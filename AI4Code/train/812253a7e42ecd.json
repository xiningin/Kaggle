{"cell_type":{"26bcb8e4":"code","bd810d56":"code","ee734699":"code","baf2958c":"code","843efd5e":"code","0690e818":"code","7ded1be8":"code","42bc17c0":"code","c47d2580":"code","d8a894f8":"code","e87b8492":"code","090a3b7f":"code","0e98a91d":"code","5bb0c0a4":"code","bf51942a":"code","5d48ed53":"code","9524c3c6":"code","e77d228a":"code","8acc73b6":"code","14b7755e":"code","99d1f1b4":"code","306ad392":"code","a47ec3c9":"code","bc9e45bd":"code","721400a5":"code","ec8a8df2":"code","4e27b0f3":"code","d70fc47b":"code","91da110a":"code","4822cced":"code","4c777573":"code","a8e0787e":"code","3f47640d":"code","0606e6eb":"code","c6499b24":"code","c3121098":"markdown","1ef8b9e1":"markdown","ba270558":"markdown","94bc0e9c":"markdown","99684c3e":"markdown","47e5152b":"markdown","54b19a76":"markdown","10689851":"markdown","c91ddaab":"markdown","6a93945e":"markdown","d9855bf9":"markdown","cec8f0fd":"markdown","c9f6d916":"markdown","841fc43d":"markdown","1f01a7e5":"markdown","38779569":"markdown","53675670":"markdown","db5e9aea":"markdown","e3867a60":"markdown","7a5ddeb5":"markdown","a2da3fa7":"markdown","217f5a85":"markdown","7c7c922c":"markdown","77a32523":"markdown","c6ddec12":"markdown","7c01abb9":"markdown","895e951e":"markdown","9e0a85c6":"markdown","8795125a":"markdown","9ace5bdf":"markdown","2a611bb7":"markdown","c98ad43c":"markdown"},"source":{"26bcb8e4":"!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n!pip install timm","bd810d56":"import os\nimport pandas as pd\nfrom scipy import stats\nimport numpy as np\nimport glob\nimport tensorflow as tf\nimport timm\nimport random\nimport time\nimport copy\nfrom operator import itemgetter\n\nfrom collections import OrderedDict, namedtuple\nimport joblib\n\nimport logging\nimport sys\n\nfrom PIL import Image\nimport cv2\nimport albumentations\nimport io\nimport IPython.display as display\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport torch.optim as optim\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.utils as xu\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics, model_selection\n\nimport warnings\nwarnings.filterwarnings(\"ignore\");","ee734699":"train_files = glob.glob('..\/input\/tpu-getting-started\/*\/train\/*.tfrec')\nval_files = glob.glob('..\/input\/tpu-getting-started\/*\/val\/*.tfrec')\ntest_files = glob.glob('..\/input\/tpu-getting-started\/*\/test\/*.tfrec')","baf2958c":"train_feature_description = {\n    'class': tf.io.FixedLenFeature([], tf.int64),\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n  # Parse the input tf.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, train_feature_description)\n\ntrain_ids = []\ntrain_class = []\ntrain_images = []\n\nfor i in train_files:\n  train_image_dataset = tf.data.TFRecordDataset(i)\n\n  train_image_dataset = train_image_dataset.map(_parse_image_function)\n\n  ids = [str(id_features['id'].numpy())[2:-1] for id_features in train_image_dataset] # [2:-1] is done to remove b' from 1st and 'from last in train id names\n  train_ids = train_ids + ids\n\n  classes = [int(class_features['class'].numpy()) for class_features in train_image_dataset]\n  train_class = train_class + classes\n\n  images = [image_features['image'].numpy() for image_features in train_image_dataset]\n  train_images = train_images + images","843efd5e":"val_feature_description = {\n    'class': tf.io.FixedLenFeature([], tf.int64),\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n  # Parse the input tf.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, val_feature_description)\n\nval_ids = []\nval_class = []\nval_images = []\n\nfor i in val_files:\n    val_image_dataset = tf.data.TFRecordDataset(i)\n\n    val_image_dataset = val_image_dataset.map(_parse_image_function)\n\n    ids = [str(image_features['id'].numpy())[2:-1] for image_features in val_image_dataset]\n    val_ids += ids\n\n    classes = [int(image_features['class'].numpy()) for image_features in val_image_dataset]\n    val_class += classes \n\n    images = [image_features['image'].numpy() for image_features in val_image_dataset]\n    val_images += images","0690e818":"test_feature_description = {\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function_test(example_proto):\n    return tf.io.parse_single_example(example_proto, test_feature_description)\n\ntest_ids = []\ntest_images = []\nfor i in test_files:\n    test_image_dataset = tf.data.TFRecordDataset(i)\n    \n    test_image_dataset = test_image_dataset.map(_parse_image_function_test)\n\n    ids = [str(id_features['id'].numpy())[2:-1] for id_features in test_image_dataset]\n    test_ids = test_ids + ids\n\n    images = [image_features['image'].numpy() for image_features in test_image_dataset]\n    test_images = test_images + images","7ded1be8":"import IPython.display as display\n\ndisplay.display(display.Image(data=val_images[1]))","42bc17c0":"class MyDataset():\n    def __init__(self, ids, cls, imgs, transforms, is_test=False):\n        self.ids = ids\n        if not is_test:\n            self.cls = cls\n        self.imgs = imgs\n        self.transforms = transforms\n        self.is_test = is_test\n    \n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        img = self.imgs[idx]\n        img = Image.open(io.BytesIO(img))\n        img = self.transforms(img)\n        if self.is_test:\n            return img, -1, self.ids[idx]\n        return img, int(self.cls[idx]), self.ids[idx]","c47d2580":"train_transforms = transforms.Compose([\n                        transforms.RandomResizedCrop(224),\n                        transforms.RandomHorizontalFlip(),\n                        transforms.RandomVerticalFlip(),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                        transforms.RandomErasing()\n                    ])\n\ntest_transforms = transforms.Compose([\n                        transforms.CenterCrop(224),\n                        transforms.Resize(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                    ])","d8a894f8":"train_ds = MyDataset(train_ids, train_class, train_images, train_transforms)\nvalid_ds = MyDataset(val_ids, val_class, val_images, test_transforms)","e87b8492":"device = xm.xla_device()","090a3b7f":"from torch.utils.data import Dataset, DataLoader, ConcatDataset\n\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_ds,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True\n    )\n\nvalid_sampler = torch.utils.data.distributed.DistributedSampler(\n        valid_ds,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True\n    )\n    \ntrain_loader = DataLoader(train_ds, 128, sampler=train_sampler, num_workers=4, pin_memory=True)\nval_loader = DataLoader(valid_ds, 128, sampler=valid_sampler, num_workers=4, pin_memory=True)\n\ndataset_sizes = {\n    'train': len(train_ds),\n    'val': len(valid_ds),\n}","0e98a91d":"dataset_sizes","5bb0c0a4":"transforms_example = transforms.Compose([\n                        transforms.CenterCrop(224),\n                        transforms.ToTensor(),])\n\nexampleset = MyDataset(train_ids, train_class, train_images, transforms_example)\n\nx, y, _ = next(iter(DataLoader(exampleset)))\n\nchannels = ['Red', 'Green', 'Blue']\ncmaps = [plt.cm.Reds_r, plt.cm.Greens_r, plt.cm.Blues_r]\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 10))\n\nfor i, axs in enumerate(fig.axes[:3]):\n    axs.imshow(x[0][i,:,:], cmap=cmaps[i])\n    axs.set_title(f'{channels[i]} Channel')\n    axs.set_xticks([])\n    axs.set_yticks([])\n    \nax[3].imshow(x[0].permute(1,2,0))\nax[3].set_title('Three Channels')\nax[3].set_xticks([])\nax[3].set_yticks([]);","bf51942a":"channels = 3\n\nloaders = {\n    'train':train_loader,\n    'val':val_loader,\n}\n\nfor channel in range(channels):\n    for x in ['train', 'val']:\n        #number of pixels in the dataset = number of all pixels in one object * number of all objects in the dataset\n        num_pxl = dataset_sizes[x]*224*224\n    \n        #we go through the butches and sum up the pixels of the objects, \n        #which then divide the sum by the number of all pixels to calculate the average\n        total_sum = 0\n        for batch in loaders[x]:\n            layer = list(map(itemgetter(channel), batch[0]))\n            layer = torch.stack(layer, dim=0)\n            total_sum += layer.sum()\n        mean = total_sum \/ num_pxl\n\n        #we calculate the standard deviation using the formula that I indicated above\n        sum_sqrt = 0\n        for batch in loaders[x]: \n            layer = list(map(itemgetter(channel), batch[0]))\n            sum_sqrt += ((torch.stack(layer, dim=0) - mean).pow(2)).sum()\n        std = torch.sqrt(sum_sqrt \/ num_pxl)\n        \n        print(f'|channel:{channel+1}| {x} - mean: {mean}, std: {std}')","5d48ed53":"x, y, _ = next(iter(exampleset))\n\ndef plotHist(img):\n  plt.figure(figsize=(10,5))\n  plt.subplot(1,2,1)\n  plt.imshow(x.permute(1,2,0))\n  plt.axis('off')\n  histo = plt.subplot(1,2,2)\n  histo.set_ylabel('Count')\n  histo.set_xlabel('Pixel Intensity')\n  plt.hist(img.numpy().flatten(), bins=10, lw=0, alpha=0.5, color='r')\n\nplotHist(x)","9524c3c6":"x.mean(), x.std()","e77d228a":"def norm_out(img):\n    \n    img = img.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    img = img*std + mean\n        \n    return np.clip(img,0,1)","8acc73b6":"def show_batch(dl):\n    \n    for images, labels, _ in dl:\n        fig, ax = plt.subplots(figsize=(25, 25))\n        ax.set_xticks([]); ax.set_yticks([])\n        #images = norm_out(images[:60])\n        ax.imshow(norm_out(make_grid(images[:60], nrow=10)))#.permute(1, 2, 0))\n        ax.set_title('Images without augmentation', fontsize=40)\n        break\n        \nshow_batch(loaders['val'])","14b7755e":"def show_batch(dl):\n    for images, labels, _ in dl:\n        fig, ax = plt.subplots(figsize=(25, 25))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:60], nrow=10).permute(1, 2, 0))\n        ax.set_title('Images with augmentation', fontsize=40)\n        break\n        \nshow_batch(loaders['train'])","99d1f1b4":"def train(loader, epoch, model, optimizer, criterion):\n   #tracker = xm.RateTracker()\n   model.train()\n   running_loss = 0.\n   running_corrects = 0.\n   tot = 0\n   for i, (ip, tgt, _) in enumerate(loader):\n      ip, tgt = ip.to(device), tgt.to(device)                            \n      output = model(ip)\n      loss = criterion(output, tgt)\n      tot += ip.shape[0]\n\n      # Append outputs\n      _, pred = output.max(dim=1)\n      running_corrects += torch.sum(pred == tgt.data)\n\n      # compute gradient and do SGD step\n      optimizer.zero_grad()\n      loss.backward()\n      #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n      #optimizer.step()\n      xm.optimizer_step(optimizer)\n\n      running_loss += loss.item()*ip.size(0)\n\n   return running_corrects, running_loss","306ad392":"def test(loader, model, criterion):\n        with torch.no_grad():\n            model.eval()\n            running_loss = 0.\n            running_corrects = 0.\n            tot = 0\n            for i, (ip, tgt, _) in enumerate(loader):\n                ip, tgt = ip.to(device), tgt.to(device)\n                output = model(ip)\n                loss = criterion(output, tgt)\n                tot += ip.shape[0]\n                _, pred = output.max(dim=1)\n                running_corrects += torch.sum(pred == tgt.data)\n                running_loss += loss.item()*ip.size(0)\n\n            return running_corrects, running_loss","a47ec3c9":"def predict(model, loader, device):\n    with torch.no_grad():\n        torch.cuda.empty_cache()\n        model.eval()\n        preds = dict()\n        for i, (ip, _, ids) in enumerate(loader):\n            ip = ip.to(device)\n            output = model(ip)\n            _, pred = output.max(dim=1)\n            for i, j in zip(ids, pred.cpu().detach()):\n                preds[i] = j\n            \n        return preds","bc9e45bd":"losses = {'train':[], 'val':[]}\naccuracies = {'train':[], 'val':[]}","721400a5":"def fit(seed, epochs, model):\n\n  # Train and valid dataloaders\n  xm.master_print('Creating a model {}...'.format(seed))\n  device = xm.xla_device()\n  WRAPPED_MODEL = xmp.MpModelWrapper(model)\n  model = WRAPPED_MODEL.to(device)\n  model.to(device)  \n  criterion = nn.CrossEntropyLoss()\n\n  if seed==1:\n        optimizer = torch.optim.Adam(model.head.parameters(), lr=0.001* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n  if seed==2 or seed==3:\n    optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n  if seed==4 or seed==0:\n    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n#   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n\n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  for epoch in range(epochs):\n    \n    #train\n    xm.master_print('Epoch: {}\/{}'.format(epoch+1, epochs))\n    para_loader = pl.ParallelLoader(train_loader, [device])\n    running_corrects, running_loss = train(para_loader.per_device_loader(device), epoch, model, optimizer, criterion)\n    epoch_loss = running_loss \/ dataset_sizes['train']\n    epoch_acc = running_corrects\/dataset_sizes['train']\n    losses['train'].append(epoch_loss)\n    accuracies['train'].append(epoch_acc)\n    xm.master_print('{} - loss:{}, accuracy{}'.format('train', epoch_loss, epoch_acc))\n\n    #val\n    para_loader = pl.ParallelLoader(val_loader, [device])\n    running_corrects, running_loss = test(para_loader.per_device_loader(device), model, criterion)\n    epoch_loss = running_loss \/ dataset_sizes['val']\n    epoch_acc = running_corrects\/dataset_sizes['val']\n    losses['val'].append(epoch_loss)\n    accuracies['val'].append(epoch_acc)\n    xm.master_print('{} - loss:{}, accuracy{}'.format('val', epoch_loss, epoch_acc))\n    \n    #epoch end\n    xm.master_print('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n    xm.master_print('=='*31)\n    if epoch_acc > best_acc:\n      best_acc = epoch_acc\n      best_model = copy.deepcopy(model.state_dict())\n    scheduler.step()\n      \n  time_elapsed = time.time() - since\n  xm.master_print('CLASSIFIER TRAINING TIME {}m {}s'.format(time_elapsed\/\/60, time_elapsed%60))\n  xm.master_print('=='*31)\n\n\n  model.load_state_dict(best_model)\n\n  for param in model.parameters():\n        param.requires_grad=True\n\n  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=0)  \n#   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  for epoch in range(epochs):\n\n    #train\n    xm.master_print('Epoch: {}\/{}'.format(epoch+1, epochs))\n    para_loader = pl.ParallelLoader(train_loader, [device])\n    running_corrects, running_loss = train(para_loader.per_device_loader(device), epoch, model, optimizer, criterion)\n    epoch_loss = running_loss \/ dataset_sizes['train']\n    epoch_acc = running_corrects\/dataset_sizes['train']\n    losses['train'].append(epoch_loss)\n    accuracies['train'].append(epoch_acc)\n    xm.master_print('{} - loss:{}, accuracy{}'.format('train', epoch_loss, epoch_acc))\n\n    #val\n    para_loader = pl.ParallelLoader(val_loader, [device])\n    running_corrects, running_loss = test(para_loader.per_device_loader(device), model, criterion)\n    epoch_loss = running_loss \/ dataset_sizes['val']\n    epoch_acc = running_corrects\/dataset_sizes['val']\n    losses['val'].append(epoch_loss)\n    accuracies['val'].append(epoch_acc)\n    xm.master_print('{} - loss:{}, accuracy{}'.format('val', epoch_loss, epoch_acc))\n    \n    #epoch end\n    xm.master_print('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n    xm.master_print('=='*31)\n    if epoch_acc > best_acc:\n      best_acc = epoch_acc\n      best_model = copy.deepcopy(model.state_dict())\n    scheduler.step()\n\n  time_elapsed = time.time() - since\n  xm.master_print('ALL NET TRAINING TIME {}m {}s'.format(time_elapsed\/\/60, time_elapsed%60))\n  xm.master_print('=='*31)\n\n  model.load_state_dict(best_model)\n    \n  predictions = predict(model, testloader, device)\n  for key in predictions.keys():\n    ensemble_df.loc[ensemble_df['id'] == key, 'model_' + str(seed + 1)] = int((predictions[key]).item())\n  \n  xm.master_print('Prediction Saved! \\n')","ec8a8df2":"densenet121 = torchvision.models.densenet121(pretrained=True)\nfor param in densenet121.parameters():\n  param.requires_grad=False\n\ndensenet121.classifier = nn.Linear(in_features=densenet121.classifier.in_features, out_features=104, bias=True)","4e27b0f3":"ViT  = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\nfor param in ViT.parameters():\n  param.requires_grad=False\n\nViT.head = nn.Linear(ViT.head.in_features, 104)","d70fc47b":"googlenet = torchvision.models.googlenet(pretrained=True)\nfor param in googlenet.parameters():\n  param.grad_requires = False\n\ngooglenet.fc = nn.Linear(in_features=googlenet.fc.in_features, out_features=104, bias=True)","91da110a":"resnet101 = torchvision.models.resnet101(pretrained=True)\nfor param in resnet101.parameters():\n  param.grad_requires = False\n\nresnet101.fc = nn.Linear(in_features=resnet101.fc.in_features, out_features=104, bias=True)","4822cced":"vgg19_bn = torchvision.models.vgg19_bn(pretrained=True)\nfor param in vgg19_bn.parameters():\n  param.grad_requires = False\n\nvgg19_bn.classifier[6] = nn.Linear(4096, 104, bias=True)","4c777573":"test_transforms = transforms.Compose([\n                        transforms.CenterCrop(224),\n                        transforms.Resize(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                    ])\n\ntest_ds = MyDataset(test_ids, [], test_images, test_transforms, True)\ntestloader = DataLoader(test_ds, 128, num_workers=4, pin_memory=True, shuffle=False)\n\nsubmit_df = pd.read_csv('..\/input\/tpu-getting-started\/sample_submission.csv')\nensemble_df = submit_df.copy()\n\nnum_models = 5\nnum_epochs = 10\n\nmodels = [densenet121, ViT, googlenet, resnet101, vgg19_bn]\n\nfor seed in range(num_models):\n   preds = fit(seed=seed, epochs=num_epochs, model=models[seed])","a8e0787e":"ensemble_df.head(10)","3f47640d":"# Final prediction\nfinal_pred = ensemble_df.iloc[:,2:].mode(axis=1).iloc[:,0]\nsubmit_df.label = final_pred.astype(int)\nsubmit_df.head(10)","0606e6eb":"# Create a submission file\nsubmit_df.to_csv('submission11062021.csv', index=False)","c6499b24":"fig, ax = plt.subplots(5, 2, figsize=(15, 15))\nmodelname = ['DenseNet', 'ViT', 'GoogLeNet', 'ResNet101', 'VGG16 with BN']\n\nepochs=10\n\ni=0\n\nfor row in range(5):\n\n  epoch_list = list(range(1,epochs*2+1))\n\n  ax[row][0].plot(epoch_list, accuracies['train'][i:20+i], '-o', label='Train Accuracy')\n  ax[row][0].plot(epoch_list, accuracies['val'][i:20+i], '-o', label='Validation Accuracy')\n  ax[row][0].plot([epochs for x in range(20)],  np.linspace(min(accuracies['train'][i:20+i]).cpu(), max(accuracies['train'][i:20+i]).cpu(), 20), color='r', label='Unfreeze net')\n  ax[row][0].set_xticks(np.arange(0, epochs*2+1, 5))\n  ax[row][0].set_ylabel('Accuracy Value')\n  ax[row][0].set_xlabel('Epoch')\n  ax[row][0].set_title('Accuracy {}'.format(modelname[row]))\n  ax[row][0].legend(loc=\"best\")\n\n  ax[row][1].plot(epoch_list, losses['train'][i:20+i], '-o', label='Train Loss')\n  ax[row][1].plot(epoch_list, losses['val'][i:20+i], '-o',label='Validation Loss')\n  ax[row][1].plot([epochs for x in range(20)], np.linspace(min(losses['train'][i:20+i]), max(losses['train'][i:20+i]), 20), color='r', label='Unfreeze net')\n  ax[row][1].set_xticks(np.arange(0, epochs*2+1, 5))\n  ax[row][1].set_ylabel('Loss Value')\n  ax[row][1].set_xlabel('Epoch')\n  ax[row][1].set_title('Loss {}'.format(modelname[row]))\n  ax[row][1].legend(loc=\"best\")\n  fig.tight_layout()\n  fig.subplots_adjust(top=1.5, wspace=0.3)\n\n  i+=20","c3121098":"**Let's take a batch from the training dataset and see its mean and standard deviation:**","1ef8b9e1":"# **MODELS**","ba270558":"# **5. Learning Visualization**","94bc0e9c":"**Let's write our dataset**","99684c3e":"**Here we read tfrecords files in PyTorch. I recommend** https:\/\/medium.com\/analytics-vidhya\/how-to-read-tfrecords-files-in-pytorch-72763786743f","47e5152b":"**Let's take a quick look at the data. I don't know about you, but the first thing I always want to do is look at what our data looks like :)**","54b19a76":"# **0. Importing Libraries**\n","10689851":"# **3. Training and Test**\n**Idea:** I will use an ensemble of pre-trained models, the idea is this: I first train only the classifier on 10 epochs, then unfreeze the network and train all together for another 10 epochs. After that, the model makes predictions on the test data","c91ddaab":"**Let's take a look at the pixel distribution after normalization**","6a93945e":"**This is where we will record the history of learning, so that we can make visualization later. We need visualization to evaluate learning, for example, overfitting or underfitting. Of course, we can analyze with numbers, but it is much easier to perceive information visually**","d9855bf9":"# **2. Data preparation**","cec8f0fd":"**Now let's check how well we managed to normalize the data for each channel for the test, training and validation datasets:**","c9f6d916":"**Paths**","841fc43d":"**We have already normalized the data, but at this stage I would like to dwell in more detail, because this is very important.**\n\nIn datasets, we have three-channel images, that is, we need to normalize for each channel separately (!!!). Because of the unnormalized data, problems may appear, for example, regularization during training can work to the detriment, but we do not want this at all. The task of normalization is to make the mean as close to zero as possible, and the standard deviation around 1.\n\nHow each channel looks separately can be seen below:","1f01a7e5":"**4. ResNet**","38779569":"PyTorch \/ XLA adds a new xla device type to PyTorch. This device type works just like other PyTorch device types.","53675670":"**Val for one epoch**","db5e9aea":"**3. GoogLeNet**","e3867a60":"**Let's write augmentation and normalization right away**","7a5ddeb5":"**PyTorch\/XLA**\n\nThe PyTorch-TPU project was born out of a collaborative effort between the Facebook PyTorch and Google TPU teams and was officially launched at the 2019 PyTorch Developer Conference. This new integration enables PyTorch users to run and scale up their models on Cloud TPUs. PyTorch \/ XLA package lets PyTorch connect to Cloud TPUs and use TPU cores as devices","a2da3fa7":"**Function for predictions on a test set**","217f5a85":"**Launching training**","7c7c922c":"Fit function structure:\n\n1. **Classifier Training**\n2. **Network-wide Training**\n3. **Predictions**","77a32523":"**Training for one epoch**","c6ddec12":"**5. VGG19**","7c01abb9":"# **4. Submit Preparing**","895e951e":"# **1. Data Loading**","9e0a85c6":"**1. DenseNet**","8795125a":"**In a typical XLA:TPU training scenario we\u2019re training on multiple TPU cores in parallel (a single Cloud TPU device includes 8 TPU cores). So we need to ensure that all the gradients are exchanged between the data parallel replicas by consolidating the gradients and taking an optimizer step. For this we provide the xm.optimizer_step(optimizer) which does the gradient consolidation and step-taking**","9ace5bdf":"![1_uR7-mfI6AE6cqGqG0rDE8w.png](attachment:4596314f-fe69-4967-83ad-83da11c6d918.png)","2a611bb7":"**As you can see, the idea of defrosting feature extractor worked and we see a sharp increase in accuracy**","c98ad43c":"**2. ViT**"}}