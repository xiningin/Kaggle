{"cell_type":{"a1fecb00":"code","cde6269e":"code","bb8404f9":"code","b59163c2":"code","83a96217":"code","f2fc2169":"code","854b22cd":"code","3ac6f5f9":"code","bd140d56":"code","e7cab7b6":"code","c98d53b5":"code","a6b620fa":"code","c896192b":"code","bd9c23e2":"code","6ab8d013":"markdown","6e037c5b":"markdown","176d571b":"markdown","2dd98068":"markdown","438da265":"markdown","fb40af60":"markdown","0ef9f0ca":"markdown"},"source":{"a1fecb00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cde6269e":"import pandas as pd\nimport numpy as np\nimport datetime\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.metrics import r2_score\nimport warnings\nwarnings.warn = False","bb8404f9":"train = pd.read_csv('..\/input\/restaurant-revenue-prediction\/train.csv')\ntest  = pd.read_csv('..\/input\/restaurant-revenue-prediction\/test.csv')\n\nprint(\"Training set = \",train.shape)\nprint(\"Testing set = \",test.shape)\nprint(\"Sum of Missing Values (Train\/Test)= \",train.isna().sum().sum(),\"(\",test.isna().sum().sum(),\")\")","b59163c2":"train.head()","83a96217":"quater_id=[1,1,1,1,2,2,2,3,3,3,4,4,4]\n\n# Working with Training Data\ntrain['year']  = pd.DatetimeIndex(train['Open Date']).year\ntrain['month'] = pd.DatetimeIndex(train['Open Date']).month\ntrain['day']   = pd.DatetimeIndex(train['Open Date']).day\ntrain = train.drop(columns=['Open Date'])\n\ntrain['quater']=[quater_id[i] for i in train.month]\ntrain['first_week'] = train.day.apply(lambda x: 1 if x<= 7 else 0)\ntrain['last_week']  = train.day.apply(lambda x: 1 if x>=21 else 0)\ntrain['rev_slot'] = pd.qcut(train['revenue'], 20, labels=False)\n\n\n# Working with Testing Data\ntest['year']  = pd.DatetimeIndex(test['Open Date']).year\ntest['month'] = pd.DatetimeIndex(test['Open Date']).month\ntest['day']   = pd.DatetimeIndex(test['Open Date']).day\ntest = test.drop(columns=['Open Date'])\n\ntest['quater']=[quater_id[i] for i in test.month]\ntest['first_week'] = test.day.apply(lambda x: 1 if x<= 7 else 0)\ntest['last_week']  = test.day.apply(lambda x: 1 if x>=21 else 0)\n\n\n# Display changes in Training Data\ntrain.head()","f2fc2169":"def define_weekdays(data):\n   \n  data['day_value'] = pd.DataFrame([datetime.date(data.year[i],data.month[i],data.day[i]).weekday() for i in range(data.shape[0])])\n  data['weekdays'] = np.where(data.day_value<5, 1,0)\n  data['weekend'] = 1-data['weekdays']\n  return data\n\ntrain = define_weekdays(train) \ntest  = define_weekdays(test) \n\ntrain.head()","854b22cd":"def get_feature_count(data):\n  col_names = ['City','City Group','Type','year','quater','month','first_week','last_week','day','weekdays','weekend','rev_slot']\n  df_all=pd.DataFrame()\n  for i in col_names:\n    u = data[i].unique()\n    temp=pd.DataFrame()\n    for j in u:\n      m = (data[i]==j).sum()\n      temp = temp.append([[j,m]])\n    temp['col_name'] = i    \n    df_all = df_all.append(temp)\n\n  df_all.columns = ['X','Y','Feature']\n  return df_all\n\ndf = get_feature_count(train)\n\nfig=px.bar(data_frame=df, x='X',y='Y',color='Y',facet_col='Feature',facet_col_wrap=4,height=600)\nfig.update_xaxes(matches=None)\nfig.update_yaxes(matches=None)\nfig.show()","3ac6f5f9":"def get_feature_count(data):\n  col_names = ['City','City Group','Type','year','quater','month','first_week','last_week','day','weekdays','weekend']\n  df_all=pd.DataFrame()\n  for i in col_names:\n    u = data[i].unique()\n    temp=pd.DataFrame()\n    for j in u:\n      m = data.revenue[data[i]==j].mean()\n      temp = temp.append([[j,m]])\n    temp['col_name'] = i\n    df_all = df_all.append(temp)\n\n  df_all.columns = ['X','Y','Feature']\n  return df_all\n\ndf = get_feature_count(train)\n\n\nfig=px.bar(data_frame=df, x='X',y='Y',color='Y',facet_col='Feature',facet_col_wrap=4,height=600)\nfig.update_xaxes(matches=None)\nfig.update_yaxes(matches=None)\nfig.show()","bd140d56":"# One-Hot Encoding\nprint(\"Prior to One-Hot Encoding\",train.shape,\" : \",test.shape)\nOHE_cols = ['City','City Group','Type','weekdays']\ntrain = pd.get_dummies(train, columns = OHE_cols, drop_first = True)\ntest  = pd.get_dummies(test,  columns = OHE_cols, drop_first = True)\nprint(\"Post to One-Hot Encoding\",train.shape,\" : \",test.shape)","e7cab7b6":"# Train-Test Dataset Ready\ny_train = train.revenue\nX_train = train.drop(['Id','revenue','rev_slot'],axis=1)\ntest    = test.drop(['Id'],axis=1)\n\nprint(train.shape,test.shape) ","c98d53b5":"# Remove columns which exists in Training data but is missing in Testing Data or Vice-Versa\n\ndef remove_columns(columns_a,columns_b):    \n  col_list = []\n  for i in columns_a:\n    flag=0\n    for j in columns_b:\n      if i==j:              \n        flag=1\n        break\n    if flag==0:            \n      col_list.append(i)              \n  return col_list\n    \ncol_list_1 = remove_columns(X_train.columns,test.columns)\ncol_list_2 = remove_columns(test.columns,X_train.columns)\n\nX_train = X_train.drop(columns=col_list_1,axis=1)\ntest = test.drop(columns=col_list_2,axis=1)\n\nprint(\"Post dropping columns from Training Data\",X_train.shape)\nprint(\"Post dropping columns from Testing Data\",test.shape) ","a6b620fa":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression(fit_intercept=True,normalize=False)\nlr.fit(X_train,y_train)\ny_pred1 = lr.predict(X_train)\n\nprint(\"Training performance from Linear Regression = \",abs(r2_score(y_train,y_pred1)))","c896192b":"# Cannot use Lasso or Elastic Net: Variables are highly correlated, so LASSO may eliminate wrongly\n\nfrom sklearn.linear_model import Ridge\nrd = Ridge(alpha=1.0, max_iter=100, tol=0.0001, random_state=100)\nrd.fit(X_train,y_train)\ny_pred2 = rd.predict(X_train)\n\nprint(\"Training performance from Ridge Regression = \",abs(r2_score(y_train,y_pred2)))","bd9c23e2":"y_pred = (0.7*y_pred1+0.3*y_pred2)\nprint(\"Training performance from Linear and Ridge Regression = \",abs(r2_score(y_train,y_pred)))\ny_pred = (0.5*y_pred1+0.5*y_pred2)\nprint(\"Training performance from Linear and Ridge Regression = \",abs(r2_score(y_train,y_pred)))\ny_pred = (0.3*y_pred1+0.7*y_pred2)\nprint(\"Training performance from Linear and Ridge Regression = \",abs(r2_score(y_train,y_pred)))\n\n# Performance will be obtained in-between Linear and Ridge Regression. \n# Thus, one or more models must be considered for taking an average or perform second stage regression.","6ab8d013":"## Bivariate Analysis","6e037c5b":"#### Average Response","176d571b":"# Feature Engineering","2dd98068":"### Ridge Regression","438da265":"### Linear Regression","fb40af60":"# Regression Modeling","0ef9f0ca":"## Univariate Analysis"}}