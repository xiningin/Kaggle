{"cell_type":{"b4800959":"code","24e69689":"code","b7404367":"code","47264d8d":"code","81acb7a8":"code","129a09e0":"code","2ac5c4b9":"code","c58ff68b":"code","326f19f1":"code","14b0f2a3":"code","6896e4bf":"code","fe7c53da":"code","a7ff9fbc":"code","697c75d7":"code","cc5f4b5f":"code","ada2a45f":"code","cea84588":"code","9c9fc307":"code","b21c2ba5":"code","8fe9fb2c":"code","5376eb79":"code","a300cb88":"code","92b6fd0b":"code","71dcbfc9":"code","3abc201c":"code","9a7ddfbc":"code","976296b8":"code","3daf463e":"code","3955bee5":"code","61b00d16":"code","70bfe9f9":"code","9b64b6a0":"code","e085332d":"code","10b97119":"code","286c35b5":"code","f707d594":"code","f339141b":"code","6f4a014f":"code","ff038a30":"code","7a850048":"code","ebd7a67a":"code","2b524b92":"code","451f547d":"code","422759a5":"code","41b304bd":"code","bdfd48a1":"code","7a18a228":"code","027ad1bd":"code","edfcfd6c":"code","7c0660b9":"code","322726ec":"code","e3bf4860":"code","dbe1646b":"code","92106e1e":"code","619fea5e":"code","33d817c6":"code","61fc174a":"code","fbb4706d":"code","770aea55":"code","90864226":"code","11860df2":"code","d3b7da50":"code","5101aa60":"code","778a6c57":"code","b5b11f02":"code","43dd6d58":"code","8ac4058d":"code","32ce55de":"code","c0404972":"code","3a30b056":"code","d72039cc":"code","5a2b28ee":"code","9645544d":"code","1c58b397":"code","cf12d96f":"code","ab65fb3f":"code","9e686b27":"code","4b99f97e":"code","23e3a025":"code","6b394911":"code","865aff05":"code","9abd1bd0":"code","f90a4c91":"code","1b5f5c3f":"code","bce710d1":"code","1a60e457":"code","7c200d32":"code","d0e22050":"code","6a9afc39":"code","e06470cf":"code","65945f13":"markdown","91c55c9d":"markdown","739d8cb1":"markdown","1dd3f77e":"markdown","0bc34859":"markdown","7347911e":"markdown","3bce08ac":"markdown","eb35f86a":"markdown","2aa02cbc":"markdown","49459190":"markdown","c3c66bc6":"markdown","1051fb01":"markdown","e06d90f5":"markdown","98774bd7":"markdown","e5aab367":"markdown","e510c809":"markdown","0991be5c":"markdown","a08a28ea":"markdown","f0a5dae8":"markdown","9fd0d77a":"markdown","5db861e7":"markdown","574c1f9f":"markdown","c7432c28":"markdown","81eb559b":"markdown","e5faca3c":"markdown","e3238b85":"markdown"},"source":{"b4800959":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np \nimport re\nimport json\nimport datetime as dt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nimport unicodedata #\u0434\u043b\u044f \u0442\u0440\u0430\u043d\u0441\u043b\u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438 \u043d\u0435 ASCII\nimport unidecode #\u0434\u043b\u044f \u0442\u0440\u0430\u043d\u0441\u043b\u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438 \u043d\u0435 ASCII \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport itertools\n%matplotlib inline\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","24e69689":"# \u0437\u0430\u0444\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u0432\u0435\u0440\u0441\u0438\u044e \u043f\u0430\u043a\u0435\u0442\u043e\u0432, \u0447\u0442\u043e\u0431\u044b \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u0431\u044b\u043b\u0438 \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u044b:\n!pip freeze > requirements.txt","b7404367":"# \u0414\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u0437\u0430\u0434\u0430\u0434\u0438\u043c:\n# - \u043e\u0431\u0449\u0438\u0439 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0447\u0438\u0441\u0435\u043b\nRANDOM_SEED = 20726\n# - \u043e\u0431\u0449\u0443\u044e \u0442\u0435\u043a\u0443\u0449\u0443\u044e \u0434\u0430\u0442\u0443\nCURRENT_DATE = pd.to_datetime('22\/02\/2020')\n","47264d8d":"DATA_DIR = '\/kaggle\/input\/sf-dst-restaurant-rating\/'\ndf_in = pd.read_csv(DATA_DIR+'main_task.csv')\n# \u041f\u0443\u0442\u044c \u043a \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0443 \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c \u0440\u0435\u0439\u0442\u0438\u043d\u0433\ndf_kagle = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n#\u041f\u0443\u0442\u044c \u043a 'submission.csv'\nsubmission_path = pd.read_csv(DATA_DIR+'sample_submission.csv')","81acb7a8":"DS_IMPORT_SC_DIR = '\/kaggle\/input\/cities-and-countries\/'\n# \u041f\u0443\u0442\u044c \u043a \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0443 \u0441\u0442\u0440\u0430\u043d - \u043e\u0442\u0441\u044e\u0434\u0430 \u0431\u0435\u0440\u0435\u043c \u0441\u0442\u043e\u043b\u0438\u0446\u044b\ndf_county = pd.read_csv(DS_IMPORT_SC_DIR+'country-list.csv')\n#\u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043f\u043e \u0433\u043e\u0440\u043e\u0434\u0430\u043c \u0438 \u0441\u0442\u0440\u0430\u043d\u0430\u043c\ndf_urb_xls = pd.read_excel(DS_IMPORT_SC_DIR+'global-city-population-estimates.xls', index_col=None, header=0, sheet_name = 'CITIES-OVER-300K')\n\n# \u041f\u0443\u0442\u044c \u043a \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0443, \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0435\u043c\u0443 \u0441\u043b\u043e\u0432\u0430 \u0441 \u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u043e\u0439 \u043e\u043a\u0440\u0430\u0441\u043a\u043e\u0439\ndf_pos_words = pd.read_csv('\/kaggle\/input\/opinion-lexicon-english\/positive-words.txt',skiprows=34, names=['word'])\npos_words_list = df_pos_words['word'].to_list() ","129a09e0":" def get_season(date):\n    '''\n    \u0412\u0440\u0435\u043c\u044f \u0433\u043e\u0434\u0430 \u0438\u0437 \u0434\u0430\u0442\u044b\n    '''\n    if (pd.isna(date)):\n        return \"OTHER\"\n    month = date.month\n    if (month > 11 or month <= 3):\n       return \"WINTER\"\n    elif (month == 4 or month == 5):\n       return \"SPRING\"\n    elif (month >=6 and month <= 9):\n       return \"SUMMER\"\n    else:\n       return \"FALL\"","2ac5c4b9":"def round_of_rating(number):\n    \"\"\"\n    \u041e\u043a\u0440\u0443\u0433\u043b\u044f\u0435\u043c \u0434\u043e 0.5\n    \"\"\"\n    return np.round(number * 2) \/ 2","c58ff68b":"def get_Weighed_Rank_RK(row):\n    '''\n    \u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u043f\u043e\u0437\u0438\u0446\u0438\u044e \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \u0441\u0440\u0435\u0434\u0438 \u0432\u0441\u0435\u0445 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u0433\u043e\u0440\u043e\u0434\u0430\n    '''\n    Weighed_Rank = row['Ranking'] \/ row['Restaurants Count']\n\n    return Weighed_Rank","326f19f1":"def get_Weighed_Rank(row):\n    i=0\n    city_min = CityMinMax[CityMinMax['City'] == row.City ]['min'].iloc[0]\n    city_max = CityMinMax[CityMinMax['City'] == row.City ]['max'].iloc[0]\n    Weighed_Rank = round(1-(row['Ranking'] - city_min)\/(city_max - city_min),3)\n    #print('<---',Weighed_Rank,'--->')\n    return Weighed_Rank","14b0f2a3":"def rev_time_delta(reviews):\n    '''\n    \u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u0432\u0440\u0435\u043c\u044f \u043c\u0435\u0436\u0434\u0443 review \u0432 \u0434\u043d\u044f\u0445\n    '''\n    if (pd.notna(reviews)):\n        reviews_dt_list = get_reviews(reviews)['reviews_dt']\n        if reviews_dt_list:\n            return (max(reviews_dt_list) - min(reviews_dt_list)).days\n        else:\n            return dt.timedelta(days=3650).days\n    else:\n        return dt.timedelta(days=3650).days","6896e4bf":"def get_reviews(rev):\n    '''\n    \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c review \u0432 \u0432\u0438\u0434\u0435:\n    review['reviews_txt'][1] - list of reviews\n    review['reviews_dt'][1] - list of reviews dates\n    '''\n    if  not pd.isna(rev): \n        rev = str(rev).replace(\"'\",'\"')\n        rev = rev.replace('], [', '], \"reviews_dt\": [')\n        rev = '{ \"reviews_txt\":' + rev + '}'\n        rev = rev.replace('[[','[').replace(']]',']')\n        d = json.loads(rev)\n\n        d['reviews_dt'] = [dt.datetime.strptime(date, '%m\/%d\/%Y').date() if len(date.split('\/')[2])==4 else dt.datetime.strptime(date, '%m\/%d\/%y').date() for date in d['reviews_dt']]\n        return d\n    else:\n        return {}","fe7c53da":"def get_cuisines(cuisines):\n    '''\n    \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u0443\u0445\u043e\u043d\u044c \u0432 \u0432\u0438\u0434\u0435:\n    cuisines[0] - list of cusines\n    \u0435\u0441\u043b\u0438 \u0431\u044b\u043b NaN, \u0442\u043e \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442\u0441\u044f 'Regionl Cusine' -\u043a\u0430\u043a \u0441\u0430\u043c\u0430\u044f \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u0430\u044f \u0432 \u0440\u0435\u0433\u0438\u043e\u043d\u0435\/\u0433\u043e\u0440\u043e\u0434\u0435\/\u0441\u0442\u0440\u0430\u043d\u0435\n    '''\n    if cuisines == 'NaN': return ['Regionl Cusine']#['Vegetarian Friendly'] # 'Vegetarian Friendly' - \u0441\u0430\u043c\u0430\u044f \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u0430\u044f\n    if  cuisines:\n        cuisines = str(cuisines).replace(\"'\",'\"')\n        return json.loads(cuisines)\n    else:\n        return ['Regionl Cusine'] #return ['Vegetarian Friendly']","a7ff9fbc":"allCusines = []\ndef cuisine_styles_count(row):\n    '''\n    \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u0443\u0445\u043e\u043d\u044c\n    '''\n    global allCusines\n    cusines = get_cuisines(row['Cuisine Style'])\n    \n    if row['Cuisine Style'] != 'NaN':    \n        cusines = get_cuisines(row['Cuisine Style'])\n        allCusines.extend(cusines)\n        cuisines_count =len(cusines)\n    else:\n        cuisines_count = 1\n\n    return cuisines_count","697c75d7":"def cleanup_string(str_in):\n    '''\n    \"\u0427\u0438\u0441\u0442\u0438\u043c\" \u0442\u0435\u043a\u0441\u0442 \u0432 review \u0434\u043b\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0439 \u0434\u0435\u0441\u0435\u0440\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438\n    \u041f\u043e\u043a\u0430 \u0442\u0435\u043a\u0441\u0442 \u0432 \u0430\u043d\u0430\u043b\u0438\u0437\u0435 \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f, \u043d\u0435 \u0443\u0441\u043f\u0435\u043b... \n    '''\n    try:      \n        \n        #middle\n\n        str = str_in.replace(\"', \\\"\",\"\u215e\").replace(\"', '\",\"\u215e\").replace(\"\\\", '\",\"\u215e\").replace(\"\\\", \\\"\",\"\u215e\")# \", \n        str = str.replace(\"\\\", \\\"\\\"\",\"\u215e\").replace(\"\\\"\\\", '\",\"\u215e\").replace(\"\\\", \\'\",\"\u215e\").replace(\"\\\"\\\", \\'\",\"\u215e\")\n        str = str.replace(\"\\', \\'\",\"\u215e\")\n        #middle\n        #left\n        str = str.replace(\"[['\",\"\u2264\").replace(\"['\",\"\u215b\")\n        #left\n        #right\n        str = str.replace(\"']]\",\"\u2265\").replace(\"']\",\"\u215d\")\n        #right\n        #cleanups\n        str = str.replace('\\'', ' ').replace('\\\"', ' ').replace('\\'', ' ').replace('\"', ' ')     \n        str = str.replace(\"\\\\\", \" \").replace(\"[[`\", \"\u2264\").replace('\\'\"', '\\'').replace('\\'\\\"', '\\'')\n        str = str.replace('\"\\'', '\\'').replace('\\\"\\'', '\\'').replace(\"[''\" ,\"\u2264\").replace(\"[\\'\\'\" ,\"\u2264\")\n        str = str.replace('\\'', ' ').replace('\\\"', ' ')\n        str = str.replace('\\'', ' ').replace('\\\"', ' ')\n        str = str.replace('\\'', ' ').replace('\"', ' ')\n        #cleanups\n        #middle\n        str = str.replace(\"\u215e\", \"', '\")\n        #middle\n        #left\n        str = str.replace(\"\u2264\", \"[['\").replace(\"\u215b\", \"['\").replace('[[ ', '[[ \\'')\n        #left\n        #right\n        str = str.replace(\"\u2265\" ,\"']]\").replace(\"\u215d\", \"']\").replace(' ]', ' \\']')\n        str = str.replace(', nan]', '\\', \\'nan\\']').replace('[nan, ', '[\\'nan\\', \\'')\n        #right\n    except Exception:\n        print('<----',str_in,'---->')\n    return str","cc5f4b5f":"def get_city_population_and_country():\n    '''\n    \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0438\u044e \u043f\u043e \u0433\u043e\u0440\u043e\u0434\u0430\u043c, \u0430 \u0442\u0430\u043a \u0436\u0435 ISO \u043a\u043e\u0434 \u0441\u0442\u0440\u0430\u043d\u044b \u043f\u043e \u0433\u043e\u0440\u043e\u0434\u0443 (\u0438\u0437 \u0432\u043d\u0435\u0448\u043d\u0438\u0445 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u043e\u0432)\n    '''\n    population_city_dict = {}\n    country_city_dict = {}\n    cities = df['City'].unique()\n    # \u0427\u0438\u0441\u0442\u0438\u043c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0433\u043e\u0440\u043e\u0434\u043e\u0432 \u043e\u0442 Unicode \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432 - \u0442\u0440\u0430\u043d\u0441\u043b\u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0435\u0439\n    df_urb_xls['Urban Agglomeration TL'] = df_urb_xls['Urban Agglomeration'].apply(lambda s: ''.join((c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')) )\n    df_urb_xls['Urban Agglomeration TL'] =  df_urb_xls['Urban Agglomeration'].apply(lambda x: unidecode.unidecode(x))\n\n    for city in cities:\n        vals = df_urb_xls[df_urb_xls['Urban Agglomeration TL'].str.contains(city)]['2015'].max()\/1000\n        vals = 0.3 if pd.isna(vals) else vals # \u0442.\u043a. \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 \u0433\u043e\u0440\u043e\u0434\u0430 \u043e\u0442 300\u0442\u044b\u0441\n        population_city_dict[city] = vals\n        country = df_urb_xls[df_urb_xls['Urban Agglomeration TL'].str.contains(city)]['Country Code']\n        country = -1 if country.shape[0] < 1 else country.values[0]\n        country_city_dict[city] = country\n\n    population_city_dict['Luxembourg'] = 0.613894 \n    population_city_dict['Brussels'] = 2.115468 \n    population_city_dict['Geneva'] = 0.686562 \n    population_city_dict['Oporto'] = 0.214349 \n    population_city_dict['Ljubljana'] = 0.279631\n\n\n\n    country_city_dict['Luxembourg'] = 442 \n    country_city_dict['Brussels'] = 56 \n    country_city_dict['Geneva'] = 756 \n    country_city_dict['Oporto'] = 620 \n    country_city_dict['Ljubljana'] = 705\n    \n    #\u0412\u0438\u0434\u0438\u043c\u043e, \u044d\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u0435\u0435???\n    population_city_dict = {    'London': 8.173900,\n    'Paris': 2.240621,\n    'Madrid': 3.155360,\n    'Barcelona': 1.593075,\n    'Berlin': 3.326002,\n    'Milan': 1.331586,\n    'Rome': 2.870493,\n    'Prague': 1.272690,\n    'Lisbon': .547733,\n    'Vienna': 1.765649,\n    'Amsterdam': .825080,\n    'Brussels': .144784,\n    'Hamburg': 1.718187,\n    'Munich': 1.364920,\n    'Lyon': .496343,\n    'Stockholm': 1.981263,\n    'Budapest': 1.744665,\n    'Warsaw': 1.720398,\n    'Dublin': .506211 ,\n    'Copenhagen': 1.246611,\n    'Athens': 3.168846,\n    'Edinburgh': .476100,\n    'Zurich': .402275,\n    'Oporto': .221800,\n    'Geneva': .196150,\n    'Krakow': .756183,\n    'Oslo': .673469,\n    'Helsinki': .574579,\n    'Bratislava': .413192,\n    'Luxembourg': .576249,\n    'Ljubljana': .277554\n    }\n    return population_city_dict, country_city_dict","ada2a45f":"def get_capital_city_dict():\n    '''\n    \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0433\u043e\u0440\u043e\u0434 == \u0441\u0442\u043e\u043b\u0438\u0446\u0430 \u0438\u043b\u0438 \u043d\u0435\u0442\n    '''\n    capital_city_dict = {}\n    cities =df['City'].unique()\n    df_county['capital TL'] = df_county['capital'].apply(lambda s: ''.join((c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')) )\n    df_county['capital TL'] =  df_county['capital'].apply(lambda x: unidecode.unidecode(x))\n    for city in cities:\n        vals = df_county[df_county['capital TL'].str.contains(city)]['country'].shape[0]   \n        vals = 0 if pd.isna(vals) or vals==0 else 1 \n        capital_city_dict[city] = vals\n    capital_city_dict['Barcelona'] = 0 # \u0421\u0442\u0440\u0430\u043d\u0430 \u0411\u0430\u0441\u043a\u043e\u0432 != \u0418\u0441\u043f\u0430\u043d\u0438\u044f, \u0434\u0430\u0434\u0438\u043c \u0411\u0430\u0440\u0441\u0435\u043b\u043e\u043d\u0435 \u0441\u0442\u0430\u0442\u0443\u0441 \u043c\u0442\u043e\u043b\u0438\u0446\u044b, \u043d\u043e \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0432 \u0418\u0441\u043f\u0430\u043d\u0438\u0438 ! 0 \u0438 \u043d\u0435 \u043d\u0430\u0434\u043e \u0432\u0440\u0430\u0442\u044c :)\n    capital_city_dict['Zurich'] = 1 \n    capital_city_dict['Geneva'] = 1 \n    capital_city_dict['Oporto'] = 1 \n    return capital_city_dict","cea84588":"def is_cuisine_top_N(cs):\n    '''\n    \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u0443\u0445\u043e\u043d\u044c, \u0432\u0445\u043e\u0434\u044f\u0449\u0438\u0445 \u0432 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u0443\u0445\u043e\u043d\u044c,\u0434\u043b\u044f \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0445 Other\n    '''\n    c = get_cuisines(cs)\n    c = set(c)\n\n    shared_cousines=()\n    shared_cousines=c.intersection(topNcusines)\n\n    if len(shared_cousines) != len(c):\n        shared_cousines = list(shared_cousines)\n        shared_cousines.extend(['Other'])\n\n    return list(shared_cousines)","9c9fc307":"def createWordList(line):\n    wordList2 =[]\n    wordList1 = line.split()\n    for word in wordList1:\n        cleanWord = \"\"\n        for char in word:\n            if char in '!,.?\":;0123456789':\n                char = \"\"\n            cleanWord += char\n        wordList2.append(cleanWord.lower())\n    return wordList2","b21c2ba5":"def count_positive_words_proportion(reviews):\n    '''\n    \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u044b\u0445 \u0441\u043b\u043e\u0432 \u0432 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043e\u0442\u0437\u044b\u0432\u0430\u0445\n    '''\n    pos_words_count = 0\n    txts=get_reviews(reviews)['reviews_txt']\n    txt = ' '.join(txts)\n    #print(type(txt))\n    words = createWordList(txt)\n    \n    words_count = len(words) if len(words) > 0 else 1\n    words_count = 1\n    pos_words_in_review=set(words).intersection(pos_words_list)\n    for word in words:\n        if word in pos_words_list:\n            #print(word)\n            pos_words_count +=1  \n    return np.round(pos_words_count\/words_count,2)","8fe9fb2c":"def list_positive_words(reviews): \n    '''\n    \u0421\u043f\u0438\u0441\u043e\u043a \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u044b\u0445 \u0441\u043b\u043e\u0432 \u0432 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043e\u0442\u0437\u044b\u0432\u0430\u0445\n    '''\n    txts=get_reviews(reviews)['reviews_txt']\n    txt = ' '.join(txts)\n    #print(type(txt))\n    words = createWordList(txt)\n    \n    words_count = len(words) if len(words) > 0 else 1\n    words_count = 1\n    pos_words_in_review=set(words).intersection(pos_words_list)\n    #print(len(pos_words_in_review))\n    if (len(pos_words_in_review) == 0):\n        return np.NAN\n    else:\n        return list(pos_words_in_review)","5376eb79":"df_in.info()","a300cb88":"df_in.head(5)","92b6fd0b":"# \u0412\u0410\u0416\u041d\u041e! \u0434\u0440\u044f \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0442\u0440\u0435\u0439\u043d \u0438 \u0442\u0435\u0441\u0442 \u0432 \u043e\u0434\u0438\u043d \u0434\u0430\u0442\u0430\u0441\u0435\u0442\n\ndf_kagle['ForTrain'] = False # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0435\u0441\u0442\ndf_kagle['Rating'] = 0 # \u0432 \u0442\u0435\u0441\u0442\u0435 \u0443 \u043d\u0430\u0441 \u043d\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f Rating, \u043c\u044b \u0435\u0433\u043e \u0434\u043e\u043b\u0436\u043d\u044b \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u043f\u043e \u044d\u0442\u043e\u043c\u0443 \u043f\u043e\u043a\u0430 \u043f\u0440\u043e\u0441\u0442\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043d\u0443\u043b\u044f\u043c\u0438\n\ndf_in['ForTrain'] = True # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0440\u0435\u0439\u043d\ndf_in = df_in.append(df_kagle, sort=False).reset_index(drop=True)# \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c","71dcbfc9":"# \u0412\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u044b\u0435 \u0434\u043b\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0441\u0442\u043e\u043b\u0431\u0446\u044b\ndf = df_in[['Ranking', 'Rating', 'Number of Reviews', 'City', 'Price Range', 'Cuisine Style', 'Reviews', 'Restaurant_id', 'ID_TA', 'ForTrain' ]].copy()","3abc201c":"df.sample(5)","9a7ddfbc":"df.Reviews[1]","976296b8":"df.info()","3daf463e":"df.nunique(dropna=False)","3955bee5":"df[df.ForTrain][['Ranking', 'Rating', 'Number of Reviews','Price Range', 'Restaurant_id']].hist(figsize=(20, 10), bins=100);\nplt.tight_layout()\n","61b00d16":"df[df.ForTrain]['Restaurant_id'].apply(lambda x: x.split('_')[1]).astype(int).hist(figsize=(10,5), bins=100);\nplt.tight_layout()\n# Restaurant_id \u041e\u0447\u0435\u043d\u044c \u043f\u043e\u0445\u043e\u0436 \u043d\u0430 Ranking","70bfe9f9":"\ndf[df.ForTrain]['ID_TA'].apply(lambda x: x.replace('d','')).astype(int).hist(figsize=(10, 5), bins=100);\nplt.tight_layout()\n# \u0412\u0438\u0434\u043d\u043e \u041d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0433\u0440\u0443\u043f\u043f - \u043d\u0430 ID - \u0442\u043e\u0447\u043d\u043e \u043d\u0435 \u043f\u043e\u0445\u043e\u0436\u0435. ","9b64b6a0":"df['ID_TA'] = df['ID_TA'].apply(lambda x: x[1:]) ","e085332d":"# Reviews - \u0443\u0431\u0438\u0440\u0430\u0435\u043c NaN \u0438 \"\u043f\u0440\u0438\u0447\u0435\u0441\u044b\u0432\u0430\u0435\u043c\" \u0442\u0435\u043a\u0441\u0442 \u043e\u0442\u0437\u044b\u0432\u043e\u0432 \ndf['Reviews_txt_NaN'] = df['Reviews'].apply(lambda x: x ==  '[[], []]')\n\ndf['Reviews'] = df['Reviews'].fillna('[[], []]')\ndf['Reviews'] = df['Reviews'].apply(lambda x: cleanup_string(x))","10b97119":"# \u041d\u0435 \u0431\u0443\u0434\u0435\u043c \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0433\u043e\u0440\u043e\u0434\u043e\u0432 - get_dummies \u0441\u043f\u0440\u0430\u0432\u0438\u0442\u0441\u044f \n# df[\"City\"] = df[\"City\"].astype('category')\n# #df[\"City\"] = df[\"City\"].cat.codes\n# encoder = LabelEncoder()\n# df['City'] = encoder.fit_transform(df['City'])","286c35b5":"# \u041f\u0435\u0440\u0435\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c Price Range \u0438 \u0443\u0434\u0430\u043b\u044f\u0435\u043c NaN\ncleanup_nums = {'Price Range':     {\"$\": 1, \"$$ - $$$\": 2, \"$$$$\": 3, np.NaN: 2}} # \u0447\u0430\u0449\u0435 \u0432\u0441\u0435\u0433\u043e \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u0435\u0442\u0441\u044f \"$$ - $$$\" == 2\ndf['Price Range NAN'] = df['Price Range'].isna()\ndf.replace(cleanup_nums, inplace=True)","f707d594":"# \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c Cuisines Count, \u0441\u0430\u043c\u0443\u044e \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u0443\u044e \u043a\u0443\u0445\u043d\u044e, \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u043a-\u0432\u043e \u043a\u0443\u0445\u043e\u043d\u044c \u0432 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0435 \u0438 \u0443\u0441\u0442\u0440\u0430\u043d\u044f\u0435\u043c NaN\ndf['Cuisine Style NAN'] = df['Cuisine Style'].isna()\ndf['Cuisine Style'] = df['Cuisine Style'].fillna('NaN')\ndf['Cuisines Count'] = df.apply(cuisine_styles_count, axis=1)\n\nmost_popular_cusine = pd.Series(allCusines).value_counts().index[0]\naverage_cousines_count = np.round(df['Cuisines Count'].mean())","f339141b":"# Number of Reviews\ndf['Number of Reviews NAN'] = df['Number of Reviews'].isna()\nreplace_val = df['Number of Reviews'].mean()\nreplace_val = np.round(replace_val)\ndf['Number of Reviews'] = df['Number of Reviews'].fillna(replace_val)","6f4a014f":"df.sample(5)","ff038a30":"plt.rcParams['figure.figsize'] = (10,5)\ndf[df.ForTrain]['Ranking'].hist(bins=100);","7a850048":"df[df.ForTrain]['City'].value_counts(ascending=True).plot(kind='barh');","ebd7a67a":"df[df.ForTrain]['Ranking'][df[df.ForTrain]['City'] =='London'].hist(bins=100);","2b524b92":"# \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0442\u043e\u043f 10 \u0433\u043e\u0440\u043e\u0434\u043e\u0432\nfor x in (df[df.ForTrain]['City'].value_counts())[0:10].index:\n    df[df.ForTrain]['Ranking'][df[df.ForTrain]['City'] == x].hist(bins=100)\nplt.show()","451f547d":"df[df.ForTrain]['Rating'].value_counts(ascending=True).plot(kind='barh');","422759a5":"df[df.ForTrain]['Ranking'][df[df.ForTrain]['Rating'] == 5].hist(bins=100);","41b304bd":"df[df.ForTrain]['Ranking'][df[df.ForTrain]['Rating'] < 4].hist(bins=100);","bdfd48a1":"plt.rcParams['figure.figsize'] = (15,15)\nsns.heatmap(df[df.ForTrain].drop(['ForTrain'], axis=1).corr(), square=True,\n            annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\");\nplt.tight_layout()","7a18a228":"population_city_dict = {}\ncountry_city_dict = {}\n# \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u0438 \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0438\u0438 \u043f\u043e \u0433\u043e\u0440\u043e\u0434\u0430\u043c, \u0430 \u0442\u0430\u043a \u0436\u0435 ISO \u043a\u043e\u0434 \u0441\u0442\u0440\u0430\u043d\u044b \u043f\u043e \u0433\u043e\u0440\u043e\u0434\u0443\npopulation_city_dict, country_city_dict = get_city_population_and_country()","027ad1bd":"# \u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u0441\u0442\u0440\u0430\u043d\u0443 \u0434\u043b\u044f \u0433\u043e\u0440\u043e\u0434\u0430 \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0435\ndf['Country'] = df[\"City\"].apply(lambda x: country_city_dict[x])","edfcfd6c":"# \u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u043a-\u0432\u043e \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u0434\u043b\u044f \u0433\u043e\u0440\u043e\u0434\u0430 \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0435\nrestorants_in_city = df.groupby('City')['Ranking'].count().to_dict()\ndf['Restaurants Count'] = df['City'].map(restorants_in_city)","7c0660b9":"# \u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u043d\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u0435 (\u0432 \u0442\u044b\u0441. \u0447\u0435\u043b) \u0434\u043b\u044f \u0433\u043e\u0440\u043e\u0434\u0430 \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0435\ndf['Population'] = df[\"City\"].map(population_city_dict)","322726ec":"# \u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u043a-\u0432\u043e \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u043d\u0430 1000 \u0447\u0435\u043b \u0434\u043b\u044f \u0433\u043e\u0440\u043e\u0434\u0430 \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0435\ndf['Restaurants for Population'] = df['Restaurants Count'] \/ (df['Population']*1000) #","e3bf4860":"# \u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043b\u0438 \u0433\u043e\u0440\u043e\u0434 \u0441\u0442\u043e\u043b\u0438\u0446\u0435\u0439 \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0435\ncapital_city_dict = get_capital_city_dict()\ndf['isCapital'] = df[\"City\"].map(capital_city_dict)","dbe1646b":"# \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u043f\u043e\u0437\u0438\u0446\u0438\u044e \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \u0441\u0440\u0435\u0434\u0438 \u0432\u0441\u0435\u0445 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u0433\u043e\u0440\u043e\u0434\u0430\ndf['Weighed Rank'] = df.apply(lambda x: get_Weighed_Rank_RK(x), axis=1)\n\nCityMinMax = df.groupby('City')['Ranking'].agg([min,max])\nCityMinMax =CityMinMax.reset_index()\ndf['Weighed Rank min max'] = df.apply(lambda x: get_Weighed_Rank(x), axis=1)","92106e1e":"# \u0424\u043b\u0430\u0433\u0438 (1\/0) isMostPopCusine - \u0435\u0441\u0442\u044c \u043b\u0438 \u0432 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0435 \u0441\u0430\u043c\u0430\u044f \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u0430\u044f \u043a\u0443\u0445\u043d\u044f; isMultyCusine - \u043a-\u0432\u043e \u043a\u0443\u0445\u043e\u043d\u044c \u0432 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u0435 \u0438\u043b\u0438 \u0441\u0442\u043e\u043b\u044c\u043a\u043e \u0436\u0435 \u0447\u0435\u043c \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c\ndf['isMostPopCusine'] = df['Cuisine Style'].apply(lambda x: 1 if most_popular_cusine in x else 0 )\ndf['isMultyCusine'] = df['Cuisines Count'].apply(lambda x: 1 if  x >= average_cousines_count else 0 )","619fea5e":"# RevTimeDelta - \u0432\u0440\u0435\u043c\u044f \u043c\u0435\u0436\u0434\u0443 review \u0432 \u0434\u043d\u044f\u0445\n\ndf['RevTimeDelta'] = df['Reviews'].apply(rev_time_delta)","33d817c6":"# NewestReviewDate - \u0432\u0440\u0435\u043c\u044f, \u043f\u0440\u043e\u0448\u0435\u0434\u0448\u0435\u0435 \u0441\u043e \u043c\u043e\u043c\u0435\u043d\u0442\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e review \u0434\u043e '22\/02\/2020'\ndf['NewestReviewDate'] = df['Reviews'].apply(lambda x: get_reviews(x)['reviews_dt'])\ndf['NewestReviewDate'] = df['NewestReviewDate'].apply(lambda x: sorted(x,reverse=True)[0] if len(x)!=0 else pd.NaT)\ndf['NewestReviewDate'] = df['NewestReviewDate'].fillna(dt.date(1970,1,1))\ndf['NewestReviewDate'] = df['NewestReviewDate'].apply(lambda x: (CURRENT_DATE.date()-x).total_seconds()\/\/86400)","61fc174a":"df['NewestReviewSeason'] = df['Reviews'].apply(lambda x: get_reviews(x)['reviews_dt'])\ndf['NewestReviewSeason'] = df['NewestReviewSeason'].apply(lambda x: sorted(x,reverse=True)[0] if len(x)!=0 else pd.NaT)\n#df['NewestReviewSeason'] = df['NewestReviewSeason'].fillna(dt.date(2020,2,22))\ndf['NewestReviewSeason'] = df['NewestReviewSeason'].apply(lambda x: get_season(x))","fbb4706d":"#  'TxtReviewsCount' - \u043a-\u0432\u043e \u043e\u0442\u0437\u044b\u0432\u043e\u0432, \u043d\u0435 \u0441\u0438\u043b\u044c\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442, \u043d\u043e \u043f\u0443\u0441\u0442\u044c \u0431\u0443\u0434\u0443\u0442\ndf['TxtReviewsCount'] = df['Reviews'].apply(lambda x: len(get_reviews(x)['reviews_txt']))","770aea55":"# \u041a-\u0432\u043e \u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u044b\u0445 \u0441\u043b\u043e\u0432 \u0432 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0445 \u043e\u0442\u0437\u044b\u0432\u0430\u0445\ndf['PositiveWords'] = df['Reviews'].apply(lambda x: count_positive_words_proportion(x))","90864226":"# \u0421\u043f\u0438\u0441\u043e\u043a \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u044b\u0445 \u0441\u043b\u043e\u0432 \u0432 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0445 \u043e\u0442\u0437\u044b\u0432\u0430\u0445\ndf['PositiveWordsList'] = df['Reviews'].apply(lambda x: list_positive_words(x))","11860df2":"cusines_in_city={}\ncusines_count_in_city={}\nfor city_name, group in df.groupby('City'):\n\n    cusines = group['Cuisine Style'].apply(get_cuisines)\n   \n    cusines_list = list(itertools.chain.from_iterable(cusines))\n    #cusines_list = [x for x in cusines_list if x != 'Vegetarian Friendly'] # \u0443\u0434\u0430\u043b\u044f\u0435\u043c 'Vegetarian Friendly' - \u043e\u043d\u0430 \"\u0437\u0430\u0431\u0438\u0432\u0430\u0435\u0442\" \u0432\u0441\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b\n    cusines_in_city[city_name] = Counter(cusines_list)\n\nfor city_name in cusines_in_city.keys():\n    cusines_count_in_city[city_name] = len(cusines_in_city[city_name])\n\ndf['Cusines Count In City'] = df['City'].map(cusines_count_in_city)","d3b7da50":"df['Weighed Cuisines Count'] = df['Cuisines Count'] \/ df['Cusines Count In City']  ","5101aa60":"df['Most Common Cusine in City'] = df['City'].apply(lambda x: cusines_in_city[x].most_common(1)[0][0])","778a6c57":"df['Cuisine Style'] = df.apply(lambda x: x['Cuisine Style'] if x['Cuisine Style NAN'] ==False else [x['Most Common Cusine in City']], axis=1)","b5b11f02":"# \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043c\u0435\u0441\u0442\u0430 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \u0432 \u0433\u043e\u0440\u043e\u0434\u0435 \u043e\u0442 \u043d\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u044f\ndf['Weighed Rank by Population'] = df['Weighed Rank']  \/ df['Population'] ","43dd6d58":"df['PositiveWords in Reviews'] = df['PositiveWords'] \/ df['Number of Reviews']","8ac4058d":"# \u041a\u0430\u043a \u0447\u0430\u0441\u0442\u043e \u0432 \u0433\u043e\u0440\u043e\u0434\u0435 \u043e\u0441\u0442\u0430\u0432\u043b\u044f\u044e\u0442 \u043e\u0442\u0437\u044b\u0432\u044b\ndf['NRP'] = df['Number of Reviews'] \/ df['Population']","32ce55de":"# \u0420\u0430\u043d\u0433 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u0447\u0430\u0441\u0442\u043e\u0442\u044b \u043e\u0442\u0437\u044b\u0432\u043e\u0432 \u0432 \u0433\u043e\u0440\u043e\u0434\u0435\ndf['WRR'] =  df['Weighed Rank']  *  df['NRP'] ","c0404972":"df['Relative Price Range'] = df['Price Range'] \/ df['Weighed Rank']","3a30b056":"# \u0421\u0440\u0435\u0434\u043d\u044f\u044f \u0446\u0435\u043d\u0430 \u0432 \u0433\u043e\u0440\u043e\u0434\u0435\nprice_in_city_dict = df.groupby('City')['Price Range'].mean().to_dict()\ndf['Price in City'] = df['City'].map(price_in_city_dict)","d72039cc":"# \u0421\u043e\u043a\u0440\u0430\u0449\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u0443\u0445\u043e\u043d\u044c \u0434\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0434\u043e N - \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0445, \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 Other - \u044d\u0442\u043e \u043f\u043e\u0447\u0442\u0438 \u0432\u0441\u0435\u0433\u0434\u0430 \u0434\u0430\u0435\u0442 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\nN=30 #!!!\n\ns = df['Cuisine Style'].apply(lambda x: get_cuisines(x))\nslist =[]\nfor x in s:\n    slist.extend(x)\ntopNcusines = set(pd.Series(slist).value_counts()[:N].index)  \ndf['Cuisine top N'] =df['Cuisine Style'].apply(lambda x: is_cuisine_top_N(x))","5a2b28ee":"# \u0421\u0435\u0442\u0435\u0432\u043e\u0439 ID \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 (\u043f\u043e\u0445\u043e\u0436\u0435, \u0447\u0442\u043e \u044d\u0442\u043e ID \u0444\u0440\u0430\u043d\u0448\u0438\u0437\u044b, \u0435\u0441\u043b\u0438 \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u0435\u0442\u0441\u044f \u0431\u043e\u043b\u0435\u0435 1-\u0433\u043e \u0440\u0430\u0437\u0430 - isNetworkRestorant)\nimport warnings; warnings.simplefilter('ignore')\ndf['Restaurant_net_id'] = df['Restaurant_id'].apply(lambda x: x.split('_')[1])\nNetworkRestorants = df[df['Restaurant_net_id'].isin(df['Restaurant_net_id'].value_counts()[df['Restaurant_net_id'].value_counts()>2].index)]\nNetworkRestorants['isNetworkRestorant'] = True\ndf['isNetworkRestorant'] = NetworkRestorants['isNetworkRestorant']\ndf['isNetworkRestorant'] = df['isNetworkRestorant'].fillna(False)","9645544d":"# \u041f\u043e\u043c\u0435\u0447\u0430\u0435\u043c, \u0432\u0445\u043e\u0434\u0438\u0442 \u043b\u0438 \u0433\u043e\u0440\u043e\u0434 \u0432 N-top \u0433\u043e\u0440\u043e\u0434\u043e\u0432, \u0435\u0441\u043b\u0438 \u0414\u0410, \u0442\u043e \u043f\u0438\u0448\u0435\u043c \u0435\u0433\u043e \u043d\u0430\u0437\u0430\u0432\u043d\u0438\u0435, \u0435\u0441\u043b\u0438 \u041d\u0415\u0422 -Other\ntop_Cityes = df['City'].value_counts()[0:10].index.to_list()\ndf['TopCityes'] = df.City.apply(lambda x: x if x in top_Cityes else 'Other_City')","1c58b397":"df[['Ranking', 'Rating', 'Number of Reviews', 'City', 'Price Range',\n        'Restaurant_id',  'Country',\n       'Restaurants Count', 'Population', 'Restaurants for Population',\n       'Weighed Rank',  'Cuisines Count',\n       'RevTimeDelta', 'NewestReviewDate',\n       'TxtReviewsCount', 'Weighed Rank by Population', 'PositiveWords','PositiveWords in Reviews', 'WRR', 'Price in City', 'Restaurant_net_id']].hist(figsize=(20, 20), bins=100);\nplt.tight_layout()","cf12d96f":"# \u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c Dummies: city, price_range, country_range, Cuisine top N\n\ndff = pd.get_dummies(df['Cuisine top N'].apply(pd.Series).stack()).sum(level=0)\ndf_mcc = pd.get_dummies(df['Most Common Cusine in City'], prefix = 'MCC')\ndf_city = pd.get_dummies(df['City'], prefix = 'City Range')\n#df_city = pd.get_dummies(df['TopCityes'], prefix = 'City', dummy_na=True)\ndf_price_range = pd.get_dummies(df['Price Range'], prefix = 'Price Range') \ndf_country_range = pd.get_dummies(df['Country'], prefix = 'Country Range',) \n#df_season_range = pd.get_dummies(df['NewestReviewSeason'], prefix = 'Season',)\n\ndf['PositiveWordsList'] = df['PositiveWordsList'].fillna('NAN')\ndf_positive_words_range = pd.get_dummies(df['PositiveWordsList'].apply(pd.Series).stack(), dummy_na=False).sum(level=0)\n\n\ndf1 = pd.concat([df,dff], axis=1)\ndf1 = pd.concat([df1,df_city], axis=1)\ndf1 = pd.concat([df1,df_price_range], axis=1)\ndf1 = pd.concat([df1,df_country_range], axis=1)\ndf1 = pd.concat([df1,df_mcc], axis=1)\ndf1 = pd.concat([df1,df_positive_words_range], axis=1)\n\n#df1 = pd.concat([df1,df_season_range], axis=1)\n\n#df1 = pd.concat([df1,df_restid_range], axis=1)\n\ncols_cuisine_style = dff.columns\ncols_city = df_city.columns\ncols_price_range =  df_price_range.columns\ncols_country_range =  df_country_range.columns\ncols_mcc =  df_mcc.columns\ncols_positive_words = df_positive_words_range.columns\n#cols_season = df_season_range.columns\n#cols_restid_range =  df_restid_range.columns","ab65fb3f":"# \u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0418 \u0420\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u043d\u0430 \u0447\u0430\u0441\u0442\u0438, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438\ncolumns = [ 'isMultyCusine', 'Price Range NAN', 'Cuisine Style NAN', 'Number of Reviews NAN', 'Number of Reviews', 'Restaurants Count', 'Cuisines Count', 'RevTimeDelta',        'NewestReviewDate', 'PositiveWords',  'Weighed Rank', 'Ranking', 'Cusines Count In City', 'WRR', 'ID_TA', 'Weighed Rank min max', 'Price in City',  'Cuisine Style NAN', 'isCapital', 'Population', 'Restaurants for Population',  ]\n\n#columns = [ 'isMultyCusine', 'Price Range NAN', 'Cuisine Style NAN', 'Number of Reviews NAN', 'Number of Reviews', 'Restaurants Count', 'Cuisines Count', 'RevTimeDelta',        'NewestReviewDate', 'PositiveWords',  'Weighed Rank', 'Ranking', 'Weighed Rank by Population',  'Cusines Count In City', 'WRR', 'ID_TA', 'Weighed Rank min max', 'Price in City', 'Weighed Rank by Population',  ]\n\ncolumns.extend(cols_price_range.tolist())\ncolumns.extend(cols_cuisine_style.tolist())\ncolumns.extend(cols_city.tolist())\ncolumns.extend(cols_country_range.tolist())\n\ncolumns.extend(cols_positive_words.tolist())\n\n#\u0420\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u043d\u0430 \u0447\u0430\u0441\u0442\u0438, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438\nX = df1[df1.ForTrain][columns]\n\ny = df1[df1.ForTrain]['Rating']","9e686b27":"# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0438:\nfrom sklearn.model_selection import train_test_split","4b99f97e":"# \u041d\u0430\u0431\u043e\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u043c\u0435\u0442\u043a\u043e\u0439 \"train\" \u0431\u0443\u0434\u0443\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438, \"test\" - \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.\n# \u0414\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c 20% \u043e\u0442 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","23e3a025":"# \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438:\nfrom sklearn.ensemble import RandomForestRegressor # \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442 \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438\nfrom sklearn import metrics # \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442\u044b \u0434\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043c\u043e\u0434\u0435\u043b\u0438","6b394911":"# \u0421\u043e\u0437\u0434\u0430\u0451\u043c \u043c\u043e\u0434\u0435\u043b\u044c (\u041d\u0410\u0421\u0422\u0420\u041e\u0419\u041a\u0418 \u041d\u0415 \u0422\u0420\u041e\u0413\u0410\u0415\u041c)\nregr = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","865aff05":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nregr.fit(X_train, y_train)\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u0430 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435.\n# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e y_pred\ny_pred = regr.predict(X_test)","9abd1bd0":"y_pred_old = y_pred.copy()\ny_pred = round_of_rating(y_pred) ","f90a4c91":"# \u0421\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f (y_pred) \u0441 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u043c\u0438 (y_test), \u0438 \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043e\u043d\u0438 \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c \u043e\u0442\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f\n# \u041c\u0435\u0442\u0440\u0438\u043a\u0430 \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f Mean Absolute Error (MAE) \u0438 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043e\u0442 \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred),  metrics.mean_absolute_error(y_test, y_pred_old) )","1b5f5c3f":"#\u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u0434\u0435\u0442\u0435\u0440\u043c\u0438\u043d\u0430\u0446\u0438\u0438:\nR_2 = metrics.r2_score(y_test, y_pred)\nprint(R_2)","bce710d1":"# \u0432 RandomForestRegressor \u0435\u0441\u0442\u044c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u0432\u0435\u0441\u0442\u0438 \u0441\u0430\u043c\u044b\u0435 \u0432\u0430\u0436\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(regr.feature_importances_, index=X.columns)\nfeat_importances.nlargest(30).plot(kind='barh');","1a60e457":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u0438 \u043d\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 (ForTrain == False)\nX_submission = df1[df1.ForTrain == False][columns]\ny_pred_submission = round_of_rating(regr.predict(X_submission))","7c200d32":"# \u0424\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0441 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 Restaurant_id -- Rating\nsubmission_df = pd.DataFrame()\nsubmission_df['Restaurant_id'] = df1[df1.ForTrain == False]['Restaurant_id']\nsubmission_df['Rating'] = y_pred_submission\nsubmission_df.head(15)","d0e22050":"print('\u0422\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442')\ndf[df.ForTrain].Rating.value_counts()","6a9afc39":"print('\u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0432 4 \u0440\u0430\u0437\u0430')\nsubmission_df.Rating.value_counts()*4","e06470cf":"# \u0421\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\nsubmission_df.to_csv('submission.csv', index=False)","65945f13":"# \u041f\u0440\u043e\u0435\u043a\u0442 \u21163. \u041e \u0432\u043a\u0443\u0441\u043d\u043e\u0439 \u0438 \u0437\u0434\u043e\u0440\u043e\u0432\u043e\u0439 \u043f\u0438\u0449\u0435 \n**[SF-DST-10] Restaurant Rating prediction Sergey Kuzmenko**","91c55c9d":"\u041f\u043e\u0434\u0440\u043e\u0431\u043d\u0435\u0435 \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c:\n* City: \u0413\u043e\u0440\u043e\u0434 \n* Cuisine Style: \u041a\u0443\u0445\u043d\u044f\n* Ranking: \u0420\u0430\u043d\u0433 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0434\u0440\u0443\u0433\u0438\u0445 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u0432 \u044d\u0442\u043e\u043c \u0433\u043e\u0440\u043e\u0434\u0435\n* Price Range: \u0426\u0435\u043d\u044b \u0432 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0435 \u0432 3 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f\u0445\n* Number of Reviews: \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0442\u0437\u044b\u0432\u043e\u0432\n* Reviews: 2 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0445 \u043e\u0442\u0437\u044b\u0432\u0430 \u0438 \u0434\u0430\u0442\u044b \u044d\u0442\u0438\u0445 \u043e\u0442\u0437\u044b\u0432\u043e\u0432\n* URL_TA: \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0430 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \u043d\u0430 'www.tripadvisor.com' \n* ID_TA: ID \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \u0432 TripAdvisor\n* Rating: \u0420\u0435\u0439\u0442\u0438\u043d\u0433 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430","739d8cb1":"### \u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c dummies","1dd3f77e":"### \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430","0bc34859":"### \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430","7347911e":"\u0423 \u043d\u0430\u0441 \u043c\u043d\u043e\u0433\u043e \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u0434\u043e\u0442\u044f\u0433\u0438\u0432\u0430\u044e\u0442 \u0438 \u0434\u043e 2500 \u043c\u0435\u0441\u0442\u0430 \u0432 \u0441\u0432\u043e\u0435\u043c \u0433\u043e\u0440\u043e\u0434\u0435, \u0430 \u0447\u0442\u043e \u0442\u0430\u043c \u043f\u043e \u0433\u043e\u0440\u043e\u0434\u0430\u043c?","3bce08ac":"\u041f\u043e\u043b\u0443\u0447\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e Ranking \u0438\u043c\u0435\u0435\u0442 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435, \u043f\u0440\u043e\u0441\u0442\u043e \u0432 \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u0433\u043e\u0440\u043e\u0434\u0430\u0445 \u0431\u043e\u043b\u044c\u0448\u0435 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432, \u0438\u0437-\u0437\u0430 \u043c\u044b \u044d\u0442\u043e\u0433\u043e \u0438\u043c\u0435\u0435\u043c \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435.\n\n>\u041f\u043e\u0434\u0443\u043c\u0430\u0439\u0442\u0435 \u043a\u0430\u043a \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u043c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0434\u043b\u044f \u0432\u0430\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438. \u042f \u043f\u043e\u043a\u0430\u0436\u0443 \u0432\u0430\u043c \u043f\u0440\u0438\u043c\u0435\u0440, \u043a\u0430\u043a \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u0438. \u0410 \u0434\u0430\u043b\u0435\u0435 \u0434\u0435\u0439\u0441\u0442\u0432\u0443\u0439\u0442\u0435 \u0431\u0435\u0437 \u043f\u043e\u0434\u0441\u043a\u0430\u0437\u043e\u043a =) \n","eb35f86a":"**\u041f\u043e\u0438\u0449\u0435\u043c \u0434\u0440\u0443\u0433\u0438\u0435\/\u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u043f\u0440\u0438\u0432\u043b\u0435\u0447\u0435\u043c \u0432\u043d\u0435\u0448\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 **","2aa02cbc":"# DATA","49459190":"---  ","c3c66bc6":"### \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439","1051fb01":"* ## 1. \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 NAN \u0438 \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n\u0423 \u043d\u0430\u043b\u0438\u0447\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043c\u043e\u0433\u0443\u0442 \u0431\u044b\u0442\u044c \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u0440\u0438\u0447\u0438\u043d\u044b, \u043d\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u043d\u0443\u0436\u043d\u043e \u043b\u0438\u0431\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u0442\u044c, \u043b\u0438\u0431\u043e \u0438\u0441\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u0438\u0437 \u043d\u0430\u0431\u043e\u0440\u0430 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e. \u041d\u043e \u0441 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043c\u0438 \u043d\u0443\u0436\u043d\u043e \u0431\u044b\u0442\u044c \u0432\u043d\u0438\u043c\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u043c, **\u0434\u0430\u0436\u0435 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0438\u0435 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u0432\u0430\u0436\u043d\u044b\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u043c!**   \n\u041f\u043e \u044d\u0442\u043e\u043c\u0443 \u043f\u0435\u0440\u0435\u0434 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u043e\u0439 NAN \u043b\u0443\u0447\u0448\u0435 \u0432\u044b\u043d\u0435\u0441\u0442\u0438 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430 \u043a\u0430\u043a \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a ","e06d90f5":"# import","98774bd7":"### \u041a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f \u0438\u043c\u0435\u044e\u0449\u0438\u0445\u0441\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 - \u043f\u0440\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u043c, \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u0443\u044e\u0449\u0438\u043c \u0441 Rating \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f Ranking. \u041e\u043d, \u0432 \u0441\u0432\u043e\u044e \u043e\u0447\u0435\u0440\u0435\u0434\u044c, \u0443\u0436\u0435 \u0438\u043c\u0435\u0435\u0442 \u0441\u043b\u0430\u0431\u0443\u044e \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044e \u043f\u0440\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438 ","e5aab367":"# EDA \n[Exploratory Data Analysis](https:\/\/ru.wikipedia.org\/wiki\/\u0420\u0430\u0437\u0432\u0435\u0434\u043e\u0447\u043d\u044b\u0439_\u0430\u043d\u0430\u043b\u0438\u0437_\u0434\u0430\u043d\u043d\u044b\u0445) - \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445\n\u041d\u0430 \u044d\u0442\u043e\u043c \u044d\u0442\u0430\u043f\u0435 \u043c\u044b \u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438, \u0438\u0449\u0435\u043c \u0437\u0430\u043a\u043e\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u0438, \u0430\u043d\u043e\u043c\u0430\u043b\u0438\u0438, \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u0438\u043b\u0438 \u0441\u0432\u044f\u0437\u0438 \u043c\u0435\u0436\u0434\u0443 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438.\n\u0412 \u043e\u0431\u0449\u0435\u043c \u0446\u0435\u043b\u044c \u044d\u0442\u043e\u0433\u043e \u044d\u0442\u0430\u043f\u0430 \u043f\u043e\u043d\u044f\u0442\u044c, \u0447\u0442\u043e \u044d\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u043d\u0430\u043c \u0434\u0430\u0442\u044c \u0438 \u043a\u0430\u043a \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043c\u043e\u0433\u0443\u0442 \u0431\u044b\u0442\u044c \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u0430\u043d\u044b \u043c\u0435\u0436\u0434\u0443 \u0441\u043e\u0431\u043e\u0439.\n\u041f\u043e\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u0438\u0437\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u0442 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043d\u043e\u0432\u044b\u0435, \u0431\u043e\u043b\u0435\u0435 \u0441\u0438\u043b\u044c\u043d\u044b\u0435 \u0438, \u0442\u0435\u043c \u0441\u0430\u043c\u044b\u043c, \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043d\u0430\u0448\u0443 \u043c\u043e\u0434\u0435\u043b\u044c \u043b\u0443\u0447\u0448\u0435.\n![](https:\/\/miro.medium.com\/max\/2598\/1*RXdMb7Uk6mGqWqPguHULaQ.png)","e510c809":"# FUNC","0991be5c":"---\n# \u0423\u0441\u0442\u0440\u0430\u043d\u0438\u043b\u0438 NaN \u0438 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u043b\u0438 \u043d\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438(\u043f\u043e\u043a\u0430 \u0431\u0435\u0437 dummies), \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u043a\u0438\u0435 \u0438\u0437 \u043d\u0438\u0445 \u043f\u043e\u0434\u0445\u043e\u0434\u044f\u0442 ","a08a28ea":"-----------------\n# \u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u0433\u043e\u0434\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439  \n\u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u043f\u043e\u0445\u043e\u0436\u0438 - \u041e\u041a!","f0a5dae8":"# Model \n","9fd0d77a":"**\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u043a-\u0432\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 (NaN)**","5db861e7":"**\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u043a-\u0432\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439**","574c1f9f":"# Submission\n\u0415\u0441\u043b\u0438 \u0432\u0441\u0435 \u0443\u0441\u0442\u0440\u0430\u0435\u0432\u0430\u0435\u0442 - \u0433\u043e\u0442\u043e\u0432\u0438\u043c Submission \u043d\u0430 \u043a\u0430\u0433\u043b","c7432c28":"\u0410 \u043a\u0442\u043e-\u0442\u043e \u0433\u043e\u0432\u043e\u0440\u0438\u043b, \u0447\u0442\u043e \u0444\u0440\u0430\u043d\u0446\u0443\u0437\u044b \u043b\u044e\u0431\u044f\u0442 \u043f\u043e\u0435\u0441\u0442\u044c=) \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u043a\u0430\u043a \u0438\u0437\u043c\u0435\u043d\u0438\u0442\u0441\u044f \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0432 \u0431\u043e\u043b\u044c\u0448\u043e\u043c \u0433\u043e\u0440\u043e\u0434\u0435:","81eb559b":"# WORK","e5faca3c":"**\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0433\u0438\u0441\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u044b \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432**","e3238b85":"\u041a\u0430\u043a \u0432\u0438\u0434\u0438\u043c, \u0431\u043e\u043b\u044c\u0448\u0438\u043d\u0441\u0442\u0432\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0443 \u043d\u0430\u0441 \u0442\u0440\u0435\u0431\u0443\u0435\u0442 \u043e\u0447\u0438\u0441\u0442\u043a\u0438 \u0438 \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438."}}