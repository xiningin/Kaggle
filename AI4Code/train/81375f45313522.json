{"cell_type":{"38e39a18":"code","156d0242":"code","afc89b8c":"code","bf75a1c4":"code","d5fb45d5":"code","c36576e7":"code","1ebefb26":"code","d08bf07f":"code","496ad523":"code","af546b84":"code","db0ba024":"code","c62ce80d":"code","412feae4":"code","bd9edb95":"code","723ccfcf":"code","1664c764":"code","eb78057c":"code","a433a8b7":"code","5eca3a53":"code","d1a77a3f":"code","eafbd448":"code","b4435480":"code","a00c1470":"code","4c74cf6d":"code","4eab392b":"markdown","5e2807e0":"markdown","6ba359eb":"markdown","45a20428":"markdown","4ccf14c2":"markdown","3c42aa1c":"markdown"},"source":{"38e39a18":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics  import accuracy_score, auc, roc_curve, precision_recall_curve, roc_auc_score, precision_score, recall_score, average_precision_score\n\nfrom xgboost import XGBClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","156d0242":"df = pd.read_excel('\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\ndf.head()","afc89b8c":"df.shape","bf75a1c4":"df['ICU'].value_counts()","d5fb45d5":"df['AGE_PERCENTIL'] = OrdinalEncoder().fit_transform(df[['AGE_PERCENTIL']])\ndf['AGE_PERCENTIL'].value_counts()","c36576e7":"df['WINDOW'].value_counts()","1ebefb26":"df_mean = df.filter(regex=\"\\w+_MEAN\")\ndf_median = df.filter(regex=\"\\w+_MEDIAN\")\nraw_columns = list(map(lambda col: col.split('_MEAN')[0], df_mean.columns))\nraw_columns","d08bf07f":"\nfig, axs = plt.subplots(int(len(raw_columns) \/ 3), 3, figsize=(10, 25))\nfor i, col in enumerate(raw_columns):\n    axs[i \/\/ 3, i % 3].scatter(x=df_mean[f\"{col}_MEAN\"], y=df_median[f\"{col}_MEDIAN\"])\n    axs[i \/\/ 3, i % 3].set_title(col)\nfig.subplots_adjust(hspace=0.6)\n    \nplt.show()","496ad523":"uniq_cols = ['PATIENT_VISIT_IDENTIFIER', 'AGE_ABOVE65', 'AGE_PERCENTIL', 'GENDER',\n       'DISEASE GROUPING 1', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3',\n       'DISEASE GROUPING 4', 'DISEASE GROUPING 5', 'DISEASE GROUPING 6', 'HTN',\n       'IMMUNOCOMPROMISED']\nspecial_cols = ['WINDOW', 'ICU']\n\ndf = df[uniq_cols + list(df_mean.columns) + special_cols]\ndf.head()","af546b84":"df.info()","db0ba024":"df['missing_data_sum'] = df.isnull().sum(axis=1)","c62ce80d":"df = df.fillna(-2)\ndf.head()","412feae4":"df_first_window = df[(df['WINDOW'] == '0-2') & (df['ICU'] != 1)]\ndf_first_window.drop(['WINDOW'], axis=1, inplace=True)\ndf_first_window.head()","bd9edb95":"len(df_first_window)","723ccfcf":"all_patients_in_icu = set(df[df['ICU'] == 1]['PATIENT_VISIT_IDENTIFIER'])\nlen(all_patients_in_icu)","1664c764":"df_first_window['ICU'] = df.apply(lambda row: 1 if row['PATIENT_VISIT_IDENTIFIER'] in all_patients_in_icu else 0, axis=1)\ndf_first_window.head()","eb78057c":"df_first_window['ICU'].value_counts()","a433a8b7":"def evaluate(model, testing_set_x, testing_set_y):\n    predictions = model.predict_proba(testing_set_x)\n    accuracy  = accuracy_score(testing_set_y, predictions[:,1] >= 0.5)\n    roc_auc   = roc_auc_score(testing_set_y, predictions[:,1])\n    precision = precision_score(testing_set_y, predictions[:,1] >= 0.5)\n    recall    = recall_score(testing_set_y, predictions[:,1] >= 0.5)\n    pr_auc    = average_precision_score(testing_set_y, predictions[:,1])\n    \n    result = pd.DataFrame([[accuracy, precision, recall, roc_auc, pr_auc]], columns=['Accuracy', 'Precision', 'Recall', 'ROC_auc','PR_auc'])\n    return(result)\n\ndef run_experiment(df, num_iterations=100, **kwargs):\n    results = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'ROC_auc','PR_auc'])\n    for i in range(num_iterations):\n        train_x, test_x = train_test_split(df.drop('PATIENT_VISIT_IDENTIFIER', axis=1),\n           test_size = 0.3,\n           random_state = i\n        )\n        \n        train_y = train_x.pop('ICU')\n        test_y  = test_x.pop('ICU')\n        \n        # Train Model\n        model = XGBClassifier(**kwargs)\n        model.fit(train_x, train_y)\n         \n        # Evaluate results\n        current_result = evaluate(model, test_x, test_y)\n        results = results.append(current_result)\n        \n    return(results.reset_index(drop=True))\n\ndef print_results(df, plot = True, extras = False, color='dodgerblue'):\n    print('|||||||||||||||||||||||||||||||||||||||||||||||||||||||')\n    print('[ Experiment Results ]')\n    print('Accuracy:   {}'.format(df.Accuracy.mean()))\n    print('Precision:  {}'.format(df.Precision.mean()))\n    print('Recall:     {}'.format(df.Recall.mean()))\n    print('ROC Auc:    {}'.format(df.ROC_auc.mean()))\n    print('PR Auc:     {}'.format(df.PR_auc.mean()))\n    print('|||||||||||||||||||||||||||||||||||||||||||||||||||||||')\n    \n    if plot:\n        fig = px.box(df.melt(var_name='metric'),\n                       y = 'metric',\n                       x = 'value',\n                       title = 'Distribution of Metric Values Across 100 Runs',\n                       color_discrete_sequence=[color]\n                      )\n\n        fig.update_xaxes(title='Metric')\n        fig.update_yaxes(title='Value')\n\n        fig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 00)',\n                           'paper_bgcolor': 'rgba(240, 240, 240, 100)'})\n        fig.show()\n        \n        \n    if extras:\n        print('Also, the maximum results were:')\n        print('    Accuracy:   {}'.format(df.Accuracy.max()))\n        print('    Precision:  {}'.format(df.Precision.max()))\n        print('    Recall:     {}'.format(df.Recall.max()))\n        print('    ROC Auc:    {}'.format(df.ROC_auc.max()))\n        print('    PR Auc:     {}'.format(df.PR_auc.max()))","5eca3a53":"results = run_experiment(df_first_window)\nprint_results(results)","d1a77a3f":"parameters = {\n    'max_depth': [5, 7, 10],\n    'n_estimators': [50, 500, 1000, 5000],\n    'eta': [0.2, 0.3, 0.4, 0.5],\n    'objective': ['binary:logistic'],\n    'nthread': [4]\n}","eafbd448":"train_x, test_x = train_test_split(df_first_window.drop('PATIENT_VISIT_IDENTIFIER', axis=1),\n   test_size = 0.3,\n)\n\ntrain_y = train_x.pop('ICU')\ntest_y  = test_x.pop('ICU')","b4435480":"grid_xgb = GridSearchCV(estimator=XGBClassifier(), param_grid=parameters, cv=2, n_jobs=-1)\ngrid_xgb.fit(train_x, train_y)","a00c1470":"print(\" Results from Grid Search \" )\nprint(\"\\n The best estimator across ALL searched params:\\n\",grid_xgb.best_estimator_)\nprint(\"\\n The best score across ALL searched params:\\n\",grid_xgb.best_score_)\nprint(\"\\n The best parameters across ALL searched params:\\n\",grid_xgb.best_params_)","4c74cf6d":"optimal_params = { 'eta': 0.4, 'max_depth': 5, 'n_estimators': 500, 'nthread': 4, 'objective': 'binary:logistic' }\nresults = run_experiment(df_first_window, **optimal_params)\nprint_results(results)","4eab392b":"Decide whether to use [mean, median], max, min, diff or relative diff","5e2807e0":"The result is better than just flipping a coin! I'll call that a decent win considering the limitations of the data. Let's do better though.","6ba359eb":"**Findings:** Focusing on either just the median or the mean doesn't make too much of a difference besides a couple variables, so we'll be focusing on the mean value.","45a20428":"**First Attempt**:\n\nOur first attempt at building a model will only look at data from the first 0-2 hours of admission.[](http:\/\/)","4ccf14c2":"We're going to use XGBoost as our baseline model, and represent our evaluated metrics as a boxplot. The below `evaluate`, `run_experiment`, and `print_results` functions have been borrowed from:\nhttps:\/\/www.kaggle.com\/andrewmvd\/enriched-lightgbm-pr-86-auc-92-68","3c42aa1c":"It is important to know whether or not a patient eventually gets admitted to the ICU and update the target to that"}}