{"cell_type":{"dd820246":"code","6ee5ad60":"code","8ed612d8":"code","80c8825b":"code","fa384727":"code","f44f8b59":"code","2ef219a2":"code","0233d9c2":"code","d9d45b0d":"code","2ef6c0fc":"code","babb5d49":"code","ecd0fb48":"code","cddddffa":"code","d06c19ee":"code","e3738e18":"code","c770b21a":"code","72c6cc53":"code","72b90b68":"code","4ca402ca":"code","b509e378":"code","28c1c1aa":"code","b2b73d74":"code","124ae2e2":"code","da43b81c":"code","f6021b26":"code","99e059f2":"code","b654c5f9":"code","fda81522":"code","fa3201de":"code","a2adddd1":"code","552384d2":"code","8b9d6607":"code","dd8a3b09":"code","4c3eedb6":"code","4c6322ae":"code","03a472c2":"code","b5d0506e":"code","9bdaa419":"code","4f2e5813":"code","69cc4cca":"code","46eda830":"code","6c6caff7":"code","f44f5586":"code","942d3026":"code","54a4725a":"code","24c8ac62":"code","c27f31d6":"code","b57c262c":"code","58b7e212":"code","b4f2bc11":"code","95e7eab7":"code","d2a9d3d0":"code","af168127":"code","7fbd6ff1":"code","d49aa2b4":"code","a800ce36":"code","8a958203":"code","733c7cab":"code","07dce139":"code","db437b8a":"code","6634201f":"code","e3a8eab5":"code","88cd8b67":"code","9b393897":"code","30f65d9e":"code","c6c4fbab":"code","982d5453":"code","92060a28":"code","2ae72869":"code","f2c68808":"code","ef18a732":"code","063b512c":"code","3f1a21e6":"code","4c6123aa":"code","25c8b5a4":"code","738b798d":"code","fadae58a":"code","18254805":"code","8fcd25d3":"code","fcb78b08":"code","2e8e45a1":"code","d7e62304":"code","ef5e8f81":"code","bd623757":"code","77e62a58":"code","43da4fd3":"code","66580169":"code","83514f1b":"code","81b91c69":"code","2ad4901d":"code","1e4ddafc":"code","7f5d1e3f":"code","e53a78ce":"code","d2463efd":"code","62f89346":"code","5920f651":"code","ed4e3ce0":"code","7a36772f":"code","48a3d14e":"code","d5990a2f":"code","2c84b48e":"code","a6c9248d":"code","184c5eff":"code","7a8d2e9c":"code","9849e1ef":"code","a8021705":"code","51088fc2":"code","0f013c85":"code","7685e463":"code","2fc48e91":"code","a556ad07":"code","7e6098df":"code","82150f7a":"code","089d039b":"code","7a2c384d":"code","2885def0":"code","be83ac1e":"code","5b3e09f4":"code","ab31eb46":"markdown","90aef513":"markdown","28a9e461":"markdown","ac99cda7":"markdown","6a98d058":"markdown","856d02fd":"markdown","ad4c7d9c":"markdown","7f7b52b4":"markdown","7a2955e7":"markdown","19de91e2":"markdown","bf2d0e23":"markdown","9b3b29c5":"markdown","05f5a794":"markdown","4f6acdca":"markdown","4a067528":"markdown","b0934417":"markdown","f55ab5ad":"markdown","14c41c67":"markdown","11b36c9e":"markdown","8604eb6b":"markdown","2f262ad9":"markdown","6581ff16":"markdown","17ae8a04":"markdown","79973318":"markdown","940c3326":"markdown","b2166a32":"markdown","67fdf743":"markdown","db29f0b0":"markdown","b924671b":"markdown","073587ba":"markdown","702f638f":"markdown","bed6b793":"markdown","e83a2280":"markdown","34b9d1ac":"markdown","acd76e99":"markdown","76680856":"markdown","e78d3fd4":"markdown","a3b0d94b":"markdown","1efbce4f":"markdown","88f12609":"markdown","804deb23":"markdown","14bd8ad6":"markdown"},"source":{"dd820246":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder\nimport random\n\n# Logistic Regression:\nfrom sklearn.linear_model import LogisticRegression\n\n# KNN:\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Support Vector Machine:\nfrom sklearn.svm import SVC\n\n# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\n# Random Forest:\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Naive Bayes:\nfrom sklearn.naive_bayes import GaussianNB\n\n# XGBoost:\nfrom xgboost import XGBClassifier\n\n# AdaBoost:\nfrom sklearn.ensemble import AdaBoostClassifier","6ee5ad60":"path = \"..\/input\/titanic\/\"\ntrain_data=pd.read_csv(f\"{path}train.csv\")\ntest_data = pd.read_csv(f\"{path}test.csv\")\nprint(\"Data imported successfully\")","8ed612d8":"train_data.head()","80c8825b":"test_data.head()","fa384727":"train_data.dtypes","f44f8b59":"print(f'''training data shape: {train_data.shape}\ntest data shape: {test_data.shape}''')","2ef219a2":"train_data[\"Train_data\"] = 1\ntest_data[\"Train_data\"] = 0\ntest_data[\"Survived\"] = np.nan # Because the test data does not have Survived column\n\ndf = pd.concat([train_data, test_data], ignore_index=True)\ndf.head()","0233d9c2":"df.isnull().sum()","d9d45b0d":"print(f\"There are {df.duplicated().sum()} duplicated rows in the data\")","2ef6c0fc":"def get_titles_from_name(data):\n    titles = np.array([])\n    for x in data[\"Name\"]:\n        name_disected = x.split(\" \")\n\n        for part in name_disected:\n            if \".\" in part:\n                if len(part) > 2:\n                    titles= np.append(titles, part.rstrip(\".\"))\n                    \n    data[\"Title\"] = titles\n    print(\"Title column was added\")","babb5d49":"get_titles_from_name(df)\ndf.head()","ecd0fb48":"# Children (0-14 years) \n# Youth (15-24 years) \n# Adults (25-64 years) \n# Seniors (65 years and over) \n\ndef get_age_group(data):\n    age_group = np.array([])\n    for age in data[\"Age\"]:\n        if age <= 14:\n            age_group = np.append(age_group, \"Child\")\n        elif age <= 24:\n            age_group = np.append(age_group, \"Youth\")\n        elif age <= 64:\n            age_group = np.append(age_group, \"Adult\")\n        elif age > 64:\n            age_group = np.append(age_group, \"Senior\")\n        else:\n            age_group = np.append(age_group, age)\n            \n    data[\"Age_group\"] = age_group\n    print(\"Age_group column was added\")","cddddffa":"get_age_group(df)\ndf.head()","d06c19ee":"plt.title(\"Train data age group distribution\")\nplt.hist(df.loc[df[\"Train_data\"]==1, \"Age_group\"]);","e3738e18":"plt.title(\"test data age group distribution\")\nplt.hist(df.loc[df[\"Train_data\"]==0, \"Age_group\"]);","c770b21a":"plt.rcParams[\"figure.figsize\"] = (18,10)\npd.crosstab(df[\"Title\"], df[\"Age_group\"]).plot(kind=\"bar\");","72c6cc53":"pd.crosstab(df[\"Title\"], df[\"Pclass\"]).plot(kind=\"bar\");","72b90b68":"plt.rcParams[\"figure.figsize\"] = (5,5)\npd.crosstab(df[\"Age_group\"], df[\"Pclass\"]).plot(kind=\"bar\");","4ca402ca":"plt.scatter(train_data[\"Pclass\"], train_data[\"Fare\"]);","b509e378":"titles_dict = {\"Master\":0, \"Miss\":1, \"Ms\":2, \"Mr\":3, \"Mrs\":4, \"Rev\":5, \"Dr\":6, \"Col\":7, \"Major\":8, \"Capt\":9, \"Jonkheer\":10, \"Mlle\":11, \"Dona\":12, \"Don\":13, \"Mme\":14, \"Lady\":15, \"Sir\":16, \"Countess\":17 }","28c1c1aa":" def fill_age_data(data):\n    global title_dict\n    for title, rank in titles_dict.items():\n        \n        # Master, Miss, Ms, Mr and Mrs are mostly of Pclass 3 (according to data)\n        if rank <= 4:\n            age = guess_data(data, 'Title', title, 'Pclass', 3)\n            data.loc[(data['Title'] == title) & (data[\"Age\"].isna()), 'Age'] = age\n            \n        # Reverands are mostly of Pclass 2 (according to data)\n        elif rank == 5:\n            age = guess_data(data, 'Title', title, 'Pclass', 2)\n            data.loc[(data['Title'] == title) & (data[\"Age\"].isna()), 'Age'] = age\n            \n        # Dr, Col, Major, Capt, Jonkheer, Mlle, Dona, Don, Mme, Lady, Sir and Countess are mostly of Pclass 1 (according to data) \n        else:\n            age = guess_data(data, 'Title', title, 'Pclass', 1)\n            data.loc[(data['Title'] == title) & (data[\"Age\"].isna()), 'Age'] = age\n            \n    #if any value is left\n    data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].mode()[0])\n            \n    print(\"Null counts:\")    \n    print(data.isna().sum())\n    ","b2b73d74":"def guess_data(data, condition1_col, condition1_val, condition2_col=\"\", condition2_val=\"\", condition3_col=\"\", condition3_val=\"\", column=\"Age\"):\n    \n    if condition3_val != \"\":\n        mode_val = data.loc[(data[condition1_col] == condition1_val) & (data[condition2_col] == condition2_val) & (data[condition3_col] == condition3_val), column].mode()\n        median_val = data.loc[(data[condition1_col] == condition1_val) & (data[condition2_col] == condition2_val) & (data[condition3_col] == condition3_val), column].median()\n        \n        if len(mode_val) > 1:\n            return mode_val[1]\n        elif len(mode_val) == 1:\n            return mode_val[0]\n        else:\n            return median_val\n    elif condition2_val != \"\":\n        mode_val = data.loc[(data[condition1_col] == condition1_val) & (data[condition2_col] == condition2_val), column].mode()\n        median_val = data.loc[(data[condition1_col] == condition1_val) & (data[condition2_col] == condition2_val), column].median()\n       \n        if len(mode_val) > 1:\n            return mode_val[1]\n        elif len(mode_val) == 1:\n            return mode_val[0]\n        else:\n            return median_val\n    else:\n        mode_val = data.loc[(data[condition1_col] == condition1_val), column].mode()\n        median_val = data.loc[(data[condition1_col] == condition1_val), column].median()\n        \n        if len(mode_val) > 1:\n            return mode_val[1]\n        elif len(mode_val) == 1:\n            return mode_val[0]\n        else:\n            return median_val","124ae2e2":"fill_age_data(df)","da43b81c":"# making the age group data once to add the new values from age\nget_age_group(df)","f6021b26":"df.head()","99e059f2":"df.loc[df[\"Ticket\"].duplicated(keep=False)].head()","b654c5f9":"df.loc[df[\"Fare\"] > 200]","fda81522":"tickets_cabin = {}\n\nfor i in range(0, len(df)):\n    ticket = df.loc[i, \"Ticket\"]\n    cabin = df.loc[i, \"Cabin\"]\n    if type(cabin) == str:\n        if ticket not in tickets_cabin:\n            tickets_cabin[ticket] = cabin","fa3201de":"df[\"Cabin\"].isnull().sum()","a2adddd1":"for ticket, cabin in tickets_cabin.items():\n    df.loc[(df[\"Ticket\"]==ticket) & (df[\"Cabin\"].isna()), \"Cabin\"] = cabin\n    \ndf[\"Cabin\"].isnull().sum()","552384d2":"def get_cabin_type(data):\n    cabin_type = np.array([])\n    for cabin in data[\"Cabin\"]:\n        if type(cabin) == str:\n            cabin_type = np.append(cabin_type, cabin[0])\n        else:\n            cabin_type = np.append(cabin_type, cabin)\n    data[\"Cabin_type\"] = cabin_type\n    print(\"Cabin_type column was added\")","8b9d6607":"df.loc[df[\"Fare\"] == 0]","dd8a3b09":"df.groupby([\"Pclass\"]).mean()","4c3eedb6":"get_cabin_type(df)\ndf.head()","4c6322ae":"df.groupby([\"Cabin_type\"]).mean()","03a472c2":"pd.crosstab(df[\"Cabin_type\"], df[\"Pclass\"]).plot(kind=\"bar\");","b5d0506e":"plt.rcParams[\"figure.figsize\"] = (18,10)\npd.crosstab(df[\"Title\"], df[\"Cabin_type\"]).plot(kind=\"bar\");","9bdaa419":"df[\"Cabin_type\"] = df[\"Cabin_type\"].replace('nan', np.nan)","4f2e5813":"df[\"Cabin_type\"].unique()","69cc4cca":"cabin_dict = {\"A\": 1, \"B\": 2, \"C\":3, \"D\":4, \"E\":5, \"F\":6, \"G\":7, \"T\": 8}","46eda830":"df[\"Cabin_code\"] = df[\"Cabin_type\"].map(cabin_dict)\ndf.head()","6c6caff7":"df.loc[df[\"Cabin_type\"] == \"T\"]","f44f5586":"plt.scatter(df[\"Cabin_code\"], df[\"Fare\"]);","942d3026":"df.loc[df[\"Cabin_type\"] == \"T\", \"Cabin_type\"] = \"C\"\ndf.loc[df[\"Cabin_type\"] == \"T\"]","54a4725a":"# Changing the cabin code to 3 as we changed the cabin type of the missclassified data to \"C\"\ndf.loc[df[\"Cabin_code\"] == 8, \"Cabin_code\"] = 3","24c8ac62":"df[\"Cabin_code\"].unique()","c27f31d6":"def fill_cabin_data(data):\n            \n    for pclass in data[\"Pclass\"].unique():\n        if pclass == 1:\n            val = guess_data(df, \"Pclass\", pclass, column=\"Cabin_code\")\n            data.loc[(data['Pclass'] == pclass) & (data[\"Cabin_type\"].isna()), 'Cabin_code'] = val\n        elif pclass == 2:\n            val = guess_data(df, \"Pclass\", pclass, column=\"Cabin_code\")\n            data.loc[(data['Pclass'] == pclass) & (data[\"Cabin_type\"].isna()), 'Cabin_code'] = val\n        else:\n            data.loc[(data['Pclass'] == pclass) & (data[\"Cabin_type\"].isna()), 'Cabin_code'] = 7.0 # G Deck\n    \n    print(\"Null counts:\")\n    print(data.isnull().sum())","b57c262c":"fill_cabin_data(df)\ndf.head()","58b7e212":"def get_family_data(data):\n    family = np.array([])\n    \n    for i in range(0,len(data)):\n        members = data.loc[data.index[i], 'SibSp'] + data.loc[data.index[i], 'Parch'] + 1 # sibling\/ spouse + parent\/ children + themself\n        family = np.append(family, members)\n    \n    data[\"Family\"] = family\n    print(\"Family column was added\")","b4f2bc11":"get_family_data(df)\ndf.head()","95e7eab7":"def isalone_data(data):\n    alone = np.array([])\n    \n    for i in range(0,len(data)):\n        family = data.loc[data.index[i], 'Family']\n        if family == 1 :\n            alone = np.append(alone, 1)\n        else:\n            alone = np.append(alone, 0)\n    \n    data[\"IsAlone\"] = alone\n    print(\"IsAlone column was added\")","d2a9d3d0":"isalone_data(df)\ndf.head()","af168127":"for i in range(0, len(df)):\n    fare = df.loc[i, \"Fare\"]\n    if fare < 1:\n        cabin = df.loc[i, \"Cabin_code\"]\n        mean_cabin_price = df.loc[df[\"Cabin_code\"] == cabin, \"Fare\"].mean()\n        df.loc[i, \"Fare\"] = mean_cabin_price","7fbd6ff1":"df.loc[df[\"Fare\"].isna()]","d49aa2b4":"df.loc[df[\"Fare\"].isna(), \"Fare\"] = df.loc[df[\"Cabin_code\"] == 7.0, \"Fare\"].mean()","a800ce36":"df.loc[1043]","8a958203":"categorical = [\"Pclass\", \"Sex\", \"Cabin_code\", \"Embarked\", \"Title\", \"Age_group\", \"IsAlone\"] # categorical variables","733c7cab":"for col in df.columns:\n    if col in categorical:\n        print(col, df[col].unique())","07dce139":"# Text data\ncategorical_data = df[categorical]\ncategorical_data","db437b8a":"plt.rcParams[\"figure.figsize\"] = (5,5)\nfor x in categorical_data.columns:\n    if categorical_data[x].isnull().sum() == 0:\n        plt.title(x)\n        plt.pie(categorical_data[x].value_counts(), labels = categorical_data[x].unique())\n        plt.legend(title=f\"{x}:\", loc= \"upper left\", bbox_to_anchor=(1.3,1.025))\n        plt.show()","6634201f":"num_data = df.select_dtypes(include='number')\nnum_data","e3a8eab5":"num_data.describe().T","88cd8b67":"plt.title(\"Survived? 0: No, 1: Yes\")\ndf[\"Survived\"].value_counts().plot.bar()","9b393897":"df[\"Sex\"] = df[\"Sex\"].map({\"male\":1, \"female\":0})\ndf.head()","30f65d9e":"df = pd.get_dummies(df, columns=[\"Embarked\"])\ndf.head()","c6c4fbab":"labelencoder_age = LabelEncoder()\n\ndf['Age_group'] = labelencoder_age.fit_transform(df['Age_group'])\ndf.head()","982d5453":"for title, rank in titles_dict.items():\n    df[\"Title\"] = df[\"Title\"].replace([title],rank)\n        \ndf.head()","92060a28":"train_data, test_data = df[df.Train_data == 1], df[df.Train_data == 0]","2ae72869":"# test_df is a copy of test_data , we can use it later\n\ntest_df = test_data.copy()","f2c68808":"train_data.drop(['Name', 'PassengerId', 'Cabin', 'Train_data', 'Cabin_type', 'Ticket'],axis=1,inplace=True)\ntest_data.drop(['Name', 'PassengerId', 'Cabin', 'Cabin_type', 'Train_data', 'Ticket', 'Survived'],axis=1,inplace=True)\n\ntrain_data.head()","ef18a732":"# Checking the correlation\nfig, ax = plt.subplots(figsize=(15,8))\nsns.heatmap(train_data.corr(), annot=True, ax=ax)","063b512c":"train_data[\"Survived\"].value_counts()","3f1a21e6":"x = train_data.loc[:,train_data.columns != \"Survived\"].values\ny = train_data[\"Survived\"].values\n\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.25, random_state = 0)","4c6123aa":"scaler = preprocessing.StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","25c8b5a4":"def visualize_confusion_matrix(model, x_test=x_test, y_test=y_test):\n    y_pred = model.predict(x_test)\n    cm = pd.DataFrame(pd.crosstab(y_test, y_pred))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    plt.figure(figsize = (7,5))\n    plt.title(\"On Test split:\")\n    sns.set(font_scale=1.4)\n    sns.heatmap(cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt=\"g\");","738b798d":"def accuracy_checker(model, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test):\n    print(f\"{model}:\")\n    train_accuracy = model.score(x_train,y_train)\n    test_accuracy = model.score(x_test,y_test)\n\n\n    print(f'''Train Accuracy: {round(train_accuracy*100,3)}%\nTest Accuracy: {round(test_accuracy*100,3)}%''')","fadae58a":"def grid_search(model, param_grid, x_train=x_train, y_train=y_train):\n    grid = GridSearchCV(estimator=model, param_grid=param_grid)\n    grid.fit(x_train, y_train)\n    print(f\"The best score is: {round(grid.best_score_*100,3)}%\\nThe best parameters are: {grid.best_params_}\")","18254805":"penalty = [\"l2\", \"none\"]\nmodel_LR = LogisticRegression(random_state = 0)\ngrid_search(model_LR, {\"penalty\":penalty})","8fcd25d3":"classifier_LR = LogisticRegression(random_state = 0)\nclassifier_LR.fit(x_train, y_train)","fcb78b08":"visualize_confusion_matrix(classifier_LR)","2e8e45a1":"accuracy_checker(classifier_LR)","d7e62304":"n_neighbors = np.array(range(1,11))\nparam_grid = dict(n_neighbors=n_neighbors)\nparam_grid[\"metric\"] = [\"manhattan\",\"euclidean\", \"chebyshev\" ]\nmodel_knn = KNeighborsClassifier(p=2)\ngrid_search(model_knn, param_grid)","ef5e8f81":"classifier_KNN = KNeighborsClassifier(p=2, metric=\"manhattan\", n_neighbors= 8)\nclassifier_KNN.fit(x_train, y_train)","bd623757":"visualize_confusion_matrix(classifier_KNN)","77e62a58":"accuracy_checker(classifier_KNN)","43da4fd3":"c = [0.001, 0.01, 0.1, 1, 10, 100]\nclassifier_svm = SVC()\nparam_grid = [{'kernel':['linear', 'poly'],'C':c }]\ngrid_search(classifier_svm, param_grid)","66580169":"classifier_SVM = SVC(kernel=\"poly\", C=1)\nclassifier_SVM.fit(x_train, y_train)\nvisualize_confusion_matrix(classifier_SVM)","83514f1b":"accuracy_checker(classifier_SVM)","81b91c69":"params = [0.001, 0.01, 0.1, 1, 10, 100]\nclassifier_svm = SVC(kernel='rbf')\nparam_grid = [{'C':params, 'gamma':params }]\ngrid_search(classifier_svm, param_grid)","2ad4901d":"classifier_SVC_rbf = SVC(kernel='rbf', gamma=0.01, C=10)\nclassifier_SVC_rbf.fit(x_train, y_train)\nvisualize_confusion_matrix(classifier_SVC_rbf)","1e4ddafc":"accuracy_checker(classifier_SVC_rbf)","7f5d1e3f":"x = train_data.loc[:,train_data.columns != \"Survived\"].values\ny = train_data[\"Survived\"].values\n\nx_train_unscaled,x_test_unscaled,y_train,y_test = train_test_split(x,y, test_size = 0.25, random_state = 0)","e53a78ce":"depth = np.array(range(2,11))\nparam_grid = dict(max_depth=depth)\nparam_grid[\"criterion\"] = [\"entropy\", \"gini\" ]\nmodel_DT = DecisionTreeClassifier()\ngrid_search(model_DT, param_grid, x_train = x_train_unscaled)","d2463efd":"classifier_DT = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4)\nclassifier_DT.fit(x_train_unscaled, y_train)\nvisualize_confusion_matrix(classifier_DT, x_test = x_test_unscaled)","62f89346":"accuracy_checker(classifier_DT, x_train=x_train_unscaled, x_test=x_test_unscaled)","5920f651":"fn = [x for x in train_data.columns if x != \"Survived\"]","ed4e3ce0":"feature_imp = pd.Series(classifier_DT.feature_importances_, index= fn).sort_values(ascending=False)\nfeature_imp","7a36772f":"sns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel(\"Feature Importance Score\")\nplt.ylabel(\"Features\")\nplt.title(\"Visualizing Important features\")\nplt.show()","48a3d14e":"trees = np.array(range(2,100))\nparam_grid = dict(n_estimators=trees)\nparam_grid[\"criterion\"] = [\"entropy\", \"gini\"]\nmodel_RF = RandomForestClassifier(n_jobs=3)\ngrid_search(model_RF, param_grid, x_train = x_train_unscaled)","d5990a2f":"classifier_RF = RandomForestClassifier(n_jobs=3, criterion = 'gini', n_estimators = 25)\nclassifier_RF.fit(x_train_unscaled, y_train)\nvisualize_confusion_matrix(classifier_RF, x_test = x_test_unscaled)","2c84b48e":"accuracy_checker(classifier_RF, x_train=x_train_unscaled, x_test=x_test_unscaled)","a6c9248d":"feature_imp = pd.Series(classifier_DT.feature_importances_, index= fn).sort_values(ascending=False)\nfeature_imp","184c5eff":"sns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel(\"Feature Importance Score\")\nplt.ylabel(\"Features\")\nplt.title(\"Visualizing Important features\")\nplt.show()","7a8d2e9c":"naive_bayes_clf = GaussianNB()\nnaive_bayes_clf.fit(x_train,y_train)","9849e1ef":"visualize_confusion_matrix(naive_bayes_clf)","a8021705":"accuracy_checker(naive_bayes_clf)","51088fc2":"max_depth = np.array(range(1,11))\nn_estimators = [x*100 for x in range(1,11)]\nparam_grid = dict(max_depth=max_depth)\nparam_grid['n_estimators'] = n_estimators\nmodel_xgb = XGBClassifier(learning_rate=0.005,\n                          gamma=0.6,\n                       random_state=42,\n                    eval_metric='error')\ngrid_search(model_xgb, param_grid)","0f013c85":"classifier_XGB = XGBClassifier(learning_rate=0.005,\n                       n_estimators=1000,\n                        max_depth= 2,\n                        gamma=0.6,\n                       random_state=42,\n                    eval_metric='error')\nclassifier_XGB.fit(x_train,y_train)","7685e463":"visualize_confusion_matrix(classifier_XGB)","2fc48e91":"accuracy_checker(classifier_XGB)","a556ad07":"classifier_AdB =  AdaBoostClassifier(n_estimators=50, random_state=0)\nclassifier_AdB.fit(x_train, y_train)","7e6098df":"visualize_confusion_matrix(classifier_AdB)","82150f7a":"accuracy_checker(classifier_AdB)","089d039b":"test_df.head()","7a2c384d":"test_data.head()","2885def0":"x_final = test_data.loc[:,test_data.columns != \"Survived\"].values\nx_sc = scaler.transform(x_final)","be83ac1e":"import statistics\n\npred_XGB = classifier_XGB.predict(x_sc)\npred_DT = classifier_DT.predict(x_final)\npred_SVM = classifier_LR.predict(x_sc)\n\nfinal_pred = np.array([])\nfor i in range(0,len(x_final)):\n    final_pred = np.append(final_pred, statistics.mode([pred_XGB[i], pred_DT[i], pred_SVM[i]]))","5b3e09f4":"output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': final_pred})\noutput[\"Survived\"] = output[\"Survived\"].astype(int)\noutput.to_csv('my_submission.csv', index=False)","ab31eb46":"### Making a Title column using the Name column:","90aef513":"## Handy functions to check accuracy and GridSearch:","28a9e461":"## AdaBoost:","ac99cda7":"### Adding IsAlone column to see if passenger was traveling alone:","6a98d058":"We can see the relation between the class of the passenger and the cabin they stayed in, so let's use that pattern to fill the data","856d02fd":"### Filling Age data:","ad4c7d9c":"## **Logistic Regression:**","7f7b52b4":"We see that the data shows that the fare of the tickets are higher for a first class passenger.","7a2955e7":"We can see that the passenger class of the passegers depend on their title. For example, we see that if a passenger has the title of Sir., he is most probably a first class passenger.","19de91e2":"## **Decision Tree:**","bf2d0e23":"### Making family data with help of SibSp & Parch columns:","9b3b29c5":"### Making Age group column:","05f5a794":"**For the purpose of preprocessing the data we will add both the train data and test data into 1 dataset and then later we will seperate it back**","4f6acdca":"## **XGBoost:**","4a067528":"## Predicitons and submission:","b0934417":"## **Naive Bayes:**","f55ab5ad":"## **Support Vector Classifier:**","14c41c67":"According to the data some passengers are travelling without paying anything :P, So let us impute the fare of these passengers to the average people paid for their Cabin Type","11b36c9e":"## **Random Forest:**","8604eb6b":"We can see that both the train data and test data have similar patterns like, there were many adults and less seniors on the ship","2f262ad9":"**Realizing that people with same ticket numbers are travelling in the same class. Let us try to impute those first**","6581ff16":"Looks like we got a few of them null datas from previous data","17ae8a04":"### Train-Test split:","79973318":"We can see that there is a high chance of a senior being a first class passenger","940c3326":"**Extracting the initials as it might have some information of the Cabin type:**","b2166a32":"**SVM with RBF kernel:**","67fdf743":"## **KNN:**","db29f0b0":"### Transforming the data so that the weights are not biased:","b924671b":"## **Importing Data:**","073587ba":"### Imputing Fare:","702f638f":"# Titanic | Kaggle problem:","bed6b793":"### We can give ranks to the different passengers using the information we got when we plotted them against their class and by researching about these titles:","e83a2280":"## **EDA & Preprocessing:**","34b9d1ac":"We can see that most of the passengers have the title Mr. and they are mostly adults. Which makes sense, the title Mr. is mostly used for Adults. Same with the title Mrs. But, if the title is Miss. which has a lot of nan data too, the passenger is most likely a youth. In the same way, if the title is Master., the passenger is most probably a child","acd76e99":"**Let us try to guess the age of people using the knowledge we got above:**\nthe idea is if the person has a certain title and certain class we can guess their age.\nExample: If a person has the title 'Dr.' he\/she is most probably travelling in 1st class (based on information we saw in the charts) and therefore we can use the mode or median of all Doctors travelling in 1st class","76680856":"We have an idea of the cabins in the different Decks now. A to C decks were mostly for the 1st class passengers, D to F were for the 2nd class passengers and G Deck was occupied by passengers of the 3rd class as this deck was at the bottom of the ship so the passengers could hear the engines noise and the most vibration on the ship was on this deck","e78d3fd4":"Googled all the ranks and titles, one of the references: https:\/\/en.wikipedia.org\/wiki\/Imperial,_royal_and_noble_ranks","a3b0d94b":"### Dealing with the Cabin Data:","1efbce4f":"The T Cabin mentioned in the data looks like a mistake in the data because there was no T Deck in Titanic and we have only one person in the whole T deck. The Pclass of the person is 1 so it is likely that he paid that price for a Cabin of 1st class that is A-C","88f12609":"Checking the data type in each column:","804deb23":"## **Importing Libraries:**","14bd8ad6":"Mapping the Cabin as per their class preference A was at the top of the ship so higher class passengers were preferred as explained in: https:\/\/en.wikipedia.org\/wiki\/First-class_facilities_of_the_Titanic\n"}}