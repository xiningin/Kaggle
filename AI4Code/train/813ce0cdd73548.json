{"cell_type":{"aba8148b":"code","20a497e2":"code","babb968b":"code","45c8e514":"code","31421a92":"code","3d4df929":"code","11a09778":"code","4589c95e":"code","f38ae69e":"code","babfb89c":"code","0b841e01":"code","a4370eaf":"code","46d71658":"code","88716b0d":"code","9da02b61":"code","f4ea14e5":"code","fc88f982":"code","a8393fb0":"code","35c65d52":"code","2c5ed590":"code","dd15b913":"code","907a68f3":"code","0fe5a4e7":"code","7c565200":"markdown","c24a85d8":"markdown","a26826b2":"markdown","93e5eefc":"markdown","1212b94f":"markdown","5f0e9e80":"markdown","5ead6fbc":"markdown","c51cc166":"markdown","f89e615f":"markdown","13a3a94b":"markdown","871f4759":"markdown","f56785a5":"markdown"},"source":{"aba8148b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","20a497e2":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nprint(train.shape)\ntrain.head()","babb968b":"test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest.head() ","45c8e514":"y_train = train['label']\nX_train = train.drop(['label'], axis=1)","31421a92":"plt.figure(figsize=(15,7))\ng = sns.countplot(y_train, palette='icefire')\nplt.title('Number of digit classes')\ny_train.value_counts() ","3d4df929":"img = X_train.iloc[1]\nimg = np.asanyarray(img)\nimg = img.reshape((28,28))\nplt.imshow(img, cmap='gray')\nplt.title(train.iloc[0,0])\nplt.axis(\"off\")\nplt.show()","11a09778":"img = X_train.iloc[2]\nimg = np.asanyarray(img)\nimg = img.reshape((28,28))\nplt.imshow(img, cmap='gray')\nplt.title(train.iloc[0,0])\nplt.axis(\"off\")\nplt.show()","4589c95e":"img = X_train.iloc[10]\nimg = np.asanyarray(img)\nimg = img.reshape((28,28))\nplt.imshow(img, cmap='gray')\nplt.title(train.iloc[0,0])\nplt.axis(\"off\")\nplt.show()","f38ae69e":"X_train, test = X_train \/ 255, test \/ 255 \nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)\nX_train.head() ","babfb89c":"X_train = X_train.values.reshape(-1,28,28,1)\nX_train.shape","0b841e01":"test=test.values.reshape(-1,28,28,1)\ntest.shape","a4370eaf":"y_train = to_categorical(y_train, num_classes = 10)","46d71658":"x_train, x_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.1, random_state=2)","88716b0d":"print(\"x_train shape\",x_train.shape)\nprint(\"x_test shape\",x_val.shape)\nprint(\"y_train shape\",y_train.shape)\nprint(\"y_test shape\",y_val.shape)","9da02b61":"# Some examples\nplt.imshow(X_train[5][:,:,0],cmap='gray')\nplt.show()","f4ea14e5":"model = Sequential() \n\nmodel.add(Conv2D(filters = 8, kernel_size=(5,5), padding='Same', \n                activation='relu', input_shape=(28,28,1))) \n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25)) \n\nmodel.add(Conv2D(filters=16, kernel_size=(3,3), strides=(2,2)))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25)) \n\nmodel.add(Flatten())\n## ANN\n\nmodel.add(Dense(256, activation=\"relu\")) \nmodel.add(Dropout(0.5))\nmodel.add(Dense(10,activation='softmax'))","fc88f982":"optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","a8393fb0":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","35c65d52":"epochs = 10  # for better result increase the epochs\nbatch_size = 250","2c5ed590":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(x_train)","dd15b913":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val), steps_per_epoch=x_train.shape[0] \/\/ batch_size)","907a68f3":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","0fe5a4e7":"Y_pred = model.predict(x_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(y_val,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Mat\")\nplt.show()","7c565200":"## Compile Model","c24a85d8":"# Normalization, Reshape and Label Encoding\n\n* If we do normalization, CNN works faster. \n* We need to reshape our data because of Keras. It will be like that 28x28x1 \n* Label Encoding\n     Encode labels to one hot vectors\n        2 => [0,0,1,0,0,0,0,0,0,0]\n        4 => [0,0,0,0,1,0,0,0,0,0]","a26826b2":"# Evaluate the model","93e5eefc":"### Define Optimizer","1212b94f":"# Loading The Dataset","5f0e9e80":"# Convolutional Neural Network\n\n* CNN is used for image detection, image classification. \n* Convolution Operation: \n    * We hace feature detector for our images. \n    * Feature detectors are also called as kernel or filter.\n    * Feature detector detects features like edges or convex shapes. \n    * If we apply it for an image, we'll have an feature map. This is the result of the our detector. \n       ","5ead6fbc":"## Max Pooling\n* It reduces the number of parameters\n* It makes the detection of features invariant to scale or orientation changes.\n\n<img src=\"https:\/\/preview.ibb.co\/gsNYFU\/maxpool.jpg\" \/>\n\n* At the and, this periot repeats a few times or how you would like, and these results will be flattened and will feed into an ANN.","c51cc166":"# Fit the Model ","f89e615f":"# Create Model","13a3a94b":"# Train and Test Split\n\n* We are going to split the data into train and test sets.","871f4759":"## Same Padding\n\n* As we keep applying conv layers, the size of the imagesses' volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n\n<img src=\"https:\/\/missinglink.ai\/wp-content\/uploads\/2019\/03\/Frame-2.png\" \/>","f56785a5":"## Data Augmentation \n\n* To avoid overfitting problem, we can expand our handwritten digit dataset\n* Rotate images, zoom images ect "}}