{"cell_type":{"eea365dc":"code","2157d7f7":"code","70e8058c":"code","ecfbe96b":"code","5155c9e2":"code","b486665c":"code","264355bd":"code","10cbc809":"code","d08acb19":"code","152ac4bf":"code","68724c0d":"code","97df7131":"code","6f2e3e51":"code","bf0c84af":"code","8dc63fe8":"code","83d42c69":"code","b7b2ce63":"code","a936b923":"code","746525f3":"code","6aea56ff":"code","d24120fd":"code","12334c65":"code","b5932da5":"code","c3843b46":"code","c82b92c7":"code","53650f89":"code","bc0d3d1a":"code","7b5615c3":"code","c492dc52":"code","2bf8da06":"code","a4df89ac":"code","d80329b3":"code","38dca6f1":"code","88ae78b2":"code","a5358554":"code","f633d9e2":"markdown","490fbaff":"markdown","4914db2f":"markdown","574f0a84":"markdown","378b80c8":"markdown"},"source":{"eea365dc":"import sys\nimport os\nimport platform\nprint(sys.version)\nprint(os.name)\nprint(platform.system())\nprint(platform.release())","2157d7f7":"import torch\nis_cuda_enabled = torch.cuda.is_available()\nprint('Cuda enabled', is_cuda_enabled)\nif torch.cuda.is_available():\n    print(torch.cuda.current_device())\n    print(torch.cuda.device(0))\n    print(torch.cuda.device_count())\n    print(torch.cuda.get_device_name(0))","70e8058c":"!nvcc --version","ecfbe96b":"!nvidia-smi","5155c9e2":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pydicom\nimport pandas as pd\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom tqdm import tqdm\nimport binascii\nfrom PIL import Image\n\nfrom fastai.vision.all import *\nimport numpy as np\nimport pandas as pd\nimport random\nnp.set_printoptions(threshold=sys.maxsize)","b486665c":"torch.cuda.empty_cache()","264355bd":"EPOCHS = 10\nINPUT_PATH = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\nLABELS_PATH = os.path.join(INPUT_PATH, 'train_labels.csv')\nMODEL_EXPORT = '\/kaggle\/working\/trained_model'\n\ndf = pd.read_csv(LABELS_PATH, header=0, names=['id','value'], dtype=object)\nexclude_cases = [\"00109\", \"00123\", \"00709\"] #according to description\ndf = df[~df.id.isin(exclude_cases)]","10cbc809":"df.head()","d08acb19":"# values distribution\nplt.figure(figsize=(5, 4))\nsns.countplot(data=df, x=\"value\")","152ac4bf":"#create output dataset folders\nos.makedirs('.\/train', exist_ok = True)\nprint('Train folder created')\n\nos.makedirs('.\/test', exist_ok = True)\nprint('Test folder created')","68724c0d":"def seed_everything(seed=2021):\n    import random\n    import os\n    import tensorflow as tf\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    print('Seed done!')\n    \ndef natural_sort(l): \n    #https:\/\/stackoverflow.com\/a\/4836734\/8245487\n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(l, key=alphanum_key)    \n    \ndef process_dicom(path):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    max_val = np.max(data)\n    if max_val == 0:  # RuntimeWarning: invalid value encountered in true_divide\n        return None\n    \n    data = data - np.min(data)\n    data = data \/ max_val\n    data = (data * 255).astype(np.uint8)\n    return data\n    \ndef save_image(data, outpath):\n    height = len(data)\n    width = len(data[0])\n    \n    pixels_out = []\n    for row in data:\n        pixels_out.extend(row)\n    assert(len(pixels_out) == height * width)\n    \n    image_out = Image.new('L', (width, height))\n    image_out.putdata(pixels_out)\n    image_out.save(outpath)\n    \ndef resolve_dicom_files(input_dir, dataset='train'):\n    for subdir, dirs, files in os.walk(f\"{input_dir}\/{dataset}\"):\n        if len(files) == 0:\n            continue\n        filename = natural_sort(files)[len(files)\/\/2] #take middle most image -- FLAIR DCM file per training item.\n        filepath = os.path.join(subdir, filename)\n        \n        if filepath.endswith(\".dcm\") and \"FLAIR\" in filepath:\n            cur_id = subdir.split('\/')[-2]\n            outpath = os.path.join(f'.\/{dataset}',f'{cur_id}.png')\n            \n            data = process_dicom(filepath)\n            save_image(data, outpath)","97df7131":"seed_everything()","6f2e3e51":"%%time\nresolve_dicom_files(INPUT_PATH, 'train')\nresolve_dicom_files(INPUT_PATH, 'test')","bf0c84af":"for id_num in df.id:\n    full_path = f'.\/train\/{id_num}.png'\n    df.loc[df.id == id_num, 'file'] = full_path","8dc63fe8":"df","83d42c69":"# a DataLoaders object is a combination of training and validation data\nimage_data = ImageDataLoaders.from_df(df, item_tfms=Resize(224), bs=64, label_col=1, fn_col=2, path='')","b7b2ce63":"# look at the data\nimage_data.show_batch()","a936b923":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self, pretrained=False):\n        super().__init__()\n        # 3 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        return x","746525f3":"model = Net()\nprint(model)","6aea56ff":"params = list(model.parameters())\nprint(len(params))\nprint(params[0].size())  # conv1's .weight","d24120fd":"# chooses an appropriate loss function\nlearn = cnn_learner(image_data, Net, metrics=[error_rate, accuracy], model_dir=\"\/tmp\/model\/\").to_fp16()","12334c65":"learn.lr_find()","b5932da5":"# Print model's state_dict\nprint(\"Model's state_dict:\")\nfor param_tensor in model.state_dict():\n    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())","c3843b46":"%%time\nlearn.fit_one_cycle(EPOCHS, lr_max=1e-2)","c82b92c7":"# show results of prediction\nlearn.show_results()","53650f89":"#save model to disk\nlearn.save(MODEL_EXPORT)","bc0d3d1a":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(9, figsize=(15,11))","7b5615c3":"df_test = pd.DataFrame(columns=['id', 'value'])\ndf_test.id = os.listdir(os.path.join(INPUT_PATH, \"test\/\"))","c492dc52":"# load weights\n#learn = cnn_learner(image_data, Net, metrics=[error_rate, accuracy], model_dir=\"\/tmp\/model\/\").to_fp16()\n#learn_new = learn.load(MODEL_EXPORT)","2bf8da06":"%%time\nfor id_num in df_test.id:\n    full_path = f'.\/test\/{id_num}.png'\n    prediction = learn.predict(full_path)\n    probability = prediction[2][1].item()\n    print(probability)\n    df_test.loc[df_test.id==id_num, 'value'] = probability","a4df89ac":"df_test.head()","d80329b3":"df_test.value.min(), df_test.value.max()","38dca6f1":"df_output = df_test.rename(columns={'id':'BraTS21ID','value':'MGMT_value'})\ndf_output.to_csv('submission.csv', index=False)\ndf_output.head()","88ae78b2":"# taken from here https:\/\/stackoverflow.com\/a\/49199019\nimport pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system\/pip names. Unfortunately,\n        # there is no systematic way to get pip names from\n        # a package's imported name. You'll have to add\n        # exceptions to this list manually!\n        poorly_named_packages = {\n            \"PIL\": \"Pillow\",\n            \"sklearn\": \"scikit-learn\"\n        }\n        if name in poorly_named_packages.keys():\n            name = poorly_named_packages[name]\n\n        yield name\nimports = list(set(get_imports()))\n\n# The only way I found to get the version of the root package\n# from only the name of the package is to cross-check the names \n# of installed packages vs. imported packages\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","a5358554":"df_test.head()","f633d9e2":"# Load labels","490fbaff":"# Predict stage","4914db2f":"# Training stage","574f0a84":"<div class='alert alert-info' style='text-align: center'><h1>Brain Tumor Classification<\/h1<\/div>\n\n#### This notebook is a train & predict script for classifiying brain tumors.\n#### It trains Classification (pos\/neg for MGMT status).\n#### The datasets are split into train\/test sets.\n#### I exported the JPGs from the RSNA-MICCAI brain MR dataset","378b80c8":"# Print requirements"}}