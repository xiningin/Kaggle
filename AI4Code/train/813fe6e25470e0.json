{"cell_type":{"b677964d":"code","052ababf":"code","3aa61dc1":"code","dba5884c":"code","7d892113":"code","f367dd8a":"code","2a659d0e":"code","6b57b5ed":"code","fa4f5ecd":"code","8520cf55":"code","3c76b58f":"code","2c7a2d7e":"code","48c02d30":"code","453215cf":"code","44979263":"code","2b66a108":"code","8f420fb7":"code","c4e17d04":"code","2ceddf1a":"code","4cba668a":"code","4b7eb37a":"code","90da30ce":"code","d51accde":"code","2ffd137b":"code","5044d6fd":"code","dacedfcf":"code","86f93a5e":"code","c75bee9c":"code","22ac6615":"code","66669a6c":"code","2a5f36b5":"code","86004d26":"code","2d739481":"code","59a36bef":"code","830f0ac8":"code","85fe9956":"code","391b816c":"code","6aee4302":"code","461b9d54":"code","f94784b4":"code","d2f11954":"code","6fea0c25":"code","407f50e0":"code","505f436e":"code","c373613e":"code","219ceafb":"code","aed68ae1":"code","439e5ba3":"code","00f27b7f":"code","07c9d8a4":"code","79cc5d45":"code","164befa9":"code","64b6f4b8":"code","2ef928c8":"code","0fb045cf":"code","977f3530":"code","70c6b8cb":"code","ebc02f38":"code","670baa1b":"code","3e74d565":"code","9701517f":"code","c04fa783":"code","95b7bf3a":"markdown","b67f8a8f":"markdown"},"source":{"b677964d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","052ababf":"data = pd.read_csv('\/kaggle\/input\/car-price-prediction\/CarPrice_Assignment.csv')\ndata","3aa61dc1":"import seaborn as sns\nsns.distplot(data.price)","dba5884c":"from sklearn.preprocessing import PowerTransformer\np = PowerTransformer(method = 'box-cox')\ndata['price'] = p.fit_transform(data[['price']])\nsns.distplot(data.price)","7d892113":"# from sklearn.preprocessing import FunctionTransformer\n#  f = FunctionTransformer(np.log1p)\n# data['price'] = f.fit_transform(data[['price']])\n# sns.distplot(data.price)","f367dd8a":"data.drop(columns = ['car_ID'],inplace = True)","2a659d0e":"car = data.CarName.str.split(expand = True)\nBrand = car[0]\ndata['Brand'] = Brand\ndata","6b57b5ed":"data.drop(columns = ['CarName'],inplace = True)","fa4f5ecd":"data","8520cf55":"data.dtypes","3c76b58f":"# Here cylinder number has mapped > because few values has gone for the least test so it should be removed,\n# so made it as > and mapped\n# (and also mapping is done because two error has occured at a time)\n# (in case if their is only one error it can be made that pericular value is not eqaul to that perticular column as below code )\n# data = data[data.cylindernumber!='three']\ndata = data[data[(\"cylindernumber\")].map(data[\"cylindernumber\"].value_counts())>4]\ndata = data[data[(\"enginetype\")].map(data[\"enginetype\"].value_counts())>1]\ndata = data[data[(\"fueltype\")].map(data[\"fueltype\"].value_counts())>3]\ndata = data[data[(\"Brand\")].map(data[\"Brand\"].value_counts())>9]\ndata = data[data.carbody!='convertable']\ndata = data[data.fueltype!='mfi']\n","2c7a2d7e":"# data.select_dtypes(include = ['int','float']).std()","48c02d30":"x = data.iloc[:,0:23]\n#y = data.price\ny = data[['price']]","453215cf":"x = data.drop(columns = ['price'])","44979263":"x","2b66a108":"y","8f420fb7":"x.dtypes","c4e17d04":"data.iloc[:,4]","2ceddf1a":"nomi_col = [4,5,12,15,23,13]\nordinal_col = [1,2,3,6]\nnumeric_col = [0,9,10,14,16,17,18,20,21,22]\nKBin_col = [11,19]\nBina_col = [7,8]","4cba668a":"from sklearn.preprocessing import KBinsDiscretizer,Binarizer,PowerTransformer\nfrom sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\ntrans = make_column_transformer((OneHotEncoder(sparse = False),nomi_col),\n                               (OrdinalEncoder(),ordinal_col),\n                                 (PowerTransformer(),numeric_col),\n                                 (KBinsDiscretizer(),KBin_col),\n                                  (Binarizer(threshold = 50),Bina_col),\n                                  remainder = 'passthrough')\nset_config(display ='diagram')\ntrans","4b7eb37a":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3)","90da30ce":"from sklearn.linear_model import LinearRegression \nmodel = LinearRegression()\nfrom sklearn.pipeline import make_pipeline\npipe = make_pipeline(trans,model)\n","d51accde":"model","2ffd137b":"pipe","5044d6fd":"pipe.fit(x_train,y_train)","dacedfcf":"pred = pipe.predict(x_test)","86f93a5e":"from sklearn.metrics import mean_squared_error\nmean_squared_error(pred,y_test)\n","c75bee9c":"model.coef_","22ac6615":"model.intercept_","66669a6c":"from sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nmodel_B = BaggingRegressor(base_estimator = SVR())\nmodel_B\n","2a5f36b5":"pipe_B = make_pipeline(trans,model_B)\npipe_B","86004d26":"pipe_B.fit(x_train,y_train)","2d739481":"pred_B = pipe_B.predict(x_test)\npred_B","59a36bef":"from sklearn.metrics import mean_squared_error\nmean_squared_error(pred_B,y_test)","830f0ac8":"from sklearn.ensemble import VotingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\nalgorithm1 = SVR()\nalgorithm2 = DecisionTreeRegressor()\nalgorithm3 = LinearRegression()\nmodel_V = VotingRegressor(estimators = [('x1',algorithm1),('x2',algorithm2),('x3',algorithm3)],verbose = True)\npipe_v = make_pipeline(trans,model_V)\npipe_v","85fe9956":"pipe_v.fit(x_train,y_train)","391b816c":"pred_v = pipe_v.predict(x_test)\npred_v","6aee4302":"\nmean_squared_error(pred_v,y_test)","461b9d54":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\nmodel_GB = GradientBoostingRegressor()\npipe_GB = make_pipeline(trans,model_GB)\npipe_GB","f94784b4":"pipe_GB.fit(x_test,y_test)","d2f11954":"pred_GB = pipe_GB.predict(x_test)\npred_GB","6fea0c25":"from sklearn.metrics import mean_squared_error\nmean_squared_error(pred_GB,y_test)","407f50e0":"import xgboost as xgb\nmodel_xgbc = xgb.XGBRegressor(learning_rate = 0.07,max_depth = 15,gamma = 4)\npipe_xgbc = make_pipeline(trans,model_xgbc)\npipe_xgbc","505f436e":"pipe_xgbc.fit(x_train,y_train)","c373613e":"pred_xgbc = pipe_xgbc.predict(x_test)","219ceafb":"mean_squared_error(pred_xgbc,y_test)","aed68ae1":"from xgboost import plot_importance\nplot_importance(model_xgbc)","439e5ba3":"from sklearn.ensemble import StackingRegressor\nfrom sklearn.linear_model import LinearRegression as lr\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nsr = StackingRegressor([('lr',lr()),('svr',SVR())],final_estimator = DecisionTreeRegressor(),cv = 7,n_jobs = -1)\npipe_sr = make_pipeline(trans,sr)\n","00f27b7f":"pipe_sr","07c9d8a4":"pipe_sr.fit(x_train,y_train)","79cc5d45":"pred_sr = pipe_sr.predict(x_test)\npred_sr","164befa9":"mean_squared_error(pred_sr,y_test)","64b6f4b8":"from sklearn.naive_bayes import GaussianNB\nGNB = GaussianNB()\nfrom sklearn.pipeline import make_pipeline\npipe_GNB = make_pipeline(trans,GNB)\npipe_GNB","2ef928c8":"y_train = y_train.astype('int')","0fb045cf":"pipe_GNB.fit(x_train,y_train)","977f3530":"y_train.dtypes","70c6b8cb":"y_train.dtypes ","ebc02f38":"pred_GNB = pipe_GNB.predict(x_test)\npred_GNB = pred_GNB.astype('float')\npred_GNB","670baa1b":"y_test","3e74d565":"mean_squared_error(pred_GNB,y_test)","9701517f":"from sklearn.preprocessing import PowerTransformer\np.inverse_transform(pred_GNB.reshape(-1,1))                  # (-1,1) converts row into column                      \n","c04fa783":"mean_squared_error(pred_GNB,y_test)","95b7bf3a":"intercept it is the slope of the y axis","b67f8a8f":"predicited value is the minimum optimum slope(i.e m dash value)and 1 value is the slope of the entire  1st column\n2nd value is the slope of the entire 2nd column (same for everythin)"}}