{"cell_type":{"a3338e8b":"code","63efc6ce":"code","8e234492":"code","fc1699c0":"code","a2c0119f":"code","6f007929":"code","cacc621c":"code","8ce3812d":"code","ff1eb5e0":"code","30ae0df3":"code","1d62b0bc":"code","4a74c165":"code","96fcc829":"code","676dd045":"code","e3bfa1a5":"code","ac0a129e":"code","f3fe5a69":"code","e30e8d35":"code","f1f511ed":"code","23183f7d":"code","0cffcd5b":"code","69485b74":"code","7f5ed8bb":"code","06274898":"code","5e3c299a":"code","908eba7f":"code","7ec8481f":"code","9ab7cd2f":"code","e1af809e":"code","c4fe7366":"code","71f963c9":"code","46bc911c":"code","bee04192":"code","72fbe644":"code","f8b5d54d":"code","31f9e59c":"code","cbc23117":"code","f6367f09":"code","ae6a9dff":"code","e81a169e":"code","f0e4957e":"code","5320e162":"code","be6f0bc1":"code","f4b8c236":"code","f17edb3a":"code","80f91a65":"code","ba335c59":"code","94bd4238":"code","705d5edb":"code","e805f38f":"code","4da9ba01":"code","7d2e9663":"code","179bdceb":"code","7e5cd877":"code","a48d050a":"code","b9538175":"code","3321c39e":"code","f0d03c72":"markdown","50bf6594":"markdown","860cee71":"markdown","ef8ce513":"markdown","9c518909":"markdown","e381f5f3":"markdown","81a2399c":"markdown","46cd883c":"markdown","e99c9fd3":"markdown","a1e1cf81":"markdown","a7dad478":"markdown","0a2d0ff4":"markdown","784f8ffd":"markdown","f06e52b7":"markdown","1b154cc5":"markdown","483e957d":"markdown","50eba214":"markdown","8402b164":"markdown","31b651e5":"markdown","7d55e27f":"markdown","8faa6d97":"markdown","a343cd7e":"markdown","1d30a442":"markdown","17c53746":"markdown","20d071f2":"markdown","977f693f":"markdown","5cb64e11":"markdown","2bd31543":"markdown","0cd6d8c6":"markdown","a70abb38":"markdown","b55f268f":"markdown","2eca3866":"markdown","f1e25186":"markdown","72d5ee34":"markdown","c4071de8":"markdown","4e6b6b0b":"markdown","ae1cbc40":"markdown","06cfd0b3":"markdown","3697afc9":"markdown","f619458b":"markdown","0461d740":"markdown","7c627f5e":"markdown","add8ce8d":"markdown","8595675f":"markdown","2ddd9590":"markdown","209700cc":"markdown","133fe088":"markdown","d882314c":"markdown","6a262a85":"markdown","63177726":"markdown","74e12279":"markdown","e3971749":"markdown","bda692a6":"markdown","43a5977e":"markdown","7974bfaa":"markdown","5387dd36":"markdown","50671c45":"markdown","e6944a10":"markdown","4d807d6c":"markdown","9d2f9513":"markdown","a0a4fffe":"markdown","2f880ca1":"markdown","80e55e25":"markdown","130a0ed5":"markdown","c339b074":"markdown","6efd65c1":"markdown","6d3c147f":"markdown"},"source":{"a3338e8b":"#Importing numpy and pandas\nimport numpy as np\nimport pandas as pd","63efc6ce":"#Importing dataset\ndf=pd.read_csv('..\/input\/montcoalert\/911.csv')","8e234492":"#Viewing the dataset\ndf.head()","fc1699c0":"#Checking columns name, null values and data types of each column\ndf.info()","a2c0119f":"#Renaming the column as follows:'zip' to 'zipcode', 'twp' to 'township',  'addr' to 'address'\ndf.rename({'zip':'zipcode', 'twp':'township', 'addr':'address'}, axis=1, inplace=True)","6f007929":"#Checking if the column name was successfully changed.\ndf.head(3)","cacc621c":"#Checking unique values in column with name 'e'\ndf.e.unique()","8ce3812d":"#deleting column 'e'\ndel df['e']","ff1eb5e0":"#Checking if the column is deleted\ndf.head(3)","30ae0df3":"#Checking for null values in percentage\ndf.isna().sum()*100 \/ len(df)","1d62b0bc":"#Deleting rows with null values in township column\ndf= df.dropna(subset=['township'])","4a74c165":"#Checking rows with null values in other coumns. In this case checking null in zipcode column\ndf[df.isnull().any(axis=1)]","96fcc829":"#Replacing null values with 0 in 'zipode' column\ndf['zipcode'].fillna(0, inplace=True)","676dd045":"#Vreifying if the null values were removed and replaced\ndf.isna().sum()","e3bfa1a5":"#We will format the column as follows: 'zipcode' as int64,  'timeStamp' as 'datetime64'\ndf = df.astype({'zipcode':'int64' , 'timeStamp':'datetime64'})","ac0a129e":"#Checking if the dateStam was formated to datetime or not!\ndf.info()","f3fe5a69":"#creating four new columns from the 'timestamp' column.\ndf['Hour'] = pd.to_datetime(df['timeStamp']).dt.hour\ndf['Day'] = pd.to_datetime(df['timeStamp']).dt.dayofweek\ndf['Month'] = pd.to_datetime(df['timeStamp']).dt.month\ndf['Year'] = pd.to_datetime(df['timeStamp']).dt.year","e30e8d35":"#Checking if new columns were inserted\ndf.head(3)","f1f511ed":"# checking number of unique values in day column\ndf.Day.unique()","23183f7d":"# checking number of unique values in month column\ndf.Month.unique()","0cffcd5b":"#mapping 'Day' column to day names\nday_map = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\ndf['Day'] = df['Day'].map(day_map)","69485b74":"#mapping 'Month' column to month names\nmonth_map = {1:'Jan',2:'Feb',3:'March',4:'April',5:'May',6:'June',7:'July',8:'Aug',9:'Sept',10:'Oct',11:'Nov',12:'Dec'}\ndf['Month'] = df['Month'].map(month_map)","7f5ed8bb":"#checking the changes\nprint(df.Day.unique())\nprint(df.Month.unique())","06274898":"#Importing seaborn and matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","5e3c299a":"#Plotting a bar plot of the count of different values in 'Year' column.\nsns.countplot(x ='Year', data = df)","908eba7f":"#Deleting rows with 2015 and 2020 in 'year' column\ndf = df[df.Year != 2015]\ndf = df[df.Year != 2020]","7ec8481f":"#Viewing our cleaned data\ndf.tail()","9ab7cd2f":"# Checking the different types of emergency types\ndf['title'].value_counts().head(20)","e1af809e":"# Splitting 'title' column into two different columns\ndf[['category','sub_category']] = df.title.str.split(':',expand=True,)","c4fe7366":"#checking if the split was done\ndf.head(3)","71f963c9":"#finding unique values in 'category' column in percentage\n(df['category'].value_counts()\/len(df['category']))*100","46bc911c":"#plotting unique values in 'category' column\nsns.countplot(x ='category', data = df)","bee04192":"#finding unique values in 'sub_category' columnn in percentage\n((df['sub_category'].value_counts()\/len(df['sub_category']))*100).head(30)","72fbe644":"#removing \" -\" from all the cells in 'sub_category' column\ndf['sub_category'] = df['sub_category'].str.replace(\" -\",\"\")","f8b5d54d":"#Again checking for unique values in 's_category' columnn in percentage\n((df['sub_category'].value_counts()\/len(df['sub_category']))*100).head(30)","31f9e59c":"#plotting unique values of first 20 values in 'category' column in descending order\nplt.figure(figsize=(8,10))\nsns.countplot(y ='sub_category', data = df, order=df['sub_category'].value_counts().iloc[:30].index)","cbc23117":"#hourly calling plot.\nplt.figure(figsize=(8,5))\nsns.countplot(df['Hour'])","f6367f09":"#Ploting calls made through various days.\nplt.figure(figsize=(8,5))\nsns.countplot(df['Day'])","ae6a9dff":"#Ploting calls made through various months.\nplt.figure(figsize=(8,5))\nsns.countplot(df['Month'])","e81a169e":"#Ploting calls made through various year present in our dataset.\nplt.figure(figsize=(8,5))\nsns.countplot(df['Year'])","f0e4957e":"plt.figure(figsize=(15,5))\nsns.countplot(df['Hour'], hue=df['category'])","5320e162":"#Extracting 'EMS' from category column and plotting the EMS column and hours\nEMS= (df.loc[df['category'] == 'EMS'])\n\nplt.figure(figsize=(8,5))\nsns.countplot(EMS['Hour'])","be6f0bc1":"#Finding the top reasons of EMS calls made (in percentage)\nEMS = df[df['category']=='EMS']['sub_category']\n(EMS.value_counts()\/len(EMS)*100).head(30)","f4b8c236":"fall_victim= df[df['sub_category']=='FALL VICTIM']['township']\n\n#plt.figure(figsize=(8,10))\n#sns.countplot(y ='township', data = fall_victim, order=df['township'].value_counts().iloc[:30].index)","f17edb3a":"#removing leading and tailing whitespace\ndf.sub_category = df.sub_category.str.strip()","80f91a65":"fall_victim= df[df['sub_category']=='FALL VICTIM']['township']\n\nplt.figure(figsize=(8,10))\nsns.countplot(y=fall_victim, order=fall_victim.value_counts().iloc[:30].index)","ba335c59":"#Extracting 'Traffic' from category column and plotting the EMS column and hours\nTraffic= (df.loc[df['category'] == 'Traffic'])\n\nplt.figure(figsize=(8,5))\nsns.countplot(Traffic['Hour'])","94bd4238":"Traffic = df[df['category']=='Traffic']['sub_category']\n(Traffic.value_counts()\/len(Traffic)*100).head(30)","705d5edb":"plt.figure(figsize=(7,4))\nsns.countplot(y=Traffic, order=Traffic.value_counts().iloc[:30].index)","e805f38f":"#Extracting 'Fire' from category column and plotting the Fire column and hours\nFire= (df.loc[df['category'] == 'Fire'])\n\nplt.figure(figsize=(8,5))\nsns.countplot(Fire['Hour'])","4da9ba01":"Fire = df[df['category']=='Fire']['sub_category']\n(Fire.value_counts()\/len(Fire)*100).head(30)","7d2e9663":"plt.figure(figsize=(8,7))\nsns.countplot(y=Fire, order=Fire.value_counts().iloc[:20].index)","179bdceb":"Fire = df[df['category']=='Fire']['sub_category']\n(Fire.value_counts()\/len(Fire)*100).head(30)","7e5cd877":"#Towns with highest number of vehicle accidents.(in percentage)\nveh_acc= df[df['sub_category'] == 'VEHICLE ACCIDENT']['township']\n(veh_acc.value_counts()\/len(veh_acc)*100).head(30)","a48d050a":"#Towns with highest number of disabled vehicle.(in percentage)\ndis_veh= df[df['sub_category'] == 'DISABLED VEHICLE']['township']\n(dis_veh.value_counts()\/len(dis_veh)*100).head(30)","b9538175":"#Towns with highest number of fire alarm.(in percentage)\nfire_alm= df[df['sub_category'] == 'FIRE ALARM']['township']\n(fire_alm.value_counts()\/len(fire_alm)*100).head(30)","3321c39e":"#Towns with highest number of fire alarm.(in percentage)\nfall_vctm= df[df['sub_category'] == 'FALL VICTIM']['township']\n(fall_vctm.value_counts()\/len(fall_vctm)*100).head(30)","f0d03c72":"## 3. Importing the data and checking for consistency","50bf6594":"Here we noticed that 'VEHICLE ACCIDENT' is repeated two times. In first place and in forth place. It is because the first 'VEHICLE ACCIDENT' has a ' -' at the end. So two seperate values are creates. One as 'VEHICLE ACCIDENT -' ans other as 'VEHICLE ACCIDENT'.\n\nSo, we will remove the extra space and - from those values. We will do this for the entire column beacuse thee are more values like this.","860cee71":"### Recommendation","ef8ce513":"We notice that previously 'VEHICLE ACCIDENT' was only 22.98%. But after correction it became 28.55%.This is a great correction that is done. Else it would have been ruin our analysis.\n\nNow lets proceed to plotting this values.","9c518909":"Here also highest accidents occurs between 8am to 7pm.\n\nLets see the subcategory for which large number of calls recorded.","e381f5f3":"#### Ans. From this we can see that ''LOWER MERION', 'UPPER MERION', 'ABINGTON', are the cities from where highest number of complain were made. This may be because this cities have bad road or bad traffic conditions. Or it might be that this cites have a very poor city controlling authority.","81a2399c":"We have found that highest number of emergency call was made for 'VEHICLE ACCIDENT'. So, lets see in which locations high number of accidents occurs.","46cd883c":"Since we find that there is only 1 value in the entire 'e' column. So this column is of no use. We will delete this column.","e99c9fd3":"We can see that most calls occured between 8am to 9pm. \n\nWe will find the sub category of highest calls made during this period as EMS.","a1e1cf81":"We can see that calls made on Saturday and Sunday are much lower than that of the other days.\n\nThis may be because most people don't go to work on those days.\n\nWe confirms that few emergency situation occur due to the people going to work. Or may be they faces different emergency problems during their working hours ","a7dad478":"We can see that the column names 'zip',   'twp',   'addr',   'e' have names that are not written properly. Also there are null values in 'zip' and 'twp' column. Moreover 'zip' and 'timeStamp' column are not formated correctly.\n\nWe will correctly write the column names. For column name with 'e' we have to check and verify it as it contain data that doesn't look correct. \n\nAnd then check for the null values. If keeping or removing the rows with null values would affect our analysis.\n\nThen format the columns properly.\n\nWe can also check for consistency of the time period. Eg. if the time period is from 2009 to 2015 the we can check that does the beggining year 2009 and ending year 2015 has data availble for all the months. If not available, should we remove data of those years which might affect our analysis.\n\nAt last we will remove all the extra spaces from every new column we create.\n\n\n","0a2d0ff4":"The above plot can be more clearly visualize if we seperately plot for three different category.","784f8ffd":"Again 'LOWER MERION' and 'ABINGTON' is at the top of the list having the highest calls made.","f06e52b7":"### Q. Which category of maximum emergency call was made in those time frames?","1b154cc5":"We can identify that those rows with null values in the 'zipcode' column has complete and unique information in other columns.\nSo we will not delete those rows for now. Because by deleting those rows, we will lost a great amount of data. \nInstead we will replace the null values with zero for the smoothness of our analysis.","483e957d":"## 4. Data Cleaning","50eba214":"This are all towns of Pennsylvania, United States. We can see from the data that some towns like 'LOWER\/UPPER MERION', 'ABINGTON', 'LOWER PROVIDENCE' have high number of calls recorded as 'FALL VICTIM'. It means that this towns may have high crime rate.","8402b164":"Now we can check for consistency by plotting year column in seaborn","31b651e5":"Here we can clearly see that calls made during the time period of 22:00 hrs at night till 6:00 hrs in the morning is extremely low compared to the other time period.\n\nThis is because its nighttime and most people sleeps in those hours.\n\nWe can see a gradually rising in the number of calls from 8am upto 5 pm. This might happen because those are the standard working hours and during their work they might faces problem.\n\nPreviously we have found that 28% of emergency calls was made for vehicle accidents. \n\nSo, we can deduce that this 28% people may have been in a rush while driving during their working hours.","7d55e27f":"'FIRE ALARM' with 38% is the highest calls made during the working hours. It may be because during the working hours most of the hotels and resturants had to works at a fast speed, due to which a fire may occurs in some of them.\n\nSecond highest call recorded is again 'VEHICLE ACCIDENT' which is for nthe reasons described above.\n\nNext are 'FIRE INVESTIGATION', 'GAS-ODOR\/LEAK' which might happen sometimes due to lots of reasons.","8faa6d97":"We can see from here that there are three main categories of emergencies like 'Traffic', 'EMS'(emergency medical service), and 'Fire'. And various other sub categories. So, we will divide the main categories and subcategories by creating two new columns as 'category' and 's_category'.","a343cd7e":"Only few towns like 'LOWER MERION', 'UPPER MERION', 'ABINGTON', 'CHELTENHAM' have high rate of above 5% Vehicle accidents. Maybe this towns have bad roads or has less roads for which high traffic occurs.","1d30a442":"#### Ans. The main type of emergencies calls are: Traffic related calls, EMS(emergency medical service) calls, and Fire related calls.","17c53746":"Analyzing the EMF emergency calls","20d071f2":"Analyzing the Fire emergency calls","977f693f":"Next we will create dataframes by keeping only those rows having 'FALL VICTIM'","5cb64e11":"Analyzing the Traffic emergency calls","2bd31543":"Next we will create dataframes by keeping only those rows having 'FIRE ALARM'","0cd6d8c6":"To answer this question we have to find the different types of emergencies from the 'title' column.","a70abb38":"To answer this question we will plot the number of calls made during hours of the day, during each day, during each month, and during each year.\n\nWe will look for patterns in each plot and find insights.","b55f268f":"### Q. At what locations highest types of emergency calls were made?","2eca3866":"#### Ans. 'VEHICLE ACCIDENT' and 'DISABLED VEHICLE' are the highest number of calls made overall. We found that this call was recorded high when people start going to work. And again when people return back from work. People might be in a hurry to reach office. And also when returning back they might be tired of whole day work and rush to reach home as early as possible. Next highestb calls recordes was 'FIRE ALARM' and 'FALL VICTIM'","f1e25186":"We didn't see much change or patterns.","72d5ee34":"'LOWER MERION' and 'ABINGTON' are again in the second and third position of the list. 'LOWER PROVIDENCE' is also on top of the list meaning that this cities may have ahigh crime rate.","c4071de8":"#### Checking for time consistency","4e6b6b0b":"Now we have two seperate columns for emergency of main category and sub category.\n\nWe will plot on this coloums to find insights and answer our question.","ae1cbc40":"### Q. Which categories of emergency has made the highest number of calls?","06cfd0b3":"We can see that there are 12.086% of null values in 'zipcode' column. And only 0.044% null values in 'township' column.\n\nWe can remove the rows with 0.044% values in the 'township' column because removing this small percent rows won't affect our analysis.\n\nWe will check the 'zipcode' column. And decide whether to remove those rows or maybe removing them would affect our further analysis.","3697afc9":"We didn't see much change or patterns.","f619458b":"#### Ans. Maximum calls was made during the awaking hours i.e. in between 6am to 10 pm. Also a gradually rising of calls from 8am till 5pm along with car accident as highest number of calls made denotes that most people are in a hurry during their working hours.","0461d740":"From this plot we can see that there are very less values for the year 2015. Also the year 2020 have almost half the values as compared to other years. This might happen because during the data collection process, the data may be collected from the last part of 2015. And for 2020 only the beggining few month of the year, the data was collected. So there were very less data for this two year.\n\nWe will remove the data of this two year. Because removing this will help us to be more accurate and consistence throughout our analysis.","7c627f5e":"##### Highest calls were made for EMS\/medical service. \n##### Most EMS calls were made for the purpose of Vehicle Accident and Disabled Vehicle to be the highest.\n##### Most of this calls were made in between 8 am to 5 pm for reporting Car Accident. This is because people are in a rush during their working working hours.\n\n##### Also in cities like Lower Merion, Upper Merion and Abington may have bad road conditions or may have poor traffic controlling authority.","add8ce8d":"#### Ans. We can see that  almost almost 28% of the calls were made for VEHICLE ACCIDENT. Followed by DISABLED VEHICLE at 7%. Then  FIRE ALARM , FALL VICTIM ,  RESPIRATORY EMERGENCY, CARDIAC EMERGENCY at 5%. And ROAD OBSTRUCTION, SUBJECT IN PAIN, HEAD INJURY at almost 3%. The rest of them are 1% or less.\n\nWe will consider only those who have call rates of 1% or above.","8595675f":"First we will create dataframes by keeping only those rows having 'VEHICLE ACCIDENT'","2ddd9590":"Highest call is 'FALL VICTIM'. This is because there may be crimes in some areas due to which people got hurt and made calls. We can verify it by plotting those area where 'FALL VICTIM' was reported.\n\nNext are 'RESPIRATORY EMERGENCY', and 'CARDIAC EMERGENCY'. This is normal as this are sicknesses which anyone may face in anytime of the day.\n\nFourth highest calls was made due to 'VEHICLE ACCIDENT' which agains derive to the previous insights we found. i.e. vehicle accidents happens due to rush during the working hours.","209700cc":"To check the time consistency we will seperate the timestamp into four seperate column as 'Hour', 'Day of week', 'Month', and 'Year'. Doing this may also help us in further process throughout our analysis.","133fe088":"### Q. What are the different types of emergency having in the dataset?","d882314c":"Ploting calls made through various hours of the day. Note: 0 represents midnight 12 or 24th hr.","6a262a85":"## 6. Explain Outcome","63177726":"##### Public Vehicle driving speed should be limited by the traffic controlling authority, specially during the working hours, in between 8am to 6pm.\n##### Road should be properly constructed in high traffic cities like Merion and Abington","74e12279":"Since it is not showning any result, may be any leading and tailing whitespace in the sub_category column values. So we will remove those and re run it.","e3971749":"## 1. Defining the problem\n\nThis dataset contains the data of all the calls made for emergency purpose to emergency helpline number 911. It have the type of emergency for which the call was made, the locations from where the call was made and the date and time of the call made.\n\nVarious people are facing several emegencies for several reasons. We can analyze our data to find some solution in order to reduce those emergency.\n\nFor this purpose we can find out the highest type\/kind of emergencies people are facing. Also we can determine the time period in which different emergency occurs. Or maybe it is a particular location that is having the same problems over and over again.\n\n","bda692a6":"#### Renaming Columns name","43a5977e":"Same as above. We can see three common towns 'LOWER MERION', 'UPPER MERION', 'ABINGTON' having highest disabled vehicle calls. This might be because of the bad road conditions or bad traffic.","7974bfaa":"## 2. Asking the questions\n\n* What are the different types of emergency having in the dataset?\n\n* Which categories of emergency has made the highest number of calls?\n\n* In which timeframe (hour, day, month and year) maximum number of calls was made?\n\n* Which categary of maximum emergency call was made in those timeframes?\n\n* At what locations highest types of emergency calls were made?\n\n\n\n** Note: When proceeding through the analysis if any question arises, please note down here. And try to answers those questions.\n\n\n","5387dd36":"#### Correcting column format","50671c45":"## 5. Performing Analysis","e6944a10":"A sudden spike in calls between 7am to 9am. Then again high number of call between 4pm to 7pm.\n\nLets see the subcategory for which large number of calls recorded.","4d807d6c":"We can see that new columns have been created but 'Day of week' column and 'Month' column have number instead of name. So we will convert this number into respective name.\n\nWe will first check the values of 'Day' and 'Month' column and map accordingly.","9d2f9513":"Creating and plotting for the fall victim calls of different locations","a0a4fffe":"The data above shows that almost 65% of the calls of 'Traffic' category was made for 'VEHICLE ACCIDENT'. Another 20% was made for 'DISABLED VEHICLE'.\n\nThis means that during 7am to 9am and 4pm to 7pm highest Vehicle accident occurs.\n\nIts because this are the time period for which people go to work and return back from work. They might be in a hurry to reach office. And also when returning back they might be tired of whole day work and rush to reach home as early as possible.","2f880ca1":"#### Deleting unnecessary columns","80e55e25":"##### This is the clean data we have to perform our further analysis","130a0ed5":"#### Handling null values","c339b074":"##### Ans. We have seen that highest calls were made for EMS\/medical service. Followed by Traffic related calls. And very few calls were made for fire related service.","6efd65c1":"### Q. In which timeframe (hour, day, month and year) maximum number of calls was made?","6d3c147f":"Next we will create dataframes by keeping only those rows having 'DISABLED VEHICLE''"}}