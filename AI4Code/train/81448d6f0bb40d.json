{"cell_type":{"28564f69":"code","fac7fac8":"code","8d97d705":"code","e5d5f0bb":"code","48978469":"code","0928f6bf":"code","623dee68":"code","efc2533d":"code","99b97906":"code","f9bf8c96":"code","54d81058":"markdown","f80440d9":"markdown","290d68e0":"markdown"},"source":{"28564f69":"import itertools\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F","fac7fac8":"perms = list(map(lambda p: \"\".join(p), itertools.permutations(\"1234567\")))\nperm2id = {p: i for i, p in enumerate(perms)}\n\nperms_arr = np.array([list(map(int, p)) for p in perms])\nperms_arr.shape","8d97d705":"perms_onehot = np.eye(7)[perms_arr-1, :].transpose(0, 2, 1)\nassert np.allclose(perms_onehot[:,0,:].astype(np.int64), (perms_arr == 1).astype(np.int64))\n\nprint(\"onehot 1234567:\")\nprint(perms_onehot[perm2id[\"1234567\"]])\n\nprint(\"onehot 5671234:\")\nprint(perms_onehot[perm2id[\"5671234\"]])\n\nprint(\"correlate between 1234567 and 5671234\")\nleft = perms_onehot[perm2id[\"1234567\"]]\nright = perms_onehot[perm2id[\"5671234\"]]\nmatches = F.conv2d(\n    F.pad(torch.Tensor(left[None, None, :, :]), (7, 7)),\n    torch.Tensor(right[None, None, :, :]),\n    padding=\"valid\"\n).numpy().reshape(-1)\nprint(matches)\nmust_match_left2right = np.array([-1, -1, -1, -1, -1, -1, -1, 7, 6, 5, 4, 3, 2, 1, 0])\nmust_match_right2left = np.array([0, 1, 2, 3, 4, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1])\ncost_ifmatch = np.array([7, 6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7])\nprint(\"cost of 1234567 -> 5671234:\", min(cost_ifmatch[np.equal(must_match_left2right, matches)]))\nprint(\"cost of 5671234 -> 1234567:\", min(cost_ifmatch[np.equal(must_match_right2left, matches)]))","e5d5f0bb":"M = F.conv2d(\n    F.pad(torch.Tensor(perms_onehot[:, None, :, :]), (7, 7)),\n    torch.Tensor(perms_onehot[:, None, :, :]),\n    padding=\"valid\"\n).squeeze().numpy()\n\nM.shape","48978469":"must_match_left2right = np.array([-1, -1, -1, -1, -1, -1, -1, 7, 6, 5, 4, 3, 2, 1, 0])\nmust_match_left2right_wild = np.array([-1, -1, -1, -1, -1, -1, -1, 6, 5, 4, 3, 2, 1, 0, 0])\n\ncost_ifmatch = np.array([7, 6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7])\n\ncostMat = np.where(M == must_match_left2right, cost_ifmatch, np.inf).min(axis=-1).astype(np.int8)\ncostMatWild = np.minimum(costMat, np.where(M == must_match_left2right_wild, cost_ifmatch, np.inf).min(axis=-1)).astype(np.int8)","0928f6bf":"symbols = \"\ud83c\udf85\ud83e\udd36\ud83e\udd8c\ud83e\udddd\ud83c\udf84\ud83c\udf81\ud83c\udf80\"\nschedule = pd.read_csv(\"..\/input\/santa-2021-24913\/submission_no_wildcards_2491_2491_2491.csv\").schedule.tolist()\nwords = [s.translate(str.maketrans(symbols, \"1234567\")) for s in schedule]\n\nlist(map(len, words))","623dee68":"\"\"\"\nPermutations Rebalancing (https:\/\/www.kaggle.com\/kostyaatarik\/permutations-rebalancing\/notebook)\n\nThis leads a relaxation of constraints and sometimes you can find a better solution of wildcard positions.\n\"\"\"\n\ndef find_strings_perms(strings, verbose=False):\n    global perms\n    found_perms = []\n    for s in strings:\n        found_perms.append([])\n        for i in range(len(s)-6):\n            p = s[i:i+7]\n            if p in perms:\n                found_perms[-1].append(p)\n    if verbose:\n        lens = [len(_) for _ in  found_perms]\n        print(f'There are {lens} permutations in strings, {sum(lens)} in total.')\n        lens = [len(set(_)) for _ in  found_perms]\n        print(f'There are {lens} unique permutations in strings, {sum(lens)} in total.')\n    return found_perms\n\ndef rebalance_perms(strings_perms, verbose=False):\n    # convert to dicts for fast lookup and to keep permutations order\n    strings_perms = [dict.fromkeys(_) for _ in strings_perms] \n    for p in strings_perms[0].copy():  # iterate over the copy to allow modification during iteration\n        if p[:2] != \"12\" and (p in strings_perms[1] or p in strings_perms[2]):\n            strings_perms[0].pop(p)\n    for p in strings_perms[1].copy():\n        if p[:2] != \"12\" and p in strings_perms[2]:\n            strings_perms[1].pop(p)\n    if verbose:\n        lens = [len(_) for _ in  strings_perms]\n        print(f'There are {lens} permutations left in strings after rebalancing, {sum(lens)} in total.')\n    return [list(_) for _ in strings_perms] \n\nfound_perms = find_strings_perms(words, verbose=True)\nbalanced_perms = rebalance_perms(found_perms, verbose=True)","efc2533d":"nodes_list = []\ntable_list = []\nfor i in range(3):\n    word = words[i]\n    nodes = [perm2id[p] for p in balanced_perms[i]]\n\n    table = np.zeros((len(nodes), 10), np.int64)\n    table[0, :] = 7\n    for i in range(1, len(nodes)):\n        e = costMat[nodes[i-1], nodes[i]]\n        ew = costMatWild[nodes[i-1], nodes[i]]\n        table[i,0] = table[i-1,0] + e\n        table[i,1] = min(table[i-1,1] + e, table[i-1,0] + ew)\n        table[i,2] = min(table[i-1,2], table[i-1,1]) + e # TODO: better transition\n        table[i,3] = min(table[i-1,3], table[i-1,2]) + e\n        table[i,4] = min(table[i-1,4], table[i-1,3]) + e\n        table[i,5] = min(table[i-1,5], table[i-1,4]) + e\n        table[i,6] = min(table[i-1,6], table[i-1,5]) + e\n        table[i,7] = min(table[i-1,7], table[i-1,6]) + e\n        table[i,8] = min(table[i-1,8], table[i-1,7]) + e\n        table[i,9] = min(table[i-1,9] + e, table[i-1,8] + ew)\n    print(table[-1].min(), table[-1])\n    nodes_list.append(nodes)\n    table_list.append(table)\n    \n# backtrack\nnew_words = []\nwilds = []\nfor nodes, table in zip(nodes_list, table_list):\n    ns = [perms[nodes[-1]]]\n    track = np.argmin(table[-1])\n    wild = []\n    for i in range(len(nodes)-2, -1, -1):\n        e = costMat[nodes[i], nodes[i+1]]\n        ew = costMatWild[nodes[i], nodes[i+1]]\n        if track == 0:\n            ns.append(perms[nodes[i]][:e])\n        elif track == 1:\n            if table[i, 1] + e < table[i, 0] + ew:\n                ns.append(perms[nodes[i]][:e])\n            else:\n                left = np.array(list(map(int, perms[nodes[i]][ew:])))\n                right = np.array(list(map(int, perms[nodes[i+1]][:-ew])))\n                mis = np.where(left != right)[0][0]\n                wild.append(table[i, track-1]-7+ew+mis)\n                ns.append(perms[nodes[i]][:ew])\n                track = track - 1\n        elif 2 <= track <= 8:\n            if table[i, track] >= table[i, track-1]:\n                track = track - 1\n            ns.append(perms[nodes[i]][:e])\n        elif track == 9:\n            if table[i, 9] + e < table[i, 8] + ew:\n                ns.append(perms[nodes[i]][:e])\n            else:\n                ns.append(perms[nodes[i]][:ew])\n                left = np.array(list(map(int, perms[nodes[i]][ew:])))\n                right = np.array(list(map(int, perms[nodes[i+1]][:-ew])))\n                mis = np.where(left != right)[0][0]\n                wild.append(table[i, track-1]-7+ew+mis)\n                track = track - 1\n        else:\n            assert False\n    assert track == 0\n    wilds.append(wild)\n    nsw = list(\"\".join(ns[::-1]))\n    for w in wild:\n        nsw[w] = \"*\"\n    new_words.append(\"\".join(nsw))","99b97906":"print(\"score: \", max(map(len, words)), \"->\", max(map(len, new_words)))","f9bf8c96":"submission = pd.Series([a.translate(str.maketrans(\"1234567*\", symbols+\"\ud83c\udf1f\")) for a in new_words], name='schedule')\nsubmission.to_csv('submission.csv', index=False)","54d81058":"This is NOT an original Notebook\nLeverages the learning from many other notebooks:\n\n1) [Santa 2021 TSP Baseline - [2500] by CHRIS DEOTTE](https:\/\/www.kaggle.com\/cdeotte\/santa-2021-tsp-baseline-2500)\n\n\n2) [Permutations Rebalancing by  KOSTYA ATARIK ](https:\/\/www.kaggle.com\/kostyaatarik\/permutations-rebalancing)\n\n\n3) [Wildcard Postprocessing Using Dynamic Programming by  YOSSHI999 ](https:\/\/www.kaggle.com\/yosshi999\/wildcard-postprocessing-using-dynamic-programming)\n\nI tried the notebooks by Chris and got a slightly better result of 2506 (vs pblic score of 2507) \nAs Chris highlights \"Yes, it may even get 2505 without changes. The TSP solver uses randomization, so every time we run this notebook the solution is slightly different.\"\n\nThen I used it on Kostya's permutation renbalancing and got a score of 2496 without wildcards. With wildcards I got 2492, slightly better than public score of 2493\n\nI used the without wild cards solution with the YOSSHI999's Wildcard Postprocessing to get 2490 \n\n","f80440d9":"## Create Cost matrix","290d68e0":"## Optim"}}