{"cell_type":{"c8b73ef6":"code","8b72b10d":"code","b53feca9":"code","2b02abfc":"code","6de4433a":"code","48e3da5a":"code","cf36d7ce":"code","5cba3d0c":"code","ed606531":"code","41a2e733":"code","212d3162":"code","6d56d5bf":"code","92c8a4ec":"code","95c3f2e5":"code","bc5a2afc":"code","fa67eb6a":"code","9f8c37c5":"code","27cb1cf7":"code","dbb27a65":"code","52ca7a71":"code","ee46eb91":"code","8a650b23":"code","1caad735":"code","e511a676":"code","04333b19":"code","0e9a108f":"markdown","c27e73c5":"markdown","73e20496":"markdown","f39b3e04":"markdown","eb6e53d8":"markdown","5f27e76b":"markdown","81841151":"markdown","8a9b6df6":"markdown","0ac47651":"markdown","9d203bd2":"markdown"},"source":{"c8b73ef6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom scipy import stats\nfrom scipy.stats import spearmanr\nfrom scipy.stats import kendalltau\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (15,8)","8b72b10d":"excel_file = pd.ExcelFile('\/kaggle\/input\/covid19\/dataset.xlsx')\ndfs = {sheet_name: excel_file.parse(sheet_name) \n          for sheet_name in excel_file.sheet_names}\n\ndf_covid = dfs['All']\n\ndf_covid.head()","b53feca9":"print('Proportion between results:\\n',(df_covid['SARS-Cov-2 exam result'].value_counts()\/len(df_covid.index))*100)","2b02abfc":"print('Remove columns having more than 76.045358% of missing data')\npd.set_option('display.max_columns', 500)\ntotal_cases = len(df_covid.index)\ndic_nan = {}\nfor item in df_covid.columns:\n    dic_nan[item] = (df_covid[item].isnull().values.sum()\/total_cases)*100\ndf_nan = pd.DataFrame.from_dict(dic_nan, orient='index')\n\ndf_nan.sort_values(by=0).tail(88).T","6de4433a":"# - Drop columns\ndf_covid_filtered = df_covid[['Patient ID','Patient age quantile','SARS-Cov-2 exam result','Influenza B','Respiratory Syncytial Virus','Influenza A','Rhinovirus\/Enterovirus','Inf A H1N1 2009','CoronavirusOC43','Coronavirus229E','Parainfluenza 4','Adenovirus','Chlamydophila pneumoniae','Parainfluenza 3','Coronavirus HKU1','CoronavirusNL63','Parainfluenza 1','Bordetella pertussis','Parainfluenza 2','Metapneumovirus']]\n\nprint('Drop rows that still have missing data')\ndf_covid_filtered.dropna(inplace=True)\n\nprint('New ratio of results:\\n',(df_covid_filtered['SARS-Cov-2 exam result'].value_counts()\/len(df_covid_filtered.index))*100)\n\n# - Map integers for the model\ndic_map = {'not_detected': 0, 'detected': 1}\nfor item in df_covid_filtered.columns:\n    try:\n         df_covid_filtered = df_covid_filtered.replace({item: dic_map})\n    except:\n        pass\n    \ndic_map = {'negative': 0, 'positive': 1}\ndf_covid_filtered = df_covid_filtered.replace({'SARS-Cov-2 exam result': dic_map})\n\ndf_covid_filtered.set_index('Patient ID',inplace=True)\n\nfor item in df_covid_filtered.columns:\n    df_covid_filtered[item] = df_covid_filtered[item].astype(int)","48e3da5a":"df_covid_filtered.head()","cf36d7ce":"df_covid_filtered.info()","5cba3d0c":"print('Remove imbalanced features:\\n')\ntotal_cases_filtered = len(df_covid_filtered.index)\nfor item in df_covid_filtered.columns:\n    if item == 'Patient ID':\n        pass\n    else:\n        print(item,':')\n        print(((df_covid_filtered[item].value_counts())\/total_cases_filtered)*100)\n        print('\\n')","ed606531":"df_covid_filtered.drop(['Parainfluenza 2','Metapneumovirus','Bordetella pertussis','Parainfluenza 1','Coronavirus HKU1','Chlamydophila pneumoniae','Adenovirus','Parainfluenza 4','Coronavirus229E','CoronavirusOC43','Influenza A'],axis=1,inplace=True)","41a2e733":"df_covid_filtered.head()","212d3162":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import RepeatedKFold\nimport numpy as np\n\nX = df_covid_filtered.drop('SARS-Cov-2 exam result',axis=1)\nY = df_covid_filtered[['SARS-Cov-2 exam result']]","6d56d5bf":"seed = 7\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)","92c8a4ec":"model = XGBClassifier()\nmodel.fit(X_train, y_train.values.ravel())\n\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","95c3f2e5":"y_pred_completo = model.predict(X)\npred = [round(value) for value in y_pred_completo]\n\ny_test_completo = Y.values.ravel()\n\npos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\nfor x in range(len(pred)):\n    if pred[x] == y_test_completo[x]:\n        if y_test_completo[x] == 1:\n            pos_correct += 1\n        else:\n            neg_correct += 1\n       \n    if y_test_completo[x] == 1:\n        pos_cnt += 1\n    else:\n        neg_cnt += 1\n        \naccuracy = accuracy_score(Y, pred)  \nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(\"pos_acc\", pos_correct\/pos_cnt*100, \"%\", '\\tAcertos:', pos_correct, ' de ', pos_cnt)\nprint(\"neg_acc\", neg_correct\/neg_cnt*100, \"%\", '\\tAcertos:', neg_correct, ' de ', neg_cnt)","bc5a2afc":"ratio = y_train['SARS-Cov-2 exam result'].value_counts()[0]\/y_train['SARS-Cov-2 exam result'].value_counts()[1]\nclass_weights = {0:1, 1:ratio}\nw_array = np.ones(y_train.shape[0], dtype = 'float')\n\noutput = y_train.values.ravel()\n\n\nfor i in range(len(output)):\n    w_array[i] = class_weights[output[i]]\n    \nmodel = XGBClassifier()\nmodel.fit(X_train, y_train.values.ravel(), sample_weight=w_array)","fa67eb6a":"y_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","9f8c37c5":"plt.rcParams[\"figure.figsize\"] = (7,7)\nplot_confusion_matrix(model, X_test, y_test.values.ravel(), cmap = plt.cm.Blues, values_format = '.10g', display_labels = ['negative', 'positive'])","27cb1cf7":"plt.rcParams[\"figure.figsize\"] = (7,7)\nplot_confusion_matrix(model, X, Y.values.ravel(), cmap = plt.cm.Blues, values_format = '.10g', display_labels = ['negative', 'positive'])","dbb27a65":"# grid search positive class weights with xgboost for imbalance classification\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom xgboost import XGBClassifier\n\n\n# define model\nmodel = XGBClassifier()\n# define grid\nweights = list(range(1,12))\nparam_grid = dict(scale_pos_weight=weights)\n# define evaluation procedure\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid search\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n# execute the grid search\ngrid_result = grid.fit(X_train, y_train.values.ravel())\n\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","52ca7a71":"y_pred_completo = grid.predict(X_test)\npred = [round(value) for value in y_pred_completo]\n\ny_test_completo = y_test.values.ravel()\n\npos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\nfor x in range(len(pred)):\n  if pred[x] == y_test_completo[x]:\n    if y_test_completo[x] == 1:\n      pos_correct += 1\n    else:\n      neg_correct += 1\n       \n  if y_test_completo[x] == 1:\n    pos_cnt += 1\n  else:\n    neg_cnt += 1\n\naccuracy = accuracy_score(y_test, pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(\"pos_acc\", pos_correct\/pos_cnt*100, \"%\", '\\tAcertos:', pos_correct, ' de ', pos_cnt)\nprint(\"neg_acc\", neg_correct\/neg_cnt*100, \"%\", '\\tAcertos:', neg_correct, ' de ', neg_cnt)","ee46eb91":"y_pred_completo = grid.predict(X)\npred = [round(value) for value in y_pred_completo]\n\ny_test_completo = Y.values.ravel()\n\npos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\nfor x in range(len(pred)):\n  if pred[x] == y_test_completo[x]:\n    if y_test_completo[x] == 1:\n      pos_correct += 1\n    else:\n      neg_correct += 1\n       \n  if y_test_completo[x] == 1:\n    pos_cnt += 1\n  else:\n    neg_cnt += 1\n\naccuracy = accuracy_score(Y, pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(\"pos_acc\", pos_correct\/pos_cnt*100, \"%\", '\\tAcertos:', pos_correct, ' de ', pos_cnt)\nprint(\"neg_acc\", neg_correct\/neg_cnt*100, \"%\", '\\tAcertos:', neg_correct, ' de ', neg_cnt)","8a650b23":"plot_confusion_matrix(grid, X, Y.values.ravel(), cmap = plt.cm.Blues, values_format = '.10g', display_labels = ['negative', 'positive'])","1caad735":"# grid search positive class weights with xgboost for imbalance classification\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom xgboost import XGBClassifier\n\n\n# define model\nmodel = XGBClassifier()\n# define grid\nweights = list(range(1,12))\nparam_grid = dict(scale_pos_weight=weights)\n# define evaluation procedure\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid search\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n# execute the grid search\ngrid_result = grid.fit(X, Y.values.ravel())\n\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","e511a676":"y_pred_completo = grid.predict(X)\npred = [round(value) for value in y_pred_completo]\n\ny_test_completo = Y.values.ravel()\n\npos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\nfor x in range(len(pred)):\n  if pred[x] == y_test_completo[x]:\n    if y_test_completo[x] == 1:\n      pos_correct += 1\n    else:\n      neg_correct += 1\n       \n  if y_test_completo[x] == 1:\n    pos_cnt += 1\n  else:\n    neg_cnt += 1\n\naccuracy = accuracy_score(Y, pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(\"pos_acc\", pos_correct\/pos_cnt*100, \"%\", '\\tAcertos:', pos_correct, ' de ', pos_cnt)\nprint(\"neg_acc\", neg_correct\/neg_cnt*100, \"%\", '\\tAcertos:', neg_correct, ' de ', neg_cnt)","04333b19":"plot_confusion_matrix(grid, X, Y.values.ravel(), cmap = plt.cm.Blues, values_format = '.10g', display_labels = ['negative', 'positive'])","0e9a108f":"# Dealing with Imbalanced Data","c27e73c5":"#### Predicting the whole data set","73e20496":"#### Test set Confusion matrix","f39b3e04":"#### **Training on the whole dataset**","eb6e53d8":"# Adding weight because of the imbalanced ratio of positive and negative cases\n\nLooking at the result seen above, we can see that the predicted instances were all predicted to be on the majority class(negative) due to the dataset being imbalanced. In order to address that point, we trained the model again, this time using weights for each class respecting the proportion on which they appear","5f27e76b":"# Model","81841151":"## Grid Search\n\nWe used a GridSearch using weights for the minority class(positive) ranging from 1 to 11 to see the behaviour of the model","8a9b6df6":"#### Predicting test set","0ac47651":"#### Separating train and test sets","9d203bd2":"#### Dataset Confusion Matrix"}}