{"cell_type":{"1eee74a5":"code","552685a6":"code","7d689d2b":"code","5ac1c69b":"code","62d55383":"code","5fcce168":"code","ea4ba77f":"code","58c26c33":"code","c90a87a8":"code","d58401bb":"code","830b7dab":"code","81f706d5":"code","b56d2741":"code","ca827419":"code","95f6020e":"code","cf32b3b2":"code","7fe8379d":"code","09011f1f":"code","16be31c6":"code","1a3d46e3":"code","038b8828":"code","aff7e209":"code","eaf78ca9":"code","00778606":"code","54aa45d1":"code","a8943582":"code","1830e1a9":"code","b2d8b738":"code","1bb398ac":"code","7bbc9d35":"code","c38f9eaa":"code","d86a16bf":"markdown","22246a15":"markdown","eb989da4":"markdown","d2678918":"markdown","84cb98c7":"markdown","66c52146":"markdown","1bd28777":"markdown","87d8d2cd":"markdown","613a9559":"markdown","933a3a36":"markdown","d90916b9":"markdown","23b3c309":"markdown","10176567":"markdown","1a5fa694":"markdown","31d52f5e":"markdown","9edf7bab":"markdown","489137f5":"markdown","4f49df8b":"markdown","25f20bfa":"markdown","83de898c":"markdown","4557f6da":"markdown","035970a5":"markdown","c216d4fd":"markdown","fc9d1af1":"markdown"},"source":{"1eee74a5":"import os\nimport tempfile\nfrom dipy.segment.mask import median_otsu\nfrom dipy.core.gradients import gradient_table\nfrom dipy.reconst.shm import CsaOdfModel\nfrom dipy.direction import peaks_from_model\nfrom dipy.direction import ProbabilisticDirectionGetter\nfrom dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel\nfrom dipy.direction import peaks_from_model\nfrom dipy.tracking.local import LocalTracking, ThresholdTissueClassifier\nfrom dipy.tracking import utils\nfrom dipy.reconst import peaks, shm\nfrom dipy.viz import window, actor\nfrom dipy.viz.colormap import line_colors\nfrom dipy.tracking.streamline import Streamlines\nfrom dipy.tracking.eudx import EuDX\nfrom nilearn.plotting import plot_anat, plot_roi, plot_stat_map\nfrom nilearn.image import index_img, iter_img, new_img_like, math_img\nfrom IPython.display import Image\nfrom xvfbwrapper import Xvfb\nimport nibabel as nb\nimport pylab as plt\nimport numpy as np","552685a6":"# helper function for plotting woth dipy and VTK on a headless system\ndef show_image(actor, size=(1000,1000)):\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        temp_filename = os.path.join(tmp_dir, 'tmp.png')\n        with Xvfb() as xvfb:\n            ren = window.Renderer()\n            ren.add(actor)\n            window.record(ren, n_frames=1, out_path=temp_filename, size=size)\n            window.clear(ren)\n        return Image(filename=temp_filename) ","7d689d2b":"img = nb.load('..\/input\/hardi150.nii\/HARDI150.nii')\ndata = img.get_data()\ndata.shape","5ac1c69b":"gtab = gradient_table('..\/input\/HARDI150.bval', '..\/input\/HARDI150.bvec')\n(gtab.bvals == 0).sum()","62d55383":"gtab.bvecs.shape","5fcce168":"show_image(actor.point(gtab.gradients, window.colors.blue, point_radius=100))","ea4ba77f":"i = 0\ncur_img = index_img(img, i)\nplot_anat(cur_img, cut_coords=(0,0,2), draw_cross=False, figure=plt.figure(figsize=(18,4)), cmap='magma', \n              vmin=0, vmax=1600, title=\"bval = %g, bvec=%s\"%(gtab.bvals[i], str(np.round(gtab.bvecs[i,:],2))))\n\ni = 38\ncur_img = index_img(img, i)\nplot_anat(cur_img, cut_coords=(0,0,2), draw_cross=False, figure=plt.figure(figsize=(18,4)), cmap='magma', \n              vmin=0, vmax=400, title=\"bval = %g, bvec=%s\"%(gtab.bvals[i], str(np.round(gtab.bvecs[i,:],2))))\n\ni = 70\ncur_img = index_img(img, i)\nplot_anat(cur_img, cut_coords=(0,0,2), draw_cross=False, figure=plt.figure(figsize=(18,4)), cmap='magma', \n              vmin=0, vmax=400, title=\"bval = %g, bvec=%s\"%(gtab.bvals[i], str(np.round(gtab.bvecs[i,:],2))))","58c26c33":"csa_model = CsaOdfModel(gtab, sh_order=8)","c90a87a8":"data_small = data[30:50, 65:85, 38:39]\ncsa_fit_small = csa_model.fit(data_small)","d58401bb":"csa_odf_small = csa_fit_small.odf(peaks.default_sphere)","830b7dab":"fodf_spheres_small = actor.odf_slicer(csa_odf_small, sphere=peaks.default_sphere, scale=0.9, norm=False, colormap='plasma')\nshow_image(fodf_spheres_small)","81f706d5":"csd_peaks_small = peaks_from_model(model=csa_model,\n                                   data=data_small,\n                                   sphere=peaks.default_sphere,\n                                   relative_peak_threshold=.5,\n                                   min_separation_angle=25,\n                                   parallel=True)\n\nfodf_peaks_small = actor.peak_slicer(csd_peaks_small.peak_dirs, csd_peaks_small.peak_values)\nshow_image(fodf_peaks_small)","b56d2741":"labels_img = nb.load(\"..\/input\/aparc-reduced.nii\/aparc-reduced.nii\")\nplot_roi(math_img(\"(labels == 1) | (labels == 2)\", labels=labels_img), index_img(img, 0),figure=plt.figure(figsize=(18,4)),)","ca827419":"labels = labels_img.get_data()\nwhite_matter = (labels == 1) | (labels == 2)\ncsa_model = shm.CsaOdfModel(gtab, 6)\ncsa_fit = csa_model.fit(data)\ncsa_peaks = peaks.peaks_from_model(model=csa_model,\n                                   data=data,\n                                   sphere=peaks.default_sphere,\n                                   relative_peak_threshold=.8,\n                                   min_separation_angle=45,\n                                   mask=white_matter)","95f6020e":"gfa_img = nb.Nifti1Image(csa_peaks.gfa, img.affine)\nplot_stat_map(gfa_img, index_img(img,0),figure=plt.figure(figsize=(18,4)))","cf32b3b2":"classifier = ThresholdTissueClassifier(csa_peaks.gfa, .25)","7fe8379d":"plot_roi(math_img(\"x == 2\", x=labels_img), index_img(img, 0), figure=plt.figure(figsize=(18,4)))","09011f1f":"seed_mask = labels == 2\nseeds = utils.seeds_from_mask(seed_mask, density=[2, 2, 2], affine=img.affine)","16be31c6":"# Initialization of LocalTracking. The computation happens in the next step.\nstreamlines_generator = LocalTracking(csa_peaks, classifier, seeds, img.affine, step_size=.5)\n\n# Generate streamlines object\nstreamlines = Streamlines(streamlines_generator)\n\ncolor = line_colors(streamlines)\nstreamlines_actor = actor.line(streamlines, line_colors(streamlines))\nshow_image(streamlines_actor)","1a3d46e3":"prob_dg = ProbabilisticDirectionGetter.from_shcoeff(csa_fit.shm_coeff,\n                                                    max_angle=30.,\n                                                    sphere=peaks.default_sphere)\n\nstreamlines_generator = LocalTracking(prob_dg, classifier, seeds, img.affine,\n                                      step_size=.5, max_cross=1)\n\n# Generate streamlines object.\nstreamlines = Streamlines(streamlines_generator)\nstreamlines_actor = actor.line(streamlines, line_colors(streamlines))\nshow_image(streamlines_actor)","038b8828":"seeds = utils.seeds_from_mask(white_matter, density=2)\nstreamline_generator = EuDX(csa_peaks.peak_values, csa_peaks.peak_indices,\n                            odf_vertices=peaks.default_sphere.vertices,\n                            a_low=.05, step_sz=.5, seeds=seeds)\naffine = streamline_generator.affine\n\nstreamlines = Streamlines(streamline_generator, buffer_size=512)\n\nshow_image(actor.line(streamlines, line_colors(streamlines)))","aff7e209":"len(streamlines)","eaf78ca9":"cc_slice = labels == 2\ncc_streamlines = utils.target(streamlines, cc_slice, affine=affine)\ncc_streamlines = Streamlines(cc_streamlines)\n\nother_streamlines = utils.target(streamlines, cc_slice, affine=affine,\n                                 include=False)\nother_streamlines = Streamlines(other_streamlines)\nassert len(other_streamlines) + len(cc_streamlines) == len(streamlines)","00778606":"len(cc_streamlines)","54aa45d1":"plot_roi(labels_img, index_img(img, 0), figure=plt.figure(figsize=(18,4)))","a8943582":"np.unique(np.array(labels))","1830e1a9":"plot_roi(math_img(\"x == 0\", x=labels_img), index_img(img, 0), figure=plt.figure(figsize=(18,4)))","b2d8b738":"plot_roi(math_img(\"x == 1\", x=labels_img), index_img(img, 0), figure=plt.figure(figsize=(18,4)))","1bb398ac":"M, grouping = utils.connectivity_matrix(cc_streamlines, labels, affine=affine,\n                                        return_mapping=True,\n                                        mapping_as_streamlines=True)\nM[:3, :] = 0\nM[:, :3] = 0\nplt.imshow(np.log1p(M), interpolation='nearest')","7bbc9d35":"np.argmax(M)\nfrom numpy import unravel_index\nnew_M = M.copy()\n#new_M[11,54] = 0\n#new_M[54,11] = 0\nunravel_index(new_M.argmax(), new_M.shape)","c38f9eaa":"from nilearn.plotting import plot_stat_map\nsource_region = 32\ntarget_region = 75\nlr_superiorfrontal_track = grouping[source_region, target_region]\nshape = labels.shape\ndm = utils.density_map(lr_superiorfrontal_track, shape, affine=affine)\ndm_img = nb.Nifti1Image(dm.astype(\"int16\"), img.affine)\npl = plot_stat_map(dm_img, index_img(img,0), figure=plt.figure(figsize=(18,4)))\npl.add_contours(math_img(\"x == %d\"%source_region, x=labels_img))\npl.add_contours(math_img(\"x == %d\"%target_region, x=labels_img))","d86a16bf":"# Fitting a model of diffusion signal","22246a15":"The file is four dimensional. The fourth dimension corresponds to the different diffusion orientation probed during the scan. In addition to the NIfTI file we will need two more files - one with diffusion weights and one with orientations.","eb989da4":"**Excercise: create density maps for other tracks**","d2678918":"## Probabilistic tracking","84cb98c7":"**Excercise: change the `sh_order` parameter**","66c52146":"## Fitting model in the whole brain","1bd28777":"# Reconstructing white matter tracks ","87d8d2cd":"Lets have a look at the data and plot the first volume.","613a9559":"# Connectivity analysis","933a3a36":"## Ploting orientation probability distributions","d90916b9":"## Ploting principal orientations","23b3c309":"## Bundle density map","10176567":"As you can see the diffusion unweighted volume (also called `b0` since the `b` value is zero) is brighter than diffusion weighted volumes. The other volumes have properties that depend on the diffusion orientation.\n\n**Excercise: plot other diffusion weighted and unweighted volumes.**","1a5fa694":"## Picking the seed","31d52f5e":"What is the strongest connection?","9edf7bab":"## Connectivity matrix","489137f5":"Looking for more data to play with? Check out https:\/\/www.kaggle.com\/openneuro\/ds001378","4f49df8b":"This tutorial has been adopted from materials available at http:\/\/nipy.org\/dipy\/examples_index.html\n# Exploring the data\nLets start by exploring the diffusion weighted data. We will start by loading the NIfTI file.","25f20bfa":"## Filtering streamlines","83de898c":"As you can see the first 10 volumes are not diffusion weighted and the rest are probing diffusion at different orientations described in the `bvecs` file.","4557f6da":"**Excercise: repeat both types of tracking - are the results the same each time?**","035970a5":"## Deterministic tracking","c216d4fd":"## Whole brain white matter tracking","fc9d1af1":"**Excercise: estimate connectivity matrix for all streamlines (not just those going through CC)**"}}