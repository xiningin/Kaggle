{"cell_type":{"1b47b32d":"code","4bca0c26":"code","76f0eff3":"code","dd9fc2a2":"code","17294dcf":"code","9e6ead60":"code","47c99575":"code","d561c48c":"code","f36ac105":"code","ce4e54ff":"code","317a3eef":"code","356e821d":"code","2daa5e8a":"code","085f63a3":"code","4f2e5e72":"code","7d2064ab":"code","e93dd300":"code","177698a2":"code","4b0b8e79":"code","4399d96d":"code","3a0d259b":"code","eaa76607":"code","693a1d1c":"code","a5d514d7":"code","70081ab1":"code","03274a7a":"code","4ba0d008":"code","21197c62":"code","5ce63571":"code","8513aa90":"code","862f5622":"code","1e296c40":"code","39c9c0ac":"code","ebdb8c7e":"code","7656b29c":"code","c1008a74":"code","c62baf01":"code","b467b0fe":"code","8c9f02f5":"code","24b77854":"code","b79c0d09":"code","ae4c19ee":"code","513bcd1c":"markdown"},"source":{"1b47b32d":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd","4bca0c26":"df = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","76f0eff3":"df.sample(2)","dd9fc2a2":"# Dropping CustomerID which is less important to predict 'Customer Churn'","17294dcf":"df.drop('customerID',axis=1,inplace=True)","9e6ead60":"df.TotalCharges.values","47c99575":"df.MonthlyCharges.values","d561c48c":"# As we can see TotalCharges is in objedt dtype , So converting it into Int dtype\n\npd.to_numeric(df.TotalCharges,errors='coerce')","f36ac105":"pd.to_numeric(df.TotalCharges,errors='coerce').isnull()","ce4e54ff":"df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]","317a3eef":"# Checking random value\ndf.iloc[488]['TotalCharges']","356e821d":"df1 = df[df.TotalCharges!=' ']\ndf1.shape","2daa5e8a":"df1.dtypes","085f63a3":"# it still does not change,so\ndf1.TotalCharges = pd.to_numeric(df1.TotalCharges)\ndf1.TotalCharges.dtypes","4f2e5e72":"# Making base for plottng Churn Rate\ndf1[df1.Churn=='No'].tenure","7d2064ab":"tenure_churn_no = df1[df1.Churn=='No'].tenure\ntenure_churn_yes = df1[df1.Churn=='Yes'].tenure\n\nplt.hist([tenure_churn_yes, tenure_churn_no], color=['orange','yellow'], label=['Churn=yes','Churn=No'])\nplt.legend()","e93dd300":"mc_churn_no = df1[df1.Churn=='No'].MonthlyCharges\nmc_churn_yes = df1[df1.Churn=='Yes'].MonthlyCharges\n\nplt.xlabel('Monthly Charges')\nplt.ylabel('Number of Customers')\nplt.title('Customer Churn Prediction Visualization')\n\nblood_sugar_men = [113,85,90,150,149,88,93,115,135,80,77,82,129]\nblood_sugar_woman = [67,98,89,120,133,150,84,69,89,79,120,112,100]\n\nplt.hist([mc_churn_yes, mc_churn_no], rwidth=0.95, color=['red','blue'], label=['Churn=yes','Churn=No'])\nplt.legend()","177698a2":"# Finding unique value in each column with column name\nfor column in df:\n    print(f'{column}: {df[column].unique()}')","4b0b8e79":"# Finding dtype=object\n","4399d96d":"def print_unique_col_values(df):\n    for column in df:\n        if df[column].dtypes=='object':\n            print(f'{column}:{df[column].unique()}')\n            \nprint_unique_col_values(df1)            ","3a0d259b":"# to replace 'No internet service','No phone service' with no\ndf1.replace('No phone service','No',inplace=True)\ndf1.replace('No internet service','No',inplace=True)","eaa76607":"print_unique_col_values(df1)","693a1d1c":"# Replacing all columns with yes or no with 0 or 1\nyes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n                   'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\n\nfor col in yes_no_columns:\n    df1[col].replace({\"Yes\":1,\"No\":0}, inplace=True)","a5d514d7":"# ignore we got \nfor col in df1:\n    print(f'{col}: {df1[col].unique()}')","70081ab1":"df1['gender'].replace({'Female':1,'Male':0}, inplace=True)","03274a7a":"# Applying  one hot encoding for categorical columns\ndf2 = pd.get_dummies(data=df1, columns=['InternetService','PaymentMethod','Contract'])\ndf2.columns","4ba0d008":"# to scale columns which are not in range  0 to 1\n\ncol_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\ndf2[col_to_scale] = scaler.fit_transform(df2[col_to_scale])\n\ndf2.sample(2)","21197c62":"# Now finally checking model for is it prepare for to train the model\nfor col in df2:\n    print(f'{col}:{df2[col].unique()}')","5ce63571":"# Yeah, it is ready,Hurray!","8513aa90":"# Now making model reday for training\nX = df2.drop('Churn',axis='columns')\ny = df2['Churn']","862f5622":"from sklearn.model_selection import train_test_split\nX_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)\nX_train.shape,X_test.shape","1e296c40":"len(X_train.columns)","39c9c0ac":"model = keras.Sequential([\n    keras.layers.Dense(26, input_shape=(26,), activation='relu'),\n    keras.layers.Dense(20,  activation='relu'),\n    keras.layers.Dense(15,  activation='relu'),\n    keras.layers.Dense(1,  activation='sigmoid'),\n])\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy']\n)\n\nmodel.fit(X_train,y_train, epochs=59)","ebdb8c7e":"# After doing 59 epoch ,we are getting 83% accuracy which is quite good looking random variables are taken ","7656b29c":"model.evaluate(X_test, y_test)","c1008a74":"yp = model.predict(X_test)\nyp[:5]","c62baf01":"y_test[:5]","b467b0fe":"# Making more readable \ny_pred = []\nfor element in yp:\n    if element > 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","8c9f02f5":"y_pred[:10]","24b77854":"y_test[:10]","b79c0d09":"# classification report\nfrom sklearn.metrics import confusion_matrix , classification_report\n\nprint(classification_report(y_test,y_pred))","ae4c19ee":"# Building Confusion Matrix\nimport seaborn as sns\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm,annot=True, fmt='d')\nplt.xlabel('predicted')\nplt.ylabel('truth')","513bcd1c":"df.dtypes"}}