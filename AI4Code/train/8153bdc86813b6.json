{"cell_type":{"24823f40":"code","573cdf30":"code","3a4aeb0a":"code","2645859b":"code","8cedd7b6":"code","0292067b":"code","ed202ed6":"code","488d20b9":"code","75d91a8a":"code","8693b04b":"code","39d52262":"code","e7e3c98d":"code","87c8d745":"code","1a4c2a79":"code","de6a5923":"code","456e9758":"code","2734b36c":"code","d9c24acd":"code","40d0f324":"code","9f5ea93f":"code","e26e3824":"code","c14ce28f":"code","354bcc04":"code","d62b2cab":"code","3435bad9":"code","d84813db":"code","65faa68f":"code","f912eb54":"code","f07dd0bf":"code","6008c719":"code","de031994":"code","93b96f13":"code","a851954f":"code","d93a932a":"code","ea1f0742":"code","67d4326a":"code","94388648":"code","1a4be1e2":"code","ca96d946":"code","1b11e816":"code","a8efd66a":"code","fac326c0":"code","ba01f64f":"code","53dfb8fb":"code","128614ec":"code","a501872a":"markdown","1cc0e2f7":"markdown","ff669417":"markdown","60f8339e":"markdown","b41e29b9":"markdown","546e674b":"markdown","41231b28":"markdown","92c9a25c":"markdown","602c4718":"markdown","fe38e6b6":"markdown","bc14e391":"markdown","a16b064d":"markdown","896b271e":"markdown","cb5f3f5c":"markdown","1474136a":"markdown","51bcfdc5":"markdown","60b01411":"markdown","f3899ed2":"markdown","defd415d":"markdown","ba692942":"markdown","1deba610":"markdown","567372fa":"markdown","d1958b70":"markdown","b95a5d62":"markdown","1eb2985d":"markdown","a2c181a5":"markdown","cbcc25ef":"markdown","de11e39d":"markdown","b2a05470":"markdown","e6edbb82":"markdown","1167ff7a":"markdown","ea9d4cb1":"markdown","5b98a911":"markdown","94fce71a":"markdown","de006d24":"markdown","b64e7c60":"markdown","763bf790":"markdown","a7f7fffe":"markdown","5825796f":"markdown"},"source":{"24823f40":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\n# import SVC classifier\nfrom sklearn.svm import SVC\n\n# import metrics to compute accuracy (Evulate)\nfrom sklearn.metrics import accuracy_score, confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","573cdf30":"df_train = pd.read_csv(\"..\/input\/human-activity-recognition-with-smartphones\/train.csv\")","3a4aeb0a":"df_train.head()","2645859b":"df_train.tail()","8cedd7b6":"df_train.shape","0292067b":"df_train.isnull().values.any()","ed202ed6":"df_train[\"Activity\"].unique()","488d20b9":"pd.crosstab(index = df_train[\"Activity\"],columns=\"count\")","75d91a8a":"plt.figure(figsize=(10,5))\nax = sns.countplot(x=\"Activity\", data=df_train)\nplt.xticks(x = df_train['Activity'],  rotation='vertical')\nplt.show()","8693b04b":"df_train[\"subject\"].unique()","39d52262":"X = pd.DataFrame(df_train.drop(['Activity','subject'],axis=1))\nY = df_train.Activity.values.astype(object)\n\nX.shape, Y.shape","e7e3c98d":"X.head()","87c8d745":"Y[1]","1a4c2a79":"X.info()","de6a5923":"#Total Number of Continous and Categorical features in the training set\nnum_cols = X._get_numeric_data().columns\nprint(\"Number of numeric features:\",num_cols.size)","456e9758":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()","2734b36c":"# encoding train labels \nencoder.fit(Y)\ny = encoder.transform(Y)\ny.shape","d9c24acd":"y[1]","40d0f324":"encoder.classes_","9f5ea93f":"encoder.classes_[2]","e26e3824":"# Scaling the feature \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","c14ce28f":"X = scaler.fit_transform(X)\nX[1]","354bcc04":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 99)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","d62b2cab":"# instantiate classifier with default hyperparameters\nsvc = SVC() ","3435bad9":"# fit classifier to training set\nsvc.fit(X_train,y_train)","d84813db":"# make predictions on test set\ny_pred = svc.predict(X_valid)","65faa68f":"# compute and print accuracy score\nprint('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","f912eb54":"# instantiate classifier with rbf kernel and C=100\nsvc = SVC(C=100.0) \n\n\n# fit classifier to training set\nsvc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred = svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","f07dd0bf":"# instantiate classifier with rbf kernel and C=1000\nsvc=SVC(C=1000.0) \n\n\n# fit classifier to training set\nsvc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","6008c719":"# instantiate classifier with linear kernel and C=1.0\nlinear_svc=SVC(kernel='linear', C=1.0) \n\n\n# fit classifier to training set\nlinear_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred_test=linear_svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred_test)))","de031994":"# instantiate classifier with linear kernel and C=100.0\nlinear_svc100=SVC(kernel='linear', C=100.0) \n\n\n# fit classifier to training set\nlinear_svc100.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=linear_svc100.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","93b96f13":"# instantiate classifier with linear kernel and C=1000.0\nlinear_svc1000=SVC(kernel='linear', C=1000.0) \n\n\n# fit classifier to training set\nlinear_svc1000.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=linear_svc1000.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","a851954f":"y_pred_train = linear_svc.predict(X_train)\n\ny_pred_train","d93a932a":"print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","ea1f0742":"print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n\nprint('Validation set score: {:.4f}'.format(linear_svc.score(X_valid, y_valid)))","67d4326a":"# check class distribution in validation set\n\n# y_valid.value_counts()","94388648":"# instantiate classifier with polynomial kernel and C=1.0\npoly_svc=SVC(kernel='poly', C=1.0) \n\n\n# fit classifier to training set\npoly_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=poly_svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","1a4be1e2":"# instantiate classifier with polynomial kernel and C=100.0\npoly_svc100=SVC(kernel='poly', C=100.0) \n\n\n# fit classifier to training set\npoly_svc100.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=poly_svc100.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","ca96d946":"Polynomial kernel gives poor performance. It may be overfitting the training set.","1b11e816":"# instantiate classifier with sigmoid kernel and C=1.0\nsigmoid_svc=SVC(kernel='sigmoid', C=1.0) \n\n\n# fit classifier to training set\nsigmoid_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=sigmoid_svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","a8efd66a":"# instantiate classifier with sigmoid kernel and C=100.0\nsigmoid_svc100=SVC(kernel='sigmoid', C=100.0) \n\n\n# fit classifier to training set\nsigmoid_svc100.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=sigmoid_svc100.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","fac326c0":"# Create the parameter grid based on the results of random search \nparams_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]","ba01f64f":"# Performing CV to tune parameters for best SVM fit \nsvm_model = GridSearchCV(SVC(), params_grid, cv=5)\nsvm_model.fit(X_train, y_train)","53dfb8fb":"# View the accuracy score\nprint('Best score for training data:', svm_model.best_score_,\"\\n\") \n\n# View the best parameters for the model found using grid search\nprint('Best C:',svm_model.best_estimator_.C,\"\\n\") \nprint('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\nprint('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n\nfinal_model = svm_model.best_estimator_\nY_pred = final_model.predict(X_valid)\nY_pred_label = list(encoder.inverse_transform(Y_pred))","128614ec":"# Making the Confusion Matrix\n#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\nprint(confusion_matrix(y_valid,Y_pred))\nprint(\"\\n\")\nprint(classification_report(y_valid,Y_pred))\n\nprint(\"Training set score for SVM: %f\" % final_model.score(X_train , y_train))\nprint(\"Validation set score for SVM: %f\" % final_model.score(X_valid  , y_valid ))\n\n# svm_model.score","a501872a":"# Hyperparameter tuning using grid search and cross validation","1cc0e2f7":"## Run SVM with linear kernel and C=100.0","ff669417":"We can see that the training set and test-set accuracy are very much comparable.","60f8339e":"We can see that sigmoid kernel is also performing poorly just like with polynomial kernel.","b41e29b9":"## Visualize the Class Distribution","546e674b":"## Run SVM with rbf kernel and C=100.0\n\nSome time there are outliers in the dataset. In that case, we should increase the value of C as higher C means fewer outliers. So, might run SVM with kernel=rbf and C=100.0.\n\nWe will try playing with various hyper-parameter.","41231b28":"Class distribution looks good.\n\nNext will check for the feature `subject`. \n\nThough feature `subject` is not much useful to us, as it is an identifier of the subject who carried out the experiment.\n\nWe are good to ignore or drop the feature.","92c9a25c":"## Transforming non numerical labels into numerical labels","602c4718":"So the train data set has 563 Columns \/ features (including the target \/ class), and 7352 rows or data points.\n\nAlso the target is Activity. As mentioned in the data description it has 6 unique values. Lets check them also in next step.","fe38e6b6":"## Check the data types of each features. \n\nAll features are of float64 type and all 561 are numeric features, except for Class (y). We need to do Label ENcoder and make it into numeirc.","bc14e391":"The training-set accuracy score is 99.71 while the validation-set accuracy to be 98.44. These two values are quite comparable. So, there is no question of overfitting.","a16b064d":"# Import Library","896b271e":"# Check for overfitting and underfitting","cb5f3f5c":"## Run SVM with linear kernel and C=1000.0","1474136a":"In this case, we can see that the accuracy had decreased with C=1000.0","51bcfdc5":"## Check for missing values in the dataset","60b01411":"## Class Distribution","f3899ed2":"Here, y_valid are the true class labels and y_pred are the predicted class labels in the test-set.","defd415d":"* Problem Type : Multi-Class Classification\n* Algorithm  : SVM","ba692942":"## Run SVM with default hyperparameters\nDefault hyperparameter means C=1.0, kernel=rbf and gamma=auto among other parameters.","1deba610":"## Confusion Matrix and Accuracy Score","567372fa":"# Human Activity Recognition with Smartphones\n\nThe Human Activity Recognition database was built from the recordings of 30 study participants performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. The objective is to classify activities into one of the six activities performed.\n\nRefer to link https:\/\/www.kaggle.com\/uciml\/human-activity-recognition-with-smartphones  for more details.\n\nThe dataset is also available on UCI Machine Learning Repository.","d1958b70":"## Run SVM with sigmoid kernel\nRun SVM with sigmoid kernel and C=1.0","b95a5d62":"## Run SVM with linear kernel \nRun SVM with linear kernel and C=1.0","1eb2985d":"We can see that we can obtain higher accuracy with C=100.0 and C=1000.0 as compared to C=1.0.\n\n","a2c181a5":"# EDA","cbcc25ef":"## Run SVM with polynomial kernel\nRun SVM with polynomial kernel and C=1.0","de11e39d":"# Load the Training DataSet","b2a05470":"# Comments\nWe get maximum accuracy with `rbf` and `linear` kernel with C=100.0. and the accuracy is 99%. Based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n","e6edbb82":"# Train the Model","1167ff7a":"# Split X and y into training and validation sets","ea9d4cb1":"We can see that we obtain a higher accuracy with C=100.0 as higher C means less outliers. \n\nNow, I will further increase the value of C=1000.0 and check accuracy.","5b98a911":"## Compare the train-set and test-set accuracy\nNow, I will compare the train-set and test-set accuracy to check for overfitting.","94fce71a":"## Feature Scaling","de006d24":"## Run SVM with rbf kernel and C=1000.0","b64e7c60":"## Run SVM with sigmoid kernel and C=100.0","763bf790":"# Compare model accuracy with null accuracy\nSo, the model accuracy is 0.9832. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the null accuracy. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.\n\nSo, we should first check the class distribution in the validation set.","a7f7fffe":"We can see that the occurences of most frequent class ---  is ---. So, we can calculate null accuracy by dividing --- by total number of occurences.","5825796f":"## Run SVM with polynomial kernel and C=100.0"}}