{"cell_type":{"cc5c802f":"code","1ba43633":"code","880c3cd1":"code","675b9feb":"code","f59b92a7":"code","e74e9a57":"code","469936c6":"code","b126852c":"code","8aa869d1":"code","715e93f6":"code","5185746d":"code","a9458bc8":"code","ad82550b":"code","eba15e7a":"code","2444a6e2":"code","d333253a":"code","3a50a71e":"code","47e9cb67":"code","e87d6155":"code","63f204b0":"code","bb93b645":"code","ed335f82":"code","b004cb00":"code","b5102025":"markdown","d51711c6":"markdown","896c8fb3":"markdown","74cefce8":"markdown","a0efd697":"markdown","4d95ef4f":"markdown","3648cc9e":"markdown","6b65af92":"markdown","d98f2064":"markdown","e83c68d1":"markdown","0a3bdc0a":"markdown","e0680e54":"markdown","d03fc9f0":"markdown","b9be8608":"markdown","b1971b8a":"markdown","d734eb12":"markdown","0090568c":"markdown","ca969f64":"markdown","72f78f49":"markdown","af654e81":"markdown","8388a558":"markdown","2a66b136":"markdown","1f3cd05c":"markdown","915d1a8d":"markdown","4914adf9":"markdown","00aa5c2c":"markdown"},"source":{"cc5c802f":"!pip install deepstack","1ba43633":"import pandas as pd\nimport numpy as np \nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.layers import PReLU\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","880c3cd1":"img_h,img_w= (300,300)\nbatch_size=128\nepochs=10\nn_class=48","675b9feb":"base_dir = '..\/input\/devnagri-handwritten-character\/DEVNAGARI_NEW'\ntrain_dir = os.path.join(base_dir, 'TRAIN')\nvalidation_dir = os.path.join(base_dir, 'TEST')","f59b92a7":"from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n\nbase_model_1=VGG19(include_top=False, weights='imagenet',input_shape=(img_h,img_w,3), pooling='avg')\n\n# Making last layers trainable, because our dataset is much diiferent from the imagenet dataset \nfor layer in base_model_1.layers[:-6]:\n    layer.trainable=False\n    \nmodel_1=Sequential()\nmodel_1.add(base_model_1)\n\nmodel_1.add(Flatten())\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dropout(0.35))\nmodel_1.add(Dense(n_class,activation='softmax'))\n            \nmodel_1.summary()","e74e9a57":"tf.keras.utils.plot_model(\n    model_1,\n    to_file=\"model_1.png\",\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=100,\n)","469936c6":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nbase_model_2= InceptionV3(include_top=False, weights='imagenet',\n                                        input_tensor=None, input_shape=(img_h,img_w,3), pooling='avg')\n\nfor layer in base_model_2.layers[:-30]:\n    layer.trainable=False\nmodel_2=Sequential()\nmodel_2.add(base_model_2)\nmodel_2.add(Flatten())\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(1024,activation='relu'))\nmodel_2.add(BatchNormalization())\n\nmodel_2.add(Dense(512,activation='relu'))\nmodel_2.add(Dropout(0.35))\nmodel_2.add(BatchNormalization())\n\nmodel_2.add(Dense(256,activation='relu'))\nmodel_2.add(Dropout(0.35))\nmodel_2.add(BatchNormalization())\n\nmodel_2.add(Dense(n_class,activation='softmax'))\n\nmodel_2.summary()","b126852c":"tf.keras.utils.plot_model(\n    model_2,\n    to_file=\"model_2.png\",\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=100,\n)","8aa869d1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n         rescale=1.\/255,\n         rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ntest_datagen= ImageDataGenerator(rescale=1.\/255)","715e93f6":"from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n\nreduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n                                         factor=0.1,\n                                         patience=3,\n                                         cooldown=2,\n                                         min_lr=1e-10,\n                                         verbose=1)\n\ncallbacks = [reduce_learning_rate]\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","5185746d":"model_1.compile( loss='categorical_crossentropy',optimizer= optimizer, metrics=['accuracy'])\nmodel_2.compile( loss='categorical_crossentropy',optimizer= optimizer, metrics=['accuracy'])","a9458bc8":"train_generator = train_datagen.flow_from_directory(\n                    train_dir,                   # This is the source directory for training images\n                    target_size=(img_h, img_w),  # All images will be resized to 300x300\n                    batch_size=batch_size,\n                    class_mode='categorical')\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nvalidation_generator = test_datagen.flow_from_directory(\n                        validation_dir,\n                        target_size=(img_h, img_w),\n                        batch_size=batch_size,\n                        class_mode='categorical')","ad82550b":"history_1 = model_1.fit(\n      train_generator,\n      steps_per_epoch=6528\/\/batch_size, \n      epochs=epochs,\n      validation_data=validation_generator,\n      validation_steps=3312\/\/batch_size,  \n      callbacks=callbacks,\n      verbose=1)","eba15e7a":"history_2 = model_2.fit(\n      train_generator,\n      steps_per_epoch=6528\/\/batch_size, \n      epochs=epochs,\n      validation_data=validation_generator,\n      validation_steps=3312\/\/batch_size,  \n      callbacks=callbacks,\n      verbose=1)","2444a6e2":"import matplotlib.pyplot as plt\nplt.plot(history_1.history['accuracy'])\nplt.plot(history_1.history['val_accuracy'])\nplt.title('VGG-19 model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_1.history['loss'])\nplt.plot(history_1.history['val_loss'])\nplt.title('VGG-19 model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","d333253a":"import matplotlib.pyplot as plt\nplt.plot(history_2.history['accuracy'])\nplt.plot(history_2.history['val_accuracy'])\nplt.title('Inception V3 model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_2.history['loss'])\nplt.plot(history_2.history['val_loss'])\nplt.title('Inception V3 model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","3a50a71e":"from deepstack.base import KerasMember\n\nmember1 = KerasMember(name=\"model1\", keras_model=model_1, train_batches=train_generator, val_batches=validation_generator)\nmember2 = KerasMember(name=\"model2\", keras_model=model_2, train_batches=train_generator, val_batches=validation_generator)","47e9cb67":"from deepstack.ensemble import DirichletEnsemble\nfrom sklearn.metrics import accuracy_score\n\nwAvgEnsemble = DirichletEnsemble(N=10000, metric=accuracy_score)\nwAvgEnsemble.add_members([member1, member2])\nwAvgEnsemble.fit()\nwAvgEnsemble.describe()","e87d6155":"from deepstack.ensemble import StackEnsemble\nimport sklearn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Ensure you have the scikit-learn version >= 0.22 installed\nprint(\"sklearn version must be >= 0.22. You have:\", sklearn.__version__)\n\nstack = StackEnsemble()\n\n# 2nd Level Meta-Learner\nestimators = [\n    ('rf', RandomForestClassifier(verbose=0, n_estimators=100, max_depth=15, n_jobs=20, min_samples_split=30)),\n    ('etr', ExtraTreesClassifier(verbose=0, n_estimators=100, max_depth=10, n_jobs=20, min_samples_split=20)),\n    ('dtc',DecisionTreeClassifier(random_state=0, max_depth=3))\n]\n# 3rd Level Meta-Learner\nclf = StackingClassifier(\n    estimators=estimators, final_estimator=LogisticRegression()\n)\n\nstack.model = clf\nstack.add_members([member1, member2])\nstack.fit()\nstack.describe(metric=sklearn.metrics.accuracy_score)","63f204b0":"stack.save()","bb93b645":"stack.load()","ed335f82":"model_json = model_1.to_json()\nwith open(\"VGG_19.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel_1.save_weights(\"VGG_19_weights.h5\")\nprint(\"Saved VGG19 to disk\")","b004cb00":"model_json = model_2.to_json()\nwith open(\"Inception_V3.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel_2.save_weights(\"Inception_V3_weights.h5\")\nprint(\"Saved Inception_V3 to disk\")","b5102025":"Don't forget to save the DCNN itself, otherwise you may have trouble.","d51711c6":"Constructor of a Dirichlet Weighted Ensemble\nArgs:\n*     N: the number of times weights should be (randomly) tried out,\n          sampled from a dirichlet distribution\n*     metric: (optional) evaluation metric function.\n         Default: `sklearn.metrics.roc_auc_score`\n*     maximize: if evaluation metric should be maximized (otherwise minimized)         ","896c8fb3":"Loading the model is as simple as this.","74cefce8":"You can see the overall achieved accuracy after training for very less time.\nNow let us use two major kind of ensembles namely\n* Weighted Average ensemble\n* Stacking ensemble with meta learners\n\nWe will be using Deepstack Library for implementing these.","a0efd697":"Importing and initializing Inception_V3","4d95ef4f":"For Inception V3 model","3648cc9e":"Compiling Models","6b65af92":"Plotting Inception_V3 model","d98f2064":"Plotting Vgg-19 model","e83c68d1":"**Importing essential pacakages**","0a3bdc0a":"Now lets save our stack-ensemble model.","e0680e54":"Now lets fit the models on our dataset","d03fc9f0":"Saves meta-learner and base-learner of ensemble into folder \/ directory.\n\n**Args:**\n* folder: the folder where models should be saved to(Create if not exists).           ","b9be8608":"Initializing train and test datagenerators","b1971b8a":"**I encourage all of you to play around with this kernel, change the hyperparameters and meta learners. This ensembling is going to help you a lot in different kaggle competitions.And please give me an upvote, it motivates me to work more. :)**","d734eb12":"*Concatenating train and test directory paths..*","0090568c":"Specifying global parameters","ca969f64":"# Stacking\n\nIn Stacking there are two types of learners called Base Learners and a Meta Learner.Base Learners and Meta Learners are the normal machine learning algorithms like Random Forests, SVM, Perceptron etc.Base Learners try to fit the normal data sets where as Meta learner fit on the predictions of the base Learner.\n![](https:\/\/miro.medium.com\/max\/1166\/0*L-yEiG9ONP-AWJ82.png)\n\nStacking Technique involves the following Steps:-\n1. Split the training data into 2 disjoint sets\n2. Train several Base Learners on the first part\n3. Test the Base Learners on the second part and make predictions\n4. Using the predictions from (3) as inputs,the correct responses from the output,train the higher level learner.\n\nMeta Learner is kind of trying to find the optimal combination of base learners.\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*1ArQEf8OFkxVOckdWi7mSA.png)\n\n","72f78f49":"I'm going to use two D-CNN models namely VGG-19 and Inception V3.If you are new to transfer learning , plaese refer [this](https:\/\/towardsdatascience.com\/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a).\n\nQuick Info:- \n\n**Transfer learning:-** Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned.\n\n# Vgg-19\nVGG is a Convolutional Neural Network (CNN) architecture that secured first and second positions in the localisation and classification tasks respectively in ImageNet challenge 2014.All the CNNs have more or less similar architecture, stack of convolution and pooling layers at start and ending with fully connected and soft-max layers.\nThe VGG architecture is also similar and is clearly explained in [this paper](https:\/\/arxiv.org\/pdf\/1409.1556.pdf).\n\nThe main contribution of VGG is to show that classification\/localisation accuracy can be improved by increasing the depth of CNN inspite of using small receptive fields in the layers. (especially earlier layers).\n\nNeural networks prior to VGG used bigger receptive fields ( 7*7 and 11*11) as compared to 3*3 in VGG, but they were not as deep as VGG. There are few variants of VGG, the deepest one is with 19 weight layers.\n\n# Inception-V3\n\nUsing multiple features from multiple filters improve the performance of the network. Other than that, there is another fact that makes the inception architecture better than others. All the architectures prior to inception, performed convolution on the spatial and channel wise domain together. By performing the 1x1 convolution, the inception block is doing cross-channel correlations, ignoring the spatial dimensions. This is followed by cross-spatial and cross-channel correlations via the 3x3 and 5x5 filters.\nFor more details refer [this paper](http:\/\/https:\/\/arxiv.org\/pdf\/1512.00567.pdf).\n","af654e81":"Creating callbacks and optimizers. You may try out diiferent optimizers","8388a558":"Now let's do weighted average ensemble.\n# **Weighted Average Ensemble:**\nThis method weights the contribution of each ensemble member based on their performance on a hold-out validation dataset. Models with better contribution receive a higher weight.\n![](https:\/\/miro.medium.com\/max\/1384\/1*5CnIeN_BtByepM_4JWrdvQ.png)","2a66b136":"Importing and initializing VGG-19","1f3cd05c":"For VGG-19 model","915d1a8d":"Importing deepstack for powerful ensembles, [more info](https:\/\/github.com\/jcborges\/DeepStack)","4914adf9":"You can add as many members as you want for ensemble.","00aa5c2c":"Now Let us plot the curves for train and val losses."}}