{"cell_type":{"f4b803fc":"code","bc77a91f":"code","fcb459fa":"code","1182e05a":"code","b13c29bb":"code","f6c02791":"code","7edb4a81":"code","9b32527a":"code","5fa8704b":"code","508d2952":"code","9f646773":"code","03b57309":"code","5b7ee9df":"code","c4a8ef67":"code","96b7aefb":"code","562e979a":"code","62e2a83f":"code","f5dc1a9c":"code","4cdcba85":"code","3cb64595":"code","41f001b9":"code","d8bf06ca":"code","80f2b673":"code","dbb0023c":"code","6f1af85b":"code","4a54b6a0":"code","4abe5745":"code","f5557c27":"code","f9c04e24":"code","034fbfbf":"code","44a102b7":"code","fbdb9851":"code","b51e01fa":"code","b9d6d529":"code","da0c46e1":"code","f0deaa3c":"code","e2aa46fd":"code","82cab19b":"code","cc14a59d":"code","cf851b6e":"code","b0fa75d2":"code","b449773c":"code","2d3b71e9":"code","0fb4ab56":"code","e55cb865":"code","f5d66628":"markdown","7e00a0d0":"markdown","5a0c3088":"markdown","7621cafa":"markdown","5e032f1a":"markdown","af0fff0c":"markdown","2dd5b309":"markdown","69ec16c2":"markdown","de6d51b2":"markdown","567c7d1f":"markdown","76073a68":"markdown","af0bb789":"markdown","02e9376e":"markdown","c543ff3f":"markdown","bce5a36e":"markdown"},"source":{"f4b803fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bc77a91f":"path = '..\/input\/Kannada-MNIST\/'","fcb459fa":"import matplotlib.pyplot as plt\nfrom PIL import Image","1182e05a":"from keras.utils import to_categorical\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nfrom keras.callbacks import EarlyStopping","b13c29bb":"\"\"\"\nhelper function to show a number of randomly selected images \nbelonging either to a specified label or selected across all labels\n\"\"\"\n\ndef show_random_images(images, num=10, label=None):\n\n    # generating images' subsample if label specified\n    if label is not None:\n        images = images[images.label == label]\n    \n    fig, axs = plt.subplots(num, figsize=(1.25, num * 2.5))\n    \n    for i in range(num):\n    \n        rnd = np.random.randint(len(images))\n    \n        # getting image data and splitting between label and pixels' vector\n        img_data = np.array(images.iloc[rnd], dtype='uint8')    \n        img_label = img_data[0]\n        img_pixels = img_data[1:]\n        \n        # reshaping image to 2D array\n        img_shape = (int(np.sqrt(img_pixels.shape[0])), int(np.sqrt(img_pixels.shape[0])))\n        img_array = img_pixels.reshape(img_shape)\n        \n        title = 'Image {} \/ labelled {}'.format(rnd, img_label)\n        \n        axs[i].imshow(img_array, alpha=0.66, cmap='gray')\n        axs[i].set_title(title)","f6c02791":"train_data = pd.read_csv(path + 'train.csv')\ntrain_data","7edb4a81":"# checking labels distribution\n\ntrain_data.label.value_counts()","9b32527a":"show_random_images(train_data, num=5, label=5)","5fa8704b":"dig_data = pd.read_csv(path + 'Dig-MNIST.csv')\ndig_data","508d2952":"# checking labels distribution\n\ndig_data.label.value_counts()","9f646773":"show_random_images(dig_data, num=5, label=5)","03b57309":"# helper function to show randomly selected image from 2D images array\n\ndef show_random_image(imgset):\n    \n    rnd = np.random.randint(imgset.shape[0])\n    imgarray = imgset[rnd]\n    plt.figure(figsize=(1.5, 1.5))\n    plt.imshow(imgarray, cmap='gray')","5b7ee9df":"# preparing train image labels using 'one-hot' encoding\n\ntrain_labels = to_categorical(train_data.label)\ntrain_labels","c4a8ef67":"train_labels.shape","96b7aefb":"# preparing train images array ('flat' image vectors)\n\ntrain_images = np.array(train_data.drop(columns='label'))\ntrain_images.shape","562e979a":"# preparing 2D train images array (reshaping original 'flat' image vectors array)\n\nn_images = train_images.shape[0]\ndim = int(np.sqrt(train_images.shape[1]))\n\ntrain_images_2D = train_images.reshape(n_images, dim, dim)\ntrain_images_2D.shape","62e2a83f":"show_random_image(train_images_2D)","f5dc1a9c":"# normalizing \"train\" images\n\ntrain_images = train_images \/ 255","4cdcba85":"# preparing dig-mnist image labels using 'one-hot' encoding\n\ndig_labels = to_categorical(dig_data.label)\ndig_labels","3cb64595":"dig_labels.shape","41f001b9":"# preparing train images array ('flat' image vectors)\n\ndig_images = np.array(dig_data.drop(columns='label'))\ndig_images.shape","d8bf06ca":"# preparing 2D dig-mnist images array (reshaping original 'flat' image vectors array)\n\nn_images = dig_images.shape[0]\ndim = int(np.sqrt(dig_images.shape[1]))\n\ndig_images_2D = dig_images.reshape(n_images, dim, dim)\ndig_images_2D.shape","80f2b673":"show_random_image(dig_images_2D)","dbb0023c":"# normalizing \"Dig-MNIST\" images\n\ndig_images = dig_images \/ 255","6f1af85b":"test_data = pd.read_csv(path + 'test.csv', index_col='id')\ntest_data","4a54b6a0":"submission = pd.read_csv(path + 'sample_submission.csv', index_col='id')\nsubmission","4abe5745":"# preparing test images array ('flat' image vectors)\n\ntest_images = np.array(test_data)\ntest_images.shape","f5557c27":"# normalizing \"test\" images\n\ntest_images = test_images \/ 255","f9c04e24":"# setting input dimensionality - \"flat\" image vectors\ninput_dim = train_images.shape[1]","034fbfbf":"# setting optimization parameters\noptimizer = 'rmsprop'\nloss = 'categorical_crossentropy'\nmetrics = ['accuracy']","44a102b7":"# setting training parameters\nepochs = 100\nbatch_size = 1024\n\nearly_stop = EarlyStopping(monitor='val_loss', \n                           min_delta=0, \n                           patience=3, \n                           verbose=True, \n                           mode='auto', \n                           baseline=None, \n                           restore_best_weights=False)\n\ncallbacks = [early_stop]","fbdb9851":"model = Sequential()\nmodel.add(Dense(128, activation='relu', input_shape=(input_dim,)))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","b51e01fa":"model.compile(optimizer=optimizer, loss=loss, metrics=metrics)","b9d6d529":"model.summary()","da0c46e1":"model.fit(train_images, train_labels, \n          batch_size=batch_size, epochs=epochs, \n          verbose=True, \n          callbacks=callbacks, \n          validation_split=0.1)","f0deaa3c":"# showing history of 'accuracy'\n\nplt.figure()\nplt.plot(model.history.history['accuracy'], label='TRAIN ACC')\nplt.plot(model.history.history['val_accuracy'], label='VAL ACC')\nplt.legend()\nplt.show()","e2aa46fd":"# showing history of 'loss'\n\nplt.figure()\nplt.plot(model.history.history['loss'], label='TRAIN LOSS')\nplt.plot(model.history.history['val_loss'], label='VAL LOSS')\nplt.legend()\nplt.show()","82cab19b":"# making predictions for \"train\" data (in-sample check)\n\npred_train = model.predict_classes(train_images)\npred_train.shape","cc14a59d":"hits = (pred_train == train_data.label)\nprint('Hits: {}, i.e. {:.2f}%'.format(hits.sum(), hits.sum() \/ pred_train.shape[0] * 100))","cf851b6e":"miss = (pred_train != train_data.label)\nprint('Misses: {}, i.e. {:.2f}%'.format(miss.sum(), miss.sum() \/ pred_train.shape[0] * 100))","b0fa75d2":"# evaluating model on \"train\" data\n\neval_metrics = model.evaluate(x=train_images, y=train_labels, \n                              batch_size=batch_size, verbose=True, callbacks=callbacks)\npd.DataFrame(eval_metrics, index=model.metrics_names, columns=['metric'])","b449773c":"# evaluating model on \"Dig-MNIST\" data\n\neval_metrics = model.evaluate(x=dig_images, y=dig_labels, \n                              batch_size=batch_size, verbose=True, callbacks=callbacks)\npd.DataFrame(eval_metrics, index=model.metrics_names, columns=['metric'])","2d3b71e9":"# setting the optimal number of epochs\nepochs = 8\n\n# re-training the model on full train dataset\nmodel.fit(train_images, train_labels, \n          batch_size=batch_size, epochs=epochs, \n          verbose=True)","0fb4ab56":"# making predictions on \"test\" data\n\npred_test = model.predict_classes(test_images)","e55cb865":"submission.label = pred_test\nsubmission.to_csv('submission.csv')","f5d66628":"#### Making predictions","7e00a0d0":"#### Preparing \"Dig-MNIST\" images","5a0c3088":"#### \"train.csv\"","7621cafa":"#### \"Dig-MNIST.csv\"","5e032f1a":"#### Model evaluation","af0fff0c":"### Data preparation","2dd5b309":"#### Loading test images and sample submission","69ec16c2":"#### Preparing test images","de6d51b2":"#### Preparing \"train\" images","567c7d1f":"### Setup & Imports","76073a68":"#### Setting (hyper)parameters","af0bb789":"### Data loading & inspection","02e9376e":"### Modelling","c543ff3f":"##### Helper functions","bce5a36e":"##### helper functions"}}