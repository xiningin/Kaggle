{"cell_type":{"2e0eca75":"code","e1392aa5":"code","c09adb8f":"code","38c77c7e":"code","e0c3d8ca":"code","717244b5":"code","3e0cb4a8":"code","d4cb404f":"code","f0d2e0ed":"code","29d51a2d":"code","2cef76e7":"code","ff8fc379":"code","a89a8088":"code","2a765a4b":"code","23c6a830":"code","9845d445":"code","d6e1cf4c":"code","84e27b1c":"code","4cfa097c":"code","f70ae43a":"code","c944dd0c":"code","f69d5af2":"code","25f8f613":"code","a7d33432":"code","825d98df":"code","198e6a31":"code","5b01a916":"code","f8bc7e75":"code","fa0b0dcc":"code","189bc945":"code","d0ef290c":"code","77aefdf2":"code","2eb48598":"code","9f0fe891":"code","3b9825aa":"code","f3e57734":"code","4df2b28d":"code","49ed115c":"code","5ce47ba6":"code","1b12c9bc":"code","83f98953":"code","809271ce":"code","7ccf639f":"code","44327672":"code","54d414b8":"code","01289944":"code","8c4caac2":"code","80c53bc8":"code","290d583b":"code","67a6b421":"code","cc78da7a":"code","7cea0d98":"code","2944ab52":"code","d0926d4b":"markdown","a21345c1":"markdown","c421bc3d":"markdown","a8cd2864":"markdown","55ab58b5":"markdown","6f73689c":"markdown","492a2410":"markdown","5ed6017b":"markdown","0ee97de5":"markdown","da57501e":"markdown","87360814":"markdown"},"source":{"2e0eca75":"#Libraries\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport numpy as np\nimport math\nimport os\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline","e1392aa5":"#obtain data from Carla dataset\ntrain_img_dir = []\ntrain_img_steer = []\n\nval_img_dir = []\nval_img_steer = []\n\n#Load validation data\nwith open('..\/input\/tfg-data\/Prueba9_mac\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    val_img_dir.append('..\/input\/tfg-data\/Prueba9_mac\/output\/'+ component[1][:-1] + '.jpg')\n    val_img_steer.append(float(component[0]))\n\n#Load training data\nwith open('..\/input\/carla-datasets-2\/Prueba4_mac\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    train_img_dir.append('..\/input\/carla-datasets-2\/Prueba4_mac\/output\/'+ component[1][:-1] + '.jpg')\n    train_img_steer.append(float(component[0]))\nwith open('..\/input\/carla-datasets-2\/Prueba5_mac\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    train_img_dir.append('..\/input\/carla-datasets-2\/Prueba5_mac\/output\/'+ component[1][:-1] + '.jpg')\n    train_img_steer.append(float(component[0]))\nwith open('..\/input\/carla-datasets-2\/Prueba6_mac\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    train_img_dir.append('..\/input\/carla-datasets-2\/Prueba6_mac\/output\/'+ component[1][:-1] + '.jpg')\n    train_img_steer.append(float(component[0]))\nwith open('..\/input\/tfg-data\/Prueba7_mac\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    train_img_dir.append('..\/input\/tfg-data\/Prueba7_mac\/output\/'+ component[1][:-1] + '.jpg')\n    train_img_steer.append(float(component[0]))\n\nwith open('..\/input\/tfg-data\/Prueba8_mac\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    train_img_dir.append('..\/input\/tfg-data\/Prueba8_mac\/output\/'+ component[1][:-1] + '.jpg')\n    train_img_steer.append(float(component[0]))","c09adb8f":"print(len(train_img_dir),\n      len(val_img_steer))","38c77c7e":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.plot(val_img_steer)\n\nplt.ylabel('steering angles')\nplt.xlabel('images')\n\nplt.show()","e0c3d8ca":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.hist( val_img_steer, 50 )\n\nplt.xlabel('steering angles')\nplt.title('Carla dataset')\n\nplt.show()","717244b5":"'''#obtain data from udacity dataset \nimg_dir = []\nimg_steer = []\n\nwith open('..\/input\/udacity-dataset\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    img_dir.append('..\/input\/udacity-dataset\/data\/'+ component[0] )\n    img_steer.append(float(line.split()[1].split(',')[0])\/360)\n    \ntrain_img_dir = img_dir[:int(len(img_steer)*0.75)]\ntrain_img_steer = img_steer[:int(len(img_steer)*0.75)]\n\nval_img_dir = img_dir[-int(len(img_steer)*0.25):]\nval_img_steer = img_steer[-int(len(img_steer)*0.25):]'''","3e0cb4a8":"len(train_img_dir)      ","d4cb404f":"aux_img = []\naux_steer = []\nstraight = 0\nfor n, s in enumerate(train_img_steer):\n    if 0.025< abs(s) :\n        aux_img.append(train_img_dir[n])\n        aux_steer.append(s)\n    if 0.025>= abs(s) and straight<(len(aux_steer)-straight):\n        straight+=1\n        aux_img.append(train_img_dir[n])\n        aux_steer.append(s)\ntrain_img_dir = aux_img\ntrain_img_steer = aux_steer","f0d2e0ed":"print(len(aux_img),\n      len(aux_steer))","29d51a2d":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nline_zero = [0 for x in range(len(train_img_steer))]\n\nplt.plot(train_img_steer)\n#plt.plot(line_zero)\n\nplt.ylabel('steering angles')\nplt.xlabel('images')\n\nplt.show()","2cef76e7":"class My_Dataset(torch.utils.data.Dataset):\n  def __init__(self, image_dir, steer, transform=None, train= False):\n    self.image_dir = image_dir\n    self.steer = steer\n    self.transform = transform\n    self.train=train\n\n  def __getitem__(self, index):\n    image = cv2.imread(self.image_dir[index])\n    image = cv2.resize(image,(200, 66))#(400, 132))\n        \n    steering_angle = self.steer[index]\n    \n    #random image horizontal flip\n    doflip = (np.random.uniform() > 0.5)\n    \n    if doflip==True and self.train == True:\n      image = cv2.flip(image,1) \n      steering_angle=-steering_angle\n        \n    if self.transform:\n      image = self.transform(image)\n    \n    return image, steering_angle\n\n  def __len__(self):\n    return len(self.image_dir)","ff8fc379":"train_dataset = My_Dataset( train_img_dir, train_img_steer, transform=transforms.ToTensor(), train=True)\nval_dataset = My_Dataset( val_img_dir, val_img_steer, transform=transforms.ToTensor())","a89a8088":"try_img = cv2.imread(train_img_dir[0])\n#try_img = cv2.flip(try_img,1)\n#try_img = cv2.resize(try_img,(200, 66))\nshow_img = cv2.cvtColor(try_img,cv2.COLOR_BGR2RGB)\nplt.imshow(show_img)#, cmap='hot')\n#plt.set_cmap('hot')\nplt.axis('off')","2a765a4b":"BATCH_SIZE = 32\nNUM_WORKERS = 2","23c6a830":"train_loader = torch.utils.data.DataLoader(\n                dataset=train_dataset,\n                batch_size=BATCH_SIZE,\n                num_workers=NUM_WORKERS,\n                shuffle=True\n                 )\n        \nval_loader = torch.utils.data.DataLoader(\n                dataset=val_dataset,\n                batch_size=1,#1\n                num_workers=0,\n                shuffle=False\n                  )","9845d445":"class Self_Steering_Model(torch.nn.Module):\n    def __init__(self):\n      super().__init__()\n\n      #self.conv = nn.Conv2d(24, 36, kernel_size=5, stride=2)\n      self.conv_network=torch.nn.Sequential(\n            \n        # 5 convolutinal layers\n        nn.Conv2d(3, 24, kernel_size=5, stride=2),\n        nn.BatchNorm2d(24),\n        nn.ReLU(), \n        nn.Conv2d(24, 36, kernel_size=5, stride=2),\n        nn.BatchNorm2d(36),\n        nn.ReLU(),\n        nn.Conv2d(36, 48, kernel_size=5, stride=2),\n        nn.BatchNorm2d(48),\n        nn.ReLU(),\n        nn.Conv2d(48, 64, kernel_size=3),\n        nn.BatchNorm2d(64),\n        nn.ReLU(),\n        nn.Conv2d(64, 64, kernel_size=3),\n        nn.Dropout(0.5),\n        nn.Flatten(),\n      )\n\n      self.fc_network=torch.nn.Sequential(\n        # 5 fully connected layer to flatten data\n        \n        nn.Linear(64*18*1, 1164),\n        nn.BatchNorm1d(1164),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(1164, 100),\n        nn.BatchNorm1d(100),\n        nn.ReLU(),\n        nn.Linear(100, 50),\n        nn.BatchNorm1d(50),\n        nn.Linear(50, 10),\n        nn.BatchNorm1d(10),\n        nn.Linear(10, 1),\n        )\n        \n    def forward(self, x):\n      x = x.view(x.size(0), 3, 200, 66) #400, 132)\n      output = self.conv_network(x)\n      #print(output.shape)\n      output = output.view(output.size(0), -1)\n      output = self.fc_network(output)\n      return output","d6e1cf4c":"def save_checkpoint(state, best=False):\n        \"\"\"Save checkpoint.\"\"\"\n        root_dir = \".\/\"\n        print(\"==> Save checkpoint ...\")\n        if not os.path.exists(root_dir):\n            os.makedirs(root_dir)\n        if best==False:\n            torch.save(state, root_dir + 'both-nvidia-model-{}.h5'.format(state['epoch']))\n        else:\n            torch.save(state, root_dir + 'both-nvidia-model-{}-best.h5'.format(state['epoch']))","84e27b1c":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","4cfa097c":"def resume(epoch, best=False):\n    print(\"==> Loading checkpoint ...\")\n    direction = \".\/both-nvidia-model-\"+str(epoch)+\".h5\"\n    if best==True:\n        direction = \".\/both-nvidia-model-\"+str(epoch)+\"-best.h5\"\n    checkpoint = torch.load(direction, map_location=lambda storage, loc: storage)\n    start_epoch = checkpoint['epoch']\n    model.load_state_dict(checkpoint['state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    scheduler.load_state_dict(checkpoint['scheduler'])","f70ae43a":"def resume_dir(epoch, direction, best=False):\n    print(\"==> Loading checkpoint ...\")\n    \n    if best==True:\n        direction = direction+'\/both-nvidia-model-'+str(epoch)+\"-best.h5\"\n    else:\n        direction = direction+'\/both-nvidia-model-'+str(epoch)+\".h5\"\n    checkpoint = torch.load(direction, map_location=lambda storage, loc: storage)\n    start_epoch = checkpoint['epoch']\n    model.load_state_dict(checkpoint['state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    scheduler.load_state_dict(checkpoint['scheduler'])","c944dd0c":"def save_info(info, name):\n  print('=> Saving',name)\n  dir='.\/'+str(name)+'.txt'\n  with open(dir, 'a') as file:\n    #file.write(\"Epoch: {} loss: {} \\n\".format(epoch,info))\n    file.write(str(info))\n  #print('=> Saved')","f69d5af2":"#graph error?epoch\n\ndef graph_error(error, doc, save= False):\n    fig = plt.figure()\n    ax = fig.add_axes([0,0,4,2])\n\n    plt.plot(error)\n\n    plt.xlabel('Epoch')\n    plt.ylabel('Error')\n    plt.show()\n    \n    if save== True:\n        plt.savefig('.\/{}.png'.format(doc))","25f8f613":"LEARNING_RATE = 1e-4\nWEIGHT_DECAY = 1e-5\nEPOCHS = 50\n\nloss_fn = nn.MSELoss(reduction='mean') \nmodel = Self_Steering_Model()\nstart_epoch = 0\noptimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# learning rate scheduler\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15,30], gamma=0.1)","a7d33432":"def train(model, device, train_loader, val_loader, loss_fn, epochs, LEARNIN_RATE, optimizer, start_epoch=0):\n        \n        all_train_loss = []\n        all_val_loss = []\n        best_model = ''\n        \"\"\"Training process.\"\"\"\n\n        model.to(device)\n        \n        for epoch in range(start_epoch, epochs + start_epoch):\n                        \n            # Training\n            train_loss = 0.0\n            model.train()\n\n            for local_batch, (images, steer ) in enumerate(train_loader):\n                # Transfer to GPU\n                images  = images.to(device) \n                steer  = steer.to(device)   \n\n                # Model computations\n                optimizer.zero_grad()\n                \n                outputs = model(images)\n                loss = loss_fn(outputs, steer.unsqueeze(1).to(torch.float32))\n                loss.backward()\n                optimizer.step()\n\n                train_loss += loss.data.item()\n\n                if local_batch % 100 == 0:\n                    print(\"Training Epoch: {} | Loss: {}\".format(epoch+1 , train_loss \/ (local_batch + 1)))\n                \n                if local_batch == (len(train_loader)-1):\n                    all_train_loss.append(train_loss \/ (local_batch + 1))\n            \n            scheduler.step()\n            \n            # Validation\n            model.eval()\n            valid_loss = 0\n            #change structure\n            for local_batch, (images, steer ) in enumerate(val_loader):\n                  # Transfer to GPU\n                images  = images.to(device) \n                steer  = steer.to(device)   \n\n                outputs = model(images)\n                loss = loss_fn(outputs, steer.unsqueeze(1).to(torch.float32))\n\n                valid_loss += loss.data.item()\n\n                if local_batch % 4000 == 0:\n                    print(\"Validation Loss: {}\".format(valid_loss \/ (local_batch + 1)))\n                \n                if local_batch == (len(val_loader)-1):\n                    all_val_loss.append(valid_loss \/ (local_batch + 1))\n\n            # Save model \n            if((epoch+1)% 5)== 0 or epoch ==(epochs + start_epoch - 1):\n                state = {\n                    'epoch': epoch + 1,\n                    'state_dict': model.state_dict(),\n                    'optimizer': optimizer.state_dict(),\n                    'scheduler': scheduler.state_dict(),\n                }\n\n                save_checkpoint(state)\n            if epoch>0 and all_val_loss[epoch]<min(all_val_loss[:-1]):\n                best_model = '\\nBest model: '+str(epoch+1)\n                state = {\n                    'epoch': epoch + 1,\n                    'state_dict': model.state_dict(),\n                    'optimizer': optimizer.state_dict(),\n                    'scheduler': scheduler.state_dict(),\n                }\n\n                save_checkpoint(state, best=True)\n        print(best_model)\n        return all_train_loss, all_val_loss","825d98df":"all_train_loss = []\nall_val_loss = []\n#Sin GPU 4 horas\nall_train_loss, all_val_loss = train(model, device, train_loader, val_loader, loss_fn, EPOCHS, LEARNING_RATE, optimizer,start_epoch)\n\nsave_info(all_train_loss, 'training')\nsave_info(all_val_loss, 'validation')","198e6a31":"\nfig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nmin_val_loss = [min(all_val_loss) for i in range(len(all_val_loss))]\n\nplt.plot(min_val_loss, color='red')\nplt.plot(all_train_loss, label= 'training')\nplt.plot(all_val_loss, label= 'validation')\n\nplt.xlabel('Epoch')\nplt.ylabel('Error')\nplt.legend()\nplt.grid()\nplt.show()\n\n#plt.savefig('.\/{}.jpg'.format('train_vs_val_error_plot'))","5b01a916":"with open('..\/input\/results-version-4\/training.txt') as file:\n    all_train_loss = file.read()\nwith open('..\/input\/results-version-4\/validation.txt') as file:\n    all_val_loss = file.read()\n    \nall_train_loss = all_train_loss.lstrip('[')\nall_train_loss = all_train_loss.rstrip(']')\nall_train_loss = all_train_loss.split(', ')\n\nall_val_loss = all_val_loss.lstrip('[')\nall_val_loss = all_val_loss.rstrip(']')\nall_val_loss = all_val_loss.split(', ')","f8bc7e75":"resume(13,best=True)","fa0b0dcc":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.plot(val_img_steer)\n   \nplt.show()\n\n","189bc945":"images = []\nsteer_angl = []\n\nfor n, (img, steer)in enumerate(val_loader):\n    images.append(img)\n    steer_angl.append(steer)\n    \nsteer_angl = np.float64(steer_angl)","d0ef290c":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.plot(steer_angl[9600:10500])\n\nplt.ylabel('steering angles')\nplt.xlabel('image')\n\nplt.show()","77aefdf2":"error = []#real - predcited\n\nfor n, i in enumerate(images):\n    out= model(i.to(device))\n    error.append(abs(float(out) - steer_angl[n]))\n    if n%200==0:\n        print(\"model output: {}, dataset value:{}, error: {}\".format(float(out), steer_angl[n],error[n]))\n    ","2eb48598":"print(\"Error -> Mean: {} min: {} max: {} variance: {}\".format(np.mean(error),min(error),max(error), np.var(error)))","9f0fe891":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.scatter(steer_angl, error )\n\nplt.xlabel('steering angles')\nplt.ylabel('error')\n\nplt.show()\n\nplt.savefig('.\/{}.jpg'.format('error_scatter_plot'))","3b9825aa":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.hist( error, 30 )\n\n#plt.xlabel('steering angles')\nplt.xlabel('error')\n\nplt.show()\n\nplt.savefig('.\/{}.jpg'.format('error_scatter_plot'))","f3e57734":"#show image function\ndef show_img(img_dir):\n    \n    try_img = cv2.imread(img_dir)\n    try_img = cv2.flip(try_img,1)\n    show_img = cv2.cvtColor(try_img,cv2.COLOR_BGR2RGB)\n    plt.imshow(show_img, cmap='hot')\n    #plt.set_cmap('hot')\n    plt.axis('off')","4df2b28d":"Show_img(train_img_dir[5005])\nprint(train_img_steer[5005])","49ed115c":"#obtain data from udacity dataset \nudacity_images_dir = []\nudacity_images_steering = []\n\nwith open('..\/input\/udacity-dataset\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    udacity_images_dir.append('..\/input\/udacity-dataset\/data\/'+ component[0] )\n    udacity_images_steering.append(float(line.split()[1].split(',')[0])\/360)\n\n","5ce47ba6":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.plot(udacity_images_steering)\n\nplt.xlabel('steering angles')\nplt.ylabel('error')\n\nplt.show()","1b12c9bc":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.hist( udacity_images_steering, 50 )\n\nplt.xlabel('steering angles')\nplt.title('Udacity dataset')\nplt.show()","83f98953":"len(udacity_images_steering)","809271ce":"Show_img(udacity_images_dir[17500])\nprint(udacity_images_steering[17500])","7ccf639f":"udacity_dataset = My_Dataset( udacity_images_dir, udacity_images_steering, transform=transforms.ToTensor())","44327672":"(udacity_dataset[0][0].shape)","54d414b8":"udacity_loader = torch.utils.data.DataLoader(\n                dataset=udacity_dataset,\n                batch_size=1,#1\n                num_workers=0,\n                shuffle=False\n                  )","01289944":"error = []#real - predcited\n\nfor n,( img, steer) in enumerate(udacity_loader):\n    if (n <= 25000) and( n >=23000):\n        out= model(img)\n        error.append(float(abs(float(out) - float(steer))))\n        if n%100==0:\n            print(\"model output: {}, dataset value:{}, error: {}\".format(float(out), float(steer),error[n-23000]))\n    ","8c4caac2":"print(\"Error -> Mean: {} min: {} max: {} variance: {}\".format(np.mean(error),min(error),max(error), np.var(error)))","80c53bc8":"carla_img_dir = []\ncarla_img_steer = []\n\nwith open('..\/input\/carla-dataset\/Carla_Dataset\/data.txt') as file:\n  for line in file:\n    component = line.split(' ')\n    carla_img_dir.append('..\/input\/carla-dataset\/Carla_Dataset\/output\/'+ component[1][:-1] + '.jpg')\n    carla_img_steer.append(float(component[0]))","290d583b":"len(carla_img_steer)","67a6b421":"fig = plt.figure()\nax = fig.add_axes([0,0,4,2])\n\nplt.plot(carla_img_steer[:3000])\n\nplt.xlabel('steering angles')\nplt.ylabel('error')\n\nplt.show()\n\n#plt.savefig('.\/{}.jpg'.format('error_scatter_plot'))","cc78da7a":"resume_dir(9, '..\/input\/model-1306-best')","7cea0d98":"list(model.children())","2944ab52":"no_of_layers=0\nconv_layers=[]\n\nmodel_children=list(model.children())\n\nfor child in model_children:\n  if type(child)==nn.Conv2d:\n    no_of_layers+=1\n    conv_layers.append(child)\n  elif type(child)==nn.Sequential:\n    for layer in child.children():\n      if type(layer)==nn.Conv2d:\n        no_of_layers+=1\n        conv_layers.append(layer)\n#print(no_of_layers)\n\nresults = [conv_layers[0](images[0].to(device))]\nfor i in range(1, len(conv_layers)):\n    results.append(conv_layers[i](results[-1]))\noutputs = results\n\n# visualize 8 features map from each layer \nfor num_layer in range(len(outputs)):\n    fig = plt.figure(figsize=(100, 50), frameon=False)\n    ax = fig.add_axes([0,0,4,2])\n    layer_viz = outputs[num_layer][0, :, :, :]\n    layer_viz = layer_viz.data\n    print(\"Layer \",num_layer+1)\n    for i, filter in enumerate(layer_viz):\n        if i == 8: \n            break\n        plt.subplot(2, 8, i + 1)\n        plt.imshow(filter)#, cmap='gray')\n        plt.axis(\"off\")\n    plt.show()\n    plt.close()","d0926d4b":"# Carla Dataset testing","a21345c1":"**Feature Map**","c421bc3d":"# Treating results","a8cd2864":"# Hyperparameters","55ab58b5":"# **Library install**","6f73689c":"# Model training","492a2410":"# Create Data Loaders","5ed6017b":"# Model definition","0ee97de5":"# Helping Functions","da57501e":"## Udacity Dataset","87360814":"## Carla Dataset"}}