{"cell_type":{"9d5730a8":"code","7cdc1f10":"code","2afd257f":"code","39b37c89":"code","295f500b":"code","fda1c078":"code","cf6efe17":"code","b4c7a1f1":"code","3929302b":"code","bc4162b5":"code","c8867282":"code","94b3a383":"code","76d9d623":"code","c740835c":"code","37ca8375":"code","624ee009":"code","7f07890c":"code","ec8e706b":"code","6c75871d":"code","793ebb68":"code","31ae3fd5":"code","0f671be4":"code","5aa00717":"code","2cfc9716":"code","d72f7628":"code","3ffe6e2f":"code","1b29520a":"code","df32e5a3":"code","2a7e6b17":"code","b11ec4d9":"code","a8285cc9":"code","811c56ef":"code","db2ecb4b":"code","585fd7c4":"code","97308e27":"code","381854c2":"code","d18623cb":"code","bbdf9462":"code","dcfead03":"code","78fd573d":"code","d6889a01":"code","ca94c57c":"code","11b7d383":"code","42a79602":"code","51189fbe":"code","14361054":"code","c680d9ae":"code","17639ea4":"code","c0b8e66e":"code","8ccb5d7c":"code","7dd76a12":"code","f8cee1f9":"code","35a7c0ae":"code","644e5a03":"code","5a0c40ca":"code","7d149423":"code","e4a778d3":"code","a2551d25":"code","f98a975f":"code","1721ca0c":"code","e6f75d80":"code","7fc24ecc":"code","d81fa7e2":"code","9e08ffe8":"code","43bc5585":"code","b495c651":"code","930cda2a":"code","5683272c":"code","2be8006b":"code","1851cfaf":"code","efa216e9":"code","9d860303":"code","f27d7582":"code","fae3b70a":"code","76d204de":"code","5d76ef48":"code","73a04b8e":"code","c4531dc0":"code","d553a67a":"code","6650222f":"code","314f36f6":"code","8da5291c":"code","98dea80b":"code","b2a75611":"code","760073d1":"code","ea465980":"code","12e93284":"code","2c982ed2":"code","c80e4e5d":"code","7eede148":"code","146c94f7":"code","82764f83":"code","1e0d2946":"code","f2d1f57b":"code","07047d78":"code","7ca7b8d5":"markdown","5e896a97":"markdown","744b4358":"markdown","4edcedea":"markdown","37bce50b":"markdown","756b29bb":"markdown","dd6274f6":"markdown","7581e015":"markdown","d69f6c75":"markdown","fc2be83a":"markdown","99b7133c":"markdown","34dd6d75":"markdown","9bf68f51":"markdown","c532d947":"markdown","25d46e69":"markdown","fa865b78":"markdown","fb3a8ceb":"markdown","69fe49d3":"markdown","b44f50ca":"markdown","c13915c1":"markdown","b6008161":"markdown","048f45d9":"markdown","45aa0f6f":"markdown","e56f316b":"markdown","714a02f2":"markdown","c38ae5c9":"markdown","0661dd74":"markdown","62749bf3":"markdown","e88bc7fa":"markdown","2998d010":"markdown","97748bd3":"markdown","e19b0483":"markdown","9ddc70a2":"markdown","b85f7e59":"markdown","f5e80cb3":"markdown","19a78d99":"markdown","bea60f27":"markdown","3403bc70":"markdown","03dc2c31":"markdown","d2883674":"markdown","79e06ad7":"markdown","74bbcd15":"markdown","df2e014b":"markdown","281e27a1":"markdown","e6825814":"markdown","86ed2531":"markdown","735e317c":"markdown","d7f7b04e":"markdown","5b30c0a6":"markdown","9e3ebd90":"markdown","2e417631":"markdown","e1aa7ab8":"markdown","5da26f67":"markdown","31b20187":"markdown","22f941c0":"markdown","6b191831":"markdown"},"source":{"9d5730a8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport torch ","7cdc1f10":"#we create some random input data\ninputs=torch.randn(1,5)\nprint(inputs,\"\\n\",inputs.shape)","2afd257f":"def no_activation(x):\n    return x","39b37c89":"def sigmoid(x):\n    return 1\/(1+torch.exp(x))","295f500b":"\nclass dense():\n    def __init__(self,input_d,units):\n        self.weights=torch.randn((input_d,units))\n        self.bias=torch.randn((1,units))\n    def __call__(self,inputs,activation=no_activation):\n        return activation(torch.mm(inputs,self.weights)+self.bias)","fda1c078":"class model():\n    def __init__(self,input_d):\n        self.layer1=dense(input_d,2)\n        self.layer2=dense(self.layer1.weights.shape[1],1)\n    def __call__(self,inputs):\n        h1= self.layer1(inputs,activation=sigmoid)\n        h2= self.layer2(h1,activation=sigmoid)\n        return h2","cf6efe17":"\ntorch.manual_seed(7)\nfeatures = torch.randn((1, 3))\nfirstnet=model(features.shape[1])\nfirstnet(features)","b4c7a1f1":"a=np.random.rand(4,3)\na","3929302b":"b=torch.from_numpy(a)\nb","bc4162b5":"b.mul_(2)","c8867282":"a","94b3a383":"b_nosharedmemory = torch.Tensor(a)","76d9d623":"b_nosharedmemory","c740835c":"b_nosharedmemory.mul_(2)","37ca8375":"a","624ee009":"b_nosharedmemory","7f07890c":"from torchvision import datasets,transforms\n\n\n\ntransform = transforms.Compose([transforms.ToTensor(),\n                              transforms.Normalize((0.5,), (0.5,)),\n                              ])\n# Download and load the data\ndata= datasets.MNIST('~\/.pytorch\/MNIST_data\/', download=True, train=True, transform=transform)\n","ec8e706b":"#this dataloader will split the data in batches of 64 samples and will shuffle them \ndataloader = torch.utils.data.DataLoader(data, batch_size=64, shuffle=True)","6c75871d":"dataiter = iter(dataloader)\nimages, labels = dataiter.next()\nprint(type(images))\nprint(images.shape)\nprint(labels.shape)","793ebb68":"plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');","31ae3fd5":"def softmax(x):\n    return torch.exp(x)\/torch.sum(torch.exp(x), dim=1).view(-1, 1)","0f671be4":"class model(object):\n    def __init__(self,input_d):\n        self.layer1=dense(input_d,256)\n        self.outputlayer=dense(self.layer1.weights.shape[1],10)\n    def __call__(self,inputs):\n        h1=self.layer1(inputs,activation=sigmoid)\n        out=self.outputlayer(h1,activation=softmax)\n        return out","5aa00717":"inputs = images.view(images.shape[0], -1)\ninputs.shape","2cfc9716":"mnist_net=model(inputs.shape[1])\noutputs=mnist_net(inputs)","d72f7628":"print(outputs.shape)\nprint(torch.sum(outputs,dim=1))","3ffe6e2f":"import torch.nn as nn\nclass model(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=nn.Linear(784,256)\n        self.out_Layer=nn.Linear(256,10)\n    def __call__(self,inputs):\n        h1=torch.sigmoid(self.layer1(inputs))\n        out=torch.softmax(self.out_Layer(h1),dim=1) #we will calculate the softamx by row \n        return out\n    ","1b29520a":"torchmodel=model(inputs.shape[1])\ntorchmodel","df32e5a3":"outputs=torchmodel(inputs)\noutputs.shape","2a7e6b17":"torch.sum(outputs,dim=1)","b11ec4d9":"import torch.nn.functional as F\nclass Model(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=nn.Linear(input_d,128)\n        self.layer2=nn.Linear(self.layer1.out_features,64)\n        self.out_layer=nn.Linear(self.layer2.out_features,10)\n    def __call__(self,inputs):\n        h1=F.relu(self.layer1(inputs))\n        h2=F.relu(self.layer2(h1))\n        out=torch.softmax(self.out_layer(h2),dim=1)\n        return out\n        \n        \n    ","a8285cc9":"relumodel=Model(inputs.shape[1])\nrelumodel","811c56ef":"torch.sum(relumodel(inputs),dim=1)\n","db2ecb4b":"\n# Build a feed-forward network\nmodel = nn.Sequential(nn.Linear(784, 128),\n                      nn.ReLU(),\n                      nn.Linear(128, 64),\n                      nn.ReLU(),\n                      nn.Linear(64, 10))\n\n# Define the loss\ncriterion = nn.CrossEntropyLoss()\n\n# Get our data\nimages, labels = next(iter(dataloader))\n# Flatten images\nimages = images.view(images.shape[0], -1)\n\n# Forward pass, get our logits\nlogits = model(images)\n# Calculate the loss with the logits and the labels\nloss = criterion(logits, labels)\n\nprint(loss)","585fd7c4":"\n# TODO: Build a feed-forward network\nmodel = nn.Sequential(nn.Linear(images.shape[1],250),\n                      nn.ReLU(),\n                      nn.Linear(250,120),\n                      nn.ReLU(),\n                      nn.Linear(120,10),\n                      nn.LogSoftmax(dim=1) \n                      #because we want to softmax by row (each row contains the score of a input), \n                      #we have 64 rows because our batch is of 64 samples\n                      )\n\n# TODO: Define the loss\ncriterion = nn.NLLLoss()\n\n\n# Forward pass, get our logits\nlogits = model(images)\nprint(logits.shape)\nprint(torch.sum(torch.exp(logits),dim=1))\n# Calculate the loss with the logits and the labels\nloss = criterion(logits, labels)\n\nprint(loss)","97308e27":"images.shape","381854c2":"tensor=torch.randn(2,2,requires_grad=True)\ntensor","d18623cb":"tensor.requires_grad=False\nprint(\"grads off:\\n\",tensor)\ntensor.requires_grad=True\nprint(\"grads on:\\n\",tensor)","bbdf9462":"with torch.no_grad():\n    y=tensor**2\ny.requires_grad","dcfead03":"print(tensor)\nwith torch.no_grad():\n    tensor=tensor**2\nprint(tensor)\ntensor.requires_grad=True","78fd573d":"tensor=torch.sqrt(tensor)\ntensor","d6889a01":"x=torch.randn(2,2,requires_grad=True)\nprint(f\"x: \\n{x}\")\ny=x**2\nprint(f\"y: \\n{y}\")\nz=torch.mean(y)\nprint(f\"z: \\n{z}\")\n","ca94c57c":"z.backward()\nprint(f\"gradients of z with respect x: \\n{x.grad}\")\nprint(f\"x\/2: \\n{x\/2}\")\n","11b7d383":"from torch import optim\n\nOptimizer = optim.SGD(model.parameters(),lr=0.01)","42a79602":"# Get our data\nimages, labels = next(iter(dataloader))\n# Flatten images\nimages = images.view(images.shape[0], -1)","51189fbe":"Optimizer.zero_grad()\noutput=model(images)\nloss=criterion(output,labels) #this is not reciprocable take care\nloss.backward()#we calculate the gradients of the loss with respect the parameters\nprint(f\"Weights before optimize(layer1): {model[0].weight}\")\nprint(f\"Example gradients(layer1): {model[0].weight.grad}\")","14361054":"Optimizer.step()\nprint(f\"Updated Weights after optimize(layer1): {model[0].weight}\")","c680d9ae":"from torchvision import datasets,transforms\n\n\n\ntransform = transforms.Compose([transforms.ToTensor(),\n                              transforms.Normalize((0.5,), (0.5,)),\n                              ])\n# Download and load the data\ndata= datasets.MNIST('~\/.pytorch\/MNIST_data\/', download=True, train=True, transform=transform)\ndataloader = torch.utils.data.DataLoader(data, batch_size=64, shuffle=True)\ndataloader.dataset.train_data.shape","17639ea4":"\n# TODO: Build a feed-forward network\nmodel = nn.Sequential(nn.Linear(784,250),\n                      nn.ReLU(),\n                      nn.Linear(250,120),\n                      nn.ReLU(),\n                      nn.Linear(120,10),\n                      nn.LogSoftmax(dim=1) \n                      #because we want to softmax by row (each row contains the score of a input), \n                      #we have 64 rows because our batch is of 64 samples\n                      )","c0b8e66e":"criterion = nn.NLLLoss()","8ccb5d7c":"def train(model,n_epochs,criterion):\n    Optimizer = optim.SGD(model.parameters(),lr=0.003)\n    for epoch in range(n_epochs):#epochs\n        epoch_loss=0\n        for images,labels in dataloader: #batches\n            Optimizer.zero_grad()\n            images=images.view(images.shape[0], -1)\n            predictions=model(images)\n            loss=criterion(predictions,labels)\n            loss.backward()\n            Optimizer.step()\n            epoch_loss+=loss.item()#we want just the number inside the tensor\n        print(f\"Epoch: {epoch} Training loss: {epoch_loss\/len(dataloader)}\")        ","7dd76a12":"train(model,5,criterion)","f8cee1f9":"def view_classify(img, ps, version=\"MNIST\"):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == \"MNIST\":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == \"Fashion\":\n        ax2.set_yticklabels(['T-shirt\/top',\n                            'Trouser',\n                            'Pullover',\n                            'Dress',\n                            'Coat',\n                            'Sandal',\n                            'Shirt',\n                            'Sneaker',\n                            'Bag',\n                            'Ankle Boot'], size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n","35a7c0ae":"%matplotlib inline\nimport helper\n\nimages, labels = next(iter(dataloader))\n\nimg = images[0].view(1, 784)\n# Turn off gradients to speed up this part\nwith torch.no_grad():\n    logps = model(img)\n\n# Output of the network are log-probabilities, need to take exponential for probabilities\nps = torch.exp(logps)\nview_classify(img.view(1, 28, 28), ps)","644e5a03":"import torch\nfrom torchvision import datasets, transforms\nimport helper\n\n# Define a transform to normalize the data\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,))])\n# Download and load the training data\ntrainset = datasets.FashionMNIST('~\/.pytorch\/F_MNIST_data\/', download=True, train=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n\n# Download and load the test data\ntestset = datasets.FashionMNIST('~\/.pytorch\/F_MNIST_data\/', download=True, train=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)","5a0c40ca":"import torch.nn.functional as F\nfrom torch import optim\n\nclass fashionModel(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=torch.nn.Linear(input_d,256)\n        self.nivel1Layer1 =torch.nn.Linear(256,80)\n        self.nivel1Layer2 =torch.nn.Linear(256,80)\n        self.Layer3=torch.nn.Linear(80+80,50)#we will concatenate the output of the 2 previous layers 200,200=400\n        self.Layer4=torch.nn.Linear(256+50,34)\n        self.outLayer=torch.nn.Linear(34,10)\n\n    \n    def forward(self,inputs):\n        h1=F.relu(self.layer1(inputs))\n        h2_1=F.relu(self.nivel1Layer1(h1))\n        h2_2=F.relu(self.nivel1Layer2(h1))\n        h3=F.relu(self.Layer3(torch.cat((h2_1,h2_2),dim=1)))\n        h4=F.relu(self.Layer4(torch.cat((h3,h1),dim=1)))\n        outputs=F.log_softmax(self.outLayer(h4),dim=1)\n        return outputs\n\n\n    def fit(self,batch_generator,num_epochs,criterion,Optimizer=None):\n        if not Optimizer:\n            Optimizer=optim.Adam(self.parameters(),lr=0.003)\n        train_samples=testloader.dataset.data.shape[0]\n        print(f\"{train_samples} training samples\")\n        for epoch in range(num_epochs):\n            epoch_loss=0\n            for images,labels in batch_generator:\n                Optimizer.zero_grad()#clean the gradients of the optimizer\n                outputs=self.forward(images.view(images.shape[0], -1))\n                loss=criterion(outputs,labels)#calculates the loss\n                loss.backward()#calculate the gradients of the loss with respect the model parameters\n                Optimizer.step()#we update the model parameters\n                epoch_loss+=loss.item()\n            print(f\"EPOCH:{epoch} loss:{epoch_loss}\")\n                ","7d149423":"x = torch.zeros(20,784, requires_grad=False)\nprint(\"Test tensor: \",x.shape)\nmodel=fashionModel(784)\nout=model(x)\nprint(\"Test output:\",out.shape)\nprint(\"Check if output its ok (sum1):\\n\",torch.sum(torch.exp(out),dim=1))","e4a778d3":"criterion = torch.nn.NLLLoss()","a2551d25":"model.fit(trainloader,7,criterion)","f98a975f":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport helper\n\n# Test out your network!\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[0]\n# Convert 2D image to 1D vector\nimg = img.resize_(1, 784)\n\n# TODO: Calculate the class probabilities (softmax) for img\nps=torch.exp(model(img))\nprint(ps)\n# Plot the image and probabilities\nview_classify(img.resize_(1, 28, 28), ps, version='Fashion')","1721ca0c":"pip install hiddenlayer","e6f75d80":"import hiddenlayer as hl\nhl.build_graph(model, torch.zeros(1, 784))","7fc24ecc":"dataiter = iter(testloader)\nimages, labels = dataiter.next()","d81fa7e2":"with torch.no_grad(): #we don't need grads in the predictions so let's speed up this part\n    predictions=model(images.view(images.shape[0],-1))\n    predictions=torch.exp(predictions)","9e08ffe8":"probabilities,p_classes=predictions.topk(1,dim=1) #to pickup the top 1 of the row (since each row is a probability vector of the image)","43bc5585":"print(p_classes.shape,\"\\n\",p_classes[:10])","b495c651":"print(labels.shape,\"\\n\",labels[:10])","930cda2a":"equals = p_classes.squeeze(1) == labels","5683272c":"print(f\"Accuracy: {torch.mean(equals.type(torch.FloatTensor)).item()*100}\")","2be8006b":"import torch.nn.functional as F\nfrom torch import optim\n\nclass fashionModel(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=torch.nn.Linear(input_d,256)\n        self.nivel1Layer1 =torch.nn.Linear(256,80)\n        self.nivel1Layer2 =torch.nn.Linear(256,80)\n        self.Layer3=torch.nn.Linear(80+80,50)#we will concatenate the output of the 2 previous layers 200,200=400\n        self.Layer4=torch.nn.Linear(256+50,34)\n        self.outLayer=torch.nn.Linear(34,10)\n\n    \n    def forward(self,inputs):\n        h1=F.relu(self.layer1(inputs))\n        h2_1=F.relu(self.nivel1Layer1(h1))\n        h2_2=F.relu(self.nivel1Layer2(h1))\n        h3=F.relu(self.Layer3(torch.cat((h2_1,h2_2),dim=1)))\n        h4=F.relu(self.Layer4(torch.cat((h3,h1),dim=1)))\n        outputs=F.log_softmax(self.outLayer(h4),dim=1)\n        return outputs\n    \n    def accuracy(self,predictions,labels):\n        predictions=torch.exp(predictions)#as we have log softmax at the end we need to calculate te actual outputs\n        probabilities,p_classes=predictions.topk(1,dim=1) #to pickup the top 1 of the row (since each row is a probability vector of the image)\n        equals = p_classes.squeeze(1) == labels\n        return torch.mean(equals.type(torch.FloatTensor)).item()\n    #todo\n    def metrics():\n        pass\n        \n\n    def fit(self,batch_generator,criterion,num_epochs=20,Optimizer=None,validation_generator=None):\n        if not Optimizer:\n            Optimizer=optim.Adam(self.parameters(),lr=0.003)\n        train_batch_size=len(batch_generator)\n        train_metrics=[] #(loss,accuracy) size:number of batches\n        if validation_generator:\n            val_batch_size=len(validation_generator)\n            val_metrics=[] #(loss,accuracy) size:number of batches\n        for epoch in range(num_epochs):\n            epoch_train_loss=0\n            epoch_train_accuracy=0\n            for images,labels in batch_generator:\n                Optimizer.zero_grad()#clean the gradients of the optimizer\n                outputs=self.forward(images.view(images.shape[0], -1))\n                loss=criterion(outputs,labels)#calculates the loss\n                loss.backward()#calculate the gradients of the loss with respect the model parameters\n                Optimizer.step()#we update the model parameters\n                accuracy=self.accuracy(outputs,labels)\n                epoch_train_loss+=loss.item()\n                epoch_train_accuracy+=accuracy\n            train_metrics.append((epoch_train_loss\/train_batch_size,epoch_train_accuracy\/train_batch_size))\n            print(f\"EPOCH:{epoch}\\nTrain loss:{train_metrics[-1][0]:.3f}.. Train accuracy:{train_metrics[-1][1]:.3f}..\")\n            if validation_generator:\n                epoch_val_loss=0\n                epoch_val_accuracy=0\n                with torch.no_grad():\n                    for images_val,labels_val in validation_generator:\n                        outputs=self.forward(images_val.view(images_val.shape[0],-1))\n                        val_loss=criterion(outputs,labels_val)\n                        val_accuracy=self.accuracy(outputs,labels_val)\n                        epoch_val_loss+=val_loss.item()\n                        epoch_val_accuracy+=val_accuracy\n                val_metrics.append((epoch_val_loss\/val_batch_size,epoch_val_accuracy\/val_batch_size))\n                print(f\"Validation loss:{val_metrics[-1][0]:.3f}.. Validation accuracy:{val_metrics[-1][1]:.3f}..\")\n        if validation_generator:\n            return train_metrics,val_metrics\n        else:\n            return train_metrics","1851cfaf":"model=fashionModel(784)\ncriterion = torch.nn.NLLLoss()\ntrain_metrics,val_metrics=model.fit(trainloader,criterion,validation_generator=testloader)","efa216e9":"import matplotlib.pyplot as plt\ndef plot_train_history(train_metrics,val_metrics):\n    train_loss,train_accuracy = zip(*train_metrics)\n    val_loss,val_accuracy = zip(*val_metrics)\n    plt.plot(train_loss, label='Training loss')\n    plt.plot(val_loss, label='Validation loss')\n    plt.legend(frameon=False)\n    plt.show()\n    plt.plot(train_accuracy, label='Training accuracy')\n    plt.plot(val_accuracy, label='Validation accuracy')\n    plt.legend(frameon=False)\n    plt.show()","9d860303":"plot_train_history(train_metrics,val_metrics)","f27d7582":"import torch.nn.functional as F\nfrom torch import optim\n\nclass fashionModel(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=torch.nn.Linear(input_d,256)\n        self.nivel1Layer1 =torch.nn.Linear(256,120)\n        self.nivel1Layer2 =torch.nn.Linear(256,120)\n        self.Layer3=torch.nn.Linear(self.nivel1Layer1.out_features+\n                                    self.nivel1Layer2.out_features,\n                                    50)#we will concatenate the output of the 2 previous layers 200,200=400\n        self.Layer4=torch.nn.Linear(self.layer1.out_features\n                                    +self.Layer3.out_features,\n                                    34)\n        self.outLayer=torch.nn.Linear(34,10)\n        \n        self.dropout=torch.nn.Dropout(p=0.6)\n\n    \n    def forward(self,inputs):\n        h1= F.relu(self.layer1(inputs))\n        h2_1= self.dropout(F.relu(self.nivel1Layer1(h1)))\n        h2_2= self.dropout(F.relu(self.nivel1Layer2(h1)))\n        h3= self.dropout(F.relu(self.Layer3(torch.cat((h2_1,h2_2),dim=1))))\n        h4= self.dropout(F.relu(self.Layer4(torch.cat((h3,h1),dim=1))))\n        outputs=F.log_softmax(self.outLayer(h4),dim=1)\n        return outputs\n    \n    def accuracy(self,predictions,labels):\n        predictions=torch.exp(predictions)#as we have log softmax at the end we need to calculate te actual outputs\n        probabilities,p_classes=predictions.topk(1,dim=1) #to pickup the top 1 of the row (since each row is a probability vector of the image)\n        equals = p_classes.squeeze(1) == labels\n        return torch.mean(equals.type(torch.FloatTensor)).item()\n        #todo\n    def metrics():\n        pass\n        \n\n    def fit(self,batch_generator,criterion,num_epochs=20,Optimizer=None,validation_generator=None):\n        if not Optimizer:\n            Optimizer=optim.Adam(self.parameters(),lr=0.003)\n        train_batch_size=len(batch_generator)\n        train_metrics=[] #(loss,accuracy) size:number of batches\n        if validation_generator:\n            val_batch_size=len(validation_generator)\n            val_metrics=[] #(loss,accuracy) size:number of batches\n        for epoch in range(num_epochs):\n            epoch_train_loss=0\n            epoch_train_accuracy=0\n            self.train()#we put our model in train mode (we enable dropout)\n            for images,labels in batch_generator:\n                Optimizer.zero_grad()#clean the gradients of the optimizer\n                outputs=self.forward(images.view(images.shape[0], -1))\n                loss=criterion(outputs,labels)#calculates the loss\n                loss.backward()#calculate the gradients of the loss with respect the model parameters\n                Optimizer.step()#we update the model parameters\n                accuracy=self.accuracy(outputs,labels)\n                epoch_train_loss+=loss.item()\n                epoch_train_accuracy+=accuracy\n            train_metrics.append((epoch_train_loss\/train_batch_size,epoch_train_accuracy\/train_batch_size))\n            print(f\"EPOCH:{epoch}\\nTrain loss:{train_metrics[-1][0]:.3f}.. Train accuracy:{train_metrics[-1][1]:.3f}..\")\n            if validation_generator:\n                epoch_val_loss=0\n                epoch_val_accuracy=0\n                with torch.no_grad():\n                    self.eval()#we enter to evaluation mode so dropout isn't enabled\n                    for images_val,labels_val in validation_generator:\n                        outputs=self.forward(images_val.view(images_val.shape[0],-1))\n                        val_loss=criterion(outputs,labels_val)\n                        val_accuracy=self.accuracy(outputs,labels_val)\n                        epoch_val_loss+=val_loss.item()\n                        epoch_val_accuracy+=val_accuracy\n                val_metrics.append((epoch_val_loss\/val_batch_size,epoch_val_accuracy\/val_batch_size))\n                print(f\"Validation loss:{val_metrics[-1][0]:.3f}.. Validation accuracy:{val_metrics[-1][1]:.3f}..\")\n        if validation_generator:\n            return train_metrics,val_metrics\n        else:\n            return train_metrics","fae3b70a":"model=fashionModel(784)\ncriterion = torch.nn.NLLLoss()\ntrain_metrics,val_metrics=model.fit(trainloader,criterion,validation_generator=testloader)","76d204de":"plot_train_history(train_metrics,val_metrics)","5d76ef48":"from pprint import pprint\nprint(f\"Model description {model}\")\nprint(\"\\nModel Parameters:\")\nfor p,v in model.state_dict().items():\n    print(f\"{p: <20}--->  {v.type(),v.shape}\")\n    \n    ","73a04b8e":"torch.save(model.state_dict(),'model_checkpoint.pth')","c4531dc0":"model=fashionModel(784)\nprint(\"New model:\\n\",list(model.state_dict().items())[-1])\ncheckpoint=torch.load('model_checkpoint.pth')\nmodel.load_state_dict(checkpoint)\nprint(\"Restored model:\\n\",list(model.state_dict().items())[-1])\n","d553a67a":"!ls -l ..\/input\/dataset\/dataset\/","6650222f":"from torchvision import datasets,transforms\n\ntransform = transforms.Compose([transforms.Resize(255),#resizes the image\n                                transforms.CenterCrop(224),#crops the image from the center\n                                transforms.ToTensor(),#converts to tensors\n                                transforms.Normalize((0.5,), (0.5,)),#normalize(scale) the tensors\n                              ])\n","314f36f6":"train_data = datasets.ImageFolder(\"..\/input\/dataset\/dataset\/training_set\", transform=transform)\ntrain_generator = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\nprint(f\"Training Data: {train_generator.dataset}\\nClasses:{train_generator.dataset.classes}\")","8da5291c":"val_data = datasets.ImageFolder(\"..\/input\/dataset\/dataset\/test_set\", transform=transform)\nval_generator = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\nprint(f\"Validation Data: {val_generator.dataset}\\nClasses:{val_generator.dataset.classes}\")","98dea80b":"## we will change only apply data augmentation in our train set\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),#rotates our images randmly in 0 to 30 degrees\n                                       transforms.RandomResizedCrop(224), #will resize and crop our images randmly in pictures of size 224\n                                       transforms.RandomHorizontalFlip(),#will flip random images horizontally\n                                       transforms.ToTensor()]) #transforms our images to tensors\ntrain_data = datasets.ImageFolder(\"..\/input\/dataset\/dataset\/training_set\", transform=train_transforms)\ntrain_generator = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\nprint(f\"Training Data: {train_generator.dataset}\\nClasses:{train_generator.dataset.classes}\")","b2a75611":"def imshow(image, ax=None, title=None, normalize=True):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax","760073d1":"# change this to the trainloader or testloader \ndata_iter = iter(train_generator)\ndata_iter_val = iter(val_generator)\n\nimages, labels = next(data_iter)\nfig, axes = plt.subplots(figsize=(10,4), ncols=4)\nfig.suptitle('Training Images')\nfor ii in range(4):\n    ax = axes[ii]\n    imshow(images[ii], ax=ax, normalize=False)\n    \nimages, labels = next(data_iter_val)\nfig, axes = plt.subplots(figsize=(10,4), ncols=4)\nfig.suptitle('Validation Images')\nfor ii in range(4):\n    ax = axes[ii]\n    imshow(images[ii], ax=ax, normalize=False)\n","ea465980":"from torch import nn\nfrom torch import optim\nfrom torch import functional as F\nfrom torchvision import models","12e93284":"model = models.resnet50(pretrained=True)\nmodel","2c982ed2":"from collections import OrderedDict\nnewClassifier=nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(2048, 512)),\n                          ('relu', nn.ReLU()),\n                          ('Dropout2',nn.Dropout(0.2\n                                                )),\n                          ('fc2', nn.Linear(512, 2)),\n                          ('output', nn.LogSoftmax(dim=1)) #compute logsoftmax over rows\n                          ]))","c80e4e5d":"for p in model.parameters():\n    p.requires_grad=False\ni=iter(model.parameters())\nnext(model.parameters()).requires_grad","7eede148":"model.fc=newClassifier\nmodel.fc","146c94f7":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","82764f83":"#model.cuda() #move the paameters of the model to the gpu memory \n#images.cuda()","1e0d2946":"import time\n\nfor device  in [\"cuda\",\"cpu\"]:\n    criterion = nn.NLLLoss()#negative log-likelihood\n    optimizer = optim.Adam(model.fc.parameters(),lr=0.001) # we only want to optimize(train) the classifier parameters\n    #lets training for 3 samples and compare the times\n    model.to(device)\n    for i ,(images,labels) in enumerate(train_generator):\n        images,labels = images.to(device),labels.to(device)\n        start=time.time()\n        outputs = model(images)\n        loss=criterion(outputs,labels)\n        loss.backward()# we compute the gradients with respect the lost and store it in the model parameters.grad\n        optimizer.step()# we update the parameters using our gradients\n        if i==4:\n            break\n    print(f\"Device = {device}; Time per batch: {(time.time() - start)\/4:.3f} seconds\")\n        ","f2d1f57b":"from tqdm import tqdm_notebook as tqdm\ndef f_accuracy(predictions,labels):\n    top_p, top_class = predictions.topk(1, dim=1)\n    equals = top_class == labels.view(*top_class.shape)\n    return torch.mean(equals.type(torch.FloatTensor)).item()\n    \ndef fit(model,train_generator,val_generator,optimizer,epochs=1,verbose=5,device='cuda',f_accuracy=f_accuracy):\n    model.to(device)\n    steps = 0\n    running_loss = 0\n    running_accuracy = 0\n    for epoch in range(epochs):\n        for inputs, labels in tqdm(train_generator,desc=\"Train Step\"):\n            steps += 1\n            # Move input and label tensors to the default device\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()#clean the optimizer gradients\n            logps = model.forward(inputs)\n            loss = criterion(logps, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            if steps % verbose == 0:\n                test_loss = 0\n                test_accuracy = 0\n                model.eval()\n                with torch.no_grad():\n                    for inputs, labels in tqdm(val_generator,desc=\"validation step\"):\n                        inputs, labels = inputs.to(device), labels.to(device)\n                        logps = model.forward(inputs)\n                        batch_loss = criterion(logps, labels)\n                        test_loss += batch_loss.item()\n                        # Calculate accuracy\n                        accuracy=f_accuracy(torch.exp(logps),labels)\n                        test_accuracy += accuracy\n                print(f\"Epoch: {epoch+1}\/Step: {steps}.. \"\n                      f\"Train loss: {running_loss\/verbose:.3f}.. \"\n                      f\"Val loss: {test_loss\/len(val_generator):.3f}.. \"\n                      f\"Val accuracy: {test_accuracy\/len(val_generator):.3f}\")\n            if steps>25:\n                break\n            running_loss = 0\n            model.train()","07047d78":"model = models.resnet50(pretrained=True)\nfor p in model.parameters():\n    p.requires_grad=False\nnewClassifier=nn.Sequential(nn.Linear(2048, 512),\n                                         nn.ReLU(),\n                                         nn.Dropout(0.2),\n                                         nn.Linear(512,2),\n                                         nn.LogSoftmax(dim=1) #compute logsoftmax over rows\n                                        )\nmodel.fc=newClassifier\noptimizer = optim.Adam(model.fc.parameters(), lr=0.003)\nval_metrics =fit(model,train_generator,val_generator,optimizer)","7ca7b8d5":" it's more convenient to build the model with a log-softmax output ,then you can get the actual probabilities by taking the exponential torch.exp(output). With a log-softmax output, we should use  to use the negative log likelihood loss\n \n \nThe softmax function returns probabilities between [0, 1].\nThe log of these probabilities returns values between [-inf, 0], since log(0) = -inf and log(1) = 0.\nThat is why the order won\u2019t change.\n\nHowever, you should use the NLLLoss with a log_softmax output\nor CrossEntropyLoss with logits if you prefer not to add an extra log_softmax layer into your model.","5e896a97":"then we need to \"freeze\" all the weights of the mobilenet and replace the classifier with out custom model, in this way we will not track the operations and calculate gradients to those layers and also tell the optimizer not to update the weights,so then we can use those ways to extract features and then classifying the images using our custom classifier.","744b4358":"the simplest way to do it is by simply save the ```state_dict()``` with ```torch.save(\"path.pth\")``` where the .pth extension is the common extension for torch checkpoints ","4edcedea":"in this case we see the torch wil track the operations in the tensor since we stablish requieres_grad as True\nwe can also globally enable or disable grads globally using \n```python\ntorch.set_grad_enabled(True|false)\n```","37bce50b":"![](http:\/\/)","756b29bb":"Then using this optimizer we can actually train our network:\nfirst we need two perfom a feedforward pass, calculate the loss with those values, then backpropagate to calculate our gradients (backward pass) and finally update our parameters(weights and biases)\n","dd6274f6":"Let's build a model and calculate the loss noticed that we calculate the loss with the output scores and not whit the probabilities coming from the activation function (softmax)","7581e015":"in order to get the predicted class since our predictions give us a probability for each class we can pickup the highest probability using the method .topk(n,dim) of our prediction tensors, this method returns a tuple (value,index) so for us will be (probability,class) ","d69f6c75":"we will apply exp to all the elements in our data, then we know each row of our data is a prediction, so we should sum by rows (in dim=1) and also in order to divide 10 values by 10 values we should transpose that summaroty of the rows two divide the the row by a value ","fc2be83a":"the we just calculate the mean of corectly classified samples\nnote*: we cast the equals vector to a float vector in order to get a float division and not a integer division","99b7133c":"#this is how our images locks like","34dd6d75":"# Transfer learning\n\nwe want to work whit this data set so torch already provides us a lot of models that perfoms very well on image classification tasks in the torch.vision package ,since this models has been trained in recognize 1000 different types of objects they provide a strong and robust set of kernels to recognize patters and shapes on images, then so, we just need to re train the classifier part of the network in order to recognize our classes.\n\nIn this case I pickup the mobilenet_v2 since it provides a lightweight and accurate network architecture","9bf68f51":"Ok now lets put all togheter below, first lets import our data,define our model, define our loss, create and optimizer and code the training loop","c532d947":"In torch NLLoss allows to pass our prediction as a vector of probabilities [y1,y2,...yn] where n is the number of classes and our actual labels as simple numbers instead of having to one hot encoding it","25d46e69":"So then to perfom the gradients of z with respect x we must perfom z.backward() and check the result in x.grad, we know that the derivative with respect of x of z are x\/2 so lets check if are the same","fa865b78":"Implementing the basic dense layer","fb3a8ceb":"# Tensors\nTorch use tensors to represent data in a very efficent way, you can perfom several mathematical operations efficiently and fast","69fe49d3":"## Optimizers\n\nThen  we know that in this way we can calculate the gradients of the loss and then update our parameters.\nPytorch provides a set of optimizers that made this process automatically, such as stochastic gradient descent or adam.","b44f50ca":"So then let's move into a complex model, so we are trying to predict over 10 different classes of clothes where also there is more vaiance in the data","c13915c1":"The we are ready to retrain our network so as we doo before we will only train the classifier module that we have replace in order to use the model for our task","b6008161":"# Loading Data\n\nAs we have seen before pytorch includes a dataset tool to load and preprocess data\n","048f45d9":"We can build neural networks perfoming the corresponding mathematical operations between tensors for example let's say we want to create a single layer network with 3 hidden units (neurons) and 4 inputs so\nin this case our inputs X should be multiplied by the weight matrix W of the layer \n$$\n\\begin{equation*}\n{X} \\times {W}= \\begin{bmatrix}\n\\mathbf{x}_1 & \\mathbf{x}_2 & \\mathbf{x}_3 & \\mathbf{x}_4\\\\\n\\end{bmatrix}\n\\times\n\\begin{vmatrix}\n\\mathbf{h}_1 & \\mathbf{h}_2 & \\mathbf{h}_3 \\\\\n{w}_{11}&{w}_{21}&{w}_{31}\\\\\n{w}_{12}&{w}_{22}&{w}_{32}\\\\\n{w}_{13}&{w}_{23}&{w}_{33}\\\\\n{w}_{14}&{w}_{24}&{w}_{34}\n\\end{vmatrix}\n\\end{equation*}\n$$\nWhere each column of W represent the 4 weights of a hidden unit $$h_{1-3}$$ corresponding to each input $$x_{1-4}$$ \n\nW will have as many columns as neurons and as many rows as inputs,we are performing the dot product of each column and the inputs to get a score for each neuron,those scores will be stored in a hidden vector h\n\nthen we will sum the bias to the hidden state vector h = X * W \n$$\n\\begin{bmatrix}\n\\mathbf{h}_1 & \\mathbf{h}_2 & \\mathbf{h}_3 \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\mathbf{b}_1 & \\mathbf{b}_2 & \\mathbf{b}_3 \\\\\n\\end{bmatrix}\n$$\nat the end our network will be \n$$\n\\mathbf{Y}_{prediction}=W\\times X + b\n$$\n\n","45aa0f6f":"Lets create a neural net two solve the mnist from of predict the number appearing on an image","e56f316b":"let's implement the validation step in the trainig pass","714a02f2":"Autograd\n\nAutograd allow us to track the operations done on a tensor and when you tell it to do a backward pass , it will go backwards  trought  each of these operations and calculate the gradients whit resect to the input parameters ","c38ae5c9":"Unfortunally this method only stored the parameters matrices of the model so we need to rewrite the model in the same way we trained it,we can preserve other information about the architecture creating a dictionary that contains the kind of layers, the input\/output shape,etc and then define how the network should be constructed.","0661dd74":"### Accuracy\nwe'll calculate the accuracy on our test set for our previous model","62749bf3":"# GPU Training \ntorch provides us a cuda mode to train our models over gpu's that parallelize the linear algebra computations over 1000x times \n\n```cuda()``` moves our model parameters and tensors to the gpu memory, we can also move it back to the cpu using ```cpu()``` or alternativily model|tensor.todevice(device)","e88bc7fa":"Then we will charge our data also applying the transform pipeline we defined before\nwe use te ```datasets.ImageFolder``` from torchvision which takes the data from a ```\"path\"``` folder then it searches for subfolders and labels the data as the name of the folder\n\n```\/path\/dogs\/hjkhkj.jpg -> dogs\n   \/path\/cats\/hjkhkj.jpg -> cats```\n\nThen we will use a dataloader to generate batches of size 64 and shuffle our data","2998d010":"There is a serious improvement using GPU instead of cpu for parallelisation\nso then we are actually perfoming the training of the model an see how it performs","97748bd3":"lets train the model remeber we have a batch generator or training called  trainloader and another for validation called testloader","e19b0483":"In torch you need to indicate that you require to calculate the gradients of a tensor","9ddc70a2":"You also can turn the grads of and turn in on again on a tensor","b85f7e59":"Using the nn module to create models","f5e80cb3":"Lets build a more complex architecture also using other activation functions such as ReLU","19a78d99":"applying dropout to our models could improve generalization significantly cause we force the neurons to learn important relationships and share information throught layers.\n\nin the case of our model we have a lot of parameters because of the paralel layers concatenation and the residual conection, so in this case the model could find hard to find  important relationships in such a varianced dataset algo we are maybe training a lot of not relevant relationships so dropout especially in the concatenation layers could help to find important relationship in all those neurons","bea60f27":"## Preprocessing\nPytorch vision provides use several tranformations to apply to our data we just need to define a preprocessing pipeline","3403bc70":"Then after calculate the loss and it's gradients we use our optimizer to update te parameters \nit's important to clean the gradients of the Optimizer cause they maybe acumulated (clean it before calulate the gradients of the loss) if you clean it here you will delete the new gradients","03dc2c31":"in this case the new tensor will share mamoery whit the numpy array so wherever change we made in any of them will affect each other","d2883674":"\n\nAs we can see the data loader iterates giving us a batch of 64  images  each time","79e06ad7":"Creating a simple model using 1 hidden layer with two neurons and and output layer with one neuron ","74bbcd15":"We can also create new tensor from numpy arrays without sharing memory between them, so this new tensor will have its own memory, and the changes on it will not affect the numpy array","df2e014b":"# Saving and loading models\nwe can save a model in order to use it for predictions in the future or even continue training or editing some parts the parameters(weights,bias matrices and more ..) of a torch.nn.Module can be obtained with ```state_dict() ```","281e27a1":"we use nn.dropout to turn off some percentage of the model during training and force the netork to share information between layer and not only train some of them\n\nwe can unable dropout to enter in evaluation mode using model.eval() and enable again for training using model.train()","e6825814":"We defined a transform to normalize the data , we are going to tranform each image to a vectorand also normalize it in a range of [-1,1] (standart normal distribution) image = (image - mean) \/ std the function normalize recieves two parameters mean and std in our case mean=0.5 and std=0.5 this normalization provides a better workfield to gradient descent since in the end we want to capture the distribution of the data its easier to capture a normal distribution 0 mean and equal variance","86ed2531":"[](http:\/\/)","735e317c":"we can create tensors from numpy arrays ","d7f7b04e":"## Data Augmentation\nWe can also use the torch transforms to perfom Data Augmentation which is a technique that allow us to introduce randomness in our data in order not only to increase our training data but also to teach our model how to perfom in very difficult enviroments low light, high contrast, different perspectives and rotations, etc.","5b30c0a6":"you can also use contexts to control the grads tracking","9e3ebd90":"then we can load the parameters to the network again by open the file, charging the checkpoint to a dict and then loading it using model.load_state_dict","2e417631":"we are going to replace the classifier on our network with a custom architecture capable of recognize two classes  ","e1aa7ab8":"## Validation\nWe also have to validate our models using some matrics in order to know if is generalizing well or  if we have to implement some techniques to improve generalization such as dropout or L regularizations","5da26f67":"then let's say we have a function \n$$\ny=x^2\n$$\n\nand also\n$$\nz = \\left[\\frac{1}{n}\\sum_i^n y_i\\right]\n$$\n\nso then we want to calculate the gradients of z with respect x\n\n$$\n\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n$$\n\nwe can easily perfom this with autograd in pytorch","31b20187":"As we can see there is a serious overfitting in the model let's try to use some generalization techniques to improve the perfomance of the model","22f941c0":"finally we replace the mobilenet classifier with ours in order to train it for our task","6b191831":"then we want two know how many samples have been correctly classified so to perfom == operations p_classes and labels should have the same shapes so we can squeeze p_classes or unsqueeze labels (also view(*p_classes.shape)"}}