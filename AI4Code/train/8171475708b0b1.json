{"cell_type":{"2f631ae3":"code","19a7224e":"code","15be0e2d":"code","38cd8eea":"code","ec5b44ba":"code","81e3cb23":"code","5480a44b":"code","43d5febb":"code","9310d39c":"code","bfd8e5d9":"code","248fbb61":"code","aab8af46":"code","b9164f3a":"code","395c313f":"code","1bb3518f":"code","f3c38f85":"code","22b2face":"code","adeb3cf2":"code","21b6bf62":"code","d090102f":"code","d0156d14":"code","50539064":"code","31f49272":"code","3fd6cc79":"code","2808ee1a":"code","c0c04649":"code","614ec597":"code","61968092":"code","37d9400c":"code","cce73e95":"code","3d2eb514":"code","803eff07":"markdown","41829354":"markdown","4f10593c":"markdown","beabb67c":"markdown","a0940104":"markdown","509dcf8e":"markdown"},"source":{"2f631ae3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix","19a7224e":"# Define direktory\ntrain_dir = '..\/input\/labeled-chest-xray-images\/chest_xray\/train'\nval_dir = '..\/input\/labeled-chest-xray-images\/chest_xray\/test'","15be0e2d":"# Visualize Image before Image Augmentation\ntrain_pneumonia_img = glob(train_dir+'\/PNEUMONIA\/*.jpeg') # Load all pneumonia images from train directory\ntrain_normal_img = glob(train_dir+'\/NORMAL\/*.jpeg') # Load all normal images frin train directory","38cd8eea":"pneumonia = np.asarray(plt.imread(train_pneumonia_img[0]))\nnormal = np.asarray(plt.imread(train_normal_img[0]))","ec5b44ba":"plt.title('PNEUMONIA', fontsize=20, color='white')\nplt.imshow(pneumonia)\nprint(pneumonia.shape) # print image size","81e3cb23":"plt.title('NORMAL', fontsize=20, color='white')\nplt.imshow(normal)\nprint(normal.shape) # print image size","5480a44b":"# ImageDataGenerator for training and test\ndatagen = ImageDataGenerator(validation_split = 0.25, \n                             rescale=1.\/255, \n                             rotation_range = 30, \n                             zoom_range = 0.15, \n                             width_shift_range=0.15, \n                             height_shift_range=0.15, \n                             horizontal_flip=False,\n                             vertical_flip=False)\n# ImageDataGenerator for val set\nval_datagen = ImageDataGenerator(rescale=1.\/255)","43d5febb":"IMG_SIZE = (227, 227)\ntrain_set = datagen.flow_from_directory(train_dir, \n                                        subset= 'training',\n                                        class_mode='binary', \n                                        batch_size= 32,\n                                        target_size=IMG_SIZE)","9310d39c":"test_set = datagen.flow_from_directory(train_dir, \n                                        subset= 'validation',\n                                        class_mode='binary', \n                                        batch_size= 32,\n                                        target_size=IMG_SIZE)","bfd8e5d9":"X_train, y_train = train_set.next()\nX_test, y_test = test_set.next()","248fbb61":"print(len(X_train), len(y_train))","aab8af46":"print('Train X=%s Y=%s' %(X_train.shape, y_train.shape))\nprint('Test X=%s Y=%s' %(X_test.shape, y_test.shape))","b9164f3a":"\n\nlabels = ['Normal' if label == 0 else 'Pneumonia' for label in y_train]\nsns.countplot(labels)","395c313f":"for idx in range(10):\n    plt.figure(figsize=(5, 5))\n    plt.imshow(X_train[idx])\n    plt.title(labels[idx])","1bb3518f":"X_train[0].shape","f3c38f85":"# Create callbacks for our model\n\n# Create checkpoint callback\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint('model_alex_net.h5') \n\n# Create Custom callback\nclass CustomCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy') > 0.93 and logs.get('val_accuracy') > 0.93) and (logs.get('loss')<= 0.3 and logs.get('val_loss') <= 0.3):\n            if logs.get('accuracy') <= logs.get('val_accuracy'):\n                self.model.stop_training = True\n            else:\n                self.model.stop_training = False\n#             if(logs.get('accuracy') > 0.94 and logs.get('val_accuracy') > 0.94) and (logs.get('loss')<= 0.3 and logs.get('val_loss') <= 0.3):\n\ncustom_cb = CustomCallback()","22b2face":"# Define alexNet model\n\n\nmodel_alex_net = tf.keras.models.Sequential([\n     # 1st conv layer                                        \n    tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3),\n                           padding='valid'),\n    tf.keras.layers.BatchNormalization(),\n    # Max pooling\n    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n    \n    # # Dropout to prevent overfit\n    # tf.keras.layers.Dropout(0.5),\n\n    # 2nd conv layer\n    tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n\n    # Max pooling\n    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n\n    # # Dropout to prevent overfit\n    # tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.BatchNormalization(),\n    # 3rd conv layer\n    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    # 4th Conv layer\n    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    # 5th Conv layer\n    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    # Max Pooling\n    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    # Dropout to prevent overfit\n    tf.keras.layers.Dropout(0.5),\n\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(4096, activation='relu'),\n    # # Dropout to prevent overfit\n    # tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(4096, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    # Dropout to prevent overfit\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","adeb3cf2":"# Look at summary of our model\nmodel_alex_net.summary()","21b6bf62":"model_alex_net.compile(loss='binary_crossentropy', optimizer =tf.optimizers.Adam(), metrics=['accuracy'])","d090102f":"hist = model_alex_net.fit(\n    train_set,\n    validation_data = test_set,\n    epochs = 32,\n    callbacks=[custom_cb, checkpoint_cb]\n)","d0156d14":"# Plot accuracy and loss\n\n\nplt.subplot(211)\nplt.title('Binary Crossentropy Loss')\nplt.plot(hist.history['loss'], color ='red', label='train')\nplt.plot(hist.history['val_loss'], color ='green', label='val')\n\nplt.subplot(212)\nplt.title('Classification Accuracy')\nplt.plot(hist.history['accuracy'], color='red', label='train')\nplt.plot(hist.history['val_accuracy'], color='green', label='test')\n\nplt.show()","50539064":"# ImageDataGenerator for val set\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Create val dataset\nval_set = val_datagen.flow_from_directory(val_dir, \n                                          batch_size= 32, \n                                          target_size=IMG_SIZE, \n                                          class_mode='binary')\nX_val, y_val = val_set.next()","31f49272":"print('Loss of the model is - ', model_alex_net.evaluate(X_val, y_val)[0])\nprint('Accuracy of the model is - ', model_alex_net.evaluate(X_val, y_val)[1]*100, '%')","3fd6cc79":"predict = model_alex_net.predict_classes(X_val)\npredict = predict.reshape(1, -1)[0]\npredict","2808ee1a":"predict_test = model_alex_net.predict_classes(X_test)\npredict_test = predict.reshape(1, -1)[0]\npredict_test","c0c04649":"\nprint(classification_report(y_val, predict, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))","614ec597":"print(classification_report(y_test, predict_test, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))","61968092":"print('Confusion Matrix\\n')\nmatrix = confusion_matrix(y_val, predict)\nprint(matrix)","37d9400c":"correct = np.nonzero(predict == y_val)[0]\nincorrect = np.nonzero(predict != y_val)[0]\nprint(len(correct), len(incorrect))","cce73e95":"i = 0\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_val[c], cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {}\\nActual Class {}\".format(predict[c], y_val[c]))\n    plt.tight_layout()\n    i += 1","3d2eb514":"i = 0\nfor c in incorrect[:6]:\n    plt.subplot(3,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_val[c], cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {}\\nActual Class {}\".format(predict[c], y_val[c]))\n    plt.tight_layout()","803eff07":"# Make Predictions","41829354":"# AlexNet CNN Architecture","4f10593c":"We'll use AlexNet Architecture to predict Pneumonia Dataset\n\nreference :https:\/\/towardsdatascience.com\/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98","beabb67c":"# Data Preparation","a0940104":"# Data preprocessing","509dcf8e":"# Import relevant libraries"}}