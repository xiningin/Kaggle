{"cell_type":{"ba32c207":"code","2797828f":"code","0a3a0615":"code","1cccb9bc":"code","f999caeb":"code","97d5e132":"code","dbd741f3":"code","1642d3e5":"code","da872896":"code","2a7ddd8b":"code","c595f8fc":"code","40a1ddaa":"code","5903e8b0":"code","49f84502":"code","8dba7339":"code","ad6d5760":"code","0f0fb5c7":"code","c1879554":"code","7c930d9e":"code","44a31759":"code","134391a5":"code","5d43b7bb":"code","67244edd":"code","76791dff":"code","8b7d3613":"code","c58f3415":"code","b459e2fb":"code","0ea0bcf0":"code","3da2911d":"code","8b1b5ed9":"code","5fa5419e":"code","bd1582ae":"code","a5749604":"code","7b173002":"markdown","c894196b":"markdown","80fd5711":"markdown"},"source":{"ba32c207":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfilesCount = 0\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        filesCount = filesCount+1\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2797828f":"filesCount","0a3a0615":"import tensorflow as tf\nimport pathlib\nimport os\nimport matplotlib.pyplot as plt\nimport re\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom kaggle_datasets import KaggleDatasets\nnp.set_printoptions(precision=4)","1cccb9bc":"AUTOTUNE = tf.data.AUTOTUNE","f999caeb":"# Detect hardware, return appropriate distribution strategy\n\"\"\"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \"\"\"# default distribution strategy in Tensorflow. Works on CPU and single GPU.","97d5e132":"listOfFiles = list()\nfor (dirpath, dirnames, filenames) in os.walk('..\/input\/drone-rf-dataset'):\n    listOfFiles += [os.path.join(dirpath, file) for file in filenames]","dbd741f3":"listOfFiles = np.array(listOfFiles)","1642d3e5":"noOfFiles = len(listOfFiles)\nfiles_ds=tf.data.Dataset.from_tensor_slices(listOfFiles[0:int(noOfFiles*0.8)])","da872896":"list(files_ds.take(1).as_numpy_iterator())","2a7ddd8b":"Lpat = re.compile(r\"(L_)\")\nHpat = re.compile(r\"(H_)\")\nlowerSpectrum = list(filter(Lpat.search, listOfFiles))\nhighSpectrum = list(filter(Hpat.search, listOfFiles))\n","c595f8fc":"repeat = 10 #to divide signal into 10 equal part of 1sec each\nlowerSpectrum = np.repeat(lowerSpectrum,repeat)\nhighSpectrum = np.repeat(highSpectrum,repeat)\narrayIndex = np.tile(np.array(range(0,repeat)),(lowerSpectrum.shape[0]\/\/repeat)).astype(str)","40a1ddaa":"lowerSpectrum.shape#[1,9*int(10e5):(10)*int(10e5)-1]","5903e8b0":"print(lowerSpectrum.shape,highSpectrum.shape,arrayIndex.shape)","49f84502":"lowSpectrum_ds = tf.data.Dataset.from_tensor_slices(list(lowerSpectrum))\nhighSpectrum_ds = tf.data.Dataset.from_tensor_slices(list(highSpectrum))\narray_index_ds = tf.data.Dataset.from_tensor_slices(arrayIndex.T)\n#signalDs = tf.data.Dataset.from_tensor_slices(np.vstack([list(lowerSpectrum),list(arrayIndex)]).T)\n#signal_ds = lowSpectrum_ds.concatenate(array_index_ds)","8dba7339":"def _tf_log10(x):\n    numerator = tf.math.log(x)\n    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n    return numerator \/ denominator","ad6d5760":"def getFFT(lSignal, hSignal,frame_length=2048,frame_step=1024,fftLength = 2048):\n    #signal = tf.signal.fftshift(tf.signal.fft(tf.cast(records,tf.complex64)))\n    lFFT_signal = tf.signal.fftshift(tf.signal.rfft(lSignal,[fftLength]))\n    lShape = lFFT_signal.shape[0]\n    hFFT_signal =tf.signal.fftshift( tf.signal.rfft(hSignal,[fftLength]))\n    hShape = hFFT_signal.shape[0]\n    signal = tf.abs(tf.concat([lFFT_signal[lShape\/\/2:], hFFT_signal[hShape\/\/2:]],axis=0))\n    return signal\n\ndef getSTFT(lSignal, hSignal,frame_length=2048,frame_step=1024,fftLength = 2048):\n    #signal = tf.signal.fftshift(tf.signal.fft(tf.cast(records,tf.complex64)))\n    #ff_length = pow(2, tf.math.ceil(tf.math.log(x)\/tf.math.log(2)))\n    lFFT_signal = tf.signal.stft(lSignal,frame_length, frame_step,fft_length=fftLength,\n                    window_fn=tf.signal.hann_window, pad_end=True )\n    lShape = lFFT_signal.shape[0]\n    hFFT_signal =tf.signal.stft(hSignal,frame_length, frame_step, fft_length=fftLength,\n                    window_fn=tf.signal.hann_window, pad_end=True,)\n    hShape = hFFT_signal.shape[0]\n    signal = tf.concat([lFFT_signal, hFFT_signal],axis=0)\n    signal = 20 * _tf_log10(tf.clip_by_value(tf.abs(signal),1e-5, 1e100))\n    return signal","0f0fb5c7":"def readFile(filePath,i):\n    highFile_path = tf.strings.regex_replace(filePath,\"L\",\"H\")\n    fileName = tf.strings.split(filePath, os.sep)[-2]\n    lrecords = tf.io.read_file(filePath)\n    hrecords = tf.io.read_file(highFile_path)\n    lrecords = tf.strings.split(lrecords,',')\n    #hrecords = tf.strings.split(records,',')\n    lrecords = tf.strings.to_number(lrecords, tf.float64)\n    i = int(i)\n    #hrecords = tf.strings.to_number(records, tf.float64)\n    return tf.gather(lrecords,list(range(i*int(10e5),(i+1)*int(10e5))))#[i*int(5e5):(i+1)*int(5e5)] ","c1879554":"def process_path(file_path,i):\n    #x,y = file_path\n    lowerFile_path = file_path\n    highFile_path = tf.strings.regex_replace(file_path,\"L\",\"H\")\n    #highFile_path = tf.strings.regex_replace(highFile_path,'RF Data_00000_H1\/RF Data_00000_H1','RF Data_00000_H1')\n    #highFile_path = tf.strings.regex_replace(highFile_path,\"RF Data_00000_H2\",\"FR Data_00000_H2\")\n    #highFile_path = tf.strings.regex_replace(highFile_path,\"RF Data_11000_H1\",\"RF Data_11000_H\/RF Data_11000_H\")\n    #highFile_path = tf.strings.regex_replace(highFile_path,\"RF Data_11000_H2\",\"RF Data_11000_H\/RF Data_11000_H\")\n    lRecords = readFile(lowerFile_path,i)\n    hRecords = readFile(highFile_path,i)\n    signal = getSTFT(lRecords,hRecords,2048,512)\n    \n    label = tf.strings.split(file_path,'_')[-2]\n    if tf.strings.regex_full_match(label,\"0*\"):\n        label=tf.strings.to_number(['0'])\n    else:\n        label=tf.strings.to_number(['1'])\n    \n    return signal, label#lowerFile_path,highFile_path, \n#labeled_ds = signalDs.apply(process_path)#,num_parallel_calls=AUTOTUNE)\n","7c930d9e":"\ndef generator():\n    for s1, s2 in zip(lowerSpectrum, arrayIndex):\n        s1, l = process_path(s1,s2)\n        l = tf.cast(l,tf.int32)\n        yield s1, l\n\ndataset = tf.data.Dataset.from_generator(generator, output_types=(tf.float64\n                                                                  , tf.int32),output_shapes=((3908,1025),1))","44a31759":"def _input_fn():\n    for s1, s2 in zip(lowerSpectrum, arrayIndex):\n        s1, l = process_path(s1,s2)\n        l = tf.cast(l,tf.int32)\n        s1 =tf.expand_dims(s1,-1)\n        yield s1, l\n    dataset = tf.data.Dataset.from_generator(generator, output_types=(tf.float64\n                                                                  , tf.int32),output_shapes=((3908,1025),1))\n    dataset = dataset.batch(32)\n    return dataset","134391a5":"for i,j in dataset.take(1):\n    print(i)","5d43b7bb":"for signal, label_text, in dataset.take(1):\n    fftSignal = signal.numpy()\n    input_shape = signal.shape\n    #print(repr(lFile_path.numpy()))\n    #print(repr(hFile_path.numpy()))\n    print(repr(fftSignal[:100]),fftSignal.shape)\n    print()\n    print(label_text.numpy())\n    print()","67244edd":"def plot_spectrogram(spectrogram):\n    # Convert to frequencies to log scale and transpose so that the time is\n    # represented in the x-axis (columns). An epsilon is added to avoid log of zero.\n    log_spec = spectrogram.T#np.log(spectrogram.T+np.finfo(float).eps)\n    height = log_spec.shape[0]\n    width = log_spec.shape[1]\n    X = np.linspace(0,np.size(spectrogram), num=width, dtype=int)\n    Y = np.arange(0,height)\n    plt.pcolormesh(X, Y, log_spec,shading='nearest')\n\n\n\nfig, axes = plt.subplots(1, figsize=(12, 8))\n#timescale = np.arange(fftSignal.shape[0])\n#axes[0].plot(timescale, fftSignal)\n#axes[0].set_title('Waveform')\n#axes[0].set_xlim([0, 16000]\nplot_spectrogram(fftSignal)\n#axes[0].set_title('Spectrogram')\nplt.show()","76791dff":"def get_spectrogram_label(spectrogram,label):\n    spectrogram = tf.expand_dims(spectrogram,-1)\n    label = tf.cast(label,tf.int32)\n    return spectrogram,label\n#spectrogram_ds = lowSpectrum_ds.map(process_path,num_parallel_calls=AUTOTUNE)\nspectrogram_ds = dataset.map(get_spectrogram_label,num_parallel_calls=AUTOTUNE)\ntrain_ds = spectrogram_ds","8b7d3613":" tf.data.experimental.cardinality(spectrogram_ds).numpy()","c58f3415":"for spectrogram,label in spectrogram_ds.take(1):\n    input_shape =spectrogram.numpy().shape\n    print('Shape of data:',input_shape)\n    print(label)","b459e2fb":"batch_size = 32\ntrain_ds = train_ds.batch(batch_size)\ntrain_ds = train_ds.cache().prefetch(AUTOTUNE)","0ea0bcf0":"#norm_layer = preprocessing.Normalization()\n#norm_layer.adapt(spectrogram_ds.map(lambda x, _: x))","3da2911d":"model = models.Sequential([\n    layers.Input(shape=input_shape),\n    preprocessing.Resizing(128, 128), \n    tf.keras.layers.BatchNormalization(),\n    layers.Conv2D(64, 3, activation='relu'),\n    layers.Conv2D(128, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1),\n])\n\nmodel.summary()","8b1b5ed9":"tf.keras.utils.plot_model(\n    model,show_shapes=True, show_dtype=True,\n    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=50,\n)","5fa5419e":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-3),\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=['accuracy'],\n)","bd1582ae":"EPOCHS = 10\nhistory = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n)\n","a5749604":"metrics = history.history\nplt.plot(history.epoch, metrics['loss'])\nplt.legend(['loss'])\nplt.show()","7b173002":"# DL Model","c894196b":"# Data I\/O","80fd5711":"## Training"}}