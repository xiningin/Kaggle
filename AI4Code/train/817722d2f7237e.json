{"cell_type":{"0e36d638":"code","4ccef61c":"code","a9139dcc":"code","04c07f3e":"code","a577c98d":"code","5e42abe5":"code","c5f416d3":"code","099dfb03":"code","0a96d8da":"code","438e8f4d":"code","723f3515":"code","2e514e81":"code","c55631cc":"code","0f033368":"code","fb3ab4a3":"code","aee0963f":"code","c4d6bdc8":"code","e9f254f0":"code","fb752cc5":"code","07f40987":"code","60de9767":"code","321bc9da":"code","c88ab668":"code","565e9da7":"code","611d6821":"code","8bb90c05":"code","222a1ebb":"code","a1941197":"code","3d1cd99e":"code","34adc75e":"code","34ceb43b":"code","d43e097d":"code","deda1b81":"code","4f3f3fe1":"code","63345856":"code","d2f01f9d":"code","68e334f7":"code","0d28d23c":"code","b00b916a":"code","54011bd9":"code","962fd9a4":"code","4039c9ef":"code","1b1f3dcd":"markdown","36989930":"markdown","579920f0":"markdown","12df163d":"markdown","f189a43b":"markdown","717b591b":"markdown","ea958e1d":"markdown","cb592589":"markdown","bf4a1958":"markdown","08a9b907":"markdown","adcb49cb":"markdown","2410b5bc":"markdown","4306c2ab":"markdown","40b5f550":"markdown","546044ec":"markdown","3670fe1b":"markdown","b61b285e":"markdown","262cc094":"markdown","4fed7e27":"markdown","e6d08697":"markdown","9946a0a2":"markdown","5ad56a25":"markdown","7b83a9c5":"markdown","5248b221":"markdown","2ed65ae5":"markdown","0431054e":"markdown","ae3b6317":"markdown","2dec9e88":"markdown","d9160814":"markdown","c31a3691":"markdown","0ab9f4f3":"markdown","94fcd8f7":"markdown","a28ad76a":"markdown","368b3cbe":"markdown"},"source":{"0e36d638":"import pandas as pd\n\nconvos_samp = pd.read_csv('..\/input\/naver-dictionary-conversation-of-the-day\/conversations.csv').fillna('')\nconvos_samp","4ccef61c":"convo_titles_samp = pd.read_csv('..\/input\/naver-dictionary-conversation-of-the-day\/conversation_titles.csv').fillna('')\nconvo_titles_samp","a9139dcc":"import urllib.request\nimport re\n\n# Let's try one webpage for now\nurl = 'https:\/\/learn.dict.naver.com\/conversation#\/korean-en'\n\npage = urllib.request.urlopen(url)\npage = str(page.read().decode())\n\n# problem: not retrieving complete page html like Firefox html download does\n#          BeautifulSoup doesn't seem to retrieve complete html either\n# possible solution: should i try using headless firefox?\n# solved! - In-kernel Web scraping via a headless Firefox browser with Selenium at the bottom page","04c07f3e":"# regex to find conversation date\ndate = re.findall(r'var regionDate = \"([0-9]+)\"', page)\n# regex to find conversation title\nconvo_title = re.findall(r'id=\"ogTitle\" content=\"(.+)\">', page)\n# regex to extract sentence pairs\neng_sents = re.findall(r'<div class=\"txt_trans ng-binding\" ng-show=\"transDisplay\" ng-bind=\"item.trsl_sentence\">(.+)<.div>', page)\n# how to strip html from text - jxb-bind-compiled-html binding ?\nkor_sents = re.findall(r'<span class=\"u_word_dic\" data-hook=\"tip\" data-type=\"arken\" data-lang=\"ko\">(.+)<\/span>.<\/span><\/span>', page)\n\n# extracting other data (e.g. conversation title, grammar, grammar description, related words)","a577c98d":"date","5e42abe5":"kor_sents","c5f416d3":"eng_sents","099dfb03":"# Checking kernel OS info\n!cat \/etc\/os-release","0a96d8da":"# Downloading Firefox for Linux\n!wget 'https:\/\/download-installer.cdn.mozilla.net\/pub\/firefox\/releases\/79.0\/linux-x86_64\/en-US\/firefox-79.0.tar.bz2'\n\n# Extracting Firefox binary\n!tar -xjf 'firefox-79.0.tar.bz2'","438e8f4d":"# Checking working directory\n!ls \/kaggle\/working","723f3515":"# Adding read\/write\/execute capabilities to 'firefox' directory\n!chmod -R 777 '..\/working\/firefox'","2e514e81":"# Installing Firefox dependencies\n!apt-get install -y libgtk-3-0 libdbus-glib-1-2 xvfb","c55631cc":"# Installing Python module for automatic handling of GeckoDriver download and installation\n!pip install webdriverdownloader","0f033368":"# Installing GeckoDriver\nfrom webdriverdownloader import GeckoDriverDownloader\n\ngdd = GeckoDriverDownloader()\ngdd.download_and_install('v0.23.0')","fb3ab4a3":"# Installing Selenium\n!pip install selenium","aee0963f":"# Loading Python modules to use\nimport pandas as pd\nimport seaborn as sns\nfrom IPython.display import Image\nimport time\n\nfrom selenium import webdriver as selenium_webdriver\nfrom selenium.webdriver.firefox.options import Options as selenium_options\nfrom selenium.webdriver.common.desired_capabilities import DesiredCapabilities as selenium_DesiredCapabilities\n\nfrom selenium.webdriver.common.by  import By as selenium_By\nfrom selenium.webdriver.support.ui import Select as selenium_Select\nfrom selenium.webdriver.support.ui import WebDriverWait as selenium_WebDriverWait\nfrom selenium.webdriver.support    import expected_conditions as selenium_ec","c4d6bdc8":"# Setting up a virtual screen for Firefox\n!export DISPLAY=:99","e9f254f0":"# Firing up a headless browser session with a screen size of 1920x1080\nbrowser_options = selenium_options()\nbrowser_options.add_argument(\"--headless\")\nbrowser_options.add_argument(\"--window-size=1920,1080\")\n\ncapabilities_argument = selenium_DesiredCapabilities().FIREFOX\ncapabilities_argument[\"marionette\"] = True\n\nbrowser = selenium_webdriver.Firefox(\n    options=browser_options,\n    firefox_binary=\"..\/working\/firefox\/firefox\",\n    capabilities=capabilities_argument\n)","fb752cc5":"# Navigating to website\nbrowser.get(\"https:\/\/learn.dict.naver.com\/conversation#\/korean-en\")\nprint(browser.current_url)\n\n# Giving the page up to 10 seconds to load\nwait = selenium_WebDriverWait(browser, 10)\nwait.until(selenium_ec.visibility_of_element_located((selenium_By.XPATH, '\/\/div[@class=\"reading_lst_wrap\"]')))\n\n# Taking a screenshot of the webpage\nbrowser.save_screenshot(\"screenshot.png\")\nImage(\"screenshot.png\", width=800, height=500)","07f40987":"# Waiting for another 10 seconds to make sure the page is complete\ntime.sleep(10)\n\n# Retrieving page source\npage = browser.page_source\npage[0:1000]","60de9767":"# regex to extract conversation date\ndate = re.findall(r'var regionDate = \"([0-9]+)\"', page)\n# regex to extract conversation title in korean\nkor_title = re.findall(r'id=\"ogTitle\" content=\"\uc624\ub298\uc758 \ud68c\ud654 - (.+)\">', page)\n# regex to extract conversation title in english\neng_title = re.findall(r'<span class=\"txt_trans ng-binding\" ng-bind=\"title_translation\">(.+)<\/span>', page)\n# regex to extract sentence pairs\neng_sents = re.findall(r'<div.+item.trsl_sentence\">(.+)<\/div>', page)\nkor_sents = re.findall(r'<span class=\"u_word_dic\" data-hook=\"tip\" data-type=\"arken\" data-lang=\"ko\">(.+)<\/span><\/span>', page)","321bc9da":"date","c88ab668":"kor_title","565e9da7":"eng_title","611d6821":"eng_sents","8bb90c05":"kor_sents[0:3]","222a1ebb":"# Stripping HTML tags from text\ndef strip_tags(sent):\n    sent = re.sub(r'<.+?>', '', sent)\n    return sent","a1941197":"kor_sents = list(map(strip_tags, kor_sents))\nkor_sents = kor_sents[0:len(eng_sents)]\nkor_sents","3d1cd99e":"# Extracting grammar of the day\ngrammar = re.findall(r'<span jxb-bind-compiled-html.+item[.]entry_name.+\"ng-scope\">(.+)<\/span><\/span>\\s+<\/div>', page)\ngrammar = list(map(strip_tags, grammar))\ngrammar","34adc75e":"# Extracting grammar description\ngrammar_desc = re.findall(r'<span class=\"txt_trans ng-binding\" ng-bind=\"item.mean\">(.+)<\/span>\\s+<\/div>', page)\ngrammar_desc = list(map(strip_tags, grammar_desc))\ngrammar_desc","34ceb43b":"# Extracting grammar of the day sentence examples\ngrammar_sents_eng = re.findall(r'<span class=\"txt_trans ng-binding\" ng-bind-html=\"desc[.]trans.+toHtml\">(.+)<\/span>', page)\ngrammar_sents_eng","d43e097d":"grammar_sents_kor = re.findall(r'<span class=\"txt_origin ng-isolate-scope\" jxb-bind-compiled-html=\"toAutolinkText\\(desc[.]origin\\)\"><span class=\"ng-scope\"><span class=\"u_word_dic\" data-hook=\"tip\" data-type=\"arken\" data-lang=\"ko\">(.+)<\/span><\/span>', page)\ngrammar_sents_kor = list(map(strip_tags, grammar_sents_kor))\ngrammar_sents_kor","deda1b81":"# convo_titles dataframe columns\ntitle_cols = {\n    'date': date,\n    'kor_title': kor_title,\n    'eng_title': eng_title,\n    'grammar': grammar,\n    'grammar_desc': grammar_desc\n}\n\n# Creating convo_titles DataFrame\nconvo_titles = pd.DataFrame(title_cols)\nconvo_titles","4f3f3fe1":"# Adding new columns: grammar sentence examples    \nfor i in range(len(grammar_sents_eng)):\n    col = f'grammar_kor_sent_{i+1}'\n    convo_titles[col] = grammar_sents_kor[i]\n    col = f'grammar_eng_sent_{i+1}'\n    convo_titles[col] = grammar_sents_eng[i]\n    \nconvo_titles","63345856":"# convos dataframe columns\nconvos_cols = {\n    'date': [date for date in date for _ in range(len(eng_sents))],\n    'conversation_id': [id+1 for id, _ in enumerate(eng_sents)],\n    'kor_sent': kor_sents,\n    'eng_sent': eng_sents,\n    'qna_id': ''  # from sender or receiver, message or feedback\n}\n\n# Creating convos DataFrame\nconvos = pd.DataFrame(convos_cols)\nconvos","d2f01f9d":"# Creating 2 empty DataFrames to hold conversations and conversation titles\ntitle_cols = [\n    'date',  # 'Conversation of the Day' date\n    'kor_title',  # 'Conversation of the Day' title in Korean\n    'eng_title',  # english translation of the title\n    'grammar',  # grammar of the day\n    'grammar_desc'  # grammar description\n]\nconvo_titles = pd.DataFrame(columns = title_cols)\n\nconvos_cols = [\n    'date',  # 'Conversation of the Day' date\n    'conversation_id',  # ordered numbering to indicate conversation flow\n    'kor_sent',  # korean sentence\n    'eng_sent',  # english translation\n    'qna_id'  # from sender or receiver, message or feedback\n]\nconvos = pd.DataFrame(columns = convos_cols)","68e334f7":"# function to strip html tags from text\ndef strip_tags(sent):\n    sent = re.sub(r'<.+?>', '', sent)\n    return sent","0d28d23c":"%%time\nstart_time = time.time()\n\nstart_date = '12\/04\/2017'\nend_date = '8\/19\/2020'\n\nfor d in pd.date_range(start=start_date, end=end_date):\n    \n    # Skip date if Sunday (Weekly Review Quiz)\n    if d.day_name() == 'Sunday':\n        continue\n    \n    date = d.strftime('%Y%m%d')\n    \n    # Navigating to website\n    url = f\"https:\/\/learn.dict.naver.com\/conversation#\/korean-en\/{date}\"\n    browser.get(url)\n    # print(browser.current_url)\n    \n    # Giving the page up to 10 seconds to load\n    wait = selenium_WebDriverWait(browser, 10)\n    wait.until(selenium_ec.visibility_of_element_located((selenium_By.XPATH, '\/\/div[@class=\"reading_lst_wrap\"]')))\n    \n    # Waiting for another 10 seconds before retrieving page source\n    time.sleep(10)\n    \n    # Retrieving page source\n    page = browser.page_source\n    \n    # Extracting data from page\n    # regex to extract conversation title in korean\n    kor_title = re.findall(r'id=\"ogTitle\" content=\"\uc624\ub298\uc758 \ud68c\ud654 - (.+)\">', page)\n    # regex to extract conversation title in english\n    eng_title = re.findall(r'<span class=\"txt_trans ng-binding\" ng-bind=\"title_translation\">(.+)<\/span>', page)\n    # regex to extract sentence pairs\n    eng_sents = re.findall(r'<div.+item.trsl_sentence\">(.+)<\/div>', page)\n    kor_sents = re.findall(r'<span class=\"u_word_dic\" data-hook=\"tip\" data-type=\"arken\" data-lang=\"ko\">(.+)<\/span><\/span>', page)\n    \n    # Stripping HTML tags from kor_sents\n    kor_sents = list(map(strip_tags, kor_sents))\n    kor_sents = kor_sents[0:len(eng_sents)]\n    \n    # Extracting grammar of the day\n    grammar = re.findall(r'<span jxb-bind-compiled-html.+item[.]entry_name.+\"ng-scope\">(.+)<\/span><\/span>\\s+<\/div>', page)\n    grammar = list(map(strip_tags, grammar))\n    \n    # Extracting grammar description\n    grammar_desc = re.findall(r'<span class=\"txt_trans ng-binding\" ng-bind=\"item.mean\">(.+)<\/span>\\s+<\/div>', page)\n    grammar_desc = list(map(strip_tags, grammar_desc))\n    \n    # Extracting grammar of the day sentence examples\n    grammar_sents_eng = re.findall(r'<span class=\"txt_trans ng-binding\" ng-bind-html=\"desc[.]trans.+toHtml\">(.+)<\/span>', page)\n    grammar_sents_kor = re.findall(r'<span class=\"txt_origin ng-isolate-scope\" jxb-bind-compiled-html=\"toAutolinkText\\(desc[.]origin\\)\"><span class=\"ng-scope\"><span class=\"u_word_dic\" data-hook=\"tip\" data-type=\"arken\" data-lang=\"ko\">(.+)<\/span><\/span>', page)\n    grammar_sents_kor = list(map(strip_tags, grammar_sents_kor))\n    \n    # Creating new DataFrame to append to convo_titles\n    title_data = {\n        'date': date,\n        'kor_title': kor_title,\n        'eng_title': eng_title,\n        'grammar': ['. '.join(grammar)],\n        'grammar_desc': ['. '.join(grammar_desc) if len(grammar_desc) > 0 else '']\n    }\n    title = pd.DataFrame(title_data)\n    \n#     # Additional columns of title DataFrame\n#     for i in range(len(grammar_sents_eng)):\n#         col = f'grammar_kor_sent_{i+1}'\n#         title[col] = grammar_sents_kor[i]\n#         col = f'grammar_eng_sent_{i+1}'\n#         title[col] = grammar_sents_eng[i]\n    \n    # Creating new DataFrame to append to convos\n    convo_data = {\n        'date': [date for date in [date] for _ in range(len(eng_sents))],\n        'conversation_id': [id+1 for id, _ in enumerate(eng_sents)],\n        'kor_sent': kor_sents,\n        'eng_sent': eng_sents,\n        'qna_id': ''\n    }\n    convo = pd.DataFrame(convo_data)\n    \n    # Appending extracted data to convo_titles and convos DataFrames\n    convo_titles = convo_titles.append(title, ignore_index = True)\n    convos = convos.append(convo, ignore_index = True)\n    \n# Printing shapes\nprint('convos shape:', convos.shape)\nprint('convo_titles shape:', convo_titles.shape)\nprint('Time taken to extract data:', '{:.2f}'.format((time.time() - start_time) \/ 60))","b00b916a":"convos","54011bd9":"convo_titles","962fd9a4":"# Exporting to CSV files\nconvos.to_csv('conversations.csv', index = False)\nconvo_titles.to_csv('conversation_titles.csv', index = False)","4039c9ef":"# Deleting unwanted files in working directory\n!rm -rf firefox\n!rm firefox-79.0.tar.bz2\n!rm geckodriver.log\n!ls ..\/working","1b1f3dcd":"# What I'm Expecting to Get From Scraping","36989930":"**Viewing page source**","579920f0":"Hi! Welcome to my notebook.\n\nI want to create a compilation of **Korean - English sentence pairs** from **Naver Dictionary's Conversation of the Day**.\n\nAt first I thought, I could type them out one by one, day by day to reinforce my Korean language learning in addition to creating a dataset for future projects (*like maybe a bilingual AI chatbot*).\n\nBut then, I remembered something called **'web scraping'**. Simply put, it is a technique of automatically extracting (*or scraping*) specific data you want from websites and saving them to a file or a database.\n\nIn this notebook, I'm going to take my first dip in web scraping in order to compile months, years of 'Conversation of the Day' from [Naver Dictionary](https:\/\/learn.dict.naver.com\/conversation#\/korean-en).","12df163d":"A bit messy.. Let's use regular expressions to find what we need.","f189a43b":"# References\n* [K-MOOC: Python Web Scraping](http:\/\/blog.naver.com\/PostView.nhn?blogId=powhy123&logNo=221193422772&categoryNo=19&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView)\n* [Kaggle web scraping via headless Firefox+selenium](https:\/\/www.kaggle.com\/dierickx3\/kaggle-web-scraping-via-headless-firefox-selenium)","717b591b":"Cool! Just like what I'm using right now.","ea958e1d":"Creating convo_titles DataFrame","cb592589":"**Save to file: conversations.csv, conversation_titles.csv**","bf4a1958":"**Extract data from html:** \n\n*Korean - English sentence pairs, grammar, related words, date*","08a9b907":"**Find patterns in the html code around the data we want to extract**","adcb49cb":"**Organizing variables for DataFrame creation**","2410b5bc":"Let's now try to scrape all the Naver Conversation of the Day data from 2017 up to today.","4306c2ab":"Let's take a look at the content of our DataFrames.","40b5f550":"**Extracting more variables**","546044ec":"Did we get it?","3670fe1b":"**Let's see if we're able to extract the data**","b61b285e":"![View source code](https:\/\/raw.githubusercontent.com\/rareloto\/workspace\/master\/naverdictionary-conversationoftheday-scraper\/photos\/view-page-source-find-patterns-koreng.png)","262cc094":"Installing Firefox browser","4fed7e27":"Lots and lots of Korean - English conversation parallel text pairs","e6d08697":"![Conversation of the Day](https:\/\/raw.githubusercontent.com\/rareloto\/workspace\/master\/naverdictionary-conversationoftheday-scraper\/naver-conversationoftheday-20200815-cropped.png)","9946a0a2":"**What's next?**\n* Automation and scripting: Extracting more data; On-demand data extraction via script\n* Dataset creation: Making the dataset user-friendly\n* Applications: I could make tons of flashcards, for now","5ad56a25":"Extracting conversations from December 4, 2017 to August 19, 2019","7b83a9c5":"# Scraping years' worth of data","5248b221":"Awesome! Looks like we're on the same page.","2ed65ae5":"Sweet!","0431054e":"Installing GeckoDriver ","ae3b6317":"Now, let's do these for years' worth of conversations.","2dec9e88":"# Web Scraping via headless Firefox with Selenium","d9160814":"**Let's get started!**","c31a3691":"Creating convos DataFrame","0ab9f4f3":"The sentence pairs were not extracted because the page source we retrieved is incomplete.\n\nMaybe I'll try a headless Firefox browser here to download the complete webpage from the browser.","94fcd8f7":"# Naver Conversation of the Day","a28ad76a":"Let's create two DataFrames:\n\n**convo_titles**\n(with columns: date, kor_title, eng_title, grammar, grammar_desc, grammar_sents)\n\n**convos**\n(with columns: date, conversation_id, kor_sent, eng_sent, qna_id)\n\nEach convo_title has more or less 4 - 8 Korean-English sentence pairs found in convos_table.","368b3cbe":"Looks good~"}}