{"cell_type":{"df90031d":"code","3d4bc622":"code","07a5ea08":"code","62436e1b":"code","27e340d7":"code","c7398fed":"code","a30be3fc":"code","786ac582":"code","f5bb0636":"code","6dbafde8":"code","e16fad2d":"code","92262d7f":"code","7a79568b":"code","84fe4384":"code","d5c3a53d":"code","f9732049":"code","928a72a5":"code","5c2f8048":"code","3b5f1581":"code","b98fe608":"code","338f3ba3":"code","71a4ec63":"code","6003d4d2":"code","d14dbc79":"code","bc489528":"code","7ea7297d":"code","56e5ffdb":"code","27aac7ef":"code","4299355d":"code","7c90401b":"markdown","3a5dd4d2":"markdown","6378bee1":"markdown","d57195cc":"markdown","608ab2d9":"markdown","4a1bc85b":"markdown","d0bf4be4":"markdown","94dfe3e4":"markdown","510cec5a":"markdown","45e5cd80":"markdown","e610963c":"markdown","7c4a2b8d":"markdown","dbb4bbd4":"markdown"},"source":{"df90031d":"# Built-in packages\nimport json\nimport warnings\nimport re\nwarnings.filterwarnings(\"ignore\")\n\n# Third party packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\nfrom plotly.offline import iplot\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom mlxtend.classifier import StackingCVClassifier\nfrom xgboost import XGBClassifier\n\n\nsns.set(context= \"notebook\", color_codes=True)\nplt.style.use('bmh')\n\npyo.init_notebook_mode()\n\n%matplotlib inline\npd.set_option('display.max_columns', None)","3d4bc622":"# Read the CSV file and display first 10 rows\ndf = pd.read_csv(\"\/kaggle\/input\/parkinsons-data-set\/parkinsons.data\")\ndf.columns = [i.replace(\" \", \"_\").replace(\"(%)\", \"_perc\").replace(\"(dB)\", \"_db\").replace(\":\", \"_\").lower() for i in df.columns]\ndf.columns = [re.sub(r\"\\((.+)\\)\", \"\", i) for i in df.columns]\n\ndf","07a5ea08":"print(f\"The shape of the DatFrame is: {df.shape}, which means there are {df.shape[0]} rows and {df.shape[1]} columns.\")","62436e1b":"df.info()","27e340d7":"# Check if any of the columns have null values\nprint(df.isnull().sum())","c7398fed":"df_summary = df.describe()\ndf_summary","a30be3fc":"df.isna().sum()","786ac582":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(), fmt='.2f', annot=True);","f5bb0636":"# A function that returns value counts for a column split by status\ndef groupby_get_cc_count(tdf, col):\n    tdf = tdf.groupby([col, \"status\"])[\"status\"].count().reset_index(level = 0)\n    tdf.columns = [col, \"count\"]\n    tdf = tdf.reset_index()\n    return tdf","6dbafde8":"df[[\"mdvp_fo\", \"mdvp_jitter\", \"status\"]]","e16fad2d":"def draw_axvlines(plt, col):\n    mean = df_summary.loc[\"mean\", col]\n    q1 = df_summary.loc[\"25%\", col]\n    q2 = df_summary.loc[\"50%\", col]\n    q3 = df_summary.loc[\"75%\", col]\n    plt.axvline(mean, color = \"g\");              # Plotting a line to mark the mean \n    plt.axvline(q1, color = \"b\");                # Plotting a line to mark Q1 \n    plt.axvline(q2, color = \"navy\");             # Plotting a line to mark Q2 \n    plt.axvline(q3, color = \"purple\");           # Plotting a line to mark Q3\n    plt.legend({\"Mean\": mean, \"25%\" : q1, \"50%\" : q2, \"75%\" : q3});\n\nfig, axes = plt.subplots(3, 2, figsize = (20,15));\nfig.suptitle('Distribution charts for Age, Experience and income.');\n\n\n# Create boxplot to show distribution of Age\nsns.boxplot(df[\"mdvp_fo\"], ax = axes[0][0], color = \"mediumslateblue\");\naxes[0][0].set(xlabel = 'Distribution of Age');\n\npp = sns.distplot(df[\"mdvp_fo\"], ax = axes[0][1], bins = 10, color = \"mediumslateblue\");\naxes[0][1].set(xlabel = 'Distribution of Age');\ndraw_axvlines(pp, \"mdvp_fo\");\n\n\n# Create boxplot to show distribution of creatinine_phosphokinase\nsns.boxplot(df[\"mdvp_fhi\"], ax = axes[1][0], color = \"mediumslateblue\");\naxes[1][0].set(xlabel = 'Distribution of creatinine_phosphokinase');\n\npp = sns.distplot(df[\"mdvp_fhi\"], ax = axes[1][1], bins = 10, color = \"mediumslateblue\");\naxes[1][1].set(xlabel = 'Distribution of creatinine_phosphokinase');\ndraw_axvlines(pp, \"mdvp_fhi\")\n\n\n# Create boxplot to show distribution of platelets\nsns.boxplot(df[\"mdvp_flo\"], ax = axes[2][0], color = \"mediumslateblue\");\naxes[2][0].set(xlabel = 'Distribution of platelets');\n\npp = sns.distplot(df[\"mdvp_flo\"], ax = axes[2][1], color = \"mediumslateblue\");\naxes[2][1].set(xlabel = 'Distribution of platelets');\ndraw_axvlines(pp, \"mdvp_flo\")","92262d7f":"plt.figure(figsize = (15, 5))\nsns.scatterplot(x = \"mdvp_fo\", y = \"mdvp_jitter_perc\", data = df[[\"mdvp_fo\", \"mdvp_jitter_perc\", \"status\"]], hue = \"status\", alpha = 0.5);","7a79568b":"df_train = df.copy().drop(columns=[\"name\"])\ncol_names = df_train.columns.tolist()\ntarget_col = [\"status\"]\ncol_names.remove(target_col[0])\ndf_train = df_train[col_names + target_col]","84fe4384":"plt.figure(figsize=(15,10))\ncorr = df_train.corr()\nsns.heatmap(corr, annot=True, fmt='.2g');","d5c3a53d":"len(df_train[col_names].columns)","f9732049":"std = StandardScaler()\n\nscaled = std.fit_transform(df_train[col_names])     # Standardize the columns to get them on the same scale\nscaled = pd.DataFrame(scaled, columns=col_names)\n\ndf_train = pd.concat([scaled, df_train[target_col]], axis=1)\n\ndf_train.head()","928a72a5":"X = df_train[col_names]      # Contains the independent columns \ny = df_train[target_col]     # Our target column","5c2f8048":"train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 323)\ntrain_y = train_y[\"status\"]\ntest_y = test_y[\"status\"]","3b5f1581":"conf_matrix_all = {}\n\ndef parkinsons_disease_prediction(name, algo, training_x, testing_x, training_y, testing_y, plot) :\n    algo.fit(training_x,training_y)                           # Fit the training data set to the algorithm passed.\n    predictions = algo.predict(testing_x)                     # Get all predictions\n    probabilities = algo.predict_proba(testing_x)             # Get probablities of predictions\n\n    conf_matrix = confusion_matrix(testing_y, predictions)    # Get confusion matrix using the predictions\n    tn, fp, fn, tp = conf_matrix.ravel()\n    \n    conf_matrix_all[name] = conf_matrix                       # Save confusion matrix values to a dictionary\n    \n    print(\"Classification report:\")                           # Print the classification report\n    print(classification_report(testing_y, predictions))\n  \n    model_roc_auc = roc_auc_score(testing_y, predictions)           # Get the Area under the curve number\n    fpr,tpr,thresholds = roc_curve(testing_y, probabilities[:,1])   # Get False postive rate and true positive rate\n    \n    print (\"Area under the curve: \", model_roc_auc)\n    \n    \n    if plot:\n        fig, axes = plt.subplots(1,2, figsize=(20, 7))\n        conf_matrix = np.flip(conf_matrix)\n        \n        labels = np.array([['\\nTP','\\nFN'],['\\nFP','\\nTN']])\n        labels = np.core.defchararray.add(conf_matrix.astype(str), labels)\n        sns.heatmap(conf_matrix, fmt='', annot = labels, ax=axes[0], cmap=\"YlGnBu\", xticklabels=[1, 0], yticklabels=[1, 0]);                                           # Plot the confusion matrix\n        axes[0].set(xlabel='Predicted', ylabel='Actual')\n\n        plt.title('Receiver Operating Characteristic')\n        sns.lineplot(fpr, tpr, ax=axes[1])                                         # Plot the ROC curve\n        plt.plot([0, 1], [0, 1],'--')                                              # Plot the diagonal line\n        axes[1].set_xlim([0, 1])                                                   # Set x-axis limit to 0 and 1\n        axes[1].set_ylim([0, 1])                                                   # Set y-axis limit to 0 and 1\n        axes[1].set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate');\n        plt.show();","b98fe608":"lr  = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, penalty=\"l1\", solver='liblinear')\n\nparkinsons_disease_prediction(\"Logistic Regression\", lr, train_X, test_X, train_y, test_y, plot = True)","338f3ba3":"knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan', metric_params=None, n_neighbors = 2, weights='distance')\n\nparkinsons_disease_prediction(\"K-Nearest Neighbours\", knn, train_X, test_X, train_y, test_y, plot=True)","71a4ec63":"gnb = GaussianNB(priors=None, var_smoothing=1e-09)\n\nparkinsons_disease_prediction(\"Gaussian Na\u00efve Bayes\", gnb, train_X, test_X, train_y, test_y, plot=True)","6003d4d2":"svc = SVC(C=1.0, kernel='linear', degree= 2, gamma=1.0, random_state=None,\n          coef0=0.0, shrinking=True, probability=True,tol=0.001,\n          cache_size=200, class_weight=None, verbose=False,max_iter= -1)\n\nparkinsons_disease_prediction(\"Support Vector Classifier\", svc, train_X, test_X, train_y, test_y, plot=True)","d14dbc79":"sclf = StackingCVClassifier(classifiers=[lr, knn, svc],\n                            meta_classifier=LogisticRegression(),\n                            random_state=42)\n\nfor clf, label in zip([lr, knn, svc, sclf], [\"Logistic Regression\" , 'KNN', 'Support Vector', 'StackingClassifier']):\n\n    scores = model_selection.cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n    \nprint(\"\\n\")\nparkinsons_disease_prediction(\"Stacking Classifier\", sclf, train_X, test_X, train_y, test_y, plot=True)","bc489528":"rfc = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = \"gini\", \n                               min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n                               max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n                               bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, \n                               warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n\nparkinsons_disease_prediction(\"Random Forest\", rfc,train_X,test_X,train_y,test_y, plot=True) ","7ea7297d":"bcc = BaggingClassifier()\n\nparkinsons_disease_prediction(\"Bagging Classifier\", bcc,train_X,test_X,train_y,test_y, plot=True) ","56e5ffdb":"abc = AdaBoostClassifier(base_estimator=None, learning_rate=0.06, algorithm='SAMME.R')\n\n\nparkinsons_disease_prediction(\"AdaBoost\", abc, train_X, test_X, train_y, test_y, plot=True)","27aac7ef":"xgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n                        max_depth = 6, min_child_weight=1, missing=None, n_estimators=50,\n                        objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1, \n                        scale_pos_weight=1, subsample=0.8)\n\nparkinsons_disease_prediction(\"XGBoost\", xgc, train_X, test_X, train_y, test_y, plot=True)","4299355d":"import math\nfig, axes = plt.subplots(3,3, figsize = (20, 15))\n\ncnt = 0\nfor r in range(4):\n    for c in range(4):\n        try:\n            conf_matrix = np.flip(list(conf_matrix_all.values())[cnt])\n            labels = np.array([['\\nTP','\\nFN'],['\\nFP','\\nTN']])\n            labels = np.core.defchararray.add(conf_matrix.astype(str), labels)\n\n            sns.heatmap(conf_matrix, fmt='', annot = labels, ax=axes[r, c], cmap=\"YlGnBu\", xticklabels=[1, 0], yticklabels=[1, 0]);\n            axes[r, c].set(title=list(conf_matrix_all.keys())[cnt])\n            cnt += 1\n        except:\n            pass","7c90401b":"## Univariate and Bivariate analysis","3a5dd4d2":"## Stack and train meta-classifier","6378bee1":"**name**$~~~~~~~~~~~~~~~~~~~~~~~~~$- ASCII subject name and recording number\n____\n**MDVP:Fo(Hz)**$~~~~~~~~~~~~~$- Average vocal fundamental frequency\n____\n**MDVP:Fhi(Hz)**$~~~~~~~~~~~~$- Maximum vocal fundamental frequency\n____\n**MDVP:Flo(Hz)**$~~~~~~~~~~~~$- Minimum vocal fundamental frequency\n____\n**MDVP:Jitter(%), <br>\nMDVP:Jitter(Abs), <br>\nMDVP:RAP, <br>\nMDVP:PPQ, <br>\nJitter:DDP**$~~~~~~~~~~~~~~~~~~$- Several measures of variation in fundamental frequency\n____\n**MDVP:Shimmer, <br>\nMDVP:Shimmer(dB), <br>\nShimmer:APQ3, <br>\nShimmer:APQ5, <br>\nMDVP:APQ, <br>\nShimmer:DDA**$~~~~~~~~~~~~~$- Several measures of variation in amplitude\n____\n**NHR,HNR**$~~~~~~~~~~~~~~~~~~~$- Two measures of ratio of noise to tonal components in the voice\n____\n**status**$~~~~~~~~~~~~~~~~~~~~~~~~$- Health status of the subject (one) - Parkinson's, (zero) - healthy\n____\n**RPDE,D2**$~~~~~~~~~~~~~~~~~~~~$- Two nonlinear dynamical complexity measures\n____\n**DFA**$~~~~~~~~~~~~~~~~~~~~~~~~~~~$- Signal fractal scaling exponent\n____\n**spread1, <br>\nspread2, <br>\nPPE**$~~~~~~~~~~~~~~~~~~~~~~~~~~~$- Three nonlinear measures of fundamental frequency variation\n____","d57195cc":"### Logistic Regression","608ab2d9":"## Standardization (Scaling)","4a1bc85b":"# Parkinsons Disease detection","d0bf4be4":"## Ensemble models\n\n### Random Forest","94dfe3e4":"### Support Vector Classifier","510cec5a":"### Na\u00efve Bayes","45e5cd80":"![P124-AIC-DBSImage-NOTEXT-(002).png](attachment:6577bbb4-1eb8-4bd9-a9ef-71e71e128765.png)\n\n### Parkinson's disease is a brain disorder that leads to shaking, stiffness, and difficulty with walking, balance, and coordination. Parkinson's symptoms usually begin gradually and get worse over time. As the disease progresses, people may have difficulty walking and talking.\n\nEven though there are lot of other tests to be able to find if the person has the Parkinsons disease or not, to be able to detect it in its early stages still seems to be a challenge. Until a mathematician called Max Little who is a research fellow from MIT found out a better way to find the same with 99% accuracy in a 30 second phone call.\n\nParkinsons can affect the patient's vocal organs in the similar way it affects limbs and hands so just by monitoring the vocal cords in the larynx (vocal box), we are now able to detect if the person has\/is developing Parkinsons or not.","e610963c":"From the above plot, we can see that the people without Parkinsons have their fundamental frequencies that is either high or very low and the percentage of jitter is usually lower that 0.005%.","7c4a2b8d":"### K-nearest Neighbors","dbb4bbd4":"## Test AND Train split 70:30 ratio"}}