{"cell_type":{"76d50745":"code","3fe8e320":"code","30495c9a":"code","d5acb8cf":"code","27328152":"code","21c79c6a":"code","57131766":"code","c80f4d9e":"code","639a2b0a":"code","51d839bc":"code","db8f4696":"code","7225e7b6":"code","82b1bacc":"code","96856385":"code","636516a2":"code","e6d01e08":"code","2de6d6f6":"code","8e6cf2a1":"code","e8b7cab1":"code","993fc834":"code","8c8f9381":"code","0720a466":"code","914af80e":"code","ff75913a":"code","435afbbc":"code","4671f95b":"code","62ddd785":"code","f35c1485":"code","88ca1ac4":"code","3e2786c7":"code","3192d671":"code","a24f20b9":"code","a1551579":"code","317ffc96":"code","f86be814":"code","cfd31e3c":"code","a9644abf":"code","e0005504":"code","779e9878":"code","461ddd04":"code","9a4b8205":"code","586e6208":"code","51f98c7d":"code","30bc099d":"code","42871be8":"code","d00ea349":"code","ad897007":"code","879d8334":"code","e7900a26":"code","07d854e6":"code","a3fc4a76":"code","eeb0681f":"markdown","03f94dba":"markdown","d0122734":"markdown","5dff7294":"markdown","353c7058":"markdown","ffda8a1f":"markdown","aa9d7868":"markdown","5cafa621":"markdown","59d0b21f":"markdown","e8f8fd82":"markdown","19c5a1fe":"markdown"},"source":{"76d50745":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fe8e320":"# import required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport glob\nimport plotly.graph_objects as go\nimport cv2\nfrom PIL import Image\nfrom PIL import ImageFile\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten , Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","30495c9a":"# get the data for training\n\nroot_dir = '..\/input\/intel-mobileodt-cervical-cancer-screening'\ntrain_dir = os.path.join(root_dir,'train', 'train')\n\ntype1_dir = os.path.join(train_dir, 'Type_1')\ntype2_dir = os.path.join(train_dir, 'Type_2')\ntype3_dir = os.path.join(train_dir, 'Type_3')\n\ntrain_type1_files = glob.glob(type1_dir+'\/*.jpg')\ntrain_type2_files = glob.glob(type2_dir+'\/*.jpg')\ntrain_type3_files = glob.glob(type3_dir+'\/*.jpg')\n\nadded_type1_files  =  glob.glob(os.path.join(root_dir, \"additional_Type_1_v2\", \"Type_1\")+'\/*.jpg')\nadded_type2_files  =  glob.glob(os.path.join(root_dir, \"additional_Type_2_v2\", \"Type_2\")+'\/*.jpg')\nadded_type3_files  =  glob.glob(os.path.join(root_dir, \"additional_Type_3_v2\", \"Type_3\")+'\/*.jpg')\n\n\ntype1_files = train_type1_files + added_type1_files\ntype2_files = train_type2_files + added_type2_files\ntype3_files = train_type3_files + added_type3_files\n\nprint(f'''Type 1 files for training: {len(type1_files)} \nType 2 files for training: {len(type2_files)}\nType 3 files for training: {len(type3_files)}''' )","d5acb8cf":"# # get data for testing\n\n# test_dir = os.path.join(root_dir,'test', 'test')\n\n# test_files = glob.glob(test_dir+'\/*.jpg')\n\n# print(f'''Test files for training: {len(test_files)}''' )","27328152":"# create dataframe of file and labels\nfiles = {'filepath': type1_files + type2_files + type3_files,\n          'label': ['Type 1']* len(type1_files) + ['Type 2']* len(type2_files) + ['Type 3']* len(type3_files)}\n\nfiles_df = pd.DataFrame(files).sample(frac=1, random_state= 1).reset_index(drop=True)\nfiles_df","21c79c6a":"# describe the dataframe\nfiles_df.describe()","57131766":"# check for duplicates\nlen(files_df[files_df.duplicated(subset=['filepath'])])","c80f4d9e":"# check for damaged files\nbad_files = []\nfor path in (files_df['filepath'].values):\n    try:\n        img = Image.open(path)\n    except:\n        index = files_df[files_df['filepath']==path].index.values[0]\n        bad_files.append(index)\nprint(len(bad_files))","639a2b0a":"# # show the bad files\n# print(bad_files)","51d839bc":"# drop the damaged files\nfiles_df.drop(bad_files, inplace=True)","db8f4696":"# check length of files in dataframe\nlen(files_df)","7225e7b6":"# check unique labels\nfiles_df['label'].unique()","82b1bacc":"# get count of each type \ntype_count = pd.DataFrame(files_df['label'].value_counts()).rename(columns= {'label': 'Num_Values'})\ntype_count","96856385":"# display barplot of type count\nplt.figure(figsize = (15, 6))\nsns.barplot(x= type_count['Num_Values'], y= type_count.index.to_list())\nplt.title('Cervical Cancer Type Distribution')\nplt.grid(True)\nplt.show()","636516a2":"# display pieplot of label distribution\npie_plot = go.Pie(labels= type_count.index.to_list(), values= type_count.values.flatten(),\n                 hole= 0.2, text= type_count.index.to_list(), textposition='auto')\nfig = go.Figure([pie_plot])\nfig.update_layout(title_text='Pie Plot of Type Distribution')\nfig.show()","e6d01e08":"# display sample images of types\nfor label in ('Type 1', 'Type 2', 'Type 3'):\n    filepaths = files_df[files_df['label']==label]['filepath'].values[:5]\n    fig = plt.figure(figsize= (15, 6))\n    for i, path in enumerate(filepaths):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n        img = cv2.resize(img, (224, 224))\n        fig.add_subplot(1, 5, i+1)\n        plt.imshow(img)\n        plt.subplots_adjust(hspace=0.5)\n        plt.axis(False)\n        plt.title(label)","2de6d6f6":"#  split the data into train  and validation set\ntrain_df, eval_df = train_test_split(files_df, test_size= 0.2, stratify= files_df['label'], random_state= 1)\nval_df, test_df = train_test_split(eval_df, test_size= 0.5, stratify= eval_df['label'], random_state= 1)\nprint(len(train_df), len(val_df), len(test_df))","8e6cf2a1":"# loads images from dataframe\ndef load_images(dataframe):\n    features = []\n    filepaths = dataframe['filepath'].values\n    labels = dataframe['label'].values\n    \n    for path in filepaths:\n        img = cv2.imread(path)\n        resized_img = cv2.resize(img, (180, 180))\n        features.append(np.array(resized_img))\n    return np.array(features), np.array(labels)","e8b7cab1":"# load training and evaluation data\ntrain_features, train_labels = load_images(train_df)\nval_features, val_labels = load_images(val_df)\ntest_features, test_labels = load_images(test_df)","993fc834":"# check lengths of training and evaluation  sets\nlen(train_features), len(train_labels), len(test_features), len(test_labels), len(test_features), len(test_labels) ","8c8f9381":"# get image shape\nInputShape = train_features[0].shape\nprint(InputShape)","0720a466":"# normalize the features\nX_train = train_features\/255\nX_val  = val_features\/255\nX_test  = test_features\/255","914af80e":"# encode the labels\nle = LabelEncoder().fit(['Type 1', 'Type 2', 'Type 3'])\ny_train = le.transform(train_labels)\ny_val = le.transform(val_labels)\ny_test = le.transform(test_labels)","ff75913a":"# check unique labels\nnp.unique(y_train)","435afbbc":"# initialize image data generator for training and evaluation sets\ntrain_datagen = ImageDataGenerator(\n                                rotation_range = 40,\n                                zoom_range = 0.2,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                shear_range=0.2,\n                                horizontal_flip=True,\n                                vertical_flip = True)\n\neval_datagen = ImageDataGenerator()","4671f95b":"# apply data augmentation to features\nBATCH_SIZE= 32\ntrain_gen = train_datagen.flow(X_train, y_train, batch_size= BATCH_SIZE)\nval_gen = eval_datagen.flow(X_val, y_val, batch_size= BATCH_SIZE)\ntest_gen = eval_datagen.flow(X_test, y_test, batch_size= BATCH_SIZE)","62ddd785":"# show shape of each  batch\nfor data_batch, labels_batch in train_gen:\n    print('data batch shape: {} \\n labels batch shape: {}'.format(data_batch.shape, labels_batch.shape))\n    break","f35c1485":"# initialize pretrained vgg model base\nconv_base = VGG16(weights= 'imagenet', include_top= False, input_shape= (180, 180, 3))","88ca1ac4":"# show trainable layers before freezing\nprint('This is the number of trainable weights '\n'before freezing layers in the conv base:', len(conv_base.trainable_weights))","3e2786c7":"# freeze few layers of pretrained model\nfor layer in conv_base.layers[:-5]:\n    layer.trainable= False","3192d671":"# show trainable layers after freezing\nprint('This is the number of trainable weights '\n'after freezing layers in the conv base:', len(conv_base.trainable_weights))","a24f20b9":"# build model \nmodel = Sequential([conv_base, \n                    Flatten(),\n                   Dropout(0.5),\n                   Dense(3, activation='softmax')])","a1551579":"# compile model\nmodel.compile(optimizer= Adam(0.0001), loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])","317ffc96":"# show model summary\nmodel.summary()","f86be814":"# define training steps\nTRAIN_STEPS = len(train_df)\/\/BATCH_SIZE\nVAL_STEPS = len(val_df)\/\/BATCH_SIZE","cfd31e3c":"# initialize callbacks\nreduceLR = ReduceLROnPlateau(monitor='val_loss', patience=10, verbose= 1, mode='min', factor=  0.2, min_lr = 1e-5)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience = 20, verbose=1, mode='min', restore_best_weights= True)\n\ncheckpoint = ModelCheckpoint('cervicalModel.weights.hdf5', monitor='val_loss', verbose=1,save_best_only=True, mode= 'min')","a9644abf":"# train model\nhistory = model.fit(train_gen, steps_per_epoch= TRAIN_STEPS, validation_data=val_gen, validation_steps=VAL_STEPS, epochs= 100,\n                   callbacks= [reduceLR, early_stopping, checkpoint])","e0005504":"# read training history into dataframe\nhistory_df = pd.DataFrame(history.history)","779e9878":"# display training and validation history\n\n# display history of accurracy\nplt.figure(figsize= (15,6))\nplt.subplot(1,2,1)\nplt.plot(history_df['accuracy'], label= 'accuracy' )\nplt.plot(history_df['val_accuracy'], label= 'val_accuracy')\n# history_df[['acc', 'val_acc']]\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy History')\nplt.legend()\n\n# display history of loss\nplt.subplot(1,2,2)\nplt.plot(history_df['loss'], label= 'loss')\nplt.plot(history_df['val_loss'], label= 'val_loss')\n# history_df[['loss', 'val_loss']].plot()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss History')\nplt.legend()\n\nplt.show()","461ddd04":"# load best weights into model\nmodel.load_weights('cervicalModel.weights.hdf5')","9a4b8205":"# save model\nmodel.save('cancer_screen_model.h5')","586e6208":"# evaluate model on test set\nmodel.evaluate(test_gen)","51f98c7d":"# with open('cancer.pickle', 'wb') as f:\n#     pickle.dump(model, f)","30bc099d":"# get test data directory\ntest_dir = os.path.join(root_dir,'test', 'test')","42871be8":"# load test features and labels\ntest_filenames = []\ntest_features = []\nfor filename in os.listdir(test_dir):\n    test_filenames.append(filename)\n    filepath = os.path.join(test_dir, filename)\n    img = cv2.imread(filepath)\n    resized_img = cv2.resize(img, (180, 180))\n    test_features.append(np.array(resized_img)) ","d00ea349":"# show length of test features and labels\nprint(len(test_filenames), len(test_features))","ad897007":"# normalize test features\ntest_X = np.array(test_features)\ntest_X = test_X\/255","879d8334":"# get test predictions\ntest_predict = model.predict(test_X)\ntest_predict[0]","e7900a26":"# show encoded classes\nle.classes_","07d854e6":"# create dataframe of test predictions\nsub_df = pd.DataFrame(test_predict, columns= ['Type 1', 'Type 2', 'Type 3' ])\nsub_df['image_name'] = test_filenames\nsub_df = sub_df[['image_name', 'Type 1', 'Type 2', 'Type 3']]\nsub_df = sub_df.sort_values(['image_name']).reset_index(drop=True)\nsub_df.head()","a3fc4a76":"# create csv file of test predictions\nsub_df.to_csv('submission.csv', index=False)","eeb0681f":"\n# Cervical Cancer Screening Project \n# Notebook by:\n# Samuel Ozechi, Adebowale Akande\n# \n# \n# Task:\n# Develop an algorithm which accurately identifies and classifies a woman\u2019s cervix type based on images.\n# \n# Dataset: \n# intel-mobileodt-cervical-cancer-screening\n# \n# The major objectives of this notebook includes:\n# \n# Rid the dataset of bad images.  \n# Explore the dataset for useful insights in model building. \n# Apply useful image data processes to develop an efficient classifier.\n# Build, train and evaluate a classifier using transfer learning.\n# Highlight useful steps that can improve the data.","03f94dba":"#### Possible steps of improving the model\n1. Acquiring more quality data\n2. Utilizing regularization methods\n3. Using a model with less capacity","d0122734":"# Model building","5dff7294":"# Model Evaluation","353c7058":"### The training and validation histories show model overfitting.\n### This could be as a result of the number of training samples, the quality of the image data or the data distribution ","ffda8a1f":"# Loading Dataset ","aa9d7868":"# Data Cleaning and Exploration","5cafa621":"### The data distribution plot shows that type 3 class has more datapoints than other types, with type 1  having the least datapoints.\n\n### A pie plot is useful in visualizing the percentage of data distribution.\n","59d0b21f":"# Data Processing","e8f8fd82":"### The pie plot shows that more than half of the dataset belong to the type two class.\n### The model built with this dataset is expected to be bias towards the the type 2 class and have less precision for identifying the type 1 class. ","19c5a1fe":"# Importing Libraries"}}