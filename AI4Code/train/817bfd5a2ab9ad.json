{"cell_type":{"7adabaad":"code","a6b7687d":"code","5769c103":"code","12966996":"code","f06dffb3":"code","066dabee":"code","4d708e7d":"code","90420c93":"code","3dd2f219":"code","ae8129ad":"code","53ac58ce":"code","a259526f":"code","2eaaa721":"code","06c0c7d4":"markdown","8ac77979":"markdown","5313aff2":"markdown","040c22bb":"markdown","c7b7522c":"markdown","e9ea6974":"markdown","97e3d572":"markdown","38d8b52f":"markdown","87c04c0b":"markdown","34c5d9fe":"markdown","f09cdf62":"markdown","180409ee":"markdown"},"source":{"7adabaad":"import tensorflow as tf\nimport zipfile\nimport numpy as np\nimport random\nimport os\nfrom tqdm import tqdm\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# # Load the extension and start TensorBoard\n\n# %load_ext tensorboard\n# %tensorboard --logdir logs","a6b7687d":"SEED = 42\nnp.random.seed = SEED\n\nUNZIP_PATH = '..\/input\/data-science-bowl-2018\/'\nTRAIN_PATH = '.\/train\/'\nTEST_PATH = '.\/test\/'\n\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3","5769c103":"# Unzip data\nwith zipfile.ZipFile(UNZIP_PATH+'stage1_train.zip', 'r') as zip_ref:\n    zip_ref.extractall('.\/train')\n    \nwith zipfile.ZipFile(UNZIP_PATH+'stage1_test.zip', 'r') as zip_ref:\n    zip_ref.extractall('.\/test')","12966996":"# get list of all subfolders\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]","f06dffb3":"# define placeholders (also used to replace NaN in images to resize by 0)\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype = np.bool)","066dabee":"# Resize images and masks\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    \n    path = TRAIN_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:, :, :IMG_CHANNELS]\n    img = resize(\n        img, (IMG_HEIGHT, IMG_WIDTH), \n        mode = 'constant', \n        preserve_range = True\n    )\n    \n    X_train[n] = img # fill empty X_train with values from img \n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype = np.bool)\n    \n    for mask_file in next(os.walk(path + '\/masks\/'))[2]:\n        mask_ = imread(path + '\/masks\/' + mask_file)\n        mask_ = np.expand_dims(\n            resize(\n                mask_, \n                (IMG_HEIGHT, IMG_WIDTH), \n                mode = 'constant', \n                preserve_range = True\n            ), \n            axis = -1\n        )\n        mask = np.maximum(mask, mask_)\n    \n    Y_train[n] = mask","4d708e7d":"# test images\nX_test = np.zeros(\n    (\n        len(test_ids), \n        IMG_HEIGHT, \n        IMG_WIDTH, \n        IMG_CHANNELS\n    ), \n    dtype = np.uint8\n)\n\nsizes_test = []\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(\n        img, \n        (IMG_HEIGHT, IMG_WIDTH), \n        mode = 'constant', \n        preserve_range = True\n    )\n    X_test[n] = img","90420c93":"inputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\ns = tf.keras.layers.Lambda(lambda x: x\/255.0)(inputs) # normalization\n\n# Contraction path\nc1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(s) # start with normal distributed weights\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c1)\np1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n\nc2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)\nc2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c2)\np2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n\nc3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p2)\nc3 = tf.keras.layers.Dropout(0.2)(c3)\nc3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c3)\np3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n\nc4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p3)\nc4 = tf.keras.layers.Dropout(0.2)(c4)\nc4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c4)\np4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n\nc5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p4)\nc5 = tf.keras.layers.Dropout(0.3)(c5)\nc5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c5)\n\n# Expansive path\nu6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides = (2,2), padding = \"same\")(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nc6 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u6)\nc6 = tf.keras.layers.Dropout(0.2)(c6)\nc6 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c6)\n\nu7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides = (2,2), padding = \"same\")(c6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nc7 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)\nc7 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c7)\n\nu8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides = (2,2), padding = \"same\")(c7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nc8 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u8)\nc8 = tf.keras.layers.Dropout(0.1)(c8)\nc8 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c8)\n\nu9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides = (2,2), padding = \"same\")(c8)\nu9 = tf.keras.layers.concatenate([u9, c1])\nc9 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u9)\nc9 = tf.keras.layers.Dropout(0.1)(c9)\nc9 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c9)\n\noutputs = tf.keras.layers.Conv2D(1, (1,1), activation='sigmoid')(c9)\n\nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","3dd2f219":"# Callbacks\ncheckpoiter = tf.keras.callbacks.ModelCheckpoint('model.h5', verbose = 1, save_best_only = True)\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(patience = 5, monitor = 'val_loss'),\n    tf.keras.callbacks.TensorBoard(log_dir = 'logs')\n            ]","ae8129ad":"results = model.fit(\n    X_train, \n    Y_train, \n    validation_split = 0.1, \n    batch_size = 16, \n    epochs = 25, \n    callbacks = callbacks)","53ac58ce":"# Predictions\nidx = random.randint(0, len(X_train))\n\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose = 1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose = 1)\npreds_test = model.predict(X_test, verbose = 1)\n\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","a259526f":"# Sanity check on random training samples\nix = random.randint(0, len(preds_train_t))\nimshow(X_train[ix])\nplt.show()\nimshow(np.squeeze(Y_train[ix]))\nplt.show()\nimshow(np.squeeze(preds_train_t[ix]))\nplt.show()","2eaaa721":"# Sanity check on random val samples\nix = random.randint(0, len(preds_val_t))\nimshow(X_train[int(X_train.shape[0]*0.9):][ix])\nplt.show()\nimshow(np.squeeze(Y_train[int(X_train.shape[0]*0.9):][ix]))\nplt.show()\nimshow(np.squeeze(preds_val_t[ix]))\nplt.show()","06c0c7d4":"# <div id=\"chap2\">Load Data<\/div>","8ac77979":"<hr>\n<br>\n<div align='justify'><font color=\"#353B47\" size=\"4\">Thank you for taking the time to read this notebook. I hope that I was able to answer your questions or your curiosity and that it was quite understandable. <u>any constructive comments are welcome<\/u>. They help me to progress and motivate me to share better quality content. I am above all a passionate person who tries to advance my knowledge but also that of others. If you liked it, just let me know <u>i'd appreciate.<\/u> <\/font><\/div>\n<br>\n<div align='center'><font color=\"#353B47\" size=\"3\">Thank you and may passion guide you.<\/font><\/div>","5313aff2":"<hr>","040c22bb":"Constants","c7b7522c":"Libraries","e9ea6974":"<div align='center'><font size=\"5\" color='#353B47'>Image Segmentation<\/font><\/div>\n<div align='center'><font size=\"4\" color=\"#353B47\">Using U-Net with Keras<\/font><\/div>\n<br>\n<hr>","97e3d572":"# <div id=\"chap5\">5. Predict and Visualize<\/div>","38d8b52f":"# <div id=\"chap3\">Get Masks<\/div>","87c04c0b":"The u-net is convolutional network architecture for fast and precise segmentation of images. \n\n![](https:\/\/lmb.informatik.uni-freiburg.de\/people\/ronneber\/u-net\/u-net-architecture.png)\n\nU-net architecture (example for 32x32 pixels in the lowest resolution). Each blue box corresponds to a multi-channel feature map. The number of channels is denoted on top of the box. The x-y-size is provided at the lower left edge of the box. White boxes represent copied feature maps. The arrows denote the different operations.\n\nThis illustration is an example of Unet architecture but layers can have different size.","34c5d9fe":"# <div id=\"chap1\">1. Introduction<\/div>","f09cdf62":"# <div id=\"chap4\">4. Training Model<\/div>","180409ee":"## <div id=\"summary\">Table of contents<\/div>\n\n**<font size=\"2\"><a href=\"#chap1\">1. Introduction<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap2\">2. Load Data<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap3\">3. Get Masks<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">4. Training Model<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap5\">5. Predict and Visualize<\/a><\/font>**"}}