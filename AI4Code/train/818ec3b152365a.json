{"cell_type":{"9a507d9e":"code","b6869cff":"code","6b088599":"code","435ded8a":"code","b02318a2":"code","c2feb3c1":"code","5c516fc6":"code","04d2d164":"code","f14c5104":"code","dc01abea":"code","e1cadb0b":"code","dd1536fa":"code","e0eeb82b":"code","829d8d87":"code","007a7e8a":"code","dbcb5aae":"code","be586790":"code","3df27cfc":"code","a72b1fbd":"code","5d4d1dd7":"code","0d6e0d83":"code","8ca68799":"code","efe97a8f":"code","bcfec57c":"code","41012446":"code","15d23cd1":"code","737c65a0":"code","4925cd17":"code","df33d231":"code","037a73c1":"code","78c0c631":"code","315e19eb":"code","3a654464":"code","8a655a7b":"code","5b8dbf8b":"code","6aa02f0e":"markdown","74f4d21b":"markdown","5b4a73e0":"markdown","ff2f01bf":"markdown","33625885":"markdown","859f138e":"markdown","402b60ad":"markdown","b8d36fc0":"markdown","f2383978":"markdown","136f8336":"markdown","a56c7e1c":"markdown","9e4efe1b":"markdown","3d5e0c72":"markdown","2d660fcb":"markdown","bf3b2ff1":"markdown","c23577b4":"markdown","2521d606":"markdown","12427754":"markdown","b5d4bbf9":"markdown","55792335":"markdown","dc05d126":"markdown"},"source":{"9a507d9e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b6869cff":"train=pd.read_csv('..\/input\/act_train.csv',parse_dates=['date'])\ntest=pd.read_csv('..\/input\/act_test.csv',parse_dates=['date'])\npeople=pd.read_csv('..\/input\/people.csv',parse_dates=['date'])","6b088599":"train.head(1)","435ded8a":"test.head(1)","b02318a2":"people.head(1)","c2feb3c1":"train=pd.merge(train,people,on='people_id')\ntest=pd.merge(test,people,on='people_id')","5c516fc6":"train.info()","04d2d164":"test.info()","f14c5104":"train.outcome.plot(kind='hist')\nplt.show()","dc01abea":"def checkMissing(df):\n    column_names=[]\n    null_count=[]\n    for i in df.columns:\n        if df[i].isnull().sum()!=0:\n            column_names.append(i)\n            null_count.append(df[i].isnull().sum())\n    if len(null_count)==0:\n        print('There is no missing values!')\n    else:\n        plt.figure(figsize=(8,4))\n        sns.barplot(x=null_count,y=column_names,color='C0')\n        plt.show()\ncheckMissing(train)","e1cadb0b":"train.char_38.nunique()","dd1536fa":"plt.hist(train[train['outcome']==1]['char_38'],color='C1',alpha=0.7)\nplt.hist(train[train['outcome']==0]['char_38'],color='C0',alpha=0.7)\nplt.show()\nprint('Number of 0 value:',train[train .char_38==0]['char_38'].count())","e0eeb82b":"train.describe(include=['object']).transpose()","829d8d87":"len(set(test['group_1'])-set(train['group_1']))","007a7e8a":"for d in ['date_x', 'date_y']:\n    print('Start of ' + d + ': ' + str(train[d].min().date()))\n    print('  End of ' + d + ': ' + str(train[d].max().date()))\n    print('Range of ' + d + ': ' + str(train[d].max() - train[d].min()) + '\\n')","dbcb5aae":"# Impute the missing values with type 0\nfor i in train.columns:\n    if np.dtype(train[i])==np.dtype('object'):\n        train[i].fillna('type 0',inplace=True)","be586790":"for i in test.columns:\n    if np.dtype(test[i])==np.dtype('object'):\n        test[i].fillna('type 0',inplace=True)","3df27cfc":"checkMissing(train)\ncheckMissing(test)","a72b1fbd":"# Mean and Median outcome group by group_1 for train\noutcomeMeanGroupbyGroup_1=train.groupby(['group_1'])['outcome'].mean().to_frame().reset_index()\noutcomeMedianGroupbyGroup_1=train.groupby(['group_1'])['outcome'].median().to_frame().reset_index()\ndict_outcomeMeanGroupbyGroup_1=dict(zip(outcomeMeanGroupbyGroup_1['group_1'],outcomeMeanGroupbyGroup_1['outcome']))\ndict_outcomeMedianGroupbyGroup_1=dict(zip(outcomeMedianGroupbyGroup_1['group_1'],outcomeMedianGroupbyGroup_1['outcome']))\ntrain['outcomeMeanGroupbyGroup_1']=train['group_1'].map(lambda x: dict_outcomeMeanGroupbyGroup_1.get(x))\ntrain['outcomeMedianGroupbyGroup_1']=train['group_1'].map(lambda x: dict_outcomeMedianGroupbyGroup_1.get(x))\n\n# Mean and Median outcome group by group_1 for test\ntest['outcomeMeanGroupbyGroup_1']=test['group_1'].map(lambda x: dict_outcomeMeanGroupbyGroup_1.get(x))\ntest['outcomeMedianGroupbyGroup_1']=test['group_1'].map(lambda x: dict_outcomeMedianGroupbyGroup_1.get(x))","5d4d1dd7":"checkMissing(test)","0d6e0d83":"# Impute missing value for test\ntest['outcomeMeanGroupbyGroup_1']=test.groupby(['activity_category'])['outcomeMeanGroupbyGroup_1'].transform(lambda x: x.fillna(x.mean()))\ntest['outcomeMedianGroupbyGroup_1']=test.groupby(['activity_category'])['outcomeMedianGroupbyGroup_1'].transform(lambda x: x.fillna(x.mean()))","8ca68799":"checkMissing(test)","efe97a8f":"def featureEngineering(df):\n    # feature engineering for dates\n    listDate=['year', 'month', 'week', 'day', 'dayofweek', 'dayofyear','is_month_end', 'is_month_start', 'is_quarter_end', 'is_quarter_start', 'is_year_end', 'is_year_start']\n    for n in listDate:\n        df[n.upper()]=df['date_x'].map(lambda x: getattr(x,n))\n        df[n.upper()]=df['date_y'].map(lambda x: getattr(x,n))\n    \n    # Extract numbers from cateforical data and convert boolean to int\n    for i in df.columns:\n        if np.dtype(df[i])==np.dtype('object') and i not in ['activity_id','people_id']:\n            df[i]=df[i].map(lambda x:int(x.split(' ')[1]))\n        elif np.dtype(df[i])==np.dtype('bool'):\n            df[i]=df[i].map(lambda x:int(x))\n\n    return df","bcfec57c":"# Feature Engineering for train and test\ntrain=featureEngineering(train)\ntest=featureEngineering(test)","41012446":"# Check feature number of train and test after feature engineering\nmissingfeatures=list(set(train.columns.tolist())-set(test.columns.tolist()))\nmissingfeatures.remove('outcome')\nprint(missingfeatures)","15d23cd1":"train.head()","737c65a0":"X_train=train.drop(['outcome','date_x','date_y','activity_id','people_id'],axis=1).copy()\ny_train=train['outcome'].copy()\nX_test=test.drop(['date_x','date_y','activity_id','people_id'],axis=1).copy()","4925cd17":"X_train.head()","df33d231":"# To save some time. I used reduced dataset.","037a73c1":"# X_train_demo=X_train.iloc[:50000,:].copy()\n# y_train_demo=y_train.iloc[:50000].copy()","78c0c631":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","315e19eb":"# Cross validate model with Kfold cross validation\nkfold=StratifiedKFold(n_splits=2)","3a654464":"# I've narrow down the range of the parameters after some tryings in order to save some time.\nlgbm = LGBMClassifier(random_state=8)\n\nlgbm_param_grid = {'num_leaves' : [2,3],\n                'learning_rate' :   [0.004,0.005,0.006,0.007],\n                'n_estimators': [50,100]}\n\nlgbm = GridSearchCV(lgbm,param_grid = lgbm_param_grid, cv=kfold, scoring=\"accuracy\",n_jobs=2, verbose = 1)\n\nlgbm.fit(X_train,y_train)\n# How to use the output of GridSearch? Please see https:\/\/datascience.stackexchange.com\/questions\/21877\/how-to-use-the-output-of-gridsearch\n# Best score\nprint(lgbm.best_score_)\nprint(lgbm.best_params_)","8a655a7b":"results = pd.DataFrame({ 'activity_id' : test['activity_id'].values, \n                       'outcome': lgbm.predict_proba(X_test)[:,1] })","5b8dbf8b":"results.to_csv('red_hat_LightGBM.csv',index=False)","6aa02f0e":"## Missing Value Imputation","74f4d21b":"Train and test have same number of features","5b4a73e0":"## Check null values","ff2f01bf":"## Checking date","33625885":"# Feature Engineering","859f138e":"# Modeling","402b60ad":"## Check if it's a class imblance problem","b8d36fc0":"This is the 3rd stop of the Kaggle Challenge","f2383978":"Merge train with people and test with people.","136f8336":"## Prediction","a56c7e1c":"## Categorical Features","9e4efe1b":"## Mean and median outcome group by group_1","3d5e0c72":"# EDA","2d660fcb":"group_1 has a large amount of unique numbers and is the only \"group\" category","bf3b2ff1":"## Data Pre-processing","c23577b4":"It's obvious that the char_38 is larger when the outcome equales to 1. And there are a lot of 0 values.","2521d606":"There are 4325 group_1s that are in the test but not in the train. It may create null value when we do feature engineering later. ","12427754":"#  Import and cleaning","b5d4bbf9":"## Model tunning","55792335":"## The char_38\n\nThe char_38 is the only numeric feature except outcome. Let's look into it.","dc05d126":"According to the result, we can use \"accuracy\" as the measurement."}}