{"cell_type":{"4f56c825":"code","236b7b95":"code","2535e988":"code","6f3e3fc4":"code","8915e4d1":"code","b80714b2":"code","5cefae84":"code","5d182fd8":"code","6ce31081":"code","b3729db1":"code","a803b2a8":"code","22bcf91a":"code","216483f1":"code","e9bf8765":"code","f738f112":"code","0d010162":"code","fff12e56":"code","a5b2601d":"code","d377a105":"code","b66045f8":"code","00a45ede":"code","9bfa3d1c":"code","50215705":"markdown","dc2ccb90":"markdown","854efaf1":"markdown","34942f84":"markdown","24d8bee3":"markdown","6165f399":"markdown","18bffafd":"markdown","b1b09a4d":"markdown","931c69e9":"markdown","e2eb71a6":"markdown","4d3d0d5c":"markdown"},"source":{"4f56c825":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.layers import Dense, LSTM, Activation, Dropout\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam","236b7b95":"train = pd.read_csv('..\/input\/train.csv', index_col = [\"PassengerId\"])\ntest = pd.read_csv('..\/input\/test.csv', index_col = [\"PassengerId\"])\ncombination = [train,test]\n\ntrain.head()","2535e988":"train.describe(), test.describe()\n","6f3e3fc4":"train[[\"Survived\",\"Pclass\"]].groupby(\"Pclass\").mean()\n\n","8915e4d1":"train[[\"Survived\", \"Sex\"]].groupby(\"Sex\").mean()","b80714b2":"train['groups']=pd.cut(train.Age,[0,10,20,30,40,50,60,70,80])\ntrain.head()","5cefae84":"train[[\"Survived\", \"groups\"]].groupby(\"groups\").mean()","5d182fd8":"sns.barplot(train.groups, train.Survived)","6ce31081":"sns.barplot(train.Sex, train.Survived)\n","b3729db1":"sns.barplot(train.Pclass, train.Survived)","a803b2a8":"sns.barplot(train.Pclass, train.Survived, hue=train.Sex)","22bcf91a":"train.describe(include = [\"O\"]), test.describe(include = [\"O\"])","216483f1":"train=train.drop([\"Name\", \"Ticket\",\"Cabin\", \"groups\"], axis=1)\ntest=test.drop([\"Name\", \"Ticket\",\"Cabin\"], axis=1)\ntrain.head()","e9bf8765":"male_female = {\"male\":1,\n              \"female\":0}\n\ntrain[\"Sex\"]=train[\"Sex\"].map(male_female)\ntest[\"Sex\"]=test[\"Sex\"].map(male_female)\ntrain.head()","f738f112":"embar = {\"C\":2,\n        \"S\":1,\n        \"Q\": 0}\ntrain[\"Embarked\"]=train[\"Embarked\"].map(embar)\ntest[\"Embarked\"]=test[\"Embarked\"].map(embar)\ntrain.head()","0d010162":"\ntrain[\"Age\"]=train[\"Age\"].fillna(value=np.mean(train[\"Age\"]))\ntest[\"Age\"]=test[\"Age\"].fillna(value=np.mean(train[\"Age\"]))\ntest[\"Fare\"]=test[\"Fare\"].fillna(value=np.mean(train[\"Fare\"]))\ntrain[\"Embarked\"]=train[\"Embarked\"].fillna(value=round(np.mean(train[\"Embarked\"])))\n","fff12e56":"train_y = train[\"Survived\"].iloc[:].values\ntrain_x = train.drop([\"Survived\"], axis = 1).iloc[:,:].values\n\ntrain_x = train_x.reshape(train_x.shape[0],-1,1)\ntrain_x.shape","a5b2601d":"batch_size = 11\nepoch = 20\nhidden_units = 256 ","d377a105":"model = Sequential()\nmodel.add(LSTM(hidden_units, input_shape=train_x.shape[1:],batch_size=batch_size))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(1))\nmodel.compile(optimizer='Adam', loss = 'mean_squared_error',metrics = ['accuracy'] )\nmodel.fit(train_x,train_y, batch_size=batch_size, epochs=epoch, verbose = 1)\n","b66045f8":"out = pd.read_csv('..\/input\/gender_submission.csv', index_col = [\"PassengerId\"])\ny_test = out.iloc[:].values","00a45ede":"test_x = test.iloc[:,:].values\ntest_x = test_x.reshape(test_x.shape[0],-1,1)\nscores = model.evaluate(test_x, y_test, batch_size=batch_size)\npredictions = model.predict(test_x, batch_size = batch_size)\n","9bfa3d1c":"\nprint('LSTM test accuracy:', scores[1])","50215705":"### Converting Data and filling missing data\nSex are either male or females, hence we will convert this data to 1s and 0s respectively. Same thing can be applied to the embarked feature [0,1,2]. ","dc2ccb90":"### Frameworks\n- pandas\n- numpy\n- seaborn \n- keras\n- scikit-learn","854efaf1":"LSTM parameters","34942f84":"## Titanc Solution using LSTM network##\nThis is my first approach to solve the titanic Kaggle problem using LSTMs, of course improvements can be made.\nThe main way the algorithm works is to use all the features as a time-series data. \nI am open to comments and possible corrections on my code. \n","24d8bee3":"For this version I have decided to delete the data regarding names, cabin and tickets. Cabin has many N\/A values, names may not be directly related to the survival rate, however, their title could be relevant for future evaluations. In this case the name values are dropped, but in the future it could be interesting keeping the title of each passenger. ","6165f399":"LSTM architecture","18bffafd":"From the data above we get information regarding the various means and standard deviation of each data, furthermore we can see where we have missing values. For example in the training data set there are 714 values for the passengers' ages, however, we know that the total number of passengers is 891. \nThis information will be useful later on. For now I will try to find which features will have a heavier influence on the Survival and delete those featurues that will have a lower influence on the output.","b1b09a4d":"In the latter I have tried to divide the passengers by age group, by doing so we see how age has a big impact on the survival of the passenger, kids between 0-10 yrs have a higher survival rate. ","931c69e9":"The data at our disposal is numerical (age, Pclass, etc.), alphabetical (name, sex & embarked) and alphanumerical (tickets). Let's get some further insight on our data:","e2eb71a6":"## Model ##\nExtracting data","4d3d0d5c":"### Plotting ###\nTo have a better view of the data I have decided to plot it. "}}