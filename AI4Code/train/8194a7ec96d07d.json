{"cell_type":{"1daff3c4":"code","015c6d9d":"code","bc2d2099":"code","726badc2":"code","f619abdf":"code","3b24549b":"code","adf3de3c":"code","162cc860":"code","b588cff8":"code","056e192f":"code","953acc1c":"code","84f2cb21":"code","da94c0d6":"code","a5ea6a95":"code","64aca9c8":"code","c3992b05":"code","f52f8bc2":"code","ae7fc048":"code","893345a7":"code","397bb9ac":"code","7da80aa6":"code","06d16ed8":"code","1ed40475":"code","edec60d3":"code","505e7566":"code","1dbfa2be":"code","7e60145d":"code","2470c1e1":"code","7fd902ef":"code","a8ebbceb":"code","2c911d88":"markdown","b787f5e7":"markdown","0976a202":"markdown","0883445a":"markdown","9dca68b2":"markdown","299bbce9":"markdown","08e4c397":"markdown"},"source":{"1daff3c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","015c6d9d":"import pandas as pd\nimport numpy as np","bc2d2099":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='whitegrid')","726badc2":"dataset = pd.read_csv('\/kaggle\/input\/diamonds\/diamonds.csv',)","f619abdf":"dataset.describe()","3b24549b":"dataset.head()","adf3de3c":"#removing index column at 0\ndataset = dataset.iloc[:,1:]\ndataset.head()","162cc860":"sns.pairplot(dataset)","b588cff8":"dataset.cut.value_counts().plot(kind='bar')","056e192f":"bar_plot_of_cuts = dataset.groupby('cut').mean().price.plot.barh()\nbar_plot_of_cuts.set_xlim(7.5,8.2)","953acc1c":"bar_plot_of_color = dataset.groupby('color').mean().price.plot.barh()\nbar_plot_of_color.set_xlim(7.5,8.2)\nbar_plot_of_color.set_title(' Color vs price')","84f2cb21":"bar_plot_of_carat = dataset.groupby('price').mean().carat.plot.hist(bins=20)\n#bar_plot_of_carat.set_ylim(7.5,8.1)\nbar_plot_of_carat.set_title(' Carat vs price')","da94c0d6":"sns.heatmap(dataset.corr(),cmap=\"BrBG\")","a5ea6a95":"# removing  outliers \ndataset = dataset[(dataset['x']<dataset['x'].quantile(.99)) & \n                  (dataset['y']<dataset['y'].quantile(.99)) & \n                  (dataset['z']<dataset['z'].quantile(.99)) ]\n\n# Removing 0s in x y and z columns\ndataset = dataset[(dataset['x']>0.01) & (dataset['y']>0.01) & (dataset['z']>0.01) ]","64aca9c8":"#Getting dummies for categorical columns\ndf = pd.get_dummies(dataset,drop_first=True)","c3992b05":"#Seggregating features and labels\nX = df.drop(['price'],1)\ny = df['price']","f52f8bc2":"# adding 2nd degree polynomial to the features\nfrom sklearn.preprocessing import PolynomialFeatures\nPl = PolynomialFeatures(degree=2)\nX = Pl.fit_transform(X)","ae7fc048":"# test and train split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=142)","893345a7":"from sklearn.linear_model import LinearRegression","397bb9ac":"lm = LinearRegression()","7da80aa6":"model =lm.fit(X_train,y_train)","06d16ed8":"# Accuracy \ny_pred = model.predict((X_test))\nmodel.score(X_test,y_test)","1ed40475":"# RMSE\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nprint(\"RMSE: {}\".format(np.sqrt(mean_squared_error((y_test),(y_pred)))))\nprint(\"R2  : {}\".format(np.sqrt(r2_score((y_test),(y_pred)))))","edec60d3":"# RMSE\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nprint(\"RMSE: {}\".format(np.sqrt(mean_squared_error(np.exp(y_test)-1,np.exp(y_pred)-1))))\nprint(\"R2  : {}\".format(np.sqrt(r2_score(np.exp(y_test)-1,np.exp(y_pred)-1))))","505e7566":"plt.scatter(((y_test)),((y_test))-((y_pred)),alpha=.2)\nplt.xlabel('Y_Test')\nplt.ylabel('Y_Pred')\nplt.title('Residuals of test set')\nplt.show()","1dbfa2be":"\nsns.distplot((np.exp(y_test)-1)-(np.exp(y_pred)-1)).set_title('Histogram of residuals')\n\n","7e60145d":"plt.scatter((np.exp(y_test)-1),(np.exp(y_pred)-1))\nplt.xlabel('Y_Test')\nplt.ylabel('Y_Pred')\nplt.title(' Actual vs Predicted on Test set')","2470c1e1":"output = pd.Series((np.exp(y_pred)-1))","7fd902ef":"output.to_csv('Final Output.csv')","a8ebbceb":"model.coef_","2c911d88":"Premium and ideal cut is not having high mean price that is strange. Also very good is price low than the good cut. very strange behaviour. I will leave it for sumbody having domain knowledge.","b787f5e7":"Very unbalanced feature classes.","0976a202":"Some random category labels","0883445a":"Price being maximum for 0.7 carat diamonds","9dca68b2":"Outliers are detected in x ,y, z columns that distort the graphs. Some column show skewed distribution ","299bbce9":"#Log transformation of the numerical columns \nfor i in dataset.columns:\n    if dataset[i].dtype != 'O' :\n        dataset[i] = np.log(dataset[i] + 1)","08e4c397":" High Correlation is detected"}}