{"cell_type":{"b7679d37":"code","123fcdf9":"code","194a8e3e":"code","f885146d":"code","772e2816":"code","9f41b2ba":"code","acc1f0cb":"code","20bc64f2":"code","fbbdba80":"code","72e3e2b6":"code","6a81ee06":"code","c0ba4259":"code","9667d3b8":"code","280221d2":"code","fd6ac682":"code","c29e2dd5":"markdown","7b460d84":"markdown"},"source":{"b7679d37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","123fcdf9":"import torch\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as Data\nimport torchvision\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt","194a8e3e":"train_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntrain_data.head()","f885146d":"train_data['label'].value_counts()","772e2816":"# CUDA for PyTorch\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")","9f41b2ba":"train_labels = train_data['label'].values\ntrain_inputs,test_inputs = train_data.values[:,1:],test_data.values\ntrain_inputs = train_inputs.reshape(-1,1,28,28)\ntest_inputs = test_inputs.reshape(-1,1,28,28)","acc1f0cb":"#by analyze the plotted miss matched image, some images are rotated, erased partly, so add the augmentation accordingly\ntrain_transform = transforms.Compose([\n        transforms.ToPILImage(),\n#       transforms.RandomApply(trans, p=0.5),\n#        transforms.RandomResizedCrop(28, scale=(0.9, 1.0), ratio=(0.9, 1.1), interpolation=2),\n#        transforms.RandomPerspective(0.2),\n        transforms.RandomAffine(degrees=10, translate=(0.1,0.1), scale=(0.9,1.1), fillcolor=0),\n#        transforms.RandomRotation(10, fill=(0,)), \n        transforms.ToTensor(),\n#        transforms.RandomErasing(p=0.5, scale=(0.005, 0.01), ratio=(0.5, 2.0), value=0, inplace=False),\n#        transforms.Normalize((0.1307,),(0.3081,))\n    ])\n    \nval_transform = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n#        transforms.Normalize((0.1307,),(0.3081,))\n    ])","20bc64f2":"# Random split Dataset\ntrain_labels = torch.from_numpy(train_labels).long()\ntrain_inputs = torch.from_numpy(train_inputs).float()\ntest_inputs = torch.from_numpy(test_inputs).float()\n\ninit_dataset = Data.TensorDataset(\n    train_inputs,\n    train_labels\n)\ntrain_size = int(0.8 * len(init_dataset))\nval_size = len(init_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(init_dataset, [train_size, val_size])\n\nclass MyDataset(Data.Dataset):\n    def __init__(self, dataset, transformation = None):\n        self.transformations = transformation\n        self.dataset = dataset\n        \n    def __getitem__(self, index):\n        self.inputs, self.labels = self.dataset[index]\n        data = self.inputs\n        if self.transformations is not None:\n            data = self.transformations(data)\n        return (data, self.labels)\n \n    def __len__(self):\n        return len(self.dataset)\n    \ntrain_dataset = MyDataset(train_dataset, train_transform)\nval_dataset = MyDataset(val_dataset, val_transform)\n\nclass TestDataset(Data.Dataset):\n    def __init__(self, inputs):\n        self.transformations = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.ToTensor()\n            ])\n        self.inputs = inputs\n        \n    def __getitem__(self, index):\n        # stuff\n        data = self.inputs[index]\n        data = self.transformations(data)\n        return data\n \n    def __len__(self):\n        return len(self.inputs)\n\n# Parameters\nparams_test = {'batch_size': 64,\n          'shuffle': False,\n          'num_workers': 0}\n\n# Generators\ntest_dataset = TestDataset(test_inputs)\ntest_loader = Data.DataLoader(test_dataset, **params_test)\n#dataiter_test = iter(test_loader)\n#images_test = next(dataiter_test)\n\n# functions to show an image\ndef imshow(img):\n    npimg = img.cpu().numpy()*255.0\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n    \n# show images\nfor i,test_input in enumerate(test_loader):\n    imshow(torchvision.utils.make_grid(test_input))\n    if i > 20:\n        break","fbbdba80":"# Parameters\nparams = {'batch_size': 1024,\n          'shuffle': True,\n          'num_workers': 0}\nmax_epochs = 200\n\n# Generators\ntrain_loader = Data.DataLoader(train_dataset, **params)\nval_loader = Data.DataLoader(val_dataset, **params)","72e3e2b6":"params_show = {'batch_size': 64,\n          'shuffle': True,\n          'num_workers': 0}\n\n# get some random training images\ntrain_show_loader = Data.DataLoader(train_dataset, **params_show)\nfor i in range(10):\n    dataiter = iter(train_show_loader)\n    images, labels = next(dataiter)\n\n    # show images\n    imshow(torchvision.utils.make_grid(images))\n# print labels\n#print(labels.reshape(8,8))","6a81ee06":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n        self.conv1_bn = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 32, 3, 1, 1)\n        self.conv2_bn = nn.BatchNorm2d(32)\n#        self.pool = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(32, 32, 5, 2, 2)\n        self.conv3_bn = nn.BatchNorm2d(32)\n        self.dropout1 = nn.Dropout2d(0.4)\n        self.conv4 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv4_bn = nn.BatchNorm2d(64)\n        self.conv5 = nn.Conv2d(64, 64, 3, 1, 1)\n        self.conv5_bn = nn.BatchNorm2d(64)\n        self.conv6 = nn.Conv2d(64, 64, 5, 2, 2)\n        self.conv6_bn = nn.BatchNorm2d(64)\n        self.dropout2 = nn.Dropout(0.4)\n        self.conv7 = nn.Conv2d(64, 128, 4, 1, 0)\n        self.conv7_bn = nn.BatchNorm2d(128)\n        self.dropout3 = nn.Dropout(0.4)\n        self.fc1 = nn.Linear(128 * 4 * 4, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1_bn(self.conv1(x)))\n        x = F.relu(self.conv2_bn(self.conv2(x)))\n        x = self.dropout1(F.relu(self.conv3_bn(self.conv3(x))))\n        x = F.relu(self.conv4_bn(self.conv4(x)))\n        x = F.relu(self.conv5_bn(self.conv5(x)))\n        x = self.dropout2(F.relu(self.conv6_bn(self.conv6(x))))\n        x = F.relu(self.conv7_bn(self.conv7(x)))\n        x = self.dropout3(x.view(-1, 128 * 4 * 4))\n        x = self.fc1(x)\n        return x\n\nnet = Net().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\n#max_pred_ind = (97,9)\n#PATH = '\/kaggle\/input\/20200301digit-recognizer-params\/20200301params_epoch97_ste{}-step{}.dict'.format(max_pred_ind[0],max_pred_ind[1])\n#net.load_state_dict(torch.load(PATH))","c0ba4259":"min_loss = 1\nmin_loss_ind = 1\ntrain_loss_list = []\nval_loss_list = []\nfor epoch in range(max_epochs):\n    running_loss = 0.0\n    val_loss = 0.0\n    for i, (train_inputs, train_labels) in enumerate(train_loader):\n        net.train()\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(train_inputs.to(device))\n        loss = criterion(outputs, train_labels.to(device))\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if (i % 10 == 9) or (i == len(train_loader)-1):    # print every 10 mini-batches and last mini-batch in an epoch\n#            print('epoch{},step{} training loss: {}'.format(epoch, i, running_loss\/10))            \n            running_loss_val = 0.0\n            if i == len(train_loader)-1:\n                train_loss_list.append(running_loss\/(len(train_loader)%10))\n            else:\n                train_loss_list.append(running_loss\/10)\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                net.eval()\n                for data in val_loader:\n                    val_inputs, val_labels = data\n                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n                    val_outputs = net(val_inputs)\n                    val_loss = criterion(val_outputs, val_labels)\n                    running_loss_val += val_loss.item()\n                    _, predicted = torch.max(val_outputs.data, 1)\n                    total += val_labels.size(0)\n                    correct += (predicted == val_labels).sum().item()\n                acc = 100 * correct \/ total\n                if min_loss > running_loss_val\/len(val_loader):\n                    min_loss = running_loss_val\/len(val_loader)\n                    min_loss_ind = (epoch, i)\n                if i == len(train_loader)-1:\n                    print('epoch{},step{} train loss: {}, val loss: {}'.format(epoch, i, running_loss\/(len(train_loader)%10), running_loss_val\/len(val_loader)))\n                else:\n                    print('epoch{},step{} train loss: {}, val loss: {}'.format(epoch, i, running_loss\/10, running_loss_val\/len(val_loader)))\n                val_loss_list.append(running_loss_val\/len(val_loader))\n                print('Accuracy of the network on the validation images: {}%\\n'.format(acc))\n                torch.save(net.state_dict(),'params_epoch{}_step{}.dict'.format(epoch,i))\n            running_loss = 0.0\n            \nprint('min loss index', min_loss_ind, 'min loss', min_loss)","9667d3b8":"plt.plot(range(len(train_loss_list)),train_loss_list, label='train_loss')\nplt.plot(range(len(train_loss_list)),val_loss_list, label='val_loss')\nplt.legend()\nplt.show()","280221d2":"\nPATH = 'params_epoch{}_step{}.dict'.format(min_loss_ind[0],min_loss_ind[1])\nnet_optimal = Net().to(device)\nnet_optimal.load_state_dict(torch.load(PATH))\nnet_optimal.eval()\ntest_outputs = []\nwith torch.no_grad():\n    for test_input in test_loader:\n        test_output = net_optimal(test_input.to(device))\n        _, test_predicted = torch.max(test_output.data, 1)\n        for test_pre in test_predicted.cpu().numpy():\n            test_outputs.append(test_pre)","fd6ac682":"test_outputs = np.array(test_outputs)\ntest_outputs[0]\nsubmit_result = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsubmit_result['Label'] = test_outputs\nsubmit_result.to_csv('submit_result.csv',index=False)","c29e2dd5":"#early stop and the optimal param is epoch12,step9 train loss: 0.020601647906005383, val loss: 0.025461613280432564\n#Accuracy of the network on the validation images: 99.3452380952381%\nmin_loss_ind = (12,9)\nPATH = '\/kaggle\/working\/params_epoch{}_step{}.dict'.format(min_loss_ind[0],min_loss_ind[1])\nnet_optimal = Net().to(device)\nnet_optimal.load_state_dict(torch.load(PATH))\nnet_optimal.eval()\ncountError = 0\n\nparams = {'batch_size': 1,\n          'shuffle': False,\n          'num_workers': 0}\n# Generators\nval_loader = Data.DataLoader(val_dataset, **params)\n\nwith torch.no_grad():\n    net.eval()\n    for data in val_loader:\n        val_inputs, val_labels = data\n        val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n        val_outputs = net(val_inputs)\n        label = val_labels[0].item()\n        _, predicted = torch.max(val_outputs.data, 1)\n        if label != predicted:\n            countError += 1\n            imshow(torchvision.utils.make_grid(val_inputs))\nprint(countError)","7b460d84":"PATH = '\/kaggle\/working\/params_epoch{}_step{}.dict'.format(min_loss_ind[0],min_loss_ind[1])\nnet.load_state_dict(torch.load(PATH))\n\nmin_loss = 1\nmin_loss_ind = 1\ntrain_loss_list = []\nval_loss_list = []\nfor epoch in range(20):\n    running_loss = 0.0\n    val_loss = 0.0\n    for i, (train_inputs, train_labels) in enumerate(train_loader):\n        net.train()\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(train_inputs.to(device))\n        loss = criterion(outputs, train_labels.to(device))\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if (i % 10 == 9) or (i == len(train_loader)-1):    # print every 10 mini-batches and last mini-batch in an epoch\n#            print('epoch{},step{} training loss: {}'.format(epoch, i, running_loss\/10))            \n            running_loss_val = 0.0\n            if i == len(train_loader)-1:\n                train_loss_list.append(running_loss\/(len(train_loader)%10))\n            else:\n                train_loss_list.append(running_loss\/10)\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                net.eval()\n                for data in val_loader:\n                    val_inputs, val_labels = data\n                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n                    val_outputs = net(val_inputs)\n                    val_loss = criterion(val_outputs, val_labels)\n                    running_loss_val += val_loss.item()\n                    _, predicted = torch.max(val_outputs.data, 1)\n                    total += val_labels.size(0)\n                    correct += (predicted == val_labels).sum().item()\n                acc = 100 * correct \/ total\n                if min_loss > running_loss_val\/len(val_loader):\n                    min_loss = running_loss_val\/len(val_loader)\n                    min_loss_ind = (epoch, i)\n                if i == len(train_loader)-1:\n                    print('epoch{},step{} train loss: {}, val loss: {}'.format(epoch, i, running_loss\/(len(train_loader)%10), running_loss_val\/len(val_loader)))\n                else:\n                    print('epoch{},step{} train loss: {}, val loss: {}'.format(epoch, i, running_loss\/10, running_loss_val\/len(val_loader)))\n                val_loss_list.append(running_loss_val\/len(val_loader))\n                print('Accuracy of the network on the validation images: {}%\\n'.format(acc))\n                torch.save(net.state_dict(),'params_epoch{}_step{}.dict'.format(epoch,i))\n            running_loss = 0.0\n            \nprint('min loss index', min_loss_ind, 'min loss', min_loss)"}}