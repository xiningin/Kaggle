{"cell_type":{"31f1cc59":"code","550be38f":"code","ab8bb48b":"code","77537d5c":"code","b9668e54":"code","670e37cd":"code","ae58c4d0":"code","2c2226c7":"code","fbb234ef":"code","28554dfb":"code","098d8785":"code","7eb2bf36":"code","3c5b231e":"code","977db4da":"code","fdeaafa5":"markdown"},"source":{"31f1cc59":"import os\nimport cv2\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.optimizers import SGD\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Flatten, Activation, Dropout\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D","550be38f":"PATH = \"..\/input\/shapes\/\"\nIMG_SIZE = 64\nShapes = [\"circle\", \"square\", \"triangle\", \"star\"]\nLabels = []\nDataset = []\n\n# From kernel: https:\/\/www.kaggle.com\/smeschke\/load-data\nfor shape in Shapes:\n    print(\"Getting data for: \", shape)\n    #iterate through each file in the folder\n    for path in os.listdir(PATH + shape):\n        #add the image to the list of images\n        image = cv2.imread(PATH + shape + '\/' + path)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        Dataset.append(image)\n        #add an integer to the labels list \n        Labels.append(Shapes.index(shape))\n\nprint(\"\\nDataset Images size:\", len(Dataset))\nprint(\"Image Shape:\", Dataset[0].shape)\nprint(\"Labels size:\", len(Labels))","ab8bb48b":"sns.countplot(x= Labels)","77537d5c":"print(\"Count of Star images:\", Labels.count(Shapes.index(\"star\")))\nprint(\"Count of Circles images:\", Labels.count(Shapes.index(\"circle\")))\nprint(\"Count of Squares images:\", Labels.count(Shapes.index(\"square\")))\nprint(\"Count of Triangle images:\", Labels.count(Shapes.index(\"triangle\")))","b9668e54":"index = np.random.randint(0, len(Dataset) - 1, size= 20)\nplt.figure(figsize=(15,10))\n\nfor i, ind in enumerate(index, 1):\n    img = Dataset[ind]\n    lab = Labels[ind]\n    lab = Shapes[lab]\n    plt.subplot(4, 5, i)\n    plt.title(lab)\n    plt.axis('off')\n    plt.imshow(img)","670e37cd":"# Normalize images\nDataset = np.array(Dataset)\nDataset = Dataset.astype(\"float32\") \/ 255.0\n\n# One hot encode labels\nLabels = np.array(Labels)\nLabels = to_categorical(Labels)\n\n# Split Dataset to train\\test\n(trainX, testX, trainY, testY) = train_test_split(Dataset, Labels, test_size=0.2, random_state=42)\n\nprint(\"X Train shape:\", trainX.shape)\nprint(\"X Test shape:\", testX.shape)\nprint(\"Y Train shape:\", trainY.shape)\nprint(\"Y Test shape:\", testY.shape)","ae58c4d0":"class LeNet():\n    @staticmethod\n    def build(numChannels, imgRows, imgCols, numClasses,  pooling= \"max\", activation= \"relu\"):\n        # initialize the model\n        model = Sequential()\n        inputShape = (imgRows, imgCols, numChannels)\n\n        # add first set of layers: Conv -> Activation -> Pool\n        model.add(Conv2D(filters= 6, kernel_size= 5, input_shape= inputShape))\n        model.add(Activation(activation))\n\n        if pooling == \"max\":\n            model.add(MaxPooling2D(pool_size= (2, 2), strides= (2, 2)))\n        else:\n            model.add(AveragePooling2D(pool_size= (2, 2), strides= (2, 2)))\n\n        # add second set of layers: Conv -> Activation -> Pool\n        model.add(Conv2D(filters= 16, kernel_size= 5))\n        model.add(Activation(activation))\n\n        if pooling == \"avg\":\n            model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n        else:\n            model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # Flatten -> FC 120 -> Dropout -> Activation\n        model.add(Flatten())\n        model.add(Dense(120))\n        model.add(Dropout(0.5))\n        model.add(Activation(activation))\n\n        # FC 84 -> Dropout -> Activation\n        model.add(Dense(84))\n        model.add(Dropout(0.5))\n        model.add(Activation(activation))\n\n        # FC 4-> Softmax\n        model.add(Dense(numClasses))\n        model.add(Activation(\"softmax\"))\n\n        return model","2c2226c7":"BS = 120\nLR = 0.01\nEPOCHS = 10\nopt = SGD(lr= LR)","fbb234ef":"# First model with max pooling\nmodel = LeNet.build(3, IMG_SIZE, IMG_SIZE, 4, pooling= \"max\")\nmodel.compile(loss= \"categorical_crossentropy\", optimizer= opt, metrics= [\"accuracy\"])\nmodel.summary()","28554dfb":"# Train model\nH1 = model.fit(trainX, trainY, validation_data= (testX, testY), batch_size= BS,\n              epochs= EPOCHS, verbose=1)\n\n# Evaluate the train and test data\nscores_train = model.evaluate(trainX, trainY, verbose= 1)\nscores_test = model.evaluate(testX, testY, verbose= 1)\n\nprint(\"\\nModel with Max Pool Accuracy on Train Data: %.2f%%\" % (scores_train[1]*100))\nprint(\"Model with Max Pool Accuracy on Test Data: %.2f%%\" % (scores_test[1]*100))","098d8785":"# Second model with average pooling\nmodel = LeNet.build(3, IMG_SIZE, IMG_SIZE, 4, pooling= \"average\")\nmodel.compile(loss= \"categorical_crossentropy\", optimizer= opt, metrics= [\"accuracy\"])\n\nmodel.summary()","7eb2bf36":"# Train model\nH2 = model.fit(trainX, trainY, validation_data= (testX, testY), batch_size= BS,\n              epochs= EPOCHS, verbose= 1)\n\n# Evaluate the train and test data\nscores_train = model.evaluate(trainX, trainY, verbose= 1)\nscores_test = model.evaluate(testX, testY, verbose= 1)\n\nprint(\"\\nModel with Average Pool Accuracy on Train Data: %.2f%%\" % (scores_train[1]*100))\nprint(\"Model with Average Pool Accuracy on Test Data: %.2f%%\" % (scores_test[1]*100))","3c5b231e":"plt.figure(figsize=(15,5))\nplt.plot(np.arange(0, EPOCHS), H1.history[\"acc\"], label=\"Max Pool Train Acc\")\nplt.plot(np.arange(0, EPOCHS), H1.history[\"val_acc\"], label=\"Max Pool Test Acc\")\nplt.plot(np.arange(0, EPOCHS), H2.history[\"acc\"], label=\"Avg Pool Train Acc\")\nplt.plot(np.arange(0, EPOCHS), H2.history[\"val_acc\"], label=\"Avg Pool Test Acc\")\nplt.title(\"Comparing Models Train\\Test Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Accuracy\")\nplt.legend(loc=\"upper left\")","977db4da":"plt.figure(figsize=(15,5))\nplt.plot(np.arange(0, EPOCHS), H1.history[\"loss\"], label=\"Max Pool Train Loss\")\nplt.plot(np.arange(0, EPOCHS), H1.history[\"val_loss\"], label=\"Max Pool Test Loss\")\nplt.plot(np.arange(0, EPOCHS), H2.history[\"loss\"], label=\"Avg Pool Train Loss\")\nplt.plot(np.arange(0, EPOCHS), H2.history[\"val_loss\"], label=\"Avg Pool Test Loss\")\nplt.title(\"Comparing Models Train\\Test Loss\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\")\nplt.legend(loc=\"upper left\")","fdeaafa5":"**Interesting observations**\n1. The train loss for the *max pool* is lower than that of the *average pool*.\n2. The accuracy for *max pool* starts higher than *average pool*.\n3. Final accuracy for *max pool* is still higher than *average pool*.\n"}}