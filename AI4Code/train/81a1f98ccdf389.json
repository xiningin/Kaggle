{"cell_type":{"9dbf096e":"code","dd226732":"code","f992a23c":"code","dde04627":"code","c8ef66fd":"code","526deedc":"code","22e6b31b":"code","bce98d2b":"code","c7096cc2":"code","f1a827e7":"code","acd4551d":"code","d9d01a3d":"code","abb240b9":"code","5913ad3b":"code","35abeeda":"code","ad9c10b5":"code","0ea55425":"code","103fba8d":"code","542de01c":"code","ba787d51":"code","bdbf562f":"code","bc41ae93":"code","19423e54":"code","380f1f0a":"code","e16720eb":"code","a69715d7":"code","8cdecc46":"code","dd79990d":"code","e0b95a5b":"code","f2ae74bf":"code","582342b8":"code","74bb9fb3":"code","5dcb474e":"code","12f37a3d":"code","de234b0c":"code","5aefc4eb":"code","43d776bf":"code","2a4f355e":"code","565c2ab6":"code","33615c89":"code","695bb216":"code","8cbe95b1":"code","b52515fc":"code","cfe50d13":"code","a7e0fac6":"code","14a20cc4":"code","8adf2686":"code","0fb8e6ad":"code","e0a401d1":"code","1cda4f0f":"code","240ed0b8":"code","8ed6443f":"code","276829b9":"code","eb9eaa7a":"code","553ceb7e":"code","1285e9a8":"code","880a6b1d":"code","fe6cf08b":"code","cbd5916e":"code","586206ac":"code","3001e120":"code","24c5dfef":"code","da0fb122":"code","426ebb23":"code","39ea4b2b":"code","c68d7b5a":"code","92568802":"code","a83fde79":"code","1988ad27":"code","d40f83cc":"code","2d848fd6":"code","4736eef9":"code","8786e9d9":"code","86cc2972":"code","3dc35486":"code","24a0c562":"code","1339ab05":"code","f2af758a":"markdown","7ce933a8":"markdown","36681cf7":"markdown","88bfa76a":"markdown","e5965cb2":"markdown","f8699939":"markdown","b8429517":"markdown","d3067314":"markdown","1a1e5bd3":"markdown","058f6c9c":"markdown","254b310b":"markdown","0d742dbd":"markdown","db1650bf":"markdown","2bc72c0d":"markdown","ac72251c":"markdown","a1950119":"markdown","5e2b7d43":"markdown","f119fa65":"markdown","f91b441f":"markdown","fe409614":"markdown","1dcfbfa2":"markdown","bf39e45c":"markdown","0b188894":"markdown","8a0dd871":"markdown","e8549e50":"markdown","4f591f99":"markdown","31b73e68":"markdown","6e6160ca":"markdown","20934da6":"markdown","ca8315ee":"markdown","d226bee9":"markdown","30ec1fa9":"markdown","2d72b36e":"markdown","8907c757":"markdown","2d2fad28":"markdown","e5cde314":"markdown","19655368":"markdown","fe5f1447":"markdown","e3787d01":"markdown","86344159":"markdown","b884a1af":"markdown","ca737179":"markdown","e5df5a69":"markdown","01cadc1c":"markdown","394fed2d":"markdown","02faa5ae":"markdown","5b0e70fc":"markdown","ade1bf4d":"markdown"},"source":{"9dbf096e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('fivethirtyeight')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd226732":"data = pd.read_csv(\"\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv\", delimiter = '\\t')","f992a23c":"data.head()","dde04627":"print(\"Data has\\033[1m\" , data.shape[0] , \"\\033[0mrows and\\033[1m\", data.shape[1] , \"\\033[0mcolumns\")","c8ef66fd":"data.columns","526deedc":"data_info = pd.DataFrame(columns=['Name of Col', 'Num of Null', 'Dtype', 'N_Unique'])\n\nfor i in range(0, len(data.columns)):\n    data_info.loc[i] = [data.columns[i],\n                        data[data.columns[i]].isnull().sum(),\n                        data[data.columns[i]].dtypes,\n                        data[data.columns[i]].nunique()] \n    \ndata_info","22e6b31b":"data.drop(labels=['ID','Z_CostContact','Z_Revenue'],axis=1,inplace=True)","bce98d2b":"data['Dt_Customer']= pd.to_datetime(data['Dt_Customer'],format='%d-%m-%Y')","c7096cc2":"data['month']=pd.DatetimeIndex(data['Dt_Customer']).month\ndata['year']=pd.DatetimeIndex(data['Dt_Customer']).year","f1a827e7":"plt.hist(x=data['Year_Birth'],edgecolor='white',bins=10,color='#26527D')\nplt.title('Distribution of Birth Year')","acd4551d":"data.loc[data['Year_Birth']<=1900,'Year_Birth']=np.round(data['Year_Birth'].mean()).astype(int)","d9d01a3d":"data['Age'] = 2021-data['Year_Birth']","abb240b9":"sns.displot(data=data,x='Age',kde=True,color='#26527D')\nplt.title('Distribution of Age')","5913ad3b":"print(\"The Age looks \\033[1mnormally distributed\\033[0m and ranges between:\\033[1m\" ,data['Age'].min(), \"-\" ,data['Age'].max() ,\"years \")","35abeeda":"plt.figure(figsize=(10,5))\nplt.hist(x=data['Dt_Customer'],edgecolor='white',color='#26527D')","ad9c10b5":"print(\"The Dt_Customer is\\033[1m uniformly distributed\\033[0m and ranges between:\\033[1m\" ,data['Dt_Customer'].min(), \"-\" ,data['Dt_Customer'].max())","0ea55425":"color=['#26527D','#E84855','#F9DC5C','#3185FC','#61988E']\nplt.figure(figsize=(12,8))\nplots=sns.countplot(x='Education',data=data,palette=color)\nplt.ylabel('No of customers')\nplt.title('Education Level')\nplt.xlabel('')\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(),),\n                       (bar.get_x() + bar.get_width() \/ 2,\n                        bar.get_height()), ha='center', va='center',\n                       size=10, xytext=(0,8),\n                       textcoords='offset points')","103fba8d":"data['Marital_Status'].value_counts()","542de01c":"data.loc[(data['Marital_Status'] =='YOLO')|(data['Marital_Status'] =='Absurd')|(data['Marital_Status'] =='Alone'),'Marital_Status']='Single'","ba787d51":"color=['#26527D','#E84855','#F9DC5C','#3185FC','#61988E']\nplt.figure(figsize=(12,8))\nplots=sns.countplot(x='Marital_Status',data=data,palette=color)\nplt.ylabel('No of customers')\nplt.title('Marital Status')\nplt.xlabel('')\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(),),\n                       (bar.get_x() + bar.get_width() \/ 2,\n                        bar.get_height()), ha='center', va='center',\n                       size=10, xytext=(0,8),\n                       textcoords='offset points')","bdbf562f":"data['is_parent']= data['Kidhome']+ data['Teenhome'] !=0","bc41ae93":"fig , ax = plt.subplots()\nsizes = data['is_parent'].value_counts()\nlabels = 'True', 'False' \nax.pie(sizes,labels=labels,autopct='%1.1f%%',shadow=True, startangle=90,wedgeprops={'edgecolor':'black'},\n        colors=['#E84855','#F5F5F5'])\nax.axis('equal')\nax.set_title('Are they parents')","19423e54":"#Helper function\ndef transform(x):\n    if x == 'Together' or x=='Married':\n        return 'Relationship'\n    else:\n        return 'Alone'","380f1f0a":"data['status'] = data['Marital_Status'].apply(transform)","e16720eb":"fig , ax = plt.subplots()\nsizes = data['status'].value_counts()\nlabels = 'Relationship', 'Alone' \nax.pie(sizes,labels=labels,autopct='%1.1f%%',shadow=True, startangle=90,wedgeprops={'edgecolor':'black'},\n        colors=['#F9DC5C','#F5F5F5'])\nax.axis('equal')\nax.set_title('Are they living alone')","a69715d7":"plt.hist(x=data['Recency'],edgecolor='white',color='#26527D')\nplt.title('Distribution of their last visit')\nplt.xlabel('Last Visit (In days)')\nplt.ylabel('Frequency')","8cdecc46":"sns.boxplot(x='Income',data=data,color='#26527D')","dd79990d":"data.loc[data['Income']>600000,'Income']=np.nan","e0b95a5b":"data['Income'].fillna(np.round(data['Income'].mean()),inplace=True)","f2ae74bf":"sns.boxplot(x='Income',data=data,color='#26527D')","582342b8":"fig , ax = plt.subplots()\nsizes = data['Complain'].value_counts() \nlabels = 'No compain', 'Complain' \nax.pie(sizes,labels=labels,autopct='%1.1f%%',shadow=True, startangle=45,wedgeprops={'edgecolor':'black'},\n        colors=['#3185FC','#F5F5F5'])\nax.axis('equal')\nax.set_title('Complains raised by the customer')","74bb9fb3":"data['Total_Amt_Spent']= data[['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']].sum(axis=1)","5dcb474e":"data['Total_purchases']= data['NumDealsPurchases']+data['NumWebPurchases']+data['NumCatalogPurchases']+data['NumStorePurchases']","12f37a3d":"to_plot=['is_parent','status']\ncolor = [['#E84855','#3185FC'],['#F9DC5C','#61988E']]\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize = (10, 15))\naxes = axes.flatten()\nfor col, ax,co in zip(to_plot, axes,color):\n    ax = sns.scatterplot(data = data, x = 'Total_Amt_Spent', y = 'Income', ax = ax,hue=col,palette=co)\n    ax.set_title(f'Effect of {col} on Income and Expenditure', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.3)\nplt.show()","de234b0c":"to_plot=['is_parent','status']\ncolor = [['#E84855','#3185FC'],['#F9DC5C','#61988E']]\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize = (10, 15))\naxes = axes.flatten()\nfor col, ax,co in zip(to_plot, axes,color):\n    ax = sns.scatterplot(data = data, x = 'Total_purchases', y = 'Total_Amt_Spent', ax = ax,hue=col,palette=co)\n    ax.set_title(f'Effect of {col} on Toal Purchases and Expenditure', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.3)\nplt.show()","5aefc4eb":"color=['#26527D','#E84855','#F9DC5C','#3185FC','#61988E']\nto_plot=['Income','Total_Amt_Spent','Total_purchases']\nfig, axes = plt.subplots(nrows=3, ncols=1, figsize = (10, 15))\naxes = axes.flatten()\nfor col, ax in zip(to_plot, axes):\n    ax = sns.barplot(data = data, x = 'Education', y = col, ax = ax,palette=color)\n    ax.set_title(f'Mean of {col} based on Education Level', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.3)\nplt.show()","43d776bf":"to_plot = ['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize = (15, 15))\naxes = axes.flatten()\n\nfor col, ax in zip(to_plot, axes):\n    ax = sns.lineplot(data = data, x = 'Age', y = col, ax = ax,color='#26527D')\n    ax.set_title(f'mean of {col} by Age', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)\n    \nplt.show()","2a4f355e":"to_plot = ['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize = (15, 15))\naxes = axes.flatten()\n\nfor col, ax in zip(to_plot, axes):\n    ax = sns.lineplot(data = data, x = 'month', y = col, ax = ax,color='#26527D')\n    ax.set_title(f'mean of {col} by Month they joined', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)\n    \nplt.show()","565c2ab6":"data['accepted_offer']= data['AcceptedCmp1']+data['AcceptedCmp2']+data['AcceptedCmp3']+data['AcceptedCmp4']+data['AcceptedCmp5']+ data['Response']","33615c89":"color=['#26527D','#E84855','#F9DC5C','#3185FC','#61988E']\nplt.figure(figsize=(12,8))\nplots=sns.countplot(x='accepted_offer',data=data,palette=color)\nplt.ylabel('No of customers')\nplt.title('No of offers accepted')\nplt.xlabel('')\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(),),\n                       (bar.get_x() + bar.get_width() \/ 2,\n                        bar.get_height()), ha='center', va='center',\n                       size=10, xytext=(0,8),\n                       textcoords='offset points')","695bb216":"color=['#26527D','#E84855','#F9DC5C','#3185FC','#61988E']\nto_plot=['Income','Total_Amt_Spent','Total_purchases']\nfig, axes = plt.subplots(nrows=3, ncols=1, figsize = (10, 15))\naxes = axes.flatten()\nfor col, ax in zip(to_plot, axes):\n    ax = sns.barplot(data = data, x = 'accepted_offer', y = col, ax = ax,palette=color)\n    ax.set_title(f'Mean of {col} based on No of offers they accepted', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.3)\nplt.show()","8cbe95b1":"to_plot = ['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize = (18, 18))\naxes = axes.flatten()\n\nfor col, ax in zip(to_plot, axes):\n    ax = sns.lineplot(data = data, x = 'accepted_offer', y = col, ax = ax,color='#26527D')\n    ax.set_title(f'mean of {col} by No of offers accepted', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)  \nplt.show()","b52515fc":"to_plot = ['NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize = (15, 15))\naxes = axes.flatten()\n\nfor col, ax in zip(to_plot, axes):\n    ax = sns.lineplot(data = data, x = 'Age', y = col, ax = ax,color='#26527D')\n    ax.set_title(f'mean of {col} by Age', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)\n#axes[-1].axis('off')     \nplt.show()","cfe50d13":"to_plot = ['NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize = (15, 15))\naxes = axes.flatten()\n\nfor col, ax in zip(to_plot, axes):\n    ax = sns.lineplot(data = data, x = 'accepted_offer', y = col, ax = ax,color='#26527D')\n    ax.set_title(f'mean of {col} by no of offers acceoted', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)   \nplt.show()","a7e0fac6":"data_copy = data.drop(['Year_Birth','Dt_Customer','AcceptedCmp3','AcceptedCmp4','AcceptedCmp1','AcceptedCmp2','AcceptedCmp5','Response','Complain','MntWines', 'MntFruits',\n       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts','MntGoldProds','month','Marital_Status','status'],axis=1)","14a20cc4":"data_copy.head()","8adf2686":"from sklearn.preprocessing import LabelEncoder","0fb8e6ad":"le = LabelEncoder()","e0a401d1":"data_copy['Education']= le.fit_transform(data_copy['Education'])","1cda4f0f":"data_copy= pd.get_dummies(data_copy,drop_first=True)","240ed0b8":"from sklearn.preprocessing import MinMaxScaler\n\nmms = MinMaxScaler()\n\nfor col in data_copy.columns:\n    data_copy[col] = mms.fit_transform(data_copy[[col]]).squeeze()","8ed6443f":"from sklearn.decomposition import PCA\n\npca_list = list()\nfeature_weight_list = list()\n\n# Fit a range of PCA models\n\nfor n in range(1, 10):\n    \n    # Create and fit the model\n    PCAmod = PCA(n_components=n)\n    PCAmod.fit(data_copy)\n    \n    # Store the model and variance\n    pca_list.append(pd.Series({'n':n, 'model':PCAmod,\n                               'var': PCAmod.explained_variance_ratio_.sum()}))\n    \n    # Calculate and store feature importances\n    abs_feature_values = np.abs(PCAmod.components_).sum(axis=0)\n    feature_weight_list.append(pd.DataFrame({'n':n, \n                                             'features': data_copy.columns,\n                                             'values':abs_feature_values\/abs_feature_values.sum()}))\n    \npca_df = pd.concat(pca_list, axis=1).T.set_index('n')\npca_df","276829b9":"features_df = (pd.concat(feature_weight_list)\n               .pivot(index='n', columns='features', values='values'))\n\nfeatures_df","eb9eaa7a":"sns.set_context('talk')\nax = pca_df['var'].plot(kind='bar',color='#26527D')\n\nax.set(xlabel='Number of dimensions',\n       ylabel='Percent explained variance',\n       title='Explained Variance vs Dimensions');","553ceb7e":"pca = PCA(n_components = 5, random_state = 42)\n\npca.fit(data_copy)\ndata_pca = pd.DataFrame(pca.transform(data_copy), \n                        columns = ([\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"]))\n\ndata_pca.describe().T","1285e9a8":"from sklearn.cluster import KMeans","880a6b1d":"km = KMeans()","fe6cf08b":"inertia =[]\nfor n in range(1,15):\n    km = KMeans(n_clusters=n)\n    km.fit(data_pca)\n    inertia.append(km.inertia_)","cbd5916e":"plt.plot(range(1,15),inertia,color='#26527D')","586206ac":"from sklearn.metrics import silhouette_score","3001e120":"def visualize_silhouette_layer(data):\n    clusters_range = range(2,10)\n    results = []\n\n    for i in clusters_range:\n        km = KMeans(n_clusters=i, random_state=42)\n        cluster_labels = km.fit_predict(data)\n        silhouette_avg = silhouette_score(data, cluster_labels)\n        results.append([i, silhouette_avg])\n\n    result = pd.DataFrame(results, columns=[\"n_clusters\", \"silhouette_score\"])\n    pivot_km = pd.pivot_table(result, index=\"n_clusters\", values=\"silhouette_score\")\n\n    plt.figure()\n    sns.heatmap(pivot_km, annot=True, linewidths=1, fmt='.3f', cmap='RdYlGn')\n    plt.tight_layout()\n    plt.show()","24c5dfef":"visualize_silhouette_layer(data_pca)","da0fb122":"km= KMeans(n_clusters=3,random_state=42)","426ebb23":"km.fit(data_pca)","39ea4b2b":"data['clusters']=km.labels_","c68d7b5a":"data.head()","92568802":"cluster_color=['#292E1E','#7F0799','#037773'] #the color palette we are going to use","a83fde79":"sns.countplot(data=data,x='clusters',palette=cluster_color)","1988ad27":"to_plot = ['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize = (15, 15))\naxes = axes.flatten()\n\nfor col, ax in zip(to_plot, axes):\n    ax = sns.barplot(data = data, x = 'clusters', y = col, ax = ax,palette=cluster_color)\n    ax.set_title(f'mean of {col} by Age', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)\n    \nplt.show()","d40f83cc":"to_plot = ['NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize = (15, 15))\naxes = axes.flatten()\n\nfor col, ax in zip(to_plot, axes):\n    ax = sns.barplot(data = data, x = 'clusters', y = col, ax = ax,palette=cluster_color)\n    ax.set_title(f'mean of {col} by Age', fontsize = 15)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)\n    \nplt.show()","2d848fd6":"plt.figure(figsize=(10,8))\nsns.scatterplot(x='Total_Amt_Spent',y=data.index,data=data,hue='clusters',palette=cluster_color)\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5),frameon=False)\nplt.ylabel('Frequency')\nplt.title(\"Clustering on Total Expenditure\")","4736eef9":"plt.figure(figsize=(10,8))\nsns.scatterplot(x='Income',y=data.index,data=data,hue='clusters',palette=cluster_color)\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5),frameon=False)\nplt.ylabel('Frequency')\nplt.title(\"Clustering on Income\")","8786e9d9":"plt.figure(figsize=(10,8))\nsns.scatterplot(x='Total_purchases',y=data.index,data=data,hue='clusters',palette=cluster_color)\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5),frameon=False)\nplt.ylabel('Frequency')\nplt.title(\"Clustering on Total Purchases\")","86cc2972":"plt.figure(figsize=(8,8))\nsns.displot(data=data,x='Age',hue='clusters',kind='kde',palette=cluster_color)\nplt.title(\"Clustering based on Age\")","3dc35486":"sns.barplot(data=data,x='clusters',y='accepted_offer',palette=cluster_color)","24a0c562":"plt.figure(figsize=(10,8))\nsns.countplot(data=data,x='Education',hue='clusters',palette=cluster_color)\nplt.legend(bbox_to_anchor=(1.01, 1),frameon=False)\nplt.title(\"Clustering based on Education\")","1339ab05":"labels=[]\nimport matplotlib.patches as mpatches\nfig , ax = plt.subplots()\nsizes = data['clusters'].value_counts() \nfor i in data['clusters'].value_counts().index:\n    labels.append(\"Cluster \"+ str(i))\nax.pie(sizes,labels=labels,autopct='%1.1f%%',shadow=True, startangle=90,wedgeprops={'edgecolor':'white'},\n        colors=['#7F0799','#7F0799','#037773'])\nax.axis('equal')\nax.set_title('Clustering of Parents')\nred_patch = mpatches.Patch(color='#7F0799', label='Are Parents')\nwhite_patch = mpatches.Patch(color='#037773', label='Not Parents')\nax.legend(bbox_to_anchor=(1, 1),labels=['Parent','Not Parent'],handles=[red_patch,white_patch],frameon=False)","f2af758a":"__Determining optimal value of n_clusters using elbow method and Silhouette method__","7ce933a8":"# Customer Profiling","36681cf7":"Next step is to reduce the dimensionality using PCA but before that we can drop some more columns that do not provide insights such as:\n- __Year_Birth__ : We will use Age instead\n- __Dt_Customer and month__ : We will use year only to track when the customer joined\n- __Complain__ : Less than 1% only filed complian and hence not useful for clustering\n- __Marital Status and status__ : As observed earlier marital status has no effect on Income,Expenditure,Purchases etc and will only add noise to the clustering\n- __AcceptedCmp3','AcceptedCmp4','AcceptedCmp1','AcceptedCmp2','AcceptedCmp5','Response'__ : All info is in accepted_offer column.\n- __'MntWines', 'MntFruits','MntMeatProducts', 'MntFishProducts', 'MntSweetProducts','MntGoldProds'__: All info is in Total_Amt_Spent column","88bfa76a":"The Income column contains some missing values which we will resolve later.\\\nThere are no duplicates in the data","e5965cb2":"#### Now let's analyze the affect of education level on various factors","f8699939":"- We can try some other clustering algorithms and compare the results \n- We can also Group Education further to create better cluster \n- Income column has a higher skew and some transformations can lead to better steps \n- Perhaphs more information can be derived from Dt_Customer column.\\\n\nThank you! for reading and I believe there are tons of more insights we can find using the above data and I encourage you to do so.","b8429517":"## How to target each audience to increase revenue","d3067314":"Looks like our customers are __divided evely between graduates and post graduates__ with a very small proportion having only basic education","1a1e5bd3":"Now we will create some more features namely :\n- __Total_Amt_Spent__ : Total amount spent by the customer \n- __Total_purchases__ : Total purchases done by the customer in last 2 years.","058f6c9c":"__Now let's look at Amount spent on Individual products__","254b310b":"# Next Steps?","0d742dbd":"# Conclusion","db1650bf":"We can see that majority of our customers are in a Relationship","2bc72c0d":"The data is taken from \"https:\/\/www.kaggle.com\/imakash3011\/customer-personality-analysis\"\n\nThe dataset for this project is provided by __Dr. Omar Romero-Hernandez__.\n\n## Content\n\n### Attributes\n\n#### People\n\n- __ID__: Customer's unique identifier\n- __Year_Birth__: Customer's birth year\n- __Education__: Customer's education level\n- __Marital_Status__: Customer's marital status\n- __Income__: Customer's yearly household income\n- __Kidhome__: Number of children in customer's household\n- __Teenhome__: Number of teenagers in customer's household\n- __Dt_Customer__: Date of customer's enrollment with the company\n- __Recency__: Number of days since customer's last purchase\n- __Complain__: 1 if the customer complained in the last 2 years, 0 otherwise\n  \n#### Products\n\n- __MntWines__: Amount spent on wine in last 2 years\n- __MntFruits__: Amount spent on fruits in last 2 years\n- __MntMeatProducts__: Amount spent on meat in last 2 years\n- __MntFishProducts__: Amount spent on fish in last 2 years\n- __MntSweetProducts__: Amount spent on sweets in last 2 years\n- __MntGoldProds__: Amount spent on gold in last 2 years\n\n#### Promotion\n\n- __NumDealsPurchases__: Number of purchases made with a discount\n- __AcceptedCmp1__: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n- __AcceptedCmp2__: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n- __AcceptedCmp3__: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n- __AcceptedCmp4__: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n- __AcceptedCmp5__: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n- __Response__: 1 if customer accepted the offer in the last campaign, 0 otherwise\n\n#### Place\n\n- __NumWebPurchases__: Number of purchases made through the company\u2019s website\n- __NumCatalogPurchases__: Number of purchases made using a catalogue\n- __NumStorePurchases__: Number of purchases made directly in stores\n- __NumWebVisitsMonth__: Number of visits to company\u2019s website in the last month","ac72251c":"# Objectives","a1950119":"__Distribution of their last visit to the store in evenly distributed__","5e2b7d43":"- We can also see the purchases made and specific items bought by the three segments for better targeting.\n- Lets focus on cluster 1 and 0 as 2 does not bring much revenue , although since they are majority they are not to be left out\n- __Cluster 0__ seems to making more deal and web purchases than others and hence __lucrative offers on websites__ can be a good method to attract them .There are of interest are mostly gold and wine\n- __Cluster 1__ seems to puchasing a lot more from the catalog and stores and they have brought revenue in all the items and hence __more divesity in the catalog__ can attract more customers like them \n- For __cluster 2__ although they have made less purchases , they also seems to be __influenced by the deals__ and hence they can be used to lure them out to make more purchases.","f119fa65":"## To perform customer segmentation\n\nWe take the following steps\n\n- Clean our data and perform the __EDA__\n- __Feature engineering__\n- __PCA__ to reduce the dimensionality\n- __KMeans__ to cluster our data\n- __Customer Profiling__ based on the clusters","f91b441f":"From above graphs we can interpret the following:\n- __Younger generation usually purchases on deals and in store__\n- __Older people generally buy using catalogs__","fe409614":"The age looks normally distributed  ","1dcfbfa2":"# Loading Data","bf39e45c":"From above plots we note the following:\n- __Wine is generally bought by older people__\n- __Meat and Fish is mostly purchased by either younger poeple with age between 25-30 or by older people__\n- __Gold is mostly bought by younger people__\n- __Those who joined in Winters have bought more wine__ (Winters + old people is ideal target for selling wine)\n- __Those who joined during new year month have bought more fruits__\n- __Gold purchase usually peaks around Aug-Sep__","0b188894":"We note that their are 7 entries which don't make any sense (Alone,YOLO,Absurd).\\\nI map them into \"Single\" category although they could just be dropped or labelled as NaN.","8a0dd871":"We can see that proportion of people who filed a complain is even __less than 1%__. Hence this columns will also not provide any insights and we will drop it later","e8549e50":"# Kmeans","4f591f99":"We create one last features.\\\n__accepted_offer__ : Total no of offers accepted by the customer","31b73e68":"The __Dt_Customer__ is interpreted as object , hence we __convert it into datetime__ to draw any meaningful insights.\\\nWe also create two new columns months and year derived from the newly converted datetime to add more information","6e6160ca":"*Important Note:* \n\nThe columns __Z_CostContact and Z_Revenue__ have same value for each row of our dataset and therefore do not provide any information.\\\nWe __drop these along with the ID column__","20934da6":"We observe that their are three outliers ,with birth year<=1900 , we replace them with mean values of our age for better clustering.","ca8315ee":"We can see one clear outlier , we convert it into Nan and impute it with other missing values with the mean value","d226bee9":"# Dataset Description","30ec1fa9":"#### Now let's analyze Income, Expenditure and Purchases based on features we created earlier","2d72b36e":"We can see that majority of our customers are parents ","8907c757":"## Key Findings","2d2fad28":"Instead of using Birth Year we can derive the age from it and use it in our analysis.","e5cde314":"# EDA + Feature Engineering","19655368":"We need to scale our data before PCA decompostion","fe5f1447":"As a rule of thumb we generally takes n value with the second best silhouette score \nTherefore we choose 3 , which also aligns with the value obtained from elbow plot","e3787d01":"Now we encode the Education column and is_parent column","86344159":"Majority of customers have not accepted any offers","b884a1af":"# PCA","ca737179":"- We can see that the algorithm has done a god job on clustering the data and we can see three clear distinct clusters\n- First we have __Cluster 1 (The rich)__ representing the non parents , their age is normally distributed and they have high income and Expenditure and they are the ones that accept majority offers \n- Next we have the parents group which are futher divided into two clusters:\n- __Cluster 2 (The poor)__ , which is what majority of data is grouped into consist of those with lower income, expenditure and purchases, they have rarely accepted any offers and their age is normally distributed with mean around 45 \n- __Cluster 0 (the middle class customer segment of our data)__ are the people that lies somewhere between Cluster 2 and Cluster 1 ","e5df5a69":"At no of dimensions= 5 explains about 79% of the data and can be chosen as an optimal value","01cadc1c":"From the above Graphs we observe the following:\n- There is positive correlation between Income and Total Amount Spent and __people with higher income tends to spend more__.\n- Customers __who are not parents generally have higher income and have spent more money__.\n- Their __iving status seems to have no relation with their income or expenditure__\n- There is __positive correlation between Purchases and Amount Spent__\n- Again those who are __not parents have made more purchases__ \n- __Living status has no relation with Total Purchases as well__","394fed2d":"Now let's analyze the Income column.\\\nNote: It contains some missing values","02faa5ae":"We can see a normal distribution of income with a little skew due to few high values.\\\nWe leave them as they are so to ensure that their is some diversity and keeping in mind that their can often be some irregularities in real life scenerio as well","5b0e70fc":"We observe the following:\n- Customers with only Basic Education have the lowest income and contribute the lowest to the purchases.\n- Customers with Post Graduations  tend to have higher income expenses than those with Graduation","ade1bf4d":"We can now create some new features based on the data we have before futher analysis\n- __Are they Parents__ or Not based on No of childrens they have \n- __Are they in a relationship__ or not based on the Marital Status"}}