{"cell_type":{"ef2940b1":"code","1e5bea8b":"code","87b50627":"code","fae3b9ff":"code","262f4a4c":"code","bdf07517":"code","86bdf202":"code","94798bf1":"code","56f4fc01":"code","c0365af7":"code","0bdb8028":"code","a7613205":"code","c9d0482f":"code","672c2a2b":"code","b20e6198":"code","22971aeb":"code","e6a6cfd4":"markdown","82c4e412":"markdown","71a19b10":"markdown","7363d259":"markdown","c008880b":"markdown","87e8b24b":"markdown","1918516a":"markdown","5c523500":"markdown","16ec36f7":"markdown","933c085e":"markdown","4ca788ba":"markdown","bb186e49":"markdown","eea6b09d":"markdown","65677d85":"markdown"},"source":{"ef2940b1":"from pathlib import Path\nimport pandas as pd\nimport re\nfrom glob import glob\nfrom tqdm.notebook import tqdm","1e5bea8b":"Path.cwd()","87b50627":"chip_dataset_dir = Path('..\/input\/spacenet-7-change-detection-chips-and-masks\/chip_dataset\/change_detection')\noutput_csv_dir = Path('.\/output_csvs')\noutput_csv_dir.mkdir(parents=True, exist_ok=True)","fae3b9ff":"[path for path in Path.cwd().iterdir()]","262f4a4c":"def extract_list_of_mask_paths(directory):\n    paths = Path.glob(directory,pattern = '**\/masks\/**\/*.*')\n    path_list = []\n    # the total var below is input to tqdm's progress bar, the number was \n    # obtained in a previous run, and tells tqdm the total number of iterations\n    # or in this specific case the total number of files we have\n    for path in tqdm(paths,total=3211520):\n        path_list.append(path)\n    return path_list","bdf07517":"def extract_metadata_from_string(string):\n    # extracted groups\n    # (fname) (year1_month_1_year2_month_2) (year_1) (month_1) (year_2) (month_2) (x) (y) (im_name) (blank??)\n    pattern = r'\/(global\\w+_((\\d+)_(\\d+)_(\\d+)_(\\d+))_chip_x(\\d+)_y(\\d+)_(.+_13))_?(blank)?\\.tif'   \n    match = re.findall(pattern=pattern,string=string)\n    return match[0]","86bdf202":"string = 'processed_data\/chip_dataset\/change_detection\/L15-0331E-1257N_1327_3160_13\/chips\/2018_9_2019_11\/global_monthly_2018_9_2019_11_chip_x832_y128_L15-0331E-1257N_1327_3160_13_blank.tif'","94798bf1":"extract_metadata_from_string(string)","56f4fc01":"def extract_metadata_from_list_of_mask_paths(data_dir):\n    d_keys = ['chip_path','mask_path','target','fname','im_dates','year1','month1','year2','month2','x','y','im_name','is_blank']\n    # initialize dictionary\n    d = {key:[] for key in d_keys}\n    \n    print('extracting mask paths ...')\n    \n    list_of_mask_paths = extract_list_of_mask_paths(data_dir)\n    \n    print('extracting metadata from paths ...')\n    \n    for i,mpath in enumerate(tqdm(list_of_mask_paths)):\n        metadata = extract_metadata_from_string(str(mpath))\n        # store metadata in dict\n        for j,data in enumerate(metadata):\n            # j + 3 in order to skip the three entries of the dict\n            d[d_keys[j+3]].append(data)\n        \n        # the path below will be reused in constructing the other paths below\n        p = f\"{d['im_dates'][i]}\/{d['fname'][i]}\"\n        \n        # reconstruct the path to the chip and the corresponding mask\n        d['chip_path'].append(f\"{d['im_name'][i]}\/chips\/{p}.tif\")\n        if d['is_blank'][i] == 'blank':\n            d['mask_path'].append(f\"{d['im_name'][i]}\/masks\/{p}_{d['is_blank'][i]}.tif\")\n            # update the target column with 0 indicating a blank chip\n            d['target'].append(0)\n        else:\n            d['mask_path'].append(f\"{d['im_name'][i]}\/masks\/{p}.tif\")\n            # update the target column with 1 indicating change in chip\n            d['target'].append(1)\n    return d","c0365af7":"metadata_dict = extract_metadata_from_list_of_mask_paths(chip_dataset_dir)","0bdb8028":"metadata_dict['chip_path'][0:5]","a7613205":"metadata_dict['mask_path'][0:5]","c9d0482f":"df = pd.DataFrame.from_dict(metadata_dict)","672c2a2b":"df.head()","b20e6198":"df[df['target']==1].head()","22971aeb":"df.to_csv(output_csv_dir\/'chip_csv_file.csv',index=False)","e6a6cfd4":"Perfect! Now finally we convert our dictionary to a dataframe so that we can export it as a csv to use later on in the [notebook for creating our model](https:\/\/www.kaggle.com\/amerii\/spacenet-7-change-detection-pytorch-starter).","82c4e412":"## Saving and Exporting our Data\nLet's convert our dictionary into a pandas dataframe","71a19b10":"Let's make sure that our function is working correctly by trying to extract the metadata from the path below","7363d259":"# Import Dependencies","c008880b":"Now that we have a function that returns all the list of paths, we need a function that will extract the metadata from each of the given paths. We achieve that using the function below.","87e8b24b":"Let's take a peak at our dataframe.","1918516a":"Let's double check that our output directory has been created","5c523500":"## Manage and Create Directories","16ec36f7":"Let's make sure that it's extracting the target column correctly.","933c085e":"Finally we export our data as a csv to use in [our other notebooks](https:\/\/www.kaggle.com\/amerii\/spacenet-7-change-detection-chips-and-masks\/notebooks).","4ca788ba":"Finally we need a function that loops through all of our paths and returns a dictionary of our metadata, so that we can later convert them into our dataframes. The function below combines the previous 2 functions and achieves that. ","bb186e49":"## Creating Data Extraction Functions","eea6b09d":"Let's check that our paths are in the correct format.","65677d85":"The function below gets all the paths to all the files in a given directory, and returns them as a list. \n\n***Note***: *We will only retrieve the paths of our masks from the dataset, because the masks contain all the necessary metadata that we need to reconstruct the metadata of the chips as well.*"}}