{"cell_type":{"877d00c9":"code","a9e8fd33":"code","1b82ecf0":"code","018e28b9":"code","dda3d86d":"code","3a9a682f":"code","b38b3d92":"code","08fd8c5e":"code","1e892394":"code","9d6e392a":"code","b152c689":"code","d17991d9":"code","5fe94e1c":"code","c1fa81ee":"code","e09a257f":"code","8aebc95c":"markdown","ceed3fc0":"markdown","8b9b9255":"markdown","ee84bd55":"markdown"},"source":{"877d00c9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Keras\nfrom keras.layers import Input, Dense, LSTM\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping\n\n# Date parser for pandas\ndef date_parser(t):\n    return pd.to_datetime(t, format=\"%d\/%m\/%Y\")\n\n# Data as pd.DataFrame\nraw_data = pd.read_csv(\"..\/input\/vix-index\/VIX (1).txt\", \n                 decimal=\",\", \n                 delimiter=\"\\t\", \n                 header=None, \n                 names=['t', 'xt'],\n                 parse_dates=['t'], \n                 date_parser=date_parser)","a9e8fd33":"# Plot serie\nplt.figure(figsize=(15, 3))\nplt.plot(raw_data.t, raw_data.xt); \nplt.title(\"VIX\")\nplt.show()","1b82ecf0":"# Index with time \nraw_data.index = raw_data.t\n\nraw_data.head()","018e28b9":"# Train\/Test split date in 2012-01-06\nt_split = \"2012-01-06\"\n\n# Training\/test data\nx_train = raw_data['xt'][:t_split] \nx_test = raw_data['xt'][t_split:]\n\n# Serie parameters\nx_mean = np.mean(x_train)\nx_std = np.std(x_train)\n\n# Normalize\nx_train = (x_train - x_mean)\/x_std\nx_test = (x_test - x_mean)\/x_std","dda3d86d":"# Plot train\/test series\n#Train in blue and Test in red\nplt.figure(figsize=(15, 3))\nplt.plot(x_train, color='blue'); \nplt.plot(x_test, color='red'); \nplt.title(\"VIX (blue train data, red test data)\")\nplt.show()","3a9a682f":"# Lenght of each observation sequence\nseq_len = 32\n\n# return a sequence list of size seq_len by slidding windows the xt series \ndef sliding_window(xt, seq_len):\n  sx = []\n  for i in range(len(xt)-seq_len+1):\n    sx.append(xt[i:i+seq_len])\n  return sx\n\n# Train\/Test sequences. Got list of arrays.\nsx_train = sliding_window(x_train.tolist(), seq_len + 1)\nsx_test = sliding_window(x_test.tolist(), seq_len + 1)\n\n# Cast to array. Got (None, sequence_length)\nsx_train = np.array(sx_train)\nsx_test = np.array(sx_test)\n\nsx_train.shape","b38b3d92":"# Labels\nsy_train = sx_train[:,-1]\nsx_train = sx_train[:,:-1]\n\n# Labels\nsy_test = sx_test[:,-1]\nsx_test = sx_test[:,:-1]","08fd8c5e":"input_model = Input(shape=(seq_len, 1)) # Model. Expected (None, seq_len, 1)\nlstm_out = LSTM(units=4)(input_model) # Lstm output. Got (None, 4)\ny_pred = Dense(units=1, activation=None)(lstm_out) # Model prediction. [None,4] x [4,1] = [None, 1]\nkeras_model = Model(inputs=input_model, outputs=y_pred) # Keras model\nkeras_model.compile(loss='mse', optimizer=Adam(lr=0.1)) # Model \nkeras_model.summary() # Model summary\n","1e892394":"# Callbacks\ncallback_early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=12)","9d6e392a":"# Fit\nlogs = keras_model.fit(x=sx_train, y=sy_train, validation_split=0.5, epochs=50, callbacks=[callback_early_stopping], batch_size=1024)","b152c689":"# Plot train\/test series\nplt.figure(figsize=(15, 3))\nplt.plot(logs.history['loss'], color='blue'); \nplt.plot(logs.history['val_loss'], color='red'); \nplt.title(\"Loss\")\nplt.show()","d17991d9":"# Predict. Got (None, 1)\npredictions = keras_model.predict(sx_test)\n\n# Squeeze to have (None, )\npredictions = predictions.squeeze()\n\n# Truth\/Pred in original scale\ny_true = sy_test*x_std + x_mean\ny_pred = predictions*x_std + x_mean\n\n# Plot truth\/predictions in original scale\nplt.figure(figsize=(15, 3))\nplt.plot(y_true, color='blue'); \nplt.plot(y_pred, color='red'); \nplt.plot(y_true-y_pred, color='gray')\nplt.hlines(y=0, xmin=0,xmax=400, color='black')\nplt.title(\"Predictions (red) and truth (blue)\")\nplt.show()","5fe94e1c":"# Mean absolute error in original scale\nnp.abs(y_true-y_pred).mean().round(2)\n\n# Difference between t+1 and t\ntrue_diff = y_true[:-1] - y_true[1:]\npred_diff = y_pred[:-1] - y_pred[1:]\n\n# Plot truth\/predicted differences\nplt.figure(figsize=(15, 3))\nplt.plot(true_diff, color='blue'); \nplt.plot(pred_diff, color='red'); \nplt.hlines(y=0, xmin=0,xmax=400, color='black')\nplt.title(\"Predictions (red) and truth (blue)\")\nplt.show()","c1fa81ee":"# Multiplied differences\ntimes_diff = true_diff * pred_diff\n\n# Plot \nplt.figure(figsize=(15, 3))\nplt.plot(times_diff, color='blue'); \nplt.hlines(y=0, xmin=0,xmax=400, color='black')\nplt.title(\"Predictions (red) and truth (blue)\")\nplt.show()","e09a257f":"# Plot \nplt.figure(figsize=(15, 3))\nplt.plot(times_diff.cumsum(), color='blue'); \nplt.hlines(y=0, xmin=0,xmax=400, color='black')\nplt.title(\"Cumulative sum of multiplied difference. Got {}.\".format(times_diff.sum().round()))\nplt.show()","8aebc95c":"<h3> <b> Sequence generation <\/b>","ceed3fc0":"<h3> <b> Model <\/b> ","8b9b9255":"<h5> <b> TRAIN TEST split and preprocessing <\/b>","ee84bd55":"<h5> By <b>Vada ZAMBLE<\/b> | vadazamble@yahoo.fr\n\n<h4> The objective is to anticpate the value of the index VIX from one week to the next according his price history.\n    \n<h4>  Data : Vix index price from 1995 to 2020\n"}}