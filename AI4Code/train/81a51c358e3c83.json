{"cell_type":{"8a352cc0":"code","450076d8":"code","4f118b5f":"code","1d174fd2":"code","f15e85a4":"code","61d45481":"code","2b91b920":"code","49e0265a":"code","41e53207":"code","0f53cbff":"code","e63214b4":"markdown","242a874b":"markdown","b444ea37":"markdown","24baebef":"markdown","5b5c172d":"markdown"},"source":{"8a352cc0":"import requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms as pth_transforms\nimport numpy as np\nfrom PIL import Image","450076d8":"patch_size = 8\n#model = torch.hub.load('facebookresearch\/dino:main', 'dino_deits8')\nmodel = torch.hub.load('facebookresearch\/dino:main', 'dino_vits16')","4f118b5f":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ndevice","1d174fd2":"for p in model.parameters():\n        p.requires_grad = False\n        \nmodel.eval()\nmodel.to(device)","f15e85a4":"img_npy = Image.open('..\/input\/dinodataset\/Dinodataset\/Train\/BigC\/3d8372246e_81080_tyraraulmartin (1).jpg')\nimg_npy = img_npy.convert('RGB')","61d45481":"plt.imshow(img_npy)\nprint(type(img_npy))","2b91b920":"transform = pth_transforms.Compose([\n    pth_transforms.ToTensor(),\n    pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\nimg = transform(img_npy)\n\n# make the image divisible by the patch size\nw, h = img.shape[1] - img.shape[1] % patch_size, img.shape[2] - img.shape[2] % patch_size\nimg = img[:, :w, :h].unsqueeze(0)\n\nw_featmap = img.shape[-2] \/\/ patch_size\nh_featmap = img.shape[-1] \/\/ patch_size\n\n#attentions = model.forward_selfattention(img.to(device))\nattentions = model.get_last_selfattention(img)   #img.cuda()\n\nprint(type(img))\nprint(img.shape)","49e0265a":"nh = attentions.shape[1] # number of head\n\n# we keep only the output patch attention\nattentions = attentions[0, :, 0, 1:].reshape(nh, -1)\n\n# we keep only a certain percentage of the mass\nval, idx = torch.sort(attentions)\nval \/= torch.sum(val, dim=1, keepdim=True)\ncumval = torch.cumsum(val, dim=1)","41e53207":"threshold = 0.6 # We visualize masks obtained by thresholding the self-attention maps to keep xx% of the mass.\nth_attn = cumval > (1 - threshold)\nidx2 = torch.argsort(idx)\nfor head in range(nh):\n    th_attn[head] = th_attn[head][idx2[head]]\n    \nth_attn = th_attn.reshape(nh, w_featmap\/\/2, h_featmap\/\/2).float()\n\n# interpolate\nth_attn = nn.functional.interpolate(th_attn.unsqueeze(0), scale_factor=patch_size, mode=\"nearest\")[0].cpu().numpy()\n\nattentions = attentions.reshape(nh, w_featmap\/\/2, h_featmap\/\/2)\nattentions = nn.functional.interpolate(attentions.unsqueeze(0), scale_factor=patch_size, mode=\"nearest\")[0].cpu().numpy()\nattentions_mean = np.mean(attentions, axis=0)","0f53cbff":"plt.figure(figsize=(6,6), dpi=200)\nplt.subplot(3,3,1)\nplt.title(\"Input\")\nplt.imshow(img_npy)\nplt.axis(\"off\")\n# visualize self-attention of each head\n\nfor i in range(6):\n    plt.subplot(3,3,i+4)\n    plt.title(\"Head \"+str(i+1))\n    plt.imshow(attentions[i])\n    plt.axis(\"off\")\n\nplt.subplot(3,3,2)\nplt.title(\"Head Mean\")\nplt.imshow(attentions_mean)\nplt.axis(\"off\")\nplt.tight_layout()","e63214b4":"## Input Image","242a874b":"## Visualize Self-attention","b444ea37":"## Get attention map","24baebef":"#### This notebook referred to the following Colab notebook.\nhttps:\/\/colab.research.google.com\/github\/oumpy\/hp_management\/blob\/master\/content\/articles\/2021sy\/blog\/attach\/dino\/dino_visualize_attention.ipynb\n\n# What is DINO?\n#### PAPER: \"Emerging Properties in Self-Supervised Vision Transformers\", released in 2021\nhttps:\/\/arxiv.org\/pdf\/2104.14294.pdf<br\/>\n- Self-supervised ViT features contain explicit information about the semantic segmentation of an image\n- These features are also excellent k-NN classifiers\n\n#### GitHub: Self-Supervised Vision Transformers with DINO\nhttps:\/\/github.com\/facebookresearch\/dino\n\n#### YouTube: DINO: Emerging Properties in Self-Supervised Vision Transformers (Facebook AI Research Explained)\nhttps:\/\/www.youtube.com\/watch?v=h3ij3F3cPIk<br\/>","5b5c172d":"# Visualize Self-Attention by Self-Supervised Vision Transformers, DINO"}}