{"cell_type":{"e9ed8bdd":"code","11d09f0d":"code","7bea51f3":"code","fe5d6d9a":"code","04dda5b1":"code","05e35b06":"code","61f57270":"code","80284813":"code","f686ea0f":"code","05d13376":"code","ecff6f2e":"code","86528438":"code","7094968f":"code","ee429ea1":"code","7c7bcc1a":"code","daaa91c2":"code","4540aa1e":"code","31379e08":"code","04a1d4ab":"code","2809a2d9":"code","809c5d3e":"code","a067703f":"code","cd17430e":"code","45c75492":"code","15ac8ade":"code","7baf671a":"code","7938f00f":"code","e7f738f3":"code","1c077d8b":"code","f50a68d2":"code","d15e903c":"code","51abd1e7":"code","e80fa154":"code","d929ad91":"code","6dfe896d":"code","d2286dfa":"code","0b952a2d":"code","e1289d03":"code","7aeb847e":"code","9c2303c0":"code","5078fb0e":"code","0d33c96c":"code","bbbe3026":"code","51a77167":"code","19b4bde4":"code","7fccd276":"code","ad9c8157":"code","15cfdd26":"code","c6c66532":"markdown","ecd6630c":"markdown","d466fc5f":"markdown","63a13570":"markdown","0d41eb4f":"markdown","afb21e44":"markdown","d1fc365e":"markdown","61037b6b":"markdown","eec7f78d":"markdown","d80b7065":"markdown","dbdf853c":"markdown","bafc2155":"markdown","ea3f72d6":"markdown","8bca50ca":"markdown"},"source":{"e9ed8bdd":"!pip install currencyconverter","11d09f0d":"# Import some libraries\n\nimport numpy as np\nimport pandas as pd\npd.options.mode.chained_assignment = None\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='whitegrid')\nfrom currency_converter import CurrencyConverter\nimport datetime\nfrom wordcloud import WordCloud, STOPWORDS \nimport textwrap\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer \nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer","7bea51f3":"# Load data from a CSV file into pandas DataFrame\n\ndata_imdb_movies = pd.read_csv('..\/input\/imdb-extensive-dataset\/IMDb movies.csv')\ndata_imdb_names = pd.read_csv('..\/input\/imdb-extensive-dataset\/IMDb names.csv')\ndata_imdb_title_principals = pd.read_csv('..\/input\/imdb-extensive-dataset\/IMDb title_principals.csv')","fe5d6d9a":"imdb_movies = data_imdb_movies.copy()\nimdb_movies.head()","04dda5b1":"imdb_names = data_imdb_names.copy()\nimdb_names.head()","05e35b06":"imdb_title_principals = data_imdb_title_principals.copy()\nimdb_title_principals.head()","61f57270":"# Informations on each data\n\nprint(imdb_movies.info())\nprint('\\n')\nprint(imdb_names.info())\nprint('\\n')\nprint(imdb_title_principals.info())","80284813":"# Merge name to title principals\nimdb_title_principals = pd.merge(imdb_title_principals, imdb_names[['imdb_name_id', 'name']], \n                                 left_on = ['imdb_name_id'], right_on = ['imdb_name_id']) \n# Ordering columns\nimdb_title_principals = imdb_title_principals[['imdb_title_id', 'ordering', 'imdb_name_id', 'name', 'category', 'job', 'characters']]\nimdb_title_principals.head()","f686ea0f":"# Create new column \"cinematographer\" into imdb_movies data\ncinematographer_name = imdb_title_principals[imdb_title_principals['category']=='cinematographer'].reset_index()\ncinematographer_name.rename(columns={'name' : 'cinematographer'}, inplace = True)\nimdb_movies = pd.merge(imdb_movies, cinematographer_name[['imdb_title_id', 'cinematographer']],\n                       left_on = 'imdb_title_id', right_on = 'imdb_title_id', how = 'left')\n\n# Group\/join cinematographer names with same imdb_title_id to avoid duplicated data (from merging imdb_movies and cinematographer_name)\nduplicated_data = imdb_movies[imdb_movies['imdb_title_id'].duplicated(keep = False)]\nmultiple_names_cinematographer = duplicated_data.groupby('imdb_title_id')['cinematographer'].apply(', '.join).reset_index()\nduplicated_data.drop(['cinematographer'], axis = 1, inplace = True)\nduplicated_data.drop_duplicates(subset=['imdb_title_id'], inplace = True)\ndata_multiple_names = pd.merge(duplicated_data, multiple_names_cinematographer[['imdb_title_id', 'cinematographer']], \n                               left_on = 'imdb_title_id', right_on = 'imdb_title_id')\ndata_multiple_names[['imdb_title_id', 'cinematographer']].head()","05d13376":"# Drop and replace duplicate data (because names of cinematographer) with data which have multiple names of cinematographer\nimdb_movies.drop_duplicates(subset=['imdb_title_id'], keep = False, inplace = True)\nimdb_movies = pd.concat((imdb_movies, data_multiple_names), sort = False).sort_values('imdb_title_id')\n\n# Reorder column cinematographer\ncols = imdb_movies.columns.tolist()\ncols = cols[0:13] + cols[-1:] + cols [13:-1]\nimdb_movies = imdb_movies[cols]\nimdb_movies.head()","ecff6f2e":"# Filtering data (only USA or Hollywood Movies)\nimdb_movies['country'].fillna('', inplace = True)\nimdb_movies = imdb_movies[imdb_movies['country'].str.contains('USA')]","86528438":"# Create budget_currency column and formatting budget column into numeric values for converting to usd\nimdb_movies['budget_currency'] = imdb_movies['budget'].str.split(' ', expand = True)[0]\nimdb_movies['budget_currency'] = imdb_movies['budget_currency'].str.replace('$', 'USD')\nimdb_movies['budget'] = imdb_movies['budget'].str.split(' ', expand = True)[1]\nimdb_movies['budget'] = pd.to_numeric(imdb_movies['budget'], errors='coerce')\n\n# Create worlwide_gross_income_currency column and formatting worlwide_gross_income column into numeric values for converting to usd\nimdb_movies['worlwide_gross_income_currency'] = imdb_movies['worlwide_gross_income'].str.split(' ', expand = True)[0]\nimdb_movies['worlwide_gross_income_currency'] = imdb_movies['worlwide_gross_income_currency'].str.replace('$', 'USD')\nimdb_movies['worlwide_gross_income'] = imdb_movies['worlwide_gross_income'].str.split(' ', expand = True)[1]\nimdb_movies['worlwide_gross_income'] = pd.to_numeric(imdb_movies['worlwide_gross_income'], errors='coerce')\n\n# Create usa_gross_income_currency column and formatting usa_gross_income column into numeric values for converting to usd\nimdb_movies['usa_gross_income_currency'] = imdb_movies['usa_gross_income'].str.split(' ', expand = True)[0]\nimdb_movies['usa_gross_income_currency'] = imdb_movies['usa_gross_income_currency'].str.replace('$', 'USD')\nimdb_movies['usa_gross_income'] = imdb_movies['usa_gross_income'].str.split(' ', expand = True)[1]\nimdb_movies['usa_gross_income'] = pd.to_numeric(imdb_movies['usa_gross_income'], errors='coerce')\n","7094968f":"# Convert currencies into USD\n\nc = CurrencyConverter()\nfor i in range(imdb_movies.shape[0]):\n    # budget column\n    if (imdb_movies['budget_currency'].iloc[i] in c.currencies):\n        imdb_movies['budget'].iloc[i] = c.convert(imdb_movies['budget'].iloc[i], imdb_movies['budget_currency'].iloc[i], 'USD')\n    else :\n        imdb_movies['budget'].iloc[i] = np.nan\n   \n    # worlwide_gross_income column   \n    if (imdb_movies['worlwide_gross_income_currency'].iloc[i] in c.currencies):\n        imdb_movies['worlwide_gross_income'].iloc[i] = c.convert(imdb_movies['worlwide_gross_income'].iloc[i], \n                                                            imdb_movies['worlwide_gross_income_currency'].iloc[i], 'USD', )\n    else :\n        imdb_movies['worlwide_gross_income'].iloc[i] = np.nan\n    \n    # usa_gross_income column   \n    if (imdb_movies['usa_gross_income_currency'].iloc[i] in c.currencies):\n        imdb_movies['usa_gross_income'].iloc[i] = c.convert(imdb_movies['usa_gross_income'].iloc[i], \n                                                       imdb_movies['usa_gross_income_currency'].iloc[i], 'USD', \n                                                       )\n    else :\n        imdb_movies['usa_gross_income'].iloc[i] = np.nan\n","ee429ea1":"num_data = ['duration', 'avg_vote', 'votes', 'budget', 'usa_gross_income', 'worlwide_gross_income', \n            'metascore', 'reviews_from_users', 'reviews_from_critics']\nimdb_movies[num_data].describe()","7c7bcc1a":"# Visualize distplot and boxplot on each numerical data\/columns\n\nfig, ax = plt.subplots(9, 2, figsize = (14, 24))\nfig.tight_layout(pad = 5)\n\nfor i, n in enumerate(num_data):\n    sns.distplot(ax = ax[i,0], a = imdb_movies[n].dropna(), label = 'skewness : %.2f'%(imdb_movies[n].skew()))\n    ax[i,0].set_title(n, fontsize = 18)\n    ax[i,0].legend(loc = 'best')\n    \n    sns.boxplot(ax = ax[i, 1], x = imdb_movies[n].dropna())\n    ax[i, 1].set_title(n, fontsize = 18)\nplt.show()","daaa91c2":"# Clean the data on 'year' column\nimdb_movies['year'].replace('TV Movie 2019', 2019, inplace = True)\nimdb_movies['year'] = imdb_movies['year'].astype(int)\n\n# Group the data based on Decades\nmovies_by_decades = imdb_movies[['imdb_title_id', 'original_title', 'year','avg_vote', 'votes']]\ndecades = movies_by_decades['year']\/\/10*10\ndecades = decades.astype(str)+' - '+ (decades+9).astype(str)\ndecades_column = pd.DataFrame(decades)\nmovies_by_decades.insert(3, 'decades', decades_column)\nmovies_by_decades.head()","4540aa1e":"# Visualize movie counts release based on decade with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\ndecades = movies_by_decades.groupby('decades')['imdb_title_id'].count().index\ncount = movies_by_decades.groupby('decades')['imdb_title_id'].count()\nsns.barplot(ax = ax, x = decades, y = count)\nax.set_title('Movie Counts Based on Decade', fontsize = 18)\nax.set_xlabel('Decade')\nfor index,count in enumerate(count.astype(int)):\n       ax.text(x=index-0.15 , y =count+1 , s=f\"{count}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nplt.show()","31379e08":"# Visualize average vote (rating) based on decade with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\ndecades = movies_by_decades.groupby('decades')['avg_vote'].mean().index\navg_vote = movies_by_decades.groupby('decades')['avg_vote'].mean()\nsns.barplot(ax = ax, x = decades, y = avg_vote)\nax.set_title('Average Vote (Rating) Based on Decade', fontsize = 18)\nax.set_xlabel('Decade')\nfor index,avg_vote in enumerate(np.round(avg_vote, 2)):\n       ax.text(x=index-0.15 , y =avg_vote+0 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim((5, 7))\n\nplt.show()","04a1d4ab":"# Preprocess the data \n\nimdb_movies['date_published'].replace('TV Movie 2019', 2019, inplace = True)\nmovies_published = imdb_movies[['imdb_title_id', 'original_title', 'genre', 'date_published']]\nmovies_published['month_published'] = [month[5:7] for month in movies_published['date_published'].astype(str)]\n\n#print(movies_published['month_published'].unique()) # There are blank values on month_published column\nmovies_published['month_published'][movies_published['month_published']==''] = np.nan # replace blank values with nan\nmovies_published.head()","2809a2d9":"# Visualize movie counts release based on month with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\nmonths_published = movies_published.groupby('month_published')['imdb_title_id'].count().index\ncount_movies = movies_published.groupby('month_published')['imdb_title_id'].count()\nsns.barplot(ax = ax, x = months_published, y = count_movies)\nax.set_title('Movie Counts Based on Month', fontsize = 18)\nax.set_xlabel('Month')\nax.set_ylabel('No. of Movies')\nfor index,count_movies in enumerate(count_movies):\n       ax.text(x=index-0.15 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_xticklabels(['January', 'February', 'March', 'April', 'May', 'June'\n                    , 'July', 'August', 'September', 'October', 'November', 'December'])\n\nplt.show()","809c5d3e":"# Create wordcloud on genre column data\n\ncomment_words = ''\nstop_words = set(STOPWORDS)\n\nfor val in imdb_movies['genre']:\n    val = str(val)\n    tokens = val.split()\n    \n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n    \n    comment_words += \" \".join(tokens)+\" \"\n\nwordcloud = WordCloud(width = 800, height = 600, background_color = 'black'\n                      , stopwords = stop_words, min_font_size = 10).generate(comment_words)\n\nfig, ax = plt.subplots(figsize = (8, 6))\nax.grid(False)\nax.imshow((wordcloud))\nfig.tight_layout(pad=0)\nplt.show()","a067703f":"# Preprocess and split genre column data (because there are more than one genre in each row data)\n\nmovies_genre = imdb_movies[['imdb_title_id', 'original_title', 'genre', 'avg_vote']]\nmovies_genre['genre'] = movies_genre['genre'].astype('str')\n\ngenre_split = pd.DataFrame(movies_genre['genre'].str.split(',').tolist(), index=movies_genre['imdb_title_id']).stack()\ngenre_split = genre_split.reset_index(['imdb_title_id'])\ngenre_split.columns = ['imdb_title_id', 'genre_split']\nmovies_genre_split = pd.merge(genre_split, movies_genre[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_genre_split['genre_split'] = movies_genre_split['genre_split'].str.lstrip(' ').str.rstrip(' ')\nmovies_genre_split.head()","cd17430e":"# Visualize top 5 genres based on movie counts and based on average vote (rating)\n\nfig, ax = plt.subplots(1, 2, figsize = (16,6))\n\ngenres = movies_genre_split.groupby('genre_split')['imdb_title_id'].count().sort_values(ascending = False).index[0:5]\ncount_movies = movies_genre_split.groupby('genre_split')['imdb_title_id'].count().sort_values(ascending = False)[0:5]\nax[0].pie(x=count_movies, autopct=\"%.2f%%\", labels=genres, pctdistance=0.5)\nax[0].set_title('Top 5 Genres Based on Movie Counts', fontsize = 18)\n\ngenres = movies_genre_split.groupby('genre_split')['avg_vote'].mean().sort_values(ascending = False).index[0:5]\navg_votes = movies_genre_split.groupby('genre_split')['avg_vote'].mean().sort_values(ascending = False)[0:5]\nsns.barplot(ax = ax[1], x = genres, y = avg_votes)\nax[1].set_title('Top 5 Genres Based on Average Vote (Rating)', fontsize = 18)\nax[1].set_xlabel('Genre')\nfor index,avg_votes in enumerate(round(avg_votes, 2)):\n    ax[1].text(x=index-0.1 , y =avg_votes+0 , s=f\"{avg_votes}\" , fontdict=dict(fontsize=10))\nax[1].set_ylabel('Average Vote')\nax[1].set_ylim(6, 8)\n\nplt.show()","45c75492":"# Preprocess and split director column data (because there are more than one director in each row data)\n\nmovies_director = imdb_movies[['imdb_title_id', 'original_title', 'director', 'avg_vote']]\nmovies_director['director'] = movies_director['director'].astype('str')\n\ndirector_split = pd.DataFrame(movies_director['director'].str.split(',').tolist(), index=movies_director['imdb_title_id']).stack()\ndirector_split = director_split.reset_index(['imdb_title_id'])\ndirector_split.columns = ['imdb_title_id', 'director_split']\nmovies_director_split = pd.merge(director_split, movies_director[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_director_split['director_split'] = movies_director_split['director_split'].str.lstrip(' ').str.rstrip(' ')\ngb_director = movies_director_split.groupby('director_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_director.drop(gb_director[gb_director.index == 'nan'].index, inplace = True)\ngb_director.head()","15ac8ade":"# Visualize top 10 directors based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\ndirectors = gb_director[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_director[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\nsns.barplot(ax = ax, x = directors, y = count_movies)\nax.set_title('Top 10 Directors Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Director')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.05 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(50, 100)\nplt.show()","7baf671a":"# Visualize top 10 directors based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have direct 5 movies\nmask = movies_director_split.groupby('director_split')['imdb_title_id'].count() >= 5\ndirectors = gb_director.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_director.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = directors, y = avg_vote)\nax.set_title('Top 10 Directors Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Director')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(7.4, 8.4)\nplt.show()","7938f00f":"# Preprocess and split writer column data (because there are more than one writer in each row data)\n\nmovies_writer = imdb_movies[['imdb_title_id', 'original_title', 'writer', 'avg_vote']]\nmovies_writer['writer'] = movies_writer['writer'].astype('str')\n\nwriter_split = pd.DataFrame(movies_writer['writer'].str.split(',').tolist(), index=movies_writer['imdb_title_id']).stack()\nwriter_split = writer_split.reset_index(['imdb_title_id'])\nwriter_split.columns = ['imdb_title_id', 'writer_split']\nmovies_writer_split = pd.merge(writer_split, movies_writer[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_writer_split['writer_split'] = movies_writer_split['writer_split'].str.lstrip(' ').str.rstrip(' ')\ngb_writer = movies_writer_split.groupby('writer_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_writer.drop(gb_writer[gb_writer.index == 'nan'].index, inplace = True)\ngb_writer.head()","e7f738f3":"# Visualize top 10 writers based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\nwriters = gb_writer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_writer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = writers, y = count_movies)\nax.set_title('Top 10 Writers Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Writer')\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.05 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(30, 60)\nplt.show()","1c077d8b":"# Visualize top 10 writers based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have write 5 movies\nmask = movies_writer_split.groupby('writer_split')['imdb_title_id'].count() >= 5\nwriters = gb_writer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_writer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = writers, y = avg_vote)\nax.set_title('Top 10 Writers Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Writer')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(7.4, 8.8)\nplt.show()","f50a68d2":"# Preprocess production company column data\n\nmovies_productioncomp = imdb_movies[['imdb_title_id', 'original_title', 'production_company', 'avg_vote']]\nmovies_productioncomp['production_company'] = movies_productioncomp['production_company'].astype('str')\n\ngb_productioncomp = movies_productioncomp.groupby('production_company').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_productioncomp.drop((gb_productioncomp[gb_productioncomp.index == ''].index) | (gb_productioncomp[gb_productioncomp.index == 'nan'].index), inplace = True)\ngb_productioncomp.head()","d15e903c":"# Visualize top 10 production companies based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\nproductioncomp = gb_productioncomp[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_productioncomp[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = productioncomp, y = count_movies)\nax.set_title('Top 10 Production Companies Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Production Company')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.1 , y =count_movies+0.6 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(100, 1400)\nplt.show()","51abd1e7":"# Visualize top 10 production companies based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have produce 20 movies\nmask = movies_productioncomp.groupby('production_company')['imdb_title_id'].count() >= 20\nproductioncomp = gb_productioncomp.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_productioncomp.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = productioncomp, y = avg_vote)\nax.set_title('Top 10 Production Companies Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Production Company')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0.005 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(6.4, 7.2)\nplt.show()","e80fa154":"# Preprocess and split actor column data (because there are more than one actor in each row data)\n\nmovies_actor = imdb_movies[['imdb_title_id', 'original_title', 'actors', 'avg_vote']]\nmovies_actor['actors'] = movies_actor['actors'].astype('str')\n\nactor_split = pd.DataFrame(movies_actor['actors'].str.split(',').tolist(), index=movies_actor['imdb_title_id']).stack()\nactor_split = actor_split.reset_index(['imdb_title_id'])\nactor_split.columns = ['imdb_title_id', 'actor_split']\nmovies_actor_split = pd.merge(actor_split, movies_actor[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_actor_split['actor_split'] = movies_actor_split['actor_split'].str.lstrip(' ').str.rstrip(' ')\ngb_actor = movies_actor_split.groupby('actor_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_actor.drop((gb_actor[gb_actor.index == 'nan'].index), inplace = True)\ngb_actor.head()","d929ad91":"# Visualize top 10 actors based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\nactor = gb_actor[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_actor[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = actor, y = count_movies)\nax.set_title('Top 10 Actors\/Actess Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Actor\/Actess')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.1 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(90, 200)\nplt.show()","6dfe896d":"# Visualize top 10 actors based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have become an actor\/actress on 10 movies\nmask = movies_actor_split.groupby('actor_split')['imdb_title_id'].count() >= 10\nactor = gb_actor.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_actor.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = actor, y = avg_vote)\nax.set_title('Top 10 Actors\/Actress Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Actor\/Actess')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0.005 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(7, 7.6)\nplt.show()","d2286dfa":"# Preprocess and split cinematographer column data (because there are more than one cinematographer in each row data)\n\nmovies_cinematographer = imdb_movies[['imdb_title_id', 'original_title', 'cinematographer', 'avg_vote']]\nmovies_cinematographer['cinematographer'] = movies_cinematographer['cinematographer'].astype('str')\n\ncinematographer_split = pd.DataFrame(movies_cinematographer['cinematographer'].str.split(',').tolist(), index=movies_cinematographer['imdb_title_id']).stack()\ncinematographer_split = cinematographer_split.reset_index(['imdb_title_id'])\ncinematographer_split.columns = ['imdb_title_id', 'cinematographer_split']\n\nmovies_cinematographer_split = pd.merge(cinematographer_split, movies_cinematographer[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_cinematographer_split['cinematographer_split'] = movies_cinematographer_split['cinematographer_split'].str.lstrip(' ').str.rstrip(' ')\ngb_cinematographer = movies_cinematographer_split.groupby('cinematographer_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_cinematographer.drop((gb_cinematographer[gb_cinematographer.index == 'nan'].index), inplace = True)\ngb_cinematographer.head()","0b952a2d":"# Visualize top 10 cinematographers based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\ncinematographer = gb_cinematographer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_cinematographer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = cinematographer, y = count_movies)\nax.set_title('Top 10 Cinematographers Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Cinematographer')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.05 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(55, 80)\nplt.show()","e1289d03":"# Visualize top 10 cinematographers based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have direct 5 movies\nmask = movies_cinematographer_split.groupby('cinematographer_split')['imdb_title_id'].count() >= 5\ncinematographer = gb_cinematographer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_cinematographer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = cinematographer, y = avg_vote)\nax.set_title('Top 10 Cinematographers Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Cinematographer')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0.005 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(6.8, 8)\nplt.show()","7aeb847e":"# Features that used in this recommender system is 'original_title' (as index),  'genre', 'director', 'actors', 'description'\ndata_recsys=imdb_movies[['original_title', 'genre', 'director', 'actors', 'description']].reset_index(drop = True)\ndata_recsys.head()","9c2303c0":"# Preprocess the data\n\ndata_recsys.set_index('original_title', inplace = True)\n\ndata_recsys['genre'] = data_recsys['genre'].fillna('').astype('str').str.lower()\ndata_recsys['genre'] = data_recsys['genre'].str.split(',')\n\ndata_recsys['director'] = data_recsys['director'].fillna('').astype('str').str.lower()\ndata_recsys['director'] = data_recsys['director'].str.split(',')\n\ndata_recsys['actors'] = data_recsys['actors'].fillna('').astype('str').str.lower()\ndata_recsys['actors'] = data_recsys['actors'].str.split(',')","5078fb0e":"# Preprocess description column data\n\ndata_recsys['description'] = data_recsys['description'].fillna('').astype('str').str.lower()\ndata_recsys['description'] = data_recsys['description'].str.translate(str.maketrans('', '', string.punctuation))\n\n#from nltk.corpus import stopwords\nlistStopwords = set(stopwords.words('english'))\nfiltered = []\nps = PorterStemmer() \nfor i, text in enumerate(data_recsys['description'].str.split()):\n    for word in text:\n        # Filtering\/Removing stopwords in the text\n        if word not in listStopwords:\n            # Stemming words\n            word_stemmed = ps.stem(word)\n            filtered.append(word_stemmed)\n    data_recsys['description'][i] = filtered\n    filtered = []","0d33c96c":"# Create new column 'bunch_of_words' that contains words taken from all features columns\n\ndata_recsys['bunch_of_words'] = ''\nfor i, text in data_recsys.iterrows():\n    words = ''\n    for col in data_recsys.columns:\n        words = words + ' '.join(text[col]) + ' '\n    data_recsys['bunch_of_words'][i] = words","bbbe3026":"data_recsys.head()","51a77167":"# Convert a collection of text documents to a vector of term\/token counts (CountVectorizer)\n\ncount = CountVectorizer()\ncount_matrix = count.fit_transform(data_recsys['bunch_of_words']).astype(np.uint8)","19b4bde4":"# To reduce memory usage\ndel data_imdb_names\ndel data_imdb_title_principals","7fccd276":"# Calculate Cosine Similarity\n# Cosine similarity is a metric used to measure how similar the documents are irrespective of their size\n\nchunk_size = 500 \nmatrix_len = count_matrix.shape[0] # Not sparse numpy.ndarray\n\n# Calculate cosine similarity chunk by chunk\ndef similarity_cosine_by_chunk(start, end):\n    if end > matrix_len:\n        end = matrix_len\n    return cosine_similarity(X=count_matrix[start:end], Y=count_matrix)\ncosine_similarity_all = []\ni=0\nfor chunk_start in range(0, matrix_len, chunk_size):\n    \n    # Initialize first cosine sim chunk (for first concatenating chunks purpose)\n    if i == 0: \n        cosine_sim = similarity_cosine_by_chunk(chunk_start, chunk_start+chunk_size)\n    \n    # Initialize other cosine sim chunk, then concatenating chunk by chunk untill all chunks concatenated\n    else :\n        cosine_similarity_chunk= similarity_cosine_by_chunk(chunk_start, chunk_start+chunk_size)\n        # Use type data float32 for reduce memory usage\n        cosine_sim = np.concatenate((cosine_sim.astype(np.float32), cosine_similarity_chunk.astype(np.float32)))\n    \n    # Change value i != 0 for execute else statement, because we dont need execute if statement anymore (if statement only to initialize first chunk for first concatenating purpose)\n    i= 1","ad9c8157":"# Create function that return 10 recommended\/similar movies based on input\n\n# Create variable index\nindex_movies = pd.Series(data_recsys.index)\n\n# Movies Recommendation function\ndef recommendation_movies(title, cosine_sim = cosine_sim):\n    recommended_movies = []\n    index_movie_input = index_movies[index_movies == title].index[0]\n    score_movies = pd.Series(cosine_sim[index_movie_input]).sort_values(ascending = False)\n    top_10_index_movies = list(score_movies.iloc[1:11].index)\n    # Get movies title and year by index (top 10 movies)\n    for i in top_10_index_movies:\n        recommended_movies.append(imdb_movies['original_title'].iloc[i] + ' (' + str(imdb_movies['year'].iloc[i]) + ')')\n    return recommended_movies","15cfdd26":"# Results\nrecommendation_movies('The Dark Knight')","c6c66532":"### Analysis Numeric Data","ecd6630c":"#### Which Director Has Release Most Movies and Highest Average Vote (Rating)","d466fc5f":"#### Which Actor Has Release Most Movies and Highest Average Vote (Rating)","63a13570":"#### Which Decade Has Release Most Movies and Highest Average Vote (Rating)","0d41eb4f":"#### Which Genre Has Release Most Movies and Highest Average Vote (Rating)","afb21e44":"# Recommender System Based on Content","d1fc365e":"### Analysis Categorical Data","61037b6b":"#### Which Cinematographer Has Release Most Movies and Highest Average Vote (Rating)","eec7f78d":"## Analysis Numeric and Categorical Data","d80b7065":"#### Which Month Has Release Most Movies","dbdf853c":"#### Which Writer Has Release Most Movies and Highest Average Vote (Rating)","bafc2155":"#### Which Production Company Has Release Most Movies and Highest Average Vote (Rating)","ea3f72d6":"# Data Preprocessing & Exploratory Data Analysis","8bca50ca":"#### Wordcloud Genre Column\n"}}