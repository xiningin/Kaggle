{"cell_type":{"62d2aadf":"code","41ea8e69":"code","4da3c099":"code","89359af6":"code","9bba3f25":"code","690a8580":"code","37e0042f":"code","435bf02b":"code","5d791aab":"code","ea3197aa":"code","d0d5527b":"code","e8aa1025":"code","adc42d6a":"code","5cf9974d":"code","d881f7c5":"code","1aa125e8":"code","75eb472d":"code","8d23e6ef":"code","dd8f3e4b":"code","1986fbf6":"code","10238c50":"code","86269c56":"code","3198d16e":"code","bab50bcc":"code","b4314a79":"code","80f5c495":"code","763dea1d":"code","746cb608":"markdown","04c966e6":"markdown","cae28f8f":"markdown","52162880":"markdown","cca8acb5":"markdown","343230bd":"markdown","9b92e9b2":"markdown","d211e9d6":"markdown"},"source":{"62d2aadf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.inception_resnet_v2 import preprocess_input,decode_predictions\nfrom keras import backend as K\nfrom keras.layers import add, Conv2D,MaxPooling2D,UpSampling2D,Input,BatchNormalization, RepeatVector, Reshape\nfrom keras.layers.merge import concatenate\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import set_random_seed\nset_random_seed(2)\nnp.random.seed(1)\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","41ea8e69":"InputPath=\"..\/input\/image-classification\/images\/images\/art and culture\/\"","4da3c099":"def noisy(noise_typ,image):\n    if noise_typ == \"gauss\":\n        row,col,ch= image.shape\n        mean = 0\n        var = 0.0001\n        sigma = var**0.05\n        gauss = np.random.normal(mean,sigma,(row,col,ch))\n        gauss = gauss.reshape(row,col,ch)\n        noisy =  gauss + image\n        return noisy\n    elif noise_typ == \"s&p\":\n        row,col,ch = image.shape\n        s_vs_p = 0.5\n        amount = 1.0\n        out = np.copy(image)\n        # Salt mode\n        num_salt = np.ceil(image.size * s_vs_p)\n        coords = [np.random.randint(0, i, int(num_salt))\n              for i in image.shape]\n        out[coords] = 1\n\n        # Pepper mode\n        num_pepper = np.ceil(image.size * (1. - s_vs_p))\n        coords = [np.random.randint(0, i , int(num_pepper))\n              for i in image.shape]\n        out[coords] = 1\n        return out\n    elif noise_typ == \"poisson\":\n        vals = len(np.unique(image))\n        vals = 2 ** np.ceil(np.log2(vals))\n        noisy = np.random.poisson(image * vals) \/ float(vals)\n        return noisy\n    elif noise_typ ==\"speckle\":\n        row,col,ch = image.shape\n        gauss = np.random.randn(row,col,ch)\n        gauss = gauss.reshape(row,col,ch)        \n        noisy = image + image * gauss\n        return noisy","89359af6":"img = cv.imread(InputPath+\"0 (3).jpg\")  \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nl = img.max()\nplt.imshow(img)\nl","9bba3f25":"Noise = noisy(\"s&p\",img)\nplt.imshow(Noise)","690a8580":"hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV) #convert it to hsv\nhsv[...,2] = hsv[...,2]*0.2\nimg1 = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\nNoise2 = noisy(\"s&p\",img1)\n\nplt.imshow(Noise2)","37e0042f":"def PreProcessData(ImagePath):\n    X_=[]\n    y_=[]\n    count=0\n    for imageDir in os.listdir(ImagePath):\n        if count<2131:\n            try:\n                count=count+1\n                img = cv.imread(ImagePath + imageDir)\n                img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n                img_y = cv.resize(img,(500,500))\n                hsv = cv.cvtColor(img_y, cv.COLOR_BGR2HSV) #convert it to hsv\n                hsv[...,2] = hsv[...,2]*0.2\n                img_1 = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n                Noisey_img = noisy(\"s&p\",img_1)\n                X_.append(Noisey_img)\n                y_.append(img_y)\n            except:\n                pass\n    X_ = np.array(X_)\n    y_ = np.array(y_)\n    \n    return X_,y_","435bf02b":"X_,y_ = PreProcessData(InputPath)","5d791aab":"K.clear_session()\ndef InstantiateModel(in_):\n    \n    model_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(in_)\n    model_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_1)\n    model_1 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_1)\n    \n    model_2 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(in_)\n    model_2 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)\n    \n    model_2_0 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)\n    \n    model_add = add([model_1,model_2,model_2_0])\n    \n    model_3 = Conv2D(64,(3,3), activation='relu',padding='same',strides=1)(model_add)\n    model_3 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_3)\n    model_3 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3)\n    \n    model_3_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_add)\n    model_3_1 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3_1)\n    \n    model_3_2 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add)\n    \n    model_add_2 = add([model_3_1,model_3_2,model_3])\n    \n    model_4 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_2)\n    model_4_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add)\n    #Extension\n    model_add_3 = add([model_4_1,model_add_2,model_4])\n    \n    model_5 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_3)\n    model_5 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add_3)\n    \n    model_5 = Conv2D(3,(3,3), activation='relu',padding='same',strides=1)(model_5)\n    \n    return model_5\n    ","ea3197aa":"Input_Sample = Input(shape=(500, 500,3))\nOutput_ = InstantiateModel(Input_Sample)\nModel_Enhancer = Model(inputs=Input_Sample, outputs=Output_)","d0d5527b":"Model_Enhancer.compile(optimizer=\"adam\", loss='mean_squared_error')\nModel_Enhancer.summary()","e8aa1025":"from keras.utils.vis_utils import plot_model\nplot_model(Model_Enhancer,to_file='model_.png',show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage(retina=True, filename='model_.png')","adc42d6a":"def GenerateInputs(X,y):\n    for i in range(len(X)):\n        X_input = X[i].reshape(1,500,500,3)\n        y_input = y[i].reshape(1,500,500,3)\n        yield (X_input,y_input)\nModel_Enhancer.fit_generator(GenerateInputs(X_,y_),epochs=53,verbose=1,steps_per_epoch=39,shuffle=True)","5cf9974d":"TestPath=\"..\/input\/image-classification\/images\/images\/art and culture\/\"","d881f7c5":"def ExtractTestInput(ImagePath):\n    img = cv.imread(ImagePath)\n    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n    img_ = cv.resize(img,(500,500))\n    hsv = cv.cvtColor(img_, cv.COLOR_BGR2HSV) #convert it to hsv\n    hsv[...,2] = hsv[...,2]*0.2\n    img1 = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n    Noise = noisy(\"s&p\",img1)\n    Noise = Noise.reshape(1,500,500,3)\n    return Noise","1aa125e8":"ImagePath=TestPath+\"101 (6).jpg\"\nimage_for_test = ExtractTestInput(ImagePath)\nPrediction = Model_Enhancer.predict(image_for_test)","75eb472d":"Prediction = Prediction.reshape(500,500,3)\nplt.imshow(Prediction)","8d23e6ef":"Image_test=TestPath+\"101 (6).jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","dd8f3e4b":"TestPath2=\"..\/input\/image-classification\/validation\/validation\/travel and adventure\/\"","1986fbf6":"Image_test2=TestPath2+\"0.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","10238c50":"Image_test2=TestPath2+\"13.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","86269c56":"Image_test2=TestPath2+\"18.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","3198d16e":"Image_test2=TestPath2+\"2.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","bab50bcc":"Image_test2=TestPath2+\"14.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","b4314a79":"Image_test2=TestPath2+\"11.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","80f5c495":"Image_test2=TestPath2+\"10.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","763dea1d":"Image_test2=TestPath2+\"12.jpg\"\nplt.figure(figsize=(30,30))\nplt.subplot(5,5,1)\nimg_1 = cv.imread(Image_test2)\nimg_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\nimg_1 = cv.resize(img_1, (500, 500))\nplt.title(\"Ground Truth\",fontsize=20)\nplt.imshow(img_1)\n\nplt.subplot(5,5,1+1)\nimg_ = ExtractTestInput(Image_test2)\nPrediction = Model_Enhancer.predict(img_)\nimg_ = img_.reshape(500,500,3)\nplt.title(\"Low Light Image\",fontsize=20)\nplt.imshow(img_)\n\nplt.subplot(5,5,1+2)\nPrediction = Prediction.reshape(500,500,3)\nimg_[:,:,:] = Prediction[:,:,:]\nplt.title(\"Enhanced Image\",fontsize=20)\nplt.imshow(img_)\n","746cb608":"## Low light Image Enhancement with Convolutional Neural Network.\nImage enhancement is one of the modern topics that are discussed now a days and Deep Learning play a major part in it. We see various types of smartPhones with their night mode in camera which help us to take beautiful images at night or low light situation.","04c966e6":"## REAL IMAGE","cae28f8f":"The Camera is not able to take the perfect image at low light because of the noise created at the camera sensors. During night mode the noise is cancelled out by the camera to get the perfect image.","52162880":"## conclusion\n\n1. The model works preety good with low light images.\n2. We have used salt and peeper noise to train the model with a relistic low light image although it is not tested for other type of noises.\n3. The model is producing inappropriate results in case of enhancing a very bright section of an image. The reason might be due to presence of salt pepper noise and might produce better results in case of real-time low light image.\n","cca8acb5":"## IMAGE WITH NOISE(SALT AND PEPPER NOISE)","343230bd":"![Low Light Image Enhancement](https:\/\/www.soyacincau.com\/wp-content\/uploads\/2014\/04\/140415-ASUS-PixelMaster.jpg)","9b92e9b2":"## COMPARATIVE ANALYSIS OF THE ENHANCED IMAGE WITH RESPECT TO GROUND TRUTH IMAGE","d211e9d6":"  ## IMAGE WITH LOW-BRIGHTNESS AND SALT-PEPPER NOISE TO GET THE PERFECT LOW-LIGHT IMAGE"}}