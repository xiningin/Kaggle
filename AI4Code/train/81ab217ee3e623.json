{"cell_type":{"6dd0a88c":"code","39253538":"code","dfdd438d":"code","fd21b4c5":"code","afe85585":"code","b087a551":"code","1dec18e0":"code","06cc964e":"code","6e96253e":"code","c3c3bb91":"code","6239dc5d":"code","5be58a16":"code","04e4af7c":"code","b9b4768d":"code","1f975de8":"code","df9cf6c1":"code","8459ccb4":"code","5347088e":"code","d3db35c4":"code","ea02b181":"code","8c6283a1":"code","84e763f9":"code","c763bee7":"code","cb3a244e":"code","b57b82bc":"code","edddc7c9":"code","3e7a7f64":"code","20654b77":"code","3342eb37":"code","eaae56cb":"markdown","5bea7b0f":"markdown","3467daed":"markdown","8120d9e0":"markdown","1e7b9c51":"markdown","c5e679e2":"markdown","e2d8ed6f":"markdown"},"source":{"6dd0a88c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","39253538":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation","dfdd438d":"train_reg= pd.read_csv('..\/input\/real-estate-price-prediction\/Real estate.csv')","fd21b4c5":"train_reg.head()","afe85585":"train_reg","b087a551":"train_reg.info()","1dec18e0":"X=train_reg.drop('Y house price of unit area', axis=1)\ny= train_reg['Y house price of unit area']","06cc964e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","6e96253e":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","c3c3bb91":"Sc_X_train=scaler.fit_transform(X_train)\nSc_X_test=scaler.transform(X_test) ## In the test dataset we call transform without fit ","6239dc5d":"lin_reg = LinearRegression(normalize=True)\nlin_reg.fit(Sc_X_train,y_train)","5be58a16":"score_train = lin_reg.score(Sc_X_train, y_train) #Coefficient of determination\nscore_test =lin_reg.score(Sc_X_test, y_test)\n\nprint('train score: {}'.format(score_train)) \nprint('test score: {}'.format(score_test))","04e4af7c":"lin_reg.intercept_","b9b4768d":"print(lin_reg.coef_)","1f975de8":"y_pred =lin_reg.predict(Sc_X_test)\ny_pred","df9cf6c1":"df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndf","8459ccb4":"from sklearn.svm import SVR\n\nreg=SVR(kernel='rbf')\nreg.fit(X_train, y_train)\n\n\nsvr_score_train = reg.score(X_train, y_train) #Coefficient of determination\nsvr_score_test =reg.score(X_test, y_test)\n\nprint('train score: {}'.format(svr_score_train)) \nprint('test score: {}'.format(svr_score_test))","5347088e":"trainC = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","d3db35c4":"trainC.info()","ea02b181":"X= trainC.drop(['diagnosis','Unnamed: 32'], axis=1)\ny= trainC['diagnosis']","8c6283a1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","84e763f9":"# Create Decision Tree classifer object\nclf = DecisionTreeClassifier(max_depth=5)\n\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)","c763bee7":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","cb3a244e":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)","b57b82bc":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","edddc7c9":"cleanup_nums = { \"diagnosis\": {\"M\": 0, \"D\": 1} }\ntrainC.replace(cleanup_nums, inplace=True)","3e7a7f64":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nSc_X_train=scaler.fit_transform(X_train)\nSc_X_test=scaler.transform(X_test)","20654b77":"#Import svm model\nfrom sklearn import svm\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='rbf') # Linear Kernel\n\n#Train the model using the training sets\nclf.fit(X_train, y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)","3342eb37":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","eaae56cb":"Obtaining the dataset: ","5bea7b0f":"# Classification dataset","3467daed":"**.score() returns the coefficient of determination, or R\u00b2, for the data passed. Its maximum is 1. The higher the R\u00b2 value, the better the fit.** <br\/>\n**Unlike root mean squared error, where the lower the value, the better the fit.** <br\/>\n**More on this part will be covered next session, but .score() is R\u00b2 and not root mean sqaured .** <br\/>\n","8120d9e0":"# Regression Dataset","1e7b9c51":"Splitting the dataset: ","c5e679e2":"Checking for data that needs cleaning: ","e2d8ed6f":"Scaling dataset to be used with linear regression and SVR: "}}