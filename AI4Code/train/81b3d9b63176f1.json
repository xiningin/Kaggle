{"cell_type":{"e3a69fc5":"code","2df3c1a4":"code","5ec6013c":"code","a78ab8a8":"code","2dfb52db":"code","874dad31":"code","f6f83145":"code","994f5bb6":"code","6af8d420":"code","b927d2cd":"code","8942a28d":"code","e127938c":"code","8dadca6a":"code","6d10193e":"code","9e85e61e":"code","b7af4039":"markdown","7b0efc9c":"markdown","bd1f930d":"markdown","e10b660f":"markdown","954f7978":"markdown","74002b52":"markdown","8e95dac0":"markdown","1eee1f3a":"markdown","f0d11baf":"markdown","40f2b9bb":"markdown"},"source":{"e3a69fc5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2df3c1a4":"!pip install pyspark","5ec6013c":"from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator","a78ab8a8":"spark = SparkSession.builder.appName('assignment7').getOrCreate()","2dfb52db":"raw_train = spark.read.csv('..\/input\/car-acceptability-prediction\/train.csv', header = True, inferSchema=True)\nraw_test = spark.read.csv('..\/input\/car-acceptability-prediction\/test.csv', header = True, inferSchema=True)","874dad31":"train_pd = raw_train.toPandas()\ntest_pd = raw_test.toPandas()","f6f83145":"train_pd.info()","994f5bb6":"test_pd.info()","6af8d420":"raw_train.groupBy('acceptability').count().sort('count').show()","b927d2cd":"indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(raw_train) for column in raw_train.columns[1:-1]]\npipeline = Pipeline(stages=indexers)\ntransformer = pipeline.fit(raw_train)\ntrain = transformer.transform(raw_train)","8942a28d":"test = transformer.transform(raw_test)","e127938c":"label_indexer = StringIndexer(inputCol='acceptability', outputCol='acceptability_index').fit(train)\ntrain = label_indexer.transform(train)","8dadca6a":"feature_transformer_train = VectorAssembler(inputCols=train.columns[8:14],outputCol=\"features\")\ntrain = feature_transformer_train.transform(train)\nfeature_transformer_test = VectorAssembler(inputCols=test.columns[7:13],outputCol=\"features\")\ntest = feature_transformer_test.transform(test)","6d10193e":"from pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"acceptability_index\", featuresCol=\"features\", maxDepth=10,seed=465)\nrf_model = rf.fit(train)\npredict = rf_model.transform(test)\n\nfrom pyspark.sql.functions import col, when\npredict = predict.withColumn(\"acceptability\", when(col(\"prediction\")==0, \"unacc\").when(col(\"prediction\")==1, \"acc\").when(col(\"prediction\")==2, \"good\").otherwise(\"vgood\"))\n\nsubmit = predict.select(\"car_id\", \"acceptability\")\nsubmit.toPandas().to_csv('final_submission.csv', header=True, index=False)","9e85e61e":"submit.groupBy('acceptability').count().sort('count').show()","b7af4039":"# Build Model, Predict Testset and Submit","7b0efc9c":"# Transform to indexers","bd1f930d":"# V\u00f5 Linh B\u1ea3o - 18520503\n# H\u00e0 V\u0103n Lu\u00e2n - 18521062","e10b660f":"# Import libraries","954f7978":"# Import dataset","74002b52":"T\u1eadp test kh\u00f4ng c\u00f3 gi\u00e1 null.","8e95dac0":"# Check datatypes and null value","1eee1f3a":"T\u1eadp train kh\u00f4ng c\u00f3 gi\u00e1 tr\u1ecb null.","f0d11baf":"Xem ph\u00e2n ph\u1ed1i gi\u00e1 tr\u1ecb c\u1ee7a bi\u1ebfn d\u1ef1 \u0111o\u00e1n.","40f2b9bb":"# Transform to features"}}