{"cell_type":{"97a78524":"code","1fe99723":"code","5b7daf65":"code","6c56ec7f":"code","9b0759d6":"code","7b5e2916":"code","908629e0":"code","e586a31c":"code","ce9bbcb7":"code","189b1dae":"code","5428429a":"code","1fd2cc03":"code","dec651e9":"code","583a45fe":"code","d2e27f0d":"code","7206c7c2":"code","9f868456":"code","63576c6b":"code","9fa9457c":"code","3a25320e":"code","d43bddad":"code","f0f8782f":"code","0dd9c6f8":"code","1fde6daf":"code","0bd1dee9":"code","9953f2aa":"code","1cb430c7":"code","e4f25766":"code","4546ecaf":"code","df93b6c4":"code","bfdf8e8b":"code","78f7f040":"markdown","3d707c1a":"markdown"},"source":{"97a78524":"#Code made by Hiago Guimaraes\n#Feel free to use and improve it as long as you give\n#the appropriate credits to me.\n\n#This code was tested in pandas 1.3.2 and 1.3.3.\n\n#importing libs\nimport pandas as pd\nimport numpy as ny\nimport statistics as stc\nfrom datetime import datetime\nfrom functools import partial","1fe99723":"#opening and exploring database\nfile = \"..\/input\/database\/database.csv\"\ndataset = pd.read_csv(file, sep=',')\n\nprint(dataset.columns)","5b7daf65":"#calling the variable where the database are\ndataset","6c56ec7f":"#translating columns names\ndataset.set_axis(['Id', 'User', 'Name', 'Product_Type', 'Shop', 'Sale_Date', 'Sale_Value',\n                  'Taxes','Receipt_Buyer_Id', 'Refund', 'Refund_Motive', 'null1','null2',\n                  'null3','null4','null5','null6','null7','null8','null9','null10','null11',\n                  'null12','null13','null14','null15','null16'], axis = 1, inplace = True)\n\n#checking if it was fixed\nprint(dataset.columns)","9b0759d6":"#checking if it has duplicates using 'Id' as base\ndataset.duplicated(subset = ['Id'], keep = False).sum()","7b5e2916":"#dropping duplicates using 'Id' as base\ndataset.drop_duplicates(subset = 'Id', keep = 'first', inplace = True)\n\n#checking if it was fixed\ndataset.duplicated(subset = ['Id'], keep = False).sum()","908629e0":"#checking if it has null values on database\ndataset.isnull().sum()","e586a31c":"#checking the data on 'Refund'\ngby = dataset.groupby(['Refund']).size()\ngby","ce9bbcb7":"#fulfilling the data on 'Refund_Motive'\ndataset['Refund_Motive'].mask((dataset['Refund'] == 'Sim') & (dataset['Refund_Motive'] == \n                                None), 'N\u00e3o informado', inplace = True)\n\ndataset['Refund_Motive'].fillna('Sem Devolu\u00e7\u00e3o', inplace = True)\n\n#checking if it was fixed\ngby = dataset.groupby(['Refund_Motive']).size()\ngby","189b1dae":"#dropping columns, from null1 to null16\ndataset.drop(columns = ['null1', 'null2', 'null3', 'null4', 'null5', 'null6', 'null7', 'null8', 'null9', 'null10',\n                       'null11', 'null12', 'null13', 'null14', 'null15', 'null16'], inplace = True)\n#checking if it was dropped\nprint(dataset.columns)","5428429a":"#dropping rows witch has more that 3 null values\ndataset.dropna(thresh = 3, inplace = True)\n\n#checking if null values were dropped\ndataset.isnull().sum()","1fd2cc03":"#checking the data on 'Shop'\ngby = dataset.groupby(['Shop']).size()\nprint(gby)","dec651e9":"#Fixing the data on 'Shop'\ndataset['Shop'].replace({'Loj L\u00e1brea':'Loja L\u00e1brea', 'Loja Manicor \u00e9':'Loja Manicor\u00e9',\n                        'Loja itacoati_ara':'Loja Itacoatiara', 'Loja manAcaPuru':'Loja Manacapuru'},\n                        regex = True, inplace = True)\n#checking if it was fixed\ngby = dataset.groupby(['Shop']).size()\ngby","583a45fe":"#checking the data on 'Receipt_Buyer_Id'\ngby = dataset.groupby(['Receipt_Buyer_Id']).size()\ngby","d2e27f0d":"#Fixing the data on 'Receipt_Buyer_Id'\ndataset['Receipt_Buyer_Id'].replace({'Na~o':'N\u00e3o'}, regex = True, inplace = True)\n\n#checking if it was fixed\ngby = dataset.groupby(['Receipt_Buyer_Id']).size()\ngby","7206c7c2":"#checking the data types\ndataset.dtypes","9f868456":"#changing 'Id' and 'User' to 'int64'\ndataset['Id'] = dataset['Id'].astype('int64')\ndataset['User'] = dataset['User'].astype('int64')\n\ndataset.dtypes","63576c6b":"#deleting 'R$' from 'Taxes' in order to convert in 'float64'\ndataset['Taxes'] = dataset['Taxes'].str.strip('R$')\ndataset['Taxes'].replace(',', '', regex = True, inplace = True)\n\n#converting 'Taxes' to 'float64'\ndataset['Taxes'] = dataset['Taxes'].astype('float64')\n\n#checking if it was fixed\ndataset.info()","9fa9457c":"#converting 'Sales_Date' to 'datetime64[ns]'\ndataset['Sale_Date'] = pd.to_datetime(dataset['Sale_Date'], format = '%d\/%m\/%Y %H:%M:%S',\n                                      errors = 'raise', utc = False)\n#checking if it was converted\ndataset.info()","3a25320e":"#using the 1\u00ba quartile (25%) and 3\u00ba quartile to find the interquartile range (IQR)\n#for 'Sale_Date'\nQ1 = dataset['Sale_Date'].quantile(0.25)\nQ3 = dataset['Sale_Date'].quantile(0.75)\nIQR = Q3 - Q1\n\n#printing the values find outs\nprint('Q1 = ', Q1)\nprint('Q3 = ', Q3)\nprint('IQR = ', IQR)","d43bddad":"#checking if the find values are corrects\ndataset['Sale_Date'].describe(datetime_is_numeric = True)","f0f8782f":"#calculating the IQR\nlower_limt = Q1 - 1.5 * IQR\nupper_limt = Q3 - 1.5 * IQR\n\n#checking if has outliers using the IQR method \nprint('Have lower outliers in \"Sale_Date\"? ', lower_limt in dataset['Sale_Date'])\nprint('Have upper outliers in \"Sale_Date\"? ', upper_limt in dataset['Sale_Date'])","0dd9c6f8":"#using the 1\u00ba quartile (25%) and 3\u00ba quartile to find the interquartile range (IQR)\n#for 'Sale_Value'\nQ1 = dataset['Sale_Value'].quantile(0.25)\nQ3 = dataset['Sale_Value'].quantile(0.75)\nIQR = Q3 - Q1\n\n#printing the values find outs\nprint('Q1 = ', Q1)\nprint('Q3 = ', Q3)\nprint('IQR = ', IQR)","1fde6daf":"#checking if the find values are corrects\ndataset['Sale_Value'].describe()","0bd1dee9":"#calculating the IQR\nlower_limt = Q1 - 1.5 * IQR\nupper_limt = Q3 - 1.5 * IQR\n\n#checking if has outliers using the IQR method\nprint('Have lower outliers in \"Sale_Value\"? ', lower_limt in dataset['Sale_Date'])\nprint('Have upper outliers in \"Sale_Value\"? ', upper_limt in dataset['Sale_Date'])","9953f2aa":"#using the 1\u00ba quartile (25%) and 3\u00ba quartile (75%) to find the interquartile range (IQR)\n#for 'Taxes'\nQ1 = dataset['Taxes'].quantile(0.25)\nQ3 = dataset['Taxes'].quantile(0.75)\nIQR = Q3 - Q1\n\n#printing the values find outs\nprint('Q1 = ', Q1)\nprint('Q3 = ', Q3)\nprint('IQR = ', IQR)","1cb430c7":"#checking if the findings values are correct\ndataset['Taxes'].describe()","e4f25766":"#calculating the IQR\nlower_limt = Q1 - 1.5 * IQR\nupper_limt = Q3 - 1.5 * IQR\n\n#checking if has outliers using the IQR method \nprint('Have lower outliers in \"Taxes\"? ', lower_limt in dataset['Taxes'])\nprint('Have upper outliers in \"Taxes\"? ', upper_limt in dataset['Taxes'])","4546ecaf":"#saving the changes in a new '.csv' file\ndataset.to_csv(path_or_buf = 'new_dataset', sep = ',')","df93b6c4":"#assigning to a new variable call 'new_dataset'\nnew_file = '.\/new_dataset'\nnew_dataset = pd.read_csv(new_file, sep = ',')\n\n#calling the variable\nnew_dataset","bfdf8e8b":"#seeing if the types are correct\nnew_dataset.info()","78f7f040":"After ","3d707c1a":"# Tutorial: Cleaning and Treating a Database With Pandas 1.3.x #"}}