{"cell_type":{"647c9561":"code","fcc8cae3":"code","21dc56b3":"code","a3a5e18b":"code","9fb7e930":"code","e2d92ecc":"code","4c0b1352":"code","5d155621":"code","d2000856":"code","3bc2b2e5":"code","84ee040b":"code","7eb42b3d":"code","45c022d5":"code","34dc2285":"code","3ce9bb6f":"code","2a8e08b9":"markdown","9d657650":"markdown","bb8ff65f":"markdown","334d36cd":"markdown","8137a085":"markdown","8d7faefa":"markdown","dd134ea5":"markdown","e0b03b3a":"markdown"},"source":{"647c9561":"# Importing usefull things \n\nfrom tensorflow.keras.models import load_model\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom pandas import DataFrame\nimport sklearn.feature_extraction.text as sk_text\nfrom sklearn.feature_extraction.text import TfidfVectorizer \nimport collections\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn import metrics\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import optimizers\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.utils import class_weight\nfrom collections import Counter\nfrom sklearn.metrics import roc_curve, auc\n\nimport time\nimport csv\nimport pandas as pd\n\n%matplotlib inline\n","fcc8cae3":"# import the data\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\ndf = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\ndf.head(10)","21dc56b3":"df.shape\n","a3a5e18b":"# check for any missing values if there is \n# convert all missing values in specified column to median\ndf.isnull().values.any()","9fb7e930":"# now drop all redundant record \n# all duplicates rows will be dropped\ndf.drop_duplicates(keep = False, inplace = True)\ndf.shape\n# supposely 1854 duplicate records were dropped ","e2d92ecc":"Counter(df['Class'])\n# 282493 cases of non-fraud\n# 460 cases of fraud","4c0b1352":"# check the distribution of Fraud and Non-fraud \ncount = pd.value_counts(df['Class'], sort = True)\ncount.plot(kind='bar', rot=0)\nplt.title('Transaction Distribution Class')\nlabels = ['Normal', 'Fraud']\nplt.xticks(range(2), labels)\nplt.xlabel('Class')\nplt.ylabel('Transactions');","5d155621":"# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\ndef to_xy(df, target):\n    result = []\n    for x in df.columns:\n        if x != target:\n            result.append(x)\n    # find out the type of the target column. \n    target_type = df[target].dtypes\n    target_type = target_type[0] if isinstance(target_type, collections.Sequence) else target_type\n    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n    if target_type in (np.int64, np.int32):\n        # Classification\n        dummies = pd.get_dummies(df[target])\n        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n    else:\n        # Regression\n        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n    \ndef encode_text_index(df, name):\n    le = preprocessing.LabelEncoder()\n    df[name] = le.fit_transform(df[name])\n    return le.classes_\n\noutcome = encode_text_index(df, 'Class')","d2000856":"x,y = to_xy(df, 'Class')\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 42)","3bc2b2e5":"y.shape","84ee040b":"model = Sequential()\nmodel.add(Dense(50, input_dim = x.shape[1], activation='relu'))\nmodel.add(Dense(25, activation='relu'))\nmodel.add(Dense(y.shape[1], activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n#class weight provides bias toward the minority which create a more balance dataset\nclass_weight = class_weight.compute_class_weight('balanced', np.unique(outcome), outcome)\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto')\nmodel.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor], epochs=100,verbose=1, class_weight=class_weight)\n","7eb42b3d":"pred = model.predict(x)\n\npredict_classes = np.argmax(pred,axis=1)\n\ntrue_classes = np.argmax(y,axis=1)\n\nprint(\"Predictions: {}\".format(predict_classes))\nprint(\"True: {}\".format(true_classes))\n\n","45c022d5":"print(outcome[predict_classes[0:1000]])","34dc2285":"#For all of the class predictions, what percent were correct?  \ny_true = np.argmax(y_test[:], axis=1)\npred = model.predict(x_test[:])\npred = np.argmax(pred, axis=1)\n\ncorrect = metrics.f1_score(true_classes, predict_classes, average=\"weighted\")\nprint(\"F1 Score: {}\".format(correct))","3ce9bb6f":"\n# Plot a confusion matrix.\n# cm is the confusion matrix, names are the names of the classes.\ndef plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(names))\n    plt.xticks(tick_marks, names, rotation=45)\n    plt.yticks(tick_marks, names)\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n# Compute confusion matrix\ncm = confusion_matrix(y_true, pred)\nprint(cm)\nprint('Plotting confusion matrix')\n\nplt.figure()\nplot_confusion_matrix(cm, outcome)\nplt.show()\n\nprint(classification_report(y_true, pred))","2a8e08b9":"## Conclusion:\n* With neural network I was able to bring the accuracy of predicting fraudulent charges to credit card up to 99.75%","9d657650":"### Since this dataset is imbalanced, it is more accurate to use F1 score","bb8ff65f":"### Importing data from kaggle","334d36cd":"### Also testing using the Confusion Matrix","8137a085":"### Predict the performance of the model","8d7faefa":"### Split x and y into training and testing set\n#### 80% training 20% testing","dd134ea5":"### Creating a fully connected neural network\n* 3 dense layers with softmax as activation\n* use categorical_crossentropy since it is a categorical problem because of the (0,1) output\n* EarlyStopping is use to avoid overfitting","e0b03b3a":"1. ## My first submission with machine learning + neural network"}}