{"cell_type":{"fb5dec3e":"code","8a6629f7":"code","0f7c9ab6":"code","0c8fbd42":"code","6963a660":"code","2b55e9b7":"code","d9f3a5e3":"code","c725ddf6":"code","7fd1a4d6":"code","daaa0326":"code","27fde0cb":"code","fae0d956":"code","4c0138b5":"code","78c4301b":"code","d716c95b":"code","0c73623e":"code","42f76d46":"code","caa7e2f0":"code","beac9069":"code","a97156b2":"code","493788ee":"code","4f58f87b":"code","6a8af6e8":"code","6fe9d797":"code","5fb19ee9":"code","bd22cfaf":"code","1db538b8":"code","ea2362d6":"code","17e35946":"code","379368a2":"code","96a69fa7":"code","1168397d":"code","9a837713":"code","70a50a4b":"code","41761e1a":"code","b0a380fb":"code","73666794":"code","a2067e7f":"code","78dc8388":"code","b1060e43":"code","50ed44d9":"code","830a5e1d":"code","59cda5b4":"code","78b4f831":"code","24454d37":"code","950a2546":"code","da2c997b":"code","be739dc0":"code","7c631402":"code","21c25895":"code","72a0098a":"code","ba159714":"code","fade5607":"code","5f144122":"code","c72ad4cb":"code","f767ff9e":"code","3f1bece5":"code","e575592a":"code","8fa6d047":"code","95e0e1d3":"code","3d0bf04e":"code","89d78be7":"code","7501f5e9":"code","22a918ea":"code","30428fa9":"code","85d014f8":"code","f1edf6e3":"code","98642329":"markdown","5b7c5d08":"markdown","5f891fcd":"markdown","91f93a6c":"markdown","b1ed5f1b":"markdown","c6a23320":"markdown","8e288116":"markdown","31911769":"markdown","d58ed3c8":"markdown","a8443445":"markdown","431dbf16":"markdown","b34ba70d":"markdown","5adffaa2":"markdown","d54a955e":"markdown","dfbe9fa1":"markdown","ec0ae4bd":"markdown","dc398584":"markdown","cd89f84c":"markdown","048b25e1":"markdown","15c551c8":"markdown","226c960e":"markdown","e9bcb0cd":"markdown","71f7dd94":"markdown","96170356":"markdown","e6126083":"markdown","6dd1824f":"markdown","b3e536cd":"markdown","05cbbc2c":"markdown","30da6a13":"markdown","7d57f7eb":"markdown","b0006697":"markdown","5547b340":"markdown","64839b2a":"markdown","fe66b96f":"markdown","5cf6313a":"markdown","e457a6db":"markdown","f2d8b2d5":"markdown","19fce2bb":"markdown","b4f4b69c":"markdown","ca262a36":"markdown","ffa1fed2":"markdown","fbf79fa4":"markdown","90679133":"markdown","c8856d9b":"markdown","677f6a31":"markdown","c6b2c177":"markdown","76fa3146":"markdown","a7853bea":"markdown","4fc25696":"markdown","908e949d":"markdown","29e1366a":"markdown","262bec59":"markdown","afe0a6dc":"markdown","6e3601e3":"markdown","b9624fba":"markdown","d79a11ef":"markdown","f580371f":"markdown","cf86ffde":"markdown","b732803a":"markdown","38d26d04":"markdown","553d6df6":"markdown","96b4ee6e":"markdown","85515381":"markdown"},"source":{"fb5dec3e":"import pandas as pd\n\n# Leitura dos dataframes dos arquivos csv\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')","8a6629f7":"train_data.head()","0f7c9ab6":"test_data.head()","0c8fbd42":"import matplotlib.pyplot as plt\n\nlabels=train_data['benign_malignant'].value_counts().index\nvalues=train_data['benign_malignant'].value_counts().values\n\nplt.title('N\u00famero de exemplos de cada classe')\nnclasses = plt.bar(labels, values)\nnclasses[0].set_color('tab:orange')\nplt.show()\n\nprint(\"N\u00famero de exemplos benignos: {}\".format(values[0]))\nprint(\"N\u00famero de exemplos malignos: {}\".format(values[1]))","6963a660":"import cv2\nimport numpy as np\n\nbenign_samples = train_data[train_data['benign_malignant']=='benign'].sample(20)\n\nfig, ax = plt.subplots(5,4, figsize=(10,8))\n\nfor i in range(len(benign_samples)):\n    img=cv2.imread(str(\"train\/\" + benign_samples['image_name'].iloc[i]+'.jpg'))\n    img = cv2.resize(img, (224,224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    ax[i\/\/4, i%4].imshow(img)\n    ax[i\/\/4, i%4].axis('off')\n\nfig.suptitle('Imagens de amostras benignas', fontsize=22)       \nplt.show()","2b55e9b7":"malignant_samples = train_data[train_data['benign_malignant']=='benign'].sample(20)\nfig, ax = plt.subplots(5,4, figsize=(10,8))\n\nfor i in range(len(malignant_samples)):\n    img=cv2.imread(str(\"train\/\" + malignant_samples['image_name'].iloc[i]+'.jpg'))\n    img = cv2.resize(img, (224,224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    ax[i\/\/4, i%4].imshow(img)\n    ax[i\/\/4, i%4].axis('off')\n        \nfig.suptitle('Imagens de amostras malignas', fontsize=22)       \nplt.show()","d9f3a5e3":"# Imports\nimport pandas as pd\nimport numpy as np\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\n\n\nfrom tensorflow.keras.metrics import TruePositives\nfrom tensorflow.keras.metrics import FalsePositives\nfrom tensorflow.keras.metrics import TrueNegatives\nfrom tensorflow.keras.metrics import FalseNegatives\nfrom tensorflow.keras.metrics import BinaryAccuracy\nfrom tensorflow.keras.metrics import Precision\nfrom tensorflow.keras.metrics import Recall\nfrom tensorflow.keras.metrics import AUC\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.metrics import roc_auc_score","c725ddf6":"# Leitura dos dataframes dos arquivos csv\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\n# Adicionando a extens\u00e3o aos nomes das imagens\ntrain_data['image_name'] = train_data['image_name'].astype(str)+\".jpg\"\ntest_data['image_name'] = test_data['image_name'].astype(str)+\".jpg\"","7fd1a4d6":"image_height = 32\nimage_width = 32\nbatch_size = 32\n\n# Carregando as imagens de treinamento com ImageDataGenerator\nimage_datagen = ImageDataGenerator(rescale = 1.\/255,          # normaliza valores dos pixels da imagem entre 0-1\n                                   validation_split = 0.3)    # divide os dados do dataset em uma propor\u00e7\u00e3o de treinamento e valida\u00e7\u00e3o\n\n\ntrain_generator = image_datagen.flow_from_dataframe(dataframe=train_data,                   # dataframe com dados da imagem\n                                                    directory=\"train\",                      # diret\u00f3rio com as imagens\n                                                    x_col=\"image_name\",                     # nome da coluna do dataframe com os nomes das imagens\n                                                    y_col=\"benign_malignant\",               # nome da coluna do dataframe com a especifica\u00e7\u00e3o das classes\n                                                    class_mode=\"binary\",                    # modo bin\u00e1rio, ir\u00e1 selecionar as imagens em duas classes\n                                                    target_size=(image_height,image_width), # tamanho das imagens de treinamento\n                                                    batch_size=batch_size,                  # quantidade de imagens por pacote\n                                                    subset=\"training\",                      # subset de treinamento ou valida\u00e7\u00e3o\n                                                    color_mode=\"rgb\")                       # modo de carregamento da imagem em 3 canais RGB\n\nvalidation_generator = image_datagen.flow_from_dataframe(dataframe=train_data,\n                                                         directory=\"train\",\n                                                         x_col=\"image_name\",\n                                                         y_col=\"benign_malignant\",\n                                                         class_mode=\"binary\",\n                                                         target_size=(image_height,image_width),\n                                                         batch_size=batch_size,\n                                                         subset=\"validation\",\n                                                         color_mode=\"rgb\")\n\n","daaa0326":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(7,7), input_shape=(32,32,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(units = 100, activation = 'relu'))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\nmodel.summary()","27fde0cb":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'), \n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]","fae0d956":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = METRICS)","4c0138b5":"early_stopping = EarlyStopping(\n    monitor='val_auc', \n    verbose=1,\n    patience=3,\n    mode='max',\n    restore_best_weights=True)","78c4301b":"# Fazer o Treinamento\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = validation_generator.n\/\/validation_generator.batch_size\n\nmodel.fit(train_generator,\n          steps_per_epoch=STEP_SIZE_TRAIN,\n          validation_data=validation_generator,\n          validation_steps=STEP_SIZE_VALID,\n          epochs=50,\n          callbacks=early_stopping,\n          workers = 16)\n\nmodel.save_weights('simple_model_weights.h5')","d716c95b":"validation_predictions = model.predict(validation_generator,\n                                       verbose=1,\n                                       workers=16)","0c73623e":"val_auc = roc_auc_score(y_true = validation_generator.classes, y_score=validation_predictions)\nprint(val_auc)","42f76d46":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_confusion_matrix(y_true, y_pred, classes, title):\n    acc = accuracy_score(y_true, y_pred)\n    title = title + \" (Acur\u00e1cia: \" + str(\"{:10.4f}\".format(acc)) + \")\"\n\n    cm = confusion_matrix(y_true, y_pred, normalize='true')\n    cm_df = pd.DataFrame(cm, index = classes, columns = classes)\n    plt.figure(figsize=(5.5,4))\n    sns.heatmap(cm_df, annot=True, cmap=\"YlGnBu\")\n    plt.title(title)\n    plt.ylabel('Label verdadeira')\n    plt.xlabel('Label predita')\n    plt.show()\n","caa7e2f0":"# Plota a matriz de confus\u00e3o dos dados de valida\u00e7\u00e3o\nplot_confusion_matrix(validation_generator.classes,\n                      (validation_predictions>0.5).astype(int),\n                      ['benign','malignant'], \"Matriz de confus\u00e3o\")","beac9069":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(dataframe=test_data,\n                                                  directory=\"test\",\n                                                  x_col=\"image_name\",\n                                                  y_col=None,\n                                                  class_mode=None,\n                                                  target_size=(image_height,image_width),\n                                                  batch_size=batch_size)\n\n# Realiza predi\u00e7\u00e3o\npredictions = model.predict(test_generator,\n                            verbose=1,\n                            workers=16)","a97156b2":"submission = pd.DataFrame(test_data['image_name'].str.replace(r'.jpg', ''))\nsubmission['target']=predictions\n\n# Cria arquivo de submiss\u00e3o\nsubmission.to_csv('simple_model_submission.csv',index=False)","493788ee":"# Carregamento das imagens\n\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\ntrain_data['image_name'] = train_data['image_name'].astype(str)+\".jpg\"\ntest_data['image_name'] = test_data['image_name'].astype(str)+\".jpg\"\n\nbatch_size = 16       # Tamanho do pacote\nimage_height = 224    # Altura da imagem\nimage_width = 224     # Largura da imagem\n\n# Realiza as augmenta\u00e7\u00f5es nas imagens\nimage_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   validation_split = 0.3)\n\ntrain_generator = image_datagen.flow_from_dataframe(dataframe=train_data,\n                                                    directory=\"train\",\n                                                    x_col=\"image_name\",\n                                                    y_col=\"benign_malignant\",\n                                                    class_mode=\"binary\",\n                                                    target_size=(image_height,image_width),\n                                                    batch_size=batch_size,\n                                                    subset=\"training\",\n                                                    color_mode=\"rgb\")\n\nvalidation_generator = image_datagen.flow_from_dataframe(dataframe=train_data,\n                                                         directory=\"train\",\n                                                         x_col=\"image_name\",\n                                                         y_col=\"benign_malignant\",\n                                                         class_mode=\"binary\",\n                                                         target_size=(image_height,image_width),\n                                                         batch_size=batch_size,\n                                                         subset=\"validation\",\n                                                         color_mode=\"rgb\")","4f58f87b":"# Cria\u00e7\u00e3o do modelo\n\nmodel = Sequential()\nmodel.add(Conv2D(input_shape=(image_height,image_width,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=1, activation=\"softmax\"))\nmodel.summary()\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = METRICS)","6a8af6e8":"# Realiza treinamento\n\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = validation_generator.n\/\/validation_generator.batch_size\n\nmodel.fit(train_generator,\n          steps_per_epoch=STEP_SIZE_TRAIN,\n          validation_data=validation_generator,\n          validation_steps=STEP_SIZE_VALID,\n          epochs=50,\n          callbacks=early_stopping,\n          workers = 16)\n\nmodel.save_weights('vgg_model_weights.h5')","6fe9d797":"validation_predictions = model.predict(validation_generator,\n                                       verbose=1,\n                                       workers=16)","5fb19ee9":"val_auc = roc_auc_score(y_true = validation_generator.classes, y_score=validation_predictions)\nprint(val_auc)","bd22cfaf":"# Plota a matriz de confus\u00e3o dos dados de valida\u00e7\u00e3o\nplot_confusion_matrix(validation_generator.classes,\n                      (validation_predictions>0.5).astype(int),\n                      ['benign','malignant'], \"Matriz de confus\u00e3o\")","1db538b8":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(dataframe=test_data,\n                                                  directory=\"test\",\n                                                  x_col=\"image_name\",\n                                                  y_col=None,\n                                                  class_mode=None,\n                                                  target_size=(image_height,image_width),\n                                                  batch_size=batch_size)\n\npredictions = model.predict(test_generator,\n                            verbose=1,\n                            workers=16)\n\n\nsubmission = pd.DataFrame(test_data['image_name'].str.replace(r'.jpg', ''))\nsubmission['target'] = predictions\n\nsubmission.to_csv('vgg_model_submission.csv',index=False)","ea2362d6":"# Carregamento das imagens\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\ntrain_data['image_name'] = train_data['image_name'].astype(str)+\".jpg\"\ntest_data['image_name'] = test_data['image_name'].astype(str)+\".jpg\"\n\n\nbatch_size = 16       # Tamanho do pacote\nimage_height = 224    # Altura da imagem\nimage_width = 224     # Largura da imagem\n\n# Realiza as augmenta\u00e7\u00f5es nas imagens\nimage_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   validation_split = 0.3,\n                                   rotation_range=30,      # Rotaciona aleat\u00f3riamente imagens em 30 graus\n                                   zoom_range=0.15,        # Zoom aleat\u00f3rio\n                                   width_shift_range=0.2,  # Shift de largura aleat\u00f3rio\n                                   height_shift_range=0.2, # Shift de altura aleat\u00f3rio\n                                   horizontal_flip=True)   # Flip horizontal aleat\u00f3rio\n\ntrain_generator = image_datagen.flow_from_dataframe(dataframe=train_data,\n                                                    directory=\"train\",\n                                                    x_col=\"image_name\",\n                                                    y_col=\"benign_malignant\",\n                                                    class_mode=\"binary\",\n                                                    target_size=(image_height,image_width),\n                                                    batch_size=batch_size,\n                                                    subset=\"training\",\n                                                    color_mode=\"rgb\")\n\nvalidation_generator = image_datagen.flow_from_dataframe(dataframe=train_data,\n                                                         directory=\"train\",\n                                                         x_col=\"image_name\",\n                                                         y_col=\"benign_malignant\",\n                                                         class_mode=\"binary\",\n                                                         target_size=(image_height,image_width),\n                                                         batch_size=batch_size,\n                                                         subset=\"validation\",\n                                                         color_mode=\"rgb\")","17e35946":"# Cria\u00e7\u00e3o do modelo\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n# load model\n\nmodel = Sequential()\nmodel.add(ResNet50(input_shape=(image_height, image_width, 3), classes=2,include_top=False, weights=None))\nmodel.add(Flatten())\nmodel.add(Dense(units=1, activation=\"sigmoid\"))\n\n\n# summarize the model\nmodel.summary()","379368a2":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = METRICS)","96a69fa7":"from sklearn.utils import class_weight\n\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_generator.classes),\n                                                 train_generator.classes)\n\nclass_weights = dict(zip(np.unique(train_generator.classes), class_weights))\nprint(class_weights)","1168397d":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = validation_generator.n\/\/validation_generator.batch_size\n\nmodel.fit(train_generator,\n          steps_per_epoch=STEP_SIZE_TRAIN,\n          validation_data=validation_generator,\n          validation_steps=STEP_SIZE_VALID,\n          epochs=50,\n          callbacks=early_stopping,\n          workers = 16,\n          class_weight=class_weights)\n\nmodel.save_weights('class_weights_balanced_weights.h5')","9a837713":"validation_predictions = model.predict(validation_generator,\n                                       verbose=1,\n                                       workers=16)","70a50a4b":"val_auc = roc_auc_score(y_true = validation_generator.classes, y_score=validation_predictions)\nprint(val_auc)","41761e1a":"# Plota a matriz de confus\u00e3o dos dados de valida\u00e7\u00e3o\nplot_confusion_matrix(validation_generator.classes,\n                      (validation_predictions>0.5).astype(int),\n                      ['benign','malignant'], \"Matriz de confus\u00e3o\")","b0a380fb":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(dataframe=test_data,\n                                                  directory=\"test\",\n                                                  x_col=\"image_name\",\n                                                  y_col=None,\n                                                  class_mode=None,\n                                                  target_size=(image_height,image_width),\n                                                  batch_size=batch_size)\n\npredictions = model.predict(test_generator,\n                            verbose=1,\n                            workers=16)\n\n\nsubmission = pd.DataFrame(test_data['image_name'].str.replace(r'.jpg', ''))\nsubmission['target'] = predictions\n\nsubmission.to_csv('class_weight_balanced_submission.csv',index=False)","73666794":"# Leitura dos dataframes dos arquivos csv\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\n# Adicionando a extens\u00e3o aos nomes das imagens\ntrain_data['image_name'] = train_data['image_name'].astype(str)+\".jpg\"\ntest_data['image_name'] = test_data['image_name'].astype(str)+\".jpg\"\n","a2067e7f":"# Carregamento das imagens\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\ntrain_data['image_name'] = train_data['image_name'].astype(str)+\".jpg\"\ntest_data['image_name'] = test_data['image_name'].astype(str)+\".jpg\"\n\n\nbatch_size = 32       # Tamanho do pacote\nimage_height = 224    # Altura da imagem\nimage_width = 224     # Largura da imagem\n\n# Realiza as augmenta\u00e7\u00f5es nas imagens\nimage_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   rotation_range=30,      \n                                   zoom_range=0.15,        \n                                   width_shift_range=0.2,  \n                                   height_shift_range=0.2, \n                                   horizontal_flip=True)   \n\n# Nesse treinamento, todas as imagens ser\u00e3o usadas como dataset de treinamento\ntrain_generator = image_datagen.flow_from_dataframe(dataframe=train_data,\n                                                    directory=\"train\",\n                                                    x_col=\"image_name\",\n                                                    y_col=\"benign_malignant\",\n                                                    class_mode=\"binary\",\n                                                    target_size=(image_height,image_width),\n                                                    batch_size=batch_size, subset=\"training\",\n                                                    color_mode=\"rgb\")","78dc8388":"import efficientnet.tfkeras as efn\n# load model\n\nmodel = Sequential([\n        efn.EfficientNetB0(\n            input_shape=(image_height, image_width, 3),\n            weights='imagenet',\n            include_top=False\n        ),\n        GlobalAveragePooling2D(),\n        Dense(1, activation='sigmoid')\n    ])\n\n\n\n# summarize the model\nmodel.summary()","b1060e43":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = METRICS)","50ed44d9":"early_stopping = EarlyStopping(\n    monitor='auc', \n    verbose=1,\n    patience=3,\n    mode='max',\n    restore_best_weights=True)","830a5e1d":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\n\nmodel.fit(train_generator,\n          steps_per_epoch=STEP_SIZE_TRAIN,\n          epochs=50,\n          callbacks=early_stopping,\n          workers = 16)","59cda5b4":"model.save_weights('tranfer_learning_weights.h5')","78b4f831":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(dataframe=test_data,\n                                                  directory=\"test\",\n                                                  x_col=\"image_name\",\n                                                  y_col=None,\n                                                  class_mode=None,\n                                                  target_size=(image_height,image_width),\n                                                  batch_size=batch_size)\n\npredictions = model.predict(test_generator,\n                            verbose=1,\n                            workers=16)\n\n\nsubmission = pd.DataFrame(test_data['image_name'].str.replace(r'.jpg', ''))\nsubmission['target'] = predictions\n\nsubmission.to_csv('effnet3_model_submission.csv',index=False)","24454d37":"# Imports\nfrom pathlib import Path\n\nfrom tensorflow.data import Dataset\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import concatenate\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array","950a2546":"class MixedDataGenerator(utils.Sequence):\n\n    def __init__(self, values: pd.DataFrame,\n                images: pd.Series, directory: str, labels: pd.Series=None,\n                target_size: tuple=(32,32), batch_size: int=32, shuffle: bool=True):\n        'Inicializa\u00e7\u00e3o'\n\n        self.values = values\n        self.labels = labels\n        self.images = images\n        self.directory = Path(directory)\n        self.target_size = target_size\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.num_files = images.count()\n        self.columns = self.values.columns\n        self.indices = None\n        self.values_gen = ImageDataGenerator()\n        self.labels_indices = None\n        if labels is not None:\n            self.labels_indices = list(self.labels.unique())\n\n        self.on_epoch_end()\n\n    \n    def __len__(self):\n        'Indica a quantidades de pacotes por \u00e9pocas'\n\n        return (self.num_files + self.batch_size - 1) \/\/ self.batch_size\n\n    \n    def __getitem__(self, index):\n        'Gera um pacote de dados'\n\n        # Gera os \u00edndices do pacote\n        if index >= len(self):\n            raise ValueError('Asked to retrieve element {index}, '\n                             'but the Sequence '\n                             'has length {length}'.format(index=index,\n                                                          length=len(self)))\n        indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n        x_images = [self.__process_image(image) for image in self.images.loc[indices]]\n        images = np.array(x_images)\n        x_values = self.values.loc[indices]\n        values = np.array(x_values)\n        if self.labels is not None:\n            y_labels = [self.labels_indices.index(label) for label in self.labels.loc[indices]]\n            labels = np.eye(len(self.labels_indices))[y_labels]\n        # Gera os dados\n        if self.labels is not None:\n            return [images, values], labels\n        else:\n            return [images, values]\n\n\n    def on_epoch_end(self):\n        'Atualiza os \u00edndices ap\u00f3s cada \u00e9poca'\n\n        self.indices = np.arange(len(self.values))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n    \n    def __process_image(self, image_name):\n        'L\u00ea a imagem da mem\u00f3ria'\n\n        image = load_img(Path(self.directory, image_name), target_size=self.target_size)\n        image = self.values_gen.apply_transform(image, dict(rescale=1.\/255))            # normaliza valores dos pixels da imagem entre 0-1\n        array = img_to_array(image)\n        image.close()\n\n        return array","da2c997b":"def treatNan(data):\n    # remove nan na coluna 'sex'\n    data = data[data.sex == data.sex]\n    # remove nan na coluna 'age_approx'\n    data = data[data.age_approx == data.age_approx]\n\n    # substitui nan na coluna 'anatom_site_general_challenge' pelo atributo 'unknown'\n    data.anatom_site_general_challenge.fillna(value='unknown', inplace=True)\n\n    return data","be739dc0":"# Leitura dos dataframes dos arquivos csv\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\n# Adicionando a extens\u00e3o aos nomes das imagens\ntrain_data['image_name'] = train_data['image_name'].astype(str)+\".jpg\"\ntest_data['image_name'] = test_data['image_name'].astype(str)+\".jpg\"\n\ntrain_data = treatNan(train_data)\ntest_data = treatNan(test_data)\n\ntrain_data.head()","7c631402":"test_data.head()","21c25895":"# Separa os dados em treinamento e valida\u00e7\u00e3o mantendo a propor\u00e7\u00e3o entre classes 'benign' e 'malignant'\ntrain_data_ben = train_data[train_data.benign_malignant == 'benign']\ntrain_data_mal = train_data[train_data.benign_malignant == 'malignant']\n\nvalid_data_ben = train_data_ben.sample(frac=0.3, random_state=1)\nvalid_data_mal = train_data_mal.sample(frac=0.3, random_state=1)\n\nvalid_data = valid_data_ben.append(valid_data_mal)\n\ntrain_data.drop(index=valid_data.index)\n\nvalid_data = valid_data.reindex(np.random.permutation(valid_data.index))\nvalid_data.reset_index(drop=True, inplace=True)\ntrain_data.reset_index(drop=True, inplace=True)","72a0098a":"# R\u00f3tulos dos dados\ny_train = train_data.benign_malignant\ny_valid = valid_data.benign_malignant\n\n# Dados com atributos para o treinamento\nX_train = train_data[['sex', 'age_approx', 'anatom_site_general_challenge']]\nX_valid = valid_data[['sex', 'age_approx', 'anatom_site_general_challenge']]","ba159714":"train_sex = X_train['sex'].str.get_dummies()\ntrain_anatom = X_train['anatom_site_general_challenge'].str.get_dummies()\n\nvalid_sex = X_valid['sex'].str.get_dummies()\nvalid_anatom = X_valid['anatom_site_general_challenge'].str.get_dummies()\n\nX_train = X_train.join([train_sex, train_anatom])\nX_valid = X_valid.join([valid_sex, valid_anatom])\n\nX_train.drop(columns=['sex', 'anatom_site_general_challenge'], inplace=True)\nX_valid.drop(columns=['sex', 'anatom_site_general_challenge'], inplace=True)\n\ntrain_columns = X_train.columns\nvalid_columns = X_valid.columns\n\nfor column in valid_columns:\n    if column not in train_columns:\n        X_train[column] = 0\n\nfor column in train_columns:\n    if column not in valid_columns:\n        X_valid[column] = 0","fade5607":"gen_train = MixedDataGenerator(values=X_train,\n                            images=train_data['image_name'],\n                            directory='train',\n                            labels=y_train,\n                            target_size=(32, 32),\n                            batch_size=32)\ngen_valid = MixedDataGenerator(values=X_valid,\n                            images=valid_data['image_name'],\n                            directory='train',\n                            labels=y_valid,\n                            target_size=(32, 32),\n                            batch_size=32)","5f144122":"def createMLP(dimension):\n    model = Sequential()\n    model.add(Dense(units=8, input_dim=dimension, activation=\"relu\"))\n    model.add(Dense(units=4, activation=\"relu\"))\n\n    return model\n\n\ndef createCNN(shape):\n    inputImage = Input(shape=shape)\n    x = inputImage\n    x = Conv2D(filters=32, kernel_size=(7,7), activation='relu')(x)\n    x = MaxPooling2D(pool_size = (2, 2))(x)\n    x = Conv2D(filters=20, kernel_size=(3, 3), activation = 'relu')(x)\n    x = MaxPooling2D(pool_size = (2, 2))(x)\n\n    x = Flatten()(x)\n    x = Dense(units = 10, activation = 'relu')(x)\n    x = Dense(units = 4, activation = 'relu')(x)\n\n    model = Model(inputImage, x)\n\n    return model\n\n\n#Cria\u00e7\u00e3o do modelo multi-Input\nmlp = createMLP(dimension=len(X_train.columns))\ncnn = createCNN((32,32,3))","c72ad4cb":"combinedInput = concatenate([cnn.output, mlp.output])\n\nx = Dense(units=4, activation=\"relu\")(combinedInput)\nx = Dense(units=2, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=[cnn.input, mlp.input], outputs=x)\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nmodel.summary()","f767ff9e":"# Treinamento\n\nmodel.fit(gen_train,\n          epochs=4,\n          validation_data=gen_valid,\n          workers=16)\nmodel.save_weights('cnn_melanoma.h5')","3f1bece5":"# Valida\u00e7\u00e3o\n\nvalidation_predictions = model.predict(gen_valid,\n                                       verbose=1,\n                                       workers=16)\nvalidation_predictions = (validation_predictions > 0.5)","e575592a":"# Faz o classification report do modelo aplicado nos dados de valida\u00e7\u00e3o\nfrom sklearn.metrics import classification_report\nreport = classification_report(pd.get_dummies(y_valid),\n                               validation_predictions)\nprint(report)","8fa6d047":"# Mostra a matriz de confus\u00e3o dos dados de valida\u00e7\u00e3o\nplot_confusion_matrix(pd.get_dummies(y_valid).values.argmax(axis=1),\n                      validation_predictions.argmax(axis=1),['benign', 'malignant'], \"Matriz de confus\u00e3o\")","95e0e1d3":"# Teste\n\nX_test = test_data.drop(columns=['image_name', 'patient_id'])\n\ntest_sex = X_test['sex'].str.get_dummies()\ntest_anatom = X_test['anatom_site_general_challenge'].str.get_dummies()\n\nX_test = X_test.join([test_sex, test_anatom])\n\nX_test.drop(columns=['sex', 'anatom_site_general_challenge'], inplace=True)\n\ntest_columns = X_test.columns\n\nfor column in train_columns:\n    if column not in test_columns:\n        X_test[column] = 0\n\n\ngen_test = MixedDataGenerator(values=X_test,\n                            images=test_data['image_name'],\n                            directory='test',\n                            target_size=(32, 32),\n                            batch_size=32)\n\n\npredictions = model.predict(gen_test,\n                            verbose=1,\n                            workers=16)\n\n\n# predictions \u00e9 um vetor em que cada elemento \u00e9 um vetor de dois valores, j\u00e1 que temos duas classes (benigno e maligno).\n# Pega-se ent\u00e3o a probabilidade do tumor ser maligno\nsubmission = pd.DataFrame(test_data['image_name'].str.replace(r'.jpg', ''))\nsubmission['target']=predictions[:,1]\n\n# Cria arquivo de submiss\u00e3o\nsubmission.to_csv('multi_input_submission.csv',index=False)","3d0bf04e":"# Leitura dos dataframes dos arquivos csv\ntrain_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\n# Adicionando a extens\u00e3o aos nomes das imagens\ntrain_data['image_name'] = train_data['image_name'].astype(str)+\".jpg\"\ntest_data['image_name'] = test_data['image_name'].astype(str)+\".jpg\"\n\ntrain_data = treatNan(train_data)\ntest_data = treatNan(test_data)\n\n\n# Separa os dados em treinamento e valida\u00e7\u00e3o mantendo a propor\u00e7\u00e3o entre classes 'benign' e 'malignant'\ntrain_data_ben = train_data[train_data.benign_malignant == 'benign']\ntrain_data_mal = train_data[train_data.benign_malignant == 'malignant']\n\nvalid_data_ben = train_data_ben.sample(frac=0.3, random_state=1)\nvalid_data_mal = train_data_mal.sample(frac=0.3, random_state=1)\n\nvalid_data = valid_data_ben.append(valid_data_mal)\n\ntrain_data.drop(index=valid_data.index)\n\nvalid_data = valid_data.reindex(np.random.permutation(valid_data.index))\nvalid_data.reset_index(drop=True, inplace=True)\ntrain_data.reset_index(drop=True, inplace=True)\n\n\n# R\u00f3tulos dos dados\ny_train = train_data.benign_malignant\ny_valid = valid_data.benign_malignant\n\n# Dados com atributos para o treinamento\nX_train = train_data[['sex', 'age_approx', 'anatom_site_general_challenge']]\nX_valid = valid_data[['sex', 'age_approx', 'anatom_site_general_challenge']]\n\n\ntrain_sex = X_train['sex'].str.get_dummies()\ntrain_anatom = X_train['anatom_site_general_challenge'].str.get_dummies()\n\nvalid_sex = X_valid['sex'].str.get_dummies()\nvalid_anatom = X_valid['anatom_site_general_challenge'].str.get_dummies()\n\nX_train = X_train.join([train_sex, train_anatom])\nX_valid = X_valid.join([valid_sex, valid_anatom])\n\nX_train.drop(columns=['sex', 'anatom_site_general_challenge'], inplace=True)\nX_valid.drop(columns=['sex', 'anatom_site_general_challenge'], inplace=True)\n\ntrain_columns = X_train.columns\nvalid_columns = X_valid.columns\n\nfor column in valid_columns:\n    if column not in train_columns:\n        X_train[column] = 0\n\nfor column in train_columns:\n    if column not in valid_columns:\n        X_valid[column] = 0\n\ngen_train = MixedDataGenerator(values=X_train,\n                            images=train_data['image_name'],\n                            directory='train',\n                            labels=y_train,\n                            target_size=(128,128),\n                            batch_size=32)\ngen_valid = MixedDataGenerator(values=X_valid,\n                            images=valid_data['image_name'],\n                            directory='train',\n                            labels=y_valid,\n                            target_size=(128,128),\n                            batch_size=32)","89d78be7":"#Cria\u00e7\u00e3o do modelo multi-Input\n\nmlp = createMLP(dimension=len(X_train.columns))\ncnn = createCNN((128,128,3))\n\ncombinedInput = concatenate([cnn.output, mlp.output])\n\nx = Dense(units=4, activation=\"relu\")(combinedInput)\nx = Dense(units=2, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=[cnn.input, mlp.input], outputs=x)\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [AUC()])","7501f5e9":"from sklearn.utils import class_weight\n\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)\n\nclass_weights = dict(zip([0,1], class_weights))","22a918ea":"# Treinamento\nmodel.fit(gen_train,\n          epochs=4,\n          validation_data=gen_valid,\n          class_weight=class_weights,\n          workers=16)\nmodel.save_weights('cnn_melanoma.h5')","30428fa9":"# Valida\u00e7\u00e3o\n\nvalidation_predictions = model.predict(gen_valid,\n                                       verbose=1,\n                                       workers=16)","85d014f8":"validation_predictions = (validation_predictions > 0.5)\n\n\n# class_labels = list(validation_generator.class_indices.keys())\n# validation_true = validation_generator.classes\n\n# Faz o classification report do modelo aplicado nos dados de valida\u00e7\u00e3o\nfrom sklearn.metrics import classification_report\nreport = classification_report(pd.get_dummies(y_valid),\n                               validation_predictions)\nprint(report)\n\n\n# Plota a matriz de confus\u00e3o dos dados de valida\u00e7\u00e3o\nplot_confusion_matrix(pd.get_dummies(y_valid).values.argmax(axis=1),\n                      validation_predictions.argmax(axis=1),['benign', 'malignant'], \"Matriz de confus\u00e3o\")","f1edf6e3":"# Teste\n\nX_test = test_data.drop(columns=['image_name', 'patient_id'])\n\ntest_sex = X_test['sex'].str.get_dummies()\ntest_anatom = X_test['anatom_site_general_challenge'].str.get_dummies()\n\nX_test = X_test.join([test_sex, test_anatom])\n\nX_test.drop(columns=['sex', 'anatom_site_general_challenge'], inplace=True)\n\ntest_columns = X_test.columns\n\nfor column in train_columns:\n    if column not in test_columns:\n        X_test[column] = 0\n\n\ngen_test = MixedDataGenerator(values=X_test,\n                            images=test_data['image_name'],\n                            directory='test',\n                            target_size=(128, 128),\n                            batch_size=32)\n\n\npredictions = model.predict(gen_test,\n                            verbose=1,\n                            workers=16)\n\n\n# predictions \u00e9 um vetor em que cada elemento \u00e9 um vetor de dois valores, j\u00e1 que temos duas classes (benigno e maligno).\n# Pega-se ent\u00e3o a probabilidade do tumor ser maligno\nsubmission = pd.DataFrame(test_data['image_name'].str.replace(r'.jpg', ''))\nsubmission['target']=predictions[:,1]\n\n# Cria arquivo de submiss\u00e3o\nsubmission.to_csv('multi_input_submission2.csv',index=False)","98642329":"As colunas de r\u00f3tulos e atributos foram separadas. Foram selecioandos apenas os atributos que geram informa\u00e7\u00e3o para o modelo, ou seja, exclu\u00edmos as colunas 'image_name' e 'patient_id', e que tamb\u00e9m constam nos dados de teste. Assim, apenas as colunas 'sex', 'age_approx' e 'anatom_site_general_challenge' foram selecionadas.","5b7c5d08":"Ap\u00f3s a submiss\u00e3o dos resultados, o score obtido foi ligeiramente maior. Contudo, a diferen\u00e7a n\u00e3o foi significativa, o que nos faz perceber que o uso de pesos para as classes ainda n\u00e3o foi suficiente para compensar o grande desbalanceamento da base de dados.\n\nAl\u00e9m disso, comparando o modelo multi-input com a CNN, observamos que utilizar as caracter\u00edsticas dos pacientes contidas no dataframe n\u00e3o gerou um ganho de informa\u00e7\u00e3o suficiente a ponto de melhorar significativamente a capacidade de classifica\u00e7\u00e3o do modelo para essa base de dados.","5f891fcd":"Para esse teste usaremos uma outra arquitetura de rede famosa, a [ResNet](https:\/\/towardsdatascience.com\/an-overview-of-resnet-and-its-variants-5281e2f56035). A ela, adicionamos uma camada densa com um neur\u00f4nio que dar\u00e1 a probabilidade em estudo.","91f93a6c":"## Construindo um simples modelo\n\nA primeira submiss\u00e3o para a competi\u00e7\u00e3o tinha o objetivo de testar um modelo simples e verificar aproximadamente quanto tempo demoraria para a sua execu\u00e7\u00e3o, com isso avaliar\u00edamos a viabilidade de lidar com essa base t\u00e3o extensa.","b1ed5f1b":"Para compilar o nosso modelo, escolhemos o otimizador [Adam](https:\/\/machinelearningmastery.com\/adam-optimization-algorithm-for-deep-learning\/) e a func\u00e3o de loss [binary_crossentropy](https:\/\/keras.io\/api\/losses\/probabilistic_losses\/#binarycrossentropy-class).\n\nPara avaliar o nosso modelo durante o treinamento, iremos observar:\n\n* True Positives: amostras com cancer corretamente classificadas.\n* False Positives: amostras sem cancer erroneamente classificadas.\n* True Negatives: amostras sem cancer corretamente classificadas.\n* False Negatives: amostras com cancer erroneamente classificadas.\n* Binary Accuracy: Acur\u00e1cia do modelo.\n* Precision: Precis\u00e3o do modelo.\n* Recall: Revoca\u00e7\u00e3o do modelo.\n* AUC: \u00c1rea aproximada abaixo da curva ROC","c6a23320":"### Cria\u00e7\u00e3o da rede neural multi-input\n\nA rede neural multi-input consiste na concatena\u00e7\u00e3o de duas, ou mais, redes neurais para gerar uma \u00fanica sa\u00edda. Nesse caso, a nossa rede neural \u00e9 uma concatena\u00e7\u00e3o de um Multi Layer Perceptron (MLP) e uma Rede Convolucional (CNN) como \u00e9 mostrado na figura a seguir.\n\n\n<img src=\"https:\/\/drive.google.com\/uc?id=122h0V2nbJCg-UUfUNfXGFSl5aUmwHZqL\" alt=\"drawing\" width=\"400\"\/>\n\n\n","8e288116":"Primeiramente, devemos ler os arquivos .csv com as informa\u00e7\u00f5es da base.","31911769":"O arquivo de dados de teste possui quase as mesmas informa\u00e7\u00f5es que o de treinamento, exceto as \u00faltimas colunas (diagnosis, benign_malignant, target), as quais queremos inferir.","d58ed3c8":"## Tentativa de realizar o pr\u00e9-processamento da base e reduzir o desbalanceamento\n\nVimos que aumentar a complexidade do modelo n\u00e3o alterou a efic\u00e1cia em predizer os pacientes com tumor maligno.\n\nUm palpide de porque o modelo est\u00e1 enviesado \u00e9 o grande desbalanceamento da base, que tentaremos corrigir utilizando pesos para as classes. Tamb\u00e9m tentaremos melhorar o pr\u00e9-processamento das bases usando [augmentations](https:\/\/www.pyimagesearch.com\/2019\/07\/08\/keras-imagedatagenerator-and-data-augmentation\/). Dessa forma a cada \u00e9poca as imagens de treinamento e valida\u00e7\u00e3o ser\u00e3o um pouco diferentes das anteriores, adicionando uma certa aleatoriedade ao processo de treinamento.\n\n","a8443445":"Vemos que esse dataset possui as informa\u00e7\u00f5es:\n\n* image_name: Nome da imagem referente a esse exemplo de treinamento.\n* patient_id: ID do paciente.\n* sex: Sexo do paciente.\n* age_approx: Idade aproximada do paciente\n* anatom_site_general_challenge: Parte do corpo onde a foto foi tirada.\n* diagnosis: Dian\u00f3stico.\n* benign_malignant: Classifica\u00e7\u00e3o da mancha em maligna ou benigna.\n* target: 0 (benigno), 1 (maligno).","431dbf16":"Caracter\u00edsticas do arquivo de treinamento.","b34ba70d":"Como podemos perceber pela sa\u00edda do m\u00e9todo fit, as m\u00e9tricas de avalia\u00e7\u00e3o do modelo n\u00e3o mudaram com o passar das \u00e9pocas. Isso indica que o modelo n\u00e3o convergiu, isso pode ser ter sido causado pela alta quantidade de camadas, pelo grande desbalanceamento da base, pela fun\u00e7\u00e3o de loss. \n\nPelos testes realizados, mudar par\u00e2metros como fun\u00e7\u00e3o de loss, tamanho do batch das imagens e fun\u00e7\u00e3o de sa\u00edda da \u00faltima camada densa n\u00e3o foram suficientes para evitar a n\u00e3o converg\u00eancia.","5adffaa2":"Para lidar com imagens, o Keras possui a ferramenta [ImageDataGenerator](https:\/\/keras.io\/api\/preprocessing\/image\/). Essa classe foi criada para lidar com grandes bases de dados de imagens e permite um carregamento em pacotes de imagens para gerar menos impacto na mem\u00f3ria RAM do computador. Al\u00e9m disso, ainda faz o pr\u00e9-processamento das imagens, colocando-as em um determinado tamanho e podendo at\u00e9 mesmo aplicar filtros e outros m\u00e9todos de vis\u00e3o computacional.\n\nPara facilitar ainda mais, essa classe possui o m\u00e9todo [flow_from_dataframe](https:\/\/keras.io\/api\/preprocessing\/image\/#flowfromdataframe-method), que faz o carregamento das imagens por meio de dados de um dataframe pandas.\n\nNessa primeira submiss\u00e3o, escolhemos um tamanho de imagem pequeno de 32x32 pixels.","d54a955e":"A medida AUC dos dados de valida\u00e7\u00e3o deu exatamente 0.5, indicando que o modelo pode estar classificando todos os exemplos em apenas uma classe.\n","dfbe9fa1":"Finalmente, as imagens de treinamento e valida\u00e7\u00e3o forma lidas e os dados mistos forma criados.","ec0ae4bd":"Nesse caso, estranhamente todos os elementos foram classificados como malignos, confirmando a n\u00e3o converg\u00eancia do modelo.","dc398584":"Para podermos visualizar o resultado, contru\u00edmos a matriz de confus\u00e3o para os dados de valida\u00e7\u00e3o","cd89f84c":"O score oficial dessa submiss\u00e3o foi 0.500.","048b25e1":"Vemos que essa base possui um forte desbalanceamento, essa caracter\u00edstica \u00e9 muito importante e ir\u00e1 influenciar a maneira como os modelos de redes neurais ser\u00e3o treinados.","15c551c8":"Para visualizar graficamente, construimos a matriz de confus\u00e3o das predi\u00e7\u00f5es de valida\u00e7\u00e3o.","226c960e":"O score oficial dessa submiss\u00e3o foi 0.506.","e9bcb0cd":"Como podemos ver, apesar de apresentar uma alta acur\u00e1cia, o modelo n\u00e3o classificou nenhuma imagem como melanoma. Isso provavelmente se deve a simplicidade do modelo, redu\u00e7\u00e3o massiva do tamanho das imagens e ao grande desbalanceamento da base.","71f7dd94":"O score oficial dessa submiss\u00e3o foi 0.523.","96170356":"## Usando um modelo pr\u00e9-treinado como extrator de features","e6126083":"## Modelo de rede neural VGG\n\nA segunda submiss\u00e3o tinha como objetivo implementar um modelo de classifica\u00e7\u00e3o de imagem j\u00e1 testado em bases de classifica\u00e7\u00e3o famosas, uma rede neural [VGG](https:\/\/becominghuman.ai\/what-is-the-vgg-neural-network-a590caa72643).\n\nNossa implementa\u00e7\u00e3o possui uma arquitetura semelhante a VGG Network, usando v\u00e1rias camadas de convolu\u00e7\u00e3o seguidas de camadas de pooling, criando uma rede neural convolucional profunda.\n\nEssa rede ter\u00e1 como entrada imagens de 224x224 pixels.","6dd1824f":"Tamb\u00e9m \u00e9 interessante visualizar algumas das imagens de ambas as classes para verificar as caracter\u00edsticas de manchas que s\u00e3o Melanoma e manchas que n\u00e3o s\u00e3o Melanomas.","b3e536cd":"# SIIM-ISIC Melanoma Classification\n\n\n","05cbbc2c":"Caracter\u00edsticas do arquivo de teste.","30da6a13":"Os dados provenientes do arquivo 'train.csv' foram separados em treinamento e valida\u00e7\u00e3o de forma a manter a propor\u00e7\u00e3o de amostras das classes 'benign' e 'malignant' nos dois conjuntos.","7d57f7eb":"Al\u00e9m disso, como uma tentativa de compensar o desbalanceamento da base, foram definidos pesos para cada classe, utilizando a fun\u00e7\u00e3o [compute_class_weight()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.utils.class_weight.compute_class_weight.html?highlight=class_weight#sklearn.utils.class_weight.compute_class_weight) do ScikitLearn.","b0006697":"Uma estrat\u00e9gia comum nas aplica\u00e7\u00f5es de redes neurais ultimamente \u00e9 a transfer\u00eancia de aprendizado ou 'transfer learning'. Nessa estrat\u00e9gia, um modelo treinado para uma finalidade \u00e9 utilizado para tentar inferir exemplos de problemas diferentes. Em outras palavras, consiste em utilizar recursos aprendidos em um problema pr\u00e9vio e aproveit\u00e1-lo em um novo problema semelhante.\n\nA rede treinada j\u00e1 entrou em contato com v\u00e1rias imagens de v\u00e1rias classes e seus pesos j\u00e1 foram usados em alguma tarefa e trouxeram resultados satisfat\u00f3rios. As camadas de convolu\u00e7\u00e3o dessa rede j\u00e1 est\u00e3o especialistas em encontrar certos tipos de features das imagens.\n\nSendo assim, podemos utilizar tais pesos para treinar um dataset que, a principio, tem poucos dados para que seja feito um treinamento do zero ou, simplesmente, com o intuito de poupar tempo\/custo de processamento.\n\nPara fazer a transfer\u00eancia de aprendizado, usa-se apenas as camadas convolucionais da rede j\u00e1 treinada e adiciona a esse modelo um classificador. \n\nA sua base de dados ir\u00e1 passar pelas camadas convolucionais da rede treinada e na pr\u00e1tica ocorrer\u00e1 a extra\u00e7\u00e3o de features das suas imagens. O seu classificador ir\u00e1 usar essas features e tentar acertar a a classe correta.\n\nA partir dos diversos tipos de redes pr\u00e9-treinadas, \u00e9 poss\u00edvel verificar o desempenho alcan\u00e7ado por cada rede em comparativos relacionados \u00e0s suas taxas de acur\u00e1cia, como ilustrado abaixo. \n\n![texto alternativo](https:\/\/drive.google.com\/uc?id=10wTfPtfhae6DGINgY-zTzTYhGP3qNM1w)\n[Fonte](https:\/\/github.com\/tensorflow\/tpu\/tree\/master\/models\/official\/efficientnet)","5547b340":"Antes de fazer a infer\u00eancia dos dados de teste, vamos analisar o resultado nos dados de valida\u00e7\u00e3o.","64839b2a":"O score oficial dessa submiss\u00e3o foi 0.500.","fe66b96f":"Para fazer o treinamento, \u00e9 \u00fatil usar uma fun\u00e7\u00e3o de callback para parar esse treinamento quando o modelo n\u00e3o est\u00e1 mais evoluindo. Por isso, utilizaremos a fun\u00e7\u00e3o [EarlyStopping](https:\/\/keras.io\/api\/callbacks\/early_stopping\/), que ir\u00e1 acompanhar a medida AUC do dataset de valida\u00e7\u00e3o ('val_auc').","5cf6313a":"Em seguida, foi criado um modelo concatenando as sa\u00eddas do MLP e da CNN. Foram adicionadas uma camada oculta e, por fim, uma de sa\u00edda. E, finalmente, para compilar o nosso modelo, escolhemos o otimizador [Adam](https:\/\/machinelearningmastery.com\/adam-optimization-algorithm-for-deep-learning\/) e a func\u00e3o de loss [binary_crossentropy](https:\/\/keras.io\/api\/losses\/probabilistic_losses\/#binarycrossentropy-class).","e457a6db":"Nesse modelo, foi usada a \u00e1rea abaixo da curva ROC como m\u00e9trica de avalia\u00e7\u00e3o em vez da acur\u00e1cia.","f2d8b2d5":"## Avalia\u00e7\u00e3o e score\n\nQuando treinamos um modelo que ser\u00e1 usado para fazer infer\u00eancias \u00e9 essencial estabelecer quais m\u00e9tricas ser\u00e3o usadas para avali\u00e1-lo.\n\nO score oficial usado para testar as submiss\u00f5es na competi\u00e7\u00e3o \u00e9 a \u00e1rea abaixo da curva ROC das probabilidades preditas e os valores esperados.\n\n### Curva ROC e AUC\n\nA curva ROC (Curva Caracter\u00edstica de Opera\u00e7\u00e3o do Receptor) \u00e9 uma forma de representar os resultados de desempenho de um classificador baseado em par\u00e2metros de taxa de resultados \"Verdadeiro Positivo\" e \"Falso Positivo\".\n\nTemos que:\n\n>$Taxa De Verdadeiros Positivos = \\frac{Verdadeiros Positivos}{Verdadeiros Positivos + Falsos Negativos}$\n\n>$Taxa De Falsos Positivos = \\frac{Falsos Positivos}{Falsos Positivos + Verdadeiros Negativos}$\n\nPara representa\u00e7\u00e3o gr\u00e1fica, s\u00e3o consideradas essas taxas referentes \u00e0 diferentes valores de threshold do classificador, aumentando e\/ou diminuindo os valores esperados como positivos ou negativos.\n\nComo ilustrado na imagem abaixo, temos a curva ROC representada a partir de diferentes pontos de treshhold do classificador (pontos A, B e C).\n\n<img src=\"https:\/\/drive.google.com\/uc?id=1mA6SJEf27PR9VJVfonuCqKHED4yMknjP\">\n\nEsse tipo de representa\u00e7\u00e3o \u00e9 extremamente \u00fatil para avalia\u00e7\u00e3o de aplica\u00e7\u00f5es que trabalham em um ambiente com uma grande despropor\u00e7\u00e3o entre classes, possibilitando a considera\u00e7\u00e3o de um \"custo\/benef\u00edcio\" para os erros\/acertos do classificador.\n\nE com o intuito de simplificar e quantizar o desempenho de um classificador representado no gr\u00e1fico de curva ROC, \u00e9 utilizado a \u00e1rea abaixo da curva ROC, chamada de AUC, como m\u00e9trica. Seu valor pode variar entre 0 e 1, sendo que quanto maior for seu valor, melhor ser\u00e1 o classificador.\n\n","19fce2bb":"Para fazer a primeira submiss\u00e3o, inferimos os dados de teste.","b4f4b69c":"Para uma pessoa sem treinamento proficional, identificar se uma amostra \u00e9 maligna ou benigna \u00e9 bastante dif\u00edcil.","ca262a36":"Para obter alguns dados de avalia\u00e7\u00e3o, utilizamos a fun\u00e7\u00e3o [classification_report](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) da biblioteca ScikitLearn.","ffa1fed2":"Para fazer o treinamento, usamos o m\u00e9todo fit com as imagens de treinamento e valida\u00e7\u00e3o. O par\u00e2metro workers faz paraleliza\u00e7\u00e3o do processamento quando m\u00faltiplos cores de processamento est\u00e3o dispon\u00edveis.","fbf79fa4":"Essa base de dados possui dados categ\u00f3ricos, contudo a rede neural n\u00e3o aceita esse tipo de dado. Assim, usamos o m\u00e9todo [get_dummies()](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.str.get_dummies.html) para transformar os dados categ\u00f3rico em num\u00e9ricos.","90679133":"Para criar a rede, primeiramente foram criados modelos de MLP e CNN usando as classes [Sequential()](https:\/\/keras.io\/api\/models\/sequential\/#sequential-class) e [Model()](https:\/\/keras.io\/api\/models\/model\/#model-class) do Keras, respectivamente. \u00c9 importante ressaltar que os modelos s\u00f3 ser\u00e3o compilados ap\u00f3s a concatena\u00e7\u00e3o.","c8856d9b":"Calcula os pesos de cada classe.","677f6a31":"### Segunda submiss\u00e3o\n\nPara uma nova submiss\u00e3o, algumas mudan\u00e7as foram feitas a fim de tentar melhorar a classifica\u00e7\u00e3o do modelo. ","c6b2c177":"Para fazer a submiss\u00e3o, inferimos os dados de teste.","76fa3146":"O score oficial dessa submiss\u00e3o foi 0.499.","a7853bea":"O score oficial dessa submiss\u00e3o foi 0.489.","4fc25696":"Um dado interessante a ser observado em qualquer base \u00e9 a distribui\u00e7\u00e3o dos exemplos em cada classe.","908e949d":"Alguns exemplos do dataframe possuem dados faltantes nas colunas 'sex', 'age_approx' e 'anatom_site_general_challenge'. Assim, foi feita uma fun\u00e7\u00e3o para tratar esses dados. \n\nComo os exemplos com dados faltante nas colunas 'sex' e 'age_approx' eram poucos, e estes s\u00f3 existiam no conjunto de treinamento, foram simplesmente removidos. \n\nCom rela\u00e7\u00e3o ao atributo 'anatom_site_general_challenge', foi criada uma nova categoria chamada 'unknown' (desconhecido), e os dados faltantes foram substitu\u00eddos por essa categoria.","29e1366a":"Primeiramente carregamos os aquivos de informa\u00e7\u00f5es e adicionamos a extens\u00e3o de formato das imagens \u00e0s colunas image_name.","262bec59":"Para que a rede neural receba duas entradas diferentes, essas entradas precisam estar em um formato compat\u00edvel entre si. Assim, foi criada a classe MixedDataGenerator para gerar a entrada mista da rede neural.\n\nEssa classe permite que os dados sejam carregados na mem\u00f3ria em pequenos pacotes e os pacotes s\u00e3o carregados iterativamente durante os processos de treinamento, valida\u00e7\u00e3o e predi\u00e7\u00e3o. Dessa forma, n\u00e3o \u00e9 necess\u00e1rio carregar os dados todos de uma \u00fanica vez, gerando menos impacto na mem\u00f3ria RAM do computador.","afe0a6dc":"Usamos o c\u00e1lculo do score AUC da biblioteca scikitLearn para obter um resultado mais fiel dessa estat\u00edstica.","6e3601e3":"O [c\u00e2ncer de pele](https:\/\/saude.gov.br\/saude-de-a-z\/cancer-de-pele) \u00e9 um grave problema de sa\u00fade, sendo o tipo de c\u00e2ncer mais comum no Brasil e no mundo. Dentro das categorias de c\u00e2ncer de pele, o Melanoma \u00e9 o tipo mais perigoso por sua alta possibilidade de ocasionar met\u00e1stase e se espalhar para outros \u00f3rg\u00e3os.\n\nA competi\u00e7\u00e3o [SIIM-ISIC Melanoma Classification](https:\/\/www.kaggle.com\/c\/siim-isic-melanoma-classification) tem o objetivo de classificar em benigna e maligna v\u00e1rias imagens suspeitas de possuir c\u00e2ncer de pele Melanoma. A submiss\u00e3o deve conter um arquivo .csv com uma coluna de dados referente ao nome das imagens e outra com as respectivas probabilidades de cada imagem conter uma amostra maligna.\n\nA base \u00e9 composta por 33126 imagens de treinamento e 10982 imagens de teste. E tamb\u00e9m por dois arquivos .csv com algumas informa\u00e7\u00f5es sobre os pacientes de cada imagem.","b9624fba":"Antes de fazer a infer\u00eancia dos dados de teste, vamos analisar o resultado nos dados de valida\u00e7\u00e3o.","d79a11ef":"Para fazer o treinamento, usamos o m\u00e9todo fit com as imagens de treinamento e valida\u00e7\u00e3o. O par\u00e2metro workers faz paraleliza\u00e7\u00e3o do processamento quando m\u00faltiplos cores de processamento est\u00e3o dispon\u00edveis.","f580371f":"Primeiramente, as imagens foram carregadas com uma resolu\u00e7\u00e3o de 128x128 pixels","cf86ffde":"## Rede neural multi-input\n\nSabemos que essa base de dados, al\u00e9m das imagens, possui um dataframe com informa\u00e7\u00f5es sobre o paciente referente a cada imagem de melanoma. Assim, \u00e9 natural imaginar um m\u00e9todo que utilize os dois tipos de informa\u00e7\u00e3o para a classifica\u00e7\u00e3o. Dessa forma, foi criada uma rede neural que recebe duas entradas, imagem e dataframe, para gerar a classifica\u00e7\u00e3o.","b732803a":"## An\u00e1lise da base de dados","38d26d04":"Em seguida, construimos um modelo simples, com apenas uma camada de convolu\u00e7\u00e3o usando a biblioteca Keras. ","553d6df6":"### Leitura dos dados","96b4ee6e":"Para todos os exemplos testados nesse notebook, admitimos que os arquivos train.csv, test.csv e as pastas \/train e \/test com as imagens .jpg est\u00e3o no mesmo diret\u00f3rio que esse c\u00f3digo.","85515381":"\u00c9 poss\u00edvel observar que o modelo n\u00e3o classificou nenhum exemplo como 'malignant'. Isso provavelmente se deve ao tamanho bastante reduzido das imagens, o uso da acur\u00e1cia como m\u00e9trica do modelo em uma base desbalanceada e, principalmente, ao enorme desbalanceamento da base de dados em si."}}