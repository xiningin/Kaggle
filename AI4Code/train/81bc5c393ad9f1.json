{"cell_type":{"b14af3bd":"code","5c6e8c75":"code","22e44452":"code","5a2357a0":"code","0201d4a9":"code","5b762faa":"code","cca938e5":"code","6383e6ad":"code","36c73464":"code","04774371":"code","44418abb":"code","a03e1f9f":"code","002ad9d7":"code","0d2bff2d":"code","b2da0861":"code","d7009e8b":"code","34eec9a7":"code","e0c9b328":"code","72999590":"code","7b8c44f9":"code","04b4179a":"code","46370e2c":"code","3ec92a36":"code","b39d90a5":"code","15ffea68":"code","b34a23ec":"markdown","8c0bec72":"markdown","b9e46a42":"markdown","60a2c1dd":"markdown","e66986c2":"markdown","85c84e6c":"markdown","e2984204":"markdown","709d6de3":"markdown","1aff2f65":"markdown","c2a2521d":"markdown","6472f89c":"markdown","56572a85":"markdown","fed39ebb":"markdown","0254f1ab":"markdown","a5e6cc96":"markdown","3eca95cb":"markdown","e73e1bca":"markdown","434d7c3d":"markdown","772a1b0f":"markdown","efc960bf":"markdown","e14e9a65":"markdown","d4b4a1e1":"markdown","deeb5bf7":"markdown","475e9e1a":"markdown","2f7ecfa8":"markdown","5a9a0393":"markdown","4138e1f9":"markdown","c3295fa9":"markdown","d1fa8641":"markdown","ed372667":"markdown"},"source":{"b14af3bd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 5, 10\nplt.style.use('seaborn-dark')\n\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\ndata   = pd.read_csv('..\/input\/heart.csv')\nlabels = data['target']","5c6e8c75":"def quartile_probs(frame, metric, target_metric):\n    first  = frame[frame[metric] <= frame.describe()[metric][4]]\n    second = frame[(frame[metric] > frame.describe()[metric][4]) & (frame[metric] <= frame.describe()[metric][5])]\n    third  = frame[(frame[metric] > frame.describe()[metric][5]) & (frame[metric] <= frame.describe()[metric][6])]\n    fourth = frame[(frame[metric] > frame.describe()[metric][6]) & (frame[metric] <= frame.describe()[metric][7])]\n    \n    one_q_prob = first[first[target_metric] == 1].count()[target_metric] \/ first[target_metric].count()\n    two_q_prob = second[second[target_metric] == 1].count()[target_metric] \/ second[target_metric].count()\n    three_q_prob = third[third[target_metric] == 1].count()[target_metric] \/ third[target_metric].count()\n    four_q_prob = fourth[fourth[target_metric] == 1].count()[target_metric] \/ fourth[target_metric].count()\n    \n    labels   = ['1Q \\n n = '+str(first[target_metric].count()),\n                '2Q \\n n = '+str(second[target_metric].count()), \n                '3Q \\n n = '+str(third[target_metric].count()), \n                '4Q \\n n = '+str(fourth[target_metric].count())]\n    problist = [one_q_prob, two_q_prob, three_q_prob, four_q_prob]\n    \n    print('1Q {} prob: {:.2f}% (n = {})'.format(metric, one_q_prob*100, first[target_metric].count()))\n    print('2Q {} prob: {:.2f}% (n = {})'.format(metric, two_q_prob*100, second[target_metric].count()))\n    print('3Q {} prob: {:.2f}% (n = {})'.format(metric, three_q_prob*100, third[target_metric].count()))\n    print('4Q {} prob: {:.2f}% (n = {})'.format(metric, four_q_prob*100, fourth[target_metric].count()))\n    \n    sns.barplot(labels, problist)\n    \ndef class_probs(frame, metric, target_metric):\n    results = []\n    for i in frame[metric].unique():\n        subset = data[data[metric] == i]\n        pct = subset[target_metric][subset[target_metric] == 1].count()\/subset[target_metric].count()\n        results.append([str(i), pct, subset[target_metric].count()])\n        \n    for i in results:\n        print(\"Probability for {}: {:.2f}% (n = {})\".format(i[0], i[1]*100, i[2]))       \n    \n    sns.barplot([x[0] for x in results], [x[1] for x in results]);","22e44452":"data.head()","5a2357a0":"data.describe()","0201d4a9":" quartile_probs(data, 'age', 'target')","5b762faa":" class_probs(data, 'sex', 'target')","cca938e5":" class_probs(data, 'cp', 'target')","6383e6ad":" quartile_probs(data, 'trestbps', 'target')","36c73464":" quartile_probs(data, 'chol', 'target')","04774371":" class_probs(data, 'fbs', 'target')","44418abb":" class_probs(data, 'restecg', 'target')","a03e1f9f":" quartile_probs(data, 'thalach', 'target')","002ad9d7":" class_probs(data, 'exang', 'target')","0d2bff2d":" quartile_probs(data, 'oldpeak', 'target')","b2da0861":" class_probs(data, 'slope', 'target')","d7009e8b":" class_probs(data, 'ca', 'target')","34eec9a7":" class_probs(data, 'thal', 'target')","e0c9b328":"data = data.drop(['fbs', 'trestbps'], axis = 1)","72999590":"from sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split","7b8c44f9":"x = data\ny = labels","04b4179a":"d = {'Gaussian Process': [], \n     'Random Forest': [], \n     'K Neighbours': [], \n     'SVC': [], \n     'Logit': []}\n\nscores = pd.DataFrame(data = d)","46370e2c":"def validate(rs):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = rs)\n    \n    GPC = GaussianProcessClassifier()\n    GPC.fit(x_train, y_train)\n    GPC.score(x_test, y_test)\n\n    RFC = RandomForestClassifier(n_estimators = 10)\n    RFC.fit(x_train, y_train)\n    RFC.score(x_test, y_test)\n\n    KNC = KNeighborsClassifier()\n    KNC.fit(x_train, y_train)\n    KNC.score(x_test, y_test)\n    \n    SVC1 = SVC()\n    SVC1.fit(x_train, y_train)\n    SVC1.score(x_test, y_test)\n    \n    LOGIT = LogisticRegression()\n    LOGIT.fit(x_train, y_train)\n    LOGIT.score(x_test, y_test)\n    \n    tempr = pd.DataFrame([[GPC.score(x_test, y_test), \n                        RFC.score(x_test, y_test),\n                        KNC.score(x_test, y_test),\n                        SVC1.score(x_test, y_test),\n                        LOGIT.score(x_test, y_test)]], columns=['Gaussian Process',\n                                                                  'Random Forest',\n                                                                  'K Neighbours',\n                                                                  'SVC',\n                                                                  'Logit'])\n                         \n    return tempr","3ec92a36":"for rs in np.random.randint(100_000, size = 1000):\n    scores = scores.append(validate(rs))","b39d90a5":"scores.mean()","15ffea68":"logit_success_rate  = scores[scores['Logit'] == 1.0]['Logit'].count() \/ scores['Logit'].count()\nprint(' {:.2f} %'.format(logit_success_rate*100))","b34a23ec":"### Age Analysis","8c0bec72":"# Fluoroscopy Analysis","b9e46a42":"## EDA","60a2c1dd":"# Dropping Irrelevant Data","e66986c2":"# Machine Learning Model","85c84e6c":"The higher the ST depression value, the less likely it is to have a heart diesease","e2984204":"Those who experienced EIA are much less likely to actually have a heart diesease.","709d6de3":"Whenever Atypical Angina or non-anginal pain occurs, there is a very high risk of heart diesease. The same goes for asymptomatic cases, however the sample for those is quite low, so our estimation should be most troublesome for asymptomatic cases and for Typical Angina cases, where the sample is relatively high.  ","1aff2f65":"Highly significant and useful feature. The probability seems to be rising in an almost ideally linear manner, and the distribution of samples is almost perfectly even.","c2a2521d":"# Chest Pain Analysis","6472f89c":"# Sex Analysis","56572a85":"Resting BPM does not seem very relevant as a sole determiner. Lower probability for 4Q is likely a random walk.","fed39ebb":"Probability of heart diesease appears to be falling in a stable manner as serum choresteral leves increase. What is also worth noticing is amazingly even distributon of n's among the quartiles.","0254f1ab":"# ST Slope Analysis","a5e6cc96":"Blood sugar does not seem to be relevant as a sole determiner.","3eca95cb":"It also appears that women are twice as likely to have a heart diesease.","e73e1bca":"It seems that only slope 2 has significant influence over the diesease prob.","434d7c3d":"Type 4 should be disregarded, as n=5, therefore, we can conclude that the coorelation is inverse.","772a1b0f":"It appears that only thal 2 has a significant influence over the diesease.","efc960bf":"# Exercise Induced Angina Analysis","e14e9a65":"# Choresterol Analysis","d4b4a1e1":"### In 1000 randomly generated 0.2 splits, the logistic regression classifier has achieved 100% success rate. Not much else to be done here....","deeb5bf7":"# Thal Analysis","475e9e1a":"First conclussions are interesting: younger people in the sample are generally less likely to have a heart diesease. The lowest probability in sample is however for the third quartile (55-61).","2f7ecfa8":"# ST Depression Analysis","5a9a0393":"# Resting BPM Analysis","4138e1f9":"# Heart Diesease Predictor\nThe goal of the model is to predict wether the patient has a heart diesease based on numeral description of his physical and psychological state. \n\nGoals:\n    - Properly describe the code\n    - Use ensemble learning\n    - Use heavy cross-validation\n    \n    \nFeature description:\n### age\nage in years\n\n### sex\n(1 = male; 0 = female)\n\n### cp\nchest pain type\n\n### trestbps\nresting blood pressure (in mm Hg on admission to the hospital)\n\n### chol\nserum cholestoral in mg\/dl\n\n### fbs\n(fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\n### restecg\nresting electrocardiographic results\n\n### thalach\nmaximum heart rate achieved\n\n### exang\nexercise induced angina (1 = yes; 0 = no)\n\n### oldpeak\nST depression induced by exercise relative to rest\n\n### slope\nthe slope of the peak exercise ST segment\n\n### ca\nnumber of major vessels (0-3) colored by flourosopy\n\n### thal\n3 = normal; 6 = fixed defect; 7 = reversable defect\n\n### target\n1 or 0 ","c3295fa9":"# Blood Sugar Analysis","d1fa8641":"Samples with type 1 score seem to have higher risk of diesease than those with type 0. No conclussions should be made with regard to type 2, as there were only 4 samples in this category.","ed372667":"# Resting electrocardiographic results Analysis"}}