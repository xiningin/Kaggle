{"cell_type":{"b5a3b1b7":"code","669fa449":"code","ac9d4bf2":"code","047cc93b":"code","6c74d7df":"code","d18a257d":"code","d67b59ef":"code","0b0e97fd":"code","7e654398":"code","e2242a06":"code","0f522955":"code","0e2400dd":"code","6eb1218a":"code","2547a1c3":"code","a0346c65":"code","d75fae22":"code","fe598c05":"code","c693b393":"code","50dc2f6e":"code","239a6f3f":"code","7b46860c":"code","ddb880d1":"code","1a6c884a":"code","b479cc36":"code","3e3da945":"code","c42f9b03":"code","9c08a75f":"code","9b19634c":"code","d5a6643d":"code","ae8ef927":"code","7342f221":"code","db19b196":"code","718ab04e":"code","73064539":"code","dbfc1832":"markdown"},"source":{"b5a3b1b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten\nfrom keras.optimizers import Adam, RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","669fa449":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntrain.head()","ac9d4bf2":"test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","047cc93b":"x_train = (train.iloc[:,1:].values).astype('float32')\n# all pixel values\ny_train = train.iloc[:,0].values.astype('int32') \n# only labels i.e targets digits\nx_test = test.values.astype('float32')","6c74d7df":"x_train","d18a257d":"y_train","d67b59ef":"# data visualization\n# conveting datast to (num_imager, img_rows, img_cols) format\nx_train = x_train.reshape(x_train.shape[0], 28, 28)\n\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);","0b0e97fd":"# expanding 1 more dimension as 1 for color channel gray\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_train.shape","7e654398":"x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\nx_test.shape","e2242a06":"# preprocessing the digit images\n# feature standardization\n\nmean_px = x_train.mean().astype(np.float32)\nstd_px = x_train.std().astype(np.float32)\n\ndef standardize(x):\n    return(x-mean_px)\/std_px","0f522955":"# one hot encoding of labels\n\nfrom keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","0e2400dd":"# plotting the 10th label\n\nplt.title(y_train[9])\nplt.plot(y_train[9])\nplt.xticks(range(10));","6eb1218a":"# designing the neural network architecture\n# fix random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","2547a1c3":"# linear model\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Lambda, Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D, MaxPooling2D","a0346c65":"model = Sequential()\nmodel.add(Lambda(standardize, input_shape=(28, 28, 1)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation = 'softmax'))\nprint(\"input shape \", model.input_shape)\nprint(\"output shape \", model.output_shape)","d75fae22":"# compiling the network\nfrom keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(lr=0.001),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","fe598c05":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()","c693b393":"# Cross Validation\n\nfrom sklearn.model_selection import train_test_split\nx = x_train\ny = y_train\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=42)\nbatches=gen.flow(x_train, y_train, batch_size=64)\nval_batches=gen.flow(x_val, y_val, batch_size=64)","50dc2f6e":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3,\n                           validation_data=val_batches, validation_steps=val_batches.n)","239a6f3f":"history_dict = history.history\nhistory_dict.keys()","7b46860c":"import matplotlib.pyplot as plt\n%matplotlib inline\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss_values, 'bo')\n# b+ is for \"blue crosses\"\nplt.plot(epochs, val_loss_values, 'b+')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.show()","ddb880d1":"plt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\n\nplt.plot(epochs, acc_values, 'bo')\nplt.plot(epochs, val_acc_values, 'b+')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.show()","1a6c884a":"def get_fc_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(optimizer='Adam', loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","b479cc36":"fc = get_fc_model()\nfc.optimizer.lr=0.01","3e3da945":"history=fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","c42f9b03":"from keras.layers import Convolution2D, MaxPooling2D\n\ndef get_cnn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Convolution2D(64,(3,3), activation='relu'),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","9c08a75f":"model = get_cnn_model()\nmodel.optimizer.lr=0.01","9b19634c":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","d5a6643d":"# Data Augmentation\ngen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n                               height_shift_range=0.08, zoom_range=0.08)\nbatches = gen.flow(x_train, y_train, batch_size=64)\nval_batches = gen.flow(x_val, y_val, batch_size=64)","ae8ef927":"model.optimizer.lr=0.001\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","7342f221":"# adding batch normalization\nfrom keras.layers.normalization import BatchNormalization\n\ndef get_bn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        BatchNormalization(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","db19b196":"model= get_bn_model()\nmodel.optimizer.lr=0.01\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","718ab04e":"model.optimizer.lr=0.01\ngen = image.ImageDataGenerator()\nbatches = gen.flow(x, y, batch_size=64)\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)","73064539":"predictions = model.predict_classes(x_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"DR.csv\", index=False, header=True)","dbfc1832":"Sumbmission"}}