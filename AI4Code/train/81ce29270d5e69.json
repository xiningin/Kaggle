{"cell_type":{"745b9f93":"code","b1a75ab7":"code","d3f763d6":"code","6f54cf37":"code","eb750937":"code","b806a2c2":"code","83eed9ef":"code","58192304":"code","b7d6d242":"code","876749cb":"code","232103f4":"code","4b76c93f":"code","18c9369d":"code","282213af":"code","c6007a80":"code","f0339ad7":"code","0599bea8":"code","21ab3df7":"code","eb087896":"markdown","691278c9":"markdown","07ee38f3":"markdown","3ac18b3e":"markdown","c3f7abf7":"markdown","a1afcb85":"markdown","05ebfb6b":"markdown","e8948751":"markdown","36d7cb47":"markdown"},"source":{"745b9f93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b1a75ab7":"# Reading the file\ndf = pd.read_csv('\/kaggle\/input\/reading-habit-analysis\/Reading Habit Analysis Article.csv', engine='python')","d3f763d6":"# Checking out top 10 items from the dataset\ndf.head(10)","6f54cf37":"# Counting the number of males and females from the Gender column of dataset\ndf['Gender'].value_counts()","eb750937":"# Ploting pie and bar charts for Gender column \nimport matplotlib.pyplot as plt\ntemp1 = df['Gender'].value_counts()\nfig = plt.figure(figsize=(10,4))\nax1 = fig.add_subplot(121)\n#ax1.set_xlabel('Gender')\n#ax1.set_ylabel('Gender Count')\nax1.set_title(\"Number of Participants based on Gender\")\ntemp1.plot(kind='pie')\nfig = plt.figure(figsize=(10,4))\nax1 = fig.add_subplot(121)\nax1.set_xlabel('Gender')\nax1.set_ylabel('Gender Count')\ntemp1.plot(kind='bar')\n","b806a2c2":"# Getting the idea of how people answered the Question: \"What motivates you to Read articles, books, technology blogs, news etc ?\" present in the dataset\ndf['What motivates you to Read articles, books, technology blogs, news etc ?']","83eed9ef":"#to split the answers (just the last column of dataset i.e. 'What motivates you to Read articles, books, technology blogs, news etc ?' )\nfrom collections import Counter\nsplit = [] #empty array to store the result of splitted data\nfor i in range(48):\n    s = df['What motivates you to Read articles, books, technology blogs, news etc ?'][i].lower().split()\n    split+= s #adding splitted values in the empty list\nprint(split)\n\n","58192304":"words = pd.DataFrame(split) #converting split into dataframe","b7d6d242":"from collections import Counter\nimport numpy as np\nfrom nltk.corpus import stopwords \n\nstop = stopwords.words('english')\n\nuseful_words = words[0].apply(lambda x: ''.join([word for word in x.split() if word not in (stop)]))  # removing English stop words from the dataset\n#print(useful_words)\n\nspacefree = pd.DataFrame(useful_words) #converting useful_words list into dataframe\nspacefree[0].replace('', np.nan, inplace=True) #replacing empty strings with NAN in the dataframe\nspacefree[0].replace('.', np.nan, inplace=True) #replacing . with NaN in the dataframe\nspacefree[0].replace(',', np.nan, inplace=True) #replacing , with NAN in the dataframe\nspacefree[0].replace('-', np.nan, inplace=True) #replacing - with NAN in the dataframe\nCounter(spacefree[0].dropna(axis=0, how='any')) #droping all NAN from the dataframe\ndf_vals = spacefree[~spacefree[0].isnull()] #If previous dropna failed then this will drop all the null values from the dataframe, I don't know but this was working like this\n#df_vals ","876749cb":"#NOW DATA IS CLEANED\nCount = Counter(df_vals[0]) #to get the word count of cleaned data\nC = Count.most_common(20) #to get 20 most common words with their count\nC = pd.DataFrame(C)       #converting the 20 most common words with their word count into dataframe\n","232103f4":"#Plotting 20 most common words Dataframe with the help of a bar chart\nC.plot.bar(x=0, y=1, rot=100)","4b76c93f":"#Other words clusters are as under with their counts\n#Count = Counter(df_vals[0])\n#Count\n#C = pd.DataFrame(C) \nfrom sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation #For clustering\n\nfig = plt.figure(figsize=(20,5))\nax = fig.add_subplot(111)\ny = np.random.rand(591)\ncolors = (\"blue\")\nscatter = ax.scatter(df_vals[0],y,c=colors, marker=\"*\")\nax.set_title('Words Clusters')\nax.set_xlabel('words')\nax.set_ylabel('Count')\nplt.scatter","18c9369d":"Count = Counter(df_vals[0])\n#Count.most_common(591) \n","282213af":"Count.most_common(197) # 591\/3 = 197\ndf_Count = pd.DataFrame(Count.most_common(591))\n\n#df_Count ","c6007a80":"list1 = [] #list to create target class\n\nfor i in range(197):\n    list1 += [0] #0 stands for common words\nfor i in range(394):\n    list1.append(1) #1 stands for un common words    \n\n#len(list1)\n#list1","f0339ad7":"\ndata = list(zip(df_Count[0], list1))\ndata\n  \n# Create the pandas DataFrame \ndf_class = pd.DataFrame(data, columns=['Words','Classes']) \n#df_class \n","0599bea8":"from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation","21ab3df7":"X = df_class['Words']# Features\ny = df_class['Classes'] # Target variable\n\nX = pd.get_dummies(X,drop_first=True) # for handling categorical data \n#y = pd.get_dummies(y,drop_first=True) # not required for this\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1) # 90% training and 10% test\n\n\n\ntree = DecisionTreeClassifier()\ntree = tree.fit(X_train, y_train)\ny_pred = tree.predict(X_test)\n#y_pred\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100)\n","eb087896":"> **Data Cleansing**","691278c9":"![](https:\/\/images.unsplash.com\/photo-1509114859430-5f2c74177f4b?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=750&q=80)","07ee38f3":"** Reading Habit Analysis**\n\n> **What Motivates you to Read ? **","3ac18b3e":"**Hi, everyone. Here I am presenting Reading Habit Analysis. Maybe there exist any other analysis like this but I have not found it as yet. I hope you will enjoy going through the below mentioned experiment :p \nAlso I have written an article corresponding to this, you can find it here:https:\/\/medium.com\/@biach1312\/reading-habit-analysis-895f78865bb0\n**\n\n**Enjoy!**","c3f7abf7":"> **------------------------------------------------------------------------------------------------------------------------------------------------**","a1afcb85":"> **Decision Tree Classifier**","05ebfb6b":"> ***Happy Machine Learning :) ***","e8948751":"![](https:\/\/media.giphy.com\/media\/WoWm8YzFQJg5i\/giphy.gif)","36d7cb47":"> **Clustering The Common Words**"}}