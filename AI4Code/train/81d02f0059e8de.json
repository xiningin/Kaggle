{"cell_type":{"329e183c":"code","a69e82d3":"code","aa402a52":"code","c498963d":"code","96ac3f60":"code","1c480b4f":"code","17cc1a1c":"code","9401a991":"code","388fffd7":"code","cd416c8c":"code","69524abb":"markdown","693272ae":"markdown","4a7bb722":"markdown","13b6830b":"markdown","f4e2c2f2":"markdown","569fcdfa":"markdown","ac56ceed":"markdown","b7236895":"markdown","7dd6b7fd":"markdown"},"source":{"329e183c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a69e82d3":"training = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntraining['train_test'] = 1\ntest['train_test'] = 0\ntest['Survived'] = np.NaN\n\nall_data = pd.concat([training, test])\nall_data.columns","aa402a52":"#quick look at our data types & null counts \ntraining.info() #Age, Cabin and Embarked has Null values","c498963d":"training.describe()","96ac3f60":"print(training.head()) #Visualise the values for analysis","1c480b4f":"# look at numeric and categorical values separately\ndf_num = training[['Age', 'SibSp', 'Parch', 'Fare']]\ndf_cat = training[['Survived', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']]","17cc1a1c":"# Potting the distributions of all numeric data\nfor col in df_num.columns:\n    plt.hist(df_num[col])\n    plt.title(col)\n    plt.show()","9401a991":"#Let's plot the correlation matrix for this numeric data and analyse\nprint(df_num.corr())\nsns.heatmap(df_num.corr())","388fffd7":"#This gives us the avg in each column to Survived column\npd.pivot_table(training, index = 'Survived', values = ['Age', 'SibSp', 'Parch', 'Fare'])","cd416c8c":"for col in df_cat.columns:\n    sns.barplot(df_cat[col].value_counts().index,df_cat[col].value_counts()).set_title(col)\n    plt.show()","69524abb":"**As we can see in above histograms the 'Age' column falls under Normal Distribution and rest of the numeric columns are skewed and need to be normalised if required.**","693272ae":" ****Importing the data into notebook****","4a7bb722":"**Adding 'train_test' column to differentiate the records in all_data dataframe by making Survived column of test as NaN for prediction.**","13b6830b":"**Now let's see the Survival rate across each numeric columns Age, SibSp, Parch and Fare**","f4e2c2f2":"# Light Data Exploration\n**1.  For numeric data**\n    * Made histograms to understand distributions\n    * Corrplot\n    * Pivot table comparing survival rate across numeric variables\n**2.  For Categorical Data**\n    * Made bar charts to understand balance of classes\n    * Made pivot tables to understand relationship with survival","569fcdfa":"# Titanic Data Analysis and Modelling\n\n**This notebook is referenced from [Ken Jee](https:\/\/www.youtube.com\/watch?v=I3FBJdiExcg)**","ac56ceed":"**Getting numeric and categorical columns seperatly to analyse**","b7236895":"**Now let's analyse the categorical columns from 'df_cat' using BarPlots**","7dd6b7fd":"**As we can see Cabin and ticket graphs are very messy. This is an area where we may want to do some feature engineering!**"}}