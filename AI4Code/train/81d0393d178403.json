{"cell_type":{"5e97d531":"code","2e35201b":"code","bf59cf5a":"code","9c57e0f9":"code","f1fc4c12":"code","e124e029":"code","0e22b6db":"code","b9b992e9":"code","c501f53d":"code","c0b6ec10":"code","9aed2122":"code","9145c803":"code","74b84894":"code","d19a7332":"code","7b1683ee":"code","5cdf2a33":"code","db093169":"code","775bdb52":"code","c4d77425":"code","7aa37d31":"code","0ecd7252":"code","8e33d177":"code","958ac347":"code","649edc89":"code","7a1b0b8a":"code","2241982e":"code","968e7bf3":"code","7c99581d":"code","d0aabae2":"code","d9c363bd":"code","edb3e52a":"code","94e8747a":"code","abc7d672":"code","2880d99a":"code","f031b6c7":"code","46a66f7f":"code","a6fc5d57":"code","ab4b7f97":"code","fedf837d":"code","b325bf02":"code","36a58ff9":"code","d1e2fe17":"code","4160a3ff":"code","58b96da4":"code","5d1b46aa":"code","161364b3":"code","88289e06":"markdown","b6014888":"markdown","b7f4bc8a":"markdown","dc937d69":"markdown","de57c364":"markdown","413736a4":"markdown","5ad1ea2f":"markdown","230b08ab":"markdown","979f0a03":"markdown","16663233":"markdown","9cd3041a":"markdown","3a6ba521":"markdown","90302c4b":"markdown"},"source":{"5e97d531":"import torch \nimport numpy as np","2e35201b":"x = torch.ones(3, 2)\nprint(x)\nx = torch.zeros(3, 2)\nprint(x)\nx = torch.rand(3, 2)\nprint(x)","bf59cf5a":"x = torch.empty(3, 2)\nprint(x)\ny = torch.zeros_like(x)\nprint(y)","9c57e0f9":"x = torch.linspace(0, 1, steps=5)\nprint(x)","f1fc4c12":"x = torch.tensor([[1, 2],\n                 [3, 4],\n                 [5, 6]])\nprint(x)","e124e029":"print(x.size())\nprint(x[:, 1])\nprint(x[0, :])","0e22b6db":"y = x[1, 1]\nprint(y)\nprint(y.item())","b9b992e9":"print(x)\ny = x.view(2, 3)\nprint(y)","c501f53d":"y = x.view(6, -1)\nprint(y)","c0b6ec10":"x = torch.ones([3, 2])\ny = torch.ones([3, 2])\nz = x + y\nprint(z)\nz = x * y\nprint(z)\nz = x - y\nprint(z)","9aed2122":"z = y.add(x)\nprint(z)\nprint(y)","9145c803":"z = y.add_(x)\nprint(z)\nprint(y)","74b84894":"x_np = x.numpy()\nprint(type(x), type(x_np))\nprint(x_np)","d19a7332":"a = np.random.randn(5)\nprint(a)\na_pt = torch.from_numpy(a)\nprint(type(a), type(a_pt))\nprint(a_pt)","7b1683ee":"np.add(a, 1, out=a)\nprint(a)\nprint(a_pt)","5cdf2a33":"%%time\nfor i in range(100):\n    a = np.random.randn(100, 100)\n    b = np.random.randn(100, 100)\n    c = np.matmul(a, b)","db093169":"%%time \nfor i in range(100):\n    a = torch.randn([100, 100])\n    b = torch.randn([100, 100])\n    c = torch.matmul(a, b)","775bdb52":"%%time\nfor i in range(10):\n    a = np.random.randn(10000, 10000)\n    b = np.random.randn(10000, 10000)\n    c = np.matmul(a, b)","c4d77425":"%%time \nfor i in range(10):\n    a = torch.randn([10000, 10000])\n    b = torch.randn([10000, 10000])\n    c = torch.matmul(a, b)","7aa37d31":"print(torch.cuda.device_count())","0ecd7252":"print(torch.cuda.device(0))\nprint(torch.cuda.get_device_name(0))","8e33d177":"cuda0 = torch.device('cuda:0')","958ac347":"a = torch.ones(3, 2, device=cuda0)\nb = torch.ones(3, 2, device=cuda0)\nc = a + b\nprint(c)","649edc89":"print(a)","7a1b0b8a":"%%time \nfor i in range(10):\n    a = np.random.randn(10000, 10000)\n    b = np.random.randn(10000, 10000)\n    np.add(b, a)","2241982e":"%%time \nfor i in range(10):\n    a_cpu = torch.randn([10000, 10000])\n    b_cpu = torch.randn([10000, 10000])\n    b_cpu.add_(a_cpu)","968e7bf3":"%%time\nfor i in range(10):\n    a = torch.randn([10000, 10000], device=cuda0)\n    b = torch.randn([10000, 10000], device=cuda0)\n    b.add_(a)","7c99581d":"%%time\nfor i in range(10):\n    a = np.random.randn(10000,10000)\n    b = np.random.randn(10000,10000)\n    np.matmul(b, a)","d0aabae2":"%%time\nfor i in range(10):\n    a_cpu = torch.randn([10000, 10000])\n    b_cpu = torch.randn([10000, 10000])\n    torch.matmul(a_cpu, b_cpu)","d9c363bd":"%%time\nfor i in range(10):\n    a = torch.randn([10000, 10000], device=cuda0)\n    b = torch.randn([10000, 10000], device=cuda0)\n    torch.matmul(a, b)","edb3e52a":"x = torch.ones([3, 2], requires_grad=True)\nprint(x)","94e8747a":"y = x + 5\nprint(y)","abc7d672":"z = y * y + 1\nprint(z)","2880d99a":"t = torch.sum(z)\nprint(t)","f031b6c7":"t.backward()","46a66f7f":"print(x.grad)","a6fc5d57":"x = torch.ones([3, 2], requires_grad=True)\ny = x + 5\nr = 1\/(1 + torch.exp(-y))\nprint(r)\ns = torch.sum(r)\ns.backward()\nprint(x.grad)","ab4b7f97":"x = torch.ones([3, 2], requires_grad=True)\ny = x + 5\nr = 1\/(1 + torch.exp(-y))\na = torch.ones([3, 2])\nr.backward(a)\nprint(x.grad)","fedf837d":"x = torch.randn([20, 1], requires_grad=True)\ny = 3*x-2","b325bf02":"w = torch.tensor([1.],requires_grad=True)\nb = torch.tensor([1.],requires_grad=True)\n\ny_hat = w*x + b\n\nloss = torch.sum((y_hat - y)**2)","36a58ff9":"print(loss)","d1e2fe17":"loss.backward()","4160a3ff":"print(w.grad, b.grad)","58b96da4":"learning_rate = 0.01\n\nw = torch.tensor([1.], requires_grad=True)\nb = torch.tensor([1.], requires_grad=True)\n\n# print(w.item(), b.item())\n\nfor i in range(10):\n    \n    x = torch.randn([20, 1])\n    y = 3*x -2\n    \n    y_hat = w*x + b\n    loss = torch.sum((y_hat - y)**2)\n    \n    loss.backward()\n    \n    with torch.no_grad():\n        w -= learning_rate * w.grad\n        b -= learning_rate * b.grad\n        \n        w.grad.zero_()\n        b.grad.zero_()\n    \n#     print(w.item(), b.item())","5d1b46aa":"%%time\nlearning_rate = 0.001\nN = 10000000\nepochs = 200\n\nw = torch.rand([N], requires_grad=True)\nb = torch.ones([1], requires_grad=True)\n\n# print(torch.mean(w).item(), b.item())\n\nfor i in range(epochs):\n    \n    x = torch.randn([N])\n    y = torch.dot(3*torch.ones([N]), x) - 2\n    \n    y_hat = torch.dot(w, x) + b\n    loss = torch.sum((y_hat - y)**2)\n    \n    loss.backward()\n    \n    with torch.no_grad():\n        w -=  learning_rate * w.grad\n        b -= learning_rate * b.grad\n        \n        w.grad.zero_()\n        b.grad.zero_()\n        \n#     print(torch.mean(w).item(), b.item())","161364b3":"%%time\nlearning_rate = 0.001\nN = 100000000\nepochs = 200\n\nw = torch.rand([N], requires_grad=True, device=cuda0)\nb = torch.ones([1], requires_grad=True, device=cuda0)\n\nfor i in range(epochs):\n    \n    x = torch.randn([N], device=cuda0)\n    y = torch.dot(3* torch.ones([N], device=cuda0),x)-2\n    \n    y_hat = torch.dot(w, x) + b\n    loss = torch.sum((y_hat - y)**2)\n    \n    loss.backward()\n    \n    with torch.no_grad():\n        w -= learning_rate * w.grad\n        b -= learning_rate * b.grad\n        \n        w.grad.zero_()\n        b.grad.zero_()\n    \n    print(torch.mean(w).item(), b.item())","88289e06":"### Autodiff","b6014888":"### Simple Tensor Operations","b7f4bc8a":"### Reshaping Tensors","dc937d69":"### CUDA Support","de57c364":"### Do it for a large problem","413736a4":"### Outline\n\n* PyTorch\n* What are tensors\n* Initialising, slicing, reshaping tensors\n* Numpy and PyTorch interfacing \n* GPU support for PyTorch + Enabling GPUs on Kaggle\n* Speed comparisons, Numpy -- PyTorch -- PyTorch on GPU\n* Autodiff concepts and application\n* Writing a basic learning loop using autograd","5ad1ea2f":"$t = \\sum_i z_i, z_i = y_i^2 + 1, y_i = x_i + 5$\n\n$\\frac{\\partial t}{\\partial x_i} = \\frac{\\partial z_i}{\\partial x_i} = \\frac{\\partial z_i}{\\partial y_i} \\frac{\\partial y_i}{\\partial x_i} = 2y_i \\times 1$\n\nAt x = 1, y = 6, $\\frac{\\partial t}{\\partial x_i} = 12$","230b08ab":"### Autodiff example that looks like what we have been doing","979f0a03":"### Do it in a loop","16663233":"### Numpy <> PyTorch","9cd3041a":"### Slicing Tensors","3a6ba521":"### Initialise Tensors","90302c4b":"$\\frac{\\partial{s}}{\\partial{x}} = \\frac{\\partial{s}}{\\partial{r}} \\cdot \\frac{\\partial{r}}{\\partial{x}}$\n\nFor the above code $a$ represents $\\frac{\\partial{s}}{\\partial{r}}$ and then $x.grad$ gives directly $\\frac{\\partial{s}}{\\partial{x}}$"}}