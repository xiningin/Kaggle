{"cell_type":{"93ac4a91":"code","dc0bae6e":"code","4e90fdc4":"code","efaac801":"code","5ca7f18a":"code","c9b1731f":"code","8422c015":"code","05b33153":"code","68766b1e":"code","d09f5482":"code","01e91fc8":"code","16b198d4":"markdown","3b7e345b":"markdown","cd4b9cea":"markdown","dcb89456":"markdown","779c3c4c":"markdown","84816e1e":"markdown","191f8406":"markdown","ff107e96":"markdown","77976760":"markdown","d9b45ff3":"markdown","40018dc6":"markdown"},"source":{"93ac4a91":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\n","dc0bae6e":"train_meta = pd.read_csv('..\/input\/training_set_metadata.csv')\ntest_meta = pd.read_csv('..\/input\/test_set_metadata.csv')","4e90fdc4":"# Make sure I can rerun that any time\nif 'object_id' in train_meta:\n    del train_meta['object_id'], train_meta['target']\n    del test_meta['object_id']\n    gc.collect()\n    \ntrain_meta['is_train'] = 1\ntest_meta['is_train'] = 0","efaac801":"np.random.seed(10)\nfull_meta = pd.concat([train_meta, test_meta], axis=0).sample(frac=1.0)","5ca7f18a":"folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n\nfeatures = [f for f in full_meta if f not in ['is_train']]\nimportances = pd.DataFrame()\n\nlgb_params = {\n    'n_estimators': 200,\n    'boosting_type': 'rf',\n    'learning_rate': .05,\n    'num_leaves': 127,\n    'subsample': 0.621,\n    'colsample_bytree': 0.7,\n    'max_depth': 7,\n    'bagging_freq': 1,\n}\noof_preds = np.zeros(full_meta.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds.split(full_meta, full_meta['is_train'])):\n    trn_x, trn_y = full_meta[features].iloc[trn_], full_meta['is_train'].iloc[trn_]\n    val_x, val_y = full_meta[features].iloc[val_], full_meta['is_train'].iloc[val_]\n    \n    clf = lgb.LGBMClassifier(**lgb_params)\n    \n    clf.fit(trn_x, trn_y)\n    \n    oof_preds[val_] = clf.predict_proba(val_x)[:, 1]\n    \n    imp_df = pd.DataFrame()\n    imp_df['feature'] = features\n    imp_df['gain'] = clf.booster_.feature_importance(importance_type='gain')\n    imp_df['split'] = clf.booster_.feature_importance(importance_type='split')\n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n\n    del trn_x, trn_y, val_x, val_y\n    gc.collect()\n\nprint('Train\/Test separation score : %.6f' % roc_auc_score(full_meta['is_train'], oof_preds))","c9b1731f":"mean_gain = importances[['gain', 'feature']].groupby('feature').mean()\nimportances['mean_gain'] = importances['feature'].map(mean_gain['gain'])\n\nplt.figure(figsize=(8, 12))\nsns.barplot(x='gain', y='feature', data=importances.sort_values('mean_gain', ascending=False))\nplt.tight_layout()","8422c015":"nulls = pd.concat([train_meta.isnull().mean(), test_meta.isnull().mean()], axis=1).sort_index()\nnulls.columns = ['train', 'test']\nnulls\n","05b33153":"del train_meta, test_meta, full_meta\ngc.collect()","68766b1e":"train = pd.read_csv('..\/input\/training_set.csv')\ntrain.shape\n# Drop object_id\ndel train['object_id']\ntrain['is_train'] = 1","d09f5482":"import time\nstart = time.time()\nchunks = 5000000\nimportances = pd.DataFrame()\nfor i_c, df in enumerate(pd.read_csv('..\/input\/test_set.csv', chunksize=chunks, iterator=True)):\n    # Drop object_id\n    del df['object_id']\n    # Add is_train feature\n    df['is_train'] = 0\n    # Concat\n    full_data = pd.concat([df, train], axis=0).sample(frac=1.0)\n    y = full_data['is_train']\n    del full_data['is_train'], df\n    gc.collect()\n    \n    # Run a lightgbm\n    folds = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)\n    \n    oof_preds = np.zeros(full_data.shape[0])\n    for fold_, (trn_, val_) in enumerate(folds.split(full_data, y)):\n        trn_x, trn_y = full_data.iloc[trn_], y.iloc[trn_]\n        val_x, val_y = full_data.iloc[val_], y.iloc[val_]\n\n        clf = lgb.LGBMClassifier(**lgb_params)\n\n        clf.fit(trn_x, trn_y)\n\n        oof_preds[val_] = clf.predict_proba(val_x)[:, 1]\n\n        imp_df = pd.DataFrame()\n        imp_df['feature'] = full_data.columns\n        imp_df['gain'] = clf.booster_.feature_importance(importance_type='gain')\n        imp_df['split'] = clf.booster_.feature_importance(importance_type='split')\n        imp_df['fold'] = i_c * folds.n_splits + fold_ + 1\n        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n\n        del trn_x, trn_y, val_x, val_y\n        gc.collect()\n\n    print('Train\/Test separation score : %.6f' % roc_auc_score(y, oof_preds))\n    \n    print('Chunk %3d Adversarial validation done [%5.1fmin spent]' % (i_c+1, (time.time() - start)\/60))\n    \n    del full_data\n    gc.collect()\n    \n    if i_c > 4 :\n        break","01e91fc8":"mean_gain = importances[['gain', 'feature']].groupby('feature').mean()\nimportances['mean_gain'] = importances['feature'].map(mean_gain['gain'])\n\nplt.figure(figsize=(8, 12))\nsns.barplot(x='gain', y='feature', data=importances.sort_values('mean_gain', ascending=False))\nplt.tight_layout()","16b198d4":"### Display contributors","3b7e345b":"### Create full dataset","cd4b9cea":"It looks like only meta data features may be a problem.\nWe now need to find a way to predict **class 99**","dcb89456":"### Drop object_id, target and create is_train feature","779c3c4c":"### Run a first Adversarial validation","84816e1e":"Most of the samples in test don't have a **hostgal_specz** measure as it is stated in the data section of the challenge.\n\nTherefore any model trained on it may have trouble generalyzing ...","191f8406":"### Display big contributors","ff107e96":"Test contains a lot more samples so will go through them by chuncks of 5e6","77976760":"This shows that **hostgal_specz** is the biggest contributor by far and that is due to :","d9b45ff3":"### Can we run adversarial validation on train and test datasets","40018dc6":"### Read meta data"}}