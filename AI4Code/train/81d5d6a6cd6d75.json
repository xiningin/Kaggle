{"cell_type":{"6611833a":"code","5ad38be9":"code","d1b0c94f":"code","475a59b2":"code","bfe233bd":"code","518bd218":"code","c65d0671":"code","19fa5642":"code","6380116f":"code","d8b96cbe":"code","47260de8":"code","a9b008c2":"code","4ad8b0a2":"code","18f021e2":"code","932d22fd":"code","0d802d26":"code","49c3b348":"markdown","6052b7e8":"markdown","490f33d9":"markdown","24f04659":"markdown","5f66728a":"markdown","9950e153":"markdown","61317b12":"markdown","a99b6b06":"markdown","0c72b800":"markdown","227103c3":"markdown","94d517e7":"markdown","750ac9cf":"markdown","98c9c618":"markdown","c2cf15a9":"markdown","2ff63ce8":"markdown","520889d7":"markdown","d6589c0b":"markdown"},"source":{"6611833a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfile_list = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        file_list.append(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5ad38be9":"# install dependencies: (use cu101 because colab has CUDA 10.1)\n!pip install -U torch==1.4 torchvision==0.5 -f https:\/\/download.pytorch.org\/whl\/cu101\/torch_stable.html \n!pip install cython pyyaml==5.1\n!pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n!gcc --version\n# opencv is pre-installed on colab","d1b0c94f":"!pip install detectron2 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu101\/index.html","475a59b2":"import math  \nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\nfrom PIL import Image\nimport cv2","bfe233bd":"\nimport requests\n\ndef download_file_from_google_drive(id, destination):\n    URL = \"https:\/\/docs.google.com\/uc?export=download\"\n\n    session = requests.Session()\n\n    response = session.get(URL, params = { 'id' : id }, stream = True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { 'id' : id, 'confirm' : token }\n        response = session.get(URL, params = params, stream = True)\n\n    save_response_content(response, destination)    \n\ndef get_confirm_token(response):\n    for key, value in response.cookies.items():\n        if key.startswith('download_warning'):\n            return value\n\n    return None\n\ndef save_response_content(response, destination):\n    CHUNK_SIZE = 32768\n\n    with open(destination, \"wb\") as f:\n        for chunk in response.iter_content(CHUNK_SIZE):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)","518bd218":"## download the pretrained weights for leaf segmentation.\n\nfile_id = '17AHanttKcR9B4A0m7QZqwAvaWxGrYYQp'\ndestination = '.\/model.pth'\ndownload_file_from_google_drive(file_id, destination)","c65d0671":"#get the predictor\ndef get_predictor():\n\n\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\n    cfg.DATASETS.TRAIN = ()\n    cfg.DATALOADER.NUM_WORKERS = 16\n\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (8)  # faster, and good enough for this toy dataset\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # 3 classes (data, fig, hazelnut)\n\n    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n    \n    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"\/kaggle\/working\/model.pth\")\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n    predictor = DefaultPredictor(cfg)\n    return predictor","19fa5642":"#function to get the leaf image.\n\ndef get_cropped_leaf(img,predictor,return_mapping=False,resize=None):\n    #convert to numpy    \n    img = np.array(img)[:,:,::-1]\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    \n    #get prediction\n    outputs = predictor(img)\n    \n    #get boxes and masks\n    ins = outputs[\"instances\"]\n    pred_masks = ins.get_fields()[\"pred_masks\"]\n    boxes = ins.get_fields()[\"pred_boxes\"]    \n    \n    #get main leaf mask if the area is >= the mean area of boxes and is closes to the centre \n    \n    masker = pred_masks[np.argmin([calculateDistance(x[0], x[1], int(img.shape[1]\/2), int(img.shape[0]\/2)) for i,x in enumerate(boxes.get_centers()) if (boxes[i].area()>=torch.mean(boxes.area()).to(\"cpu\")).item()])].to(\"cpu\").numpy().astype(np.uint8)\n\n    #mask image\n    mask_out = cv2.bitwise_and(img, img, mask=masker)\n    \n    #find contours and boxes\n    contours, hierarchy = cv2.findContours(masker.copy() ,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    contour = contours[np.argmax([cv2.contourArea(x) for x in contours])]\n    rotrect = cv2.minAreaRect(contour)\n    box = cv2.boxPoints(rotrect)\n    box = np.int0(box)\n    \n\n    #crop image\n    cropped = get_cropped(rotrect,box,mask_out)\n\n    #resize\n    rotated = MakeLandscape()(Image.fromarray(cropped))\n    \n    if not resize == None:\n        resized = ResizeMe((resize[0],resize[1]))(rotated)\n    else:\n        resized = rotated\n        \n    if return_mapping:\n        img = cv2.drawContours(img, [box], 0, (0,0,255), 10)\n        img = cv2.drawContours(img, contours, -1, (255,150,), 10)\n        return resized, ResizeMe((int(resize[0]),int(resize[1])))(Image.fromarray(img))\n    \n    return resized\n\n#function to crop the image to boxand rotate\n\ndef get_cropped(rotrect,box,image):\n    \n    width = int(rotrect[1][0])\n    height = int(rotrect[1][1])\n\n    src_pts = box.astype(\"float32\")\n    # corrdinate of the points in box points after the rectangle has been\n    # straightened\n    dst_pts = np.array([[0, height-1],\n                        [0, 0],\n                        [width-1, 0],\n                        [width-1, height-1]], dtype=\"float32\")\n\n    # the perspective transformation matrix\n    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n\n    # directly warp the rotated rectangle to get the straightened rectangle\n    warped = cv2.warpPerspective(image, M, (width, height))\n    return warped\n\ndef calculateDistance(x1,y1,x2,y2):  \n    dist = math.hypot(x2 - x1, y2 - y1)\n    return dist  \n","6380116f":"#image manipulations \n\nclass ResizeMe(object):\n    #resize and center image in desired size \n    def __init__(self,desired_size):\n        \n        self.desired_size = desired_size\n        \n    def __call__(self,img):\n    \n        img = np.array(img).astype(np.uint8)\n        \n        desired_ratio = self.desired_size[1] \/ self.desired_size[0]\n        actual_ratio = img.shape[0] \/ img.shape[1]\n\n        desired_ratio1 = self.desired_size[0] \/ self.desired_size[1]\n        actual_ratio1 = img.shape[1] \/ img.shape[0]\n\n        if desired_ratio < actual_ratio:\n            img = cv2.resize(img,(int(self.desired_size[1]*actual_ratio1),self.desired_size[1]),None,interpolation=cv2.INTER_AREA)\n        elif desired_ratio > actual_ratio:\n            img = cv2.resize(img,(self.desired_size[0],int(self.desired_size[0]*actual_ratio)),None,interpolation=cv2.INTER_AREA)\n        else:\n            img = cv2.resize(img,(self.desired_size[0], self.desired_size[1]),None, interpolation=cv2.INTER_AREA)\n            \n        h, w, _ = img.shape\n\n        new_img = np.zeros((self.desired_size[1],self.desired_size[0],3))\n        \n        hh, ww, _ = new_img.shape\n\n        yoff = int((hh-h)\/2)\n        xoff = int((ww-w)\/2)\n        \n        new_img[yoff:yoff+h, xoff:xoff+w,:] = img\n\n        \n        return Image.fromarray(new_img.astype(np.uint8))\n\nclass MakeLandscape():\n    #flip if needed\n    def __init__(self):\n        pass\n    def __call__(self,img):\n        \n        if img.height> img.width:\n            img = np.rot90(np.array(img))\n            img = Image.fromarray(img)\n        return img\n","d8b96cbe":"predictor = get_predictor()","47260de8":"img, img1 = get_cropped_leaf(Image.open(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_1254.jpg\"),predictor,return_mapping=True,resize = (512,int(512*.7)))","a9b008c2":"img","4ad8b0a2":"img1","18f021e2":"final_image = []\n\nfor x in range(75):\n    #select random image\n    file_loc = file_list[np.random.randint(0,len(file_list))]\n    #get outputs from predictor\n    img, img1 = get_cropped_leaf(Image.open(file_loc),predictor,return_mapping=True,resize = (600,int(600*.65)))\n    #stack horizontally\n    stacked = np.hstack([img,img1])\n    #append images\n    final_image.append(stacked)\n","932d22fd":"import matplotlib.pyplot as plt\n%matplotlib inline","0d802d26":"for x in final_image:\n    fig = plt.figure(figsize=(20,10))\n    plt.imshow(x)","49c3b348":"### Display of multiple images stacked","6052b7e8":"# How to!","490f33d9":"# Inference Method","24f04659":"# Display","5f66728a":"### Below code is to download the pretrained weights from my google drive.","9950e153":"# Imports","61317b12":"# Image segmentation using Detectron2\n\n## Using Detectron2 and mask R-CNN it is possible to isolate each leaf from the input image and extract the most prominent one for later analysis.\n\n### Steps involved:\n\n* Download and install detectron2 and other dependancies\n\n* Hand annotate images with the objects mask (not covered in this kernel) - google \"labelme\" and \"training detectron2 on custom dataset\" \n\n* Train detectron2 (not covered in this kernel) \n\n* Load pretrained weights into detectron2\n\n* Infer image masks and identifiy prominent objects\n\n* Mask and extract from original image\n\n* Crop and rotate object to fit\n\n![Masked1](https:\/\/i.imgur.com\/tnC1ljY.jpg \"Masked Leaf 1\")\n\n![Masked](https:\/\/i.imgur.com\/nemK62H.jpg \"Masked Leaf\")\n\n\n### To Do:\n\n* Futher training of the mask R-CNN model to improve segmentation.\n\n\n","a99b6b06":"# Image manipulations","0c72b800":"### Load the predictor ","227103c3":"## Detectron2 uses pytorch and makes it amazingly easy to retrain its pretrained model on a custom dataset. I won't go into the method of doing this but there is a wealth of information online. \n\n## The python tool \"labelme\" is great for drawing the masks over your images.\n\n![labelme](https:\/\/i.imgur.com\/phNlpnX.jpg \"Label Me\")\n\n\n","94d517e7":"### Get Images","750ac9cf":"### Basic recipe for inferance ","98c9c618":"### Lets then download all of the required libraries to the kaggle kernel ","c2cf15a9":"### First we will list out all the files in the directory for later use.","2ff63ce8":"# Model Collection","520889d7":"### Import the required libraries.","d6589c0b":"### I hope this has been some help to anyone who reads it. "}}