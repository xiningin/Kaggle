{"cell_type":{"5817c56b":"code","d215a7c4":"code","11588564":"code","7d147dce":"code","d24a72a4":"code","3b40057d":"code","79fc4690":"code","75220b26":"markdown"},"source":{"5817c56b":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","d215a7c4":"#create X and Y\nx = np.linspace(0,50,50) + np.random.uniform(-3,3,50)\ny = np.linspace(0,50,50)+ np.random.uniform(-3,5,50)\n\nplt.scatter(x,y)\nplt.title('training')\nplt.show()","11588564":"#X & Y are placeholders , to hold training data on runtime. We'll use stochastic gradient descend (add one training data at a time)\n\nX = tf.placeholder(\"float\")\nY = tf.placeholder(\"float\")\n\n#W & b are variables , which have an initialized value and will be changed during training\nW = tf.Variable(np.random.rand())\nb = tf.Variable(np.random.rand())","7d147dce":"epochs = 1000\nlearning_rate = .01","d24a72a4":"y_pred = tf.add(tf.multiply(W,X),b)\ncost = tf.reduce_sum(tf.pow(y_pred - Y,2))\/100\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)","3b40057d":"init = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(epochs):\n        for _x,_y in zip(x,y):\n            #optimizer will be called , that causes the weights to get corrected\n            sess.run(optimizer,feed_dict={X:_x,Y:_y})\n        if(epoch%50 == 0):\n            print('cost :',sess.run(cost,feed_dict={X:x,Y:y}))\n    finalW = sess.run(W)\n    finalb = sess.run(b)\npredictions = finalW*x + finalb","79fc4690":"#Orange points in the below plots show the prediction\nplt.scatter(x,y)\nplt.scatter(x,predictions)\nplt.show()","75220b26":"**Linear Regressor using Tensorflow**\n\nThis notebook is to have an understanding of how to implement a simple linear regressor (single feature) in tensorflow.\nX and Y are calculated using linspace and a slight noise will be introduced. In the last cell, tou can see the derived linear curve solution."}}