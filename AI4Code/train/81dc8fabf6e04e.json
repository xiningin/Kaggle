{"cell_type":{"131ac821":"code","8f89ffd0":"code","9e6e9f68":"code","e17dbf84":"code","c32dea85":"code","443416c9":"code","a77cb885":"code","893a2448":"code","4bbca703":"code","3c76a0f4":"code","068f78a6":"code","e6372687":"code","24cabbbc":"code","13861014":"code","fd32653b":"code","da8e2bfb":"code","950b2758":"code","04e2497c":"code","68140262":"code","ed9cb1cb":"code","75ee4e23":"code","42f983ac":"code","d1b715c8":"code","283890a8":"code","d06828a2":"code","ba1410ba":"code","1057e2da":"code","fa1058e5":"code","c99569f5":"code","daee2ef9":"code","80c4e00b":"code","2a1aef57":"code","c869f67b":"code","2677924f":"code","2170970f":"code","dbb48bf6":"code","f4329a4e":"code","c5530659":"code","91084c7c":"code","a3a028c9":"code","5228489c":"code","9ac86ca0":"code","2d3f6630":"code","2d975c80":"markdown","58fcb608":"markdown","0ae2aa5e":"markdown","98745536":"markdown","a5866bab":"markdown","ca6a7070":"markdown","d862a6ef":"markdown","cd4e9b29":"markdown","de09459f":"markdown","a680aaf4":"markdown","82fdf220":"markdown","210a3c29":"markdown","5a243f13":"markdown","1b43bc6a":"markdown"},"source":{"131ac821":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrain=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n","8f89ffd0":"test.head()","9e6e9f68":"print(\"train shape: \", train.shape)\nprint(\"test shape: \", test.shape)","e17dbf84":"full_data = [train,test]","c32dea85":"test_ID = test['Id']\n\nfor dataset in full_data:\n    dataset.drop('Id',axis=1,inplace=True)","443416c9":"print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \nprint(\"The test data size after dropping Id feature is : {} \".format(test.shape))","a77cb885":"train['SalePrice'].describe()","893a2448":"from scipy import stats\nfrom scipy.stats import norm, skew\n\nax = sns.distplot(train['SalePrice'],fit = norm)\n(mu, sigma) = norm.fit(train['SalePrice'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')","4bbca703":"print(\"Skewness: %f\" % train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train['SalePrice'].kurt())","3c76a0f4":"fig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'],alpha=0.5)\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","068f78a6":"train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n\nfig, ax = plt.subplots()\nax.scatter(train['GrLivArea'], train['SalePrice'],alpha=0.5)\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","e6372687":"train['SalePrice'] = np.log1p(train['SalePrice'])\n","24cabbbc":"ax = sns.distplot(train['SalePrice'],fit=norm)\n(mu, sigma) = norm.fit(train['SalePrice'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n","13861014":"train_labels = train.pop('SalePrice')","fd32653b":"features = pd.concat([train, test], keys=['train', 'test'])","da8e2bfb":"features.select_dtypes(include='object').isnull().sum()[features.select_dtypes(include='object').isnull().sum()>0]","950b2758":"features.select_dtypes(include=['int','float']).isnull().sum()[features.select_dtypes(include=['int','float']).isnull().sum()>0]","04e2497c":"all_data_na = (features.isnull().sum() \/ len(features)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","68140262":"features.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'],axis=1, inplace=True)","ed9cb1cb":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    features[col] = features[col].fillna('None')","75ee4e23":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    features[col] = features[col].fillna(0)","42f983ac":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath','MasVnrArea'):\n    features[col] = features[col].fillna(0)","d1b715c8":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','MasVnrType'):\n    features[col] = features[col].fillna('None')","283890a8":"for col in ('MSZoning','Exterior1st','Exterior2nd','KitchenQual','SaleType','Functional','Electrical','Utilities'):\n    features[col]=features[col].fillna(features[col].mode()[0])","d06828a2":"features['LotFrontage'] = features['LotFrontage'].fillna(features['LotFrontage'].mean())","ba1410ba":"print(features.isnull().sum().sum())","1057e2da":"from sklearn.preprocessing import LabelEncoder\nlist_of_col = list(features.select_dtypes(include='object').columns)\n\nfor col in list_of_col:\n    lbl = LabelEncoder() \n    lbl.fit(list(features[col].values)) \n    features[col] = lbl.transform(list(features[col].values))\n\n# shape        \nprint('Shape all_data: {}'.format(features.shape))","fa1058e5":"features['TotalSF'] = features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\nfeatures.drop(['TotalBsmtSF', '1stFlrSF', '2ndFlrSF'], axis=1, inplace=True)","c99569f5":"numeric_features = features.loc[:,['LotFrontage', 'LotArea', 'GrLivArea', 'TotalSF']]\nnumeric_features_standardized = (numeric_features - numeric_features.mean())\/numeric_features.std()","daee2ef9":"ax = sns.pairplot(numeric_features_standardized)","80c4e00b":"all_numeric_feats = features.dtypes[features.dtypes != \"object\"].index\nskewed_feats = features[all_numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","2a1aef57":"skewness = skewness[abs(skewness) > 0.75]\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    features[feat] = boxcox1p(features[feat], lam)\n    \nfeatures[skewed_features] = np.log1p(features[skewed_features])","c869f67b":"train_features = features.loc['train'].select_dtypes(include=[np.number])\ntest_features = features.loc['test'].select_dtypes(include=[np.number])","2677924f":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.15, random_state=42)","2170970f":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn import linear_model,svm, ensemble\nfrom sklearn.preprocessing import RobustScaler\n\nlasso = make_pipeline(RobustScaler(), linear_model.Lasso(alpha =0.005, random_state=42)).fit(x_train, y_train)\nridge = linear_model.Ridge(alpha = 0.2, random_state=42).fit(x_train, y_train)\nbayesian = linear_model.BayesianRidge(n_iter=300).fit(x_train, y_train)\nsvr = svm.SVR(kernel=\"linear\").fit(x_train, y_train)\ngbr = ensemble.GradientBoostingRegressor(n_estimators= 1500, max_depth= 4, min_samples_split= 10,\n                                         learning_rate= 0.05, loss='huber').fit(x_train, y_train)","dbb48bf6":"scores = cross_val_score(lasso, x_test, y_test, cv=5)\nprint(\"Lasso R-Square : %0.4f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","f4329a4e":"scores = cross_val_score(ridge, x_test, y_test, cv=5)\nprint(\"Ridge R-Square: %0.4f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","c5530659":"scores = cross_val_score(bayesian, x_test, y_test, cv=5)\nprint(\"BayesianRidge R-Square: %0.4f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","91084c7c":"scores = cross_val_score(svr, x_test, y_test, cv=5)\nprint(\"SupportVectorRegression R-Square: %0.4f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","a3a028c9":"scores = cross_val_score(gbr, x_test, y_test, cv=5)\nprint(\"GradientBoostingRegression R-Square: %0.4f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","5228489c":"pred1 = lasso.predict(test_features)\npred2 = gbr.predict(test_features)\npred3 = svr.predict(test_features)\npred = (np.exp(pred1) + np.exp(pred2) +  np.exp(pred3)) \/ 3 \n","9ac86ca0":"output=pd.DataFrame({'Id':test_ID, 'SalePrice':pred})\noutput.to_csv('submission.csv', index=False)","2d3f6630":"output.head()","2d975c80":"**Missing Values**","58fcb608":"**Categorical**","0ae2aa5e":"**Label Encoding**","98745536":"**Histogram**","a5866bab":"**Models**","ca6a7070":"**Splitting data**","d862a6ef":"**Numerical**","cd4e9b29":"**Linear relationship**","de09459f":"**Adding new feature**","a680aaf4":"**Standardizing numeric data**\n","82fdf220":"**Deleting outliers**","210a3c29":"**Log transformation**","5a243f13":"**Submission**","1b43bc6a":"**Skewed features**\n"}}