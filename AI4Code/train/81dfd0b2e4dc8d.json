{"cell_type":{"b711aa23":"code","d609e4a8":"code","1fe847ba":"code","f71149c6":"code","0eb4491b":"code","da728c39":"code","b8163638":"code","68773b9d":"code","7a28cb7f":"code","31e73390":"code","0723bf11":"code","2c89e4b4":"code","4ea4c283":"code","6fb59cd0":"code","d0cad734":"code","82a45ad7":"code","27d8d70b":"code","e9a432a2":"code","2f55bf8a":"code","a76be3f0":"code","f66ca7ad":"code","71cfe232":"code","a82d3384":"code","03e57bba":"code","b27366bd":"code","62100202":"code","c3b7aa4a":"code","5335ad2a":"code","1374dd0b":"code","aa845484":"code","bc532cd9":"code","39b70bbd":"code","0ba1e3fd":"code","6d12373e":"code","5ffbba03":"code","51a40443":"code","76363c75":"code","65bc8496":"code","6560d7b7":"code","25929a80":"code","5e879bfe":"code","50ac5065":"code","f101d8c0":"code","faf3a8ee":"markdown","9c081a82":"markdown","a56ed67f":"markdown","e2614108":"markdown","4fec94dd":"markdown","f2834c0a":"markdown","d687c87a":"markdown","44631596":"markdown","05f71b40":"markdown","cb85a462":"markdown","27be6ed0":"markdown","7d2284b9":"markdown"},"source":{"b711aa23":"import re # regular expression\nimport math # algebra\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n%matplotlib inline\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # data visualization\n\nfrom sklearn.preprocessing import LabelEncoder # encoding categorical columns\nfrom sklearn.model_selection import train_test_split # split data\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix # evaluation metric\nfrom sklearn.model_selection import KFold, cross_val_score # cross-validation\nimport optuna # hyperparameter tuning\nfrom sklearn.inspection import permutation_importance # feature importance\nfrom xgboost import plot_importance # feature importance\nfrom sklearn.linear_model import LogisticRegression # training model\nfrom sklearn.ensemble import RandomForestClassifier # training model\nfrom xgboost import XGBClassifier # training model\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nRANDOM_SEED = 42","d609e4a8":"%%time\n\n# read train and test datasets in pandas dataframe\ndf_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n# check the numbers of samples and features\nprint(f\"Train dataset has {df_train.shape[0]} samples, {df_train.shape[1]} features.\")\nprint(f\"Test dataset has {df_test.shape[0]} samples, {df_test.shape[1]} features.\\n\")","1fe847ba":"# display the last five rows of the train dataset\ndf_train.tail()","f71149c6":"# display the first five rows of the test dataset\ndf_test.head()","0eb4491b":"# brief summary of train dataset\ndf_train.info()","da728c39":"# statistical summary of train dataset\ndf_train.describe()","b8163638":"# total missing values\nprint(f\"Total missing values in train data: {df_train.isna().sum().sum()}\")\nprint(f\"Total missing values in train data: {df_test.isna().sum().sum()}\")","68773b9d":"# missing values for each column in train dataset\nprint(\"Train dataset: \\n\")\nfor i in df_train.columns[df_train.isnull().any()]:\n    print(f\"{i} - {df_train[i].isnull().sum()} ({round(df_train[i].isnull().sum()\/df_train.shape[0]*100, 2)}%)\")","7a28cb7f":"# missing values for each column in test dataset\nprint(\"Test dataset: \\n\")\nfor i in df_test.columns[df_test.isnull().any()]:\n    print(f\"{i} - {df_test[i].isnull().sum()} ({round(df_test[i].isnull().sum()\/df_test.shape[0]*100, 2)}%)\")","31e73390":"# Cabin column has missing values that we cannot handle, so let's drop it\ndf_train.drop([\"Cabin\"], axis=1, inplace=True)\ndf_test.drop([\"Cabin\"], axis=1, inplace=True)","0723bf11":"# fill missing values with median of male and female\n\nm_train, f_train = df_train.groupby(\"Sex\").Age.median()\n\ndef fillna_train(age, sex):\n    if math.isnan(age):\n        if sex == \"male\":\n            return m_train\n        else:\n            return f_train\n    else:\n        return age\n\ndf_train[\"Age\"] = df_train.apply(lambda x: fillna_train(x[\"Age\"], x[\"Sex\"]), axis = 1)","2c89e4b4":"m_test, f_test = df_test.groupby(\"Sex\").Age.median()\n\ndef fillna_test(age, sex):\n    if math.isnan(age):\n        if sex == \"male\":\n            return m_test\n        else:\n            return f_test\n    else:\n        return age\n\ndf_test[\"Age\"] = df_test.apply(lambda x: fillna_test(x[\"Age\"], x[\"Sex\"]), axis = 1)","4ea4c283":"df_train[\"Embarked\"] = df_train[\"Embarked\"].fillna(df_train.Embarked.mode()[0])\ndf_test[\"Fare\"] = df_test[\"Fare\"].fillna(df_test.Fare.mean())","6fb59cd0":"# total missing values after processing\nprint(f\"Total missing values in train data after processing: {df_train.isna().sum().sum()}\")\nprint(f\"Total missing values in train data after processing: {df_test.isna().sum().sum()}\")","d0cad734":"# check duplicates in datasets\nprint(f\"Total duplicate rows in train data: {df_train[df_train.duplicated()].sum().sum()}\")\nprint(f\"Total duplicate rows in test data: {df_test[df_test.duplicated()].sum().sum()}\")","82a45ad7":"# save the 'id' column\ntrain_id = df_train['PassengerId']\ntest_id = df_test['PassengerId']\n\n# drop the 'id' column for unnecessity\ndf_train.drop(columns='PassengerId', inplace=True)\ndf_test.drop(columns='PassengerId', inplace=True)\n\n# drop the 'Ticket' column for unnecessity\ndf_train.drop(columns='Ticket', inplace=True)\ndf_test.drop(columns='Ticket', inplace=True)","27d8d70b":"df_train.head()","e9a432a2":"# Concatenate train and test dataset\ndf = pd.concat([df_train.drop('Survived', axis=1, inplace=False), df_test])\nprint(f\"Full dataset has {df.shape[0]} rows, {df.shape[1]} columns.\")","2f55bf8a":"df.Age.hist(bins=20, figsize=(5, 5))\nplt.ylabel(\"Count\")\nplt.xlabel(\"Age\")\nplt.show()","a76be3f0":"df.Sex.value_counts().plot(kind=\"barh\")\nplt.ylabel(\"Sex\")\nplt.xlabel(\"Count\")\nplt.show()","f66ca7ad":"df.Pclass.value_counts().plot(kind=\"barh\")\nplt.ylabel(\"Class\")\nplt.xlabel(\"Count\")\nplt.show()","71cfe232":"# 1 - Survived, 0 - Unable to survive\nprint(df_train.Survived.value_counts())\ndf_train.Survived.value_counts().plot(kind='barh')\nplt.xlabel('Count')\nplt.ylabel('Survived')\nplt.show()","a82d3384":"# 38% survived, 62% unable to survive  \nprint(round(df_train.Survived.value_counts(normalize=True)*100, 2))\n(df_train.Survived.value_counts(normalize=True)*100).plot(kind='barh')\nplt.xlabel('% of survival')\nplt.ylabel('Survived')\nplt.show()","03e57bba":"# encode name column\ndf_train['Name'] = df_train['Name'].apply(lambda x: re.search(r\"(?<=\\, )(.*?)(?=\\.)\", x).group())\ndf_test['Name'] = df_test['Name'].apply(lambda x: re.search(r\"(?<=\\, )(.*?)(?=\\.)\", x).group())","b27366bd":"# concatenate 'SibSp' and 'Parch' columns\ndf_train['isAlone'] = df_train.pop('SibSp') + df_train.pop('Parch')\ndf_test['isAlone'] = df_test.pop('SibSp') + df_test.pop('Parch')","62100202":"# round values of 'Fare' column\ndf_train[\"Fare\"] = df_train[\"Fare\"].apply(lambda x: round(x, 2))\ndf_test[\"Fare\"] = df_test[\"Fare\"].apply(lambda x: round(x, 2))","c3b7aa4a":"df_train.head()","5335ad2a":"def transform(df):\n    if df == 'Mr' or df == 'Miss' or df == 'Mrs' or df == 'Master':\n        return df\n    else:\n        return 'Other'\n\ndf_train['Name'] = df_train['Name'].apply(transform)\ndf_test['Name'] = df_test['Name'].apply(transform)","1374dd0b":"print(f\"Unique values of Sex column: {df_train.Sex.unique()}\")\nprint(f\"Unique values of Embarked column: {df_train.Embarked.unique()}\")\nprint(f\"Unique values of Name column: {df_train.Name.unique()}\")\nprint(f\"Unique values of isAlone column: {df_train.isAlone.unique()}\")","aa845484":"# encode 'Sex' column\nencode_sex = LabelEncoder()\ndf_train[\"Sex\"] = encode_sex.fit_transform(df_train[\"Sex\"]) \ndf_test[\"Sex\"] = encode_sex.transform(df_test[\"Sex\"]) ","bc532cd9":"# encode 'Embarked' column\nencode_embarked = {\"S\": 0, \"C\": 1, \"Q\": 2}\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].replace(encode_embarked)\ndf_test[\"Embarked\"] = df_test[\"Embarked\"].replace(encode_embarked)","39b70bbd":"# encode 'Name' column\ndf_train['Name'] = df_train['Name'].map({'Mr': 1, 'Mrs': 2, 'Miss': 3, 'Master': 4, 'Other': 5})\ndf_test['Name'] = df_test['Name'].map({'Mr': 1, 'Mrs': 2, 'Miss': 3, 'Master': 4, 'Other': 5})","0ba1e3fd":"def encode_isAlone(df):\n    if df > 0:\n        return 0\n    else:\n        return 1\n\ndf_train[\"isAlone\"] = df_train[\"isAlone\"].apply(encode_isAlone)\ndf_test[\"isAlone\"] = df_test[\"isAlone\"].apply(encode_isAlone)","6d12373e":"print(\"After encoding:\")\nprint(f\"Unique values of Sex column - {df_train.Sex.unique()}\")\nprint(f\"Unique values of Embarked column - {df_train.Embarked.unique()}\")\nprint(f\"Unique values of Name column: {df_train.Name.unique()}\")\nprint(f\"Unique values of isAlone column: {df_train.isAlone.unique()}\")","5ffbba03":"df_train.head()","51a40443":"print(f\"Train: {df_train.shape} \\nTest: {df_test.shape}\")","76363c75":"# declare feature vector and target variable\nX = df_train.drop('Survived', axis=1, inplace=False)\ny = df_train.Survived\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)\n\nprint(f\"Train dataset shape: {X_train.shape}\")\nprint(f\"Validation dataset shape: {X_valid.shape}\")","65bc8496":"# Logistic Regression\nlog_reg = LogisticRegression(solver='liblinear', random_state=0).fit(X_train, y_train)\nlog_reg_preds = log_reg.predict(X_valid)\nprint(\"Accuracy:\", accuracy_score(y_valid, log_reg_preds))\nprint(\"Precision:\", precision_score(y_valid, log_reg_preds))\nprint(\"Recall:\", recall_score(y_valid, log_reg_preds))","6560d7b7":"confusion_matrix(y_valid, log_reg_preds)","25929a80":"# XGBoost\nxgb_clf = XGBClassifier(eval_metric='logloss', random_state=0).fit(X_train, y_train)\nxgb_clf_preds = xgb_clf.predict(X_valid)\nprint(\"Accuracy:\", accuracy_score(y_valid, xgb_clf_preds))\nprint(\"Precision:\", precision_score(y_valid, xgb_clf_preds))\nprint(\"Recall:\", recall_score(y_valid, xgb_clf_preds))","5e879bfe":"confusion_matrix(y_valid, xgb_clf_preds)","50ac5065":"# RandomForest Classifier\nrndm_frst = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0).fit(X_train, y_train)\n# rndm_frst = RandomForestClassifier(random_state=0).fit(X_train, y_train)\nrndm_frst_preds = rndm_frst.predict(X_valid)\nprint(\"Accuracy:\", accuracy_score(y_valid, rndm_frst_preds))\nprint(\"Precision:\", precision_score(y_valid, rndm_frst_preds))\nprint(\"Recall:\", recall_score(y_valid, rndm_frst_preds))","f101d8c0":"# RandomForest Classifier\nmodel = RandomForestClassifier(n_estimators=100, \n                               max_depth=5, \n                               random_state=0).fit(X, y)\npredictions = model.predict(df_test)\n\noutput = pd.DataFrame({'PassengerId': test_id, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","faf3a8ee":"# Handle unnecessary columns","9c081a82":"# Model Training","a56ed67f":"# Load and read datasets","e2614108":"# Split data into Train and Test sets","4fec94dd":"# Handle missing values","f2834c0a":"# Data Visualization","d687c87a":"# Handle duplicate values","44631596":"# Imports","05f71b40":"# Submission","cb85a462":"# Feature Engineering","27be6ed0":"# Label Encoding","7d2284b9":"## Baseline models"}}