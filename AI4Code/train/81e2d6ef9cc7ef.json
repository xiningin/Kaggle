{"cell_type":{"95c92d80":"code","140b2ff7":"code","d84e95f2":"code","f290f540":"code","ff12f9ff":"code","c320f9ab":"code","a0aad94b":"markdown","cb8d432b":"markdown","45e45584":"markdown","f6a0ddbb":"markdown","52066e13":"markdown","3cc7906e":"markdown","220a37c0":"markdown"},"source":{"95c92d80":"import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nimport random\nimport warnings\nimport glob\nimport shutil\nimport tensorflow as tf\nimport tensorflow.keras.applications.efficientnet as efn\nimport tensorflow.keras.backend as K\nfrom pathlib import Path\nfrom tensorflow.random import set_seed\nfrom tensorflow.keras.models import Model, model_from_json\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, concatenate, BatchNormalization\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings('ignore')","140b2ff7":"CFG = {\n    'load_dir':\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/\",\n    'train_csv_name':\"train.csv\",\n    'submit_csv_name':\"sample_submission.csv\",\n    'batch_size':32,\n    'epoch':20,\n    'seed':20210222,\n    'size_x':(224, 240, 260, 300, 380, 456, 528, 600),  # efficientnetB0\uff5eB07\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\n    'size_y':(224, 240, 260, 300, 380, 456, 528, 600),  # efficientnetB0\uff5eB07\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\n    'channel':3,\n    'fold':3,\n    'label_num':11,\n}","d84e95f2":"def seed_set(seed):\n    \"\"\"\n    Seed\u5024\u306e\u56fa\u5b9a\n    \"\"\"\n    # tendorflow seed\n    set_seed(seed)\n    # for numpy.random\n    np.random.seed(seed)\n    # for built-in random\n    random.seed(seed)\n    # for hash seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\ndef build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n    \"\"\"\n    \u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u5185\u3067\u753b\u50cf\u30d1\u30b9\u304b\u3089\u8aad\u307f\u8fbc\u3093\u3067\u524d\u51e6\u7406\u3059\u308b\n    \"\"\"\n    def decode(path):\n        \n        file_bytes = tf.io.read_file(path) \n\n        if ext == 'png':\n            # PNG\u3067\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u305f\u753b\u50cf\u3092 uint8 \u307e\u305f\u306f uint16 \u306e\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\n            img = tf.image.decode_png(file_bytes, channels=3) \n        elif ext in ['jpg', 'jpeg']:\n            # JPEG\u3067\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u305f\u753b\u50cf\u3092uint8\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n        # float32\u578b\u306b\u5909\u63db\u3057\u3066\u6b63\u898f\u5316\n        img = tf.cast(img, tf.float32) \/ 255.0\n        # \u30ea\u30b5\u30a4\u30ba\u51e6\u7406\n        img = tf.image.resize(img, target_size)\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\n# \u30c7\u30fc\u30bf\u5897\u5f37\ndef build_augmenter(with_labels=True):\n    \"\"\"\n    \u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u5185\u3067\u30c7\u30fc\u30bf\u5897\u5f37\u95a2\u6570\n    \"\"\"\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)  # \u30e9\u30f3\u30c0\u30e0\u3067\u6c34\u5e73\u65b9\u5411\u306b\u53cd\u8ee2\n        img = tf.image.random_flip_up_down(img)  # \u30e9\u30f3\u30c0\u30e0\u3067\u5782\u76f4\u65b9\u5411\u306b\u53cd\u8ee2\n#         img = tf.image.random_saturation(img, 0.8, 1.2)  # RGB\u753b\u50cf\u306e\u5f69\u5ea6\u3092\u8abf\u6574\n        img = tf.image.random_brightness(img, 0.2) # \u753b\u50cf\u306e\u660e\u308b\u3055\u3092\u8abf\u6574\n        img = tf.image.random_contrast(img, 0.8, 1.2)  # \u753b\u50cf\u306e\u30b3\u30f3\u30c8\u30e9\u30b9\u30c8\u3092\u8abf\u6574\n#         img = tf.image.random_hue(img, 0.2)  # RGB\u753b\u50cf\u306e\u8272\u76f8\u3092\u8abf\u6574\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    \"\"\"\n    \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u69cb\u7bc9\u3057\u3066\u30c7\u30fc\u30bf\u3092\u5410\u304d\u51fa\u3059\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u3092\u4f5c\u6210\u3059\u308b\u95a2\u6570\u3002\n    \"\"\"\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4f5c\u6210\n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    # \u5024\u3092\u76f4\u63a5\u5909\u3048\u308b\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3(\u203b\u753b\u50cf\u306e\u524d\u51e6\u7406(\u30ea\u30b5\u30a4\u30ba\u30fb\u6b63\u898f\u5316 etc)\u3092\u884c\u3046)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)  \n    # \u9ad8\u901f\u5316\u306e\u305f\u3081\u524d\u51e6\u7406\u5f8c\u306e\u30c7\u30fc\u30bf\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u3057\u3066\u4fdd\u6301\u3057\u3066\u304a\u304f\u3002\n    dset = dset.cache(cache_dir) if cache else dset  \n    # \u5024\u3092\u76f4\u63a5\u5909\u3048\u308b\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3(\u30c7\u30fc\u30bf\u5897\u5f37)\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset \n    # \u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u56de\u6570Repeat\u3059\u308b \n    dset = dset.repeat() if repeat else dset\n    # \u30c7\u30fc\u30bf\u3092shuffle\u3059\u308b\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    # \u30e2\u30c7\u30eb\u306e\u8a13\u7df4\u4e2d\u306b\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30d0\u30c3\u30c1\u53d6\u5f97\u3002\n    dset = dset.batch(bsize).prefetch(AUTO)\n    return dset\n\ndef load_model(h_size_x, h_size_y, h_channel, h_n_labels, h_trainable=True):\n    \"\"\"\n    imagenet\u5b66\u7fd2\u6e08\u306eEfficientNet\u3092\u69cb\u7bc9\u3059\u308b\u3002\n    \"\"\"\n    model_path = '..\/input\/tfkeras-efficientnet-weights\/efficientnetb2_notop.h5'  # imagenet\n    # EfficientNet\u306einagenet\u5b66\u7fd2\u6e08\u30e2\u30c7\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n    eff_net = efn.EfficientNetB2(weights=model_path, include_top=False, input_shape=(h_size_x, h_size_y, h_channel))\n    # True\u306e\u5834\u5408\u3001EfficientNet\u306e\u306b\u5bfe\u3057\u3066Fine\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u65bd\u3059\u308b\u3002\n    eff_net.trainable = h_trainable\n    x = eff_net.output\n    x1 = GlobalAveragePooling2D()(x) \n    x2 = GlobalMaxPooling2D()(x)\n    x = concatenate([x1, x2])\n    x = BatchNormalization()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(252, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    # \u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u305f\u3081\u3001\u51fa\u529b\u5c64\u306fsofmax\u3067\u306f\u306a\u304f\u3001sigmoid\u95a2\u6570\u3092\u8a2d\u5b9a\u3059\u308b\u3002\n    predictions = Dense(h_n_labels, activation='sigmoid')(x)\n    model = Model(inputs = eff_net.input, outputs = predictions)\n    return model\n\ndef load_dataset(h_train_paths, h_labels, h_size_x, h_size_y, h_n_splits, h_seed=None):\n    \"\"\"\n    \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8gnerator\u3092\u53d6\u5f97\u3059\u308b\n    \"\"\"\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7f6e\u306e\u5b9a\u7fa9\n    decoder = build_decoder(with_labels=True, target_size=(h_size_x, h_size_y))\n\n    dtrain_list = []\n    dvalid_list = []\n    train_paths_len_list = []\n\n    # Ffold\n#     kf = StratifiedKFold(h_n_splits, shuffle=True)\n    kf = KFold(n_splits=h_n_splits, shuffle=True)\n    for train_index, test_index in kf.split(h_train_paths, h_labels):\n        train_data = h_train_paths[train_index]\n        train_label = h_labels[train_index]\n        val_data = h_train_paths[test_index]\n        val_label = h_labels[test_index]\n\n        train_paths_len_list.append(len(train_data))\n\n        # train\u30c7\u30fc\u30bfgenerator\u3092\u751f\u6210\n        dtrain_list.append(build_dataset(\n            train_data, train_label, bsize=CFG['batch_size'], augment=True,\n            cache_dir='.\/cache\/tf_cache', decode_fn=decoder\n        ))\n\n        # validtion\u30c7\u30fc\u30bfgenerator\u3092\u751f\u6210\n        dvalid_list.append(build_dataset(\n            val_data, val_label, bsize=CFG['batch_size'], \n            repeat=False, shuffle=False, augment=True, \n            cache_dir='.\/cache\/tf_cache', decode_fn=decoder\n        ))\n\n    return dtrain_list, dvalid_list, train_paths_len_list","f290f540":"# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\nload_dir = CFG['load_dir']\n\n# train\u30c7\u30fc\u30bf\u306e\u30d1\u30b9\u3092\u8aad\u307f\u8fbc\u307f\ndf = pd.read_csv(CFG['load_dir'] + CFG['train_csv_name'])\ntrain_paths = CFG['load_dir'] + \"train\/\" + df['StudyInstanceUID'] + '.jpg'\n\n# test\u30c7\u30fc\u30bf\u306e\u30d1\u30b9\u3092\u8aad\u307f\u8fbc\u307f\nsub_df = pd.read_csv(CFG['load_dir'] + CFG['submit_csv_name'])\ntest_paths = CFG['load_dir'] + \"test\/\" + sub_df['StudyInstanceUID'] + '.jpg'\n\n# label\u30c7\u30fc\u30bf\u3092\u751f\u6210\nlabel_cols = sub_df.columns[1:]\nlabels = df[label_cols].values","ff12f9ff":"# seed\u5024\u3092\u56fa\u5b9a\u3059\u308b\nseed_set(CFG[\"seed\"])\n\n# input\u306esize\u3092\u8a2d\u5b9a\nsize_x = CFG[\"size_x\"][2]\nsize_y = CFG[\"size_y\"][2]\n\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30ed\u30fc\u30c9\u3059\u308b\ndtrain_list, dvalid_list, train_len_list = load_dataset(train_paths, labels, size_x, size_y, CFG['fold'], h_seed=CFG[\"seed\"])\n\n# Fold\nfor i, (dtrain, dvalid, shape) in enumerate(zip(dtrain_list, dvalid_list, train_len_list)):\n    # \uff11\u30a8\u30dd\u30c3\u30af\u3067\u5168\u753b\u50cf\u3092\u51e6\u7f6e\u3059\u308b\n    steps_per_epoch = shape \/\/ CFG['batch_size']\n    # imagenet\u5b66\u7fd2\u6e08\u306e\u30e2\u30c7\u30eb\u3092\u53d6\u5f97\n    model = load_model(size_x, size_y, CFG[\"channel\"], CFG[\"label_num\"], h_trainable=True)\n    # \u30e2\u30c7\u30eb\u30b3\u30f3\u30d1\u30a4\u30eb\n    model.compile(\n        optimizer=optimizers.Adam(lr=0.001),\n        loss='binary_crossentropy', \n        metrics=[tf.keras.metrics.AUC(multi_label=True)]\n    )\n    # checkpoint\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u3059\u308b\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\n    checkpoint = tf.keras.callbacks.ModelCheckpoint('.\/model_Fold{}.h5'.format(str(i)), save_best_only=True, monitor='val_loss', mode='min')\n\n    # \u5b66\u7fd2\u304c\u505c\u6ede\u3057\u305f\u3089\u3001\u5b66\u7fd2\u7387\u3092\u534a\u6e1b\u3059\u308b\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\n    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=3, min_lr=1e-6, mode='min')\n    \n    # \u5b66\u7fd2\n    history = model.fit(\n        dtrain, \n        epochs=CFG[\"epoch\"],\n        verbose=1,\n        callbacks=[checkpoint, lr_reducer],\n        steps_per_epoch=steps_per_epoch,\n        validation_data=dvalid\n        )","c320f9ab":"# \u30e2\u30c7\u30eb\u69cb\u9020\u306e\u8aad\u307f\u8fbc\u307f\nsize_x = CFG[\"size_x\"][2]\nsize_y = CFG[\"size_y\"][2]\nmodel = load_model(size_x, size_y, CFG[\"channel\"], CFG[\"label_num\"], h_trainable=True)\n\n# test\u30c7\u30fc\u30bf\u306e\u30d1\u30b9\u3092\u8aad\u307f\u8fbc\u307f\nsub_df = pd.read_csv(CFG['load_dir'] + CFG['submit_csv_name'])\ntest_paths = CFG['load_dir'] + \"test\/\" + sub_df['StudyInstanceUID'] + '.jpg'\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7f6e\u306e\u5b9a\u7fa9\ntest_decoder = build_decoder(with_labels=False, target_size=(size_x, size_y))\n\n# test\u30c7\u30fc\u30bfgenerator\u3092\u751f\u6210\ndtest = build_dataset(\n    test_paths, bsize=CFG['batch_size'], repeat=False, \n    shuffle=False, augment=False, cache=False, \n    decode_fn=test_decoder\n)\n\n# \u63a8\u8ad6\nfor i in range(CFG['fold']):\n    model.load_weights('.\/model_Fold{}.h5'.format(str(i)))\n    if i==0:\n        pred = model.predict(dtest, verbose=1)\n    else:\n        pred = pred + model.predict(dtest, verbose=1)\n\n# \u5f8c\u51e6\u7406\nsub_df[label_cols] = pred \/ CFG['fold']\nsub_df.to_csv('submission.csv', index=False)\n\nsub_df.head()","a0aad94b":"# \u5404\u7a2e\u30d1\u30b9\u53d6\u5f97\u3068\u30e9\u30d9\u30eb\u751f\u6210","cb8d432b":"# Import","45e45584":"# Settings","f6a0ddbb":"# Functions","52066e13":"# \u63a8\u8ad6","3cc7906e":"# \u5b66\u7fd2","220a37c0":"# Concept\n- FOLD\u5225\u306e\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u3092\u884c\u3046\u3002"}}