{"cell_type":{"42fc6534":"code","05dd8d8c":"code","00d1c244":"code","4cde4d84":"code","d07fdf47":"code","404c9337":"code","ea4d680e":"code","6aab9430":"code","0430effb":"code","87ea2ae4":"code","f9a7eca6":"code","1bfefe7d":"code","efe41528":"code","ad409b8d":"markdown","e04df936":"markdown","e614e019":"markdown","2d78d614":"markdown","c0f124bb":"markdown","df6aacde":"markdown","e0537508":"markdown","39041885":"markdown","73c7ba74":"markdown"},"source":{"42fc6534":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05dd8d8c":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","00d1c244":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","4cde4d84":"def train_val_processing(main_data,split=0.8):\n    data=main_data.copy()\n    \n    train=data.iloc[:int(split*data.shape[0]),:]\n    y_train=train.pop('label')\n    validation=data.iloc[int(split*data.shape[0]):,:]\n    validation_y=validation.pop('label')\n    train_dataset=tf.data.Dataset.from_tensor_slices((train.to_numpy().reshape(-1,28,28,1).astype('float32')\/255.0,y_train.to_numpy().reshape(-1,1)))\n    validation_dataset=tf.data.Dataset.from_tensor_slices((validation.to_numpy().reshape(-1,28,28,1).astype('float32')\/255.0,validation_y.to_numpy().reshape(-1,1)))\n    \n    \n    \n    return train_dataset.shuffle(36000).batch(32),validation_dataset.shuffle(36000).batch(32)\n\n    ","d07fdf47":"train_dataset,validation_dataset=train_val_processing(train_data,split=0.8)\ntest=test_data.to_numpy().reshape(-1,28,28,1).astype('float32')\/255.0","404c9337":"len(validation_dataset)","ea4d680e":"class simpleDense(tf.keras.layers.Layer):\n\n    \n    def __init__(self, units=32, activation=None):\n        super(simpleDense, self).__init__()\n        self.units = units\n        \n        \n        self.activation = tf.keras.activations.get(activation)\n\n\n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.w = tf.Variable(name=\"kernel\",\n            initial_value=w_init(shape=(input_shape[-1], self.units),\n                                 dtype='float32'),\n            trainable=True)\n        b_init = tf.zeros_initializer()\n        self.b = tf.Variable(name=\"bias\",\n            initial_value=b_init(shape=(self.units,), dtype='float32'),\n            trainable=True)\n        super().build(input_shape)\n\n\n    def call(self, inputs):\n        \n        \n        return self.activation(tf.matmul(inputs, self.w) + self.b)","6aab9430":"class Digit_model(tf.keras.Model):\n    def __init__(self,n_class):\n        super(Digit_model,self).__init__()\n        self.conv1=tf.keras.layers.Conv2D(64,(3,3),activation='relu')\n        self.conv2=tf.keras.layers.Conv2D(128,(3,3),activation='relu')\n        self.bn1=tf.keras.layers.BatchNormalization()\n        self.bn2=tf.keras.layers.BatchNormalization()\n        self.pool=tf.keras.layers.MaxPool2D()\n        self.gap=tf.keras.layers.GlobalAveragePooling2D()\n        self.flat=tf.keras.layers.Flatten()\n        self.cus_layer=simpleDense(128, activation='relu')\n        self.drop=tf.keras.layers.Dropout(0.2)\n        self.classifier=tf.keras.layers.Dense(n_class, activation='softmax')\n    def call(self,inputs):\n        \n        x=self.conv1(inputs)\n        x=self.bn1(x)\n        x=self.pool(x)\n        x=self.conv2(x)\n        x=self.bn2(x)\n        x=self.gap(x)\n        x=self.flat(x)\n        x=self.cus_layer(x)\n        x=self.drop(x)\n        return self.classifier(x)","0430effb":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28, 28,1)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D((3,3)),\n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Flatten(),\n    simpleDense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation='softmax')\n])","87ea2ae4":"model=Digit_model(10)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","f9a7eca6":"EPOCHS=100\n\nhistory = model.fit(train_dataset,\n                    \n                    validation_data=validation_dataset, epochs=EPOCHS)","1bfefe7d":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc=0)\nplt.figure()\nplt.plot(epochs, loss , 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc=0)\nplt.figure()\n\nplt.figure()\n\n\n","efe41528":"y_pred = model.predict(test)\n\nfinal_ans = []\nfor i in range(y_pred.shape[0]):\n    final_ans.append(np.argmax(y_pred[i]))\n\npd.DataFrame({'ImageId':range(1,28001),'Label':final_ans}).to_csv('submission.csv',index=False)","ad409b8d":"Data processing","e04df936":"Importing Essential Library","e614e019":"**Model Define model**\n![]([](http:\/\/)https:\/\/cdn-images-1.medium.com\/max\/980\/1*vczqmHklozzgLpZxKAZEjw.jpeg)","2d78d614":"**Model**","c0f124bb":"**Performance Visualization**","df6aacde":"**Submittion**","e0537508":"Importing data","39041885":"Custom Layer","73c7ba74":"Initialization"}}