{"cell_type":{"346bd1aa":"code","4a10ed7f":"code","fc4080f8":"code","14fc4b49":"code","03c82708":"code","69f978e8":"code","c093e0a7":"code","5b54a679":"code","38c8a73f":"code","70e9512d":"code","752308c0":"code","bf5cd910":"code","ed435a6d":"code","fc6a85f2":"code","b76aceb0":"markdown","11a76440":"markdown","c67f76f3":"markdown","b31b146c":"markdown","09cd1a2f":"markdown","85d134a5":"markdown","4516fd40":"markdown","4be88450":"markdown","203f6913":"markdown","d21b05b1":"markdown","b5208515":"markdown","9b8f5f3e":"markdown"},"source":{"346bd1aa":"import numpy as np  # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n                                 \nimport warnings     # `do not disturbe` mode\nwarnings.filterwarnings('ignore')","4a10ed7f":"forest_train = pd.read_csv('..\/input\/learn-together\/train.csv')\n# print a summary of the data\nforest_train.describe()","fc4080f8":"forest_train.isnull().values.any()","14fc4b49":"forest_train.columns","03c82708":"y = forest_train.Cover_Type","69f978e8":"forest_features = ['Elevation', 'Aspect', \n                   'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', \n                   'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n\nX = forest_train[forest_features]\n\nX.describe()","c093e0a7":"X.head()","5b54a679":"from sklearn.tree import DecisionTreeRegressor\n\n# Define model. Specify a number for random_state to ensure same results each run\nforest_model = DecisionTreeRegressor(random_state=1)\n\n# Fit model\nforest_model.fit(X, y)","38c8a73f":"print(\"Making predictions for the following 5 trees:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(forest_model.predict(X.head()))","70e9512d":"from sklearn.metrics import mean_absolute_error\n\npredicted_cover_type = forest_model.predict(X)\nmean_absolute_error(y, predicted_cover_type)","752308c0":"from sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both features and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n# Define model\nforest_model = DecisionTreeRegressor()\n# Fit model\nforest_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_predictions))","bf5cd910":"def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\n# compare MAE with differing values of max_leaf_nodes\nfor max_leaf_nodes in [5, 50, 200, 500]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %.2f\" %(max_leaf_nodes, my_mae))","ed435a6d":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nr_forest_model = RandomForestRegressor(n_estimators=1100,\n                                       max_features=4,\n                                       random_state=70,\n                                       max_depth=120,\n                                       bootstrap=True)\n\nr_forest_model.fit(train_X, train_y)\nr_forest_preds = r_forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, r_forest_preds))","fc6a85f2":"# path to file you will use for predictions\ntest_data_path = '..\/input\/learn-together\/test.csv'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\n\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = test_data[forest_features]\n\n# make predictions which we will submit. \ntest_preds = np.round(r_forest_model.predict(test_X)).astype(int)\n\n# The lines below shows how to save predictions in format used for competition scoring\n# Just uncomment them.\n\noutput = pd.DataFrame({'Id': test_data.Id,\n                       'Cover_Type': test_preds})\noutput.to_csv('submission.csv', index=False)","b76aceb0":"**Selecting The Prediction Target**","11a76440":"**Model Validation**","c67f76f3":"# Make Predictions\nRead the file of \"test\" data. And apply model to make predictions","b31b146c":"**Next model - random forest**","09cd1a2f":"Just for safety check if any data is missing","85d134a5":"**Building Model**","4516fd40":"**Choosing \"Features\"**","4be88450":"**Basic Data Exploration**","203f6913":"Looks better and believable. Now experiment with different models","d21b05b1":"Hmm, zero **MAE** does not look right. The most straightforward way to improve this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before.","b5208515":"**Selecting Data for Modeling**\n\nStart by picking a few columns using intuition.","9b8f5f3e":"We now have a fitted model that we can use to make predictions."}}