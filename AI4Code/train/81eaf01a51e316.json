{"cell_type":{"46699e72":"code","ae65fa30":"code","95734168":"code","f96d5fdf":"code","c28e2ab1":"code","bf976ef1":"code","a6691651":"code","aee3c071":"code","5177374c":"code","58177585":"code","9173df8b":"code","5e345488":"code","7b349e06":"code","e95ff9ee":"code","eac4caa7":"code","9817fe6b":"code","fd482897":"code","70190616":"code","ca4f658b":"code","8482ed36":"code","5c0a23e9":"code","88b7995e":"code","d70dc2f8":"code","288cd27a":"code","74196a82":"code","ebb81214":"code","4db1976c":"code","a218d0c5":"markdown","f3527a62":"markdown","e47938e6":"markdown","e5be6da4":"markdown","899d5c73":"markdown","a91945b9":"markdown","28b7d6cf":"markdown","e9c2f268":"markdown","6bf70c5d":"markdown","86a59bd1":"markdown","43209701":"markdown","cf6eaca3":"markdown","81d92a55":"markdown","3944c334":"markdown","8090258e":"markdown","f19e4838":"markdown","9db520a6":"markdown","676dedfc":"markdown","07f2ebe8":"markdown","1746cf39":"markdown","a5010479":"markdown","b1a14e41":"markdown","b24bb58b":"markdown","ed82e8a8":"markdown","5073f09c":"markdown","47d10676":"markdown","f59d6cb7":"markdown","b7f0351d":"markdown"},"source":{"46699e72":"# INSTALL\n# Latest version of tensorflow, which comes with useful image loading APIs\n!pip install tf-nightly  # run only once per session\n\n# IMPORT\n\n## Magic commands for interactivity\n%pylab inline                 \n\n## Basic Utilities  \nimport sys                    # Enabler of operating system dependent functionality\nimport os                     # Provides access to some variables & functions for the interpreter\nimport shutil                 # Provides high-level operations on files and collections of files\nfrom shutil import copyfile   # Import module we'll need to import our custom module\nimport math                   # Provides access to basic mathematical functions\nimport time                   # Provides various time-related functions\nimport glob                   # Pathnames management\nfrom PIL import Image as pil_image\nimport itertools\n\n## Data Manipulation & Analysis\nimport pandas as pd           # Methods to manipulate, filter, group, and transform data\nimport numpy as np            # Efficient storage and computation for multi-dimensional data arrays\nfrom numpy import expand_dims\n\n## Data Visualization \nimport matplotlib             # Interface for creation of publication-quality plots and figures\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport matplotlib.image as mpimg\nimport seaborn as sns         # Matplotlib-based statistical data visualization interface \n### import plotly             # Interactive plotting library \nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n## Machine Learning \n### Scikit-Learn\nfrom sklearn.model_selection import train_test_split # Split arrays or matrices into random train and test subsets\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.decomposition import PCA, TruncatedSVD # Principal component analysis (PCA); dimensionality reduction using truncated SVD.\n### TensorFlow\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img, save_img\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.optimizers import Adam , RMSprop\n### SMOTE\nfrom imblearn.over_sampling import SMOTE # Class Balancing ","ae65fa30":"# Here we get an insight of the datasets\n\nkaggle = True\nif kaggle:\n    outdir = r\"..\/working\/\"\n    indir = r\"..\/input\/plantvillage\/\"\nelse:\n    outdir = r\"Q:\/tooBigToDrive\/plantsvillage\/temp\/\"\n    indir = r\"Q:\/tooBigToDrive\/plantsvillage\/\"\n    \ntest_dir = indir + \"plantvillage_split_dataset\/test_images\"\ntrain_labels_csv = pd.read_csv(indir+\"plantvillage_split_dataset\/train.csv\")\nprint(train_labels_csv.head())\nprint(\"-------------------------------------\")\nexample_submission_csv = pd.read_csv(indir+\"plantvillage_split_dataset\/sample_submission.csv\")\nprint(example_submission_csv.head() )\nprint(\"-------------------------------------\")\ntest_csv = pd.read_csv(indir+\"plantvillage_split_dataset\/test.csv\")\ntest_paths_csv= pd.DataFrame(test_csv[\"image_id\"].apply(lambda x: test_dir+\"\/\"+x+\".jpg\"))\nprint(test_paths_csv.head() )","95734168":"# Create csv files with images\ntrain_val_healthy_csv = train_labels_csv[train_labels_csv[\"healthy\"] == 1]\ntrain_val_multiple_diseases_csv  = train_labels_csv[train_labels_csv[\"multiple_diseases\"] == 1]\ntrain_val_rust_csv = train_labels_csv[train_labels_csv[\"rust\"] == 1]\ntrain_val_scab_csv = train_labels_csv[train_labels_csv[\"scab\"] == 1]\n\n# We will check that this has no entry\ntwo_classes = train_labels_csv[(train_labels_csv[\"scab\"] == 1) & (train_labels_csv[\"multiple_diseases\"] == 1)]\n\ntrain_val_healthy_names = train_val_healthy_csv[\"image_id\"].tolist()\ntrain_val_multiple_diseases_names = train_val_multiple_diseases_csv[\"image_id\"].tolist()\ntrain_val_rust_names = train_val_rust_csv[\"image_id\"].tolist()\ntrain_val_scab_names = train_val_scab_csv[\"image_id\"].tolist()\n\nsrc_dir = indir+\"plantvillage_split_dataset\/train&val_images\" #\"..\/input\/plantvillage\/images\"\ntrain_dst_dir = outdir+\"train\" #\"..\/working\/train&val_images\"\n\n# val_dst_dir = outdir+\"val\"  #\"..\/working\/test_images\"\ntrain_dst_healthy_dir = outdir+\"train\/healthy\"#\"..\/working\/train&val_images\"\ntrain_dst_multiple_diseases_dir =outdir+\"train\/multiple_diseases\"\ntrain_dst_rust_dir = outdir+\"train\/rust\"\ntrain_dst_scab_dir = outdir+\"train\/scab\"\n\ntest_dst_dir = outdir + \"test_image\/test\"\n\n# Create and fill the directories\ntry:\n    os.mkdir(train_dst_dir)\n\n    os.mkdir(train_dst_healthy_dir)\n    os.mkdir(train_dst_multiple_diseases_dir)\n    os.mkdir(train_dst_rust_dir)\n    os.mkdir(train_dst_scab_dir)\n    os.makedirs(test_dst_dir)\n\n    for image in train_val_healthy_names :\n            shutil.copy(src_dir+\"\/\"+image+\".jpg\",train_dst_healthy_dir)\n            \n    for image in train_val_multiple_diseases_names :\n            shutil.copy(src_dir+\"\/\"+image+\".jpg\",train_dst_multiple_diseases_dir)\n\n    for image in train_val_rust_names :\n            shutil.copy(src_dir+\"\/\"+image+\".jpg\",train_dst_rust_dir)\n\n    for image in train_val_scab_names :\n            shutil.copy(src_dir+\"\/\"+image+\".jpg\",train_dst_scab_dir)\n\n    for image in test_paths_csv[\"image_id\"].tolist():\n        shutil.copy(image,test_dst_dir)\n        \nexcept FileExistsError as err:\n    print(\"folders already exist\")\n \n# Check for possible errors\ntotal = len([f for f in  os.listdir(src_dir)])\ntrain_healthy_total = len([f for f in  os.listdir(train_dst_healthy_dir)])\ntrain_multiple_diseases_total = len([f for f in  os.listdir(train_dst_multiple_diseases_dir)])\ntrain_rust_total = len([f for f in  os.listdir(train_dst_rust_dir)])\ntrain_scab_total = len([f for f in  os.listdir(train_dst_scab_dir)])\n\ntotal = train_healthy_total + train_multiple_diseases_total +train_rust_total+ train_scab_total \ntrain_size = math.ceil(total*0.8)\nval_size = total - train_size\ntest_size = test_csv.size \nimage_size  = (200,200)\nbatch_size = 32\nseed = 100\nprint(train_healthy_total,train_multiple_diseases_total,train_rust_total,train_scab_total,)","f96d5fdf":"def create_augmented_data(train_dst_dir , train_generator, val_generator, aug, batch_size, valid = True):\n    if valid:\n        # Load data into tensorflow dataset: if we used the flow_form_directory method of the train_generator, \n        ## it would have been  too slow\n        print(\"loading data...\")\n        train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n        train_dst_dir,\n        validation_split=0.2,\n        subset=\"training\",\n        seed=1337,\n        image_size=image_size,\n        batch_size=train_size, \n        )\n\n        val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n            train_dst_dir,\n            validation_split=0.2,\n            subset=\"validation\",\n            seed=1337,\n            image_size=image_size,\n            batch_size=val_size,\n        )\n        \n        print(\"augmenting train...\")\n        res = list(zip(*train_ds.unbatch().as_numpy_iterator()))\n        x_train = np.array(res[0])\n        print(\"x done\")\n        y_train = np.array(res[1])\n        yforpca = y_train\n        print(x_train.shape,y_train.shape)\n        unique, counts = numpy.unique(y_train, return_counts=True)\n        print(\"class distribution before smote = \", counts)\n        x_train  = np.array([image.flatten() for image in x_train ])\n        xforpca = x_train\n        print(\"flattened\")\n\n        smote_train = SMOTE(sampling_strategy = \"all\", random_state = 420,k_neighbors=10,n_jobs=4) # svmsmote goes out of memory in all configs\n        x_train, y_train = smote_train.fit_resample(x_train, y_train)\n        x_train = np.reshape(x_train,(-1,200,200,3))\n        tot_train = len(x_train)\n        print(\"total_train after smote = \", x_train.shape)\n        yforpca1 = y_train #\n        xforpca1 = x_train  #\n        unique, counts = numpy.unique(y_train, return_counts=True)\n        print(\"class distribution after smote = \", counts)\n        y_train_cat = tf.keras.utils.to_categorical(\n            y_train, num_classes=4, dtype='float32'\n        )\n        \n        \n        train_generator.fit(x_train, seed = seed)\n        aug_train_images, aug_train_labels = train_generator.flow(x = x_train,y = y_train_cat,shuffle = False,batch_size = tot_train,seed = seed).next() \n        aug_train_images = np.array(aug_train_images)\n        aug_train_labels = np.array(aug_train_labels)\n        \n        # Save memory\n        del x_train\n        #del y_train\n        del train_ds\n\n        out_train_datagen = ImageDataGenerator()\n        out_train_datagen.fit(aug_train_images)\n        out_train_flow = out_train_datagen.flow(aug_train_images,aug_train_labels,batch_size = batch_size,shuffle = False)\n\n        del aug_train_images\n        del aug_train_labels\n\n        print(\"train augmented, augmenting val...\")\n        #i = 0\n        res = list(zip(*val_ds.unbatch().as_numpy_iterator()))\n        x_val = np.array(res[0])\n        y_val = np.array(res[1])\n        y_val_cat = tf.keras.utils.to_categorical(\n            y_val, num_classes=4, dtype='float32'\n        )\n        print(x_val.shape,y_val.shape,y_val_cat.shape)\n        \n        \n        val_generator.fit(x_val)\n        aug_val_images, aug_val_labels = val_generator.flow(x = x_val,y = y_val_cat,shuffle = False,batch_size = val_size,seed = seed).next()\n        aug_val_images = np.array(aug_val_images)\n        aug_val_labels = np.array(aug_val_labels)\n\n        del x_val\n        del val_ds\n\n        out_val_datagen = ImageDataGenerator()\n        out_val_datagen.fit(aug_val_images)\n        out_val_flow = out_val_datagen.flow(aug_val_images,aug_val_labels,batch_size = val_size, shuffle = False)\n\n        del aug_val_images\n        del aug_val_labels\n        del res\n\n        print(\"returning\")\n        return (out_train_flow,out_val_flow,y_val,y_train,tot_train)\n    # If validation is not provided \/ one intends to test\n    else:\n        print(\"loading data...\")\n        train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n        train_dst_dir,\n        seed=1337,\n        image_size=image_size,\n        batch_size=train_size, \n        )\n        \n        print(\"augmenting train...\")\n        res = list(zip(*train_ds.unbatch().as_numpy_iterator()))\n        x_train = np.array(res[0])\n        y_train = np.array(res[1])\n        print(x_train.shape,y_train.shape)\n        unique, counts = numpy.unique(y_train, return_counts=True)\n        print(\"class distribution before smote = \", counts)\n        x_train  = np.array([image.flatten() for image in x_train ])\n        print(\"flattened\")\n        yforpca = y_train \n        xforpca = x_train  \n        smote_train = SMOTE(sampling_strategy = \"all\", random_state = 420,k_neighbors=10,n_jobs=4)\n        x_train, y_train = smote_train.fit_resample(x_train, y_train)\n        x_train = np.reshape(x_train,(-1,200,200,3))\n        yforpca1 = y_train \n        xforpca1 = x_train \n        unique, counts = numpy.unique(y_train, return_counts=True)\n        print(\"class distribution after smote = \", counts)\n        tot_train = len(x_train)\n        print(\"total_train after smote = \", x_train.shape)\n        \n        y_train_cat = tf.keras.utils.to_categorical(\n            y_train, num_classes=4, dtype='float32'\n        )   \n\n        train_generator.fit(x_train,seed = seed)\n        aug_train_images, aug_train_labels = train_generator.flow(x = x_train,y = y_train_cat,shuffle = False,batch_size = tot_train,seed = seed).next()\n        aug_train_images = np.array(aug_train_images)\n        aug_train_labels = np.array(aug_train_labels)\n\n        del x_train\n        del y_train\n        del train_ds\n\n        out_train_datagen = ImageDataGenerator()\n        out_train_datagen.fit(aug_train_images)\n        out_train_flow = out_train_datagen.flow(aug_train_images,aug_train_labels,batch_size = batch_size,shuffle = False)\n\n        del aug_train_images\n        del aug_train_labels\n        \n        return (out_train_flow,tot_train,xforpca,yforpca,xforpca1,yforpca1)","c28e2ab1":"def get_augmented_test(test_dir, test_generator):\n    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n        outdir + \"test_image\",\n        labels=\"inferred\",\n        label_mode=\"int\",\n        class_names=None,\n        color_mode=\"rgb\",\n        batch_size=test_size,\n        image_size=image_size,\n        shuffle = False,\n        seed=None,\n        validation_split=None,\n        subset=None,\n        interpolation=\"bilinear\",\n        follow_links=False,\n    )\n    \n    x_test = np.array([ array for array, label in test_ds.unbatch().as_numpy_iterator()])\n    test_generator.fit(x_test,seed = seed)\n    test_flow = test_generator.flow(\n        x= x_test,\n        y=None,\n        batch_size = test_size,\n        shuffle=False,seed = seed)\n\n    test_imgs = test_flow.next()\n\n    del test_ds\n    del x_test\n    del test_generator\n\n    return test_imgs","bf976ef1":"# TRAIN\ntrain_datagen = ImageDataGenerator(rotation_range=360,                # DATA AUGMENTATION\n                                   #shear_range=.25,                  # DATA AUGMENTATION\n                                   #zoom_range=.25,                   # DATA AUGMENTATION\n                                   #width_shift_range=.25,            # DATA AUGMENTATION\n                                   #height_shift_range=.25,           # DATA AUGMENTATION\n                                   rescale=1.\/255,                    # DATA MODIFICATION\n                                   #brightness_range=[.5,1.5],        # DATA AUGMENTATION\n                                   horizontal_flip=True,              # DATA AUGMENTATION\n                                   #vertical_flip=True                # DATA AUGMENTATION\n                                  )\n\n# VALIDATION\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# TEST\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# To train and validate\ntrain_flow_80, val_flow, y_val, y_train,total_train_80 = create_augmented_data(train_dst_dir  = train_dst_dir,train_generator = train_datagen, val_generator = val_datagen , aug = 5, batch_size = batch_size )\ntrain_flow,total_train,x,y,xS,yS = create_augmented_data(train_dst_dir  = train_dst_dir,train_generator = train_datagen, val_generator = val_datagen , aug = 5, batch_size = 32, valid = False )","a6691651":"def plot_LSA(test_data, test_labels, plot=True):\n        lsa = TruncatedSVD(n_components=2)\n        lsa.fit(test_data)\n        lsa_scores = lsa.transform(test_data)\n        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n        color_column = [color_mapper[label] for label in test_labels]\n        colors = [\"orange\",\"blue\",\"red\",\"green\"]\n        if plot:\n            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n            #plt.legend(handles=[orange_patch, blue_patch], prop={'size': 20})\n\nx_train  = np.array([image.flatten() for image in x ])\nx_trainS  = np.array([image.flatten() for image in xS ])\n\ndel x,xS\n\nfig = plt.figure(figsize=(20,10))\nfig.add_subplot(121)\nplot_LSA(x_train, y)\nplt.title(\"pre_SMOTE\")\nfig.add_subplot(122)\nplot_LSA(x_trainS, yS)\nplt.title(\"post_SMOTE\")","aee3c071":"pca = PCA()\npca.fit(x_trainS)\n\nU = pca.transform(x_trainS)\nS = pca.explained_variance_\nV = pca.components_\n\nprint (\"U.shape = \", U.shape)\nprint (\"S.shape = \",S.shape)\nprint (\"V.shape = \", V.shape)\n\nplt.rc(\"image\", cmap=\"binary\")\nplt.figure(figsize=(8,5))\nfor i in range(15):\n    plt.subplot(3,5,i+1)\n    plt.imshow(tf.keras.preprocessing.image.array_to_img(x_train[i].reshape(200,200,3)))\n    plt.title(y[i])\n    plt.xticks(())\n    plt.yticks(())\nplt.tight_layout()\n\n\nprint(\"plot the first principal components\")\n\nplt.figure(figsize=(8,5))\nfor i in range(10):\n    plt.subplot(2,5,i+1)\n    plt.imshow(tf.keras.preprocessing.image.array_to_img(V[i].reshape(200,200,3)))\n    plt.xticks(())\n    plt.yticks(())\nplt.tight_layout()\n\n\nprint(\"plot less relevant principal components\")\nplt.figure(figsize=(8,5))\nfor i in range(10):\n    plt.subplot(2,5,i+1)\n    plt.imshow(tf.keras.preprocessing.image.array_to_img(V[200+i].reshape(200,200,3)))\n    plt.xticks(())\n    plt.yticks(())\nplt.tight_layout()","5177374c":"ev_cumsum = np.cumsum(pca.explained_variance_)\/(pca.explained_variance_).sum()\nev_at90 = ev_cumsum[ev_cumsum<0.9].shape[0]\nprint (ev_at90)\n\nplt.plot(ev_cumsum)\nplt.title(\"Explained Variance\")\nplt.xlabel(\"Components\")\nplt.xticks([0, ev_at90, 1000, 1500, 2000, 2500])\nplt.yticks(list(plt.yticks()[0]) + [0.9])\nplt.vlines(ev_at90, 0, 1, linestyles='dashed')\nplt.hlines(0.9, 0, 1000, linestyles='dashed');","58177585":"# Create a directory to save outputs \nos.makedirs(\"..\/working\/Saved\/\")\n\nargs = {\n    \"save_weights_only\":True,\n    \"monitor\":'val_categorical_auc',\n    \"mode\":'max',\n    \"save_best_only\":True,\n    \"verbose\":0  }\n\ncheckpoint_filepaths = [\"..\/working\/Saved\/drop0.hdf5\",\"..\/working\/Saved\/drop1.hdf5\",\"..\/working\/Saved\/drop2.hdf5\",\"..\/working\/Saved\/drop3.hdf5\",\"..\/working\/Saved\/drop4.hdf5\"\n                       ,\"..\/working\/Saved\/drop5.hdf5\",\"..\/working\/Saved\/drop6.hdf5\",\"..\/working\/Saved\/drop7.hdf5\",\"..\/working\/Saved\/drop8.hdf5\",\"..\/working\/Saved\/drop9.hdf5\"]","9173df8b":"def get_deeper_model():\n    #reg = .0005\n    \n    METRICS = [ \n      tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n      tf.keras.metrics.AUC(name='categorical_auc',multi_label=True),\n        ]\n    \n    model = tf.keras.Sequential([DenseNet121(input_shape=(200, 200, 3),\n                                weights='imagenet',\n                                include_top=False),\n                                L.GlobalAveragePooling2D(),\n                                L.Dense(4,activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                loss = 'categorical_crossentropy',\n                metrics=METRICS)\n    \n    print(model.summary())\n    return model","5e345488":"def get_model(drop):\n    \n    METRICS = [ \n      tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n      tf.keras.metrics.AUC(name='categorical_auc',multi_label=True),\n        ]\n    \n    model = tf.keras.models.Sequential([\n        # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n\n        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)), #, input_shape=(150, 150, 3)\n        tf.keras.layers.MaxPooling2D(2, 2),\n\n        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n\n        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n\n        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        \n        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        \n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(drop),\n        tf.keras.layers.Dense(4, activation='softmax')\n    ])\n\n\n    model.compile(RMSprop(lr=5e-4,momentum = 0.1),loss='categorical_crossentropy', metrics = METRICS)\n\n    # Model Summary\n    #print(model.summary())\n    \n    return model","7b349e06":"drops =[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nval_loss =[]\nmax_val_loss_epoch = []\nval_acc = []\nmax_val_acc_epoch = []\nval_auc = []\nmax_val_auc_epoch = []\nhistories = []\nepochs_l = []\ni = 0\nfor drop in drops:\n    model = get_model(drop)\n    args[\"filepath\"] = checkpoint_filepaths[i]\n    history = model.fit_generator(train_flow_80,\n                steps_per_epoch = total_train_80 \/\/ batch_size, #train_size\/\/batch_size\n                epochs=80, # the model never seems to suffer from validation loss increase (even up to 100 epochs)\n                validation_data=val_flow,\n                validation_steps=1,\n                callbacks = [ModelCheckpoint(**args)],                  # we tried early stopping and learning rate scheduling, but they proved inefficient due to the high loss swipes we had during training.\n                workers=4,\n                verbose = 0 )   \n    val_loss.append(np.max(np.array(history.history[\"val_loss\"])))\n    val_acc.append(np.max(np.array(history.history['val_categorical_accuracy'])))\n    val_auc.append(np.max(np.array(history.history['val_categorical_auc'])))\n    epochs_l.append(np.argmax(np.array(history.history['val_categorical_auc'])))\n    histories.append(history)\n    i = i+1\n    print(\"drop  = \",drop, \"done, next...\")\n    \nhistory  = histories[np.argmax(np.array(val_auc))]\ndrop = drops[np.argmax(np.array(val_auc))]\nepochs = epochs_l[np.argmax(np.array(val_auc))]+1 #epochs = np.argmax(np.array(history.history[\"val_categorical_auc\"]))\nbest_weights = checkpoint_filepaths[np.argmax(np.array(val_auc))]","e95ff9ee":"print(\"best drop = \", drop,\"best epochs = \", epochs, \"best_weights = \", best_weights)\n\nfig, axs = plt.subplots(1,3, figsize = (15,15))\naxs[0].set_title(\"val_loss\")\naxs[0].set_xlabel(\"dropout\")\naxs[0].set_ylabel(\"val_loss\")\naxs[0].plot(drops, val_loss)\n\naxs[1].set_title(\"val_acc\")\naxs[1].set_xlabel(\"dropout\")\naxs[1].set_ylabel(\"val_acc\")\naxs[1].plot(drops, val_acc)\n\naxs[2].set_title(\"val_auc\")\naxs[2].set_xlabel(\"dropout\")\naxs[2].set_ylabel(\"val_loss\")\naxs[2].plot(drops, val_auc) ","eac4caa7":"model_new = get_model(drop)\nhistory_new = model_new.fit_generator(train_flow_80,\n            steps_per_epoch = total_train_80 \/\/ batch_size, #train_size\/\/batch_size\n            epochs=80,           # the model never seems to suffer from validation loss increase (even up to 100 epochs)\n            validation_data=val_flow,\n            validation_steps=1,  # we tried early stopping and learning rate scheduling, but they proved inefficient due to the high loss swipes we had during training.\n            workers=4)   \n\ndeeper_model = get_deeper_model()\ndeeper_history = deeper_model.fit_generator(train_flow_80,\n            steps_per_epoch = total_train_80 \/\/ batch_size, #train_size\/\/batch_size\n            epochs=20,               # the model never seems to suffer from validation loss increase (even up to 100 epochs)\n            validation_data=val_flow,\n            validation_steps=1,      # we tried early stopping and learning rate scheduling, but they proved inefficient due to the high loss swipes we had during training.\n            workers=4)","9817fe6b":"def plot_train_history(history):\n    fig = go.Figure()\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['categorical_accuracy'], marker=dict(color=\"dodgerblue\"),\n                name=\"Train acc\"))\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['val_categorical_accuracy'], marker=dict(color=\"darkblue\"),\n                name=\"Val acc\"))\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['categorical_auc'], marker=dict(color=\"orange\"),\n                name=\"Train auc\"))\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['val_categorical_auc'], marker=dict(color=\"orangered\"),\n                name=\"Val auc\"))\n\n    fig.update_layout(title_text=\"\", yaxis_title= \"Metrics\", xaxis_title=\"Epochs\", template=\"plotly_white\")\n    fig.show()","fd482897":"plot_train_history(history)","70190616":"plot_train_history(history_new)","ca4f658b":"plot_train_history(deeper_history)","8482ed36":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=False):\n\n    accuracy = np.trace(cm) \/ np.sum(cm).astype('float')\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","5c0a23e9":"Y_pred = model.predict_generator(val_flow, train_size \/\/ batch_size +1) #128 +1\ny_pred = np.argmax(Y_pred, axis=1)\na = confusion_matrix(y_val, y_pred)\n\nplot_confusion_matrix(a,[\"h\",\"d\",\"c\",\"f\"],normalize=True)","88b7995e":"Y_pred = deeper_model.predict_generator(val_flow, train_size \/\/ batch_size +1) #128 +1\ny_pred = np.argmax(Y_pred, axis=1)\na = confusion_matrix(y_val, y_pred)\n\nplot_confusion_matrix(a,[\"h\",\"d\",\"c\",\"f\"],normalize=True)","d70dc2f8":"# Save memory\ndel y,yS\ndel train_flow_80, y_train, val_flow, y_val\n\n# Load test\ntest_imgs = get_augmented_test(test_dir = test_dir, test_generator = test_datagen)\nprint(test_imgs.shape)\n\n#os.listdir(\"..\/working\")","288cd27a":"EKM = get_model(drop) #0.4\nEKM.fit_generator(train_flow,\n            steps_per_epoch = total_train \/\/ batch_size, #train_size\/\/batch_size\n            epochs=epochs,\n            #callbacks=[lr_schedule],\n            workers=4)\n\ndef tensorSort(data):\n    return sorted(data, key=lambda item: (int(item.partition(' ')[0])\n                               if item[0].isdigit() else float('inf'), item))\n\ny_predicted = EKM.predict(test_imgs)\nsubmission = pd.DataFrame(y_predicted, columns = [\"healthy\", \"multiple_diseases\", \"rust\",\"scab\"],)\nsubmission.insert(0,\"image_id\",tensorSort(test_csv[\"image_id\"].tolist()))\nsubmission.to_csv(\"..\/working\/submission.csv\", index = False)\nsubmission\n\nmodel_loaded = get_model(drop)\nmodel_loaded.load_weights(best_weights)\n\n\ny_predicted = model_loaded.predict(test_imgs)\nsubmission_loaded = pd.DataFrame(y_predicted, columns = [\"healthy\", \"multiple_diseases\", \"rust\",\"scab\"])\nsubmission_loaded.insert(0,\"image_id\",tensorSort(test_csv[\"image_id\"].tolist()))\nsubmission_loaded.to_csv(\"..\/working\/submission_loaded.csv\", index = False)\nsubmission_loaded","74196a82":"Dense = get_deeper_model()\nDense.fit_generator(train_flow,\n            steps_per_epoch = total_train \/\/ batch_size, #train_size\/\/batch_size\n            epochs=20,\n            #callbacks=[lr_scheduled],\n            workers=4)\n\n\ny_predicted = Dense.predict(test_imgs)\nsubmission = pd.DataFrame(y_predicted, columns = [\"healthy\", \"multiple_diseases\", \"rust\",\"scab\"],)\nsubmission.insert(0,\"image_id\",tensorSort(test_csv[\"image_id\"].tolist()))\nsubmission.to_csv(\"..\/working\/deeper_submission.csv\", index = False)\nsubmission","ebb81214":"# Load model\nmodel = EKM\n\n# Summarize model \nmodel.summary()\n\n# Summarize filters\nfor layer in model.layers:\n    if 'conv' not in layer.name:            # focus on convolutional layers\n        continue\n    filters, biases = layer.get_weights()   # extract filter weights\n    print(layer.name, filters.shape)\n    \n# Extract weights \nfilters, biases = model.layers[0].get_weights()\n\n# Normalize filter values for visualization\nfilters_min, filters_max = filters.min(), filters.max()\nfilters = (filters - filters_min) \/ (filters_max - filters_min)\n\n# Plot some of the first layers\nn_filters, index = 7, 1\nfor i in range(n_filters):\n    f = filters[:, :, :, i]                      # get the filter\n    for j in range(3):                           # plot each channel separately\n        ax = pyplot.subplot(n_filters, 3, index)    # specify subplot and turn of axis\n        ax.set_xticks([])\n        ax.set_yticks([])\n        pyplot.imshow(f[:, :, j], cmap='gray')   # plot filter channel in grayscale\n        index += 1\npyplot.show()      ","4db1976c":"# Select input image \nimg = np.array([test_imgs[58]]) \n\n# Load model\nmodel = EKM\n\n# Select the convolutional layers \nindices = [0,2,4,6,8]\noutputs = [model.layers[i].output for i in ixs]\nmodel = Model(inputs=model.inputs, outputs=outputs)\n\n# Get feature map for 1st hidden layer\nfeature_maps = model.predict(img)\n\n# Plot the output from each layer\nsquare = 4\n\nfor fmap in feature_maps:\n    index = 1\n    plt.figure(figsize = (13,13))\n    for _ in range(square):\n        for _ in range(square):\n            ax = pyplot.subplot(square, square, index)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            try:\n                pyplot.imshow(fmap[0, :, :, index-1], cmap = 'gray')\n            except:\n                print(\"\", end = \"\\r\")\n            index += 1\n    pyplot.show()","a218d0c5":"### Data Exploration","f3527a62":"#### EKM","e47938e6":"#### EKM Filters","e5be6da4":"#### EKM ","899d5c73":"Here we plot the *explained variance* as a function of the principal directions retained.","a91945b9":"### Keras Implementation\n\n#### Callbacks \n\nHere we instantiate a **checkpoint callback**: a learning rate modifier which saves the best model weights both for prediction and for stocasticity evaluation.","28b7d6cf":"### Sigular Value Decomposition (SVD) & Principal Component Analysis (PCA) \n\n#### SVD\n\nPlot the projection of the train+test sets on the plane defined by the two directions with largest variance, before and after the application of `SMOTE`. ","e9c2f268":"### Test Set Preprocessing\n\nThe test set is preprocessed just as the validation set, in order to give the model the same feature distribution.","6bf70c5d":"#### Explicit Keras Model: **EKM**","86a59bd1":"### EKM Feature Maps","43209701":"#### DenseNet121","cf6eaca3":"# Dataset Analysis and CNN Models Optimization for Plant Disease Classification\n\n### Related Material \n\n* Explore the [GitHub repository](https:\/\/github.com\/InPhyT\/NeuralNetworksProject) of the project.\n* Read the report in [PDF](https:\/\/github.com\/InPhyT\/NeuralNetworksProject\/Report\/report.pdf) or [HTML](https:\/\/inphyt.github.io\/NeuralNetworksProject\/Report\/report.html) format.","81d92a55":"### Training Histories ","3944c334":"### Modules","8090258e":"### Train, Validation Splitting\n\nThe following cell creates four directories `healthy`, `multiple_diseases`, `rust`, `scab` with the corresponding images from the train dataset. It is a very technical part due to the way the images need to be organized for TensorFlow.","f19e4838":"#### EKM","9db520a6":"### Data Generators \n\nIt's important to stress the difference between **data preprocessing** and **data augmentation**: \n* preprocessing refers to a well defined transformation applied to all data (in order to save memory, speed up execution, etc...)\n* augmentation refers to a random modification applied to a random sample of the data to train a more rubust model.\n\nTherefore (selected) augmentation techniques are applied to train only, while validation and test sets receive just the preprocessing applied to train.\n\nVisit https:\/\/keras.io\/api\/preprocessing\/image\/#imagedatagenerator-class for more details. ","676dedfc":"#### Stochasticity Evaluation ","07f2ebe8":"### Confusion Matrix","1746cf39":"### Model Training & Validation (80%, 20%)\n\nThe EKM is trained on 80% of train data and validated on the rest.","a5010479":"#### DenseNet121 ","b1a14e41":"#### PCA\n\nAlthough the two plots above show that the dataset (assuming its signal to be greater than noise) does not live on a *linear submanifold*, we've decided to plot its principal components below.","b24bb58b":"### Filters & Feature Maps ","ed82e8a8":"### Models\n\n#### Pre-Trained Keras Model: **DenseNet121**","5073f09c":"### Model Training, Prediction & Submission","47d10676":"#### DenseNet121","f59d6cb7":"### Class Balancing & Data Augmentation\/Prepocessing\n\nThe function `create_augmented_data` performs class balancing with `SMOTE` and data augmentation with `ImageDataGenerator` by TensorFlow.\n\nWe have tried multiple variants of `SMOTE` and `ImageDataGenerator` and selected the following configuration as optimal taking the performance into account. <br> Please notice that the function is split in two by the `valid` parameter: it allows to apply the function to output both the train and validation data together and just the train . ","b7f0351d":"### Train & Validation, Test Splitting \n\nThis section has been run previously. The output dataset can be found in the input folder.\n\n```python\n\nsrc_dir = \"..\/input\/plantvillage\/images\" #r\"..\/plant-pathology-2020-fgvc7\/images\"\ntrain_val_dst_dir = \"..\/working\/train&val_images\" #r\"..\/plant-pathology-2020-fgvc7\/train&val_images\" #\"..\/working\/train&val_images\"\ntest_dst_dir = \"..\/working\/test_images\" #r\"..\/plant-pathology-2020-fgvc7\/test_images\"  #\"..\/working\/test_images\"\n\nif not os.path.isdir(train_val_dst_dir):\n    os.mkdir(train_val_dst_dir)\nif not os.path.isdir(test_dst_dir):\n    os.mkdir(test_dst_dir)\n\n\nif len([f for f in os.listdir(test_dst_dir)]) == 0:\n    all_images_names = os.listdir(src_dir)\n    train_val_images = []\n    test_images  = []\n    for image in all_images_names:\n        if \"Train\" in image:\n            shutil.copy(src_dir+\"\/\"+image,train_val_dst_dir)\n        elif \"Test\" in image:\n            shutil.copy(src_dir+\"\/\"+image,test_dst_dir)\n        else:\n            print(\"error\")\n\n# Check for possible errors\ntotal = len([f for f in  os.listdir(src_dir)])\ntrain_val_total = len([f for f in  os.listdir(train_val_dst_dir)])\ntest_total = len([f for f in  os.listdir(test_dst_dir)])\nprint(total == train_val_total + test_total)\n```\n[ ] : True"}}