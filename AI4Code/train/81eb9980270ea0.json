{"cell_type":{"8dafa7e7":"code","0d0f246c":"code","bcd5bfd4":"code","b45476c4":"code","28755a6f":"code","dd45f197":"code","55d98f04":"code","4315e0ca":"code","ec3d4da9":"code","2b2c940c":"code","e4651db0":"code","8f0ee538":"code","a657fa4e":"code","878f8112":"code","4759049a":"code","d594ee8b":"code","1c684d32":"code","ded641b1":"code","65d1aa85":"code","463ae889":"code","10db463a":"code","3fdb6b22":"code","293ed9e0":"code","4be6957d":"markdown","68049432":"markdown","deb9e8fb":"markdown","50781b1a":"markdown","2ddbc790":"markdown","07fa8be3":"markdown","4ed03bda":"markdown"},"source":{"8dafa7e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d0f246c":"%matplotlib inline\n\nimport numpy as np\n\nimport keras\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.metrics import categorical_crossentropy\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-bright')\n\nimport itertools\n\nfrom prettytable import PrettyTable\n\nimport time\noptimizers.SGD()","bcd5bfd4":"from sklearn.datasets import load_iris\niris = load_iris()\n\nX = iris['data']\ny = iris['target']\nnames = iris['target_names']\nfeature_names = iris['feature_names']\n\n#  suffle them\nfrom sklearn.utils import shuffle\nX, y = shuffle(X, y)\n\n# take %20 for test\nx_test = X[0:15,:]\ny_test = y[0:15]\n\n\nX = X[15:,:]\ny = y[15:]\n\n# One hot encoding\nenc = OneHotEncoder()\nY = enc.fit_transform(y[:, np.newaxis]).toarray()\ny_test = enc.fit_transform(y_test[:, np.newaxis]).toarray()\n\n\n# Scale data to have mean 0 and variance 1 \n# which is importance for convergence of the neural network\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nx_test = scaler.fit_transform(x_test)","b45476c4":"import keras.backend as K\n\ndef model_parameters(model): # Compute number of params in a model (the actual number of floats)\n    return sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])","28755a6f":"class TimeHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.times = []\n\n    def on_epoch_begin(self, batch, logs={}):\n        self.epoch_time_start = time.time()\n\n    def on_epoch_end(self, batch, logs={}):\n        self.times.append(time.time() - self.epoch_time_start)\n","dd45f197":"# Split the data set into training and testing\nx_train, x_valid, y_train, y_valid = train_test_split(X_scaled, Y, test_size=0.3, random_state=2)\n\nn_features = X.shape[1]\nn_classes = Y.shape[1]","55d98f04":"print(\"     number of train data = %d\"%(x_train.shape[0]))\nprint(\"number of validation data = %d\"%(x_valid.shape[0]))\nprint(\"      number of test data = %d\"%(x_test.shape[0]))","4315e0ca":"# Visualize the data sets\nplt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nfor target, target_name in enumerate(names):\n    X_plot = X[y == target]\n    plt.plot(X_plot[:, 0], X_plot[:, 1], linestyle='none', marker='o', label=target_name)\nplt.xlabel(feature_names[0])\nplt.ylabel(feature_names[1])\nplt.axis('equal')\nplt.legend();\n\nplt.subplot(1, 2, 2)\nfor target, target_name in enumerate(names):\n    X_plot = X[y == target]\n    plt.plot(X_plot[:, 2], X_plot[:, 3], linestyle='none', marker='o', label=target_name)\nplt.xlabel(feature_names[2])\nplt.ylabel(feature_names[3])\nplt.axis('equal')\nplt.legend();","ec3d4da9":"epochs = 100\nbatch_size = 5\n\nmodels={}\ntimes={}\nhistories={}\n\nmodel_layers={}\nmodel_layers['4']= [4] \nmodel_layers['5000']= [5000] \nmodel_layers['8-8']= [8, 8] \nmodel_layers['1000-1000']= [1000,1000] \nmodel_layers['8-8-8']= [8,8,8]\nmodel_layers['1000-1000-1000']= [1000,1000,1000]\n\n\nfor name, nodes in model_layers.items():\n    \n    model = Sequential(name=name)\n    \n    for index, node in enumerate(nodes):\n        if index == 0:\n            model.add(Dense(node, input_dim=n_features, activation='relu'))\n        else:\n            model.add(Dense(node, activation='relu'))\n    \n    model.add(Dense(n_classes, activation='softmax'))\n    \n    Adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n    \n    model.compile(optimizer=Adam, loss='mean_squared_error', metrics=['accuracy'] )\n    \n    models[name]=model\n    \n    time_callback = TimeHistory()\n    h = model.fit(\n        x_train, y_train, \n        validation_data=(x_valid,y_valid), \n        batch_size=batch_size, \n        epochs=epochs, shuffle=True, \n        verbose=0,\n        callbacks=[time_callback]\n    )\n    times[name] = time_callback.times\n    histories[name] = h\n#print(h.history)","2b2c940c":"for model_name, h in histories.items():\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15, 5))\n\n    val_acc = h.history['val_accuracy']\n    val_loss = h.history['val_loss']\n    acc = h.history['accuracy']\n    loss = h.history['loss']\n    \n    ax1.plot(val_acc, label=\"Validation\")\n    ax1.plot(acc, label=\"Train\")\n    \n    ax2.plot(val_loss, label=\"Validation\")\n    ax2.plot(loss, label=\"Train\")\n    \n    ax1.set_title(\"model: 4-%s-3\"%(model_name))\n    ax2.set_title(\"model: 4-%s-3\"%(model_name))\n    ax1.set_ylabel('Accuracy')\n    ax2.set_ylabel('loss (MSE)')\n    ax2.set_xlabel('epochs')\n    ax1.set_xlabel('epochs')\n    ax1.grid(True)\n    ax2.grid(True)\n    ax1.legend()\n    ax2.legend()\n    plt.show()","e4651db0":"x = PrettyTable()\nx.field_names = [\"Model Name\", \"Best Train Acc.\",\"Best Validation Acc.\", \"Test Acc.\" ,\"Epochs\" , \"Time (s)\", \"Trainable Parameters\"]\n\n\nfor model_name, h in histories.items():\n    validation = models[model_name].evaluate(x_test, y_test, verbose=0)\n    x.add_row([\n        \"4-\"+model_name+\"-3\",  \n        \"%% %.2f\"%(100* max(h.history['accuracy']) ),\n        \"%% %.2f\"%(100* max(h.history['val_accuracy']) ),\n        \"%% %.2f\"%(100* validation[1] ),\n        epochs,\n        \"%.2f\"%(sum(times[model_name])),\n        model_parameters(models[model_name])\n    ])\nprint(x)","8f0ee538":"fig, (ax1, ax2) = plt.subplots(2,1, figsize=(10, 10))\nmarker = itertools.cycle((',', '+', '.', 'o', '*')) \n\nfor name, h in histories.items():\n    loss = h.history['loss']\n    this_marker = next(marker)\n    ax1.plot(loss, label='Model - 4-%s-3'%(name), marker=this_marker)\n\nax1.set_title(\"models - Train\")\nax1.set_ylabel('loss')\nax1.set_xlabel('epochs')\nax1.legend()\nax1.grid(True)\nplt.show()","a657fa4e":"histories={}\ntest_sizes={}\n\ntest_sizes['0.1']=0.1\ntest_sizes['0.5']=0.3\ntest_sizes['0.9']=0.9\n\ntimes = {}\nvalidations={}\n\nepochs = 100\nbatch_size = 5\n\n\n# Save the weights to reset the model every iteration\n# model.save_weights('model-section-1.h5')\n\nfor name, ts in test_sizes.items():\n    \n    \n    \n    # change the test_size\n    x2_train, x2_valid, y2_train, y2_valid = train_test_split(X_scaled, Y, test_size=ts, random_state=2)\n    \n    \n    model = Sequential([\n        Dense(8, input_dim=4, activation='relu'),\n        Dense(8, activation='relu'),\n        Dense(8, activation='relu'),\n        Dense(3, activation='softmax')\n    ])\n\n    Adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n    model.compile( optimizer=Adam, loss='mean_squared_error', metrics=['accuracy'] )\n    \n    time_callback = TimeHistory()\n    h = model.fit(\n        x2_train, y2_train, \n        validation_data=(x2_valid,y2_valid), \n        batch_size=batch_size, \n        epochs=epochs, shuffle=True, \n        verbose=0,\n        callbacks=[time_callback]\n    )\n    times[name] = time_callback.times\n    \n    validations[name] = model.evaluate(x_test, y_test, verbose=0)\n    \n    # Save data\n    histories[name] = h","878f8112":"model_parameters(model)","4759049a":"# report table\nprint(\"Epochs = %d\"%(epochs))\nx = PrettyTable()\nx.field_names = [\"validation\/train ratio\", \"validation\/train count\", \"Best Train loss\", \"Best Validation lost.\",\"epochs\", \"Trainable Parameters\"]\n\nfor index, h in histories.items():\n    x.add_row( [\n        test_sizes[index],\n        \"%d \/ %d \"%( int( 135*(test_sizes[index])), int(135*(1-test_sizes[index])) ),\n        \"%.4f\"%(min(h.history['loss']) ),\n        \"%.4f\"%(min(h.history['val_loss']) ),\n        epochs,\n#         \"%.2f\"%(sum(times[index])),\n        model_parameters(model)\n    ])\nprint(x)\n\n#Diagram\nfor index, h in histories.items():\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15, 5))\n\n    val_acc = h.history['val_accuracy']\n    val_loss = h.history['val_loss']\n    acc = h.history['accuracy']\n    loss = h.history['loss']\n    \n    ax1.plot(val_acc, label=\"Validation\")\n    ax1.plot(acc, label=\"Train\")\n    \n    ax2.plot(val_loss, label=\"Validation\")\n    ax2.plot(loss, label=\"Train\")\n    \n    ax1.set_title(\"Number of train vs test ratio= %.2f\"%(test_sizes[index]))\n    ax2.set_title(\"Number of train vs test ratio= %.2f\"%(test_sizes[index]))\n    ax1.set_ylabel('accuracy')\n    ax2.set_ylabel('loss (MSE)')\n    ax2.set_xlabel('epochs')\n    ax1.set_xlabel('epochs')\n    ax1.legend()\n    ax2.legend()\n    ax1.grid(True)\n    ax2.grid(True)\n    plt.show()","d594ee8b":"from keras.callbacks import Callback\n\nclass EarlyStoppingByLossVal(Callback):\n    def __init__(self, monitor='val_loss', value=0.00001, verbose=0):\n        super(Callback, self).__init__()\n        self.monitor = monitor\n        self.value = value\n        self.verbose = verbose\n\n    def on_epoch_end(self, epoch, logs={}):\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n\n        if current < self.value:\n            if self.verbose > 0:\n                print(\"Epoch %05d: early stopping THR\" % epoch)\n            self.model.stop_training = True","1c684d32":"histories={}\ntimes={}\nvalidations={}\nparameters={}\n\nsplit_ratio = 0.3\nepochs = 1000\nbatch_size = 5\nActivation_function={}\nActivation_function['sigmoid']= 'sigmoid'\nActivation_function['tanh']='tanh'\nActivation_function['relu']='relu'\n\ncallbacks = [\n    EarlyStoppingByLossVal(monitor='val_loss', value=0.02, verbose=1)\n#     ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n]\n\nfor name, a in Activation_function.items():\n    model = Sequential([\n        Dense(8, input_dim=4, activation=a),\n        Dense(8, activation=a),\n        Dense(8, activation=a),\n        Dense(3, activation='softmax')\n    ])\n    Adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n    model.compile( optimizer= Adam, loss='mean_squared_error', metrics=['accuracy'] )\n    \n    print(\"====== Started model %s\"%(name))\n    s = time.time()\n    h = model.fit(\n        x_train, y_train, \n        validation_data=(x_test,y_test), \n        batch_size=batch_size, \n        epochs=epochs, shuffle=True, verbose=0,\n        callbacks=callbacks\n    )\n    e = time.time()\n    \n    histories[name] = h\n    times[name] = e-s\n    parameters[name] = model_parameters(model)\n    validations[name] = model.evaluate(x_test, y_test, verbose=1)","ded641b1":"len(histories['sigmoid'].history['loss'])-1\nfor index, h in histories.items():\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15, 5))\n\n    val_acc = h.history['val_accuracy']\n    val_loss = h.history['val_loss']\n    acc = h.history['accuracy']\n    loss = h.history['loss']\n    \n    ax1.plot(val_acc, label=\"Validation\")\n    ax1.plot(acc, label=\"Train\")\n    \n    ax2.plot(val_loss, label=\"Validation\")\n    ax2.plot(loss, label=\"Train\")\n    \n    ax1.set_title(\"Activation Nonlinear Function : %s\"%(Activation_function[index]))\n    ax2.set_title(\"Activation Nonlinear Function : %s\"%(Activation_function[index]))\n    ax1.set_ylabel('accuracy')\n    ax2.set_ylabel('loss (MSE)')\n    ax2.set_xlabel('epochs')\n    ax1.set_xlabel('epochs')\n    ax1.legend()\n    ax2.legend()\n    ax1.grid(True)\n    ax2.grid(True)\n    plt.show()","65d1aa85":"validations","463ae889":"# report table\nx = PrettyTable()\nx.field_names = [\"Activation\", \"Test Accuracy\", \"Train Loss (MSE)\", \"Validation Loss (MSE)\",\"epochs\", \"Time(ms)\", \"Trainable Parameters\"]\n\nfor index, h in histories.items():\n    x.add_row( [\n        index,\n        \"%% %.2f\"%(100* validations[index][1] ),\n        \"%.4f\"%(h.history['loss'][-1]),\n        \"%.4f\"%(h.history['val_loss'][-1]),\n        len(histories[index].history['loss'])-1,\n        \"%.2f\"%(1000*times[index]),\n        parameters[index]\n    ])\nprint(x)","10db463a":"histories={}\ntimes={}\nvalidations={}\nparameters={}\n\ncallbacks = [\n    EarlyStoppingByLossVal(monitor='val_loss', value=0.02, verbose=1)\n]\n\nsplit_ratio = 0.3\nepochs = 300\nbatch_size = 5\nactivation = 'relu'\n\ntestOpts={}\ntestOpts['sgd'] = optimizers.SGD(lr=0.01, decay=0.0, momentum=0.0, nesterov=False)\ntestOpts['sgd_d'] = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.0, nesterov=False)\ntestOpts['sgd_m'] = optimizers.SGD(lr=0.01, decay=0.0, momentum=0.9, nesterov=False)\ntestOpts['sgd_md'] = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=False)\ntestOpts['RMSprop'] = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=1e-6)\ntestOpts['Adagrad'] = optimizers.Adagrad(lr=0.01, epsilon=None, decay=1e-6)\ntestOpts['Adadelta'] = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\ntestOpts['Adam'] = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n\n\nfor name,opt in testOpts.items():\n    model = Sequential([\n        Dense(8, input_dim=4, activation=activation),\n        Dense(8, activation=activation),\n        Dense(8, activation=activation),\n        Dense(3, activation='softmax')\n    ])\n    model.compile( optimizer=opt , loss='mean_squared_error', metrics=['accuracy'] )\n    \n    print(\"====== Started model %s\"%(name))\n    s = time.time()\n    h = model.fit(\n        x_train, y_train, \n        validation_data=(x_test,y_test), \n        batch_size=batch_size, \n        epochs=epochs, shuffle=True, verbose=0,\n        callbacks=callbacks\n    )\n    e = time.time()\n    \n    histories[name] = h\n    times[name] = e-s\n    parameters[name] = model_parameters(model)\n    validations[name] = model.evaluate(x_test, y_test, verbose=1)","3fdb6b22":"marker = itertools.cycle((',', '+', '.', 'o', '*')) \n\nfig, (ax1, ax2) = plt.subplots(2,1, figsize=(10, 12))\nfor index, h in histories.items():\n    val_loss = h.history['val_loss']\n    loss = h.history['loss']\n    this_marker = next(marker)\n    ax1.plot(loss, label= index, marker=this_marker)\n    ax2.plot(val_loss, label=index, marker=this_marker)\n\nax1.set_title(\"Effect of parameter update methods - Train\")\nax2.set_title(\"Effect of parameter update methods - Test\")\nax1.set_ylabel('loss')\nax2.set_ylabel('loss')\nax2.set_xlabel('epochs')\nax1.set_xlabel('epochs')\nax1.legend()\nax2.legend()\nax1.grid(True)\nax2.grid(True)\nplt.show()","293ed9e0":"# report table\nx = PrettyTable()\nx.field_names = [\"Update Method\", \"Test Accuracy\", \"Train Loss (MSE)\", \"Validation Loss (MSE)\", \"epochs\", \"Time(s)\", \"Trainable Parameters\"]\n\nfor index, h in histories.items():\n    x.add_row( [\n        index,\n        \"%% %.2f\"%(100* validations[index][1] ),\n        round(h.history['loss'][-1],3),\n        round(h.history['val_loss'][-1],3),\n        len(histories[index].history['loss'])-1,\n        \"%.3f\"%(times[index]),\n        parameters[index]\n    ])\nprint(x)","4be6957d":"# **Load Data**","68049432":"# **1. Effect of train vs validation ratio**\nIn this section we change use 0.1, 0.3, 0.5, 0.7 as the ratio of test\/train numbers\n\n1. Select a good model\n2. only change the split_ratio\n3. plot accuracy","deb9e8fb":"# **3. Effect of parameter update methods\u00b6**\nSGD\nSGD - with decay\nSGD - with momentum\nSGD - with momentum and decay\nRMSprop\nAdagrad\nAdadelta\nAdam","50781b1a":"# **Train Multiple**","2ddbc790":"# **3. Effect different activation functions**\nActivation functions: relu, sigmoid, TANH","07fa8be3":"# **Visualize**","4ed03bda":"# **Split Data**"}}