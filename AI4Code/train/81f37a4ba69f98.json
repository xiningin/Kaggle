{"cell_type":{"a0df5122":"code","b941c86c":"code","319344b7":"code","f51afff0":"code","325034aa":"code","ecc46126":"code","aa9f1dd6":"code","15219510":"code","b12decd2":"code","15d3a7d6":"code","0dddf2ca":"code","a5c5f770":"code","1561c590":"code","5761deff":"code","8ca000a8":"code","d05c6268":"code","eeb0cc69":"code","ec5c7461":"code","596ff658":"code","34a2fd4a":"code","3f2393bb":"code","0457f12e":"code","536b50ad":"code","79ee1b3b":"code","ed986cdf":"code","257111b8":"code","e8a8b741":"code","cee5cd39":"code","c8243ae3":"code","51371263":"code","426501a8":"code","bb5842b2":"code","5b8e0113":"code","6de088e8":"code","d086c608":"code","2d491c65":"code","a6c20e30":"code","5ab606d8":"code","01ab61b7":"code","d49284ca":"code","cffc34b4":"code","829238bc":"code","1a549273":"code","b4c0cf21":"code","8d7f530b":"code","f763f76e":"code","6ada404c":"code","c78f24a8":"code","4c0c0761":"markdown"},"source":{"a0df5122":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b941c86c":"data_train=pd.read_csv('\/kaggle\/input\/instagram-fake-spammer-genuine-accounts\/train.csv')\ndata_train","319344b7":"data_test=pd.read_csv('\/kaggle\/input\/instagram-fake-spammer-genuine-accounts\/test.csv')\ndata_test","f51afff0":"data = pd.concat([data_train, data_test], axis=0)\ndata","325034aa":"data.info()","ecc46126":"data.nunique()","aa9f1dd6":"data.describe()","15219510":"from scipy.stats import skew\ndata['fake'].skew()","b12decd2":"corr_mat=data.corr().round(2)","15d3a7d6":"import seaborn as sns\nsns.heatmap(corr_mat,annot=True)","0dddf2ca":"data_train.skew()","a5c5f770":"data_train['#followers'] = np.log1p(data_train['#followers'])\ndata_train['#posts'] = np.log1p(data_train['#posts'])","1561c590":"X=data_train.drop(columns=['fake'])\nY=data_train['fake']","5761deff":"Y.value_counts()","8ca000a8":"X.drop(columns=['nums\/length fullname','name==username', 'external URL'], inplace=True)","d05c6268":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,random_state=7)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","eeb0cc69":"Y_train.value_counts()","ec5c7461":"from imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\nX_train, Y_train = rus.fit_resample(X_train, Y_train)","596ff658":"#from imblearn.over_sampling import SMOTE\n#smote = SMOTE(sampling_strategy='auto')\n#X_train, Y_train = smote.fit_sample(X_train, Y_train)\n#print(X_train.shape,Y_train.shape)","34a2fd4a":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","3f2393bb":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nr_estimator=LogisticRegression()\n\nparameters={'penalty' : ['l1', 'l2', 'elasticnet' ],\n               'class_weight' : ['balanced'],\n           'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\ngrid=GridSearchCV(estimator=r_estimator,param_grid=parameters,verbose=True,cv=7,n_jobs=-1)\ngrid.fit(X_train,Y_train)\ngrid.best_params_","0457f12e":"from  sklearn.linear_model import RidgeClassifier\nmodel =RidgeClassifier()\nmodel.fit(X_train, Y_train)","536b50ad":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators = 500,max_features='auto')\n\nmodel.fit(X_train, Y_train)","79ee1b3b":"a = model.feature_importances_\nfor i in range(1, len(a)):\n    if a[i] < 0.01:\n        print('the columns ', X.columns[i], ' has feature value ', a[i])","ed986cdf":"from sklearn.linear_model import LogisticRegression","257111b8":"model = LogisticRegression(class_weight = 'balanced',\n                          penalty = 'l1',\n                          solver = 'liblinear',max_iter = 1000)\nmodel.fit(X_train, Y_train)","e8a8b741":"pred = model.predict(X_test)\npred","cee5cd39":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report, auc, roc_curve\nconfusion_matrix(pred, Y_test)","c8243ae3":"precision_score(Y_test, pred)","51371263":"recall_score(Y_test, pred)","426501a8":"f1_score(pred,Y_test)","bb5842b2":"print(classification_report(pred, Y_test))","5b8e0113":"roc_curve(pred,Y_test)","6de088e8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.pipeline import Pipeline","d086c608":"dtr = RandomForestRegressor()\ndtr.fit(X_train,Y_train)\ny_pred = dtr.predict(X_test)\n\nmse = mean_squared_error(Y_test,y_pred)\nprint(\"RMSE Error:\", np.sqrt(mse))\nr2 = r2_score(Y_test,y_pred)\nprint(\"R2 Score:\", r2)","2d491c65":"dtr = xgb.XGBRegressor()\ndtr.fit(X_train,Y_train)\ny_pred = dtr.predict(X_test)\n\nmse = mean_squared_error(Y_test, y_pred)\nprint(\"RMSE Error:\", np.sqrt(mse))\nr2 = r2_score(Y_test, y_pred)\nprint(\"R2 Score:\", r2)","a6c20e30":"a = dtr.feature_importances_\nfor i in range(1, len(a)):\n        print('the columns ', X.columns[i], ' has feature value ', a[i])","5ab606d8":"import seaborn as sns\nplt.figure(figsize=(10,7))\ncorr_mat=data.corr()\nsns.heatmap(data=corr_mat>0.2,annot=True)","01ab61b7":"X=data.drop(columns=['profile pic','fullname words','fake'])\nY=data['fake']","d49284ca":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)","cffc34b4":"dtr = RandomForestRegressor()\ndtr.fit(X_train,Y_train)\ny_pred = dtr.predict(X_test)                                         \n\nmse = mean_squared_error(Y_test,y_pred)\nprint(\"RMSE Error:\", np.sqrt(mse))                           #good rmse\nr2 = r2_score(Y_test,y_pred)\nprint(\"R2 Score:\", r2)","829238bc":"dtr = xgb.XGBRegressor()\ndtr.fit(X_train,Y_train)\ny_pred = dtr.predict(X_test)\n\nmse = mean_squared_error(Y_test, y_pred)\nprint(\"RMSE Error:\", np.sqrt(mse))\nr2 = r2_score(Y_test, y_pred)\nprint(\"R2 Score:\", r2)","1a549273":"data[\"fake_followers_count\"] = data.groupby(['#followers'])['fake'].transform('count')","b4c0cf21":"from sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nfpr, tpr, thres = roc_curve(Y_test,  pred)\nplt.scatter(fpr, tpr)\nthres","8d7f530b":"roc_auc_score(pred, Y_test)","f763f76e":"from sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\ny_pred_proba = model.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(Y_test,  y_pred_proba)\nauc = roc_auc_score(Y_test, pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","6ada404c":"plt.scatter(fpr, tpr)\nplt.show()","c78f24a8":"import numpy as np\nplt.plot(fpr,tpr)\nplt.show() \nauc = np.trapz(tpr,fpr)\nprint('AUC:', auc)","4c0c0761":"# converging two data set to single data set"}}