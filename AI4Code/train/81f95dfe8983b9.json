{"cell_type":{"364bbfd1":"code","02b476d6":"code","b48ed8a4":"code","fb712a71":"code","57cceba4":"code","1bc9cf6f":"code","2e28dbbb":"code","bf378b82":"code","0af3fdd1":"code","8ae435b2":"code","18da9610":"code","ceffaa9a":"code","13e30a72":"code","014f7e13":"code","1092d1b3":"code","359745ff":"code","b965ac0c":"code","731843b4":"code","6b1e10ae":"code","381eb329":"code","0ac8ba9b":"code","2cdf021a":"code","89855cfa":"code","14b8eee0":"code","d9b5986b":"code","95f569f3":"code","c70971c5":"code","48c19b97":"code","6abc0faa":"markdown","80bd56e0":"markdown","d3dd3756":"markdown","c4dcb130":"markdown","f59cbdc7":"markdown","cf1ea5ed":"markdown","f0a331e8":"markdown","9d229bd5":"markdown","28e0f4cf":"markdown","8e406502":"markdown","25725831":"markdown","6712f850":"markdown","d019f209":"markdown","1db86f46":"markdown","b0ef4841":"markdown","5232724f":"markdown","dd16db96":"markdown","1a09de67":"markdown"},"source":{"364bbfd1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02b476d6":"df= pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test= pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf.head()","b48ed8a4":"df['Died'] = 1 - df['Survived']\n\ndf.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(10,6), stacked=True);","fb712a71":"figure = plt.figure(figsize=(25, 7))\nplt.hist([df[df['Survived'] == 1]['Fare'], df[df['Survived'] == 0]['Fare']], \n         stacked=True, color = ['g','r'],\n         bins = 50, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend();","57cceba4":"## Finding out the missing values\n\ndf.isna().sum().sort_values(ascending = False)","1bc9cf6f":"df.corr()","2e28dbbb":"df.drop({'Cabin', 'Age', 'Embarked'}, axis=1, inplace= True)\n\n# from the test data set as well. \n\ndf_test.drop({'Cabin', 'Age', 'Embarked'}, axis=1, inplace= True)","bf378b82":"df_test.isna().sum().sort_values(ascending = False)","0af3fdd1":"df_test[df_test.isna().T.any().T]","8ae435b2":"df_test1= pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ndf_test1['Fare'].groupby([df_test1['Pclass'], df_test1['Sex']]).mean()","18da9610":"df_test1['Fare'].groupby([df_test1['Pclass'], df_test1['Sex']]).median()","ceffaa9a":"# Setting up a loop to fill value for that specific row\n\nfor i in range(len(df_test['Fare'])):\n    if df_test['PassengerId'][i] == 1044:\n        df_test['Fare'][i] = 10\n               ","13e30a72":"# Checking it..\n\ndf_test.iloc[[152]]['Fare']","014f7e13":"print(df.shape)\nprint(df_test.shape)","1092d1b3":"df.head()","359745ff":"df_test.head()","b965ac0c":"id= df_test['PassengerId']\n\ndf.drop({'PassengerId', 'Died'}, axis=1, inplace= True)\ndf_test.drop({'PassengerId'}, axis=1, inplace= True)","731843b4":"print(df.shape)\nprint(df_test.shape)","6b1e10ae":"y= df['Survived']\ndf.drop({'Survived'}, axis= 1, inplace= True)","381eb329":"df1= df\ndf2= df_test\n\ndf= pd.get_dummies(df)\ndf_test= pd.get_dummies(df_test)","0ac8ba9b":"for col in df.columns:\n  if col not in df_test.columns:\n    df.drop({col}, axis= 1, inplace= True)\n    \nfor col in df_test.columns:\n  if col not in df.columns:\n    df_test.drop({col}, axis= 1, inplace= True)","2cdf021a":"# Checking out the shapes of both data sets:\n\nprint(df.shape)\nprint(df_test.shape)","89855cfa":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Splitting data for training, validation\n\nX_train, X_test, y_train, y_test= train_test_split(df, y, random_state= 42)\n","14b8eee0":"# Training the model to do some geeky magic!\nreg= GradientBoostingClassifier()\nreg.fit(X_train, y_train)","d9b5986b":"#Some \"scoring\",  because.. why not?\nreg.score(X_test, y_test)","95f569f3":"# Here we are predicting the label for an out-of-the-sample data which is our prime objective \n\na= reg.predict(df_test)","c70971c5":"a= pd.DataFrame({'PassengerId': id, 'Survived': a})\na.set_index('PassengerId', inplace= True)\n\na.to_csv('titanic_new.csv')\n\n# Then, setting the data in a way we are asked to- no index- so we can sort of make passenger_id our index\n\n\n\n# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"titanic_new.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe\ncreate_download_link(a)","48c19b97":"a","6abc0faa":"### Importing the libraries from Ministry of Magic, Hogwarts","80bd56e0":"### We can see here that females had a greater chances of survival than men. A perfect example from the movie- Rose survived.","d3dd3756":"### So, what this plot tells us is that passengers with cheaper ticket fares are more likely to die. Put differently, passengers with more expensive tickets- which also means a higher passanger class, and therefore a more important social status, seem to be rescued first.\n\n### If only Jack was rich...","c4dcb130":"### Checking do the missing values actually matter?\n#### What i mean is: is age and cabin highly correlated with the label we are interested in predicting?\n#### Let's find out!","f59cbdc7":"#### Looking up for this value in our dataset:\n\n#### Alright we can use an estimation that what would be generally the mean (or median) fare for someone travelling in class 3 and is aged over 60 years.","cf1ea5ed":"### And then forming a dataframe and stroting the predicted values in it, following which we shall save it in a csv file. ","f0a331e8":"Now, after doing this, you might have some unever number of columns, which would be a little bit dramatic for our model to understand","9d229bd5":"### The ritual called Visualizations :D\nLets see some interesting insights into the data- (The Titanic movie was a literal visualization, but alas- Jack never told us that female were more likely to survive more than men, so i guess we will have to use our Statistico Reducto spell!) :P","28e0f4cf":"### Let's see how Fare impacts survival.","8e406502":"## Thou shalt Behold thou data first!","25725831":"#### Visualizing Survival based on gender","6712f850":"### Couple of things here:\n\n#### We will nedd passenger id later during predicting survuval on testing data, so saving it in another variable.\n\n#### We also need to remove Died from training data and passenger id from both of the data sets. ","d019f209":"#### The one extra column in train is the label. so lets take that out:\n#### We can train_test_split the train then to get out validation data;","1db86f46":"### Age and cabin aren't really something we can afford to say \"correlated\" with our label. And missing values arent making them any more desirable.\n\n### so lets drop Cabin, Age, Embarked\n\n\n\n\n\n","b0ef4841":"#### One -hot encoding:\n\nSince we have categorical variables, we must convert them to some sort of numeric value so that our model could understand and create a relationship between various attributes. We can do that by-\n\n1. Label Encoder\n2. One Hot encoding\n\nWe will use One- hot here: (using pd.get_dummies)","5232724f":"## The score this notebook fetches is around 78.9%. it gets you in top 10% at the time of creating this noteboook.\nHappy MLing!","dd16db96":"### Lets try to impute that one missing value in the fare column in the test dataset.\nSee what is that about.","1a09de67":"#### We can see the mean price for a male in Pclass 3 is approximately 12 dollars, and the median is 8 dollars.\n#### Lets make it an even 10?\n#### Also, on a completely irrelevant topic: Did you notice, Female ticket prices are always higher than men?\n#### Intresting.."}}