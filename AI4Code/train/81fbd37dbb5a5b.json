{"cell_type":{"f55a8004":"code","00f2d82c":"code","8dac9f72":"code","4d8719cf":"code","09466a8a":"code","a6a0d064":"code","235a3fd6":"code","0bc11eae":"code","3a359614":"code","9a5621bd":"code","d6094720":"code","ad863f5a":"code","8d896ad1":"code","e92aa6fa":"code","5764d72a":"code","5dd64665":"code","1ce001eb":"code","63030f0d":"code","6b415775":"code","66bb336c":"code","416a40c5":"code","65c19f8e":"code","a50ed18d":"code","01e04b08":"code","e90d497c":"code","8c318d81":"markdown","6e6094d7":"markdown","149497ab":"markdown","59648ce2":"markdown","1f20c670":"markdown","9376e801":"markdown","7290d46e":"markdown","461a9ae6":"markdown","05363f03":"markdown","7f787e93":"markdown","a48a88c4":"markdown","0b35cd46":"markdown","a681463a":"markdown","69cfb200":"markdown","6892f05e":"markdown","f38f85ad":"markdown","12ab954f":"markdown","967bebd0":"markdown","69f969c1":"markdown","6495ff02":"markdown","c15d384a":"markdown","3bf5a131":"markdown"},"source":{"f55a8004":"!pip install ftfy\n!pip install gensim","00f2d82c":"#Para o uso geral\nimport random\nimport numpy as np\nimport pandas as pd\nimport copy \nimport time\nfrom scipy.stats import uniform\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nimport io\nfrom subprocess import check_output\n\n#Para o processamento de textos\nfrom ftfy import fix_text\nimport string\nimport re\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\n#Para Machine Learning e NLP\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score","8dac9f72":"path=\"..\/input\/sentiment-analysis-pmr3508\"\n\nprint(check_output([\"ls\", path]).decode(\"utf8\"))","4d8719cf":"%%time\ndata = pd.read_csv(path+\"\/data_train.csv\")","09466a8a":"data.head()","a6a0d064":"data.loc[data.duplicated(subset='review', keep=False)==True].sort_values(by='review').head(10)","235a3fd6":"data=data.drop_duplicates(subset='review', keep='first')\ndata.shape","0bc11eae":"data.loc[:,'positive'].value_counts()","3a359614":"X_train = data.loc[:,'review'].tolist()\ny_train = np.array(data.loc[:,'positive'].tolist())","9a5621bd":"X_train[5]","d6094720":"def clean(text):\n    txt=text.replace(\"<br \/>\",\" \") #retirando tags\n    txt=fix_text(txt) #consertando Mojibakes (Ver https:\/\/pypi.org\/project\/ftfy\/)\n    txt=txt.lower() #passando tudo para min\u00fasculo\n    txt=txt.translate(str.maketrans('', '', string.punctuation)) #retirando toda pontua\u00e7\u00e3o\n    txt=txt.replace(\" \u2014 \", \" \") #retirando h\u00edfens\n    txt=re.sub(\"\\d+\", ' <number> ', txt) #colocando um token especial para os n\u00fameros\n    txt=re.sub(' +', ' ', txt) #deletando espa\u00e7os extras\n    return txt","ad863f5a":"%%time\nX_train = [clean(x) for x in X_train]","8d896ad1":"X_train = [x.split() for x in X_train]","e92aa6fa":"%%time\nd2v = Doc2Vec.load(path+\"\/doc2vec\")  ","5764d72a":"def emb(txt, model, normalize=False): \n    model.random.seed(42)\n    x=model.infer_vector(txt, steps=20)\n    \n    if normalize: return(x\/np.sqrt(x@x))\n    else: return(x)","5dd64665":"%%time\nX_train = [emb(x, d2v) for x in X_train] \nX_train = np.array(X_train)","1ce001eb":"X_train.shape, y_train.shape","63030f0d":"%%time\nlogreg = LogisticRegression(solver='liblinear',random_state=42)\nhyperparams = dict(C=np.linspace(0,10,100), \n                     penalty=['l2', 'l1'])\nclf = RandomizedSearchCV(logreg, hyperparams, scoring='roc_auc', n_iter=50, cv=2, n_jobs=-1, random_state=0, verbose=2)\nsearch_logreg = clf.fit(X_train, y_train)","6b415775":"search_logreg.best_params_, search_logreg.best_score_ ","66bb336c":"logreg = LogisticRegression(C=search_logreg.best_params_['C'], \n                            penalty=search_logreg.best_params_['penalty'],\n                            solver='liblinear', random_state=42)\n\nlogreg.fit(X_train, y_train)","416a40c5":"%%time\ntest1 = pd.read_csv(path+\"\/data_test1.csv\")\nX_test1 = test1.loc[:,'review'].tolist()\nX_test1 = [clean(x).split() for x in X_test1]\nX_test1 = [emb(x, d2v) for x in X_test1] \nX_test1 = np.array(X_test1)\n\ny_test1 = np.array(test1.loc[:,'positive'].tolist())\n\nX_test1.shape, y_test1.shape","65c19f8e":"print('AUCs --- Log. Reg.: {:.4f}'.format(roc_auc_score(y_test1, logreg.predict_proba(X_test1)[:,1])))","a50ed18d":"%%time\ntest2 = pd.read_csv(path+\"\/data_test2_X.csv\")\nX_test2 = test2.loc[:,'review'].tolist()\nX_test2 = [clean(x).split() for x in X_test2]\nX_test2 = [emb(x, d2v) for x in X_test2] \nX_test2 = np.array(X_test2)\n\nX_test2.shape","01e04b08":"output = {'positive': logreg.predict_proba(X_test2)[:,1]}\noutput = pd.DataFrame(output)\n\noutput.head()","e90d497c":"output.to_csv(\"submission.csv\", index = True, index_label = 'Id')","8c318d81":"Treinando modelos finais e vendo suas performances no conjunto de teste","6e6094d7":"Em primeiro lugar, vamos carregar os pacotes que faremos uso:","149497ab":"Abrindo Doc2Vec pr\u00e9-treinado (treinado no notebook \"Introdu\u00e7\u00e3o ao Doc2Vec\"):","59648ce2":"Agora vamos criar as listas X_train e y_train, que cont\u00e9m os textos e os marcadores, respectivamente:","1f20c670":"Assim como feito no notebook \"Introdu\u00e7\u00e3o ao Doc2Vec\", vamos definir uma fun\u00e7\u00e3o para a limpeza e padroniza\u00e7\u00e3o dos textos.\n\n**MUITO IMPORTANTE:** \u00e9 *muito* recomendado que a fun\u00e7\u00e3o de limpeza utilizada no uso do modelo de representa\u00e7\u00e3o, i.e. Doc2Vec, seja **id\u00eantica** \u00e0 aquele utilizada no momento do treinamento do modelo de representa\u00e7\u00e3o.","9376e801":"# An\u00e1lise de sentimentos utilizando representa\u00e7\u00e3o Doc2Vec para textos\n\n#### Disciplina: PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es\n\nNeste notebook ser\u00e1 apresentado como fazer uso de um modelo Doc2Vec pr\u00e9-treinado para a an\u00e1lise de sentimentos. O modelo Doc2Vec foi introduzido em 2014 por [0] e tem duas poss\u00edveis formula\u00e7\u00f5es, sendo que aqui focaremos naquela an\u00e1loga ao Word2Vec COBW, que se chama PV-DM (Distributed Memory version of Paragraph Vector).\n\nO modelo Doc2Vec \u00e9 um \u00f3timo exemplo de como as Redes Neurais Artificiais podem ser utilizadas para gerar representa\u00e7\u00f5es estruturadas para dados, a princ\u00edpio, n\u00e3o estruturados. Como j\u00e1 foi dito, a vers\u00e3o mais popular do modelo Doc2Vec \u00e9 uma extens\u00e3o do famigerado modelo Word2Vec, que \u00e9 amplamente utilizado para gerar representa\u00e7\u00f5es para palavras e express\u00f5es. \u00c9 importante dizer que os treinamentos tanto do Word2Vec quanto do Doc2Vec s\u00e3o dados de maneira auto supervisionada (*self-supervised*), que resumidamente \u00e9 se fazer o uso de m\u00e9todos supervisionados tradicionais para a realiza\u00e7\u00e3o de tarefas tradicionalmente consideradas de aprendizado n\u00e3o supervisionado. O aprendizado auto supervisionado \u00e9 um paradigma moderno de aprendizagem e vale a pena pesquisar mais sobre.\n\nEscolhemos utilizar as representa\u00e7\u00f5es Doc2Vec para textos neste trabalho pois, apesar de n\u00e3o ser o estado da arte no que tange \u00e0 utiliza\u00e7\u00e3o de redes neurais para processamento de linguagem natural, temos os seguintes benef\u00edcios did\u00e1ticos e pr\u00e1ticos: (i) esse modelo \u00e9 uma extens\u00e3o de um dos modelos de redes neurais hist\u00f3ricamente mais importantes para NLP, que \u00e9 o Word2Vec; (ii) \u00e9 um modelo relativamente simples e que d\u00e1 uma boa ideia de como as Redes Neurais podem ser utilizadas para se trabalhar com dados n\u00e3o estruturados, e.g. textos; (iii) \u00e9 um modelo de f\u00e1cil\/r\u00e1pido treinamento e uso, o que possibilita a obten\u00e7\u00e3o de um bom baseline para seus projetos.\n\nAgora faremos uma breve introdu\u00e7\u00e3o de como utilizar um modelo Doc2Vec pr\u00e9-treinado em seus projetos de Machine Learning e NLP.\n\n### Base de dados que utilizaremos\n\nOs dados utilizados neste notebook podem ser encontradas em https:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/ em sua forma bruta. Gostar\u00edamos de agradecer aos autores de [0] por disponibilizarem os dados!\n\n\n### Refer\u00eancias\n\n[0] Le, Q., & Mikolov, T. (2014, January). Distributed representations of sentences and documents. In International conference on machine learning (pp. 1188-1196). Link: https:\/\/cs.stanford.edu\/~quocle\/paragraph_vector.pdf\n\n[1] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).","7290d46e":"#### Submiss\u00e3o","461a9ae6":"Tokenizando os textos:","05363f03":"Temos duas colunas, sendo que a primeira cont\u00e9m avalia\u00e7\u00f5es (escritas) sobre filmes e a segunda nos diz se aquela avalia\u00e7\u00e3o \u00e9 positiva ou negativa - se 'positive'==1 para uma certa avalia\u00e7\u00e3o, ent\u00e3o aquela avalia\u00e7\u00e3o tem sentimento positivo. Por outro lado, se 'positive'==0 para uma certa avalia\u00e7\u00e3o, ent\u00e3o aquela avalia\u00e7\u00e3o tem sentimento negativo. Tendo duas classes, dizemos que temos um problema de classifica\u00e7\u00e3o bin\u00e1ria.\n\nVamos ver a distribui\u00e7\u00e3o de 'positive':","7f787e93":"Vamos checar se h\u00e1 textos duplicados e especular se deveriam estar duplicados ou n\u00e3o:","a48a88c4":"Utilizando Random Search para escolher os melhores hiperpar\u00e2metros para o modelo de classifica\u00e7\u00e3o Regress\u00e3o Log\u00edstica para a an\u00e1lise de sentimentos com base na m\u00e9trica *roc_auc*:","0b35cd46":"### Resolu\u00e7\u00e3o\n\nVamos treinar uma regress\u00e3o log\u00edstica","a681463a":"Pelo fato de as avalia\u00e7\u00f5es duplicadas n\u00e3o serem muito simples, \u00e9 prov\u00e1vel que as duplica\u00e7\u00f5es de devam a erros na coleta dos dados e n\u00e3o duplica\u00e7\u00f5es que poderiam de fato ocorrer. Ent\u00e3o, vamos excluir uma das avalia\u00e7\u00f5es duplicadas:","69cfb200":"Limpando e padronizando os textos:","6892f05e":"Agora que j\u00e1 temos X_train e y_train nos formatos usuais e que voc\u00eas j\u00e1 conhecem bem, podemos seguir para a etapa de classifica\u00e7\u00e3o. Vamos ver os formatos dos dois arrays:","f38f85ad":"Obtendo as representa\u00e7\u00f5es vetoriais para os textos:","12ab954f":"Vamos definir uma fun\u00e7\u00e3o para obtermos as representa\u00e7\u00f5es vetoriais dos textos. \n\nNo momento do treinamento do Doc2Vec, geramos representa\u00e7\u00f5es somente para os textos que foram utilizados para aquele fim. Ent\u00e3o teremos que inferir as representa\u00e7\u00f5es para os novos textos, que utilizaremos agora. A infer\u00eancia \u00e9 feita utilizando a descida pela gradiente, congelando a rede neural do Doc2Vec e atualizando somente os pesos referentes ao novos textos. Na fun\u00e7\u00e3o abaixo, fixamos uma semente (*seed*) afim de garantir resultados reprodut\u00edveis e definimos que a descida pelo gradiente d\u00ea 20 passos:","967bebd0":"Abrindo dados para o treinamento do nosso classificador:","69f969c1":"### Iniciando...","6495ff02":"Vamos ver um dos textos:","c15d384a":"### Utilizando Doc2Vec e modelos supervisionados para An\u00e1lise de Sentimentos","3bf5a131":"Abrindo e processando conjunto de teste:"}}