{"cell_type":{"c776fb43":"code","dbabcbfe":"code","ab9c488e":"code","90f2a617":"code","3269d767":"code","23863a9b":"code","afc83dfb":"code","fa276bec":"code","ad640993":"code","6e50968e":"code","f50a7196":"code","d8e85b0a":"code","db372e6b":"code","f0dea292":"markdown","2d16d4cf":"markdown","526274d1":"markdown","6b466922":"markdown","5f3ea26e":"markdown","9cf3f90e":"markdown","a8216d05":"markdown","648e5bf4":"markdown","781c75e8":"markdown","8cdcf961":"markdown"},"source":{"c776fb43":"import numpy as np \nimport pandas as pd \nfrom collections import OrderedDict\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn import ensemble\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","dbabcbfe":"RANDOM_STATE = 42\nmin_estimators = 30\nmax_estimators = 100","ab9c488e":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","90f2a617":"#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","3269d767":"y = train[\"Survived\"]\nX = train.drop([\"Survived\"], axis=1)\nX_test = test","23863a9b":"rf1 = RandomForestClassifier(\n            warm_start=True,\n            oob_score=True,\n            max_features='sqrt',\n            random_state=RANDOM_STATE,\n        )\n\nrf2 =  RandomForestClassifier(\n            warm_start=True,\n            max_features='log2',\n            oob_score=True,\n            random_state=RANDOM_STATE,\n        )\n\nrf3 = RandomForestClassifier(\n            warm_start=True,\n            max_features=None,\n            oob_score=True,\n            random_state=RANDOM_STATE,\n        )\n\nrf4 = RandomForestClassifier(\n            warm_start=True,\n            max_features=0.5,\n            oob_score=True,\n            random_state=RANDOM_STATE,\n        )\n\nrf5 = RandomForestClassifier(\n            warm_start=True,\n            max_features=0.7,\n            oob_score=True,\n            random_state=RANDOM_STATE,\n        )\n\n\nensemble_clfs = [(\"rf1\",rf1),(\"rf2'\",rf2),(\"rf3\",rf3),(\"rf4\",rf4),(\"rf5\",rf5)]","afc83dfb":"error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\nerror_rate","fa276bec":"min_oob_error = 1.0\nmin_label = \"\"\nmin_index = 0\nfor label, clf in ensemble_clfs:\n    for i in range(min_estimators, max_estimators + 1):\n        clf.set_params(n_estimators=i)\n        clf.fit(X, y)\n\n        oob_error = 1 - clf.oob_score_\n        error_rate[label].append((i, oob_error))\n        \n        if min_oob_error > oob_error:\n            min_oob_error = oob_error\n            min_label = label\n            min_index = i\n        \n#         print(\"clf.oob_score_\",clf.oob_score_)\n#         print(\"oob_error\",round(oob_error,3))\n#         print(\"\")\n        \n        \nprint(\"min_oob_error=\",min_oob_error)\nprint(\"min_label=\",min_label)\nprint(\"min_index=\",min_index)","ad640993":"for label, clf_err in error_rate.items():\n    xs, ys = zip(*clf_err)\n    plt.plot(xs, ys, label=label)\n\nplt.xlim(min_estimators, max_estimators)\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"OOB error rate\")\nplt.legend(loc=\"upper right\")\nplt.show()","6e50968e":"rf = RandomForestClassifier(\n           n_estimators = 56,\n            warm_start=True,\n            max_features='sqrt',\n            oob_score=True,\n            random_state=RANDOM_STATE\n)\nrf.fit(X,y)","f50a7196":"y_train_pred = cross_val_predict(rf, X, y, cv=3)\nprint( confusion_matrix(y, y_train_pred) )\n\nprint(\"\")\n\nprint(\"precision_score1:\",precision_score(y, y_train_pred) )\ncm = confusion_matrix(y, y_train_pred)\nprint(\"precision_score2:\",cm[1, 1] \/ (cm[0, 1] + cm[1, 1]) )\n\nprint(\"\")\n\nprint(\"recall_score1:\",recall_score(y, y_train_pred))\nprint(\"recall_score2:\",cm[1, 1] \/ (cm[1, 0] + cm[1, 1]) )\n\nprint(\"\")\n\nprint(\"f1_score1:\",f1_score(y, y_train_pred))\nprint(\"f1_score2:\", cm[1, 1] \/ (cm[1, 1] + (cm[1, 0] + cm[0, 1]) \/ 2) )\n\nprint(\"\")\n\nprint(\"roc_auc score\",roc_auc_score(y, y_train_pred) )","d8e85b0a":"predictions = rf.predict(X_test)","db372e6b":"sub = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsub[\"Survived\"] = predictions\nsub.to_csv('submission.csv', index=False)\nsub.head()","f0dea292":"# Evaluate Model","2d16d4cf":"# common variables","526274d1":"# import libraries","6b466922":"# submission","5f3ea26e":"# define element models","9cf3f90e":"# split data","a8216d05":"# predict test data using stacking one model","648e5bf4":"# build model using best parameter ","781c75e8":"# preprocess","8cdcf961":"# load data"}}