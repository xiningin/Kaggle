{"cell_type":{"b29ac3c5":"code","1f48192b":"code","e3dca91b":"code","48ac4a6f":"code","0e3082da":"code","dd4d3074":"code","7df5484e":"code","8dc62fde":"code","633e3642":"code","e6fd7186":"code","a65dc965":"code","d32688de":"code","a30756b7":"code","45487d6c":"code","326f1123":"code","0db38e55":"code","a5472a1b":"code","c5f47c3f":"code","1d872e08":"code","109bd298":"code","6f8ab8dc":"code","57e0641f":"code","ff36957d":"code","4ed49e0d":"code","d8c4bc8d":"code","0f55170a":"code","40af947c":"code","c559cf0d":"code","b9276894":"code","5e29e6f7":"code","bace8cfa":"code","66766a3b":"code","0d1c7ad8":"code","e46d8ae1":"code","c562eca7":"code","0e80b862":"code","eb4c62c7":"code","676a7682":"code","3c25b692":"code","664bfaf0":"code","5a0e39ca":"code","b04d926a":"code","0d037a18":"code","b6e35843":"code","73ac6f00":"code","e2f58372":"code","f838aa78":"code","2e9d1714":"code","129a903f":"code","965df37e":"code","6329c9ff":"code","4b27b36a":"code","74b10244":"code","3f7d1006":"code","b83b1350":"code","6964e507":"code","636fab5d":"code","462d9e08":"code","816b1be7":"code","54211de7":"markdown","2133aac7":"markdown","32c87e8b":"markdown","db27f70e":"markdown","689ad02d":"markdown","c25b0329":"markdown","2ade6494":"markdown","80d15b4d":"markdown","2ae7b47d":"markdown"},"source":{"b29ac3c5":"import sys\nimport os\n\nimport albumentations\nimport pandas as pd\nimport numpy as np\n\nimport gc\nfrom glob import glob\nimport pickle\nimport json\nfrom pprint import pprint\nimport subprocess\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\n\nfrom tqdm import tqdm\nimport ast\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\n\n\nimport cv2\n\nfrom tqdm import tqdm","1f48192b":"# !python -m pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'","e3dca91b":"# import detectron2\n# from detectron2.utils.logger import setup_logger\n\n# # import some common detectron2 utilities\n# from detectron2 import model_zoo\n# from detectron2.engine import DefaultPredictor\n# from detectron2.config import CfgNode, LazyConfig, get_cfg, instantiate\n# from detectron2.utils.visualizer import Visualizer\n# from detectron2.data import MetadataCatalog, DatasetCatalog\n# from detectron2.structures import Boxes, Instances, ROIMasks\n# from detectron2.modeling import GeneralizedRCNN\n# from detectron2.data import DatasetFromList\n# from detectron2.checkpoint import DetectionCheckpointer\n","48ac4a6f":"DATA_DIR = '..\/input\/petfinder-pawpularity-score'\nIMG_PATH = '..\/input\/petfinder-pawpularity-score'","0e3082da":"train_df=pd.read_csv(f'{DATA_DIR}\/train.csv')\ntest_df=pd.read_csv(f'{DATA_DIR}\/test.csv')\n\ntrain_df['image_path'] = f'{IMG_PATH}\/train\/' + train_df['Id'] + '.jpg'\ntest_df['image_path'] = f'{IMG_PATH}\/test\/' + test_df['Id'] + '.jpg'","dd4d3074":"# model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")","7df5484e":"# cfg = get_cfg()\n# # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n# # Find a model from detectron2's model zoo. You can use the https:\/\/dl.fbaipublicfiles... url as well\n# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n\n# predictor = DefaultPredictor(cfg)","8dc62fde":"# !echo a | python -m pip download 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'\n# import pickle\n# with open('mask_rcnn_X_101_32x8d_FPN_3x.pkl', 'wb') as p:\n#     pickle.dump(predictor, p)","633e3642":"# MetadataCatalog.get(cfg.DATASETS.TRAIN[0])","e6fd7186":"# train_df['height'] = 0\n# train_df['width'] = 0\n# train_df['fields'] = ''\n# train_df","a65dc965":"# cfg.INPUT.FORMAT","d32688de":"# %%time\n\n# plt.figure(figsize=(24, 24))\n\n# for index in tqdm(range(len(train_df))):\n#     # for index in tqdm(range(16)):\n#     im = cv2.imread(train_df.loc[index, 'image_path'])\n#     outputs = predictor(im)\n    \n# #     # Visualize\n# #     v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n# #     out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n# #     out = out.get_image()\n# #     out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n# #     plt.subplot(4, 4, index+1)\n# #     plt.imshow(out[:, :, ::-1])\n    \n#     # Add detect information to table\n#     (height, width) =  outputs['instances'].image_size\n#     fields = outputs['instances'].get_fields()\n#     fields.pop('pred_masks')\n\n#     train_df.loc[index, ['height', 'width', 'fields']] = height, width, fields\n    \n    ","a30756b7":"# train_df.loc[0:15, ['image_path', 'height', 'width', 'fields']]","45487d6c":"# train_df.loc[0, 'fields']","326f1123":"# train_df['Persons'] = 0\n# train_df['Cats'] = 0\n# train_df['Dogs'] = 0\n# train_df","0db38e55":"# for index in tqdm(range(len(train_df))):\n#     # for index in tqdm(range(16)):\n#     train_df.loc[index, 'Persons'] = train_df.loc[index, 'fields']['pred_classes'].tolist().count(0)\n#     train_df.loc[index, 'Cats'] = train_df.loc[index, 'fields']['pred_classes'].tolist().count(15)\n#     train_df.loc[index, 'Dogs'] = train_df.loc[index, 'fields']['pred_classes'].tolist().count(16)\n# train_df","a5472a1b":"# train_df.to_csv(\"train.csv\", index=False)","c5f47c3f":"# train_df['Cats'].sum()","1d872e08":"# train_df['Dogs'].sum()","109bd298":"# train_df['Persons'].sum()","6f8ab8dc":"DATA_DIR = '..\/input\/petfinder2-detected-info'\n\ntrain_df=pd.read_csv(f'{DATA_DIR}\/train.csv')\ntrain_df['image_path'] = f'{IMG_PATH}\/train\/' + train_df['Id'] + '.jpg'\ntrain_df","57e0641f":"train_df['fields'] = train_df['fields'].apply(fields_to_dict)\ntrain_df['fields']","ff36957d":"add_hwf(train_df)","4ed49e0d":"train_df_info['Cats'].sum()","d8c4bc8d":"train_df_info['Dogs'].sum()","0f55170a":"train_df_info['Persons'].sum()","40af947c":"plt.figure(figsize=(12, 6))\nplt.hist(train_df['height'])","c559cf0d":"plt.figure(figsize=(12, 6))\nplt.hist(train_df['width'])","b9276894":"plt.figure(figsize=(12, 6))\nplt.hist(train_df['height'] + train_df['width'])","5e29e6f7":"plt.figure(figsize=(12, 6))\nplt.hist(train_df['Persons'])","bace8cfa":"# Reason only plot 5 cats are the number of sample is too small over 5 cats.\nprint(train_df[train_df['Persons']==0]['Pawpularity'].mean(), train_df[train_df['Persons']>0]['Pawpularity'].mean())\n\nplt.figure(figsize=(12, 6))\nplt.hist(train_df[train_df['Persons']==0]['Pawpularity'], 50, alpha = 0.5, label=f'No person', density=True, stacked=True)\nplt.hist(train_df[train_df['Persons']>0]['Pawpularity'], 50, alpha = 0.5, label=f'Persons', density=True, stacked=True)\nplt.legend(loc='upper left')","66766a3b":"# Compare to labeled data\nb_same_sum = sum((train_df['Human']) == (train_df['Persons'] > 0))\nprint(f'Both of labels is same {b_same_sum}')\nprint(f'Different labels {len(train_df) - b_same_sum}')","0d1c7ad8":"# Human label is 0 but detectron2 detect human\nspecific_train = train_df[(train_df['Human'] == 0) & (train_df['Persons'] > 0)]\n\nplt.figure(figsize=(24, 24))\n\n# for index in tqdm(range(len(train_df))):\nfor index in range(16):\n    im = cv2.imread(specific_train.iloc[index]['image_path'])\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    plt.subplot(4, 4, index+1)\n    plt.title(specific_train.iloc[index]['Pawpularity'])\n    plt.imshow(im)","e46d8ae1":"# Human label is 1 but detectron2 can't detect human\nspecific_train = train_df[(train_df['Human'] == 1) & (train_df['Persons'] == 0)]\n\nplt.figure(figsize=(24, 24))\n\n# for index in tqdm(range(len(train_df))):\nfor index in range(16):\n    im = cv2.imread(specific_train.iloc[index]['image_path'])\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    plt.subplot(4, 4, index+1)\n    plt.title(specific_train.iloc[index]['Pawpularity'])\n    plt.imshow(im)","c562eca7":"len(train_df[train_df['Cats'] > 0])","0e80b862":"plt.figure(figsize=(12, 6))\nplt.hist(train_df['Cats'])","eb4c62c7":"# Reason only plot 5 cats are the number of sample is too small over 5 cats.\nplt.figure(figsize=(12, 6))\nfor i in range(1, 4):\n    print(len(train_df[train_df['Cats']==i]), train_df[train_df['Cats']==i]['Pawpularity'].mean())\n    plt.hist(train_df[train_df['Cats']==i]['Pawpularity'], 50, alpha = 0.4, label=f'{i} cats', density=True, stacked=True)\nplt.legend(loc='upper left')","676a7682":"# Cat pictures\nspecific_train = train_df[train_df['Cats'] > 0]\n\nplt.figure(figsize=(24, 24))\n\n# for index in tqdm(range(len(train_df))):\nfor index in range(16):\n    im = cv2.imread(specific_train.iloc[index]['image_path'])\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    plt.subplot(4, 4, index+1)\n    plt.title(specific_train.iloc[index]['Pawpularity'])\n    plt.imshow(im)","3c25b692":"len(train_df[train_df['Dogs'] > 0])","664bfaf0":"plt.figure(figsize=(12, 6))\nplt.hist(train_df['Dogs'])","5a0e39ca":"plt.figure(figsize=(12, 6))\nfor i in range(1, 4):\n    print(len(train_df[train_df['Dogs']==i]), train_df[train_df['Dogs']==i]['Pawpularity'].mean())\n    plt.hist(train_df[train_df['Dogs']==i]['Pawpularity'], 50, alpha = 0.4, label=f'{i} dogs', density=True, stacked=True)\nplt.legend(loc='upper left')","b04d926a":"# Cat pictures\nspecific_train = train_df[train_df['Dogs'] > 0]\n\nplt.figure(figsize=(24, 24))\n\n# for index in tqdm(range(len(train_df))):\nfor index in range(16):\n    im = cv2.imread(specific_train.iloc[index]['image_path'])\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    plt.subplot(4, 4, index+1)\n    plt.title(specific_train.iloc[index]['Pawpularity'])\n    plt.imshow(im)","0d037a18":"print('Cats and Dog mean')\nprint(train_df[train_df['Cats']>0]['Pawpularity'].mean(), train_df[train_df['Dogs']>0]['Pawpularity'].mean())","b6e35843":"# Normalized histgram\nplt.figure(figsize=(12, 6))\nplt.hist(train_df[train_df['Cats']>0]['Pawpularity'], 50, alpha = 0.5, label='Cats', density=True, stacked=True)\nplt.hist(train_df[train_df['Dogs']>0]['Pawpularity'], 50, alpha = 0.5, label='Dogs', density=True, stacked=True)\nplt.legend(loc='upper left')","73ac6f00":"# The number of animals\ntrain_df['Animals'] = train_df['Cats'] + train_df['Dogs']","e2f58372":"plt.figure(figsize=(12, 6))\nfor i in range(0, 5):\n    print(len(train_df[train_df['Animals']==i]), train_df[train_df['Animals']==i]['Pawpularity'].mean())\n    plt.hist(train_df[train_df['Animals']==i]['Pawpularity'], 50, alpha = 0.4, label=f'{i} animals', density=True, stacked=True)\nplt.legend(loc='upper left')","f838aa78":"# Showing pictures\nfor i in range(0, 8):\n    # Cat pictures\n    specific_train = train_df[train_df['Animals']==i]\n    \n    plt.figure(figsize=(24, 12))\n    plt.suptitle(f'{i} animals')\n\n    # for index in tqdm(range(len(train_df))):\n    for index in range(8):\n        im = cv2.imread(specific_train.iloc[index]['image_path'])\n        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        \n        plt.subplot(1, 8, index+1)\n        plt.title(specific_train.iloc[index]['Pawpularity'])\n        plt.imshow(im)","2e9d1714":"train_df['fields'][0]","129a903f":"plt.figure(figsize=(24, 24))\nfor index in range(16):\n    im = cv2.imread(train_df.loc[index, 'image_path'])\n    outputs = train_df.loc[index, 'fields']\n    outputs = predictor(im)\n    print(outputs)\n    print(type(outputs))\n    break\n    \n    # Visualize\n    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    out = out.get_image()\n    out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n    plt.subplot(4, 4, index+1)\n    plt.title(train_df.iloc[index]['Pawpularity'])\n    plt.imshow(out[:, :, ::-1])","965df37e":"import json","6329c9ff":"\nfrom detectron2.structures import Boxes, Instances, ROIMasks\n\ntrain_df['fields'].apply(Instances)","4b27b36a":"train_df['fields'][0]","74b10244":"train_df['fields'][0][1:-1]","3f7d1006":"train_df['fields']['']","b83b1350":"test = ast.literal_eval(train_df['fields'][0])","6964e507":"\nast.literal_eval(json.dumps(train_df['fields'][0], ensure_ascii=False).encode('utf8'))\n","636fab5d":"test = detectron2.structures.instances.Instances(image_size=[train_df['height'][0], train_df['width'][0]], train_df['fields'][0])","462d9e08":"test","816b1be7":"test.get('pred_boxes')","54211de7":"## Persons","2133aac7":"### Dogs","32c87e8b":"## Image Size","db27f70e":"## Cats and Dogs","689ad02d":"## Compare Dog and Cat","c25b0329":"Showing how to make published petfinder2-detected-info dataset.\nBelow program is proceses of only 16 samples.","2ade6494":"### Cats","80d15b4d":"<img src=\"https:\/\/github.com\/facebookresearch\/detectron2\/raw\/main\/.github\/Detectron2-Logo-Horz.svg\" width=\"300\" >\n\nDetectron2 is Facebook AI Research's next generation library\nthat provides state-of-the-art detection and segmentation algorithms.\nIt is the successor of\n[Detectron](https:\/\/github.com\/facebookresearch\/Detectron\/)\nand [maskrcnn-benchmark](https:\/\/github.com\/facebookresearch\/maskrcnn-benchmark\/).\nIt supports a number of computer vision research projects and production applications in Facebook.\n\n<div align=\"center\">\n  <img src=\"https:\/\/user-images.githubusercontent.com\/1381301\/66535560-d3422200-eace-11e9-9123-5535d469db19.png\"\/>\n<\/div>\n\nSourced from [detectron2(github)](https:\/\/github.com\/facebookresearch\/Detectron\/)\n\n<\/br>\n\nI wrote some ideas to improve model at [Please check my ideas to improve model\ud83d\ude4f](https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/295808).\nThe 3 idea is \"Training by using crop dogs and cats by Object Detection images\", and the 4 idea is \"Separate dogs and cats then train\".\n\nThus, in this code I did object detect as a pre-process of these two ideas, I used detectron2's COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x model to detect cats and dogs.\nThen I did EDA, so I show my result.\n\nThe train.csv with object detect infomation like is [petfinder2-detect-info](https:\/\/www.kaggle.com\/masaishi\/petfinder2-detected-info)\n\n<\/br>\n\n### Result\nCats and dogs have different pawpularity distributions.\nCats mean is 35.62513274336283, and dog one is 41.24786324786325.\nThus, dogs' image can get beter pawpularity, so the 4 idea of making model for only cats and dogs may be good.\n","2ae7b47d":"By doing that procese, I generate petfinder2-detected-info dataset.\n\n# EDA of detect info"}}