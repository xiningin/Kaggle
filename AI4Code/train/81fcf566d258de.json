{"cell_type":{"e612ba3e":"code","9aa8a943":"code","2e1cdabd":"code","ad1f6f8d":"code","b7e273aa":"code","3bf9e24f":"code","34ad061d":"code","53159235":"code","2c6f6805":"code","4100ee2b":"code","4c345223":"code","fba67fc0":"code","911eb02d":"code","a1476ae2":"code","ca765efe":"code","6d245efd":"code","bbbd38d3":"code","3e62dc08":"code","afc7e4b5":"code","008a42c1":"code","ca47613e":"code","e4da9eed":"code","3860d19d":"code","83d3d5cc":"code","c7ce733d":"code","33c96922":"code","f77365ea":"code","66a57fc2":"code","9208cb66":"code","0a548471":"code","31f72e7f":"code","466adb25":"code","a84cfaf8":"code","37ca3301":"code","3fa43252":"code","316a6567":"code","c5f73d91":"code","ab106da1":"code","13e59d3f":"code","bc9f3c36":"code","d7aea1cc":"code","8bd48eef":"code","076cfee8":"code","64553245":"code","669f25bf":"code","e854890e":"code","473fd309":"code","73b77125":"code","29c77a3d":"code","4e8f2a58":"code","fe4e74e8":"code","d61deda8":"code","951c3e2a":"code","810e27c5":"code","547c7ada":"code","8e55677b":"code","d69afe14":"code","63284500":"code","8869b490":"markdown","21c200c0":"markdown","51991ba2":"markdown","e98c6e4c":"markdown","af487422":"markdown","e1cf1e0d":"markdown","a7953aaf":"markdown","751f369a":"markdown","ab439f6c":"markdown","c1bb37c8":"markdown","7a2330c5":"markdown","9c894000":"markdown","4a9a77c9":"markdown","daa7f186":"markdown","e636f365":"markdown","d988aee5":"markdown","d98b96e1":"markdown"},"source":{"e612ba3e":"import pandas as pd\nimport numpy as np\nimport random\n%matplotlib inline\nimport matplotlib.pyplot as plt","9aa8a943":"data = pd.read_csv('..\/input\/Indicators.csv')\ndata.shape","2e1cdabd":"countries = pd.read_csv('..\/input\/Country.csv') \ncountries.shape","ad1f6f8d":"# the group of countries\ncountries[countries['CurrencyUnit'].isnull()].head()","b7e273aa":"# creation of a series for the countries only\nsr_countries_only = countries[countries['CurrencyUnit'].isnull()==False]['CountryCode']","3bf9e24f":"# filter of counties\nfilterCountry = (data['CountryCode'].isin(sr_countries_only))","34ad061d":"# countries data\ndataCountries= data[filterCountry]","53159235":"dataCountries.head()","2c6f6805":"dataCountries.loc[filterCountry,'ID']=dataCountries.loc[filterCountry,'CountryCode']+dataCountries.loc[filterCountry,'Year'].map(str)","4100ee2b":"dataCountries['ID'].isnull().any()","4c345223":"pd.crosstab(dataCountries['ID'].isnull(),dataCountries['CountryCode'].isnull())","fba67fc0":"dataCountries.loc[:,'CNT'] = 1\n#del dataCountries['CNT']","911eb02d":"dataCountries.loc[:5,'CNT']","a1476ae2":"# checking if the length of all the country code is 3\ntmp = pd.DataFrame({'lng':dataCountries['CountryCode'].str.len()})\ntmp['cnt'] = 1\ntmp.groupby('lng').sum()","ca765efe":"dataCountries[dataCountries['IndicatorCode']=='NY.GDP.MKTP.KN'].head()","6d245efd":"GDP_lcu = dataCountries[dataCountries['IndicatorCode']=='NY.GDP.MKTP.KN'][['ID','Value']]\nGDP_lcu.head()","bbbd38d3":"GDP_lcu.columns=['ID', 'GDP_lcu']","3e62dc08":"GDP_lcu.shape","afc7e4b5":"dataCountries.head()","008a42c1":"# gdp per capita in usd\nGDP_perCapita = dataCountries[dataCountries['IndicatorCode']=='NY.GDP.PCAP.KD'][['ID','Value']]\nGDP_perCapita.columns=['ID', 'GDP_perCapita']\nGDP_perCapita.shape","ca47613e":"GDP_perCapita.head()","e4da9eed":"# Labour\nlabour = dataCountries[dataCountries['IndicatorCode']=='SL.TLF.TOTL.IN'][['ID','Value']]\nlabour.columns=['ID', 'labour']\nlabour.shape","3860d19d":"labour.head()","83d3d5cc":"# capital\ncapital = dataCountries[dataCountries['IndicatorCode']=='NE.GDI.TOTL.KN'][['ID','Value']]\ncapital.columns=['ID', 'capital']\ncapital.shape","c7ce733d":"capital.head()","33c96922":"# population\npopulation = dataCountries[dataCountries['IndicatorCode']=='SP.POP.TOTL'][['ID','Value']]\npopulation.columns=['ID', 'population']\npopulation.shape","f77365ea":"population.head()","66a57fc2":"consumption=dataCountries[dataCountries['IndicatorCode']=='NE.CON.TETC.CD'][['ID','Value']]\nconsumption.columns=['ID', 'consumption']\nconsumption.shape","9208cb66":"consumption.head()","0a548471":"dataModel = GDP_lcu\ndataModel =  pd.merge(dataModel, GDP_perCapita, on='ID', how='inner')","31f72e7f":"dataModel.shape","466adb25":"dataModel =  pd.merge(dataModel, labour, on='ID', how='inner')\ndataModel.shape","a84cfaf8":"dataModel =  pd.merge(dataModel, capital, on='ID', how='inner')\ndataModel.shape","37ca3301":"dataModel =  pd.merge(dataModel, population, on='ID', how='inner')\ndataModel.shape","3fa43252":"dataModel =  pd.merge(dataModel, consumption, on='ID', how='inner')\ndataModel.shape","316a6567":"dataModel.head()","c5f73d91":"dataModel['Year'] = pd.to_numeric(dataModel['ID'].str.slice(3, 7)) ","ab106da1":"dataModel.head()","13e59d3f":"dataModel['CNT']=1","bc9f3c36":"dataModel.groupby('Year').sum()['CNT']","d7aea1cc":"dataModel.loc[:,'GDP_usd'] = dataModel['GDP_perCapita'] * dataModel['population']","8bd48eef":"dataModel.head()","076cfee8":"dataModel.loc[:,'Capital_usd'] = dataModel['capital']\/dataModel['GDP_lcu'] * dataModel['GDP_usd']","64553245":"dataModel.head()","669f25bf":"dataModel.loc[:,'Production_usd'] = dataModel['GDP_usd'] + dataModel['consumption']","e854890e":"dataModel.head()","473fd309":"from sklearn.linear_model import LinearRegression\n# from sklearn.model_selection import train_test_split \n# from sklearn.metrics import mean_squared_error\n# from math import sqrt","73b77125":"# getting the unique years from the DataFrame dataModel\nnda_years=pd.unique(dataModel['Year'])","29c77a3d":"# creating an empty dataframe\nelasticities=pd.DataFrame(columns=['Year', 'ElasticityLabour','ElasticityCapital'])\nelasticities.head()","4e8f2a58":"features=['labour','Capital_usd']\ntarget=['Production_usd']\ndataModel.shape","fe4e74e8":"dataModel.to_csv('dataModel-all-years.csv',sep=',') # some negative values were identified for the capital (6 observations).\n    # these negative observations will be deleted.","d61deda8":"dataModel = dataModel[dataModel['Capital_usd']>0]\ndataModel.shape","951c3e2a":"j=0\nfor i in nda_years:\n    # setting the year\n    elasticities.loc[j,'Year'] = i\n    \n    # Selecting the features for the year i\n    X = dataModel[dataModel['Year']==i][features]\n    \n    # Selecting the target for the year i\n    Y = dataModel[dataModel['Year']==i][target]\n    \n    # Defining a linear regressor\n    regressor = LinearRegression()\n    regressor.fit(np.log(X),np.log(Y))\n    \n    # setting the elasticities\n    elasticities.loc[j,'ElasticityLabour'] = regressor.coef_[0][0]\n    elasticities.loc[j,'ElasticityCapital'] = regressor.coef_[0][1]\n    j=j+1","810e27c5":"elasticities","547c7ada":"elasticities.index= elasticities['Year'].values","8e55677b":"elasticities","d69afe14":"plt.plot(elasticities['Year'], elasticities['ElasticityLabour'], color='blue', linewidth=1, label='Labour Elasticity')\nplt.plot(elasticities['Year'], elasticities['ElasticityCapital'], color='green', linewidth=1, label='Capital Elasticity')\nplt.xlabel('Year')\n#plt.ylabel('Elasticities (%)')\nplt.title('Labour Elasticity VS Capital Elasticity over the year 1990 to 2014')\nplt.legend(loc='center left')\nplt.show()","63284500":"# Some data\nlabels = 'Labour Elasticity', 'Capital Elasticity'\nfracs1990 = list(np.array(elasticities[elasticities['Year']==1990][['ElasticityLabour','ElasticityCapital']])[0])\nfracs2000 = list(np.array(elasticities[elasticities['Year']==2000][['ElasticityLabour','ElasticityCapital']])[0])\nfracs2014 = list(np.array(elasticities[elasticities['Year']==2014][['ElasticityLabour','ElasticityCapital']])[0])\n\n# Make figure and axes\nfig, axs = plt.subplots(3,1, figsize=(3, 15))\n\n# A standard pie plot\naxs[0].pie(fracs1990, labels=labels, autopct='%1.1f%%', shadow=True)\naxs[0].set_title(\"Labour VS Capital in 1990\")\n\n# Shift the second slice using explode\naxs[1].pie(fracs2000, labels=labels, autopct='%.0f%%', shadow=True)\naxs[1].set_title(\"Labour VS Capital in 2000\")\n\n# Shift the second slice using explode\naxs[2].pie(fracs2014, labels=labels, autopct='%.0f%%', shadow=True)\naxs[2].set_title(\"Labour VS Capital in 2014\")\n\nplt.show()","8869b490":"### 3.2.2. Selection of the GDP per capital in USD, Labour, Capital in local currency, total population, Consumption in local currency","21c200c0":"# 1. Objective\n\nBased on [Cobb-Douglas production function](https:\/\/en.wikipedia.org\/wiki\/Cobb%E2%80%93Douglas_production_function), it is expected to get the sum of the respective elasticities of labour and capital equal to 1 (`i.e.` \u03b1 + \u03b2 = 1). The production function is definied as following:\n\n$$P = a.L^\\alpha.K^\\beta$$\n\n* P = total production (the real value of all goods produced in a year or 365.25 days)\n* L = labor input (the total number of person-hours worked in a year or 365.25 days)\n* K = capital input (the real value of all machinery, equipment, and buildings)\n* a = total factor productivity and your usual depreciation by utility in day after\n* \u03b1 and \u03b2 are the output elasticities of capital and labor, respectively. These values are constants determined by available technology in the economy.\n\nOver the years, the economy is relying more and more on technology. So, it is expected to get, on one hand, the capital elasticity increasing over the years. On the other hand, the labour elasticity is decreasing over the years.\n\nThe questions to be answered in this mini-project are the following:\n\n1. How are the capital and the labour elasticities are distributed over the years? (which productivity factor is contributing the most in economy?)\n\n2. Do the trends of the capital elasticity and the labour elasticity confirm the increase of the technology usage in whole the world economy?\n\n## 1.2. The outline of project\n\n## 1.3. What measures the output elasticity?\nThe output elasticity measures the responsiveness of output to a change in levels of either labor or capital used in production. For example, if \u03b1 = 0.45, a 1% increase in capital usage would lead to approximately a 0.45% increase in output.\n\n","51991ba2":"**Conclusions:**\n\n1. The figure above shows clearly that the capital is contributing more than the labour and in large scale. In 90s, the labour is contributing around 17% and the capital is contributing around 82%. But, starting from 2009, the labour contribution to the production is below ~10% and did not get higher than that. **The production is relying mainly on capital. In other terms, the production is relying on technology rather than on labour**\n\n2. There were some fluctuations on the distribution of the elasticities between labour and capital during the years 1990-2011. But, starting from 2011, there is clear descent of the labour productivity. **It seems to be the begining of the Artificial Intelligence and Machine Learning Era**.\n\n**Perspective**\n\nBased on conclusion 2, **it seems to be low skilled labour will stuggle to get jobs**. In fact, these low skilled labour would not be able to deal with new technologies at work. To confirm this hypothesis, a distribution of labour by skilled and skilled is required to observe their elasticities during the years.\n\nThe suggested production function would be as follows:\n\n$$ P = a. L^{\\alpha_1}_{Skilled}.L^{\\alpha_2}_{NonSkilled}.k^{\\beta}$$\n\n\n","e98c6e4c":"## 3.1. Selection of the targeted countries\nSome observations in the `Country.csv` files are not countries. In fact, they are groups of countries such as **Euro area**. These groups of countries will not targeted in the study.\n\nThese groups of countries can be identified through the variable `CurrencyUnit` when it is `NA`.","af487422":"### 3.2.5. Calculation the production in USD\n\n**PS:** the `consumption` variable is already defined in current USD. No conversion is needed.","e1cf1e0d":"# 4. Building the models","a7953aaf":"### 3.2.3. Merging the variables in one single DataFrame\nAs it can be seen in the previous the observations are having different size. Only the commun parts will be taken","751f369a":"## 3.2. Selection of the Cobb-Douglas variables\n\nThe variables to be collected are:\n\n* Production\n* Capital\n* Labour\n\n**Production:** It is approximated by the GDP per capita multiplied by the total population + the total consumption.\n\nSince the GDP variable in WDI data is in local currency and no exchange rates are available for each currency with the USD for each year, the GDP in USD will be simply the GDP per capita _(which is in USD)_ multiplied by the total population.\n\n**Capital:** It is the gross capital formation. Since, the variable needs to be converted in USD, the exchange rate will be GDP per capita multiplied by the total population and then divided by the GDP in the local currency\n\n**Labour:** To be taken as it is.","ab439f6c":"## 4.1. Setting the features and the target","c1bb37c8":"### 3.2.4. Converting the Capital in usd\n\nThe Conversion will be based on the `GDP_lcu` and `GDP_usd`.\n\n$$CapitalUSD = Capital . \\frac{GdpUSD}{GdpLCU}$$","7a2330c5":"# 2. Loading libraries","9c894000":"<br><p style=\"font-family: Arial; font-size:2em;color:purple; font-style:bold\">\n<br> <br>World Development Indicators:<br> <br> Labour elasticity VS Capital elasticity  <br><br> over the years:<br><br> Towards AI\/ML era?<\/p>\n\n","4a9a77c9":"# 5. Labour Elasticity VS Capital Elasticity","daa7f186":"### 3.2.4. Getting the GDP in USD\n\nBefore starting building the Cobb-Douglas production model for each year, there must enough observations for each year.\n\nThe query below showed it is safe to build a model for each year.","e636f365":"# 3. Loading data","d988aee5":"### 3.2.3. Getting the year","d98b96e1":"### 3.2.1. Selection of the GDP in local currency"}}