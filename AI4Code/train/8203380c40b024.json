{"cell_type":{"b6e4ea40":"code","73887ac4":"code","4213484d":"code","4cf12389":"code","5a2d3289":"code","bd598bdc":"code","c2b776e0":"code","faf0f947":"code","d2d5502d":"code","361c767f":"code","9203cd52":"code","6df3f619":"code","dbc5046d":"code","dfdc60cc":"code","bce59750":"code","333f974b":"code","3acdb56e":"code","bb80b2b0":"code","ceaab19b":"markdown","c9da2bf1":"markdown","30499603":"markdown","d58059b2":"markdown","7049e28e":"markdown","3b3686fc":"markdown","b33e61f7":"markdown","ef6926a6":"markdown","ededb5b2":"markdown"},"source":{"b6e4ea40":"import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","73887ac4":"import wandb\nfrom wandb.keras import WandbCallback\nfrom tensorflow.keras.callbacks import TensorBoard","4213484d":"# !wandb login","4cf12389":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","5a2d3289":"# plotting some random 10 images\nclass_names = ['airplane','automobile','bird','cat','deer',\n               'dog','frog','horse','ship','truck']\nnum_classes = 10\n\nfig = plt.figure(figsize=(8,3))\nfor i in range(num_classes):\n    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n    idx = np.where(y_train[:]==i)[0]\n    features_idx = x_train[idx,::]\n    img_num = np.random.randint(features_idx.shape[0])\n    im = (features_idx[img_num,::])\n    ax.set_title(class_names[i])\n    plt.imshow(im)\nplt.show()","bd598bdc":"# convert to float, normalise the data\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255","c2b776e0":"y_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)","faf0f947":"batch_size = 32\nepochs = 50","d2d5502d":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))","361c767f":"model.summary()","9203cd52":"# compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='Adam',\n              metrics=['accuracy'])","6df3f619":"history = model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True,\n              callbacks=[#WandbCallback(data_type=\"image\", labels=class_names), \n              TensorBoard(log_dir='.\/log1\/', histogram_freq=1)]\n            )","dbc5046d":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","dfdc60cc":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512,kernel_regularizer=l2(0.01)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))","bce59750":"model.summary()","333f974b":"# compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='Adam',\n              metrics=['accuracy'])","3acdb56e":"history = model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True,\n              callbacks=[#WandbCallback(data_type=\"image\", labels=class_names), \n              TensorBoard(log_dir='.\/log2\/', histogram_freq=1)])","bb80b2b0":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","ceaab19b":"# Model Architecture without Batch Normalization","c9da2bf1":"# Introduction","30499603":"The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10 classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets provides 10,000 images. This image taken from the CIFAR repository ( https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html ). This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset.","d58059b2":"## Dataset","7049e28e":"# Load and split data into train and test sets","3b3686fc":"# Model Architecture without Batch Normalization","b33e61f7":"# Import Libraries","ef6926a6":"<div style=\"text-align: center;\">\n<img src= \"https:\/\/github.com\/zyper26\/Skin-Cancer-ISIC\/blob\/main\/cifar_10.jpeg?raw=true\" title =\"Dataset Example\" style='width: 1000px;'>\n<\/div>","ededb5b2":"# Convert class vectors to binary class matrices."}}