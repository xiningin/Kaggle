{"cell_type":{"e1c201a3":"code","f97b44da":"code","19d62443":"code","00a9e241":"code","655617cc":"code","119af54c":"code","b0621c26":"code","165017a1":"code","57b3c5e8":"code","ab65a12b":"code","223eb66b":"code","e9d01e9c":"code","09403559":"code","fc2e1c1a":"code","24484444":"code","f58aea7f":"code","7bccf54a":"code","ba34fd6c":"code","82d80c8d":"code","d4238ab3":"code","dc0bbd15":"code","f5b56416":"code","20708b41":"code","83fd1af4":"code","d1046a36":"code","5aa3ddb6":"code","20ad122e":"markdown","2132ceb6":"markdown","777c8768":"markdown"},"source":{"e1c201a3":"import pandas as pd\ndf=pd.read_csv(\"..\/input\/fake-news\/train.csv\")\ndf.head()","f97b44da":"df.shape","19d62443":"df.info()","00a9e241":"round((df.isnull().sum().sort_values(ascending=False) * 100 \/len(df)),2)","655617cc":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer","119af54c":"df=df.dropna()\ndf.shape","b0621c26":"df.head()","165017a1":"df.reset_index(inplace=True)\ndf.head()","57b3c5e8":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(df)):\n    review = re.sub('[^a-zA-Z]', ' ', df['title'][i])\n    review = review.lower()\n    review = review.split()    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\ncorpus[:5]","ab65a12b":"# ## Get the Independent Features\n## Applying Countvectorizer\n# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=4094,ngram_range=(1,3))\nX = cv.fit_transform(corpus).toarray()\nX.shape","223eb66b":"## Get the Dependent features\ny=df['label']\ny.head()","e9d01e9c":"## Divide the dataset into Train and Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","09403559":"cv.get_feature_names()[:5]","fc2e1c1a":"cv.get_params()","24484444":"count_df = pd.DataFrame(X_train, columns=cv.get_feature_names())\ncount_df.head()","f58aea7f":"from sklearn.naive_bayes import MultinomialNB\nclassifier=MultinomialNB()\nclassifier.fit(X_train, y_train)","7bccf54a":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,classifier.predict(X_test),target_names=['FAKE', 'REAL']))","ba34fd6c":"from sklearn import metrics\nscore = metrics.accuracy_score(y_test, classifier.predict(X_test))\nscore","82d80c8d":"from sklearn.linear_model import PassiveAggressiveClassifier\nlinear_clf = PassiveAggressiveClassifier(max_iter=64)","d4238ab3":"linear_clf.fit(X_train, y_train)\nprint(classification_report(y_test,linear_clf.predict(X_test),target_names=['FAKE', 'REAL']))","dc0bbd15":"score = metrics.accuracy_score(y_test, linear_clf.predict(X_test))\nscore","f5b56416":"classifier=MultinomialNB(alpha=0.1)\nimport numpy as np\nprevious_score=0\nfor alpha in np.arange(0,1,0.05):\n    sub_classifier=MultinomialNB(alpha=alpha)\n    sub_classifier.fit(X_train,y_train)\n    y_pred=sub_classifier.predict(X_test)\n    score = metrics.accuracy_score(y_test, y_pred)\n    if score>previous_score:\n        classifier=sub_classifier\n    print(\"Alpha: {}, Score : {}\".format(alpha,score))","20708b41":"## Get Features names\nfeature_names = cv.get_feature_names()\nfeature_names[:5]","83fd1af4":"classifier.coef_[0]","d1046a36":"### Most real\nsorted(zip(classifier.coef_[0], feature_names), reverse=True)[:5]","5aa3ddb6":"### Most fake\nsorted(zip(classifier.coef_[0], feature_names))[:5]","20ad122e":"# Multinomial Classifier with Hyperparameter","2132ceb6":"# Passive Aggressive Classifier Algorithm","777c8768":"# MultinomialNB Algorithm"}}