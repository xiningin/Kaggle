{"cell_type":{"ed3df27a":"code","f8736a5d":"code","ab48f046":"code","06416adb":"code","a6f5c98a":"code","f658b04f":"code","f0935ea7":"code","bef441ee":"code","2cbb54a3":"code","b1a8cfdd":"code","6d9a4da9":"code","05d4b78b":"code","1b6ea83f":"code","90c184eb":"code","913e8647":"code","a85c8ad5":"code","ac742616":"code","2dac0c69":"code","51272fc6":"code","8310dc0c":"code","e420601f":"code","642719c5":"code","97d10342":"code","acedd0c3":"markdown","50a758b8":"markdown","1d972128":"markdown","062a2888":"markdown","bd2269da":"markdown","6c5c9420":"markdown","6f01d7e2":"markdown","43e69270":"markdown","96d9cf61":"markdown","39bf1de1":"markdown","2b3960b0":"markdown","91be796a":"markdown","93d451b4":"markdown","09757206":"markdown","1beada2d":"markdown","3cf2f0bc":"markdown","63cbe005":"markdown"},"source":{"ed3df27a":"SEED  = 2021\nFOLDS = 20\nDIM   = 380","f8736a5d":"import numpy as np \nimport pandas as pd \nimport os, shutil\nfrom glob import glob\nfrom sklearn.cluster import KMeans\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder","ab48f046":"train_label_df = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntest_label_df  = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')","06416adb":"train_paths = glob('..\/input\/seti-breakthrough-listen\/train\/**\/*.npy')\ntest_paths = glob('..\/input\/seti-breakthrough-listen\/test\/**\/*.npy')\nlen(train_paths), len(test_paths)","a6f5c98a":"train_df = pd.DataFrame({'filepath':train_paths})\ntrain_df['id'] = train_df.filepath.map(lambda x: x.split('\/')[-1].split('.')[0])\ntrain_df['group'] = train_df.filepath.map(lambda x: x.split('\/')[-2])\ntrain_df = pd.merge(train_df, train_label_df, on='id', how='left')\ntrain_df['group_target'] = train_df.group+train_df.target.astype(str)\ntrain_df.head()","f658b04f":"test_df = pd.DataFrame({'filepath':test_paths})\ntest_df['id'] = test_df.filepath.map(lambda x: x.split('\/')[-1].split('.')[0])\ntest_df['group'] = test_df.filepath.map(lambda x: x.split('\/')[-2])\ntest_df.head()","f0935ea7":"train_df.target.value_counts()","bef441ee":"train_df.group.value_counts()","2cbb54a3":"train_df.groupby(['group','target'])['id'].count()","b1a8cfdd":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['group_target'])):\n    train_df.loc[val_idx,'fold'] = fold\n# train_df.groupby(['fold', 'target'])['id'].count()","6d9a4da9":"import matplotlib.pyplot as plt, cv2\n\ndef load_signal(filepath, dim=DIM):\n    sgnl = np.load(filepath)\n    sgnl = sgnl[::2,] # we're taking only 1, 3, 5\n    img  = np.moveaxis(sgnl, 0, -1)\n    img  = img.astype(np.float32)\n    if dim is not None:\n        img = cv2.resize(img, dsize=(dim, dim), interpolation=cv2.INTER_NEAREST)\n    return img\n\ndef visualize(sgnl):\n    sgnl = sgnl.astype(float)\n    plt.figure(figsize=(20, 10))\n    for idx in range(3):\n        plt.subplot(2, 6, idx+1)\n        plt.imshow(sgnl[...,idx])\n        plt.axis('OFF')\n    plt.tight_layout()\n    plt.show()","05d4b78b":"sgnl = load_signal(train_df[train_df.target==1].filepath.iloc[2], dim=None)\nvisualize(sgnl)\nsgnl.shape, sgnl.dtype","1b6ea83f":"sgnl = load_signal(train_df[train_df.target==1].filepath.iloc[2], dim=DIM)\nvisualize(sgnl)\nsgnl.shape, sgnl.dtype","90c184eb":"import tensorflow as tf\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","913e8647":"def train_serialize_example(feature0, feature1, feature2, feature3):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n      'group'         : _bytes_feature(feature2),    \n      'target'        : _int64_feature(feature3),\n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","a85c8ad5":"show=True\nfolds = train_df.fold.unique().tolist()\nfor fold in tqdm(folds): # create tfrecord for each fold\n    fold_df = train_df[train_df.fold==fold]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n#         samples = 200\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it: # images in fold\n            row = fold_df.iloc[k,:]\n            image      = load_signal(row['filepath'], dim=DIM)\n            image      = image[...,::-1] # rgb -> bgr, we'll get the rgb form after decoding the tfrec\n            image_id   = row['id']\n            group      = row['group']\n            target     = np.array(row['target'], dtype=np.uint8)\n            example  = train_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id),\n                str.encode(group),\n                target,\n                )\n            writer.write(example)\n        if show:\n            filepath = 'train%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('\/')[-1]\n            filesize = os.path.getsize(filepath)\/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","ac742616":"def test_serialize_example(feature0, feature1, feature2):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n      'group'         : _bytes_feature(feature2),    \n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","2dac0c69":"show  = True\nfolds = 10\nl     = int(np.ceil(test_df.shape[0]\/folds))\nfor fold in tqdm(range(folds)): # create tfrecord for each fold\n    fold_df = test_df.iloc[l*fold:l*(fold+1)]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('test%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n#         samples = 200\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it: # images in fold\n            row = fold_df.iloc[k,:]\n            image      = load_signal(row['filepath'], dim=DIM)\n            image      = image[...,::-1] # rgb -> bgr, we'll get the rgb form after decoding the tfrec\n            image_id   = row['id']\n            group      = row['group']\n            example  = test_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id),\n                str.encode(group),\n                )\n            writer.write(example)\n        if show:\n            filepath = 'test%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('\/')[-1]\n            filesize = os.path.getsize(filepath)\/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","51272fc6":"import re, math\ndef decode_image(image_data):\n    image = tf.image.decode_png(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\ndef prepare_target(target):    \n    target = tf.cast(target, tf.float32)            \n    target = tf.reshape(target, [1])         \n    return target\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    image  = tf.reshape(image, [DIM, DIM, 3])\n    target = prepare_target(example['target'])\n    return image, target # returns a dataset of (image, label) pairs\n\ndef load_dataset(fileids, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(fileids, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(20, seed=SEED)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef count_data_items(fileids):\n    # the number of data items is written in the id of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1)) for fileid in fileids]\n    return np.sum(n)","8310dc0c":"def display_batch(batch, size=2):\n    imgs, tars = batch\n    for img_idx in range(size):\n        plt.figure(figsize=(4*2, 12*2))\n        for idx in range(3):\n            plt.subplot(size, 3, idx+1)\n            plt.title(f'Target:{tars[img_idx].numpy()[0]}')\n            plt.imshow(imgs[img_idx,:, :, idx])\n            plt.text(5, 10, str(idx), bbox={'facecolor': 'white'})\n            plt.xticks([])\n            plt.yticks([])\n        plt.tight_layout()\n        plt.show() ","e420601f":"# INITIALIZE VARIABLES\nIMAGE_SIZE= [DIM,DIM];\nBATCH_SIZE = 32\nAUTO = tf.data.experimental.AUTOTUNE\nTRAINING_FILENAMES = tf.io.gfile.glob('train*.tfrec')\nTEST_FILENAMES     = tf.io.gfile.glob('test*.tfrec')\nprint('There are %i train & %i test images'%(count_data_items(TRAINING_FILENAMES), count_data_items(TEST_FILENAMES)))","642719c5":"# DISPLAY TRAIN IMAGES\ntraining_dataset = get_training_dataset()\ntraining_dataset = training_dataset.unbatch().batch(20)\ntrain_batch = next(iter(training_dataset))\ndisplay_batch(train_batch, 2);","97d10342":"img, label = train_batch\nnp.unique(label.numpy(), return_counts=True)","acedd0c3":"# Writing TFRecord (Test)","50a758b8":"# Visualize Channels","1d972128":"# Resize","062a2888":"# Check the signals\nFrom the [dataset information](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/overview\/data-information),\n>>\nNot all of the \u201cneedle\u201d signals look like diagonal lines, and they may not be present for the entirety of all three \u201cA\u201d observations, but what they do have in common is that they are only present in some or all of the \u201cA\u201d observations (panels **1**, **3**, and **5** in the cadence snippets).\n\n","bd2269da":"# Check The Data","6c5c9420":"# Writng TFRecord (Train)","6f01d7e2":"# TFRecord Data","43e69270":"# How to Create TFRecord","96d9cf61":"## No Resize","39bf1de1":"# Reading TFRecord","2b3960b0":"# Reference\nCheck this amazing notebook, [How To Create TFRecords](https:\/\/www.kaggle.com\/cdeotte\/how-to-create-tfrecords) by [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte)","91be796a":"# [SETI Breakthrough Listen - E.T. Signal Search](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen)\n>Find extraterrestrial signals in data from deep space \n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/23652\/logos\/header.png?t=2021-02-24-19-15-30)","93d451b4":"# Total Images","09757206":"# Stratified KFold by Groups","1beada2d":"# Visual","3cf2f0bc":"# Importing Packages","63cbe005":"# Once Batch Image"}}