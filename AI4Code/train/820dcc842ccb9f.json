{"cell_type":{"a662de60":"code","0a3e4e96":"code","70cdff04":"code","16b7fdcb":"code","34218454":"code","e1811031":"code","742431fe":"code","af661698":"code","33a6b3da":"code","dcd07640":"code","56438866":"code","296e7f0d":"code","36fb17f6":"code","45c096f7":"code","296bafcd":"code","4796571d":"code","f115888a":"code","847016ba":"markdown","ab66c9b5":"markdown","c8dca785":"markdown","a422125c":"markdown"},"source":{"a662de60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.options.mode.chained_assignment = None\nfrom datetime import datetime, timedelta\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a3e4e96":"df = pd.read_csv('\/kaggle\/input\/order-brushing-shopee-code-league\/order_brush_order.csv')","70cdff04":"df.describe(include='all')","16b7fdcb":"df.shopid.nunique()","34218454":"#Ok. Lets try to split the date\/time column into individual feature\ndf.dtypes","e1811031":"df['event_time'] = pd.to_datetime(df['event_time'], format=\"%Y\/%m\/%d %H:%M:%S\") #2019-12-27 00:23:03","742431fe":"df.dtypes","af661698":"df.head()","33a6b3da":"#Lets try to group order ID based on hour\ndf['hour'] = df['event_time'].dt.hour\ndf['year'] = df['event_time'].dt.year\ndf['month'] = df['event_time'].dt.month\ndf['day'] = df['event_time'].dt.day\ndf.head()","dcd07640":"dfObj = pd.DataFrame(columns=['shopid','event_time', 'concentrate_rate', 'userid','no_of_users','no_of_orders'])\nfor shopid in df.shopid.unique():\n    #now we need to find out orders that are taken place in one hr. START = First Order, END = \n    #Lets create a new Data frame for each of the Shop ID\n    df_shopid = df[df['shopid']==(shopid)]\n    df_shopid['event_time'] = pd.DatetimeIndex(df_shopid['event_time'])\n    #Lets Sort it\n    df_shopid = df_shopid.sort_values('event_time')\n    #print(df_shopid.head(20))\n    #print(df_shopid.count())\n    df_shopid.index=pd.to_datetime(df_shopid.event_time)    \n    for index, row in df_shopid.iterrows():\n        user_list = []\n        start = row['event_time']\n        end = start + timedelta(hours=1)\n        mask = (df_shopid['event_time'] > start) & (df_shopid['event_time'] <= end)\n        df_inbetween = df_shopid.loc[mask]\n        #Now Lets try to calculate \"Concentrate rate\" which is \n        # (Orders ......) \/ ( User .......)\n        concentrate_rate = (df_inbetween['orderid'].nunique() \/ df_inbetween['userid'].nunique()) if df_inbetween['userid'].nunique() != 0 else 0\n        #concentrate_rate = df_inbetween['orderid'].nunique() \/ df_inbetween['userid'].nunique()\n        t_userid = sorted(df_inbetween['userid'].unique())\n        #print('concentrate_rate - >',concentrate_rate)\n        #print('user id', t_userid)\n        #Lets add the data to dataframe\n        if concentrate_rate > 0 :\n            dfObj = dfObj.append({'shopid' : shopid , 'event_time' : start,\n                                  'concentrate_rate' : concentrate_rate,\n                                  'userid': '&'.join(map(str, t_userid)),\n                                 'no_of_users' : df_inbetween['userid'].nunique(),\n                                 'no_of_orders' : df_inbetween['orderid'].nunique()} , ignore_index=True)\n        else:\n            dfObj = dfObj.append({'shopid' : shopid , 'event_time' : start,\n                                  'concentrate_rate' : 0, 'userid': 0,\n                                 'no_of_users' : df_inbetween['userid'].nunique(),\n                                 'no_of_orders' : df_inbetween['orderid'].nunique()} , ignore_index=True)\n    #print(dfObj.head(20))\n    #break","56438866":"#Lets Sort the dataframe by shopid and concentrate_rate\ndf_sorted = dfObj.sort_values(by=['shopid','concentrate_rate'])","296e7f0d":"#Check the datatypes one more time\ndf_sorted.dtypes","36fb17f6":"#Simple Group by to get the max of concentrate_rate\nu = df_sorted.groupby('shopid')['concentrate_rate'].idxmax()\ndf_final = df_sorted.loc[u, ['shopid', 'userid']].reset_index(drop=1)","45c096f7":"#Prepeare for submission\ndf_submission = pd.DataFrame(df_final)","296bafcd":"df_submission.head()","4796571d":"#Lets write the file\ndf_submission.to_csv('submission.csv', index=False)","f115888a":"#Validate if the total records is 18770 (No. of unique shops)\ndf_submission.shape","847016ba":"## This code is not fully optimized.","ab66c9b5":"# Simple Try with Python","c8dca785":"# Real code here. \n## Below is the list of steps done for this\n1) Create new dataframe for each of Shop ID and calculate concentrate_rate <br>\n2) append other columns. Final Columns would be ['shopid','event_time', 'concentrate_rate', 'userid','no_of_users','no_of_orders']","a422125c":"### We are not using below event time seperation. Just for explorartion only"}}