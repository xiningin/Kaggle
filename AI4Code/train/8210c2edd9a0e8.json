{"cell_type":{"224f9127":"code","dabcf926":"code","b5bb3f61":"code","c65b3f48":"code","a8ee5032":"code","541f3f17":"code","46af4a22":"code","c803e001":"code","992ec98d":"code","f62bd7ff":"code","0b46ab19":"code","5df7ff98":"code","2e994878":"code","b62d8bd0":"code","1b79e2ae":"code","f0ba3fbd":"code","90fb5a3c":"code","093df197":"code","e02a36d4":"code","54fcfe0b":"code","6268a519":"code","62c35acb":"code","6bb4661e":"code","c9144163":"code","56633cc5":"code","46021555":"code","821ca5bf":"code","e63e7ee6":"code","a75555b1":"code","40525ecc":"code","dfe1bb8c":"code","3acd49aa":"code","843e7699":"code","8f052f8d":"code","941276c8":"code","b6d2408d":"code","ee9a3450":"code","80cb4856":"code","2a3dc473":"code","a012fe74":"code","78be42c7":"code","1341cf6a":"code","40a0fcf4":"code","7fa46446":"code","41874598":"code","4e0eac7a":"code","ecccd6c5":"code","ffc3c43e":"code","c752ac99":"code","be420f7b":"code","ad8dd488":"code","6c3a39d7":"code","2351b8d8":"code","92e3a52c":"code","4c7cb76c":"code","6b52ce5f":"code","12cf6cd8":"code","725f5c81":"code","223a8070":"code","93485d53":"code","718572ff":"code","e493d397":"code","508fe759":"code","cf98cb51":"code","6b6a490e":"code","d71eed6a":"code","698fc905":"code","aa788b67":"code","8e2f49ac":"code","dd0d1746":"code","bb45f397":"code","99d9b1e1":"code","9b7975ba":"code","e1fa492e":"code","3508e007":"code","d72aa287":"code","870281ad":"code","a4ab1a16":"code","75b4d7b7":"code","a7d27610":"code","dfdf1bea":"markdown","2f0f5e90":"markdown","487d1b17":"markdown","18525d02":"markdown","214c96ee":"markdown","42a75da7":"markdown","c3bbbdc3":"markdown","9f5452e2":"markdown","3f245eaf":"markdown","c04daeaa":"markdown","1abd0835":"markdown","f0796a5a":"markdown","996bd63e":"markdown","5b548d23":"markdown","1ee64b8e":"markdown","69e6e1ef":"markdown","5df8770c":"markdown","5b6088da":"markdown","2bf490de":"markdown","e150ae61":"markdown","aa1c8150":"markdown","1c5ad193":"markdown","029a8cc1":"markdown","25935d92":"markdown","8a8408b3":"markdown","1f36fad3":"markdown","6b1b8dee":"markdown","744d263e":"markdown","5ac692e3":"markdown","0c277a4b":"markdown","464a0c19":"markdown","466000c5":"markdown","28d2350e":"markdown","ad39c88c":"markdown","f76160d9":"markdown","e3fa6e08":"markdown","695d4a53":"markdown","04e2fdc6":"markdown","957e950a":"markdown","f929ad8e":"markdown","2e1b2544":"markdown","8bd931ba":"markdown","ee8dab19":"markdown","89840d6a":"markdown","4da9f234":"markdown","99946553":"markdown","059461d2":"markdown","474066fe":"markdown","ff6adbb6":"markdown","1adcaca2":"markdown","ee7d5c79":"markdown","2a167de9":"markdown","ebfe77b0":"markdown","5c6adba7":"markdown","eac6048c":"markdown","9c233e80":"markdown","a4b82c28":"markdown","5481a873":"markdown","489f6e9d":"markdown"},"source":{"224f9127":"%matplotlib inline\nRANDOM_STATE = 0\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\npd.set_option('display.float_format', '{:.3f}'.format)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, ParameterGrid, StratifiedKFold\nfrom sklearn import metrics\nfrom tqdm import tqdm\n\nimport eli5 \nfrom eli5.sklearn import PermutationImportance\n\nimport itertools\n\nimport catboost as cb\nfrom catboost import CatBoostClassifier\nfrom catboost import Pool","dabcf926":"def summary(df):\n    summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    return summary","b5bb3f61":"def remove_whitespace(x):\n    '''remove spaces inside and outside of string\n        df.orderId = df.orderId.apply(remove_whitespace)\n        df = df.applymap(remove_whitespace)\n    '''\n    try:\n        x = \"\".join(x.split())\n\n    except:\n        pass\n    return x","c65b3f48":"def plot_cf_matrix_and_roc(model, \n                           X_train, \n                           y_train,\n                           X_test, \n                           y_test,\n                           y_pred, \n                           classes=[0,1],\n                           normalize=False,\n                           cmap=plt.cm.Blues):\n    metrics_list = []\n    \n    # the main plot\n    plt.figure(figsize=(15,5))\n\n    # the confusion matrix\n    plt.subplot(1,2,1)\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    \n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        plt.title(\"Normalized confusion matrix\")\n    else:\n        plt.title('Confusion matrix')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    # the result metrix\n    summary_df = pd.DataFrame([[str(np.unique( y_pred )),\n                               str(round(metrics.precision_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.accuracy_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.recall_score(y_test, y_pred.round(), average='binary'),3)),\n                               str(round(metrics.roc_auc_score(y_test, y_pred.round()),3)),\n                                str(round(metrics.cohen_kappa_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.f1_score(y_test, y_pred.round(), average='binary'),3))]], \n                              columns=['Class', 'Precision', 'Accuracy', 'Recall', 'ROC-AUC', 'Kappa', 'F1-score'])\n    # print the metrics\n    print(\"\\n\");\n    print(summary_df);\n    print(\"\\n\");\n    \n    plt.show()","a8ee5032":"def cross_val(X, y, param, cat_features='', class_weights = '', n_splits=3):\n    results = []\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n    \n    for tr_ind, val_ind in skf.split(X, y):\n        X_train_i = X.iloc[tr_ind]\n        y_train_i = y.iloc[tr_ind]\n        \n        X_valid_i = X.iloc[val_ind]\n        y_valid_i = y.iloc[val_ind]\n        \n        if class_weights == '' :\n            clf = CatBoostClassifier(iterations=param['iterations'],\n                            loss_function = param['loss_function'],\n                            depth=param['depth'],\n                            l2_leaf_reg = param['l2_leaf_reg'],\n                            eval_metric = param['eval_metric'],\n                            leaf_estimation_iterations = 10,\n                            use_best_model=True,\n                            logging_level='Silent',\n                            od_type=\"Iter\",\n                            early_stopping_rounds=param['early_stopping_rounds']\n            )\n        else:\n            clf = CatBoostClassifier(iterations=param['iterations'],\n                            loss_function = param['loss_function'],\n                            depth=param['depth'],\n                            l2_leaf_reg = param['l2_leaf_reg'],\n                            class_weights = class_weights,\n                            eval_metric = param['eval_metric'],\n                            leaf_estimation_iterations = 10,\n                            use_best_model=True,\n                            logging_level='Silent',\n                            od_type=\"Iter\",\n                            early_stopping_rounds=param['early_stopping_rounds']\n            )\n        \n        \n        if cat_features == '' :\n            clf.fit(X_train_i, \n                    y_train_i,\n                    eval_set=(X_valid_i, y_valid_i)\n            )\n        else:\n            clf.fit(X_train_i, \n                    y_train_i,\n                    cat_features=cat_features,\n                    eval_set=(X_valid_i, y_valid_i)\n            )\n        \n        # predict\n        y_pred = clf.predict(X_valid_i)\n        \n        # select the right metric\n        if(param['eval_metric'] == 'Recall'):\n            metric = metrics.recall_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'Accuracy'):\n            metric = metrics.accuracy_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'F1'):\n            metric = metrics.f1_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'AUC'):\n            metric = metrics.roc_auc_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'Kappa'):\n            metric = metrics.cohen_kappa_score(y_valid_i, y_pred)\n        else:\n            metric = metrics.accuracy_score(y_valid_i, y_pred)\n        \n        #append the metric\n        results.append(metric)\n        \n        print('Classes: '+str(np.unique( y_pred )))\n        print('Precision: '+str(round(metrics.precision_score(y_valid_i, y_pred.round()),3)))\n        print('Accuracy: '+str(round(metrics.accuracy_score(y_valid_i, y_pred.round()),3)))\n        print('Recall: '+str(round(metrics.recall_score(y_valid_i, y_pred.round(), average='binary'),3)))\n        print('Roc_Auc: '+str(round(metrics.roc_auc_score(y_valid_i, y_pred.round()),3)))\n        print('F1 score: '+str(round(metrics.f1_score(y_valid_i, y_pred.round(), average='binary'),3)))\n        print('Mean and standard deviation for '+param['eval_metric']+' oof prediction: ',np.mean(results),np.std(results))\n        print(\"\\n\")\n    return sum(results)\/n_splits","541f3f17":"def catboost_GridSearchCV(X, y, params, cat_features='', class_weights='', n_splits=5):\n    ps = {'score':0,'param': []}\n    for prms in tqdm(list(ParameterGrid(params)), ascii=True, desc='Params Tuning:'):\n        score = cross_val(X, y, prms, cat_features, class_weights, n_splits)\n        if score > ps['score']:\n            ps['score'] = score\n            ps['param'] = prms\n    print('Score: '+str(ps['score']))\n    print('Params: '+str(ps['param']))\n    return ps['param']","46af4a22":"def check_target(df, target):\n    sns.countplot(df[target])\n    count_no = len(df[df[target]==0])\n    count_yes = len(df[df[target]==1])\n    pct_of_no_sub = count_no\/(count_no+count_yes)*100\n    pct_of_sub = count_yes\/(count_no + count_yes)*100\n    print('{} {} % >50K '.format(count_yes, pct_of_sub))\n    print('{} {} % <=50K '.format(count_no, pct_of_no_sub))","c803e001":"## Import the data file\ndata = pd.read_csv('..\/input\/adult-census-income\/adult.csv')","992ec98d":"data.head()","f62bd7ff":"summary(data)","0b46ab19":"# Some of the column names have whitespaces, thats why we need to strip them\ndata.rename(columns=lambda x: x.strip(), inplace=True)\ndata = data.applymap(remove_whitespace)","5df7ff98":"pd.crosstab(data.age,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Age \/ Income')\nplt.xlabel('Age')\nplt.ylabel('Age \/ Income')","2e994878":"bins = [0, 25, 45, 65, 100]\nnames = ['Young', 'Middle', 'Senior', 'Old']\ndata['ageRange'] = pd.cut(data['age'], bins, labels=names)","b62d8bd0":"pd.crosstab(data.ageRange,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Age range \/ Income')\nplt.xlabel('Age range')\nplt.ylabel('Age range \/ Income')","1b79e2ae":"data.groupby('ageRange').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","f0ba3fbd":"pd.crosstab(data.workclass,data.income).plot(kind='bar', figsize=(20,10), stacked=True)\nplt.title('Workclass \/ Income')\nplt.xlabel('Workclass')\nplt.ylabel('Workclass \/ Income')","90fb5a3c":"data.groupby('workclass').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","093df197":"data['workclass'].replace('?', 'Unknown', inplace=True)\ndata['isSelfEmployed'] = np.where(((data['workclass']=='Self-emp-inc') | (data['workclass']=='Self-emp-not-inc')), 1, 0)\ndata['worksForGov'] = np.where(((data['workclass']=='Federal-gov') | (data['workclass']=='Local-gov')| (data['workclass']=='State-gov')), 1, 0)\ndata['dontEarnMoney'] = np.where(((data['workclass']=='Without-pay') | (data['workclass']=='Never-worked')), 1, 0)","e02a36d4":"data = data.drop(columns=['fnlwgt'])","54fcfe0b":"pd.crosstab(data.education,data.income).plot(kind='bar', figsize=(20,10), stacked=True)\nplt.title('Education \/ Income')\nplt.xlabel('Education')\nplt.ylabel('Education \/ Income')","6268a519":"data.groupby('education').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","62c35acb":"pd.crosstab(data.age,data.education).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Education \/ Income')\nplt.xlabel('Education')\nplt.ylabel('Education \/ Income')","6bb4661e":"# New feature\ndata['hasHSGrad'] = np.where(((data['education']=='10th') \n                              | (data['education']=='11th') \n                              | (data['education']=='12th')\n                              | (data['education']=='1st-4th')\n                              | (data['education']=='5th-6th')\n                              | (data['education']=='7th-8th')\n                              | (data['education']=='9th')\n                              | (data['education']=='Preschool')), 0, 1)","c9144163":"pd.crosstab(data.hasHSGrad,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Has highscool graduation \/ Income')\nplt.xlabel('Has highscool graduation')\nplt.ylabel('Has highscool graduation \/ Income')","56633cc5":"data.groupby('hasHSGrad').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","46021555":"# combine some values in other\ndata['educationNew'] = data['education']\ndata.loc[data.educationNew == 'Preschool', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == '1st-4th', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == '5th-6th', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == '7th-8th', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == '9th', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == '10th', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == '11th', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == '12th', 'educationNew'] = 'Dropout'\ndata.loc[data.educationNew == 'Assoc-acdm', 'educationNew'] = 'Associates'\ndata.loc[data.educationNew == 'Assoc-voc', 'educationNew'] = 'Associates'\ndata.loc[data.educationNew == 'Some-college', 'educationNew'] = 'Colleges'","821ca5bf":"pd.crosstab(data.educationNew,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Education \/ Income')\nplt.xlabel('Education')\nplt.ylabel('Education \/ Income')","e63e7ee6":"data.groupby('educationNew').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","a75555b1":"#data = data.drop(columns=['education-num'])","40525ecc":"data['marital.status'].unique()","dfe1bb8c":"pd.crosstab(data['marital.status'],data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Marital status \/ Income')\nplt.xlabel('Marital status')\nplt.ylabel('Marital status \/ Income')","3acd49aa":"# combine some values in other\ndata['isMarried'] = data['marital.status']\ndata.loc[data.isMarried == 'Never-married', 'isMarried'] = 'Not-Married'\ndata.loc[data.isMarried == 'Divorced', 'isMarried'] = 'Not-Married'\ndata.loc[data.isMarried == 'Married-spouse-absent', 'isMarried'] = 'Not-Married'\ndata.loc[data.isMarried == 'Separated', 'isMarried'] = 'Not-Married'\ndata.loc[data.isMarried == 'Widowed', 'isMarried'] = 'Not-Married'\ndata.loc[data.isMarried == 'Married-civ-spouse', 'isMarried'] = 'Married'\ndata.loc[data.isMarried == 'Married-AF-spouse', 'isMarried'] = 'Married'","843e7699":"pd.crosstab(data['isMarried'],data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Is married \/ Income')\nplt.xlabel('Is married')\nplt.ylabel('Is married \/ Income')","8f052f8d":"data['occupation'].unique()","941276c8":"pd.crosstab(data.occupation,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Occupation \/ Income')\nplt.xlabel('Occupation')\nplt.ylabel('Occupation \/ Income')","b6d2408d":"data.groupby('occupation').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","ee9a3450":"data['occupation'].replace('?', 'Unknown', inplace=True)\ndata['occupationNew'] = data['occupation']\ndata.loc[data.occupationNew == 'Adm-clerical', 'occupationNew'] = 'White-Collar'\ndata.loc[data.occupationNew == 'Armed-Forces', 'occupationNew'] = 'Military'\ndata.loc[data.occupationNew == 'Craft-repair', 'occupationNew'] = 'Blue-Collar'\ndata.loc[data.occupationNew == 'Exec-managerial', 'occupationNew'] = 'White-Collar'\ndata.loc[data.occupationNew == 'Farming-fishing', 'occupationNew'] = 'Blue-Collar'\ndata.loc[data.occupationNew == 'Handlers-cleaners', 'occupationNew'] = 'Blue-Collar'\ndata.loc[data.occupationNew == 'Machine-op-inspct', 'occupationNew'] = 'Blue-Collar'\ndata.loc[data.occupationNew == 'Other-service', 'occupationNew'] = 'Service'\ndata.loc[data.occupationNew == 'Priv-house-serv', 'occupationNew'] = 'Service'\ndata.loc[data.occupationNew == 'Prof-specialty', 'occupationNew'] = 'Professional'\ndata.loc[data.occupationNew == 'Protective-serv', 'occupationNew'] = 'Service'\ndata.loc[data.occupationNew == 'Sales', 'occupationNew'] = 'Sales'\ndata.loc[data.occupationNew == 'Tech-support', 'occupationNew'] = 'White-Collar'\ndata.loc[data.occupationNew == 'Transport-moving', 'occupationNew'] = 'Blue-Collar'","80cb4856":"data['occupationNew'].unique()","2a3dc473":"pd.crosstab(data.occupationNew,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Occupation \/ Income')\nplt.xlabel('Occupation')\nplt.ylabel('Occupation \/ Income')","a012fe74":"data.groupby('occupationNew').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","78be42c7":"pd.crosstab(data.occupationNew,data.educationNew).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Occupation \/ Income')\nplt.xlabel('Occupation')\nplt.ylabel('Occupation \/ Income')","1341cf6a":"data['relationship'].unique()","40a0fcf4":"pd.crosstab(data.relationship,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Relationship \/ Income')\nplt.xlabel('Relationship')\nplt.ylabel('Relationship \/ Income')","7fa46446":"pd.crosstab(data.relationship,data.isMarried).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Relationship \/ Income')\nplt.xlabel('Relationship')\nplt.ylabel('Relationship \/ Income')","41874598":"data['race'].unique()","4e0eac7a":"pd.crosstab(data.race,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Race \/ Income')\nplt.xlabel('Race')\nplt.ylabel('Race \/ Income')","ecccd6c5":"data.groupby('race').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","ffc3c43e":"data['sex'].unique()","c752ac99":"pd.crosstab(data.sex,data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Sex \/ Income')\nplt.xlabel('Sex')\nplt.ylabel('Sex \/ Income')","be420f7b":"data.groupby('sex').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","ad8dd488":"pd.crosstab(data['capital.gain'],data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Capital gain \/ Income')\nplt.xlabel('Capital gain')\nplt.ylabel('Capital gain \/ Income')","6c3a39d7":"pd.crosstab(data['capital.loss'],data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Capital loss \/ Income')\nplt.xlabel('Capital loss')\nplt.ylabel('Capital loss \/ Income')","2351b8d8":"pd.crosstab(data['hours.per.week'],data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Hours per week \/ Income')\nplt.xlabel('Hours per week')\nplt.ylabel('Hours per week \/ Income')","92e3a52c":"pd.crosstab(data['native.country'],data.income).plot(kind='bar', figsize=(20,5), stacked=True)\nplt.title('Native country \/ Income')\nplt.xlabel('Native country')\nplt.ylabel('Native country \/ Income')","4c7cb76c":"summary(data)","6b52ce5f":"data['income'] = data['income'].replace(['<=50K', '>50K'], [0, 1])","12cf6cd8":"data['age_isMarried']=data['age'].astype('str')+'|'+data['isMarried'].astype('str')\ndata['age_education']=data['age'].astype('str')+'|'+data['education'].astype('str')\ndata['age_marital-status']=data['age'].astype('str')+'|'+data['marital.status'].astype('str')\ndata['sex_relationship']=data['sex'].astype('str')+'|'+data['relationship'].astype('str')\ndata['sex_workclass']=data['sex'].astype('str')+'|'+data['workclass'].astype('str')\ndata['age_occupationNew']=data['age'].astype('str')+'|'+data['occupationNew'].astype('str')","725f5c81":"data = data.drop(columns=[\n    'hasHSGrad', \n    'isSelfEmployed', \n    'worksForGov', \n    'dontEarnMoney', \n    'race', \n    'native.country',\n    'sex'\n ])","223a8070":"data.head()","93485d53":"X = data.drop('income', 1)\ny = data['income']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=47)\nX_train.shape, X_test.shape","718572ff":"X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.20, random_state=47)\nX_test.shape, X_validation.shape","e493d397":"train_df = pd.concat([X_train, y_train], axis=1)\ncheck_target(train_df, 'income')","508fe759":"test_df = pd.concat([X_test, y_test], axis=1)\ncheck_target(test_df, 'income')","cf98cb51":"validation_df = pd.concat([X_validation, y_validation], axis=1)\ncheck_target(validation_df, 'income')","6b6a490e":"cat_features=[i for i in X_train.columns if ((X_train.dtypes[i]!='int64'))]\ncat_features","d71eed6a":"bool_features=[i for i in X_train.columns if ((X_train.dtypes[i]=='int64') & (len(X_train[i].unique()) == 2))]\nbool_features","698fc905":"num_features=[i for i in X_train.columns if ((X_train.dtypes[i]=='int64') & (len(X_train[i].unique()) > 2))]\nnum_features","aa788b67":"from sklearn.utils import class_weight\ncw = list(class_weight.compute_class_weight('balanced',\n                                             np.unique(data['income']),\n                                             data['income']))","8e2f49ac":"params = {'depth':[2, 3, 4],\n          'iterations':[3000],\n          'loss_function': ['Logloss'],\n          'l2_leaf_reg':np.logspace(-19,-20,3),\n          'early_stopping_rounds': [700],\n          'learning_rate':[0.01],\n          'eval_metric':['F1']\n}\n\n# parameter tuning\n#param = catboost_GridSearchCV(X_train, y_train, params, cat_features, cw)","dd0d1746":"# pre-optimized parameters\nparam = {\n    'depth': 3, \n    'eval_metric': 'F1', \n    'iterations': 3000, \n    'l2_leaf_reg': 1e-19, \n    'loss_function': 'Logloss',\n    'early_stopping_rounds': 700\n}\n\n# create the model\nclf2 = CatBoostClassifier(iterations=param['iterations'],\n                        loss_function = param['loss_function'],\n                        depth=param['depth'],\n                        l2_leaf_reg = param['l2_leaf_reg'],\n                        eval_metric = param['eval_metric'],\n                        leaf_estimation_iterations = 10,\n                        use_best_model=True,\n                        early_stopping_rounds=param['early_stopping_rounds'],\n                        class_weights = cw\n)\n\n# train the model\nclf2.fit(X_train, \n        y_train,\n        cat_features=cat_features,\n        logging_level='Silent',\n        eval_set=(X_test, y_test)\n)","bb45f397":"feature_score = pd.DataFrame(list(zip(X_train.dtypes.index, clf2.get_feature_importance(Pool(X_train, label=train_df['income'], cat_features=cat_features)))),\n                columns=['Feature','Score'])\n\nfeature_score = feature_score.sort_values(by='Score', ascending=False, inplace=False, kind='quicksort', na_position='last')\nplt.rcParams[\"figure.figsize\"] = (15,8)\nax = feature_score.plot('Feature', 'Score', kind='bar', color='c')\nax.set_title(\"Catboost Feature Importance Ranking\", fontsize = 14)\nax.set_xlabel('')\n\nrects = ax.patches\n\nlabels = feature_score['Score'].round(2)\n\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()\/2, height + 0.35, label, ha='left', va='bottom')\nplt.xticks(rotation=85)\n\nplt.gca().invert_xaxis()\n\nplt.show()\nprint(feature_score)\n","99d9b1e1":"pred_catboost2_train = clf2.predict(X_train)","9b7975ba":"plot_cf_matrix_and_roc(clf2, X_train, y_train, X_train, y_train, pred_catboost2_train , classes=['<=50k','>50k'])","e1fa492e":"print(metrics.classification_report(y_train, pred_catboost2_train))","3508e007":"pred_catboost2_train = clf2.predict(X_test)","d72aa287":"plot_cf_matrix_and_roc(clf2, X_train, y_train, X_test, y_test, pred_catboost2_train , classes=['<=50k','>50k'])","870281ad":"print(metrics.classification_report(y_test, pred_catboost2_train))","a4ab1a16":"pred_catboost2_train = clf2.predict(X_validation)","75b4d7b7":"plot_cf_matrix_and_roc(clf2, X_train, y_train, X_validation, y_validation, pred_catboost2_train , classes=['<=50k','>50k'])","a7d27610":"print(metrics.classification_report(y_validation, pred_catboost2_train))","dfdf1bea":"## workclass","2f0f5e90":"## age","487d1b17":"The distribution of the income is alsmost the same for each data frame.","18525d02":"Let's check the relation between relationship and the new feature maritalStatusNew.","214c96ee":"# Feature engineering","42a75da7":"### Todo\n* replace all values \"?\" with \"Unknown\"\n* Create new feature: isSelfEmployed\n* Create new feature: worksForGov\n* Create new feature: dontEarnMoney","c3bbbdc3":"## fnlwgt","9f5452e2":"## Check the validation data","3f245eaf":"#### Drop unused features","c04daeaa":"## hours-per-week","1abd0835":"**Interpretation**\n* Most of the people are working 40 hours per week\n* In percentage terms, people who work more than 40 hours a week earn more","f0796a5a":"## Catboost Classifier with Feature Importance\n\n### The problem statement \n\nIn this kernel, I try to predict whether a person makes over 50K a year. I use Catboost Classifier with Python and Scikit-Learn.\n\nCatBoost is an algorithm for gradient boosting on decision trees. It is developed by Yandex researchers and engineers, and is used for search, recommendation systems, personal assistant, self-driving cars, weather prediction and many other tasks at Yandex and in other companies, including CERN, Cloudflare, Careem taxi. It is in open-source and can be used by anyone.\n\nI hope you find this kernel useful and your UPVOTES would be very much appreciated.","996bd63e":"### Split test and validation","5b548d23":"## marital-status","1ee64b8e":"**Interpretation**\n* Interesting feature. Most of the people in the data set has no capital gain.","69e6e1ef":"## native-country","5df8770c":"As first we need to check which kind of features we have. Let's see the different types of the features: Categorical, Numeric and Boolean (only 2 numeric values 0 or 1)","5b6088da":"## education-num\nThis feature seems not useless at this moment. We drop it.","2bf490de":"# Exploratory Analysis","e150ae61":"### ToDo\n* Add new category \"Unknown\"\n* Lets reorganize a bit the values to become a better view of the occupation","aa1c8150":"#### Create some feature interactions","1c5ad193":"#### Feature importance","029a8cc1":"## relationship","25935d92":"## capital-loss","8a8408b3":"**Interpretation**\n* Older people have the chance to earn more than the younger ones\n* Teens earn less than 50k\n* From an age where you have most likely graduated from college, you can start to earn over 50k","1f36fad3":"## sex","6b1b8dee":"**Interpretation**\n* Civilian spouses are the most and most earn over 50k","744d263e":"### Check the distribution of the income for train, test and validation","5ac692e3":"**Interpretation**\n* More males earn more than 50k","0c277a4b":"**Interpretation**\n* Most of the people in the dataset are \"White\" and over 25% earn over 50k\n* The other races are not so much representative in the dataset. This feature will be not so interesting, because it will bias the model.","464a0c19":"**Interpretation**\n* Most people work in the private sector\n* People who work for themselves in corporate entities has the biggest chances to earn over 50k\n* People who work for the goverment has also big chances to earn over 50k","466000c5":"### Todo\n* Create new feature: hasHSGrad - has high scool graduation\n* Reduce the education categories and combine some of them","28d2350e":"### Todo\n* Lets combine some of the values","ad39c88c":"**Interpretation**\n* People without a high scool graduation can rarely earn over 50k\n* A minimum of bachelor's degree gives you greater chances of earning over 50k\n* Our assumption is correct","f76160d9":"### Lets check how the education is dependent on the age","e3fa6e08":"### Todo\n* Create new feature: ageRange (17-25, 26-45, 46-65, 66-100)","695d4a53":"**Interpretation**\n* Interesting feature. Most of the people in the data set has no capital loss.","04e2fdc6":"## occupation","957e950a":"## education\nThe assumption would be that the higher your education, the greater your chances of making more money. Let's check that out.","f929ad8e":"**Interpretation**\n* In percentage terms, more seniors (46-65 years old) earn over 50k per year\n* Only 2% from the young people (17-25 years old) earn over 50k per year","2e1b2544":"## Check the test data","8bd931ba":"## Check the train data","ee8dab19":"## race","89840d6a":"The features:\n\n* age: the age of an individual\nInteger greater than 0\n* workclass: a general term to represent the employment status of an individual\nPrivate, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n* fnlwgt: this is the number of people the census believes the entry represents.\nInteger greater than 0\n* education: the highest level of education achieved by an individual.\nBachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n* education-num: the highest level of education achieved in numerical form.\nInteger greater than 0\n* marital-status: marital status of an individual. Married-civ-spouse corresponds to a civilian spouse while Married-AF-spouse is a spouse in the Armed Forces.\nMarried-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n* occupation: the general type of occupation of an individual\nTech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n* relationship: represents what this individual is relative to others. For example an individual could be a Husband. Each entry only has one relationship attribute and is somewhat redundant with marital status. We might not make use of this attribute at all\nWife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n* race: Descriptions of an individual\u2019s race\nWhite, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n* sex: the biological sex of the individual\nMale, female\n* capital-gain: capital gains for an individual\nInteger greater than or equal to 0\n* capital-loss: capital loss for an individual\nInteger greater than or equal to 0\n* hours-per-week: the hours an individual has reported to work per week\ncontinuous\n* native-country: country of origin for an individual\nUnited-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n* income: the label whether or not an individual makes more than $50,000 annually.\n<= 50K, >50K","4da9f234":"## Conclusion\n\nThe model appears to be very stable. Train, test, and validation metrics are nearly identical.\n\nFeel free to discuss the kernel and give ideas for optimization.","99946553":"Lets see the summary of the features","059461d2":"On the first view, we don't have any missing values","474066fe":"**Interpretation**\n* As with marital status, we see that married people make more money.","ff6adbb6":"## capital-gain","1adcaca2":"**Interpretation**\n* The picture coincides with the assumption that the better education you have, the better job you can do and earn more money","ee7d5c79":"**Interpretation**\n* The most of the cases in the data set are coming from the USA, which means this feature is not so interesting for prediction","2a167de9":"### Split train and test","ebfe77b0":"**Interpretation**\n* Unmarried people don't seem to earn that well","5c6adba7":"**Interpretation**\n* The data match each other exactly\n* We need to check if these two features are not correlated to each other","eac6048c":"**Interpretation**\n* Fewer people have no high school degrees. Just a small fraction of it will earn over 50k\n* If you have at least a high school degree, you have a 25% chance of earning over 50k","9c233e80":"To be able to make a good prediction we need first to understand the data. Lets go trough each feature, explore it and find the correlation to the income variable \"income\".","a4b82c28":"This is a not known feature. We will drop it and don't analyse it.","5481a873":"* Interesting to see, that the capital-gain is one of the most important features\n* Also capital-loss seems to be a good feature\n* Relationship and marital status seem very important in making good money","489f6e9d":"**Interpretation**\n* A very small percentage of people without education earn over 50k\n* People with a professional school graduation tend to earn more than 50k"}}