{"cell_type":{"c8417cec":"code","7ca80b8c":"code","96d0960c":"code","8b96e3bf":"code","e01cce3d":"code","0770af28":"code","ef7a78c8":"code","a3b27a83":"code","73af4476":"code","039a41fb":"code","42a5cb66":"code","a8cc58c8":"code","4d6be467":"code","6b710f74":"code","c9bdb8bd":"code","414da6c0":"code","0fdc9452":"code","6189dad0":"code","04e381a2":"code","702c3d3c":"code","138c695e":"code","5b8e1321":"code","2702eeb8":"code","ceaf366d":"code","b10c28d3":"code","aa9e11cd":"code","bd266955":"code","8284ae7c":"markdown","e124baef":"markdown","59656efc":"markdown","b7a0d514":"markdown","1eff9538":"markdown","10f491f8":"markdown","50cb7963":"markdown","f906e8f5":"markdown","0151542c":"markdown","aaf521bc":"markdown","d9264fd5":"markdown","448c5e32":"markdown","e28c7e10":"markdown","47b2995f":"markdown","ebc548c4":"markdown","5f6f6ac7":"markdown","9fdaf9b0":"markdown"},"source":{"c8417cec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ca80b8c":"data = pd.read_csv('\/kaggle\/input\/glass\/glass.csv')","96d0960c":"data.head()","8b96e3bf":"data.dtypes","e01cce3d":"# checking the size of our dataset\ndata.shape","0770af28":"# checking missing data. There's no missing values\ndata.isnull().sum().sum()","ef7a78c8":"## Checking each column for outliers\nfig = plt.figure(figsize = (12,10))\n\nax1 = fig.add_subplot(3,3,1)\nax2 = fig.add_subplot(3,3,2)\nax3 = fig.add_subplot(3,3,3)\nax4 = fig.add_subplot(3,3,4)\nax5 = fig.add_subplot(3,3,5)\nax6 = fig.add_subplot(3,3,6)\nax7 = fig.add_subplot(3,3,7)\nax8 = fig.add_subplot(3,3,8)\nax9 = fig.add_subplot(3,3,9)\n\n# Boxplot for RI\nax1.boxplot(data['RI'])\nax1.set_title('Distribution of RI')\n\n# Boxplot for Na\nax2.boxplot(data['Na'])\nax2.set_title('Distribution of Na')\n\n# Boxplot for Mg\nax3.boxplot(data['Mg'])\nax3.set_title('Distribution of Mg')\n\n\n# Boxplot for AL\nax4.boxplot(data['Al'])\nax4.set_title('Distribution of Al')\n\n\n\n# Boxplot for Si\nax5.boxplot(data['Si'])\nax5.set_title('Distribution of Si')\n\n\n# Boxplot for K\nax6.boxplot(data['K'])\nax6.set_title('Distribution of K')\n\n# Boxplot for Ca\nax7.boxplot(data['Ca'])\nax7.set_title('Distribution of Ca')\n\n\n# Boxplot for Ba\nax8.boxplot(data['Ba'])\nax8.set_title('Distribution of Ba')\n\n\n# Boxplot for Fe\nax9.boxplot(data['Fe'])\nax9.set_title('Distribution of Fe');\n","a3b27a83":"sns.distplot(data['Type'], kde = False)","73af4476":"X = data.iloc[:,:-1]\nX","039a41fb":"y = data['Type']\ny","42a5cb66":"from sklearn.model_selection import train_test_split","a8cc58c8":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 50)","4d6be467":"from sklearn import tree","6b710f74":"classifier_tree = tree.DecisionTreeClassifier()","c9bdb8bd":"classifier_tree.fit(X_train, y_train)","414da6c0":"plt.figure(figsize = (20,10))\ntree.plot_tree(classifier_tree);","0fdc9452":"predict_type = classifier_tree.predict(X_test)","6189dad0":"predict_type","04e381a2":"## Let's plot to see how it's performance\nsns.distplot(y_test, kde = False)\nsns.distplot(predict_type, kde = False)","702c3d3c":"from sklearn.metrics import accuracy_score","138c695e":"accuracy_score(y_test,predict_type)","5b8e1321":"from sklearn.neighbors import KNeighborsClassifier","2702eeb8":"classifier_n = KNeighborsClassifier()","ceaf366d":"# important to mention that n_neighbors = 5, is not a multiple value of our quantity of features\nclassifier_n.fit(X_train,y_train)","b10c28d3":"predict_type_n = classifier_n.predict(X_test)","aa9e11cd":"## Let's plot to see how it's performance\nsns.distplot(y_test, kde = False)\nsns.distplot(predict_type_n, kde = False)","bd266955":"accuracy_score(y_test,predict_type_n)","8284ae7c":"## Decision Tree","e124baef":"Not the best visualization for this, but is the one i found it.. If anyone have other suggestion would be great!","59656efc":"## Exploring our Dataset","b7a0d514":"## Predictions with our Decision Tree","1eff9538":"![windscreen.jpg](attachment:windscreen.jpg)","10f491f8":"## Making Predictions with our KNN","50cb7963":"Hello Guys for this Kernel I will try to create my first analysis using Decision Tree and KNN. The dataset that we will be focusing is Glass Types, where we can find some patterns across the types of Glasses based on various characteristics.\n\nPS: First Model created by my own! Still a lot of things to improve.\n\nAny feedback would be great, I really appreciate it","f906e8f5":"Visualizing the frequency from the each type","0151542c":"## Conclusion:\n\nFor this dataset the decision tree did a higher job predicting each type of glass would be based on theses features.\nIsn't the best result on the various kernels around there, but for me as a rookie and apprentice i found it very interesting and pride for the results!\n\nThanks!\n","aaf521bc":"Accuracy of the Tree","d9264fd5":"## Splitting into train and test data","448c5e32":"## Dividing into X e y ","e28c7e10":"Is this data we can see that probably the decision tree has a higher accuracy, but we better check with accuracy_score","47b2995f":"Not exactly what we expected, but for the first try, it is a good result. For me! xD","ebc548c4":"# Visualizing initial data in our dataset","5f6f6ac7":"## Testing with K Neighbors","9fdaf9b0":"Visualizing our Tree"}}