{"cell_type":{"ba1bff10":"code","2e085c91":"code","938b3c3d":"code","2083e528":"code","046abf9e":"code","63968c36":"code","93d6d686":"code","9395f069":"code","0a3661c3":"code","19f00039":"code","bfbdec4e":"code","e2b2d7e2":"code","9676b9f6":"code","045d742b":"code","cf4a19bd":"code","7abaca38":"code","34d7030b":"code","de6daeb5":"code","1c33f0cb":"code","062668dd":"code","50611a5e":"code","591e5f31":"code","e80caf6d":"code","cb040b6a":"code","869d50e4":"code","b470997e":"code","70ab5c8a":"code","bbe61a33":"code","8090d52d":"code","6ac6fe09":"code","0a222fb7":"markdown","812ce190":"markdown","7ce611d1":"markdown","d15f1fc7":"markdown","8ca5e18f":"markdown","01aa65e2":"markdown","72665705":"markdown","74461566":"markdown","a85a7f8a":"markdown","d3173e8c":"markdown","c65229b4":"markdown","ae112a9a":"markdown","77e70d9c":"markdown","f0b8365e":"markdown","01ba0783":"markdown","98d27b3a":"markdown","911bbbbe":"markdown","1e2f2688":"markdown","5a2e4b18":"markdown","dacf3cdd":"markdown","21ecba16":"markdown","d9456f1d":"markdown"},"source":{"ba1bff10":"## Essential libraries for data exploration\n\nimport numpy as np\nimport pandas as pd\n\nfrom itertools import chain\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2e085c91":"## Comment out these two lines if you are running this notebook on Kaggle\n\n# train_data = pd.read_json('.\/data\/train.json')\n# test_data = pd.read_json('.\/data\/test.json')","938b3c3d":"## Uncomment these two lines if you are running this notebook on Kaggle\n\ntrain_data = pd.read_json('..\/input\/train.json') \ntest_data = pd.read_json('..\/input\/test.json')","2083e528":"train_data.info()","046abf9e":"train_data.head()","63968c36":"test_data.info()","93d6d686":"test_data.head()","9395f069":"## Take a look at our target variable\n\nprint(\"Number of cuisine classes: {}\".format(len(train_data.cuisine.unique())))\ntrain_data.cuisine.unique()","0a3661c3":"## Import plotpy library for data visualization\n\nimport plotly\nimport plotly.offline as offline\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\ninit_notebook_mode(connected=True)","19f00039":"## Helper function for generating a list of n random colors for visualization purposes.\nimport random\n\ndef random_colors(n):\n    colors = []\n    for i in range(n):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors","bfbdec4e":"trace = go.Table(\n    header=dict(\n        values=['Cuisine', 'Number of Recipes'],\n        fill={'color': '#ddeaff'},\n        align = ['left'] * 5\n    ),\n    cells = dict(\n        values=[train_data.cuisine.value_counts().index, train_data.cuisine.value_counts()],\n        align=['left'] * 5\n    ))\n\nlayout = go.Layout(\n    title='Number of Recipes in Each Cuisine Class',\n    titlefont={'size': 20},\n    width=500, height=550,\n    paper_bgcolor='#ffffff',\n    plot_bgcolor='#ffffff',\n    autosize = False,\n    margin=dict(l=30,r=30,b=50,t=50,pad=1)\n)\n\niplot({'data': [trace], 'layout': layout})","e2b2d7e2":"percentages = []\nfor i in train_data.cuisine.value_counts():\n    percent = (i\/sum(train_data.cuisine.value_counts())) * 100\n    percent = \"%.2f\" % percent \n    percent = str(percent) + '%'\n    percentages.append(percent)\n    \ntrace = go.Bar(\n    x=train_data.cuisine.value_counts().values[::-1],             # x-axis: value_counts, sorted in descending\n    y=[i for i in train_data.cuisine.value_counts().index][::-1], # y-axis: cuisine label\n    text = percentages[::-1],                                     # bar-plot associated with bars\n    textposition = \"outside\",                                     # place text outside of bars\n    orientation = 'h',                                            # horizontal\n    marker = {'color': random_colors(20)}                         # colors for bars\n)\n\nlayout = go.Layout(\n    title=\"Cuisine Class Distribution\",                           # title of diagram\n    titlefont={'size': 25},                                       # size of title\n    width=1000, height=450,                                       # diagram size\n    plot_bgcolor='rgba(0,0,0,0)',                                 # color\n    paper_bgcolor='rgba(0,0,0,0)',                                # ... and color\n    margin=dict(l=75,r=75,b=50,t=50,pad=1)                        # margin\n)\n\niplot({'data': [trace], 'layout': layout})","9676b9f6":"trace = go.Histogram(\n    x=train_data['ingredients'].str.len(),\n    xbins={'start': 0, 'end': 90, 'size': 1},\n    marker={'color': '#7a5634'},\n    opacity=0.75)\n\nlayout = go.Layout(\n    title=\"Distribution of Recipe Length\",\n    titlefont={'size': 25},\n    xaxis={'title': 'Number of Ingredients'},\n    yaxis={'title': 'Count of Recipes'},\n    bargap=0.1, bargroupgap=0.2\n)\n\niplot({'data': [trace], 'layout': layout})","045d742b":"long_recipes = train_data[train_data['ingredients'].str.len() > 30]\nprint(\"There are {} recipes consist of more than 30 ingredients.\".format(len(long_recipes)))\n\nshort_recipes = train_data[train_data['ingredients'].str.len() < 2]\nprint(\"There are {} recipes consist of less than 2 ingredients.\".format(len(short_recipes)))","cf4a19bd":"colors = random_colors(21)\ncuisines = [i for i in train_data.cuisine.value_counts().index][::-1]\ndata = []\n\nfor i in range(20):\n    trace = go.Box(\n        y=train_data[train_data['cuisine'] == cuisines[i]]['ingredients'].str.len(),\n        name=cuisines[i], \n        marker={'color': colors[i]}\n    )\n    data.append(trace)\n    \nlayout = go.Layout(\n    title = \"Recipe Length Distribution by Cuisine\"\n)\n\niplot({'data': data, 'layout': layout})","7abaca38":"from collections import Counter\n\nall_ingredients = []\nfor item in train_data['ingredients']:\n    for ingr in item:\n        all_ingredients.append(ingr)\n        \ncounter = Counter()\nfor ingredient in all_ingredients:\n    counter[ingredient] += 1\n    \nprint(\"Among {} unique ingredients in our training sample,\" \n      \"the most commonly used 20 are: \".format(len(counter)))\ncounter.most_common(20)","34d7030b":"most_common = counter.most_common(20)\nmost_common_ingredients = [i[0] for i in most_common]\nmost_common_ingredients_count = [i[1] for i in most_common]\n\ntrace = go.Bar(\n    x=most_common_ingredients_count[::-1],\n    y=most_common_ingredients[::-1],\n    orientation='h',\n    marker={'color': random_colors(20)}\n)\n\nlayout = go.Layout(\n    xaxis={'title': \"Number of Occurrences in All Reciples (Training Sample)\"},\n    yaxis={'title': \"Ingredient\"},\n    title=\"The 20 Most Common Ingredients\",\n    titlefont={'size': 20},\n    width=800, height=400,\n    margin=dict(l=150,r=10,b=80,t=50,pad=5),\n)\n\niplot({'data': [trace], 'layout': layout})","de6daeb5":"cuisine_all_ingredients = []\nfor cuisine in cuisines:\n    ingredients = []\n    for item in train_data[train_data['cuisine'] == cuisine]['ingredients']:\n        for ingr in item:\n            ingredients.append(ingr)\n    result = (cuisine, len(list(set(ingredients))))\n    cuisine_all_ingredients.append(result)\n    \ntrace = go.Bar(\n    y=[i[0] for i in cuisine_all_ingredients],\n    x=[i[1] for i in cuisine_all_ingredients],\n    orientation='h',\n    marker={'color': random_colors(20)}\n)\n\nlayout = go.Layout(\n    xaxis={'title': 'Count of different ingredients'},\n    yaxis={'title': \"Cuisine\"},\n    title=\"Number of Unique Ingredientse Used In a Given Cuisine\",\n    titlefont={'size': 20},\n    margin=dict(l=100,r=10,b=60,t=60),\n    width=800, height=500\n)\n\niplot({'data': [trace], 'layout': layout})","1c33f0cb":"all_ingredients = list(set(all_ingredients)) # now unique\n\ndef top_cuisine_specific_ingredient(cuisine, top_num):\n    ingredients_used_by_other_cuisines = []\n    for item in train_data[train_data.cuisine != cuisine]['ingredients']:\n        for ingr in item:\n            ingredients_used_by_other_cuisines.append(ingr)\n    ingredients_used_by_other_cuisines = list(set(ingredients_used_by_other_cuisines))\n    ingredients_used_only_by_this_cuisine = [x for x in all_ingredients if x not in ingredients_used_by_other_cuisines]\n    \n    myCounter = Counter()\n    for item in train_data[train_data.cuisine == cuisine]['ingredients']:\n        for ingr in item:\n            myCounter[ingr] += 1\n    \n    for cuisine in list(myCounter):\n        if cuisine not in ingredients_used_only_by_this_cuisine:\n            del myCounter[cuisine]\n            \n    cuisine_specific = pd.DataFrame(myCounter.most_common(top_num), columns=['ingredient', 'count'])\n    return cuisine_specific","062668dd":"labels = [i for i in train_data.cuisine.value_counts().index]\nnumPlots = 20\ny = [[i]*2 for i in range(1, 20)]\ny = list(chain.from_iterable(y))\nz = [1, 2]*int(numPlots\/2)\n\nfig = tools.make_subplots(\n    rows=10, cols=2, subplot_titles=labels,\n    specs=[[{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}],\n            [{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}]],  \n    horizontal_spacing=0.20,\n    print_grid=False)\n\ntraces = []\nfor i, e in enumerate(labels):\n    cuisine_specific = top_cuisine_specific_ingredient(e, 5)\n    trace = go.Bar(\n        x = cuisine_specific['count'].values[::-1],\n        y = cuisine_specific['ingredient'].values[::-1],\n        orientation = 'h', \n        marker = {'color': random_colors(5)}\n    )\n    traces.append(trace)\n    \nfor trace, y, z in zip(traces, y, z):\n    fig.append_trace(trace, y, z)\n    fig['layout'].update(\n        height = 1600, width = 840, showlegend = False,\n        margin = dict(l=170,r=5,b=40,t=90,pad=5),\n        title = \"Ingredients Used Only in One Cuisine\"\n    );\n    \niplot(fig)","50611a5e":"features =  []# list of list of ingredients\nall_ingredients = [] # all ingredients (with duplicate)\nfor ingredient_list in train_data['ingredients']: # item here is a list of ingredients\n    features.append(ingredient_list)\n    all_ingredients += ingredient_list\n    \ntest_features = []\nfor ingredient_list in test_data['ingredients']: # item here is a list of ingredients\n    test_features.append(ingredient_list)","591e5f31":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(\n    vocabulary = list(set([str(i).lower() for i in all_ingredients])), \n    max_df=0.99, norm='l2', ngram_range=(1, 4)\n).fit([str(i) for i in features])\n\nX_tr = tfidf.transform([str(i) for i in features]) # X_tr - matrix of tf-idf scores\nto_predict = tfidf.transform([str(i) for i in test_features])\nfeature_names = tfidf.get_feature_names()","e80caf6d":"# Define a function for finding the most important features in a given cuisine according to Tf-Idf measure \ndef top_feats_by_class(min_tfidf=0.1, top_n=10):\n    ''' \n     Input:\n         trainsample - the tf-idf transformed training sample;\n         target - the target variable;\n         featurenames - array mapping from feature integer indices (position in the dataset) to feature name (ingredient in our case) in the Tf-Idf transformed dataset; \n         min_tfidf - features having tf-idf value below the min_tfidf will be excluded ;\n         top_n - how many important features to show.\n     Output:\n          Returns a list of dataframe objects, where each dataframe holds top_n features and their mean tfidf value\n         calculated across documents (recipes) with the same class label (cuisine). \n     '''\n    dfs = []\n    labels = np.unique(target)\n    \n    for label in labels:\n        \n        ids = np.where(target==label)\n        D = X_tr[ids].toarray()\n        D[D < min_tfidf] = 0\n        tfidf_means = np.nanmean(D, axis=0)\n        \n        topn_ids = np.argsort(tfidf_means)[::-1][:top_n] #  Get top n tfidf values\n        top_feats = [(feature_names[i], tfidf_means[i]) for i in topn_ids] # find their corresponding feature names\n        df = pd.DataFrame(top_feats)\n        df.columns = ['feature', 'tfidf']\n        \n        df['cuisine'] = label\n        dfs.append(df)\n        \n    return dfs","cb040b6a":"target = train_data['cuisine']\nresult_tfidf = top_feats_by_class(min_tfidf=0.1, top_n=5)","869d50e4":"cuisines = []\nfor i, e in enumerate(result_tfidf):\n    cuisines.append(result_tfidf[i].cuisine[0])\n\ntotalPlot = 20\ny = [[i] * 2 for i in range(1, 20)]\ny = list(chain.from_iterable(y))\nz = [1,2] * int((totalPlot\/2))\n\nfig = tools.make_subplots(\n    rows=10, cols=2, subplot_titles=cuisines, \n    specs=[[{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}],\n           [{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}]],  \n    horizontal_spacing=0.20, \n    print_grid=False)\n\ntraces = []\nfor index,element in enumerate(result_tfidf): \n    trace = go.Bar(\n        x=result_tfidf[index].tfidf[::-1],\n        y=result_tfidf[index].feature[::-1],\n        orientation='h',\n        marker={'color': random_colors(5)}\n    )\n    traces.append(trace)\n\nfor trace, y, z in zip(traces, y, z):\n    fig.append_trace(trace, y, z)\n    fig['layout'].update(\n        height=1600, width=840, showlegend=False,\n        margin=dict(l=110,r=5,b=60,t=90,pad=5), \n        title='Feature Importance based on Tf-Idf measure'\n    )\n\niplot(fig)","b470997e":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nencoder = LabelEncoder()\ny_transformed = encoder.fit_transform(train_data.cuisine)\n\nX_train, X_test, y_train, y_test = train_test_split(X_tr, y_transformed, random_state=42)","70ab5c8a":"from sklearn.linear_model import LogisticRegression\n\nclf1_cv = LogisticRegression(C=10, verbose=True)\nclf1_cv.fit(X_train, y_train)\n\ny_pred = encoder.inverse_transform(clf1_cv.predict(X_train))\ny_true = encoder.inverse_transform(y_train)\n\nprint(\"Accuracy score on train data: {}\".format(accuracy_score(y_true, y_pred)))\nprint(\"Accuracy score on test data: {}\".format(clf1_cv.score(X_test, y_test)))","bbe61a33":"from sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsRestClassifier\n\n_SVC = SVC(C=50, kernel='rbf', gamma=1.4, coef0=1, cache_size=3000, probability=True, verbose=True)\nOvRSVC = OneVsRestClassifier(_SVC, n_jobs=-1)\nOvRSVC.fit(X_train, y_train)\n\ny_pred = encoder.inverse_transform(OvRSVC.predict(X_train))\ny_true = encoder.inverse_transform(y_train)\n\nprint(\"Accuracy score on train data: {}\".format(accuracy_score(y_true, y_pred)))\nprint(\"Accuracy score on test data: {}\".format(OvRSVC.score(X_test, y_test)))","8090d52d":"from sklearn.ensemble import VotingClassifier\nvclf=VotingClassifier(estimators=[('clf1',clf1_cv),('clf2',OvRSVC)],voting='soft',weights=[1,2])\nvclf.fit(X_train , y_train)\nvclf.score(X_test, y_test)","6ac6fe09":"predicted_result = vclf.predict(to_predict)\npredicted_result_encoded = encoder.inverse_transform(predicted_result)\nresult_to_submit = pd.DataFrame({'cuisine' : predicted_result_encoded , 'id' : test_data.id })\nresult_to_submit = result_to_submit[[ 'id' , 'cuisine']]\nresult_to_submit.to_csv('submit.csv', index = False)","0a222fb7":"#### Submission","812ce190":"# What's Cooking?","7ce611d1":"#### Box Plot: Recipe Length Distribution by Cuisine","d15f1fc7":"## Setup ","8ca5e18f":"---\n## Constructing Models","01aa65e2":"#### Support Vector Classifier","72665705":"**Source**: [Kaggle - What's Cooking?](https:\/\/www.kaggle.com\/c\/whats-cooking-kernels-only)\n\n**Problem** - Predict the type of cuisine based on given data (ingredients).\n\n**Type** - Multiclass classification with text processing and analysis.","74461566":"#### TFIDF \n\nTFIDF, short for **term frequency\u2013inverse document frequency**, is a numerical statistic that is intended to reflect **how important a word to a document in a collection or corpus**. In this case, it can tell us which are the features (words) that are important for a given cuisine - a higher TFIDF score means higher importance of the word for the given cuisine and vice versa. The result of the sklearn tf-idf transormation is a matrix of tf-idf scores with one row per recipe and as many columns as there are different ingredients in the dataset.","a85a7f8a":"#### Ingredients Used Only in One Cuisine Class","d3173e8c":"#### Table: Number of Recipes in Each Cuisine Class","c65229b4":"#### Bar Plot: Distribution of Recipe Length","ae112a9a":"#### Import libraries and data","77e70d9c":"#### Overview","f0b8365e":"---\n**Credit**\n- https:\/\/www.kaggle.com\/gloriahristova\/a-walkthrough-eda-vizualizations-unigram-model\/notebook\n- https:\/\/www.kaggle.com\/ash316\/what-is-the-rock-cooking-ensembling-network","01ba0783":"---\n## EDA","98d27b3a":"#### Logistic Regression","911bbbbe":"#### Voting Classifier","1e2f2688":"#### Bar Plot: Cuisine Class Distribution","5a2e4b18":"**Plotly**\n- Official website: [Plotly Python Open Source Graphing Library](https:\/\/plot.ly\/python\/)\n- A very helpful tutorial: [Plotly Tutorial for Beginners - Kaggle Notebook](https:\/\/www.kaggle.com\/kanncaa1\/plotly-tutorial-for-beginners)","dacf3cdd":"#### Bar Plot: Number of Unique Ingredients Used in a Given Cuisine","21ecba16":"#### A Closer Look at Ingredients: Top 20 Most Common Ingredients","d9456f1d":"#### Preparation"}}