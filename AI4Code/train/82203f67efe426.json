{"cell_type":{"a1318e10":"code","19db904b":"code","056ea863":"code","71b0e8a6":"code","49e3b504":"code","bd7d5914":"code","48975855":"code","38ddb18c":"code","fc4d4e40":"code","45fdd09f":"code","8a024ce1":"code","56713150":"code","ff78ab9f":"code","db3bbac3":"code","1ec9fd13":"code","07f5cb02":"code","1e9d29d1":"code","9692a3c8":"code","fadc3953":"code","c7b047f4":"code","6b2b1dfe":"code","d387da40":"code","d64a9f0f":"code","bc9e0815":"code","77384f48":"code","963b76ea":"code","a815ee34":"code","66cd9006":"code","18e852ac":"code","c109920c":"code","aaa1259b":"code","47702e85":"code","ebcc4d65":"code","713c3036":"code","34b6852b":"code","8eb32f3d":"code","7a02def7":"code","d26f2402":"markdown","08195077":"markdown","1dc5ac40":"markdown","61672415":"markdown","1f982512":"markdown","05e28cc0":"markdown","8395ad5c":"markdown","00aa115e":"markdown","691bf5c8":"markdown","6634f339":"markdown","04b7da5a":"markdown","d88efa1b":"markdown","5279addd":"markdown","8c815ce4":"markdown","2c8913ee":"markdown","a4c1efee":"markdown","8ab482eb":"markdown","6e15fc2c":"markdown","c67bcbe3":"markdown","75ea99e0":"markdown","62f73d7a":"markdown","a6251e5c":"markdown"},"source":{"a1318e10":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold,KFold\nfrom sklearn.metrics import f1_score\nfrom lightgbm import LGBMRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nimport xgboost as xgb\n\nseed = 47","19db904b":"train_data = pd.read_csv('..\/input\/mf-accelerator\/contest_train.csv')\ntest_data = pd.read_csv('..\/input\/mf-accelerator\/contest_test.csv')\nsample_subm = pd.read_csv('..\/input\/mf-accelerator\/sample_subm.csv')","056ea863":"print('Size of training set: {} rows and {} columns'.format(*train_data.shape))\ntrain_data.head()","71b0e8a6":"train_data['TARGET'].value_counts(normalize=True)","49e3b504":"def basic_details(df):\n    b = pd.DataFrame()\n    b['Missing value'] = df.isnull().sum()\n    b['N unique value'] = df.nunique()\n    b['dtype'] = df.dtypes\n    return b\ndet = basic_details(train_data)\ndet.sort_values(by='Missing value', ascending=False)[:10]","bd7d5914":"start_drop = ['FEATURE_189', 'FEATURE_190', 'FEATURE_191', 'FEATURE_194']\n\ntrain = train_data.drop(start_drop, axis=1)\ntest = test_data.drop(start_drop, axis=1)","48975855":"cols = [c for c in train_data.columns[2:]]\nprint('Number of features: {}'.format(len(cols)))\n\nprint('Feature types:')\ntrain_data[cols].dtypes.value_counts()","38ddb18c":"counts = [[], [], []]\nfor c in [c for c in train.columns[2:]]:\n    typ = train[c].dtype\n    uniq = len(np.unique(train_data[c]))\n    if uniq == 1: counts[0].append(c)\n    elif uniq == 2: counts[1].append(c)\n    elif uniq<15: counts[2].append(c)\n\nprint('Constant features: {} Binary features: {} Categorical features: {}\\n'.format(*[len(c) for c in counts]))\n\nprint('Constant features:', counts[0])\nprint('Binary features:', counts[1])\nprint('Categorical features:', counts[2])","fc4d4e40":"conts_drop = ['FEATURE_3', 'FEATURE_144', 'FEATURE_249', 'FEATURE_256']\ntrain = train.drop(conts_drop, axis=1)\ntest = test.drop(conts_drop, axis=1)","45fdd09f":"binary_means = [np.mean(train[c]) for c in counts[1]]\nbinary_names = np.array(counts[1])[np.argsort(binary_means)]\nbinary_means = np.sort(binary_means)\n\nplt.title('Mean values of binary variables')\n\nnames, means = binary_names, binary_means\nplt.barh(range(len(means)), means)\nplt.xlabel('Mean value')\nplt.yticks(range(len(means)), names)\nplt.show()","8a024ce1":"count = []\nfor c in [c for c in train.columns[2:]]:\n    typ = train[c].dtype\n    uniq = len(np.unique(train[c]))\n    if uniq<15 and train[c].value_counts(normalize=True).values[0]>0.94: count.append(c)\n\nprint('Almost const features:', count)","56713150":"almost_const = ['FEATURE_2', 'FEATURE_5', 'FEATURE_6', 'FEATURE_31', 'FEATURE_140', 'FEATURE_156', 'FEATURE_157', 'FEATURE_159']\ntrain = train.drop(almost_const, axis=1)\ntest = test.drop(almost_const, axis=1)","ff78ab9f":"for c in ['FEATURE_9', 'FEATURE_10', 'FEATURE_213', 'FEATURE_214', 'FEATURE_218', 'FEATURE_219', 'FEATURE_220', 'FEATURE_257', 'FEATURE_258', 'FEATURE_259']:\n    value_counts = train[c].value_counts()\n    fig, ax = plt.subplots(figsize=(10, 5))\n    plt.title('Categorical feature {} - Cardinality {}'.format(c, len(np.unique(train[c]))))\n    plt.xlabel('Feature value')\n    plt.ylabel('Occurences')\n    plt.bar(range(len(value_counts)), value_counts.values)\n    ax.set_xticks(range(len(value_counts)))\n    ax.set_xticklabels(value_counts.index, rotation='vertical')\n    plt.show()","db3bbac3":"count_num = []\nfor c in [c for c in train.columns[2:]]:\n    typ = train[c].dtype\n    uniq = len(np.unique(train[c]))\n    if uniq>=100: count_num.append(c)\n\nprint('Number of numerical features:', len(count_num))","1ec9fd13":"from sklearn.impute import SimpleImputer\n\nimpute = SimpleImputer(strategy='most_frequent')\nX_impute = impute.fit_transform(train.drop(['TARGET', 'ID'], axis=1))\nX_test_impute = impute.fit_transform(test.drop(['ID'], axis=1))\n\nX = pd.DataFrame(X_impute)\nX.columns = train.drop(['TARGET', 'ID'], axis=1).columns\nX.index = train.drop(['TARGET', 'ID'], axis=1).index\n\nX_test = pd.DataFrame(X_test_impute)\nX_test.columns = test.drop(['ID'], axis=1).columns\nX_test.index = test.drop(['ID'], axis=1).index\n\ny = train['TARGET']","07f5cb02":"mms = MinMaxScaler()\n\nX[count_num] = mms.fit_transform(X[count_num])\nX_test[count_num] = mms.fit_transform(X_test[count_num])","1e9d29d1":"from optuna import Trial\nimport gc\nimport optuna\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\n\n\ndef objective(trial:Trial):\n    \n    gc.collect()\n    models=[]\n    validScore=0\n   \n    model,log = fitXGB(trial,X,y)\n    \n    models.append(model)\n    gc.collect()\n    validScore+=log\n    validScore\/=len(models)\n    \n    return validScore","9692a3c8":"def fitXGB(trial,X, y):\n    \n    params={\n    'n_estimators':trial.suggest_int('n_estimators', 0, 1000), \n    'max_depth':trial.suggest_int('max_depth', 2, 128),\n    'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.2),\n    'subsample': trial.suggest_loguniform('subsample', 0.01, 1),\n    'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1),\n    'min_child_weight ': trial.suggest_int('min_child_weight', 1, 256),\n    'reg_alpha':trial.suggest_uniform('reg_alpha', 0, 5),\n    'reg_lambda':trial.suggest_uniform('reg_lambda', 0, 5),\n    'random_state':seed\n    }\n    stkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n    model = xgb.XGBClassifier(\n                           n_estimators=params['n_estimators'],\n                           max_depth=params['max_depth'],\n                           learning_rate=params['learning_rate'],\n                           random_state =params['random_state '],\n                           min_child_weight =params['min_child_weight '],\n                           subsample=params['subsample'],\n                           colsample_bytree=params['colsample_bytree'],\n                           reg_alpha=params['reg_alpha'], \n                           reg_lambda=params['reg_lambda'],\n                           objective=\"multi:softprob\")\n    res=[]\n    local_probs=pd.DataFrame()\n\n    for i, (tdx, vdx) in enumerate(stkfold.split(X, y)):\n        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n        model.fit(X_train, y_train,\n                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                 verbose=False)   \n        preds = pd.DataFrame(model.predict(X_valid))\n        \n        res.append(f1_score(y_valid, preds, average='macro'))\n    \n    err = np.mean(res)\n    print('**score :',err)\n    return model, 1-err","fadc3953":"#study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n#study.optimize(objective, timeout=60*60*2)","c7b047f4":"strfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\nparams={\n    'n_estimators':719, \n    'num_leaves':19,\n    'max_depth':59,\n    'learning_rate': 0.056142869266916216,\n    'subsample': 0.013006267502359514,\n    'colsample_bytree': 0.027391500037335745,\n    'min_data_in_leaf': 125,\n    'feature_fraction': 0.8466331464702941,\n    'bagging_fraction': 0.5683222789764869,\n    'bagging_freq':1,\n    'random_state':seed\n    }\nlgbm = LGBMRegressor(num_leaves=params['num_leaves'],\n                    n_estimators=params['n_estimators'],\n                    max_depth=params['max_depth'],\n                    learning_rate=params['learning_rate'],\n                    random_state=params['random_state'],\n                    min_data_in_leaf=params['min_data_in_leaf'],\n                    subsample=params['subsample'],\n                    colsample_bytree=params['colsample_bytree'],\n                    bagging_freq=params['bagging_freq'],\n                    bagging_fraction=params['bagging_fraction'],\n                    feature_fraction=params['feature_fraction'],\n                    verbose_eval=20,\n                    objective='multiclass',\n                    num_class=3)","6b2b1dfe":"def calc(X,y,X_test, model, cv, cols, oof):\n    \n    if cols is None:\n        cols = X.columns\n    X=X[cols]\n    \n    res=[]\n    local_probs = pd.DataFrame()\n    for i, (tdx, vdx) in enumerate(cv.split(X, y)):\n        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n        model.fit(X_train, y_train,\n                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                 early_stopping_rounds=30, verbose=False)   \n        preds = pd.DataFrame(model.predict(X_valid)).idxmax(axis=1).values\n        \n        if oof==1:   \n            X_test=X_test[cols]\n            oof_predict = model.predict(X_test)\n            local_probs[f'fold_{i+1}'] = pd.DataFrame(model.predict(X_test)).idxmax(axis=1)\n        ll = f1_score(y_valid, preds, average='macro')\n        print(f'{i} Fold: {ll}')\n        res.append(ll)\n    print(f'AVG score: {round(np.mean(res), 5)}')\n    return np.mean(res), local_probs.mode(axis=1)","d387da40":"_, _ = calc(X, y, X_test, lgbm, strfold, None, 0)","d64a9f0f":"lgbm.fit(X, y)\npreds_lgbm = pd.DataFrame(lgbm.predict(X_test)).idxmax(axis=1).values\n\nsample_subm['Predicted'] = preds_lgbm\nsample_subm.to_csv('subm_lgbm.csv', index=False)","bc9e0815":"feature_imp = pd.DataFrame(sorted(zip(lgbm.feature_importances_,X.columns)), columns=['Value','Feature'])[-50:]\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features Top 50')\nplt.tight_layout()\nplt.show()","77384f48":"import h2o\nprint(h2o.__version__)\nfrom h2o.automl import H2OAutoML\n\nh2o.init(max_mem_size='16G')","963b76ea":"train10 = h2o.import_file(\"..\/input\/mf-accelerator\/contest_train.csv\")\ntest10 = h2o.import_file(\"..\/input\/mf-accelerator\/contest_test.csv\")\n\ntrain10[train10[\"TARGET\"] ==2, \"TARGET\"] = 0\nx = test10.columns[1:]\ny = 'TARGET'\n\ntrain10[y] = train10[y].asfactor()","a815ee34":"aml10 = H2OAutoML(max_runtime_secs = 2*60, seed = seed)\naml10.train(x=x, y=y, training_frame=train10)","66cd9006":"lb = aml10.leaderboard\nlb.head()","18e852ac":"model_ids = list(aml10.leaderboard['model_id'].as_data_frame().iloc[:,0])\nse = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\nmetalearner = h2o.get_model(se.metalearner()['name'])\nmetalearner.std_coef_plot()","c109920c":"pred10 = aml10.predict(test10)\npred10.head()","aaa1259b":"pred_ml = pd.read_csv('..\/input\/mf-accelerator\/sample_subm.csv')\npred_ml['1_0'] = pred10.as_data_frame()['predict'].values","47702e85":"train20 = h2o.import_file(\"..\/input\/mf-accelerator\/contest_train.csv\")\ntest20 = h2o.import_file(\"..\/input\/mf-accelerator\/contest_test.csv\")\n\ntrain20[train20[\"TARGET\"] ==1, \"TARGET\"] = 0\nx = test20.columns[1:]\ny = 'TARGET'\n\ntrain20[y] = train20[y].asfactor()","ebcc4d65":"aml20 = H2OAutoML(max_runtime_secs = 2*60, seed = seed)\naml20.train(x=x, y=y, training_frame=train20)","713c3036":"lb = aml20.leaderboard\nlb.head()","34b6852b":"model_ids = list(aml20.leaderboard['model_id'].as_data_frame().iloc[:,0])\nse = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\nmetalearner = h2o.get_model(se.metalearner()['name'])\nmetalearner.std_coef_plot()","8eb32f3d":"pred20 = aml20.predict(test20)\npred_ml['2_0'] = pred20.as_data_frame()['predict'].values","7a02def7":"pred_ml['Predicted'] = pred_ml['1_0'] + pred_ml['2_0']\npred_ml[\"Predicted\"].replace({3:2}, inplace=True)\npred_ml = pred_ml[['ID', 'Predicted']]\npred_ml.to_csv('subm_automl.csv', index=False)","d26f2402":"The AutoML Stacked Ensembles use the GLM with non-negative weights as the default metalearner (combiner) algorithm. Let's examine the variable importance of the metalearner algorithm in the ensemble. This shows us how much each base learner is contributing to the ensemble.","08195077":"## Feature analysis","1dc5ac40":"And for CV it was decided to use **MinMaxScaler**.","61672415":"**Target Variable:**\n\n\"TARGET\" is the variable we need to predict. So let us do some analysis on this variable first.","1f982512":"Using CV, I defined 94 as the percentage of the most popular feature category that can be removed.","05e28cc0":"## 2\/0 Binary classification","8395ad5c":"## AutoML\n\n**Automated machine learning (AutoML)** is the process of automating the end-to-end process of applying machine learning to real-world problems. In a typical machine learning application, the typical stages (and sub-stages) of work are the following:\n\n1. Data preparation\n    * data pre-processing\n    * feature engineering\n    * feature extraction\n    * feature selection\n2. Model selection\n3. Hyperparameter optimization (to maximize the performance of the final model)\n\nAutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.","00aa115e":"> One of the problems was that all values are in float format, and if you apply some kind of data processing strategies to all columns, you might get a bad result.\n\nI have compiled in a rather crude way such a set of columns as numeric.","691bf5c8":"I decided to try setting up 2 models for binary classification, so I was not sure if the library supports multicalss.","6634f339":"# Load modules","04b7da5a":"We can see that there are several columns where **more than 90% of the data is missing**. Using popular imputers, it is unlikely that it will be possible to fill in the missing values qualitatively. So I decided to remove them from the set.","d88efa1b":"Thanks to the organizers for this challenge and everyone for participating! In this notebook you will find:\n\n* EDA\n* fast preproccessing\n* modelling\n* AutoML\n","5279addd":"Among the most important arguments (with their default values) of H2OAutoML() are the following:\n\n* **nfolds=5** - number of folds for k-fold cross-validation (nfolds=0 disables cross-validation)\n* **balance_classes=False** - balance training data class counts via over\/under-sampling\n* **max_runtime_secs=3600** - how long the AutoML run will execute (in seconds) (I set 120 seconds to show with an example)\n* **max_models=None** - the maximum number of models to build in an AutoML run (None means no limitation)\n* **include_algos=None** - list of algorithms to restrict to during the model-building phase (cannot be used in combination with exclude_algos parameter; None means that all appropriate H2O algorithms will be used)\n* **exclude_algos=None** - list of algorithms to skip during the model-building phase (None means that all appropriate H2O algorithms will be used)\n* **seed=None** - a random seed for reproducibility (AutoML can only guarantee reproducibility if max_models or early stopping is used because max_runtime_secs is resource limited, meaning that if the resources are not the same between runs, AutoML may be able to train more models on one run vs another)","8c815ce4":"The graph shows that some binary functions are strongly skewed towards one of the values (**the average value is about 0**). I thought that these functions might decrease the performance of the models because they have unbalanced values. Perhaps such functions will be among the categorical ones too? Let's check.","2c8913ee":"## Missing values\n\nLet's see how much missing data is in the dataset.","a4c1efee":"# Fast preproccessing\n\n## Impute values\n\nFor the baseline, I used **SimpleImputer** as a tool to fill in the missing data. You could also fill in the data separately for categorical data and for numeric data, try KNNImputer.","8ab482eb":"So out of all our features, we are given 260 float variables. What about the cardinality of our features?","6e15fc2c":"We have **4 features which only have a single value in them** - these are pretty useless for supervised algorithms, and should probably be dropped.\n\nThe rest of our dataset is made up of many binary features and categorical features.","c67bcbe3":"Outlier identification remains an unsolved problem. I tried various methods, but I think you shouldn't pay too much attention to them here *(you can overdo it and delete the required data, mistaking it for anomalous).*","75ea99e0":"## 1\/0 Binary classification","62f73d7a":"# Modeling\n\n## LGBM\n\n* I used Optuna for hyperparameters tuning\n* It was performed with respect to StratifiedKFold cross validation on 5 folds\n* Parameters for tuning and their final values in cells below","a6251e5c":"# EDA\n\n## Training set"}}