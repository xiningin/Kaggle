{"cell_type":{"6cf64d1b":"code","208f4bc1":"code","eb795ea9":"code","568a951c":"code","0df7566a":"code","79108384":"code","4da23ce8":"code","21b376c0":"code","8e7e680b":"code","973e9bef":"code","b389d2c6":"code","0db8bd45":"code","7359d25e":"code","531f0fed":"code","c294650f":"code","2197c621":"code","9767cf4b":"code","d920ba9f":"code","4122eaa6":"code","2309e2a2":"code","d51b8cc6":"code","7bbebcab":"code","37f592b6":"code","ddeb95c8":"code","8b629504":"code","23ea9ea7":"code","a173fbcb":"code","49e981c1":"code","c1706274":"markdown","af187361":"markdown","1417cfa3":"markdown"},"source":{"6cf64d1b":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#!pip install tensorflow==2.6.0\nimport tensorflow as tf\n\n\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import StratifiedKFold\nimport tensorflow_addons as tfa\nfrom sklearn.utils import class_weight\nimport os \nfrom tensorflow.keras import layers\n\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras import layers\nimport glob","208f4bc1":"import random","eb795ea9":"#!pip install tensorflow-addons==0.13.0\nimport tensorflow_addons  as tfa","568a951c":"try:\n    import efficientnet.keras as efn\nexcept:\n    \n    !pip install -U efficientnet\n    import efficientnet.keras as efn\n","0df7566a":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","79108384":"CREATE_TF_RECORD = True","4da23ce8":"train_csv = \"..\/input\/seti-breakthrough-listen\/train_labels.csv\"\n\ntrain_df_master = pd.read_csv( train_csv )\ntrain_df_master[\"path\"] = train_df_master[\"id\"].apply( lambda x: \"..\/input\/seti-breakthrough-listen\/train\/\"+ str(x[0]) +\"\/\"+x +\".npy\" )\ntrain_df_master.head()\n","21b376c0":"CFG= {\n    \n    \"IMG_LENGTH\" :  256,\n    \"IMG_WIDTH\" : 256,\n    \"CHANNELS\" : 3,\n    \"RANDOM_STATE\" : 100,\n    \"BATCH_SIZE\"  :8*50 * strategy.num_replicas_in_sync,\n    \"FOLDS\" : 5,\n    \"LEARNING_RATE\" : 0.1\n}","8e7e680b":"gcs_path= KaggleDatasets().get_gcs_path(\"seti-tfrecord-256x256\")\ntf_rec_file_list = glob.glob( gcs_path )","973e9bef":"\ngcs_path= KaggleDatasets().get_gcs_path(\"seti-tfrecord-256x256\")\ntf_rec_file_list = glob.glob( gcs_path )\n\ntrain_df_master_2 = train_df_master\ntrain_df,test_df = train_test_split ( train_df_master_2, train_size = 0.8, random_state= CFG[\"RANDOM_STATE\"],shuffle = True,stratify = train_df_master_2[\"target\"])\n\nprint (\"number of samples for train data set  = {} \".format(len ( train_df) ) )\nprint (\"number of samples for test data set  = {} \".format(len ( test_df)))\n","b389d2c6":"## Creating data generator which can work on Both TPU + GPU\n\ndef decode_numpy(  channel  ):\n    \n    def read_image(file_name, channel = None   ):\n        np_data =  tf.io.read_file ( file_name )\n        np_data = tf.io.decode_raw( np_data, tf.float16 )\n        np_data = tf.reshape( np_data[64:], (6, 273, 256 )) # (6, 273, 256 ) is data origional shape \n        np_data_1 = tf.stack( (np_data[0],np_data[2] ,np_data[4]), axis = 2 ) \n        #np_data_2 = tf.stack( (np_data[1],np_data[3] ,np_data[5]), axis = 2 ) \n        np_data_1 = tf.image.resize( np_data_1, (256,256))\n        #np_data_2 = tf.image.resize( np_data_2, (256,256))\n        \n        if channel == None: \n            random_int = np.random.randint(3)\n            np_data = np_data_1[:,:,random_int ] \n            return tf.stack( (np_data, np_data , np_data ), axis = 2) \n        else:\n            np_data = np_data_1[:,:,channel ] \n            return tf.stack( (np_data, np_data , np_data ), axis = 2) \n        \n        \n      \n    def decode( file_name,target ):\n        channel = None \n        return read_image ( file_name, channel   ),tf.cast(target, tf.float32)\n        \n    def decode_test_channel_0( file_name,target ):\n        channel = 0\n        return read_image ( file_name, channel   ),tf.cast(target, tf.float32)\n    \n    def decode_test_channel_1( file_name,target ):\n        channel = 1\n        return read_image ( file_name, channel   ),tf.cast(target, tf.float32) \n    \n    def decode_test_channel_2( file_name,target ):\n        channel = 2\n        return read_image ( file_name, channel   ),tf.cast(target, tf.float32) \n    \n    if channel == None :\n        \n        return decode\n    elif channel == 0 :\n        return  decode_test_channel_0\n\n    elif channel == 1 :\n        return  decode_test_channel_1\n\n    elif channel == 2 :\n        return  decode_test_channel_2\n\ndef data_augmentation( ):\n    \n    def add_augmentation( image, target ):\n        \n        image = tf.image.random_flip_left_right( image, seed=CFG[\"RANDOM_STATE\"] )\n        image = tf.image.random_flip_up_down( image, seed=CFG[\"RANDOM_STATE\"] )\n        image = tf.image.random_contrast( image,0.2,0.5, seed=CFG[\"RANDOM_STATE\"] )\n        \n        return image,target\n    \n    return  add_augmentation\n\ndef datagenerator_rev_02(df,test = False,channel = None ):\n    file_list = df[\"tpu_path\"].to_list() \n    target = df[\"target\"].to_list() \n    decode_tf = decode_numpy( channel )\n    augment_fn = data_augmentation()\n    \n    datagen = tf.data.Dataset.from_tensor_slices( (file_list,target ))\n    datagen = datagen.map( decode_tf ,num_parallel_calls= tf.data.AUTOTUNE )\n    datagen = datagen.map(augment_fn, num_parallel_calls= tf.data.AUTOTUNE ) if not test else datagen\n    datagen = datagen.repeat() if not test else datagen\n    datagen = datagen.shuffle(1024) if not test else datagen\n    datagen = datagen.batch(CFG[\"BATCH_SIZE\"])\n    datagen = datagen.prefetch(tf.data.AUTOTUNE )\n    return  datagen","0db8bd45":"## Creating data generator which can work on Both TPU + GPU\n\ndef decode_numpy(    ):\n    \n    def read_image(file_name, channel ):\n        np_data =  tf.io.read_file ( file_name )\n         \n        np_data = tf.reshape( tf.io.decode_raw( np_data, tf.float16 )[64:], (6, 273, 256 ))  # (6, 273, 256 ) is data origional shape \n        #np_data_1 = tf.stack( (np_data[0],np_data[2] ,np_data[4]), axis = 2 ) \n        #np_data_1 = tf.image.resize( np_data_1, (256,256))\n        #np_data = np_data_1[:,:,channel ] \n        if channel == 1 : channel = 2\n        if channel == 2 : channel = 4\n        return  tf.image.resize(tf.stack( (np_data[channel], np_data[channel] , np_data[channel] ), axis = 2) , (256,256) )\n        \n        \n      \n    def decode( file_name,target,channel ):\n        \n        return read_image ( file_name, channel   ),tf.cast(target, tf.float32)\n     \n    return decode\n    \n    \ndef data_augmentation( ):\n    \n    def add_augmentation( image, target ):\n        \n        return  tf.image.random_contrast( tf.image.random_flip_up_down( tf.image.random_flip_left_right( image, seed=CFG[\"RANDOM_STATE\"] \n                                                                                                       ), \n                                                                       seed=CFG[\"RANDOM_STATE\"] \n                                                                      ),\n                                         0.3,0.8, seed=CFG[\"RANDOM_STATE\"] \n                                        ), target\n       \n        #return image,target\n    \n    return  add_augmentation\n\ndef datagenerator_rev_02(df,test = False, channel =None  ):\n    file_list = df[\"tpu_path\"].to_list() \n    target = df[\"target\"].to_list() \n    df_channel = [channel]*df.shape[0] # df[\"channel\"].to_list() \n    \n    decode_tf = decode_numpy(  )\n    augment_fn = data_augmentation()\n    \n    datagen = tf.data.Dataset.from_tensor_slices( (file_list,target, df_channel ))\n    datagen = datagen.map( decode_tf ,num_parallel_calls= tf.data.AUTOTUNE )\n    datagen = datagen.map(augment_fn, num_parallel_calls= tf.data.AUTOTUNE ) if not test else datagen\n    datagen = datagen.repeat() if not test else datagen\n    datagen = datagen.shuffle(1024) if not test else datagen\n    datagen = datagen.batch(CFG[\"BATCH_SIZE\"])\n    datagen = datagen.prefetch(tf.data.AUTOTUNE )\n    return  datagen","7359d25e":"def _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef train_serialize_example(image, img_id, target ):\n    feature = {\n      'image'         : _bytes_feature(image),\n      'image_id'      : _bytes_feature(img_id),   \n      'target'        : _int64_feature(target),\n      }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n","531f0fed":"\nif CREATE_TF_RECORD and False :\n    \n    !mkdir \"256x256_channel_1_tf_record\"\n    each_file_contain = 100\n    \n    for i in range( 100, 200):\n        print ( i )\n        file_list = train_df_master[\"path\"][i*each_file_contain: (i+1)*each_file_contain] \n        target_val = train_df_master[\"target\"][i*each_file_contain: (i+1)*each_file_contain] \n\n        with tf.io.TFRecordWriter( \".\/256x256_channel_1_tf_record\/256x256_tfrecord_\" +str(i) + \".tfrec\" ) as writer:\n            for file_name, target in zip (file_list,target_val):\n                np_data = np.load ( file_name )\n                np_data= np.dstack(( np_data[0],np_data[2],np_data[4]))\n                np_data =  tf.image.resize( np_data,( 256,256) ).numpy()\n                np_data  = np_data.astype( np.float32 )\n                file_id  = file_name.split(\"\/\")[-1].replace( \".npy\",\"_chan_\")\n                for channel in ( 0, 1, 2 ):\n                    example = train_serialize_example(np_data[:,:,channel].tobytes() , str.encode(file_id +\"str(channel)\"), target )\n                    writer.write(example)\n            writer.close()\n            \n    !zip -r  \".\/256x256_channel_1_tf_record_part1.zip\" \".\/256x256_channel_1_tf_record\"\n    ","c294650f":"## code decode tfrecode \ndef decode_image(image_data):\n    image = tf.io.decode_raw( image_data,tf.float32 )\n    #image = tf.cast(image, tf.float32) \/ 255.0  # convert image to floats in [0, 1] range\n    #image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef prepare_target(target):    \n    target = tf.cast(target, tf.float32)            \n    target = tf.reshape(target, [1])         \n    return target\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"image_id\":tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    image  = tf.reshape(image, [256, 256])\n    image = tf.stack( (image, image, image), axis = 2)\n    target = prepare_target(example['target'])\n    return image, target # returns a dataset of (image, label) pairs\n\ndef augmanet_data(image, target ):\n    \n    mask = random.randrange(2, 40, 2)\n   \n    #offset = random.randrange( 1, 200, 2 )\n    \n    image =  tf.image.random_contrast( tf.image.random_flip_up_down( tf.image.random_flip_left_right( image, seed=CFG[\"RANDOM_STATE\"]  ),  seed=CFG[\"RANDOM_STATE\"] \n                                                               ),0.3,0.8, seed=CFG[\"RANDOM_STATE\"] )\n    \n    #image= tf.squeeze(tfa.image.random_cutout( tf.expand_dims(image,0), (10, 10) ) )\n    #image = tfa.image.cutout( tf.expand_dims(image,0),(10,10), constant_values = 0.0,offset = (2,2,2) )\n    #image = tfa.image.cutout( images= image, mask_size = (mask,mask), constant_values = 0  )#, offset =(2,2 ), constant_values = 0)\n      \n    return image , target\n    \n                                        \n\ndef load_dataset(fileids, augment = False ,labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(fileids, num_parallel_reads=tf.data.AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord,num_parallel_calls= tf.data.AUTOTUNE)\n   # dataset = dataset.map( augmanet_data ,num_parallel_calls= tf.data.AUTOTUNE) if augment else dataset\n    \n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\n\n## Main function \ndef get_training_dataset(file_ist,repeat = True, augment= True   ):\n    dataset = load_dataset(file_ist,augment, labeled=True, ordered = False )\n    dataset = dataset.repeat()  if repeat else  dataset # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(20, seed=CFG[\"RANDOM_STATE\"])\n    dataset = dataset.batch(CFG[\"BATCH_SIZE\"])\n    dataset = dataset.prefetch(tf.data.AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\n#data_gen = get_training_dataset( train_files[:2],repeat = True, augment= True  )","2197c621":"def short_effnet_model():\n    #with strategy.scope():\n        \n    model_input = layers.Input( shape=  ( CFG[\"IMG_LENGTH\"],CFG[\"IMG_WIDTH\"], 3 ) , name= \"encoder_input_layer\" )\n\n\n    efff_net =efn.EfficientNetB0(include_top = False, \n                                   weights =\"noisy-student\" , \n                                   input_shape = ( CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"]) ,\n                                   input_tensor = model_input ,\n                                   classes=2,\n                                   pooling = True,\n                                   #classifier_activation='softmax',\n                                   drop_connect_rate= 0.7\n                                  ) \n\n    for layer in  efff_net.layers  : layer.trainable = True\n    \n    gaussian_noise = tf.keras.layers.GaussianNoise( stddev = 0.3 ) ( model_input )\n    random_crop = tf.keras.layers.experimental.preprocessing.RandomCrop( height = 30, width = 30 , seed=CFG[\"RANDOM_STATE\"]  ) (gaussian_noise)\n    random_flip =tf.keras.layers.experimental.preprocessing.RandomFlip( mode=\"horizontal_and_vertical\", seed=CFG[\"RANDOM_STATE\"] ) ( random_crop )\n    zoom_layer = tf.keras.layers.experimental.preprocessing.RandomZoom(  height_factor =(-0.3, -0.2)  , width_factor=(-0.3, -0.2), fill_mode='reflect', interpolation='bilinear', seed=CFG[\"RANDOM_STATE\"], fill_value=0.0 ) ( random_flip)\n    random_contrast = tf.keras.layers.experimental.preprocessing.RandomContrast( factor =[0.2, 0.8 ] , seed=CFG[\"RANDOM_STATE\"] ) ( zoom_layer )\n    \n    efff_net.layers[0] ( random_contrast )\n    layer_00 = efff_net.layers[-1].output\n    layer_01 = layers.Flatten()( layer_00 )\n    layer_02 = layers.Dense( 1, activation =\"sigmoid\") ( layer_01)\n    model_short = tf.keras.Model( inputs = model_input, outputs = layer_02 )\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate= 0.00126000004\/2 ) \n    model_short.compile( optimizer= optimizer,loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n                 metrics=[tf.keras.metrics.AUC() ])#AUC(curve='ROC')\n    \n    return model_short","9767cf4b":"model_effnet = short_effnet_model()\nmodel_effnet.summary()","d920ba9f":"gcs_path= KaggleDatasets().get_gcs_path(\"seti-tfrecord-256x256\") +\"\/256x256_channel_tf_record\"\ntf_rec_file_list = glob.glob( gcs_path ) \ntf_rec_file_list","4122eaa6":"CFG[\"RANDOM_STATE\"] =3000\ntrain_files , val_files = train_test_split ( glob.glob( \"..\/input\/seti-tfrecord-256x256\/256x256_channel_tf_record\/*.tfrec\"), train_size = 0.8, random_state= CFG[\"RANDOM_STATE\"],shuffle = True)\n","2309e2a2":"if True :\n    \n    group_list =[]\n    for i in range( 0, 300 ):\n        group_list = group_list + [ i ]*200\n\n    train_df_master[\"group_tfrec\"] = group_list\n   \n    anamally_count_group = train_df_master[[\"group_tfrec\", \"target\"]].groupby( by = \"group_tfrec\").sum().reset_index()\n    \n    test_file_group  = [ int( x.split(\"\/\")[-1].replace(\"256x256_tfrecord_\",\"\").replace(\".tfrec\",\"\")) for x in train_files ]\n    \n    anamally_sum = anamally_count_group[\"target\"].loc[ test_file_group ].sum()\n    \n    class_weight  = { 0:1, 1: ( ( ( len(train_files)* 200 ) - anamally_sum )  \/ anamally_sum ) }\n    class_weight","d51b8cc6":"class_weight","7bbebcab":"\n    \nwith strategy.scope():\n    model_effnet = short_effnet_model()\n\n\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(  patience=2,\n                                                    min_lr= 0.000001,\n                                                    monitor='val_loss', \n                                                    factor=0.45, \n                                                    verbose=1,\n                                                    min_delta = 0.2,\n                                                    cooldown=2,\n                                                    mode='auto', \n                                                   )\n\n\n\n\ntrain_file_count = len( train_files )*200*3\nval_file_count  = len( val_files )*200 *3\n\nCFG[\"BATCH_SIZE\"]= 16*45 * strategy.num_replicas_in_sync\n\nCFG[\"TRAIN_STEPS\"] = int ( train_file_count \/CFG[\"BATCH_SIZE\"] ) + (1 if train_file_count % CFG[\"BATCH_SIZE\"] != 0 else 0)\nCFG[\"VAL_STEPS\"] = int ( val_file_count\/CFG[\"BATCH_SIZE\"] ) + (1 if val_file_count% CFG[\"BATCH_SIZE\"] != 0 else 0)\n\n\n\n#model_effnet.load_weights(\"..\/input\/seti-gpu-rev-01-model\/Efficient_Net_Model_Rev_01.h5\")\ncheckpoint = tf.keras.callbacks.ModelCheckpoint( f'model{1}.h5', save_best_only=True, monitor='val_loss', mode='min')\n\n\nmodel_history = model_effnet.fit( get_training_dataset([ gcs_path +\"\/\"+ x.split(\"\/\")[-1] for x in train_files],repeat = True, augment= True  ),\n                        class_weight= class_weight ,\n                         steps_per_epoch= CFG[\"TRAIN_STEPS\"], \n                         epochs =12, \n                         validation_data= get_training_dataset([ gcs_path +\"\/\"+ x.split(\"\/\")[-1] for x in val_files],repeat = True, augment= False  ),\n                         validation_steps = CFG[\"VAL_STEPS\"],\n                         callbacks=[ checkpoint,lr_reducer ]\n                       )\n","37f592b6":"TEST = False","ddeb95c8":"\nif TEST:\n    ## Creating data generator which can work on Both TPU + GPU\n\n    def decode_numpy(    ):\n\n        def read_image(file_name, channel ):\n            np_data =  tf.io.read_file ( file_name )\n\n            np_data = tf.reshape( tf.io.decode_raw( np_data, tf.float16 )[64:], (6, 273, 256 ))  # (6, 273, 256 ) is data origional shape \n\n            if channel == 1 : channel = 2\n            if channel == 2 : channel = 4\n            return  tf.image.resize(tf.stack( (np_data[channel], np_data[channel] , np_data[channel] ), axis = 2) , (256,256) )\n\n\n\n        def decode( file_name,target,channel ):\n\n            return read_image ( file_name, channel   ),tf.cast(target, tf.float32)\n\n        return decode\n\n\n\n    def datagenerator_rev_03(df,test = False,channel = 0  ):\n        file_list = df[\"tpu_path\"].to_list() \n        target = df[\"target\"].to_list() \n        df_channel = [channel]*df.shape[0]\n\n        decode_tf = decode_numpy(  )\n        augment_fn = data_augmentation()\n\n        datagen = tf.data.Dataset.from_tensor_slices( (file_list,target, df_channel ))\n        datagen = datagen.map( decode_tf ,num_parallel_calls= tf.data.AUTOTUNE )\n        datagen = datagen.repeat() if not test else datagen\n        datagen = datagen.shuffle(1024) if not test else datagen\n        datagen = datagen.batch(CFG[\"BATCH_SIZE\"])\n        datagen = datagen.prefetch(tf.data.AUTOTUNE )\n        return  datagen","8b629504":"if TEST:\n    submission_gcs_path = KaggleDatasets().get_gcs_path(\"seti-breakthrough-listen\") +\"\/test\/\"\n    submission_df = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/sample_submission.csv\")\n    submission_df[\"tpu_path\"] = submission_df[\"id\"].apply( lambda x: submission_gcs_path+ str(x[0]) +\"\/\"+x +\".npy\" )\n    submission_df[\"target\"] = [1]*submission_df.shape[0]\n","23ea9ea7":"if TEST:\n    CFG[\"BATCH_SIZE\"]= 20 * strategy.num_replicas_in_sync\n    submission_data_gen = datagenerator_rev_03( submission_df, True, 0   )\n    submission_df[\"prediction_Channel_0\"] = model_effnet.predict( submission_data_gen )\n    print (\"completed channel-0\")\n    submission_data_gen = datagenerator_rev_03( submission_df, True, 1   )\n    submission_df[\"prediction_Channel_1\"] = model_effnet.predict( submission_data_gen ) \n    print (\"completed channel -1\")\n    submission_data_gen = datagenerator_rev_03( submission_df, True, 2   )\n    submission_df[\"prediction_Channel_2\"] = model_effnet.predict( submission_data_gen ) \n    print (\"completed channel -2\")\n    submission_df[\"target\"] =submission_df[[\"prediction_Channel_0\",\"prediction_Channel_1\",\"prediction_Channel_2\"]].apply( lambda x :  np.max( x ),axis = 1)","a173fbcb":"if TEST: submission_df[\"target\"] =submission_df[[\"prediction_Channel_0\",\"prediction_Channel_1\",\"prediction_Channel_2\"]].apply( lambda x :  np.max( x ),axis = 1)","49e981c1":"if TEST: submission_df[[\"id\",\"target\"]].to_csv(\".\/sample_submission.csv\",index = False)","c1706274":"# Reading TF Record","af187361":"# File to TFRECORD conversion\n","1417cfa3":"COMPETITION_NAME = \"seti-breakthrough-listen\"\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\ntrain_df_master[\"tpu_path\"] = train_df_master[\"path\"].apply( lambda x : x.replace(\"..\/input\/seti-breakthrough-listen\",GCS_DS_PATH))\ntrain_df_master.head()"}}