{"cell_type":{"1151c0b3":"code","cbc7d3b8":"code","67789c15":"code","579e672f":"code","bfc5a807":"code","0de32e96":"code","e602ec85":"code","af113b49":"code","d2b35b58":"code","5bac3545":"code","c0fd0080":"code","1269493e":"code","b4346937":"code","a5035b06":"code","0b6a27a5":"code","d842410b":"code","4f2bc4b1":"markdown","d57e0e84":"markdown","08a3c5c8":"markdown","d62198df":"markdown","ee9a0ac8":"markdown","766a5a47":"markdown"},"source":{"1151c0b3":"import os\nimport numpy as np\nimport pandas as pd","cbc7d3b8":"leafType = os.listdir(\"..\/input\/binaryplantdisease\/PlantDIseaseDataset\/train\") # list of all the leaf types in the dataset\nmain_dir = \"..\/input\/binaryplantdisease\/PlantDIseaseDataset\" ## main directory\ntrain_dir = \"..\/input\/binaryplantdisease\/PlantDIseaseDataset\/train\" ## train directory\ntest_dir = \"..\/input\/binaryplantdisease\/PlantDIseaseDataset\/valid\" ## test directory\nprint('base_dir:', (os.listdir(main_dir )))\nprint('total nubmer of classes:', len(os.listdir(train_dir )))","67789c15":"# number of samples for each class i.e images in each directory\nprint('total nubmer of images of each class in train set')\nfor i in leafType:\n    temp_dir = os.path.join(train_dir, i)\n    print(i[0:50],\":  \", len( os.listdir(temp_dir)))\n    \n    \nprint('\\ntotal nubmer of images of each class in test set')    \nfor i in leafType:\n    temp_dir = os.path.join(test_dir, i)\n    print(i[0:50],\":  \", len( os.listdir(temp_dir)))","579e672f":"import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport random\nfrom PIL import Image \nfrom skimage.io import imread","bfc5a807":"# randomly plotting images from all categories from training set\nimages = []\nfor folder in os.listdir(train_dir):\n    for image in os.listdir(train_dir + '\/' + folder):\n        images.append(os.path.join(train_dir, folder, image))\n\nplt.figure(1, figsize=(12, 12))\nn = 0\nfor i in range(16):\n    n += 1\n    random_img = random.choice(images)\n    imgs = imread(random_img)\n    sp = plt.subplot(4, 4, n)\n    sp.axis('off')# Don't show axes (or gridlines)\n    plt.imshow(imgs)\nplt.show()","0de32e96":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n## Image augmentation\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255. )\n\n# --------------------\n# Flow training images in batches of 32 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=32,\n                                                    class_mode='binary',\n                                                    target_size=(224, 224))     \n# --------------------\n# Flow validation images in batches of 32 using test_datagen generator\n# --------------------\ntest_generator =  test_datagen.flow_from_directory(test_dir,\n                                                         batch_size=32,\n                                                         class_mode  = 'binary',\n                                                         target_size = (224, 224))","e602ec85":"import tensorflow as tf\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 224x224 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    #dropout layer\n    tf.keras.layers.Dropout(0.2),\n    # Only 1 output neuron for binary classification\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","af113b49":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics = ['accuracy'])\n","d2b35b58":"from keras.callbacks import ModelCheckpoint\n\nfilepath=\"ssaPlantDiseaseDetector.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","5bac3545":"history = model.fit(\n            train_generator,\n            validation_data = test_generator,\n            steps_per_epoch = 100,\n            epochs = 25,\n            validation_steps = 50,\n            callbacks=callbacks_list,\n            verbose = 1)","c0fd0080":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","1269493e":"path_val_image = \"..\/input\/ssatestdata\/WhatsApp Image 2020-12-10 at 10.52.03 AM.jpeg\" # copied path of image\nimg = mpimg.imread(path_val_image)\nplt.imshow(img)\nplt.show()","b4346937":"from keras.preprocessing import image\n\nimg = image.load_img(path_val_image, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nclasses = model.predict(x)\nprint(classes)\nif classes>0.5:\n    print(\" diseased\")\nelse:\n    print(\"healthy\")","a5035b06":"import pathlib \nsaved_model = tf.keras.models.load_model('.\/ssaPlantDiseaseDetector.h5')\nconverter =  tf.lite.TFLiteConverter.from_keras_model(saved_model)\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\ntflite_model = converter.convert()","0b6a27a5":"tflite_model_file = pathlib.Path('ssaPlantDiseaseDetector.tflite')\ntflite_model_file.write_bytes(tflite_model)","d842410b":"from sklearn.metrics import classification_report, confusion_matrix\nnum_of_test_samples = 13893\nbatch_size = 32\nY_pred = model.predict_generator(test_generator, num_of_test_samples \/\/ batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(test_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['Healthy', 'Diseased']\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","4f2bc4b1":"## predicting classes","d57e0e84":"## Image data preprocessing\n","08a3c5c8":"## converting into tflite file","d62198df":"## Building a model ","ee9a0ac8":"## PlantDiseaseDetection","766a5a47":"## Exploring data"}}