{"cell_type":{"6315fc5d":"code","70db1189":"code","1854db63":"code","3472759c":"code","7c3bfc64":"code","31b00f17":"code","769ac4d5":"code","86ec1a91":"code","2d2999ac":"code","becb0200":"code","e240ac4b":"code","b07c0718":"code","492efb50":"code","fd39909f":"code","204437ec":"code","ea072d05":"code","8621050b":"code","6c7214da":"code","655312fd":"code","2ea3428c":"code","d2ae2d56":"code","144416c6":"code","ff1f7a8a":"code","68175d30":"code","bc6cf38d":"code","1fe6dc5f":"code","8c8f8bf5":"code","93d30ce1":"markdown","e9cb7093":"markdown","83c54571":"markdown","0a78e5f5":"markdown","0952fec4":"markdown","97f2dfe0":"markdown","79375710":"markdown","8abbd47c":"markdown","d6076119":"markdown","f754084b":"markdown","f4185c94":"markdown","80759d82":"markdown","440b6543":"markdown","13cb1c81":"markdown","35a8577e":"markdown","b54d8b2a":"markdown"},"source":{"6315fc5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","70db1189":"dataPath = \"\/kaggle\/input\/m5-forecasting-accuracy\/\"\ntimesteps = 14\nstartDay = 0","1854db63":"dt = pd.read_csv(dataPath + \"\/sales_train_validation.csv\")\ndt.head(3)\n","3472759c":"print(dt.info())","7c3bfc64":"#To reduce memory usage\ndef downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df","31b00f17":"#Reduce memory usage and compare with the previous one to be sure\ndt = downcast_dtypes(dt)","769ac4d5":"print(dt.info())","86ec1a91":"#Take the transpose so that we have one day for each row, and 30490 items' sales as columns\ndt = dt.T    \ndt.head(8)","2d2999ac":"#Remove id, item_id, dept_id, cat_id, store_id, state_id columns\ndt = dt[6 + startDay:]\ndt.head(5)","becb0200":"calendar = pd.read_csv(dataPath + \"\/calendar.csv\")\n","e240ac4b":"#Create dataframe with zeros for 1969 days in the calendar\ndaysBeforeEvent = pd.DataFrame(np.zeros((1969,1)))","b07c0718":"# \"1\" is assigned to the days before the event_name_1. Since \"event_name_2\" is rare, it was not added.\nfor x,y in calendar.iterrows():\n   if((pd.isnull(calendar[\"event_name_1\"][x])) == False):\n           daysBeforeEvent[0][x-1] = 1 \n            #if first day was an event this row will cause an exception because \"x-1\".\n            #Since it is not i did not consider for now.\n   ","492efb50":"#\"calendar\" won't be used anymore. \ndel calendar\n","fd39909f":"#\"daysBeforeEventTest\" will be used as input for predicting (We will forecast the days 1913-1941)\ndaysBeforeEventTest = daysBeforeEvent[1913:1941]\n#\"daysBeforeEvent\" will be used for training as a feature.\ndaysBeforeEvent = daysBeforeEvent[startDay:1913]\n","204437ec":"#Before concatanation with our main data \"dt\", indexes are made same and column name is changed to \"oneDayBeforeEvent\"\ndaysBeforeEvent.columns = [\"oneDayBeforeEvent\"]\ndaysBeforeEvent.index = dt.index","ea072d05":"dt = pd.concat([dt, daysBeforeEvent], axis = 1)\ndt.columns","8621050b":"#Feature Scaling\n#Scale the features using min-max scaler in range 0-1\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\ndt_scaled = sc.fit_transform(dt)","6c7214da":"X_train = []\ny_train = []\nfor i in range(timesteps, 1913 - startDay):\n    X_train.append(dt_scaled[i-timesteps:i])\n    y_train.append(dt_scaled[i][0:30490]) \n    #\u0130mportant!! if extra features are added (like oneDayBeforeEvent) \n    #use only sales values for predictions (we only predict sales) \n    #this is why 0:30490 columns are choosen","655312fd":"del dt_scaled\n","2ea3428c":"#Convert to np array to be able to feed the LSTM model\nX_train = np.array(X_train)\ny_train = np.array(y_train)\nprint(X_train.shape)\nprint(y_train.shape)","d2ae2d56":"dt.shape","144416c6":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first LSTM layer and some Dropout regularisation\nlayer_1_units=100\nregressor.add(LSTM(units = layer_1_units, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\nregressor.add(Dropout(0.2))\n\n# Adding a second LSTM layer and some Dropout regularisation\nlayer_2_units=3000\nregressor.add(LSTM(units = layer_2_units, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third LSTM layer and some Dropout regularisation\nlayer_3_units=3000\nregressor.add(LSTM(units = layer_3_units))\nregressor.add(Dropout(0.2))\n# layer_4_units=500\n# regressor.add(LSTM(units = layer_4_units))\nregressor.add(Dropout(0.2))\n# Adding the output layer\nregressor.add(Dense(units = 30490))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nepoch_no=500\nbatch_size_RNN=56\nregressor.fit(X_train, y_train, epochs = epoch_no, batch_size = batch_size_RNN)","ff1f7a8a":"# # Importing the Keras libraries and packages\n# from keras.models import Sequential\n# from keras.layers import Dense\n# from keras.layers import LSTM\n# from keras.layers import Dropout\n\n# # Initialising the RNN\n# regressor = Sequential()\n\n# # Adding the first LSTM layer and some Dropout regularisation\n# layer_1_units=40\n# regressor.add(LSTM(units = layer_1_units, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n# regressor.add(Dropout(0.25))\n\n# # Adding a second LSTM layer and some Dropout regularisation\n# layer_2_units=280\n# regressor.add(LSTM(units = layer_2_units, return_sequences = True))\n# regressor.add(Dropout(0.25))\n\n# # Adding a third LSTM layer and some Dropout regularisation\n# layer_3_units=280\n# regressor.add(LSTM(units = layer_3_units, return_sequences = True))\n# regressor.add(Dropout(0.3))\n\n# layer_4_units=300 \n# regressor.add(LSTM(units = layer_4_units))\n# regressor.add(Dropout(0.3))\n\n# # Adding the output layer\n# regressor.add(Dense(units = 30490))\n\n# # Compiling the RNN\n# regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# # Fitting the RNN to the Training set\n# epoch_no=35\n# batch_size_RNN=36\n# regressor.fit(X_train, y_train, epochs = epoch_no, batch_size = batch_size_RNN)\n\n","68175d30":"inputs= dt[-timesteps:]\ninputs = sc.transform(inputs)","bc6cf38d":"X_test.shape","1fe6dc5f":"X_test = []\nX_test.append(inputs[0:timesteps])\nX_test = np.array(X_test)\npredictions = []\n\nfor j in range(timesteps,timesteps + 28):\n#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n    predicted_stock_price = regressor.predict(X_test[0,j - timesteps:j].reshape(1, timesteps, 30491))\n    testInput = np.column_stack((np.array(predicted_stock_price), daysBeforeEventTest[0][1913 + j - timesteps]))\n    X_test = np.append(X_test, testInput).reshape(1,j + 1,30491)\n    predicted_stock_price = sc.inverse_transform(testInput)[:,0:30490]\n    predictions.append(predicted_stock_price)","8c8f8bf5":"import time\n\nsubmission = pd.DataFrame(data=np.array(predictions).reshape(28,30490))\n\nsubmission = submission.T\n    \nsubmission = pd.concat((submission, submission), ignore_index=True)\n\nsample_submission = pd.read_csv(dataPath + \"\/sample_submission.csv\")\n    \nidColumn = sample_submission[[\"id\"]]\n    \nsubmission[[\"id\"]] = idColumn  \n\ncols = list(submission.columns)\ncols = cols[-1:] + cols[:-1]\nsubmission = submission[cols]\n\ncolsdeneme = [\"id\"] + [f\"F{i}\" for i in range (1,29)]\n\nsubmission.columns = colsdeneme\n\ncurrentDateTime = time.strftime(\"%d%m%Y_%H%M%S\")\n\nsubmission.to_csv(\"submission.csv\", index=False)","93d30ce1":"* Take last days, 14 for this notebook (\"timestep\" parameter) in order to predict firts unknown day's sales.\n* Before using values for prediction, again use min-max transformation","e9cb7093":"* Concatenate \"daysBeforeEvent\" feature with our main dataframe \"dt\"","83c54571":"* Here a dataframe is created to store the knowledge if an event exist in the next day\n* Firstly, fill with zeros the dataframe","0a78e5f5":"* Here is the important part. \"X_train\" and \"y_train\" data is created. For each X_train item, 14 past days' sales and 14 daysBeforeEvent feature are included. So one element of X_train's shape is (14, 30491). For y_train we are predicting one day sales of 30490 items therefore one element of y_train's shape is (1, 30490)","0952fec4":"* Now, \"1\" is assigned the day before an event exist. Other days will remain as \"0\".","97f2dfe0":"Creation of X_train and y_train\n![resim.png](attachment:resim.png)","79375710":"* Here is again an important part. \n* We are using last 14 days in order to predict day 1915 sales.\n* In order to predict 1916th day, 13 days from our input data and 1 day from our prediction are used. After that we slide the window one by one.\n    * 12 days from input data + 2 days from our prediction to predict 1917th day\n    * 11 days from input data + 3 days from our prediction to predict 1918th day\n    * .....\n    * 14 days our prediction to predict last 1941th day sales.","8abbd47c":"* Remove the first six  colums id, item_id, dept_id, cat_id, store_id, state_id columns, to end up only days as rows","d6076119":"* Below timesteps is set to 14 to use past 14 days' sales.\n* Since there are lots of zero values in first days, \"startDay\" parameter can be used ignore unwanted days from the beginning.","f754084b":"# Data Prepration for LSTM\n\n* In this notebook LSTM is used for forecasting future sales. \n* The type of the LSTM can be regarded as Multivariate and Multiple Input Series (Multi-step is not used).\n* The model is trained using past sales values for each 30490 item and a feature which represents if there exists an event at the following day.  \n* For this notebook \"sales of past 14 days and event feature\" are used for predicting 15th day sales. Past days is a parameter which can be set to see the effect. ","f4185c94":"![resim.png](attachment:resim.png)","80759d82":"# Future Improvements\n* Here only sales of past days and oneDayBeforeEvent feature are used for prediction. More feature can be added.\n    * Maybe, lag features, sell prices can be included. But including those features for each item can increase the column size from 30491 to 60981 maybe more. Any ideas for feature addition are very welcome. I could not find a proper way to add those kind of features.\n* Data preprocessing may be applied. There are lots of zero values especially in the first year. But I could not find a way how to deal with them. In addition, outliers can be handled if any, especially if sell prices data is used.\n* Multi-step LSTM can be used for prediction of more than one day (for example 28 days at once or 14 days, 7 days, 2 days etc.)\n* Choosing correct neuron sizes, batch size and layer size can be achieved.\n* Each run can create different results. I did not add seed value but may be this can be added. I have wanted to see how much the result differs\n* You can share any ideas for improvement as a comment, we can discuss more detail","440b6543":"* Since, the \"daysBeforeEvent\" feature is used for predicting after the model trained as input, we seperate the 28 days as \"daysBeforeEventTest\"\n* For training the first 1914 days (if \"startDay\" is zero otherwise \"1913-startDay\") will be used.","13cb1c81":"# LSTM Model with Keras","35a8577e":"# Submission File Creation\n* Here, the submission file creation is done.","b54d8b2a":"* The shape of the data is not exactly what we want.\n* We want to have each day as row and 30490 items' sales as columns (features)\n* Therefore take the transpose of \"dt\""}}