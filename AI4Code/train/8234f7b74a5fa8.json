{"cell_type":{"65a922ba":"code","7339a43c":"code","4b60ca5e":"code","08e8070f":"code","8120ca56":"code","e5dd485b":"code","799bc3c6":"code","63733a94":"code","545439a5":"code","8ab2bab3":"code","752ddfd0":"code","b2bfdbd0":"code","5ed18f74":"code","c7733662":"code","ef945465":"code","5b48f46a":"code","81299d6f":"code","bd0ec9b8":"code","33247e94":"code","9da5420f":"code","529cfdad":"code","e979e237":"code","434ddff2":"code","8a76ab04":"code","04bc127b":"code","79aa9526":"code","b7250b07":"code","4955c843":"markdown","b006707a":"markdown","f98a04f2":"markdown","fc97dee4":"markdown","0c79b03a":"markdown","b2c9df5c":"markdown","f9307418":"markdown","9c6be7de":"markdown","51ae66c5":"markdown","e86bb526":"markdown"},"source":{"65a922ba":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7339a43c":"import warnings\nwarnings.filterwarnings('ignore')","4b60ca5e":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","08e8070f":"df=pd.read_csv('\/kaggle\/input\/data-scientist-salary-us-glassdoor\/data_cleaned_2021.csv')","8120ca56":"df.head()","e5dd485b":"df.info()","799bc3c6":"df['Sector'].unique()","63733a94":"df['job_title_sim'].unique()","545439a5":"df1=df.iloc[:,[19,12,39,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38]]","8ab2bab3":"df1.head()","752ddfd0":"plt.figure(figsize = (15,8))\nsns.heatmap(df1.corr(),annot=True, fmt=\"1.1f\")","b2bfdbd0":"df2=df.groupby('Sector')['Avg Salary(K)'].mean().sort_values(ascending=False)\nplt.figure(figsize = (15,8))\ncolor = [('b' if i < 100 else 'r') for i in df2]\ndf2.plot.bar(color=color)","5ed18f74":"df3=df.groupby('job_title_sim')['Avg Salary(K)'].mean().sort_values(ascending=False)\nplt.figure(figsize = (15,8))\ncolor = [('b' if i < 100 else 'r') for i in df3]\ndf3.plot.bar(color=color)","c7733662":"plt.figure(figsize=(15,15))\nplt.subplot(441)\ncolorlist = ['#377eb8','#e41a1c']\ndf.groupby('Python')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('Python')\nplt.subplot(442)\ndf.groupby('spark')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('spark')\nplt.subplot(443)\ndf.groupby('aws')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('aws')\nplt.subplot(444)\ndf.groupby('excel')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('excel')\nplt.subplot(445)\ndf.groupby('sql')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('sql')\nplt.subplot(446)\ndf.groupby('sas')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('sas')\nplt.subplot(447)\ndf.groupby('keras')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('keras')\nplt.subplot(448)\ndf.groupby('pytorch')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('pytorch')\nplt.subplot(449)\ndf.groupby('scikit')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('scikit')\nplt.subplot(4,4,10)\ndf.groupby('tensor')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('tensor')\nplt.subplot(4,4,11)\ndf.groupby('hadoop')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('hadoop')\nplt.subplot(4,4,12)\ndf.groupby('tableau')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('tableau')\nplt.subplot(4,4,13)\ndf.groupby('bi')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('bi')\nplt.subplot(4,4,14)\ndf.groupby('flink')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('flink')\nplt.subplot(4,4,15)\ndf.groupby('mongo')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('mongo')\nplt.subplot(4,4,16)\ndf.groupby('google_an')['Avg Salary(K)'].mean().plot.bar(color=colorlist)\nplt.title('google_an')\nplt.subplots_adjust(hspace=0.5)\nplt.subplots_adjust(wspace=0.5)","ef945465":"def rank(ex):\n    if ex >=100:\n        return 1\n    else:\n        return 0","5b48f46a":"df1.loc[:,'rank']=df1.loc[:,'Avg Salary(K)'].apply(rank)\ndf1","81299d6f":"df4=df1.drop(['Avg Salary(K)','Sector','job_title_sim'],axis=1)","bd0ec9b8":"pip install pycaret --ignore-installed llvmlite numba","33247e94":"from pycaret.classification import *","9da5420f":"exp_clf = setup(df4, target = 'rank',silent=True,session_id=1)","529cfdad":"compare_models()","e979e237":"rf = create_model('rf')","434ddff2":"plot_model(rf,'confusion_matrix')","8a76ab04":"plot_model(rf,'auc')","04bc127b":"plot_model(rf,'pr')","79aa9526":"interpret_model(rf)","b7250b07":"plot_model(rf,'feature')","4955c843":"This is a good opportunity for me to consider what I should learn in 2022 as a new year resolution !\nI focused on skills of data science in data set. This note book includes\n* Data Preprocessing\n* Feature engineering - drop features which are not skills\n* Visualization\n* Feature engineering - classify the data into two category 0 and 1 by average salary. 0 is less than 100k and 1 is 100k or more.\n* data classification by PyCaret\n\n\nI got some insight about what I should learn in 2022.\n* According to the correlation map, keras, pytorch, scikit and tensor are strong pisitive correlation. It means that I can expect synegy when I dig into them together.\n![image.png](attachment:8728ca36-35d8-48e9-9dc6-50a9ae10b470.png)\n\n\n* And according to the shap, it seems to be nice for me to try spark and mongo this year if I have a chance...\n![image.png](attachment:f3b2998c-94c6-41fd-9fb3-ef193e14ac8d.png)\n\n![spark.png](attachment:0c7eedc5-3ecd-4b9b-8227-e4935dd46bc3.png)\n\n![mongo.png](attachment:8d95ab34-6325-41f0-9eb0-0a74a7398364.png)\n","b006707a":"2) Average Salary by Sectors","f98a04f2":"2. Feature engineering - drop features which are not skills","fc97dee4":"1. Data Preprocessing","0c79b03a":"3) Average Salary by Job Title","b2c9df5c":"5. Data classification by pycaret","f9307418":"4) Average Salary by Skills","9c6be7de":"3. Visualization","51ae66c5":"4. Feature engineering - classify the data into two category 0 and 1 by average salary. 0 is less than 100k and 1 is 100k or more.","e86bb526":"1) Correlation"}}