{"cell_type":{"3d62a182":"code","f888f3e2":"code","d5d08bf8":"code","d8cfe930":"code","d5c3b883":"code","02d40dfa":"code","e9211a52":"code","325bd43e":"code","5818ffe1":"code","bdde54a2":"code","9abab38d":"code","4d810bc5":"code","ddc9db7b":"code","224670cf":"code","0347bc60":"markdown","1f2fa1cd":"markdown","e44e69bf":"markdown"},"source":{"3d62a182":"!pip install albumentations","f888f3e2":"import os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\n\nfrom torchvision.datasets import ImageFolder\nimport torchvision.models as models\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\n\nfrom datetime import datetime\nimport glob\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom PIL import Image","d5d08bf8":"DATA_DIR = \"..\/input\/enel-scene-classification-challenge-2021\/scene\"","d8cfe930":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nassert (\n    device.type == \"cuda\"\n), f\"your device type is {device.type}, change your runtime type to GPU\"\nprint(\"Device: {}\".format(device))","d5c3b883":"NUM_IMGS = 6\nIMG_SIZE = 150\nPADDING = 2\nPAD_VALUE = 1.0\n\nscene_train = ImageFolder(os.path.join(DATA_DIR, 'train'), transform=T.ToTensor())\nclasses = scene_train.classes\nnum_classes = len(classes)\nimgs = [torch.zeros(0, 3, IMG_SIZE, IMG_SIZE) for _ in range(num_classes)]\nwith_all_imgs = [False] * num_classes\nfor data, target in DataLoader(scene_train):\n    if len(imgs[target]) == NUM_IMGS:\n        with_all_imgs[target] = True\n    else:\n        imgs[target] = torch.cat((imgs[target], data))\n\n    if all(with_all_imgs):\n        break\n\nbatch = torch.cat(imgs)\nimg_grid = make_grid(batch, nrow=num_classes, padding=PADDING, pad_value=PAD_VALUE).numpy().transpose(1, 2, 0)\nplt.figure(figsize=(10, 10))\nplt.imshow(img_grid)\n\n\nticks = range(\n    IMG_SIZE \/\/ 2 + PADDING,\n    IMG_SIZE * NUM_IMGS + (NUM_IMGS + 1) * PADDING - IMG_SIZE \/\/ 2,\n    IMG_SIZE + PADDING,\n)\nplt.xticks(ticks, range(1, num_classes + 1))\nplt.yticks(ticks, classes)\n\nplt.ylim(IMG_SIZE * NUM_IMGS + (NUM_IMGS + 1) * PADDING, -PADDING)\nplt.title(\"Scene Images\")\nplt.show()","02d40dfa":"def train(\n    model, optimizer, criterion, data_loader, device, log_interval,\n):\n    running_loss = 0.0\n    running_corrects = 0\n    running_len = 0\n    dataset_len = len(data_loader.dataset)\n\n    model.train()\n\n    for n, (data, target) in enumerate(data_loader, 1):\n        data = data.to(device)\n        target = target.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(data)\n        _, preds = torch.max(outputs, 1)\n        loss = criterion(outputs, target)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * len(data)\n        running_corrects += torch.sum(preds == target.data).item()\n        running_len += len(data)\n\n        if n % log_interval == 0:\n            perc_len = 100.0 * running_len \/ dataset_len\n            print(\n                f\"[{running_len:>5}\/{dataset_len} ({perc_len:>4.1f}%)] \"\n                f\"- loss: {running_loss \/ running_len:.4f} \"\n                f\"- acc: {running_corrects \/ running_len:.4f}\"\n            )\n\n\ndef validate(model, criterion, data_loader, device):\n    running_loss = 0.0\n    running_corrects = 0\n\n    model.eval()\n\n    with torch.no_grad():\n        for data, target in data_loader:\n            data = data.to(device)\n            target = target.to(device)\n\n            outputs = model(data)\n            loss = criterion(outputs, target)\n            _, preds = torch.max(outputs, 1)\n\n            running_loss += loss.item() * len(data)\n            running_corrects += torch.sum(preds == target.data).item()\n\n    running_loss \/= len(data_loader.dataset)\n    running_corrects \/= len(data_loader.dataset)\n    return running_loss, running_corrects\n\n\ndef test(model, data_loader):\n    pred_class_ids = []\n\n    model.eval()\n\n    with torch.no_grad():\n        for data in data_loader:\n            outputs = model(data.to(device))\n            _, preds = torch.max(outputs, 1)\n            pred_class_ids.extend(preds.tolist())\n\n    return pred_class_ids","e9211a52":"class SceneTestDataset(Dataset):\n    def __init__(self, path, transform=None):\n        self.imgs = sorted(\n            glob.glob(os.path.join(path, \"*.jpg\")),\n            key=lambda x: int(os.path.basename(x)[:-4]),\n        )\n        self.transform = transform\n\n    def __getitem__(self, index):\n        x = Image.open(self.imgs[index])\n        if self.transform is not None:\n            x = self.transform(x)\n\n        return x\n\n    def __len__(self):\n        return len(self.imgs)","325bd43e":"class BaselineNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(256, 512, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.flatten = nn.Flatten()\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = self.flatten(x)\n        x = self.classifier(x)\n        return x","5818ffe1":"print(BaselineNet())","bdde54a2":"BATCH_SIZE = 32\nTRANSFORMS = {\n    \"train\": T.Compose(\n        [\n            T.Resize((224, 224)),\n            T.RandomHorizontalFlip(),  # simple data augmentation\n            T.ToTensor(),\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]\n    ),\n    \"val\": T.Compose(\n        [\n            T.Resize((224, 224)),\n            T.ToTensor(),\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]\n    ),\n}\n\nimage_datasets = {\n    x: ImageFolder(os.path.join(DATA_DIR, x), TRANSFORMS[x]) for x in [\"train\", \"val\"]\n}\nimage_datasets[\"test\"] = SceneTestDataset(path=os.path.join(DATA_DIR, 'test'), transform=TRANSFORMS[\"val\"])\ndata_loaders = {\n    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=x == \"train\")\n    for x in [\"train\", \"val\", \"test\"]\n}\n\nidx_to_class = {\n    ID: category for category, ID in image_datasets[\"train\"].class_to_idx.items()\n}","9abab38d":"%%time\n# Wall time: 6min 24s\n\nMODEL = BaselineNet()\nMODEL.to(device)\nNUM_EPOCHS = 5\nLR = 0.001\nMOMENTUM = 0.9\nOPTIMIZER = optim.SGD(MODEL.parameters(), lr=LR, momentum=MOMENTUM)\nCRITERION = nn.CrossEntropyLoss()\nLOG_INTERVAL = len(data_loaders[\"train\"]) \/\/ 5  # \/\/ x => print \"x\" times per epoch\n\ntorch.manual_seed(42)\n\nfor epoch in range(1, NUM_EPOCHS + 1):\n    print(f\"\\nEpoch: {epoch}\/{NUM_EPOCHS}\")\n    train(\n        model=MODEL,\n        criterion=CRITERION,\n        optimizer=OPTIMIZER,\n        log_interval=LOG_INTERVAL,\n        data_loader=data_loaders[\"train\"],\n        device=device,\n    )\n    val_loss, val_acc = validate(\n        model=MODEL, criterion=CRITERION, data_loader=data_loaders[\"val\"], device=device\n    )\n    print(f\"Val. loss: {val_loss:.4}\")\n    print(f\"Val. acc: {val_acc:.4}\")","4d810bc5":"test_ids = sorted(\n    [int(os.path.basename(img[:-4])) for img in image_datasets[\"test\"].imgs]\n)\npred_class_ids = test(MODEL, data_loaders[\"test\"])\npred_classes = [idx_to_class[pred_class_id] for pred_class_id in pred_class_ids]","ddc9db7b":"my_submission = pd.DataFrame({\"Image ID\": test_ids, \"Image Class\": pred_classes})\nmy_submission.head()","224670cf":"my_submission.to_csv(\"submission.csv\", index=False)","0347bc60":"# Scene Images","1f2fa1cd":"What follow is the code that was used to make sampleSubmission.csv. \n\n**First, run the following code without modifying it and try your first submission.**\n\nOnce you have verified that you are able to make a submission, try to improve the accuracy.\n\n> **Tips**:\n*   Change the model to use transfer learning \/ fine-tuning\n*   Add tensorboard visualization\n*   Play around with hyper-parameters, some examples are:\n  *   Try another optimizer\n  *   Add a learning rate scheduler\n  *   Try a different learning rate \/ momentum \/ batch size ...\n*   Try data augmentation (**only train**). See [torchvision.transforms](https:\/\/pytorch.org\/vision\/stable\/transforms.html) or [albumentations](https:\/\/github.com\/albumentations-team\/albumentations) if you feel fancy\n*   Implement early stopping and saving the best weights during training, see the [A Gentle Introduction to Early Stopping to Avoid Overtraining Neural Networks](https:\/\/machinelearningmastery.com\/early-stopping-to-avoid-overtraining-neural-network-models\/) Machine Learning Mastery article\n*   Try model ensembling, see the [Ensemble Learning Methods for Deep Learning Neural Networks](https:\/\/machinelearningmastery.com\/ensemble-methods-for-deep-learning-neural-networks\/#:~:text=Ensemble%20learning%20combines%20the%20predictions,and%20how%20predictions%20are%20combined.) Machine Learning Mastery article","e44e69bf":"# Your Solution"}}