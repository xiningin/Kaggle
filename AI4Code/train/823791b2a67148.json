{"cell_type":{"c0c99733":"code","7b88040e":"code","3b2e20f9":"code","c91ae996":"code","631396f7":"code","3f9d4503":"code","9919783c":"code","01c72d96":"code","45db11e9":"code","9fb6ace8":"code","5b3a16a3":"code","4ef3ab35":"code","fc1af3f4":"code","7dd1946c":"code","aa088d4e":"code","43b4bb25":"code","ae99f18f":"code","9c7d42d1":"code","9ad3d064":"code","aa8e1ed1":"code","d6603374":"code","3f92127a":"code","aeb16c05":"code","2c77aec7":"code","c288b81b":"code","be67ab81":"code","8ce35aff":"code","45d89e25":"code","f0a71e3c":"code","2c75f019":"code","41e00420":"code","93cd8435":"code","ee204a2b":"code","261f920d":"code","7ecc57aa":"markdown","61aff2fe":"markdown","e1eac69b":"markdown","b3b61029":"markdown","2fc76bde":"markdown","c5f02e42":"markdown","9132ba6d":"markdown","e00bddbf":"markdown","a100d9af":"markdown","7d25c9a7":"markdown","e99be5e0":"markdown","79b9d421":"markdown","50df3265":"markdown","7e43c1d1":"markdown","4f010966":"markdown","6b05bc13":"markdown","0bb88e1f":"markdown","03ab8c79":"markdown","9a1a6a60":"markdown","68fc1bbc":"markdown","70cbe6c5":"markdown","be98701b":"markdown","8aeefb05":"markdown","3427f60f":"markdown","3fe57ecc":"markdown","a003de8d":"markdown","329164af":"markdown","ceb6c4c3":"markdown","7eb56160":"markdown","874e2130":"markdown","91dad155":"markdown","69ca43a0":"markdown","c029ef94":"markdown","91726111":"markdown","bebeb879":"markdown"},"source":{"c0c99733":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\nimport plotly.express as px\nimport squarify \nfrom textwrap import wrap\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b88040e":"data_ml= pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\neu =['Greece', 'Belgium','Poland', 'Italy','Spain','France', 'Sweden','Netherlands','Romania', 'Austria','Ireland','Portugal', 'Denmark', 'Germany','Czech Republic']\ndata_eu = data_ml[data_ml.Q3.apply(lambda x : x in eu)]\ndata_ml.head(5)","3b2e20f9":"# total countries \ncountries = data_ml.Q3.unique()\n\n# total no. of users\ntotal_participants = len(data_ml)\n\n# Creating a dictiononary of countries with their population % to create a Series\nparticipants = {}\neu_participants = {}\nfor i in countries:\n    total_participants_country = len(data_ml[data_ml.Q3 == i].Q3)\n    if i in eu:\n        eu_participants_country = len(data_ml[data_ml.Q3 == i].Q3)\n        eu_participants[i] = (eu_participants_country)\n    participants[i] = (total_participants_country\/total_participants)* 100\nparticipants.pop('In which country do you currently reside?')\n\n# Creating dataframe of countries with their percentage users\ncountry_participants = pd.Series(participants)\ncountry_participants = pd.DataFrame(country_participants).reset_index().rename(columns = {'index':'Countries', 0:'%'}).sort_values('%', ascending = False)\n# country_participants =country_participants[:50]\n\nfig,axes = plt.subplots(1,1,figsize=(20,5))\nsns.barplot(data = country_participants, x = 'Countries', y = '%', palette ='cividis')\naxes.bar_label(axes.containers[0], fmt='%1.1f',size = 8)\nplt.xticks(rotation=89)\naxes.grid(False)\naxes.tick_params(bottom=True, left=False)\nsns.despine(left = True)\nplt.yticks([])\nplt.show()\n\n","c91ae996":"eu_df = pd.DataFrame(pd.Series(data = eu_participants)).reset_index().rename(columns = {'index': 'Country', 0:'Users'}).sort_values('Users',ascending = False)\ntotal_eu_users = eu_df.Users.sum()\n\neu_users_percentage = (total_eu_users\/ total_participants)*100\nrest_of_world = (total_participants - total_eu_users)\/total_participants*100\n\neu_vs_world_dic = {'Eu':eu_users_percentage ,'World':rest_of_world}\n\neu_vs_world_df = pd.DataFrame(pd.Series(data = eu_vs_world_dic)).reset_index().rename(columns = {'index': 'EU\/World', 0:'% Users'})\n\n# kig = plt.figure(figsize=(18,5))\n# axes = plt.subplot2grid((1,2),(0,0))\n# sns.barplot(data = eu_vs_world_df, x = 'EU\/World', y = '% Users')\n\nkig = plt.figure(figsize=(17,6))\naxes = plt.subplot2grid((1,2),(0,0))\nplt.pie(data = eu_vs_world_df,x = '% Users',pctdistance=0.50,labels = 'EU\/World', autopct='%1.1f%%',colors = ['#cdbe68','#0d2f5d'], labeldistance= 1.1, radius = 0.8,)\ncentre_circle = plt.Circle((0,0),0.7,fc='white') \nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n\n\naxes = plt.subplot2grid((1,2),(0,1))\nsns.barplot(data = eu_df, y = 'Country', x = 'Users', palette = 'cividis')\naxes.bar_label(axes.containers[0],size = 10)\nplt.xticks([])\nsns.despine(bottom = True)\naxes.grid(False)\naxes.tick_params(bottom=False, left=True)\n\nplt.tight_layout()\nplt.show()\n","631396f7":"# for eu\nage_dist = data_eu.groupby(['Q1']).count()['Time from Start to Finish (seconds)']\nage_dist = pd.DataFrame(age_dist).reset_index().rename(columns = {'Q1': 'Age Group', 'Time from Start to Finish (seconds)': \"% Users\"})\nage_dist['% Users']= (age_dist['% Users']\/age_dist['% Users'].sum())*100\n# for World\nage_dist_w = data_ml.groupby(['Q1']).count()['Time from Start to Finish (seconds)']\nage_dist_w = pd.DataFrame(age_dist_w).reset_index().rename(columns = {'Q1': 'Age Group', 'Time from Start to Finish (seconds)': \"% Users\"})\nage_dist_w.drop(labels= 11, inplace = True)\nage_dist_w['% Users'] = (age_dist_w['% Users']\/age_dist_w['% Users'].sum())*100\n\nkig = plt.figure(figsize=(20,5))\naxes = plt.subplot2grid((1,2),(0,0))\nsns.barplot(data = age_dist, x = '% Users', y = 'Age Group', palette='cividis')\nsns.despine(bottom=True)\naxes.grid(False)\naxes.tick_params(bottom=False, left=True)\naxes.bar_label(axes.containers[0], fmt = '%1.1f',size = 10)\nplt.xticks([])\n\naxes = plt.subplot2grid((1,2),(0,1))\nsns.barplot(data = age_dist_w, x = '% Users', y = 'Age Group',  palette='rainbow')\nsns.despine(bottom=True)\naxes.grid(False)\naxes.tick_params(bottom=False, left=True)\naxes.bar_label(axes.containers[0],size = 10,fmt = '%1.1f')\nplt.xticks([])\n\nplt.suptitle('Age Distribution: left:- EU, right:- The World')\nplt.show()\n","3f9d4503":"# for eu\nman = len(data_eu[data_eu.Q2 == 'Man'])\nprefer_not_to_say = len(data_eu[data_eu.Q2 == 'Prefer not to say'])\nwoman = len(data_eu[data_eu.Q2 == 'Woman'])\nnonbinary = len(data_eu[data_eu.Q2 == 'Nonbinary'])\nprefer_to_self_describe = len(data_eu[data_eu.Q2 == 'Prefer to self-describe'])\nothers = prefer_not_to_say + prefer_to_self_describe + nonbinary\ngender_dis ={'Man': man,'Others': others,'Woman': woman}\n\n# for world\nman_w = len(data_ml[data_ml.Q2 == 'Man'])\nprefer_not_to_say_w = len(data_ml[data_ml.Q2 == 'Prefer not to say'])\nwoman_w = len(data_ml[data_ml.Q2 == 'Woman'])\nnonbinary_w = len(data_ml[data_ml.Q2 == 'Nonbinary'])\nprefer_to_self_describe_w = len(data_ml[data_ml.Q2 == 'Prefer to self-describe'])\nothers_w = prefer_not_to_say_w + prefer_to_self_describe_w + nonbinary_w\ngender_dis_w ={'Man': man_w,'Others': others_w,'Woman': woman_w}\n\na = pd.DataFrame(pd.Series(gender_dis)).reset_index().rename(columns={'index':'Gender', 0: 'Participants'})\nb = pd.DataFrame(pd.Series(gender_dis_w)).reset_index().rename(columns={'index':'Gender', 0: 'Participants'})\n\nkig = plt.figure(figsize=(20,5))\naxes = plt.subplot2grid((1,2),(0,0))\nplt.pie( data = a,x = 'Participants', startangle=90,pctdistance=0.70,labels = 'Gender', autopct='%1.1f%%',colors = ['#0e3362','#c4b66e','#6b6c70'], labeldistance= 1.1, radius = 0.8,)\ncentre_circle = plt.Circle((0,0),0.7,fc='white') \nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\naxes = plt.subplot2grid((1,2),(0,1))\nplt.pie( data = b,x = 'Participants', startangle = 90,pctdistance=0.70,labels = 'Gender', autopct='%1.1f%%',colors = ['#69e2c1','#e78759','#6859e5'], labeldistance= 1.1, radius = 0.8,)\ncentre_circle = plt.Circle((0,0),0.7,fc='white') \nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nplt.suptitle('Gender Distribution: right:- EU, left:- The World')\nplt.tight_layout()\nplt.show()\n\n","9919783c":"new_df = data_ml[['Q6','Q25']].drop(0).dropna()\nyears_arr = new_df.Q6.unique()\n\nQ_dict = {'25,000-29,999':[], '60,000-69,999':[], '$0-999':[], '30,000-39,999':[],\n       '15,000-19,999':[], '70,000-79,999':[], '2,000-2,999':[], '10,000-14,999':[],\n       '5,000-7,499':[], '20,000-24,999':[], '1,000-1,999':[], '100,000-124,999':[],\n       '7,500-9,999':[], '4,000-4,999':[], '40,000-49,999':[], '50,000-59,999':[],\n       '3,000-3,999':[], '300,000-499,999':[], '200,000-249,999':[],\n       '125,000-149,999':[], '250,000-299,999':[], '80,000-89,999':[],\n       '90,000-99,999':[], '150,000-199,999':[], '>$1,000,000':[],\n       '$500,000-999,999':[]}\nL_dict = {'25,000-29,999':[], '60,000-69,999':[], '$0-999':[], '30,000-39,999':[],\n       '15,000-19,999':[], '70,000-79,999':[], '2,000-2,999':[], '10,000-14,999':[],\n       '5,000-7,499':[], '20,000-24,999':[], '1,000-1,999':[], '100,000-124,999':[],\n       '7,500-9,999':[], '4,000-4,999':[], '40,000-49,999':[], '50,000-59,999':[],\n       '3,000-3,999':[], '300,000-499,999':[], '200,000-249,999':[],\n       '125,000-149,999':[], '250,000-299,999':[], '80,000-89,999':[],\n       '90,000-99,999':[], '150,000-199,999':[], '>$1,000,000':[],\n       }\n\nfor i in years_arr:\n    salary_count_df = pd.DataFrame(new_df[new_df.Q6 == i].drop('Q6', axis =1).value_counts())\n    if i != 'I have never written code':\n        for key in Q_dict:\n            Q_dict[key].append(salary_count_df.loc[key][0].sum())\n    else:   \n        for key in L_dict:\n            Q_dict[key].append(salary_count_df.loc[key][0].sum())\n\nQ_dict['$500,000-999,999'].append(0)   ","01c72d96":"def df_creater(eu_world,replacing, column_name):\n    if replacing == 'Q9':\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8','Q9_Part_9','Q9_Part_10','Q9_Part_11','Q9_Part_12','Q9_OTHER']\n    elif replacing =='Q10':\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8','Q9_Part_9','Q9_Part_10','Q9_Part_11','Q9_Part_12','Q9_Part_13','Q9_Part_14','Q9_Part_15','Q9_Part_16','Q9_OTHER']\n    elif replacing =='Q16':\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8','Q9_Part_9','Q9_Part_10','Q9_Part_11','Q9_Part_12','Q9_Part_13','Q9_Part_14','Q9_Part_15','Q9_Part_16','Q9_Part_17','Q9_OTHER']\n    elif replacing =='Q32_A':\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8','Q9_Part_9','Q9_Part_10','Q9_Part_11','Q9_Part_12','Q9_Part_13','Q9_Part_14','Q9_Part_15','Q9_Part_16','Q9_Part_17','Q9_Part_18','Q9_Part_19','Q9_Part_20','Q9_OTHER']\n    elif replacing == 'Q18':\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_OTHER']\n    elif replacing == 'Q19':\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_OTHER']\n    elif replacing == 'Q24' or replacing == 'Q37_A' or replacing == 'Q30_A':\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_OTHER']\n    else:\n        Q9 = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8','Q9_Part_9','Q9_Part_10','Q9_Part_11','Q9_OTHER']\n    Q_dict = {}\n    for i in Q9:\n        i = i.replace('Q9',replacing)\n        if str(eu_world) == str(data_ml):\n            Q_dict[eu_world.drop(0)[i].dropna().unique()[0]] = len(eu_world.drop(0)[i].dropna())\n        else:\n            Q_dict[eu_world[i].dropna().unique()[0]] = len(eu_world[i].dropna())\n        dataframe_name = pd.DataFrame(Q_dict, index = [0]).T.reset_index().rename(columns = {'index': column_name, 0:'% Users'})\n        \n    return dataframe_name     ","45db11e9":"#world Level\neducation_level_w = data_ml.groupby(['Q4']).count()['Time from Start to Finish (seconds)']\neducation_level_w = pd.DataFrame(education_level_w).reset_index().rename(columns = {'Q4': 'Education Level', 'Time from Start to Finish (seconds)': 'Count'}).drop(labels = 7).sort_values('Count', ascending =False)\neducation_level_w.Count = (education_level_w.Count\/education_level_w.Count.sum())*100\n\n# EU\neducation_level = data_eu.groupby(['Q4']).count()['Time from Start to Finish (seconds)']\neducation_level = pd.DataFrame(education_level).reset_index().rename(columns = {'Q4': 'Education Level', 'Time from Start to Finish (seconds)': 'Count'})\neducation_level.Count = (education_level.Count\/education_level.Count.sum())*100\n\n\n\nfig, ax = plt.subplots(figsize=(15,5))\n\nx = np.arange(len(education_level))\nwidth = 0.4\nplt.barh(x-0.2, education_level.reindex([3,0,1,6,2,4,5]).Count, width, color='#0e3362', label='EU') \n\nplt.barh(x+0.2, education_level_w.Count, width, color='#69e2c1', label='World')\n\n\nplt.ylabel(None)\nplt.yticks(education_level.index, labels =  ['Master\u2019s degree', 'Bachelor\u2019s degree', 'Doctoral degree','Some college\/university study','I prefer not to answer', 'No formal education past high school','Professional doctorate'])\n\nplt.xlabel('Percentage', fontsize=10)\nplt.yticks(fontsize=9)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=True)\n\nplt.suptitle('Formal Education')\nplt.legend(frameon=False, fontsize=15)\nplt.show()\n\n","9fb6ace8":"Social_w_df = df_creater(data_ml,'Q42', 'Social Media').sort_values('% Users')\nSocial_w_df['% Users'] = (Social_w_df['% Users']\/Social_w_df['% Users'].sum())*100\nSocial_w_df['Names'] = ['Other', 'None', 'Slack', 'Podcasts', 'Reddit', 'Course Forums', 'Journal Publications', 'Newsletters', 'Twitter', 'Blogs','YouTube', 'Kaggle']\n\n\nSocial_df = df_creater(data_eu,'Q42', 'Social Media').sort_values('% Users')\nSocial_df['% Users'] = (Social_df['% Users']\/Social_df['% Users'].sum())*100\nSocial_df['Names'] = ['Other', 'None', 'Slack', 'Course Forums','Podcasts', 'Reddit', 'Twitter','Newsletters','Journal Publications', 'YouTube',  'Blogs', 'Kaggle']\n\n\nlabels = Social_w_df['Names']\nsizes = Social_w_df['% Users'].values.tolist()\ncolors = [plt.cm.viridis(i\/float(len(labels))) for i in range(len(labels))]\n\nplt.figure(figsize=(18,6), dpi= 80)\naxes = plt.subplot2grid((1,2),(0,1))\nsquarify.plot(sizes=sizes, label=labels, alpha=.8, color = colors)\nplt.axis('off')\n\n\nlabels = Social_df['Names']\nsizes = Social_df['% Users'].values.tolist()\naxes = plt.subplot2grid((1,2),(0,0))\ncolors = [plt.cm.cividis(i\/float(len(labels))) for i in range(len(labels))]\nsquarify.plot(sizes=sizes, label=labels, alpha=.8, color = colors)\n\n\n# Decorate\nplt.suptitle('Popular Social Media')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n","5b3a16a3":"plat_ds_course_w_df = df_creater(data_ml,'Q40', 'Platform for DS Courses').sort_values('% Users', ascending = False)\nplat_ds_course_w_df['% Users'] = (plat_ds_course_w_df['% Users']\/plat_ds_course_w_df['% Users'].sum())*100 \n\nplat_ds_course_w_df['Platform for DS Courses'].replace(['University Courses (resulting in a university degree)','Cloud-certification programs (direct from AWS, Azure, GCP, or similar)'],['University', 'Cloud-Certificate'], inplace = True)\n\nlabels = plat_ds_course_w_df['Platform for DS Courses']\nsizes = plat_ds_course_w_df['% Users'].values.tolist()\ncolors = [plt.cm.cividis(i\/float(len(labels))) for i in range(len(labels))]\n\nplt.figure(figsize=(20,6))\nsquarify.plot(sizes=sizes, label=labels, alpha=.8, color = colors)\nplt.axis('off')\n\n# Decorate\nplt.suptitle('Popular Platform for DS Courses')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n","4ef3ab35":"programming_w_df = df_creater(data_ml,'Q7', 'Language').sort_values('% Users', ascending = False)\nprogramming_w_df['% Users'] = (programming_w_df['% Users']\/programming_w_df['% Users'].sum())*100\n# programming_w_df\n\nprogramming_df = df_creater(data_eu,'Q7', 'Language').sort_values('% Users')\nprogramming_df['% Users'] = (programming_df['% Users']\/programming_df['% Users'].sum())*100\n\n\nfig, ax = plt.subplots(figsize=(18,6))\n\nx = np.arange(len(programming_w_df))\nwidth = 0.4\nplt.barh(x-0.2, programming_df['% Users'].reindex([0,2,4,1,5,3,6,10,11,9,7,8]), width, color='#0e3362', label='EU') \nplt.barh(x+0.2, programming_w_df['% Users'], width, color='#69e2c1', label='World')\n\n# plt.title('TOP5 countries by pure alcohol consumption', fontsize=25)\nplt.ylabel(None)\nplt.yticks(programming_w_df.index, labels = programming_w_df.Language)\n\nplt.xlabel('Percentage', fontsize=7)\nplt.yticks(fontsize=10)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=True)\nplt.suptitle('Preffered Programming Language')\nplt.legend(frameon=False, fontsize=15)\nplt.show()\n","fc1af3f4":"recomm_language_w = pd.DataFrame(data_ml.Q8.drop(0).dropna().value_counts()).reset_index().rename(columns = {'index':'Recommended Language', 'Q8': 'Count'})\nrecomm_language_w.Count =(recomm_language_w.Count\/recomm_language_w.Count.sum())*100\n\nrecomm_language= pd.DataFrame(data_eu.Q8.dropna().value_counts()).reset_index().rename(columns = {'index':'Recommended Language', 'Q8': 'Count'})\nrecomm_language.Count =(recomm_language.Count\/recomm_language.Count.sum())*100\n\nfig, ax = plt.subplots(figsize=(18,6))\nx = np.arange(len(recomm_language))\nwidth = 0.4\nplt.barh(x-0.2, recomm_language['Count'], width, color='#0e3362', label='EU') \nplt.barh(x+0.2, recomm_language_w['Count'], width, color='#69e2c1', label='World')\n\nplt.ylabel(None)\nplt.yticks(recomm_language_w.index, labels = recomm_language_w['Recommended Language'])\n\nplt.xlabel('Percentage', fontsize=7)\nplt.yticks(fontsize=10)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=True)\n\nplt.suptitle('Recommended Programming Language')\nplt.legend(frameon=False, fontsize=15)\nplt.show()\n","7dd1946c":"# for world\njob_w = data_ml.groupby(['Q5']).count()['Time from Start to Finish (seconds)']\njob_w = pd.DataFrame(job_w).reset_index().rename(columns = {'Q5': 'Current Job', 'Time from Start to Finish (seconds)': '% Users'}).drop(labels = 12)\ntotal_sum_w = job_w['% Users'].sum()\njob_w['% Users'] = (job_w['% Users']\/ total_sum_w)*100\n# for Eu\njob = data_eu.groupby(['Q5']).count()['Time from Start to Finish (seconds)']\njob = pd.DataFrame(job).reset_index().rename(columns = {'Q5': 'Current Job', 'Time from Start to Finish (seconds)': '% Users'})\ntotal_sum = job['% Users'].sum()\njob['% Users'] = (job['% Users'] \/ total_sum)*100\n\n\nfig, ax = plt.subplots(figsize=(18,7))\n\n\nsns.scatterplot(alpha = 0.8, data = job, x = '% Users', y = 'Current Job',sizes=(1000, 1001),size = \"% Users\", legend=False, color = '#0e3362')\n\n  \nsns.scatterplot(data = job_w, x = '% Users', y = 'Current Job',sizes=(1000, 1001), size = \"% Users\",legend=False, color = '#69e2c1')\n\nax.tick_params(bottom=False, left=True)\n\nplt.suptitle(\"Job's Title\")\nplt.tight_layout()\nplt.show()","aa088d4e":"industry_w_df = pd.DataFrame(data_ml['Q20'].value_counts()).reset_index().drop(18).rename(columns = {'index':'Industry','Q20': 'Users'})\nindustry_w_df.Users = (industry_w_df.Users\/industry_w_df.Users.sum())*100\n\nindustry_df = pd.DataFrame(data_eu['Q20'].value_counts()).reset_index().rename(columns = {'index':'Industry','Q20': 'Users'})\nindustry_df.Users = (industry_df.Users\/industry_df.Users.sum())*100\n\nlabels = industry_df['Industry']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nfig, ax = plt.subplots(figsize=(15,7))\n\nax.barh(labels, industry_df['Users'], width, label='EU', color='#0e3362')\nax.barh(labels, industry_w_df['Users'], width,  color='#69e2c1',left=industry_df['Users'],label='World')\n\n\nplt.yticks(fontsize=8)\nax.set_xlabel('% Users')\nax.grid(False)\nsns.despine(bottom=True)\n# ax.set_title('Scores by group and gender')\nax.tick_params(bottom=False, left=True)\n\nax.legend()\nplt.show()\n","43b4bb25":"ml_business_w_df = pd.DataFrame(data_ml['Q23'].value_counts()).reset_index().drop(6).rename(columns = {'index':'Ml incorporation in Business','Q23': 'Users'})\nml_business_w_df.Users = (ml_business_w_df.Users\/ml_business_w_df.Users.sum())*100\n\n\nml_business_df = pd.DataFrame(data_eu['Q23'].value_counts()).reset_index().rename(columns = {'index':'Ml incorporation in Business','Q23': 'Users'})\nml_business_df.Users = (ml_business_df.Users\/ml_business_df.Users.sum())*100\n\nml_business_df['Ml incorporation in Business'] = ['\\n'.join(wrap(x, 45)) for x in  ml_business_df['Ml incorporation in Business']]\n\nlabels = ml_business_df['Ml incorporation in Business']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nfig, ax = plt.subplots(figsize=(13,5))\n\nax.barh(labels, ml_business_df['Users'], width, label='EU', color='#0e3362')\n# labels = ml_business_w_df['Ml incorporation in Business']\nax.barh(labels, ml_business_w_df['Users'], width,  color='#69e2c1',left=ml_business_df['Users'],label='World')\n\nplt.yticks(fontsize=8)\nax.set_xlabel('Users')\nax.grid(False)\nsns.despine(bottom=True)\n# ax.set_title('Scores by group and gender')\nax.tick_params(bottom=False, left=True)\nax.legend()\nplt.show()\n","ae99f18f":"role_w_df = df_creater(data_ml, 'Q24', 'Role').sort_values('% Users', ascending = False)\nrole_w_df['% Users'] = (role_w_df['% Users']\/role_w_df['% Users'].sum())*100\nrole_w_df['Role'] = ['\\n'.join(wrap(x, 35)) for x in  role_w_df['Role']]\n\nfig, ax = plt.subplots(figsize=(15,6))\n\nax.hlines(role_w_df['Role'], xmin=0, xmax = role_w_df['% Users']-0.40, colors = '#0e3362')\nsns.scatterplot( data = role_w_df, x = '% Users', y = 'Role',sizes=(650, 651),size = \"% Users\", legend=False, color= '#04a664', alpha = 0.5)\n\n# for j in range(len(hosted_nb_w_df)):\n#     plt.annotate( \"{hosted_nb_w_df['% Users'][j]: .0%}\".format(hosted_nb_w_df['% Users'][j]), (hosted_nb_w_df['% Users'][j], hosted_nb_w_df['Hosted Notebook'][j]),weight = 'bold', color = '#5b5eec')\n\nfor j in range(len(role_w_df)):\n    plt.annotate( f'{role_w_df[\"% Users\"][j]:1.0f}', (role_w_df['% Users'][j]-0.3, role_w_df['Role'][j]),weight = 'bold', color = 'white')\n\nplt.xticks([]) \nax.set_xlim(0,30)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=False)\nplt.suptitle('Role at Work')\nplt.tight_layout()\nplt.show()\n","9c7d42d1":"salary_year_df = pd.DataFrame(data = Q_dict,index =years_arr ,columns = ['25,000-29,999', '60,000-69,999', '$0-999', '30,000-39,999',\n       '15,000-19,999', '70,000-79,999', '2,000-2,999', '10,000-14,999',\n       '5,000-7,499', '20,000-24,999', '1,000-1,999', '100,000-124,999',\n       '7,500-9,999', '4,000-4,999', '40,000-49,999', '50,000-59,999',\n       '3,000-3,999', '300,000-499,999', '200,000-249,999',\n       '125,000-149,999', '250,000-299,999', '80,000-89,999',\n       '90,000-99,999', '150,000-199,999', '>$1,000,000',\n       '$500,000-999,999'])      \nsalary_year_df = salary_year_df.reindex(['I have never written code','< 1 years','1-3 years','3-5 years','5-10 years','10-20 years','20+ years'])\nsalary_year_df = salary_year_df.reindex(columns = ['$0-999','1,000-1,999','2,000-2,999','3,000-3,999','4,000-4,999','5,000-7,499', '7,500-9,999','10,000-14,999','15,000-19,999','20,000-24,999','25,000-29,999','30,000-39,999','40,000-49,999','50,000-59,999','60,000-69,999','70,000-79,999','80,000-89,999','90,000-99,999','100,000-124,999','125,000-149,999','150,000-199,999','200,000-249,999','250,000-299,999','300,000-499,999','$500,000-999,999','>$1,000,000'])","9ad3d064":"fig, ax = plt.subplots(figsize=(18,6))\nsns.heatmap(data = salary_year_df,cmap = 'viridis', linecolor='white', linewidths=2, annot = True, fmt = 'd')\nplt.suptitle('Relation between Coding experience and Compensastion ')\nplt.show()","aa8e1ed1":"company_ds_w_df = data_ml[['Q21','Q22']].drop(0).dropna()\ncompany_arr = company_ds_w_df.Q21.unique()\n\nQ_dict = {'3-4':[], '1-2':[], '0':[], '5-9':[], '10-14':[],'20+':[], '15-19':[]}\n\nfor i in company_arr:\n    company_ds_count_df = pd.DataFrame(company_ds_w_df[company_ds_w_df.Q21 == i].drop('Q21', axis =1).value_counts())\n    for key in Q_dict:\n        Q_dict[key].append(company_ds_count_df.loc[key][0].sum())\n\nnew_company_ds_df = pd.DataFrame(data = Q_dict,index =company_arr ,columns = ['3-4', '1-2', '0', '5-9', '10-14','20+', '15-19'])      \nnew_company_ds_df = new_company_ds_df.reindex([ '0-49 employees','50-249 employees', '250-999 employees', '1000-9,999 employees','10,000 or more employees'])\nnew_company_ds_df = new_company_ds_df.reindex(columns = ['0','1-2','3-4', '5-9', '10-14', '15-19','20+'])\n\nfig, ax = plt.subplots(figsize=(13,6))\nsns.heatmap(data = new_company_ds_df, linecolor='white', linewidths=2, annot  =True, fmt = 'd',cmap = 'viridis')\nplt.show()","d6603374":"# For World\nvisualization_w_df = df_creater(data_ml,'Q14', 'Visualization Tool')\nvisualization_w_df['% Users'] = (visualization_w_df['% Users']\/visualization_w_df['% Users'].sum())*100\n\n# For Eu\nvisualization_df = df_creater(data_eu,'Q14', 'Visualization Tool')\nvisualization_df['% Users'] = (visualization_df['% Users']\/visualization_df['% Users'].sum())*100\n\nlabels = visualization_df['Visualization Tool']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nfig, ax = plt.subplots(figsize=(13,6))\n\nax.barh(labels, visualization_df['% Users'], width, label='EU', color='#0e3362')\nax.barh(labels, visualization_w_df['% Users'], width,  color='#69e2c1',left=visualization_df['% Users'],\n       label='World')\n# plt.xticks(rotation = 90)\nax.set_xlabel('% Users')\nax.grid(False)\nsns.despine(bottom=True)\n# ax.set_title('Scores by group and gender')\nax.tick_params(bottom=False, left=True)\nax.legend()\nplt.show()\n\n","3f92127a":"hosted_nb_w_df = df_creater(data_ml, \"Q10\", 'Hosted Notebook').sort_values('% Users',ascending = False)\nhosted_nb_w_df['% Users'] =( hosted_nb_w_df['% Users']\/hosted_nb_w_df['% Users'].sum())* 100","aeb16c05":"fig, ax = plt.subplots(figsize=(15,7))\n\nax.hlines(hosted_nb_w_df['Hosted Notebook'], xmin=0, xmax = hosted_nb_w_df['% Users']-0.45, colors = '#0e3362')\nsns.scatterplot( data = hosted_nb_w_df, x = '% Users', y = 'Hosted Notebook',sizes=(650, 651),size = \"% Users\", legend=False, color= '#04a664', alpha = 0.5)\n\n# for j in range(len(hosted_nb_w_df)):\n#     plt.annotate( \"{hosted_nb_w_df['% Users'][j]: .0%}\".format(hosted_nb_w_df['% Users'][j]), (hosted_nb_w_df['% Users'][j], hosted_nb_w_df['Hosted Notebook'][j]),weight = 'bold', color = '#5b5eec')\n\nfor j in range(len(hosted_nb_w_df)):\n    plt.annotate( f'{hosted_nb_w_df[\"% Users\"][j]:.1f}', (hosted_nb_w_df['% Users'][j]-0.4, hosted_nb_w_df['Hosted Notebook'][j]),weight = 'bold', color = 'white')\n\nplt.xticks([]) \nax.set_xlim(0,30)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=False)\nplt.tight_layout()\nplt.show()\n","2c77aec7":"computing_plat_w_df = pd.DataFrame(data_ml['Q11'].value_counts()).reset_index().drop(6).rename(columns = {'index':'Computing Platform','Q11': 'Users'})\ncomputing_plat_w_df.Users  = (computing_plat_w_df.Users \/computing_plat_w_df.Users .sum())*100\nsum_4_5 = computing_plat_w_df.Users[4]+computing_plat_w_df.Users[5]\ndf2 = pd.DataFrame([['None\/Other', sum_4_5 ]], columns=['Computing Platform', 'Users'], index=[4])\ncomputing_plat_w_df = computing_plat_w_df.drop([4,5]).append(df2)\ncomputing_plat_w_df['Computing Platform'] = ['\\n'.join(wrap(x, 30)) for x in  computing_plat_w_df['Computing Platform']]\n\ncomputing_plat_df = pd.DataFrame(data_eu['Q11'].value_counts()).reset_index().rename(columns = {'index':'Computing Platform','Q11': 'Users'})\ncomputing_plat_df.Users  = (computing_plat_df.Users \/computing_plat_df.Users .sum())*100\nsum_4_5 = computing_plat_df.Users[4]+computing_plat_df.Users[5]\ndf2 = pd.DataFrame([['None\/Other', sum_4_5 ]], columns=['Computing Platform', 'Users'], index=[4])\ncomputing_plat_df = computing_plat_df.drop([4,5]).append(df2)\ncomputing_plat_df['Computing Platform'] = ['\\n'.join(wrap(x, 30)) for x in  computing_plat_df['Computing Platform']]\n\ncolor_list = ['#0e3362','#55658a','#979693','#c9be89','#eddb71']\n\nkig = plt.figure(figsize=(15,5.5))\naxes = plt.subplot2grid((1,2),(0,0))\nplt.pie( data = computing_plat_df,x = 'Users', startangle=30,pctdistance=0.65,labels = 'Computing Platform', autopct='%1.1f%%',colors = color_list, labeldistance= 1.1, radius = 0.8,)\ncentre_circle = plt.Circle((0,0),0.7,fc='white') \nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\naxes = plt.subplot2grid((1,2),(0,1))\nplt.pie( data = computing_plat_w_df,x = 'Users', startangle = 30,pctdistance=0.65,labels = 'Computing Platform', autopct='%1.1f%%',colors = ['#693476','#6275a2','#4da7a3','#7ed381','#d3e64d'], labeldistance= 1.1, radius = 0.8,)\ncentre_circle = plt.Circle((0,0),0.7,fc='white') \nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nplt.suptitle('Computing Platforms: left:- EU, right:- World')\nplt.tight_layout()\nplt.show()\n\n","c288b81b":"big_data_w_df = df_creater(data_ml, \"Q32_A\", 'Big Data Products')\nbig_data_w_df['% Users'] = (big_data_w_df['% Users']\/big_data_w_df['% Users'].sum())*100\n\nbig_data_df = df_creater(data_eu, \"Q32_A\", 'Big Data Products')\nbig_data_df['% Users'] = (big_data_df['% Users']\/big_data_df['% Users'].sum())*100\n\nlabels = big_data_w_df['Big Data Products']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nfig, ax = plt.subplots(figsize=(15,7))\n\nax.barh(labels,big_data_df['% Users'], width, label='EU', color='#0e3362')\nax.barh(labels, big_data_w_df['% Users'], width,  color='#4da7a3',left=big_data_df['% Users'],label='World')\n\nplt.yticks(fontsize=8)\nax.set_xlabel('% Users')\nax.grid(False)\nsns.despine(bottom=True)\n# ax.set_title('Scores by group and gender')\nax.tick_params(bottom=False, left=True)\nax.legend()\nplt.suptitle('Big Data Products')\nplt.show()\n","be67ab81":"business_intelligence_w_df = pd.DataFrame(data_ml['Q35'].value_counts()).reset_index().drop([15,16]).rename(columns = {'index':'Business Intelligence','Q35': 'Users'})\nbusiness_intelligence_w_df.Users = (business_intelligence_w_df.Users\/business_intelligence_w_df.Users.sum())*100\n\nbusiness_intelligence_df = pd.DataFrame(data_eu['Q35'].value_counts()).reset_index().rename(columns = {'index':'Business Intelligence','Q35': 'Users'})\nbusiness_intelligence_df.Users = (business_intelligence_df.Users\/business_intelligence_df.Users.sum())*100\n\nlabels = business_intelligence_df['Business Intelligence']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nfig, ax = plt.subplots(figsize=(15,7))\n\nax.barh(labels,business_intelligence_df['Users'], width, label='EU', color='#0e3362')\nax.barh(labels, business_intelligence_w_df['Users'], width,  color='#4da7a3',left=business_intelligence_df['Users'],label='World')\n\nplt.yticks(fontsize=8)\nax.set_xlabel('Users')\nax.grid(False)\nsns.despine(bottom=True)\n# ax.set_title('Scores by group and gender')\nax.tick_params(bottom=False, left=True)\nax.legend()\nplt.show()\n","8ce35aff":"ml_method_w_df = pd.DataFrame(data_ml['Q15'].value_counts()).reset_index().drop(9).rename(columns = {'index':'ML Method','Q15': 'Users'})\nml_method_w_df.Users = (ml_method_w_df.Users \/ ml_method_w_df.Users.sum())*100\nml_method_w_df['ML Method'].replace('I do not use machine learning methods', 'No Method',inplace =True)\n\n\nml_method_df = pd.DataFrame(data_eu['Q15'].value_counts()).reset_index().rename(columns = {'index':'ML Method','Q15': 'Users'})\nml_method_df.Users = (ml_method_df.Users \/ ml_method_df.Users.sum())*100\nml_method_df['ML Method'].replace('I do not use machine learning methods', 'No Method',inplace =True)\n\nlabels = ml_method_df['ML Method']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nfig, ax = plt.subplots(figsize=(15,6))\n\nax.barh(labels, ml_method_df['Users'], width, label='EU', color='#0e3362')\nax.barh(labels, ml_method_w_df['Users'], width,  color='#4da7a3',left=ml_method_df['Users'],\n       label='World')\n# plt.xticks(rotation = 90)\nax.set_xlabel('Users')\nax.grid(False)\nsns.despine(bottom=True)\n# ax.set_title('Scores by group and gender')\nax.tick_params(bottom=False, left=True)\n\nplt.suptitle('ML Method Experience')\nax.legend()\nplt.show()\n","45d89e25":"ml_framework_w_df  = df_creater(data_ml,'Q16', 'ML Framework').sort_values('% Users', ascending = False)\nml_framework_w_df['% Users'] = (ml_framework_w_df['% Users']\/ml_framework_w_df['% Users'].sum())*100 \n\nlabels = ml_framework_w_df['ML Framework']\nsizes = ml_framework_w_df['% Users'] .values.tolist()\ncolors = [plt.cm.viridis(i\/float(len(labels))) for i in range(len(labels))]\n\nplt.figure(figsize=(15,6))\nsquarify.plot(sizes=sizes, label=labels, alpha=.8, color = colors)\nplt.axis('off')\n\n# Decorate\nplt.suptitle('Popular ML Framework')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n","f0a71e3c":"\nml_algo_w_df = df_creater(data_ml,'Q17', 'ML Algorithm').sort_values('% Users')\nml_algo_w_df['% Users'] = (ml_algo_w_df['% Users']\/ml_algo_w_df['% Users'].sum())*100\nml_algo_df = df_creater(data_eu,'Q17', 'ML Algorithm').sort_values('% Users')\nml_algo_df['% Users'] = (ml_algo_df['% Users']\/ml_algo_df['% Users'].sum())*100\nml_algo_df['ML Algorithm'] = ['\\n'.join(wrap(x, 7)) for x in  ml_algo_df['ML Algorithm']]\n\n# cv\ncv_method_w_df = df_creater(data_ml,'Q18', 'CV Method').sort_values('% Users')\ncv_method_w_df['% Users'] = (cv_method_w_df['% Users']\/cv_method_w_df['% Users'].sum())*100\ncv_method_df = df_creater(data_eu,'Q18', 'CV Method').sort_values('% Users')\ncv_method_df['% Users'] = (cv_method_df['% Users']\/cv_method_df['% Users'].sum())*100\ncv_method_w_df['CV Method'].replace(['Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)'],['VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc'], inplace = True)\ncv_method_w_df['CV Method'] = ['\\n'.join(wrap(x, 12)) for x in  cv_method_w_df['CV Method']]\n\n# nlp\nnlp_method_w_df = df_creater(data_ml,'Q19', 'NLP Method').sort_values('% Users')\nnlp_method_w_df['% Users'] = (nlp_method_w_df['% Users']\/nlp_method_w_df['% Users'].sum())*100\nnlp_method_df = df_creater(data_eu,'Q19', 'NLP Method').sort_values('% Users')\nnlp_method_df['% Users'] = (nlp_method_df['% Users']\/nlp_method_df['% Users'].sum())*100\nnlp_method_w_df['NLP Method'] = ['\\n'.join(wrap(x, 12)) for x in nlp_method_w_df['NLP Method']]\n\n\nlabels = ml_algo_df['ML Algorithm']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nkig = plt.figure(figsize=(20,8))\n\na = '#0e3362'\nb = '#4da7a3'\n\naxes = plt.subplot2grid((1,3),(0,0))\naxes.bar(labels, ml_algo_df['% Users'] , width, label='EU', color=a)\naxes.bar(labels, ml_algo_w_df['% Users'] , width,  color=b,bottom=ml_algo_df['% Users'],label='World')\naxes.set_ylabel('% Users')\naxes.grid(False)\naxes.tick_params(bottom=True, left=False)\naxes.legend()\nplt.title('ML Methods')\nplt.xticks(fontsize=8)\n\naxes = plt.subplot2grid((1,3),(0,1))\nlabels = cv_method_w_df['CV Method']\naxes.bar(labels, cv_method_df['% Users'] , width, label='EU', color=a)\naxes.bar(labels, cv_method_w_df['% Users'] , width,  color=b,bottom=cv_method_df['% Users'],label='World')\naxes.set_ylabel('% Users')\naxes.grid(False)\naxes.tick_params(bottom=True, left=False)\naxes.legend()\nplt.title('CV Methods')\nplt.xticks(fontsize=8)\n\naxes = plt.subplot2grid((1,3),(0,2))\nlabels = nlp_method_w_df['NLP Method']\naxes.bar(labels, nlp_method_df['% Users'] , width, label='EU', color=a)\naxes.bar(labels,nlp_method_w_df['% Users'] , width,  color=b,bottom=nlp_method_df['% Users'],label='World')\naxes.set_ylabel('% Users')\naxes.grid(False)\naxes.tick_params(bottom=True, left=False)\naxes.legend()\nplt.title('NLP Methods')\nplt.xticks(fontsize=8)\n\nsns.despine(left=True)\nplt.tight_layout()\nplt.show()\n","2c75f019":"#37-A -7\nauto_ml_w_df = df_creater(data_ml, \"Q37_A\", 'Automated ML Tools').sort_values('% Users')\nauto_ml_w_df['% Users'] = (auto_ml_w_df['% Users']\/auto_ml_w_df['% Users'].sum())*100\n\nauto_ml_df = df_creater(data_eu, \"Q37_A\", 'Automated ML Tools').sort_values('% Users')\nauto_ml_df['% Users'] = (auto_ml_df['% Users']\/auto_ml_df['% Users'].sum())*100\n\nauto_ml_w_df['Automated ML Tools'] = ['\\n'.join(wrap(x, 15)) for x in  auto_ml_w_df['Automated ML Tools']]\nauto_ml_df['Automated ML Tools'] = ['\\n'.join(wrap(x, 15)) for x in  auto_ml_df['Automated ML Tools']]\n\n\ncolor_list = ['#55658a','#797d8a','#979693','#b7b090','#c9be89','#dbcc80','#eddb71','#334e71']\ncolors = ['#693476','#69619c','#6275a2','#5a86a4','#4da7a3','#7ed381','#a6df69','#d3e64d']\n\nkig = plt.figure(figsize=(20,5.5))\naxes = plt.subplot2grid((1,2),(0,0))\nplt.pie( data = auto_ml_df,x = '% Users', startangle=90,pctdistance=0.65,labels = 'Automated ML Tools', autopct='%1.1f%%',colors = color_list, labeldistance= 1.1, radius = 0.8,)\ncentre_circle = plt.Circle((0,0),0.7,fc='white') \nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\naxes = plt.subplot2grid((1,2),(0,1))\nplt.pie( data = auto_ml_w_df,x = '% Users', startangle = 90,pctdistance=0.65,labels = 'Automated ML Tools', autopct='%1.1f%%',colors = colors, labeldistance= 1.1, radius = 0.8,)\ncentre_circle = plt.Circle((0,0),0.7,fc='white') \nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nplt.suptitle('Auto ML Tools: left- EU, right- World')\nplt.tight_layout()\nplt.show()\n\n\n","41e00420":"tools_w_df = df_creater(data_ml, 'Q38_A', 'Tools')\ntools_w_df['% Users'] = (tools_w_df['% Users']\/tools_w_df['% Users'].sum())*100\n\ntools_df = df_creater(data_eu, 'Q38_A', 'Tools')\ntools_df['% Users'] = (tools_df['% Users']\/tools_df['% Users'].sum())*100\n\nlabels = tools_df['Tools']\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\nfig, ax = plt.subplots(figsize=(15,6))\n\nax.barh(labels,tools_df['% Users'], width, label='EU', color='#0e3362')\nax.barh(labels, tools_w_df['% Users'], width,  color='#4da7a3',left=tools_df['% Users'],label='World')\n\nplt.yticks(fontsize=8)\nax.set_xlabel('% Users')\nax.grid(False)\nsns.despine(bottom=True)\n# ax.set_title('Scores by group and gender')\nax.tick_params(bottom=False, left=True)\nax.legend()\nplt.suptitle('ML Managing Tools')\nplt.show()\n","93cd8435":"cloud_plat_w_df = df_creater(data_ml, 'Q27_A', 'Cloud Computing Platform').sort_values('% Users',ascending = False)\ncloud_plat_w_df['% Users'] = (cloud_plat_w_df['% Users'] \/cloud_plat_w_df['% Users'].sum())*100\n\ncloud_plat_df = df_creater(data_eu, 'Q27_A', 'Cloud Computing Platform').sort_values('% Users',ascending = False).reindex([0,2,10,1,3,4,7,11,5,6,8,9])\ncloud_plat_df['% Users'] = (cloud_plat_df['% Users'] \/cloud_plat_df['% Users'].sum())*100\n\nfig, ax = plt.subplots(figsize=(15,6))\nx = np.arange(len(cloud_plat_df))\nwidth = 0.4\nplt.barh(x-0.2, cloud_plat_df['% Users'], width, color='#0e3362', label='EU') \nplt.barh(x+0.2, cloud_plat_w_df['% Users'], width, color='#69e2c1', label='World')\n\nplt.ylabel(None)\nplt.yticks(cloud_plat_w_df.index, labels = cloud_plat_w_df['Cloud Computing Platform'])\n\nplt.xlabel('Percentage', fontsize=7)\nplt.yticks(fontsize=10)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=True)\nplt.legend(frameon=False, fontsize=15)\nplt.show()\n","ee204a2b":"cloud_investment_w_df = pd.DataFrame(data_ml['Q26'].value_counts()).reset_index().drop(6).rename(columns = {'index':'Cloud Investment','Q26': 'Users'})\ncloud_investment_w_df.Users = (cloud_investment_w_df.Users\/cloud_investment_w_df.Users.sum())*100\n\ncloud_investment_df = pd.DataFrame(data_eu['Q26'].value_counts()).reset_index().rename(columns = {'index':'Cloud Investment','Q26': 'Users'})\ncloud_investment_df.Users = (cloud_investment_df.Users\/cloud_investment_df.Users.sum())*100\n\nfig, ax = plt.subplots(figsize=(15,5))\nx = np.arange(len(cloud_investment_df))\nwidth = 0.4\nplt.barh(x-0.2, cloud_investment_df.reindex([0,2,1,4,3,5])['Users'], width, color='#0e3362', label='EU') \nplt.barh(x+0.2, cloud_investment_w_df['Users'], width, color='#69e2c1', label='World')\n\nplt.ylabel(None)\nplt.yticks(cloud_investment_w_df.index, labels = cloud_investment_w_df['Cloud Investment'])\n\nplt.xlabel('Percentage', fontsize=7)\nplt.yticks(fontsize=10)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=True)\nplt.legend(frameon=False, fontsize=15)\nplt.show()\n","261f920d":"# data_storage_w_df = df_creater(data_ml, 'Q30_A', 'Data Storage Products').sort_values('% Users')\n# data_storage_w_df['% Users'] = (data_storage_w_df['% Users']\/data_storage_w_df['% Users'].sum())*100\n\ndata_storage_df = df_creater(data_eu, 'Q30_A', 'Data Storage Products').sort_values('% Users', ascending = False)\ndata_storage_df['% Users'] = (data_storage_df['% Users']\/data_storage_df['% Users'].sum())*100\n\nfig, ax = plt.subplots(figsize=(13,4))\n\nax.hlines(data_storage_df['Data Storage Products'], xmin=0, xmax = data_storage_df['% Users']-0.50, colors = '#0e3362')\nsns.scatterplot( data = data_storage_df, x = '% Users', y = 'Data Storage Products',sizes=(650, 651),size = \"% Users\", legend=False, color= '#04a664', alpha = 0.5)\n\n# for j in range(len(hosted_nb_w_df)):\n#     plt.annotate( \"{hosted_nb_w_df['% Users'][j]: .0%}\".format(hosted_nb_w_df['% Users'][j]), (hosted_nb_w_df['% Users'][j], hosted_nb_w_df['Hosted Notebook'][j]),weight = 'bold', color = '#5b5eec')\n\nfor j in range(len(data_storage_df)):\n    plt.annotate( f'{data_storage_df[\"% Users\"][j]:1.0f}', (data_storage_df['% Users'][j]-0.3, data_storage_df['Data Storage Products'][j]),weight = 'bold', color = 'white')\n\nplt.xticks([]) \nax.set_xlim(0,30)\nsns.despine(bottom=True)\nax.grid(False)\nax.tick_params(bottom=False, left=False)\nplt.tight_layout()\nplt.show()\n","7ecc57aa":"## <span style = 'color:#003399'>EU vs the World<\/span>\n> The **European countries has a share of 10.3%** in this survey. **Germany, Spain and France** are the top three contributors, all of the have **over 400 users**. ","61aff2fe":"<span style = 'color:#c9be89'>**5. Tools to Manage ML Experiments**\n\n> * About **60%** users **doesn't prefer** to use any managing tool.\n> * Still **15%** users prefer to use **MLflow** and about **20% TensorBoard**.","e1eac69b":"## <span style = 'color:#003399'>Education<\/span>\n\n<span style = 'color: #b7b146'>**1. Highest Level of Formal Education**\n\n> The age distribution is clearly being reflected in the education plot. Since EU is missing people in the age group of 18-24, which generally is the age of Bachelor's degree, we see great **divergence between the people having Bachelor's degree in EU as compared to the World**. It is roughly the **difference of 25%**. \n> \n> * People in **EU** are having roughly **15% more Master's degree** as compared to the world.\n> * The Bachelor's degree and Master's degree holders are almost equivalent when we consider the world. On the other hand there is a **difference of almost 40%** when we consider the EU, In EU we have way more Master's degree holders.","b3b61029":"## <span style = 'color:#0e3362'>Big Data<\/span>\n\n> * For Big Data, most popular products are **MySQL, ProstgreSQL and MongoDB**.\n> * 13% people doesn't use any big data product.\n> \n> ","2fc76bde":"> Also, when asked about which programming language would you recommend to an aspiring Data Scientist,we get following results:","c5f02e42":"## <span style = 'color:#0e3362'>Job<\/span>\n> In EU the top 3 places are occupied by the **Data Scientist, Student** and Research Scientist. Whereas Student, Data Scientist and Software Engineer are the top 3 place holders in the world.\n> \n> The major divergence between the world and the EU is only present in the Student and Data Scientist category.\n> ","9132ba6d":"> Dominance of Python is quite clear here, **almost 80% people would recommend Python**. Also, this advice is coming from the people who are already in this field, which clearly indicates that **Python is the furture!**.","e00bddbf":"<span style = 'color:#c4b66e'>**4. Impact of Coding Experience on Compensastion**","a100d9af":"<span style = 'color:#c4b66e'>**5. Company Size vs Data Science Workers**\n\n> There is almost a linear relation between the company size and Data Science. **The bigger the comapny the larger data science employees it has**. ","7d25c9a7":"## <span style = 'color:#0e3362'>Computing Platform for Data Science Projects<\/span>\n\n> Majority of users are going with the laptop and a personal computer, followed by the cloud platforms. The recent advancements in the computing power of the laptops and their comfortability might be a huge boost to this trend.","e99be5e0":"## <span style = 'color:#0e3362'>Cloud Platform<\/span>\n\n<span style= 'color:#c4b66e'>**1. Usage of Cloud Platform**\n\nThe top 3 places in both the EU and the world is occupied by **AWS, Microsoft Azure and Google Cloud PLatform**. In EU GCP is being used more as compared to the world which is favouring Microsoft Azure a bit more but overall, the trend of cloud platforms in EU and the world, align with each other. \n","79b9d421":"<span style= 'color: #b7b146'>**1. Industry of the Current Employer**\n\n> The industry is kind of equivalent for both the world and EU. **Computers, Academia and Accounting** takes the **top 3** places. However, it is good to see rest of the industry having their hands on ML and Data Science.","50df3265":"## <span style = 'color:#003399'>Introduction<\/span>\n\n> Kaggle is a great platform for data scientists and machine learning practitioners, it has grown quite alot since its start and has reached **over 8 million registered users as of 2021**. Most of the data scientists and machine learning practitioners are fimilar with Kaggle, hence this survey would surely provide a accurate picture of data science and machine learning scene.\n> \n> Since we already have plenty of notebooks about the world, I don't want to waste the time of my fellow readers to go through another one, but let me take all of you to **the largest economic continent on the Earth i.e, Europe**. It is the richest region as measured by assets under management with over \\\\$32.7 trillion compared to North America's $27.1 trillion in 2008.\n> \n> The objective of this notebook would be figuring out the difference in scene of ML and Data Science in Europe as compared to the world. I would try to have a pretty comprehensive analysis and would present most of the questions asked in the survey.","7e43c1d1":"<span style = 'color:#cbbf80'>**3. Popular ML Algorithms**\n\n> * Most popular ML Method: **Linear or Logistic Regression**, CV Method: **VGG, Inception, ResNet**, etc, NLP Method: **Word embeddings\/vectors**.\n> * Both EU and the World follow the **same pattern**.","4f010966":"<span style= 'color: #b7b146'>**3. Platforms for Data Science Courses**\n\n> The top online platforms which are desired for doing data science courses are Kaggle, followed by Coursera, Udemy and University courses.\n> Important observation here is that **people prefer Kaggle courses more than University courses**. One of the reason could be the non practicality of most of the University courses.","6b05bc13":"## <span style = 'color:#0e3362'>Visualization Tools<\/span>\n\n> * **Matplotlib, Seaborn and Plotly are fan favourite** with whooping 33%, 23% and 13% users.\n> * About **8%-10% people doesn't use any visualization tools**, they depend upon default.\n> * Here also there isn't much deviation between EU and the world.","0bb88e1f":"##  <span style = 'color:#003399'>Countries Participating in the Survey<\/span>\n> It is quite evident from the below plot that the maximum number of people are from **India, which constitute nearly 30% of the total participants of the survey, followed by USA.** The population of India and its presence in IT industry might be a factor for their participation in the Kaggle. But thats just absolute figure, a more accurate representation would be person per 100 of the respective courtry's population. \n> \n> The **European countries** start with the **11th position, occupied by the Germany**, followed by Spain. **Germany has 1.8%** whereas Spain is not that far behind and has 1.7% participants.","03ab8c79":"<span style = 'color: #c4b66e'>**2. Incorporation of ML Methods into Business**\n\n> * Approximately 70% of the Businesses are either using some form of ML methods in their working or are going to work on it in coming days.\n> * Out of these 70%, 20% have well established ML Methods.\n> * Both EU and the world are on par with each other regarding this.\n> ","9a1a6a60":"##  <span style = 'color:#0e3362'>Hosted Notebook Products<\/span>\n\n>* **Google Colab Notebooks and Kaggle Notebooks** are the clear **winner** with 26% and 25% users respectively.\n> * A large majority of users **doesn't use any hosted notebook**, which accounts for **19% users**.","68fc1bbc":"## <span style = 'color:#003399'>Demography: Age and Gender<\/span>","70cbe6c5":"> The interesting observation here is that, the peak age in the world's distribution is around the age group of 18-29, i.e, the contribution of young population is quite evident there whereas the peak of age's distribution of EU is at 25-29. **EU is missing the contribution of people in the age group of 18-24.**\n> \n> However, having a median in the age group of 25-29 is still a positive sign for the ML and Data Science practitioners, because it suggests that young people are interested in this field and this would surely help in flourishing field further.","be98701b":"<span style = 'color: #c4b66e'>**3. Activities Important for Work**\n\n> **Analysis and understanding of data** to influence product or business decisions takes the first place here with 27% followed by building prototypes to explore **ML in new areas** with 16%.","8aeefb05":"> An interesting observation that can be drawn out from the below heat map is that most of the people have **coding experience under 3 years and earn in the range of \\\\$0-999**.\n> \n","3427f60f":"## <span style = 'color:#0e3362'>Machine Learning<\/span>\n\n<span style = 'color:#cbbf80'>**1. ML Methods Experinece**\n\n> * Most of the users are quite new to ML methods, there are only few seasoned professionals with 20+ years of experience. This indicates that young people are interested in this field, which is good for this growing community.\n> * Both the world and the EU are following **similar trend** regarding this. Almost **30% users** have **under 1 year of experince**.\n> * Also, **13% users** claims to have **no ML method experience**.","3fe57ecc":"## <span style = 'color:#0e3362'>Conclusion<\/span>\n\n> There isn't any major difference in the working of EU and the world, apart from slight variations, like variations in age distribution and the formal education distribution. Even these variations can be easily explained. For example, because of presence of a subsidized education system in EU, people tend to have more formal degrees as compared to other nations where the fees are quite hefty. We can therefore say that EU is not an outlier and is mostly aligned with the rest of the world.\n\nThis is my first nootebook ever, and I tried my best, your feedbacks are much appreciated!\n","a003de8d":"## <span style = 'color:#0e3362'>Business Intelligence Tools<\/span>\n\n> * The EU trend matches the world trend regarding Business Intelligence Tools.\n> * **Microsoft Power BI and Tableau** are the **top 2** favourites with 35% and 30% users respectively.","329164af":"<span style= 'color:#b7b146'>**2. Social Media**\n\n> Prior to the Covid-19, the online platforms were not that rigorously used but now things have changed. The online platforms share almost the same level of importance, if not more. Below is the treemap of popular social media sources for getting information regarding ML and Data Scince. There are some slight difference between popularity in the EU and the world but, overall the **top 3 place holders are  Kaggle, YouTube and Blogs**.","ceb6c4c3":"<span style = 'color:#cbbf80'>**2. Popular ML Framework**\n\n> The **top 4** popular ML frameworks are **Scikit-learn, TensorFlow, Keras and PyTorch**. Scikit-learn being most popular shows that traditional ML algorithms are still being used, but the rising popularity of TensorFlow and PyTorch reflects the growth of Deep Learning.","7eb56160":"## <span style = 'color:#003399'>Data<\/span>","874e2130":"> There isn't much divergence regarding the gender distribution between EU and the World. This field seems to be **male dominant** with around huge **80% participants being male**. And only 15% being female. ","91dad155":"## <span style= 'color:#0e3362'>Programming Language<\/span>\n> There isn't much difference about the prefernce of programming language among the EU and the world. Both the parties prefer the **python** with about **33%** users, followed by the R and SQL.\n> ","69ca43a0":"## <img src= \"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/b\/b7\/Flag_of_Europe.svg\" style='width: 35px; float: left'> <span style = 'color:#003399'> EUROPE<\/span> : <span style = 'color: #b7b146'>ANY DIFFERENT FROM THE WORLD ?<\/span>","c029ef94":"<span style= 'color:#c4b66e'>**3. Usage of Data Storage Products**\n\n* Amazon Simple Storage Service is taking the lead here with 29%, followed by Google Cloud Storage with 20%\n* 17% of people aren't using any storage device, this could be because most of them are student.","91726111":"<span style = 'color:#cbbf80'>**4. Auto ML**\n\n> Both in EU and the world people **doesn't prefer** to use **any automated ML tools**.\n> However, there is a differnce of 10% among the people in world and EU who prefer to use Google Cloud AutoML.","bebeb879":"<span style= 'color:#c4b66e'>**2. Money Spent on ML and\/or Cloud Computing Services**\n* **38% people aren't speding any money** on ML and\/or cloud Computing services.\n* Here also, there isn't much difference in EU and the World"}}