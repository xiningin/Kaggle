{"cell_type":{"3c53cfb9":"code","e10f6700":"code","44f23a03":"code","8fd10b0e":"code","d27f239d":"code","6e9e726c":"code","3c97e22e":"code","37e1790c":"code","bb9c43a6":"code","e2d208ac":"code","1e100549":"code","e05f3ef4":"code","c29b035d":"code","51f54f78":"code","aaee53c6":"code","6a93517b":"code","59577f88":"code","b6c172b4":"code","ed6f3d8a":"code","e149a650":"code","1002daf8":"code","7f00d5ba":"code","8eeb17f8":"code","cdae174e":"code","cd566274":"code","f33bf4d9":"code","35ce47c4":"code","4ce2c723":"code","e549addf":"code","4004937c":"code","53d8d0b9":"code","326d7334":"code","4962255e":"markdown","2163df6f":"markdown","9af7e704":"markdown","6afb6021":"markdown"},"source":{"3c53cfb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20, 10\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nimport keras\n\nfrom keras.utils import np_utils\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization\nimport os\nprint(os.listdir(\"..\/input\/ckplus\/CK+48\"))\n\n\n# Any results you write to the current directory are saved as output\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.datasets import make_classification\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","e10f6700":"data_path = '..\/input\/ckplus\/CK+48'\ndata_dir_list = os.listdir(data_path)\n\nimg_rows=256\nimg_cols=256\nnum_channel=1\n\nnum_epoch=10\n\nimg_data_list=[]\n\n\nfor dataset in data_dir_list:\n    img_list=os.listdir(data_path+'\/'+ dataset)\n    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n    for img in img_list:\n        input_img=cv2.imread(data_path + '\/'+ dataset + '\/'+ img )\n        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n        input_img_resize=cv2.resize(input_img,(48,48))\n        img_data_list.append(input_img_resize)\n        \nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data = img_data\/255\nimg_data.shape","44f23a03":"num_classes = 7\n\nnum_of_samples = img_data.shape[0]\nlabels = np.ones((num_of_samples,),dtype='int64')\n\nlabels[0:134]=0 #135\nlabels[135:188]=1 #54\nlabels[189:365]=2 #177\nlabels[366:440]=3 #75\nlabels[441:647]=4 #207\nlabels[648:731]=5 #84\nlabels[732:980]=6 #249\n\nnames = ['anger','contempt','disgust','fear','happy','sadness','surprise']\n\ndef getLabel(id):\n    return ['anger','contempt','disgust','fear','happy','sadness','surprise'][id]","8fd10b0e":"Y = np_utils.to_categorical(labels, num_classes)\n\n#Shuffle the dataset\nx,y = shuffle(img_data,Y, random_state=2)\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\nx_test=X_test","d27f239d":"def create_model():\n    input_shape=(48,48,3)\n\n    model = Sequential()\n    model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(7, activation = 'softmax'))\n\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='RMSprop')\n    \n    return model\n","6e9e726c":"from sklearn.model_selection import KFold","3c97e22e":"kf = KFold(n_splits=5, shuffle=False)","37e1790c":"from keras.preprocessing.image import ImageDataGenerator\n\naug = ImageDataGenerator(\n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")\n","bb9c43a6":"BS = 7\nEPOCHS = 200","e2d208ac":"result = []\nscores_loss = []\nscores_acc = []\nk_no = 0\nfor train_index, test_index in kf.split(x):\n    X_Train_ = x[train_index]\n    Y_Train = y[train_index]\n    X_Test_ = x[test_index]\n    Y_Test = y[test_index]\n\n    file_path = \"\/kaggle\/working\/weights_best_\"+str(k_no)+\".hdf5\"\n    checkpoint = ModelCheckpoint(file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n    early = EarlyStopping(monitor=\"val_binary_crossentropy\", mode=\"min\", patience=8)\n\n    callbacks_list = [checkpoint, early]\n\n    model = create_model()\n    hist = model.fit_generator(aug.flow(X_Train_, Y_Train), epochs=EPOCHS,validation_data=(X_Test_, Y_Test), callbacks=callbacks_list, verbose=1)\n    # model.fit(X_Train, Y_Train, batch_size=batch_size, epochs=epochs, validation_data=(X_Test, Y_Test), verbose=1)\n    model.load_weights(file_path)\n    result.append(model.predict(X_Test_))\n    score = model.evaluate(X_Test_,Y_Test, verbose=0)\n    scores_loss.append(score[0])\n    scores_acc.append(score[1])\n    k_no+=1","1e100549":"print(scores_acc,scores_loss)","e05f3ef4":"value_min = min(scores_loss)\nvalue_index = scores_loss.index(value_min)\nprint(value_index)","c29b035d":"model.load_weights(\"\/kaggle\/working\/weights_best_\"+str(value_index)+\".hdf5\")","51f54f78":"best_model = model","aaee53c6":"score = best_model.evaluate(X_test, y_test, verbose=0)\nprint('Test Loss:', score[0])\nprint('Test accuracy:', score[1])\n\ntest_image = X_test[0:1]\nprint (test_image.shape)\n\nprint(best_model.predict(test_image))\nprint(best_model.predict_classes(test_image))\nprint(y_test[0:1])\n\nres = best_model.predict_classes(X_test[9:18])\nplt.figure(figsize=(10, 10))\n\nfor i in range(0, 9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(x_test[i],cmap=plt.get_cmap('gray'))\n    plt.gca().get_xaxis().set_ticks([])\n    plt.gca().get_yaxis().set_ticks([])\n    plt.ylabel('prediction = %s' % getLabel(res[i]), fontsize=14)\n# show the plot\nplt.show()","6a93517b":"# visualizing losses and accuracy\n%matplotlib inline\n\ntrain_loss=hist.history['loss']\nval_loss=hist.history['val_loss']\ntrain_acc=hist.history['accuracy']\nval_acc=hist.history['val_accuracy']\n\nepochs = range(len(train_acc))\n\nplt.plot(epochs,train_loss,'r', label='train_loss')\nplt.plot(epochs,val_loss,'b', label='val_loss')\nplt.title('train_loss vs val_loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,train_acc,'r', label='train_acc')\nplt.plot(epochs,val_acc,'b', label='val_acc')\nplt.title('train_acc vs val_acc')\nplt.legend()\nplt.figure()","59577f88":"print(train_loss)","b6c172b4":"print(val_loss)","ed6f3d8a":"print(train_acc)","e149a650":"print(val_acc)","1002daf8":"#Model Save\nbest_model.save_weights('model_weights.h5')\nbest_model.save('model_keras.h5')","7f00d5ba":"# Evaluating the model\nscore = best_model.evaluate(X_test, y_test, verbose=0)\nprint('Test Loss:', score)\n\ntest_image = X_test[0:1]\nprint (test_image.shape)\n\n#predict\ny_pred = best_model.predict(X_test) \n\nprint(best_model.predict(test_image))\nprint(best_model.predict_classes(test_image))\n\nplt.figure(figsize=(10, 10))\n","8eeb17f8":"from sklearn.metrics import confusion_matrix\nresults = best_model.predict_classes(X_test)\ncm = confusion_matrix(np.where(y_test == 1)[1], results)\n#cm = cm.astype(np.float) \/ cm.sum(axis=1)[:, np.newaxis]","cdae174e":"import seaborn as sns\nimport pandas as pd\n","cd566274":"label_mapdisgust = ['anger','contempt','disgust','fear','happy','sadness','surprise']","f33bf4d9":"#Transform to df for easier plotting\ncm_df = pd.DataFrame(cm, index = label_mapdisgust,\n                     columns = label_mapdisgust\n                    )\n","35ce47c4":"final_cm = cm_df","4ce2c723":"plt.figure(figsize = (5,5))\nsns.heatmap(final_cm, annot = True,cmap='Greys',cbar=False,linewidth=2,fmt='d')\nplt.title('CNN Emotion Classify')\nplt.ylabel('True class')\nplt.xlabel('Prediction class')\nplt.show()","e549addf":"from sklearn.metrics import roc_curve,auc\nfrom itertools import cycle","4004937c":"new_label = ['anger','contempt','disgust','fear','happy','sadness','surprise']\nfinal_label = new_label\nnew_class = 7","53d8d0b9":"#ravel flatten the array into single vector\ny_pred_ravel = y_pred.ravel()\nlw = 2","326d7334":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(new_class):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \n#colors = cycle(['red', 'green','black'])\ncolors = cycle(['red', 'green','black','blue', 'yellow','purple','orange'])\nfor i, color in zip(range(new_class), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0}'''.format(final_label[i]))\n    \n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","4962255e":"**In this notebook augmentation is done.In the previous version non-augemennted is done.**","2163df6f":"\n\nConfusion Matrix\n","9af7e704":"**Conduct k-Fold Cross-Validation**","6afb6021":"\n\nROC Curve\n"}}