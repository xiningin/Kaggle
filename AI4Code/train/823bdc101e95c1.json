{"cell_type":{"4955ae63":"code","9f893c5c":"code","0d089ffc":"code","76922a03":"code","c48d38d1":"code","628621db":"code","ba9d05b3":"code","ae2239b4":"code","011c5cd7":"code","68f07a7e":"code","9155f339":"code","6a61c412":"code","23b722f9":"code","c584eb10":"code","6d4f97b6":"code","bf9a2d62":"code","7b61b119":"code","2346efe9":"code","e856bd01":"code","63011d70":"code","7d370a1a":"code","3026d4ac":"code","92bad5d3":"code","ce1f6c11":"code","e1f38a4d":"code","76cc540c":"code","c6e39d82":"code","1b6bdbff":"code","35ea4041":"code","c70a897e":"code","5d2c1d91":"code","4db2a516":"markdown","2a8e6772":"markdown","c1ebf9d4":"markdown","9bbab919":"markdown","0f9cd9ca":"markdown","20f9d056":"markdown","025a9348":"markdown","d5d2e0ae":"markdown","83db820c":"markdown","69aa01db":"markdown","14eb299c":"markdown","3c71088a":"markdown","4dad450e":"markdown","3e97a8ac":"markdown","4a8cb86d":"markdown","3df7ad0b":"markdown","6124c9a8":"markdown","c5c4667e":"markdown","c00027e3":"markdown","6679525f":"markdown","e67a5190":"markdown","45eb56dd":"markdown","8d98efbc":"markdown","b4787ebf":"markdown","8e5c35c0":"markdown"},"source":{"4955ae63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f893c5c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn as sk\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","0d089ffc":"train_data = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv')","76922a03":"train_data.describe()","c48d38d1":"#Printing all variable names and the datatypes \ntrain_data.dtypes","628621db":"train_data.head()","ba9d05b3":"train_data.isnull().sum()","ae2239b4":"res = {col:train_data[col].value_counts() for col in train_data.columns}\n\n\nfor i in train_data.columns:\n    print (i)\n    print (res[i])\n    print ('\\n')","011c5cd7":"plt.figure(figsize=[30,6])\nsns.histplot(data= train_data,  x=\"city\", hue = \"target\")\nplt.xticks(rotation=70,fontsize=13);","68f07a7e":"# city_count=train_data['city'].value_counts()\ncity_count=pd.DataFrame(train_data.city.value_counts().reset_index().values,columns=[\"city\",\"city_count\"])\ncity_count['count_sum']= city_count['city_count'].cumsum()\ncity_count['count_sum'] = city_count[city_count['count_sum']<=0.7*19158]['count_sum']\n\nfinial_city_count= city_count.dropna()\ntrain_data_w_major_cities = train_data[train_data['city'].isin(finial_city_count['city'])]\n\nsns.histplot(data= train_data_w_major_cities,  x=\"city\", hue = \"target\",multiple=\"dodge\", shrink=.8)\nplt.xticks(rotation=70);\n\n","9155f339":"k= train_data_w_major_cities.groupby(['city','city_development_index']).size()\nplt.figure(figsize=[8,8])\nsns.heatmap(train_data[['city_development_index','target']].corr(),annot=True,fmt='.2f',cbar_kws={\"orientation\": \"horizontal\"})\nplt.title('Correlation factors between target and city development index column \\n \\n');","6a61c412":"train_data['gender']=train_data['gender'].fillna('DNM')\nplt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\nsorted_counts=train_data['gender'].value_counts()\nplt.pie(sorted_counts,labels=sorted_counts.index,startangle=90,counterclock=False,wedgeprops={'width':0.4})\nplt.axis('square');\nplt.subplot(1,2,2)\n# sns.barplot(sorted_counts.index.values,sorted_counts)\nax = sns.histplot(data = train_data,x=\"gender\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.show();","23b722f9":"plt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\nsorted_counts=train_data['relevent_experience'].value_counts()\nplt.pie(sorted_counts,labels=sorted_counts.index,startangle=90,counterclock=False,wedgeprops={'width':0.4})\nplt.axis('square');\nplt.subplot(1,2,2)\n# sns.barplot(sorted_counts.index.values,sorted_counts)\nax = sns.histplot(data = train_data,x=\"relevent_experience\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.show();","c584eb10":"train_data['enrolled_university']=train_data['enrolled_university'].fillna('DNM')\nplt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\nsorted_counts=train_data['enrolled_university'].value_counts()\nplt.pie(sorted_counts,labels=sorted_counts.index,startangle=90,counterclock=False,wedgeprops={'width':0.4})\nplt.axis('square');\nplt.subplot(1,2,2)\n# sns.barplot(sorted_counts.index.values,sorted_counts)\nax = sns.histplot(data = train_data,x=\"enrolled_university\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.show();","6d4f97b6":"train_data['education_level']=train_data['education_level'].fillna('DNM')\nplt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\n#creating waffle plot for education level\ndef percentage_blocks(df, var):\n    \"\"\"\n    Take as input a dataframe and variable, and return a Pandas series with\n    approximate percentage values for filling out a waffle plot.\n    \"\"\"\n    # compute base quotas\n    percentages = 100 * train_data[var].value_counts() \/ df.shape[0]\n    counts = np.floor(percentages).astype(int) # integer part = minimum quota\n    decimal = (percentages - counts).sort_values(ascending = False)\n\n    # add in additional counts to reach 100\n    rem = 100 - counts.sum()\n    for cat in decimal.index[:rem]:\n        counts[cat] += 1\n\n    return counts\n\n\nwaffle_counts = percentage_blocks(train_data, 'education_level')\n\nprev_count = 0\n# for each category,\nfor cat in range(waffle_counts.shape[0]):\n    # get the block indices\n    blocks = np.arange(prev_count, prev_count + waffle_counts[cat])\n    # and put a block at each index's location\n    x = blocks % 10 # use mod operation to get ones digit\n    y = blocks \/\/ 10 # use floor division to get tens digit\n    plt.bar(x = x, height = 0.8, width = 0.8, bottom = y)\n    prev_count += waffle_counts[cat]\n\n    \n# aesthetic wrangling\nplt.legend(waffle_counts.index, bbox_to_anchor = (1, 0.5), loc = 6);\nplt.axis('off')\nplt.axis('square');\n\nplt.subplot(1,2,2)\nax = sns.histplot(data = train_data,x=\"education_level\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.xlabel(\"Education Level\")\nplt.show();","bf9a2d62":"train_data['major_discipline']=train_data['major_discipline'].fillna('DNM')\nplt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\n\n\n\n\nwaffle_counts = percentage_blocks(train_data, 'major_discipline')\n\nprev_count = 0\n# for each category,\nfor cat in range(waffle_counts.shape[0]):\n    # get the block indices\n    blocks = np.arange(prev_count, prev_count + waffle_counts[cat])\n    # and put a block at each index's location\n    x = blocks % 10 # use mod operation to get ones digit\n    y = blocks \/\/ 10 # use floor division to get tens digit\n    plt.bar(x = x, height = 0.8, width = 0.8, bottom = y)\n    prev_count += waffle_counts[cat]\n\n    \n# aesthetic wrangling\nplt.legend(waffle_counts.index, bbox_to_anchor = (1, 0.5), loc = 6);\nplt.axis('off')\nplt.axis('square');\n\nplt.subplot(1,2,2)\nax = sns.histplot(data = train_data,x=\"major_discipline\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.xlabel(\"Major\")\nplt.show();","7b61b119":"train_data['experience']=train_data['experience'].fillna('DNM')\nplt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\ntrain_data['Exp'] = np.where(train_data['experience'].isin(['<1','1','2','3']), \"Entry-level Exp\", \"DNM\")\ntrain_data['Exp'] = np.where(train_data['experience'].isin(['4','5','6','7','8']), \"Mid-level Exp\",train_data['Exp'])\ntrain_data['Exp'] = np.where(train_data['experience'].isin(['9','10','11','12','13','14','15','16','17','18','19','20','>20']), \"Senior-level Exp\",train_data['Exp'])\nsorted_counts=train_data['Exp'].value_counts()\nplt.pie(sorted_counts,labels=sorted_counts.index,startangle=90,counterclock=False,wedgeprops={'width':0.4})\nplt.axis('square');\nplt.subplot(1,2,2)\n# sns.barplot(sorted_counts.index.values,sorted_counts)\nax = sns.histplot(data = train_data,x=\"Exp\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.xlabel(\"Experience\")\nplt.show();","2346efe9":"train_data['company_size']=train_data['company_size'].fillna('DNM')\nplt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\ntrain_data['size'] = np.where(train_data['company_size'].isin(['50-99','10\/49','<10']), \"Small Enterprise\", \"DNM\")\ntrain_data['size'] = np.where(train_data['company_size'].isin(['100-500','500-999']), \"Medium Enterprise\",train_data['size'])\ntrain_data['size'] = np.where(train_data['company_size'].isin(['10000+','1000-4999','5000-9999']), \"Large Enterprise\",train_data['size'])\nsorted_counts=train_data['size'].value_counts()\nplt.pie(sorted_counts,labels=sorted_counts.index,startangle=90,counterclock=False,wedgeprops={'width':0.4})\nplt.axis('square');\nplt.subplot(1,2,2)\n# sns.barplot(sorted_counts.index.values,sorted_counts)\nax = sns.histplot(data = train_data,x=\"size\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.xlabel(\"Company Size\")\nplt.show();","e856bd01":"train_data['company_type']=train_data['company_type'].fillna('DNM')\nplt.figure(figsize=[40,10])\nplt.subplot(1,2,1)\nsorted_counts=train_data['company_type'].value_counts()\nplt.pie(sorted_counts,labels=sorted_counts.index,startangle=90,counterclock=False,wedgeprops={'width':0.4})\nplt.axis('square');\nplt.subplot(1,2,2)\n# sns.barplot(sorted_counts.index.values,sorted_counts)\nax = sns.histplot(data = train_data,x=\"company_type\",hue=\"target\",multiple=\"dodge\", shrink = 0.6)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():,.0f}\\n',\n                (p.get_x() + p.get_width() \/ 2, p.get_height()), ha='center', va='center')\n\nplt.ylabel(\"Number of people\")\nplt.xlabel(\"Company Type\")\nplt.show();","63011d70":"plt.figure(figsize=[20,5])\nplt.subplot(1,2,1)\n\n\nsns.histplot(data=train_data['training_hours'], bins =20)\n# sns.histplot(train_data['training_hours'], bins = bin_edges)\n# plt.axis('square');\nplt.subplot(1,2,2)\n# sns.barplot(sorted_counts.index.values,sorted_counts)\nsns.heatmap(train_data[['training_hours','target']].corr(),annot=True,fmt='.2f',cbar_kws={\"orientation\": \"horizontal\"})\nplt.title('Correlation factors between target and Training Hours \\n \\n');\nplt.show();","7d370a1a":"train_data['last_new_job']=train_data['last_new_job'].fillna('DNM')\ntrain_data.head()\n","3026d4ac":"def test_transform(df):\n    \n    df['gender']=df['gender'].fillna('DNM')\n    df['enrolled_university']=df['enrolled_university'].fillna('DNM')\n    df['education_level']=df['education_level'].fillna('DNM')\n    df['major_discipline']=df['major_discipline'].fillna('DNM')\n    df['Exp'] = np.where(df['experience'].isin(['<1','1','2','3']), \"Entry-level Exp\", \"DNM\")\n    df['Exp'] = np.where(df['experience'].isin(['4','5','6','7','8']), \"Mid-level Exp\",df['Exp'])\n    df['Exp'] = np.where(df['experience'].isin(['9','10','11','12','13','14','15','16','17','18','19','20','>20']), \"Senior-level Exp\",df['Exp'])\n\n\n    df['size'] = np.where(df['company_size'].isin(['50-99','10\/49','<10']), \"Small Enterprise\", \"DNM\")\n    df['size'] = np.where(df['company_size'].isin(['100-500','500-999']), \"Medium Enterprise\",df['size'])\n    df['size'] = np.where(df['company_size'].isin(['10000+','1000-4999','5000-9999']), \"Large Enterprise\",df['size'])\n\n\n    df['company_type']=df['company_type'].fillna('DNM')\n\n    df['last_new_job']=df['last_new_job'].fillna('DNM')\n    return df\n\ntest_data = test_transform(test_data)","92bad5d3":"def transform_data(df):\n    df.head()\n    df['gender']=df['gender'].replace({'Male':0,'Female':1,'Other':3,'DNM':2})\n    df['enrolled_university']=df['enrolled_university'].replace({'no_enrollment':0,'Full time course':1,'Part time course':2, 'DNM':3})\n    df['relevent_experience']=df['relevent_experience'].replace({'No relevent experience':0,'Has relevent experience':1})\n    df['education_level'] = df['education_level'].replace({'Graduate':1,'High School':4,'Primary School':5,'Masters':2,'Phd':3, 'DNM':6})\n    df['major_discipline']=df['major_discipline'].replace({'STEM':1, 'Humanities':2, 'Arts':3, 'Business Degree':4,'No Major':5,'Other':6, 'DNM':7})\n    df['Exp'] = df['Exp'].replace({'Entry-level Exp':1, 'Mid-level Exp':2,'Senior-level Exp':3, 'DNM':4 })\n    df['size'] = df['size'].replace({'Small Enterprise':1,'Medium Enterprise':2,'Large Enterprise':3, 'DNM':4})\n    df['last_new_job']=df['last_new_job'].replace({'>4':5,'1':1,'never':0,'4':4, '3':3, '2':2 ,'DNM':0})\n    df['company_type']=df['company_type'].replace({'Pvt Ltd':1,'Funded Startup':2,'Public Sector':3,'Early Stage Startup':4,'NGO':5,'Other':6,'DNM':7})\n    return df\n    \n\ntrain_data=transform_data(train_data)\n\ntest_data = transform_data(test_data)\n\n    ","ce1f6c11":"train_data.drop(['experience','company_size','enrollee_id','city'],axis =1,inplace = True)\ntest_data2 = test_data.drop(['experience','company_size' ,'city'],axis =1,inplace = True)","e1f38a4d":"y=train_data['target']\nx=train_data.drop(['target'],axis=1)","76cc540c":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=44, shuffle =True)\n\n#Splitted Data\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","c6e39d82":"from sklearn.ensemble import GradientBoostingClassifier\n \n\nGBCModel = GradientBoostingClassifier(n_estimators=500,max_depth=50,random_state=33) \nGBCModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('GBCModel Train Score is : ' , GBCModel.score(X_train, y_train))\nprint('GBCModel Test Score is : ' , GBCModel.score(X_test, y_test))\n \n#Calculating Prediction\ny_pred = GBCModel.predict(X_test)\ny_pred_prob = GBCModel.predict_proba(X_test)","1b6bdbff":"# applying  random forest\nRandomForestClassifierModel = RandomForestClassifier(criterion = 'gini',n_estimators=500,max_depth=10,random_state=33) #criterion can be also : entropy \nRandomForestClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(X_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(X_test, y_test))\nprint('RandomForestClassifierModel features importances are : ' , RandomForestClassifierModel.feature_importances_)\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(X_test)\ny_pred_prob = RandomForestClassifierModel.predict_proba(X_test)\nprint('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for RandomForestClassifierModel is : ' , y_pred_prob[:10])","35ea4041":"test_data.head()","c70a897e":"pred = RandomForestClassifierModel.predict(test_data.drop('enrollee_id', axis='columns'))\nsubmission = pd.DataFrame({'enrollee_id':test_data['enrollee_id'],'target':pred})\ndisplay(submission)","5d2c1d91":"submission.to_csv('submission.csv',index=False)","4db2a516":"##### In this we denote the Nulls by DNN - \"Did not Mention\" and see what effect it has on the overall Job change\n\n##### In the above we see that majority of the participants are not enrolled in the course currently. Since the next graph shows that majority of the participants are gaduates, meaning the above graph might be people enrolled right now. And the people enrolled in Full-time course right now, might be looking for the next shift.","2a8e6772":"##### In this we denote the Nulls by DNN - \"Did not Mention\" and see what effect it has on the overall Job change\n\n##### In the above we see that majority of the participants are not enrolled in the course currently. Since the next graph shows that majority of the participants are gaduates, meaning the above graph might be people enrolled right now. And the people enrolled in Full-time course right now, might be looking for the next shift.","c1ebf9d4":"<a id=\"2.3.9\"><\/a>\n<h3 id=\"Heading15\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing training hours with candidates looking for the job  \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading15 Data\">\u00b6<\/a>\n<\/h3>","9bbab919":"##### In this we denote the Nulls by DNN - \"Did not Mention\" and see what effect it has on the overall Job change\n\n##### In the above we see that majority of the participants are not enrolled in the course currently. Since the next graph shows that majority of the participants are gaduates, meaning the above graph might be people enrolled right now. And the people enrolled in Full-time course right now, might be looking for the next shift.","0f9cd9ca":"<a id=\"2.3.5\"><\/a>\n<h3 id= \"Heading11\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing education level with candidates looking for the job \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading11 Data\">\u00b6<\/a>\n<\/h3>","20f9d056":"<a id=\"1.3\"><\/a>\n<h1 id = \"Heading1\" style=\"background-color:yellow;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Importing Packages\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading1 Data\">\u00b6<\/a>\n<\/h1>","025a9348":"<a id=\"table\"><\/a>\n<h1 style=\"background-color:cyan;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Table Of Content<\/h1>\n\n\n* [1. Introduction](#1)\n    * [1.1 Loading Data](#1.2)\n    * [1.2 Importing Packages](#1.3)                                         \n* [2. Exploratory Data Analysis](#2)    \n    * [2.1 Understanding the Data and the variables](#2.1)\n    * [2.2 Null values and the different elements in each variable](#2.2)\n    * [2.3 Analyzing each variable with respect to the target variable](#2.3)\n        * [2.3.1 Comparing cities and the development index with candidates looking for the job](#2.3.1)\n        * [2.3.2 Comparing gender with candidates looking for the job](#2.3.2)\n        * [2.3.3 Comparing relevant experience with candidates looking for the job](#2.3.3)\n        * [2.3.4 Comparing type of program with candidates looking for the job](#2.3.4)\n        * [2.3.5 Comparing education level with candidates looking for the job](#2.3.5)\n        * [2.3.6 Comparing field of major with candidates looking for the job](#2.3.5)\n        * [2.3.7 Comparing experience with candidates looking for the job](#2.3.7)\n        * [2.3.8 Comparing company size and type with candidates looking for the job](#2.3.8)\n        * [2.3.9 Comparing training hours with candidates looking for the job](#2.3.9)\n* [3. Modeling And Prediction](#3)    \n    * [3.1 Data transformation for prediction](#3.1)\n    * [3.2 ML models](#3.2)\n        \n    \n    ","d5d2e0ae":"##### In this we denote the Nulls by DNT - \"Did not tell\" and see what effect it has on the overall Job change\n\n##### In the above we see that majority of the participants are male. Also, we see that, by proportion the candidates who did not what to mention their gender were more willing to change the Job.","83db820c":"<a id=\"2.3.6\"><\/a>\n<h3 id=\"Heading12\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing field of major with candidates looking for the job \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading12 Data\">\u00b6<\/a>\n<\/h3>","69aa01db":"<a id=\"3.1\"><\/a>\n<h1 id=\"Heading8\" style=\"background-color:yellow;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\"> Data Transformation for Prediction \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading8 Data\">\u00b6<\/a>\n<\/h1>","14eb299c":"<a id=\"2.3.3\"><\/a>\n<h3 id=\"Heading9\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing relevant experience with candidates looking for the job  \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading9 Data\">\u00b6<\/a>\n<\/h3>","3c71088a":"<a id=\"2.1\"><\/a>\n<h1 id=\"Heading4\" style=\"background-color:yellow;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Understanding the data and the Variables\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading4 Data\">\u00b6<\/a>\n<\/h1>","4dad450e":"<a id=\"2.3.2\"><\/a>\n<h3 id=\"Heading8\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing gender with candidates looking for the job  \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading8 Data\">\u00b6<\/a>\n<\/h3>\n","3e97a8ac":"<a id=\"2.2\"><\/a>\n<h1 id=\"Heading5\" style=\"background-color:yellow;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\"> Null values and the different elements in each variable \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading5 Data\">\u00b6<\/a>\n<\/h1>","4a8cb86d":"<a id=\"2.3.1\"><\/a>\n<h3 id= \"Heading7\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing cities and the development index with candidates looking for the job  \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading7 Data\">\u00b6<\/a>\n<\/h3>\n","3df7ad0b":"<a id=\"3\"><\/a>\n<h1 id = \"Heading7\" style=\"background-color:cyan;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Modeling and Prediction\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading7 Data\">\u00b6<\/a>\n<\/h1>","6124c9a8":"##### In the above we see that majority of the participants have relevant experience and those who don't seems to be more eager to shift the job.","c5c4667e":"<a id=\"2.3.4\"><\/a>\n<h3 id = \"Heading10\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing type of program with candidates looking for the job  \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading10 Data\">\u00b6<\/a>\n<\/h3>","c00027e3":"<a id=\"2.3.7\"><\/a>\n<h3 id= \"Heading13\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing experience with candidates looking for the job \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading13 Data\">\u00b6<\/a>\n<\/h3>","6679525f":"<a id=\"3.2\"><\/a>\n<h1 id=\"Heading9\" style=\"background-color:yellow;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\"> ML models \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading9 Data\">\u00b6<\/a>\n<\/h1>","e67a5190":"<b>Note<\/b>:  Since there are 123 cities in this data set, we can take the top 11 cities as they make up more than 70% fo the data as seen below ","45eb56dd":"<a id=\"2.3.8\"><\/a>\n<h3 id=\"Heading14\" style=\"background-color:LimeGreen;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius: 12px 30px;\"> Comparing company size and type with candidates looking for the job  \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading14 Data\">\u00b6<\/a>\n<\/h3>","8d98efbc":"<a id=\"2.3\"><\/a>\n<h1 id=\"Heading6\" style=\"background-color:yellow;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\"> Analyzing each variable with respect to the target variable \n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading6 Data\">\u00b6<\/a>\n<\/h1>","b4787ebf":"<a id=\"2\"><\/a>\n<h1 id = \"Heading3\" style=\"background-color:cyan;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Exploratory Data Analysis\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading3 Data\">\u00b6<\/a>\n<\/h1>","8e5c35c0":"<a id=\"1.2\"><\/a>\n<h1 id = \"Heading\" style=\"background-color:yellow;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\"> Loading Data\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/hvempati\/hr-analytics-job-change-of-data-scientists\/notebook#Heading Data\">\u00b6<\/a>\n<\/h1>\n"}}