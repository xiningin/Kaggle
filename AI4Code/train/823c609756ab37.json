{"cell_type":{"bde092ae":"code","64cf0332":"code","3fcf1ad7":"code","fd7fd1ad":"code","abad6fde":"code","227e941c":"code","9648912c":"code","24759d24":"code","143304f4":"code","7ae661cb":"code","f7bbbd2c":"code","a0ad2d05":"code","5f7cbdd1":"code","32066e08":"code","87cd03b8":"code","945e2918":"code","c5fdb8dd":"code","9161e7ca":"code","c5062136":"code","01a6d100":"code","f0df5390":"code","d3217811":"code","6f00b1d9":"code","7b1ac841":"code","d717dceb":"code","c6444900":"code","80489e8a":"code","a17c277f":"code","75f32c85":"code","dbd284d5":"code","a1e61f43":"code","1ce904ab":"markdown","1c8707bd":"markdown","10929218":"markdown","ea503465":"markdown","954489d1":"markdown","875b1f9c":"markdown","8a2b28b0":"markdown","2a0997f4":"markdown","102ff7a4":"markdown","8cb19e98":"markdown","acc68956":"markdown","e3f36bea":"markdown","9832f5a4":"markdown","cac77975":"markdown","445dfba7":"markdown","9b50f0d8":"markdown","27065ba4":"markdown","8b523d1a":"markdown","f4f3f18d":"markdown","ff1dfd68":"markdown","921d2319":"markdown","7d05e614":"markdown","e1ab5be9":"markdown","7d2c7e73":"markdown","49546269":"markdown","4d9b8463":"markdown","d88bd3d4":"markdown","5af43b9b":"markdown","72259259":"markdown","ae671c20":"markdown","64b961cc":"markdown","9d05a711":"markdown","24e39c19":"markdown","fa759713":"markdown","0a6f491a":"markdown","ddf2aea5":"markdown","c55f6a30":"markdown","32d262fe":"markdown","0f3d1eb1":"markdown","66a2ecfd":"markdown","b4fbcb56":"markdown","40e7384a":"markdown","0d4160cd":"markdown","b3ffc974":"markdown","2f7b4407":"markdown","7e4e6b34":"markdown","d4f317ee":"markdown","147de573":"markdown","13ac2593":"markdown","83adcc02":"markdown"},"source":{"bde092ae":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import RMSprop\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model\n\nimport numpy as np\n\nfrom IPython.display import SVG\n\nfrom datetime import datetime","64cf0332":"BATCH = 128\ndatagen = ImageDataGenerator(rescale=1.\/255)\n\n\n    \ntrain_data = datagen.flow_from_directory('\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train',\n                                        target_size=(150, 150),\n                                        batch_size=BATCH,\n                                        class_mode='categorical',\n                                        shuffle=True)\n\ntest_data = datagen.flow_from_directory('\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test',\n                                        target_size=(150, 150),\n                                        batch_size=BATCH,\n                                        class_mode='categorical',\n                                        shuffle=True)","3fcf1ad7":"train_data.class_indices","fd7fd1ad":"EPOCHS = 15","abad6fde":"import subprocess\nimport pprint\n\nsp = subprocess.Popen(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\nout_str = sp.communicate()\nout_list = str(out_str[0]).split('\\\\n')\n\nout_dict = {}\n\nfor item in out_list:\n    print(item)","227e941c":"def saveModel(model, filename):\n    model.summary()\n    plot_model(model,to_file=filename,show_shapes=True, expand_nested=True)","9648912c":"def addDenseLayers(model):\n    denseLayers = [\n        layers.Dense(1024, activation='relu'),\n        layers.Dense(256, activation='relu'),\n        layers.Dense(64, activation='relu'),\n        layers.Dense(6, activation='softmax')\n    ]\n    for layer in denseLayers:\n        model.add(layer)","24759d24":"model = Sequential([\n    layers.Conv2D(3, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.Flatten(),\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model1.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","143304f4":"model = Sequential([\n    layers.Conv2D(3, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model1_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","7ae661cb":"model = Sequential([\n    layers.Conv2D(3, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model2.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","f7bbbd2c":"model = Sequential([\n    layers.Conv2D(3, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model2_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","a0ad2d05":"model = Sequential([\n    layers.Conv2D(6, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model3.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","5f7cbdd1":"model = Sequential([\n    layers.Conv2D(6, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model3_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","32066e08":"model = Sequential([\n    layers.Conv2D(6, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model4.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","87cd03b8":"model = Sequential([\n    layers.Conv2D(6, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model4_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","945e2918":"model = Sequential([\n    layers.Conv2D(12, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model5.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","c5fdb8dd":"model = Sequential([\n    layers.Conv2D(12, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model5_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","9161e7ca":"model = Sequential([\n    layers.Conv2D(12, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model6.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","c5062136":"model = Sequential([\n    layers.Conv2D(12, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model6_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","01a6d100":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(6, (3, 3), activation = 'relu', padding = 'same'),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model7.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","f0df5390":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(6, (3, 3), activation = 'relu', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model7_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","d3217811":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(6, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model8.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","6f00b1d9":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(6, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model8_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","7b1ac841":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model9.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","d717dceb":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model9_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","c6444900":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model10.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","80489e8a":"model = Sequential([\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model10_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","a17c277f":"model = Sequential([\n    layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model11.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","75f32c85":"model = Sequential([\n    layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model11_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","dbd284d5":"model = Sequential([\n    layers.Conv2D(128, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(64, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model12.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","a1e61f43":"model = Sequential([\n    layers.Conv2D(128, (3, 3), activation = 'tanh', padding = 'same', input_shape = (150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(64, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(32, (3, 3), activation = 'tanh', padding = 'same'),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten()\n])\naddDenseLayers(model)\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nsaveModel(model, 'model12_pooling.png')\n\ntime_start = datetime.now()\nhistory = model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\nprint('Time: ', datetime.now() - time_start)","1ce904ab":"---","1c8707bd":"### \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21161","10929218":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","ea503465":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","954489d1":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","875b1f9c":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","8a2b28b0":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","2a0997f4":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f 5\n\u041f\u0440\u043e\u0434\u043e\u043b\u0436\u0438\u043c \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0442\u044c \u0447\u0438\u0441\u043b\u043e \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0438 \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u043f\u043e\u043a\u0430 \u0432\u0441\u0451 \u0442\u0430\u043a \u0436\u0435 \u043e\u0434\u0438\u043d \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u0439 \u0441\u043b\u043e\u0439. \u0413\u0438\u043f\u043e\u0442\u0435\u0437\u0430: \u0437\u0430\u043c\u0435\u0442\u043d\u043e\u0439 \u043f\u0440\u0438\u0431\u0430\u0432\u043a\u0438 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u044d\u0442\u043e \u043d\u0435 \u0434\u0430\u0441\u0442.","102ff7a4":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","8cb19e98":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","acc68956":"\u0412\u0432\u0435\u0434\u0451\u043c \u0435\u0449\u0451 \u043e\u0434\u0438\u043d \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u0439 \u0441\u043b\u043e\u0439. \u041f\u0435\u0440\u0432\u044b\u0439 \u0441\u043b\u043e\u0439 \u0431\u0443\u0434\u0435\u0442 \u0438\u043c\u0435\u0442\u044c 32 \u0444\u0438\u043b\u044c\u0442\u0440\u0430, \u0432\u0442\u043e\u0440\u043e\u0439 - 6 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432. \u0422\u0430\u043a\u0430\u044f \"\u0434\u0432\u0443\u0445\u0443\u0440\u043e\u0432\u043d\u0435\u0432\u0430\u044f\" \u0441\u0432\u0451\u0440\u0442\u043a\u0430 \u0438\u043c\u0435\u0435\u0442 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0443\u044e \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0446\u0438\u044e: \u0441\u043f\u0435\u0440\u0432\u0430 \u043c\u044b \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0442\u044c \u0431\u043e\u043b\u0435\u0435 \u0441\u043b\u043e\u0436\u043d\u044b\u0435 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u0430 \u0437\u0430\u0442\u0435\u043c \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u0432\u044b\u0445\u043e\u0434\u0430 \u043f\u0440\u043e\u0432\u0435\u0434\u0451\u043c \u0443\u0436\u0435 \u043f\u0440\u0438\u0432\u044b\u0447\u043d\u0443\u044e \u0441\u0432\u0451\u0440\u0442\u043a\u0443 \u0441 6 \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u043c\u0438, \u0432\u044b\u0445\u043e\u0434 \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u043e\u0436\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0442\u0430\u043a: \u043f\u0438\u043a\u0441\u0435\u043b\u044e \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u0439 \u0435\u043c\u0443 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0438\u043d\u0430\u0434\u043b\u0435\u0436\u043d\u043e\u0441\u0442\u0438 \u043a \u043e\u0434\u043d\u043e\u043c\u0443 \u0438\u0437 \u043a\u043b\u0430\u0441\u0441\u043e\u0432. \u0415\u0441\u043b\u0438 \u0441\u043e\u0439\u0434\u0443\u0442\u0441\u044f \u0437\u0432\u0451\u0437\u0434\u044b, \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0440\u043e\u0441\u0442 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438.","e3f36bea":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","9832f5a4":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","cac77975":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21163","445dfba7":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","9b50f0d8":"### \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","27065ba4":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","8b523d1a":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","f4f3f18d":"\u041f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0432\u0441\u0451 \u0442\u0430\u043a \u0436\u0435 \u0438\u043c\u0435\u0435\u0442 \u043c\u0435\u0441\u0442\u043e \u0431\u044b\u0442\u044c, \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0441\u043d\u0438\u0437\u0438\u0442\u044c \u0435\u0433\u043e \u0432\u043b\u0438\u044f\u043d\u0438\u0435, \u0434\u043e\u0431\u0430\u0432\u0438\u0432 \u0435\u0449\u0451 \u043e\u0434\u0438\u043d \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u0439 \u0441\u043b\u043e\u0439.","ff1dfd68":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","921d2319":"\u0423\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0447\u0438\u0441\u043b\u043e \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0432\u043e \u0432\u0442\u043e\u0440\u043e\u0439 \u0441\u0432\u0451\u0440\u0442\u043a\u0435 \u0434\u043e 32.","7d05e614":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","e1ab5be9":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21166","7d2c7e73":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","49546269":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21167","4d9b8463":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","d88bd3d4":"\u041d\u0430\u0447\u043d\u0451\u043c \u0441\u043e \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0438 \u0441 \u043e\u0434\u043d\u0438\u043c \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u043c \u0441\u043b\u043e\u0435\u043c \u0438 \u0447\u0438\u0441\u043b\u043e\u043c \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0440\u0430\u0432\u043d\u044b\u043c 3 (\u0432 \u0434\u0432\u0430 \u0440\u0430\u0437\u0430 \u043c\u0435\u043d\u044c\u0448\u0435, \u0447\u0435\u043c \u0447\u0438\u0441\u043b\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432):","5af43b9b":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u211611","72259259":"### \u0410\u043d\u0430\u043b\u0438\u0437 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432:\n* \u041a\u0430\u043a \u0438 \u043e\u0436\u0438\u0434\u0430\u043b\u043e\u0441\u044c, \u0441\u043a\u043e\u043b\u044c-\u043d\u0438\u0431\u0443\u0434\u044c \u043e\u0449\u0443\u0442\u0438\u043c\u043e\u0439 \u043f\u0440\u0438\u0431\u0430\u0432\u043a\u0438 \u0432 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043f\u043e \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044e \u0441 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0439 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0435\u0439 \u043c\u044b \u043d\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438\n* \u0414\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0435 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435 \u0447\u0438\u0441\u043b\u0430 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u043f\u0440\u0438 \u043e\u0434\u043d\u043e\u043c \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u043c \u0441\u043b\u043e\u0435 \u043e\u0441\u043e\u0431\u043e \u0441\u043c\u044b\u0441\u043b\u0430 \u043d\u0435 \u0438\u043c\u0435\u0435\u0442: \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f 12 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0432\u043c\u0435\u0441\u0442\u043e 6 (\u0447\u0438\u0441\u043b\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432), \u043c\u044b \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u0438\u043a\u0441\u0435\u043b\u0438 \u0443\u0436\u0435 \u043d\u0435 \u043d\u0430 6 \u043a\u043b\u0430\u0441\u0441\u043e\u0432, \u0430 \u043d\u0430 12, \u043d\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0442\u0430\u043a\u043e\u0439 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e (\u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u0432 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0443 \u043d\u0430\u0441 \u0432\u0441\u0435\u0433\u043e 6 \u043a\u043b\u0430\u0441\u0441\u043e\u0432).\n---","ae671c20":"\u0410\u043d\u0430\u043b\u0438\u0437 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430:\n* \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043d\u0430 20% \u0432\u044b\u0448\u0435, \u0447\u0435\u043c \u043b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442, \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0439 \u0432 \u043f\u0435\u0440\u0432\u043e\u0439 \u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u0435 (\u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0435 \u0441\u0435\u0442\u0438);\n* \u0442\u0435\u043c \u043d\u0435 \u043c\u0435\u043d\u0435\u0435, \u0435\u0441\u0442\u044c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0451\u043d\u043d\u0430\u044f \u0443\u0432\u0435\u0440\u0435\u043d\u043d\u043e\u0441\u0442\u044c, \u0447\u0442\u043e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043c\u043e\u0436\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0431\u044b\u0441\u0442\u0440\u043e\u0435 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 (\u0443\u0436\u0435 \u043d\u0430 \u0447\u0435\u0442\u0432\u0451\u0440\u0442\u043e\u0439 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0431\u043e\u043b\u044c\u0448\u0435 \u0447\u0435\u043c \u043d\u0430 30% \u0432\u044b\u0448\u0435, \u0447\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0438 \u043f\u043e\u0447\u0442\u0438 \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f.\n* \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0436\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0437\u0430 \u0441\u0447\u0451\u0442 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u044f \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0432 \u0441\u0435\u0442\u0438 \u043a\u0430\u043a \u043c\u0438\u043d\u0438\u043c\u0443\u043c \u0434\u043e \u0447\u0438\u0441\u043b\u0430 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0438 \u0434\u0430\u043b\u044c\u0448\u0435. \u042d\u0442\u043e \u043e\u0431\u044a\u044f\u0441\u043d\u044f\u0435\u0442\u0441\u044f \u0442\u0435\u043c, \u0447\u0442\u043e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0439 \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435 \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f \u0442\u0440\u0451\u0445\u043c\u0435\u0440\u043d\u044b\u0439 \u0442\u0435\u043d\u0437\u043e\u0440 \u043c\u043e\u0436\u043d\u043e \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0442\u044c \u043a\u0430\u043a \u043f\u0438\u043a\u0441\u0435\u043b\u044c \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0430\u044f \u0435\u043c\u0443 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u043d\u0430\u0434\u043b\u0435\u0436\u043d\u043e\u0441\u0442\u0438 \u0435\u0433\u043e \u043a \u043e\u0434\u043d\u043e\u043c\u0443 \u0438\u0437 \u043a\u043b\u0430\u0441\u0441\u043e\u0432. \u0414\u043b\u044f \u0442\u0430\u043a\u043e\u0439 \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0446\u0438\u0438 \u043f\u043e\u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u043a\u0430\u043a \u043c\u0438\u043d\u0438\u043c\u0443\u043c 6 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 (\u0447\u0438\u0441\u043b\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u0437\u0430\u0434\u0430\u0447\u0435). \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043d\u0430\u0448\u0443 \u0442\u0435\u043e\u0440\u0438\u044e \u0432 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0438.\n---","64b961cc":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21162","9d05a711":"\u0412\u0430\u0440\u044c\u0438\u0440\u0443\u0435\u043c\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b:\n* \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 (32, 64, 128)\n* \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u0445 \u0441\u043b\u043e\u0451\u0432 (\u0442\u0440\u043e\u0435\u043a, \u0441\u043e\u0441\u0442\u043e\u044f\u0449\u0438\u0445 \u0438\u0437 \u0441\u0432\u0451\u0440\u0442\u043a\u0438, \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438 \u0438 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044f)\n* \u0412\u0438\u0434 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438","24e39c19":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","fa759713":"\u0417\u0430\u0434\u0430\u0434\u0438\u043c \u043e\u0431\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0439 \u0440\u0430\u0432\u043d\u043e\u0435 **20**.","0a6f491a":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","ddf2aea5":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21164","c55f6a30":"## \u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 \u21163","32d262fe":"## GPU Info","0f3d1eb1":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","66a2ecfd":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","b4fbcb56":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u211612","40e7384a":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","0d4160cd":"## \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21168","b3ffc974":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","2f7b4407":"\u0421 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","7e4e6b34":"### \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u211610","d4f317ee":"### \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u21169","147de573":"### \u0410\u043d\u0430\u043b\u0438\u0437 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432\n* \u043c\u044b \u0443\u043b\u0443\u0447\u0448\u0438\u043b\u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043f\u043e\u0447\u0442\u0438 \u043d\u0430 10 \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u043e\u0432, \u044d\u0442\u043e \u0440\u0430\u0434\u0443\u0435\u0442\n* \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u0441\u043d\u0438\u0437\u0438\u0442\u044c \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u0442\u0430\u043a \u043d\u0430 \u0447\u0435\u0442\u0432\u0451\u0440\u0442\u043e\u0439 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438 \u0440\u0430\u0437\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0441\u043e\u043a\u0440\u0430\u0442\u0438\u043b\u0430\u0441\u044c \u043d\u0430 10% \u043f\u043e \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044e \u0441 \u043f\u0440\u043e\u0448\u043b\u043e\u0439 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0435\u0439\n* \u043d\u0430\u0448\u0430 \u0442\u0435\u043e\u0440\u0438\u044f \u043e \u0442\u043e\u043c, \u0447\u0442\u043e \u0447\u0438\u0441\u043b\u043e \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0434\u043e\u043b\u0436\u043d\u043e \u0431\u044b\u0442\u044c \u043a\u0430\u043a \u043c\u0438\u043d\u0438\u043c\u0443\u043c \u0440\u0430\u0432\u043d\u043e \u0447\u0438\u0441\u043b\u0443 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u043f\u043e\u0434\u0442\u0432\u0435\u0440\u0434\u0438\u043b\u0430\u0441\u044c \u0438 \u0434\u0430\u043b\u0430 \u0437\u0430\u043a\u043e\u043d\u043e\u043c\u0435\u0440\u043d\u0443\u044e \u043f\u0440\u0438\u0431\u0430\u0432\u043a\u0443 \u0432 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438\n---","13ac2593":"\u0411\u0435\u0437 max pooling \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f:","83adcc02":"### \u0418\u043c\u043f\u043e\u0440\u0442\u044b"}}