{"cell_type":{"77401e7c":"code","edafa108":"code","a2e393ba":"code","900bb45d":"code","641e3f88":"code","2e95fbef":"code","3f8b6fa6":"code","fd2853d3":"code","2705b7a7":"code","0b01fd3e":"code","8c58967f":"code","93cf97e4":"code","6d1e13c0":"code","a91440ca":"code","aea08436":"code","adb53923":"code","65e03ec5":"code","6cf81613":"code","2b0151cc":"code","96694d6d":"code","2c52adc5":"code","166666eb":"markdown","507b073f":"markdown","493fc66a":"markdown","70aaaa2b":"markdown","ab90d765":"markdown","c1adf9ec":"markdown","61063859":"markdown","1add7cba":"markdown"},"source":{"77401e7c":"import os\nfrom PIL import Image\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torch.autograd import Variable\nfrom torchvision import datasets, models, transforms\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nplt.ion()   # interactive mode\n\nimport time\nfrom tqdm import tqdm, trange\ntqdm.pandas()\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfrom shutil import copyfile\nprint(os.listdir(\"..\/input\"))","edafa108":"train_df = pd.read_csv('..\/input\/train\/train.csv')\ntest_df = pd.read_csv('..\/input\/test\/test.csv')\ntest_df['AdoptionSpeed'] = [-1] * len(test_df)\ndata_df = pd.concat([train_df, test_df], axis=0).reset_index()\nprint(train_df.shape[0], test_df.shape[0], data_df.shape[0])","a2e393ba":"data_df.head(2)","900bb45d":"def pil_loader(path):\n    # open path as file to avoid ResourceWarning (https:\/\/github.com\/python-pillow\/Pillow\/issues\/835)\n    with open(path, 'rb') as f:\n        img = Image.open(f)\n        return img.convert('RGB')\n\n\ndef accimage_loader(path):\n    import accimage\n    try:\n        return accimage.Image(path)\n    except IOError:\n        # Potentially a decoding problem, fall back to PIL.Image\n        return pil_loader(path)\n\n\ndef default_loader(path):\n    from torchvision import get_image_backend\n    if get_image_backend() == 'accimage':\n        return accimage_loader(path)\n    else:\n        return pil_loader(path)\n\nclass DogCatDataset(Dataset):\n    \"\"\"Dog Cat classify dataset.\"\"\"\n    \n    def __init__(self, data_df, root_dir='..\/input\/', train_or_valid='train', transform=None):\n        super(DogCatDataset, self).__init__()\n        self.classes = ['dog', 'cat']\n        self.class_to_idx = {'dog':0, 'cat':1}\n        \n        self.transform = transform\n        self.img_list = [] # read train\/valid image path\n        petids = data_df['PetID'].values\n        for petid in tqdm(petids):\n            row = data_df.loc[data_df['PetID'] == petid, :]\n            anim_type = 'cat' if row['Type'].values[0] == 2 else 'dog'\n            photo_amt = row['PhotoAmt'].values[0]\n            img_type = 'train' if row['AdoptionSpeed'].values[0] >= 0 else 'test'\n            \n            if train_or_valid == 'train':\n                for i in range(2, int(photo_amt) + 1):\n                    img_path = f'{root_dir}{img_type}_images\/{petid}-{i}.jpg'\n                    if not os.path.exists(img_path): continue\n                    self.img_list.append((img_path, self.class_to_idx[anim_type]))\n            else:  # valid\n                img_path = f'{root_dir}{img_type}_images\/{petid}-1.jpg'\n                if not os.path.exists(img_path): continue\n                self.img_list.append((img_path, self.class_to_idx[anim_type]))\n    \n    def __len__(self):\n        return len(self.img_list)\n    \n    def __getitem__(self, index):\n        path, target = self.img_list[index]\n        image = default_loader(path)\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, target\n        ","641e3f88":"batch_size = 64\n\nimage_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\nimage_datasets = {x: DogCatDataset(data_df, train_or_valid=x, transform=image_transforms[x])\n                  for x in ['train', 'valid']}\n\ndataloaders = {x: torch.utils.data.dataloader.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)#, num_workers=4)\n               for x in ['train', 'valid']}","2e95fbef":"print('Train:', len(image_datasets['train']), ', Valid:', len(image_datasets['valid']))\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\nclass_names = image_datasets['train'].classes\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint('class:', class_names)\nprint('device:', device)","3f8b6fa6":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.figure(figsize=(16, 6))\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.show()","fd2853d3":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs[:4])\nimshow(out, title=[class_names[x] for x in classes[:4]])","2705b7a7":"model = models.resnet18(pretrained=True)\nfc_in_features = model.fc.in_features\nmodel.fc = nn.Linear(fc_in_features, 2)\nmodel = model.to(device)\n\nloss_fn = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","0b01fd3e":"epochs = 6\n\nbest_valid_loss = np.inf\nbest_valid_acc = 0.\nbest_model_wts = copy.deepcopy(model.state_dict())\ndidnt_improve_count = 0\n\nfor epoch in range(epochs):\n    start_time = time.time()\n    # set train mode\n    model.train()\n    avg_train_loss = 0.\n    train_corrects = 0.\n    \n    for x_batch, y_batch in dataloaders['train']:\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n        \n        y_pred = model(x_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        avg_train_loss += loss.item() \/ len(dataloaders['train'])\n        \n        _, y_pred = torch.max(y_pred, 1)\n        train_corrects += torch.sum(y_pred == y_batch.data).double()\n    \n    train_acc = train_corrects \/ dataset_sizes['train']\n    \n    torch.cuda.empty_cache()\n    \n    model.eval()\n    avg_val_loss = 0.\n    valid_corrects = 0.\n    for x_batch, y_batch in dataloaders['valid']:\n        with torch.no_grad():\n            x_batch = x_batch.to(device)\n            y_batch = y_batch.to(device)\n        \n            y_pred = model(x_batch)\n            loss = loss_fn(y_pred, y_batch)\n            avg_val_loss += loss.item() \/ len(dataloaders['valid'])\n        \n            _, y_pred = torch.max(y_pred, 1)\n            valid_corrects += torch.sum(y_pred == y_batch.data).double()\n    \n    valid_acc = valid_corrects \/ dataset_sizes['valid']\n    \n    elapsed_time = time.time() - start_time \n    print('Epoch {}\/{}  train-loss={:.4f}  train-acc={:.4f}  val_loss={:.4f}  valid-acc={:.4f}  time={:.2f}s'.format(\n        epoch + 1, epochs, avg_train_loss, train_acc, avg_val_loss, valid_acc, elapsed_time))\n    \n    # deep copy the model\n    if avg_val_loss < best_valid_loss:\n        best_valid_loss = avg_val_loss\n        best_valid_acc = valid_acc\n        didnt_improve_count = 0\n        best_model_wts = copy.deepcopy(model.state_dict())\n    else:\n        didnt_improve_count += 1\n        if didnt_improve_count > 2:\n            break\n    \nprint('Best valid-loss={:.4f} \\t valid-acc={:.4f}'.format(best_valid_loss, best_valid_acc))\nprint('save and load best model weights')\nmodel.load_state_dict(best_model_wts)\ntorch.save(model.state_dict(), 'best_resnet18_weights.model')","8c58967f":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\ninputs, classes = inputs[:4], classes[:4]\nground_truth = [class_names[i] for i in classes]\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\ninputs = inputs.cuda()\npreds = model(inputs)\n_, preds = torch.max(preds, 1)\npredict_class = [class_names[i] for i in preds]\nimshow(out, title=f\"Truth : {ground_truth}\\nPredict: {predict_class}\")","93cf97e4":"image_features = []\ndef hook_feature(module, input, output):\n    # hook the feature extractor\n    image_features.append(np.squeeze(output.data.cpu().numpy()))\n\nmodel._modules.get('avgpool').register_forward_hook(hook_feature)","6d1e13c0":"extract_transform = image_transforms['valid']","a91440ca":"train_pids = train_df.PetID.values\ninput_tensor = torch.zeros(1, 3, 224, 224)\n\ntrain_image_features = {}\nfor petid in tqdm(train_pids):\n    train_img = f\"..\/input\/train_images\/{petid}-1.jpg\"\n    if not os.path.exists(train_img): continue\n    \n    train_img = Image.open(train_img)\n    train_img = extract_transform(train_img)\n    input_tensor[0, :, :, :] = train_img\n    input_tensor = input_tensor.cuda()\n    model(input_tensor)\n    train_image_features[petid] = image_features[0]\n    image_features.clear()\n","aea08436":"train_image_features = pd.DataFrame.from_dict(train_image_features, orient='index')\ntrain_image_features.columns = [f'img_nn_feat{idx}' for idx in train_image_features.columns.values]\ntrain_image_features = train_image_features.reset_index().rename(columns={'index':'PetID'})","adb53923":"train_image_features.head()","65e03ec5":"train_image_features.to_csv('train_image_features.csv', index=False)","6cf81613":"test_pids = test_df.PetID.values\ninput_tensor = torch.zeros(1, 3, 224, 224)\n\ntest_image_features = {}\nfor petid in tqdm(test_pids):\n    test_img = f\"..\/input\/test_images\/{petid}-1.jpg\"\n    if not os.path.exists(test_img): continue\n    \n    test_img = Image.open(test_img)\n    test_img = extract_transform(test_img)\n    input_tensor[0, :, :, :] = test_img\n    input_tensor = input_tensor.cuda()\n    model(input_tensor)\n    test_image_features[petid] = image_features[0]\n    image_features.clear()\n","2b0151cc":"test_image_features = pd.DataFrame.from_dict(test_image_features, orient='index')\ntest_image_features.columns = [f'img_nn_feat{idx}' for idx in test_image_features.columns.values]\ntest_image_features = test_image_features.reset_index().rename(columns={'index':'PetID'})","96694d6d":"test_image_features.head()","2c52adc5":"test_image_features.to_csv('test_image_features.csv', index=False)","166666eb":"## Extract Test Image Features","507b073f":"We save the features as a csv to disk, so others can link and join the data frame with their train.csv and test.csv","493fc66a":"## Finetuning the pretrained model","70aaaa2b":"Pretrained Neural Networks like VGG16\/VGG19\/ResNet\/DenseNet are trained on ImageNet which contains 1000-class images. This competition just contains two classes: cat and dog. In this kernel, I want to demonstrate how to build a model with **Pytorch** to classify dog or cat to **Finetuning the convnet**, and then **fix ConvNet to extract image features**. \n\nThis include four steps:\n\n- Build Dog\/Cat classify dataset for supervised training.\n- Prepare dataset for Pytorch.\n- Fintune pretrained ResNet-18 model.\n- Fixed ConvNet to extract image features.\n\nReference:\n\n- [Extract Image features from pretrained NN](https:\/\/www.kaggle.com\/christofhenkel\/extract-image-features-from-pretrained-nn)\n- [Transfer Learning Using Pytorch](https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html)\n\n**Please UPVOTE if you find it useful** :)","ab90d765":"## Visualize a few images","c1adf9ec":"## Extract Train Image Features","61063859":"## Split Dog\/Cat images for supervised training","1add7cba":"Here we use `PetID-1.jpg`(default profile) image for valid image per PetId, and finally we have 68350 training images and 5000 valid images, the `cat : dog = 1 : 1`"}}