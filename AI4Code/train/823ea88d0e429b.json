{"cell_type":{"be5ca5d7":"code","6ff75d56":"code","493a20d9":"code","df099602":"code","99485e8e":"code","b316ca3b":"code","7acf8954":"code","b19cd730":"code","2d3e6a7d":"code","1718c330":"code","4e43e879":"code","b49aa1b5":"code","9a57f166":"code","36cf72e0":"code","663d0bdb":"code","a3e00ca4":"code","9d6b8bba":"code","17c54b34":"code","30103394":"code","137c01b3":"code","9775f580":"code","59d3e848":"code","5d86d66a":"code","72c45798":"code","68963ab1":"code","11b9d554":"code","c0f279a5":"code","fbeada94":"code","f6f79708":"code","a6fa3674":"code","d651e5a3":"code","a68b59ee":"code","0a874711":"code","b80a7755":"code","e8e7888a":"code","5ef7f472":"code","98b1a848":"code","6a62240e":"code","465bf03f":"code","9882c496":"code","07baf6a2":"code","0405de1c":"code","7deb1019":"code","ed1f5bd9":"code","3187c526":"code","b3f5c550":"code","109e8785":"code","5523eece":"code","99f873bd":"code","1a579e16":"code","99a36130":"code","aa0965e1":"code","4337cbf5":"code","8a8dbebb":"code","41c077a5":"code","171d349f":"code","448c1ba0":"code","9854c97c":"code","d9f0105f":"markdown","d0d70b1f":"markdown","00cb129e":"markdown","c2010019":"markdown","f613bbe8":"markdown","5e43702e":"markdown","1a8f9c7d":"markdown","36eca979":"markdown"},"source":{"be5ca5d7":"from sklearn.ensemble import RandomForestClassifier\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nimport xml.etree.ElementTree as Xet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom scipy import stats\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nimport itertools\n%matplotlib inline\nsns.set(rc={'figure.figsize': [10, 10]}, font_scale=1.2)\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6ff75d56":"def normalize_column(df,column):\n    return MinMaxScaler().fit_transform(np.array(df[column]).reshape(-1,1))\n    \n","493a20d9":"dataset_path = r'..\/input\/car-crashes-severity-prediction'\n\ndf = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\n\ndf.head()","df099602":"df.describe()","99485e8e":"def plott(df,col1,col2):\n    CrosstabResult=pd.crosstab(index=df[col1],columns=df[col2])\n    print(CrosstabResult)\n    %matplotlib inline \n    CrosstabResult.plot.bar()","b316ca3b":"df = df.drop(columns=['ID', 'Bump', 'No_Exit', 'Give_Way', 'Roundabout'])\ndf","7acf8954":"df['timestamp']","b19cd730":"df['timestamp_hour'] = pd.to_datetime(df['timestamp'])\ndf['timestamp_hour'] = df['timestamp_hour'].dt.strftime('%Y-%m-%d %H')\ndf['timestamp_normal'] = pd.to_datetime(df['timestamp'])\ndf['timestamp_normal'] = df['timestamp_normal'].dt.strftime('%Y-%m-%d')\n\ndf['Date']= pd.to_datetime(df['timestamp'])\n\n\ndf['day'] = df['Date'].dt.day\ndf['month'] = df['Date'].dt.month\ndf['year'] = df['Date'].dt.year\ndf['hour'] = df['Date'].dt.hour\n\n\ndf['x']=np.cos(df['Lat']) * np.cos(df['Lng'])\ndf['y']=np.cos(df['Lat']) * np.sin(df['Lng'])\ndf['z']=np.sin(df['Lat'])\ndf['loc']=df['x']*df['y']*df['z']\n\ndf","2d3e6a7d":"df.plot(x ='x', y='Severity', kind = 'scatter')\nplt.show()\n","1718c330":"df.plot(x ='y', y='Severity', kind = 'scatter')\nplt.show()","4e43e879":"df.plot(x ='z', y='Severity', kind = 'scatter')\nplt.show()","b49aa1b5":"df.plot(x ='loc', y='Severity', kind = 'scatter')\nplt.show()","9a57f166":"def encoding(dataset, cols):\n    for col_name in cols:\n        if dataset[col_name].dtypes == 'bool':\n            dataset[col_name] = dataset[col_name].astype(int)\n        else:\n            dataset[col_name] = dataset[col_name].replace({'L': 1, 'R': 0})\n            \n    return dataset","36cf72e0":"df = encoding(df, ['Crossing', 'Junction', 'Railway', 'Stop', 'Amenity', 'Side'])\ndf.describe()\n","663d0bdb":"df","a3e00ca4":"df.plot(x ='Distance(mi)', y='Severity', kind = 'scatter')\nplt.show()","9d6b8bba":"df.plot(x ='Side', y='Severity', kind = 'scatter')\nplt.show()\n\nplott(df,'Side','Severity')","17c54b34":"df.plot(x ='Amenity', y='Severity', kind = 'scatter')\nplt.show()\nplott(df,'Amenity','Severity')","30103394":"df.plot(x ='year', y='Severity', kind = 'scatter')\nplt.show()\nplott(df,'year','Severity')","137c01b3":"df.plot(x ='month', y='Severity', kind = 'scatter')\nplt.show()\nplott(df,'month','Severity')","9775f580":"df.plot(x ='day', y='Severity', kind = 'scatter')\nplt.show()\nplott(df,'day','Severity')","59d3e848":"df.plot(x ='hour', y='Severity', kind = 'scatter')\nplt.show()\nplott(df,'hour','Severity')","5d86d66a":"df.plot(x ='Date', y='Severity', kind = 'scatter')\nplt.show()\n","72c45798":"def read_xml(file_path):\n    cols = ['date', 'description']\n    rows = []\n\n    # Parsing the XML file\n    xmlparse = Xet.parse(file_path)\n    root = xmlparse.getroot()\n\n    for i in root:\n        description = i.find(\"description\").text\n        date = i.find(\"date\").text\n\n        rows.append({\"description\": description,\n                     \"date\": date})\n    \n    return pd.DataFrame(rows, columns=cols)","68963ab1":"df_holiday = read_xml(os.path.join(dataset_path, 'holidays.xml'))\n\ndf_holiday","11b9d554":"df_holiday['description'].value_counts()","c0f279a5":"df_merged = pd.merge(df_holiday, df, left_on='date', right_on='timestamp_normal', how='right')\n\ndf_merged\n\n","fbeada94":"df_merged['description'].describe()","f6f79708":"df_merged['description'] = df_merged['description'].apply(lambda x: 0 if x is np.nan else 1)\ndf_merged\n","a6fa3674":"df_merged['description'].describe()","d651e5a3":"plott(df_merged,'description','Severity')","a68b59ee":"df_weather = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df_weather.shape))\n\ndf_weather.head()","0a874711":"df_weather['timestamp_weather'] = df_weather['Year'].astype(str) + '-' + df_weather['Month'].astype(str)  + '-' + df_weather['Day'].astype(str) + ' ' + df_weather['Hour'].astype(str)\ndf_weather['timestamp_weather']\ndf_weather['timestamp'] = df_weather['Year'].astype(str) + '-' + df_weather['Month'].astype(str)  + '-' + df_weather['Day'].astype(str)\ndf_weather['timestamp']\ndf_weather\n","b80a7755":"weather_dict = {\n    np.nan : 1,\n    'Clear':                    1,\n    'Fair':                     2,\n    'Fair \/ Windy':             3,\n    'Mist':                     4,\n    'Shallow Fog':              5,\n    'Haze':                     6,\n    'Fog':                      7,\n    'Smoke':                    8,\n    'Partly Cloudy':            9,\n    'Partly Cloudy \/ Windy':    10,\n    'Mostly Cloudy':            11,\n    'Mostly Cloudy \/ Windy':    12,\n    'Scattered Clouds':         13,\n    'Cloudy':                   14,\n    'Cloudy \/ Windy':           15,\n    'Overcast':                 16,\n    'Light Rain':               17,\n    'Light Rain \/ Windy':       18,\n    'Rain':                     19,\n    'Heavy Rain':               20\n}\n\n# apply using map\ndf_weather['Weather_Condition'] = df_weather['Weather_Condition'].map(weather_dict)\ndf_weather","e8e7888a":"df_weather=df_weather.dropna()\n\ndf_weather.drop_duplicates(subset=['timestamp_weather'], keep='first',inplace=True)\n","5ef7f472":"df_weather\n","98b1a848":"df_weather = df_weather.drop(columns=['Year','Day','Month','Hour'])\n\n\ndf_final = pd.merge(df_weather, df_merged, left_on='timestamp_weather', right_on='timestamp_hour', how='right')\n\ndf_final\n","6a62240e":"names=['Weather_Condition',\"Wind_Chill(F)\",'Precipitation(in)','Temperature(F)','Humidity(%)','Wind_Speed(mph)','Visibility(mi)']\n\nfor i in names:\n    df_final[i].fillna(df_final[i].median(), inplace=True)\ndf_final\n\ndf_final","465bf03f":"names=['Weather_Condition',\"Wind_Chill(F)\",'Precipitation(in)','Temperature(F)','Humidity(%)','Wind_Speed(mph)','Visibility(mi)']\n\nfor i in names:\n    df_final[i]=normalize_column(df_final,i)\n    \n\nnames=['day','month','year','hour','x','y','z','loc']\nfor i in names:\n    df_final[i]=normalize_column(df_final,i)\n    ","9882c496":"df_final","07baf6a2":"\n# playing with model\ndf_selected = df_final[[\n'description',\n'Crossing',\n'Junction',\n'Railway',\n'Stop',\n#'Amenity',\n'Side',\n#'loc',\n'x',\n'y',\n'z',\n#'Lat',\n# 'Lng',\n'Distance(mi)',\n'Severity',\n'day' ,\n#'month',\n'year',\n#'hour',\n'Weather_Condition',\n\"Wind_Chill(F)\",\n'Precipitation(in)',\n'Temperature(F)',\n'Humidity(%)',\n'Wind_Speed(mph)',\n'Visibility(mi)'\n]]\n\n[ 'Distance(mi)', 'year',   'description', 'y', 'Crossing', 'loc' ]  \n\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\ncv = KFold(n_splits=5, random_state=1, shuffle=True) \n\n\n#build multiple linear regression model\nX = df_selected.drop(columns=['Severity'])\ny = df_selected['Severity']\n\n\n#use LOOCV to evaluate model\nscores = cross_val_score(classifier, X, y,\n                         cv=cv, n_jobs=-1)\nprint(scores)\n","0405de1c":"print(np.mean(scores))","7deb1019":"# val_df >> test_df                -   X_train, X_test, y_train, y_test\ntrain_df, val_df = train_test_split(df_selected, test_size=.2, random_state=42) \n\nX_train = train_df.drop(columns=['Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['Severity'])\ny_val = val_df['Severity']\n\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)\nprint(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","ed1f5bd9":"# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)\nprint(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","3187c526":"test_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\ntest_df","b3f5c550":"test_df = test_df.drop(columns=[ 'Bump', 'No_Exit', 'Give_Way', 'Roundabout'])\n\ntest_df['timestamp_hour'] = pd.to_datetime(test_df['timestamp'])\ntest_df['timestamp_hour'] = test_df['timestamp_hour'].dt.strftime('%Y-%m-%d %H')\ntest_df","109e8785":"test_df = encoding(test_df, ['Crossing', 'Junction', 'Railway', 'Stop', 'Amenity', 'Side'])\ntest_df","5523eece":"df_merged = pd.merge(df_holiday, test_df, left_on='date', right_on='timestamp', how='right')\ndf_merged['description'] = df_merged['description'].apply(lambda x: 0 if x is np.nan else 1)\ndf_merged = df_merged.drop(['date'], axis = 1)\ndf_merged\n\ndf=df_merged","99f873bd":"\ndf['Date']= pd.to_datetime(df['timestamp'])\n\n\ndf['day'] = df['Date'].dt.day\ndf['month'] = df['Date'].dt.month\ndf['year'] = df['Date'].dt.year\ndf['hour'] = df['Date'].dt.hour\n\n\ndf['x']=np.cos(df['Lat']) * np.cos(df['Lng'])\ndf['y']=np.cos(df['Lat']) * np.sin(df['Lng'])\ndf['z']=np.sin(df['Lat'])\ndf['loc']=df['x']*df['y']*df['z']\n\ndf","1a579e16":"df_final = pd.merge(df_weather, df, left_on='timestamp_weather', right_on='timestamp_hour', how='right')\n\ndf_final","99a36130":"names=['Weather_Condition',\"Wind_Chill(F)\",'Precipitation(in)','Temperature(F)','Humidity(%)','Wind_Speed(mph)','Visibility(mi)']\n\nfor i in names:\n    df_final[i].fillna(df_final[i].median(), inplace=True)\ndf_final\n\ndf_final.describe()","aa0965e1":"names=['Weather_Condition',\"Wind_Chill(F)\",'Precipitation(in)','Temperature(F)','Humidity(%)','Wind_Speed(mph)','Visibility(mi)']\n\nfor i in names:\n    df_final[i]=normalize_column(df_final,i)\n    \n\nnames=['day','month','year','hour','x','y','z','loc']\nfor i in names:\n    df_final[i]=normalize_column(df_final,i)\n    ","4337cbf5":"df_selected = df_final[[\n'description',\n'Crossing',\n'Junction',\n'Railway',\n'Stop',\n#'Amenity',\n'Side',\n#'loc',\n'x',\n'y',\n'z',\n#'Lat',\n# 'Lng',\n'Distance(mi)',\n'day' ,\n#'month',\n'year',\n#'hour',\n'Weather_Condition',\n\"Wind_Chill(F)\",\n'Precipitation(in)',\n'Temperature(F)',\n'Humidity(%)',\n'Wind_Speed(mph)',\n'Visibility(mi)'\n]]","8a8dbebb":"# test_df = pd.DataFrame(test_df)\n# test_df\ny_test_predicted = classifier.predict(df_selected)\ny_test_predicted","41c077a5":"df_selected['Severity'] = y_test_predicted\ndf_selected.head()\n\ndf_selected['ID']=df_final['ID']","171d349f":"df_selected[['ID', 'Severity']].to_csv('submission2.csv', index=False)","448c1ba0":"# # You should update\/remove the next line once you change the features used for training\n# X_test = X_test[['Lat', 'Lng', 'Distance(mi)']]\n\n# y_test_predicted = classifier.predict(X_test)\n\n# test_df['Severity'] = y_test_predicted\n\n# test_df.head()","9854c97c":"# test_df[['ID', 'Severity']].to_csv(dataset_path+'\\submission.csv', index=False)","d9f0105f":"# 01- Import the libraries","d0d70b1f":"# Model Training","00cb129e":"# Holiday ----------------------------------------------------------","c2010019":"# 3- Data Visualization and Preprocessing","f613bbe8":"# Weather\n1- Read Weather.csv as df\n\n\n2- cast date in the weather_df and join with df","5e43702e":"# Encoding df","1a8f9c7d":"# 02- Exploratory Data Analysis","36eca979":"# Test ---------------------------------"}}