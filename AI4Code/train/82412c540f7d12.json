{"cell_type":{"97c5f880":"code","94aa6cd4":"code","1bff573d":"code","f1588abc":"code","74cc983f":"code","3fb9fa0e":"code","c6a51f14":"code","60fb8fc6":"markdown","c87897dc":"markdown","6500004e":"markdown","a540d7af":"markdown","16e4ed44":"markdown","90731035":"markdown"},"source":{"97c5f880":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94aa6cd4":"# Reading the Dataset\ndataset = pd.read_csv('\/kaggle\/input\/restaurant-reviews\/Restaurant_Reviews.tsv', sep='\\t', quoting=3)\ndataset","1bff573d":"import re, nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\ncorpus = []\nfor i in range(len(dataset['Review'])):\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n    review = review.lower()\n    review = review.split()\n    review = [PorterStemmer().stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)\n    \ncorpus[:10]","f1588abc":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=1500)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:, 1].values","74cc983f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","3fb9fa0e":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","c6a51f14":"from sklearn.metrics import confusion_matrix\ny_pred = classifier.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))","60fb8fc6":"# Splitting the dataset into the Training set and Test set","c87897dc":"# Cleaning the text","6500004e":"# Fitting the Naive Bayes Model on the training data","a540d7af":"Codes in this Notebook are from the Udemy course: Machine Learning A2Z","16e4ed44":"# Model Prediction and Confusion Matrix","90731035":"# Creating the Bag of Words model"}}