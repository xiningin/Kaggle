{"cell_type":{"017fa0e5":"code","1cebaa66":"code","9020a72d":"code","baa46080":"code","a61b616a":"code","12301bde":"code","7a1c5748":"code","f0257d56":"code","a3053d88":"code","db389129":"code","da389d4b":"code","afd5357c":"code","1d863e9e":"code","f0c47760":"code","208edee4":"code","628d1eac":"code","12c12994":"code","4b617a21":"code","fd7b4112":"code","ce06d22b":"code","fe961924":"code","07127944":"code","662d3689":"code","cef11f5c":"code","2116ba86":"code","7bdcf813":"markdown","c90e2124":"markdown","95740954":"markdown","62f1b8ba":"markdown","9cdd0df4":"markdown","05ea4c71":"markdown","6cfbb573":"markdown","1a4f1f6d":"markdown","14f5592c":"markdown"},"source":{"017fa0e5":"\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1cebaa66":"data = pd.read_csv(r\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndata.info()","9020a72d":"data.describe()","baa46080":"data.columns","a61b616a":"data.isnull().sum()","12301bde":"print(data.Outcome.value_counts())\nlabels = '0', '1',\nsizes = [500, 268]\ncolors = ['palegoldenrod','lightgrey']\nexplode = (0, 0)\nfig1, ax1 = plt.subplots(figsize =(10,10))\nax1.pie(sizes,colors = colors ,explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Outcome\")\nplt.show()","7a1c5748":"data_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age']\nfor each in data_columns:\n    fig1, ax1 = plt.subplots(figsize =(10,10))\n    plt.hist(data[each], bins=80,color = \"cadetblue\")\n    plt.xlabel(each)\n    plt.ylabel(\"Frequency\")\n    plt.grid()\n    plt.show()","f0257d56":"df = pd.DataFrame(data,columns=data_columns)\nf, ax = plt.subplots(figsize =(15,11))\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","a3053d88":"g = sns.jointplot(\n    data=data,\n    x=\"Glucose\", y=\"Insulin\", \n    kind=\"kde\",\n)\nplt.show()   ","db389129":"fig1, ax1 = plt.subplots(figsize =(10,10))\nplt.scatter(data.index , data.Glucose,label =  \"Glucose\",alpha = 0.5,color = \"orangered\")\nplt.scatter(data.index , data.Insulin,label =  \"Insulin\",alpha = 0.5,color = \"darkblue\")\nplt.legend(loc =\"best\")\nplt.xlabel(\"index\")\nplt.ylabel(\"Value\")\nplt.grid()\nplt.show()","da389d4b":"g = sns.catplot(\n    data=data, kind=\"bar\",\n    x=\"Outcome\", y=\"Glucose\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6,\n)\ng.despine(left=True)\ng.set_axis_labels(\"Outcome\", \"Glucose\")\nplt.grid()\nplt.show()","afd5357c":"g = sns.catplot(\n    data=data, kind=\"bar\",\n    x=\"Outcome\", y=\"Insulin\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6,\n)\ng.despine(left=True)\ng.set_axis_labels(\"Outcome\", \"Insluin\")\nplt.grid()\nplt.show()","1d863e9e":"sns.violinplot(data=data, x=\"Outcome\", y=\"Glucose\",\n               split=True, inner=\"quart\", linewidth=1,)\nsns.despine(left=True)\nplt.show()","f0c47760":"sns.violinplot(data=data, x=\"Outcome\", y=\"Insulin\",\n               split=True, inner=\"quart\", linewidth=1,)\nsns.despine(left=True)\nplt.show()","208edee4":"y = data.Outcome\ndata.drop([\"Outcome\"],axis = 1 , inplace = True)\nx = (data-np.min(data))\/(np.max(data)-np.min(data))","628d1eac":"from sklearn.model_selection import train_test_split\nx_train , x_test , y_train, y_test = train_test_split(x,y,test_size = 0.2 , random_state = 42)","12c12994":"from sklearn.svm import SVC\nsvm1 = SVC(gamma = 0.01 , C = 10 , kernel = \"rbf\")\nsvm1.fit(x_train,y_train)\nsvm1_score = svm1.score(x_test,y_test)\nprint(\"SVM Max Score = : \", svm1_score)","4b617a21":"y_pred = svm1.predict(x_test)\ny_true = y_test\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize =(9,9))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","fd7b4112":"knn_list = []\nfrom sklearn.neighbors import KNeighborsClassifier\nfor each in range(1,100):\n    knn1 = KNeighborsClassifier(n_neighbors = each,weights = \"distance\",metric = \"manhattan\" )\n    knn1.fit(x_train,y_train)\n    knn1_score = knn1.score(x_test,y_test)\n    knn_list.append(knn1_score)\nknn_max = np.max(knn_list)\nprint(\"KNN Max Score = \",knn_max)","ce06d22b":"y_pred2 = knn1.predict(x_test)\ny_true2 = y_test\nfrom sklearn.metrics import confusion_matrix\ncm2 = confusion_matrix(y_true2,y_pred2)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(11,11))\nsns.heatmap(cm2,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","fe961924":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(C = 1.0, penalty = \"l2\")\nlr.fit(x_train,y_train)\nprint(\"Logistic Regression Max Score : \",lr.score(x_test,y_test))\nlr_max = lr.score(x_test,y_test)","07127944":"y_pred3 = lr.predict(x_test)\ny_true3 = y_test\nfrom sklearn.metrics import confusion_matrix\ncm3 = confusion_matrix(y_true3,y_pred3)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(11,11))\nsns.heatmap(cm3,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","662d3689":"score_list = []\nfrom sklearn.ensemble import RandomForestClassifier\nfor each in range (1,100):\n    rf = RandomForestClassifier(n_estimators = each,random_state = 18,bootstrap = \"False\",criterion=\"gini\",\n                                    min_samples_split = 10 , min_samples_leaf = 10)\n    rf.fit(x_train,y_train)\n    score_list.append(rf.score(x_test,y_test))    \nrf_max = np.max(score_list)\nprint(\"RF Max Score : \",rf_max)","cef11f5c":"y_pred4 = rf.predict(x_test)\ny_true4 = y_test\nfrom sklearn.metrics import confusion_matrix\ncm4 = confusion_matrix(y_true4,y_pred4)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(11,11))\nsns.heatmap(cm4,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","2116ba86":"results = pd.DataFrame({\"Classification\" :[\"Random Forest C.\" ,\"Logistic Regression C.\",\n            \"K-Nearest Neighbor C.\",\"Support Vector C.\"],\n                        \"Accuracy\" : [rf_max*100,lr_max*100,knn_max*100,svm1_score*100]})\nresults = results.sort_values(by=['Accuracy'],ascending = False)\nprint(results)","7bdcf813":"<a id = \"2\"><\/a>\n<font color ='red'>\n# 2. Visualizing Data","c90e2124":"<a id = \"3\"><\/a>\n<font color ='red'>\n# 3. Prediction","95740954":"<a id = \"4\"><\/a>\n<font color ='red'>\n# 4.Results","62f1b8ba":"<a id = \"5\"><\/a>\n<font color ='red'>\n## Support Vector Classification","9cdd0df4":"<a id = \"7\"><\/a>\n<font color ='red'>\n# Logistic Regression Classifier","05ea4c71":"<a id = \"1\"><\/a>\n<font color ='red'>\n# 1.Load and Check Data","6cfbb573":"<a id = \"6\"><\/a>\n<font color ='red'>\n## K-Nearest Neighbor Classification","1a4f1f6d":"<a id = \"8\"><\/a>\n<font color ='red'>\n# Random Forest Classification","14f5592c":"<font color ='red'>\n    \nContent :\n    \n1. [ Load and Check Data](#1) \n    \n2. [ Visualizing Data](#2)    \n       \n3. [ Prediction](#3) \n    \n    *[Support Vector Classification](#5)     \n    \n    *[ K-Nearest Neighbor Classification](#6)       \n    \n    *[ Logistic Regression Classification](#7)          \n    \n    *[ Random Forest Classification](#8) \n    \n        \n4. [ Results](#4)    \n    "}}