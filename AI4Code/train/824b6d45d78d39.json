{"cell_type":{"b2cfd5eb":"code","88cb85f7":"code","1d82111d":"code","c06205cb":"code","e640fb97":"code","cfc359b0":"code","ebe40018":"code","26fbdee6":"code","0b2e6589":"code","48a5eb2e":"code","f8548810":"code","85c8b340":"code","6a2f9b6a":"code","c2810c38":"code","f4349ba9":"code","0449281b":"code","0c977d71":"code","83dd0722":"code","e9daa1c8":"code","8f25b406":"code","287d8437":"code","f270d4b9":"code","015d30ae":"code","49f04855":"code","20e63677":"code","377f8393":"code","985d1f63":"code","f98a00ef":"code","693a5aa5":"code","e98e97ff":"code","5c65eaee":"code","5a85f37f":"code","6ba4d39d":"code","6e5fc7d4":"code","9ecb6214":"code","e9e92c88":"code","024c3bf1":"code","b3880da2":"code","5a2414f0":"code","e679b398":"code","36262776":"code","c30c60a7":"code","9bad1140":"code","b8ec3487":"code","00689de5":"code","c8a1def9":"code","dd60d27c":"code","5e7483b9":"code","ad955d8a":"code","25e1568c":"code","ca94fe41":"markdown","c54ba1b2":"markdown","a285a82c":"markdown","2186ae39":"markdown","f4f2aa52":"markdown","ff9a8274":"markdown","8a81fa2e":"markdown","b1eab43d":"markdown","63301d48":"markdown","2abd9e27":"markdown","b7ac77ed":"markdown","daac1d4e":"markdown","8c01ee07":"markdown","c0461c77":"markdown","e8cb8515":"markdown","84d3662f":"markdown","5eea011e":"markdown","e9256fb7":"markdown","c3a025cb":"markdown","88dfd9d1":"markdown","7d2e5091":"markdown","496acdcb":"markdown","21d1372f":"markdown","e08ffd0a":"markdown","71773092":"markdown","0ff66b5a":"markdown","c122e80a":"markdown","7849a303":"markdown","d2f7effd":"markdown","f105dad4":"markdown","e28f01b2":"markdown"},"source":{"b2cfd5eb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Data Vizulization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Splitting the data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\n# Algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n# Model Stacking\nfrom sklearn.ensemble import StackingClassifier\n\n# For Hyper-parameter Tuning the model\nfrom sklearn.model_selection import GridSearchCV\n\n# For checking Model Performance\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import learning_curve\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\")","88cb85f7":"data = pd.read_csv('..\/input\/fetal-health-classification\/fetal_health.csv')\ndata.head().T","1d82111d":"data.info()","c06205cb":"data.describe().T","e640fb97":"data['fetal_health'].unique()","cfc359b0":"sns.countplot(data['fetal_health'])","ebe40018":"data['fetal_health'].value_counts()","26fbdee6":"hist_plot = data.hist(figsize=(20,20))","0b2e6589":"corr = data.corr()\n\nplt.figure(figsize=(12,10))\nsns.heatmap(corr, annot=True, cmap='rainbow')\nplt.show()","48a5eb2e":"data = data.drop(['histogram_min','histogram_median','histogram_mode'], axis=1)\ndata","f8548810":"## Count the missing and null values\nnv = data.columns[data.isnull().any()]\nprint('Null values = ', nv)\n\nmv = data.columns[data.isna().any()]\nprint('Missing values = ', mv)","85c8b340":"# Splitting data into 75% train set and 25% test set\n\nX = data.drop(['fetal_health'], axis=1)\ny = data['fetal_health']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)","6a2f9b6a":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","c2810c38":"params = {\"tol\": [0.0001,0.0002,0.0003],\n          \"intercept_scaling\": [1, 2, 3, 4]\n         }","f4349ba9":"cv_method = StratifiedKFold(n_splits=3, \n                            random_state=42)","0449281b":"GridSearchCV_LR = GridSearchCV(estimator=LogisticRegression(), \n                       param_grid=params,\n                       cv=cv_method,\n                       n_jobs=2,\n                       scoring=\"accuracy\"\n                      )","0c977d71":"GridSearchCV_LR.fit(X_train, y_train)","83dd0722":"best_params_LR = GridSearchCV_LR.best_params_\nbest_params_LR","e9daa1c8":"lr = LogisticRegression(C=10, intercept_scaling=1, tol=0.0001, penalty=\"l2\", solver=\"liblinear\", random_state=42)\nlr.fit(X_train, y_train)\nlr.score(X_test, y_test)","8f25b406":"pred = lr.predict(X_test)","287d8437":"print(\"Classification Report\")\nprint(classification_report(y_test, pred))","f270d4b9":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred), annot=True, ax = ax, cmap = \"BuPu\");\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","015d30ae":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","49f04855":"params_RF = {\"min_samples_split\": [2, 6, 20],\n             \"min_samples_leaf\": [1, 4, 16],\n             \"n_estimators\" :[100,150, 200, 250],\n             \"criterion\": [\"gini\"]             \n            }","20e63677":"GridSearchCV_RF = GridSearchCV(estimator=RandomForestClassifier(), \n                                param_grid=params_RF, \n                                cv=cv_method,\n                                n_jobs=2,\n                                scoring=\"accuracy\"\n                                )","377f8393":"GridSearchCV_RF.fit(X_train, y_train)","985d1f63":"best_params_RF = GridSearchCV_RF.best_params_\nbest_params_RF","f98a00ef":"rf = RandomForestClassifier(criterion=\"gini\", n_estimators = 100, min_samples_leaf=1, min_samples_split=2, random_state=42)\nrf.fit(X_train, y_train)\nrf.score(X_test, y_test)","693a5aa5":"pred_rf = rf.predict(X_test)","e98e97ff":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_rf))","5c65eaee":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_rf), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","5a85f37f":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\nmodel.score(X_test, y_test)","6ba4d39d":"pred_gbc = gbc.predict(X_test)","6e5fc7d4":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_gbc))","9ecb6214":"ax = plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_gbc), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","e9e92c88":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nxgb.score(X_test, y_test)","024c3bf1":"pred_xgb = xgb.predict(X_test)","b3880da2":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_xgb))","5a2414f0":"ax = plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_xgb), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","e679b398":"estimators = [\n    ('rf', RandomForestClassifier(criterion=\"gini\", n_estimators = 100, min_samples_leaf=1, min_samples_split=2, random_state=42)),\n    ('gb', GradientBoostingClassifier()),\n    ('xgb', XGBClassifier()\n    )\n]","36262776":"clf = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(criterion=\"gini\", n_estimators = 100, min_samples_leaf=1, min_samples_split=2, random_state=42), cv=5)\nclf.fit(X_train, y_train).score(X_test, y_test)","c30c60a7":"pred_clf = clf.predict(X_test)","9bad1140":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_clf))","b8ec3487":"ax = plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_clf), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","00689de5":"def plot_learning_curve(estimator, title, x, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n        \n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, x, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"#80CBC4\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"#00897B\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","c8a1def9":"plot_learning_curve(GridSearchCV_LR.best_estimator_,title = \"Logistict Regression learning curve\", x = X_train, y = y_train, cv = cv_method)","dd60d27c":"plot_learning_curve(GridSearchCV_RF.best_estimator_,title = \"Random Forest learning curve\", x = X_train, y = y_train, cv = cv_method)","5e7483b9":"plot_learning_curve(gbc,title = \"Gradient Boosting Classifier learning curve\", x = X_train, y = y_train, cv = cv_method)","ad955d8a":"plot_learning_curve(xgb, title = \"XGBoost Classifier learning curve\", x = X_train, y = y_train, cv = cv_method)","25e1568c":"plot_learning_curve(clf, title = \"Stacked Model learning curve\", x = X_train, y = y_train, cv = cv_method)","ca94fe41":"### Confusion Matrix","c54ba1b2":"From the Correlation matrix, we can say that 'histogram_mode', 'histogram_mean' and 'histogram_median' are highly correlated to each other. Also, 'histogram_min' and 'histogram_width' are highly negatively correlated. So we will remove 'histogram_mode', 'histogram_median' and 'histogram_min' columns from the dataset.","a285a82c":"<h2 style='color:blue'>4. Modeling and Hypertuning<\/h2>","2186ae39":"### Classification Report","f4f2aa52":"### Prediction","ff9a8274":"<h3 style='color: green'>Logistic Regression<\/h3>","8a81fa2e":"<h3 style='color: green'>XGBoost Classifier<\/h3>","b1eab43d":"### Stacked Model Curve","63301d48":"<h3 style='color: green'>Gradient Boosting Classifier<\/h3>","2abd9e27":"### Correlation Matrix","b7ac77ed":"### Classification Report","daac1d4e":"### Histogram","8c01ee07":"### Splitting the Data","c0461c77":"### XGBoost Classifier Curve","e8cb8515":"<h3 style='color: green'>Random Forest Classifier<\/h3>","84d3662f":"### Classification Report","5eea011e":"<h2 style='color:blue'>1. Import Necessary Libraries and Dataset<\/h2>","e9256fb7":"### Confusion Matrix","c3a025cb":"### Find out the best parameters using GridSearchCV","88dfd9d1":"### Analyze & Vizulize the Target Variable","7d2e5091":"### Find Missing Values :\n<i>The real-world data often has a lot of missing values. The cause of missing values can be data corruption or failure to record data. The handling of missing data is very important during the preprocessing of the dataset as many machine learning algorithms do not support missing values.<\/i>","496acdcb":"<h2 style='color:blue'>3. Data Pre-processing<\/h2>","21d1372f":"### Random forest Curve","e08ffd0a":"# <center><u>Fetal Health Classification<\/u><\/center>\n   #### <p>This dataset contains 2126 records of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into 3 classes:\n* Normal\n* Suspect\n* Pathological<\/p>\n \n<p><h3 style=\"display: inline;\">Target :<\/h3> So in this task, We will classify the data into three categories using various classification algorithms to achieve lowest prediction error.<\/p>\n\n### Table of Content :\n1. Importing Data and Libraries\n2. Exploratory Data Analysis (EDA)\n3. Data Pre-processing\n6. Modeling & Hypertuning<br \/>\n    * Logistic Regression<br \/>\n    * Random Forest Classifier<br \/>\n    * Gradient Boosting Classifier <br \/>\n    * XGBoost Classifier <br \/>\n6. Model Stacking\n7. Plotting a Learning Curve","71773092":"<h2 style='color:blue'> Model Stcking<\/h2>","0ff66b5a":"### Find out the best parameters using GridSearchCV","c122e80a":"### Confusion Matrix","7849a303":"### Gradient Boosting Classifier Curve","d2f7effd":"### Logistic Regression Curve","f105dad4":"<h2 style='color:blue'>Plotting a Learning Curve<\/h2>","e28f01b2":" <h2 style='color:blue'>2. Exploratory Data Analysis (EDA)<\/h2>\n <p>EDA and Data Vizulization gives the basic overview of the quality and nature of the information available before you begin studying it in more detail. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.<\/p>\n<p>In this step, We will get the basic information about the data like Mean, Standard Daviation, Quatiles, Min-Max values of all the numeric features.\n<p>Also, We will try to understand the data using various plots.<\/p>"}}