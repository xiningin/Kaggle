{"cell_type":{"9c3ee2de":"code","cd49f8c8":"code","61709b57":"code","90e83610":"code","82710873":"code","6f47a16e":"code","27f0dc3d":"code","242e5bd9":"code","9a4aaecc":"code","ac4f2783":"code","628baa9e":"code","3e919448":"code","c1b013e4":"code","d0a2e789":"code","72e95b23":"code","2fbaff89":"code","f8894b52":"code","3eae1e05":"code","a97aae8f":"code","3b0120f1":"code","a52cf300":"code","e1f314de":"code","aebaa163":"code","bd46a40e":"code","26770019":"markdown","f20f3d35":"markdown","ee4cc239":"markdown","c34c27e8":"markdown","f4214d6f":"markdown","fed56dbe":"markdown","b9913f62":"markdown","565480b8":"markdown","319d3714":"markdown","2f1978f0":"markdown"},"source":{"9c3ee2de":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","cd49f8c8":"# Importing the real dataset for prediction\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\n# Temporary data set for analysis and preprocessing\ntemp_df = pd.concat([df_train, df_test], ignore_index=True, sort=False)\n\ntemp_df.head()","61709b57":"temp_df.isnull().sum() ","90e83610":"temp_df['NameLength'] = temp_df['Name'].apply(len)\ntemp_df[['Name', 'NameLength']].head() ","82710873":"# HasCabin - means that the passenger has his own Cabin\ntemp_df['HasCabin'] = temp_df['Cabin'].apply(lambda i: 1 if type(i)==str else 0)\ntemp_df[['Cabin', 'HasCabin']].head() ","6f47a16e":"temp_df['FamilySize'] = 1 + temp_df['Parch'] + temp_df['SibSp']\n# Using siblings and parents \/ children, we can create a new column called FamilySize.\ntemp_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean() ","27f0dc3d":"# In the beginning we will indicate that all people are lonely.\ntemp_df['IsAlone'] = 0\n# Now check the number of people in the family. If it is 1, it means that the person is one.\ntemp_df.loc[temp_df['FamilySize']==1, 'IsAlone'] = 1\ntemp_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","242e5bd9":"# Using the \"fillna\" we fill the NA \/ NaN value with an \"S\". \"S\" is the most common port name.\ntemp_df['Embarked'] = temp_df['Embarked'].fillna('S')\n# Reading a lot of kernels I found out that instead of LabelEncoder we can use the map function.\ntemp_df['Embarked'] = temp_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ntemp_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()","9a4aaecc":"temp_df['Fare'] = temp_df['Fare'].fillna(temp_df['Fare'].median())\n# pandas.cut - This feature is useful for moving from a continuous variable to a categorical variable.\n# For example, a reduction may transform age into groups of age ranges.\nCategoricalFare = pd.cut(temp_df['Fare'], 5)\n# output CategoricalFare:  [(-0.512, 102.466] < (102.466, 204.932] < (204.932, 307.398] < (307.398, 409.863] < (409.863, 512.329]]\n# loc function - Access a group of rows and columns by label(s) or a boolean array.\ntemp_df.loc[temp_df['Fare']<=102, 'Fare'] = 0\ntemp_df.loc[(temp_df['Fare']>102) & (temp_df['Fare']<=204), 'Fare'] = 1\ntemp_df.loc[(temp_df['Fare']>204) & (temp_df['Fare']<=307), 'Fare'] = 2\ntemp_df.loc[(temp_df['Fare']>307) & (temp_df['Fare']<=409), 'Fare'] = 3\ntemp_df.loc[(temp_df['Fare']>409) & (temp_df['Fare']<=512), 'Fare'] = 4\ntemp_df['Fare'] = temp_df['Fare'].astype(int)\ntemp_df[['Fare', 'Survived']].groupby(['Fare'], as_index=False).mean()","ac4f2783":"# To work with the Age, we need to take the mean and standard deviation.\nmean = temp_df['Age'].mean()\nstd = temp_df['Age'].std()\n# Create an array with the size of the missing data and fill the array randomly choosing one value from the following two operations.\nrandomAge = np.random.randint(mean-std, mean+std, size=temp_df['Age'].isnull().sum())\ntemp_df['Age'][np.isnan(temp_df['Age'])] = randomAge\n# Then everything goes according to the previous algorithm.\nCategoricalAge = pd.cut(temp_df['Age'], 5)\n# output: [(0.34, 16.336] < (16.336, 32.252] < (32.252, 48.168] < (48.168, 64.084] < (64.084, 80.0]]\ntemp_df.loc[temp_df['Age']<=16 , 'Age'] = 0\ntemp_df.loc[(temp_df['Age']>16) & (temp_df['Age']<=32), 'Age'] = 1\ntemp_df.loc[(temp_df['Age']>32) & (temp_df['Age']<=48), 'Age'] = 2\ntemp_df.loc[(temp_df['Age']>48) & (temp_df['Age']<=64), 'Age'] = 3\ntemp_df.loc[(temp_df['Age']>64) & (temp_df['Age']<=80), 'Age'] = 4\ntemp_df['Age'] = temp_df['Age'].astype(int)\ntemp_df[['Age', 'Survived']].groupby(['Age'], as_index=False).mean() ","628baa9e":"temp_df['Name'].head()","3e919448":"# Here you have to work with strings.\n# That is, we need to take on behalf of the passenger polite treatment (Mr., Mrs, etc.)\ntemp_df['Title'] = [i.split(', ')[1].split('.')[0] for i in temp_df['Name']]\ntemp_df['Title'] = temp_df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntemp_df['Title'] = temp_df['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntemp_df['Title'] = temp_df['Title'].replace('Mme', 'Mrs')\ntemp_df['Title'] = temp_df['Title'].map({\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Rare\": 4})\n\n\ntemp_df['Sex'] = temp_df['Sex'].map({'male':0, 'female':1}).astype(int)","c1b013e4":"temp_df.head()","d0a2e789":"def analize(df):\n    df['NameLength'] = df['Name'].apply(len)\n    df['HasCabin'] = df['Cabin'].apply(lambda i: 1 if type(i)==str else 0)\n    df['FamilySize'] = 1 + df['Parch'] + df['SibSp']\n    \n    df['IsAlone'] = 0\n    df.loc[df['FamilySize']==1, 'IsAlone'] = 1\n\n    df['Embarked'] = df['Embarked'].fillna('S')\n    df['Embarked'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n    CategoricalFare = pd.cut(df['Fare'], 5)\n    # output: [(-0.512, 102.466] < (102.466, 204.932] < (204.932, 307.398] < (307.398, 409.863] < (409.863, 512.329]]\n    df.loc[df['Fare']<=102, 'Fare'] = 0\n    df.loc[(df['Fare']>102) & (df['Fare']<=204), 'Fare'] = 1\n    df.loc[(df['Fare']>204) & (df['Fare']<=307), 'Fare'] = 2\n    df.loc[(df['Fare']>307) & (df['Fare']<=409), 'Fare'] = 3\n    df.loc[(df['Fare']>409) & (df['Fare']<=512), 'Fare'] = 4\n    df['Fare'] = df['Fare'].astype(int)\n\n    # --- Age\n    mean = df['Age'].mean()\n    std = df['Age'].std()\n    randomAge = np.random.randint(mean-std, mean+std, size=df['Age'].isnull().sum())\n    df['Age'][np.isnan(df['Age'])] = randomAge\n    CategoricalAge = pd.cut(df['Age'], 5)\n    # output: [(0.34, 16.336] < (16.336, 32.252] < (32.252, 48.168] < (48.168, 64.084] < (64.084, 80.0]]\n    df.loc[df['Age']<=16 , 'Age'] = 0\n    df.loc[(df['Age']>16) & (df['Age']<=32), 'Age'] = 1\n    df.loc[(df['Age']>32) & (df['Age']<=48), 'Age'] = 2\n    df.loc[(df['Age']>48) & (df['Age']<=64), 'Age'] = 3\n    df.loc[(df['Age']>64) & (df['Age']<=80), 'Age'] = 4\n    df['Age'] = df['Age'].astype(int)\n\n    # --- Title\n    df['Title'] = [i.split(', ')[1].split('.')[0] for i in df['Name']]\n    df['Title'] = df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n    df['Title'] = df['Title'].map({\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Rare\": 4})\n\n    df['Sex'] = df['Sex'].map({'male':0, 'female':1}).astype(int)\n    \n    df = df.drop(columns=['PassengerId','Name','SibSp','Parch','Ticket','Cabin'])\n    return df","72e95b23":"train = analize(df_train)\ntrain.head()","2fbaff89":"# Splitting dataset into X and y\ny = train['Survived'].values\nx = train.iloc[:, 1:].values\n\nX_train, X_test, y_train, y_test = train_test_split(x,y, random_state=0)","f8894b52":"classifier = RandomForestClassifier(n_estimators=100, max_depth=20, max_features='sqrt')\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test) ","3eae1e05":"# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nimport itertools\nlabels = ['Predicted NO', 'Predicted YES','Actual NO','Actual YES']\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix of the classifier\\n')\nax.set_xticklabels([''] + labels[0:2])\nax.set_yticklabels([''] + labels[2:4])\nfmt = '.0f'\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], fmt),\n        horizontalalignment=\"center\",\n        color=\"red\", fontsize = 22)\nplt.show()","a97aae8f":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","3b0120f1":"test = analize(df_test)\ntest.head() ","a52cf300":"output_train = train['Survived'].values\nintput_train = train.drop(columns=['Survived']).values\ninput_test = test.values","e1f314de":"output_pred = classifier.predict(input_test)","aebaa163":"result = pd.DataFrame({\n    'PassengerId': df_test['PassengerId'],\n    'Survived': output_pred.astype(int)\n})","bd46a40e":"result.head()","26770019":"# Introduction\nIn this notebook I want to show you how I have reached up to 24%. Date of writing this notebook: 24-12-2018.\nTo begin, let me introduce myself. My name is Nurtai Maksat. I am a 3rd year student at the International University of Information Technology. \n\nFor this task, I used the RandomForestClassifier model. If you read to the end, you will find out which parameters I used. Let's get started. Below I will show the steps you need to perform.\n    1. Importing the libraries\n    2. Importing the dataset\n    3. Create function that processes data\n        a. Create new columns\n        b. Fill missing values\n        c. Delete unnecessary data\n    4. Trainig\n        a. Process data\n        b. Create model and train model with 'train' dataset\n    5. Prediction\n    6. Save result to csv","f20f3d35":"Wow, good! The impact is significant.","ee4cc239":"# Feature Engineering and Data Cleaning\nFor a start, look at which columns have missing data.","c34c27e8":"As we see, this has a good impact on our forecast, but let's not stop and go ahead and examine people, whether they are alone on this ship or not, and how they react to survival.","f4214d6f":"Well, we learned in which columns there is blank data. Let me show you how the data was processed using a temporary dataset.","fed56dbe":"Well, we finished this stage. For further work and convenience, I will put all these codes into a function.","b9913f62":"# Prediction","565480b8":"In the process of studying and analyzing the data, I found a more accurate article that showed that the length of the names of passengers greatly influences the final result in the RandomForest model.","319d3714":"The next step is to create a model with the following parameters:\n1. n_estimators=100\n2. max_depth=20\n3. max_features='sqrt'","2f1978f0":"# Training model"}}