{"cell_type":{"3b92bc29":"code","87da1073":"code","82eb7809":"code","4ccd9aaf":"code","01b6c56b":"code","eb12bba0":"code","cc1ba377":"code","befcb3fd":"code","4582744e":"code","2b96982f":"code","c00ce39f":"code","a27fd134":"code","a321f8c9":"code","bb14edfd":"code","4a7bfaa8":"code","a8551250":"code","4e6af47b":"code","9dd14938":"code","7b613bd1":"code","d708867c":"code","d0506b84":"code","efc1c700":"code","22daf77f":"markdown","35d253fa":"markdown","4745c01f":"markdown","e624bc09":"markdown","28e7b337":"markdown","a043bf18":"markdown"},"source":{"3b92bc29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87da1073":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n##loading the data\npd.set_option('display.max_columns', None)\ndf = pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")\n\ndf.head()","82eb7809":"df.shape","4ccd9aaf":"df.isna().sum()","01b6c56b":"df.drop('Unnamed: 32',axis=1,inplace=True)\ndf.head()","eb12bba0":"df.shape","cc1ba377":"df.info()","befcb3fd":"## data visualization\nsns.countplot(x='diagnosis',data=df);","4582744e":"y = df['diagnosis']\nx = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']];","2b96982f":"##let's see range of each feature so that we can decide to go for standard scaling \nx.describe()","c00ce39f":"x_scalled = (x - x.mean()) \/ (x.std()) ","a27fd134":"##let's focus on first 10 features feature_mean\ndata = pd.concat([y,x_scalled.iloc[:,0:10]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value');\nplt.figure(figsize=(10,10));\nsns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\");\nplt.xticks(rotation=90);\n","a321f8c9":"plt.figure(figsize=(10,10))\nsns.boxplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data)\nplt.xticks(rotation=90);","bb14edfd":"data = pd.concat([y,x_scalled.iloc[:,10:20]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value');\nplt.figure(figsize=(10,10));\nsns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\");\nplt.xticks(rotation=90);","4a7bfaa8":"plt.figure(figsize=(10,10))\nsns.boxplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data)\nplt.xticks(rotation=90);","a8551250":"data = pd.concat([y,x_scalled.iloc[:,20:]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value');\nplt.figure(figsize=(10,10));\nsns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\");\nplt.xticks(rotation=90);","4e6af47b":"plt.figure(figsize=(10,10))\nsns.boxplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data)\nplt.xticks(rotation=90);","9dd14938":"f,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax,cmap='YlGnBu')","7b613bd1":"drop_list1 = ['perimeter_mean',\n              'radius_mean',\n              'compactness_mean',\n              'concave points_mean',\n              'radius_se','perimeter_se',\n              'radius_worst','perimeter_worst',\n              \n              'texture_worst',\n              'area_worst']\n","d708867c":"x_1 = x.drop(drop_list1,axis = 1 )     ##selected features after one interpolation\nx_1.head()","d0506b84":"f,ax = plt.subplots(figsize=(14, 14))\nsns.heatmap(x_1.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax ,cmap='YlGnBu');","efc1c700":"#let's fit a model and find out how well we selected features\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n# split data train 70 % and test 30 %\nx_train, x_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3)\n\n#random forest classifier with n_estimators=10 (default)\nclf_rf = RandomForestClassifier()      \nclr_rf = clf_rf.fit(x_train,y_train)\n\nac = accuracy_score(y_test,clf_rf.predict(x_test))\nprint('Accuracy is: ',ac)\ncm = confusion_matrix(y_test,clf_rf.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")","22daf77f":"**interpretation Example** of above plot data\n\nin **texture_mean, parameter_mean,area_mean, concavity_mean** features, median of the Malignant and Benign looks like separated so it can be good for classification.\n<br>\nHowever, in fractal_dimension_mean feature, median of the Malignant and Benign does not looks like separated so it does not gives good information for classification.\n\n**Now let's go for next 10 features**","35d253fa":"**feature**&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;**having very high correlation or dependacy with** <br>\nradius_mean &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; parameter_mean, area_mean, rdius_worst, parameter_worst, _area_worst_ &emsp;&emsp; we will be using **area_mean** in our model<br>\ntexture_mean&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; texture_worst<br>\nradius_worst &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; perimeter_worst and area_worst &emsp;&emsp; i will use area_worst\n\nradius_se &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; parameter_se, area_se &emsp;&emsp; we will be using **area_se** in our model<br>\nCompactness_mean, concavity_mean and concave points_mean\n\n**im not writing for all features but u can follow this**","4745c01f":"ohh!! features are scalled , we are going to perform standard scalling, so that it dont make any biasness in plot and model as well\n","e624bc09":"there are more Benign then Malignent ....... wait ti's not we need to find<br>\nLet's first do some data exploration","28e7b337":"**Important initial insights**\n<br>\n1. id can't be used for classification\n2. diagnosis is our lebel column for classification\n3. unnamed32 is useless and we have already droped that **cheers**.\n4. other features --- we need to know about them","a043bf18":"## AIM :\n    To come up with the most accurate model to predict brest cancer type.\n\n### Data Information\n    1. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]\n\n    2. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n\n    3. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\n    4. This database is also available through the UW CS ftp server:\n    ftp ftp.cs.wisc.edu\n    cd math-prog\/cpo-dataset\/machine-learn\/WDBC\/\n\n\n### Features Information\n1. **ID NUMBER**<br>\n    represents id no of patient , which help to identify them easily\n    \n2. **Diagnosis**: <br>\n    a catogerical feature having two vlaue :<br>\n    **M** = malignant<br>\n    **B** = benign<br>\n<br>**Ten real-valued features are computed for each cell nucleus:**<br>\n3. **radious_mean**:<br>\n    Mean of distances from center to points in the perimeter for each cell(**cell might not be circular**)<br><br>\n4. **texture_mean**:<br>\n    standard deviation of gray-scale values<br><br>\n5. **perimeter_mean**:<br>\n    mean size of core tumor<br><br>\n6. **area_mean**:<br>\n    area of tumor cell<br><br>\n7. **smoothness_mean**:<br>\n    mean of local variation in radious lengths,basically measures how circular\/spharical the tumor cell is<br><br>\n8. **compactness_mean**:<br>\n    mean of parimeter <sup>2 <\/sup> \/ area - 1.0 <br><br>\n    \n9. **concavity_mean**:<br>\n    mean of severity of concave portions the contour<br><br>\n10. **concave_points**:<br>\n    number of concave portions of the contour\n    <br><br>\n11. **fractal dimension**:<br> (\n    \"coastline approximation\" - 1\n    <br><br>\n**The mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.**\n"}}