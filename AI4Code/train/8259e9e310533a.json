{"cell_type":{"a38b48eb":"code","73693081":"code","56def077":"code","34bb486d":"code","ca44080e":"code","259dd829":"code","772a8d61":"code","06813663":"code","088be078":"code","ad9fbd68":"code","35756a08":"code","ef88b417":"code","2e834bf5":"code","d629743e":"code","65badab8":"code","b202fe43":"code","a519336d":"code","b1c9005d":"code","dcfab648":"code","cb9fb80a":"code","3e5fece4":"code","c2f81c55":"code","a4498335":"code","10a8f08d":"code","54874408":"code","3d175959":"code","4f1792ad":"code","475ecf2d":"code","37f2ac22":"code","11d47777":"code","ca4cd275":"code","453c1319":"code","baf76494":"code","8304a921":"code","4142a1ef":"code","001abd91":"code","4d4d9aa3":"code","4152c78f":"code","38f60dea":"code","1bbbf2b8":"code","68acb5dd":"code","d1167763":"code","d3ddf466":"code","aa20b314":"code","489378b2":"code","da07cfae":"code","4a5c5020":"code","bba867f4":"markdown","2785ce8a":"markdown","08646489":"markdown","f90b4ebc":"markdown","aae93176":"markdown","175a32f6":"markdown","97b3543b":"markdown","d3f9a502":"markdown","30306e08":"markdown","5267e814":"markdown","930c7ea4":"markdown","4143c344":"markdown","86456308":"markdown","56569975":"markdown","be227703":"markdown","50ba71e7":"markdown","61e478aa":"markdown","cbc56665":"markdown","118e1050":"markdown","4692c73b":"markdown","f2dd9c53":"markdown","9518e873":"markdown","bae539a0":"markdown","5595ee30":"markdown","1f60d8ea":"markdown","0ba130d3":"markdown","2c8f8eb7":"markdown","843be64e":"markdown","01aa0114":"markdown","17092bb5":"markdown","4858434d":"markdown","fdd26803":"markdown","20c1988e":"markdown","21fef7d2":"markdown","a4f5a728":"markdown","84d36510":"markdown","a97c6923":"markdown","77d7f335":"markdown","5d0d95f5":"markdown","e3ad6ef4":"markdown","177569cf":"markdown","1e5fbc4d":"markdown"},"source":{"a38b48eb":"# Importing necessary libraries\nimport statsmodels.api as sm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","73693081":"# Fetching the data from statsmodel api\ndf = sm.datasets.macrodata.load_pandas().data\ndf.head()","56def077":"print(sm.datasets.macrodata.NOTE)","34bb486d":"print(\"The head of the dataset is:\")\ndf.head()","ca44080e":"print(\"The tail of the dataset is:\")\ndf.tail()","259dd829":"index = pd.Index(sm.tsa.datetools.dates_from_range('1959Q1','2009Q3'))\ndf.index = index","772a8d61":"print(\"The head of the dataset is:\")\ndf.head()","06813663":" df['realgdp'].plot()","088be078":"gdp_cycle, gdp_trend = sm.tsa.filters.hpfilter(df['realgdp'])","ad9fbd68":"df['trend'] = gdp_trend\ndf[['realgdp','trend']].plot(figsize=(12,8))","35756a08":"df[['realgdp','trend']]['2002-03-31':].plot(figsize=(12,8))","ef88b417":"# Importing necessary library\nfrom statsmodels.tsa.seasonal import seasonal_decompose","2e834bf5":"df['realgdp'].plot(figsize=(12,8))","d629743e":" result = seasonal_decompose(df['realgdp'], model='additive')","65badab8":"fig = result.plot()\nfig.set_size_inches(12,8)","b202fe43":"df['12-month-SMA'] = df['realgdp'].rolling(window=12).mean()","a519336d":"df[['realgdp','12-month-SMA']].plot(figsize=(12,8))","b1c9005d":"df['EWMA-12'] =  df['realgdp'].ewm(span=12).mean()","dcfab648":"df[['realgdp','EWMA-12']].plot(figsize=(12,8))","cb9fb80a":"df['realgdp'].plot()","3e5fece4":"time_series = df['realgdp']\ntime_series.rolling(12).mean().plot(label = '12 Month Rolling Mean')\ntime_series.rolling(12).std().plot(label = '12 Month Rolling STD')\ntime_series.plot()\nplt.legend()","c2f81c55":"decomp = seasonal_decompose(time_series)\nfig = decomp.plot()\nfig.set_size_inches(12,8)","a4498335":"# Importing necessary library\nfrom statsmodels.tsa.stattools import adfuller","10a8f08d":"result = adfuller(df['realgdp'])","54874408":"def adf_check(time_series):\n    result = adfuller(time_series)\n    print(\"Augmented Dicky-Fuller Test\")\n    labels = ['ADF Test Statistic', 'p-value', '# of lags','# of observations used']\n    \n    for value, label in zip(result, labels):\n        print(label + \" : \" + str(value))\n        \n    if result[1] <= 0.05:\n        print(\"Strong evidence against null hypothesis.\\nReject Null Hypothesis.\\nData has no unit root and is stationary.\")\n    else:\n        print(\"Weak evidence against null hypothesis.\\nFail to reject Null Hypothesis.\\nData has a unit root and is non-stationary.\")","3d175959":"adf_check(df['realgdp'])","4f1792ad":"df['First Difference'] = df['realgdp'] - df['realgdp'].shift(1)\ndf['First Difference'].plot()","475ecf2d":"adf_check(df['First Difference'].dropna())","37f2ac22":"df['Second Difference'] = df['First Difference'] - df['First Difference'].shift(1)\ndf['Second Difference'].plot()","11d47777":"adf_check(df['Second Difference'].dropna())","ca4cd275":"# Importing necessary libary\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf","453c1319":"fig_first = plot_acf(df['First Difference'].dropna())","baf76494":"fig_first_pacf = plot_pacf(df['First Difference'].dropna())","8304a921":"fig_second = plot_acf(df['Second Difference'].dropna())","4142a1ef":"fig_second_pacf = plot_pacf(df['Second Difference'].dropna())","001abd91":"# Importing necessary library\nfrom statsmodels.tsa.arima_model import ARIMA","4d4d9aa3":"# Initializing the model\nmodel = sm.tsa.ARIMA(df['realgdp'], order = (1, 0, 0))","4152c78f":"# Fitting the model\nresults = model.fit()","38f60dea":"# Summary of the fit\nprint(results.summary())","1bbbf2b8":"# Plotting the residual values\nresults.resid.plot()","68acb5dd":"# Plotting the residual values KDE\nresults.resid.plot(kind='kde')","d1167763":"# Predicting using the ARIMA model\ndf['forecast'] = results.predict(start = 160, end = 203)\ndf[['realgdp','forecast']].plot(figsize = (12, 8))","d3ddf466":"# Importing necessary library\nfrom pandas.tseries.offsets import DateOffset","aa20b314":"# Since we are working with quarterly data, keeping step in range as 3\nfuture_dates = [df.index[-1] + DateOffset(months = x) for x in range(3,28,3)]","489378b2":"# Concatenating to the dataframe\nfuture_df = pd.DataFrame(index=future_dates, columns = df.columns)\nfinal_df = pd.concat([df,future_df])","da07cfae":"final_df.shape","4a5c5020":"final_df['forecast'] = results.predict(start = 168, end = 212)\nfinal_df[['realgdp','forecast']].plot(figsize = (12, 8))","bba867f4":"Looking at the plot, we can see that the we do not have any lag at the start of the data in comparison to SMA.","2785ce8a":"This is how we can perform ETS decomposition and look at the Error-Trend-Seasonality of our data.","08646489":"As we can see there is a lag at the start of the SMA. However, we can fix that with Exponential Weighted Moving Averages.\n\nNow, calculating the EWMA with a span of 12 months.","f90b4ebc":"## 2. ETS Models for time-series analysis","aae93176":"Plotting the timeseries data.","175a32f6":"The data looks seasonal and looks to have an upward trend. Calculating the 12 month SMA and plotting it.","97b3543b":"The statsmodels library contains an extensive list of descriptive statistics, statistical tests, plotting functions and result statistics for different types of data and estimators. More information about the statsmodels library can be found here: https:\/\/www.statsmodels.org\/stable\/index.html","d3f9a502":"Now that we are clear with what data we are working on, let us introduce a datetime feature out of the 'year' column to conduct time-series analysis. First, we have to find the starting and ending date range of the data.","30306e08":"Testing if the data is stationary or not using the Augmented Dickey-Fuller test. If the p-value is less than 0.05 then, the time series data is stationary. Thus, our null hypothesis states that the data is non-stationary.","5267e814":"Note: I will be updating this notebook frequently, so please feel free to check back from time to time. If you like the kernel, hope you give it an upvote.","930c7ea4":"### Coding an ARIMA Model\n\nNow, onto the coding. This is our process:\n\n- Visualize Time Series Data\n- Make the time series data stationary\n- Plot the correlation and autocorrelation charts\n- Construct the ARIMA model\n- Use the model to make predictions","4143c344":"Calcualting Simple Moving Averages for 12 months.","86456308":"## 3. SMA and EWMA Models for time-series analysis","56569975":"# Time-series analysis with Python","be227703":"The data is now stationary. Just in case if you want to perform a second difference, here is how you do it.","50ba71e7":"## 1. Introduction to statsmodels for time-series analysis","61e478aa":"Since we now have a datetime feature, we can perform analysis of multiple columnns using time-series analysis. \n\nFor an example, let us find the cyclical component and trend of the 'realgdp' column. Visualizing the column's data in respect to the datetime values.","cbc56665":"Taking a look at the data again by visualizing it, we can see that it is linearly growing.","118e1050":"Taking the first difference and performing ADF test.","4692c73b":"Plotting the result of the decomposition.","f2dd9c53":"Visualizing the trend using pandas plot() function.","9518e873":"The Hodrick-Prescott filter seperates a time-series into a cyclical component and a trend and can be easily called using the hpfilter() method of statsmodels.","bae539a0":"As we can observe, the first starting date is 1959 Quarter 1 and the ending date is 2009 Quarter 3. Therefore, creating a data range from 1959Q1 to 2009Q3 and assigning it to the index of the dataframe.","5595ee30":"Pretty close! \n\nNow, finally let's predict the values for the future. We will first have to add datetime values for the future dates that we want to predict.","1f60d8ea":"Looking at the head of the DataFrame again.","0ba130d3":"We can see that the trend is modelling the realgdp value and is upward. Let us have an even detailed look into the difference between the 'realgdp' value and the trend line.","2c8f8eb7":"An ETS Model stands for Error-Trend-Seasonality model. It takes each of the three terms (Error-Trend-Seasonality) for smoothing and may add them, multiply them or even just leave some of them out. We can create a model to fit our data based off these key factors. \n\nWe will be using Time Series Decomposition to break down the time-series data into the three key terms.\n","843be64e":"And this is how you implement the ARIMA model.","01aa0114":"Now, time for modelling. Since the data is not seasonal, we should be using the non-seasonal ARIMA model.","17092bb5":"## 4. ARIMA Model for time-series analysis","4858434d":"In this ever-growing notebook, I will be doing my best to conduct and showcase various time-series analyses with Python. If you like the notebook, please feel free to give it an upvote. ","fdd26803":"Calculating the Simple Moving Average (SMA) of a time-series data can allow us to create a simple model that describes some trend level behavior of it. However, some of the offcomings of the SMA model are the following:\n\n- Smaller windows will lead to more noise rather than signal.\n- It will always lag by the size of the window.\n- It will never reach to full peak or valley of the data due to averaging.\n- It does not inform about possible future behaviors and it only describes the trend in the data.\n- Extreme historically values can skew SMA significantly.\n\nWe can improve on the basic SMA and fix some of these issue by using an Exponentially Weighted Moving Average (EWMA) model.\n\nEWMA will allow us to reduce the lag effect from SMA and it will put more weight on values that occurred more recently (by applying more recent values). The amount of weight applied to the most recent values will depend on the actual parameters used in the EWMA and the number of periods given a window size.\n\nNow, saying all this, let us first move to calculating the Simple Moving Average and then, the Exponentially Weighted Moving Average.","20c1988e":"Plotting the data.","21fef7d2":"Now, plotting ACF and PACF for the two differences that we have took.","a4f5a728":"A sharp drop in all of our plots suggests that we should use an AR model.","84d36510":"Decomposing the time series data into ETS model.","a97c6923":"The ARIMA model is one of the most common time series models and it stands for AutoRegressive Integrated Moving Average.\n\nIt is a generalization of the autoregressive moving average (ARMA) model. Both of these models are fitted to time series data either to better understand the data or to predict future points in the series, i.e., forecasting. The two types of ARIMA models are Non-seasonal ARIMA and Seasonal ARIMA.\n\nARIMA models are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the 'integrated' part of the model) can be applied one or more times to eliminate the non-stationarity.\n\nNon-seasonal ARIMA models are generally denoted as ARIMA(p,d,q) where parameters p, d and q are non-negative integers.\n\nThe major components of non-seasonal ARIMA are:\n\n- **p (AR - Autoregression):** A regression model that utilizes the dependent relationship between a current observation and observations over a previous period.\n\n- **d (I - Integrated):** Differencing of observations (subtracting an obervation from an observation at the previous time step) in order to make the time series stationary.\n\n- **q (MA - Moving Average):** A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n\nStationary time-series data has constant mean, covariance and variance over time. We can use the Augmented Dickey-Fuller test to test if a time-series data is stationary or not.\n\nAlso, the p, d and q terms can be choosed by looking at **AutoCorrelation Plots** and **Partial AutoCorrelation Plots**.\n\n### Autocorrelation Plots and Partial AutoCorrelation Plots\n\nAn autocorrelation plot shows the correlation of the timeseries with itself, lagged by x time units. So, the y-axis of the plot is the correlation and the x-axis of the plot is the number of time units of lags. The two general autocorrelation plots are Gradual Decline and Sharp Drop-off.\n\nIf the autocorrelation plot shows positive autocorrelation at the first lag (lag-1), then it suggests to use the AR terms in relation to the lag.\n\nIf the autocorrelation plot shows negative autocorrelation at the first lag (lag-1), then it suggests to use the MA terms.\n\n- p: The number of lag observations included in the model.\n- d: The number of times that the raw observations are differenced.\n- q: The size of the moving average window, also called the order of moving average.\n\nIn general, a partial correlation is a conditional correlation. It is the correlation between two variables under the assumption that we know and take into account the values of some other set of variables.\n\nTypically, a sharp drop after lag 'k' suggests an AR-k model should be used. If there is a gradual decline, it suggests an MA model.\n\nKey points:\n\n- Identification of an AR model is often best done with the PACF(unction).\n- Identification of an MA model is often best done with the ACF(unction) rather than the PACF(unction).\n","77d7f335":"A description of the dataset can be found by running the following code.","5d0d95f5":"For this introduction section, I will be using the macrodata dataset provided by the statsmodels api.","e3ad6ef4":"Calling seasonal_decompose() function of statsmodels will provide us with the ETS values of the data.","177569cf":"The data is still stationary even if we take a second difference.","1e5fbc4d":"As we can see the trend line is representative of the data and doesn't fit perfectly to the actual values itself. This is because a trend is a smooth, general, long-term, average tendency of the data to increase or decrease during a period of time."}}