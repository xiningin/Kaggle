{"cell_type":{"76090cb8":"code","fae51175":"code","d01a764b":"code","707b1447":"code","b96116b1":"code","12e7c500":"code","81fd8ea7":"code","dd538386":"code","fac000a3":"code","1ea056e7":"code","f7b8d02c":"code","fdf594cc":"code","fb2e49c5":"code","1633929f":"code","9a569d4c":"code","2790f90a":"markdown"},"source":{"76090cb8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport torchvision.models as models\n\ntrain = pd.read_parquet(r'\/kaggle\/input\/kaggle-pog-series-s01e01\/train.parquet')\ntest = pd.read_parquet('\/kaggle\/input\/kaggle-pog-series-s01e01\/test.parquet')\nsubmission = pd.read_csv('\/kaggle\/input\/kaggle-pog-series-s01e01\/sample_submission.csv')\n\ntrain.shape, test.shape, submission.shape","fae51175":"averages_channel = train.groupby(by = ['channelTitle']).mean('target')['target'].to_dict()\n\naverages_category = train.groupby(by = ['categoryId']).mean('target')['target'].to_dict()","d01a764b":"train['target_average_channel'] = [averages_channel[a] for a in train['channelTitle']]","707b1447":"test['target_average_channel'] = [averages_channel[a] if a in set(train['channelTitle']) else averages_category[b] for a, b in zip(test['channelTitle'], test['categoryId'])]","b96116b1":"train['target_average_category'] = [averages_category[a] for a in train['categoryId']]\ntest['target_average_category'] = [averages_category[a] for a in test['categoryId']]","12e7c500":"train['trending_date'] = pd.to_datetime(train['trending_date'])\ntest['trending_date'] = pd.to_datetime(test['trending_date'])","81fd8ea7":"train['day_olds'] = (train['trending_date'].dt.date - train['publishedAt'].dt.date).dt.days\ntest['day_olds'] = (test['trending_date'].dt.date - test['publishedAt'].dt.date).dt.days","dd538386":"features = ['target_average_channel', 'target_average_category', 'comments_disabled', 'ratings_disabled', 'has_thumbnail', 'day_olds']\ntargets = ['target']","fac000a3":"from torch.utils.data import Dataset\nimport cv2\nimport torch\nfrom torchvision import transforms\nimport albumentations\nfrom PIL import Image\nimport numpy as np","1ea056e7":"class data(Dataset):\n    def __init__(self, id , tabular , image,mean , std):\n        self.id = id # for taking id of each data in table with respect to its image data  \n        self.tabular = tabular # processed and cleaned tabular data \n        self.image = image # image data with respect to its tabular data \n        self.target = tabular.target.values\n        self.aug = albumentations.Compose([\n               albumentations.Normalize(mean , std , always_apply = True) \n            ])\n        \n    def __len__(self):\n        return len(self.id) # returns the length of the dataset class\n    \n    def __getitem__(self, index):\n        id = self.id[index]\n\n        # converting numpy format of images to torch tensors for pytorch model\n \n        img = cv2.imread('\/kaggle\/input\/kaggle-pog-series-s01e01\/thumbnails\/'+ self.image[index] +'.jpg') # first loading the data from its respective folder path\n        if img is None:\n            img = np.zeros((360, 480,3), np.uint8)\n        img = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) # Resizing the images then \n        img = Image.fromarray(img).convert('RGB') # converting grayscale to RGB\n        img = self.aug(image = np.array(img))['image'] # Applying agumentations according to train or validation data on the image data\n        img = np.transpose(img, (2,0,1)).astype(np.float32) # 2,0,1 because pytorch excepts image channel first then dimension of image\n        \n        tabular = self.tabular.iloc[:,:] # converting the tabular data into numpy array\n        \n        X = tabular[['target_average_channel', 'target_average_category', 'comments_disabled'\n                     , 'ratings_disabled', 'has_thumbnail', 'day_olds']].astype(float)\n        X = X.values[index] # extracting the tabular data with respect to the index value of the image data \n        \n       # returning a dictionary for the extracted things from the dataset\n        return (torch.tensor(img, dtype = torch.float) , torch.tensor(X, dtype = torch.float) , \n                        torch.tensor(self.target[index], dtype = torch.float))","f7b8d02c":"train_data = data(id = [i for i in range(len(train))], \n                         tabular = train, \n                         image = train['video_id'],  \n                         mean = (0.485, 0.456, 0.406),\n                         std = (0.229, 0.224, 0.225) )","fdf594cc":"TRAIN_BATCH_SIZE = 200\ntraining_dataloader = DataLoader(train_data,\n                        batch_size=TRAIN_BATCH_SIZE,num_workers=6\n                       )","fb2e49c5":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# increasing few layers in our model\nclass Model(nn.Module):\n    def __init__(self):\n        # for image data\n        super(Model, self).__init__()\n        self.cnn1 = nn.Conv2d(in_channels=3,out_channels=8,kernel_size=3,stride=1,padding=1)\n        self.batchnorm1 = nn.BatchNorm2d(8)\n        self.maxpool = nn.MaxPool2d(2)\n        # output size = \n        self.cnn2 = nn.Conv2d(in_channels=8,out_channels=32,kernel_size=5,stride=1,padding=2)\n        self.batchnorm2 = nn.BatchNorm2d(32)\n        # \n        self.fc1 = nn.Linear(32768 ,600)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(600,40)\n        self.fc3 = nn.Linear(40,4)\n        self.relu = nn.ReLU() # adding a non-linear Rectified Linear Unit layer \n\n        # for tabular data\n        self.tabular_dense_layer_1 = nn.Linear(6, 16) # taking 21 columns of tabular data as channels and feeding it to 16 dense layers\n        self.tabular_dense_layer_2 = nn.Linear(16, 8) # then from 16 dense layers feeding it to 8 dense layers\n        self.tabular_dense_layer_3 = nn.Linear(8, 4) # then 8 to 4 dense layers\n        self.tabular_dense_layer_4 = nn.Linear(4, 4) # then 4 to 1 dense layer *\n\n        self.reactivity_layer = nn.Linear(8 , 1) # 1st target value generated finally taking the 1 layer of processed channel from image data and 1 layer of processed channel from tabular data adding them both and then processing them from 2 to 1 channel finally\n\n    # setting up the connection in the forward function    \n    def forward(self, inputs):\n        image_inputs , tabular_data_inputs = inputs\n        out = self.cnn1(image_inputs)\n        out = self.batchnorm1(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n\n        out = self.cnn2(out)\n        out = self.batchnorm2(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n        out = out.flatten(start_dim=1)\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc3(out)\n\n\n        # connection from our tabular data\n        tab = self.tabular_dense_layer_1(tabular_data_inputs)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_2(tab)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_3(tab)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_4(tab)\n        tab = self.relu(tab)\n        x = torch.cat((out, tab), dim=1) # this is syntax where we concatenate the 1 channel from image data and 1 from tabular data i.e. 1+1 = 2\n        x = self.relu(x)\n\n        return self.reactivity_layer(x) \n    \nmodel = Model()","1633929f":"import torch.optim as optim\nimport torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()\n\ncriterion = nn.MSELoss(reduce=True)\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","9a569d4c":"model = model.to(device)\nfor epoch in range(1):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(training_dataloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        img,tab, output = data\n        img = img.to(device)\n        tab = tab.to(device)\n        output = output.to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        # forward + backward + optimize\n        outputs = model((img,tab))\n        loss = criterion(outputs, output)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 10 == 0:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss :.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')","2790f90a":"Please upvote is this helped you in any way"}}