{"cell_type":{"f987dafe":"code","c804030c":"code","3ba8e3d7":"code","f0c307e4":"code","0b8fff75":"code","672c4f0a":"code","dcd9b279":"code","6ae92723":"code","bfc0e9f3":"code","652a2835":"code","6758b6a3":"code","c6c91bd3":"code","52652bc1":"code","3db103a8":"code","65366094":"code","d0157bd3":"code","4eda022c":"code","39136590":"code","04261f58":"code","3601e868":"code","ab9a16b3":"code","f88ccb7b":"code","6f6bd6fc":"markdown"},"source":{"f987dafe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c804030c":"df=pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')\ndf1=pd.read_csv('..\/input\/Admission_Predict.csv')","3ba8e3d7":"df.shape","f0c307e4":"df1.shape","0b8fff75":"final_df=pd.concat([df,df1],axis=0)\nfinal_df.shape","672c4f0a":"final_df.isnull().sum()","dcd9b279":"final_df.describe()","6ae92723":"import seaborn as sns\nimport pandas as pd","bfc0e9f3":"sns.pairplot(final_df,diag_kind='kde')","652a2835":"from scipy.stats import zscore\nz = np.abs(zscore(final_df))\nthreshold=3\nprint(np.where(z>33))\noutlier = final_df[(z <3).all(axis=1)]\noutlier.shape","6758b6a3":"Q1=final_df.quantile(0.25)\nQ3=final_df.quantile(0.75)\nIQR=Q3-Q1\noutliers = final_df[~((final_df < (Q1 - 1.5 * IQR)) |(final_df > (Q3 + 1.5 * IQR))).any(axis=1)]\noutliers\n","c6c91bd3":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfinal_df.columns","52652bc1":"final_df.columns\nX=final_df.drop('Chance of Admit ',axis=1)\ny=final_df['Chance of Admit ']","3db103a8":"X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.3)","65366094":"Model1=LinearRegression()\nModel1=Model1.fit(X_train,y_train)\npred=Model1.predict(X_test)","d0157bd3":"from sklearn import metrics","4eda022c":"rmse=np.sqrt(metrics.mean_squared_error(y_test,pred))\nrmse","39136590":"rmse=[]\nfrom sklearn.model_selection import KFold,cross_val_score\nkfold =KFold(n_splits=5,random_state=2)\ncv_results = cross_val_score(Model1, X, y, cv=kfold)\nrmse.append(cv_results)\nmsg =cv_results.mean()\nprint(msg)\nprint(np.std(rmse))\nrmse","04261f58":"variance=np.sum((rmse-np.mean(rmse))**2)","3601e868":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nModel2=DecisionTreeRegressor()\nModel3=KNeighborsRegressor(n_neighbors=30)","ab9a16b3":"models=[]\nmodels.append(('LinearRegression',Model1))\nmodels.append(('DecisionTree',Model2))\nmodels.append(('KNN',Model3))","f88ccb7b":"results=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,random_state=2)\n    cv_results=cross_val_score(model,X,y,cv=kfold)\n    names.append(name)\n    results.append(cv_results)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n    \n","6f6bd6fc":"#Decision Tree is showing both high variance erroe and high bias error.\n#Linear Regression is also showing high bias error."}}