{"cell_type":{"d3ce1211":"code","e31a7009":"code","69611115":"code","77efa9dd":"code","4c8a925d":"code","e0eef2fb":"code","61d18254":"code","9b0897ca":"code","37bcaee8":"code","773cc2fe":"code","dff9c9cf":"code","c200d7aa":"code","0ae3b804":"code","c056ed9d":"code","8fe64e20":"code","2b9f06c0":"code","fd9a4bfa":"code","a11d5129":"code","8ee1efaf":"code","25f3f4f4":"code","70c569e3":"code","efb03f6f":"code","4ad599a3":"code","7a920734":"code","8493318d":"code","20e70548":"code","4dae94b7":"code","4ff72354":"code","37783c08":"code","b4255083":"code","d3ddc787":"code","53fc0141":"code","5f9c9a00":"code","56142157":"code","4d3eabad":"code","7a59fb8f":"code","6681042a":"code","490c3649":"code","32c808d7":"code","0e8f9e4a":"code","7a9cae94":"code","f4bc71d7":"code","672c7828":"code","02a9cc22":"code","4c79e40c":"code","bfaad1ed":"code","09b499e7":"code","165656bf":"code","d7332b5b":"markdown","b800ece1":"markdown","a18318b6":"markdown","d7a7cdfc":"markdown"},"source":{"d3ce1211":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e31a7009":"df = pd.read_excel('\/kaggle\/input\/legio-urbana-songs\/lu2.xlsx')\ndf.head()","69611115":"df.isnull().sum()","77efa9dd":"#Code by Mohammad Imran Shaikh https:\/\/www.kaggle.com\/shikhnu\/covid19-tweets-eda-visualization-wordcloud\n\nunique_df = pd.DataFrame()\nunique_df['Features'] = df.columns\nunique=[]\nfor i in df.columns:\n    unique.append(df[i].nunique())\nunique_df['Uniques'] = unique\n\nf, ax = plt.subplots(1,1, figsize=(15,7))\n\nsplot = sns.barplot(x=unique_df['Features'], y=unique_df['Uniques'], alpha=0.8)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center',\n                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\nplt.title('Bar plot for number of unique values in each column',weight='bold', size=15)\nplt.ylabel('#Unique values', size=12, weight='bold')\nplt.xlabel('Features', size=12, weight='bold')\nplt.xticks(rotation=90)\nplt.show()","4c8a925d":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.musica)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='Set2', background_color=\"black\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","e0eef2fb":"#Code by Savita Nair https:\/\/www.kaggle.com\/savitanair\/hr-analytics\n\nprint(f'Dataset has {len(df.musica.unique())} unique groups')\nprint('*'*20)\nprint(f'And the top 10 counts are :')\nprint(df.musica.value_counts().head(10))\nprint('*'*20)\n\nc = df.musica.value_counts().head(10)\nfig, ax = plt.subplots(1,1,figsize=(12,6))\nax.bar(c.index, c.values, width=0.8, color='y')\nplt.xticks(rotation=45)","61d18254":"#Code by Savita Nair https:\/\/www.kaggle.com\/savitanair\/hr-analytics\n\nprint(f'Dataset has {len(df.letra.unique())} unique groups')\nprint('*'*20)\nprint(f'And the top 10 counts are :')\nprint(df.letra.value_counts().head(10))\nprint('*'*20)\n\nc = df.letra.value_counts().head(10)\nfig, ax = plt.subplots(1,1,figsize=(12,6))\nax.bar(c.index, c.values, width=0.8, color='b')\nplt.xticks(rotation=45)","9b0897ca":"#Code by Savita Nair https:\/\/www.kaggle.com\/savitanair\/hr-analytics\n\nprint(f'Dataset has {len(df.\u00e1lbum.unique())} unique groups')\nprint('*'*20)\nprint(f'And the top 10 counts are :')\nprint(df.\u00e1lbum.value_counts().head(10))\nprint('*'*20)\n\nc = df.\u00e1lbum.value_counts().head(10)\nfig, ax = plt.subplots(1,1,figsize=(12,6))\nax.bar(c.index, c.values, width=0.8, color='r')\nplt.xticks(rotation=45)","37bcaee8":"#Import Packages\n\nimport tensorflow as tf\nfrom pathlib import Path\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.feature_extraction import text\nimport matplotlib.pyplot as plt\nimport string\nimport re","773cc2fe":"input_folder = Path(\"\/kaggle\/input\")\ninput_file = input_folder\/\"legio-urbana-songs\"\/\"lu2.xlsx\"","dff9c9cf":"# Get Title Counts\ndf['musica'].value_counts().sort_index()","c200d7aa":"# Filter Data with more than 3 words\ndf = df[df['letra'].apply(lambda x: len(x.split(\" \")) > 3)]","0ae3b804":"# Punctuation Regex\npunct = re.compile(r'[!\\\\\"#$%&\\'()*+,-.\/:;<=>?@\\[\\]^_`{|}~0-9]+')","c056ed9d":"#Get Frequency Counts after processing => Lowercase + remove numbers, punctuation + strip whitespace\ncv = text.CountVectorizer(lowercase=True,preprocessor=lambda x: punct.sub(\"\",x.strip()).lower(),stop_words='english')","8fe64e20":"op = cv.fit_transform(df[\"letra\"])","2b9f06c0":"df_freq = pd.DataFrame(op.toarray(),columns=cv.get_feature_names())","fd9a4bfa":"df_freq.head()","a11d5129":"freq_words = df_freq.sum(axis=0)","8ee1efaf":"freq_words.sort_values(ascending=False)","25f3f4f4":"wc = WordCloud(width=600,height=300).generate_from_frequencies(freq_words)","70c569e3":"plt.rcParams[\"figure.figsize\"] = (20,5)\nplt.imshow(wc)","efb03f6f":"#Store processed text in a new column\ndf['cleaned_letra'] = df['letra'].apply(lambda x: punct.sub(\"\",x.strip()).lower())","4ad599a3":"# Join lines of a song by title\ndf_song = df.groupby('musica',sort=False).apply(lambda x: \" \".join(x['cleaned_letra']))","7a920734":"df_song.iloc[0]","8493318d":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","20e70548":"num_words = 5000\noov_token = '<UNK>'\npad_type = 'post'\ntrunc_type = 'post'","4dae94b7":"tokenizer = Tokenizer(num_words=num_words,oov_token=oov_token)","4ff72354":"tokenizer.fit_on_texts(df_song)","37783c08":"seqs = tokenizer.texts_to_sequences(df_song)","b4255083":"n_grams = 11\ngram_seqs = []\nn_seqs = len(seqs)\nfor i in seqs:\n    n_i = len(i)\n    for j in range(n_i-n_grams):\n        gram_seqs.append(i[j:j+n_grams])","d3ddc787":"labels = [i[-1] for i in gram_seqs]\ninputs = [i[:-1] for i in gram_seqs]","53fc0141":"from sklearn.preprocessing import OneHotEncoder\nfrom keras.utils import to_categorical\nfrom keras import Model\nfrom keras.layers import Dense, Embedding, LSTM, Input, Bidirectional","5f9c9a00":"encoded_labels = to_categorical(labels,num_classes=num_words)","56142157":"class lyrics_generator(Model):\n    def __init__(self):\n        super(lyrics_generator,self).__init__()\n        self.embedding = Embedding(num_words,64,input_length=n_grams-1)\n        self.lstm = Bidirectional(LSTM(20))\n        self.dense = Dense(num_words,activation='softmax')\n    \n    def call(self,x):\n        x = self.embedding(x)\n        x = self.lstm(x)\n        x = self.dense(x)\n        return x\n    \n    def model(self):\n        x = Input(shape=(n_grams-1))\n        return Model(inputs=[x], outputs=self.call(x))","4d3eabad":"m = lyrics_generator()","7a59fb8f":"dataset = tf.data.Dataset.from_tensor_slices((inputs,encoded_labels)).batch(64)","6681042a":"m.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n          ,loss=tf.keras.losses.CategoricalCrossentropy()\n         ,metrics=[tf.keras.metrics.CategoricalAccuracy()])","490c3649":"m.model().summary()","32c808d7":"history = m.fit(dataset,epochs=200,verbose=0)","0e8f9e4a":"print(\"Loss: {} and Accuracy: {}\".format(history.history['loss'][-1],history.history['categorical_accuracy'][-1]))","7a9cae94":"def write_lyric(text,text_length=10):\n    for i in range(text_length):\n        seqs_test = tokenizer.texts_to_sequences([text])\n        seqs_test = pad_sequences(seqs_test,maxlen=n_grams-1,value=1)\n        pred_probs = m(seqs_test)\n        index = tf.argmax(pred_probs,axis=1)[0].numpy()\n        word = tokenizer.index_word[index]\n        text = text+\" \"+word\n    return text","f4bc71d7":"write_lyric(\"tire suas m\u00e3os\")","672c7828":"write_lyric(\"medo da escurid\u00e3o\")","02a9cc22":"write_lyric(\"ego\u00edsmo n\u00e3o\")","4c79e40c":"write_lyric(\"conseguir vencer\")","bfaad1ed":"write_lyric(\"nossa pr\u00f3pria cria\u00e7\u00e3o\")","09b499e7":"write_lyric(\"ser\u00e1\")","165656bf":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Ser\u00e1? What the f* is that lyrics above? Mar\u00edlia Prata, @mpwolke was Here' )","d7332b5b":"![](https:\/\/i.pinimg.com\/originals\/c4\/e3\/b6\/c4e3b6b41644308e64f1802e7ba16300.jpg)pinterest","b800ece1":"I tried to change stop words to PORTUGHESE. It didn't work.","a18318b6":"#\"Tire suas m\u00e3os de mim eu n\u00e3o perten\u00e7o a voc\u00ea. N\u00e3o \u00e9 me dominando assim que voc\u00ea vai me entender.\"\n\nNothing to do with the output above.","d7a7cdfc":"#Codes by Akhil Teja  https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python"}}