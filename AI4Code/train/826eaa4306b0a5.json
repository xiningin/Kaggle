{"cell_type":{"7cf37201":"code","b8c4fe17":"code","766cbdea":"code","53108bff":"code","ba1d9bc7":"code","5b60716f":"code","cb8df998":"code","1831d59e":"code","6170f93c":"code","b928bb9f":"code","e4692d27":"code","3b867c46":"code","e9d8e225":"code","68a643ef":"code","ba85e532":"code","b401e11c":"code","4cde22a9":"code","6129a8f0":"code","b483fec5":"code","2af47388":"code","c85bc08e":"code","4d12607f":"code","cbf2a427":"code","bfee0b8d":"code","ee1842ef":"code","950d6f60":"code","c5d2e19f":"code","d94ad603":"code","7ad21aaa":"code","3c1e3d7e":"code","bf4abb79":"code","d1799707":"code","5426e970":"code","da956bed":"code","f8f1561e":"code","b516d9a4":"code","517cab81":"code","7e3697cb":"code","3b3f5dc8":"code","aa10edd8":"code","c3b5bc12":"code","1652631d":"code","73c72770":"code","03fb1714":"code","ad0fac10":"code","af2c9eef":"code","752c91a1":"markdown","674d7dd4":"markdown"},"source":{"7cf37201":"#Importation des librairies Pandas et seaborn et renommagerespectivement en pd et sns\n#seaborn permet l'affichage des tableaux\nimport seaborn as sns\nimport pandas as pd\n#Charger les donn\u00e9es du fichier sms-spam-collection-dataset sous forme de dataframe:\nsms = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\", encoding='latin-1')\n#afficher les premi\u00e8res lignes du tableau\nsms.head()","b8c4fe17":"#affichage des dimensions du tableau pour v\u00e9rifier la consigne\nsms.shape","766cbdea":"#Supression des colonnes (axis1) vides (Unnamed: 2', 'Unnamed: 3','Unnamed: 4)\nsms=sms.drop(['Unnamed: 2', 'Unnamed: 3','Unnamed: 4'], axis=1)","53108bff":"#Renommage des colonnes V1 et V2 respectivement en Label et Message et affichage du resultat\nsms.rename(columns={'v1': 'Label', 'v2': 'Message'},inplace={True})\nsms.head()","ba1d9bc7":"sms[\"Label\"] = sms[\"Label\"].astype(\"category\")\n#on d\u00e9finit le type comme cat\u00e9gorie bien que ce ne soit pas n\u00e9cessaire\n#cr\u00e9ation de l'histogramme affichant la quantit\u00e9 de spam et ham\nsns.countplot(sms.Label)\nsms.head()","5b60716f":"#affichage des dimensions de la dataframe\nsms.shape","cb8df998":"#R\u00e9duction de la taille de la police en minuscules\nsms['Message']=sms['Message'].str.lower()","1831d59e":"#Importation de la fonction word_tokenize de la biblioth\u00e8que nltk.tokenize\nfrom nltk.tokenize import word_tokenize","6170f93c":"#Importation des ponctuations et affichage de ces derni\u00e8res\nimport string\nstring.punctuation","b928bb9f":"#Retrait des ponctuations des lignes du tableau\ndef remove_punct(text):\n    #division du text en moreceaux\n    text_tok = word_tokenize(text)\n    #initialiser liste vide\n    l=[]\n    for token in text_tok :\n        if not token in string.punctuation :\n        #test si text n'est pas dans ponc\n            l.append(token)\n    resultat = \" \".join(l)\n    \n    return resultat","e4692d27":"#application de la fonction \u00e9dit\u00e9e pr\u00e9c\u00e9demment\nsms['Message']=sms.Message.apply(remove_punct)\nsms.Message","3b867c46":"from nltk.corpus import stopwords\n#T\u00e9l\u00e9charger les stopwords\nstop=set(stopwords.words('english'))","e9d8e225":"#D\u00e9finition de la fonction stopword\ndef remove_stopword(text):\n    text_tok= word_tokenize(text)\n    l=[]\n    for token in text_tok : \n        if not token in stop : \n            l.append(token)\n    resultat= \" \".join(l)\n    return resultat","68a643ef":"#application de la fonction \u00e9dit\u00e9e pr\u00e9c\u00e9demment\nsms['Message']=sms.Message.apply(remove_stopword)\nsms.Message","ba85e532":"#Importation de la fonction wordnetlemmatizer de la biblioth\u00e8que nltk.stem\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer=WordNetLemmatizer()\n#on renomme just la fonction pour simplifier l'expression","b401e11c":"def lemm(text):\n    text_tok = word_tokenize(text)\n    l=[]\n    for token in text_tok :\n        l.append(lemmatizer.lemmatize(token))\n    resultat = \" \".join(l)\n    return resultat","4cde22a9":"sms.Message=sms.Message.apply(lemm)\nsms.head()","6129a8f0":"corpus=sms['Message'].values\ncorpus","b483fec5":"from sklearn.feature_extraction.text import CountVectorizer\nbw_vect = CountVectorizer(max_features=200)\n# tokenize et construire le vocabulaire\nbw_fit=bw_vect.fit(corpus)\n# vectoriser les mots\nbw_corpus = bw_fit.transform(corpus)","2af47388":"cv_data=pd.DataFrame(bw_corpus.toarray(),columns=bw_fit.get_feature_names())\ncv_data","c85bc08e":"from sklearn.model_selection import train_test_split\nY=sms.Label\nX=cv_data\n# Split train \/ test data :\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n","4d12607f":"from sklearn import tree\n#choisir le nombre d'\u00e9tapes de l'arbre sa profondeur (changer le depth pour essayer)\ntree_model = tree.DecisionTreeClassifier(max_depth = 15)\ntree_model=tree_model.fit(X_train, Y_train)","cbf2a427":"X_train.shape","bfee0b8d":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'ham']\ntree.plot_tree(tree_model,feature_names = X.columns, \n               class_names=names,\n               filled = True)","ee1842ef":"Y_predict=tree_model.predict(X_test)","950d6f60":"Y_predict.shape","c5d2e19f":"from sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predict, Y_test)\nprint(mat)","d94ad603":"#plt.figure(figsize=(15,5))\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","7ad21aaa":"# Accuracy: nb bonne rep \/par le nb total de rep\na_CART = accuracy_score(Y_test,Y_predict)\nprint(\"L'accuracy score du mod\u00e8le CART est de : \",a_CART)","3c1e3d7e":"from sklearn.model_selection import GridSearchCV\nimport numpy as np\ndepths = np.arange(1, 21,2)\nparam_grid = [{'max_depth':depths}]\ngrid_tree= GridSearchCV(estimator=tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='accuracy',cv=10)\ngrid_tree.fit(X_train, Y_train)\nbest_model_tree = grid_tree.best_estimator_\n#permet de trouver le meilleur parametre de recherche\n","bf4abb79":"grid_tree.best_params_","d1799707":"from sklearn.feature_extraction.text import TfidfVectorizer","5426e970":"#Initialiser les param\u00e8tres du vectoriseur\ntf_vect = TfidfVectorizer(max_features=200)\n#Apprendre le vocabulaire du vectoriseur bas\u00e9 sur le param\u00e8tre initialis\u00e9\ntfidf_fit=tf_vect.fit(corpus)\n#Vectoriser le corpus\ntfidf_corpus= tfidf_fit.transform(corpus)","da956bed":"tfidf_data=pd.DataFrame(tfidf_corpus.toarray(),columns=tfidf_fit.get_feature_names())\ntfidf_data","f8f1561e":"from sklearn.model_selection import train_test_split\nY=sms.Label\nX=tfidf_data\n# Split train \/ test data :\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)","b516d9a4":"from sklearn import tree\n#choisir le nombre d'\u00e9tapes de l'arbre sa profondeur (changer le depth pour essayer)\ntree_model = tree.DecisionTreeClassifier(max_depth = 15)\ntree_model=tree_model.fit(X_train, Y_train)","517cab81":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'ham']\ntree.plot_tree(tree_model,feature_names = X.columns, \n               class_names=names,\n               filled = True)","7e3697cb":"Y_predict=tree_model.predict(X_test)\nfrom sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predict, Y_test)\nprint(mat)","3b3f5dc8":"#plt.figure(figsize=(15,5))\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","aa10edd8":"# Accuracy: nb bonne rep \/par le nb total de rep\na_CART = accuracy_score(Y_test,Y_predict)\nprint(\"L'accuracy score du mod\u00e8le CART est de : \",a_CART)","c3b5bc12":"from sklearn.model_selection import GridSearchCV\nimport numpy as np\ndepths = np.arange(10, 40, 5)\nparam_grid = [{'max_depth':depths}]\ngrid_tree= GridSearchCV(estimator=tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='accuracy',cv=10)\ngrid_tree.fit(X_train, Y_train)\nbest_model_tree = grid_tree.best_estimator_\n#permet de trouver le meilleur parametre de recherche\ngrid_tree.best_params_","1652631d":"#choisir le nombre d'\u00e9tapes de l'arbre sa profondeur (changer le depth pour essayer)\ntree_model = tree.DecisionTreeClassifier(max_depth = 20)\ntree_model=tree_model.fit(X_train, Y_train)","73c72770":"\nplt.figure(figsize=(15,10))\nnames = ['spam', 'ham']\ntree.plot_tree(tree_model,feature_names = X.columns, \n               class_names=names,\n               filled = True)","03fb1714":"def classer(text):\n    text=text.lower()\n    text=remove_punct(text)\n    text=remove_stopword(text)\n    text=lemm(text)\n    tfidf_text=tfidf_fit.transform([text])\n    resultat=best_model_tree.predict(tfidf_text)\n    \n    return resultat","ad0fac10":"classer('i need your money')","af2c9eef":"while True:\n    text = str(input(\"Input: \"))\n    if text== \"exit\":\n        print(\"Response: Exiting.....\")\n        break\n    print(\"Response:\",classer(text))","752c91a1":"M\u00e9thode Bag of words :","674d7dd4":"M\u00e9thode TF-IDF"}}