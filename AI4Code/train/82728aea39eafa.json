{"cell_type":{"894714c8":"code","73c69095":"code","37b53e30":"code","f1009c56":"code","f1cc2822":"code","e0239c01":"code","12dfcafc":"code","1b8ab0dc":"code","55546813":"code","9b2ff895":"code","f8e16d67":"code","339e8647":"code","ffb45908":"code","3a7a1a24":"code","5d8f1a1c":"code","f7d856ab":"code","ee44b165":"code","1a4045d6":"code","cf878bb5":"code","194f5cbb":"code","d311d181":"markdown","d262f2b1":"markdown","0cdd00ab":"markdown","f364e1a9":"markdown","5c0ce5ab":"markdown","5ad93f00":"markdown","8d977d1b":"markdown","d7fd22af":"markdown","d0ec6c53":"markdown","42b43e23":"markdown","25fd951b":"markdown","5cf06faf":"markdown","80e36f82":"markdown"},"source":{"894714c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","73c69095":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","37b53e30":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest  = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","f1009c56":"print(train.columns)","f1cc2822":"y_train = train[\"label\"]\nx_train = train.drop(labels=[\"label\"],axis =1)\n\ny_train.value_counts()","e0239c01":"x_train = x_train\/255.0\ntest = test\/255.0\n\nprint(x_train[\"pixel454\"])","12dfcafc":"x_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",x_train.shape)\nprint(\"test shape: \",test.shape)\n\n","1b8ab0dc":"y_train = to_categorical(y_train, num_classes =10)","55546813":"x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size = 0.1, random_state=2)","9b2ff895":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","f8e16d67":"learning_rate = 0.001\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","339e8647":"model.compile(optimizer = optimizer,loss = \"categorical_crossentropy\",\n             metrics=[\"accuracy\"])","ffb45908":"epochs = 2\nbatch_size = 250","3a7a1a24":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","5d8f1a1c":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                             epochs = epochs, validation_data = (x_val,y_val),\n                             steps_per_epoch = x_train.shape[0] \/\/ batch_size)","f7d856ab":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","ee44b165":"# Confusion matrix e bakal\u0131m \n\nimport seaborn as sns\n# Modelimzi predict ediyoruz\nY_pred = model.predict(x_val)\n# \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# \nY_true = np.argmax(y_val,axis = 1) \n# \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\n# ve \u00e7izdirelim\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","1a4045d6":"# Yanl\u0131\u015f tahmin edilen baz\u0131 \u00f6rnekleri g\u00f6relim\n\n\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = x_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\nmost_important_errors = sorted_dela_errors[-6:]\n\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","cf878bb5":"# test edelim\nresults = model.predict(test)\n\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","194f5cbb":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","d311d181":"**\u015eimdi label encoding yap\u0131caz. Yani say\u0131lar\u0131 s\u0131n\u0131fland\u0131r\u0131ca\u011f\u0131z. **","d262f2b1":"**\u015eimdi reshape yapaca\u011f\u0131z.**","0cdd00ab":"**Modelimizi compile ettik. Accucary \u00fczerinden de\u011ferlendirece\u011fimizi s\u00f6yledik.**","f364e1a9":"**test_size = datam\u0131z\u0131 hangi oranda b\u00f6lece\u011fimizi s\u00f6yler. %10 olarak ay\u0131rd\u0131k.\nrandom_state = bu ay\u0131rma i\u015flemi random bir \u015fekilde yap\u0131l\u0131yor. Kodu her run etti\u011fimizde farkl\u0131 de\u011ferler almamak i\u00e7in random_state belirliyoruz.**","5c0ce5ab":"**\u015eimdi \u00f6nemli hyper parameterlerimiz olan epoch ve batch_size \u0131 belirleyelim.\nEpoch = Modelimizin ka\u00e7 kere \u00e7al\u0131\u015faca\u011f\u0131n\u0131 belirler.\nbatch_size = Bir \u00e7al\u0131\u015fmad\u0131 ka\u00e7 veriyi ayn\u0131 anda e\u011fitece\u011fimizi belirler.**","5ad93f00":"**train'in ilk s\u00fctunu labeld\u0131r. Yani say\u0131n\u0131n ka\u00e7 oldu\u011funu s\u00f6yleyen s\u00fctundur. Bu y\u00fczden onu y_traine al\u0131yoruz. Sonra label s\u00fctununu \u00e7\u0131kar\u0131p kalanlar\u0131 x_traine al\u0131yoruz.**","8d977d1b":"**Ve datalar\u0131m\u0131z haz\u0131r \u015fimdi CNN modelimize kurabiliriz.\nKuraca\u011f\u0131m cnn mimarisi bu \u015fekilde -> [[Conv2D->relu] -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out \nMimariye l\u00fctfen tak\u0131lmay\u0131n. Kendimi geli\u015ftirmekteyim.**","d7fd22af":"**\u015fimdi learning_rate yi belirleyelim. learning_rate modelin \u00f6\u011frenme h\u0131z\u0131d\u0131r. Model geli\u015ftik\u00e7e \u00f6\u011frenme h\u0131z\u0131da belli oranlarda de\u011fi\u015fsin diye belirli optimizasyonlar yazm\u0131\u015flar. Biz bunlar adaptif moment'i kullanaca\u011f\u0131z.**","d0ec6c53":"***Data augmentation yapal\u0131m. Yani elimizdeki verilerin\nkonumlar\u0131yla renkleriyle vs. \u00f6zellikleri oynayarak onlar\u0131 \u00e7o\u011faltal\u0131m.\nBu \u00f6zelliklerin ne oldu\u011fun daha iyi anlamak i\u00e7in keras'\u0131n d\u00f6k\u00fcmanlar\u0131na bakabilirsiz.\nGayet anla\u015f\u0131l\u0131r ve \u00f6rneklidir.**\n","42b43e23":"**\u015eimdi datalar\u0131m\u0131z\u0131 normalle\u015ftiriyoruz. Yani normalizasyon yap\u0131yoruz.Normalizasyon yapmak datalar\u0131 0 ile 1 aras\u0131nda de\u011ferlere getirmektir. Resimdeki renk kanallar\u0131 i\u015fimizi zorla\u015ft\u0131rmamas\u0131 i\u00e7in hepsi gri tonu yap\u0131yoruz.**","25fd951b":"**\u015eimdi datalar\u0131m\u0131z\u0131 split yapaca\u011f\u0131z. Ger\u00e7ek d\u00fcnya verileri ile test etmeden \u00f6nce kendi verilerimiz ile test etmek i\u00e7in bunu yap\u0131yoruz.**","5cf06faf":"**** Modelimiz haz\u0131r art\u0131k fit edip sonucumuzu g\u00f6rebiliriz.***","80e36f82":"Geri d\u00f6n\u00fc\u015fleriniz benim i\u00e7in \u00f6nemlidir. G\u00f6rd\u00fc\u011f\u00fcn\u00fcz hatalar\u0131 l\u00fctfen s\u00f6yleyin. Te\u015fekk\u00fcrler."}}