{"cell_type":{"d9b82443":"code","844bfca0":"code","349d2912":"code","c3fb3812":"code","89cd6288":"code","02e742e5":"markdown"},"source":{"d9b82443":"# Importing modules\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score","844bfca0":"# Loading Datasets\ndata_train  = pd.read_csv('..\/input\/learn-together\/train.csv')\ndata_test = pd.read_csv('..\/input\/learn-together\/test.csv')","349d2912":"# Droping 'Id' and 'Cover_Type' columns\ndata_train=data_train.drop(['Id'],axis=1)\ndata_id = data_test['Id']\ndata_test = data_test.drop(['Id'],axis=1)\n\nx = data_train.drop(['Cover_Type'],axis=1)\ny = data_train['Cover_Type']","c3fb3812":"# The model parameters are obtained using GridSearchCV and insted spliting the dataset into train and \n# valid sets I am using the complete training set to Train.\nclf = XGBClassifier(n_estimators=500,colsample_bytree=0.9,max_depth=9,random_state=1,eta=0.2)\nclf.fit(x,y)","89cd6288":"test_pred = clf.predict(data_test)\noutput = pd.DataFrame({'Id': data_id,\n                       'Cover_Type': test_pred})\noutput.to_csv('submission.csv', index=False)","02e742e5":"Hello kagglers,In this Kernel, I have used XGBClassifier is trained on complete training data to learn more about data and this always increases the accuracy by a large margin. The classifer's parameter is obtained using GridSearchCV.\nYour feedback is important. :)\nIf you like the work Please **UpVote** :)"}}