{"cell_type":{"fb4a0da4":"code","75831b00":"code","8c8a1ccb":"code","6377b504":"code","ea59db22":"code","460f8c35":"code","34829aad":"code","2a543f05":"code","9f3644c8":"code","9bff8191":"code","ef92b254":"code","9e13ba55":"code","3511e0db":"code","419755cb":"code","4a97c771":"code","520b6ba9":"code","a6781e86":"code","fd530a48":"code","a966f27f":"code","6c074016":"code","5ebe4b78":"code","4eda8776":"code","c40886d6":"code","25b3f4d4":"code","f901c19b":"code","433ef266":"code","7aa89a42":"code","8b02007e":"code","b5749661":"code","2ee148cf":"code","17e5d341":"code","5b591e96":"code","cb1b439d":"code","eb923cc7":"code","255b8111":"code","8c0a4378":"code","d4cb9ac1":"code","877ca4fd":"code","ae47329d":"code","d29abdb7":"code","34101d0e":"code","532d9329":"code","a0e7329a":"code","918c5a78":"code","a34a44b4":"code","07997a9d":"markdown","36a47778":"markdown","22b7e9a9":"markdown","4c7b7663":"markdown","4535980b":"markdown","72b39897":"markdown","3027381a":"markdown","8474bb6c":"markdown","d4984dab":"markdown","d7f4a4b1":"markdown","ed154a69":"markdown","34afda7f":"markdown","11e71a0d":"markdown","d02795b8":"markdown","20ae5591":"markdown","12a4c509":"markdown","c4967cca":"markdown","2ab0e0c0":"markdown"},"source":{"fb4a0da4":"# Heart Attack Analysis and Prediction Dataset\n# Date: April 26, 2021","75831b00":"import numpy as np #linear algebra\nimport pandas as pd #data processing\n\nimport matplotlib.pyplot as plt #data visualization\nimport seaborn as sns #data visualization\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") #to ignore the warnings\n\n#for model building\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb\n","8c8a1ccb":"#Reading the csv file heart.csv in variable \ndf=pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","6377b504":"# looking at the first 5 rows of our data\ndf.head(10)\n","ea59db22":"df.shape","460f8c35":"df.tail(25)","34829aad":"print('Number of rows are',df.shape[0], 'and number of columns are ',df.shape[1])","2a543f05":"df.info()","9f3644c8":"df.isnull().sum()","9bff8191":"df.columns","ef92b254":"df.duplicated().sum()","9e13ba55":"df.drop_duplicates(inplace=True)\nprint('Number of rows are',df.shape[0], 'and number of columns are ',df.shape[1])","3511e0db":"df.describe().T","419755cb":"sns.pairplot(df)","4a97c771":"#This is to look at what all unique values have . Just trying to use python\nlist_col=['sex','chol','trtbps','cp','thall','exng']\n\nfor col in list_col: \n    print('{} :{} ' . format(col.upper(),df[col].unique()))","520b6ba9":"sns.boxplot(df['trtbps'])\n","a6781e86":"sns.boxplot(df['chol'])","fd530a48":"sns.boxplot(df['thalachh'])","a966f27f":"sns.boxplot(df['oldpeak'])","6c074016":"print(np.where(df['trtbps']>175))\nprint(np.where(df['chol']>380))\nprint(np.where(df['oldpeak']>4))\nprint(np.where(df['thalachh']<80))","5ebe4b78":"df.drop(df.index[[101, 110, 202, 222, 247, 259, 265,28,85,  96, 219, 245,101, 203, 220, 249, 290,271]],inplace=True)","4eda8776":"df.shape","c40886d6":"df.tail(15)","25b3f4d4":"print(f'Number of people having sex as 0 are {df.sex.value_counts()[0]} and Number of people having sex as 1 are {df.sex.value_counts()[1]}')\np = sns.countplot(data=df, x=\"sex\", palette='pastel')\nplt.show()","f901c19b":"sns.countplot(x='cp', data=df, palette='pastel')","433ef266":"sns.countplot(x='fbs', data=df, palette='pastel')","7aa89a42":"sns.countplot(x='thall', data=df, palette='pastel')","8b02007e":"sns.countplot(x='restecg', data=df, palette='pastel')","b5749661":"plt.figure(figsize = (10,10))\nsns.swarmplot(x=df['caa'],y=df['age'],hue=df['output'], palette='pastel')","2ee148cf":"sns.color_palette(\"pastel\")\nplt.title('Checking Outliers with distplot()')\nsns.distplot(df.trtbps, label='trtbps', kde=True, bins=10, color='green')\nplt.legend()","17e5d341":"plt.title('Checking Outliers with distplot()')\nsns.distplot(df.chol, label='chol', kde=True, color='red')\nplt.legend()","5b591e96":"plt.title('Checking Outliers with distplot()')\nsns.distplot(df['thalachh'],label='thalachh', kde=True )\nplt.legend()","cb1b439d":"plt.figure(figsize=(20,10))\nsns.lineplot(x = df['age'], y = df['thall'],marker = '*', linestyle = '--', color = 'red')\n\nplt.figure(figsize = (20,10))\nsns.regplot(x=df['age'],y=df['oldpeak'])","eb923cc7":"X = df.drop('output', axis = 1)\ny = df['output']","255b8111":"df.reset_index(drop=True, inplace=True)","8c0a4378":"columns_to_scale = df.iloc[:,[0,3,4,7,9,]]\ncolumns_to_scale","d4cb9ac1":"# Spliting the data\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\nss = StandardScaler()\nscaled_values = ss.fit_transform(columns_to_scale)\nscaled_values = pd.DataFrame(scaled_values, columns=columns_to_scale.columns)\nscaled_values\n","877ca4fd":"scaled_df = pd.concat([scaled_values,df.iloc[:,[1,2,5,6,8,10,11,12,13]]],axis=1)\nscaled_df","ae47329d":"key = ['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier','GradientBoostingClassifier','AdaBoostClassifier','XGBClassifier']\nvalue = [LogisticRegression(random_state=9), KNeighborsClassifier(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(), AdaBoostClassifier(), xgb.XGBClassifier()]\nmodels = dict(zip(key,value))","d29abdb7":"predicted =[]","34101d0e":"for name,algo in models.items():\n    model=algo\n    model.fit(X_train,y_train)\n    predict = model.predict(X_test)\n    acc = accuracy_score(y_test, predict)\n    predicted.append(acc)\n    print(name,acc)","532d9329":"plt.figure(figsize = (10,5))\nsns.barplot(x = predicted, y = key, palette='pastel')","a0e7329a":"lr = AdaBoostClassifier(n_estimators=100, random_state=0)\nrs = []\nacc = []\nfor i in range(1,100,1):\n    X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = i)    \n    model_lr_rs = lr.fit(X_train, y_train.values.ravel())\n    predict_values_lr_rs = model_lr_rs.predict(X_test)\n    acc.append(accuracy_score(y_test, predict_values_lr_rs))\n    rs.append(i)","918c5a78":"plt.figure(figsize=(10,10))\nplt.plot(rs, acc)","a34a44b4":"for i in range(len(rs)):\n    print(rs[i],acc[i])","07997a9d":"**Observation:** Thall count is maximum for type 2 ( 165 ) and min for type 0 ( 2 ) .\n","36a47778":"# Hear Attack Analysis and Prediction Dataset\n\nThis dataset contains information about people and there chances of having a heart stroke.\n\n\n **Dataset Information:**\n\n\n\n\n\n* Age : Age of the patient\n* Sex : Sex of the patient\n* exang: exercise induced angina (1 = yes; 0 = no)\n* ca: number of major vessels (0-3)\n* cp : Chest Pain type chest pain type\n    * Value 1: typical angina\n    * Value 2: atypical angina\n    * Value 3: non-anginal pain\n    * Value 4: asymptomatic\n* trtbps : resting blood pressure (in mm Hg)\n* chol : cholestoral in mg\/dl fetched via BMI sensor\n* fbs : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n* rest_ecg : resting electrocardiographic results\n    * Value 0: normal\n    * Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n* thalach : maximum heart rate achieved\n* target : \n    * 0 = less chance of heart attack \n    * 1 = more chance of heart attack\n    \n    \n\n**Objective:**\n\n\n\n\n* With the dataset provided for heart analysis, we have to analyse the possibilities of heart attack on the basis of various features, and then the prediction from the analysis will tell us that whether an individual is prone to heart attack or not. \n* The detailed analysis can proceed with the exploratory data analysis (EDA). \n* The classification for predication can be done using various machine learning model algorithms, choose the best suited model for heart attack analysis and finally save the model in the pickle (.pkl) file.\n\n\n**Questions to be answered:**\n\n\n\n\n\n* Does the age of a person contribute towards heart attack?\n* Are different types of chest pain related to each other or the possibility of getting a heart attack?\n* Does high blood pressure increase the risk of heart attack?\n* Does the choestrol level eventually contribute as a risk factor towards heart attack?\n\n","22b7e9a9":"**Observations:**\n\n* trtbps and chol looks like they are normally distributed, with some outliers highly skewed towards right.\n* In case of thalachh the data is highly skewed towards right!","4c7b7663":"**Observation:**\n\n* The average blood pressure of an individual is 130 whereas the maximun value goes upto 200.\n* The average heart rate of the group is 152, whereas overall it ranges between 133 to 202\n* Age of the group varies from 29 to 77 and the mean age is 55.5","4535980b":"**Observation:** \n\n* The number of people belonging to sex category 0 are 96 whereas 1 are 206.\n* The number of people in one category are more than double than the zero.","72b39897":"# Conclusion: \n\n\n* High Blood Pressure, High Cholestrol and High Heart Rate leads to high chance of heart attack.\n\n* In the count of target showed up that we have more chance of heart attack details.\n\n* Age from 40-60 years have the high chance of heart attack.\n\n* Male gender has more chance of heart attack compared to female ones.\n\n* Highly Correlated factors in this dataset are :\n    * Age and trtbps (blood pressure rate)\n    * Age and chol (cholestrol level)","3027381a":"**Observation:**\n \n * Seems like all the columns are already in int or float data types.\n * If the columns were not in int or float ( i.e they were categorical variables), we would have had to convert them for model building.\n * Few ways to do so are by using pd.get_dummies, one hot encoding, multi collinearity, label encoder etc.","8474bb6c":"**Observation:**  From the above figure we can see that none of the above models give an accuracy greater than 90%. Let us try some other approach. Lets take some other random_state for Logistic Regression Model and see if the accuracy improves!","d4984dab":"**Observation:**\n\n* There are two sex : 0 and 1\n* The highest cholestrol level is 564 and the lowest is 126.\n* Resting Blood Pressure of individuals vary between 94 to 200.\n* There are 4 types of chest pain.\n* exercise induced angina has 2 types (1 = yes; 0 = no)","d7f4a4b1":"**Observation:**\n\n* There are no missing rows in the entire dataset.\n* All the columns except oldpeak (float) are of int data type.","ed154a69":"**Observation:** There are no missing values.","34afda7f":"**Observation:**\n\n* This swarmplot gives us a lot of information.\n* Accoring to the figure, people belonging to caa category '0' , irrespective of their age are highly prone to getting a heart attack.\n* While there are very few people belonging to caa category '4' , but it seems that around 75% of those get heart attacks.\n* People belonging to category '1' , '2' and '3' are more or less at similar risk.","11e71a0d":"**Observation:**\n\n* cp : Chest Pain type chest pain type\n\n    * Value 0: typical angina\n    * Value 1: atypical angina\n    * Value 2: non-anginal pain\n    * Value 3: asymptomatic\n    \n* People of chest pain category '0' have the highest count, whereas of count of chest pain '3' is the lowest","d02795b8":"**Observation:** People of fbs category 1 are less than 25% of people of fbs category 0.","20ae5591":"**About StandardScaler:**\n\n* Python sklearn library offers us with StandardScaler() function to standardize the data values into a standard format.\n\n* Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).\n\n* StandardScaler follows Standard Normal Distribution (SND). Therefore, it makes mean = 0 and scales the data to unit variance.","12a4c509":"**Observation:** There is 1 duplicate row. Let's drop it!","c4967cca":"**Observation:** \n\n* This hardly provides any information. \n* The relationship between age-oldpeak and age-thall is highly uncertain and varies significantly.","2ab0e0c0":"**Observation:** \n\n* ECG count is almost the same for type 0 and 1. \n* Also, its almost negligible for type 2 in comparision to type 0 and 1."}}