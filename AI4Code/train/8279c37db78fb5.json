{"cell_type":{"fe35aca2":"code","dd34ed03":"code","753e71bf":"code","4e754ee9":"code","242b0664":"code","b7fb3165":"code","fb95c1e0":"code","08379df1":"code","31b6e8f3":"code","3990058b":"code","bf7147fe":"code","2f777cb2":"code","1220c4c7":"code","e866da3f":"markdown","89622c0a":"markdown","d7e52202":"markdown","3008e451":"markdown","5ff387a7":"markdown","d3791b0d":"markdown","66ddf8dc":"markdown","f350cea3":"markdown","a10892e0":"markdown"},"source":{"fe35aca2":"# For audio files \nimport librosa as lr\nfrom glob import glob\n\n# Lineas algebra\nimport numpy as np\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data laoding\nimport pandas as pd","dd34ed03":"# default settings\nplt.rcParams['figure.dpi'] = 200 #high resolution\ncolors = ['#264653', '#2a9d8f', '#e9c46a', '#f4a261', '#e76f51']\ncolors.reverse()\ncolors = sns.color_palette(colors)\nsns.palplot(colors)\nsns.set_palette(colors)\n\n# utilities\ndef get_unique_count(col):\n    return setA_df[col].nunique()","753e71bf":"# List all the wave files in the folder\ndata_dir = '..\/input\/heartbeat-sounds\/set_a'\naudio_files = glob(data_dir + '\/*.wav')\n\n# Read one audio file, create the time array\naudio, audio_sfreq = lr.load(audio_files[20])\ntime = np.arange(0, len(audio)) \/ audio_sfreq","4e754ee9":"# Plot audio over time\nfig, ax = plt.subplots()\nax.plot(time, audio)\nax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\nax.set_title('Heartbeat of person through time')\nplt.show()","242b0664":"setA_df = pd.read_csv('..\/input\/heartbeat-sounds\/set_a.csv')\nsetA_df.head(5)","b7fb3165":"# labels in the data \nset(setA_df['label'].values)","fb95c1e0":"# Extracting the normal and abnormal heartbeat sounds\nnormal = audio_files = glob(data_dir + '\/normal__2011*.wav')\nabnormal = audio_files = glob(data_dir + '\/murmur*.wav')\n\n# The lengths are the same \n#assert len(normal) == len(abnormal)\n\n# Calculate the time array \ntime = np.arange(0, len(normal)) \/ audio_sfreq\n\n# Read one audio file, create the time array\nnormal_audio, sfreq = lr.load(normal[0])\nabnormal_audio, sfreq = lr.load(abnormal[0])\n\n# Calculate the time array \ntime = np.arange(0, len(normal_audio)) \/ sfreq\n\n# Visualize the data \nfig2, ax2 = plt.subplots(2,1)\nax2[0].plot(time, normal_audio)\nax2[0].set_xlabel('time')\nax2[0].set_ylabel('heartbeat')\nax2[0].set_title('normal')\nax2[1].plot(time, abnormal_audio)\nax2[1].set_xlabel('time')\nax2[1].set_ylabel('heartbeat')\nax2[1].set_title('abnormal')\n\nfig.tight_layout()\nplt.show()","08379df1":"# Make a series of data points \naudio = pd.Series(normal_audio, index=time)\n\n# Plot the raw data first\nraw_plot = audio.plot(figsize=(10, 5))\nraw_plot.set_title('Raw data')\nplt.show()","31b6e8f3":"# Rectify the audio signal\naudio_rectified = audio.apply(np.abs)\n\n# Plot the result\nrectified_plot = audio_rectified.plot(figsize=(10, 5))\nrectified_plot.set_title('Rectified audio')\nplt.show()","3990058b":"# Smooth by applying a rolling mean\naudio_rectified_smooth = audio_rectified.rolling(50).mean()\n\n# Plot the result\naudio_rectified_smooth.plot(figsize=(10, 5))\nplt.show()","bf7147fe":"normal_series = pd.Series(normal_audio, time)\nabnormal_series = pd.Series(abnormal_audio, time)\naudio_df = pd.concat([normal_series, abnormal_series], axis=1)\n\naudio_df.head(5)","2f777cb2":"audio_tempo = lr.beat.tempo(normal_audio, sr=sfreq, hop_length=2**6, aggregate=None)","1220c4c7":"# Import the stft function\nfrom librosa.core import stft\nfrom librosa.core import amplitude_to_db\nfrom librosa.display import specshow\n\n# Prepare the STFT\nHOP_LENGTH = 2**4\nspec = stft(normal_audio, hop_length=HOP_LENGTH, n_fft=2**7)\n\n# Convert into decibels\nspec_db = amplitude_to_db(np.abs(spec))\n\n# Compare the raw audio to the spectrogram of the audio\nfig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\naxs[0].plot(time, normal_audio)\nspecshow(spec_db, sr=sfreq, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH)\nplt.show()","e866da3f":"We can see that heartbeat sounds come in pairs. This is proven by the biology literature. The heart has two sounds in total one in R and the other in the near end of T wave in the elctrogram. \n\n![ECG](https:\/\/meetjegezondheid.nl\/wp-content\/uploads\/2020\/09\/normaal-ecg-hartslag.jpg)","89622c0a":"# Smoothening the data and removing the noise","d7e52202":"# The auditory envelope\n\nSmoothing the data helps us calculate the auditory envelope related to the total amount of audio energy present at each moment of time. ","3008e451":"# Rectifying the audio","5ff387a7":"# Derivative features: The tempogram \nAuditory data has a set of features that can help us extract valuable data from it. We can get the tempogram of an audio to compute the rythm and tempo of it.\nThese features can help us and the model get a better sense of the data we're dealing with. ","d3791b0d":"# Exploring the data\nEach audio file shows the sound amplitude of a person's heartbeat thruogh time. This is a special kind of time series since it shows data from every second of the heartbeat. This data is important for diagnosis. ","66ddf8dc":"# Spectograms\nIn the field of audio engineering, spectograms are used to describe the presense spectral content (low pitch etc.) over time. Spectral analysis is commen in other forms of time series as well. ","f350cea3":"# Normal vs Abnormal\nHow does the data differ in an abnormal patient?","a10892e0":"By rectifying the signal and cleaning up all the noise, we now have a better understanding of the data and can draw insights from it\ud83d\ude42"}}