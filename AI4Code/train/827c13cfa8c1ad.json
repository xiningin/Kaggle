{"cell_type":{"33a75356":"code","2042ec68":"code","db5b7b4f":"code","2bc8c546":"code","f5cb3924":"code","d0d7e9b3":"code","0096a9c9":"code","15fe3846":"code","616c79c3":"code","84f635b0":"code","a4c8c796":"code","ade2c754":"code","462b8134":"code","4ba5840c":"code","f4a18803":"code","bf2b5d56":"code","dee38cc1":"markdown","c0945854":"markdown"},"source":{"33a75356":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.patches as patches\nimport pylab as pl\nfrom PIL import Image","2042ec68":"img0 = \"..\/input\/detect-person-on-motorbike-or-scooter\/dataset\/obj\/1 (1).jpg\"\n_ = plt.figure(figsize = (15,20))\n_ = plt.axis('off')\n_ = plt.imshow(mpimg.imread(img0))","db5b7b4f":"directory = '..\/input\/detect-person-on-motorbike-or-scooter\/dataset\/obj\/'\n\nimagepath=[]\nimagefile=[]\nboxset=[]\nboxfile=[]\n\nfor im in os.listdir(directory):\n    if im[-4:]=='.jpg':\n        path=os.path.join(directory,im)\n        imagepath+=[path]\n        imagefile+=[im]\n        \nfor im in imagefile:\n    if im[-4:]=='.jpg':\n        bx=im[0:-4]+'.txt'\n        path=os.path.join(directory,bx)\n        if os.path.isfile(path):\n            bxdata=np.loadtxt(path)\n        boxset+=[bxdata]\n        boxfile+=[bx]       ","2bc8c546":"print(imagefile[0:5])\nprint(boxfile[0:5])\n\n#for itemA, itemB in zip(imagefile, boxfile):\n#    a=itemA.index('.')\n#    b=itemB.index('.')\n#    if itemA[0:a]!=itemB[0:b]:\n#        print(itemA,itemB)","f5cb3924":"print(len(boxset))\nprint(len(imagepath))","d0d7e9b3":"def draw_bbox2(num0):\n    \n    img0=imagepath[num0]\n    box0=boxset[num0]\n    im = Image.open(img0)\n    W,H = im.size\n    print(im.size)\n    \n    _ = plt.figure(figsize = (15,20))\n    _ = plt.axis('on')\n    _ = plt.imshow(mpimg.imread(img0))\n    \n    ax = plt.gca()\n    ax.text(10,50,f'PERSON ON BIKE',fontsize=20,color='yellow')\n    \n    if type(box0[0])==np.float64:\n        mk,x0,y0,w0,h0 = box0\n        x=(x0-w0\/2)*W\n        y=(y0-h0\/2)*H\n        w=w0*W\n        h=h0*H\n        rect = patches.Rectangle((x,y),w,h,linewidth=2,edgecolor='yellow',fill = False)\n        ax.add_patch(rect)\n        plt.show\n\n    else:\n        for item in box0:\n            mk,x0,y0,w0,h0 = item\n            x=(x0-w0\/2)*W\n            y=(y0-h0\/2)*H\n            w=w0*W\n            h=h0*H\n            rect = patches.Rectangle((x,y),w,h,linewidth=2,edgecolor='yellow',fill = False)\n            ax.add_patch(rect)\n            plt.show","0096a9c9":"num0=0\nfor i in range(692):\n    if imagepath[i]==img0:\n        num0=i\n        print(i)","15fe3846":"draw_bbox2(num0)\nprint(imagepath[num0])","616c79c3":"weights_path = '..\/input\/detect-person-on-motorbike-or-scooter\/yolov3-obj_final.weights'\nconfiguration_path = '..\/input\/detect-person-on-motorbike-or-scooter\/yolov3_pb.cfg'\n\nprobability_minimum = 0.5\nthreshold = 0.3","84f635b0":"network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\nlayers_names_all = network.getLayerNames()\nlayers_names_output = [layers_names_all[i[0]-1] for i in network.getUnconnectedOutLayers()]","a4c8c796":"labels = open('..\/input\/detect-person-on-motorbike-or-scooter\/coco.names').read().strip().split('\\n')\nprint(labels)","ade2c754":"image_input = cv2.imread(imagepath[num0])\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0,15.0)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","462b8134":"blob = cv2.dnn.blobFromImage(image_input,1\/255.0,(416,416),swapRB=True,crop=False)\nblob_to_show = blob[0,:,:,:].transpose(1,2,0)\nnetwork.setInput(blob)\noutput_from_network = network.forward(layers_names_output)\nnp.random.seed(42)\ncolours = np.random.randint(0,255,size=(len(labels),3),dtype='uint8')","4ba5840c":"bounding_boxes = []\nconfidences = []\nclass_numbers = []\nh,w = image_input.shape[:2]\n\nfor result in output_from_network:\n    for detection in result:\n        scores = detection[5:]\n        class_current=np.argmax(scores)\n        confidence_current=scores[class_current]\n        if confidence_current>probability_minimum:\n            box_current=detection[0:4]*np.array([w,h,w,h])\n            x_center,y_center,box_width,box_height=box_current.astype('int')\n            x_min=int(x_center-(box_width\/2))\n            y_min=int(y_center-(box_height\/2))\n            bounding_boxes.append([x_min,y_min,int(box_width),int(box_height)])\n            confidences.append(float(confidence_current))\n            class_numbers.append(class_current)","f4a18803":"results = cv2.dnn.NMSBoxes(bounding_boxes,confidences,probability_minimum,threshold)\nprint(len(results))\n\nif len(results) > 0:\n    for i in results.flatten():\n        x_min,y_min=bounding_boxes[i][0],bounding_boxes[i][1]\n        box_width,box_height= bounding_boxes[i][2],bounding_boxes[i][3]\n        colour_box_current=[int(j) for j in colours[class_numbers[i]]]\n        cv2.rectangle(image_input,(x_min,y_min),(x_min+box_width,y_min+box_height),colour_box_current,5)\n        text_box_current='{}: {:.4f}'.format(labels[int(class_numbers[i])],confidences[i])\n        cv2.putText(image_input,text_box_current,(x_min,y_min-7),cv2.FONT_HERSHEY_SIMPLEX,1.5,colour_box_current, 5)","bf2b5d56":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0,15.0)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","dee38cc1":"# YOLO Detection","c0945854":"# Data Viewing"}}