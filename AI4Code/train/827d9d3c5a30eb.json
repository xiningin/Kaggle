{"cell_type":{"1687c708":"code","98040305":"code","24afef62":"code","8a688c9c":"code","aa8d11fb":"code","465e66b6":"code","b7f74694":"code","810cb577":"code","0f7a9dcc":"code","ea151faa":"code","0904be33":"code","7e575904":"code","eb980ba5":"code","be76e2f6":"code","72b0617c":"code","c426727c":"code","f29f21cd":"code","38c8e1a9":"code","7d029f97":"code","94d68a2f":"code","014d81e4":"code","c119c20f":"code","c4521330":"code","c533aff3":"code","0984a097":"code","2ba4d0d9":"markdown","bcf16667":"markdown","7e05c340":"markdown","38b70137":"markdown","b47064eb":"markdown","f48cdc3e":"markdown","7ca5ef1b":"markdown","9b15050a":"markdown","e19ed164":"markdown","0f21d264":"markdown","81fa45d5":"markdown"},"source":{"1687c708":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nfrom tqdm import tqdm\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport seaborn as sb","98040305":"df_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv')\ndf_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/test.csv')\ndf_building = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')\ndf_w_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_train.csv')\ndf_w_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_test.csv')","24afef62":"def reduce_df_mem_usage(df, verbose=True):\n    '''\n    Function that reduces memory cosumption of pandas dataframe reducing number of bits for floats and numbers\n\n    Parameters\n    ----------\n    df : pandas.data_frame \n        The dataframe to be shrinked\n    verbose: boolean, optional\n        if function should print the memory reduction\n    \n    Returns\n    ----------\n    df : pandas.data_frame \n        The shrinked dataframe\n    '''\n\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\ndef generate_date_parts_features(df, timestamp_col='timestamp'):\n    df['dt_timestamp'] = pd.to_datetime(df[timestamp_col], format='%Y-%m-%d %H:%M:%S')\n    df['dt_weekday'] = df['dt_timestamp'].dt.weekday\n    df['dt_quarter'] = df['dt_timestamp'].dt.quarter\n    df['dt_year'] = df['dt_timestamp'].dt.year\n    df['dt_month'] = df['dt_timestamp'].dt.month\n    df['dt_day'] = df['dt_timestamp'].dt.day\n    df['dt_dayofyear'] = df['dt_timestamp'].dt.dayofyear\n    df['dt_weekofyear'] = df['dt_timestamp'].dt.weekofyear\n    df['dt_hour'] = df['dt_timestamp'].dt.hour\n    return df    ","8a688c9c":"df_train = reduce_df_mem_usage(df_train)\ndf_test = reduce_df_mem_usage(df_test)\ndf_w_train = reduce_df_mem_usage(df_w_train)\ndf_w_test = reduce_df_mem_usage(df_w_test)","aa8d11fb":"df_train = generate_date_parts_features(df_train)\ndf_test = generate_date_parts_features(df_test)","465e66b6":"n_train = len(df_train)\nn_test = len(df_test)\nprint(n_train, n_test)","b7f74694":"df_train = pd.merge(df_train, df_building, left_on='building_id', right_on='building_id', how='left')\ndf_test = pd.merge(df_test, df_building, left_on='building_id', right_on='building_id', how='left')\ndf_train = pd.merge(df_train, df_w_train, left_on=['site_id', 'timestamp'], right_on=['site_id', 'timestamp'], how='left')\ndf_test = pd.merge(df_test, df_w_test, left_on=['site_id', 'timestamp'], right_on=['site_id', 'timestamp'], how='left')\ndf_train = reduce_df_mem_usage(df_train)\ndf_test = reduce_df_mem_usage(df_test)","810cb577":"df_train.head()","0f7a9dcc":"df_train.tail()","ea151faa":"df_test.head()","0904be33":"df_test.tail()","7e575904":"df_train.dt_timestamp.describe()","eb980ba5":"df_test.dt_timestamp.describe()","be76e2f6":"pd.options.display.float_format = '{:,.3f}'.format\ndf_train.meter_reading.describe()","72b0617c":"## looks like an error outlier. Let's check top 5 values\ndf_train.meter_reading.sort_values().tail(5)","c426727c":"df_train.iloc[8905140]","f29f21cd":"df_train[df_train.building_id==1099].groupby(['building_id','meter'])['meter_reading'].agg(['max', 'min', 'mean', 'std'])","38c8e1a9":"## Plot some buildings consumption\nfrom IPython.display import display\n\nrandom_buildings = [1018] # = df_building.sample(10)['building_id'].values\nfor b_id in random_buildings:\n    sb.lineplot(x='dt_timestamp', y='meter_reading', data=df_train[(df_train.building_id==b_id)&(df_train.meter==1)], hue='meter' ).set_title('Building_id = %s' % str(b_id))\n    plt.show()","7d029f97":"## Some buildings have no data for some period. For instance Building_id == 1442. Let's investigate\nsb.lineplot(x='dt_timestamp', y='meter_reading', data=df_train[df_train.building_id==1442], hue='meter' ).set_title('Building_id =1442')","94d68a2f":"df_building_1442 = df_train[((df_train.building_id==1442)&(df_train.dt_timestamp > '2016-02-10')&(df_train.dt_timestamp < '2016-03-30'))]\nplt.figure(figsize=(16, 6))\nsb.lineplot(x='dt_timestamp', y='meter_reading', data=df_building_1442[df_building_1442.meter==0]).set_title('Building_id =1442 between Feb and Mar')","014d81e4":"## Target was clearly interpolated. Let's try to see why\ndf_building_1442[df_building_1442.meter==0].head(50)","c119c20f":"from sklearn.ensemble import RandomForestRegressor\n\nX = df_train.copy()\n\ny = df_train['meter_reading']\nX = X.drop(['meter_reading','timestamp', 'dt_timestamp'], axis=1)\n\nX = X.fillna(-999)\n\n# Label encoder for categorical features\nfor c in X.columns[X.dtypes == 'object']:\n    X[c] = X[c].factorize()[0]\n    \nrf = RandomForestRegressor(max_depth=5)\nrf.fit(X,y)\nplt.plot(rf.feature_importances_)\nplt.xticks(np.arange(X.shape[1]), X.columns.tolist(), rotation=90);","c4521330":"## Number of NaN on each column\ndf_train.isnull().sum(axis=0)","c533aff3":"df_test.isnull().sum(axis=0)","0984a097":"## check if there are buildings in test set not present on train data\ntrain_buildings = df_train.building_id.unique()\ntest_buildings = df_test.building_id.unique()\nprint(set(train_buildings) == set(test_buildings))","2ba4d0d9":"Actually seaborn interpolated the missing data. Some series has missing values. In 1442 Building example above, there's only values for a few days","bcf16667":"Actualy depending on meter type values oscilate too much","7e05c340":"It is clear that some meters are inversely proportional to others and that there is some interpolated data","38b70137":"### Some thoughts\n\n* Investigate Holidays (which country?)\n* Probably we cannot treat each meter series independently, because they are correlated\n* Investigate site_id variable.\n* Several missing data in some dates for some buildings. Interpolate?\n* Several nan in weather sensors. Interpolate?\n* Generate aggregate metrics for weather sensors. What the best windows size? Hyperparameter?","b47064eb":"* ### Investigate Nulls","f48cdc3e":"# Ashrae - Beginner EDA\n\nThis is an EDA for Ashrae Energy Prediction Competition's data.","7ca5ef1b":"### Cleansing, merging and shrinking data","9b15050a":"### Basic EDA","e19ed164":"Let's investigate\n","0f21d264":"### Build a simple model to check feature importance","81fa45d5":"### Investigate target variable"}}