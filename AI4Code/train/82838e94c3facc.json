{"cell_type":{"721bbe29":"code","b2f988f9":"code","c4b4127e":"code","f990a1a7":"code","e1fc5177":"code","1f33f328":"code","499cafdb":"code","342447d9":"code","c549d4d3":"code","957bedca":"code","82279676":"code","261ea7de":"code","760b2e78":"code","43b3f122":"code","d489d6ff":"code","0da9e98e":"code","a50476eb":"code","32b7effa":"code","1fcd8438":"code","849e59d8":"code","45c3ba5c":"code","19f955d2":"code","dd3b8a96":"code","e9f4dffb":"code","2a663f78":"code","32f0cda2":"code","4771e740":"markdown","700e1811":"markdown","b9ee143b":"markdown","8f15268c":"markdown","abcc29a7":"markdown","45d470ea":"markdown","2a93a51f":"markdown","149e7c57":"markdown","521ba65a":"markdown"},"source":{"721bbe29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b2f988f9":"df_sales = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\", index_col=\"item_id\")\ndf_prices = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\ndf_calendar = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\", index_col = \"date\")\nfirst_date = \"d_1\"\nlast_date = \"d_1913\"\n#dates = pd.DataFrame([df_calendar.index, df_calendar.d, df_calendar.weekday, df_calendar.month, df_calendar.year]).transpose()\n#dates.columns = [\"Date\", \"d\", \"weekday\", \"month\", \"year\"]\n#dates_ = dates[[\"Date\", \"d\"]]\n","c4b4127e":"from sklearn.preprocessing import LabelEncoder\n\nnonservingcols = [\"wm_yr_wk\", \"wday\"]\ndates = df_calendar.drop(nonservingcols, axis = 1)\ndates[\"Date\"] = dates.index\ndates.index = dates[\"d\"]\ndates = dates.fillna(0)\n\ncategorical_cols = [\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]\nmy_labeler = LabelEncoder()\nfor i in categorical_cols:\n    dates[i] = my_labeler.fit_transform(dates[i].astype(\"str\"))","f990a1a7":"def createFeatures(series):\n    serie = series.transpose()\n    df_products = pd.merge(serie, dates, left_index= True, right_index = True)\n    df_products[\"Date\"] = pd.to_datetime(df_products[\"Date\"])\n    df_products[\"quarter\"] = df_products[\"Date\"].dt.quarter.astype(\"uint8\")\n    df_products[\"Month\"] = df_products[\"Date\"].dt.month.astype(\"uint8\")\n    df_products[\"Year\"] = df_products[\"Date\"].dt.year.astype(\"uint8\")\n    df_products[\"dayofyear\"] = df_products[\"Date\"].dt.dayofyear.astype(\"uint8\")\n    df_products[\"dayofweek\"] = df_products[\"Date\"].dt.dayofweek.astype(\"uint8\")\n    df_products.index = df_products.Date\n    df_products = df_products.drop([\"Date\", \"weekday\", \"month\", \"d\"], axis= 1)\n    return df_products\n\ndef crearseries(data):\n    a = data[0]\n    df = df_sales.copy()\n    first_date = \"d_1\"\n    last_date = \"d_1969\"\n    if a:\n        final_df = df.groupby(data).sum()\n        lnn = list()\n        try:\n            for i in final_df.index:\n                nn = \"_\".join([i[0], i[1]])\n                lnn.append(nn)\n                final_df[\"final_name\"] = lnn\n                final_df.index = final_df[\"final_name\"]\n                final_df = final_df.drop(\"final_name\", axis =1)\n        except:\n            pass\n        return final_df\n    else:\n        df = df.loc[:,first_date:last_date]\n        final_df = pd.Series(df.sum(axis = 0))\n        return final_df\n\n","e1fc5177":"df_prices_stats = df_prices.loc[:,[\"item_id\", \"sell_price\"]]\ndf_prices_stats = df_prices_stats.groupby(\"item_id\").sell_price.agg([min, max, \"mean\"])\ndf_estados = df_sales.loc[:,\"state_id\":last_date]\ndf_estados = df_estados.groupby(\"state_id\").sum()\ndf_estados_Q = pd.DataFrame(df_estados.sum(axis=1))","1f33f328":"df_estados = df_estados.transpose()\ndf_estados= pd.merge(df_estados, dates, left_index= True, right_index = True)\ndf_estados.Date = pd.to_datetime(df_estados.Date)\ndf_estados.head()","499cafdb":"df_sales_tot_ = pd.DataFrame(df_sales.loc[:, first_date:last_date].sum(axis=1))\ndf_sales_tot_a = df_sales_tot_.groupby(df_sales_tot_.index).sum()\ndf_sales_tot = pd.merge(df_sales_tot_a, df_prices_stats, right_index = True, left_index=True)\ndf_sales_tot[\"Total\"] = df_sales_tot.iloc[:,0]*df_sales_tot.loc[:,\"mean\"]\ndf_sales_tot = df_sales_tot.Total.sort_values()\ndf_sales_tot_b = pd.DataFrame(df_sales_tot[-10:])\ndf_sales_tot_l = pd.DataFrame(df_sales_tot[:10])","342447d9":"import plotly.express as px\nimport plotly.graph_objects as go\nfig_a = px.bar(df_sales_tot_b, x = df_sales_tot_b.index, y = df_sales_tot_b.iloc[:,0])\nfig_a.show()\n\npms = df_sales_tot_b.index\npms_a = pd.DataFrame(df_sales.loc[pms, first_date:last_date])\npms_ = pms_a.groupby(pms_a.index).sum().transpose()\npms_d = pd.merge(pms_, dates, left_index = True, right_index = True)\n#pms_d.head()\n\nfig_c = go.Figure()\nfig_c.add_trace(go.Scatter(x=pms_d.Date, y=pms_d.iloc[:,9], name=pms_d.columns[9],\n                         line_color='deepskyblue'))\nfig_c.add_trace(go.Scatter(x=pms_d.Date, y=pms_d.iloc[:,5], name=pms_d.columns[5],\n                         line_color='dimgray'))\nfig_c.add_trace(go.Scatter(x=pms_d.Date, y=pms_d.iloc[:,4], name=pms_d.columns[0],\n                         line_color='red'))\nfig_c.update_layout(title_text='Articles analysis timeseries',\n                  xaxis_rangeslider_visible=True)\nfig_c.show()","c549d4d3":"fig_l = px.bar(df_sales_tot_l, x = df_sales_tot_l.index, y = df_sales_tot_l.iloc[:,0])\nfig_l.show()\npmsmin = pd.DataFrame(df_sales_tot[:10]).index\npms_a_min = pd.DataFrame(df_sales.loc[pmsmin, first_date:last_date])\npms_min = pms_a.groupby(pms_a_min.index).sum().transpose()\npms_d_min = pd.merge(pms_min, dates, left_index = True, right_index = True)\n#pms_d.head()\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=pms_d_min.Date, y=pms_d_min.iloc[:,0], name=pms_d_min.columns[0],\n                         line_color='deepskyblue'))\nfig.add_trace(go.Scatter(x=pms_d_min.Date, y=pms_d_min.iloc[:,4], name=pms_d_min.columns[4],\n                         line_color='dimgray'))\nfig.add_trace(go.Scatter(x=pms_d_min.Date, y=pms_d_min.iloc[:,5], name=pms_d_min.columns[5],\n                         line_color='red'))\nfig.update_layout(title_text='Articles analysis timeseries',\n                  xaxis_rangeslider_visible=True)\nfig.show()","957bedca":"fig = px.choropleth(locations=df_estados_Q.index, locationmode=\"USA-states\", color=df_estados_Q.iloc[:,0], scope=\"usa\")\nfig.show()\n\n#fig = px.bar(df_estados_Q, x= df_estados_Q.index, y = df_estados_Q.iloc[:,0], color = df_estados_Q.index)\n#fig.show()","82279676":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=df_estados.Date, y=df_estados['CA'], name=\"California\",\n                         line_color='deepskyblue'))\nfig.add_trace(go.Scatter(x=df_estados.Date, y=df_estados['TX'], name=\"Texas\",\n                         line_color='dimgray'))\nfig.add_trace(go.Scatter(x=df_estados.Date, y=df_estados['WI'], name=\"Wisconsin\",\n                         line_color='red'))\nfig.update_layout(title_text='State analysis timeseries',\n                  xaxis_rangeslider_visible=True)\nfig.show()","261ea7de":"df_weekday = df_estados.loc[:,[\"CA\", \"TX\", \"WI\", \"weekday\"]]\ndf_weekday = df_estados.groupby(\"weekday\").sum()\ndf_weekday.sort_values(\"CA\")","760b2e78":"fig = go.Figure()\nfig.add_trace(go.Bar(x=df_weekday.index,\n                y=df_weekday.CA,\n                name='California Stores',\n                marker_color='rgb(55, 83, 109)'\n                ))\nfig.add_trace(go.Bar(x=df_weekday.index,\n                y=df_weekday.TX,\n                name='Texas Stores',\n                marker_color='rgb(55, 83, 220)'\n                ))\nfig.add_trace(go.Bar(x=df_weekday.index,\n                y=df_weekday.WI,\n                name='Wisconsin Stores',\n                marker_color='rgb(55, 100, 30)'\n                ))\n\nfig.update_layout(\n    title=\"Sells by State stores\",\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Quantity (Products)',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=0,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, # gap between bars of adjacent location coordinates.\n    bargroupgap=0.1 # gap between bars of the same location coordinate.\n)\nfig.show()","43b3f122":"df_month = df_estados.loc[:,[\"CA\", \"TX\", \"WI\", \"month\"]]\ndf_month = df_estados.groupby(\"month\").sum()\ndf_month.sort_values(\"CA\")\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df_month.index,\n                y=df_month.CA,\n                name='California Stores',\n                marker_color='rgb(55, 83, 109)'\n                ))\nfig.add_trace(go.Bar(x=df_month.index,\n                y=df_month.TX,\n                name='Texas Stores',\n                marker_color='rgb(55, 83, 220)'\n                ))\nfig.add_trace(go.Bar(x=df_month.index,\n                y=df_month.WI,\n                name='Wisconsin Stores',\n                marker_color='rgb(55, 100, 30)'\n                ))\n\nfig.update_layout(\n    title=\"Sells by State stores per month\",\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Quantity (Products)',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=0,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, # gap between bars of adjacent location coordinates.\n    bargroupgap=0.1 # gap between bars of the same location coordinate.\n)\nfig.show()","d489d6ff":"df_year = df_estados.loc[:,[\"CA\", \"TX\", \"WI\", \"year\"]]\ndf_year = df_estados.groupby(\"year\").sum()\ndf_year.sort_values(\"CA\")\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df_year.index,\n                y=df_year.CA,\n                name='California Stores',\n                marker_color='rgb(55, 83, 109)'\n                ))\nfig.add_trace(go.Bar(x=df_year.index,\n                y=df_year.TX,\n                name='Texas Stores',\n                marker_color='rgb(55, 83, 220)'\n                ))\nfig.add_trace(go.Bar(x=df_year.index,\n                y=df_year.WI,\n                name='Wisconsin Stores',\n                marker_color='rgb(55, 100, 30)'\n                ))\n\nfig.update_layout(\n    title=\"Sells by State stores per year\",\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Quantity (Products)',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=0,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, # gap between bars of adjacent location coordinates.\n    bargroupgap=0.1 # gap between bars of the same location coordinate.\n)\nfig.show()","0da9e98e":"def rollingSeriesSuma(series, contador):\n    db_roll = series.rolling(contador).sum()\n    return db_roll[contador:]\n\ndef rollingSeriesMedia(series, contador=28):\n    db_roll = series.rolling(contador).mean()\n    db_roll = db_roll.fillna(db_roll.mean())\n    return db_roll\n\ndef createDBprod(product, df_sales, first_date, last_date, contador = 28):\n    df_products = df_sales.loc[product, first_date:last_date]\n    df_products = df_products.groupby(df_products.index).sum().transpose()\n    df_products = pd.merge(df_products, dates, left_index= True, right_index = True)\n    df_products[\"Date\"] = pd.to_datetime(df_products[\"Date\"])\n    df_products[\"quarter\"] = df_products[\"Date\"].dt.quarter.astype(\"uint8\")\n    df_products[\"Month\"] = df_products[\"Date\"].dt.month.astype(\"uint8\")\n    df_products[\"Year\"] = df_products[\"Date\"].dt.year.astype(\"uint8\")\n    df_products[\"dayofyear\"] = df_products[\"Date\"].dt.dayofyear.astype(\"uint8\")\n    df_products[\"dayofweek\"] = df_products[\"Date\"].dt.dayofweek.astype(\"uint8\")\n    df_products.index = df_products.Date\n    df_products = df_products.drop([ \"d\", \"Date\", \"weekday\", \"month\"], axis= 1)\n    df_products[\"Rolling\"] = rollingSeriesMedia(df_products[product], contador)\n    return df_products\n\ndf_products = createDBprod(pms[-1], df_sales, first_date, last_date)\ndf_products.tail(5)","a50476eb":"products = [pms[-1], pms[0] , df_sales_tot.index[np.random.randint(1300,len(df_sales_tot))],df_sales_tot.index[np.random.randint(1300,len(df_sales_tot))] ,pmsmin[0]]\nfor i in products:\n    db_roll = createDBprod(i, df_sales, first_date, last_date)\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=db_roll.index, y=db_roll[i], name = i,\n                             line_color='deepskyblue'))\n    fig.add_trace(go.Scatter(x=db_roll.index, y=db_roll[\"Rolling\"], name = \"Rolling 28 Days\",\n                             line_color='black'))\n    fig.show()\n","32b7effa":"products = [pms[-1], pms[0] , df_sales_tot.index[np.random.randint(1300,len(df_sales_tot))],df_sales_tot.index[np.random.randint(1300,len(df_sales_tot))] ,pmsmin[0]]\ncontador=28\nfor i in products:\n    df_products = createDBprod(i, df_sales, first_date, last_date)\n    db_exp = df_products[i].expanding(contador).mean()\n    db_exp = pd.Series(db_exp[contador:])\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=db_exp.index, y=db_exp, name=\"EXPANDING\",\n                             line_color='blue'))\n    fig.add_trace(go.Scatter(x=df_products.index, y=df_products[i], name=i,\n                             line_color='black'))\n    fig.update_layout(title_text='Rolling analysis timeseries',\n                      xaxis_rangeslider_visible=True)\n    fig.show()","1fcd8438":"product_ = pms[-1]\ndf_products = createDBprod(product_, df_sales, first_date, last_date)\nyears = np.unique(dates[\"year\"])\nyear = list()\nfig = go.Figure()\ncolors = [\"red\", \"black\", \"deepskyblue\", \"yellow\", \"orange\", \"green\"]\ncolor_ = dict(zip(years, colors))\nfor i in years:\n    a = str(i)\n    name_ = product_ + \" - \" + a\n    year = df_products[df_products[\"year\"]==i]\n    fig.add_trace(go.Scatter(x=year.dayofyear, y=year[product_], name=name_,\n                         line_color=color_.get(i)))\nfig.show()","849e59d8":"import math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","45c3ba5c":"def LSTMnn(serie, split= 100, lb = 28, plot = False):\n    #fix random seed for reproducibility\n    np.random.seed(7)\n    scaler = MinMaxScaler(feature_range = (0,1))\n    df = scaler.fit_transform(serie)\n    train_size = int(len(df)-split)\n    test_size = len(df) - train_size\n    train, test = df[0:train_size,:], df[train_size:len(df), :]\n    def create_dataset(dataset, look_back = 28):\n        dataX, dataY = [], []\n        for i in range(len(dataset)-look_back-1):\n            a = dataset[i:(i+look_back), 0]\n            dataX.append(a)\n            dataY.append(dataset[i+look_back,0])\n        return np.array(dataX), np.array(dataY)\n    trainX,trainY = create_dataset(train, lb)\n    testX, testY = create_dataset(test, lb)\n\n    # reshape input to be [samples, time steps, features]\n    \n    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n    \n    # create and fit the lstm network\n    \n    model = Sequential()\n    model.add(LSTM(4, input_shape = (1, lb)))\n    model.add(Dense(1))\n    model.compile(loss = \"mean_squared_error\", optimizer = \"adam\")\n    model.fit(trainX, trainY, epochs = 10, batch_size = 1, verbose = False)\n    \n    # make predictions\n    trainPredict = model.predict(trainX)\n    testPredict = model.predict(testX)\n    #invert predictions\n    trainPredict = scaler.inverse_transform(trainPredict)\n    trainY = scaler.inverse_transform([trainY])\n    testPredict = scaler.inverse_transform(testPredict)\n    testY = scaler.inverse_transform([testY])\n    # calculate root mean squared error\n    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n    print('Train Score: %.2f RMSE' % (trainScore))\n    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n    print('Test Score: %.2f RMSE' % (testScore))\n    trainPredictPlot = np.empty_like(df)\n    trainPredictPlot[:, :] = np.nan\n    trainPredictPlot[lb:len(trainPredict)+lb, :] = trainPredict\n    testPredictPlot = np.empty_like(df)\n    testPredictPlot[:, :] = np.nan\n    testPredictPlot[len(df)-len(testPredict):, :] = testPredict\n    testPredictPlot = pd.DataFrame(testPredictPlot)\n    if plot == True:\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=serie.index, y=serie.iloc[:,0], name=\"Original Serie\",\n                                 line_color='deepskyblue'))\n        fig.add_trace(go.Scatter(x=df_estados.Date, y=Data_train.iloc[:,0], name=\"Dataset train\",\n                                 line_color='Green'))\n        fig.add_trace(go.Scatter(x=df_estados.Date,y=Data_test.iloc[:,0], name=\"Dataset test\",\n                                 line_color='red'))\n        fig.show()\n    return trainPredictPlot, testPredictPlot\n","19f955d2":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\ndef features_(df, train = True, label = None):\n    cols_to_remove = [\"year\",label]\n    X = df.drop(cols_to_remove, axis = 1)\n    if label:\n        y = df[label]\n        return X, y\n    else:\n        return X\n\ndef funcionevaluacion(real_values, predict):\n    mse = mean_absolute_error(real_values, predict)\n    n = len(predict)\n    suma =0\n    for i in range(1, n):\n        est = (real_values[i]-real_values[i-1])**2\n        suma +=est\n    a = 1\/(n-1)*suma\n    evaluacion = np.sqrt((1\/n)*mse\/a)\n    return evaluacion","dd3b8a96":"from sklearn.model_selection import GridSearchCV\n\ndef _AnalisisXGBoost(df_product, parametros, plot = False):\n    _evals = list()\n    #df_product = createDBprod(i, df_sales, first_date, last_date)\n    y = df_product.iloc[:,0]\n    split_date = df_product.index[-60]\n    df_train = df_product.loc[df_product.index < split_date].copy()\n    df_test = df_product.loc[df_product.index >= split_date].copy()\n    X_train, y_train = features_(df_train, train = True, label = df_product.columns[0])\n    X_test, y_test = features_(df_test, train = False, label = df_product.columns[0])\n\n    model = xgb.XGBRegressor(n_estimators  =200)\n    #model = GridSearchCV(model,\n    #                    parametros,\n    #                    cv = 2,\n    #                    n_jobs=5,\n    #                    verbose = False)\n    model.fit(X_train, y_train,\n           eval_set = [(X_train, y_train), (X_test, y_test)],\n           early_stopping_rounds = 10,\n           verbose = False)\n\n    #_ = plot_importance(model, height = 1)\n    #df_train[\"PREDICTION\"] = df_train[i]\n    df_test[\"PREDICTION\"] = model.predict(X_test)\n    _evals= funcionevaluacion(y_test, df_test[\"PREDICTION\"])\n    df_final = pd.concat([df_train, df_test], sort = False)\n    if plot == True:\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=df_final.index, y=df_final.PREDICTION, name=\"PREDICTION\",\n                         line_color='red'))\n        fig.add_trace(go.Scatter(x=df_final.index, y=df_final.iloc[:,0], name=\"Dataset\",\n                         line_color='deepskyblue'))\n        fig.show()\n    return df_final, _evals","e9f4dffb":"s1 = [[None],\n      [\"state_id\"],\n      [\"store_id\"],\n      [\"cat_id\"],\n      [\"dept_id\"],\n      [\"state_id\", \"cat_id\"],\n      [\"state_id\", \"dept_id\"],\n      [\"store_id\", \"cat_id\"],\n      [\"store_id\", \"dept_id\"],\n      [\"item_id\"],\n      [\"item_id\", \"state_id\"],\n      [\"item_id\", \"store_id\"]]\n\nprueba = crearseries(s1[1])","2a663f78":"results_XGBoost = list()\nresults_LSTMNN = list()\nfor i in prueba.index:\n    serie = prueba.loc[i,:]\n    df_serie = createFeatures(serie)\n    serie_pred_XGBoost, resultado_XGBoost = _AnalisisXGBoost(df_serie, \"parametros\")\n    serie_pred_LSTMNN, resultado_LSTMNN = LSTMnn(pd.DataFrame(df_serie.iloc[:,0]))\n    results_XGBoost.append([serie_pred_XGBoost, resultado_XGBoost])\n    results_LSTMNN.append([serie_pred_LSTMNN, resultado_LSTMNN])\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=df_serie.index, y=df_serie.iloc[:,0], name=\"REAL DATA\",\n                         line_color='blue'))\n    fig.add_trace(go.Scatter(x=df_serie.index, y=serie_pred_XGBoost.PREDICTION, name=\"XGBoost Prediction\",\n                         line_color='red'))\n    fig.add_trace(go.Scatter(x=df_serie.index, y=resultado_LSTMNN.iloc[:,0], name=\"LSTMNN Prediction\",\n                         line_color='black'))\n    fig.show()","32f0cda2":"\"\"\"\nparameters = {\n    \"learning_rate\" : [.01, .03, .05],\n    \"max_depth\" : [6,7, 8],\n    \"n_estimators\": [500]\n    }\n\nproducts = [pms[-1], pms[0] , \n            df_sales_tot.index[np.random.randint(1300,len(df_sales_tot))],\n            df_sales_tot.index[np.random.randint(1300,len(df_sales_tot))] ,\n            df_sales_tot.index[np.random.randint(800,1300)] ,\n            df_sales_tot.index[np.random.randint(200,800)] ,\n            pmsmin[0],\n            pmsmin[6],\n            pmsmin[-1]]\ntotaleval = list()\nfor i in products:\n    analisis_, evaluacion = _AnalisisXGBoost(i, parameters)\n    totaleval.append([i, evaluacion])\n    \ntotaleval = pd.DataFrame(totaleval)\n\nimport plotly.express as px\nfig = px.bar(totaleval, x=0, y=1, color = 1)\nfig.show()\n\"\"\"","4771e740":"We can observe some peaks along the time series, probably these are referring to weekends and months. So, let's plot it:","700e1811":"# XGBoost\n\n**TRAIN \/ TEST SPLIT**\n\nCut off last 28 days to use as our validation test","b9ee143b":"# FEATURE SELECTION","8f15268c":"Let's implement two more features:\n - Rolling over 7 days ago \n - Rolling over 25 days ago\n - Expanding\n \nAnd plot it.","abcc29a7":"# LSTM Neural Network","45d470ea":"# XGBOOST HIPERPARAMETRIZATION\n\nPENDING TO FINALIZE","2a93a51f":"**Please upvote if you find interesting my Kernel :)**","149e7c57":"# EDA - Exploratory Data Analysis","521ba65a":"Let's analyce some products across time with following techniques:\n - Neural Networks LSTM\n - Regression\n \nLet's see which tools is providing us best results\n\nLet's work with following products:\n - Most sold:\n - 10 most sold\n - Random product\n - Less sold\n \nLet's divide the data in one month for testing and the rest of the data to train our model."}}