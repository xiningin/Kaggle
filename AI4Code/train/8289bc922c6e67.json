{"cell_type":{"c8cbb5c0":"code","1c15257e":"code","5e5e46c7":"code","3c21bbf6":"code","bb79c11f":"code","44df89f8":"code","11d117ae":"code","5a2d0536":"code","adf707a5":"code","bed673a9":"code","31f5c80d":"code","0b26b9f2":"code","385eb598":"code","abb18101":"code","309c4beb":"code","1e20d70f":"markdown","26dc11b3":"markdown","6444de54":"markdown","7c0f0262":"markdown","bbfb6873":"markdown","7244084b":"markdown","a80f2330":"markdown","f3a0bb28":"markdown","7e1fdbb2":"markdown","be04ee60":"markdown","7a3a7439":"markdown","7404fd94":"markdown"},"source":{"c8cbb5c0":"# Import libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os.path\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import accuracy_score, f1_score\n\nprint(f'tensorflow version is {tf.__version__}')","1c15257e":"def imgPaths(filepath):\n\n    labels = [str(filepath[i]).split(\"\/\")[-2] \\\n              for i in range(len(filepath))]\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df","5e5e46c7":"# Create Variables\ntrain_image_dir = Path('..\/input\/asl-alphabet\/asl_alphabet_train')\ntrain_filepaths = list(train_image_dir.glob(r'**\/*.jpg'))\n\ntest_image_dir = Path('..\/input\/asl-alphabet\/asl_alphabet_test')\ntest_filepaths = list(train_image_dir.glob(r'**\/*.jpg'))\n\n# Create df\ntrain_df = imgPaths(train_filepaths)\ntest_df = imgPaths(test_filepaths)\n\n# Show the result\nprint(train_df.head(3))\nprint(test_df.head(3))","3c21bbf6":"\nprint(f'Number of pictures: {train_df.shape[0]}\\n')\n\nprint(f'Number of different labels: {len(train_df.Label.unique())}\\n')\n\nprint(f'Labels: {train_df.Label.unique()}')\n\n\n# Create a DataFrame with one Label of each category\n# drops dups of columns\ndf_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()","bb79c11f":"# Display 40 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=4, ncols=10, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(train_df.Filepath[i]))\n    ax.set_title(train_df.Label[i])\nplt.tight_layout(pad=.5)\nplt.show()","44df89f8":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","11d117ae":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(244, 244),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","5a2d0536":"# Load the pretained model\npretrainedModel = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n     include_top=False,\n     weights='imagenet',\n     pooling='avg'\n)\npretrainedModel.trainable = False","adf707a5":"inputs = pretrainedModel.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrainedModel.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(29, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nadam = tf.keras.optimizers.Adam(\n    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n    name='Adam'\n)\n\nmodel.compile(\n    optimizer=adam,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=3,\n    callbacks=[\n         tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=2,\n            restore_best_weights=True\n        )\n     ]\n )","bed673a9":"# Evaluate\nresults = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","31f5c80d":"# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","0b26b9f2":"from sklearn.metrics import accuracy_score\ny_test = list(test_df.Label)\nacc = accuracy_score(y_test,pred)\nprint(f'Accuracy on the test set: {acc * 100:.2f}%')","385eb598":"from sklearn.metrics import classification_report\ny_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","abb18101":"# Display the result of prediction from before\nprint(f'The first 5 predictions: {pred[:5]}')","309c4beb":"# Display 50 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=5, ncols=7, figsize=(20, 12),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {pred[i].split('_')[0]}\", fontsize = 15)\nplt.tight_layout()\nplt.show()","1e20d70f":"# Train Feature Extraction and ImageGenerator","26dc11b3":"**Function to build the train and test df**","6444de54":"# Import Libraries","7c0f0262":"# Display Images","bbfb6873":"# Build Train and Test Data Frame","7244084b":"**Display 50 images with predict and validation**","a80f2330":"**Predict**","f3a0bb28":"# Fit Data to the Model","7e1fdbb2":"**Classification Report**","be04ee60":"# Visualize the Results","7a3a7439":"# Import Pretrained MobileNet V2 Model","7404fd94":"**Accuracy**"}}