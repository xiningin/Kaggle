{"cell_type":{"8a2d6353":"code","96ce1651":"code","4ee39ab6":"code","a650b78b":"code","e87a10f9":"code","c0723713":"code","ef879517":"code","9c874152":"code","b41e65fb":"code","786ff1bc":"code","76288016":"code","02fdb3a2":"code","8943d8c5":"code","4a7df48d":"code","ab698fd2":"code","e1c3c5e6":"code","386139ea":"code","31802c7f":"code","5e1d753e":"code","c34bdd3b":"code","ddb0fe39":"code","79504891":"code","43d589a3":"code","a48b78aa":"code","13861c73":"code","9894f193":"code","90e395d6":"code","cc6438dc":"code","e12d1b40":"code","d17bedf0":"code","04fa5998":"code","aa2893de":"code","de8ed76a":"code","44101492":"code","cc194b5a":"code","464ede26":"code","e5f5db43":"code","21149381":"code","a21914e1":"code","62c03e02":"code","610427d4":"code","b1754b44":"code","8c38ab85":"code","d4f8af34":"code","5b2e7f3d":"code","7a9fde57":"code","e757c002":"code","543a8268":"code","322b3f31":"code","928f760f":"code","bcd9fd38":"code","1be88a8b":"code","873dee3c":"code","2561731f":"markdown","dafe9b63":"markdown","9b6c94e2":"markdown","e51ac736":"markdown","3c1301ab":"markdown","dad3c0e0":"markdown","d9526bf7":"markdown","5c4a2d17":"markdown","0268044a":"markdown","7b7944c8":"markdown","f56bf1eb":"markdown","b6a4542c":"markdown","277b499e":"markdown","b6e5b5df":"markdown","edf89236":"markdown","5b4f9eec":"markdown","4e59ceed":"markdown","2da28975":"markdown","4bbfe33d":"markdown","d3af9809":"markdown","e1161281":"markdown","4418c4af":"markdown","9ce124d8":"markdown","c5d32f6b":"markdown","1f925111":"markdown","f3d865a6":"markdown","5662d95e":"markdown","a8c92f34":"markdown","1d0ec720":"markdown","6e0ac150":"markdown","17fc3f29":"markdown","83eec1f4":"markdown"},"source":{"8a2d6353":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nimport pandas as pd\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import losses\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import multilabel_confusion_matrix\nimport seaborn as sns\nfrom tensorflow.keras.callbacks import LearningRateScheduler","96ce1651":"# Define paths to model files\nKAGGLE_MODELS_DIR = '\/kaggle\/input\/digit-recognizer-tflite-micro\/models\/'\nMODELS_DIR = 'models\/'\nif not os.path.exists(MODELS_DIR):\n    os.mkdir(MODELS_DIR)\nMODEL_TF = KAGGLE_MODELS_DIR + 'model_tf'\nQ_AWARE_MODEL_TF = KAGGLE_MODELS_DIR + 'q_aware_model_tf'\nMODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\nMODEL_QUANT_TFLITE = MODELS_DIR + 'model_quant.tflite'\nMODEL_Q_AWARE_TFLITE = MODELS_DIR + 'model_q_aware.tflite'\nQUANT_MODEL_TFLITE_MICRO = MODELS_DIR + 'quant_model.cc'\nQ_AWARE_MODEL_TFLITE_MICRO = MODELS_DIR + 'q_aware_model.cc'","4ee39ab6":"# Calculating a directory's size including subfolders\ndef get_size(start_path = '.'):\n    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(start_path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            # skip if it is symbolic link\n            if not os.path.islink(fp):\n                total_size += os.path.getsize(fp)\n\n    return total_size","a650b78b":"train_set = '\/kaggle\/input\/digit-recognizer\/train.csv'\ndf_tr = pd.read_csv(train_set, sep=',')","e87a10f9":"df_tr.head()","c0723713":"labels = np.array(df_tr)[:,0]\nprint(labels.shape)\nprint(labels)","ef879517":"samples = np.array(df_tr)[:,1:]\nprint(samples.shape)\nprint(samples)","9c874152":"img_arr = np.reshape(samples , (labels.shape[0], 28, 28, 1))\nprint(img_arr.shape)","b41e65fb":"plt.imshow(img_arr[100, :, :, 0], cmap=plt.cm.gray, interpolation='bilinear')","786ff1bc":"df_train, df_test = train_test_split(df_tr, train_size=0.85, test_size=0.15, random_state=42, shuffle = True)\ndf_train, df_val = train_test_split(df_train, train_size=0.8, test_size=0.2, random_state=42, shuffle = True)","76288016":"train_count = df_train['label'].value_counts()\nprint(\"Total : \", np.sum(train_count))\ntrain_count.plot(kind='bar', title='Train set Count')","02fdb3a2":"val_count = df_val['label'].value_counts()\nprint(\"Total : \", np.sum(val_count))\nval_count.plot(kind='bar', title='validation set Count')","8943d8c5":"test_count = df_test['label'].value_counts()\nprint(\"Total : \", np.sum(test_count))\ntest_count.plot(kind='bar', title='Test set Count')","4a7df48d":"tr_img_arr = np.reshape(np.array(df_train)[:,1:] , (np.sum(train_count), 28, 28, 1))\nprint(tr_img_arr.shape)\n\nval_img_arr = np.reshape(np.array(df_val)[:,1:] , (np.sum(val_count), 28, 28, 1))\nprint(val_img_arr.shape)","ab698fd2":"# Normalize the input image so that each pixel value is between 0 to 1\nGenerator = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_Gen = Generator.flow(x=tr_img_arr,\n                y=np.array(df_train[\"label\"]),\n                batch_size=32,\n                shuffle=True,\n                seed=1)\n\nval_Gen = Generator.flow(x=val_img_arr,\n                y=np.array(df_val[\"label\"]),\n                batch_size=32,\n                shuffle=True,\n                seed=1)","e1c3c5e6":"model = keras.Sequential([\n  keras.layers.InputLayer(input_shape=(28, 28, 1)),\n  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n  keras.layers.Flatten(),\n  keras.layers.Dense(10, activation = 'softmax')\n])\n\nfor layer in model.layers:\n    layer.trainable = True","386139ea":"model.compile(loss = losses.SparseCategoricalCrossentropy(),\n              optimizer = optimizers.Adam(),\n              metrics=['accuracy'])","31802c7f":"model.summary()","5e1d753e":"def step_decay(epoch, lr):\n    return 0.00025*np.exp(-0.09*epoch)\nSchedule = LearningRateScheduler(step_decay, verbose = 1)","c34bdd3b":"epochs_count = 15\nHistory = model.fit(train_Gen, \n                    epochs = epochs_count,\n                    verbose = 0,\n                    validation_data = val_Gen,\n                    callbacks = [Schedule])","ddb0fe39":"x = np.arange(1, epochs_count, 2) \ny = 0.00025*np.exp(-0.09*x)\nplt.plot(x, y)\nplt.xlabel('epoch') \nplt.ylabel('learning rate') \nplt.show()","79504891":"f, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\nt = f.suptitle('Model Performance', fontsize = 12)\nf.subplots_adjust(top = 0.85, wspace = 0.3)\n\nepoch_list = list(range(1,epochs_count+1))\n\nax1.plot(epoch_list, History.history['accuracy'], label = 'Training Accuracy')\nax1.plot(epoch_list, History.history['val_accuracy'], label = 'Validation Accuracy')\nax1.set_xticks(np.arange(0, epochs_count+1, 2))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, History.history['loss'], label = 'Training Loss')\nax2.plot(epoch_list, History.history['val_loss'], label = 'Validation Loss')\nax2.set_xticks(np.arange(0, epochs_count+1, 2))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc = \"best\")","43d589a3":"# Save the model to disk\nmodel.save(MODEL_TF)","a48b78aa":"!pip install -q tensorflow-model-optimization\nimport tensorflow_model_optimization as tfmot","13861c73":"quantize_model = tfmot.quantization.keras.quantize_model\n\n# q_aware stands for for quantization aware.\nq_aware_model = quantize_model(model)\n\n# `quantize_model` requires a recompile.\nq_aware_model.compile(loss = losses.SparseCategoricalCrossentropy(),\n              optimizer = optimizers.Adam(),\n              metrics=['accuracy'])\n\nq_aware_model.summary()","9894f193":"train_images = tr_img_arr.astype(np.float32) \/ 255\ntrain_images_subset = train_images[0:1000]\ntrain_labels_subset = np.array(df_train[\"label\"])[0:1000]\n\nq_aware_model.fit(train_images_subset, train_labels_subset, batch_size = 32, \n                  epochs = 2, validation_split = 0.1)","90e395d6":"# Save the model to disk\nq_aware_model.save(Q_AWARE_MODEL_TF)","cc6438dc":"# Prepare testing data\ntest_img_arr = np.reshape(np.array(df_test)[:,1:] , (np.sum(test_count), 28, 28, 1))\nprint(test_img_arr.shape)\n\ntest_labels = np.array(df_test[\"label\"])\n\ntest_Gen = Generator.flow(x = test_img_arr,\n                y = test_labels,\n                batch_size = 32,\n                shuffle = False)","e12d1b40":"test_Gen.reset()\nbaseline_model_loss, baseline_model_accuracy = model.evaluate(test_Gen, verbose = 0)\n\nq_aware_model_loss, q_aware_model_accuracy = q_aware_model.evaluate(test_Gen, verbose=0)\n\nprint('Baseline test accuracy:', baseline_model_accuracy)\nprint('Quant-aware test accuracy:', q_aware_model_accuracy)","d17bedf0":"# Convert the model to the TensorFlow Lite format without quantization\nconverter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\nmodel_no_quant_tflite = converter.convert()\n\n# Save the TFlite model to disk\nno_quant_tflite_model_size = open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)","04fa5998":"train_images = tr_img_arr.astype(np.float32) \/ 255\ndef representative_dataset():\n    for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n        # Model has only one input so each data point has one element.\n        yield [input_value]","aa2893de":"# Set the optimization flag.\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Provide a representative dataset to ensure we quantize correctly.\nconverter.representative_dataset = representative_dataset\n\n# Enforce integer only quantization\n# Ensure that if any ops can't be quantized, the converter throws an error\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Set the input and output tensors to int8\nconverter.inference_input_type = tf.int8\nconverter.inference_output_type = tf.int8\n\nmodel_quant_tflite = converter.convert()\n\n# Save the model to disk\nquant_tflite_model_size = open(MODEL_QUANT_TFLITE, \"wb\").write(model_quant_tflite)","de8ed76a":"converter_q_aware = tf.lite.TFLiteConverter.from_saved_model(Q_AWARE_MODEL_TF)\nconverter_q_aware.optimizations = [tf.lite.Optimize.DEFAULT]\n\nq_aware_tflite_model = converter_q_aware.convert()\n\n# Save the model to disk\nq_aware_tflite_model_size = open(MODEL_Q_AWARE_TFLITE, \"wb\").write(q_aware_tflite_model)","44101492":"def predict_tflite(tflite_model, x_test):\n  # Prepare the test data\n  x_test_ = x_test.copy()\n  #x_test_ = x_test_.reshape((x_test.size, 1))\n  #x_test_ = x_test_.astype(np.float32)\n\n  # Initialize the TFLite interpreter\n  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n  interpreter.allocate_tensors()\n\n  input_details = interpreter.get_input_details()[0]\n  output_details = interpreter.get_output_details()[0]\n\n  # If required, quantize the input layer (from float to integer)\n  input_scale, input_zero_point = input_details[\"quantization\"]\n  if (input_scale, input_zero_point) != (0.0, 0):\n    x_test_ = x_test_ \/ input_scale + input_zero_point\n    x_test_ = x_test_.astype(input_details[\"dtype\"])\n  \n  # Invoke the interpreter\n  y_pred = np.empty((x_test_.shape[0], 10), dtype=output_details[\"dtype\"])\n  for i in range(len(x_test_)):\n    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n    interpreter.invoke()\n    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n  \n  # If required, dequantized the output layer (from integer to float)\n  output_scale, output_zero_point = output_details[\"quantization\"]\n  if (output_scale, output_zero_point) != (0.0, 0):\n    y_pred = y_pred.astype(np.float32)\n    y_pred = (y_pred - output_zero_point) * output_scale\n\n  return y_pred","cc194b5a":"# Normalize the test images (0, 255) -> (0.0, 1.0)\nx_test = test_img_arr.astype(np.float32) \/ 255\n\n# calculate predictions of the original tensorflow model\ny_test_pred_tf = model.predict(x = x_test, verbose = 1)\n\nlst = []\nfor i in range(len(y_test_pred_tf)):\n    lst.append(np.argmax(y_test_pred_tf[i]))\nY_test_pred_tf = np.array(lst)","464ede26":"# Calculate predictions of the 3 tflite models\ny_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test)\ny_test_pred_quant_tflite = predict_tflite(model_quant_tflite, x_test)\ny_test_pred_q_aware_tflite = predict_tflite(q_aware_tflite_model, x_test)","e5f5db43":"def prediction_digits_array(y_test_pred):\n    lst = []\n    for i in range(len(y_test_pred)):\n        lst.append(np.argmax(y_test_pred[i]))\n    return np.array(lst)","21149381":"Y_test_pred_no_quant_tflite = prediction_digits_array(y_test_pred_no_quant_tflite)\n\nY_test_pred_quant_tflite = prediction_digits_array(y_test_pred_quant_tflite)\n\nY_test_pred_q_aware_tflite = prediction_digits_array(y_test_pred_q_aware_tflite)","a21914e1":"# Compare predictions\n\n# calculating the confusion matrices of the 4 models\nconf_matrix_tf = multilabel_confusion_matrix(y_true = test_labels, y_pred = Y_test_pred_tf, \n                                          labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nconf_matrix_no_quant_tflite = multilabel_confusion_matrix(y_true = test_labels, y_pred = Y_test_pred_no_quant_tflite, \n                                          labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nconf_matrix_quant_tflite = multilabel_confusion_matrix(y_true = test_labels, y_pred = Y_test_pred_quant_tflite, \n                                          labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nconf_matrix_q_aware_tflite = multilabel_confusion_matrix(y_true = test_labels, y_pred = Y_test_pred_q_aware_tflite, \n                                          labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])","62c03e02":"def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize = 14):\n    df_cm = pd.DataFrame(\n        confusion_matrix, index = class_names, columns = class_names,\n    )\n\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar = False, ax = axes)\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation = 0, ha = 'right', fontsize = fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation = 45, ha = 'right', fontsize = fontsize)\n    axes.set_ylabel('True label')\n    axes.set_xlabel('Predicted label')\n    axes.set_title(\"class : \" + class_label)","610427d4":"def plot_cf_matrix(conf_matrix):\n    fig, ax = plt.subplots(1, 10, figsize=(24, 4))\n\n    for axes, cfs_matrix, label in zip(ax.flatten(), conf_matrix, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]):\n        print_confusion_matrix(cfs_matrix, axes, label, [\"NO\", \"YES\"])\n\n    fig.tight_layout()\n    plt.show()","b1754b44":"plot_cf_matrix(conf_matrix_tf)","8c38ab85":"plot_cf_matrix(conf_matrix_no_quant_tflite)","d4f8af34":"plot_cf_matrix(conf_matrix_quant_tflite)","5b2e7f3d":"plot_cf_matrix(conf_matrix_q_aware_tflite)","7a9fde57":"def evaluate_tflite(y_pred, x_test, y_true):\n  global model\n  prediction_digits = []\n  for i in range(len(y_pred)):\n    prediction_digits.append(np.argmax(y_pred[i]))\n  loss_function = tf.keras.losses.get(model.loss)\n  loss = loss_function(y_true, y_pred).numpy()\n  accuracy = (prediction_digits == y_true).mean()\n  return loss, accuracy","e757c002":"# Calculate loss and accuracy for the 3 tflite models\nloss1, acc1 = evaluate_tflite(y_test_pred_no_quant_tflite, x_test, test_labels)\nloss2, acc2 = evaluate_tflite(y_test_pred_quant_tflite, x_test, test_labels)\nloss3, acc3 = evaluate_tflite(y_test_pred_q_aware_tflite, x_test, test_labels)","543a8268":"# Compare loss\ndf = pd.DataFrame.from_records(\n    [[\"Baseline TensorFlow\", baseline_model_loss, baseline_model_accuracy],\n     [\"TensorFlow Lite No Quant\", loss1, acc1],\n     [\"TensorFlow Lite Quantized\", loss2, acc2],\n    [\"TFLite quant_aware_training\", loss3, acc3]],\n     columns = [\"Model\", \"SparseCategoricalCrossEntropy loss\", \"accuracy\" ], index=\"Model\").round(4)\ndf","322b3f31":"baseline_tf_model_size = get_size(MODEL_TF)\nno_quant_tflite_model_size = os.path.getsize(MODEL_NO_QUANT_TFLITE)\nquant_tflite_model_size = os.path.getsize(MODEL_QUANT_TFLITE)\nq_aware_tflite_model_size = os.path.getsize(MODEL_Q_AWARE_TFLITE)","928f760f":"# Compare size\npd.DataFrame.from_records(\n    [[\"Baseline TF model\", \"%.3f MB\" % ( baseline_tf_model_size\/(1024**2) ), \"\"],\n     [\"No Quant TF Lite model\", \"%.3f KB\" % (no_quant_tflite_model_size\/1024), \n      \"(reduced by %.3f KB\" % ( (baseline_tf_model_size - no_quant_tflite_model_size)\/1024 ) ],\n     [\"Quantized TF Lite model\", \"%.3f KB\" % (quant_tflite_model_size\/1024), \n      \"(reduced by %.3f KB\" % ( (no_quant_tflite_model_size - quant_tflite_model_size)\/1024 ) ],\n     [\"Quant-Aware TF Lite model\", \"%.3f KB\" % (q_aware_tflite_model_size\/1024), \n      \"(reduced by %.3f KB\" % ( (no_quant_tflite_model_size - q_aware_tflite_model_size)\/1024 ) ]\n    ],\n     columns = [\"Model\", \"Size\", \"\"], index = \"Model\")","bcd9fd38":"# Install xxd if it is not available\n!apt-get update && apt-get -qq install xxd","1be88a8b":"# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n!xxd -i {MODEL_QUANT_TFLITE} > {QUANT_MODEL_TFLITE_MICRO}\n# Update variable names\nREPLACE_TEXT = MODEL_QUANT_TFLITE.replace('\/', '_').replace('.', '_')\n!sed -i 's\/'{REPLACE_TEXT}'\/g_model\/g' {QUANT_MODEL_TFLITE_MICRO}","873dee3c":"# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n!xxd -i {MODEL_Q_AWARE_TFLITE} > {Q_AWARE_MODEL_TFLITE_MICRO}\n# Update variable names\nREPLACE_TEXT = MODEL_Q_AWARE_TFLITE.replace('\/', '_').replace('.', '_')\n!sed -i 's\/'{REPLACE_TEXT}'\/g_model\/g' {Q_AWARE_MODEL_TFLITE_MICRO}","2561731f":"# Model training","dafe9b63":"**Helper functions**\n\nWe define the predict (for predictions) and evaluate (for loss) functions for TFLite models.\n*Note*: These are already included in a TF model, but not in a TFLite model.","9b6c94e2":"To prove these models are accurate even after conversion and quantization, we'll compare their predictions and losses on our test dataset.","e51ac736":"We will apply quantization aware training to the whole model and see this in the model summary. All layers are now prefixed by \"quant\".\n\n*Note* : that the resulting model is quantization aware but not quantized (e.g. the weights are float32 instead of int8). The sections after show how to create a quantized model from the quantization aware one.","3c1301ab":"**2. Confusion Matrices**","dad3c0e0":"# Generate a TensorFlow Lite Model","d9526bf7":"To quantize the variable data (such as model input\/output and intermediates between layers), we need to provide a RepresentativeDataset,\n* It is a generator function that provides a set of input data that's large enough to represent typical values.\n* It allows the converter to estimate a dynamic range for all the variable data.\n* The dataset does not need to be unique compared to the training or evaluation dataset.","5c4a2d17":"# Explore the dataset","0268044a":"# Build the model","7b7944c8":"**Using learning rate decay for a better optimization**","f56bf1eb":"## Generate a TensorFlow Lite for Microcontrollers Model","b6a4542c":"### 3. Compare Models' Performance","277b499e":"Follow the instructions in [the Github repository README.md](https:\/\/github.com\/JarmouniA\/Kaggle_HandwrittenDigits_Inference_ESP32\/) to deploy this model on ESP32-CAM (AI Thinker) or other [embedded devices supported by TensorFlow Lite For Microcontrollers](https:\/\/www.tensorflow.org\/lite\/microcontrollers).","b6e5b5df":"Convert the Quantization-aware TensorFlow Lite model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers.","edf89236":"[Quantization aware training](https:\/\/www.tensorflow.org\/model_optimization\/guide\/quantization\/training) emulates inference-time quantization, creating a model that downstream tools will use to produce actually quantized models. The quantized models use lower-precision (e.g. 8-bit instead of 32-bit float), leading to benefits during deployment.","5b4f9eec":"There is minimal to no loss in test accuracy after quantization aware training, compared to the baseline","4e59ceed":"### 1. Generate Models with and without Quantization using the baseline tf model","2da28975":"### 2. Create quantized tflite model using quantization-aware model","4bbfe33d":"There is minimal to no loss in test accuracy after quantization aware training, compared to the baseline.","d3af9809":"**4. Size Comparison**","e1161281":"# Deploy to a memory-constrained device","4418c4af":"Convert the model to the TensorFlow Lite format with full integer quantization of weights and activations.","9ce124d8":"# Quatization aware training","c5d32f6b":"We'll use the TensorFlow Lite Converter to convert the model into a special, space-efficient format for use on memory-constrained devices.\n\nSince this model is going to be deployed on an ESP32, we want it to be as tiny as possible!\n\nOne technique for reducing the size of a model is called [post-training quantization](https:\/\/www.tensorflow.org\/lite\/performance\/post_training_quantization). It reduces the precision of the model's weights, and possibly the activations (output of each layer) as well, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.","1f925111":"**Reshaping the images arrays**","f3d865a6":"**Training and validation generators for an efficient training**","5662d95e":"# Preprocess the images arrays and the labels","a8c92f34":"**We split the data into training, validation and testing sets (from train.csv file)**","1d0ec720":"Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers.","6e0ac150":"To demonstrate fine tuning after training the model, we will fine tune with quantization aware training on a subset of the training data.","17fc3f29":"**1. Predictions**","83eec1f4":"**3. Loss (Sparse Categorical Cross Entropy) and Accuracy**"}}