{"cell_type":{"b96955ed":"code","483d8dd5":"code","94f3416e":"code","1de591ce":"code","28443ff1":"code","c94c2459":"code","862b0d1a":"code","d4380711":"code","b6e820d9":"code","f45b9396":"code","cfe1a126":"code","0723de1f":"code","deac1832":"markdown","940e61ea":"markdown","9e6171ef":"markdown","3bfc5e00":"markdown","3d8f4ddf":"markdown","550f6b8f":"markdown","4edd63d2":"markdown","96a88f67":"markdown"},"source":{"b96955ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy.stats as stats\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n    for filename in filenames:\n        credit_data = pd.read_csv(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","483d8dd5":"credit_data.shape","94f3416e":"credit_data.describe()","1de591ce":"from sklearn.model_selection import train_test_split\n\ndef split_data(credit_data):\n    \"\"\"\n    Splits the data into sets of size 0.6, 0.2 and 0.2\n    where the train set does not contain any outliers and the\n    validation and test sets both contain the same amount\n    of outliers.\n    \"\"\"\n    \n    # Separate the outliers because we want\n    # both sets to have the same amount of outliers\n    non_outliers = credit_data.loc[credit_data['Class'] == 0]\n    outliers = credit_data.loc[credit_data['Class'] == 1]\n    \n    # Split the data\n    train, test = train_test_split(non_outliers, test_size=0.4, random_state=42)\n    val, test = train_test_split(test, test_size=0.5, random_state=42)\n    \n    \n    val_outliers, test_outliers = train_test_split(outliers, test_size=0.5, random_state=42)\n    \n    # Add the outliers back to both sets\n    val = pd.concat([val, val_outliers])\n    test = pd.concat([test, test_outliers])\n    \n    return train, val, test\n\ntrain, val, test = split_data(credit_data)\n\nprint(train['Class'].value_counts())\nprint(val['Class'].value_counts())\nprint(test['Class'].value_counts())","28443ff1":"TRIVIAL_COLUMN_NAMES = ['Class', 'Time', 'Amount']\nCLASS_COLUMN_NAME = 'Class'\n\ndef separate_x_y(data):\n    X = data.drop(columns=TRIVIAL_COLUMN_NAMES)\n    y = data[CLASS_COLUMN_NAME]\n    \n    return X,y","c94c2459":"X_train, _ = separate_x_y(train)\nX_val, y_val = separate_x_y(val)\nX_test, y_test = separate_x_y(test)","862b0d1a":"from sklearn.base import BaseEstimator, ClassifierMixin\n\nclass GaussianAnomalyClassifier(BaseEstimator, ClassifierMixin):\n    \"\"\"\n    An anomaly detection classifier.\n    \"\"\"\n    \n    ANOMALY_CLASS_LABEL = 1\n    NON_ANOMALY_CLASS_LABEL = 0\n    \n    def __init__(self, anomaly_threshold=None):\n        \"\"\"\n        params:\n        anomaly_threshold - The minimum probability a sample\n                            can have before being classified\n                            as an anomaly.\n        \"\"\"\n        \n        self.anomaly_threshold = anomaly_threshold\n        \n        \n    def fit(self, X, y=None):\n        \"\"\"\n        Estimates the parameters of a multivariate Gaussian\n        distribution on X.\n        \"\"\"\n        covariance_matrix = np.cov(X, rowvar=0)\n        means = np.mean(X,axis=0)\n        \n        self.distribution = stats.multivariate_normal(mean=means, cov=covariance_matrix)\n        \n        \n        return self\n    \n    def predict_proba(self, X):\n        \"\"\"\n        Calculates the likelihoods of X\n        coming from the estimated distribution\n        \"\"\"\n        if self.distribution is None:\n            raise RuntimeError(\"You must train the classifier before prediction\")\n            \n        probabilities = self.distribution.pdf(X)\n        \n        return probabilities\n    \n    def predict(self, X, y=None):\n        \"\"\"\n        Classifies each sample in X\n        \"\"\"\n        \n        probabilities = self.predict_proba(X)\n        \n        predictions = np.where(probabilities < self.anomaly_threshold, \\\n                               self.ANOMALY_CLASS_LABEL, self.NON_ANOMALY_CLASS_LABEL)\n        \n        return predictions\n        ","d4380711":"from sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\n\nclassifier = GaussianAnomalyClassifier(0.01)\nclassifier = classifier.fit(X_train)\npredictions = classifier.predict_proba(X_val)\n\nprecision_recall = precision_recall_curve(y_val, predictions)\n\nplt.figure()\nplt.step(precision_recall[1],precision_recall[0], where='post')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 0.1])\nplt.xlim([0.0, 1.0])\n","b6e820d9":"from sklearn.metrics import precision_recall_fscore_support\n\ndef print_scores(predictions, y_true):\n    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, predictions, average='binary', pos_label=1)\n    print('Precision: ', precision)\n    print('Recall: ', recall)\n    print('Fscore: ', fscore)\n    print()\n    print(pd.Series(predictions).value_counts())\n    \n    return precision,recall,fscore","f45b9396":"print(\"REAL VALUE COUNTS VALIDATION SET\")\nprint(pd.Series(y_val).value_counts())\nprint('------------------------------')\nprint('------------------------------\\n')\n\n\n# create a list of increasingly smaller thresholds to test\nthresholds = [0.000000000000000001 * (0.1)**x for x in range(170)]\nthresholds.reverse()\n\ncounter = 159\nfscores = [] # Save fscores to plot them afterwards\n\nfor threshold in thresholds:\n    classifier = GaussianAnomalyClassifier(threshold)\n    classifier = classifier.fit(X_train)\n    predictions = classifier.predict(X_val)\n\n    _,_, fscore = print_scores(predictions, y_val)\n    \n    print('threshold index: ', counter)\n    print('------------------------')\n    \n    \n    fscores.append(fscore)\n    counter -= 1\n    \nfscores.reverse()","cfe1a126":"plt.scatter(range(len(fscores)), fscores, s=4)\n\nplt.title(\"Fscores of increasingly smaller probability thresholds\")\nplt.xlabel('Threshold Index')\nplt.ylabel('Fscore')","0723de1f":"threshold = 0.000000000000000001 * (0.1)**80\n\nclassifier = GaussianAnomalyClassifier(threshold)\nclassifier = classifier.fit(X_train)\npredictions = classifier.predict(X_test)\n\n_,_,_ = print_scores(predictions, y_test)","deac1832":"# Our final test evaluation results in just a slightly lower Fscore.\n\n# Our test score forecasts that we will catch about 79% of fraudulent transactions and that approximately half of the transaction we flag as fraudulent are actually normal, non fraudulent transactions ","940e61ea":"# Credit Card Fraud Detection\n\nIn the following notebook we will attempt to perform anomaly detection on the labelled credit card dataset.\nThe dataset consists of 284,807 observations and 31 features of which 1 is the class label.\n\n\nWe will attempt to model our data using a multivariate Gaussian distribution and flag transactions\nas anomalous if the likelihod that they come from the modelled distribution is below a set threshold.","9e6171ef":"# At last, we compute the final test set score","3bfc5e00":"# The above automatic threshold tester precision_recall_curve from Scikit-Learn does not seem to give good results.\n\n# So, we will manually test out different thresholds below.","3d8f4ddf":"# Below, we will try to automatically find a threshold using Scikit-Learns precision_recall_curve function","550f6b8f":"# Catching fraudulent transactions is more important than not wrongly flagging valid transactions. So, we will chose a threshold with a higher recall at the cost of some precision.\n\nHowever, recall seems to plateau below index 80 where the recall is approximately 0.75.\nTherefore, we will choose the threshold with index 80.\n\nThe following statistics come from index 80:\n\n    Precision:  0.5210084033613446\n    Recall:  0.7560975609756098\n    Fscore:  0.6169154228855721\n\n    0    56752\n    1      357\n    dtype: int64\n    threshold index:  80\n    \nindex 80 corresponds to the threshold of: \n# 0.000000000000000001 * (0.1)**80\n","4edd63d2":"# Next, split data and remove non-used columns","96a88f67":"# For learning purposes, we will write our own classifier that works as described in the introduction"}}