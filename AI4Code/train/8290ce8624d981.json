{"cell_type":{"800b9142":"code","34625c97":"code","3dc80ef7":"code","eb7eb45e":"code","00e52bfa":"code","f2a9bf53":"code","3f3c53d1":"code","828760ba":"code","fb972d06":"code","2d50c190":"code","1d332988":"code","5449100c":"code","3e6cef50":"code","50784837":"code","90e8cf53":"code","ec19cb20":"code","1a010b9c":"code","fa5e5253":"code","0ef27779":"code","a3eeb3e4":"code","ae053f64":"code","fc4f47e8":"code","06d95198":"code","f8e79d31":"markdown","ce084907":"markdown","a5f1a43c":"markdown","efba2a42":"markdown","8d35574d":"markdown","72f8e2d7":"markdown","b1bea45f":"markdown","aeb847b4":"markdown","23b4062d":"markdown","354a81d6":"markdown","bf34e87d":"markdown","1cda1805":"markdown","3b522c3e":"markdown","8ac03241":"markdown"},"source":{"800b9142":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn.metrics as metrics\nfrom sklearn import datasets\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV, calibration_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import tree\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34625c97":"churning_data = pd.read_csv(os.path.join(dirname, filename))\nprint(churning_data.shape)\nprint(churning_data.head)","3dc80ef7":"def printConfusionMatrix (name , y_true , y_pred):    \n    cm = confusion_matrix(y_true, y_pred).ravel()\n    print (name)\n    print ('==============================')\n    print (\"True Negatives : \" + str(cm[0]))\n    print (\"True Positives : \" + str(cm[3]))\n    print (\"False Positives : \" + str(cm[1]))\n    print (\"False Negatives : \" + str(cm[2]))\n    print ('==============================')","eb7eb45e":"def getModelPerformance (y_true , y_pred):\n    cm = confusion_matrix(y_true, y_pred).ravel()    \n    sensitivity = cm[3] \/ (cm[3] + cm[2])    \n    specificity = cm[0] \/ (cm[0] + cm[1])\n    accuracy = (cm[0] + cm[3]) \/ (cm[0] + cm[1] + cm[2] + cm[3])\n    percision = cm[3] \/ (cm[3] + cm[1])\n    recall = cm[3] \/ (cm[3] + cm[2])\n    MCC = ((cm[3] * cm[0]) - (cm[1]*cm[2])) \/ (np.sqrt((cm[3] + cm[1]) * (cm[3] + cm[2]) * (cm[0] + cm[1]) * (cm[0] + cm[2])))\n    return [sensitivity , specificity , accuracy , percision , recall , MCC ]\n\ndef printPerformanceData (name , p):\n    print (name)    \n    print ('==============================')\n    print (\"Sensitivity : \" + str(p[0]))\n    print (\"Specificity : \" + str(p[1]))\n    print (\"Accuracy : \" + str(p[2]))    \n    print (\"Precision : \" + str(p[3]) )\n    print (\"Recall : \" + str(p[4]) )\n    print (\"Mathew Accuracy : \" + str(p[5]))\n    print ('==============================')\n","00e52bfa":"def plotLR_ROC (nsProb , lr_probs , y_test , X_test, modelName ):\n    ns_probs = np.array([nsProb for _ in range(len(y_test))])        \n    lr_fpr, lr_tpr , lr_thr = roc_curve(y_test, lr_probs)\n    ns_fpr, ns_tpr , ns_thr = roc_curve(y_test, ns_probs)\n\n    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Null model')\n    plt.plot(lr_fpr, lr_tpr, marker='.', label=modelName)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    plt.show()\n","f2a9bf53":"plt.figure(figsize=(10,7), dpi= 80)\n\nexited_df = churning_data.groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\nfig, axs = plt.subplots(figsize=(10, 7))\naxs.bar(exited_df['Exited'] , exited_df['total_number'] , color=\"dodgerblue\") \naxs.set_title('Churning')\nplt.xticks(exited_df['Exited'] , ('Stays' , 'Exits'))\nplt.show()\n","3f3c53d1":"exit_females = churning_data.loc[churning_data.Gender == 'Female'].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\nexit_males = churning_data.loc[churning_data.Gender == 'Male'].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\n\nwidth = 0.2\n\nfig, axs = plt.subplots(figsize=(10, 7))\naxs.bar(exit_females['Exited'] - width\/2 , exit_females['total_number'] , width , color=\"orange\" , label='Female') \naxs.bar(exit_males['Exited'] + width\/2 , exit_males['total_number'] , width ,  color=\"dodgerblue\" , label='Male') \naxs.legend()\naxs.set_title('Churning by Gender')\nplt.xticks(exit_females['Exited'] , ('Stays' , 'Exits'))\nplt.show()\n","828760ba":"exit_france = churning_data.loc[churning_data.Geography == 'France'].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\nexit_spain = churning_data.loc[churning_data.Geography == 'Spain'].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\nexit_germany = churning_data.loc[churning_data.Geography == 'Germany'].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\n\nwidth = 0.3\n\nfig, axs = plt.subplots(figsize=(10, 7))\naxs.bar(exit_france['Exited'] + width\/2 , exit_france['total_number'] , width , color=\"orange\" , label='France') \naxs.bar(exit_spain['Exited'] - width\/2, exit_spain['total_number'] , width ,  color=\"dodgerblue\" , label='Spain') \naxs.bar(exit_germany['Exited'] + 1.5 * width , exit_germany['total_number'] , width ,  color=\"red\" , label='Germany') \n\naxs.legend()\naxs.set_title('Churning by Country')\nplt.xticks(exit_females['Exited'] , ('Stays' , 'Exits'))\nplt.show()","fb972d06":"exit_hasCrCard = churning_data.loc[churning_data.HasCrCard == 1 ].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\nexit_NoCrCard = churning_data.loc[churning_data.HasCrCard == 0].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\n\nwidth = 0.3\n\nfig, axs = plt.subplots(figsize=(10, 7))\naxs.bar(exit_hasCrCard['Exited'] + width\/2 , exit_hasCrCard['total_number'] , width , color=\"orange\" , label='Has Credit Card') \naxs.bar(exit_NoCrCard['Exited'] - width\/2, exit_NoCrCard['total_number'] , width ,  color=\"dodgerblue\" , label='No Credit Card') \n\naxs.legend()\naxs.set_title('Credit Cards')\nplt.xticks(exit_females['Exited'] , ('Stays' , 'Exits'))\nplt.show()\n","2d50c190":"exit_IsActiveMember = churning_data.loc[churning_data.IsActiveMember == 1 ].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\nexit_NotActiveMember = churning_data.loc[churning_data.IsActiveMember == 0].groupby('Exited').agg(total_number = ('Exited' , 'count')).reset_index()\n\nwidth = 0.3\n\nfig, axs = plt.subplots(figsize=(10, 7))\naxs.bar(exit_IsActiveMember['Exited'] + width\/2 , exit_IsActiveMember['total_number'] , width , color=\"orange\" , label='Active Member') \naxs.bar(exit_NotActiveMember['Exited'] - width\/2, exit_NotActiveMember['total_number'] , width ,  color=\"dodgerblue\" , label='Not active Member') \n\naxs.legend()\naxs.set_title('Active Member')\nplt.xticks(exit_females['Exited'] , ('Stays' , 'Exits'))\nplt.show()\n","1d332988":"stays = churning_data.loc[churning_data.Exited == 1, 'CreditScore']\nexits = churning_data.loc[churning_data.Exited == 0, 'CreditScore']\n\nkwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2})\n\nplt.figure(figsize=(10,7), dpi= 80)\n\nsns.distplot(stays, color=\"dodgerblue\", label=\"Stays\", **kwargs).set_title(\"Credit Score\")\nsns.distplot(exits, color=\"orange\", label=\"Exits\", **kwargs)\nplt.legend();","5449100c":"stays = churning_data.loc[churning_data.Exited == 1, 'EstimatedSalary']\nexits = churning_data.loc[churning_data.Exited == 0, 'EstimatedSalary']\n\nkwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2})\n\nplt.figure(figsize=(10,7), dpi= 80)\n\nsns.distplot(stays, color=\"dodgerblue\", label=\"Stays\", **kwargs).set_title(\"Churning and Salary\")\nsns.distplot(exits, color=\"orange\", label=\"Exits\", **kwargs)\nplt.legend();","3e6cef50":"stays = churning_data.loc[churning_data.Exited == 1, 'NumOfProducts']\nexits = churning_data.loc[churning_data.Exited == 0, 'NumOfProducts']\n\nkwargs = dict(hist_kws={'alpha':.5}, kde_kws={'linewidth':2})\n\nplt.figure(figsize=(10,7), dpi= 80)\n\nsns.distplot(stays, color=\"dodgerblue\", label=\"Stays\", **kwargs).set_title(\"Number of Products\")\nsns.distplot(exits, color=\"orange\", label=\"Exits\", **kwargs)\n\nplt.legend();","50784837":"stays = churning_data.loc[churning_data.Exited == 1, 'Age']\nexits = churning_data.loc[churning_data.Exited == 0, 'Age']\n\nkwargs = dict(hist_kws={'alpha':.5}, kde_kws={'linewidth':2})\n\nplt.figure(figsize=(10,7), dpi= 80)\n\nsns.distplot(stays, color=\"dodgerblue\", label=\"Stays\", **kwargs).set_title('Churning by Age')\nsns.distplot(exits, color=\"orange\", label=\"Exits\", **kwargs)\n\nplt.legend();\n","90e8cf53":"stays = churning_data.loc[churning_data.Exited == 1, 'Balance']\nexits = churning_data.loc[churning_data.Exited == 0, 'Balance']\n\nkwargs = dict(hist_kws={'alpha':.5}, kde_kws={'linewidth':2})\n\nplt.figure(figsize=(10,7), dpi= 80)\n\nsns.distplot(stays, color=\"dodgerblue\", label=\"Stays\", **kwargs).set_title('Balance')\nsns.distplot(exits, color=\"orange\", label=\"Exits\", **kwargs)\n\nplt.legend();","ec19cb20":"stays = churning_data.loc[churning_data.Exited == 1, 'Tenure']\nexits = churning_data.loc[churning_data.Exited == 0, 'Tenure']\n\nkwargs = dict(hist_kws={'alpha':.5}, kde_kws={'linewidth':2})\n\nplt.figure(figsize=(10,7), dpi= 80)\n\nsns.distplot(stays, color=\"dodgerblue\", label=\"Stays\", **kwargs).set_title('Tenure')\nsns.distplot(exits, color=\"orange\", label=\"Exits\", **kwargs)\n\nplt.legend();","1a010b9c":"## data info. \nlabel_encoder = LabelEncoder()\n## Categorical data encoding , Gender , Geography. \nchurning_data['Gender'] = label_encoder.fit_transform(churning_data['Gender']) ## Gender (Female , Male)\nchurning_data['Geography'] = label_encoder.fit_transform(churning_data['Geography']) ## Geography (France , Spain ...etc)\n\n## predictors : Credit Score , Geography , Gender , Age , Tenure , Balance , NumOfProducts , HasCrCard , IsActiveMember , EstimatedSalary\nX = churning_data[['CreditScore' , 'Geography' , 'Gender' , 'Age' , 'Tenure' , 'Balance' , 'NumOfProducts' , 'HasCrCard' , 'IsActiveMember' , 'EstimatedSalary']]\n\n## dependent variable , \"Exited\"\ny = churning_data[['Exited']]\n\n## Split data into training and test sets. Use following proportions  train 70% and test 30%\nX_train, X_test, y_train, y_test =  train_test_split (X , y , test_size=0.3 , random_state = 42)\n\npositives = churning_data[churning_data['Exited'] == 1]\npositivePercent = len(positives) \/ len(churning_data)\nprint(\"Positive (exited = 1) in Null model  : \" + str(positivePercent))\nprint(\"Negatives (exited = 0) in Null model  : \" + str(1 - positivePercent))\n\n\npositivesTest = y_test[y_test['Exited'] == 1]\npositivePercentTest = len(positivesTest) \/ len(X_test)\nprint(\"Positive (exited = 1) in Null model on test data  : \" + str(positivePercentTest))\nprint(\"Negatives (exited = 0) in Null model on test data  : \" + str(1 - positivePercentTest))\n\n","fa5e5253":"lr1 = LogisticRegression()\nlr1.fit(X_train , y_train.values.ravel())\n\ny_test_pred1 = lr1.predict(X_test)\nprintConfusionMatrix (\"Confusion Matrix of LR without regularization\" , y_test , y_test_pred1)\nperformanceTest = getModelPerformance (y_test , y_test_pred1)\nprintPerformanceData(\"Logistic Regression model Performance on test data\" , performanceTest)\nlr_probs = lr1.predict_proba(X_test)[:, 1]\nlr1_score = metrics.roc_auc_score(y_test, y_test_pred1)\nprint ('AUC Score : ' + str(lr1_score))\nplotLR_ROC((1-positivePercent) , lr_probs , y_test , X_test , \"Logistic Regression\")\n","0ef27779":"lr2 = LogisticRegression( penalty='l2' , C=1 , class_weight='balanced' , solver='liblinear')\nlr2.fit(X_train , y_train.values.ravel())\n\ny_test_pred2 = lr2.predict(X_test)\nprintConfusionMatrix (\"Confusion Matrix of LR , balanced on test data\" , y_test , y_test_pred2)\nperformanceTest2 = getModelPerformance (y_test , y_test_pred2)\nprintPerformanceData(\"Logistic Regression model Performance on test data\" , performanceTest2)\nlr_probs = lr2.predict_proba(X_test)[:, 1]\nlr2_score = metrics.roc_auc_score(y_test, y_test_pred2)\nprint ('AUC Score : ' + str(lr2_score))\nplotLR_ROC((1-positivePercent) , lr_probs , y_test , X_test , \"Logistic Regression\")\n","a3eeb3e4":"lr2 = LogisticRegression( penalty='l2' , C=1 , class_weight='balanced' , solver='liblinear')\nlr2.fit(X_train , y_train.values.ravel())\n\nlr_probs = lr2.predict_proba(X_test)[:, 1]\n\nthreshold = 0.55\n\ny_test_pred2 = lr_probs > threshold\nprintConfusionMatrix (\"Confusion Matrix of LR , balanced on test data\" , y_test , y_test_pred2)\nperformanceTest2 = getModelPerformance (y_test , y_test_pred2)\nprintPerformanceData(\"Logistic Regression model Performance on test data\" , performanceTest2)\nlr2_score = metrics.roc_auc_score(y_test, y_test_pred2)\nprint ('AUC Score : ' + str(lr2_score))\n","ae053f64":"param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 10)}    \nct = tree.DecisionTreeClassifier()   \nct_gscv = GridSearchCV(ct, param_grid, cv=20)    \nct_gscv.fit(X_train, y_train)\nprint (\"tuned hpyerparameters :(best parameters) \" + str(ct_gscv.best_params_))\n\ny_test_pred4 = ct_gscv.predict(X_test)\nprintConfusionMatrix (\"Confusion Matrix of Classification Tree on Test Data \" , y_test , y_test_pred4)\nperformanceTest4 = getModelPerformance (y_test , y_test_pred4)\nprintPerformanceData(\"Classification trees model's Performance on test data\" , performanceTest4)\nct_probs = ct_gscv.predict_proba(X_test)[:, 1]\nct_score = metrics.roc_auc_score(y_test, y_test_pred4)\nprint ('AUC Score : ' + str(ct_score))\nplotLR_ROC((1-positivePercent) , ct_probs , y_test , X_test , \"Classification Tree\")\n","fc4f47e8":"param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 10)}    \nct = tree.DecisionTreeClassifier()   \nct_gscv = GridSearchCV(ct, param_grid, cv=20)    \nct_gscv.fit(X_train, y_train)\nprint (\"tuned hpyerparameters :(best parameters) \" + str(ct_gscv.best_params_))\n\nthreshold = 0.3\nct_probs = ct_gscv.predict_proba(X_test)[:, 1]\ny_test_pred4 = ct_probs > threshold\nprintConfusionMatrix (\"Confusion Matrix of Classification Tree on Test Data \" , y_test , y_test_pred4)\nperformanceTest4 = getModelPerformance (y_test , y_test_pred4)\nprintPerformanceData(\"Classification trees model's Performance on test data\" , performanceTest4)\nct_score = metrics.roc_auc_score(y_test, y_test_pred4)\nprint ('AUC Score : ' + str(ct_score))","06d95198":"rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\nrf.fit(X_train, y_train.values.ravel());\n\ny_test_pred5 = rf.predict(X_test) >= 0.3\nprintConfusionMatrix (\"Confusion Matrix of random forest on test data\" , y_test , y_test_pred5)\nperformanceTest5 = getModelPerformance (y_test , y_test_pred5)\nprintPerformanceData(\"Random forest model's Performance on test data\" , performanceTest5)\nrf_prob = rf.predict(X_test)\nrf_score = metrics.roc_auc_score(y_test, y_test_pred5)\nprint ('AUC Score : ' + str(rf_score))\nplotLR_ROC((1-positivePercent) , rf_prob , y_test , X_test , \"Random Forest\")\n","f8e79d31":"This model has high accuracy but low Mathew's accuracy because the data is not distributed evenly on the two classes , it is bad in predicting true positives (People who leave their jobs) but doing better with true negatives (people who stay) which is the trend which predicts the null model. This model is not useful and we should try to improve it by scaling the data ,  using regularization , trying different solver. In the model below we'll try to use liblinear solver and tackle the imbalance by using class_weight = 'balanced'","ce084907":"\n\nNow I will move to classification tree to see if we can obtain more accurate model. I used grid search to choose optimal tree depth. ","a5f1a43c":"The resulting model is better in terms of higher true positives but at the expense of introducing high number of false positives and lower true negatives. Accuracy has dropped due to increase in errors coming from lower true negatives. \n\nBy using a different threshold we can balance the error a little bit as shown below where I chose threshold of 0.55","efba2a42":"In the last model I will use random forest and will see if we can beat the last model of classification tree with threshold 0.3 ","8d35574d":"* Function to plot the ROC curve.\n","72f8e2d7":"I start by visualizing the depended variable **(Exited, 1 means wants to leave and 0 wants to stay)** against other independent variables in the dataset.\n","b1bea45f":"Set of functions to print model performance data , confusion matrix and to plot ROC curve. \n* Function **printConfusionMatrix** to print Confusion Matrix of statistical models.\n","aeb847b4":"Reading data from Kaggle source .","23b4062d":"The tree model is obviously good in predicting the true positives but not as good as the last logistic regression . We can choose different thresholds to balance the results as in the code below , I tried with different valuse and used 0.3 . \n","354a81d6":"**The null model (Model without any predictors) tends to predict that majority of employees stay with 80% probability.**","bf34e87d":"From this barchart we can see that the data is imbalanced , more people stay than those who leave. This information is important when we build the logistic regression model , and this is the reason for using Mathew's accuracy in my performance measures set.","1cda1805":"* Function getModelPerformance to calculate performance measures of estimated models , such as (Specificity , Sensitivity , Accuracy , Precision , Recall , Mathew's Accuracy)\n* Another function to print performance data.","3b522c3e":"I will try to solve this classification problem using three techniques: \n* Logistic Regression (Different models)\n* Classification Trees.\n* Random Forests.","8ac03241":"Data is split into trainging and test sets (70\/30) percent."}}