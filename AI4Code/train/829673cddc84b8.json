{"cell_type":{"efa3b89c":"code","9a6c4954":"code","e631f68e":"code","214b3e35":"code","43b1abfa":"code","7389e99f":"code","a868480e":"code","4cfd617d":"code","46c9fb1b":"code","d43ed274":"code","0c8b78dd":"code","89e80f64":"code","a3adff8e":"code","8499e176":"code","7cbdab0e":"code","84ea7747":"code","063a658d":"code","6f1fc6cc":"code","c70e8236":"code","84f1517d":"markdown","06d948cb":"markdown","d1235ffc":"markdown","a4a8c143":"markdown","709b753a":"markdown","6fb2ffe4":"markdown","78cb48ae":"markdown","0a31f106":"markdown","bfca8b76":"markdown","700d2f6d":"markdown","71e42905":"markdown","a53f0505":"markdown","2a0f25a9":"markdown","09b81b95":"markdown","20ec9d78":"markdown","54f252a7":"markdown","1217461e":"markdown","0f62f6b2":"markdown","0bc342d4":"markdown","23f3b110":"markdown","1c34ffbb":"markdown","74e1a0c9":"markdown","1e994c8b":"markdown","15fcc733":"markdown","242da225":"markdown","7dbdf542":"markdown","861927d4":"markdown","d21aafe0":"markdown","8db506a8":"markdown","ebc28cd5":"markdown","b8ecdede":"markdown","113d3e86":"markdown","e7d860b0":"markdown","14022b0c":"markdown","66eadc95":"markdown","74289029":"markdown","99197ee5":"markdown","b0817b1d":"markdown","a456c9e8":"markdown","fbc9c9df":"markdown","2e794c4e":"markdown","6e3e6609":"markdown","49bca0ff":"markdown"},"source":{"efa3b89c":"import warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import rcParams\n\nplt.style.use(\"ggplot\")\nrcParams[\"figure.figsize\"] = [12, 9]\nrcParams[\"xtick.labelsize\"] = 15\nrcParams[\"ytick.labelsize\"] = 15\nrcParams[\"font.size\"] = 15\n\nwarnings.filterwarnings(\"ignore\")","9a6c4954":"tps = pd.read_csv(\n    \"..\/input\/tabular-playground-series-jul-2021\/train.csv\",\n    parse_dates=[\"date_time\"], index_col=\"date_time\"\n)\n\ntps[\"deg_C\"].plot(figsize=(16, 6), fontsize=15)\nplt.xlabel(\"Date\")\nplt.ylabel(\"Degrees Celcius\");","e631f68e":"# Load meat production dataset in the USA\nmeat = pd.read_csv(\n    \"https:\/\/s3.amazonaws.com\/assets.datacamp.com\/production\/course_5226\/datasets\/ch4_meat.csv\", \n    parse_dates=[\"date\"], index_col=\"date\")\n\nmeat.plot(figsize=(16, 10))\nplt.legend(fontsize=\"large\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Meat Production (t)\");","214b3e35":"import statsmodels.api as sm\nfrom matplotlib import rcParams\n\ndecomposition = sm.tsa.seasonal_decompose(meat[\"beef\"])\n\nrcParams[\"figure.figsize\"] = 16, 4\ndecomposition.seasonal.plot();","43b1abfa":"decomposition.seasonal[\"1999\":\"2005\"].plot();","7389e99f":"# Init empty dict to store decompose results\nseasonality_dict = {}\n\nfor ts in meat.columns:\n    decompositions = sm.tsa.seasonal_decompose(meat[ts].dropna())\n    # Store the results back\n    seasonality_dict[ts] = decompositions.seasonal\n\n# Plot\nrcParams[\"figure.figsize\"] = 16, 14\npd.DataFrame(seasonality_dict)[\"2000\":\"2005\"].plot(\n    subplots=True, layout=(4, 2), linewidth=3\n);","a868480e":"trend_dict = {}\n\nfor ts in meat.columns:\n    decomposition = sm.tsa.seasonal_decompose(meat[ts].dropna())\n    # Store back the results\n    trend_dict[ts] = decomposition.trend\n\npd.DataFrame(trend_dict).plot(subplots=True, layout=(4, 3), linewidth=3);","4cfd617d":"resid_dict = {}\n\nfor ts in meat.columns:\n    decomposition = sm.tsa.seasonal_decompose(meat[ts].dropna())\n    resid_dict[ts] = decomposition.resid\n\npd.DataFrame(resid_dict).plot(subplots=True, layout=(3, 3), linewidth=1);","46c9fb1b":"meat.plot(figsize=(16, 8), title=\"Meat Production in Tons in the USA\")\nplt.xlabel(\"Date\");","d43ed274":"meat.div(meat.iloc[0]).head()","0c8b78dd":"normalized = meat.div(meat.iloc[0]).mul(100)  # Multiply by 100 to get percentages\n\nnormalized.plot(figsize=(16, 8), title=\"Growth of Production in Different Meat Sectors\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Increase (%)\");","89e80f64":"# Create a custom palette\ncmap = sns.diverging_palette(250, 15, s=75, l=40, n=9, center=\"light\", as_cmap=True)\n\n# Compute corr matrix\nmatrix = meat.corr(method=\"pearson\")\n# Create a mask\nmask = np.triu(np.ones_like(matrix, dtype=bool))\n\nfig, ax = plt.subplots(figsize=(7, 7))\nsns.heatmap(matrix, mask=mask, cmap=cmap, square=True, annot=True, fmt=\".2f\", ax=ax)\nplt.show();","a3adff8e":"seasonality_dict = {\n    ts: sm.tsa.seasonal_decompose(meat[ts].dropna()).seasonal for ts in meat.columns\n}\n\n# Compute corr matrix\nseasonality_corr = pd.DataFrame(seasonality_dict).corr()\n\nsns.clustermap(seasonality_corr, annot=True, square=True)\nplt.show();","8499e176":"trend_dict = {\n    ts: sm.tsa.seasonal_decompose(meat[ts].dropna()).trend for ts in meat.columns\n}\n\n# Compute corr matrix\ntrend_dict = pd.DataFrame(trend_dict).corr()\n\nsns.clustermap(trend_dict, annot=True, square=True)\nplt.show();","7cbdab0e":"normalized = meat.div(meat.iloc[0]).mul(100)\n\nnormalized.plot(figsize=(16, 8), title=\"Growth of Production in Different Meat Sectors\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Increase (%)\");","84ea7747":"from statsmodels.graphics import tsaplots\n\nrcParams[\"figure.figsize\"] = 10, 6\n\n# Stands for Time Series Analysis Plots (TSA Plots)\nfig = tsaplots.plot_acf(tps[\"deg_C\"], lags=60)\n\nplt.xlabel(\"Lag at k\")\nplt.ylabel(\"Correlation coefficient\")\nplt.show()","063a658d":"beef = meat[\"beef\"].to_frame(name=\"beef\")\n\nbeef[\"lag_1\"] = beef[\"beef\"].shift(periods=1)\nbeef[\"lag_2\"] = beef[\"beef\"].shift(periods=2)\nbeef[\"lag_3\"] = beef[\"beef\"].shift(periods=3)\n\nbeef.head()","6f1fc6cc":"fig = tsaplots.plot_acf(tps[\"target_carbon_monoxide\"], lags=70)\n\nplt.title(\"Autocorrelation of Carbon Monoxide\")\nplt.xlabel(\"Lag at k\")\nplt.ylabel(\"Correlation Coefficient\")\nplt.show();","c70e8236":"# Mind the extra 'p' in plot_pacf\nfig = tsaplots.plot_pacf(tps[\"target_benzene\"], lags=70)\n\nplt.title(\"Partial Autocorrelation of Benzene\")\nplt.xlabel(\"Lag at k\")\nplt.ylabel(\"Correlation Coefficient\")\nplt.show();","84f1517d":"The only difference is that this method tries to account for the effect the intervening lags have. For example, at lag 3, partial autocorrelation removes the effect lags 1 and 2 have on computing the correlation.\n\nWhile autocorrelation is useful for analyzing a time series's properties and choosing what type of ARIMA model to use, partial autocorrelation tells what order of autoregressive model to fit.\n\nAgain, this topic will be discussed in-depth when we talk about forecasting. So, [stay tuned](https:\/\/medium.com\/r\/?url=https%3A%2F%2Fibexorigin.medium.com%2F)!","06d948cb":"Any time series distribution has 3 core components:\n\n1. **Seasonality**\u200a-\u200adoes the data have a clear cyclical\/periodic pattern?\n2. **Trend**\u200a-\u200adoes the data represent a general upward or downward slope?\n3. **Noise**\u200a-\u200awhat are the outliers or missing values that are not consistent with the rest of the data?\n\nDeconstructing a time series into these components is called **decomposition**, and we will explore each one in detail.","d1235ffc":"### You might also be interested...\n- [Every Pandas Function You Can (Should) Use to Manipulate Time Series](https:\/\/towardsdatascience.com\/every-pandas-function-you-can-should-use-to-manipulate-time-series-711cb0c5c749?source=your_stories_page-------------------------------------)\n- [Comprehensive Guide on Multiclass Classification Metrics](https:\/\/towardsdatascience.com\/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd?source=your_stories_page-------------------------------------)\n- [Practical Sklearn Feature Selection in 3 stages](https:\/\/towardsdatascience.com\/4-part-practical-study-guide-to-sklearn-feature-selection-b959a28d9ef7?source=your_stories_page-------------------------------------)","a4a8c143":"The XAxis of an autocorrelation function plot (ACF) is the lag number k. For example, when k=1, the correlation is found by shifting the series by 1. This is the same as using the `shift` function of Pandas:","709b753a":"I want you to tread carefully when making assumptions about correlated features. Always remember that correlation does not mean causation. When two features are heavily correlated, it does not mean an increase in one causes an increase in another.\n\nAn example I like to use is that even though the number of storks in a town can correlate with the number of newborn babies, it does not mean that storks deliver the babies.\n\nIt might take a while to draw the line between correlation and causation clearly, so why don't you take a look at my [other article](https:\/\/towardsdev.com\/how-to-not-misunderstand-correlation-75ce9b0289e?source=your_stories_page-------------------------------------) on the topic.","6fb2ffe4":"# Advanced Time Series Analysis in Python: Seasonality and Trend Analysis (Decomposition), Autocorrelation \n## and other advanced techniques to find relationship between multiple time series.\n![](https:\/\/cdn-images-1.medium.com\/max\/1500\/1*Vkes2H7Soxgdngi969oAEQ.jpeg)\n<figcaption style=\"text-align: center;\">\n    <strong>\n        Photo by \n        <a href='https:\/\/www.pexels.com\/@bentonphotocinema?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Jordan Benton<\/a>\n        on \n        <a href='https:\/\/www.pexels.com\/photo\/shallow-focus-photography-of-hourglass-1095602\/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pexels<\/a>\n    <\/strong>\n<\/figcaption>","78cb48ae":"Once again, the overall trend of a time series shows whether it increased, decreased, or stayed constant (flat) over a time period. The above `DecomposeResult` object contains values that show the overall slope of a time series under the `trend` attribute.\n\nLet's plot them for the meat production dataset:","0a31f106":"The YAXis is the amount of correlation at each lag k. The shaded red region is a confidence interval\u200a-\u200aif the height of the bars is outside this region, it means the correlation is *statistically significant*.\n\nPlease pause and think of what you can learn from an ACF plot.\n\nThey offer an alternative way of detecting patterns and seasonality. For example, the ACF plot of temperature in Celcius shows that the correlation at every 15 lags decreases or every 25 lags increases.\n\nWhen a clear trend exists in a time series, the autocorrelation tends to be high at small lags like 1 or 2. When seasonality exists, the autocorrelation goes up periodically at larger lags.\n\nLet's look at another example:","bfca8b76":"### 2.1 Relationships between time series with correlation","700d2f6d":"## 2. Working With Multiple Time Series","71e42905":"This time, we are using a ClusterMap rather than a heatmap to see closely correlated groups with the help of dendrograms immediately.\n\nThe plot tells us that the seasonality of beef, broilers, and other chicken meats are heavily correlated. The same is true with pork and lamb\/mutton meats. This positive correlation can be indicative of close seasonality matches. \n\nFor example, it is possible that increase\/decrease patterns of beef, broilers, and other chicken meats often matched over the given period.\n\nLet's do the same for trends, which I think should be more interesting:","a53f0505":"The ACF of carbon monoxide confirms that small lags tend to have high correlations. It also shows that every 25 lags, the correlation increases significantly but quickly drops down to the negative. But most of the downward bars are inside the shaded area, suggesting that they are *not statistically significant*.\n\nThis ability to compare the relationship between past and present data points present a unique advantage. If you can associate the present value to points k periods before, this also means you can find a link to values that come after k periods.\n\nBesides, understanding autocorrelation is key to modeling time series with ARIMA models (a topic for another article).","2a0f25a9":"What we are more interested in is how underlying components of time series affect each other. For example, let's see how the seasonality of each time series influences others:","09b81b95":"The above plot is awesome because it helps us validate our assumptions in the trend analysis section. Let's look at the normalized plot of meat production once again:","20ec9d78":"Beef and pork saw the highest percentage increases while veal and lamb meat production plummeted over the given time period.","54f252a7":"### 1.1 Seasonality analysis","1217461e":"### 2.1 Generals","0f62f6b2":"This plot shows that beef production really goes down at the beginning of each year, but it reaches its peak towards the end.\n\n> Note on `seasonal_decompose` function: it produces small figures by default. You have to control its aspects on your own and the `plot` function does not accept most of the regular Matplotlib parameters.\n\nNow, let's plot the seasonality of all types of meat over a 5-year interval:","0bc342d4":"Consider this TPS July Kaggle playground dataset:","23f3b110":"Can you match the patterns in the cluster map to the line plot? For example, beef has strong negative correlations with lamb\/mutton and veal. This is matched by the fact that beef production tripled in amount while the production of the other two decreased by ~75% (seen from the line plot).\n\nThe same observations can be made between pork and veal, lamb\/mutton.","1c34ffbb":"This plot is massively insightful compared to the simple line plot we saw in the beginning. Indeed, we now see that meat from lambs and veal production has decreased dramatically since the 1940s.\n\nThis might be in part caused by the double or triple production increases in beef, broilers, and turkey. We are performing informed guesses now, but we will explore some powerful methods to validate them in later sections.","74e1a0c9":"When features with larger scales squish others to a flat line (lamb and veal), it is impossible to compare their growth. One solution is using normalization.\n\nWhen normalizing time series, you divide every data point in the distribution by the first sample. This has the effect of representing every single data point as the percentage increase relative to the first sample:","1e994c8b":"Autocorrelation is a powerful analysis tool for modeling time series data. As the name suggests, it involves computing the correlation coefficient. But here, rather than computing it between two features, correlation of a time series is found with a lagging version of itself.\n\nLet's first look at an example plot and explain further:","15fcc733":"### 3.2 Partial autocorrelation\n\nEven though discussing partial autocorrelation means we are getting way ahead of things, I will give you the gist.\n\nIt is similar to autocorrelation\u200a-\u200ait is calculated using the series and its lagged version at k:","242da225":"As you can see, each meat types have rather different seasonality patterns. Now, let's explore trends.","7dbdf542":"> Calling `plot` on the whole `DecomposeResult` object will produce a plot with all components displayed on the same axes.\n\nDecomposing your times series helps you think of them in a structured manner. Instead of imagining a series as a value changing over time, you can think of it as a distribution with a particular seasonality signal or a feature with a particular slope. This level of data understanding can be a key factor during feature engineering and modeling.","861927d4":"To find hidden seasonal patterns from time series like above, we will use the `seasonal_decompose` function from `statsmodels`:","d21aafe0":"### 1.3 Noise","8db506a8":"### 1.2 Trend Analysis","ebc28cd5":"Following my very [well-received post](https:\/\/medium.com\/r?url=https%3A%2F%2Ftowardsdatascience.com%2Fevery-pandas-function-you-can-should-use-to-manipulate-time-series-711cb0c5c749%3Fsource%3Dyour_stories_page-------------------------------------) and [Kaggle notebook](https:\/\/medium.com\/r\/?url=https%3A%2F%2Fwww.kaggle.com%2Fbextuychiev%2Fevery-pandas-function-to-manipulate-time-series%2Fcomments) on every single Pandas function to manipulate time series, it is time to take the trajectory of this TS project to visualization.\n\nThis post is about the core processes that make up an in-depth time series analysis. Specifically, we will talk about:\n\n- Decomposition of time series\u200a-\u200aseasonality and trend analysis\n- Analyzing and comparing multiple time series simultaneously\n- Calculating autocorrelation and partial autocorrelation and what they represent\n\nand if seasonality or trends among multiple series affect each other.\n\nMost importantly, we will build some very cool visualizations, and this image should be a preview of what you will be learning.\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*ToUsutofdinrqAann6druA.png)\n\nI hope you are as excited about learning these things as I when writing this article. Let's begin.","b8ecdede":"## 1. Decomposition of Time Series ","113d3e86":"The best part is now, each distribution has the same scale. Let's plot the meat production data by performing normalization:","e7d860b0":"Obviously, summer months have higher temperatures, and we would expect this behavior to repeat every year. However, the human eye and its ability to detect patterns can only go so far.\n\nFor example, it might be harder to find seasonal patterns from plots such as these:","14022b0c":"### 2.2 Correlation does not mean causation","66eadc95":"## Summary\n\nCongratulations!\n\nBy reading this post, you learned powerful techniques to dissect any time series and derive meaningful insights. Most importantly, you now have the ability to apply these techniques to multiple time series and critically evaluate the relationships between them.\n\nThank you for reading, and I will see you in the next one!","74289029":"## Introduction","99197ee5":"Working with multiple time series presents certain challenges. One example, as we saw, is the different scales each distribution comes in:","b0817b1d":"I know what you are saying: \"Correlation? Really? What's new\u2026.\"\n\nBut bear with me. A simple correlation heatmap can indeed tell a lot about the linear relationships between variables:","a456c9e8":"The third component of time series is noise. There is nothing fancy about it like the other two components. It only shows random and irregular data points that could not be attributed to either seasonality or noise.\n\nYou can plot them using the `resid` attribute from the `DecomposeResult` object:","fbc9c9df":"Using `sm.tsa.seasonal_decompose` on 'beef' time-series returns a `DecomposeResult` object with attributes like seasonal, trend and resid (more on the last two later).\n\nAbove, we are plotting the seasonality, but the plot is not useful since it has too much noise. Let's choose an interval to give the line some room to breathe:","2e794c4e":"## 3. Autocorrelation and partial autocorrelation","6e3e6609":"### 3.1 Autocorrelation","49bca0ff":"## Setup"}}