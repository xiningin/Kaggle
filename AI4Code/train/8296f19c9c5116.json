{"cell_type":{"8d766be9":"code","850011e3":"code","bc55df0f":"code","87cca019":"code","32de808b":"code","419f5890":"code","938a7f11":"code","c7170e15":"code","ce528ffb":"code","f510f134":"code","f4181040":"code","c1e6181b":"code","71ddda43":"code","0bf69ed9":"code","14f95ac3":"code","fefb8ade":"code","f9457e61":"code","6534f99a":"code","0f421770":"code","4fd84cfe":"code","2c8b45e2":"code","70f9c433":"code","14947780":"code","b86ded7b":"code","e5d26fb5":"code","bb9f1517":"code","6399fdc7":"code","11fd0208":"code","667825f5":"code","b679e1e8":"code","55176bff":"code","db1c6c18":"code","a79a3fcd":"code","1e7dcdb2":"code","a7ef61dc":"code","93c46d97":"code","499bbf15":"code","917e2da8":"code","cd32840a":"code","caa2be06":"code","1b5d3214":"code","61048f10":"code","a8cb7c96":"code","c4cb24c5":"markdown","a432b7b5":"markdown","a1d83aae":"markdown","952c432d":"markdown","61360cd4":"markdown","523895d5":"markdown","d374c415":"markdown","9354278c":"markdown","bed6b78f":"markdown","0e831145":"markdown","808a0d81":"markdown","033590d7":"markdown","2082c93e":"markdown","190ca4a9":"markdown","029bcb7d":"markdown","dbb4fc62":"markdown","71f0f5b3":"markdown","bf5f46e2":"markdown","903f2c57":"markdown","1b040efe":"markdown","afa8cb1c":"markdown","611bb030":"markdown"},"source":{"8d766be9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle","850011e3":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","bc55df0f":"print(\"Train Shape: \",train.shape)\nprint(\"Test Shape: \",test.shape)","87cca019":"print(train.info())","32de808b":"print(test.info())","419f5890":"print(train.isnull().sum())","938a7f11":"sns.heatmap(train.isnull())","c7170e15":"print(test.isnull().sum())","ce528ffb":"sns.heatmap(test.isnull())","f510f134":"cat_col_train = ['FireplaceQu','GarageType','GarageFinish','MasVnrType','BsmtQual',\n           'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu',\n          'GarageQual','GarageCond']\n\nncat_col_train = ['LotFrontage','GarageYrBlt','MasVnrArea']","f4181040":"for i in cat_col_train:\n    train[i] = train[i].fillna(train[i].mode()[0])\n    \nfor j in ncat_col_train:\n    train[j] = train[j].fillna(train[j].mean())","c1e6181b":"cat_col_test = ['FireplaceQu','GarageType','GarageFinish','MasVnrType','BsmtQual',\n           'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu',\n          'GarageQual','GarageCond','MSZoning','Utilities','Exterior1st','Exterior2nd','KitchenQual','Functional','SaleType']\n\nncat_col_test = ['LotFrontage','GarageYrBlt','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath',\n                'BsmtHalfBath','GarageCars','GarageArea']","71ddda43":"for i in cat_col_test:\n    test[i] = test[i].fillna(test[i].mode()[0])\n    \nfor j in ncat_col_test:\n    test[j] = test[j].fillna(test[j].mean())","0bf69ed9":"to_drop = ['Id','Alley','PoolQC','Fence','MiscFeature']\n\nfor k in to_drop:\n    train.drop([k], axis = 1, inplace = True)\n    test.drop([k], axis = 1, inplace = True)","14f95ac3":"sns.heatmap(train.isnull())","fefb8ade":"sns.heatmap(test.isnull())","f9457e61":"print(\"Train Shape: \",train.shape)\nprint(\"Test Shape: \",test.shape)","6534f99a":"final_df = pd.concat([train,test], axis = 0)","0f421770":"final_df.shape","4fd84cfe":"all_cat_col = ['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope',\n              'Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl',\n              'Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual',\n              'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir',\n              'Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual',\n              'GarageCond','PavedDrive','SaleType','SaleCondition']","2c8b45e2":"def cat_onehot_encoding(multicol):\n    df_final = final_df\n    i = 0\n    for fields in multicol:\n        print(fields)\n        df1 = pd.get_dummies(final_df[fields],drop_first = True)\n        \n        final_df.drop([fields], axis = 1, inplace = True)\n        if i==0:\n            df_final = df1.copy()\n        else:\n            df_final = pd.concat([df_final,df1], axis=1)\n        i = i+1\n    \n    df_final = pd.concat([final_df,df_final], axis = 1)\n    \n    return df_final","70f9c433":"final_df = cat_onehot_encoding(all_cat_col)","14947780":"final_df.shape","b86ded7b":"final_df = final_df.loc[:,~final_df.columns.duplicated()]\nfinal_df.shape","e5d26fb5":"df_train = final_df.iloc[:1460,:]\ndf_test = final_df.iloc[1460:,:]","bb9f1517":"df_test.drop(['SalePrice'], axis = 1, inplace = True)","6399fdc7":"print(\"Train Shape: \",df_train.shape)\nprint(\"Test Shape: \",df_test.shape)","11fd0208":"x_train = df_train.drop(['SalePrice'], axis = 1)\ny_train = df_train['SalePrice']","667825f5":"import xgboost\n\nxgb_model = xgboost.XGBRegressor()\nxgb_model.fit(x_train, y_train)","b679e1e8":"param = {\n    'n_estimators': [100, 500, 900, 1100, 1500],\n    'max_depth': [2,3,5,10,15],\n    'learning_rate': [0.05, 0.1, 0.15, 0.2],\n    'min_child_weight': [1,2,3,4],\n    'booster': ['gbtree','gblinear'],\n    'base_score': [0.25, 0.5, 0.75, 1]\n}","55176bff":"from sklearn.model_selection import RandomizedSearchCV","db1c6c18":"random_cv = RandomizedSearchCV(estimator=xgb_model,\n                              param_distributions = param,\n                              cv=5, n_iter=50,\n                              scoring = 'neg_mean_absolute_error', n_jobs = 4,\n                              verbose = 5,\n                              return_train_score = True,\n                              random_state = 42)\nrandom_cv.fit(x_train, y_train)","a79a3fcd":"random_cv.best_estimator_","1e7dcdb2":"xgb_model = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)\n\nxgb_model.fit(x_train, y_train)","a7ef61dc":"f = \"xgb_model.pkl\"\npickle.dump(xgb_model,open(f,'wb'))","93c46d97":"pred_xgb = xgb_model.predict(df_test)\nprint(pred_xgb.shape)","499bbf15":"sub_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsub_df['SalePrice'] = pred_xgb\nsub_df.to_csv('sample_sub_xgb.csv', index = False)","917e2da8":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout","cd32840a":"from keras import backend as k\ndef root_mean_squared_error(y_true, y_pred):\n    return k.sqrt(k.mean(k.square(y_pred - y_true)))","caa2be06":"nn_model = Sequential()\n\nnn_model.add(Dense(50, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 176))\nnn_model.add(Dense(25, kernel_initializer = 'he_uniform', activation = 'relu'))\nnn_model.add(Dense(50, kernel_initializer = 'he_uniform', activation = 'relu'))\nnn_model.add(Dense(1, kernel_initializer = 'he_uniform'))\n\nnn_model.compile(loss = root_mean_squared_error, optimizer = 'Adamax')\n\nnn_model.fit(x_train.values, y_train.values, validation_split = 0.25, batch_size = 10, epochs = 1000)","1b5d3214":"nn_model.save('nn_model.h5')","61048f10":"pred_nn = nn_model.predict(df_test)\nprint(pred_nn.shape)","a8cb7c96":"sub_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsub_df['SalePrice'] = pred_nn\nsub_df.to_csv('sample_sub_nn.csv', index = False)","c4cb24c5":"#### Submission","a432b7b5":"## Overview\nAsk a home buyer to describe their dream house, and they probably won\u2019t begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition\u2019s dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home","a1d83aae":"### Artificial Neural Network","952c432d":"### Train Data","61360cd4":"## Training Data","523895d5":"# House Prediction","d374c415":"### Check for NULL values","9354278c":"## So let's start here...","bed6b78f":"#### For Train Data","0e831145":"## Acknowledgments\nThe Ames Housing dataset was compiled by Dean De Cock for use in data science education. It\u2019s an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset.","808a0d81":"#### Predictions","033590d7":"## XGBoost","2082c93e":"#### For Test Data","190ca4a9":"### Handling NULL data\n\nWe can see that 'Alley','PoolQC','Fence' and 'MiscFeature' columns have more than 70% of null values in both train and test data. So, we will drop these columns.<br>\nAlso, we will drop 'Id' column.\nFor non-categorical columns, we will handle null values by filling mean of the column.<br>\nFor categorical columns, we will handle null values by filling mode of the column.","029bcb7d":"#### Drop Columns","dbb4fc62":"#### Save Model","71f0f5b3":"It is observed that for some columns in train data few categories are not present but available in test data. So, we will concat test data to train data, then perform one hot encoding on all categorical columns.","bf5f46e2":"## Files\n* train.csv - the training set\n* test.csv - the test set\n* data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here","903f2c57":"train has 81 columns (79 features + id and target SalePrice) and 1460 entries<br>\ntest has 80 columns (79 features + id) and 1459 entries","1b040efe":"### Test Data","afa8cb1c":"Let's now divide our data to train and test data.","611bb030":"## Load Data"}}