{"cell_type":{"49415b5b":"code","41ce3892":"code","7af1d8ca":"code","42259f0a":"code","edbbd3eb":"code","0c4da65f":"markdown","c9f8500d":"markdown","eec534f1":"markdown","36aa1913":"markdown","b728e5b2":"markdown"},"source":{"49415b5b":"import os\nimport cv2\nimport numpy as np\nfrom time import time\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","41ce3892":"train_dir = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\ntest_dir = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\nplt.figure(figsize=(11, 11))\nfor i in range (0,29):\n    plt.subplot(7,7,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    path = train_dir + \"\/{0}\/{0}1.jpg\".format(classes[i])\n    img = plt.imread(path)\n    plt.imshow(img)\n    plt.xlabel(classes[i])","7af1d8ca":"def load_data(train_dir):\n    images = []\n    labels = []\n    size = 32,32\n    index = -1\n    for folder in os.listdir(train_dir):\n        index +=1\n        for image in os.listdir(train_dir + \"\/\" + folder):\n            temp_img = cv2.imread(train_dir + '\/' + folder + '\/' + image)\n            temp_img = cv2.resize(temp_img, size)\n            images.append(temp_img)\n            labels.append(index)\n    \n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n    labels = utils.to_categorical(labels)\n    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.1)\n    \n    print('Loaded', len(x_train),'images for training,','Train data shape =', x_train.shape)\n    print('Loaded', len(x_test),'images for testing','Test data shape =', x_test.shape)\n    \n    return x_train, x_test, y_train, y_test\n\nstart = time()\nx_train, x_test, y_train, y_test = load_data(train_dir)\nprint('Loading:', time() - start)","42259f0a":"classes = 29\nbatch = 128\nepochs = 5\nlearning_rate = 0.001\n\ndef results(model):\n  adam = Adam(lr=learning_rate)\n\n  model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\n  start = time()\n  history = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, validation_split=0.1, shuffle = True, verbose=1)\n  train_time = time() - start\n\n  model.summary()\n\n  plt.figure(figsize=(12, 12))\n  plt.subplot(3, 2, 1)\n  plt.plot(history.history['accuracy'], label = 'train_accuracy')\n  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.subplot(3, 2, 2)\n  plt.plot(history.history['loss'], label = 'train_loss')\n  plt.plot(history.history['val_loss'], label = 'val_loss')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.show()\n\n  start = time()\n  test_loss, test_acc = model.evaluate(x_test, y_test)\n  test_time = time() - start\n  print('\\nTrain time: ', train_time)\n  print('Test accuracy:', test_acc)\n  print('Test loss:', test_loss)\n  print('Test time: ', test_time)","edbbd3eb":"model = Sequential()\nmodel.add(Conv2D(256, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='sigmoid'))\nmodel.add(Dense(classes, activation='softmax'))\n\nresults(model)","0c4da65f":"## The data","c9f8500d":"## Configuration","eec534f1":"# ASL Alphabet Classification with CNN","36aa1913":"## Loading","b728e5b2":"## Network"}}