{"cell_type":{"913d2b03":"code","224a53a4":"code","51f7399a":"code","050799f8":"code","826f515a":"code","18775c2c":"code","26576ad8":"code","175a9e58":"code","e0f6ebb4":"code","4805437b":"code","ab27ad33":"code","4730bca5":"code","ba6ba0b3":"code","f624a0f5":"code","03db06ba":"code","ea764752":"code","3cf3d682":"code","a8013ce2":"code","eb4b3840":"code","f6855a4b":"code","fa39e5eb":"code","2f1c3c48":"code","bc781c6c":"code","9b3d2e70":"markdown","158b9488":"markdown","4a3ce571":"markdown","cf42523c":"markdown","7f352d2e":"markdown","664955ec":"markdown","b2b99bb7":"markdown","c1c48ddc":"markdown","36b8cab1":"markdown","5bf34798":"markdown","2baa55de":"markdown","b250579d":"markdown","3bc12c65":"markdown"},"source":{"913d2b03":"import pandas as pd","224a53a4":"train = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\ntrain.head()","51f7399a":"cat_cols = [x for x in train.columns if x.startswith('cat')]\ncat_cols","050799f8":"x_train = train.drop(columns=['id','target'])\ny_train = train['target']","826f515a":"from categorical_transform import CategoricalTransform, OneHotTransform\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd","18775c2c":"min_cat_size = [0, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\ndata_size = []\nfor min_data_portion in min_cat_size:\n    ct = CategoricalTransform(cat_cols, min_data_portion = min_data_portion)\n    pipe = Pipeline([('categorical_transform', ct), \n                    ('one hot', OneHotTransform())])\n    data_size.append(pipe.fit_transform(x_train).shape[1])\npd.DataFrame(dict(min_cat_size=min_cat_size, num_columns=data_size))","26576ad8":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nkfold = KFold(n_splits=5, shuffle=True)","175a9e58":"def analyse_cat_size(pipe, x_train=x_train, y_train = y_train):\n    gscv = GridSearchCV(pipe, dict(trans__min_data_portion=min_cat_size), cv=kfold, scoring='roc_auc', verbose=1)\n    gscv.fit(x_train, y_train)\n    return pd.DataFrame(dict(cat_size = min_cat_size, \n                  fit_time=gscv.cv_results_['mean_fit_time'], \n                  auc=gscv.cv_results_['mean_test_score']))","e0f6ebb4":"from lightgbm.sklearn import LGBMClassifier","4805437b":"lightgbm_pipe = Pipeline([(\"trans\", CategoricalTransform(cat_cols)),\n                          (\"lgbm\", LGBMClassifier(n_jobs = -2))])","ab27ad33":"analyse_cat_size(lightgbm_pipe)","4730bca5":"from xgboost import XGBClassifier\nxgb = XGBClassifier(n_jobs=-2, eval_metric='auc', use_label_encoder=False)\nfrom categorical_transform import IntegerCategoricalTransform\nfrom sklearn.pipeline import Pipeline\nxgb_pipe = Pipeline([('trans',IntegerCategoricalTransform(cat_cols=cat_cols)),('xgboost', xgb)])","ba6ba0b3":"analyse_cat_size(xgb_pipe)","f624a0f5":"from xgboost import XGBClassifier\nxgb = XGBClassifier(n_jobs=-2, eval_metric='auc', use_label_encoder=False)\nfrom categorical_transform import CategoricalTransform, OneHotTransform\nfrom sklearn.pipeline import Pipeline\nxgb_pipe = Pipeline([('trans',CategoricalTransform(cat_cols=cat_cols)),\n                     ('oht',OneHotTransform()),\n                     ('xgboost', xgb)])","03db06ba":"analyse_cat_size(xgb_pipe)","ea764752":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_jobs=-2)\nfrom categorical_transform import IntegerCategoricalTransform\nfrom sklearn.pipeline import Pipeline\nrf_pipe = Pipeline([('trans',IntegerCategoricalTransform(cat_cols=cat_cols)),('rf', rf)])","3cf3d682":"analyse_cat_size(rf_pipe)","a8013ce2":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_jobs=-2)\nfrom categorical_transform import CategoricalTransform, OneHotTransform\nfrom sklearn.pipeline import Pipeline\nrf_pipe = Pipeline([('trans',CategoricalTransform(cat_cols=cat_cols)),\n                    ('oht', OneHotTransform()),\n                    ('rf', rf)])","eb4b3840":"analyse_cat_size(rf_pipe)","f6855a4b":"from sklearn.naive_bayes import CategoricalNB\ncatnb = CategoricalNB()\nfrom categorical_transform import NonNegativeIntegerCategoricalTransform\nfrom sklearn.pipeline import Pipeline\ncatnb_pipe = Pipeline([('trans',NonNegativeIntegerCategoricalTransform(cat_cols=cat_cols)),\n                       ('catnb', catnb)])","fa39e5eb":"analyse_cat_size(catnb_pipe, x_train=x_train[cat_cols])","2f1c3c48":"from sklearn.linear_model import LogisticRegression\nfrom categorical_transform import CategoricalTransform, OneHotTransform\nfrom sklearn.pipeline import Pipeline\nlr_pipe = Pipeline([('trans',CategoricalTransform(cat_cols=cat_cols)),\n                     ('oht', OneHotTransform()),\n                     ('lr', LogisticRegression(n_jobs=-2))])","bc781c6c":"analyse_cat_size(lr_pipe, x_train=x_train)","9b3d2e70":"# Reducing the number of categories\nEffect of reducing the number of categories for different types of models","158b9488":"## Load data","4a3ce571":"## Lightgbm default model performance with different min_cat_sizes","cf42523c":"## Default xgboost, one-hot encoding","7f352d2e":"## Randomforest default integer encoding","664955ec":"## Categorical naive bayes","b2b99bb7":"One hot slightly better than ordinal encoding. Reducing category size speeds up training slightly.","c1c48ddc":"## Default xgboost, integer encoding","36b8cab1":"## Reduction of columns in one hot encoding by category size reduction","5bf34798":"One hot slightly better than ordinal encoding. Reducing category size speeds up training significantly.","2baa55de":"# Logistic Regression","b250579d":"## Randomforest one hot encoding","3bc12c65":"## Analysis Tools"}}