{"cell_type":{"17fda5a8":"code","cd8e11dc":"code","97d46ec9":"code","6af45e4f":"code","a8bec1ec":"code","12d679f6":"code","6539eec6":"code","f8ce89e2":"code","fc65c840":"code","b34cc517":"code","20fac056":"code","b0193b7e":"code","f5eef44a":"code","7cec6107":"code","e3c90cc2":"code","2d13bc7e":"code","1c2838e9":"code","7da595aa":"code","7729b0aa":"code","81209b8a":"code","2ad5d94e":"code","da6e0687":"code","ec285544":"code","7f4a7e76":"code","ecf0e092":"code","0add8b9a":"code","f6ef4f71":"code","54c3a636":"code","6e2f23b6":"code","25b2b363":"code","f0d80ec5":"code","b39a3e70":"code","f8ee36fe":"code","3a16f550":"code","31a374a2":"code","a4b44ca7":"code","5d7d12b7":"code","617a9289":"code","757b117f":"code","4f55b598":"code","fbb13030":"code","a8c81f6f":"code","71364c05":"code","9245bd8a":"code","614faf5a":"code","c40ba4ef":"code","ddfbafab":"code","38edc84b":"code","2d52d7f0":"code","03cd3c3f":"code","859a152e":"code","1aa3079d":"code","4d958664":"code","00e434e6":"code","c94c9bdf":"code","ea882a5a":"code","48a2d3d1":"code","2c38982c":"code","7cd07b88":"code","b9382abd":"code","7f87b8dd":"code","e4748f34":"code","4e13e2b8":"code","29fef526":"code","66ff28c5":"code","87fde960":"code","597af423":"code","7a49f36a":"code","ed135c53":"code","921b6a8e":"code","55142578":"code","cc0b0450":"code","dc1ef3e7":"code","80bcdf0b":"code","2e3e3681":"code","df1c91e7":"code","b9ae1827":"code","8ae09e49":"code","4e508112":"code","7d5f59ab":"code","bb8c6d29":"code","9788f3df":"code","ba3643d9":"code","9d4df52a":"code","713280d4":"code","8b664c04":"code","2bde33d6":"code","d36ecbe5":"code","2441a38a":"code","5bfbe67a":"code","922ca108":"code","19286f06":"code","2bdc6c77":"code","a68d5640":"code","9c20c234":"code","a59dfec2":"code","3cf4189b":"code","29d53dff":"code","d1ef2aac":"code","b7df75f7":"code","fc5259eb":"code","93a2056a":"code","dc5046b3":"code","39c18d40":"code","98e555d1":"code","b4fa0fea":"code","e354aa61":"code","c049e28d":"code","a8b76054":"code","99883931":"code","5c753315":"code","76fa9987":"code","987b4b0d":"code","3d2f05e5":"code","501124ca":"code","db240a33":"code","435f1fdf":"code","58f1bfbc":"code","d7b0a262":"code","c08df0ba":"code","c5a56c52":"code","800fabd8":"code","7401ef37":"code","320c8a61":"code","fc7d6160":"code","99565345":"code","2c65a7e1":"code","046876f9":"code","f4488e93":"code","50a5696e":"code","35003d25":"code","27dd81ae":"code","d5c8947f":"code","006363f1":"code","c0a9634f":"code","29d4601b":"code","95eae2af":"code","eeb7dd31":"code","5fd4f026":"code","e25246da":"code","6b5b5137":"code","339878ce":"code","50c8e3c2":"code","4c22cf55":"code","5d4f0f91":"code","2840082d":"code","724ba5c4":"code","b36567a0":"code","6df5b36d":"code","520d5662":"code","76511faa":"code","9b264828":"code","54124e5a":"code","742a2a75":"code","b854ecb7":"code","f983ef00":"code","6f2ecdaa":"code","d71c09e1":"code","9eba2321":"code","e7a8f5d4":"code","d5e1b6a8":"code","db19df1f":"code","811dc34f":"code","b60f6b49":"code","40b02ceb":"code","32ebc8e0":"code","a2179754":"code","f98132a7":"code","291d1604":"markdown","878595eb":"markdown","a70f24cb":"markdown","1cbfc13f":"markdown","7a4a474a":"markdown","0f5192d3":"markdown","5bdddda4":"markdown","2d7aa44d":"markdown","c1cf6c01":"markdown","8dcb7cc0":"markdown","8bfcd2e2":"markdown","c8a35251":"markdown","c802adc1":"markdown","98fc38c0":"markdown","6b5792c2":"markdown","4ae013d7":"markdown","ab8f2392":"markdown","e1c26bfe":"markdown","8c6eb752":"markdown","9c72abb6":"markdown","0533d650":"markdown","0da16b8e":"markdown","3b96a6e5":"markdown","b7a50cb5":"markdown","7db3c108":"markdown","92c02a49":"markdown","7d6e0021":"markdown","c5fa7c22":"markdown","7fbc1d24":"markdown","906e9ce0":"markdown","c047e72b":"markdown","13d05960":"markdown","1a526f7b":"markdown","b5923e7d":"markdown","2b7ae966":"markdown","1651dd96":"markdown","6e8608e1":"markdown","4651db53":"markdown","87edc46f":"markdown","7679c445":"markdown","48fbd1bd":"markdown","bb1a13df":"markdown","ed4b04ab":"markdown","88aea993":"markdown","a0f11ad5":"markdown","22a09165":"markdown","f5759891":"markdown","e542e62e":"markdown","50598b80":"markdown"},"source":{"17fda5a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd8e11dc":"df_train = pd.read_csv('\/kaggle\/input\/GiveMeSomeCredit\/cs-training.csv', index_col = 0)\ndf_test = pd.read_csv('\/kaggle\/input\/GiveMeSomeCredit\/cs-test.csv', index_col = 0)\ndf_entry = pd.read_csv('\/kaggle\/input\/GiveMeSomeCredit\/sampleEntry.csv', index_col = 0)","97d46ec9":"df_train.head()","6af45e4f":"df_test.head()","a8bec1ec":"df_train.info()","12d679f6":"df_test.info()","6539eec6":"pd.DataFrame({'count':df_train.isnull().sum().values, 'ratio': df_train.isnull().mean() * 100})","f8ce89e2":"pd.DataFrame({'count':df_test.isnull().sum().values, 'ratio': df_test.isnull().mean() * 100})","fc65c840":"df_train[df_train['MonthlyIncome'].isnull()][['NumberOfDependents', 'DebtRatio']].describe()","b34cc517":"df_train[df_train['NumberOfDependents'].isnull()][['MonthlyIncome', 'DebtRatio']].describe()","20fac056":"df_train[df_train['DebtRatio']>100]['MonthlyIncome'].isnull().sum()\/len(df_train)*100, df_test[df_test['DebtRatio']>100]['MonthlyIncome'].isnull().sum()\/len(df_test)*100","b0193b7e":"df_train[df_train['MonthlyIncome'].isnull()]['NumberOfDependents'].isnull().sum()\/len(df_train)*100, df_test[df_test['MonthlyIncome'].isnull()]['NumberOfDependents'].isnull().sum()\/len(df_test)*100","f5eef44a":"df_train[(df_train['DebtRatio']>100) & (df_train['MonthlyIncome'].notnull())]['MonthlyIncome'].describe()","7cec6107":"df_train[(df_train['DebtRatio']<100) & (df_train['MonthlyIncome'].notnull())]['MonthlyIncome'].describe()","e3c90cc2":"df_train['MonthlyIncome'].replace(np.nan, 0, inplace=True)\ndf_test['MonthlyIncome'].replace(np.nan, 0, inplace=True)\ndf_train['NumberOfDependents'].replace(np.nan, 0, inplace=True)\ndf_test['NumberOfDependents'].replace(np.nan, 0, inplace=True)","2d13bc7e":"df_train['SeriousDlqin2yrs'].value_counts()\/len(df_train)","1c2838e9":"sns.countplot('SeriousDlqin2yrs' ,data=df_train)","7da595aa":"df_train['RevolvingUtilizationOfUnsecuredLines'].describe().to_frame().T","7729b0aa":"df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] > df_train['RevolvingUtilizationOfUnsecuredLines'].quantile(0.99)]['RevolvingUtilizationOfUnsecuredLines'].describe()","81209b8a":"fig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.distplot(x = np.array(df_train['RevolvingUtilizationOfUnsecuredLines']),\n             ax = axes[0])\naxes[0].set_title('Histogram Plot of RevolvingUtilizationOfUnsecuredLines')\nsns.boxplot(x = df_train['RevolvingUtilizationOfUnsecuredLines'], ax = axes[1])\naxes[1].set_title('Box Plot of RevolvingUtilizationOfUnsecuredLines')","2ad5d94e":"below_1 = df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] < 1]['RevolvingUtilizationOfUnsecuredLines'].count()*100\/len(df_train)\nbet_1_10 = df_train[(df_train['RevolvingUtilizationOfUnsecuredLines'] > 1) &\n        (df_train['RevolvingUtilizationOfUnsecuredLines'] < 10)]['RevolvingUtilizationOfUnsecuredLines'].count() * 100\/len(df_train)\nbeyond_10 = df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] > 10]['RevolvingUtilizationOfUnsecuredLines'].count()*100\/len(df_train)","da6e0687":"fig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.boxplot(x = df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] < 1]['RevolvingUtilizationOfUnsecuredLines'],\n            ax = axes[0])\naxes[0].set_title('{}% of Train_Dataset'.format(round(below_1, 0)))\nsns.boxplot(x = df_train[(df_train['RevolvingUtilizationOfUnsecuredLines'] > 1) &\n                        (df_train['RevolvingUtilizationOfUnsecuredLines'] < 10)]['RevolvingUtilizationOfUnsecuredLines'],\n            ax = axes[1])\naxes[1].set_title('{}% of Train_Dataset'.format(round(bet_1_10, 0)))","ec285544":"df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] > 10]['RevolvingUtilizationOfUnsecuredLines'].count()\/len(df_train)*100, df_test[df_test['RevolvingUtilizationOfUnsecuredLines'] > 10]['RevolvingUtilizationOfUnsecuredLines'].count()\/len(df_test)*100","7f4a7e76":"to_drop_train = df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] > 10].index.values\n#to_drop_test = df_test[df_test['RevolvingUtilizationOfUnsecuredLines'] > 10].index.values","ecf0e092":"#df_train.drop(to_drop_train, axis = 0, inplace = True)\n#df_test.drop(to_drop_test, axis = 0, inplace = True)","0add8b9a":"df_train['DebtRatio'].describe().to_frame().T","f6ef4f71":"fig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.distplot(x = np.array(df_train['DebtRatio']),\n             ax = axes[0])\naxes[0].set_title('Histogram Plot of Debt Ratio')\nsns.boxplot(x = df_train['DebtRatio'], ax = axes[1])\naxes[1].set_title('Box Plot of Debt Ratio')","54c3a636":"pd.DataFrame({'below 1': df_train[df_train['DebtRatio'] <= 1]['DebtRatio'].count()*100\/len(df_train),\n             'between 1 - 10': df_train[(df_train['DebtRatio'] > 1) &\n                                        (df_train['DebtRatio'] <=10)]['DebtRatio'].count()*100\/len(df_train),\n             'beyond 10': df_train[df_train['DebtRatio'] > 10]['DebtRatio'].count()*100\/len(df_train)}, index = [1])","6e2f23b6":"df_train[(df_train['DebtRatio'] > 1) & (df_train['DebtRatio'] <=10)]['DebtRatio'].describe().to_frame().T","25b2b363":"df_train[df_train['DebtRatio'] > 10]['DebtRatio'].describe().describe().to_frame().T","f0d80ec5":"fig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.boxplot(x= df_train['age'], ax = axes[0])\naxes[0].set_title('Train_Dataset')\nsns.boxplot(x= df_test['age'], ax = axes[1])\naxes[1].set_title('Test_Dataset')","b39a3e70":"df_train['age'].replace(0, 18, inplace=True)","f8ee36fe":"fig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.histplot(x = df_train['NumberOfOpenCreditLinesAndLoans'], binwidth=1, ax = axes[0])\nsns.histplot(x = df_test['NumberOfOpenCreditLinesAndLoans'], binwidth=1, ax = axes[1])","3a16f550":"fig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.histplot(x = df_train['NumberRealEstateLoansOrLines'], binwidth=1, ax = axes[0])\nsns.histplot(x = df_test['NumberRealEstateLoansOrLines'], binwidth=1, ax = axes[1])","31a374a2":"df_train['NumberRealEstateLoansOrLines'].value_counts()","a4b44ca7":"fig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.histplot(x = df_train['NumberOfDependents'], binwidth=1, ax = axes[0])\nsns.histplot(x = df_test['NumberOfDependents'], binwidth=1, ax = axes[1])","5d7d12b7":"due_30_59 = pd.DataFrame(df_train['NumberOfTime30-59DaysPastDueNotWorse'].value_counts()).rename(columns = {'NumberOfTime30-59DaysPastDueNotWorse':'30-59days'})\ndue_60_89 =  pd.DataFrame(df_train['NumberOfTime60-89DaysPastDueNotWorse'].value_counts()).rename(columns = {'NumberOfTime60-89DaysPastDueNotWorse':'60-89days'})\ndue_90 = pd.DataFrame(df_train['NumberOfTimes90DaysLate'].value_counts()).rename(columns = {'NumberOfTimes90DaysLate':'90days'})\npd.concat([due_30_59, due_60_89, due_90], axis = 1)","617a9289":"df_train[df_train['NumberOfTime30-59DaysPastDueNotWorse'] > 17][['NumberOfTime30-59DaysPastDueNotWorse',\n                                                                'NumberOfTime60-89DaysPastDueNotWorse',\n                                                                'NumberOfTimes90DaysLate']]","757b117f":"df_train[df_train['NumberOfTime30-59DaysPastDueNotWorse'] > 17]['SeriousDlqin2yrs'].mean()*100","4f55b598":"#import libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc, f1_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","fbb13030":"#ROC curve function\n# We plot the false positive rate along the x-axis and the true positive rate along the y-axis,\ndef plot_roc(y_valid, y_pred_proba):\n    fpr, tpr, thresholds = roc_curve(y_valid, y_pred_proba)\n    plt.plot(fpr, tpr)\n    plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')","a8c81f6f":"df_train.reset_index(drop = True, inplace = True)\n#df_test.reset_index(drop = True, inplace = True)","71364c05":"df_train_inputs = df_train.loc[:, df_train.columns.values[1:]]\ndf_test_inputs = df_test.loc[:, df_train.columns.values[1:]]\ndf_train_target = df_train.loc[:, df_train.columns.values[0]].to_frame()","9245bd8a":"#stratified split\nX_train, X_valid, y_train, y_valid = train_test_split(np.array(df_train_inputs), np.array(df_train_target),\n                                                      test_size = 0.2, random_state = 42, stratify = np.array(df_train_target))","614faf5a":"#logistic regression object\nlr = LogisticRegression(max_iter=300, solver = 'liblinear')","c40ba4ef":"#fit logistic regression\nlr.fit(X_train, y_train)","ddfbafab":"#predictions 1 or 0\ny_pred = lr.predict(X_valid)","38edc84b":"#predictions in probalities\ny_pred_proba = lr.predict_proba(X_valid)\ny_pred_proba = y_pred_proba[: ][: , 1]","2d52d7f0":"#confusion matrix\ncm = metrics.confusion_matrix(y_valid, y_pred)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt=\".2f\", linewidths=.5, square =True, cmap = 'Blues_r');\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nall_sample_title = 'Confusion Matrix'\nplt.title(all_sample_title, size = 15)\nplt.show()","03cd3c3f":"#classification report: recall, precision, f1-score, accuracy\nprint(classification_report(y_valid, y_pred))","859a152e":"#ROC_curve\nplot_roc(y_valid, y_pred_proba)","1aa3079d":"#AUC score\nroc_auc_score(y_valid, y_pred_proba)","4d958664":"y_proba_base = lr.predict_proba(np.array(df_test_inputs))\nlr_baseline_model = pd.DataFrame({'Id': df_test.index.values,\n                                 'Probability': y_proba_base[:, 1]})\nlr_baseline_model.set_index(keys = 'Id', inplace = True)\nlr_baseline_model","00e434e6":"def woe_discrete(df, discrete_variabe_name, good_bad_variable_df):\n    df = pd.concat([df[discrete_variabe_name], good_bad_variable_df], axis = 1)\n    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n    df = df.iloc[:, [0, 1, 3]]\n    df.columns = [df.columns.values[0], 'n_obs', 'prop_bad']\n    df['prop_n_obs'] = df['n_obs'] \/ df['n_obs'].sum()\n    df['n_bad'] = df['prop_bad'] * df['n_obs']\n    df['n_good'] = (1 - df['prop_bad']) * df['n_obs']\n    df['prop_n_good'] = df['n_good'] \/ df['n_good'].sum()\n    df['prop_n_bad'] = df['n_bad'] \/ df['n_bad'].sum()\n    df['WoE'] = np.log(df['prop_n_good'] \/ df['prop_n_bad'])\n    df = df.sort_values(['WoE'])\n    df = df.reset_index(drop = True)\n    df['diff_prop_good'] = (1 - df['prop_bad']).diff().abs()\n    df['diff_WoE'] = df['WoE'].diff().abs()\n    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n    #df['IV'] = df['IV'].replace([np.inf, -np.inf], np.nan).sum()\n    return df","c94c9bdf":"def woe_continuous(df, discrete_variabe_name, good_bad_variable_df):\n    df = pd.concat([df[discrete_variabe_name], good_bad_variable_df], axis = 1)\n    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n    df = df.iloc[:, [0, 1, 3]]\n    df.columns = [df.columns.values[0], 'n_obs', 'prop_bad']\n    df['prop_n_obs'] = df['n_obs'] \/ df['n_obs'].sum()\n    df['n_bad'] = df['prop_bad'] * df['n_obs']\n    df['n_good'] = (1 - df['prop_bad']) * df['n_obs']\n    df['prop_n_good'] = df['n_good'] \/ df['n_good'].sum()\n    df['prop_n_bad'] = df['n_bad'] \/ df['n_bad'].sum()\n    df['WoE'] = np.log(df['prop_n_good'] \/ df['prop_n_bad'])\n    #df = df.sort_values(['WoE'])\n    #df = df.reset_index(drop = True)\n    df['diff_prop_good'] = (1 - df['prop_bad']).diff().abs()\n    df['diff_WoE'] = df['WoE'].diff().abs()\n    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n    #df['IV'] = df['IV'].replace([np.inf, -np.inf], np.nan).sum()\n    return df","ea882a5a":"# Below we define a function that takes 2 arguments: a dataframe and a number.\n# The number parameter has a default value of 0.\n# This means that if we call the function and omit the number parameter, it will be executed with it having a value of 0.\n# The function displays a graph.\ndef plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n    x = np.array(df_WoE.iloc[:, 0].apply(str))\n    # Turns the values of the column with index 0 to strings, makes an array from these strings, and passes it to variable x.\n    y = df_WoE['WoE']\n    # Selects a column with label 'WoE' and passes it to variable y.\n    plt.figure(figsize=(18, 6))\n    # Sets the graph size to width 18 x height 6.\n    plt.plot(x, y, marker = 'o', linestyle = '--', color = 'k')\n    # Plots the datapoints with coordiantes variable x on the x-axis and variable y on the y-axis.\n    # Sets the marker for each datapoint to a circle, the style line between the points to dashed, and the color to black.\n    plt.xlabel(df_WoE.columns[0])\n    # Names the x-axis with the name of the column with index 0.\n    plt.ylabel('Weight of Evidence')\n    # Names the y-axis 'Weight of Evidence'.\n    plt.title(str('Weight of Evidence by ' + df_WoE.columns[0]))\n    # Names the grapth 'Weight of Evidence by ' the name of the column with index 0.\n    plt.xticks(rotation = rotation_of_x_axis_labels)\n    # Rotates the labels of the x-axis a predefined number of degrees.","48a2d3d1":"df_temp = woe_discrete(df_train_inputs, 'NumberOfTime30-59DaysPastDueNotWorse', df_train_target)\ndf_temp","2c38982c":"plot_by_woe(df_temp)","7cd07b88":"df_train_inputs['PastDue30-59:11-13-96-10'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([11,13,96,10]), 1, 0)\ndf_train_inputs['PastDue30-59:98-6-7-12'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([98,6,7,12]), 1, 0)\ndf_train_inputs['PastDue30-59:5-4'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([5,4]), 1, 0)\ndf_train_inputs['PastDue30-59:3'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([3]), 1, 0)\ndf_train_inputs['PastDue30-59:9-8'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([9,8]), 1, 0)\ndf_train_inputs['PastDue30-59:2'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([2]), 1, 0)\ndf_train_inputs['PastDue30-59:1'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([1]), 1, 0)\n#df_train_inputs['PastDue30-59:0'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([5,4]), 1, 0)","b9382abd":"df_test_inputs['PastDue30-59:11-13-96-10'] = np.where(df_test_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([11,13,96,10]), 1, 0)\ndf_test_inputs['PastDue30-59:98-6-7-12'] = np.where(df_test_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([98,6,7,12]), 1, 0)\ndf_test_inputs['PastDue30-59:5-4'] = np.where(df_test_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([5,4]), 1, 0)\ndf_test_inputs['PastDue30-59:3'] = np.where(df_test_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([3]), 1, 0)\ndf_test_inputs['PastDue30-59:9-8'] = np.where(df_test_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([9,8]), 1, 0)\ndf_test_inputs['PastDue30-59:2'] = np.where(df_test_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([2]), 1, 0)\ndf_test_inputs['PastDue30-59:1'] = np.where(df_test_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([1]), 1, 0)\n#df_train_inputs['PastDue30-59:0'] = np.where(df_train_inputs['NumberOfTime30-59DaysPastDueNotWorse'].isin([5,4]), 1, 0)","7f87b8dd":"df_temp = woe_discrete(df_train_inputs, 'NumberOfTime60-89DaysPastDueNotWorse', df_train_target)\ndf_temp","e4748f34":"plot_by_woe(df_temp)","4e13e2b8":"df_train_inputs['PastDue60-89:11-96-6-9'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([11,96,6,9]), 1, 0)\ndf_train_inputs['PastDue60-89:4-5'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([4,5]), 1, 0)\ndf_train_inputs['PastDue60-89:3-98'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([3, 98]), 1, 0)\ndf_train_inputs['PastDue60-89:7-8'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([7, 8]), 1, 0)\ndf_train_inputs['PastDue60-89:2'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([2]), 1, 0)\ndf_train_inputs['PastDue60-89:1'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([1]), 1, 0)\n#df_train_inputs['PastDue60-89:0'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([0]), 1, 0)","29fef526":"df_test_inputs['PastDue60-89:11-96-6-9'] = np.where(df_test_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([11,96,6,9]), 1, 0)\ndf_test_inputs['PastDue60-89:4-5'] = np.where(df_test_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([4,5]), 1, 0)\ndf_test_inputs['PastDue60-89:3-98'] = np.where(df_test_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([3,98]), 1, 0)\ndf_test_inputs['PastDue60-89:7-8'] = np.where(df_test_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([7,8]), 1, 0)\ndf_test_inputs['PastDue60-89:2'] = np.where(df_test_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([2]), 1, 0)\ndf_test_inputs['PastDue60-89:1'] = np.where(df_test_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([1]), 1, 0)\n#df_train_inputs['PastDue60-89:0'] = np.where(df_train_inputs['NumberOfTime60-89DaysPastDueNotWorse'].isin([0]), 1, 0)","66ff28c5":"df_temp = woe_discrete(df_train_inputs, 'NumberOfTimes90DaysLate', df_train_target)\ndf_temp","87fde960":"plot_by_woe(df_temp)","597af423":"df_train_inputs['PastDue90:9-96-7-17-15-8'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([9,96,7,17,15,8]), 1, 0)\ndf_train_inputs['PastDue90:4-5'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([4,5]), 1, 0)\ndf_train_inputs['PastDue90:6-10-11'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([6,10,11]), 1, 0)\ndf_train_inputs['PastDue90:3-98'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([3,98]), 1, 0)\ndf_train_inputs['PastDue90:12-13-14'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([12,13,14]), 1, 0)\ndf_train_inputs['PastDue90:2'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([2]), 1, 0)\ndf_train_inputs['PastDue90:1'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([1]), 1, 0)\n#df_train_inputs['PastDue90:0'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([0]), 1, 0)","7a49f36a":"df_test_inputs['PastDue90:9-96-7-17-15-8'] = np.where(df_test_inputs['NumberOfTimes90DaysLate'].isin([9,96,7,17,15,8]), 1, 0)\ndf_test_inputs['PastDue90:4-5'] = np.where(df_test_inputs['NumberOfTimes90DaysLate'].isin([4,5]), 1, 0)\ndf_test_inputs['PastDue90:6-10-11'] = np.where(df_test_inputs['NumberOfTimes90DaysLate'].isin([6,10,11]), 1, 0)\ndf_test_inputs['PastDue90:3-98'] = np.where(df_test_inputs['NumberOfTimes90DaysLate'].isin([3,98]), 1, 0)\ndf_test_inputs['PastDue90:12-13-14'] = np.where(df_test_inputs['NumberOfTimes90DaysLate'].isin([12,13,14]), 1, 0)\ndf_test_inputs['PastDue90:2'] = np.where(df_test_inputs['NumberOfTimes90DaysLate'].isin([2]), 1, 0)\ndf_test_inputs['PastDue90:1'] = np.where(df_test_inputs['NumberOfTimes90DaysLate'].isin([1]), 1, 0)\n#df_train_inputs['PastDue90:0'] = np.where(df_train_inputs['NumberOfTimes90DaysLate'].isin([0]), 1, 0)","ed135c53":"df_temp = woe_discrete(df_train_inputs, 'NumberOfDependents', df_train_target)\ndf_temp","921b6a8e":"plot_by_woe(df_temp)","55142578":"df_train_inputs['NumberOfDependents:>9'] = np.where(df_train_inputs['NumberOfDependents'].isin([9,10,13,20]), 1, 0)\ndf_train_inputs['NumberOfDependents:6'] = np.where(df_train_inputs['NumberOfDependents'].isin([6]), 1, 0)\ndf_train_inputs['NumberOfDependents:4'] = np.where(df_train_inputs['NumberOfDependents'].isin([4]), 1, 0)\ndf_train_inputs['NumberOfDependents:1'] = np.where(df_train_inputs['NumberOfDependents'].isin([1]), 1, 0)\ndf_train_inputs['NumberOfDependents:2'] = np.where(df_train_inputs['NumberOfDependents'].isin([2]), 1, 0)\ndf_train_inputs['NumberOfDependents:7'] = np.where(df_train_inputs['NumberOfDependents'].isin([7]), 1, 0)\ndf_train_inputs['NumberOfDependents:5'] = np.where(df_train_inputs['NumberOfDependents'].isin([5]), 1, 0)\ndf_train_inputs['NumberOfDependents:3'] = np.where(df_train_inputs['NumberOfDependents'].isin([3]), 1, 0)\ndf_train_inputs['NumberOfDependents:8'] = np.where(df_train_inputs['NumberOfDependents'].isin([8]), 1, 0)\n#df_train_inputs['NumberOfDependents:0'] = np.where(df_train_inputs['NumberOfDependents'].isin([0]), 1, 0)","cc0b0450":"df_test_inputs['NumberOfDependents:>9'] = np.where(df_test_inputs['NumberOfDependents'].isin([9,10,13,20]), 1, 0)\ndf_test_inputs['NumberOfDependents:6'] = np.where(df_test_inputs['NumberOfDependents'].isin([6]), 1, 0)\ndf_test_inputs['NumberOfDependents:4'] = np.where(df_test_inputs['NumberOfDependents'].isin([4]), 1, 0)\ndf_test_inputs['NumberOfDependents:1'] = np.where(df_test_inputs['NumberOfDependents'].isin([1]), 1, 0)\ndf_test_inputs['NumberOfDependents:2'] = np.where(df_test_inputs['NumberOfDependents'].isin([2]), 1, 0)\ndf_test_inputs['NumberOfDependents:7'] = np.where(df_test_inputs['NumberOfDependents'].isin([7]), 1, 0)\ndf_test_inputs['NumberOfDependents:5'] = np.where(df_test_inputs['NumberOfDependents'].isin([5]), 1, 0)\ndf_test_inputs['NumberOfDependents:3'] = np.where(df_test_inputs['NumberOfDependents'].isin([3]), 1, 0)\ndf_test_inputs['NumberOfDependents:8'] = np.where(df_test_inputs['NumberOfDependents'].isin([8]), 1, 0)\n#df_train_inputs['NumberOfDependents:0'] = np.where(df_train_inputs['NumberOfDependents'].isin([0]), 1, 0)","dc1ef3e7":"fig, axes = plt.subplots(2, 2, figsize=(18,6))\nsns.histplot(x = df_train[df_train['MonthlyIncome'] < 1000]['MonthlyIncome'], ax = axes[0,0])\nsns.histplot(x = df_train[(df_train['MonthlyIncome'] > 1000) & \n                         (df_train['MonthlyIncome'] <= 10000)]['MonthlyIncome'], ax = axes[0,1])\nsns.histplot(x = df_train[(df_train['MonthlyIncome'] > 10000) & \n                         (df_train['MonthlyIncome'] <= 20000)]['MonthlyIncome'], ax = axes[1,0])\nsns.histplot(x = df_train[(df_train['MonthlyIncome'] > 20000) & \n                         (df_train['MonthlyIncome'] <= 50000)]['MonthlyIncome'], ax = axes[1,1])","80bcdf0b":"bins = pd.IntervalIndex.from_tuples([(0, 1000)])\nbins3 = pd.IntervalIndex.from_tuples([(10000, 12000), (12000, 14000), (14000, 16000), (16000, 20000)])\nbins4 = pd.IntervalIndex.from_tuples([(20000, 30000), (30000, 50000)])\nbox1 = pd.cut(df_train[df_train['MonthlyIncome'] <= 1000]['MonthlyIncome'], bins)\nbox2 = pd.qcut(df_train[(df_train['MonthlyIncome'] > 1000) & \n                         (df_train['MonthlyIncome'] <= 10000)]['MonthlyIncome'], 4)\nbox3 = pd.cut(df_train[(df_train['MonthlyIncome'] > 10000) & \n                         (df_train['MonthlyIncome'] <= 20000)]['MonthlyIncome'], bins3)\nbox4 = pd.cut(df_train[(df_train['MonthlyIncome'] > 20000) & \n                         (df_train['MonthlyIncome'] <= 50000)]['MonthlyIncome'], bins4)","2e3e3681":"fig, axes = plt.subplots(2, 2, figsize=(18,6))\nsns.histplot(x = df_train[(df_train['MonthlyIncome'] > 50000) & \n                         (df_train['MonthlyIncome'] <= 100000)]['MonthlyIncome'], ax = axes[0,0])\nsns.histplot(x = df_train[(df_train['MonthlyIncome'] > 100000) & \n                         (df_train['MonthlyIncome'] <= 200000)]['MonthlyIncome'], ax = axes[0,1])\nsns.histplot(x = df_train[(df_train['MonthlyIncome'] > 200000) & \n                         (df_train['MonthlyIncome'] <= 500000)]['MonthlyIncome'], ax = axes[1,0])\nsns.histplot(x = df_train[df_train['MonthlyIncome'] > 500000]['MonthlyIncome'], ax = axes[1,1])","df1c91e7":"bins5 = pd.IntervalIndex.from_tuples([(50000, 70000), (70000,100000), (100000, 140000), (140000, 200000), (200000, 500000),\n                                     (500000, 3500000)])\nbox5 = pd.cut(df_train[df_train['MonthlyIncome'] > 50000]['MonthlyIncome'], bins5)","b9ae1827":"df_train_inputs['MonthlyIncome_x'] = df_train_inputs['MonthlyIncome'].values","8ae09e49":"df_train_inputs.loc[box1.index.values, 'MonthlyIncome_x'] = box1.values\ndf_train_inputs.loc[box2.index.values, 'MonthlyIncome_x'] = box2.values\ndf_train_inputs.loc[box3.index.values, 'MonthlyIncome_x'] = box3.values\ndf_train_inputs.loc[box4.index.values, 'MonthlyIncome_x'] = box4.values\ndf_train_inputs.loc[box5.index.values, 'MonthlyIncome_x'] = box5.values","4e508112":"df_temp = woe_continuous(df_train_inputs, 'MonthlyIncome_x', df_train_target)\ndf_temp","7d5f59ab":"df_train_inputs['MonthlyIncome:0-200'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(0, 200)), 1, 0)\ndf_train_inputs['MonthlyIncome:200-1000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(200, 1000)), 1, 0)\ndf_train_inputs['MonthlyIncome:1000-3500'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(1000, 3500)), 1, 0)\ndf_train_inputs['MonthlyIncome:3500-5000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(3500, 5000)), 1, 0)\n#df_train_inputs['MonthlyIncome:5000-6850'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(5000, 6850)), 1, 0)\ndf_train_inputs['MonthlyIncome:6850-10000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(6850, 10000)), 1, 0)\ndf_train_inputs['MonthlyIncome:10000-12000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(10000, 12000)), 1, 0)\ndf_train_inputs['MonthlyIncome:12000-16000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(12000, 16000)), 1, 0)\ndf_train_inputs['MonthlyIncome:16000-30000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(16000, 30000)), 1, 0)\ndf_train_inputs['MonthlyIncome:30000-70000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(30000, 70000)), 1, 0)\ndf_train_inputs['MonthlyIncome:70000-100000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(70000, 100000)), 1, 0)\ndf_train_inputs['MonthlyIncome:100000-140000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(100000, 140000)), 1, 0)\ndf_train_inputs['MonthlyIncome:140000-500000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(140000, 500000)), 1, 0)\ndf_train_inputs['MonthlyIncome:>500000'] = np.where(df_train_inputs['MonthlyIncome'].isin(range(500000, int(df_train_inputs['MonthlyIncome'].max()))), 1, 0)","bb8c6d29":"df_test_inputs['MonthlyIncome:0-200'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(0, 200)), 1, 0)\ndf_test_inputs['MonthlyIncome:200-1000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(200, 1000)), 1, 0)\ndf_test_inputs['MonthlyIncome:1000-3500'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(1000, 3500)), 1, 0)\ndf_test_inputs['MonthlyIncome:3500-5000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(3500, 5000)), 1, 0)\n#df_test_inputs['MonthlyIncome:5000-6850'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(5000, 6850)), 1, 0)\ndf_test_inputs['MonthlyIncome:6850-10000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(6850, 10000)), 1, 0)\ndf_test_inputs['MonthlyIncome:10000-12000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(10000, 12000)), 1, 0)\ndf_test_inputs['MonthlyIncome:12000-16000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(12000, 16000)), 1, 0)\ndf_test_inputs['MonthlyIncome:16000-30000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(16000, 30000)), 1, 0)\ndf_test_inputs['MonthlyIncome:30000-70000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(30000, 70000)), 1, 0)\ndf_test_inputs['MonthlyIncome:70000-100000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(70000, 100000)), 1, 0)\ndf_test_inputs['MonthlyIncome:100000-140000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(100000, 140000)), 1, 0)\ndf_test_inputs['MonthlyIncome:140000-500000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(140000, 500000)), 1, 0)\ndf_test_inputs['MonthlyIncome:>500000'] = np.where(df_test_inputs['MonthlyIncome'].isin(range(500000, int(df_test_inputs['MonthlyIncome'].max()))), 1, 0)","9788f3df":"#Train_Dataset Boxplot\nfig, axes = plt.subplots(2, 2, figsize=(18,6))\nsns.histplot(x = df_train[df_train['DebtRatio'] < 1]['DebtRatio'],\n            ax = axes[0,0])\nsns.histplot(x = df_train[(df_train['DebtRatio'] > 1) & \n                        (df_train['DebtRatio'] <= 10)]['DebtRatio'],\n            ax = axes[0,1])\nsns.histplot(x = df_train[(df_train['DebtRatio'] > 10) & \n                        (df_train['DebtRatio'] <= 100)]['DebtRatio'],\n            ax = axes[1,0])\nsns.histplot(x = df_train[(df_train['DebtRatio'] > 100) & \n                        (df_train['DebtRatio'] <= 1000)]['DebtRatio'],\n            ax = axes[1,1])","ba3643d9":"sns.histplot(x = df_train[(df_train['DebtRatio'] > 1000) & \n                        (df_train['DebtRatio'] <= 10000)]['DebtRatio'])","9d4df52a":"bins = pd.IntervalIndex.from_tuples([(1, 10), (10, 100), (100, 1000), (1000, int(df_train_inputs['DebtRatio'].max()))])\nbox1 = pd.qcut(df_train[df_train['DebtRatio'] <= 1]['DebtRatio'], 10)\nbox2 = pd.cut(df_train[df_train['DebtRatio'] > 1]['DebtRatio'], bins)","713280d4":"df_train_inputs['DebtRatio_x'] = df_train_inputs['DebtRatio'].values","8b664c04":"df_train_inputs.loc[box1.index.values, 'DebtRatio_x'] = box1.values\ndf_train_inputs.loc[box2.index.values, 'DebtRatio_x'] = box2.values","2bde33d6":"df_temp = woe_continuous(df_train_inputs, 'DebtRatio_x', df_train_target)\ndf_temp","d36ecbe5":"plot_by_woe(df_temp, 90)","2441a38a":"df_train_inputs['DebtRatio:<0.0129'] = np.where(round(df_train_inputs['DebtRatio'], 3).isin(np.arange(0.0, 0.0129, 0.001)), 1, 0)\n#df_train_inputs['DebtRatio:<0.159'] = np.where(round(df_train_inputs['DebtRatio'], 4).isin(np.arange(0.0129, 0.159, 0.001)), 1, 0)\ndf_train_inputs['DebtRatio:<0.218'] = np.where(round(df_train_inputs['DebtRatio'], 3).isin(np.arange(0.159, 0.218, 0.001)), 1, 0)\ndf_train_inputs['DebtRatio:<0.333'] = np.where(round(df_train_inputs['DebtRatio'], 3).isin(np.arange(0.218, 0.333, 0.001)), 1, 0)\ndf_train_inputs['DebtRatio:<0.483'] = np.where(round(df_train_inputs['DebtRatio'], 3).isin(np.arange(0.333, 0.483, 0.001)), 1, 0)\ndf_train_inputs['DebtRatio:<0.621'] = np.where(round(df_train_inputs['DebtRatio'], 3).isin(np.arange(0.483, 0.621, 0.001)), 1, 0)\ndf_train_inputs['DebtRatio:<1'] = np.where(round(df_train_inputs['DebtRatio'], 3).isin(np.arange(0.621, 1, 0.001)), 1, 0)\ndf_train_inputs['DebtRatio:<10'] = np.where(round(df_train_inputs['DebtRatio'], 0).isin(range(1, 10)), 1, 0)\ndf_train_inputs['DebtRatio:<100'] = np.where(round(df_train_inputs['DebtRatio'], 0).isin(range(10, 100)), 1, 0)\ndf_train_inputs['DebtRatio:<1000'] = np.where(round(df_train_inputs['DebtRatio'], 0).isin(range(100, 1000)), 1, 0)\ndf_train_inputs['DebtRatio:>1000'] = np.where((df_train_inputs['DebtRatio'] > 1000), 1, 0)","5bfbe67a":"df_test_inputs['DebtRatio:<0.0129'] = np.where(round(df_test_inputs['DebtRatio'], 3).isin(np.arange(0.0, 0.0129, 0.001)), 1, 0)\n#df_test_inputs['DebtRatio:<0.159'] = np.where(round(df_test_inputs['DebtRatio'], 4).isin(np.arange(0.0129, 0.159, 0.001)), 1, 0)\ndf_test_inputs['DebtRatio:<0.218'] = np.where(round(df_test_inputs['DebtRatio'], 3).isin(np.arange(0.159, 0.218, 0.001)), 1, 0)\ndf_test_inputs['DebtRatio:<0.333'] = np.where(round(df_test_inputs['DebtRatio'], 3).isin(np.arange(0.218, 0.333, 0.001)), 1, 0)\ndf_test_inputs['DebtRatio:<0.483'] = np.where(round(df_test_inputs['DebtRatio'], 3).isin(np.arange(0.333, 0.483, 0.001)), 1, 0)\ndf_test_inputs['DebtRatio:<0.621'] = np.where(round(df_test_inputs['DebtRatio'], 3).isin(np.arange(0.483, 0.621, 0.001)), 1, 0)\ndf_test_inputs['DebtRatio:<1'] = np.where(round(df_test_inputs['DebtRatio'], 3).isin(np.arange(0.621, 1, 0.001)), 1, 0)\ndf_test_inputs['DebtRatio:<10'] = np.where(round(df_test_inputs['DebtRatio'], 0).isin(range(1, 10)), 1, 0)\ndf_test_inputs['DebtRatio:<100'] = np.where(round(df_test_inputs['DebtRatio'], 0).isin(range(10, 100)), 1, 0)\ndf_test_inputs['DebtRatio:<1000'] = np.where(round(df_test_inputs['DebtRatio'], 0).isin(range(100, 1000)), 1, 0)\ndf_test_inputs['DebtRatio:>1000'] = np.where((df_test_inputs['DebtRatio'] > 1000), 1, 0)","922ca108":"#Train_Dataset Boxplot\nfig, axes = plt.subplots(1, 2, figsize=(18,6))\nsns.histplot(x = df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] < 1]['RevolvingUtilizationOfUnsecuredLines'],\n            ax = axes[0])\nsns.histplot(x = df_train[(df_train['RevolvingUtilizationOfUnsecuredLines'] > 1) & \n                        (df_train['RevolvingUtilizationOfUnsecuredLines'] <= 10)]['RevolvingUtilizationOfUnsecuredLines'],\n            ax = axes[1])","19286f06":"#bins = pd.IntervalIndex.from_tuples([(1, 10), (10, 100), (100, 1000), (1000, int(df_train_inputs['RevolvingUtilizationOfUnsecuredLines'].max()))])\nbox1 = pd.cut(df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] <= 1]['RevolvingUtilizationOfUnsecuredLines'], 50)\nbox2 = pd.cut(df_train[df_train['RevolvingUtilizationOfUnsecuredLines'] > 1]['RevolvingUtilizationOfUnsecuredLines'], 10)","2bdc6c77":"df_train_inputs['RevolvingUtilizationOfUnsecuredLines_x'] = df_train_inputs['RevolvingUtilizationOfUnsecuredLines'].values","a68d5640":"df_train_inputs.loc[box1.index.values, 'RevolvingUtilizationOfUnsecuredLines_x'] = box1.values\ndf_train_inputs.loc[box2.index.values, 'RevolvingUtilizationOfUnsecuredLines_x'] = box2.values","9c20c234":"df_temp = woe_continuous(df_train_inputs, 'RevolvingUtilizationOfUnsecuredLines_x', df_train_target)\ndf_temp","a59dfec2":"plot_by_woe(df_temp, 90)","3cf4189b":"df_train_inputs['RevolvingUtilizationOfUnsecuredLines:<0.0004'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] < 0.0004), 1, 0)\n#df_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.0004-0.05_REF'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] >= 0.0004) & (train['RevolvingUtilizationOfUnsecuredLines'] < 0.05) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.05-0.1'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.05) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.1) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.1-0.2'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.1) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.2) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.2-0.3'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.2) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.3) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.3-0.4'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.3) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.4) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.4-0.6'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.4) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.6) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.6-0.8'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.6) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.8) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.8-1.0'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.8) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 1.0) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:1-10'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 1) & (df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 10) , 1, 0)\ndf_train_inputs['RevolvingUtilizationOfUnsecuredLines:>10'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] > 10) , 1, 0)","29d53dff":"df_test_inputs['RevolvingUtilizationOfUnsecuredLines:<0.0004'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] < 0.0004), 1, 0)\n#df_train_inputs['RevolvingUtilizationOfUnsecuredLines:0.0004-0.05_REF'] = np.where((df_train_inputs['RevolvingUtilizationOfUnsecuredLines'] >= 0.0004) & (train['RevolvingUtilizationOfUnsecuredLines'] < 0.05) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:0.05-0.1'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.05) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] < 0.1) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:0.1-0.2'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.1) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.2) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:0.2-0.3'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.2) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.3) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:0.3-0.4'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.3) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.4) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:0.4-0.6'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.4) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.6) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:0.6-0.8'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.6) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 0.8) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:0.8-1.0'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 0.8) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 1.0) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:1-10'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 1) & (df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] <= 10) , 1, 0)\ndf_test_inputs['RevolvingUtilizationOfUnsecuredLines:>10'] = np.where((df_test_inputs['RevolvingUtilizationOfUnsecuredLines'] > 10) , 1, 0)","d1ef2aac":"df_temp = woe_continuous(df_train_inputs, 'NumberOfOpenCreditLinesAndLoans', df_train_target)\ndf_temp","b7df75f7":"plot_by_woe(df_temp)","fc5259eb":"df_train_inputs['NumberOfOpenCreditLinesAndLoans:0'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin([0]), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:1'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin([1]), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:2'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin([2]), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:3'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin([3]), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:4-6'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(4, 6)), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:6-8'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(6, 8)), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:9-13'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(9, 13)), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:13'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin([13]), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:14-18'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(14, 18)), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:19'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin([19]), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:20-24'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(20, 24)), 1, 0)\ndf_train_inputs['NumberOfOpenCreditLinesAndLoans:24-26'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(24, 27)), 1, 0)\n#df_train_inputs['NumberOfOpenCreditLinesAndLoans:>26_REF'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(27, int(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].max()))), 1, 0)","93a2056a":"df_test_inputs['NumberOfOpenCreditLinesAndLoans:0'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin([0]), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:1'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin([1]), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:2'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin([2]), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:3'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin([3]), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:4-6'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(4, 6)), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:6-8'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(6, 8)), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:9-13'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(9, 13)), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:13'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin([13]), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:14-18'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(14, 18)), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:19'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin([19]), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:20-24'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(20, 24)), 1, 0)\ndf_test_inputs['NumberOfOpenCreditLinesAndLoans:24-26'] = np.where(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(24, 27)), 1, 0)\n#df_train_inputs['NumberOfOpenCreditLinesAndLoans:>26_REF'] = np.where(df_train_inputs['NumberOfOpenCreditLinesAndLoans'].isin(range(27, int(df_test_inputs['NumberOfOpenCreditLinesAndLoans'].max()))), 1, 0)","dc5046b3":"df_temp = woe_continuous(df_train_inputs, 'NumberRealEstateLoansOrLines', df_train_target)\ndf_temp","39c18d40":"plot_by_woe(df_temp)","98e555d1":"df_train_inputs['NumberRealEstateLoansOrLines:0'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([0]), 1, 0)\ndf_train_inputs['NumberRealEstateLoansOrLines:1'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([1]), 1, 0)\ndf_train_inputs['NumberRealEstateLoansOrLines:2'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([2]), 1, 0)\ndf_train_inputs['NumberRealEstateLoansOrLines:3'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([3]), 1, 0)\ndf_train_inputs['NumberRealEstateLoansOrLines:4'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([4]), 1, 0)\ndf_train_inputs['NumberRealEstateLoansOrLines:5'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([5]), 1, 0)\ndf_train_inputs['NumberRealEstateLoansOrLines:6'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([6]), 1, 0)\ndf_train_inputs['NumberRealEstateLoansOrLines:7'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin([7]), 1, 0)\n#df_train_inputs['NumberRealEstateLoansOrLines:>7_REF'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin(range(8, int(df_train_inputs['NumberRealEstateLoansOrLines'].max()))), 1, 0)","b4fa0fea":"df_test_inputs['NumberRealEstateLoansOrLines:0'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([0]), 1, 0)\ndf_test_inputs['NumberRealEstateLoansOrLines:1'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([1]), 1, 0)\ndf_test_inputs['NumberRealEstateLoansOrLines:2'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([2]), 1, 0)\ndf_test_inputs['NumberRealEstateLoansOrLines:3'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([3]), 1, 0)\ndf_test_inputs['NumberRealEstateLoansOrLines:4'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([4]), 1, 0)\ndf_test_inputs['NumberRealEstateLoansOrLines:5'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([5]), 1, 0)\ndf_test_inputs['NumberRealEstateLoansOrLines:6'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([6]), 1, 0)\ndf_test_inputs['NumberRealEstateLoansOrLines:7'] = np.where(df_test_inputs['NumberRealEstateLoansOrLines'].isin([7]), 1, 0)\n#df_train_inputs['NumberRealEstateLoansOrLines:>7_REF'] = np.where(df_train_inputs['NumberRealEstateLoansOrLines'].isin(range(8, int(df_test_inputs['NumberRealEstateLoansOrLines'].max()))), 1, 0)","e354aa61":"#fine classing age feature into 30 categories\nbins=np.linspace(df_train_inputs['age'].min(), df_train_inputs['age'].max()+1, 30)\ndf_train_inputs['age_x'] = pd.cut(df_train_inputs['age'], bins=bins, include_lowest=True, precision=0)","c049e28d":"df_temp = woe_continuous(df_train_inputs, 'age_x', df_train_target)\ndf_temp","a8b76054":"plot_by_woe(df_temp, 90)","99883931":"df_train_inputs['age:<24'] = np.where(df_train_inputs['age'].isin(range(24)), 1, 0)\ndf_train_inputs['age:24-33'] = np.where(df_train_inputs['age'].isin(range(24, 33)), 1, 0)\ndf_train_inputs['age:33-36'] = np.where(df_train_inputs['age'].isin(range(33, 36)), 1, 0)\ndf_train_inputs['age:36-42'] = np.where(df_train_inputs['age'].isin(range(36, 42)), 1, 0)\ndf_train_inputs['age:42-55'] = np.where(df_train_inputs['age'].isin(range(42, 55)), 1, 0)\ndf_train_inputs['age:55-58'] = np.where(df_train_inputs['age'].isin(range(55, 58)), 1, 0)\ndf_train_inputs['age:58-64'] = np.where(df_train_inputs['age'].isin(range(58, 64)), 1, 0)\ndf_train_inputs['age:64-67'] = np.where(df_train_inputs['age'].isin(range(64, 67)), 1, 0)\ndf_train_inputs['age:67-70'] = np.where(df_train_inputs['age'].isin(range(67, 70)), 1, 0)\ndf_train_inputs['age:70-73'] = np.where(df_train_inputs['age'].isin(range(70, 73)), 1, 0)\ndf_train_inputs['age:73-89'] = np.where(df_train_inputs['age'].isin(range(73, 89)), 1, 0)\n#df_train_inputs['age:>89_REF'] = np.where(df_test_inputs['age'].isin(range(89, int(df_train_inputs['age'].max()))), 1, 0)","5c753315":"df_test_inputs['age:<24'] = np.where(df_test_inputs['age'].isin(range(24)), 1, 0)\ndf_test_inputs['age:24-33'] = np.where(df_test_inputs['age'].isin(range(24, 33)), 1, 0)\ndf_test_inputs['age:33-36'] = np.where(df_test_inputs['age'].isin(range(33, 36)), 1, 0)\ndf_test_inputs['age:36-42'] = np.where(df_test_inputs['age'].isin(range(36, 42)), 1, 0)\ndf_test_inputs['age:42-55'] = np.where(df_test_inputs['age'].isin(range(42, 55)), 1, 0)\ndf_test_inputs['age:55-58'] = np.where(df_test_inputs['age'].isin(range(55, 58)), 1, 0)\ndf_test_inputs['age:58-64'] = np.where(df_test_inputs['age'].isin(range(58, 64)), 1, 0)\ndf_test_inputs['age:64-67'] = np.where(df_test_inputs['age'].isin(range(64, 67)), 1, 0)\ndf_test_inputs['age:67-70'] = np.where(df_test_inputs['age'].isin(range(67, 70)), 1, 0)\ndf_test_inputs['age:70-73'] = np.where(df_test_inputs['age'].isin(range(70, 73)), 1, 0)\ndf_test_inputs['age:73-89'] = np.where(df_test_inputs['age'].isin(range(73, 89)), 1, 0)\n#df_test_inputs['age:>89_REF'] = np.where(df_test_inputs['age'].isin(range(89, int(df_test_inputs['age'].max()))), 1, 0)","76fa9987":"#original feature categories in a list\noriginal_features = ['RevolvingUtilizationOfUnsecuredLines', 'age', \n                     'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', \n                     'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', \n                     'NumberOfTimes90DaysLate','NumberRealEstateLoansOrLines',\n                     'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']","987b4b0d":"woe_train_inputs = df_train_inputs.copy()\nwoe_test_inputs = df_test_inputs.copy()","3d2f05e5":"for col in df_train_inputs:\n    if col not in original_features:\n        df_train_inputs.drop(col, axis = 1, inplace = True)","501124ca":"for col in df_test_inputs:\n    if col not in original_features:\n        df_test_inputs.drop(col, axis = 1, inplace = True)","db240a33":"fine_class = ['MonthlyIncome_x', 'DebtRatio_x', 'RevolvingUtilizationOfUnsecuredLines_x', 'age_x']\nother_ref_columns = ['MonthlyIncome:5000-6850', 'DebtRatio:<0.159', 'PastDue30-59:0', 'PastDue60-89:0',\n                    'PastDue90:0', 'NumberOfDependents:0', 'RevolvingUtilizationOfUnsecuredLines:0.0004-0.05_REF',\n                    'NumberOfOpenCreditLinesAndLoans:>26_REF', 'NumberRealEstateLoansOrLines:>7_REF', 'age:>89_REF']\nto_drop = original_features + fine_class + other_ref_columns","435f1fdf":"for col in to_drop:\n    if col in woe_train_inputs.columns.values:\n        woe_train_inputs.drop(col, axis = 1, inplace = True)","58f1bfbc":"for col in to_drop:\n    if col in woe_test_inputs.columns.values:\n        woe_test_inputs.drop(col, axis = 1, inplace = True)","d7b0a262":"#stratified split\nX_train, X_valid, y_train, y_valid = train_test_split(woe_train_inputs.values, df_train_target.values,\n                                                      test_size = 0.2, random_state = 42, stratify = df_train_target.values)","c08df0ba":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_valid.shape)\nprint(y_valid.shape)","c5a56c52":"lr_woe = LogisticRegression(max_iter=300, solver = 'liblinear')","800fabd8":"#fit logistic regression\nlr_woe.fit(X_train, y_train.ravel())","7401ef37":"#predictions 1 or 0\ny_pred = lr_woe.predict(X_valid)","320c8a61":"#predictions in probalities\ny_pred_proba = lr_woe.predict_proba(X_valid)\ny_pred_proba = y_pred_proba[: , 1]","fc7d6160":"#confusion matrix\ncm = metrics.confusion_matrix(y_valid, y_pred)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt=\".2f\", linewidths=.5, square =True, cmap = 'Blues_r');\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nall_sample_title = 'Confusion Matrix'\nplt.title(all_sample_title, size = 15)\nplt.show()","99565345":"#classification report: recall, precision, f1-score, accuracy\nprint(classification_report(y_valid, y_pred))","2c65a7e1":"#ROC_curve\nplot_roc(y_valid, y_pred_proba)","046876f9":"#AUC score\nroc_auc_score(y_valid, y_pred_proba)","f4488e93":"#logistic regrssion with p-values function\nfrom sklearn import linear_model\nimport scipy.stats as stat\n\nclass LogisticRegression_with_p_values:\n    \n    def __init__(self,*args,**kwargs):\n        self.model = linear_model.LogisticRegression(*args,**kwargs, max_iter=300)\n\n    def fit(self,X,y):\n        self.model.fit(X,y)\n        denom = (2.0 * (1.0 + np.cosh(self.model.decision_function(X))))\n        denom = np.tile(denom,(X.shape[1],1)).T\n        F_ij = np.dot((X \/ denom).T,X)\n        Cramer_Rao = np.linalg.inv(F_ij)\n        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n        z_scores = self.model.coef_[0] \/ sigma_estimates\n        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores]\n        self.coef_ = self.model.coef_\n        self.intercept_ = self.model.intercept_\n        self.p_values = p_values","50a5696e":"#logistic regression object\nlr_p = LogisticRegression_with_p_values()","35003d25":"lr_p.fit(X_train, y_train.ravel())","27dd81ae":"#creating a dataframe with feature name, p_values and logistic regression coefficient\nsummary_table = pd.DataFrame(columns = ['Feature name'], data = woe_train_inputs.columns.values)\nsummary_table['Coefficients'] = np.transpose(lr_p.coef_)\nsummary_table.index = summary_table.index + 1\nsummary_table.loc[0] = ['Intercept', lr_p.intercept_[0]]\nsummary_table = summary_table.sort_index()\np_values = lr_p.p_values\np_values = np.append(np.nan, np.array(p_values))\nsummary_table['p_values'] = p_values","d5c8947f":"#pd.options.display.max_rows = None\nsummary_table.head(5)","006363f1":"summary_table[summary_table['p_values'] > 0.05]","c0a9634f":"dummy_drop = list(woe_train_inputs.filter(regex='Depend').columns) + list(woe_train_inputs.filter(regex='age').columns) ","29d4601b":"woe_train_inputs_copy = woe_train_inputs.copy()\nwoe_test_inputs_copy = woe_test_inputs.copy()","95eae2af":"woe_train_inputs_copy.drop(dummy_drop, axis = 1, inplace = True)","eeb7dd31":"woe_test_inputs_copy.drop(dummy_drop, axis = 1, inplace = True)","5fd4f026":"X_train, X_valid, y_train, y_valid = train_test_split(woe_train_inputs_copy.values, df_train_target.values,\n                                                      test_size = 0.2, random_state = 42, stratify = df_train_target.values)","e25246da":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_valid.shape)\nprint(y_valid.shape)","6b5b5137":"lr_woe = LogisticRegression(max_iter=300, solver = 'liblinear')","339878ce":"#fit logistic regression\nlr_woe.fit(X_train, y_train.ravel())","50c8e3c2":"#predictions 1 or 0\ny_pred = lr_woe.predict(X_valid)","4c22cf55":"#predictions in probalities\ny_pred_proba = lr_woe.predict_proba(X_valid)\ny_pred_proba = y_pred_proba[: , 1]","5d4f0f91":"#confusion matrix\ncm = metrics.confusion_matrix(y_valid, y_pred)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt=\".2f\", linewidths=.5, square =True, cmap = 'Blues_r');\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nall_sample_title = 'Confusion Matrix'\nplt.title(all_sample_title, size = 15)\nplt.show()","2840082d":"#classification report: recall, precision, f1-score, accuracy\nprint(classification_report(y_valid, y_pred))","724ba5c4":"#ROC_curve\nplot_roc(y_valid, y_pred_proba)","b36567a0":"#AUC score\nroc_auc_score(y_valid, y_pred_proba)","6df5b36d":"def rf_func(target, *data):\n    precision = []\n    recall = []\n    f1_score_ = []\n    auc_ = []\n    for df in data:\n        X_train, X_valid, y_train, y_valid = train_test_split(df.values, target.values,\n                                                      test_size = 0.2, random_state = 42, stratify = target.values)\n        \n        rf = RandomForestClassifier(n_estimators=500)\n        rf.fit(X_train, y_train.ravel())\n        rf_pred = rf.predict(X_valid)\n        rf_pred_proba = rf.predict_proba(X_valid)\n        rf_pred_proba = rf_pred_proba[: , 1]\n        precision.append(round(precision_score(y_valid, rf_pred, average=None)[1], 2))\n        recall.append(round(recall_score(y_valid, rf_pred, average=None)[1], 2))\n        f1_score_.append(round(f1_score(y_valid, rf_pred, average=None)[1], 2))\n        auc_.append(round(roc_auc_score(y_valid, rf_pred_proba), 3))\n    return pd.DataFrame([precision, recall, f1_score_, auc_], index = ['Precision', 'recall',\n                                                                      'f1_score', 'auc'],\n                       columns = ['Original Features', 'WOE_Features', 'WOE_Features_Trimmed'])","520d5662":"df_ = rf_func(df_train_target, df_train_inputs, woe_train_inputs, woe_train_inputs_copy)\ndf_.T","76511faa":"#import libraries\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV , StratifiedShuffleSplit","9b264828":"\n#Construct some pipelines\n\npipe_lr = Pipeline([('clf', LogisticRegression(random_state=42, max_iter=300))])\n\npipe_rf = Pipeline([('clf', RandomForestClassifier(max_features = 'auto', random_state=0, n_estimators=500, n_jobs=-1))])\n\n#Set grid search params\n\ngrid_params_lr = [{'clf__penalty': ['l1','l2'],\n            'clf__C': [0.1, 0.2, 1, 2],\n            'clf__solver': ['liblinear','lbfgs']}] \n\ngrid_params_rf = [{'clf__min_samples_leaf': [2,5],\n                'clf__max_depth': [5,10],\n                'clf__min_samples_split': [3,5]}]\n\n#Construct grid searches\n\ngs_lr = GridSearchCV(estimator=pipe_lr,\n            param_grid=grid_params_lr,\n            scoring='roc_auc',\n            cv = StratifiedShuffleSplit(n_splits=3,test_size=0.2,random_state = 0), \n            n_jobs=-1)\n\ngs_rf = GridSearchCV(estimator=pipe_rf,\n            param_grid=grid_params_rf,\n            scoring='roc_auc',\n            cv = StratifiedShuffleSplit(n_splits=3,test_size=0.2,random_state = 0),\n            n_jobs=-1)\n\n\n#List of pipelines for ease of iteration\ngrids = [gs_lr, gs_rf]\n\n#Dictionary of pipelines and classifier types for ease of reference\ngrid_dict = {0: 'Logistic Regression', 1: 'Random Forest'}\n\n\n#Fit the grid search objects\nprint('Performing model optimizations...')\n\nfor idx, gs in enumerate(grids):\n    print('\\nEstimator: %s' % grid_dict[idx])\n    # Fit grid search\n    if idx == 0:\n        gs.fit(woe_train_inputs.values, df_train_target)\n        # Best params\n        print('Best params: %s' % gs.best_params_)\n        # Best Score\n        print('Best AUC score: %.4f' % gs.best_score_)\n    else:\n        gs.fit(df_train_inputs.values, df_train_target)\n        # Best params\n        print('Best params: %s' % gs.best_params_)\n        # Best Score\n        print('Best AUC score: %.4f' % gs.best_score_)","54124e5a":"#import libraries\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","742a2a75":"#loading best parameters\nlr = LogisticRegression(C=0.1, max_iter=300, solver='liblinear', penalty='l2')\nrf = RandomForestClassifier(n_estimators=500, random_state=10 , min_samples_leaf=5, max_depth=10,\n                            min_samples_split=3, n_jobs=-1)","b854ecb7":"#stratified kfold\nscoring = 'roc_auc'\nmodels = []\nmodels.append(('LR', lr))\nmodels.append(('RFG', rf))\nnames = []\nresults = []\nfor name, model in models:\n    kfold = StratifiedKFold(n_splits=3, shuffle=True , random_state = 47)\n    if name == 'LR':\n        cv_results = cross_val_score(model, woe_train_inputs.values, df_train_target.values, cv=kfold, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n    else:\n        cv_results = cross_val_score(model, df_train_inputs.values, df_train_target.values, cv=kfold, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)","f983ef00":"# Compare Algorithms\nfig = plt.figure(figsize=(10,8))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","6f2ecdaa":"def trade_off(clf, train_input, target):\n    X_train, X_valid, y_train, y_valid = train_test_split(train_input.values, target.values.ravel(),\n                                                     test_size = 0.2, random_state = 42,\n                                                      stratify = target.values.ravel())\n    clf.fit(X_train, y_train)\n    clf_pred = clf.predict(X_valid)\n    clf_pred_proba = clf.predict_proba(X_valid)\n    clf_pred_proba = clf_pred_proba[:, 1]\n    predictions = pd.concat([pd.DataFrame(clf_pred_proba), pd.DataFrame(clf_pred)],  axis = 1)\n    predictions.columns = ['probability', 'class']\n    precision_recall_df = pd.DataFrame({'precision':[0,0,0,0], 'recall':[0,0,0,0], 'f1_score':[0,0,0,0],\n                                   'auc_score':[0,0,0,0]}, index = ['threshold:0.3', 'threshold:0.4',\n                                                                   'threshold:0.5', 'threshold:0.6'])\n    for threshold, idx in zip([0.3, 0.4, 0.5, 0.6], precision_recall_df.index.values):\n        predictions['class_temp'] = np.where(predictions['probability'] > threshold, 1, 0)\n        precision_recall_df.loc[idx, 'precision'] = round(precision_score(y_valid, predictions['class_temp'],\n                                                                      average=None)[1], 2)\n        precision_recall_df.loc[idx, 'recall'] = round(recall_score(y_valid, predictions['class_temp'],\n                                                                average=None)[1], 2)\n        precision_recall_df.loc[idx, 'f1_score'] = round(f1_score(y_valid, predictions['class_temp'],\n                                                              average=None)[1], 2)\n        precision_recall_df.loc[idx, 'auc_score'] = round(roc_auc_score(y_valid, predictions['probability']), 3)\n    return precision_recall_df\n    ","d71c09e1":"trade_off(rf, df_train_inputs, df_train_target)","9eba2321":"trade_off(lr, woe_train_inputs, df_train_target)","e7a8f5d4":"lr.fit(woe_train_inputs.values, df_train_target.values.ravel())\nlr_pred = lr.predict(woe_test_inputs.values)\nlr_pred_proba = lr.predict_proba(woe_test_inputs.values)\nlr_pred_proba = lr_pred_proba[:, 1]","d5e1b6a8":"lr_woe_model = pd.DataFrame({'Id': df_test.index.values,\n                                 'Probability': lr_pred_proba})\nlr_woe_model.set_index(keys = 'Id', inplace = True)\nlr_woe_model","db19df1f":"rf.fit(df_train_inputs.values, df_train_target.values.ravel())","811dc34f":"rf_pred = rf.predict(df_test_inputs.values)\nrf_pred_proba = rf.predict_proba(df_test_inputs.values)\nrf_pred_proba = rf_pred_proba[:, 1]","b60f6b49":"rf_model = pd.DataFrame({'Id': df_test.index.values,\n                                 'Probability': rf_pred_proba})\nrf_model.set_index(keys = 'Id', inplace = True)\nrf_model.head(10)","40b02ceb":"importance = lr.coef_[0]\nfeat_importances = pd.DataFrame(importance, index=woe_train_inputs.columns.values, columns=['Score'])\nfeat_importances = feat_importances.sort_values(by='Score',ascending=True)\nfeat_importances.plot(kind='bar', title='Features Importance',legend=False, figsize=(14,8))\n#plt.xlabel('Importance Score')\nplt.ylabel('Coefficient')\nplt.show()","32ebc8e0":"def plot_feature_importance(importance,names,model_type):\n    #Create arrays from feature importance and feature names\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n\n    #Create a DataFrame using a Dictionary\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n\n    #Sort the DataFrame in order decreasing feature importance\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n\n    #Define size of bar plot\n    plt.figure(figsize=(10,8))\n    #Plot Searborn bar chart\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n    #Add chart labels\n    plt.title(model_type + 'FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES')","a2179754":"plot_feature_importance(rf.feature_importances_,df_train_inputs.columns,'RANDOM FOREST')","f98132a7":"rf_model.to_csv('submission.csv')","291d1604":"## CREDIT UTILIZATION RATIO","878595eb":"### Observation\n* WOE has improved both Precison(0.58) and recall(0.20) achieving a good AUC score of 0.862","a70f24cb":"# Handling Missing Number of Dependents\n* Records with missing Number of Dependents occured simultaneously with missing missing MonthlyIncome (i.e they share the same index)\n* This shows that same set of borrowers that left their Monthly Income blank also left Number of Dependents field Blank.\n* Summary stat of Borrowers with missing monthly Income reveals they have no dependents\n* It's quite logical that this category of borrowers with little to no Income have no dependents.\n* Thus, the best way to handle this missing values is to replace with 0 which is also consisent with the Range of this Variable","1cbfc13f":"### NUMBER OF DAYS PAST DUE\n***","7a4a474a":"### Note\nAge tends to have a somewhat reasonable distribution. There are a suspicious number of centenarians but plausible. The only certainly incorrect data is that there is one person in the dataset with age 0, and because infants are not legally permitted to take out loans, we will impute that to the next youngest person in the dataset.","0f5192d3":"# Observations\n- Training dataset have 150,000 records<br>\n- Test dataset have 101,503 records<br>\n- There are 10 Numeric Independent Variables<br>\n- SeriousDlqin2yrs is the Dependent Variable<br>","5bdddda4":"## BASELINE MODELS \n***","2d7aa44d":"### Let's further investige important features","c1cf6c01":"## Note\n- The target class (SeriousDlqin2yrs) is highly imbalanced (14 : 1)\n- Due to the Bias Nature of the Dataset towards a particular class (0), Precision, Recall, F1-score and AUC are the metrics to evaluate our Predictive Models\n- Resampling Techniques such as SMOTE and Tomek Links would be employed to improve our model","8dcb7cc0":"Not much sense can be made of the plots due to high level of skewness. The summary stats shows that the mean is 40 times bigger than the median and there is huge change in values beyond the 99th percentile value. There are notable extreme outliers.","8bfcd2e2":"## Imbalanced Dataset","c8a35251":"## RANDOM FOREST CLASSIFIER\n***","c802adc1":"## GOAL\n***\nTo Predict the probability of a Customer not paying back on a loan in the next two years","98fc38c0":"> There is always a trade-off between model precision and recall, base on the nature of the  business problem. A precision focused model is a cautious model that puts more emphasis on lowering false positives. This type of model is very strict and highly discriminatory to a particular class. It uses a higher threshold (probability) value to assign a data point to a positive class (event). The higher the threshold the higher the precision of a model.<br>\nOn the other hand, a recall based model is more oriented in lowering false negatives. This type of model don't want a positive data point to go unnoticed. A lower threshold value means the model is less strict in discriminating between the two classes and would classify any data point with a inkling of positive attribute to a positive class.<br>\nWhen giving out loans, it is often better to deny a potentially good customer than to approve a high risk borrower. Hence, our model would be recall specific. Although, optimizing our model to be more skillful is generally preferred.<br>\nComparing the scores from both classifiers. Random forest is more skillful with AUC score of 0.868 to Logistic Regression's 0.864. Relative to other thresholds, using a threshold of 0.3 would give the best balance between precision (0.46) and recall (0.40).","6b5792c2":"### FINE CLASSING AND COARSE CLASSING NUMBER OF DAYS PAST DUE 30 - 59","4ae013d7":"### FINE CLASSING AND COARSE CLASSING NUMBER OF DAYS PAST DUE 90","ab8f2392":"## PRECISION, RECALL TRADEOFF\n***","e1c26bfe":"## Note\n- MonthlyIncome and Number of Dependents  have ~20% and ~2.6% missing values respectively on both Training and Test Dataset","8c6eb752":"## METHODS\n***\n### Feature Engineering\n- Weight of Evidence (WOE)\n- P-value for Feature Selection\n### Algorithms\n- Logistic Regression (Baseline Model)\n- Random Forest\n### Evaluation\n- Precision, Recall, F1-score, roc_auc","9c72abb6":"## WEIGHT OF EVIDENCE\n***\n### Background\nThis method is commonly used alongside Logistic Regression for modelling Probability of Default. WOE access the amount of information each attribute (category) of an independent variable has in predicting the class of a target variable. Mathematically, it is the natural log of the ratio of percentage distribution of non-defaulting customers to percentage of defauting customers.\n\n### Steps\n* Fine Classing: All Continuous Variables would be binned into several categories base on its distribution. Any variable with more than 50 unique values is considered to be a continuous Variable. Other Numerical variable with less than 50 unique values would have each element as a separate category\n* Coarse Classing: Categories with similar WOE value would be binned together. Percentage of observation would also influence coarse classing.\n* Dummy variable would be created for each coarse class\n* Each variable would have a reference attribute to avoid dummy variable trap\n\n### Information Value and P-Value\nInformation Value shows the strength of a variable in predicting the target class. It is summation of the product of WOE and the difference between proportion of good customers and bad customers for each Variable category. P-value access the statiscal significance of each variable as a part of total variables in predicting the target class. We are going to use P-value to select statistically significant variables.\n","0533d650":"## Observations\n- Comparing Random Forest classifier across the 3 different datasets shows that it performs best on the Original datasets.\n- This result is equivalent to the one achieved using Logistic Regression on WOE Engineered Features.\n- This confirms the basic principle of Weight of Evidence, it breaks down a variable to classes with similar informative power on the target variable\n- Which is similar to the basic algorithimic principle of Random Forest: collection of decision trees that looks for the most informative data point (test construction) from the best feature to achieve a pure leaf using few hierachical questions as possible.\n- Henceforth, Original Dataset would be used for training RF Classifier while WOE dummy features would be used for training Logistic Regression Model\n- we shall perform hyperparameter tuning to find the best combination of hyperparameters to optimize the performance of both Classifiers.\n- We shall also compare the most important Features from both models.","0da16b8e":"### Note\nApproximately 98% of values of this Variable are between 0 and 1 with a well defined right-skewed distribution. Generally, Credit Utilization is expected to be within this regio (0 - 1). Altough, Borrowers can sometimes spend beyond credit limit. Values between 1 and 10 make up 2% of the dataset. Values beyond 10 are extremely big and they make up less than 0.5% of our data, these values would be dropped to prevent them from impacting our model.","3b96a6e5":"## NUMBER OF DEPENDENTS","b7a50cb5":"# EXPLORATORY DATA ANALYSIS\n***","7db3c108":"### FINE CLASSING AND COARSE CLASSING NUMBER OF DAYS PAST DUE 60 - 89","92c02a49":"## AGE\n***","7d6e0021":"### Note\nThis variable is right skewed. Majority of the Borrowers have between 0 - 3 Dependents. Further preprocessing of this data would be aggregating similar Category (Fine Class) to a Coarse class during WOE Feature Engineering and Data Preprocessing.","c5fa7c22":"## FEATURE ENGINEERING AND DATA PREPROCESSING\n***\n","7fbc1d24":"## NUMBER OF DEPENDENTS\n***","906e9ce0":"### COEFFICIENTS OF LOGISTIC REGRESSION\n* Coefficient of a Feature in a Logistic Regression indicates its predictive strength and the class it favours\n* The further away from zero the higher the predictive power.\n* Coefficients greater than zero is indicative of the event class (target:1) while negative coefficients tends towards the no-event class (target:0). Here, event means default and no-event means non-default\n* Coefficients closer to zero are indifferent to either class\n* The graph of coefficients above is bidirectional\n* Features on the far right are indicative of a defaulting Borrower\n* Revolving Credit Utilization and Number of Days past due are important features in predicting the likelihood of a Borrower defaulting\n* Borrowers with Credit Utilization beyond 0.5 are high risk\n* Borrowers that defaulted on their loan at least twice for 90 days are high risk \n* Borrowers that defaulted on their loan more than 3 times for 60-89 days are high risk\n* Borrowers that defaulted on their loan more than 4 times for 30-59 days should also be considered high risk\n* While Age, Number of Dependents, Monthly Income, Debt Ratio and others apart from the ones above are generally class indifferent, some categories are worth noting.\n* Older customers (>65) are less likely to default.\n* Debt Ratio above 10 are high risk.\n* Borrowers with at least 6 dependents are high risk","c047e72b":"### Note\nOur Baseline model achieves an AUC score of 0.8014. This isn't skillful enough, we need to jack it up.","13d05960":"### RANDOM FOREST FEATURE IMPORTANCE\nThe value assigned to Random Forest Features measure their predictive power but they are not class indicative. It tells how informative the features are in splitting the target variable into distinctive classes. The above graph further tells us that Number of Days past due (30, 60 and 90) and Revolving Credit Utilization are the most important features for our PD model.","1a526f7b":"### Notes\n* 76% of values in this variable are between 0 - 1\n* 4% are between 1 - 10\n* The remaining 20% have high values (Median of 2166). Outliers responsible for skewing the Variable\n* These outliers won't be discarded as we've earlier established that they are special case of Borrowers","b5923e7d":"### RELEVANT FEATURES\n* Using 5% significance value.\n* Any Original Feature having all its dummy variable greater the 5% would be dropped.\n* All features have at least one statistically significant variable.\n* Although, Features like Age, Number of Dependents,Monthly Income, Number of open credit and Number of Real Estate have many statistically insignificant variable. This implies they have low predictive power.\n\n","2b7ae966":"#  MISSING VALUES","1651dd96":"## DEBT RATIO","6e8608e1":"## NUMBER OF OPEN CREDIT LINES AND LOANS","4651db53":"## NUMBER OF OPEN CREDIT LINES\n***","87edc46f":"### DEBT RATIO\n***","7679c445":"### REVOLVING CREDIT UTILIZATION RATIO","48fbd1bd":"### Note\nThis variable is right-skewed with no extreme values. Further preprocessing of this data would be aggregating similar Category (Fine Class) to a Coarse class during WOE Feature Engineering and Data Preprocessing.","bb1a13df":"## MONTHLY INCOME","ed4b04ab":"## NUMBER OF REAL ESTATE LOANS AND LINES\n***","88aea993":"# Handling Missing Monthly Income\n* Records with missing Monthly Income have high Debt Ratio (Median 1159)\n* Summary Stat of Borrowers with high Debt Ratio shows that the Monthly Income of these Borrowers are 0\n* This could mean Borrowers with missing Monthly Income delibrately left the column blank because they are trivial woorkers not earning Monthly Income\n* The best method to handle this missing values is to replace it with 0","a0f11ad5":"### Note\nThis variable is highly skewed to the right, Majority of the Borrowers have between 0 to 2 Mortgage loans. Further preprocessing of this data would be aggregating similar Category (Fine Class) to a Coarse class during WOE Feature Engineering and Data Preprocessing.","22a09165":"## AGE","f5759891":"## INTRODUCTION\n***\nBanks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit. \n\nCredit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.","e542e62e":"### Note\nThese Features have similar distribution. There are two unique values (98 and 96). It is impossible for a borrower to exhibit delinquency 98 or 96 times in space of 2 years. It can also be observerd that these values share the same corresponding index, which might indicates Data Entry error. However, they can't be dropped due to high information they possess in identifying defaulting members. 55% of Borrowers in this category defaulted compared to 6% global default rate. Its best we keep them and assign a separate class for these values","50598b80":"## NUMBER OF REAL ESTATE LOANS AND LINES"}}