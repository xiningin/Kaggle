{"cell_type":{"8ddb1ad0":"code","f896b239":"code","d165a3b8":"code","2e2df8e9":"code","cb6f7fb9":"code","376ba840":"code","28908822":"code","1a8f9d75":"code","91cfb0e9":"code","23c7c144":"code","151a777e":"code","30b40f67":"code","7950342d":"code","45f3c18d":"code","53f957c5":"code","c6f7f9fd":"code","72d36d52":"code","d2381175":"code","a8e8ee4c":"code","f8190074":"code","8de5d1b8":"code","aebc40f6":"code","a2a4c4a6":"code","06c38b99":"code","c99bf692":"code","1227003a":"code","b1be947f":"code","1bd8b1e2":"code","f5e42991":"code","2176085e":"code","b217d7e6":"code","d2c8561d":"code","a10b6fdc":"code","e8bbda34":"code","eb132b1a":"code","741c10ab":"code","7941bb2c":"code","fb800b94":"code","a1bb87f4":"code","bb41d7d2":"code","9b73814d":"code","15e0ef7d":"code","15a29c29":"code","36d2157a":"code","c7fe30ef":"code","dc360702":"code","c7e33c14":"code","a5fd3d4b":"code","3a1a0773":"code","3d4bba53":"code","19cf6b54":"code","0410d6b2":"code","6bb5fa79":"code","30f00350":"code","b9c25cb8":"code","c6762548":"code","77142f40":"code","07d46cd2":"code","730cc94d":"code","092286bb":"code","85b11eb7":"code","bcb17959":"code","142fcb2d":"code","0bb75bfe":"code","99445920":"code","0b32a0d1":"code","7cc6ec85":"code","36feffa5":"code","dadeb6a5":"code","6341b90f":"code","d265cc51":"code","fa86a87e":"code","5abcde9c":"code","b1ef3eef":"code","f8525734":"code","4123d2fd":"code","b2236dd4":"code","86de8685":"code","096596b1":"code","9ece6dfa":"code","50670f02":"markdown","a158de80":"markdown","827ad7e2":"markdown","717dd044":"markdown","4867491e":"markdown","6294fe1a":"markdown","a9a633f3":"markdown","55cfe2ae":"markdown","9840b1df":"markdown","16878ac4":"markdown","5987eef9":"markdown","92386ec8":"markdown","8c41a554":"markdown","17e112ba":"markdown","ed3c4d0c":"markdown","a43a4f12":"markdown","2007de9b":"markdown","b7a0aae7":"markdown","c6ebcb0d":"markdown","47a1cade":"markdown","43028a81":"markdown","a2fda0c5":"markdown","1a1666d6":"markdown","fdb53560":"markdown","6753a72d":"markdown","e1d1cd5b":"markdown","a29ac0f2":"markdown","1d8563c2":"markdown","a0d65539":"markdown","c6ee7931":"markdown","03045a9c":"markdown","4d067c09":"markdown","a2da49c7":"markdown","4c9a1d36":"markdown","a3fb372f":"markdown","64afb6c6":"markdown","366fa2dd":"markdown","f3d1dac9":"markdown","0b563c9f":"markdown","cf731c90":"markdown","c3d1821d":"markdown","1cb36967":"markdown","28b84729":"markdown","4cdd3e62":"markdown","d1175b9d":"markdown","12d320cb":"markdown","d8975c1f":"markdown","c310c9cf":"markdown","f060b76c":"markdown","985aeabe":"markdown","d3a90e58":"markdown","479f236e":"markdown","5a0f2975":"markdown","0a2d05e7":"markdown","82656c84":"markdown","fb55dcd2":"markdown","fd74d122":"markdown","1917e92b":"markdown","41f48b31":"markdown","be887a40":"markdown","fa8f03b8":"markdown","179f6cbc":"markdown","90590436":"markdown","2acbad20":"markdown","5aa9bcf1":"markdown","4c719e30":"markdown","1163e456":"markdown","c9bff42b":"markdown","f5148576":"markdown","895b90cc":"markdown","f0479f97":"markdown","1924fb2c":"markdown","a9c3c1f9":"markdown","0d8c4b5d":"markdown","c2cb9aeb":"markdown","7a563d02":"markdown","34e04ded":"markdown","91d9c844":"markdown","d9c5726d":"markdown","bdde227c":"markdown","0a86d5fe":"markdown","fbb309b3":"markdown","9eb10bf5":"markdown","55be852e":"markdown","5463c302":"markdown","faa24172":"markdown","7a7bdaed":"markdown","fc66b545":"markdown","4badedff":"markdown","e6251364":"markdown","00e880dd":"markdown","c11156b9":"markdown","abaa1cb7":"markdown","f2051a33":"markdown","8059af83":"markdown","4ca17909":"markdown","6fd44bca":"markdown","4a8b27d8":"markdown","f008d950":"markdown","064d9506":"markdown","660311a0":"markdown","f70751e7":"markdown","30cab419":"markdown","900f6e12":"markdown","d505263a":"markdown","867d0d20":"markdown","c8294e2a":"markdown"},"source":{"8ddb1ad0":"import os\nimport ast\nimport json\nimport glob\nimport random\nimport collections\nfrom tqdm import tqdm\nimport gc\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Seed for reproducability\nseed = 1234\nnp.random.seed(seed)","f896b239":"# Paths \nKAGGLE_DIR = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/'\nIMG_PATH_TRAIN = KAGGLE_DIR + 'train\/'\nIMG_PATH_TEST = KAGGLE_DIR + 'test\/'\nTRAIN_CSV_PATH = KAGGLE_DIR + 'train_labels.csv'\nTEST_CSV_PATH = KAGGLE_DIR + 'sample_submission.csv'","d165a3b8":"train_df = pd.read_csv(TRAIN_CSV_PATH)\ndisplay(train_df.head(5))\nprint('MGMT counts:')\ntrain_df.MGMT_value.value_counts()","2e2df8e9":"plt.figure(figsize=(5, 5))\nplt.title('Train csv')\nsns.countplot(data=train_df, x=\"MGMT_value\");","cb6f7fb9":"test_df = pd.read_csv(TEST_CSV_PATH)\ndisplay(test_df.head(5))\nprint('MGMT counts:')\ntest_df.MGMT_value.value_counts()","376ba840":"plt.figure(figsize=(5, 5))\nplt.title('Test csv')\nsns.countplot(data=test_df, x=\"MGMT_value\");","28908822":"# All filenames for train and test images\ntrain_images = os.listdir(IMG_PATH_TRAIN)\ntest_images = os.listdir(IMG_PATH_TEST)","1a8f9d75":"def load_dicom(path):\n    # read file\n    dicom = pydicom.read_file(path)\n    # get pixel data into a useful format. \n    data = dicom.pixel_array\n    # transform data into black and white scale \/ grayscale\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\n\ndef visualize_sample(\n    brats21id, \n    slice_i,\n    mgmt_value,\n    types=(\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\")\n):\n    plt.figure(figsize=(16, 5))\n    patient_path = os.path.join(\n        IMG_PATH_TRAIN, \n        str(brats21id).zfill(5),\n    )\n    for i, t in enumerate(types, 1):\n        t_paths = sorted(\n            glob.glob(os.path.join(patient_path, t, \"*\")), \n            key=lambda x: int(x[:-4].split(\"-\")[-1]),\n        )\n        data = load_dicom(t_paths[int(len(t_paths) * slice_i)])\n        plt.subplot(1, 4, i)\n        plt.imshow(data, cmap=\"gray\")\n        plt.title(f\"{t}\", fontsize=16)\n        plt.axis(\"off\")\n\n    plt.suptitle(f\"MGMT_value: {mgmt_value}\", fontsize=16)\n    plt.show()","91cfb0e9":"for i in random.sample(range(train_df.shape[0]), 10): # get 10 random indexes from the train ds\n    _brats21id = train_df.iloc[i][\"BraTS21ID\"] # for these indexes get the associated brats ID\n    _mgmt_value = train_df.iloc[i][\"MGMT_value\"] # and tumor class\n    visualize_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5) # visualize samples","23c7c144":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\n\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(6, 6))\n    plt.axis('off')\n    im = plt.imshow(ims[0], cmap=\"gray\")\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000\/\/24)","151a777e":"def load_dicom_line(path):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    images = []\n    for filename in t_paths:\n        data = load_dicom(filename)\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images","30b40f67":"IMG_PATH_TRAIN = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/\"\nIMG_PATH_TEST = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/\"","7950342d":"# review training directory\ns_sizes = [] # list of no. of scans present for each patient\np_sizes = [] # list of no. of dcm files present for each patient\npatient_id = [] # patient id\nfile_paths = [] # file_paths\n\nfor d in os.listdir(IMG_PATH_TRAIN):\n#     print(\"Patient '{}' has {} scans and a total of {} DICOM images\".format(d, len(os.listdir(TRAIN_DIR + d)), len(glob.glob(TRAIN_DIR+ d + \"\/*\/*.dcm\"))))\n    s_sizes.append(len(os.listdir(IMG_PATH_TRAIN + d)))\n    p_sizes.append(len(glob.glob(IMG_PATH_TRAIN + d + \"\/*\/*.dcm\")))\n    patient_id.append(d)\n\npatient_files_df = pd.DataFrame(\n    {'patient_id': patient_id,\n     'file_count': p_sizes,\n    })\n    \nprint('----')\nprint('Total patients {} Total DCM files {}'.format(len(os.listdir(IMG_PATH_TRAIN)), \n                                                      len(glob.glob(IMG_PATH_TRAIN+ \"\/*\/*\/*.dcm\"))))\n\nprint('----')\nprint('TRAIN Dataframe with File Count per Patient ')\ndisplay(patient_files_df.head(5))\n\nprint('----')\nprint('Verify total File Count for all Patients ')\nprint('Total number of patients:', patient_files_df.shape[0])\n\nprint('Total file count:', patient_files_df.file_count.sum())","45f3c18d":"f = []\nfor (dirpath, dirnames, filenames) in os.walk(IMG_PATH_TRAIN):\n    f.extend(os.path.join(dirpath, x) for x in filenames)\n    \ntrain_file_paths_df = pd.DataFrame({'file_paths': f})\ntrain_file_paths_df['train_dir'] = IMG_PATH_TRAIN\ntrain_file_paths_df['patient_id'] = train_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[4]\ntrain_file_paths_df['scan_type'] = train_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[5]\ntrain_file_paths_df['file'] = train_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[6]\ndisplay(train_file_paths_df.head(2))\ntrain_file_paths_df.shape[0]","53f957c5":"print('Possible Number of scans for all patients:', set(s_sizes))","c6f7f9fd":"# lets visualize trainig data\np = sns.color_palette()\nplt.hist(p_sizes, color=p[2])\nplt.ylabel('Number of patients')\nplt.xlabel('Count of DICOM files')\nplt.title('Histogram of DICOM count per patient - Training Data');","72d36d52":"# review test directory\ns_sizes = [] # list of no. of scans present for each patient\np_sizes = [] # list of no. of dcm files present for each patient\npatient_id = [] # patient id\n\nfor d in os.listdir(IMG_PATH_TEST):\n#     print(\"Patient '{}' has {} scans and a total of {} DICOM images\".format(d, \n#                     len(os.listdir(IMG_PATH_TEST + d)), len(glob.glob(IMG_PATH_TEST+ d + \"\/*\/*.dcm\"))))\n    s_sizes.append(len(os.listdir(IMG_PATH_TEST + d)))\n    p_sizes.append(len(glob.glob(IMG_PATH_TEST + d + \"\/*\/*.dcm\")))\n    patient_id.append(d)\n\npatient_files_df = pd.DataFrame(\n    {'patient_id': patient_id,\n     'file_count': p_sizes,\n    })\n    \nprint('----')\nprint('Total patients {} Total DCM files {}'.format(len(os.listdir(IMG_PATH_TEST)), \n                                                      len(glob.glob(IMG_PATH_TEST+ \"\/*\/*\/*.dcm\"))))\nprint('----')\nprint('TRAIN Dataframe with File Count per Patient ')\ndisplay(patient_files_df.head(5))\n\nprint('----')\nprint('Verify total File Count for all Patients ')\nprint('Total number of patients:', patient_files_df.shape[0])\n\nprint('Total file count:', patient_files_df.file_count.sum())","d2381175":"f = []\nfor (dirpath, dirnames, filenames) in os.walk(IMG_PATH_TEST):\n    f.extend(os.path.join(dirpath, x) for x in filenames)\n    \ntest_file_paths_df = pd.DataFrame({'file_paths': f})\ntest_file_paths_df['train_dir'] = IMG_PATH_TEST\ntest_file_paths_df['patient_id'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[4]\ntest_file_paths_df['scan_type'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[5]\ntest_file_paths_df['file'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[6]\ndisplay(test_file_paths_df.head(2))\ntest_file_paths_df.shape[0]","a8e8ee4c":"print('Possible Number of scans for all patients:', set(s_sizes))","f8190074":"# lets visualize test data\np = sns.color_palette()\nplt.hist(p_sizes, color=p[2])\nplt.ylabel('Number of patients')\nplt.xlabel('Count of DICOM files')\nplt.title('Histogram of DICOM count per patient - Training Data');","8de5d1b8":"# sizes = [os.path.getsize(dcm)\/1000000 for dcm in glob.glob(TRAIN_DIR+ \"\/*\/*\/*.dcm\")]\n# print('DCM file sizes: min {:.3}MB max {:.3}MB avg {:.3}MB std {:.3}MB'.format(np.min(sizes), \n#                                                        np.max(sizes), np.mean(sizes), np.std(sizes)))","aebc40f6":"print('Example of all data in a single DICOM file:\\n')\nexample_dicom = pydicom.dcmread(train_file_paths_df['file_paths'][0])\nprint(example_dicom)","a2a4c4a6":"# All columns for which we want to collect information\nmeta_cols = ['SpecificCharacterSet','ImageType','SOPClassUID',\n             'SOPInstanceUID','AccessionNumber','Modality', 'SeriesDescription', \n             'PatientID', 'MRAcquisitionType', 'SliceThickness', \n             'EchoTime', 'NumberOfAverages', 'ImagingFrequency', 'ImagedNucleus', \n             'MagneticFieldStrength', 'SpacingBetweenSlices', \n             'EchoTrainLength', 'PercentSampling', 'PercentPhaseFieldOfView',\n             'PixelBandwidth', 'TriggerWindow', 'ReconstructionDiameter', 'AcquisitionMatrix',\n             'FlipAngle', 'SAR', 'PatientPosition',\n             'StudyInstanceUID', 'SeriesInstanceUID', 'SeriesNumber', 'InstanceNumber',\n             'ImagePositionPatient', 'ImageOrientationPatient', 'Laterality',\n             'PositionReferenceIndicator', 'SliceLocation', 'InStackPositionNumber',\n             'SamplesPerPixel', 'PhotometricInterpretation', 'Rows', 'Columns', 'PixelSpacing',\n             'BitsAllocated', 'BitsStored', 'HighBit', 'PixelRepresentation', 'WindowCenter',\n             'WindowWidth', 'RescaleIntercept', 'RescaleSlope', 'RescaleType']","06c38b99":"# Initialize dictionaries to collect the metadata\ncol_dict_train = {col: [] for col in meta_cols}\ncol_dict_test = {col: [] for col in meta_cols}","c99bf692":"'''Uncomment code snipet to obtain metadata for all train DICOM images'''\n# # Get values for training images\n# for img in tqdm(train_file_paths_df.file_paths): \n#     dicom_object = pydicom.dcmread(img)\n#     for col in meta_cols: \n# #         print(str(getattr(dicom_object, col)))\n#         try:\n#             col_dict_train[col].append(str(getattr(dicom_object, col)))\n#         except AttributeError:\n#             col_dict_train[col].append(\"NaN\")\n\n# # Store all information in a DataFrame\n# meta_df_train = pd.DataFrame(col_dict_train)\n# del col_dict_train\n# # Garbage Collector for memory cleaning\n# gc.collect()","1227003a":"'''Uncomment code snipet to obtain metadata for all test DICOM images'''\n# # Get values for training images\n# for img in tqdm(test_file_paths_df.file_paths): \n#     dicom_object = pydicom.dcmread(img)\n#     for col in meta_cols: \n# #         print(str(getattr(dicom_object, col)))\n#         try:\n#             col_dict_test[col].append(str(getattr(dicom_object, col)))\n#         except AttributeError:\n#             col_dict_test[col].append(\"NaN\")\n\n# # Store all information in a DataFrame\n# meta_df_test = pd.DataFrame(col_dict_test)\n# del col_dict_test\n# # Garbage Collector for memory cleaning\n# gc.collect()","b1be947f":"'''Uncomment code snipet to store metadata dataframes for test and train dfs'''\n# # Save to CSV\n# meta_df_train.to_csv('stage_0_train_with_metadata.csv', index=False)\n# meta_df_test.to_csv('stage_0_test_with_metadata.csv', index=False)","1bd8b1e2":"test_meta_df = pd.read_csv(\"..\/input\/stage0-metadata-rsna\/stage_0_test_with_metadata.csv\")\ntrain_meta_df = pd.read_csv(\"..\/input\/stage0-metadata-rsna\/stage_0_train_with_metadata.csv\")","f5e42991":"meta_attr = []\nnum_unique = []\n\nfor col in train_meta_df:\n#     print(\"* For attribute  '{}' , there are [ {} ] unique values.\".format(col,\n#                     len(train_meta_df[col].unique())))\n    meta_attr.append(col)\n    num_unique.append(len(train_meta_df[col].unique()))\n    \ntrain_meta_values_df = pd.DataFrame(\n    {'attribute': meta_attr,\n     'value_count': num_unique,\n     'nan_count': train_meta_df.isna().sum()\n    })\n\ntrain_meta_values_df = train_meta_values_df.sort_values(by=['value_count'], ascending=False).reset_index(drop=True)\ntrain_meta_values_df","2176085e":"meta_attr = []\nnum_unique = []\n\nfor col in test_meta_df:\n#     print(\"* For attribute  '{}' , there are [ {} ] unique values.\".format(col,\n#                     len(train_meta_df[col].unique())))\n    meta_attr.append(col)\n    num_unique.append(len(test_meta_df[col].unique()))\n    \ntest_meta_values_df = pd.DataFrame(\n    {'attribute': meta_attr,\n     'value_count': num_unique,\n     'nan_count': test_meta_df.isna().sum()\n    })\n\ntest_meta_values_df = test_meta_values_df.sort_values(by=['value_count'], ascending=False).reset_index(drop=True)\ntest_meta_values_df","b217d7e6":"def color_code_by_vcount(df):\n    if df['value_count'] == 1.0:\n        return 'k' # Single unique value, color-code black\n    elif df['value_count'] <= 1000.0:\n        return 'b' # Unique value count between one and 1000, color-code blue\n    else:\n        return 'r' # Unique value count more than > 1000, color-code red\n\ntrain_mv_df = train_meta_values_df.copy().set_index(\"attribute\")\ntrain_mv_df['color'] = train_mv_df.apply(color_code_by_vcount, axis=1)\n\nax = train_mv_df['value_count'].plot(kind='bar',\n                                    figsize=(14,8),  color=train_mv_df['color'],\n                                    title=\"Number of Unique Values per Attribute [LOG SCALE]\")\nax.set_xlabel(\"Metadata Attribute\")\nax.set_ylabel(\"Unique Number of Values [LOG SCALE]\")\nax.set_yscale('log');","d2c8561d":"f, axes = plt.subplots(1, 2, figsize=(15,15))\n\nnans = train_meta_df.isna().sum().sort_values(ascending=False)\nsns.barplot(y=nans.index, x=nans, orient='h', ax = axes[0])\naxes[0].set_title(\"Train NaN Count\")\n\nnans_test = test_meta_df.isna().sum().sort_values(ascending=False)\nsns.barplot(y=nans_test.index, x=nans_test, orient='h', ax = axes[1])\naxes[1].yaxis.set_ticks_position(\"right\")\naxes[1].set_title(\"Test NaN Count\");","a10b6fdc":"merged_meta_attrs = pd.merge(train_meta_values_df, test_meta_values_df, on=\"attribute\", \n                             suffixes=(\"_train\",\"_test\"))\nmerged_meta_attrs","e8bbda34":"'''Print attributes unique values for low value count and descrepancy between test and train.'''\nprint(train_meta_df[\"SpecificCharacterSet\"].unique())\nprint(test_meta_df[\"PositionReferenceIndicator\"].unique())","eb132b1a":"list_drop_attrs = [\"SOPInstanceUID\",\"ImagePositionPatient\",\"SliceLocation\",\"WindowWidth\",\n                   \"WindowCenter\",\"SeriesInstanceUID\",\"SAR\",\"ImageOrientationPatient\",\n                   \"ImagingFrequency\",\"AccessionNumber\",\"StudyInstanceUID\",\"HighBit\",\n                   \"RescaleIntercept\",\"BitsStored\",\"BitsAllocated\",\"RescaleSlope\",\n                   \"PatientPosition\",\"PhotometricInterpretation\",\"SamplesPerPixel\",\n                   \"PositionReferenceIndicator\",\"Laterality\",'ImageType',\"SpacingBetweenSlices\",\n                   \"Modality\",\"SOPClassUID\",\"RescaleType\",]","741c10ab":"print(\"Columns before : \", len(train_meta_df.columns))\ntrain_meta_df_useful = train_meta_df.drop(list_drop_attrs, axis=1)\nprint(\"Columns after : \", len(train_meta_df_useful.columns))","7941bb2c":"sizes = train_meta_df.apply(lambda x: f'{x.Rows}x{x.Columns}', axis=1)\nplt.figure(figsize=(15, 8))\nplt.xticks(rotation=45)\nsns.countplot(sizes);","fb800b94":"sns.countplot(train_meta_df.SeriesDescription);","a1bb87f4":"plt.figure(figsize=(12, 5))\nplt.xticks(rotation=45)\nsns.countplot(train_meta_df.SliceThickness);","bb41d7d2":"sns.jointplot(data=train_meta_df, x='SliceThickness', y='SpacingBetweenSlices');","9b73814d":"sns.countplot(train_meta_df.MRAcquisitionType);","15e0ef7d":"sns.countplot(train_meta_df.NumberOfAverages);","15a29c29":"sns.countplot(train_meta_df.MagneticFieldStrength);","36d2157a":"plt.figure(figsize=(12, 5))\nplt.xticks(rotation=45)\nsns.countplot(train_meta_df.ReconstructionDiameter);","c7fe30ef":"len(train_meta_df.PixelRepresentation.unique())","dc360702":"sns.countplot(train_meta_df.PixelRepresentation);","c7e33c14":"def get_image_plane(data):\n    '''\n    Returns the MRI's plane from the dicom data.\n    \n    '''\n    x1,y1,_,x2,y2,_ = [round(j) for j in ast.literal_eval(data.ImageOrientationPatient)]\n    cords = [x1,y1,x2,y2]\n\n    if cords == [1,0,0,0]:\n        return 'coronal'\n    if cords == [1,0,0,1]:\n        return 'axial'\n    if cords == [0,1,0,0]:\n        return 'sagittal'\n    \ntrain_meta_df['Orientation'] = train_meta_df.apply(get_image_plane, axis=1)\n\ntest_meta_df['Orientation'] = test_meta_df.apply(get_image_plane, axis=1)","a5fd3d4b":"sns.countplot(train_meta_df.Orientation);","3a1a0773":"sns.countplot(test_meta_df.Orientation);","3d4bba53":"sns.histplot(data=train_meta_df, x=\"SeriesDescription\", hue=\"Orientation\", \n             multiple=\"dodge\", shrink=.8);","19cf6b54":"sns.histplot(data=test_meta_df, x=\"SeriesDescription\", hue=\"Orientation\", \n             multiple=\"dodge\", shrink=.8);","0410d6b2":"df2 = train_meta_df.groupby(['PatientID', 'Orientation', 'SeriesDescription']).size().reset_index(name='count') \ndf2","6bb5fa79":"len(df2.PatientID.unique()) * 4","30f00350":"dft = test_meta_df.groupby(['PatientID', 'Orientation', 'SeriesDescription']).size().reset_index(name='count') \ndft","b9c25cb8":"len(dft.PatientID.unique()) * 4","c6762548":"fig, ax = plt.subplots(figsize=(10,10))   \nsns.heatmap(train_meta_df.corr(), ax =ax)","77142f40":"def image_stats(image):\n    nonzero_pixels = image[np.nonzero(image)]\n    if nonzero_pixels.shape == (0,):\n        mean = 0\n        std = 0\n    else:\n        mean = np.mean(nonzero_pixels)\n        std = np.std(nonzero_pixels)\n    return (mean,std)\n\ndef plot_image_hist(image, threshold = 1.5, normalize = False):\n    pixels = image.ravel()\n    nonzero_pixels = pixels[np.nonzero(pixels)]\n    (mean,std) = image_stats(nonzero_pixels)\n    if normalize:\n        nonzero_pixels = (nonzero_pixels - mean) \/ std\n        (mean,std) = image_stats(nonzero_pixels)\n    over_threshold = np.count_nonzero(nonzero_pixels > mean + threshold * std)\n\n    fig, (axi, axh) = plt.subplots(1, 2, figsize = (20,3), \n                                   gridspec_kw={'width_ratios': [1, 4]})\n    fig.suptitle(f'Pixels over threshold # ({over_threshold})')\n\n    axh.hist(nonzero_pixels, 200)\n\n    ax_limits = axh.get_ylim()\n    axh.vlines(mean, ymin=ax_limits[0], \n               ymax=ax_limits[1], colors='b')\n    axh.vlines(mean+std, ymin=ax_limits[0], \n               ymax=ax_limits[1], colors='b', linestyles='dotted')\n    axh.vlines(mean + threshold * std, ymin=ax_limits[0], \n               ymax=ax_limits[1], colors='b', linestyles='dashed')\n    axi.imshow(image, cmap = plt.cm.gray)\n    axi.grid(False)\n    axi.axis('off')\n    plt.show()","07d46cd2":"img = load_dicom(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T2w\/Image-200.dcm\")\nplot_image_hist(img, threshold = 2, normalize = True)","730cc94d":"plot_image_hist(img, threshold = 2, normalize = False)","092286bb":"def visualize_hist_sample_image(\n    brats21id, \n    slice_i,\n    mgmt_value,\n    types=(\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"),\n    threshold = 1.5, normalize = False\n):\n    plt.figure(figsize=(16, 5))\n    patient_path = os.path.join(\n        IMG_PATH_TRAIN, \n        str(brats21id).zfill(5),\n    )\n    for i, t in enumerate(types, 1):\n        t_paths = sorted(\n            glob.glob(os.path.join(patient_path, t, \"*\")), \n            key=lambda x: int(x[:-4].split(\"-\")[-1]),\n        )\n        image = load_dicom(t_paths[int(len(t_paths) * slice_i)])\n        pixels = image.ravel()\n        nonzero_pixels = pixels[np.nonzero(pixels)]\n        (mean,std) = image_stats(nonzero_pixels)\n        if normalize:\n            nonzero_pixels = (nonzero_pixels - mean) \/ std\n            (mean,std) = image_stats(nonzero_pixels)\n        over_threshold = np.count_nonzero(nonzero_pixels > mean + threshold * std)\n\n        fig, (axi, axh) = plt.subplots(1, 2, figsize = (20,3), \n                                       gridspec_kw={'width_ratios': [1, 4]});\n\n        axh.hist(nonzero_pixels, 200)\n\n        ax_limits = axh.get_ylim()\n        axh.vlines(mean, ymin=ax_limits[0], \n                   ymax=ax_limits[1], colors='b')\n        axh.vlines(mean+std, ymin=ax_limits[0], \n                   ymax=ax_limits[1], colors='b', linestyles='dotted')\n        axh.vlines(mean + threshold * std, ymin=ax_limits[0], \n                   ymax=ax_limits[1], colors='b', linestyles='dashed')\n        axi.imshow(image, cmap = plt.cm.gray)\n        axi.grid(False)\n        plt.title(f\"{t}: pixels over threshold # ({over_threshold})\", fontsize=16)\n        axi.axis('off')\n#     plt.suptitle(f\"MGMT_value: {mgmt_value}\", fontsize=16)\n    plt.show()\n    print(f\"MGMT_value: {mgmt_value}\")","85b11eb7":"for i in random.sample(range(train_df.shape[0]), 2): # get 10 random indexes from the train ds\n    _brats21id = train_df.iloc[i][\"BraTS21ID\"] # for these indexes get the associated brats ID\n    _mgmt_value = train_df.iloc[i][\"MGMT_value\"] # and tumor class\n    visualize_hist_sample_image(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5,\n                           threshold = 2, normalize = True) # visualize samples","bcb17959":"def visualize_masked_sample(\n    brats21id, \n    slice_i,\n    mgmt_value,\n    types=(\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"),\n    threshold = -1\n):\n    plt.figure(figsize=(16, 5))\n    patient_path = os.path.join(\n        IMG_PATH_TRAIN, \n        str(brats21id).zfill(5),\n    )\n    for i, t in enumerate(types, 1):\n        t_paths = sorted(\n            glob.glob(os.path.join(patient_path, t, \"*\")), \n            key=lambda x: int(x[:-4].split(\"-\")[-1]),\n        )\n        data = load_dicom(t_paths[int(len(t_paths) * slice_i)])\n        if threshold > -1:\n            data[data < threshold] = 0\n        plt.subplot(1, 4, i)\n        plt.imshow(data, cmap=\"gray\")\n        plt.title(f\"{t}\", fontsize=16)\n        plt.axis(\"off\")\n\n    plt.suptitle(f\"MGMT_value: {mgmt_value}\", fontsize=16)\n    plt.show()","142fcb2d":"i = 520\n_brats21id = train_df.iloc[i][\"BraTS21ID\"] # for these indexes get the associated brats ID\n_mgmt_value = train_df.iloc[i][\"MGMT_value\"] # and tumor class\nvisualize_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5) # visualize samples","0bb75bfe":"i = 520\n_brats21id = train_df.iloc[i][\"BraTS21ID\"] # for these indexes get the associated brats ID\n_mgmt_value = train_df.iloc[i][\"MGMT_value\"] # and tumor class\nvisualize_masked_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.4,\n                           threshold = 80) # visualize samples","99445920":"i = 520\n_brats21id = train_df.iloc[i][\"BraTS21ID\"] # for these indexes get the associated brats ID\n_mgmt_value = train_df.iloc[i][\"MGMT_value\"] # and tumor class\nvisualize_masked_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5,\n                           threshold = 120) # visualize samples","0b32a0d1":"train_px_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/stats_train_file_paths_df.csv')\ntest_px_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/stats_test_file_paths_df.csv')","7cc6ec85":"stats_cols = []\nnum_unique = []\n\nfor col in train_px_df:\n#     print(\"* For attribute  '{}' , there are [ {} ] unique values.\".format(col,\n#                     len(train_meta_df[col].unique())))\n    stats_cols.append(col)\n    num_unique.append(len(train_px_df[col].unique()))\n    \ntrain_df_stats = pd.DataFrame(\n    {'col_name': stats_cols,\n     'value_count': num_unique,\n     'nan_count': train_px_df.isna().sum()\n    })\n\ntrain_df_stats = train_df_stats.sort_values(by=['value_count'], ascending=False).reset_index(drop=True)\ntrain_df_stats = train_df_stats.set_index('col_name').T\ntrain_df_stats","36feffa5":"stats_cols = []\nnum_unique = []\n\nfor col in test_px_df:\n#     print(\"* For attribute  '{}' , there are [ {} ] unique values.\".format(col,\n#                     len(train_meta_df[col].unique())))\n    stats_cols.append(col)\n    num_unique.append(len(test_px_df[col].unique()))\n    \ntest_df_stats = pd.DataFrame(\n    {'col_name': stats_cols,\n     'value_count': num_unique,\n     'nan_count': test_px_df.isna().sum()\n    })\n\ntest_df_stats = test_df_stats.sort_values(by=['value_count'], ascending=False).reset_index(drop=True)\ntest_df_stats = test_df_stats.set_index('col_name').T\ntest_df_stats","dadeb6a5":"print(train_px_df.min_px.unique(), train_px_df.max_px.unique())\nprint(test_px_df.min_px.unique(), test_px_df.max_px.unique())","6341b90f":"min(train_px_df.mean_px.unique()), max(train_px_df.mean_px.unique())","d265cc51":"fig, axes = plt.subplots(1, 2, figsize=(25, 8), sharey=True)\nfig.suptitle('Train - Test Dataset Pixel Distributions Mean + STD')\n\nsns.histplot(ax=axes[0], data = train_px_df[['mean_px', 'std_px']], bins=50, alpha=0.5)\naxes[0].set_yscale('log')\nsns.histplot(ax=axes[1], data = test_px_df[['mean_px', 'std_px']], bins=50, alpha=0.5)\nplt.show();","fa86a87e":"g = sns.FacetGrid(train_px_df, col=\"scan_type\")\ng.map(plt.hist, 'mean_px', bins=50);\ng.set(yscale=\"log\")","5abcde9c":"g = sns.FacetGrid(test_px_df, col=\"scan_type\")\ng.map(plt.hist, 'mean_px', bins=50);\ng.set(yscale=\"log\")","b1ef3eef":"train_lbls = pd.read_csv(TRAIN_CSV_PATH)","f8525734":"train_px_df = train_px_df.merge(train_lbls, left_on='patient_id', right_on='BraTS21ID')\ntrain_px_df.head(2)","4123d2fd":"g = sns.FacetGrid(train_px_df, col=\"scan_type\", hue='MGMT_value')\ng.map(plt.hist, 'mean_px', bins=50, alpha=0.5);\ng.set(yscale=\"log\")\ng.add_legend()","b2236dd4":"images = load_dicom_line(IMG_PATH_TRAIN + \"00000\/FLAIR\")\ncreate_animation(images)","86de8685":"images = load_dicom_line(IMG_PATH_TRAIN + \"00000\/T1w\")\ncreate_animation(images)","096596b1":"images = load_dicom_line(IMG_PATH_TRAIN + \"00000\/T1wCE\")\ncreate_animation(images)","9ece6dfa":"images = load_dicom_line(IMG_PATH_TRAIN + \"00000\/T2w\")\ncreate_animation(images)","50670f02":"The exact mpMRI scans included are:\n\n- Fluid Attenuated Inversion Recovery (FLAIR)\n- T1-weighted pre-contrast (T1w)\n- T1-weighted post-contrast (T1Gd)\n- T2-weighted (T2)","a158de80":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Reconstruction Diameter](https:\/\/dicom.innolitics.com\/ciods\/nm-image\/nm-reconstruction\/00181100): Diameter, in mm, of the region from within which the data was used in creating the reconstruction of the image. Data may exist outside this region and portions of the patient may exist outside this region. The diameter defines a circular region that is entirely contained within the encoded Pixel Data (7FE0,0010), unless the encoded image has been cropped after reconstruction.\n\n**_Note_**\nIf not cropped or padded, for square images with square pixels, both values of Pixel Spacing (0028,0030) will be equal and equal to Reconstruction Diameter (0018,1100) \/ Rows (0028,0010) and Reconstruction Diameter (0018,1100) \/ Columns (0028,0011). ","827ad7e2":"## Mask and Plot Image Data","717dd044":"<a id=\"10\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>4. EDA DICOM Metadata<center><h2>","4867491e":"<a id=\"5\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>3. EDA DICOM Images<center><h2>","6294fe1a":"# Let's check the size of the dicom images","a9a633f3":"**test\/ dataset:** \n\nWe have a total of 87 directories, one for each patient, with 4 subdirectories corresponding to 4 scans per patient and total of 51473 dicom images, i.e. **about 13% and 87% test \/ train split**. ","55cfe2ae":"### Take a look into distribution per scan type","9840b1df":"For this part we make use of image statistical properties and [this dataset](https:\/\/www.kaggle.com\/smoschou55\/train-test-filepaths-rsna-full) produced using [this notebook](https:\/\/www.kaggle.com\/smoschou55\/dicom-to-2d-resized-axial-pngs-256x256-x36).","16878ac4":"There are 50 attributes present in the DICOM images of the **train\/  - dataset** and 585 unique patients.","5987eef9":"### 4.4 Series Description","92386ec8":"<a id=\"2\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>2. Quick EDA and Data Visualization<center><h2>","8c41a554":"### train\/ dataset","17e112ba":"count: \"axial\" > \"sagittal\" > \"coronal\"","ed3c4d0c":"### 4.2 Let's try merging train\/ and test\/ to gain some more insights","a43a4f12":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Rows](https:\/\/dicom.innolitics.com\/ciods\/us-image\/image-pixel\/00280010): Number of rows in the image.Shall be an exact multiple of the vertical downsampling factor if any of the samples (planes) are encoded downsampled in the vertical direction for pixel data encoded in a Native (uncompressed) format. E.g., required to be an even value for a Photometric Interpretation (0028,0004) of YBR_FULL_422.\n\n* [Columns](https:\/\/dicom.innolitics.com\/ciods\/us-image\/image-pixel\/00280011): Number of columns in the image. Shall be an exact multiple of the horizontal downsampling factor if any of the samples (planes) are encoded downsampled in the horizontal direction for pixel data encoded in a Native (uncompressed) format. E.g., required to be an even value for a Photometric Interpretation (0028,0004) of YBR_FULL_422.","2007de9b":"- We confirm that the images have been normalized between [0, 255].\n- All images have min value 0 and max value either min=max=0 or max=255.\n\nThe normalization has taken place within the notebook: [\ud83e\udde0 DICOM to 2D Resized Axial PNGs 256x256 [x36] \ud83e\udde0](https:\/\/www.kaggle.com\/smoschou55\/dicom-to-2d-resized-axial-pngs-256x256-x36) in order to draw useful conclusions and make meaningful comparisons.","b7a0aae7":"### 4.8 MagneticFieldStrength","c6ebcb0d":"**Min and Max values for all Images in Train and Test**","47a1cade":"**\\train**","43028a81":"In general:\n\n**This compeition contains some highly consistent data, with well-balanced distributions between train and test datasets and with very informative matadata that correspond to the actual values, ot the extend investigated in this notebook.**\n\nMinor points to be careful with and that are not expected to affect the data handling and modeling part:\n* There seem to be both 3D and 2D labeled MR Acquisition Types. I don't expect this to have any impact on modeling though, as there still are 2D slices comprising a 3D volume of a brain.\n* There is a magnetic field intensity 15000 suposedly in Tesla, but that is most probably a typo meaning 15000 Gauss which is equal to 1.5 Tesla.\n\nSpecific comments:\n* There is no class imbalance between positive and negative class in the train dataset, i.e. half of the train do show MGMT methylation and half do not.\n* There several images that have very small parts of the brain or nothing at all captured and these are expected to not play a major role in the classification task later on, so could be removed as a first order approach.\n* Spacing resolution seems to be the same for all images, i.e. Spacing Between Slices is 1mm.\n* Most images are of size 512x512, but sizes can vary significantly, so resazing is going to be necessary for most ML algorithms.\n* There are at laeast about 80,000 images per each one of the T1w, T1wCE, T2w, FLAIR modalities\n* Overall there are more axial images than sagittal and way more than coronal (more on [MRI Planes in this notebook section](https:\/\/www.kaggle.com\/arnabs007\/part-1-rsna-miccai-btrc-understanding-the-data\/comments?scriptVersionId=70970330&cellId=18))\n* The dominant orientations strongly vary between the different modalities. This needs to be considered in 2D modeling efforts or when combining the different modalities in preprocessing for example. More specifically,\n    * T2w dominant oriantation is saggital\n    * FLAIR dominant orientation is coronal and\n    * T1w and T1wCE dominant orientation is axial.\n* Train and Test datasets follow similar trends in terms of orientation and most features explored herein.\n* For each patient the orientations of images within each modality do not change.\n* Tumors appear bright in FLAIR and T2w, less bright in T1wCE, and not bright at all in T1w. Histograms reflect this as well, with different modalities having their peaks and being skewed towards different directions. This needs to be considered if one wants to apply a low limit on pixel intensity to remove non-informative pixels. There is no single threshold that fits all.\n* Interestingly, there are some noticeable differences between the mean distributions of pixels between patients with MGMT_value 0 and MGMT_value 1.\n    - Images of Patients with MGMT methylation, have larger peaks for T2w, T1wCE and FLAIR. This could be due to some number difference between slices in the two groups.\n    - And most importantly, Images of Patients with MGMT methylation have consistently larger mean values for scan types T2w, T1wCE and FLAIR.\n    - T1w distributions for both MGMT 0 and 1 groups are almost indiscriminate.\n\nRegarding combining data from the different modalities and using external sources, you can read more about it in [this discussion post](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/discussion\/253488), but the main points are also summarized below.\n* We can use the Task 1 Tumor Segmentation dataset that is part of the larger BraTS21 challenge hosted in a different platform: https:\/\/www.synapse.org\/#!Synapse:syn25829067\/wiki\/610863\n* In order to properly use the extra datasets, we need to keep in mind that the Task 1 data is resampled, co-registered, NIFTI files, whereas our data (Task 2 : Radiogenomics Classification) DICOM files, have various resolutions and are not co-registered.\n* Co-registration is a transformation \/ alignment into the same coordinate system and this can happen in a number of ways. \n* The proper from the [FSL course Material](https:\/\/fsl.fmrib.ox.ac.uk\/fslcourse\/online_materials.html) seems to be:\n    * the Afine + Non-linear Registrations for cross-subject transformations (multi-patient studies) to align scans of all subjects\n    * and I don't think that we can co-register \/ align images between different modalities e.g. T2w with FLAIR and T1w, there were originally captured to be in different planes (sagittal, coronal, axial).\n* See also the [\ud83e\udde0 DICOM to 2D Resized Axial PNGs 256x256 [x36] \ud83e\udde0](https:\/\/www.kaggle.com\/smoschou55\/dicom-to-2d-resized-axial-pngs-256x256-x36) notebook and references therein.","a2fda0c5":"### test\/ dataset","1a1666d6":"<a id=\"1\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>1. Overview<center><h2>","fdb53560":"**\/test**","6753a72d":"### 4.3 Image sizes","e1d1cd5b":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Number Of Averages](https:\/\/dicom.innolitics.com\/ciods\/mr-image\/mr-image\/00180083): Number of times a given pulse sequence is repeated before any parameter is changed.","a29ac0f2":"## Load 3D DICOM files and create animations with them","1d8563c2":"Replace with zeros all pixels with values below a larger threshold.","a0d65539":"- Similar to **\/train** with the difference that cutsoff are all value 20 less than train cut off values.\n- Peaks remain in the same places as train peaks.","c6ee7931":"With respect to pixel values we see that:\n- All scans peak at mean = 0, i.e. there are many empty slices.\n- T2w distribution peaks at mean = 20 and almost cuts off at 60, with low values up to 100.\n- T1wCE is similar to T2w with the difference that the peak at value 20 is rounder and wider.\n- T1w is thicker and more uniform with a sharp cutoff at value 100.\n- FLAIR distribution is similar to T2w with a peak at 30 and a thicker tail that cutsoff at 80 with low values up to 100.","03045a9c":"# Peek at one example dicom-file ","4d067c09":"Plot DICOM image and pixel value distributions next to each other.","a2da49c7":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Magnetic Field](https:\/\/dicom.innolitics.com\/ciods\/mr-image\/mr-image\/00180087): Nominal field strength of MR magnet, in Tesla.\nExample Values:\n    * 15000 \ud83d\ude31\ud83d\ude31\ud83d\ude31\n    * 1.5\n    * 3\n","4c9a1d36":"Calculate unique number of values per metadata attribute.","a3fb372f":"### **test\\** Dataset","64afb6c6":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Image Orientation](https:\/\/dicom.innolitics.com\/ciods\/mr-image\/image-plane\/00200037) (0020,0037) specifies the direction cosines of the first row and the first column with respect to the patient. These Attributes shall be provide as a pair. Row value for the x, y, and z axes respectively followed by the Column value for the x, y, and z axes respectively.\n_The direction of the axes is defined fully by the patient's orientation._","366fa2dd":"## Histogram of Raw Image Data","f3d1dac9":"# Main Competition Workflow","0b563c9f":"Indeed for each patient the orientations of images within each modality do not change.","cf731c90":"### train\/ - dataset","c3d1821d":"- Train and test images follow similar distributions with respect the mean and standard deviation.\n- Test_mean = train_mean - 20 and test_std = train_std - 20.","1cb36967":"### 4.10 Pixel Representation","28b84729":"![RadiogenomicsCompetitionFlowchart.png](attachment:286369f1-2662-4008-a1f8-4b106096757b.png)","4cdd3e62":"\u2757\u2757\u2757 **If you want to create the collactive metadata dataframes for test and train datasets from the DICOM images within the directory tree, you can uncomment the following three code snipets \/ cells.** \u2757\u2757\u2757\n\n\ud83c\udfce   To speed things up I skip this step here, as it takes O(hours) and I have already done this once and loaded the train and test metadata *.csv files as input.","d1175b9d":"## Load Metadata for train\/ and test\/ and do EDA for insights","12d320cb":"### 4.9 Reconstruction Diameter","d8975c1f":"There are 50 attributes present in the DICOM images of the **test\/  - dataset** and 87 unique patients.","c310c9cf":"### 4.1 NAN count","f060b76c":"Orientation Distribution per Scan Type","985aeabe":"Interestingly, there are some noticeable differences between the distributions of pixels between patients with MGMT_value 0 and MGMT_value 1.\n- Images of Patients with MGMT methylation, have larger peaks for T2w, T1wCE and FLAIR. This could be due to some number difference between slices in the two groups.\n- And most importantly, Images of Patients with MGMT methylation have consistently larger mean values for scan types T2w, T1wCE and FLAIR.\n- T1w distributions for both MGMT 0 and 1 groups are almost indiscriminate.","d3a90e58":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:darkviolet; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation<\/center><\/h3>\n\n* [1. Overview](#1)\n* [2. Quick EDA and Data Visualization](#2)\n* [3. EDA DICOM Images](#5)\n* [4. EDA DICOM Metadata](#10)\n* [5. EDA Pixel Data](#15)\n* [6. 3D Visualizations](#20)\n* [7. Conclusions](#30)\n    ","479f236e":"Different scans have different histogram distributions as they focus and capture different pathological features.","5a0f2975":"TBD : Work in Progress","0a2d05e7":"## Files\n**train\/** - folder containing the training files, with each top-level folder representing a subject  \n**train_labels.csv** - file containing the target MGMT_value for each subject in the training data (e.g. the presence of MGMT promoter methylation)   \n**test\/** - the test files, which use the same structure as train\/; your task is to predict the MGMT_value for each subject in the test data. NOTE: the total size of the rerun test set (Public and Private) is ~5x the size of the Public test set   \n**sample_submission.csv** - a sample submission file in the correct format","82656c84":" Save metadata dataframes to *.csv files so that we don't have to redo this long computation.","fb55dcd2":"DICOM\u00ae \u2014 [Digital Imaging and Communications in Medicine](https:\/\/www.dicomstandard.org\/about-home) \u2014 is the international standard for medical images and related information. It defines the formats for medical images that can be exchanged with the data and quality necessary for clinical use. With hundreds of thousands of medical imaging devices in use, DICOM\u00ae is one of the most widely deployed healthcare messaging Standards in the world.","fd74d122":"### Insights on Metadata","1917e92b":"### **train\\** Dataset","41f48b31":"The [pydicom](https:\/\/pydicom.github.io\/pydicom\/stable\/getting_started.html) library allows us to conveniently read in DICOM files and access different values from the file. The actual image can be found in \"pixel_array\".","be887a40":"Replace with zeros all pixels with values below a threshold.","fa8f03b8":"\u2757\u2757\u2757 SAME AS FOR TRAIN \u2757\u2757\u2757(Confusing Colors)\n\ncount: \"axial\" > \"sagittal\" > \"coronal\"","179f6cbc":"**\/train**","90590436":"* Visualize 10 random observations and show the 4 datasets (FLAIR, T1w, T1wCE, T2w) for each.\n\n* Each dataset is a 3D scan \/ dataset and thus for simplicity visualize a specific slice for each dataset chosen by the variable $slice_i$","2acbad20":"**\\test**","5aa9bcf1":"**\/test - dataset**","4c719e30":"### 4.5 Slice Thickness","1163e456":"Exact folder structure:\n\n\n```\nTraining\/Validation\/Testing\n\u2502\n\u2514\u2500\u2500\u2500 00000\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500 FLAIR\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1wCE\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T2w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 .....\n\u2502   \n\u2514\u2500\u2500\u2500 00001\n\u2502   \u2502 ...\n\u2502   \n\u2502 ...   \n\u2502   \n\u2514\u2500\u2500\u2500 00002\n\u2502   \u2502 ...\n```","c9bff42b":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Pixel Representation](https:\/\/dicom.innolitics.com\/ciods\/segmentation\/image-pixel\/00280103): Data representation of the pixel samples. Each sample shall have the same pixel representation.\nEnumerated Values:\n    * 0000H: unsigned integer.\n    * 0001H: 2's complement. ","f5148576":"Get Orientation of each Image from coordinates [x1,y1,x2,y2] to coronal, axial or sagittal.","895b90cc":"Visualize the histogram distribution of all the scans for a random patient ID.","f0479f97":"### Look into label differences","1924fb2c":"<a id=\"15\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>5. EDA Pixel Data<center><h2>","a9c3c1f9":"### 4.7 Number Of Averages","0d8c4b5d":"So all patients in the train\/ ds had all 4 types of scans: T1w, T1wCE, T2w, FLAIR.","c2cb9aeb":"There are not any other obvious descrepancies between **train\\** and **test\\** from the value count, so we will continue looking into the train data for more insights below.","7a563d02":"So we are left with the following columns","34e04ded":"### 4.11 Pixel Representation","91d9c844":"### 4.12 Heatmap","d9c5726d":"### 4.6 MR Acquisition Type","bdde227c":"It's difficult to find and apply a lower threshold in each image in order to isolate the tumor and remove non-important features, as there is no single threshold that fits all the kinds of scans. This is because especially T1wCE is bright overall when the majority of features of FLAIR and T2w appear darker. The reason for this is that each of the different scan types capture and give emphasis on different pathological\/anatomical structures.","0a86d5fe":"Not very interesting patterns in term of metadata feature correlation.","fbb309b3":"**\/train\/ dataset**","9eb10bf5":"Plot Histogram of Pixel Values per Image","55be852e":"We are **probably** interested in the **blue-range** attributes mainly since, highly-unique and single value attributes, will not help learn new information that will help our model discriminate between different cases during training.","5463c302":"Here we extract all features for the training and testing set.","faa24172":"**train\/ dataset:** \n\nWe have a total of 585 directories, one for each patient, with 4 subdirectories corresponding to 4 scans per patient and total of 348641 dicom images","7a7bdaed":"Overall Orientation Distribution","fc66b545":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/29653\/logos\/header.png)","4badedff":"### In conclusion so far we can drop the following metadata attributes, since they probably won't help our model:\n* SOPInstanceUID\n* ImagePositionPatient\n* SliceLocation\n* WindowWidth\n* WindowCenter\n* SeriesInstanceUID\n* SAR\n* ImageOrientationPatient\n* ImagingFrequency\n* AccessionNumber\n* StudyInstanceUID\n* HighBit\n* RescaleIntercept\n* BitsStored\n* BitsAllocated\n* RescaleSlope\n* PatientPosition\n* PhotometricInterpretation\n* SamplesPerPixel\n* PositionReferenceIndicator\n* Laterality\n* ImageType\n* SpacingBetweenSlices\n* Modality\n* SOPClassUID\n* RescaleType","e6251364":"### For more details in pixel arrays see : [Working with Pixel Data](https:\/\/pydicom.github.io\/pydicom\/stable\/old\/working_with_pixel_data.html)","00e880dd":"* Similar Distributions for both Train and Test.\n* T2w has more sagittal images.\n* FLAIR more coronal\n* T1w and T1wCE many more axial.","c11156b9":"The work uses some ideas from next great works:\n- [EDA with Animation](https:\/\/www.kaggle.com\/avloss\/eda-with-animation) - animation technique","abaa1cb7":"The DICOM files in the **\\train** dataset have sizes between 0.1MB and 2.1MB (average 0.34MB).\n\nResult: DCM file sizes: min 0.0991MB max 2.08MB avg 0.341MB std 0.202MB","f2051a33":"Randomly choose a case to visualize and explore whether a threshold can be applied.","8059af83":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Slice Thickness](https:\/\/dicom.innolitics.com\/ciods\/ct-image\/image-plane\/00180050): Nominal slice thickness, in mm. \n* [Spacing Between Slices](https:\/\/dicom.innolitics.com\/ciods\/mr-image\/mr-image\/00180088): Spacing between slices, in mm. The spacing is measured from the center-to-center of each slice.","4ca17909":"# Advanced Exploratory Data Analysis\n## \ud83e\udde0 RSNA-MICCAI Brain Tumor Radiogenomic Classification \ud83e\udde0\n\n\n**Advanced Exploratory Data Analysis** and **Data Cleaning** for [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification) challenge with **useful insights**, **visualizations** and **extra resources** on MRI scans.\n\nNotebook based on the following fantastic notebooks: \n1. [\n\ud83e\udde0Brain Tumor\ud83e\udde0 - EDA with Animations and Modeling](https:\/\/www.kaggle.com\/ihelon\/brain-tumor-eda-with-animations-and-modeling)\n2. [Converting DICOM Metadata to CSV](https:\/\/www.kaggle.com\/carlolepelaars\/converting-dicom-metadata-to-csv-rsna-ihd-2019)\n3. [DICOM Metadata EDA](https:\/\/www.kaggle.com\/anarthal\/dicom-metadata-eda)\n4. [Pulmonary Dicom Preprocessing](https:\/\/www.kaggle.com\/allunia\/pulmonary-dicom-preprocessing#Prepare-to-start-) and \n5. [Insightful EDA on Meta Data & Dicom Files](https:\/\/www.kaggle.com\/jagdmir\/insightful-eda-on-meta-data-dicom-files).\n6. [BTRC EDA (Final)](https:\/\/www.kaggle.com\/josecarmona\/btrc-eda-final)\n7. [(Part-1) RSNA-MICCAI BTRC: Understanding The Data](https:\/\/www.kaggle.com\/arnabs007\/part-1-rsna-miccai-btrc-understanding-the-data)\n8. [\ud83e\udde0 DICOM to 2D Resized Axial PNGs 256x256 [x36] \ud83e\udde0](https:\/\/www.kaggle.com\/smoschou55\/dicom-to-2d-resized-axial-pngs-256x256-x36)","6fd44bca":"Same goes for the test dataset.","4a8b27d8":"* There are some descrepancy between test and train value counts.","f008d950":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [Series Description](https:\/\/dicom.innolitics.com\/ciods\/segmentation\/general-series\/0008103e): Description of Series. Long String (LO). \n\nIn our case: T1w, T1wCE, T2w, FLAIR","064d9506":"## Image Pixel Data Stats","660311a0":"## MRI Scan Basics\n\n**1. [MRI NHS Explanation](https:\/\/www.nhs.uk\/conditions\/mri-scan\/)**\n\nShort bursts of radio waves are then sent to certain areas of the body, knocking the protons out of alignment.\n- When the radio waves are turned off, the protons realign. This sends out radio signals, which are picked up by receivers.\n- **These signals provide information about the exact location of the protons in the body.**\n- **They also help to distinguish between the various types of tissue in the body, because the protons in different types of tissue realign at different speeds and produce distinct signals.**\n- **In the same way that millions of pixels on a computer screen can create complex pictures, the signals from the millions of protons in the body are combined to create a detailed image of the inside of the body.**\n- **Fourier Transform is used to get the final image from k-space.**\n\n**2. [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Magnetic_resonance_imaging)**\n\n **Definitions**\n- **T1-weighted**: \nThe dominant signal intensities of different tissues are:\n    - Lower signal for more water content, as in edema, tumor, infarction, inflammation, infection, hyperacute or chronic hemorrhage.\n    - High signal for fat\n    - High signal for paramagnetic substances, such as MRI contrast agents\n_Standard foundation and comparison for other sequences_\n- **Constrast**:\n    - T1 - signal increase. Pathological tissues (tumours, areas of inflammation \/ infection) will demonstrate accumulation of contrast (mostly due to leaky blood vessels) and therefore appear as brighter than surrounding tissue. \n    - Often post contrast T1 sequences are also fat suppressed (see below) to make this easier to appreciate. Fat suppression (or attenuation or saturation) is a tweak performed on many T1 weighted sequences, to suppress the bright signal from fat.\n- **T2-weighted**: \n    - Higher signal for more water content\n    - Low signal for fat\n    - Low signal for paramagnetic substances\n_Standard foundation and comparison for other sequences_\n- **FLAIR**:\n    - Fluid suppression by setting an inversion time that nulls fluids\n\n**3. For Intuitive MRI-scan examples see: [The Basics of MRI Interpretation](https:\/\/geekymedics.com\/the-basics-of-mri-interpretation\/)**\n\n**4. For a good explanation of T1w, T1wCE, T2w, FLAIR see: [Radiopaedia: MRI sequences](https:\/\/radiopaedia.org\/articles\/mri-sequences-overview?lang=gb)**\n\n**5. For a detailed list of DICOM metadata attributes and explanations see: [DICOM Attributes](https:\/\/dicom.innolitics.com\/ciods\/mr-image\/mr-image\/00181100).**","f70751e7":"<a id=\"20\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>6. 3D Visualizations<center><h2>","30cab419":"<a id=\"30\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>7. Conclusions<center><h2>","900f6e12":"So all patients in the test\/ ds had all 4 types of scans: T1w, T1wCE, T2w, FLAIR.","d505263a":"**Let's see if all images per patient and per modality have the same orientation**","867d0d20":"**Definitions from [DICOM Standard Website](https:\/\/dicom.innolitics.com\/ciods)**\n* [MR Acquisition Type\n](https:\/\/dicom.innolitics.com\/ciods\/mr-image\/mr-image\/00180023): Identification of data encoding scheme.Enumerated Values\n    * 2D: frequency x phase\n    * 3D: frequency x phase x phase","c8294e2a":"* AccessionNumber, PatientID and StudyInstanceUID seem to be unique per patient as there are 585 and 87 unique values for **train\/** and **test\/** datasets, i.e. as many patients there are in each ds respectively. So we can either drop them all and only keep PatientID as the patient identifier."}}