{"cell_type":{"92349814":"code","97f486f2":"code","1e318594":"code","ed2217eb":"code","712fe2a1":"code","7b621f07":"code","1a8b4d2b":"markdown","1c92f7ca":"markdown","bf1cd1fc":"markdown","98fa5edb":"markdown","9175913c":"markdown","72813e8f":"markdown","a09b914a":"markdown","fe64cef5":"markdown","9ce989c1":"markdown","76218619":"markdown","f89391e4":"markdown","3d50c1b5":"markdown","80d49ee4":"markdown","01997109":"markdown","a794ea80":"markdown","5b88f590":"markdown","eaf50edf":"markdown","98369859":"markdown","a34a1d38":"markdown"},"source":{"92349814":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","97f486f2":"dataset = pd.read_csv('..\/input\/position-salaries\/Position_Salaries.csv')\nX = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values","1e318594":"from sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(X, y)","ed2217eb":"regressor.predict([[6.5]])","712fe2a1":"X_grid = np.arange(min(X), max(X), 0.01)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n'''\nHere we are predicting each and every value of X starting from level 1 till level 10 with an interval of 0.01 to know the outcome and plot each value, as we plot each value we can\nsee that the model is predicting same outcome for level 1.5 to 2.5 as salary of a level 2, 2.5 to 3.5 as outcome of salary of level 3\nIf we haven't predicted outcome of each value we will get a graph which is drawn in the next \ncode cell and there is very less to interpret from that.\n'''\nplt.title('Truth or Bluff (Decision Tree Regression)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","7b621f07":"plt.scatter(X, y, color = 'red')\nplt.plot(X, regressor.predict(X), color = 'blue')\nplt.title('Truth or Bluff (Decision Tree Regression)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","1a8b4d2b":"We will be using the same dataset used in the SVR and other to train the model and then predict the salary of a person who is in between level 6 & 7.","1c92f7ca":"For better understanding of current notebook for beginners go through the links:\n\n [1.1 Data Preprocessing](http:\/\/www.kaggle.com\/saikrishna20\/data-preprocessing-tools)\n\n\n[1.2 Simple linear Regression](https:\/\/www.kaggle.com\/saikrishna20\/1-2-simple-linear-regression) \n\n\n[1.3 Multiple linear Regression with Backward Elimination](http:\/\/www.kaggle.com\/saikrishna20\/1-3-multiple-linear-regression-backward-eliminat)\n\n[1.4 Polynomial Linear Regression](https:\/\/www.kaggle.com\/saikrishna20\/1-4-polynomial-linear-regression)\n\n[1.5 Support Vector Regression (SVR)](https:\/\/www.kaggle.com\/saikrishna20\/1-5-support-vector-regression-svr\/edit\/run\/37240657)\n\n\nIt basically tells u about the preprocessing & Linear Regression which will help u in understanding this notebook better","bf1cd1fc":"# Like this notebook then upvote it.\n\n# Need to improve it then comment below.\n\n# Enjoy Machine Learning","98fa5edb":"## Importing the dataset","9175913c":"Decision Tree works better with multiple feature data i.e X should be multiple columns.\n\nHere we are going to go with single feature as it will have an advantage to visualise the result in a 2 Dimensional plot.\n\nsuppose if we have 5 features then there will be total 6 items including the output to show on the graph and it's not possible to show the 6 dimensions hence we are sticking to a single feature dataset. for our understanding.","72813e8f":"**Decision Tree unlike other models doesn't use mathematic equations to predict the value\/ Traget as it uses a splitting of nodes and make branches and sub-nodes.**\n\n**Hence we dont have to scale the data.**","a09b914a":"# 1.6 Decision Tree Regression","fe64cef5":"![decitree.png](attachment:decitree.png)","9ce989c1":"![Decision_Tree-2.png](attachment:Decision_Tree-2.png)","76218619":"There is a little tuning we can do for the model to work better, but let's go with basics here.\n\nWe are fixing the random seed\/ random_state to some value so that we can reproduce the same results everytime.\n\n","f89391e4":"For a better understanding of Decision Tree if u don't have any idea whatsoever, visit the links:\n\n[Decision Tree Intuition 1](https:\/\/www.geeksforgeeks.org\/decision-tree\/)\n\n[Decision Tree Intuition 2](https:\/\/www.kdnuggets.com\/2020\/01\/decision-tree-algorithm-explained.html)\n","3d50c1b5":"## Visualising the Decision Tree Regression results (higher resolution)","80d49ee4":"From the plot we can say that the model has trained in a way to predict and this is how it goes:\n\nfrom level 3.5 to 4.5 it predicts every feature value as same as level 4 it goes on for all levels.\n\nfor level 6.5 it predicted the target as 150000 because the model thought that from level 5.5 to 6.5 every feature value will be equal to level 6 i.e the model thinks of a range which will be a node and if a certain feature in that node yes then certain output if not more splitting of nodes and branches.\n\nHence this decision tree is prefered for more features insted of a single feature.\n\n","01997109":"Visualising in general which doesn't make any sense so better go with the higher resolution model. as it doesn't show the stepping range for each point.","a794ea80":"## Predicting a new result","5b88f590":"let's predict the salary of a person who is in between level 6 & 7","eaf50edf":"## Importing the libraries","98369859":"# Visualising the Decision Tree Regressor ","a34a1d38":"## Training the Decision Tree Regression model on the whole dataset"}}