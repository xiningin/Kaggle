{"cell_type":{"c1fc2392":"code","1d9c9b96":"code","50ba7845":"code","d769f6a8":"code","a0dc2e9a":"code","1c1a1d7e":"code","d8e9fce7":"code","ce29dc8d":"code","a0640017":"code","99c5363a":"code","f27b268b":"code","cacfe32c":"code","53fc67b4":"code","ee4fa26e":"code","455769b3":"code","235a585a":"code","1723f5d0":"code","f9497ac7":"code","9eeaa185":"code","fe3bb05a":"code","44bd63e5":"markdown","0ad0e5fe":"markdown","b3fa4f90":"markdown","3a67973c":"markdown","9219b4bc":"markdown","91a891d1":"markdown","159da4b7":"markdown","326e00a9":"markdown","1397a509":"markdown","e21f4d4a":"markdown","a7a479f3":"markdown","a29dcadd":"markdown","18d62deb":"markdown"},"source":{"c1fc2392":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d9c9b96":"\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport warnings\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom scipy.stats import skew\nfrom scipy import stats\nfrom scipy.stats.stats import pearsonr\nfrom scipy.stats import norm\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve,train_test_split\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler, Normalizer, RobustScaler,LabelEncoder\nfrom collections import Counter\nwarnings.filterwarnings('ignore')\nsns.set(style='white', context='notebook', palette='deep')","50ba7845":"train = pd.read_csv(\"\/kaggle\/input\/glass-quality-prediction\/Train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/glass-quality-prediction\/Test.csv\")\ntrain.head()\n","d769f6a8":"test.head()","a0dc2e9a":"train.describe()","1c1a1d7e":"print(train.isnull().mean())#checking null value","d8e9fce7":"sns.boxplot(x=\"class\",y=\"max_luminosity\", data=train)#outliers\nsns.boxplot(x=\"class\",y=\"thickness\", data=train)#outliers\nsns.boxplot(x=\"class\",y=\"ymin\", data=train)#outliers\n","ce29dc8d":"from scipy import stats#removing using zscore\nimport numpy as np\nz = np.abs(stats.zscore(train))\nprint(train.shape)\ntrain = train[(z < 3).all(axis=1)]\nprint(train.shape)","a0640017":"sns.boxplot(x=\"class\",y=\"max_luminosity\", data=train)#outliers\nprint(train[\"max_luminosity\"].skew())#before\ntrain[\"max_luminosity\"] = train[\"max_luminosity\"].map(lambda i: np.log(i) if i > 0 else 0) \nprint(train[\"max_luminosity\"].skew())#after\n'''\nsns.boxplot(x=\"class\",y=\"thickness\", data=train)#outliers\nprint(train[\"thickness\"].skew())\ntrain[\"thickness\"] = train[\"thickness\"].map(lambda i: np.log(i) if i > 0 else 0) \nprint(train[\"thickness\"].skew())'''","99c5363a":"fig, axs = plt.subplots(nrows=1, figsize=(13, 9))\nsns.heatmap(train.corr(),\n            annot=True, square=True, cmap='YlGnBu', linewidths=2, linecolor='black',\n            annot_kws={'size':12})","f27b268b":"dataset = pd.concat([train,test],sort=False,ignore_index=True)#combine so easily drops columns\n#always drop columns from test and train data both ore it will produce very poor results\ndataset.drop([\"xmax\",'ymax','pixel_area',\"x_component_1\",\"x_component_4\",\"x_component_5\",\n             \"grade_A_Component_1\"],axis=1,inplace=True)\n# i remove few other columns too as their value is never changing alsways the same throughout data\n\n","cacfe32c":"train = dataset[:len(train)]\ny_train = train[\"class\"].values\nx_train = train.drop(\"class\", axis=1)\ntest = dataset[len(train):].drop(\"class\",axis=1)","53fc67b4":"#always apply scalling as i do\n#never to scale target data..... or predictions\nscaler = MinMaxScaler()\nscaler.fit(x_train)# this should remain same for train and test both\nscaled_train = scaler.transform(x_train)\nscaled_test = scaler.transform(test)\nprint(scaled_train)","ee4fa26e":"X_train,X_test,y_train,y_test = train_test_split(scaled_train,y_train,random_state=1)\n","455769b3":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier,StackingClassifier,RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.pipeline import Pipeline, make_pipeline","235a585a":"lr = LogisticRegression(C=1)\nmlp = MLPClassifier(hidden_layer_sizes=[100, 100],alpha=.1,learning_rate=\"constant\",)\nxgb = XGBClassifier(gamma = .0001, learning_rate = .1, max_depth = 3, n_estimators = 100)              \ngboost = GradientBoostingClassifier(learning_rate = 0.01, max_depth = 4, n_estimators = 100)\nbayes = GaussianNB()\nrfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=12, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)","1723f5d0":"#use grid search to find best parameters for every model\ngrid_param = { 'hidden_layer_sizes': [[100,100]], \n              'alpha': [.0001,.001,.01,.1,1] }\ngrid_search = GridSearchCV(MLPClassifier(), grid_param,cv=5)\ngrid_search.fit(X_train,y_train)\ny_pred = grid_search.predict(X_test)\nprint(grid_search.best_params_)#it will show the best parameters\n#u can also use pipeline and robust feature on classifier for more functionality","f9497ac7":"clf_isotonic = CalibratedClassifierCV(rfc, cv=2, method='isotonic')\nclf_isotonic.fit(X_train,y_train)\ny_rfc = clf_isotonic.predict_proba(X_test)\nprint(clf_isotonic.score(X_train, y_train))\n","9eeaa185":"def get_models():\n\tmodels = dict()\n\tmodels['lr'] = lr\n\tmodels['mlp'] = mlp\n\tmodels['xgb'] = xgb\n\tmodels['gboost'] = gboost\n\tmodels['bayes'] = bayes\n\treturn models\n\n\n# get a stacking ensemble of models\ndef get_stacking():\n\t# define the base models\n\tlevel0 = list()\n\tlevel0.append(('lr', lr))\n\tlevel0.append(('mlp', mlp))\n\tlevel0.append(('xgb', xgb))\n\tlevel0.append(('gboost', gboost))\n\tlevel0.append(('bayes', bayes))\n\t# define meta learner model\n\tlevel1 = LogisticRegression()\n\t# define the stacking ensemble\n\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n\treturn model\n\n \n# evaluate a given model using cross-validation\ndef evaluate_model(model):\n\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\tscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n\treturn scores\n \n# get the models to evaluate\nmodels = get_models()\nmodels['staking'] = get_stacking()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n\tscores = evaluate_model(model)\n\tresults.append(scores)\n\tnames.append(name)\n# plot model performance for comparison\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","fe3bb05a":"def get_stacking():\n\t# define the base models\n\tlevel0 = list()\n\tlevel0.append(('lr', lr))\n\tlevel0.append(('mlp', mlp))\n\tlevel0.append(('xgb', xgb))\n\tlevel0.append(('gboost', gboost))\n\tlevel0.append(('rfc', rfc))\n    \n\t# define meta learner model\n\tlevel1  = LogisticRegression()\n\t# define the stacking ensemble\n\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n\treturn model\nmodel = get_stacking()\nmodel.fit(X_train,y_train)\ny_pred = model.predict_proba(X_test)\nprint(model.score(X_train, y_train))\nprint(model.score(X_test, y_test))\n\noutput = pd.DataFrame({1:y_pred[:,0], 2:y_pred[:,1]})\noutput.to_excel(\"submitted.xlsx\",index=False)","44bd63e5":"> now we apply stacking model where we use all above models","0ad0e5fe":"**u can see our training and test score is quite good**\n> if u face any problem or have any question u can ask below in comments","b3fa4f90":"**no null data in train and test**","3a67973c":"**xmin and xmax are correlated, ymin,ymax also related, pixel_area and log area too... they are perfectly positively co related so need to be removed\ngrade_A_Component_1 and grade_A_Component_2 are also perfectlt negetively related so need to be removed","9219b4bc":"check for correlation in datasets","91a891d1":"**removing outliers from training data only never remove from test data.....","159da4b7":"**Scalling of data","326e00a9":"**MODELING**","1397a509":"now how to use single model and then we will use stacking model","e21f4d4a":"**final predictions**","a7a479f3":"**seperating train and test data","a29dcadd":"**now we apply log function to remove skewness from data and in output we see decrement in skewness of data so thats good","18d62deb":"here u can see accuracy of our all models \n> **our stacking model perform quite well** but its not always perform good"}}