{"cell_type":{"5c093dd0":"code","105a8971":"code","4ceafaa9":"code","455ec0f6":"code","80f8c2fb":"code","c4997693":"code","7bf3ed5d":"code","d1ce6c61":"code","e06cf7e0":"code","b13cfc6e":"code","1364017f":"code","367e092a":"code","f3d95437":"code","377defaf":"code","7c426b10":"code","325be0b0":"code","0ef036ac":"code","7863d6bd":"code","c2cbcb61":"code","e5a09ac6":"code","4d1ccb0d":"code","b89619bf":"code","1527b67b":"code","f843ef08":"code","65ee6341":"code","b0b99e88":"code","5414d55d":"code","ce70601e":"code","9ac90237":"code","f06b2472":"code","37e8e521":"code","a7c7173d":"code","fe80b87b":"code","594718ce":"code","785a9dcd":"code","02aea29d":"code","d8510a9e":"code","a914fd17":"code","0b1beaea":"code","dc1d0856":"code","82317d6d":"code","bb528f05":"code","6c4dbd75":"code","1e5d1a63":"code","41b4565d":"code","020764e0":"code","892af448":"markdown","410cfdbf":"markdown","f4e16822":"markdown","b9e3220d":"markdown","acc2376b":"markdown","2e2401da":"markdown","8e92c6f4":"markdown","65449cc8":"markdown","1b4f2619":"markdown","adf7398a":"markdown","cd6ccbfe":"markdown","d87e92e9":"markdown","e5b6776d":"markdown","e8189b3f":"markdown","9178b5a1":"markdown","19a1889b":"markdown","dddfe23f":"markdown","18af89a0":"markdown","8f5d19eb":"markdown","d60fde04":"markdown","b4fffde4":"markdown","27fcdf9b":"markdown"},"source":{"5c093dd0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","105a8971":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px \nfrom matplotlib import pyplot\nfrom pandas.plotting import autocorrelation_plot\nfrom pandas import DataFrame\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4ceafaa9":"df = pd.read_csv(\"..\/input\/world-population-by-year\/WorldPopulation.csv\") ","455ec0f6":"df.columns","80f8c2fb":"df.head()","c4997693":"df.tail()","7bf3ed5d":"df.shape","d1ce6c61":"df.describe()","e06cf7e0":"df.describe().T","b13cfc6e":"df.info()","1364017f":"import missingno as msn\nmsn.matrix(df)","367e092a":"df.isnull().sum()","f3d95437":"plt.scatter(df['Year'],df[ 'Population'])","377defaf":"x = df['Year']\ny = df['Density']\nplt.plot(x,y)\nplt.xlabel('Year')\nplt.ylabel('Density')","7c426b10":"x = df['Year']\ny = df['Urban']\nplt.plot(x,y)\nplt.xlabel('Year')\nplt.ylabel('Urban')","325be0b0":"x = df['Year']\ny = df['UrbanPerc']\nplt.plot(x,y)\nplt.xlabel('Year')\nplt.ylabel('UrbanPerc')","0ef036ac":"plt.xlabel('Year')\nplt.ylabel('Density')\nplt.scatter(df['Year'],df['Density'])","7863d6bd":"plt.xlabel('Year')\nplt.ylabel('Urban')\nplt.scatter(df['Year'],df['Urban'])","c2cbcb61":"fig=plt.figure(figsize=(15,10))\nplt.bar(df['Year'],df.Population)\nplt.bar(df['Year'],df.Urban)\nplt.xlabel(\"Year\")\nplt.show()","e5a09ac6":"plt.figure(figsize=(20,15))\nsns.barplot(df.Year[:50],df.Density)","4d1ccb0d":"plt.hist(df.Urban)\nplt.show","b89619bf":"plt.hist(df.NetChange)\nplt.show","1527b67b":"corr=df.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr,annot=True, cmap='RdYlBu')","f843ef08":"!pip install dabl","65ee6341":"# comparison of all other attributes with respect to Math Marks\n\nimport dabl\n\nplt.rcParams['figure.figsize'] = (18, 6)\nplt.style.use('fivethirtyeight')\ndabl.plot(df, target_col = 'Population')","b0b99e88":"# Skewness of the Data. \n\nplt.subplot(1, 3, 1)\nsns.distplot(df['Urban'],color = 'magenta')\n\nplt.subplot(1, 3, 2)\nsns.distplot(df['NetChange'],color = 'magenta')\n\nplt.subplot(1, 3, 3)\nsns.distplot(df['ChangePerc'],color = 'magenta')\n\nplt.suptitle('Checking for Skewness', fontsize = 18)\nplt.show()","5414d55d":"x= df.iloc[:, :-6].values     # for Year \ny= df.iloc[:, 1].values        # For population ","ce70601e":"from sklearn.model_selection import train_test_split  \nx_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 1\/3, random_state=0)  ","9ac90237":"#Fitting the Simple Linear Regression model to the training dataset  \nfrom sklearn.linear_model import LinearRegression  \nregressor= LinearRegression()  \nregressor.fit(x_train, y_train)  ","f06b2472":"#Prediction of Test and Training set result  \ny_pred= regressor.predict(x_test)  \nx_pred= regressor.predict(x_train)  ","37e8e521":"plt.scatter(x_train, y_train, color=\"green\")   \nplt.plot(x_train, x_pred, color=\"red\")    \nplt.title(\"Population with Years \")  \nplt.xlabel(\"Year\")  \nplt.ylabel(\"Population\")  \nplt.show()   ","a7c7173d":"from sklearn.metrics import mean_squared_error\nmean_squared_error(x_train,x_pred) ","fe80b87b":"#visualizing the Test set results  \nplt.scatter(x_test, y_test, color=\"blue\")   \nplt.plot(x_train, x_pred, color=\"red\")    \nplt.title(\"Population with Years \")  \nplt.xlabel(\"Year\")  \nplt.ylabel(\"Population\")  \nplt.show()  ","594718ce":"print(regressor.score(x_test, y_test))","785a9dcd":"from sklearn.preprocessing import PolynomialFeatures  \npoly_regs= PolynomialFeatures(degree= 6)  # For better accuracy we can use 3,4,5,6 also. \nx_poly= poly_regs.fit_transform(x)  \nlin_reg_2 =LinearRegression()  \nlin_reg_2.fit(x_poly, y)  ","02aea29d":"#Visulaizing the result for Polynomial Regression  \nplt.scatter(x,y,color=\"blue\")  \nplt.plot(x, lin_reg_2.predict(poly_regs.fit_transform(x)), color=\"red\")  \nplt.title(\"Population with Years \")  \nplt.xlabel(\"Year\")  \nplt.ylabel(\"Population\")   \nplt.show()  ","d8510a9e":"print(lin_reg_2.score(x_poly, y))","a914fd17":"import xgboost as xgb\nmodel = xgb.XGBRegressor(n_estimators = 100, max_depth = 85, random_state = 52).fit(x_train, y_train)\npred = model.predict(x_test)\npred\nmodel.score(x_test, y_test)","0b1beaea":"df1 = df[['Year', 'Population']]","dc1d0856":"df1","82317d6d":"plt.plot(df1['Year'],df1['Population'])\nplt.xlabel(\"Year\")\nplt.ylabel(\"Population\")\nplt.show()","bb528f05":"# perform Dickey-Fuller test\nfrom statsmodels.tsa.stattools import adfuller\n\nprint('Results of Dickey-Fuller Test')\n\ndftest = adfuller(df1.Population, autolag='AIC') \n\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p value','#Lags used', 'No:of observations found'])\nfor key, value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\n    \nprint(dfoutput)","6c4dbd75":"pip install pmdarima","1e5d1a63":"from statsmodels.tsa.arima_model import ARIMA\nimport pmdarima as pm\n\nmodel = pm.auto_arima(df1['Population'], start_p=1, start_q=1,\n                      test='adf',       # use adftest to find optimal 'd'\n                      max_p=3, max_q=3, # maximum p and q\n                      m=1,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\n\nprint(model.summary())","41b4565d":"model.plot_diagnostics(figsize=(7,5))\nplt.show()","020764e0":"# Forecast\n\nn_periods = 2400\nfc, confint = model.predict(n_periods=n_periods, return_conf_int=True)\nindex_of_fc = np.arange(len(df1['Population']), len(df1['Population'])+n_periods)\n\n# make series for plotting purpose\nfc_series = pd.Series(fc, index=index_of_fc)\nlower_series = pd.Series(confint[:, 0], index=index_of_fc)\nupper_series = pd.Series(confint[:, 1], index=index_of_fc)\n\n# Plot\nplt.plot(df1['Population'])\nplt.plot(fc_series, color='darkgreen')\nplt.fill_between(lower_series.index, \n                 lower_series, \n                 upper_series, \n                 color='k', alpha=.15)\n\nplt.title(\"Final Forecast\")\nplt.show()","892af448":"# We can find that Our Polynomial Regression with this degree have highest score such as 99.98 % ","410cfdbf":"# There is a increment in Population and urban population with respect to Years Increse.","f4e16822":"# There are no null values here. ","b9e3220d":"# XGBOOST","acc2376b":"# View the Data","2e2401da":"- This is Linear but I think Simple Linear Regression couldn't be a good choice. This should be Polynomial Regression.","8e92c6f4":"# Not Same Growth rate in Urban Population with the Years.","65449cc8":"# Variables:\n- Year: 1951 to 2020\n- Population: World Population\n- ChangePerc: Yearly Change in Percentage\n- NetChange: Total Yearly Change\n- Density: Density in P\/Km\u00b2\n- Urban: Urban Population\n- UrbanPerc: Urban Population Percentage","1b4f2619":"# Auto Arima Forecast in Python\n","adf7398a":"# Correlation ","cd6ccbfe":"# There is a positive growth in the density also. ","d87e92e9":"# Polynomial Regression","e5b6776d":"# Descriptive Statistics\n\n","e8189b3f":"# Reading the Data","9178b5a1":"# Now we can see clearly through the Heatmap our positive and Negative Relationship ","19a1889b":"# Thanks ","dddfe23f":"# Importing the Libraries ","18af89a0":"# Linear Regression ","8f5d19eb":"# Predictions","d60fde04":"# NetChange is high or low but it is also not regular, ","b4fffde4":"# Time Series ","27fcdf9b":"# 1. We want to predict the Population of the Upcoming Years. "}}