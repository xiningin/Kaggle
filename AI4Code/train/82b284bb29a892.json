{"cell_type":{"8be064fc":"code","1de2b98c":"code","778527d8":"code","54190e66":"code","1cc56814":"code","0b90cbfc":"code","e1200817":"code","d2e7c4c0":"code","d9e5bc05":"code","49ec5edc":"code","aebc8d33":"code","c4303d8a":"code","220d0c13":"code","65dcf271":"code","0ebf445d":"code","c6e2c59a":"code","28a68c4e":"code","f3e9d69d":"code","238a40df":"code","2aba1b7f":"code","d9f0dc50":"code","3275d126":"code","e6361a5d":"code","4ea28229":"code","e40cdd4e":"code","dc864f56":"code","de10ebfa":"code","6ffb2359":"code","4c56ca11":"code","37560411":"code","c15fb711":"code","46b1be9a":"code","515ad961":"code","ade82909":"code","41d9b962":"code","84b424ae":"code","7207db12":"code","21515702":"code","8c41b978":"code","7cc61c1b":"code","10aef35d":"code","d8288ee0":"code","d92838bd":"code","310a0403":"code","a6682cba":"code","ba1c3e46":"code","6a22bc43":"code","a84d465a":"code","31dd19ee":"code","3f3fb4d8":"code","241e1ac8":"code","bed66bc5":"code","877d3341":"code","dc254760":"code","7092e7fe":"code","3bfaf164":"code","e8c80450":"code","cfe511df":"code","707e8e48":"code","1ee4f300":"code","2c195ee8":"code","f345280d":"code","6fd61b6f":"code","800d764b":"code","bced69e5":"code","46bf386a":"code","875540b6":"code","372b97a3":"code","d9a96e71":"code","6efe5931":"code","356d1c1d":"code","c6cb3187":"code","ac69f3e9":"code","68b159dc":"code","4659e30f":"code","9a219342":"code","e93bbd41":"code","79487c1a":"code","8a4471c6":"code","c0e9da25":"code","5b287c7c":"code","d2e69806":"code","ba866d34":"code","1c3ca3c6":"code","3ec7b08f":"code","8895ecff":"code","51ca2ea6":"code","36d47950":"markdown","936e9bf7":"markdown","017d14e8":"markdown","67f06398":"markdown","055ab4a2":"markdown","67075fa2":"markdown","dccda59a":"markdown","353c1f8c":"markdown","656ce329":"markdown","efec59ea":"markdown","bd0ef86e":"markdown","b7373dc5":"markdown","e78fad59":"markdown","5b74a2e2":"markdown","f192826d":"markdown","842af041":"markdown","ef078325":"markdown","a49522e8":"markdown","d977290a":"markdown","72fdae8b":"markdown","3bda32a4":"markdown","143fa37b":"markdown","dfb3f4ce":"markdown","a78221bf":"markdown","ef15f1fe":"markdown","a42a3f3f":"markdown","c3be781a":"markdown","2c81ab60":"markdown","018bf0e8":"markdown","a657104f":"markdown","161c956c":"markdown","91149f9d":"markdown","56565229":"markdown","9fcd1801":"markdown","3deafd2f":"markdown","3db55de6":"markdown","5552c556":"markdown","7d2f2d1f":"markdown","0b74c363":"markdown","a56b2b04":"markdown","f59b0c93":"markdown","d93266c6":"markdown","4ae7788a":"markdown","5fc20034":"markdown"},"source":{"8be064fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1de2b98c":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","778527d8":"train_df.columns","54190e66":"train_df.head()","1cc56814":"train_df.describe()","0b90cbfc":"train_df.info()","e1200817":"def bar_plot(variable):\n    var = train_df[variable] # get feature\n    varValue = var.value_counts()#count number of categorical variables\n    \n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"variable\")\n    plt.show\n    print(\"{}: \\n {}\".format(variable, varValue))","d2e7c4c0":"category1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\nfor c in category1:\n     bar_plot(c)\n        ","d9e5bc05":"category2 = [\"Name\",\"Cabin\",\"Ticket\"]\nfor c in category2: \n    print(\"{} \\n\".format(train_df[c].value_counts()))","49ec5edc":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable])\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    ","aebc8d33":"numericVar = [\"Fare\", \"Age\", \"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","c4303d8a":"train_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","220d0c13":"train_df[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","65dcf271":"train_df[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","0ebf445d":"train_df[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","c6e2c59a":"def detect_outliers(df, features):\n    outlier_indices = []\n    \n    for c in features:\n        Q1 = np.percentile(df[c],25)\n        Q3 = np.percentile(df[c],75)\n        \n        IQR = Q3 - Q1\n        outlier_step = IQR * 1.5   # outlier step\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index # detect outlier and their indeces\n        outlier_indices.extend(outlier_list_col) # store indeces\n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    return(multiple_outliers)\n        ","28a68c4e":"train_df.loc[detect_outliers(train_df,[\"Age\", \"SibSp\", \"Parch\", \"Fare\"])]","f3e9d69d":"train_df = train_df.drop(detect_outliers(train_df,[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]), axis = 0).reset_index(drop = True)","238a40df":"train_df_len= len(train_df)\ntrain_df = pd.concat([train_df,test_df], axis = 0).reset_index(drop = True)","2aba1b7f":"train_df.columns[train_df.isnull().any()]","d9f0dc50":"train_df.isnull().sum()","3275d126":"train_df[train_df[\"Embarked\"].isnull()]","e6361a5d":"train_df.boxplot(column=\"Fare\", by = \"Embarked\")\nplt.show()","4ea28229":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","e40cdd4e":"train_df[train_df[\"Fare\"].isnull()]","dc864f56":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","de10ebfa":"train_df[train_df[\"Fare\"].isnull()]","6ffb2359":"list1 = [\"SibSp\" , \"Parch\" , \"Age\" , \"Fare\" , \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","4c56ca11":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\",data = train_df,kind = \"bar\", size = 9)\ng.set_ylabels(\"Survived Probablity\")\nplt.show()","37560411":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df,size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","c15fb711":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\",data = train_df , kind = \"bar\", size = 6)\nplt.show()","46b1be9a":"g = sns.FacetGrid(train_df, col = \"Survived\" )\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","515ad961":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\")\ng.map(plt.hist, \"Age\",bins = 25)\ng.add_legend()\nplt.show()","ade82909":"g = sns.FacetGrid(train_df,  row = \"Embarked\")\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\",bins = 25)\ng.add_legend()\nplt.show()","41d9b962":"#Female survival rate better than male","84b424ae":"g = sns.FacetGrid(train_df, row = \"Embarked\",col = \"Survived\")\ng.map(sns.barplot,\"Sex\",\"Fare\")\ng.add_legend()\nplt.show()","7207db12":"# passenger who pay high fare have better survival","21515702":"train_df[train_df[\"Age\"].isnull()]","8c41b978":"sns.factorplot(x = \"Sex\",y = \"Age\",data = train_df,kind = \"box\")\nplt.show()","7cc61c1b":"sns.factorplot(x = \"Sex\",y = \"Age\",hue = \"Pclass\" ,data = train_df,kind = \"box\")\nplt.show()","10aef35d":"sns.factorplot(x = \"Parch\",y = \"Age\",data = train_df,kind = \"box\")\nsns.factorplot(x = \"SibSp\",y = \"Age\",data = train_df,kind = \"box\")\nplt.show()","d8288ee0":"train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","d92838bd":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),annot = True)","310a0403":"# age is not correlated with sex but age is correlated with parch,SibSp","a6682cba":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nindex_nan_age\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) & (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"]) & (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_pred = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","ba1c3e46":"train_df[train_df[\"Age\"].isnull()]","6a22bc43":"age_pred","a84d465a":"train_df[\"Name\"].head(10)","31dd19ee":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","3f3fb4d8":"train_df[\"Title\"].head(10)","241e1ac8":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","bed66bc5":"#Convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Don\",\"Rev\",\"Dr\",\"Mme\",\"Mile\",\"Sir\",\"Lady\",\"Dona\",\"jonkheer\",\"the Countess\",\"Major\",\"Capt\",\"Col\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]","877d3341":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()\n","dc254760":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","7092e7fe":"train_df.drop(labels = [\"Name\"],axis = 1 , inplace = True)\ntrain_df.head()","3bfaf164":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","e8c80450":"train_df.head()","cfe511df":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","707e8e48":"train_df.head()","1ee4f300":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\n\ng.set_ylabels(\"Survival Probability\")\nplt.show()","2c195ee8":"train_df[\"Family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","f345280d":"train_df.head(25)","6fd61b6f":"sns.countplot(x=\"Family_size\", data = train_df)\nplt.show()\n","800d764b":"g = sns.factorplot(x = \"Family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\n\ng.set_ylabels(\"Survival Probability\")\nplt.show()","bced69e5":"train_df = pd.get_dummies(train_df,columns=[\"Family_size\"])\ntrain_df.head()","46bf386a":"sns.countplot(x=\"Embarked\", data = train_df)\nplt.show()","875540b6":"train_df = pd.get_dummies(train_df,columns=[\"Embarked\"])\ntrain_df.head()","372b97a3":"train_df[\"Ticket\"].head(25)","d9a96e71":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","6efe5931":"train_df[\"Ticket\"].head(15)","356d1c1d":"train_df = pd.get_dummies(train_df,columns=[\"Ticket\"],prefix = \"T\")\ntrain_df.head()","c6cb3187":"sns.countplot(x=\"Pclass\", data = train_df)\nplt.show()","ac69f3e9":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df,columns=[\"Pclass\"])\ntrain_df.head()","68b159dc":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df,columns=[\"Sex\"])\ntrain_df.head()","4659e30f":"train_df.drop(labels = [\"PassengerId\",\"Cabin\"], axis = 1,inplace = True)","9a219342":"train_df.columns","e93bbd41":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","79487c1a":"train_df_len","8a4471c6":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"], axis = 1, inplace = True)\ntest.head()","c0e9da25":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train , test_size = 0.33, random_state = 42)\nprint(\"X_train\", len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_test\",len(y_test))\nprint(\"y_train\",len(y_train))\nprint(\"test\",len(test))","5b287c7c":"\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2)\nacc_log_test = round(logreg.score(X_test, y_test)*100,2)\nprint(\"Training accuracy: % {}\".format(acc_log_train))\nprint(\"Testing accuracy: % {}\".format(acc_log_test))","d2e69806":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\" : range(1,20,2)}\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\" : [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\nrf_param_grid = {\"max_features\" : [1,3,10],\n                \"min_samples_split\" : [2,3,10],\n                \"bootstrap\" : [False],\n                \"n_estimators\" : [100,300],\n                \"criterion\" : [\"gini\"]}\nlogreg_param_grid = {\"C\" : np.logspace(-3,3,7),\n                    \"penalty\" : [\"l1\",\"l2\"]}\nknn_param_grid = {\"n_neighbors\" : np.linspace(1,19,10, dtype = int).tolist(),\n                  \"weights\" : [\"uniform\",\"distance\"],\n                  \"metric\" : [\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid,\n                   ]\n        \n                 ","ba866d34":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid = classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1, verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","1c3ca3c6":"cv_results = pd.DataFrame({\"Cross Validation Means\" : cv_result, \"ML Models\":[\"DecisionTreeClassifier\",\"SVM\",\"RandomForestClassifier\",\"LogisticRegression\",\"KNeighborsClassifier\"]})\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","3ec7b08f":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"svm\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train,y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","8895ecff":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","51ca2ea6":"test_survived\n","36d47950":"<a id = '1'><\/a><br>\n## Load and check data","936e9bf7":"<a id = '28'><\/a><br>\n## Dropping passenger ID and Cabin","017d14e8":"<a id = '18'><\/a><br>\n## Embarked -- Sex -- Pclass -- Survived","67f06398":"<a id = '16'><\/a><br>\n## Age -- Survived","055ab4a2":"<a id = '7'><\/a><br>\n# Outlier Detection\n","67075fa2":"<a id = '30'><\/a><br>\n## Train - test split","dccda59a":"Small families have more chance to survive than big families","353c1f8c":"<a id = '31'><\/a><br>\n## Simple logistic regression","656ce329":"<a id = '14'><\/a><br>\n## Parch -- Survived","efec59ea":"<a id = '3'><\/a><br>\n# Univarite variable analysis\n\n   * Categorical variable:Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch \n   * Numerical variable: Fare, age and passengerId","bd0ef86e":"* Sibsp and parch can be used for new feature extraction with th = 3\n* small families have more chance to survive\n* o siyah \u00e7izgi standart sapma","b7373dc5":"<a id = '9'><\/a><br>\n## Find missing value","e78fad59":"<a id = '25'><\/a><br>\n## Ticket","5b74a2e2":"* having a lot of sibsp means less chance to survive\n* if sibsp == 0 , 1 or 2 have more chance to survive\n* we can consider a new feature describing these categories ","f192826d":"<a id = '22'><\/a><br>\n## Name -- Title","842af041":"<a id = '32'><\/a><br>\n## Hyperparameter tuning -- Grid search -- Cross validation\nWe will compare 5 ml classifier and evuluate mean accuracy of each of them by stratified cross validation.\n\n* Decision tree\n* SVM\n* Random Forest\n* KNN\n* Logistic regression","ef078325":"<a id = '26'><\/a><br>\n## Pclass","a49522e8":"<a id = '19'><\/a><br>\n## Embarked -- Sex -- Fare -- Survived","d977290a":"<a id = '23'><\/a><br>\n## Family size","72fdae8b":"* age <= 10 has a high survival rate\n* oldest passenger (80) survived","3bda32a4":"<a id = '20'><\/a><br>\n## Fill missing age feature","143fa37b":"* float64(2): Fair and age\n* int64(5): Pclass, sibsp, parch, passengerId and survived\n* object(5); cabin. embarked, ticket, name and sex","dfb3f4ce":"Fare feature seems to have correlation with survived feature (0.26)","a78221bf":"<a id = '10'><\/a><br>\n## Fill missing value\n    * embarked has 2 missing value\n    * fare has only one missing value","ef15f1fe":"<a id = '33'><\/a><br>\n## Ensemble Modeling","a42a3f3f":"* pclass is important feature for model training","c3be781a":"<a id = '8'><\/a><br>\n# Missing value\n    * Find missing value\n    * Fill missing value","2c81ab60":"<a id = '15'><\/a><br>\n## Pclass -- Survived","018bf0e8":"<a id = '13'><\/a><br>\n## SibSp -- Survived   ","a657104f":"<a id = '12'><\/a><br>\n## [Correlation between Sibsp -- Parch -- Age -- Fare -- Survived](#12)","161c956c":"Sex is not useful information becauseage distribution seems same","91149f9d":"<a id = '5'><\/a><br>\n## Numerical variable","56565229":"<a id = '34'><\/a><br>\n## Prediction and Submission","9fcd1801":"# Introduction\nThe sinking of Titanic is one of the notorius shipwreck in the history.In 1912 during her voyage.The titanic sank after colliding with an iceberg,killing 1502 out of 2224 passengers and crew\n\n<font color = \"blue\" >\nContent:\n\n    \n1. [Load and check data](#1)\n2. [Variable Description](#2)\n    * [Univarite variable analysis](#3)\n        * [Categorical variable ](#4)\n        * [Numerical variable ](#5)\n1. [Basic data analysis](#6)\n1. [Outlier Detection](#7)\n1. [Missing value](#8)\n    * [Find missing value](#9)\n    * [Fill missing value](#10)\n1. [Visiualization](#11)\n    * [Correlation between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13) \n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill missing age feature](#20)\n1.  [Feature Engineering](#21)\n    * [Name -- Title](#22)\n    * [Family size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop ID and cabin](#28)\n1. [Modeling](#29)\n    * [Train - Test Split](#30)\n    * [Simple logistic regression](#31)\n    * [Hyperparameter tuning -- Grid search -- Cross validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)","3deafd2f":"<a id = '6'><\/a><br>\n## Basic data analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","3db55de6":"<a id = '17'><\/a><br>\n## Pclass -- Survived -- age","5552c556":"<a id = '4'><\/a><br>\n## Categorical variable","7d2f2d1f":"<a id = '29'><\/a><br>\n## Modeling","0b74c363":"<a id = '2'><\/a><br>\n## Variable Description\n\n1. PassengerId: unique id number to each passenger\n1. Survived: passenger survive(1) or died(0)\n1. Pclass: passenger class\n1. Name: name\n1. Sex: gender\n1. Age: age\n1. SibSp: Number of siblings\/spouses\n1. Parch: Number of parent\/child\n1. Ticket:ticket number\n1. Fare: amount of money spend to ticket\n1. Cabin: cabin category\n1. Embarked: port where passenger embark (C = Cherbourg, Q = Queenstown, S = Southampton)","a56b2b04":"<a id = '27'><\/a><br>\n## Sex","f59b0c93":"<a id = '21'><\/a><br>\n#  Feature Engineering\n    \n    ","d93266c6":"<a id = '24'><\/a><br>\n## Embarked","4ae7788a":"<a id = '11'><\/a><br>\n# Visiulation","5fc20034":"1st class is older than 2nd class and 2nd class older than 3rd class"}}