{"cell_type":{"bac4dffa":"code","e03276ed":"code","a49e8a04":"code","dcfb2477":"code","3dfcc409":"code","f06f3bf3":"code","4342e43d":"code","ef07f024":"code","a591a728":"code","5e84bc40":"code","bb3172b0":"code","f56ce970":"code","83f28a11":"code","5f00fc2c":"code","a31f6ac9":"code","c365bc20":"code","b65d1713":"code","38dfd7be":"code","cc7a8dab":"code","dd976f87":"code","82606ca4":"code","040015a6":"code","2c4da204":"code","05e920df":"code","c7117017":"markdown","88a74bd7":"markdown","96da3e2f":"markdown","03b76cfd":"markdown","0555f278":"markdown","111326ab":"markdown","b10d1772":"markdown","b1f65a75":"markdown","65591896":"markdown","10363000":"markdown","7b05cd7c":"markdown","eda7d011":"markdown","9b2194e6":"markdown"},"source":{"bac4dffa":"from torchvision import transforms, datasets, models\nimport torch\nfrom torch import optim, cuda\nfrom torch.utils.data import DataLoader, sampler, random_split\nimport torch.nn as nn\n\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","e03276ed":"print(os.listdir('..\/input\/data\/natural_images'))","a49e8a04":"#Visualising Data\nclasses = []\nimg_classes = []\nn_image = []\nheight = []\nwidth = []\ndim = []\n\n\n# Using folder names to identify classes\nfor folder in os.listdir('..\/input\/data\/natural_images'):\n    classes.append(folder)\n    \n    # Number of each image\n    images = os.listdir('..\/input\/data\/natural_images\/'+folder)\n    n_image.append(len(images))\n      \n    for i in images:\n        img_classes.append(folder)\n        img = np.array(Image.open('..\/input\/data\/natural_images\/'+folder+'\/'+i))\n        height.append(img.shape[0])\n        width.append(img.shape[1])\n    dim.append(img.shape[2])\n    \ndf = pd.DataFrame({\n    'classes': classes,\n    'number': n_image,\n    \"dim\": dim\n})\nprint(\"Random heights:\" + str(height[10]), str(height[123]))\nprint(\"Random Widths:\" + str(width[10]), str(width[123]))\ndf","dcfb2477":"image_df = pd.DataFrame({\n    \"classes\": img_classes,\n    \"height\": height,\n    \"width\": width\n})\nimg_df = image_df.groupby(\"classes\").describe()\nprint(img_df)","3dfcc409":"#Display random image\nImage.open('..\/input\/data\/natural_images\/cat\/cat_0007.jpg')","f06f3bf3":"image_transforms = {\n    # Train uses data augmentation\n    'train':\n    transforms.Compose([\n        transforms.RandomResizedCrop(size=256, scale=(0.95, 1.0)),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(),\n        transforms.RandomHorizontalFlip(),\n        transforms.CenterCrop(size=224),  # Image net standards\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])  # Imagenet standards\n    ]),\n    'val':\n    transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test':\n    transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","4342e43d":"def imshow_tensor(image, ax=None, title=None):\n\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    # Set the color channel as the third dimension\n    image = image.numpy().transpose((1, 2, 0))\n\n    # Reverse the preprocessing steps\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n\n    # Clip the image pixel values\n    image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    plt.axis('off')\n\n    return ax, image","ef07f024":"img = Image.open('..\/input\/data\/natural_images\/flower\/flower_0124.jpg')\nimg","a591a728":"transform = image_transforms['train']\nplt.figure(figsize=(24, 24))\n\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    _ = imshow_tensor(transform(img), ax=ax)\n\nplt.tight_layout()","5e84bc40":"batch_size = 128\n\nall_data = datasets.ImageFolder(root='..\/input\/data\/natural_images')\ntrain_data_len = int(len(all_data)*0.8)\nvalid_data_len = int((len(all_data) - train_data_len)\/2)\ntest_data_len = int(len(all_data) - train_data_len - valid_data_len)\ntrain_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\ntrain_data.dataset.transform = image_transforms['train']\nval_data.dataset.transform = image_transforms['val']\ntest_data.dataset.transform = image_transforms['test']\nprint(len(train_data), len(val_data), len(test_data))\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)","bb3172b0":"trainiter = iter(train_loader)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels.shape)","f56ce970":"model = models.vgg16(pretrained=True)\nmodel","83f28a11":"# Freeze early layers\nfor param in model.parameters():\n    param.requires_grad = False","5f00fc2c":"n_classes = 8\nn_inputs = model.classifier[6].in_features\n# n_inputs will be 4096 for this case\n# Add on classifier\nmodel.classifier[6] = nn.Sequential(\n    nn.Linear(n_inputs, 256),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(256, n_classes),\n    nn.LogSoftmax(dim=1))\n\nmodel.classifier","a31f6ac9":"# Show the summary of our model and the training params\n# Can use the below code if torchsummary is available (which it is not on Kaggle)\n#summary(model, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')","c365bc20":"criterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nmodel.cuda()","b65d1713":"model.class_to_idx = all_data.class_to_idx\nmodel.idx_to_class = {\n    idx: class_\n    for class_, idx in model.class_to_idx.items()\n}\n\nlist(model.idx_to_class.items())","38dfd7be":"def train(model,\n         criterion,\n         optimizer,\n         train_loader,\n         val_loader,\n         save_location,\n         early_stop=3,\n         n_epochs=20,\n         print_every=2):\n   \n#Initializing some variables\n  valid_loss_min = np.Inf\n  stop_count = 0\n  valid_max_acc = 0\n  history = []\n  model.epochs = 0\n  \n  #Loop starts here\n  for epoch in range(n_epochs):\n    \n    train_loss = 0\n    valid_loss = 0\n    \n    train_acc = 0\n    valid_acc = 0\n    \n    model.train()\n    ii = 0\n    \n    for data, label in train_loader:\n      ii += 1\n      data, label = data.cuda(), label.cuda()\n      optimizer.zero_grad()\n      output = model(data)\n      \n      loss = criterion(output, label)\n      loss.backward()\n      optimizer.step()\n      \n      # Track train loss by multiplying average loss by number of examples in batch\n      train_loss += loss.item() * data.size(0)\n      \n      # Calculate accuracy by finding max log probability\n      _, pred = torch.max(output, dim=1) # first output gives the max value in the row(not what we want), second output gives index of the highest val\n      correct_tensor = pred.eq(label.data.view_as(pred)) # using the index of the predicted outcome above, torch.eq() will check prediction index against label index to see if prediction is correct(returns 1 if correct, 0 if not)\n      accuracy = torch.mean(correct_tensor.type(torch.FloatTensor)) #tensor must be float to calc average\n      train_acc += accuracy.item() * data.size(0)\n      if ii%15 == 0:\n        print(f'Epoch: {epoch}\\t{100 * (ii + 1) \/ len(train_loader):.2f}% complete.')\n      \n    model.epochs += 1\n    with torch.no_grad():\n      model.eval()\n      \n      for data, label in val_loader:\n        data, label = data.cuda(), label.cuda()\n        \n        output = model(data)\n        loss = criterion(output, label)\n        valid_loss += loss.item() * data.size(0)\n        \n        _, pred = torch.max(output, dim=1)\n        correct_tensor = pred.eq(label.data.view_as(pred))\n        accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n        valid_acc += accuracy.item() * data.size(0)\n        \n      train_loss = train_loss \/ len(train_loader.dataset)\n      valid_loss = valid_loss \/ len(val_loader.dataset)\n      \n      train_acc = train_acc \/ len(train_loader.dataset)\n      valid_acc = valid_acc \/ len(val_loader.dataset)\n      \n      history.append([train_loss, valid_loss, train_acc, valid_acc])\n      \n      if (epoch + 1) % print_every == 0:\n        print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n        print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n        \n      if valid_loss < valid_loss_min:\n        torch.save(model.state_dict(), save_location)\n        stop_count = 0\n        valid_loss_min = valid_loss\n        valid_best_acc = valid_acc\n        best_epoch = epoch\n        \n      else:\n        stop_count += 1\n        \n        # Below is the case where we handle the early stop case\n        if stop_count >= early_stop:\n          print(f'\\nEarly Stopping Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n          model.load_state_dict(torch.load(save_location))\n          model.optimizer = optimizer\n          history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc','valid_acc'])\n          return model, history\n        \n  model.optimizer = optimizer\n  print(f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n  \n  history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n  return model, history","cc7a8dab":"model, history = train(\n    model,\n    criterion,\n    optimizer,\n    train_loader,\n    val_loader,\n    save_location='.\/natural_images.pt',\n    early_stop=5,\n    n_epochs=30,\n    print_every=2)","dd976f87":"history","82606ca4":"def accuracy(model, test_loader, criterion):\n  with torch.no_grad():\n    model.eval()\n    test_acc = 0\n    for data, label in test_loader:\n      data, label = data.cuda(), label.cuda()\n      \n      output = model(data)\n      \n      _, pred = torch.max(output, dim=1)\n      correct_tensor = pred.eq(label.data.view_as(pred))\n      accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n      test_acc += accuracy.item() * data.size(0)\n      \n    test_acc = test_acc \/ len(test_loader.dataset)\n    return test_acc","040015a6":"model.load_state_dict(torch.load('.\/natural_images.pt'))\ntest_acc = accuracy(model.cuda(), test_loader, criterion)\nprint(f'The model has achieved an accuracy of {100 * test_acc:.2f}% on the test dataset')","2c4da204":"def evaluate(model, test_loader, criterion):\n  \n  classes = []\n  acc_results = np.zeros(len(test_loader.dataset))\n  i = 0\n\n  model.eval()\n  with torch.no_grad():\n    for data, labels in test_loader:\n      data, labels = data.cuda(), labels.cuda()\n      output = model(data)\n      \n      for pred, true in zip(output, labels):\n        _, pred = pred.unsqueeze(0).topk(1)\n        correct = pred.eq(true.unsqueeze(0))\n        acc_results[i] = correct.cpu()\n        classes.append(model.idx_to_class[true.item()])\n        i+=1\n  \n  results = pd.DataFrame({\n      'class': classes,\n      'results': acc_results    \n  })\n  results = results.groupby(classes).mean()\n\n  return results\n","05e920df":"evaluate(model, test_loader, criterion)","c7117017":"I've defined the function for testing the model on the last set of data that we prepared earlier, and the model has never seen this set of data before.","88a74bd7":"After freezing the pre-trained layers of the network (which will take extremely long if we were to retrain it due to the sheer amount of layers), we now have to define the classifier layer which we will train to suit our dataset and use case","96da3e2f":"The loss function and optimizer is defined below and the model will use GPU to train","03b76cfd":"From Above, we can see the number of images each class contains, and that the height and width of images are not of a standard size. The only constant is the dimension, 3, representing that all are RGB colored images.\n\nWhen using images in the pre-trained network, we'll have to reshape them to 224 x 224. This is the size of Imagenet images and is therefore what the model expects. The images that are larger than this will be truncated while the smaller images will be interpolated. Data Augmentation and Resizing will be used later to modify the images","0555f278":"Now that the data is prepared, We'll start defining the model used, which in this case is a pre-trained model","111326ab":"Visualising and demonstrating how transformations will look like by writing a function below to plot examples of how images can be randomly transformed\n","b10d1772":"![](http:\/\/)We'll first import the data from the relevant path and do some simple visualisations","b1f65a75":"Data is now split into training, validation and test sets and then loaded into the data loaders","65591896":"As seen in the results, this model was probably an overkill for this dataset, however, this is just a walkthrough of how transfer learning from pre-trained models can be used for image classification purposes. Moving forward, for more complex and larger image datasets, the earlier layers of the model can be unfrozen such that the model can pick up features specific to the dataset it is learning on.","10363000":"We'll define the transformations that will be done for the 3 different sets of data (training, validation, test - which will be split later as well). Only the training data will be augmented.","7b05cd7c":"In this notebook, I'll be training a model on the natural image dataset available on Kaggle using transfer learning techniques to extract features from a pre-trained model to achieve high accuracy classification of this dataset. This is my first kernel on Kaggle, so any feedback on areas of improvement and better practices that I should adopt is definitely welcome.","eda7d011":"To see which class the model made the mistake on, the function below picks it out individually","9b2194e6":"After training over a number of epochs, we can see that the model is able to pick up the features of the images very quickly and classify them accordingly, therefore the accuracy is also so high for the first few epochs. This is because the model was trained on ImageNet, which contained millions of data and over 1,000 classes, therefore the layers (which we froze) were able to pick out the distinguishing features of the images, making it straightforward for the classifier which we were training to predict accurately"}}