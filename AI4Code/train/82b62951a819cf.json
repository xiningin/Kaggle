{"cell_type":{"5f03ce27":"code","0849dca4":"code","86184d5a":"code","96620197":"code","042deead":"code","9b398413":"code","e43683a2":"code","ed600c65":"code","ce70325a":"code","3c98280e":"code","a8eb5899":"code","4cdb390c":"code","4d2b5945":"code","2a17c01b":"code","1dc12d16":"code","9f4a8415":"code","dbf263c7":"code","d7306b2b":"code","7fb8e6c2":"code","74da65e6":"code","ee215250":"markdown","82d9bb1c":"markdown","f0765ab9":"markdown","e051dbb7":"markdown","75cca9a8":"markdown","3811d24b":"markdown","1c614fda":"markdown","12bfd845":"markdown"},"source":{"5f03ce27":"!nvidia-smi","0849dca4":" !pip install -U keras-tuner","86184d5a":"from __future__ import absolute_import, division, print_function, unicode_literals\n\ntry:\n  %tensorflow_version 2.x\nexcept:\n  pass\nimport tensorflow as tf\n\nimport os\nimport datetime\nimport tensorflow_datasets as tdfs\nfrom kerastuner.engine.hyperparameters import HyperParameters\n\n%load_ext tensorboard","96620197":"tf.config.experimental.list_physical_devices()","042deead":"import tensorflow_datasets as tfds\ndata, info = tfds.load(name='fashion_mnist',with_info=True,as_supervised=True,try_gcs=True,split=['train','test'])","9b398413":"print(info.features)\nprint(info.features['label'].num_classes)\nprint(info.features['label'].names)","e43683a2":"fm_train, fm_test = data[0],data[1]\nfm_val = fm_test.take(3000)\nfm_test = fm_test.skip(3000)","ed600c65":"import matplotlib.pyplot as plt\nimport numpy as np\nfor fm_sample in fm_train.take(3):\n  image,label = fm_sample[0], fm_sample[1]\n  \n  plt.figure()\n  plt.imshow(image.numpy()[:,:,0].astype(np.float32),cmap=plt.get_cmap('gray'))\n  plt.show()\n  print(\"Label: \",label.numpy())\n  print(\"Category: \",info.features['label'].names[label.numpy()])","ce70325a":"def scale(image,label):\n  image = tf.cast(image,tf.float32)\n  image \/= 255.0\n\n  return image, label","3c98280e":"def get_datasets(batch_size=64):\n  train_dataset_scaled = fm_train.map(scale).shuffle(60000).batch(batch_size)\n  test_dataset_scaled = fm_test.map(scale).batch(batch_size)\n  val_datset_scaled = fm_val.map(scale).batch(batch_size)\n  return train_dataset_scaled, test_dataset_scaled, val_datset_scaled","a8eb5899":"hp = HyperParameters()\nhp.Choice('learning_rate',[1e-1,1e-3])\nhp.Int('conv_blocks',3,4,default=3)\nhp.Int('hidden_size',128,256,step=64,default=128)","4cdb390c":"def build_model(hp):\n  inputs = tf.keras.Input(shape=(28,28,1))\n  x = inputs\n  for i in range(hp.get('conv_blocks')):\n    filters = hp.Int('filters_'+str(i),32,256,step=64)\n    for _ in range(2):\n      x = tf.keras.layers.Convolution2D(filters,kernel_size=(3,3),padding='same')(x)\n      x = tf.keras.layers.BatchNormalization()(x)\n      x = tf.keras.layers.ReLU()(x)\n    if hp.Choice('pooling_'+str(i),['avg','max']) == 'max':\n      x = tf.keras.layers.MaxPool2D()(x)\n    else:\n      x = tf.keras.layers.AvgPool2D()(x)\n  x = tf.keras.layers.GlobalAvgPool2D()(x)\n  x = tf.keras.layers.Dense(hp.get('hidden_size'),activation='relu')(x)\n  x = tf.keras.layers.Dropout(0.5)(x)\n  outputs = tf.keras.layers.Dense(10,activation='softmax')(x)\n\n  model = tf.keras.Model(inputs,outputs)\n  model.compile(\n        optimizer = tf.keras.optimizers.Adam(hp.get('learning_rate')),\n        loss = 'sparse_categorical_crossentropy',\n        metrics=['accuracy']\n  )\n  return model","4d2b5945":"import kerastuner as kt\ntuner = kt.Hyperband(\n    build_model,\n    objective='val_accuracy',\n    hyperparameters = hp,\n    max_epochs = 5,\n    hyperband_iterations = 2\n)","2a17c01b":"tuner.search_space_summary()","1dc12d16":"train_dataset, test_dataset, val_dataset = get_datasets()\ntrain_dataset.cache()\ntest_dataset.cache()\n#cache is used to store data in GPU\n\ntuner.search(train_dataset,\n             validation_data=val_dataset,\n             epochs=5,\n             callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])","9f4a8415":"best_model = tuner.get_best_models(1)[0]","dbf263c7":"best_model.summary()","d7306b2b":"best_hyperparameters = tuner.get_best_hyperparameters(1)[0]","7fb8e6c2":"best_hyperparameters.values","74da65e6":"tuner.results_summary()","ee215250":"Now build the model using keras tuner functions","82d9bb1c":"Train, Test and Validation datasets","f0765ab9":"Sample images","e051dbb7":"Scale the values to 0-1","75cca9a8":"Batch selection and scaling","3811d24b":"Keras tuner will find the best hyperparameters for the model","1c614fda":"In this I am taking fashion MNIST datadets from tensorflow hub. You can also use kaggle hub datasets","12bfd845":"Hyper parameters setting: You can chosse number of conv blocks, learning rate & hidden size"}}