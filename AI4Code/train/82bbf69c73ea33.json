{"cell_type":{"adc4e508":"code","089a2c45":"code","42625496":"code","2ba91a41":"code","0aec1b16":"code","ffa0e898":"code","d965f637":"code","c3ac8a58":"code","648ec8a8":"code","d636e0f3":"code","8c3f6452":"code","ab448e6c":"code","e925087f":"code","64d3ccef":"code","dd043567":"code","0227ad45":"code","33ebf95c":"code","95a253c9":"code","7bca2766":"code","37ff8c39":"code","97e16e9d":"code","4c3edc55":"code","6ec48f5b":"code","7326e54f":"code","d86367b3":"code","3d3bb71e":"code","edc1fb29":"code","a0fbd09e":"code","cffd87a4":"code","217bef73":"code","9b52eecc":"code","c8940745":"code","4d642040":"code","411e1849":"code","83764fe0":"code","b71f6f6a":"code","4b0d78bf":"code","9ea601af":"code","0b5536ac":"code","c03effb7":"code","41a9617e":"code","06587693":"code","42e9f4be":"code","ba7429cf":"code","2f9d5ade":"code","5a8aa70f":"code","e6cbbee4":"code","56b3abf5":"code","f3fff78d":"code","a33b6ded":"code","ea9ac7d0":"code","67d9d39c":"code","8a47c879":"code","24ff8487":"code","9bce8798":"code","3647655e":"code","7c41298d":"code","390d9afd":"code","bc7a0ee7":"code","2e5ff2be":"code","fccf2731":"code","2edd9697":"code","2bfe7459":"markdown","4a876993":"markdown","31f1d4ad":"markdown","1339a3f0":"markdown","97d32068":"markdown","ceb58898":"markdown","7b575985":"markdown","e3bde4f0":"markdown","130acb15":"markdown","955594bc":"markdown","65be9051":"markdown","a0a19113":"markdown","c41b0fdd":"markdown","fffaf89b":"markdown","c39668ed":"markdown","3506a0b4":"markdown","ce0c81cb":"markdown","df4a7c96":"markdown","b1844dbd":"markdown","7c177304":"markdown","ea05e959":"markdown","d4f7497c":"markdown","d531cf60":"markdown","555134d8":"markdown","e23e5608":"markdown"},"source":{"adc4e508":"import pandas as pd\nimport datatable as dt\nfrom datatable import f, min, max, mean\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport plotly.io as pio\nimport scipy.stats as stats\nimport warnings\nimport numpy as np\nwarnings.filterwarnings(\"ignore\")","089a2c45":"# Only for kaggle\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)","42625496":"df = dt.fread(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","2ba91a41":"df.head()","0aec1b16":"df.shape","ffa0e898":"df[f.Churn == \"Yes\", dt.count()]","d965f637":"1869\/7043","c3ac8a58":"df[:, dt.count(), dt.by(dt.f.Churn)]","648ec8a8":"df[dt.f.Churn == 'Yes', 'TotalCharges'].sum1()","d636e0f3":"df_pandas = df.to_pandas()","8c3f6452":"df_pandas.head()","ab448e6c":"def diagnostic_plots(df_pandas, variable):\n    \n    plt.figure(figsize=(20, 9))\n\n    plt.subplot(1, 3, 1)\n    sns.histplot(data = df_pandas, x=variable, bins=30, kde=True)\n    plt.title('Histogram')\n    \n    plt.subplot(1, 3, 2)\n    stats.probplot(df_pandas[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('RM quantiles')\n\n    plt.subplot(1, 3, 3)\n    sns.boxplot(x=df_pandas[variable])\n    plt.title('Boxplot')\n    \n    plt.show()","e925087f":"num_columns=df_pandas.select_dtypes(include=[\"number\"]).columns\nnum_columns","64d3ccef":"for i in num_columns:\n    diagnostic_plots(df_pandas,i)","dd043567":"sns.pairplot(df_pandas.drop(\"SeniorCitizen\",axis=1),hue=\"Churn\",aspect=3);","0227ad45":"fig = px.histogram(df_pandas, x=\"Churn\")\nfig.update_layout(width=700, height=500, bargap=0.1)\nfig.show()","33ebf95c":"fig = px.histogram(df_pandas, x=\"Churn\", color=\"SeniorCitizen\")\nfig.update_layout(width=700, height=500, bargap=0.1)\nfig.show()","95a253c9":"fig = px.histogram(df_pandas, x=\"Churn\", color=\"OnlineSecurity\", barmode=\"group\")\nfig.update_layout(width=700, height=500, bargap=0.1)\nfig.show()","7bca2766":"fig = px.box(df_pandas, x='Churn', y = 'tenure')\nfig.show()","37ff8c39":"ax = sns.kdeplot(df_pandas.MonthlyCharges[(df_pandas[\"Churn\"] == 'No') ],\n                color=\"Red\", shade = True);\nax = sns.kdeplot(df_pandas.MonthlyCharges[(df_pandas[\"Churn\"] == 'Yes') ],\n                ax =ax, color=\"Blue\", shade= True);\nax.legend([\"Not Churn\",\"Churn\"],loc='upper right');\nax.set_ylabel('Density');\nax.set_xlabel('Monthly Charges');\nax.set_title('Distribution of monthly charges by churn');","97e16e9d":"corr = df_pandas.apply(lambda x: pd.factorize(x)[0]).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nheat = go.Heatmap(\n    z=corr.mask(mask),\n    x=corr.columns,\n    y=corr.columns,\n    colorscale=px.colors.diverging.RdBu,\n    zmin=-1,\n    zmax=1\n)\n\npio.templates.default = \"plotly_white\"\n\n\nfig.update_xaxes(side=\"bottom\")\n\nfig.update_layout(\n    title_text='Heatmap', \n    title_x=0.5, \n    width=1000, \n    height=1000,\n    xaxis_showgrid=False,\n    yaxis_showgrid=False,\n    xaxis_zeroline=False,\n    yaxis_zeroline=False,\n    yaxis_autorange='reversed',\n    template='plotly_white'\n)\n\nfig=go.Figure(data=[heat])\nfig.show()","4c3edc55":"df.names","6ec48f5b":"df.stypes","7326e54f":"##\u00a0missing values\ndt.math.isna(df).sum()","d86367b3":"##\u00a0Delete missing rows\ndf = df[dt.rowall(dt.f[:] != None), :]","3d3bb71e":"#\u00a0Delete customerID\ndel df[:, \"customerID\"]","edc1fb29":"df.head()","a0fbd09e":"#\u00a0Enconde Churn\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf[:, 'Churn'] = dt.Frame(le.fit_transform(np.ravel(df[:, 'Churn'])))","cffd87a4":"# Function for OHE\ndef ohe_columns(columns,df):\n    df_work = df.copy()\n    for column in columns:\n        df_ohe = dt.str.split_into_nhot(df_work[column])\n        df_ohe.names = [f'{column}_{col}' for col in df_ohe.names]\n        df_work.cbind(df_ohe)\n    return df_work","217bef73":"# Select categorical columns\ncategorical_columns = df[:, str].names","9b52eecc":"# Get final df after OHE\ndf_final = ohe_columns(categorical_columns,df)","c8940745":"# Delete orignal columns\ndel df_final[:, categorical_columns]","4d642040":"df_final.head()","411e1849":"import h2o\nfrom h2o.automl import *","83764fe0":"h2o.init()","b71f6f6a":"dataset = h2o.H2OFrame(df_final.to_pandas())","4b0d78bf":"dataset.head()","9ea601af":"train, test = dataset.split_frame([0.8], seed=42)","0b5536ac":"print(\"train:%d test:%d\" % (train.nrows, test.nrows))","c03effb7":"# Identify predictors and response\nx = train.columns\ny = \"Churn\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()","41a9617e":"aml = H2OAutoML(max_runtime_secs = 90, #change this if you are in a rush hehehe\n                max_models = 25,  \n                seed = 42, \n                project_name='classification_1',\n                sort_metric = \"AUC\")\n\n%time aml.train(x = x, y = y, training_frame = train)","06587693":"lb = aml.leaderboard\nlb.head(rows = lb.nrows)","42e9f4be":"aml.leader","ba7429cf":"aml.leader.model_performance(test_data=test)","2f9d5ade":"aml.leader.model_performance(test_data=test).plot()","5a8aa70f":"aml.predict(test)","e6cbbee4":"aml.explain(test)","56b3abf5":"aml.leader.model_performance(test_data=test).confusion_matrix()","f3fff78d":"from h2o.estimators import *\nfrom h2o.grid import *","a33b6ded":"train, valid, test = dataset.split_frame([0.7, 0.15], seed=42)","ea9ac7d0":"# Identify predictors and response\nx = train.columns\ny = \"Churn\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\nvalid[y] = valid[y].asfactor()","67d9d39c":"gbm = H2OGradientBoostingEstimator(seed = 42, \n                                   model_id = 'default_gbm')\n\n%time gbm.train(x = x, y = y, training_frame = train, validation_frame = valid)","8a47c879":"gbm","24ff8487":"gbm.predict(valid)","9bce8798":"default_gbm_per = gbm.model_performance(test)","3647655e":"default_gbm_per","7c41298d":"# Hyperparameter estimation\n\ngbm = H2OGradientBoostingEstimator(ntrees = 500,\n                                   learn_rate = 0.05,\n                                   seed = 42,\n                                   model_id = 'grid_gbm')\n\nhyper_params_tune = {'max_depth' : [4, 5, 6, 7, 8],\n                     'sample_rate': [x\/100. for x in range(20,101)],\n                     'col_sample_rate' : [x\/100. for x in range(20,101)],\n                     'col_sample_rate_per_tree': [x\/100. for x in range(20,101)],\n                     'col_sample_rate_change_per_level': [x\/100. for x in range(90,111)]}\n\nsearch_criteria_tune = {'strategy': \"RandomDiscrete\",\n                        'max_runtime_secs': 90,  \n                        'max_models': 100,  ## build no more than 100 models\n                        'seed' : 42}\n\nrandom_grid = H2OGridSearch(model = gbm, hyper_params = hyper_params_tune,\n                            grid_id = 'random_grid',\n                            search_criteria = search_criteria_tune)\n\n%time random_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)","390d9afd":"sorted_random_search = random_grid.get_grid(sort_by = 'auc',decreasing = True)\nsorted_random_search.sorted_metric_table()","bc7a0ee7":"tuned_gbm = sorted_random_search.models[0]","2e5ff2be":"tuned_gbm_per = tuned_gbm.model_performance(test)\nprint(tuned_gbm_per.auc())","fccf2731":"tuned_gbm.explain(test)","2edd9697":"tuned_gbm.explain_row(test, row_index=0)","2bfe7459":"Thanks to Rohan Rao (@vopani) for his invaluable help and resources, and of course the whole H2O community.","4a876993":"## Data exploration","31f1d4ad":"| Description                    | Customers | Value | Total     |\n|--------------------------------|-----------|-------|-----------|\n| True Positive                  | 294       | 7500  | 2,205,294 |\n| True Positive + False Positive | 529       | 500   | -264,500  |\n|                                |           |       | **1,940,794** |\n\nSo we could have save (or make) the company almost 2 million dollars with this model.\n\nYou perform the same analysis for the following models.","1339a3f0":"## Understand the business context and problem","97d32068":"## \u00a0Data cleaning","ceb58898":"We only have 11 missing values in the TotalCharges column. ","7b575985":"We have lost $2.862.926 due to customer churn. So let's try to solve this problem.","e3bde4f0":"## Modeling","130acb15":"After those meetings we have to check the existing data in the company and find useful information in it. Let's assume we did it and after a data integration process we created a comprehensive dataset for our customers and their information. Remember that we are working with a telco company. ","955594bc":"## References\n\n- https:\/\/github.com\/vopani\/datatableton\n- https:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/welcome.html\n- https:\/\/h2oai.github.io\/tutorials\/introduction-to-machine-learning-with-h2o-3-automl\/#0\n- https:\/\/www.kaggle.com\/bhartiprasad17\/customer-churn-prediction\n- https:\/\/www.kaggle.com\/parulpandey\/speed-up-your-data-munging-with-python-s-datatable\/data\n- https:\/\/www.kaggle.com\/ferhatmetin34\/telco-churn-prediction-under-oversampling-automl\/data\n- https:\/\/www.kaggle.com\/sudalairajkumar\/hyperparam-tuning-automl\n- https:\/\/www.kaggle.com\/nishantdhingra\/h2o-automl-kfold\n- https:\/\/towardsdatascience.com\/predict-customer-churn-the-right-way-using-pycaret-8ba6541608ac\n- https:\/\/github.com\/h2oai\/h2o-meetups\/blob\/master\/2021_02_26_USFData_H2OAutoMLExplain\/h2o_automl_explain_usfca_feb2021.pdf\n- https:\/\/towardsdatascience.com\/explain-your-model-with-the-shap-values-bc36aac4de3d","65be9051":"Check this great source for learning more about datatable by my friend Rohan Rao:\n\nhttps:\/\/github.com\/vopani\/datatableton","a0a19113":"In a churn model, often the reward of true positives is way different than the cost of false positives. Let\u2019s use the following assumptions:\n\n- \\$500 voucher will be offered to all the customers identified as churn (True Positive + False Positive);\n- If we are able to stop the churn, we will gain $7500 in customer lifetime value.","c41b0fdd":"## The problem: Customer Churn\n\n![](https:\/\/www.insideselfstorage.com\/sites\/insideselfstorage.com\/files\/styles\/article_featured_retina\/public\/Sad-Customer-Service.jpg?itok=S9sd0R3T)\nCredit:https:\/\/www.insideselfstorage.com\/customer-service\/7-deadly-customer-service-situations-self-storage-and-how-handle-them\n\nCustomer churn is defined as when customers or subscribers discontinue doing business with a firm or service.\n\nEach row represents a customer, each column contains customer\u2019s attributes.\n\nThe data set includes information about:\n\n- Customers who left within the last month \u2013 the column is called **Churn**\n- Services that each customer has signed up for \u2013 phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n- Customer account information \u2013 how long they\u2019ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n- Demographic info about customers \u2013 gender, age range, and if they have partners and dependents","fffaf89b":"The colour signifies the datatype where red denotes string, green denotes int, yellow means boolean and blue stands for float.","c39668ed":"## How much money have we lost due to the loss of customers?","3506a0b4":"Before spending time trying to solve a business problem, we have to be sure that we have a problem. For that we need to have meetings with the people close to the business problem and the steakholders. \n\nWe had two meetings, one with HR and the other with the main excecutives. This is what we heard:\n\n- Curstomers are leaving but we don't know why.\n- We have 1 month of data for customers where we know which ones stayed and which ones left.\n- The customer churn can't surpass 15% per year due to our calculations.\n- We don't know the financial impact on losing a customer\n- We can give a voucher for \\$500 for customers identified as churn.\n- The estimated life time value for a customer is \\$7500.","ce0c81cb":"### 1. H2O AutoML","df4a7c96":"1869 customers have left, that means 26% of our customers. So if we remember the metrics from the business we have a problem. ","b1844dbd":"This confusion matrix is on the test set which includes 20% of our data (1400 rows) We have 294 True Positives (21%) \u2014 these are the customers for which we will be able to extend the lifetime value. If we wouldn\u2019t have predicted, then there was no opportunity for intervention.\n\nWe also have 235 (16%) False Positives where we will lose money because the promotion offered to these customers will just be an extra cost.\n\n780 (55%) are True Negatives (good customers) and 87 (6%) are False Negative (this is a missed opportunity).","7c177304":"## Acknowledgements","ea05e959":"## How many customers have left? ","d4f7497c":"# Telco churn prediction with H2O and Datatable\n### Favio V\u00e1zquez","d531cf60":"## Load data","555134d8":"### 2. GBM with H2O","e23e5608":"## Libraries"}}