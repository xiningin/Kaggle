{"cell_type":{"fe7a0829":"code","d87ba6af":"code","5d9022e6":"code","d2ac0808":"code","171be2e4":"code","170f46d2":"code","70366015":"code","27031f1d":"code","343a506c":"code","0de10f10":"code","a951c461":"code","4095f37a":"code","8787d3e0":"code","6ff392e1":"code","c0142613":"code","db100741":"code","d12cf58c":"code","4e2b7fc4":"markdown","70b9246b":"markdown","110937a3":"markdown","9918cbb5":"markdown","3d7d280e":"markdown"},"source":{"fe7a0829":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d87ba6af":"from time import time\nimport pandas as pd\nimport numpy as np\nimport re\nimport sys\nimport csv\ncsv.field_size_limit(sys.maxsize)\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns\n","5d9022e6":"# Reading the dataset with no columns titles and with latin encoding \ndf_raw = pd.read_csv('\/kaggle\/input\/bitcoin-tweets-20160101-to-20190329\/tweets.csv', delimiter=';', skiprows=0, lineterminator='\\n' )\ndf_raw.head()","d2ac0808":" # Rename columns\ndf_raw.columns = [\"id\", \"user\", \"fullname\", \"url\", \"timestamp\", \"replies\",\"likes\",\"retweets\",\"text\"]\n\n# Show the first 5 rows of the dataframe.\n# You can specify the number of rows to be shown as follows: df_raw.head(10)\ndf_raw.head()","171be2e4":"# Ommiting every column except for the text and the date, as we won't need any of the other information\ndf = df_raw[['timestamp','text']]\ndf.sample(5)","170f46d2":"#Create split by dates \ndf.timestamp.dtypes","70366015":"df['date'] = pd.to_datetime(df['timestamp'],format= '%Y-%m-%d').dt.date\ndf['date']","27031f1d":"#new df is now SORTED by DATE\ndf = df.sort_values(by='date')\ndf.head()","343a506c":"df = df.set_index('date')\ndf.head()","0de10f10":"# df.date.year > '2017'\nstartdate = pd.to_datetime(\"2017-01-01\").date()\ndf = df.loc[startdate:]\ndf.tail()","a951c461":"pip install whatthelang","4095f37a":"from whatthelang import WhatTheLang\nwtl = WhatTheLang()\nresult = [wtl.predict_lang(row) for row in df['text']]\ndf['lang'] = result\ndf.head()","8787d3e0":"#ATTENTION, we will take only text, date and lang column FOR THE texts in ENglish and below DATES starting 2017 jan\nen_df = df[df[\"lang\"] == 'en']\nen_df.sample(10, random_state = 5)","6ff392e1":"# checking for null values, if any\nen_df.isnull().sum()","c0142613":"#ditching all row when text is null, as need text for analysis\nen_df.dropna(how='any', inplace=True)\nen_df.sample(3)","db100741":"en_df.info()","d12cf58c":"#export to new CSV as it kept crashing my google colab otherwise\n# en_df = reset_index(inplace=True)\nen_df.to_csv('\/kaggle\/input\/bitcoin-tweets-20160101-to-20190329\/tweetsENdates.csv')","4e2b7fc4":"Now that we have cleant the dates of our data => let s analyze how many tweets are in which language, and if unbalanced, we will only keep the tweets in ENglish","70b9246b":"The data was really unbalanced : it had a few tweets from 2009, most of the tweets are in english (90%) but those handful foreign tweets do mess up with the analysis.","110937a3":"Now that we have something less clumsy to work on, I will work on the data preprocessing before modeling \nHere is the step 2 [suite...](http:\/\/www.kaggle.com\/leticehs\/nlp-bitcoin-analysis-2-preprocessing)","9918cbb5":"Here is the code to cut this dataset to : \n. data from 2017-01-01\n. tweets only in English language","3d7d280e":"When I first explored this dataset, i found it so clumsy,and so messy, that I decided to cut it. "}}