{"cell_type":{"9847eda8":"code","fa6a604b":"code","c84d0632":"code","dd28cf2a":"code","6c66bdbd":"code","3720669d":"code","a0adcb3a":"code","b10fcc6e":"code","676cb6b9":"code","ff376e92":"code","bca636d2":"code","76bc6053":"code","c85d792c":"code","7aeebf12":"code","306c071e":"code","b5b0b50d":"code","bdfba4e8":"code","f059e6bb":"code","d4219e5f":"code","c047fea8":"code","dd633a7a":"code","8a896eee":"code","1d0da90b":"code","e9620ceb":"code","8eb76adc":"code","2d23531c":"code","6b180886":"code","02693533":"code","f923e59d":"code","a021b333":"code","f5de200a":"code","c949000b":"code","09eafab2":"code","5b4a5dc2":"code","d607bd52":"code","3af36c86":"code","2c0c3b88":"code","d7d2c794":"code","2c595be5":"code","e335fc1e":"code","af5a1057":"code","1cd26e6b":"code","610b9a83":"code","bd417ff9":"code","478266cf":"code","9c8a912d":"code","8cb39246":"code","c7e9f7b7":"code","e30aecef":"code","cde482d8":"code","ac52c5b3":"code","c4a0fa16":"code","64812536":"code","fa96c55e":"code","fc50be36":"code","c8395f61":"code","dc9cfd98":"code","b3f0f735":"markdown","29edc605":"markdown","62a8cd90":"markdown","49f444c9":"markdown","357ca83a":"markdown","d28a6bf3":"markdown","40187300":"markdown","b6581fdc":"markdown","11a1c261":"markdown","4725fc3b":"markdown","7ed7a5be":"markdown"},"source":{"9847eda8":"import torch","fa6a604b":"torch.zeros([3, 4])","c84d0632":"torch.ones([3, 4, 2])","dd28cf2a":"torch.Tensor([[1,  2,  3,  4],\n              [5,  6,  7,  8],\n              [9, 10, 11, 12]])","6c66bdbd":"x = torch.Tensor([[1,  2,  3,  4],\n                  [5,  6,  7,  8],\n                  [9, 10, 11, 12]])","3720669d":"x.size()","a0adcb3a":"x.shape","b10fcc6e":"x[0]","676cb6b9":"x[1]","ff376e92":"x[0, 0]","bca636d2":"x[:, 0]","76bc6053":"x + 10","c85d792c":"x ** 2","7aeebf12":"y = torch.Tensor([[12, 11, 10, 9],\n                  [8, 7, 6, 5],\n                  [4, 3, 2, 1]])","306c071e":"x + y","b5b0b50d":"x * y","bdfba4e8":"x \/ y","f059e6bb":"x % y","d4219e5f":"torch.exp(x)","c047fea8":"torch.log(x)","dd633a7a":"torch.sin(x)","8a896eee":"x > 3","1d0da90b":"mask = x > 3","e9620ceb":"x[mask]","8eb76adc":"x[x > 3]","2d23531c":"y = x\ny[0, 0] = 999\nprint(x)\nprint(y)","6b180886":"x = torch.Tensor([[1,  2,  3,  4],\n                  [5,  6,  7,  8],\n                  [9, 10, 11, 12]])","02693533":"y = x.clone()\ny[0, 0] = 999\nprint(x)\nprint(y)","f923e59d":"x.dtype","a021b333":"x = x.double()\nprint(x)\nx = x.int()\nprint(x)\nx = x.float()\nprint(x)","f5de200a":"import numpy as np\nx = np.array([[1, 2, 3, 4],\n              [4, 3, 2, 1]])\nx","c949000b":"x = torch.from_numpy(x)\nx","09eafab2":"x = x.numpy()\nx","5b4a5dc2":"x = torch.rand([10,20])\nx","d607bd52":"torch.cuda.is_available()","3af36c86":"torch.device('cuda:0')","2c0c3b88":"torch.device('cpu')","d7d2c794":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","2c595be5":"x_cuda = x.to(device)\n# x_cuda","e335fc1e":"%time y = (x - x + x * 10.0) ** 2","af5a1057":"%time y_cuda = (x_cuda - x_cuda + x_cuda * 10.0) ** 2","1cd26e6b":"import torch\n\nx = torch.tensor(\n    [[1.,  2.,  3.,  4.],\n     [5.,  6.,  7.,  8.],\n     [9., 10., 11., 12.]], requires_grad=True)\n\n#######\ndevice = torch.device('cuda:0' \n                      if torch.cuda.is_available() \n                      else 'cpu')\nx = x.to(device)\n#######\n\nfunction = 10 * (x ** 2).sum()\n\nfunction.backward()\n\nprint(x.grad, '<- gradient')","610b9a83":"print(function.grad_fn)\nprint(function.grad_fn.next_functions[0][0])\nprint(function.grad_fn.next_functions[0][0].next_functions[0][0])\nprint(function.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0])","bd417ff9":"x = torch.tensor(\n    [[1.,  2.,  3.,  4.],\n     [5.,  6.,  7.,  8.],\n     [9., 10., 11., 12.]], requires_grad=True)","478266cf":"function = 10 * (x ** 2).sum()\nfunction.backward()","9c8a912d":"x, function","8cb39246":"x.grad","c7e9f7b7":"x.data -= 0.001 * x.grad","e30aecef":"x.grad.zero_()","cde482d8":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef show_contours(objective,\n                  x_lims=[-10.0, 10.0], \n                  y_lims=[-10.0, 10.0],\n                  x_ticks=100,\n                  y_ticks=100):\n    x_step = (x_lims[1] - x_lims[0]) \/ x_ticks\n    y_step = (y_lims[1] - y_lims[0]) \/ y_ticks\n    X, Y = np.mgrid[x_lims[0]:x_lims[1]:x_step, y_lims[0]:y_lims[1]:y_step]\n    res = []\n    for x_index in range(X.shape[0]):\n        res.append([])\n        for y_index in range(X.shape[1]):\n            x_val = X[x_index, y_index]\n            y_val = Y[x_index, y_index]\n            res[-1].append(objective(np.array([[x_val, y_val]]).T))\n    res = np.array(res)\n    plt.figure(figsize=(7,7))\n    plt.contour(X, Y, res, 100)\n    plt.xlabel('$x_1$')\n    plt.ylabel('$x_2$')","ac52c5b3":"import torch\n\nx = torch.tensor(\n    [8., 8.], requires_grad=True)\nvar_history = []\nfn_history = []\n\ndef function_parabola(variable):\n    return 10 * (variable ** 2).sum()\n\ndef make_gradient_step(function, variable):\n    function_result = function(variable)\n    function_result.backward()\n    variable.data -= 0.001 * variable.grad\n    variable.grad.zero_()\n\nfor i in range(500):\n    var_history.append(x.data.cpu().numpy().copy())\n    fn_history.append(function_parabola(x).data.cpu().numpy().copy())\n    make_gradient_step(function_parabola, x)","c4a0fa16":"import torch\n\nx = torch.tensor(\n    [8., 8.], requires_grad=True)\nvar_history = []\nfn_history = []\n\noptimizer = torch.optim.SGD([x], lr=0.001)\n\ndef function_parabola(variable):\n    return 10 * (variable ** 2).sum()\n\ndef make_gradient_step(function, variable):\n    function_result = function(variable)\n    function_result.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \nfor i in range(500):\n    var_history.append(x.data.numpy().copy())\n    fn_history.append(function_parabola(x).data.cpu().numpy().copy())\n    make_gradient_step(function_parabola, x)","64812536":"show_contours(function_parabola)\nplt.scatter(np.array(var_history)[:,0], np.array(var_history)[:,1], s=10, c='r');","fa96c55e":"plt.figure(figsize=(7,7))\nplt.plot(fn_history);\nplt.xlabel('step')\nplt.ylabel('function value');","fc50be36":"plt.figure(figsize=(7,7))\nplt.semilogy(fn_history);\nplt.xlabel('step')\nplt.ylabel('function value');","c8395f61":"def function_skewed(variable):\n    gramma = torch.tensor([[1., -1.], [1., 1.]]) @ torch.tensor([[1.0, 0.0], [0.0, 4.0]])\n    res = 10 * (variable.unsqueeze(0) @ (gramma @ variable.unsqueeze(1))).sum()\n    return res\n\ndef function_skewed_np(variable):\n    gramma = np.array([[1, -1], [1, 1]]) @ np.array([[1.0, 0.0], [0.0, 4.0]])\n    res = 10 * (variable.transpose(1, 0) @ (gramma @ variable)).sum()\n    return res","dc9cfd98":"show_contours(function_skewed_np)\nplt.scatter(np.array(var_history)[:,0], np.array(var_history)[:,1], s=10, c='r');","b3f0f735":"**Numpy & pytorch**","29edc605":"**\u0413\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u044b\u0439 \u0441\u043f\u0443\u0441\u043a**\n\n![](https:\/\/i.gifer.com\/R46v.gif)\n\n$f(x) \\longrightarrow  \\displaystyle \\min_{x} $\n\n$x^{t+1} = x^t-\\alpha{f'(x^t)}$\n\n$f(x^{t+1}) = f(x^t-\\alpha{f'(x^t)})$\n\n$f(\\textbf{X}) = 10\\cdot\\sum\\limits_{i, j}x_{ij}^2$\n\n$f'(\\textbf{X})_{\\textbf{X}} = ? $\n\n$f'(\\textbf{X})_{x_{kl}} = \\Big( 10\\cdot\\sum\\limits_{i, j}x_{ij}^2\\Big)_{x_{kl}}' = 10 \\cdot\\Big(\\sum\\limits_{i, j}x_{ij}^2\\Big)_{x_{kl}}' $\n\n$ \\quad = 10 \\cdot\\sum\\limits_{i, j}\\Big(x_{ij}^2\\Big)_{x_{kl}}' $\n\n$ \\quad = 10 \\cdot\\sum\\limits_{i, j}2 x_{ij} \\big(x_{ij}\\big)_{x_{kl}}' $\n\n$ \\quad = 10 \\cdot 2 x_{kl} \\cdot 1 = 20 x_{kl} $\n\n$f(\\textbf{X}) = 10\\cdot\\sum\\limits_{i, j}x_{ij}^2$\n\n$f'(\\textbf{X})_{\\textbf{X}} = 20 \\textbf{X} $\n","62a8cd90":"![](https:\/\/i.gifer.com\/S76D.gif)","49f444c9":"**\u041e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 \u0441 \u0434\u0432\u0443\u043c\u044f \u0442\u0435\u043d\u0437\u043e\u0440\u0430\u043c\u0438**","357ca83a":"**\u0418\u043d\u0434\u0435\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435**","d28a6bf3":"**\u0422\u0438\u043f\u044b \u0434\u0430\u043d\u043d\u044b\u0445**","40187300":"**\u041c\u0430\u0441\u043a\u0438**","b6581fdc":"**\u041a\u043e\u043f\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0442\u0435\u043d\u0437\u0435\u0440\u043e\u0432**","11a1c261":"# \u041b\u0435\u043a\u0446\u0438\u044f 3. Pytorch, \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0441\u043f\u0443\u0441\u043a\u0430\n\n![](https:\/\/i.gifer.com\/G2It.gif)","4725fc3b":"**\u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 gpu\\cpu**","7ed7a5be":"@ - \u043c\u0430\u0442\u0440\u0438\u0447\u043d\u043e\u0435 \u0443\u043c\u043d\u043e\u0436\u0435\u043d\u0438\u0435"}}