{"cell_type":{"29fa1047":"code","75b8e0bb":"code","d44f29d4":"code","dc6ba972":"code","956c9a58":"code","7c763f7a":"code","1120295d":"code","244e0de1":"code","b6a3eac8":"code","a33bd299":"code","64fbaff1":"code","56f73b6f":"code","a85d123d":"code","03e67597":"code","7927dbe2":"code","40de0d4a":"code","dea297fd":"code","9dad9d24":"code","a808bcc5":"code","63291f15":"code","58fda399":"code","4be62174":"code","9d7a9338":"code","b069142c":"code","7da94b63":"code","a3df09df":"code","340a0aad":"code","5b1cf381":"code","ae51ba48":"code","3a767376":"code","606afe51":"code","1147ce4a":"code","218c34b5":"code","a800d763":"markdown","bb5c54fc":"markdown","87cf3ca8":"markdown","d5e1de87":"markdown","27f5c51c":"markdown","037fffe8":"markdown","6337addf":"markdown","5aca3a73":"markdown","d178f84f":"markdown","85b7f4dc":"markdown","3caa6ae7":"markdown","88b6183e":"markdown","be92785c":"markdown","2014baa1":"markdown","386f3f53":"markdown","f6e7b735":"markdown","7405c2e5":"markdown","57dd4b8e":"markdown","dc8d6a39":"markdown","ddd7e2db":"markdown","be2e1a66":"markdown","582e4e3d":"markdown","dcb93cfa":"markdown","181bf78c":"markdown","50d93233":"markdown","c8844eaf":"markdown","05b95570":"markdown","83bf8927":"markdown","2ccb210e":"markdown","765e0ad5":"markdown","2a0eff7d":"markdown"},"source":{"29fa1047":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","75b8e0bb":"data = pd.read_csv('..\/input\/FIFA 2018 Statistics.csv')\ny = (data['Man of the Match'] == \"Yes\")  # Convert from string \"Yes\"\/\"No\" to binary\n\nfeature_names = [i for i in data.columns if data[i].dtype in [np.int64]]\nX = data[feature_names]","d44f29d4":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)","dc6ba972":"my_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)","956c9a58":"import eli5\nfrom eli5.sklearn import PermutationImportance","7c763f7a":"perm = PermutationImportance(my_model, random_state = 1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = val_X.columns.tolist())","1120295d":"!conda install -c conda-forge Skater -y","244e0de1":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# Reference for customizing matplotlib: https:\/\/matplotlib.org\/users\/style_sheets.html\nplt.style.use('ggplot')","b6a3eac8":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\n\nfrom skater.core.explanations import Interpretation\nfrom skater.model import InMemoryModel","a33bd299":"data = load_breast_cancer()\n# Description of the data\nprint(data.DESCR)\npd.DataFrame(data.target_names)","64fbaff1":"X = data.data\ny = data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","56f73b6f":"def model_training(X_train, y_train):\n    clf1 = LogisticRegression(random_state=1)\n    clf2 = RandomForestClassifier(random_state=1)\n    clf3 = GaussianNB()\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n    eclf = eclf.fit(X_train, y_train)\n    return (clf1,clf2,clf3, eclf)\n\nclf1,clf2,clf3, eclf = model_training(X_train,y_train)","a85d123d":"def train_all_model(clf1,clf2,clf3, X_train,y_train):\n    clf1 = clf1.fit(X_train, y_train)\n    clf2 = clf2.fit(X_train, y_train)\n    clf3 = clf3.fit(X_train, y_train)\n    models = {'lr':clf1, 'rf':clf2, 'gnb':clf3, 'ensemble':eclf}\n    return (clf1,clf2,clf3, models)\n\nclf1,clf2,clf3, models = train_all_model(clf1,clf2,clf3,X_train,y_train)","03e67597":"# Ensemble Classifier does not have feature importance enabled by default\nf, axes = plt.subplots(2, 2, figsize = (26, 18))\n\nax_dict = {'lr':axes[0][0],'rf':axes[1][0],'gnb':axes[0][1],'ensemble':axes[1][1]}\ninterpreter = Interpretation(X_test, feature_names=data.feature_names)\n\nfor model_key in models:\n    pyint_model = InMemoryModel(models[model_key].predict_proba, examples=X_test)\n    ax = ax_dict[model_key]\n    interpreter.feature_importance.plot_feature_importance(pyint_model, ascending=True, ax=ax)\n    ax.set_title(model_key)","7927dbe2":"# Before interpreting, lets check on the accuracy of all the models\nfrom sklearn.metrics import f1_score\nfor model_key in models:\n        print(\"Model Type: {0} -> F1 Score: {1}\".\n              format(model_key, f1_score(y_test, models[model_key].predict(X_test))))","40de0d4a":"%matplotlib inline\nX_train = pd.DataFrame(X_train)\nX_train.head()","dea297fd":"def understanding_interaction():\n    pyint_model = InMemoryModel(eclf.predict_proba, examples=X_test, target_names=data.target_names)\n    # ['worst area', 'mean perimeter'] --> list(feature_selection.value)\n    interpreter.partial_dependence.plot_partial_dependence(list(feature_selection.value),\n                                                                    pyint_model, \n                                                                    grid_resolution=grid_resolution.value, \n                                                                    with_variance=True)\n        \n    # Lets understand interaction using 2-way interaction using the same covariates\n    # feature_selection.value --> ('worst area', 'mean perimeter')\n    axes_list = interpreter.partial_dependence.plot_partial_dependence([feature_selection.value],\n                                                                       pyint_model, \n                                                                       grid_resolution=grid_resolution.value, \n                                                                       with_variance=True)","9dad9d24":"!conda install ipywidgets --yes","a808bcc5":"# One could further improve this by setting up an event callback using\n# asynchronous widgets\nimport ipywidgets as widgets\nfrom ipywidgets import Layout\nfrom IPython.display import display\nfrom IPython.display import clear_output\ngrid_resolution = widgets.IntSlider(description=\"GR\", \n                                    value=10, min=10, max=100)\ndisplay(grid_resolution)\n\n# dropdown to select relevant features from the dataset\nfeature_selection = widgets.SelectMultiple(\n    options=tuple(data.feature_names),\n    value=['worst area', 'mean perimeter'],\n    description='Features',\n    layout=widgets.Layout(display=\"flex\", flex_flow='column', align_items = 'stretch'),\n    disabled=False,\n    multiple=True\n)\ndisplay(feature_selection)","63291f15":"# Reference: http:\/\/ipywidgets.readthedocs.io\/en\/latest\/examples\/Widget%20Events.html\nbutton = widgets.Button(description=\"Generate Interactions\")\ndisplay(button)\n\ndef on_button_clicked(button_func_ref):\n    clear_output()\n    understanding_interaction()\n\nbutton.on_click(on_button_clicked)","58fda399":"from skater.core.local_interpretation.lime.lime_tabular import LimeTabularExplainer\nfrom IPython.display import display, HTML, clear_output\nint_range = widgets.IntSlider(description=\"Index Selector\", value=9, min=0, max=100)\ndisplay(int_range)\n\ndef on_value_change(change):\n    index = change['new']\n    exp = LimeTabularExplainer(X_test, \n                           feature_names=data.feature_names, \n                           discretize_continuous=False, \n                           class_names=['p(Cancer)-malignant', 'p(No Cancer)-benign'])\n    print(\"Model behavior at row: {}\".format(index))\n    # Lets evaluate the prediction from the model and actual target label\n    print(\"prediction from the model:{}\".format(eclf.predict(X_test[index].reshape(1, -1))))\n    print(\"Target Label on the row: {}\".format(y_test.reshape(1,-1)[0][index]))\n    clear_output()\n    display(HTML(exp.explain_instance(X_test[index], models['ensemble'].predict_proba).as_html()))\n    \nint_range.observe(on_value_change, names='value')","4be62174":"from IPython.display import Image\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport xgboost\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image","9d7a9338":"data = pd.read_csv(\"..\/input\/FIFA 2018 Statistics.csv\")\ny = (data['Man of the Match'] == \"Yes\")  # Convert from string \"Yes\"\/\"No\" to binary\nfeature_names = [i for i in data.columns if data[i].dtype in [np.int64, np.int64]]\nX = data[feature_names]\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=9487)","b069142c":"params = {'base_score': 0.5,\n         'booster': 'gbtree',\n         'colsample_bylevel': 1,\n         'colsample_bytree': 1,\n         'gamma': 0,\n         'learning_rate': 0.05,\n         'max_delta_step': 0,\n         'max_depth': 3,\n         'min_child_weight': 1,\n         'missing': None,\n         'n_estimators': 400,\n         'n_jobs': 1,\n         'objective': 'binary:logistic',\n         'random_state': 0,\n         'reg_alpha': 0,\n         'reg_lambda': 1,\n         'scale_pos_weight': 1,\n         'seed': 0,\n         'silent': True,\n         'subsample': 1}\n\nparams['eval_metric'] = 'auc'","7da94b63":"d_train = xgboost.DMatrix(X_train, y_train)\nd_val = xgboost.DMatrix(X_val, y_val)\nwatchlist = [(d_train, \"train\"), (d_val, \"valid\")]\n\n#train model\n\nmodel = xgboost.train(params, d_train, num_boost_round=2000, evals=watchlist, early_stopping_rounds=100, verbose_eval=10)","a3df09df":"# Simple check what model ran out of things\ndata_for_prediction = xgboost.DMatrix(X_train.iloc[[83],:])  # use 1 row of data here. Could use multiple rows if desired\nmodel.predict(data_for_prediction)","340a0aad":"import shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(model)\n# Calculate Shap values\nshap_values = explainer.shap_values(X_train)\nshap.initjs()","5b1cf381":"shap.summary_plot(shap_values, X_train)","ae51ba48":"data_for_prediction = xgboost.DMatrix(X_train.iloc[[10],:])  # use 1 row of data here. Could use multiple rows if desired\nprint(f\"The 85th data is predicted to be True's probability: {model.predict(data_for_prediction)}\")\nshap.force_plot(explainer.expected_value, shap_values[10,:], X_train.iloc[10,:])","3a767376":"data_for_prediction = xgboost.DMatrix(X_train.iloc[[83],:])  # use 1 row of data here. Could use multiple rows if desired\nprint(f\"The 83rd data is predicted to be True's probability: {model.predict(data_for_prediction)}\")\nshap.force_plot(explainer.expected_value, shap_values[83,:], X_train.iloc[83,:])","606afe51":"plt.figure(figsize=(20,8))\nxs = np.linspace(-5,5,100)\nplt.xlabel(\"Log odds of winning\")\nplt.ylabel(\"Probability of winning\")\nplt.title(\"Log odds & prob of winning convert\")\nplt.plot(xs, 1\/(1+np.exp(-xs)))\n\nnew_ticks = np.linspace(-5, 5, 11)\nplt.xticks(new_ticks)\nplt.show()","1147ce4a":"shap.force_plot(explainer.expected_value, shap_values, X_train)","218c34b5":"shap.dependence_plot('Ball Possession %', shap_values, X_train, interaction_index=\"Goal Scored\")","a800d763":"### **6.Global Intepretability**","bb5c54fc":"### **1.Load Packages**","87cf3ca8":"**Note :** This tutorial made for learning and all content with proper references listed below. still found any feed back on comment.\n\n### **References**\n\n1. https:\/\/github.com\/slundberg\/shap\n2. https:\/\/github.com\/datascienceinc\/Skater\n3. https:\/\/eli5.readthedocs.io\/en\/latest\/","d5e1de87":"---\n\n# **3.SHAP**\n\n---\n\n**More Example for Learning: https:\/\/github.com\/slundberg\/shap**\n\n* Shap values show how much a given feature changed our prediction (compared to if we made that prediction at some baseline value of that feature).\n* For example, consider an ultra-simple model: $$y = 4 * x1 + 2 * x2$$\n\n* If $x1$ takes the value 2, instead of a baseline value of 0, then our SHAP value for $x1$ would be 8 (from 4 times 2).\n* These are harder to calculate with the sophisticated models we use in practice. But through some algorithmic cleverness, Shap values allow us to decompose any prediction into the sum of effects of each feature value, yielding a graph like this:\n\n![](https:\/\/camo.githubusercontent.com\/06cf2db4ee53c00baa7d20c8b1ccfcccdfd964f1\/68747470733a2f2f692e696d6775722e636f6d2f4a56443255376b2e706e67)\n\n\n### **1.Read Packages**","27f5c51c":"### **9.Evaluate a point locally, lets apply Local Interpretation using an interactive slider**","037fffe8":"### **3.Train Test Split**","6337addf":"### **4.Model Training**","5aca3a73":"Through global and local interpretation, one can understand the interaction between independent (input features) and dependent variables (P (cancer) \/ P (no cancer) by interrogating the behavior of the model, and the importance of features helps us understand better The weights of the variables used are understood by the predictive model: partial dependency graphs and LIME help to understand the interactions between variables that influence prediction.","d178f84f":"### **2.Read Data**","85b7f4dc":"### **6.Decision Boundaries**","3caa6ae7":"### **7.Partial Dependence Plots with Interactive slider for controlling grid resolution**","88b6183e":"### **3.Parameter Tuning**","be92785c":"### **Interpreting Permutation Importances**\n* The qualities towards the best are the most essential features, and those towards the base issue least.\n* The primary number in each row demonstrates how much model execution diminished with an random shuffling (for this situation, utilizing \"accuracy\" as the execution metric).\n* Like most things in the stream of data science, there is some randomness to the definite execution change from a shuffling a data. We measure the measure of haphazardness in our permutation importance estimation by repeating the procedure with numerous mixes. The number after the \u00b1 measures how execution differed starting with one-reshuffling then onto the next.\n* We'll sporadically observe negative values for permutation importances. In those cases, the forecasts on the shuffled (or noisy) information happened to be more exact than the genuine data. This happens when the feature didn't make a difference (ought to have had an importance near 0), yet arbitrary shot made the forecasts on shuffled data be progressively precise. This is increasingly basic with little datasets, similar to the one in this model, in light of the fact that there is more space for good fortune\/possibility. \n* In our precedent, the most imperative feature was Goals scored. That appears to be reasonable. Soccer fans may have some instinct about whether the orderings of different variables(factor) are astounding or not.","2014baa1":"### **10.Dependence_plot**","386f3f53":"### **4.Model Training**","f6e7b735":"### **2.Load Data**","7405c2e5":"### **8.Output Value **","57dd4b8e":"---\n\n# **2.Skater**\n\n---\n### **Reference : https:\/\/datascienceinc.github.io\/Skater\/tutorial.html**\n* ***Skater is a unified framework that allows the interpretation of models for all forms of models to help build an interpretable machine learning system that is often needed for real world use cases using an agnostic approach.*** The **Python library** is designed to ***demystify the structures learned from a black box model globally*** (inference based on a complete data set) and locally (inference about individual prediction).\n\n![](https:\/\/cdn-images-1.medium.com\/max\/720\/0*JwGzVZvQ6yWNODLM.png)\n\n* The skater initially began as a part of LIME and was then developed as a independent structure with an assortment of features and abilities to interpretation independent models for all black box. The undertaking started as an research idea to discover courses for better interpretability (ideally human interpretability) to predict \"Black Boxes\" for scientists and researchers.\n\nDocumentation for Reading\n\n|||\n|---------------------------------------------------------------------------------------|----------------------------------------------|\n| [**Overview**](https:\/\/datascienceinc.github.io\/Skater\/overview.html) | Introduction to the Skater library |\n| [**Installing**](https:\/\/datascienceinc.github.io\/Skater\/install.html) | How to install the Skater library |\n| [**Tutorial**](https:\/\/datascienceinc.github.io\/Skater\/tutorial.html) | Steps to use Skater effectively. |\n| [**API Reference**](https:\/\/datascienceinc.github.io\/Skater\/api.html) | The detailed reference for Skater's API. |\n| [**Contributing**](https:\/\/github.com\/datascienceinc\/Skater\/blob\/master\/CONTRIBUTING.rst) | Guide to contributing to the Skater project. |\n\n### **Skater Technique**\n\n![](https:\/\/cdn-images-1.medium.com\/max\/900\/1*qrdvdL1aIElWDw58ghFK4Q.png)","dc8d6a39":"### **4.Model Training**","ddd7e2db":"### **9.Aggregated force_plot**","be2e1a66":"### **7.ForcePlot**","582e4e3d":"### **Installation**","dcb93cfa":"### **2.Load Dataset**","181bf78c":"### **5.Permutation Importance**","50d93233":"### **1.Load Packages**","c8844eaf":"### **5.Model Interpretation**","05b95570":"### **3.Train test split**","83bf8927":"### **8.Understanding interaction using interactive widgets**","2ccb210e":"---\n\n# **1.ELI5**\n\n---\n # **Permutation Feature Importance**\n* ***Permutation Feature Importance is an algorithm that ascertains hugeness scores for every one of the characteristic factors in a dataset. Proportions of importance are controlled by figuring the affectability of a model to arbitrary permutations of characteristic values. As such, an importance score measures the commitment of a specific characteristic to the prescient execution of a model as far as the amount of a picked assessment metric that is avoided in the wake of changing the estimations of that characteristic.***\n\n* ***The instinct behind permutation importance is that on the off chance that a feature isn't helpful for forecasting a result, at that point adjusting or permuting its qualities won't result in a critical decrease in a model's execution. This procedure is regularly utilized in [random forests](http:\/\/oz.berkeley.edu\/~breiman\/randomforests-rev.pdf) and is portrayed by Breiman in his original paper Random Forests. The methodology, nonetheless, can be summed up and adjusted to other order and relapse models.***\n \n ***Reading : https:\/\/eli5.readthedocs.io\/en\/latest\/overview.html***","765e0ad5":"## **Interpreting Machine Learning models is no more a lavishness but a requirement given the acute compliance of AI in the industry.**\n\n---\n\n### **Hands-on Guide of explain potential black-box machine learning models**\n\n* Kaggle FIFA Dataset\n* **Objective of this notebook to give hands-on experience of Machine Learning model intepretation.**\n\n### **Frame Work Going to Cover**\n* [**1.ELI5**](#1.ELI5)\n* [**2.Skater**](#2.Skater)\n* [**3.SHAP**](#3.SHAP)\n* [**References**](#References)","2a0eff7d":"### **5.Model Interpretability**"}}