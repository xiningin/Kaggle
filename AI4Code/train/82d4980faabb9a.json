{"cell_type":{"12cbe892":"code","b53f68f9":"code","0ba9642a":"code","2a5a4d6f":"code","8165946f":"code","827907ba":"code","c2fef838":"code","bab19322":"code","313092bd":"code","309ecc93":"code","9758cc01":"code","7368260f":"code","3d3b4fd5":"code","233fc549":"code","48d5d1f8":"code","88a95799":"code","2407162f":"code","fd4a2a10":"code","2a053359":"code","35139d57":"code","dcd39d82":"code","24e37c35":"code","38e15498":"code","ec4a2914":"code","6ad1a282":"code","d7a3e62f":"code","7af83813":"code","2d75be41":"code","78595f44":"code","4b8a0d79":"code","bab6b005":"code","363ef982":"code","22acbc6a":"code","324ae95f":"code","6d40fc6b":"code","5632e7d8":"code","46b05d26":"code","825dcd2b":"code","0f9596c7":"code","fd9e68ee":"code","064ff54f":"code","492ac045":"code","8ae1cfa9":"code","f89b1c61":"code","277cd651":"code","953baae2":"code","f2426681":"code","d6cf66dd":"code","565ab977":"code","9a880193":"code","ae2f13f7":"code","f5f7395d":"markdown","f8b2a166":"markdown","191ada55":"markdown","5637d662":"markdown","b20b43c8":"markdown","b3879066":"markdown","72e1f86d":"markdown","c48f0b2e":"markdown","c8055737":"markdown"},"source":{"12cbe892":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # visuallization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b53f68f9":"data = pd.read_csv('\/kaggle\/input\/fifa19\/data.csv')","0ba9642a":"data.info() # We will learn something about this data set","2a5a4d6f":"data.corr() # We will make it better after Code Line\n# We make with matplotlib","8165946f":"f,ax = plt.subplots(figsize = (18,18))\nsns.heatmap(data.corr(), annot = True , linewidths = 1, fmt = '.1f',ax = ax)\nplt.title('Correlation Map of Data Set')\nplt.show()","827907ba":"data.head()\n# Default value is 5 but you can change it like this","c2fef838":"data.head(10)\n# \".tail()\" method also works in the same logic  ","bab19322":"data.tail()","313092bd":"data.tail(10)","309ecc93":"data.columns\n# We can learn columns' names with this methods","9758cc01":"# First of all we must fix the column names \ndata.columns = [each.split()[0]+'_'+each.split()[1] if(len(each.split()) > 1) else each for each in data.columns]\n#This method combines spaces between words\ndata.columns = [each.lower() for each in data.columns]\n#This method writes the titles in lower case\n#We will learn for loop later in this kernel","7368260f":"data.columns\n# This looks better","3d3b4fd5":"# Line Plot \ndata.overall.plot(kind = 'line',color = 'red',label = \"Overall\",linewidth = 0.75,alpha = 1,grid = True)\ndata.potential.plot(color = 'green',label = 'Potential',linewidth = 1,grid = True,alpha = 0.15,linestyle = '-.')\nplt.legend(loc = 'upper right')\nplt.xlabel('X Axis')\nplt.ylabel('Y Axis')\nplt.title('Example of Line Plot')\nplt.show()","233fc549":"#Scatter Plot\ndata.plot(kind = 'scatter', x = 'acceleration',y = 'sprintspeed',alpha = 0.25,color = 'red')\nplt.xlabel('Acceleration')\nplt.ylabel('Sprintspeed')\nplt.title('Acceleration and Sprint Speed Scatter Plot')\nplt.show()","48d5d1f8":"#Histogram Plot\n# bins = number of bar in figure\ndata.jersey_number.plot(kind = 'hist',bins = 99,figsize = (10,10))\nplt.xlabel('Players Jersey Number')\nplt.ylabel('Frequency')\nplt.show()\n# bins is 99 because 99 kind jersey number we have","88a95799":"#Let's create a dictionary!\ndictionary = {'fruit' : 'apple','vegetable' : 'carrot'}\n# fruit and vegetable are \"KEY\"\n# apple and carrot are \"VALUE\"\nprint(dictionary.keys())\nprint(dictionary.values())","2407162f":"dictionary['fruit'] = 'banana' # update\nprint(dictionary)\ndictionary['fast-food'] = 'hamburger' # new entry\nprint(dictionary)\ndel dictionary['fruit'] # remove entry with key 'fruit'\nprint('fast-food' in dictionary) # cheack include or not\ndictionary.clear() #remove all entries in dictionary\nprint(dictionary)","fd4a2a10":"# Comparison operator\n\nprint(156 > -1)\nprint(1000000000 != 0)\n\n# Boolean operators\nprint(True and False)\nprint(True or False)","2a053359":"x = data.gkreflexes > 88\n# We have a 7 player who have higher goalkeeper reflexes value than 90\ndata[x]","35139d57":"# Let's use one Boolean operator\ndata[np.logical_and(data.gkreflexes > 88,data.overall >= 90)]\n#You can only use 2 comparison options","dcd39d82":"# You can use Code line too\ndata[(data.gkreflexes > 88) & (data.overall >= 90)]","24e37c35":"n = 0\nwhile n != 5:\n    print('n is : ',n)\n    n += 1\nprint(n,' is equal to 5')    ","38e15498":"array1 = np.arange(1,6,1)# You don't need this method but this is same logic with lis = [1,2,3,4,5] \nlis = list(array1)\nfor n in lis:\n    print('n is : ',n)\nprint(' ')    ","ec4a2914":"# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   ","6ad1a282":"# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'fruit' : 'apple','vegetable' : 'carrot'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')","d7a3e62f":"# For pandas we can achieve index and value\nfor index,value in data[['overall']][0:1].iterrows():\n    print(index, ' : ' ,value)","7af83813":"data = pd.read_csv(\"\/kaggle\/input\/fifa19\/data.csv\")\ndata.head() # We learned this code line the starting of this kernel","2d75be41":"data.tail() # This too","78595f44":"# shape gives number of rows and columns in a tuble\ndata.shape","4b8a0d79":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","bab6b005":"data.columns = [each.split()[0]+\"_\"+each.split()[1] if(len(each.split()) > 1) else each for each in data.columns]\ndata.columns = [each.lower() for each in data.columns]\ndata.columns","363ef982":"data_head = data.head(125)\na = data_head.nationality.value_counts(dropna = False)\na","22acbc6a":"data.describe()","324ae95f":"data.boxplot(column = \"stamina\",by = \"work_rate\",figsize = (12,12))\nplt.show()","6d40fc6b":"data_new = data.head(10)\ndata_new","5632e7d8":"data.columns","46b05d26":"# Firstly I create new data from players data to explain melt more easily.\n# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame = data_new,id_vars = \"name\",value_vars = [\"age\",\"work_rate\",\"value\",\"wage\"])\nmelted","825dcd2b":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\n\npivoted = melted.pivot(index = \"name\",columns = \"variable\",values = \"value\")\npivoted","0f9596c7":"# We can concatenate two dataframe\n# Firstly lets create 2 data frame\n\ndata_head = data.head()\ndata_tail = data.tail()\n\nconc_data_row = pd.concat([data_head,data_tail],axis = 0,ignore_index = True)\nconc_data_row","fd9e68ee":"data1 = data.overall.head()\ndata2 = data.potential.head()\n\ndata_1_and_2_conc = pd.concat([data1,data2],axis = 1)\n# axis = 0 : adds dataframes in row\ndata_1_and_2_conc","064ff54f":"data.dtypes","492ac045":"# lets convert object(str) to categorical and int to float\ndata.nationality = data.nationality.astype(\"category\")\ndata.overall = data.overall.astype(\"float\")","8ae1cfa9":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","f89b1c61":"# Lets look at does player data have nan value\n# As you can see there are 18207 entries. However release_clause has 16643 non-null object so it has 1564 null object.\ndata.info()","277cd651":"data.release_clause.value_counts(dropna = False)","953baae2":"data.release_clause.dropna(inplace = True) # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","f2426681":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","d6cf66dd":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","565ab977":"assert data.release_clause.notnull().all() # returns nothing because we drop nan values","9a880193":"data.release_clause.fillna('empty',inplace = True)","ae2f13f7":"assert data.release_clause.notnull().all()# returns nothing because we do not have nan values","f5f7395d":"***MISSING DATA and TESTING WITH ASSERT***\nIf we encounter with missing data, what we can do:\n\n\n1]leave as is\n\n2]drop them with dropna()\n\n3]fill missing value with fillna()\n\n4]fill missing values with test statistics like mean\n\nAssert statement: check that you can turn on or turn off when you are done with your testing of the program\n","f8b2a166":"**DATA TYPES**","191ada55":"***3.CLEANING DATA***","5637d662":"In this part , you have to learn:\n\n1]How to import csv file,\n\n2]Plotting line,Scatter Line and Histogram,\n\n3]Basic dictionary features,\n\n4]Basic pandas features like filtering that is actually something always used and main for being data scientist,\n\n5]While and For loops:\n","b20b43c8":"Before continue with pandas, we need to learn **logic**, **control** **flow** and **filtering**.\n\nComparison operator: ==, <, >, <=\n\nBoolean operators: and, or ,not","b3879066":"***!!! First of all !!!* **\nSorry for my English skills\nThank you for your understanding","72e1f86d":"value_counts(): Frequency counts\n\noutliers: the value that is considerably higher or lower from rest of the data\n\nLets say value at 75% is Q3 and value at 25% is Q1.\n\nOutlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n\nWe will use describe() method. Describe method includes:\n\ncount: number of entries\n\nmean: average of entries\n\nstd: standart deviation\n\nmin: minimum entry\n\n25%: first quantile\n\n50%: median or second quantile\n\n75%: third quantile\n\nmax: maximum entry\n","c48f0b2e":"What is quantile?\n\n1,4,5,6,8,9,11,12,13,14,15,16,17\n\nThe median is the number that is in middle of the sequence. In this case it would be 11.\n\n\nThe lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n\n\nThe upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.\n\n","c8055737":"**WHILE** and **FOR LOOPS**"}}