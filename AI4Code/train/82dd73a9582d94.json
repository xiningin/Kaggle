{"cell_type":{"903b95e9":"code","9c183ce2":"code","8657ceda":"code","e5066845":"code","59abd3dc":"code","08a75f93":"code","64e21d98":"code","9808ae73":"code","99b67fac":"code","76213b0c":"code","2d79219f":"code","492ae06e":"code","20faec33":"code","513e315e":"code","0b6aa665":"code","fa8228ee":"markdown","f25f1dd1":"markdown"},"source":{"903b95e9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nimport requests\nfrom urllib.request import urlretrieve\nimport shutil\nfrom io import StringIO, BytesIO\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_absolute_error, roc_auc_score, log_loss, f1_score\nimport warnings\nfrom termcolor import colored\nfrom datetime import timedelta, datetime\nfrom tqdm.notebook import tqdm\n\nfrom functools import partial\nimport numpy as np\nimport scipy as sp\n\ntqdm.pandas()\n\nwarnings.filterwarnings(\"ignore\")","9c183ce2":"def data_from_link(link):\n    re = requests.get(link)\n    assert re.status_code == 200, 'Download Failed'\n    return pd.read_csv(BytesIO(re.content))","8657ceda":"train_link = 'https:\/\/datahack-prod.s3.amazonaws.com\/train_file\/train_fNxu4vz.csv'\ntest_link = 'https:\/\/datahack-prod.s3.amazonaws.com\/test_file\/test_fjtUOL8.csv'\nsubmission_link = 'https:\/\/datahack-prod.s3.amazonaws.com\/sample_submission\/sample_submission_HSqiq1Q.csv'","e5066845":"%%time\ntrain = data_from_link(train_link)\nprint('train file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\ntest = data_from_link(test_link)\nprint('test file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\nsubmission = data_from_link(submission_link)\nprint('submission file have {} rows and {} columns'.format(submission.shape[0], submission.shape[1]))\n\ntrain['Loan_Amount_Requested'] = train['Loan_Amount_Requested'].str.replace(',', '').astype('float')\ntest['Loan_Amount_Requested'] = test['Loan_Amount_Requested'].str.replace(',', '').astype('float')\ntrain['Length_Employed'] = train['Length_Employed'].replace({'< 1 year': '0', '1 year': '1', '10+ years': '10'}).str.replace(' years', '').astype('float')\ntest['Length_Employed'] = test['Length_Employed'].replace({'< 1 year': '0', '1 year': '1', '10+ years': '10'}).str.replace(' years', '').astype('float')","59abd3dc":"train.head(2)","08a75f93":"test.head(2)","64e21d98":"submission.head(2)","9808ae73":"class OptimizedRounder_v2(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [1, 2, 3])\n        return - f1_score(y, preds, average='weighted')\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = [1.5, 2.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')['x']\n    \n    def predict(self, X, coef=None):\n        if coef is None:\n            coef = self.coefficients()\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [1, 2, 3])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_","99b67fac":"class SimpleModel:\n    def __init__(self, train, n_splits, params, categorical):\n        self.feature = [col for col in train.columns if col not in ['Loan_ID', 'Interest_Rate']]\n        self.categorical = categorical\n        self.target = 'Interest_Rate'\n        self.n_splits = n_splits\n        self.params = params\n        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        train = train.copy()\n        train[self.categorical] = train[self.categorical].astype('category')\n        self.models = []\n        self.optimized_rounders = []\n        oof_pred = np.zeros((len(train),))\n        oof_pred_class = np.zeros((len(train),))\n        \n        for fold, (train_idx, val_idx) in enumerate(cv.split(train, train[self.target])):\n            x_train, x_val = train[self.feature].iloc[train_idx], train[self.feature].iloc[val_idx]\n            y_train, y_val = train[self.target][train_idx], train[self.target][val_idx]\n            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n            model = self.train_model(train_set, val_set)\n            oof_pred[val_idx] = model.predict(x_val)\n            self.models.append(model)\n            print('\\n\\n optimized rounder')\n            pred = model.predict(x_train)\n            opt_rounder = OptimizedRounder_v2()\n            opt_rounder.fit(pred, y_train)\n            self.optimized_rounders.append(opt_rounder)\n            print(f'coef: {opt_rounder.coefficients()}')\n            oof_pred_class[val_idx] = opt_rounder.predict(oof_pred[val_idx])\n\n            print('Partial score of fold {} is: {}'.format(fold, f1_score(y_val, opt_rounder.predict(oof_pred_class[val_idx]), average='weighted')))\n        \n        \n        loss_score = f1_score(train[self.target], oof_pred_class, average='weighted')\n        print('Our f1 score is: ', loss_score)\n\n        opt_rounder = OptimizedRounder_v2()\n        for i in range(len(self.optimized_rounders)):\n            if i == 0:\n                opt_rounder.coef_ = self.optimized_rounders[i].coef_\/self.n_splits\n            else:\n                opt_rounder.coef_ += self.optimized_rounders[i].coef_\/self.n_splits\n        print(f'coef: {opt_rounder.coefficients()}')\n        self.opt_rounder_avg = opt_rounder\n\n        loss_score = f1_score(train[self.target], self.opt_rounder_avg.predict(oof_pred), average='weighted')\n        print('Our f1 score is (opt avg): ', loss_score)\n\n\n    \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n        return train_set, val_set\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100\n        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], \n                         categorical_feature=self.categorical, verbose_eval=verbosity)\n    \n    def predict(self, test_df):\n        x_test = test_df[self.feature].copy()\n        x_test[self.categorical] = x_test[self.categorical].astype('category')\n        y_pred = np.zeros((len(test_df), ))\n        for model_ in self.models:\n            y_pred += model_.predict(x_test) \/ self.n_splits\n        return self.opt_rounder_avg.predict(y_pred)","76213b0c":"categorical_1 = ['Home_Owner', 'Income_Verified', 'Purpose_Of_Loan', 'Gender']\n\nparams = {'n_estimators':2500,\n            'boosting_type': 'gbdt',\n            'objective': 'fair',\n            'metric': ['l2', 'l1'],\n            'subsample': 0.70,\n            'subsample_freq': 1,\n            'learning_rate': 0.02,\n            'feature_fraction': 0.75,\n            'max_depth': 13,\n            'lambda_l1': 0.5,  \n            'lambda_l2': 0.5,\n            'early_stopping_rounds': 100,\n            'seed': 42\n            }\n\nmodel_train_1 = SimpleModel(train, n_splits=5, params=params, categorical=categorical_1)","2d79219f":"train['Interest_Rate'].value_counts(dropna=False, normalize=True)","492ae06e":"np.all(submission['Loan_ID'] == test['Loan_ID'])","20faec33":"submission['Interest_Rate'] = model_train_1.predict(test)\nsubmission.head()","513e315e":"submission['Interest_Rate'].value_counts(dropna=False, normalize=True)","0b6aa665":"submission.to_csv('submission_fair_loss.csv', index=False)","fa8228ee":"<font color=\"red\" size=\"5\">If you find it usefull, please upvote :) <\/font>","f25f1dd1":"## Approach :\n\nWe will use regression model and later find the threshold to classify interest rate.\n\nAdantage: It will internalize the fact that class 1, 2, 3 are monotonic\n\nThreshold : [Opitmizer Rounder](https:\/\/www.kaggle.com\/naveenasaithambi\/optimizedrounder-improved) to optimize thresholds"}}