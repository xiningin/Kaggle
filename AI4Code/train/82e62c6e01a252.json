{"cell_type":{"933f0b6f":"code","5991e0ee":"code","4d465c2f":"code","038b536e":"code","5882890a":"code","bfe9168c":"code","048acf25":"code","2811b92d":"code","571c2ef5":"code","2bd1f89d":"code","57f8fd4e":"code","9fb57e2d":"code","bf4d5b61":"code","c2a4a9a2":"code","90be0308":"code","551c9f86":"code","4adac834":"code","1122f776":"code","63459cda":"code","7bb0fc7a":"code","b2de70ab":"code","50ddb6bb":"code","d2a3d61e":"code","222632e4":"code","8dbfd39d":"code","5aa7671f":"code","65adc3ab":"code","8d52e0f3":"code","e21dbf38":"code","cf85ef24":"code","a5c57dea":"code","50f2a648":"code","5fa7ff33":"code","9e324256":"code","9a203dc4":"code","c21a6dc1":"code","9738d105":"code","809cff0c":"code","528de128":"code","62519ccf":"code","135e951a":"code","d7703cd5":"code","0201e545":"code","448a37f7":"code","e2783412":"code","9a6b07f1":"code","a8cc18e5":"code","c198f528":"code","8ee1d3d2":"code","c94b9cdb":"code","7b420b65":"code","4bedac36":"code","12f5a09a":"code","ad7c7a44":"code","3153a79d":"code","9a47e980":"code","68b49b3a":"markdown","a73bcee8":"markdown","6ca4d2be":"markdown","ca67f107":"markdown"},"source":{"933f0b6f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","5991e0ee":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nimport xgboost \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\npd.set_option('display.max_columns',None)","4d465c2f":"dataset = pd.read_csv('..\/input\/telecom-users-dataset\/telecom_users.csv')","038b536e":"dataset.columns","5882890a":"dataset.sort_values('Unnamed: 0')","bfe9168c":"dataset = dataset.drop(['Unnamed: 0','customerID'],axis=1)","048acf25":"dataset.isnull().sum()","2811b92d":"dataset","571c2ef5":"dataset.info()","2bd1f89d":"dataset['TotalCharges'] = dataset['TotalCharges'].str.strip()","57f8fd4e":"dataset['TotalCharges'] = np.where(dataset['TotalCharges']=='',0,dataset['TotalCharges'])","9fb57e2d":"dataset['TotalCharges'] = dataset['TotalCharges'].astype(float)","bf4d5b61":"dataset","c2a4a9a2":"dataset.describe(include='all')","90be0308":"numerical_features = [feat for feat in dataset.columns if dataset[feat].dtype!='O']\nnumerical_features","551c9f86":"for feat in numerical_features:\n    print(feat,',','Unique :', len(dataset[feat].unique()))","4adac834":"categorical_features = [feat for feat in dataset.columns if feat not in numerical_features and feat not in ['TotalCharges']+['Churn']]\ncategorical_features","1122f776":"for feat in categorical_features:\n    print(feat,',','Unique :', len(dataset[feat].unique()))","63459cda":"for feat in numerical_features:\n    \n    plt.figure(figsize=(9,6))\n    plt.style.use('ggplot')\n    dataset.groupby('Churn')[feat].count().plot.bar()\n    plt.xlabel('Churn',fontsize=12)\n    plt.ylabel(feat,fontsize=12)\n    plt.show()","7bb0fc7a":"for feat in numerical_features:\n    \n    plt.figure(figsize=(9,6))\n    plt.style.use('ggplot')\n    dataset.groupby('Churn')[feat].mean().plot.bar()\n    plt.xlabel('Churn',fontsize=12)\n    plt.ylabel(feat,fontsize=12)\n    plt.show()","b2de70ab":"plt.figure(figsize=(10,7))\nsns.heatmap(dataset.corr(),annot=True)","50ddb6bb":"for feat in numerical_features:\n\n    plt.figure(figsize=(9,6))\n    plt.style.use('ggplot')\n    sns.histplot(data=dataset,x=dataset[feat],color='red',kde=True)\n    plt.xlabel('Churn',fontsize=12)\n    plt.ylabel(feat,fontsize=12)\n    plt.show()","d2a3d61e":"for feat in numerical_features:\n    data =dataset.copy()\n    if 0 in data[feat].unique():\n        pass\n    else:\n        data[feat] = np.log(data[feat])\n        \n        data.boxplot(column=feat)\n    ","222632e4":"dataset[categorical_features]","8dbfd39d":"df =dataset.copy()","5aa7671f":"df[categorical_features]","65adc3ab":"encoding_feature = [feat for feat in categorical_features + ['Churn']]\nencoding_feature","8d52e0f3":"from sklearn.preprocessing import LabelEncoder\nfor feat in encoding_feature:\n    le = LabelEncoder()\n    df[feat]= le.fit_transform(df[feat])","e21dbf38":"df","cf85ef24":"dataset = df.copy()","a5c57dea":"dataset","50f2a648":"plt.figure(figsize=(15,10))\nsns.heatmap(dataset.corr(),annot=True)","5fa7ff33":"dataset","9e324256":"X = dataset.drop(['Churn','TotalCharges'],axis=1)","9a203dc4":"y = dataset['Churn']","c21a6dc1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","9738d105":"from sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel","809cff0c":"select_best_feat = SelectFromModel(Lasso(alpha=.001,random_state=101))","528de128":"select_best_feat.fit(X,y)","62519ccf":"select_best_feat.get_support()","135e951a":"selected_feat = X.columns[(select_best_feat.get_support())]","d7703cd5":"selected_feat","0201e545":"X_train= X_train[selected_feat]","448a37f7":"X_test= X_test[selected_feat]","e2783412":"from sklearn.preprocessing import MinMaxScaler","9a6b07f1":"scaler = MinMaxScaler()","a8cc18e5":"X_train_scaled = scaler.fit_transform(X_train)","c198f528":"X_test_scaled =  scaler.fit_transform(X_test)","8ee1d3d2":"key = ['LogisticRegression','KNeighborsClassifier','SVC','RandomForestClassifier','AdaBoostClassifier','XGBClassifier']\nvalue = [LogisticRegression(),KNeighborsClassifier(),SVC(),RandomForestClassifier(),AdaBoostClassifier(),xgboost.XGBClassifier()]\n\nmodel = dict(zip(key,value))\nmodel","c94b9cdb":"predictions = []\n\nfor i,k in model.items():\n    model = k\n    model.fit(X_train_scaled,y_train)\n    pred = model.predict(X_test_scaled)\n    score = accuracy_score(y_test,pred)\n    predictions.append(score)\n    print(i,score,'\\n')","7b420b65":"ada = AdaBoostClassifier(base_estimator=LogisticRegression(),\n    n_estimators=1000,\n    learning_rate=.1,\n    algorithm='SAMME.R')","4bedac36":"ada.fit(X_train,y_train)","12f5a09a":"ada.predict(X_test)","ad7c7a44":"accuracy_score(y_test,ada.predict(X_test))","3153a79d":"# !pip install keras-tuner","9a47e980":"from kerastuner import HyperModel\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch\n\n\nclass MyHyperModel(HyperModel):\n\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n\n    def build(self, hp):\n        model = keras.Sequential()\n        model.add(layers.Dense(units=hp.Int('units',\n                                            min_value=32,\n                                            max_value=512,\n                                            step=32),\n                               activation='relu'))\n        model.add(layers.Dense(self.num_classes, activation='softmax'))\n        model.compile(\n            optimizer=keras.optimizers.Adam(\n                hp.Choice('learning_rate',\n                          values=[1e-2, 1e-3, 1e-4])),\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n        return model\n\n\nhypermodel = MyHyperModel(num_classes=10)\n\ntuner = RandomSearch(\n    hypermodel,\n    objective='val_accuracy',\n    max_trials=20,\n    directory='my_dir',\n    project_name='helloworld')\n\ntuner.search(X_train, y_train,\n             epochs=20,\n             validation_data=(X_test,y_test))","68b49b3a":"# All Models Accuracy Score","a73bcee8":"# train_test_split","6ca4d2be":"# ANN And Keras Tuner","ca67f107":"# LogisticRegression\n"}}