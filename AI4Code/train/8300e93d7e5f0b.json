{"cell_type":{"3e901499":"code","55d06c13":"code","2d6cfc70":"code","2ab0b3ed":"code","904d92cf":"code","ef510b80":"code","4e55b421":"code","14852090":"code","8e561012":"code","d9748274":"code","849fa79f":"code","98a38b43":"code","cfc6b492":"code","9af26ca9":"code","2f3f3b37":"markdown","cb0c774b":"markdown"},"source":{"3e901499":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","55d06c13":"import pandas as pd\ntrain_data =pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nall_data = pd.concat([train_data, test_data])\n\nall_data\n","2d6cfc70":"y_train = train_data['Survived']\n\nall_data.drop(['Survived'], axis=1, inplace=True)\nall_data","2ab0b3ed":"all_data.dtypes","904d92cf":"all_data.drop(['Name'], axis=1, inplace=True)\nall_data.drop(['Ticket'], axis=1, inplace=True)\nprint('Sex_null_count :', all_data['Sex'].isnull().sum())\nprint('Age_null_count :', all_data['Age'].isnull().sum())\nprint('SibSp_null_count :', all_data['SibSp'].isnull().sum())\nprint('Parch_null_count :', all_data['Parch'].isnull().sum())\nprint('Fare_null_count :', all_data['Fare'].isnull().sum())\nprint('Cabin_null_count :', all_data['Cabin'].isnull().sum())\nprint('Embarked_null_count :', all_data['Embarked'].isnull().sum())","ef510b80":"import numpy as np\ngrouped = all_data.groupby('Sex').mean()\nall_data['Age'] = all_data['Age'].fillna(-1)\nall_data['Fare'] = all_data['Fare'].fillna(-1)\nall_data","4e55b421":"all_data['Cabin'] = all_data['Cabin'].fillna('Z')\nall_data['Cabin'] = all_data['Cabin'].apply(lambda x : str(x)[0])\ngroupby_cabin = all_data.groupby('Cabin')\ngroupby_cabin.count()","14852090":"all_data['Embarked'] = all_data['Embarked'].fillna('Z')\ngroupby_embarked = all_data.groupby('Embarked')\ngroupby_embarked.count()","8e561012":"print('Sex_null_count :', all_data['Sex'].isnull().sum())\nprint('Age_null_count :', all_data['Age'].isnull().sum())\nprint('SibSp_null_count :', all_data['SibSp'].isnull().sum())\nprint('Parch_null_count :', all_data['Parch'].isnull().sum())\nprint('Fare_null_count :', all_data['Fare'].isnull().sum())\nprint('Cabin_null_count :', all_data['Cabin'].isnull().sum())\nprint('Embarked_null_count :', all_data['Embarked'].isnull().sum())","d9748274":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\n\nall_data['Sex'] = encoder.fit_transform(all_data['Sex']) \nall_data['Cabin'] = encoder.fit_transform(all_data['Cabin']) \nall_data['Embarked'] = encoder.fit_transform(all_data['Embarked']) ","849fa79f":"x_train = all_data.iloc[:train_data.shape[0]]\nx_test = all_data.iloc[train_data.shape[0]:]\nx_train.tail()\nx_test.head()","98a38b43":"from xgboost import XGBClassifier\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\n\ny_train = y_train.to_numpy()\nx_train = x_train.to_numpy()\nx_test = x_test.to_numpy()\n\n\nparam_dist = {\n    'min_child_weight': [1, 5, 10],\n    'gamma': [0.5, 1, 1.5, 2, 5],\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'max_depth': [3, 4, 5]\n}\n\n\nxgb_model = XGBClassifier()\n\nmodel = RandomizedSearchCV(xgb_model,\n                           param_distributions= param_dist,\n                              cv=5)\n\nmodel.fit(x_train, y_train)\ny_predict = model.predict(x_test)\ny_predict","cfc6b492":"tmp = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ntmp","9af26ca9":"y_predict = pd.DataFrame(y_predict)\npassenger_id = tmp['PassengerId']\nresult_data = pd.concat([passenger_id,y_predict], axis=1, names=['PassengerId', 'Survived'])\n\nresult_data.columns =['PassengerId', 'Survived']\nresult_data.to_csv(\"result3_ramdomizedSearch.csv\", index=False)","2f3f3b37":"## train_data.shape = 891, 12 <br>\n## test_data.shape = 418, 11 <br>\n## all_data.shape = 1309,12 <br>\n","cb0c774b":"## \uacb0\uacfc csv \ud5e4\ub354, \uc778\ub371\uc2a4 \ud3ec\ud568, passengerid, survived "}}