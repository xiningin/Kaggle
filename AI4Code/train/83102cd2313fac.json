{"cell_type":{"300614b5":"code","543406cb":"code","d4683565":"code","b85fa86e":"code","339c6e08":"code","4ad23975":"code","1b3f8cab":"code","1ba99ad0":"code","3d25431f":"code","54de195f":"code","a301db89":"code","c61bc7ae":"code","8bbe63b3":"code","626724f2":"code","106ab81b":"code","8074d363":"code","a989c7be":"code","fd56f82f":"code","c73174fe":"code","1235ad02":"code","f1ec2ddf":"code","073c34fe":"code","300d2235":"code","f937d5b5":"code","5c7239ec":"code","88cd7b9c":"code","2d7fd7f1":"code","ff90f390":"code","d188b9c9":"code","aa8157c6":"code","11656950":"code","0da46b39":"code","46f5beff":"code","bbbee816":"markdown","8cb2eb1e":"markdown","8d44d2a5":"markdown","1069cdf6":"markdown","9186a699":"markdown","e16f0433":"markdown","3ee2a6dc":"markdown","e1845fa1":"markdown","d361e486":"markdown","2c34fbed":"markdown","bb4067e5":"markdown","29eabff5":"markdown","63f614c0":"markdown","9cd8a6d0":"markdown","c9bd4089":"markdown","4edcb1aa":"markdown","0803c543":"markdown","8f2d6342":"markdown","cf539d8a":"markdown","28973bc6":"markdown","810bbffe":"markdown"},"source":{"300614b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","543406cb":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","d4683565":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')","b85fa86e":"display(train.head(3))\ndisplay(test.head(3))\ndisplay(submission.head(3))","339c6e08":"print('Feature Names in Train:\\n\\n', train.columns)\nprint('\\n\\nFeature Names in Test:\\n\\n', test.columns)","4ad23975":"display(train.shape)\ndisplay(test.shape)\ndisplay(submission.shape)","1b3f8cab":"train_EDA = train.drop('PassengerId', axis=1)\ntest_EDA = test.drop('PassengerId', axis=1)","1ba99ad0":"display(train_EDA.describe())\ndisplay(test_EDA.describe())","3d25431f":"print('Number of Survivors and Non-Survivors:\\n\\n', train['Survived'].value_counts())\nprint('\\n\\n', sns.countplot(x='Survived', data=train))\nplt.show()","54de195f":"print('Number of Male and Female Passengers:\\n\\n', train['Sex'].value_counts())\nprint('\\n\\n', sns.countplot(x='Sex', data=train))\nplt.show()","a301db89":"print('Number of Embarked:\\n\\n', train['Embarked'].value_counts())\nprint('\\n\\n', sns.countplot(x='Embarked', data=train))\nplt.show()","c61bc7ae":"f, ax = plt.subplots(1,2,figsize=(18,8))  \n\ntrain_EDA['Survived'].value_counts().plot.pie(explode=[0,0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\nax[0].set_title('Pie plot - Survived')\nax[0].set_ylabel('') #ylabel = blank\n# Count the Survived in the file train_EDA\nsns.countplot('Survived', data=train_EDA, ax=ax[1])\nax[1].set_title('Count plot - Survived')\nplt.show()","8bbe63b3":"train_EDA[['Pclass','Survived']].groupby(['Pclass']).sum()","626724f2":"pd.crosstab(train_EDA['Pclass'],train_EDA['Survived'], margins=True).style.background_gradient(cmap='cool')","106ab81b":"pd.crosstab(train_EDA['Sex'], train_EDA['Survived'], margins=True).style.background_gradient(cmap='summer_r')","8074d363":"f,ax=plt.subplots(2, 2, figsize=(20,15))\n\nsns.countplot('Embarked', data=train_EDA, ax=ax[0,0])\nax[0,0].set_title('(1) No. Of Passengers Boarded')\n\nsns.countplot('Embarked', hue='Sex', data=train_EDA, ax=ax[0,1])\nax[0,1].set_title('(2) Male-Female Split for Embarked')\n\nsns.countplot('Embarked', hue='Survived', data=train_EDA, ax=ax[1,0])\nax[1,0].set_title('(3) Embarked vs Survived')\n\nsns.countplot('Embarked', hue='Pclass', data=train_EDA, ax=ax[1,1])\nax[1,1].set_title('(4) Embarked vs Pclass')\n\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","a989c7be":"# Pearson Correlation\nplt.figure(figsize=(8,6))\nsns.heatmap(train_EDA.corr(method='pearson'), annot=True, cbar=False, linewidth=0.2, fmt='0.2f');","fd56f82f":"# Spearman Correlation\nplt.figure(figsize=(8,6))\nsns.heatmap(train_EDA.corr(method='spearman'), annot=True, cbar=False, linewidth=0.2, fmt='0.2f');","c73174fe":"# kendall\nfig, ax = plt.subplots(1, 3, figsize=(17 , 5))\n\nfeature_lst = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n\ncorr = train_EDA[feature_lst].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nfor idx, method in enumerate(['pearson', 'kendall', 'spearman']):\n    sns.heatmap(train_EDA[feature_lst].corr(method=method), ax=ax[idx],\n            square=True, annot=True, fmt='.2f', center=0, linewidth=2,\n            cbar=False, cmap=sns.diverging_palette(240, 10, as_cmap=True),\n            mask=mask\n           ) \n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')     \n\nplt.show()","1235ad02":"# import H2O and AutoML package\nimport h2o\nfrom h2o.automl import H2OAutoML","f1ec2ddf":"# Initialize h2o\nh2o.init(\n    nthreads=-1,     # number of threads when launching a new H2O server\n    max_mem_size='16G'  # in gigabytes\n)","073c34fe":"train_data = h2o.import_file('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest_data = h2o.import_file('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')","300d2235":"# Identify predictors and response\nx = ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Ticket', 'Fare', 'Cabin', 'Embarked']\ny = 'Survived'","f937d5b5":"# Split the data in 80:20 ratio for training and testing\ntrain, test = train_data.split_frame(ratios=[0.8])","5c7239ec":"train_data.head()","88cd7b9c":"# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\naml = H2OAutoML(max_models=10000, seed=47, max_runtime_secs=1800)\naml.train(x=x, y=y, training_frame=train_data)\n\n# h2o train\n#aml = H2OAutoML(nfolds=10, sort_metric='auc', stopping_metric='auc', max_runtime_secs=3600*8, seed=0)","2d7fd7f1":"# Binary classification, the default ranking metric is Area Under the ROC Curve (AUC).\n# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head()","ff90f390":"# Get leaderboard with `extra_columns` = 'ALL'\nlb = h2o.automl.get_leaderboard(aml, extra_columns = 'ALL')\nlb","d188b9c9":"# To generate predictions on a test set, you can make predictions\n# directly on the `\"H2OAutoML\"` object or on the leader model\n# object directly\npreds = aml.predict(test_data)","aa8157c6":"print (preds)","11656950":"# Print all rows instead of default (10 rows)\n# Entire leaderboard\nlb.head(rows=lb.nrows)","0da46b39":"# The leader model is stored here\naml.leader","46f5beff":"# Get the top model of leaderboard\nse = aml.leader\n  \n# Get the metalearner model of top model\nmetalearner = h2o.get_model(se.metalearner()['name'])\n  \n# list baselearner models :\nmetalearner.varimp()","bbbee816":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> d) Preparing Dataset <\/h1>\n\n#### We need to decide on the features and the prediction columns. We use the same features and the predication column","8cb2eb1e":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> e) Applying AutoML <\/h1>\n\n#### Now, we are all set for applying AutoML on our dataset. The AutoML will run for a fixed amount of time set by us and give us the optimized model. We set up the AutoML using the following statement.\n\n#### The first parameter specifies the number of models that we want to evaluate and compare\n\n#### The second parameter specifies the time for which the algorithm runs","8d44d2a5":"submission['Survived'] = preds['predict']\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","1069cdf6":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\"> 3. Load Required Libraries <\/h1>","9186a699":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> b) Initialize H2O <\/h1>","e16f0433":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\"> 6. H20 AutoML <\/h1>","3ee2a6dc":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\"> 4. Import Data <\/h1>","e1845fa1":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\"> 2. Reference <\/h1>\n\n - https:\/\/www.kaggle.com\/saurabhshahane\/h2oautoml-template\n \n - https:\/\/www.kaggle.com\/tunguz\/apr-21-tps-h2o-automl\n    \n - https:\/\/www.h2o.ai\/products\/h2o-automl\/\n    \n - https:\/\/www.kaggle.com\/general\/232139\n    \n - https:\/\/www.analyticsvidhya.com\/blog\/2020\/11\/exploring-linear-regression-with-h20-automlautomated-machine-learning\/\n    \n - [Datacamp](https:\/\/www.datacamp.com\/community\/tutorials\/h2o-automl?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=278443377095&utm_targetid=aud-299261629574:dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=9061992&gclid=Cj0KCQjw38-DBhDpARIsADJ3kjkBfUqGMOh6PhnfNl3Zz9gImsOb8LeECsnqP3RNl5n1CyaCpZ_aEvsaAkZnEALw_wcB)","d361e486":"![H20](https:\/\/imgur.com\/6pCgC8e.png)","2c34fbed":"## Automatic machine learning broadly includes the following steps:\n\n- **Data preparation and Ingestion:** The real-world data can be raw data or just in any format. In this step, data needs to be converted into a format that can be processed easily. This also required to decide the data type of different columns in the dataset. We also required a clear knowledge about the task we need  to perform on data (e.g classification, regression, etc.)\n\n- **Feature Engineering:** This includes various steps that are required for cleaning the dataset such as dealing with NULL \/missing values, selecting the most important features of the dataset, and removing the low-correlational features, dealing with the skewed dataset.\n\n- **Hyperparameter Optimization:** To obtain the best results on any model, the AutoML need to carefully tune the hyperparameter values.\nModel Selection: H2O autoML trains with a large number of models in order to produce the best results. H2O AutoML also trains the data of different ensembles to get the best performance out of training data.","bb4067e5":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> f) Printing the Leaderboard <\/h1>\n\n#### When the AutoML processing completes, it creates a leaderboard ranking all the 30 algorithms that it has evaluated. To see the first 10 records of the leaderboard, use the following code","29eabff5":"## Table of Contents:\n\n#### 1. Intoduction\n#### 2. Reference\n#### 3. Load Required Libraries\n#### 4. Import Data\n#### 5. EDA (Explaratory Data Analysis)\n#### 6. H20 AutoML\n - **a) Importing AutoML**\n - **b) Initialize H2O**\n - **c) Loading Data**\n - **d) Preparing Dataset**\n - **e) Applying AutoML**\n - **f) Printing the Leaderboard**\n - **g) Predicting on Test Data**\n - **h) Printing Result**\n - **i) Printing the Ranking for All**\n - **j) Submission**","63f614c0":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> a) Importing AutoML <\/h1>\n\n#### First import H2O and AutoML package into the project","9cd8a6d0":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> c) Loading Data <\/h1>","c9bd4089":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\">1. Introduction <\/h1>","4edcb1aa":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\">4. Submission <\/h1>","0803c543":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\"> 5. EDA (Explaratory Data Analysis) <\/h1>","8f2d6342":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> g) Predicting on Test Data <\/h1>\n\n#### Now, you have the models ranked, you can see the performance of the top-rated model on your test data. To do so, run the following code statement","cf539d8a":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> i) Printing the Ranking for All <\/h1>\n\n#### If you want to see the ranks of all the tested algorithms, run the following code statement","28973bc6":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> h) Printing Result <\/h1>","810bbffe":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 15px 50px;\"> Auto-ML (Automated Machine Learning) <\/h1>"}}