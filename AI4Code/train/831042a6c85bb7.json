{"cell_type":{"9e12d53f":"code","2ba13d51":"code","8ace0c38":"code","acf67e2d":"code","4988dbf6":"code","aad346a3":"code","89baca76":"code","a57fad9e":"code","987cd986":"code","03639346":"code","15ff6e8a":"code","9051ccc7":"code","d97f0df0":"code","d8d94386":"markdown"},"source":{"9e12d53f":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python.keras import models\ntf.enable_eager_execution()","2ba13d51":"# input batch shape = (1, 2, 2, 1) -> (batch_size, height, width, channels) - 2x2x1 image in batch of 1\nx = tf.constant(np.array([[\n    [[1], [2]], \n    [[3], [4]]\n]]), tf.float32)","8ace0c38":"inputs = layers.Input(shape=(2,2,1))    # 256\noutputs = layers.Conv2DTranspose(1, (2, 2), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\nprint('For one channel input filtered once:')\nprint('Given input:\\n {}'.format(np.squeeze(x) ))\nprint('The output is:\\n {}'.format(np.squeeze(model.predict(x)) ))","acf67e2d":"inputs = layers.Input(shape=(2,2,1))    # 256\noutputs = layers.Conv2DTranspose(2, (2, 2), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\nprint('For one channel input filtered twice:')\nprint('output 1:\\n {}'.format(np.squeeze(model.predict(x)[0,:,:,0]) ))\nprint('output 2:\\n {}'.format(np.squeeze(model.predict(x)[0,:,:,1]) ))\n","4988dbf6":"x1 = tf.constant(np.array([[\n    [[1, 1], [2, 2]], \n    [[3, 3], [4, 4]]\n]]), tf.float32)\nprint('input with 2 channels:\\nchannel 1:\\n{}'.format(np.squeeze(x1.numpy()[0,:,:,0]) ))\nprint('channel 2:\\n{}'.format(np.squeeze(x1.numpy()[0,:,:,1]) ))","aad346a3":"inputs = layers.Input(shape=(2,2,2))    # 256\noutputs = layers.Conv2DTranspose(1, (2, 2), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\nprint('For 2-channel input filtered once:')\nprint('output:\\n{}'.format(np.squeeze(model.predict(x1)[0,:,:,0]) ))\n","89baca76":"inputs = layers.Input(shape=(2,2,2))    # 256\noutputs = layers.Conv2DTranspose(2, (2, 2), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\n\nprint('For 2-channel input filtered twice:')\nprint('output channel 1:\\n{}'.format(np.squeeze(model.predict(x1)[0,:,:,0]) ))\nprint('output channel 2:\\n{}'.format(np.squeeze(model.predict(x1)[0,:,:,1]) ))","a57fad9e":"x2 = tf.constant(np.array([[\n    [[1, 5], [2, 6]], \n    [[3, 7], [4, 8]]\n]]), tf.float32)\ny2 = np.array([\n    [6, 6, 8, 8], [6, 6, 8, 8], \n    [10, 10, 12, 12], [10, 10, 12, 12]\n])\nprint('Assumption 1: If input is\\n channel 1:\\n{}'.format(np.squeeze(x2.numpy()[0,:,:,0]) ))\nprint('channel 2:\\n{}'.format(np.squeeze(x2.numpy()[0,:,:,1]) ))\nprint('The output would be:\\n{}'.format(y2))","987cd986":"inputs = layers.Input(shape=(2,2,2))    # 256\noutputs = layers.Conv2DTranspose(1, (2, 2), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\nprint('output:\\n{}'.format(np.squeeze(model.predict(x2)[0,:,:,0]) ))\nprint('Assumption 1 is correct.')","03639346":"print('Assumption 2: When output 2 channels, the second one would the same.' )\ninputs = layers.Input(shape=(2,2,2))    # 256\noutputs = layers.Conv2DTranspose(2, (2, 2), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\nprint('output channel 1:\\n{}'.format(np.squeeze(model.predict(x2)[0,:,:,0]) ))\nprint('channel 2:\\n{}'.format(np.squeeze(model.predict(x2)[0,:,:,1])) )\nprint('Assumption 2 is correct.')","15ff6e8a":"print('Question: What is the output for input with 4 channels?')\nx4 = tf.constant(np.array([[\n    [[-1, 2, 3, 4], [2, 3, 4, 5]], \n    [[3, 4, 5, 6], [4, 5, 6, 7]]\n]]), tf.float32)\ninputs = layers.Input(shape=(2,2,4))    # 256\noutputs = layers.Conv2DTranspose(4, (2, 2), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\nprint('output channel 1:\\n{}'.format(np.squeeze(model.predict(x4)[0,:,:,0]) ))\nprint('channel 2:\\n{}'.format(np.squeeze(model.predict(x4)[0,:,:,1])) )\nprint('channel 3:\\n{}'.format(np.squeeze(model.predict(x4)[0,:,:,2])) )\nprint('channel 4:\\n{}'.format(np.squeeze(model.predict(x4)[0,:,:,3])) )\nprint('Conclusion: all channels convoluted with filter and sumed up.')","9051ccc7":"print('When filter size is (3, 3)')\ninputs = layers.Input(shape=(2,2,1))    # 256\noutputs = layers.Conv2DTranspose(4, (3, 3), strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.Ones())(inputs)\nmodel = models.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=tf.train.AdamOptimizer())\nmodel.summary()\nprint('output channel 1:\\n{}'.format(np.squeeze(model.predict(x)[0,:,:,0]) ))\nprint('channel 2:\\n{}'.format(np.squeeze(model.predict(x)[0,:,:,1])) )\nprint('channel 3:\\n{}'.format(np.squeeze(model.predict(x)[0,:,:,2])) )\nprint('channel 4:\\n{}'.format(np.squeeze(model.predict(x)[0,:,:,3])) )","d97f0df0":"from IPython.display import Image\nfrom IPython.core.display import HTML \nprint(\"The calculation demostrated in the following picture is correct!\")\nprint(\"We should go to this website to upvote this answer:\\nhttps:\/\/datascience.stackexchange.com\/questions\/6107\/what-are-deconvolutional-layers\/20176#20176\")\nImage(url=\"https:\/\/i.stack.imgur.com\/GlqLM.png\")\n","d8d94386":"# what does transposed 2D convolution in Tensorflow do?\nI was confused by several explanations about transposed 2D convolutions, therefore decide to check myself what does it do.\nThis is a demostration of the filter only implemented in Tensorflow Keras. \nFor the purpose of demostration, I did:\n* implement a model contains one transposed 2D convolutional layer\n* the loss of the network is not defined, thus there is warning\n* eager execution is enabled \n* the kernel is initialized with all ones. "}}