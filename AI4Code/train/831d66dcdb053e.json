{"cell_type":{"4bef077b":"code","57fd99b1":"code","d71d5c02":"code","eeee15d4":"code","f95ccaa4":"code","460e0804":"code","b3115a4d":"code","dd547819":"code","a8a49c28":"code","9eca9108":"code","a88c3b65":"code","7d07f5d9":"code","2819cdee":"code","47760cb6":"code","daadef11":"code","495e37d6":"code","0fc2e019":"code","ecc77134":"code","9a7d18d7":"code","16572a53":"code","87b89b68":"code","33ef35e6":"code","886a91af":"code","6af637c4":"code","3543c974":"code","f723ffe1":"code","590e3964":"code","c7ddaf9b":"code","1eb1d7b3":"code","4945036a":"code","8aa4b59d":"code","5094601b":"code","f3d78e6b":"code","1598073f":"code","cc5d0e8e":"code","94d350d1":"code","12f91f64":"code","c4138a03":"code","95e00071":"code","5da3b585":"code","0d6ad35d":"code","09b64ee8":"code","ec5e5e3d":"code","4413b30a":"markdown","228a9b8b":"markdown","8ef0c2fb":"markdown","49057131":"markdown","f3a983fe":"markdown","5e112f6d":"markdown","ca8b85b6":"markdown","30b9c88b":"markdown","b31424b3":"markdown","61c9b129":"markdown","912ef5b0":"markdown"},"source":{"4bef077b":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\nimport gc\n\n# plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators import H2OGeneralizedLinearEstimator, H2ORandomForestEstimator, H2OGradientBoostingEstimator","57fd99b1":"# configuration to show all columns in output\npd.set_option('display.max_columns', None)","d71d5c02":"# load data (this takes some time)\nt1 = time.time()\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\ndf_sub = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","eeee15d4":"# dimensions\nprint('Train Set:', df_train.shape)\nprint('Test Set :', df_test.shape)","f95ccaa4":"# structure of data frame\ndf_train.info(verbose=True, show_counts=True)","460e0804":"df_test.info(verbose=True, show_counts=True)","b3115a4d":"# basic stats\nprint(df_train.target.value_counts().reset_index(drop=True))\ndf_train.target.value_counts().reset_index(drop=True).plot(kind='bar')\nplt.grid()\nplt.show()","dd547819":"# plot target vs BINNED numerical features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in ['f34','f55']:\n    # add binned version of each numerical feature first\n    new_var = f + '_bin'\n    df_train[new_var] = pd.qcut(df_train[f], 8)\n    # then create mosaic plot\n    plt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\n    mosaic(df_train, [new_var, 'target'], title='Target vs ' + f + ' [binned]')\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save\n\n# remove temporary columns\ndf_train = df_train.drop(['f34_bin','f55_bin'], axis=1)","a8a49c28":"# extract list of features\nfeatures_num = df_train.columns.tolist()\nfeatures_num.remove('id')\nfeatures_num.remove('target')","9eca9108":"# basic stats (training)\ndf_train[features_num].describe()","a88c3b65":"# boxplot of all features (training)\nn_plot_rows = 10\nn_plot_cols = 10\nfor i in range(n_plot_rows):\n    print('Columns', n_plot_cols*i+1 , 'to', n_plot_cols*i+n_plot_cols)\n    df_train.iloc[:,n_plot_cols*i+1:n_plot_cols*i+n_plot_cols+1].plot(kind='box', figsize=(15,5))\n    plt.xticks(rotation=90)\n    plt.grid()\n    plt.show()","7d07f5d9":"# correlations (training)\ncorr_pearson_train = df_train[features_num].corr(method='pearson')\ncorr_pearson_test = df_test[features_num].corr(method='pearson')","2819cdee":"fig = plt.figure(figsize = (12,10))\nsns.heatmap(corr_pearson_train, annot=False, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation - Train')\nplt.show()","47760cb6":"fig = plt.figure(figsize = (12,10))\nsns.heatmap(corr_pearson_test, annot=False, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation - Test')\nplt.show()","daadef11":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # define maximum memory usage and number of cores","495e37d6":"# upload training data in H2O environment\nt1 = time.time()\ntrain_hex = h2o.H2OFrame(df_train) # use all data\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,4))","0fc2e019":"# force categorical target\ntrain_hex['target'] = train_hex['target'].asfactor()","ecc77134":"# upload test data in H2O environment\nt1 = time.time()\ntest_hex = h2o.H2OFrame(df_test) # use all data\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,4))","9a7d18d7":"# select predictors\npredictors = features_num\ntarget = 'target'","16572a53":"# define GLM\nn_cv = 5\n\nfit_GLM = H2OGeneralizedLinearEstimator(family = 'binomial',\n                                        nfolds = n_cv,\n                                        alpha = 0, \n                                        # 0: Ridge (L2), 1: LASSO (L1)                                          \n                                        lambda_search = True,\n                                        score_each_iteration = True,                                          \n                                        seed=12345)","87b89b68":"# train model\nt1 = time.time()\nfit_GLM.train(predictors, target, training_frame = train_hex)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","33ef35e6":"# show model details\nfit_GLM","886a91af":"# show cross validation metrics\nfit_GLM.cross_validation_metrics_summary()","6af637c4":"# variable importance\nfit_GLM.varimp_plot()","3543c974":"# training performance\nperf_train = fit_GLM.model_performance(train=True)\nperf_train.plot()","f723ffe1":"# cross validation performance\nperf_cv = fit_GLM.model_performance(xval=True)\nperf_cv.plot()","590e3964":"# predict on train set (extract probabilities only)\npred_train_GLM = fit_GLM.predict(train_hex)['p1']\npred_train_GLM = pred_train_GLM.as_data_frame().p1\n\n# plot train set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_train_GLM, bins=100)\nplt.title('Predictions on Train Set - GBM')\nplt.grid()\nplt.show()","c7ddaf9b":"# calibration\nn_actual = sum(df_train.target)\nn_pred_GLM = sum(pred_train_GLM)\n\nprint('Actual Frequency    :', n_actual)\nprint('Predicted Frequency :', n_pred_GLM)\nprint('Calibration Ratio   :', n_pred_GLM \/ n_actual)","1eb1d7b3":"# fit Gradient Boosting model\nn_cv = 5\n\nfit_GBM = H2OGradientBoostingEstimator(ntrees=250,\n                                       max_depth=6,\n                                       min_rows=10,\n                                       learn_rate=0.1, # default: 0.1\n                                       sample_rate=1,\n                                       col_sample_rate=0.5,\n                                       nfolds=n_cv,\n                                       score_each_iteration=True,\n                                       stopping_metric='auc',\n                                       stopping_rounds=5,\n                                       stopping_tolerance=0.0001,\n                                       seed=999)\n# train model\nt1 = time.time()\nfit_GBM.train(x=predictors,\n              y='target',\n              training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","4945036a":"# show cross validation metrics\nfit_GBM.cross_validation_metrics_summary()","8aa4b59d":"# show scoring history - training vs cross validations\nfor i in range(n_cv):\n    cv_model_temp = fit_GBM.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [AUC]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_auc, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_auc, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.ylabel('AUC')\n    plt.ylim(0.4,0.8)\n    plt.legend()\n    plt.grid()\n    plt.show()","5094601b":"# variable importance\nfit_GBM.varimp_plot()","f3d78e6b":"# alternative variable importance using SHAP => see direction as well as severity of feature impact\nt1 = time.time()\nfit_GBM.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","1598073f":"# training performance\nperf_train = fit_GBM.model_performance(train=True)\nperf_train.plot()","cc5d0e8e":"# cross validation performance\nperf_cv = fit_GBM.model_performance(xval=True)\nperf_cv.plot()","94d350d1":"# predict on train set (extract probabilities only)\npred_train_GBM = fit_GBM.predict(train_hex)['p1']\npred_train_GBM = pred_train_GBM.as_data_frame().p1\n\n# plot train set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_train_GBM, bins=100)\nplt.title('Predictions on Train Set - GBM')\nplt.grid()\nplt.show()","12f91f64":"# calibration\nn_actual = sum(df_train.target)\nn_pred_GBM = sum(pred_train_GBM)\n\nprint('Actual Frequency    :', n_actual)\nprint('Predicted Frequency :', n_pred_GBM)\nprint('Calibration Ratio   :', n_pred_GBM \/ n_actual)","c4138a03":"# predict on test set (extract probabilities only)\npred_test_GLM = fit_GLM.predict(test_hex)['p1']\npred_test_GLM = pred_test_GLM.as_data_frame().p1\n\n# plot test set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_test_GLM, bins=100)\nplt.title('Predictions on Test Set - GLM')\nplt.grid()\nplt.show()","95e00071":"# GLM submission\ndf_sub_GLM = df_sub.copy()\ndf_sub_GLM.target = pred_test_GLM\ndisplay(df_sub_GLM.head())\n# save to file\ndf_sub_GLM.to_csv('submission_GLM.csv', index=False)","5da3b585":"# predict on test set (extract probabilities only)\npred_test_GBM = fit_GBM.predict(test_hex)['p1']\npred_test_GBM = pred_test_GBM.as_data_frame().p1\n\n# plot test set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_test_GBM, bins=100)\nplt.title('Predictions on Test Set - GBM')\nplt.grid()\nplt.show()","0d6ad35d":"# GBM submission\ndf_sub_GBM = df_sub.copy()\ndf_sub_GBM.target = pred_test_GBM\ndisplay(df_sub_GBM.head())\n# save to file\ndf_sub_GBM.to_csv('submission_GBM.csv', index=False)","09b64ee8":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Pred_GLM': df_sub_GLM.target, \n                        'Pred_GBM': df_sub_GBM.target})\nsns.jointplot(data=df_temp, x='Pred_GLM', y='Pred_GBM',\n              joint_kws = {'alpha' : 0.1})\nplt.show()","ec5e5e3d":"# blend submission\ndf_sub_blend = df_sub.copy()\nw_GLM = 0.65\ndf_sub_blend.target = w_GLM * df_sub_GLM.target + (1-w_GLM) * df_sub_GBM.target\ndisplay(df_sub_blend.head())\n# save to file\ndf_sub_blend.to_csv('submission_blend.csv', index=False)","4413b30a":"<a id='Import'><\/a>\n# Import and first checks","228a9b8b":"### Blend","8ef0c2fb":"<a id='Model_GBM'><\/a>\n# Model - Gradient Boosting","49057131":"<a id='Model_GLM'><\/a>\n# Model - GLM","f3a983fe":"<a id='Target'><\/a>\n# Target","5e112f6d":"#### => Nicely balanced target!","ca8b85b6":"<a id='PredTest'><\/a>\n# Predict on Test Set + Submissions","30b9c88b":"# Table of Contents\n* [Import and first checks](#Import)\n* [Target](#Target)\n* [Features](#Features)\n* [Model - GLM](#Model_GLM)\n* [Model - Gradient Boosting](#Model_GBM)\n* [Predict on Test Set + Submissions](#PredTest)","b31424b3":"### Impact of Features on Target (examples):","61c9b129":"<a id='Features'><\/a>\n# Features","912ef5b0":"### Correlations:"}}