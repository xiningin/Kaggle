{"cell_type":{"49b709c0":"code","bd600ce4":"code","1286dd3c":"code","d85be2a8":"code","cfb001f0":"code","e57f5381":"code","847c080b":"code","933d1f48":"code","ccbcf109":"code","a449d8f1":"code","08d0f3fd":"code","601b7e62":"code","da45cd56":"code","f2b73598":"code","cc5b1b5b":"code","71d29295":"markdown","33b90920":"markdown","3503bf77":"markdown","74a66a21":"markdown","e92cd969":"markdown","4a735cab":"markdown","beccc82e":"markdown"},"source":{"49b709c0":"import numpy as np \nimport pandas as pd \n\nimport sklearn.model_selection as model_selection\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\n#For Missing Value Treatment\n#from sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\n\n#For Binning and creating Dummy Variables\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif, VarianceThreshold\nfrom sklearn.impute import SimpleImputer, KNNImputer, MissingIndicator\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error","bd600ce4":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nsub_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","1286dd3c":"train.head()","d85be2a8":"y = train['SalePrice']\nX = train.drop(['SalePrice','Id'], axis = 1)","cfb001f0":"X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=0.2, random_state = 200)","e57f5381":"#Condidering Numerical Features only\nnumerical_features = [c for c, dtype in zip(X.columns, X.dtypes) if dtype.kind in ['i','f'] ]\ncategorical_features = [c for c, dtype in zip(X.columns, X.dtypes) if dtype.kind not in ['i','f'] ]\n\nprint('Numerical : ' + str(numerical_features))\nprint('Categorical : ' + str(categorical_features))","847c080b":"X[numerical_features].nunique()","933d1f48":"#Data Processing Steps\npreprocessor = make_column_transformer(\n    \n    (make_pipeline(\n        VarianceThreshold(),\n        MinMaxScaler(),\n        KNNImputer(n_neighbors=10),\n        KBinsDiscretizer(n_bins = 6),\n        SelectKBest(f_classif, k=15),\n    ), numerical_features),\n    \n    (make_pipeline(\n        SimpleImputer(strategy = 'constant', fill_value = 'missing'),\n        OneHotEncoder(categories = 'auto', handle_unknown = 'ignore'),\n        SelectKBest(f_classif, k=15),\n    ), categorical_features)\n    \n)","ccbcf109":"from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, VotingRegressor","a449d8f1":"#Model Steps\np1 = make_pipeline(preprocessor, RandomForestRegressor(n_estimators = 100))\np2 = make_pipeline(preprocessor, AdaBoostRegressor(n_estimators = 100))\np3 = make_pipeline(preprocessor, GradientBoostingRegressor(n_estimators = 100))\nfin_voting = make_pipeline(VotingRegressor(estimators=\n                                            [(\"randomforestregressor\",p1), \n                                             (\"adaboostregressor\",p2), \n                                             ('gradientboostingregressor',p3)]))","08d0f3fd":"fin_voting.fit(X_train, y_train)","601b7e62":"y_train_pred = fin_voting.predict(X_train)\ny_test_pred = fin_voting.predict(X_test)\n\nprint(f'Train MSLE : {np.sqrt(mean_squared_log_error(y_train, y_train_pred)):.3f}')\nprint(f'Test MSLE : {np.sqrt(mean_squared_log_error(y_test, y_test_pred)):.3f}')","da45cd56":"y_sub_pred = fin_voting.predict(sub_test.drop(['Id'], axis = 1))","f2b73598":"submission_df = pd.DataFrame({'Id' : sub_test['Id'], 'SalePrice' : y_sub_pred})","cc5b1b5b":"submission_df.to_csv('Voting_Pipeline.csv', index = False)\nsubmission_df.head()","71d29295":"# Import Libraries","33b90920":"# Fit Model","3503bf77":"# Split Data into Train and test ","74a66a21":"# Check Accuracy","e92cd969":"# Make Submission","4a735cab":"# Build Pipeline","beccc82e":"# Import Data"}}