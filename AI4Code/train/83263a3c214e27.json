{"cell_type":{"a204ce48":"code","861571c7":"code","41aec1fd":"code","cefbfd32":"code","ed4f532b":"code","d31d8fdf":"code","a2324d7c":"code","a1f6b211":"code","b5fc947b":"code","b6878c30":"code","2bc2e883":"code","f59a050d":"code","08ff0b42":"code","021fc2f9":"code","396fa64e":"code","f51d9411":"code","e473e10a":"code","509d67bb":"code","da7e8aa5":"code","5abbd5f9":"markdown","f1af46ee":"markdown","5caf9513":"markdown","2db9c148":"markdown","c837373b":"markdown"},"source":{"a204ce48":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","861571c7":"train_df = pd.read_csv('\/kaggle\/input\/cte-ml-hack-2019\/train_real.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/cte-ml-hack-2019\/test_real.csv')","41aec1fd":"train_df[\"Azimuthal_angle\"] = np.sqrt(train_df[\"Azimuthal_angle\"])\n\ntrain_df[\"H_dist_Hydro\"] = np.sqrt(train_df[\"H_dist_Hydro\"])\n\ntrain_df[\"Dist_Hydro\"] = np.sqrt((train_df[\"H_dist_Hydro\"]**2 + train_df[\"V_dist_Hydro\"]**2))\ntest_df[\"Dist_Hydro\"] = np.sqrt((test_df[\"H_dist_Hydro\"]**2 + test_df[\"V_dist_Hydro\"]**2))\n\ntrain_df['Dist_Hydro'] = np.sqrt(train_df['Dist_Hydro'])\n\ntrain_df[\"H_dist_Fire\"] = np.sqrt(train_df[\"H_dist_Fire\"])\n\ntrain_df[\"H_dist_Road\"] = np.sqrt(train_df[\"H_dist_Road\"])\n\ntrain_df[\"Incline\"] = np.sqrt(train_df[\"Incline\"])\n\ntrain_df['Hillshade_9am'] = (train_df['Hillshade_9am'])**3\n\ntrain_df = train_df.drop(train_df[(train_df['Azimuthal_angle']>25)].index)\ntrain_df = train_df.reset_index(drop = True)\ntrain_df = train_df.drop(train_df[(train_df['H_dist_Hydro']<5)].index)\ntrain_df = train_df.reset_index(drop = True)\n\nX = train_df.drop(['Id', 'label','Soil','V_dist_Hydro'], axis=1)\ny = train_df['label']\n\nX_test = test_df.drop(['Id','Soil','V_dist_Hydro'], axis=1)\n\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)","cefbfd32":"y_train.head()","ed4f532b":"X_train.head()","d31d8fdf":"#Just checking features for any unnaturally high skewness\n\nprint(train_df.skew())","a2324d7c":"# Correlation tells relation between two attributes.\n# Correlation requires continous data. Hence, ignore Wilderness_Area and Soil_Type as they are binary\n\n#Index where continuous data ends\nsize = 10\n\ndata=train_df.iloc[:,:size] \n\ncols=data.columns \n\ndata_corr = data.corr()\n\nthreshold = 0.5\n\ncorr_list = []\n\nfor i in range(0,size):\n    for j in range(i+1,size):\n        if (data_corr.iloc[i,j] >= threshold and data_corr.iloc[i,j] < 1) or (data_corr.iloc[i,j] < 0 and data_corr.iloc[i,j] <= -threshold):\n            corr_list.append([data_corr.iloc[i,j],i,j]) \n\ns_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n\nfor v,i,j in s_corr_list:\n    print (\"%s and %s = %.2f\" % (cols[i],cols[j],v))","a1f6b211":"#Plotting the features with high correlation along with the labels\nfor v,i,j in s_corr_list:\n    sns.pairplot(train_df, hue=\"label\", height=6, x_vars=cols[i],y_vars=cols[j] )\n    plt.show()","b5fc947b":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier \n\nrf = RandomForestClassifier(random_state=42, n_estimators=180,n_jobs=-1,max_depth = 8).fit(X_train, y_train)\n\nxgb = XGBClassifier(random_state=42, n_estimators=180,n_jobs=-1,max_depth = 8).fit(X_train, y_train)\n\nknn = KNeighborsClassifier(7).fit(X_train,y_train)","b6878c30":"rf_validation_res=rf.predict(X_validation)\nprint(accuracy_score(rf_validation_res, y_validation))","2bc2e883":"xgb_validation_res=xgb.predict(X_validation)\nprint(accuracy_score(xgb_validation_res, y_validation))","f59a050d":"knn_validation_res=knn.predict(X_validation)\nprint(accuracy_score(knn_validation_res, y_validation))","08ff0b42":"from functools import reduce\nfrom sklearn.metrics import roc_auc_score\ndef generate_rf(X_train, y_train, X_validation, y_validation, x):\n    rf = RandomForestClassifier(n_estimators=25*(x+1), min_samples_leaf=2, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    print (\"rf score: \", rf.score(X_validation, y_validation))\n    print (\"rf auc score: \", roc_auc_score(rf.predict(X_validation), y_validation))\n    return rf\n\ndef combine_rfs(rf_a, rf_b):\n    rf_a.estimators_ += rf_b.estimators_\n    rf_a.n_estimators = len(rf_a.estimators_)\n    return rf_a\n\nrfs = [generate_rf(X, y, X_validation, y_validation, i) for i in range(10)]\n# in this step below, we combine the list of random forest models into one giant model\nrf_combined = reduce(combine_rfs, rfs)\n# the combined model scores better than most of the component models\nprint (\"rf combined score: \", rf_combined.score(X_validation, y_validation))\nprint (\"rf combined auc score: \", roc_auc_score(rf_combined.predict(X_validation), y_validation))","021fc2f9":"test_res = rf_combined.predict(X_test)","396fa64e":"submission_df = pd.DataFrame()\nsubmission_df['Id'] = test_df['Id']","f51d9411":"submission_df['Predicted'] = test_res.tolist()","e473e10a":"submission_df.tail()","509d67bb":"submission_df.to_csv('ml_hack_submission.csv',index=False)","da7e8aa5":"!ls","5abbd5f9":"# Combining models\n# \n# Here we saw that the Random Forest Classifier gave us the best accuracy in our data, but these model's tend to have high biases in exchange for increased variance. Here we try to combine Random Forest models and see if it improves our accuracy.\n#","f1af46ee":"# Basic Linear models\n# \n# We use Random Forest and K Nearest Neighbours models and use the one which gives us  higher accuracy\n#","5caf9513":"As we don't have that large of a dataset to work on, we train it on the whole dataset instead of just the training set. This obviously means that it will give bloated accuracies in the validation as it has already seen this data beofore. The only thing we are actually checking for in this accuracy is whether our model is overfitting or not, and as we can see, it is not.","2db9c148":"# EDA\n# This is where we start to explore the data and the features to see if we can apply some algorithms to the features to make them more usable for our model","c837373b":"# Train-Test split\n# \n# Here we split train_df into train and validation dataframes"}}