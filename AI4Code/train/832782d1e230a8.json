{"cell_type":{"e834d8a2":"code","447dd896":"code","43884749":"code","649d2315":"code","c90eb6fc":"code","13cce0a2":"code","4647541a":"code","22774c97":"code","a576d619":"code","388ee4b3":"code","ced46ba6":"code","5635bc6c":"code","3c1c3eac":"code","2ef1e26f":"code","6c514ac8":"code","aa3979d6":"code","ed8a867a":"code","d178cf31":"code","8eba5acc":"code","758cd456":"code","553f33ca":"code","1f973766":"code","15831732":"code","4ac75f05":"code","3974120b":"code","557564c3":"markdown","0787e3df":"markdown","2bbd90da":"markdown","900eccdd":"markdown","8665f0dc":"markdown","891e294c":"markdown","adbfbeb3":"markdown","dee5b715":"markdown","e017ce5c":"markdown","92e332b9":"markdown","40bd6800":"markdown","5091955c":"markdown","6886b4b2":"markdown","0dfe7eaa":"markdown","81b6242b":"markdown","7dabd72e":"markdown","f58ee4a3":"markdown","43127c16":"markdown"},"source":{"e834d8a2":"import glob\nimport os\nimport time\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nprint(tf.__version__)\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom IPython import display","447dd896":"# asign some paths\ntrain_csv_path = '..\/input\/siim-isic-melanoma-classification\/train.csv'\ntest_csv_path = '..\/input\/siim-isic-melanoma-classification\/test.csv'\nimage_path = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\n\n# read the csv data using pandas\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\n\nprint(\"unique values in column 'target': {}\".format(list(train_df['target'].unique())))\ntarget_dis = list(train_df['target'].value_counts())\nbenign_per = target_dis[0]\/sum(target_dis)\nprint(\"target count distribution: {}\".format(target_dis))\nprint(\"benign percentage: {:.2f}% vs malignant: {:.2f}%\".format(benign_per*100, (1-benign_per)*100))","43884749":"# detect and initialize TPU (ignore if using GPU)\n# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     print('Device:', tpu.master())\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     # set distribution strategy\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# except:\n#     strategy = tf.distribute.get_strategy()\n# print('Number of replicas:', strategy.num_replicas_in_sync)\n\n# # Use these params if using TPU\n# IMAGE_SIZE = [128, 128]  # used for reshaping\n# AUTOTUNE = tf.data.experimental.AUTOTUNE\n# GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-128x128')  # store dataset to gcs buckets for the TPU to access in cloud\n# BATCH_SIZE = 16 * strategy.num_replicas_in_sync","649d2315":"path_tfrec = '..\/input\/melanoma-128x128\/'\npath_jpg = '..\/input\/jpeg-melanoma-128x128\/train\/'\nIMAGE_SIZE = [128, 128]\n\nmalignant = train_df[train_df[\"target\"] == 1]  # list of malignant images\n\ndef preprocess_X():  # load the images into memory\n    X = []\n    for img in malignant.image_name.values:\n        img_name = path_jpg + img + '.jpg'\n        i = tf.keras.preprocessing.image.load_img(img_name) #color_mode='grayscale')\n        i = tf.keras.preprocessing.image.img_to_array(i)\n        i = preprocess_input(i)  # preprocessing fits the pixel value from -127.5 to 127.5\n        X.append(i)\n    return np.array(X)  # convert to numpy array","c90eb6fc":"X = preprocess_X()\nX.shape","13cce0a2":"def display_img(arr):\n    i = tf.keras.preprocessing.image.array_to_img(arr)\n    plt.imshow(i, cmap='gray')\n\nplt.figure(figsize=(7,7))\nfor i in range(9):\n    plt.subplot(3,3, i+1)\n    display_img(X[i])  ","4647541a":"BUFFER_SIZE = 584\nBATCH_SIZE = 32  # from 128\nEPOCHS = 50  # from 50\nnoise_dim = 200  # from 100\nnum_examples_to_generate = 9\n\n# We will reuse this seed overtime (so it's easier to visualize progress in the animated GIF)\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","22774c97":"def augmentation_pipeline(image):\n    image = tf.image.random_flip_left_right(image)\n#     image = tf.image.resize(image, IMAGE_RESIZE)\n    return image","a576d619":"# Simple dataset processing with batch and shuffle\ndef get_dataset():\n    ds = tf.data.Dataset.from_tensor_slices(X)\n#     ds = ds.map(augmentation_pipeline)\n    ds = ds.shuffle(BUFFER_SIZE)\n    ds = ds.batch(BATCH_SIZE)\n    return ds\n    \ntrain_dataset = get_dataset()\n# inspect a batch\nn_batch = 0\nfor i in train_dataset:\n    n_batch += 1\nprint(f\"num of batch: {n_batch}, shape of each batch: {i.shape}\")","388ee4b3":"def make_generator_model():\n    model = tf.keras.Sequential()   # dense unit is configured to match soon tobe reshaped layer\n    model.add(layers.Dense(32*32*256, use_bias=False, input_shape=(noise_dim,)))  # starts with 1D array, input is noise array of 100\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    # 32x32 bcz there's 2 conv2D. 128\/2\/2=32\n    model.add(layers.Reshape((32, 32, 256)))\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n\n    return model\n\n# create the generator\ngenerator = make_generator_model()\ngenerator.summary()","ced46ba6":"noise = tf.random.normal([1, noise_dim])  # outputs random values from normal dist. to a certain array shape\ngenerated_image = generator(noise, training=False)  # interesting, doesn't need .fit .predict or anything\n\nplt.imshow(generated_image[0, :, :, :]*255)#, cmap='gray')","5635bc6c":"def make_discriminator_model():\n    model = tf.keras.Sequential()   # basic binary classification model\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[128, 128, 3]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model\n\n# create D\ndiscriminator = make_discriminator_model()\nprint(discriminator.summary())","3c1c3eac":"decision = discriminator(generated_image)\nprint(decision)","2ef1e26f":"# This method returns a helper function to compute cross entropy loss (prob between 0 and 1)\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","6c514ac8":"def discriminator_loss(real_output, fake_output):\n    # ones_like creates array of ones with similar shape as the input array\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","aa3979d6":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","ed8a867a":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)  # but here they use the same Adam anyway\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","d178cf31":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","8eba5acc":"# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","758cd456":"def train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n\n        for image_batch in dataset:\n            train_step(image_batch)\n\n        # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator,\n                                 epoch + 1,\n                                 seed)\n\n        # Save the model every 15 epochs\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n        # Generate after the final epoch\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, epochs, seed)","553f33ca":"def generate_and_save_images(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)  # same as num_examples_to_generate\n    fig = plt.figure(figsize=(12,12))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(3, 3, i+1)\n        plt.imshow(predictions[i, :, :, :] * 127.5 + 127.5, cmap='gray')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","1f973766":"train(train_dataset, EPOCHS)","15831732":"benign = train_df[train_df[\"target\"] == 0]\nmalignant = train_df[train_df[\"target\"] == 1]\n\ndef show_img(target, n=16):\n    img_name = target.image_name.values\n    ex_img = np.random.choice(img_name, n)  # grab n number of images\n    plt.figure(figsize=(15,15))\n    for i in range(n):\n        plt.subplot(4, 4, i + 1)\n        img = plt.imread(image_path + ex_img[i]+'.jpg')\n        plt.imshow(img, cmap='gray')\n        plt.axis('off')\n    plt.tight_layout()","4ac75f05":"show_img(benign)","3974120b":"show_img(malignant)","557564c3":"### Display preprocessed image","0787e3df":"### Discriminator Loss\nmeasures how well D distinguish real and fake images. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.","2bbd90da":"## Why use GAN?\n\n* Dataset target classes are highly imbalance, only 1.76% of malignant\n\n## Interesting topics to try\n\n1. GAN to generate additional malignant class images\n2. Using VAEs to train anomaly detection from benign (non lethal) lesion\n3. GAN to generate SR and additional attention based cropping for train a better lesion classifier and detector","900eccdd":"Display an image generated from noise (G still not trained yet)","8665f0dc":"### Increase training data with Augmentations","891e294c":"### Optimizers","adbfbeb3":"### Hyperparameters","dee5b715":"### Preprocess Image","e017ce5c":"## 2. GAN for anomali detection\n\n* Anomali detection in Alzheimer Disease with GAN\n* SHOW RESULTS\n\n* Also other research that has anomali results: HERE HERE and HERE\n* Very effective when positive samples are rare, it's also a how doctors learn to classify\n* But in melanoma, is it really effective? since the difference between benign and malignant images can sometimes be **very subtle**","92e332b9":"Let the untrained D predict that generated image","40bd6800":"## Define Loss and Optimizer","5091955c":"### Defining training loop\n\nThe training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fake images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator.","6886b4b2":"### Create Generator and Discriminator","0dfe7eaa":"### Create callbacks","81b6242b":"### Generator Loss\nMeasures how well G can trick D. If G is performing well, D will classify fake images as 1 (real)\nthe discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s. Here, we will compare the discriminators decisions on the generated images to an array of 1s.","7dabd72e":"## 1. DCGAN to generate Malignant images\n\nSource\n* [code](https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan) \n* [GAN-based Synthetic Medical Image Augmentation](https:\/\/arxiv.org\/pdf\/1803.01229.pdf)\n\nDataset\n* [JPEG 128x128](https:\/\/www.kaggle.com\/cdeotte\/jpeg-melanoma-128x128) melanoma from Chris Deotte\n\nProblems:\n* Generated images are nowhere near the input images\n* Maybe needs some augmentation. [Augmentation in GAN](https:\/\/arxiv.org\/pdf\/2006.05338v1.pdf) ","f58ee4a3":"# GAN to assist in Melanoma Detection\n\n[melanoma competition](https:\/\/www.kaggle.com\/c\/siim-isic-melanoma-classification\/data)\n","43127c16":"### 2.1 Papers on anomali detection\n\n* [Lesion detection in Brain MRI with constrained adversarial auto-encoder](https:\/\/arxiv.org\/pdf\/1806.04972.pdf)\n* "}}