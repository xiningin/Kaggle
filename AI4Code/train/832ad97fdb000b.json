{"cell_type":{"647ce83e":"code","0ff2d287":"code","29d31465":"code","2333f398":"code","82c67396":"code","a4143b4c":"code","d5af581f":"code","46c179f5":"code","990897f3":"code","f59b5220":"code","dc52590a":"code","4b2cd054":"code","270a37cc":"code","d785b1cc":"code","deaddb94":"code","bf978913":"code","ca0afb4f":"code","f926db73":"code","53e9650b":"code","ff973365":"code","7f3cc9b3":"code","46043a71":"code","c171f599":"code","1812401d":"code","42bca372":"code","af2e0e16":"code","ffb6990a":"code","16c590e1":"code","a4bf7b0b":"code","68bf9577":"code","488ef0e5":"code","6787d8e3":"code","595b8356":"markdown","d249b728":"markdown","abe13444":"markdown","c4c4d544":"markdown","6ab2cebf":"markdown","97574966":"markdown","7db4d959":"markdown","e45f2a98":"markdown","70bb4bb5":"markdown","cd49a724":"markdown","76662102":"markdown","e8fece11":"markdown","a731b869":"markdown","a3a719a0":"markdown","49e45d00":"markdown","8da92ecb":"markdown","fc9ddf8d":"markdown","831d62d2":"markdown","76067f8b":"markdown","a8e77fb5":"markdown","bd13c08a":"markdown","9402127a":"markdown","be61afbd":"markdown","57379caf":"markdown","f3e8a25e":"markdown","d639b299":"markdown","4289fff1":"markdown","43e4815e":"markdown","729c7b80":"markdown","1f9dab3a":"markdown","da7edcc2":"markdown","ca4d8bb5":"markdown","8c7cfcfd":"markdown","5b152da4":"markdown","d9827a5e":"markdown"},"source":{"647ce83e":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np","0ff2d287":"df = pd.read_csv('..\/input\/students-performance-in-exams\/StudentsPerformance.csv')","29d31465":"df.shape","2333f398":"df.columns","82c67396":"df.info()","a4143b4c":"df.describe()","d5af581f":"df.head()","46c179f5":"df.isnull().sum()","990897f3":"df.rename(columns = {'race\/ethnicity':'race'}, inplace = True)\ndf.rename(columns = {'parental level of education':'parent_education'}, inplace = True)\ndf.rename(columns = {'test preparation course':'prep_course'}, inplace = True)\ndf.rename(columns = {'math score':'math_score'}, inplace = True)\ndf.rename(columns = {'reading score':'reading_score'}, inplace = True)\ndf.rename(columns = {'writing score':'writing_score'}, inplace = True)","f59b5220":"df['total_score'] = df['math_score'] + df['reading_score'] + df['writing_score']","dc52590a":"df.columns","4b2cd054":"import seaborn as sns\nimport matplotlib.pyplot as plt","270a37cc":"plt.figure(figsize = (6,8))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'Set2')\nax = sns.countplot(\n    x = 'gender',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Student Genders', fontsize = 15)\nax.set(xlabel = 'Gender', ylabel = 'Frequency')","d785b1cc":"plt.figure(figsize = (9,6))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'race',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Student Race\/Ethnicity', fontsize = 15)\nax.set(xlabel = 'Race\/Ethnicity', ylabel = 'Frequency')","deaddb94":"plt.figure(figsize = (13,6))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'parent_education',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Parent Education Level', fontsize = 20)\nax.set(xlabel = 'Parental Education Level', ylabel = 'Frequency')","bf978913":"plt.figure(figsize = (6,8))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'lunch',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Lunch Options', fontsize = 15)\nax.set(xlabel = 'Lunch Option', ylabel = 'Frequency')","ca0afb4f":"plt.figure(figsize = (6,8))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'prep_course',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Prep Course', fontsize = 15)\nax.set(xlabel = 'Prep Course', ylabel = 'Frequency')","f926db73":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['math_score'], bins = 20, color = 'cornflowerblue')\nplt.xlabel('Math Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Math Scores', fontsize = 13)\nplt.show()","53e9650b":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['reading_score'], bins = 20, color = 'lightcoral')\nplt.xlabel('Reading Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Reading Scores', fontsize = 13)\nplt.show()","ff973365":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['writing_score'], bins = 20, color = 'goldenrod')\nplt.xlabel('Writing Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Writing Score', fontsize = 13)\nplt.show()","7f3cc9b3":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['total_score'], bins = 20, color = 'darkorchid')\nplt.xlabel('Total Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Total Score', fontsize = 13)\nplt.show()","46043a71":"df1 = df[['gender', 'race', 'parent_education', 'prep_course', 'lunch']]\nX = pd.get_dummies(df1, columns = ['gender', 'race', 'parent_education', 'prep_course', 'lunch'], dtype = int)\ny = df['total_score']","c171f599":"from sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y, X_constant).fit()\nlin_reg.summary()","1812401d":"import statsmodels.stats.api as sms\nsns.set_style('darkgrid')\nsns.mpl.rcParams['figure.figsize'] = (15.0, 9.0)","42bca372":"def linearity_test(model, y):\n    fitted_vals = model.predict()\n    resids = model.resid\n    \n    fig, ax = plt.subplots(1,2)\n    \n    sns.regplot(x = fitted_vals, y = y, lowess = True, ax = ax[0], line_kws = {'color': 'red'})\n    ax[0].set_title('Observed vs. Predicted Values', fontsize = 16)\n    ax[0].set(xlabel = 'Predicted', ylabel = 'Observed')\n    \n    sns.regplot(x = fitted_vals, y = resids, lowess = True, ax = ax[1], line_kws = {'color' : 'red'})\n    ax[1].set_title('Residuals vs. Predicted Values', fontsize = 16)\n    ax[1].set(xlabel = 'Predicted', ylabel = 'Residuals')\n    \nlinearity_test(lin_reg, y)","af2e0e16":"lin_reg.resid.mean()","ffb6990a":"plt.figure(figsize = (10,8))\nsns.heatmap(X.corr(), annot = True, cmap = 'cubehelix_r')\nplt.show()","16c590e1":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index = X.columns).to_csv","a4bf7b0b":"def homoscedasticity_test(model):\n    fitted_vals = model.predict()\n    resids = model.resid\n    resids_standardized = model.get_influence().resid_studentized_internal\n\n    fig, ax = plt.subplots(1,2)\n\n    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n    ax[0].set_title('Residuals vs Fitted', fontsize=16)\n    ax[0].set(xlabel='Fitted Values', ylabel='Residuals')\n\n    sns.regplot(x=fitted_vals, y=np.sqrt(np.abs(resids_standardized)), lowess=True, ax=ax[1], line_kws={'color': 'red'})\n    ax[1].set_title('Scale-Location', fontsize=16)\n    ax[1].set(xlabel='Fitted Values', ylabel='sqrt(abs(Residuals))')\n\n    bp_test = pd.DataFrame(sms.het_breuschpagan(resids, model.model.exog), \n                           columns=['value'],\n                           index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n\n    gq_test = pd.DataFrame(sms.het_goldfeldquandt(resids, model.model.exog)[:-1],\n                           columns=['value'],\n                           index=['F statistic', 'p-value'])\n\n    print('\\n Breusch-Pagan test ----')\n    print(bp_test)\n    print('\\n Goldfeld-Quandt test ----')\n    print(gq_test)\n    print('\\n Residuals plots ----')\n\nhomoscedasticity_test(lin_reg)","68bf9577":"import statsmodels.tsa.api as smt\n\nacf = smt.graphics.plot_acf(lin_reg.resid, lags = 40, alpha = 0.05)\nacf.show()","488ef0e5":"from scipy import stats\n\ndef normality_of_residuals_test(model):\n    sm.ProbPlot(model.resid).qqplot(line='s');\n    plt.title('Q-Q plot');\n\n    jb = stats.jarque_bera(model.resid)\n    sw = stats.shapiro(model.resid)\n    ad = stats.anderson(model.resid, dist='norm')\n    ks = stats.kstest(model.resid, 'norm')\n    \n    print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n    print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n    print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n    print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n    print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, the null hypothesis that the data come from the Normal distribution should be rejected. ')\n    \nnormality_of_residuals_test(lin_reg)","6787d8e3":"lin_reg.summary()","595b8356":"# Student Test Scores Analysis - Linear Regression","d249b728":"# Modeling - Linear Regression","abe13444":"# Data Cleaning","c4c4d544":"Good, very small.","6ab2cebf":"**Rename Columns**","97574966":"The plot looks pretty good, quite normally distributed. Additionally, the Jarque-Bera, Kolmogorov-Smirnov and Shapiro-Wilk test confirm this. However the Anderson-Darling test appears to claim that the residuals are not normally distributed because the test statistic is greater than the critical value.","7db4d959":"First, lets take a look at the corr map","e45f2a98":"# Environment Set Up","70bb4bb5":"Awesome, no nulls","cd49a724":"# Data Exploration - Visualization","76662102":"**Assumption Check: homoscedasticity (equality of residual variance)**","e8fece11":"It appears that parental education is the greatest predictor of student success (in this fake dataset).","a731b869":"**Assumption Check: no autocorrelation of residuals","a3a719a0":"**Model**","49e45d00":"**Check for nulls**","8da92ecb":"**Assumption Check: normality of residuals**","fc9ddf8d":"**Assumption Check: Mean of residuals is zero**","831d62d2":"**Load Libraries**","76067f8b":"Plots look like they satisfy the assumption, and the outputs certify that assertion with p-values > 0.05","a8e77fb5":"**Assumption check: no multicollinearity**","bd13c08a":"The following analysis is performed on a generated data structure of hypothetical student test scores and the student's various characteristics. \n\nThe analysis includes an exploratory data analysis, regression modeling, and assumption checks.\n\nMuch of the modeling code was sourced from the following article: https:\/\/towardsdatascience.com\/verifying-the-assumptions-of-linear-regression-in-python-and-r-f4cd2907d4c0","9402127a":"Looks good! Linearity assumption is satisifed.","be61afbd":"To be honest, I'm not sure why the output is \"inf\" for most of these variables when it should be super low.","57379caf":"Y (response variable) is assumed to be a linear function of the features. We will inspect plots of observed vs predicted values AND residuals vs predicted values. We hope to find a linear plot for the former and a horizontal line for the latter.","f3e8a25e":"**Variable Distributions**","d639b299":"**Assumption Check: Linearity**","4289fff1":"**Create a total_score column**","43e4815e":"It definitely looks like the variables are not highly correlated. Let's make a function to determine the VIF of each variable","729c7b80":"**Setting up**","1f9dab3a":"**Data Overview**","da7edcc2":"Let's finish out this notebook with another iteration of the linear regression test to review our results.","ca4d8bb5":"Check the column now","8c7cfcfd":"# Checking Assumptions","5b152da4":"**Load Data**","d9827a5e":"**Load Libaries**"}}