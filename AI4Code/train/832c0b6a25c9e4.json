{"cell_type":{"3655166e":"code","1075d6f2":"code","02ba91ac":"code","024e78cd":"code","572caa9a":"code","fd3efdc6":"code","c98dc79c":"code","5b481778":"code","20cae680":"code","a13c717b":"code","dd5783cc":"code","547880f9":"code","681b27d7":"code","b509bb17":"code","eb8d7b72":"code","fb0c05f3":"code","a30e8e0f":"code","9377e2d5":"code","a74f5bab":"code","d511c5eb":"code","8726280f":"code","2cee8398":"code","426ad33f":"code","bd08ad94":"code","1523a319":"code","61b97c40":"code","0a4358be":"code","32435986":"code","c97ed06a":"code","7ef4f5d8":"code","d86579a2":"code","e0679ecd":"code","cde4b0f2":"code","6847027a":"code","a7d970ea":"code","d2f12933":"code","c118d965":"code","fe36176b":"code","6c2d27cf":"code","a99fde7e":"code","9ff3e45b":"code","c97cc39e":"code","90088b86":"code","e9e0bd58":"code","c21ec347":"code","1490b123":"code","ceaa706d":"code","8fc4fd28":"code","eddccc65":"code","cfdde2bf":"code","78dcea07":"code","7ffd3d3a":"code","6196db17":"code","a738c120":"code","6ef944bc":"code","869324d3":"code","7bb28d15":"code","9839909d":"code","c5513c10":"code","ecbd10f3":"code","d84f8043":"code","85dcc3d0":"code","877bf1ed":"code","64f70edc":"code","6e0d64e9":"code","0e1a7d3f":"code","2bad38c7":"code","54031484":"code","0412f72e":"code","ef2aed11":"markdown","6d32cc85":"markdown","40040e27":"markdown","69de1298":"markdown","15ba046d":"markdown","2f69586b":"markdown","b6d9c8d4":"markdown","4b11cd6a":"markdown","a2cbae8a":"markdown","670af636":"markdown"},"source":{"3655166e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1075d6f2":"# Importing the required libabries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier","02ba91ac":"data = pd.read_csv(r'\/kaggle\/input\/hr-attrition\/HR_Employee_Attrition_Data.csv')","024e78cd":"# Description of DataFrame\n\nprint(\"The data has {} rows and {} columns\".format(data.shape[0], data.shape[1]))\nprint('#'*75)\nprint(data.dtypes)\ndata_cols = list(data.columns)\nprint(data_cols)","572caa9a":"# Description of the dataset\n\nprint(data.describe(include='all').T)","fd3efdc6":"data.head()","c98dc79c":"# Resetting the index\ndata.set_index('EmployeeNumber', inplace = True)","5b481778":"data.head()","20cae680":"# Mapping the catagorical variable 'Attrition' to 'Numerical' values using map\n\ndata['Attrition'] = data['Attrition'].map({'Yes':1, 'No':0})\n\n# 1 Indicates employee resigning and 0 indicates employee staying with the Org","a13c717b":"data.head(10)","dd5783cc":"cols_object = [var for var in data.columns if data[var].dtype == 'O']\nprint(cols_object)","547880f9":"data.drop('Over18', axis = 1, inplace = True)","681b27d7":"from sklearn import preprocessing\n\ndef preprocessor(df):\n    res_df = df.copy()\n    le = preprocessing.LabelEncoder()\n    \n    res_df['BusinessTravel'] = le.fit_transform(res_df['BusinessTravel'])\n    res_df['Department'] = le.fit_transform(res_df['Department'])\n    res_df['EducationField'] = le.fit_transform(res_df['EducationField'])\n    res_df['Gender'] = le.fit_transform(res_df['Gender'])\n    res_df['JobRole'] = le.fit_transform(res_df['JobRole'])\n    res_df['MaritalStatus'] = le.fit_transform(res_df['MaritalStatus'])\n    res_df['OverTime'] = le.fit_transform(res_df['OverTime'])\n    \n    return res_df","b509bb17":"encoded_df = preprocessor(data)","eb8d7b72":"encoded_df.head()\nprint(encoded_df.dtypes)","fb0c05f3":"feature_space = encoded_df.iloc[:, encoded_df.columns != 'Attrition']\nfeature_class = encoded_df.iloc[:, encoded_df.columns == 'Attrition']","a30e8e0f":"X_train, X_test, y_train, y_test = train_test_split(feature_space, feature_class, test_size = 0.2, random_state =42 )","9377e2d5":"X_train.values","a74f5bab":"rf = RandomForestClassifier(random_state = 42)","d511c5eb":"y_test = y_test.values.ravel() \ny_train = y_train.values.ravel() ","8726280f":"import time\nnp.random.seed(42)\n\nstart = time.time()\n\nparam_dist = {'max_depth':[2,3,4,5,6,7,8],\n             'bootstrap':[True, False],\n             'max_features':['auto', 'sqrt', 'log2', None],\n             'criterion':['gini', 'entropy']}\n\ncv_rf = GridSearchCV(rf, cv = 10, param_grid = param_dist, n_jobs = 3)\ncv_rf.fit(X_train, y_train)\nprint('Best Parameters using grid search: \\n', cv_rf.best_params_)\nend = time.time()\nprint('Time taken in grid search: {0: .2f}'.format(end - start))","2cee8398":"rf.set_params(criterion = 'entropy',\n                  max_features = None, \n                  max_depth = 8, bootstrap = True)","426ad33f":"rf.set_params(warm_start = True, oob_score = True)","bd08ad94":"# Estimation of the error rate for each n_estimators\n\n# For estimating n_estimators, warm_start has to be set as True and oob_score as True\n# rf.set_params(***) - sets the parameters for the model defined earlier. \n# In thi scase, rf is the model name for RandomForestClassifier\n\nmin_estimators = 100\nmax_estimators = 1000\n\n\n\n\n\nerror_rate = {}\n\nfor i in range(min_estimators, max_estimators+1):\n    rf.set_params(n_estimators = i)\n    rf.fit(X_train, y_train)\n    oob_error = 1 - rf.oob_score_\n    error_rate[i] = oob_error","1523a319":"oob_series = pd.Series(error_rate)","61b97c40":"plt.style.use('ggplot')\nfig, ax = plt.subplots(figsize=(16, 12))\n\nax.set_facecolor('#e6e6ff')\n\noob_series.plot(kind='line',color = 'red')\nplt.axhline(0.074, color='#33FFE5',linestyle='--')\nplt.axhline(0.071, color='#33FFE5',linestyle='--')\nplt.xlabel('n_estimators')\nplt.ylabel('OOB Error Rate')\nplt.title('OOB Error Rate Across various Forest sizes \\n(From 100 to 1000 trees)')\nplt.show()","0a4358be":"for i in range(100, 1000, 100):\n    print('OOB Error rate for {} trees is {}'.format(i, oob_series[i]))","32435986":"# Refine the tree via OOB Output\nrf.set_params(n_estimators=800,\n                  bootstrap = True,\n                  warm_start=False, \n                  oob_score=False)","c97ed06a":"rf.fit(X_train, y_train)","7ef4f5d8":"cols = [var for var in X_train.columns]\ncols_df = pd.DataFrame(cols, columns = ['Feature_Name'])\n\nimportance = list(rf.feature_importances_)\nprint(importance, len(importance))","d86579a2":"imp = pd.DataFrame(importance, columns = ['Importance'])\nfeature_imp = pd.concat([cols_df, imp], axis = 1)","e0679ecd":"feature_imp","cde4b0f2":"# Plotting a barplot to identify & visualize feature importance\nplt.figure(figsize=(16,12))\nx = sns.barplot(feature_imp['Feature_Name'], feature_imp['Importance'])\nx.set_xticklabels(labels=feature_imp.Feature_Name.values, rotation=90)\nplt.show()","6847027a":"predictions = rf.predict(X_test)\n\nprobability = rf.predict_proba(X_test)\n\nfpr, tpr, threshold = roc_curve(y_test, probability[:,1])\nprint(fpr)\nprint(tpr)\nprint(threshold)\n","a7d970ea":"# Printing of the Confusion Matrix\n\ncm = confusion_matrix(y_test, predictions)\n\nprint(cm)\nprint(type(cm))","d2f12933":"# Code to plot Confusion matrix in graphical way\n\nsns.set(font_scale=1.8) # scaling the font sizes\nplt.figure(figsize=(10,10))\n\nsns.heatmap(cm, annot=True, cbar=False, fmt = '', xticklabels = ['TRUE', 'FALSE'], yticklabels = ['TRUE', 'FALSE'])\nplt.xlabel('Predicted', color = 'blue', fontsize = 'xx-large' )\nplt.ylabel('Actual', color = 'blue', fontsize = 'xx-large')\nplt.show()","c118d965":"TP = cm[0][0]\nFP = cm[0][1]\nFN = cm[1][0]\nTN = cm[1][1]\n\nprint(TP, FP, FN, TN)","fe36176b":"Recall = (TP \/ (TP+FN))\nSpecificity = (TN \/ (FP+TN))\nAccuracy = ((TP+TN) \/ (TP+TN+FP+FN))\n\n\nprint(\"The Recall score is: {} \".format(np.round(Recall,2)))\nprint(\"The Specificity score is : {}\".format(np.round(Specificity,2)))\nprint(\"The Accuracy score is: {}\".format(np.round(Accuracy,2)))","6c2d27cf":"# The Accuracy score obtained using rf.score and manual calculation yield the same result\nprint(rf.score(X_test, y_test))","a99fde7e":"roc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(12,10))\n\nplt.plot(fpr, tpr, color = 'red', lw =2, label = 'Decision Tree (AUC = {})'.format(np.round(roc_auc, 2)))\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Area Under Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","9ff3e45b":"data_svm = encoded_df.copy()\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()","c97cc39e":"cont_cols = [var for var in data_svm.columns if data_svm[var].dtype != 'O']\nprint(cont_cols)","90088b86":"corr_mat = data_svm.corr()\nsns.set(font_scale=1.5)\nf, ax = plt.subplots(figsize=(20, 16))\nsns.heatmap(corr_mat, vmax =1, annot = True , square = False, annot_kws={\"size\":15},  cbar = False, fmt=\".2f\", cmap='coolwarm')\n\n\n# Arguments used for heatmap\n# cmap = colormap (coolwarm )","e9e0bd58":"cols_drop = ['JobLevel', 'YearsWithCurrManager', 'StandardHours', 'EmployeeCount', 'YearsInCurrentRole']","c21ec347":"data_wo_corr = data_svm.drop(cols_drop, axis = 1)\ndata_wo_corr.head()","1490b123":"# feature separation\n\nX = data_wo_corr.drop(['Attrition'], axis = 1)\ny = data_wo_corr['Attrition']\n\n\nscaler.fit(X)\nX = scaler.transform(X)","ceaa706d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","8fc4fd28":"from sklearn.svm import SVC\nfrom sklearn import metrics\nsvc=SVC() #Default hyperparameters\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))\n","eddccc65":"# Using Linear Kernel\n\nsvc=SVC(kernel='linear')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","cfdde2bf":"# Using Polynomial kernel\n\nsvc=SVC(kernel='poly')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","78dcea07":"kernel_choice = ['linear', 'poly', 'rbf']\n\nfor val in kernel_choice:\n    svc = SVC(kernel = val)\n    svc.fit(X_train, y_train)\n    y_pred = svc.predict(X_test)\n    print(\"Accuracy score using {} kernel is: {}\".format(val, metrics.accuracy_score(y_test,y_pred)))","7ffd3d3a":"#from sklearn.cross_validation import cross_val_score\nfrom sklearn.model_selection import cross_val_score\n\nC_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='linear', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nprint(acc_score)","6196db17":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\nC_values=list(range(1,26))\n# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)\nplt.plot(C_values,acc_score)\nplt.xticks(np.arange(0,27,2))\nplt.xlabel('Value of C for SVC')\nplt.ylabel('Cross-Validated Accuracy')","a738c120":"C_range=list(np.arange(0.1,6,0.1))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='linear', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    \n    acc_score.append(scores.mean())\nprint(acc_score)    ","6ef944bc":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nC_values=list(np.arange(0.1,6,0.1))\n# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)\n\nplt.figure(figsize=(16,8))\nplt.plot(C_values,acc_score)\nplt.xticks(np.arange(0.0,6,0.3))\nplt.xlabel('Value of C for SVC ')\nplt.ylabel('Cross-Validated Accuracy')","869324d3":"gamma_range=[0.0001,0.001,0.01,0.1,1,10,100]\nacc_score=[]\nfor g in gamma_range:\n    svc = SVC(kernel='rbf', gamma=g)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nprint(acc_score)  ","7bb28d15":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ngamma_range=[0.0001,0.001,0.01,0.1,1,10,100]\n\n# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)\nplt.figure(figsize = (16,12))\nplt.plot(gamma_range,acc_score)\nplt.xlabel('Value of gamma for SVC ')\nplt.xticks(np.arange(0.0001,100,5))\nplt.ylabel('Cross-Validated Accuracy')","9839909d":"from sklearn.svm import SVC\nsvm_model= SVC()\n\ntuned_parameters = { 'kernel': ['linear', 'rbf', 'poly'],\n 'C': (np.arange(0.1,1,0.1)) , 'gamma': [0.01,0.02,0.03,0.04,0.05], 'degree': [2,3,4] }","c5513c10":"#from sklearn.grid_search import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nmodel_svm = GridSearchCV(svm_model, tuned_parameters,cv=10,scoring='accuracy')\n\nmodel_svm.fit(X_train, y_train)\nprint(model_svm.best_score_)","ecbd10f3":"print(model_svm.best_params_)","d84f8043":"svm_model.set_params(C = 0.9, degree = 3, gamma = 0.05, kernel = 'poly', probability = True)","85dcc3d0":"svm_model.fit(X_train, y_train)\n\ny_pred = svm_model.predict(X_test)","877bf1ed":"proba = svm_model.predict_proba(X_test)\n\nfpr, tpr, threshold = roc_curve(y_test, proba[:,1])\nprint(fpr)\nprint(tpr)\nprint(threshold)","64f70edc":"cm = confusion_matrix(y_test, y_pred)\n\nprint(cm)\nprint(type(cm))","6e0d64e9":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(svm_model, X_test, y_test)","0e1a7d3f":"from sklearn.metrics import ConfusionMatrixDisplay\n\nConfusionMatrixDisplay(cm,display_labels = [1,0]).plot()","2bad38c7":"# Code to plot Confusion matrix in graphical way\n\nsns.set(font_scale=1.8) # scaling the font sizes\nplt.figure(figsize=(10,10))\n\nsns.heatmap(cm, annot=True, cbar=False, fmt = '', xticklabels = ['TRUE', 'FALSE'], yticklabels = ['TRUE', 'FALSE'])\nplt.xlabel('Predicted', color = 'blue', fontsize = 'xx-large' )\nplt.ylabel('Actual', color = 'blue', fontsize = 'xx-large')\nplt.show()","54031484":"TP = cm[0][0]\nFP = cm[0][1]\nFN = cm[1][0]\nTN = cm[1][1]\n\nprint(TP, FP, FN, TN)\n\nRecall = (TP \/ (TP+FN))\nSpecificity = (TN \/ (FP+TN))\nAccuracy = ((TP+TN) \/ (TP+TN+FP+FN))\n\n\nprint(\"The Recall score is: {} \".format(np.round(Recall,2)))\nprint(\"The Specificity score is : {}\".format(np.round(Specificity,2)))\nprint(\"The Accuracy score is: {}\".format(np.round(Accuracy,2)))","0412f72e":"roc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(12,10))\n\nplt.plot(fpr, tpr, color = 'red', lw =2, label = 'Decision Tree (AUC = {})'.format(np.round(roc_auc, 2)))\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Area Under Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","ef2aed11":"# OOB Rate\n\n- OOB stands for Out of Bag\n- Bootstrapping is a technique wherein the samples are selected in random with replacement from the original dataset\n- It may also happen that an observation might be selected more than once in a bootstrap\n- The proportion of samples that are left out after bootstrapping is equal to (1-(1\/N))^N. This approximates to 36.8 % \n- All the out of bag samples are used to cross validate the classification against each Decision Tree that form the Ensemble(Random Forest)\n- The aggreagate voting from each validation is used to classify the out of bag data from the dataset\n- The OOB error rate is the number of misclassifications that occur on the out of bag samples from the train data\n- This is equal to (1-oob_score_). Choose the n_estimators that gives the less oob error rate","6d32cc85":"# Making predictions on the Test Data","40040e27":"# Optimizing the HyperParameter C","69de1298":"# Plotting ROC AUC Curve","15ba046d":"# HR Attrition using SVMs","2f69586b":"# Using GridSearchCV to find Hyperparameters (C, gamma, kernel)","b6d9c8d4":"# Calculating Sensitivity (Recall) & Specificity","4b11cd6a":"# SVM with default HyperParameters","a2cbae8a":"# Optimizing the HyperParameter Gamma","670af636":"# Hyperparameter tuning using GridSearchCV"}}