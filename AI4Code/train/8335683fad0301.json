{"cell_type":{"b88027d1":"code","43794da8":"code","8e51ae3a":"code","c1b2db3b":"code","cf1b0cda":"code","a9f54bb5":"code","342bde80":"code","0ad8fc75":"code","7cad5cec":"code","b5237edf":"code","f404d46b":"code","00c37259":"code","1db36a5d":"code","286aebc8":"code","d4682b3e":"code","7e911c6f":"code","dccc21ae":"code","a2c5a543":"code","f596e5c6":"code","4272791e":"code","9ae95d43":"code","904ce740":"code","3c68bc48":"code","2c0775cc":"code","948ba18f":"code","45b89b28":"code","be21796f":"code","0d787bd2":"code","6b9a527f":"code","4bea9151":"code","7f504dee":"code","a76c14cf":"code","0dc90e10":"code","a4bebb7f":"code","cdc28edc":"code","95bd7e10":"code","99a9bfed":"code","1e016616":"code","378c8be7":"code","03fe9850":"code","b12d5ddf":"code","2035b08b":"code","78e6858c":"code","8be9099f":"code","74692bc9":"code","914e2076":"code","76a09e2f":"code","da2da731":"code","538651f5":"code","d48ae01a":"code","1bfe11e8":"code","71fb46b0":"code","26448117":"code","8a1dc42c":"code","a15ad072":"code","c3b618b1":"code","d1d65426":"code","4faff09b":"code","12070a25":"code","a6d25595":"code","b83704d7":"code","350aa950":"code","f899bd0a":"code","a6189652":"code","17705f5d":"markdown","3e3a3b54":"markdown","f2394099":"markdown","64308c3e":"markdown","8703c456":"markdown","c9e41daa":"markdown","b9ecb3e1":"markdown","561f878f":"markdown","68c526ed":"markdown","f4a82059":"markdown","2d01a3fc":"markdown","d687118c":"markdown","0ab6e3cd":"markdown","ac9324cf":"markdown","f6d76f7c":"markdown","6f89704f":"markdown","3a1f5c42":"markdown","e7e1ffed":"markdown","3295ba13":"markdown","43674b5c":"markdown","c578977b":"markdown","509fa726":"markdown","922dcf82":"markdown","9713f302":"markdown","020cd03b":"markdown","971d3e2b":"markdown","36f2102b":"markdown","cc648abf":"markdown","dd874d79":"markdown","d377c8c9":"markdown","70e1b1b7":"markdown","30c83c15":"markdown","c49fcfb4":"markdown","89227670":"markdown","60afe433":"markdown","640792b4":"markdown","d69c7c53":"markdown","9c36e713":"markdown","e43153bd":"markdown","3a402059":"markdown","2324b915":"markdown","d5f56923":"markdown","59506b1c":"markdown","d53606a3":"markdown","a3368249":"markdown"},"source":{"b88027d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","43794da8":"# Pytorch in python can be accessed by Torch library\nimport torch","8e51ae3a":"# Check current torch version\ntorch.__version__","c1b2db3b":"# In case Nvidea Cuda available, this will give True as result else False\ntorch.cuda.is_available()","cf1b0cda":"import torchvision\n# transform is used to convert data into Tensor form with transformations\nimport torchvision.transforms as transforms","a9f54bb5":"import torchvision\nimport torchvision.transforms as transforms","342bde80":"train_set = torchvision.datasets.MNIST(\nroot = '.\/data',\ntrain = True,\ndownload = True,\ntransform = transforms.Compose([transforms.ToTensor()])\n)","0ad8fc75":"# Length of train set\nlen(train_set)","7cad5cec":"# Lets study first image\n\nimg, label = train_set[0]\nimg.shape, label","b5237edf":"def show_img(img, label):\n    print('Label: ', label)\n    plt.imshow(img.permute(1,2,0), cmap = 'gray')","f404d46b":"# Without these libraries, we cant think of running any Data analysis related python program\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","00c37259":"# lets observe some images\nshow_img(*train_set[1])","1db36a5d":"show_img(*train_set[19992])","286aebc8":"trans = transforms.Compose([\n    # To resize image\n    transforms.Resize((32,32)),\n    transforms.ToTensor(),\n    # To normalize image\n    transforms.Normalize((0.5,), (0.5,))\n])","d4682b3e":"train_set = torchvision.datasets.MNIST(\nroot = '.\/data',\ntrain = True,\ndownload = True,\ntransform = trans\n)","7e911c6f":"test_set = torchvision.datasets.MNIST(\nroot = '.\/data',\ntrain = False,\ndownload = True,\ntransform = trans\n)","dccc21ae":"len(train_set), len(test_set)","a2c5a543":"img, label = train_set[0]\nimg.shape, label","f596e5c6":"show_img(*train_set[0])","4272791e":"show_img(*train_set[9999])","9ae95d43":"show_img(*test_set[5999])","904ce740":"# this function will generate random indexes between 0 and 59999\ndef split_indices(n, val_per, seed = 0):\n    n_val = int(n * val_per)\n    np.random.seed(seed)\n    idx = np.random.permutation(n)\n    return idx[n_val : ], idx[: n_val]","3c68bc48":"val_per = 0.2\nrand_seed = 42\n\ntrain_indices, val_indices = split_indices(len(train_set), val_per, rand_seed)\n\nprint(len(train_indices), len(val_indices))","2c0775cc":"# Lets plot some indexes\n\nprint(\"Validation Indices: \", val_indices[:20])\nprint(\"Training Indices: \", train_indices[:20])","948ba18f":"from torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader","45b89b28":"# this is one of Hyper parameter, but let's select given below value\nbatch_size = 512","be21796f":"# training data loader\ntrain_sampler = SubsetRandomSampler(train_indices)\ntrain_dl = DataLoader(train_set, batch_size, sampler = train_sampler)","0d787bd2":"# validation dataloader\nval_sampler = SubsetRandomSampler(val_indices)\nval_dl = DataLoader(train_set, batch_size, sampler = val_sampler)","6b9a527f":"from torchvision.utils import make_grid\n# this will help us to create Grid of images","4bea9151":"# We will select first 110 image from first batch of size = 512\ndef show_batch(dl):\n    for img, label in dl:\n        fig, ax = plt.subplots(figsize = (12,8))\n        ax.imshow(make_grid(img[:110], 10).permute(1,2,0))\n        break","7f504dee":"show_batch(val_dl)","a76c14cf":"show_batch(train_dl)","0dc90e10":"import torch.nn as nn\nimport torch.nn.functional as F","a4bebb7f":"class LeNet5(nn.Module):\n    \n    def __init__(self, num_classes):\n        \n        super().__init__()\n        \n        self.num_classes = num_classes\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 6, kernel_size = 5),\n            nn.Tanh(),\n            nn.MaxPool2d(kernel_size = 2),\n            nn.Conv2d(6, 16, kernel_size = 5),\n            nn.Tanh(),\n            nn.MaxPool2d(kernel_size = 2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(16*5*5, 120),\n            nn.Tanh(),\n            nn.Linear(120, 84),\n            nn.Tanh(),\n            nn.Linear(84, num_classes)  \n        )\n        \n        \n        \n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        logit = self.classifier(x)\n        return logit","cdc28edc":"# Load Model\nmodel = LeNet5(num_classes = 10)","95bd7e10":"model","99a9bfed":"sample = next(iter(train_set))\nimg = sample[0]\nimg.shape","1e016616":"img.unsqueeze(0).shape\n# Now we have [1, 1, 32, 32] shape of image","378c8be7":"out = model(img.unsqueeze(0))\nout","03fe9850":"# Output In terms of Probability\nF.softmax(out)","b12d5ddf":" # Demo function to test result\n\nfor images, labels in train_dl:\n    print('Image Shape', images.shape)\n    out = model(images)\n    print('output shape', out.shape)\n    print('out[0]', out[0])\n    break","2035b08b":"probs = F.softmax(out[0], dim = 0)\nprobs","78e6858c":"m = torch.argmax(probs)\nm","8be9099f":"# Lets plot\nplt.imshow(img.permute(1,2,0))","74692bc9":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","914e2076":"device = get_default_device()\ndevice","76a09e2f":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device)","da2da731":"def loss_batch(model, loss_func, x, y, opt = None, metric = None):\n    \n    pred = model(x)\n    \n    loss = loss_func(pred, y)\n    \n    if opt is not None:\n        \n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        \n    metric_result = None\n    \n    if metric is not None:\n        \n        metric_result = metric(pred, y)\n        \n    return loss.item(), len(x), metric_result","538651f5":"def evaluate(model, loss_fn, val_dl, metric = None):\n    \n    with torch.no_grad():\n        \n        results = [loss_batch(model, loss_fn, x, y, metric = metric) for x, y in val_dl]\n        \n        losses, nums, metrics = zip(*results)\n        \n        total = np.sum(nums)\n        \n        avg_loss = np.sum(np.multiply(losses, nums)) \/ total\n        \n        avg_metric = None\n        \n        if metric is not None:\n            avg_metric = np.sum(np.multiply(metrics, nums)) \/ total\n            \n    return avg_loss, total, avg_metric","d48ae01a":"def fit(epochs, model, loss_fn, train_dl, val_dl, opt_fn = None, metric = None, scheduler = None, scheduler_on = 'val_metric'):\n    \n    train_losses, val_losses, val_metrics, train_metrics = [], [], [], []\n    \n    \n    for epoch in range(epochs):\n        \n        model.train()\n        for x, y in train_dl:\n            train_loss, _, train_metric = loss_batch(model, loss_fn, x, y, opt_fn, metric)\n            \n        model.eval()\n        result = evaluate(model, loss_fn, val_dl, metric)\n        val_loss, total, val_metric = result\n        \n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_metrics.append(val_metric)\n        train_metrics.append(train_metric)\n        \n        if metric is None:\n            print('Epoch{}\/{}, train_loss: {:.4f}, val_loss: {:.4f}' \n                 .format(epoch+1, epochs, train_loss, val_loss))\n            \n        else:\n            print('Epoch {}\/{}, train_loss: {:.4f}, val_loss: {:.4f}, val_{}: {:.4f}, train_{}: {:.4f}'\n                 .format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric, metric.__name__, train_metric))\n            \n        if scheduler is not None:\n            if scheduler_on == 'val_metric':\n                scheduler.step(val_metrics[-1])\n        \n            \n    return train_losses, val_losses, val_metrics, train_metrics","1bfe11e8":"def accuracy(output, labels):\n    _, preds = torch.max(output, dim = 1)\n    \n    return torch.sum(preds == labels).item() \/ len(preds)","71fb46b0":"val_loss, _, val_acc = evaluate(model, F.cross_entropy, val_dl, metric = accuracy)\n\nprint(val_loss, val_acc)","26448117":"num_epochs = 25\n\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, mode = 'max', verbose = True)","8a1dc42c":"history = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, optimizer, accuracy, scheduler, 'val_metric')","a15ad072":"plt.figure(figsize = (8,8))\nplt.plot(history[0], '-x')\nplt.xlabel('Epochs')\nplt.ylabel('Training Loss')\nplt.title('Plot between Training Loss vs Epochs')","c3b618b1":"plt.figure(figsize = (8,8))\nplt.plot(history[1], '-x')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.title('Plot between Validation Loss vs Epochs')","d1d65426":"plt.figure(figsize = (8,8))\nplt.plot(history[0], '-go')\nplt.plot(history[1], '-yx')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.title('Plot between Validation Loss & training Loss vs Epochs')\nplt.legend(['Train Loss', 'Validation Loss'], loc = 'upper right')","4faff09b":"plt.figure(figsize = (8,8))\nplt.plot(history[3], '-go')\nplt.plot(history[2], '-yx')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Plot between Training Accuracy & Validation vs Epochs')\nplt.legend(['Train Accuracy', 'Validation Accuracy'], loc = 'lower right')","12070a25":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","a6d25595":"img, label = test_set[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","b83704d7":"img, label = test_set[1839]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","350aa950":"img, label = test_set[193]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","f899bd0a":"img, label = test_set[1000]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","a6189652":"test_loader = DeviceDataLoader(DataLoader(test_set, batch_size=256), device)\nresult = evaluate(model, F.cross_entropy, test_loader, metric = accuracy)\nresult\nAccuracy = result[2] * 100\nAccuracy\nloss = result[0]\nprint(\"Total Losses: {}, Accuracy: {}\".format(loss, Accuracy))","17705f5d":"Let's Import libraries to generate Random Subset & dataLoader to feed Batch of data to model, as feeding whole dataset may lead to System failure or Hang\n\n","3e3a3b54":"Well, this is amazing right ?? 100% Train Accuracy and 98.86% Validation accuracy!!","f2394099":"May Be over fitting ?? Well, its fairly simplest dataset that anyone ever get, so It was not probably over fitting :(","64308c3e":"# Important Library Loading & Data Loading","8703c456":"Thats it for this Notebook...\n\nIf you like this kindly Consider Upvoting!! Happy learning!!","c9e41daa":"It seems indexes are distributed across range as provided","b9ecb3e1":"Torch Vision is library to work with Images in Pytorch","561f878f":"If you like this kindly Consider Upvoting!! Happy learning!!","68c526ed":"Torchvision has inbuilt Dataset where Mnist dataset is available, Lets import data\n\n","f4a82059":"This was tough one, but model predicted coreectly","2d01a3fc":"# Test data & Model Evaluation","d687118c":"Lets see initial guesses from model","0ab6e3cd":"Too Much of noise because of Batch Stochastic gradient","ac9324cf":"# About data","f6d76f7c":"# Data Study","6f89704f":"Let's verify where we have all class from output columns in both train and validation set\n\n","3a1f5c42":"# Plotting result","e7e1ffed":"# Data Normalization","3295ba13":"# Define Helper Fit Model","43674b5c":"So each Image is 28*28 pixel and Its Gray scale image, as color channel is 1","c578977b":"In Neural Network we have to perform Data Normalization to reduce possibility of Over Fitting, also CNN algorithms use Gradient boosting, So its must to perform Normalization else some variable may be given higher weightage.","509fa726":"Wow, 98.87% Accuracy, I can just believe inventor of this model, Their Hard Work and Their dedication, hats Off to those guys","922dcf82":"Initial guess on Validation data","9713f302":"We need to import one extra dimension as Model need shape as [batch_size COlor Channel heigh * Width]\n\n.unsqueeze() from torch help to add extra dimension","020cd03b":"Define Accuracy function","971d3e2b":"This is how Yen LeKun has decribed and built First Neural network in 1988, that was probably first working Neural model","36f2102b":"Well, it was wrong guess from Model :(","cc648abf":"Initial guess from model suggest, probability of each class as 10%, which is kind of 1st prediction from model\n\n","dd874d79":"# Device Selection","d377c8c9":"As a final step, let's also look at the overall loss and accuracy of the model on the test set.\n\n","70e1b1b7":"As torch has image representation as [color channel, Height, Width] but Maplotlib accepts [height, width, color channel], hence above .permute() function does that.","30c83c15":"The first layer is the input layer with feature map size 32X32X1.\n\nThen we have the first convolution layer with 6 filters of size 5X5 and stride is 1. The activation function used at his layer is tanh. The output feature map is  28X28X6.\n\nNext, we have an average pooling layer with filter size 2X2 and stride 1. The resulting feature map is 14X14X6. Since the pooling layer doesn\u2019t affect the number of channels.\n\nAfter this comes the second convolution layer with 16 filters of 5X5 and stride 1. Also, the activation function is tanh. Now the output size is 10X10X16.\n\nAgain comes the other average pooling layer of 2X2 with stride 2. As a result, the size of the feature map reduced to 5X5X16.\n\nThe final pooling layer has 120 filters of 5X5  with stride 1 and activation function tanh. Now the output size is 120.\n\nThe next is a fully connected layer with 84 neurons that result in the output to 84 values and the activation function used here is again tanh.\n\nThe last layer is the output layer with 10 neurons and  Softmax function. The Softmax gives the probability that a data point belongs to a particular class. The highest value is then predicted.\n\nThis is the entire architecture of the Lenet-5 model. The number of trainable parameters of this architecture is around sixty thousand.","c49fcfb4":"So now we have images with 32*32 pixels","89227670":"Images seems equally Distributed\n\n","60afe433":"Plot between Training Loss vs Epochs","640792b4":"Let's define a function which can help us to plot an Image and hence reproduceable\n\n","d69c7c53":"It seems model predict index 7, i.e. letter 7 as output, its initial guess !!","9c36e713":"Yippy!! That's Correct\n\n","e43153bd":"Lets observe some changes","3a402059":"## What is Lenet5?\nLenet-5 is one of the earliest pre-trained models proposed by Yann LeCun and others in the year 1998, in the research paper Gradient-Based Learning Applied to Document Recognition. They used this architecture for recognizing the handwritten and machine-printed characters.","2324b915":"Let's test model based on initial Guesses by Pytorch\n\n","d5f56923":"The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n\nFor example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.","59506b1c":"# Model Building using Torch.nn","d53606a3":"As we are using GPU, so below code will help us to access GPU at different stage of Processing\n\n","a3368249":"# Train & Validation data Split"}}