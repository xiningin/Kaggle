{"cell_type":{"8cce809c":"code","1e943d57":"code","bff872e5":"code","f9ef083d":"code","d0cd183e":"code","a06996a1":"code","5c92f930":"code","6e2254dc":"code","7f338079":"code","3254c951":"code","a76258d8":"code","c37c61d1":"code","1f9e17ca":"code","a038e290":"code","1fc83d87":"code","70bee78f":"code","a5bfb97a":"code","18a18ffa":"code","6f564840":"code","efbbe65d":"code","5a67cd54":"code","4fc7d065":"code","b1fdc002":"code","ec0716ed":"code","54beb683":"code","67f74e3d":"code","421a768b":"code","cedd6490":"code","8a2f12f6":"code","5914390d":"code","0a6b6354":"code","f7bd4084":"code","46fd3f31":"code","55122a7d":"markdown","74782740":"markdown","7438ed88":"markdown","7bfee69e":"markdown","893ee5ff":"markdown","77907dc8":"markdown","f5ce49ca":"markdown","12a192b6":"markdown","4d670f34":"markdown","ee646056":"markdown","1428fe16":"markdown"},"source":{"8cce809c":"import pandas as pd # table operations\nimport numpy as np # linear algebra\nimport seaborn as sns # visualizing\nimport os # getting path\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt # visualizing\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img # prepare image\nimport cv2 # haar cascade\nfrom scipy.spatial import distance\nimport glob\nfrom warnings import filterwarnings\nfrom tensorflow.keras.applications import VGG19 # classify modle\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.callbacks import ModelCheckpoint # save best model weights\nfrom tensorflow.keras.models import Model, load_model # load model\nfrom sklearn.metrics import confusion_matrix\nfrom skimage import io\nfilterwarnings(\"ignore\")","1e943d57":"path  = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/\"","bff872e5":"dataset = {\"image_path\":[],\"mask_status\":[],\"where\":[]}\nfor where in os.listdir(path):\n    for status in os.listdir(path+\"\/\"+where):\n        for image in glob.glob(path+where+\"\/\"+status+\"\/\"+\"*.png\"):\n            dataset[\"image_path\"].append(image)\n            dataset[\"mask_status\"].append(status)\n            dataset[\"where\"].append(where)\ndataset = pd.DataFrame(dataset)\ndataset","f9ef083d":"dataset.value_counts(\"mask_status\")","d0cd183e":"mask = dataset.value_counts(\"mask_status\")[1]\nwithoutmask = dataset.value_counts(\"mask_status\")[0]\n\nprint(f\"With Mask: {mask},\\nWithout Mask: {withoutmask}\\n\")\nsns.countplot(dataset[\"mask_status\"])\nplt.show()","a06996a1":"plt.figure(figsize = (14,10))\nfor i in range(9):\n    random = np.random.randint(1,len(dataset))\n    plt.subplot(3,3,i+1)\n    plt.imshow(cv2.imread(dataset.loc[random,\"image_path\"]))\n    plt.title(dataset.loc[random, \"mask_status\"], size = 10, color = \"purple\") \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","5c92f930":"train_df = dataset[dataset[\"where\"] == \"Train\"]\ntest_df = dataset[dataset[\"where\"] == \"Test\"]\nvalid_df = dataset[dataset[\"where\"] == \"Validation\"]","6e2254dc":"train_df = train_df.sample(frac=1)\ntest_df = test_df.sample(frac=1)\nvalid_df = valid_df.sample(frac=1)\n","7f338079":"train_df.head()","3254c951":"test_df.head()","a76258d8":"valid_df.head()","c37c61d1":"plt.figure(figsize = (15,6))\nplt.subplot(1,3,1)\nsns.countplot(train_df[\"mask_status\"])\nplt.title(\"Train_df\", size = 14, color = \"orange\")\n\n\nplt.subplot(1,3,2)\nsns.countplot(test_df[\"mask_status\"])\nplt.title(\"Test_df\", size = 14, color = \"red\")\n\n\nplt.subplot(1,3,3)\nsns.countplot(valid_df[\"mask_status\"])\nplt.title(\"Validation_df\", size = 14, color = \"blue\")\n\nplt.show()","1f9e17ca":"datagen = ImageDataGenerator(rescale = 1.\/255)","a038e290":"train_generator=datagen.flow_from_dataframe(\ndataframe=train_df,\ndirectory=\"..\/input\",\nx_col=\"image_path\",\ny_col=\"mask_status\",\nbatch_size=80,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))","1fc83d87":"valid_generator=datagen.flow_from_dataframe(\ndataframe=valid_df,\ndirectory=\"..\/input\",\nx_col=\"image_path\",\ny_col=\"mask_status\",\nbatch_size=80,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))","70bee78f":"test_generator=datagen.flow_from_dataframe(\ndataframe=test_df,\ndirectory=\"..\/input\",\nx_col=\"image_path\",\ny_col=\"mask_status\",\nbatch_size=80,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))","a5bfb97a":"model = VGG19(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\nfor layer in model.layers[2:]: \n  layer.trainable = False\nmodel.summary()","18a18ffa":"x=Flatten()(model.output)\nx2 = Dense(128, activation=\"relu\")(x)\noutput=Dense(1,activation='sigmoid')(x2) # \nmodel=Model(model.input,output)","6f564840":"model.summary()","efbbe65d":"# save best weights\ncheckpoint = ModelCheckpoint(\"classify_model.h5\", save_best_only=True, verbose = 1)","5a67cd54":"model.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nhistory = model.fit_generator(train_generator,validation_data  = valid_generator, epochs = 10, steps_per_epoch=(len(train_generator.labels) \/ 80) ,validation_steps=(len(valid_generator.labels)\/80), callbacks =[checkpoint])","4fc7d065":"# load model\nmodel = load_model(\"classify_model.h5\")","b1fdc002":"model.evaluate_generator(test_generator, verbose=1)","ec0716ed":"model.summary()","54beb683":"plt.figure(figsize = (10,4))\nplt.subplot(1,2,1)\nplt.plot(history.history[\"accuracy\"], label = \"train accuracy\", color = \"red\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation accuracy\", color = \"blue\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history[\"loss\"], label = \"train loss\", color = \"red\")\nplt.plot(history.history[\"val_loss\"], label = \"validation loss\", color = \"blue\")\n\nplt.legend()\nplt.show()","67f74e3d":"predictions = model.predict_generator(test_generator, verbose = 1,workers=-1)","421a768b":"plt.figure(figsize = (8,5))\nsns.heatmap(confusion_matrix(test_generator.labels, predictions.round()), annot = True,fmt=\"d\",cmap = \"Blues\")\nplt.show()","cedd6490":"face_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')","8a2f12f6":"img = cv2.imread(train_df.loc[np.random.randint(1,len(train_df)),\"image_path\"])\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)\nplt.figure(figsize=(6,6))\nplt.imshow(out_img)\nplt.show()","5914390d":"mask_label = {0:'Has Mask!',1:'No Mask'}\ndist_label = {0:(0,255,0),1:(255,0,0)}\nMIN_DISTANCE = 0\n\nimg= io.imread(\"https:\/\/www.ctvnews.ca\/polopoly_fs\/1.4986740.1592334933!\/httpImage\/image.jpg_gen\/derivatives\/landscape_960\/image.jpg\")\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=8)\n\nif len(faces)>=1:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(150,150))\n        crop = np.reshape(crop,[1,150,150,3])\/255.0\n        mask_result = model.predict(crop)\n        cv2.putText(img,mask_label[round(mask_result[0][0])],(x, y+90), cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n        cv2.rectangle(img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img)\n            \nelse:\n    print(\"No Face!\")","0a6b6354":"img = io.imread('https:\/\/us.123rf.com\/450wm\/filipw\/filipw1602\/filipw160200148\/52231994-studio-shot-of-young-man-looking-at-the-camera-isolated-on-white-background-horizontal-format-he-has.jpg?ver=6')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),1)\nplt.figure(figsize=(12,12))\nplt.imshow(img)","f7bd4084":"if len(faces)>=1:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(150,150))\n        crop = np.reshape(crop,[1,150,150,3])\/255.0\n        mask_result = model.predict(crop)\n        cv2.putText(new_img,mask_label[round(mask_result[0][0])],(x, y), cv2.FONT_HERSHEY_SIMPLEX,1,dist_label[label[i]],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"No Face!\")","46fd3f31":"model.save(\"classify_model.h5\")","55122a7d":"## Preprocessing image ","74782740":"<div style = \"padding:30px;\">\n    <h2 style = \"text-align:center;color:#4B0082 ;margin-bottom:25x;\">  Mask Detection \ud83d\ude37 <\/h2>  \n<div style = \"text-align:center;\">\n    <img  src = \"https:\/\/cssh.northeastern.edu\/philosophy\/wp-content\/uploads\/sites\/11\/2020\/09\/Illustrated-Community-Masks-3-with-Hijab.jpg\" style =\"width:90%;height:450px;\"><\/div>\n    <\/div>","7438ed88":"## Model evaluation","7bfee69e":"## The last check","893ee5ff":"## Face detection Model","77907dc8":"<p style = \"color:#8A2BE2;font-size:20px;\">  \ud83d\udc4b Please, if you have a suggestion, write feedback, Stay Healthy \ud83d\ude0a <\/p>","f5ce49ca":"The path is created for getting data and then I concatened dataframes of mask and without mask.","12a192b6":"## Classify Model","4d670f34":"in this notebook, following process is adopted:<br>\n* Prepare mask and without mask images for classifiying model \n* Train the classifier to classify faces into mask or non-mask labels.\n* Detect Face with Opencv Haar Cascade Classifier\n* Classifiy Face with Pretrained VGG19 model","ee646056":"## import libraries","1428fe16":"<p style = \"font-weight:bold;\"> Hello, Welcome to my mask detection project \ud83d\udc4b <\/p>\n<p>\nThe covid19 virus influence negatively our life since 2019 and the virus the first appearance place in the world was Wuhan city in China, \nand then spread all over world,from this moment we have to  wear a face maske in  crowded places such as cafe, restaurant.. While wearing mask is not the ultimate solution, it still reduces the rate of transmission of the virus.In addition much applications were produced by software developers. I devoloped this project to solve face mask problem.\n<\/p>"}}