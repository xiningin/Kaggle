{"cell_type":{"0a0a9d2c":"code","31a4d02f":"code","339987b4":"code","e3746b2b":"code","c1bea0d8":"code","e423fcf5":"code","12a3c125":"code","5aff9c21":"code","e77356fa":"code","c29a4364":"code","56d8c2ae":"code","587bd186":"code","0dd4361a":"code","1cb5dd2a":"code","afb359b4":"code","eab7338a":"code","1f47958d":"code","7673d2ec":"code","7d5fe889":"code","069aaa5f":"code","f8f606f6":"code","846b2a0e":"markdown","73e31cdf":"markdown","f0ef5c70":"markdown","272a286a":"markdown","2d4f5842":"markdown","45e4be3e":"markdown","e8d2a573":"markdown","e2f07f9c":"markdown","68862ec5":"markdown","b079d51d":"markdown","f8da70cf":"markdown","4a46a092":"markdown","e618b7f1":"markdown","11c7f66e":"markdown","554498a0":"markdown","fd7999e2":"markdown","9e79028f":"markdown","87f21e26":"markdown","bcee5746":"markdown","1a64dc02":"markdown","f65cec10":"markdown","902bfccf":"markdown","000f84ca":"markdown","05d1c494":"markdown","89606da4":"markdown"},"source":{"0a0a9d2c":"from IPython.display import Image\nImage(\"..\/input\/cvcnnimages\/1.png\")","31a4d02f":"# importing tensorflow and keras\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.utils import to_categorical, plot_model","339987b4":"# Printing version of the TensorFlow\n\nprint(tf.__version__)","e3746b2b":"# Loading the dataset\n\nfashion_mnist=keras.datasets.fashion_mnist # Loading the dataset\n\n(xtrain,ytrain),(xtest,ytest)=fashion_mnist.load_data()\n\nprint(xtrain.shape)\nprint(ytrain.shape)\nprint(xtest.shape)\nprint(ytest.shape)\nprint(ytrain)\n\n# see the size of the dataset\n# print(\"Train Images Shape: %s \\nTrain Labels: %s \\nTest Images Shape: %s \\nTest Labels: %s\"  % (xtrain.shape, xtrain,xtest.shape,ytest))\n","c1bea0d8":"# Defining array. Each item of array represent integer value of labels. 10 clothing item for 10 integer label.\n\nclass_names =['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nprint(class_names)","e423fcf5":"# inspect the data in the array\n\nindex=0 # change this number \nplt.imshow(xtrain[index], cmap='gray') # printing 10th image\nplt.colorbar() # shows the bar on the right side of the image\nplt.grid(True) # will shot the grid\nplt.show()\nprint(\"Class ID: %s and Class name: %s\" % (ytrain[index], class_names[ytrain[index]]))","12a3c125":"# display the first 25 images from traing set\n\nplt.figure(figsize=(10,10))\nfor i in range(25): # 25 images\n  plt.subplot(5,5,i+1) # matrix of 5 X 5 array\n  plt.xticks([])\n  plt.yticks([])\n  plt.grid(False)\n  plt.imshow(xtrain[i], cmap=plt.cm.binary) # printing binary\/black and white image\n  plt.xlabel(\"%s %s\" % (ytrain[i], class_names[ytrain[i]])) # Assigning name to each image\nplt.show()","5aff9c21":"# Pixel value of the image falls between 0 to 255.\n\nxtrain = xtrain\/255 # So, we are scale the value between 0 to 1 before by deviding each value by 255\nprint(xtrain.shape)\n\nxtest = xtest\/255 # So, we are scale the value between 0 to 1 before by deviding each value by 255\nprint(xtest.shape)","e77356fa":"# One hot encoding of the labels.\n#(generally we do one hot encoding of the features in EDA but in this case we are doing it for labels)\n\n# Before one hot encoding\nprint(\"ytrain Shape: %s and value: %s\" % (ytrain.shape, ytrain))\nprint(\"ytest Shape: %s and value: %s\" % (ytest.shape, ytest))\n\nytrain=to_categorical(ytrain)\nytest=to_categorical(ytest)\n\n# After one hot encoding\nprint(\"ytrain Shape: %s and value: %s\" % (ytrain.shape, ytrain[0]))\nprint(\"ytest Shape: %s and value: %s\" % (ytest.shape, ytest[1]))","c29a4364":"from IPython.display import Image\nImage(\"..\/input\/cvcnnimages\/2.png\")","56d8c2ae":"# Modelling - Model on CNN\n\nfrom tensorflow.keras import models, layers\n\n# create a sequential model i.e. empty neural network which has no layers in it.\nmodel=models.Sequential()\n\n#==================== Feature Detection \/ extraction Block ====================#\n\n# Add first convolutional block - To deal with images we use Conv2D and for colour images and shape use Conv3D\n#model.add(layers.Conv2D(filters=6, kernal_size(3,3), input_shape=(28,28,1), activation='relu'))\n# in the first block we need to mention input_shape\nmodel.add(layers.Conv2D(6,(3,3),input_shape=(28,28,1),activation='relu'))\n# Add the max pooling layer\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n# Add Second convolutional block\n#model.add(layers.Conv2D(filters=6, kernal_size(3,3), activation='relu'))\nmodel.add(layers.Conv2D(10,(3,3),activation='relu'))\n# Add the max pooling layer\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n#==================== Transition Block (from feature detection to classification) ====================#\n\n# Add Flatten layer. Flatten simply converts matrics to array\nmodel.add(layers.Flatten(input_shape=(28,28))) # this will flatten the image and after this Classification happens\n\n#==================== Classification Block ====================#\n\n# Classification segment - fully connected network\n# The Dence layer does classification and is deep neural network. Dense layer always accept the array.\nmodel.add(layers.Dense(128, activation='relu')) # as C5 layer in above image. \n# this 120 is hyper parameter whcih is number of neuron \n#model.add(layers.Dense(84, activation='relu'))# as F6 layer in aboave image\n\n# Add the output layer\nmodel.add(layers.Dense(10, activation='softmax')) # as Output layer in above image. The output layer normally have softmax activation\n\n# Ploting the Model\nplot_model(model)","587bd186":"# Compile the model\n\n# if we use softmax activation in output layer then best fit optimizer is categorical_crossentropy\n# for sigmoid activation in output layer then loss will be binary_crossentropy\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n# if we do not go for One Hot Encoding then use loss='sparse_categorical_crossentropy'\n\nmodel.summary()","0dd4361a":"# Train the model \n# Using GPU really speeds up this code\nxtrain2=xtrain.reshape(60000,28,28,1)\nxtest2=xtest.reshape(10000,28,28,1)\n\n# print(xtrain.shape)\n# print(xtest.shape)\n# print(ytrain.shape)\n# print(ytest.shape)\n\nmodel.fit(xtrain2,ytrain,epochs=20,batch_size=1000,verbose=True,validation_data=(xtest2,ytest))","1cb5dd2a":"# evaluate accuracy of the model\n\ntest_loss, test_acc = model.evaluate(xtest2, ytest)\nprint(\"accuracy:\", test_acc)","afb359b4":"# predicting lable for test_images\n\npredictions=model.predict(xtest2)\n\n# Prediction of the 1st result. It will show the 10 predictions of labels for test image\nprint(\"1. Prediction array: %s\" % (predictions[0]))\n\n# we will verify that which result for label has highest confidence\nprint(\"2. Label number having highest confidence in prediction array: %s\" % (np.argmax(predictions[0])))\n\n# let us verify what is the label in test_labels.\nprint(\"3. Actual label in dataset: %s\" % (ytest[0]))","eab7338a":"# creating a funtion which will help to verify the prediction is true of not\n\ndef plot_image(i, predictions_array, true_label, img): # taking index and 3 arrays viz. prediction array, true label array and image array\n  \n  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(img, cmap=plt.cm.binary) # showing b\/w image\n\n  predicted_label=np.argmax(predictions_array)\n  true_label=np.argmax(true_label)\n\n  # print(predicted_label)\n  # print(true_label)\n  \n  if predicted_label == true_label: #setting up label color\n    color='blue' # correct then blue colour\n    \n  else:\n    color='red' # wrong then red colour\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                       100*np.max(predictions_array),\n                                       class_names[true_label]),\n             color=color)\n  \n# function to display bar chart showing whether image prediction is how much correct  \ndef plot_value_array(i, predictions_array, true_label): # taking index along with predictions and true label array\n  predictions_array, true_label = predictions_array[i], true_label[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  thisplot=plt.bar(range(10), predictions_array, color='gray')\n  plt.ylim([0,1])\n  predicted_label=np.argmax(predictions_array)\n  true_label=np.argmax(true_label)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('green')","1f47958d":"# call the function\n\n# defining parameters to pass to function\ni=12 # image number 56. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\n\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","7673d2ec":"# call the function\n\n# defining parameters to pass to function\ni=7 # image number 5. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","7d5fe889":"# call the function\n\n# defining parameters to pass to function\ni=12 # image number 12. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","069aaa5f":"# verification our prediction on single image\n\ni=24 # image number 0. You may change value of i for play around\nimg = xtest2[i]\nprint(img.shape)\n\nimg=(np.expand_dims(img,0))\nprint(img.shape)\n\npredictions_single = model.predict(img)\nprint(predictions_single)\n\nplot_value_array(i, predictions,ytest)\n_ = plt.xticks(range(10), class_names,rotation=45)\n\nnp.argmax(predictions_single[0])","f8f606f6":"# verification of several images\n\nnum_rows=6\nnum_cols=4\nnum_images=num_rows*num_cols\n\nplt.figure(figsize=(2*2*num_cols,2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i,predictions, ytest, xtest)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions, ytest)\nplt.show()","846b2a0e":"## Verifying several images","73e31cdf":"## Test for single image","f0ef5c70":"# Importing packages","272a286a":"# Modelling - Model on CNN\n- There are 2 ways to program CNN with keras:\n  - Sequential approach: Here, we generally add layers in sequence.\n  - Modular approach: This is more important. This more dynamic, cusotmized, moulded and easy to explore. We generally use this.\n\nEffectiveness in both the approach will remain same.\n\nWe are creating this model based on lecun-99\nSource: http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-99.pdf\n\n","2d4f5842":"Observation:\n* This means model shows most confidence about 1st test_image is 'Ankle boot' ('T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n* test_labels[0] also gives result as 9 (i.e. 'Ankle boot'). So, the prediction is correct. The data is one hot encoded so there is 1 at the last\n","45e4be3e":"## Predicting label","e8d2a573":"# Data Preparation","e2f07f9c":"# Evaluation of the model","68862ec5":"## Compile the model","b079d51d":"## Test for single image","f8da70cf":"Observations:\n* There are 60,000 images. We assigned 10,000 to test dataset\n* Images are black and white and is of 28 x 28 pixels\n* Train Images: Array of 60,000 images in 28 X 28 pixel\n* Train Labels: Integer array of 60,000 labels, value between 0 to 9\n* Test Images: Array of 10,000 images in 28 X 28 pixel\n* Test Labels: Integer array of 10,000 labels, value between 0 to 9\n* Each image mapped to a single label\n* Each integer value in label array represent clothing item","4a46a092":"# Conclusions\n\n* With a complex sequential model with multiple convolution layers and 20 epochs for the training, we obtained an accuracy ~0.91 for test prediction. \n* After investigating the validation accuracy and loss, we understood that the model is overfitting.\n* Model may be retrained with Dropout layers to reduce overfitting.\n* Most of the images can be identified except few.","e618b7f1":"## Test for single image","11c7f66e":"## Scaling the image values","554498a0":"# Evaluation of the data","fd7999e2":"# Loading the Dataset","9e79028f":"# Testing the model on data","87f21e26":"# Computer Vision: Image Identification \/ Classification from fashion_mnist dataset using TensorFlow\n\n**Domain:**Image Identification \/ Classification\n\n**About:**\nFashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n\nZalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\n**Problem Statement:** To predict correct label for each image given in test dataset.\n\nDescription text source: https:\/\/www.tensorflow.org\/datasets\/catalog\/fashion_mnist\n\nTo see image, visit: https:\/\/github.com\/zalandoresearch\/fashion-mnist\n\n**We will use GPU for this notebook to speed up process.**\n","bcee5746":"Observation:\n* there is a very little gap between accracy of train and test model i.e. 0.91 and 0.89 that means model is little overfitting","1a64dc02":"## Building model","f65cec10":"## Train the model","902bfccf":"Reading the summary:\n- There are 5 computational layers i.e. all the layers where param value is non-zero that is why it is called LeNet-5.\n- Params are weights and bias\n- the value 60 = 6 filters X  kernal size 9 i.e.(3 X 3) = 54 + 6 bias (equal to number of filters) = 60\n- the value 550 = 10 filters X  kernal size 9 i.e.(3 X 3) = 90 X 6 filters of earliar layer = 540 + 10 bias (equal to number of filters) = 550\n- In case of Dense layer 30120 = 250 X 120 = 30,000 + 120 bias\n- In case of Dense layer 10164 = 120 X 84 = 10080 + 84 bias","000f84ca":"## Creating a function to verify prediction is True or False","05d1c494":"## One hot encoding of the labels\n- This is NOT required in two-class classification problem\n- This is REQUIRED in multi-class classification problem\n- This is 10 class classification problem so after one hot encoding it will generate 10 columns i.e. 10 output nurons for each label","89606da4":"## Evaluating model accuracy"}}