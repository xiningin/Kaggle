{"cell_type":{"b0daceb4":"code","9f0a9133":"code","d241704b":"code","5c84be9f":"code","24dbb30c":"code","1922c7ed":"code","8bd8e683":"code","49bc69c5":"code","77d03a0c":"code","9c34e4f4":"code","7e7f043d":"code","2154ee3b":"markdown","791e7a96":"markdown","88e9a64f":"markdown","6c86ddea":"markdown","49198fe4":"markdown","f549a230":"markdown","98b78f31":"markdown","bf5c796e":"markdown","4ff21cf8":"markdown","4a8389f4":"markdown","95239554":"markdown","c7ecafca":"markdown"},"source":{"b0daceb4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom json import JSONDecoder, JSONDecodeError  # for reading the JSON data files\nimport re  # for regular expressions\nimport os  # for os related operations","9f0a9133":"print(os.listdir(\"..\/input\"))","d241704b":"def decode_obj(line, pos=0, decoder=JSONDecoder()):\n    no_white_space_regex = re.compile(r'[^\\s]')\n    while True:\n        match = no_white_space_regex.search(line, pos)\n        if not match:\n            return\n        pos = match.start()\n        try:\n            obj, pos = decoder.raw_decode(line, pos)\n        except JSONDecodeError as err:\n            print('Oops! something went wrong. Error: {}'.format(err))\n        yield obj","5c84be9f":"def get_obj_with_last_n_val(line, n):\n    obj = next(decode_obj(line))  # type:dict\n    id = obj['id']\n    class_label = obj['classNum']\n\n    data = pd.DataFrame.from_dict(obj['values'])  # type:pd.DataFrame\n    data.set_index(data.index.astype(int), inplace=True)\n    last_n_indices = np.arange(0, 60)[-n:]\n    data = data.loc[last_n_indices]\n\n    return {'id': id, 'classType': class_label, 'values': data}","24dbb30c":"def convert_json_data_to_csv(data_dir: str, file_name: str):\n    \"\"\"\n    Generates a dataframe by concatenating the last values of each\n    multi-variate time series. This method is designed as an example\n    to show how a json object can be converted into a csv file.\n    :param data_dir: the path to the data directory.\n    :param file_name: name of the file to be read, with the extension.\n    :return: the generated dataframe.\n    \"\"\"\n    fname = os.path.join(data_dir, file_name)\n\n    all_df, labels, ids = [], [], []\n    with open(fname, 'r') as infile: # Open the file for reading\n        for line in infile:  # Each 'line' is one MVTS with its single label (0 or 1).\n            obj = get_obj_with_last_n_val(line, 1)\n            all_df.append(obj['values'])\n            labels.append(obj['classType'])\n            ids.append(obj['id'])\n\n    df = pd.concat(all_df).reset_index(drop=True)\n    df = df.assign(LABEL=pd.Series(labels))\n    df = df.assign(ID=pd.Series(ids))\n    df.set_index([pd.Index(ids)])\n    # Uncomment if you want to save this as CSV\n    # df.to_csv(file_name + '_last_vals.csv', index=False)\n    return df","1922c7ed":"path_to_data = \"..\/input\"\nfile_name = \"fold3Training.json\"\n\ndf = convert_json_data_to_csv(path_to_data, file_name)  # shape: 27006 X 27\nprint('df.shape = {}'.format(df.shape))\n# print(list(df))","8bd8e683":"df = df.dropna()  # shape: 26666 X 27\nprint('df.shape = {}'.format(df.shape))","49bc69c5":"t = (2\/3) * df.shape[0]\ndf_train = df[df['ID'] <= t]  # shape: 18004 X 27\ndf_val = df[df['ID'] > t]  # shape: 9002 X 27\nprint('df_train.shape = {}'.format(df_train.shape))\nprint('df_val.shape = {}'.format(df_val.shape))","77d03a0c":"from sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score","9c34e4f4":"# Separate values and labels columns\ndf_train_data = df_train.iloc[:, :-2]  # all columns excluding 'ID' and 'LABEL'\ndf_train_labels = pd.DataFrame(df_train.LABEL)  # only 'LABEL' column\n\ndf_val_data = df_val.iloc[:, :-2]  # all columns excluding 'ID' and 'LABEL'\ndf_val_labels = pd.DataFrame(df_val.LABEL)  # only 'LABEL' column\n\n# Train a simple SVM as an example\nsvm_c = 1000\nsvm_gamma = 0.01\nclf = svm.SVC(gamma=svm_gamma, C=svm_c, max_iter=-1, verbose=1, shrinking=True, random_state=42)\nclf.fit(df_train_data, np.ravel(df_train_labels))","7e7f043d":"# Test the model against the validation set\npred_labels = clf.predict(df_val_data)\n\n# Evaluate the predictions\nscores = confusion_matrix(df_val_labels, pred_labels).ravel()\ntn, fp, fn, tp = scores\nprint('TN:{}\\tFP:{}\\tFN:{}\\tTP:{}'.format(tn, fp, fn, tp))\nf1 = f1_score(df_val_labels, pred_labels, average='binary', labels=[0, 1])\nprint('f1-score = {}'.format(f1))","2154ee3b":"* To train a simple classifier, we first need to have training and validation sets. For simplicity, let's assign the first two-third of this fold to our training set, and use the rest as a validation set.","791e7a96":"* Our model is now ready for prediction. Let's see how good it performs. (We measure its performance using f1-score).","88e9a64f":"* To be able to read the data in json format, we need to have a decoder as follows:","6c86ddea":"Input data files are available in the '..\/input\/' directory.\nAny results you write to the current directory will be saved here as output.\n\n* We can list all files in this directory:","49198fe4":"* Finally, time to train a model. Of course, we should import some packages first.","f549a230":"#### The following steps would help you get started. To **RUN THIS CODE HERE**, you need to *fork* a new branch (see the blue button on the top-right corner), and then execute each cell by pressing *Shift+Enter* or clicking on the blue botton on the left side of each cell.\n\n* Let's import a few handy toolds.","98b78f31":"* There are many ways to deal with missing values. The simplest approach would be to drop all rows which contain any missing values.","bf5c796e":"Oops! It seems that the model is not good at all! Maybe the model needs tuning! Maybe the data needs more preprocessing! Or, maybe the \"last values\", as we used in this example code, is not such a good predicator for solar flares!\n#### You can pick up from here. It's all in your hands now.","4ff21cf8":"* The above methods allow us to load the data as Pandas.DataFrame, or even save them in CSV format. Let's define a new method that does this. Note that you can uncomment the part that stores the data in CSV format if you want.","4a8389f4":"* Now we are ready to load data. We try loading 'fold3Training.json' as an example. This should result in a dataframe with 27006 rows and 27 columns (i.e., all 25 physical parameters, plus two additional columns: ID and LABEL)","95239554":"**Note** that the training phase may take a few minutes.","c7ecafca":"* As an example, let's implement a method that gets the last values of a multi-variate time series corresponding to each observation window."}}