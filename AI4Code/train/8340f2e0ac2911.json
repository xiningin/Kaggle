{"cell_type":{"eb98450a":"code","cf943cbf":"code","e30c45fa":"code","acf99c83":"code","41c2735c":"code","427fc512":"code","9d392de4":"code","51102ca1":"code","48048cff":"code","11b0e49d":"code","a090e610":"code","07a7fa9d":"code","8ecda358":"code","39d6cd61":"code","591dc7a0":"code","2cdfa17b":"code","d6a4b2f6":"code","5ad5694c":"code","a1cdb884":"code","b7c1d943":"code","5eb44c22":"markdown","2b10cdcb":"markdown","8012dfae":"markdown"},"source":{"eb98450a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf943cbf":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport numpy as np","e30c45fa":"#importing data\ndata = pd.read_json('..\/input\/myspotifydata\/StreamingHistory0.json')\ndata.head()","acf99c83":"data.shape","41c2735c":"#creating a column with the total minute played\ndata['minPlayed'] = data.msPlayed \/ 60000\ndata.drop(columns = 'msPlayed',  inplace = True)","427fc512":"#total number of minutes listened in hours\ndata.minPlayed.sum()\/60","9d392de4":"data.head()","51102ca1":"#top 15 artists\ntop10_artists = data.artistName.value_counts()[:15]\nprint(top10_artists)","48048cff":"#top 15 tracks\ntop10_tracks = data.trackName.value_counts()[:15]\nprint(top10_tracks)","11b0e49d":"#converting endTime to datetime\ndata['endTime'] = pd.to_datetime(data['endTime'])\n#creating a column for date, weekday and hour only\ndata['date'] = data['endTime'].dt.date\ndata['hour'] = data['endTime'].dt.hour\n#data['weekday'] = pd.to_datetime(data['endTime'])\ndata['weekday'] = data['endTime'].dt.weekday","a090e610":"#checking for data types\ndata.dtypes","07a7fa9d":"#taking a look at distribuition of listening in dates\nplt.figure(figsize = (8,8))\nplt.hist(data = data, x = 'date', bins = 12)\nplt.xticks(rotation = 90)\nplt.grid(True, axis = 'y')\nplt.title('Distribution of music listened in 2020')","8ecda358":"#filtering and creating another df \ndays_hours = data.filter(['hour','weekday','minPlayed'])","39d6cd61":"#checking the process\ndays_hours","591dc7a0":"#making a plot with most common listening hours\nplt.figure(figsize = (8,8))\ncol = sb.color_palette()[0]\n#order = ['0h','1h','2h','3h','4h','5h','6h','7h','8h','9h','10h','11h','12h','13h','14h','15h','16h','17h','18h','19h','20h','21h','22h','23h']\nsb.countplot(data = days_hours, x ='hour', color = col) #,  order = order)\nplt.title('Most common listening hours')\nplt.ylabel('Number of streams')\nplt.xlabel('Hour')\nplt.xticks(rotation = 90);","2cdfa17b":"#making a plot with the most commom listening days\nplt.figure(figsize = (8,8))\ncol = sb.color_palette()[0]\n#order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nday_short_names = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\nsb.countplot(data = days_hours, x ='weekday', color = col) #order = order)\nplt.xticks([0,1,2,3,4,5,6], day_short_names);\nplt.title('Most common listening days')\nplt.ylabel('Number of streams')\nplt.xlabel('Weekday');","d6a4b2f6":"data['date']= pd.to_datetime(data['date'])","5ad5694c":"#pivoting the df and creating another one. We'll use wekkday and hour as index, because this is what\n#we want to display in the heatmap\ndata_df = pd.pivot_table(data[['hour','weekday','minPlayed']], index = ['weekday','hour'], aggfunc = 'count')","a1cdb884":"#unstacking the data, and filling the NaN values with 0\ndata_df2 = data_df.unstack(level = 0)\ndata_df3 = data_df2.fillna(0)\ndata_df3","b7c1d943":"#plotting the heatmap with most listening hours and days\nday_short_names = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\nplt.figure(figsize = (20,15))\nsb.heatmap(data = data_df3, annot = True, cmap = 'BuGn', fmt = '000', xticklabels=day_short_names)\nplt.title('Days and Hours with most listening to Spotify', fontsize = 25)\nplt.xlabel('')\nplt.ylabel('Hours - 24h format');","5eb44c22":"- The day I listened the most was Wednesday\n- My moments of most listening were during the night\n- The most frequent time of listening is between 12h to 22h.","2b10cdcb":"## What we'll look into?\n\n- Analysis\n    - what part of the day I listen the most?\n    - What part of the year I listened the most?\n    - The top artists\n    - The top tracks\n","8012dfae":"### Sources\n\n[Heatmap](https:\/\/dfrieds.com\/data-visualizations\/when-use-heatmaps.html)\n\n[Seaborn Documentation](https:\/\/seaborn.pydata.org\/api.html)\n\n[Changing xticks label](https:\/\/www.kite.com\/python\/answers\/how-to-set-tick-labels-with-matplotlib-in-python)\n\n[Matplotlib Documentation](https:\/\/matplotlib.org\/3.3.3\/index.html)\n\n[Pandas Documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/index.html)\n\n[Color Palette](https:\/\/chrisalbon.com\/python\/data_visualization\/seaborn_color_palettes\/)"}}