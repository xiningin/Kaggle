{"cell_type":{"2001d4e8":"code","3e22b111":"code","9b1cd72c":"code","e095dd4a":"code","666260c4":"code","89019372":"code","a6b50eae":"code","0e353539":"code","16781dec":"code","69bd92af":"code","7584c3b0":"markdown","2d83f95b":"markdown","019d6738":"markdown","ee64373f":"markdown","f58dc6e4":"markdown","56d32fd9":"markdown","44423f0a":"markdown","f7b51551":"markdown","809e4b66":"markdown"},"source":{"2001d4e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3e22b111":"df_train = pd.read_csv('..\/input\/porto-seguro-safe-driver-prediction\/train.csv')\n\ntarget_count = df_train.target.value_counts()\nprint('Class 0:', target_count[0])\nprint('Class 1:', target_count[1])\nprint('Proportion:', round(target_count[0] \/ target_count[1], 2), ': 1')\n\ntarget_count.plot(kind='bar', title='Count (target)');","9b1cd72c":"df_train.head()","e095dd4a":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Remove 'id' and 'target' columns\nlabels = df_train.columns[2:]\n\nX = df_train[labels]\ny = df_train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n                                                    random_state=42, stratify=y)\n\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","666260c4":"model = XGBClassifier()\nmodel.fit(X_train[['ps_calc_01']], y_train)\ny_pred = model.predict(X_test[['ps_calc_01']])\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","89019372":"from sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\n\nconf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\nprint('Confusion matrix:\\n', conf_mat)\n\nlabels = ['Class 0', 'Class 1']\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","a6b50eae":"# Fun\u00e7\u00e3o para devolver a contagem de amostras na classe 0 e na classe 1\nlen_class_0, len_class_1 = df_train.target.value_counts()\n\n# devidir o df por classe\ndf_class_0 = df_train[df_train['target'] == 0] \ndf_class_1 = df_train[df_train['target'] == 1]","0e353539":"df_class_0_under = df_class_0.sample(len_class_1)\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Random under-sampling:')\nprint(df_test_under.target.value_counts())\n\ndf_test_under.target.value_counts().plot(kind='bar', title='Count (target)')\nplt.show()","16781dec":"# separando X e y do df_test_under\nlabels = df_train.columns[2:]\nX_tun = df_test_under[labels]\ny_tun = df_test_under['target']","69bd92af":"model = XGBClassifier()\nmodel.fit(X_tun, y_tun)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","7584c3b0":"N\u00e3o \u00e9 o nosso caso! Assim como no exemplo de fraudes, o modelo n\u00e3o previu nenhuma observa\u00e7\u00e3o como \"Classe 1\"","2d83f95b":"**<h2 id=\"t2\" style=\"margin-bottom: 18px\">Paradoxo da Acu\u00e1cia<\/h2>**\n\nUm dos maiores erros que data scientists inexperientes cometem quando lidam com datasets desbalanceados \u00e9 confiar em uma m\u00e9trica simples como <code>accuracy_score<\/code> Apesar de um score elevado nessa m\u00e9trica, vamos provar como ela pode ser enganosa.\n","019d6738":"<h2 id=\"t3\" style=\"margin-bottom: 18px\">Matriz de Confus\u00e3o<\/h2>\n\nUma forma interessante de avaliar os resultados \u00e9 atrav\u00e9s da matriz de confus\u00e3o que mostra os valores preditos e esperados ou reais.  \nNa primeira linha, a primeira coluna indica quantos \"Classe 0\" foram preditos corretamente (como \"Classe 0\") \nNa primeira linha, segunda coluna os erroneamente classificados como \"Classe 1\".\nNa segunda linha, a primeira coluna nos mostra quantos \"Classe 1\" foram preditos erroneamente (como \"Classe 0\") \nNa segunda linha, e segunda coluna os corretamente classificados como \"Classe1\"\n\nA diagonal descendente nos mostra as predi\u00e7\u00f5es corretas. Modelos que acertam mais possuem concentra\u00e7\u00e3o de valores maiores na primeira linha, primeira coluna e na segunda linha, segunda coluna.","ee64373f":"### Vamos piorar o nosso modelo\nSe esse modelo estiver certo com uma acur\u00e1cia de 96%, podemos pior\u00e1-lo ao treinar e testar com apenas uma feature ","f58dc6e4":"## Vamos olhar para o comportamento dos dados","56d32fd9":"**Vamos testar modelar e testar**","44423f0a":"<h1 id=\"t5\">Resampling<\/h1>","f7b51551":">> n\u00e3o nos fala muito, mas a temos um id na primiera coluna que podemos dropar e o target que precisamos dropar das features","809e4b66":"<h2 id=\"t5\">Random undersampling<\/h2>"}}