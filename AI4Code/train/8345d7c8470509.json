{"cell_type":{"bc1f7e52":"code","37b8b54e":"code","bd7960ca":"code","87f45b9c":"code","86caab34":"code","92d5cb8e":"code","b1199590":"code","d9844ffa":"code","05d97440":"markdown","53178d96":"markdown","efee594f":"markdown","c7f0cd03":"markdown","31e10987":"markdown"},"source":{"bc1f7e52":"import os\nimport glob\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm, trange\n\ntf.version.VERSION","37b8b54e":"train_files = sorted(glob.glob('\/kaggle\/input\/**\/train-*-of-01024', recursive=True))\nvalid_files = sorted(glob.glob('\/kaggle\/input\/imagenet*\/validation\/*'))\ndict(valid=dict(count=len(valid_files), first_file=valid_files[0], last_file=valid_files[-1]),\n     train=dict(count=len(train_files), first_file=train_files[0], last_file=train_files[-1]))","bd7960ca":"sample = next(iter(tf.data.TFRecordDataset(valid_files[0]).take(1)))\ntf.train.Example.FromString(sample.numpy())","87f45b9c":"image_shape = (224, 224)\n\ndef decode(serialized_example):\n    features = tf.io.parse_single_example(\n        serialized_example,\n        features={\n            'image\/encoded': tf.io.FixedLenFeature([], tf.string),\n            'image\/class\/label': tf.io.FixedLenFeature([], tf.int64),\n        })\n    image = tf.image.decode_jpeg(features['image\/encoded'], channels=3)\n    image = tf.image.resize_with_pad(image, *image_shape)  # crop\/augment instead\n    label = tf.cast(features['image\/class\/label'], tf.int64) - 1  # [0-999]\n    return image, label","86caab34":"def create_ds(tfrecords, batch_size=8):\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=tf.data.AUTOTUNE)\n    dataset = dataset.map(decode, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset","92d5cb8e":"dataset = create_ds(valid_files)\n\nfor images, labels in dataset.take(1):\n    print('Image shape:', images.shape, 'Labels:', labels.numpy())\n\nconcat = np.concatenate(list(images), axis=1)\n\nplt.figure(figsize=(20, 3), dpi=80)\nplt.imshow(concat.astype(int))\nplt.axis('off')\nplt.show()","b1199590":"valid_ds = create_ds(valid_files, batch_size=100)\nn = 0\n\nfor images, labels in tqdm(valid_ds):\n    n += len(images)\n\nprint(n, 'validation images')","d9844ffa":"train_ds = create_ds(train_files, batch_size=100)\nn = 0\n\nfor images, labels in tqdm(train_ds):\n    n += len(images)\n\nprint(n, 'training images')","05d97440":"# Time Validation Set Decoding","53178d96":"# List TFrecord files","efee594f":"# Sample TFrecord\nSerialized with [Protocol Buffers](https:\/\/developers.google.com\/protocol-buffers)\n<br>\nImage encoded as JPEG","c7f0cd03":"# Decode with TensorFlow","31e10987":"# Time Training Set Decoding"}}