{"cell_type":{"057048ec":"code","c09b6a03":"code","3124e619":"code","81f36d7d":"code","6c0b668d":"code","4b956a07":"code","e755e873":"code","9fa2d2f5":"code","4e040229":"code","622e3dc8":"code","662b3cb9":"code","6554ed4d":"code","2c0e5571":"code","dc2d2e51":"code","6a110a07":"code","b905dfe7":"code","eeaaed5f":"code","204245dd":"code","96bf3340":"code","6356ff8c":"code","d689ddcc":"code","89ce6fe6":"code","9fc40f72":"code","53b50433":"code","ed1bb3ff":"code","803a92c5":"code","eb926922":"code","80a63743":"code","91c637e4":"code","6fd632b6":"code","604b3fb7":"code","0a823a8c":"code","61383cc0":"code","693540ef":"code","66a2bec1":"code","7da71f7a":"code","1a518754":"code","c81c1112":"markdown","e373ef9d":"markdown","6d717fd5":"markdown","dd7eae69":"markdown","4a50c395":"markdown","c4644445":"markdown","fa35b094":"markdown","3245d9ed":"markdown","c3d8308b":"markdown","12970951":"markdown","c3790538":"markdown","ff2a19d6":"markdown","595dc61d":"markdown","ff20c32c":"markdown","cdc31c2b":"markdown","1cd786e4":"markdown","c2fbcd99":"markdown","4109d9e1":"markdown","8f301cbf":"markdown","96fa399d":"markdown","71400017":"markdown","088376c0":"markdown"},"source":{"057048ec":"import pandas as pd\nimport numpy as np\nimport cv2\nimport seaborn as sns\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom textwrap import wrap\nimport pytesseract\nimport re,string\nfrom wordcloud import WordCloud, STOPWORDS\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')","c09b6a03":"path = '..\/input\/shopee-product-matching'\ntrain_path = '..\/input\/shopee-product-matching\/train_images'\ntest_path = '..\/input\/shopee-product-matching\/test_images'","3124e619":"data = pd.read_csv(path+'\/'+'train.csv')\ndata.head()","81f36d7d":"print(f\"The Shape of the train data : {data.shape}\")\nprint(f\"Duplicate Rows : {data.shape[0] - len(data['posting_id'].unique())}\")","6c0b668d":"print(\"Number unique label_groups = {}\".format( len(data[\"label_group\"].unique()) ))","4b956a07":"num_label_groups = {}\nfor i in data['label_group']:\n    num_label_groups[i] = data[data['label_group'] == i]\n","e755e873":"len_label_groups = {}\nfor i in num_label_groups:\n    len_label_groups[i] = len(num_label_groups[i])\n\nprint(f\"Max of all the label groups : {max(len_label_groups.values())}\")\nprint(f\"Min of all the label groups : {min(len_label_groups.values())}\")","9fa2d2f5":"label_names = list(num_label_groups.keys())\nnum_label_groups[label_names[5]]","4e040229":"def visualize_sim_products(label_id):\n    sns.set_style(\"whitegrid\")\n    plt.rcParams['font.size'] = '28'\n    plt.figure(figsize=(50,50))\n    length = len_label_groups[label_id]\n    if length > 10:\n        length = 10\n    for i in range(length):\n        img = plt.imread(train_path + '\/' + num_label_groups[label_id]['image'].iloc[i])\n        plt.subplot(length,2,i+1)\n        plt.imshow(img)\n        plt.title(\"\\n\".join(wrap(num_label_groups[label_id]['title'].iloc[i],60)))\n        plt.axis('off')\n    plt.show()","622e3dc8":"visualize_sim_products(label_names[14])","662b3cb9":"num_label_groups[label_names[17]]['image_phash']","6554ed4d":"def hamming(s1, s2):\n    return float(sum(c1 != c2 for c1, c2 in zip(s1, s2))) \/ float(len(s1))\nhamming('bf38f0e08397c712','bf38f0e083d7c710')","2c0e5571":"copies = {}\nfor i in data['image_phash']:\n    copies[i] = data[data['image_phash'] == i]\nphash_list = list(copies.keys())\n\ncopies[phash_list[14]]","dc2d2e51":"copies_len = {}\nfor i in copies.keys():\n    copies_len[i] = len(copies[i])","6a110a07":"copies_len = pd.DataFrame({'phash':copies_len.keys(),'count':copies_len.values()})\n# copies_len.reset_index(inplace=True)\ncopies_len.head()","b905dfe7":"copies_len.sort_values(by='count',ascending = False, inplace = True)","eeaaed5f":"fig = plt.figure(figsize=(70,50))\nsns.barplot(x = copies_len.iloc[:10]['phash'],y=copies_len.iloc[:10]['count'])\nplt.show()","204245dd":"def visualize_sim_phashes(phash):\n    sns.set_style(\"whitegrid\")\n    plt.rcParams['font.size'] = '28'\n    plt.figure(figsize=(50,50))\n    length = len(copies[phash])\n    if length > 10:\n        length = 10\n    for i in range(length):\n        img = plt.imread(train_path + '\/' + copies[phash]['image'].iloc[i])\n        plt.subplot(length,2,i+1)\n        plt.imshow(img)\n        plt.title(\"\\n\".join(wrap(copies[phash]['title'].iloc[i],60)))\n        plt.axis('off')\n    plt.show()","96bf3340":"visualize_sim_phashes(phash_list[14])","6356ff8c":"title_text = data['title'].values","d689ddcc":"def clean(title):\n    stop = stopwords.words('english')\n    title = [x for x in title.split() if not x in stop]\n    title = \" \".join(title)\n    title = title.lower()\n    title = re.sub(r\"\\-\",\"\",title)\n    title = re.sub(r\"\\+\",\"\",title)\n    title = re.sub (r\"&\",\"and\",title)\n    title = re.sub(r\"\\|\",\"\",title)\n    title = re.sub(r\"\\\\\",\"\",title)\n    title = re.sub(r\"\\W\",\" \",title)\n    for p in string.punctuation :\n        title = re.sub(r\"f{p}\",\"\",title)\n    \n    title = re.sub(r\"\\s+\",\" \",title)\n    \n    return title","89ce6fe6":"data.head()","9fc40f72":"stopwords_wc = set(STOPWORDS) \ntoken_text = ''\n\nfor i in tqdm(title_text):\n    token_l = i.split()\n    token_text += \" \".join(token_l) + \" \" ","53b50433":"wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords_wc, \n                min_font_size = 10).generate(token_text)\n\nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","ed1bb3ff":"# Use this for OCR extraction\n# ocr_text = []\n# for i in tqdm(range(data.shape[0])):\n#     img = cv2.imread(train_path + '\/' + data['image'].iloc[i])\n#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#     text = pytesseract.image_to_string(img)\n#     text = \" \".join(text.split())\n#     if len(text) != 0:\n#         ocr_text.append(text)\n#     else:\n#         ocr_text.append('Nothing Found')\n\n# data['ocr_text'] = ocr_text","803a92c5":"# data.to_csv('cleaned_and _raw_ocr.csv')\ndata = pd.read_csv('..\/input\/cleaned-shopee-data-with-ocr\/cleaned_title_and_ocr.csv')\n# Cleaning titles and ocr text again for stopwords, which I missed before\ndata.drop(['cleaned_title','cleaned_ocr_text'],axis=1,inplace=True)\ndata['cleaned_title'] = data['title'].map(clean)","eb926922":"data['cleaned_ocr_text'] = data['ocr_text'].map(clean)\ndata.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1,inplace=True)\ndata.to_csv('cleaned_title_and_ocr_sw.csv')","80a63743":"data.head()","91c637e4":"title_text = data['cleaned_ocr_text'].values\nstopwords_wc = list(STOPWORDS)\ntoken_text = ''\n\nfor i in tqdm(title_text):\n    if i.strip() != 'Nothing Found'.lower():\n        token_l = i.split()\n        token_text += \" \".join(token_l) + \" \"\n\nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords_wc, \n                min_font_size = 10,contour_color='steelblue').generate(token_text)\n\nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud,interpolation='bilinear') \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()     ","6fd632b6":"plt.figure(figsize = (10, 6))\nsns.set_style(\"whitegrid\")\nsns.kdeplot(data['cleaned_title'].apply(lambda x: len(x)),fill = True,edgecolor='black',alpha=0.9)\nplt.xlabel('Title Text Length')\nplt.show()","604b3fb7":"plt.figure(figsize = (10, 6))\nsns.set_style(\"whitegrid\")\nsns.kdeplot(data['cleaned_title'].apply(lambda x: len(x.split())),fill = True,edgecolor='black',alpha=0.9,color='cyan')\nplt.xlabel('Title Text Tokens Count')\nplt.show()","0a823a8c":"plt.figure(figsize = (10, 6))\nsns.set_style(\"whitegrid\")\nsns.kdeplot(data['cleaned_ocr_text'].apply(lambda x: len(x)),fill = True,color = 'red',edgecolor='black',alpha=0.9)\nplt.xlabel('OCR Text Length')\nplt.show()","61383cc0":"plt.figure(figsize = (10, 6))\nsns.set_style(\"whitegrid\")\nsns.kdeplot(data['cleaned_ocr_text'].apply(lambda x: len(x.split())),fill = True,color = 'maroon',edgecolor='black',alpha=0.9)\nplt.xlabel('OCR Text Tokens Count')\nplt.show()","693540ef":"image_shapes_h = []\nimage_shapes_w = []\nimage_shapes_c = []\nfor i in tqdm(range(data.shape[0])):\n    img = cv2.imread(train_path + '\/' + data['image'].iloc[i])\n    h, w, c = img.shape\n    image_shapes_h.append(h)\n    image_shapes_w.append(w)\n    image_shapes_c.append(c)","66a2bec1":"dump(image_shapes_h,'heights.pkl')\ndump(image_shapes_w,'widths.pkl')\ndump(image_shapes_c,'channels.pkl')\n\nimage_shapes_h = load('heights.pkl')\nimage_shapes_w = load('widths.pkl')\nimage_shapes_c = load('channels.pkl')","7da71f7a":"set(image_shapes_c)","1a518754":"sns.set_style(\"white\")\nsns.axes_style('whitegrid')\nh = sns.JointGrid(x =  image_shapes_h,y = image_shapes_w,height=8)\nh.plot_joint(sns.scatterplot)\nh.plot_marginals(sns.histplot, kde=True)\nplt.show()","c81c1112":"## Insights to the Data (Compilation)\n\n+ There are a total of 34250 products in the database which are unique, that means there are no duplicate rows.\n+ There are 11014 label_groups provided in the dataset.\n+ Max of all the label groups : 51\n+ Min of all the label groups : 2\n+ Perceptual hash of all the images in a label group are not the same, but there are some identical images with different titles.\n+ Phash hamming distance might be a good feature in the future to use.\n+ We can refer the respective wordclouds to get an idea of frequenty used words in the title and ocr text.\n+ The OCR text might be a good feature for the model.\n+ Title text length  seem to be less than 90 characters for most of the data.\n+ Title text tokens count seems to be less than 20 words for most of the data.\n+ Similarly OCR text length also seems to be less than 90-100 characters.\n+ The count of OCR text tokens seem to be less than 18-20 tokens (most of these tokens are garbled noise from bad OCR)\n+ All images are 3-channeled RGB images, there are no B&W or gray images in the dataset. The jointplot can be refered to get and idea of images heights and widths distribution.","e373ef9d":"## WordClouds","6d717fd5":"**There aren't any B&W\/Gray images**","dd7eae69":" **Seems like my hypotheses was wrong.** \n\nBut we can use the hamming distance between these phashes as a feature (Feature Engineering), that will be for another notebook though. \n\nSeems like exact same images have same pHash.","4a50c395":"### Let's find out how many same exact images are there","c4644445":"# Shopee Product Matching EDA and Cleaning\n### Import Required Libraries","fa35b094":"### WordCloud For the OCR data","3245d9ed":"### Perceptual Hashing\n\nIn this challenge perpetual hashing is provided, so I read up on it, According to wikipedia : \n> Perceptual hashing is the use of an algorithm that produces a snippet or fingerprint of various forms of multimedia.[1][2] Perceptual hash functions are analogous if features of the multimedia are similar, whereas cryptographic hashing relies on the avalanche effect of a small change in input value creating a drastic change in output value. Perceptual hash functions are widely used in finding cases of online copyright infringement as well as in digital forensics because of the ability to have a correlation between hashes so similar data can be found (for instance with a differing watermark).\n\n*So maybe similar objects have similar Perceptual hash values.* \nThis is my hypothesis, let's check if this is true.","c3d8308b":"### Basic Details about the data","12970951":"**Here one label group indicates similar products, i.e: all products with same label_id are similar**","c3790538":"### Distribution of OCR text lengths","ff2a19d6":"**Let's have a look at the data head**","595dc61d":"## Let's have a look at title and OCR text as well\n\n### Distribution of Title text Lengths","ff20c32c":"### Distribution of OCR text tokens count","cdc31c2b":"## Image shapes EDA","1cd786e4":"### Let's view some exact copies","c2fbcd99":"### Top 10 duplicate images' phashes","4109d9e1":"**Let's Extract everything we can from the images, maybe used as a feature in the future**","8f301cbf":"### WordCloud for Title Text","96fa399d":"**Let's Visualize some Similar products**\n\nThis Function allows you to input label_id and view top 10 (or less where applicable) similar products.","71400017":"# NLP Based EDA","088376c0":"### Distribution of Title text Tokens Count"}}