{"cell_type":{"74e56ed1":"code","da1f7ea9":"code","2ea7ffb3":"code","4e32cf67":"code","412605f7":"code","deea838f":"code","9e68f36f":"code","751deccf":"code","6b2d5dfd":"code","e269d967":"code","de56cc33":"code","983cae3a":"code","94996dbe":"code","5b24e4ed":"code","b1869b89":"code","fad97d52":"code","40149df1":"code","a552d79a":"code","738763b3":"code","6882928b":"code","7a148598":"code","6f318014":"code","3260fc15":"code","9216357a":"code","f99cf3dc":"code","1acefbd1":"code","95abbff2":"code","af75d5ed":"code","c145d69b":"code","a4c37c74":"code","f80d2a1c":"code","b1615ee7":"code","2f20dd35":"code","cc729303":"code","d226ba9d":"code","f2be7ec2":"code","694c950c":"code","aa5b5476":"code","2aed80a7":"code","415c7e96":"code","71b9f1ca":"code","614cd7ad":"code","3bbc407d":"code","bb0275a8":"code","781b32b0":"code","20bdfafb":"code","9cc4152b":"code","23b8a986":"code","c43f429e":"code","a537399a":"code","45097ce2":"code","5550d2b2":"code","cf0d273f":"code","6ecf2326":"code","06faed89":"code","0ee53b2f":"code","ab4096f2":"code","f61573e9":"code","054697c6":"code","bf9fd880":"code","e5b8bd75":"code","2e952ad6":"markdown","3800f201":"markdown","bf4c4a00":"markdown","8b9c328a":"markdown","1184471e":"markdown","53e0d4d6":"markdown","0b95e97a":"markdown","eef6d3a3":"markdown","f68f6e8d":"markdown","68c965fb":"markdown","0bf79b35":"markdown","2007d7f0":"markdown","e2d928dc":"markdown","f617d99f":"markdown","3f080fb0":"markdown","99917595":"markdown","baf32f83":"markdown","80a0516d":"markdown","cc38e100":"markdown"},"source":{"74e56ed1":"\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","da1f7ea9":"urldata = pd.read_csv(\"..\/input\/urldata.csv\")","2ea7ffb3":"urldata.head()","4e32cf67":"#Removing the unnamed columns as it is not necesary.\nurldata = urldata.drop('Unnamed: 0',axis=1)","412605f7":"urldata.head()","deea838f":"urldata.shape","9e68f36f":"urldata.info()","751deccf":"urldata.isnull().sum()","6b2d5dfd":"!pip install tld","e269d967":"#Importing dependencies\nfrom urllib.parse import urlparse\nfrom tld import get_tld\nimport os.path","de56cc33":"#Length of URL\nurldata['url_length'] = urldata['url'].apply(lambda i: len(str(i)))","983cae3a":"#Hostname Length\nurldata['hostname_length'] = urldata['url'].apply(lambda i: len(urlparse(i).netloc))","94996dbe":"#Path Length\nurldata['path_length'] = urldata['url'].apply(lambda i: len(urlparse(i).path))","5b24e4ed":"#First Directory Length\ndef fd_length(url):\n    urlpath= urlparse(url).path\n    try:\n        return len(urlpath.split('\/')[1])\n    except:\n        return 0\n\nurldata['fd_length'] = urldata['url'].apply(lambda i: fd_length(i))","b1869b89":"#Length of Top Level Domain\nurldata['tld'] = urldata['url'].apply(lambda i: get_tld(i,fail_silently=True))\ndef tld_length(tld):\n    try:\n        return len(tld)\n    except:\n        return -1\n\nurldata['tld_length'] = urldata['tld'].apply(lambda i: tld_length(i))","fad97d52":"urldata.head()","40149df1":"urldata = urldata.drop(\"tld\",1)","a552d79a":"urldata.head()","738763b3":"urldata['count-'] = urldata['url'].apply(lambda i: i.count('-'))","6882928b":"urldata['count@'] = urldata['url'].apply(lambda i: i.count('@'))","7a148598":"urldata['count?'] = urldata['url'].apply(lambda i: i.count('?'))","6f318014":"urldata['count%'] = urldata['url'].apply(lambda i: i.count('%'))","3260fc15":"urldata['count.'] = urldata['url'].apply(lambda i: i.count('.'))","9216357a":"urldata['count='] = urldata['url'].apply(lambda i: i.count('='))","f99cf3dc":"urldata['count-http'] = urldata['url'].apply(lambda i : i.count('http'))","1acefbd1":"urldata['count-https'] = urldata['url'].apply(lambda i : i.count('https'))","95abbff2":"urldata['count-www'] = urldata['url'].apply(lambda i: i.count('www'))","af75d5ed":"def digit_count(url):\n    digits = 0\n    for i in url:\n        if i.isnumeric():\n            digits = digits + 1\n    return digits\nurldata['count-digits']= urldata['url'].apply(lambda i: digit_count(i))","c145d69b":"def letter_count(url):\n    letters = 0\n    for i in url:\n        if i.isalpha():\n            letters = letters + 1\n    return letters\nurldata['count-letters']= urldata['url'].apply(lambda i: letter_count(i))","a4c37c74":"def no_of_dir(url):\n    urldir = urlparse(url).path\n    return urldir.count('\/')\nurldata['count_dir'] = urldata['url'].apply(lambda i: no_of_dir(i))","f80d2a1c":"urldata.head()","b1615ee7":"import re","2f20dd35":"#Use of IP or not in domain\ndef having_ip_address(url):\n    match = re.search(\n        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\\/)|'  # IPv4\n        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\\/)' # IPv4 in hexadecimal\n        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n    if match:\n        # print match.group()\n        return -1\n    else:\n        # print 'No matching pattern found'\n        return 1\nurldata['use_of_ip'] = urldata['url'].apply(lambda i: having_ip_address(i))","cc729303":"def shortening_service(url):\n    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n                      'tr\\.im|link\\.zip\\.net',\n                      url)\n    if match:\n        return -1\n    else:\n        return 1\nurldata['short_url'] = urldata['url'].apply(lambda i: shortening_service(i))","d226ba9d":"urldata.head()","f2be7ec2":"#Heatmap\ncorrmat = urldata.corr()\nf, ax = plt.subplots(figsize=(25,19))\nsns.heatmap(corrmat, square=True, annot = True, annot_kws={'size':10})","694c950c":"plt.figure(figsize=(15,5))\nsns.countplot(x='label',data=urldata)\nplt.title(\"Count Of URLs\",fontsize=20)\nplt.xlabel(\"Type Of URLs\",fontsize=18)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","aa5b5476":"print(\"Percent Of Malicious URLs:{:.2f} %\".format(len(urldata[urldata['label']=='malicious'])\/len(urldata['label'])*100))\nprint(\"Percent Of Benign URLs:{:.2f} %\".format(len(urldata[urldata['label']=='benign'])\/len(urldata['label'])*100))","2aed80a7":"plt.figure(figsize=(20,5))\nplt.hist(urldata['url_length'],bins=50,color='LightBlue')\nplt.title(\"URL-Length\",fontsize=20)\nplt.xlabel(\"Url-Length\",fontsize=18)\nplt.ylabel(\"Number Of Urls\",fontsize=18)\nplt.ylim(0,1000)\n","415c7e96":"plt.figure(figsize=(20,5))\nplt.hist(urldata['hostname_length'],bins=50,color='Lightgreen')\nplt.title(\"Hostname-Length\",fontsize=20)\nplt.xlabel(\"Length Of Hostname\",fontsize=18)\nplt.ylabel(\"Number Of Urls\",fontsize=18)\nplt.ylim(0,1000)","71b9f1ca":"plt.figure(figsize=(20,5))\nplt.hist(urldata['tld_length'],bins=50,color='Lightgreen')\nplt.title(\"TLD-Length\",fontsize=20)\nplt.xlabel(\"Length Of TLD\",fontsize=18)\nplt.ylabel(\"Number Of Urls\",fontsize=18)\nplt.ylim(0,1000)","614cd7ad":"plt.figure(figsize=(15,5))\nplt.title(\"Number Of Directories In Url\",fontsize=20)\nsns.countplot(x='count_dir',data=urldata)\nplt.xlabel(\"Number Of Directories\",fontsize=18)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","3bbc407d":"plt.figure(figsize=(15,5))\nplt.title(\"Number Of Directories In Url\",fontsize=20)\nsns.countplot(x='count_dir',data=urldata,hue='label')\nplt.xlabel(\"Number Of Directories\",fontsize=18)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","bb0275a8":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of IP In Url\",fontsize=20)\nplt.xlabel(\"Use Of IP\",fontsize=18)\n\nsns.countplot(urldata['use_of_ip'])\nplt.ylabel(\"Number of URLs\",fontsize=18)","781b32b0":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of IP In Url\",fontsize=20)\nplt.xlabel(\"Use Of IP\",fontsize=18)\nplt.ylabel(\"Number of URLs\",fontsize=18)\nsns.countplot(urldata['use_of_ip'],hue='label',data=urldata)\nplt.ylabel(\"Number of URLs\",fontsize=18)","20bdfafb":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of http In Url\",fontsize=20)\nplt.xlabel(\"Use Of IP\",fontsize=18)\nplt.ylim((0,1000))\nsns.countplot(urldata['count-http'])\nplt.ylabel(\"Number of URLs\",fontsize=18)","9cc4152b":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of http In Url\",fontsize=20)\nplt.xlabel(\"Count Of http\",fontsize=18)\nplt.ylabel(\"Number of URLs\",fontsize=18)\nplt.ylim((0,1000))\nsns.countplot(urldata['count-http'],hue='label',data=urldata)\nplt.ylabel(\"Number of URLs\",fontsize=18)","23b8a986":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of http In Url\",fontsize=20)\nplt.xlabel(\"Count Of http\",fontsize=18)\n\nsns.countplot(urldata['count-http'],hue='label',data=urldata)\n\nplt.ylabel(\"Number of URLs\",fontsize=18)","c43f429e":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of WWW In URL\",fontsize=20)\nplt.xlabel(\"Count Of WWW\",fontsize=18)\nsns.countplot(urldata['count-www'])\nplt.ylim(0,1000)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","a537399a":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of WWW In URL\",fontsize=20)\nplt.xlabel(\"Count Of WWW\",fontsize=18)\n\nsns.countplot(urldata['count-www'],hue='label',data=urldata)\nplt.ylim(0,1000)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","45097ce2":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\n","5550d2b2":"#Predictor Variables\nx = urldata[['hostname_length',\n       'path_length', 'fd_length', 'tld_length', 'count-', 'count@', 'count?',\n       'count%', 'count.', 'count=', 'count-http','count-https', 'count-www', 'count-digits',\n       'count-letters', 'count_dir', 'use_of_ip']]\n\n#Target Variable\ny = urldata['result']","cf0d273f":"x.shape","6ecf2326":"y.shape","06faed89":"#Splitting the data into Training and Testing\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.3, random_state=42)","0ee53b2f":"#Decision Tree\ndt_model = DecisionTreeClassifier()\ndt_model.fit(x_train,y_train)\n\ndt_predictions = dt_model.predict(x_test)\naccuracy_score(y_test,dt_predictions)\n","ab4096f2":"print(confusion_matrix(y_test,dt_predictions))","f61573e9":"#Random Forest\nrfc = RandomForestClassifier()\nrfc.fit(x_train, y_train)\n\nrfc_predictions = rfc.predict(x_test)\naccuracy_score(y_test, rfc_predictions)","054697c6":"print(confusion_matrix(y_test,rfc_predictions))","bf9fd880":"#Logistic Regression\nlog_model = LogisticRegression()\nlog_model.fit(x_train,y_train)\n\nlog_predictions = log_model.predict(x_test)\naccuracy_score(y_test,log_predictions)","e5b8bd75":"print(confusion_matrix(y_test,log_predictions))","2e952ad6":"## 1. DATA PREPROCESSING","3800f201":"### 1.2 Count Features","bf4c4a00":"The data shows a class imbalance to some extent.","8b9c328a":"# Detecting Maclicious URLs using Machine Learning<br>\nThe malicious urls can be detected using the lexical features along with tokenization of the url strings. I aim to build a basic binary classifier which would help classify the URLs as malicious or benign.","1184471e":"### 1.1 Length Features","53e0d4d6":"Dataset after extracting length features","0b95e97a":"No missing values in any column.","eef6d3a3":"Checking Missing Values","f68f6e8d":"Steps followed in building the machine learning classifier<br>\n1. Data Preprocessing \/ Feature Engineering\n2. Data Visualization\n3. Building Machine Learning Models using Lexical Features.\n4. Building Machine Learning Models using Lexical Features and Tokenization. (Will Update this part)","68c965fb":"## 3. Building Models Using Lexical Features Only","0bf79b35":"# 2. Data Visualization","2007d7f0":"Overall all the models showed great results with decent accuracy and low error rate.<br>\nThe high accuracy can be due to the class imbalance situation which is not fixed yet.","e2d928dc":"Data after extracting Binary Features","f617d99f":"Further Improvements<br>\n1. Analyse the code and tags used in the webpages.\n2. Reduce the class imbalance problem.","3f080fb0":"I will be using three models for my classification.\n<br>1. Logistic Regression\n<br>2. Decision Trees\n<br>3. Random Forest","99917595":"Data after extracting Count Features","baf32f83":"The following features will be extracted from the URL for classification. <br>\n<ol>\n    <li>Length Features\n    <ul>\n        <li>Length Of Url<\/li>\n        <li>Length of Hostname<\/li>\n        <li>Length Of Path<\/li>\n        <li>Length Of First Directory<\/li>\n        <li>Length Of Top Level Domain<\/li>\n    <\/ul>\n    <\/li>\n    <br>\n   <li>Count Features\n    <ul>\n    <li>Count Of  '-'<\/li>\n    <li>Count Of '@'<\/li>\n    <li>Count Of '?'<\/li>\n    <li>Count Of '%'<\/li>\n    <li>Count Of '.'<\/li>\n    <li>Count Of '='<\/li>\n    <li>Count Of 'http'<\/li>\n    <li>Count Of 'www'<\/li>\n    <li>Count Of Digits<\/li>\n    <li>Count Of Letters<\/li>\n    <li>Count Of Number Of Directories<\/li>\n    <\/ul>\n    <\/li>\n    <br>\n    <li>Binary Features\n    <ul>\n        <li>Use of IP or not<\/li>\n        <li>Use of Shortening URL or not<\/li>\n    <\/ul>\n    <\/li>\n    \n<\/ol>\n\nApart from the lexical features, we will use TFID - Term Frequency Inverse Document as well.","80a0516d":"Importing The Dependencies","cc38e100":"### 1.3 Binary Features"}}