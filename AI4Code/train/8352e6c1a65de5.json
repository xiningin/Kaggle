{"cell_type":{"db340190":"code","fbbcdfdd":"code","372134a1":"code","bff50301":"code","9e847242":"code","eba9953f":"code","fad70468":"code","180f564c":"code","3d9c9d7b":"code","b079d551":"code","9adbf461":"code","27ce79d3":"code","c53fafcd":"code","7ea2dfd3":"code","e0a40a89":"code","e9e573dd":"code","25897dff":"code","36e20042":"code","c558ece7":"code","feb71897":"code","fc51dcc2":"code","baebbe77":"code","00930716":"code","d84eb965":"code","126724d6":"code","cc012651":"markdown","137be686":"markdown","b7d5646c":"markdown","403a6d3e":"markdown","aac22ee3":"markdown","3e400a3a":"markdown","a7025b96":"markdown","49be9e04":"markdown","c40d3504":"markdown","3321dafe":"markdown","ea74cd1a":"markdown","7934d44b":"markdown","483f5704":"markdown"},"source":{"db340190":"import os, cv2 # to import directory of file\nimport zipfile\nimport pandas as pd #libraries to read\nimport numpy as np #for algebric function\nimport matplotlib.pyplot as plt # for visualization\nimport matplotlib.image as imgplt #for image visualization\nimport seaborn as sns #Seaborn for visualization\n\n# Sklearn Libraries\nfrom sklearn.model_selection import train_test_split #for test & train Split\nfrom sklearn.metrics import confusion_matrix, accuracy_score # metrics\nfrom sklearn.preprocessing import StandardScaler #for scaling to increase computing speed\n\n#keras libraries\nimport tensorflow as tf\nimport keras\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Conv3D, Flatten, MaxPool2D, Dropout, Activation, AvgPool2D\nfrom keras.preprocessing.image import img_to_array, ImageDataGenerator, load_img\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import RMSprop, Adam\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","fbbcdfdd":"fdirl=[]\ns_id = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        fdir = os.path.join(dirname, filename)\n        s_idd = os.path.join(filename)\n        fdirl.append(fdir)\n        s_id.append(s_idd)\nfdirl = fdirl[1:] \nfdirl[:2]","372134a1":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# jaypee_metadata.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf = pd.read_csv('..\/input\/chest-xrays-tuberculosis-from-india\/jaypee_metadata.csv', delimiter=',', nrows = nRowsRead)\n#df1.dataframeName = 'jaypee_metadata.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","bff50301":"df[:5]","9e847242":"print(df[\"findings\"].unique())\ndf[:2]","eba9953f":"sns.countplot(df[\"findings\"])\n#data is equally distributed","fad70468":"dft = df[df[\"findings\"]==\"Tuberculosis\"]\ndff = df[df[\"findings\"]==\"False\"]\nprint(dft.shape)\nprint(dff.shape)","180f564c":"tt = dft[\"study_id\"].to_list()\nff = dff[\"study_id\"].to_list()","3d9c9d7b":"lable = []\nfor i in s_id:\n  if i in tt:\n     lable.append(1)\n  if i in ff:\n      lable.append(0)\nlable = np.array(lable)\nlen(lable)","b079d551":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n    return cv2.resize(img, (250, 250), interpolation=cv2.INTER_CUBIC)","9adbf461":"train = np.array([read_image(i) for i in fdirl])\nprint(\"Train :\",train.shape)","27ce79d3":"print(\"Count of TB pat  :\",list(lable).count(1))\nprint(\"Count of False   :\",list(lable).count(0))","c53fafcd":"plt.imshow(train[7][:,:,0])\nplt.title(lable[7])\n#lable 0 --> No TB\n#lable 1 --> TB","7ea2dfd3":"x=train\ny=lable\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.33,random_state=7)\n#y_train = y_train.reshape(-1,1)\n#y_test = y_test.reshape(-1,1)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nint_sh = x_train.shape[1:]\nprint(\"Input shape :\",int_sh)","e0a40a89":"def tbornot():\n  model = Sequential()\n\n  model.add(Conv2D(32,(3, 3), padding='same', input_shape=(250,250,3)))\n  model.add(Activation(\"relu\"))\n  model.add(MaxPool2D(pool_size=(2, 2)))\n\n  model.add(Conv2D(64,(3,3)))\n  model.add(Activation(\"relu\"))\n  model.add(MaxPool2D(pool_size=(2, 2)))\n\n  model.add(Conv2D(128,(3,3)))\n  model.add(Activation(\"relu\"))\n  model.add(Conv2D(250,(3,3)))\n  model.add(Activation(\"relu\"))\n  #model.add(Dropout(0.25))\n  model.add(Conv2D(120,(3,3)))\n  model.add(Activation(\"relu\"))\n  model.add(AvgPool2D(2,2))\n  model.add(Conv2D(64,(3,3)))\n  model.add(Activation(\"relu\"))\n  model.add(AvgPool2D(2,2))\n\n  model.add(Conv2D(32,(2,2)))\n  model.add(Activation(\"relu\"))\n  model.add(MaxPool2D(2,2))\n\n  model.add(Flatten())\n  model.add(Dense(32))\n  model.add(Dropout(0.25))\n  model.add(Dense(1))\n  model.add(Activation(\"sigmoid\"))\n\n  opt = keras.optimizers.Adam(0.001)\n  model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n  return model","e9e573dd":"model = tbornot()","25897dff":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=4, min_lr=0.0001)","36e20042":"datagen = ImageDataGenerator(\n    shear_range=0.1,\n    zoom_range=0.2,\n    rescale=1.0\/255.0,\n    rotation_range = 10)\ndatagen.fit(x_train)","c558ece7":"mod2 = model.fit(datagen.flow(x_train,y_train,batch_size=30),\n                validation_data=(x_train,y_train),epochs=100,callbacks=[reduce_lr])","feb71897":"print(mod2.history.keys())","fc51dcc2":"# summarize history for Loss\nplt.plot(mod2.history[\"loss\"])\nplt.plot(mod2.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","baebbe77":"# summarize history for accuracy\nplt.plot(mod2.history['accuracy'])\nplt.plot(mod2.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","00930716":"y_pred = model.predict(x_test)\ny_pred[:5]","d84eb965":"print(accuracy_score(y_pred.round(),y_test))\ncm = confusion_matrix(y_pred.round(),y_test,labels=[0,1])\ncm","126724d6":"df_cm = pd.DataFrame(cm, index = [0,1],\n                  columns = [0,1])\nsns.heatmap(df_cm, annot=True)","cc012651":"# Prediction","137be686":"# Learning Rate optimize","b7d5646c":"# Report of Loss & Accuracy","403a6d3e":"# Read Doc","aac22ee3":"# Assigning Lable Values","3e400a3a":"# Samle Image","a7025b96":"# Importing Essential Packages","49be9e04":"# Train & Test Split","c40d3504":"# Fitting Model","3321dafe":"# Confusion Matrix","ea74cd1a":"# Data Argumentation","7934d44b":"# Read Image","483f5704":"# CNN Model"}}