{"cell_type":{"3311fee1":"code","a2c53d4a":"code","dd8568c5":"code","1b40a1ae":"code","c46dcdb7":"code","2eafd2f6":"code","9db4c39f":"code","d06780c5":"code","1d05c721":"code","a47da3f6":"code","0eb09638":"code","37bc2be7":"code","f1a29255":"code","5eec9d94":"code","082b929f":"code","a6f565b0":"code","5b98eba1":"code","5cf29f50":"code","a8eccd9b":"code","231224c4":"code","36896532":"code","fcef0511":"code","1715d805":"code","3c1c05f8":"code","9dc0f49f":"code","9f4743dc":"code","e5db00b3":"code","99154875":"code","daf779a6":"code","f88fb1b0":"code","954ad117":"code","5ca880fb":"code","6821563a":"markdown","1336ca7b":"markdown","a48ab428":"markdown","54fe7be0":"markdown","2a7eab7c":"markdown","aa85faea":"markdown","844772ec":"markdown","ece4895d":"markdown","ed28f7b0":"markdown","d5f1fa66":"markdown","0ad38257":"markdown","011bb72c":"markdown","eed32cea":"markdown","54d5da8a":"markdown","de941c72":"markdown","da2a433f":"markdown"},"source":{"3311fee1":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sb\nsb.set()","a2c53d4a":"# \/kaggle\/input\/bike-sharing-demand\/sampleSubmission.csv\n# \/kaggle\/input\/bike-sharing-demand\/train.csv\n# \/kaggle\/input\/bike-sharing-demand\/test.csv","dd8568c5":"train_data = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv')","1b40a1ae":"train_data.head()","c46dcdb7":"test_data.head()","2eafd2f6":"print(train_data.shape)\nprint(test_data.shape)","9db4c39f":"fig , axs = plt.subplots(1,4 , figsize=(20,5) , sharey=False , sharex=False , )\nfig.tight_layout(pad=2.5)\nsb.countplot(data=train_data , x='season'      , ax=axs[0])\nsb.countplot(data=train_data , x='holiday'     , ax=axs[1])\nsb.countplot(data=train_data , x='workingday'  , ax=axs[2])\nsb.countplot(data=train_data , x='weather'     , ax=axs[3])\n","d06780c5":"from sklearn.base import TransformerMixin , BaseEstimator\nfrom datetime import datetime\nclass TSSplit(BaseEstimator , TransformerMixin):\n    def __init__(self , format_str , out_col = ['year' , 'month' , 'day' , 'hour' , 'minute' , 'sec' , 'dayname' , 'dayNUM' , 'isweekend'] , weed_end_days = ['Saturday' ,'Sunday']):\n        self.format_str    = format_str\n        self.out_col       = out_col\n        self.weed_end_days = weed_end_days\n    \n    def fit(self , X , y=None):\n        return self\n    \n    def columns(self):\n        return self.out_col\n    \n    def transform(self , X):\n        col = X.copy().values\n        dict = {}\n        \n        for i in self.out_col:\n            if i == 'day'      : dict['day'       ] = np.array([datetime.strptime(i[0], self.format_str).day                                  for i in col] ).reshape(-1,1)\n            if i == 'year'     : dict['year'      ] = np.array([datetime.strptime(i[0], self.format_str).year                                 for i in col] ).reshape(-1,1)\n            if i == 'month'    : dict['month'     ] = np.array([datetime.strptime(i[0], self.format_str).month                                for i in col] ).reshape(-1,1)\n            if i == 'hour'     : dict['hour'      ] = np.array([datetime.strptime(i[0], self.format_str).hour                                 for i in col] ).reshape(-1,1)\n            if i == 'minute'   : dict['minute'    ] = np.array([datetime.strptime(i[0], self.format_str).minute                               for i in col] ).reshape(-1,1)\n            if i == 'sec'      : dict['sec'       ] = np.array([datetime.strptime(i[0], self.format_str).second                               for i in col] ).reshape(-1,1)\n            if i == 'dayname'  : dict['dayname'   ] = np.array([datetime.strptime(i[0], self.format_str).strftime(\"%A\")                       for i in col] ).reshape(-1,1)\n            if i == 'dayNUM'   : dict['dayNUM'    ] = np.array([datetime.strptime(i[0], self.format_str).isoweekday()                            for i in col] ).reshape(-1,1)\n            if i == 'isweekend': dict['isweekend' ] = np.array([datetime.strptime(i[0], self.format_str).strftime(\"%A\") in self.weed_end_days for i in col] ).astype(int).reshape(-1,1)\n        \n        out_list = []\n        \n        for i in self.out_col:\n            out_list.append(dict[i])\n        return np.concatenate(out_list , axis=1)\n  \n\n# exmple\n# from sklearn.compose import ColumnTransformer\n\n# obj = TSSplit(format_str='%Y-%m-%d %H:%M:%S')\n# out = obj.fit_transform(train_data)\n\n# pd.DataFrame(out , columns=obj.columns()).head(50)","1d05c721":"from sklearn.base import TransformerMixin , BaseEstimator\nfrom sklearn.cluster import DBSCAN , KMeans \n\nfrom datetime import datetime\n\nclass LablizeGroup(BaseEstimator , TransformerMixin):\n    def __init__(self  , df , columns , K = 5 ):\n        self.K    = K\n        self.df  = df\n        self.columns = columns\n    \n    def fit(self , X=None , y=None):\n        self.clustrer = KMeans(n_clusters = self.K , random_state=42)\n        return self\n        \n    def getLablesFromTest(self , test_df):\n        data_to_get_label = test_df[self.columns]\n        labels = self.clustrer.predict(data_to_get_label)\n        return pd.DataFrame(labels , columns=['lables'])\n    \n    def transform(self , X):\n        data_to_cluster = self.df[self.columns]\n        labels          = self.clustrer.fit_predict(data_to_cluster)\n        return pd.DataFrame(self.clustrer.labels_ , columns=['lables'])\n","a47da3f6":"TSSplit_obj = TSSplit(format_str='%Y-%m-%d %H:%M:%S' , weed_end_days=['Saturday', 'Sunday'] )\nres1 = TSSplit_obj.fit_transform(train_data)\ncols_outofDate = pd.DataFrame(res1 , columns=TSSplit_obj.columns())\ncols_outofDate","0eb09638":"trainWithDate = pd.concat(\n    [\n        train_data.drop(['datetime'] , axis=1  ) ,\n        cols_outofDate , \n    ], axis=1\n)\npd.set_option('display.max_columns' , None)\ntrainWithDate","37bc2be7":"trainWithDate[trainWithDate['windspeed'] == 0]","f1a29255":"from sklearn.base import TransformerMixin , BaseEstimator\nfrom sklearn.ensemble import RandomForestRegressor , BaggingRegressor , ExtraTreesRegressor\n\nfrom datetime import datetime\n\nclass Replace0_sUsingRF():\n    def __init__(self  , df  , columnwithzeros , X_cols = []):\n        self.df  = df\n        self.columnwithzeros = columnwithzeros\n        self.X_cols = X_cols\n    \n    def fit(self):\n        self.RF = RandomForestRegressor(max_depth = 1000 , random_state=42)\n        self.RF = ExtraTreesRegressor(random_state=42)\n        return self\n        \n    \n    def transform(self):\n        datawith0    = self.df[self.df[self.columnwithzeros]==0]\n        datawithout0 = self.df[self.df[self.columnwithzeros]!=0]\n        self.RF.fit(datawithout0[self.X_cols] , datawithout0[self.columnwithzeros])\n        predictions = pd.DataFrame(self.RF.predict(datawith0[self.X_cols]).reshape(-1,1) , index=datawith0.index)\n        imputed_data  =  pd.merge(datawith0.drop([self.columnwithzeros] , axis=1) , pd.DataFrame(predictions), on=datawith0.index)\n        imputed_data.rename(columns={ 0 : self.columnwithzeros} , inplace=True)\n        return pd.concat([datawithout0 , imputed_data.set_index('key_0')] , axis=0).sort_index()\n    \ndfwithout0 = Replace0_sUsingRF(trainWithDate ,X_cols=[\"season\",\"weather\",\"humidity\",\"month\",\"temp\",\"year\",\"atemp\"] , columnwithzeros='windspeed').fit().transform()","5eec9d94":"fig , axs = plt.subplots(1 , 2 , figsize=(10 , 5))\nsb.histplot(data=trainWithDate , x='windspeed' , ax=axs[0] , kde=True)\nsb.histplot(data=dfwithout0    , x='windspeed' , ax=axs[1] , kde=True)","082b929f":"fig , axs = plt.subplots(1 , 2 , figsize=(10 , 5))\nsb.histplot(data=dfwithout0    , x='windspeed' , ax=axs[1] , kde=True)\nndf = dfwithout0.copy()\nndf['windspeed'] = np.sqrt(ndf['windspeed'])\nsb.histplot(data=ndf , x='windspeed' , ax=axs[0] , kde=True)\n","a6f565b0":"# dfwithout0['windspeed'] = np.sqrt(dfwithout0['windspeed'])","5b98eba1":"LablizeGroup_obj = LablizeGroup(dfwithout0 , ['temp','atemp','humidity','windspeed'] , K = 4)\nres2 = LablizeGroup_obj.fit_transform(dfwithout0)\nlabels = pd.DataFrame(res2)\nlabels","5cf29f50":"sb.countplot(data = labels , x='lables')","a8eccd9b":"fedf = pd.concat(\n    [\n        dfwithout0 ,\n        labels\n    ], axis=1\n)\npd.set_option('display.max_columns' , None)\nfedf","231224c4":"import missingno as msno\nmsno.matrix(fedf,figsize=(12,5))","36896532":"# season\tholiday\tworkingday\tweather\ttemp\tatemp\thumidity\twindspeed\tcasual\tregistered\tcount\tyear\tmonth\tday\thour\tminute\tsec\tdayname\tdayNUM\tisweekend\tlables\nfig , axs = plt.subplots(3,4 , figsize=(30 , 20))\nfig.tight_layout(pad=2.5)\nsb.boxplot(data=fedf , y='count' , x='season'  , orient='v' , ax=axs[0][0] )\nsb.boxplot(data=fedf , y='count' , x='holiday'  , orient='v' , ax=axs[0][1] )\nsb.boxplot(data=fedf , y='count' , x='workingday'  , orient='v' , ax=axs[0][2] )\nsb.boxplot(data=fedf , y='count' , x='weather'  , orient='v' , ax=axs[0][3] )\n\nsb.boxplot(data=fedf , y='count' , x='year'  , orient='v' , ax=axs[1][0] )\nsb.boxplot(data=fedf , y='count' , x='month'  , orient='v' , ax=axs[1][1] )\nsb.boxplot(data=fedf , y='count' , x='day'  , orient='v' , ax=axs[1][2] )\nsb.boxplot(data=fedf , y='count' , x='hour'  , orient='v' , ax=axs[1][3] )\n\nsb.boxplot(data=fedf , y='count' ,  orient='v' , ax=axs[2][0] )\nsb.boxplot(data=fedf , y='count' , x='dayNUM'  , orient='v' , ax=axs[2][1] )\nsb.boxplot(data=fedf , y='count' , x='isweekend'  , orient='v' , ax=axs[2][2] )\nsb.boxplot(data=fedf , y='count' , x='lables'  , orient='v' , ax=axs[2][3] )","fcef0511":"df_olDroped = fedf[fedf['count'] < (( fedf['count'].quantile(q=0.75) - fedf['count'].quantile(q=0.25) ) * 1.5)]\n# df_olDroped = fedf[np.abs(fedf[\"count\"]-fedf[\"count\"].mean())<=(3*fedf[\"count\"].std())] ","1715d805":"print(fedf.shape)\nprint(df_olDroped.shape)","3c1c05f8":"df_olDroped","9dc0f49f":"sb.boxplot(data=df_olDroped , y='count' ,  orient='v'  )","9f4743dc":"fig, ax = plt.subplots(figsize=(16,15))\nsb.heatmap(data=df_olDroped.corr(), annot=True, linewidths=.5, ax=ax)","e5db00b3":"from sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(df_olDroped.drop(columns=['count' , 'dayname' , \t'registered' ,'casual' , 'year' , 'day'  , 'temp' , 'minute',\t'sec' ] ,axis=1) , df_olDroped['count'] , test_size = 0.1)","99154875":"from sklearn.ensemble import GradientBoostingRegressor , AdaBoostRegressor , BaggingRegressor\nmodel = BaggingRegressor()\nmodel.fit(X_train , y_train)\nprint(model.score(X_train , y_train))\nprint(model.score(X_test , y_test))","daf779a6":"from sklearn.metrics import mean_squared_log_error\ntrain_err = np.sqrt(mean_squared_log_error(y_train , model.predict(X_train)))\nvalid_err = np.sqrt(mean_squared_log_error(y_test  , model.predict(X_test )))\nprint('training error = ' , train_err)\nprint('testing error = ' , valid_err)\nprint(train_err - valid_err*100)","f88fb1b0":"test_data\n","954ad117":"test_data = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv')\ntest_data\n\nTSSplit_obj = TSSplit(format_str='%Y-%m-%d %H:%M:%S' , weed_end_days=['Saturday', 'Sunday'] )\nres1 = TSSplit_obj.fit_transform(test_data)\ncols_outofDate = pd.DataFrame(res1 , columns=TSSplit_obj.columns())\ncols_outofDate\n\n\nLablizeGroup_obj \nres2 = LablizeGroup_obj.getLablesFromTest(test_data)\nlabels = pd.DataFrame(res2 )\nlabels\n\n\nfedf = pd.concat(\n    [\n        test_data.drop(['datetime'] , axis = 1),\n        cols_outofDate ,\n        labels\n    ], axis=1\n)\npd.set_option('display.max_columns' , None)\nfedf\n\ntst = fedf.drop(columns=['dayname'  , 'year' , 'day'  , 'temp' , 'minute',\t'sec' ] ,axis=1)","5ca880fb":"pd.DataFrame(model.predict(tst) , columns=['count'] , index = test_data.datetime).to_csv('Submission.csv')","6821563a":"from this data we can say that\n- ","1336ca7b":"as we can see there is outliers in count column so it needs further investigation","a48ab428":"# <center>cluster weather transformer","54fe7be0":"# <center>import data","2a7eab7c":"| cloumn name | needed or not | |\n| ----------- | ----------- | |\n| datetime | neede to be splited  | |\n| season   | needed | |\n| holiday  |  not needed  | the working day also represents <br> this column |\n| workingday |  needed | |\n| weather\t| | |\n| temp\t| | |\n| atemp\t| | |\n| humidity\t| | |\n| windspeed | | |\n| casual | not needed | the count cannot be a feature <br> as it should be predicted |\n| registered | not needed | the count cannot be a feature <br> as it should be predicted |\n| **count** | target | |","aa85faea":"# <center>merge all together","844772ec":"# <center>concatinate year , month , ... cols with other columns","ece4895d":"# This note book was made as a part of ML course in ITI internship ( for educational purpose ) \nsteps done in this note book are\n- data\n - about data\n - data summary\n \n- feature engineering\n - missing value analysis\n - outliers analysis\n - filling 0s in wind spped column using RandomForest\n \n- data visualization\n - visualize the distripution\n - visualize target vs features\n \n- modeling\n - try linear model\n - regularization model\n - ensemble mdoel","ed28f7b0":"# <center> Missing Values Analysis","d5f1fa66":"| data | #rows | #columns | |\n| ---- | ----- | ------- | |\n| train data | 10886 |  12 | |\n|test data | 6493 |  9| there is no <br> casual<br>\tregistered<br>\tcount<br> columns in test |","0ad38257":"# <center>generate year , month , day , hour , minute , sec , dayname , dayNUM , isweekend","011bb72c":"so, both the training data and testing data has the following columns\n\n| cloumn name | discription | values |\n| ----------- | ----------- | ----------- |\n| datetime | time stamp | YYYY-MM-DD HH-mm-ss format | \n| season   | - |  1 = spring, 2 = summer, 3 = fall, 4 = winter |\n| holiday  |  whether the day is considered a holiday  | 1= holyday |\n| workingday |  whether the day is neither a weekend nor holiday | 1= it's working day |\n| weather | - | 1: Clear, Few clouds, Partly cloudy, Partly cloudy <br\/> 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist <br\/> 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds <br\/> 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n |\n| casual | number of non-registered user rentals initiated | - |\n| registered | number of registered user rentals initiated | - |\n| **count** | number of total rentals | target |\n","eed32cea":"# <center>clustering weather data","54d5da8a":"# <center>split datetime column transformer","de941c72":"# <center>replace zeros in windspeed column using randomforest","da2a433f":"# <center>plot data count"}}