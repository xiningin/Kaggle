{"cell_type":{"b926cc51":"code","2c097bfc":"code","aede00d3":"code","667ac1a9":"code","2c52f086":"code","86c41bd1":"code","d2c98d95":"code","5e2fe135":"code","2a5f41e0":"code","1d875105":"code","60d25b1a":"code","523e7380":"code","b3048bc0":"code","f179c798":"code","1ddc6995":"code","3bb4ad22":"code","2eecd28b":"code","c5d40804":"markdown","9f4b68f5":"markdown","3a601d2b":"markdown","bb84dc98":"markdown","2b31a376":"markdown","be193350":"markdown","7bb6e9ea":"markdown","43ace7ac":"markdown","485e17cf":"markdown","62bf6fd5":"markdown","016b8cea":"markdown","bdddae86":"markdown","c5925a62":"markdown","804bc67b":"markdown","7f355378":"markdown","90d1886a":"markdown","89928f6f":"markdown","cf6e005d":"markdown","1e73dcb8":"markdown","6073c3bc":"markdown","32539859":"markdown","6744f86c":"markdown","5b61ca68":"markdown","a2228a36":"markdown","79390f59":"markdown","70a68719":"markdown","7ff73705":"markdown","9f14df3a":"markdown","ed892208":"markdown","7aa1266b":"markdown","ca74547b":"markdown","69ea4f2f":"markdown","ffb12683":"markdown"},"source":{"b926cc51":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# import data from sklearn datasets\nfrom sklearn.datasets import load_breast_cancer\n\n# import sklearn models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# import Cross validation from sklearn\nfrom sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_predict, cross_val_score, \\\nStratifiedKFold, GridSearchCV\n\n# to check accuracy\nfrom sklearn.metrics import accuracy_score\n\n# To ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nseed = 11","2c097bfc":"data = load_breast_cancer(as_frame=True)\ndf = data.data\ndf['target'] = data.target","aede00d3":"df.shape","667ac1a9":"df.head(2)","2c52f086":"df.isnull().any().sum()","86c41bd1":"# Spliting the data into X and y\nX = df.drop('target', axis = 1)\ny = df['target']","d2c98d95":"model = LogisticRegression()\ncv_scores_5_fold = cross_val_score(model, X, y, cv = 5)\nprint(\"Accuracy score in each iteration: {}\".format(cv_scores_5_fold))\nprint(\"K-Fold Score: {}\".format(np.mean(cv_scores_5_fold)))","5e2fe135":"cv_predicts_5_fold = cross_val_predict(model, X, y, cv = 5)\nprint(\"Predicted class for each record: {}\".format(cv_predicts_5_fold))\nprint(\"Total records: {}, Total predicted values: {}\".format(df.shape[0],len(cv_predicts_5_fold)))\n\n# To check the accuracy use prediction values as y-hat and use accuracy score to calculate accuracy\ncv_pred = cv_predicts_5_fold\nprint(accuracy_score(y, cv_pred))","2a5f41e0":"# create LOOCV procedure\ncv = LeaveOneOut()\n# create model\nmodel = LogisticRegression(random_state=seed)\n# evaluate model\nscores = cross_val_score(model, X, y, scoring = 'accuracy', cv = cv, n_jobs = -1)\n# report performance\nprint('Accuracy: %.3f (%.3f)' %(np.mean(scores), np.std(scores)))","1d875105":"# create LOOCV procedure\ncv = KFold(n_splits= 10, random_state= 10, shuffle=True)\n# create model\nmodel = LogisticRegression(random_state=seed)\n# evaluate model\nscores = cross_val_score(model, X, y, scoring = 'accuracy', cv = cv, n_jobs = -1)\n# report performance\nprint('Accuracy: %.3f (%.3f)' %(np.mean(scores), np.std(scores)))","60d25b1a":"plt.errorbar(range(1,11), scores)","523e7380":"# create LOOCV procedure\ncv = StratifiedKFold(n_splits= 10, random_state= 10, shuffle=True)\n# create model\nmodel = LogisticRegression(random_state=seed)\n# evaluate model\nscores = cross_val_score(model, X, y, scoring = 'accuracy', cv = cv, n_jobs = -1)\n# report performance\nprint('Accuracy: %.3f (%.3f)' %(np.mean(scores), np.std(scores)))","b3048bc0":"models = {'Random Forest': RandomForestClassifier(random_state=seed),\n          'Decision Tree': DecisionTreeClassifier(random_state=seed), \n          'Logistic Regression': LogisticRegression(random_state=seed)}\nfor name, model in models.items():\n    score = cross_val_score(model, X, y, cv = 5) # here we can select different versions of cv\n    print(f\"{name} has accuracy score: {np.mean(score)}\")","f179c798":"rf_model = RandomForestClassifier(random_state=seed)","1ddc6995":"n_estimators = list(range(5,20))\nmaxdepth = list(range(2, 10))\n\nhyperparameters = dict(n_estimators = n_estimators, max_depth= maxdepth)\ngrid_rf_model = GridSearchCV(estimator=rf_model, param_grid=hyperparameters, cv = 5, verbose=1)\n\nimporved_model = grid_rf_model.fit(X, y)","3bb4ad22":"# Find the best parameters\n# print('Complete CV results: ', imporved_model.cv_results_)\nprint('Best estimator: ', imporved_model.best_estimator_)\nprint('Best accuracy score: ',imporved_model.best_score_)\nprint('Best parameters: ',imporved_model.best_params_)","2eecd28b":"rf_model = RandomForestClassifier(max_depth=4, n_estimators = 14, random_state=seed)\nscore = cross_val_score(rf_model, X, y, cv = 5)\nprint('CV Score:', np.mean(score))","c5d40804":"### General Implementation using Scikit-learn Library:\n`- cross_val_score`: To compute **score** of each test fold.     \n`- cross_val_predict`: To predict and returns **predicted score** of each test fold.\n","9f4b68f5":"### 1. Model Selection\n    Aim: Compare different classifiers using cross-val-score library of scikit-learn.","3a601d2b":"### References:\n[LOOCV](https:\/\/machinelearningmastery.com\/loocv-for-evaluating-machine-learning-algorithms\/)   \n[K-Fold](https:\/\/machinelearningmastery.com\/how-to-configure-k-fold-cross-validation\/)     \n[GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html)","bb84dc98":"**Pros of K-Fold**    \n* Computationally less expensive.\n* less variance \n\n**Cons of K-Fold**    \n* Can make the split of data imbalance and impact our model.","2b31a376":"# <span style = 'color:blue'> Types\nOn the basis of the subsets that a dataset is split into, CV is of different types. Among all, **LOOCV, K-Fold and Stratified CV** are the most common types. In this notebook, I would explain each of these type along with their implementation using scikit library. ","be193350":"### 3. Stratified K-Fold CV   \nThis is an improved version of K-Fold where each fold has same percent of samples of each target class. and Hence overcome the drawback of K-Fold CV. ","7bb6e9ea":"**Use LOOCV**  for small datasets or when estimated model performance is critical.     \n**Don't Use LOOCV**  Large datasets or costly models to fit.","43ace7ac":"**Note**   \n`n_jobs = -1` means use all CPU cores, decreasing the computational cost in fitting and evalualting.\n* for regression problem, `scoring=` would be different. it can be `'neg-mean-absolute-error'` i.e. mean absolute error metric to check the accuracy. \n* if you leave p training datapoints as test datapoints instead of one then it is called **Leave P out Cross Validation**.","485e17cf":"## Data\nI am using breast cancer dataset from sklearn library, which has 569 observations and 31 features including target (binary variable). ","62bf6fd5":"![](CV_image.svg)","016b8cea":"# <span style = 'color:blue'> Inference\n* Stratified K-Fold for only classification problems\n* Chose K value wisely to maintain the bias-variance balance\n    * **Lower k ----> more bias, less variance (underfit)**\n    * **Higher k ----> less bias, more variance (overfit)**\n* Use LOOCV for very small dataset.","bdddae86":"# <span style = 'color:green'> Cross-Validation Types and Applications","c5925a62":"**Pros of Stratified K-Fold**    \n* train-test split preserve the class distribution in the dataset.\n\n**Cons of Stratified K-Fold**    \n* Only useful for classification modeling","804bc67b":"## Import Libraries","7f355378":"### 2. Hyper-parameter Tuning of Random Forest\nIn order to find the best parameter for a particular case study, tuning the hyper-parameter is a vital step to follow. **GridSearchCV** Scikit-learn library is used for that.","90d1886a":"# <span style = 'color:blue'>What is Cross-Validation?\nCross-Validation is basically a resampling technique to make our model sure about its efficiency and accuracy on the unseen data.    \n**Bunch of train\/test splits __ testing accuracy for each split__ average them**    \n* **Steps**\n    1. Divide data into K equal size partitions.\n    2. Treat 1-Fold as test and another K-1 folds as training data.\n    3. Fit the model on training data and compute the score on test data.\n    4. Repeat step 3 for all folds by taking another fold as test and remaining as training.\n    5. Take average of scores of all the test folds.\n* It overcome **over-fitting and Under-fitting** by choosing optimal value of k and hence estimate the model more accurately as compared to `train_test_split` method.","89928f6f":"**Implementation of Scikit Learn LOOCV**","cf6e005d":"If the esitmator (model) is a Claissifier and \u2018y\u2019(target variable) is either binary\/multicalss, then **\u2018StratifiedKfold\u2019** technique is used by default. In all other cases **\u2018K_Fold\u2019** technique is used as a default to split and train the model.","1e73dcb8":"**Note**   Stratified K-Fold is specifically used for classification in order to incorporate same proportion of each class in each split to make the true representaton of the actual dataset.","6073c3bc":"**Implementation of Scikit Learn K-Fold CV**","32539859":"**Implementation of Scikit Learn Stratified K-Fold CV**","6744f86c":"**Testing the best paramters**","5b61ca68":"**Note**   The k value must be chosen carefully. Generally, the value of k is chosen such that each train\/test group of data samples is large enough to be statistically representative of the broader dataset.    \nThe Common choice of k-value is 5 or 10. On increasing K, bias becomes smaller. ","a2228a36":"**Conclusion:** The accuracy is improved by 0.2%\nIn order to further increase the accuracy you can try tuning the other hyper-parameters or different range of these parameters. ","79390f59":"**Conclusions:** Random Forest has maximum accuracy. ","70a68719":"**Note** There are 15 different values of n_estimator and 8 different values of maxdepth, So there would be 120 combinations that has to test to find the best. For each combination there are 5 iterations(cv= 5) hence there would be total 120 x 5 = 600 iterations. In each iteration model train on training data and score on test data. ","7ff73705":"## Agenda\n**What is CV?**    \n**Types**\n1. Leave one out cross validation (LOOCV)\n2. K-Fold\n3. Stratified K-Fold  \n\n**Applications**\n1. Hyper-parameter tuning\n2. Model selection \n3. Feature selection \n\n**Inference**","9f14df3a":"# <span style = 'color:blue'> Applications\nCV is generally used for **model selection** and **hyperparameter tunning**. In advance studies, CV has also been implemented in **feature selection**.","ed892208":"lets tune two hyper-parameters: `n_estimators` and `maxdepth`.","7aa1266b":"### 1. LOOCV   \nData is partitioned into blocks representing each with 1 record as test while remaining as train, Hence each and every record is treated as test therefore number of iterations would be equal to number of records. ","ca74547b":"* `cv_results_` contains all the results.\n* `best_estimator` estimator which gave highest score.\n* `best_score` mean cross-validated score of the best_estimator.\n* `best_params` parameters that gave best results","69ea4f2f":"### 2. K-Fold CV   \nData is partitioned into K blocks, out of which only one block is treated as test while remaining K-1 blocks were used as training the model. This procedure repeats for every block.","ffb12683":"**Pros of LOOCV**    \n* provides sort of certainty of model performance when tested on unseen data.\n* low bias\n\n**Cons of LOOCV**    \n* computationally very expensive\n* higher variance (everything is tested and trained)"}}