{"cell_type":{"f16feaf2":"code","7b9b5a49":"code","da3d897e":"code","1ac03a3c":"code","402267b3":"code","7e88460c":"code","153d0d3f":"code","f24feb7e":"code","543ebd5f":"code","87ac5251":"code","58e611a3":"code","5aa0766d":"code","970b5aa7":"code","5f3bcd6a":"code","5c7a2160":"code","6928fd25":"code","3bc3ca13":"code","647ab02d":"code","4a4eaedd":"markdown","8f77b1c9":"markdown","10550ed0":"markdown","14a61027":"markdown","946edf3f":"markdown","2a0c5eaf":"markdown","dcaacd21":"markdown","9c0956df":"markdown","75128b54":"markdown","0afbfe7f":"markdown","d85b076a":"markdown","8df50f89":"markdown","9f92ddcd":"markdown","effec543":"markdown","41cde48c":"markdown","4fca75b1":"markdown","69a676ff":"markdown"},"source":{"f16feaf2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import accuracy_score # metric scoring\nfrom sklearn import neighbors # Nearest neighbors model\nfrom sklearn.linear_model import LinearRegression # Linear regression model\nfrom sklearn.linear_model import SGDClassifier # SGD classifier model\nfrom sklearn.tree import DecisionTreeClassifier # Decision Tree Model\nfrom sklearn.model_selection import train_test_split # For divding \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b9b5a49":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","da3d897e":"print(train_data.shape)\nprint(train_data.head())\nprint(train_data.describe())\nprint(train_data.isnull().sum())\n\nprint(test_data.shape)\nprint(test_data.head())\nprint(test_data.describe())\nprint(test_data.isnull().sum())\n","1ac03a3c":"train_data = train_data[train_data['Embarked'].notna()]\ntrain_data.drop(columns = ['Name', 'Ticket'], inplace = True)\ntest_data.drop(columns = ['Name', 'Ticket'], inplace = True)","402267b3":"train_data.hist(figsize = (12,7))\ntest_data.hist()","7e88460c":"train_age_median = train_data['Age'].median()\ntest_age_median = test_data['Age'].median()\ntrain_data['Age'] = train_data['Age'].fillna(train_age_median)\ntest_data['Age'] = test_data['Age'].fillna(test_age_median)","153d0d3f":"test_fare_mode = test_data['Fare'].mode()\ntest_data['Fare'] = test_data['Fare'].fillna(test_fare_mode[0])\nprint(train_data.isnull().sum())\nprint(test_data.isnull().sum())","f24feb7e":"print(train_data['Cabin'].unique())","543ebd5f":"cabin_mask = train_data['Cabin'].isnull()\nwithout_Cabin = train_data[cabin_mask]\nwith_Cabin = train_data[np.invert(cabin_mask)]\n\nprint('average of confirmed cabin passengers',np.average(with_Cabin['Fare']))\nprint('min of confirmed cabin passengers',np.min(with_Cabin['Fare']))\nprint('max of confirmed cabin passengers',np.max(with_Cabin['Fare']))\nprint('average of no cabin passengers',np.average(without_Cabin['Fare']))\nprint('min of no cabin passengers',np.min(without_Cabin['Fare']))\nprint('max of no cabin passengers',np.max(without_Cabin['Fare']))","87ac5251":"with_Cabin.hist(column = 'Fare')\nwithout_Cabin.hist(column = 'Fare')","58e611a3":"\nfirst_bin_train = train_data['Fare'] < 50 \nfirst_bin_train = first_bin_train & cabin_mask\nthird_bin_train = train_data['Fare' ] > 300 \nthird_bin_train = third_bin_train & cabin_mask\n\nfirst_bin_test = test_data['Fare'] < 50 \nfirst_bin_test = first_bin_test & cabin_mask\nthird_bin_test = test_data['Fare'] > 300 \nthird_bin_test = third_bin_test & cabin_mask\n\n# Set upper and lower bins\ntrain_data.loc[first_bin_train,'Cabin'] = 'L'\ntrain_data.loc[third_bin_train,'Cabin'] = 'U'\ntest_data.loc[first_bin_test,'Cabin'] = 'L'\ntest_data.loc[third_bin_test,'Cabin'] = 'U'\n\n# Remaining null values belong in middle bin\ntrain_data['Cabin'].fillna('M', inplace = True)\ntest_data['Cabin'].fillna('M', inplace = True)\n\n# Check\nprint(train_data.isna().sum())\nprint(test_data.isna().sum())","5aa0766d":"print(pd.get_dummies(train_data))","970b5aa7":"\n\ntrain_data.loc[train_data['Cabin'].str.startswith('A'), 'Cabin'] = 'A' \ntrain_data.loc[train_data['Cabin'].str.startswith('B'), 'Cabin'] = 'B' \ntrain_data.loc[train_data['Cabin'].str.startswith('C'), 'Cabin'] = 'C' \ntrain_data.loc[train_data['Cabin'].str.startswith('D'), 'Cabin'] = 'D' \ntrain_data.loc[train_data['Cabin'].str.startswith('E'), 'Cabin'] = 'E' \ntrain_data.loc[train_data['Cabin'].str.startswith('F'), 'Cabin'] = 'F' \ntrain_data.loc[train_data['Cabin'].str.startswith('G'), 'Cabin'] = 'G' \ntest_data.loc[test_data['Cabin'].str.startswith('A'), 'Cabin'] = 'A' \ntest_data.loc[test_data['Cabin'].str.startswith('B'), 'Cabin'] = 'B' \ntest_data.loc[test_data['Cabin'].str.startswith('C'), 'Cabin'] = 'C' \ntest_data.loc[test_data['Cabin'].str.startswith('D'), 'Cabin'] = 'D' \ntest_data.loc[test_data['Cabin'].str.startswith('E'), 'Cabin'] = 'E' \ntest_data.loc[test_data['Cabin'].str.startswith('F'), 'Cabin'] = 'F' \ntest_data.loc[test_data['Cabin'].str.startswith('G'), 'Cabin'] = 'G' \n\ntrain_data = pd.get_dummies(train_data)\ntest_data = pd.get_dummies(test_data)","5f3bcd6a":"corr = train_data.corr()\nplt.figure(figsize = (20,20))\nsns.heatmap(corr, vmax = .8, linewidths = 0.01, square = True, annot = True, cmap = 'YlGnBu', linecolor = 'White')\nplt.title('Feature correlation')\n\nother_corr = test_data.corr()\nplt.figure(figsize = (20,20))\nsns.heatmap(other_corr, vmax = .8, linewidths = 0.01, square = True, annot = True, cmap = 'YlGnBu', linecolor = 'White')\nplt.title('Feature correlation')","5c7a2160":"train_data = train_data.drop(columns = ['Cabin_F', 'Cabin_G', 'Cabin_T'])","6928fd25":"# Split training and test data\nX = train_data.loc[:,train_data.columns!= 'Survived']\nY = train_data['Survived']\nX_train,X_test, y_train, y_test = train_test_split(X, Y, test_size= .33,random_state = 21)\nprint(X_train.shape)\n# Create model objects\nLinReg = LinearRegression()\nknn = neighbors.KNeighborsClassifier(n_neighbors = 4)\n\n# Train Models\nLinReg.fit(X_train,y_train)\nknn.fit(X_train,y_train)\n\n# Run predictions\ny_pred_reg = LinReg.predict(X_test)\npredict_knn = knn.predict(X_test)\npredictions = [1 if p > 0.5 else 0 for p in y_pred_reg]\npredictions = np.array(predictions)\n","3bc3ca13":"print('knn accuracy:', round(accuracy_score(predict_knn,y_test)*100,2))\nprint('lin reg accuracy', round(accuracy_score(predictions,y_test)*100,2))","647ab02d":"print(test_data.shape)\nfinal_predictions = LinReg.predict(test_data)\nsurvived = [1 if p > 0.5 else 0 for p in final_predictions]\nsurvived = np.array(survived)\nSubmission = pd.DataFrame({'PassengerId':test_data['PassengerId'], 'Survived':survived})\nprint(Submission.head())\nSubmission.to_csv('submission.csv', index = False)","4a4eaedd":"**Now we are left with only the NaN values for cabin, I'm assuming this just means they didn't have a cabin not actual missing values but we will check it by first seeing how many cabin values there are**","8f77b1c9":"**Lets see if any features including cabins appear to have some sort of correlation with survival**","10550ed0":"# Generate Submission Data","14a61027":"# Model Evaluation","946edf3f":"# Model Building\n","2a0c5eaf":"**To understand how the data is distributed and determine what to do with missing age and fare values we will use a histogram**","dcaacd21":"**There does seem to be some level of influence between certain cabins and the survival outcome so we will keep it for now**\n**Test data doesn't have cabins F, G, or T so we won't train on those**","9c0956df":"# Exploratory Data Analysis","75128b54":"# Data Loading","0afbfe7f":"**Our regression Model appears to be  accurate so we will generate submission data from that**","d85b076a":"**Since age follows a somewhat normal distribution we will use the median to replace missing values**","8df50f89":"**There is only one missing value for fare, It isn't normally distributed so we'll essentially just guess by taking the mode**","9f92ddcd":"**We can also look at the distributions again**\n","effec543":"**Since embarked isn't missing in test data we'll go ahead and drop the missing embarked entry. \n  Additionally, names and tickets are categorical values that are unique, hard to hash and unlikely to impact survival\n  We'll go ahead and remove them**","41cde48c":"**If we were to convert our categories there are obviously too many columns for the cabins, It would be better to seperate columns by level.The highest cabin level on the titanic was A and the lowest was G so we will group all the cabins by level**","4fca75b1":"**To test if Nan is those without a cabin we will compare ticket prices for those with cabins to those without, if it is a really low value I think they might be cabinless**","69a676ff":"**The average ticket price disparity made me think that the assumption that nan meaning no cabin is right but the max and min values suggest that there are also some actual missing cabin values and the histograms also support that I'll represent these missing values into 3 categories based on fare, the categories will be 0-50, 100 - 300 and 300 since it is likely cabin qualities are linked to fare**"}}