{"cell_type":{"c748faf8":"code","51ad20aa":"code","82e412d1":"code","1a761690":"code","b0ef804b":"code","a290a01d":"code","44f1ba5c":"code","41fab303":"code","dd9c39c9":"markdown","596cd984":"markdown","27de7b4e":"markdown","5109b451":"markdown","77258668":"markdown","abac92d9":"markdown","bc31646c":"markdown","82894d6b":"markdown"},"source":{"c748faf8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","51ad20aa":"train = pd.read_csv('..\/input\/train.csv')\nholdout = pd.read_csv('..\/input\/test.csv')\ntrain.head()","82e412d1":"# %load functions.py\ndef process_missing(df):\n    \"\"\"Handle various missing values from the data set\n    Usage\n    ------\n    holdout = process_missing(holdout)\n    \"\"\"\n    df[\"Fare\"] = df[\"Fare\"].fillna(train[\"Fare\"].mean())\n    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n    return df\n\ndef process_age(df):\n    \"\"\"Process the Age column into pre-defined 'bins' \n    Usage\n    ------\n    train = process_age(train)\n    \"\"\"\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n    cut_points = [-1,0,5,12,18,35,60,100]\n    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n    return df\n\ndef process_fare(df):\n    \"\"\"Process the Fare column into pre-defined 'bins' \n    Usage\n    ------\n    train = process_fare(train)\n    \"\"\"\n    cut_points = [-1,12,50,100,1000]\n    label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n    return df\n\ndef process_cabin(df):\n    \"\"\"Process the Cabin column into pre-defined 'bins' \n    Usage\n    ------\n    train process_cabin(train)\n    \"\"\"\n    df[\"Cabin_type\"] = df[\"Cabin\"].str[0]\n    df[\"Cabin_type\"] = df[\"Cabin_type\"].fillna(\"Unknown\")\n    df = df.drop('Cabin',axis=1)\n    return df\n\ndef process_titles(df):\n    \"\"\"Extract and categorize the title from the name column \n    Usage\n    ------\n    train = process_titles(train)\n    \"\"\"\n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Officer\",\n        \"Col\":         \"Officer\",\n        \"Major\":       \"Officer\",\n        \"Dr\":          \"Officer\",\n        \"Rev\":         \"Officer\",\n        \"Jonkheer\":    \"Royalty\",\n        \"Don\":         \"Royalty\",\n        \"Sir\" :        \"Royalty\",\n        \"Countess\":    \"Royalty\",\n        \"Dona\":        \"Royalty\",\n        \"Lady\" :       \"Royalty\"\n    }\n    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    df[\"Title\"] = extracted_titles.map(titles)\n    return df\n\ndef process_fam(df):\n    \"\"\"Process the Family column into pre-defined 'bins' \n    Usage\n    ------\n    train = process_fam(train)\n    \"\"\"\n    df[\"familysize\"] = df[[\"SibSp\",\"Parch\"]].sum(axis=1)\n    cut_points = [0,1,2,3,4,5,6,7,8,9,10,20]\n    label_names = [\"0fam\",\"1fam\",\"2fam\",\"3fam\",\"4fam\",\"5fam\",\"6fam\",\"7fam\",\"8fam\",\"9fam\",\"Manyfam\"]\n    df[\"Fam\"] = pd.cut(df[\"familysize\"],cut_points,labels=label_names)\n    return df\n\ndef create_dummies(df,column_name):\n    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n    Usage\n    ------\n    train = create_dummies(train,\"Age\")\n    \"\"\"\n    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\ndef PrepareDF(df):\n    df = process_missing(df)\n    df = process_age(df)\n    df = process_fare(df)\n    df = process_titles(df)\n    df = process_cabin(df)\n    df = process_fam(df)\n    \n    df = create_dummies(df,'Age_categories')\n    df = create_dummies(df,'Fare_categories')\n    df = create_dummies(df,'Title')\n    df = create_dummies(df,'Cabin_type')\n    df = create_dummies(df,'Sex')\n    df = create_dummies(df,'Fam')\n    return df\n\ndef allDone():\n  display(Audio(url='https:\/\/sound.peal.io\/ps\/audios\/000\/000\/537\/original\/woo_vu_luvub_dub_dub.wav', autoplay=True))   ","1a761690":"train = PrepareDF(train)\nholdout = PrepareDF(holdout)","b0ef804b":"for col in train.columns: \n    print(col) ","a290a01d":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFECV\n\ndef select_features(df):\n    # Remove non-numeric columns, columns that have null values\n    df = df.select_dtypes([np.number]).dropna(axis=1)\n    all_X = df.drop([\"Survived\",\"PassengerId\"],axis=1)\n    all_y = df[\"Survived\"]\n    \n    clf = RandomForestClassifier(random_state=1)\n    selector = RFECV(clf,cv=10)\n    selector.fit(all_X,all_y)\n    \n    best_columns = list(all_X.columns[selector.support_])\n    print(\"Best Columns \\n\"+\"-\"*12+\"\\n{}\\n\".format(best_columns))\n    \n    return best_columns\n\ncols = select_features(train)","44f1ba5c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ndef select_model(df,features):\n    \n    all_X = df[features]\n    all_y = df[\"Survived\"]\n\n    # List of dictionaries, each containing a model name,\n    # it's estimator and a dict of hyperparameters\n    models = [\n#        {\n#            \"name\": \"LogisticRegression\",\n#            \"estimator\": LogisticRegression(),\n#            \"hyperparameters\":\n#                {\n#                    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n#                }\n#        },\n#        {\n#            \"name\": \"KNeighborsClassifier\",\n#            \"estimator\": KNeighborsClassifier(),\n#            \"hyperparameters\":\n#                {\n#                    \"n_neighbors\": range(1,20,2),\n#                    \"weights\": [\"distance\", \"uniform\"],\n#                    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n#                    \"p\": [1,2]\n#                }\n#        },\n        {\n            \"name\": \"RandomForestClassifier\",\n            \"estimator\": RandomForestClassifier(random_state=1),\n            \"hyperparameters\":\n                {\n                    \"n_estimators\": range(1,30,2),\n                    \"criterion\": [\"entropy\", \"gini\"],\n                    \"max_depth\": range(1,30,2),\n                    \"max_features\": [\"log2\", \"sqrt\"],\n                    \"min_samples_leaf\": [1, 5, 8],\n                    \"min_samples_split\": [2, 3, 5]\n                }\n        }\n        {\n            \"name\": \"SuportVectorMachine\",\n            \"estimator\": SVC\n            \"hyperparameters\":\n            {\n                \"n_estimators\": range(1,30,2),\n            }\n        }\n    ]\n\n    for model in models:\n        print(model['name'])\n        print('-'*len(model['name']))\n\n        grid = GridSearchCV(model[\"estimator\"],\n                            param_grid=model[\"hyperparameters\"],\n                            cv=10)\n        grid.fit(all_X,all_y)\n        model[\"best_params\"] = grid.best_params_\n        model[\"best_score\"] = grid.best_score_\n        model[\"best_model\"] = grid.best_estimator_\n\n        print(\"Best Score: {}\".format(model[\"best_score\"]))\n        print(\"Best Parameters: {}\\n\".format(model[\"best_params\"]))\n\n    return models\n\nresult = select_model(train,cols)\nallDone()","41fab303":"def save_submission_file(model,cols,filename=\"submission.csv\"):\n    holdout_data = holdout[cols]\n    predictions = model.predict(holdout_data)\n    \n    holdout_ids = holdout[\"PassengerId\"]\n    submission_df = {\"PassengerId\": holdout_ids,\n                 \"Survived\": predictions}\n    submission = pd.DataFrame(submission_df)\n\n    submission.to_csv(filename,index=False)\n\nbest_rf_model = result[2][\"best_model\"]\nsave_submission_file(best_rf_model,cols)\n\nallDone()","dd9c39c9":"# Print Columns","596cd984":"# Functions","27de7b4e":"# Making a submission","5109b451":"# Selecting and Tuning Different Algorithms","77258668":"# Read CSV","abac92d9":"**Author:** Jo\u00e3o Ant\u00f3nio - joaoantonio@ua.pt \\& github.com\/JoaoAnt\/.\n\n**The ipybn version can be found in:** the Github in the WaddlePortfolio\/Projects.\n\n**Made in:** Python 3 in the Jupyter Notebook software.","bc31646c":"# Apply Functions","82894d6b":"# Select best columns"}}