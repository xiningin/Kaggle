{"cell_type":{"0fb3be16":"code","0ea724ee":"code","619acccb":"code","c7dd93ad":"code","a4c3102d":"code","c4a76e5c":"code","ae119fcf":"code","5d30fa0d":"code","f23e9026":"code","5809c82e":"code","1c0766d6":"code","6318364d":"code","6a2a74f2":"code","e15d78ab":"code","3902b200":"code","ba12dc84":"code","6db70096":"code","b0e80296":"code","b6a70c27":"code","36fc9327":"code","9b1f523d":"code","994c557d":"code","47085807":"code","415da8e2":"code","1354e436":"code","9762b07d":"code","4b2b789b":"code","d041fc09":"code","d7db81af":"code","70f23420":"code","58eb9c33":"code","cbf3d092":"code","fe965914":"code","92e9d2ef":"code","0283efaa":"code","9e9f01e3":"code","e6aea45e":"code","6902494d":"code","42e295fc":"code","488b09fa":"code","6ac1ce13":"code","516e5efa":"code","fb7921b1":"code","2fe908f8":"code","e0bd38a3":"code","4df4872c":"code","079135ed":"code","6a74a381":"code","e97fab35":"markdown","a193e0eb":"markdown","1ab1e828":"markdown","e8be14e3":"markdown","3f3f88b3":"markdown","777aee24":"markdown","e2d83aab":"markdown"},"source":{"0fb3be16":"import pandas as pd # used for dataframes\nimport numpy as np \nimport xgboost as xgb # Gradient Boosting Algorithm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc # Garbage Collector required to extract unused and residual data and variables from memory\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","0ea724ee":"fields1 = ['username', 'course_id', 'action', 'truth'] # specific columns to load into the dataframe\nfields2 = ['username', 'course_id', 'time']\ngc.enable()","619acccb":"data_train_action = pd.read_csv('..\/input\/mooc-final\/train\/train.csv', usecols = fields1, nrows = 14582760) # load specific columns from train.csv\ndata_train_action.info()","c7dd93ad":"data_train_time = pd.read_csv('..\/input\/mooc-final\/train\/train.csv', usecols = fields2, nrows = 14582760) # load specific columns from train.csv\ndata_train_time.info()","a4c3102d":"data_test_action = pd.read_csv('..\/input\/mooc-final\/test\/test.csv', usecols = fields1, nrows = 6472430) # load specific columns from test.csv\ndata_test_action.info()","c4a76e5c":"data_test_time = pd.read_csv('..\/input\/mooc-final\/test\/test.csv', usecols = fields2, nrows = 6472430) # load specific columns from test.csv\ndata_test_time.info()","ae119fcf":"data_train_action = pd.get_dummies(data_train_action, columns = ['action']) # Getting dummies of 'action' column to convert 'object' type data into float values\ndata_test_action = pd.get_dummies(data_test_action, columns = ['action'])","5d30fa0d":"data_train_time['Datetime'] = pd.to_datetime(data_train_time['time']) # Converting 'time' column of 'object' type\ndata_test_time['Datetime'] = pd.to_datetime(data_test_time['time'])","f23e9026":"data_train_time = data_train_time.drop(['time'], axis = 1) # Dropping 'time' column to reduce memory usage\ndata_test_time = data_test_time.drop(['time'], axis = 1)","5809c82e":"gc.collect()","1c0766d6":"data_train_time['timestamp'] = data_train_time.Datetime.values.astype(np.int64) \/\/ 10 ** 9 # Converting data from 'datetime' type to timestamp\ndata_test_time['timestamp'] = data_test_time.Datetime.values.astype(np.int64) \/\/ 10 ** 9","6318364d":"data_train_time = data_train_time.drop(['Datetime'], axis = 1) # Dropping 'Datetime' column to reduce memory usage\ndata_test_time = data_test_time.drop(['Datetime'], axis = 1)","6a2a74f2":"gc.collect()","e15d78ab":"data_train_time['time_difference'] = pd.DataFrame(data_train_time.timestamp.diff()) # Calculating difference in timestamps of consecutive activities\ndata_test_time['time_difference'] = pd.DataFrame(data_test_time.timestamp.diff())","3902b200":"data_train_time = data_train_time.groupby(['username', 'course_id']).sum() # Grouping data into unique user-course pairs\ndata_train_time = pd.DataFrame(data_train_time.reset_index())\n\ndata_test_time = data_test_time.groupby(['username', 'course_id']).sum()\ndata_test_time = pd.DataFrame(data_test_time.reset_index())\n\ndata_train_action = pd.DataFrame(data_train_action.groupby(['username', 'course_id']).sum())\ndata_train_action = pd.DataFrame(data_train_action.reset_index())\n\ndata_test_action = pd.DataFrame(data_test_action.groupby(['username', 'course_id']).sum())\ndata_test_action = pd.DataFrame(data_test_action.reset_index())","ba12dc84":"data_train = pd.merge(data_train_action, data_train_time, left_index = True, right_index = True) # merging data_train_time and data_train_action into a single dataframe","6db70096":"del data_train_action\ndel data_train_time","b0e80296":"gc.collect()","b6a70c27":"data_test = pd.merge(data_test_action, data_test_time, left_index = True, right_index = True) # merging data_test_time and data_test_action into a single dataframe","36fc9327":"del data_test_action\ndel data_test_time","9b1f523d":"gc.collect()","994c557d":"data_train['truth'] = np.where(data_train['truth'] >= 1, 1,0) # Converting all non-zero values into 1, sine the XGBoost Classifier algorithm requires binary (0 or 1) as \n# input data\ndata_train['action_click_about'] = np.where(data_train['action_click_about'] >= 1, 1,0)\ndata_train['action_click_courseware'] = np.where(data_train['action_click_courseware'] >= 1, 1,0)\ndata_train['action_click_forum'] = np.where(data_train['action_click_forum'] >= 1, 1,0)\ndata_train['action_click_info'] = np.where(data_train['action_click_info'] >= 1, 1,0)\ndata_train['action_click_progress'] = np.where(data_train['action_click_progress'] >= 1, 1,0)\ndata_train['action_close_courseware'] = np.where(data_train['action_close_courseware'] >= 1, 1,0)\ndata_train['action_delete_comment'] = np.where(data_train['action_delete_comment'] >= 1, 1,0)\ndata_train['action_load_video'] = np.where(data_train['action_load_video'] >= 1, 1,0)\ndata_train['action_pause_video'] = np.where(data_train['action_pause_video'] >= 1, 1,0)\ndata_train['action_play_video'] = np.where(data_train['action_play_video'] >= 1, 1,0)\ndata_train['action_problem_check_correct'] = np.where(data_train['action_problem_check_correct'] >= 1, 1,0)\ndata_train['action_problem_get'] = np.where(data_train['action_problem_get'] >= 1, 1,0)\ndata_train['action_problem_save'] = np.where(data_train['action_problem_save'] >= 1, 1,0)\ndata_train['action_seek_video'] = np.where(data_train['action_seek_video'] >= 1, 1,0)","47085807":"data_test['truth'] = np.where(data_test['truth'] >= 1, 1,0)\ndata_test['action_click_about'] = np.where(data_test['action_click_about'] >= 1, 1,0)\ndata_test['action_click_courseware'] = np.where(data_test['action_click_courseware'] >= 1, 1,0)\ndata_test['action_click_forum'] = np.where(data_test['action_click_forum'] >= 1, 1,0)\ndata_test['action_click_info'] = np.where(data_test['action_click_info'] >= 1, 1,0)\ndata_test['action_click_progress'] = np.where(data_test['action_click_progress'] >= 1, 1,0)\ndata_test['action_close_courseware'] = np.where(data_test['action_close_courseware'] >= 1, 1,0)\ndata_test['action_delete_comment'] = np.where(data_test['action_delete_comment'] >= 1, 1,0)\ndata_test['action_load_video'] = np.where(data_test['action_load_video'] >= 1, 1,0)\ndata_test['action_pause_video'] = np.where(data_test['action_pause_video'] >= 1, 1,0)\ndata_test['action_play_video'] = np.where(data_test['action_play_video'] >= 1, 1,0)\ndata_test['action_problem_check_correct'] = np.where(data_test['action_problem_check_correct'] >= 1, 1,0)\ndata_test['action_problem_get'] = np.where(data_test['action_problem_get'] >= 1, 1,0)\ndata_test['action_problem_save'] = np.where(data_test['action_problem_save'] >= 1, 1,0)\ndata_test['action_seek_video'] = np.where(data_test['action_seek_video'] >= 1, 1,0)","415da8e2":"data_train.head(10)","1354e436":"data_test.head(10)","9762b07d":"train_length = len(data_train)\nprint(train_length)","4b2b789b":"data_train.head(10)","d041fc09":"data_train.tail(10)","d7db81af":"data_train1 = data_train.loc[:int(train_length\/2)] # Splitting data_train into two halves to make training efficient","70f23420":"data_train1.head(10)","58eb9c33":"data_train1.tail(10)","cbf3d092":"data_train2 = data_train.loc[(int(train_length\/2) + 1):]","fe965914":"data_train2.head(10)","92e9d2ef":"data_train2.tail(10)","0283efaa":"del data_train","9e9f01e3":"gc.collect()","e6aea45e":"train_labels1 = data_train1['truth']\ntrain_features1 = data_train1[['timestamp', 'time_difference',\n                            'action_click_about', 'action_click_courseware', 'action_click_forum', \n                             'action_click_info', 'action_click_progress', 'action_close_courseware', \n                             'action_delete_comment', 'action_load_video', 'action_pause_video', 'action_play_video', 'action_problem_check_correct',\n                             'action_problem_get', 'action_problem_save', 'action_seek_video']]\n\nx_train1 = train_features1\ny_train1 = np.ravel(train_labels1)","6902494d":"train_labels2 = data_train2['truth']\ntrain_features2 = data_train2[['timestamp', 'time_difference',\n                            'action_click_about', 'action_click_courseware', 'action_click_forum', \n                             'action_click_info', 'action_click_progress', 'action_close_courseware', \n                             'action_delete_comment', 'action_load_video', 'action_pause_video', 'action_play_video', 'action_problem_check_correct',\n                             'action_problem_get', 'action_problem_save', 'action_seek_video']]\n\nx_train2 = train_features2\ny_train2 = np.ravel(train_labels2)","42e295fc":"test_length = len(data_test)\nprint(test_length)","488b09fa":"data_test1 = data_test.loc[:int(test_length\/4)] # Splitting data_train to make testing efficient","6ac1ce13":"test_labels1 = data_test1['truth']\ntest_features1 = data_test1[['timestamp', 'time_difference',\n                            'action_click_about', 'action_click_courseware', 'action_click_forum', \n                             'action_click_info', 'action_click_progress', 'action_close_courseware', \n                             'action_delete_comment', 'action_load_video', 'action_pause_video', 'action_play_video', 'action_problem_check_correct',\n                             'action_problem_get', 'action_problem_save', 'action_seek_video']]\n\nx_test1 = test_features1\ny_test1 = np.ravel(test_labels1)","516e5efa":"model1 = xgb.XGBClassifier(\n    tree_method = 'gpu_hist'  # THE MAGICAL PARAMETER THAT INTEGRATES KAGGLE'S GPU ACCELERATED KERNEL\n)\n%time model1.fit(x_train1, y_train1) # Fitting the data into the model","fb7921b1":"# model1.save_model('model1.model')","2fe908f8":"%time y_pred1 = model1.predict(x_test1)\naccuracy1 = accuracy_score(y_test1, y_pred1)\nprint(\"Model 1 Accuracy: %.2f%%\" % (accuracy1 * 100.0))","e0bd38a3":"'''model2 = xgb.XGBClassifier()\nmodel2.fit(x_train2, y_train2)\ny_pred2 = model2.predict(x_test2)\naccuracy2 = accuracy_score(y_test2, predictions2)\nprint(\"Model 2 Accuracy: %.2f%%\" % (accuracy2 * 100.0))'''","4df4872c":"# model2_update = ","079135ed":"'''y_pred2_update = model2_update.predict(x_test2)\naccuracy2 = accuracy_score(y_test2, predictions2)\nprint(\"Model 2 Accuracy: %.2f%%\" % (accuracy2 * 100.0))'''","6a74a381":"'''model_loaded = xgb.XGBClassifier()\nbooster = xgb.Booster()\nbooster.load_model('..\/input\/mooc-final\/model1.model')\nmodel_loaded._Booster = booster\n\n%time y_pred1 = model_loaded.predict(x_test1) '''","e97fab35":"Importing Libraries","a193e0eb":"Loading the data","1ab1e828":"Data Wrangling and Feature Engineering","e8be14e3":"Setting Features and Labels from dataframes for Training","3f3f88b3":"Testing the trained model","777aee24":"Creating and Training a XGBClassifier() binary model","e2d83aab":"Setting Features and Labels from dataframes for Testing"}}