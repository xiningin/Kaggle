{"cell_type":{"c62495af":"code","904d25c4":"code","24b801d9":"code","bc1a7762":"code","4614ff8c":"code","a7429137":"code","22637621":"code","dd0c6fbf":"code","ff519347":"code","470d861e":"code","fe671167":"code","5ba7e60c":"code","73447766":"code","76e25396":"code","40658b01":"markdown","4033fc96":"markdown","2f06044a":"markdown","193123a5":"markdown","a57991f4":"markdown","a0abf522":"markdown","5790b7c0":"markdown","363181ba":"markdown","26a29b42":"markdown","8fbb48e6":"markdown","f343ddfe":"markdown","17d00366":"markdown","15fbe39c":"markdown"},"source":{"c62495af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","904d25c4":"from pathlib import Path \nfrom fastai import *\nfrom fastai.vision import *\nimport torch","24b801d9":"# stores Path of input directory to be used as an argument in fetching test and train \ndata_folder = Path(\"..\/input\")\ndata_folder.ls()","bc1a7762":"# Read CSV train and test files using Pandas\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/sample_submission.csv\")","4614ff8c":"# Load test images using from_df. Get the filenames in cols of test_df with folder in front of them\n# Read more: https:\/\/docs.fast.ai\/vision.data.html#ImageList.from_df\ntest_img = ImageList.from_df(test_df, path=data_folder\/'test', folder='test')","a7429137":"# do_flip = True --> a random flip is applied with probability 0.5\n# flip_vert = True --> requires do_flip = True, the image will be flipped vertically or rotated by 90 degrees\n# max_rotate = 10.0 --> random rotation between -10 to +10 with probability of p_affine\n# max_zoom = 1.1 --> random zoom applied between 1 and 1.1 with probability of p_affine\n# max_lighting = 0.2 --> lighting and contrast of magnitude between -0.2 and 0.2 applied with probability of p_lighting\n# max_wrap = 0.2 --> symmetric warp of magnitude between -0.2 and 0.2 with probability of p_affine\n# p_affine = 0.75 --> 0.75 probability used to apply max_rotate, max_zoom, max_wrap\n# p_lighting = 0.75 --> 0.75 probability used to apply max_lighting\n# Read more: https:\/\/docs.fast.ai\/vision.transform.html#get_transforms\ntrfm = get_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)","22637621":"train_img = (ImageList.from_df(train_df, path=data_folder\/'train', folder='train')  # load training images using from_df()\n        .split_by_rand_pct(0.01)                                                    # randomly puts 0.01 = 1% of data into validation set\n        .label_from_df()                                                            # fetches all labels with corresponding images. Only works with from_df()\n        .add_test(test_img)                                                         # adds test images\n        .transform(trfm, size=128)                                                  # transformation are applied to the training set\n        .databunch(path='.', bs=64, device= torch.device('cuda:0'))                 # creates DataBunch with batchsize = 64, and device = cuda index 0 GPU\n        .normalize(imagenet_stats)                                                  # using imagenet_stats to normalize the dataset. Other valid values are cifar_stats and mnist_stats\n       )","dd0c6fbf":"# Displays 2 rows of images from the training dataset\ntrain_img.show_batch(rows=2, figsize=(7,6))","ff519347":"# Using resnet18 base architecture for transfer learning and metrics as error_rate and accuracy.\n# The various models fastai offers for vision are torch models (https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html) + fastai models (https:\/\/docs.fast.ai\/vision.models.html)\n# Read more: https:\/\/docs.fast.ai\/vision.learner.html#cnn_learner\nlearn = cnn_learner(train_img, models.resnet18, metrics=[error_rate, accuracy])","470d861e":"learn.lr_find()\nlearn.recorder.plot()","fe671167":"lr = 3e-02\nlearn.fit_one_cycle(5, slice(lr))","5ba7e60c":"preds,_ = learn.get_preds(ds_type=DatasetType.Test)","73447766":"test_df.has_cactus = preds.numpy()[:, 0]","76e25396":"test_df.to_csv('submission_resnet_18.csv', index=False)","40658b01":"# Display sample data","4033fc96":"# Initialise directory path","2f06044a":"# Find learning rate","193123a5":"# Fit model using 1cycle policy\n### Read more: https:\/\/sgugger.github.io\/the-1cycle-policy.html","a57991f4":"# Submission","a0abf522":"# Prediction","5790b7c0":"# Load training images and preprocess","363181ba":"# Data augmentation preparation","26a29b42":"# Imports","8fbb48e6":"# Load train and test csvs","f343ddfe":"**Referred from https:\/\/www.kaggle.com\/kenseitrg\/simple-fastai-exercise**","17d00366":"# Load test images","15fbe39c":"# Transfer learning"}}