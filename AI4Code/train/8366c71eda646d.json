{"cell_type":{"8e44acad":"code","acaa8f4e":"code","75e05ecb":"code","8eeb7070":"code","d70af5dd":"code","84b7333f":"code","5746cf10":"code","1ecc1aba":"code","9c60ca01":"code","072ae7fd":"code","69746245":"code","e5c73bdb":"code","adc018ab":"code","08205c4d":"code","ed624e2c":"code","7c210224":"code","c6dac393":"code","e1e9a00b":"code","6da5cf7a":"code","07d46e66":"code","d5e04cbe":"code","d2619db5":"code","5db5084f":"code","a796a135":"code","6b062c8f":"code","0e1427e0":"code","ede8031b":"code","3114dcff":"markdown","cc976e6d":"markdown","ed911d2a":"markdown","ae0a25fd":"markdown","503950df":"markdown","dfc10eaf":"markdown","3c097753":"markdown","7d0c94da":"markdown","e9bb600a":"markdown"},"source":{"8e44acad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","acaa8f4e":"df = pd.read_csv(\"\/kaggle\/input\/caravan-insurance-challenge\/caravan-insurance-challenge.csv\")","75e05ecb":"df.head()","8eeb7070":"df.describe()","d70af5dd":"df.shape","84b7333f":"df.info()","5746cf10":"# Lets get the % of each null values.\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent_1 = df.isnull().sum()\/df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head()","1ecc1aba":"import matplotlib.pyplot as plt\nimport seaborn as sns","9c60ca01":"# Visualizing the NULL data using Seaborn HeatMap.\nsns.heatmap(df.isnull(), yticklabels = False, cbar = False)","072ae7fd":"categ_features = df.select_dtypes(include='object').columns\nnumeric_features = df.select_dtypes(include='int').columns\ndisplay(categ_features, numeric_features, len(categ_features), len(numeric_features))","69746245":"df['ORIGIN'].unique()\n# So this df data-set contains both train and test data.","e5c73bdb":"# Get the count of Train and Test data.\ndf['ORIGIN'].value_counts()","adc018ab":"# Get the count of Train and Test data.\ndf['CARAVAN'].value_counts()","08205c4d":"#Using Pearson Correlation\n\nplt.figure(figsize=(20,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","ed624e2c":"plt.figure(figsize=(20,5))\ndf.hist(column=numeric_features[1:5])\nplt.show()","7c210224":"# Split DataFrame in train and test\ntrain_df = df.loc[:5821]\ntest_df = df.loc[5822:]\ndisplay(train_df['ORIGIN'].unique(), test_df['ORIGIN'].unique())","c6dac393":"# Get the count of Train and Test data.\ndisplay(train_df['CARAVAN'].value_counts(), test_df['CARAVAN'].value_counts())","e1e9a00b":"# Split Train Data-set into train and valid data-sets, on which we will train our model. Before that will get our X and y.\n\nX = train_df.drop(['CARAVAN'], axis = 1)\n \ny = train_df['CARAVAN']\n \ndisplay(X.head(), y.head())    ","6da5cf7a":"# split the train_df into 2 DF's aka X_train, X_valid, y_train, y_valid.\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n\nprint (X_train.shape, y_train.shape)\nprint (X_valid.shape, y_valid.shape)\nprint(test_df.shape)","07d46e66":"# test_df \nX_test  = test_df.drop(['CARAVAN'], axis = 1)\ny_test = test_df['CARAVAN']\nprint (X_test.shape, y_test.shape)","d5e04cbe":"# Now we do have proper data splitting.. will drop the column 'ORIGIN'.\nX_train.drop('ORIGIN', inplace = True, axis = 1)\nX_valid.drop('ORIGIN', inplace = True, axis = 1)\nX_test.drop('ORIGIN', inplace = True, axis = 1)\n\nprint (X_train.shape, y_train.shape)\nprint (X_valid.shape, y_valid.shape)\nprint (X_test.shape, y_test.shape)","d2619db5":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","5db5084f":"# Model Performance matrix\nfrom sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, classification_report","a796a135":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","6b062c8f":"# Predict the model\n\nY_valid_pred_lr = logreg.predict(X_valid)\nY_test_pred_lr = logreg.predict(X_test)","0e1427e0":"print(\"LogisticRegression (on Train and Valid Data-Set) --> \")\nprint(\"Score : \", round(logreg.score(X_train, y_train) * 100, 2) )\n\nprint(\"Accuracy Score : \", round(accuracy_score(y_valid, Y_valid_pred_lr) * 100, 2) )\n\nprint(\"Confusion Matrix : \" )\ndisplay( confusion_matrix(y_valid, Y_valid_pred_lr) )\n\nprint(\"ROC AUC Score : \", roc_auc_score(y_valid, Y_valid_pred_lr) )\n","ede8031b":"print(\"LogisticRegression (Test Data-Set) --> \")\nprint(\"Score : \", round(logreg.score(X_test, y_test) * 100, 2) )\n\nprint(\"Accuracy Score : \", round(accuracy_score(y_test, Y_test_pred_lr) * 100, 2) )\n\nprint(\"Confusion Matrix : \" )\ndisplay( confusion_matrix(y_test, Y_test_pred_lr) )\n\nprint(\"ROC AUC Score : \", roc_auc_score(y_test, Y_test_pred_lr) )","3114dcff":"ORIGIN is the only field \/ column which is of Categorical type. Lets check its unique values.","cc976e6d":"** This is an Insurance Challenge **\nhttps:\/\/www.kaggle.com\/uciml\/caravan-insurance-challenge\n\nThis data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was collected to answer the following question: Can you predict who would be interested in buying a caravan insurance policy and give an explanation why?\n","ed911d2a":"# Split into Train and Test Data","ae0a25fd":"# Model Performance","503950df":"So we do have 5822 train and 4000 as test data. Will separate the data going forward.","dfc10eaf":"# Correlation Heatmap","3c097753":"Cool... No null values.","7d0c94da":"# Modeling","e9bb600a":"# Check the data-types"}}