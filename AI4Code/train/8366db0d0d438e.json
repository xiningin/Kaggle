{"cell_type":{"749546c2":"code","8d5a0b97":"code","4b60e6a1":"code","70291516":"code","1acd02b0":"code","cfaaf11e":"code","6cf311fb":"code","ac0dc8f7":"code","0d853698":"code","a95693bd":"code","90998e37":"code","6a001ad1":"code","fca236da":"code","cbdff57d":"code","0ce394c1":"code","ee5c4824":"code","544a4ba2":"code","eecc650a":"code","8fc280db":"code","727fc68e":"code","8c11759b":"code","edeb232d":"code","e3afcdc9":"code","503487a3":"code","90977dff":"code","a0292f1a":"code","d2515d05":"code","9d9b5c3f":"code","c82c1247":"code","119ac277":"code","691155a7":"code","7a625c87":"code","230ea7f8":"code","96c0e3ac":"code","e7a98cf6":"code","24bb288f":"code","596ab2ef":"markdown","dfa68010":"markdown","1d0a98bd":"markdown","81b815fa":"markdown","9d01a05a":"markdown","d38a6532":"markdown","3259665f":"markdown","055e514f":"markdown","ac09eefd":"markdown"},"source":{"749546c2":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.despine()\nplt.style.use(\"fivethirtyeight\")\nsns.set_style(\"darkgrid\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nimport emoji\nfrom wordcloud import WordCloud, STOPWORDS\nimport re,string, nltk\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom nltk.stem.snowball import SnowballStemmer\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")","8d5a0b97":"df = pd.read_csv(\"\/kaggle\/input\/cyberbullying-classification\/cyberbullying_tweets.csv\")\ndf.head()","4b60e6a1":"print(f\"Data has {df.shape[0]} rows and {df.shape[1]} columns.\")","70291516":"df = df.rename(columns={\"tweet_text\":\"text\",\"cyberbullying_type\":\"sentiment\"})","1acd02b0":"df.info()","cfaaf11e":"# percentage of null values in the dataset\n(df.isna().sum())\/(len(df))","6cf311fb":"df.sentiment.value_counts()","ac0dc8f7":"plt.figure(figsize=(14,5))\nsns.countplot(df.sentiment,palette=\"mako\")","0d853698":"# function for cleaning tweets\ndef clean_tweet(df,field):\n    df[field] = df[field].str.replace(r\"http\\S+\",\" \")\n    df[field] = df[field].str.replace(r\"http\",\" \")\n    df[field] = df[field].str.replace(r\"@\",\"at\")\n    df[field] = df[field].str.replace(\"#[A-Za-z0-9_]+\", ' ')\n    df[field] = df[field].str.replace(r\"[^A-Za-z(),!?@\\'\\\"_\\n]\",\" \")\n    df[field] = df[field].str.lower()\n    return df","a95693bd":"clean_tweet(df,\"text\")","90998e37":"# Applying Lemmmatizer to remove tenses from texts.\nlemmatizer = WordNetLemmatizer()\nstemmer = SnowballStemmer(\"english\")\nSTOPWORDS.update(['rt', 'mkr', 'didn', 'bc', 'n', 'm', \n                  'im', 'll', 'y', 've', 'u', 'ur', 'don', \n                  'p', 't', 's', 'aren', 'kp', 'o', 'kat', \n                  'de', 're', 'amp', 'will'])\ncorpus = []\ndef preprocess_tweet(tweet):\n    tweet = re.sub(r\"won\\'t\", \"will not\", tweet)\n    tweet = re.sub(r\"can\\'t\", \"can not\", tweet)\n    tweet = re.sub(r\"n\\'t\", \" not\", tweet)\n    tweet = re.sub(r\"\\'re\", \" are\", tweet)\n    tweet = re.sub(r\"\\'s\", \" is\", tweet)\n    tweet = re.sub(r\"\\'d\", \" would\",tweet)\n    tweet = re.sub(r\"\\'ll\", \" will\", tweet)\n    tweet = re.sub(r\"\\'t\", \" not\", tweet)\n    tweet = re.sub(r\"\\'ve\", \" have\", tweet)\n    tweet = re.sub(r\"\\'m\", \" am\", tweet)\n    tweet = re.sub('[^a-zA-Z]',' ',tweet)\n    tweet = re.sub(emoji.get_emoji_regexp(),\"\",tweet)\n    tweet = re.sub(r'[^\\x00-\\x7f]','',tweet)\n    tweet = \" \".join([stemmer.stem(word) for word in tweet.split()])\n    tweet = [lemmatizer.lemmatize(word) for word in tweet.split() if not word in set(STOPWORDS)]\n    tweet = ' '.join(tweet)\n    return tweet\n\ndf[\"text_clean\"] = df[\"text\"].apply(preprocess_tweet)","6a001ad1":"df[\"text_clean\"].duplicated().sum()","fca236da":"df.drop_duplicates(\"text_clean\", inplace=True)","cbdff57d":"# removing other_cyberbullying category as it doesnot contribute much.\ndf = df[df[\"sentiment\"]!=\"other_cyberbullying\"]","0ce394c1":"df.shape","ee5c4824":"# Calculating tweet length\ntweet_len = pd.Series([len(tweet.split())for tweet in df[\"text\"]])\nplt.figure(figsize=(8,5))\ntweet_len.plot(kind=\"box\")\nplt.ylabel(\"Tweet Length\")","544a4ba2":"plt.figure(figsize=(12,8))\nsns.histplot(tweet_len,palette=\"deep\")","eecc650a":"df[\"Length\"] = df.text_clean.str.split().apply(len)\nplt.figure(figsize=(14,7))\nsns.histplot(df[df[\"sentiment\"]==\"not_cyberbullying\"]['Length'],color=\"g\")\nplt.title(\"Distribution of Tweet Length for not_cyberbullying\")\ndisplay(df.Length[df[\"sentiment\"]==\"not_cyberbullying\"].describe())","8fc280db":"plt.figure(figsize=(14,7))\nsns.histplot(df[df[\"sentiment\"]==\"gender\"][\"Length\"],color=\"r\")\nplt.title(\"Distribution of Tweet length for Gender\")\ndisplay(df.Length[df[\"sentiment\"]==\"gender\"].describe())","727fc68e":"plt.figure(figsize=(14,7))\nsns.histplot(df[df[\"sentiment\"]==\"religion\"][\"Length\"],color=\"y\")\nplt.title(\"Distribution of Tweet length for Religion\")\ndisplay(df.Length[df[\"sentiment\"]==\"religion\"].describe())","8c11759b":"plt.figure(figsize=(14,7))\nsns.histplot(df[df[\"sentiment\"]==\"age\"][\"Length\"], color=\"b\")\nplt.title('Distribution of Tweet length for Age')\ndisplay(df.Length[df[\"sentiment\"]==\"age\"].describe())","edeb232d":"plt.figure(figsize=(14,7))\nsns.histplot(df[df[\"sentiment\"]==\"ethnicity\"][\"Length\"], color=\"b\")\nplt.title('Distribution of Tweet length for Ethnicity')\ndisplay(df.Length[df[\"sentiment\"]==\"ethnicity\"].describe())","e3afcdc9":"plt.figure(figsize=(20,20))\nwc = WordCloud(max_words=2000,min_font_size=10, height=800,width=1600,\n               background_color=\"white\").generate(\" \".join(df[df[\"sentiment\"]==\"not_cyberbullying\"].text_clean))\nplt.imshow(wc)","503487a3":"plt.figure(figsize=(20,20))\nwc1 = WordCloud(max_words=2000, min_font_size=10,height=800,width=1600,\n        background_color=\"white\").generate(\" \".join(df[df[\"sentiment\"]==\"gender\"].text_clean))\nplt.imshow(wc1)","90977dff":"plt.figure(figsize=(20,20))\nwc2 = WordCloud(max_words=2000, min_font_size=10, height=800, width=1600, \n        background_color=\"white\").generate(\" \".join(df[df[\"sentiment\"]==\"religion\"].text_clean))\nplt.imshow(wc2)","a0292f1a":"plt.figure(figsize=(20,20))\nwc3 = WordCloud(max_words=2000, min_font_size=10, height=800, width=1600,\n            background_color=\"white\").generate(\" \".join(df[df[\"sentiment\"]==\"ethnicity\"].text_clean))\nplt.imshow(wc3)","d2515d05":"df.head()","9d9b5c3f":"df.sentiment.value_counts()","c82c1247":"labels = {\"not_cyberbullying\":0,\"gender\":1,\"ethnicity\":2,\"religion\":3,\"age\":4}\nlabels","119ac277":"corpus, target_labels, target_names = (df['text_clean'], [labels[label] for label in df['sentiment']],df['sentiment'])\ndf_new = pd.DataFrame({\"text_clean\":corpus,\"sentiment Label\": target_labels,\"sentiment names\": target_names})\ndf_new","691155a7":"corpus","7a625c87":"X_train, X_test, y_train, y_test = train_test_split(np.array(df_new[\"text_clean\"]),np.array(df_new[\"sentiment Label\"]), test_size=0.25, random_state=0)\ndisplay(X_train.shape)\ndisplay(X_test.shape)","230ea7f8":"(unique, counts) = np.unique(y_train, return_counts=True)\nnp.asarray((unique, counts)).T","96c0e3ac":"tfidf = TfidfVectorizer(use_idf=True, tokenizer=word_tokenize,min_df=0.00002,max_df=0.70)\nX_train_tf = tfidf.fit_transform(X_train.astype('U'))\nX_test_tf = tfidf.transform(X_test.astype('U'))\n\nprint(f\"TF_IDF Model: Train features shape:{X_train_tf.shape} and Test features shape:{X_test_tf.shape}\")","e7a98cf6":"rf = RandomForestClassifier(random_state=42)\ngb = GradientBoostingClassifier(random_state=42)\nada = AdaBoostClassifier(random_state=42)\nlgb = LGBMClassifier(random_state=42)\nxgb = XGBClassifier(eval_metric=\"mlogloss\",random_state=42)\ndt = DecisionTreeClassifier(random_state=42)\nsvc = SVC(random_state=42)\nnb = MultinomialNB()\nmlp = MLPClassifier(random_state=42)\n\nclfs = {\n    \"Random Forest\": rf,\n    \"Gradient Boosting\":gb,\n    \"AdaBoost\": ada,\n    \"LightGBM\": lgb,\n    \"XGBoost\": xgb,\n    \"Decision Tree\":dt,\n    \"Support Vector Machine\":svc,\n    \"Naive Bayes\": nb,\n    \"Multilayer Perceptron\":mlp\n}\n\ndef fit_model(clf,x_train,y_train,x_test, y_test):\n    clf.fit(x_train,y_train)\n    y_pred = clf.predict(x_test)\n    accuracy = accuracy_score(y_pred, y_test)\n    return accuracy\n\naccuracys = []\n#precisions = []\n\nfor name,clf in clfs.items():\n    curr_acc = fit_model(clf,X_train_tf,y_train,X_test_tf,y_test)\n    accuracys.append(curr_acc)\n  #  precisions.append(curr_pre)","24bb288f":"models_df = pd.DataFrame({\"Models\":clfs.keys(),\"Accuracy Scores\":accuracys}).sort_values('Accuracy Scores',ascending=False)\nmodels_df","596ab2ef":"### Splitting Data into Training and Testing set","dfa68010":"* **Random Forest has the highest Accuracy of around 93.3%**","1d0a98bd":"# EDA","81b815fa":"## WordCloud","9d01a05a":"## Model Building","d38a6532":"# Cyberbullying Tweets Analysis","3259665f":"## NLP Procedure\n* Cleaning of text\n* Lemmatization\n* TF-IDF","055e514f":"* Class seems to be balanced. So, no need for oversampling or undersampling.","ac09eefd":"##  TF-IDF"}}