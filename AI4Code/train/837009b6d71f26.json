{"cell_type":{"e86b1096":"code","bd6a809a":"code","3f775951":"code","3a9a4c70":"code","6e3cbf0d":"code","417ca7dc":"code","94b6b108":"code","f1b23e5a":"code","b5ac8567":"code","a59e6f17":"code","f1f0df9b":"code","e141d18c":"code","9c58c2b6":"code","26bd3ea5":"code","f24a90cf":"code","fae6a94f":"code","3490dc3a":"code","e7ed4aa4":"code","3635f8d0":"code","e07b540e":"markdown","12803aab":"markdown","bcd9d890":"markdown","1c59d006":"markdown","a88e67aa":"markdown","46a195f8":"markdown","b59d2f60":"markdown","1819f560":"markdown","bb6a67bc":"markdown","260dd97b":"markdown","6b44aa50":"markdown"},"source":{"e86b1096":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import hstack\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport eli5","bd6a809a":"train = pd.read_csv('..\/input\/train.csv', index_col='id').fillna(' ')\nvalid = pd.read_csv('..\/input\/valid.csv', index_col='id').fillna(' ')\ntest = pd.read_csv('..\/input\/test.csv', index_col='id').fillna(' ')","3f775951":"train.head()","3a9a4c70":"train_val = pd.concat([train, valid])","6e3cbf0d":"sns.countplot(train_val['label']);\nplt.title('Train+val: Target distribution');","417ca7dc":"plt.subplots(1, 2)\nplt.subplot(1, 2, 1)\ntrain_val['text'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Train & val');\nplt.subplot(1, 2, 2)\ntest['text'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Test');","94b6b108":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train_val[\"text\"], title=\"Word Cloud of reviews\")","f1b23e5a":"text_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=True, max_features=150000)","b5ac8567":"%%time\nX_train_text = text_transformer.fit_transform(train_val['text'])\nX_test_text = text_transformer.transform(test['text'])","a59e6f17":"X_train_text.shape, X_test_text.shape","f1f0df9b":"logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial', random_state=17, n_jobs=4)","e141d18c":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)","9c58c2b6":"%%time\ncv_results = cross_val_score(logit, X_train_text, train_val['label'], cv=skf, scoring='f1_micro')","26bd3ea5":"cv_results, cv_results.mean()","f24a90cf":"%%time\nlogit.fit(X_train_text, train_val['label'])","fae6a94f":"eli5.show_weights(estimator=logit, \n                  feature_names= list(text_transformer.get_feature_names()),\n                 top=(50, 5))","3490dc3a":"test_preds = logit.predict(X_test_text)","e7ed4aa4":"pd.DataFrame(test_preds, columns=['label']).head()","3635f8d0":"pd.DataFrame(test_preds, columns=['label']).to_csv('logit_tf_idf_starter_submission.csv',\n                                                  index_label='id')","e07b540e":"**Trying to interpret model weights with ELI5 - look reasonable.**","12803aab":"We'll be using a Tf-Idf vectorizer.","bcd9d890":"We can see that test texts are in general shorter.","1c59d006":"**Cross-validation**","a88e67aa":"As for the model, let's simply pick logistic regression.","46a195f8":"As an entertainment, we can build a wordcloud for reviews. However, no useful insights from such pictures.","b59d2f60":"**What you can try next**\n\n - tune hyperparams, those of `TfIdfVectorizers` as well\n - add Word2Vec\/GloVE\/Fasttext embeddings, at least for titles\n - switch to ULMFiT and other heavy stuff\n ","1819f560":"It's nice to see that cross-validation is more or less stable across folds. Let's train the model on train + val.","bb6a67bc":"**Preparing submission.**","260dd97b":"Tf-Idf + Logistic regression is a very nice baseline for many tasks. Here we'll briefly explore the given dataset and then we'll build a simple baseline based on Tf-Idf representations of product reviews. Further we'll compare heavier approaches (like ULMFiT) with this baseline.","6b44aa50":"We'll be validating with train + validation files."}}