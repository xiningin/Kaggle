{"cell_type":{"0f735e64":"code","890db759":"code","83ed08dc":"code","21a1f278":"code","837123af":"code","7d6f8e38":"code","ac7ac79c":"code","a582001b":"code","bf4b00e2":"code","7a897b34":"code","efe28fa5":"markdown","d6874c03":"markdown","a1325c9d":"markdown"},"source":{"0f735e64":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","890db759":"\n\nimport keras\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nimport sklearn\nimport itertools\nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport csv\nfrom tqdm import tqdm\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n#from keras.applications.mobilenet import MobileNet\n#from sklearn.metrics import roc_auc_score\n#from sklearn.metrics import roc_curve\n#from sklearn.metrics import auc\n#import warnings\n#warnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\n","83ed08dc":"imageSize=50\ntrain_dir = \"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/\"\ntest_dir =  \"..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test\/\"\nfrom tqdm import tqdm\ndef get_data(folder):\n    \"\"\"\n    Load the data and labels from the given folder.\n    \"\"\"\n    X = []\n    y = []\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['A']:\n                label = 0\n            elif folderName in ['B']:\n                label = 1\n            elif folderName in ['C']:\n                label = 2\n            elif folderName in ['D']:\n                label = 3\n            elif folderName in ['E']:\n                label = 4\n            elif folderName in ['F']:\n                label = 5\n            elif folderName in ['G']:\n                label = 6\n            elif folderName in ['H']:\n                label = 7\n            elif folderName in ['I']:\n                label = 8\n            elif folderName in ['J']:\n                label = 9\n            elif folderName in ['K']:\n                label = 10\n            elif folderName in ['L']:\n                label = 11\n            elif folderName in ['M']:\n                label = 12\n            elif folderName in ['N']:\n                label = 13\n            elif folderName in ['O']:\n                label = 14\n            elif folderName in ['P']:\n                label = 15\n            elif folderName in ['Q']:\n                label = 16\n            elif folderName in ['R']:\n                label = 17\n            elif folderName in ['S']:\n                label = 18\n            elif folderName in ['T']:\n                label = 19\n            elif folderName in ['U']:\n                label = 20\n            elif folderName in ['V']:\n                label = 21\n            elif folderName in ['W']:\n                label = 22\n            elif folderName in ['X']:\n                label = 23\n            elif folderName in ['Y']:\n                label = 24\n            elif folderName in ['Z']:\n                label = 25\n            elif folderName in ['del']:\n                label = 26\n            elif folderName in ['nothing']:\n                label = 27\n            elif folderName in ['space']:\n                label = 28           \n            else:\n                label = 29\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '\/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)\n                    y.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y\nX_train, y_train = get_data(train_dir) \n#X_test, y_test= get_data(test_dir) # Too few images\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2) \n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(y_train, num_classes = 30)\ny_testHot = to_categorical(y_test, num_classes = 30)","21a1f278":"def plotHistogram(a):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    plt.imshow(a)\n    plt.axis('off')\n    histo = plt.subplot(1,2,2)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\nplotHistogram(X_train[1])\n\n","837123af":"print(\"A\")\nmultipleImages = glob('..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/A\/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","7d6f8e38":"print(\"B\")\nmultipleImages = glob('..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/B\/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","ac7ac79c":"\n\nmap_characters = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', 27: 'nothing', 28: 'space', 29: 'other'}\ndict_characters=map_characters\nimport seaborn as sns\ndf = pd.DataFrame()\ndf[\"labels\"]=y_train\nlab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)\n\n","a582001b":"###using TensorFlow > keras > CNN\n\nimport tensorflow as tf\n\nmap_characters1 = map_characters\n# Define the Model and train it normally\n\nmodel = tf.keras.Sequential()\n# Must define the input shape in the first layer of the neural network\nmodel.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu', input_shape=(50, 50, 3))) \nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=2))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=2))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=2))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(30, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\nmodel.fit(X_train, y_trainHot, epochs=12,batch_size=64)\n\n#save model\n###This is only the model on Training Dataset. We will use this MODEL in our software. Yet we can also do something els\n\nmodel.save_weights(\"ASL_model.h5\")","bf4b00e2":"print(tf.__version__)\n","7a897b34":"#### That saved model is on training dataset.\n\n#### We can test our model on testing dataset to see it's accuracy on UNSEEN DATASET.\n\n\n#####upadate, try, commit, git, think about what else","efe28fa5":"* This part is basically the starting point of kaggle\n","d6874c03":"24.12.19\nthis was the result...\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 50, 50, 64)        4864      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 25, 25, 64)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 25, 25, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 25, 25, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 12, 12, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 12, 12, 16)        4624      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 16)          0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 6, 6, 16)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 576)               0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               147712    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                7710      \n=================================================================\nTotal params: 183,374\nTrainable params: 183,374\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 69600 samples\nEpoch 1\/12\n69600\/69600 [==============================] - 253s 4ms\/sample - loss: 2.3458 - accuracy: 0.3002\nEpoch 2\/12\n69600\/69600 [==============================] - 249s 4ms\/sample - loss: 1.0475 - accuracy: 0.6486\nEpoch 3\/12\n69600\/69600 [==============================] - 251s 4ms\/sample - loss: 0.7439 - accuracy: 0.7450\nEpoch 4\/12\n69600\/69600 [==============================] - 252s 4ms\/sample - loss: 0.5699 - accuracy: 0.8017\nEpoch 5\/12\n69600\/69600 [==============================] - 249s 4ms\/sample - loss: 0.4795 - accuracy: 0.8319\nEpoch 6\/12\n69600\/69600 [==============================] - 253s 4ms\/sample - loss: 0.4231 - accuracy: 0.8540\nEpoch 7\/12\n69600\/69600 [==============================] - 253s 4ms\/sample - loss: 0.3680 - accuracy: 0.8714\nEpoch 8\/12\n69600\/69600 [==============================] - 252s 4ms\/sample - loss: 0.3411 - accuracy: 0.8813\nEpoch 9\/12\n69600\/69600 [==============================] - 252s 4ms\/sample - loss: 0.3212 - accuracy: 0.8892\nEpoch 10\/12\n69600\/69600 [==============================] - 252s 4ms\/sample - loss: 0.2914 - accuracy: 0.8990\nEpoch 11\/12\n69600\/69600 [==============================] - 252s 4ms\/sample - loss: 0.2705 - accuracy: 0.9078\nEpoch 12\/12\n69600\/69600 [==============================] - 254s 4ms\/sample - loss: 0.2607 - accuracy: 0.9106\n","a1325c9d":"![Forking ASL and Creating Kernel](http:\/\/)\n"}}