{"cell_type":{"2e5e8fb0":"code","0ca10f4d":"code","9bce043d":"code","2f9384b1":"code","c72e3f29":"code","e29f5c19":"code","64454317":"code","dc2fb04d":"code","a669ad62":"code","9ff5a17d":"code","510cf673":"code","5c3f8cb1":"code","03f6d533":"code","2e0eeb58":"code","986e694e":"code","4ee7010f":"code","6ac46344":"code","3b172944":"code","2a2b3a21":"code","ebddb26d":"code","d3bf1c0a":"code","f13c0262":"code","a6ea9020":"code","ece2a46c":"code","854a1d75":"code","89f178eb":"code","c3335d66":"code","63b2a855":"code","99d59948":"code","0b624510":"code","06b50758":"code","5d9a677b":"code","60c506f0":"code","745f5c02":"code","2f31ced2":"code","4f131861":"code","8e79dc6c":"code","ad9e111d":"code","55a650a8":"code","45aa83d4":"code","4fa23039":"code","474642fc":"code","b05daa1b":"code","07a306ad":"code","9ed4b0f7":"code","2b023f30":"code","d01f9872":"markdown","87ac63ec":"markdown","d9c79842":"markdown","c7ceeadb":"markdown","ae3cdfec":"markdown","fe48618e":"markdown","7bc8cce2":"markdown","d756e15f":"markdown","b2bb3327":"markdown","34eb5831":"markdown","299083a6":"markdown","4e9bc09e":"markdown","288c4017":"markdown","79b7cb94":"markdown","8fc3f976":"markdown","9c5b2a60":"markdown","369f8bff":"markdown","8c791240":"markdown","555ed934":"markdown","f35a9c04":"markdown","865cf2a0":"markdown","f2e66ac1":"markdown","1c50538d":"markdown","65fc6e39":"markdown","2f6213b2":"markdown"},"source":{"2e5e8fb0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0ca10f4d":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain = train.append(test)","9bce043d":"train","2f9384b1":"train.info()","c72e3f29":"import missingno as msno\nmsno.bar(train, color='darkblue')","e29f5c19":"train['Cabin'].value_counts()","64454317":"train['Cabin'].fillna(0).value_counts()","dc2fb04d":"train.drop('Cabin', axis=1, inplace=True)","a669ad62":"train[train['Embarked'].isnull()]","9ff5a17d":"train['Embarked'].fillna('Unknown', inplace=True)","510cf673":"train[train['Age'].isnull()]","5c3f8cb1":"train.groupby(['Pclass', 'Sex']).mean()","03f6d533":"def impude_age(cols):\n    Age=cols[0]\n    Pclass = cols[1]\n    Sex = cols[2]\n    if pd.isnull(Age):\n        if Pclass == 1 and Sex =='male':\n            return 41\n        elif Pclass == 1 and Sex =='female':\n            return 34\n        elif Pclass == 2 and Sex =='male':\n            return 31\n        elif Pclass == 2 and Sex =='female':\n            return 29\n        elif Pclass == 3 and Sex =='male':\n            return 27\n        else:\n            return 22\n    else:\n        return Age","2e0eeb58":"train['Age'] = train[['Age', 'Pclass', 'Sex']].apply(impude_age, axis=1)","986e694e":"msno.bar(train, color='green')","4ee7010f":"train.drop(['Name', 'Ticket'], axis=1, inplace=True)","6ac46344":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain['Sex'] = le.fit_transform(train['Sex'])\ntrain['Embarked'] = le.fit_transform(train['Embarked'])","3b172944":"test = train[891:].drop('Survived',axis=1)\ntrain = train[:891]","2a2b3a21":"test.info()","ebddb26d":"train.info()","d3bf1c0a":"a= train.corr()\nplt.figure(figsize=(14,8))\nsns.heatmap(a.corr(), annot=True, cmap='coolwarm')","f13c0262":"fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(10,5))\na = sns.scatterplot(x='PassengerId', y='Fare', data=train,ax=ax[0][0], color='darkred', s=100)\nb = sns.scatterplot(x='PassengerId', y='Age', data=train,ax=ax[0][1], color='darkgreen', s=100)\nc = sns.scatterplot(x='PassengerId', y='Embarked', data=train,ax=ax[1][0], color='darkred', s=100)\nd = sns.scatterplot(x='PassengerId', y='Parch', data=train,ax=ax[1][1], color='darkred', s=100)\n\na.set_title('Fare Outliers', fontsize=20)\nb.set_title('Age Outliers', fontsize=20)\nc.set_title('Embarked Outliers', fontsize=20)\nd.set_title('Parch Outliers', fontsize=20)\n\n\n\nplt.tight_layout()","a6ea9020":"q_hi_f = train['Fare'].quantile(0.95)\nq_low_f = train['Fare'].quantile(0)\ntrain_1 = train[(train['Fare'] >= q_low_f) & (train['Fare']<q_hi_f)]","ece2a46c":"q_hi_e = train_1['Embarked'].quantile(0.9999)\nq_low_e = train_1['Embarked'].quantile(0)\ntrain_2 = train_1[(train_1['Embarked'] >= q_low_e) & (train_1['Embarked']<q_hi_e)]","854a1d75":"q_hi_p = train_2['Parch'].quantile(0.97)\nq_low_p = train_2['Parch'].quantile(0)\ntrain_3 = train_2[(train_2['Parch'] >= q_low_p) & (train_2['Parch']<=q_hi_p)]","89f178eb":"fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(10,5))\na = sns.scatterplot(x='PassengerId', y='Fare', data=train_3,ax=ax[0][0], color='darkgreen', s=100)\nb = sns.scatterplot(x='PassengerId', y='Age', data=train_3,ax=ax[0][1], color='darkgreen', s=100)\nc = sns.scatterplot(x='PassengerId', y='Embarked', data=train_3,ax=ax[1][0], color='darkgreen', s=100)\nd = sns.scatterplot(x='PassengerId', y='Parch', data=train_3,ax=ax[1][1], color='darkgreen', s=100)\n\na.set_title('Fare Outliers', fontsize=20)\nb.set_title('Age Outliers', fontsize=20)\nc.set_title('Embarked Outliers', fontsize=20)\nd.set_title('Parch Outliers', fontsize=20)\n\n\n\nplt.tight_layout()","c3335d66":"train_3 = train_3.drop('PassengerId',axis=1)\ntest_1 = test.drop(['PassengerId'],axis=1)","63b2a855":"train_3['Survived'].value_counts()","99d59948":"train_3.columns","0b624510":"from imblearn.over_sampling import SMOTE\nos = SMOTE()\nX_train, y_train  = os.fit_resample(train_3[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n       'Embarked']], train_3['Survived'])","06b50758":"y_train.value_counts()","5d9a677b":"from sklearn.preprocessing import MinMaxScaler\nmn = MinMaxScaler()\nX_train_scaled = mn.fit_transform(X_train)\nX_test_scaled = mn.transform(test_1)","60c506f0":"X_train_scaled = pd.DataFrame(X_train_scaled, columns=[X_train.columns])\nX_train_scaled","745f5c02":"X_test_scaled = pd.DataFrame(X_test_scaled, columns=test_1.columns)\nX_test_scaled","2f31ced2":"val_test_X = X_train_scaled[:300]\nval_test_y = y_train[:300]\nX_train_scaled_2 = X_train_scaled[300:]\ny_train_scaled_2 = y_train[300:]","4f131861":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","8e79dc6c":"model = Sequential()\nmodel.add(Dense(units= 7, activation='relu'))\n#model.add(Dropout(0.5))\n#model.add(Dense(units= 14, activation='relu'))\n#model.add(Dropout(0.5))\nmodel.add(Dense(units= 3, activation='relu'))\nmodel.add(Dense(units=1,kernel_initializer='uniform', activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n#early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40)","ad9e111d":"model.fit(x=X_train_scaled_2, y=y_train_scaled_2, epochs=1000, batch_size=200,\n          validation_data=(val_test_X, val_test_y)) #callbacks=early_stopping)","55a650a8":"pd.DataFrame(model.history.history).plot()","45aa83d4":"p = model.predict_classes(X_test_scaled)\np = pd.DataFrame(p)","4fa23039":"predictions = pd.concat([test, p], axis=1)\n#predictions = predictions.drop('Survived', axis=1)\npredictions = predictions.rename(columns={0:'Survived'})\npredictions = predictions[['PassengerId', 'Survived']]\npredictions","474642fc":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","b05daa1b":"X_test_scaled['Fare'] = X_test_scaled['Fare'].fillna(X_test_scaled['Fare'].mean())\nX_test_scaled.info()","07a306ad":"X = X_train_scaled[['Pclass', 'Sex', 'Fare', 'Age', 'Parch', 'Embarked', 'SibSp']]\ny = pd.DataFrame(y_train)\nrfc = RandomForestClassifier(n_estimators=500, max_depth=7)\nrfc.fit(X, y)\npredict = rfc.predict(X_test_scaled[['Pclass', 'Sex', 'Fare', 'Age', 'Parch', 'Embarked', 'SibSp']])","9ed4b0f7":"a = pd.DataFrame(test['PassengerId'])\nb = pd.DataFrame(predict, columns=['Survived'])\nprediction = pd.concat([a, b], axis=1)\nprediction","2b023f30":"prediction.to_csv('Predictions.csv', index=False)","d01f9872":"# Exploratory Analysis","87ac63ec":"* We can see that random forest classifier, decision tree and XGBoost have performed nearly the same.\n* We will chose one of these as they have showed good results.","d9c79842":"* Checking to see if all the columns are now equal\n* Seems like everything is fine here","c7ceeadb":"# Data Analyzing","ae3cdfec":"# Analyzing Train Set for Outliers","fe48618e":"# Age Column","7bc8cce2":"* The analysis for outliers show that Fare, Embarked and Parch column have some outliers. \n* We will try to remove these outlier rows in each of the columns to make sure our analysis is accurate\n* Outliers can really influence the final model.\n* they tend to drag averages up or down and can really change the predictive capabilities of the model.","d756e15f":"# Embarked Column","b2bb3327":"# Predictive Analysis Machine Learning","34eb5831":"# Oversampling Analysis for Train Set","299083a6":"1. It seems that there are many missing values (687) \n2. We will have to drop this column as there seems to be no rrelevance of this column to predict survivors.  ","4e9bc09e":"* Changing the datatypes to numeric for Embarked and Sex","288c4017":"* As we can see in the above visuals now that the outliers have been very thoroughly removed \n* each column is dealt seperately to cut out the outliers which might create noise in the model\n* All this data is now around cleaned from extreme values!","79b7cb94":"* Three columns need engineering: Cabin, Embarked and Age\n* We will try to fix them in the best possible way we can ","8fc3f976":"* The issue of oversampling is now resolved.\n* Both the labels have now equal count of values that will be inserted in the model","9c5b2a60":"* The data is now scaled \n* We are now ready to apply this data to a model","369f8bff":"# Scaling the data","8c791240":"* We will delete the passengerId column now since we do not need it anymore. \n* We required it before to do the outlier analysis","555ed934":"* There are imbalances in the fields\n* The problem of oversampling will occur in the model\n* This is because we have more labels of one type.\n* To fix this we will need to balance the dataset. \n* This can be done by oversampling analysis","f35a9c04":"#  Predictive Model..Working on it right now","865cf2a0":"* Now that the feature engineering is done\n* We will split the two sets back again.\n* Train and Test sets","f2e66ac1":"* Filling Embarked column with unknown as there are only two rows. \n* We will not drop the column as there are sufficient rows to keep them in our analysis. ","1c50538d":"* Age had some of the missing values.\n* These were filled in using a special formula\n* This formula took into account the PClass and Sex Column to define the missing age\n* For example a person with PClass of A and Sex 'Male' will have the average of 41\n* 41 came from the groupby that we performed earlier right before the formula above","65fc6e39":"# Cabin Column ","2f6213b2":"* Dropping these columns as they do not carry any significance."}}