{"cell_type":{"50bb9a2c":"code","baa8fbb9":"code","b6433f1d":"code","e5925a26":"code","743083b8":"code","348f12d7":"code","83e58796":"code","f2582e82":"code","758f61e6":"code","5becd5af":"code","5d3f31c5":"code","b7fba0a7":"code","c595ea3a":"code","5aa98062":"code","19375325":"code","90fb10ba":"code","3ca4caa9":"code","6007e913":"code","006dc44f":"code","cb3ab88a":"code","d1536f24":"code","f708280d":"code","cd3b023d":"code","c96ee05b":"code","5efe75a6":"code","6a551368":"code","dd55d2c1":"code","1e18126e":"code","9dbe214e":"code","ba56324e":"code","4e8fde9c":"code","1099940e":"code","f1dd6908":"code","ac58ff29":"code","7da2145e":"code","2a04484e":"code","b895738f":"code","d5481224":"code","008639a4":"code","74fbf655":"code","d1b4e4bf":"code","5455459c":"code","55535c59":"code","483c9b59":"code","177a66ed":"code","6ba27f08":"markdown","de6eb5b2":"markdown","cb9a7895":"markdown","6f1cba57":"markdown","a4edfd27":"markdown","f943c8eb":"markdown"},"source":{"50bb9a2c":"import cv2 as cv\nfrom IPython.display import Video, display\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nimport subprocess\n\nplt.rcParams['figure.dpi'] = 150\nfrom PIL import Image\n\n\n%matplotlib inline\nfrom IPython.display import Video, display\n\n#block those warnings from pandas about setting values on a slice\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\n\n","baa8fbb9":"image_train = pd.read_csv(\"..\/input\/nfl-impact-detection\/image_labels.csv\")\nimage_train.head()","b6433f1d":"im = cv.imread(\"..\/input\/nfl-impact-detection\/images\/\" + image_train[\"image\"][0])\nplt.imshow(im)","e5925a26":"# Set the name of our working image\nimg_name = image_train['image'][0]\nimg_name","743083b8":"# Define the path to our selected image\nimg_path = f\"\/kaggle\/input\/nfl-impact-detection\/images\/{img_name}\"","348f12d7":"image_path = '..\/input\/nfl-impact-detection'","83e58796":"\nimage_train.info()","f2582e82":"import seaborn as sns","758f61e6":"video_train = pd.read_csv(\"..\/input\/nfl-impact-detection\/train_labels.csv\")\nvideo_train.head()","5becd5af":"video_train.query(\"impact == 1\")","5d3f31c5":"!ls ..\/input\/nfl-impact-detection\/train","b7fba0a7":"display(Video(data=\"\/kaggle\/input\/nfl-impact-detection\/train\/58098_001193_Endzone.mp4\", embed=True))\n","c595ea3a":"video = cv.VideoCapture(\"\/kaggle\/input\/nfl-impact-detection\/train\/58098_001193_Endzone.mp4\")","5aa98062":"print(\"Width\", video.get(cv.CAP_PROP_FRAME_WIDTH))\n\nprint(\"Height\",video.get(cv.CAP_PROP_FRAME_HEIGHT))\n\nprint(\"FPS\",video.get(cv.CAP_PROP_FPS))\n\nprint(\"Frame Count\",video.get(cv.CAP_PROP_FRAME_COUNT))","19375325":"ret, frame = video.read()\nplt.imshow(frame)","90fb10ba":"video.set(cv.CAP_PROP_POS_FRAMES, 100)\nret, frame = video.read()\nplt.imshow(frame)","3ca4caa9":"tracking_train = pd.read_csv(\"..\/input\/nfl-impact-detection\/train_player_tracking.csv\")\ntracking_train.head()","6007e913":"\ntracking_train.shape","006dc44f":"import numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import patches\nfrom PIL import Image\n\nimport os\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\n\nimport torch\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor","cb3ab88a":"DATA_PATH = '..\/input\/nfl-impact-detection'","d1536f24":"def add_bboxes(ax, img, img_df):\n    img_data = img_df[img_df['image'] == img]\n    for i in range(img_data.shape[0]):\n        data = img_data.iloc[i]\n        bbox = patches.Rectangle((\n            data['left'],\n            data['top']),\n            data['width'],\n            data['height'],\n            linewidth=1,\n            edgecolor='r',\n            facecolor='None',\n            alpha=0.7\n        )\n        ax.add_patch(bbox)\n    return\n\ndef plot_random_images(root_path, plot_bboxes=True, verbose=True):\n   \n    images_path = root_path + '\/images\/'\n    img_labels_df = pd.read_csv(root_path + '\/image_labels.csv')\n    \n    images_list = os.listdir(images_path)\n    n_images = len(images_list)\n    endzone_images = [image for image in images_list if 'Endzone' in image]\n    sideline_images = [image for image in images_list if 'Sideline' in image]\n\n    if verbose:\n        print(f'There are {n_images} images in the `images` folder.')\n        print(f'  {len(endzone_images)} - images from endzone.')\n        print(f'  {len(sideline_images)} - images from sideline.')\n\n    fig, ax = plt.subplots(4, 2, figsize=(14, 12))\n    for i in range(4):\n        for j in range(2):\n            if j == 0:\n                random_idx = np.random.randint(len(endzone_images))\n                random_img_name = endzone_images[random_idx]\n                random_img = Image.open(images_path + random_img_name)\n            else:\n                random_idx = np.random.randint(len(sideline_images))\n                random_img_name = sideline_images[random_idx]\n                random_img = Image.open(images_path + random_img_name)\n            ax[i][j].imshow(random_img)\n            ax[i][j].set_axis_off()\n            if plot_bboxes:\n                add_bboxes(ax[i][j], random_img_name, img_labels_df)\n\n    ax[0][0].set_title('Endzone images')\n    ax[0][1].set_title('Sideline images')\n    fig.tight_layout()","f708280d":"plot_random_images(DATA_PATH, plot_bboxes=True, verbose=True)","cd3b023d":"img_labels_df = pd.read_csv(DATA_PATH + '\/image_labels.csv')\nplt.figure(figsize=(12, 6))\nimg_labels_df.label.hist()","c96ee05b":"class HelmetsDataset(object):\n    \n    def __init__(self, root_path):\n        self.root_path = root_path\n        self.images_list = os.listdir(os.path.join(root_path, 'images'))\n        self.images_df = pd.read_csv(os.path.join(root_path, 'image_labels.csv'))\n        self.labels_dict = {'Helmet': 1,\n                           'Helmet-Blurred': 2,\n                           'Helmet-Difficult': 3,\n                           'Helmet-Sideline': 4,\n                           'Helmet-Partial': 5}\n        \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_path, 'images', self.images_list[idx])\n        img = np.array(Image.open(img_path)) \/ 255\n        img = np.moveaxis(img, 2, 0) # to [C, H, W]\n        \n        # Collect data about boxes and helmet labels from `image_labels.csv`\n        img_data_df = self.images_df[self.images_df['image'] == self.images_list[idx]]     \n        n_bboxes = img_data_df.shape[0]\n        bboxes = []\n        labels = []\n        for i in range(n_bboxes):\n            img_data = img_data_df.iloc[i]\n            x_min = img_data.left\n            x_max = img_data.left + img_data.width\n            y_min = img_data.top\n            y_max = img_data.top + img_data.height\n            bboxes.append([x_min, y_min, x_max, y_max])\n            label = self.labels_dict[img_data.label]\n            labels.append(label)\n         \n        # Convert data to tensors\n        img = torch.as_tensor(img, dtype=torch.float32)    \n        bboxes = torch.as_tensor(bboxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        image_id = torch.tensor([idx])\n        \n        target = {}\n        target['boxes'] = bboxes\n        target['labels'] = labels\n        target['image_id'] = image_id\n        \n        return img, target\n    \n    def __len__(self):\n        return len(self.images_list)","5efe75a6":"def get_model(n_classes=6):\n    # model pretrained on COCO dataset\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n    # original number of features in classifier head\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # adapting number of classes\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, n_classes)\n    return model","6a551368":"def forward_train(model, data, device):\n    imgs, targets = data\n    imgs = [image.to(device) for image in imgs]\n    targets = [{k: v.to(device) for k, v in tgt.items()} for tgt in targets]\n    \n    loss_dict = model(imgs, targets) \n    losses = sum(loss for loss in loss_dict.values())\n    \n    return losses","dd55d2c1":"# One more helper function in order to handle batches with different shapes\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n","1e18126e":"BATCH_SIZE = 8 # Here I am use small batch size in order to avoid kernel crash\nN_TEST = 100\n\ndataset = HelmetsDataset(DATA_PATH)\n\n\n# train and test split\nidxs = torch.randperm(len(dataset)).tolist()\ndataset_train = torch.utils.data.Subset(dataset, idxs[:-N_TEST])\ndataset_test = torch.utils.data.Subset(dataset, idxs[-N_TEST:])\n                      \ntrain_dataloader = torch.utils.data.DataLoader(dataset_train,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True,\n                                               num_workers=4,\n                                               collate_fn=collate_fn)\n                      \ntest_dataloader = torch.utils.data.DataLoader(dataset_test,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True,\n                                               num_workers=4,\n                                               collate_fn=collate_fn)","9dbe214e":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Device: {device}')\nmodel = get_model()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nmodel.to(device)\n","ba56324e":"N_ITERS = 100\n\n\nprogress_bar = tqdm(range(N_ITERS))\ntr_it = iter(train_dataloader)\nloss_log = []\niterations = []\n\nfor i in progress_bar:\n    try:\n        data = next(tr_it)\n    except StopIteration:\n        tr_it = iter(train_dataloader)\n        data = next(tr_it)\n    model.train()\n    torch.set_grad_enabled(True)\n    \n    losses = forward_train(model, data, device)\n    \n    optimizer.zero_grad()\n    losses.backward()\n    optimizer.step()\n        \n    loss_log.append(losses.item())\n    iterations.append(i)\n    progress_bar.set_description(f'batch loss: {losses.item()}, average loss: {np.mean(loss_log)}.')\n    \n    clear_output(True)\n    plt.plot(iterations, loss_log)\n    plt.show()","4e8fde9c":"def plot_detected_bboxes(test_img, predictions, n_to_plot=2, score_threshold=0.5):\n    \n    n = min(len(test_img), n_to_plot)\n    \n    fig, ax = plt.subplots(1, n, figsize=(16, 8))\n    \n    for i in range(n):\n        img = np.asarray(test_img[i].cpu().numpy() * 255, dtype=np.int64)\n        img = np.moveaxis(img, 0, 2)\n        img = Image.fromarray(np.uint8(img)).convert('RGB')\n        ax[i].imshow(img)\n        ax[i].set_axis_off()\n\n        bboxes = predictions[i]['boxes'].cpu().numpy()\n        scores = predictions[i]['scores'].cpu().numpy()\n        scores_mask = scores > score_threshold\n        for bbox in bboxes[scores_mask]:\n            patch = patches.Rectangle(\n                (bbox[0], bbox[1]),\n                bbox[2] - bbox[0], bbox[3] - bbox[1],\n                linewidth=1,\n                edgecolor='b',\n                facecolor='None',\n                alpha=0.8)\n            ax[i].add_patch(patch)  \n        \n    fig.tight_layout()\n    return ","1099940e":"model.eval()\ntorch.set_grad_enabled(False)\n\ntest_it = iter(test_dataloader)\n","f1dd6908":"test_img, test_gt  = next(test_it)\ntest_img = [image.to(device) for image in test_img]\n\npredictions = model(test_img)\n\nplot_detected_bboxes(test_img, predictions,\n                     n_to_plot=4,\n                     score_threshold=0.6)","ac58ff29":"import tensorflow as tf\nfrom tensorflow import keras\nprint(\"Tensorflow Version:\", tf.__version__)\nprint(\"Keras Version:\", keras.__version__)","7da2145e":"from tensorflow.keras.optimizers import SGD\n\n\n# Create Sequential Model\nmodel = keras. models.Sequential()\n#model.add(keras.layers.Dense(100, activation =\"relu\"))\nmodel.add(keras.layers.Dense(100, activation =\"relu\"))\nmodel.add(keras.layers.Dense(100, activation =\"relu\"))\nmodel.add(keras.layers.Dense(6, activation = \"softmax\"))","2a04484e":"import numpy as np\nfrom scipy.optimize import linear_sum_assignment\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image","b895738f":"def iou(bbox1, bbox2):\n    bbox1 = [float(x) for x in bbox1]\n    bbox2 = [float(x) for x in bbox2]\n\n    (x0_1, y0_1, x1_1, y1_1) = bbox1\n    (x0_2, y0_2, x1_2, y1_2) = bbox2\n\n    # get the overlap rectangle\n    overlap_x0 = max(x0_1, x0_2)\n    overlap_y0 = max(y0_1, y0_2)\n    overlap_x1 = min(x1_1, x1_2)\n    overlap_y1 = min(y1_1, y1_2)\n\n    # check if there is an overlap\n    if overlap_x1 - overlap_x0 <= 0 or overlap_y1 - overlap_y0 <= 0:\n            return 0\n\n    # if yes, calculate the ratio of the overlap to each ROI size and the unified size\n    size_1 = (x1_1 - x0_1) * (y1_1 - y0_1)\n    size_2 = (x1_2 - x0_2) * (y1_2 - y0_2)\n    size_intersection = (overlap_x1 - overlap_x0) * (overlap_y1 - overlap_y0)\n    size_union = size_1 + size_2 - size_intersection\n\n    return size_intersection \/ size_union","d5481224":"def precision_calc(gt_boxes, pred_boxes):\n    cost_matix = np.ones((len(gt_boxes), len(pred_boxes)))\n    for i, box1 in enumerate(gt_boxes):\n        for j, box2 in enumerate(pred_boxes):\n            dist = abs(box1[0]-box2[0])\n            if dist > 4:\n                continue\n            iou_score = iou(box1[1:], box2[1:])\n\n            if iou_score < 0.35:\n                continue\n            else:\n                cost_matix[i,j]=0\n\n    row_ind, col_ind = linear_sum_assignment(cost_matix)\n    fn = len(gt_boxes) - row_ind.shape[0]\n    fp = len(pred_boxes) - col_ind.shape[0]\n    tp=0\n    for i, j in zip(row_ind, col_ind):\n        if cost_matix[i,j]==0:\n            tp+=1\n        else:\n            fp+=1\n            fn+=1\n    return tp, fp, fn","008639a4":"gt_boxes = [[0, 50,60, 120, 130], [0, 40, 20, 110, 80], [0, 140, 20, 190, 80]]\npred_boxes = [[0, 55, 30, 130, 110], [0, 60, 90, 135, 140], [0, 70, 120, 155, 190]]\n\nim = np.array(Image.new('RGB', (224, 224)))\nfig,ax = plt.subplots(1)\nax.imshow(im)\n\nfor box in gt_boxes:\n    rect = patches.Rectangle((box[1],box[2]),box[3]-box[1],box[4]-box[2],linewidth=1,edgecolor='g',facecolor='none')\n    ax.add_patch(rect)\n    \nfor box in pred_boxes:\n    rect = patches.Rectangle((box[1],box[2]),box[3]-box[1],box[4]-box[2],linewidth=1,edgecolor='r',facecolor='none')\n    ax.add_patch(rect)","74fbf655":"tp, fp, fn = precision_calc(gt_boxes, pred_boxes)\nprint(f'TP: {tp}, FP: {fp} FN: {fn}')\n","d1b4e4bf":"#Calculating CV score.\ntestdata = np.load('..\/input\/test-metrics\/testdata.npy', allow_pickle=True)\nftp, ffp, ffn = [], [], []\nfor count, data in enumerate(testdata):\n    pred_boxes = data['data']['preds']\n    gt_boxes = data['data']['gt']\n    tp, fp, fn = precision_calc(gt_boxes, pred_boxes)\n    ftp.append(tp)\n    ffp.append(fp)\n    ffn.append(fn)\n\ntp = np.sum(ftp)\nfp = np.sum(ffp)\nfn = np.sum(ffn)\nprecision = tp \/ (tp + fp + 1e-6)\nrecall =  tp \/ (tp + fn +1e-6)\nf1_score = 2*(precision*recall)\/(precision+recall+1e-6)\nprint(f'TP: {tp}, FP: {fp}, FN: {fn}, PRECISION: {precision:.4f}, RECALL: {recall:.4f}, F1 SCORE: {f1_score}')","5455459c":"\ntest_data = pd.read_csv(\"..\/input\/nfl-impact-detection\/test_player_tracking.csv\")\nprint(test_data.shape)\n# test_data.head()\nsub = pd.read_csv(\"..\/input\/nfl-impact-detection\/sample_submission.csv\")","55535c59":"from torch.utils.data import Dataset,DataLoader","483c9b59":"\nresult_image_ids = []\nresults_boxes = []data\nresults_scores = []\nfor images, image_ids in data_loader:\n    box_list, score_list = make_predictions(images, score_threshold=DETECTION_THRESHOLD)\n    for i, image in enumerate(images):\n        boxes = box_list[i]\n        scores = score_list[i]\n        image_id = image_ids[i]\n        boxes[:, 0] = (boxes[:, 0] * 1280 \/ 512)\n        boxes[:, 1] = (boxes[:, 1] * 720 \/ 512)\n        boxes[:, 2] = (boxes[:, 2] * 1280 \/ 512)\n        boxes[:, 3] = (boxes[:, 3] * 720 \/ 512)\n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        boxes = boxes.astype(np.int32)\n        boxes[:, 0] = boxes[:, 0].clip(min=0, max=1280-1)\n        boxes[:, 2] = boxes[:, 2].clip(min=0, max=1280-1)\n        boxes[:, 1] = boxes[:, 1].clip(min=0, max=720-1)\n        boxes[:, 3] = boxes[:, 3].clip(min=0, max=720-1)\n        result_image_ids += [image_id]*len(boxes)\n        results_boxes.append(boxes)\n        results_scores.append(scores)","177a66ed":"import pandas as df\nimport nflimpact\nenv =  nflimpact.make_env().predict(df)\n\nenv.predict(df) # df is a pandas dataframe of your entire submission file","6ba27f08":"# **Exploring the Image dataset**","de6eb5b2":"# To finetune the Faster R-CNN","cb9a7895":"# Using RCNN model for helmets detectionfor images","6f1cba57":"# Model Evaluation","a4edfd27":"# Exploring the Video dataset","f943c8eb":"# Exploring the Tracking dataset"}}