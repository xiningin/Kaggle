{"cell_type":{"c1201b83":"code","ed1ed72d":"code","b1e625fd":"code","6a11c927":"code","f372f031":"code","9bb05a95":"code","c6b4ab02":"code","c62b48d6":"code","45e13200":"code","ef640ba3":"code","907553f8":"code","1e585807":"code","75d38a2c":"code","b12d6df0":"code","9b61aef3":"code","3c48dedb":"code","dc48d429":"code","3467f2b8":"code","c7c44b9d":"code","2d404651":"code","3c487953":"code","a7e50947":"code","f48f7215":"code","7da6c766":"code","1a525be9":"code","11de10d5":"code","2630c3d6":"code","c7727ae2":"code","3e8cbd1e":"code","43c1e2f3":"code","54678a8a":"code","9ddafc27":"code","7c206491":"code","0b12eb40":"code","48115efc":"code","cfd8b39c":"code","e93f3d45":"code","c37e1591":"code","b6ca4f80":"code","de367b6e":"code","31269f0f":"code","fcca7434":"code","7f9ae043":"code","9fb5eab0":"code","1cb55a8f":"code","e3846460":"markdown","8cb0a2c6":"markdown","c696a88f":"markdown","2684f18d":"markdown","46dc2e92":"markdown","4ffc6c21":"markdown","ef26ad4a":"markdown","e4288aab":"markdown","8e28e9c6":"markdown","b11d9e30":"markdown","dbc7a0a6":"markdown","027c435a":"markdown","2fd2cab8":"markdown","7b91adf8":"markdown"},"source":{"c1201b83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ed1ed72d":"# read the data to pandas dataframe\n\nretail = pd.read_csv('..\/input\/online-retail-customer-clustering\/OnlineRetail.csv', sep=\",\", encoding=\"ISO-8859-1\", header=0)\nretail.head()","b1e625fd":"# shape of df\n\nretail.shape","6a11c927":"# df info\n\nretail.info()","f372f031":"type_counts = retail['Country'].value_counts()\nCountry=pd.DataFrame(type_counts)\nCountry.head()","9bb05a95":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(20,10))\nCountry=Country.head()\nax = sns.barplot(y='Country',x=Country.index, data=Country.head())\nplt.xticks(rotation=45)","c6b4ab02":"retail=retail[retail['Country']=='Germany']\nretail.shape","c62b48d6":"# Calculating the Missing Values % contribution in DF\n\ndf_null = round(100*(retail.isnull().sum())\/len(retail), 2)\ndf_null","45e13200":"# Droping rows having missing values\n\nretail = retail.dropna()\nretail.shape","ef640ba3":"# Changing the datatype of Customer Id as per Business understanding\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)","907553f8":"# New Attribute : Recency\n\n# Convert to datetime to proper datatype\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')","1e585807":"# Compute the maximum date to know the last transaction date\n\nmax_date = max(retail['InvoiceDate'])\nmax_date","75d38a2c":"# Compute the difference between max date and transaction date\n\nretail['Diff'] = max_date - retail['InvoiceDate']\nretail.head()","b12d6df0":"# Compute last transaction date to get the recency of customers\n\nrfm_r = retail.groupby('CustomerID')['Diff'].min().reset_index()\nrfm_r.head()","9b61aef3":"# Extract number of days only\n\nrfm_r['Diff'] = rfm_r['Diff'].dt.days\nrfm_r.columns = ['CustomerID','Recency']\nrfm_r.head()","3c48dedb":"### New Attribute : Frequency\n\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count().reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\nrfm_f.head()","dc48d429":"# New Attribute : Monetary\n\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\nrfm_m = retail.groupby('CustomerID')['Amount'].sum().reset_index()\nrfm_m.head()","3467f2b8":"rfm = rfm_r.merge(rfm_f,how='inner',on=['CustomerID'])\nrfm =rfm.merge(rfm_m,how='inner',on=['CustomerID'])\nrfm.head()","c7c44b9d":"# Outlier Analysis of Amount Frequency and Recency\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nattributes = ['Recency','Frequency','Amount',]\nplt.rcParams['figure.figsize'] = [10,8]\nsns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"Attributes\", fontweight = 'bold')","2d404651":"# Removing (statistical) outliers for Amount\nQ1 = rfm.Amount.quantile(0.05)\nQ3 = rfm.Amount.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Recency\nQ1 = rfm.Recency.quantile(0.05)\nQ3 = rfm.Recency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Frequency\nQ1 = rfm.Frequency.quantile(0.05)\nQ3 = rfm.Frequency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]","3c487953":"# Rescaling the attributes\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\n\nrfm_df = rfm[['Recency','Frequency', 'Amount']]\n\n# Instantiate\nscaler = StandardScaler()\n\n# fit_transform\nrfm_df_scaled = scaler.fit_transform(rfm_df)\nrfm_df_scaled.shape","a7e50947":"rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']\nrfm_df_scaled.head()","f48f7215":"# k-means with some arbitrary k\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","7da6c766":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","1a525be9":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='distortion')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show() ","11de10d5":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='silhouette')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","2630c3d6":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='calinski_harabasz')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","c7727ae2":"# k-means with some arbitrary k\nk=4\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=k, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","3e8cbd1e":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","43c1e2f3":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Recency', data=rfm)","54678a8a":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Frequency', data=rfm)","9ddafc27":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Amount', data=rfm)","7c206491":"Target_Customer = rfm[rfm['Cluster_Id']=='1']\nTarget_Customer.head()","0b12eb40":"Target_Customer.count()","48115efc":"from scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","cfd8b39c":"# Single linkage: \n\nmergings = linkage(rfm_df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","e93f3d45":"# Complete linkage\n\nmergings = linkage(rfm_df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","c37e1591":"# Average linkage\n\nmergings = linkage(rfm_df_scaled, method=\"average\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","b6ca4f80":"# 3 clusters\nk=4\ncluster_labels = cut_tree(mergings, n_clusters=k).reshape(-1, )\nrfm['Cluster_Labels'] = cluster_labels\nrfm.head()","de367b6e":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Labels\"] = rfm[\"Cluster_Labels\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Labels')\nfig.show()","31269f0f":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Recency', data=rfm)","fcca7434":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Frequency', data=rfm)","7f9ae043":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Amount', data=rfm)","9fb5eab0":"Target_Customer2 = rfm[rfm['Cluster_Labels']=='2']\nTarget_Customer2.head()","1cb55a8f":"Target_Customer2.count()","e3846460":"Method 1: Finding the elbow point for (inertia_) \"Sum of squared distances of samples to their closest cluster center\".","8cb0a2c6":"# **Step 4: Hierarchical Clustering**","c696a88f":"2. Calculating Frequency","2684f18d":"# **Step 3: Data Preparation for RFM Factors**","46dc2e92":"5. Rescaling the Attributes by Standardisation (mean-0, sigma-1)","4ffc6c21":"1. Visualize Tree by Linkage Methods","ef26ad4a":"1. Calculating Recency","e4288aab":"4. Remove Outliers","8e28e9c6":"# **Step 2: Data Cleaning**","b11d9e30":"# **Step 1: Import and Examine the data**","dbc7a0a6":"3. Calculating Monetary","027c435a":"**2. Finding the best K: A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. **","2fd2cab8":"1. Initial Cluster Given K","7b91adf8":"# **Step 3: K-Means Clustering**"}}