{"cell_type":{"0c72d362":"code","ffee4329":"code","58ed81f3":"code","8d891d75":"code","77341a39":"code","97e75a1c":"code","75fc66f3":"code","7ad710ea":"code","994cff96":"code","0f27a565":"code","58270ec1":"code","5b6fc2a5":"code","27655a0d":"code","2652d629":"code","81e6c0bd":"code","1b770058":"code","a824360f":"code","a2fc74d9":"code","64b125ab":"code","12a5b8a5":"code","725cd9da":"code","f6eefb62":"code","09215e4e":"code","5af78c9e":"code","e3c492cd":"code","29971476":"code","fe5664c1":"code","b5b49727":"code","8b66edcd":"code","007af4d9":"code","aaeb6850":"code","ba7cf6f6":"code","89370842":"code","f08b4fb8":"code","9a2ad37b":"code","fb69e52c":"code","933cab1c":"code","f13b03ce":"code","7abeaaec":"code","5002ea3f":"code","3de7ffc7":"code","25ebee49":"code","fe93433d":"code","d4b626c8":"markdown","cb3a3f86":"markdown","a8fa34a8":"markdown","471aff81":"markdown","6bc47c83":"markdown","34ea26fd":"markdown","813e931f":"markdown","6cea0783":"markdown","1a55b6b1":"markdown","ab6c365d":"markdown","b31d9a08":"markdown","ffc6ddc6":"markdown","cebcc2b9":"markdown","6ec6210d":"markdown","08378502":"markdown","e9f5d594":"markdown","187cd0b1":"markdown","9be85a5b":"markdown","3689b6a5":"markdown","4c09ad3a":"markdown","0065887d":"markdown","3cee884d":"markdown","81e3cc88":"markdown","1c8eaadf":"markdown","36969f13":"markdown","82280dd0":"markdown","a3235ddb":"markdown","f26fa12b":"markdown","9933af5d":"markdown","8deb1b5d":"markdown","57220c3e":"markdown","22c64422":"markdown","14f2e7f1":"markdown","a7e116a3":"markdown","285aa8bf":"markdown","8f64d25e":"markdown","17b6e8a4":"markdown","8f8db6d8":"markdown","27e362a8":"markdown","53e1429f":"markdown","1acdce9c":"markdown","789bedda":"markdown","78c57265":"markdown","fef83afe":"markdown"},"source":{"0c72d362":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# importing matplotlib modules \nimport matplotlib.image as mpimg \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import recall_score\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as metrics\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# read in data:\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) # show what data is available","ffee4329":"img = mpimg.imread('\/kaggle\/input\/healthcare-dataset-stroke-data\/Screen Shot 2018-04-17 at 12.15.42 AM.png') \n  \n# Output Images \nplt.figure(figsize = (20,20))\nplt.imshow(img, interpolation='nearest')","58ed81f3":"train = pd.read_csv('\/kaggle\/input\/healthcare-dataset-stroke-data\/train_2v.csv')\ntest = pd.read_csv('\/kaggle\/input\/healthcare-dataset-stroke-data\/test_2v.csv')\nprint('TRAIN:')\ndisplay(train)\nprint('TEST:')\ndisplay(test)","8d891d75":"train.info()","77341a39":"train.isnull().sum()","97e75a1c":"test.info()","75fc66f3":"test.isnull().sum()","7ad710ea":"train_df = train.drop(columns=['id','smoking_status'])\ntrain_df.dropna(subset=['bmi'], inplace=True)\ntrain_df.info()","994cff96":"test_df = test.drop(columns=['id','smoking_status'])\ntest_df.dropna(subset=['bmi'], inplace=True)\ntest_df.info()","0f27a565":"fig = plt.figure(figsize = (15,15))\nax = fig.gca()\ntrain_df.hist(ax=ax)\nplt.show()","58270ec1":"train_df.stroke.value_counts()","5b6fc2a5":"encoded_train = train_df.copy()\n\nencoder = LabelEncoder()\nencoder.fit(train_df.gender)\nencoded_train.gender = encoder.transform(train_df.gender)\n\nencoder.fit(train_df.ever_married)\nencoded_train.ever_married = encoder.transform(train_df.ever_married)\n\nencoder.fit(train_df.work_type)\nencoded_train.work_type = encoder.transform(train_df.work_type)\n\nencoder.fit(train_df.Residence_type)\nencoded_train.Residence_type = encoder.transform(train_df.Residence_type)\n\ndisplay(encoded_train)\nencoded_train.info()","27655a0d":"training_features, test_features, \\\ntraining_target, test_target, = train_test_split(encoded_train.drop(['stroke'], axis=1),\n                                                 encoded_train['stroke'],\n                                                 test_size = .1,\n                                                 random_state=12)","2652d629":"x_train, x_test, y_train, y_test = train_test_split(training_features, training_target,\n                                                  test_size = .1,\n                                                  random_state=12)","81e6c0bd":"y_train.value_counts()","1b770058":"sm = SMOTE(random_state=12, ratio = 1.0)\nx_train_res, y_train_res = sm.fit_sample(x_train, y_train)","a824360f":"unique, counts = np.unique(y_train_res, return_counts=True)\ndict(zip(unique, counts))","a2fc74d9":"# clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n# clf_rf.fit(x_train_res, y_train_res)","64b125ab":"# print('Validation Results')\n# print(clf_rf.score(x_test, y_test))\n# print(recall_score(y_test, clf_rf.predict(x_test)))\n# print('\\nTest Results')\n# print(clf_rf.score(test_features, test_target))\n# print(recall_score(test_target, clf_rf.predict(test_features)))","12a5b8a5":"log_df = pd.DataFrame(data=x_train_res,    # values\n             index= list(range(0,len(x_train_res))),    # index\n             columns= encoded_train.drop(columns='stroke').columns)  # columns of encoded_train as the column names\nlog_df['stroke'] = y_train_res\ndisplay(log_df)","725cd9da":"# Set the background to white so it won't show after adding the mask.\nsns.set(style=\"white\")\n\n# Compute the correlation matrix from train_df.\ncorr = log_df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(20, 11))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.xticks(rotation=60)","f6eefb62":"#Correlation with output variable\ncor_target = abs(corr[\"stroke\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.001]\nrelevant_features.sort_values(ascending=False)","09215e4e":"X = log_df[['age', 'heart_disease', 'hypertension', 'avg_glucose_level']]\ny = log_df[['stroke']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n\nX_train.head()","5af78c9e":"logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')","e3c492cd":"logit.fit(X_train, y_train)","29971476":"print('Coefficient: \\n', logit.coef_)\nprint('Intercept: \\n', logit.intercept_)","fe5664c1":"y_pred = logit.predict(X_train)","b5b49727":"y_pred_proba = logit.predict_proba(X_train)","8b66edcd":"## verify\ny_pred_proba_viz = [i[1] for i in y_pred_proba]\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.scatter(y_pred_proba_viz, y_pred)","007af4d9":"print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n     .format(logit.score(X_train, y_train)))","aaeb6850":"print(confusion_matrix(y_train, y_pred))","ba7cf6f6":"print(classification_report(y_train, y_pred))","89370842":"fpr, tpr, threshold = metrics.roc_curve(y_train, y_pred_proba[:, 1])\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","f08b4fb8":"y_test_pred = logit.predict(X_test)","9a2ad37b":"y_test_pred_proba = logit.predict_proba(X_test)","fb69e52c":"print('Accuracy of Logistic Regression classifier on test set: {:.2f}'\n     .format(logit.score(X_test, y_test)))","933cab1c":"print(confusion_matrix(y_test, y_test_pred))","f13b03ce":"fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_pred_proba[:, 1])\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","7abeaaec":"display(test_df)","5002ea3f":"test_df = test_df[['age', 'heart_disease', 'hypertension', 'avg_glucose_level']]","3de7ffc7":"y_pred = logit.predict(test_df)","25ebee49":"y_pred","fe93433d":"test_df['prediction'] = y_pred\ndisplay(test_df)","d4b626c8":"## Estimate the probability of a patient having a stroke, using the training data","cb3a3f86":"# I switched to trying logistic regression...","a8fa34a8":"## Compute the accuracy","471aff81":"## Use SMOTE to create synthetic data to balance the sample.\n### SMOTE = Synthetic Minority Over-sampling Technique","6bc47c83":"## All NaNs gone. Let's look at the distribution of the train data in each column.","34ea26fd":"## Estimate whether or not a patient had a stroke, using the test data","813e931f":"## There are exactly the same number of stroke and non-stroke observations in y_train_res.","6cea0783":"## All of these features are numerical so I don't need to encode anything.","1a55b6b1":"## Estimate whether or not a patient had a stroke, using the training data","ab6c365d":"## Visualize Model","b31d9a08":"## age and ever_married are the first and second highest, but we don't want to use both of them since their correlation with each other is .62. We'll use the remaining features with above a .26 correlation. ","ffc6ddc6":"### Read and Show Dictionary Image","cebcc2b9":"## logistic regression is very sensitive to correlated features, so let's check that first.","6ec6210d":"## Stroke, heart disease, and hypertension data look very imbalanced, but my main concern is my target data, stroke.","08378502":"## Estimate the probability of a patient having a stroke, using the test data","e9f5d594":"# Evaluate Model on train data\n## Compute the accuracy","187cd0b1":"### Read in test and train data into respective dataframes.","9be85a5b":"## Compute Precision, Recall, F1-score, and Support","3689b6a5":"## Select the same four features used in train.","4c09ad3a":"## Since over 30% of the data is missing for smoking status, we will drop that column.\n\n## Only 3% of the bmi data is missing. I could fill those with the mean or median, but it's such an important value and I have plenty of data that I am going to instead drop those rows.\n\n## Also drop the id column.","0065887d":"# Test Model on test data\n## Compute the accuracy of the model when run on the test data","3cee884d":"## Fit the model to the training data","81e3cc88":"# The real test data does not have a column for stroke because this was a contest. So I will add the predictions from my model onto the original cleaned data.","1c8eaadf":"## Now I will oversample the stroke observations, but only on the training data so I don't bias my test data.\n\n## Since the original \"test\" data given has no stroke data, I will split the given \"train\" data into a train and test set.","36969f13":"## Estimate whether or not a patient had a stroke, using the test data","82280dd0":"## Create a confusion matrix","a3235ddb":"## Create a confusion matrix","f26fa12b":"## And do the same for the test data while we're at it.","9933af5d":"### Import modules and data for notebook.","8deb1b5d":"# Objective\n## Predict whether a Patient will have stroke or not based on some given attributes. Evaluation metric was AUC-ROC Score.","57220c3e":"## Understanding Data\nHere is the Definitions of the columns of the data\n\n1. id-Patient ID\n2. gender-Gender of Patient\n3. age-Age of Patient\n4. hypertension-0 - no hypertension, 1 - suffering from hypertension\n5. heart_disease-0 - no heart disease, 1 - suffering from heart disease\n6. ever_married-Yes\/No\n7. work_type-Type of occupation\n8. Residence_type-Area type of residence (Urban\/ Rural)\n9. avg_glucose_level-Average Glucose level (measured after meal)\n10. bmi-Body mass index\n11. smoking_status-patient\u2019s smoking status\n12. stroke-0 - no stroke, 1 - suffered stroke","22c64422":"## NOW what is the proportion of non-stroke (0) and stroke (1) observations?","14f2e7f1":"# The following code was supposed to confirm the results were generalizable, but it yielded a recall of 0... so something is wrong.","a7e116a3":"# Need to change x_train_res and y_train_res, which are numpy arrays with the oversampled observations, back into a dataframe.","285aa8bf":"## What is the proportion of non-stroke (0) and stroke (1) observations?","8f64d25e":"## Indeed, there are 41,295 stroke patients and only 643 non-stroke patients. I am concerned that a ML algorithm will predict no stroke for all data. First, we need to encode the categorical data.","17b6e8a4":"### 5751\/18601 = 30.9% of smoking status missing from test data.\n### 591\/18601 = 3.2% of bmi missing from test data.","8f8db6d8":"## But, of course, there is no way to test my recall on this data.","27e362a8":"## Recall is 93%.\n## Print the AUC-ROC.","53e1429f":"## Ever_married and age have a .62 correlation, so we shouldn't use both of them. The rest range between .33 and -.28 which is acceptable.\n\n## Let's rank the features to see which is most highly correlated with stroke, which is our target.","1acdce9c":"# Train Model\n## Create the logistic regression object","789bedda":"### 13292\/43400 = 30.6% of smoking status missing in train data.\n### 1462\/43400 = 3.4% of bmi missing in train data.","78c57265":"## By oversampling only on the training data, none of the information in the validation data is being used to create synthetic observations. So these results should be generalizable. Let\u2019s see if that\u2019s true.","fef83afe":"## Print the coefficients and intercept of the model"}}