{"cell_type":{"eb726895":"code","8333c6a0":"code","e7d8208e":"code","a06e2fae":"code","0b692b58":"code","7e89fc6e":"code","2b57f985":"code","676300fb":"code","6a64b468":"code","cc89255b":"code","5dfae652":"code","1205ba42":"code","e6dfe9f7":"code","cb56e770":"code","5e7cd7eb":"code","775415b7":"code","b969a0ba":"code","39d44654":"code","2de644ee":"code","52c28ed8":"code","9d94cc72":"code","b755b1db":"code","b7a9055c":"code","4df437a4":"code","001c3a40":"code","fa6c13a9":"code","2345123a":"code","17f816f1":"code","03949051":"code","4ad587dc":"code","5405d33d":"code","7832174f":"code","43521cf2":"code","e52bfd89":"code","f7241c83":"code","5d686370":"markdown","6f10715a":"markdown","c97b0d84":"markdown","d846fa95":"markdown","6ff4cd97":"markdown","8e7fe328":"markdown","0d16821d":"markdown","d6da5ecd":"markdown","9af733c4":"markdown","1e334e10":"markdown","e7ffdddc":"markdown","38f696bc":"markdown","bbb78537":"markdown"},"source":{"eb726895":"!pip install dataprep","8333c6a0":"!pip install autoviz","e7d8208e":"!pip install xlrd","a06e2fae":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nfrom dataprep.eda import *\nfrom dataprep.eda import plot\nfrom dataprep.eda import plot_diff\nfrom dataprep.eda import plot_correlation\nfrom dataprep.eda import plot_missing\n","0b692b58":"train_file = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_file = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","7e89fc6e":"plot(train_file, \"SalePrice\")","2b57f985":"import pandas_profiling as profilereport\nprofilereport.ProfileReport(test_file)","676300fb":"#create_report(train_file)","6a64b468":"dataset = train_file.append(test_file).reset_index(drop=True)\ndataset.head()","cc89255b":"plot_missing(dataset)","5dfae652":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\ntarget='SalePrice'\ndf = AV.AutoViz(filename=\"\",sep=',', depVar=target, dfte=dataset, header=0, verbose=2, \n                 lowess=False, chart_format='svg', max_rows_analyzed=150000, max_cols_analyzed=30)","1205ba42":"dataset.shape","e6dfe9f7":"total_missing_values = dataset.isnull().sum().sort_values(ascending=False)\npercentage_missing_values = np.round(dataset.isnull().mean(), 4).sort_values(ascending=False)    \nmissing_values = pd.concat([total_missing_values,percentage_missing_values], axis=1, keys=['Total','Percent'])\nmissing_values.head(20)","cb56e770":"missing_values = missing_values.drop(['SalePrice'])\nmissing_values.head(20)","5e7cd7eb":"dataset = dataset.drop((missing_values[missing_values['Total'] > 159]).index,1)\ndataset.shape","775415b7":"numerical_features_missing = [i for i in dataset if dataset[i].isnull().sum() >= 1 and dataset[i].dtype !='object' ]\n\nfor i in numerical_features_missing:\n  print(i, np.round(dataset[i].isnull().mean(),4))","b969a0ba":"#Fill missing values for numerical values with median value\n#Impute \/ Replace missing values with median\n\nfor i in numerical_features_missing:\n    if i != \"SalePrice\":\n        dataset[i].fillna(dataset[i].median(),inplace=True)","39d44654":"dataset[numerical_features_missing].isnull().sum()","2de644ee":"categorical_features_missing = [i for i in dataset if dataset[i].isnull().sum() >= 1 and dataset[i].dtype =='object']\n\nfor i in categorical_features_missing:\n  print(i, np.round(dataset[i].isnull().mean(),4))","52c28ed8":"#Fill missing values for categorical values with mode value\n#Impute \/ Replace missing values with mode\n\nfor i in categorical_features_missing:\n  dataset[i].fillna(dataset[i].mode()[0],inplace=True)","9d94cc72":"dataset[categorical_features_missing].isnull().sum()","b755b1db":"dataset.shape","b7a9055c":"dataset.head()","4df437a4":"plot_missing(dataset)","001c3a40":"categorical_features = [i for i in dataset if dataset[i].dtype =='object']\ncategorical_features","fa6c13a9":"indexes = dataset[(dataset['GrLivArea']>4000) & (dataset['SalePrice']<300000)].index \ndataset = dataset.drop(indexes)\ndataset.shape","2345123a":"from sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\nlabelencoder_features = [i for i in categorical_features]\n\nfor f in labelencoder_features:\n  dataset[f] = labelencoder.fit_transform(dataset[f].astype(str))","17f816f1":"train = dataset[dataset['SalePrice'].notnull()]\ntest = dataset[dataset['SalePrice'].isnull()].drop(\"SalePrice\", axis=1)\ny_train = np.log1p(train['SalePrice'])\nX_train = train.drop([\"Id\", \"SalePrice\"], axis=1)","03949051":"from xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import GridSearchCV, cross_val_score","4ad587dc":"models = [('GBM', GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, \n                                              max_depth=4, max_features='sqrt',\n                                              min_samples_leaf=15, min_samples_split=10, \n                                              loss='huber',random_state =46)),\n          (\"XGBoost\", XGBRegressor(learning_rate=0.01, n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7, verbosity = 0,\n                                     objective='reg:squarederror', nthread=-1,\n                                     scale_pos_weight=1, seed=1, reg_alpha=0.00006)),\n          (\"LightGBM\", LGBMRegressor(objective='regression', num_leaves=4,\n                                   learning_rate=0.01, n_estimators=5000,\n                                   max_bin=200, bagging_fraction=0.75,\n                                   bagging_freq=5, bagging_seed=7,\n                                   feature_fraction=0.2,\n                                   feature_fraction_seed=7, verbose=-1,\n                                  colsample_bytree=None, subsample=None, subsample_freq=None)),\n          (\"CatBoost\", CatBoostRegressor(verbose=False))]","5405d33d":"for i, j in models:\n    rmse = np.mean(np.sqrt(-cross_val_score(j, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({i}) \")","7832174f":"final_model = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7, verbosity = 0,\n                                     objective='reg:squarederror', nthread=-1,\n                                     scale_pos_weight=1, seed=1, reg_alpha=0.00006)\n\nrmse = np.mean(np.sqrt(-cross_val_score(final_model,\n                                        X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")))\nrmse","43521cf2":"test.drop(\"Id\", axis = 1, inplace = True)","e52bfd89":"final_model.fit(X_train, y_train)\npredicted_prices = final_model.predict(test)","f7241c83":"output = pd.DataFrame({'Id':test_file.Id,'SalePrice': np.exp(predicted_prices)})\noutput.to_csv(\"submission.csv\", index=False)\noutput.head()","5d686370":"# **House Prices - Advanced Regression Techniques**\n![header.png](attachment:25faebab-20f7-4241-abbb-856238bd7ae7.png)\nStart here if...\nYou have some experience with R or Python and machine learning basics. This is a perfect competition for data science students who have completed an online course in machine learning and are looking to expand their skill set before trying a featured competition. \n","6f10715a":"# Models\n* [GBR](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingRegressor.html)\n* [XGBoost](https:\/\/xgboost.readthedocs.io\/en\/latest\/)\n* [LGBM](https:\/\/lightgbm.readthedocs.io\/en\/latest\/Python-API.html)\n* [CatBoost](https:\/\/catboost.ai\/)","c97b0d84":"# **Create Report**","d846fa95":"# **EDA**\nDataPrep.EDA is the fastest and the easiest EDA (Exploratory Data Analysis) tool in Python. It allows you to understand and visualize dataset by one command line, also we can create report and generate profile reports from a pandas DataFrame.","6ff4cd97":"The first 6 features have a large percentage of missing values (more than 17%) - since these features did not have a strong correlation according to the previous analysis - we will remove them.","8e7fe328":"Clear the data from outliers which are 2 houses.","0d16821d":"There are several approaches for missing values imputation - drop lines with such data, fill in with statistical methods (mean, median, mode), KNN and multiple imputation. First, let's examine the missing values.","d6da5ecd":"Check the normal distribution of Saleprice.","9af733c4":"# **xlrd**\nxlrd is a library for reading data and formatting information from Excel files in the historical .xls format.","1e334e10":"# **Dataprep**\nDataprep is an open-source python library that allows you to prepare your data and that too with just a few lines of code. By preparing data it means that we can analyze the properties of the attributes that are there in the data. In the current version of DataPrep, they have a very useful module named EDA(Exploratory Data Analysis).","e7ffdddc":"# **AutoViz**\nAutoViz is a one-click visualization engine: It creates powerful charts that anyone from a beginner to an expert can use","38f696bc":"The function plot_missing() enables thorough analysis of the missing values and their impact on the dataset. ","bbb78537":"All missing values has been imputed, except SalePrice, because we combined the train and test data. As we know that test does not contain SalePrice."}}