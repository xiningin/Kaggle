{"cell_type":{"6be19f6b":"code","dc33ab33":"code","56819b0b":"code","fe7781f5":"code","b97bfa93":"code","f4f6b322":"code","a3fe5407":"code","35961304":"code","5df387be":"code","7c1e4b30":"code","1dbeaf1c":"code","c95e15f6":"code","e4171753":"code","2402e0f2":"code","b676df4b":"code","2cc4b25e":"code","1076377c":"code","1a7b02c3":"code","3a916b2c":"code","8898d227":"code","ac997269":"code","1fbae302":"code","a04d3c31":"code","5e7dba27":"code","ecdc6ead":"code","678a9fe8":"code","a2981bd1":"code","2e7e49f5":"code","15abb167":"code","34a35a84":"code","b703efc5":"code","c993aba6":"code","c6c49249":"code","df46e461":"code","0f3316ce":"code","cbf97f54":"code","9afafdff":"code","0f306ee0":"code","74418604":"code","895491c9":"code","2eea68a1":"markdown","dfe951e7":"markdown","8ebe0a2a":"markdown","f99a1308":"markdown","f95294fc":"markdown","1aa7ae2f":"markdown","9eb10b67":"markdown","22f22bbf":"markdown","924ac34a":"markdown","6a023d5f":"markdown","54a103c7":"markdown","6e9fe720":"markdown","909a66bb":"markdown","f031dbcc":"markdown","8bc39a5b":"markdown","56d1e882":"markdown","02cb0754":"markdown","c5fe7bbe":"markdown","60afb9c0":"markdown","4c85df62":"markdown","c22a1c8d":"markdown","68b6e0c3":"markdown","fd99db44":"markdown","e66d93bb":"markdown","08a09697":"markdown","73653598":"markdown","2ebe82b9":"markdown","1ffdde37":"markdown","7abbfe13":"markdown","33b10af5":"markdown","e7c5d774":"markdown","8830ae37":"markdown","174497c4":"markdown","2dc8c2ea":"markdown","6039a083":"markdown"},"source":{"6be19f6b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm import tqdm\nimport time\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold,KFold, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nimport xgboost as xgb\nfrom sklearn import preprocessing, model_selection, pipeline\nfrom sklearn.metrics import f1_score, roc_auc_score,roc_curve\n\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM, GRU\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import EarlyStopping","dc33ab33":"df=pd.read_csv(\"..\/input\/real-or-fake-fake-jobposting-prediction\/fake_job_postings.csv\")\ndf.head()","56819b0b":"df.info()","fe7781f5":"df.shape","b97bfa93":"# Missing values\ndf.isnull().sum()","f4f6b322":"text_df = df[[\"title\", \"company_profile\", \"description\", \"requirements\", \"benefits\",\"fraudulent\"]]\ntext_df = text_df.fillna(' ')\ntext_df.head()","a3fe5407":"cat_df = df[[\"telecommuting\", \"has_company_logo\", \"has_questions\", \"employment_type\", \"required_experience\", \"required_education\", \"industry\", \"function\",\"fraudulent\"]]\ncat_df = cat_df.fillna(\"None\")\n\ncat_df.head()","35961304":"df.drop(['salary_range','job_id'], axis = 1, inplace = True)","5df387be":"df.fillna(\" \",inplace = True)","7c1e4b30":"df['text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] ","1dbeaf1c":"df.text[0]","c95e15f6":"df.drop(['title','location','department','company_profile','description','requirements','benefits','employment_type','required_experience','required_education','industry','function'], axis = 1, inplace = True)","e4171753":"df.head()","2402e0f2":"df['text_length'] = df.text.apply(len)\ndf.head()","b676df4b":"fraud = df[\"fraudulent\"].value_counts()\nsns.barplot(fraud.index, fraud, color=\"salmon\")\nplt.title('Target Count', fontsize=14)","2cc4b25e":"df.fraudulent.value_counts()","1076377c":"plt.figure(figsize=(12, 8))\n\ndf[df.fraudulent==0].text_length.plot(bins=35, kind='hist', color='blue', \n                                       label='Real Job Post', alpha=0.6)\ndf[df.fraudulent==1].text_length.plot(kind='hist', color='red', \n                                       label='Fake Job Post', alpha=0.6)\nplt.legend()\nplt.xlabel(\"Text Length\")","1a7b02c3":"cat_cols = [\"telecommuting\", \"has_company_logo\", \"has_questions\", \"employment_type\", \"required_experience\", \"required_education\",]\n# visualizating catagorical variable by target\nimport matplotlib.gridspec as gridspec # to do the grid of plots\ngrid = gridspec.GridSpec(3, 3, wspace=0.5, hspace=0.5) # The grid of chart\nplt.figure(figsize=(15,25)) # size of figure\n\n# loop to get column and the count of plots\nfor n, col in enumerate(cat_df[cat_cols]): \n    ax = plt.subplot(grid[n]) # feeding the figure of grid\n    sns.countplot(x=col, data=cat_df, hue='fraudulent', palette='Set2') \n    ax.set_ylabel('Count', fontsize=12) # y axis label\n    ax.set_title(f'{col} Distribution by Target', fontsize=15) # title label\n    ax.set_xlabel(f'{col} values', fontsize=12) # x axis label\n    xlabels = ax.get_xticklabels() \n    ylabels = ax.get_yticklabels() \n    ax.set_xticklabels(xlabels,  fontsize=10)\n    ax.set_yticklabels(ylabels,  fontsize=10)\n    plt.legend(fontsize=8)\n    plt.xticks(rotation=90) \n    total = len(cat_df)\n    sizes=[] # Get highest values in y\n    for p in ax.patches: # loop to all objects\n        height = p.get_height()\n        sizes.append(height)\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/total*100),\n                ha=\"center\", fontsize=10) \n    ax.set_ylim(0, max(sizes) * 1.15) #set y limit based on highest heights\n\n\nplt.show()","3a916b2c":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nlength=text_df[text_df[\"fraudulent\"]==1]['company_profile'].str.len()\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nlength=text_df[text_df[\"fraudulent\"]==0]['company_profile'].str.len()\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in Company Profile')\nplt.show()","8898d227":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nlength=text_df[text_df[\"fraudulent\"]==1]['description'].str.len()\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nlength=text_df[text_df[\"fraudulent\"]==0]['description'].str.len()\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in description')\nplt.show()","ac997269":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nlength=text_df[text_df[\"fraudulent\"]==1]['requirements'].str.len()\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nlength=text_df[text_df[\"fraudulent\"]==0]['requirements'].str.len()\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in description')\nplt.show()","1fbae302":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nlength=text_df[text_df[\"fraudulent\"]==1]['benefits'].str.len()\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nlength=text_df[text_df[\"fraudulent\"]==0]['benefits'].str.len()\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in description')\nplt.show()","a04d3c31":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nnum=text_df[text_df[\"fraudulent\"]==1]['company_profile'].str.split().map(lambda x: len(x))\nax1.hist(num,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nnum=text_df[text_df[\"fraudulent\"]==0]['company_profile'].str.split().map(lambda x: len(x))\nax2.hist(num, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Words in company profile')\nplt.show()","5e7dba27":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nnum=text_df[text_df[\"fraudulent\"]==1]['description'].str.split().map(lambda x: len(x))\nax1.hist(num,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nnum=text_df[text_df[\"fraudulent\"]==0]['description'].str.split().map(lambda x: len(x))\nax2.hist(num, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Words in description')\nplt.show()","ecdc6ead":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nnum=text_df[text_df[\"fraudulent\"]==1]['requirements'].str.split().map(lambda x: len(x))\nax1.hist(num,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nnum=text_df[text_df[\"fraudulent\"]==0]['requirements'].str.split().map(lambda x: len(x))\nax2.hist(num,bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Words in requirements')\nplt.show()","678a9fe8":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nnum=text_df[text_df[\"fraudulent\"]==1]['benefits'].str.split().map(lambda x: len(x))\nax1.hist(num,bins = 20,color='orangered')\nax1.set_title('Fake Post')\nnum=text_df[text_df[\"fraudulent\"]==0]['benefits'].str.split().map(lambda x: len(x))\nax2.hist(num, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Words in benefits')\nplt.show()","a2981bd1":"lemmatizer = WordNetLemmatizer()\ndef text_cleaning(text):\n    text = re.sub(\"[^a-zA-Z]\", \" \", text) # removing punctuation\n    text = text.lower() # text to lowercase\n    text = text.split()\n    text = [lemmatizer.lemmatize(word) for word in text if not word in stopwords.words('english')]\n    return ' '.join(text)    ","2e7e49f5":"df['text'] = df['text'].apply(text_cleaning)","15abb167":"plt.figure(figsize = (20,20)) # Text that is not fraudulent(0)\nwc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(df[df.fraudulent == 0].text))\nplt.imshow(wc , interpolation = 'bilinear')","34a35a84":"plt.figure(figsize = (20,20)) # Text that is fraudulent(1)\nwc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(df[df.fraudulent == 1].text))\nplt.imshow(wc , interpolation = 'bilinear')","b703efc5":"# Dependrnt and Independent Variable\nX = df.text\ny = df.fraudulent","c993aba6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 0)","c6c49249":"tfid = TfidfVectorizer(min_df=0, max_df=1, ngram_range=(1,3))\n# transformed train\ntfid_train = tfid.fit_transform(X_train)\n# transformed test\ntfid_test = tfid.transform(X_test)\nprint('Tfidf_train : ', tfid_train.shape)\nprint('Tfidf_test : ', tfid_test.shape)","df46e461":"#training the model\nmnb=MultinomialNB()\n#fitting the nb for tfidf features\nmnb_tfidf=mnb.fit(tfid_train, y_train)\nprint(mnb_tfidf)","0f3316ce":"#Predicting the model for tfidf features\nmnb_tfidf_predict=mnb.predict(tfid_test)","cbf97f54":"#Accuracy score for tfidf features\nmnb_tfidf_score=accuracy_score(y_test, mnb_tfidf_predict)\nprint(\"Accuracy Score :\", mnb_tfidf_score)","9afafdff":"fpr, tpr, thr = roc_curve(y_test, mnb.predict_proba(tfid_test)[:,1])\n#auc = auc(fpr, tpr)\nauc = roc_auc_score(y_test, mnb_tfidf_predict)\nlw = 2\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label=\"Curve Area = %0.3f\" % auc)\nplt.plot([0, 1], [0, 1], color='green', lw=lw, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic Plot')\nplt.legend(loc=\"lower right\")\nplt.show()","0f306ee0":"from sklearn.ensemble import RandomForestClassifier\nrandom = RandomForestClassifier()\nrandom.fit(tfid_train, y_train)\ny_pred=random.predict(tfid_test)","74418604":"print('Accuracy Score :: ', accuracy_score(y_pred, y_test))","895491c9":"fpr, tpr, thr = roc_curve(y_test, random.predict_proba(tfid_test)[:,1])\n#auc = auc(fpr, tpr)\nauc = roc_auc_score(y_test, mnb_tfidf_predict)\nlw = 2\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label=\"Curve Area = %0.3f\" % auc)\nplt.plot([0, 1], [0, 1], color='green', lw=lw, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic Plot')\nplt.legend(loc=\"lower right\")\nplt.show()","2eea68a1":"### Data Info","dfe951e7":"### Dropping Column and Filling Missing Values","8ebe0a2a":"### Exploratory Data Analysis","f99a1308":"## Real or Fake Job Post Prediction\n\nThis dataset contains 18K job descriptions out of which about 800 are fake. The data consists of both textual information and meta-information about the jobs. The dataset can be used to create classification models which can learn the job descriptions which are fraudulent.","f95294fc":"### Requirements","1aa7ae2f":"### TF-IDF Vectorizer","9eb10b67":"### Extracting Text Features","22f22bbf":"### Handling NaN Features","924ac34a":"### Read Dataset","6a023d5f":"### Text Cleaning\n#### Remove Punctuation, Stopwords and Applying WordNetLemmatizer","54a103c7":"### Train Test Split","6e9fe720":"### Number of words\n\nLet's compare the number of words in the fake post and real post and try to distinguish pattern in the fake and real post based on number of words used in the post.\n\n### Company Profile","909a66bb":"Pattern of words in company profile is same as character in company profile. fake post has less words in the company profile while real post has more words.\n\n### Description","f031dbcc":"### Importing Libraries","8bc39a5b":"### AUC Score","56d1e882":"We can see that fake post has less characters in the company profile while real post has more charaters.","02cb0754":"### WordCloud","c5fe7bbe":"### Naive Bayes","60afb9c0":"### Shape of Dataset","4c85df62":"### Null Values","c22a1c8d":"\n### Description","68b6e0c3":"Both the post has similar distribution of words in description.\n\n### Requirements","fd99db44":"### Length of each Text","e66d93bb":"The distribution of charaters in requirements of the fake and real post are similar.","08a09697":"The distribution of words in requirements of the fake and real post are similar.\n\n### Benefits","73653598":"Here, We can see class count is near 17014 for 0 (Real Post) and 866  for 1 (Fake Post). Target count is highly imbalanced. ","2ebe82b9":"### Target","1ffdde37":"### Benefits","7abbfe13":"### Number of characters\n\nLet's compare the number of character in the fake post and real post and try to distinguish pattern in the fake and real post based on number of charater used in the post.\n\n### Company profile","33b10af5":"### AUC Score","e7c5d774":"The distribution of charaters in requirements of the fake and real post are same around 1500 to 1800.","8830ae37":"The distribution of charaters in description of the fake and real post are similar but some fake post reach to 6000 to 6500 characters.","174497c4":"### Model Evaluation","2dc8c2ea":"### Random Forest","6039a083":"### Model Selection"}}