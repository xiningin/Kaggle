{"cell_type":{"241f7ca4":"code","1f8ff612":"code","156bda05":"code","7b2b14e8":"code","dcdf3594":"code","f1149de0":"code","6d34615f":"code","34828784":"code","80be7890":"code","6b9c1f48":"code","0bf702c3":"code","41da7c46":"code","5a474229":"code","dd04d3f0":"code","380525a9":"code","3677ec90":"code","604bf384":"code","87241c8a":"code","b0bfeb12":"code","7114f7b8":"code","f691235b":"code","f7e4bade":"code","1cff31fe":"code","72e2a2f2":"code","b6d686d7":"code","07850abe":"code","4720265b":"code","1ea795f9":"markdown","b850255a":"markdown","bc063b72":"markdown","e3e45a7a":"markdown","1080698c":"markdown","c6cb43b0":"markdown","3e518c57":"markdown","9af49082":"markdown","f74747be":"markdown","45f47811":"markdown","95597dea":"markdown","29d5147e":"markdown","8b7a62ca":"markdown","fabdd930":"markdown","4806d38b":"markdown","f3794486":"markdown","e612e4db":"markdown","8fa4ea22":"markdown","42fff01a":"markdown","efc685f2":"markdown","9092f521":"markdown","2e8c3259":"markdown","96be7e85":"markdown","e4e8b289":"markdown","bcb46e5f":"markdown","d9dce433":"markdown","d549e563":"markdown"},"source":{"241f7ca4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f8ff612":"import pandas as pd\n\ndf = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","156bda05":"print(df)","7b2b14e8":"df.plot.scatter(x=\"Class\", y=\"Amount\")\n#This line of code plots the class of the sample versus the ammount expent. This shows, clearly, that fraud transactions are most common in lower amounts.\n","dcdf3594":"import numpy as np\nimport math\n\nfraud = df[df[\"Class\"] == 1]\nn_fraud = df[df[\"Class\"] == 0]\n\nprint(fraud[\"Amount\"].describe())\n\nfraud.plot.hist(y=\"Amount\", bins=200, figsize=(30,10), alpha = 1)\nn_fraud.plot.hist(y=\"Amount\", bins=1000, figsize=(30,10), color = 'g')\n","f1149de0":"print(\"Not frauded transactions:\", len(n_fraud.index))\nprint(\"Fraud transactions:\", len(fraud.index))\n\nrlt = len(fraud.index) \/ len(n_fraud.index)\n\nprint(\"Relation between classes:\", rlt)","6d34615f":"import pandas as  pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n\nfig, ax = plt.subplots(figsize=(30,30)) \nsns.heatmap(df.corr(), annot=True, cmap=\"YlGnBu\", ax=ax)\nplt.show()","34828784":"from sklearn.feature_selection import SelectKBest, f_classif\n\nX = df.loc[:, \"Time\":\"Amount\"]\nY = df[\"Class\"]\n\n# instantiate SelectKBest to determine 20 best features\nbest_features = SelectKBest(score_func=f_classif, k=28)\nfit = best_features.fit(X,Y)\ndf_scores = pd.DataFrame(fit.scores_)\ndf_columns = pd.DataFrame(X.columns)\n\n# concatenate dataframes\nfeature_scores = pd.concat([df_columns, df_scores],axis=1)\nfeature_scores.columns = ['Feature_Name','Score']  # name output columns\nprint(feature_scores.nlargest(28,'Score'))  # print 20 best features\n","80be7890":"n_folds = 5","6b9c1f48":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\nx = df.loc[:, :\"Amount\"]\n\ny = df[\"Class\"]\n\n# splits data in train and test with a rate of 66% for training and 33% for testing\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n\n# skf = StratifiedKFold(n_splits=n_folds)\n\n# splits = skf.split(x, y)\n\n","0bf702c3":"from random import seed\nfrom random import random\n\nseed()\ndummy_predictions = []\n\nfor i in range(len(x_test)):\n    r = random()\n    dummy_predictions.append(1 if r < rlt else 0)\n    \n\n    dummy_predictions.count(0)","41da7c46":"# 1-rlt","5a474229":"from sklearn import metrics\nimport seaborn as sns\n\nprint('accyracy:\\t', metrics.accuracy_score(y_test.values.tolist(), dummy_predictions))\nprint('precision:\\t', metrics.precision_score(y_test.values.tolist(), dummy_predictions, average=\"micro\", labels=[1,0]))\nprint('recall:\\t\\t', metrics.recall_score(y_test.values.tolist(), dummy_predictions, pos_label=1))\nprint('f1:\\t\\t', metrics.f1_score(y_test.values.tolist(), dummy_predictions, average=\"micro\"))    \n\n\ncf_matrix = metrics.confusion_matrix(y_test, dummy_predictions)\n\ngroup_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()\/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')","dd04d3f0":"from sklearn.linear_model import LogisticRegression\n\n\n# 1. Instance of the model\nlogisticRegr = LogisticRegression(max_iter = 600, class_weight='balanced')\n\n# 2. Fit the model\nlogisticRegr.fit(x_train, y_train)\n\n# 3. Make predictions\npredictions = logisticRegr.predict(x_test)","380525a9":"import seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\n\n\nprint('accyracy:\\t', metrics.accuracy_score(y_test, predictions))\nprint('precision:\\t', metrics.precision_score(y_test, predictions))\nprint('recall:\\t\\t', metrics.recall_score(y_test, predictions))\nprint('f1:\\t\\t', metrics.f1_score(y_test, predictions)) \n\nprint(classification_report(y_test, predictions, target_names=['N\u00e3o Fraude', 'Fraude']))\n\n\ncf_matrix = metrics.confusion_matrix(y_test, predictions)\ngroup_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()\/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n","3677ec90":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom copy import deepcopy\nfrom sklearn.model_selection import StratifiedKFold\n\n\n# 1. Instance of the model\nlogisticRegr = LogisticRegression(max_iter = 600, class_weight='balanced')\n\nrecallFraud = []\nprecisionFraud = []\nrecallNotFraud = []\nprecisionNotFraud = []\nf1Fraud = []\nf1NotFraud = []\nprecision = []\nrecall = []\naccuracy = []\nf1 = []\n\nskf = StratifiedKFold(n_splits=n_folds)\nsplits = splits = skf.split(x_train, y_train)\n\n# 2. Fit the model\ni = 0\nfor train_index, test_index in splits:\n    \n    x_train_k, x_val_k = x_train.iloc[train_index], x_train.iloc[test_index]\n    y_train_k, y_val_k = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n    logisticRegr.fit(x_train, y_train)\n\n    # 3. Make predictions\n    y_pred = logisticRegr.predict(x_val_k)\n    print('---> Itera\u00e7\u00e3o:', i)\n    print(classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude']))\n    \n    \n    \n    result = classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude'], output_dict=True)\n    recallFraud.append(result['Fraude']['recall'])\n    recallNotFraud.append(result['N\u00e3o Fraude']['recall'])\n\n    precisionFraud.append(result['Fraude']['precision'])\n    precisionNotFraud.append(result['N\u00e3o Fraude']['precision'])\n\n    f1Fraud.append(result['Fraude']['f1-score'])\n    f1NotFraud.append(result['N\u00e3o Fraude']['f1-score'])\n    \n#     y_pred_full = logisticRegr.predict(x_test)\n    \n#     accuracy.append(metrics.accuracy_score(y_test, y_pred_full))\n#     precision.append(metrics.precision_score(y_test, y_pred_full))\n#     recall.append(metrics.recall_score(y_test, y_pred_full))\n#     f1.append(metrics.f1_score(y_test, y_pred_full)) \n    \n    i = i + 1\n    \nprint(\"Fraude precision (mean):\\t\", sum(precisionFraud)\/n_folds)\nprint(\"Fraude recall (mean):\\t\\t\", sum(recallFraud)\/n_folds)\nprint(\"Fraude f1-score (mean):\\t\\t\", sum(f1Fraud)\/n_folds)\n\nprint('\\n')\n\nprint(\"N\u00e3o Fraude precision (mean):\\t\", sum(precisionNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude recall (mean):\\t\", sum(recallNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude f1-score (mean):\\t\", sum(f1NotFraud)\/n_folds)\n\n# print('\\n')\n\n# print(\"Total accuracy (mean):\\t\\t\", sum(accuracy)\/n_folds)\n# print(\"Total precision (mean):\\t\\t\", sum(precision)\/n_folds)\n# print(\"Total recall (mean):\\t\\t\", sum(recall)\/n_folds)\n# print(\"Total f1-score (mean):\\t\\t\", sum(f1)\/n_folds)","604bf384":"from sklearn.linear_model import LogisticRegression\nfrom imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(sampling_strategy=0.7)\n    \nx_train_downsampled, y_train_downsampled = rus.fit_resample(x_train, y_train)\n\n\n# 1. Instance of the model\nlogisticRegr_down = LogisticRegression(max_iter = 600)\n\n# 2. Fit the model\nlogisticRegr_down.fit(x_train_downsampled, y_train_downsampled)\n\n# 3. Make predictions\npredictions_downsample = logisticRegr_down.predict(x_test)","87241c8a":"import seaborn as sns\nfrom sklearn import metrics\n\nprint('accuracy:\\t', metrics.accuracy_score(y_test, predictions_downsample))\nprint('precision:\\t', metrics.precision_score(y_test, predictions_downsample))\nprint('recall:\\t\\t', metrics.recall_score(y_test, predictions_downsample))\nprint('f1:\\t\\t', metrics.f1_score(y_test, predictions_downsample)) \n\nprint(classification_report(y_test, predictions_downsample, target_names=['N\u00e3o Fraude', 'Fraude']))\n\ncf_matrix = metrics.confusion_matrix(y_test, predictions_downsample)\n\ngroup_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()\/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')","b0bfeb12":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom copy import deepcopy\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# 1. Instance of the model\nlogisticRegr_down = LogisticRegression(max_iter = 600, class_weight='balanced')\n\nrecallFraud = []\nprecisionFraud = []\nrecallNotFraud = []\nprecisionNotFraud = []\nf1Fraud = []\nf1NotFraud = []\nprecision = []\nrecall = []\naccuracy = []\nf1 = []\n\nskf = StratifiedKFold(n_splits=n_folds)\nsplits_downsampled = skf.split(x_train, y_train)\n\n# 2. Fit the model\ni = 0\nfor train_index, test_index in splits_downsampled:\n    \n    rus = RandomUnderSampler(sampling_strategy=0.7)\n    \n    \n    \n    x_train_k, x_val_k = x_train.iloc[train_index], x_train.iloc[test_index]\n    y_train_k, y_val_k = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n    x_res, y_res = rus.fit_resample(x_train_k, y_train_k)\n    \n    logisticRegr_down.fit(x_res, y_res)\n\n    # 3. Make predictions\n    y_pred = logisticRegr_down.predict(x_val_k)\n    print('---> Itera\u00e7\u00e3o:', i)\n    print(classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude']))\n    \n    \n    \n    result = classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude'], output_dict=True)\n    recallFraud.append(result['Fraude']['recall'])\n    recallNotFraud.append(result['N\u00e3o Fraude']['recall'])\n\n    precisionFraud.append(result['Fraude']['precision'])\n    precisionNotFraud.append(result['N\u00e3o Fraude']['precision'])\n\n    f1Fraud.append(result['Fraude']['f1-score'])\n    f1NotFraud.append(result['N\u00e3o Fraude']['f1-score'])\n    \n#     y_pred_full = logisticRegr_down.predict(x_test)\n    \n#     accuracy.append(metrics.accuracy_score(y_test, y_pred_full))\n#     precision.append(metrics.precision_score(y_test, y_pred_full))\n#     recall.append(metrics.recall_score(y_test, y_pred_full))\n#     f1.append(metrics.f1_score(y_test, y_pred_full)) \n    \n    i = i + 1\n    \nprint(\"Fraude precision (mean):\\t\", sum(precisionFraud)\/n_folds)\nprint(\"Fraude recall (mean):\\t\\t\", sum(recallFraud)\/n_folds)\nprint(\"Fraude f1-score (mean):\\t\\t\", sum(f1Fraud)\/n_folds)\n\nprint('\\n')\n\nprint(\"N\u00e3o Fraude precision (mean):\\t\", sum(precisionNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude recall (mean):\\t\", sum(recallNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude f1-score (mean):\\t\", sum(f1NotFraud)\/n_folds)\n\n# print('\\n-> Utilizando o conjunto de teste padrao:\\n')\n\n# print(\"Total accuracy (mean):\\t\\t\", sum(accuracy)\/n_folds)\n# print(\"Total precision (mean):\\t\\t\", sum(precision)\/n_folds)\n# print(\"Total recall (mean):\\t\\t\", sum(recall)\/n_folds)\n# print(\"Total f1-score (mean):\\t\\t\", sum(f1)\/n_folds)","7114f7b8":"from sklearn import tree\n\n# 1. Instance of the model\nclf_tree = tree.DecisionTreeClassifier(max_depth = 5)\n\n# 2. Fit model \nclf_tree = clf_tree.fit(x_train, y_train)\n\n# 3. Make predictions\ntree_pred = clf_tree.predict(x_test)","f691235b":"import seaborn as sns\nfrom sklearn import metrics\n\nprint('accyracy:\\t', metrics.accuracy_score(y_test, tree_pred))\nprint('precision:\\t', metrics.precision_score(y_test, tree_pred))\nprint('recall:\\t\\t', metrics.recall_score(y_test, tree_pred))\nprint('f1:\\t\\t', metrics.f1_score(y_test, tree_pred), '\\n') \n\nprint(classification_report(y_test, tree_pred, target_names=['N\u00e3o Fraude', 'Fraude']))\n\ncf_matrix = metrics.confusion_matrix(y_test, tree_pred)\n\ngroup_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()\/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n ","f7e4bade":"import graphviz \ndot_data = tree.export_graphviz(clf_tree, out_file=None,   \n                      filled=True, rounded=True,  \n                      special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","1cff31fe":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom copy import deepcopy\n\n\nrecallFraud = []\nprecisionFraud = []\nrecallNotFraud = []\nprecisionNotFraud = []\nf1Fraud = []\nf1NotFraud = []\nprecision = []\nrecall = []\naccuracy = []\nf1 = []\n\nskf = StratifiedKFold(n_splits=n_folds)\nsplits = skf.split(x_train, y_train)\n\n# 2. Fit the model\ni = 0\nfor train_index, test_index in splits:\n    \n    x_train_k, x_val_k = x_train.iloc[train_index], x_train.iloc[test_index]\n    y_train_k, y_val_k = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n    # 1. Instance of the model\n    clf_tree = tree.DecisionTreeClassifier(max_depth = 5)\n    \n    clf_tree.fit(x_train_k, y_train_k)\n\n    # 3. Make predictions\n    y_pred = clf_tree.predict(x_val_k)\n    print('---> Itera\u00e7\u00e3o:', i)\n    print(classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude']))\n    \n    \n    \n    result = classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude'], output_dict=True)\n    recallFraud.append(result['Fraude']['recall'])\n    recallNotFraud.append(result['N\u00e3o Fraude']['recall'])\n\n    precisionFraud.append(result['Fraude']['precision'])\n    precisionNotFraud.append(result['N\u00e3o Fraude']['precision'])\n\n    f1Fraud.append(result['Fraude']['f1-score'])\n    f1NotFraud.append(result['N\u00e3o Fraude']['f1-score'])\n    \n#     y_pred_full = clf_tree.predict(x_test)\n    \n#     accuracy.append(metrics.accuracy_score(y_test, y_pred_full))\n#     precision.append(metrics.precision_score(y_test, y_pred_full))\n#     recall.append(metrics.recall_score(y_test, y_pred_full))\n#     f1.append(metrics.f1_score(y_test, y_pred_full)) \n    \n    i = i + 1\n    \nprint(\"Fraude precision (mean):\\t\", sum(precisionFraud)\/n_folds)\nprint(\"Fraude recall (mean):\\t\\t\", sum(recallFraud)\/n_folds)\nprint(\"Fraude f1-score (mean):\\t\\t\", sum(f1Fraud)\/n_folds)\n\nprint('\\n')\n\nprint(\"N\u00e3o Fraude precision (mean):\\t\", sum(precisionNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude recall (mean):\\t\", sum(recallNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude f1-score (mean):\\t\", sum(f1NotFraud)\/n_folds)\n\n# print('\\n-> Utilizando o conjunto de teste padrao:\\n')\n\n# print(\"Total accuracy (mean):\\t\\t\", sum(accuracy)\/n_folds)\n# print(\"Total precision (mean):\\t\\t\", sum(precision)\/n_folds)\n# print(\"Total recall (mean):\\t\\t\", sum(recall)\/n_folds)\n# print(\"Total f1-score (mean):\\t\\t\", sum(f1)\/n_folds)","72e2a2f2":"from sklearn import tree\nfrom imblearn.under_sampling import RandomUnderSampler\n\n\nrus = RandomUnderSampler(sampling_strategy=0.7)\n \nx_train_downsampled, y_train_downsampled = rus.fit_resample(x_train, y_train)\n\n\n# 1. Instance of the model\nclf_tree_downsampled = tree.DecisionTreeClassifier(max_depth=5)\n\n# 2. Fit model \nclf_tree_downsampled = clf_tree_downsampled.fit(x_train_downsampled, y_train_downsampled)\n\n# 3. Make predictions\ntree_pred_downsampled = clf_tree_downsampled.predict(x_test)","b6d686d7":"import seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\nprint('accyracy:\\t', metrics.accuracy_score(y_test, tree_pred_downsampled))\nprint('precision:\\t', metrics.precision_score(y_test, tree_pred_downsampled))\nprint('recall:\\t\\t', metrics.recall_score(y_test, tree_pred_downsampled))\nprint('f1:\\t\\t', metrics.f1_score(y_test, tree_pred_downsampled), '\\n') \n\nprint(classification_report(y_test, tree_pred_downsampled, target_names=['N\u00e3o Fraude', 'Fraude']))\n\ncf_matrix = metrics.confusion_matrix(y_test, tree_pred_downsampled)\n\ngroup_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()\/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')","07850abe":"import graphviz \ndot_data = tree.export_graphviz(clf_tree_downsampled, out_file=None,   \n                      filled=True, rounded=True,  \n                      special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","4720265b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom copy import deepcopy\nfrom imblearn.under_sampling import RandomUnderSampler\n\n\n# 1. Instance of the model\nclf_tree_downsampled = tree.DecisionTreeClassifier(max_depth=3)\n\nrecallFraud = []\nprecisionFraud = []\nrecallNotFraud = []\nprecisionNotFraud = []\nf1Fraud = []\nf1NotFraud = []\nprecision = []\nrecall = []\naccuracy = []\nf1 = []\n\nskf = StratifiedKFold(n_splits=n_folds)\nsplits_downsampled = skf.split(x_train, y_train)\n\n# 2. Fit the model\ni = 0\nfor train_index, test_index in splits_downsampled:\n    \n    x_train_k, x_val_k = x_train.iloc[train_index], x_train.iloc[test_index]\n    y_train_k, y_val_k = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n    rus = RandomUnderSampler(sampling_strategy=0.7)\n    x_train_downsampled, y_train_downsampled = rus.fit_resample(x_train_k, y_train_k)\n    \n    clf_tree_downsampled.fit(x_train_downsampled, y_train_downsampled)\n\n    # 3. Make predictions\n    y_pred = clf_tree_downsampled.predict(x_val_k)\n    print('---> Itera\u00e7\u00e3o:', i)\n    print(classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude']))\n    \n    \n    \n    result = classification_report(y_val_k, y_pred, target_names=['N\u00e3o Fraude', 'Fraude'], output_dict=True)\n    recallFraud.append(result['Fraude']['recall'])\n    recallNotFraud.append(result['N\u00e3o Fraude']['recall'])\n\n    precisionFraud.append(result['Fraude']['precision'])\n    precisionNotFraud.append(result['N\u00e3o Fraude']['precision'])\n\n    f1Fraud.append(result['Fraude']['f1-score'])\n    f1NotFraud.append(result['N\u00e3o Fraude']['f1-score'])\n    \n#     y_pred_full = clf_tree_downsampled.predict(x_test)\n    \n#     accuracy.append(metrics.accuracy_score(y_test, y_pred_full))\n#     precision.append(metrics.precision_score(y_test, y_pred_full))\n#     recall.append(metrics.recall_score(y_test, y_pred_full))\n#     f1.append(metrics.f1_score(y_test, y_pred_full)) \n    \n    i = i + 1\n    \nprint(\"Fraude precision (mean):\\t\", sum(precisionFraud)\/n_folds)\nprint(\"Fraude recall (mean):\\t\\t\", sum(recallFraud)\/n_folds)\nprint(\"Fraude f1-score (mean):\\t\\t\", sum(f1Fraud)\/n_folds)\n\nprint('\\n')\n\nprint(\"N\u00e3o Fraude precision (mean):\\t\", sum(precisionNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude recall (mean):\\t\", sum(recallNotFraud)\/n_folds)\nprint(\"N\u00e3o Fraude f1-score (mean):\\t\", sum(f1NotFraud)\/n_folds)\n\n# print('\\n-> Utilizando o conjunto de teste padrao:\\n')\n\n# print(\"Total accuracy (mean):\\t\\t\", sum(accuracy)\/n_folds)\n# print(\"Total precision (mean):\\t\\t\", sum(precision)\/n_folds)\n# print(\"Total recall (mean):\\t\\t\", sum(recall)\/n_folds)\n# print(\"Total f1-score (mean):\\t\\t\", sum(f1)\/n_folds)","1ea795f9":"### 3.5.1 Create and train the model","b850255a":"### 3.6.3 Using K-Fold","bc063b72":"### 3.6.2 Evaluate model","e3e45a7a":"### 3.4.2 Evaluate model","1080698c":"### 3.7.1 Create and train model","c6cb43b0":"### 3.2.1 Creating model","3e518c57":"### 1.2. Relation between classes","9af49082":"# 3. Classifiers","f74747be":"## 3.6 Decision Trees - Unbalanced","45f47811":"### 3.2.2 Evaluate model","95597dea":"The heatmap above indicates the correlation between each variable. We are interested specially in the correlation of each variable and the variable \"Class\", and we can see that all the correlations have a low value, and that the ones with higher value are v4 (with 0,13) and v11 (with 0,15), for positive values, and v17 (with -0,33) and v14 (with 0,3), for negative values.","29d5147e":"## 3.2 Dummy Clissifier - unbalanced\nRandomly pick a class according to the relation between the classes","8b7a62ca":"# 1. Analise Transaction's amount\n\nIn this section we are analising the ammount of the transactions.","fabdd930":"### 3.5.2 Evaluate model","4806d38b":"### 3.4.1 Create and train the model","f3794486":"### 3.7.2 Evaluate Model","e612e4db":"### 3.1.1 Split train and test data - unbalanced","8fa4ea22":"## 3.7. Decision trees - Downsampled","42fff01a":"## 3.4. Logistic regression - unbalanced","efc685f2":"## 3.5. Logistic regression - Downsampled","9092f521":"As we can see in the plots bellow above, most of the transactions do not count with high ammounts, including the fraudulent transactions.","2e8c3259":"### 3.6.1 Create and train model","96be7e85":"### 3.7.3 Using K-Fold","e4e8b289":"### 3.4.3 Using K-fold","bcb46e5f":"### 3.5.3 Using K-Fold","d9dce433":"## 3.1 Dataset","d549e563":"# 2.Variables correlation\n\nIn this section we aim to understand how each variable interfere with the other ones"}}