{"cell_type":{"4453356b":"code","e0d32136":"code","53549f7e":"code","5b0c458b":"code","82a62621":"code","1315a485":"code","1665bdfb":"code","0c90d381":"code","0391457a":"code","8a6fd0f1":"code","56f3feb7":"code","87756a94":"code","8c09dd8e":"code","4b0e9f62":"code","222dd730":"code","f78cda05":"code","ab4535c1":"code","d39c94d6":"code","d06ea5f6":"code","ceab6d3d":"code","b4a3634e":"code","91fb1389":"code","24542cb8":"code","c308fbdd":"code","26bb2dba":"code","1ff8ea7c":"code","0bfffd72":"code","7a42954f":"code","c09ad36e":"code","0cafc676":"code","8de561d8":"code","b017fae0":"code","5da0aaf0":"code","bbc72ce0":"code","1a909c5f":"code","49e356ba":"markdown","fa124b18":"markdown","7095db69":"markdown","2359789d":"markdown","fea95321":"markdown","528e5770":"markdown","014dfe3e":"markdown","957fa5d8":"markdown","5a305420":"markdown","d0485d1a":"markdown","10ea3aa7":"markdown","849b0712":"markdown","37647fc5":"markdown","1985813f":"markdown","164345fd":"markdown","8d72a252":"markdown","6d6c36f2":"markdown","ca306e90":"markdown","59c87cc8":"markdown"},"source":{"4453356b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0d32136":"import torch\nimport torch.nn as nn\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\nimport transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup","53549f7e":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","5b0c458b":"SEED = 1234\n\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","82a62621":"train_df = pd.read_csv(\"\/kaggle\/input\/quora-question-pairs\/train.csv.zip\")\ntrain_df.info()","1315a485":"# remove Null Values\ntrain_df.dropna(inplace=True)","1665bdfb":"train_sentences_lens = train_df['question1'].apply(lambda x: len(x.split(' '))).tolist()\ntrain_sentences_lens.extend(train_df['question2'].apply(lambda x: len(x.split(' '))).tolist())\nsns.distplot(train_sentences_lens)","0c90d381":"MAX_LEN = 40","0391457a":"def pie_chart(similar_questions_num, different_questions_num, set_type):\n    labels = 'Similiar', 'Different'\n    sizes = [similar_questions_num, different_questions_num]\n\n    fig1, ax1 = plt.subplots()\n    ax1.set_title(set_type)\n    ax1.pie(sizes, labels=labels, autopct='%1.2f%%', shadow=True, startangle=90)\n\n    plt.show()\n\nsimilar_samples_num = sum(train_df['is_duplicate'].values)\npie_chart(similar_samples_num, len(train_df['is_duplicate']) - similar_samples_num, 'train set')","8a6fd0f1":"qids = pd.Series(list(train_df['qid1']) + list(train_df['qid2']))\n\nprint ('Unique Questions number: {}\\n'.format(len(np.unique(qids))))\n\nq_vals=qids.value_counts()[0:5]\nprint ('Top 5 most frequently asked questions: ')\n\nfor pair in q_vals.iteritems():\n    print(train_df.loc[train_df['qid2']==pair[0]]['question1'].head(1).values + \" count: \" + str(pair[1]))\n\nq_vals=q_vals.values","56f3feb7":"duplicate_rows = train_df[train_df.duplicated(['qid1','qid2'])]\nprint (\"Number of duplicate questions : \", len(duplicate_rows))","87756a94":"x = [\"Unique\" , \"Repeated\"]\ny =  [len(np.unique(qids)), np.sum(qids.value_counts() > 1)]\n\nplt.figure(figsize=(10, 8))\nplt.title (\"Unique and Repeated questions counts\")\nsns.barplot(x,y)\nplt.show()","8c09dd8e":"# Number of common unique words in question1 and question2\ndef common_words(row):\n    q1_word_set = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    q2_word_set = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return 1.0 * len(q1_word_set & q2_word_set)\n\ntrain_df['common_words'] = train_df.apply(common_words, axis=1)","4b0e9f62":"plt.figure(figsize=(15, 10))\n\nplt.subplot(1,2,2)\nsns.distplot(train_df[train_df['is_duplicate'] == 1]['common_words'][0:] , label = \"1\", color = 'red')\nsns.distplot(train_df[train_df['is_duplicate'] == 0]['common_words'][0:] , label = \"0\" , color = 'blue' )\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y = 'common_words', data = train_df[0:])\n\nplt.show()","222dd730":"# Number of common words between question1 and question2 divided by total words between both of them\ndef shared_words(row):\n    q1_word_set = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    q2_word_set = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return 1.0 * len(q1_word_set & q2_word_set) \/ (len(q1_word_set) + len(q2_word_set))    \n\ntrain_df['shared_words'] = train_df.apply(shared_words, axis=1)","f78cda05":"plt.figure(figsize=(15, 10))\n\nplt.subplot(1,2,2)\nsns.distplot(train_df[train_df['is_duplicate'] == 1]['shared_words'][0:] , label = \"1\", color = 'red')\nsns.distplot(train_df[train_df['is_duplicate'] == 0]['shared_words'][0:] , label = \"0\" , color = 'green' )\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y = 'shared_words', data = train_df[0:])\n\nplt.show()","ab4535c1":"BERT_VERSION = 'bert-base-uncased'\nPOOLED_OUTPUT_DIM = 768 ","d39c94d6":"tokenizer = BertTokenizer.from_pretrained(BERT_VERSION)","d06ea5f6":"# split data to train and validation sets\ntrain_df, val_df = train_test_split(train_df, test_size=0.1)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","ceab6d3d":"class BertDataSet:\n    def __init__(self, first_questions, second_questions, targets, tokenizer):\n        self.first_questions = first_questions\n        self.second_questions = second_questions\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.length = len(first_questions)\n        \n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, item):\n        first_question = str(self.first_questions[item])\n        second_question = str(self.second_questions[item])\n\n        # removes extra white spaces from questions\n        first_question = \" \".join(first_question.split())\n        second_question = \" \".join(second_question.split())\n        \n        ### [CLS] question1 [SEP] questions2 [SEP] ... [PAD]\n        inputs = self.tokenizer.encode_plus(\n            first_question,\n            second_question,\n            add_special_tokens=True,\n            padding='max_length',\n            max_length=2 * MAX_LEN + 3, # max length of 2 questions and 3 special tokens\n            truncation=True   \n        )\n        \n        # return targets 0, when using data set in testing and targets are none\n        return {\n            \"ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n            \"mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n            \"token_type_ids\": torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n            \"targets\": torch.tensor(int(self.targets[item]), dtype=torch.long) if self.targets is not None else 0\n        }\n        ","b4a3634e":"# creates dataset and returns dataloader of it\ndef get_data_loader(df, targets, batch_size, shuffle, tokenizer):\n    dataset = BertDataSet(\n        first_questions=df[\"question1\"].values,\n        second_questions=df[\"question2\"].values,\n        targets=targets,\n        tokenizer=tokenizer\n    )\n    \n    data_loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size = batch_size,\n        shuffle=shuffle\n    )\n    \n    return data_loader","91fb1389":"# training batch size we gonna use throughout this notebook.\nBS = 128","24542cb8":"# create data loaders of training and validation data.\ntrain_data_loader = get_data_loader(\n    df=train_df,\n    targets=train_df[\"is_duplicate\"].values,\n    batch_size=BS,\n    shuffle=True,\n    tokenizer=tokenizer\n)\n\nval_data_loader = get_data_loader(\n    df=val_df,\n    targets=val_df[\"is_duplicate\"].values,\n    batch_size=4 * BS,\n    shuffle=True,\n    tokenizer=tokenizer\n)","c308fbdd":"class BertModel(nn.Module):\n    def __init__(self, bert_path):\n        super(BertModel, self).__init__()\n        self.bert_path = bert_path\n        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n        self.dropout = nn.Dropout(0.3)\n        self.out = nn.Linear(POOLED_OUTPUT_DIM, 1)\n\n    def forward(self, ids, mask, token_type_ids):\n        _, pooled = self.bert(ids, attention_mask=mask,token_type_ids=token_type_ids)\n        \n        # add dropout to prevent overfitting.\n        pooled = self.dropout(pooled) \n        return self.out(pooled)\n\nmodel = BertModel(BERT_VERSION).to(device)","26bb2dba":"# loss function is simple binary cross entropy loss\n# need sigmoid to put probabilities in [0,1] interval\ndef loss_fn(outputs, targets):\n    outputs = torch.squeeze(outputs)\n    return nn.BCELoss()(nn.Sigmoid()(outputs), targets)","1ff8ea7c":"# computes perplexity on validation data\ndef calculate_perplexity(data_loader, model, device):\n    model.eval()\n    \n    # tells Pytorch not to store values of intermediate computations for backward pass because we not gonna need gradients.\n    with torch.no_grad():\n        total_loss = 0\n        for batch in data_loader:\n            ids = batch[\"ids\"].to(device, dtype=torch.long)\n            mask = batch[\"mask\"].to(device, dtype=torch.long)\n            token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n            targets = batch[\"targets\"].to(device, dtype=torch.float)\n\n            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n            total_loss += loss_fn(outputs, targets).item()\n            \n    model.train()\n\n    return np.exp(total_loss \/ len(data_loader))","0bfffd72":"def train_loop(epochs, train_data_loader, val_data_loader, model, optimizer, device, scheduler=None):\n    it = 1\n    total_loss = 0\n    curr_perplexity = None\n    perplexity = None\n    \n    model.train()\n    for epoch in range(epochs):\n        print('Epoch: ', epoch + 1)\n        for batch in train_data_loader:\n            ids = batch[\"ids\"].to(device, dtype=torch.long)\n            mask = batch[\"mask\"].to(device, dtype=torch.long)\n            token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n            targets = batch[\"targets\"].to(device, dtype=torch.float)\n\n            optimizer.zero_grad()\n            \n            # do forward pass, will save intermediate computations of the graph for later backprop use.\n            outputs = model(ids, mask=mask, token_type_ids=token_type_ids)\n            \n            loss = loss_fn(outputs, targets)\n            total_loss += loss.item()\n            \n            # running backprop.\n            loss.backward()\n            \n            # doing gradient descent step.\n            optimizer.step()\n            \n            # we are logging current loss\/perplexity in every 100 iteration\n            if it % 100 == 0:\n                \n                # computing validation set perplexity in every 500 iteration.\n                if it % 500 == 0:\n                    curr_perplexity = calculate_perplexity(val_data_loader, model, device)\n                    \n                    if scheduler is not None:\n                        scheduler.step()\n\n                    # making checkpoint of best model weights.\n                    if not perplexity or curr_perplexity < perplexity:\n                        torch.save(model.state_dict(), 'saved_model')\n                        perplexity = curr_perplexity\n\n                print('| Iter', it, '| Avg Train Loss', total_loss \/ 100, '| Dev Perplexity', curr_perplexity)\n                total_loss = 0\n\n            it += 1\n        ","7a42954f":"def run(model, train_df, device, train_data_loader, val_data_loader):\n    EPOCHS = 1\n    \n    lr = 3e-5\n    num_training_steps = int(len(train_data_loader) * EPOCHS)\n    optimizer = AdamW(model.parameters(), lr=lr)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=0,\n        num_training_steps=num_training_steps\n    )\n    \n    \n    train_loop(EPOCHS, train_data_loader, val_data_loader,  model, optimizer, device, scheduler)","c09ad36e":"run(model, train_df, device, train_data_loader, val_data_loader)","0cafc676":"test_df = pd.read_csv(\"\/kaggle\/input\/quora-question-pairs\/test.csv\")\ntest_df.head()","8de561d8":"# this function returns probabilities for every test case.\ndef test(model, test_df, device):\n    predictions = torch.empty(0).to(device, dtype=torch.float)\n    \n    test_dataset = BertDataSet(\n        first_questions=test_df[\"question1\"].values,\n        second_questions=test_df[\"question2\"].values,\n        targets=None,\n        tokenizer=tokenizer\n    )\n    \n    test_data_loader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=512\n    )\n    \n    with torch.no_grad():\n        model.eval()\n        for batch in tqdm(test_data_loader):\n            ids = batch[\"ids\"]\n            mask = batch[\"mask\"]\n            token_type_ids = batch[\"token_type_ids\"]\n\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n\n            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n            predictions = torch.cat((predictions, nn.Sigmoid()(outputs)))\n    \n    return predictions.cpu().numpy().squeeze()\n\npredictions = test(model, test_df, device)\nlen(predictions)","b017fae0":"# write down answers in is_duplicate column.\ntest_df['is_duplicate'] = predictions","5da0aaf0":"# save results to submission.csv.\ntest_df[['test_id', 'is_duplicate']].to_csv('submission.csv', index=False)","bbc72ce0":"# prints if two questions is similar and score of confidence\ndef eval(model, tokenizer, first_question, second_question, device):\n    inputs = tokenizer.encode_plus(\n        first_question,\n        second_question,\n        add_special_tokens=True,\n    )\n\n    ids = torch.tensor([inputs[\"input_ids\"]], dtype=torch.long).to(device, dtype=torch.long)\n    mask = torch.tensor([inputs[\"attention_mask\"]], dtype=torch.long).to(device, dtype=torch.long)\n    token_type_ids = torch.tensor([inputs[\"token_type_ids\"]], dtype=torch.long).to(device, dtype=torch.long)\n\n    with torch.no_grad():\n        model.eval()\n        output = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n        prob = nn.Sigmoid()(output).item()\n\n        print(\"questions [{}] and [{}] are {} with score {}\".format(first_question, second_question, 'similar' if prob > 0.5 else 'not similar', prob))","1a909c5f":"# change questions to test model\nfirst_question = \"how to register on hackerrank with google account?\"\nsecond_question = \"Can I sign using google account on hackerrank?\"\n\neval(model, tokenizer, first_question, second_question, device)","49e356ba":"# Data analysis","fa124b18":"The data is more or less balanced","7095db69":"### Checking whether there are any repeated pair of questions","2359789d":"As we can see from the graphs, the rate of shared words is on average higher in similar question pairs","fea95321":"**test whether the system has a GPU support and fix device variable accordingly**","528e5770":"### Common words plots","014dfe3e":"### Shared words plots","957fa5d8":"# Evaluation","5a305420":"### Draw pie chart which shows distribution of positive and negative examples","d0485d1a":"# Model","10ea3aa7":"As we see from the graph, the number of cases where words counts greater than 40 is too small.","849b0712":"common words distributions more or less the same in both kind of question pairs","37647fc5":"**Set the random seeds for deterministic results.**","1985813f":"### See most frequently asked questions","164345fd":"# Training","8d72a252":"# Testing","6d6c36f2":"### Draw graph which shows number of words in both questions.","ca306e90":"# Dataset Preparation","59c87cc8":"### Plot representing unique and repeated question counts"}}