{"cell_type":{"fceef638":"code","89ba694b":"code","79f3b59d":"code","3ec9f580":"code","87dd55cc":"code","83bd72fe":"code","ebd9f274":"code","0a2f9e90":"markdown","ace68ff6":"markdown","501060f5":"markdown","79d741ed":"markdown","35a08541":"markdown"},"source":{"fceef638":"import torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data.sampler import *\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms, datasets\nimport torchvision\nimport numpy as np\nimport torchvision.models as models\n\ndataset_root = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\"\nbatch_size = 128\ntarget_size = (224,224)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","89ba694b":"# Get the transforms\ndef load_datasets():\n\n    # Transforms for the image.\n    transform = transforms.Compose([\n                        transforms.Grayscale(),\n                        transforms.Resize(target_size),\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.5,), (0.5,)),\n                        nn.Flatten()\n                ])\n\n    # Define the image folder for each of the data set types\n    trainset = torchvision.datasets.ImageFolder(\n        root=dataset_root + 'train',\n        transform=transform\n    )\n    validset = torchvision.datasets.ImageFolder(\n        root=dataset_root + 'val',\n        transform=transform\n    )\n    testset = torchvision.datasets.ImageFolder(\n        root=dataset_root + 'test',\n        transform=transform\n    )\n\n\n    # Define indexes and get the subset random sample of each.\n    train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n    valid_dataloader = torch.utils.data.DataLoader(validset, batch_size=len(validset), shuffle=True)\n    test_dataloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=True)\n\n\n    # Convert data to tensors. This could be made faster.\n    x_test = []\n    y_test = []\n    for idx, (data, tar) in enumerate(test_dataloader):\n        x_test = data.squeeze()\n        y_test = tar.squeeze()\n\n    x_train = []\n    y_train = []\n    for idx, (data, tar) in enumerate(train_dataloader):\n        x_train = data.squeeze()\n        y_train = tar.squeeze()\n        \n    x_test = torch.tensor(x_test, device=device)\n    y_test = torch.tensor(y_test, device=device)\n    x_train = torch.tensor(x_train, device=device)\n    y_train = torch.tensor(y_train, device=device)\n    return x_train, y_train, x_test, y_test","79f3b59d":"def knn(x_train, y_train, x_test, k, device, log_interval=100, log=True):\n\n    # Get the amount of images, training images, and image size.\n    num_images = x_test.shape[0]\n    num_train = y_train.shape[0]\n    img_size = x_test.shape[1]\n\n    y_test = torch.zeros((num_images), device=device, dtype=torch.float)\n\n    # For each of the images in the test set\n    for test_index in range(0, num_images):\n\n        # Get the image and calculate the distance to every item in the trainset\n        test_image = x_test[test_index]\n        distances = torch.norm(x_train - test_image, dim=1)\n\n        # Get the top k indexes and get the most used index between them all\n        indexes = torch.topk(distances, k, largest=False)[1]\n        classes = torch.gather(y_train, 0, indexes)\n        mode = int(torch.mode(classes)[0])\n\n        # Save the test value in the index.\n        y_test[test_index] = mode\n\n        # Logging since with large sets it may be helpful\n        if log:\n            if test_index % log_interval == 0:\n                print(\"Currently predicting at test_index = %d\" % test_index)\n\n    return y_test","3ec9f580":"print(\"Loading data from folders.\")\nx_train, y_train, x_test, y_test = load_datasets()\nprint(\"Loaded train and test with sizes: %s, %s\" % (str(x_train.shape), str(x_test.shape)))","87dd55cc":"pred = knn(x_train, y_train, x_test, k=1, device=device)","83bd72fe":"correct = pred.eq(y_test.to(device).view_as(pred)).sum()\nprint(\"Correct predictions: %d\/%d, Accuracy: %f\" % (correct, y_test.shape[0], 100. * correct \/ y_test.shape[0]))","ebd9f274":"#https:\/\/en.wikipedia.org\/wiki\/K-nearest_neighbors_algorithm suggests k = ~sqrt(N).\nk_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 25, 37, 49, int(np.floor(np.sqrt(x_train.shape[0]))), 200]\n\ncorrect_vals = []\n\nbest_k = -1\nbest_correct = 0\n\nfor k in k_values:\n    pred = knn(x_train, y_train, x_test, k=k, device=device, log=False)\n    correct = pred.eq(y_test.view_as(pred)).sum()\n    print(\"K = %d, Correct: %d, Accuracy: %.2f\" % (k, correct, 100. * correct \/ y_test.shape[0]))","0a2f9e90":"# KNN\nhttps:\/\/en.wikipedia.org\/wiki\/K-nearest_neighbors_algorithm\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/e\/e7\/KnnClassification.svg\/330px-KnnClassification.svg.png)\n\n\nThe objective is given a bunch of training data and pairs, find the k closest training examples and get their labels. Whatever label has the highest probability is what the test image is classified as.\n\nFor this instance, the green dot is our test xray image. Depending on how many neighbours we consider it will change the outcome of how we classify our test image. K = 2 will classify it as red (PNEUMONIA), while K = 5 will classify it as blue (NORMAL).","ace68ff6":"# Objective\nThis notebook was created as a clone of my CMPUT 466 machine learning project on google colab. A majority of the primary data analysis is missing. One of the noted items was the lack of validation data which was modified. For the purpose of this kaggle notebook, the code is below to modify the data set but will not be used.\n\n```\ndef copy_files(PATH, NEWPATH, AMOUNT):\n    filelist = os.listdir(PATH)\n    for i in range(0, AMOUNT):\n        os.rename(PATH + filelist[i], NEWPATH + filelist[i])\n\ntest_balance = 50\ntrain_balance = 200\n\n# This is to balance out the 16 validation by taking from test and train.\ntarget_path = \"\/content\/chest_xray\/val\/\"\ntrain_path = \"\/content\/chest_xray\/train\/\"\ntest_path = \"\/content\/chest_xray\/test\/\"\n\ncopy_files(train_path + \"NORMAL\/\", target_path + \"NORMAL\/\", 100)\ncopy_files(train_path + \"PNEUMONIA\/\", target_path + \"PNEUMONIA\/\", 100)\ncopy_files(test_path + \"NORMAL\/\", target_path + \"NORMAL\/\", 50)\ncopy_files(test_path + \"PNEUMONIA\/\", target_path + \"PNEUMONIA\/\", 50)\n\n```\n\nThe goal of this notebook is to classify whether or not the user has pneumonia or not. This attempt uses K-Nearest Neighbours","501060f5":"# Data Loading and Modifications\nThe following transformations are performed on the data:\n* Convert it to greyscale as x-rays are black and white\n* Resize the image to the VGG-16 input size of (224, 224)\n* Convert the image to a tensor\n* Normalize with std=0.5, mean=0.5\n* Flatten the image","79d741ed":"# Hyperparameter Grid Search\nThis performs grid search on some common K-values as well as some guesses to see what the best result ends up being.","35a08541":"# Testing"}}