{"cell_type":{"cf291672":"code","8397bf57":"code","c14cc889":"code","98b41fd8":"code","b19cc079":"code","92f0107f":"code","af925ced":"code","2e3bb7f1":"code","51856739":"code","7ff93436":"code","138d74b8":"code","dee121eb":"code","6b984605":"code","7e689f07":"code","2cfc430a":"code","c94721b9":"code","dab65cdc":"code","58e44018":"code","e32f67ec":"code","90664621":"code","e65e3025":"code","3fe7664e":"code","23fd9f32":"code","12f3f2f2":"code","4520aade":"code","c467d4de":"code","81ef75bf":"code","8654a6da":"code","57ba7191":"code","fb2f5505":"code","24c97de6":"code","67ff678e":"code","67293e03":"code","6fa50af0":"code","c81c2d9e":"code","7855799e":"code","9e51bb73":"code","f52d4e69":"code","48ce0cdb":"code","7b24819e":"code","4a25aa50":"code","1aacd6f5":"code","77c2ced6":"code","bfaa19cc":"code","f2ff868e":"code","8f716533":"code","8958849c":"code","d64a14d5":"code","b6a07d37":"code","1daa337c":"code","eb29296a":"code","23246e73":"code","da4e88c0":"code","430f7cca":"code","dcd6a673":"code","cbf6a11d":"code","9caaabd6":"code","bfcb3a6c":"code","faad038e":"code","bfb9cea6":"code","2e2379b7":"code","0a12b10d":"code","56d8e40e":"code","ac35aec4":"code","6f63e34c":"code","c366adaf":"code","ccf6ce9d":"code","0427d859":"code","1feaaf58":"code","8d97e92f":"code","e77a4e49":"code","47f76555":"code","6e5bb565":"code","67e86c9a":"code","f35ac108":"code","3444dbb2":"code","962f935d":"code","836dd68b":"code","38e51187":"code","61e63cdf":"code","8c36df51":"code","a4b450a0":"code","0aac6ed8":"code","a4a2a68a":"code","ce41fe34":"code","29a06ad4":"code","52942e96":"code","aefc0104":"code","f637a19f":"code","5e38065e":"code","1878f51f":"code","ce9afafa":"code","4deb67df":"code","5c866658":"code","7d8340f4":"code","618a6ac1":"code","4569f30e":"code","9ff9a316":"code","b1e0585d":"code","b57566c7":"code","494dd410":"code","87dcffd7":"code","4ac84646":"code","6ec7b6f1":"code","64bb9000":"code","de224ef1":"code","042270a6":"code","2c84a26c":"code","aa518ac3":"code","66d9f9f9":"code","ee8eb0d0":"code","1b2c7c31":"code","0ee408d3":"code","b45c1ab4":"code","f989a03d":"code","bdd303e5":"code","878c8783":"code","0495ad8c":"code","8c7725d3":"code","2c2bf96b":"code","7df7fb7b":"markdown","af904ea0":"markdown","335e7724":"markdown","08f18a24":"markdown","ffc612f6":"markdown","2cf2f2e6":"markdown","db515797":"markdown","f7c7c401":"markdown","23d95120":"markdown","c106b375":"markdown","8b70605c":"markdown","4ba057bc":"markdown","a12d9c23":"markdown","21d085ea":"markdown","973e02dd":"markdown","cb35c5dd":"markdown","45d7d721":"markdown","c08f93f2":"markdown","745b4cb7":"markdown","7b261ed7":"markdown","24a68e7f":"markdown","36bbebfb":"markdown","33ee1f7a":"markdown","c42717bc":"markdown","779bd0da":"markdown","5b19ad0f":"markdown","25fd9023":"markdown","e2c5b683":"markdown","b049ba0a":"markdown","93884ea3":"markdown","e0b01da1":"markdown","c3ae2101":"markdown","0cf7f2d6":"markdown","e23919bb":"markdown","7787d2de":"markdown","4d38d77b":"markdown","d61ab665":"markdown","daa3675f":"markdown","90a1580a":"markdown","bc5a4d80":"markdown","f741823f":"markdown","34835868":"markdown","1dbe6b88":"markdown","e0800ad3":"markdown","c2042aae":"markdown","183fe2c9":"markdown","c168be89":"markdown","7e114484":"markdown","627a740c":"markdown","739ce8d5":"markdown","151dc885":"markdown","742bfd7a":"markdown","433403fe":"markdown","19300211":"markdown","31f92ed3":"markdown","1a460d87":"markdown","bbb0bd84":"markdown","992b819e":"markdown","ef008671":"markdown","3fd5e046":"markdown","7b08a906":"markdown","c60a2128":"markdown","5a3338b9":"markdown","a825777a":"markdown","977e1982":"markdown","3d2a185d":"markdown","6dcd65d4":"markdown","3416c59d":"markdown","10e2c53c":"markdown","c5efc2e4":"markdown","b50e470d":"markdown","f746cd34":"markdown","f5c9cae5":"markdown","6b5d1c15":"markdown","640ce08f":"markdown","bf4d2402":"markdown"},"source":{"cf291672":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8397bf57":"# Import required libraries\n\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns # data visualization\n\nimport warnings # Warnings\nwarnings.filterwarnings('ignore') # Ignore warnings","c14cc889":"# Embed static images in notebook\n%matplotlib inline\n\n# Show upto 150 rows and columns in a DataFrame\npd.set_option('display.max_columns', 150)\npd.set_option('display.max_rows', 150)","98b41fd8":"# Detecting the encoding of the files to be imported\n\nimport chardet\n\ndef find_encoding(fname):\n    r_file = open(fname, 'rb').read()\n    result = chardet.detect(r_file)\n    charenc = result['encoding']\n    return charenc\n\nprint(\"Encoding of the application_data file: \" + find_encoding('\/kaggle\/input\/bank-loans-dataset\/application_data.csv'))\nprint(\"Encoding of the previous_application file: \" + find_encoding('\/kaggle\/input\/bank-loans-dataset\/previous_application.csv'))","b19cc079":"# Time to read the files\n\napplication_data = pd.read_csv('\/kaggle\/input\/bank-loans-dataset\/application_data.csv', encoding = 'ascii')\nprev_application = pd.read_csv('\/kaggle\/input\/bank-loans-dataset\/previous_application.csv', encoding = 'ascii')","92f0107f":"# Shape of the dataframes\n\nprint('Application Data: ', application_data.shape)\nprint('Previous Application Data: ', prev_application.shape)","af925ced":"# Snapshots of the datasets\n\napplication_data.head()","2e3bb7f1":"prev_application.head()","51856739":"# Statistical summary of application data\n\napplication_data.describe()","7ff93436":"# Statistical summary of application data\n\napplication_data.describe(include = 'all')","138d74b8":"# Statistical summary of Previous Application Data\n\nprev_application.describe()","dee121eb":"# Get percentage of missing data for each column and save it in another DataFrame\n\napp_data_missing = pd.DataFrame(100*application_data.isnull().sum()\/application_data.shape[0]).reset_index()","6b984605":"# Creating a chart for missing values\n\nplt.figure(figsize = (20,5))\nplt.plot(app_data_missing['index'], app_data_missing[0])\nplt.xticks(rotation = 90, fontsize = 8)\nplt.title('Percentage of missing values in each column of Application Data', fontsize = 14)\nplt.xlabel('Columns \/ Variables', fontsize = 10)\nplt.ylabel('Percentage Missing', fontsize = 10)\nplt.grid(b = True)\nplt.show()","7e689f07":"# Storing the variables having >45% missing values in a list\n\nmiss_cols = list(app_data_missing.loc[app_data_missing[0] > 45, 'index'])\nlen(miss_cols)","2cfc430a":"# Removing the high missing columns\n\napplication_data.drop(miss_cols, axis = 1, inplace = True)","c94721b9":"# Checking the shape of application data again\n\napplication_data.shape","dab65cdc":"# Dropping FLAG_WORK_PHONE variable\n\napplication_data.drop('FLAG_WORK_PHONE', axis = 1, inplace = True)","58e44018":"# Dropping EXT_SOURCE_2, EXT_SOURCE_3 variables\n\napplication_data.drop(['EXT_SOURCE_2', 'EXT_SOURCE_3'], axis = 1, inplace = True)","e32f67ec":"# Removing unnecessary columns\n\napplication_data.drop(['NAME_TYPE_SUITE', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY'], axis = 1, inplace = True)","90664621":"# Creating the NUM_DOCS_ADDED Column\n\napplication_data['NUM_DOCS_ADDED'] = application_data['FLAG_DOCUMENT_2'] + application_data['FLAG_DOCUMENT_3'] + application_data['FLAG_DOCUMENT_4'] + application_data['FLAG_DOCUMENT_5'] + application_data['FLAG_DOCUMENT_6'] + application_data['FLAG_DOCUMENT_7'] + application_data['FLAG_DOCUMENT_8'] + application_data['FLAG_DOCUMENT_9'] + application_data['FLAG_DOCUMENT_10'] + application_data['FLAG_DOCUMENT_11'] + application_data['FLAG_DOCUMENT_12'] + application_data['FLAG_DOCUMENT_13'] + application_data['FLAG_DOCUMENT_14'] + application_data['FLAG_DOCUMENT_15'] + application_data['FLAG_DOCUMENT_16'] + application_data['FLAG_DOCUMENT_17'] + application_data['FLAG_DOCUMENT_18'] + application_data['FLAG_DOCUMENT_19'] + application_data['FLAG_DOCUMENT_20'] + application_data['FLAG_DOCUMENT_21']","e65e3025":"# Removing Document flag variables\n\napplication_data.drop(['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21'], axis = 1, inplace = True)","3fe7664e":"# Updated shape of Application Data\n\napplication_data.shape","23fd9f32":"# Print percentage missing values of each column\n\nprint(100*application_data.isnull().sum()\/application_data.shape[0])","12f3f2f2":"# Removing missing values for AMT_ANNUITY\napp_data_1 = application_data[~application_data['AMT_ANNUITY'].isnull()].copy()\n\n# Removing missing values for AMT_GOODS_PRICE\napp_data_2 = app_data_1[~app_data_1['AMT_GOODS_PRICE'].isnull()].copy()\n\n# Removing missing values for OBS_30_CNT_SOCIAL_CIRCLE\napp_data_3 = app_data_2[~app_data_2['OBS_30_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for DEF_30_CNT_SOCIAL_CIRCLE\napp_data_4 = app_data_3[~app_data_3['DEF_30_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for OBS_60_CNT_SOCIAL_CIRCLE\napp_data_5 = app_data_4[~app_data_4['OBS_60_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for DEF_60_CNT_SOCIAL_CIRCLE\napp_data_6 = app_data_5[~app_data_5['DEF_60_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for DAYS_LAST_PHONE_CHANGE\napp_data_7 = app_data_6[~app_data_6['DAYS_LAST_PHONE_CHANGE'].isnull()].copy()","4520aade":"# Shape of updated DataFrame\n\napp_data_7.shape","c467d4de":"# Count of each instance of OCCUPATION_TYPE\n\n100*app_data_7['OCCUPATION_TYPE'].value_counts(normalize = True)","81ef75bf":"# Imputing missing values in OCCUPATION_TYPE with 'Unknown'\n\napp_data_7['OCCUPATION_TYPE'].fillna('Unknown', inplace = True)","8654a6da":"# Imputing missing values in AMT_REQ_CREDIT_BUREAU variables with the median of each column\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_HOUR'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_HOUR'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_DAY'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_DAY'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_WEEK'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_WEEK'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_MON'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_MON'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_QRT'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_QRT'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_YEAR'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_YEAR'].median(), inplace = True)","57ba7191":"# Verifying whether all missing values are treated\n\nprint(100*app_data_7.isnull().sum()\/app_data_7.shape[0])","fb2f5505":"# Looking at the dataset again\n\napp_data_7.head()","24c97de6":"# Converting Negative Days to Positive Years\n\napp_data_7['DAYS_BIRTH_YRS'] = app_data_7['DAYS_BIRTH'].apply(lambda x : (-1.0)*x\/365)\n\napp_data_7['DAYS_EMPLOYED_YRS'] = app_data_7['DAYS_EMPLOYED'].apply(lambda x: (-1.0)*x\/365)\n\napp_data_7['DAYS_REGISTRATION_YRS'] = app_data_7['DAYS_REGISTRATION'].apply(lambda x : (-1.0)*x\/365)\n\napp_data_7['DAYS_ID_PUBLISH_YRS'] = app_data_7['DAYS_ID_PUBLISH'].apply(lambda x : (-1.0)*x\/365)","67ff678e":"# Drop negative days columns\n\napp_data_7.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH'], axis = 1, inplace = True)","67293e03":"# Convert CNT_FAM_MEMBERS to int\n\napp_data_7['CNT_FAM_MEMBERS'] = app_data_7.loc[:,'CNT_FAM_MEMBERS'].astype(int)","6fa50af0":"# Converting Social Circle variables to int\n\napp_data_7['OBS_30_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'OBS_30_CNT_SOCIAL_CIRCLE'].astype(int)\n\napp_data_7['DEF_30_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'DEF_30_CNT_SOCIAL_CIRCLE'].astype(int)\n\napp_data_7['OBS_60_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'OBS_60_CNT_SOCIAL_CIRCLE'].astype(int)\n\napp_data_7['DEF_60_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'DEF_60_CNT_SOCIAL_CIRCLE'].astype(int)","c81c2d9e":"# Unique values in each variable\n\napp_data_7.nunique().sort_values()","7855799e":"# Box plot for AMT_INCOME_TOTAL\n\nplt.figure(figsize = (18,5))\nsns.boxplot(app_data_7['AMT_INCOME_TOTAL'])\nplt.title('Box plot of AMT_INCOME_TOTAL')\nplt.show()","9e51bb73":"# Statistical summary of AMT_INCOME_TOTAL\n\napp_data_7['AMT_INCOME_TOTAL'].describe()","f52d4e69":"# Removing the outlier observation\n\napp_data_7 = app_data_7[app_data_7['AMT_INCOME_TOTAL']< app_data_7['AMT_INCOME_TOTAL'].max()]","48ce0cdb":"# Box plot for AMT_INCOME_TOTAL after removing the outlier\n\nplt.figure(figsize = (18,5))\nsns.boxplot(app_data_7['AMT_INCOME_TOTAL'])\nplt.title('Box plot of AMT_INCOME_TOTAL')\nplt.show()","7b24819e":"# Distribution of Applicant's income\n\nplt.figure(figsize = (18,6))\nplt.hist(app_data_7['AMT_INCOME_TOTAL'])\nplt.yscale('log')\nplt.xlabel(\"Applicant's Income\",fontsize=12)\nplt.title('Distribution of AMT_INCOME_TOTAL')\nplt.show()","4a25aa50":"# Different percentiles of Income variable\n\napp_data_7['AMT_INCOME_TOTAL'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","1aacd6f5":"# Creating bins for Income variable\n\napp_data_7['APPLICANT_INCOME'] = pd.cut(x=app_data_7['AMT_INCOME_TOTAL'],\n                                    bins=[0, 50000, 100000, 150000, 300000, 500000, 1000000, 2000000, 100000000],\n                                    labels=['<50k', '50k - 1lac', '1lac - 1.5lac', '1.5lac - 3lac', '3lac - 5lac', '5lac - 10lac', '10lac - 20lac', '>20lac'])","77c2ced6":"# Value Counts of APPLICANT_INCOME\n\napp_data_7['APPLICANT_INCOME'].value_counts(normalize = True, sort = False)","bfaa19cc":"#Distribution of Applicant's age\n\nplt.figure(figsize = (18,6))\nplt.hist(app_data_7['DAYS_BIRTH_YRS'])\nplt.xlabel(\"Age of Applicant\",fontsize=12)\nplt.title('Distribution of AMT_INCOME_TOTAL')\nplt.show()","f2ff868e":"# Box plot of DAYS_BIRTH_YRS\n\nplt.figure(figsize = (18,4))\nsns.boxplot(app_data_7['DAYS_BIRTH_YRS'])\nplt.title('Box plot of DAYS_BIRTH_YRS')\nplt.show()","8f716533":"#Creating bins for Applicant's age\n\napp_data_7['APPLICANT_AGE'] = pd.cut(x=app_data_7['DAYS_BIRTH_YRS'],\n                                    bins=[0, 25, 40, 60, 80],\n                                    labels=['<25 yrs', '25-40 yrs', '40-60 yrs', '>60 yrs'])","8958849c":"# Checking the composition of the APPLICANT_AGE variable\n\n100*app_data_7['APPLICANT_AGE'].value_counts(normalize = True)","d64a14d5":"# Box plot of AMT_CREDIT\n\nplt.figure(figsize = (18,5))\nsns.boxplot(app_data_7['AMT_CREDIT'])\nplt.title('Box plot of AMT_CREDIT')\nplt.show()","b6a07d37":"# Different percentiles of the AMT_CREDIT variable\n\napp_data_7['AMT_CREDIT'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","1daa337c":"# Creating bins for AMT_CREDIT\n\napp_data_7['LOAN_AMOUNT'] = pd.cut(x=app_data_7['AMT_CREDIT'],\n                                    bins=[0, 250000, 500000, 750000, 1000000, 1500000, 2000000, 5000000],\n                                    labels=['<2.5lac', '2.5lac - 5lac', '5lac - 7.5lac', '7.5lac - 10lac', '10lac - 15lac', '15lac - 20lac', '>20lac'])","eb29296a":"# Checking the composition of LOAN_AMOUNT variable\n\napp_data_7['LOAN_AMOUNT'].value_counts(normalize = True, sort = False)","23246e73":"# Counting number of rows for TARGET values of 1 and 0\n\nprint(app_data_7['TARGET'].value_counts(normalize = True))\n\nprint(app_data_7['TARGET'].value_counts(normalize = False))","da4e88c0":"# Creating DataFrame with TARGET = 1\n\napp_data_target_1 = app_data_7.loc[app_data_7['TARGET'] == 1]\napp_data_target_1","430f7cca":"# Creting DataFrame with TARGET = 0\n\napp_data_target_0 = app_data_7.loc[app_data_7['TARGET'] == 0]\napp_data_target_0","dcd6a673":"# Confirming whether the new DataFrames have correct row counts\n\nprint(app_data_7['TARGET'].value_counts(),\"\\n\",app_data_target_0.shape[0],\"\\n\",app_data_target_1.shape[0])","cbf6a11d":"# Data Types\n\napp_data_target_0.dtypes","9caaabd6":"# Plotting the CODE_GENDER variable\n\nplt.figure(figsize = (18,6))\nplt.title('Applicant Gender')\n\nplt.subplot(121)\nplt.title('Percentage of Male\/Female for Target = 0', fontsize = 10)\nplt.xlabel('Target = 0')\nplt.ylabel('Percentage')\n(100*app_data_target_0['CODE_GENDER'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(122)\nplt.title('Percentage of Male\/Female for Target = 1', fontsize = 10)\nplt.xlabel('Target = 1')\nplt.ylabel('Percentage')\n(100*app_data_target_1['CODE_GENDER'].value_counts(normalize = True)).plot.bar()","bfcb3a6c":"app_data_target_0['CODE_GENDER'].value_counts(normalize = False)","faad038e":"# Removing rows with Gender as 'XNA'\n\napp_data_target_0 = app_data_target_0[~(app_data_target_0['CODE_GENDER'] == 'XNA')]","bfb9cea6":"# Making the chart again\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Applicant Gender')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['CODE_GENDER'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['CODE_GENDER'].value_counts(normalize = True)).plot.bar()","2e2379b7":"# Actual values\nprint(app_data_target_0['CODE_GENDER'].value_counts(normalize = True))\nprint(app_data_target_1['CODE_GENDER'].value_counts(normalize = True))","0a12b10d":"# Plotting the NAME_CONTRACT_TYPE variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Loan Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_CONTRACT_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_CONTRACT_TYPE'].value_counts(normalize = True)).plot.bar()","56d8e40e":"# Actual values\nprint(app_data_target_0['NAME_CONTRACT_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_CONTRACT_TYPE'].value_counts(normalize = True))","ac35aec4":"# Plotting NAME_INCOME_TYPE variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Income Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_INCOME_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_INCOME_TYPE'].value_counts(normalize = True)).plot.bar()","6f63e34c":"# Actual values\nprint(app_data_target_0['NAME_INCOME_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_INCOME_TYPE'].value_counts(normalize = True))","c366adaf":"# Plotting NAME_FAMILY_STATUS variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Family Status')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_FAMILY_STATUS'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_FAMILY_STATUS'].value_counts(normalize = True)).plot.bar()","ccf6ce9d":"# Actual values\nprint(app_data_target_0['NAME_FAMILY_STATUS'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_FAMILY_STATUS'].value_counts(normalize = True))","0427d859":"# Plotting NAME_HOUSING_TYPE variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Housing Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_HOUSING_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_HOUSING_TYPE'].value_counts(normalize = True)).plot.bar()","1feaaf58":"# Actual values\nprint(app_data_target_0['NAME_HOUSING_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_HOUSING_TYPE'].value_counts(normalize = True))","8d97e92f":"# Plotting OCCUPATION_TYPE variable\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('Occupation Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['OCCUPATION_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['OCCUPATION_TYPE'].value_counts(normalize = True)).plot.bar()","e77a4e49":"# Actual values\nprint(app_data_target_0['OCCUPATION_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['OCCUPATION_TYPE'].value_counts(normalize = True))","47f76555":"# Plotting ORGANIZATION_TYPE variable\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('Income Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\nplt.xticks(fontsize = 7)\n(100*app_data_target_0['ORGANIZATION_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\nplt.xticks(fontsize = 7)\n(100*app_data_target_1['ORGANIZATION_TYPE'].value_counts(normalize = True)).plot.bar()","6e5bb565":"# Actual values\nprint(app_data_target_0['ORGANIZATION_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['ORGANIZATION_TYPE'].value_counts(normalize = True))","67e86c9a":"app_data_target_0.dtypes","f35ac108":"# Plotting the FLAG_OWN_CAR\n\nfig = plt.figure(figsize = (18,5))\nfig.suptitle('Does the Applicant own a Car?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['FLAG_OWN_CAR'].value_counts(normalize = True)).plot.pie()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['FLAG_OWN_CAR'].value_counts(normalize = True)).plot.pie()","3444dbb2":"# Plotting the FLAG_OWN_REALTY\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Does the Applicant own a House?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['FLAG_OWN_REALTY'].value_counts(normalize = True)).plot.pie()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['FLAG_OWN_REALTY'].value_counts(normalize = True)).plot.pie()","962f935d":"# Plotting the NAME_EDUCATION_TYPE\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('Education level of Applicant')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['NAME_EDUCATION_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_EDUCATION_TYPE'].value_counts(normalize = True)).plot.bar()","836dd68b":"# Plotting the APPLICANT_INCOME\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('What is the income of the Applicant?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['APPLICANT_INCOME'].value_counts(normalize = True, sort = False)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['APPLICANT_INCOME'].value_counts(normalize = True, sort = False)).plot.bar()","38e51187":"# Plotting the APPLICANT_AGE\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('What is the age of the Applicant?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['APPLICANT_AGE'].value_counts(normalize = True, sort = False)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['APPLICANT_AGE'].value_counts(normalize = True, sort = False)).plot.bar()","61e63cdf":"# Plotting the LOAN_AMOUNT\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('What is the loan amount?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['LOAN_AMOUNT'].value_counts(normalize = True, sort = False)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['LOAN_AMOUNT'].value_counts(normalize = True, sort = False)).plot.bar()","8c36df51":"# Statistical summary of Target = 0\n\napp_data_target_0.describe()","a4b450a0":"# Statistical summary of Target = 1\n\napp_data_target_1.describe()","0aac6ed8":"# Box plots of CNT_CHILDREN\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Number of Children')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['CNT_CHILDREN'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['CNT_CHILDREN'].plot.box()","a4a2a68a":"# Box plots of CNT_FAM_MEMBERS\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Number of Family Members')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['CNT_FAM_MEMBERS'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['CNT_FAM_MEMBERS'].plot.box()","ce41fe34":"# Box plots of REGION_RATING_CLIENT\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Rating of Applicant\\'s Region')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['REGION_RATING_CLIENT'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['REGION_RATING_CLIENT'].plot.box()","29a06ad4":"# Box plots of FLAG_OWN_CAR vs AMT_ANNUITY\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\n#plt.xlabel('Target = 0')\nsns.boxplot(x='FLAG_OWN_CAR', y='AMT_ANNUITY', data=app_data_target_0)\nplt.yscale('log')\n\nplt.subplot(ax2)\n#plt.xlabel('Target = 1')\nsns.boxplot(x='FLAG_OWN_CAR', y='AMT_ANNUITY', data=app_data_target_1)\nplt.yscale('log')","52942e96":"# Box plots of APPLICANT_INCOME vs AMT_ANNUITY\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\n#plt.xlabel('Target = 0')\nsns.boxplot(x=\"APPLICANT_INCOME\", y='AMT_ANNUITY', data=app_data_target_0)\nplt.yscale('log')\n\nplt.subplot(ax2)\n#plt.xlabel('Target = 1')\nsns.boxplot(x=\"APPLICANT_INCOME\", y='AMT_ANNUITY', data=app_data_target_1)\nplt.yscale('log')","aefc0104":"# Strip Plots of AMT_GOODS PRICE vs LOAN AMOUNT\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nsns.stripplot(x='AMT_GOODS_PRICE', y=\"LOAN_AMOUNT\", data=app_data_target_0)\n\nplt.subplot(ax2)\nsns.stripplot(x='AMT_GOODS_PRICE', y=\"LOAN_AMOUNT\", data=app_data_target_1)","f637a19f":"# Strip plot for AMT_GOODS_PRICE vs APLICANT_INCOME\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nsns.stripplot(x='AMT_GOODS_PRICE', y=\"APPLICANT_INCOME\", data=app_data_target_0)\n\nplt.subplot(ax2)\nsns.stripplot(x=\"AMT_GOODS_PRICE\", y=\"APPLICANT_INCOME\", data=app_data_target_1)\n","5e38065e":"# Box plots of DAYS_LAST_PHONE_CHANGE\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Number of Defaults in Applicant\\'s social surroundings')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['DAYS_LAST_PHONE_CHANGE'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['DAYS_LAST_PHONE_CHANGE'].plot.box()","1878f51f":"# Checking dtypes again\n\napp_data_target_0.dtypes","ce9afafa":"sns.pairplot(data = app_data_target_0, vars = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_YEAR'])\nplt.show()","4deb67df":"sns.pairplot(data = app_data_target_0, vars = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_YEAR'])\nplt.show()","5c866658":"sns.pairplot(data = app_data_target_1, vars = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_YEAR'])\nplt.show()","7d8340f4":"#Creating the Correlation Matrix for Target = 0\n\ncurr_0 = app_data_target_0[['AMT_CREDIT', 'AMT_ANNUITY', 'AMT_INCOME_TOTAL', 'CNT_CHILDREN', 'DAYS_EMPLOYED_YRS', 'DAYS_BIRTH_YRS']]\n\ncor_0 = curr_0.corr()\n\nsns.heatmap(cor_0, cmap = \"YlGnBu\", annot = True)\n\nplt.show()","618a6ac1":"#Creating the Correlation Matrix for Target = 0\n\ncurr_1 = app_data_target_1[['AMT_CREDIT', 'AMT_ANNUITY', 'AMT_INCOME_TOTAL', 'CNT_CHILDREN', 'DAYS_EMPLOYED_YRS', 'DAYS_BIRTH_YRS']]\n\ncor_1 = curr_1.corr()\n\nsns.heatmap(cor_1, cmap = \"YlGnBu\", annot = True)\n\nplt.show()","4569f30e":"# Get percentage of missing data for each column and save it in another DataFrame\n\nprev_app_data_missing = pd.DataFrame(100*prev_application.isnull().sum()\/prev_application.shape[0]).reset_index()","9ff9a316":"# Creating chart for missing values \n\nplt.figure(figsize = (18,5))\nplt.plot(prev_app_data_missing['index'], prev_app_data_missing[0])\nplt.xticks(rotation = 90, fontsize = 7)\nplt.title('Percentage of Missing Values in each column of Previous Application Data', fontsize = 14)\nplt.xlabel('Columns', fontsize = 10)\nplt.ylabel('Percentage Missing', fontsize = 10)\nplt.figure()\nplt.show()","b1e0585d":"# Displaying the Missing percentage values as a DataFrame\n\nprev_app_data_missing","b57566c7":"# Getting the list of columns with > 45% data as missing\n\nmiss_cols_prev_app_data = list(prev_app_data_missing.loc[prev_app_data_missing[0] > 45, 'index'])\nprint(len(miss_cols_prev_app_data))","494dd410":"# Dropping the columns from Application Data\n\nprev_application.drop(miss_cols_prev_app_data, axis = 1, inplace = True)","87dcffd7":"# Print percentage missing values of each column\n\nprint(100*prev_application.isnull().sum()\/prev_application.shape[0])","4ac84646":"# Removing missing values for PRODUCT_COMBINATION\n\nprev_app_data_1 = prev_application[~prev_application['PRODUCT_COMBINATION'].isnull()].copy()","6ec7b6f1":"prev_app_data_1.shape[0]","64bb9000":"prev_app_data_1['DAYS_LAST_DUE'].median()","de224ef1":"# Imputing missing values with median\n\nprev_app_data_1['AMT_ANNUITY'].fillna(prev_app_data_1['AMT_ANNUITY'].median(), inplace = True)\n\nprev_app_data_1['AMT_GOODS_PRICE'].fillna(prev_app_data_1['AMT_GOODS_PRICE'].median(), inplace = True)\n\nprev_app_data_1['CNT_PAYMENT'].fillna(prev_app_data_1['CNT_PAYMENT'].median(), inplace = True)\n\nprev_app_data_1['DAYS_FIRST_DRAWING'].fillna(prev_app_data_1['DAYS_FIRST_DRAWING'].median(), inplace = True)\n\nprev_app_data_1['DAYS_FIRST_DUE'].fillna(prev_app_data_1['DAYS_FIRST_DUE'].median(), inplace = True)\n\nprev_app_data_1['DAYS_LAST_DUE_1ST_VERSION'].fillna(prev_app_data_1['DAYS_LAST_DUE_1ST_VERSION'].median(), inplace = True)\n\nprev_app_data_1['DAYS_LAST_DUE'].fillna(prev_app_data_1['DAYS_LAST_DUE'].median(), inplace = True)\n\nprev_app_data_1['DAYS_TERMINATION'].fillna(prev_app_data_1['DAYS_TERMINATION'].median(), inplace = True)\n\nprev_app_data_1['NFLAG_INSURED_ON_APPROVAL'].fillna(prev_app_data_1['NFLAG_INSURED_ON_APPROVAL'].median(), inplace = True)","042270a6":"# Print percentage missing values of each column\n\nprint(100*prev_app_data_1.isnull().sum()\/prev_app_data_1.shape[0])","2c84a26c":"# Changing the DAYS_FIRST_DUE variable to positive years\n\nprev_app_data_1['DAYS_FIRST_DUE'] = prev_app_data_1['DAYS_FIRST_DUE'].apply(lambda x : (-1.0)*x\/365)","aa518ac3":"# Checking DataTypes of Previous Application Data\n\nprev_app_data_1.dtypes","66d9f9f9":"# Removing irrelevant columns\n\nprev_app_data_1.drop(['WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'FLAG_LAST_APPL_PER_CONTRACT', 'NFLAG_LAST_APPL_IN_DAY'], axis = 1, inplace = True)","ee8eb0d0":"# Unique values in each variable\n\nprev_app_data_1.nunique().sort_values()","1b2c7c31":"# Box plot for AMT_ANNUITY\n\nplt.figure(figsize = (18, 4))\nsns.boxplot(prev_app_data_1['AMT_ANNUITY'])\nplt.show()","0ee408d3":"# Different percentiles of the AMT_ANNUITY variable\n\nprev_app_data_1['AMT_ANNUITY'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","b45c1ab4":"# Creating bins for AMT_ANNUITY\n\nprev_app_data_1['LOAN_INSTALMENT'] = pd.cut(x=prev_app_data_1['AMT_ANNUITY'],\n                                    bins=[0, 5000, 10000, 20000, 30000, 40000, 50000, 500000],\n                                    labels=['<5k', '5k - 10k', '10k - 20k', '20k - 30k', '30k - 40k', '40k - 50k', '>50k'])","f989a03d":"prev_app_data_1.columns","bdd303e5":"sns.stripplot(x='DAYS_TERMINATION', y=\"NAME_CONTRACT_STATUS\", data=prev_app_data_1)\nplt.plot()","878c8783":"plt.suptitle(\"Amount of Loan asked Vs Contract Status\")\nsns.stripplot(x='AMT_APPLICATION', y=\"NAME_CONTRACT_STATUS\", data=prev_app_data_1)\nplt.plot()","0495ad8c":"plt.suptitle(\"when was the decision about previous application made Vs Contract Status\")\nsns.stripplot(x= \"DAYS_DECISION\", y=\"NAME_CONTRACT_STATUS\", data=prev_app_data_1)\nplt.plot()","8c7725d3":"prev_app_data_1.NAME_CONTRACT_STATUS.value_counts(normalize=True).plot.barh()\nplt.show()","2c2bf96b":"prev_app_data_1.NAME_PORTFOLIO.value_counts(normalize=True).plot.barh()\nplt.show()","7df7fb7b":"Since we have a large number of variables, let's first visualize the missing values in a chart.","af904ea0":"The percentage of missing values for columns *AMT_ANNUITY*, *AMT_GOODS_PRICE*, *OBS_30_CNT_SOCIAL_CIRCLE*, *DEF_30_CNT_SOCIAL_CIRCLE*, *OBS_60_CNT_SOCIAL_CIRCLE*, *DEF_60_CNT_SOCIAL_CIRCLE*, *DAYS_LAST_PHONE_CHANGE* is very less. So, we can **remove these missing rows**.","335e7724":"Now, there are no columns that are of date type in this DataFrame. We only have the age\/time since documents were changed which are recorded as float. We should not convert these to DateTime type.","08f18a24":"So, both the files are encoded as 'ascii'. Let's import the files now.","ffc612f6":"We can see that the columns *DAYS_BIRTH*, *DAYS_EMPLOYED*, *DAYS_REGISTRATION*, *DAYS_PUBLISH* are negative. These should be in positive years or months. Let's **convert these to years**.","2cf2f2e6":"## Univariate Analysis","db515797":"### Categorical Ordered Univariate Analysis","f7c7c401":"The column *NAME_TYPE_SUITE* which indicates who was accompanying the client while applying for the loan has no relation with whether the client will default or not, we can remove this column too. <br>\nSimilarly, the columns *WEEKDAY_APPR_PROCESS_START*, *HOUR_APPR_PROCESS_START*, *REG_REGION_NOT_LIVE_REGION*, *REG_REGION_NOT_WORK_REGION*, *LIVE_REGION_NOT_WORK_REGION*, *REG_CITY_NOT_LIVE_CITY*, *REG_CITY_NOT_WORK_CITY*, *LIVE_CITY_NOT_WORK_CITY* can also be removed.","23d95120":"Let's first identify the Ordered Categorical variables in our dataset. ","c106b375":"## Read the Data files","8b70605c":"Now, let's look at some variables where the DataType is not stored correctly. <br>\nLet's look at CNT_FAM_MEMBERS which is stored as float. It should be stored as integer.","4ba057bc":"## EDA on Previous Application Data","a12d9c23":"Let us create a DataFrame of the columns that have more than 45% values as missing.","21d085ea":"Laborers, Sales staff, Drivers are more likely to default.","973e02dd":"Now, we can **remove the Document flag variables**.","cb35c5dd":"The Data Types of all remaining variables are correct.","45d7d721":"Let's look at the relation between Income and Loan amount.","c08f93f2":"To know more, we can look at the percentile values of the Income variable.","745b4cb7":"Most of the times, you will not need to check the encoding of the data files. But, it is a good practice to check it to avoid any errors due to reading the files with the wrong encoding.","7b261ed7":"Let's repeat all the processes done with the Application Data file.","24a68e7f":"### Univariate Analysis","36bbebfb":"### Categorical Unordered Univariate Analysis","33ee1f7a":"We can remove these 49 columns.","c42717bc":"## Treating missing values and removing irrelevant variables","779bd0da":"### Numeric - Numeric Analysis","5b19ad0f":"Let's first see which numerical columns we have.","25fd9023":"All missing values have been imputed.","e2c5b683":"## Class Imbalance","b049ba0a":"So, imbalance for TARGET = 1 is 91.9114% and for TARGET = 0 is 8.0886%.","93884ea3":"We only have 42 columns now.","e0b01da1":"We can see that our median is just around 1.5 lakh. So, our bins have to be more dense below 1.5 lakh and sparse beyond that. Let's create these bins.","c3ae2101":"Let's look at the same variables for Target = 1.","0cf7f2d6":"Now, let's look at *AMT_REQ_CREDIT_BUREAU* columns and how we can impute their missing values. <br>\n\nSince these columns are numeric and represent the number of queries in the Credit Bureau about the client in the specified time period, we can **use the median of each column to impute the values**.","e23919bb":"## Handling Outliers and Binning","7787d2de":"So, there are no outliers in the DAYS_BIRTH_YRS variable. But, we can still bin this variable as people of an age group tend to behave in a similar manner.","4d38d77b":"People who do not own a house are more likely to default.","d61ab665":"Let's see the composition of our new variable APPLICANT_INCOME.","daa3675f":"We can see that many of the variables have a high percentage of missing values.","90a1580a":"We start our analysis by checking the imbalance in the data. Imbalance is the ratio of one value of Target variable vs the other.","bc5a4d80":"## Dividing dataset into 1 and 0","f741823f":"We can see that one value is way higher than all other values. We can delete this value.","34835868":"Now, we need to drop the older Days columns.","1dbe6b88":"Now, we need to identify the outliers in our continuous variables. <br>\nFor this, we first need to identify the continuous variables in our dataset. So, let's look at the number of unique values in each variable.","e0800ad3":"Married people are less likely to default while Single and Civil married people are more likely to default.","c2042aae":"Here, we can see that Males are more likely to default on a loan.","183fe2c9":"This represents 99.97% of the original data.","c168be89":"Let's see the statistical summary of our DataFrames. ","7e114484":".describe gives us the statistical summary of the numerical variables only. However, if we want to also include the categorical variables, we can set the parameter include = 'all'.","627a740c":"Although Laborers make up a large percent of our data, it is not so high that we replace our missing values with it. So, let us **impute the missing values in this column with 'Unknown'**. In the machine learning model, this column, combined with *'NAME_INCOME_TYPE'* could indicate towards a person's occupation.","739ce8d5":"People with a higher level of education are less likely to default.","151dc885":"Now, we can bin these values. For that, we first need to look at the distribution of the variable.","742bfd7a":"Now, we also do not have any context on what the variables *EXT_SOURCE_2* and *EXT_SOURCE_3* mean and how they relate to whether the client is more probable to default or not, we can remove these columns too.","433403fe":"So, Revolving loans are less likely to default.","19300211":"## Bivariate Analysis","31f92ed3":"People who do not own a car are more likely to default.","1a460d87":"Now, we will divide the dataset into two parts - One with TARGET = 0 and one with TARGET = 1.","bbb0bd84":"The variables FLAG_OWN_CAR, FLAG_OWN_REALTY, NAME_EDUCATION_TYPE, APPLICANT_INCOME, APPLICANT_AGE, LOAN_AMOUNT are all Ordered Categorical variables. Let's look at these one by one.","992b819e":"People living with parents or in a rented apartment are more likely to default.","ef008671":"We can confirm that the two new dataframes have correct respective TARGET value and right row count.","3fd5e046":"Application Data contains the information about the loan and applicant at the time of the application of the loan. <br>\nPrevious Application Data contains the Application Data for the client's previous loan application. It has one row per previous application.","7b08a906":"## Cleaning the Data types","c60a2128":"So, our unordered categorical variables are NAME_CONTRACT_TYPE, CODE_GENDER, NAME_INCOME_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, OCCUPATION_TYPE, ORGANIZATION_TYPE.","5a3338b9":"Now, the columns of document flags are not individually important as we have no information about which document is being referred to. But, they can be a good indicator at an **aggregate** level. So, we can create another column *NUM_DOCS_ADDED* as the number of documents submitted.","a825777a":"So, the numerical columns are AMT_INCOME_TOTAL, AMT_CREDIT, AMT_ANNUITY, AMT_GOODS_PRICE, REGION_POPULATION_RELATIVE, AMT_REQ_CREDIT_BUREAU_WEEK, AMT_REQ_CREDIT_BUREAU_MON, AMT_REQ_CREDIT_BUREAU_YEAR, DAYS_BIRTH_YRS, DAYS_EMPLOYED_YRS, DAYS_REGISTRATION_YRS.","977e1982":"Now, let's plot the box plots of the variables CNT_CHILDREN, CNT_FAM_MEMBERS, REGION_RATING_CLIENT, DEF_30_CNT_SOCIAL_CIRCLE, DEF_60_CNT_SOCIAL_CIRCLE, NUM_DOCS_ADDED, DAYS_LAST_PHONE_CHANGE.","3d2a185d":"We can see here that the variables REGION_POPULATION_RELATIVE, AMT_GOODS_PRICE, AMT_INCOME_TOTAL, DAYS_LAST_PHONE_CHANGE, AMT_CREDIT, DAYS_ID_PUBLISH_YRS, DAYS_EMPLOYED_YRS, AMT_ANNUITY, DAYS_REGISTRATION_YRS and DAYS_BIRTH_YRS are continuous variables since their number of unique values is large. ","6dcd65d4":"All missing values of the application dataset are cealned.","3416c59d":"Let's see the correlation between AMT_CREDIT, AMT_ANNUITY, AMT_INCOME_TOTAL, CNT_CHILDREN, DAYS_EMPLOYED_YRS, DAYS_BIRTH_YRS","10e2c53c":"## Data Summary","c5efc2e4":"So, we have 306199 rows in the data now, ehich is around **99.57% of the original data**. So, we are good to go with this data.","b50e470d":"Let's try to find outliers in variables AMT_INCOME_TOTAL, AMT_CREDIT, DAYS_BIRTH_YRS.","f746cd34":"Let's look at these one by one for both Target = 0 an Target = 1","f5c9cae5":"*OCCUPATION_TYPE* column is a categorical variable, let's look at the composition of the variable.","6b5d1c15":"### Numerical variables","640ce08f":"Now, let's see how our DAYS_BIRTH_YRS, which represents the age of the applicant, is distributed.","bf4d2402":"Let's start by first identifying the unnecessary columns based on our understanding from the columns_description file.<br>\n\nThe columns *FLAG_WORK_PHONE* and *FLAG_PHONE* both contain the information on whether the client provided home phone or not. Since, work phone information is captured in the *FLAG_EMP_PHONE* variable, we can remove the *FLAG_WORK_PHONE* variable."}}