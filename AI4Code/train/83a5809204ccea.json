{"cell_type":{"f2d9a6ed":"code","59a14ebe":"code","fc5f38c2":"code","72f47add":"code","ad4e6366":"code","61283829":"code","e4cb6405":"code","931a689d":"code","a2490303":"code","aad0ab29":"code","168b907d":"code","9ccae4e5":"code","e10281a8":"code","8aae7db6":"code","03d43d3b":"code","0aa5e20d":"code","f297eb65":"code","2b87d646":"code","a3d1b7bb":"code","7a3fdc7c":"code","93776352":"code","5e97b703":"code","2715f8fb":"code","5cc799b3":"code","ddae841c":"code","8f31f04d":"code","c959f756":"code","86ac37db":"code","0a0e5d37":"markdown"},"source":{"f2d9a6ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","59a14ebe":"DIR = \"..\/input\/medium-articles-dataset\/medium_data.csv\"","fc5f38c2":"import numpy\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n\nimport nltk \n#nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport cv2\n\nIMAGE_SIZE = (150, 150)\n\nfrom skimage import io\n\n\n","72f47add":"\n\n\nimport re\ndf = pd.read_csv(DIR)","ad4e6366":"df = df.drop(['url'], axis=1)\n\n","61283829":"df = df.dropna(subset = ['image'])","e4cb6405":"df = df[:500]","931a689d":"def image(x):\n    try:\n        if type(x) != str:\n            return None\n        \n        img_path = \"..\/input\/medium-articles-dataset\/images\/\" + x\n\n        image = io.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, IMAGE_SIZE) \n        if type(image) == float:\n            return None\n        return image\n    except:\n#         img_path = \"..\/input\/medium-articles-dataset\/images\/1\"\n\n#         image = io.imread(img_path)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#         image = cv2.resize(image, IMAGE_SIZE) \n        return None\n        \n    \n    \ndf.image = df.image.apply(lambda x: image(x))\n","a2490303":"# df.image = df.image.replace(to_replace='None', value=np.nan).dropna()\n\n\ndf.image = df.image.dropna()\n","aad0ab29":"text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n\ndef clean(text):\n    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n    return text\ndf.title = df.title.apply(lambda x: clean(x))\ndf.subtitle = df.subtitle.apply(lambda x: clean(x))\n\n# df.responses  = df.responses.apply(lambda x: int(x))\n","168b907d":"def cleaner(num):\n    if (num > 500):\n        return 500\n    else:\n        return num\ndf.claps = df.claps.apply(lambda x: cleaner(x))","9ccae4e5":"TRAIN_SIZE = 0.8\nMAX_NB_WORDS = 100000\nMAX_SEQUENCE_LENGTH = 20\n\ntrain_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE,\n                                         random_state=7) # Splits Dataset into Training and Testing set\nprint(\"Train Data size:\", len(train_data))\nprint(\"Test Data size\", len(test_data))","e10281a8":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_data.title)\n\nword_index = tokenizer.word_index\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Vocabulary Size :\", vocab_size)\n\nfrom keras.preprocessing.sequence import pad_sequences\n\nx_train = pad_sequences(tokenizer.texts_to_sequences(train_data.title),\n                        maxlen = MAX_SEQUENCE_LENGTH)\nx_test = pad_sequences(tokenizer.texts_to_sequences(test_data.title),\n                       maxlen = MAX_SEQUENCE_LENGTH)\n\nsubtitle_train = pad_sequences(tokenizer.texts_to_sequences(train_data.subtitle),\n                        maxlen = MAX_SEQUENCE_LENGTH)\nsubtitle_test = pad_sequences(tokenizer.texts_to_sequences(test_data.subtitle),\n                       maxlen = MAX_SEQUENCE_LENGTH)\n\nresponses_train = train_data.responses\nresponses_test = test_data.responses\n\n\nreading_time_train = train_data.reading_time\nreading_time_test = test_data.reading_time\n\n\ny_train = train_data.claps\ny_test = test_data.claps\n\nprint(\"Training X Shape:\",x_train.shape)\nprint(\"Testing X Shape:\",x_test.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_test shape:\", y_test.shape)","8aae7db6":"img_train = train_data.image\nimg_test = test_data.image\n\n\n","03d43d3b":"print(img_train.shape)\n\nfor i in img_train:\n    print(i.shape)","0aa5e20d":"print(img_test.shape)\n\nfor i in img_test:\n    print(i.shape)","f297eb65":"GLOVE_DIR = '..\/input\/glove6b300dtxt\/glove.6B.300d.txt'\n\n\nembeddings_index = {}\nf = open(GLOVE_DIR)\nprint('Loading GloVe from:', GLOVE_DIR,'...', end='')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\nf.close()\nprint(\"Done.\\n Proceeding with Embedding Matrix...\", end=\"\")\n\nembedding_matrix = np.random.random((len(word_index) + 1, 300))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\nprint(\" Completed!\")","2b87d646":"# img_train = np.array(img_train, dtype = 'float32')\n# img_test = np.array(img_test, dtype = 'float32')\n# img_train=np.asarray(img_train).astype(np.float32)\n# img_test=np.asarray(img_test).astype(np.float32)\n\nimg_train=tf.convert_to_tensor(list(img_train), dtype = tf.float32)\nimg_test=tf.convert_to_tensor(list(img_test), dtype = tf.float32)\n","a3d1b7bb":"#1\n# from tensorflow.keras.layers import *\n\n\n# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n# embedding_layer = Embedding(len(word_index) + 1,\n#                            300,\n#                            weights = [embedding_matrix],\n#                            input_length = MAX_SEQUENCE_LENGTH,\n#                            trainable=False,# prevent re-training the glove vector\n#                            name = 'embeddings')\n# embedded_sequences = embedding_layer(sequence_input)\n# x = LSTM(60, return_sequences=True,name='lstm_layer')(embedded_sequences)\n# x = GlobalMaxPool1D()(x)\n# x = Dropout(0.1)(x)\n# x = Dense(50, activation=\"relu\")(x)\n# x = Dropout(0.1)(x)\n# preds = Dense(1)(x)\n\n\n# ####\n\n# from tensorflow.keras.models import Model\n\n# model = Model(sequence_input, preds)\n# model.compile(loss='mean_squared_error', optimizer='adam',\n#              metrics = ['mae'])","7a3fdc7c":"# model = keras.Sequential([\n#       norm,\n#       layers.Dense(64, activation='relu'),\n#       layers.Dense(64, activation='relu'),\n#       layers.Dense(1)\n#   ])\n\n#   model.compile(loss='mean_absolute_error',\n#                 optimizer=tf.keras.optimizers.Adam(0.001))","93776352":"#1\nfrom tensorflow.keras.layers import *\n\n# Title\nsequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n\nembedding_layer = Embedding(len(word_index) + 1,\n                           300,\n                           weights = [embedding_matrix],\n                           input_length = MAX_SEQUENCE_LENGTH,\n                           trainable=False,# prevent re-training the glove vector\n                           name = 'embeddings')\nembedded_sequences = embedding_layer(sequence_input)\nx = LSTM(60, return_sequences=True,name='lstm_layer')(embedded_sequences)\n# x = Conv1D(64, 5, activation='relu')(x)\nx = GlobalMaxPool1D()(x)\n\nx = Dropout(0.1)(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\npreds = Dense(10)(x)\n\n#Subtitle\nsequence_input2= Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n\nembedded_sequences2 = embedding_layer(sequence_input2)\nx2 = LSTM(60, return_sequences=True,name='lstm_layer2')(embedded_sequences2)\n# x = Conv1D(64, 5, activation='relu')(x)\nx2 = GlobalMaxPool1D()(x2)\nx2 = Dropout(0.1)(x2)\nx2 = Dense(50, activation=\"relu\")(x2)\nx2 = Dropout(0.1)(x2)\npreds2 = Dense(10)(x2)\n\n#reading_time\ninput_y = Input(shape = (1,), dtype='int32')\ny = Dense(2, activation=\"relu\")(input_y)\n\n#Image\ninput_image = Input(shape = (150,150,3)) # , dtype='object'\nz = Conv2D(32, (3, 3), activation = 'relu')(input_image)\nz = MaxPooling2D(2,2)(z)\nz = Conv2D(32, (3, 3), activation = 'relu')(z)\nz = MaxPooling2D(2,2)(z)\nz = Flatten()(z)\nz = Dense(128, activation=\"relu\")(z)\n\n\n\nconcat = Concatenate()([preds, preds2, y, z])\n\noutput = Dense(1)(concat)\n\n####\n\nfrom tensorflow.keras.models import Model\n\nmodel = Model(inputs = [sequence_input, sequence_input2, input_y, input_image], outputs = [output])\n\nmodel.compile(loss='mean_absolute_error', optimizer='adam',\n             metrics = ['mae'])\n\n######\n\nprint('Training progress:')\n\nhistory = model.fit([x_train,subtitle_train, reading_time_train, img_train], y_train, epochs = 15, batch_size=64, validation_data=([x_test,subtitle_test, reading_time_test, img_test], y_test))\n\nmae = history.history['mae']\nval_mae = history.history['val_mae']\nepochs = range(1, len(mae)+1)\n\nplt.plot(epochs, mae, label='Training mae')\nplt.plot(epochs, val_mae, label='Validation MAE')\nplt.title('Training and validation MAE')\nplt.ylabel('MAE\/val_MAE')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show();","5e97b703":"print (type(sequence_input))","2715f8fb":"# #2 \n# from tensorflow.keras.layers import *\n\n\n# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n\n# embedding_layer = Embedding(len(word_index) + 1,\n#                            300,\n#                            weights = [embedding_matrix],\n#                            input_length = MAX_SEQUENCE_LENGTH,\n#                            trainable=False,# prevent re-training the glove vector\n#                            name = 'embeddings')\n# embedded_sequences = embedding_layer(sequence_input)\n# x = LSTM(60, return_sequences=True,name='lstm_layer')(embedded_sequences)\n# x = Dense(64, activation=\"relu\")(x)\n# x = Dense(64, activation=\"relu\")(x)\n# x = Dense(64, activation=\"relu\")(x)\n\n# preds = Dense(10)(x)\n\n\n\n# ####\n\n# from tensorflow.keras.models import Model\n\n# model = Model(sequence_input, preds)\n# model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.001),\n#              metrics = ['mae'])\n\n\n\n# ######\n\n# print('Training progress:')\n# history = model.fit(x_train, y_train, epochs = 50, batch_size=64, validation_data=(x_test, y_test))\n\n# mae = history.history['mae']\n# val_mae = history.history['val_mae']\n# epochs = range(1, len(mae)+1)\n\n# plt.plot(epochs, mae, label='Training mae')\n# plt.plot(epochs, val_mae, label='Validation MAE')\n# plt.title('Training and validation MAE')\n# plt.ylabel('MAE\/val_MAE')\n# plt.xlabel('Epochs')\n# plt.legend()\n# plt.show();","5cc799b3":"tf.keras.utils.plot_model(model)\n","ddae841c":"test_predictions = model.predict([x_test,subtitle_test, reading_time_test, img_test]).flatten()\n\n# a = plt.axes(aspect='equal')\nplt.scatter(y_test, test_predictions)\nplt.xlabel('True Values [Claps]')\nplt.ylabel('Predictions [Claps]')","8f31f04d":"#1\nmae = history.history['mae']\nval_mae = history.history['val_mae']\nepochs = range(1, len(mae)+1)\n\nplt.plot(epochs, mae, label='Training mae')\nplt.plot(epochs, val_mae, label='Validation MAE')\nplt.title('Training and validation MAE')\nplt.ylabel('MAE\/val_MAE')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show();","c959f756":"# print(x_test.shape)\n# print(y_test.shape)\n# test_predictions = model.predict(x_test)\n# print(test_predictions.flatten().shape)\n# print(test_predictions.shape)\n","86ac37db":"User_title = input(\"Your Title is: \")\nUser_subtitle = input(\"Your Subtitle is: \")\n\n\n#User_title_pred = []\n#User_subtitle_pred = []\n\ntext_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\nUser_title = re.sub(text_cleaning_re, ' ', str(User_title).lower()).strip()\nUser_subtitle = re.sub(text_cleaning_re, ' ', str(User_subtitle).lower()).strip()\n\nUser_title_tokenised = pad_sequences(tokenizer.texts_to_sequences(User_title),\n                        maxlen = MAX_SEQUENCE_LENGTH)\nUser_subtitle_tokenised = pad_sequences(tokenizer.texts_to_sequences(User_subtitle),\n                        maxlen = MAX_SEQUENCE_LENGTH)\n\nUser_title_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\nUser_subtitle_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n\n#User_title_pred.append(User_title_tokenised)\n#User_subtitle_pred.append(User_subtitle_tokenised)\n\n\nUser_image_path = \"..\/input\/medium-articles-dataset\/images\/1.png\"\nUser_image = io.imread(User_image_path)\nUser_image = cv2.cvtColor(User_image, cv2.COLOR_BGR2RGB)\nUser_image = cv2.resize(User_image, IMAGE_SIZE) \nUser_image =tf.convert_to_tensor(list(User_image), dtype = tf.float32)\nprint(User_image.shape)\n\nReading_time = 10\n\nUser_title_input = Input(shape=(MAX_SEQUENCE_LENGTH,))\nUser_subtitle_input = Input(shape=(MAX_SEQUENCE_LENGTH,))\nReading_time_input = Input(shape = (1,))\nUser_image_input = Input(shape = (150,150,3)) # , dtype='object'\n\n\ntest_predictions_user = model.predict([User_title_input,User_subtitle_input, Reading_time_input, User_image_input])\n\nprint (test_predictions_user)","0a0e5d37":"# input input\n\n"}}