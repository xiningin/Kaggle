{"cell_type":{"56ba6cc4":"code","d82e19b4":"code","c21e0524":"code","94b259f5":"code","ce6ac2eb":"code","c312c729":"code","e590350a":"code","e26a6a52":"code","7d53ac52":"code","77469a01":"code","06547d07":"code","ffc0b643":"code","6551765f":"code","94b5c760":"markdown","20d7fac8":"markdown","bcf769ef":"markdown","cd72b81b":"markdown","7a1ac43a":"markdown","123f7506":"markdown","7ced27b3":"markdown","7cd0e79e":"markdown","62bafa20":"markdown","d1b228b6":"markdown"},"source":{"56ba6cc4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","d82e19b4":"df = pd.read_csv(\"..\/input\/china_gdp.csv\")\ndf.head(10)","c21e0524":"plt.figure(figsize=(8,5))\nx_data, y_data = (df[\"Year\"].values, df[\"Value\"].values)\nplt.plot(x_data, y_data, 'ro')\nplt.ylabel('GDP')\nplt.xlabel('Year')\nplt.show()","94b259f5":"X = np.arange(-5.0, 5.0, 0.1)\nY = 1.0 \/ (1.0 + np.exp(-X))\n\nplt.plot(X,Y) \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","ce6ac2eb":"def sigmoid(x, Beta_1, Beta_2):\n     y = 1 \/ (1 + np.exp(-Beta_1*(x-Beta_2)))\n     return y","c312c729":"beta_1 = 0.10\nbeta_2 = 1990.0\n\n#logistic function\nY_pred = sigmoid(x_data, beta_1 , beta_2)\n\n#plot initial prediction against datapoints\nplt.plot(x_data, Y_pred*15000000000000.)\nplt.plot(x_data, y_data, 'ro')","e590350a":"# Lets normalize our data\nxdata =x_data\/max(x_data)\nydata =y_data\/max(y_data)","e26a6a52":"from scipy.optimize import curve_fit\npopt, pcov = curve_fit(sigmoid, xdata, ydata)\n#print the final parameters\nprint(\" beta_1 = %f, beta_2 = %f\" % (popt[0], popt[1]))","7d53ac52":"x = np.linspace(1960, 2015, 55)\nx = x\/max(x)\nplt.figure(figsize=(12,6))\ny = sigmoid(x, *popt)\nplt.plot(xdata, ydata, 'ro', label='data')\nplt.plot(x,y, linewidth=3.0, label='fit')\nplt.legend(loc='best')\nplt.ylabel('GDP')\nplt.xlabel('Year')\nplt.show()","77469a01":"# split data into train\/test\nmsk = np.random.rand(len(df)) < 0.8\ntrain_x = xdata[msk]\ntest_x = xdata[~msk]\ntrain_y = ydata[msk]\ntest_y = ydata[~msk]","06547d07":"# build the model using train set\npopt, pcov = curve_fit(sigmoid, train_x, train_y)","ffc0b643":"# predict using test set\ny_hat = sigmoid(test_x, *popt)","6551765f":"print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat - test_y) ** 2))\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(y_hat , test_y) )","94b5c760":"**Loading the Dataset**","20d7fac8":"**Importing required libraries**","bcf769ef":"Now we plot our resulting regresssion model.","cd72b81b":"Our task here is to find the best parameters for our model. Lets first normalize our x and y:","7a1ac43a":"**Building The Model**\n\n Let's build our regression model and initialize its parameters","123f7506":"**Plotting the Dataset**","7ced27b3":"Lets look at a sample sigmoid line that might fit with the data:","7cd0e79e":"**Choosing a model**\n\nFrom an initial look at the plot, we determine that the logistic function could be a good approximation, since it has the property of starting with a slow growth, increasing growth in the middle, and then decreasing again at the end; as illustrated below:","62bafa20":"**What is the accuracy of our model?**","d1b228b6":"**How we find the best parameters for our fit line?**\n\nWe can use curve_fit which uses non-linear least squares to fit our sigmoid function, to data"}}