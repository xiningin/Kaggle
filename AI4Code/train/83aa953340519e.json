{"cell_type":{"6529410d":"code","20628d6f":"code","64c5fa2e":"code","cc9d339c":"code","fba1c85d":"code","353d2b3f":"code","2b8f5433":"markdown","c32cec57":"markdown","9c7742a1":"markdown","1b29a029":"markdown","ebb42833":"markdown"},"source":{"6529410d":"import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Sequential\uff1aA model constructed sequentially\nfrom keras.models import Sequential\n# Dense\uff1aFully Connected Layer\nfrom keras.layers import Dense","20628d6f":"# Use Numpy to generate 100 random numbers\nx_data = np.random.rand(100)\nnoise = np.random.normal(0,0.01,x_data.shape)\ny_data = x_data*0.1 + 0.2 + noise\n\n# plotting\nplt.scatter(x_data, y_data)\nplt.show()","64c5fa2e":"model = Sequential()\nmodel.add(Dense(units=1,input_dim=1))\nmodel.compile(optimizer='sgd', loss='mse')\n\n#train model by batch,3001 times\nfor step in range(3001):\n    cost = model.train_on_batch(x_data, y_data)\n    if step % 500 == 0:\n        print('cost:', cost)\n        \n# print weight and basis\nW,b = model.layers[0].get_weights()\nprint('W:',W,'b:',b)\n\n# input x_data and get predicitons(y_pred)\ny_pred = model.predict(x_data)\n\n# plotting\nplt.scatter(x_data, y_data)\nplt.plot(x_data, y_pred, 'r-', lw=3)\nplt.show()","cc9d339c":"# Use Numpy to generate 100 random numbers\nx_data = np.random.rand(100)\ny_data = x_data*0.1 + 0.2\n\n# plotting\nplt.scatter(x_data, y_data)\nplt.show()","fba1c85d":"model = Sequential()\nmodel.add(Dense(units=1,input_dim=1))\nmodel.compile(optimizer='sgd', loss='mse')\n\n#train model by batch,3001 times\nfor step in range(3001):\n    cost = model.train_on_batch(x_data, y_data)\n    if step % 500 == 0:\n        print('cost:', cost)\n        \n# print weight and basis\nW,b = model.layers[0].get_weights()\nprint('W:',W,'b:',b)\n\n# input x_data and get predicitons(y_pred)\ny_pred = model.predict(x_data)\n\n# plotting\nplt.scatter(x_data, y_data)\nplt.plot(x_data, y_pred, 'r-', lw=3)\nplt.show()","353d2b3f":"model = Sequential()\nmodel.add(Dense(units=1,input_dim=1))\nmodel.compile(optimizer='sgd', loss='mse')\n\n#train model by batch,3001 times\nfor step in range(10001):\n    cost = model.train_on_batch(x_data, y_data)\n    if step % 500 == 0:\n        print('cost:', cost)\n        \n# print weight and basis\nW,b = model.layers[0].get_weights()\nprint('W:',W,'b:',b)\n\n# input x_data and get predicitons(y_pred)\ny_pred = model.predict(x_data)\n\n# plotting\nplt.scatter(x_data, y_data)\nplt.plot(x_data, y_pred, 'r-', lw=3)\nplt.show()","2b8f5433":"With the increase of the number of iterations, the fitting degree becomes better and better","c32cec57":"- Cost value are getting smaller\n- The redline is the regression line","9c7742a1":"## Can we do better\uff1f\n#### The fitting is not good, increase the number of iterations and try it\n- 3001\u219210001","1b29a029":"## Increases the challenge level\n- drop the noise and see what will happen","ebb42833":"### Build model and FCL\n- units:Positive integer,dimensionality of the output space\n- input_dim:dimensionality of the input space\n- sgd:Stochastic gradient descent\n- mse:Mean Squared Error"}}