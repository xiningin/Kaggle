{"cell_type":{"7b8f50ef":"code","fdc0087b":"markdown"},"source":{"7b8f50ef":"from keras.models import Sequential #\u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom keras.activations import relu, softmax\nfrom keras.callbacks import (EarlyStopping, LearningRateScheduler,\nModelCheckpoint, TensorBoard, ReduceLROnPlateau)\nfrom keras.layers import (Convolution2D, Dense, Dropout, GlobalAveragePooling2D, \nGlobalMaxPool2D, Input, MaxPool2D, concatenate, Activation,\nMaxPooling2D,Flatten,BatchNormalization, Conv2D,AveragePooling2D)\nfrom sklearn.datasets import load_iris\nfrom sklearn.datasets import make_moons \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.pipeline import Pipeline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport keras\nimport random\ndata = pd.read_csv('..\/input\/nslkdd\/KDDTest+.txt', delimiter=',', header = None) #\u0441 \u0447\u0438\u0442\u044b\u0432\u0430\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 KDD \u0438\u0437 \u0444\u0430\u0439\u043b\u0430 \u0438 \u043f\u0440\u0438\u0441\u0432\u0430\u0438\u0432\u0430\u043d\u0438\u0435 \u0438\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 data\ncolumns = (['duration', #\u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c\u044b\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0434\u043b\u044f \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e\u0433\u043e \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0444\u0430\u0439\u043b\u0430 \u0444\u043e\u0440\u043c\u0430\u0442\u0430 .txt \n'protocol_type',\n'service',\n'flag',\n'src_bytes',\n'dst_bytes',\n'land',\n'wrong_fragment',\n'urgent',\n'hot',\n'num_failed_logins',\n'logged_in',\n'num_compromised',\n'root_shell',\n'su_attempted',\n'num_root',\n'num_file_creations',\n'num_shells',\n'num_access_files',\n'num_outbound_cmds',\n'is_host_login',\n'is_guest_login',\n'count',\n'srv_count',\n'serror_rate',\n'srv_serror_rate',\n'rerror_rate',\n'srv_rerror_rate',\n'same_srv_rate',\n'diff_srv_rate',\n'srv_diff_host_rate',\n'dst_host_count',\n'dst_host_srv_count',\n'dst_host_same_srv_rate',\n'dst_host_diff_srv_rate',\n'dst_host_same_src_port_rate',\n'dst_host_srv_diff_host_rate',\n'dst_host_serror_rate',\n'dst_host_srv_serror_rate',\n'dst_host_rerror_rate',\n'dst_host_srv_rerror_rate',\n'attack',\n'level'])\n\ndf = pd.DataFrame(data) # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 DataFrame \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0441\u0447\u0438\u0442\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043f\u043e\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u0435\u0433\u043e \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e df\ndf.columns = columns # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u044b \u0442\u0438\u043f\u0430 DataFrame\ndata.columns = columns # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0432 \u043e\u0431\u044a\u0435\u043a\u0442 DataFrame\n\nprint(df.head()) #\u043c\u0435\u0442\u043e\u0434 \u0434\u043b\u044f \u0432\u043e\u0437\u0432\u0440\u0430\u0442\u0430 \u043f\u0435\u0440\u0432\u044b\u0445 n (\u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e 5) \u0441\u0442\u0440\u043e\u043a \u0444\u0440\u0435\u0439\u043c\u0430\ninformation = df.loc[:,columns[7:10]] # \u043d\u0430\u0431\u043e\u0440 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0431\u0443\u0434\u0443\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438, df.loc \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0434\u043e\u0441\u0442\u0443\u043f \u043a \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u043c \u043f\u043e \u043c\u0435\u0442\u043a\u0435 \u0438\u043b\u0438 \u043f\u043e \u0431\u0443\u043b\u0435\u0430\u043d\u043e\u0432\u0441\u043a\u043e\u043c\u0443 \u043c\u0430\u0441\u0441\u0438\u0432\u0443 \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435.\nresearch = df['land'] # \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n\nX_train, X_test, Y_train, Y_test = train_test_split(information, research, test_size = 0.4, random_state = 0) # \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 , \u0441\u043e\u0437\u0434\u0430\u044e\u0442\u0441\u044f 4 \"\u043f\u043e\u0440\u0446\u0438\u0438\" \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438\n\n\nclf = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', ) \nclf = clf.fit(X_train, Y_train) \nY_pred = clf.predict(X_test) \nlog_regr_score = clf.score(X_test, Y_test) \nprint('log_regr_score ',log_regr_score)\nconfusion_matrix(Y_test, Y_pred) \n\n\n# \u0414\u0435\u0440\u0435\u0432\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u0439\nclf = DecisionTreeClassifier(max_depth=10) # max_depth - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430\nclf = clf.fit(X_train, Y_train) \nY_pred = clf.predict(X_test) \ndec_tree_score = clf.score(X_test, Y_test) \nprint('dec_tree_score ',dec_tree_score) \nconfusion_matrix(Y_test, Y_pred) \n\n# \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043b\u0435\u0441\nclf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0) #n_estimators - \u043e\u0431\u0449\u0435\u0435 \u0447\u0438\u0441\u0442\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432,  max_depth - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430, \n# \u0421\u0443\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 random_state (\u0432\u043e \u0432\u0441\u0435\u0445 \u0444\u0443\u043d\u043a\u0446\u0438\u044f\u0445 \u0438 \u043c\u0435\u0442\u043e\u0434\u0430\u0445 \u0438\u0437 SciKit-\n\nclf = clf.fit(X_train, Y_train) \nY_pred = clf.predict(X_test) \nrand_frst_score = clf.score(X_test, Y_test) \nprint('rand_forest_score ',rand_frst_score) \nconfusion_matrix(Y_test, Y_pred) \n\n# k-\u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0435 \u0441\u043e\u0441\u0435\u0434\u0438\nclf = KNeighborsClassifier(n_neighbors=3) # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043e\u0441\u0435\u0434\u0435\u0439 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0434\u043b\u044f \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432\nclf = clf.fit(X_train, Y_train) \nY_pred = clf.predict(X_test)\nKNbrs_score1 = clf.score(X_test, Y_test) \nprint('KNbrs_score ',KNbrs_score1) \nconfusion_matrix(Y_test, Y_pred) \n\n# \u041c\u0435\u0442\u043e\u0434 \u043e\u043f\u043e\u0440\u043d\u044b\u0445 \u0432\u0435\u043a\u0442\u043e\u0440\u043e\u0432\nclf = SVC(gamma='auto') # \u043c\u0430\u0441\u0448\u0442\u0430\u0431, \u0435\u0441\u043b\u0438 \"\u0430\u0432\u0442\u043e\", \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f 1 \/ n_features\nclf = clf.fit(X_train, Y_train) \nY_pred = clf.predict(X_test)  \nSVC_score2 = clf.score(X_test, Y_test)\nprint('SVC_score ',SVC_score2) \nconfusion_matrix(Y_test, Y_pred) \n\n# \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0411\u0430\u0439\u0435\u0441\u0430\nclf = GaussianNB()\nclf = clf.fit(X_train, Y_train)  \nmoonsY_pred = clf.predict(X_test) \nNB_score = clf.score(X_test, Y_test)\nprint('NB_score ',NB_score) \nconfusion_matrix(Y_test, Y_pred)","fdc0087b":"\u0423 \u0446\u0456\u0439 \u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0456\u0439 \u0440\u043e\u0431\u043e\u0442\u0456 \u044f \u0432\u0437\u0430\u0454\u043c\u043e\u0434\u0456\u044e \u0437\u0456 \u0437\u043c\u0456\u043d\u043d\u0438\u043c\u0438 \u0437\u0430 \u0434\u043e\u043f\u043e\u043c\u043e\u0433\u043e\u044e \u0440\u0456\u0437\u043d\u0438\u0445 \u043c\u0435\u0442\u043e\u0434\u0456\u0432. \u0422\u0430\u043a\u0438\u0445 \u044f\u043a \u0414\u0435\u0440\u0435\u0432\u043e \u0440\u0456\u0448\u0435\u043d\u044c, \u0412\u0438\u043f\u0430\u0434\u043a\u043e\u0432\u0438\u0439 \u043b\u0456\u0441 \u0456 \u0442\u0434.\u0414\u0435\u0440\u0435\u0432\u0430 \u0420\u0406\u0428\u0415\u041d\u042c \u0434\u043e\u0437\u0432\u043e\u043b\u044f\u044e\u0442\u044c \u043f\u043e\u0431\u0443\u0434\u0443\u0432\u0430\u0442\u0456 \u0456\u0454\u0440\u0430\u0440\u0445\u0456\u044e \u043f\u0440\u0430\u0432\u0438\u043b \u00ab\u044f\u043a\u0449\u043e ... \u0442\u043e\u00bb (\u0442\u0435\u0441\u0442\u0438), \u042f\u043a\u0456 \u043f\u0440\u0438\u0432\u043e\u0434\u044f\u0442\u044c \u0434\u043e \u0440\u043e\u0437\u0432'\u044f\u0437\u043a\u0438 \u0437\u0430\u0434\u0430\u0447\u0456. \u0414\u043b\u044f \u0437\u0430\u0434\u0430\u0447\u0456 \u043a\u043b\u0430\u0441\u0456\u0444\u0456\u043a\u0430\u0446\u0456\u0457, \u043b\u0438\u0441\u0442\u0430\u043c\u0438 \u0434\u0435\u0440\u0435\u0432 \u0420\u0406\u0428\u0415\u041d\u042c \u0431\u0443\u0434\u0443\u0442 \u0432\u0441\u0456 \u041c\u043e\u0436\u043b\u0438\u0432\u0456 \u043a\u043b\u0430\u0441\u0456.\u0426\u0435 \u043d\u0430\u0431\u0456\u0440 \u0434\u0435\u0440\u0435\u0432 \u0420\u0406\u0428\u0415\u041d\u042c, \u0432 \u044f\u043a\u043e\u043c\u0443 \u041a\u043e\u0436\u043d\u0435 \u0434\u0435\u0440\u0435\u0432\u043e \u0414\u0435\u0449\u043e \u0432\u0456\u0434\u0440\u0456\u0437\u043d\u044f\u0454\u0442\u044c\u0441\u044f \u0432\u0456\u0434 \u0456\u043d\u0448\u043e\u0433\u043e.\u041e\u0441\u043d\u043e\u0432\u043d\u0430 \u043c\u0435\u0442\u0430 \u043f\u043e\u0431\u0443\u0434\u043e\u0432\u0430 \u0412\u0438\u043f\u0430\u0434\u043a\u043e\u0432\u0435 \u043b\u0456\u0441\u0443 - \u0417\u043c\u0435\u043d\u0448\u0438\u0442\u0438 \u043f\u0435\u0440\u0435\u043d\u0430\u0432\u0447\u0430\u043d\u043d\u044f \u043e\u043a\u0440\u0435\u043c\u0438\u0439 \u0434\u0435\u0440\u0435\u0432.\u041c\u0435\u0442\u043e\u0434 k-\u043d\u0430\u0439\u0431\u043b\u0438\u0436\u0447\u0435 \u0441\u0443\u0441\u0456\u0434\u0456\u0432 (\u043d\u0430\u0439\u0431\u043b\u0438\u0436\u0447\u0435 \u0441\u0443\u0441\u0456\u0434\u0456\u0432 (k-\u043d\u0430\u0439\u0431\u043b\u0438\u0436\u0447\u0435 \u0441\u0443\u0441\u0456\u0434\u0456\u0432 (Nearest Neighbors). \u041e\u0441\u043d\u043e\u0432\u043d\u0430 \u0456\u0434\u0435\u044f \u043f\u0456\u0434\u0445\u043e\u0434\u0443 \u041f\u043e\u043b\u044f\u0433\u0430\u0454 \u0443 \u043f\u043e\u0438\u0441\u043a\u0430 \u0441\u0445\u043e\u0436\u0438\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0443 \u041d\u0430\u0432\u0447\u0430\u043b\u044c\u043d\u0438\u0445 \u0414\u0430\u043d\u0438\u0445 \u0442\u0430 \u043e\u0431'\u0454\u0434\u043d\u0430\u043d\u043d\u0456 \u0457\u0445 \u0443 \u043e\u0434\u0438\u043d \u043a\u043b\u0430\u0441.\u041c\u0435\u0442\u043e\u0434 \u043e\u043f\u043e\u0440\u043d\u0438\u0445 \u0432\u0435\u043a\u0442\u043e\u0440\u0456\u0432 (Support Vector Machine). \u043e\u0434\u0438\u043d \u0437 \u043e\u0441\u043d\u043e\u0432\u043d\u0438\u0445 \u043c\u0435\u0442\u043e\u0434\u0456\u0432 \u043a\u043b\u0430\u0441\u0456\u0444\u0456\u043a\u0430\u0446\u0456\u0457. \u041c\u0435\u0442\u043e\u0434 \u043c\u043e\u0436\u0435\u0442 \u0432\u0438\u043a\u043e\u0440\u0438\u0441\u0442\u043e\u0432\u0443\u0432\u0430\u0442 \u0434\u043b\u044f \u043f\u043e\u0431\u0443\u0434\u043e\u0432\u0430 \u043d\u0435\u043b\u0456\u043d\u0456\u0439\u043d\u0456\u0445 \u043a\u043b\u0430\u0441\u0456\u0444\u0456\u043a\u0430\u0442\u043e\u0440\u0456\u0432. \u0423 \u043c\u0435\u0442\u043e\u0434\u0456 \u043e\u043f\u043e\u0440\u043d\u0438\u0445 \u0432\u0435\u043a\u0442\u043e\u0440\u0456\u0432 \u041a\u043e\u0436\u043d\u0430 \u0442\u043e\u0447\u043a\u0430 \u0432 n-\u0432\u0438\u043c\u0456\u0440\u043d\u043e\u043c\u0443 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0454\u0442\u044c\u0441\u044f \u044f\u043a n-\u0432\u0456\u043c\u0456\u0440\u043d\u0456\u0439 \u0432\u0435\u043a\u0442\u043e\u0440, \u043e\u0441\u043a\u0456\u043b\u044c\u043a\u0456 \u0437 \u0442\u043e\u0447\u043d\u043e\u044e \u043f\u043e\u0432'\u044f\u0437\u0430\u043d\u043e \u043d\u0430\u0431\u0456\u0440 \u0435\u0435 n \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442. \u0406\u0434\u0435\u044f \u043c\u0435\u0442\u043e\u0434\u0443 \u041f\u043e\u043b\u044f\u0433\u0430\u0454 \u0443 \u043f\u043e\u0431\u0443\u0434\u043e\u0432\u0456 \u0433\u0456\u043f\u0435\u0440\u043f\u043b\u043e\u0449\u0456\u043d\u0456 \u043a\u043b\u0430\u0441\u0456\u0444\u0456\u043a\u0430\u0442\u043e\u0440\u0430 (\u0440\u043e\u0437\u043c\u0456\u0440\u043d\u043e\u0441\u0442\u0456 n-1) \u043d\u0430\u0439\u0431\u0456\u043b\u044c\u0448 \u0432\u0456\u0434\u0434\u0430\u043b\u0435\u043d\u043e\u0457 \u0432\u0456\u0434 \u043a\u0440\u0430\u0439\u043d\u0456\u0445 \u0421\u041f\u041e\u0421\u0422\u0415\u0420\u0415\u0416\u0415\u041d\u042c (\u043a\u0440\u0430\u0439\u043d\u0456\u0445 \u0442\u043e\u0447\u043e\u043a \u043e\u0431\u043b\u0430\u0441\u0442\u0456) . \u0422\u0430\u043a\u0456 \u0442\u043e\u0447\u043a\u0438, \u0432\u043b\u0430\u0441\u043d\u0435, \u0438 \u043d\u0430\u0437\u0456\u0432\u0430\u044e\u0442\u044c\u0441\u044f \u043e\u043f\u043e\u0440\u043d\u0438\u043c\u0438 \u0432\u0435\u043a\u0442\u043e\u0440\u0430\u043c\u0438. \u041d\u0430\u0457\u0432\u043d\u0456\u0439 \u043a\u043b\u0430\u0441\u0438\u0444\u0456\u043a\u0430\u0442\u043e\u0440 \u0411\u0430\u0454\u0441\u0430 (Na\u00efve Bayesian) .\u0412 \u041e\u0441\u043d\u043e\u0432\u0456 \u043a\u043b\u0430\u0441\u0456\u0444\u0456\u043a\u0430\u0442\u043e\u0440\u0430 \u043b\u0435\u0436\u0438\u0442\u044c \u0442\u0435\u043e\u0440\u0435\u043c \u0430 \u0411\u0430\u0454\u0441\u0430, \u044f\u043a\u0430 \u0434\u043e\u0437\u0432\u043e\u043b\u044f\u0454\u0440\u043e\u0437\u0440\u0430\u0445\u0443\u0432\u0430\u0442\u0456 \u0443\u043c\u043e\u0432\u043d\u043e \u0439\u043c\u043e\u0432\u0456\u0440\u043d\u0456\u0441\u0442\u044c \u043f\u043e\u0434\u0456\u0457 A \u043f\u0440\u0438 \u0443\u043c\u043e\u0432\u0456, \u0447\u0442\u043e \u0432\u0456\u0434\u0431\u0443\u043b\u0430\u0441\u044f \u041f\u043e\u0434\u0456\u044f B"}}