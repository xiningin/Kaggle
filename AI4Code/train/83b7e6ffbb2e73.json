{"cell_type":{"391894c7":"code","81b3e96c":"code","a9d03620":"code","295c04c7":"code","2411a934":"code","53a0867a":"code","83e7da5b":"code","2a42ffa1":"code","00bfe29a":"code","d0572618":"code","773dd8ba":"code","ccf5d549":"code","dcb0a1c4":"code","f6395479":"code","c4343a13":"code","cc13f2f3":"code","2b8ebe3c":"code","111d2b53":"code","ae2d3eb2":"code","0c3d32a7":"code","0eee60f2":"code","b3004016":"code","8d92ca81":"code","012b5904":"code","6b48e15f":"code","777fa171":"code","0d26da2f":"code","7b366bc3":"code","3298abcf":"code","5293071b":"code","1e21c742":"code","0eba8f1a":"code","93173548":"code","4d586976":"code","7a884baa":"markdown","f785da85":"markdown","647fa48e":"markdown","4d678ed9":"markdown","957ccbda":"markdown","37a2a973":"markdown","5e2b3587":"markdown","e9b61a42":"markdown","12408613":"markdown","83a43e09":"markdown","9aced24e":"markdown","c046812e":"markdown","4d08cfd9":"markdown","d103bae1":"markdown","af49591f":"markdown","98b36e1a":"markdown","f3901c9a":"markdown"},"source":{"391894c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.split('.')[-1]=='csv':\n            print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81b3e96c":"# !pip install python-gdcm\n# !pip uninstall -y pylibjpeg\n# !pip uninstall -y  pylibjpeg-libjpeg\n!conda install -c conda-forge gdcm -y","a9d03620":"#xray\nimport pydicom as dicom\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nimport cv2\n# color\nfrom colorama import Fore, Back, Style\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n# plotly\nimport pprint\nimport plotly.express as px\nimport plotly\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')","295c04c7":"submission_df = pd.read_csv(r'\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\ntrain_img_level_df = pd.read_csv(r'\/kaggle\/input\/siim-covid19-detection\/train_image_level.csv')\ntrain_study_level_df = pd.read_csv(r'\/kaggle\/input\/siim-covid19-detection\/train_study_level.csv')","2411a934":"train_study_level_df.head(10)","53a0867a":"\nprint(train_study_level_df.shape)\n#check if 2 classes can be in same study image or not-\ntrain_study_level_df['sumApperance'] = train_study_level_df['Atypical Appearance'] + train_study_level_df['Indeterminate Appearance'] \\\n                                    + train_study_level_df['Typical Appearance'] +\\\n                                    train_study_level_df['Negative for Pneumonia'] \nprint('unique count',train_study_level_df['sumApperance'].nunique())\n\nfor idx,col in enumerate(train_study_level_df.columns):\n    if col =='id':\n        continue\n    plt.figure(idx)\n    sns.countplot(train_study_level_df[col])\n    #train_img_level_dfproces['Negative for Pneumonia'].value_counts().index\nplt.show()","83e7da5b":"#check relative frequency \n#create 4 class - Negative for Pneumonia - 0 , Typical Appearance\t1, Indeterminate Appearance 2, Atypical Appearance 3.\ntrain_study_level_df['target'] = 0\ntrain_study_level_df.loc[train_study_level_df['Atypical Appearance']==1,'target']=3\ntrain_study_level_df.loc[train_study_level_df['Indeterminate Appearance']==1,'target']=2\ntrain_study_level_df.loc[train_study_level_df['Typical Appearance']==1,'target']=1\nplt.figure(100)\nax= sns.countplot(train_study_level_df['target'])\n#plt.plot(train_img_level_dfproces['target'].value_counts().index,train_img_level_dfproces['target'].value_counts())\n#plt.legend()\nplt.title('Negative for Pneumonia: 0,Typical Appearance: 1, Indeterminate Appearance 2, Atypical Appearance 3')\nplt.show()","2a42ffa1":"train_img_level_df.isnull().sum()","00bfe29a":"train_study_level_df.isnull().sum()","d0572618":"train_img_level_df.head(10)","773dd8ba":"#merge using pandas\ntrain_study_level_df['StudyInstanceUID'] = train_study_level_df['id'].apply(lambda x: x.replace('_study', ''))\ndel train_study_level_df['id']\ndel train_study_level_df['sumApperance']\ntrain_merger_df = train_img_level_df.merge(train_study_level_df, on='StudyInstanceUID')\ntrain_merger_df.head()","ccf5d549":"train_merger_df.shape,train_merger_df['StudyInstanceUID'].shape,train_merger_df['StudyInstanceUID'].nunique()","dcb0a1c4":"train_img_level_df['StudyInstanceUID'].shape,train_img_level_df['StudyInstanceUID'].nunique()","f6395479":"def getScorefromStudyTable(df,columnName,row_id):\n    dftmp = df.loc[df[columnName]==row_id]\n    result = dict()\n    if dftmp.shape[0] !=1:\n        print('Not a unique score')\n        print(dftmp)\n        raise Exception('Issue of unique score for given row id,',row_id)\n    else:      \n        result['Atypical Appearance'] = dftmp['Atypical Appearance'].values[0]\n        result['Indeterminate Appearance'] = dftmp['Indeterminate Appearance'].values[0]\n        result['Typical Appearance'] = dftmp['Typical Appearance'].values[0]\n        result['Negative for Pneumonia'] = dftmp['Negative for Pneumonia'].values[0]\n        result['TotalScore'] =  dftmp['Atypical Appearance'].values[0] + dftmp['Indeterminate Appearance'].values[0] \\\n                                    + dftmp['Typical Appearance'].values[0] +\\\n                                    dftmp['Negative for Pneumonia'].values[0] \n    return result","c4343a13":"values = train_img_level_df['StudyInstanceUID'].value_counts().keys().tolist()\ncounts = train_img_level_df['StudyInstanceUID'].value_counts().tolist()\nprint(len(values),len(counts))\nstudyID2imageID = {}\n#Find all 1 to many - study ID and its image ID \nmaxInfo = 5\ncount=0\nfor idx,item in enumerate(values):\n    if count > maxInfo:\n        break\n    if counts[idx] ==1:\n        continue\n    else:\n        studyID2imageID[item]= counts[idx]\n        print('*'*50)\n        print('Study id -',item)\n        #print(train_study_level_df.loc[train_study_level_df['StudyInstanceUID']==item])\n        r = getScorefromStudyTable(train_study_level_df,'StudyInstanceUID',item)\n        imgdf = train_img_level_df.loc[train_img_level_df['StudyInstanceUID']==item]\n        print(r)\n        for index,row in imgdf.iterrows():\n            print(index,row['id'],row['boxes'],row['label'])\n        print('*'*75)\n        \n        count +=1\n#studyID2imageID","cc13f2f3":"if False:\n    train_img_level_df_process = train_img_level_df.copy()\n    #merging study & image tabel - using loiops - not good approch.\n    #Negative for Pneumonia - 0 , Typical Appearance\t1, Indeterminate Appearance 2, Atypical Appearance 3, target\n    train_img_level_df_process['Negative for Pneumonia'] = -1\n    train_img_level_df_process['Typical Appearance'] = -1\n    train_img_level_df_process['Indeterminate Appearance'] = -1\n    train_img_level_df_process['Atypical Appearance'] = -1\n    train_img_level_df_process['target'] = -1\n    runcount = 0\n    for row in train_img_level_df_process['StudyInstanceUID']:#.iterrows():\n        runcount +=1\n        studyid = f\"{row}_study\"\n        #print(studyid)\n        df_found = train_study_level_df.loc[train_study_level_df['id']==studyid]\n        #print(df_found['target'].values[0])\n        train_img_level_df_process.loc[train_img_level_df_process['StudyInstanceUID']==row,'target'] = df_found['target'].values[0]\n        train_img_level_df_process.loc[train_img_level_df_process['StudyInstanceUID']==row,'Atypical Appearance'] = df_found['Atypical Appearance'].values[0]\n        train_img_level_df_process.loc[train_img_level_df_process['StudyInstanceUID']==row,'Indeterminate Appearance'] = df_found['Indeterminate Appearance'].values[0]\n        train_img_level_df_process.loc[train_img_level_df_process['StudyInstanceUID']==row,'Typical Appearance'] = df_found['Typical Appearance'].values[0]\n        train_img_level_df_process.loc[train_img_level_df_process['StudyInstanceUID']==row,'Negative for Pneumonia'] = df_found['Negative for Pneumonia'].values[0]\n        #break\n        #if runcount > 5:\n        #    break\n\n    train_img_level_df_process.head(10)","2b8ebe3c":"voi_lut=True\nfix_monochrome=True\ndef dicom_dataset_to_dict(filename):\n    \"\"\"Credit: https:\/\/github.com\/pydicom\/pydicom\/issues\/319\n               https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    \"\"\"\n    \n    dicom_header = dicom.dcmread(filename) \n    #====== DICOM FILE DATA ======\n    dicom_dict = {}\n    repr(dicom_header)\n    for dicom_value in dicom_header.values():\n        if dicom_value.tag == (0x7fe0, 0x0010):\n            #discard pixel data\n            continue\n        if type(dicom_value.value) == dicom.dataset.Dataset:\n            dicom_dict[dicom_value.name] = dicom_dataset_to_dict(dicom_value.value)\n        else:\n            v = _convert_value(dicom_value.value)\n            dicom_dict[dicom_value.name] = v\n      \n    del dicom_dict['Pixel Representation']\n    \n    #====== DICOM IMAGE DATA ======\n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom_header.pixel_array, dicom_header)\n    else:\n        data = dicom_header.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom_header.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    modified_image_data = (data * 255).astype(np.uint8)\n    \n    return dicom_dict, modified_image_data\n\ndef _sanitise_unicode(s):\n    return s.replace(u\"\\u0000\", \"\").strip()\n\ndef _convert_value(v):\n    t = type(v)\n    if t in (list, int, float):\n        cv = v\n    elif t == str:\n        cv = _sanitise_unicode(v)\n    elif t == bytes:\n        s = v.decode('ascii', 'replace')\n        cv = _sanitise_unicode(s)\n    elif t == dicom.valuerep.DSfloat:\n        cv = float(v)\n    elif t == dicom.valuerep.IS:\n        cv = int(v)\n    else:\n        cv = repr(v)\n    return cv\n","111d2b53":"if True:\n    #filename = r'..\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm'\n    filename = r'\/kaggle\/input\/siim-covid19-detection\/train\/ff0879eb20ed\/d8a644cc4f93\/000c3a3f293f.dcm'\n    df, img_array = dicom_dataset_to_dict(filename)\n    fig, ax = plt.subplots(1, 2, figsize=[10, 8])\n    ax[0].imshow(img_array, cmap=plt.cm.gray)\n    ax[1].imshow(img_array, cmap=plt.cm.plasma)    \n    plt.show()\n    \n    pprint.pprint(df)","ae2d3eb2":"import glob\ndef findImages(rootfolder):\n    listOfimages = glob.glob(os.path.join(rootfolder,'*\/*.dcm'))+glob.glob(os.path.join(rootfolder,'*\/*\/*.dcm'))\n    return listOfimages\n\nfolderpathTrain = r'\/kaggle\/input\/siim-covid19-detection\/train'\nimgListTrain = findImages(folderpathTrain)\n#print(imgListTrain[:10])\nfolderpathTest = r'\/kaggle\/input\/siim-covid19-detection\/test'\nimgListTest = findImages(folderpathTest)\n#print(imgListTest[:10])\nprint('#imgListTest,#imgListTrain',len(imgListTest),len(imgListTrain))","0c3d32a7":"testbasenameList = [os.path.basename(file) for file in imgListTest]\n#print(testbasenameList[:10])\ncommonFile = []\nfor file in imgListTrain:\n    basename = os.path.basename(file)\n    #print(basename)\n    if basename in testbasenameList:\n        #print(file)\n        commonFile.append(file)\n\nif len(commonFile)>0:\n    print('Found common files-',commonFile)\nelse:\n    print('No common files')","0eee60f2":"for imgpath in imgListTrain[:5]:\n    df, img_array = dicom_dataset_to_dict(imgpath)\n    fig, ax = plt.subplots(1, 2, figsize=[10, 8])\n    ax[0].imshow(img_array, cmap=plt.cm.gray)\n    ax[1].imshow(img_array, cmap=plt.cm.plasma)    \n    plt.show()","b3004016":"from sklearn.model_selection import StratifiedKFold\nnFolds = 3\ntrain_merger_df['kfold'] = -1\nskf = StratifiedKFold(n_splits=nFolds, shuffle=True, random_state=123)\nimages = train_merger_df['id']\ntarget = train_merger_df['target']\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(images, target)):\n    train_merger_df.loc[valid_idx, 'kfold'] = fold","8d92ca81":"sns.countplot(train_merger_df['kfold'])\nplt.show()","012b5904":"def savedcmtopng(index,rowid,trainFolder,localdir):\n    global train_merger_df\n    global save_png,plot_image_with_bbox,plot_flag\n    #print(index,rowid,trainFolder,localdir)\n    image = rowid.id\n    bbox = rowid.boxes\n    label = rowid.label\n    target = rowid.target\n    studyUID = rowid.StudyInstanceUID\n    \n    studyfolder = os.path.join(trainFolder,studyUID)\n    folders = os.listdir(studyfolder)\n    dcmfolder = os.path.join(studyfolder,folders[0])\n    files = glob.glob(os.path.join(dcmfolder,'*.dcm'))\n    dcm_path = files[0]\n    firstname = os.path.basename(dcm_path)\n    firstname_noextn = firstname.split('.')[0]\n    try:\n        df, img_array = dicom_dataset_to_dict(dcm_path)\n        H,W = img_array.shape\n        if save_png:\n            png_path = os.path.join(localdir,f\"{firstname_noextn}.png\")\n            if resize_flag:\n                img_array_sz = cv2.resize(img_array,resize_dims,interpolation=cv2.INTER_LINEAR)\n            else:\n                img_array_sz = img_array\n            cv2.imwrite(png_path,img_array_sz)\n        if plot_image_with_bbox != -1 and plot_flag and isinstance(bbox,list):\n            img_plot = np.stack([img_array]*3,axis=-1)\n            plot_count += 1\n            bbox = eval(bbox)\n            numBox = len(bbox)\n            print(bbox)\n            for idbox in range(numBox):\n                item = bbox[idbox]\n                x = int(item['x'])\n                y = int(item['y'])\n                width = int(item['width'])\n                height = int(item['height'])\n                #print(x,y,width,height)\n                cv2.rectangle(img_plot,(x,y),(x+width,y+height),(255,0,0),20)\n            plt.imshow(img_plot)\n            if plot_count >= plot_image_with_bbox:\n                plot_flag = False\n                #break\n            plt.show()\n    except Exception as e:\n        H = -1\n        W = -1\n        png_path = None\n        print(image,dcm_path,e,bbox)\n        \n    train_merger_df.loc[index,'dcm_path']= dcm_path\n    train_merger_df.loc[index,'height']= H\n    train_merger_df.loc[index,'width']= W\n    train_merger_df.loc[index,'png_path']= png_path","6b48e15f":"import shutil\nimport matplotlib.pyplot as plt\nlocaldir = os.path.join('.','train')\n#shutil.rmtree(localdir)\nos.makedirs(localdir,exist_ok=True)\ntrain_merger_df['dcm_path'] = None\ntrain_merger_df['width'] = None\ntrain_merger_df['height'] = None\ntrain_merger_df['png_path'] = None\ntrainFolder = r'\/kaggle\/input\/siim-covid19-detection\/train'\ntestFolder = r'\/kaggle\/input\/siim-covid19-detection\/test'\n\nsave_png = True\nplot_image_with_bbox = 10 #-1 for no plot\nplot_count = 0\nplot_flag = False#True\nresize_flag = True\nresize_dims = (512,512)\nif False:\n    for index,rowid in train_merger_df.iterrows():\n        image = rowid.id\n        bbox = rowid.boxes\n        label = rowid.label\n        target = rowid.target\n        studyUID = rowid.StudyInstanceUID\n\n        studyfolder = os.path.join(trainFolder,studyUID)\n        folders = os.listdir(studyfolder)\n        dcmfolder = os.path.join(studyfolder,folders[0])\n        files = glob.glob(os.path.join(dcmfolder,'*.dcm'))\n        dcm_path = files[0]\n        firstname = os.path.basename(dcm_path)\n        firstname_noextn = firstname.split('.')[0]\n        try:\n            df, img_array = dicom_dataset_to_dict(dcm_path)\n            H,W = img_array.shape\n            if save_png:\n                png_path = os.path.join(localdir,f\"{firstname_noextn}.png\")\n                if resize_flag:\n                    img_array_sz = cv2.resize(img_array,resize_dims,interpolation=cv2.INTER_LINEAR)\n                else:\n                    img_array_sz = img_array\n                cv2.imwrite(png_path,img_array_sz)\n            if plot_image_with_bbox != -1 and plot_flag and isinstance(bbox,list):\n                img_plot = np.stack([img_array]*3,axis=-1)\n                plot_count += 1\n                bbox = eval(bbox)\n                numBox = len(bbox)\n                print(bbox)\n                for idbox in range(numBox):\n                    item = bbox[idbox]\n                    x = int(item['x'])\n                    y = int(item['y'])\n                    width = int(item['width'])\n                    height = int(item['height'])\n                    #print(x,y,width,height)\n                    cv2.rectangle(img_plot,(x,y),(x+width,y+height),(255,0,0),20)\n                plt.imshow(img_plot)\n                if plot_count >= plot_image_with_bbox:\n                    plot_flag = False\n                    break\n                plt.show()\n        except Exception as e:\n            H = -1\n            W = -1\n            png_path = None\n            print(image,dcm_path,e,bbox)\n\n        train_merger_df.loc[index,'dcm_path']= dcm_path\n        train_merger_df.loc[index,'height']= H\n        train_merger_df.loc[index,'width']= W\n        train_merger_df.loc[index,'png_path']= png_path\n    ","777fa171":"from concurrent.futures import ThreadPoolExecutor,as_completed\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    futureObjs = []\n    for index,rowid in train_merger_df.iterrows():\n        #savedcmtopng(index,rowid,trainFolder,localdir)\n        #break\n        futureObjs.append(executor.submit(savedcmtopng, index,rowid,trainFolder,localdir))\n    #for fut in as_completed(futureObjs):\n    #    print(fut)\nprint('Parallel Done')","0d26da2f":"train_merger_df.head(10)","7b366bc3":"train_merger_df.to_csv(r'\/kaggle\/working\/train_data.csv')","3298abcf":"!cd \/kaggle\/working","5293071b":"!zip -r train_patches_512.zip train","1e21c742":"#!tar -zcf train_patches_512.tar.gz \/kaggle\/working\/train","0eba8f1a":"print('done')","93173548":"from IPython.display import FileLink\nFileLink('train_patches_512.zip')","4d586976":"# https:\/\/www.kaggle.com\/sumitjha19\/pytorch-starter-fasterrcnn-train-v2\n# https:\/\/www.kaggle.com\/sumitjha19\/fasterrcnn-with-dataaug-yolov3-and-kfolds-wip\n# https:\/\/www.kaggle.com\/sumitjha19\/pytorch-starter-fasterrcnn-train-v2\n# https:\/\/www.kaggle.com\/sumitjha19\/pytorch-starter-fasterrcnn-inference\n#https:\/\/www.kaggle.com\/sumitjha19\/data-exploration-training-data-prp\n    ","7a884baa":"# **Explore train_image_level.csv**","f785da85":"# **Missing values**","647fa48e":"**Plot sample image**","4d678ed9":"**plot few images**","957ccbda":"**Handling GDCM error**","37a2a973":"# **Update the path of image in merge table**","5e2b3587":"# **Collect image path for Study Id**","e9b61a42":"**So, same studyID is mapped to many imagees ..more than 1 image_id. Let's find such mapping**","12408613":"# **Merging two CSV**","83a43e09":"**Dicom Data**\n\nTaken from - https:\/\/www.kaggle.com\/ruchi798\/siim-covid-19-detection-eda-data-augmentation","9aced24e":"**Relationship b\/w train_image_level & study_level**","c046812e":"**Any overlap b\/w test & train image**","4d08cfd9":"# **DICOM to PNG**","d103bae1":"# **Get Kfolds**","af49591f":"**Dataset information**\nThe train dataset comprises 6,334 chest scans in DICOM format, which were de-identified to protect patient privacy. All images were labeled by a panel of experienced radiologists for the presence of opacities as well as overall appearance.\n\nNote that all images are stored in paths with the form **study-id\/series\/image-id**. The study ID here relates directly to the study-level predictions, and the image ID is the ID used for image-level predictions.\n\nThe hidden test dataset is of roughly the same scale as the training dataset.\n\n**Files**\ntrain_study_level.csv - the train study-level metadata, with one row for each study, including correct labels.\ntrain_image_level.csv - the train image-level metadata, with one row for each image, including both correct labels and any bounding boxes in a dictionary format. Some images in both test and train have multiple bounding boxes.\nsample_submission.csv - a sample submission file **containing all image- and study-level IDs**.","98b36e1a":"# **Guideline**\nhttps:\/\/journals.lww.com\/thoracicimaging\/Fulltext\/2020\/11000\/Review_of_Chest_Radiograph_Findings_of_COVID_19.4.aspx\n\n![image.png](attachment:886039d3-7153-4dfe-8acd-9db8ec74bcf1.png)]\n\n\n**Zoning**\n\n![image.png](attachment:d1668cc0-3512-443d-b503-b774fe30ec7c.png)]","f3901c9a":"# **Explore  Train_Study_level.csv**"}}