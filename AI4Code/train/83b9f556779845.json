{"cell_type":{"357e7bd5":"code","872ed51e":"code","6892244f":"code","0ec010a0":"code","da9792a4":"code","cd318174":"code","01977e00":"code","70012783":"code","c6c70987":"code","f46a13b3":"code","fe074297":"code","e7f106c0":"code","b4f1741f":"code","54d0ba6f":"code","5616fd20":"code","f48058c4":"code","3b780115":"code","52ddcd4b":"code","e2003e9b":"markdown","c14530c0":"markdown","60a173e3":"markdown","d52ed5d2":"markdown","829d748a":"markdown","71ae39e8":"markdown","0199ee38":"markdown","ea8dd7ec":"markdown","9bbcc9f8":"markdown","0788aadb":"markdown","3237a92e":"markdown","52dc3b47":"markdown","1ebc9813":"markdown","2e666e89":"markdown","a7e26e32":"markdown","72c686c9":"markdown","a353cc45":"markdown","eef20742":"markdown","5f213148":"markdown","439d8470":"markdown","ae3679f0":"markdown","e882c294":"markdown","b2e7a1af":"markdown","151b9df6":"markdown"},"source":{"357e7bd5":"import pandas as pd # data processing\nimport matplotlib.pyplot as plt # basic plotting \nimport numpy as np # linear algebra\nimport geopandas as gpd # geospatial data\nfrom scipy import stats as st # probability distributions and statistical functions\nimport seaborn as sns #data visualization library based on matplotlib\nimport folium #interactive leaflet map\n\nfrom folium.plugins import FloatImage\n\nfrom matplotlib.colors import ListedColormap\nfrom shapely.geometry import Point\nfrom sklearn import preprocessing\n\n\n%matplotlib inline \nplt.style.use('ggplot') # use ggplot style\nsns.set(style='whitegrid', palette='pastel', color_codes=True) \nsns.mpl.rc('figure', figsize=(30,15))\n","872ed51e":"# read in the data from the provided csv file\ndata = pd.read_csv(\"..\/input\/housesalesprediction\/kc_house_data.csv\")\ndata.head(5)","6892244f":"#shape command will give number of rows\/samples\/examples and number of columns\/features\/predictors in dataset\n#(rows,columns)\ndata.shape","0ec010a0":"#  Describe gives statistical information about numerical columns in the dataset\ndata.describe(include='all')","da9792a4":"# missing values\ndata.isnull().sum()","cd318174":"## First method\n## Before deleting outliers length =  21613\n## After deleting outliers length =  14934\n# print(\"Before deleting outliers length = \" , len(data))   \n# Q1 = data.quantile(0.25)\n# Q3 = data.quantile(0.75)\n# IQR = Q3 - Q1\n# data = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n# print(\"After deleting outliers length = \" ,  len(data)) \n\n## Second method\n## Before deleting outliers length =  21613\n## After deleting outliers length =  20770\n\nprint(\"Before deleting outliers length = \" , len(data))                \ntarget = data['price']\ntarget_mean = target.mean()\ntarget_sd = target.std()\ndata = data[(target > target_mean - 2*target_sd) & (target < target_mean + 2*target_sd)]\nprint(\"After deleting outliers length = \" ,  len(data)) \n\n","01977e00":"# Dividing columns into numerical and categorical\nnumerical_columns   = ['price','sqft_living','sqft_living','sqft_lot','sqft_above','sqft_basement','sqft_living15','sqft_lot15']\ncategorical_columns = ['bedrooms','bathrooms','floors','waterfront','view','condition','yr_built','yr_renovated','zipcode']\n\nnumerical_features   = data[numerical_columns]\ncategorical_features = data[categorical_columns]","70012783":"fig = plt.figure(figsize=(25, 10))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(2,4,i+1)\n    sns.distplot(numerical_features.iloc[:,i].dropna(), rug=True, hist=True, label='UW', kde_kws={'bw':1})\n    plt.xlabel(numerical_features.columns[i])\nplt.tight_layout()\nplt.show()","c6c70987":"fig = plt.figure(figsize=(25,40))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(4,2,i+1)\n    sns.boxplot( y=numerical_features.iloc[:,i])\n\nplt.tight_layout()\nplt.show()\n","f46a13b3":"\nfig = plt.figure(figsize=(30,40))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(8,2,i+1)\n    sns.regplot(numerical_features.iloc[:, i],data['price'],line_kws={\"color\": \"red\"})\nplt.tight_layout()\nplt.show()\n","fe074297":"data.hist(bins=10,figsize=(25,15) , column = categorical_columns)\n;","e7f106c0":"#correlation matrix Heatmap\nax = plt.axes()\ndf = pd.DataFrame(data,columns=pd.read_csv('..\/input\/housesalesprediction\/kc_house_data.csv', nrows=1).columns.tolist())\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True , fmt=\".3f\", vmin=0, cmap=sns.cm.rocket_r,annot_kws={\"size\": 18},  linewidths=.1,)\nax.set_title('Correlation matrix Heatmap',fontsize=25)\nplt.show()\n\n","b4f1741f":"# most correlated features Heatmap\nax = plt.axes()\nmostCorrMatrix = data.corr()\ntop_corr_features = mostCorrMatrix.index[abs(mostCorrMatrix[\"price\"])>0.5]\nsns.heatmap(df[top_corr_features].corr(),annot=True ,fmt=\".3f\" ,vmin=0 ,cmap=sns.cm.rocket_r ,annot_kws={\"size\": 25},  linewidths=.1, )\nsns.set(font_scale = 1)\nax.set_title('Most correlated features Heatmap',fontsize=25)\nplt.show()","54d0ba6f":"min_max_scaler = preprocessing.MinMaxScaler()\ncolumn_sels = [ 'bathrooms', 'sqft_living', 'grade', 'sqft_above','sqft_living15']\ny = data['price']\nx = pd.DataFrame(data=min_max_scaler.fit_transform(data.loc[:,column_sels]), columns=column_sels)\nfig, axs = plt.subplots(ncols=5, nrows=1, figsize=(25, 5))\nindex = 0\naxs = axs.flatten()\nfor i, k in enumerate(column_sels):\n    sns.regplot(y=y, x=x[k], ax=axs[i],line_kws={\"color\": \"red\"})\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","5616fd20":"# Create data\nsqft_living = data['sqft_living']\nprice =  data['price']\n\n#regression\nr = st.linregress(sqft_living,price)\nplt.plot(sqft_living, r.intercept + r.slope*sqft_living, 'r', label='fitted line' ,c='#4a70e1')\n\n# Plot\nplt.scatter(sqft_living, price, s=10, c='#d50a59', alpha=0.5)\nplt.title('Scatter plot pythonspot.com')\nplt.xlabel('sqft_living')\nplt.ylabel('price')\nplt.show()","f48058c4":"box_ax = df.boxplot(vert=False ,column='price',figsize=(25,70) , by='zipcode', grid=True, rot=90   ,showfliers=False , fontsize='15',  patch_artist = True )\n# box_ax.set_ylim(-0e5, 1.5e6)\nbox_ax.set_yticklabels(['%s  (%d)'%(k, (v['id'])) for k, v in data.groupby('zipcode').count().iterrows() ] , rotation=0 )\n\nplt.show()\n\n\n","3b780115":"# import king county street map\nstreet_map = gpd.read_file(r'..\/input\/kingcountyshapefileroadmap\/tl_2017_53033_roads.shp')\n\n# designate coordinate system\ncrs = {'init':\"EPSG:3857\"}\n\n# zip x and y coordinates into single feature\ngeometry = [Point(xy) for xy in zip(df['long'], df['lat'])]\n\n# create GeoPandas dataframe\ngeo_df = gpd.GeoDataFrame(df,crs = crs,geometry = geometry)\n\n\n# create figure and axes, assign to subplot\nfig, ax = plt.subplots()\n\n# add .shp mapfile to axes\nstreet_map.plot(ax=ax, alpha=0.2,color='#CCCCCC')\n\n\n# assign \u2018price\u2019 variable to represent coordinates on graph\nmy_cmap = ListedColormap(sns.color_palette(['#FFF5F0' ,'#FCBBA1' ,'#FB6A4A' ,'#CB181D' ,'#67000D']).as_hex())\ngeo_df.plot(column='price',ax=ax,   legend=True,   cmap=my_cmap , edgecolor='#EAEAF2' )\n\n# add title to graph\nplt.title('House Prices in  King County, USA', fontsize=15,fontweight='bold' )\n\n# set latitiude and longitude boundaries for map display\nplt.xlim(-122.6 ,-121.06)\nplt.ylim( 47.06 ,47.8 )\n\n# show map\nplt.show()","52ddcd4b":"#add heatmao scall to map \n\nmymap = folium.Map(location= [47.56 , -122.22], zoom_start =9) \n\n# Get the highest average house price\nmaxave = int(data.groupby(['zipcode']).mean()['price'].max())\nprint(\"Highest City House Price is: \", maxave)\n\n# Create a color map to match house prices. White - low price, Black - high price\ncolormap = ['#00009B' ,'#0099FF' ,'#63FF9B' ,'#FFFB00' ,'#FF2F00' , '#8B0000']\n\n# Add marker info \n\nfor index, row in data.groupby('zipcode').agg({'lat': 'mean','long': 'mean', 'price':'mean', 'zipcode':'count' }).iterrows(): \n    # Set icon color based on price \n    theCol = colormap[ int((len(colormap) - 1 ) *  float( row['price']) \/ maxave) ]\n    markerText =  ( 'Average price : ' + str(round(row['price'], 2) ) +' $' + '\\n' + 'Houses sold : ' + str(row['zipcode']) )\n    folium.CircleMarker( radius=(row['zipcode'])\/15, location=[row['lat'],row['long']], popup=folium.Popup(markerText,max_width=150,min_width=150), color= theCol,fill=True,fill_color=theCol,  ).add_to(mymap)\n\nFloatImage('https:\/\/lh3.googleusercontent.com\/proxy\/SRXTqZngcyOscx1nR1iB9c4IobPtOn0cEROsZ_wK6CO3nfAjD4e4TDXPDjN3AU2ZLJxzJQaoLJnlqk9zZevN7S2wZZctQysIIKOvigpGatc', bottom=0, left=65).add_to(mymap)\nmymap","e2003e9b":"### Which area have the most expensive houses on sale. And the number of sales.","c14530c0":"### house sales by zip code on the map","60a173e3":"## Intro\n","d52ed5d2":"###  Univariate Analysis","829d748a":"### Checking for missing values","71ae39e8":"### Columns Descriptions\n* **date**- Date of the home sale.\n* **price** - House sale price.\n* **bedrooms** - Number of bedrooms.\n* **bathrooms** - Number of bathrooms. (.5 accounts for a room with a toilet but no shower).\n* **sqft_living** - Square footage of the apartments interior living space.\n* **sqft_lot** - Square footage of the land space.\n* **floors** - Number of floors.\n* **waterfront** - Whether the apartment overlooking the seafront or not.\n* **view** -  0 to 4 index of how good the view of the property is.\n* **condition** - 1 to 5 index of the condition of the apartment.\n* **grade** - 1 to 13 index of the level of construction and design.\n* **sqft_above** - The area in square feet of the interior space above ground level .\n* **sqft_basement** - The area in square feet of the interior space below ground level.\n* **yr_built** - The year of construction of the house.\n* **yr_renovated** - The year of the house\u2019s last renovation.\n* **zipcode** - the zipcode area in which the house is located.\n* **lat** - Lattitude.\n* **long** - Longitude.\n* **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbors.\n* **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbors.\n.","0199ee38":"### Correlation Matrix","ea8dd7ec":"## Reading & Understanding the Data \n","9bbcc9f8":"## Distribution Maps","0788aadb":"I'm new to data science and this is my first project on kaggle. Looking forward for all types of feedback, advice, comments ...","3237a92e":"**bathrooms**, **sqft_living**, **grade**, **sqft_above**, **sqft_living15**, have more than 0.5 correlation with **price**.\n","52dc3b47":"### Removing outliers ","1ebc9813":"###  Importing Libraries","2e666e89":"### Distribution of Data","a7e26e32":"## Import and preparation of data","72c686c9":"Apparently we have no missing values. Yay, me.","a353cc45":"When I applied the first method to exclude outliers, many fields were lost e.g : yr_renovated and view. Due to the extreme skewness of the data distribution. Therefore, I had to target a specific field to exclude the outliers of, Using the second method.","eef20742":"### plotting the relation between price and space","5f213148":"## Associations and Correlations between Variables","439d8470":"### Main statistics of each parameters","ae3679f0":"## Data visualization","e882c294":"## Descriptive statistics","b2e7a1af":"###  Bivariate Analysis","151b9df6":"## Cleaning the data "}}