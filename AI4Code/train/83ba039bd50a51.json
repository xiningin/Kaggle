{"cell_type":{"43894ccf":"code","d9e7e801":"code","f139dd68":"code","65dd8ffe":"code","f8ff89af":"code","4832e454":"code","c212f6b6":"code","c97f410a":"code","6a776441":"code","43cbba4e":"code","646bbba6":"code","a22d746b":"code","7443decc":"code","8a4e71d1":"code","a05bfe2d":"code","35119ce5":"code","1eb5bbb0":"code","1b01f524":"code","ef3b69ed":"code","ed424164":"code","c484b238":"code","3bd74ede":"code","423af0ce":"code","0e617554":"code","f6e83e6f":"code","81ba867f":"code","eae3fbd7":"code","caf73dd5":"code","c512ef4d":"code","bae83d15":"code","59d2ef98":"markdown","da9333e0":"markdown","7d6b2c64":"markdown","c119f715":"markdown","00c577fa":"markdown","0132db71":"markdown","253ca8ef":"markdown"},"source":{"43894ccf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9e7e801":"# linear algebra\nimport numpy as np\n\n# data processing\nimport pandas as pd\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# neural network\nimport tensorflow as tf\n\n# data preprocessing\nfrom sklearn.model_selection import train_test_split","f139dd68":"# Importing the training and testing datasets\ntraining = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntesting = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","65dd8ffe":"training.shape","f8ff89af":"training.head()","4832e454":"# Number of instances of each number\nplt.figure(figsize = (12,6))\n\ngraph = sns.countplot(training['label'], palette = 'OrRd')\nfor p in graph.patches:\n  graph.annotate(s = p.get_height(), \n                 xy = (p.get_x() + p.get_width()\/2, p.get_height()),\n                 xytext = (0,5),\n                 textcoords=\"offset points\",\n                 ha = 'center',\n                 va = 'center')","c212f6b6":"# Viewing randomly selected numbers and their labels\nwidth = 15\nlength = 15\n\nplt.figure(figsize=(20,30))\nfor i in range(length * width):\n  plt.subplot(length, width, i+1)\n  index = np.random.randint(0, len(training))\n  plt.gca().set_title(training.iloc[index, 0], fontsize = 15)\n  plt.imshow(training.iloc[index, 1:].values.reshape(28, 28))\n  plt.axis('off')","c97f410a":"# Separating the label and the pixel matrix\nX = training.drop(columns = 'label').values\ny = training['label'].values","6a776441":"# Rescaling and reshaping the pixel matrix\nX = X\/255\nX = X.reshape(X.shape[0], *(28, 28, 1))\nprint(X.shape)","43cbba4e":"# Rescaling and reshaping the testing data\ntesting = testing.values\ntesting = testing\/255\ntesting = testing.reshape(testing.shape[0], *(28, 28, 1))","646bbba6":"# Splitting the training data into validation and training sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)","a22d746b":"cnn = tf.keras.models.Sequential()","7443decc":"cnn.add(layer = tf.keras.layers.Conv2D(input_shape = (28, 28, 1),\n                                       filters=64,\n                                       kernel_size = (3,3), \n                                       activation = 'relu'))","8a4e71d1":"cnn.add(layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides = 2))","a05bfe2d":"cnn.add(layer = tf.keras.layers.Conv2D(filters=64,\n                                       kernel_size = (3,3), \n                                       activation = 'relu'))","35119ce5":"cnn.add(layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides = 2))","1eb5bbb0":"cnn.add(layer = tf.keras.layers.Flatten())","1b01f524":"cnn.add(layer = tf.keras.layers.Dropout(0.5))","ef3b69ed":"cnn.add(layer = tf.keras.layers.Dense(units = 108, activation='relu'))","ed424164":"cnn.add(layer = tf.keras.layers.Dropout(0.5))","c484b238":"cnn.add(layer = tf.keras.layers.Dense(units = 108, activation='relu'))","3bd74ede":"cnn.add(layer = tf.keras.layers.Dense(units = 10, activation = 'softmax'))","423af0ce":"cnn.compile(optimizer = 'adam',\n             loss = 'sparse_categorical_crossentropy',\n             metrics = ['accuracy'])","0e617554":"model_train = cnn.fit(x = X_train, y = y_train, validation_data = (X_val, y_val), epochs = 25)","f6e83e6f":"# Observing the changes in the validation and training loss\nplt.plot(list(range(1, 26)), model_train.history['loss'], 'y', label='Training Loss')\nplt.plot(list(range(1, 26)), model_train.history['val_loss'], 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","81ba867f":"# Observing the changes in the validation and training accuracy\nplt.plot(list(range(1, 26)), model_train.history['accuracy'], 'y', label='Training Accuracy')\nplt.plot(list(range(1, 26)), model_train.history['val_accuracy'], 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","eae3fbd7":"# Predicting the labels of the testing set\ny_pred = np.argmax(cnn.predict(testing), axis = -1)","caf73dd5":"y_pred","c512ef4d":"predictions = pd.DataFrame({\"ImageId\" : list(range(1, len(y_pred)+1)),\n                             \"Label\" : y_pred})","bae83d15":"# Saving the predicted results in a csv file\npredictions.to_csv('predictions.csv', index = False)","59d2ef98":"# Importing Libraries","da9333e0":"# Training the CNN Model","7d6b2c64":"# Data Preprocessing","c119f715":"# Importing Dataset","00c577fa":"# Data Visualisation","0132db71":"# Predicting Test Set Results","253ca8ef":"# Building the CNN"}}