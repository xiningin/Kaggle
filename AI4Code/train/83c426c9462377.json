{"cell_type":{"5f2fc72a":"code","25ab2564":"code","b5b02993":"code","cef12bbd":"code","2bf04a75":"code","d7c6c3cf":"code","8cd5eea4":"code","83bf0177":"markdown"},"source":{"5f2fc72a":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport random\nimport os \nfrom sklearn import metrics, model_selection\nfrom sklearn import preprocessing\nimport time\nimport gc\nfrom tqdm.notebook import tqdm\nimport joblib\nimport lightgbm as lgb\nimport seaborn as sns","25ab2564":"gc.enable()\n\nNUM_FOLDS = 5\nSEED = 541","b5b02993":"train_df_preds = pd.concat([pd.read_csv('..\/input\/pretrained-feature-model-keras\/train_preds.csv'), pd.read_csv('..\/input\/pretrained-feature-model-keras\/valid_preds.csv')]).reset_index(drop=True)\ntrain_df_preds.head()","cef12bbd":"test_df_preds = pd.read_csv('..\/input\/pretrained-feature-model-keras\/submission.csv')\ntest_df_preds.head()","2bf04a75":"def create_folds(data):\n    data[\"kfold\"] = -1\n    data = data.sample(frac=1, random_state=SEED).reset_index(drop=True)\n\n\n    kf = model_selection.KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n    for f, (t_, v_) in enumerate(kf.split(X=data)):\n        data.loc[v_, 'kfold'] = f  \n    \n    return data\n\ntest_df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ntest_df = pd.concat([test_df, test_df_preds], axis=1)\n\ntrain_df = train_df_preds.copy()\ntrain_df.drop(['Id', 'path'], axis=1, inplace=True)\n\ntest_df.drop(['Id'], axis=1, inplace=True)\ntest_df.rename(columns={'Pawpularity':'preds'}, inplace=True)\n\ncat_cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n\nfor col in cat_cols:\n    train_df[col] = train_df[col].astype('category')\n    test_df[col] = test_df[col].astype('category')\n    \n    \ntrain_data = create_folds(train_df)","d7c6c3cf":"scores = []\n\ntest_probs = pd.DataFrame()\ntrain_probs = pd.DataFrame()\n\nfor fold in range(NUM_FOLDS):\n    train = train_data[train_data['kfold'] != fold].reset_index(drop=True)\n    val = train_data[train_data['kfold'] == fold].reset_index(drop=True)\n    \n    xtrain = train.drop(['Pawpularity', 'kfold'], axis=1)\n    xval = val.drop(['Pawpularity', 'kfold'], axis=1)\n    \n    model = lgb.LGBMRegressor(n_jobs=-1)\n    model.fit(xtrain, train.Pawpularity.values)\n    \n    save_to = 'lgb_fold{}.txt'.format(fold)\n    model.booster_.save_model(save_to)\n    \n    predictions = model.predict(xval)\n    train_probs[f'fold_{fold}'] = model.predict(train_data.drop(['Pawpularity','kfold'], axis=1))\n    test_probs[f'fold_{fold}'] = model.predict(test_df)\n\n    score = metrics.mean_squared_error(val.Pawpularity.values, predictions, squared=False)\n    print(f\"Fold: {fold}, Score: {score}\")\n    scores.append(score)\n    \n    \n    lgb.plot_importance(model)\n    plt.title(f\"Feature importance fold: {fold}\")\n    plt.show()\n    \nprint(f\"CV: {np.mean(scores)}\")","8cd5eea4":"ss = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\nss['Pawpularity'] = test_probs.mean(axis=1)\nss[['Id','Pawpularity']].to_csv('submission.csv', index=False)","83bf0177":"## A very naive experiment\n\nI was thinking what if instead of getting image embeddings what if I can just get the final output and combine it with the other attributes present here using a LGBR.\n\nLong version:\n\n1. I passed the images through a pretrained feature extractor (EffficientNet B7)\n2. I got the final output and submitted one entry. LB (18.86)\n3. I combined the output from Step 2 with the other metadata and modelled using a very naive LGB regressor.\n4. On CV I got 17.33 but LB is much worse than Step 2 (18.98)\n5. I want to know if this naive experiment is structered incorrectly.\n\n"}}