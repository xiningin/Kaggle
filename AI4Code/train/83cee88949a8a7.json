{"cell_type":{"3c675e7f":"code","f4b5d0a2":"code","f6af7658":"code","28dcdc18":"code","1e3fb9fe":"code","d67b6617":"code","88ae08ef":"code","082c90a3":"code","953a67ba":"code","af7e71aa":"code","ecb75b51":"code","86166b21":"code","f9a485bf":"code","3fa64411":"code","e465ceae":"code","1964cd35":"code","1d284a90":"code","8f015873":"code","20f1f9e5":"code","a7df0c47":"code","95c566f6":"code","f826de39":"markdown","6c90149e":"markdown","339c4b27":"markdown","5c8d6688":"markdown","9ff8059f":"markdown","af1e7b1f":"markdown","16adb68a":"markdown","2d5f0d01":"markdown","f63576a0":"markdown","1d61cd2a":"markdown"},"source":{"3c675e7f":"\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","f4b5d0a2":"df_main = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\ndf_main.describe(include='all')\n","f6af7658":"print(df_main.columns)","28dcdc18":"df_main.head()","1e3fb9fe":"df_main.tail()","d67b6617":"df_main.Survived.value_counts(normalize=True).plot(kind='bar',alpha=0.5)\nplt.title('1: Survived  0:not Survived')\nplt.show()","88ae08ef":"\nfig=plt.figure(figsize=(18,6))\nplt.subplot2grid((3,4),(0,0))\ndf_main.Survived[df_main.Sex=='male'].value_counts(normalize=True).plot(kind='bar',alpha=0.5)\nplt.title(\"men Survived\")\n\nplt.subplot2grid((3,4),(0,1))\ndf_main.Survived[df_main.Sex =='female'].value_counts(normalize=True).plot(kind='bar',alpha=0.5,color='red')\nplt.title(\"Women Survived\")\nplt.show()\n","082c90a3":"\nfig=plt.figure(figsize=(18,6))\nplt.subplot2grid((4,4),(0,0))\ndf_main.Survived[(df_main.Sex=='male') & (df_main.Pclass==1)].value_counts(normalize=True).plot(kind='bar',alpha=0.5)\nplt.title(\"poor men Survived\")\n\nplt.subplot2grid((4,4),(0,1))\ndf_main.Survived[(df_main.Sex =='male') & (df_main.Pclass==3)].value_counts(normalize=True).plot(kind='bar',alpha=0.5)\nplt.title(\"rich men Survived\")\n\n\nplt.subplot2grid((4,4),(2,0))\ndf_main.Survived[(df_main.Sex=='female') & (df_main.Pclass==1)].value_counts(normalize=True).plot(kind='bar',alpha=0.8,color='red')\nplt.title(\"poor women Survived\")\n\nplt.subplot2grid((4,4),(2,1))\ndf_main.Survived[(df_main.Sex =='female') & (df_main.Pclass==3)].value_counts(normalize=True).plot(kind='bar',alpha=0.8,color='red')\nplt.title(\"rich women Survived\")\nplt.show()","953a67ba":"y=df_main[['Survived']]\ndf_main=df_main.drop(['PassengerId', 'Name','Ticket','Cabin','Survived'], axis=1)\nx=df_main.values","af7e71aa":"imp_mean = SimpleImputer( strategy='most_frequent')\nimp_mean.fit(x)\nx = imp_mean.transform(x)","ecb75b51":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nx[:,1]=le.fit_transform(x[:,1])\nle2=LabelEncoder()\nx[:,-1]=le2.fit_transform(x[:,-1])","86166b21":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct=ColumnTransformer([('one_hot_encoder',OneHotEncoder(categories='auto'),[1])],remainder='passthrough')\nx=ct.fit_transform(x)\nx=x[:,:-1]","f9a485bf":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=0)","3fa64411":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","e465ceae":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=4,metric='minkowski')\nknn.fit(x_train,y_train)\ny_pred=knn.predict(x_test)\nprint('KNN')\ncm=confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_gaussian = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(\"accuracy score is \",acc_gaussian)","1964cd35":"# Decision tree\nfrom sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\ny_pred=dt.predict(x_test)\nprint('Decision Tree')\ncm2=confusion_matrix(y_test,y_pred)\nprint(cm2)\nacc_gaussian = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(\"accuracy score is \",acc_gaussian)","1d284a90":"# gaussianNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\ngnb=GaussianNB()\ngnb.fit(x_train,y_train)\ny_pred=gnb.predict(x_test)\ncm2=confusion_matrix(y_test,y_pred)\nprint(cm2)\nacc_gaussian = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(\"accuracy score is \",acc_gaussian)","8f015873":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlr=LogisticRegression()\nlr.fit(x_train,y_train)\ny_pred=lr.predict(x_test)\ncm=confusion_matrix(y_test,y_pred)\nprint(cm)\nacc_lr=round(accuracy_score(y_pred,y_test)*100,2)\nprint(\"accuracy score is \",acc_lr)","20f1f9e5":"#support vector machine\nfrom sklearn.svm import SVC\nsvc=SVC()\nsvc.fit(x_train,y_train)\ny_pred=svc.predict(x_test)\ncm=confusion_matrix(y_test,y_pred)\nprint(cm)\nacc_svc=round(accuracy_score(y_pred,y_test)*100,2)\nprint(\"accuarcy score is\",acc_svc)","a7df0c47":"classifier=Sequential()\n\nclassifier.add(Dense(6,activation='relu',kernel_initializer=\"uniform\",input_dim=7))\n\nclassifier.add(Dense(6,activation='relu',kernel_initializer=\"uniform\"))\n\nclassifier.add(Dense(1,activation='sigmoid',kernel_initializer=\"uniform\"))\n\nclassifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n\nclassifier.fit(x_train,y_train,epochs=100)\ny_pred=classifier.predict(x_test)\n","95c566f6":"y_pred=(y_pred>0.5)\ncm=confusion_matrix(y_test,y_pred)\nprint(cm)\nacc_Neural=round(accuracy_score(y_pred,y_test)*100,2)\nprint(\"accuarcy score is\",acc_Neural)","f826de39":"# 3) Data Analysis","6c90149e":"# Missing Values","339c4b27":"**Decision Tree Classifier**","5c8d6688":"# 4) Data Visualization","9ff8059f":"# Now Let's try to something else and create an artificial neural network and see the result","af1e7b1f":"\n\n# Data Preprocessing\nlet's drop unnecessary columns for training from our data\n","16adb68a":"# 2)Read in and Explore Data\nit's time to read our training data,and take look at the training data using the describe() function.\n","2d5f0d01":"# 1) Import Necessary Libraries","f63576a0":"# 5) choosing the best model","1d61cd2a":"**Pclass Feature**"}}