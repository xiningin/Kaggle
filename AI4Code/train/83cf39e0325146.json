{"cell_type":{"b822970a":"code","6c1d0c90":"code","eccf874c":"code","8278cb70":"code","0db1e31c":"code","989bfbc1":"code","42b5e00f":"code","cc152de4":"code","3a3b322f":"code","2a561062":"code","084ca281":"code","cf36beff":"code","db5bb872":"code","7021014c":"code","283cf8ee":"code","46ab087a":"code","fced7f85":"code","48055bc3":"markdown","80defe3e":"markdown","8acb36a5":"markdown","0b93b3d5":"markdown","4428c1e0":"markdown","66817d4a":"markdown","557fd082":"markdown","99ad01cb":"markdown","a074ed3a":"markdown","6c4b5620":"markdown"},"source":{"b822970a":"import torch.nn as  nn\nimport torch.nn.functional as F","6c1d0c90":"import torchvision.datasets as datasets\nimport torchvision.transforms as transforms","eccf874c":"import torch","8278cb70":"from torch.utils.data import DataLoader","0db1e31c":"import torch.optim as optim","989bfbc1":"class SimpleNN(nn.Module):\n    def __init__(self, input_size, classes):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_size, 50)\n        self.fc2 = nn.Linear(50, classes)\n    \n    def forward(self,x):\n        out = F.relu(self.fc1(x))\n        out = self.fc2(out)\n        return out\n        ","42b5e00f":"# testing\nmodel = SimpleNN(784, 10)\ninput_tensor = torch.randn(64, 784)\nout_tensor = model(input_tensor)\nout_tensor.shape","cc152de4":"device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","3a3b322f":"input_size = 784\nclasses = 10\nlearning_rate = 0.001\nbatch_size=64\nnum_epochs=100","2a561062":"train_dataset = datasets.MNIST(root='dataset\/', download=True, train=True, transform=transforms.ToTensor())","084ca281":"train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)","cf36beff":"test_dataset = datasets.MNIST(root='dataset\/', download=True, train=False, transform=transforms.ToTensor())\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","db5bb872":"simple_model = SimpleNN(input_size,classes)","7021014c":"loss_criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)","283cf8ee":"for epoch in range(num_epochs):\n    current_loss  = 0\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # reshape the data\n        data = data.reshape(data.shape[0], -1)\n        \n        # calculate score and loss forward pass\n        scores = model(data)\n        loss = loss_criterion(scores, target)\n        current_loss = loss\n        \n        # update weights backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # optimzer step\n        optimizer.step()\n    print(f\"current epoch : {epoch} loss: {current_loss}\")","46ab087a":"def check_accuracy(model, loader):\n    model.eval()\n    num_samples = 0\n    num_correct = 0\n    \n    with torch.no_grad():\n        for x,y in loader:\n            x = x.reshape(x.shape[0],-1)\n            score = model(x)\n            print(score)\n            _,predictions = score.max(1)\n            print(predictions, y)\n            \n            num_samples += predictions.size(0)\n            num_correct += (y==predictions).sum()\n            break\n            \n    print(f\" total samples = {num_samples} , total correct = {num_correct}, percentage = {float(num_correct)\/float(num_samples)*100:.2f}%\")","fced7f85":"check_accuracy(simple_model, train_loader)\ncheck_accuracy(simple_model, test_loader)","48055bc3":"### Calculating the accuracy","80defe3e":"### Initialising the model","8acb36a5":"### Setting the device","0b93b3d5":"# Learning Pytorch\n\nThis series would be taken from various tutorial available in youtube.\n\n## 1 : Creating a simple network\n\nThis one is taken from excellent channel Alladin Perrson : https:\/\/www.youtube.com\/watch?v=Jy4wM2X21u0&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=3\n\n![](https:\/\/i.morioh.com\/200620\/5b0ea047.jpg)","4428c1e0":"### Creating a fully connected network","66817d4a":"### Loss and optimiser","557fd082":"### Setting up hyperparameters","99ad01cb":"The model seems to be very biased towards 7. I wonder why.","a074ed3a":"### Training the model","6c4b5620":"### Imports"}}