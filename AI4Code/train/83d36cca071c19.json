{"cell_type":{"ffca429f":"code","db9e1d59":"code","de695b2d":"code","1bdb778c":"code","86af99a2":"code","bebcf544":"code","e2fbc583":"code","1b41f605":"code","67e47dd6":"code","9c0a9009":"code","5fe05a86":"code","f1b3ef98":"code","42adad88":"code","b6e3c200":"code","6f52aad3":"code","2a485d66":"code","c14c3a86":"markdown","78c8c3d5":"markdown","d62eccf7":"markdown","dff55dd6":"markdown","d8e18518":"markdown","f7fe689c":"markdown","ff872334":"markdown","69858878":"markdown","cd32b5e0":"markdown","a23d9a13":"markdown","9ffb7481":"markdown","93c94e6c":"markdown","7f27ed65":"markdown","d3b27656":"markdown","4d11be7a":"markdown","ed11c34d":"markdown","d090a050":"markdown","6b9a76fd":"markdown","9699a84e":"markdown","b4377ab7":"markdown"},"source":{"ffca429f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","db9e1d59":"#Impoting Datasets\ndataset = pd.read_csv(\"..\/input\/Mall_Customers.csv\")","de695b2d":"dataset.head()","1bdb778c":"dataset.Genre.value_counts()","86af99a2":"print(dataset.dtypes)","bebcf544":"# Summary of Object Variables\ndataset.describe(include=[np.object])","e2fbc583":"\nplt.figure(figsize = (15,5))\nnames  = dataset['Genre'].value_counts()[:2].index\nvalues  = dataset['Genre'].value_counts()[:2].values\ncolors = ['cyan','yellowgreen']\n#explode = []\n\nplt.pie(values, labels = names , colors=colors ,startangle=90,shadow=True,autopct='%1.2f%%')\nplt.axis('equal')\nplt.show()","1b41f605":"import seaborn as sb\nsb.pairplot(dataset, hue='Spending Score (1-100)')","67e47dd6":"sb.pairplot(dataset, hue='Genre')","9c0a9009":"dataset.isnull().sum()","5fe05a86":"x = dataset.iloc[:,[3,4]].values\n\n# Using dendograms to find optimal numbers of clusters\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(x, method = 'ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidian Distance')\nplt.show()","f1b3ef98":"from sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\n\ny_hc = hc.fit_predict(x)","42adad88":"plt.scatter(x[y_hc == 0,0], x[y_hc == 0,1], s = 50, c = '#F72E6E', label = 'cluster 1')\nplt.scatter(x[y_hc == 1,0], x[y_hc == 1,1], s = 50, c = '#60F6C2', label = 'cluster 2')\nplt.scatter(x[y_hc == 2,0], x[y_hc == 2,1], s = 50, c = '#00FF3E', label = 'cluster 3')\nplt.scatter(x[y_hc == 3,0], x[y_hc == 3,1], s = 50, c = '#B11EF5', label = 'cluster 4')\nplt.scatter(x[y_hc == 4,0], x[y_hc == 4,1], s = 50, c = '#271276', label = 'cluster 5')\nplt.title('Clusters of Customers Hierarchical')\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.legend()\nplt.show()","b6e3c200":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i , init='k-means++',random_state=0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","6f52aad3":"kmeans = KMeans(n_clusters=5 , init='k-means++',random_state=0)\ny_kmeans = kmeans.fit_predict(x)","2a485d66":"plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(x[y_kmeans == 3, 0], x[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(x[y_kmeans == 4, 0], x[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 250, c = 'grey', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","c14c3a86":" >Here we look for branches that has long vertical distance. Although here branches with longest vertical distane are three with green and two with blue, total of 5. So the best numbers of clusters we found from dendograms are 5.","78c8c3d5":"## Fitting K-Means to the dataset","d62eccf7":"## Interpretation from visualization","dff55dd6":"## Fitting Hierarchical Clustering to the datasets","d8e18518":"## Plotting to get optimum numbers of clusters to segmentise data","f7fe689c":"\u2022 The optimum numbers of clusters that we found in this case is 5.\n\u2022 Five clusters can be defined as follows:\n\n        1. Cluster 1 has people with high annual income but their spending score is less. So mall employees should \n           bring some kind of advertisement and should develope interest in spending.\n           \n        2. Cluster 2 has people with moderate income and their spending score also lie in the middle. To have these \n           people in cluster 3 mall employees should display some offers so then they can spend more money.\n           \n        3. Cluster 3 people are the great imcome source of the total revenue. So we don't have to work on them.\n        \n        4. Cluster 4 has individuals who are buying more stuff than their earnings. For while we leave these \n           group of prople.\n           \n        5. Cluster 5 includes people which are earning less and they spend less as well. I don't know as such how \n           how to deal with these group but the mall expertise will have some solutions.","ff872334":"# **Clustering approach for Mall Customers**","69858878":"> Checking the content of dataset","cd32b5e0":"## Plotting to get exact numbers of clusters using L-Bow method","a23d9a13":">Visualizing the clusters","9ffb7481":">Importing the libraries required","93c94e6c":">Reading the datasets","7f27ed65":"![](https:\/\/data-flair.training\/blogs\/wp-content\/uploads\/sites\/2\/2019\/07\/R-project-customer-segmentation.png)","d3b27656":">Importing Libraries required for H.C.","4d11be7a":"> There are more numbers of females customers than male.  ","ed11c34d":">  Visualising the clusters","d090a050":"## Gender wise contribution to shoppings in mall","6b9a76fd":">Results","9699a84e":"> So here the change in slope of line after 5 numbers of cluster is not having much change in the WCS. Hence the optimum numbers of clusters that we choose are 5.","b4377ab7":"## Checking for missing values"}}