{"cell_type":{"e76d4161":"code","4821d91c":"code","cbfed944":"code","56d3403b":"code","2768b1bb":"code","e1fb2699":"code","a3880614":"code","d796f2c7":"code","67a9910f":"code","be07d102":"code","f0f16db3":"code","9cc03746":"code","85ffd018":"code","be66e57c":"code","c10400cc":"code","0374f579":"code","7c1c35be":"code","1dd9c32d":"code","d367e445":"code","015d39be":"code","bbdb6f8c":"code","de938c37":"code","9f6d470c":"code","31b1194e":"code","57aa0b7b":"code","5a4044a5":"code","5158f911":"code","c9a65092":"code","d403ea14":"code","03f22d13":"code","71e2f9ef":"code","3a63e052":"code","4b61588e":"code","e7ea329e":"code","bdd042ff":"code","2ae918a1":"code","1b740fc0":"code","7a789beb":"code","38bfdcb4":"code","0b223acf":"code","5298f5aa":"code","2435c229":"code","2c2201d0":"code","911f797f":"code","ba4c11c7":"code","40056571":"code","18fdf05b":"code","eba13299":"code","67a44cc7":"code","65dfab76":"code","f75c6245":"code","88c40404":"code","26758b70":"code","216099d1":"code","96ec6b80":"code","b58ec402":"code","d82261c7":"code","aa0e1d6b":"code","07f9100f":"code","9d4d8f0d":"code","e04dc69c":"code","2b40955a":"code","8ce6457b":"code","4b6c0d5c":"code","24468f60":"code","6a2f1c9c":"code","a8270e85":"code","a31f6ea0":"code","7be798f0":"code","d39281bd":"code","82e2b804":"code","54e09273":"code","7491ee5b":"code","60806ce0":"code","bb2ad5ee":"code","50c19b9f":"code","ddbc9a85":"code","45d6864b":"code","32b471ff":"code","ac609d78":"code","5728b44b":"code","b3c93485":"code","e6a1195e":"code","d987b047":"code","6e065c90":"code","af948208":"code","e72949ad":"code","966ef629":"code","beaf7494":"code","eba3f045":"code","bb0e8974":"code","4b63e8bd":"code","660f11bc":"code","0605bb9e":"code","a66a5b03":"code","f91f3827":"code","0c224ec3":"code","904001c5":"markdown","73458629":"markdown","842b9368":"markdown","5d8afe94":"markdown","eeb04f2b":"markdown","50bad0ca":"markdown","74a8c284":"markdown","2659196e":"markdown","6fd551c2":"markdown","bf231308":"markdown","8aca3326":"markdown","bd89a65e":"markdown","9a7e9678":"markdown","1c0b838d":"markdown","a346a728":"markdown","98d56a8c":"markdown","02302254":"markdown","d80dfd56":"markdown","a4018fa9":"markdown","d50b00c0":"markdown","88b2395f":"markdown","e57292ad":"markdown","41688385":"markdown","5866e883":"markdown","7dbe8c91":"markdown","61ec1e48":"markdown","bc2ca80a":"markdown","3ecbaed1":"markdown","4430515e":"markdown","d965a602":"markdown","b037ef7b":"markdown","8073ded8":"markdown","57e2f04c":"markdown","21335930":"markdown","e4af8830":"markdown","9ab0bf98":"markdown"},"source":{"e76d4161":"from IPython.display import Image\nimport os\n!ls ..\/input\/","4821d91c":"import numpy as np\nimport pandas as pd\n# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore') ","cbfed944":"car = pd.read_csv(\"..\/input\/header\/CarPrice_Assignment.csv\")","56d3403b":"# Check the head of the dataset\ncar.head()","2768b1bb":"car.shape","e1fb2699":"car.info()","a3880614":"car.describe()","d796f2c7":" # we  need to consider only company name as the independent variable for model building. ","67a9910f":"#Splitting company name from CarName column\nCompanyName = car['CarName'].apply(lambda x : x.split(' ')[0])\ncar.insert(3, \"CompanyName\", CompanyName)\ncar.drop(\"CarName\", axis = 1, inplace = True)\ncar.head()","be07d102":"\ncar.CompanyName.unique()","f0f16db3":"# Correcting Invalid values(Spelling Errors)\n\ncar.CompanyName = car.CompanyName.str.lower()\n\ndef replace_name(a,b):\n    car.CompanyName.replace(a, b, inplace = True)\n    \n\nreplace_name('maxda','mazda')\nreplace_name('porcshce','porsche')\nreplace_name('toyouta','toyota')\nreplace_name('vokswagen','volkswagen')\nreplace_name('vw','volkswagen')\n\ncar.CompanyName.unique()","9cc03746":"\n#Checking for duplicates\ncar.loc[car.duplicated()]","85ffd018":"pd.set_option('display.max_columns',500)","be66e57c":"car.head()","c10400cc":"car['CompanyName'].value_counts()","0374f579":"import matplotlib.pyplot as plt\nimport seaborn as sns","7c1c35be":"#Visualising Price vs variuos parameters\n\ndef scatter (x,fig):\n    plt.subplot(5,2,fig)\n    plt.scatter(car[x],car['price'])\n    plt.title(x+' vs Price')\n    plt.ylabel('Price')\n    plt.xlabel(x)\n\n\nplt.figure(figsize=(10,20))\n\nscatter('carlength', 1)\nscatter('carwidth', 2)\nscatter('carheight', 3)\nscatter('curbweight', 4)\n\nplt.tight_layout()\n    ","1dd9c32d":"#Deduction::\n\n#carheight doesn't show any significant correlation with price.\n\n#width, length and weight seems to have a poitive correlation with price as can be easily inferred by above.\n","d367e445":"np.corrcoef(car['carlength'], car['carwidth'])[0,1]","015d39be":"#visualising Price vs few more important variables\n\ndef pairplot(x,y,z):\n    sns.pairplot(car, x_vars = [x,y,z], y_vars = ['price'], size = 4, aspect = 1, kind='scatter')\n    plt.show()\n    \npairplot('compressionratio', 'horsepower', 'peakrpm')\npairplot('enginesize', 'boreratio', 'stroke')\npairplot('wheelbase', 'citympg', 'highwaympg')","bbdb6f8c":"#Deductions:\n\n#citympg, highwaympg have a negative correlation with price as can be easily inferred from above \n#however boreratio, enginesize, horsepower, wheelbase - seem to have a  positive correlation with price..","de938c37":"# visualising which numeric variables has good correlation with price  i.e which affects the price mostly.\nsns.pairplot(car)\nplt.show()","9f6d470c":"##width, length and weight seems to have a poitive correlation with price\n#citympg, highwaympg have a negative correlation with price as can be easily inferred from above \n#however boreratio, enginesize, horsepower, wheelbase - seem to have a  positive correlation with price\n#carheight doesn't show any significant correlation with price.\n","31b1194e":"#Binning all the Car Companies based on average price of each Company.\n\ncar['price'] = car['price'].astype('int')\ntemp = car.copy()\ncar1 = temp.groupby(['CompanyName'])['price'].mean()\ntemp = temp.merge(car1.reset_index(), how='left',on='CompanyName')\nbins = [0,10000,20000,40000]\ncar_bin=['Budget','Medium','Luxurious']\ncar['Range'] = pd.cut(temp['price_y'],bins,right=False,labels=car_bin)\ncar.head()\n","57aa0b7b":"# CompanyName\n# Symboling\n#fueltype\n#enginetype\n#carbody\n#doornumber\n#enginelocation\n#fuelsystem\n#cylindernumber\n#aspiration\n#drivewheel","5a4044a5":"plt.figure(figsize=(25, 6))\n\nplt.subplot(1,3,1)\nplt1 = car.fueltype.value_counts().plot('bar')\nplt.title('Fuel Type Histogram')\nplt1.set(xlabel = 'Fuel Type', ylabel='Fuel type Freq')\n\n\nplt.subplot(1,3,2)\nplt1 = car.carbody.value_counts().plot('bar')\nplt.title('Car Type Histogram')\nplt1.set(xlabel = 'Car Type', ylabel='car type Freq')\n\nplt.subplot(1,3,3)\nplt1 = car.CompanyName.value_counts().plot('bar')\nplt.title('Company Histogram')\nplt1.set(xlabel = 'Car company', ylabel='company freq')","5158f911":"plt.figure(figsize=(20,8))\nplt.subplot(1,2,1)\nplt.title('Symboling versus Price')\nsns.boxplot(x=car.symboling, y=car.price, palette=(\"cubehelix\"))\n\nplt.subplot(1,2,2)\nplt.title('Symboling Histogram')\nsns.countplot(car.symboling, palette=(\"cubehelix\"))\n\nplt.show()","c9a65092":"# Inferences::\n\n#symboling 0 &1 has maximum frequency\n# symboling -1,-2 has high price and thats justified since -1,-2 are good\n# also 3 has same price range as -2\n# There is a decrease at 1","d403ea14":"plt.figure(figsize=(25, 6))\ndf = pd.DataFrame(car.groupby(['fueltype'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Fuel Type versus Average Price')\nplt.show()","03f22d13":"#Deduction:\n# Diesel fueled has higher price than Gas fueled","71e2f9ef":"plt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'drivewheel', y = 'price', data = car)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'aspiration', y = 'price', data = car)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'cylindernumber', y = 'price', data = car)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'enginetype', y = 'price', data = car)\nplt.subplot(2,3,5)\nsns.boxplot(x = 'symboling', y = 'price', data = car)\nplt.subplot(2,3,6)\nsns.boxplot(x = 'fueltype', y = 'price', data = car)\nplt.show()","3a63e052":"# Deductions::\n#rwd has higher price than fwd and 4wd\n#aspiration turbo has higher price than std\n# 8-cylinder has highest price and 4-cylinder lowest\n# -1 & -2 synboling has higher prices that means auto is pretty safe and thats justified.\n# Engine type Ohcv has higher range then comes dohc and then i ","4b61588e":"plt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'carbody', y = 'price', data = car)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'doornumber', y = 'price', data = car)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'enginelocation', y = 'price', data = car)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'fuelsystem', y = 'price', data = car)\n","e7ea329e":"# Deductions::\n#hardtop has highest price range followed by convertible\n# 4-door has slightly has price than 2-doors\n# rear engine location has pretty higher price range as compared to front engine location\n# mpfi and idi fuel system has higher price range than others","bdd042ff":"plt.figure(figsize=(25, 6))\n\ndf = pd.DataFrame(car.groupby(['drivewheel','fuelsystem','Range'])['price'].mean().unstack(fill_value=0))\ndf.plot.bar()\nplt.title('Car Range versus Average Price')\nplt.show()","2ae918a1":"# see  General spread of car-price \n\nplt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Car-Price Distribution Plot')\nsns.distplot(car.price)\n\nplt.subplot(1,2,2)\nplt.title('Car-Price Spread')\nsns.boxplot(y=car.price)\n\nplt.show()","1b740fc0":"print(car.price.describe(percentiles = [0.25,0.50,0.75,0.85,0.90,1]))","7a789beb":"#Range,wheel base,Fuel type,Boreratio,Aspiration,Cylinder Number,Drivewheel,\n#Curbweight,Car width, Car length, Engine Size, carbody, Horse Power,Engine type \n","38bfdcb4":"cars_regression = car[['price', 'fueltype', 'aspiration','carbody', 'drivewheel','wheelbase',\n                  'curbweight', 'enginetype', 'cylindernumber', 'enginesize', 'boreratio','horsepower', 'carlength','carwidth', 'Range']]\ncars_regression.head()","0b223acf":"sns.pairplot(cars_regression)\nplt.show()","5298f5aa":"\n\n# Defining the map function for Dummy variables\n\ndef dummies(x,df):\n    temp = pd.get_dummies(df[x], drop_first = True)\n    df = pd.concat([df, temp], axis = 1)\n    df.drop([x], axis = 1, inplace = True)\n    return df\n\n# Applying the function to the car_Regression\n\ncars_regression = dummies('Range',cars_regression)\ncars_regression= dummies('carbody',cars_regression)\ncars_regression = dummies('aspiration',cars_regression)\ncars_regression = dummies('enginetype',cars_regression)\ncars_regression = dummies('drivewheel',cars_regression)\ncars_regression = dummies('cylindernumber',cars_regression)\ncars_regression = dummies('fueltype',cars_regression)\n\n","2435c229":"cars_regression.head()","2c2201d0":"cars_regression.shape","911f797f":"from sklearn.model_selection import train_test_split\n\n#We specify this so that the train and test data set always have the same rows, respectively\n\nnp.random.seed(0)\ndf_train, df_test = train_test_split(cars_regression, train_size = 0.7, test_size = 0.3, random_state = 100)","ba4c11c7":"df_train.shape","40056571":"df_test.shape","18fdf05b":"from sklearn.preprocessing import MinMaxScaler","eba13299":"scaler = MinMaxScaler()\nnum_vars = ['wheelbase', 'enginesize', 'curbweight', 'horsepower', 'boreratio','carwidth','carlength','price']\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","67a44cc7":"df_train.head()","65dfab76":"df_train.describe()","f75c6245":"#Plotting Heatmap to see the Correlation\nplt.figure(figsize = (30, 25))\nsns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","88c40404":"# dividing dataframe into x and y variables:\n\ny_train = df_train.pop('price')\n","26758b70":"x_train = df_train","216099d1":"y_train.shape","96ec6b80":"x_train.shape","b58ec402":"import statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","d82261c7":"lm = LinearRegression()\nlm.fit(x_train,y_train)\nrfe = RFE(lm, 10)\nrfe = rfe.fit(x_train, y_train)","aa0e1d6b":"list(zip(x_train.columns,rfe.support_,rfe.ranking_))","07f9100f":"x_train.columns[rfe.support_]","9d4d8f0d":"x_train_rfe = x_train[x_train.columns[rfe.support_]]\nx_train_rfe.head()","e04dc69c":"## Invoking Functions to Build Model and  to Check VIF\n\ndef build_model(X,y):\n    X = sm.add_constant(X) #to add constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X\n    \ndef checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","2b40955a":"x_train_new = build_model(x_train_rfe,y_train)","8ce6457b":"#Calculating the Variance Inflation Factor\ncheckVIF(x_train_new)","4b6c0d5c":"# dropping curbweight to to high VIF value (it has high multicolinearity)\nx_train_new = x_train_new.drop([\"curbweight\"], axis = 1)","24468f60":"x_train_new = build_model(x_train_new,y_train)","6a2f1c9c":"checkVIF(x_train_new)","a8270e85":"#dropping engine size due to its high p-value\nx_train_new = x_train_new.drop([\"enginesize\"], axis = 1)","a31f6ea0":"x_train_new = build_model(x_train_new,y_train)","7be798f0":"checkVIF(x_train_new)","d39281bd":"# dropping sedan becasue of its high VIF value\nx_train_new = x_train_new.drop([\"sedan\"], axis = 1)","82e2b804":"x_train_new = build_model(x_train_new,y_train)","54e09273":"checkVIF(x_train_new)","7491ee5b":"# dropping wagon due to high p-value as it becomes insignificant then.\n","60806ce0":"x_train_new = x_train_new.drop([\"wagon\"], axis = 1)","bb2ad5ee":"x_train_new = build_model(x_train_new,y_train)","50c19b9f":"checkVIF(x_train_new)","ddbc9a85":"# dropping dohcv and check stats","45d6864b":"x_train_new = x_train_new.drop([\"dohcv\"], axis = 1)","32b471ff":"x_train_new = build_model(x_train_new,y_train)","ac609d78":"#removing three because of high p-value\n\nx_train_new = x_train_new.drop([\"three\"], axis = 1)","5728b44b":"x_train_new = build_model(x_train_new,y_train)","b3c93485":"checkVIF(x_train_new)","e6a1195e":"\nlm = sm.OLS(y_train,x_train_new).fit()\ny_train_price = lm.predict(x_train_new)","d987b047":"# Plotting the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  \nplt.xlabel('Errors', fontsize = 18)\n\n","6e065c90":"#Scaling the test set\nnum_vars = ['wheelbase', 'curbweight', 'enginesize', 'boreratio', 'horsepower','carlength','carwidth','price']\ndf_test[num_vars] = scaler.fit_transform(df_test[num_vars])","af948208":"df_test.describe()","e72949ad":"#Dividing into X and y","966ef629":"y_test = df_test.pop('price')\n","beaf7494":"x_test = df_test","eba3f045":"# # Now let's use our model to make predictions.\n\nx_train_new = x_train_new.drop('const',axis=1)\n\n","bb0e8974":"# Creating X_test_new dataframe by dropping variables from X_test\nx_test_new = x_test[x_train_new.columns]","4b63e8bd":"# Adding a constant variable \nx_test_new = sm.add_constant(x_test_new)","660f11bc":"y_pred = lm.predict(x_test_new)","0605bb9e":"from sklearn.metrics import r2_score","a66a5b03":"r2_score(y_test, y_pred)\n","f91f3827":"#Let's now plot the graph for actual versus predicted values.\n\n\n\n# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_predict', fontsize=20)              # Plotting heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)   \n","0c224ec3":"print(lm.summary())","904001c5":"Model 4","73458629":"# Highly correlated variables to price are - highend , enginesize, horsepower,carwidth and curbweight.","842b9368":"# Bulding the Model","5d8afe94":"#Visualising Categorical Data","eeb04f2b":"p-values - p-values for all the coefficients are less than the significance level of 0.05. - that means all the predictors \nare statistically significant.\n \nR-sqaured and Adjusted R-squared (extent of fit) - 0.899 and 0.896 - 90% variance explained.\n \nF-stats and Prob(F-stats) (overall model fit) - 308 and 1.04e-67(approx. 0.0) - Model fir is significant and explained 90% variance is noy just by chance.\n","50bad0ca":"# Prediction and Evaluation","74a8c284":"# Data Cleaning and Preparation","2659196e":"# Data Preparation","6fd551c2":"Model 1","bf231308":"![](http:\/\/)","8aca3326":"# Useful Deductions","bd89a65e":"#useful observations from above plots\n\n# we have data points far more away spread from mean as can be seen in the box plot.\n# 85% of the prices are below 18,500, whereas the remaining 15% are between 18,500 and 45,400.) \n# Much difference between Mean and Median ","9a7e9678":"#High price ranged cars has rwd drivewheel with idi or mpfi fuelsystem.","1c0b838d":"# Deductions:\n\n#sedan is most preffered type.\n# Gas Fueled cars are much more than diesel fueled.\n# again same inference that \"Toyota\" is most favored car company.","a346a728":"# Model Evaluation","98d56a8c":"we can see VIF has been decreased for most of the variables automatically\n","02302254":"#Applying the scaling on the test sets","d80dfd56":"# Problem Statement\n\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts. \n\n \n\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n\nWhich variables are significant in predicting the price of a car\nHow well those variables describe the price of a car\n\nBased on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market. ","a4018fa9":"# Making Predictions","d50b00c0":"Model 5","88b2395f":"# As we can see Error terms are approximately normally distributed so our assumptions are satisfied.","e57292ad":"We can see that the equation of our best fitted line is:\n\nprice = .395 x carwidth + .279 x Luxurious + .44 x horsepower -.0414 x hatchback - .0824","41688385":"Visualising the numeric variables","5866e883":"Model 4","7dbe8c91":"# Step 1: Reading and Understanding the Data","61ec1e48":"Model 3","bc2ca80a":"# Feature scaling","3ecbaed1":"# Equation of best fit line::","4430515e":"Inspecting the various important aspects of the given dataframe","d965a602":"## we can see that Toyota is the top choice","b037ef7b":"Model 2","8073ded8":"# we can see there is almost 4 % difference between R-Square of Test and Train Set which means our Model is performing well.","57e2f04c":"# Splitting the Data into Training and Testing Sets","21335930":"##important and significant vaiables after visualisation##","e4af8830":"# Visualising the Data","9ab0bf98":"# Residual Analysis"}}