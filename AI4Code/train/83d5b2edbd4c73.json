{"cell_type":{"c1872b0b":"code","e66f4612":"code","d8c6dad2":"code","0d15dc22":"code","c5a0429a":"code","c17f6132":"code","6e0ed733":"code","62b043a4":"code","d7a33f43":"code","14ee1527":"code","b29298d4":"code","a8ad8a37":"code","67fc9620":"code","2cb3b02e":"code","86b4cca3":"code","2cdd6195":"code","9b4600b8":"code","02a1b4a0":"code","a137f417":"code","aa0ffc56":"code","8e6aa154":"code","20367291":"code","e0f20402":"code","fcff77cb":"code","8825bd29":"code","e01680c1":"code","949a2bd0":"code","89fb2fd8":"code","d986b9c7":"code","b6f6adac":"code","56c23d9d":"code","ea4339d9":"code","eac6f06b":"code","b2a6b3f3":"code","8572e4a4":"code","c7185947":"code","29377f5c":"code","79124a98":"code","64851fdf":"code","741d095b":"code","623964ae":"code","3693b2ec":"code","9eebdcf9":"code","9510a244":"code","bc9cb99c":"code","e8b5ac1d":"code","c520aa2f":"code","05b81925":"code","0884fbc7":"code","e2b8e32a":"code","8fdaf26b":"code","60d24271":"code","499dcca6":"code","42531654":"code","d6c39059":"code","21916404":"code","c2762ebe":"code","b290a1ce":"code","e61eb0b3":"code","d2403071":"code","4ab6d3ff":"code","5b6c7797":"code","5cb6dcb3":"code","71d0092d":"code","8db49907":"code","6e543019":"code","e34279de":"code","b199b8c8":"code","3fb2d832":"code","d16d5383":"code","b5809aef":"code","cb474cb8":"code","675e4dbf":"code","00dc1033":"code","c81819ba":"code","24f9bd60":"code","7b6b5ea0":"code","28cf94d4":"code","1a8617e5":"code","541a7f49":"code","e3b15a4a":"code","f72206cf":"code","0f64696b":"code","22a58c2f":"code","428606a6":"code","7881df3d":"code","6af95a69":"code","5e0d558e":"code","961405fb":"code","5f3c085c":"code","9242e269":"code","44e0bf40":"code","753a86ea":"code","f69f90b1":"code","b4861fd3":"code","350d25e4":"code","499e440c":"code","1c3ed65e":"code","d7e48340":"code","3535dcdd":"code","c31ee406":"code","f82b7e20":"code","d34d3659":"code","0ce423df":"code","5c3df0fa":"code","b1fd9c0c":"code","108e4771":"code","08f366ce":"code","0f057981":"code","5440537d":"code","3cf5e6c9":"code","ec67ab4a":"code","955c0c96":"markdown","deef4f2e":"markdown","14c5778f":"markdown","146046ff":"markdown","c85c9df4":"markdown","0d766924":"markdown","f9e226ab":"markdown","66ef1a2a":"markdown","a22369b2":"markdown","ca739881":"markdown","f5ac4864":"markdown","ed833154":"markdown","341bb994":"markdown","1f13bb1c":"markdown","57926fba":"markdown","c9af95d2":"markdown","110de08b":"markdown","535e1dce":"markdown","d33db389":"markdown","bec2b62c":"markdown","e0b67b46":"markdown","ef832641":"markdown","856c74ef":"markdown","0b80068b":"markdown","23ab0826":"markdown","3ee117c8":"markdown","ab5ae2a9":"markdown","e5511711":"markdown","d8f4fca7":"markdown","3798ad8f":"markdown","62f2f999":"markdown","8e3fae9c":"markdown","b812c239":"markdown","6adc5645":"markdown","f87d91f1":"markdown","b088f0b8":"markdown","fe36ac9e":"markdown","4433934e":"markdown","dd241c4c":"markdown","12160829":"markdown","4b3b8b2e":"markdown","38f5f721":"markdown","3ab923e8":"markdown","65d542f8":"markdown","5f9b7276":"markdown","6ac02d57":"markdown","bbbb76ce":"markdown","3de99ea0":"markdown","cb799f8b":"markdown","b365a95b":"markdown","16914214":"markdown","9e8d9803":"markdown","bc122745":"markdown","acf35a0a":"markdown","ac88dcc1":"markdown","2ac49314":"markdown","1825045d":"markdown","66bd7ddb":"markdown","a02bdb3d":"markdown","4e3e3a7b":"markdown","9c3eb8d6":"markdown","19ade4fc":"markdown","b800d28e":"markdown","27be40e1":"markdown","db613e26":"markdown","46a72a34":"markdown","ed1079b2":"markdown","07955417":"markdown","ce3aa104":"markdown","18fd33f8":"markdown","9a9eb5a1":"markdown","a0e9eea5":"markdown","c8e725b2":"markdown","e0d6f95b":"markdown","b33cc5a5":"markdown","651213cc":"markdown","86fdb5b3":"markdown","cfa01ea4":"markdown","f005d524":"markdown","57ad37a7":"markdown","5fd5bc67":"markdown","0fe11af6":"markdown","4952e7c0":"markdown","121f4f5b":"markdown","9ca1d6a1":"markdown","0602f515":"markdown","b3dd4dc9":"markdown","ed42b5d6":"markdown","c4ae7a28":"markdown","3065b04b":"markdown","6962f25f":"markdown","887acc1c":"markdown","d18667a6":"markdown","84e40d43":"markdown","fee611be":"markdown","8866d013":"markdown","be4422df":"markdown","a7a924df":"markdown","ff523706":"markdown","8d8e6ac2":"markdown","9582b613":"markdown","bd2fb69b":"markdown","8dc87f89":"markdown","5f47d5e0":"markdown","af31201a":"markdown","38a98f46":"markdown","c6438ba5":"markdown","cea29887":"markdown","c055dae6":"markdown","5b57d8ef":"markdown","35f4bc43":"markdown","49be9cf9":"markdown","e451d69d":"markdown","c7246b23":"markdown","2e05717c":"markdown","4cba12a3":"markdown","eb0272ab":"markdown","a96f6e84":"markdown","4f425d8f":"markdown","04f302c9":"markdown","8d2e9800":"markdown","91f92a2d":"markdown","6020ecec":"markdown","3f1d6f4a":"markdown","dafed1b2":"markdown","a0031db7":"markdown","bdab4626":"markdown","96168af8":"markdown","b35daede":"markdown","1320934a":"markdown","d3af6815":"markdown","daef04c5":"markdown","6b2c518e":"markdown","469000b4":"markdown","2115d3d2":"markdown","73703e82":"markdown","bf3c0576":"markdown","29165f81":"markdown","f0988087":"markdown","e30cb290":"markdown","c9b86be5":"markdown","6c5b48f8":"markdown","c463067a":"markdown","be33035b":"markdown","50a63084":"markdown","dbec0b14":"markdown","0c829ab9":"markdown","dc04cc25":"markdown","1e29ccf1":"markdown","9ef32a42":"markdown","417bab98":"markdown","50d01630":"markdown","ade902e5":"markdown","d178ad46":"markdown","0a165de0":"markdown","3b6be119":"markdown","ded6341b":"markdown","89fda24a":"markdown","b53e29e3":"markdown","96cc2ca1":"markdown","2e8ba14a":"markdown","6e84abae":"markdown","56778e2c":"markdown","3f626332":"markdown","a1250cca":"markdown","4f4430e3":"markdown","f54f9b75":"markdown"},"source":{"c1872b0b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats as st\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_predict\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.dummy import DummyRegressor","e66f4612":"df = pd.read_csv('..\/input\/student-alcohol-consumption\/student-mat.csv')","d8c6dad2":"df.head()","0d15dc22":"df.info()","c5a0429a":"df.describe(include='all').T","c17f6132":"pd.concat([df['school'].value_counts().to_frame(), df['school'].value_counts(normalize=True).to_frame()], axis=1)","6e0ed733":"sns.histplot(df.age, bins=8, discrete=True)\nplt.title('Age distribtuion')\nplt.show()","62b043a4":"sns.histplot(df.sex)\nplt.title('Gender distribtuion')\nplt.show()","d7a33f43":"sns.histplot(df.Dalc, discrete=True)\nplt.title('Workday alcohol consumption distribtuion')\nplt.show()","14ee1527":"df['Dalc'].value_counts(normalize=True)","b29298d4":"sns.histplot(df.Walc, discrete=True)\nplt.title('Weekend alcohol consumption distribtuion')\nplt.show()","a8ad8a37":"df['Walc'].value_counts(normalize=True)","67fc9620":"df[df['Dalc'] == 1]['Walc'].value_counts(normalize=True)","2cb3b02e":"sns.histplot(df['absences'], bins=30)\nplt.title('Absences distribtuion')\nplt.show()","86b4cca3":"sns.histplot(df['G1'], discrete=True)\nplt.title('G1 distribtuion')\nplt.show()","2cdd6195":"sns.histplot(df['G2'], discrete=True)\nplt.title('G2 distribtuion')\nplt.show()","9b4600b8":"sns.histplot(df['G3'], discrete=True)\nplt.title('G3 distribtuion')\nplt.show()","02a1b4a0":"df.query('G3 == 0')","a137f417":"fig, axes = plt.subplots(1, 2, figsize=(14,5))\naxes[0].scatter(data=df, x='G1', y='G3')\naxes[0].set_title('G3 versus G1')\naxes[0].set_xlabel('G1')\naxes[0].set_ylabel('G3')\naxes[1].scatter(data=df, x='G2', y='G3')\naxes[1].set_title('G3 versus G2')\naxes[1].set_xlabel('G2')\naxes[1].set_ylabel('G3')\nplt.show()","aa0ffc56":"sns.histplot(data=df, x=\"Dalc\", hue=\"sex\", element=\"step\",  stat=\"density\")\nplt.title('Influence of gender on the alcohol consumption on the workdays')\nplt.show()","8e6aa154":"sns.histplot(data=df, x=\"Walc\", hue=\"sex\", element=\"step\",  stat=\"density\")\nplt.title('Influence of gender on the alcohol consumption on the weekend')\nplt.show()","20367291":"df.groupby('sex')[['Dalc', 'Walc']].mean()","e0f20402":"df.groupby('age')[['Dalc', 'Walc']].mean().plot(kind='bar')\nplt.ylabel('Alcohol consumption')\nplt.xticks(rotation=0)\nplt.title('Mean alcohol consumption over age')\nplt.show()","fcff77cb":"df.groupby('age')[['Dalc', 'Walc']].agg(['mean', 'count'])","8825bd29":"df.groupby('address')[['Dalc', 'Walc']].agg(['mean', 'count'])","e01680c1":"for group, data in df.groupby('address'):\n    data['Dalc'].hist(alpha=0.5, density=True, label=group, grid=False)\nplt.legend()\nplt.title('Workday alcohol consumption depending of the type of living area')\nplt.show()","949a2bd0":"for group, data in df.groupby('address'):\n    data['Walc'].hist(alpha=0.5, density=True, label=group, grid=False)\nplt.legend()\nplt.title('Weekend alcohol consumption depending of the type of living area')\nplt.show()","89fb2fd8":"sample_R = df.query('address == \"R\"')['Walc']\nsample_U = df.query('address == \"U\"')['Walc']","d986b9c7":"st.ttest_ind(sample_R, sample_U).pvalue","b6f6adac":"df.groupby('Pstatus')[['Dalc', 'Walc']].agg(['mean', 'count'])","56c23d9d":"for group, data in df.groupby('Pstatus'):\n    data['Dalc'].hist(alpha=0.5, density=True, label=group, grid=False)\nplt.legend()\nplt.title('Workday alcohol consumption depending of the parent\\'s cohabitation status')\nplt.show()","ea4339d9":"for group, data in df.groupby('Pstatus'):\n    data['Walc'].hist(alpha=0.5, density=True, label=group, grid=False)\nplt.legend()\nplt.title('Weekend alcohol consumption depending of the parent\\'s cohabitation status')\nplt.show()","eac6f06b":"plt.figure(figsize=(15,6))\nfor age, grouped_data in df.groupby('age'):\n    if age <= 19:\n        sns.kdeplot(grouped_data['G1'], label=age)\nplt.legend()\nplt.title('Grade distribtuion depending on age of students')\nplt.show()","b2a6b3f3":"df.query('age <= 19').groupby('age')['G1'].mean().plot(kind='bar')\nplt.title('Mean value of G1 over age')\nplt.ylabel('Mean value of G1')\nplt.xticks(rotation=0)\nplt.show()","8572e4a4":"print(st.ttest_ind(df.query('age == 15')['G1'], df.query('age == 19')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('age == 15')['G1'], df.query('age == 18')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('age == 15')['G1'], df.query('age == 17')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('age == 15')['G1'], df.query('age == 16')['G1'], equal_var=False).pvalue)","c7185947":"sns.kdeplot(data=df, x=\"G1\", hue=\"sex\")\nplt.title('Influence of gender on G1')\nplt.show()","29377f5c":"df.groupby('sex')[['G1']].mean()","79124a98":"st.ttest_ind(df.query('sex == \"M\"')['G1'], df.query('sex == \"F\"')['G1'], equal_var=False).pvalue","64851fdf":"plt.figure(figsize=(15,6))\nfor dalc, grouped_data in df.groupby('Dalc'):\n    sns.kdeplot(grouped_data['G1'], label=dalc)\nplt.legend()\nplt.title('Grade distribtuion depending on the workday alcohol consumption')\nplt.show()","741d095b":"df.groupby('Dalc')['G1'].mean().plot(kind='bar')\nplt.title('Mean value of G1 over workday alcohol consumption')\nplt.ylabel('Mean value of G1')\nplt.xticks(rotation=0)\nplt.show()","623964ae":"print(st.ttest_ind(df.query('Dalc == 1')['G1'], df.query('Dalc == 2')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('Dalc == 1')['G1'], df.query('Dalc == 3')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('Dalc == 1')['G1'], df.query('Dalc == 4')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('Dalc == 1')['G1'], df.query('Dalc == 5')['G1'], equal_var=False).pvalue)","3693b2ec":"df.groupby('Dalc')['Dalc'].count().to_frame()","9eebdcf9":"plt.figure(figsize=(15,6))\nfor walc, grouped_data in df.groupby('Walc'):\n    sns.kdeplot(grouped_data['G1'], label=walc)\nplt.legend()\nplt.title('Grade distribtuion depending on the weekend alcohol consumption')\nplt.show()","9510a244":"df.groupby('Walc')['G1'].mean().plot(kind='bar')\nplt.title('Mean value of G1 over weekend alcohol consumption')\nplt.ylabel('Mean value of G1')\nplt.xticks(rotation=0)\nplt.show()","bc9cb99c":"print(st.ttest_ind(df.query('Walc == 2')['G1'], df.query('Walc == 1')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('Walc == 2')['G1'], df.query('Walc == 3')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('Walc == 2')['G1'], df.query('Walc == 4')['G1'], equal_var=False).pvalue)\nprint(st.ttest_ind(df.query('Walc == 2')['G1'], df.query('Walc == 5')['G1'], equal_var=False).pvalue)","e8b5ac1d":"df.groupby('Walc')['Walc'].count().to_frame()","c520aa2f":"df[['age', 'absences', 'G1']].corr()","05b81925":"features_imp = df.copy().drop(['G1', 'G2', 'G3'], axis=1)\ntarget_imp = df.copy()['G1']","0884fbc7":"print(features_imp.shape)\nprint(target_imp.shape)","e2b8e32a":"scaler_num = StandardScaler()\nfeatures_imp[['age', 'absences']] = scaler_num.fit_transform(features_imp[['age', 'absences']])","8fdaf26b":"ohe_columns = []\nfor col in features_imp.columns:\n    if col not in ['age', 'absences']:\n        ohe_columns.append(col)\n        \nfeatures_imp = pd.get_dummies(features_imp, drop_first=True, columns=ohe_columns)","60d24271":"features_imp.head()","499dcca6":"linear_regressor = LinearRegression()\nlinear_regressor.fit(features_imp, target_imp)","42531654":"feature_importances_lr_coef = pd.concat([pd.Series(features_imp.columns, name='features'), \n                                         pd.Series(linear_regressor.coef_, name='weights')],\n                                        axis=1)","d6c39059":"feature_importances_lr_coef","21916404":"feature_importances_lr_coef['weights'] = abs(feature_importances_lr_coef['weights'])","c2762ebe":"feature_importances_lr_coef = feature_importances_lr_coef.sort_values(by='weights', ascending=False).reset_index(drop=True)","b290a1ce":"plt.figure(figsize=(15,9))\nsns.barplot(data=feature_importances_lr_coef[:20], x='features', y='weights')\nplt.xticks(rotation=45)\nplt.show()","e61eb0b3":"parameters = {'max_depth' : [8, 10, 12, 20],\n              'n_estimators' : [200, 250, 300],\n              'max_features' : [5, 25, 50],\n              'min_samples_split' : [2, 4, 6]}\ngrid_search = GridSearchCV(estimator = RandomForestRegressor(random_state=42),\n                           param_grid = parameters,\n                           scoring = 'neg_mean_squared_error',\n                           cv = 5)\ngrid_search.fit(features_imp, target_imp)","d2403071":"grid_search.best_params_","4ab6d3ff":"regressor_rf = RandomForestRegressor(max_depth=12, n_estimators=300, max_features=25, min_samples_split=6, random_state=42)\nregressor_rf.fit(features_imp, target_imp)","5b6c7797":"feature_importances_rf = pd.concat([pd.Series(features_imp.columns, name='features'), \n                                    pd.Series(regressor_rf.feature_importances_, name='importance')],\n                                    axis=1).sort_values(by='importance', ascending=False).reset_index(drop=True)","5cb6dcb3":"feature_importances_rf","71d0092d":"plt.figure(figsize=(15,9))\nsns.barplot(data=feature_importances_rf[:20], x='features', y='importance')\nplt.xticks(rotation=45)\nplt.show()","8db49907":"sns.histplot(df['failures'], discrete=True)\nplt.title('Distribution of failures')\nplt.show()\ndf['failures'].value_counts(normalize=True).to_frame()","6e543019":"plt.figure(figsize=(15,6))\nfor failures, grouped_data in df.groupby('failures'):\n    sns.kdeplot(grouped_data['G1'], label=failures)\nplt.legend()\nplt.title('Grade distribtuion depending on the past failures')\nplt.show()","e34279de":"sns.histplot(df['freetime'], discrete=True)\nplt.title('Distribution of freetime')\nplt.show()\ndf['freetime'].value_counts(normalize=True).to_frame()","b199b8c8":"plt.figure(figsize=(15,6))\nfor freetime, grouped_data in df.groupby('freetime'):\n    sns.kdeplot(grouped_data['G1'], label=freetime)\nplt.legend()\nplt.title('Grade distribtuion depending on freetime')\nplt.show()","3fb2d832":"df.groupby('freetime')['G1'].mean().plot(kind='bar')\nplt.title('Mean value of G1 over freetime')\nplt.ylabel('Mean value of G1')\nplt.xticks(rotation=0)\nplt.show()","d16d5383":"sns.histplot(df['Medu'], discrete=True)\nplt.title('Distribution of mother\\'s education')\nplt.show()\ndf['Medu'].value_counts(normalize=True).to_frame()","b5809aef":"plt.figure(figsize=(15,6))\nfor medu, grouped_data in df.groupby('Medu'):\n    sns.kdeplot(grouped_data['G1'], label=medu)\nplt.legend()\nplt.title('Grade distribtuion depending on mother\\'s education')\nplt.show()","cb474cb8":"df.groupby('Medu')['G1'].mean().plot(kind='bar')\nplt.title('Mean value of G1 over mother\\'s education')\nplt.ylabel('Mean value of G1')\nplt.xticks(rotation=0)\nplt.show()","675e4dbf":"sns.histplot(df['schoolsup'], discrete=True)\nplt.title('Distribution of scholl support')\nplt.show()\ndf['schoolsup'].value_counts(normalize=True).to_frame()","00dc1033":"plt.figure(figsize=(15,6))\nfor schoolsup, grouped_data in df.groupby('schoolsup'):\n    sns.kdeplot(grouped_data['G1'], label=schoolsup)\nplt.legend()\nplt.title('Grade distribtuion depending on school support')\nplt.show()","c81819ba":"df.groupby('schoolsup')['G1'].mean().plot(kind='bar')\nplt.title('Mean value of G1 over school support')\nplt.ylabel('Mean value of G1')\nplt.xticks(rotation=0)\nplt.show()","24f9bd60":"sns.histplot(df['studytime'], discrete=True)\nplt.title('Distribution of study time')\nplt.show()\ndf['studytime'].value_counts(normalize=True).to_frame()","7b6b5ea0":"plt.figure(figsize=(15,6))\nfor studytime, grouped_data in df.groupby('studytime'):\n    sns.kdeplot(grouped_data['G1'], label=studytime)\nplt.legend()\nplt.title('Grade distribtuion depending on study time')\nplt.show()","28cf94d4":"df.groupby('studytime')['G1'].mean().plot(kind='bar')\nplt.title('Mean value of G1 over study time')\nplt.ylabel('Mean value of G1')\nplt.xticks(rotation=0)\nplt.show()","1a8617e5":"sns.histplot(df['absences'], bins=30)\nplt.title('Absences distribtuion')\nplt.show()","541a7f49":"plt.scatter(df['absences'], df['G1'])\nplt.xlabel('Number of absences')\nplt.ylabel('Grade')\nplt.show()","e3b15a4a":"_, axes = plt.subplots(2, 2, figsize=(15,9))\n_.suptitle('Influence of absences on grade')\nsns.kdeplot(df.query('absences == 0')['G1'], label='0 absences', ax=axes[0, 0])\nsns.kdeplot(df.query('absences > 0')['G1'], label='there are absences', ax=axes[0, 0])\naxes[0, 0].legend()\n\nsns.kdeplot(df.query('absences < 5')['G1'], label='less than 5 ', ax=axes[0, 1])\nsns.kdeplot(df.query('absences >= 5 ')['G1'], label='>= 5', ax=axes[0, 1])\naxes[0, 1].legend()\n\nsns.kdeplot(df.query('absences < 10')['G1'], label='less than 10 ', ax=axes[1, 0])\nsns.kdeplot(df.query('absences >= 10 ')['G1'], label='>= 10', ax=axes[1, 0])\naxes[1, 0].legend()\n\nsns.kdeplot(df.query('absences < 20')['G1'], label='less than 20 ', ax=axes[1, 1])\nsns.kdeplot(df.query('absences >= 20 ')['G1'], label='>= 20', ax=axes[1, 1])\naxes[1, 1].legend()\nplt.show()","f72206cf":"features = df.copy().drop(['G1', 'G2', 'G3'], axis=1)\ntarget = df.copy()['G1']","0f64696b":"print(features.shape)\nprint(target.shape)","22a58c2f":"features.head()","428606a6":"ohe_columns = []\nfor col in features.columns:\n    if col not in ['age', 'absences']:\n        ohe_columns.append(col)\n        \nfeatures = pd.get_dummies(features, drop_first=True, columns=ohe_columns)","7881df3d":"features.head()","6af95a69":"features_train, features_test, target_train, target_test = train_test_split(features, \n                                                                            target, \n                                                                            test_size=0.2,\n                                                                            random_state=5)","5e0d558e":"print(features_train.shape)\nprint(features_test.shape)\nprint(target_train.shape)\nprint(target_test.shape)","961405fb":"sns.kdeplot(target_train, label='target')\nsns.kdeplot(target_test, label='test')\nplt.legend()\nplt.title('G1 distribution in the test and train set')\nplt.show()","5f3c085c":"print('train mean value:', target_train.mean())\nprint('test mean value:', target_test.mean())","9242e269":"scaler = StandardScaler()\nfeatures_train[['age', 'absences']] = scaler.fit_transform(features_train[['age', 'absences']])\nfeatures_test[['age', 'absences']] = scaler.transform(features_test[['age', 'absences']])","44e0bf40":"features_train.head()","753a86ea":"features_test.head()","f69f90b1":"regressor_lr = LinearRegression()\nregressor_lr.fit(features_train, target_train)","b4861fd3":"feature_importances = pd.concat([pd.Series(features_train.columns, name='features'), \n                                 pd.Series(regressor_lr.coef_, name='importance')],\n                                axis=1)\n\nfeature_importances['importance'] = abs(feature_importances['importance'])\n\nfeature_importances = feature_importances.sort_values(by='importance', ascending=False).reset_index(drop=True)","350d25e4":"feature_importances.head()","499e440c":"results_features = pd.DataFrame({'threshold' : [], \n                    'number_of_features' : [],\n                    'mse' : []})\n\nfor threshold in np.arange(0, 4, 0.05):\n    features_truncated = features_train.copy()\n\n    for col in features_truncated.columns:\n        if feature_importances.loc[feature_importances['features'] == col]['importance'].values < threshold:\n            features_truncated = features_truncated.drop(col, axis=1)\n\n    y_pred = cross_val_predict(KNeighborsRegressor(n_neighbors=6), features_truncated, target_train, cv=5)\n    mse = mean_squared_error(target_train, y_pred)\n    if results_features.empty or results_features['number_of_features'].iloc[-1] > features_truncated.shape[1]:\n        results_features = results_features.append(pd\n                                                   .DataFrame([[threshold, \n                                                                features_truncated.shape[1], \n                                                                mse]], \n                                                              columns=results_features.columns))","1c3ed65e":"results_features.sort_values(by='mse').head()","d7e48340":"features_train_truncated = features_train.copy()\n\nfor col in features_train_truncated.columns:\n    if feature_importances.loc[feature_importances['features'] == col]['importance'].values < 0.9:\n        features_train_truncated = features_train_truncated.drop(col, axis=1)","3535dcdd":"features_train_truncated.head()","c31ee406":"features_test_truncated = features_test.copy()\n\nfor col in features_test_truncated.columns:\n    if feature_importances.loc[feature_importances['features'] == col]['importance'].values < 0.9:\n        features_test_truncated = features_test_truncated.drop(col, axis=1)","f82b7e20":"features_test_truncated.head()","d34d3659":"parameters = {'max_depth' : [2, 3, 4],\n              'n_estimators' : [20, 30, 50, 75, 100],\n              'eta' : [0.5, 0.3, 0.1, 0.05]}\ngrid_search_xgb = GridSearchCV(estimator=XGBRegressor(random_state=42),\n                               param_grid=parameters,\n                               scoring='neg_mean_squared_error',\n                               cv=5,\n                               verbose=1)\n\ngrid_search_xgb.fit(features_train_truncated, target_train)","0ce423df":"grid_search_xgb.best_params_","5c3df0fa":"grid_search_xgb.best_score_","b1fd9c0c":"regressor = XGBRegressor(max_depth=2, \n                         n_estimators=20,\n                         eta=0.5,\n                         random_state=42)\nregressor.fit(features_train_truncated, target_train)","108e4771":"target_pred = regressor.predict(features_test_truncated)","08f366ce":"mean_squared_error(target_test, target_pred) ** 0.5","0f057981":"mean_squared_error(target_train,  regressor.predict(features_train_truncated)) ** 0.5","5440537d":"X_train, X_val, y_train, y_val = train_test_split(features_train_truncated, target_train, test_size = 0.2, random_state=100500)\ntrain_errors, val_errors = [], []\nfor m in range(1, len(X_train)):\n    regressor.fit(X_train[:m], y_train[:m])\n    y_train_predict = regressor.predict(X_train[:m])\n    y_val_predict = regressor.predict(X_val)\n    train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n    val_errors.append(mean_squared_error(y_val, y_val_predict))\nplt.figure(figsize=(14,6))\nplt.plot(np.sqrt(train_errors), 'r-+', linewidth=2, label='train')\nplt.plot(np.sqrt(val_errors), 'b-', linewidth=3, label='val')\nplt.xlabel('Training set size')\nplt.ylabel('RMSE')\nplt.legend()\nplt.title('Learning curve', fontsize = 20)\nplt.show()","3cf5e6c9":"regressor_mean = DummyRegressor(strategy='mean')\nregressor_mean.fit(features_train_truncated, target_train)","ec67ab4a":"mean_squared_error(target_test, regressor_mean.predict(features_test_truncated)) ** 0.5","955c0c96":"Let's check ourselves.","deef4f2e":"Another important feature is *Walc* - weekend alcohol consumption.","14c5778f":"In this paragraph, I would like to have a look at the target (grades), at some basic features (age, sex, etc.) and at the level of alcohol consumption to get an understanding of the dataset we have. We will consider several features (which can affect the target and alcohol consumption based on my prejudiced opinion) and their influence on the target and alcohol consumption. A more precise investigation of all features will be done in the next paragraph. ","146046ff":"Now we can make a loop to evaluate different thresholds of importance.","c85c9df4":"In this paragraph, several features and their influence on the grade were briefly investigated. The conclusions are following:\n1. The age of the majority of students in the dataset is in the range between 15 and 18. The oldest student is 22 years old.\n2. The majority of students (almost 70%) do not drink alcohol during the workdays, 19% drink a bit more than nothing, 2.5% drink a lot during the workdays.\n3. The situation with alcohol consumption changes on the weekend. Only 38% of students do not drink, 22% drink a bit, 20% have medium consumption, 13% - higher than medium, 7% - the highest consumption.\n4. The grades have distributions similar to the normal distribution. There is a strong linear correlation between grade in the first period, grade in the second period, and final grade. \n5. Male students consume more alcohol than female students. \n6. With an increase in age, alcohol consumption on the weekend also increases and reaches its peak at 17 years old.\n7. Students living in rural areas drink more alcohol than students living in urban areas.\n8. Age and gender do not affect grade. \n9. Alcohol consumption affects grade. Students, that have high alcohol consumption, have lower grade.","0d766924":"79% of students do not have any past class failures. Let's have a look at how this fact affects grade. We will separate the dataset according to the number of past class failures and build a distribution of grade for them.","f9e226ab":"We have already seen the distribution of absences, but let's do it again to have all information in one place.","66ef1a2a":"### General familiarization with the data","a22369b2":"In spite of p-value in the last case being slightly higher than our significance level, I would say that the high alcohol consumption on the weekend leads to low grade at school. Students with low and medium alcohol consumption on the weekend have the same grade.","ca739881":"First of all, we will check the distribution of grades for every age.","f5ac4864":"In our dataset, there are a bit more females than males.","ed833154":"#### Feature importances using Random Forest","341bb994":"Also, we have to keep in mind that correlation accounts only for linear dependence. It's the main disadvantage of the approach.","1f13bb1c":"Let's start with age. Does age affect the grade at school? Do students get better marks as they get older or in the opposite? We will take into account only students younger than 20 because we have enough data of them.","57926fba":"The original dataset consists of two parts: students that study math and students that study the Portuguese language. In this notebook we will consider only the first part - students studying math.","c9af95d2":"It seems like students which live in rural area consume more alcohol, but the number of these students are not so high. To be sure we can carry out the statisctical test.","110de08b":"So, I tend to assume that workday alcohol consumption affects grade, and the lower alcohol consumption - the better grade.","535e1dce":"If we bring all features to the same scale, we are able to assess feature importance by coefficients (weights) of the linear regression model.","d33db389":"In this section we will consider how the features discussed above affect the target (*G1*).","bec2b62c":"We can clearly see that points are scattered around the line y=x, which means that our assumption is correct.\n\nFor simplicity's sake in future reasoning, we will consider only G1, and obtained results can be applied to G2 and G3 as well. ","e0b67b46":"From that we can conclude that the majority of students (almost 70%) do not drink alcohol during the week (1 in *Dalc* means very low consumption. It's weird that there is no choice of 0 meaning \"no alcohol at all'. Since it's unrealistic to assume that every student drinks alcohol, in this notebook we will consider \"very low consumption\" as \"no alcohol\"). 19% drink a bit more than nothing, 2.5% drink a lot during the week. ","ef832641":"Now we can consider the parent's cohabitation status.","856c74ef":"Since RandomForestRegressor has a lot of hyperparameters to tune, we have to find the optimum ones. GridSearchCV will be applied.","0b80068b":"First of all, we have to highlight the goals of our research:\n1. Understand, which features affect the grades of students.\n2. Assess the influence of alcohol consumption on the grades.","23ab0826":"### Encoding categorical data","3ee117c8":"The distribution of G1 over ages do not differ too much. The mean value is slightly decreasing. Let's check, whether the difference between ages is significant or not by applying the statistical test.","ab5ae2a9":"The main goal of this part is to build a model that will be able to predict students grade.\n\nIt will be done in 3 steps:\n1. Training the model.\n2. Evaluating the model performance on the test set.\n3. \u0421hecking the model for adequacy (comparison with a constant model).","e5511711":"#### Alcohol consumption","d8f4fca7":"As we said in section 2.1.1, we will consider only G1.","3798ad8f":"We can assume that students usually have approximately the same grade in the first and second periods, as well as final grade. Let's check this assumption.","62f2f999":"#### Features affecting the grade","8e3fae9c":"Now we can train the model.","b812c239":"As in the previous cases, we will build distributions and then compare the mean values. ","6adc5645":"A model can be recognized as adequate or meaningful if its performance is better than the performance of a constant model (which output is always the same (for example, mean or median value)). For comparison we will be using RMSE. Our model has RMSE of 3.24 on the test.","f87d91f1":"Let's check the model, that always predict the mean value.","b088f0b8":"In this paragraph, feature importances were defined using different approaches. The following conclusions were obtained:\n1. Correlation analysis is not applicable because the majority of features are categorical.\n2. Based on the analysis of linear regression coefficients the top-5 features that have the most influence on the target are the following: *failures*, *freetime*, *Medu*, *studytime*, *schoolsup*.\n3. Based on Random Forest the top-5 features that have the most influence on the target are the following: *absences*, *schoolsup*, *failures*, *age*, *Medu*.\n4. Both algorithms agree regarding *failures*, *freetime*, *Medu* and *schoolsup*, but there are some contradictions: while Random Forest considers *age*, *absences* and *sex* important features, weights of these features in Linear Regression are small. It should be clarified in the next step. Important features from both algorithms should be investigated in detail.","fe36ac9e":"Now it's time to consider the influence of alcohol consumption on the grade.","4433934e":"As in the previous case, we will check the mean values, number of students in each group and then build the distributions.","dd241c4c":"The best mean_squared_error was achieved by using a threshold of 0.9 with 32 features. Let's drop unnecessary features.","12160829":"Our assumption was right. Students that study more than 5 hours per week get a higher grade than those who study less than 5 hours.","4b3b8b2e":"Till now we considered the features, that were named \"important\" by both methods used in the previous paragraph. Let's check the feature *absences*. Based on the Random Forest this feature has the highest importance, but its weight in the Linear Regression was low.  ","38f5f721":"Everything is correct.","3ab923e8":"Also, we already calculated the linear correlation between absences and grade. The value is -0.031. It means that there is no linear correlation between them. Let's plot G1 versus absences, maybe we will be able to detect another type of dependence. ","65d542f8":"The goals of the present work are:\n1. Estimate the factors affecting grade of students.\n2. Estimate the level of alcohol consumption among students.\n3. Build a machine learning model which is able to predict grade of students based on the available features.","5f9b7276":"## First look at the data","6ac02d57":"Now we will do the same procedure but for alcohol consumption on the weekend.","bbbb76ce":"#### Analysis of linear regression coefficients","3de99ea0":"### Training the model","cb799f8b":"We can clearly see that boys drink more than girls, which is to be expected. And both groups drink more on the weekend in comparison to the weekdays. ","b365a95b":"#### Extra educational support","16914214":"Let's make a dataframe containing the features and their importnaces.","9e8d9803":"### Matrix of features and dependent variable vector","bc122745":"In the dataset we have students from 2 different schools. Let's have a look, how many students they have.","acf35a0a":"### Train-test split","ac88dcc1":"1. The dataset includes information about 395 students.\n2. There are 33 features. The majority of them are categorical variables. Some variables look numerical, but in fact, they are categorical. For example, *Medu* -  mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 \u2013 5th to 9th grade, 3 \u2013 secondary education or 4 \u2013 higher education). There are only 5 real numerical features - *age*, *absences*, and grades (*G1*, *G2*, *G3*). \n3. There are no missing values.","2ac49314":"The distributions are slightly different and the mean value for males is higher than for females. The difference is not big enough to be confident, so we will again apply the statistical test, namely t-test with a significance level of 0.05.","1825045d":"Another interesting feature could be *absences*.","66bd7ddb":"Also it's useful to have a look at a sample size.","a02bdb3d":"We will use the same matrix of features, as well as the dependent variable vector, as we used in the previous section.","4e3e3a7b":"With an increase of age, alcohol consumption on the weekend also increases and reaches the peak at 17 years old, then it decreases a bit and again increases significantly at age of 20-22. But, as we remember from the previous section, we have only a few students older than 19, so this data is not representative for them. ","9c3eb8d6":"The performance on the test set is a bit worse than on the training set, but it's appropriate. We can conclude, that overfitting hasn't happened.","19ade4fc":"Another feature, that was recognized as important by both algorithms, is *studytime* - weekly study time (1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours). Let's have a look at how many hours peer week they study. ","b800d28e":"It's very important to understand which features affect the target and which features don't, and also it's useful to somehow assess their influence. In the previous paragraph, we did this stochastically: just randomly considered several features that could affect the target based on our knowledge and experience. \n\nBut we have 30 features and it would be quite problematic to precisely consider all of them. However, there is a way how to do it methodically and intelligently. \n\nWe will estimate the feature importances and then only the most important features will be precisely considered.\n\nThere are different ways to estimate feature importances: correlation analysis, machine learning models, etc.","27be40e1":"#### Number of past class failures","db613e26":"Ok, it looks fine.","46a72a34":"### Detailed consideration of important features","ed1079b2":"Let's have a look at the 20 features (including dummy variables, in fact there will be less), that have the strongest influence on the target.","07955417":"The correlation analysis means finding linear correlation between numeric variables. Unfortunately, we have only 2 numeric variables (*age* and *absences*), and in our case it's meaningless to apply the correlation analysis. ","ce3aa104":"Build two samples.","18fd33f8":"#### Free time after school","9a9eb5a1":"For evaluating RMSE (root mean squared error) will be used.","a0e9eea5":"For encoding the categorical features One Hot Encoding technique will be used.","c8e725b2":"P-value is lower than the significance level. It means that the probability to take these samples randomly is low (with a condition that there is no difference in alcohol consumption), and we can conclude that the difference is significant. Students living in rural area drink more alcohol that students living in urban area.","e0d6f95b":"These three distribtuions look similar to normal distribution. *G2* and *G3* have outliers in 0. According to https:\/\/www.scholaro.com\/pro\/Countries\/Portugal\/Grading-System, the lowest possible grade in Portugal is 1. Let's have a look at the students that have 0 grade.","b33cc5a5":"## Modeling","651213cc":"In this paragraph we will get a closer look at the important features highlighted in the previous paragraph.","86fdb5b3":"Now we move on to *Medu* which means mother's education (0 - none, 1 - primary education (4th grade), 2 \u2013 5th to 9th grade, 3 \u2013 secondary education or 4 \u2013 higher education)","cfa01ea4":"From these distributions, we can conclude that number of absences does not affect grade. \n\nIt's weird that Random Forest considered this feature important. Also, Random Forest considered *sex* and *age* important features, but in our analysis, in section 2.1.3 we found out that it is not. Based on this, we can conclude that calculating feature importances based on linear regression coefficients is more reliable for our dataset. ","f005d524":"Anyway, let's calculate the correlation at least for these 2 features.","57ad37a7":"Let's build a model and find feature importances.","5fd5bc67":"The difference is insignificant, so we can conclude that age does not affect the grade.","0fe11af6":"This method is based on the attribute available for RandomForestRegressor. The procedure is very simple: fit the RandomForestRegressor and then call the attribute.","4952e7c0":"Let's start with workday alcohol consumption.","121f4f5b":"### Feature engineering","9ca1d6a1":"### Evaluating the model performance on the test set","0602f515":"#### Distributions","b3dd4dc9":"Based on the distributions, we can clearly see that students, which do not have any past class failures, have the better grade. It means, that on the previous step both algorithms were correct regarding the importance of this feature.","ed42b5d6":"First of all, we will consider the effect of gender on alcohol comsuption.","c4ae7a28":"Another basic features is gender.","3065b04b":"Looking at this plot, it's difficult to conclude anything. \n\nBased on common sense, students with a high number of absences should have a lower grade. Maybe it starts after a certain threshold. Let's choose 4 thresholds for absences and compare grade of students that have more and fewer absences than that threshold: 0 absences, 5, 10 and 20.","6962f25f":"OHE was carried out successfully.","887acc1c":"First of all, let's import the libraries we will need.","d18667a6":"The most important features based on the Random Forest:\n1. *absences* - number of school absences.\n2. *schoolsup* - extra educational support.\n3. *failures* - number of past class failures.\n4. *age*.\n5. *Medu* - mother's education.\n6. *Fjob* - father's job (whether father is teacher or not).\n7. *sex*.\n8. *freetime* - free time after school.\n9. *studytime* - weekly study time.\n10. *famsup* - family educational support.\n11. *Fedu* - father's education.\n12. *Mjob* - mother's job.\n13. *reason* - reason to choose this school.\n14. *higher* - wants to take higher education.","84e40d43":"Only 13% of students get extra educational support. We can assume that they are quite bad at math, therefore they have to take additional classes, and probably their grade should be lower.","fee611be":"I do not think, that it's a good idea to make new features in our dataset because the features here are quite clear. So feature engineering in this notebook will imply dropping features that have no influence on the target (these features are garbage for the model).\n\nThe procedure will be the following:\n1. Define the feature importance as we did in section 2.2.2, but only using the train set.\n2. Set a threshold for feature importance, unimportant features are deleted.\n3. Build a simple model (we will use KNN) and assess its performance via cross validation.\n4. Repeat steps 2 and 3 to find the best model.","8866d013":"We will use t-test with a significance level of 0.05","be4422df":"50% of students study 2 to 5 hours per week, 27% - less than 2 hours, 7% - more than 10 hours. Seems like students do not like to spend their time on study. Now we can check how it affects their grade. We can suppose, that the more hours of study - the higher grade.","a7a924df":"It seems like a normal distribution. 5% of students have very low freetime, 10% of students have a lot of freetime. Let's have a look at how it affects the target.","ff523706":"**Student Alcohol Consumption. Detailed EDA and grade prediction.**","8d8e6ac2":"To encode categorical data we will use one hot encoding (OHE).","9582b613":"Other features that can affect alcohol consumptions are the type of place of living (urban or rural) and the parent's cohabitation status (living together or apart).","bd2fb69b":"Set the significance level - 0.05.\n\nWe will use t-test.","8dc87f89":"The data were obtained in a survey of students math courses in secondary school. It contains a lot of interesting social, gender and study information about students.","5f47d5e0":"Combining related dummy variables into single features, we can highlight the most important features: \n1. *failures* - number of past class failures.\n2. *freetime* - free time after school.\n3. *Medu* - mother's education.\n4. *studytime* - weekly study time.\n5. *schoolsup* - extra educational support.\n6. *famrel* - quality of family relationships.\n7. *Fjob* - father's job (whether father is teacher or not).\n8. *Mjob* - mother's job (whether mother is teacher or not).\n9. *traveltime* - home to school travel time.\n10. *higher* - wants to take higher education.\n11. *health* - current health status.\n12. *famsup* - family educational support.","af31201a":"The sign of weights is not important for us, so we can use the absolute values.","38a98f46":"The age of majority of students is in the range between 15 and 18. The oldest students are 22 years old.","c6438ba5":"#### Correlation analysis","cea29887":"Now we will consider the feature *Dalc*. It shows a workday alcohol consumption (from 1 - very low to 5 - very high).","c055dae6":"And the same for the test set.","5b57d8ef":"The difference between the first and second groups is significant. Other differences are not significant, but it can be caused by the small size of the groups with higher alcohol consumption.","35f4bc43":"Now we can move on to gender.","49be9cf9":"From the distribution and the comparison of mean values, we can conclude that students with very low freetime after school have a worse grade, which is reasonable because they can be busy with sports training or musical school (or whatever) and they do not have enough time to study. ","e451d69d":"The correlation is very weak.","c7246b23":"### Model adequacy","2e05717c":"### Feature importances","4cba12a3":"Standardization was carried out successfully.","eb0272ab":"It's important that the test and train set has a similar distribution of the target value. Let's check this. If this condition is not met, random seed in train_test_split should be changed.","a96f6e84":"#### Conclusions","4f425d8f":"Another important feature is *schoolsup* - extra educational support (yes or no). Let's have a look and find out how many students get extra educational support.","04f302c9":"In this paragraph, we will prepare our data for building a machine learning model. \n\nAs we said in section 2.1.1 all grades (G1, G2, G3) have a very strong linear correlation, and on the EDA stage, we considered only G1. We will continue considering only G1 on the modeling stage as well. ","8d2e9800":"We can summarize on one table mean alcohol consumption for every age and number of students of this age.","91f92a2d":"Also, it's interesting to see, how many students, that do not drink alcohol during the week, drink alcohol on the weekend. ","6020ecec":"For training, we will be using XGBRegressor from xgboost library. The choice is based on the fact that usually gradient boosting shows the best results on table data.","3f1d6f4a":"Let's make a dataframe containing the features and their weights.","dafed1b2":"We can separate these students into two groups:\n1. Students of the first group have *G2*, but *G3* is 0. It can be missing values, or by the time when the dataset was being created the student did not have a grade due to some circumstances. \n2. Students of the second group have zero in *G2*, and in *G3* as well. We can assume that these students left the school after the first period. ","a0031db7":"#### Mother's education","bdab4626":"Let's have a look at *failures*.","96168af8":"The sample for students, which mothers have no education at all, is too small. So we can drop it from consideration. Based on other observations, we can conclude that the higher the level of mother's education the better grade. ","b35daede":"#### Conclusions","1320934a":"## EDA","d3af6815":"Then we can create a dataframe and have a look at it.","daef04c5":"The features and the target are prepared. Now we can build the linear regression model.","6b2c518e":"Most students either do not have a lot of absences or have 0 absences at all. But there are some unique students that have more than 30 absences.","469000b4":"### Feature scaling","2115d3d2":"The distributions look similar. We can conclude that the split was carried out successfully. ","73703e82":"Here the situation changes completely. It seems like students start drinking on the weekend. ","bf3c0576":"Let's create the matrix of features and the dependent variable vector.","29165f81":"2 numerical features should be standardized.","f0988087":"1. Students, that do not have any past class failures, have a better grade.\n2. Students with very low freetime after school have a lower grade.\n3. Mother's education affects grade. The higher the level of mother's education the better grade.\n4. Students, that have extra educational support, have a lower grade.\n5. Students that study more than 5 hours per week get a higher grade than those who study less than 5 hours.\n6. Number of absences does not affect grade.\n7. Since *absences*, *age* and *sex* were considered important features by the Random Forest, but actually, it is not, we can conclude that calculating feature importances based on linear regression coefficients is more reliable for our dataset, because important features from the Linear Regression showed that they affect grade. ","e30cb290":"Let's have a look at the learning curve.","c9b86be5":"88% of students belong to Gabriel Pereira school, the rest belong to Mousinho da Silveira school. ","6c5b48f8":"GridSearchCV will be used for tuning the hyperparameters of the model.","c463067a":"**The performance of the constant model is a bit better. Well, we have to admit that we did not manage to get a reasonable model for grade prediction.**","be33035b":"The optimal hyperparameters were defined. Now we can train the model.","50a63084":"As in the previous section, let's have a look at the 20 features and by combining dummy variables into single features the most important features will be highlighted.","dbec0b14":"Now let's investigate the influence of age on alcohol consumption.","0c829ab9":"#### Study time","dc04cc25":"Another important feature, that was recognized by both algorithms, is *freetime* (free time after school (from 1 - very low to 5 - very high)).","1e29ccf1":"Let's have a look at the age of students.","9ef32a42":"Now, we can go to our target - grades.","417bab98":"Now we can standardize the numerical features.","50d01630":"Here we have a similar situation to that we had with workday alcohol consumption. Again we need to apply the t-test. Now group 2 has the highest mean value, so it'll be compared with other groups.","ade902e5":"Ideally, we should have the same RMSE on the training and on the validation sets. The curves tend to converge, but there are not enough data. If the dataset was larger the predictions would be more precise.","d178ad46":"## Data preprocessing","0a165de0":"Let's start with the type of place of living. Let's build a table showing the mean values and number of students, and then build the distribtuions of alcohol consumption. ","3b6be119":"#### Absences","ded6341b":"#### Conclusions","89fda24a":"Let's check.","b53e29e3":"Source - https:\/\/www.kaggle.com\/uciml\/student-alcohol-consumption","96cc2ca1":"Distributions are different. For students that consume a low amount of alcohol on workdays (or no alcohol at all), there is a wide peak, but for students that consume more alcohol, this peak is narrower. The mean values are slightly different, and students with the lowest alcohol consumption have the highest mean grade, but the groups have different sizes and our sample is relatively small, so we can not be sure. Let's turn again to the t-test with a significance level of 0.05.","2e8ba14a":"The p-value is higher than the significance level, so we do not have enough reasons to reject the null hypothesis. Based on this, we can conclude that mean G1 for males and females are the same. And we can say that gender does not affect the grade. ","6e84abae":"More than 45%.","56778e2c":"Yes, our assumption was correct. Students, that don't have extra educational support, have higher average grade.","3f626332":"To estimate the model performance in the future we have to create a test set. In our case, it will contain 20% of all data.","a1250cca":"We have 30 features, all columns except index and grades. Our target is G1.","4f4430e3":"Students, which parents live apart, drink a bit more on the weekdays and a bit less on the weekend in comparison with those, which parents live together. Taking into account the small sample of students, which parents live apart, we can not say that the difference is significant. So, the parent\\'s cohabitation status does not affect students alcohol consumption.","f54f9b75":"Let's have a closer look at alcohol consumption among students."}}