{"cell_type":{"3f8b5b3b":"code","0235d55e":"code","419a1ab4":"code","768da0d0":"code","9c0ef24a":"code","22abd062":"code","71fabd1c":"code","cfb2fc04":"code","e26cb75a":"code","ce3d387d":"code","f0e2e0cc":"code","19cc100a":"code","6576b480":"code","9521794c":"code","c86bddaa":"code","17f41630":"code","2ca7a87e":"code","66c6b972":"code","771b3343":"code","3742b7c5":"code","375bab1f":"code","2cf0dde0":"code","895ec891":"code","73b5c2dc":"code","ab333801":"code","3933e74b":"code","a66bdc3d":"code","190b998b":"code","9ece7860":"code","1b694c14":"code","be48ef9f":"code","4f318818":"code","8bf58914":"code","080e2504":"code","4d470084":"code","e066c3d1":"code","971fc360":"code","8f01e4e8":"code","3e93e75b":"code","d9c32d4b":"code","bf15f170":"code","5eee2f6a":"code","a79c55c8":"code","8634e338":"code","2a395f26":"code","05180d6d":"code","ee13db48":"code","5bd3e5d0":"code","1a96f373":"markdown","397b9ac3":"markdown","4988251e":"markdown","85e6b3ec":"markdown","57140443":"markdown","2f0391ce":"markdown","7f6d0257":"markdown","9fa38e2e":"markdown","bf44d828":"markdown","20d1e7ab":"markdown","7e2a4c92":"markdown","f78da1ef":"markdown","3249aa1b":"markdown","2e14a41d":"markdown","02b01746":"markdown","bf4c7c09":"markdown","f7d5444e":"markdown","038d4aea":"markdown","ccc1763c":"markdown","c7091569":"markdown","e68cba12":"markdown","f0127410":"markdown","09a41913":"markdown","0c5b047f":"markdown","96f4ef43":"markdown","e73c5579":"markdown","c9db2cd2":"markdown","e7e11a15":"markdown","3823ac37":"markdown","8ecb38c3":"markdown","371695c6":"markdown","1027c5dd":"markdown","af48ddc2":"markdown","782a840b":"markdown","bc6cc879":"markdown","1488134b":"markdown","ac891c10":"markdown","9ee06988":"markdown","3526f6d7":"markdown","88a47567":"markdown","34c59d8e":"markdown","d5064f64":"markdown"},"source":{"3f8b5b3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0235d55e":"df = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ndf.shape, test.shape","419a1ab4":"df_all = df.append(test)\n\ndf_all.shape","768da0d0":"df['Target'].hist(grid = False, bins = 10)","9c0ef24a":"df.Target.value_counts()\/100","22abd062":"df_all.describe().T","71fabd1c":"df_all.select_dtypes('object').head()","cfb2fc04":"df_all['edjefa'].value_counts()","e26cb75a":"mapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","ce3d387d":"df_all.select_dtypes('object').head()","f0e2e0cc":"df_all['dependency'].value_counts()","19cc100a":"df_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","6576b480":"df_all.select_dtypes('object').head()","9521794c":"df_all.isnull().sum().sort_values()","c86bddaa":"data_na = df_all.isnull().sum().values \/ df_all.shape[0] *100\ndf_na = pd.DataFrame(data_na, index=df_all.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_value_count = df_na[df_na['Count']>0].shape[0]\n\nprint(f'We got {missing_value_count} rows which have missing value in train set ')\ndf_na.head(6)\n\n# rez_esc represents \"years behind in school\", missing value could be filled as 0\n# meaneduc represents \"average years of education for adults (18+)\", missing value could be filled as 0\n# v18q1 really depends on v18q\n# v2a1 depends on tipovivi3\n# We do not really need SQBxxxx features for polynomial in our case, and i will use fillna as 0 after at the last step of feature engineering\n","17f41630":"df_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","2ca7a87e":"df_all['v18q'].value_counts()","66c6b972":"df_all['v2a1'].fillna(0, inplace=True)\ndf_all['v18q1'].fillna(0, inplace=True)\ndf_all['rez_esc'].fillna(0, inplace=True)\n","771b3343":"df_all['v2a1'].hist(grid = False, bins = 10)","3742b7c5":"df_all['v18q1'].hist(grid = False, bins = 10)","375bab1f":"df_all.meaneduc.describe().T","2cf0dde0":"df_all.SQBmeaned.describe().T","895ec891":"#df_all.loc[df_all.meaneduc.isnull(), \"meaneduc\"] = 0\n#df_all.loc[df_all.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n\ndf_all['meaneduc'].fillna(df_all['meaneduc'].median(), inplace=True) \ndf_all['SQBmeaned'].fillna(df_all['SQBmeaned'].median(), inplace=True)\n","73b5c2dc":"df_all['meaneduc'].hist(grid = False, bins = 10)","ab333801":"df_all['SQBmeaned'].hist(grid = False, bins = 10)","3933e74b":"df_all.isnull().sum().sort_values()","a66bdc3d":"df_all.fillna(-1, inplace=True)\n","190b998b":"df_all['hsize-pc'] = df_all['hhsize'] \/ df_all['tamviv']\ndf_all['phone-pc'] = df_all['qmobilephone'] \/ df_all['tamviv']\ndf_all['tablets-pc'] = df_all['v18q1'] \/ df_all['tamviv']\ndf_all['rooms-pc'] = df_all['rooms'] \/ df_all['tamviv']\ndf_all['rent-pc'] = df_all['v2a1'] \/ df_all['tamviv']","9ece7860":"\nimport seaborn as sns\n\nvariables = ['Target', 'dependency', 'v2a1', 'v18q1', 'rez_esc', 'meaneduc' ,'SQBmeaned']\n\n# Calculate the correlations\ncorr_mat = df_all[variables].corr().round(2)\n\n# Draw a correlation heatmap\nplt.rcParams['font.size'] = 12\nplt.figure(figsize = (12, 12))\nsns.heatmap(corr_mat, vmin = -0.5, vmax = 0.8, center = 0, \n            cmap = plt.cm.RdYlBu, annot = True);\n\n","1b694c14":"\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","be48ef9f":"train, test = df_all[df_all['Target'] != -1], df_all[df_all['Target'] == -1]","4f318818":"heads = train[train['parentesco1'] == 1]","8bf58914":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n#parameter value is copied from \nclf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                             random_state=None, silent=True, metric='None', \n                             n_jobs=4, n_estimators=700, class_weight='balanced',\n                             colsample_bytree =  0.93, min_child_samples = 95, num_leaves = 14, subsample = 0.96)\n\n\nclf.fit(heads[feats], heads['Target'])\n\naccuracy_score(heads['Target'], clf.predict(heads[feats]))","080e2504":"test['Target'] = clf.predict(test[feats]).astype(int)\n","4d470084":"test['Target'].value_counts(normalize=True)","e066c3d1":"\n#test[['Id', 'Target']].to_csv('submission.csv', index=False)","971fc360":"# Trabalhando com CatBoost\nfrom catboost import CatBoostClassifier\ncbc = CatBoostClassifier(random_state=42)\ncbc.fit(heads[feats], heads['Target'])\naccuracy_score(test['Target'], cbc.predict(test[feats]))","8f01e4e8":"test['Target'] = cbc.predict(test[feats]).astype(int)\ntest['Target'].value_counts(normalize=True)\n#test[['Id', 'Target']].to_csv('submission.csv', index=False)","3e93e75b":"fig=plt.figure(figsize=(15, 20))\n\npd.Series(cbc.feature_importances_, index=feats).sort_values().plot.barh()","d9c32d4b":"\n\nrf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n","bf15f170":"rf.fit(heads[feats], heads['Target'])","5eee2f6a":"test['Target'] = rf.predict(test[feats]).astype(int)","a79c55c8":"test['Target'].value_counts(normalize=True)\n","8634e338":"accuracy_score(heads['Target'], rf.predict(heads[feats]))","2a395f26":"test[['Id', 'Target']].to_csv('submission.csv', index=False)\n","05180d6d":"fig=plt.figure(figsize=(15, 20))\n\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","ee13db48":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.figure(figsize = (10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, size = 18)\n    plt.colorbar(aspect=4)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, size = 12)\n    plt.yticks(tick_marks, classes, size = 12)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    \n    # Labeling the plot\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), fontsize = 16,\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.grid(None)\n    plt.tight_layout()\n    plt.ylabel('True label', size = 12)\n    plt.xlabel('Predicted label', size = 12)\n","5bd3e5d0":"    cm = confusion_matrix(heads['Target'], rf.predict(heads[feats]))\n\n    plot_confusion_matrix(cm, classes = ['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable'],\n                      title = 'Poverty Confusion Matrix')","1a96f373":"* Obserando a coluna dependency","397b9ac3":"* Plotando a Matrix de correla\u00e7\u00e3o","4988251e":"* Prenchendo com \"0\" os valores nulos de: v2a1, v18q1 e rez_esc","85e6b3ec":"* Feature Engineering\n\n* Criando novas colunas para valores percapita","57140443":"* Prenchendo com \"-1\" os valores nulos ainda existentes","2f0391ce":"* Analizando os principais indicadores para SQBmeaned","7f6d0257":"## An\u00e1lise explorat\u00f3ria e tratamento de dados\n\n* Estat\u00edsticas b\u00e1sicas\n* Verificar m\u00ednimos e m\u00e1ximos para garantir se est\u00e3o dentro dos limites esperados\n* Verificar intervalo de varia\u00e7\u00e3o da medida\n* Verificar poss\u00edveis outliers","9fa38e2e":"* Observando as colunas do dataframe que s\u00e3o do tipo object","bf44d828":"* Analizando os principais indicadores para meaneduc","20d1e7ab":"## Carregar e ler dados\n\n* Importanto das bibliotecas necess\u00e1rias\n* Listando os arquivos de banco de dados dispon\u00edvel no diret\u00f3rio input","7e2a4c92":"* Verificando quais vari\u00e1veis ainda possuem nulos","f78da1ef":"* Observando os dados da coluna edjefa\n","3249aa1b":"# MODELOS\n","2e14a41d":"* Plotanto SQBmeaned e analisando distribui\u00e7\u00e3o","02b01746":"Embora todos os membros de uma fam\u00edlia devam ter o mesmo r\u00f3tulo nos dados de treinamento, existem erros onde os indiv\u00edduos na mesma casa t\u00eam r\u00f3tulos diferentes. Nestes casos, somos orientados a usar o r\u00f3tulo do chefe de cada fam\u00edlia, que pode ser identificado pelas linhas onde parentesco1 == 1.0. \n\n* Limitando o treinamento ao chefe da familia\n* Criando um novo dataframe para treinar","bf4c7c09":"* Analisando os valores nulos de cada vari\u00e1vel","f7d5444e":"* Transformando 'yes' em 1 e 'no' em 0\n* Para a coluna dependency","038d4aea":"* Separando as colunas para treinamento","ccc1763c":"* Separando os dataframes","c7091569":"* Treinando o modelo RandomForestClassifier","e68cba12":"## Conclus\u00e3o\n\nEsse desafio foi de grande proveito para a pr\u00e1tica dos conhecimentos adquiridos, pois foi poss\u00edvel aplicar uma solu\u00e7\u00e3o completa de ci\u00eancia de dados para um problema do mundo real. \n\nCaminho percorrido para chegar nessa solu\u00e7\u00e3o:\n* Entendimento do desafio;\n* An\u00e1lise Explorat\u00f3ria de Dados;\n* An\u00e1lise dos dados com problemas e pesquisa de solu\u00e7\u00f5es propostas nos f\u00f3runs de discuss\u00f5es;\n* Preenchimento dos valores ausentes utilizando t\u00e9cnicas de input;\n* Cria\u00e7\u00e3o de novas feactures;\n* Experimento de modelos diferentes para verificar qual apresentava melhor score;\n\nAp\u00f3s aplica\u00e7\u00e3o dos modelos foi poss\u00edvel analisar os resultados, principalmente quais vari\u00e1veis mais influenciavam nos resultados. \n\nCom isso foi poss\u00edvel efetuar novas tentativas com inputs diferenciados para essas vari\u00e1veis em quest\u00e3o, a\u00e7\u00e3o essa que melhorou significativamente os resultados obtidos.\n\n### RESULTADOS\n\nModelo LightGBM\n* Score: 0.37500\n\nModelo CatBoostClassifier\n* Score: 0.37500\n\nModelo RandomForestClassifier\n* Score: 0.44117\n\nA parte mais valiosa do trabalho proposto foi o conhecimento pr\u00e1tico adquirido com a utiliza\u00e7\u00e3o e participa\u00e7\u00e3o efetiva nas competi\u00e7\u00f5es do Kaggle. Foi \u00f3timo desenvolver solu\u00e7\u00f5es realistas como um cientista de dados. \n\n\nMarcilon Cunha.\n","f0127410":"* Verificando quais colunas do dataframe s\u00e3o do tipo object","09a41913":"* Prenchendo com a Mediana os valores nulos de: meaneduc e SQBmeaned","0c5b047f":"* Analisando os valores de aluguel (v2a1) para os chefes\/as de familia (parentesco1 = 1)","96f4ef43":"## RandomForestClassifier\n\n* Instanciando o random forest classifier","e73c5579":"Analisando a vari\u00e1vel TARGET com a base de dados Train.\n\nOs valores Target representam os n\u00edveis de pobreza da seguinte forma:\n\n1 = pobreza extrema;\n\n2 = pobreza moderada;\n\n3 = fam\u00edlias vulner\u00e1veis;\n\n4 = fam\u00edlias n\u00e3o vulner\u00e1veis;\n","c9db2cd2":"* Plotanto v2a1 e analisando distribui\u00e7\u00e3o","e7e11a15":"* Transformando 'yes' em 1 e 'no' em 0\n* Para as colunas edjefa e edjefe","3823ac37":"* Criando o arquivo para submiss\u00e3o","8ecb38c3":"## LightGBM\n\n* Instanciando o LightGBM","371695c6":"* Plotanto meaneduc e analisando distribui\u00e7\u00e3o","1027c5dd":"* Plotanto v18q1 e analisando distribui\u00e7\u00e3o","af48ddc2":"* Observando quais colunas do dataframe s\u00e3o do tipo object","782a840b":"* Analisando as previs\u00f5es para o Target","bc6cc879":"* Prevendo o Target de teste usando o modelo treinado","1488134b":"* Verificar os principais indicadores descritivos","ac891c10":"* Analizando os dados de vari\u00e1vel v18q","9ee06988":"# IESB - Trabalho final - Data Mining e Machine Learning II\n## Marcilon Silva Cunha Alves \n## Matricula: 1931133129\n\n# Previs\u00e3o da situa\u00e7\u00e3o de pobreza Costa-Riquenha\n\nO Banco Interamericano de Desenvolvimento est\u00e1 pedindo \u00e0 comunidade Kaggle ajuda com a qualifica\u00e7\u00e3o de renda para algumas das fam\u00edlias mais pobres do mundo. \n\nNa Am\u00e9rica Latina, um m\u00e9todo popular usa um algoritmo para verificar a qualifica\u00e7\u00e3o de renda. \u00c9 chamado de Teste de M\u00e9dia de Proxy (ou PMT). Com a PMT, as ag\u00eancias usam um modelo que considera os atributos dom\u00e9sticos observ\u00e1veis de uma fam\u00edlia, como o material das paredes e do teto, ou os ativos encontrados na casa para classific\u00e1-los e prever seu n\u00edvel de necessidade.\n\nPara melhorar a PMT, o BID (a maior fonte de financiamento para o desenvolvimento da Am\u00e9rica Latina e do Caribe) recorreu \u00e0 comunidade Kaggle. Eles acreditam que novos m\u00e9todos al\u00e9m da econometria tradicional, com base em um conjunto de dados de caracter\u00edsticas dom\u00e9sticas da Costa Rica, podem ajudar a melhorar o desempenho do PMT.\n\nAl\u00e9m da Costa Rica, muitos pa\u00edses enfrentam o mesmo problema de avaliar incorretamente as necessidades sociais. Se Kagglers puder gerar uma melhoria, o novo algoritmo pode ser implementado em outros pa\u00edses ao redor do mundo.\n","3526f6d7":"* Juntando os dataframes df (treino) e test (teste)","88a47567":"## CatBoostClassifier\n\n* Instanciando o CBC","34c59d8e":"* Plotando e avalisando a import\u00e2ncia de cada coluna (cada vari\u00e1vel de entrada)","d5064f64":"* Carregando os dados de treino e de teste"}}