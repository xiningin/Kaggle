{"cell_type":{"b315bf55":"code","60f43430":"code","d52ec446":"code","17ef8630":"code","35fb7ac3":"code","f9941089":"code","ffea6a21":"code","5c4a1460":"code","05bcc030":"code","32cc6a67":"code","aa1437cc":"code","fa34da1d":"code","e4cafae2":"code","57fbd7f1":"code","876a9000":"code","a823b88a":"code","594ac976":"code","b57d8b06":"code","4ef6b1c5":"code","26750780":"code","789e2b32":"code","7609a23b":"code","da15dd0a":"code","24593ba0":"code","b55303a6":"code","5ca46518":"code","21865a7c":"code","1b08ae0e":"code","f7f3396f":"code","42df7d34":"markdown","95aba166":"markdown","c742f592":"markdown","1d736f42":"markdown","ec8eac5f":"markdown","30197503":"markdown"},"source":{"b315bf55":"import os\nimport cv2\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, cohen_kappa_score\nfrom keras.models import Model\nfrom keras import optimizers, applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\nimport tensorflow as tf\n\nfrom keras.applications import inception_v3\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    #set_random_seed(0)\nseed_everything()\n\n%matplotlib inline\nsns.set(style=\"whitegrid\")\nwarnings.filterwarnings(\"ignore\")","60f43430":" #This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# # You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d52ec446":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import regularizers, optimizers\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","17ef8630":"os.chdir('\/kaggle\/input')\n!ls","35fb7ac3":"os.getcwd()","f9941089":"df=pd.read_csv('blindness\/extra_info.csv')","ffea6a21":"df['diagnosis'] = df['diagnosis'].astype('str')\ndf.describe()","5c4a1460":"df","05bcc030":"df = df.sample(frac=1).reset_index(drop=True)\ndf.head(10)","32cc6a67":"x_col=\"id_code\"\ny_col=\"diagnosis\"","aa1437cc":"x_col=\"id_code\"\ny_col=\"diagnosis\"\n\ndatagen=ImageDataGenerator(rescale=1.\/255,validation_split=0.15)\ntrain_generator=datagen.flow_from_dataframe(dataframe=df,directory=\"\/kaggle\/input\/blindness\/dataset\/\",x_col=x_col,y_col=y_col,\n                                subset=\"training\",batch_size=16,seed=42,shuffle=True,class_mode=\"categorical\",target_size=(300,300))\nvalid_generator=datagen.flow_from_dataframe(dataframe=df,directory=\"\/kaggle\/input\/blindness\/dataset\/\",x_col=x_col,y_col=y_col,\n                                subset=\"validation\",batch_size=16,seed=42,shuffle=True,class_mode=\"categorical\",target_size=(300,300))","fa34da1d":"os.chdir('\/kaggle\/input\/')\n","e4cafae2":"testdf=pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv',dtype=str)\ntestdf.head()","57fbd7f1":"def append_ext(fn):\n    return fn+\".png\"\ntestdf[\"id_code\"]=testdf[\"id_code\"].apply(append_ext)\n","876a9000":"testdf","a823b88a":"os.chdir('\/kaggle\/input\/aptos2019-blindness-detection\/test_images\/')\ntest_datagen=ImageDataGenerator(rescale=1.\/255.)\ntest_generator=test_datagen.flow_from_dataframe(\ndataframe=testdf,\ndirectory=\"\/kaggle\/input\/aptos2019-blindness-detection\/test_images\/\",\nx_col=\"id_code\",\ny_col=None,\nbatch_size=32,\nseed=42,\nshuffle=False,\nclass_mode=None,\ntarget_size=(300, 300))\n","594ac976":"import numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nimport keras\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\nimport tensorflow as tf\nimport keras.backend as K\n","b57d8b06":"def kappa_loss(y_pred, y_true, y_pow=2, eps=1e-10, N=5, bsize=16, name='kappa'):\n    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n        Args:\n            y_pred: 2D tensor or array, [batch_size, num_classes]\n            y_true: 2D tensor or array,[batch_size, num_classes]\n            y_pow: int,  e.g. y_pow=2\n            N: typically num_classes of the model\n            bsize: batch_size of the training or validation ops\n            eps: a float, prevents divide by zero\n            name: Optional scope\/name for op_scope.\n        Returns:\n            A tensor with the kappa loss.\"\"\"\n\n \n\n    with tf.name_scope(name):\n        y_true = tf.cast(y_true,dtype=tf.float32)\n        repeat_op = tf.cast(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]),dtype=tf.float32)\n        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n        weights = repeat_op_sq \/ tf.cast((N - 1) ** 2,dtype=tf.float32)\n    \n        pred_ = y_pred ** y_pow\n        try:\n            pred_norm = pred_ \/ (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n        except Exception:\n            pred_norm = pred_ \/ (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n    \n        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n        hist_rater_b = tf.reduce_sum(y_true, 0)\n    \n        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n    \n        nom = tf.reduce_sum(weights * conf_mat)\n        denom = tf.reduce_sum(weights * tf.matmul(\n            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) \/\n                              tf.cast(bsize,dtype=tf.float32))\n    \n        return nom \/ (denom + eps)","4ef6b1c5":"from keras.models import model_from_json","26750780":"\nos.chdir('\/kaggle\/working')\njson_file = open('\/kaggle\/working\/model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\nloaded_model.load_weights(\"model.h5\")","789e2b32":"# add new classifier layers\nflat1 =  GlobalAveragePooling2D()(loaded_model.output)\n\nclass2=Dense(64, activation='relu')(flat1)\noutput = Dense(5, activation='softmax')(class2)\n# define new model\nmodel = Model(inputs=loaded_model.inputs, outputs=output)\n# summarize\nmodel.summary()","7609a23b":"\n# instantiating the model in the strategy scope creates the model on the TPU\n\nmodel.compile(optimizer=keras.optimizers.Adam(),\n                  loss=keras.losses.CategoricalCrossentropy(),\n                  metrics=[kappa_loss,keras.metrics.CategoricalAccuracy()])\nmodel.fit_generator(train_generator,steps_per_epoch=3000\/20  ,epochs=15,\n                                  validation_data=valid_generator)\n","da15dd0a":"import gc \ngc.collect()\n","24593ba0":"test_generator.reset()\npred=loaded_model.predict_generator(test_generator)\n","b55303a6":"predicted_class_indices=np.argmax(pred,axis=1)","5ca46518":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","21865a7c":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"id_code\":filenames,\n                      \"diagnosis\":predictions})\n","1b08ae0e":"os.chdir('\/kaggle\/working')","f7f3396f":"results.to_csv(\"submission.csv\",index=False)","42df7d34":"def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    quadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              \/ num_scored_items)\n            d = pow(i - j, 2.0) \/ pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] \/ num_scored_items\n            denominator += d * expected_count \/ num_scored_items\n\n    return 1.0 - numerator \/ denominator\n","95aba166":"optR = OptimizedRounder()\noptR.fit(valid_predictions, targets)\ncoefficients = optR.coefficients()\nvalid_predictions = optR.predict(valid_predictions, coefficients)\ntest_predictions = optR.predict(test_predictions, coefficients)\n","c742f592":"import numpy as np\nfrom sklearn.metrics import cohen_kappa_score\n\nimport keras.backend as K\nimport tensorflow as tf\n\n\ndef kappa_keras(y_true, y_pred):\n\n    y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')\n    y_pred = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n\n    # Figure out normalized expected values\n    min_rating = K.minimum(K.min(y_true), K.min(y_pred))\n    max_rating = K.maximum(K.max(y_true), K.max(y_pred))\n\n    # shift the values so that the lowest value is 0\n    # (to support scales that include negative values)\n    y_true = K.map_fn(lambda y: y - min_rating, y_true, dtype='int32')\n    y_pred = K.map_fn(lambda y: y - min_rating, y_pred, dtype='int32')\n\n    # Build the observed\/confusion matrix\n    num_ratings = max_rating - min_rating + 1\n    observed = tf.confusion_matrix(y_true, y_pred,\n                                num_classes=num_ratings)\n    num_scored_items = K.shape(y_true)[0]\n\n    weights = K.expand_dims(K.arange(num_ratings), axis=-1) - K.expand_dims(K.arange(num_ratings), axis=0)\n    weights = K.cast(K.pow(weights, 2), dtype='float64')\n\n    hist_true = tf.math.bincount(y_true, minlength=num_ratings)\n    hist_true = hist_true[:num_ratings] \/ num_scored_items\n    hist_pred = tf.math.bincount(y_pred, minlength=num_ratings)\n    hist_pred = hist_pred[:num_ratings] \/ num_scored_items\n    expected = K.dot(K.expand_dims(hist_true, axis=-1), K.expand_dims(hist_pred, axis=0))\n\n    # Normalize observed array\n    observed = observed \/ num_scored_items\n\n    # If all weights are zero, that means no disagreements matter.\n    score = tf.where(K.any(K.not_equal(weights, 0)), \n                     K.sum(weights * observed) \/ K.sum(weights * expected), \n                     0)\n    \n    return 1. - score\n\n","1d736f42":"os.chdir('\/kaggle\/working')\nmodel_json = base_model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nbase_model.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n \n","ec8eac5f":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","30197503":"# example of tending the vgg16 model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\n# load model without classifier layers\nbase_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(300, 300, 3))\n\nbase_model.trainable = False\n"}}