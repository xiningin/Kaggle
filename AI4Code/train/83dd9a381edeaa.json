{"cell_type":{"8ecd4bb5":"code","b2a1bb35":"code","2ce49469":"code","83f48104":"code","1f592069":"code","d1fd2d99":"code","21649344":"code","e3451cd5":"code","9a29c08f":"code","555782fc":"code","09adb33f":"code","1763d863":"code","bf8cfd4b":"code","5afba907":"code","db7a5469":"code","1c88d923":"code","603d758b":"code","644cbbfc":"code","3f64c3e1":"code","843a0c0c":"code","434b4e25":"code","2f0d79b0":"code","7a59a438":"code","85075a90":"code","82f06b5c":"code","36bb979c":"code","e8e4de08":"code","399ca212":"code","17f2ac99":"code","da43f38f":"code","b8bf4054":"code","08f900b6":"code","fa2fe7a6":"code","51a0b7d4":"code","8b10ec41":"code","b83ed5c7":"code","7021ed1d":"markdown","6980e82f":"markdown"},"source":{"8ecd4bb5":"import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","b2a1bb35":"df = pd.read_csv('..\/input\/articles\/articles.csv')","2ce49469":"df.head()","83f48104":"df.isnull().sum() ## Check for empty data","1f592069":"df['Article'][1029]","d1fd2d99":"len(df)","21649344":"from sklearn.feature_extraction.text import CountVectorizer\ncvr = CountVectorizer(max_df=0.9, min_df=2, stop_words='english') \n# max_df = discard 90% of the words that are common in all documents\/rows\n# min_df = check freq of a word so that it should be common in atleast 2 documents","e3451cd5":"dtm = cvr.fit_transform(df['Article'])","9a29c08f":"dtm","555782fc":"from sklearn.decomposition import LatentDirichletAllocation\nimport torch\ntorch.cuda.is_available()","09adb33f":"if torch.cuda.is_available():  \n  dev = \"cuda:0\" \nelse:  \n  dev = \"cpu\"\n\ndevice = torch.device(dev)","1763d863":"LDA = LatentDirichletAllocation(n_components=7, random_state=42) # n_components = Topics","bf8cfd4b":"LDA","5afba907":"LDA.fit(dtm).to(device)","db7a5469":"print(f'{\"DONE FINALLY!!!!!!\"}')","1c88d923":"# Grab vocabulary of words\nlen(cvr.get_feature_names())","603d758b":"type(cvr.get_feature_names())","644cbbfc":"cvr.get_feature_names()[1029]","3f64c3e1":"## We can import any random words from the list(54777)\nimport random\n\nrandom_word_id = random.randint(0, 54777)\ncvr.get_feature_names()[random_word_id]","843a0c0c":"# Grab the topics\nlen(LDA.components_)## checking the length of components\/topics","434b4e25":"type(LDA.components_) ## Just a numpy array containing probabilities of each word","2f0d79b0":"# Grab single topic out of those 7 components\nsingle_topic = LDA.components_[0] # grabbing very first topic","7a59a438":"single_topic.argsort() # returns index position to sort the array from lowest value to highest value","85075a90":"## example how argsort() works\nimport numpy as np\n\narr = np.array([5, 100, 23, 1])\nprint(f'Simple array:- {arr}')\nprint(f'Argsort:- {arr.argsort()}') ## will return index value of the numbers in an ascending order","82f06b5c":"# Let's grab top 10 values (top 10 greatest values) from single_topic using argsort()\n\nsingle_topic.argsort()[-10:] ## since argsort() works in ascending order, hence, [-10:] is bringing last 10 greatest values","36bb979c":"top_10_words = single_topic.argsort()[-10:]","e8e4de08":"for index in top_10_words:\n    print(cvr.get_feature_names()[index])","399ca212":"# The above was for first topic. Let's do it for 3rd topic and grab top 20 words\nthird_topic = LDA.components_[2]\nthird_topic.argsort()\ntop_20_words_in_3rd = third_topic.argsort()[-20:]\n\nfor i in top_20_words_in_3rd:\n    print(cvr.get_feature_names()[i])","17f2ac99":"# Grab the highest probability words per topic\nfor i, topic in enumerate(LDA.components_):\n    print(f'TOP 15 WORDS FOR TOPIC #{i}')\n    print([cvr.get_feature_names()[index] for index in topic.argsort()[-15:]])\n    print('\\n\\n')","da43f38f":"topic_results = LDA.transform(dtm)","b8bf4054":"topic_results","08f900b6":"topic_results.shape","fa2fe7a6":"# Probabilities belonging to a particular topic\nprint(topic_results[0])\n\nprint(f'-------------------------------------------------------------')\n# Percentages in a rounded off form\nprint(topic_results[0].round(2))","51a0b7d4":"# Getting index position of the highest probability\ntopic_results[0].argmax()","8b10ec41":"df['Topics'] = topic_results.argmax(axis=1)","b83ed5c7":"df ## which all rows of article data are under general topics","7021ed1d":"`Let's perform Latent Dirichlet Allocation using Scikit-Learn`","6980e82f":"> `Applying un-supervised learning`"}}