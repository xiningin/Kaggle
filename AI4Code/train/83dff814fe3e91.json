{"cell_type":{"60cb4bd5":"code","b9a0b87b":"code","16b3ad37":"code","a932d401":"code","38eb7270":"code","fd94e85a":"code","585f5ba7":"code","ce84d075":"code","a5035f4c":"code","c473d46a":"code","8df29f6f":"code","fe6ead28":"code","cc748ea2":"code","618ad2b3":"code","4e22263d":"code","d08e032b":"code","ad8834bf":"code","6f48db60":"code","530113dd":"code","ae69a512":"code","abe5b7b0":"code","6221bdaa":"code","b2a4f95f":"code","94c43a52":"code","4cca6594":"code","d9461b77":"code","631eff45":"markdown","3f9c2716":"markdown","f95d5238":"markdown"},"source":{"60cb4bd5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#import visulization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9a0b87b":"train_path =\"..\/input\/30-days-of-ml\/train.csv\"\ntest_path= \"..\/input\/30-days-of-ml\/test.csv\"\nsample_submission_path= \"..\/input\/30-days-of-ml\/sample_submission.csv\"","16b3ad37":"train = pd.read_csv(train_path,index_col=0)\ntest = pd.read_csv(test_path,index_col=0)\nsample_submission = pd.read_csv(sample_submission_path)","a932d401":" #print shape of all three dataset avaiable to us\n print(train.shape)\n print(test.shape)\n print(sample_submission.shape)","38eb7270":" #read first 5 rows of train dataset\n train.head(5)","fd94e85a":"#checking null values of train and test data\ntrain.isnull().sum().sum(),test.isnull().sum().sum()","585f5ba7":"#let's get statistical quick look to data\ntrain.describe()","ce84d075":"#Getting more info about data\ntrain.info()","a5035f4c":"# Get list of categorical variables\ns = (train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","c473d46a":"#get list of numrical variables\ns = (train.dtypes == 'float64')\nnum_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(num_cols)","8df29f6f":"fig,axes = plt.subplots(1,1,figsize=(16,14))\nsns.heatmap(train.corr(),annot=True)\nplt.show()","fe6ead28":"#scatter plot between Target and cont12\nplt.scatter(train['cont12'], train['target'], alpha=0.5)\nplt.title('Scatter plot of Target with cont12')\nplt.xlabel('cont12')\nplt.ylabel('Target')\nplt.show()","cc748ea2":"#scatter plot between Target and cont13\nplt.scatter(train['cont13'], train['target'], alpha=0.5)\nplt.title('Scatter plot of Target with cont13')\nplt.xlabel('cont13')\nplt.ylabel('Target')\nplt.show()","618ad2b3":"#Select target variable\ndependent_variable = train['target']\n","4e22263d":"#Select features on which target value depend\nindependent_variables= train.drop('target',axis=1)","d08e032b":"#Print head of independent variables\nindependent_variables.head()","ad8834bf":"# assign y for dependent and X for independent variable for our ease\ny = dependent_variable\nX = independent_variables.copy()\n\n#assign X_test for test for ease\nX_test =test.copy()","6f48db60":"#Get all Categorical column of Train data\ncategorical_col = [col for col in independent_variables.columns if 'cat'in col]\ncategorical_col","530113dd":"# converting Categorical variable into numric by using Ordinal Encoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\nencoder_ordnl = OrdinalEncoder()\n\nX[categorical_col] = encoder_ordnl.fit_transform(independent_variables[categorical_col])\nX_test[categorical_col] = encoder_ordnl.transform(test[categorical_col])","ae69a512":"#print head of  ordinal-encoded features of X\nX.head(2)","abe5b7b0":"#print head of  ordinal-encoded features of X_test\nX_test.head(2)","6221bdaa":"#split the data in X_train, X_test, y_train, y_test\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,random_state=0)","b2a4f95f":"from xgboost import XGBRegressor\n\nxgb_model =XGBRegressor(random_state=1)\nxgb_model.fit(X_train,y_train)\npredict_y_xgb = xgb_model.predict(X_valid)\nprint(mean_squared_error(predict_y_xgb,y_valid,squared=False))\n\n#result 0.7268784689736293  without tuning","94c43a52":"#it takes very less time in  comparison to XGboost without GPU and Error also reduced to 0.7216. \nfrom xgboost import XGBRegressor\n\nxgb_model = XGBRegressor(random_state=1, \n                         n_jobs=4,\n                         n_estimators= 5000,\n                         tree_method='gpu_hist',\n                         learning_rate= 0.01,\n                         subsample= 0.9,\n                         max_depth= 5,\n                         colsample_bytree= 0.5,\n                         reg_alpha = 30,eval_metric='rmse')\n#xgb_model =XGBRegressor(random_state=1)\nxgb_model.fit(X_train,y_train)\npredict_y_xgb = xgb_model.predict(X_valid)\nprint(mean_squared_error(predict_y_xgb,y_valid,squared=False))\n\n#result 0.721601537976836  with tuning and GPU","4cca6594":"# Use the model to generate predictions\npredictions = xgb_model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","d9461b77":"pd.DataFrame(predictions).shape","631eff45":"# Train Model","3f9c2716":"## XGBoost With Hyperparameter And GPU","f95d5238":"## XGBoost Without Hyperparameter"}}