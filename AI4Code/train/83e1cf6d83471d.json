{"cell_type":{"ee3c46af":"code","fe5618d1":"code","a3714c68":"code","79cd98b2":"code","84c6f641":"code","15d97418":"code","08bc119c":"code","e2cafa4f":"code","c0d25d50":"code","e1aa720a":"code","1b4ae8a8":"code","2e900e19":"code","4568efbc":"code","ab2f9e36":"code","9f959d87":"code","8649fe1a":"code","a2a40e31":"code","4fc8b7ed":"code","7c5c8d0e":"code","928b552d":"code","c9995c7d":"code","f5e72347":"code","cb93626e":"code","76c8a6e0":"code","7232f95b":"code","6e42d021":"code","50209592":"code","457c9c6a":"code","5f18ec98":"code","feceb01b":"code","e36abb78":"code","5349e47c":"code","f5cb3d6e":"code","7f743d26":"code","68964f64":"code","1db6db5a":"code","7b013961":"code","aa77f645":"code","1af96c32":"markdown","04a0b149":"markdown","63efd0d6":"markdown","c0681fde":"markdown","83e5fdc9":"markdown","fde6f43e":"markdown","3ac85e66":"markdown","c48a4f68":"markdown","b40b9e86":"markdown","7abd52ab":"markdown","5aefc0bc":"markdown","0cd076ba":"markdown","18b81835":"markdown","9122f801":"markdown","b4e1d4da":"markdown","e6b26571":"markdown","09ecdaa2":"markdown","4efb0ec1":"markdown","dec8d6ff":"markdown"},"source":{"ee3c46af":"# Import necessary packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score","fe5618d1":"data = pd.read_csv('..\/input\/cap-4611-spring-21-assignment-1\/train.csv')\ndata.head()","a3714c68":"# Calculate the number of missing values\nprint('Number of Missing Values:', data.isnull().sum().sum())","79cd98b2":"# Calculate the number of outliers per feature\nquantiles = data.iloc[:, 2:].quantile([.25, .75]).transpose()\noutliers = pd.DataFrame({\n    'Lower Threshold' : quantiles[0.25] - (1.5 * (quantiles[0.75] - quantiles[0.25])),\n    'Upper Threshold' : quantiles[0.75] + (1.5 * (quantiles[0.75] - quantiles[0.25])),\n    'Outliers' : 0\n})\n\nfor column in data.iloc[:, 2:].columns:\n    lval = outliers.at[column, 'Lower Threshold']\n    uval = outliers.at[column, 'Upper Threshold']\n    outliers.at[column, 'Outliers'] = sum(data[column] < lval) + sum(data[column] > uval)\n\noutliers","84c6f641":"# Clamp Transformation\nclamp_data = data.iloc[:, :]\n\nfor column in data.iloc[:, 2:].columns:\n    clamp_data[column] = np.maximum(clamp_data[column], outliers.at[column, 'Lower Threshold'])\n    clamp_data[column] = np.minimum(clamp_data[column], outliers.at[column, 'Upper Threshold'])\n    \n# Sanity Check\nfor column in data.iloc[:, 2:].columns:\n    lval = outliers.at[column, 'Lower Threshold']\n    uval = outliers.at[column, 'Upper Threshold']\n    total_outliers = sum(clamp_data[column] < lval) + sum(clamp_data[column] > uval)\n    outliers.at[column, 'Outliers'] = total_outliers\n\nprint('Total number of outliers after clamp transformation:', sum(outliers['Outliers']))","15d97418":"SEED = 42\n\n# Create feature, target arrays, training set and hold-out set for unclamped data\nX = data.drop(['id', 'Bankrupt'], axis=1).values\ny = data['Bankrupt'].values\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=.3, random_state=SEED, stratify=y)\n\n# Create feature, target arrays, training set and hold-out set for clamped data\nCX = clamp_data.drop(['id', 'Bankrupt'], axis=1).values\ncy = clamp_data['Bankrupt'].values\nCX_train, CX_test, cy_train, cy_test = train_test_split(\n    CX, cy, test_size=.3, random_state=SEED, stratify=y)","08bc119c":"def get_model_performance(X_test, y_test, model, label):\n    y_pred = model.predict(X_test)\n    y_pred_prob = model.predict_proba(X_test)[:,1]\n    \n    roc_auc = roc_auc_score(y_test, y_pred_prob)\n    f1 = f1_score(y_test, y_pred)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    print(label, 'ROC AUC Score:', roc_auc)\n    print(label, 'F1 Score:', f1)\n    print(label, 'Accuracy Score:', accuracy)","e2cafa4f":"def train_decision_tree_model(X_train, X_test, y_train, y_test, label):\n    # Train model\n    dt = DecisionTreeClassifier()\n    dt.fit(X_train, y_train)\n    \n    #Check performance\n    get_model_performance(X_test, y_test, dt, label)\n    \n    # Return model\n    return dt","c0d25d50":"# Benchmark Decision Tree Model for Unclamped Data\nunclamped_dt_benchmark = train_decision_tree_model(\n    X_train, X_test, y_train, y_test, 'Benchmark Decision Tree')","e1aa720a":"# Benchmark Decision Tree Model for Clamped Data\nclamped_dt_benchmark = train_decision_tree_model(\n    CX_train, CX_test, cy_train, cy_test, 'Clamped Benchmark Decision Tree')","1b4ae8a8":"def hypertune_decision_tree_model(X_train, X_test, y_train, y_test, parameters, label):\n    # Train model\n    dt = DecisionTreeClassifier()\n    grid_dt = GridSearchCV(dt, parameters, scoring='roc_auc', cv=10, n_jobs=-1)\n    grid_dt.fit(X_train, y_train)\n    \n    # Get the best set of parameters and score\n    best_parameters = grid_dt.best_params_\n    best_score = grid_dt.best_score_\n    \n    print(label, 'Best Decision Tree Parameters:', best_parameters)\n    print(label, 'Best Decision Tree ROC AUC Score:', best_score)\n    \n    # Return model\n    return grid_dt","2e900e19":"parameter_grid = {\n    'criterion':['gini', 'entropy'], \n    'max_depth':[3, 4, 5, 6, 7], \n    'min_samples_leaf':[5, 6, 8, 10, 12]}\n\n# Hypertuned Decision Tree Model for Unclamped Data, Min Samples Leaf as Integer\nunclamped_dt_hypertuned_int = hypertune_decision_tree_model(\n    X_train, X_test, y_train, y_test, parameter_grid, \n    'Hypertuned, Min Samples Leaf as Integer - ')","4568efbc":"# Hypertuned Decision Tree Model for Clamped Data, Min Samples Leaf as Integer\nclamped_dt_hypertuned_int = hypertune_decision_tree_model(\n    CX_train, CX_test, cy_train, cy_test, parameter_grid, \n    'Clamped Hypertuned, Min Samples Leaf as Integer - ')","ab2f9e36":"parameter_grid = {\n    'criterion':['gini', 'entropy'], \n    'max_depth':[3, 4, 5, 6, 7], \n    'min_samples_leaf':[0.1, 0.2, 0.3, 0.4, 0.5]}\n\n# Hypertuned Decision Tree Model for Unclamped Data, Min Samples Leaf as %\nunclamped_dt_hypertuned_perc = hypertune_decision_tree_model(\n    X_train, X_test, y_train, y_test, parameter_grid, \n    'Hypertuned, Min Samples Leaf as % - ')","9f959d87":"# Hypertuned Decision Tree Model for Clamped Data, Min Samples Leaf as %\nclamped_dt_hypertuned_perc = hypertune_decision_tree_model(\n    CX_train, CX_test, cy_train, cy_test, parameter_grid, \n    'Clamped Hypertuned, Min Samples Leaf as % - ')","8649fe1a":"parameter_grid = {\n    'criterion':['gini', 'entropy'], \n    'max_depth':[3, 4, 5, 6, 7],\n    'min_samples_leaf':[0.1, 0.2, 0.3, 0.4, 0.5],\n    'min_samples_split':[0.1, 0.15, 0.2, 0.25, 0.3]}\n\n# Hypertuned Decision Tree Model for Unclamped Data\nunclamped_dt_hypertuned = hypertune_decision_tree_model(\n    X_train, X_test, y_train, y_test, parameter_grid, 'Hypertuned - ')","a2a40e31":"# Hypertuned Decision Tree Model for Clamped Data\nclamped_dt_hypertuned = hypertune_decision_tree_model(\n    CX_train, CX_test, cy_train, cy_test, parameter_grid, 'Clamped Hypertuned - ')","4fc8b7ed":"# Get the best models\nunclamped_dt_hypertuned_model = unclamped_dt_hypertuned.best_estimator_\nclamped_dt_hypertuned_model = clamped_dt_hypertuned.best_estimator_\n\n# Check performance\nget_model_performance(\n    X_test, y_test, unclamped_dt_hypertuned_model, \"Hypertuned Decision Tree\")\n\nget_model_performance(\n    CX_test, cy_test, clamped_dt_hypertuned_model, \"Clamped Hypertuned Decision Tree\")","7c5c8d0e":"def train_random_forest_model(X_train, X_test, y_train, y_test, label):\n    # Train model\n    rf = RandomForestClassifier()\n    rf.fit(X_train, y_train)\n    \n    #Check performance\n    get_model_performance(X_test, y_test, rf, label)\n    \n    # Return model\n    return rf","928b552d":"# Benchmark Random Forest Model for Unclamped Data\nunclamped_rf_benchmark = train_random_forest_model(\n    X_train, X_test, y_train, y_test, 'Benchmark Random Forest')","c9995c7d":"# Benchmark Random Forest Model for Clamped Data\nclamped_rf_benchmark = train_random_forest_model(\n    CX_train, CX_test, cy_train, cy_test, 'Clamped Benchmark Random Forest')","f5e72347":"def hypertune_random_forest_model(X_train, X_test, y_train, y_test, parameters, label):\n    # Train model\n    rf = RandomForestClassifier()\n    grid_rf = GridSearchCV(rf, parameters, scoring='roc_auc', cv=10, n_jobs=-1)\n    grid_rf.fit(X_train, y_train)\n    \n    # Get the best set of parameters and score\n    best_parameters = grid_rf.best_params_\n    best_score = grid_rf.best_score_\n    \n    print(label, 'Best Random Forest Parameters:', best_parameters)\n    print(label, 'Best Random Forest ROC AUC Score:', best_score)\n    \n    # Return model\n    return grid_rf","cb93626e":"def plot_random_forest_parameter(X_train, X_test, y_train, y_test, parameters):\n    parameter_label, parameter_values = parameters\n    training_roc_auc = np.empty(len(parameter_values))\n    test_roc_auc = np.empty(len(parameter_values))\n\n    for i, param in enumerate(parameter_values):\n        model_param = {parameter_label:param}\n\n        rf = RandomForestClassifier(**model_param)\n        rf.fit(X_train, y_train)\n\n        y_pred_prob_train = rf.predict_proba(X_train)[:, 1]\n        training_roc_auc[i] = roc_auc_score(y_train, y_pred_prob_train)\n\n        y_pred_prob_test = rf.predict_proba(X_test)[:, 1]\n        test_roc_auc[i] = roc_auc_score(y_test, y_pred_prob_test)\n    \n    plt.title('ROC AUC: Varying ' + parameter_label)\n    plt.plot(parameter_values, test_roc_auc, label = 'Testing ROC AUC')\n    plt.plot(parameter_values, training_roc_auc, label = 'Training ROC AUC')\n    plt.legend()\n    plt.xlabel('Number of ' + parameter_label)\n    plt.ylabel('ROC AUC')\n    plt.show()","76c8a6e0":"# Test Varying n_estimators for Unclamped Data\nplot_random_forest_parameter(\n    X_train, X_test, y_train, y_test, \n    ('n_estimators', [200, 400, 600, 800, 1000]))","7232f95b":"# Test Varying n_estimators for Clamped Data\nplot_random_forest_parameter(\n    CX_train, CX_test, cy_train, cy_test, \n    ('n_estimators', [200, 400, 600, 800, 1000]))","6e42d021":"# Test Varying max_depths for Unclamped Data\nplot_random_forest_parameter(\n    X_train, X_test, y_train, y_test, \n    ('max_depth', [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]))","50209592":"# Test Varying max_depths for Clamped Data\nplot_random_forest_parameter(\n    CX_train, CX_test, cy_train, cy_test, \n    ('max_depth', [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]))","457c9c6a":"# Test Varying min_samples_split for Unclamped Data\nplot_random_forest_parameter(\n    X_train, X_test, y_train, y_test, \n    ('min_samples_split', [.1, .2, .3, .4, .5, .6, .7, .8, .9]))","5f18ec98":"# Test Varying min_samples_split for Unclamped Data\nplot_random_forest_parameter(\n    X_train, X_test, y_train, y_test, \n    ('min_samples_split', [2, 4, 6, 8, 10, 12, 14, 16]))","feceb01b":"# Test Varying min_samples_split for Clamped Data\nplot_random_forest_parameter(\n    CX_train, CX_test, cy_train, cy_test, \n    ('min_samples_split', [.1, .2, .3, .4, .5, .6, .7, .8, .9]))","e36abb78":"# Test Varying min_samples_split for Clamped Data\nplot_random_forest_parameter(\n    CX_train, CX_test, cy_train, cy_test, \n    ('min_samples_split', [2, 4, 6, 8, 10, 12, 14, 16]))","5349e47c":"# Test Varying min_samples_leaf for Unclamped Data\nplot_random_forest_parameter(\n    X_train, X_test, y_train, y_test, \n    ('min_samples_leaf', [2, 4, 6, 8, 10, 12, 14, 16]))","f5cb3d6e":"# Test Varying min_samples_leaf for Clamped Data\nplot_random_forest_parameter(\n    CX_train, CX_test, cy_train, cy_test, \n    ('min_samples_leaf', [2, 4, 6, 8, 10, 12, 14, 16]))","7f743d26":"parameter_grid = {\n    'n_estimators': [400, 600, 800],\n    'max_depth': [5, 10, 15, 20, 25],\n    'max_features': ['log2', 'sqrt'],\n    'min_samples_split': [2, 4, 6],\n    'min_samples_leaf': [1, 4, 6, 8]}\n\n# Hypertuned Random Forest Model for Unclamped Data\nunclamped_rf_hypertuned = hypertune_random_forest_model(X_train, X_test, y_train, y_test, \n                                                        parameter_grid, 'Hypertuned Random Forest - ')","68964f64":"# Hypertuned Random Forest Model for Clamped Data\nclamped_rf_hypertuned = hypertune_random_forest_model(CX_train, CX_test, cy_train, cy_test, \n                                                        parameter_grid, 'Clamped Hypertuned Random Forest - ')","1db6db5a":"# Get the best models\nunclamped_rf_hypertuned = unclamped_rf_hypertuned.best_estimator_\nclamped_rf_hypertuned = clamped_rf_hypertuned.best_estimator_\n\n# Check performance\nget_model_performance(X_test, y_test, unclamped_rf_hypertuned, \"Hypertuned Random Forest\")\nget_model_performance(CX_test, cy_test, clamped_rf_hypertuned, \"Clamped Hypertuned Random Forest\")","7b013961":"test_data = pd.read_csv(\"..\/input\/cap-4611-spring-21-assignment-1\/test.csv\")\ntest_data.head()","aa77f645":"X_comptest = test_data.drop(['id'], axis=1).values\npredictions_prob = unclamped_rf_hypertuned.predict_proba(X_comptest)[:,1]\noutput = pd.DataFrame({\"id\": test_data[\"id\"], \"Bankrupt\": predictions_prob})\noutput.to_csv(\"danny-vail-cap4611-assignment-1-submission.csv\", index=False)\noutput","1af96c32":"## The Preamble\n\nLoading up the training dataset and verifying that it has correctly loaded.","04a0b149":"#### Benchmark Models\n\nWe'll similarly train random forest models like our decision trees: we'll train two initial random forest models with default parameters to serve as a baseline for improvement. To measure their performance, we will calculate the ROC AUC, F1, and Accuracy Score.","63efd0d6":"#### Outliers\n\nWe can check for outliers by examining the min and max values for each feature or the interquartile range. We lack the domain knowledge necessary to determine whether the min and max values out of the ordinary, so we will use the interquartile range.\n\nThe interquartile range is the difference between the 75th and 25th percentile:\n\n$$\nIQR = Q_3 - Q_1\n$$\n\nWe will label a value as an outlier if it is lower than the 25th percentile minus 1.5 times the interquartile range or if it is greater than the 75th percentile plus 1.5 times the interquartile range:\n\n$$\nOutlier < Q_1 - 1.5IQR \\\\\nOutlier > Q_3 + 1.5IQR\n$$","c0681fde":"#### Hyperparameter Tuned Models\n\nThere are multiple parameters that we can adjust to improve the performance of our decision tree model, including:\n\n- **Criterion**: We can split nodes using the Gini Index or Information Gain.\n- **Max_depth**: We can prevent the tree from growing too deep. If our tree has too many levels, we risk overfitting. Too few levels, and we risk underfitting.\n- **Min_samples_leaf**: We can increase the minimum number of samples required at each leaf node and prevent the tree from overfitting the data. The min_samples_leaf can be integers or percentages.\n\nLet's test with integers and percentages for `min_samples_leaf`.","83e5fdc9":"### Random Forest Model","fde6f43e":"#### The Best Random Forest Model","3ac85e66":"**Takeaway**\n\n- **N_estimators**: Saw improvements in metrics up until around 600 then gains weren't as great for the processing hit. Will skip the lower numbers and cut off at 800.\n- **Max_depth**: Saw dips in metrics after 40-45. Best to keep tree shorter. Cap max depth at 25.\n- **Min_samples_split**: Easier to tune with integers vs percentages. Peaks at lower numbers before slowing rising with larger numbers. Cap at 6.\n- **Min_samples_leaf**: Values of 4-8 seem to be sweet spots.","c48a4f68":"#### Benchmark Models\n\nWe will train two initial decision trees with default parameters to serve as a baseline for improvement. To measure their performance, we will calculate the ROC AUC, F1, and Accuracy Score.","b40b9e86":"We have a couple of options for handling these outliers. Since we lack the domain knowledge to know if these are valid values, we could leave them in the training set. Another option is to perform a clamp transformation. At this point, it is unknown how clamping will affect the model. Instead, we will train two models, one with clamping and one without, and select the better performing model.\n\nTo clamp the outliers, we can use the lower and upper thresholds we calculated while looking for outliers. Any outlier smaller than the lower threshold is set to the lower threshold. Likewise, any outlier larger than the upper threshold is reduced to the upper threshold. Such a transformation may alter the shape of the dataset. That is why we will be training one of each model with clamping and one without clamping. Alternatively, with a smaller dataset, we could plot each feature on a histogram before and after clamping and observe any distribution changes.","7abd52ab":"### Handling Data Issues\n\n#### Missing Values\n\nWe can check if there are missing values to handle by calculating the sum of the `isnull` method. The first sum counts the number of missing values in each column and the second sum adds the column counts. There are no missing values to handle.\n\nAlternatively, we could use the `info` method, which gives us the total number of observations and a count of the non-null values per column. The `info` table is more challenging to scan since there are many features.\n\n_* Caveat: the zero values may be synonymous with null. Without domain knowledge to confirm, we will not remove them._","5aefc0bc":"# Assignment Overview\n\nFor this assignment, you will use decision trees and random forests to try and predict whether or not a company will go bankrupt given a set of financial metrics for that company.","0cd076ba":"## Building the Models\n\nWe will split the clamped and unclamped datasets into training and test\/hold-out sets for our validation. These will train all of our models.","18b81835":"#### Hyperparameter Tuned Models\n\nRight off the bat, the benchmark random forest tree is more promising than the decision trees. Like the decision trees, there are multiple parameters that we can adjust to improve the performance of our random forest models, including:\n\n- **N_estimators**: We can increase the number of trees generated. More trees will improve the performance of our model, but too many can be costly. There is also a point where more trees will no longer grant us significant improvements.\n- **Max_features**: We can modify the policy for deciding the maximum number of features to consider when splitting a node.\n- **Max_depth**: We can control the growth of our trees for computation reasons by limiting the maximum depth. We can test if it is worth taking a hit in processing time for larger trees. We also can't go too deep as this risks overfitting the data.\n- **Min_samples_split**: We can control our trees' size by adjusting the minimum number of samples required to split. Testing will be necessary to see if we can improve model performance here.\n- **Min_samples_leaf**: We can also control our trees' size by adjusting the minimum number of samples required at each leaf node. It is worth testing to see if there is anything to gain by increasing the default.\n\nTuning a random forest tree is more expensive than tuning a decision tree, so we'll proceed a little more cautiously than we did with the decision tree. We will test parameters individually to see if they are worth pursing in our grid search.","9122f801":"#### Normalization\n\nWe generally don't need to normalize datasets for tree-based models. We build tree models by asking questions about the data and splitting on the questions that yield the most significant information gain: Is this sample A? Branch to the left, otherwise branch to the right. This type of analysis does not benefit from normalization.","b4e1d4da":"Using percentages for the `min_samples_leaf` yielded better results. Can it be improved by including `min_samples_split`, the minimum number of samples required to split?","e6b26571":"## Prediction","09ecdaa2":"### Decision Tree Model","4efb0ec1":"#### The Best Decision Tree Model\n\nThe second and third tests were comparable. We'll go with the third test, created by tuning the criterion, max depth, min samples leaf, and min samples split. We'll pull those models and check the performance of our test datasets.","dec8d6ff":"The best overall model that we tested in terms of ROC AUC Score was the unclamped hyperparameter tuned random forest tree."}}