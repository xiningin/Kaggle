{"cell_type":{"ad1ac1d7":"code","caef132f":"code","353f98da":"code","d0e8c41f":"code","5690ef7d":"code","50af4f9c":"code","48b1513c":"code","634bfe05":"code","42d53fa3":"code","b363a035":"code","6eb2b56a":"code","1497e6ea":"code","834a6388":"code","9cc8ec41":"markdown","3f51581f":"markdown","5f9faaf9":"markdown","7b54b87b":"markdown","4b478511":"markdown","d8547940":"markdown","80fab817":"markdown"},"source":{"ad1ac1d7":"import pandas as pd\nimport numpy as np\nimport datatable as dt\nimport optuna\n\nimport gc; gc.enable()\n\nimport warnings\nwarnings.filterwarnings('ignore')","caef132f":"from matplotlib import pyplot as plt\nimport seaborn as sns; sns.set()\n%matplotlib inline","353f98da":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","d0e8c41f":"%%time\nPATH = '..\/input\/tabular-playground-series-nov-2021\/train.csv'\ntrain = dt.fread(PATH).to_pandas().drop('id', axis=1)\ntrain = reduce_memory_usage(train)\n\nPATH = '..\/input\/tabular-playground-series-nov-2021\/test.csv'\ntest = dt.fread(PATH).to_pandas().drop('id', axis=1)\ntest = reduce_memory_usage(test)","5690ef7d":"train.head()","50af4f9c":"train.info()","48b1513c":"bool_cols_train = []\nfor i, col in enumerate(train.columns):\n    if train[col].dtypes == bool:\n        bool_cols_train.append(i)\n        \nbool_cols_test = []\nfor i, col in enumerate(test.columns):\n    if test[col].dtypes == bool:\n        bool_cols_test.append(i)\n\ntrain.iloc[:, bool_cols_train] = train.iloc[:, bool_cols_train].astype(int)\ntest.iloc[:, bool_cols_test] = test.iloc[:, bool_cols_test].astype(int)","634bfe05":"target = 'target'\nX = train.drop(target, axis=1).copy()\ny = train[target].copy()\n\ndel train; gc.collect()","42d53fa3":"SIZE = (13,5)\n\nfor c in ['f34', 'f55', 'f91', 'f43', 'f8', 'f27', 'f50', 'f71']:\n    plt.figure(figsize=SIZE)\n    sns.histplot(X[c], alpha=0.5, label='train')\n    sns.histplot(test[c], color='red', alpha=0.5, label='test')\n    plt.title(f'{c} - Distributions')\n    plt.legend()\n    plt.show()","b363a035":"for c in ['f34', 'f55', 'f91', 'f43', 'f8', 'f27', 'f50', 'f71']:\n    plt.figure(figsize=SIZE)\n    sns.histplot(X.loc[y==0, c], alpha=0.5, label='class 0')\n    sns.histplot(X.loc[y==1, c], color='orange', alpha=0.5, label='class 1')\n    plt.title(f'{c} - Class Distributions')\n    plt.legend()\n    plt.show()","6eb2b56a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import KBinsDiscretizer","1497e6ea":"target = 'train\/test'\n\nX[target] = 0\ntest[target] = 1\n\nX = X.append(test)\ny = X[target]\ndel X[target]; del test; gc.collect()\n\nX.sample(5)","834a6388":"clf = LogisticRegression(class_weight='balanced', n_jobs=-1, random_state=42)\nbinner = KBinsDiscretizer(20)\npipe = make_pipeline(binner, clf)\n\nscores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\nscores.mean(), scores.std()","9cc8ec41":"## Import Packages","3f51581f":"## Adversarial Scorecard","5f9faaf9":"## Visualizations","7b54b87b":"# Adversarial Train\/Test Similarity - TPS Nov21\n\nIn this notebook we:\n* visualize a few key features, \n* their relation to the target, \n* and build a **Adversarial Scorecard Model** to distinguish between the Train\/Test sets.\n    * *Scorecard = Discretized Severity Levels + Logit Link Function*","4b478511":"## **Conclusion**\n\nThere doesn't seem to be much of a difference between the train\/test sets. \n\n*Whew!* One less thing to worry about. I was afraid there may have been some drift in a few variables since the tree-based approaches seem to be under-performing compared to the linear-based methods. \n\n**Q:** So what could be the reason for that?\n\nThoughts?","d8547940":"## Data Prep","80fab817":"## Down-Casting"}}