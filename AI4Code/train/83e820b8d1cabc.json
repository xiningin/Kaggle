{"cell_type":{"e7f00852":"code","65f52464":"code","7fc8c533":"code","bf73f2b3":"code","8150546e":"code","7adcf3d1":"code","86d33832":"code","eebfd1aa":"code","42ad7cdb":"code","7c1a160e":"code","82875e11":"code","0e0c079e":"code","3549520d":"code","dda103ed":"code","961bf21e":"code","ce1f072a":"code","6c71a784":"code","9f92b56b":"code","e70536f9":"code","eb76d127":"code","acd6de39":"markdown","623947c5":"markdown","414df898":"markdown","6413a826":"markdown","60d946ab":"markdown","879ede4d":"markdown","7295a2f1":"markdown","53cb1b22":"markdown","ba8b7a4b":"markdown","692a861c":"markdown","6ef26feb":"markdown","d3f8b60a":"markdown","6a34ba08":"markdown","7fc57ca8":"markdown","28652fdf":"markdown"},"source":{"e7f00852":"import pandas as pd\nimport numpy as np\nimport warnings\nimport seaborn as sns\nimport datetime\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')\npd.__version__","65f52464":"\nimport os\nprint(os.listdir(\"..\/input\"))\n#We can see that the dataset has data of Data,Time,Transaction and the item sold at the bakery.\ndf = pd.read_csv('..\/input\/BreadBasket_DMS.csv')\n\ndf.head(), df.info()","7fc8c533":"df['Item'] = df['Item'].str.lower()","bf73f2b3":"x = df['Item'] == \"none\"\nprint(x.value_counts())","8150546e":"df = df.drop(df[df.Item == 'none'].index)","7adcf3d1":"len(df['Item'].unique())","86d33832":"fig, ax=plt.subplots(figsize=(16,7))\ndf['Item'].value_counts().sort_values(ascending=False).head(20).plot.bar(width=0.5,edgecolor='k',align='center',linewidth=1)\nplt.xlabel('Food Item',fontsize=20)\nplt.ylabel('Number of transactions',fontsize=17)\nax.tick_params(labelsize=20)\nplt.title('20 Most Sold Items at the Bakery',fontsize=20)\nplt.grid()\nplt.ioff()","eebfd1aa":"df['datetime'] = pd.to_datetime(df['Date']+\" \"+df['Time'])\ndf['Week'] = df['datetime'].dt.week\ndf['Month'] = df['datetime'].dt.month\ndf['Weekday'] = df['datetime'].dt.weekday\ndf['Hours'] = df['datetime'].dt.hour\n","42ad7cdb":"df1=df[['Date','Transaction', 'Month','Week', 'Weekday','Hours']]","7c1a160e":"df2['Counts'] = df1(['Date']).size().reset_index(name=\"counts\")","82875e11":"sns.countplot(x='Weekday',data=df1)","0e0c079e":"sns.countplot(x='Hours',data=df1)","3549520d":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","dda103ed":"hot_encoded_df = df.groupby(['Transaction', 'Item'])['Item'].count().unstack().reset_index().fillna(0).set_index('Transaction')","961bf21e":"hot_encoded_df.head()","ce1f072a":"def encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\nhot_encoded_df = hot_encoded_df.applymap(encode_units)","6c71a784":"frequent_itemsets = apriori(hot_encoded_df, min_support=0.01, use_colnames=True)","9f92b56b":"rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\nrules.head(10)","e70536f9":"rules[ (rules['lift'] >= 1) & (rules['confidence'] >= 0.5)]","eb76d127":"support = rules.as_matrix(columns=['support'])\nconfidence = rules.as_matrix(columns=['confidence'])\nimport seaborn as sns\n\nfor i in range (len(support)):\n    support[i] = support[i]\n    confidence[i] = confidence[i]\n    \nplt.title('Assonciation Rules')\nplt.xlabel('support')\nplt.ylabel('confidance')\nsns.regplot(x=support, y=confidence, fit_reg=False)\n\n","acd6de39":"For instance from the last rule we can see that toast and coffee are commonly bought together. This makes sense since people who purchase toast would like to have coffee with it. \n\nThe support value for the this rule is 0.023666. This number is calculated by dividing the number of transactions containing toast divided by total number of transactions. The confidence level for the rule is 0.704403 which shows that out of all the transactions that contain toast , 70.44% of the transactions also contain coffee. Finally, the lift of 1.47 tells us that coffee is 1.47 times more likely to be bought by the customers who buy toast compared to the default likelihood of the sale of coffee.","623947c5":"We only want to see the rules where confidence is greater than or equal to 50% so:","414df898":"Using Datetime i created a new column called \"day_of_week\" which can give us insights on which weekday has more transactions","6413a826":"Above lineAbove line of code is transfrom data to make items as columns and each transaction as a row and count same Items bought in one transaction but fill other cloumns of the row with 0 to represent item which are not bought.\n","60d946ab":"## Importing the modules needed","879ede4d":"## Transforming all item names to lower case","7295a2f1":"This means that there rows where transaction is made but item is \"none\" and number of such rows are 786. which will be removed to take in consideration only those rows where transaction is made with an item.","53cb1b22":"## Top 20 best selling items","ba8b7a4b":"## Importing the data","692a861c":"Now, we need to run apriori algorithm to get insight that if a customer buys one item which item he\/she buys next.","6ef26feb":"Support is an indication of how frequently the itemset appears in the dataset.\n\nConfidence is an indication of how often the rule has been found to be true.","d3f8b60a":"### There are 94 different unique items sold by bakery or simply only these items are present in the Items column.","6a34ba08":"## Checking all unique items that are sold","7fc57ca8":"## Inspecting the data","28652fdf":"## Droping all none values"}}