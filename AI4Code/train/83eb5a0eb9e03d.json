{"cell_type":{"37c6c320":"code","27f39ba2":"code","b06a03d0":"code","2b64a09d":"code","f25b35ea":"code","6cdd0b90":"code","9bac35ab":"code","6c66fff1":"code","17364fc9":"code","31bd355f":"code","8ccd7e98":"code","c92e6def":"code","1be40f6f":"code","e2c34394":"code","f9cf0872":"code","cf0531eb":"code","4df7cec5":"code","92ceb879":"code","5951911f":"code","5fc6e6e9":"code","c391a457":"code","cc0fe27d":"code","f218e96d":"code","fa5f5c2b":"code","8c24787c":"code","49a6d6b4":"code","5727e9c8":"code","18b79721":"code","a4c03213":"code","56c55be1":"code","37ba09f4":"code","d3b1a597":"code","1d3af397":"code","e796f5a5":"code","315e6db2":"code","5cecae8f":"code","a3da0017":"code","d10585b1":"code","79eb8e0e":"code","792ba423":"code","219239ac":"code","3c9683c4":"code","fbf11f77":"code","2151de0a":"code","012abc96":"code","b1591843":"code","5c9eff6f":"code","ebf3e12e":"code","32345a91":"code","ff188742":"code","ec05bc92":"code","4bb61345":"code","d57725ae":"code","3246662d":"code","290c1c45":"code","6d7c2c66":"code","90e955a0":"code","8d7486fd":"code","0f92bffe":"code","95fe0376":"code","8a5ea63e":"code","461ab637":"code","4efc028c":"code","fa8e6ebc":"code","f0b010b8":"code","5862a890":"code","3b1b29da":"code","17e5423c":"code","08599cdf":"code","f17b72ca":"markdown","98f71c5c":"markdown","4a337993":"markdown","45dcaa4e":"markdown","96a3e17d":"markdown","bf062f3b":"markdown","348ffa99":"markdown","2a6644e1":"markdown","28d81384":"markdown","35a65e56":"markdown","bf2c82e9":"markdown","7b1e2ade":"markdown","d5c371a9":"markdown","bb1eecd7":"markdown","61bccef6":"markdown","7852a3fa":"markdown"},"source":{"37c6c320":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","27f39ba2":"import plotly\nplotly.offline.init_notebook_mode (connected = True)","b06a03d0":"img = read_xray('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/0108949daa13dc94634a7d650a05c0bb.dicom')\nplt.figure(figsize = (12,12))\nplt.imshow(img, 'gray')","2b64a09d":"img = read_xray('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/0108949daa13dc94634a7d650a05c0bb.dicom', fix_monochrome = False)\nplt.figure(figsize = (12,12))\nplt.imshow(img, 'gray')","f25b35ea":"import pandas as pd\n## adding the center of each bbox\ndf = pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv')\ndf['x_center'] = (df['x_min'] + df['x_max'])\/2\ndf['y_center'] = (df['y_min'] + df['y_max'])\/2","6cdd0b90":"## Will be futher analyzed in future version of the notebook -  analysis on gender, img_height, img_width and age.\n\n\n#Ref : https:\/\/www.kaggle.com\/craigmthomas\/localization-of-findings\n# from pathlib import Path\n# from pydicom import dcmread\n\n# def add_image_dimensions_gender(df):\n#     path_spec = \"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/{}.dicom\"\n#     height = []\n#     width = []\n#     gender = []\n#     age = []\n#     for _, row in df.iterrows():\n#         dcm = dcmread(Path(path_spec.format(row[\"image_id\"])), stop_before_pixels=True)\n#         height.append(dcm.Rows)\n#         width.append(dcm.Columns)\n#         gender.append(dcm[0x10, 0x40].value)\n#         patient_age = dcm[0x10, 0x1010].value if [0x10, 0x1010] in dcm else \"\"\n#         age.append(patient_age)\n#     df[\"image_height\"] = height\n#     df[\"image_width\"] = width\n#     df[\"gender\"] = gender\n#     df[\"age\"] = age\n\n# add_image_dimensions_gender(df)\n","9bac35ab":"df.head()","6c66fff1":"df.image_id.nunique()","17364fc9":"len(df)","31bd355f":"per_img_disease = len(df)\/df.image_id.nunique()\nprint(f\"therefore on average we have {per_img_disease} disease for each image\")","8ccd7e98":"import seaborn as sns","c92e6def":"dist_diseases = df.class_name.value_counts()\ndist_diseases","1be40f6f":"import plotly.io as pio","e2c34394":"fig = dict({\n    \"data\": [{\"type\": \"bar\",\n              \"x\": dist_diseases.index.tolist(),\n              \"y\": dist_diseases.values.tolist()}],\n    \"layout\": {\"title\": {\"text\": \"Occurences of Diseases\"}}\n})\n\npio.show(fig)","f9cf0872":"radiologist_dist = df.rad_id.value_counts()\nfig = dict({\n    \"data\": [{\"type\": \"bar\",\n              \"x\": radiologist_dist.index.tolist(),\n              \"y\": radiologist_dist.values.tolist()}],\n    \"layout\": {\"title\": {\"text\": \"Distribution of Radiologists\"}}\n})\n\npio.show(fig)","cf0531eb":"radiologist_dist_by_percentage = (radiologist_dist*100)\/len(df)\nfig = dict({\n    \"data\": [{\"type\": \"bar\",\n              \"x\": radiologist_dist_by_percentage.index.tolist(),\n              \"y\": radiologist_dist_by_percentage.values.tolist()}],\n    \"layout\": {\"title\": {\"text\": \"Distribution of Radiologists 2\"}}\n})\n\npio.show(fig)","4df7cec5":"rad_ids = ['R8', 'R9', 'R10']\nfor rad_id in rad_ids:\n    rad_df = df[df.rad_id == rad_id]\n    rad_df_disease_distribution = rad_df.class_name.value_counts()\n\n\n    fig = dict({\n        \"data\": [{\"type\": \"bar\",\n                  \"x\": rad_df_disease_distribution.index.tolist(),\n                  \"y\": rad_df_disease_distribution.values.tolist()}],\n        \"layout\": {\"title\": {\"text\": f\"Distribution of Disease by {rad_id}\"}}\n    })\n\n    pio.show(fig)","92ceb879":"df.head()","5951911f":"unique_class_names = df.class_name.unique()\nunique_class_names","5fc6e6e9":"import plotly.express as px","c391a457":"fig, axes = plt.subplots(4 ,4, figsize = (20, 18))\nfor i, d in enumerate(unique_class_names):\n    if d == \"No finding\":\n        continue\n    disease_df = df[df.class_name == d]\n    axes[i\/\/4, i%4 - 1].hist2d(disease_df['x_center'].values.tolist(),disease_df['y_center'].values.tolist(), bins = [np.arange(0,3500,100),np.arange(0,3500,100)])\n    axes[i\/\/4, i%4 - 1].set_title(d)","cc0fe27d":"df['area'] = (df['x_max'] - df['x_min']) * (df['y_max'] - df['y_min'])\/(2800 * 3100)","f218e96d":"plt.figure(figsize=(20, 16))\nax = sns.boxplot(x=\"area\", y=\"class_name\", data=df, orient=\"h\")\nax.set_title(\"Distribution of Bounding box area by Diseases\")","fa5f5c2b":"import umap","8c24787c":"reducer = umap.UMAP()","49a6d6b4":"df.head()","5727e9c8":"# converting the categorical data to numerical data\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder","18b79721":"\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ndf['rad_id_numerical'] = labelencoder.fit_transform(df['rad_id'])\ndf.head()","a4c03213":"## removing the nan values corresponding to this class\ndf_with_valid_class = df[df.class_name!='No finding']","56c55be1":"# verifying \ndf_with_valid_class.isna().sum(axis=0)","37ba09f4":"len(df_with_valid_class)","d3b1a597":"df_data = df_with_valid_class[\n    [\n        \"rad_id_numerical\",\n        \"x_min\",\n        \"y_min\",\n        \"x_max\",\n        \"y_max\",\n        \"x_center\",\n        \"y_center\",\n        \"area\"\n    ]\n].values\nscaled_df_data = StandardScaler().fit_transform(df_data)","1d3af397":"scaled_df_data.shape","e796f5a5":"embedding = reducer.fit_transform(scaled_df_data)\nembedding.shape","315e6db2":"disease_map = {cn:i for i, cn in enumerate(unique_class_names)}","5cecae8f":"disease_map, len(disease_map)","a3da0017":"# plt.figure(figsize=(16, 16))\n# plt.scatter(embedding[:, 0], embedding[:, 1], c = df_with_valid_class.class_name.map(disease_map).values, cmap='Spectral', s=15)\n# plt.gca().set_aspect('equal', 'datalim')\n# plt.colorbar(boundaries=np.arange(16)-0.5).set_ticks(np.arange(15))\n# plt.title('UMAP projection of the dataset', fontsize=24);\n","d10585b1":"embedding_df = pd.DataFrame({'y':embedding[:, 0], 'x': embedding[:, 1]})","79eb8e0e":"embedding_df.head()","792ba423":"import plotly.express as px\nfig = px.scatter(embedding_df, x=\"y\", y=\"x\", color=df_with_valid_class.class_name)\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=1000)\nfig.show()","219239ac":"## trying to understand what is the localization of different disease\n\n# figs, axes = plt.subplots(4, 4, figsize = (16, 14))\n# for i, d in enumerate(unique_class_names):\n#     if d == 'No finding':\n#         continue\n#     x_min_by_d = int(df[df.class_name == d].x_min.min())\n#     x_max_by_d = int(df[df.class_name == d].x_max.max())\n#     y_min_by_d = int(df[df.class_name == d].y_min.min())\n#     y_max_by_d = int(df[df.class_name == d].y_max.max())\n#     img = read_xray('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/21a10246a5ec7af151081d0cd6d65dc9.dicom')\n#     cv2.rectangle(img, (x_min_by_d, y_min_by_d), (x_max_by_d, y_max_by_d), (0, 0, 0), 3)\n\n#     axes[i\/\/4, i%4 - 1].imshow(img, 'gray')\n    \n    \n    ","3c9683c4":"df.head()","fbf11f77":"from random import randint\n\nclass_color_mapping = {cn : [randint(0, 255) for _ in range(3)] for cn in df.class_name.unique()}\nclass_color_mapping","2151de0a":"from tqdm import tqdm","012abc96":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\n## https:\/\/www.kaggle.com\/trungthanhnguyen0502\/eda-vinbigdata-chest-x-ray-abnormalities\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', scale=4):\n    rows = len(imgs)\/\/cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img is not None:\n            img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n    \ndef plot_imgs_with_annotations(image_ids, class_name = 'all'):\n    font = cv2.FONT_HERSHEY_SIMPLEX \n    fontScale = 1\n    color = (0, 0, 0) \n    thickness = 2\n    scale = 4\n    imgs = []\n    for image_id in tqdm(image_ids, total = len(image_ids)):\n        img = read_xray(path = f\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/{image_id}.dicom\")\n        if img is not None:\n            img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n        boxes = df.loc[df.image_id == image_id,['x_min', 'y_min', 'x_max', 'y_max']].values\/\/scale\n        classes = df.loc[df.image_id == image_id,'class_name'].values\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        for i, box in enumerate(boxes):\n            if classes[i]!='No finding' and classes[i] == class_name:\n                cv2.rectangle(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), class_color_mapping[class_name], 3)\n                img = cv2.putText(img, classes[i], (int(box[0]), int(box[1])), font,  fontScale, color, thickness, cv2.LINE_AA)\n        imgs.append(img)\n    return imgs","b1591843":"def plotClassImages(class_to_plot):\n    print(class_to_plot)\n    image_ids = df.loc[df.class_name==class_to_plot, ['image_id']].values\n    image_ids = image_ids.flatten()\n    imgs = plot_imgs_with_annotations(image_ids[:4], class_name = class_to_plot)\n    plot_imgs(imgs, title = class_to_plot)","5c9eff6f":"plotClassImages(unique_class_names[0])","ebf3e12e":"plotClassImages(unique_class_names[1])","32345a91":"plotClassImages(unique_class_names[2])","ff188742":"plotClassImages(unique_class_names[3])","ec05bc92":"plotClassImages(unique_class_names[4])","4bb61345":"plotClassImages(unique_class_names[5])","d57725ae":"plotClassImages(unique_class_names[6])","3246662d":"plotClassImages(unique_class_names[7])","290c1c45":"plotClassImages(unique_class_names[8])","6d7c2c66":"plotClassImages(unique_class_names[9])","90e955a0":"plotClassImages(unique_class_names[10])","8d7486fd":"plotClassImages(unique_class_names[11])","0f92bffe":"plotClassImages(unique_class_names[12])","95fe0376":"plotClassImages(unique_class_names[13])","8a5ea63e":"plotClassImages(unique_class_names[14])","461ab637":"df.head()","4efc028c":"image_id = \"9a5094b2563a1ef3ff50dc5c7ff71345\"","fa8e6ebc":"import random\n\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport albumentations as A","f0b010b8":"def visualize(image, aug_image):\n    plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    plt.imshow(image)\n    \ndef plot_aug_imgs(img, aug_img, augment_type,cols=2, size=7, is_rgb=True, title=\"\", cmap='gray', scale=4):\n    rows = 1\n    subtitle = ['Original', augment_type]\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate([img, aug_img]):\n        if img is not None:\n            img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n        plt.title(subtitle[i])\n    plt.show()","5862a890":"img = read_xray(path = f\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/{image_id}.dicom\")\nscale = 5\nif img is not None:\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)","3b1b29da":"transform = A.GridDistortion(p=1)\nrandom.seed(7)\naugmented_image = transform(image=img)['image']\nplot_aug_imgs(img, augmented_image, 'GridDistortion')","17e5423c":"transform = A.OpticalDistortion(p=1)\nrandom.seed(7)\naugmented_image = transform(image=img)['image']\nplot_aug_imgs(img, augmented_image, 'Optical Distortion')","08599cdf":"transform = A.ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\nrandom.seed(7)\naugmented_image = transform(image=img)['image']\nplot_aug_imgs(img, augmented_image, 'Elastic Transform')","f17b72ca":"1. Image with image ids and show their diseases\n2. show images for specific diseases\n","98f71c5c":"# IMAGE LEVEL EDA","4a337993":"\n# How about the distribution of radiologist?","45dcaa4e":"## Area Distribution By Disease","96a3e17d":"Now finding the centroid of each bounding boxes to draw the density plot for each disease\n","bf062f3b":"The aim of this notebook is to get an understanding about the data. Plots have been added to show the localization of different diseases in various region of lungs. Also UMAP(Uniform Manifold Approximation and Projection). The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.(https:\/\/arxiv.org\/abs\/1802.03426#:~:text=UMAP%20(Uniform%20Manifold%20Approximation%20and,applies%20to%20real%20world%20data.)\n","348ffa99":"All images in dataset are DICOM format. So we need to convert data from DICOM to numpy array. Original dicom2array function in [raddar's notebook](https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way)\n","2a6644e1":"What if hadn't fixed MONOCHROME issue:","28d81384":"\n## lets see the location of bounding boxes for each diseases","35a65e56":"## Distribution of diseases","bf2c82e9":"<!-- IMAGE AUGMENTATION SAMPLE FOR MEDICAL IMAGERY\nScreenshot 2021-01-29 at 4.56.06 PM![image.png](attachment:image.png) -->","7b1e2ade":"R8, R9, R10 are the most occuring radiologists. lets see which is the most frequently marked disease by these people.","d5c371a9":"Various Image Transformation:\nreduced_image_quality.jpg![image.png](attachment:image.png)","bb1eecd7":"Seems like the relative location of the diseases will be an important factor while building the model as confirmed by the 2d histogram and UMAP.","61bccef6":"# Image Augmentation: Albumentation","7852a3fa":"## UMAP - Plotting the dataframe data on 2 dimension"}}