{"cell_type":{"468222ec":"code","16eea300":"code","507341f3":"code","860d7634":"code","c8b06824":"code","a8256854":"code","b1919a90":"code","d3b49125":"code","2504c107":"code","6a01685c":"code","bcb0e3eb":"code","4bf59656":"code","15b098f4":"markdown","275dda74":"markdown","ff39d043":"markdown","6c1c9412":"markdown","ea6ec468":"markdown","eca88199":"markdown","5f69482c":"markdown","5789f3f1":"markdown","f04e31fa":"markdown","599bd644":"markdown","1305a658":"markdown","a4fb5bab":"markdown"},"source":{"468222ec":"# example of loading the fashion mnist dataset\nfrom matplotlib import pyplot\nfrom keras.datasets import fashion_mnist","16eea300":"# load dataset\n(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n# summarize loaded dataset\nprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\nprint('Test: X=%s, y=%s' % (testX.shape, testy.shape))","507341f3":"# plot first few images\nfor i in range(9):\n    pyplot.subplot(330 + 1 + i)\n    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n# show the figure\npyplot.show()","860d7634":"from tensorflow.keras.utils import to_categorical\n# reshape dataset to have a single channel\ntrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\ntestX = testX.reshape((testX.shape[0], 28, 28, 1))\n\n# one hot encode target values\ntrainy = to_categorical(trainy)\ntesty = to_categorical(testy)","c8b06824":"# convert from integers to floats\ntrain_norm = trainX.astype('float32')\ntest_norm = testX.astype('float32')\n# normalize to range 0-1\ntrain_norm = train_norm \/ 255.0\ntest_norm = test_norm \/ 255.0\n\ntrain_norm_y = trainy.astype('float32')\ntest_norm_y = testy.astype('float32')\n# normalize to range 0-1\ntrain_norm_yy = train_norm_y \/ 255.0\ntest_norm_yy = test_norm_y \/ 255.0","a8256854":"# scale pixels\ndef prep_pixels(train, test):\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    train_norm = train_norm \/ 255.0\n    test_norm = test_norm \/ 255.0\n    return train_norm, test_norm","b1919a90":"prep_pixels(train_norm, train_norm_y);","d3b49125":"from sklearn.model_selection import KFold\nfrom keras.datasets import fashion_mnist\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom tensorflow.keras.optimizers import SGD","2504c107":"def define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(10, activation='softmax'))\n    # compile model\n    opt = SGD(learning_rate=0.01, momentum=0.9)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","6a01685c":"define_model()","bcb0e3eb":"def evaluate_model(dataX, dataY, n_folds=5):\n    scores, histories = list(), list()\n    # prepare cross validation\n    kfold = KFold(n_folds, shuffle=True, random_state=1)\n    # enumerate splits\n    for train_ix, test_ix in kfold.split(dataX):\n        # define model\n        model = define_model()\n        # select rows for train and test\n        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n        # fit model\n        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n        # evaluate model\n        _, acc = model.evaluate(testX, testY, verbose=0)\n        print('> %.3f' % (acc * 100.0))\n        # append scores\n        scores.append(acc)\n        histories.append(history)\n    return scores, histories","4bf59656":"evaluate_model(train_norm, train_norm_y)","15b098f4":"# pixels done","275dda74":"# We prepare the pixels in array form","ff39d043":"# We define our model with 5 layers and softmax activiation and he_uniform intializer to ensure our model trains all fitted values","6c1c9412":"# We Now Evaluate our model","ea6ec468":"# Different Aspects of the fashion dataset","eca88199":"# We import accuracy metrics and modelling algorithms of Deep learning","5f69482c":"# As shown we achieved 90% above accuracy due to data being completely sorted and minium use of computing power required\n* We could have used other loss fucntions for better performances\n* Used gradient Descent\n* transformed our data to greater extents before testing and training splits","5789f3f1":"# We Split the data into training and testing","f04e31fa":"# We get a glimpse of how our data looks like","599bd644":"# After encoding thte values we cast them into floats for further processing","1305a658":"# After defining our loss function and optimizer as categorical_crossentropy and opt as its fashion dataset and categorical encoding needs to be cross checked for the gradient to be accurate","a4fb5bab":"# We load the data here"}}