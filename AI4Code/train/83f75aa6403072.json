{"cell_type":{"3bfada27":"code","91e6f46f":"code","4a2ee8ba":"code","603ec4b0":"code","02ec9fab":"code","c45b96df":"code","f13e9aa9":"markdown","838722e6":"markdown"},"source":{"3bfada27":"#Imports\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","91e6f46f":"class Perceptron:\n    \n    def __init__(self, learning_rate=0.01, n_iters=1000):\n        self.lr = learning_rate # taxa de aprendizagem\n        self.n_iters = n_iters # n\u00famero de treinamentos\n        self.activaction_func = self._unit_step_func # fun\u00e7\u00e3o de ativa\u00e7\u00e3o\n        self.weights = None # precisa definir ou adquerir\n        self.bias = None # precisa definir ou adquerir\n        \n    def fit(self, X_train, Y_train): #essa fun\u00e7\u00e3o pega os inputs e labels de treinamento \n        n_samples, n_features = X_train.shape\n        # pesos da fun\u00e7\u00e3o init, mudar conforme o exerc\u00edcio\n        self.weights = np.random.rand(n_features)\n        #self.weights = np.array([0,0,0])\n        self.bias = 0\n        # para garantir que s\u00f3 existem 1 e -1 em y, fazemos o seguinte:\n        y_ = np.array([1 if i > 0 else -1 for i in Y_train])\n        for _ in range(self.n_iters):\n            for idx, x_i in enumerate(X_train):\n                linear_output = np.dot(x_i, self.weights) + self.bias\n                y_predicted = self.activaction_func(linear_output)\n                update = self.lr * (y_[idx] - y_predicted)\n                self.weights += update * x_i\n                self.bias += update\n        \n    \n    def predict(self, X_train):\n        linear_output = np.dot(X_train, self.weights) + self.bias\n        y_predicted = self.activaction_func(linear_output)\n        return y_predicted\n        \n    def _unit_step_func(self, x): # fun\u00e7\u00e3o de ativa\u00e7\u00e3o definida, mudar aqui se mudar a fun\u00e7\u00e3o\n        return np.where(x>=0, 1, -1)","4a2ee8ba":"# Primeiro foi criado uma fun\u00e7\u00e3o para definir a acur\u00e1cia do modelo\ndef accuracy(y_true, y_pred):\n    accuracy = np.sum(y_true == y_pred)\/len(y_true)\n    \n# Segundo deve-se carregar o modelo do anexo do exerc\u00edcio\ntreino = pd.read_csv('..\/input\/epc1-anexo\/Anexo_EPC.csv')\nprint(treino.head())","603ec4b0":"#Separando os Y_train do X_train\nY_a = treino[\"d\"].to_numpy()\nX_a = treino.drop(labels = [\"Amostra\", \"d\"], axis = 1).to_numpy()","02ec9fab":"# Separando uma parte para treino (70%) e outra para valida\u00e7\u00e3o (30%)\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X_a, Y_a, test_size = 0.3, random_state=9)\nprint('Qtde de treino: {}'.format(len(x_train)))\nprint('Qtde de valida\u00e7\u00e3o: {}'.format(len(x_val)))","c45b96df":"# Preparando o Modelo\n\np = Perceptron(learning_rate=0.01, n_iters=1000)\np.fit(x_train, y_train)\npredictions = p.predict(x_val)\nprint(\"Perceptron Classification Accuracy\", accuracy(y_val,predictions))","f13e9aa9":"**Definindo o Modelo *Perceptron***","838722e6":"**Treinando o modelo com os dados do anexo**\n![image.png](attachment:d2718655-ef2e-4e22-b11d-8b42e0d82d82.png)\n\nA partir da an\u00e1lise de um processo de destila\u00e7\u00e3o fracionada de petr\u00f3leo observou-se que determinado \u00f3leo poderia ser classificado em duas classes de pureza {C1 e C2}, mediante a medi\u00e7\u00e3o de tr\u00eas grandezas {x1, x2 e x3} que representam algumas das propriedades f\u00edsico-qu\u00edmicas do \u00f3leo. A equipe de engenheiros e cientistas pretende utilizar um perceptron para executar a classifica\u00e7\u00e3o autom\u00e1tica destas duas classes.\n\nAssim, baseadas nas informa\u00e7\u00f5es coletadas do processo, formou-se o conjunto de treinamento em anexo, tomando por conven\u00e7\u00e3o o valor \u20131 para \u00f3leo pertencente \u00e0 classe C1 e o valor +1 para \u00f3leo pertencente \u00e0 classe C2.\n\nPortanto, o neur\u00f4nio constituinte do perceptron ter\u00e1 tr\u00eas entradas e uma sa\u00edda, conforme ilustrado na figura acima:\n\nUtilizando o algoritmo supervisionado de Hebb (regra de Hebb) para classifica\u00e7\u00e3o de padr\u00f5es, e assumindo-se a taxa de aprendizagem igual a 0.01, fa\u00e7a as seguintes atividades:\n\n**Treine o modelo**\n"}}