{"cell_type":{"b74a7474":"code","1abb248b":"code","b37c7189":"code","a9d04606":"code","214a72b2":"code","bfbfa536":"code","7bd9b08c":"code","e031902e":"code","bc8f986d":"code","f5bbb4d7":"code","fb5de3b8":"code","945b3a0e":"code","aa6065a1":"code","d7fd858b":"code","3b64abf0":"code","63fab5b8":"code","c9d9129b":"code","c979cbab":"markdown","605400d4":"markdown","df804905":"markdown","45c53ca0":"markdown","f0e1b254":"markdown","a3e1f363":"markdown","dbf95314":"markdown","2c78f5a1":"markdown","e21f4c0f":"markdown","da5fe104":"markdown","aacec301":"markdown","69ef24f7":"markdown","9e56028f":"markdown"},"source":{"b74a7474":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns;\nimport matplotlib.pyplot as plt;\n\nimport warnings;\nwarnings.filterwarnings('ignore');\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1abb248b":"# Train data\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\");\nprint(train.shape);\ntrain.head()","b37c7189":"# Test data\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\");\nprint(test.shape);\ntest.head()","a9d04606":"yTrain = train[\"label\"];\ntrain.drop(\"label\", axis = 1, inplace = True);\ntrain.head()","214a72b2":"plt.figure(figsize = (15, 7));\nsns.countplot(yTrain);\nplt.title(\"Number of Digit Classes\");\nyTrain.value_counts()","bfbfa536":"# Visualize an image\nindex = 9;\nimg = train.iloc[index, :].values.reshape(-1, 1);\nsizeOfImg = np.sqrt(len(img));\nimg = img.reshape(28, 28);\nplt.imshow(img, cmap = 'gray');\nplt.title(yTrain.values[index]);\nplt.axis(\"off\");\nplt.show();","7bd9b08c":"train = train \/ 255.0;\ntest = test \/ 255.0;","e031902e":"train = train.values.reshape(-1, 28, 28, 1);\ntest = test.values.reshape(-1, 28, 28, 1);\nprint(\"Train Shape: \", train.shape);\nprint(\"Test Shape: \", test.shape);","bc8f986d":"import tensorflow as tf;\nfrom tensorflow import keras\nfrom keras.utils.np_utils import to_categorical;\n\nyTrain = to_categorical(yTrain, num_classes = 10);","f5bbb4d7":"from sklearn.model_selection import train_test_split;\nxTrain, xVal, yTrain, yVal = train_test_split(train, yTrain, test_size = 0.1, random_state = 42);\nprint(\"X Train Shape: \", xTrain.shape);\nprint(\"Y Train Shape: \", yTrain.shape);\nprint(\"X Validation Shape: \", xVal.shape);\nprint(\"Y Validation Shape: \", yVal.shape);","fb5de3b8":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential();\n# 1. Layer Set\nmodel.add(Conv2D(filters = 8, kernel_size = (5, 5), padding = \"Same\", activaiton = \"relu\", input_shape = (28, 28, 1)));\nmodel.add(MaxPool2D(pool_size = (2, 2)));\nmodel.add(Dropout(0.25));\n\n# 2. Layer Set\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), padding = \"Same\", activaiton = \"relu\"));\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = (2, 2)));\nmodel.add(Dropout(0.25));\n\n# Fully connected layer\nmodel.add(Flatten());\nmodel.add(Dense(256, activation = \"relu\"));\nmodel.add(Dropout(0.5));\nmodel.add(Dense(10, activation = \"softmax\"));","945b3a0e":"optimizer = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999);","aa6065a1":"model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]);\nepochs = 10;\nbatch_size = 250;","d7fd858b":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.1, # Randomly zoom image 10%\n        width_shift_range=0.1,  # randomly shift images horizontally 10%\n        height_shift_range=0.1,  # randomly shift images vertically 10%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(xTrain)","3b64abf0":"history = model.fit_generator(datagen.flow(xTrain, yTrain, batch_size = batch_size),\n                              epochs = epochs, validation_data = (xVal, yVal), steps_per_epoch = xTrain.shape() \/\/ batch_size);\n","63fab5b8":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","c9d9129b":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","c979cbab":"## Define Optimizer","605400d4":"## Evaluate the Model Results","df804905":"# Normalization, Reshape and Label Encoding","45c53ca0":"## Reshape\nKeras expect 4d input data where the first dimension is the number of data, the second dimension is the x size of the image, the third dimension is the y size of the image and the forth size is the number of channels of the image. The number of channels is 1 in this study, because the used images are grayscale images.","f0e1b254":"## Data Augmentation","a3e1f363":"## Compile the Model","dbf95314":"## Fit the Model","2c78f5a1":"## Label Encoding\n\nThe training labels must be converted into categorical form to be processed in CNN in Keras library. The categorical form means --> 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n                                        5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n                                        8 -> [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n                                        .\n                                        .\n                                        .\nThis converting method is called as one-hot encoding.","e21f4c0f":"# Load the training and test data","da5fe104":"# Implementing CNN With Keras","aacec301":"## Create Model","69ef24f7":"## Normalization\n\nNormalization is made to restrict the values of the pixels in the image in [0-1] interval.\nThis makes the CNN run faster.","9e56028f":"# Train and Test Data Splitting"}}