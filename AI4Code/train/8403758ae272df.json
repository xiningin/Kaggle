{"cell_type":{"82a1eafa":"code","c5d7f38d":"code","fa100672":"code","9b90dcf8":"code","5fc554d7":"code","6182dbac":"code","b0dc0ea0":"code","9a281176":"code","194bca4a":"code","b8010f20":"code","20917f44":"code","0df8bb5d":"code","f1c65bb1":"code","25699b1b":"code","9de34955":"code","35d6c876":"code","cac8c9f5":"code","3c70c602":"code","c22215dd":"code","e63b5c7a":"code","1c47877d":"code","6d15c7aa":"code","dca800ca":"code","5b8cd145":"code","c0a84d9c":"code","8d3efd78":"code","db2dc2a9":"code","b532f5fe":"code","e65e9467":"code","b1aa7a86":"code","dd6aea96":"code","cde6c1e5":"code","66159de7":"code","1f46ccd3":"code","afcbfe76":"code","9c9d9ced":"code","23fde6ce":"code","29be7160":"markdown","6f85c2df":"markdown","922c4315":"markdown","ac154434":"markdown","d2542989":"markdown","8d4bece4":"markdown","7b66c273":"markdown","e8c74ef2":"markdown","ae5f0627":"markdown","037123fc":"markdown","15ae4ded":"markdown","58799aae":"markdown","0599f2cc":"markdown","fd12c6c8":"markdown","97638650":"markdown","fcba170d":"markdown","07f8885d":"markdown","e168900e":"markdown"},"source":{"82a1eafa":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nfrom scipy.interpolate import Rbf, interp2d\nimport datetime\n\n# For import data\nimport os\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Modeling and Prediction\nfrom fbprophet import Prophet\nfrom sklearn.metrics import r2_score, mean_absolute_error\n\nimport warnings\nwarnings.simplefilter('ignore')","c5d7f38d":"indicator_names = ['PM2.5', 'PM10']\nindicator_name = indicator_names[0]\ntype_agg='mean' # 'mean' or 'max'\ntime_interval = 'H' # 'H' - 'hour'","fa100672":"#datetime_analysis = '2021-11-16 10:00:00'\ndatetime_analysis = '2021-11-27 09:00:00'  # maximum value after 2021-11-16\n#datetime_analysis = '2021-11-12 18:00:00'\n#datetime_analysis = '2021-01-23 18:00:00'  # maximum value","9b90dcf8":"# Import files with data from Kaggle dataset\ndataset_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        dataset_files.append(os.path.join(dirname, filename))\ndataset_files","5fc554d7":"len(dataset_files)","6182dbac":"# Data from SaveEcoBot\nstations_about = pd.read_csv('..\/input\/air-quality-monitoring\/saveecobot_city_about_stations.csv', header=0, sep=';')\nstations_about = stations_about[stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\nstations_about","b0dc0ea0":"def get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    # Transform indicator to SaveEcoBot variants\n    if indicator_name=='PM2.5':\n        indicator_name = 'pm25'\n    elif indicator_name=='PM10':\n        indicator_name = 'pm10'\n    \n    # Get codes station\n    id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = stations_about.loc[num,'id_ecocity']\n    if not np.isnan(id_station_ecocity):\n        id_station_ecocity = int(id_station_ecocity)\n        id_station = \"EcoCity_\" + str(id_station_ecocity)\n    else: id_station = \"SaveEcoBot_\" + str(id_station_saveecobot)\n    #print(num, id_station_saveecobot, id_station_ecocity, id_station)\n        \n    df = pd.read_csv(f\"..\/input\/air-quality-monitoring\/data_saveecobot_{id_station_saveecobot}.csv\")\n    #display(df.head())\n    df = df[df['indicator_code']==indicator_name]\n    #display(df.head())\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    #df = df.dropna().reset_index(drop=True)\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    #display(df.head())\n    # Data processing - converting data to average or maximum values per given time_interval\n    #df = df.resample('H').mean()\n    if type_agg == 'mean':\n        df = df.resample(time_interval).mean()\n    else:\n        # type_agg == 'max'\n        df = df.resample(time_interval).max()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n\n    if df.shape[1] > 1:\n        # Resample is successfull\n        #display(df.head())\n        df['network'] = str(stations_about.loc[num,'network'])\n        df['id_station'] = id_station\n        df['lat'] = float(stations_about.loc[num,'lat'])\n        df['lng'] = float(stations_about.loc[num,'lng'])\n        print(f\"Number of data for {num}th station #{id_station} is {len(df)}\")\n        #display(df)\n        #print(df.info())   \n    else:\n        print(f\"Data for {num}th station #{id_station} is bad\")\n        df = pd.DataFrame()\n    return df","9a281176":"%%time\ndf = pd.DataFrame()\nln = 0\nfor i in range(len(stations_about)):\n    df_i = get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, i)\n    #df_i.info()\n    if len(df) > 0:\n        #ln += len(df_i)\n        #print('\\n',ln)\n        df = pd.concat([df, df_i], ignore_index=True)\n    else: df = df_i\ndf = df.dropna().reset_index(drop=True)\ndf","194bca4a":"df.info()","b8010f20":"# Data from SaveEcoBot\necocity_stations_about = pd.read_csv('..\/input\/air-quality-monitoring-from-ecocity\/ecocity_about_stations_2021.csv', header=0, sep=';')\necocity_stations_about","20917f44":"ecocity_stations_about_region = ecocity_stations_about[ecocity_stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\necocity_stations_about_region['id_ecocity'] = ecocity_stations_about_region['id_ecocity'].astype('int')\necocity_stations_about_region","0df8bb5d":"def get_data_for_indicator_of_station_from_ecocity(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    #id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = int(stations_about.loc[num,'id_ecocity'])\n    \n    # Find file name\n    for i in range(len(dataset_files)):\n        if dataset_files[i].find(str(id_station_ecocity))>0:\n            file_name = dataset_files[i]\n    \n    df = pd.read_csv(file_name)\n    #display(df)\n    df = df[df['indicator_name']==indicator_name]\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    df = df.resample('H').mean()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n    df['network'] = str(stations_about.loc[num,'network'])\n    #df['id_station_ecocity'] = id_station_ecocity\n    df['id_station'] = \"EcoCity_\" + str(id_station_ecocity)\n    df['lat'] = float(stations_about.loc[num,'lat'])\n    df['lng'] = float(stations_about.loc[num,'lng'])\n    #print(f\"Number of data for {num}th station #{id_station_saveecobot} in SaveEcoBot and #{id_station_ecocity} in EcoCity is {len(df)}\")\n    #display(df)\n    return df","f1c65bb1":"%%time\ndf2 = pd.DataFrame()\nfor i in range(len(ecocity_stations_about_region)):\n    df_i = get_data_for_indicator_of_station_from_ecocity(ecocity_stations_about_region, indicator_name, i)\n    if len(df2) > 0:\n        df2 = pd.concat([df2, df_i], ignore_index=True)\n    else: df2 = df_i\ndf2","25699b1b":"df2.info()","9de34955":"# Drop data on stations of the EcoCity network from SaveEcoBot \n# with datetime which equal datetime of data from EcoCity\nif len(df)>0:\n    len_before = len(df)\n    for id_station in df2['id_station'].unique().tolist():\n        print(id_station)\n        ds_list = df2[df2['id_station']==id_station]['ds'].tolist()\n        df = df.drop(df[(df.id_station == id_station) & (df.ds.isin(ds_list))].index)\n    len_after = len(df)\n    print(f\"Number of data before the dropping duplicates - {len_before}, after - {len_after}\")","35d6c876":"if len(df)>0:\n    df = pd.concat([df, df2], ignore_index=True)\nelse: df = df2\ndf","cac8c9f5":"df.info()","3c70c602":"df.describe()","c22215dd":"# Selection data for interpolation\nif type_agg == 'mean':\n    data = df[df['ds']==datetime.datetime.fromisoformat(datetime_analysis)].reset_index(drop=True)\nelse:\n    #type_agg == 'max':\n    datetime_analysis = 'all time'\n    data = df.copy()\n    \nx = data.lng.values\ny = data.lat.values\nz = data.value.values\nfig = plt.figure()\nplt.scatter(x, y)\nplt.title(f'Stations in Vinnytsia region with data for {indicator_name} in {datetime_analysis}')\ndisplay(data)\nplt.show()","e63b5c7a":"number_steps_in_day = 24 if time_interval=='H' else 1","1c47877d":"def get_data_for_prediction(df, id_station_name, num_last_data=30):\n    # Get data for given id_station_name with the last num_last_data data\n    #id_station_name = 'EcoCity_848'\n    df_i = df[df['id_station']==id_station_name]\n    df_i = df_i[(len(df_i)-num_last_data):].reset_index(drop=True)\n    display(df_i['value'].describe())\n    print(len(df_i))\n    return df_i","6d15c7aa":"def plot_with_anomalies(df, cols_y_list, cols_y_list_name, dates_x, anomalous_dates, log_y=False):\n    # Thanks to https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality\n    # Draws a plot with title - the features cols_y_list (y) and dates_x (x) from the dataframe df\n    # and with vertical lines in the dates from the list anomalous_dates\n    # with the length between the minimum and maximum of feature cols_y_list[0]\n    # with log_y = False or True\n    # cols_y_list - dictionary of the names of cols from cols_y_list (keys - name of feature, value - it's name for the plot legend), \n    # name of cols_y_list[0] is the title of the all plot\n    \n    fig = px.line(df, x=dates_x, y=cols_y_list[0], title=cols_y_list_name[cols_y_list[0]], log_y=log_y, template='gridon',width=800, height=600)\n    y_max = df[cols_y_list[0]].max()\n    for i in range(len(cols_y_list)-1):\n        fig.add_trace(go.Scatter(x=df[dates_x], y=df[cols_y_list[i+1]], mode='lines', name=cols_y_list_name[cols_y_list[i+1]]))\n        max_i = df[cols_y_list[i+1]].max()\n        y_max = max_i if max_i > y_max else y_max\n    \n    y_min = min(df[cols_y_list[0]].min(),0)\n    for i in range(len(anomalous_dates)):\n        anomal_date = anomalous_dates[i]\n        #print(anomal_date, y_min, y_max)\n        fig.add_shape(dict(type=\"line\", x0=anomal_date, y0=y_min, x1=anomal_date, y1=y_max, line=dict(color=\"red\", width=1)))\n    fig.show()","dca800ca":"def get_model_err(df, res, model, id_station_name, forecasting_period,\n                 Q_order, daily_order, weekly_order, quarterly_order):\n    # Data prediction and score calculation\n    \n    # Make a forecast\n    future = model.make_future_dataframe(periods = forecasting_period, freq=time_interval)\n    forecast = model.predict(future)\n        \n    # Ouput the prediction for the next time\n    forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(2)\n    y_pred = forecast['yhat'][:-forecasting_period]\n    \n    # Calculation r2_score (accuracy of prediction for training data)\n    r2 = round(r2_score(df['y'], y_pred),2)\n    mae_err = round(mean_absolute_error(df['y'], y_pred),2)\n    \n    # Save results\n    if res.empty:\n        num = 0\n    else: num = len(res)\n    res.loc[num, 'id_station'] = id_station_name\n    res.loc[num, 'Q_order'] = Q_order\n    res.loc[num, 'daily_order'] = daily_order\n    res.loc[num, 'weekly_order'] = weekly_order\n    res.loc[num, 'quarterly_order'] = quarterly_order\n    res.loc[num, 'r2_score'] = r2\n    res.loc[num, 'mae'] = mae_err\n    print(id_station_name, Q_order, daily_order, weekly_order, quarterly_order, r2, mae_err)\n    #display(res)\n    \n    # Draw plot of the values with forecasting data\n    #label_str = \" - \".join([id_station_name, indicator_name, str(Q_order), str(daily_order), str(weekly_order), str(quarterly_order), str(r2), str(mae_err)])\n    #figure = model.plot(forecast, xlabel = 'Date', ylabel = label_str)\n    \n    # Draw plot with the components (trend and seasonalities) of the forecasts\n    #figure_component = model.plot_components(forecast)    \n\n    return res","5b8cd145":"def Prophet_tuning(df, number_steps_in_day, Q_order, daily_order, weekly_order, quarterly_order):\n    # Prophet tuning\n\n    model = Prophet(daily_seasonality=False, weekly_seasonality=False, yearly_seasonality=False, \n                    changepoint_range=1, n_changepoints = 1, seasonality_mode = 'additive')\n\n    if (Q_order > 0) and (number_steps_in_day > 1):\n        model.add_seasonality(name='Q_hours', period=Q, \n                              fourier_order=Q_order, mode = 'additive')\n\n    if (daily_order > 0) and (number_steps_in_day > 1):\n        model.add_seasonality(name='daily', period=1*number_steps_in_day, \n                              fourier_order=daily_order, mode = 'additive')\n    if (weekly_order > 0):\n        model.add_seasonality(name='weekly', period=7*number_steps_in_day, \n                              fourier_order=weekly_order, mode = 'additive')\n    if (quarterly_order > 0):\n        model.add_seasonality(name='quarterly', period=365.25\/12*4*number_steps_in_day, \n                              fourier_order=quarterly_order, mode = 'additive')\n    model.fit(df)\n\n    return model","c0a84d9c":"def model_tuning(res, df, id_station_name, number_steps_in_day, forecasting_period):\n    # Prophet model with parameters and structure tuning\n    \n    Q_order_from = -1\n    daily_order_from = -1\n    weekly_order_from = -1\n    quarterly_order_from = -1\n    \n    Q_order_to = 0\n    daily_order_to = 0\n    weekly_order_to = 0\n    quarterly_order_to = 0\n    \n    order_min = 3\n    order_max = 6\n    \n    if len(df)\/number_steps_in_day > 31*4*2:\n        # All data more 2 quarters\n        quarterly_order_from = order_min\n        quarterly_order_to = order_max\n\n    if len(df)\/number_steps_in_day > 7*2:\n        # All data more 2 weeks\n        weekly_order_from = order_min\n        weekly_order_to = order_max\n\n    if len(df)\/number_steps_in_day > 2:\n        # All data more 2 days\n        daily_order_from = order_min\n        daily_order_to = order_max        \n\n    if len(df) > 2*Q:\n        # All data more Q hours\n        Q_order_from = order_min\n        Q_order_to = order_max        \n\n    print(Q_order_from, daily_order_from, weekly_order_from, quarterly_order_from)\n    print(Q_order_to, daily_order_to, weekly_order_to, quarterly_order_to)\n    \n    for i0 in range(Q_order_to-Q_order_from):\n        Q_order = Q_order_from + i0\n\n        for i1 in range(daily_order_to-daily_order_from):\n            daily_order = daily_order_from + i1\n\n            for i2 in range(weekly_order_to-weekly_order_from):\n                weekly_order = weekly_order_from + i2\n\n                for i3 in range(quarterly_order_to-quarterly_order_from):\n                    quarterly_order = quarterly_order_from + i3\n\n                    print(Q_order, daily_order, weekly_order, quarterly_order, Q_order)\n                    model = Prophet_tuning(df, number_steps_in_day, Q_order, daily_order, \n                                           weekly_order, quarterly_order)\n\n                    # Training err for prediction by the model                \n                    res = get_model_err(df, res, model, id_station_name, forecasting_period,\n                             Q_order, daily_order, weekly_order, quarterly_order)\n    #print('model_tuning')\n    #display(res)\n    return res","8d3efd78":"def prophet_pred(res, df, id_station_name, number_steps_in_day, threshold_min, forecasting_period):\n    \n    # Data preparation \n    df = df[['ds', 'value']].reset_index(drop=True)\n    df.columns = ['ds', 'y']\n    \n    # Get anomalous\n    \n    # Find anomalous data\n    display(df.describe([threshold_min]))\n    \n    # Modeling and Visualization\n    # Model tuning\n    res = model_tuning(res, df, id_station_name, number_steps_in_day, forecasting_period)\n    \n    # Resiults display \n    res = res.sort_values(by=['mae'], ascending=True)\n    display(res)\n    \n    # Prediction with OPTIMAL parameters\n    model = Prophet_tuning(df, number_steps_in_day, \n                           int(res.head(1)['Q_order']), \n                           int(res.head(1)['daily_order']), \n                           int(res.head(1)['weekly_order']), \n                           int(res.head(1)['quarterly_order']))\n    # Make a forecast\n    future = model.make_future_dataframe(periods = forecasting_period, freq=time_interval)\n    forecast = model.predict(future)\n\n    # Ouput the prediction for the next time\n    forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(2)\n    y_pred = forecast['yhat'][:-forecasting_period]\n\n    # Draw plot of the values with forecasting data\n    label_str = \" - \".join([id_station_name, indicator_name])\n    figure = model.plot(forecast, xlabel = 'Date', ylabel = label_str)\n\n    # Draw plot with the components (trend and seasonalities) of the forecasts\n    figure_component = model.plot_components(forecast)\n    \n    return res","db2dc2a9":"id_station_list = df['id_station'].unique().tolist()\nid_station_list","b532f5fe":"for id_st in id_station_list:\n    df_i = df[df['id_station']==id_st]\n    df_i = df_i[(len(df_i)-10*24):]\n    print(id_st, int(len(df_i)\/number_steps_in_day))\n    df_i['value'].plot()\n    plt.show()\n    display(df_i.head(1))\n    display(df_i.tail(1))","e65e9467":"# Staions with good series in November 2021\nid_station_best_list = ['EcoCity_337', 'EcoCity_848', 'EcoCity_1315']\n#id_station_best_list = ['EcoCity_337']\nid_station_best_list","b1aa7a86":"# Set parameters\nN = 15*number_steps_in_day\nforecasting_period = 2  # in time_intervals\ntime_interval='H' # or 'H' or 'D'\nQ = 12  # Seasonality is less than a day, hours, if time_interval='H'","dd6aea96":"%%time\nres = pd.DataFrame(columns = ['id_station', 'Q_order', 'daily_order', 'weekly_order', 'quarterly_order', \n                              'r2_score', 'mae'])\nfor id_station_name in id_station_best_list:\n    print(id_station_name)\n    df1 = get_data_for_prediction(df, id_station_name, num_last_data=N)    \n    res = prophet_pred(res, df1, id_station_name, number_steps_in_day, threshold_min=0.95, forecasting_period=forecasting_period)","cde6c1e5":"# Set parameters\nnumber_steps_in_day = 1\nN = 15*number_steps_in_day\nforecasting_period = 2  # in time_intervals\ntime_interval='D' # or 'H' or 'D'","66159de7":"%%time\nres = pd.DataFrame(columns = ['id_station', 'Q_order', 'daily_order', 'weekly_order', 'quarterly_order', \n                              'r2_score', 'mae'])\nfor id_station_name in id_station_best_list:\n    print(id_station_name)\n    df1 = get_data_for_prediction(df, id_station_name, num_last_data=N)\n    \n    # Resampling data from 'H' to 'D'\n#     df1 = df1[['ds', 'value']]\n#     df1.index = df1['ds']\n#     df1 = df1.drop(columns=['ds'])\n#     df1 = df1.resample('D').mean()\n#     df1 = df1.reset_index(drop=False)\n#     df1 = df1.dropna().reset_index(drop=True)\n    \n    # The main calculation\n    res = prophet_pred(res, df1, id_station_name, number_steps_in_day, threshold_min=0.95, forecasting_period=forecasting_period)","1f46ccd3":"# def an(s, n, P):\n#     an = (2\/P)*np.pi)*sum()...","afcbfe76":"# def seas(P, t):\n#     # P = period\n#     # N = fourier_order\n    \n#     an = an_calc(y,n,P)\n#     bn = an_calc(y,n,P)\n#     r = 0\n#     for n in range(N)\n#         r += an*np.cos(2*np.pi*n*t)","9c9d9ced":"# seas_daily = seas(P=7, N=2)","23fde6ce":"# from scipy.fft import fft, fftfreq\n# # sample spacing\n# T = 1.0 \/ N\n# x = np.linspace(0.0, N*T, N, endpoint=False)\n# y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n# yf = fft(y)\n# xf = fftfreq(N, T)[:N\/\/2]\n# import matplotlib.pyplot as plt\n# plt.plot(xf, 2.0\/N * np.abs(yf[0:N\/\/2]))\n# plt.grid()\n# plt.show()","29be7160":"## I plan to implement in the future:\n* Download today data from API (SaveEcoBot and Center for Hydrometeorology in Vinnytsia region)\n* Download of state (Center for Hydrometeorology in Vinnytsia region) monitoring data\n* Calculation AQI (Air Quality Index)\n* export optimal parameters of prediction model for each monitoring station to csv-file\n* export results to csv-files","6f85c2df":"### 3.2. Selection parameters <a class=\"anchor\" id=\"3.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","922c4315":"## 5. Result visualization and saving<a class=\"anchor\" id=\"5\"><\/a>\n\n[Back to Table of Contents](#0.1)","ac154434":"### 3.3. Prediction results <a class=\"anchor\" id=\"3.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","d2542989":"### 3.3.1. Results for hourly data <a class=\"anchor\" id=\"3.3.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","8d4bece4":"### 2.1 Download data from SaveEcoBot<a class=\"anchor\" id=\"2.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","7b66c273":"## 4. Synthesis formula for prediction<a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","e8c74ef2":"## 3. Data prediction<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","ae5f0627":"## Acknowledgements\n\n### Notebooks:\n* [Air Quality in Region - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-region-2d-analysis)\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/eda-for-tabular-data-advanced-techniques)\n* [COVID in UA: Prophet with 4, Nd seasonality](https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality)\n\n### Kaggle Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)\n\n### Other open data:\n* [Open data of the Vinnytsia City Council](https:\/\/opendata.gov.ua\/dataset\/pibehb-3a6pydhehocti-test)\n* [API of the Center for Hydrometeorology in Vinnytsia region](http:\/\/meteo.vn.ua\/api\/api.php)","037123fc":"### 2.2 Download data from EcoCity<a class=\"anchor\" id=\"2.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","15ae4ded":"<a class=\"anchor\" id=\"0\"><\/a>\n# Air Quality City - for Vinnytsia city:\n* Download today data from API (SaveEcoBot and Center for Hydrometeorology in Vinnytsia region)\n* Download of public (from SaveEcoBot and EcoCity) monitoring data\n* 2 indicators: PM2.5, PM10\n* prediction data in each monitoring station with tuning parameters\n* conversion of minute data into a given time interval (week, day, hour, 6hour, etc.) with the definition of average or maximum values","58799aae":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n   - [Download data from SaveEcoBot](#2.1)\n   - [Download data from EcoCity](#2.2)\n   - [Selection data for interpolation](#2.3)\n1. [Data prediction](#3)\n   - [Prediction functions](#3.1)\n   - [Selection parameters](#3.2)\n   - [Prediction results](#3.3)\n       - [Results for hourly data](#3.3.1)\n       - [Results for daily data](#3.3.2)\n1. [Synthesis formula for prediction](#4)\n1. [Result visualization and saving](#5)","0599f2cc":"### 3.1. Prediction functions <a class=\"anchor\" id=\"3.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","fd12c6c8":"## 2. Download data<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","97638650":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","fcba170d":"### 2.3 Selection data for interpolation<a class=\"anchor\" id=\"2.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","07f8885d":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","e168900e":"### 3.3.2. Results for daily data <a class=\"anchor\" id=\"3.3.2\"><\/a>\n\n[Back to Table of Contents](#0.1)"}}