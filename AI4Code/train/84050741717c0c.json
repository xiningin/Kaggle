{"cell_type":{"0bbe18a5":"code","c8533b3a":"code","163e3f50":"code","3018b40f":"code","f710bf54":"code","5702633f":"code","9960e6fb":"markdown","df39e11a":"markdown","ae2ecadd":"markdown","3e076516":"markdown","9176c816":"markdown","d6ad3dcb":"markdown"},"source":{"0bbe18a5":"from PIL import Image\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n\n####================Main Preprocessing\n#we classify defective items as positive, as they have the \"signal\" pixels\ndata_dir = \"\/kaggle\/input\/real-life-industrial-dataset-of-casting-product\/casting_512x512\/casting_512x512\/\"\nneg_dir = \"ok_front\/\"\npos_dir = \"def_front\/\"\noutput_dir = \"D:\/ML Data\/Kaggle\/casting\/data\/processed_data_512\/\"\n#output dir split in same way\ndir_list = [pos_dir, neg_dir]\n\npos_imgs, neg_imgs = [], []\nfor pos_file in os.listdir(data_dir+pos_dir):\n    img = Image.open(data_dir+pos_dir+pos_file)\n    img = np.array(img, dtype=np.uint8)\n    pos_imgs.append(img)\nfor neg_file in os.listdir(data_dir+neg_dir):\n    img = Image.open(data_dir+neg_dir+neg_file)\n    img = np.array(img, dtype=np.uint8)\n    neg_imgs.append(img)\n    \nx_data = np.concatenate([pos_imgs,neg_imgs],axis=0)\ny_data = np.concatenate([np.ones( (len(pos_imgs),1) ), \n                        np.zeros( (len(neg_imgs),1) )], axis=0)\n\n\n\n","c8533b3a":"\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.layers import Input, Activation\nfrom tensorflow.keras.layers import Conv2D, Dropout, Reshape, Lambda, Flatten\nfrom tensorflow.keras.layers import GaussianDropout, GaussianNoise\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras.layers import BatchNormalization as BatchNorm\nfrom tensorflow.keras.layers import MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import SGD, RMSprop, Adam\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.utils import Sequence\n\nimport matplotlib as mplot\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nfrom concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n\n####================Main Model Function\ndef build_model(opt, lr, out_type):\n    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')#sets values to be float16 for nvidia 2000,3000 series GPUs, plus others im sure\n    \n    input_img = Input(shape=(512, 512, 1))\n    x = Lambda(lambda x: K.cast_to_floatx(x))(input_img)\n    x = Lambda(lambda x: x\/255.)(x)\n    \n    x = BatchNorm()(x)\n    x = Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = MaxPooling2D(2)(x)\n    x = BatchNorm()(x)\n\n    x = Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = MaxPooling2D(2)(x)\n    x = BatchNorm()(x)\n    \n    x = Conv2D(16, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = MaxPooling2D(2)(x)\n    x = BatchNorm()(x)\n    \n    x = Conv2D(32, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = Conv2D(32, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n    x = MaxPooling2D(2)(x)\n    x = BatchNorm()(x)    \n\n    x = Conv2D(16, 1, activation=\"selu\",kernel_initializer=\"lecun_normal\",dtype=policy)(x)\n    x = Conv2D(1, 1, activation='linear')(x)\n    x_map = Activation(\"sigmoid\")(x)\n    \n\n    \n    y = GlobalMaxPooling2D()(x_map)\n    \n    if opt == \"SGD\":\n        #looks like pretty good but noisy results with no momentum, lets check 0.9...\n        optimizer = SGD(lr=lr)\n    if opt == \"RMSprop\":\n        optimizer = RMSprop(learning_rate=lr)\n    if opt == \"Adam\":\n        optimizer = Adam(learning_rate=lr)\n\n    if out_type == \"classify\":\n        model = Model(inputs=input_img, outputs=y)\n    if out_type == \"map\":\n        model = Model(inputs=input_img, outputs=x_map)\n    model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n\n    return model\n\n","163e3f50":"\n####================Data Generator, mostly used for rotation\/flip augmentation\n#idk why this is separated exaclty\ndef augment_image(img):\n    if np.random.rand()>0.5:\n        img = np.transpose(img, axes=(1,0,2))\n    img = np.rot90(img, np.random.randint(0,3), axes=(0,1))\n    return img\n\nclass Augment_Generator(Sequence):\n    def __init__(self, images, y_data, batch_size, shuffle, augment, mode):\n        'Initialization'\n        self.images = images\n        self.y_data = y_data\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.augment = augment\n        self.mode=mode     \n        \n        self.epoch_ix = np.arange(len(self.images))\n        \n        if self.shuffle:\n            np.random.shuffle(self.epoch_ix)\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.ceil(len(self.epoch_ix)\/self.batch_size))\n \n    def __getitem__(self, index):\n        'Generate one batch of data'       \n        batch_ixs = self.epoch_ix[index*self.batch_size:(index+1)*self.batch_size]#exchange sequential call with shuffleable ix list\n        x_batch = self.images[batch_ixs]\n        if self.augment:\n            x_batch = np.asarray([augment_image(img) for img in x_batch])\n        \n        if self.mode==\"Train\" or self.mode==\"Validate\":\n            y_batch = self.y_data[batch_ixs]        \n            return x_batch,y_batch\n        if self.mode==\"Test\":\n            return x_batch\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.epoch_ix)#shuffle the order of lines\n\n####================Callbacks and stuff for monitoring progress\nclass PlotLoss(Callback):\n    def __init__(self, freq):\n        self.freq = freq      \n        self.logs = []\n        self.train_auc = []\n        self.val_auc = []\n        self.loss = []\n        self.val_loss = []\n    def on_epoch_end(self, epoch, logs={}):\n        if (epoch+1)%self.freq==0:\n            self.logs.append(logs)\n            self.train_auc.append(logs.get('auc'))\n            self.loss.append(logs.get('loss'))\n            self.val_auc.append(logs.get('val_auc'))\n            self.val_loss.append(logs.get('val_loss'))\n            fig, ax = plt.subplots(1,2, figsize=(12,5))\n            ax[0].plot(self.train_auc)\n            ax[0].plot(self.val_auc)            \n            ax[1].plot(self.loss)\n            ax[1].plot(self.val_loss)\n            plt.show()            \n        return\n","3018b40f":"\n####================Model Construction\n\nshuffle_ix = list(range(len(x_data)))\nnp.random.shuffle(shuffle_ix)\nx_data = x_data[:,:,:,0:1]\nx_data = x_data[shuffle_ix]\ny_data = y_data[shuffle_ix]\n\nval_ix = int(np.floor(len(x_data)*0.8))\nx_train = x_data[:val_ix]\ny_train = y_data[:val_ix]\n\nx_valid = x_data[val_ix:]\ny_valid = y_data[val_ix:]\n\n\ntrain_batch, valid_batch = 16, 32\ntrain_gen = Augment_Generator(x_train, y_train, batch_size=train_batch, shuffle=True, augment=True, mode=\"Train\")\nvalid_gen = Augment_Generator(x_valid, y_valid, batch_size=valid_batch, shuffle=False, augment=False, mode=\"Validate\")\ntrain_steps = int(np.ceil(len(x_train)\/train_batch))\nvalid_steps = int(np.ceil(len(x_valid)\/valid_batch))\n\n\nmap_model = build_model(\"SGD\", 1e-2, \"map\")\nPlot_Boxes = PlotBoxes(map_model, disp_imgs, (29, 64, 16), 5)\nplot_Loss = PlotLoss(5)\n\nmodel = build_model(\"SGD\", 1e-2, \"classify\")\nmodel.summary()\n\n\nhist = model.fit(train_gen, steps_per_epoch=train_steps, epochs=200,\n                 validation_data=valid_gen, validation_steps=valid_steps,\n                 verbose=0)\nplt.plot(hist.history['auc'])\nplt.plot(hist.history['val_auc'])\nplt.show()\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.show()","f710bf54":"\n\n#takes in 6 images and activation maps, reutrns a 3x2 grid of images with box highlighting   \ndef plot_maps(images, maps, k, dims):\n    map_size=dims[0]\n    r_size = dims[1]\n    r_stride = dims[2]\n    colors = ['#ff0000', '#ff0080', '#ff00ff', '#8000ff', '#0080ff', '#00ffff', '#00ff80']\n              \n    fig, ax = plt.subplots(2, 3, figsize=(12,8))\n    for j , (img, mask) in enumerate(zip(images, maps)):\n        mask = mask.flatten()\n        j_a = (j-j%3)\/\/3\n        j_b = j%3\n        img = np.asarray(img[:,:,0],dtype=np.float32)\/255\n        ax[j_a][j_b].imshow(img,cmap=plt.get_cmap('gray'))\n        \n        for i in range(k):\n            a_max = np.argmax(mask)\n            x_region = a_max%map_size#note, numpy addresses work on arr[y, x, z], compared to image coordinates\n            y_region = (a_max-(a_max%map_size))\/\/map_size\n            prob = mask[a_max]\n            if prob<0.5:break\n            x_pixel = r_stride*(x_region)\n            y_pixel = r_stride*(y_region)\n   \n            \n            \n            #rectangle expects bottom left coordinates. We've generated Top Right\n            rectangle = mplot.patches.Rectangle((x_pixel, y_pixel), r_size, r_size, edgecolor=colors[i-1],facecolor=\"none\")\n            ax[j_a][j_b].add_patch(rectangle)\n            \n            font = {'color':colors[i-1]}\n            ax[j_a][j_b].text(x_pixel,y_pixel,s=\"{0:.3f}\".format(prob), fontdict=font)\n            \n            mask[a_max]= 0#to help get the next most maximum\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.show()\n            \n            \n        ","5702633f":"#we select out some display images, 3 positive and 3 negative samples\ndisp_imgs_pos = x_valid[np.where(y_valid==1)[0][:3]]\ndisp_imgs_neg = x_valid[np.where(y_valid==0)[0][:3]]\ndisp_imgs = np.concatenate([disp_imgs_pos, disp_imgs_neg], axis=0)\n\nmap_model.set_weights(model.get_weights())\n\npred_maps = map_model.predict(disp_imgs)\n\nplot_maps(disp_imgs, pred_maps, 5, (29, 64, 16))","9960e6fb":"Now for the magic part, we load the trained weights into Map Model, and we output a set of scores for each region of the input images. \nThis shows three positive samples from the validation set on top, and three negative samples from the val set on bottom. \n\nMagic.","df39e11a":"This is a simple CNN designed for SemiSupervised Learning. Our goal is not just to classify images, but also localize our detection to specific regions of the image. This is a relatively robust model, and should train relatively well on a wide range of hyperparameters. ","ae2ecadd":"Next, we're going to define the model. This is not all that different from models like VGG or Resnet. In normal object detection we want information from all over the image to combine, but to do localization we want to do exaclty not that. Instead, we'll classify each patch directly, which is why a 1x1 conv layer reduces the channels to 1, and sigmoid activates. \n\nPrior, I had opened several of the 512x512 files in GIMP and notice that their channel information is duplicated. Then, I estimated the size of the typical fault and found they were between 16px and 32px wide. I decided a detection area of 64x64 pixels was approprate. This isn't a hyperparameter, but must be baked into the size and order of the conv layers, in order to generate a receptive field of 64. \n\nSince any patch with a defect implies the image is of a defected part, we use GlobalMaxPooling to select the highest defect score as the image score. \n\nI find the imbalanced nature of this problem to be a serious issue for RELU, SELU supposedly has magic properties and it doesn't let down here. However, its typically not advised to mix MaxPooling with selu, in favor of strided convolution. I found they would overfit, so I just batchnormed the output of the max poolings. Selu is, to some degree, meant to eliminate batch norm, so this may not really be necessary. \n\nTowards the end we define two ways to return the model, in \"classify\" and \"map\" modes. Basically, classify mode output the maximum region score, \"map\" mode outputs all of the region scores, so we can highlight those regions on the images later. ","3e076516":"Next we defeine the generator. I tend to do these by hand so I can do more advanced augmentation, but it didn't seem totally necessary this time. I only use transpose and 90-degree rotations for augmentation. ","9176c816":"1. Here we organize data into train and validation sets, and run the model","d6ad3dcb":"This first section just loads the data, should be standard stuff"}}