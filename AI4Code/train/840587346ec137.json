{"cell_type":{"cde269d2":"code","26b68492":"code","686bd155":"code","726631c2":"code","52e257ef":"code","b62d7cc1":"code","23dde25c":"markdown","137b9306":"markdown"},"source":{"cde269d2":"!pip install interface_meta --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/interface_meta-1.2.4-py2.py3-none-any.whl\n!pip install astor --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/astor-0.8.1-py2.py3-none-any.whl\n!pip install formulaic --no-index --find-links=file:..\/input\/formulaic\/formulaic-0.2.4-py3-none-any.whl\n!pip install autograd --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/autograd-1.3-py3-none-any.whl\n!pip install autograd-gamma --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/autograd-gamma-0.5.0\/dist\/autograd-gamma-0.5.0.tar\n!pip install lifelines --no-index --find-links=file:..\/input\/lifelines\/lifelines-0.26.4-py3-none-any.whl\n!pip install ngboost --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/ngboost-0.3.12-py3-none-any.whl\n!pip install boostaroota --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/boostaroota-1.3-py2.py3-none-any.whl\n!pip install matplotlib --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl\n!pip install catboost --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/catboost-0.21-cp38-none-manylinux1_x86_64.whl\n!pip install pytorch_tabnet --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/pytorch_tabnet-3.1.1-py3-none-any.whl\n!pip install shap --no-index --find-links=file:..\/input\/e2eml-inc-dependencies\/shap-0.39.0-cp35-cp35m-linux_armv6l.whl\n!pip uninstall scikit-learn -y\n!pip install scikit-learn --no-index --find-links=file:..\/input\/sklearn-1-0\/scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n!pip install e2eml --no-index --no-dependencies --find-links=file:..\/input\/e2eml-inc-dependencies\/e2eml-2.10.4-py3-none-any.whl","26b68492":"import pandas as pd\nimport numpy as np\n# load libraries\nimport sys\nfrom e2eml.regression import regression_blueprints\nfrom e2eml.full_processing import postprocessing\nfrom e2eml.full_processing.postprocessing import save_to_production, load_for_production\nfrom e2eml.timetravel import timetravel\nfrom sklearn.model_selection import train_test_split\nimport gc","686bd155":"target = \"target\"","726631c2":"market_ml = load_for_production(file_path='..\/input\/ubiquant-e2eml-lgbm\/', file_name='market_ml_lgbm_instance.dat')","52e257ef":"import ubiquant\nenv = ubiquant.make_env()\n# initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","b62d7cc1":"for (test_df, sample_prediction_df) in iter_test:\n    test_df[\"time_id\"] = 0\n    market_ml = load_for_production(file_path='..\/input\/ubiquant-e2eml-lgbm\/', file_name='market_ml_lgbm_instance.dat') # load Blueprint\n    market_ml.ml_bp12_regressions_full_processing_lgbm(test_df) # predict\n    sample_prediction_df['target'] =   market_ml.predicted_values['lgbm'] # attach predictions\n    env.predict(sample_prediction_df)   # register your predictions\n    del test_df\n    del market_ml\n    del sample_prediction_df\n    _ = gc.collect()","23dde25c":"# Automl using e2eml\n\nWe use e2eml. There are plenty of fantastic frameworks. Chose whatever you like.\nHere we:\n- load our prepared blueprint (see part 2 for the creation part)\n- run the blueprint to get new predictions\n- keep memory clean\n\nPretty elegant :-) ","137b9306":"# Follow up\nIn the previous notebook we took a micro sample and tried to find the best model and preprocessing based on it:\nhttps:\/\/www.kaggle.com\/thomasmeiner\/naive-model-overview-using-automl-on-micro-sample \n\nNow we make use of our results and train a model finally.\n"}}