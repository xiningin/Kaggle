{"cell_type":{"c539bf70":"code","ae2056b0":"code","7ec115f0":"code","1908b315":"code","1c748814":"code","81ebc46b":"code","d4bb4c48":"code","c95d4758":"code","c8f3490c":"code","17612fc6":"code","a12d6ae8":"code","e869f1ef":"code","085ed5f0":"markdown","ab28720c":"markdown","212185e8":"markdown","6e5300f9":"markdown","43a42027":"markdown"},"source":{"c539bf70":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ae2056b0":"import torch \nimport pandas as pd\nimport numpy as np\nfrom torch import nn,optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import LabelBinarizer","7ec115f0":"train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest  = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\nprint(train.shape)\nprint(test.shape)","1908b315":"# Splitting the labels from data\nxtrain = np.array(train.iloc[:,1:])\/255\nytrain = np.array(train.iloc[:,0])\nxtest = np.array(test.iloc[:,1:])\/255\nytest = np.array(test.iloc[:,0])\n\nprint(xtrain.shape, ytrain.shape)\nprint(xtest.shape, ytest.shape)","1c748814":"# Train loader\ntensor_x = torch.Tensor(xtrain) # transform to torch tensor\ntensor_y = torch.Tensor(ytrain)\ntensor_y = tensor_y.type(torch.LongTensor)\n\n\nmy_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\ntrain_loader = DataLoader(my_dataset,batch_size = 64) # create your dataloader for train data\n\n# Test Loader\ntensor_xtest = torch.Tensor(xtest) # transform to torch tensor\ntensor_ytest = torch.Tensor(ytest)\ntensor_ytest = tensor_ytest.type(torch.LongTensor)\n\n\nmy_dataset = TensorDataset(tensor_xtest,tensor_ytest) # create your datset\ntest_loader = DataLoader(my_dataset,batch_size = 64,shuffle=True) # create your dataloader for test data","81ebc46b":"class Net(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        # Fully-connected layer-1\n        self.fc1 = nn.Linear(784, 256)\n        # Fully-connected layer-2\n        self.fc2 = nn.Linear(256, 128)\n        # Fully-connected layer-3\n        self.fc3 = nn.Linear(128,64)\n        # Fully-connected layer-4 or output-layer\n        self.fc4 = nn.Linear(64,10)\n        \n        #Lets create a Dropout to prevent overfitting\n        self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self,x):\n        x = self.dropout(F.relu(self.fc1(x))) # ReLU and dropout is applied to layer-1\n        x = self.dropout(F.relu(self.fc2(x))) # ReLU and dropout is applied to layer-1\n        x = self.dropout(F.relu(self.fc3(x))) # ReLU and dropout is applied to layer-1\n        x = F.log_softmax(self.fc4(x),dim=1)  # Softmax is applied to output layer\n        return x","d4bb4c48":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","c95d4758":"model = Net()\n\n# Loss \ncriterion = nn.NLLLoss()\n\n# Optimizer\noptimizer = optim.Adam(model.parameters(),lr=0.003)","c8f3490c":"# Shift model to GPU\nmodel = model.to(device)","17612fc6":"epochs = 100\n\nloss_train,acc_train,losstest,acctest = [],[],[],[]\n\nfor e in range(1,epochs + 1):\n    \n    # Setting model to train mode\n    model.train()\n    \n    running_loss, total, correct = 0,0,0\n    \n    for images,labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        # Forward Pass\n        outputs = model(images)\n        loss = criterion(outputs,labels)\n        \n        # Backward Pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        #Metrics\n        _, predicted = torch.max(outputs.data, 1)\n        running_loss += loss.item()\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    else:\n        # Validation Forward pass\n        with torch.no_grad():\n            \n            # setting model to test mode\n            model.eval()    # will switch off dropouts during test\n            \n            running_loss_test, total_test, correct_test = 0,0,0\n            for images_test, labels_test in test_loader:\n                images_test, labels_test = images_test.to(device), labels_test.to(device)\n                # Forward Pass\n                outputs_test = model(images_test)\n                loss_test = criterion(outputs_test,labels_test)\n\n                #Metrics\n                _, predicted_test = torch.max(outputs_test.data, 1)\n                running_loss_test += loss_test.item()\n                total_test += labels_test.size(0)\n                correct_test += (predicted_test == labels_test).sum().item()\n\n        # Logs per Epoch\n        loss_train.append(running_loss)\n        acc_train.append(correct\/total * 100)\n        losstest.append(running_loss_test)\n        acctest.append(correct_test\/total_test * 100)\n        print(f'Epoch {e} Train: Loss: {running_loss}, Accuracy = {correct\/total * 100 :.2f} Validation: Loss: {running_loss_test}, Accuracy = {correct_test\/total_test * 100 :.2f}')\n        ","a12d6ae8":"import plotly.graph_objs as go\n\n# Plot Loss\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = loss_train,\n    mode = 'lines',\n    name = 'Train loss'   \n))\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = losstest,\n    mode = 'lines',\n    name = 'Validation loss'   \n))\n\nfig.update_layout(\n    title = 'Train and Validation Loss'\n)\nfig.show()","e869f1ef":"# Plot Accuracy\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = acc_train,\n    mode = 'lines',\n    name = 'Train Accuracy'   \n))\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = acctest,\n    mode = 'lines',\n    name = 'Validation Accuracy'   \n))\n\nfig.update_layout(\n    title = 'Train and Validation Accuracy'\n)\nfig.show()","085ed5f0":"**1. Import the Necessary Dependancies**","ab28720c":"**3. Neural Network Architecture**","212185e8":"Dataloaders are useful for supplying the data to your model in batches. Before that lets just split the labels from the data and normalize the pixels by dividing each pixel by 255.","6e5300f9":"**4. Train the model**","43a42027":"**2. Creating the Data Loaders**"}}