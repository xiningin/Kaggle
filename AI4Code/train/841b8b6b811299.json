{"cell_type":{"f0927d71":"code","f7383108":"code","d4aee005":"code","0af61a6b":"code","d518a19a":"code","ef9e210c":"code","81733c77":"code","287727a9":"code","b55e80a3":"code","e25cda4c":"code","866b1bdb":"code","88d993c1":"code","04e54d82":"code","ba8e4b1e":"code","aa7b9802":"code","f1e332db":"markdown"},"source":{"f0927d71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7383108":"solar_2= pd.read_csv('\/kaggle\/input\/solar-power-generation-data\/Plant_2_Generation_Data.csv')\nweather_2 = pd.read_csv('\/kaggle\/input\/solar-power-generation-data\/Plant_2_Weather_Sensor_Data.csv')","d4aee005":"solar_2","0af61a6b":"weather_2.head()","d518a19a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport warnings\nimport datetime as dt\nimport matplotlib.dates as mdates\nwarnings.filterwarnings('ignore')","ef9e210c":"#my aim now is to analyse the data and find falty and underperforming solar panels \n#plot daily yield & AC power \n\nsns.distplot(solar_2['AC_POWER'])\n","81733c77":"sns.distplot(solar_2['DAILY_YIELD'])","287727a9":"var = 'DATE_TIME'\ndata= pd.concat([solar_2['DAILY_YIELD'],solar_2[var]],axis=1)\ndata.plot(x=var,y='DAILY_YIELD')","b55e80a3":"import datetime\n\n#so it is the same way. I want to fix the dates this time \n#I will format the date_time feature\n#I dont know how these two lines work:\nsolar_2['DATE_TIME']= pd.to_datetime(solar_2['DATE_TIME'],format='%Y-%m-%d')\ndf_gen=solar_2.groupby('DATE_TIME').sum().reset_index()\ndf_gen['time']=df_gen['DATE_TIME'].dt.time\n#So i will investigate them further.\n\n\n\ndf_gen.plot(x='DATE_TIME',y='DAILY_YIELD',color='navy')","e25cda4c":"solar_2.value_counts()  ","866b1bdb":"weather_2.value_counts()","88d993c1":"solar_2.isna().sum() #no missing values in solar data","04e54d82":"weather_2.isna().sum() #no missing values here as well ","ba8e4b1e":"solar_2.groupby('AC_POWER').SOURCE_KEY.count() #","aa7b9802":"solar_2['SOURCE_KEY'].nunique() #there is 1 plant ID which is unique ","f1e332db":"This is the article which will help me in exporing the data: https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python \n\nI will also get some help from here:https:\/\/www.kaggle.com\/virosky\/how-to-manage-a-solar-power-plant\n\n\nfirst identify the variables, then the type of variables, then the segment (building space location), expectations "}}