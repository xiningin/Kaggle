{"cell_type":{"bea33301":"code","1984f44a":"code","01cfb709":"code","0983729f":"code","624a5ec7":"code","14399b98":"code","4f793f2c":"code","1c7fce54":"code","72bb0af9":"code","e2274b51":"code","a45f32d0":"code","c8fd0d5d":"code","5106f877":"code","a675f4aa":"code","79849545":"code","023731c2":"code","ba2654d9":"code","e999b5b9":"code","6f3eb23c":"code","ecb2c090":"code","e97a5a16":"code","2737698b":"code","34b2ccd7":"code","a1f4d8d3":"code","1bd2515e":"code","0cba97d5":"code","30850127":"code","f2068c54":"code","7494bdb5":"code","f2e1db3c":"code","9aab5d59":"code","49e6bcbc":"code","cf76c2e7":"code","865b2542":"code","ba0c1fad":"code","54b6ab88":"code","241bf3cc":"code","6904a4be":"code","e49e7721":"code","43b978a7":"code","d2c9d4d8":"code","e3183697":"code","c3ec75ee":"code","21281dfc":"code","1186b3f2":"code","7a64cb87":"code","7da82464":"code","fa4fd374":"code","01f786eb":"code","6164111a":"code","e1c9e5b2":"code","2fb0d985":"code","d273b1a1":"code","11729e46":"code","708fce06":"code","5e914445":"code","97311ded":"markdown","f135db2f":"markdown","92c7fdce":"markdown","cd0daa95":"markdown","153b9285":"markdown","bfeb2ea6":"markdown","b4559a0a":"markdown","02aaaa64":"markdown","8694f088":"markdown","ad99659d":"markdown","13e85366":"markdown","86e3efe5":"markdown","bf4f7d94":"markdown","f135aea1":"markdown","1213d7c5":"markdown","8c0e38f4":"markdown","f1ec9261":"markdown","18dbe526":"markdown","930e0776":"markdown","043a0cb7":"markdown","b2ec7cca":"markdown","411b5b39":"markdown","f8d3e511":"markdown","1eb5a160":"markdown","39a54643":"markdown","31eab6ad":"markdown","b265cee1":"markdown","7954b7fe":"markdown","a4c00b00":"markdown","90ae083e":"markdown","a85340e1":"markdown","5837cf19":"markdown","8d9ca5de":"markdown","4c50ea77":"markdown","aa1ca8d1":"markdown","99c0dbf0":"markdown","42dc26fa":"markdown","4273285d":"markdown","d49b66d9":"markdown","445ccde7":"markdown","12b1646c":"markdown","b3588d32":"markdown","de150110":"markdown","be6feb1f":"markdown","d297abdd":"markdown","af68c39d":"markdown","cd024a8f":"markdown","f38c99f5":"markdown","64ce8fb2":"markdown","be08934a":"markdown","c32a9bb4":"markdown","7cd7c8f1":"markdown"},"source":{"bea33301":"import warnings\nimport random\nimport os\nimport gc\nimport torch","1984f44a":"import pandas            as pd\nimport numpy             as np\nimport matplotlib.pyplot as plt \nimport seaborn           as sns\nimport joblib            as jb\nimport scikitplot        as skplt","01cfb709":"from sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.preprocessing   import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, QuantileTransformer\nfrom sklearn.impute          import SimpleImputer\nfrom sklearn                 import metrics","0983729f":"import xgboost               as xgb","624a5ec7":"def jupyter_setting():\n    \n    %matplotlib inline\n      \n    #os.environ[\"WANDB_SILENT\"] = \"true\" \n    #plt.style.use('bmh') \n    #plt.rcParams['figure.figsize'] = [20,15]\n    #plt.rcParams['font.size']      = 13\n     \n    pd.options.display.max_columns = None\n    #pd.set_option('display.expand_frame_repr', False)\n\n    warnings.filterwarnings(action='ignore')\n    warnings.simplefilter('ignore')\n    warnings.filterwarnings('ignore')\n    #warnings.filterwarnings(category=UserWarning)\n\n    warnings.filterwarnings('ignore', category=DeprecationWarning)\n    warnings.filterwarnings('ignore', category=FutureWarning)\n    warnings.filterwarnings('ignore', category=RuntimeWarning)\n    warnings.filterwarnings('ignore', category=UserWarning)\n    #warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n    pd.set_option('display.max_rows', 150)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.max_colwidth', None)\n\n    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n    #sns.palplot(sns.color_palette(icecream))\n    \n    return icecream\n\nicecream = jupyter_setting()\n\n# Colors\ndark_red = \"#b20710\"\nblack    = \"#221f1f\"\ngreen    = \"#009473\"\nmyred    = '#CD5C5C'\nmyblue   = '#6495ED'\nmygreen  = '#90EE90'\n\ncols= [myred, myblue,mygreen]","14399b98":"colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]","4f793f2c":"def missing_zero_values_table(df):\n        mis_val         = df.isnull().sum()\n        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n                                                     0 : 'Valores ausentes', \n                                                     1 : '% de valores totais'})\n        \n        mz_table['Tipo de dados'] = df.dtypes\n        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n                                     sort_values('% de valores totais', ascending=False)\n        \n        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n            \n        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n        \n        return mz_table.reset_index()","1c7fce54":"def describe(df):\n    var = df.columns\n\n    # Medidas de tend\u00eancia central, m\u00e9dia e mediana \n    ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n    ct2 = pd.DataFrame(df[var].apply(np.median)).T\n\n    # Dispens\u00e3o - str, min , max range skew, kurtosis\n    d1 = pd.DataFrame(df[var].apply(np.std)).T\n    d2 = pd.DataFrame(df[var].apply(min)).T\n    d3 = pd.DataFrame(df[var].apply(max)).T\n    d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n    d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n    d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n    d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) \/ np.std(x) ))).T\n\n    # concatenete \n    m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n    m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n    \n    return m","72bb0af9":"def reduce_memory_usage(df, verbose=True):\n    \n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    \n    for col in df.columns:\n        \n        col_type = df[col].dtypes\n        \n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n        \n    return df","e2274b51":"def plot_roc_curve(fpr, tpr, label=None):\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr, \"r-\", label=label)\n    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.rcParams['font.size'] = 12\n    plt.title('ROC curve for TPS 09')\n    plt.xlabel('False Positive Rate (1 - Specificity)')\n    plt.ylabel('True Positive Rate (Sensitivity)')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)","a45f32d0":"def confusion_plot(matrix, labels = None, title = None):\n        \n    labels = labels if labels else ['Negative (0)', 'Positive (1)']    \n    \n    fig, ax = plt.subplots(nrows=1, ncols=1)\n    \n    sns.heatmap(data        = matrix, \n                cmap        = 'Blues', \n                annot       = True, \n                fmt         = 'd',\n                xticklabels = labels, \n                yticklabels = labels, \n                ax          = ax);\n    \n    ax.set_xlabel('\\n PREVISTO', fontsize=15)\n    ax.set_ylabel('REAL \\n', fontsize=15)\n    ax.set_title(title)\n    \n    plt.close();\n    \n    return fig;","c8fd0d5d":"!mkdir img\n!mkdir Data\n!mkdir Data\/pkl\n!mkdir Data\/submission\n\n!mkdir model\n!mkdir model\/preds\n!mkdir model\/optuna\n\n!mkdir model\/preds\/test\n!mkdir model\/preds\/test\/n1\n!mkdir model\/preds\/test\/n2\n!mkdir model\/preds\/test\/n3\n\n!mkdir model\/preds\/train\n!mkdir model\/preds\/train\/n1\n!mkdir model\/preds\/train\/n2\n!mkdir model\/preds\/train\/n3\n!mkdir model\/preds\/param","5106f877":"path = '..\/input\/tabular-playground-series-nov-2021\/'","a675f4aa":"%%time\n\ndf1_train     = pd.read_csv(path + 'train.csv')\ndf1_test      = pd.read_csv(path + 'test.csv')\ndf_submission = pd.read_csv(path + 'sample_submission.csv')\n\ndf1_train.shape, df1_test.shape, df_submission.shape","79849545":"df1_train.head()","023731c2":"df1_test.head()","ba2654d9":"print('TREINO')\nprint('Number of Rows: {}'.format(df1_train.shape[0]))\nprint('Number of Columns: {}'.format(df1_train.shape[1]), end='\\n\\n')\n\nprint('TESTE')\nprint('Number of Rows: {}'.format(df1_test.shape[0]))\nprint('Number of Columns: {}'.format(df1_test.shape[1]))","e999b5b9":"df1_train.info()","6f3eb23c":"df1_test.info()","ecb2c090":"print(f'{3*\"=\"} For Pandas {10*\"=\"}\\n{(df1_train.dtypes).value_counts()}')\nprint(f'\\n{3*\"=\"} For Datatable {7*\"=\"}\\n{(df1_test.dtypes).value_counts()}')","e97a5a16":"missing = missing_zero_values_table(df1_train)\nmissing[:].style.background_gradient(cmap='Reds')","2737698b":"missing = missing_zero_values_table(df1_test)\nmissing[:].style.background_gradient(cmap='Reds')","34b2ccd7":"feature_cat   = df1_test.select_dtypes(object).columns.to_list()\nfeature_float = df1_test.select_dtypes(np.number).columns.to_list()","a1f4d8d3":"print('Temos {} vari\u00e1vies num\u00e9ricas e {} categ\u00f3ricas.'.format(len(feature_float), len(feature_cat)))","1bd2515e":"df1_train[feature_float].describe().style.background_gradient(cmap='YlOrRd')","0cba97d5":"df1_test[feature_float].describe().style.background_gradient(cmap='YlOrRd')","30850127":"df1_train[feature_cat].columns","f2068c54":"df = df1_train[feature_float].corr().round(5)\n\n# M\u00e1scara para ocultar a parte superior direita do gr\u00e1fico, pois \u00e9 uma duplicata\nmask = np.zeros_like(df)\nmask[np.triu_indices_from(mask)] = True\n\n# Making a plot\nplt.figure(figsize=(16,16))\nax = sns.heatmap(df, annot=False, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n\nax.set_title(\"Mapa de calor de correla\u00e7\u00e3o das vari\u00e1vel\", fontsize=17)\n\nplt.setp(ax.get_xticklabels(), \n         rotation      = 90, \n         ha            = \"right\",\n         rotation_mode = \"anchor\", \n         weight        = \"normal\")\n\nplt.setp(ax.get_yticklabels(), \n         weight        = \"normal\",\n         rotation_mode = \"anchor\", \n         rotation      = 0, \n         ha            = \"right\");","7494bdb5":"fig, ax = plt.subplots(figsize=(5, 5))\n\npie = ax.pie([len(df1_train), len(df1_test)],\n             labels   = [\"Train dataset\", \"Test dataset\"],\n             colors   = [\"salmon\", \"teal\"],\n             textprops= {\"fontsize\": 15},\n             autopct  = '%1.1f%%')\n\nax.axis(\"equal\")\nax.set_title(\"Compara\u00e7\u00e3o de comprimento do conjunto de dados \\n\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","f2e1db3c":"fig, ax = plt.subplots(figsize=(5, 5))\n\nplt.pie([len(feature_cat), len(feature_float)], \n        labels=['Categorical', 'Continuos'],\n        textprops={'fontsize': 13},\n        autopct='%1.1f%%')\n\n#ax.axis(\"equal\")\nax.set_title(\"Compara\u00e7\u00e3o vari\u00e1veis continuas\/categ\u00f3ricas \\n Dataset Treino\/Teste\", fontsize=18)\nfig.set_facecolor('white')\nplt.show()","9aab5d59":"%%time \n\ncol = [(1,51), (51,100),  ]\n       \nfor x in col:\n       \n    L    = len(df1_train[feature_float].columns[x[0]:x[1]])\n    nrow = int(np.ceil(L\/6))\n    ncol = 6\n    i    = 1\n\n    remove_last = (nrow * ncol) - L\n    fig, ax     = plt.subplots(nrow, ncol,figsize=(24, 30))\n    \n    fig.subplots_adjust(top=0.95)\n    \n    for feature in df1_train[feature_float].columns[x[0]:x[1]]:\n\n        plt.subplot(nrow, ncol, i)\n\n        ax = sns.kdeplot(df1_train[feature], shade=True, color='salmon',  alpha=0.5, label='train')\n        ax = sns.kdeplot(df1_test[feature], shade=True, color='teal',  alpha=0.5, label='test')\n        plt.xlabel(feature, fontsize=9)\n        plt.legend()\n\n        i += 1\n        \n        gc.collect()\n    \n    plt.suptitle('DistPlot: train & test data de {} \u00e0 {}'.format(x[0],x[1]), fontsize=20)\n    plt.show()\n    \n    gc.collect()\n    \ngc.collect()","49e6bcbc":"col = [(1,21), (21,41), (41,61), (61,81), (81,101)]\n\ndf_plot = ((df1_train[feature_float] - df1_train[feature_float].min())\/\n           (df1_train[feature_float].max() - df1_train[feature_float].min()))\n\nfig, ax = plt.subplots(len(col), 1, figsize=(25,30))\n\nfor i, (x) in enumerate(col): \n    sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]);\n    gc.collect()","cf76c2e7":"col = [(1,21), (21,41), (41,61), (61,81), (81,101)]\n\ndf_plot = ((df1_test[feature_float] - df1_test[feature_float].min())\/\n           (df1_test[feature_float].max() - df1_test[feature_float].min()))\n\nfig, ax = plt.subplots(len(col), 1, figsize=(25,30))\n\nfor i, (x) in enumerate(col): \n    sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]);\n    gc.collect()    \n    ","865b2542":"plt.figure(figsize=(8, 6))\nax = sns.countplot(x=df1_train['target'], palette='viridis')\nax.set_title('Distribui\u00e7\u00e3o da vari\u00e1vel Target', fontsize=20, y=1.05)\n\nsns.despine(right=True)\nsns.despine(offset=10, trim=True)","ba0c1fad":"%%time \n\ncol = [(1,21), (21,41), (41,61), (61,81), (81,100) ]\n       \nfor x in col:\n       \n    L    = len(df1_train[feature_float].columns[x[0]:x[1]])\n    nrow = int(np.ceil(L\/6))\n    ncol = 6\n    i    = 1\n\n    remove_last = (nrow * ncol) - L\n    fig, ax     = plt.subplots(nrow, ncol,figsize=(30, 20))\n    \n    fig.subplots_adjust(top=0.95)\n    \n    for feature in df1_train[feature_float].columns[x[0]:x[1]]:\n\n        plt.subplot(nrow, ncol, i)\n\n        ax = sns.kdeplot(df1_train[feature], \n                     shade    = True, \n                     palette  = 'viridis',  \n                     alpha    = 0.5, \n                     hue      = df1_train['target'], \n                     multiple = \"stack\")\n        \n        plt.xlabel(feature, fontsize=9)\n       \n        i += 1\n        \n        gc.collect()\n    \n    plt.suptitle('DistPlot: Vari\u00e1vel de treino vs target {} \u00e0 {}'.format(x[0],x[1]), fontsize=20)\n    \n    plt.show()\n       \n    gc.collect()\n    \ngc.collect()","54b6ab88":"%%time\ndf1_train = reduce_memory_usage(df1_train)\ndf1_test  = reduce_memory_usage(df1_test)","241bf3cc":"#jb.dump(df1_train, path + 'pkl\/df1_nb_01_train.pkl.z')\n#jb.dump(df1_test,  path + 'pkl\/df1_nb_01_test.pkl.z')","6904a4be":"gc.collect()\nX      = df1_train.drop(['target', 'id'], axis=1)\ny      = df1_train['target']\nX_test = df1_test.drop(['id'], axis=1)\ncols   = X_test.columns\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size    = 0.2,\n                                                      shuffle      = True, \n                                                      stratify     = y,\n                                                      random_state = 12359)\n\ndel df1_train,df1_test\n\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape , X_test.shape","e49e7721":"X_test.head()","43b978a7":"seed   = 12359\nparams = {'objective'     : 'binary:logistic',    \n          'eval_metric'   : 'auc',\n          'random_state'  : seed}\n\nif torch.cuda.is_available():           \n    params.update({'predictor'  : 'gpu_predictor', \n                   'tree_method': 'gpu_hist', \n                   'gpu_id'     :  0})\n\nparams","d2c9d4d8":"%%time \n\nmodel_baseline = xgb.XGBClassifier(**params)\n\nscalers = [None, \n           StandardScaler(), \n           RobustScaler(), \n           MinMaxScaler(), \n           MaxAbsScaler(), \n           QuantileTransformer(output_distribution='normal', random_state=0)]\n\nfor scaler in scalers: \n    \n    if scaler!=None:\n        X_train_s = scaler.fit_transform(X_train)\n        X_valid_s = scaler.fit_transform(X_valid)\n    else:\n        X_train_s = X_train\n        X_valid_s = X_valid\n                \n    model_baseline.fit(X_train_s, y_train, verbose = False)\n    y_hat = model_baseline.predict_proba(X_valid_s)[:, 1]    \n    auc   = metrics.roc_auc_score(y_valid, y_hat) \n    \n    print('Valida\u00e7ao AUC: {:2.5f} => {}'.format(auc, scaler))\n\n    gc.collect()\n\nprint()   ","e3183697":"path='Data\/'\ndef cross_val_model(model, X_train_, y_train_, X_test_,  scalers, name_model, \n                    FOLDS=5, verbose=False, seed=12359, use_ntree_limit=False): \n    \n    mdl_train   = []\n    feature_imp = 0 \n    auc_best    = 0\n    \n    for scaler in scalers: \n        \n        gc.collect()\n\n        df_submission.claim = 0           \n        feature_imp_best    = 0       \n        auc                 = []\n        lloss               = []\n        f1                  = []\n        ntree               = []\n        n_estimators        = model.get_params()['n_estimators'] \n        kfold               = KFold(n_splits=FOLDS, random_state=seed, shuffle=True)\n\n        if scaler!=None:\n            X_ts = scaler.fit_transform(X_test_.copy())\n        else:\n            X_ts = X_test_.copy()\n\n        print('='*80)\n        print('Scaler: {} - n_estimators: {}'.format(scaler,n_estimators))\n        print('='*80)\n\n        for i, (train_idx, test_idx) in enumerate(kfold.split(X_train_)):\n\n            i+=1\n\n            X_tr, y_tr = X_train_.iloc[train_idx], y_train_.iloc[train_idx]\n            X_vl, y_vl = X_train_.iloc[test_idx], y_train_.iloc[test_idx]\n\n            # Scaler\n            if scaler!=None:    \n                X_tr = scaler.fit_transform(X_tr)\n                X_vl = scaler.fit_transform(X_vl)                \n\n            model.fit(X_tr, y_tr, \n                      eval_set              = [(X_tr,y_tr), (X_vl,y_vl)],\n                      early_stopping_rounds = int(n_estimators*.1), \n                      verbose               = verbose\n                     )\n            \n            if use_ntree_limit:\n                y_hat_prob  = model.predict_proba(X_vl, ntree_limit=model.best_ntree_limit)[:, 1] # \n                best_ntree_ = model.best_ntree_limit\n            else: \n                y_hat_prob  = model.predict_proba(X_vl)[:, 1] # \n                best_ntree_ = n_estimators\n                            \n            y_hat         = (y_hat_prob >.5).astype(int) \n            log_loss_     = metrics.log_loss(y_vl, y_hat_prob)                \n            f1_score_     = metrics.f1_score(y_vl, y_hat)                    \n            auc_          = metrics.roc_auc_score(y_vl, y_hat_prob)\n\n            stop = '*' if n_estimators > best_ntree_ else ' '\n            msg  = '[Fold {}] AUC: {:.5f} - F1: {:.5f} - L. LOSS: {:.5f} {} {}'\n            print(msg.format(i, auc_, f1_score_,log_loss_, stop, best_ntree_))\n\n            # Getting mean feature importances (i.e. devided by number of splits)\n            feature_imp  += model.feature_importances_ \/ FOLDS\n            \n            df_submission['target'] += model.predict_proba(X_ts)[:, 1] \/ FOLDS\n\n            f1.append(f1_score_)\n            lloss.append(log_loss_)\n            auc.append(auc_)\n            ntree.append(best_ntree_)\n            \n            gc.collect()\n                        \n        auc_mean   = np.mean(auc)\n        auc_std    = np.std(auc)\n        lloss_mean = np.mean(lloss)\n        f1_mean    = np.mean(f1)\n        ntree_mean = np.mean(ntree)\n        \n        if auc_mean > auc_best: \n            auc_best          = auc_mean\n            f1_best           = f1_mean\n            lloss_best        = lloss_mean\n            model_best        = model\n            feature_imp_best  = feature_imp\n            scaler_best       = scaler\n                                    \n        print('-'*80)\n        msg = '[Mean Fold] AUC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - L. LOSS: {:.5f} - {} '\n        print(msg.format(auc_mean,auc_std, f1_mean, lloss_mean, ntree_mean))\n        print('='*80)\n        print('')\n\n        # Gerar o arquivo de submiss\u00e3o \n        name_file_sub = 'submission\/' + name_model + '_' + str(scaler).lower()[:4] + '.csv'\n        df_submission.to_csv(path + name_file_sub.format(auc_mean), index = False)\n\n        gc.collect()\n     \n    mdl_name_best = 'model\/' + name_model.format(auc_mean)\n    \n    jb.dump(model_best, mdl_name_best)\n    \n    print()\n    print('='*80)\n    print('Scaler Best: {}'.format(scaler_best))\n    print('AUC        : {:2.5f}'.format(auc_best))\n    print('F1-Score   : {:2.5f}'.format(f1_best))\n    print('L. Loss    : {:2.5f}'.format(lloss_best))\n    print('='*80)\n    print()\n            \n    gc.collect()  \n    \n    return model_best","c3ec75ee":"%%time\n\ngc.collect()\n\nparams.update({'n_estimators': 100})\n\nscalers = [None, \n           StandardScaler(), \n           RobustScaler(), \n           MinMaxScaler(), \n           MaxAbsScaler(), \n           QuantileTransformer(output_distribution='normal', random_state=0)]\n\nmodel_best = cross_val_model(model                = xgb.XGBClassifier(**params), \n                             X_train_             = X, \n                             y_train_             = y,\n                             X_test_              = X_test,                                            \n                             scalers              = scalers, \n                             name_model           = 'xgb_001_bl_{:2.5f}', \n                             FOLDS                = 5, \n                             seed                 = seed, \n                             use_ntree_limit      = False\n                             ) \n\ngc.collect()\nprint(params)","21281dfc":"%%time\n\ngc.collect()\n\nparams.update({'n_estimators': 1000})\n\nscalers = [None, \n           StandardScaler(), \n           RobustScaler(),           \n           QuantileTransformer(output_distribution='normal', random_state=0)]\n\nmodel_best = cross_val_model(model           = xgb.XGBClassifier(**params), \n                             X_train_        = X, \n                             y_train_        = y,\n                             X_test_         = X_test,                                            \n                             scalers         = scalers, \n                             name_model      = 'xgb_002_bl_n_estimators_1000_{:2.5f}', \n                             FOLDS           = 5, \n                             seed            = seed, \n                             use_ntree_limit = False\n                             ) \n\ngc.collect()","1186b3f2":"%%time\n\ngc.collect()\n\nparams.update({'n_estimators': 1000})\n\nscalers = [None, \n           StandardScaler(), \n           RobustScaler(),           \n           QuantileTransformer(output_distribution='normal', random_state=0)]\n\nmodel_best = cross_val_model(model           = xgb.XGBClassifier(**params), \n                             X_train_        = X, \n                             y_train_        = y,\n                             X_test_         = X_test,                                            \n                             scalers         = scalers, \n                             name_model      = 'xgb_003_bl_n_estimators_1000_limit_{:2.5f}', \n                             FOLDS           = 5, \n                             seed            = seed, \n                             use_ntree_limit = True\n                             ) \n\ngc.collect()\n\nprint(params)\nprint()","7a64cb87":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size    = 0.2,\n                                                      shuffle      = True, \n                                                      stratify     = y,\n                                                      random_state = 12359)\n\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape , X_test.shape","7da82464":"%%time\n\nparams.update({'n_estimators': 1000})\n\nscaler     = QuantileTransformer(output_distribution='normal', random_state=0) \nmodel_best = cross_val_model(model           = xgb.XGBClassifier(**params), \n                             X_train_        = X_train, \n                             y_train_        = y_train,\n                             X_test_         = X_test,                                            \n                             scalers         = [scaler], \n                             name_model      = 'xgb_004_bl_n_estimators_1000_{:2.5f}', \n                             FOLDS           = 5, \n                             seed            = seed, \n                             use_ntree_limit = False\n                             ) \n\ngc.collect()\n\nprint(params)","fa4fd374":"model_best.get_params()","01f786eb":"results     = model_best.evals_result()\nntree_limit = model_best.best_ntree_limit\n\nplt.figure(figsize=(7,5))\nplt.plot(results[\"validation_0\"][\"auc\"], label=\"Treinamento\")\nplt.plot(results[\"validation_1\"][\"auc\"], label=\"Valida\u00e7\u00e3o\")\n\n\nplt.axvline(ntree_limit, \n            color=\"gray\", \n            label=\"N. de \u00e1rvore ideal {}\".format(ntree_limit))\n\nplt.xlabel(\"N\u00famero de \u00e1rvores\")\nplt.ylabel(\"AUC\")\nplt.legend();","6164111a":"X_valid_sc  = scaler.fit_transform(X_valid)","e1c9e5b2":"%%time\n\nthreshold   =.5\ny_pred_prob = model_best.predict_proba(X_valid_sc,  ntree_limit=ntree_limit)[:, 1] \ny_pred      = (y_pred_prob > threshold).astype(int)\n\nf1_    = metrics.f1_score(y_valid, y_pred)\nauc_   = metrics.roc_auc_score(y_valid, y_pred_prob)\nlloss_ = metrics.log_loss(y_valid, y_pred_prob) \n    \nprint('AUC     : {:2.5f}'.format(auc_))\nprint('F1-Score: {:2.5f}'.format(f1_))\nprint('L. Loss : {:2.5f}'.format(lloss_))\nprint()","2fb0d985":"fpr, tpr, thresholds = metrics.roc_curve(y_valid, y_pred_prob)\n\nplot_roc_curve(fpr, tpr, label=\"XGB\")\nplt.show()","d273b1a1":"threshold    = .5\ny_pred_valid = (y_pred_prob > threshold).astype(int)\nf1_          = metrics.f1_score (y_valid, y_pred_valid)\nauc_         = metrics.roc_auc_score(y_valid, y_pred_prob)\n\nprint(metrics.classification_report(y_valid, y_pred_valid))\nprint('')\nprint('AUC     : {:2.5f}'.format(auc_))\nprint('F1-score: {:2.5f}'.format(f1_))\n\nconfusion_plot(metrics.confusion_matrix(y_valid, y_pred) )","11729e46":"threshold    = .43\ny_pred_valid = (y_pred_prob > threshold).astype(int)\nf1_          = metrics.f1_score (y_valid, y_pred_valid)\nauc_         = metrics.roc_auc_score(y_valid, y_pred_prob)\n\nprint(metrics.classification_report(y_valid, y_pred_valid))\nprint('')\nprint('AUC     : {:2.5f}'.format(auc_))\nprint('F1-score: {:2.5f}'.format(f1_))\n\nconfusion_plot(metrics.confusion_matrix(y_valid, y_pred_valid) )","708fce06":"feature_imp_     = model_best.feature_importances_\n\ndf               = pd.DataFrame()\ndf[\"Feature\"]    = X.columns\ndf[\"Importance\"] = feature_imp_ \/ feature_imp_.sum()\n\ndf.sort_values(\"Importance\", axis=0, ascending=False, inplace=True)","5e914445":"fig, ax = plt.subplots(figsize=(13, 70))\nbars    = ax.barh(df[\"Feature\"], \n                  df[\"Importance\"], \n                  height    = 0.4,\n                  color     = \"mediumorchid\", \n                  edgecolor = \"black\")\n\nax.set_title(\"Feature importances\", fontsize=30, pad=15)\nax.set_ylabel(\"Feature name\", fontsize=20, labelpad=15)\n#ax.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\nax.set_yticks(df[\"Feature\"])\nax.set_yticklabels(df[\"Feature\"], fontsize=13)\nax.tick_params(axis=\"x\", labelsize=15)\nax.grid(axis=\"x\")\n\n# Adicionando r\u00f3tulos na parte superior\nax2 = ax.secondary_xaxis('top')\n#ax2.set_xlabel(\"Feature importance\", fontsize=20, labelpad=13)\nax2.tick_params(axis=\"x\", labelsize=15)\nax.margins(0.05, 0.01)\n\n# Inverter a dire\u00e7\u00e3o do eixo y \nplt.gca().invert_yaxis()","97311ded":"<h1 div class='alert alert-success'><center> Ponto de partida (EDA, linha de base)<\/center><\/h1>\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/26480\/logos\/header.png?t=2021-04-09-00-57-05)","f135db2f":"##### 1.2.2.1.1. Data Train ","92c7fdce":"# Descri\u00e7\u00e3o de dados\n\nPara esta competi\u00e7\u00e3o, voc\u00ea vai prever se um cliente fez uma reclama\u00e7\u00e3o sobre uma ap\u00f3lice de seguro. A verdade fundamental claimtem valor bin\u00e1rio, mas uma previs\u00e3o pode ser qualquer n\u00famero de 0.0 para 1.0, representando a probabilidade de uma reclama\u00e7\u00e3o. Os recursos neste conjunto de dados foram tornados an\u00f4nimos e podem conter valores ausentes.\narquivos\n\n- `train.csv`: os dados de treinamento com o alvo claimcoluna\n- `test.csv`: o conjunto de teste; voc\u00ea estar\u00e1 prevendo o claimpara cada linha neste arquivo\n- `sample_submission.csv`:  um arquivo de envio de amostra no formato correto","cd0daa95":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\n    \nCom scaler QuantileTransformer obtivemos uma AUC de 0.73057, como estamos fazer apenas uma valida\u00e7\u00e3o simples, neste caso a pontua\u00e7\u00e3o do score pode ser afetada por aleatoriedade dos dados, sendo assim, vamos fazer uma valida\u00e7\u00e3o cruzada para termos uma estimativa robusta.  <br>\n\nPara o treinamento do modelo foi criado uma fun\u00e7\u00e3o,que tem a finalidade de treinar um conjunto de scalers para um determinado modelo, durante o treinamento ser\u00e3o exibidos os resultados e no final ser\u00e1 retornado o melhor modelo.\n    \n<\/div>","153b9285":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\nNo treinamento do modelo, podemos observar uma melhar na AUC de `0.73104`  sem fazer o scaler para `0.73136`, no resultado das submiss\u00f5es dos arquivos obtivemos os seguintes resultados: \n\n\n- None: 0.73794\n- QuantileTransforme:  `0.73812`\n    \n    \nMais uma vez o scaler QuantileTransforme se mostrou melhor na submiss\u00e3o e bateu a baseline de `0.73136` para `0.73812`, como podemos observar o aumento de estimadores (arvores) melhorou o score, ser\u00e1 que o n\u00famero de 1000 arvores para o XBG \u00e9 o ideal? O XGB tem um atributo chamado `best_ntree_limit` que retorna o n\u00famero aproximado de arvores, que pode ser utilizado na previs\u00e3o do modelo atrav\u00e9s do parametro `ntree_limit` do m\u00e9todo `predict`ou pridict_proba.  \n    \n<\/div>","bfeb2ea6":"## 1.2. Fun\u00e7\u00f5es\nAqui centralizamos todas as fun\u00e7\u00f5es desenvolvidas durante o projeto para melhor organiza\u00e7\u00e3o do c\u00f3digo.","b4559a0a":"<div class=\"alert alert-info\" role=\"alert\"> \n    \n**`NOTA:`** <br>\nAcima recuperamos as informa\u00e7\u00f5es de treinamento do nosso modelo, podemos observar que o n\u00famero de 1000 estimadores \u00e9 mais que suficiente para o treinamento do modelo, o ideal \u00e9 que fique em entre de 110 \u00e0 120 para esses dados e com a utiliza\u00e7\u00e3o dos parametros padr\u00f5es que devem ser ajustados para o `XGB`. <br>\n    \n    \nVamos agora utilizar o modelo treinado que foi retornado pela fun\u00e7\u00e3o e vamos fazer a previs\u00e3o para novos dados que o modelo n\u00e3o viu no treinamento, para termos uma ideia da generaliza\u00e7\u00e3o do modelo, lembrando que o modelo que foi treinado utiliza 1000 estimadores (arvores), sendo assim, vamos utilizar na previss\u00e3o 114 estimadores utilizando o parametro `ntree_limit` ao fazermos as previs\u00f5es.\n\n<\/div>","02aaaa64":"#### 2.1.3.1. Com ponto de corte padr\u00e3o","8694f088":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\n    \nTivemos uma redu\u00e7\u00e3o em ambos datasets de 74.9%, com isso o dataset de treino passou de 466.9 MB para 117.3 Mb e no dataset de teste passou de 416.1 MB para 105.06 Mb.\n    \n<\/div>","ad99659d":"### 2.1.3. Feature Importances  ","13e85366":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <BR>\n    \n- O dataset de treiro tem 466.9 MB com 600000 de registros e 102 columas; \n- O dataset de teste tem 416.1 com 540000 de registros e 101 columas\n   \n    \nVamos fazer uma redu\u00e7\u00e3o desses dataset nas pr\u00f3ximas etapas, primeiro vamos identificar os tipos de dados que temos nos datasets.\n\n<\/div>","86e3efe5":"#### 1.2.2.4. Vari\u00e1veis preditoras  vs Target.","bf4f7d94":"### 2.1.1. N\u00famero de Estimadores","f135aea1":"#### 1.2.2.1. Target\nVamos ver as ocorr\u00eancias de n\u00fameros individuais do conjunto de dados de treino.","1213d7c5":"#### 1.2.2.3. Target\nA vari\u00e1vel alvo tem os valores 0 e 1, vamos verificar a distribui\u00e7\u00e3o da vari\u00e1vel `target` que \u00e9 o nosso alvo de previs\u00e3o.","8c0e38f4":"### 2.1.2. Curva ROC","f1ec9261":"<div class=\"alert alert-info\" role=\"alert\"> \n    \n**`NOTA:`** <br>\n    \nObservando a Curva ROC acima, podemos fazer alguns testes em rela\u00e7\u00e3o ao ponto de corte, pois a AUC de 0.72866 tem um ponto de corte de 0.5 que \u00e9 padr\u00e3o, o que nos dar um F1-score de 0.69587, vamos fazer um gr\u00e1fico de Matriz de Confus\u00e3o para termos uma ideia melhor das previs\u00f5es do modelo.  \n    \n<\/div>","18dbe526":"#### 1.2.2.1. Train \/ Test","930e0776":"# <div class=\"alert alert-success\">  2. Modelo Baseline XGB <\/div> <br>\n\nNesta etapa do processo, vamos utilizar o **XGBClassifier** como linha de base, em rela\u00e7\u00e3o ao tratamento dos dados vamos fazer apenas o scaler neste momento.","043a0cb7":"# <div class=\"alert alert-success\">  3. Conclus\u00e3o <\/div> <br>","b2ec7cca":"<div class=\"alert alert-info\" role=\"alert\"> \n    \n**`NOTA:`** <br>\nCom um ponto de corte de 0.43 temos um F1-score de 0.71225, passamos a acerta mais os falso positivos. \n    \n<\/div>\n","411b5b39":"- Train","f8d3e511":"### 1.1.2. Dimens\u00e3o do DataSet","1eb5a160":"#### 1.1.6.1. Atributos Categ\u00f3ricos","39a54643":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\n    \nPodemos observar no gr\u00e1fico acima que n\u00e3o temos desbalanceamento nos dados, temos mais dados na classe possitiva. \n    \n<\/div>","31eab6ad":"### 2.1.3. Matriz de Confus\u00e3o","b265cee1":"### 1.1.6. Estat\u00edstica Descritiva\nAbaixo est\u00e3o as estat\u00edsticas b\u00e1sicas para cada vari\u00e1vel que cont\u00e9m informa\u00e7\u00f5es sobre contagem, m\u00e9dia, desvio padr\u00e3o, m\u00ednimo, 1\u00ba quartil, mediana, 3\u00ba quartil e m\u00e1ximo.","7954b7fe":"### 1.2.1. Correla\u00e7\u00e3o\nVamos examinar a correla\u00e7\u00e3o entre as vari\u00e1veis.","a4c00b00":"##### 1.2.2.1.2. Data Test","90ae083e":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\n\n- Os conjuntos de treinamento e teste t\u00eam aproximadamente as mesma distribui\u00e7\u00e3o em termos de vari\u00e1veis; <br>\n- Temos poucas vari\u00e1veis com distribui\u00e7\u00e3o normal; <br>\n- A maioria das vari\u00e1veis tem distribui\u00e7\u00f5es distorcidas. <br>\n\n<\/div>","a85340e1":"#### 1.2.2.2. Propor\u00e7\u00e3o das vari\u00e1veis","5837cf19":"# <div class=\"alert alert-success\">  2. Split Train\/Test <\/div> <br>\n\nAntes de fazer a divis\u00e3o dos dados dataset, vamos fazer a redu\u00e7\u00e3o dos mesmo com a utliza\u00e7\u00e3o de uma fun\u00e7\u00e3o que modifica os tipos de vari\u00e1veis dos dataset, ao fazermos isso ganhamos espa\u00e7o.  ","8d9ca5de":"# <div class=\"alert alert-success\">  1.0. An\u00e1lise Explorat\u00f3ria de Dados (EDA)  <\/div> ","4c50ea77":"#### 1.2.2.1. Detec\u00e7\u00e3o de Outlier","aa1ca8d1":"# <div class=\"alert alert-success\">  1. IMPORTA\u00c7\u00d5ES <\/div> ","99c0dbf0":"## 1.4. Carregar Dados\nS\u00e3o dois arquivos que vamos utilizar para an\u00e1lise e treinanmento dos modelos, e um arquivo para submiss\u00e3o na competi\u00e7\u00e3o.\n\n- `train.csv`: arquivo com dados de treinamento;  \n- `test.csv`: arquivo que ser\u00e1 utilizado para previs\u00e3o; \n- `sample_submission.csv`: arquivo utlizado para envio das previs\u00f5es.  \n","42dc26fa":"### 1.2.2. Distribui\u00e7\u00e3o","4273285d":"## 2.1. An\u00e1lise do Modelo \nVamos fazer o treinamento novamente do modelo com 1000 estimadores e fazer a previs\u00e3o utilizando o limite ideal sugerido pelo atributo `best_ntree_limit` do XGB, sendo que vamos treinar em 80% dos dados e fazer a previs\u00e3o em 20% dos dados que o medelo n\u00e3o viu, para termos uma id\u00e9ia da rubustez do modelo em dados n\u00e3o visto no treinamento.  ","d49b66d9":"### 1.1.3. Tipo de Dados","445ccde7":"<div class=\"alert alert-info\" role=\"alert\"> \n    \n**`NOTA:`** <br>\n\nNo treinamento obtivemos uma AUC de 0.72913 e no dados de valida\u00e7\u00e3o obtivemos uma AUC de 0.72866, temos uma pequena diferen\u00e7a, o que nos indica que o modelo consegue generalizar em dados n\u00e3o visto no treinamento.  \n    \n<\/div>","12b1646c":"### 1.1.4. Idenficar Vari\u00e1veis Ausentes (NA)\nVamos verificar os valores ausentes em cada vari\u00e1vel conjunto de treinono e teste.","b3588d32":"<div class=\"alert alert-info\" role=\"alert\"> \n\nCom este notebook fizemos uma pequena an\u00e1lise dos dados e identificamos que os dados dispon\u00edveis para a competi\u00e7\u00e3o n\u00e3o segue uma distribui\u00e7\u00e3o normal, tem muitos outliers que precisam de um tratamento, nesta etapa utilizamos o XGB como modelo de linha de base e testamos diversos tipos de padroniza\u00e7\u00e3o de dados, o `QuatileTransforme` se mostrou o melhor padronizador com o XGB com a maioria dos parametros padr\u00e3o.   \n\n<br>     \nNo pr\u00f3ximo notebook vamos criar novas vari\u00e1veis para ajuda os modelos a identificar novos padr\u00f5es nos dados e melhor AUC.  \n    \n    \n<\/div>\n","de150110":"## 1.2. An\u00e1lise Gr\u00e1fica","be6feb1f":"<div class=\"alert alert-info\" role=\"alert\"> \n    \n**`NOTA:`** <br>\n\nN\u00e3o temos dados faltantes.\n    \n<\/div>","d297abdd":"## 1.1. Bibliotecas ","af68c39d":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\n  \n\nComo podemos observar os resultados n\u00e3o melhou na valida\u00e7\u00e3o, por\u00e9m ao fazer as submiss\u00f5es dos dois melhores resultados obtivemos os seguites resultados com uma pequena melhoria em ambos os scalres: \n  \n- None: 0.73816 \n- QuantileTransforme: `0.73818`\n  \n<br> \n    \nO QuantileTransforme novamente se mostrou o melhor scaler para o XGB e outro ponto importante \u00e9 o n\u00famero de estimadores que fica em m\u00e9dia de 100 \u00e0 120 estimadores, vamos fazer uma pequena an\u00e1lise do modelo com esses parametros e scaler quantileTransforme. \n    \n<\/div>","cd024a8f":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\n    \nAcima observamos que temos muitos outliers em ambos conjunto de dados, na etapa de processamento vamos fazer o tramento ou remo\u00e7\u00e3o dos outliers para ajudar na previs\u00e3o dos modelos. \n\n<\/div>","f38c99f5":"<div class=\"alert alert-info\" role=\"alert\">\n\n**`NOTA:`** <br>\n    \nNa valida\u00e7\u00e3o cruzada obtivemos uma `AUC` de `0.73104` com um desvio padr\u00e3o de `0.00113` sem fazer o scaler, na submiss\u00e3o obtivemos os seguintes resultados: <br>\n\n- None: 0.73562    \n- StandarScaler: 0.73706    \n- QuartileTransforme: `0.73780`\n    \n\n<br>\n    \nCom a submiss\u00e3o dos arquivo na competi\u00e7\u00e3o, observamos que QuartileTransforme resulta no melhor, **agora temos uma baseline que AUC 0.73780**.\n    \n \nVamos treinar novamente, sendo que vamos acrescentar o parametros  `n_estimators` que indica o n\u00famero de arvores para o treinamento do modelo.\n    \n<\/div>","64ce8fb2":"<div class=\"alert alert-info\" role=\"alert\"> \n \n**`NOTA:`** <br>\n    \nComo podemos observar, a correla\u00e7\u00e3o est\u00e1 entre -0.075 e 0.1, o que \u00e9 muito pequeno, portanto, as vari\u00e1veis s\u00e3o fracamente correlacionados.\n    \n<\/div>","be08934a":"#### 2.1.3.2. Com ponto de corte","c32a9bb4":"- Test","7cd7c8f1":"#### 1.1.6.1. Atributos Num\u00e9ricos"}}