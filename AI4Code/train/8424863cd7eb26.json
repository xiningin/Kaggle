{"cell_type":{"92e7ae8b":"code","6db449b5":"code","b6f59da0":"code","27a0d20a":"code","bc0e8388":"code","e5c6bb8f":"code","bcb8dee9":"code","c137184f":"code","7f6b289c":"code","41fa6502":"code","90a6b728":"code","14a9d52b":"code","d837b332":"code","937ef189":"code","aaacefda":"code","75b76452":"code","21e053d8":"code","a7147dd3":"code","c6448d22":"code","04311e0e":"code","7b2a3a2d":"code","f948c7f0":"code","a5d05430":"code","a46a785a":"code","00e6dcd8":"code","2b4d6860":"code","6a920d65":"code","7f55e9d1":"code","0a869e73":"code","e2a860fb":"code","556833e9":"code","c81e027f":"markdown","e8094e8b":"markdown","0dbc79f3":"markdown","98c5b523":"markdown","0b4dccaf":"markdown","9845d9f8":"markdown","0a01e8a9":"markdown","da540d4a":"markdown","49bde83a":"markdown","7460ca40":"markdown","debaceab":"markdown","6b50dbdf":"markdown","c710a74b":"markdown","fd66dac5":"markdown","7fe7ec7e":"markdown","77520e69":"markdown","84411fa0":"markdown","0f9c05b0":"markdown"},"source":{"92e7ae8b":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcS0WNpRevX2b8A237rMQ2VQaXkQSv20nnmGW2lOFJFlwjI43aGO2w&s',width=400,height=400)","6db449b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b6f59da0":"wids = pd.read_csv(\"..\/input\/widsdatathon2020\/training_v2.csv\")\ntest = pd.read_csv(\"..\/input\/widsdatathon2020\/unlabeled.csv\")\nsub = pd.read_csv('..\/input\/widsdatathon2020\/samplesubmission.csv')","27a0d20a":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSQ44CM9UB1kKjsFpFGU-DTRVmlvGugTz3wPRllnbucMXplydui6w&s',width=400,height=400)","bc0e8388":"wids.head()","e5c6bb8f":"wids.dtypes","bcb8dee9":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTJE4rPsgdkEJgNcZCknrweDTpASeH3LggoTzdqsZd8iUDTaRz_&s',width=400,height=400)","c137184f":"wids.describe()","7f6b289c":"print(\"The number of nulls in each column are \\n\", wids.isna().sum())","41fa6502":"sns.countplot(wids[\"hospital_death\"])\nplt.xticks(rotation=45)\nplt.yticks(rotation=45)\nplt.show()","90a6b728":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT1XBLX-CmEdjlURIK4ovG5Aflo8QKS_hnycP5kDwlw50C5QRWx&s',width=400,height=400)","14a9d52b":"sns.distplot(wids[\"hospital_death\"])","d837b332":"sns.scatterplot(x='age',y='hospital_death',data=wids)","937ef189":"print (\"Skew is:\", wids.hospital_death.skew())\nplt.hist(wids.hospital_death, color='pink')\nplt.show()","aaacefda":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/i.pinimg.com\/236x\/ac\/fb\/8b\/acfb8b6026740e5c50063307c468f12f.jpg',width=400,height=400)","75b76452":"# Necessary Functions: \ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label+value\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","21e053d8":"sns.boxplot(x=\"hospital_death\", y=\"patient_id\", data=wids)\n","a7147dd3":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcS8TMbfKeH67PQNL0ghQrPrwG75wjca1M7g38Bi9Jbj1T3dsh0F&s',width=400,height=400)","c6448d22":"#codes from PSVishnu @psvishnu\nhospital = [\n    'patient_id','hospital_id','hospital_death','encounter_id']","04311e0e":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTxDDQDIfj58v2qLXz1NnNM9fqYg1xdM3cGdJ5d3ktKlMvRpALqqw&s',width=400,height=400)","7b2a3a2d":"sns.pairplot(data=wids,diag_kind='kde',vars=hospital,hue='hospital_death')\nplt.show()","f948c7f0":"import plotly.offline as py\nvalue_counts = wids['hospital_id'].value_counts()\nlabels = value_counts.index.tolist()\npy.iplot(pie_plot(labels, value_counts,['#1B9E77', '#7570B3'], \"Hospital Id\"))","a5d05430":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSVbT0PMefnpoA7dQYRZKmGvxVO3kXqb6MVCgTcy-guauA-xBX2Cw&s',width=400,height=400)","a46a785a":"from collections import Counter\nimport json\nfrom IPython.display import HTML\nimport altair as alt\nfrom  altair.vega import v5","00e6dcd8":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcR-TVKsdRr0lRfeZHuaMMrzA4g7qN1pOsU-hnd3MoedAtQKTC3T&s',width=400,height=400)","2b4d6860":"\n##-----------------------------------------------------------\n# This whole section \nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\")))","6a920d65":"def word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https:\/\/vega.github.io\/schema\/vega\/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hospital - Women in Data Science 2020\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),  \n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n            \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\nfrom collections import defaultdict\n\ndef wordcloud_create(wids):\n    ult = {}\n    corpus = wids.icu_type.values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words.split():\n             final[word]+=1\n    temp = Counter(final)\n    for k, v in  temp.most_common(200):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))","7f55e9d1":"wordcloud_create(wids)","0a869e73":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/www.kdnuggets.com\/wp-content\/uploads\/career-progression.jpg',width=400,height=400)","e2a860fb":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in wids.apache_2_bodysystem)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200, background_color=\"black\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","556833e9":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQhs0JIJjvon1mlAC_QGIIIZDTwGUPY5ZByFTdFaSE9f3l2RC3L2g&s',width=400,height=400)","c81e027f":"* I AM WHAT I AM (Lyrics) - GLORIA GAYNOR\n* I am what I am\/I don't want praise, I don't want pity\/I bang my own drum\/Some think it's noise, I think it's pretty\/And so what if I love each sparkle and each bangle\/Why not try to see things from a different angle\/Your life is a sham\/Till you can shout out\/I am what I am\nI am what I am\/And what I am needs no excuses\/I deal my own deck\/Sometimes the aces sometimes the deuces\/It's one life and there's no return and no deposit\/One life so it's time to open up your closet\/Life's not worth a damn till you can shout out\/I am what I am\nI am what I am\/And what I am needs no excuses\/I deal my own deck sometimes the aces sometimes the deuces\/It's one life and there's no return and no deposit\/One life so it's time to open up your closet\/Life's not worth a damn till you can shout out\/I am what I am\nI am, I am, good\/I am, I am, strong\/I am, I am somebody\/I am I do belong\/I am, I am, good\/I am, I am, strong\/I am, I am somebody\/I am I do belong\/I am, I am, useful\/I am, I am true\/I am, I am worthy\/I am as good as you\/I am, I am, useful\/I am, I am true\/I am, I am worthy\nI am as good as you\/\n* Source: LyricFind - Songwriters: Mark Owen - I Am What I Am lyrics \u00a9 BMG Rights Management, Universal Music Publishing Group\n","e8094e8b":"* Keep your mind opened, even to informality. It can surprises you and bring new ideas. Give a shot to innovation. Try to read beyond your codes.\n* Why not try to see things from a different angle? Your life is a sham. Till you can shout out: I am what I am!\n* Kaggle Notebook Runner: Mar\u00edlia Prata @mpwolke","0dbc79f3":"* Geena Davis Institute on Gender in media\n* If she can see it, she can be it\n* Geena and some STEM sheroes!\u2060 These incredible WomenInSTEM are @ifthenshecan ambassadors: role models for future scientists!\u2060\u2800\nhttps:\/\/seejane.org\/","98c5b523":"Image www2.deloitte.com - Women in Data Science and Analytics. Developing the next generation of data leaders","0b4dccaf":"<iframe width=\"951\" height=\"535\" src=\"https:\/\/www.youtube.com\/embed\/mEVKkIWbPrY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>","9845d9f8":"Image github.com","0a01e8a9":"* Image dataquest.io - The Gender Gap in Data Science (and What You Can Do About It). \n* Childcare, Elderly care, and Paid Leave Programs\n* The Gender Pay Gap\n* Lack of Mentorship and Leadership for Women in STEM\n* Resources and Solutions for Data Science https:\/\/www.dataquest.io\/blog\/women-data-science-gender-gap\/","da540d4a":"Image thecube.net","49bde83a":"Image ww2.amstat.org","7460ca40":"Image twitter.com","debaceab":"Image thedatalab.com","6b50dbdf":"* Image https:\/\/br.pinterest.com\/pin\/175921929180613562\/\n* It's not easy to take care of any one (children, husband and parents) and still have time to work or do whatever you want. Don't charge yourself too much. We aren't Super Women. It's overwhelming to make an imputation during 7 hours when you've to take care of your family. Then you change a dipper and make a submission almost at the same time. Following performances it's overwhelming. Leave it to the guys. There's no problem to be average. Average is good. In fact, I'm lower than average. Be ethical, try to keep learning, SHARE and have fun! Do what's possible. No one can do everything at high-levels.       ","c710a74b":"Image kdnuggets.com","fd66dac5":"Image meetup.com","7fe7ec7e":"The stats from Women in Data Science Datathon 2020.","77520e69":"# It's about Women, however I won't be here if I couldn't count on those helpful guys and others that I excuse myself since I forget. Plus I have a lot of \"friends\"  that I found in Kaggle. Thanks to Rodrigo, David, Vasi, Dan , Anthony, Mukharbek, Mobassir, Prashant, Fatih, Cris, Firat, Leo, Atul, Marcos, Marco Vasquez, Andre, Fares, Leo, Ben, Ian, Mukesh, Lucas, Ashish, Shivam, Gabriel,Santiago,Jacky, Inversion, Mohamed, Solve, qizheng, DtneSEffct, Erik, Paulo, Saurav, Cem, Sahib, Xiao, Johar, Carlos,Shivam, Paul.... Sorry if I forget someone. I can update the list any time. Just remember me! \n","84411fa0":"Image https:\/\/www.kdnuggets.com\/2018\/09\/diversity-data-science.html","0f9c05b0":"#Codes from Shivam Ralli @hoshi7"}}