{"cell_type":{"f707cf55":"code","ba6e4747":"code","a9043c3c":"code","d414d04c":"code","dbf77084":"code","4fd7f7c3":"code","8a0ad896":"code","b52ad397":"code","2ab67a3b":"code","62b1b0dd":"code","884e163f":"code","3755bba4":"code","bbd5f535":"code","f218f726":"code","8bf461d6":"code","ebe69179":"code","5d0e7d6d":"code","4d85541e":"code","14ab281d":"code","91288e34":"code","8e5fc9b9":"code","09daf79e":"code","e7113859":"code","87af9aba":"code","eab837f1":"code","f6ef97d7":"code","d2448384":"code","316671ca":"code","773c68af":"code","5e4a61be":"code","159d4b2f":"markdown","27e2bb47":"markdown","a49ebbcf":"markdown","5558e4d2":"markdown","b819966f":"markdown","db265e5e":"markdown","967cd967":"markdown","06ee2e55":"markdown","0e02dfd1":"markdown","5e3f821d":"markdown","a496340f":"markdown"},"source":{"f707cf55":"from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\npd.options.display.max_columns = 500\npd.options.display.max_rows = 5","ba6e4747":"from transformers import AutoModel, AutoTokenizer","a9043c3c":"MODEL_ORG = 'allenai'\nMODEL_NAME = 'longformer-base-4096'","d414d04c":"MODEL_DIR = str(Path('\/kaggle\/input') \/ MODEL_NAME)\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n    model = AutoModel.from_pretrained(MODEL_DIR)\nexcept (OSError, ValueError):\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_ORG + '\/' + MODEL_NAME)\n    model = AutoModel.from_pretrained(MODEL_ORG + '\/' + MODEL_NAME)","dbf77084":"df = pd.read_csv('data\/train.csv')\ndf\nprint( train.shape )\ntrain.head()","4fd7f7c3":"print('Training labels:')\ntrain.discourse_type.unique()","8a0ad896":"ids = train.id.unique()\nprint(f'{len(ids)} training set texts.')","b52ad397":"MAX_LEN = 1024\n\nshape = (len(ids), MAX_LEN)\ntrain_tokens = np.zeros(shape, dtype='int32')\ntrain_attention = np.zeros(shape, dtype='int32')\n\n# HELPER VARIABLES\ntrain_lens = []\ntarget_map = ['Lead',        'Position',      'Evidence',      'Claim',         'Concluding Statement', 'Counterclaim',  'Rebuttal']\ntargets_b = [np.zeros(shape), np.zeros(shape), np.zeros(shape), np.zeros(shape), np.zeros(shape),        np.zeros(shape), np.zeros(shape)]\ntargets_i = [np.zeros(shape), np.zeros(shape), np.zeros(shape), np.zeros(shape), np.zeros(shape),        np.zeros(shape), np.zeros(shape)]\n","2ab67a3b":"# all discourse_start indexes without each document id are sorted in increasing order so the diff is never negative\nassert not (train.groupby('id')['discourse_start'].diff() <= 0).sum()","62b1b0dd":"\n\nfor id_num in range(len(ids)):\n    if LOAD_TOKENS_FROM: break\n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = IDS[id_num]\n    name = f'data\/train\/{n}.txt'\n    txt = open(name, 'r').read()\n    train_lens.append( len(txt.split()))\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    train_tokens[id_num,] = tokens['input_ids']\n    train_attention[id_num,] = tokens['attention_mask']\n    \n    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n    offsets = tokens['offset_mapping']\n    offset_index = 0\n    df = train.loc[train.id==n]\n    for index,row in df.iterrows():\n        a = row.discourse_start\n        b = row.discourse_end\n        if offset_index>len(offsets)-1:\n            break\n        c = offsets[offset_index][0]\n        d = offsets[offset_index][1]\n        beginning = True\n        while b>c:\n            if (c>=a)&(b>=d):\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][id_num][offset_index] = 1\n                    beginning = False\n                else:\n                    targets_i[k][id_num][offset_index] = 1\n            offset_index += 1\n            if offset_index>len(offsets)-1:\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]\n    if not id_num % 100:\n        print(f'{id_num} {end}')","884e163f":"if LOAD_TOKENS_FROM is None:\n    plt.hist(train_lens,bins=100)\n    plt.grid.('on')\n    plt.show()","3755bba4":"if LOAD_TOKENS_FROM is None:\n    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n    for k in range(7):\n        targets[:,:,2*k] = targets_b[k]\n        targets[:,:,2*k+1] = targets_i[k]\n    targets[:,:,14] = 1-np.max(targets,axis=-1)","bbd5f535":"model = AutoModel.from_pretrained(\"allenai\/longformer-base-4096\")","f218f726":"if LOAD_TOKENS_FROM is None:\n    np.save(f'targets_{MAX_LEN}', targets)\n    np.save(f'tokens_{MAX_LEN}', train_tokens)\n    np.save(f'attention_{MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{LOAD_TOKENS_FROM}\/targets_{MAX_LEN}.npy')\n    train_tokens = np.load(f'{LOAD_TOKENS_FROM}\/tokens_{MAX_LEN}.npy')\n    train_attention = np.load(f'{LOAD_TOKENS_FROM}\/attention_{MAX_LEN}.npy')\n    print('Loaded NER tokens')","8bf461d6":"# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)\nprint('Train size',len(train_idx),', Valid size',len(valid_idx))","ebe69179":"# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\nEPOCHS = 5\nLRS = [1e-4, 1e-4, 1e-4, 1e-4, 1e-5]\ndef lrfn(epoch):\n    return LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","5d0e7d6d":"# LOAD MODEL\nif LOAD_MODEL_FROM:\n    model.load_weights(f'{LOAD_MODEL_FROM}\/long_v{VER}.h5')\n    \n# OR TRAIN MODEL\nelse:\n    model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n          y = targets[train_idx,],\n          validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n                             targets[valid_idx,]),\n          callbacks = [lr_callback],\n          epochs = EPOCHS,\n          batch_size = 32,\n          verbose = 2)\n\n    # SAVE MODEL WEIGHTS\n    model.save_weights(f'long_v{VER}.h5')","4d85541e":"p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n                  batch_size=16, verbose=2)\nprint('OOF predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","14ab281d":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","91288e34":"def get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n    all_predictions = []\n\n    for id_num in range(len(preds)):\n    \n        # GET ID\n        if (id_num%100==0)&(verbose): \n            print(id_num,', ',end='')\n        n = text_ids[id_num]\n    \n        # GET TOKEN POSITIONS IN CHARS\n        name = f'..\/input\/feedback-prize-2021\/{dataset}\/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        # KEY:\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        pred = preds[id_num,]\/2.0\n    \n        i = 0\n        while i<MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=MAX_LEN: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=MAX_LEN: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>4:\n                all_predictions.append( (n, target_map_rev[int(start)], \n                                ' '.join([str(x) for x in prediction]) ) )\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n    \n    return df","8e5fc9b9":"oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx] )\noof.head()","09daf79e":"print('The following classes are present in oof preds:')\noof['class'].unique()","e7113859":"# CODE FROM : Rob Mulla @robikscube\n# https:\/\/www.kaggle.com\/robikscube\/student-writing-competition-twitch\ndef calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter \/ len_gt\n    overlap_2 = inter\/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https:\/\/www.kaggle.com\/c\/feedback-prize-2021\/overview\/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP \/ (TP + 0.5*(FP+FN))\n    return my_f1_score","87af9aba":"# VALID DATAFRAME\nvalid = train.loc[train['id'].isin(IDS[valid_idx])]","eab837f1":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall',np.mean(f1s))","f6ef97d7":"# GET TEST TEXT IDS\nfiles = os.listdir('..\/input\/feedback-prize-2021\/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","d2448384":"# CONVERT TEST TEXT TO TOKENS\ntest_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'..\/input\/feedback-prize-2021\/test\/{n}.txt'\n    txt = open(name, 'r').read()\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']","316671ca":"# INFER TEST TEXTS\np = model.predict([test_tokens, test_attention], \n                  batch_size=16, verbose=2)\nprint('Test predictions shape:',p.shape)\ntest_preds = np.argmax(p,axis=-1)","773c68af":"# GET TEST PREDICIONS\nsub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\nsub.head()","5e4a61be":"# WRITE SUBMISSION CSV\nsub.to_csv('submission.csv',index=False)","159d4b2f":"# Train or Load Model\nIf you provide a path in variable `LOAD_MODEL_FROM` above, then it will load your previously trained model. Otherwise it will train now. \n\nWe train 5 epochs of batch size 32 using learning rate `1e4` for the first four and `1e5` for the last epoch. I trained my model offline. If you wish to train on Kaggle's GPU, we may need to reduce the batch size. If we reduce the batch size to 8. That is 1\/4 original. So we should also reduce the learning rates to `0.25e-4` and `0.25e-5`.","27e2bb47":"# Infer Test Data\nWe will now infer the test data and create a submission. Our CV is 0.617, let's see what our LB is!","a49ebbcf":"![train_token_counts.png](attachment:32758c72-717f-4674-9131-423d834e61a9.png)\n\nFrom the histogram of train token counts above, we see that using a transformer width of 1024 is a good comprise of capturing most of the data's signal but not having too large a model. We could probably explore other widths between 512 and 1024 also. Or we could use widths of size 512 or smaller and use a stride which breaks a single text into multiple chunks (with possible overlap).","5558e4d2":"# Validate Model - Infer OOF\nWe will now make predictions on the validation texts. Our model makes label predictions for each token, we need to convert this into a list of word indices for each label. Note that the tokens and words are not the same. A single word may be broken into multiple tokens. Therefore we need to first create a map to change token indices to word indices.","b819966f":"# HuggingFace LongFormer with NER\n## Feedback Prize - Evaluating Student Writing\n\n* longformer-base-4096 ([docs][1] and [specs][2])\n* NER formulation\n* 10% validation set\n\nSimilar to Roberta but accepts inputs as long as 4096 tokens. This notebook uses only 1024 tokens. \n\n[1]: https:\/\/huggingface.co\/docs\/transformers\/model_doc\/longformer\n[2]: https:\/\/huggingface.co\/allenai\/longformer-base-4096","db265e5e":"# Offline?\nDownload:\n\n1. model weights\n2. tokenizer files\n3. config file\n\nand upload these to a Kaggle dataset.","967cd967":"# Compute Validation Metric\nThe following code is from Rob Mulla's excellent notebook [here][2]. Our LongFormer single fold model achieves CV score 0.617! Hooray!\n\n[2]: https:\/\/www.kaggle.com\/robikscube\/student-writing-competition-twitch","06ee2e55":"# Tokenize Train\nThe following code converts Kaggle's train dataset into a NER token array that we can use to train a NER transformer. I have made it very clear which targets belong to which class. This allows us to very easily convert this code to `Question Answer formulation` if we want. Just change the 14 NER arrays to be 14 arrays of `start position` and `end position` for each of the 7 classes. (You will need to think creatively what to do if a single text has multiple of one class).","0e02dfd1":"# Write Submission CSV","5e3f821d":"# NER\nCreate new NER tokens or load existing tokens. ","a496340f":"#### Load training set"}}