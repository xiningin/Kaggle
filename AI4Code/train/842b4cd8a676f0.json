{"cell_type":{"eeef3a12":"code","1d0e6dbf":"code","c629e62c":"code","7de841ba":"code","55fcddbc":"code","56c83a77":"code","a0269b3b":"code","229fe518":"code","4e128691":"code","16fa38ab":"code","a9cdc513":"markdown","e11ecf8a":"markdown","a77baafc":"markdown"},"source":{"eeef3a12":"import warnings, re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\npd.options.mode.chained_assignment = None\n# dir(pd.options.display)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nplt.style.use('ggplot')","1d0e6dbf":"train = pd.read_csv('..\/input\/birdsong-recognition\/train.csv')\nprint(train.shape)\ntrain.head(3)","c629e62c":"train['background'].value_counts(dropna=True, sort=True).to_frame().head(20).plot.bar(\n    color='deeppink', figsize=(15, 5)\n);","7de841ba":"def get_multi_label(s, bird_l):\n    if type(s) != str: s = str(s)\n    return [b in re.sub(r' \\([^()]*\\)', '', s).split('; ') for b in bird_l]","55fcddbc":"bird_l = train.species.unique().tolist()","56c83a77":"# default label\nlabel_df = pd.get_dummies(train.species).set_index(train.xc_id)\nlabel_df.head(3)","a0269b3b":"%%time\nbackground_arr = np.array([get_multi_label(r, bird_l) for r in train.background])\nbackground_arr.shape","229fe518":"label_df.iloc[:, :] = label_df.values + background_arr\nlabel_df['label_n'] = label_df.sum(axis=1)","4e128691":"label_df.label_n.value_counts().plot.bar(figsize=(10, 5), color='deeppink');","16fa38ab":"label_df.drop('label_n', axis=1).to_csv('multi-label.csv')","a9cdc513":"Make a neet function to extract multi label information from train.background column.","e11ecf8a":"As a result, almost of all instances are still mono-labeled. But one third of all train data is multi-labeled.\n\nOne strategy may be, first we train our models with mono-labeled data, then fine-tune with multi-labeled data.\nI'm not sure this may be good or not. But hope this information will help you.  \n\nHappy Kaggling!!!\n\n<img src=\"https:\/\/storage.googleapis.com\/kaggle-avatars\/images\/2080166-kg.png\" width=100 align='left'>","a77baafc":"Update: June.18.2020  \n\nAs in [this discussion](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/discussion\/159123#890189) or [host comments](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/discussion\/159123#890675), `background` column or `secondary_labels` column in train.csv have multi-label information.  \nI think both columns are almost same, after processing like below I did here. But using `secondary_labels` will be preferable based on host's comment. (Here I stick to using `background`)\n\n[host](https:\/\/www.kaggle.com\/stefankahl) comments:\n> Overlapping vocalizations are a major issue and Xeno-canto recordings may or may not contain background species and they may or may not have an appropriate label (typically primary and secondary labels in the metadata). \n\nI'm not sure using secondary labels makes our score better or not, but for curiosity I made an dataframe for multi-label task. Please let me know, if I'm wrong."}}