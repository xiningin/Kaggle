{"cell_type":{"31026480":"code","00832a61":"code","99d3e123":"code","9ba7af0f":"code","82c5fd95":"code","79879c64":"code","37442602":"code","66797451":"code","97b71ccc":"code","19f9d078":"code","abace3ac":"code","6ac84e7b":"code","19f6ce12":"code","79624bf1":"code","c83d2448":"code","8ef9f272":"code","cf1b8b03":"code","6ebf4223":"code","bc450e2d":"code","0934afe6":"code","ec046ba9":"code","c4dff82d":"code","76319454":"code","9d7cb0c1":"code","28ccc3a0":"code","eca24a2d":"code","f3a9cc48":"code","764eb1eb":"code","2777d195":"code","12c0e43d":"code","503eb15c":"code","69f45767":"code","dacf383d":"code","ee6c2943":"code","790a4496":"code","59cdceaf":"code","a0ec7bd9":"code","97d62e21":"code","55c4d129":"code","3fb0d082":"code","046bc5d1":"code","b05f0d27":"code","bef417be":"code","12739360":"code","23ebe35b":"code","aaf85220":"code","4b961e7e":"code","b720399d":"code","5a30f247":"code","75b0a7bb":"code","0ed56b08":"code","333cb0ed":"code","93e5a85c":"code","ebbab6ee":"markdown","7aa7975f":"markdown","3aa27405":"markdown","42d40be2":"markdown","d49031e7":"markdown","50d9935f":"markdown","d08b2b0e":"markdown","e3ccbc9d":"markdown","e1ffea10":"markdown","f099f318":"markdown","c11a8089":"markdown","24c8eeed":"markdown","482e4307":"markdown","ffd9d0eb":"markdown","f4325554":"markdown","5da84156":"markdown","b3e0cb69":"markdown","62fa3dd2":"markdown","7b55bd76":"markdown","213d88c4":"markdown","4e5f4088":"markdown","9a869cb5":"markdown","4512bdb4":"markdown","c6f55895":"markdown","1ff01e91":"markdown"},"source":{"31026480":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn')","00832a61":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ny = train['SalePrice']","99d3e123":"train.shape","9ba7af0f":"test.shape","82c5fd95":"sns.heatmap(train.isnull(),yticklabels=False, cmap='plasma')","79879c64":"train.isnull().sum().sort_values(ascending=False)[0:19]","37442602":"test.isnull().sum().sort_values(ascending=False)[0:33]","66797451":"columns = ['Alley', 'MiscFeature', 'Fence', 'GarageYrBlt']\n\ntrain.drop(columns=columns, inplace=True)\ntest.drop(columns=columns, inplace=True)\ntrain['PoolQC'] = train['PoolQC'].fillna('None')\ntest['PoolQC'] = test['PoolQC'].fillna('None')\n\ntrain.drop(columns=['Id'], inplace=True)","97b71ccc":"columns = ['LotFrontage', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',  'TotalBsmtSF', 'GarageArea']\n\nfor item in columns:\n    train[item] = train[item].fillna(train[item].mean())\n    test[item] = test[item].fillna(test[item].mean())","19f9d078":"columns = ['BsmtCond', 'BsmtQual', 'FireplaceQu', 'GarageType', 'GarageCond', 'GarageFinish', 'GarageQual', 'MSZoning',\n           'MasVnrType', 'MasVnrArea', 'BsmtExposure','BsmtFinType2', 'BsmtFinType1', 'Electrical',  'Utilities',\n           'BsmtFullBath', 'BsmtHalfBath', 'Functional', 'SaleType', 'Exterior2nd', 'Exterior1st', 'KitchenQual']\n\nfor item in columns:\n    train[item] = train[item].fillna(train[item].mode()[0])\n    test[item] = test[item].fillna(test[item].mode()[0])","abace3ac":"train.isnull().any().any()","6ac84e7b":"test.isnull().any().any()","19f6ce12":"sns.distplot(train['SalePrice'], bins=100);","79624bf1":"df_num = train.select_dtypes(include = ['float64', 'int64'])\ndf_num.head()","c83d2448":"df_num_corr = df_num.corr()['SalePrice'][:-1]\ngolden_features_list = df_num_corr[abs(df_num_corr) >= 0].sort_values(ascending=False)\ngolden_features_list","8ef9f272":"for i in range(0, len(df_num.columns), 5):\n    sns.pairplot(data=df_num,\n                x_vars=df_num.columns[i:i+5],\n                y_vars=['SalePrice'])","cf1b8b03":"corr = df_num.drop('SalePrice', axis=1).corr() # We already examined SalePrice correlations\nplt.figure(figsize=(12, 10))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","6ebf4223":"df_not_num = train.select_dtypes(include = ['O'])","bc450e2d":"fig, axes = plt.subplots(round(len(df_not_num.columns) \/ 3), 3, figsize=(12, 30))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(df_not_num.columns):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n        sns.countplot(x=df_not_num.columns[i], alpha=0.7, data=df_not_num, ax=ax)\n\nfig.tight_layout()","0934afe6":"golden_features_list1 = list(df_not_num.columns)","ec046ba9":"excluded_features = ['GarageCond', 'Functional', 'Heating', 'BsmtFinType2', 'RoofMatl', 'Street', 'Utilities']\n\nfor item in excluded_features:\n    golden_features_list1.remove(item)","c4dff82d":"golden_features_list = list(golden_features_list.index)","76319454":"golden_features_list.extend(golden_features_list1)","9d7cb0c1":"train = train[golden_features_list]","28ccc3a0":"test = test[golden_features_list]","eca24a2d":"final_df = pd.concat([train, test], axis=0)","f3a9cc48":"final_df.shape","764eb1eb":"final_df.isnull().any().any()","2777d195":"def One_hot_encoding(columns):\n    df_final=final_df\n    i=0\n    for fields in columns:\n        df1=pd.get_dummies(final_df[fields],drop_first=True)\n        \n        final_df.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:           \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([final_df,df_final],axis=1)\n        \n    return df_final","12c0e43d":"df_final = One_hot_encoding(golden_features_list1)","503eb15c":"df_final.shape","69f45767":"df_final = df_final.loc[:,~df_final.columns.duplicated()]","dacf383d":"df_final.shape","ee6c2943":"df_Train=df_final.iloc[:1460,:]\ndf_Test=df_final.iloc[1460:,:]","790a4496":"my_temp = pd.concat([df_Train,y],axis=1)\n#my_temp.to_csv('train_conv_1.csv',index=False)\n#df_Test.to_csv('test_conv_1.csv',index=False)","59cdceaf":"import xgboost","a0ec7bd9":"regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, missing=None, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n             objective='reg:squarederror', random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n             validate_parameters=1, verbosity=None)","97d62e21":"regressor.fit(df_Train,y);","55c4d129":"y_pred = regressor.predict(df_Test)","3fb0d082":"y_pred","046bc5d1":"pred=pd.DataFrame(y_pred)\nsamp = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsub = pd.concat([samp['Id'],pred], axis=1)\nsub.columns=['Id','SalePrice']","b05f0d27":"sub","bef417be":"#sub.to_csv('My_sub3.csv',index=False)","12739360":"df_train = pd.read_csv('..\/input\/my-data\/train_conv.csv')\ndf_test = pd.read_csv('..\/input\/my-data\/test_conv.csv')","23ebe35b":"sub.drop(['Id'],axis=1, inplace=True)\ndf_Test=pd.concat([df_test,sub],axis=1)","aaf85220":"df_Train=pd.concat([df_train,df_Test],axis=0)","4b961e7e":"X_train=df_Train.drop(['SalePrice'],axis=1)\ny_train=df_Train['SalePrice']","b720399d":"from keras import backend as K\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))","5a30f247":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.layers import Dropout\n\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n\n# Adding the second hidden layer\nclassifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n\n# Adding the third hidden layer\nclassifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n# Adding the output layer\nclassifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n\n# Compiling the ANN\nclassifier.compile(loss=root_mean_squared_error,optimizer='Adamax')\n\n# Fitting the ANN to the Training set\nmodel_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)","75b0a7bb":"ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)","0ed56b08":"ann_pred","333cb0ed":"ann_pred=pd.DataFrame(ann_pred)\nsamp = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsub = pd.concat([samp['Id'],ann_pred], axis=1)\nsub.columns=['Id','SalePrice']","93e5a85c":"#sub.to_csv('My_sub_final.csv',index=False)","ebbab6ee":"# Contents:\n\n1. Import Libraries\n2. Import DataSets\n3. Handle Missing Value\n4. Exploratory Data Analysis(EDA)\n5. Feature selection\n6. Feature Engineering\n7. Train Xgboost Classifier\n8. Artificial Intelligence\n\nXgBoost - 92% Accuracy, AI - 95% Accuracy\n\n**check my beginners nodebook to know why i aaplied feature enginnering and Xgboost Classifier:**\n[Beginners Notebook-90% Accuracy][1] \n\n[1]: https:\/\/www.kaggle.com\/harshkothari21\/beginners-notebook-90-accuracy","7aa7975f":"### Use mean for filling null values for numerical features","3aa27405":"Correlation by itself does not always explain the relationship between data so ploting them could even lead us to new insights and in the same manner, check that our correlated values have a linear relationship to the `SalePrice`.","42d40be2":"# Train Xgboost Classifier","d49031e7":"We will be using onehot encoding technique for feature engineering ","50d9935f":"# Feature selection","d08b2b0e":"**Ensuring null values is any**","e3ccbc9d":"With this information we can see that the prices are skewed right and some outliers lies above ~500,000. We will eventually want to get rid of the them to get a normal distribution of the independent variable (`SalePrice`) for machine learning.","e1ffea10":"### Checking for missing values if any!","f099f318":"# Import Datasets","c11a8089":"### Drop columns with too much missing values\nPlus there is so much features to analyse that it may be better to concentrate on the ones which can give us real insights. Also I tried including these features in model but score was not up do the mark","24c8eeed":"**Let's examine Non Numerical Features**","482e4307":"if we look closely at the data we can see that a lot of data points are located on `x = 0` which may indicate the absence of such feature in the house.","ffd9d0eb":"# Import Libraries","f4325554":"# Exploratory Data Analysis(EDA)","5da84156":"### If you want know how I selected best parameter for XgBosst(HyperParameter Tunning): \n\n[Beginners Notebook-90% Accuracy][1] \n\n[1]: https:\/\/www.kaggle.com\/harshkothari21\/beginners-notebook-90-accuracy","b3e0cb69":"### Take Top strongly correlated values with SalePrice:\n\n**I tried Selecting Top 10 features and trained my model but score was not up to the mark**","62fa3dd2":"Let's Just exclude that features from our model","7b55bd76":"**Data Frame with only numerical features**","213d88c4":"### Use mode for filling null values for categorical features","4e5f4088":"We can see that some categories are predominant for some features such as `Utilities`, `Heating`, `GarageCond`, `Functional`... These features may not be relevant for our predictive model","9a869cb5":"# Artificial Intelligence\n\n**Below csv files have all features with applied feature engineering. If you want to know in detail, check my notebook :**\n\n[Beginners Notebook-90% Accuracy][1] \n\n[1]: https:\/\/www.kaggle.com\/harshkothari21\/beginners-notebook-90-accuracy","4512bdb4":"# Feature Engineering","c6f55895":"# Handle Missing Values","1ff01e91":"### Let's examine feature by correlation matrix"}}