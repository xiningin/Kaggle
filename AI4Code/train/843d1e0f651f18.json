{"cell_type":{"cd09168f":"code","824816ef":"code","30ed395d":"code","23719f44":"code","9545ae4d":"code","d3c5ac04":"code","eed22780":"code","043c0844":"code","d1b564fa":"code","72cc04be":"code","77541451":"code","4368ff5b":"code","8f3b039f":"code","0ec765f7":"code","2624650c":"code","9300c058":"code","18121ede":"code","0101d3b9":"code","cf037099":"code","eac93a26":"code","a51317cf":"code","a90a663e":"code","eaf428e9":"code","d8dde6f6":"code","8b9bc522":"code","0bbf0810":"code","97132b53":"code","fa8a93fb":"code","e907ed25":"code","be2f738b":"code","035095fc":"code","1f6848a7":"code","281ea0cc":"code","eade3c72":"code","559a633f":"code","801b16c2":"code","980c3d89":"code","224558f7":"code","8ee872af":"code","abf0bcba":"code","440a3e12":"code","ce8f1abe":"code","36643dbe":"code","6379a202":"code","933aa202":"code","0fec0407":"code","677e91b2":"code","24397228":"code","65f6d381":"code","227f9541":"code","ebf5957b":"code","d658715a":"code","ef75c174":"code","12b6173c":"code","2aa0c32c":"code","cb9ab666":"code","0cf7cf7a":"code","5c9cc912":"code","7e7d184b":"code","04d57f03":"code","f2392621":"code","e25c3e59":"code","85326c90":"code","eb7db401":"code","38452827":"code","8b77b65d":"code","8641fe21":"code","af218722":"code","2de5437f":"code","f76c92bd":"code","184925db":"code","17caada3":"code","00081205":"code","ebfd7343":"code","b8dff412":"code","f1f33a8e":"code","7e1ece54":"code","8b9f31ce":"code","296e2d1a":"code","ee7d4549":"code","349e98bf":"code","d6a4532f":"code","f8ddd5e1":"code","78aa49a3":"code","45f8ba2b":"code","27832a72":"code","fb23d2ce":"code","8179c211":"code","f0de6451":"code","1cf58ed6":"code","79102b0a":"code","de2593f9":"code","68fed7cf":"code","553705b5":"code","8f9b90ec":"code","227f1f8f":"code","635c30bd":"code","98665947":"code","e7d03f72":"markdown","665ee861":"markdown","74689d08":"markdown","a24081e6":"markdown","1a965d74":"markdown","555ea60e":"markdown","fbd80a77":"markdown","b7938063":"markdown","99cd95f7":"markdown","76de5bfd":"markdown","5a4bf9fe":"markdown","d30d5b80":"markdown","99e3b529":"markdown","e99ba299":"markdown","a15ec581":"markdown","5f31b6db":"markdown","83b808ef":"markdown","51e4b067":"markdown","d793e590":"markdown","a2da8855":"markdown","41089626":"markdown","56d3819c":"markdown","dd1ec39a":"markdown","463e70ed":"markdown","ff56acc3":"markdown","366d66dc":"markdown","bdb8e179":"markdown","0d668402":"markdown","f396eb58":"markdown","0a8379c6":"markdown","a3b94c1c":"markdown","a6341e7e":"markdown","831e1b61":"markdown","505227ac":"markdown","022a912f":"markdown","71ef4375":"markdown","3ea773b6":"markdown","137a99d9":"markdown","edab502a":"markdown","3931b1df":"markdown","b2e6157c":"markdown","80828fe3":"markdown","8798a28e":"markdown","53003c20":"markdown","6877f558":"markdown","02f233c4":"markdown","561cce0a":"markdown","2bda2842":"markdown","30fa8ab3":"markdown","e27299d3":"markdown","a0712a11":"markdown","1fc52927":"markdown","ef6fac4c":"markdown","a40fb3d5":"markdown","dfbe8119":"markdown","24a7e0b2":"markdown","57d62332":"markdown","9312029c":"markdown","8cbb9069":"markdown","e5671dcf":"markdown","c889251c":"markdown","e342b0be":"markdown","e436bf0f":"markdown","ccb920cb":"markdown","e5e47e9f":"markdown","5b8cdd93":"markdown","e908d303":"markdown"},"source":{"cd09168f":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\nimport pandas as pd\nimport matplotlib as plt\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n","824816ef":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\ndata1= pd.read_csv(\"..\/input\/properati\/DS_Proyecto_01_Datos_Properati.csv\")\n#como ver todas las columnas en head\n#pd.options.display.max_columns = None\ndata1.head()\n\n","30ed395d":"print('El dataset tiene', data1.shape[0], 'filas y', data1.shape[1], 'columnas.')\n","23719f44":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\n\nprint('Valores faltantes por columna')\n\n\nprint (data1.isnull().sum())\n","9545ae4d":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\n#tipos=data.property_type.unique()\nprint('Los tipos de propiedades en anuncios son: ', data1['property_type'].unique())\nnumero_de_tipos=data1[\"property_type\"].value_counts()\nprint(numero_de_tipos)\n\n","d3c5ac04":"#g = sns.factorplot(\"property_type\", data=data1, aspect=1.5, kind=\"count\", color=\"r\",orient=\"h\")\n#g.set_xticklabels(rotation=30)\n#sns.displot(data, x=\"property_type\", bins=20)","eed22780":"\nfig, ax = plt.subplots(figsize = (12,8))\n\nsns.countplot(y = 'property_type', data = data1, order = data1.property_type.value_counts().index)\nplt.ylabel('Tipo de propiedad', size = 18, color='red')\nplt.xlim(0,130000)\nax.xaxis.set_ticks_position('top')\nax.set_xlabel('')   \nax.text(0, 1.05, 'Instancias', transform=ax.transAxes, size=18, color='red')\nplt.title(' Distribucion Por Tipo De Propiedad', size = 25, weight=600, pad = 60, loc = 'left')\n\nplt.show()","043c0844":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\n\nv2=data1.l2\nv3=data1.l3\n#plt.figure(figsize=(20,30))\n#g=sns.catplot(x=\"l2\", kind=\"count\", palette=\"ch:.25\", data=data1,aspect=3)\n#g=sns.catplot(x=\"l3\", kind=\"count\", palette=\"ch:.25\", data=data1,aspect=3)\n","d1b564fa":"plt.figure(figsize = (15,10))\n\nplt.subplot(2,1,1)\nsns.countplot(data = data1, x = 'l2', order = data1.l2.value_counts().index)\nplt.xlabel('Zonas de Buenos Aires', size = 15)\nplt.ylabel('Cantidad de listings', size = 15)\n\n\nplt.subplot(2,1,2)\nsns.countplot(data = data1, x = 'l3',order = data1.l3.value_counts().index)\nplt.xticks(rotation= 90)\nplt.xlabel('Barrios de Buenos Aires', size = 15)\nplt.ylabel('Cantidad de listings', size = 15)\n\nplt.show()","72cc04be":"#plt.figure(figsize=(15,20))\n\n#plt.subplot(211)\n#data1['l2'].value_counts().plot(kind='bar')\n#plt.subplot(212)\n#data1['l3'].value_counts().plot(kind='barh')","77541451":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\ntipos=[\"Departamento\",\"PH\",\"Casa\"]\nregion=[\"Capital Federal\"]\nproperati_top3 = data1[data1.property_type.isin(tipos)  & data1.l2.isin(region)] \nprint(\"NUEVO DATA FRAME\", properati_top3.shape)\nprint(\"Coincide con el dato del Checkpoint\")\n\n#data1.shape","4368ff5b":"plt.figure(figsize = (10,5))\nsns.countplot(x='property_type', data = properati_top3, palette='Blues')\nplt.xlabel('Tipo de propiedad', size = 13)\nplt.ylabel('Cantidad', size = 13)\nplt.title('Top 3 de propiedades a la venta en Capital Federal', size = 15)\n\nplt.show()","8f3b039f":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\nproperati_top3.describe()","0ec765f7":"properati_top3.head()","2624650c":"properati_top3.currency.value_counts()","9300c058":"\nproperati_top3.operation_type.value_counts()","18121ede":"properati_top3.l1.value_counts()","0101d3b9":"properati_top3.drop(['lon','lat', 'start_date','end_date','created_on','l1', 'currency', 'operation_type', 'l2'],1, inplace = True)","cf037099":"properati_top3.shape","eac93a26":"#properati_top3.boxplot([\"surface_total\"])\n#import seaborn as sns\nplt.figure(figsize = (30,10))\nsns.set_theme(style=\"whitegrid\")\nax = sns.boxplot(x=properati_top3[\"surface_total\"])\nsns.distplot(properati_top3['surface_total'])","a51317cf":"mask_st = properati_top3['surface_total'] < properati_top3['surface_total'].quantile(0.95)\n\n\nplt.figure(figsize = (30,10))\n\nplt.subplot(2,1,1)\nsns.boxplot(properati_top3['surface_total'][mask_st])\nplt.xlabel(\"\")\nplt.title('Distribuci\u00f3n de la superficie total filtrando cuantil 0.95', weight=600, size = 50, pad = 20)\n#ax.tick_params(axis=\"x\", labelsize=15)\nplt.subplot(2,1,2)\nsns.distplot(properati_top3['surface_total'][mask_st], kde = False)\nplt.xlabel('Superficie Total [$m^{2}$]', size = 25, color='#777')\nplt.savefig('Dist_sup_total_q95.png')\nplt.show()","a90a663e":"properati_top3=properati_top3[mask_st]","eaf428e9":"properati_top3.shape","d8dde6f6":"properati_top3.nsmallest(5, ['surface_total'])","8b9bc522":"\nmask_surface = properati_top3['surface_covered'] <= properati_top3['surface_total']\n\nproperati_top3 = properati_top3[mask_surface]","0bbf0810":"properati_top3.shape","97132b53":"properati_top3.nsmallest(5, ['surface_total'])","fa8a93fb":"mask_ss = properati_top3.surface_total >= 20\nproperati_top3= properati_top3[mask_ss]\nproperati_top3.describe()","e907ed25":"print('Ambientes:\\n', properati_top3.rooms.value_counts().sort_index()) #\u00bfcu\u00e1ntos valores tenemos por unidades?","be2f738b":"plt.figure(figsize = (30,10))\n\nplt.subplot(2,1,1)\nsns.boxplot(properati_top3['surface_total'][mask_st])\nplt.xlabel(\"\")\nplt.title('Distribuci\u00f3n de la superficie total', weight=600, size = 50, pad = 20)\n#ax.tick_params(axis=\"x\", labelsize=15)\nplt.subplot(2,1,2)\nsns.distplot(properati_top3['surface_total'][mask_st], kde = False)\nplt.xlabel('Superficie Total [$m^{2}$]', size = 25, color='#777')\n#plt.savefig('Dist_sup_total_q95.png')\nplt.show()","035095fc":"\nproperati_top3 = properati_top3[properati_top3['surface_total'] <= 180] \nprint(properati_top3.shape)\n#properati_top3.head()","1f6848a7":"plt.figure(figsize = (25,5))\nsns.boxplot(x = 'surface_total', data = properati_top3) #volvemos a graficar para verificar la distribuci\u00f3n\nplt.title('Distribuci\u00f3n de Superficies Totales (filtrado)', size = 30)\nplt.xlabel('Superficie Total [$m^{2}$]', size = 15)\nplt.show()","281ea0cc":"\nplt.figure(figsize = (26,10))\nsns.boxplot( x='price', data = properati_top3) \nplt.title('Gr\u00e1fico de Precios', size = 15)\nplt.xlabel('Precio de propiedades en USD')\nplt.xticks([0, 5000000, 10000000, 15000000, 20000000, 25000000, 30000000], labels = ['0', '5 Millones','10 Millones','15 Millones','20 Millones','25 Millones', '30 Millones'])\nplt.show()","eade3c72":"mask_p = properati_top3['price'] < properati_top3['price'].quantile(0.99)\nproperati_top3 = properati_top3[mask_p]","559a633f":"\nplt.figure(figsize = (30,10))\n\nplt.subplot(2,1,1)\nsns.boxplot(properati_top3.price)\nplt.xlabel(\"\")\nplt.title('Distribuci\u00f3n del precio filtrando el cuantil 0.99', weight=600, size = 50, pad = 20)\nplt.subplot(2,1,2)\nsns.distplot(properati_top3.price, kde = True, hist = True)\n\nplt.xlabel('Precio [USD]', size = 18, color='#777777')\nplt.ylabel('Probabilidad', size = 18, color='#777777')\nplt.savefig('Dist_precio_q90.png')\nplt.show()","801b16c2":"properati_top3[properati_top3.rooms > 7].head(20)","980c3d89":"print('Las propiedades con m\u00e1s de 7 ambientes respresentan el', \n      round((properati_top3[properati_top3.rooms > 7].shape[0]\/properati_top3.rooms.shape[0])*100,2),'% de nuestro dataset al momento.')","224558f7":"properati_top3 = properati_top3[properati_top3.rooms < 8]\nproperati_top3.shape","8ee872af":"properati_top3.describe()","abf0bcba":"properati_top3.bathrooms.value_counts().sort_index()","440a3e12":"print('Las propiedades con m\u00e1s de 5 ba\u00f1os respresentan el', round((properati_top3[properati_top3.bathrooms > 5].shape[0]\/properati_top3.bathrooms.shape[0])*100,2),'% de nuestro dataset al momento.')","ce8f1abe":"properati_top3 = properati_top3[properati_top3.bathrooms < 6]","36643dbe":"properati_top3.bedrooms.value_counts().sort_index()","6379a202":"print('Las propiedades con m\u00e1s de 5 dormitorios respresentan el', round((properati_top3[properati_top3.bedrooms > 5].shape[0]\/properati_top3.bedrooms.shape[0])*100,2),'% de nuestro dataset al momento.')","933aa202":"properati_top3 = properati_top3[properati_top3.bedrooms < 6]","0fec0407":"properati_top3.describe()","677e91b2":"properati_top3.shape","24397228":"plt.figure(figsize = (40,13))\nsns.pairplot(data = properati_top3, hue = 'property_type')\nplt.savefig('pairplot_df_cf.png')\nplt.show()","65f6d381":"sns.heatmap(properati_top3.corr(),cmap= \"YlGnBu\",annot=True)","227f9541":"#plt.barh(X_train.columns, tree_regressor.feature_importances_)","ebf5957b":"dptos = properati_top3[properati_top3.property_type == 'Departamento']\ncasas = properati_top3[properati_top3.property_type == 'Casa']\nph = properati_top3[properati_top3.property_type == 'PH']","d658715a":"sns.heatmap(dptos.corr(),cmap= \"YlGnBu\",annot=True)","ef75c174":"sns.heatmap(casas.corr(),cmap= \"YlGnBu\",annot=True)","12b6173c":"sns.heatmap(ph.corr(),cmap= \"YlGnBu\",annot=True)","2aa0c32c":"properati_top3.shape","cb9ab666":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\ndesafio= pd.read_csv('..\/input\/properati\/DS_Proyecto_01_Datos_Properati.csv')\ndesafio.head(5)","0cf7cf7a":"\ndesafio = desafio.filter(items=['l2', 'l3','surface_total', 'price', 'property_type'])\ndesafio","5c9cc912":"\ndesafio['price_m2'] = desafio['price']\/desafio['surface_total']\ndesafio.head(5)","7e7d184b":"table = pd.pivot_table(desafio, values='price_m2', index=['l3'], aggfunc = np.mean)\ncaros = table.sort_values('price_m2', ascending=False).iloc[:5]\ncaros","04d57f03":"baratos = table.sort_values('price_m2', ascending=True).iloc[:5]\nbaratos\n","f2392621":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\n#Filtrado de DF\ndata_raiz = pd.read_csv('..\/input\/properati\/DS_Proyecto_01_Datos_Properati.csv') \ndata2 = data_raiz[(data_raiz['l2'] == \"Capital Federal\") & (data_raiz.property_type.isin(['Departamento','Casa','PH']))]\ndata2 = data2[(data2['surface_total'] >= 15) & (data2['surface_total'] <= 1000)]\ndata2 = data2[(data2['price'] <= 4000000)]\ndata2 = data2.filter(items=['rooms', 'bedrooms','bathrooms','surface_total', 'surface_covered', 'price'])\ndata2 = data2.dropna()\nprint('Checkpoint: ', data2.shape)\n\ndata2.head(5)","e25c3e59":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error","85326c90":"X = data2.drop(['price'], axis=1)\ny = data2['price']","eb7db401":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=42)\n\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","38452827":"lineal_regressor = LinearRegression()\n","8b77b65d":"lineal_regressor.fit(X_train, y_train)","8641fe21":"y_train_pred_lin = lineal_regressor.predict(X_train)\ny_test_pred_lin = lineal_regressor.predict(X_test)","af218722":"\nrmse_lin_train = np.sqrt(mean_squared_error(y_train, y_train_pred_lin))\nrmse_lin_test = np.sqrt(mean_squared_error(y_test, y_test_pred_lin))","2de5437f":"print(f'Ra\u00edz del error cuadr\u00e1tico medio en Regresi\u00f3n Lineal - Train: {rmse_lin_train}')\nprint(f'Ra\u00edz del error cuadr\u00e1tico medio en Regresi\u00f3n Lineal - Test: {rmse_lin_test}')","f76c92bd":"data2.describe()","184925db":"tree_regressor = DecisionTreeRegressor()","17caada3":"\ntree_regressor.fit(X_train, y_train)","00081205":"y_train_pred_tree = tree_regressor.predict(X_train)\ny_test_pred_tree = tree_regressor.predict(X_test)","ebfd7343":"rmse_train_tree = np.sqrt(mean_squared_error(y_train, y_train_pred_tree))\nrmse_test_tree = np.sqrt(mean_squared_error(y_test, y_test_pred_tree))\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Train es de: {rmse_train_tree}')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Test es de: {rmse_test_tree}')","b8dff412":"list_rmse_train_tree = []\nlist_rmse_test_tree = []\nrmse_train = 0\nrmse_test = 0\nmax_depths = [1,5,6,7,8,9,10,10.5,11,12,13,14,15,16,17,18,19,20,21,22,24,25,30,40,50]\n\nfor i in max_depths:\n    tree_reg = DecisionTreeRegressor(max_depth = i)\n    tree_reg.fit(X_train,y_train)\n    \n    y_train_pred_tree = tree_reg.predict(X_train)\n    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred_tree))\n\n    y_test_pred_tree = tree_reg.predict(X_test)\n    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred_tree))\n    \n    list_rmse_train_tree.append(rmse_train)\n    list_rmse_test_tree.append(rmse_test)","f1f33a8e":"min_test_tree = np.amin(list_rmse_test_tree)\nlista_rmse_test_tree_op = list_rmse_test_tree.index(min(list_rmse_test_tree))\nmax_depths_op = max_depths[lista_rmse_test_tree_op]\nprint('El m\u00ednimo de RMSE en test es ', min_test_tree, ' en ', max_depths_op, ' profundidad del \u00e1rbol.')\n\nplt.figure(figsize=(15,5))\n\nplt.plot(max_depths, list_rmse_train_tree, 'o-', label = 'RMSE train')\nplt.plot(max_depths, list_rmse_test_tree, 'o-', label = 'RMSE test')\nplt.xlabel('Profundidad del \u00e1rbol [max_depths]', size = 15)\nplt.ylabel('RMSE', size =15)\nplt.title('Rendimiento \u00c1rbol de Decisi\u00f3n', size = 20)\nplt.scatter(max_depths_op, min_test_tree, s=300, marker = '*', \n         label = 'RMSE = {} \\nmax_depth = {} '.format(round(min_test_tree),max_depths_op), color = 'red')\nplt.legend(loc = 'upper right', fontsize = 15)\nplt.savefig('Arbol1.png')\n\nplt.show()","7e1ece54":"tree_regressor = DecisionTreeRegressor(max_depth = 16)\ntree_regressor.fit(X_train, y_train)\ny_train_pred_tree = tree_regressor.predict(X_train)\ny_test_pred_tree = tree_regressor.predict(X_test)\n\nrmse_train_tree = np.sqrt(mean_squared_error(y_train, y_train_pred_tree))\nrmse_test_tree = np.sqrt(mean_squared_error(y_test, y_test_pred_tree))\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Train es de: {rmse_train_tree}')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Test es de: {rmse_test_tree}')","8b9f31ce":"knn_regressor = KNeighborsRegressor()\nknn_regressor","296e2d1a":"knn_regressor.fit(X_train, y_train) \n\ny_train_pred_knn = knn_regressor.predict(X_train)\ny_test_pred_knn = knn_regressor.predict(X_test)","ee7d4549":"\nrmse_train_knn = np.sqrt(mean_squared_error(y_train, y_train_pred_knn))\nrmse_test_knn = np.sqrt(mean_squared_error(y_test, y_test_pred_knn))\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Train es de: {rmse_train_knn}')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Test es de: {rmse_test_knn}')","349e98bf":"lista_rmse_train_knn = []\nlista_rmse_test_knn = []\nvecinos = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,25,30,35,40,45,50]\n\nfor i in vecinos:\n    knn_reg = KNeighborsRegressor(n_neighbors = i)\n    knn_reg.fit(X_train,y_train)\n    \n    y_train_pred_knn = knn_reg.predict(X_train)\n    rmse_train_knn = np.sqrt(mean_squared_error(y_train, y_train_pred_knn))\n\n    y_test_pred_knn = knn_reg.predict(X_test)\n    rmse_test_knn = np.sqrt(mean_squared_error(y_test, y_test_pred_knn))\n    \n    lista_rmse_train_knn.append(rmse_train_knn)\n    lista_rmse_test_knn.append(rmse_test_knn)","d6a4532f":"min_test_knn = np.amin(lista_rmse_test_knn)\nlista_rmse_test_knn_op = lista_rmse_test_knn.index(min(lista_rmse_test_knn))\nvecinos_op = vecinos[lista_rmse_test_knn_op]\n\nprint('Minimo de RMSE en test es ', min_test_knn,' en vecinos', vecinos_op)\n\n\nplt.figure(figsize=(15,5))\n\nplt.plot(vecinos, lista_rmse_train_knn, 'o-', label = 'RMSE train')\nplt.plot(vecinos, lista_rmse_test_knn, 'o-', label = 'RMSE test')\nplt.xlabel('Cantidad de Vecinos [n_neighbors]', size = 15)\nplt.ylabel('RMSE', size =15)\nplt.title('Rendimiento KNN', size = 20)\nplt.scatter(vecinos_op, min_test_knn, s=300, marker = '*', \n         label = 'RMSE = {} \\nn_neighbors = {} '.format(round(min_test_knn),vecinos_op), color = 'red')\nplt.legend(loc = 'center right', fontsize = 15)\nplt.savefig('KNN1.png')\n\nplt.show()","f8ddd5e1":"\nknn_regressor = KNeighborsRegressor(n_neighbors = 3)\nknn_regressor.fit(X_train, y_train)\ny_train_pred_knn = knn_regressor.predict(X_train)\ny_test_pred_knn = knn_regressor.predict(X_test)\nrmse_train_knn = np.sqrt(mean_squared_error(y_train, y_train_pred_knn))\nrmse_test_knn = np.sqrt(mean_squared_error(y_test, y_test_pred_knn))\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Train es de: {rmse_train_knn}')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Test es de: {rmse_test_knn}')","78aa49a3":"print(f'Ra\u00edz del error cuadr\u00e1tico medio en Regresi\u00f3n Lineal - Train: {rmse_lin_train}')\nprint(f'Ra\u00edz del error cuadr\u00e1tico medio en Regresi\u00f3n Lineal - Test: {rmse_lin_test}')\nprint(f'Ra\u00edz del error cuadr\u00e1tico medio en \u00c1rbol de Decisi\u00f3n - Train: {rmse_train_tree}')\nprint(f'Ra\u00edz del error cuadr\u00e1tico medio en \u00c1rbol de Decisi\u00f3n - Test: {rmse_test_tree}')\nprint(f'Ra\u00edz del error cuadr\u00e1tico medio en KNN - Train: {rmse_train_knn}')\nprint(f'Ra\u00edz del error cuadr\u00e1tico medio en KNN - Test: {rmse_test_knn}')","45f8ba2b":"modelos = ['\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos - KNN', 'Regresi\u00f3n Lineal',]\n\nfor i, model in enumerate([tree_regressor, knn_regressor, lineal_regressor]):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    \n    print(f'Modelo: {modelos[i]}')\n\n    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n    print(f'Ra\u00edz del error cuadr\u00e1tico medio en Train: {rmse_train}')\n    print(f'Ra\u00edz del error cuadr\u00e1tico medio en Test: {rmse_test}')\n    \n    plt.figure(figsize = (15,2))\n\n    plt.subplot(1,2,1)\n    sns.distplot(y_train - y_train_pred, bins = 20, label = 'train')\n    sns.distplot(y_test - y_test_pred, bins = 20, label = 'test')\n    plt.xlabel('Errores')\n    plt.legend()\n\n\n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  \n    np.max([ax.get_xlim(), ax.get_ylim()]), \n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","27832a72":"tree_regressor.fit(X_train, y_train)\ny_pred = tree_regressor.predict(X_test)\nval_real = pd.Series(y_test.values)\nval_pred = pd.Series(y_pred)\n\npredicciones_tree = pd.concat([val_real.rename('ValorReal'),\n                          val_pred.rename('ValorPred') ,\n                          abs(val_real-val_pred).rename('Dif(+\/-)'),\n                          abs((val_real-val_pred)\/(val_pred)*100).rename('Porcentaje de la diferencia')] ,  axis=1)\n\npredicciones_tree","fb23d2ce":"dummy_tipos = pd.get_dummies(properati_top3['property_type']) #vuelvo numericas \u00e9stas categorias\ndummy_barrio = pd.get_dummies(properati_top3['l3'])\ndata_ml2 = pd.concat([properati_top3,dummy_barrio, dummy_tipos], axis = 1)\ndata_ml2 = data_ml2.drop(['l3','title', 'description','property_type'], axis =1) #elimino las columnas categoricas\ndata_ml2.dropna(inplace=True)\nprint(data_ml2.shape)\ndata_ml2.head(2)","8179c211":"\nX_2 = data_ml2.drop(['price'], axis=1)\ny_2 = data_ml2['price']\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y_2, test_size=0.30) #Divido las muestras\nprint(X_train2.shape, y_train2.shape, X_test2.shape, y_test2.shape)","f0de6451":"tree_regressor_2 = DecisionTreeRegressor()\nknn_regressor_2 = KNeighborsRegressor()\nlinear_model_2 = LinearRegression() #benchmark","1cf58ed6":"\ntree_regressor_2.fit(X_train2, y_train2) #entrenamos\nknn_regressor_2.fit(X_train2, y_train2)\nlinear_model_2.fit(X_train2, y_train2)","79102b0a":"y_train_pred_tree2 = tree_regressor_2.predict(X_train2)\ny_test_pred_tree2 = tree_regressor_2.predict(X_test2)\ny_train_pred_knn2 = knn_regressor_2.predict(X_train2)\ny_test_pred_knn2 = knn_regressor_2.predict(X_test2)\ny_train_pred_lineal2 = linear_model_2.predict(X_train2)\ny_test_pred_lineal2 = linear_model_2.predict(X_test2)","de2593f9":"#primer pantallazo de RMSE\nrmse_train_tree2 = np.sqrt(mean_squared_error(y_train2, y_train_pred_tree2))\nrmse_test_tree2 = np.sqrt(mean_squared_error(y_test2, y_test_pred_tree2))\nprint('RMSE \u00c1RBOL 2')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en TRAIN es de: {rmse_train_tree2} ')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en TEST es de: {rmse_test_tree2} \\n')\n\nrmse_train_knn2 = np.sqrt(mean_squared_error(y_train2, y_train_pred_knn2))\nrmse_test_knn2 = np.sqrt(mean_squared_error(y_test2, y_test_pred_knn2))\nprint('RMSE KNN 2')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en TRAIN es de: {rmse_train_knn2} ')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en TEST es de: {rmse_test_knn2} \\n')\n\nrmse_train_lenal2 = np.sqrt(mean_squared_error(y_train2, y_train_pred_lineal2)) #PUNTO Lineal\nrmse_test_lineal2 = np.sqrt(mean_squared_error(y_test2, y_test_pred_lineal2))\nprint('RMSE REGRESI\u00d3N LINEAL 2')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en TRAIN es de: {rmse_train_lenal2} ')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en TEST es de: {rmse_test_lineal2} \\n')","68fed7cf":"lista_rmse_train_tree2 = []\nlista_rmse_test_tree2 = []\nrmse_train2 = 0\nrmse_test2 = 0\nmax_depths2 = [1,5,6,7,10,10,11,12,14,15,18,19,20,23,25,30,35,38,40,42,44,45,50]\n\nfor i in max_depths2:\n    tree_reg2 = DecisionTreeRegressor(max_depth = i)\n    tree_reg2.fit(X_train2,y_train2)\n    \n    y_train_pred_tree2 = tree_reg2.predict(X_train2)\n    rmse_train2 = np.sqrt(mean_squared_error(y_train2, y_train_pred_tree2))\n\n    y_test_pred_tree2 = tree_reg2.predict(X_test2)\n    rmse_test2 = np.sqrt(mean_squared_error(y_test2, y_test_pred_tree2))\n    \n    lista_rmse_train_tree2.append(rmse_train2)\n    lista_rmse_test_tree2.append(rmse_test2)\n    \n\nmin_test_tree2 = np.amin(lista_rmse_test_tree2) #optmizaci\u00f3n\nlista_rmse_test_tree_op2 = lista_rmse_test_tree2.index(min(lista_rmse_test_tree2))\nmax_depths_op2 = max_depths2[lista_rmse_test_tree_op2]\nprint('El m\u00ednimo de RMSE en test es ', min_test_tree2, ' en ', max_depths_op2, ' profundidad del \u00e1rbol.')\n\n\nplt.figure(figsize=(15,5)) #ploteo\nplt.plot(max_depths2, lista_rmse_train_tree2, 'o-', label = 'RMSE train 2')\nplt.plot(max_depths2, lista_rmse_test_tree2, 'o-', label = 'RMSE test 2')\nplt.xlabel('Profundidad del \u00e1rbol [max_depths]', size = 15)\nplt.ylabel('RMSE', size =15)\nplt.title('Rendimiento \u00c1rbol de Decisi\u00f3n con Properati top 3', size = 20)\nplt.scatter(max_depths_op2, min_test_tree2, s=300, marker = '*', \n         label = 'RMSE2 = {} \\nmax_depth = {} '.format(round(min_test_tree2),max_depths_op2), color = 'red')\nplt.legend(loc = 'upper right', fontsize = 15)\nplt.savefig('Arbol2.png')\nplt.show()","553705b5":"\ntree_regressor_2 = DecisionTreeRegressor(max_depth = 44)\ntree_regressor_2.fit(X_train2, y_train2)\ny_train_pred_tree2 = tree_regressor_2.predict(X_train2)\ny_test_pred_tree2 = tree_regressor_2.predict(X_test2)\n\nrmse_train2 = np.sqrt(mean_squared_error(y_train2, y_train_pred_tree2))\nrmse_test2 = np.sqrt(mean_squared_error(y_test2, y_test_pred_tree2))\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Train es de: {rmse_train2}')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Test es de: {rmse_test2}')","8f9b90ec":"lista_rmse_train_knn2 = []\nlista_rmse_test_knn2 = []\nvecinos2 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,25,30,35,40]\n\nfor i in vecinos2:\n    knn_reg = KNeighborsRegressor(n_neighbors = i)\n    knn_reg.fit(X_train2,y_train2)\n    \n    y_train_pred_knn2 = knn_reg.predict(X_train2)\n    rmse_train_knn2 = np.sqrt(mean_squared_error(y_train2, y_train_pred_knn2))\n\n    y_test_pred_knn2 = knn_reg.predict(X_test2)\n    rmse_test_knn2 = np.sqrt(mean_squared_error(y_test2, y_test_pred_knn2))\n    \n    lista_rmse_train_knn2.append(rmse_train_knn2)\n    lista_rmse_test_knn2.append(rmse_test_knn2)\n\nmin_test_knn2 = np.amin(lista_rmse_test_knn2)\nlista_rmse_test_knn_op2 = lista_rmse_test_knn2.index(min(lista_rmse_test_knn2))\nvecinos_op2 = vecinos[lista_rmse_test_knn_op2]\nprint('M\u00ednimo de RMSE en test es ', min_test_knn2,' en vecinos', vecinos_op2)\n\n\nplt.figure(figsize=(15,5))\n\nplt.plot(vecinos2, lista_rmse_train_knn2, 'o-', label = 'RMSE train 2')\nplt.plot(vecinos2, lista_rmse_test_knn2, 'o-', label = 'RMSE test 2')\nplt.xlabel('Cantidad de Vecinos [n_neighbors]', size = 15)\nplt.ylabel('RMSE', size =15)\nplt.title('Rendimiento KNN con properati top 3 ', size = 20)\nplt.scatter(vecinos_op2, min_test_knn2, s=500, marker = '*', \n         label = 'RMSE2 = {} \\nn_neighbors = {} '.format(round(min_test_knn2),vecinos_op2), color = 'red')\nplt.legend(loc = 'center right', fontsize = 15)\nplt.savefig('KNN2.png')\n\nplt.show()","227f1f8f":"\nknn_regressor_2 = KNeighborsRegressor(n_neighbors = 2)\nknn_regressor_2.fit(X_train2, y_train2)\ny_train_pred_knn2 = knn_regressor_2.predict(X_train2)\ny_test_pred_knn2 = knn_regressor_2.predict(X_test2)\nrmse_train_knn2 = np.sqrt(mean_squared_error(y_train2, y_train_pred_knn2))\nrmse_test_knn2 = np.sqrt(mean_squared_error(y_test2, y_test_pred_knn2))\n\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Train es de: {rmse_train_knn2}')\nprint(f'La ra\u00edz del error cuadr\u00e1tico medio en Test es de: {rmse_test_knn2}')\n","635c30bd":"modelos = ['\u00c1rbol de Decisi\u00f3n 2', 'Vecinos m\u00e1s cercanos - KNN 2', 'Regresi\u00f3n Lineal 2',]\n\nfor i, model in enumerate([tree_regressor_2, knn_regressor_2, linear_model_2]):\n    y_train_pred2 = model.predict(X_train2)\n    y_test_pred2 = model.predict(X_test2)\n    \n    print(f'Modelo: {modelos[i]}')\n    rmse_train2 = np.sqrt(mean_squared_error(y_train2, y_train_pred2))\n    rmse_test2 = np.sqrt(mean_squared_error(y_test2, y_test_pred2))\n    print(f'Ra\u00edz del error cuadr\u00e1tico medio en Train: {rmse_train2}')\n    print(f'Ra\u00edz del error cuadr\u00e1tico medio en Test: {rmse_test2} \\n')\n    \n    plt.figure(figsize = (15,4))\n\n    plt.subplot(1,2,1)\n    sns.distplot(y_train2 - y_train_pred2, bins = 20, label = 'train')\n    sns.distplot(y_test2 - y_test_pred2, bins = 20, label = 'test')\n    plt.xlabel('Errores')\n    plt.legend()\n\n\n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test2,y_test_pred2, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  \n    np.max([ax.get_xlim(), ax.get_ylim()]), \n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","98665947":"plt.figure(figsize=(20,10))\n\nplt.plot(max_depths, list_rmse_train_tree, 'o-', label = 'Train consigna')\nplt.plot(max_depths, list_rmse_test_tree, 'o-', label = 'Test consigna')\nplt.xlabel('Profundidad del \u00e1rbol [max_depths]', size = 15)\nplt.ylabel('RMSE', size =15)\nplt.scatter(max_depths_op, min_test_tree, s=300, marker = '*', \n         label = 'RMSE consigna= {} \\nmax_depth = {} '.format(round(min_test_tree),max_depths_op), color = 'orange')\nplt.plot(max_depths2, lista_rmse_train_tree2, 'o-', label = 'Train2 personal')\nplt.plot(max_depths2, lista_rmse_test_tree2, 'o-', label = 'Test2 personal')\nplt.xlabel('Profundidad del \u00e1rbol [max_depths]', size = 15)\nplt.ylabel('RMSE', size =15)\nplt.scatter(max_depths_op2, min_test_tree2,s=300, marker = '*', \n         label = 'RMSE2 personal = {} \\nmax_depth = {} '.format(round(min_test_tree2),max_depths_op2), color = 'red')\nplt.legend(loc = 'upper right', fontsize = 12)\nplt.title('Comparaci\u00f3n del Modelo \u00c1rbol - datasets Consigna vs. Personal ', size = 20)\n\nplt.savefig('Arbolvs.png')\nplt.show()\n\nprint('El modelo Personal muestra una disminuci\u00f3n de errores RMSE del ', round(((min_test_tree-min_test_tree2)\/min_test_tree)*100,2),'%')","e7d03f72":"Podemos observar que existe una diferencia abismal entre el cuartil 75% y el maximo asi que miraremos mas profundo  ","665ee861":"Obtengo un RMSE mayor al del modelo de arbol de decision , no obstante descubro que mi numero de vecinos ideal es 3 asi que entreno y guardo el modelo","74689d08":"Luego creo una nueva columna llama price_m2 para hacer la comparacion mas precisa comparando el precio por metro cuadrado de cada propiedad de los distintos barrios","a24081e6":"-----------Me parece que una manera de valuar las propiedades tiene que ver con usar los datos de precios de las propiedades aleda\u00f1as, evolucion de sus precios a traves del tiempo, y sus caracteristicas principales, ademas pordria ser util saber si en la zona se estan construyendo lugares de interes que puedan valorizar las propiedades de la zona.---\nlas dimensiones\namenidades de la propiedad\nzona\ncuanto tiempo lleva el anuncio y si se vendio o no y en que precio ademas de la variacion del mismo (si es que hubo)\n\n<br \/>\n<br \/>\n\n# RESPONDER SECCI\u00d3N 1 ANTES DE CONTINUAR\n<br \/>\n<br \/>\n\n---","1a965d74":"Volvemos a observar los valores minimos para ver si existe alguna otra irregularidad\n","555ea60e":"Despues del previo analisis puedo inferir que currency, operation_type y l1 tienen un solo valor para todas las publicaciones, lat y lon no seran tomadas en cuenta,asi como las fechas de publicacion y por ultimo como solo usaremos publicaciones de Capital Federal l2 ya no es necesario","fbd80a77":"Luego filtro aquellas columnas que me serviran para responder a mi pregunta","b7938063":"UTILIZAREMOS LA METRICA RMSE PARA EVALUAR EL MODELO PUESTO QUE ES EL ESTANDAR PARA ESTE TIPO DE REGRESION QUE TRATA DE PREDECIR PRECIOS ,ELIMINANDO OUTLIERS, ENTONCES MIENTRAS MENOR SEA NUESTRO RMSE MEJOR SERA NUESTRO MODELO","99cd95f7":"PROCEDO A UTILIZAR PROPERATI TOP 3 COMO MI DATASET PARA EL MODELADO DE ML","76de5bfd":"Ahora bien podemos plantear una mejor metodologia, como entendimos anteriormente el precio es determinado por la superficie y tambien otras variables importantes en el rubro inmobiliario son el tipo de propiedad y su ubicaci\u00f3n. Por este motivo, intentar\u00e9 entrenar los modelos con el dataset trabajado personalmente en la consigna anterior, al cual llame properati_top3. Adem\u00e1s, antes debo convertir \u00e9stas variables categoricas que destaque como importantes, en valores num\u00e9ricos para que puedan ser aplicadas a los modelos regresivos, para ello aplicar\u00e9 las variables dummy modificando el dataset personal en los atributos property_type (Casa, Departamento y PH) y l3 de Capital Federal.","5a4bf9fe":"Se puede observar que tanto Departamento , Casa y PH son los mas abundantes dentro de los listings, sacando diferencias de mas de 10x los demas tipos de propiedades\n","d30d5b80":"Creo la tabla que muestra los 5 barrios mas baratos para comprar una propiedad en Bs As","99e3b529":"Primero marcamos un modelo de regresion lineal como benchmark para nuestro punto de partida","e99ba299":"puedo observar que las propiedades con mas de 5 ba\u00f1os representan un porcentaje infimo del dataset y podria afectar nuestro modelo asi que procedo a filtrarlos\n","a15ec581":"4. \u00bfDe qu\u00e9 regiones son las publicaciones? Haz gr\u00e1ficos de barras para las variables `l2` y `l3`. Si te animas, puedes hacer los dos gr\u00e1ficos usando `subplot` de Matplotlib. Dale un tama\u00f1o apropiado a la figura para que ambos gr\u00e1ficos se visualicen correctamente.","5f31b6db":"fiteo los datos y entreno y predigo el modelo","83b808ef":"# Proyecto: An\u00e1lisis de mercado inmobiliario\n\n\u00a1Bienvenido\/a al primer proyecto de la carrera de Data Science de Acamica! \n\nEl objetivo de este proyecto es reproducir los pasos que har\u00eda un\/a Data Scientist cuando se enfrenta a una problem\u00e1tica real. Por eso, consta de tres secciones:\n* En la Parte 1, te presentamos la problem\u00e1tica sobre la cual vas a trabajar. En esta secci\u00f3n deber\u00e1s decidir qu\u00e9 datos te ayudar\u00e1n a trabajar en este problema y d\u00f3nde puedes conseguirlos.\n* En la Parte 2 te proveemos de un dataset para abordar la problem\u00e1tica planteada. Deber\u00e1s realizar un An\u00e1lisis Exploratorio de Datos sobre este dataset.\n* En la Parte 3, deber\u00e1s utilizar herramientas de Machine Learning para predecir la variable de inter\u00e9s.\n\n\nEn este proyecto vas a trabajar con un dataset de propiedades en venta publicado en el portal [Properati](www.properati.com.ar).\n\n**Importante:** recuerda que un notebook es un informe, por lo que debes ir explicando lo que haces a medida que resuelves las consignas. Es importante que quien que lo lea entienda el flujo de trabajo, qu\u00e9 quisiste hacer. Recuerda, simple y conciso es una combinaci\u00f3n ganadora. \n\n## Problema\n\nRecientemente te has incorporado al equipo de Datos de una gran inmobiliaria. La primera tarea que se te asigna es ayudar a los tasadores\/as a valuar las propiedades, ya que es un proceso dif\u00edcil y, a veces, subjetivo. Para ello, propones crear un modelo de Machine Learning que, dadas ciertas caracter\u00edsticas de la propiedad, prediga su precio de venta.\n\n### 1. Pensando como un\/a Data Scientist\n\nResponde la siguientes pregunta:\n1. \u00bfQu\u00e9 datos crees que te ayudar\u00edan a trabajar en el problema?\u00bfPor qu\u00e9?\n\n**Importante**: NO deber\u00e1s buscar esos datos, solamente justificar qu\u00e9 informaci\u00f3n crees que te ayudar\u00eda a resolver la problem\u00e1tica planteada.","51e4b067":"Para predecir el precio que tiene una media de 260.000 usd, veo que es un modelo muy general y con muy poca precisi\u00f3n.","d793e590":"### 3. Machine Learning\n\nEn esta secci\u00f3n, debes entrenar dos modelos de Machine Learning - uno de vecinos m\u00e1s cercanos y otro de \u00e1rboles de decisi\u00f3n -  para predecir el precio de las propiedades tipo `Departamento`, `PH` y `Casa`  en la Ciudad Aut\u00f3noma de Buenos Aires (`Capital Federal`). Para ello, no debes olvidarte de:\n\n* Elegir una m\u00e9trica apropiada para evaluar los resultados de los modelos.\n* Seleccionar las variables predictoras (`X`) y la variable a predecir (`y`). \n* Realizar un Train\/Test split de los datos.\n* Generar un modelo *benchmark* y evaluarlo.\n* Entrenar un modelo de vecinos m\u00e1s cercanos y un modelo de \u00e1rbol de decisi\u00f3n con hiperpar\u00e1metros iniciales de su elecci\u00f3n.\n* Evaluar los modelos obtenidos. Para ello, eval\u00faa la m\u00e9trica elegida en el conjunto de Test y en el conjunto de Train. Tambi\u00e9n, realiza gr\u00e1ficos de valores reales vs. valores predichos.\n* Mejorar el desempe\u00f1o de sus modelos optimizando el n\u00famero de vecinos y la profundidad del \u00e1rbol, respectivamente.\n* Entre los modelos entrenados, \u00bfcu\u00e1l elegir\u00edas para utilizar?\u00bfPor qu\u00e9? \n* Ser **cr\u00edtico\/a** con la metodolog\u00eda utilizada. Por ejemplo, responde las siguientes preguntas: \u00bfQu\u00e9 informaci\u00f3n no est\u00e1s usando que podr\u00eda ayudar al modelo?\u00bfQu\u00e9 informaci\u00f3n puede estar dem\u00e1s o repetida?\n\nEstos lineamientos corresponden al **m\u00ednimo entregable** de esta secci\u00f3n.\n\n\n**Importante:** para asegurarnos que trabajes con un dataset apropiados, debes volver a cargar los datos y realizar el siguiente filtrado:\n\n1. Selecciona aquellas propiedades en Capital Federal y cuyo tipo de propiedad es Departamento, PH o Casa.\n1. Selecciona aquellas propiedades cuya superficie total es menor a 1000 m2 y mayor a 15 m2.\n1. Selecciona aquellas propiedades cuya precio es menor 4000000 d\u00f3lares.\n1. Selecciona las columnas `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered` y `price`.\n1. Descarta aquellas instacias con valores faltantes.\n\n**Checkpoint:** deber\u00edas obtener un dataset con 81019 instacias y 6 columnas.","a2da8855":"\n**PROCEDEMOS A ESTUDIAR LA DISTRIBUCION DE SURFACE TOTAL**","41089626":"7. **Correlaciones:** Estudia la correlaci\u00f3n entre las variables `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered`, `price`. \u00bfCu\u00e1les son las mejores variables para predecir el precio?\u00bfQu\u00e9 diferencias encuentras seg\u00fan cada tipo de propiedad?","56d3819c":"FIltramos como pide la orden","dd1ec39a":"Al observar los titulos de aquellas propiedades con mas de 7 cuartos puedo ver que existen muchos errores como ser listings ofreciendo hostales, centros medicos, viviendas multi familiares, e incluso mas de 1 departamento listado en una sola instancia, es por eso que procedere a tomar en cuenta solo aquellas propiedades con 7 rooms o menos","463e70ed":"\n-A partir de los valores de correlaci\u00f3n vistos en la tabla y analizando el pairplot, se puede ver que las mejores variables para predecir el precio son surface_total y surface_covered por ser de 0.74 y 0.76 respectivamente\n-la correlacion entre bedrooms y rooms es demasiado alta puede ser una multicolinealidad, que podria perjudicar el modelo\n-Tambien se puede apreciar una correlacion numero de ba\u00f1os y el precio de 0.64 podria ser util potencialmente\n\nPara visualizar mejor la diferencia entre los distintos tipos de propiedades procedemos a visualizar las correlaciones por tipo de propiedad\n","ff56acc3":"### 2.1 Desaf\u00edo\n\nEn el dataset provisto hay mucha informaci\u00f3n, m\u00e1s all\u00e1 del problema planteado. Propone una pregunta que pueda ser respondida por el dataset e intenta responderla.\u00bfCu\u00e1les son los sesgos de la respuesta obtenida?(\u00bfCu\u00e1n generalizable es la respuesta obtenida?)\u00bfNecesitas informaci\u00f3n complementaria?\u00bfC\u00f3mo la obtendr\u00edas?\n\nPor ejemplo: \u00bfCu\u00e1l es el barrio m\u00e1s caro de Buenos Aires? Probablemente puedas responder esta pregunta con este dataset. Pero podria ocurrir que la respuesta est\u00e9 sesgada. \u00bfC\u00f3mo? Tal vez las propiedades m\u00e1s caras no se publican de forma online, sino que utilizan otro canal de venta.\n","366d66dc":"A simple vista se puede inferir que la mayoria de las listings se encuentran en la capital federal.\nAdemas en las cantidades de publicaciones por barrio, se destaca que de los 7 con m\u00e1s publicaciones, 6 pertenecen a Capital Federal , lo cual era esperable teniendo en cuenta los gr\u00e1ficos anteriores.","bdb8e179":"Ahora para evaluarlo vamos a obtener el RMSE, para ello obtenemos el mean_squared_error y luego su ra\u00edz cuadrada:","0d668402":"### 2. An\u00e1lisis Exploratorio de Datos\n\nEn esta secci\u00f3n, debes realizar un An\u00e1lisis Exploratorio de Datos sobre el dataset de propiedades de Properati. Es importante que respondas las siguientes preguntas durante el an\u00e1lisis:\n\n* \u00bfQu\u00e9 tama\u00f1o tiene el dataset?\u00bfCu\u00e1ntas instancias y cu\u00e1ntas columnas?\n* \u00bfCu\u00e1ntos valores faltantes hay en cada columna?\n* \u00bfC\u00f3mo es la distribuci\u00f3n de cada variable? Deber\u00e1s hacer histogramas para las variables num\u00e9ricas y gr\u00e1ficos de barras para las variables categ\u00f3ricas.\n* \u00bfC\u00f3mo se relacionan las variables entre s\u00ed?\u00bfQu\u00e9 tipo de gr\u00e1fico ser\u00e1 conveniente para presentar esta informaci\u00f3n?\n* \u00bfC\u00f3mo est\u00e1n correlacionadas las variables num\u00e9ricas?\u00bfQu\u00e9 tipo de gr\u00e1fico ser\u00e1 conveniente para presentar esta informaci\u00f3n?\u00bfCu\u00e1les ser\u00e1n los mejores predictores de la variable de inter\u00e9s?\n\nVas a encontrar instrucciones para responder estas preguntas. Es importante aclarar que estas instrucciones corresponden al **m\u00ednimo entregable** que esperamos en la consigna.\n\n**Comentarios sobre el dataset** \n1. Nosotros ya hicimos un *curado* sobre el dataset que puedes descargar directamente de la p\u00e1gina de Properati. Muchos de los pasos que hicimos para curar el conjunto de datos los veremos durante el Bloque 2 de la carrera.\n\n2. Si tienes dudas sobre qu\u00e9 representa alguna de las columnas, puedes consultar [aqu\u00ed](https:\/\/www.properati.com.ar\/data\/). Notar\u00e1s que algunas columnas fueron descartadas.\n\n3. `Capital Federal` refiere a la Ciudad de Buenos Aires. `Bs.As. G.B.A. Zona Norte`, `Bs.As. G.B.A. Zona Sur` y `Bs.As. G.B.A. Zona Oeste` son regiones que conforman el [Gran Buenos Aires](https:\/\/es.wikipedia.org\/wiki\/Gran_Buenos_Aires), un conjunto de ciudades que rodean a la Ciudad de Buenos Aires.\n\n","f396eb58":"Tambien noto que, falta entender el manejo de outliers con m\u00e1s determinaci\u00f3n y\/o contar con m\u00e1s herramientas que nos ayuden a hacer un recorte lo m\u00e1s cercano a la 'objetividad'.","0a8379c6":"1. Carga el dataset usando las funcionalidades de Pandas. Imprimir cu\u00e1ntas filas y columnas tiene, y sus cinco primeras instancias.","a3b94c1c":"A SIMPLE VISTA PODEMOS VER QUE ESTOS MARGENES DE ERROR SON MUCHO MEJORES QUE EL MODELO SUGERIDO POR LA CONSIGNA","a6341e7e":"Ahora, mediante un loop for, crearemos listas de los diferentes errores segun la profundidad del \u00e1rbol, \u00e9sto lo haremos para poder medir d\u00f3nde es el punto del arbol que es m\u00e1s efectivo y contenga menos errores.","831e1b61":"Luego de Probar mi data set personal, y al correr de nuevo los modelos de ML llegue a la conclusion de que los resultados del best performer (arbol de decision) presenta una mejora de 69% con relacion a los parametros sugeridos por la consigna, aunque sigue siendo alto 45426 USD para esta industria en especifico, queda abierto a mejoras con mejores herramientas, manejo de outliers e ingenieria de features\n","505227ac":"Contin\u00fao ahora otimizando KNN con los datos personales:","022a912f":"Se puede evindeciar la presencia de los outliers en la variable superficie total, procedemos a filtrar por cuantiles 0.95\n","71ef4375":"Como primer paso uso .describe() para tener una primer pantallazo de las estad\u00edsticas de cada feature.\n\n\n*   Las medias estan demasiado alejadas de los maximos valores lo que indica que tenemos que filtrar outliers\n*   Podemos inferir que existen errores puesto que en valores minimos de dormitorios (0) y surface covered (1) no tendria sentido si es que hablamos de los top 3 tipos de propiedades\n*   Se observa que no todas las features tienen la misma cantidad de instancias, en algunas features bordeando las 10000 instancias de diferencia\n*   Las columnas de lat y lon no van a ser analizadas posteriormente por lo que puedo descartar esta informaci\u00f3n\n*   se infiere que existen errores o outliers en la columna bedrooms con un maximo de 26, el cual parece descabellado a simple vista\n* se infiere que existen errores o outliers en la columna bathrooms con un maximo de 14, el cual parece descabellado a simple vista\n\n\n\n\n\n","3ea773b6":"3. **Tipos de propiedad**: \u00bfCu\u00e1ntos tipos de propiedad hay publicados seg\u00fan este dataset?\u00bfCu\u00e1ntos instancias por cada tipo de propiedad hay en el dataset? Responde esta pregunta usando las funcionalidad de Pandas y con un gr\u00e1fico apropiado de Seaborn. **Pistas**: Te puede ser \u00fatil googlear c\u00f3mo rotar las etiquetas del eje x.","137a99d9":"Entrenaremos un arbol de regresion","edab502a":"0. Importa las librer\u00edas necesarias para trabajar en la consigna.","3931b1df":"lt5. **Filtrando el Dataset:** A partir de los resultados del punto 3. y 4., selecciona las tres clases m\u00e1s abundantes de tipos de propiedad y la regi\u00f3n con m\u00e1s propiedades publicadas. Crea un nuevo Data Frame con aquellas instancias que cumplen con esas condiciones e imprime su `shape`.","b2e6157c":"Se observa que existen instancias con Nan en la columna bathrooms, lo cual me lleva a pensar que no son departamentos como estarian listados originalmente, asi mismo se puede deber a los listings que son solamente cocheras , es por esto que filtrare todas aquellas instancias con surface total menores que 20 para asegurarme de que por lo menos son mono ambientes muy peque\u00f1os","80828fe3":"Aqui podemos notar que depues de 180m2 aproximadamente comienzas los outliers es por eso que los filtraremos","8798a28e":"Contamos con una cantidad razonable de outliers, procedemos a estudiar los valores mas bajos de superficie total, PUESTO QUE EXISTIAN VALORES MINIMOS DE 10M2\n","53003c20":"Luego de \u00e9ste primer recorrido observando los valores de RMSE obtenidos a partir de los modelos con los hiperpar\u00e1metros optimizados de los datos de la consigna, se puede ver que los errores son excesivamente altos de 148371 USD (en el modelo mejor desempe\u00f1ado \u00c1rbol de Decisi\u00f3n) teniendo en cuenta la media de la variable price que es de 260.000 USD aproximadamente. Sin embargo, en estas comparaciones podemos remarcar nuevamente que el modelo que mejor se desempe\u00f1\u00f3 fue el \u00c1rbol de Decisi\u00f3n ya que tiene el menor RMSE en test de los tres modelos probados aqu\u00ed y la Regresi\u00f3n Lineal tuvo el peor desempe\u00f1o.\n\nNo obstante al hacer el analisis exploratorio de los datos pudimos darnos cuenta que existen otras variables que podrian ser un mejor fit para nuestros modelos como ser surface, bedrooms, o ubicaciones.\n\nAdemas queda pendiente utilizar mi dataset filtrado para ver si mejora o empeora los resultados asi como tambien aprender sobre metodos mas precisos de filtrado de datos para optimizar el analisis exploratorio y asi minimizar los errores al filtrar, puesto que en este proyecto utilice los filtros de cuantiles al ojo y no asi una ciencia exacta","6877f558":"Como se puede notar existen instancias en las cuales surface covered es mayor que surface total, lo cual no tiene sentido, asi que proceso a eliminar esta clase de errores\n","02f233c4":"\n2. **Valores Faltantes**: imprime en pantalla los nombres de las columnas y cu\u00e1ntos valores faltantes hay por columna.","561cce0a":"separamos el data set en entrenamiento (70%) y un conjunto de test (30%).","2bda2842":"Me propongo a encontrar los 5 barrios mas caros y mas baratos de Buenos Aires, primero creo un data frame para este desafio","30fa8ab3":"Creo la tabla que muestra los 5 barrios mas caros para comprar una propiedad en Bs As","e27299d3":"Ahora que las superficies totales estan filtradas correctamente, pasamos a revisar los precios","a0712a11":"A simple vista se puede inferir que surface total and covered siguen siendo las variables mas significativas para predecir el precio, aunque en menos proporcion para las casas, no obstante tambien el numero de ba\u00f1os toma un valor importante","1fc52927":"PROCEDO A SACAR EL REGRESOR LINEAL PARA USARLO COMO BENCHMARK","ef6fac4c":"Los errores disminuyeron aunque siguen altos a comparacion de la media de precio usd","a40fb3d5":"Se nota que los errores bajaron en el modelo Test.Pero claramente sus valores de error en precio siguen siendo demasiado altos para los n\u00fameros de precios USD que manejamos.","dfbe8119":"#Procedemos a estudiar las relaciones y correlaciones entre las variables restantes para definir cuales nos seran utiles para nuestros modelos de ML","24a7e0b2":"Calculo RMSE:","57d62332":"Claramento los errores siguen demasiado altos como para usar este modelo para un cliente real","9312029c":"Creo un loop de posibilidades para optimizar el modelo al igual que en el arbol","8cbb9069":"Se ve que existen bastantes valores extremos que dificultan las visualizacion, asi como el manejo del dataset.\nProbamos con el cuantil 0.99","e5671dcf":"\nLos modelos con el dataset personal mostraron un desempe\u00f1o superior con los modelos de la consigna, hay una gran diferencia de errores y en este caso tambi\u00e9n, el mejor desempe\u00f1o lo muestra nuevamente el \u00c1rbol de Decisi\u00f3n.\n","c889251c":"**Checkpoint:** deber\u00edas tener un dataset con 91485 instacias, 19 columnas.\n\n6. **Distribuciones y relaciones de a pares:** Estudia la distribuci\u00f3n y las relaciones de a pares de las variables `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered`, `price` para cada tipo de propiedad. Para ello, ten en cuenta:\n    1. Obtiene estad\u00edsticos que te sirvan para tener una primera idea de los valores que abarcan estas variables. \u00bfCu\u00e1les crees que toman valores que tal vez no tengan mucho sentido?\n    1. Algunas instancias tienen valores de superficie (`surface_total`) muy grandes y dificultan la correcta visualizaci\u00f3n. Estudia la distribuci\u00f3n de esa variable y filtra por un valor razonable que te permita obtener gr\u00e1ficos comprensibles. Puede ser \u00fatil un boxplot para determinar un rango razonable.\n    1. Lo mismo ocurre con valores de superficie total muy chico.\n    1. Las propiedades no pueden tener `surface_covered` mayor a `surface_total`. Si eso sucede, debes filtrar esas instancias.\n    1. El rango de precios que toman las propiedades es muy amplio. Estudia la distribuci\u00f3n de esa variable y filtra por un valor razonable que te permita obtener gr\u00e1ficos comprensibles. Puede ser \u00fatil un boxplot para determinar un rango razonable.\n    1. Una vez filtrado el dataset, puedes utilizar la funci\u00f3n `pairplot` de Seaborn.","e342b0be":"**COMPLETA EN ESTA CELDA TU RESPUESTA**","e436bf0f":"AL filtrar el dataset por dormitorios menores que seis vemos que las diferencias entre el cuartil 75% y el max no es tan grande lo que nos lleva a decir que este dataset esta listo para ser modelado","ccb920cb":"Encontramos que 16 es el valor que botiene el error de test menor entre la lista de  parametros que probamos, entonces procedemos a entrenar el modelo con 16\n","e5e47e9f":"sigue habiendo amplia diferencia en bedrooms y bathrooms del cuartil 75% al maximo valor procedo a explorar estas features","5b8cdd93":"Confirmamos que las 3 tipos de propiedades con mayores listings son Departamento, PH y Casa, tambien se puede inferir que PH supera a Casa, esto difiere con el anterior de grafico de tipos de propiedades , lo que quiere decir que la mayoria de los listings de Casas se encuentran fuera de la Capital Federal","e908d303":"Creo un modelo de KNN, optimizando su hiperpar\u00e1metro n_neighbors."}}