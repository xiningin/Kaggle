{"cell_type":{"6a1de769":"code","0e1fd871":"code","988ec490":"code","e6ce78ef":"code","2f81c49d":"code","489ce423":"code","bda55f75":"code","dcf8834d":"markdown","ad9d7797":"markdown","9a1f77c4":"markdown","12de359a":"markdown","1ffa8ce2":"markdown","25642d52":"markdown","15e4da54":"markdown"},"source":{"6a1de769":"import pandas as pd\nimport numpy as np\n\n\nfrom sklearn import ensemble\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn import decomposition\nfrom sklearn import preprocessing\nfrom sklearn import pipeline","0e1fd871":"if __name__ == \"__main__\":\n    df = pd.read_csv(\"..\/input\/mobile_train.csv\")\n    X = df.drop(\"price_range\", axis = 1).values\n    y = df.price_range.values\n    \n    classifier = ensemble.RandomForestClassifier(n_jobs = -1)\n    param_grid = {\n        \"n_esimators\" : [100, 200, 300, 400],\n        \"max_depth\" : [1,3,5,7],\n        \"criterion\" : [\"gini\", \"entropy\"],\n    }\n    model = model_selection.GridSearchCV(\n        estimator = classifier,\n        param_grid = param_grid,\n        scoring = \"accuracy\",\n        verbose = 10,\n        n_jobs = 1,\n        cv = 5,\n    )\n    model.fit(X,y)\n    \n    print(model.best_score_)\n    print(model.best_estimator_.get_params()) ","988ec490":"if __name__ == \"__main__\":\n    df = pd.read_csv(\"..\/input\/mobile_train.csv\")\n    X = df.drop(\"price_range\", axis = 1).values\n    y = df.price_range.values\n    \n    classifier = ensemble.RandomForestClassifier(n_jobs = -1)\n    param_grid = {\n        \"n_esimators\" : np.arange(100, 1500, 100),\n        \"max_depth\" : np.arange(1,20),\n        \"criterion\" : [\"gini\", \"entropy\"],\n    }\n    model = model_selection.RandomizedSearchCV(\n        estimator = classifier,\n        param_distributions = param_grid,\n        scoring = \"accuracy\",\n        n_iter = 10,\n        verbose = 10,\n        n_jobs = 1,\n        cv = 5,\n    )\n    model.fit(X,y)\n    \n    print(model.best_score_)\n    print(model.best_estimator_.get_params()) ","e6ce78ef":"if __name__ == \"__main__\":\n    df = pd.read_csv(\"..\/input\/mobile_train.csv\")\n    X = df.drop(\"price_range\", axis = 1).values\n    y = df.price_range.values\n    \n    scl = preprocessing.StandardScaler()\n    pca = decomposition.PCA()\n    rf = ensemble.RandomForestClassifier(n_jobs = -1)\n    \n    classifer = pipeline.Pipeline([(\"scaling\", scl), (\"pca\", pca), (\"rf\", rf)])\n    \n    param_grid = {\n        \"pca__n_components\" : np.arange(5,10),\n        \"rf__n_esimators\" : np.arange(100, 1500, 100),\n        \"rf__max_depth\" : np.arange(1,20),\n        \"rf__criterion\" : [\"gini\", \"entropy\"],\n    }\n    model = model_selection.RandomizedSearchCV(\n        estimator = classifier,\n        param_distributions = param_grid,\n        scoring = \"accuracy\",\n        n_iter = 10,\n        verbose = 10,\n        n_jobs = 1,\n        cv = 5,\n    )\n    model.fit(X,y)\n    \n    print(model.best_score_)\n    print(model.best_estimator_.get_params()) ","2f81c49d":"from functools import partial\nfrom skopt import space, gp_minimize\ndef optimize(params, param_names, x, y):\n    params = dict(zip(param_names, params))\n    model = ensemble.RandomForestClassifier(**params)\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    accuracies = []\n    for idx in kf.split(X = x, y=y):\n        train_idx, test_idx = idx[0], idx[1]\n        xtrain = x[train_idx]\n        y_train = y[train_idx]\n        \n        xtest = x[test_idx]\n        y_test = y[testin_idx]\n        \n        model.fit(xtrain, ytrain)\n        preds = model.predict(xtest)\n        fold_acc = metrics.accuracy_score(ytest, preds)\n        accuracies.append(fold_acc)\n        \n    return -1.0 * np.mean(accuracies)\n\nif __name__ == \"__main__\":\n    df = pd.read_csv(\"..\/input\/mobile_train.csv\")\n    X = df.drop(\"price_range\", axis = 1).values\n    y = df.price_range.values\n    \n    param_space = [\n        space.Integer(3, 15, name = \"max_depth\"),\n        space.Integer(100, 600, nume = \"n_estimators\"),\n        space.Categorical([\"gini\", \"entropy\"], name = \"criterion\"),\n        space.Real(0.01, 1, prior = \"uniform\", name=\"max_features\"),\n    ]\n    param_names = [\"max_depth\", \"n_estimators\", \"criterion\", \"max_features\"]\n    optimization_function = partial(\n        optimize,\n        param_names = param_names,\n        x = X,\n        y = y\n    )\n    \n    result = gp_minimize(\n        optimization_function,\n        dimensions = param_space,\n        n_calls = 15,\n        n_random_starts = 10,\n        verbose = 10,\n    )\n    \n    print(dict(zip(param_names, result.x)))\n    ","489ce423":"from functools import partial\nfrom skopt import space, gp_minimize\nfrom hyperopt import hp, fmin, tpe, Trails\nfrom hyperopt.pyll.base import scope \n\n\ndef optimize(params, x, y):\n    params = dict(zip(param_names, params))\n    model = ensemble.RandomForestClassifier(**params)\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    accuracies = []\n    for idx in kf.split(X = x, y=y):\n        train_idx, test_idx = idx[0], idx[1]\n        xtrain = x[train_idx]\n        y_train = y[train_idx]\n        \n        xtest = x[test_idx]\n        y_test = y[testin_idx]\n        \n        model.fit(xtrain, ytrain)\n        preds = model.predict(xtest)\n        fold_acc = metrics.accuracy_score(ytest, preds)\n        accuracies.append(fold_acc)\n        \n    return -1.0 * np.mean(accuracies)\n\nif __name__ == \"__main__\":\n    df = pd.read_csv(\"..\/input\/mobile_train.csv\")\n    X = df.drop(\"price_range\", axis = 1).values\n    y = df.price_range.values\n    \n    param_space = {\n        \"max_depth\" : scope.int(hp.quniform(\"max_depth\", 3, 15, 1)),\n        \"n_estimators\" : scope.int(hp.quniform(\"n_estimators\", 100, 600, 1)),\n        \"criterion\" : hp.choice(\"criterion\" , [\"gini\", \"entropy\"]),\n        \"max_features\" : hp.uniform(\"max_features\", 0.01, 1),\n    }\n    optimization_function = partial(\n        optimize,\n        x = X,\n        y = y\n    )\n    \n    trials = Trials()\n    \n    result = fmin(\n        fn = optimization_function,\n        space = param_space,\n        algo = tpe.suggest,\n        max_evals = 15,\n        trials = trials,\n    )\n    \n    print(result)\n    ","bda55f75":"from functools import partial\nfrom skopt import space, gp_minimize\nfrom hyperopt import hp, fmin, tpe, Trails\nfrom hyperopt.pyll.base import scope \nimport optuna\n\n\ndef optimize(trail, x, y):\n    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1500)\n    max_depth = trail.suggest_int(\"max_depth\", 3, 15)\n    max_features = trail.suggest_uniform(\"max_features\", 0.01, 1.0)\n    \n    model = ensemble.RandomForestClassifier(\n        n_estimators = n_estimators,\n        max_depth = max_depth,\n        max_features = max_features,\n        criterion = criterion,\n    )\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    accuracies = []\n    for idx in kf.split(X = x, y=y):\n        train_idx, test_idx = idx[0], idx[1]\n        xtrain = x[train_idx]\n        y_train = y[train_idx]\n        \n        xtest = x[test_idx]\n        y_test = y[testin_idx]\n        \n        model.fit(xtrain, ytrain)\n        preds = model.predict(xtest)\n        fold_acc = metrics.accuracy_score(ytest, preds)\n        accuracies.append(fold_acc)\n        \n    return -1.0 * np.mean(accuracies)\n\nif __name__ == \"__main__\":\n    df = pd.read_csv(\"..\/input\/mobile_train.csv\")\n    X = df.drop(\"price_range\", axis = 1).values\n    y = df.price_range.values\n    optimization_function = partial(optimize, x = X, y = y)\n    \n    study = optuna.create_study(direction= \"minimize\")\n    study.optimize(optimization_function, n_trials = 15)\n    \n    ","dcf8834d":"## Bayesian optimization","ad9d7797":"## GridSearchCV","9a1f77c4":"## RandomizedSearchCV Pipline","12de359a":"## Hyperopt","1ffa8ce2":"# Different Method for HyperParameter Tuning in Machine Learning","25642d52":"## RandomizedSearchCV","15e4da54":"## Optuna "}}