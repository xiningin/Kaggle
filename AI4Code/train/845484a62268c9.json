{"cell_type":{"95158456":"code","511d377b":"code","934a70e6":"code","6faa7c28":"code","afa98f26":"code","2dcf19b7":"code","da1e6050":"code","4d0adb06":"code","e9b6d686":"code","98d42b46":"code","29c84953":"code","cff81185":"code","d19c9d45":"code","d9fc23fa":"code","db925ea8":"code","13ca9921":"code","b5e0de3e":"code","f23b98eb":"code","a9d78b2b":"code","50c9f821":"code","d564d5e1":"code","fb29a394":"code","c2332f34":"code","b00e09bb":"code","38f74b75":"code","6ed6c85c":"markdown","26fa028f":"markdown","9d04756f":"markdown","0512c917":"markdown","e7a896bf":"markdown","3e0d3292":"markdown","5580488a":"markdown","88224f3e":"markdown","bb1d6fe6":"markdown","91ed0233":"markdown","df0cc924":"markdown","fdf31abf":"markdown","c5cda38b":"markdown","094cf53b":"markdown","10baa7f2":"markdown","c5d808ac":"markdown","97baa054":"markdown","5eb521bd":"markdown","16ee6ca0":"markdown","cea2f0a7":"markdown"},"source":{"95158456":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.preprocessing import LabelEncoder\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","511d377b":"data_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndata = pd.concat([data_train, data_test], ignore_index=True, sort=False)","934a70e6":"print(\"Colums: \", data_train.columns.values)\nprint(\"Shape: \", data.shape)\n\n# Missing values\nplt.ylabel(\"Missing values:\")\nplt.plot(pd.DataFrame(data.isnull().sum()))\nplt.show()\nprint(data.isnull().sum())\n\nsns.heatmap(data.isnull(), cbar=False).set_title(\"Missing values heatmap\")\nplt.show()\n","6faa7c28":"pClass_1 = round(\n    (data_train[data_train.Pclass == 1].Survived == 1).value_counts()[1] \/\n    len(data_train[data_train.Pclass == 1]) * 100, 2)\npClass_2 = round(\n    (data_train[data_train.Pclass == 2].Survived == 1).value_counts()[1] \/\n    len(data_train[data_train.Pclass == 2]) * 100, 2)\npClass_3 = round(\n    (data_train[data_train.Pclass == 3].Survived == 1).value_counts()[1] \/\n    len(data_train[data_train.Pclass == 3]) * 100, 2)\n\npClassDf = pd.DataFrame(\n    {\"Survived\": {\"Class 1\": pClass_1,\n                  \"Class 2\": pClass_2,\n                  \"Class 3\": pClass_3},\n     \"Not survived\": {\"Class 1\": 100 - pClass_1,\n                      \"Class 2\": 100 - pClass_2,\n                      \"Class 3\": 100 - pClass_3}})\npClassDf.plot.bar().set_title(\"Survived ~ Class\")\nplt.show()\n\ndata_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","afa98f26":"sex_1 = round(\n    (data_train[data_train.Sex == 'male'].Survived == 1).value_counts()[1] \/\n    len(data_train[data_train.Sex == 'male']) * 100, 2)\nsex_2 = round(\n    (data_train[data_train.Sex == 'female'].Survived == 1).value_counts()[1] \/\n    len(data_train[data_train.Sex == 'female']) * 100, 2)\n\npClassDf = pd.DataFrame(\n    {\"Survived\": {\"Male\": sex_1,\n                  \"Female\": sex_2},\n     \"Not survived\": {\"Male\": 100 - sex_1,\n                      \"Female\": 100 - sex_2}})\npClassDf.plot.bar().set_title(\"Survived ~ Sex\")\nplt.show()\n\ndata_train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","2dcf19b7":"ss = pd.DataFrame()\nss['survived'] = data_train.Survived\nss['sibling_spouse'] = pd.cut(data_train.SibSp, [0, 1, 2, 3, 4, 5, 6, 7, 8], include_lowest=True)\n\nx = sns.countplot(x=\"sibling_spouse\", hue=\"survived\", data=ss, palette=[\"C1\", \"C0\"]).legend(\n    labels=[\"Not survived\", \"Survived\"])\nx.set_title(\"Survival ~ Number of siblings or spouses\")\nplt.show()\n\ndata_train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","da1e6050":"pc = pd.DataFrame()\npc['survived'] = data_train.Survived\npc['parents_children'] = pd.cut(data_train.Parch, [0, 1, 2, 3, 4, 5, 6], include_lowest=True)\nx = sns.countplot(x=\"parents_children\", hue=\"survived\", data=pc, palette=[\"C1\", \"C0\"]).legend(\n    labels=[\"Not survived\", \"Survived\"])\n\nx.set_title(\"Survival ~ Parents\/Children\")\nplt.show()\n\ndata_train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","4d0adb06":"data['AgeRange'] = pd.cut(data.Age, [0, 10, 20, 30, 40, 50, 60, 70, 80])\nsns.countplot(x=\"AgeRange\", hue=\"Survived\", data=data, palette=[\"C1\", \"C0\"]).legend(labels=[\"Not survived\", \"Survived\"])\nplt.show()","e9b6d686":"data['FareCategory'] = pd.cut(data_train['Fare'], bins=[0, 7.90, 14.45, 31.28, 120], labels=['Low', 'Mid',\n                                                                                                    'High_Mid', 'High'])\nx = sns.countplot(x=\"FareCategory\", hue=\"Survived\", data=data, palette=[\"C1\", \"C0\"]).legend(\n    labels=[\"Not survived\", \"Survived\"])\nx.set_title(\"Survival ~ Fare\")","98d42b46":"p = sns.countplot(x=\"Embarked\", hue=\"Survived\", data=data_train, palette=[\"C1\", \"C0\"])\np.set_xticklabels([\"Southampton\", \"Cherbourg\", \"Queenstown\"])\np.legend(labels=[\"Not survived\", \"Survived\"])\np.set_title(\"Survival ~ Embarking.\")","29c84953":"data['Family'] = data.Parch + data.SibSp\ndata['IsAlone'] = data.Family == 0\ndata['SmallFamily'] = data['Family'].map(lambda s: 1 if 1 <= s <= 3 else 0)\ndata['BigFamily'] = data['Family'].map(lambda s: 1 if 4 <= s else 0)","cff81185":"data['Salutation'] = data.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip()) \nprint(data.Salutation.unique())\ndata.Salutation.nunique()","d19c9d45":"dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in data[\"Name\"]]\ndata['Title']=data.Name.apply(lambda x: x.split('.')[0].split(',')[1].strip())\nnewtitles={\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"}\n\ndata['Title']=data.Title.map(newtitles)\n\ndata['Mother'] = (data['Title'] == 'Mrs') & (data['Parch'] > 0)\ndata['Mother'] = data['Mother'].astype(int)","d9fc23fa":"grp = data.groupby(['Sex', 'Pclass', 'Title'])\ndata.Age = grp.Age.apply(lambda x_: x_.fillna(x_.median()))\ndata.Age.fillna(data.Age.median, inplace=True)\n\ndata['AgeRange'] = pd.cut(data['Age'].astype(int), 5)","db925ea8":"data['Ticket_Lett'] = data['Ticket'].apply(lambda x: str(x)[0])\ndata['Ticket_Lett'] = data['Ticket_Lett'].apply(lambda x: str(x))\ndata['Ticket_Lett'] = np.where((data['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), data['Ticket_Lett'],\n                                   np.where((data['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n                                            'Low_ticket', 'Other_ticket'))\ndata['Ticket_Len'] = data['Ticket'].apply(lambda x: len(x))","13ca9921":"data.Fare.fillna(data.Fare.mean(), inplace = True)\n# data['FareCategory'] = pd.qcut(data['Fare'], 4)","b5e0de3e":"data.Embarked.fillna(data.Embarked.mode()[0], inplace = True)","f23b98eb":"data.Cabin.fillna('NA', inplace=True)\n\ndata['Cabin'] = data['Cabin'].map(lambda s: s[0])","a9d78b2b":"\ndata['Title'] = LabelEncoder().fit_transform(data['Title'])\n\ndata = pd.concat([data,\n                pd.get_dummies(data.Cabin, prefix=\"Cabin\"),\n                pd.get_dummies(data.AgeRange, prefix=\"AgeRange\"), \n                pd.get_dummies(data.Embarked, prefix=\"Embarked\", drop_first = True),\n                pd.get_dummies(data.Title, prefix=\"Title\", drop_first = True),\n                pd.get_dummies(data.FareCategory, prefix=\"Fare\", drop_first = True), \n                pd.get_dummies(data.Ticket_Lett, prefix=\"Ticket\", drop_first = True), \n                pd.get_dummies(data.Pclass, prefix=\"Class\", drop_first = True)], axis=1)\n\ndata['IsAlone'] = LabelEncoder().fit_transform(data['IsAlone'])\ndata['Sex'] = LabelEncoder().fit_transform(data['Sex'])\n","50c9f821":"data.drop(['Pclass', 'Fare','Cabin', 'FareCategory','Name','Salutation', 'Ticket_Lett', 'Ticket','Embarked', 'AgeRange', 'SibSp', 'Parch', 'Age'], axis=1, inplace=True)","d564d5e1":"print(\"Colums: \", data.columns.values)","fb29a394":"import sklearn\n\n\n# Prediction\n\nX_pred = data[data.Survived.isnull()].drop(['Survived'], axis=1)\n\n# Training data\n\ntrain_data = data.dropna()\nX = train_data.drop(['Survived'], axis=1)\ny = train_data['Survived']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n","c2332f34":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\n\n\n\nclf = GradientBoostingClassifier(learning_rate=0.1,\n                                 n_estimators=700,\n                                 max_depth=2)\n\nclf.fit(X_train, np.ravel(y_train))\nprint(\"RF Accuracy: \" + repr(round(clf.score(X_test, y_test) * 100, 2)) + \"%\")\n\nresult_rf = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\nprint('The cross validated score for Random forest is:', round(result_rf.mean() * 100, 2))\ny_pred = cross_val_predict(clf, X_train, y_train, cv=5)","b00e09bb":"# Random forest\n# entropy\n# gini\n\nclf = RandomForestClassifier(criterion='entropy',\n                             n_estimators=700,\n                             min_samples_split=5,\n                             min_samples_leaf=1,\n                             max_features = \"auto\",\n                             oob_score=True,\n                             random_state=0,\n                             n_jobs=-1)\n\nclf.fit(X_train, np.ravel(y_train))\nprint(\"RF Accuracy: \" + repr(round(clf.score(X_test, y_test) * 100, 2)) + \"%\")\n\nresult_rf = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\nprint('The cross validated score for Random forest is:', round(result_rf.mean() * 100, 2))\ny_pred = cross_val_predict(clf, X_train, y_train, cv=5)\n","38f74b75":"result = clf.predict(X_pred)\nsubmission = pd.DataFrame({'PassengerId':X_pred.PassengerId,'Survived':result})\nsubmission.Survived = submission.Survived.astype(int)\nprint(submission.shape)\nfilename = 'TitanicPredictions4.csv'\nsubmission.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","6ed6c85c":"# Sex \nDescription","26fa028f":"# Feature Engineering\n\nCategorical:\n\n* Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\n* Numerical: Age, Fare. Discrete: SibSp, Parch.\n* Nullable: Survived, Age, Cabin, Embarked","9d04756f":"# Label encorder","0512c917":"# Naming","e7a896bf":"# Age\nDescription","3e0d3292":"# Fare\nMissing values","5580488a":"# Cabin\nMissing values","88224f3e":"# Ticket","bb1d6fe6":"# Age\nMissing values","91ed0233":"# Embarked\nMissing values","df0cc924":"# Parch\nDescription","fdf31abf":"# SibSp\nDescription","c5cda38b":"# Fare\nDescription","094cf53b":"# Embarked\nDesrcipton","10baa7f2":"# Salutation","c5d808ac":"# Data\n\n**Read data from csv**","97baa054":"# Analyze data\n\n**Describe data**\n\n* look at columns\n* check shape\n* check null columns\n* draw plot graphic to look at nullable data\n* create describing list\n* create heatmap","5eb521bd":"# Family\nDescription","16ee6ca0":"# PClass\nDescription","cea2f0a7":"# Imports\n\n***Using*:**\n* **numpy** for linear algebra\n* **pandas** for data processing\n* **matplotlib** and seaborn for graphics\n* **sklearn** for algorithms\n"}}