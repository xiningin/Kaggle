{"cell_type":{"1bc6d3b0":"code","10f1687d":"code","f9911b1d":"code","0fd34102":"code","6fe6a00b":"code","49394c08":"code","67f82753":"code","cffb06e0":"code","7110ec13":"code","8b580f8a":"code","321b3d08":"code","93440bf1":"code","74938599":"code","50ed0720":"code","56d1d06c":"code","39f1b279":"code","282a335d":"code","0053099c":"code","572fc6c0":"code","d26d1ce6":"code","c4c66439":"code","c1689507":"code","14d927b7":"code","4a136d6e":"code","fc38d521":"code","cebaa7ec":"code","1d55d4fb":"code","2552e544":"code","aab56cbe":"markdown","f10b3744":"markdown","77d8b97c":"markdown","68083797":"markdown","632cc8b9":"markdown","f060eed7":"markdown","9a6dcd41":"markdown","a5076f18":"markdown","10d4a124":"markdown","7c55221e":"markdown","a624f80e":"markdown"},"source":{"1bc6d3b0":"import pandas as pd\nimport nltk\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nimport re\nimport category_encoders as ce\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport pickle","10f1687d":"df_train = pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\", encoding = \"ISO-8859-1\")\ndf_test = pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv\")","f9911b1d":"df_train.head()","0fd34102":"df_test.head()","6fe6a00b":"df_train[\"Sentiment\"].value_counts()","49394c08":"corpus = []\nstemmer = PorterStemmer() \nfor i in range(len(df_train)):\n    review = re.sub('[^a-zA-Z]',\" \",df_train[\"OriginalTweet\"][i])\n    review = review.lower()\n    review = review.split()\n    review = [stemmer.stem(word) for word in review if word.lower() not in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","67f82753":"corpus[1:10]","cffb06e0":"tfidf = TfidfVectorizer(max_features=5000)\nX = tfidf.fit_transform(corpus).toarray()","7110ec13":"def ordinal_encoding(df,col,mapping):\n    ordinal_encoder = ce.OrdinalEncoder(cols = [col],return_df = True,mapping = [{'col':col,'mapping':mapping}])\n    df_final = ordinal_encoder.fit_transform(df)\n    return df_final","8b580f8a":"plot = sns.countplot(x='Sentiment', data=df_train).set_xticklabels(labels=['Neutral', 'Positive', 'Extremely Negative', 'Negative','Extremely Positive'],rotation=20)","321b3d08":"dict = {'Neutral':3, 'Positive':2, 'Extremely Negative':5, 'Negative':4,\n       'Extremely Positive':1}","93440bf1":"df_train_final = ordinal_encoding(df_train,\"Sentiment\",dict)","74938599":"def minimize_categories(val):\n    if val == 1 or val == 2:\n        return 1\n    elif val == 3:\n        return 2\n    elif val == 4 or val == 5:\n        return 3","50ed0720":"df_train_final[\"Sentiment\"] = df_train_final[\"Sentiment\"].apply(minimize_categories)","56d1d06c":"sns.countplot(x='Sentiment', data=df_train_final)","39f1b279":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nimport numpy as npy\nfrom PIL import Image\nimport requests\nimport io\nresponse = requests.get(\"https:\/\/res.cloudinary.com\/maxie\/image\/upload\/v1617197755\/TEMP\/covid_ywd7ph.jpg\")\nimage_bytes = io.BytesIO(response. content)\ndataset = \" \".join(corpus)\ndef create_word_cloud(string):\n\n    maskArray = npy.array(Image.open(image_bytes))\n    cloud = WordCloud(background_color = \"black\", max_words = 150, mask = maskArray, stopwords = set(STOPWORDS),contour_width=1, contour_color='#333')\n    cloud.generate(string)\n#     cloud.to_file(\"wordCloud.png\")\n    return cloud\ndataset = dataset.lower()\nwordcloud=create_word_cloud(dataset)\nplt.figure(figsize=[20,10])\nplt.imshow(wordcloud) # image show\nplt.axis('off') # to off the axis of x and y\nplt.show()","282a335d":"Y = df_train_final[\"Sentiment\"]\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,random_state= 0,stratify =Y)","0053099c":"multinb = MultinomialNB()\nmultinb.fit(X_train,Y_train)","572fc6c0":"Y_pred_multinb = multinb.predict(X_test)","d26d1ce6":"log = LogisticRegression()\nlog.fit(X_train,Y_train)\nY_pred_log = log.predict(X_test)","c4c66439":"accuracy_score(Y_pred_multinb,Y_test)","c1689507":"print(classification_report(Y_pred_multinb,Y_test))","14d927b7":"accuracy_score(Y_pred_log,Y_test)","4a136d6e":"print(classification_report(Y_pred_log,Y_test))","fc38d521":"text = \"T 3590 -I have tested CoviD positive ..  shifted to Hospital  .. hospital informing  authorities .. family and staff undergone tests , results awaited ..All that have been in close proximity to me in the last 10 days are requested to please get themselves tested !\"\n# predict(text)","cebaa7ec":"def preprocess_text(text):\n    corpus = []\n    stemmer = PorterStemmer()\n    review = re.sub('[^a-zA-Z]',\" \",text)\n    review = review.lower()\n    review = review.split()\n    review = [stemmer.stem(word) for word in review if word.lower() not in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)\n    return corpus","1d55d4fb":"corpus = preprocess_text(text)\nX = tfidf.transform(corpus).toarray()\nprediction = log.predict(X)[0]\nif prediction == 1:\n    print(\"Your Tweet is Negative\")\nelif prediction == 2:\n    print(\"Your Tweet is Neutral\")\nelif prediction == 3:\n    print(\"your Tweet is Positive\")","2552e544":"pickle.dump(log,open(\"model_tweet.pkl\",\"wb\"))\npickle.dump(tfidf,open(\"tfidf_tweet.pkl\",\"wb\"))","aab56cbe":"# Importing Packages","f10b3744":"# Data Overview","77d8b97c":"# Evaluation Metrics","68083797":"# Training Models","632cc8b9":"<center><img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRWDgteV-sNXVRkc0xwyodmJt18ImebZ1UcKA&amp;usqp=CAU\"><\/center>","f060eed7":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https:\/\/deepnote.com?utm_source=created-in-deepnote-cell&projectId=0849d265-fb72-44e9-85d2-abe70c414f0a' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image\/svg+xml;base64,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' > <\/img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote<\/span><\/a>","9a6dcd41":"<h1 style=\"color:rgb(0,0,150);font-weight:bold;font-size:2em;text-align:center\">\nCORONAVIRUS TWEETS CLASSIFIER\n<\/h1>\n<center>\n<img\nsrc=\"https:\/\/www.asata.co.za\/wp-content\/uploads\/2020\/03\/corona-4901878_640.jpg\"\nstyle=\"width: 100%\"\/>\n<\/center>\n<br>\n<h3 style=\"font-weight: bold\">Context<\/h3>\n<p>Sentiment analysis studies the subjective information in an expression, that is, the opinions, appraisals, emotions, or attitudes towards a topic, person or entity. Expressions can be classified as positive, negative, or neutral. \n<\/p>\n<h3 style=\"font-weight: bold\">Content<\/h3>\n<p>The dataset contains information about<\/p>\n<ul type=\"square\">\n<li>UserName<\/li>\n<li>ScreenName<\/li>\n<li>Location<\/li>\n<li>TweetAt<\/li>\n<li>OriginalTweet<\/li>\n<li>Sentiment<\/li>\n<\/ul>\n\n<h3 style=\"font-weight: bold\">Contents:<\/h3>\n<ul type=\"square\" style=\"color:blue\">\n<li>Importing Packages<\/li>\n<li>Importing Data<\/li>\n<li>Analysing Data<\/li>\n<li>Data Overview<\/li>\n<li>Visualization<\/li>\n<li>Training Models<\/li>\n<li>Evaluation Metrics<\/li>\n<li>Dumping Model<\/li>\n<\/ul>","a5076f18":"# Analysing Data","10d4a124":"# Visualization","7c55221e":"# Dumping Model","a624f80e":"# Importing Data"}}