{"cell_type":{"795bc40a":"code","fdc6733c":"code","6e01cbd5":"code","911ac1d0":"code","13a391b4":"code","23038f7b":"code","f55b86a7":"code","e7a05f29":"code","2885ce7c":"code","833ecdaf":"code","fe04f267":"code","3004dfc1":"code","8355848b":"code","9a5312fc":"code","57129ebe":"code","ed288d57":"markdown","f4b8d9bb":"markdown","b2a929f1":"markdown","dc4ae37c":"markdown","358e9a96":"markdown","767e6565":"markdown"},"source":{"795bc40a":"import time\n\nfrom tqdm import tqdm\nimport os\nimport time\n\nimport numpy as np\n\nimport nibabel as nib\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, concatenate, Dropout\n\nfrom skimage.transform import resize\nfrom skimage import exposure\nimport cv2 as cv\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.optimizers import Adam\n\nfrom keras.models import Model, load_model\n\n\n","fdc6733c":"def read_image(path):\n    image = nib.load(path)\n    image = (image.dataobj)\n    return np.asarray(image)\n","6e01cbd5":"# 341\ncase = '001'\ncase_path = f'..\/input\/brats20-dataset-training-validation\/BraTS2020_TrainingData\/MICCAI_BraTS2020_TrainingData\/BraTS20_Training_{case}'\n\nimg = np.zeros((128, 128, 155))\nimg = np.asarray(tf.image.resize(read_image(os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii')), (128, 128)))\n\n\npath = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii')\nvol=read_image(path);\nX = np.empty((60, 240, 240))\nY = np.zeros((60, 128, 128, 4))\n\nfor i in range(60):    \n    X[i] = vol[:,:, i+34]\n    \nX[X==4] = 3\nmask = tf.one_hot(X, 4)\nY = tf.image.resize(mask, (128, 128))\nY = np.asarray(Y, dtype = int)\nprint(Y.dtype)","911ac1d0":"plt.figure()\nf, axarr = plt.subplots(1,6, figsize = (18, 50)) \ns = 41\n# img = np.power(img, 2)\nimg = img\/np.max(img)\n\naxarr[0].imshow(X[s], cmap =\"gray\")\naxarr[1].imshow(Y[s,:,:,0], cmap=\"gray\")\naxarr[2].imshow(Y[s,:,:,1], cmap=\"gray\")\naxarr[3].imshow(Y[s,:,:,2], cmap=\"gray\")\naxarr[4].imshow(Y[s,:,:,3], cmap=\"gray\")\naxarr[5].imshow(img[:,:,s+34], cmap=\"gray\")\n\n\n\n","13a391b4":"def dice_coef_loss(y_true, y_pred):\n    ''' Dice Coefficient Loss\n\n    Args:\n        y_true (np.array): Ground Truth Heatmap (Label)\n        y_pred (np.array): Prediction Heatmap\n    '''\n    return 1-dice_coef(y_true, y_pred)","23038f7b":"def dice_coef(y_true, y_pred, smooth=1.0):\n    ''' Dice Coefficient\n\n    Args:\n        y_true (np.array): Ground Truth Heatmap (Label)\n        y_pred (np.array): Prediction Heatmap\n    '''\n\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss \/ class_num\n    return total_loss","f55b86a7":"\n# Build U-Net model\ndropout=0.2\nhn = 'he_normal'\ndef unet():\n    \n    inputs = Input((128, 128, 2)) \n    \n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv3)\n    \n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    model = Model(inputs = inputs, outputs = conv10)\n\n    return model\n\nK.clear_session()\n\nmodel = unet()\nmodel.summary()","e7a05f29":"train_set_path = '..\/input\/brats20-dataset-training-validation\/BraTS2020_TrainingData\/MICCAI_BraTS2020_TrainingData'\npatient_IDs = next(os.walk(train_set_path, topdown=True))[1][:350]\nval_IDs = next(os.walk(train_set_path, topdown=True))[1][350:370]\n\nval_IDs.remove('BraTS20_Training_355')","2885ce7c":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, spatient_IDs, dim=(128,128), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = spatient_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*100, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*100, 240, 240))\n        Y = np.zeros((self.batch_size*100, *self.dim, 4))\n\n\n        \n        # Generate data\n        # for i, ID in enumerate(Batch_ids):\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(train_set_path, i)\n\n            vol_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair =read_image(vol_path)      \n\n            vol_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            ce =read_image(vol_path)\n            \n            vol_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg =read_image(vol_path)\n        \n            for j in range(100):\n                 X[j +100*c,:,:,0] = cv.resize(flair[:,:,j+22], (128, 128));\n                 X[j +100*c,:,:,1] = cv.resize(ce[:,:,j+22], (128, 128));\n\n                 y[j +100*c] = seg[:,:,j+22];\n                    \n            #=============Preprocess masks===========\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (128, 128));\n        return X\/np.max(X), Y\n        \ntraining_generator = DataGenerator(patient_IDs)\nvalid_generator = DataGenerator(val_IDs)\n\n","833ecdaf":"\n\ncallbacks = [\n            # ModelCheckpoint(\"model.h5\", verbose=1, save_best_model=True),\n            ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.1, verbose=1, min_lr=1e-6),\n            EarlyStopping(monitor=\"loss\", patience=3, verbose=1)\n            ]\n\nmodel.compile(optimizer = \"adam\", \n                    loss = 'categorical_crossentropy', \n                    metrics = [\"accuracy\", dice_coef]\n                    ) \n\nresults = model.fit_generator(training_generator,\n                              epochs=30,\n                              steps_per_epoch=len(patient_IDs),  \n                              validation_data = valid_generator,\n                              callbacks= callbacks,\n                              )  ","fe04f267":"plt.plot(results.history['loss'])\nplt.plot(results.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","3004dfc1":"plt.plot(results.history['dice_coef'])\nplt.plot(results.history['val_dice_coef'])\nplt.title('model Dice')\nplt.ylabel('Dice_Coefficient')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n                    wspace=0.35)\nplt.show()","8355848b":"def vol_pred(case_path):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((100, 128, 128, 2))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=read_image(vol_path);\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=read_image(vol_path);   \n\n    \n    for j in range(100):\n         X[j,:,:,0] = cv.resize(flair[:,:,j+22], (128,128))\n         X[j,:,:,1] = cv.resize(ce[:,:,j+22], (128,128))\n    return model.predict(X\/np.max(X), verbose=1)\n\n\ncase = '050'\npath = f\"..\/input\/brats20-dataset-training-validation\/BraTS2020_TrainingData\/MICCAI_BraTS2020_TrainingData\/BraTS20_Training_{case}\"\ngt = read_image(os.path.join(path, f'BraTS20_Training_{case}_seg.nii'))\np = vol_pred(path)","9a5312fc":"\n#p[p >= 0.4] = 1\n#p[p <0.4] = 0\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\n\ns = 40\nplt.figure()\nf, axarr = plt.subplots(1,5, figsize = (18, 50)) \n\naxarr[0].imshow(cv.resize(gt[:,:,s+22], (128, 128)), cmap=\"gray\")\naxarr[1].imshow(p[s,:,:,1:4], cmap=\"gray\")\naxarr[2].imshow(edema[s], cmap=\"gray\")\naxarr[3].imshow(core[s], cmap=\"gray\")\naxarr[4].imshow(enhancing[s], cmap=\"gray\")\n","57129ebe":"model.save_weights('weights.h5')","ed288d57":"**Read sample image&mask**","f4b8d9bb":"**Prepare image paths to feed DataGenerator function**","b2a929f1":"**How to use dataGenerator: https:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly**\n\nHere we train (the middle 100 slice of each volume) per epoch\nSo, Batch size=1 means batch size = 100 slice","dc4ae37c":"**building Unet**\n\n**main source: https:\/\/naomi-fridman.medium.com\/multi-class-image-segmentation-a5cc671e647a **","358e9a96":"**Display t1ce slice and it's mask + processed mask**","767e6565":"**A function to Read .nii images using nibabel**"}}