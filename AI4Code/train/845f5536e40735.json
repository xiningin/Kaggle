{"cell_type":{"34d2aca1":"code","37e105d8":"code","14010151":"code","3f87efc8":"code","29207995":"code","9a9a2b4d":"code","0fe9b581":"code","d35d4da3":"code","59845ef1":"code","9c024cd1":"code","108e0cbe":"code","b5fd341a":"code","acd788a3":"code","4d8b127b":"code","870cdadc":"code","153f5afc":"code","176891d7":"code","6205877e":"code","84109d72":"code","31f45425":"code","3240594a":"code","b7be21ff":"code","2062d9a6":"code","512215e4":"code","058192c4":"code","ef9fa9e8":"code","20cb354b":"code","06f9d7ba":"code","4fd62abb":"code","beef2588":"code","c996d264":"markdown","29f84c38":"markdown","2132fcad":"markdown","33d2c74e":"markdown","007efa89":"markdown","5462ab28":"markdown","aee2b1ae":"markdown","b01e61a6":"markdown","2019e1fb":"markdown","e5690768":"markdown","2cf271a9":"markdown","30a01641":"markdown","8c2bdd02":"markdown","50040f91":"markdown","32f5d692":"markdown","759b2de5":"markdown","7ee64409":"markdown","bc62746d":"markdown"},"source":{"34d2aca1":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt","37e105d8":"adult = pd.read_csv(\"..\/input\/adult-pmr3508\/train_data.csv\", names=[\"Age\",\"Workclass\",\"fnlwgt\",\"Education\",\"Education-Num\",\"Martial Status\",\"Occupation\",\"Relationship\",\"Race\",\"Sex\",\"Capital Gain\",\"Capital Loss\",\"Hour per week\",\"Country\",\"Target\"],sep=r'\\s*,\\s*',engine='python',skiprows=1,na_values=\"?\")","14010151":"testadult = pd.read_csv(\"..\/input\/adult-pmr3508\/test_data.csv\", names=[\"Age\",\"Workclass\",\"fnlwgt\",\"Education\",\"Education-Num\",\"Martial Status\",\"Occupation\",\"Relationship\",\"Race\",\"Sex\",\"Capital Gain\",\"Capital Loss\",\"Hour per week\",\"Country\",\"Target\"],sep=r'\\s*,\\s*',engine='python',skiprows=1,na_values=\"?\")","3f87efc8":"adult.shape","29207995":"adult.head() #Comando para mostrar uma tabela sample de adult\nadult.shape #Comando para mostrar o tamanho da variavel adult\nadult[\"Country\"].value_counts() #Conta o n\u00ba de incidencias dos dados, da coluna Country\nadult[\"Age\"].value_counts().plot(kind=\"bar\") #Plota os dados em grafico de barras\nadult[\"Occupation\"].value_counts().plot(kind=\"bar\")\nadult[\"Education\"].value_counts().plot(kind=\"bar\")","9a9a2b4d":"adult[\"Country\"].value_counts()","0fe9b581":"adult[\"Age\"].value_counts().plot(kind=\"bar\")","d35d4da3":"adult[\"Occupation\"].value_counts().plot(kind=\"bar\")","59845ef1":"adult[\"Education\"].value_counts().plot(kind=\"bar\")","9c024cd1":"adult[\"Relationship\"].value_counts().plot(kind=\"bar\")","108e0cbe":"nadult = adult.dropna() #Comando para retirar as linhas com dados faltantes\nntestadult = testadult.dropna()\n","b5fd341a":"from sklearn.neighbors import KNeighborsClassifier #Importando classificador KNN\nfrom sklearn.model_selection import cross_val_score #Importando teste de valida\u00e7\u00e3o cruzada\nfrom sklearn.metrics import accuracy_score #Importando teste de acur\u00e1cia da base de teste\nfrom sklearn import preprocessing  #importando preprocessamento de dados, para dados strings, como \"Country\" e \"Martial Status\"","acd788a3":"numadult = nadult.apply(preprocessing.LabelEncoder().fit_transform) #Preprocessamento para transformar dados n\u00e3o-numericos em dados numericos\nnumtestadult = ntestadult.apply(preprocessing.LabelEncoder().fit_transform)\n\nXadult = numadult[[\"Age\",\"Workclass\",\"Education-Num\",\"Martial Status\",\"Occupation\",\"Relationship\",\"Race\",\"Sex\",\"Capital Gain\",\"Capital Loss\",\"Hour per week\",\"Country\"]]\nYadult = numadult.Target\nXtestadult = numtestadult[[\"Age\",\"Workclass\",\"Education-Num\",\"Martial Status\",\"Occupation\",\"Relationship\",\"Race\",\"Sex\",\"Capital Gain\",\"Capital Loss\",\"Hour per week\",\"Country\"]]\nYtestadult = numtestadult.Target","4d8b127b":"knn = KNeighborsClassifier(n_neighbors=28)","870cdadc":"scores = cross_val_score(knn,Xadult,Yadult,cv=10)","153f5afc":"print(scores)","176891d7":"knn.fit(Xadult,Yadult) #Treinando o classificador com os dados de treino\nYtestpred = knn.predict(Xtestadult) #Prevendo rotulos da base de teste, usando o classificador","6205877e":"pred = []; #lista utilizada para passar os dados de YtestPred, que est\u00e3o escritos em 0 ou 1, para <=50K e >50K\nfor i in range(len(Ytestpred)-1):\n    pred.append(0)\n    if Ytestpred[i] == 0:\n        pred[i] = \"<=50K\"\n    elif Ytestpred[i] == 1:\n        pred[i] = \">50K\"\npred","84109d72":"from sklearn.neural_network import MLPClassifier #importa o modelo.\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score #importa m\u00e9tricas de avalia\u00e7\u00e3o\n","31f45425":"mlp_model = MLPClassifier() #cria o modelo. Os Hiperpar\u00e2metros dos classificador ser\u00e3o o default\nprint(mlp_model)\nmlp_model.fit(Xadult, Yadult) #treina o modelo\nYtestpredMLP = mlp_model.predict(Xtestadult) #predi\u00e7\u00e3o do conjunto de testes","3240594a":"print(\"-------Confusion Matrix------- \\n\", confusion_matrix(Ytestpred, YtestpredMLP))\n","b7be21ff":"print('-----Classification Report----- \\n', classification_report(Ytestpred, YtestpredMLP))\nprint('Accuracy Score of MLP, compared to KNN: ', accuracy_score(Ytestpred, YtestpredMLP))","2062d9a6":"print(accuracy_score(Ytestpred, YtestpredMLP))","512215e4":"from sklearn.ensemble import GradientBoostingClassifier","058192c4":"lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n\nfor learning_rate in lr_list:\n    gbc_model = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, random_state=0)\n    gbc_model.fit(Xadult, Yadult)\n    \n    print(\"Learning Rate: \", learning_rate)\n    print(\"Accuracy Score (training): {0:.3F}\".format(gbc_model.score(Xadult, Yadult)))\n    print(\"Accuracy Score (validation with KNN): {0:.3F}\".format(gbc_model.score(Xtestadult, Ytestpred)))\n    print(\"\\n\")\n","ef9fa9e8":"gbc_model2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.05, random_state=0)\ngbc_model2.fit(Xadult, Yadult)\nYtestpredGBC = gbc_model2.predict(Xtestadult)","20cb354b":"print(\"-------Confusion Matrix------- \\n\", confusion_matrix(Ytestpred, YtestpredGBC))","06f9d7ba":"print('-----Classification Report----- \\n', classification_report(Ytestpred, YtestpredGBC))\nprint('Accuracy Score of MLP, compared to KNN: ', accuracy_score(Ytestpred, YtestpredGBC))","4fd62abb":"print(\"-------Confusion Matrix------- \\n\", confusion_matrix(YtestpredMLP, YtestpredGBC))","beef2588":"print('-----Classification Report----- \\n', classification_report(YtestpredMLP, YtestpredGBC))\nprint('Accuracy Score of MLP, compared to KNN: ', accuracy_score(YtestpredMLP, YtestpredGBC))","c996d264":"O tempo de processamento do classificador Boosting foi de 6 segundos. Nota-se que ele possui vantagem superior de tempo de processamento, quando comparado ao MLP e ao KNN. Entretanto, a classifica\u00e7\u00e3o do GBC diferiu muito do KNN, como observador pela matriz de confus\u00e3o. As classifica\u00e7\u00f5es de renda >50k foram diferentes em ambos, com apenas uma classifica\u00e7\u00e3o semelhante.\n\n\nRealizando os mesmos testes, comparando agora os classificadores MLP e GBC:","29f84c38":"1) Preprocessamento e prepara\u00e7\u00e3o dos dados para classificador, com conjunto de melhor resultado (do primeiro exerc\u00edcio)","2132fcad":"An\u00e1lise de Dados:","33d2c74e":"1) Predi\u00e7\u00e3o dos dados da base de teste","007efa89":"PMR3508-Aprendizado de M\u00e1quina - Exerc\u00edcio Pr\u00e1tico 2\n\nAutor: Daniel dos Santos Hil\u00e1rio       N\u00baUSP: 98364696","5462ab28":"2) Medidas de desempenho\n   Ser\u00e3o realizadas medidas de desempenho para comparar os m\u00e9todos de KNN com o de Redes Neurais por MLP. \n   Essas medidas ser\u00e3o a matriz de confus\u00e3o, junto com as m\u00e9tricas derivada dessa matriz. \n   Ser\u00e1 calculada, tamb\u00e9m, a acur\u00e1cia (accuracy score)","aee2b1ae":"1) Primeiro Classificador: KNN\n\n\n\nImporta\u00e7\u00e3o de fun\u00e7\u00f5es:","b01e61a6":"3) Cria\u00e7\u00e3o e Treino do Classificador e predi\u00e7\u00e3o do conjunto de teste.","2019e1fb":"Pelos teste acima, verifica-se que a texa de aprendizagem de 0.05 tem maior semelhan\u00e7a aos resultados do KNN","e5690768":"Prepara\u00e7\u00e3o dos dados para classificador teste:","2cf271a9":"3) Terceiro Classificador: Regular Gradient Boosting Classifier\n\nImporta\u00e7\u00e3o de Fun\u00e7\u00f5es","30a01641":"3) Medidas de desempenho. Ser\u00e3o verificadas matriz de confus\u00e3o, m\u00e9tricas derivadas da matriz e acur\u00e1cia com rela\u00e7\u00e3o ao KNN","8c2bdd02":"Nota-se que a acur\u00e1cia do MLP, comparado ao KNN, \u00e9 muito alta, sendo quase 1. Pela matriz de confus\u00e3o, entretanto, nota-se que ambos os classificadores identificam bem situa\u00e7\u00f5es de renda anual <=50k, enquanto que diferem razoavelmente para rendas de >50k, sendo semelhantes em 67% dos casos, comparado ao KNN.\n\nO tempo total, no computador testado,  para rodar o c\u00f3digo do KNN foi de 4 minutos e 25 segundos, sendo que foram 3 minutos e 47 segundos para o teste de valida\u00e7\u00e3o cruzada e  38 segundos para o treinamento+predi\u00e7\u00e3o do classificador.\nPara o classificador de rede neural, demorou 2 minutos e 8 segundos para treinamento+predi\u00e7\u00e3o do classificador.\n\nSendo assim, em quest\u00e3o de treinamento e predi\u00e7\u00e3o, o KNN possui tempo menor de processamento comparado ao MLP, apesar de ambos retornarem valores pr\u00f3ximos de classifica\u00e7\u00e3o. Logo, o KNN pode ser mais vi\u00e1vel, na pr\u00e1tica, devido \u00e0 sua simplicidade, menor tempo de processamento e facilidade de compreens\u00e3o.\n\n","50040f91":"3) Teste do hiperpar\u00e2metro de taxa de aprendizagem","32f5d692":"O classificador GBC tamb\u00e9m difere do MLP, em quest\u00e3o de classifica\u00e7\u00e3o de renda >50k.\nComo n\u00e3o se possui os r\u00f3tulos da base de teste, n\u00e3o \u00e9 poss\u00edvel afirmar quais desses classificadores prev\u00ea melhor a realidade. Entrentanto, devdo \u00e0 maior similaridade, em questao de classifica\u00e7\u00e3o, entre o KNN e o MLP, pode-se inferir que os resultados obtidos por esses dois se assemelham mais a realidade, pois um verifica o outro, al\u00e9m do fato do KNN ser mais simples de entender. Apesar disso, o Boosting possui tempo de processamento muito menor, o que pode torn\u00e1-lo melhor em situa\u00e7\u00f5es que exigem velocidade.","759b2de5":"2) Cria\u00e7\u00e3o e Treino do Classificador e predi\u00e7\u00e3o do conjuntode teste.\n   Ser\u00e1 usado o mesmo conjunto de vari\u00e1veis do classificador KNN, para compara\u00e7\u00e3o","7ee64409":"2) Segundo Classificador: Rede Neural MLP (MultiLayer Perceptron)\n\n\nImporta\u00e7\u00e3o de fun\u00e7\u00f5es","bc62746d":"Pelos exerc\u00edcio, t\u00eam que o melhor resultado, para o classificador KNN foi para conjunto de vari\u00e1veis acima, para k=28\n\nCria\u00e7\u00e3o do classificador definitivo"}}