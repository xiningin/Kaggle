{"cell_type":{"a3b9748d":"code","75bd8dd1":"code","5e8b50f0":"code","f26c6507":"code","a8f84363":"code","06814418":"code","04680795":"code","f42129f3":"code","74357d36":"code","73552ec5":"code","20d9b634":"code","d545d91a":"code","93a2b65a":"code","8119809f":"markdown","1ec78d48":"markdown","a07918ba":"markdown","c509a316":"markdown","ba7b0741":"markdown","e877ee70":"markdown","b73a1435":"markdown","6a16f312":"markdown"},"source":{"a3b9748d":"# Importing the libraries\nimport tensorflow as tf\n\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt","75bd8dd1":"# Let's download the data\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()","5e8b50f0":"# Normalize pixel values between 0 and 1\ntrain_images, test_images = train_images\/255.0, test_images\/255.0","f26c6507":"train_images.shape","a8f84363":"# Let's plot some images to check the data\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'lion',\n               'dog', 'frog', 'horse', 'ship', 'truck']\n\nplt.figure(figsize = (12,12))\n\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap = plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i][0]])\nplt.show()","06814418":"model = models.Sequential()","04680795":"model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (32,32,3)))\nmodel.add(layers.MaxPool2D(2,2))\nmodel.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (32,32,3)))\nmodel.add(layers.MaxPool2D(2,2))\nmodel.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (32,32,3)))","f42129f3":"# Let's check our model's architecture till now\nmodel.summary()","74357d36":"# Let's now add flatten and dense layers\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10))\n","73552ec5":"# Complete architecture of the model\nmodel.summary()","20d9b634":"model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n             metrics = ['accuracy'])\n\nhistory = model.fit(train_images, train_labels, epochs = 10, validation_data = (test_images, test_labels))","d545d91a":"plt.plot(history.history['accuracy'], label = 'accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)","93a2b65a":"print(test_acc)","8119809f":"### Compile and train the model","1ec78d48":"### CNN (Convolution Neural Networks)\n#### This notebook is entirely dedicated to the complete beginners in the field of deep learning. It will show you how can you create a simple CNN model using tensorflow keras.\n\n![image.png](attachment:image.png)","a07918ba":"Here we are using CIFAR10 dataset\n\nThe CIFAR10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them.","c509a316":"** For this simple CNN model we created we are getting the accuracy of 68%(approx). Not bad Huh **","ba7b0741":"**** After reading this notebook if you find it helpful then do support and don't forget to give an upvote ****","e877ee70":"** And if u wanna read about CNN refer to ----> https:\/\/www.superdatascience.com\/blogs\/the-ultimate-guide-to-convolutional-neural-networks-cnn **","b73a1435":"### Evaluating the model","6a16f312":"### Let's create our CNN\n\nAs input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. If you are new to these dimensions, color_channels refers to (R,G,B)"}}