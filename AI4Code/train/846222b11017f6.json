{"cell_type":{"69abe9d0":"code","2c75d361":"code","525aa7a0":"code","e154ef79":"code","e02ed6b3":"code","94ed8801":"code","8a520182":"code","244feebc":"code","50d86897":"code","b23adfdd":"code","2babaea2":"code","2b06835d":"code","902a3585":"code","0f7b0d9b":"code","42eb04f6":"code","edc34db9":"markdown","09440c24":"markdown","dc14ed36":"markdown","6762eb11":"markdown","ffc595d6":"markdown","af41f5ca":"markdown","0b3fae68":"markdown","4369e9ea":"markdown","cefb1a41":"markdown"},"source":{"69abe9d0":"%%capture\n!pip install -U \"scikit-learn\"","2c75d361":"from pathlib import Path\n\nif Path.cwd() == Path('\/kaggle\/working'):\n    # Kaggle\n    import sys\n    LIB_PATH = (Path.cwd()\/\"..\"\/\"input\"\/\"feedback-prize-2021-lib\").resolve()\n    assert LIB_PATH.is_dir(), (\"Use the '+ Add data' feature to add the 'Notebook Output Files' from the 'sentinel1\/feedback-prize-2021-lib' \"\n                               \"in order to make some utilities importable from that library (one time restart is required after adding).\")\n    sys.path.insert(0, str(LIB_PATH))\nelse:\n    # Local machine\n    assert (Path.cwd()\/\"lib\"\/\"feedback_util.py\").is_file(), (\"Run the 'sentinel1\/feedback-prize-2021-lib' notebook locally \"\n                                                             \"in order to generate the importable library on your machine\")","525aa7a0":"from lib.feedback_util import get_train_df_with_fixed_PII_offsets, train_df_k_fold_split, get_train_essay_text, color_print_essay","e154ef79":"import pandas as pd\nimport numpy as np","e02ed6b3":"K_FOLDS = 6  # Split the data into how many folds?","94ed8801":"train_df = get_train_df_with_fixed_PII_offsets(use_tmp_cache=True)\ntrain_df.head(2)","8a520182":"train_df = train_df_k_fold_split(train_df, K=K_FOLDS, display_split_statistics=True)","244feebc":"train_df.head()","50d86897":"import importlib\n\nif importlib.util.find_spec('ipywidgets') is not None:\n    from tqdm.auto import tqdm\nelse:\n    from tqdm import tqdm\n\n    \ntrain_folds = [1, 2, 3, 4]\nval_folds = [5, 6]\n\n\nfor fold in train_folds:\n    fold_df = train_df[train_df['CV'] == fold]\n    for idx,row in tqdm(fold_df.iterrows(), desc=f'Train Fold {fold}', total=len(fold_df), dynamic_ncols=True, miniters=10):\n        discourse_text = row['discourse_text']\n        essay_text = get_train_essay_text(row['id'])\n        # Train\n\n\nfor fold in val_folds:\n    fold_df = train_df[train_df['CV'] == fold]\n    for val_idx,val_row in tqdm(fold_df.iterrows(), desc=f'Val Fold {fold}', total=len(fold_df), dynamic_ncols=True, miniters=10):\n        val_discourse_text = val_row['discourse_text']\n        val_essay_text = get_train_essay_text(val_row['id'])\n        # Validate\n","b23adfdd":"print(discourse_text)","2babaea2":"print(val_discourse_text)","2b06835d":"print(essay_text)","902a3585":"color_print_essay(row['id'], train_df, start_end_indicators=True)","0f7b0d9b":"print(val_essay_text)","42eb04f6":"color_print_essay(val_row['id'], train_df)","edc34db9":"## Print the last \"train\" discourse text from the above loops (i.e. `discourse_text`)","09440c24":"## Print the last \"train\" essay from the above loops (i.e. `essay_text`)","dc14ed36":"## Example Loops\n\nSimply one of the many possible loops demonstrating the use of the above calculated K-Folds split (i.e. usage of the `CV` column in the `train_df`)","6762eb11":"## Load metadata from the `train.csv`\n\nUsing the `get_train_df_with_fixed_PII_offsets()` function in order to have PII masking noise corrected in the `train_df`\n\nNOTE: Passing the `use_tmp_cache=True` argument in the function call below will speed up loading of the `train_df` by saving cache file into the `..\/temp` directory on the first call and reusing it on the consecutive calls.","ffc595d6":"## Example\/test of `train_df_k_fold_split()` \u2014 Split data into K-Folds\n\n\nNOTES:\n- Part of examples for the `feedback-prize-2021-lib` [library](https:\/\/www.kaggle.com\/sentinel1\/feedback-prize-2021-lib)\n- The `train_df_k_fold_split()` function requires newer version of `scikit-learn`. Please update the scikit-learn package first. If you will NOT update the `scikit-learn` package then the `train_df_k_fold_split()` function will raise a relevant exception if called, but the rest of the library will continue to work normally without updating anything, so you can skipp the `!pip install -U \"scikit-learn\"` part when you are NOT using the `train_df_k_fold_split()` function.","af41f5ca":"## Split data into K-Folds\n\nSplit the data using the `train_df_k_fold_split()` function in order to have evenly distributed dicsourse types between folds while preventing the same essay to spread across folds, this is achieved in the `train_df_k_fold_split()` function by using the `StratifiedGroupKFold` of the `scikit-learn ` (i.e. the Stratified K-Folds iterator variant with non-overlapping groups). Calling the function will add the `CV` column to the `train_df` dataframe indicating which fold is each row part of.\n\nNOTE: Passing the `display_split_statistics=True` argument in the function call below will cause `train_df_k_fold_split()` function to calculate and display basic statistics of how the data was split across the folds (i.e. counts of essays, discourses and each discourse types per CV), it does NOT affect the returned dataframe and it would work faster with the `display_split_statistics=False` (which is the default).","0b3fae68":"## Configuration of K fold split","4369e9ea":"## Print the last \"validation\" essay text from the above loops (i.e. `val_essay_text`)","cefb1a41":"## Print the last \"validation\" discourse text from the above loops (i.e. `val_discourse_text`)"}}