{"cell_type":{"319881bb":"code","9e468439":"code","e5647593":"code","25e45b10":"code","77265f0f":"code","22dae64b":"code","eb73dbf1":"code","eb8aee8d":"code","0d20f3dd":"code","077e192b":"code","2cc1c4ea":"code","802ae106":"code","53cbfdb4":"code","26638c85":"code","41f6af6b":"code","a8b4c232":"code","af190b8d":"code","0069fc12":"code","5993f110":"code","2048bb93":"code","14ad0126":"code","cc757e1d":"code","6630a9fa":"code","12481de3":"code","ed0117bf":"code","9b50c963":"code","8f0e30bb":"code","b0b3dd50":"code","9dbc8888":"code","3779a633":"code","a25e6a7e":"code","b3c4adcd":"code","848d5b69":"code","771b00d2":"code","38cbf6b1":"code","743ea0bd":"code","651c923c":"code","dbff9d1b":"code","83f34fe4":"code","35a48769":"code","a83089a7":"code","9eddf329":"code","b31380ea":"code","49bce423":"code","c75c0452":"code","2f0690bb":"code","69835f31":"markdown","6d5f9fba":"markdown","3cccd9dd":"markdown","d9432dc6":"markdown","a8240955":"markdown","40b594c4":"markdown","ac7b2f15":"markdown","d9e9e26f":"markdown","7af803ce":"markdown","3b37c711":"markdown","4897e999":"markdown","90705ed8":"markdown","b6dad9d8":"markdown","01b857cb":"markdown","07798266":"markdown","303d638a":"markdown","aa988d8d":"markdown","a3d52d09":"markdown","4ee29abf":"markdown","f6b423bf":"markdown","04835619":"markdown","de4e4f8a":"markdown","da554507":"markdown","86df0530":"markdown","8cb88637":"markdown","2fb9f02c":"markdown"},"source":{"319881bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas.plotting import scatter_matrix\nimport sys\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9e468439":"def load_data(data_path,data_fname):\n    csv_path = os.path.join(data_path, data_fname)\n    return pd.read_csv(csv_path)","e5647593":"filename=filenames[0]\nif (filenames[1].find('region')>0):\n    filename=filenames[1]\n    ","25e45b10":"df_reg = load_data(dirname,filename)\ndf_reg.head()","77265f0f":"df_reg.shape","22dae64b":"df_reg.info()","eb73dbf1":"df_reg.describe(include='all')","eb8aee8d":"df_reg=df_reg.drop('Country',axis=1)","0d20f3dd":"df_reg=df_reg.drop('SNo',axis=1)","077e192b":"df_reg.columns","2cc1c4ea":"df_reg.Date.value_counts()","802ae106":"df_reg.Date=pd.to_datetime(df_reg.Date)","53cbfdb4":"df_reg.info()","26638c85":"df_reg_conv=df_reg.loc[:,['RegionCode','RegionName']]","41f6af6b":"sum_devstd=0\nfor reg in df_reg_conv.RegionName.value_counts().index:\n    print (reg)\n    print ('Coded as:')\n    print(str(df_reg_conv.loc[df_reg_conv.RegionName==reg].mean()[0]))\n    sum_dev_std=+df_reg_conv.loc[df_reg_conv.RegionName==reg].std()[0]\nprint ('Total Dev Std:')\nprint(str(sum_dev_std))\n    \n    ","a8b4c232":"df_reg=df_reg.drop('RegionName',axis=1)","af190b8d":"df_reg.set_index('Date')","0069fc12":"df_reg.TotalPositiveCases.plot()","5993f110":"train_set,test_set=train_test_split(df_reg,test_size=0.2, random_state=10)","2048bb93":"train_set.plot(kind='scatter',x='Longitude',y='Latitude')","14ad0126":"train_set.loc[df_reg_conv.RegionCode==19].loc[:,['Latitude','Longitude']].mean()","cc757e1d":"train_set.plot(kind=\"scatter\", x=\"Longitude\", y=\"Latitude\", alpha=0.4,\n    s=train_set['TotalPositiveCases'], figsize=(10,13),\n    c='TestsPerformed', cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.legend()","6630a9fa":"corr_mx=train_set.iloc[:,1:].corr()","12481de3":"col=train_set.iloc[:,1:].columns","ed0117bf":"sns.set(font_scale=1.5)\nhm=sns.heatmap(corr_mx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size':6},yticklabels=col,xticklabels=col)","9b50c963":"corr_mx=train_set.iloc[:,5:].corr()\ncol=train_set.iloc[:,5:].columns","8f0e30bb":"hm=sns.heatmap(corr_mx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size':9},yticklabels=col,xticklabels=col)","b0b3dd50":"col=['TotalHospitalizedPatients','IntensiveCarePatients','CurrentPositiveCases','TotalPositiveCases','HomeConfinement','Recovered','Deaths','TestsPerformed']","9dbc8888":"axes =scatter_matrix(train_set[col],figsize=(14,10))\n\nfor ax in axes.flatten():\n    ax.xaxis.label.set_rotation(90)\n    ax.yaxis.label.set_rotation(0)\n    ax.yaxis.label.set_ha('right')\n\nplt.tight_layout()\nplt.gcf().subplots_adjust(wspace=0, hspace=0)\nplt.show()","3779a633":"corr_mx.NewPositiveCases.sort_values(ascending=False)","a25e6a7e":"train_set_m=train_set.iloc[:,4:]\ntest_set_m=test_set.iloc[:,4:]\ntrain_set_m=train_set_m.drop('Deaths',axis=1)\ntrain_set_m=train_set_m.drop('Recovered',axis=1)\ntest_set_m=test_set_m.drop('Deaths',axis=1)\ntest_set_m=test_set_m.drop('Recovered',axis=1)","b3c4adcd":"y_train_set_m=train_set_m.iloc[:,5]\ny_test_set_m=test_set_m.iloc[:,5]\nX_train_set_m=train_set_m.drop('NewPositiveCases',axis=1)\nX_test_set_m=test_set_m.drop('NewPositiveCases',axis=1)","848d5b69":"X_train_set_m.describe()","771b00d2":"lin_reg=LinearRegression()\nlin_reg.fit(X_train_set_m_std,y_train_set_m)","38cbf6b1":"y_test_predict=lin_reg.predict(X_test_set_m)\nlin_rmse=np.sqrt(mean_squared_error(y_test_set_m,y_test_predict))\nprint(lin_rmse)","743ea0bd":"rnd_clf=RandomForestRegressor(n_estimators=30)\nrnd_clf.fit(X_train_set_m,y_train_set_m)","651c923c":"y_test_predict_rf=rnd_clf.predict(X_test_set_m)\nlin_rmse_rf=np.sqrt(mean_squared_error(y_test_set_m,y_test_predict_rf))\nprint(lin_rmse_rf)","dbff9d1b":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","83f34fe4":"param_grid=[{'n_estimators':[3,30,50,80,100]}]","35a48769":"grid_search=GridSearchCV(rnd_clf,param_grid,cv=5,scoring='neg_mean_squared_error',return_train_score=True)","a83089a7":"grid_search.fit(X_train_set_m,y_train_set_m)","9eddf329":"grid_search.best_estimator_","b31380ea":"cvres=grid_search.cv_results_\nfor mean_score,params in zip(cvres[\"mean_test_score\"],cvres[\"params\"]):\n    print(np.sqrt(-mean_score),params)","49bce423":"rnd_clf=RandomForestRegressor(n_estimators=80)\nrnd_clf.fit(X_train_set_m,y_train_set_m)\ny_test_predict_rf=rnd_clf.predict(X_test_set_m)\nlin_rmse_rf=np.sqrt(mean_squared_error(y_test_set_m,y_test_predict_rf))\nprint(lin_rmse_rf)","c75c0452":"from sklearn.model_selection import cross_val_score\nscores=cross_val_score(rnd_clf,X_train_set_m,y_train_set_m,scoring=\"neg_mean_squared_error\",cv=10)\n","2f0690bb":"score_rmse=np.sqrt(-scores)\nprint(score_rmse)\nprint(score_rmse.mean())\nprint(score_rmse.std())","69835f31":"The best model is Linear Regression one (less RMSE)! Let's try to tune the Random Forest model and cross validate it.","6d5f9fba":"Random Forest Regressor:","3cccd9dd":"Now lets see ","d9432dc6":"Linear Regression:","a8240955":"As shown hereafter the increment of Total Positive Cases vs Time is exponential:","40b594c4":"# <center>Covid-19 in Italy<\/center>\n\n#### <center> 29 March 2020 <\/center> \n#####  <center> A.P. <\/center> \n\n\n\n# Introduction \nWith this exercise I tried to perform some consideration about data provided in \"covid19-in-italy\" database (only covid19_italy_region table). At first I have reported some considerations to remove redundant information. I have splitted data in a train and a test set. I have reported \"time\" and \"space\" analysis. Finally I have tried to predict \"NewPositiveCases\" with two supervised learning algorithms: Linear Regression and Random Forest. The performance measurement chosen is RMSE.\nX train matrix is build with  Test Performed and Home Confinement data. These provision, which are the strongest weapons against virus.\n","ac7b2f15":"Looking for correlations","d9e9e26f":"The best model is still Linear Regression one with 4.68 of rmse vs 91.82 (MEAN) of Random Forest one.","7af803ce":"*Thanks for the attention. Any feedback are  welcome.*","3b37c711":"Visualizing Geographical Data:","4897e999":"Hereafter the strongest correlations found (scc>0.9):\n1. TotalHospitalizedPatients w.r.t. IntensiveCarePatients (scc=0.99)\n2. TotalHospitalizedPatients w.r.t. CurrentPositiveCases (scc=0.99)\n2. TotalHospitalizedPatients w.r.t. TotalPositiveCases (scc=0.98)\n2. TotalHospitalizedPatients w.r.t. HomeConfinement (scc=0.93)\n2. TotalHospitalizedPatients w.r.t. Recovered (scc=0.93)\n2. TotalHospitalizedPatients w.r.t. Deaths (scc=0.95)\n3. IntensiveCarePatients w.r.t. CurrentPositiveCases (scc=0.98)\n4. IntensiveCarePatients w.r.t. HomeConfinement (scc=0.93)\n4. IntensiveCarePatients w.r.t. Deaths (scc=0.91)\n4. HomeConfinement w.r.t. Deaths (scc=0.92)\n4. HomeConfinement w.r.t. TestsPerformed (scc=0.93)\n4. Recovered w.r.t. CurrentPositiveCases (scc=0.92)\n4. Recovered w.r.t. TotalPositiveCases (scc=0.96)\n4. Recovered w.r.t. Deaths (scc=0.99)\n4. Death w.r.t. CurrentPositiveCases (scc=0.95)\n5. TotalPositiveCases w.r.t. Deaths (scc=0.98)","90705ed8":"An interesting parameter to be predicted is the number of new positive cases.\nA Strong \nI try to build a model ","b6dad9d8":"\"Country\" column can be dropped because do not add any relevant information","01b857cb":"# Conclusion","07798266":"Data related to time period from end of february to the end of march. It has to be converted to datetime object.","303d638a":"And hereafter represented the scatter matrix of these parameters:","aa988d8d":"It is convenient to set the index to Date parameter:","a3d52d09":"Total sum of Standard Deviation is 0. Coding has been displayed before. Therefore \"RegionName\" column can be dropped.","4ee29abf":"To predict it I will use parameters with scc >0.8, with exception of Test Performed which, togheter with Home Confinement,are the strongest weapons against virus.","f6b423bf":"Last object type remained is \"Region Name\", which I suppose has been already coded by column \"Region Code and therefore irrelevant. Let's see:","04835619":"Train Test Split and Visual Analysis of Train Test Set:","de4e4f8a":"The radius of each circle represent the Total Positive Cases and the color represents the Number of Test Performed.\nThe greatest number of test performed and positive cases are concentrated in Northern Italy","da554507":"Lets try to predict \"NewPositiveCases\" with two supervised learning algorithms: Linear Regression and Random Forest. The performance measurement chosen is RMSE.","86df0530":"The above heatmap shows uncorrelation between geographical data and medical ones. Therefore these data can be removed. ","8cb88637":"It looks like Italy. Each dot is related to a Region. E.G. the dot in the middle lower part of the plot is Sicily:","2fb9f02c":"\"SNo\" can also be dropped cause it seems to be a Serial Number, counting numbers of row and therefore redundant w.r.t. dataframe index information "}}