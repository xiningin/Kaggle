{"cell_type":{"1f545206":"code","366590ba":"code","03242472":"code","636bfcb1":"code","426985b5":"code","11cca706":"code","f488f277":"code","49f1c642":"code","76bc3808":"code","d3a57183":"code","aea62800":"code","e13e56a7":"code","de2458b6":"code","db5e605c":"code","c5c2a052":"code","ba821af3":"code","c6ddc02e":"code","fb170014":"code","ed1a3d94":"code","33b4f3ad":"code","ab9b60e8":"code","487440d9":"code","49f1e475":"markdown","e071c425":"markdown","efb9262c":"markdown","ea3fc5e1":"markdown","8f226314":"markdown","0a77bd69":"markdown"},"source":{"1f545206":"!pip install ktrain","366590ba":"import os\nos.environ['DISABLE_V2_BEHAVIOR'] = '1' # to use bilstm-crf on ktrain, disable to use bilstm-bert\nimport re\nimport sys\nimport random\nimport ktrain\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom itertools import cycle\nfrom datetime import datetime\nfrom tqdm import tqdm","03242472":"print('Python version:', sys.version)\nprint('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('KTrain version:', ktrain.__version__)\nprint('Tensorflow version:', tf.__version__)","636bfcb1":"SEED = 42\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\ntqdm.pandas()","426985b5":"model_name = 'bilstm-crf'\nepoch = 25\nbatch_size = 64","11cca706":"df_train = pd.read_pickle('\/kaggle\/input\/scl-2021-2-processed-data\/train.pickle')\ndf_train","f488f277":"df_test = pd.read_csv('\/kaggle\/input\/scl-2021-ds\/test.csv')\nX_test = df_test['raw_address'].tolist()\nX_test[:10]","49f1c642":"# Source: https:\/\/github.com\/NLPatVCU\/medaCy\/blob\/2cd3c7eae2c6949de5b6332f4a7533c3b8056f7f\/medacy\/ner\/model\/stratified_k_fold.py\nclass SequenceStratifiedKFold:\n    \"\"\"\n    Partitions a data set of sequence labels and classifications into 10 stratified folds.\n    See Dietterich, 1997 \"Approximate Statistical Tests for Comparing Supervised Classification\n    Algorithms\" for in-depth analysis.\n    Each partition should have an evenly distributed representation of sequence labels.\n    Without stratification, under-representated labels may not appear in some folds.\n    \"\"\"\n\n    def __init__(self, folds = 10):\n        self.folds = folds\n\n    def __call__(self, X, y):\n        \"\"\"\n        Returns an iterable [(X*,y*), ...] where each element contains the indices\n        of the train and test set for the particular testing fold.\n        :param X: a collection of sequences\n        :param y: a collection of sequence labels\n        :return:\n        \"\"\"\n\n        # labels are ordered by most examples in data\n        labels = np.unique([label for sequence in y for label in sequence])\n        np.flip(labels)\n\n        added = np.ones(len(y), dtype=bool)\n        partitions = [[] for fold in range(self.folds)]\n        partition_cycler = cycle(partitions)\n\n\n        for label in labels:\n            possible_sequences = [index for index, sequence in enumerate(y) if label in sequence]\n            for index in possible_sequences:\n                if added[index]:\n                    partition = next(partition_cycler)\n                    partition.append(index)\n                    added[index] = 0\n        train_test_array = []\n\n        for i, _ in enumerate(partitions):\n            y = partitions[i]\n            X = []\n            for j, partition in enumerate(partitions):\n                if i != j:\n                    X += partition\n\n            # print(X)\n            train_test_array.append((X,y))\n\n        return train_test_array","76bc3808":"kf = SequenceStratifiedKFold(folds=6)\nX = df_train['raw_address'].tolist()\ny = df_train['ner_tag'].tolist()\n\nfor train_idx, val_idx in kf(X,y):\n    X_train = [X[i] for i in train_idx]\n    X_val = [X[i] for i in val_idx]\n\n    y_train = [y[i] for i in train_idx]\n    y_val = [y[i] for i in val_idx]\n    break","d3a57183":"train_ds, val_ds, preproc = ktrain.text.entities_from_array(\n    X_train, y_train,\n    X_val, y_val,\n    use_char=True\n)","aea62800":"model = ktrain.text.sequence_tagger(\n    model_name, preproc=preproc,\n    char_lstm_size=300,\n    fc_dim=300,\n    wv_path_or_url='https:\/\/dl.fbaipublicfiles.com\/fasttext\/vectors-crawl\/cc.id.300.vec.gz', # ~1.1GB\n)\nmodel.summary()","e13e56a7":"learner = ktrain.get_learner(model, train_data=train_ds, val_data=val_ds, batch_size=batch_size)\nlearner.lr_find(lr_mult=1.01, show_plot=True, restore_weights_only=True)","de2458b6":"lr = learner.lr_estimate()\nprint(lr)\n\ntry:\n    lr = learner.lr_estimate()\n    lr = max(lr) \/ 3\nexcept:\n    print('Use default LR!')\n    lr = 0.002","db5e605c":"es_callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=5, verbose=1,\n    mode='auto', baseline=None, restore_best_weights=True\n)\n\nlearner.autofit(lr, epoch, callbacks=[es_callback])","c5c2a052":"learner.plot('loss')\nlearner.plot('lr')\nlearner.plot('momentum')","ba821af3":"learner.validate()","c6ddc02e":"learner.view_top_losses(n=3)","fb170014":"# Modified from https:\/\/github.com\/amaiya\/ktrain\/blob\/master\/ktrain\/text\/ner\/predictor.py for batch prediction\nimport ktrain.text.textutils as TU\n\ndef batch_predict(self, sentences):\n    lang = TU.detect_lang(sentences)\n    nerseq = self.preproc.preprocess(sentences, lang=lang, custom_tokenizer=None)\n    if not nerseq.prepare_called:\n        nerseq.prepare()\n    nerseq.batch_size = len(sentences)\n    x_true, _ = nerseq[0]\n    lengths = nerseq.get_lengths(0)\n    y_pred = self.model.predict(x_true)\n    y_labels = self.preproc.p.inverse_transform(y_pred, lengths)\n    \n    # get data\n    try:\n        probs = np.max(y_pred, axis=2)\n    except:\n        probs = y_pred.numpy().tolist() # TODO: remove after confirmation (#316)\n\n    return_datas = []\n    for x, y, prob in zip(nerseq.x, y_labels, probs):\n        return_data = [(x[i], y[i], prob[i]) for i in range(len(x))]\n        return_datas.append(return_data)\n\n    return return_datas","ed1a3d94":"predictor = ktrain.get_predictor(learner.model, preproc)\npredictor.batch_predict = batch_predict\npredictor.save(f'.\/{model_name}') # create directory","33b4f3ad":"y_preds = []\ndoc_count = len(X_test)\n\nfor idx_start in tqdm(range(0, doc_count, batch_size)):\n    idx_end = idx_start + batch_size\n    if idx_end > doc_count:\n        idx_end = doc_count\n\n    y_pred = predictor.batch_predict(predictor, X_test[idx_start:idx_end])\n    y_preds.extend(y_pred)\n    \ny_preds[:3]","ab9b60e8":"y_predicts = []\nfor X, y_pred in tqdm(zip(X_test, y_preds)):\n    # Assuming POI\/street sequence appear once\n    poi_token = []\n    street_token = []\n    for token, tag, prob in y_pred:\n        if tag == 'POI':\n            poi_token.append(re.escape(token))\n        if tag == 'street':\n            street_token.append(re.escape(token))\n\n    # regex not throughfully tested\n    poi_regex = '.*'.join(poi_token)\n    street_regex = '.*'.join(street_token)\n    \n    poi = ''\n    try:\n        if poi_regex != '':\n            re_result = re.search(rf'{poi_regex}', X)\n            poi = X[re_result.start() : re_result.end()]\n    except Exception as ex:\n        print('POI regex')\n        print(ex)\n        print(X)\n        print('-'*50)\n\n    street = ''\n    try:\n        if street_regex != '':\n            re_result = re.search(rf'{street_regex}', X)\n            street = X[re_result.start() : re_result.end()]\n    except Exception as ex:\n        print('street regex')\n        print(ex)\n        print(X)\n        print('-'*50)\n    poi_street = f'{poi}\/{street}'\n\n    y_predicts.append(poi_street)\n\ny_predicts[:10]","487440d9":"df_submission = pd.DataFrame({\n    'id': np.arange(len(y_predicts)),\n    'POI\/street': y_predicts\n})\ndf_submission.to_csv(f'submission.csv', index=False)\ndf_submission","49f1e475":"# 2. Dataset","e071c425":"# 6. Predict","efb9262c":"# 4. Model","ea3fc5e1":"# 1. Library","8f226314":"# 3. Process dataset","0a77bd69":"# 5. Train"}}