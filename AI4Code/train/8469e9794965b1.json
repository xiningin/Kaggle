{"cell_type":{"70fb83b9":"code","ea07988c":"code","f6e74bc2":"code","80af7129":"code","40e8b7ee":"code","86b33e06":"code","4456f828":"code","d99d90ed":"code","c4bb0a8f":"code","3a073697":"code","f45f3cf8":"code","7ef23138":"code","116917d3":"code","1b912fe3":"code","a7a452c2":"code","03cf2b63":"code","b4b970a1":"code","9dbef6eb":"code","3661327a":"code","f78a16a1":"code","bf99279d":"code","b58e3b36":"code","1b388055":"code","0b8fea0c":"code","f544e6dd":"code","caf9f5ff":"code","44f95093":"code","78ece24b":"code","de579857":"markdown","a532afe9":"markdown","257c4fa1":"markdown","a7250ccc":"markdown","0009faf4":"markdown","a702fb00":"markdown","bb8f139c":"markdown","2a58e0a9":"markdown"},"source":{"70fb83b9":"import numpy as np\nfrom scipy import spatial\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE","ea07988c":"# load the whole embedding into memory       \nembeddings_dict={}\nwith open('..\/input\/glove-global-vectors-for-word-representation\/glove.6B.100d.txt','r') as f:\n    for line in f:\n        values=line.split()\n        word=values[0]\n        vectors=np.asarray(values[1:],'float32')\n        embeddings_dict[word]=vectors\nf.close()\nprint('Loaded %s word vectors.' % len(embeddings_dict))","f6e74bc2":"# show first words \nlist(embeddings_dict.keys())[:10]","80af7129":"# display a single vector (embedding)\nembeddings_dict['the']","40e8b7ee":"# how long is this vector (dimensions)?\nlen(embeddings_dict['the'])","86b33e06":"# show end of list:\nlist(embeddings_dict.keys())[399990:400000]","4456f828":"# define (euclidean) distance function \ndef find_closest_embeddings(embedding): \n    return sorted(embeddings_dict.keys(), key=lambda word: spatial.distance.euclidean(embeddings_dict[word], embedding))","d99d90ed":"print(find_closest_embeddings(embeddings_dict[\"the\"])[1:6])","c4bb0a8f":"print(find_closest_embeddings(embeddings_dict[\"king\"])[1:6])","3a073697":"print(find_closest_embeddings(\n    embeddings_dict[\"king\"] - embeddings_dict[\"man\"] + embeddings_dict[\"woman\"])[1:6])","f45f3cf8":"embeddings_dict[\"queen\"]","7ef23138":"embeddings_dict[\"king\"] - embeddings_dict[\"man\"] + embeddings_dict[\"woman\"]","116917d3":"spatial.distance.euclidean(embeddings_dict[\"king\"] - embeddings_dict[\"man\"] + embeddings_dict[\"woman\"],embeddings_dict[\"queen\"])","1b912fe3":"spatial.distance.euclidean(embeddings_dict[\"king\"], embeddings_dict[\"prince\"])","a7a452c2":"spatial.distance.euclidean(embeddings_dict[\"king\"], embeddings_dict[\"queen\"])","03cf2b63":"spatial.distance.euclidean(embeddings_dict[\"king\"], embeddings_dict[\"telefon\"])","b4b970a1":"spatial.distance.euclidean(embeddings_dict[\"begin\"], embeddings_dict[\"start\"])","9dbef6eb":"print(find_closest_embeddings(embeddings_dict[\"doctor\"])[1:6])","3661327a":"print(find_closest_embeddings(embeddings_dict[\"nurse\"])[1:6])","f78a16a1":"print(find_closest_embeddings(\n    embeddings_dict[\"doctor\"] - embeddings_dict[\"he\"] + embeddings_dict[\"she\"])[1:6])","bf99279d":"print(find_closest_embeddings(\n    embeddings_dict[\"doctor\"] - embeddings_dict[\"man\"] + embeddings_dict[\"woman\"])[1:6])","b58e3b36":"print(find_closest_embeddings(embeddings_dict[\"fruit\"])[1:21])","1b388055":"print(find_closest_embeddings(embeddings_dict[\"apple\"])[1:21])","0b8fea0c":"print(find_closest_embeddings(\n    embeddings_dict[\"apple\"] - embeddings_dict[\"microsoft\"] + embeddings_dict[\"fruit\"])[1:21])","f544e6dd":"print(find_closest_embeddings(embeddings_dict[\"man\"] + embeddings_dict[\"woman\"])[1:6])","caf9f5ff":"print(find_closest_embeddings(embeddings_dict[\"man\"] - embeddings_dict[\"woman\"])[1:6])","44f95093":"print(find_closest_embeddings(embeddings_dict[\"woman\"] - embeddings_dict[\"man\"])[1:6])","78ece24b":"print(find_closest_embeddings(embeddings_dict[\"start\"] - embeddings_dict[\"stop\"])[1:6])","de579857":"### Gender Bias","a532afe9":"The similarity isn't too obvious","257c4fa1":"### Further examples","a7250ccc":"## Examples of Similar Word Embeddings in GloVe (king - man + woman = ...)\n\nSources: https:\/\/medium.com\/analytics-vidhya\/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db, https:\/\/www.kaggle.com\/alankritamishra\/allinonefromlstmtobert, https:\/\/www.kaggle.com\/shahules\/basic-eda-cleaning-and-glove","0009faf4":"## Show distances (examples)","a702fb00":"### Ambiguities: Fruit or Company?","bb8f139c":"### Find similar words","2a58e0a9":"The \"king\" and \"queen\" embeddings are already quite similar. The similarity example \"king-man-woman=queen\" works. \n\nLet's look at the vectors:"}}