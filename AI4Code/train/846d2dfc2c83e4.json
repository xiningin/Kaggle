{"cell_type":{"3f00f1d4":"code","1fa85439":"code","2586d551":"code","6d4554b9":"code","4f9e6743":"code","e5a20a78":"code","29f76f2c":"code","35728d0c":"code","e4e3fe06":"markdown","a097822e":"markdown","89c1fc22":"markdown"},"source":{"3f00f1d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1fa85439":"pip install openpyxl","2586d551":"\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n#import matplotlib.patheffects as path_effects\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom tabulate import tabulate\n\n\n#measuring performance metrics quarterly, yearly, and overall\n\n#metrics    1. return - OK\n#               1.0. total return - OK\n#               1.1. cagr - OK\n#           2. volatility - OK               \n#           3. sharpe - OK\n#           4. sortino -OK\n#           5. risk return ratio - OK\n#           6. treynor - OK\n#           6. max dd - OK\n#           7. max dd length - OK\n#           8. market beta - OK\n#           9. alpha - OK\n#               9.0 alpha raw - OK\n#               9.1 alpha CAPM - OK\n#           10. omega - OK\n#           12. VaR - OK\n#           13. max single period return - OK\n#           14. min single period ret - OK\n#           15. skewness - OK\n#           16. kurtosis - OK\n#           17. CDD (Conditional Draw Down): average of max 20% drawdowns - OK\n#           18. CDD Duration - OK\n#table - OK\n#plots      1. compounded return\n#           2. returns\n#           3. underwater\n#           4. heatmap\n#           5. annual return\n#\n\n# port_metrics_weekly = df_port_rets_weekly.loc[:,:1].apply(lambda x: pd.Series(performance_metrics(x, market=market_weekly, rf=rf_weekly, freq='W')), axis=0).T #visualization was made for only one portfolio\n\ndef performance_metrics(series_in, market=None, rf=None, target=None, freq=None, table=True, plots=True):\n    \n    # series_in is the pnl series of the asset or the strategy \n    \n    periods = series_in.shape[0]# total length of the return series that feed in\n    if freq=='Y':\n        unit_period = 1\n    elif freq=='M':\n        unit_period = 12\n    elif freq=='W':\n        unit_period = 52\n    elif freq=='D':\n        unit_period = 252\n    else:\n        print('Please check freq argument!')\n        return np.nan\n          \n    series = series_in.copy()\n    idx = series_in.index\n    \n    if rf is None:\n        print('rf is assumed as 0!')        \n        series_excess = series.copy()\n    elif type(rf)==int or type(rf)==float:\n        print('rf converted to unit period in a non-compounding way')\n        series_excess = series - rf\/unit_period\n    else:\n        series_excess = series - rf\n               \n    series_compounded = (series+1).cumprod()\n    series_excess_compounded = (series_excess+1).cumprod()\n    \n    ret_compounded = series_compounded.iloc[-1] - 1\n    ret_excess_compounded = series_excess_compounded.iloc[-1] - 1\n    cagr = (ret_compounded+1) ** (unit_period\/periods) - 1\n    \n    volatility = series.std() * unit_period**.5\n    series_negative = series.copy()\n    series_negative[series_negative>0] = 0\n    volatility_negative = series_negative.std() * unit_period**.5\n    \n    sharpe = cagr \/ volatility\n    \n    # sortinoe, ref: http:\/\/www.sunrisecapital.com\/wp-content\/uploads\/2014\/06\/Futures_Mag_Sortino_0213.pdf\n    sortino = cagr \/ volatility_negative\n    \n    # max dd\n    \n    max_dd_all = (series_compounded \/ series_compounded.cummax() )\n    max_dd = max_dd_all.min()-1\n    \n    # max_dd duration\n    \n    max_dddur_all = max_dd_all.copy()\n    max_dddur_all[max_dddur_all<1] = 0\n    max_dddur_all_cumsum = max_dddur_all.cumsum()\n    max_dddur_all = max_dddur_all_cumsum.value_counts()\n    max_dddur = max_dddur_all.max() # this is in terms of unit period\n\n    # risk return ratio [similar ratios; calmar, mar, sterling, burke... etc.]\n    \n    risk_return = cagr \/ (-max_dd)\n    \n    # Conditional drawdown  \n    condition = .2\n    n = int(np.round((max_dddur_all[max_dddur_all>1].shape[0]*condition)))\n    conditional_dd = max_dddur_all_cumsum.groupby(max_dddur_all_cumsum).apply(lambda x: max_dd_all.loc[x.index].min()).sort_values().iloc[:n].mean() - 1\n    #conditional_dd = 5\n    # CDD duration\n    \n    conditional_dd_dur = max_dddur_all.iloc[:n].mean()\n    \n    # alpha and beta\n    \n    def alpha_beta(return_series, market):\n\n        X = market.values.reshape(-1, 1)\n        X = np.concatenate([np.ones_like(X), X], axis=1)\n        b = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(return_series.values)\n        return b[0], b[1]\n    \n    if market is None:\n        alpha_raw = ret_compounded\n        alpha = np.nan\n        beta = np.nan\n    else:\n        alpha,beta = alpha_beta(series_excess, market)\n        alpha_raw = ret_compounded -((market +1).cumprod().iloc[-1]-1)\n        \n    # treynor ratio\n    \n    if market is None:\n        treynor = np.nan\n    else:\n        treynor = cagr \/ beta\n    \n    # max-min single\n    \n    max_single = series_in.max()\n    min_single = series_in.min()\n    \n    # skewness -kurt\n    \n    skewness = series_in.skew()\n    kurt = series_in.kurt()\n    \n    # Var\n    \n    VaR = series_in.quantile(.05)\n    \n    #omega ratio\n    \n    omega = cagr \/ (-series_negative.mean()) # need to be checked\n    \n    \n    metrics_names = ['Compounded Total Return', 'Compounded Excess Return', 'CAGR',\n                     'Annualized Volatility', 'Annualized Negative Volatility', 'Sharpe', 'Sortino',\n                     'Treynor', 'Omega', 'Risk-Return', 'alpha Raw', 'alpha',\n                     'beta', 'Max Drawdown', 'Conditional Drawdown (Highest 20%)',\n                     'Max Drawdown Duration', 'Conditional Drawdown Duration (Longest 20%)',\n                     'Maximum Single Period Return', 'Minimum Single Period Return', 'VaR (5%)', \n                     'Skewness', 'Kurtosis']\n    \n    metrics_values = [ret_compounded, ret_excess_compounded, cagr, volatility,\n                      volatility_negative, sharpe, sortino, treynor, omega, \n                      risk_return, alpha_raw, alpha, beta, max_dd, conditional_dd,\n                      max_dddur, conditional_dd_dur, max_single, min_single, VaR,\n                      skewness, kurt]\n    \n    dict_table = dict(zip(metrics_names, metrics_values))\n    \n    \n#-----------------------------------------------------------------------------------------------------    \n    \n    if table:\n        print(tabulate(zip(metrics_names, metrics_values), headers=['Metrics', 'Value'], tablefmt=\"fancy_grid\", floatfmt=\".4f\"))\n\n#-----------------------------------------------------------------------------------------------------\n    \n    if plots:\n        \n        #-----------------------------------------------------------------------------------------------------\n\n#        # plotting compounded returns\n#        plt.figure()\n#        series_compounded.plot(color='red', linewidth=1)\n#        #plt.plot(series_compounded)\n#        plt.fill_between(series_compounded.index,series_compounded, 1)\n#        plt.ylabel(\"Compounded Returns\")\n#        plt.xlabel(\"Date\")\n#        plt.title(\"Portfolio in Time\");\n#        plt.grid(color='black', linestyle='--', linewidth=0.5)\n        \n        #-----------------------------------------------------------------------------------------------------\n        \n        # plotting raw returns\n        plt.figure()\n        plt.plot(series_in.index,series_in,color='blue',linewidth=0.5)\n        plt.axhline(y=series_in.mean(), color='red', linewidth=1,linestyle='--')\n        plt.ylabel(\"Return\")\n        plt.xlabel(\"Date\")\n        plt.title('Raw Return')\n        plt.grid(color='black', linestyle='--', linewidth=0.5)\n        \n        #-----------------------------------------------------------------------------------------------------\n        \n        # plotting underwater figure\n        \n        plt.figure()\n        plt.plot(max_dd_all.index,max_dd_all,color='red',linewidth=0.2)\n        plt.fill_between(max_dd_all.index, max_dd_all,1)\n        plt.ylabel(\"Return\")\n        plt.xlabel(\"Date\")\n        plt.title(\"Underwater graph of highest 5 drawdown\");\n        plt.grid(color='black', linestyle='--', linewidth=0.5)\n        plt.show()\n        \n        #-----------------------------------------------------------------------------------------------------\n        \n        # plotting conditional max dd areas\n    \n        plt.figure()\n        list_color=['red','blue','black','green','orange']\n        cap_dd_toPlot = 5\n        n_dd_toPlot = min(len(max_dddur_all),cap_dd_toPlot)\n        \n        for i in range(n_dd_toPlot):\n            \n            start = max_dddur_all_cumsum[(max_dddur_all_cumsum==max_dddur_all.index[i])].index[0]\n            stop = max_dddur_all_cumsum[(max_dddur_all_cumsum==max_dddur_all.index[i])].index[-1]\n           \n           #plt.plot(series_compounded)\n            plt.axvspan(start,stop, alpha=0.3, color=list_color[i])\n           \n        plt.plot(series_compounded)\n        plt.show()\n        \n        \n        #-----------------------------------------------------------------------------------------------------\n        \n        # plotting  returns\n        fig, ax = plt.subplots()\n        ax= sns.boxplot(saturation=5, fliersize=5,width=0.75,data=series,whis=1)\n        ax = sns.swarmplot(data=series, color=\".25\")\n        ax.set(xlabel='Date', ylabel='Return')\n        plt.show()\n        \n        #-----------------------------------------------------------------------------------------------------\n        \n        # plotting heat map and annual returns\n        \n        if not freq=='Y':\n            \n            plt.figure()\n            \n            years = idx.year.unique()\n            \n            if freq=='M':\n                secondary_period = idx.month.unique().sort_values()\n            \n            elif freq=='W':\n                \n                secondary_period_end = series_in.groupby(pd.Grouper(freq='A')).apply(lambda x: x.index.week.unique().shape[0]).max()#range(53)\n                secondary_period = range(0,secondary_period_end+1)\n                \n            elif freq=='D':\n\n                secondary_period_end = max(series_in.groupby(pd.Grouper(freq='A')).apply(lambda x: x.shape[0]).max(),252)#idx.day.unique().sort_values()\n                secondary_period = range(0,secondary_period_end)\n                \n                \n            series_grouped = series_in.groupby(series_in.index.year)\n        \n            ret_perPeriod = pd.concat([series_grouped.get_group(i).reset_index(drop=True) for i in years], axis=1).T\n            ret_perPeriod.iloc[0]=ret_perPeriod.iloc[0].shift(ret_perPeriod.iloc[0].isna().sum()) #aligning the nan's as for the first year\n            ret_perPeriod.index = years\n            ret_perPeriod.columns = secondary_period\n        \n            plt.ylabel('Date')\n            plt.xlabel('Month')\n            plt.title('Return')\n            #heat_map = \n            sns.heatmap(ret_perPeriod,cbar_kws={'label': 'Colorbar', 'orientation': 'horizontal'}) # ,annot=True,) \n            \n            plt.show()\n            \n            # plot annualized\n           \n            annualized_perPeriod=(ret_perPeriod.T.replace(np.nan,0)+1).cumprod().iloc[-1,:]-1\n            \n            fig, ax = plt.subplots()\n            y_pos = np.arange(len(annualized_perPeriod))\n            \n            ax.barh(y_pos,annualized_perPeriod*100, align='center',alpha=0.6)\n            ax.set_yticks(y_pos)\n            ax.set_yticklabels(years)\n            ax.invert_yaxis()  # labels read top-to-bottom\n            ax.set_xlabel('Return  % ')\n            ax.set_title('Annual Return')\n            \n            plt.show()        \n              \n        elif freq == 'Y':\n            \n            years = idx.year\n            \n            fig, ax = plt.subplots()\n            y_pos = np.arange(len(series))\n            \n            ax.barh(y_pos,series*100, align='center',alpha=0.6)\n            ax.set_yticks(y_pos)\n            ax.set_yticklabels(years)\n            ax.invert_yaxis()  # labels read top-to-bottom\n            ax.set_xlabel('Return  % ')\n            ax.set_title('Annual Return')\n            \n            plt.show()\n    \n\n    return dict_table\n","6d4554b9":"data_path = '..\/input\/data-port\/'\ndata_daily = pd.read_excel(data_path+'sp500_daily.xlsx')\n\ndata_daily.index = pd.to_datetime(data_daily.Date)\nport_original_daily = data_daily['Price Close'].pct_change().iloc[1:]\nport_original_daily.name = 'SP500'\n\nhigh_daily = port_original_daily.shape[0]\nlen_port_daily = 252 * 10\nn_port = 1000\n\nmarket_daily = port_original_daily.iloc[-len_port_daily:]\n","4f9e6743":"# constructing portfolios\n\nidx_daily = np.random.randint(0,high_daily,(len_port_daily,n_port))   \n\ndf_port_rets_daily = pd.DataFrame(port_original_daily.values[idx_daily], columns = list(range(n_port)), index = list(range(len_port_daily))) \ndf_port_rets_daily.index = market_daily.index\n\ncorr_port_daily = df_port_rets_daily.corr().values[np.triu_indices(df_port_rets_daily.shape[1], k=1)]\nplt.figure(figsize=(10,10))\nprint(pd.Series(corr_port_daily).describe())\nplt.hist(corr_port_daily, bins=1000);\n\n#------------------------------------------------------------------------------","e5a20a78":"# monthly test\n\nmarket_monthly = (market_daily+1).groupby(pd.Grouper(freq='M')).apply(np.prod) - 1\n\n#data_rf_monthly = pd.read_excel('\/home\/research\/Desktop\/portfolio_metrics_project\/data\/M_TB3MS.xls')\n#data_rf_monthly = data_rf_monthly.iloc[:,1]\n\n#rf_monthly = data_rf_monthly.iloc[-len_port_monthly:] \/ 12\n#rf_monthly.index = market_monthly.index\n\nrf_monthly=True\n\n# constructing portfolios\n\n\ndf_port_rets_monthly = (df_port_rets_daily+1).groupby(pd.Grouper(freq='M')).apply(np.prod) - 1\n\ncorr_port_monthly = df_port_rets_monthly.corr().values[np.triu_indices(df_port_rets_monthly.shape[1], k=1)]\n# plt.subplot(2,2,2)\nprint(pd.Series(corr_port_monthly).describe())\nplt.hist(corr_port_monthly, bins=1000);\nplt.show()\n\n# calculating metrics\nport_metrics_monthly = df_port_rets_monthly.loc[:,:1].apply(lambda x: pd.Series(performance_metrics(x, market=market_monthly, rf=rf_monthly, freq='M')), axis=0).T  #visualization was made for only one portfolio\ncorr_port_metrics_monthly = port_metrics_monthly.corr()\nsns.heatmap(corr_port_metrics_monthly,cmap=\"YlGnBu\").set_title(\"corr_port_metrics_monthly\");","29f76f2c":"market_weekly = (market_daily+1).groupby(pd.Grouper(freq='W')).apply(np.prod) - 1\n\n#data_rf_weekly = pd.read_excel('\/home\/research\/Desktop\/portfolio_metrics_project\/data\/M_TB3MS.xls')\n#data_rf_weekly = data_rf_weekly.iloc[:,1]\n\n#rf_weekly = data_rf_weekly.iloc[-len_port_weekly:] \/ 12\n#rf_weekly.index = market_weekly.index\n\nrf_weekly=True\n\n# constructing portfolios\n\n\ndf_port_rets_weekly = (df_port_rets_daily+1).groupby(pd.Grouper(freq='W')).apply(np.prod) - 1\n\ncorr_port_weekly = df_port_rets_weekly.corr().values[np.triu_indices(df_port_rets_weekly.shape[1], k=1)]\n\nprint(pd.Series(corr_port_weekly).describe())\nplt.hist(corr_port_weekly, bins=1000)\n\n# calculating metrics\n\nport_metrics_weekly = df_port_rets_weekly.loc[:,:1].apply(lambda x: pd.Series(performance_metrics(x, market=market_weekly, rf=rf_weekly, freq='W')), axis=0).T #visualization was made for only one portfolio\n\ncorr_port_metrics_weekly = port_metrics_weekly.corr()\nsns.heatmap(corr_port_metrics_weekly,cmap=\"YlGnBu\").set_title(\"corr_port_metrics_weekly\");\n\n#------------------------------------------------------------------------------","35728d0c":"market_annual = (market_daily+1).groupby(pd.Grouper(freq='A')).apply(np.prod) - 1\n\n#data_rf_annual = pd.read_excel('\/home\/research\/Desktop\/portfolio_metrics_project\/data\/M_TB3MS.xls')\n#data_rf_annual = data_rf_annual.iloc[:,1]\n\n#rf_annual = data_rf_annual.iloc[-len_port_annual:] \/ 12\n#rf_annual.index = market_annual.index\n\nrf_annual=True\n\n# constructing portfolios\n\n\ndf_port_rets_annual = (df_port_rets_daily+1).groupby(pd.Grouper(freq='A')).apply(np.prod) - 1\n\ncorr_port_annual = df_port_rets_annual.corr().values[np.triu_indices(df_port_rets_annual.shape[1], k=1)]\n\nprint(pd.Series(corr_port_annual).describe())\nplt.hist(corr_port_annual, bins=1000)\n\n# calculating metrics\n\nport_metrics_annual = df_port_rets_annual.loc[:,:1].apply(lambda x: pd.Series(performance_metrics(x, market=market_annual, rf=rf_annual, freq='Y')), axis=0).T #visualization was made for only one portfolio\n\ncorr_port_metrics_annual = port_metrics_annual.corr()\nsns.heatmap(corr_port_metrics_annual,cmap=\"YlGnBu\").set_title(\"corr_port_metrics_annual\");","e4e3fe06":"# Annual test","a097822e":"# Weekly test\n","89c1fc22":"# Monthly test"}}