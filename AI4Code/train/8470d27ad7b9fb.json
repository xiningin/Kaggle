{"cell_type":{"5d602b82":"code","cb1bed10":"code","1beba6b7":"code","a24acd89":"code","117bd33c":"code","4328639e":"code","43bd236c":"code","0efd4f40":"code","9fb53434":"code","f0b467da":"code","499b67ba":"code","d598b1cf":"code","4c837219":"code","c63ef76e":"code","eb30ea6f":"code","15697cf2":"code","c0340d50":"code","0e0a8c81":"code","45b9c49d":"code","23c18592":"code","afa0cba3":"code","3d8145d8":"code","f15887b9":"code","0f3ea570":"code","bf54fbe0":"code","54f73e30":"code","727b8bea":"code","b2d775b3":"code","23ad1514":"code","c941880f":"code","1b62245e":"code","9f6f7164":"code","6d1f77ab":"code","0f0e0eda":"code","d16ddf53":"code","b8f5f9fa":"code","77726264":"code","f6a82ea3":"code","82f90bc2":"code","708b66c3":"code","30c4e5f8":"code","681d36e1":"code","ddf0ebea":"code","f3a807d2":"code","5f49ecb3":"code","ded269f0":"markdown","f8795715":"markdown","0c289c9b":"markdown","60c0c11b":"markdown","469a41f6":"markdown","8b56f77c":"markdown","1d907601":"markdown","8688716d":"markdown","53ada4df":"markdown","9eb7974d":"markdown","4ba66a68":"markdown","d1f9bb3a":"markdown","86e9e0ad":"markdown","eed6916a":"markdown","5ee53444":"markdown","d5ad0032":"markdown","7673ae83":"markdown","49a1e8ec":"markdown","c7a58f01":"markdown","1c3811da":"markdown","8c0707f2":"markdown","a3c87183":"markdown","a81e6026":"markdown"},"source":{"5d602b82":"import pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split","cb1bed10":"train = pd.read_csv('..\/input\/otus-rec-sys\/user_course_train.csv', index_col = 0)\ntrain.head()","1beba6b7":"train.info()","a24acd89":"# very low non-NAN values\nuser_course_blackout = ['partner_campaign_id','certificate_company_title_latin',\n                        'hidden_description','project_work_latin','subscription_id']\n\n# dates\nuser_course_blackout += [c for c in train.columns if c.find('date')>0]","117bd33c":"train_reduced = train.drop(user_course_blackout, axis=1)\nfor c in train_reduced.columns:\n    unique = len(train_reduced[c].unique())\n    if unique == 1:\n        user_course_blackout.append(c)\n    elif unique < 10:\n        vc = train_reduced[c].value_counts(dropna=False)\n        top_cnt = vc.values[0]\n        if top_cnt\/len(train_reduced)>.9:\n            print(f\"{c:25s}\\t{100*top_cnt\/len(train_reduced):.2f}% in {vc.index[0]}\")\n            user_course_blackout.append(c)","4328639e":"# manual filtering\nuser_course_blackout.append('id')\ntrain_reduced = train.drop(user_course_blackout, axis=1)","43bd236c":"object_columns = [train_reduced.columns[i] for i,dt in enumerate(train_reduced.dtypes) if dt==object]\nfor column in object_columns:\n    non_digit = [val for val in train_reduced[column] if not str(val).isdigit()]\n    if len(non_digit)\/len(train_reduced)<.1:\n        print(column,set(non_digit))\n    \n    non_digit = [val for val in train_reduced[column] if not str(val).replace('.','').isdigit()]\n    if len(non_digit)\/len(train_reduced)<.1:\n        print(column,set(non_digit))","0efd4f40":"train_reduced.loc[train_reduced.month_every_discount == '\\ufeff0','month_every_discount'] = 0\ntrain_reduced.month_every_discount = train_reduced.month_every_discount.astype(int)\ntrain_reduced.loc[train_reduced.full_discount == '0\\ufeff','full_discount'] = 0\ntrain_reduced.loc[train_reduced.full_discount == '6000\\ufeff','full_discount'] = 6000\ntrain_reduced.full_discount = train_reduced.full_discount.astype(int)\n\ntrain_reduced.loc[train_reduced.max_month_discount == '\\ufeff\"0.50\"','max_month_discount'] = 0.5\ntrain_reduced.max_month_discount = train_reduced.max_month_discount.astype(float)\ntrain_reduced.loc[train_reduced.max_total_discount == '0.2\\ufeff0','max_total_discount'] = 0.2\ntrain_reduced.max_total_discount = train_reduced.max_total_discount.astype(float)\ntrain_reduced.loc[train_reduced.step_percent_discount == '0\\ufeff.00','step_percent_discount'] = 0.0\ntrain_reduced.step_percent_discount = train_reduced.step_percent_discount.astype(float)","9fb53434":"object_columns = [train_reduced.columns[i] for i,dt in enumerate(train_reduced.dtypes) if dt==object]\nfor column in object_columns:\n    print(f\"{column}\\n{train_reduced[column].value_counts().iloc[:3]}\\n\")","f0b467da":"# manual filtering\nuser_course_blackout_2 = ['certificate_hash','certificate_path','certificate_path_en','created','tax_deduction_pdf_hash',\n                          'tax_deduction_pdf_path','tax_deduction_pdf_size','comment','useronlinecourse_applied_id']\ntrain_reduced = train_reduced.drop(user_course_blackout_2, axis=1)","499b67ba":"object_columns = [train_reduced.columns[i] for i,dt in enumerate(train_reduced.dtypes) if dt==object]\ntext_columns_train = ['project_work','certificate_company_title']","d598b1cf":"train_reduced.uid.value_counts()","4c837219":"train_reduced[train_reduced.uid=='367de0628b354f018975825439da0a05']","c63ef76e":"# seems some data issue - expect uid to be unique\ntrain_reduced = train_reduced[train_reduced.uid!='367de0628b354f018975825439da0a05'].drop('uid',axis=1)","eb30ea6f":"train_reduced.info()","15697cf2":"courses = pd.read_csv('..\/input\/otus-rec-sys\/course.csv', index_col = 0, sep = ';')\ncourses.head()","c0340d50":"# remove _id columns\ncourses = courses.drop([c for c in courses.columns if c.find('_id')>0],axis=1)","0e0a8c81":"for c in courses.columns:\n    print(c,end=', ')","45b9c49d":"courses_cherrypick_columns = ['salary','enabled','visible','title','created_date']\ncourses = courses[courses_cherrypick_columns]","23c18592":"print(courses.enabled.value_counts(dropna=False))\nprint(courses.visible.value_counts(dropna=False))","afa0cba3":"courses.reset_index(inplace=True)\ncourses.rename(columns={'id':'course_id'}, inplace=True)","3d8145d8":"assessments = pd.read_csv('..\/input\/otus-rec-sys\/assessment_train.csv', index_col = 0)\nassessments.head()","f15887b9":"assessments_cherrypick_columns = ['user_id','course_id','finish','mark','visible_mark','status']\nassessments = assessments[assessments_cherrypick_columns]\n\nassessments['is_finished'] = ~assessments.finish.isna()","0f3ea570":"assessments.finish[assessments['is_finished']][pd.to_datetime(assessments.finish[assessments['is_finished']], format='%d.%m.%Y %H:%M', errors='coerce').isna()]","bf54fbe0":"assessments.loc[31946,'finish'] = '10.02.2019 19:41'\nassessments.loc[43307,'finish'] = '28.06.2019 05:51'\nassessments.loc[73908,'finish'] = '26.01.2020 16:08'\nassessments.loc[157079,'finish'] = '28.12.202\ufeff0 17:05'\n\nassessments.loc[:,'finish'] = pd.to_datetime(assessments.finish, format='%d.%m.%Y %H:%M',errors='coerce')","54f73e30":"assessments.head()","727b8bea":"with open('..\/input\/otus-rec-sys\/test_ids.txt') as f:\n    test_ids = [int(id) for id in f.read().split('\\n') if len(id)>0]\nlen(test_ids)","b2d775b3":"ui_matrix = {}\nuser_in_db = {}\nsimilarity = {}\nmean_courses = {}\n\nmaps = {}","23ad1514":"# build user-itteractions matrix and calculate similarity\nui_matrix['all'] = pd.get_dummies(train_reduced[train_reduced.course_id.isin(courses.course_id)][['user_id','course_id']],columns=['course_id']).groupby('user_id').sum()\nuser_in_db['all'] = list(ui_matrix['all'].index)\n\nsimilarity['all'] = cosine_similarity(ui_matrix['all'])\n\n# get top 3 most popular courses\nmean_user = ui_matrix['all'].mean()\nmean_courses['all'] = [int(cid.replace('course_id_','')) for cid in mean_user.sort_values(ascending=False)[:3].index]\n\n# two lists of courses, which might be usefull in recommendation based on enabled and visible\nvisible_courses = courses[courses.visible==1].course_id.values\nenabled_courses = courses[np.logical_or(courses.enabled==1,courses.enabled.isna())].course_id.values","c941880f":"unique_users = train_reduced.user_id.unique()\ntrn_users, val_users = train_test_split(unique_users,test_size=.1,random_state=42)\n\n# split validation user into new and loyal\nval_users_as_new, val_users_as_loyal = train_test_split(val_users,test_size=.5,random_state=42)\n\n# new user - get all courses as GT\nval_taken_courses_as_new = (train_reduced[train_reduced.user_id.isin(val_users_as_new)].\n                                groupby('user_id').course_id.apply(lambda x: list(x.values)))\n# loyal user - get only last 3 courses as GT\nval_taken_courses_as_loyal = (train_reduced[train_reduced.user_id.isin(val_users_as_loyal)].\n                                groupby('user_id').course_id.apply(lambda x: list(x.values)[-3:]))\nval_taken_courses = pd.concat((val_taken_courses_as_new, val_taken_courses_as_loyal)).to_dict()\n\ntrain_for_val = (train_reduced[~train_reduced.apply(lambda x: x['user_id'] in val_taken_courses and x['course_id'] in val_taken_courses[x['user_id']], axis=1)])\n\n# build user-itteractions matrix and calculate similarity\nui_matrix['val'] = pd.get_dummies(train_for_val[train_for_val.course_id.isin(courses.course_id)][['user_id','course_id']],columns=['course_id']).groupby('user_id').sum()\nuser_in_db['val'] = list(ui_matrix['val'].index)\n\nsimilarity['val'] = cosine_similarity(ui_matrix['val'])\n\n# get top 3 most popular courses\nmean_user_for_val = ui_matrix['val'].mean()\nmean_courses['val'] = [int(cid.replace('course_id_','')) for cid in mean_user_for_val.sort_values(ascending=False)[:3].index]","1b62245e":"from ml_metrics import mapk\ndef validate(recommendations:list):\n    y_true = [val_taken_courses[uid] for uid,_ in recommendations]\n    y_pred = [pred for _,pred in recommendations]\n    mapk_ = mapk(y_true,y_pred,k=3)\n    print('MAP@3 =', round(mapk_,3))\n    return mapk_","9f6f7164":"def clean_ids(userid: int, mode:str)->list:\n    return [int(cid.replace('course_id_','')) for cid in ui_matrix[mode].loc[userid][ui_matrix[mode].loc[userid]==1].index]\n\ndef recommend_cbf(user_ids: list, whitelist_courses:list=None, mode:str='all')->list:\n    recommendations = []\n    for user_id in tqdm(user_ids):\n        recommended = []\n        passed_assessments = []\n        if user_id in assessments.user_id.values:\n            for recommendation in [int(cid) for cid in \n                                  (assessments[np.logical_and(assessments.user_id==user_id,assessments.visible_mark.isin(['A','B','C','D']))].\n                                       sort_values('finish', ascending=False).\n                                           course_id.\n                                               values)]:\n                if (whitelist_courses is None or recommendation in whitelist_courses):\n                    passed_assessments.append(recommendation)\n            \n\n        if user_id in user_in_db[mode]:\n            user_vector = similarity[mode][user_in_db[mode].index(user_id)]\n            done_courses = clean_ids(user_id,mode)\n            recommended += [cid for cid in passed_assessments if cid not in done_courses]\n            for each in user_vector.argsort()[-2::-1]:\n                for recommendation in clean_ids(user_in_db[mode][each],mode):\n                    if (recommendation not in done_courses and \n                        recommendation not in recommended and\n                        (whitelist_courses is None or recommendation in whitelist_courses)                        \n                       ):\n                        recommended.append(recommendation)\n                if len(recommended)>=3:\n                    break\n        else:\n            recommended += passed_assessments\n            recommended += mean_courses[mode]\n\n        recommended = recommended[:3]\n        recommendations.append((user_id,recommended))\n    return recommendations\n\nrec_to_val = recommend_cbf(val_users, mode='val')\nmaps['naive'] = validate(rec_to_val)\n\nrecommendations = recommend_cbf(test_ids)\n\nwith open('submission_cbf1.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","6d1f77ab":"total_recommended = 0\nnonvisible_recommended = 0\nfor each in recommendations:\n    for e in each[1]:\n        total_recommended += 1\n        nonvisible_recommended += e not in visible_courses\n\ntotal_recommended = 0\nnonenabled_recommended = 0\nfor each in recommendations:\n    for e in each[1]:\n        total_recommended += 1\n        nonenabled_recommended += e not in enabled_courses\nprint(f\"Total={total_recommended}, not visible={nonvisible_recommended}, not enabled={nonenabled_recommended}\")","0f0e0eda":"rec_to_val = recommend_cbf(val_users, visible_courses,mode='val')\nmaps['visible'] = validate(rec_to_val)\n\nrecommendations = recommend_cbf(test_ids, visible_courses)\ntotal_recommended = 0\nnonvisible_recommended = 0\nfor each in recommendations:\n    for e in each[1]:\n        total_recommended += 1\n        nonvisible_recommended += e not in visible_courses\nprint(total_recommended, nonvisible_recommended)\n\nwith open('submission_cbf2.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","d16ddf53":"rec_to_val = recommend_cbf(val_users, enabled_courses,mode='val')\nmaps['enabled'] = validate(rec_to_val)\n\nrecommendations = recommend_cbf(test_ids, enabled_courses)\ntotal_recommended = 0\nnonenabled_recommended = 0\nfor each in recommendations:\n    for e in each[1]:\n        total_recommended += 1\n        nonenabled_recommended += e not in enabled_courses\nprint(total_recommended, nonenabled_recommended)\n\nwith open('submission_cbf3.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","b8f5f9fa":"is_duplicated = 0\nfor each in recommendations:\n    if each[1][0]==each[1][1] or each [1][1]==each[1][2] or each[1][0]==each[1][2]:\n        is_duplicated += 1\nprint(f\"Total={len(recommendations)}, duplicated={is_duplicated}\")","77726264":"def nonduplicate_list(seq):\n    seen = set()\n    seen_add = seen.add\n    return [x for x in seq if not (x in seen or seen_add(x))]\n\ndef recommend_cbf_non_dup(user_ids: list, whitelist_courses:list=None, mode:str='all')->list:\n    recommendations = []\n    for user_id in tqdm(user_ids):\n        recommended = []\n        passed_assessments = []\n        if user_id in assessments.user_id.values:\n            for recommendation in [int(cid) for cid in \n                                  (assessments[np.logical_and(assessments.user_id==user_id,assessments.visible_mark.isin(['A','B','C','D']))].\n                                       sort_values('finish', ascending=False).\n                                           course_id.\n                                               values)]:\n                if (whitelist_courses is None or recommendation in whitelist_courses):\n                    passed_assessments.append(recommendation)\n        passed_assessments = nonduplicate_list(passed_assessments) \n\n        if user_id in user_in_db[mode]:\n            user_vector = similarity[mode][user_in_db[mode].index(user_id)]\n            done_courses = clean_ids(user_id,mode)\n            recommended += [cid for cid in passed_assessments if cid not in done_courses]\n            for each in user_vector.argsort()[-2::-1]:\n                for recommendation in clean_ids(user_in_db[mode][each],mode):\n                    if (recommendation not in done_courses and \n                        recommendation not in recommended and\n                        (whitelist_courses is None or recommendation in whitelist_courses)                        \n                       ):\n                        recommended.append(recommendation)\n                recommended = nonduplicate_list(recommended) \n                if len(recommended)>=3:\n                    break\n        else:\n            recommended += passed_assessments\n            recommended += mean_courses[mode]\n            recommended = nonduplicate_list(recommended)\n\n        recommended = recommended[:3]\n        recommendations.append((user_id,recommended))\n    return recommendations\n\nrec_to_val = recommend_cbf_non_dup(val_users,mode='val')\nmaps['non-duplicated'] = validate(rec_to_val)\n\nrecommendations = recommend_cbf_non_dup(test_ids)\n\nfor each in recommendations:\n    if each[1][0]==each[1][1] or each [1][1]==each[1][2] or each[1][0]==each[1][2]:\n        print (each)\n        \nwith open('submission_cbf4.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","f6a82ea3":"mean_courses['all'] = [int(cid.replace('course_id_','')) for cid in mean_user.sort_values(ascending=False).index][:5]\nmean_courses['val'] = [int(cid.replace('course_id_','')) for cid in mean_user_for_val.sort_values(ascending=False).index][:5]\n\ndef recommend_cbf_non_dup_rot5(user_ids: list, whitelist_courses:list=None, mode:str='all')->list:\n    recommendations = []\n    counter=1\n    for user_id in tqdm(user_ids):\n        recommended = []\n        passed_assessments = []\n        if user_id in assessments.user_id.values:\n            for recommendation in [int(cid) for cid in \n                                  (assessments[np.logical_and(assessments.user_id==user_id,assessments.visible_mark.isin(['A','B','C','D']))].\n                                       sort_values('finish', ascending=False).\n                                           course_id.\n                                               values)]:\n                if (whitelist_courses is None or recommendation in whitelist_courses):\n                    passed_assessments.append(recommendation)\n        passed_assessments = nonduplicate_list(passed_assessments) \n\n        if user_id in user_in_db[mode]:\n            user_vector = similarity[mode][user_in_db[mode].index(user_id)]\n            done_courses = clean_ids(user_id,mode)\n            recommended += [cid for cid in passed_assessments if cid not in done_courses]\n            for each in user_vector.argsort()[-2::-1]:\n                for recommendation in clean_ids(user_in_db[mode][each],mode):\n                    if (recommendation not in done_courses and \n                        recommendation not in recommended and\n                        (whitelist_courses is None or recommendation in whitelist_courses)                        \n                       ):\n                        recommended.append(recommendation)\n                recommended = nonduplicate_list(recommended) \n                if len(recommended)>=3:\n                    break\n        else:\n            recommended += passed_assessments\n            if counter%3==0:\n                recommended += mean_courses[mode][:2]\n                recommended.append(mean_courses[mode][4])\n            elif counter%2==0:\n                recommended += mean_courses[mode][:2]\n                recommended.append(mean_courses[mode][3])\n                \n            else:\n                recommended += mean_courses[mode][:3]\n            counter += 1\n            recommended = nonduplicate_list(recommended)\n\n        recommended = recommended[:3]\n        recommendations.append((user_id,recommended))\n    return recommendations\n\nrec_to_val = recommend_cbf_non_dup_rot5(val_users,mode='val')\nmaps['top5_rotation'] = validate(rec_to_val)\n\nrecommendations_rotation = recommend_cbf_non_dup_rot5(test_ids)\n\nwith open('submission_cbf6.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations_rotation:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","82f90bc2":"mean_anti_courses = {}\nmean_anti_courses['all'] = [int(cid.replace('course_id_','')) for cid in mean_user.sort_values(ascending=True).index][:20]\nmean_anti_courses['val'] = [int(cid.replace('course_id_','')) for cid in mean_user_for_val.sort_values(ascending=True).index][:20]\n\nmean_courses['all'] = [int(cid.replace('course_id_','')) for cid in mean_user.sort_values(ascending=False).index][:3]\nmean_courses['val'] = [int(cid.replace('course_id_','')) for cid in mean_user_for_val.sort_values(ascending=False).index][:3]\n\ndef recommend_cbf_non_dup_rot4(user_ids: list, whitelist_courses:list=None, mode:str='all')->list:\n    recommendations = []\n    counter=0\n    for user_id in tqdm(user_ids):\n        recommended = []\n        passed_assessments = []\n        if user_id in assessments.user_id.values:\n            for recommendation in [int(cid) for cid in \n                                  (assessments[np.logical_and(assessments.user_id==user_id,assessments.visible_mark.isin(['A','B','C','D']))].\n                                       sort_values('finish', ascending=False).\n                                           course_id.\n                                               values)]:\n                if (whitelist_courses is None or recommendation in whitelist_courses) and recommendation not in mean_anti_courses[mode]:\n                    passed_assessments.append(recommendation)\n        passed_assessments = nonduplicate_list(passed_assessments) \n\n        if user_id in user_in_db[mode]:\n            user_vector = similarity[mode][user_in_db[mode].index(user_id)]\n            done_courses = clean_ids(user_id,mode)\n            recommended += [cid for cid in passed_assessments if cid not in done_courses]\n            for each in user_vector.argsort()[-2::-1]:\n                for recommendation in clean_ids(user_in_db[mode][each],mode):\n                    if (recommendation not in done_courses and \n                        recommendation not in recommended and\n                        (whitelist_courses is None or recommendation in whitelist_courses)\n                        and recommendation not in mean_anti_courses[mode]\n                       ):\n                        recommended.append(recommendation)\n                recommended = nonduplicate_list(recommended) \n                if len(recommended)>=3:\n                    break\n        else:\n            recommended += passed_assessments\n            recommended += mean_courses[mode]\n            counter += 1\n            recommended = nonduplicate_list(recommended)\n        \n        recommended = recommended[:3]\n        recommendations.append((user_id,recommended))\n    return recommendations\n\nrec_to_val = recommend_cbf_non_dup_rot4(val_users,mode='val')\nmaps['bottom20_black'] = validate(rec_to_val)\n\nrecommendations_rotation4_black = recommend_cbf_non_dup_rot4(test_ids)\n\nwith open('submission_cbf7.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations_rotation4_black:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","708b66c3":"blacklist = ['\u0423\u0434\u0430\u043b\u0438\u0442\u044c','OTUS Teachers Workshops','\u0414\u043b\u044f \u0442\u0440\u0430\u043d\u0441\u043b\u044f\u0446\u0438\u0439 \u0431\u0435\u0437 \u0433\u0440\u0443\u043f\u043f','TeachTalkBar 21+','Data Engineer \u0434\u043b\u044f \u0420\u0430\u0439\u0444\u0444\u0430\u0439\u0437\u0435\u043d\u0431\u0430\u043d\u043a\u0430',\n             'DevOps \u0434\u043b\u044f \u0412\u0422\u0411','ELK_VTB','Devops \u0434\u043b\u044f \u041f\u043e\u0447\u0442\u044b \u0420\u043e\u0441\u0441\u0438\u0438','\u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u043c\u043e\u043d\u0438\u0442\u043e\u0440\u0438\u043d\u0433\u0430 Zabbix \u0434\u043b\u044f \u0420\u0430\u0439\u0444\u0444\u0430\u0439\u0437\u0435\u043d\u0431\u0430\u043d\u043a\u0430','IT-Recruiter \u0434\u043b\u044f \u041d\u0435\u043e\u0444\u043b\u0435\u043a\u0441',\n             'ELK intensive Rosbank','Vagrant \u0434\u043b\u044f \u041f\u043e\u0447\u0442\u044b \u0420\u043e\u0441\u0441\u0438\u0438','Git \u0434\u043b\u044f \u041f\u043e\u0447\u0442\u044b \u0420\u043e\u0441\u0441\u0438\u0438','\u0411\u0430\u0437\u043e\u0432\u044b\u0439 Linux \u0434\u043b\u044f \u041f\u043e\u0447\u0442\u0430 \u0420\u043e\u0441\u0441\u0438\u0438','\u0420\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a Java\\xa0(\u043e\u0447\u043d\u043e \u0432 \u041c\u0410\u0418)']\nmean_anti_courses['all'] += list(courses[courses.title.isin(blacklist)].course_id.values)\nmean_anti_courses['val'] += list(courses[courses.title.isin(blacklist)].course_id.values)\n\nrec_to_val = recommend_cbf_non_dup_rot4(val_users,mode='val')\nmaps['bottom20_black+manual'] = validate(rec_to_val)\n\nrecommendations_rotation4_black = recommend_cbf_non_dup_rot4(test_ids)\n\nwith open('submission_cbf8.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations_rotation4_black:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","30c4e5f8":"courses_reduced = courses[~courses.title.isin(blacklist)]","681d36e1":"groups = ['java','android','py','ruby','cpp','sec','devops','php','py','mng','tch','mng','tch','bd','devops','market','java','market','js',\n 'android','ui','qa','game','py','ui','mng','recruit','ios','mng','anal','ds','ds','spring','go','c#','qa','sql','ds','qa','mng','qa','ds','block','market','basis',\n 'mng','other','sec','sec','mng','sec','mng','market','market','market','market','market','mng','tch','sec','qa','qa','qa','sql','bd','devops','tch','basis',\n 'mng','sql','anal','sec','android','sec','market','devops','ds','anal','java','anal','sec','android','android','ios','tch','sec','web','cpp','devops',\n 'qa','qa','js','sql','sec','qa','ds','basis','basis','ds','mng','java','android','sql','devops','cpp','game','mng','sec','basis','qa','ds','mng','ds',\n 'py','ds','ds','devops','ds','kotlin','qa','devops','php','ds','basis','sec','devops','devops','devops','qa','devops','js','js','mng','c#','js','ds','recruit',\n 'qa','devops','devops','basis','java','java','basis','devops','game','devops','php','php','java','devops','go','mng','sql','1c','bd','ds','sec','basis',\n 'basis','py','devops','android','ds','basis','devops','qa','mng','iot','other','subscr','subscr','py','js','ds','sql','mng','mng','bd','js','java','qa','devops',\n 'devops','ios','js','c','mobile','ds','devops','sql','qa','devops','devops','devops','qa','game','tch','sql','mng','sql','tch','bd','mng','devops','devops','devops',\n 'devops','devops','anal','devops','devops','bd','bd','devops','c#','java','devops','devops','mng','ds','ds','ds','devops','bd']","ddf0ebea":"courses_reduced['group'] = groups\ncourses_reduced","f3a807d2":"def recommend_cbf_with_groups(user_ids: list, whitelist_courses:list=None, mode:str='all')->list:\n    recommendations = []\n    for user_id in tqdm(user_ids):\n        recommended = []\n        passed_assessments = []\n        groups = []\n        if user_id in assessments.user_id.values:\n            for recommendation in [int(cid) for cid in \n                                  (assessments[np.logical_and(assessments.user_id==user_id,assessments.visible_mark.isin(['A','B','C','D']))].\n                                       sort_values('finish', ascending=False).\n                                           course_id.\n                                               values)]:\n                if (whitelist_courses is None or recommendation in whitelist_courses):\n                    passed_assessments.append(recommendation)\n                    group = courses_reduced[courses_reduced.course_id==recommendation].group.values\n                    if len(group)>0:\n                        groups.append(group[0])\n            \n        recommended += nonduplicate_list(passed_assessments)\n        if user_id in user_in_db[mode]:\n            user_vector = similarity[mode][user_in_db[mode].index(user_id)]\n            done_courses = clean_ids(user_id,mode)\n            recommended += [cid for cid in passed_assessments if cid not in done_courses]\n            for each in user_vector.argsort()[-2::-1]:\n                for recommendation in clean_ids(user_in_db[mode][each],mode):\n                    if (recommendation not in done_courses and \n                        recommendation not in recommended and\n                        (whitelist_courses is None or recommendation in whitelist_courses)                        \n                       ):\n                        recommended.append(recommendation)\n                        group = courses_reduced[courses_reduced.course_id==recommendation].group.values\n                        if len(group)>0:\n                            groups.append(group[0])\n                if len(recommended)>=3+len(passed_assessments):\n                    break\n        else:\n            recommended += mean_courses[mode]\n        groups_couter = Counter(groups)\n        top_picks = []\n        for mc in groups_couter.most_common():\n            for i,g in enumerate(courses_reduced[courses_reduced.course_id.isin(recommended)].group.values):\n                if g==mc[0]:\n                    top_picks.append(recommended[i])\n        top_picks = nonduplicate_list(top_picks)\n        top_picks += [r for r in recommended if r not in top_picks]\n        recommended = nonduplicate_list(top_picks)[:3]\n        if len(recommended)!=3:\n            print(user_id,recommended,top_picks)\n        recommendations.append((user_id,recommended))\n    return recommendations\n\nrec_to_val = recommend_cbf_with_groups(val_users,mode='val')\nmaps['groups'] = validate(rec_to_val)\n\nrecommendations = recommend_cbf_with_groups(test_ids)\n\nwith open('submission_cbf_groups.csv','w') as f:\n    f.write(f\"Id,Predicted\\n\")\n    for each in recommendations:\n        f.write(f\"{each[0]},{each[1][0]} {each[1][1]} {each[1][2]}\\n\")","5f49ecb3":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\nmaps_sorted = {s:maps[s] for s in sorted(maps,key=lambda x: maps[x])}\nsns.set_theme(style=\"whitegrid\")\nplt.figure(figsize=(15,7))\nplt.title('Validation mAP for different models')\nax = sns.barplot(y=list(maps_sorted.keys()), x=list(maps_sorted.values()))","ded269f0":"# Summary","f8795715":"Some of the columns has id, hashes, filenames, etc. - this will be filtered manually.","0c289c9b":"## user_course_train","60c0c11b":"Again data input isssue - need a manual fix","469a41f6":"Since courses is more a metadata for this task I'll just cherry-pick columns of interest.","8b56f77c":"Some of columns contain very high concentration in only one column value - this will be aslo filtered out as low-informative.","1d907601":"# Data exploration and preparation","8688716d":"## assessment_train","53ada4df":"Quality down - need a better refined skill graph to achieve goals","9eb7974d":"# Cosine-similarity recommendations","4ba66a68":"Some recommednatios are duplicated - need improvement","d1f9bb3a":"Assessments data will be used as a supplimentary, so again cherry-pick approach","86e9e0ad":"Again not helpfull - might be old test set where non-visible\/disabled is not true for that time period","eed6916a":"Some courses recommended are not visible or enabled anymore, need a fix","5ee53444":"Two columns 'enabled' and 'visible' might be important filtering criteria - need to look into further on modeling.","d5ad0032":"According to validation mAP and also Public Score on Kaggle approach with removing duplicates and blacklisting least popular courses shows better results.\n\nStill model is suffering from 2 major problems:\n- Overfitting: since data is the model here and generalization is hardly possible\n\n  Overfitting can be solved by implementing more complex model. Due to poor experience with RecSys my attempts with, for instance, LightFM didn't give better results on Leaderboard.\n- Cold start: new user always get most popular courses as a recommendation, if they didn't take any assessments.\n\n  In real-life scenarios system, probably, will have additional user context (at least web-metrics) which can be used to better recommend to new users.\n  \nApproach with groups failed, but it still might be benefitial for OTUS to invest time of experts into building a Skill Graph for available courses, so gaps can be identified and also learning paths can be defined.","7673ae83":"Some columns has data input error for int\/float columns - need a manual fix.","49a1e8ec":"Didn't help - let's try with enabled==(1 or None)","c7a58f01":"Depending on the algorithm to be used a Null handling might be required.","1c3811da":"## course","8c0707f2":"### Try LearningGraph","a3c87183":"Many columns have very low non-nan count, it was decided to exclude those as poor-informative.\nSame applies to dates since they are not usefull for distance calculation in general case.","a81e6026":"## test_ids"}}