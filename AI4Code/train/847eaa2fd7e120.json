{"cell_type":{"e467c99d":"code","54bfc55e":"code","87a5f2be":"code","61a44191":"code","af29070e":"code","4884791d":"code","faee2b54":"markdown","df1507bb":"markdown","e25b6b97":"markdown","e6d179b4":"markdown","b9d0508b":"markdown","97e7a05a":"markdown"},"source":{"e467c99d":"# Internet ON\n!pip install simpletransformers==0.41.2\n","54bfc55e":"# Internet OFF\n# !pip install '\/kaggle\/input\/simple-transformers-pypi\/seqeval-0.0.12-py3-none-any.whl' -q\n# !pip install '\/kaggle\/input\/simple-transformers-pypi\/simpletransformers-0.22.1-py3-none-any.whl' -q","87a5f2be":"import json\n\ntrain_data = list()\n\nimport pandas as pd\n\ntrain = pd.read_csv('..\/input\/tweet-sentiment-extraction\/train.csv')\n\nfor id, row in train.iterrows():\n    template = {\n        'context': \"\",\n        'qas': [\n            {\n                'id': \"\",\n                'is_impossible': False,\n                'question': \"\",\n                'answers': [\n                    {\n                        'text': \"\",\n                        'answer_start': 0\n                    }\n                ]\n            }\n        ]\n    }\n\n    template['context'] = str(row['text'])\n    template['qas'][0]['id'] = row['textID']\n    template['qas'][0]['question'] = row['sentiment']\n    template['qas'][0]['answers'][0]['text'] = str(row['selected_text'])\n    try:\n        template['qas'][0]['answers'][0]['answer_start'] = row['text'].index(row['selected_text'])\n    except AttributeError:\n        print(id, row['text'], row['selected_text'])\n\n    train_data.append(template)\n\nwith open('train_processed.json', 'w') as f:\n    json.dump(train_data, f)","61a44191":"import json\n\ntrain_data = list()\n\nimport pandas as pd\n\ntrain = pd.read_csv('..\/input\/tweet-sentiment-extraction\/test.csv')\n\nfor id, row in train.iterrows():\n    template = {\n        'context': \"\",\n        'qas': [\n            {\n                'id': \"\",\n                'is_impossible': False,\n                'question': \"\",\n                'answers': [\n                    {\n                        'text': \"\",\n                        'answer_start': 0\n                    }\n                ]\n            }\n        ]\n    }\n\n    template['context'] = str(row['text'])\n    template['qas'][0]['id'] = row['textID']\n    template['qas'][0]['question'] = row['sentiment']\n    train_data.append(template)\n\nwith open('test_processed.json', 'w') as f:\n    json.dump(train_data, f)","af29070e":"# arch = 'albert'\n# m = '\/kaggle\/input\/pretrained-albert-pytorch\/albert-large-v1'\n\narch = 'distilbert'\nm = '\/kaggle\/input\/transformers-pretrained-distilbert\/distilbert-base-uncased-distilled-squad\/'","4884791d":"from simpletransformers.question_answering import QuestionAnsweringModel\nimport json\nimport os\nimport logging\n\n\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)\n\nwith open('train_processed.json', 'r') as f:\n    train_data = json.load(f)\n\ntrain_args = {\n    'use_multiprocessing': False,\n#     'use_early_stopping': True,\n#     'early_stopping_patience': 7,\n    'weight_decay': 0.000001,\n    'do_lower_case': False,\n    \"wandb_project\": False,\n    'learning_rate': 2e-5,\n    'num_train_epochs': 2,\n    'max_seq_length': 384,\n    'doc_stride': 128,\n    'overwrite_output_dir': True,\n    'reprocess_input_data': False,\n    'train_batch_size': 8,\n    'gradient_accumulation_steps': 2,\n    'save_steps': 0,\n    'fp16': False,\n    'save_eval_checkpoints': False,\n    'save_model_every_epoch': False\n}\n\n# m = 'outputs\/best_model'\n# m = 'outputs\/checkpoint-1644-epoch-2'\n\n# Create the QuestionAnsweringModel\nmodel = QuestionAnsweringModel(arch, m,\n                               args=train_args,\n                               use_cuda=True\n                               )\n\n# Train the model with JSON file\n# model.train_model()\n\nmodel.train_model(train_data)\n\n\nwith open('test_processed.json', 'r') as f:\n    test_data = json.load(f)\n\nimport pandas as pd\npred = model.predict(test_data)\n\nfinal_output = list()\n\nfor p in pred:\n    idText = p['id']\n    answer = '\"' + p['answer'] + '\"'\n    out = {'textID': idText, 'selected_text': answer}\n    final_output.append(out)\n    \nout_df = pd.DataFrame(final_output)\nout_df.to_csv('submission.csv', index=False)","faee2b54":"# Prepare Test Corpus","df1507bb":"# Prepare Training corpus","e25b6b97":"# Install dependencies","e6d179b4":"# Add dependency as the dataset to run it offeline for Submission\n* [Simple transformers PyPI](https:\/\/www.kaggle.com\/jonathanbesomi\/simple-transformers-pypi)","b9d0508b":"# Preprocess the data converting the formate similar to squad data","97e7a05a":"# Create model and run the training\n**Note:** To run the training offline you need to add the models as the Dataset using- \n* [ALBERT](https:\/\/www.kaggle.com\/radream\/pretrained-albert-pytorch)\n* [DISTILBERT](https:\/\/www.kaggle.com\/jonathanbesomi\/transformers-pretrained-distilbert)"}}