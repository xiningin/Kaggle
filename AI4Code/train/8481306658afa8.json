{"cell_type":{"2244f3d1":"code","fd2c40b2":"code","7c71d9b6":"code","b02d901a":"markdown","b9bb1e97":"markdown","f2afd12d":"markdown","f2ac4a9b":"markdown","51a7200b":"markdown","58053eb6":"markdown","9b3ee807":"markdown","3fe01e05":"markdown"},"source":{"2244f3d1":"import os\nimport cv2\nimport sys\nimport random\nimport math\nimport re\nimport time\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport skimage\nimport glob\nimport keras\nfrom mrcnn import utils\nfrom mrcnn import visualize\nfrom mrcnn.visualize import display_images\nimport mrcnn.model as modellib\nfrom mrcnn.model import log\n# Root directory of the project\nROOT_DIR = os.getcwd()\n\n# Import Mask RCNN\nsys.path.append(ROOT_DIR)  # To find local version of the library\n\ncustom_WEIGHTS_PATH = sorted(glob.glob(\"\/content\/drive\/My Drive\/nature.h5\"))[-1]\n\n%matplotlib inline \n\n# Directory to save logs and trained model\nMODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n\n\nclass InferenceConfig(config.__class__):\n    # Run detection on one image at a time\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\nconfig = InferenceConfig()\nconfig.display()\n\n# Device to load the neural network on.\n# Useful if you're training a model on the same \n# machine, in which case use CPU and leave the\n# GPU for training.\nDEVICE = \"\/gpu:0\"  # \/cpu:0 or \/gpu:0\n\n# Inspect the model in training or inference modes\n# values: 'inference' or 'training'\n# TODO: code for 'training' test mode not ready yet\nTEST_MODE = \"inference\"\n\ndef get_ax(rows=1, cols=1, size=16):\n    \"\"\"Return a Matplotlib Axes array to be used in\n    all visualizations in the notebook. Provide a\n    central point to control graph sizes.\n    \n    Adjust the size attribute to control how big to render images\n    \"\"\"\n    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n    return ax\n  \n# Load validation dataset\n#dataset = nature.natureDataset()\n#dataset.load_nature(custom_DIR, \"val\")\n\n# Must call before using the dataset\n#dataset.prepare()\n\n#print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n\n# Create model in inference mode\nwith tf.device(DEVICE):\n    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n                              config=config)\n\n# load the last model you trained\n# weights_path = model.find_last()[1]\n\n# Load weights\nprint(\"Loading weights \", custom_WEIGHTS_PATH)\nmodel.load_weights(custom_WEIGHTS_PATH, by_name=True)\n\nfrom importlib import reload # was constantly changing the visualization, so I decided to reload it instead of notebook\nreload(visualize)\n\nimport cv2\n#path = '\/content\/drive\/My Drive\/images\/000000.png'\n #img = image.load_img(path, target_size=(150, 150))\n  #x = image.img_to_array(img)\n  #x = np.expand_dims(x, axis=0)\n#image = skimage.io.imread(path)\nimage=cv2.imread('\/root\/Mask_RCNN-Multi-Class-Detection\/mkdb\/nature\/train\/glacier_images_135.jpg',1)\nprint(image.shape)\nresults = model.detect([image], verbose=1)\n# Visualize results\nr = results[0]\n\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n                              dataset.class_names, r['scores'])\n#int(type[dataset.c_ss_names[r['class_ids'][0]]])\n\n\nlabel=dataset.class_names[r['class_ids'][0]]+'   score:'+str(r['scores'][0])\n\n\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.models import load_model\nmodel = Sequential()\nmodel = load_model('\/content\/natureghc.h5')\n\n\n\n\nimport os\nimport cv2\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\n\n\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\n\n\n\n\n\n\nobj_id=np.array([7,9,10])\nobj_id2=np.array([2,5])\nobj_id3=np.array([1])\nobj_id4=np.array([4])\nobj_id5=np.array([3])\n\ncount=np.zeros(max(r['class_ids'])+1,dtype=int)\n\nfor x in (r['class_ids']):\n  for y in obj_id:\n    if (x==y):\n      count[x]=count[x]+1\n\ncount2=0\nfor x in range(max(r['class_ids'])+1):\n    \n    if count[x]>=1:\n      count2=count2+1\n\n     \n\nif count2>=(len(obj_id)\/2):\n  print('street')\nelse:\n  count=np.zeros(max(r['class_ids'])+1,dtype=int)\n\n  for x in (r['class_ids']):\n    for y in obj_id2:\n      if (x==y):\n        count[x]=count[x]+1\n  \n  count2=0\n  for x in range(max(r['class_ids'])+1):\n    \n      if count[x]>=1:\n        count2=count2+1\n\n     \n \n  if count2>=(len(obj_id2)\/2):\n    print('mountain')\n  else:\n    count=np.zeros(max(r['class_ids'])+1,dtype=int)\n    for x in (r['class_ids']):\n       for y in obj_id3:\n          if (x==y):\n            count[x]=count[x]+1\n  \n    count2=0\n    for x in range(max(r['class_ids'])+1):\n    \n       if count[x]>=1:\n          count2=count2+1\n\n     \n \n    if count2>=(len(obj_id3)\/2):\n        print('forest')\n    else:\n        count=np.zeros(max(r['class_ids'])+1,dtype=int)\n        for x in (r['class_ids']):\n          for y in obj_id4:\n             if (x==y):\n               count[x]=count[x]+1\n  \n        count2=0\n        for x in range(max(r['class_ids'])+1):\n    \n          if count[x]>=1:\n            count2=count2+1\n\n     \n \n        if count2>=(len(obj_id4)\/2):\n          print('glacier')\n        else:\n          count=np.zeros(max(r['class_ids'])+1,dtype=int)\n          for x in (r['class_ids']):\n             for y in obj_id5:\n                if (x==y):\n                   count[x]=count[x]+1\n  \n          count2=0\n          for x in range(max(r['class_ids'])+1):\n    \n             if count[x]>=1:\n                count2=count2+1\n\n     \n \n          if count2>=(len(obj_id5)\/2):\n             print('sea')\n          else:\n             print('could not find')\n     \n  \n  from google.colab.patches import cv2_imshow\n  cv2_imshow(image)\n      \n  \n","fd2c40b2":"from IPython.display import Image\nimport os\n!ls ..\/input\/result","7c71d9b6":"Image(\"..\/input\/result\/result.png\")","b02d901a":"**EXISTING MODELS**\n\n    In recent years, many models to perform scene recognition have been proposed. To name a few:\n\n1. Deep Bolzmann Machines (DBM)\n2. Multi-spectral SIFT (MSIFT)\n3. Spatial Pyramid Matching\n4. MSIFT and kernel based classifier\n\n**ISSUES IN EXISTING MODELS**\n\n    These models are mostly based on surface feature extraction. Surface features like colour and texture have  been mostly used. The above mentioned features have some limitations. These features neglect hidden information of images.\n    \n    With these features we cannot assure that all  internal characteristics of images can be extracted. So, for recognition of different scenes, different features have to be chosen and also different methods have to be developed.","b9bb1e97":"**REFERENCES**\n\n1. https:\/\/www.kaggle.com\/ad271828\/alexnet-pytorch-scene-classification\n\n2. https:\/\/www.kaggle.com\/manhnguyenthe\/jackmon\n\n3. https:\/\/www.kaggle.com\/vnygupta\/intelscene\n\n4. https:\/\/www.kaggle.com\/kerneler\/starter-scene-classification-f8c0e826-e\n\n5. https:\/\/www.kaggle.com\/aiswaryaramachandran\/image-scene-classification-transfer-learning","f2afd12d":"**MENTOR:** \nDr.M.NIRMALA DEVI,CSE DEPT.,THIAGARAJAR COLLEGE OF ENGINEERING,MADURAI\n\n**DONE BY:**\nR.P. MAHALAKSHMI - 18D059\nS. NAVEEN KUMAR - 18D069\nS. NIRMAL SELVA - 18D070","f2ac4a9b":"**CODE**","51a7200b":"**CONCLUSION**\n\n    In this mini-project a deep learning based natural scenery recognition model is proposed. Our approach involves multiple object detection using Mask RCNN and Integration of the result from Mask RCNN using  an Image Classifier and recognizing the overall scene. This natural scenery recognition model can be used in Automatic driving,  robot navigation,etc.","58053eb6":"**INTRODUCTION**\n\n    Understanding the world in a single glance is one of the most accomplished feats of human brain. Our brain takes only a few tens of milliseconds to recognize the category of an object or environment. Great progress in computer vision has been made towards human level scene recognition because of the development of deep neural networks and large scale image datasets. Deep learning based approach helps to narrow the gap between computer and  human beings on scene understanding. Thus, scene recognition has an abundance of applications in fields of computer vision and multimedia on a global scale.","9b3ee807":"**PYTHON CONCEPTS AND PACKAGES USED**\n  \nClass\nFunctions\nObjects\nNumpy\nPandas\nKeras\nGlob\nSkimage\nVisualize\nMatplotlib\nConditional Statements\nLooping Statements\nTypecasting","3fe01e05":"**PROBLEM STATEMENT**\n\n    Identification of sceneries in the given images based on the occurrence of objects.\n   \n**OBJECTIVES**\n\n    To help strengthen developings fields such as automated driving and robot navigation\n   \n    To perform Image classification for websites with large visual databases"}}