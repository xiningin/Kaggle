{"cell_type":{"d357760a":"code","d5db9a15":"code","cc8538b0":"code","8704f15b":"code","112764c7":"code","d37371e1":"code","ea8f47da":"code","508691a4":"code","8ae39354":"code","80ed9fee":"code","81c35b90":"code","bfc4e624":"code","c3705515":"code","60df76e4":"code","9d6f341a":"code","255fd73f":"code","30352bae":"code","21069314":"code","cfdbd015":"code","74318ad3":"code","c8453587":"code","7936f8c4":"code","c9690003":"code","1ddb4cf7":"code","7c3aa9ce":"code","620c352f":"code","9819008a":"code","cd9b5225":"code","547b989b":"code","29267bb2":"code","78f3b9b4":"code","19a59a13":"code","ba832c3e":"code","5a71b0ea":"code","25f857d7":"code","35633dbf":"markdown","f61842af":"markdown","abc14b5e":"markdown","229cf1bc":"markdown","dde346dd":"markdown","26b5a432":"markdown"},"source":{"d357760a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5db9a15":"import numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.preprocessing.image import load_img, array_to_img, img_to_array, ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import *\nimport os\nimport cv2","cc8538b0":"img = cv2.cvtColor(cv2.imread('\/kaggle\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/collages\/Kata_F2_C1_00405.jpg'), cv2.COLOR_BGR2RGB)","8704f15b":"imgs_dir = '\/kaggle\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/images'\nmasks_dir = '\/kaggle\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/masks'","112764c7":"load_img(os.path.join(imgs_dir, os.listdir(imgs_dir)[0]), target_size = (256, 256, 3))","d37371e1":"load_img(os.path.join(masks_dir, os.listdir(masks_dir)[0]), target_size = (256, 256, 1))","ea8f47da":"imgs_arr = np.zeros((len(os.listdir(imgs_dir)), 256, 256, 3), dtype = np.float32)\nmasks_arr = np.zeros((len(os.listdir(masks_dir)), 256, 256, 1), dtype = np.bool)","508691a4":"for index in range(len(os.listdir(imgs_dir))):\n    img = load_img(os.path.join(imgs_dir, os.listdir(imgs_dir)[index]), target_size = (256, 256, 3))\n    imgs_arr[index] = img_to_array(img)\n","8ae39354":"for index in range(len(os.listdir(masks_dir))):\n    img = load_img(os.path.join(masks_dir, os.listdir(masks_dir)[index]), target_size = (256, 256, 1), color_mode=\"grayscale\" )\n    masks_arr[index] = img_to_array(img)","80ed9fee":"plt.imshow(masks_arr[1])","81c35b90":"plt.imshow(array_to_img(imgs_arr[1]))","bfc4e624":"X_train, X_test = imgs_arr[:int(len(imgs_arr) * 0.80)], imgs_arr[int(len(imgs_arr) * 0.80):]\ny_train, y_test = masks_arr[:int(len(masks_arr) * 0.80)], masks_arr[int(len(masks_arr) * 0.80):]","c3705515":"import tensorflow as tf\n\n\nmodel = Sequential()\n\nmodel.add(Lambda(lambda x: x \/ 255))\nmodel.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', input_shape=(256, 256, 3)))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', ))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', ))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\nmodel.add(BatchNormalization())\n \nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', ))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', ))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', ))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Conv2D(1, (1,1), activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])","60df76e4":"model.fit(X_train, y_train, epochs = 20, batch_size = 32, validation_data = (X_test, y_test))","9d6f341a":"model.evaluate(X_test, y_test)","255fd73f":"array_to_img(imgs_arr[0])","30352bae":"array_to_img(model.predict(imgs_arr[0].reshape((1, 256, 256,3))).reshape((256, 256, 1)))","21069314":"array_to_img(masks_arr[0])","cfdbd015":"import cv2\n\nimage = np.asarray(load_img('\/kaggle\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/images\/HipHop_HipHop1_C0_00180.png'), dtype = 'uint8')\n\n# here should be output from model (mask) just now I haven't time to train the model, sorry, and I use ready-made images\n\ngray = img_to_array(load_img('\/kaggle\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/masks\/HipHop_HipHop1_C0_00180.png', target_size = (384, 512, 1), color_mode=\"grayscale\" )).reshape((384, 512)).astype('uint8')\n\n_, binary = cv2.threshold(gray, 254, 255, cv2.THRESH_BINARY)\n\nblack_back_img = image * np.asarray(binary \/ 255, dtype = 'uint8').reshape(384, 512, 1)","74318ad3":"_, anti_img = cv2.threshold(black_back_img, 1, 255, cv2.THRESH_BINARY)","c8453587":"plt.imshow(black_back_img)","7936f8c4":"white_back_binary = np.ones(shape = (anti_img.shape)) - anti_img","c9690003":"plt.imshow(white_back_binary)","1ddb4cf7":"target_img = img_to_array(load_img('\/kaggle\/input\/zakatasoihbaksvbsdkvjbsdkjbvsdkjvbsdljvbsd\/zakat.jpg'), dtype = 'uint8')","7c3aa9ce":"second_part = array_to_img(\n    img_to_array(array_to_img(white_back_binary).resize((256, 256))) * img_to_array(array_to_img(image).resize((256, 256))))","620c352f":"plt.imshow(second_part)","9819008a":"third_part = img_to_array(array_to_img(black_back_img).resize((256, 256))).astype('uint8') + img_to_array(array_to_img(white_back_binary).resize((256, 256))).astype('uint8')\n          ","cd9b5225":"plt.imshow(third_part)","547b989b":"collage= np.zeros(shape = (256, 256 * 3, 3), dtype = 'uint8')","29267bb2":"collage[:, :256] = img_to_array(array_to_img(image).resize((256, 256)))\ncollage[:, 256 : 256 * 2] = second_part\ncollage[:, 256 * 2: 256 * 3] = third_part","78f3b9b4":"array_to_img(collage)","19a59a13":"# put everything here\n\n#  function takes original image and mask asnd return collage\n# instead path to mask here should be output from model (mask) just now I haven't time to train the model, sorry, and I use ready-made images\n\ndef make_collage(image_path, mask_path):\n    \n    import cv2\n    \n#     original image\n    image = np.asarray(load_img(image_path), dtype = 'uint8')\n#     mask - output of your model(neural network)\n    gray = img_to_array(load_img(mask_path, target_size = (384, 512, 1), color_mode=\"grayscale\" )).reshape((384, 512)).astype('uint8')\n# binarization\n    _, binary = cv2.threshold(gray, 254, 255, cv2.THRESH_BINARY)\n\n    black_back_img = image * np.asarray(binary \/ 255, dtype = 'uint8').reshape(384, 512, 1)\n\n    _, anti_img = cv2.threshold(black_back_img, 1, 255, cv2.THRESH_BINARY)\n\n    white_back_binary = np.ones(shape = (anti_img.shape)) - anti_img\n\n    second_part = array_to_img(\n        img_to_array(array_to_img(white_back_binary).resize((256, 256))) * img_to_array(array_to_img(image).resize((256, 256))))\n\n    third_part = img_to_array(array_to_img(black_back_img).resize((256, 256))).astype('uint8') + img_to_array(array_to_img(white_back_binary).resize((256, 256))).astype('uint8')\n\n    collage= np.zeros(shape = (256, 256 * 3, 3), dtype = 'uint8')\n\n    collage[:, :256] = img_to_array(array_to_img(image).resize((256, 256)))\n    collage[:, 256 : 256 * 2] = second_part\n    collage[:, 256 * 2: 256 * 3] = third_part\n\n    array_to_img(collage)\n    \n    return collage","ba832c3e":"\n\nfourth_part =  array_to_img(\n        img_to_array(array_to_img(target_img).resize((256, 256))) + img_to_array(array_to_img(black_back_img).resize((256, 256))).astype('uint8')\n    )\n","5a71b0ea":"array_to_img(fourth_part)","25f857d7":"collage1= np.zeros(shape = (256, 256 * 4, 3), dtype = 'uint8')\ncollage1[:, :256] = img_to_array(array_to_img(image).resize((256, 256)))\ncollage1[:, 256 : 256 * 2] = second_part\ncollage1[:, 256 * 2: 256 * 3] = third_part\ncollage1[:, 256 * 3: 256 * 4] = fourth_part\n\n\narray_to_img(collage1)","35633dbf":"Honestly I didn't write many comments because here so many illustrations that it doesn't necessary","f61842af":"model gives 99.4% accuracy U can check this","abc14b5e":"predicted mask","229cf1bc":"original mask","dde346dd":"I made a function for this processing","26b5a432":"original image"}}