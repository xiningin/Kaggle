{"cell_type":{"84a6e901":"code","d1df8339":"code","ee778003":"code","1f560306":"code","0f7d0395":"code","f265bece":"code","b11b1a53":"code","5985b9d2":"code","6b213a66":"code","eb86962f":"code","55f018e3":"code","4d476280":"code","db2fcd5b":"code","6b8f825a":"code","95488da0":"markdown","00abe91a":"markdown"},"source":{"84a6e901":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf \nfrom tensorflow import keras\nimport urllib.request\nimport matplotlib.pyplot as plt\n","d1df8339":"def getImagesFromDirectory(train_data_gen, validation_data_gen, directory, image_size=(180,180), batch_size=12, shuffle=True):\n    train_dataset = train_data_gen.flow_from_directory(directory,\n                                                    target_size=image_size, \n                                                    batch_size=batch_size,\n                                                    subset='training',\n                                                    class_mode='categorical',\n                                                    shuffle=True,\n                                                    seed=123)\n    validation_dataset = validation_data_gen.flow_from_directory(directory,\n                                                          target_size=image_size,\n                                                          batch_size=batch_size,\n                                                          shuffle=True,\n                                                          subset='validation',\n                                                          class_mode='categorical',\n                                                          seed=123)\n    return train_dataset, validation_dataset","ee778003":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.1)\nvalidate_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.1)\n\n## get the dataset from directory\ntrain_dataset, validation_dataset = getImagesFromDirectory(\n            train_data_gen=train_datagen,\n            validation_data_gen=validate_datagen,\n            directory='\/kaggle\/input\/natural-images\/natural_images')","1f560306":"def create_model2(input_shape, pool_size=(2,2)):\n    \n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape = input_shape, activation = 'relu'))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size = pool_size))\n    \n    model.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape = input_shape, activation = 'relu'))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size = pool_size))\n    \n    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size = pool_size))\n    ## reshape tensor shapes \n    model.add(tf.keras.layers.Flatten())\n    ## Connect all perceptrons densly to 128 new perceptron in the new layer\n    model.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n    num_classes = 8\n    ## Connect all perceptrons densly to 20 new perceptron in the output layer\n    model.add(tf.keras.layers.Dense(units = num_classes, activation = 'softmax'))\n    \n    return model    \nmodel = create_model2(input_shape=(180,180) + (3,))\nkeras.utils.plot_model(model, show_shapes=True)","0f7d0395":"## Custom functions to check scores\nfrom keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","f265bece":"## Run the model with number of epochs\nepochs = 5\n\n## save the model found in each iteration\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"model_save_at_{epoch}.h5\"),\n]\nmodel.compile(\n    optimizer='adam',\n    loss=\"categorical_crossentropy\",\n    metrics=[\"categorical_accuracy\",f1_m, precision_m, recall_m],\n)\n## Train the model and get the history\nhistory = model.fit(\n    train_dataset, epochs=epochs, callbacks=callbacks,\n    validation_data=validation_dataset\n)","b11b1a53":"link = \"https:\/\/scontent-frt3-1.cdninstagram.com\/v\/t51.2885-15\/e35\/203937871_516266329513830_4919080390915015277_n.jpg?_nc_ht=scontent-frt3-1.cdninstagram.com&_nc_cat=106&_nc_ohc=RS-_f8P_TtUAX_YqnpP&edm=ALQROFkBAAAA&ccb=7-4&ig_cache_key=MjYwMDA1NDQzODM3NjAzNzI4NA%3D%3D.2-ccb7-4&oh=00_AT8tjFK75dFaQefVq7L_BnDW3ZFsSA4vBKcCAm4z_uloUg&oe=61F4D389&_nc_sid=30a2ef\"\n\nurllib.request.urlretrieve(link, '\/kaggle\/working\/image.jpg' )\n","5985b9d2":"!ls","6b213a66":"img = image.load_img('image.jpg', target_size=(180,180))\nnp.array(img).shape\n","eb86962f":"img = tf.keras.preprocessing.image.img_to_array(img)\nimg = np.expand_dims(img, axis = 0)\n\nmodel.predict(img)","55f018e3":"!pwd","4d476280":"## because we used some custom objects during training process, To load the model we need to mention them in load_model function\ncustom_objects={\"recall_m\": recall_m, \"precision_m\": precision_m, \"f1_m\": f1_m}\n\n## we have loaded the model in epoch 3 because its accuracy is better than other epochs\n## Note: epoch meaning the iteration over all images\nmodel_ = keras.models.load_model('.\/model_save_at_3.h5', custom_objects)","db2fcd5b":"## load the image we have downloaded\n\nimg = keras.preprocessing.image.load_img('image.jpg', target_size=(180,180))\nnp.array(img).shape\n","6b8f825a":"## apply some prepration to the image\nimg = tf.keras.preprocessing.image.img_to_array(img)\nimg = np.expand_dims(img, axis = 0)\n\n## then we can predict\nmodel_.predict(img)","95488da0":"As we can see the class for the image is 5. meaning class 5 in train folder is chosen. If we want to know which class it is, we can count the folders in dataset. By counting we saw that flower is chosen at classified class!","00abe91a":"## To Load model "}}