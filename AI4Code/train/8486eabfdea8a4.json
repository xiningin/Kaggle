{"cell_type":{"88816af5":"code","6235c515":"code","c5fe5c10":"code","c00cacf3":"code","830b1b65":"code","27582a4d":"code","7b8f6044":"code","1aa845a6":"code","49561fc9":"code","2ffcd51e":"code","6d3fc6f9":"markdown","44626a8c":"markdown","7ce6ad93":"markdown","601dea57":"markdown","d79d7990":"markdown","14d2e640":"markdown","2771a6e2":"markdown","1b1d8d34":"markdown"},"source":{"88816af5":"# \u53e3\u7f69\u8fa8\u8b58 (Mask Detection)\n# \u4e0b\u8f09FaceMask \u8a13\u7df4\u4e4bCNN\u6a21\u578b https:\/\/kaggle.com\/rkuo2000\/facemask-cnn \n# \u4ee5\u81c9\u90e8\u5340\u57df\u505a\u9032\u884c\u6a21\u578b\u8fa8\u8b58","6235c515":"train_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/\"\nvalid_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/\"\ntest_dir  = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/\"","c5fe5c10":"import numpy as np\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.utils import to_categorical\n\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt","c00cacf3":"target_size=(96,96)\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',    \n    shuffle=True,\n    seed=42,\n    class_mode='categorical')\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\n\nvalid_generator = valid_datagen.flow_from_directory(\n    valid_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=False,    \n    class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb', \n    shuffle=False,    \n    class_mode='categorical')","830b1b65":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Model,save_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Input, BatchNormalization, Activation, LeakyReLU, Concatenate\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix","27582a4d":"num_classes = 2 # WithMask, WithoutMask\n\ninput_shape = (96,96,3)\n\n# Build Model\ninput_image = Input(shape=input_shape)\n# 1st Conv layer\nmodel = Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape)(input_image)\nmodel = MaxPooling2D((2, 2),padding='same')(model)\n# 2nd Conv layer\nmodel = Conv2D(32, (3, 3), activation='relu', padding='same')(model)\nmodel = MaxPooling2D((2, 2),padding='same')(model)\n# 3rd Conv layer\nmodel = Conv2D(64, (3, 3), activation='relu', padding='same')(model)\nmodel = MaxPooling2D((2, 2),padding='same')(model)\n# 4th Conv layer\nmodel = Conv2D(128, (3, 3), activation='relu', padding='same')(model)\nmodel = MaxPooling2D((2, 2),padding='same')(model)\n# 5th Conv layer\nmodel = Conv2D(256, (3, 3), activation='relu', padding='same')(model)\nmodel = MaxPooling2D((2, 2),padding='same')(model)\n# FC layers\nmodel = Flatten()(model)\n#model = Dense(1024, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(model)\nmodel = Dense(1024)(model)\n#model = Dropout(0.2)(model)\n\n#model = Dense(64, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(model)\nmodel = Dense(64)(model)\n#model = Dropout(0.2)(model)\n\noutput= Dense(num_classes, activation='softmax')(model)\n\nmodel = Model(inputs=[input_image], outputs=[output])\n\nmodel.summary()\n\n# Compile Model\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])","7b8f6044":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST =test_generator.n\/\/test_generator.batch_size\nnum_epochs = 100\n\n# Train Model\nmodel.fit_generator(train_generator,steps_per_epoch=STEP_SIZE_TRAIN,epochs=num_epochs, validation_data=valid_generator, validation_steps=STEP_SIZE_VALID) #, callbacks=[checkpoint])","1aa845a6":"save_model(model, \"facemask_cnn.h5\")","49561fc9":"score = model.evaluate_generator(test_generator, steps=STEP_SIZE_TEST)\nprint(score)","2ffcd51e":"predY=model.predict_generator(test_generator)\ny_pred = np.argmax(predY,axis=1)\n#y_label= [labels[k] for k in y_pred]\ny_actual = test_generator.classes\ncm = confusion_matrix(y_actual, y_pred)\nprint(cm)\n\n# report\nlabels = ['withMask', 'withoutMask']\nprint(classification_report(y_actual, y_pred, target_names=labels))","6d3fc6f9":"## Confusion Matrix","44626a8c":"## [Dataset](https:\/\/www.kaggle.com\/ashishjangra27\/face-mask-12k-images-dataset)\n![image.png](attachment:image.png)","7ce6ad93":"## Data Augmentation","601dea57":"## Train Model","d79d7990":"## Build Model","14d2e640":"## Evaluate Model","2771a6e2":"## Save Model","1b1d8d34":"# FaceMask Image Classification\n### withMask, withoutMask"}}