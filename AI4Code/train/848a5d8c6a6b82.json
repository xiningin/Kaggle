{"cell_type":{"2485a4ec":"code","e7a24013":"code","f97e9816":"code","8d8fe2e7":"code","03ef6710":"code","1c57896c":"code","99244991":"code","af229297":"code","51021632":"code","ac07d837":"code","e0050883":"code","0849dd05":"code","06cedeec":"code","2d03b7f4":"code","996ec066":"code","059eead0":"code","8dbc3762":"code","de32b1ef":"code","56742b2b":"code","45b312b7":"code","b345a5c2":"code","bc8bc840":"code","f96b1e25":"code","64b6720a":"code","023bf8f5":"code","a41a41b8":"code","eda7a5d2":"code","5411ceb2":"code","9e5ef55c":"code","8cd64eb3":"code","9da6c888":"code","49b3758c":"code","d69ccb02":"code","8b85e1ee":"code","74ac55f4":"code","b35ff608":"code","bc747658":"code","9d0dcd6d":"code","1c5ae911":"code","3c0dfb46":"code","c4076d2d":"code","8a1c15c9":"code","cf42fb02":"code","18aeb8d6":"markdown","48dee917":"markdown","e761cb50":"markdown","483cac26":"markdown","4eeebf75":"markdown","0ed353fe":"markdown","994a34eb":"markdown","0389c1c4":"markdown","30287564":"markdown","37b9ab8d":"markdown","0a482542":"markdown","e8b66220":"markdown","d6175646":"markdown","11b569f0":"markdown","9a809e12":"markdown","c7346ebc":"markdown","dee60b15":"markdown","6c0a5ecc":"markdown","8e14d64d":"markdown","3f4dcdce":"markdown","62d6f779":"markdown","2baab99f":"markdown","9670906f":"markdown","6ef9d5fa":"markdown","3816e292":"markdown","9b7f515a":"markdown","a4fb02e4":"markdown"},"source":{"2485a4ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7a24013":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\ngender_data = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ndatasets = [train_data, test_data]\n","f97e9816":"train_data.head()","8d8fe2e7":"test_data.head()","03ef6710":"train_data.info()","1c57896c":"test_data.info()","99244991":"\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nax = sns.barplot(data= train_data, x= 'Sex', y='Survived')\nplt.title('Pclass and Survived')\nplt.show()\nprint(\"% men survived: \", rate_men)\nprint(\"% women survived: \", rate_women)","af229297":"ax = sns.barplot(data= train_data, x= 'Pclass', y='Survived')\nplt.title('Pclass and Survived')\nplt.show()\n","51021632":"ax = sns.barplot(data= train_data, x= 'Embarked', y='Survived')\nplt.title('Embarked and Survived')\nplt.show()","ac07d837":"train_data['bands'] = pd.qcut(train_data['Fare'], 3)\ntrain_data['bands'].unique()","e0050883":"for dataset in datasets:\n    \n    dataset.loc[(-0.001 < dataset['Fare']) & (dataset['Fare'] <= 8.662), 'Fare'] = 0\n    dataset.loc[(8.662 < dataset['Fare']) & (dataset['Fare'] <= 26.0), 'Fare'] = 1\n    dataset.loc[(26.0 < dataset['Fare']) & (dataset['Fare'] <= 513.329), 'Fare'] = 2\n    \n   \n    dataset['Fare'] = dataset.loc[dataset['Fare'].notnull(), 'Fare'].astype(int)","0849dd05":"ax = sns.barplot(data=train_data, x='Fare', y='Survived')\nplt.title('Fare and Survived')\nplt.show()","06cedeec":"train_data['AgeBands'] = pd.qcut(train_data['Age'], 5)\ntrain_data['AgeBands'].unique()","2d03b7f4":"for dataset in datasets:\n    \n    dataset.loc[dataset['Age'] <= 19, 'Age'] = 10\n    dataset.loc[(19 < dataset['Age'] ) & (dataset['Age'] <= 25), 'Age' ] = 20\n    dataset.loc[(25.0 < dataset['Age'] ) & (dataset['Age'] <= 31.8), 'Age' ] = 30\n    dataset.loc[(31.8 < dataset['Age'] ) & (dataset['Age'] <= 41.0), 'Age' ] = 40\n    dataset.loc[(41.0 < dataset['Age'] ) & (dataset['Age'] <= 80.0), 'Age' ] = 50\n    \n    dataset['Age'] = dataset.loc[dataset['Age'].notnull(), 'Age'].astype(int)","996ec066":"ax = sns.barplot(data=train_data, x='Age', y='Survived')\nplt.title('Age and Survived')\nplt.show()","059eead0":"ax = sns.barplot(data = train_data, x = 'SibSp', y = 'Survived')\nplt.title('SibSp and Survived')\nplt.show()","8dbc3762":"ax = sns.barplot(data = train_data, x = 'Parch', y = 'Survived')\nplt.title('Parch and Survived')\nplt.show()","de32b1ef":"train_data.loc[(train_data['Age'] == 10), 'Age'] = 2\ntrain_data.loc[(train_data['Age'] == 20) | (train_data['Age'] == 50), 'Age'] = 0\ntrain_data.loc[(train_data['Age'] == 30) | (train_data['Age'] == 40), 'Age'] = 1\n\ntest_data.loc[(test_data['Age'] == 10), 'Age'] = 2\ntest_data.loc[(test_data['Age'] == 20) | (test_data['Age'] == 50), 'Age'] = 0\ntest_data.loc[(test_data['Age'] == 30) | (test_data['Age'] == 40), 'Age'] = 1\n\n\nfor pclass in range(1, 4):\n    \n    train_data.loc[ (train_data['Pclass'] == pclass) & (train_data['Age'].isnull()), 'Age'] = train_data.loc[ (train_data['Pclass'] == pclass) & (train_data['Age'].notnull()), 'Age' ].median()\n    test_data.loc[ (test_data['Pclass'] == pclass) & (test_data['Age'].isnull()), 'Age'] = test_data.loc[ (test_data['Pclass'] == pclass) & (test_data['Age'].notnull()), 'Age' ].median()","56742b2b":"parchValues = train_data['Parch'].unique()\nSibSpValues = train_data['SibSp'].unique()","45b312b7":"print('Shape before deletion for train data: ' + str(train_data.shape))\nprint('Shape before deletion for test data: ' + str(test_data.shape))\n\n\ntrain_data = train_data.drop(['Ticket', 'PassengerId', 'Cabin', 'AgeBands', 'bands'], axis=1)\ntest_data = test_data.drop(['Ticket', 'PassengerId', 'Cabin'], axis=1)\n    \nprint('\\nshape after deletion for train data: ' + str(train_data.shape))\nprint('shape after deletion for test data: ' + str(test_data.shape))","b345a5c2":"print(train_data.head())","bc8bc840":"train_data['Embarked'].describe()","f96b1e25":"train_data.loc[train_data['Embarked'].isnull(), 'Embarked'] = 'S'","64b6720a":"train_data['Fare'].describe()","023bf8f5":"test_data.loc[test_data['Fare'].isnull(), 'Fare'] = test_data['Fare'].median()\n\ntest_data['Fare'] = test_data['Fare'].astype(int)\n","a41a41b8":"train_data[ ['Pclass', 'Survived'] ].groupby('Pclass', as_index=False).mean().sort_values(by='Survived', ascending=False)","eda7a5d2":"train_data[ ['Embarked', 'Survived'] ].groupby('Embarked', as_index=False).mean().sort_values(by='Survived', ascending=False)","5411ceb2":"train_data[ ['Sex', 'Survived'] ].groupby('Sex', as_index=False).mean().sort_values(by='Survived', ascending=False)","9e5ef55c":"train_data.info()","8cd64eb3":"sexMap = {'male':0.1889, 'female':0.742}\nembarkedMap = {'S':0.34, 'Q':0.39, 'C':0.55}\nPclassMap = {3:0.24, 2:0.47, 1:0.63}","9da6c888":"train_data['isAlone'] = 0\ntrain_data.loc[ (train_data['SibSp'] == 0) & (train_data['Parch'] == 0) , 'isAlone'] = 1\n\ntest_data['isAlone'] = 0\ntest_data.loc[ (test_data['SibSp'] == 0) & (test_data['Parch'] == 0) , 'isAlone'] = 1","49b3758c":"train_data['Sex'] = train_data['Sex'].map(sexMap)\ntrain_data['Embarked'] = train_data['Embarked'].map(embarkedMap)\ntrain_data['Pclass']= train_data['Pclass'].map(PclassMap)\n\ntrain_data.loc[train_data['SibSp'] >= 3, 'SibSp'] = 0\ntrain_data.loc[train_data['SibSp'] < 3, 'SibSp'] = 1\n    \n    \ntrain_data.loc[train_data['Parch'] >= 4, 'Parch'] = 0\ntrain_data.loc[(train_data['Parch'] > 0) & (train_data['Parch'] < 4), 'Parch'] = 1\n","d69ccb02":"test_data['Sex'] = test_data['Sex'].map(sexMap)\ntest_data['Embarked'] = test_data['Embarked'].map(embarkedMap)\ntest_data['Pclass']= test_data['Pclass'].map(PclassMap)\n\ntest_data.loc[test_data['SibSp'] >= 3, 'SibSp'] = 0\ntest_data.loc[test_data['SibSp'] < 3, 'SibSp'] = 1 \n    \ntest_data.loc[test_data['Parch'] >= 4, 'Parch'] = 0\ntest_data.loc[(test_data['Parch'] > 0) & (test_data['Parch'] < 4), 'Parch'] = 1","8b85e1ee":"train_data['Title'] = train_data.Name.str.extract(r'(\\w+)\\.')\ntrain_data = train_data.drop('Name', axis=1)\n\ntest_data['Title'] = test_data.Name.str.extract(r'(\\w+)\\.')\ntest_data = test_data.drop('Name', axis= 1)\n\ntrain_data['Title'].unique()","74ac55f4":"titles = train_data['Title'].unique()\nnumDict = dict()\nfor title in titles:\n    numDict[title] = train_data.loc[ train_data['Title'] == title, 'Title' ].count()\n\ndataframe = train_data[ ['Title', 'Survived'] ].groupby('Title', as_index=False).mean().sort_values(by='Survived', ascending= False)\ndataframe['Repeated'] = [numDict[title] for title in dataframe['Title']]\nprint(dataframe)","b35ff608":"train_data = train_data.replace(['Countess', 'Ms', 'Mme', 'Lady', 'Dona', 'Mlle', 'Mrs', 'Miss', 'Master', 'Dr'], 2)\ntest_data = test_data.replace(['Countess', 'Ms', 'Mme', 'Lady', 'Dona', 'Mlle', 'Mrs', 'Miss', 'Master', 'Dr'], 2)\n\n\ntrain_data = train_data.replace(['Col', 'Major', 'Sir', 'Capt'], 1)\ntest_data = test_data.replace(['Col', 'Major', 'Sir', 'Capt'], 1)\n\n\ntrain_data = train_data.replace(['Rev', 'Mr', 'Jonkheer', 'Don'], 0)\ntest_data = test_data.replace(['Rev', 'Mr', 'Jonkheer', 'Don'], 0)","bc747658":"X = train_data.drop(['Survived'], axis=1)\ny = train_data['Survived']","9d0dcd6d":"lg_model = LogisticRegression()\nlg_model.fit(X, y)\nlg_model_score =(lg_model.score(X, y)) *100\n","1c5ae911":"NN_model = KNeighborsClassifier()\nNN_model.fit(X,y)\nNN_model_score = (NN_model.score(X,y))*100\n","3c0dfb46":"tree_model = DecisionTreeClassifier()\ntree_model.fit(X, y)\ntree_model_score = round(tree_model.score(X, y) * 100)\n","c4076d2d":"SGD_model = SGDClassifier()\nSGD_model.fit(X, y)\nSGD_model_score = round(SGD_model.score(X, y) * 100, 2)\n","8a1c15c9":"print('Logistic Regression: %' + str(lg_model_score))\nprint('\\nNearest Neighbors: %' + str(NN_model_score))\nprint('\\nDecision Tree: %' + str(tree_model_score))\nprint('\\nSGD Classifier: %' + str(SGD_model_score))","cf42fb02":"ourPred = tree_model.predict(test_data)\ntestReal = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmission = pd.DataFrame({\n        \"PassengerId\": testReal[\"PassengerId\"],\n        \"Survived\": ourPred\n    })\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","18aeb8d6":"we can categorize the sibsp and parch down to if the person was alone or not. to make it more simplistic ","48dee917":"Clean up the Data","e761cb50":"Map the datasets with their actual ratio values","483cac26":"The range for Fare is to great, use bands to create ranges to graph","4eeebf75":"## Data Analysis","0ed353fe":"the range for ages is to great, bands again for age","994a34eb":"Nearest Neighbors","0389c1c4":"Test between male and female survival ","30287564":"Map out the datasets","37b9ab8d":"replace missing data with the most freq. ","0a482542":"It must clearly contain a section where you evaluate the models\n\nIt must clearly contain a section where you generate the submission data using the best model","e8b66220":"## Load Data","d6175646":"SibSp (siblings spouses) bands wont work for for whatever reason.","11b569f0":"## Model Builds","9a809e12":"Logistic Regression","c7346ebc":"## Evaluate the Models","dee60b15":"Test between class and survival \n","6c0a5ecc":"## Submission Data","8e14d64d":"replace missing data with the mean of fare. and then convert from a float to a int64","3f4dcdce":"Decision Tree","62d6f779":"Test between where passenger embarked","2baab99f":"SGD Classifier","9670906f":"now i need to get the title from Name. then seperate the title from name and then drop name. ","6ef9d5fa":"Parch (Parents and children) ","3816e292":"Dropping Data that is needed for the predictions ","9b7f515a":"Get the ratios of each deciding dataset in order to make the maps, convert and categorize the data","a4fb02e4":"## Christopher Gray \n\n## Assignmnet 0\n\n## CAP 4611\n"}}