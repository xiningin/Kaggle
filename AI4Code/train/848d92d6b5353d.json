{"cell_type":{"c8d78409":"code","1874af2e":"code","37c40b99":"code","216864f2":"code","357f70d0":"code","7dcd486c":"code","dee60147":"code","f8076e25":"code","f1953b53":"code","5db79efc":"code","9222a6cc":"code","27b4c23b":"code","ca63216b":"code","b061721e":"code","7caea33f":"code","dced0bb1":"code","78189b98":"code","2b2c9948":"markdown","b79674f3":"markdown","874864b8":"markdown","4ba75ee0":"markdown","7950fa60":"markdown","a45530e4":"markdown","d0b18dd8":"markdown","b3a1b873":"markdown","211221f6":"markdown","e3a8c6e1":"markdown","db53b20a":"markdown","469c18ee":"markdown","c2239a32":"markdown"},"source":{"c8d78409":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras import optimizers\nfrom keras import regularizers","1874af2e":"def clean(df):\n    # Delimiter lats and lons to NY only\n    df = df[(-76 <= df['pickup_longitude']) & (df['pickup_longitude'] <= -72)]\n    df = df[(-76 <= df['dropoff_longitude']) & (df['dropoff_longitude'] <= -72)]\n    df = df[(38 <= df['pickup_latitude']) & (df['pickup_latitude'] <= 42)]\n    df = df[(38 <= df['dropoff_latitude']) & (df['dropoff_latitude'] <= 42)]\n    # Remove possible outliers\n    df = df[(0 < df['fare_amount']) & (df['fare_amount'] <= 250)]\n    # Remove inconsistent values\n    df = df[(df['dropoff_longitude'] != df['pickup_longitude'])]\n    df = df[(df['dropoff_latitude'] != df['pickup_latitude'])]\n    \n    return df","37c40b99":"def late_night (row):\n    if (row['hour'] <= 6) or (row['hour'] >= 20):\n        return 1\n    else:\n        return 0\n\n\ndef night (row):\n    if ((row['hour'] <= 20) and (row['hour'] >= 16)) and (row['weekday'] < 5):\n        return 1\n    else:\n        return 0\n    \n    \ndef manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n\n\ndef add_time_features(df):\n    df['pickup_datetime'] =  pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')\n    df['year'] = df['pickup_datetime'].apply(lambda x: x.year)\n    df['month'] = df['pickup_datetime'].apply(lambda x: x.month)\n    df['day'] = df['pickup_datetime'].apply(lambda x: x.day)\n    df['hour'] = df['pickup_datetime'].apply(lambda x: x.hour)\n    df['weekday'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n    df['pickup_datetime'] =  df['pickup_datetime'].apply(lambda x: str(x))\n    df['night'] = df.apply (lambda x: night(x), axis=1)\n    df['late_night'] = df.apply (lambda x: late_night(x), axis=1)\n    # Drop 'pickup_datetime' as we won't need it anymore\n    df = df.drop('pickup_datetime', axis=1)\n    \n    return df\n\n\ndef add_coordinate_features(df):\n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    \n    # Add new features\n    df['latdiff'] = (lat1 - lat2)\n    df['londiff'] = (lon1 - lon2)\n\n    return df\n\n\ndef add_distances_features(df):\n    # Add distances from airpot and downtown\n    ny = (-74.0063889, 40.7141667)\n    jfk = (-73.7822222222, 40.6441666667)\n    ewr = (-74.175, 40.69)\n    lgr = (-73.87, 40.77)\n    \n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    \n    df['euclidean'] = (df['latdiff'] ** 2 + df['londiff'] ** 2) ** 0.5\n    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n    \n    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n    \n    return df","216864f2":"def output_submission(raw_test, prediction, id_column, prediction_column, file_name):\n    df = pd.DataFrame(prediction, columns=[prediction_column])\n    df[id_column] = raw_test[id_column]\n    df[[id_column, prediction_column]].to_csv((file_name), index=False)\n    print('Output complete')\n    \n    \ndef plot_loss_accuracy(history):\n    plt.figure(figsize=(20,10))\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper right')\n    plt.show()","357f70d0":"TRAIN_PATH = '..\/input\/train.csv'\nTEST_PATH = '..\/input\/test.csv'\nSUBMISSION_NAME = 'submission.csv'\n\n# Model parameters\nBATCH_SIZE = 256\nEPOCHS = 50\nLEARNING_RATE = 0.001\nDATASET_SIZE = 6000000","7dcd486c":"# Load values in a more compact form\ndatatypes = {'key': 'str', \n              'fare_amount': 'float32',\n              'pickup_datetime': 'str', \n              'pickup_longitude': 'float32',\n              'pickup_latitude': 'float32',\n              'dropoff_longitude': 'float32',\n              'dropoff_latitude': 'float32',\n              'passenger_count': 'uint8'}\n\n# Only a fraction of the whole data\ntrain = pd.read_csv(TRAIN_PATH, nrows=DATASET_SIZE, dtype=datatypes, usecols=[1,2,3,4,5,6])\ntest = pd.read_csv(TEST_PATH)","dee60147":"train = clean(train)\n\ntrain = add_time_features(train)\ntest = add_time_features(test)\n\nadd_coordinate_features(train)\nadd_coordinate_features(test)\n\ntrain = add_distances_features(train)\ntest = add_distances_features(test)\n\ntrain.head(5)","f8076e25":"# Drop unwanted columns\ndropped_columns = ['pickup_longitude', 'pickup_latitude', \n                   'dropoff_longitude', 'dropoff_latitude']\ntrain_clean = train.drop(dropped_columns, axis=1)\ntest_clean = test.drop(dropped_columns + ['key', 'passenger_count'], axis=1)\n\n# peek data\ntrain_clean.head(5)","f1953b53":"train_df, validation_df = train_test_split(train_clean, test_size=0.10, random_state=1)\n\n# Get labels\ntrain_labels = train_df['fare_amount'].values\nvalidation_labels = validation_df['fare_amount'].values\ntrain_df = train_df.drop(['fare_amount'], axis=1)\nvalidation_df = validation_df.drop(['fare_amount'], axis=1)","5db79efc":"# Scale data\n# Note: im doing this here with sklearn scaler but, on the Coursera code the scaling is done with Dataflow and Tensorflow\nscaler = preprocessing.MinMaxScaler()\ntrain_df_scaled = scaler.fit_transform(train_df)\nvalidation_df_scaled = scaler.transform(validation_df)\ntest_scaled = scaler.transform(test_clean)","9222a6cc":"model = Sequential()\nmodel.add(Dense(256, activation='relu', input_dim=train_df_scaled.shape[1], activity_regularizer=regularizers.l1(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(8, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1))\n\nadam = optimizers.adam(lr=LEARNING_RATE)\nmodel.compile(loss='mse', optimizer=adam, metrics=['mae'])","27b4c23b":"print('Dataset size: %s' % DATASET_SIZE)\nprint('Epochs: %s' % EPOCHS)\nprint('Learning rate: %s' % LEARNING_RATE)\nprint('Batch size: %s' % BATCH_SIZE)\nprint('Input dimension: %s' % train_df_scaled.shape[1])\nprint('Features used: %s' % train_df.columns)","ca63216b":"model.summary()","b061721e":"history = model.fit(x=train_df_scaled, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, \n                    verbose=1, validation_data=(validation_df_scaled, validation_labels), \n                    shuffle=True)","7caea33f":"plot_loss_accuracy(history)","dced0bb1":"# Make prediction\nprediction = model.predict(test_scaled, batch_size=128, verbose=1)","78189b98":"# output prediction\noutput_submission(test, prediction, 'key', 'fare_amount', SUBMISSION_NAME)","2b2c9948":"## Data clean\n### Here i'm removing some outliers, and noisy data.\n* Lats and lons that do not belong to New York.\n* Negative fare.\n* Fare greater than 250 (this seems to be noisy data).\n* Rides that begin and end in the same location.","b79674f3":"### Auxiliar functions","874864b8":"### Model parameters","4ba75ee0":"### This is an adaptation of the Coursera code (originally built with tensorflow), on this one i used Keras to make the model part simpler, maybe it can help people that are new to deep learning or anyone else that want to use Keras on this competition.\n\n#### Notes: \n* [Link for a tensorflow version](https:\/\/www.kaggle.com\/dimitreoliveira\/tensorflow-dnn-coursera-ml-course-code)\n* [Link for a more complete version on Github](https:\/\/github.com\/dimitreOliveira\/NewYorkCityTaxiFare)\n* I'm not using \"passenger count\" because it something that is not supposed to really matter in this case.\n* I've created two features derived from \"hour\" (night and late night), according to some research i did it's added an additional value if it's a business day (mon ~ fri), and it's night, also there's another added value if it's dawn.\n* I'm binning latitudes and longitudes to make it easier to work with.\n* Even tough deep learning is robust enough to deal with noisy data, i'm removing outliers (it may save some memory).\n* Currently i'm using both Euclidean and Manhattan distances, it may be a bit redundant, but they have a different meaning and i'm still not sure of witch one is better(if you have some insights about this please let me know)","7950fa60":"### Parameters","a45530e4":"#### Clean and process data","d0b18dd8":"### Dependencies","b3a1b873":"### Train model","211221f6":"### Plot metrics","e3a8c6e1":"### Load data","db53b20a":"## Feature engineering\n*  Now i'll do some feature engineering and process the data, i'm basically creating 3 kinds of features.\n    *  **Time features**\n        * Year, Month, Day, Hour, Weekday\n        * Night (between 16h and 20h, from monday to friday)\n        * Late night (between 20h and and 6h)\n    * **Coordinate features**\n        * Latitude difference (difference from pickup and dropout latitudes)\n        * Longitude difference (difference from pickup and dropout longitudes)\n    * **Distances features**\n        * Euclidean (Euclidean distance from pickup and dropout)\n        * Manhattan (Manhattan distance from pickup and dropout)\n        * Manhattan distances from pickup location and downtown, JFK, EWR and LGR airports (see if the ride started at one of these locations).\n        * Manhattan distances from dropout location and downtown, JFK, EWR and LGR airports (see if the ride ended at one of these locations).","469c18ee":"### Model","c2239a32":"#### Split data in train and validation (90% ~ 10%)"}}