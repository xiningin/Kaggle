{"cell_type":{"10f50fe7":"code","39ccdb44":"code","4947322e":"code","39f5a290":"code","0464b7c4":"code","8b06c657":"code","67524c6c":"code","b119d4ba":"code","34c9dcde":"markdown","8bc85fc2":"markdown","061a4920":"markdown","1c107f30":"markdown","431a8604":"markdown","74e48b5a":"markdown","699fe81e":"markdown"},"source":{"10f50fe7":"# IMPORT LIBRARIES\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import ArtistAnimation\nfrom sklearn.linear_model import LogisticRegression\n\n# LOAD THE DATA\ntest = pd.read_csv('..\/input\/test.csv')\ntrain = pd.read_csv('..\/input\/train.csv')\ntrain.head()","39ccdb44":"plt.figure(figsize=(15,15))\nfor i in range(5):\n    for j in range(5):\n        plt.subplot(5,5,5*i+j+1)\n        plt.hist(test[str(5*i+j)],bins=100)\n        plt.title('Variable '+str(5*i+j))\nplt.show()","4947322e":"plt.figure(figsize=(10,10))\nplt.scatter(train['33'],train['65'],c=train['target'])\nplt.plot([-1.6,1.4],[3,-3],':k')\nplt.xlabel('variable 33')\nplt.ylabel('variable 65')\nplt.title('Training data')\nplt.show()","39f5a290":"# FIND NORMAL TO HYPERPLANE\nclf = LogisticRegression(solver='liblinear',penalty='l2',C=0.1,class_weight='balanced')\nclf.fit(train.iloc[:,2:],train['target'])\nu1 = clf.coef_[0]\nu1 = u1\/np.sqrt(u1.dot(u1))","0464b7c4":"# CREATE RANDOM DIRECTION PERPENDICULAR TO U1\nu2 = np.random.normal(0,1,300)\nu2 = u2 - u1.dot(u2)*u1\nu2 = u2\/np.sqrt(u2.dot(u2))","8b06c657":"# CREATE RANDOM DIRECTION PERPENDICULAR TO U1 AND U2\nu3 = np.random.normal(0,1,300)\nu3 = u3 - u1.dot(u3)*u1 - u2.dot(u3)*u2\nu3 = u3\/np.sqrt(u3.dot(u3))","67524c6c":"# CREATE AN ANIMATION\nimages = []\nsteps = 60\nfig = plt.figure(figsize=(8,8))\nfor k in range(steps):\n    \n    # CALCULATE NEW ANGLE OF ROTATION\n    angR = k*(2*np.pi\/steps)\n    angD = round(k*(360\/steps),0)\n    u4 = np.cos(angR)*u1 + np.sin(angR)*u2\n    u = np.concatenate([u4,u3]).reshape((2,300))\n    \n    # PROJECT TRAIN AND TEST ONTO U3,U4 PLANE\n    p = u.dot(train.iloc[:,2:].values.transpose())\n    p2 = u.dot(test.iloc[:,1:].values.transpose())\n    \n    # PLOT TEST DATA\n    img1 = plt.scatter(p2[0,:],p2[1,:],c='gray')\n    \n    # PLOT TRAIN DATA (KEEP CORRECT COLOR IN FRONT)\n    idx0 = train[ train['target']==0 ].index\n    idx1 = train[ train['target']==1 ].index\n    if angD<180:\n        img2 = plt.scatter(p[0,idx1],p[1,idx1],c='yellow')\n        img3 = plt.scatter(p[0,idx0],p[1,idx0],c='blue')\n    else:\n        img2 = plt.scatter(p[0,idx0],p[1,idx0],c='blue')\n        img3 = plt.scatter(p[0,idx1],p[1,idx1],c='yellow')\n        \n    # ANNOTATE AND ADD TO MOVIE\n    img4 = plt.text(1.5,-3.5,'Angle = '+str(angD)+' degrees')\n    images.append([img1, img2, img3, img4])\n    \n# SAVE MOVIE TO FILE\nani = ArtistAnimation(fig, images)\nani.save('data.gif', writer='imagemagick', fps=15)","b119d4ba":"from IPython.display import Image\nImage(\"..\/working\/data.gif\")","34c9dcde":"# Conclusion\nIn this kernel, we learned how to create an animation. This animation shows us that the training data target=1 and target=0 are separable. Also, it can be shown that if we use the hyperplane that separates the training data as our classification decision boundary for the test data, we will score LB 0.75 in this competition.","8bc85fc2":"Each of the 300 variables has a Gaussian distribution with mean 0 and standard deviation 1. We can see this by plotting histograms of the train and test data combined. Therefore the 20000 data points reside within a 300 dimensional hypersphere of approximate radius 3 centered at the origin (zero).","061a4920":"![image](http:\/\/playagricola.com\/Kaggle\/data.gif)","1c107f30":"If we plot only variable 33 and 65 from the 250 training data points and color target=1 yellow and target=0 blue, we see that the data may be separable. We can confirm this with logistic regression on all 300 variables below.","431a8604":"# How to Make an Animation!\nThe data for the \"Don't Overfit! II\" competition has 300 features. Therefore it resides in 300 dimensional space and we have trouble visualizing it. In this kernel, we project it into 2 dimensional space and create an animation by rotating it through a third dimension. This visualization shows us that the training data target=1 and target=0 is separable by a hyperplane.  \n  \n![image](http:\/\/playagricola.com\/Kaggle\/data.gif)\n\n# Load the data","74e48b5a":"# Logistic regression finds a hyperplane!\nThe coefficients to logistic regression are the normal of (perpendicular direction to) the hyperplane that separates the data in 300 dimensional space. This direction is variable `u1` below. Next we create two random perpendicular directions `u2` and `u3`. Thus if we project all the points onto the plane created by `u1` and `u3` we will see if the train data is separable. Next we can rotate through the direction `u2` and view an animation.","699fe81e":"# Create an animation"}}