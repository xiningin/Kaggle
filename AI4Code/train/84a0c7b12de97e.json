{"cell_type":{"2143d0ab":"code","49ec61f4":"code","3eb2c01f":"code","dbe524a0":"code","eb45f0ba":"code","de107659":"code","9e5a8103":"code","0a674c87":"code","198d9d7c":"code","0b1dd88d":"code","e739a826":"code","3b208295":"code","a7037816":"code","676be070":"code","aec1f7fb":"code","90dfc2ce":"code","466bac01":"code","e7f38aac":"code","077f3643":"code","0337e822":"code","42c6a4df":"code","68120644":"code","82e6aea5":"code","c9cde598":"code","369a1a23":"code","c4250597":"code","1c8b3d18":"code","892f7d0f":"code","7025118c":"code","cb8b39c5":"code","d2fd192f":"code","f4347c6f":"code","33ed39c1":"code","25821436":"code","654bcfed":"code","9332e2cb":"code","85a645c1":"code","8659a90f":"markdown","5f494c55":"markdown"},"source":{"2143d0ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\nfrom datetime import datetime\n#from pandasql import sqldf\nimport xgboost as xgb\nfrom pandasql import sqldf\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import train_test_split\nimport matplotlib as plot\n%matplotlib inline\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","49ec61f4":"#load dataset\ndf_train = pd.read_csv('..\/input\/dataset_treino.csv', low_memory=False)\n                                                 \n#load dataset\ndf_test = pd.read_csv('..\/input\/dataset_teste.csv', low_memory=False)\n\n#load dataset\ndf_lojas = pd.read_csv('..\/input\/lojas.csv', low_memory=False)","3eb2c01f":"df_train.shape","dbe524a0":"df_test.head()","eb45f0ba":"df_train.groupby('Open')['Store'].count()","de107659":"df_train.groupby('Open')['Store'].count()","9e5a8103":"#Vendas por dia da semana\ndf_train[['Sales','DayOfWeek']].groupby('DayOfWeek').describe().T","0a674c87":"df_train['Sales'].describe()","198d9d7c":"df_train.corr()","0b1dd88d":"_=df_train.hist(figsize=(20,10))","e739a826":"#filtrar lojas fechas e sem vendas\ndf_train=df_train[df_train['Open']!=0]\ndf_train=df_train[df_train['Sales']>0]","3b208295":"df_train.isna().any().any()","a7037816":"df_test.isna().any()","676be070":"#Atribuindo 1 \"Aberto\" para lojas com a variavel \"Open\" nula.\ndf_test['Open'].fillna(1, inplace = True)","aec1f7fb":"#Verificando registros com vari\u00e1veis nulas no dataset \"Lojas\" \npd.DataFrame(pd.isnull(df_lojas).sum(), columns=['qtd']).query('qtd>0')","90dfc2ce":"#Atribuido a m\u00e9dia da Distancia para os registros nulos\ndf_lojas['CompetitionDistance'].fillna(np.round(df_lojas.CompetitionDistance.mean()), inplace = True)","466bac01":"##Somente variaveis sem dados missing\ndf_lojas_feature = df_lojas[['Store','StoreType','Assortment','Promo2','CompetitionDistance']] ","e7f38aac":"#Transformando vari\u00e1veis categ\u00f3ricas em fatores\nlabels, uniques = df_lojas_feature.loc[:,'StoreType'].factorize(na_sentinel=-1)\ndf_lojas_feature.loc[:,'StoreType']=labels\n\nlabels1, uniques1 = df_lojas_feature.loc[:,'Assortment'].factorize(na_sentinel=-1)\ndf_lojas_feature.loc[:,'Assortment']=labels1\n\nlabels2, uniques2 = df_test.loc[:,'StateHoliday'].factorize(na_sentinel=-1)\ndf_test.loc[:,'StateHoliday']=labels2\n\nlabels3, uniques3 = df_train.loc[:,'StateHoliday'].factorize(na_sentinel=-1)\ndf_train.loc[:,'StateHoliday']=labels3\n","077f3643":"#Trabalhando a vari\u00e1vel Date\ndef criaVar(ext, data):\n    \n    ext.extend(['Month', 'Day', 'Year', 'WeekOfYear'])\n    data['Year'] = pd.to_datetime(data.Date).dt.year\n    data['Month'] = pd.to_datetime(data.Date).dt.month\n    data['Day'] = pd.to_datetime(data.Date).dt.day\n    data['WeekOfYear'] = pd.to_datetime(data.Date).dt.weekofyear\n    \n    return data","0337e822":"avg_customer = sqldf(\n\"\"\"\nSELECT\nStore,\nDayOfWeek,\nsum(case when Customers is not null then Sales\/Customers else 0 end) as Wapp,\nround(avg(Customers)) Avg_Customers\nfrom df_train\ngroup by Store,DayOfWeek\n\"\"\"\n)","42c6a4df":"df_test = sqldf(\n\"\"\"\nSELECT\nt.*,\nac.Wapp,\nac.Avg_Customers\nfrom df_test t\nleft join avg_customer ac on t.Store = ac.Store and t.DayOfWeek = ac.DayOfWeek\n\"\"\"\n)","68120644":"df_train = sqldf(\n\"\"\"\nSELECT\nt.*,\nac.Wapp,\nac.Avg_Customers\nfrom df_train t\nleft join avg_customer ac on t.Store = ac.Store and t.DayOfWeek = ac.DayOfWeek\n\"\"\"\n)","82e6aea5":"#Jun\u00e7\u00e3o dos datasets de vendas com as lojas\ntrain = pd.merge(df_train, df_lojas_feature, on='Store', )\ntest = pd.merge(df_test, df_lojas_feature, on='Store')","c9cde598":"ext = []\n\ncriaVar(ext, train)\ncriaVar([], test)\n\next","369a1a23":"#Set index as date\ntrain.set_index('Date', inplace = True)\ntest.set_index('Date', inplace = True)\n\ntrain.sort_index(inplace=True)\ntest.sort_index(inplace=True)","c4250597":"def split_data(data, split_date):\n    return data[data.index <= split_date].copy(), \\\n           data[data.index >  split_date].copy()","1c8b3d18":"train, evaluate = split_data(train, '2014-12-31')","892f7d0f":"#Trazendo o indice para para\ntrain['date'] =pd.to_datetime(train.index)\nevaluate['date'] = pd.to_datetime(evaluate.index)\ntest['date'] = pd.to_datetime(test.index)","7025118c":"#convertendo date para int\n\ntrain['date'] = train['date'].apply(lambda x:x.toordinal())\nevaluate['date'] = evaluate['date'].apply(lambda x:x.toordinal())\ntest['date'] =  test['date'].apply(lambda x:x.toordinal())\n","cb8b39c5":"#Preparando as vari\u00e1veis de treino\nX0=train.loc[:,['Store','date','DayOfWeek',  'Open', 'Promo',\n                'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'Promo2', \n                'Wapp', 'Avg_Customers',\n                'Month', 'Day', 'Year', 'WeekOfYear']]\ny0= (train.loc[:,['Sales']])\n\n","d2fd192f":"#Preparando as vari\u00e1veis de valida\u00e7\u00e3o\nX1=evaluate.loc[:,['Store','date','DayOfWeek',  'Open', 'Promo',\n                'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'Promo2', \n                'Wapp', 'Avg_Customers',\n                'Month', 'Day', 'Year', 'WeekOfYear']]\ny1= (evaluate.loc[:,['Sales']])","f4347c6f":"#Preparando as vari\u00e1veis de teste\nX2 = test.loc[:,['Store','date','DayOfWeek',  'Open', 'Promo',\n                'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'Promo2', \n                'Wapp', 'Avg_Customers',\n                'Month', 'Day', 'Year', 'WeekOfYear']]","33ed39c1":"#Treinando o modelo\nreg = xgb.XGBRegressor(objective=\"reg:linear\", eta=0.3, subsample=0.7,colsample_bytree = 0.7,\n           silent=1, booster=\"gbtree\",  early_stopping_rounds=50, n_estimators=1000)\nreg.fit(X0, y0,\n        eval_set=[(X0, y0), (X1, y1)],      \n        verbose=False) # Change verbose to True if you want to see it train","25821436":"#Imprimindo o peso de cada variavel\nxgb.plot_importance(reg, height=0.9)","654bcfed":"#Calculando o rmsep\nevaluate_pred= (reg.predict(X1))\nevaluate_true= (np.array(y1))\na = ((pd.DataFrame(evaluate_true) - pd.DataFrame(evaluate_pred) )\/  pd.DataFrame(evaluate_pred))\nloss =  np.sqrt(np.mean(np.square(a.values), axis=0))\nloss","9332e2cb":"#Prevendo com a base de teste\ntest_predict = reg.predict(X2)\ntest_predict = (test_predict)","85a645c1":"#Gerando o arquivo de output\ny_test = pd.DataFrame()\ny_test['ID'] = test['Id']\ny_test['Sales'] = test_predict\ny_test.to_csv('predict_sales.csv',index=False)","8659a90f":"## Pr\u00e9-processamento","5f494c55":"## An\u00e1lise explorat\u00f3ria"}}