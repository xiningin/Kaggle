{"cell_type":{"8d1dc28a":"code","f06e4689":"code","8b156764":"code","62d7a293":"code","6db6646b":"code","b2d17531":"code","928e60d6":"code","345e5c88":"code","d9de981b":"code","482c869b":"code","50f1ad2b":"code","23b0b80c":"code","d2ae4354":"code","e04032ed":"code","ad980d7a":"code","93369d6c":"code","59ef0adb":"code","fec15153":"code","a8009a9b":"code","13bbcde8":"code","16f38b5e":"code","9130e56f":"code","f8519b3d":"code","2b0912d7":"code","ef7c4b94":"code","8a27cea2":"code","7715fe05":"code","e1f11ddd":"code","d46db0dd":"code","d02250d8":"code","d71fafb6":"code","4038cb67":"code","b590bf07":"code","583b79df":"code","898a2e37":"code","8f1fcd44":"code","b6350383":"code","2620eb15":"code","a1943042":"code","a884a8f5":"code","9a538af9":"code","2e6abc6f":"code","fab94003":"code","fa4f516b":"code","27b1447f":"code","695cbb6a":"code","bebb2b28":"code","f6571f70":"code","f7816dc9":"code","8b2c3b51":"code","824fc636":"code","8adfd279":"code","29933d91":"code","ee4abeb1":"code","0a8fd124":"code","2a6b647c":"code","7e539e53":"markdown","784b3214":"markdown","a3c9b844":"markdown","4ca3dd5b":"markdown"},"source":{"8d1dc28a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f06e4689":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport missingno as msng\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error,r2_score\n","8b156764":"train_=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain_","62d7a293":"train_data=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv').iloc[:,1:]\ntrain=train_data.copy()\ntrain.head(15)","6db6646b":"train.drop([i for i in train if train[i].isnull().sum()>(len(train)*0.30)],axis=1,inplace=True)","b2d17531":"def cleanData(data):\n    for feature in list(data.columns):\n        if data[feature].dtype == 'int64' or data[feature].dtype =='float64':\n            data[feature].fillna(0,inplace=True)\n        elif data[feature].dtype == 'object' :\n             data[feature].fillna('None',inplace=True)\n    return data","928e60d6":"def cleanOutlier(data):\n        for feature in data.select_dtypes(['int64','float64']).nunique().sort_values(ascending=False).head(20).index:\n            if feature!='SalePrice':\n   \n                q1=data[feature].quantile(0.25)\n                q3=data[feature].quantile(0.75)\n\n                iqr=q3-q1\n                floor=q1-1.5*iqr\n                ceiling = q3 + 1.5*iqr\n                data[feature][data[feature]>ceiling]=ceiling\n                data[feature][data[feature]<floor]=floor  \n        return data","345e5c88":"#We review the nan values\n#msng.matrix(train[(train.isnull().sum().sort_values(ascending=False).head(20)>0).index])","d9de981b":"#We filled in the missing observations in our data set with the cleanData function we defined above.\ndf_train=cleanData(train)\n","482c869b":"#msng.matrix(df_train[(df_train.isnull().sum().sort_values(ascending=False).head(20)>0).index])","50f1ad2b":"sns.set(rc={'figure.figsize':(40,15)})\nsns.heatmap(df_train.corr(),annot=True)","23b0b80c":"#Variables with a correlation with SalePrice less than 0.30\ndf_train.drop([i for i in df_train.corr().SalePrice.index if (abs(df_train.corr().SalePrice[i])<0.2)],axis=1,inplace=True)","d2ae4354":"sns.set(rc={'figure.figsize':(40,15)})\nsns.heatmap(df_train.corr(),annot=True)","e04032ed":"#df_train=df_train.apply(lambda x: x.astype('O') if x.nunique()<=10  else x)","ad980d7a":"#df_train.select_dtypes('int','float').nunique().sort_values(ascending=False)","93369d6c":"df_train.select_dtypes('int','float').nunique().sort_values(ascending=False)\n","59ef0adb":"df_train['Condition1'].value_counts()","fec15153":"df_train['Condition2'].value_counts()","a8009a9b":"df_train.select_dtypes('object').nunique().sort_values(ascending=False)","13bbcde8":"df_train.drop(['Exterior2nd','BsmtFinType2','GarageCond','BsmtCond','Condition2'],axis=1,inplace=True)","16f38b5e":"plt.figure(figsize=(20,20))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)\nfor i,j in enumerate(df_train.select_dtypes(['int','float']),):\n    plt.subplot(10,4,i+1)\n    sns.histplot(df_train.select_dtypes(['int','float'])[j])","9130e56f":"#plt.subplots?","f8519b3d":"plt.figure(figsize=(20,40))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)\nfor i,j in enumerate(df_train.select_dtypes(['int','float']).columns):\n    plt.subplot(10,4,i+1)\n    feature=df_train.select_dtypes(['int','float'])[j]\n    sns.boxplot(x=feature,data=df_train)","2b0912d7":"#df_train=cleanOutlier(df_train)","ef7c4b94":"# plt.figure(figsize=(20,20))\n# plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)\n# for i,j in enumerate(df_train.select_dtypes(['int','float']).columns,):\n#     plt.subplot(10,4,i+1)\n#     feature=df_train.select_dtypes(['int','float'])[j]\n#     sns.boxplot(x=feature,data=df_train)","8a27cea2":"print(df_train.select_dtypes('object').shape)\nprint(df_train.select_dtypes(['int','float']).shape)\nprint(df_train.shape)","7715fe05":"#before dropping categorical variable visualizations\nplt.figure(figsize=(30,40))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=1)\nfor i,j in enumerate(df_train.select_dtypes('object').columns,):\n    plt.subplot(11,4,i+1)\n    s=sns.countplot(x=j,data=df_train)\n    s.set_xticklabels(s.get_xticklabels(),rotation=45)\nplt.show(block=False)","e1f11ddd":"#We remove the weak representations of our categorical variables from our data because the explanatory effect on the dependent variable is low.\ndf_train.drop([i for i in df_train if df_train[i].value_counts().max()>len(df_train)*0.80],axis=1,inplace=True)","d46db0dd":"#categorical variable visualizations\nplt.figure(figsize=(30,40))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=1)\nfor i,j in enumerate(df_train.select_dtypes('object').columns,):\n    plt.subplot(10,4,i+1)\n    s=sns.countplot(x=j,data=df_train)\n    s.set_xticklabels(s.get_xticklabels(),rotation=45)\nplt.show(block=False)","d02250d8":"df_train.shape","d71fafb6":"#Our last edited train data\ndf_train_end=pd.get_dummies(df_train,df_train.select_dtypes('object').columns,drop_first=True,dtype='int')\ndf_train_end","4038cb67":"submission=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest=pd.concat([test,submission],axis=1)\ntest.drop('Id',axis=1,inplace=True)\ndf_test=test.copy()\ntest.head(5)\n","b590bf07":"df_test=df_test[df_train.columns]","583b79df":"#msng.matrix(df_test)","898a2e37":"df_test=cleanData(df_test)","8f1fcd44":"#df_test=cleanOutlier(df_test)","b6350383":"df=pd.concat([df_train,df_test])","2620eb15":"df_end=pd.get_dummies(df,df.select_dtypes('object').columns)","a1943042":"df_end","a884a8f5":"#msng.matrix(df_test[(df_test.isnull().sum().sort_values(ascending=False).head(20)>0).index])","9a538af9":"#df_test_end=pd.get_dummies(df_test,df_test.select_dtypes('object').columns)\n#df_test_end","2e6abc6f":"#new_cols= list(set(df_train_end.columns) - set(df_test_end.columns))\n#new_cols","fab94003":"#df_train_end.drop(new_cols,axis=1,inplace=True)\n#df_train_end","fa4f516b":"#dum_df=pd.DataFrame(data=np.zeros(shape=(len(df_test_end),len(new_cols))),columns=new_cols,dtype='int')","27b1447f":"#test_x=pd.concat([df_test_end,dum_df],axis=1)\n#df_test_end=test_x[df_train_end.columns]\n#df_test_end=df_test_end[df_train_end.columns]\n#df_test_end","695cbb6a":"#print(df_test_end.shape)\n#print(df_train_end.shape)","bebb2b28":"from sklearn.preprocessing import StandardScaler\nx_train=df_end.drop('SalePrice',axis=1)[:len(df_train)].values\ny_train=df_end['SalePrice'][:len(df_train)].values\nx_test=df_end.drop('SalePrice',axis=1)[len(df_train):].values\ny_test=submission.SalePrice.values\n\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\n\nx_test=sc.transform(x_test)","f6571f70":"#xgb.XGBRegressor?","f7816dc9":"import xgboost  as xgb\nxgb_tuned=xgb.XGBRegressor(learning_rate=0.1,\n                            n_estimators=150,\n                            max_depth=20,\n                            subsample=0.7,         \n                            colsample_bytree=0.5,\n                            seed=27,\n                            reg_alpha=0.6).fit(x_train,y_train,verbose=True)\n\n#model train\nprint('Model train')\nprint('rmse: ',np.sqrt(mean_squared_error(y_train,xgb_tuned.predict(x_train))))\nprint('r2: ',r2_score(y_train,xgb_tuned.predict(x_train)))\n\n\nprint('Model test')\nprint('rmse :',np.sqrt(mean_squared_error(y_test,xgb_tuned.predict(x_test))))\nprint('r2 :',r2_score(y_test,xgb_tuned.predict(x_test)))","8b2c3b51":"from sklearn.decomposition import PCA\npca=PCA()\nx_reduce_train=pca.fit_transform(x_train)\nx_reduce_test=pca.fit_transform(x_test)","824fc636":"np.cumsum(np.round(pca.explained_variance_ratio_,decimals=4)*100)[:110]\n","8adfd279":"from sklearn import model_selection           \ncv_5=model_selection.KFold(n_splits=5,shuffle=True,random_state=1) \n\nRMSE=[]\nxgb_tuned=xgb.XGBRegressor( reg_lambda=0.1,\n                            reg_alpha=0.1,\n                            max_leaves=5,\n                            n_estimators=100,\n                            gamma=0.2, \n                            learning_rate=0.1,\n                            max_depth=3,\n                            random_state=42,      \n                            subsample=0.5)\n\nfor i in np.arange(1,x_reduce_train.shape[1]+1):\n    score=np.sqrt(-1*model_selection.cross_val_score(xgb_tuned,x_reduce_train[:,:i],\n                                                     y_train,\n                                                     cv=cv_5,\n                                                     scoring='neg_mean_squared_error').mean())\n    RMSE.append(score)\n    ","29933d91":"import matplotlib.pyplot as plt\nplt.plot(RMSE,'-v')\nplt.xlabel('number of component')\nplt.ylabel('RMSE')\n","ee4abeb1":"pca_feature=80\nxgb_tuned=xgb.XGBRegressor( reg_lambda=1,\n                            reg_alpha=1,\n                            max_leaves=10,\n                            n_estimators=300,\n                            gamma=0.2, \n                            learning_rate=0.1,\n                            max_depth=15,\n                            random_state=42,      \n                            subsample=0.9).fit(x_reduce_train[:,:pca_feature],y_train,verbose=True)\n\n\n\n#model train\n\nprint('Model train')\nprint('rmse: ',np.sqrt(mean_squared_error(y_train,xgb_tuned.predict(x_reduce_train[:,:pca_feature]))))\nprint('r2: ',r2_score(y_train,xgb_tuned.predict(x_reduce_train[:,:pca_feature])))\n\n\nprint('Model test')\nprint('rmse :',np.sqrt(mean_squared_error(y_test,xgb_tuned.predict(x_reduce_test[:,:pca_feature]))))\nprint('r2 :',r2_score(y_test,xgb_tuned.predict(x_reduce_test[:,:pca_feature])))","0a8fd124":"submission_new=pd.DataFrame()\nsubmission_new['SalePrice']=xgb_tuned.predict(x_reduce_test[:,:pca_feature])\nsubmission_new.index=submission['Id']\nsubmission_new.to_csv('\/kaggle\/working\/submission.csv')","2a6b647c":"submission_new","7e539e53":"### msng.matrix(df_test)","784b3214":"# PCA","a3c9b844":"# TEST data preprocessing","4ca3dd5b":"from sklearn.preprocessing import StandardScaler\nx_train=df_train_end.drop('SalePrice',axis=1).values\ny_train=df_train_end['SalePrice'].values\nx_test=df_test_end.drop('SalePrice',axis=1).values\ny_test=submission.SalePrice.values\n\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.transform(x_test)\n"}}