{"cell_type":{"eec16cb7":"code","8fe980d7":"code","bd4520cb":"code","ef522929":"code","b73ba6f2":"code","0cfd57f1":"code","eefdebf2":"markdown","d761f224":"markdown","2e9abf60":"markdown","7bfdbe66":"markdown","81b363fd":"markdown","80426243":"markdown","e41e2ef8":"markdown","7fc9cc2a":"markdown"},"source":{"eec16cb7":"import numpy as np \nimport pandas as pd ","8fe980d7":"data = pd.read_csv('\/kaggle\/input\/supermarket\/GroceryStoreDataSet.csv', header=None)\ndata.head()\ntransactions = []\nfor i in range(len(data)):\n    transactions.append(data.values[i, 0].split(','))\nprint(transactions)","bd4520cb":"class Apriori:\n    \n    def __init__(self, transactions, min_support, min_confidence):\n        self.transactions = transactions\n        self.min_support = min_support # The minimum support.\n        self.min_confidence = min_confidence # The minimum confidence.\n        self.support_data = {} # A dictionary. The key is frequent itemset and the value is support.      \n        \n    def create_C1(self):\n        \"\"\"\n        create frequent candidate 1-itemset C1 by scaning data set.\n        Input:\n            None\n        Output:\n            C1: A set which contains all frequent candidate 1-itemsets\n        \"\"\"\n        C1 = set()\n        for transaction in self.transactions:\n            for item in transaction:\n                C1.add(frozenset([item]))\n        return C1\n    \n    def create_Ck(self, Lksub1, k):\n        \"\"\"\n        Create Ck.\n        Input:\n            Lksub1: Lk-1, a set which contains all frequent candidate (k-1)-itemsets.\n            k: the item number of a frequent itemset.\n        Output:\n            Ck: A set which contains all all frequent candidate k-itemsets.\n        \"\"\"\n        \n        Ck = set()\n        len_Lksub1 = len(Lksub1)\n        list_Lksub1 = list(Lksub1)\n        for i in range(len_Lksub1):\n            for j in range(i+1, len_Lksub1):\n                l1 = list(list_Lksub1[i])\n                l2 = list(list_Lksub1[j])\n                l1.sort()\n                l2.sort()\n                if l1[0:k-2] == l2[0:k-2]:\n                    # TODO: self joining Lk-1\n                    Ck_tmp = list(set(l1) | (set(l2)))\n                    # TODO: pruning\n                    flag = 1\n                    for k in range(len(Ck_tmp)):\n                        tmp = Ck_tmp.copy()\n                        tmp.pop(k)\n                        if not set(tmp) in Lksub1:\n                            flag = 0\n                            break\n                    if flag:\n                        Ck.add(frozenset(Ck_tmp))\n        return Ck\n    \n    def generate_Lk_from_Ck(self, Ck):\n        \"\"\"\n        Generate Lk by executing a delete policy from Ck.\n        Input:\n            Ck: A set which contains all all frequent candidate k-itemsets.\n        Output:\n            Lk: A set which contains all all frequent k-itemsets.\n        \"\"\"\n        \n        Lk = set()\n        item_count = {}\n        for transaction in self.transactions:\n            for item in Ck:\n                if item.issubset(transaction):\n                    if item not in item_count:\n                        item_count[item] = 1\n                    else:\n                        item_count[item] += 1\n        t_num = float(len(self.transactions))\n        for item in item_count:\n            support = item_count[item] \/ t_num\n            if support >= self.min_support:\n                Lk.add(item)\n                self.support_data[item] = support\n        return Lk\n        \n    def generate_L(self):\n        \"\"\"\n        Generate all frequent item sets..\n        Input:\n            None\n        Output:\n            L: The list of Lk.\n        \"\"\"        \n        self.support_data = {}\n        \n        C1 = self.create_C1()\n        L1 = self.generate_Lk_from_Ck(C1)\n        Lksub1 = L1.copy()\n        L = []\n        L.append(Lksub1)\n        i = 2\n        while True:\n            Ci = self.create_Ck(Lksub1, i)\n            Li = self.generate_Lk_from_Ck(Ci)\n            if Li:\n                Lksub1 = Li.copy()\n                L.append(Lksub1)\n                i += 1\n            else:\n                break\n        return L\n        \n        \n    def generate_rules(self):\n        \"\"\"\n        Generate association rules from frequent itemsets.\n        Input:\n            None\n        Output:\n            big_rule_list: A list which contains all big rules. Each big rule is represented\n                       as a 3-tuple.\n        \"\"\"\n        L = self.generate_L()\n        \n        big_rule_list = []\n        sub_set_list = []\n        for i in range(0, len(L)):\n            for freq_set in L[i]:\n                for sub_set in sub_set_list:\n                    if sub_set.issubset(freq_set):\n                        # TODO : compute the confidence\n                        conf = float(format(self.support_data[freq_set] \/ self.support_data[freq_set - sub_set],'.3f'))\n                        big_rule = (set(freq_set - sub_set), set(sub_set), conf)\n                        if conf >= self.min_confidence and big_rule not in big_rule_list:\n                            big_rule_list.append(big_rule)\n                sub_set_list.append(freq_set)\n        return big_rule_list\n        ","ef522929":"model = Apriori(transactions, min_support=0.1, min_confidence=0.75)","b73ba6f2":"L = model.generate_L()\n\nfor Lk in L:\n    print('frequent {}-itemsets\uff1a\\n'.format(len(list(Lk)[0])))\n\n    for freq_set in Lk:\n        print(set(freq_set), 'support:', model.support_data[freq_set])\n    \n    print()","0cfd57f1":"rule_list = model.generate_rules()\n\nfor item in rule_list:\n    print(item[0], \"=>\", item[1], \"confidence: \", item[2])","eefdebf2":"**Step 2: Inplementation of Apriori algorithm**","d761f224":"** Step 0\uff1aEnvironment Setup**","2e9abf60":"    3. Association rule mining","7bfdbe66":"    1. Model construction","81b363fd":"**Step 1: Data Preparation**","80426243":"**Step 3\uff1a Test Algorithm**","e41e2ef8":"# Apriori Algorithm\n\nThis is the first homework of EE448. In this work, you should be familiar with the Apriori algorithm and complete its implementation.\n\nThe specific points involved are, \n* candidate generation : self-joining\n* candidate generation : pruning\n* association rule mining: calculation of confidence","7fc9cc2a":"    2. Frequent item set mining"}}