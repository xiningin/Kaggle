{"cell_type":{"9c7a53b4":"code","1c7e3d3e":"code","e87a0c2c":"code","ac7c58a2":"code","9fdd094c":"code","09fe4f16":"code","2a2fa995":"code","40980a40":"code","264aaccd":"code","f9786277":"code","f0a10405":"code","7d60f192":"code","0c67f645":"code","5f3a69dd":"code","a5088c35":"code","622e018d":"code","53c01f5a":"code","98771f9f":"code","843f0d67":"code","938b132d":"code","f968b76d":"code","8ee8491d":"code","0c881922":"code","4f61ab39":"code","fcfc53eb":"code","1729f7b0":"code","2bae2e7a":"code","467076e8":"code","8c046bf3":"code","ba749bf3":"code","987011c1":"code","1f6390ac":"code","6ab9e568":"code","d154d6d1":"code","0228e806":"code","3fda582f":"code","8691f2f1":"code","fdc0b4b8":"markdown","36d241c4":"markdown","e039f719":"markdown","f6dc64be":"markdown"},"source":{"9c7a53b4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nnp.set_printoptions(precision=4)\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score , confusion_matrix, f1_score, roc_auc_score\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom IPython.display import display,Markdown,HTML\nimport warnings\nwarnings.filterwarnings('ignore')","1c7e3d3e":"df = pd.read_csv('..\/input\/noshowappointments\/KaggleV2-May-2016.csv')\ndf.head(5)","e87a0c2c":"df.shape","ac7c58a2":"df.isna().sum()","9fdd094c":"df.info()","09fe4f16":"df.duplicated().sum()","2a2fa995":"df['ScheduledDay'] = df['ScheduledDay'].apply(np.datetime64)\ndf['AppointmentDay'] = df['AppointmentDay'].apply(np.datetime64)\ndf['diff_days'] = (df['AppointmentDay'] - df['ScheduledDay']).dt.days\ndf['diff_days']","40980a40":"df['diff_days'].describe()","264aaccd":"df = df.drop(['ScheduledDay','AppointmentDay','PatientId','AppointmentID'],axis=1)\ndf.columns","f9786277":"df['No-show'] = [1 if x == 'Yes' else 0 for x in df['No-show']]\ndf['No-show']","f0a10405":"df['Gender'] = [0 if x == 'F' else 1 for x in df['Gender']]\ndf['Gender']","7d60f192":"text_negative = \"Negative\"\ntext_positive = \"Positive\"\ntarget_column = \"No-show\"\n\ndf_all = df.copy()\n\ndf_positive = df[df[target_column]==1]\n\ndf_negative = df[df[target_column]==0]","0c67f645":"def plot_pie(column, title=\"All Group\/Class\"):\n    fig,axs = plt.subplots(1,1)\n    data = df_all[column].value_counts()\n    plt.pie(data,autopct='%1.2f%%',labels=data.index)\n    plt.title(title)\n    plt.show()\n    \ndef plot_hist(column, title=\"All Group\/Class\"):\n    plt.hist(df_all[column],density=True)\n    plt.title(title)\n    plt.show()\n\ndef plot_bar(column, sort=False, title=\"All Group\/Class\"):\n    if sort:\n        data_all = df_all[column].value_counts().sort_index()\n    else:\n        data_all = df_all[column].value_counts()\n    plt.bar(data_all.index.astype(str),data_all)\n    plt.title(title)\n    plt.show()\n    \ndef plot_bar_compare(column, sort=False):\n    if sort:\n        data_positive = df_positive[column].value_counts().sort_index()\n        data_negative = df_negative[column].value_counts().sort_index()\n    else:\n        data_positive = df_positive[column].value_counts()\n        data_negative = df_negative[column].value_counts()\n    \n    fig,axs = plt.subplots(2,1)\n    plt.subplots_adjust(left=0, bottom=0, right=1, top=2, wspace=0, hspace=0.2)\n    axs[0].bar(data_negative.index.astype(str),data_negative)\n    axs[0].title.set_text(text_negative)\n    axs[1].bar(data_positive.index.astype(str),data_positive)\n    axs[1].title.set_text(text_positive)\n    plt.show()\n\ndef plot_hist_compare(column, bins=5):\n    plt.hist([df_negative[column], df_positive[column]] , color=['c','r'])\n    plt.legend((text_negative, text_positive))\n    plt.show()\n    \ndef plot_pie_compare(column):\n    data_positive = df_positive[column].value_counts()\n    data_negative = df_negative[column].value_counts()\n    \n    fig,axs = plt.subplots(2,1)\n    plt.subplots_adjust(left=0, bottom=0, right=1, top=2, wspace=0, hspace=0.2)\n    axs[0].pie(data_negative,autopct='%1.2f%%',labels=data_negative.index)\n    axs[0].title.set_text(text_negative)\n    axs[1].pie(data_positive,autopct='%1.2f%%',labels=data_positive.index)\n    axs[1].title.set_text(text_positive)\n    plt.show()\n\ndef plot_boxplot(column, title=\"\"):\n    ax = sns.boxplot(x=target_column, y=column, palette=[\"c\", \"r\"],\n            hue=target_column,  data=df_all).set_title(title, fontsize=15)\n    plt.show()\n\ndef check_median(column):\n    data_negative = df_negative[column].describe()\n    data_positive = df_positive[column].describe()\n    print(\"Median:\")\n    print('{}: {}'.format(text_negative,data_negative['50%']))\n    print('{}: {}'.format(text_positive,data_positive['50%']))\n\ndef check_most(column):\n    data_negative = df_negative[column].value_counts()\n    data_positive = df_positive[column].value_counts()\n    print(\"Most:\")\n    print('{}: {}'.format(text_negative,data_negative.index[0]))\n    print('{}: {}'.format(text_positive,data_positive.index[0]))","5f3a69dd":"def eda(df_all):\n    display(HTML('<h1>Exploratory Data Analysis<h1>'))\n    \n    for column in df_all.columns:\n        if column == target_column:\n            continue\n        display(HTML('<h2>{}<h2>'.format(column)))\n        if df[column].dtype == 'int64' or df[column].dtype == 'float64':\n            if len(df[column].unique())>10 :\n                plot_boxplot(column)\n                check_median(column)\n            else:\n                plot_bar(column)\n                plot_pie(column)\n                plot_pie_compare(column)\n                check_most(column)\n        elif df[column].dtype == 'object':\n            if len(df[column].unique())>10 :\n                df[column].value_counts().head(5)\n                df_negative[column].value_counts().head(5)\n                df_positive[column].value_counts().head(5)\n            else:\n                plot_bar(column)\n                plot_pie(column)\n                plot_pie_compare(column)\n                check_most(column)\n        else:\n            None","a5088c35":"df[target_column].value_counts()","622e018d":"plot_pie(target_column)","53c01f5a":"eda(df_all)","98771f9f":"df_all['Neighbourhood'].value_counts().head(10)","843f0d67":"df_negative['Neighbourhood'].value_counts().head(10)","938b132d":"df_positive['Neighbourhood'].value_counts().head(10)","f968b76d":"data = df.corr()\ndata","8ee8491d":"data = data.sort_values(by='No-show', ascending=False)\ndata['No-show']","0c881922":"X = df.copy()\n\ny = X[target_column]\n\nX = X.drop([target_column], axis=1)","4f61ab39":"#transform categorical data\nX = pd.get_dummies(X, columns=['Neighbourhood'], drop_first=True)","fcfc53eb":"#Split to data train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)","1729f7b0":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=1234)\n\nX_sm, y_sm = sm.fit_resample(X_train, y_train)\n\nprint(f'''Shape of X before SMOTE: {X.shape}\nShape of X after SMOTE: {X_sm.shape}''')\n\nprint('\\nBalance of positive and negative classes (%):')\ny_sm.value_counts(normalize=True) * 100","2bae2e7a":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nX_sm = sc.fit_transform(X_sm)\nX_test = sc.transform(X_test)","467076e8":"# Import ML Libraries\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = [[CatBoostClassifier(verbose=0),'CatBoost Classifier'],[XGBClassifier(eval_metric='error'),'XGB Classifier'], [RandomForestClassifier(),'Random Forest'], \n    [KNeighborsClassifier(), 'K-Nearest Neighbours'], [SGDClassifier(),'SGD Classifier'], [SVC(),'SVC'],[LGBMClassifier(),'LGBM Classifier'],\n              [GaussianNB(),'GaussianNB'],[DecisionTreeClassifier(),'Decision Tree Classifier'],[LogisticRegression(),'Logistic Regression'],[AdaBoostClassifier(),\"AdaBoostClassifier\"]]","8c046bf3":"for cls in classifiers:\n    model = cls[0]\n    model.fit(X_sm, y_sm)\n    \n    y_pred = model.predict(X_test)\n    print(cls[1])\n    print ('Confusion Matrix:')\n    print(confusion_matrix(y_test, y_pred))\n    print(\"Accuracy : \", accuracy_score(y_test, y_pred) *  100)\n    print(\"Recall : \", recall_score(y_test, y_pred) *  100)\n    print(\"Precision : \", precision_score(y_test, y_pred) *  100)\n    print(\"F1 : \", f1_score(y_test, y_pred) *  100)\n    print(\"ROC AUC : \", roc_auc_score(y_test, y_pred) *  100)","ba749bf3":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.losses import BinaryCrossentropy","987011c1":"X_train.shape","1f6390ac":"#train the model\nmodel = Sequential()\nmodel.add(Dense(128, input_shape=(89,), activation='relu')),\nmodel.add(Dropout(0.5)),\nmodel.add(Dense(64, activation='relu')),\nmodel.add(Dropout(0.3)),\nmodel.add(Dense(32, activation='relu')),\nmodel.add(Dropout(0.2)),\nmodel.add(Dense(16, activation='relu')),\nmodel.add(Dropout(0.2)),\nmodel.add(Dense(1, activation='sigmoid'))","6ab9e568":"opt = Adam(learning_rate=0.0001)\nearlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='max',patience=15, verbose=1,restore_best_weights=True)\nmodel.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\nhistory = model.fit(X_sm, y_sm, batch_size=32, epochs=200,validation_split = 0.15, callbacks = [earlystopper],verbose = 1)\nhistory_dict = history.history","d154d6d1":"loss_values = history_dict['loss']\nval_loss_values=history_dict['val_loss']\nplt.plot(loss_values,'b',label='training loss')\nplt.plot(val_loss_values,'r',label='val training loss')\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.show()","0228e806":"accuracy_values = history_dict['accuracy']\nval_accuracy_values=history_dict['val_accuracy']\nplt.plot(val_accuracy_values,'-r',label='val_accuracy')\nplt.plot(accuracy_values,'-b',label='accuracy')\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.show()","3fda582f":"y_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5)\ny_pred = [1 if x == True else 0 for x in y_pred]","8691f2f1":"print(confusion_matrix(y_test, y_pred))\nprint(\"Accuracy : \", accuracy_score(y_test, y_pred) *  100)\nprint(\"Recall : \", recall_score(y_test, y_pred) *  100)\nprint(\"Precision : \", precision_score(y_test, y_pred) *  100)\nprint(\"F1 : \", f1_score(y_test, y_pred) *  100)\nprint(\"ROC AUC : \", roc_auc_score(y_test, y_pred) *  100)","fdc0b4b8":"# No Show","36d241c4":"The Best Algorithm is **SVC**\n\n* Accuracy :  78.67999638107301\n* Recall :  11.498881431767337\n* Precision :  40.440597954366645\n* F1 :  17.906288103117923\n* ROC AUC :  53.603262444166724\n\n","e039f719":"# Neighbourhood","f6dc64be":"# Data Preprocessing"}}