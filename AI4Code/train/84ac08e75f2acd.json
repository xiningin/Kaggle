{"cell_type":{"6618b2b0":"code","22b8700b":"code","bba6171f":"code","81099daf":"code","7c1f4c4f":"code","3b3c2770":"code","693a1cd7":"code","172ccf4c":"code","d2dad3eb":"code","741939c7":"code","6f385b24":"markdown","0ab2a4f2":"markdown","dfc2b4d2":"markdown","af30eb9b":"markdown","35486a8f":"markdown","3b12c596":"markdown","82dfb41e":"markdown","4938c9ac":"markdown"},"source":{"6618b2b0":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt","22b8700b":"df=pd.read_excel('..\/input\/number-of-sold-cars-by-country-by-year\/cars_sold.xlsx')\nprint(\"First rows\")\ndf.head()\n","bba6171f":"print(\"Last rows\")\ndf.tail()","81099daf":"#define training and testing sets\nfeatures=['2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018']\nX=df[features]\nX.head()\ny=df['2019']\ny.head()\nX_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.20, random_state=4)","7c1f4c4f":"#scoring model by mean_abs_error for different max_leaf_nodes\nmae=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    mae.append(mean_absolute_error(y_test, y_predict))\n#plotting MAE variation by Max leaf nodes\nplt.figure(figsize=(8,8),edgecolor='red')\nplt.plot(mae)\nplt.ylabel('MAE')\nplt.xlabel('Max Leaf Nodes')","3b3c2770":"#scoring model by r2_score for different max_leaf_nodes\nR2=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    R2.append(r2_score(y_test, y_predict))\n#plotting R2 variation by Max leaf nodes\nplt.figure(figsize=(10,10),edgecolor='red')\nplt.plot(R2)\nplt.ylabel('R2')\nplt.xlabel('Max Leaf Nodes')","693a1cd7":"#scoring model by explained variance for different max_leaf_nodes\nExp_var=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    Exp_var.append(explained_variance_score(y_test, y_predict))\n#plotting explained variance score variation by Max leaf nodes\nplt.figure(figsize=(10,10),edgecolor='red')\nplt.plot(Exp_var)\nplt.ylabel('Exp_var')\nplt.xlabel('Max Leaf Nodes')","172ccf4c":"#scoring model by mean squarred log for different max_leaf_nodes\nm_s_l=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    m_s_l.append(mean_squared_log_error(y_test, y_predict))\n#plotting mean suarred log variation by Max leaf nodes\nplt.figure(figsize=(10,10),edgecolor='red')\nplt.plot(m_s_l)\nplt.ylabel('mean_squ_log')\nplt.xlabel('Max Leaf Nodes')","d2dad3eb":"#define training and testing sets\nfeatures=['2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018']\nX=df[features]\nX.head()\ny=df['2019']\ny.head()\nX_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.05, random_state=4)","741939c7":"#scoring model by mean_abs_error for different max_leaf_nodes\nmae=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    mae.append(mean_absolute_error(y_test, y_predict))\n#plotting MAE variation by Max leaf nodes\nplt.figure(figsize=(5,5))\nplt.plot(mae,color='red')\nplt.ylabel('MAE')\nplt.xlabel('Max Leaf Nodes')\n#scoring model by r2_score for different max_leaf_nodes\nR2=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    R2.append(r2_score(y_test, y_predict))\n#plotting R2 variation by Max leaf nodes\nplt.figure(figsize=(5,5))\nplt.plot(R2,color='green')\nplt.ylabel('R2')\nplt.xlabel('Max Leaf Nodes')\n#scoring model by explained variance for different max_leaf_nodes\nExp_var=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    Exp_var.append(explained_variance_score(y_test, y_predict))\n#plotting explained variance score variation by Max leaf nodes\nplt.figure(figsize=(5,5))\nplt.plot(Exp_var,color='blue')\nplt.ylabel('Exp_var')\nplt.xlabel('Max Leaf Nodes')\n#scoring model by mean squarred log for different max_leaf_nodes\nm_s_l=[]\nfor i in range(98):\n    model = DecisionTreeRegressor(max_leaf_nodes=i+2,random_state=1)\n    model.fit(X_train,y_train)\n    y_predict=model.predict(X_test)\n    m_s_l.append(mean_squared_log_error(y_test, y_predict))\n#plotting mean suarred log variation by Max leaf nodes\nplt.figure(figsize=(5,5),edgecolor='red')\nplt.plot(m_s_l,color='magenta')\nplt.ylabel('mean_squ_log')\nplt.xlabel('Max Leaf Nodes')","6f385b24":"Then we define our training and test sets, as well as the features and the target.\nI choosed tharget = number of cars sold in 2019 so the model could predict the number of cars sold in 2019 by looking to the past years sales.\nI also choosed to split data to 80% training and 20% testing.\nAt the end of the notebook, I will change these values to observe the effect on the model.","0ab2a4f2":"Now, let's define our Decision Tree Regressor models with Max_leaf_nodes between 2 and 100, and score them with different tools:","dfc2b4d2":"Here I come the end of this notebook.\nI hope you enjoy it.\nPlease feel free to underline any mistake and to give my any useful advice so that I can improve my skills.\nSee you next notebook !!","af30eb9b":"1. Hi everybody !\nI'm so happy to share with you my first machine learning project.\nThe project is based on a dataset from https:\/\/knoema.com\/ which shows the number of cars sold in different countries every year (2006 to 2019)\nThe aim of this notebook is to apply Decision Tree Regressor and to evaluate its error for different values of Max Leaf Nodes.\nAt the end I also explore the effect of the size of testing and training sets on the performance of the model.\nI hope you will appreciate this project from a beginner and that you will give me all the advice and observations you can.","35486a8f":"Comment:\nAs you can see from the plots : under some value of max_leaf_nodes (around 20) the model gets more accurate by increasing leaf nodes. Beyond that value, the accuracy is stable.\n\nNow let's see what happens when we decrease the test set size : which mean we will produce a model that is more linked to the training set...","3b12c596":"Then we import and print our data:","82dfb41e":"We first start with importing all necessary tools:","4938c9ac":"Comment:\nThis show that when we decrease the test set size to 5% we get an overfitted model: the model appears to reach 100% accuracy faster (with less leaf nodes), but in fact it's useless because it won't be able to predict target for new values with the same accuracy as in the training time."}}