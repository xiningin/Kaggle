{"cell_type":{"1ef1a8ab":"code","c298e797":"code","d90780f1":"code","cc4f838b":"code","ada07269":"code","b9601a91":"code","960cb07f":"code","08352653":"code","ee8fe4b3":"code","8eae6b7a":"code","f12cecda":"code","61d8828f":"code","085d206f":"code","1a6f435d":"code","52f1ff58":"code","4789a77e":"code","53aa9f04":"code","dbba01b5":"code","76f795e7":"code","271d3bb9":"code","2fd90d94":"code","47f6d3fb":"code","401c7c5b":"code","6006048c":"code","f8405409":"code","244aab8c":"code","7b2acd2c":"code","ae0a5b05":"code","29841d9a":"code","94893f3e":"code","b2699950":"code","693ec2e0":"code","40ddce26":"code","a0bdedf6":"code","da7151f4":"code","b1f35735":"code","a16be528":"code","854d8292":"code","fe91c005":"code","626a2957":"code","80f4bb06":"code","256ae0cd":"code","f375799b":"code","276a0a92":"code","4d8c1fa1":"code","5fcefe7c":"code","1e340322":"code","7f6767e1":"code","87d16718":"code","92c9032a":"code","b7ca1571":"code","b8fc7455":"code","1583b4ae":"code","6d0a890a":"markdown","8557c8f1":"markdown","86d475ed":"markdown","78a44234":"markdown","8d819963":"markdown","31608010":"markdown","7b9e302d":"markdown","5c5454f2":"markdown","0afefebf":"markdown","8ad9f274":"markdown","6dae32a7":"markdown","ede0d15f":"markdown","ce362801":"markdown","9a17cf65":"markdown","c61a71eb":"markdown","042485af":"markdown","8a5b1206":"markdown","a1fd1421":"markdown","efd3149e":"markdown","73a18f74":"markdown","01da29fd":"markdown","a7e28289":"markdown","b07e931a":"markdown","a8c1edc4":"markdown","99edbf1d":"markdown","78bbe5ee":"markdown","e0d26715":"markdown","a07961dc":"markdown","8060b7be":"markdown","ac40bc24":"markdown","4a094e7c":"markdown","de314c5c":"markdown","d1efc425":"markdown","b6ee2041":"markdown","f19fea4b":"markdown","0bfdfe71":"markdown","11fa6a0c":"markdown","84daef89":"markdown","f161c693":"markdown","e6300431":"markdown"},"source":{"1ef1a8ab":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:90% !important; }<\/style>\"))","c298e797":"%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nsns.set() # seaborn \uc18d\uc131\uc744 \uae30\ubcf8\uac12\uc73c\ub85c \uc124\uc815","d90780f1":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\n#from enum import Enum\nclass Columns:\n    # \uc6d0\ub798 \uc874\uc7ac\ud558\ub294 \ud56d\ubaa9\n    PassengerId = \"PassengerId\"\n    Survived = \"Survived\"\n    Pclass = \"Pclass\"\n    Name = \"Name\"\n    Sex = \"Sex\"\n    Age = \"Age\"\n    SibSp = \"SibSp\"\n    Parch = \"Parch\"\n    Ticket = \"Ticket\"\n    Fare = \"Fare\"\n    Cabin = \"Cabin\"\n    Embarked = \"Embarked\"\n    \n    # \uc0c8\ub85c \uc0dd\uc131\ud558\ub294 \ud56d\ubaa9\n    Title = \"Title\"\n    FareBand = \"FareBand\"\n    Family = \"Family\"\n    Deck = \"Deck\" # Cabin\uc758 \uc54c\ud30c\ubcb3\uc744 \ub5bc\uc11c Deck\uc744 \uc9c0\uc815\ud55c\ub2e4.\n    CabinExists = \"CabinExists\"","cc4f838b":"train.head()","ada07269":"test.head()","b9601a91":"print(train[[Columns.Pclass, Columns.Survived]].head())\ntrain[[Columns.Pclass, Columns.Survived]].groupby([Columns.Pclass]).mean().plot.bar()","960cb07f":"train[[Columns.Sex, Columns.Survived]].groupby([Columns.Sex]).mean().plot.bar()","08352653":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(10, 8))\nsns.countplot(x=Columns.Sex, hue=Columns.Survived, data=train, ax=ax[0])\nsns.countplot(x=Columns.Sex, hue=Columns.Pclass, data=train, ax=ax[1])\nsns.countplot(x=Columns.Pclass, hue=Columns.Survived, data=train, ax=ax[2])","ee8fe4b3":"train[Columns.Age].plot.kde() # \uac00\uc6b0\uc2dc\uc548 \ucee4\ub110 \ud568\uc218\ub97c \uc0ac\uc6a9\ud574\uc11c KDE plot\uc744 \uadf8\ub9bc","8eae6b7a":"df = train[train[Columns.Age].isnull() == False] # Age\uac00 \uc5c6\ub294 \ub370\uc774\ud130\ub294 \ube80\ub2e4.\n#df.describe()\n\nbincount = 12\n# \ub098\uc774\ub300\ub85c \ub098\ub204\uc5b4\uc11c \ucd9c\ub825\ud574 \ubcf8\ub2e4.\nage_min = df[Columns.Age].min().astype('int')\nage_max = df[Columns.Age].max().astype('int')\nprint(\"Age :\", age_min, \" ~ \", age_max)\ngap = ((age_max - age_min) \/ bincount).astype(int)\nprint('gap:', gap)\n\nbins = [-1]\nfor i in range(bincount):\n    bins.append(i * gap)\nbins.append(np.inf)\nprint(bins)\n\n_df = df\n_df['AgeGroup'] = pd.cut(_df[Columns.Age], bins) #bins\ub85c \uad6c\ubd84\ub41c 'AgeGroup' category column\uc744 \uc0dd\uc131\ud55c\ub2e4.\nfig, ax = plt.subplots(figsize=(20, 10))\nsns.countplot(x='AgeGroup', hue=Columns.Survived, data=_df, ax=ax) #'AgeGroup'\uc744 \uae30\uc900\uc73c\ub85c \uc0dd\uc874\/\uc0ac\ub9dd \uc218\ub97c \ud45c\uc2dc\ud55c\ub2e4.","f12cecda":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(16, 20))\nsns.violinplot(x=Columns.Pclass, y=Columns.Age, hue=Columns.Survived, data=train, scale='count', split=True, ax=ax[0])\nsns.violinplot(x=Columns.Sex, y=Columns.Age, hue=Columns.Survived, data=train, scale='count', split=True, ax=ax[1])\nsns.violinplot(x=Columns.Pclass, y=Columns.Sex, hue=Columns.Survived, data=train, scale='count', split=True, ax=ax[2])\n","61d8828f":"_train = train\n_train['Family'] = _train[Columns.SibSp] + _train[Columns.Parch] + 1 #\ud615\uc81c + \uc9c1\uacc4 + \uc790\uae30\uc790\uc2e0(1)\n_train[['Family', Columns.Survived]].groupby('Family').mean().plot.bar()","085d206f":"train[Columns.Age].plot.hist() # \uc2b9\uac1d\ub4e4\uc758 \ub098\uc774 \ubd84\ud3ec","1a6f435d":"sns.countplot(x='Family', data=_train)","52f1ff58":"sns.countplot(x='Family', hue=Columns.Survived, data=_train)","4789a77e":"train_len = train.shape[0]\n'''\nignore_index=True\ub85c \ud558\uc9c0 \uc54a\uc73c\uba74 test\uc758 \uc778\ub371\uc2a4\uac00 0\ubd80\ud130 \uc2dc\uc791\ud574\uc11c iterrow()\ub4f1\uc758 \ubc18\ubcf5\uc790\ub97c \n\uc0ac\uc6a9\ud560 \ub54c \uc624\ub3d9\uc791\ud55c\ub2e4.(0\uc774 \ub450\uac1c\uac00 \ub418\ub294 \ub4f1)\n'''\n\nmerged = train.append(test, ignore_index=True) \nprint(\"train len : \", train.shape[0])\nprint(\"test len : \", test.shape[0])\nprint(\"merged len : \", merged.shape[0])","53aa9f04":"merged[Columns.Family] = merged[Columns.Parch] + merged[Columns.SibSp] + 1\nif Columns.Parch in merged:    \n    merged = merged.drop([Columns.Parch], axis=1)\nif Columns.SibSp in merged:\n    merged = merged.drop([Columns.SibSp], axis=1)\n    \nmerged.head()","dbba01b5":"most_embarked_label = merged[Columns.Embarked].value_counts().index[0]\n\nmerged = merged.fillna({Columns.Embarked : most_embarked_label})\nmerged.describe(include=\"all\")","76f795e7":"# Name\uc5d0\uc11c Title \ucd94\ucd9c(\uadf8\ub0e5 \uc54c\ud30c\ubcb3 \ub05d\uc5d0 .\uc774 \ubd99\uc5b4 \uc788\ub294\uac78 \ucd94\ucd9c\ud55c\ub2e4.)\nmerged[Columns.Title] = merged.Name.str.extract('([A-Za-z]+)\\. ', expand=False) # expand:True\uba74 DataFrame\uc744, False\uba74 Series\ub97c \ub9ac\ud134\ud55c\ub2e4.\n\nprint(\"initial titles : \", merged[Columns.Title].value_counts().index)\n#initial titles :  Index(['Mr', 'Miss', 'Mrs', 'Master', 'Dr', 'Rev', 'Col', 'Ms', 'Mlle', 'Major',\n#                         'Sir', 'Jonkheer', 'Don', 'Mme', 'Countess', 'Lady', 'Dona', 'Capt'],\n\n# \uc815\ub9ac(\ud76c\uadc0\ud55c title\uc744 \ubaa8\uc544\uc11c \uc815\ub9ac\ud55c\ub2e4.)\nmerged[Columns.Title] = merged[Columns.Title].replace(['Lady', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\nmerged[Columns.Title] = merged[Columns.Title].replace(['Countess', 'Lady', 'Sir'], 'Royal')\nmerged[Columns.Title] = merged[Columns.Title].replace(['Miss', 'Mlle', 'Ms', 'Mme'], 'Mrs')\n\nprint(\"Survival rate by title:\")\nprint(\"========================\")\nprint(merged[[Columns.Title, Columns.Survived]].groupby(Columns.Title).mean())\n\nidxs = merged[Columns.Title].value_counts().index # \ub9ce\uc740 \uc21c\uc11c\ub300\ub85c \uc815\ub82c\ud574\uc11c \uc624\ub984\ucc28\uc21c\uc73c\ub85c \uac12\uc744 \ub9e4\uae40\nprint(idxs)\n\n# \uc22b\uc790\uac12\uc73c\ub85c \ubcc0\uacbd\ud55c\ub2e4.\nmapping = {}\nfor i in range(len(idxs)):\n    mapping[idxs[i]] = i + 1\nprint(\"Title mapping : \", mapping)\nmerged[Columns.Title] = merged[Columns.Title].map(mapping)\n\nif Columns.Name in merged:\n    merged = merged.drop([Columns.Name], axis=1)\n    \nmerged.head()","271d3bb9":"sns.countplot(x=Columns.Title, hue=Columns.Survived, data=merged)\nprint(merged[Columns.Title].value_counts())","2fd90d94":"mapping = {'male':0, 'female':1}\nmerged[Columns.Sex] = merged[Columns.Sex].map(mapping)","47f6d3fb":"merged.head(n=10)","401c7c5b":"# {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5, 'Royal': 6}\n\nmapping = {1:21, 2:28, 3:28, 4:40, 5:50, 6:60}\ndef guess_age(row):\n    return mapping[row[Columns.Title]]\n\ndef fixup_age(df):\n    for idx, row in df[df[Columns.Age].isnull() == True].iterrows():\n        df.loc[idx, Columns.Age] = guess_age(row)\n    return df\n    \nmerged = fixup_age(merged)\nmerged.describe(include='all')","6006048c":"def make_deck(df):\n    '''\n    Cabin\uc5d0\uc11c \uc54c\ud30c\ubcb3\uc744 \ub5bc\uc11c Deck \uc54c\ud30c\ubcb3\uc744 \uc0dd\uc131\ud55c\ub2e4.\n    '''\n    df[Columns.Deck] = df[Columns.Cabin].str.extract('([A-Za-z]+)', expand=True)\n    return df\n\nmerged = make_deck(merged)\nmerged.describe(include='all')","f8405409":"merged[[Columns.Deck, Columns.Fare]].groupby(Columns.Deck).mean().sort_values(by=Columns.Fare)","244aab8c":"sns.countplot(x=Columns.Deck, hue=Columns.Survived, data=merged)","7b2acd2c":"print(\"total survived rate: \", merged[Columns.Survived].mean())\nprint(\"deck survived rate: \", merged[merged[Columns.Deck].isnull() == False][Columns.Survived].mean())\nprint(\"no deck survived rate: \", merged[merged[Columns.Deck].isnull()][Columns.Survived].mean())\n\nfig, ax = plt.subplots(2, 1, figsize=(16, 16))\nmerged[[Columns.Deck, Columns.Survived]].groupby(Columns.Deck).mean().plot.bar(ax=ax[0])\n\ndef generate_fare_group(df, slicenum):\n    if \"FareGroup\" in df:\n        df.drop(\"FareGroup\", axis=1)\n    # \ub098\uc774\ub300\ub85c \ub098\ub204\uc5b4\uc11c \ucd9c\ub825\ud574 \ubcf8\ub2e4.\n    _min = df[Columns.Fare].min().astype('int')\n    _max = df[Columns.Fare].max().astype('int')\n    print(\"Fare :\", _min, \" ~ \", _max)\n    gap = ((_max - _min) \/ slicenum).astype(int)\n    print('gap:', gap)\n\n    bins = [-1]\n    for i in range(slicenum):\n        bins.append(i * gap)\n    bins.append(np.inf)\n    print(bins)\n    df['FareGroup'] = pd.cut(df[Columns.Fare], bins)    \n    return df\n\ndf = generate_fare_group(merged.copy(), 16)\n\n# deck \uc815\ubcf4\uac00 \uc5c6\ub294 \uc0ac\ub78c\ub4e4\uc758 \uc694\uae08\uc5d0 \ub530\ub978 \uc0dd\uc874\uc790\/\uc0ac\ub9dd\uc790 \uc218\nsns.countplot(x=\"FareGroup\", hue=Columns.Survived, data=df[df[Columns.Deck].isnull()], ax=ax[1])\n","ae0a5b05":"merged[Columns.CabinExists] = (merged[Columns.Cabin].isnull() == False)\nmerged[Columns.CabinExists] = merged[Columns.CabinExists].map({True:1, False:0})","29841d9a":"merged.head()","94893f3e":"merged[merged[Columns.Fare].isnull()]","b2699950":"merged.loc[merged[Columns.Fare].isnull(), [Columns.Fare]] = merged[Columns.Fare].mean()","693ec2e0":"merged.head()","40ddce26":"sns.distplot(merged[Columns.Fare])","a0bdedf6":"'''\nlog\ub97c \ucde8\ud558\ub294 \ubc29\ubc95\n'''\n\n#merged[Columns.Fare] = merged[Columns.Fare].map(lambda i : np.log(i) if i > 0 else 0)\n\n'''\n\ub4f1\uae09\uc744 4\ub2e8\uacc4\ub85c \ub098\ub204\ub294 \ubc29\ubc95\n'''\nmerged[Columns.FareBand] = pd.qcut(merged[Columns.Fare], 4, labels=[1,2,3,4]).astype('float')\n#merged[Columns.Fare] = merged[Columns.FareBand]\n\nmerged.head(n=20)\n","da7151f4":"merged[Columns.Fare] = merged[Columns.FareBand]\nmerged = merged.drop([Columns.FareBand], axis=1)\nmerged.head()","b1f35735":"merged.head()","a16be528":"sns.distplot(merged[Columns.Fare])","854d8292":"merged.head()","fe91c005":"if Columns.Ticket in merged:\n    merged = merged.drop(labels=[Columns.Ticket], axis=1)\nif Columns.Cabin in merged:\n    merged = merged.drop(labels=[Columns.Cabin], axis=1)\nif Columns.Deck in merged:\n    merged = merged.drop(labels=[Columns.Deck], axis=1)\n\n# passengerId\ub294 \ub098\uc911\uc5d0 \uc0ad\uc81c\ud55c\ub2e4.\n# if Columns.PassengerId in merged:\n#     merged = merged.drop(labels=[Columns.PassengerId], axis=1)","626a2957":"merged.describe(include='all')","80f4bb06":"merged.head()","256ae0cd":"merged = pd.get_dummies(merged, columns=[Columns.Pclass], prefix='Pclass')\nmerged = pd.get_dummies(merged, columns=[Columns.Title], prefix='Title')\nmerged = pd.get_dummies(merged, columns=[Columns.Embarked], prefix='Embarked')\nmerged = pd.get_dummies(merged, columns=[Columns.Sex], prefix='Sex')\nmerged.head()","f375799b":"from sklearn.preprocessing import MinMaxScaler\n\nclass NoColumnError(Exception):\n    \"\"\"Raised when no column in dataframe\"\"\"\n    def __init__(self, value):\n        self.value = value\n    # __str__ is to print() the value\n    def __str__(self):\n        return(repr(self.value))\n\n# normalize AgeGroup\ndef normalize_column(data, columnName):\n    scaler = MinMaxScaler(feature_range=(0, 1))    \n    if columnName in data:\n        aaa = scaler.fit_transform(data[columnName].values.reshape(-1, 1)) # \uc785\ub825\uc744 2D \ub370\uc774\ud130\ub85c \ub123\uc5b4\uc57c \ud558\ubbc0\ub85c reshape\ud574 \uc900\ub2e4.\n        aaa = aaa.reshape(-1,) # \ub2e4\uc2dc \uc6d0\ubcf5\ud574\uc11c \ub123\uc5b4\uc8fc\uc9c0\ub9cc, \uadf8\ub0e5 \ub123\uc5b4\ub3c4 \uc54c\uc544\uc11c \uc81c\ub300\ub85c \ub4e4\uc5b4\uac04\ub2e4...\n        #print(aaa.shape)\n        data[columnName] = aaa\n        return data\n    else:\n        raise NoColumnError(str(columnName) + \" is not exists!\")\n\ndef normalize(dataset, columns):\n    for col in columns:\n        dataset = normalize_column(dataset, col)\n    return dataset","276a0a92":"merged.head()","4d8c1fa1":"merged = normalize(merged, [Columns.Age, Columns.Fare, Columns.Family])","5fcefe7c":"merged.head(n=10)","1e340322":"train = merged[:train_len]\ntest = merged[train_len:]\ntest = test.drop([Columns.Survived], axis=1)\n\ntrain = train.drop([Columns.PassengerId], axis=1)\n\ntest_passenger_id = test[Columns.PassengerId]\ntest = test.drop([Columns.PassengerId], axis=1)\n\nprint(train.shape)\nprint(test.shape)","7f6767e1":"train_X = train.drop([Columns.Survived], axis=1).values #Series.values\ub294 numpy array \ud0c0\uc785\uc758 \ub370\uc774\ud130\uc784\ntrain_Y = train[Columns.Survived].values.reshape(-1, 1)\nprint(train_X.shape)\nprint(train_Y.shape)","87d16718":"test.shape","92c9032a":"test.describe(include='all')","b7ca1571":"train.head()","b8fc7455":"test.head()","1583b4ae":"import keras\nfrom keras import layers, models\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_X = train_X.astype(np.float32)\ntrain_Y = train_Y.astype(np.float32)\n\nclass SimpleNN(models.Sequential):\n    def __init__(self, input_shape, dropout):\n        super().__init__()\n        \n        self.add(layers.Dense(units=20, activation='relu', input_shape=input_shape))\n        self.add(layers.Dropout(dropout))\n        \n        self.add(layers.Dense(units=8, activation='relu'))\n        self.add(layers.Dropout(dropout))\n        \n        self.add(layers.Dense(units=1, activation='sigmoid'))\n        self.add(layers.Dropout(dropout))\n        \n        self.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n\nbatch_size = 32\nepochs = 30\ndropout = 0.0\nn_splits = 10\n\nkfold = KFold(n_splits=n_splits, shuffle=True, random_state=7)\n\ncvscores = []\nmodels = []\nacc_hist = []\nfor _train, _test in kfold.split(train_X, train_Y):\n    model = SimpleNN(input_shape=(train_X.shape[1],), dropout=dropout)\n    history = model.fit(train_X[_train], train_Y[_train], epochs=epochs, batch_size=batch_size, verbose=0)\n    #print(\"history=\", history.history['acc'])\n    acc_hist.append(history.history['acc'])\n    #evaluate model:\n    scores = model.evaluate(train_X[_test], train_Y[_test], verbose=0)    \n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\n    models.append(model)\n\n    \nfig, ax = plt.subplots(nrows=10, ncols=1, figsize=(n_splits, 8 * n_splits))\nfor i in range(len(acc_hist)):\n    title = \"model \" + str(i)    \n    ax[i].plot(acc_hist[i])\n    ax[i].set_title(title)\nplt.show()\n\nprint(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\nmaxidx = np.argmax(cvscores)\nprint(\"Max : [\", maxidx, \"] : \", \"{0:.2f}\".format(cvscores[maxidx]))\n\n# \uac00\uc7a5 \uc810\uc218\uac00 \ub192\uc740 \ubaa8\ub378\ub85c test \ub370\uc774\ud130\ub97c \ub3cc\ub9b0\ub2e4.\npred = models[maxidx].predict(test, batch_size=test.shape[0], verbose=0)\n\nfrom sklearn.preprocessing import Binarizer\nbinarizer=Binarizer(0.5)\n\ntest_predict_result=binarizer.fit_transform(pred)\ntest_predict_result=test_predict_result.astype(np.int32)\n#print(test_predict_result[:10])\nsubmission = pd.DataFrame({\"PassengerId\" : test_passenger_id, \"Survived\":test_predict_result.reshape(-1)})\nsubmission.to_csv('submission.csv', index=False)\n","6d0a890a":"\uc804\ucc98\ub9ac\uac00 \ub2e4 \ub418\uc5c8\uc73c\uba74 \ub2e4\uc74c \uacfc\uc815\uc744 \uc218\ud589\ud55c\ub2e4.\n\n- \ubd88\ud544\uc694\ud55c \uc5f4 \uc0ad\uc81c\n- scaling\n- train\/test\ub85c \ub2e4\uc2dc \ubd84\ub9ac\n- train\uc744 input\/label\ub85c \ubd84\ub9ac(Survived)","8557c8f1":"Parch\uc640 SibSp\ub97c Family\ub85c \ubcc0\uacbd\ud558\uace0 \ud574\ub2f9 \ud56d\ubaa9\ub4e4\uc740 \uc0ad\uc81c\ud55c\ub2e4.","86d475ed":"\uc131\ubcc4\uc5d0 \ub530\ub978 \uc0dd\uc874\ub960","78a44234":"FareBand\ub97c Fare\uc5d0 \ub123\uace0 FareBand\ub294 \uc0ad\uc81c\ud55c\ub2e4.","8d819963":"\ud558\ub098\ub9cc \uc788\uc73c\ubbc0\ub85c \uadf8\ub0e5 \ud3c9\uade0\uac12\uc744 \ub123\uc5b4\uc900\ub2e4.","31608010":"Deck\uacfc Fare\uc5d0 \ub530\ub77c \uc0dd\uc874 \uc218\ub97c \ud655\uc778\ud574 \ubcf8\ub2e4.","7b9e302d":"### violinplot\n    categorical\ud55c \ub370\uc774\ud130\uc758 \ubd84\ud3ec\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud560 \uc218 \uc788\ub294 \ucc28\ud2b8\uc774\ub2e4.\n    x : x\ucd95\uc5d0 \uadf8\ub824\uc9c8 column\n    y : y\ucd95\uc5d0 \uadf8\ub824\uc9c8 column\n    hue : kde plot\uc73c\ub85c \uadf8\ub824\uc9c8 column","5c5454f2":"Sex \ud56d\ubaa9\uc744 \uc22b\uc790\ub85c \ubcc0\uacbd","0afefebf":"\uac00\uc871 \uc218 ( Parch + SibSp + 1(\uc790\uae30\uc790\uc2e0))\uacfc \uc0dd\uc874\ub960\uc744 \ube44\uad50\ud574 \ubcf8\ub2e4.","8ad9f274":"Name\uc5d0\uc11c \ud638\uce6d\uc744 \ucd94\ucd9c\ud574\uc11c \uc0c8 \ud56d\ubaa9(Title)\uc744 \ucd94\uac00\ud558\uace0 \uc22b\uc790\uac12\uc73c\ub85c \ubcc0\ud658\ud55c\ub2e4. <br>\nName\uc740 \uc9c0\uc6b4\ub2e4.","6dae32a7":"### \ub370\uc774\ud130 \uc18d\uc131 \ud655\uc778","ede0d15f":"### kde(kernel density estimation) :     \n    \ucee4\ub110\uc774\ub77c\ub294 \ud568\uc218\ub97c \uacb9\uce58\ub294 \ubc29\ubc95\uc73c\ub85c \ud788\uc2a4\ud1a0\uadf8\ub7a8\ubcf4\ub2e4 \ubd80\ub4dc\ub7ec\uc6b4 \ud615\ud0dc\uc758 \ubd84\ud3ec \uace1\uc120\uc744 \uadf8\ub9bc\n    density estimation :\n        \uc5b4\ub5a4 \ubcc0\uc218\uac00 \uac00\uc9c8 \uc218 \uc788\ub294 \uac12 \ubc0f \uadf8 \uac12\uc744 \uac00\uc9c8 \uac00\ub2a5\uc131\uc758 \uc815\ub3c4\ub97c \ucd94\uc815\n    \n    kernel function:\n        \uc6d0\uc810\uc744 \uc911\uc2ec\uc73c\ub85c \ub300\uce6d\uc774\uba74\uc11c \uc801\ubd84\uc774 1\uc778 non-negative \ud568\uc218\n        \uac00\uc6b0\uc2dc\uc548, uniform\ud568\uc218 \ub4f1\uc774 \ub300\ud45c\uc801\uc778 \ucee4\ub110 \ud568\uc218\uc774\ub2e4.\n    \n    kernel density estimation:\n        \ucee4\ub110 \ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \ud788\uc2a4\ud1a0\uadf8\ub7a8 \ud568\uc218\ub97c smoothing\ud558\ub294 \ubc29\ubc95\n        \uc544\ub798 \ub9c1\ud06c \ucc38\uace0\n        https:\/\/darkpgmr.tistory.com\/147","ce362801":"merged\ub97c train\/test\ub85c \ubd84\ub9ac\ud55c\ub2e4.","9a17cf65":"Family \ubcc4\ub85c Survived\uac12\uc758 \uad6c\uc131\uc744 \ubcf4\uc5ec\uc900\ub2e4.","c61a71eb":"\ubd88\ud544\uc694\ud55c \uc5f4 \uc0ad\uc81c","042485af":"Cabin\uc5d0\uc11c \uc54c\ud30c\ubcb3\uc744 \ucd94\ucd9c\ud574\uc11c Deck\ud56d\ubaa9\uc744 \ucd94\uac00\ud55c\ub2e4.","8a5b1206":"distribution\uc774 \ube44\ub300\uce6d\uc778 \uac83\uc744 \uc54c \uc218 \uc788\ub2e4.(high skewness). <br>\n\ubaa8\ub378\uc758 \ud559\uc2b5\uc5d0 \uc88b\uc9c0 \uc54a\uc740 \uc601\ud5a5\uc744 \ubbf8\uce5c\ub2e4\uace0 \ud55c\ub2e4. <br>\noutlier\uc758 \uc601\ud5a5\uc744 \uc904\uc774\uae30 \uc704\ud574 log\ub97c \ucde8\ud574\uc11c \uac12\uc758 \ucc28\uc774\ub97c \uc904\uc774\uac70\ub098 \ub3d9\uc218\ub85c \uadf8\ub8f9\uc744 \ub098\ub204\uc5b4\uc11c \uac12\uc744 \ubc30\uc815\ud558\uac70\ub098 \ud560 \uc218 \uc788\ub2e4.","a1fd1421":"### \ube44\uc5b4\uc788\ub294 Age\ub97c \ucc98\ub9ac(\ucc44\uc6b4\ub2e4)\n\nTitle\ub85c \uc801\ub2f9\ud788 \ucd94\ub9ac\ud55c\ub2e4. (\ub108\ubb34 \ub54c\ub824\ub9de\ucd94\uae30\uac00 \uc544\ub2cc\uc9c0...?)","efd3149e":"## \uc785\ub825 \ub370\uc774\ud130 :\n\n- **PassengerId** : \uc2b9\uac1d \ubc88\ud638<br>\n- **Survived** : \uc0dd\uc874\uc5ec\ubd80(1: \uc0dd\uc874, 0 : \uc0ac\ub9dd)<br>\n- **Pclass** : \uc2b9\uc120\uad8c \ud074\ub798\uc2a4(1 : 1st, 2 : 2nd ,3 : 3rd)<br>\n- **Name** : \uc2b9\uac1d \uc774\ub984<br>\n- **Sex** : \uc2b9\uac1d \uc131\ubcc4 (male\/female)<br>\n- **Age** : \uc2b9\uac1d \ub098\uc774(float) <br>\n- **SibSp** : \ub3d9\ubc18\ud55c \ud615\uc81c\uc790\ub9e4, \ubc30\uc6b0\uc790 \uc218<br>\n- **Parch** : \ub3d9\ubc18\ud55c \ubd80\ubaa8, \uc790\uc2dd \uc218<br>\n- **Ticket** : \ud2f0\ucf13\uc758 \uace0\uc720 \ub118\ubc84(\ubb38\uc790\uc5f4)<br>\n- **Fare** \ud2f0\ucf13\uc758 \uc694\uae08(float)<br>\n- **Cabin** : \uac1d\uc2e4 \ubc88\ud638<br>\n- **Embarked** : \uc2b9\uc120\ud55c \ud56d\uad6c\uba85(C : Cherbourg, Q : Queenstown, S : Southampton)<br>\n\n","73a18f74":"<a id=\"data_manipulation\"><\/a> <br> \n# **2. \ub370\uc774\ud130 \ud3b8\uc9d1:**\n\n\ube44\uc5b4\uc788\ub294 \ub370\uc774\ud130(null)\uc744 \ucc98\ub9ac\ud55c\ub2e4.<br>\n\n###### \uae30\uc874 feature\ub4e4\uc744 \ubcf4\uc644\/\uac00\uacf5\n**Age** : null\uc774 \ub9ce\uace0 \ub098\uc774\uac00 \uc911\uc694\ud560 \uac83\uc73c\ub85c \ud310\ub2e8\ub418\ub2c8 \ub370\uc774\ud130\ub97c \ucc44\uc6cc\uc57c \ud560 \ud544\uc694\uac00 \uc788\ub2e4.<br>\n**Cabin** : null\uc774 \ub108\ubb34 \ub9ce\ub2e4.<br>\n**Embarked** : null\uc774 \uac70\uc758 \uc5c6\uc73c\ubbc0\ub85c \uc911\uc694\ud558\uc9c0 \uc54a\uc740 \uac12\uc73c\ub85c \ucc44\uc6cc\ub3c4 \ubb38\uc81c\uac00 \uc5c6\uc5b4 \ubcf4\uc784<br>\n**Parse, SibSp** : \ud569\uccd0\uc11c Family\ub85c \ub9cc\ub4e4\uace0 \uc0ad\uc81c\ud558\uc790.\n\n###### \uc0c8\ub85c\uc6b4 feature\ub97c \ucd94\uac00\n**Family** : Parch + SibSp + 1(\uc790\uae30\uc790\uc2e0) <br>\n**Title** : Name\uc5d0\uc11c \ucd94\ucd9c\ud574\uc11c \uc0dd\uc131\ud55c\ub2e4.","01da29fd":"Pclass\/Age\uc5d0 \ub530\ub978 \uc0dd\uc874\ub960 \ubcc0\ud654\ub7c9\uc744 \ud655\uc778\ud55c\ub2e4.","a7e28289":"null\uc778 \ud56d\ubaa9\uc774 \uc788\ub2e4.","b07e931a":"Age\uc5d0 \ub530\ub978 \uc0dd\uc874\ub960\ub97c \ud655\uc778\ud574 \ubcf8\ub2e4.","a8c1edc4":"Deck\uacfc Survived\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ud655\uc778\ud558\uc790.","99edbf1d":"### Fare \uc815\ub9ac","78bbe5ee":"\uc218\uce58 \ub370\uc774\ud130\ub294 \uc77c\uc815 \uac12\uc73c\ub85c scaling \ud574\uc8fc\ub294 \uac83\uc774 \ud544\uc694\ud558\ub2e4.<br>\n\uc785\ub825 \ub370\uc774\ud130\ub97c 0~1\ub85c scaling\ud558\ub294 \ud568\uc218","e0d26715":"Fare(\uc694\uae08) \ud56d\ubaa9\uc758 \ubd84\ud3ec\ub97c check\ud574 \ubcf4\uc790.","a07961dc":"\uce74\ud14c\uace0\ub9ac \ub370\uc774\ud130\ub294 one-hot \uc778\ucf54\ub529\uc73c\ub85c \ubcc0\uacbd\ud55c\ub2e4. <br>\n- Pclass\n- Embarked\n- Title","8060b7be":"#### \ub370\uc774\ud130\uac00 \uc874\uc7ac\ud558\uc9c0 \uc54a\ub294 feature\ub4e4\uc744 \ud655\uc778\ud574 \ubcf8\ub2e4.","ac40bc24":"<a id=\"modelling_training_submit\"><\/a> <br> \n# **3. \ubaa8\ub378 \uc0dd\uc131\/\ud6c8\ub828\/\uc81c\ucd9c:**\n\n1. keras\ub85c FC\ub808\uc774\uc5b4\ub97c \uba87 \uac1c \uc313\uc544\uc11c \ub9cc\ub4e0 model \uc0dd\uc131\n2. kfold cross-validation \uc0ac\uc6a9\ud574\uc11c model train\n3. 2\uc5d0\uc11c train\uc644\ub8cc\ub41c \ubaa8\ub378 \uc911 accuracy\uac00 \uac00\uc7a5 \ub192\uc740 \ubaa8\ub378 \uc120\ud0dd\ud574\uc11c test\ub370\uc774\ud130 \ud310\uc815\n4. csv\ud30c\uc77c\ub85c \uc0dd\uc131","4a094e7c":"<a id=\"data_analysis\"><\/a> <br> \n# **1. \ub370\uc774\ud130 \ubd84\uc11d:**\n\n\ud30c\uc77c\uc5d0\uc11c \ub370\uc774\ud130\ub97c \uc77d\uc5b4\ub4e4\uc784","de314c5c":"# kaggle Titanic(Keras \uc2e0\uacbd\ub9dd \uad6c\ud604)\n\nbaseline notebook for using fc layers.\n\n## \ubaa9\ucc28\n\n**1. [\ub370\uc774\ud130 \ubd84\uc11d](#data_analysis)** <br>\n**2. [\ub370\uc774\ud130 \ud3b8\uc9d1](#data_manipulation)** <br>\n**3. [\ubaa8\ub378 \uc0dd\uc131\/\ud6c8\ub828\/\uc81c\ucd9c](#modelling_training_submit)** <br>\n\n<a id=\"Introduction\"><\/a> <br> \n","d1efc425":"\ucc98\uc74c\uc5d0\ub294 \ube44\uc5b4\uc788\ub294 Deck\uc744 \ucc44\uc6cc\uc57c \ud55c\ub2e4\uace0 \uc0dd\uac01\ud558\uc600\ub2e4.<br>\n\uadf8\ub7f0\ub370 Cabin\uc774 \uc788\ub294 \uadf8\ub8f9\uacfc \uc5c6\ub294 \uadf8\ub8f9\uac04\uc758 \uc0dd\uc874\ub960 \ucc28\uc774\uac00 \uc720\uc758\ubbf8\ud558\uace0, Cabin\uc5d0\uc11c \ucd94\ucd9c\ud55c Deck\uc758 \uc0dd\uc874\ub960\uc774 \ub2e4 \ud3c9\uade0\uc740 \ub118\uc73c\ub2c8 \uadf8\ub0e5 Cabin\uc758 \uc874\uc7ac\uc720\ubb34\ub85c \ud558\ub294 \uac83\uc740 \uc5b4\ub5a8\uae4c \ud558\ub294 \uc0dd\uac01\uc774 \ub4e4\uc5c8\ub2e4.<br>\n\uadf8\ub0e5 Cabin\uc758 \uc874\uc7ac\uc720\ubb34 \ud56d\ubaa9\uc744 \ucd94\uac00\ud558\uc790.","b6ee2041":"### countplot :     \n    show the **counts** of observations in each **categorical** bin using bars\n    x : x\ucd95\uc5d0 \uadf8\ub824\uc9c8 \ubd84\ub958 \uae30\uc900 categorical column\n    hue : y\ucd95\uc5d0 \uac01\uac01\uc758 value\ub9c8\ub2e4 count\ub97c \uc138\uc11c \ud45c\uc2dc\ub420 categorical column\n    data : DataFrame \uac1d\uccb4","f19fea4b":"\ub098\uc774\ub300\ub97c \ubd84\ud560\ud558\uc5ec bar graph\ub85c \ucd9c\ub825\ud55c\ub2e4.","0bfdfe71":"### Embarked \uc815\ub9ac\n\ube48 \uac2f\uc218\uac00 \uba87\uac1c \uc5c6\uc73c\ubbc0\ub85c \uadf8\ub0e5 \uac00\uc7a5 \ub9ce\uc740 \uac83\uc73c\ub85c \ucc44\uc6b4\ub2e4.","11fa6a0c":"countplot \uba85\ub839\uc744 \uc0ac\uc6a9\ud558\uba74 \uac01 \uce74\ud14c\uace0\ub9ac \uac12\ubcc4\ub85c \ub370\uc774\ud130\uac00 \uc5bc\ub9c8\ub098 \uc788\ub294\uc9c0 \ud45c\uc2dc\ud560 \uc218 \uc788\ub2e4.","84daef89":"## train\/test\ub97c \ub530\ub85c \ud558\uc9c0 \ub9d0\uace0, \ud569\uccd0\uc11c \ucc98\ub9ac\ud558\uace0 \ub9c8\uc9c0\ub9c9(\ubaa8\ub378 \ub123\uae30 \uc9c1\uc804)\uc5d0 \ub2e4\uc2dc \ubd84\ub9ac\ud55c\ub2e4.","f161c693":"test\uc758 \uacbd\uc6b0 \uc608\uce21\uc5d0\uc11c \uc81c\ucd9c\ud574\uc57c \ud558\ub294 \ub370\uc774\ud130\uc774\uae30\uc5d0 Survived \ud56d\ubaa9\uc774 \uc5c6\ub2e4.","e6300431":"Pclass \uc5d0 \ub530\ub978 \uc0dd\uc874\ub960\n\n1. train[[Columns.Pclass, Columns.Survived] <= Pclass, Survivied\ub9cc \uc788\ub294 dataframe \uc0dd\uc131\n2. groupby([Columns.Pclass]) <= Pclass column \uac12\ub9c8\ub2e4 group\uc73c\ub85c \ubb36\uc74c(DataFrameGroupBy)\n3. \ubb36\uc778 \ud56d\ubaa9(Pclass. \uc5ec\ub7ec column\uc774 \uc788\uc744 \uacbd\uc6b0 \uac01\uac01)\uc758 \ud3c9\uade0(mean())\uac12\uc744 \uacc4\uc0b0\ud558\uace0 \uadf8\ub798\ud504\ub85c \ucd9c\ub825(plot.bar())"}}