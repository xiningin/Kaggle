{"cell_type":{"066732aa":"code","acdc00ef":"code","74fa6dde":"code","deecbabd":"code","f411ae1f":"code","f4e2c0d2":"code","125b3f9c":"code","533b3fbb":"code","bf4d9922":"code","d77ce6ca":"code","27096264":"code","22e4df69":"code","bd0252fb":"code","b5c3df41":"code","00881b76":"code","34e98222":"code","28dcc17a":"code","f48c5d4a":"code","2ff963c3":"code","bca2ab74":"code","378d234c":"code","6b072d42":"code","14b14c37":"code","06071179":"code","34113349":"code","c2ad1f8b":"code","b240dfe0":"code","f0dbb846":"code","c379b8ee":"code","b125b41a":"code","ec95599b":"code","9128c543":"code","dc2bc3ea":"code","5ad08363":"code","21de55e0":"code","fff9b87f":"code","078642e7":"code","3a60265a":"code","240b676e":"code","c4f02403":"code","9ae73af2":"code","8be6202b":"code","499ecdeb":"code","53b18f03":"code","4b2b8cc0":"code","fca163f4":"code","c5f45783":"code","8e12fe60":"code","b2e1342a":"code","1a6fa0af":"code","10a67467":"code","f417e6cf":"code","490fca9e":"code","e4d4b85b":"code","f5100ca8":"code","87f1eaae":"code","cc98c490":"code","f0693aff":"code","9741680e":"code","398f7795":"code","227f4ed4":"code","71c5e436":"code","d86f085c":"code","5f612333":"code","8e558186":"markdown","609a86fb":"markdown","8271196b":"markdown","ed372893":"markdown","a36ba270":"markdown","ae9ef648":"markdown","bdefef75":"markdown","9a0950c9":"markdown","e7b080d3":"markdown","0eb09e4f":"markdown","5c982cf3":"markdown","6566742d":"markdown","f2f64eb2":"markdown","ce9a7f0a":"markdown","21c41c44":"markdown","426f4e3a":"markdown","1be49ac6":"markdown","473ff694":"markdown","bf825018":"markdown","c36ddc4c":"markdown","f01c7744":"markdown","5183fa94":"markdown","2a76f3be":"markdown","010a8b78":"markdown","1a0a5609":"markdown","0c2c4eaf":"markdown","84924c29":"markdown","5d5a2c1b":"markdown","730d75af":"markdown","46862265":"markdown","e61c2890":"markdown","57c9f4c1":"markdown","51b3ecea":"markdown","b6b31b78":"markdown","bcc61e39":"markdown","8bc15bdf":"markdown","5aa82520":"markdown","3bdf1b0d":"markdown","0c60a97e":"markdown","5a3074b4":"markdown","44466f3a":"markdown","8f6ef6ce":"markdown","cd75bd13":"markdown","bece8276":"markdown","58b7776f":"markdown","f68659fe":"markdown","740e337d":"markdown","6c500a60":"markdown","01f8b6ca":"markdown","a1de45ee":"markdown","b9201fc4":"markdown","aaa13d22":"markdown"},"source":{"066732aa":"# data analysis and data handling\nimport pandas as pd\nimport numpy as np\n\n# data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","acdc00ef":"#train_df = pd.read_csv('data\/train.csv')\n#test_df = pd.read_csv('data\/test.csv')\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","74fa6dde":"print('Shape of training set = {}'.format(train_df.shape))\nprint('_'*40)\nprint('Shape of testing set  = {}'.format(test_df.shape))","deecbabd":"train_df.head(5)","f411ae1f":"test_df.head(5)","f4e2c0d2":"print(train_df.columns)\nprint('_'*40)\nprint(test_df.columns)","125b3f9c":"print(train_df.dtypes)\nprint('_'*40)\nprint(test_df.dtypes)","533b3fbb":"train_df.isnull().sum()","bf4d9922":"test_df.isnull().sum()","d77ce6ca":"print(train_df.info())\nprint('_'*40)\nprint(test_df.info())","27096264":"train_df.groupby('Survived').size()","22e4df69":"train_df.describe()","bd0252fb":"train_df.describe(include=['O'])","b5c3df41":"test_df.describe()","00881b76":"test_df.describe(include=['O'])","34e98222":"train_df.hist(figsize=(20,10), layout=(3,3), bins=20)","28dcc17a":"train_df.plot(\n    figsize=(20,10), \n    kind='box', \n    sharex=False, \n    subplots=True, \n    layout=(3,3)\n)","f48c5d4a":"#from pandas.plotting import scatter_matrix\ntemp_filtered_df = train_df[train_df['Age'].notnull()]\npd.plotting.scatter_matrix(\n    temp_filtered_df, \n    figsize=(20,10), \n    c=temp_filtered_df['Survived'], \n    alpha=0.3\n)\n#plt.legend(loc = 'best')","2ff963c3":"names = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\ncorr_train_df = train_df[names].corr()\n\nfig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(111)\ncorr_plot = ax.matshow(corr_train_df, vmin=-1, vmax=1, cmap='Spectral')\nfig.colorbar(corr_plot)\nticks = np.arange(0,5,1) # total 6 items\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nplt.show()","bca2ab74":"(\n    train_df[['Pclass', 'Survived']]\n    .groupby(['Pclass'], as_index=False)\n    .mean()\n    .sort_values(by='Survived', ascending=False)\n)","378d234c":"(\n    train_df[['Sex', 'Survived']]\n    .groupby(['Sex'], as_index=False)\n    .mean().sort_values(by='Survived', ascending=False)\n)","6b072d42":"(\n    train_df[['SibSp', 'Survived']]\n    .groupby(['SibSp'], as_index=False)\n    .mean()\n)","14b14c37":"(\n    train_df[['Parch', 'Survived']]\n    .groupby(['Parch'], as_index=False)\n    .mean()\n)","06071179":"(\n    train_df[['Embarked', 'Survived']]\n    .groupby(['Embarked'], as_index=False)\n    .mean()\n    .sort_values(by='Survived', ascending=False)\n)","34113349":"(\n    train_df[['Pclass', 'SibSp', 'Survived']]\n    .groupby(['Pclass', 'SibSp'], as_index=False)\n    .mean()\n    .sort_values(by='Survived', ascending=False)\n)","c2ad1f8b":"(\n    train_df[['Pclass', 'Parch', 'Survived']]\n    .groupby(['Pclass', 'Parch'], as_index=False)\n    .mean()\n    .sort_values(by='Survived', ascending=False)\n)","b240dfe0":"sns.FacetGrid(train_df, col='Survived', height=4, aspect=1).map(plt.hist, 'Age', bins=20)\n\nprint(\"Mean age relative to survival:\")\nprint(train_df[['Age', 'Survived']].groupby(['Survived'], as_index=False).mean())\nprint(\"Median age relative to survival:\")\nprint(train_df[['Age', 'Survived']].groupby(['Survived'], as_index=False).median())","f0dbb846":"sns.FacetGrid(train_df, col='Survived', height=4, aspect=1).map(plt.hist, 'Fare', bins=20)\n\nprint(\"Mean fare relative to survival:\")\nprint(train_df[['Fare', 'Survived']].groupby(['Survived'], as_index=False).mean())\nprint(\"Median fare relative to survival:\")\nprint(train_df[['Fare', 'Survived']].groupby(['Survived'], as_index=False).median())","c379b8ee":"grid = sns.FacetGrid(train_df, height=5, aspect=1)\ngrid.map(sns.pointplot, 'SibSp', 'Survived', ci=95)\ngrid.add_legend()","b125b41a":"grid = sns.FacetGrid(train_df, height=5, aspect=1)\ngrid.map(sns.pointplot, 'Parch', 'Survived', ci=95)\ngrid.add_legend()","ec95599b":"sns.FacetGrid(\n    train_df, \n    col='Survived', \n    row='Pclass', \n    height=3, \n    aspect=1\n).map(\n    plt.hist, \n    'Age', \n    alpha=.5, \n    bins=20\n).add_legend();","9128c543":"sns.FacetGrid(\n    train_df, \n    col='Survived', \n    row='Pclass', \n    height=3, \n    aspect=1\n).map(\n    plt.hist, \n    'Fare', \n    alpha=.5, \n    bins=20\n).add_legend();","dc2bc3ea":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', height=3, aspect=1)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=95, order=['male', 'female'])\ngrid.add_legend()","5ad08363":"grid = sns.FacetGrid(train_df, col='Embarked', height=3, aspect=1)\ngrid.map(sns.pointplot, \n         'Pclass', \n         'Survived', \n         'Sex', \n         order = [1,2,3], \n         hue_order=['male', 'female'], \n         palette='deep', \n         ci=95\n        )\ngrid.add_legend()\n\n(\n    train_df[['Embarked', 'Pclass', 'Sex']]\n    .groupby(['Embarked', 'Pclass', 'Sex'], as_index=False)\n    .size()\n)","21de55e0":"(\n    train_df[['Embarked']]\n    .groupby(['Embarked'], as_index=False)\n    .size()\n)","fff9b87f":"test_feature_df = train_df.copy()\n\ntest_feature_df['FamilySize'] = test_feature_df['SibSp'] + test_feature_df['Parch'] + 1","078642e7":"print(\n    test_feature_df[['FamilySize', 'Survived']]\n    .groupby(['FamilySize'], as_index=False)\n    .mean()\n)\nprint(\n    test_feature_df[['FamilySize']]\n    .groupby(['FamilySize'], as_index=False)\n    .size()\n)\nprint (\n    test_feature_df[['FamilySize', 'Pclass']]\n    .groupby(['Pclass', 'FamilySize'], as_index=False)\n    .size()\n)","3a60265a":"grid = sns.FacetGrid(test_feature_df, height=5, aspect=1)\ngrid.map(sns.pointplot, 'FamilySize', 'Survived', ci=95)\ngrid.add_legend()","240b676e":"print(\n    test_feature_df[['FamilySize', 'Sex', 'Survived']]\n    .groupby(['FamilySize', 'Sex'], as_index=False)\n    .mean()\n)\nprint(\n    test_feature_df[['FamilySize', 'Sex', 'Survived']]\n    .groupby(['FamilySize', 'Sex'], as_index=False)\n    .size()\n)","c4f02403":"grid = sns.FacetGrid(test_feature_df, height=5, aspect=1)\ngrid.map(\n    sns.pointplot, \n    'FamilySize', 'Survived', 'Sex', \n    order = [1,2,3,4,5,6,7,8,9,10,11], \n    hue_order=['male', 'female'], \n    palette='deep', \n    ci=95\n)\ngrid.add_legend()","9ae73af2":"grid = sns.FacetGrid(test_feature_df, col='Pclass', height=5, aspect=1)\ngrid.map(sns.pointplot, 'FamilySize', 'Survived', ci=95)\ngrid.add_legend()","8be6202b":"test_feature_df = train_df.copy()\n\ntest_feature_df['FamilySize'] = test_feature_df['SibSp'] + test_feature_df['Parch'] + 1\n\ntest_feature_df['IsAlone'] = (test_feature_df['FamilySize'] == 1).astype(int)","499ecdeb":"grid = sns.FacetGrid(test_feature_df, height=5, aspect=1)\ngrid.map(sns.pointplot, 'IsAlone', 'Survived', ci=95)\ngrid.add_legend()","53b18f03":"grid = sns.FacetGrid(test_feature_df, col='Pclass', height=5, aspect=1)\ngrid.map(sns.pointplot, 'IsAlone', 'Survived', ci=95)\ngrid.add_legend()","4b2b8cc0":"test_feature_df = train_df.copy()\nnum_bins = 10\ntest_feature_df['age_cat'] = pd.cut(test_feature_df['Age'], \n                                    num_bins, \n                                    #labels=[i for i in range(0,num_bins)]\n                                   )\n\n#test_feature_df['age_cat'] = (test_feature_df['age_cat']).astype(int)\n\n(\n    test_feature_df[['age_cat', 'Survived']]\n    .groupby(['age_cat'], as_index=False)\n    .mean()\n    .sort_values(by='age_cat', ascending=True)\n)","fca163f4":"(\n    test_feature_df[['age_cat', 'Survived']]\n    .groupby(['age_cat'], as_index=False)\n    .size()\n)","c5f45783":"test_feature_df = train_df.copy()\nnum_bins = 10\ntest_feature_df['fare_cat'] = pd.cut(test_feature_df['Fare'], \n                                     num_bins, \n                                     #labels=[i for i in range(0,num_bins)]\n                                    )\n\n#test_feature_df['fare_cat'] = (test_feature_df['fare_cat']).astype(int)\n\n(\n    test_feature_df[['fare_cat', 'Survived']]\n    .groupby(['fare_cat'], as_index=False)\n    .mean()\n    .sort_values(by='fare_cat', ascending=True)\n)","8e12fe60":"(\n    test_feature_df[['fare_cat', 'Survived']]\n    .groupby(['fare_cat'], as_index=False)\n    .size()\n)","b2e1342a":"MEDIAN_AGE = None\nMEDIAN_FARE = None\nMEDIAN_EMBARKED = 'S'","1a6fa0af":"\ndef create_family_size_feature(df):\n    df['num_family_travelling_with'] = df['SibSp'] + df['Parch'] + 1\n    return df\n\ndef create_is_alone_feature(df):\n    df['is_alone'] = (df['num_family_travelling_with'] == 1).astype(int)\n    return df\n\ndef discretize_continuous_feature(df, new_column, column_to_bin, num_bins):\n    df[new_column] = pd.cut(df[column_to_bin],\n                            num_bins,\n                            labels=[i for i in range(0,num_bins)]\n                           )\n    df[new_column] = (df[new_column]).astype(int)\n    return df\n    \ndef categorize_feature(df, new_column, old_column, old_column_value):\n    def get_new_column_value(row, old_column, old_column_value):\n        if row[old_column] == old_column_value:\n            new_value = 1\n        else:\n            new_value = 0\n        return new_value\n    \n    df[new_column] = df.apply(\n        lambda row: get_new_column_value(row, old_column, old_column_value),\n        axis=1\n    )\n    return df\n\n\n# data transform pipeline\ndef transform_pipeline(df, data_set_type):\n    # global is not great to use. Need to refactor pipeline into a class :( \n    global MEDIAN_AGE, MEDIAN_FARE, MEDIAN_EMBARKED\n    \n    # engineer family size feature\n    df = create_family_size_feature(df)\n    \n    # engineer IsAlone feature\n    df = create_is_alone_feature(df)\n    \n    # calculate median values of missing data columns if data_set_type = 'train'\n    if data_set_type == 'train':\n        MEDIAN_AGE = df['Age'].median()\n        print('Median age of training data is {}'.format(MEDIAN_AGE))\n        MEDIAN_FARE = df['Fare'].median()\n        print('Median Fare of training data is {}'.format(MEDIAN_FARE))\n        print('Median embarked is {}'.format(MEDIAN_EMBARKED))\n        \n    # Fill missing values with medians\n    fill_na_dict = {\n        'Age': MEDIAN_AGE,\n        'Fare': MEDIAN_FARE,\n        'Embarked': MEDIAN_EMBARKED\n    }\n    df = df.fillna(fill_na_dict)\n    \n    # discretize certian continuous variable features\n    num_bins = 10\n    # Age\n    df = discretize_continuous_feature(df, 'age_cat', 'Age', num_bins)\n    # Fare\n    df = discretize_continuous_feature(df, 'fare_cat', 'Fare', num_bins)\n    \n    # Engineer categorical classification features into binary features\n    new_column_list = ['is_first_class', 'is_second_class', 'is_third_class',\n                       'embarked_S', 'embarked_C', 'embarked_Q',\n                       'is_male']\n    old_column_list = ['Pclass', 'Pclass', 'Pclass',\n                       'Embarked', 'Embarked', 'Embarked',\n                       'Sex']\n    old_column_value_list = [1, 2, 3,\n                             'S', 'C', 'Q',\n                             'male']\n    for new_column, old_column, old_column_value in zip(new_column_list,\n                                                       old_column_list,\n                                                       old_column_value_list):\n        df = categorize_feature(df, new_column, old_column, old_column_value)\n    \n    \n    \n    # drop columns\n    features_to_drop = ['Name', \n                        'Parch', \n                        'Ticket', \n                        'Cabin', \n                        'Pclass', \n                        'Embarked', \n                        'Sex', \n                        'Age', \n                        'Fare',\n                        'PassengerId']\n    df.drop(features_to_drop, axis=1, inplace=True)\n    \n    # rename columns\n    df = df.rename(\n        columns = {\n            'SibSp': 'num_siblings_spouse',\n        }\n    )\n    \n    # assert no null values in dataframe\n    assert pd.notnull(df).all().all()\n    \n    return df.values","10a67467":"train_labels = train_df['Survived'].copy()\ntrain_prepared = transform_pipeline(train_df.drop(['Survived'], axis=1).copy(), 'train')","f417e6cf":"train_prepared","490fca9e":"train_prepared.shape","e4d4b85b":"train_labels.shape","f5100ca8":"# import sklearn stuff\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\nimport numpy as np","87f1eaae":"log_reg = LogisticRegression()\n\nhyper_param_distribs = {\n    'penalty': ['l1', 'l2'],\n    'dual': [False],\n    'tol': [1e-4],\n    'C': uniform(loc=0, scale=4),\n    'fit_intercept': [True, False],\n    'intercept_scaling': [1.0],\n    'class_weight': [None],\n    'random_state': [None],\n    'solver': ['liblinear'],\n    'max_iter': [100],\n    'multi_class': ['ovr'],\n    'verbose': [0],\n    'warm_start': [False],\n    'n_jobs': [None]\n}\n\nrnd_search = RandomizedSearchCV(\n    log_reg, \n    hyper_param_distribs, \n    n_iter=1000, \n    scoring='accuracy', \n    cv=10, \n    verbose=1, \n    random_state=78, \n    n_jobs=1, \n    error_score=np.nan \n)","cc98c490":"rnd_search.fit(train_prepared, train_labels)","f0693aff":"rnd_search.best_params_","9741680e":"rnd_search.best_estimator_","398f7795":"rnd_search.best_score_","227f4ed4":"#cv_results = rnd_search.cv_results_\n#for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n#    print(mean_score, params)","71c5e436":"# define best model\nfinal_model = rnd_search.best_estimator_\n# prepare (transform) test data\ntest_IDs = test_df['PassengerId'].copy()\ntest_prepared = transform_pipeline(test_df.copy(), 'test')\n\ntest_prepared.shape","d86f085c":"# make predictions for test data\ntest_predictions = final_model.predict(test_prepared)","5f612333":"# print submission\nsubmission = pd.DataFrame({\n    'PassengerId': test_IDs,\n    'Survived': test_predictions\n})\nsubmission.to_csv('submission_logistic_regression.csv', index=False)\n","8e558186":"***\n# 2. Explore data (data quality, stats, viz, patterns)","609a86fb":"### Conclusions\/decision from above: \n\nIt is very difficult to pick out relations between attributes with regards to survival. (Also, not sure which colour corresponds to survived and not survived). Have to dig in a bit more.","8271196b":"### Conclusions\/decisions from above:\n\n - It seems that there is an optimum, or close to, family size for survival\n - Small family sizes, in particular = 1, there is <50% fraction of survival. These are mostly male passengers. Most people in training data fall in this familysize (travelling alone)\n - Survival fraction increases up to familysize = 4, after which it drops off. This indicates that people travelling alone, or nearly so (males especially), and people with large family sizes were less likely to survive --> most people with large families are from 3rd class as well\n - **decision**: engineer `FamilySize` as a feature. Also, keep `SibSp` since there is a clear relation between it and survival. **Drop `Parch` since there is no clear trend between it and survival**.\n - Consider engineering an is alone feature since there seems to be a tight correlation between family size = 0 and not surviving\n ","ed372893":"### correlation between categorical features","a36ba270":"## Analyze survival rate as related to (categorical and ordinal) features\n\nCan only do this for features that contain no NaN values (So, can't do this for Age, embark, and cabin). Also, would be easiest to only do this for categorical features (Pclass, Sex, Parch, SibSp). (Note, in general this could be done for all features, but at this point we do have features that contain NaN values and not all features are binned\/categorized).","ae9ef648":"## Print some high-level stats for dataframes","bdefef75":"### Conclusions\/decisions from above:\n\n - Bin ages and fares according to above\n - Should really put a ceiling on both, but for now, just do equal bins for the range of values in each feature","9a0950c9":"### Conclusions\/decisions from above: \n\n - Pclass: Strong correlation between class and survival rate. 1st class passengers are more likely to survive, 3rd class are least likely. \n - Sex: Strong correlation between sex and survival. ~74% of females survived.\n - SibSp: Appears to be a negative correlation between survival and SibSp\n - Parch: No trend between survival and Parch is super evident\n - Embarked: No definite relationship between port of embarkation and survival. There appears to be a slight trend that embarking at 'S' correlates with not surviving (~33% survived). Conversely, passengers embarking from 'C' had a ~55% survival fraction.\n\n**Parch and Sibsp: What IS CLEAR is that travelling with a larger number of siblings\/spouses or parents\/children DOES RESULT IN A LOW SURVIVAL RATE**. This indicates that passengers belonging to larger families that are travelling together will probably not survive. Should include this as an engineered feature and see what trends come about. Does \"family size\" and survival rate correlate with class? (i.e. which classes tend to have larger families --> it is known that upper class passengers have higher survival rate, so my hypothesis is that large families tend to be from lower classes). \n\n**Can test this with current features below:**","e7b080d3":"### Conclusions\/decisions from above:\n\n - Still not clear whether being in 3rd class correlates with not surviving (already known) or if family size has any impact. This does motivate the need to engineer a new feature and check, though!","0eb09e4f":"# Titanic: Machine Learning from Disaster\n# *using logistic regression\n\n## Goals\/Description of competition:\n\n### tl;dr: Exercise in binary classification. Given training data, train a model to predict survived or not. Using this model, predict outcomes for test data set and submit to competition. Note: we are not limited to the features given, i.e. can create new ones.\n\n### Also note: data is not very nice :( \n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n## Analysis Procedure\n\n - Collect training and test data\n - Explore data (quality, patterns, stats, viz)\n - Data cleaning\/Feature engineering\n - Select, train, and fine-tune model \n - Evaluate model on test data and submit","5c982cf3":"## Plot 2D scatter plots of numerical training data (with relation to survival)","6566742d":"## Test binning of age and fare data","f2f64eb2":"## Double check data types of columns in dataframes","ce9a7f0a":"## Summary of (training) data exploration (data quality, stats, viz, patterns)\n\n### Single feature relations to survival:\n\n - `Pclass`: Upper class passengers tended to survive (~63% survived), lower class passengers tended to not survive (~24% survived)\n - `Sex`: About 64% of passengers were male. Females tended to survive (74% of females and 19% of males survived)\n - `Age`: Infants tended to survive, passengers between age ~16-32 tended to not survive, especially in 3rd class\n - `SibSp` and `Parch`: Appears to be a negative correlation between SibSp and survival, and no clear trend exists between Parch and survival. There does seem to be a slight trend that larger SibSp or Parch correlates with not surviving. This could indicate that larger \"family size\" correlates with not surviving. It is unclear whether family size also correlates with class at this point. Travelling alone also seems to correlate with low survival.\n - `Ticket`: Did not analyze. These values are alpha-numeric strings. Not sure what they represent or how they correlate. There is some duplication\/degeneracy in string values, though.\n - `Fare`: Larger fares tended to survive while lower fares tended not to survive. Fare could correlate with class.\n - `Cabin`: Did not analyze. Only not NaN for first class passengers. Not sure what it represents. There could be subgroups within 1st class with differing relations to survival where `cabin` might be useful.\n - `Embarked`: ~72% of passengered embarked from 'S' (Southampton). There is no definite\/overly obvious relation between port of embarkation and survival. However, there does appear to be a slight trend\/correlation that passengers embarking from 'S' (and 'Q') were less likely to survive (~33% and ~38% survival fraction, respectively) than those embarking from 'C' (~55% survival fraction).\n\n### Conclusions and decision made going further:\n\n - Drop `Cabin` and `Ticket` in modelling. Not sure how they relate. Could explore this further down the road\n - Create new feature \"family size\" that combines `SibSp` and `Parch`, and see its relation with survival. If it does correlate, then drop `SibSp` and\/or `Parch`. \n - Could complete `Age` feature and fill missing values somehow.\n - Could complete `Embarked`, 2 missing values in training data.\n - Could complete `Cabin`, or feature engineer (sublcasses of first class that have better survival fractions). For now, drop since there are NaN values for classes 2 and 3, and see how things perform\n - 1 `Fare` value missing for test data. Could complete it using some modelling.\n - Could extract something useful out of `Name`, like the title of the person --> could correlate with survival (i.e. sex, status, etc). For now, drop this column, and see how things perform.\n - **DROP**: `Cabin`, `Ticket`, `Name`. _Will also need to drop `PassengerId` before modelling --> just assign a copy with this column for X values in modelling_.","21c41c44":"## What are dimensions of the dataframes?","426f4e3a":"### Conclusions\/decisions from above:\n\n - Every passenger has a unique name\n - ~65% of passengers in training data are male\n - Tickets can be duplicate --> Not sure what these represent then\n - Cabins can be duplicate, so, more than one person can be assigned to a cabin. Number of duplicates for a passenger might correspond to sibsp and\/or Parch \n - Most popular port of embarkation is 'S', Southampton, ~72% of passengers in training data embarked from here","1be49ac6":"### conclusions\/decisions from above:\n\n - Most 3rd class did not survive, most 1st class did survive. infants in all classes tended to survive","473ff694":"## Read in data","bf825018":"### Conclusions\/decisions from above:\n\nNot many conclusions can be drawn from the above plot. \n - Age: Central age is ~25, and there is a bump at very young ages.\n - Fare: Most fares were relatively low.\n - Parch: Number of parents\/children tends to zero.\n - Pclass: Most passengers were in 2nd and 3rd(!) class.\n - SibSp: Most passengers were travelling with 1 or fewer siblings\/spouses","c36ddc4c":"## Plot histograms of numerical columns in training data","f01c7744":"***\n# 4. Select, train, and fine-tune model","5183fa94":"## Analyze survival related to SibSp and Parch with viz (follow up from tables above)","2a76f3be":"### conclusions\/decisions from above:\n\n - females have a higher survival fraction (confrimed) across all classes and ports of embarkation\n - could drop embarkation. However, from tables above ^^^^ there might be a small correlation between `Embarked` and overall survival (i.e. higher survival from embark = C)\n - Most people embarked at `Embarked` = S","010a8b78":"## Test IsAlone feature","1a0a5609":"### conclusions\/decisions from above:\n\n - Many infants survived\n - Mean age is slightly younger for survived than not survived\n - Median age is same for survived and did not survive\n - Histograms appear to show that more younger (between age ~16-32) passengers did not survive","0c2c4eaf":"## Column descriptions:\n\n\n**11 features, 2 targets**\n\n - `PassengerId`: _(numerical)_ Integer ID of passenger\n - `Survived`: _(Ordinal target)_ Flag in training set to indicate whether the passenger survived (=1) or not (=0)\n - `Pclass`: _(Ordinal feature)_ Ticket class, 1 = 1st (Upper, i.e. Rose), 2 = 2nd (Middle), 3 = 3rd (Lower, i.e. Jack)\n - `Name`: _(String feature)_ Name of passenger, surname first, includes title of passenger\n - `Sex`: _(Categorical feature)_ string 'male' or 'female'\n - `Age`: _(Numerical feature)_ age of passengger in years. is fractional if less than 1. If age is estimated, it is in the form of xx.5\n - `SibSp`: _(Ordinal feature)_ # of siblings \/ spouses aboard the Titanic. Sibling = brother, sister, stepbrother, stepsister. Spouse = husband, wife (mistresses and fiances were ignored)\n - `Parch`: _(Ordinal feature)_ # of parents \/ children aboard the Titanic. Parent = mother, father. Child = daughter, son, stepdaughter, stepson. Some children travelled only with a nanny, therefore `Parch = 0` for them.\n - `Ticket`: _(alpha-numerica string feature)_ Ticket number (string type)\n - `Fare`: _(Numerical feature)_ passenger fare, i.e. cost of the ticket\n - `Cabin`: _(alpha-numeric string feature)_ cabin number of passenger's room. **Apparently, only 1st class has this**\n - `Embarked`: _(Categorical feature)_ Port of embarkation. C = Cherbourg, Q = Queenstown (now Cobh), S = Southampton\n\n**Note: test data set does not have `Survived` target**","84924c29":"### Conlusions\/Decisions from above:\n\n - ~38% survival rate\n - Most passengers in 2nd or 3rd class. At least 50% of passengers are in 3rd class.\n - Mean and median age in late twenties. 50% of passengers are aged between ~20 and 38 years old. \n - On average, passengers travelling with 0.5 siblings\/spouses. Median is zero though, so at least 50% of passengers not travelling with siblings\/spouses\n - On average, passengers travel with 0.38 parents\/children. Median, 25th, and 75th percentile are zero, though, so, at least 75% of passengers are not travelling with parents\/children.\n - Average fare is ~\\\\$32. Median is ~\\\\$14.5. Fares are skewed quite a lot towards higher fares.","5d5a2c1b":"### Conclusions\/decisions from above:\n\n - **Pretty much the same observations as with the training data**","730d75af":"## Print dataframe info for double checking","46862265":"## Analyze survival as a function of combinations of (numerical, ordinal, categorical) features, with visualization","e61c2890":"## How many samples in each column are NULL\/NaN values?","57c9f4c1":"## How many passengers in training data survived\/didn't survive?","51b3ecea":"## Imports","b6b31b78":"***\n# 5. Evaluate model on test set","bcc61e39":"### conclusions\/decisions from above:\n\n - 1st class paid higher fares, lower classes paid less, makes sense --> higher fare correlates with higher survival\n - within first class, survivors paid even higher fares. This indicates subgroups of 1st class, possibly related to cabin\n - lowest fares (most from 3rd class) had highest mortality fraction","8bc15bdf":"### Conclusions\/decisions from above:\n\nThe same conclusions can be drawn from the histogram plot above this box and whisker plot. This plot is here mostly for completeness and reference for how to plot a box and whisker plot straight from a pandas dataframe.","5aa82520":"## Test FamilySize feature","3bdf1b0d":"## Create and run data transformation pipeline\n\n - Use statistics of training set to fill values in training and test sets --> **I am assuming** the two sets come from the same distribution\n - Use same number of bins for training and test data when discretizing continuous variable features into bins --> **I am assuming** the two sets come from the same distribution\n - Use median age to fill missing values, for now\n - Use `Embarked` = S for filling missing values since it is the port with the most embarkations\n - Use median Fare to fill missing values, for now\n - Discretize and bin `Age` values into equal sized bins, for now\n - Discretize and bin `Fare` values into equal sized bins, for now\n - Categorize `Pclass` into binary features\n - Categorize `Embarked` into binary features\n - Categorize `Sex` into a binary feature\n - Drop `Name`, `Parch`, `Ticket`, and `Cabin` as discussed above (i.e. don't consider their value at all)","0c60a97e":"### Conclusions\/decisions from above:\n\n - Many ages are missing. Historically, age was an important factor in surviving the titanic disaster. Will have to see if the data indicates that as well (~20% of ages are missing from BOTH training and test data) \n - A LOT of cabin info is missing, since cabins were only assigned to first class passengers. This indicates that first class passengers are a minority in these samples. Should double check that if a passenger is 1st class, then they have a cabin assigned. If not, would have to do some special stuff to fill in the blanks if we want. (77-78% of samples lack a cabin)\n - There are a couple of embarkation ports missing in the training data, but none are missing in the test data. Might just drop those samples\/passengers, or could try some modelling to fill in the gaps for the missing two. This coul be something we play with, since I am not sure what the right answer is, and it is the case for only 2 samples. (~0.2% of passengers in training data are lacking this data)\n - one fare in test data is missing","5a3074b4":"I have used various resources I found on the internet for researching this problem. I in no way intend to take this work as my own. This is just for fun for me. Thank you to those for the wisdom :) ","44466f3a":"### Conclusions\/decisions from above:\n\n - Pclass and Fare are negatively correlated --> Upper class tend to pay higher fare\n - Age and Pclass seems to be slightly negatively correlated --> older people tend to be more from upper class\n - Age and SibSp seems to be slightly negatively correlated --> Younger passengers tend to have more siblings\/spouses\n - SibSp and Parch seems to be slightly positively correlated --> Passengers travelling with siblings\/spouses tend to also be travlling with parents\/children (Maybe this is just families travelling together?)\n - **All other combinations --> doesn't seem to be a definite correlation between them**","8f6ef6ce":"### Conclusions\/decisions from above:\n\n - **Pretty much the same observations as with the training data**","cd75bd13":"## Analyze survival related to individual numerical features (with visualization)","bece8276":"***\n# 3. Data cleaning\/Feature selection\/Feature engineering","58b7776f":"### Conclusions\/decisions from above:\n\n - Being alone does seem to correlate with survival across all classes (3rd class just overall has a lower survival fraction)\n - Engineer `IsAlone` as a feature!","f68659fe":"## Plot correlation matrix of numerical training data","740e337d":"## Plot box and whisker plots of numerical training data","6c500a60":"### conclusions\/decisions from above:\n\n - More higher fares tended to survive, more lower fares tended not to survive. This could be linked to fare<->class relationship","01f8b6ca":"### ordinal and numerical features","a1de45ee":"## Print first few rows of the dataframes","b9201fc4":"***\n# 1. Collect training and test data","aaa13d22":"### conclusions\/decisions from above:\n\n - There does appear to be a trend of increasing survival with decreasing SibSp\n - No clear trend for Parch\n - Passengers travelling alone do not have maximum survival rate\n - Passengers travelling with relatively large number of SibSp or Parch seem to have low survival rate\n - Confirms that we should engineer a family size feature and test correlation with survival"}}