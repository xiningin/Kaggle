{"cell_type":{"3df21c81":"code","a747a923":"code","548b9310":"code","bc12a255":"code","4baf813c":"code","ac6d5479":"code","3786117d":"code","c500bfb5":"code","c4c2a640":"code","55abe7b1":"code","c08d9c41":"code","76352a47":"markdown","1fb44e7d":"markdown","c2f6f7d9":"markdown","1a1b58f0":"markdown","230f934d":"markdown","7ae160cf":"markdown","521ffabf":"markdown"},"source":{"3df21c81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","a747a923":"print(os.listdir('..\/input'))","548b9310":"label_names = [\"No\",\"Yes\"]\ndf_train = pd.read_csv(\"..\/input\/volcanoes_train\/train_images.csv\",header=None)\ndf_test = pd.read_csv(\"..\/input\/volcanoes_test\/test_images.csv\",header=None)\nprint(\"Shapes training: \",df_train.shape)\nprint(\"Shapes test: \",df_test.shape)\ndf_test.head()","bc12a255":"train_labels = pd.read_csv(\"..\/input\/volcanoes_train\/train_labels.csv\")\ntest_labels = pd.read_csv(\"..\/input\/volcanoes_test\/test_labels.csv\")\ntrain_labels.head()","4baf813c":"sns.countplot(data = train_labels,x=\"Volcano?\")\nplt.show()\nprint(\"On the ones with volcanoes\")\nsns.countplot(data = train_labels,x=\"Type\")\nplt.show()\nsns.countplot(data = train_labels,x=\"Number Volcanoes\")\nplt.show()","ac6d5479":"#Reshape \nX_test = df_test.values.reshape((df_test.shape[0],1,110,110)) \nX_train = df_train.values.reshape((df_train.shape[0],1,110,110))\nprint(X_train.shape)","3786117d":"#preprocess\nX_test = X_test\/255.0\nX_train = X_train\/255.0\n#Transpose to tensorflow dimension.\nX_test = X_test.transpose([0,2, 3, 1])\nX_train = X_train.transpose([0,2, 3, 1])\nprint(X_train.shape)","c500bfb5":"train_labels[\"Volcano?\"]","c4c2a640":"def visualize(X,Y):\n    n = np.random.randint(0,X.shape[0])\n    aux = X[n]\n    \n    f,ax = plt.subplots(1,figsize=(8,3))\n    ax.set_title(\"Ground Truth of Volcano?: %s \"%(label_names[Y[\"Volcano?\"][n]]))\n\n    ax.imshow(aux[:,:,0],cmap='copper') #the one channel\n    ax.set_yticks([])\n    ax.set_xticks([])\n    plt.show()\n    print(\"Detail:\",Y.loc[n,:])\n    \nvisualize(X_train,train_labels)","55abe7b1":"visualize(X_train,train_labels)","c08d9c41":"visualize(X_train,train_labels)","76352a47":"There is 0 csv file in the current version of the dataset:\n","1fb44e7d":"Now we have change the channel of the image and normalize between 0 and 1. Also we can visualize!","c2f6f7d9":"## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made.","1a1b58f0":"Now we are going to preprocess the data","230f934d":"## Introduction\nGreetings! This is an example kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.","7ae160cf":"There are two folders, one per each set.","521ffabf":"Here wen can see the unbalaced about the images with volcanoes and not, the relation is 1 to 6 in the training set. Also we can see there is a lot of images with only one volcanoe in the training set, also there are few most reliable volcanoes (type 1).\n\nFirst we need to reshape the rows of the data to retrieve the shape of the images (one chanel of 110x110 pixels images)\n\n### Create data as input\n\nAs the data come in rows, we have to reshape to recover the original matrix array and then we normalize between 0 and 1, also we transpose the matrix to have the shape accepted by the tensorflow backend (x,y,chanels).\n"}}