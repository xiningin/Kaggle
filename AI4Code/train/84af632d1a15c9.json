{"cell_type":{"af50bb4b":"code","1ee27f8c":"code","978ba333":"code","b6b82edf":"code","5fabb2b6":"code","c4ca98ef":"code","79f552b7":"code","5fba0c89":"code","84bf70db":"code","bac4cfa4":"code","d6fa9f5a":"code","498aa881":"code","e069d0e2":"code","80a0ae80":"code","c1d8edd8":"code","bda68a57":"code","f9136301":"code","fdce9452":"code","dabce8ab":"code","cb43eec5":"markdown","dd635f43":"markdown","062f94ce":"markdown","91521669":"markdown","2c813337":"markdown","b1431ecf":"markdown","d160c6b7":"markdown"},"source":{"af50bb4b":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport time","1ee27f8c":"import torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim","978ba333":"torch.__version__","b6b82edf":"import torchvision\ntorchvision.__version__","5fabb2b6":"# Kaggle Kernel-dependent\ninput_path = \"..\/input\/alien_vs_predator_thumbnails\/data\/\"","c4ca98ef":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\n# Use resnet pre-processing\ndata_transforms = {\n    'train':\n    transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize\n    ]),\n    'validation':\n    transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        normalize\n    ]),\n}\n\nimage_datasets = {\n    'train': \n    datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n    'validation': \n    datasets.ImageFolder(input_path + 'validation', data_transforms['validation'])\n}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=0),  # for Kaggle\n    'validation':\n    torch.utils.data.DataLoader(image_datasets['validation'],\n                                batch_size=32,\n                                shuffle=False,\n                                num_workers=0)  # for Kaggle\n}","79f552b7":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","5fba0c89":"model = models.resnet50(pretrained=True).to(device)\n# model = models.densenet121(pretrained=True).to(device)\n# print(model)\nfor param in model.parameters():\n    param.requires_grad = False   \n\n# num_ftrs = model.classifier.in_features\nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)\n# model.classifier = nn.Sequential(\n#                nn.Linear(num_ftrs, 128),\n#                nn.ReLU(inplace=True),\n#                nn.Linear(128, 2)).to(device)","84bf70db":"criterion = nn.CrossEntropyLoss()\n# Optimzer\noptimizer = optim.Adam(model.fc.parameters(), lr=0.0001)\n# LR scheduler\nlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                    cooldown=4,\n                                                    verbose=True)","bac4cfa4":"def train_model(model, criterion, optimizer, num_epochs=3):\n    last_end = time.time()\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train', 'validation']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                _, preds = torch.max(outputs, 1)\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(image_datasets[phase])\n            epoch_acc = running_corrects.double() \/ len(image_datasets[phase])\n            epoch_time = time.time() - last_end\n            last_end = time.time()\n            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n                                                        epoch_loss,\n                                                        epoch_acc))\n            print('Epoch Time {epoch_time:.3f}'.format(epoch_time=epoch_time))\n            if phase == 'validation':\n                lr_scheduler.step(epoch_loss)\n                print('-' * 10)\n    return model","d6fa9f5a":"model_trained = train_model(model, criterion, optimizer, num_epochs=20)","498aa881":"!mkdir models\n!mkdir models\/pytorch","e069d0e2":"torch.save(model_trained.state_dict(), 'models\/pytorch\/weights.h5')","80a0ae80":"model = models.resnet50(pretrained=False).to(device)\nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)\nmodel.load_state_dict(torch.load('models\/pytorch\/weights.h5'))","c1d8edd8":"validation_img_paths = [\"validation\/alien\/11.jpg\",\n                        \"validation\/alien\/22.jpg\",\n                        \"validation\/predator\/33.jpg\"]\nimg_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]","bda68a57":"validation_batch = torch.stack([data_transforms['validation'](img).to(device)\n                                for img in img_list])","f9136301":"pred_logits_tensor = model(validation_batch)\npred_logits_tensor","fdce9452":"pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\npred_probs","dabce8ab":"fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\nfor i, img in enumerate(img_list):\n    ax = axs[i]\n    ax.axis('off')\n    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n                                                            100*pred_probs[i,1]))\n    ax.imshow(img)","cb43eec5":"### 5. Save and load the model","dd635f43":"### 2. Create PyTorch data generators","062f94ce":"### 6. Make predictions on sample test images","91521669":"There is some error (even though the same version work on my own computer):\n\n> RuntimeError: DataLoader worker (pid 56) is killed by signal: Bus error. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n> RuntimeError: DataLoader worker (pid 59) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n \nSee [this issue](https:\/\/github.com\/pytorch\/pytorch\/issues\/5301) and [that thread](https:\/\/discuss.pytorch.org\/t\/dataloader-randomly-crashes-after-few-epochs\/20433\/2). Setting `num_workers=0` in `DataLoader` solved it.","2c813337":"Based on:\n\n* A deepsense.ai blog post [Keras vs. PyTorch - Alien vs. Predator recognition with transfer learning](https:\/\/deepsense.ai\/keras-vs-pytorch-avp-transfer-learning) in which we compare and contrast Keras and PyTorch approaches.\n* Repo with code: [github.com\/deepsense-ai\/Keras-PyTorch-AvP-transfer-learning](https:\/\/github.com\/deepsense-ai\/Keras-PyTorch-AvP-transfer-learning).\n* https:\/\/github.com\/pytorch\/examples\/blob\/master\/imagenet\/main.py\n\nChanges:\n\n* Add densenet121\n* Add imagenet preprocessing\n* Add lr_scheduler\n\n### 1. Import dependencies","b1431ecf":"### 3. Create the network","d160c6b7":"### 4. Train the model"}}