{"cell_type":{"fade7514":"code","c2628c06":"code","b5240896":"code","783fcfcf":"code","ceb2964d":"code","c17f67cc":"code","a807418e":"code","c5870540":"code","a64d50ba":"code","55d5228b":"code","9b5bc69c":"code","fd20b74c":"code","8fcfbbdf":"code","ff190dc9":"code","b8b18a52":"code","1fe3ac75":"code","94bd31ee":"code","a9bccf41":"code","89ffbd6a":"code","35ef0e5e":"code","d760234b":"code","f3aca470":"markdown","f2edf2f1":"markdown"},"source":{"fade7514":"#Libraries\nimport numpy as np \nimport pandas as pd \nfrom keras.layers import Input, Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import decode_predictions\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom PIL import Image \nimport seaborn as sns\nimport os \nfrom keras.applications import VGG19\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom numpy import newaxis\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,Dense,Activation,Dropout,Flatten,BatchNormalization\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import optimizers, applications, Sequential, losses\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom IPython.display import SVG\nfrom keras.applications import VGG19\nfrom skimage.feature import local_binary_pattern\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\ndir = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'\nlabel = []\npath = []\nfor dirname, _,filenames in os.walk(dir):\n    for filename in filenames:\n        if os.path.splitext(filename)[1]=='.png':\n            if dirname.split()[-1]!='GT':          \n                label.append(os.path.split(dirname)[1])\n                path.append(os.path.join(dirname,filename))\n\ndf = pd.DataFrame(columns=['path','label'])\ndf['path']=path\ndf['label']=label","c2628c06":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndf.tail()","b5240896":"print(df.shape)","783fcfcf":"df['label'].value_counts()","ceb2964d":"df.info()","c17f67cc":"df['label'].unique()","a807418e":"df['label']=df['label'].astype('category')","c5870540":"ind=0\nfig, ax = plt.subplots(nrows=3, ncols=3, figsize=(12,6), constrained_layout=True)\nax=ax.flatten()\nfor i in df['label'].unique():    \n    ax[ind].imshow(plt.imread(df[df['label']==i].iloc[0,0]))\n    ax[ind].set_title(i)\n    ind=ind+1","a64d50ba":"#random shape check\nk=int(np.random.randint(0,25))\nfor i in range(4):\n    print(\"the shape of the {}th image: \".format(i*k), plt.imread(df['path'][i*k]).shape)","55d5228b":"x_train, x_test=train_test_split(df, test_size=0.2, random_state=2, shuffle=True)\nprint(\"x_train shape is: \" , x_train.shape )\nprint(\"x_test shape is: \",   x_test.shape )\nNUM_TRAINING_IMAGES = int(x_train.shape[0])+int(x_test.shape[1])","9b5bc69c":"train_datagen = ImageDataGenerator(\n    zca_epsilon=1e-05,\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.4,\n    horizontal_flip=True,validation_split=0.3)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","fd20b74c":"X_train_img = train_datagen.flow_from_dataframe(dataframe=x_train, x_col='path', y_col='label',class_mode='categorical', subset='training', color_mode='rgb', batch_size=32)\nX_val_img = train_datagen.flow_from_dataframe(dataframe=x_train, x_col='path', y_col='label',class_mode='categorical', subset='validation', color_mode='rgb', batch_size=32)\nX_test_img =test_datagen.flow_from_dataframe(dataframe=x_test, x_col='path', y_col='label',class_mode='categorical', color_mode='rgb', batch_size=32, shuffle=False)","8fcfbbdf":"print(\"type:\", type(X_test_img))\nX_test_img[1][0].shape","ff190dc9":"image_shape=(256,256,3)\nBATCH_SIZE = 16 \nEPOCHS =42\nLEARNING_RATE = 3e-5 \nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nN_CLASSES = 9\nES_PATIENCE = 5\nLR_START = 0.000002\nLR_MIN = 0.000001\nLR_MAX = LEARNING_RATE\nLR_RAMPUP_EPOCHS = 4\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\n\nsns.set(style='whitegrid')\nfig, ax = plt.subplots(figsize=(20, 7))\nplt.plot(rng, y)\n\nprint(f'{EPOCHS} total epochs and {NUM_TRAINING_IMAGES\/\/BATCH_SIZE} steps per epoch')\nprint(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')","b8b18a52":"#base_model = tf.keras.applications.ResNet50V2(input_shape=(256,256,3), include_top=False, weights='imagenet')\n#base_model.trainable=True\n#base_model.summary()","1fe3ac75":"#tuning_layer_name = 'conv5_block1_preact_bn'\n#tuning_layer = base_model.get_layer(tuning_layer_name)\n#tuning_index = base_model.layers.index(tuning_layer)\n\n#for layer in base_model.layers[:tuning_index]:\n#    layer.trainable = False\n    \n#base_model.summary()","94bd31ee":"#model = tf.keras.Sequential([base_model, tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dense(N_CLASSES , activation='softmax')])\n\n\n#model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lrfn(EPOCHS)), metrics=['accuracy'])\n#history = model.fit(X_train_img, validation_data=X_val_img , epochs=EPOCHS)","a9bccf41":"base_model = tf.keras.applications.EfficientNetB5(input_shape=(256,256,3), include_top=False, weights='imagenet')\nbase_model.trainable=True\n#base_model.summary()","89ffbd6a":"model = tf.keras.Sequential([base_model, tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dense(N_CLASSES , activation='softmax')])\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lrfn(EPOCHS)), metrics=['accuracy'])","35ef0e5e":"history = model.fit(X_train_img, validation_data=X_val_img , epochs=EPOCHS)","d760234b":"pred = model.predict(X_test_img)\n\npred=np.argmax(pred,axis=1)\npred_df=x_test.copy()\nlabels={}\nfor l,v in X_test_img.class_indices.items():\n    labels.update({v:l})\npred_df['pred']=pred\npred_df['pred']=pred_df['pred'].apply(lambda x: labels[x])\n\nprint(f\"Accuracy Score: {accuracy_score(pred_df['label'],pred_df['pred'])}\")\nsns.heatmap(confusion_matrix(pred_df['label'],pred_df['pred']), annot=True, fmt='2d')   ","f3aca470":"![dee](https:\/\/wallpaperaccess.com\/full\/275637.jpg)","f2edf2f1":"# $\\color{ORANGE}{\\text{EfficientNet on Fish DataSet  }}$"}}