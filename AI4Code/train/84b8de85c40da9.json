{"cell_type":{"db974967":"code","2d35c4b0":"code","22a0ab09":"code","f197a6d8":"code","614a5941":"code","9f5bc306":"code","effd82c7":"code","658c1ce8":"code","f1c4f757":"code","389dcc49":"code","812eaad0":"code","4354f393":"code","13dc6859":"code","6e3a30d4":"code","52418ea1":"code","c65bdf0d":"code","5bb16064":"code","d8a3b3f1":"code","fe371565":"code","aa4e50b9":"code","1fa0987a":"code","a8146c10":"code","3a348638":"code","f0b7deef":"code","fd2af065":"code","d1580265":"code","4101f396":"code","04d0efba":"code","1f7c3544":"code","afadf8ba":"code","64ce9ca1":"code","79cd6905":"code","afd1a1a4":"code","c2209faf":"code","7eb46c49":"code","fa741a45":"code","852972d0":"code","faa025ff":"code","289d4dfb":"code","f8c9d3d3":"code","75fed6d9":"markdown","cfa836ca":"markdown","ff3eb300":"markdown","63ec9d43":"markdown","8d7be631":"markdown","c2de40c6":"markdown","bcf6b1a0":"markdown","f8ec616a":"markdown","a7d4cad5":"markdown","b8293112":"markdown","427beca1":"markdown","fbcaf73c":"markdown","d15f76bf":"markdown","fad2724c":"markdown","19a676c4":"markdown","8ef51e1f":"markdown","14278b82":"markdown","fa46169d":"markdown","c31fd734":"markdown","1bebda5b":"markdown","e32a711d":"markdown","2a40c44e":"markdown","8259173f":"markdown","055e2726":"markdown","afead132":"markdown","315fce6a":"markdown"},"source":{"db974967":"import numpy as np\nimport pandas as pd \n\nimport os\nimport plotly.express as px\n\nimport matplotlib.pyplot as plt\nimport cv2\nfrom wordcloud import WordCloud, STOPWORDS","2d35c4b0":"train = pd.read_csv('\/kaggle\/input\/shopee-product-matching\/train.csv')\ntrain","22a0ab09":"ds = train['label_group'].value_counts().reset_index()\nds.columns = ['label_group', 'products_count']\nds['label_group'] = ds['label_group'].astype(str)\nds = ds.sort_values(['products_count'])\n\nfig = px.bar(\n    ds.tail(50), \n    x=\"products_count\", \n    y=\"label_group\", \n    orientation='h', \n    title='Top 40 groups by number of products', \n    width=800, \n    height=1000\n)\n\nfig.show()","f197a6d8":"def plot_images(images_number):\n    \n    plot_list = train['image'].sample(n=images_number).tolist()\n    size = np.sqrt(images_number)\n    if int(size)*int(size) < images_number:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(os.path.join('..\/input\/shopee-product-matching\/train_images\/', image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(image_id, fontsize=12)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()","614a5941":"plot_images(16)","9f5bc306":"def plot_images(group):\n    \n    plot_list = train[train['label_group'] == group]\n    plot_list = plot_list['image'].tolist()\n    images_number = len(plot_list)\n    size = np.sqrt(images_number)\n    if int(size)*int(size) < images_number:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(os.path.join('..\/input\/shopee-product-matching\/train_images\/', image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(image_id, fontsize=6)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()","effd82c7":"plot_images(3627744656)","658c1ce8":"sample = train[train['label_group'] == 3627744656]\nprint('Total number of items in group 3627744656: ' + str(len(sample)) + ', number of unique titles: ' + str(sample['title'].nunique()))","f1c4f757":"plot_images(1163569239)","389dcc49":"sample = train[train['label_group'] == 1163569239]\nprint('Total number of items in group 1163569239: ' + str(len(sample)) + ', number of unique titles: ' + str(sample['title'].nunique()))","812eaad0":"plot_images(994676122)","4354f393":"sample = train[train['label_group'] == 994676122]\nprint('Total number of items in group 994676122: ' + str(len(sample)) + ', number of unique titles: ' + str(sample['title'].nunique()))","13dc6859":"plot_images(3113678103)","6e3a30d4":"sample = train[train['label_group'] == 3113678103]\nprint('Total number of items in group 3113678103: ' + str(len(sample)) + ', number of unique titles: ' + str(sample['title'].nunique()))","52418ea1":"plot_images(1141798720)","c65bdf0d":"sample = train[train['label_group'] == 1141798720]\nprint('Total number of items in group 1141798720: ' + str(len(sample)) + ', number of unique titles: ' + str(sample['title'].nunique()))","5bb16064":"plot_images(2329453736)","d8a3b3f1":"plot_images(1591152872)","fe371565":"plot_images(4057376991)","aa4e50b9":"ds = train['image_phash'].value_counts().reset_index()\nds.columns = ['image_phash', 'products_count']\nds['image_phash'] = ds['image_phash'].astype(str)\nds = ds.sort_values(['products_count'])\n\nfig = px.bar(\n    ds.tail(50), \n    x=\"products_count\", \n    y=\"image_phash\", \n    orientation='h', \n    title='Top 40 image_phash by number of products', \n    width=800, \n    height=1000\n)\n\nfig.show()","1fa0987a":"def plot_images(group):\n    \n    plot_list = train[train['image_phash'] == group]\n    plot_list = plot_list['image'].tolist()\n    images_number = len(plot_list)\n    size = np.sqrt(images_number)\n    if int(size)*int(size) < images_number:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(os.path.join('..\/input\/shopee-product-matching\/train_images\/', image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(image_id, fontsize=6)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()","a8146c10":"plot_images('fad28daa2ad05595')","3a348638":"plot_images('d0c0ea37bd9acce0')","f0b7deef":"plot_images('be12e12f9ec1e198')","fd2af065":"plot_images('f6d98134b904b56b')","d1580265":"train['title_len'] = train['title'].str.len()\ntrain","4101f396":"fig = px.histogram(\n    train, \n    x=\"title_len\",\n    width=800,\n    height=500,\n    title='Title length distribution'\n)\nfig.show()","04d0efba":"def build_wordcloud(df, title):\n    wordcloud = WordCloud(\n        background_color='black', \n        stopwords=set(STOPWORDS), \n        max_words=50, \n        max_font_size=40, \n        random_state=666\n    ).generate(str(df))\n\n    fig = plt.figure(1, figsize=(14,14))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=16)\n    fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","1f7c3544":"wordcloud = WordCloud(\n    background_color='black', \n    stopwords=set(STOPWORDS), \n    max_words=100, \n    max_font_size=40, \n    random_state=666\n).generate(str(train['title']))","afadf8ba":"ds = pd.DataFrame.from_dict(list(wordcloud.words_.items()))\nds.columns = ['word', 'score']\nds = ds.sort_values(['score'])\nds['word'] = ds['word'].astype(str)\n\nfig = px.bar(\n    ds.tail(50), \n    x=\"score\", \n    y=\"word\", \n    orientation='h', \n    title='Top 50 words in titles', \n    width=800, \n    height=1000\n)\n\nfig.show()","64ce9ca1":"build_wordcloud(train['title'], 'Wordcloud for train set titles')","79cd6905":"test =  pd.read_csv('\/kaggle\/input\/shopee-product-matching\/test.csv')\ntest","afd1a1a4":"sample = pd.read_csv('\/kaggle\/input\/shopee-product-matching\/sample_submission.csv')\nsample","c2209faf":"check = test.groupby(['title']).count().reset_index()['title'].tolist()\na = []\nb = []\nfor item in check:\n    res = test[test['title']== item]['posting_id'].tolist()\n    ans = \"\"\n    for id_item in res:\n        ans = ans + str(id_item) + \" \"\n    for id_item in res:\n        a.append(id_item)\n        b.append(ans)","7eb46c49":"submission1 = pd.DataFrame()\nsubmission1['posting_id'] = a\nsubmission1['matches'] = b\nsubmission1","fa741a45":"check = test.groupby(['image_phash']).count().reset_index()['image_phash'].tolist()\na = []\nb = []\nfor item in check:\n    res = test[test['image_phash']== item]['posting_id'].tolist()\n    ans = \"\"\n    for id_item in res:\n        ans = ans + str(id_item) + \" \"\n    ans = ans[:-1]\n    for id_item in res:\n        a.append(id_item)\n        b.append(ans)","852972d0":"submission2 = pd.DataFrame()\nsubmission2['posting_id'] = a\nsubmission2['matches'] = b\nsubmission2","faa025ff":"sub = pd.merge(submission1, submission2, on='posting_id', how='inner')\nsub['list'] = sub['matches_x'] + sub['matches_y']\nsub","289d4dfb":"final = []\nfor index, row in sub.iterrows():\n    res = list(set(row['list'].split(' ')))\n    ans = \"\"\n    for item in res:\n        ans = ans + str(item) + \" \"\n    ans = ans[:-1]\n    final.append(ans)\n    \nsubmission = pd.DataFrame()\nsubmission['posting_id'] = sub['posting_id']\nsubmission['matches'] = final\nsubmission","f8c9d3d3":"submission.to_csv('submission.csv', index=False)","75fed6d9":"<a id=\"5\"><\/a>\n<h2 style='background:orange; border:0; color:white'><center>5. Simple model for the same titles<\/center><h2>","cfa836ca":"#### Product 2329453736\t","ff3eb300":"#### Let's see products from the largest groups.","63ec9d43":"#### d0c0ea37bd9acce0","8d7be631":"**[train\/test].csv** - the training set metadata. Each row contains the data for a single posting. Multiple postings might have the exact same image ID, but with different titles or vice versa.\n\n* posting_id - the ID code for the posting.\n\n* image - the image id\/md5sum.\n\n* image_phash - a perceptual hash of the image.\n\n* title - the product description for the posting.\n\n* label_group - ID code for all postings that map to the same product. Not provided for the test set.","c2de40c6":"#### Product 3113678103","bcf6b1a0":"<a id=\"4\"><\/a>\n<h2 style='background:orange; border:0; color:white'><center>4. Test set<\/center><h2>","f8ec616a":"## So we can see a lot of exact duplicates here and some samples even have the same titles.","a7d4cad5":"#### be12e12f9ec1e198","b8293112":"#### Product 994676122","427beca1":"#### f6d98134b904b56b","fbcaf73c":"#### Let's check now the smallest groups.","d15f76bf":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h2>\n\n* [1. Training set](#1)\n* [2. Images visualization](#2)\n* [3. Titles analysis](#3)\n* [4. Test set](#4)\n* [5. Simple model for the same titles](#5)","fad2724c":"#### Product 1141798720","19a676c4":"<a id=\"3\"><\/a>\n<h2 style='background:orange; border:0; color:white'><center>3. Titles analysis<\/center><h2>","8ef51e1f":"#### Product 1591152872\t","14278b82":"<h1><center>Shopee - Data understanding and analysis<\/center><\/h1>\n\n<center><img src=\"https:\/\/klgadgetguy.com\/wp-content\/uploads\/2018\/10\/6ce1f4f6d79353c5f24ee047a5132d77.jpg\"><\/center>","fa46169d":"#### fad28daa2ad05595","c31fd734":"**sample_submission.csv** - a sample submission file in the correct format.\n\n* posting_id - the ID code for the posting.\n\n* matches - Space delimited list of all posting IDs that match this posting. Posts always self-match. Group sizes were capped at 50, so there's no need to predict more than 50 matches.","1bebda5b":"#### Let's check products that are in the same group.","e32a711d":"#### Product 1163569239","2a40c44e":"#### Let's assume that the records with exactly the same titles are the same products ","8259173f":"#### Product 3627744656","055e2726":"<a id=\"1\"><\/a>\n<h2 style='background:orange; border:0; color:white'><center>1. Training set<\/center><h2>","afead132":"#### Product 4057376991\t","315fce6a":"<a id=\"2\"><\/a>\n<h2 style='background:orange; border:0; color:white'><center>2. Images visualization<\/center><h2>"}}