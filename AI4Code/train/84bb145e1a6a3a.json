{"cell_type":{"54784cdc":"code","3f353102":"code","b4685e76":"code","c06da14e":"code","b71f8982":"code","4b229357":"code","a8ec1b5a":"code","b3e079ac":"code","30cfe2cb":"code","2bbdb9eb":"code","1e47986f":"code","6859a5d7":"code","42a27c00":"code","c691f5b7":"markdown","96c05123":"markdown","b5bcb3f1":"markdown","013b02ee":"markdown","6f89a05e":"markdown","31ab3ade":"markdown","a1b63ab6":"markdown","1300d18d":"markdown","2c528c1d":"markdown","6b5b3c66":"markdown","5840b3e4":"markdown","ad51af33":"markdown","5e38ea5a":"markdown","b0d9eb41":"markdown","a71b9243":"markdown","560219f4":"markdown"},"source":{"54784cdc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb # gradient boosting\nimport hyperopt as hp # optimization for Bayes\nimport sklearn # grid search and random search\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV","3f353102":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","b4685e76":"# Look at our data\ntrain.head(3)","c06da14e":"test.head(3)","b71f8982":"train = train.fillna(train.mean())","4b229357":"train.head(3)","a8ec1b5a":"train = pd.get_dummies(train) # Dummies without categorical vars","b3e079ac":"train.head(3)","30cfe2cb":"#creating matrices for sklearn:\nX_train = train[:train.shape[0]]\nX_test = train[train.shape[0]:]\ny = train.SalePrice","2bbdb9eb":"xgbr = xgb.XGBRegressor(n_estimators=100, n_jobs=-1) # our classification model","1e47986f":"folds = 6\nparam_comb = 10","6859a5d7":"skf = sklearn.model_selection.StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)","42a27c00":"g_search = GridSearchCV(xgbr,\n    {\n        'max_depth': [3],\n        'n_estimators': [6],\n        'learning_rate': [0.2],\n    }, n_jobs=4, cv=skf.split(X_train,y), verbose=3)\n\nr_search = RandomizedSearchCV(xgbr,\n    {\n        'max_depth': [3],\n        'n_estimators': [6],\n        'learning_rate': [0.2],\n    }, n_jobs=4, cv=skf.split(X_train,y), verbose=3)","c691f5b7":"## 1. Libraries and CSV Files\n\n---","96c05123":"### Dummy vars","b5bcb3f1":"# House Prices || Hyperparam Optimization\/Tuning Tutorial\n\n---\n\n<img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/5407\/logos\/front_page.png\"><\/img>","013b02ee":"There's not much to do here except:\n* Create dummy categorical variables.\n* Fill in NA values with the mean (we call this ***average imputation***)","6f89a05e":"# Conclusion\n\n---\n\nUsing this, fork and try to run the cross-validation model yourself. Hope you learnt something from this.","31ab3ade":"### Our approach and the models\n\n* **Random Search**: Using Scikit-Learn\u2019s RandomizedSearchCV function, we can define a grid of hyperparameter ranges, and randomly sample from the grid, performing K-Fold Cross Validation with each combination of values.\n* **Grid Search**: Grid search methodically builds and evaluates a model for every combination of parameters specified in a grid.","a1b63ab6":"Here we have a stratified KFold (another CV method) for us to use:","1300d18d":"## 2. Preprocessing","2c528c1d":"## 3. Define XGBoost and CV Model","6b5b3c66":"We are going to define an XGBoost Regressor model. And then we'll define our CV models.","5840b3e4":"### Cross-validation \n\n**Here are some good videos to watch:**\n* [Video 1](https:\/\/www.youtube.com\/watch?v=poKFir0QGCI)\n* [Video 2](https:\/\/www.youtube.com\/watch?v=sFO2ff-gTh0)","ad51af33":"### The model","5e38ea5a":"The CSV files can be read using the pandas `read_csv` function.","b0d9eb41":"In this tutorial, you are going to learn how to optimize your hyperparameters with Scikit-learn, HyperOpt and XGBoost. I assume those who read this have some knowledge of ML beforehand. \n\nThe techniques that will be covered are:\n* Grid search\n* Random search\n","a71b9243":"I'm not really going to explain to you about XGBoost if you don't know about it yet, but I have a few places for you to try and look up about XGBoost:\n* [This is from Medium.](https:\/\/towardsdatascience.com\/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)\n* [The official XGBoost Documentation](https:\/\/xgboost.readthedocs.io\/en\/latest\/)\n\nOr you can watch the videos:\n* [Video 1: Regression](https:\/\/www.youtube.com\/watch?v=OtD8wVaFm6E)\n* [Video 2: Classification](https:\/\/www.youtube.com\/watch?v=8b1JEDvenQU)\n* [Video 3: Mathematical Fundamentaks](https:\/\/www.youtube.com\/watch?v=ZVFeW798-2I)","560219f4":"You can import libraries here."}}