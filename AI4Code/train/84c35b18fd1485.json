{"cell_type":{"ab8ab566":"code","f13749d2":"code","d085bb21":"code","e6ba282f":"code","987b476a":"code","0d3af266":"code","79886e00":"code","a728238a":"code","1a04d5b4":"code","9e3cfb56":"code","80c99967":"code","e581d613":"code","01dec773":"code","fbd20b3a":"code","3981ac4b":"code","fa84b1a4":"code","97004cc7":"code","613555ed":"code","1b93b816":"code","295bebe8":"markdown","d8716fe9":"markdown","feaaf45a":"markdown","4ec15728":"markdown","fc16f892":"markdown","097d85e1":"markdown","ace93caa":"markdown","fa640a52":"markdown","e67a0b9e":"markdown","86abe5b1":"markdown","64a3f319":"markdown","779fc1e1":"markdown","2feff16b":"markdown"},"source":{"ab8ab566":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f13749d2":"datasetTrainPath = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ndatasetTestPath = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\ndatasetTrain = pd.read_csv(datasetTrainPath)\ndatasetTest = pd.read_csv(datasetTestPath)","d085bb21":"datasetTrain.head(5)","e6ba282f":"datasetTest.head(5)","987b476a":"import seaborn as sns \nimport matplotlib.pyplot as plt\ndatasetTrainY = datasetTrain[\"label\"]\ndatasetTrainX = datasetTrain.drop(labels = [\"label\"] , axis = 1)\nlabelDistributionPlot = sns.countplot(datasetTrainY)","0d3af266":"datasetTrainX.isnull().any().describe()","79886e00":"datasetTrainY.isnull().any()","a728238a":"datasetTest.isnull().any().describe()","1a04d5b4":"from sklearn.model_selection import train_test_split\ntrain_data_X , val_data_X , train_data_Y , val_data_Y = train_test_split(datasetTrainX, datasetTrainY, test_size = 0.2, \n                                                                             random_state = 0)","9e3cfb56":"train_data_X = train_data_X.astype(\"float32\") \/ 255.0\nval_data_X = val_data_X.astype(\"float32\") \/ 255.0","80c99967":"from sklearn import svm\nclf = svm.SVC()\nclf.fit(train_data_X, train_data_Y.ravel()) \nclf.score(val_data_X, val_data_Y)","e581d613":"from keras.utils.np_utils import to_categorical\ntrain_data_Y = to_categorical(train_data_Y, num_classes = 10)\nval_data_Y = to_categorical(val_data_Y, num_classes = 10)\n#28*28 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \ntrain_data_X = train_data_X.values.reshape(-1,*[28,28],1)\nval_data_X = val_data_X.values.reshape(-1,*[28,28],1)","01dec773":"from tensorflow.keras.optimizers import RMSprop\noptimizer = RMSprop(learning_rate = 0.001, rho = 0.9, epsilon = 1e-8, decay = 0.0)","fbd20b3a":"from keras.models import Sequential \nfrom keras.layers import MaxPool2D, Conv2D, Dropout, Flatten, Dense\nmodel = Sequential()\n# Conv2D \u0441\u043b\u043e\u0439 \u0441 32 \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u043c\u0438, \u044f\u0434\u0440\u043e\u043c 3*3, \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439 \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438 relu (\u043d\u0435\u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f), \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 28*28 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \u0441 1 \u043a\u0430\u043d\u0430\u043b\u043e\u043c \u0446\u0432\u0435\u0442\u0430\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), activation = \"relu\", input_shape = (*[28,28],1)))\n# \u0415\u0449\u0435 \u043e\u0434\u0438\u043d Conv2D \u0441\u043b\u043e\u0439 \u0441 \u044f\u0434\u0440\u043e\u043c 5*5, \u043d\u0443\u043b\u0435\u0432\u043e\u0439 \u043e\u0442\u0441\u0442\u0443\u043f(same)\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\"))\n# MaxPool2D \u0441\u043b\u043e\u0439 \u0441 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u043c \u043f\u0443\u043b\u0430 2*2\nmodel.add(MaxPool2D(pool_size = (2,2)))\n#Dropout \u0441\u043b\u043e\u0439 \u0441 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u043c \u043f\u0440\u043e\u043f\u043e\u0440\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u0438 0,25, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c \u0438\u0433\u043d\u043e\u0440\u0438\u0440\u0443\u0435\u0442 25% \u0443\u0437\u043b\u043e\u0432 \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0448\u0430\u0433\u0435, \n#\u0447\u0442\u043e \u0441\u043d\u0438\u0436\u0430\u0435\u0442 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u0441\u0432\u044f\u0437\u0438 \u043c\u0435\u0436\u0434\u0443 \u0443\u0437\u043b\u0430\u043c\u0438\nmodel.add(Dropout(0.25))\n\n#\u0421\u043d\u043e\u0432\u0430 Conv2D \u0441\u043b\u043e\u0438, \u043d\u043e \u0443\u0436\u0435 \u0441 64 \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u043c\u0438 \nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\nmodel.add(Dropout(0.25))\n\n#Flatten \u0441\u043b\u043e\u0439 \u0447\u0442\u043e\u0431\u044b \u0432\u0435\u0440\u043d\u0443\u0442\u044c \u0432 \u043e\u0434\u043d\u043e\u043c\u0435\u0440\u043d\u044b\u0439 \u0432\u0435\u043a\u0442\u043e\u0440\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\n# \u0421\u043b\u043e\u0439 softmax \u0441 10 \u0432\u044b\u0445\u043e\u0434\u0430\u043c\u0438:\nmodel.add(Dense(10, activation = \"softmax\"))","3981ac4b":"from keras.losses import categorical_crossentropy\nmodel.compile(optimizer = RMSprop(), loss = categorical_crossentropy, metrics = [\"accuracy\"])","fa84b1a4":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n#\u0423\u0447\u0438\u043c\u0441\u044f \u043d\u0430 42000 * 0.8 = 33600. 33600\/64 = 525 \u0431\u0430\u0442\u0447.\nepochs = 10\nbatch_size = 64\n\ngen = ImageDataGenerator() \ngenFlowTrain = gen.flow(train_data_X, train_data_Y, batch_size = batch_size)\ngenFlowVal = gen.flow(val_data_X, val_data_Y, batch_size = batch_size)\nsteps_per_epoch = genFlowTrain.n \/\/ batch_size \nvalidation_steps = genFlowVal.n \/\/ batch_size \n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\nhistory = model.fit_generator(generator = genFlowTrain, steps_per_epoch = steps_per_epoch, epochs = epochs,\n                             validation_data = genFlowVal, validation_steps = validation_steps,\n                             )","97004cc7":"datasetTestArray = np.array(datasetTest)\ndatasetTestArray = datasetTestArray.reshape(-1,28,28,1)\npredictions = model.predict(datasetTestArray)\nprint(predictions)\npredictionsTest = []\nfor prediction in predictions:\n    predictionsTest.append(np.argmax(prediction))","613555ed":"submission = pd.DataFrame({\n    \"ImageId\" : datasetTest.index+1,\n    \"Label\": predictionsTest\n})\nsubmission.to_csv('submission.csv', index = False)","1b93b816":"submission.head()","295bebe8":"\u041a\u0430\u043a \u0432\u0438\u0434\u0438\u043c, \u043d\u0435\u0442 \u0446\u0438\u0444\u0440\u044b, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u044b \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u043b\u0430\u0441\u044c \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0440\u0435\u0434\u043a\u043e \u0438\u043b\u0438 \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0447\u0430\u0441\u0442\u043e \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0445. \u042d\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u043e.","d8716fe9":"\u0421\u043e\u0431\u0435\u0440\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c","feaaf45a":"\u041f\u0435\u0440\u0435\u0434 \u043d\u0430\u0447\u0430\u043b\u043e\u043c \u0440\u0430\u0431\u043e\u0442\u044b \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0441 \u043a\u0430\u043a\u0438\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u043c\u044b \u0438\u043c\u0435\u0435\u043c \u0434\u0435\u043b\u043e.","4ec15728":"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043a\u0430\u043a\u0438\u0445 \u0446\u0438\u0444\u0440 \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c.","fc16f892":"\u0417\u0430\u0434\u0430\u0434\u0438\u043c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438, \u0447\u0442\u043e\u0431\u044b \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u043e\u0442\u0435\u0440\u044c (categorical_crossentropy - \u0440\u0430\u0437\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u043c\u0438 \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u043c\u0438 \u043c\u0435\u0442\u043a\u0430\u043c\u0438). \u0412 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u044b \u0441\u0442\u0430\u0440\u0430\u0435\u043c\u0441\u044f \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u043e\u0442\u0435\u0440\u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0438 \u043e\u0431\u043d\u043e\u0432\u043b\u044f\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0434\u043b\u044f \u043f\u043e\u0432\u044b\u0448\u0435\u043d\u0438\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438.\n\n\u0421\u0440\u0435\u0434\u043d\u0435\u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0438\u0447\u043d\u043e\u0435 \u0440\u0430\u0441\u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u043a\u043e\u0440\u043d\u044f (RMSprop) \u2014 \u044d\u0442\u043e \u044d\u043a\u0441\u043f\u043e\u043d\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0437\u0430\u0442\u0443\u0445\u0430\u044e\u0449\u0435\u0435 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0441\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e.","097d85e1":"\u0422\u0435\u043f\u0435\u0440\u044c \u043f\u0435\u0440\u0435\u0439\u0434\u0435\u043c \u043a \u043c\u043e\u0434\u0435\u043b\u0438.","ace93caa":"\u041f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u0438\u043c \u0432\u0441\u0435 \u043a\u0430\u043a \u0432\u0435\u043a\u0442\u043e\u0440 \u0434\u043b\u044f 10 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439 (\u0442\u0430\u043a \u043a\u0430\u043a \u0446\u0438\u0444\u0440\u044b \u043e\u0442 0 \u0434\u043e 9). \n\u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 (0010000000) \u044d\u0442\u043e 2","fa640a52":"\u0422\u0435\u043f\u0435\u0440\u044c \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043d\u0430 null \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f. ","e67a0b9e":"\u0420\u0430\u043d\u0434\u043e\u043c\u043d\u043e \u0440\u0430\u0437\u043e\u0431\u044a\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 (\u0441\u043e\u0441\u0442\u0430\u0432\u0438\u0442 20%). ","86abe5b1":"\u041d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 0.97. \u041e\u0434\u043d\u0430\u043a\u043e \u0441\u0442\u043e\u0438\u0442 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0442\u044c, \u0447\u0442\u043e \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0443 \u043d\u0430\u0441 \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0430\u044f (20% \u043e\u0442 \u0432\u0441\u0435\u0439), \u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043d\u0435\u0442\u043e\u0447\u043d\u044b\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 (\u0432\u0435\u0440\u043e\u044f\u0442\u043d\u0435\u0435 \u0431\u043e\u043b\u0435\u0435 \u043e\u043f\u0442\u0438\u043c\u0438\u0441\u0442\u0438\u0447\u043d\u044b\u0439, \u0447\u0435\u043c \u0435\u0441\u043b\u0438 \u0431\u044b \u043e\u043d\u0430 \u0431\u044b\u043b\u0430 \u0431\u043e\u043b\u044c\u0448\u0435). \n\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0440\u0435\u0448\u0438\u0442\u044c \u0437\u0430\u0434\u0430\u0447\u0443 \u043f\u043e-\u0434\u0440\u0443\u0433\u043e\u043c\u0443.","64a3f319":"\u0412\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u0441\u044f \u043c\u0435\u0442\u043e\u0434\u043e\u043c \u043e\u043f\u043e\u0440\u043d\u044b\u0445 \u0432\u0435\u043a\u0442\u043e\u0440\u043e\u0432. ","779fc1e1":"\u0412\u0441\u0435 \u043e\u0442\u043b\u0438\u0447\u043d\u043e, null \u043d\u0435\u0442.","2feff16b":"\u0421\u043d\u0430\u0447\u0430\u043b\u0430 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435."}}