{"cell_type":{"e455488a":"code","10a5b0b0":"code","a561f5ec":"code","cba31ed7":"code","a226cae7":"code","39366350":"code","cc8977b5":"code","93684fb5":"code","8019995e":"code","c12f3671":"code","e8017075":"code","26251083":"markdown","9f44c352":"markdown","31c32d54":"markdown","bd50321e":"markdown"},"source":{"e455488a":"# Import necessary libraries\nfrom copy import deepcopy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt","10a5b0b0":"# Set three centers, the model should predict similar results\ncenter_1 = np.array([1,1])\ncenter_2 = np.array([5,5])\ncenter_3 = np.array([8,1])\n\n# Generate random data and center it to the three centers\ndata_1 = np.random.randn(200, 2) + center_1\ndata_2 = np.random.randn(200,2) + center_2\ndata_3 = np.random.randn(200,2) + center_3\n\ndata = np.concatenate((data_1, data_2, data_3), axis = 0)\n\nplt.scatter(data[:,0], data[:,1], s=7)","a561f5ec":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","cba31ed7":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\ncenters_new    ","a226cae7":"# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","39366350":"df = pd.read_csv(\"..\/input\/Iris.csv\") #load the dataset\ndf.drop('Id',axis=1,inplace=True) # Se elimina la columna no requerida","cc8977b5":"df.head()","93684fb5":"# Change categorical data to number 0-2\ndf[\"Species\"] = pd.Categorical(df[\"Species\"])\ndf[\"Species\"] = df[\"Species\"].cat.codes\n# Change dataframe to numpy matrix\ndata = df.values[:, 0:4]\ncategory = df.values[:, 4]","8019995e":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","c12f3671":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\ncenters_new    ","e8017075":"# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","26251083":"# Create K-Means Algorithm\nGenerate random data normally distributed around 3 centers, with a noise.","9f44c352":"# Generate Random Data\nGenerate random data normally distributed around 3 centers, with a noise.","31c32d54":"# K-Means Clustering\nThis work is based on Mubaris' great work (\nhttps:\/\/mubaris.com\/2017\/10\/01\/kmeans-clustering-in-python\/).\n\nA description of the algorithm can be found:\nhttps:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/cs229-notes7a%202.pdf\n\n![](https:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/k4XcapI.gif?raw=true)","bd50321e":"# Test on Iris Dataset"}}