{"cell_type":{"8cf51e6b":"code","0d6034df":"code","cd328409":"code","0dc43c71":"code","982b3054":"code","6b4aae69":"code","1047f712":"code","661568f2":"code","48c97406":"code","0dd483d0":"code","581375c3":"code","692c4f1d":"code","d6d1cc92":"code","5c81f9b6":"code","d217bf78":"code","d14d5dca":"code","0cfe7898":"code","9c0253ac":"code","8cc632c2":"code","212696b2":"code","d5c07c1d":"code","659bb9bd":"code","7ee2ae00":"code","d094063a":"code","1cbe0030":"code","b8b5613a":"code","d7ae1f16":"code","76db8107":"code","df94c697":"code","75cb941c":"code","5c327979":"code","618e07ca":"code","5acc242a":"code","c9e0da12":"code","b5604b1b":"code","d26b83bb":"code","f062b6bb":"code","111c5393":"code","44a40e1f":"code","a2dd05f8":"code","6d502d88":"code","edd8cab6":"code","43b2d457":"code","46e5c3b9":"code","9871ac8c":"code","80639f2f":"code","16f4e625":"code","aaabcaec":"code","06982e3d":"code","9eab58bf":"code","cf49cfff":"code","24593b1f":"code","a1ee2c84":"markdown","89e61458":"markdown","bf562c50":"markdown","7c1bf440":"markdown"},"source":{"8cf51e6b":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score,roc_curve,classification_report,confusion_matrix,f1_score\nfrom sklearn.model_selection import train_test_split,cross_val_score\n%matplotlib inline\ndata = pd.read_csv(\"..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")","0d6034df":"data.head()","cd328409":"data.shape","0dc43c71":"data.isnull().sum()","982b3054":"# number of nulls are drawn using heatmap we can also print the values ( caution may not show small values like in this case )\nsns.heatmap(data.isnull(),yticklabels=False,cbar=False) \nplt.show()","6b4aae69":"sns.countplot(x=\"Property_Area\",data=data)\nplt.show()","1047f712":"sns.countplot(x=\"Gender\",data=data)","661568f2":"sns.countplot(x=\"Loan_Status\",hue=\"Married\",data=data)\n# it can be seen that married people are more likely to be given loan","48c97406":"sns.countplot(x=\"Loan_Status\",hue=\"Credit_History\",data=data,palette = \"rainbow\")\nplt.show()\n# it can be seen that credit history  is one of the most important feature for loan status","0dd483d0":"sns.countplot(x=\"Loan_Status\",data=data)","581375c3":"data.hist(bins=50,figsize=(10,10),grid=False)\nplt.tight_layout()\nplt.show()","692c4f1d":"sns.boxplot(x=\"Credit_History\",y=\"LoanAmount\",data=data,palette=\"winter\")","d6d1cc92":"sns.countplot(x=\"Dependents\",data=data)\nplt.show()","5c81f9b6":"sns.countplot(x=\"Self_Employed\",data=data)\nplt.show()","d217bf78":"sns.countplot(x=\"Education\",hue=\"Loan_Status\",data=data)\nplt.show()","d14d5dca":"# from the boxplot i can see that mean loan amount for both credit history is approximately same so i will fill nan using mean \n# value only\ndata.LoanAmount.fillna(data.LoanAmount.mean(),inplace=True)","0cfe7898":"# from the countplot of gender w can see that male is  more than female so we have high chances of nan being male \ndata.Gender.fillna(\"Male\",inplace=True)","9c0253ac":"data.Dependents.fillna('0',inplace=True)","8cc632c2":"data.Self_Employed.fillna(\"No\",inplace=True)","212696b2":"data.Credit_History.fillna(0.0,inplace=True)","d5c07c1d":"data.Loan_Amount_Term.fillna(data.Loan_Amount_Term.mode()[0],inplace=True)\ndata.Married.fillna(data.Married.mode()[0],inplace = True)","659bb9bd":"# ouliers in loan amount dataset can be log transformed so that effect of outliers can be removed\ndata[\"log_LoanAmount\"] = np.log(data.LoanAmount)","7ee2ae00":"data.log_LoanAmount.hist(bins=50)\nplt.show()","d094063a":"# rather than using differnet values of the Income combining both to get a general income and than taking log to remove \n# effect of outliers\ndata[\"totalIncome_log\"] = np.log(data.ApplicantIncome + data.CoapplicantIncome)","1cbe0030":"data.totalIncome_log.hist()","b8b5613a":"data.head()","d7ae1f16":"data = data.drop([\"Loan_ID\",\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\"],axis=1)","76db8107":"data.head()","df94c697":"data.info()","75cb941c":"from sklearn.preprocessing import LabelEncoder\ncategorical_column = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']\nle = LabelEncoder()\nfor i in categorical_column:\n    data[i] = le.fit_transform(data[i])\ndata.head()","5c327979":"data.info()","618e07ca":"data.info()","5acc242a":"train = data\ntrain.head()","c9e0da12":"train.Loan_Status.value_counts()","b5604b1b":"from sklearn.utils import resample\ndata_major = train[train.Loan_Status==1]\ndata_minor = train[train.Loan_Status==0]\ndata_upscale = resample(data_minor,replace= True,n_samples=422)\ntrain=pd.concat([data_major,data_upscale])","d26b83bb":"train.shape","f062b6bb":"def roc_curve_do(c_name,classifier,x_test,y_test):\n    probs = classifier.predict_proba(x_test)  \n    probs = probs[:, 1]  \n    fper, tper, thresholds = roc_curve(y_test, probs)\n    plt.plot(fper, tper)\n    plt.plot([0,1], [0,1], 'k--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('{} ROC curve'.format(c_name))\n  # show the plot\n    plt.show()\n\ndef kfold(classifier,X,Y,cv):\n    score=cross_val_score(classifier,X,Y,cv=cv)\n    print(\"Individual Score:\",score)\n    print(\"Mean Score:\",score.mean()*100,\"%\")\n  # plot\n    plt.plot(np.arange(cv), score, 'o-', linewidth=1)\n    plt.title(\"Accuracy: %f%% and Deviation (%f%%)\" % (score.mean()*100, score.std()*100))\n    plt.xlabel('number of Folds')\n    plt.ylabel('Accuracy score')\n    plt.show()\n\ndef all_score(classifier,x_test,y_test,x_train,y_train):\n    predict=classifier.predict(x_test)\n    print(\"testing accuracy:\",accuracy_score(y_test,predict))\n    print(\"training accuracy:\",accuracy_score(y_train,classifier.predict(x_train)))\n    print(confusion_matrix(y_test,predict))\n    print(\"Classification report:\\n\",classification_report(y_test,predict))","111c5393":"xtrain = train.drop([\"Loan_Status\"],axis=1)\nytrain = train[\"Loan_Status\"]","44a40e1f":"x_train,x_test,y_train,y_test = train_test_split(xtrain,ytrain,test_size=0.2)","a2dd05f8":"model = LogisticRegression(max_iter=200)\nmodel.fit(x_train,y_train)","6d502d88":"roc_curve_do(\"Logistic Regression\",model,x_test,y_test)\nkfold(model,xtrain,ytrain,5)\nall_score(model,x_test,y_test,x_train,y_train)","edd8cab6":"model1 = RandomForestClassifier(n_estimators=200)\nmodel1.fit(x_train,y_train)","43b2d457":"roc_curve_do(\"Logistic Regression\",model1,x_test,y_test)\nkfold(model1,xtrain,ytrain,5)\nall_score(model1,x_test,y_test,x_train,y_train)","46e5c3b9":"parameters =  ['Gender', 'Married', 'Dependents', 'Education','Self_Employed', 'Loan_Amount_Term', 'Credit_History', 'Property_Area','log_LoanAmount','totalIncome_log']\nfeatimp = pd.Series(model1.feature_importances_, index=parameters).sort_values(ascending=False)\nprint (featimp)","9871ac8c":"new_train = train.drop(['Property_Area','Married','Education','Gender','Self_Employed','Dependents','Loan_Amount_Term'],axis=1)","80639f2f":"new_train.head()","16f4e625":"new_xtrain = new_train.drop([\"Loan_Status\"],axis=1)\nnew_ytrain = new_train[\"Loan_Status\"]","aaabcaec":"new_xtrain.head()","06982e3d":"x_newtrain,x_newtest,y_newtrain,y_newtest = train_test_split(new_xtrain,new_ytrain,test_size=0.2)","9eab58bf":"model2 = RandomForestClassifier(n_estimators=150)","cf49cfff":"model2.fit(x_newtrain,y_newtrain)","24593b1f":"roc_curve_do(\"Random Forest\",model2,x_newtest,y_newtest)\nkfold(model2,new_xtrain,new_ytrain,5)\nall_score(model2,x_newtest,y_newtest,x_newtrain,y_newtrain)","a1ee2c84":"feature selection using random forest","89e61458":"some extra pre processing ","bf562c50":"# clearly dataset is very imbalance therefore using upsampling to make datatset balanced","7c1bf440":"NAN removing according to the plots we have plotted above\n\n\n\n\n\n\n"}}