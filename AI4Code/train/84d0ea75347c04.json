{"cell_type":{"bad726ba":"code","ed66bcc6":"code","4158f4f7":"code","9ef1dc0a":"code","dc95ade5":"code","3b75e7ff":"code","a493a4ec":"code","dc7ff8fd":"code","81efac26":"code","49b794f2":"code","6dffa157":"code","a2b55f5e":"code","354e7a7b":"code","88336e6d":"code","fee61cee":"code","a83dab3f":"code","a589075e":"code","358ea954":"code","b65091d8":"code","6996fcc8":"code","a87fc78c":"code","d4bb4a0a":"markdown","2d0a275f":"markdown"},"source":{"bad726ba":"import sys\nsys.path.append('..\/input\/keras-ssd\/')","ed66bcc6":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \nimport tensorflow as tf","4158f4f7":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import load_model\nfrom math import ceil\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom models.keras_ssd7 import build_model\nfrom keras_loss_function.keras_ssd_loss import SSDLoss\nfrom keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\nfrom keras_layers.keras_layer_DecodeDetections import DecodeDetections\nfrom keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n\nfrom ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\nfrom ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n\nfrom data_generator.object_detection_2d_data_generator import DataGenerator\nfrom data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\nfrom data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\nfrom data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\nfrom data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n\n%matplotlib inline","9ef1dc0a":"img_height = 300\nimg_width = 480\nimg_channels = 3\n\nintensity_mean = 127.5\nintensity_range = 127.5\n\nn_classes = 5\nscales = [0.08, 0.16, 0.32, 0.64, 0.96]\naspect_ratios = [0.5, 1.0, 2.0]\ntwo_boxes_for_ar1 = True\nsteps = None\noffsets = None\nclip_boxes = False\nvariances = [1.0, 1.0, 1.0, 1.0]\nnormalize_coords = True","dc95ade5":"K.clear_session()\n\nmodel = build_model(image_size=(img_height, img_width, img_channels),\n                    n_classes=n_classes,\n                    mode='training',\n                    l2_regularization=0.0005,\n                    scales=scales,\n                    aspect_ratios_global=aspect_ratios,\n                    aspect_ratios_per_layer=None,\n                    two_boxes_for_ar1=two_boxes_for_ar1,\n                    steps=steps,\n                    offsets=offsets,\n                    clip_boxes=clip_boxes,\n                    variances=variances,\n                    normalize_coords=normalize_coords,\n                    subtract_mean=intensity_mean,\n                    divide_by_stddev=intensity_range)","3b75e7ff":"model.load_weights('..\/input\/keras-ssd\/ssd7_weights.h5')\n\nadam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n\nssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n\nmodel.compile(optimizer=adam, loss=ssd_loss.compute_loss)","a493a4ec":"train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\nval_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)","dc7ff8fd":"images_dir = '..\/input\/self-driving-cars\/images\/'\n\ntrain_labels_filename = '..\/input\/self-driving-cars\/labels_train.csv'\nval_labels_filename   = '..\/input\/self-driving-cars\/\/labels_val.csv'","81efac26":"train_dataset.parse_csv(images_dir=images_dir,\n                        labels_filename=train_labels_filename,\n                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n                        include_classes='all')\n\nval_dataset.parse_csv(images_dir=images_dir,\n                      labels_filename=val_labels_filename,\n                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n                      include_classes='all')","49b794f2":"train_dataset_size = train_dataset.get_dataset_size()\nval_dataset_size   = val_dataset.get_dataset_size()\n\nprint(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\nprint(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))","6dffa157":"batch_size = 16\n\ndata_augmentation_chain = DataAugmentationConstantInputSize(random_brightness=(-48, 48, 0.5),\n                                                            random_contrast=(0.5, 1.8, 0.5),\n                                                            random_saturation=(0.5, 1.8, 0.5),\n                                                            random_hue=(18, 0.5),\n                                                            random_flip=0.5,\n                                                            random_translate=((0.03,0.5), (0.03,0.5), 0.5),\n                                                            random_scale=(0.5, 2.0, 0.5),\n                                                            n_trials_max=3,\n                                                            clip_boxes=True,\n                                                            overlap_criterion='area',\n                                                            bounds_box_filter=(0.3, 1.0),\n                                                            bounds_validator=(0.5, 1.0),\n                                                            n_boxes_min=1,\n                                                            background=(0,0,0))","a2b55f5e":"predictor_sizes = [model.get_layer('classes4').output_shape[1:3],\n                   model.get_layer('classes5').output_shape[1:3],\n                   model.get_layer('classes6').output_shape[1:3],\n                   model.get_layer('classes7').output_shape[1:3]]","354e7a7b":"ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n                                    img_width=img_width,\n                                    n_classes=n_classes,\n                                    predictor_sizes=predictor_sizes,\n                                    scales=scales,\n                                    aspect_ratios_global=aspect_ratios,\n                                    two_boxes_for_ar1=two_boxes_for_ar1,\n                                    steps=steps,\n                                    offsets=offsets,\n                                    clip_boxes=clip_boxes,\n                                    variances=variances,\n                                    matching_type='multi',\n                                    pos_iou_threshold=0.5,\n                                    neg_iou_limit=0.3,\n                                    normalize_coords=normalize_coords)","88336e6d":"train_generator = train_dataset.generate(batch_size=batch_size,\n                                         shuffle=True,\n                                         transformations=[data_augmentation_chain],\n                                         label_encoder=ssd_input_encoder,\n                                         returns={'processed_images',\n                                                  'encoded_labels'},\n                                         keep_images_without_gt=False)\n\nval_generator = val_dataset.generate(batch_size=batch_size,\n                                     shuffle=False,\n                                     transformations=[],\n                                     label_encoder=ssd_input_encoder,\n                                     returns={'processed_images',\n                                              'encoded_labels'},\n                                     keep_images_without_gt=False)","fee61cee":"model_checkpoint = ModelCheckpoint(filepath='ssd7_weights.h5',\n                                   monitor='val_loss',\n                                   verbose=1,\n                                   save_best_only=True,\n                                   save_weights_only=False,\n                                   mode='auto',\n                                   period=1)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               min_delta=0.0,\n                               patience=10,\n                               verbose=1)\n\nreduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n                                         factor=0.2,\n                                         patience=8,\n                                         verbose=1,\n                                         min_delta=0.001,\n                                         cooldown=0,\n                                         min_lr=0.00001)\n\ncallbacks = [model_checkpoint,\n             early_stopping,\n             reduce_learning_rate]","a83dab3f":"def train(model):\n    initial_epoch   = 0\n    final_epoch     = 20\n    steps_per_epoch = 1000\n\n    history = model.fit_generator(generator=train_generator,\n                                steps_per_epoch=steps_per_epoch,\n                                epochs=final_epoch,\n                                callbacks=callbacks,\n                                validation_data=val_generator,\n                                validation_steps=ceil(val_dataset_size\/batch_size),\n                                initial_epoch=initial_epoch)\n\n    plt.figure(figsize=(20,12))\n    plt.plot(history.history['loss'], label='loss')\n    plt.plot(history.history['val_loss'], label='val_loss')\n    plt.legend(loc='upper right', prop={'size': 24})\n\n    return model","a589075e":"predict_generator = val_dataset.generate(batch_size=1,\n                                         shuffle=True,\n                                         transformations=[],\n                                         label_encoder=None,\n                                         returns={'processed_images',\n                                                  'processed_labels',\n                                                  'filenames'},\n                                         keep_images_without_gt=False)","358ea954":"batch_images, batch_labels, batch_filenames = next(predict_generator)\n\ni = 0\n\nprint(\"Image:\", batch_filenames[i])\nprint()\nprint(\"Ground truth boxes:\\n\")\nprint(batch_labels[i])","b65091d8":"y_pred = model.predict(batch_images)","6996fcc8":"# 4: Decode the raw prediction `y_pred`\n\ny_pred_decoded = decode_detections(y_pred * 266.,\n                                   confidence_thresh=0.5,\n                                   iou_threshold=0.45,\n                                   top_k=200,\n                                   normalize_coords=normalize_coords,\n                                   img_height=img_height,\n                                   img_width=img_width)\n\nnp.set_printoptions(precision=2, suppress=True, linewidth=90)\nprint(\"Predicted boxes:\\n\")\nprint('   class   conf xmin   ymin   xmax   ymax')\nprint(y_pred_decoded[i])","a87fc78c":"plt.figure(figsize=(20,12))\nplt.imshow(batch_images[i])\n\ncurrent_axis = plt.gca()\n\ncolors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\nclasses = ['background', 'car', 'truck', 'pedestrian', 'bicyclist', 'light']\n\nfor box in batch_labels[i]:\n    xmin = box[1]\n    ymin = box[2]\n    xmax = box[3]\n    ymax = box[4]\n    label = '{}'.format(classes[int(box[0])])\n    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='green', fill=False, linewidth=2))  \n    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':'green', 'alpha':1.0})\n\nfor box in y_pred_decoded[i]:\n    xmin = box[-4]\n    ymin = box[-3]\n    xmax = box[-2]\n    ymax = box[-1]\n    color = colors[int(box[0])]\n    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  ","d4bb4a0a":"# Predictions","2d0a275f":"# Single Shot MultiBox Detector (SSD) Self-Driving Cars"}}