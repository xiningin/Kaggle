{"cell_type":{"936568bb":"code","a7e33d14":"code","607ac44c":"code","525c509b":"code","7fdce9e4":"code","f1dd4ddd":"code","6f4f1167":"code","9d8ad0e9":"markdown","0ae5bbc4":"markdown","c1d4629d":"markdown","05ae52ba":"markdown","a70f920d":"markdown","c23b0232":"markdown","4c6e2fb2":"markdown"},"source":{"936568bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy.stats import truncnorm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a7e33d14":"def sigmoid(x):\n    return 1 \/ (1 + np.e ** -x)\n\n\nactivation_function = sigmoid\n\n\ndef truncated_normal(mean=0, sd=1, low=0, upp=10):\n    return truncnorm(\n        (low - mean) \/ sd, (upp - mean) \/ sd, loc=mean, scale=sd)","607ac44c":"Acc = []  # Accuracy\nInput_Data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\nOutput_Data = np.array([[0], [1], [1], [0]])","525c509b":"class NeuralNetwork:\n    def __init__(self,\n                 no_of_in_nodes,\n                 no_of_out_nodes,\n                 no_of_hidden_nodes,\n                 learning_rate):\n        self.no_of_in_nodes = no_of_in_nodes\n        self.no_of_out_nodes = no_of_out_nodes\n        self.no_of_hidden_nodes = no_of_hidden_nodes\n        self.learning_rate = learning_rate\n        self.create_weight_matrices()\n\n    def create_weight_matrices(self):\n        \"\"\" A method to initialize the weight matrices of the neural network\"\"\"\n        rad = 1 \/ np.sqrt(self.no_of_in_nodes)\n        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n        self.weights_in_hidden = X.rvs((self.no_of_hidden_nodes,\n                                        self.no_of_in_nodes))\n        rad = 1 \/ np.sqrt(self.no_of_hidden_nodes)\n        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n        self.weights_hidden_out = X.rvs((self.no_of_out_nodes,\n                                         self.no_of_hidden_nodes))\n\n    def train(self, input_vector, target_vector):\n        # input_vector and target_vector can be tuple, list or ndarray\n        input_vector = np.array(input_vector, ndmin=2).T\n        target_vector = np.array(target_vector, ndmin=1).T\n\n        # hidden layer1\n        output_vector1 = np.dot(self.weights_in_hidden, input_vector)\n        output_vector_hidden = activation_function(output_vector1)\n        # hidden layer2\n        output_vector2 = np.dot(self.weights_hidden_out, output_vector_hidden)\n        output_vector_network = activation_function(output_vector2)\n        # errors\n        output_errors = target_vector - output_vector_network\n\n        # Added Portion#######\n        Acc.append(np.mean(1 - (np.abs(output_errors))))\n        #################\n\n        # update the weights:\n        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)\n        tmp = self.learning_rate * np.dot(tmp, output_vector_hidden.T)\n        self.weights_hidden_out += tmp\n        # calculate hidden errors:\n        hidden_errors = np.dot(self.weights_hidden_out.T, output_errors)\n        # update the weights:\n        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n        self.weights_in_hidden += self.learning_rate * np.dot(tmp, input_vector.T)\n\n        return output_vector_network\n\n    def run(self, input_vector):\n        # input_vector can be tuple, list or ndarray\n        input_vector = np.array(input_vector, ndmin=2).T\n        output_vector = np.dot(self.weights_in_hidden, input_vector)\n        output_vector = activation_function(output_vector)\n\n        output_vector = np.dot(self.weights_hidden_out, output_vector)\n        output_vector = activation_function(output_vector)\n\n        return output_vector","7fdce9e4":"#### first for() : Determine the number of hidden nodes\nfor count in range(1, 1000):\n    simple_network = NeuralNetwork(no_of_in_nodes=2,\n                                   no_of_out_nodes=1,\n                                   no_of_hidden_nodes=count,\n                                   learning_rate=0.7)\n    x, y = [], []\n\n    #### second for() : Input data, Output data, iteration(50000)\n    for i in range(50000):\n        traning_cls = simple_network.train(Input_Data, Output_Data)\n        x.append(traning_cls[0])\n        y.append(i)\n        if (i % 10000 == 0): print(i, \": \", traning_cls)\n\n    acc = Acc[49999]  # the last stored value Acc\n    print(\"\\n\\nno_of_hidden_nodes : \", count, \"\\nAccuracy  : \", acc)\n\n    #### Variable initialization for when the number of hidden nodes increases (that is, when the next for loop is repeated)\n    Acc.clear(), y.clear(), x.clear()\n\n    #### If Accuracy is greater than 0.95 (that is, when the accuracy is greater than 95%), break\n    if (acc > 0.95):\n        break","f1dd4ddd":"data = pd.read_csv('\/kaggle\/input\/xordataset\/test.csv').values\nN, d = data.shape\nInput_test = data[:, 0:d].reshape(-1, d)\n\nx1 = data[:, 0].reshape(-1, 1)\nx2 = data[:, 1].reshape(-1, 1)\n\n#print(Input_test)\ncls1 = simple_network.run(Input_test)\nfor i in range(len(Input_test)):\n    print(Input_test[i][0], \" XOR \", Input_test[i][1], \" : \", round(cls1[0][i], 2))","6f4f1167":"fig = pyplot.figure()\nax = Axes3D(fig)\nax.set_label(\"ABC\")\nax.scatter3D(x1, x2, cls1)\nax.set_xlabel(xlabel=\"Input 1\")\nax.set_ylabel(ylabel=\"Input 2\")\nax.set_zlabel(zlabel=\"Output\")\npyplot.show()","9d8ad0e9":"**Function**","0ae5bbc4":"**Draw 3D**","c1d4629d":"**Variable**","05ae52ba":"**Main() Function** ","a70f920d":"**Test**","c23b0232":"# **Assignment1: **\n\nDesign a Neural Networks to train the XOR problem as following using Python programming language.\nXOR problem\n\nInputs     |    output\n\n   i1 i2\n   \n   0  0  ----->        0\n   \n   0  1  ----->        1\n   \n   1  0  ----->        1\n   \n   1  1  ----->        0\n\nTake the output of the network for the ranges  i1 =[-0.8, 1.2],  i2 =[-0.8, 1.2]\nwith the interval of 0.05 sequentially and draw the output in 3D.","4c6e2fb2":"**Class Definitions** "}}