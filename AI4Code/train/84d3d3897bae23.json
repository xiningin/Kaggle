{"cell_type":{"305d6b27":"code","e6c95d49":"code","92fc3d51":"code","fd0fb62c":"code","80f74391":"code","8d76e414":"code","953848b9":"code","5d56579e":"code","66668adc":"code","b5660768":"code","38cf6549":"code","3b9b5685":"code","0ead8cd0":"code","bb44601d":"code","42a5dac0":"code","0ab6e2f4":"code","e9c21939":"code","255ba0ac":"code","84264266":"code","3f374c9d":"code","981f16df":"code","c8b499c3":"code","0757a38a":"code","b7177e38":"code","ae16078d":"code","8427fbfb":"code","8a79ec22":"code","c509ac84":"code","de1b6ddd":"code","68b2563c":"code","d15262cf":"code","0b4a57bc":"code","878225f9":"code","149e1f18":"code","494203ca":"code","7644528a":"code","8426e326":"code","938c9063":"code","22c6ef2f":"code","b43e24cd":"code","7c7b8213":"code","9a669e56":"code","758af7fb":"code","497aac60":"code","5b22cc4b":"code","f4c95d39":"code","0665eca6":"code","30de849e":"code","153a2994":"code","aa6566a5":"code","0b82bb56":"code","87e24f06":"code","5a81f8da":"code","c0fb3c66":"code","4af9c0ac":"code","043f87e3":"code","e44af410":"code","193c0481":"code","fb2299f6":"code","06b32205":"code","59a112af":"code","b1e7863d":"code","a6dd4efc":"code","02c3a02c":"markdown","396cc446":"markdown","b5e9b495":"markdown","a51b1150":"markdown","3330ab57":"markdown","27ecfad7":"markdown","7671dcd4":"markdown","6c4fbe8b":"markdown","27d6426d":"markdown","4b1f4935":"markdown","f93e9b6a":"markdown","d7eb4613":"markdown","055133ef":"markdown","6ebcd912":"markdown","b74807d3":"markdown","1c037387":"markdown","6ae259d0":"markdown","a981554b":"markdown","f1d9b0a6":"markdown","981e6d08":"markdown","ac406b9d":"markdown","e4bc453d":"markdown","1403d26b":"markdown","399b79ab":"markdown","537af14d":"markdown","ca644ed9":"markdown","f21bef2b":"markdown","1bc7ab50":"markdown","0b98c1c5":"markdown","6cf5054d":"markdown","eef3b177":"markdown","6afd36b9":"markdown","1bf5b5af":"markdown","6ec48264":"markdown","7cb4285e":"markdown","e1f5bfbb":"markdown","840cf4b2":"markdown","78581fe7":"markdown","49136d4d":"markdown","14c7169b":"markdown","8f623dbd":"markdown","3386da11":"markdown","9b9bd52e":"markdown","06b13a1b":"markdown","3f3b4460":"markdown","5833a9b0":"markdown","f05b6526":"markdown"},"source":{"305d6b27":"import warnings\nwarnings.filterwarnings('ignore')","e6c95d49":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","92fc3d51":"df = pd.read_csv('..\/input\/heart.csv')\ndf.head(3)","fd0fb62c":"df.info()","80f74391":"print('Number of rows in the dataset: ',df.shape[0])\nprint('Number of columns in the dataset: ',df.shape[1])","8d76e414":"df.isnull().sum()","953848b9":"df.describe()","5d56579e":"male =len(df[df['sex'] == 1])\nfemale = len(df[df['sex']== 0])\n\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Male','Female'\nsizes = [male,female]\ncolors = ['skyblue', 'yellowgreen']\nexplode = (0, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=90)\n \nplt.axis('equal')\nplt.show()","66668adc":"plt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Chest Pain Type:0','Chest Pain Type:1','Chest Pain Type:2','Chest Pain Type:3'\nsizes = [len(df[df['cp'] == 0]),len(df[df['cp'] == 1]),\n         len(df[df['cp'] == 2]),\n         len(df[df['cp'] == 3])]\ncolors = ['skyblue', 'yellowgreen','orange','gold']\nexplode = (0, 0,0,0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","b5660768":"plt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'fasting blood sugar < 120 mg\/dl','fasting blood sugar > 120 mg\/dl'\nsizes = [len(df[df['fbs'] == 0]),len(df[df['cp'] == 1])]\ncolors = ['skyblue', 'yellowgreen','orange','gold']\nexplode = (0.1, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","38cf6549":"plt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'No','Yes'\nsizes = [len(df[df['exang'] == 0]),len(df[df['exang'] == 1])]\ncolors = ['skyblue', 'yellowgreen']\nexplode = (0.1, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=90)\n \nplt.axis('equal')\nplt.show()","3b9b5685":"sns.set_style('whitegrid')","0ead8cd0":"plt.figure(figsize=(14,8))\nsns.heatmap(df.corr(), annot = True, cmap='coolwarm',linewidths=.1)\nplt.show()","bb44601d":"sns.distplot(df['thalach'],kde=False,bins=30,color='violet')","42a5dac0":"sns.distplot(df['chol'],kde=False,bins=30,color='red')\nplt.show()","0ab6e2f4":"sns.distplot(df['trestbps'],kde=False,bins=30,color='blue')\nplt.show()","e9c21939":"plt.figure(figsize=(15,6))\nsns.countplot(x='age',data = df, hue = 'target',palette='GnBu')\nplt.show()","255ba0ac":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='chol',y='thalach',data=df,hue='target')\nplt.show()","84264266":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='trestbps',y='thalach',data=df,hue='target')\nplt.show()","3f374c9d":"X= df.drop('target',axis=1)\ny=df['target']","981f16df":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=42)","c8b499c3":"from sklearn.preprocessing import StandardScaler","0757a38a":"scaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_train = pd.DataFrame(X_train_scaled)\n\nX_test_scaled = scaler.transform(X_test)\nX_test = pd.DataFrame(X_test_scaled)","b7177e38":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nknn =KNeighborsClassifier()\nparams = {'n_neighbors':list(range(1,20)),\n    'p':[1, 2, 3, 4,5,6,7,8,9,10],\n    'leaf_size':list(range(1,20)),\n    'weights':['uniform', 'distance']\n         }","ae16078d":"model = GridSearchCV(knn,params,cv=3, n_jobs=-1)","8427fbfb":"model.fit(X_train,y_train)\nmodel.best_params_           #print's parameters best values","8a79ec22":"predict = model.predict(X_test)","c509ac84":"from sklearn.metrics import accuracy_score,confusion_matrix\nprint('Accuracy Score: ',accuracy_score(y_test,predict))\nprint('Using k-NN we get an accuracy score of: ',\n      round(accuracy_score(y_test,predict),5)*100,'%')","de1b6ddd":"\ncnf_matrix = confusion_matrix(y_test,predict)\ncnf_matrix","68b2563c":"class_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for k-Nearest Neighbors Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","d15262cf":"from sklearn.metrics import classification_report","0b4a57bc":"print(classification_report(y_test,predict))","878225f9":"from sklearn.metrics import roc_auc_score,roc_curve","149e1f18":"#Get predicted probabilites from the model\ny_probabilities = model.predict_proba(X_test)[:,1]","494203ca":"#Create true and false positive rates\nfalse_positive_rate_knn,true_positive_rate_knn,threshold_knn = roc_curve(y_test,y_probabilities)","7644528a":"#Plot ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('Revceiver Operating Characterstic')\nplt.plot(false_positive_rate_knn,true_positive_rate_knn)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","8426e326":"#Calculate area under the curve\nroc_auc_score(y_test,y_probabilities)","938c9063":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression()","22c6ef2f":"# Setting parameters for GridSearchCV\nparams = {'penalty':['l1','l2'],\n         'C':[0.01,0.1,1,10,100],\n         'class_weight':['balanced',None]}\nlog_model = GridSearchCV(log,param_grid=params,cv=10)","b43e24cd":"log_model.fit(X_train,y_train)\n\n# Printing best parameters choosen through GridSearchCV\nlog_model.best_params_","7c7b8213":"predict = log_model.predict(X_test)","9a669e56":"from sklearn.metrics import accuracy_score\nprint('Accuracy Score: ',accuracy_score(y_test,predict))\nprint('Using Logistic Regression we get an accuracy score of: ',\n      round(accuracy_score(y_test,predict),5)*100,'%')","758af7fb":"from sklearn.metrics import recall_score,precision_score,classification_report,roc_auc_score,roc_curve\nprint(classification_report(y_test,predict))","497aac60":"cnf_matrix = confusion_matrix(y_test,predict)\ncnf_matrix","5b22cc4b":"class_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Logisitic Regression Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","f4c95d39":"#Get predicted probabilites\ntarget_probailities_log = log_model.predict_proba(X_test)[:,1]","0665eca6":"#Create true and false positive rates\nlog_false_positive_rate,log_true_positive_rate,log_threshold = roc_curve(y_test,\n                                                             target_probailities_log)","30de849e":"#Plot ROC Curve\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.title('Reciver Operating Characterstic Curve')\nplt.plot(log_false_positive_rate,log_true_positive_rate)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.show()","153a2994":"#Calculate area under the curve\nroc_auc_score(y_test,target_probailities_log)","aa6566a5":"from sklearn.tree import DecisionTreeClassifier\ndtree= DecisionTreeClassifier(random_state=7)","0b82bb56":"#Setting parameters for GridSearchCV\nparams = {'max_features': ['auto', 'sqrt', 'log2'],\n          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11]}\ntree_model = GridSearchCV(dtree, param_grid=params, n_jobs=-1)","87e24f06":"tree_model.fit(X_train,y_train)\n#Printing best parameters selected through GridSearchCV\ntree_model.best_params_","5a81f8da":"predict = tree_model.predict(X_test)","c0fb3c66":"from sklearn.metrics import accuracy_score\nprint('Accuracy Score: ',accuracy_score(y_test,predict))\nprint('Using Decision Tree we get an accuracy score of: ',\n      round(accuracy_score(y_test,predict),5)*100,'%')","4af9c0ac":"from sklearn.metrics import classification_report,roc_auc_score,roc_curve","043f87e3":"print(classification_report(y_test,predict))","e44af410":"cnf_matrix = confusion_matrix(y_test,predict)\ncnf_matrix","193c0481":"class_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Decision Tree Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","fb2299f6":"#Get predicted probabilites\ntarget_probailities_tree = tree_model.predict_proba(X_test)[:,1]","06b32205":"#Create true and false positive rates\ntree_false_positive_rate,tree_true_positive_rate,tree_threshold = roc_curve(y_test,\n                                                             target_probailities_tree)","59a112af":"#Plot ROC Curve\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.title('Reciver Operating Characterstic Curve')\nplt.plot(tree_false_positive_rate,tree_true_positive_rate)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.show()","b1e7863d":"#Calculate area under the curve\nroc_auc_score(y_test,target_probailities_tree)","a6dd4efc":"#Plot ROC Curve\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.title('Reciver Operating Characterstic Curve')\nplt.plot(false_positive_rate_knn,true_positive_rate_knn,label='k-Nearest Neighbor')\nplt.plot(log_false_positive_rate,log_true_positive_rate,label='Logistic Regression')\nplt.plot(tree_false_positive_rate,tree_true_positive_rate,label='Decision Tree')\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.legend()\nplt.show()","02c3a02c":"#### **3. trestbps: resting blood pressure (in mm Hg on admission to the hospital)**","396cc446":"**Making predictions**","b5e9b495":"**Implementing GridSearchCv to select best parameters and applying k-NN Algorithm**","a51b1150":"**Classification Report**","3330ab57":"**The features described in the above data set are:**\n\n**1. Count** tells us the number of NoN-empty rows in a feature.<br>\n\n**2. Mean** tells us the mean value of that feature.<br>\n\n**3. Std** tells us the Standard Deviation Value of that feature.<br>\n\n**4. Min** tells us the minimum value of that feature.<br>\n\n**5. 25%**, **50%**, and **75%** are the percentile\/quartile of each features.<br>\n\n**6. Max** tells us the maximum value of that feature.<br>\n","27ecfad7":"**Splitting the dataset into training and test set**","7671dcd4":"#### **4.exang: exercise induced angina (1 = yes; 0 = no)**","6c4fbe8b":"I hope you find this kernel helpful and some **<font color='red'>UPVOTES<\/font>** would be very much appreciated","27d6426d":"#### **1. Sex**","4b1f4935":"**Receiver Operating Characterstic(ROC) Curve**","f93e9b6a":"**Making predictions**","d7eb4613":"### **Loading the data**","055133ef":"**Dimensions of the dataset**","6ebcd912":"### **Checking features of various attributes**","b74807d3":"The dataset contains the following features:<br>\n**1. age(in years)**<br>\n**2. sex:** (1 = male; 0 = female)<br>\n**3. cp:** chest pain type<br>\n**4. trestbps:** resting blood pressure (in mm Hg on admission to the hospital)<br>\n**5. chol:** serum cholestoral in mg\/dl<br>\n**6. fbs:** (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)<br>\n**7. restecg:** resting electrocardiographic results<br>\n**8. thalach:** maximum heart rate achieved<br>\n**9. exang:** exercise induced angina (1 = yes; 0 = no)<br>\n**10. oldpeak**: ST depression induced by exercise relative to rest<br>\n**11. slope:** the slope of the peak exercise ST segment<br>\n**12. ca:** number of major vessels (0-3) colored by flourosopy<br>\n**13. thal:** 3 = normal; 6 = fixed defect; 7 = reversable defect<br>\n**14. target:** 1 or 0 <br>","1c037387":"#### **2.chol: serum cholestoral in mg\/dl **","6ae259d0":"**Checking for null values in the dataset**","a981554b":"#### **2. Chest Pain Type**","f1d9b0a6":"**Making predictions**","981e6d08":"#### **4. Number of people who have heart disease according to age **","ac406b9d":"**Classification report**","e4bc453d":"### **Features of the data set**","1403d26b":"#### **3. fbs: (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)**","399b79ab":"### **Making Predictions**","537af14d":"**Suggestions are welcome**","ca644ed9":"## **3. Decision Tree**","f21bef2b":"## **2. Logistic Regression**","1bc7ab50":"** Comparing ROC Curve of k-Nearest Neighbors, Logistic Regression and Decision Tree**","0b98c1c5":"### **Importing required libraries**","6cf5054d":"#### **1. thalach: maximum heart rate achieved**","eef3b177":"**Confusion Matrix**","6afd36b9":"#### **Plotting the distribution of various attribures**","1bf5b5af":"#### **5.Scatterplot for thalach vs. chol **","6ec48264":"**Preprocessing - Scaling the features**","7cb4285e":"**Confusion Matrix**","e1f5bfbb":"## **1. k-Nearest Neighor Algorithm**","840cf4b2":"**Receiver Operating Characterstic(ROC) Curve**","78581fe7":"**Accuracy Metrics**","49136d4d":"In this kernel I have performed Exploratory Data Analysis on the Heart Diseases UCI and tried to identify relationship between heart disease  and various other features. After EDA data pre-processing is done I have applied k-NN(k-Nearest Neighbors) method and Logistic Regression Algorithm to make the predictions.\nI will use various other algorithms for predictions in future and add them in this kernel.","14c7169b":"There are no null values in the dataset","8f623dbd":"**Confusion Matrix**","3386da11":"**Checking accuracy**","9b9bd52e":"### **Exploratory Data Analysis**","06b13a1b":"#### **1. Heatmap**","3f3b4460":"**Receiver Operating Characterstic(ROC) Curve**","5833a9b0":"**Accuracy Metrics**","f05b6526":"#### **6.Scatterplot for thalach vs. trestbps **"}}