{"cell_type":{"9662b6f7":"code","6fb8bd52":"code","a2c19b2e":"code","3de3a6c7":"code","8c0d9880":"code","6fd91ae0":"code","5dc3e4dd":"code","9813a4ad":"code","5987574b":"code","87963423":"code","5685b806":"code","a263ad74":"code","88a48647":"code","c90f0f92":"code","a2f68f37":"code","79b5d575":"code","aa41f607":"code","4edc0db8":"code","13152391":"code","9b2bb777":"code","411e4626":"code","686c4de7":"markdown"},"source":{"9662b6f7":"!cp -r ..\/input\/mmdetv2\/cocoapi\/cocoapi .\/\n!cp -r ..\/input\/mmdetv2models\/mmdetection\/mmdetection .\/","6fb8bd52":"!cp -r ..\/input\/mmdetv2models\/runtime.txt .\/mmdetection\/requirements","a2c19b2e":"!pip install ..\/input\/mmdetv2\/addict-2.2.1-py3-none-any.whl \n!pip install ..\/input\/mmdetv2\/terminal-0.4.0-py3-none-any.whl\n!pip install ..\/input\/mmdetv2\/pytest_runner-5.2-py2.py3-none-any.whl\n!pip install ..\/input\/mmdetv2\/yapf-0.30.0-py2.py3-none-any.whl","3de3a6c7":"!pip install ..\/input\/mmdetv2models\/mmcv-full-1.0.2\/mmcv-full-1.0.2","8c0d9880":"%cd .\/cocoapi\/pycocotools\n!make > \/dev\/null\n!make install > \/dev\/null\n!python setup.py install > \/dev\/null\nimport pycocotools\n%cd ..\/..","6fd91ae0":"%cd mmdetection\n# ! pip install -r requirements\/build.txt\n! pip install -v -e . > \/dev\/null\n%cd ..\/","5dc3e4dd":"import sys\n# #print(sys.path)\nsys.path.append('mmdetection')\nimport mmcv\nfrom mmcv import Config\nfrom mmcv.runner import load_checkpoint\nfrom mmcv.parallel import MMDataParallel\nfrom mmdet.apis import single_gpu_test\nfrom mmdet.datasets import build_dataloader, build_dataset\nfrom mmdet.apis import init_detector, inference_detector, show_result_pyplot\nfrom mmdet.models import build_detector\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nimport json\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch","9813a4ad":"# !cp -r \/kaggle\/input\/mmdetv2models\/wheat_test_cas.py \/kaggle\/working\/mmdetv2models\/mmdetection\/mmdetection\/configs\/wheat","5987574b":"# !cp -r \/kaggle\/input\/mmdetv2models\/wheat_gfl_no_aug_test.py \/kaggle\/working\/mmdetv2models\/mmdetection\/mmdetection\/configs\/wheat","87963423":"cfg_path = '.\/mmdetection\/configs\/wheat\/wheat_train_cas.py'\ncp_path = '\/kaggle\/input\/mmdetv2models\/resnest-cas-0.5mosaic-e36-ap540.pth'\nimg_list = os.listdir('\/kaggle\/input\/global-wheat-detection\/test')\nmodel_init = init_detector(cfg_path, cp_path, device='cuda:0')\nscore_threshold = 0.3\nfor img in img_list[:10]:\n    # test a single image\n  img_path = '\/kaggle\/input\/global-wheat-detection\/test\/'+img\n  result = inference_detector(model_init,img_path)\n    # show the results\n  show_result_pyplot(model_init, img_path, result, score_thr=score_threshold)\n  final_scores = np.array(result[0][:,4])\n  print(final_scores.shape)\n  print(min(final_scores[final_scores>score_threshold]))","5685b806":"!mkdir -p \/kaggle\/working\/data\/annotations\n!cp -r \/kaggle\/input\/global-wheat-detection\/test .\/data\/test","a263ad74":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n    return \" \".join(pred_strings)\n\n\ndef gen_test_annotation(test_data_path, annotation_path):\n    test_anno_list = []\n    for img in os.listdir(test_data_path):\n        if img.endswith('jpg'):\n            img_info = {}\n            img_info['filename'] = img\n            img_size = Image.open(os.path.join(test_data_path, img)).size\n            img_info['width'] = img_size[0]\n            img_info['height'] = img_size[1]\n            test_anno_list.append(img_info)\n    with open(annotation_path, 'w+') as f:\n        json.dump(test_anno_list, f)","88a48647":"import sys\nsys.path.insert(0, \"\/kaggle\/input\/weightedboxesfusion\")\nfrom ensemble_boxes import *\n\ndef run_wbf(prediction, image_size=1024, iou_thr=0.4, skip_box_thr=0.32, weights=None):\n    boxes = [(prediction[:, :4]\/(image_size-1)).tolist()]\n    scores = [(prediction[:,4]).tolist()]\n    labels = [(np.ones(prediction[:,4].shape[0])).tolist() ]\n#     boxes, scores, labels = nms(boxes, scores, labels, weights=None, iou_thr=iou_thr)\n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    boxes = boxes*(image_size-1)\n    return boxes, scores, labels\n\ndef make_predictions(dataset, outputs):\n    results = []\n    all_boxes = []\n    all_scores = []\n    image_ids = []\n    for images_info, result in zip(dataset.data_infos, outputs):\n        boxes, scores, labels = run_wbf(result[0])\n        boxes = boxes.astype(np.int32).clip(min=0, max=1023)\n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        boxes = boxes[scores >= 0.05].astype(np.int32)\n        scores = scores[scores >=float(0.05)]\n        if len(boxes)>0:\n            result = {\n           'image_id': images_info['filename'][:-4],\n           'PredictionString': format_prediction_string(boxes, scores)}\n        else:\n            result = {\n           'image_id': images_info['filename'][:-4],\n           'PredictionString': ''}\n        results.append(result)\n        all_boxes.append(boxes)\n        all_scores.append(scores)\n        image_ids.append(images_info['filename'])\n        \n        \n    return results, image_ids, all_boxes, all_scores\n        ","c90f0f92":"DIR_INPUT = '.\/data'\nDIR_TEST = f'{DIR_INPUT}\/test\/'\nDIR_ANNO = f'{DIR_INPUT}\/annotations'\n\n# DIR_WEIGHTS = '\/kaggle\/input\/mmdetv2models'\n# WEIGHTS_FILE = f'{DIR_WEIGHTS}\/resnest101-cas-aug-e24-ap47.4.pth'\n\n# test_df = pd.read_csv(f'{DIR_INPUT}\/sample_submission.csv')\n\n# prepare test data annotations\ngen_test_annotation(DIR_TEST, DIR_ANNO + '\/detection_test.json')","a2f68f37":"cfg = Config.fromfile(cfg_path)\n# cfg.dataset_type = 'WheatDatasetTest\ncfg.data.samples_per_gpu = 1\ncfg.data.workers_per_gpu = 1\ncfg.data.test.test_mode = True\n# cfg.test_pipeline[0].flip=False\n# cfg.data.test.ann_file = DIR_ANNO + '\/detection_test.json'\n# cfg.data.test.img_prefix = DIR_TEST\ncfg.model.pretrained = None\ndistributed = False","79b5d575":"dataset = build_dataset(cfg.data.test)\ndata_loader = build_dataloader(\n    dataset,\n    samples_per_gpu=1,\n    workers_per_gpu=1,\n    dist=distributed,\n    shuffle=False)","aa41f607":"device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n\nmodel = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\ncheckpoint = load_checkpoint(model, cp_path, map_location='cpu')\n\nmodel.CLASSES = dataset.CLASSES\n\nmodel = MMDataParallel(model.cuda(0), device_ids=[0])\noutputs = single_gpu_test(model, data_loader)\nresults, image_ids, all_boxes, all_scores = make_predictions(dataset, outputs)","4edc0db8":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])","13152391":"!rm -rf .\/*","9b2bb777":"# save result\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","411e4626":"import cv2\nimport matplotlib.pyplot as plt\ndef draw_rect(img, bboxes, scores,color=None):\n    img = img.copy()\n    bboxes = bboxes[:, :4]\n    bboxes = bboxes.reshape(-1, 4)\n    for bbox,score in zip(bboxes,scores):\n        pt1, pt2 = (bbox[0], bbox[1]), (bbox[2], bbox[3])\n        pt1 = int(pt1[0]), int(pt1[1])\n        pt2 = int(pt2[0]), int(pt2[1])\n        img = cv2.rectangle(img.copy(), pt1, pt2, color, int(max(img.shape[:2]) \/ 200))\n        cv2.putText(img, '%.2f'%(score), pt1, cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 2, cv2.LINE_AA)                 \n    return img\n\n# print(image_ids[0])\n# print(all_boxes[0])\nfig, ax = plt.subplots(10, 1, figsize=(160, 80))\nfor i in range(10):\n    im0 = cv2.imread('\/kaggle\/input\/global-wheat-detection\/test\/'+str(image_ids[i]))[:,:,::-1]\n    box0 = all_boxes[i]\n    box0[:,2] = box0[:,2]+box0[:,0]\n    box0[:,3] = box0[:,1]+box0[:,3]\n    score0 = np.array(all_scores[i])\n    img = draw_rect(im0,np.array(box0),score0, color=(255,0,0))\n    ax[i].imshow(img)","686c4de7":"A simple inference for mmdetv2. I use mosaic,affine,cutout,random hsv etc.,but it seems not work in mmdetv2.Any one feel the same way?"}}