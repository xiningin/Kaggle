{"cell_type":{"2f034edf":"code","b0bca534":"code","5b77737b":"code","f0ef2982":"code","fad6d137":"code","7348cb76":"code","f1766fe5":"code","2c10143d":"code","e9db1146":"code","2fa136be":"code","d81187f2":"code","9f0f3c2d":"code","425df589":"code","b60980ee":"code","9c4c57f6":"code","0b9dfd30":"code","a7beff06":"code","85e80bad":"code","68dd729c":"code","e457fb26":"code","1c5bc9da":"code","8b2fb4af":"code","6410bb7e":"code","4f66d4bb":"code","d5997289":"code","93cc2a9a":"code","9d8254ff":"code","7a27b23b":"code","40adb9ba":"code","8cbdef21":"code","3bfc4d0f":"code","21158de3":"code","73a48996":"code","df7c6441":"code","3d56eccc":"code","7e1b00c7":"code","cf01d10e":"markdown","2e26a1b4":"markdown","927085f3":"markdown","340c8d98":"markdown"},"source":{"2f034edf":"import os\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\nimport sys\nimport copy\nimport random\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt","b0bca534":"data = pd.read_csv('..\/input\/gtzan-dataset-music-genre-classification\/Data\/features_3_sec.csv')\n# we dont't want serial number \ndata = data.iloc[0:, 1:] \ndata.head()","5b77737b":"d = []\nfor i in data[data.columns[58]]:\n    if i == 'blues':\n        d.append(0)\n    if i == 'classical':\n        d.append(1)\n    if i == 'country':\n        d.append(2)\n    if i == 'disco':\n        d.append(3)\n    if i == 'hiphop':\n        d.append(4)\n    if i == 'jazz':\n        d.append(5)\n    if i == 'metal':\n        d.append(6)\n    if i == 'pop':\n        d.append(7)\n    if i == 'reggae':\n        d.append(8)\n    if i == 'rock':\n        d.append(9)","f0ef2982":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2).fit_transform(data.drop(columns= 'label'))\nplt.scatter(tsne[:,0], tsne[:,1],c=d)","fad6d137":"data.describe()","7348cb76":"corr = data.corr()\n# corr = data.corr()\nplt.figure()\nax = sns.heatmap(\n    corr, \n#     vmin=-1, vmax=1, center=0,\n#     cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)","f1766fe5":"data.columns","2c10143d":"features = data.drop(columns= 'label')\n# labels = data[data.columns[58]]\nlabels = pd.DataFrame(d)","e9db1146":"labels = np.array(labels).reshape(9990)\nprint(labels)\nprint(labels.shape)","2fa136be":"min_max_scaler = preprocessing.MinMaxScaler()\nfeatures_scaled = min_max_scaler.fit_transform(features)\n\n# new data frame with the new scaled data. \nfeatures_scaled = pd.DataFrame(features_scaled, columns = features.columns)","d81187f2":"def linear_classification_train(model, features, labels, test_split_size, title = \"Default\"):\n    \"\"\"\n    input :\n    takes scaled features and labels\n    split size for test\n    model\n    \n    output : \n    accuracy after fitting the model and testing on test split\n    \"\"\"\n    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=test_split_size, random_state=42)\n    model.fit(x_train, y_train)\n    preds = model.predict(x_test)\n    print('Accuracy', title, ':', round(accuracy_score(y_test, preds), 4)*100, '\\n')\n    plt.figure()\n#     plt.show(confusion_matrix(y_test, preds))\n    ax = sns.heatmap(\n        confusion_matrix(y_test, preds), \n#         vmin=-1, vmax=1, center=0,\n#         cmap=sns.diverging_palette(20, 220, n=200),\n        square=True,annot = True,\n        cmap=plt.cm.Blues\n    )    ","9f0f3c2d":"model = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\nlinear_classification_train(model, features_scaled, labels, 0.2, \"Logistic Regression\")","425df589":"from sklearn.svm import SVC\nmodel = SVC(C=1.0,kernel='linear',random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM linear kernel\")","b60980ee":"model = SVC(C=1.0,kernel='poly',degree=2,random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly kernel of degree 2\")","9c4c57f6":"model = SVC(C=1.0,kernel='poly',degree=3,random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly kernel of degree 3\")","0b9dfd30":"model = SVC(C=1.0,kernel='poly',degree=4,random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly kernel of degree 4\")","a7beff06":"model = SVC(C=1.0,kernel='poly',degree=5,random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly kernel of degree 5\")","85e80bad":"model = SVC(C=1.0,kernel='poly',degree=6,random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly kernel of degree 6\")","68dd729c":"model = SVC(C=1.0,kernel='poly',degree=7,random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly kernel of degree 7\")","e457fb26":"for i in range(1,3):\n    c=i\n    model = SVC(C=i,kernel='rbf',random_state=0)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=\" + str(c))\n","1c5bc9da":"for i in range(10,101,10):\n    model = SVC(C=i,kernel='rbf',random_state=0)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=\" + str(i))","8b2fb4af":"for i in range(100,1001,100):\n    model = SVC(C=i,kernel='rbf',random_state=0)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=\" + str(i))","6410bb7e":"model = SVC(C=1.0,kernel='sigmoid',random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM sigmoid kernel\")","4f66d4bb":"for i in range(1,11):\n    c = i\/10.0\n    model = SVC(C=c,kernel='poly',degree=6,random_state=0)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly d=6 kernel \" + str(c))","d5997289":"for i in range(1,4):\n    c = i\n    model = SVC(C=c,kernel='poly',degree=6,random_state=0)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM poly deg=6 kernel \" + str(c))","93cc2a9a":"# sgd = SGDClassifier(max_iter=5000, random_state=0, loss = 'log')\n# linear_classification_train(sgd, features_scaled, labels, 0.2, \"SGD Classifier logistic regression\")\n\n# sgd = SGDClassifier(max_iter=5000, random_state=0, loss = 'modified_huber')\n# linear_classification_train(sgd, features_scaled, labels, 0.2, \"SGD Classifier some model\")\n\n# sgd = SGDClassifier(max_iter=50000, random_state=0, loss = 'epsilon_insensitive')\n# linear_classification_train(sgd, features_scaled, labels, 0.2, \"SGD Classifier some other model\")\n\n# # sgd = SGDClassifier(max_iter=50000, random_state=0, loss = 'squared_epsilon_insensitive')\n# # linear_classification_train(sgd, features_scaled, labels, 0.2, \"SGD Classifier ...\")\n\n# sgd = SGDClassifier(max_iter=5000, random_state=0)\n# linear_classification_train(sgd, features_scaled, labels, 0.2, \"SGD Classifier SVM\")","9d8254ff":"# def cluster_train(model, features, labels, test_split_size):\n#     x_train, x_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=test_split_size, random_state=42)\n#     pred = model.fit(x_train)\n    \n#     print(len(pred.labels_))\n#     print(pred.labels_)\n    \n#     pred_labels = [0,0,0,0,0,0,0,0,0,0]\n    \n#     for i in pred.labels_:\n#         pred_labels[i-1] += 1\n        \n#     print(pred_labels)\n#     print(y_train)\n    \n#     print(len(labels))\n#     print('Accuracy of kmeans :', round(accuracy_score(y_train, pred.labels_), 5), '\\n')","7a27b23b":"# model = KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=3000)\n# cluster_train(sgd, features_scaled, labels, 0.2)","40adb9ba":"model = SVC(C=160,kernel='sigmoid',random_state=0,gamma=0.03)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM sigmoid kernel\")","8cbdef21":"# for c in range(10,201,10):\n#     for g in range(1,10):\n#         model = SVC(C=c,kernel='sigmoid',random_state=0,gamma = g\/100)\n#         linear_classification_train(model, features_scaled, labels, 0.2, \"SVM sigmoid kernel c=\" +str(c)+\" gamma=\"+str(g\/100))\n#     for g in range(1,11):\n#         model = SVC(C=c,kernel='sigmoid',random_state=0,gamma = g\/10)\n#         linear_classification_train(model, features_scaled, labels, 0.2, \"SVM sigmoid kernel c=\" +str(c)+\" gamma=\"+str(g\/10))","3bfc4d0f":"for i in range(0,10):\n    labels1=[]\n    fs1=[]\n    #     labels1 = copy.deepcopy(labels)\n    for j in range(len(labels)):\n        if labels[j] == i:\n            fs1.append(features_scaled.iloc[j,:])\n            labels1.append(1)\n        else :\n            k = random.randint(0,10)\n            if k == 1:\n                fs1.append(features_scaled.iloc[j])\n                labels1.append(0)\n    fs1 = pd.DataFrame(fs1)\n    labels1 = np.array(pd.DataFrame(labels1))\n    print(fs1.shape,labels1.shape)\n    model = SVC(C=130,kernel='sigmoid',random_state=0,gamma=0.04)\n    linear_classification_train(model, fs1, labels1, 0.2, \"SVM sigmoid kernel \" + str(i) + \" vs rest\")\n#     break","21158de3":"model = SVC(C=200,kernel='rbf',random_state=0)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=200 \")","73a48996":"for i in range(1,10):\n    model = SVC(C=200,kernel='rbf',random_state=0,gamma=i\/100)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=200 gamma=\" + str(i\/100))\nfor i in range(1,11):\n    model = SVC(C=200,kernel='rbf',random_state=0,gamma=i\/10)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=200 gamma=\" + str(i\/10))","df7c6441":"for i in range(1,11):\n    model = SVC(C=200,kernel='rbf',random_state=0,gamma=i)\n    linear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=200 gamma=\" + str(i))","3d56eccc":"model = SVC(C=200,kernel='rbf',random_state=0,gamma=3)\nlinear_classification_train(model, features_scaled, labels, 0.2, \"SVM rbf kernel c=200 gamma=\" + str(3))","7e1b00c7":"model.get_params(deep = True)","cf01d10e":"Logistic regression  \n\nExperimented with :  \n1. Saga  \n2. Sag  \n3. Newton-cg  \n\nlbfgs gives best accuracy","2e26a1b4":"### NORMALISE","927085f3":"### SPLIT AND TRAIN","340c8d98":"### FEATURES"}}