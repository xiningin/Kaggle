{"cell_type":{"ab758738":"code","1de88fb0":"code","baf1785e":"code","87c16e77":"code","6e99f337":"code","80a20180":"code","18fc26bc":"code","2e62181a":"code","2a314b7a":"code","97b4d347":"code","54fd2add":"code","3932677a":"code","e4bbead1":"code","5af0ff65":"code","efc4d461":"code","23fa3db9":"code","0c5fe660":"code","a4ff705e":"code","f1b7a8b6":"code","cda20afa":"code","486b7734":"code","d3e9bfc3":"code","56a9ffca":"code","bda79f00":"code","c02f509e":"code","e5d126ee":"code","a8183ecd":"code","a14192da":"code","31afb090":"code","5e1e01da":"code","9d6ca57e":"markdown","699b2ac2":"markdown","0f01286e":"markdown","d98d91f4":"markdown","91d97910":"markdown","470b758e":"markdown","2e839999":"markdown","d28c18b9":"markdown","ff0a3f0c":"markdown","9c442726":"markdown","469fd779":"markdown","6ce223a0":"markdown","4d8d930b":"markdown","71de02b8":"markdown","e7490582":"markdown","8b4081c0":"markdown","092a7fa8":"markdown","011d702d":"markdown","2c323a48":"markdown","419d2251":"markdown","0d54d638":"markdown","ef234d6b":"markdown","66278dc5":"markdown","925bef7a":"markdown","1d756f5a":"markdown","3b713ff7":"markdown","af6a8776":"markdown","3905cb85":"markdown","1cdffac7":"markdown","77715f96":"markdown","8d30a9ce":"markdown","a087bc98":"markdown","7f20bfb4":"markdown","d14a6d92":"markdown","8d9b9276":"markdown","ee68c843":"markdown","9bac9d70":"markdown"},"source":{"ab758738":"# Data Manipulation libraries\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\n\nfrom datetime import timedelta\n\n# Data Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","1de88fb0":"# Loading the data\ndata = pd.read_csv(\"..\/input\/ecommerce-data\/data.csv\", encoding=\"unicode_escape\", parse_dates=['InvoiceDate'])\nprint(\"Total number of transactions happened in the given period: \"+ str(data.shape[0]))\ndata.head(5)","baf1785e":"# Checking the data types\ndata.info()","87c16e77":"# Checking for missing Values\npd.DataFrame(zip(data.isnull().sum(), data.isnull().sum()\/len(data)), columns=['count', 'proportion'], index=data.columns)","6e99f337":"# Visualizing the missing values\nmsno.matrix(data)","80a20180":"# Removing null CustomerIDs\nmain = data.copy()\ndata = data[pd.notnull(data['CustomerID'])]","18fc26bc":"# Descriptive Statistics\ndata.describe()","2e62181a":"# Filter for most frequently returned items\nrefunds = data[data['Quantity']<0]\nrefunds = refunds.groupby('Description')['Quantity'].count().sort_values(ascending=False).reset_index()[:10]\n\nplt.figure(figsize=(16,4))\nsns.barplot(x= refunds['Description'], y=refunds['Quantity'])\nplt.title(\"Top 10 more frequently returned items\", size=15)\nplt.xticks(rotation=90)\nplt.xlabel(\" \")\nplt.show()","2a314b7a":"data[data['UnitPrice']>1000].tail(7)","97b4d347":"data = data[~data['Description'].isin(['POSTAGE', 'DOTCOM POSTAGE', 'CRUK Commission', 'Manual'])]\ndata.describe()","54fd2add":"data['TotalSales'] = data['Quantity'].multiply(data['UnitPrice'])\ndata.head()","3932677a":"# Printing the details of the dataset\nmaxdate = data['InvoiceDate'].dt.date.max()\nmindate = data['InvoiceDate'].dt.date.min()\nunique_cust = data['CustomerID'].nunique()\nunique_stocks = data['StockCode'].nunique()\ntot_quantity = data['Quantity'].sum()\ntot_sales = data['TotalSales'].sum()\n\nprint(f\"The Time range of transactions is: {mindate} to {maxdate}\")\nprint(f\"Total number of unique customers: {unique_cust}\")\nprint(f\"Total number of unique stocks: {unique_stocks}\")\nprint(f\"Total Quantity Sold: {tot_quantity}\")\nprint(f\"Total Sales for the period: {tot_sales}\")","e4bbead1":"# The most purchased products from the website\ntop_purchase = data.groupby('Description')['TotalSales'].count().sort_values(ascending=False)[:10]\n\nplt.figure(figsize=(16,4))\nsns.barplot(x=top_purchase.index, y=top_purchase.values)\nplt.xticks(rotation=90)\nplt.title(\"Top 10 Most Purchased Products\", size=15)\nplt.xlabel(\" \")\nplt.show()","5af0ff65":"# Top countries by sales value\ntop_country = data.groupby('Country')['TotalSales'].sum().sort_values(ascending=False)[:10]\n\nlabels = top_country[:5].index\nsize = top_country[:5].values\n\nplt.figure(figsize=(7,7))\nplt.pie(size, labels=labels, explode=[0.05]*5, autopct='%1.0f%%')\nplt.title(\"Top 5 Countries by Total Sales Value\", size=15)\nplt.axis('equal')\nplt.show()","efc4d461":"data['Hour'] = data['InvoiceDate'].dt.hour\ndata['Weekday'] = data['InvoiceDate'].dt.weekday\ndata['Month'] = data['InvoiceDate'].dt.month\ndata.head(3)","23fa3db9":"# Transaction trend in hour of the day\nhour = data.groupby('Hour')['Quantity'].count()\nplt.figure(figsize=(16,4))\nhour.plot(marker='+')\nplt.title(\"Transactions - Hourly\", size=15)\nplt.show()","0c5fe660":"# Transaction trend in day of week\nweekday = data.groupby('Weekday')['Quantity'].count()\nplt.figure(figsize=(16,4))\nweekday.plot(marker='^')\nplt.title(\"Transactions - Day of Week\", size=15)\nplt.show()","a4ff705e":"# Transaction trend across months\nmonth = data.groupby('Month')['Quantity'].count()\nplt.figure(figsize=(16,4))\nmonth.plot(marker='+')\nplt.title(\"Transactions - Monthly\", size=15)\nplt.show()","f1b7a8b6":"def RFM_Features(df, customerID, invoiceDate, transID, sales):\n    ''' Create the Recency, Frequency, and Monetary features from the data '''\n    # Final date in the data + 1 to create latest date\n    latest_date = df[invoiceDate].max() + timedelta(1)\n    \n    # RFM feature creation\n    RFMScores = df.groupby(customerID).agg({invoiceDate: lambda x: (latest_date - x.max()).days, \n                                          transID: lambda x: len(x), \n                                          sales: lambda x: sum(x)})\n    \n    # Converting invoiceDate to int since this contains number of days\n    RFMScores[invoiceDate] = RFMScores[invoiceDate].astype(int)\n    \n    # Renaming column names to Recency, Frequency and Monetary\n    RFMScores.rename(columns={invoiceDate: 'Recency', \n                         transID: 'Frequency', \n                         sales: 'Monetary'}, inplace=True)\n    \n    return RFMScores.reset_index()","cda20afa":"RFM = RFM_Features(df=data, customerID= \"CustomerID\", invoiceDate = \"InvoiceDate\", transID= \"InvoiceNo\", sales=\"TotalSales\")\nRFM.head()","486b7734":"# Descriptive Stats\ndisplay(RFM.describe())\n\n# Distributions of Recency, Frequency, and Monetary features\n# Here we will filter out the extreme values in the Frequency and Monetary columns to avoid the skewness the distribution\nfig, ax = plt.subplots(1,3, figsize=(14,6))\n\nsns.distplot(RFM.Recency, bins=20, ax=ax[0])\nsns.distplot(RFM[RFM['Frequency']<1000]['Frequency'], bins=20, ax=ax[1])\nsns.distplot(RFM[RFM['Monetary']<10000]['Monetary'], bins=20, ax=ax[2])\nplt.show()","d3e9bfc3":"# Creating quantiles \nQuantiles = RFM[['Recency', 'Frequency', 'Monetary']].quantile([0.25, 0.50, 0.75])\nQuantiles = Quantiles.to_dict()\nQuantiles","56a9ffca":"# Creating RFM ranks\ndef RFMRanking(x, variable, quantile_dict):\n    ''' Ranking the Recency, Frequency, and Monetary features based on quantile values '''\n    \n    # checking if the feature to rank is Recency\n    if variable == 'Recency':\n        if x <= quantile_dict[variable][0.25]:\n            return 4\n        elif (x > quantile_dict[variable][0.25]) & (x <= quantile_dict[variable][0.5]):\n            return 3\n        elif (x > quantile_dict[variable][0.5]) & (x <= quantile_dict[variable][0.75]):\n            return 2\n        else:\n            return 1\n    \n    # checking if the feature to rank is Frequency and Monetary\n    if variable in ('Frequency','Monetary'):\n        if x <= quantile_dict[variable][0.25]:\n            return 1\n        elif (x > quantile_dict[variable][0.25]) & (x <= quantile_dict[variable][0.5]):\n            return 2\n        elif (x > quantile_dict[variable][0.5]) & (x <= quantile_dict[variable][0.75]):\n            return 3\n        else:\n            return 4","bda79f00":"RFM['R'] = RFM['Recency'].apply(lambda x: RFMRanking(x, variable='Recency', quantile_dict=Quantiles))\nRFM['F'] = RFM['Frequency'].apply(lambda x: RFMRanking(x, variable='Frequency', quantile_dict=Quantiles))\nRFM['M'] = RFM['Monetary'].apply(lambda x: RFMRanking(x, variable='Monetary', quantile_dict=Quantiles))","c02f509e":"RFM.head()","e5d126ee":"RFM['Group'] = RFM['R'].apply(str) + RFM['F'].apply(str) + RFM['M'].apply(str)\nRFM.head()","a8183ecd":"# Check the number of score segments\nRFM.Group.value_counts()","a14192da":"RFM[\"Score\"] = RFM[['R', 'F', 'M']].sum(axis=1)\nRFM.head()","31afb090":"# Loyalty levels\nloyalty = ['Bronze', 'Silver', 'Gold', 'Platinum']\nRFM['Loyalty_Level'] = pd.qcut(RFM['Score'], q=4, labels= loyalty)\nRFM.head()","5e1e01da":"behaviour = RFM.groupby('Loyalty_Level')[['Recency', 'Frequency', 'Monetary', 'Score']].mean()\nbehaviour","9d6ca57e":"To do the RFM analysis, we need to create 3 features from the data:\n* **Recency**   - Latest date - Last invoice date. (Number of days since the last purchase date)\n* **Frequency** - count of invoice numbers. (Total number of transactions made by a unique customer)\n* **Monetary**  - Sum of Total sales. (Total value of transacted sales by each customer)\n\nNow, let's create a function which can be used to generate the RFM features.","699b2ac2":"**1. Introduction**\n\n**2. Data Preprocessing**\n\n**3. Exploratory Analysis**\n\n**4. RFM Modeling** \n    \n**5. Conclusion**","0f01286e":"The transaction on the website starts to increase around 7 in the morning and peaks at 12PM in the noon. Then the trend slowly decreases and ends at 6PM in the evening. ","d98d91f4":"These are some of the most frequently returned items on the site. \n\nFrom the descriptive statistics, the maximum Quantity bought is 80.9K, but if you check carefully 75% of Quantity values are less than or equal to 10. The large values in Quantity is possible here because the ecommerce platform is for wholesalers.\n\nThe maximum value of UnitPrice is 13.5K but 75% of prices are below 5. Lets explore further the reason for this high values.","91d97910":"In this article, I will guide you through the complete process of RFM modeling and analysis to segment customers based on their transactional behaviour.","470b758e":"RFM stands for Recency, Frequency, and Monetary value, each corresponding to some key customer trait. These RFM metrics are important indicators of a customer\u2019s behavior because frequency and monetary value affects a customer\u2019s lifetime value, and recency affects retention, a measure of engagement.\n\nBusinesses that lack the monetary aspect, like viewership, readership, or surfing-oriented products, could use Engagement parameters instead of Monetary ones. This results in using **RFE** (Recency, Frequency, Engagement) \u2013 a variation of RFM. Further, this Engagement parameter could be defined as a composite value based on metrics such as bounce rate, visit duration, number of pages visited, time spent per page, etc.","2e839999":"Lets calculate the total sales value for each transaction from the quantity and unit price.","d28c18b9":"Before jumping into the Modeling, it is always important and necessary to explore the data. This helps us to understand the data and the business better. \n\nExploratory data analysis helps us to answer questions such as:\n* What are the most purchased products in the platform?\n* People from which country are transacting more?\n* Which hour of the day, day of the week is when the most transactions happen?\n* What is the trend of transactions for the given period?","ff0a3f0c":"From the descriptive statistics, we can see that the Quantity has negative values. This could mean that either the product is returned\/refunded.\n\nLets explore further on this","9c442726":"## Table of Contents:","469fd779":"4. **Bronze:** This is the dormant group with average days since their last purchase is 193. They have transacted around 15 times in the platform with average sales of 245 pounds. \nThese are customers who used to visit and purchase in your platform, but haven\u2019t been visiting recently. Bring them back with relevant promotions, and run surveys to find out what went wrong and avoid losing them to a competitor.","6ce223a0":"People tend to purchase more from Monday to Thursday. Surprisingly, there are no transactions that took place on Saturdays for the given time period in the data.","4d8d930b":"We can now use this score to assign Loyalty level to each customer instead of handling the N^3 rank groups. The Loyalty level will capture different behaviours of the customers and also helps in analyzing and targeting each customer group based on their behaviour.","71de02b8":"RFM features of customers illustrates these characteristics:\n* The more recent they purchase, the more responsive they are to the promotions.\n* The more frequent they purchase, the more engaged and satisfied they are.\n* The more monetary value helps to differentiate high spenders vs low spenders.","e7490582":"The above function can be used to create RFM features for any dataset by specifying the actual names of the respective columns from the dataset you are working on.\n\nLet's explore some descriptive statistics of the new features.","8b4081c0":"Happy Learning!!","092a7fa8":"## 4. RFM Modeling","011d702d":"There seems to be missing values in the Description and CustomerID column. \n\nSince our analysis objective is to identify customer groups, the column CustomerID is should contain unique identifiers for customers. Hence, we can drop the NA values since the data without CustomerID is not much helpful for our task.\n","2c323a48":"In this article, we are going to work with the online-retail dataset from UCI Machine Learning repository.\n\n**Dataset Information:**\n\nThis is a transnational data set which contains all the transactions occurring between 01\/12\/2010 and 09\/12\/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\n**Attribute Information:**\n\n* *InvoiceNo*: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n\n* *StockCode*: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n\n* *Description*: Product (item) name. Nominal.\n\n* *Quantity*: The quantities of each product (item) per transaction. Numeric.\n\n* *InvoiceDate*: Invoice Date and time. Numeric, the day and time when each transaction was generated.\n\n* *UnitPrice*: Unit price. Numeric, Product price per unit in sterling.\n\n* *CustomerID*: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n\n* *Country*: Country name. Nominal, the name of the country where each customer resides.","419d2251":"# Marketing Analytics: RFM Modeling","0d54d638":"## 2. Data Preprocessing","ef234d6b":"We have calculated the ranks for each individual attribute of RFM at the customer level. We can use this to find the total number of rank groups that are created based on our ranking scale. \n\nTo do this you can simply combine all the individual R, F, and M ranks to check how many groups are created and the share of customers in each segment.\n\nFor our case, the maximum number of groups should be 4^3 = 64. Lets, check if it is true.","66278dc5":"## 1. Introduction   ","925bef7a":"To conduct RFM analysis, we need to rank the customers based on each RFM attribute separately.\n\nAssume that we rank these customers from 1-4 using RFM values. (1-low score & 4-High score)\n\n**Steps to be followed for RFM ranking:**\n1. Sort the Recency column by **most recent purchases at the top.** For Frequency and Monetary features sort it by the **most frequent** and **most valuable** purchases at the top.\n2. If you are using N-scale ranking to rank the customers then you have to divide the sorted values of the features into 1\/N groups. Here, we are using 4-scale ranking hence we need to divide the values into 4 groups.\n\nwe can do both the sorting and grouping using pandas **df.quantile** method by providing the number of quantiles as a list.\n\n\n","1d756f5a":"## 5. Conclusion","3b713ff7":"There are some odd descriptions like Manual, POSTAGE, DOTCOM POSTAGE, CRUK Commission, and Discount. Let us check what does these mean:\n* POSTAGE\/DOTCOM POSTAGE: The amount spent by the user on postages.\n* CRUK Commission: An initiative to pay some part of the sales to the Cancer Research UK (CRUK).\n* Manual: Since there is no proper definition we can think of this as manual service provided for the purchase of an item.\n* Discount: This explains the discount provided for a product.\n\nExcept for Discount, all the other categories do not directly affect the sales. Hence, we can remove those from the data.","af6a8776":"Monthly trend reveals that the number of people using the platform is showing an increasing trend. Further, the rate of increase stayed flat till August 2011 and rapidly increasing from September 2011. \n\nThe sudden dip in the month of December is because we have only data till December 9th.","3905cb85":"We have successfully grouped 62 segments based on individual R, F, M scores into 4 broad loyalty levels. Let's explore the characteristics of each loyalty levels.\n\n**Customer Behaviour and potential targeting techniques for each Loyalty Level:**\n1. **Platinum:** People in this group are more frequent buyers with average days since the last purchase is 13 and average number of times they have transacted in the platform is about 292 times in the last 1 year. Also, their average sales value is 6.5K pounds.\nThese are your most loyal customers, who bought recently, most often, and are heavy spenders. Reward these customers so that they can become an early adopters for your future products and help to promote your brand.","1cdffac7":"Now we will explore on how transaction trend is changing within a day, week and across months.\n\nTo analyze this, we need to create new features from the InvoiceDate column - which denotes the date and time each transaction takes place.","77715f96":"Note that the total rank groups created is 62 and this makes sense because the maximum number of groups based on our ranking scale is 64.\n\nThe reason for getting 62 instead of 64 rank groups is because there might be some missing combinations in the ranks of R, F, and M.\n\nFinally, we can create a composite score for these customers by combining their individual R, F, and M ranks to arrive at an aggregated RFM score. This RFM score, displayed in the table below, is simply the average of the individual R, F, and M ranks, obtained by giving equal weights to each RFM attribute.","8d30a9ce":"## 3. Exploratory Analysis","a087bc98":"  When it comes to marketing, if you're trying to talk to everybody, you\u2019re going to have a difficult time reaching anybody. Vague and generic messages are far less likely to resonate with audiences than specific, direct communication \u2013 which is why targeting in marketing is so important.\nSmart marketers understand the importance of \"know thy customer\". Instead of simply focusing on generating more clicks, marketers must follow the paradigm shift from increased CTRs (Click-Through Rates) to retention, loyalty, and building customer relationships.\n\nInstead of analyzing the entire customer base as a whole, it's better to segment them into homogeneous groups, understand the traits\/behaviour of each group, and engage them with relevant targeted campaigns. \n\nOne of the most popular, easy-to-use, and effective segmentation methods which enable marketers to analyze the customer behavior is RFM analysis.","7f20bfb4":"3. **Silver:** People in this group have made a transaction on the platform about 87 days ago. Their frequency and monetary values are 34 times and 644 pounds respectively.\nThese are your customers who purchased a decent number of times and spent good amounts, but haven\u2019t purchased recently. Sending them personalized campaigns, offers, and product recommendations will help to reconnect with them.","d14a6d92":"The Primary step in any modeling\/analysis is the data preprocessing.\n\nTo do the analysis, we need the data. I have already downloaded the data from the UCI Machine Learning repository and saved in my local direcotry. Here is the link for the dataset https:\/\/archive.ics.uci.edu\/ml\/datasets\/online+retail#.\n\nFirst import all the necessary libraries and load the data.","8d9b9276":"RFM is a data-driven customer segmentation technique that allows marketers to make informed decisions. It empowers marketers to quickly identify and segment users into homogeneous groups and target them with differentiated and personalized marketing strategies. This in turn improves user engagement and retention.\n\nI have used equal weightage scheme for each RFM variables in this analysis. But depending on the nature of your businesses, you can increase or decrease the relative importance of each RFM variable to arrive at the final score. For example:\n\n* In a *consumer durables* business, the monetary value per transaction is normally high but frequency and recency is low. For example, you can\u2019t expect a customer to purchase a refrigerator or air conditioner on a monthly basis. In this case, a marketer could give more weight to monetary and recency aspects rather than the frequency aspect.\n\n* In a *retail* business, customers purchase products every month or every week, so they will have a higher recency and frequency score than monetary score. Accordingly, the RFM score could be calculated by giving more weight to R and F scores than M.\n\n* For *streaming* business like Hotstar or Netflix, a binge watcher will have a longer session length than a mainstream consumer watching at regular intervals. For bingers, engagement and frequency could be given more importance than recency, and for mainstreamers, recency and frequency can be given higher weights than engagement to arrive at the RFE score.\n\nThanks for reading this far. I hope this article helps you to understand the concept and process behind creating the RFM Model. You can follow these steps to create your own RFM model to segment customers.","ee68c843":"2. **Gold:** This group has an average frequency of 83 times and recency of 46 days. This group is also high spenders with average sales of about 1.3K pounds. \n These are your recent customers with an average frequency and who spent a good amount. Offer membership or loyalty programs or recommend related products to upsell them and help them become your Platinum members.","9bac9d70":"\n**NOTE:** The value of N decides the number of different RFM rank groups you want to create. All possible combination of ranks from 1-N for all the three RFM features results in N^3 rank groups ranging from 111(lowest) to NNN(highest).\n\nIn our case N=4, hence we could have a maximum of 4^3 = 64 rank groups with scores from 111 to 444."}}