{"cell_type":{"ab1375cc":"code","ec32e613":"code","dd60ffd9":"code","4e964c38":"code","92061e54":"code","ed773c2b":"code","e2a00f06":"code","e420c171":"code","d8c9db6b":"code","f9033f9d":"code","dc4886e0":"code","53f2611b":"code","241f3c50":"code","6a6b27b2":"code","0d092d26":"code","45e79b12":"code","2e915e74":"code","f03ee4f9":"code","e58161eb":"code","e7e65aa7":"code","1898306e":"code","3c63d9a6":"code","20843764":"code","f9a06d05":"code","86470360":"code","2e9027d0":"markdown","30b92a48":"markdown","69b0ab25":"markdown","5ad9545a":"markdown","db9bd59a":"markdown","d88164a9":"markdown","3a8c33ca":"markdown","6294f9a0":"markdown","121b1316":"markdown","76620506":"markdown"},"source":{"ab1375cc":"import numpy as np\nimport pandas as pd\n\nimport re\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression","ec32e613":"one_star_df = pd.read_csv('..\/input\/michelin-restaurants\/one-star-michelin-restaurants.csv')\ntwo_star_df = pd.read_csv('..\/input\/michelin-restaurants\/two-stars-michelin-restaurants.csv')\nthree_star_df = pd.read_csv('..\/input\/michelin-restaurants\/three-stars-michelin-restaurants.csv')","dd60ffd9":"one_star_df.head()","4e964c38":"two_star_df.head()","92061e54":"three_star_df.head()","ed773c2b":"one_star_df['stars'] = pd.Series(0, index=one_star_df.index)\ntwo_star_df['stars'] = pd.Series(1, index=two_star_df.index)\nthree_star_df['stars'] = pd.Series(2, index=three_star_df.index)\n\ncombined_df = pd.concat([one_star_df, two_star_df, three_star_df], axis=0).sample(frac=1.0).reset_index(drop=True)","e2a00f06":"combined_df","e420c171":"y = combined_df['stars'].copy()\nX = combined_df.drop('stars', axis=1)","d8c9db6b":"X = X.drop(['name', 'zipCode', 'url'], axis=1)","f9033f9d":"X","dc4886e0":"X.isna().sum()","53f2611b":"X['price'].value_counts()","241f3c50":"X['price'] = X['price'].fillna(X['price'].mode().values[0])","6a6b27b2":"X.isna().sum()","0d092d26":"{column: list(X[column].unique()) for column in X.columns if X.dtypes[column] == 'object'}","45e79b12":"price_ordering = ['$', '$$', '$$$', '$$$$', '$$$$$']\n\nX['price'] = X['price'].apply(lambda price: price_ordering.index(price))","2e915e74":"X","f03ee4f9":"# Removing zip codes from city column\nX['city'] = X['city'].apply(lambda city: re.sub(r' - \\d+$', '', city) if str(city) != 'nan' else city)","e58161eb":"def onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","e7e65aa7":"X = onehot_encode(\n    X,\n    ['city', 'region', 'cuisine'],\n    ['CI', 'RE', 'CU']\n)","1898306e":"X","3c63d9a6":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","20843764":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=40)","f9a06d05":"models = []\nCs = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n\nfor i in range(len(Cs)):\n    model = LogisticRegression(C=Cs[i])\n    model.fit(X_train, y_train)\n    models.append(model)","86470360":"model_acc = [model.score(X_test, y_test) for model in models]\n\nprint(f\"Model Accuracy (C={Cs[0]}):\", model_acc[0])\nprint(f\" Model Accuracy (C={Cs[1]}):\", model_acc[1])\nprint(f\"  Model Accuracy (C={Cs[2]}):\", model_acc[2])\nprint(f\"   Model Accuracy (C={Cs[3]}):\", model_acc[3])\nprint(f\"   Model Accuracy (C={Cs[4]}):\", model_acc[4])\nprint(f\"  Model Accuracy (C={Cs[5]}):\", model_acc[3])\nprint(f\" Model Accuracy (C={Cs[6]}):\", model_acc[4])","2e9027d0":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/Nm8FO8_yHUI","30b92a48":"# Task for Today  \n\n***\n\n## Michelin Restaurant Star Prediction  \n\nGiven *data about Michelin starred restaurants*, let's try to predict the **number of stars** of a given restaurant.  \n  \nWe will use a logistic regression model to make our predictions.","69b0ab25":"## Missing Values","5ad9545a":"## Scaling\/Splitting","db9bd59a":"## Encoding","d88164a9":"# Results","3a8c33ca":"# Preprocessing","6294f9a0":"## Unneeded Columns","121b1316":"# Getting Started","76620506":"# Training"}}