{"cell_type":{"62c025ec":"code","ec4442bd":"code","13e68627":"code","faa81270":"code","10774628":"code","320fff0d":"code","f0624b07":"code","cad009a3":"code","bad23bca":"code","11bd6106":"code","e3ffe485":"code","4b5a1ddf":"code","99a14e47":"code","47919b99":"code","eefada62":"code","ff48e59f":"code","12429a65":"code","a7b6d050":"markdown","486d21c2":"markdown","1fc569e2":"markdown","c4de0a91":"markdown","4e6055f4":"markdown","5e3664f4":"markdown","e107b5bb":"markdown","774c84e3":"markdown","800d4095":"markdown","44c278ab":"markdown","c441236d":"markdown","9563fca5":"markdown","93480a49":"markdown","a2e636eb":"markdown"},"source":{"62c025ec":"import numpy as np\nimport mxnet as mx \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nfrom IPython.display import clear_output\nprint(os.listdir(\"..\/input\"))\nprint(mx.test_utils.list_gpus())\n\n# Any results you write to the current directory are saved as output.","ec4442bd":"train_data_ = pd.read_csv('..\/input\/mnist_train.csv')\ntest_data_ = pd.read_csv('..\/input\/mnist_test.csv')","13e68627":"print(train_data_.head())","faa81270":"train_label = train_data_['label']\ntest_label = test_data_['label']\ntrain_data = train_data_.drop(columns='label').values\ntest_data = test_data_.drop(columns='label').values\ntrain_data = np.concatenate((train_data,test_data),axis = 0)\ntrain_label = np.concatenate((train_label, test_label),axis =0)\ntrain_data = mx.nd.array(train_data)\nprint(train_data.shape)","10774628":"def get_image(mat):\n    mat = mat.reshape((28,28))\/255.0\n    print(mat.shape)\n    plt.imshow(mat.asnumpy(),cmap = 'gray')\n    plt.show\n    \ndef get_sturctured_images(data):\n    # convert to batch_size X width X height form\n    data = data.reshape((-1,28,28))\n    return (data\/255.0)\n\n# plot the image at this index:\nidx = 4\nget_image(train_data[idx])\ntrain_data = get_sturctured_images(train_data)\n    ","320fff0d":"def concat_img_label(imgs, labels):\n    '''\n    concatenates 28X28 images with their suitably represented labels\n    '''\n    imgs = imgs.as_in_context(ctx).reshape((-1,1,28,28))\n    labels = mx.ndarray.one_hot(mx.nd.array(labels),10).expand_dims(axis=2)\n    labels = labels.broadcast_to((labels.shape[0],10,10))\n    labels = np.tile(labels.asnumpy(), reps=(1,2,2))\n    labels = np.pad(labels, mode='constant',constant_values = 0.,pad_width=((0,0),(4,4),(4,4)))\n    img_label = mx.ndarray.concat(imgs, mx.nd.array(labels).as_in_context(ctx).expand_dims(axis=1) , dim =1)  # along the 'channel dimension' in NCHW format\n    return [img_label]","f0624b07":"class GenInputIter(mx.io.DataIter):\n    def __init__(self, batch_size, dim_x, dim_y):\n        self.batch_size = batch_size\n        self.ndim = (dim_x,dim_y)\n        self.provide_data = [('rand_label', (batch_size, 2, dim_x, dim_y))]\n        self.provide_label = [('labels',(batch_size,))]\n    def iter_next(self):\n        return True\n    def __iter__(self):\n        return self\n    def __next__(self):\n        return self.next()\n    def reset(self):\n        self.current_batch = 0\n    def next(self):\n        # NOTE: make sure batch_size divides total sample size. Else, make changes in slicing op.\n        labels = mx.ndarray.random.randint(0,10,shape=(batch_size,))\n        rand = mx.random.normal(0, 1.0, shape=(self.batch_size ,\n                                               1, self.ndim[0], self.ndim[1]))\n        gen_label = mx.ndarray.one_hot(mx.nd.array(labels),10).expand_dims(axis=2)\n        gen_label = gen_label.broadcast_to((self.batch_size,\n                                            self.ndim[0], self.ndim[1])).expand_dims(axis=1)\n        gen_label_batch = mx.ndarray.concat(rand, gen_label, dim =1)  # along the 'channel dimension' in NCHW format\n        data = [gen_label_batch.as_in_context(ctx)]\n        label = [labels.as_in_context(ctx)]\n        # to visualize the 2 channels:\n#         fig,(ax1,ax2) = plt.subplots(1,2,figsize=(8,4))\n#         ax1.imshow(rand[0].asnumpy().reshape(10,10),cmap='gray')\n#         ax2.imshow(gen_label[0].asnumpy().reshape(10,10),cmap='gray')\n#         ax1.title.set_text('Noise(Ch.1)')\n#         ax2.title.set_text('Label Encoding(Ch.2), (label = '+str(label[0][0].asnumpy())+' )')\n#         plt.show()\n        return mx.io.DataBatch(data),label","cad009a3":"class DiscInputIter(mx.io.DataIter):\n    def __init__(self, batch_size, data, label):\n        assert batch_size<=data.shape[0], 'Batch size exceeds input'\n        self.batch_size = batch_size\n        self.ndim = 28\n        self.provide_data = [('data', (batch_size, 2, 28, 28))]\n        self.provide_label = []\n        self.current_batch = 0\n        self.data = concat_img_label(data,label)[0]\n        \n    def iter_next(self):\n        return True\n    def reset(self):\n        self.current_batch = 0\n    def next(self):#getdata\n        #Returns images: batch_sizeX28X28 ...\n        # ... concatenated to the label\n        # NOTE: make sure batch_size divides total sample size. Else, make changes in slicing op.\n        if self.current_batch + batch_size >= self.data.shape[0]:\n            raise StopIteration\n        else:\n            img_label_batch = self.data[self.current_batch:self.current_batch+batch_size]\n            self.current_batch = (self.current_batch+batch_size)%(self.data.shape[0])\n            return mx.io.DataBatch([img_label_batch])","bad23bca":"def render(wait_at_sample=True,plot_binarized=False, text=None, animate_frames=None):\n    # do a conditional forward-pass on Generator and view result\n    labels = range(10)\n    labels = mx.ndarray.one_hot(mx.nd.array(labels),10).expand_dims(axis=2)\n    rand = mx.random.normal(0, 1.0, shape=(10 , 1, 10,10))\n    gen_label_batch = labels.broadcast_to((10, 10,10)).expand_dims(axis =1)\n    gen_label_batch = mx.ndarray.concat(rand, gen_label_batch , dim =1)  # along the 'channel dimension' in NCHW format\n    generator.forward(mx.io.DataBatch([gen_label_batch]),is_train=False)\n    outG = generator.get_outputs()[0]\n        \n    # now, plot these:\n    w=15\n    h=5\n    fig=plt.figure(figsize=(8, 4))\n    columns = 5\n    rows = 2\n    thresh = 0.7\n    for i in range(1, columns*rows +1):\n        ax = fig.add_subplot(rows, columns, i,label=str(i))\n        ax.title.set_text(str(i-1))\n        img = outG[i-1].asnumpy().reshape((28,28))\n        if plot_binarized:\n            img[img<thresh]=0.\n            img[img>=thresh]=1.\n        im = plt.imshow(img,cmap='gray')\n        plt.axis('off')\n    plt.suptitle(text)\n\n    if animate_frames is not None:\n        fig.canvas.draw()       # draw the canvas, cache the renderer\n        image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n        image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n        animate_frames.append(image)\n    if wait_at_sample:\n        plt.show()\n        input()\n    else:\n        plt.close(fig)    # close the figure\n    if animate_frames:\n        return animate_frames","11bd6106":"# The model specifics\nctx = mx.gpu(0)\n#Hyper-parameters\nsigma = 0.02\nlr_gen = 0.001#0.001\nlr_disc = 0.001\nbeta1 = 0.7#0.9\nbeta2 = 0.4#0.7\nbatch_size = 20  # keep this st. it divides the total no. of samples : 70k","e3ffe485":"# The Generator Module\ndef gen_module():\n    # just create the generator module and return it\n    # it would generate an image from some random number\n    fix_gamma = False\n    epsilon = 1e-5 + 1e-12\n    \n    rand_label = mx.sym.Variable('rand_label')\n    # gen_label = mx.sym.Variable('gen_label')\n    # convert the label to 10 X 10 matrix and concatenate as the second channel to random matrix\n    # input: 10 X 10 X 2 for each image\n    \n    g1 = mx.sym.Deconvolution(rand_label, name='g1', kernel=(5,5), num_filter=256)\n    gbn1 = mx.sym.BatchNorm(g1, name='gbn1', fix_gamma=fix_gamma, eps=epsilon)\n    gact1 = mx.sym.Activation(gbn1, name='gact1', act_type='relu')\n    # ---> 14 X 14 X 256 (each)\n    \n    g2 = mx.sym.Deconvolution(gact1, name='g2', kernel=(5,5), num_filter=256)#7\n    gbn2 = mx.sym.BatchNorm(g2, name='gbn2', fix_gamma=fix_gamma, eps=epsilon)\n    gact2 = mx.sym.Activation(gbn2, name='gact2', act_type='relu')\n    # ---> 18 X 18 X 256 (each)\n    \n    g3 = mx.sym.Deconvolution(gact2, name='g3', kernel=(5,5), num_filter=256)#9\n    gbn3 = mx.sym.BatchNorm(g3, name='gbn3', fix_gamma=fix_gamma, eps=epsilon)\n    gact3 = mx.sym.Activation(gbn3, name='gact3', act_type='relu')\n    # ---> 22 X 22 X 256\n    \n    g4 = mx.sym.Deconvolution(gact3, name='g4', kernel=(7,7), num_filter=1)\n    gbn4 = mx.sym.BatchNorm(g4, name='gbn4', fix_gamma=fix_gamma, eps=epsilon)\n    gact4= mx.sym.Activation(gbn4, name='gact4', act_type='sigmoid')\n    # ---> 28 X 28 X 1 (each)\n    \n    # using sigmoid here as our images are normalized between [0,1]\n    generatorSymbol = gact4\n    return generatorSymbol","4b5a1ddf":"# The discriminator module:\ndef discr_module():\n    fix_gamma = True\n    epsilon = 1e-5 + 1e-12\n    # creat the discriminator\n    type_label = mx.sym.Variable('type_var')    # Y\/N (1\/0): whether this is a fake or a real image of the above type\n    data = mx.sym.Variable('data')              # input is similar to that to generator : image concatenated to label\n    # input: 28 X 28 X 2 for each\n    \n    d1 = mx.sym.Convolution(data, name='d1', kernel=(9,9), num_filter=128)#9\n    dbn1 = mx.sym.BatchNorm(d1, name='dbn1', fix_gamma=fix_gamma, eps=epsilon)\n    dact1 = mx.sym.LeakyReLU(dbn1, name='dact1', act_type='leaky', slope=0.2)\n    # ---> 20 X 20 X 128 (each)\n    \n    d2 = mx.sym.Convolution(dact1, name='d2', kernel=(7,7), num_filter=128)#7\n    dbn2 = mx.sym.BatchNorm(d2, name='dbn2', fix_gamma=fix_gamma, eps=epsilon)\n    dact2 = mx.sym.LeakyReLU(dbn2, name='dact2', act_type='leaky', slope=0.2)\n    # ---> 14 X 14 X 128 (each)\n    \n    d3 = mx.sym.Convolution(dact2, name='d3', kernel=(5,5), num_filter=128)\n    dbn3 = mx.sym.BatchNorm(d3, name='dbn3', fix_gamma=fix_gamma, eps=epsilon)\n    dact3 = mx.sym.LeakyReLU(dbn3, name='dact3', act_type='leaky', slope=0.2)\n    # ---> 10 X 10 X 2 (each)\n    \n#     d4 = mx.sym.Convolution(dact3, name='d4', kernel=(5,5), num_filter=2)\n#     dbn4 = mx.sym.BatchNorm(d4, name='dbn4', fix_gamma=fix_gamma, eps=epsilon)\n#     dact4 = mx.sym.LeakyReLU(dbn4, name='dact', act_type='leaky', slope=0.2)\n#     # output: 10 X 10 X 2 (each)\n    \n    d5 = mx.sym.Flatten(dact3, name = 'd5')\n    fc1 = mx.sym.FullyConnected(d5, name = 'fc1', num_hidden = 100)\n    fbn1 = mx.sym.BatchNorm(fc1,name='fbn1',fix_gamma=fix_gamma, eps=epsilon)\n    fact1 = mx.sym.Activation(data=fbn1, act_type='relu', name='fcact1')\n    fc2 = mx.sym.FullyConnected(fact1, name = 'fc2', num_hidden = 1)\n    \n    discriminatorSymbol = mx.sym.LogisticRegressionOutput(data=fc2, label=type_label, name='dloss')\n    return discriminatorSymbol\n    ","99a14e47":"#=============Generator Module=============\nrand_iter = GenInputIter(batch_size, 10,10)\ngenerator = mx.mod.Module(symbol=gen_module(), data_names=('rand_label',), label_names=None, context=ctx)\ngenerator.bind(data_shapes=rand_iter.provide_data)\ngenerator.init_params(initializer=mx.init.Normal(sigma))\ngenerator.init_optimizer(\n    optimizer='adam',\n    optimizer_params={\n        'learning_rate': lr_gen,\n        'beta1': beta1,\n        'beta2' : beta2,\n    })\n# =============Discriminator Module=============\nimage_iter = DiscInputIter(batch_size,train_data,train_label)\ndiscriminator = mx.mod.Module(symbol=discr_module(), data_names=('data',), label_names=('type_var',), context=ctx)\ndiscriminator.bind(data_shapes=image_iter.provide_data,\n                label_shapes=[('type_var', (batch_size,))],\n                inputs_need_grad=True)\ndiscriminator.init_params(initializer=mx.init.Normal(sigma))\ndiscriminator.init_optimizer(\n    optimizer='adam',\n    optimizer_params={\n        'learning_rate': lr_disc,\n        'beta1': beta1,\n        'beta2' : beta2,\n    })","47919b99":"frames=[]\nprint('Training...')\nfor epoch in range(2):\n    image_iter.reset()\n    rand_iter.reset()\n    for i, batch in enumerate(image_iter):\n        \n        # --------------------------  Step 1  -------------------------- #  \n        fake_batch,label_batch = rand_iter.next()\n        # Forward pass on fake batch over the generator\n        generator.forward(fake_batch, is_train=True)\n        # Output of training batch is the 28X28X1 images\n        outG = generator.get_outputs()\n        \n        # --------------------------  Step 2  -------------------------- #\n        # Pass the generated (fake) image through the discriminator, and save the gradient\n        # Label (for outer-most 1-neuron layer) is an array of 0's since this image is fake\n        label = mx.nd.zeros((batch_size,), ctx=ctx)\n        \n        # Forward pass on the discriminator\n        discriminator.forward(mx.io.DataBatch(concat_img_label(outG[0],label_batch[0]), [label]), is_train=True)\n        \n        # Do the backward pass and save the gradient\n        discriminator.backward()\n        gradD = [[grad.copyto(grad.context) for grad in grads] for grads in discriminator._exec_group.grad_arrays]\n        \n        \n        # --------------------------  Step 3  -------------------------- #\n        # Pass a batch of real images from MNIST through the discriminator\n        # Set the label to be an array of 1's because these are the real images\n        label[:] = 1\n        batch.label = [label]\n        # Forward pass on a batch of MNIST images\n        discriminator.forward(batch, is_train=True)\n        # Do the backward pass and add the saved gradient from the fake images to the gradient\n        # generated by this backwards pass on the real images\n\n        discriminator.backward()\n        \n        # --------------------------  Step 4  -------------------------- #\n        for gradsr, gradsf in zip(discriminator._exec_group.grad_arrays, gradD):\n            for gradr, gradf in zip(gradsr, gradsf):\n                gradr += gradf\n        # Update gradient of the discriminator\n        discriminator.update()\n        \n        \n        # --------------------------  Step 5  -------------------------- #\n        # First do a forward pass and backwards pass on the newly updated discriminator\n        discriminator.forward(mx.io.DataBatch(concat_img_label(outG[0],label_batch[0]), [label]), is_train=True)\n        discriminator.backward()\n        # DO NOT UPDATE THE DISCRIMINATOR THIS TIME- we only need the gradients for generator's parameters here\n        # NOTICE that even though we are doing a forward pass on fake images, we keep labels as 1 - \n        # to activate only first term of Cross-Entropy loss.\n        # Get the input gradient from the backwards pass on the discriminator, and use it to do the\n        # backwards pass on the generator\n        diffD = discriminator.get_input_grads()\n        \n        # --------------------------  Step 6  -------------------------- #\n        generator.backward([diffD[0].split(axis=1,num_outputs=2)[0]])\n        #Update the gradients on the generator\n        generator.update()\n\n        # --------------------------Visualization-------------------------- #\n        i += 1\n        if i % 100 == 0:\n            plot_text = 'Epoch: '+str(epoch)+'; Batch: '+str(i)\n            clear_output()\n            #print('epoch:', epoch,'\\titer:',i)\n            frames=render(wait_at_sample=False,text=plot_text,animate_frames=frames)\n        ","eefada62":"generator.save_params('gen')\ndiscriminator.save_params('disc')","ff48e59f":"from IPython.display import HTML\nimport matplotlib.animation as animation\nfig=plt.figure(figsize=(12, 6))\nim = plt.imshow(frames[0], animated=True)\nidx=0\ndef update_fn(img):\n    im.set_array(img)\n    return im,\nani = animation.FuncAnimation(fig,update_fn, frames=frames, repeat=False)\nHTML(ani.to_jshtml())","12429a65":"ani.save('animation2.gif', writer='imagemagick')","a7b6d050":"### Binding the modules to Iterators & Optimizers","486d21c2":"## The model hyper-parameters","1fc569e2":"- **For Discriminator**: (creates a set of real images in NCHW format; 2nd channel being label encodings)\n    - The function *concat_img_label()* handles this.\n    - Convert labels into one-hot encoding : --> (batch_size, 10 )\n    - Broadcast to (batch_size X 10 X 10 shape) --> (batch_size, 10, 10)\n    - Tile along each axes --> (batch_size, 20, 20)\n    - Pad four 0's on each side along both axes --> (batch_size, 28, 28)\n    - Add another dimension for channel: --> (batch_size, 1, 28, 28)\n    - Take a batch of real MNIST images --> (batch_size, 1, 28, 28)\n    - Concatenate the label encodings with images: --> (batch_size, 2, 28, 28)","c4de0a91":"# Conditional Deep Convolutional GAN using MXNet\n**For detailed explanation, refer my article [here](https:\/\/medium.com\/@suyashdamle\/nuts-and-bolts-of-conditional-deep-convolutional-gans-58f6b9b8106a).**\n\n***","4e6055f4":"***\n## Final Training Loop\n### Steps of Training:\n- Step 1: Generate a set of fake images using the generator\n- Step 2: Do forward and backward pass on the discriminator using the **fake images** and labels = 0 for all images. Collect gradients  ---> grads_1\n- Step 3: Do forward and backward pass on discriminator using **real images** with labels =1 for all images. Collect gradients ---> grads_2\n- Step 4: Update the discriminator with **grad_1 + grad_2**\n- Step 5: Do a forward pass on updated discriminator using **fake images** and **labels = 1** for all images. This is inorder to ensure that we use the modified version of the loss function for generator update - the loss function for generator is therefore $$-\\:(Pr(z) . log(D(G(z)))$$ . Get the **input gradients** of the discriminator\n- Step 6: Use these gradients to backpropagate error to the generator","5e3664f4":"## Figuring out the data format and making it usable","e107b5bb":"### Function for concatenating images with label-representations appropriately","774c84e3":"## Viewing the generated frames as an animation","800d4095":"After a lot of haggling with the hyper-parameters, I finally got seemingly right parameters. This image was certainly the high-point.  :)\n\nAfter about 3000 iterations:\n![image.png](attachment:image.png)","44c278ab":"### Trying to recreate the images","c441236d":"### A function to visualize our generator's outputs periodically","9563fca5":"### The custom image\/random sample iterators for generator and discriminator\n- **For generator**: (creates set of fake images in NCHW format ; 2nd channel being label encodings)\n    - Generate random integers between 0 and 9 (of 1 X batch_size shape). These would be our labels for fake images\n    - Convert these into one-hot encoding : --> (batch_size, 10 )\n    - Broadcast to (batch_size X 10 X 10 shape) --> (batch_size, 10, 10)\n    - Add another dimension for channel: --> (batch_size, 1, 10, 10)\n    - Generate a 10X10 noise matrix using mx.random.normal() --> (batch_size, 1, 10, 10)\n    - Concatenate the label encodings with noise: --> (batch_size, 2, 10, 10)","93480a49":"## Getting a few required helper code-segments in place","a2e636eb":"\n***\n***\n\n## The Generator & Discriminator models"}}