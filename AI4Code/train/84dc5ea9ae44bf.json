{"cell_type":{"06c7dfd4":"code","21291ec2":"code","56a2bc2a":"code","984fb2be":"code","dc6c57ed":"code","b719cfba":"code","d42e922e":"code","0bbd3291":"code","d18924ae":"code","aafdcdb9":"code","d8836f63":"code","0d2c0503":"code","eed017a3":"code","b29c0439":"code","c50b9482":"code","2f55d38c":"code","74983ac8":"code","d1e85d68":"code","2bb906bb":"code","d6261ac7":"code","e0d0c211":"code","9e4fd595":"code","c320bd8f":"code","92be9635":"code","45c724da":"markdown","3873a3a9":"markdown","6d90749f":"markdown","b8fe7adb":"markdown","2dd9fb8c":"markdown","d13a6924":"markdown","1169b24e":"markdown","5a339bb0":"markdown"},"source":{"06c7dfd4":"import pandas as pd\nimport re\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","21291ec2":"# Load in the train and test datasets\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)","56a2bc2a":"full_data = [train, test]\n\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n\n# Create new feature FamilySize as a combination of SibSp and Parch\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n# Create new feature IsAlone from FamilySize\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n# Remove all NULLS in the Embarked column\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n# Remove all NULLS in the Fare column and create a new feature CategoricalFare\nfor dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n# Create a New feature CategoricalAge\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n# Define function to extract titles from passenger names\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n# Create a new feature Title, containing the titles of passenger names\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n# Group all non-common titles into one single grouping \"Rare\"\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nfor dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4","984fb2be":"# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)","dc6c57ed":"train.head(3)","b719cfba":"test.head(3)","d42e922e":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","0bbd3291":"g = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare',\n                        u'Embarked', u'FamilySize', u'Title']],hue='Survived', \n                 diag_kind='hist', palette = 'seismic', size=1.2, plot_kws=dict(s=10))\ng.set(xticklabels=[])","d18924ae":"from sklearn.model_selection import (GridSearchCV,\n                                     train_test_split,\n                                     StratifiedKFold)\n\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\nfrom xgboost import XGBClassifier\n\n# \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432\ngbc_params = {'learning_rate': np.arange(0.1, 0.8, 0.5)} # GradientBoostingClassifier\n\nrfc_params = {'n_estimators': range(10, 100, 10), # RandomForestClassifier\n              'min_samples_leaf': range(1, 5)}\n\nsvc_params = {'kernel': ['linear', 'rbf'], # SVC\n              'C': np.arange(0.1, 1, 0.2)}\n\nlr_params = {'C': np.arange(0.5, 1, 0.1)}\n\nskf = StratifiedKFold(n_splits=5, random_state=17)","aafdcdb9":"from sklearn.metrics import accuracy_score\n\ntrain_targets = train['Survived']\ntrain_values = train.drop(columns='Survived')\n\nx_train, x_test, y_train, y_test = train_test_split(train_values, \n                                                    train_targets,\n                                                    test_size=0.3,\n                                                    random_state=17)","d8836f63":"gbc = GradientBoostingClassifier(random_state=17)\ngrid_gbc = GridSearchCV(gbc, param_grid=gbc_params, cv=skf)\nmodel_gbc = grid_gbc.fit(x_train, y_train)\nmodel_gbc.best_params_","0d2c0503":"rfc = RandomForestClassifier(random_state=17)\ngrid_rfc = GridSearchCV(rfc, param_grid=rfc_params, cv=skf)\nmodel_rfc = grid_rfc.fit(x_train, y_train)\nmodel_rfc.best_params_","eed017a3":"svc = SVC(random_state=17)\ngrid_svc = GridSearchCV(svc, param_grid=svc_params, cv=skf)\nmodel_svc = grid_svc.fit(x_train, y_train)\nmodel_svc.best_params_","b29c0439":"lr = LogisticRegression(random_state=17)\ngrid_lr = GridSearchCV(lr, param_grid=lr_params, cv=skf)\nmodel_lr = grid_lr.fit(x_train, y_train)\nmodel_lr.best_params_","c50b9482":"gbc_base = GradientBoostingClassifier(random_state=17, learning_rate=0.1)\nmodel_gbc_base = gbc_base.fit(x_train, y_train)\ngbc_base_predict = model_gbc_base.predict(x_test)\ngbc_accuracy =accuracy_score(gbc_base_predict, y_test)\nprint(f'GradientBoostingClassifier accuracy: {gbc_accuracy}')","2f55d38c":"rfc_base = RandomForestClassifier(random_state=17, min_samples_leaf=3, n_estimators=10)\nmodel_rfc_base = rfc_base.fit(x_train, y_train)\nrfc_base_predict = model_rfc_base.predict(x_test)\nrfc_accuracy = accuracy_score(rfc_base_predict, y_test)\nprint(f'RandomForestClassifier accuracy: {rfc_accuracy}')","74983ac8":"svc_base = SVC(random_state=17, C=0.9000000000000001, kernel='rbf')\nmodel_svc_base = svc_base.fit(x_train, y_train)\nsvc_base_predict = model_svc_base.predict(x_test)\nsvc_accuracy = accuracy_score(svc_base_predict, y_test)\nprint(f'SVC accuracy: {svc_accuracy}')","d1e85d68":"lr_base = LogisticRegression(random_state=17, C=0.5)\nmodel_lr_base = lr_base.fit(x_train, y_train)\nlr_base_predict = model_lr_base.predict(x_test)\nlr_accuracy = accuracy_score(lr_base_predict, y_test)\nprint(f'LogisticRegression accuracy: {lr_accuracy}')","2bb906bb":"xgb_params = {'n_estimators': range(10, 100, 5),\n              'eta': np.arange(0.1, 1., .1),\n              'min_child_weight': range(1, 10, 1),\n              'subsample': np.arange(0.1, 1., 0.2)}","d6261ac7":"meta_mtrx = np.empty((y_test.shape[0], 4))\nmeta_mtrx[:,0] = gbc_base_predict \nmeta_mtrx[:,1] = rfc_base_predict\nmeta_mtrx[:,2] = svc_base_predict\nmeta_mtrx[:,3] = lr_base_predict","e0d0c211":"xgb = XGBClassifier(random_state=17, cv=5)\ngrid_xgb = GridSearchCV(xgb, param_grid=xgb_params, cv=skf)\nmodel_xgb = grid_xgb.fit(meta_mtrx, y_test)\nmodel_xgb.best_params_","9e4fd595":"from sklearn.model_selection import cross_val_predict\n\ngbc_base = GradientBoostingClassifier(random_state=17, learning_rate=0.1)\nrfc_base = RandomForestClassifier(random_state=17, min_samples_leaf=3, n_estimators=10)\nsvc_base = SVC(random_state=17, C=0.9000000000000001, kernel='rbf')\nlr_base = LogisticRegression(random_state=17, C=0.5)\n\nmeta_alg = XGBClassifier(random_state=17, cv=5, eta=0.1, min_child_weight=1, n_estimators=55, subsample=0.30000000000000004)\n\nmodels = [gbc_base, rfc_base, svc_base, lr_base]\n\nmeta_mtrx = np.empty((train_targets.shape[0], len(models)))\nmodels_base = []\n        \nfor n, model in enumerate(models):\n    meta_mtrx[:, n] = cross_val_predict(model, train_values.values, train_targets.values, cv=5, method='predict')\n    model_base = model.fit(train_values, train_targets);\n    models_base.append(model_base)\n        \nmodel_meta = meta_alg.fit(meta_mtrx, train_targets)\n        \nmeta_mtrx_test = np.empty((test.shape[0], len(models)))         \nfor n, model in enumerate(models_base):\n    meta_mtrx_test[:, n] = model.predict(test)\n            \nmeta_predict = model_meta.predict(meta_mtrx_test)  ","c320bd8f":"def write_to_submission_file(predictions, PassengerID, out_file='Submission.csv', columns=['PassengerID', 'Survived']):\n    predicted_df = pd.DataFrame(np.array([PassengerId, predictions]).T, columns=columns)\n    predicted_df.to_csv(out_file, index=False)","92be9635":"write_to_submission_file(meta_predict, PassengerId)","45c724da":"### 3.\n\u0421 \u043f\u043e\u043c\u043e\u0449\u044c\u044e GridSearchCV \u0438 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u043d\u0438\u0436\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u0442\u0435 \u043c\u0435\u0442\u0430-\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043d\u0430 \u043c\u0435\u0442\u0430-\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 5-\u043a\u0440\u0430\u0442\u043d\u0443\u044e \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e \u0438 random_state=17 \u043f\u0440\u0438 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430). \u041c\u0430\u0442\u0440\u0438\u0446\u0443 \u043c\u0435\u0442\u0430\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 \u0438\u0437 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439, \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0432 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u043c \u043f\u0443\u043d\u043a\u0442\u0435 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0431\u0430\u0437\u043e\u0432\u044b\u043c\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\u043c\u0438. \u0412\u044b\u0432\u0435\u0434\u0438\u0442\u0435 \u043b\u0443\u0447\u0448\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b.","3873a3a9":"My first probe on Kaggle. I used XGBoosting in this Notebook ","6d90749f":"### 6.\n\u041a\u0430\u043a\u043e\u0432 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 score, \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u043d\u0430 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438?","b8fe7adb":"### 2.\n1. \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u0435 \u043e\u0431\u044a\u0435\u043a\u0442 GridSearchCV \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 (\u0432 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 \u043f\u0440\u0438 \u0435\u0433\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0438, \u0435\u0441\u043b\u0438 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u0443\u043a\u0430\u0436\u0438\u0442\u0435 random_state=17). \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 cv \u0443\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0439\u0442\u0435 \u0440\u0430\u0432\u043d\u044b\u043c skf.\n\n2. \u041e\u0431\u0443\u0447\u0438\u0442\u0435 \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0438\u0437 1-\u0433\u043e \u043f\u0443\u043d\u043a\u0442\u0430 \u043d\u0430 \u043f\u043e\u043b\u0443\u0447\u0438\u0432\u0448\u0435\u0439\u0441\u044f \u043f\u0440\u0438 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435. \u0412\u044b\u0432\u0435\u0434\u0438\u0442\u0435 \u043b\u0443\u0447\u0448\u0435\u0435 \u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0438\u0437 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432.\n\n3. \u0414\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0432\u044b\u0432\u0435\u0434\u0438\u0442\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u0435\u0442 \u043c\u0435\u0442\u0440\u0438\u043a\u0435 \u043e\u0446\u0435\u043d\u043a\u0438 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f.","2dd9fb8c":"\u0412\u0430\u0448 \u043e\u0442\u0432\u0435\u0442: 0.76555","d13a6924":"### 5.\n\u0421 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043d\u0438\u0436\u0435\u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0439\u0442\u0435 \u0444\u0430\u0439\u043b \u043f\u043e\u0441\u044b\u043b\u043a\u0438 \u0434\u043b\u044f \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f \u0438 \u043e\u0442\u043f\u0440\u0430\u0432\u044c\u0442\u0435 \u043d\u0430 Kaggle.","1169b24e":"### 4.\n\u041d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 \u0438\u0437 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0433\u043e \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u0433\u043e \u0437\u0430\u0434\u0430\u043d\u0438\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u0442\u0435 \u0441\u0442\u0435\u043a\u0438\u043d\u0433 (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 5-\u043a\u0440\u0430\u0442\u043d\u0443\u044e \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e) \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0441 \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0438\u043c\u0438 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043d\u043d\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438. \u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 \u0432\u0435\u0441\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 train.csv, \u0430 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 - \u0432\u0435\u0441\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 test.csv. \u0421\u0434\u0435\u043b\u0430\u0439\u0442\u0435 \u043f\u0440\u043e\u0433\u043d\u043e\u0437 \u043c\u0435\u0442\u0430-\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 \u0434\u043b\u044f test.csv.","5a339bb0":"\u0418\u0442\u0430\u043a, \u0443 \u043d\u0430\u0441 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438\u0441\u044c \u0434\u0432\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0441 \u043d\u043e\u0432\u044b\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438. \u0422\u0435\u043f\u0435\u0440\u044c \u043f\u0440\u0438\u0441\u0442\u0443\u043f\u0438\u043c \u043a \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044e \u043c\u043e\u0434\u0435\u043b\u0438.\n\n### \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\n\n### 1.\n\n\u0412\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435\u0441\u044c \u0432\u0430\u0448\u0438\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u043c \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430 \u0438\u0437 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0433\u043e \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u0433\u043e \u0437\u0430\u0434\u0430\u043d\u0438\u044f. \u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 RandomForestClassifier, SVC, GradientBoostingClassifier \u0438 LogisticRegression; \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043c\u0435\u0442\u0430-\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 - XGBoost.\n\n\u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 train \u043d\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0443\u044e \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0441 random_state=17 \u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u043c \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f test_size=.3 (\u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u0432\u043e\u0437\u044c\u043c\u0438\u0442\u0435 \u0441\u0442\u043e\u043b\u0431\u0435\u0446 Survived, \u0430 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 - \u0432\u0441\u0435 \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u044b).\n\n\u041d\u0438\u0436\u0435 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u044b \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0438\u0437 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043d\u0430\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043d\u0430 5-\u043a\u0440\u0430\u0442\u043d\u043e\u0439 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e GridSearchCV:"}}