{"cell_type":{"81212903":"code","31c72d4c":"code","48ec21f8":"code","87e37551":"code","241daefe":"code","0730786f":"code","735d2b7c":"code","9aa26eee":"code","64de9036":"code","ec707b5b":"code","69f53a5b":"code","366a5d36":"code","065342b1":"code","1ce78c66":"code","c5712a2f":"code","51d5ca17":"code","f509a565":"code","94805d3c":"code","aabec214":"code","c962d657":"code","6d15a978":"code","a5e214c1":"markdown","8d936d3e":"markdown","6a706ca6":"markdown","e96ddd19":"markdown","45ea7780":"markdown","95d5ebde":"markdown","b6742892":"markdown","504f9bc6":"markdown","faa052a0":"markdown","733d011a":"markdown","be0f9c16":"markdown","b63faf8f":"markdown","42182a83":"markdown","dcb830d2":"markdown","6778fd1f":"markdown"},"source":{"81212903":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31c72d4c":"import matplotlib.pyplot as plt\nimport seaborn as sns","48ec21f8":"data = pd.read_csv('\/kaggle\/input\/vehicle-dataset-from-cardekho\/car data.csv')\ndata.head()","87e37551":"data.shape","241daefe":"data.isnull().sum()","0730786f":"data['current year'] = 2021\ndata['no.of years used'] = data['current year'] - data['Year']\ndata.head()","735d2b7c":"data.drop(['Car_Name','Year','current year'],1,inplace = True)\n","9aa26eee":"data.head()","64de9036":"print(data['Fuel_Type'].unique())\nprint(data['Seller_Type'].unique())\nprint(data['Transmission'].unique())\nprint(data['Owner'].unique())\n","ec707b5b":"data = pd.get_dummies(data,drop_first=True)\ndata.head()","69f53a5b":"X = data.iloc[:,1:]\ny = data.iloc[:,0]\nprint(X)\nprint(y)","366a5d36":"plt.figure(figsize=(20,20))\nsns.heatmap(X.corr(),annot = True)","065342b1":"from sklearn.ensemble import ExtraTreesRegressor\nmodel = ExtraTreesRegressor()\nmodel.fit(X, y)\nimportant_features = pd.Series(model.feature_importances_, index = X.columns)\nprint(important_features.nlargest(5))\nimportant_features.nlargest(9).plot(kind ='bar')\nplt.show","1ce78c66":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\nX_train.shape,X_test.shape","c5712a2f":"#model creation\n#MANNUALLY INITIALIZING THE PARAMETERS\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nmodel=RandomForestRegressor(n_estimators=300,max_features='sqrt',min_samples_leaf=10,random_state=100).fit(X_train,y_train)\npredictions=model.predict(X_test)\nrmse_value = mean_squared_error(y_test, predictions, squared=False)\nrmse_value\n","51d5ca17":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 100,5)]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10,14]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,6,8]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}","f509a565":"rf=RandomForestRegressor()\nrf_randomcv=RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=100,cv=5,verbose=2,\n                               random_state=10,n_jobs=-1)\n### fit the randomized model\nrf_randomcv.fit(X_train,y_train)\n","94805d3c":"rf_randomcv.best_params_\n","aabec214":"best_random_grid=rf_randomcv.best_estimator_\ny_pred=best_random_grid.predict(X_test)\nrmse_value = mean_squared_error(y_test, y_pred, squared=False)\nrmse_value\n","c962d657":"sns.distplot(y_test-y_pred);\n","6d15a978":"plt.scatter(y_test, y_pred)","a5e214c1":"FINDIND THE BEST PARAMETER","8d936d3e":"USING \"RandomizedSearchCV\" TO FIND THE BEST PARAMETERS ","6a706ca6":"USING THE BEST ESTIMATOR TO PREDICT THE RESULTS","e96ddd19":"SEPARATING THE FEATURES AND TARGET LABEL","45ea7780":"CHECKING FOR NULL VALUES","95d5ebde":"LOADING THE DATASET","b6742892":"MODEL BUILDING : RANDOM FOREST","504f9bc6":"CONVERTING THE YEAR COLUMN TO NO.OF YEARS USED","faa052a0":"SHAPE OF THE DATASET","733d011a":"REMOVING THE COLUMS WHICH ARE NOT GOING TO BE USED","be0f9c16":"CHECKING THE CORRELATION BETWEEN THE INDEPENDENT FEATURES","b63faf8f":"USING \"ONE HOT ENCODING\" ","42182a83":"CHECKING WHICH FEATURE IS IMPORTANT TO PREDICT THE OUTPUT","dcb830d2":"SPLITING THE DATA FOR TRAINING AND TESTING","6778fd1f":"CHECKING FOR CATEGORICAL COLUMNS"}}