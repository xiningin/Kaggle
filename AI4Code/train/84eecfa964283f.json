{"cell_type":{"31763960":"code","32b90fed":"code","03ea2c21":"code","ed2f7b93":"code","ec81d35b":"code","cb925e48":"code","6a9abacb":"code","4a5a8eb0":"code","6c38c50f":"code","b6720c5d":"code","aa90b4ba":"code","3a755bd4":"code","8503c075":"code","e33e6827":"code","ec0ad753":"code","df2369d7":"code","9fbb7b4c":"code","05e6140a":"code","535d474f":"code","d1269f9a":"code","4adecbd8":"markdown","38777d73":"markdown","d3583e0b":"markdown","7d863f17":"markdown","ac756a59":"markdown","66e9b883":"markdown","bf7929f3":"markdown","e7d1a16d":"markdown","08dc4b94":"markdown","4674db96":"markdown","0909bab6":"markdown","c7abcfb2":"markdown"},"source":{"31763960":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import linalg\nimport sys\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nimport cv2","32b90fed":"def svd(A, tol=1e-5):\n    #singular values and right singular vectors coming from eigenvalues and eigenvectors of A' x A\n    eigs, V = linalg.eig(A.T.dot(A))\n\n    #singular values are the square root of the eigenvalues\n    sing_vals = np.sqrt(eigs)\n\n    #sort both sigular values and right singular vector\n    idx = np.argsort(sing_vals)\n\n    sing_vals = sing_vals[idx[::-1]]\n    V = V[:, idx[::-1]]\n\n    #remove zero singular values below tol\n    sing_vals_trunc = sing_vals[sing_vals>tol]\n    V = V[:, sing_vals>tol]\n\n    #is not necessary to store the entire sigma matrix, so only the diagonal is returned\n    sigma = sing_vals_trunc\n\n    #evaluate U matrix\n    U = A @ V \/sing_vals_trunc\n    \n    return U.real, sigma.real, V.T.real","03ea2c21":"def truncate(U, S, V, k):\n    U_trunc = U[:, :k]\n    S_trunc = S[:k]\n    V_trunc = V[:k, :]\n    return U_trunc, S_trunc, V_trunc","ed2f7b93":"from sklearn.datasets import load_iris\nimport seaborn as sns\nimport pandas as pd\n\niris = load_iris()\niris.keys()","ec81d35b":"data = pd.DataFrame(iris.data)\nfeature_names = iris[\"feature_names\"]\ndata.columns = feature_names\ndata[\"labels\"] = iris.target","cb925e48":"def custom_pairplot(data, feature_names, labels):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(left = 0, right=1.5, bottom=0, top=1.5)\n    n_features = len(feature_names)\n    \n    for i in range(len(feature_names)):\n        for j in range(len(feature_names)):\n            plt.subplot(n_features, n_features, i*n_features+j+1)\n            if i==j:\n                sns.violinplot(data=data, x=labels, y=feature_names[i])\n            else:\n                plt.scatter(data[feature_names[i]], data[feature_names[j]], c=data[labels])\n                plt.xlabel(feature_names[i])\n                plt.ylabel(feature_names[j])","6a9abacb":"custom_pairplot(data, feature_names=feature_names, labels=\"labels\")","4a5a8eb0":"k = 2\n\nA = data[feature_names].values\n\nU, S, Vt = svd(A)\nU_trunc, S_trunc, Vt_trunc = truncate(U, S, Vt, k)\n\ntrunc_A = U_trunc @ np.diag(S_trunc)\nreduced_data = pd.DataFrame(trunc_A)\nplt.figure(figsize=(5, 5))\nplt.barh(feature_names[::-1], S[::-1])\nplt.title(f\"Singular values, (first {k} are kept)\")\nplt.gca().xaxis.grid(True)","6c38c50f":"plt.figure(figsize=(5, 5))\nplt.scatter(reduced_data[0], reduced_data[1], c = iris.target)\nplt.xlabel(\"First feature\")\nplt.ylabel(\"Second feature\");","b6720c5d":"def im2double(im):\n    info = np.iinfo(im.dtype)\n    return im.astype(np.float)\/info.max","aa90b4ba":"# grayscale image (is still saved with 3 channels so I take the first one)\nimg = plt.imread(\"..\/input\/grayscale_image.jpg\")[:,:,0]","3a755bd4":"gray_channel = im2double(img)\n\n#my implementation\nU, S, V = svd(gray_channel)\n\n#linalg library implementation\nU_, S_, V_ = np.linalg.svd(gray_channel)","8503c075":"#number of singular values kept\nk = 20\n\nfig = plt.figure(figsize=(15,15))\n\nax1 = plt.subplot(1, 3, 1)\nax2 = plt.subplot(1, 3, 2)\nax3 = plt.subplot(1, 3, 3)\n\nplt.ion()\n\nfig.canvas.draw()\n\nU_trunc, S_trunc, Vt_trunc = truncate(U, S, V, k)\n_U_trunc, _S_trunc, _Vt_trunc = truncate(U_, S_, V_, k)\n\nmy_channel = 255 * U_trunc @ np.diag(S_trunc) @ Vt_trunc\nlinalg_channel = 255 * _U_trunc @ np.diag(_S_trunc) @ _Vt_trunc\n\nax1.title.set_text(f\"Original image\")\nax1.imshow(gray_channel, cmap='gray')\n    \nax2.title.set_text(f\"Custom svd implementation, k={k}\")\nax2.imshow(my_channel, cmap='gray')\n\n\nax3.title.set_text(f\"Numpy linalg svd implementation, k={k}\")\nax3.imshow(linalg_channel, cmap='gray')\n       \n","e33e6827":"plt.rcParams['animation.embed_limit'] = 2**128\nfps = 30\nstep = 5\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\n\nax2.axis(\"off\")\n\n#set figure dimension\nfig.set_size_inches(10, 5)\n\n#set first frame for the first plot (single values)\nax1.set_yscale(\"log\")\nax1.plot(S)\nax1.grid()\n\n\n#set first frame for the second plot (image)\nim = ax2.imshow(gray_channel, interpolation='none', vmin=0, vmax=1, cmap='gray');\nplt.tight_layout()\n\ndef animate_func(i):\n    #set next frame for single value truncation\n    k = len(S)-i*step\n    ax1.clear()\n    ax1.set_yscale(\"log\")\n    ax1.axvline(x=k, ymin=0, ymax=1, c=\"gray\", linestyle=\"--\")\n    ax1.plot(S)\n    ax1.legend([f\"Truncation k={k}\", \"Log10 of singular value\"])\n    \n    ax1.grid()\n        \n    #truncate svd decomposition and set new frame\n    U_trunc, S_trunc, Vt_trunc = truncate(U, S, V, k)\n    new_channel = U_trunc @ np.diag(S_trunc) @ Vt_trunc\n    im.set_array(new_channel)\n    return [fig]\n\nanim = animation.FuncAnimation(\n                               fig, \n                               animate_func, \n                               frames = len(S)\/\/step+1,\n                               interval = 100 \/ fps, # in ms\n                               );\n","ec0ad753":"HTML(anim.to_jshtml())","df2369d7":"#getting image channels\nrgb_img = plt.imread(\"..\/input\/rgb_image.jpg\")\n\n#separate them\nred_channel = im2double(rgb_img[:, :, 0])\ngreen_channel = im2double(rgb_img[:, :, 1])\nblue_channel = im2double(rgb_img[:, :, 2])\n\n#get SVD factorization\nr_U, r_S, r_V = svd(red_channel)\ng_U, g_S, g_V = svd(green_channel)\nb_U, b_S, b_V = svd(blue_channel)","9fbb7b4c":"fig, (ax1, ax2) = plt.subplots(1, 2)\n\nax2.axis(\"off\")\n\n#set figure dimension\nfig.set_size_inches(10, 5)\n\n#set first frame for the first plot (single values)\nax1.set_yscale(\"log\")\nax1.plot(S)\nax1.grid()\n\n#set first frame for the second plot (image)\nim = ax2.imshow(cv2.merge((red_channel, green_channel, blue_channel)).clip(0.0, 1.0),\n                interpolation='none', vmin=0, vmax=1)\n\nplt.tight_layout()\n\ndef animate_func(i):\n    #set next frame for single value truncation\n    k = len(S)-i*step\n    ax1.clear()\n    ax1.set_yscale(\"log\")\n    ax1.axvline(x=k, ymin=0, ymax=1, linestyle='--', c=\"gray\")\n    \n    ax1.plot(r_S, c=\"red\", linewidth=1)\n    ax1.plot(g_S, c=\"green\", linewidth=1)\n    ax1.plot(b_S, c=\"blue\", linewidth=1)\n\n    ax1.legend([f\"Truncation k={k}\", \"Log10 of RED singular value\",\n                \"Log10 of GREEN singular value\", \"Log10 of BLUE singular value\"])\n    ax1.grid()\n    \n    #truncate svd decomposition and set new frame\n    r_U_trunc, r_S_trunc, r_Vt_trunc = truncate(r_U, r_S, r_V, k)\n    g_U_trunc, g_S_trunc, g_Vt_trunc = truncate(g_U, g_S, g_V, k)\n    b_U_trunc, b_S_trunc, b_Vt_trunc = truncate(b_U, b_S, b_V, k)\n\n    r_new_channel = r_U_trunc @ np.diag(r_S_trunc) @ r_Vt_trunc\n    g_new_channel = g_U_trunc @ np.diag(g_S_trunc) @ g_Vt_trunc\n    b_new_channel = b_U_trunc @ np.diag(b_S_trunc) @ b_Vt_trunc\n\n    im.set_array(cv2.merge((r_new_channel, g_new_channel, b_new_channel)).clip(0.0, 1.0))\n    return [fig]\n\nanim = animation.FuncAnimation(\n                               fig, \n                               animate_func, \n                               frames = len(S)\/\/step+1,\n                               interval = 100 \/ fps, # in ms\n                               )\n","05e6140a":"HTML(anim.to_jshtml())","535d474f":"original_size = np.prod(rgb_img.shape) #evaluated in float numbers (dimension on disk is different)\n\ncompressed_size = []\n\nstart_dim = np.linalg.matrix_rank(red_channel)\n\nfor k in range(1, start_dim+1):\n    # evaluation is done for red channel and then multiplied by 3\n    r_U_trunc, r_S_trunc, r_Vt_trunc = truncate(r_U, r_S, r_V, k)\n    compressed_size.append((np.prod(r_U_trunc.shape)+k+np.prod(r_Vt_trunc.shape)) * 3)\n\ntot_var = sum(r_S**2)+sum(g_S**2)+sum(b_S**2)\n\nr_S_padded = np.pad(r_S, (0, start_dim-len(r_S)))\ng_S_padded = np.pad(g_S, (0, start_dim-len(g_S)))\nb_S_padded = np.pad(b_S, (0, start_dim-len(b_S)))\n\n\nexplained = np.cumsum(r_S_padded**2)+np.cumsum(g_S_padded**2)+np.cumsum(b_S_padded**2)\nexplained \/= tot_var","d1269f9a":"plt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(original_size\/compressed_size)\nplt.yscale(\"log\")\nplt.grid()\nplt.xlabel(\"Number of singular values\")\nplt.ylabel(\"Compression ratio\")\n\nplt.subplot(1, 2, 2)\nplt.plot(explained)\nplt.xscale(\"log\")\nplt.grid()\nplt.xlabel(\"Number of singular values\")\nplt.ylabel(\"Explained variability\");\n","4adecbd8":"# SVD decomposition and applications\n\nSVD is a factorization used for solving linear equations, dimensionality reduction, data compression and so on.<br>\nIt's based on the following decomposition:\n$$A = U\\Sigma V^*$$\n<br>\nIn which the matrix A *(m x n)* can be factorized into three matrices:<br>\n**U** *(m x m)* unitary matrix <br>\n**\u03a3** *(m x n)* rectangular diagonal matrix <br>\n**V** *(n x n)* unitary matrix <br>\n\nColumns of **V** are the eigenvectors of **A\\*A** called singular vectors<br>\nColumns of **U** are the eigenvectors of **AA*** called singular vectors<br>\nThe elements on the diagonal of **\u03a3** are the ordered non-zero eigenvalues of both **A*A** and **AA*** called *singular values*<br>","38777d73":"The same technique can be applied to RGB images, the only difference is that SVD needs to be applied 3 times, one for every channel.","d3583e0b":"Side by side with my svd implementation there is also the *numpy.linalg* algorithm *svd*","7d863f17":"Let's apply SVD decomposition to keep only two dimensions (k=2)<br>","ac756a59":"The proposed implementation of SVD consists of evaluating eigenvalues and eigenvectors of A\\*A with numpy library *linalg.eig* to get V and the singular values<br>\nThen the singular values are sorted, and so the singular vectors in V<br>\nWe consider only non-zero singular values<br>\nThen U is computed solving the linear equation with A, V and \u03a3.\n","66e9b883":"The resulting image can be stored as the three truncated matrices. So we can define the compression ratio as the ratio between uncompressed size and compressed.<br>\n$$Compression\\ ratio=\\frac{Uncompressed\\ size}{Compressed\\ size}$$\n\nIt's also possible to compute the percentage of explained variability<br>\n\n$$Explained\\ variability = \\frac{\\sum_{j=1}^{k}{\\sigma_j^2}}{\\sum_{j=1}^{n}{\\sigma_j^2}}$$\n\nWhere sigma j is the j-th singular value.<br> There is a rule of thumb that suggests to keep enough singular values to have 85% of variability explained","bf7929f3":"We can see how the image changes with k with this animation.","e7d1a16d":"This is a custom version of the *sns.pairplot* with violins instead of histograms and scatters colored according to the class","08dc4b94":"# SVD for dimensionality reduction\nWe can see how svd decomposition applies to dimensionality reduction, in this example, using the **Iris dataset** available directly from library *sklearn*","4674db96":"The singular values stored inside \u03a3 have very different values, they indicates how much \"relevant\" that singular values are.<br>\nSo we can just take the first k singular values, truncating \u03a3 and consequently V and U.<br>\nIn this way the matrix product is still doable and the resulting matrix has the same shape as the original.<br>\nIf we use svd for dimensionality reduction we just need to keep U and \u03a3, because V is just used to *project the lower rank matrix **U\u03a3** into the previous dimension*.","0909bab6":"# SVD for Image Compression\nNow we can see how to apply svd to image compression<br>","c7abcfb2":"As we can see, keeping two dimensions leads to quite well separated classes.<br>\nIn this case working on 4 features instead of 2 is not a problem but in other context dimensionality reductions is almost mandatory"}}