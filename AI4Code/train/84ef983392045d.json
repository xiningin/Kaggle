{"cell_type":{"8fe29077":"code","20be7502":"code","52364b64":"code","6ae2a1b0":"code","c1b47606":"code","1cf33af6":"code","eea7c0cc":"code","33f87bac":"code","f520fa9c":"code","7be7ee91":"code","8d629d7c":"code","3388f612":"code","52b62194":"code","4fd51946":"code","a19276d4":"code","85b9ad32":"code","cdce488b":"code","b2965d98":"code","03490aa2":"code","1cad7ee2":"code","e32555f3":"code","f5fe8fdf":"code","4f8e3f9c":"code","708b9199":"code","4a34d3f8":"code","011a06e6":"code","eb35fb7d":"code","fca623f2":"code","fc91f3b4":"code","6af91c69":"code","cfc0828c":"code","8cf2c29e":"code","748b4752":"code","9f0299ef":"code","06bfab2f":"code","a6c33e0f":"code","d8eca4c6":"code","01ce39f2":"code","6184126e":"code","e01b4365":"code","b977069b":"code","a4dc9d94":"code","c2caf5cd":"code","70b1ee40":"code","961777da":"code","6cb10531":"code","4dfdd55f":"code","bc2f5f71":"code","44373e46":"code","1dac9cbc":"code","0d5d9f2f":"code","2725bf66":"code","b5c9819b":"code","0921831e":"code","5ed80dd8":"code","24f15d35":"code","da2f5869":"code","58e20273":"code","cc4f1ca0":"code","fd1ff72b":"code","f8e66e88":"code","a638cd7f":"code","be579364":"code","1f4433eb":"code","5109fe22":"code","05a55ff4":"code","ed501095":"code","2f3a6286":"code","36c70684":"code","234edcaf":"code","5b06291d":"code","c261ab0a":"code","40f9cdbb":"code","9aed566c":"code","503cd710":"code","5e97e898":"code","c908151b":"code","e7d31c09":"code","9fe98312":"code","72ae8429":"markdown","7e2785b6":"markdown","06979596":"markdown","9fdccbfa":"markdown","969cf09b":"markdown","0699a0af":"markdown","b28043d3":"markdown","d75c98ea":"markdown","bc1c2942":"markdown","35e281e8":"markdown","873f9306":"markdown","62c910a5":"markdown","9c458206":"markdown","6f3e5432":"markdown","d045b6ea":"markdown","9bb68b60":"markdown","dfc0b2d8":"markdown","7b6e7e0c":"markdown","234d315a":"markdown","5c946351":"markdown","7d932abc":"markdown","9ec7e5af":"markdown","1d817d9d":"markdown","0d6e8fa7":"markdown","936bcfbf":"markdown","0244e4c9":"markdown","b57004bb":"markdown","97a6cf91":"markdown","ab9b0c48":"markdown","ea6760c7":"markdown","3e55e5c7":"markdown","3c12c2d4":"markdown","901b6d2f":"markdown","68c76079":"markdown","0fc2a72b":"markdown","06ab644c":"markdown","fb3d1e77":"markdown","b3dea561":"markdown","e402bb76":"markdown","3107e2cb":"markdown","d54ddf40":"markdown","527ddce3":"markdown","ef5cb18e":"markdown","4b725d69":"markdown","a513d2f8":"markdown","bf5a09d3":"markdown","7d09d7db":"markdown","cb5b9847":"markdown","7507aae3":"markdown","02382fe6":"markdown","c8c30be7":"markdown","11e0115f":"markdown","33e4dfa6":"markdown","a18189a0":"markdown","b2b05098":"markdown","0bc686d2":"markdown","3abb5abb":"markdown","40ee72e7":"markdown","02077927":"markdown","cf353c23":"markdown","87831e49":"markdown","bb554223":"markdown","9af48d93":"markdown","f83d1b3a":"markdown","27918654":"markdown","b7923936":"markdown","3e35e901":"markdown","a6f55883":"markdown","4c526556":"markdown","19f348f2":"markdown","a4ac7509":"markdown","6aad27e7":"markdown","d446651f":"markdown","ad3ded65":"markdown","0c3e0154":"markdown","355d5bcf":"markdown","15f1626a":"markdown","8d3ac908":"markdown","883552f9":"markdown","f877925e":"markdown","afaff0b6":"markdown"},"source":{"8fe29077":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","20be7502":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","52364b64":"# Lecture des donn\u00e9es d'apprentissage et de test\nt = pd.read_csv(\"..\/input\/titanic\/train.csv\")","6ae2a1b0":"t.head().T","c1b47606":"t.Sex.value_counts()      # nombre d'hommes et de femmes","1cf33af6":"t.Sex.count()              # nombre total hommes + femmes ","eea7c0cc":"t.Cabin.count()","33f87bac":"t.count()                  # Comptage par colonnes","f520fa9c":"t[np.isnan(t.Age)].Survived.value_counts()","7be7ee91":"hommes = (t.Sex == \"male\")","8d629d7c":"t[hommes].head()        # t[hommes] est le tableau o\u00f9 on ne retient que lignes pour lesquelles hommes est True","3388f612":"t[hommes].Survived.value_counts()","52b62194":"femmes = t.Sex == \"female\"\nclasse1 = t.Pclass == 1\nclasse2 = t.Pclass == 2\nclasse3 = t.Pclass == 3\nsurvivant = t.Survived == 1\nmort = ~ survivant","4fd51946":"jack = hommes & classe3\nrose = femmes & classe1","a19276d4":"p_jack = t[jack & survivant].Sex.count()\/t[jack].Sex.count()\nprint(p_jack)","85b9ad32":"p_rose = t[rose & survivant].Sex.count()\/t[rose].Sex.count()\nprint(p_rose)","cdce488b":"# Embarked par \u00e2ge\nsns.boxplot(x=\"Embarked\", y=\"Age\", data = t)","b2965d98":"# Concentration par \u00e2ge\nplt.figure(figsize = [10,5])\nsns.distplot(t.Age)","03490aa2":"# Concentration par classe\nplt.figure(figsize = [10,5])\nsns.distplot(t.Pclass)","1cad7ee2":"# Boxplot Age par class\ng = sns.FacetGrid(t, col = \"Pclass\")\ng.map(sns.boxplot, \"Age\")","e32555f3":"# Kdeplot Age par class\ng = sns.FacetGrid(t, col = \"Pclass\")\ng.map(sns.kdeplot, \"Age\")","f5fe8fdf":"t.columns","4f8e3f9c":"# On \u00e9limine les colonnes non pertinentes pour la pr\u00e9diction\ntitanic = t.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)","708b9199":"titanic.count()","4a34d3f8":"titanic[np.isnan(titanic.Age)]","011a06e6":"titanic1 = titanic.fillna(value = {'Age':titanic.Age.mean()})","eb35fb7d":"plt.hist(titanic1.Age, bins=80)","fca623f2":"titanic = titanic.fillna(method='pad')","fc91f3b4":"titanic = titanic.fillna(method='pad')","6af91c69":"titanic.count()","cfc0828c":"plt.hist(titanic.Age, bins=80)","8cf2c29e":"sns.distplot(titanic.Fare, color='blue')","748b4752":"titanic['log_fare'] = np.log(titanic.Fare+1)","9f0299ef":"sns.kdeplot(titanic.log_fare, color='blue')","06bfab2f":"titanic = titanic.drop(['Fare'], axis=1)","a6c33e0f":"titanic[['Age','log_fare']].describe()","d8eca4c6":"sns.kdeplot(titanic.log_fare, color='blue')\nsns.kdeplot(titanic.Age, color='red')","01ce39f2":"from sklearn import preprocessing","6184126e":"minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))\ntitanic[['Age', 'log_fare']] = minmax.fit_transform(titanic[['Age', 'log_fare']])","e01b4365":"sns.distplot(titanic.log_fare, color='blue')\nsns.distplot(titanic.Age, color='red')","b977069b":"scaler = preprocessing.StandardScaler()\ntitanic[['Age', 'log_fare']] = scaler.fit_transform(titanic[['Age', 'log_fare']])","a4dc9d94":"sns.kdeplot(titanic.log_fare, color='blue')\nsns.kdeplot(titanic.Age, color='red')","c2caf5cd":"titanic.info()","70b1ee40":"titanic.Sex = titanic.Sex.map({\"male\":0, \"female\":1})","961777da":"titanic = pd.get_dummies(data=titanic, columns=['Pclass', 'Embarked'])","6cb10531":"titanic.head()","4dfdd55f":"X = titanic.drop(['Survived'], axis=1)\ny = titanic.Survived","bc2f5f71":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","44373e46":"print(X_train.shape)\nprint(X_test.shape)","1dac9cbc":"from sklearn.linear_model import LogisticRegression","0d5d9f2f":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","2725bf66":"y_lr = lr.predict(X_test)","b5c9819b":"# Importation des m\u00e9thodes de mesure de performances\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score","0921831e":"print(confusion_matrix(y_test,y_lr))","5ed80dd8":"print(accuracy_score(y_test,y_lr))","24f15d35":"print(classification_report(y_test, y_lr))","da2f5869":"probas = lr.predict_proba(X_test)","58e20273":"print(probas)","cc4f1ca0":"dfprobas = pd.DataFrame(probas,columns=['proba_0','proba_1'])\ndfprobas['y'] = np.array(y_test)","fd1ff72b":"dfprobas","f8e66e88":"plt.figure(figsize=(10,10))\nsns.distplot(1-dfprobas.proba_0[dfprobas.y==0], bins=50)\nsns.distplot(dfprobas.proba_1[dfprobas.y==1], bins=50)","a638cd7f":"false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint (roc_auc)","be579364":"plt.figure(figsize=(12,12))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\nplt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","1f4433eb":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","5109fe22":"print(classification_report(y_test, y_rf))","05a55ff4":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","ed501095":"rf1 = ensemble.RandomForestClassifier(n_estimators=10, min_samples_leaf=10, max_features=3)\nrf1.fit(X_train, y_train)\ny_rf1 = rf.predict(X_test)\nprint(classification_report(y_test, y_rf1))","2f3a6286":"from sklearn.model_selection import validation_curve\nparams = np.arange(1, 300,step=30)\ntrain_score, val_score = validation_curve(rf, X, y, 'n_estimators', params, cv=7)\nplt.figure(figsize=(12,12))\nplt.plot(params, np.median(train_score, 1), color='blue', label='training score')\nplt.plot(params, np.median(val_score, 1), color='red', label='validation score')\nplt.legend(loc='best')\nplt.ylim(0, 1)\nplt.xlabel('n_estimators')\nplt.ylabel('score');","36c70684":"from sklearn import model_selection","234edcaf":"param_grid = {\n              'n_estimators': [10, 100, 500],\n              'min_samples_leaf': [1, 20, 50]\n             }\nestimator = ensemble.RandomForestClassifier()\nrf_gs = model_selection.GridSearchCV(estimator, param_grid)","5b06291d":"rf_gs.fit(X_train, y_train)","c261ab0a":"print(rf_gs.best_params_)","40f9cdbb":"rf2 = rf_gs.best_estimator_","9aed566c":"y_rf2 = rf2.predict(X_test)","503cd710":"print(classification_report(y_test, y_rf2))","5e97e898":"importances = rf2.feature_importances_\nindices = np.argsort(importances)","c908151b":"plt.figure(figsize=(8,5))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns[indices])\nplt.title('Importance des caracteristiques')","e7d31c09":"# Sous Jupyter, si xgboost n'est pas d\u00e9j\u00e0 install\u00e9\n!pip install xgboost","9fe98312":"import xgboost as XGB\nxgb  = XGB.XGBClassifier()\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)\ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)\nprint(classification_report(y_test, y_xgb))","72ae8429":"En comparant les valeurs pr\u00e9dites et les valeurs r\u00e9elles, on a plusieurs possibilit\u00e9s :\n- *Vrais positifs* (VP ou TP) : on pr\u00e9dit \"oui\" et la valeur attendue est \"oui\"\n- *Vrais n\u00e9gatifs* (VN ou TN) : on pr\u00e9dit \"non\" et la valeur attendue est \"non\"\n- *Faux positifs* (FP) : on pr\u00e9dit \"oui\" et la valeur attendue est \"non\"\n- *Faux n\u00e9gatifs* (FN) : on pr\u00e9dit \"non\" et la valeur attendue est \"oui\"\n\nPar exemple, si veut pr\u00e9dire le d\u00e9c\u00e8s, le nombre de vrais positifs est le nombre de fois o\u00f9 on a pr\u00e9dit 0 pour des passagers effectivement morts sur le Titanic (*survived = 0*)","7e2785b6":"## Lecture des donn\u00e9es","06979596":"<img src = \"http:\/\/scikit-learn.org\/0.16\/_static\/ml_map.png\">","9fdccbfa":"L'option *method='pad'* permet d'utiliser la pr\u00e9c\u00e9dente valeur non manquante :","969cf09b":"La **matrice de confusion** permet de compter les vrais positifs, faux positifs, ...","0699a0af":"Il manque des valeurs, par exemple pour la colonne *age*","b28043d3":"# Rose & Jack","d75c98ea":"*value_counts* permet de compter le nombre d'\u00e9l\u00e9ments par cat\u00e9gorie d'une s\u00e9rie","bc1c2942":"<img src=\"https:\/\/www.scienceabc.com\/wp-content\/uploads\/2016\/04\/titanic-jack-and-rose-plank-scene.webp\">","35e281e8":"Jack est un homme en 3\u00e8me classe, et Rose une femme en 1\u00e8re (d\u00e9finir les bool\u00e9ens *jack* et *rose*) :","873f9306":"On peut voir les param\u00e8tres s\u00e9lectionn\u00e9s et le score :","62c910a5":"On teste les for\u00eats al\u00e9atoires :","9c458206":"http:\/\/scikit-learn.org\/0.16\/tutorial\/machine_learning_map\/index.html","6f3e5432":"Tracer diff\u00e9rentes repr\u00e9sentations du dataset","d045b6ea":"On peut compter les hommes survivants ou non :","9bb68b60":"La m\u00e9thode *GridSearchCV* permet de tester plusieurs combinaisons de param\u00e8tres (list\u00e9s dans une grille de param\u00e8tres) et de s\u00e9lectionner celle qui donne la meilleure pertinence","dfc0b2d8":"On utilise la fonction *get_dummies* de Pandas pour transformer les colonnes multimodales (par exemple 'embarked') en plusieurs colonnes binaires (par exemple 'embarked_C' dont les valeurs sont 1 si le passager a embarqu\u00e9 \u00e0 Cherbourg et 0 sinon) :","7b6e7e0c":"La fonction *fillna* permet de compl\u00e9ter simplement les param\u00e8tres manquants. ","234d315a":"## R\u00e9gression logistique","5c946351":"On s\u00e9pare le dataset en deux parties :\n- un ensemble d'apprentissage (entre 70% et 90% des donn\u00e9es), qui va permettre d'entra\u00eener le mod\u00e8le\n- un ensemble de test (entre 10% et 30% des donn\u00e9es), qui va permettre d'estimer la pertinence de la pr\u00e9diction","7d932abc":"### Mise \u00e0 l'\u00e9chelle des donn\u00e9es quantitatives","9ec7e5af":"Dans ce cas, une transformation log peut am\u00e9liorer l'\u00e9quilibre :","1d817d9d":"La librairie *sklearn* comporte une librairie de pr\u00e9traitement des donn\u00e9es","0d6e8fa7":"La distribution des \u00e2ges n'est pas significativement modifi\u00e9e ...","936bcfbf":"La distribution id\u00e9ale permet de s\u00e9parer totalement la pr\u00e9diction des positifs et n\u00e9gatifs :  \n<img src=\"https:\/\/miro.medium.com\/max\/660\/1*Uu-t4pOotRQFoyrfqEvIEg.png\">\nLe cas le plus d\u00e9favorable consiste en une distribution \u00e9quivalente pour les positifs et les n\u00e9gatifs :  \n<img src=\"https:\/\/miro.medium.com\/max\/538\/1*iLW_BrJZRI0UZSflfMrmZQ.png\">","0244e4c9":"Les valeurs inconnues sont affich\u00e9es comme **NaN** (*Not a Number*).  \nOn peut tester si une valeur est **NaN** avec la fonction *np.isnan(valeur)*  \nAfficher les lignes pour lesquelles l'\u00e2ge est inconnu :","b57004bb":"La pertinence (ou *accuracy*) mesure le nombre de bonnes pr\u00e9dictions sur le nombre total d'observations","97a6cf91":"On peut visualiser ces degr\u00e9s d'importance avec un graphique \u00e0 barres par exemple :","ab9b0c48":"La m\u00e9thode XGBoost est d\u00e9riv\u00e9e des arbres de d\u00e9cision, et tr\u00e8s efficace, en particulier pour de grandes quantit\u00e9s de donn\u00e9es.","ea6760c7":"*predict_proba* donne un tableau de couples de probabilit\u00e9s : *[probabilit\u00e9 de pr\u00e9diction 0, probabilit\u00e9 de pr\u00e9diction 1]*","3e55e5c7":"### Donn\u00e9es manquantes","3c12c2d4":"Que peut-on dire des voyageurs de 1ere, 2eme et 3eme classe ?","901b6d2f":"D\u00e9finir les bool\u00e9ens pour *femmes, classe1, classe2, classe3, survivant, ...*","68c76079":"Tracer l'histogramme des \u00e2ges. Qu'observez-vous ?","0fc2a72b":"On s\u00e9lectionne le meilleur estimateur :","06ab644c":"## Cr\u00e9ation des jeux d'apprentissage et de test","fb3d1e77":"## Exercice : tester diff\u00e9rentes visualisations sur le dataset","b3dea561":"### Importance des caract\u00e9ristiques","e402bb76":"# Le Titanic","3107e2cb":"On affiche la distribution des probabilit\u00e9s de pr\u00e9diction de 1, et celle des non probabilit\u00e9s de pr\u00e9diction de 0 :","d54ddf40":"- survived - Survival (0 = No; 1 = Yes)\n- pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n- name - Name\n- sex - Sex\n- age - Age\n- sibsp - Number of Siblings\/Spouses Aboard\n- parch - Number of Parents\/Children Aboard\n- ticket - Ticket Number\n- fare - Passenger Fare\n- cabin - Cabin\n- embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n","527ddce3":"https:\/\/www.kaggle.com\/joelkalildasilva\/india-diabetes","ef5cb18e":"On peut normaliser les valeurs min et \u00e0 max (valeurs ramen\u00e9es entre 0 et 1) :","4b725d69":"On utilise ces distributions pour construire la **courbe ROC** (Receiving Operator Characteristic) qui repr\u00e9sente le taux de vrais positifs par rapport aux taux de faux positifs.  \nLa mesure de l'aire sous la courbe **AUC** (Area Under Curve) est un bon indicateur de performance  \nPour plus de d\u00e9tails : http:\/\/www.xavierdupre.fr\/app\/mlstatpy\/helpsphinx\/c_metric\/roc.html","a513d2f8":"*validation_curve* permet de tracer la courbe du score sur un ensemble d'apprentissage et sur un ensemble de test (*cross validation*), en faisant varier un param\u00e8tre, par exemple *n_estimators* :","bf5a09d3":"La plupart des algorithmes ont besoin de donn\u00e9es num\u00e9riques, et n'acceptent pas les cha\u00eenes de caract\u00e8res :","7d09d7db":"On voit qu'il manque des donn\u00e9es, en particulier pour la colonne *'age'*  \nIl existe plusieurs approches pour compl\u00e9ter les donn\u00e9es manquantes :  \n- **suppression** des donn\u00e9es manquantes (par exemple avec la fonction *dropna*). C'est une m\u00e9thode simple, mais qui \u00e9limine de l'information\n- **remplacement** des donn\u00e9es manquantes. Par exemple, on pourrait remplacer les informations manquantes pour l'\u00e2ge par la moyenne de la colonne (mais on introduit un biais sur cette valeur), ou par un nombre al\u00e9atoire g\u00e9n\u00e9r\u00e9 par une loi normale de m\u00eame moyenne et variance ...\n- **estimation** des param\u00e8tres manquants avec une m\u00e9thode de pr\u00e9diction (par exemple avec une r\u00e9gression)","cb5b9847":"Parmi les hyperparam\u00e8tres de l'algorithme qui peuvent avoir un impact sur les performances, on a :\n- **n_estimators** : le nombre d'arbres de d\u00e9cision de la for\u00eat al\u00e9atoire\n- **min_samples_leaf** : le nombre d'\u00e9chantillons minimum dans une feuille de chaque arbre\n- **max_features** : le nombre de caract\u00e9ristiques \u00e0 prendre en compte lors de chaque split\n\nPour chaque algorithme de *sklearn*, on peut trouver la liste des param\u00e8tres dans la documentation, avec des exemples :  \nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html  ","7507aae3":"Certaines distributions sont d\u00e9s\u00e9quilibr\u00e9es, et \u00e9loign\u00e9es d'une loi normale :","02382fe6":"On peut d\u00e9finir un bool\u00e9en pour abr\u00e9ger une caract\u00e9ristique :","c8c30be7":"**Exercice** : tracer les courbes de validation pour les param\u00e8tres *min_samples_leaf* et *max_features* (attention pour ce dernier, le nombre max est le nombre de caract\u00e9ristiques \/ colonnes du tableau)","11e0115f":"Ici on a choisi des valeurs pour le nombres d'arbres dans la for\u00eat al\u00e9atoire (*'n_estimators'*) et le nombre minimum d'\u00e9chantillons pour une feuille. On pourrait tester d'autres valeurs, et d'autres param\u00e8tres, cf :  \nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html","33e4dfa6":"## D\u00e9s\u00e9quilibre des distributions","a18189a0":"## Exercice : appliquer les m\u00e9thodes sur le dataset *Indian Diabete*","b2b05098":"## Ajustement des hyperparam\u00e8tres (Random Forests)","0bc686d2":"Tracer l'histogramme pour *age* :","3abb5abb":"N\u00e9anmoins cette mesure peut \u00eatre fauss\u00e9e dans certains cas, en particulier si le nombre de 0 et de 1 est d\u00e9s\u00e9quilibr\u00e9.\nOn a donc d'autres estimateurs :\n- la **pr\u00e9cision** est le nombre de pr\u00e9dictions positives correctes sur le nombre total de pr\u00e9dictions positives : *precision = VP\/(VP+FP)*\n- la **sensibilit\u00e9** (*recall*) est le nombre de pr\u00e9dictions positives sur le nombre effectif de \"oui\" : *recall = VP:(VP+FN)*\n- le **score F1** est la moyenne pond\u00e9r\u00e9e de la pr\u00e9cision et de la sensibilit\u00e9 : *f1-score = 2xprecisionxrecall\/(precision+recall)*","40ee72e7":"On met les probabilit\u00e9s de pr\u00e9diction de la valeur 1 dans un dataframe, avec les valeurs effectives, pour faciliter la visualisation :","02077927":"Afficher la matrice de confusion :","cf353c23":"## Mesures de performance","87831e49":"On remarque qu'il manque des valeurs pour 'age' et 'embarked' (pr\u00e9sence de valeurs ind\u00e9finies 'NaN')","bb554223":"## Interpr\u00e9tation des param\u00e8tres","9af48d93":"On lance l'entrainement :","f83d1b3a":"Calculer la probabilit\u00e9 de survie de Jack :","27918654":"## Exercice : quelle est la probabilit\u00e9 de survie de Rose et Jack ?","b7923936":"On peut \u00e9galement utiliser le *StandardScaler* pour ramener la moyenne \u00e0 0 et l'\u00e9cart type \u00e0 1 :","3e35e901":"Calculer la probabilit\u00e9 de survie de Rose :","a6f55883":"<img src=\"https:\/\/i.stack.imgur.com\/gKyb9.png\">","4c526556":"Tracer les courbes de distribution de l'\u00e2ge selon la classe (utiliser *FacetGrid*)","19f348f2":"*Les passagers de premi\u00e8re classe sont plus \u00e2g\u00e9s que ceux des autres classes. Les passagers de 2 et 3 classes sont plus jeunes, mais les passagers de 3 classes, qui constituent la majorit\u00e9 des passagers, ont plus de 20 ans.*","a4ac7509":"## Conditionnement des donn\u00e9es","6aad27e7":"L'attribut *feature_importances_* renvoie un tableau du poids de chaque caract\u00e9ristique dans la d\u00e9cision :","d446651f":"Cr\u00e9er les jeux d'apprentissage et de test","ad3ded65":"On a am\u00e9lior\u00e9 la performance du mod\u00e8le","0c3e0154":"On voit qu'il y a une forte diff\u00e9rente de distribution entre les deux s\u00e9ries.  \nCertains algorithmes demandent une distribution normalis\u00e9e. Pour une discussion d\u00e9taill\u00e9e sur ce sujet, cf par exemple :  \nhttp:\/\/www.faqs.org\/faqs\/ai-faq\/neural-nets\/part2\/section-16.html  \nhttp:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html","355d5bcf":"### Encodage binaire des donn\u00e9es qualitatives (*one hot encoding*)","15f1626a":"Appliquer une r\u00e9gression logistique pour classifier sur l'ensemble de test","8d3ac908":"## XGBoost","883552f9":"Sous Anaconda prompt :\n*pip install xgboost*  \n(d\u00e9j\u00e0 disponible sous Kaggle)","f877925e":"Eliminer les colonnes non pertinentes pour la pr\u00e9diction (on peut utiliser une liste de colonnes dans *drop*), et placer le r\u00e9sultat dans la variable *titanic* :","afaff0b6":"## Exercice : explorer d'autres m\u00e9thodes de classification"}}