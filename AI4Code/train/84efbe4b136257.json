{"cell_type":{"82e8277f":"code","2750ead1":"code","c60f126d":"code","7938fe33":"code","9e77440d":"code","f4bf78f1":"code","d6bea14d":"code","8312999d":"code","4741fb01":"markdown","384d850b":"markdown","f8b79312":"markdown","a4684d68":"markdown"},"source":{"82e8277f":"import numpy as np\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n\nfrom tqdm import tqdm\nimport PIL.Image as Image\n\nif not os.path.isdir('.\/experiments'):\n    os.makedirs('.\/experiments')\n    \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","2750ead1":"#Change them \/ create some others ?\nbatch_size = 16\nepochs = 5","c60f126d":"data_transforms = transforms.Compose([\n    transforms.Resize((256, 256), Image.BILINEAR),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('..\/input\/mva-recvis-2021\/bird_dataset\/train_images', transform=data_transforms),\n    batch_size=batch_size, shuffle=True, num_workers=1)\n\nval_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('..\/input\/mva-recvis-2021\/bird_dataset\/val_images',transform=data_transforms),\n    batch_size=batch_size, shuffle=True, num_workers=1)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('..\/input\/mva-recvis-2021\/bird_dataset\/test_images',transform=data_transforms),\n    batch_size=1, shuffle=False, num_workers=1)","7938fe33":"#Change this model by another one.\nmodel = torchvision.models.resnet34(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 20)\nmodel.to(device)\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\ncriterion = torch.nn.CrossEntropyLoss()","9e77440d":"def train(model, epoch):\n    model.train()\n    for batch_idx, (data, labels) in enumerate(train_loader):\n        data, labels = data.to(device), labels.to(device)\n        optimizer.zero_grad()\n        #forward\n        preds = model(data)\n        loss = criterion(preds, labels)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 25 == 0:\n            print('[{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.data.item()))\n\n\ndef validation(model):\n    model.eval()\n    validation_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, labels in val_loader:\n            data, labels = data.to(device), labels.to(device)\n            preds = model(data)\n            # sum up batch loss\n            validation_loss += criterion(preds, labels).data.item()\n            m = nn.Softmax(dim=1)\n            probs = m(preds)\n            preds_classes = probs.max(1, keepdim=True)[1]\n            correct += preds_classes.eq(labels.data.view_as(preds_classes)).sum()\n        validation_loss \/= len(val_loader.dataset)\n    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)'.format(\n        validation_loss, correct, len(val_loader.dataset),\n        100. * correct \/ len(val_loader.dataset)))","f4bf78f1":"for epoch in range(1, epochs + 1):\n    print(\"################################################# EPOCH\", epoch)\n    train(model, epoch)\n    preds = validation(model)\n    model_file = 'experiments' + '\/model_' + str(epoch) + '.pth'\n    torch.save(model.state_dict(), model_file)","d6bea14d":"preds = np.array([])\nmodel.eval()\nwith torch.no_grad():\n    for i, (data, labels) in tqdm(enumerate(test_loader, 0)):\n        data, labels = data.to(device), labels.to(device)\n        output1 = model(data)\n        sm = nn.Softmax(dim=1)(output1)\n        pred = sm.max(1, keepdim=True)[1]    \n        preds = np.hstack((preds, torch.squeeze(pred).cpu().numpy()))","8312999d":"f = open(\"submission.csv\", \"w\")\nf.write(\"Id,Category\\n\")\nfor (n,_),p in zip(test_loader.dataset.samples,preds):\n    f.write(\"{},{}\\n\".format(n.split('\/')[-1].split('.')[0], int(p)))\nf.close()","4741fb01":"# Notebook example using Kaggle GPU","384d850b":"# Test","f8b79312":"# Data Loading & Model creation","a4684d68":"# Train"}}