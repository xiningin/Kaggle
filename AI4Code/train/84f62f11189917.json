{"cell_type":{"ae77b3d0":"code","bad8a66f":"code","a9bff0d0":"code","03b70137":"code","a29df072":"code","b6d4ec6d":"code","0a10b817":"code","ce410853":"code","783f7880":"code","08ae5580":"code","325a37f0":"code","3749dc45":"code","8c91f4ea":"markdown","1b1ba31a":"markdown","b6cba337":"markdown","933f6f9f":"markdown","7b66a8d5":"markdown","f320048f":"markdown","60c5031b":"markdown","575b2802":"markdown","0e6dedee":"markdown"},"source":{"ae77b3d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bad8a66f":"\n%matplotlib inline\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\nimport random\nfrom scipy import stats\nfrom scipy.optimize import fmin","a9bff0d0":"f = lambda x: x*2+17+np.random.randn(len(x))*10","03b70137":"x = np.linspace(-1,20,1000)\nplt.plot(x,f(x))\nplt.xlim([-1,20])\nplt.ylim([0,100])\nplt.show()","a29df072":"x = np.random.random(500000)*100\ny = f(x) \nm = len(y)","b6d4ec6d":"from random import shuffle\n\nx_shuf = []\ny_shuf = []\nindex_shuf = list(range(len(x)))\nshuffle(index_shuf)\nfor i in index_shuf:\n    x_shuf.append(x[i])\n    y_shuf.append(y[i])","0a10b817":"h = lambda theta_0,theta_1,x: theta_0 + theta_1*x","ce410853":"cost = lambda theta_0,theta_1, x_i, y_i: 0.5*(h(theta_0,theta_1,x_i)-y_i)**2","783f7880":"theta_old = np.array([0.,0.])\ntheta_new = np.array([1.,1.]) # The algorithm starts at [1,1]\nn_k = 0.000005 # step size","08ae5580":"iter_num = 0\ns_k = np.array([float(\"inf\"),float(\"inf\")])\nsum_cost = 0\ncost_list = []","325a37f0":"for j in range(10):\n    for i in range(m):\n        iter_num += 1\n        theta_old = theta_new\n        s_k[0] = (h(theta_old[0],theta_old[1],x[i])-y[i])\n        s_k[1] = (h(theta_old[0],theta_old[1],x[i])-y[i])*x[i]\n        s_k = (-1)*s_k\n        theta_new = theta_old + n_k * s_k\n        sum_cost += cost(theta_old[0],theta_old[1],x[i],y[i])\n        if (i+1) % 10000 == 0:\n            cost_list.append(sum_cost\/10000.0)\n            sum_cost = 0   \n            \nprint(\"Local minimum occurs where:\")\nprint(\"theta_0 =\", theta_new[0])\nprint(\"theta_1 =\", theta_new[1])","3749dc45":"iterations = np.arange(len(cost_list))*10000\nplt.plot(iterations,cost_list)\nplt.xlabel(\"iterations\")\nplt.ylabel(\"avg cost\")\nplt.show()","8c91f4ea":" cost goes down quickly at first, but starts to level off as we go through more iterations:","1b1ba31a":"Run stochastic gradient descent algorithm . To track progress get an average cost from the last 10,000 steps and append to list then run entore list 10 times ","b6cba337":"Hypothesis  function","933f6f9f":"create a set of 500,000 points around the line $y = 2x+17+\\epsilon$, for values of x between 0 and 100:","7b66a8d5":"Randomly shuffle around our dataset.","f320048f":"cosy function","60c5031b":"we plot our cost versus the number of iterations","575b2802":"Function f(x) = \ud835\udc66=2\ud835\udc65+17+\ud835\udf16","0e6dedee":"values for $\\theta_0$ and $\\theta_1$ are close to their true values of 17 and 2."}}