{"cell_type":{"0beb92db":"code","b05fc6f1":"code","d430ebde":"code","19013b99":"code","b79939d4":"code","dad85472":"code","de42f1b6":"code","e2131d7b":"code","a92e395d":"code","3c000f18":"code","23ad7868":"code","c5d45596":"code","757cae5f":"code","c03ff0ab":"code","d97a0cc2":"code","4abc6e05":"code","2ad00b7e":"code","ca2a6fd4":"code","fe7be218":"code","f62a1e69":"markdown","da28014c":"markdown","e7822cd4":"markdown","0c0dd89e":"markdown","4190ac88":"markdown","ca6e15df":"markdown","084b51c7":"markdown","842a2f53":"markdown","9c000085":"markdown","f69892e5":"markdown","23f511e9":"markdown","46bdafee":"markdown","f00f4b6b":"markdown","b99d0a9c":"markdown"},"source":{"0beb92db":"import pandas as pd\nimport numpy as np\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\napplication_train = pd.read_csv('..\/input\/application_train.csv')","b05fc6f1":"application_sample1 = application_train.loc[application_train.TARGET==1].sample(frac=0.1, replace=False)\nprint('label 1 sample size:', str(application_sample1.shape[0]))\napplication_sample0 = application_train.loc[application_train.TARGET==0].sample(frac=0.1, replace=False)\nprint('label 0 sample size:', str(application_sample0.shape[0]))\napplication = pd.concat([application_sample1, application_sample0], axis=0).sort_values('SK_ID_CURR')","d430ebde":"categorical_list = []\nnumerical_list = []\nfor i in application.columns.tolist():\n    if application[i].dtype=='object':\n        categorical_list.append(i)\n    else:\n        numerical_list.append(i)\nprint('Number of categorical features:', str(len(categorical_list)))\nprint('Number of numerical features:', str(len(numerical_list)))","19013b99":"from sklearn.preprocessing import Imputer\napplication[numerical_list] = Imputer(strategy='median').fit_transform(application[numerical_list])","b79939d4":"del application_train; gc.collect()\napplication = pd.get_dummies(application, drop_first=True)\nprint(application.shape)","dad85472":"X = application.drop(['SK_ID_CURR', 'TARGET'], axis=1)\ny = application.TARGET\nfeature_name = X.columns.tolist()","de42f1b6":"def cor_selector(X, y):\n    cor_list = []\n    # calculate the correlation with y for each feature\n    for i in X.columns.tolist():\n        cor = np.corrcoef(X[i], y)[0, 1]\n        cor_list.append(cor)\n    # replace NaN with 0\n    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n    # feature name\n    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-100:]].columns.tolist()\n    # feature selection? 0 for not select, 1 for select\n    cor_support = [True if i in cor_feature else False for i in feature_name]\n    return cor_support, cor_feature","e2131d7b":"cor_support, cor_feature = cor_selector(X, y)\nprint(str(len(cor_feature)), 'selected features')","a92e395d":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import MinMaxScaler\nX_norm = MinMaxScaler().fit_transform(X)\nchi_selector = SelectKBest(chi2, k=100)\nchi_selector.fit(X_norm, y)","3c000f18":"chi_support = chi_selector.get_support()\nchi_feature = X.loc[:,chi_support].columns.tolist()\nprint(str(len(chi_feature)), 'selected features')","23ad7868":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nrfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=100, step=10, verbose=5)\nrfe_selector.fit(X_norm, y)","c5d45596":"rfe_support = rfe_selector.get_support()\nrfe_feature = X.loc[:,rfe_support].columns.tolist()\nprint(str(len(rfe_feature)), 'selected features')","757cae5f":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\n\nembeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), '1.25*median')\nembeded_lr_selector.fit(X_norm, y)","c03ff0ab":"embeded_lr_support = embeded_lr_selector.get_support()\nembeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\nprint(str(len(embeded_lr_feature)), 'selected features')","d97a0cc2":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier\n\nembeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), threshold='1.25*median')\nembeded_rf_selector.fit(X, y)","4abc6e05":"embeded_rf_support = embeded_rf_selector.get_support()\nembeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\nprint(str(len(embeded_rf_feature)), 'selected features')","2ad00b7e":"from sklearn.feature_selection import SelectFromModel\nfrom lightgbm import LGBMClassifier\n\nlgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n\nembeded_lgb_selector = SelectFromModel(lgbc, threshold='1.25*median')\nembeded_lgb_selector.fit(X, y)","ca2a6fd4":"embeded_lgb_support = embeded_lgb_selector.get_support()\nembeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\nprint(str(len(embeded_lgb_feature)), 'selected features')","fe7be218":"pd.set_option('display.max_rows', None)\n# put all selection together\nfeature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support,\n                                    'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgb_support})\n# count the selected times for each feature\nfeature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n# display the top 100\nfeature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\nfeature_selection_df.index = range(1, len(feature_selection_df)+1)\nfeature_selection_df.head(100)","f62a1e69":"### Stratified Sampling (ratio = 0.1)","da28014c":"### Deal with Categorical features: OneHotEncoding","e7822cd4":"###  <a id='2-3-3'>3.3 LightGBM<\/a>\n**Note**\n- Normalization: No\n- Impute missing values: No","0c0dd89e":"###  <a id='2-1-2'>1.2 Chi-2<\/a>\n\n**Note**\n- Normalization: MinMaxScaler (values should be bigger than 0)\n- Impute missing values: yes","4190ac88":"## <a id='2-1'>1 Filter<\/a>\n- documentation for **SelectKBest**: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.SelectKBest.html\n\n###  <a id='2-1-1'>1.1 Pearson Correlation<\/a>\n**Note**\n- Normalization: no\n- Impute missing values: yes","ca6e15df":"## <a id='2-3'>3. Embeded<\/a>\n- documentation for **SelectFromModel**: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.SelectFromModel.html\n###  <a id='2-3-1'>3.1 Logistics Regression L1<\/a>\n**Note**\n- Normalization: Yes\n- Impute missing values: Yes","084b51c7":"# <a id='2'>Feature Selection<\/a>\n- select **100** features from 226\n- **xxx_support**: list to represent select this feature or not\n- **xxx_feature**: the name of selected features","842a2f53":"# <a id='1'>Prepare<\/a>","9c000085":"### Feature matrix and target","f69892e5":"# <a id='3'>Summary<\/a>","23f511e9":"### Impute missing values","46bdafee":"- <a href='#1'>Prepare<\/a>  \n- <a href='#2'>Feature Selection<\/a>\n    - <a href='#2-1'>1. Filter<\/a>\n        - <a href='#2-1-1'>1.1 Pearson Correlation<\/a>\n        - <a href='#2-1-2'>1.2 Chi-2<\/a>\n    - <a href='#2-2'>2. Wrapper<\/a>\n    - <a href='#2-3'>3. Embeded<\/a>\n        - <a href='#2-3-1'>3.1 Logistics Regression L1<\/a>\n        - <a href='#2-3-2'>3.2 Random Forest<\/a>\n        - <a href='#2-3-3'>3.3 LightGBM<\/a>\n- <a href='#3'>Summary<\/a>","f00f4b6b":"## <a id='2-2'>2. Wrapper<\/a>\n- documentation for **RFE**: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.RFE.html\n\n**Note**\n- Normalization: depend on the used model; yes for LR\n- Impute missing values: depend on the used model; yes for LR\n","b99d0a9c":"###  <a id='2-3-2'>3.2 Random Forest<\/a>\n**Note**\n- Normalization: No\n- Impute missing values: Yes"}}