{"cell_type":{"13ef27da":"code","341d9096":"code","4d27f300":"code","f7d6ece5":"code","2b1cc7da":"code","0428012b":"code","cb91bea3":"code","ab1fba45":"code","3d6ca61d":"code","7d7389be":"code","a8273834":"code","737175ba":"code","d0e7d64b":"code","cd5a4900":"code","311133bb":"code","0c920ae7":"code","001044bb":"code","b7e92565":"code","b6cc1a2e":"code","a51d3d70":"code","5829f32b":"markdown","4b2a4419":"markdown","b85525e8":"markdown","4520bc70":"markdown","530d2fc5":"markdown","4dda792b":"markdown","8bb01347":"markdown","550e799c":"markdown"},"source":{"13ef27da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","341d9096":"## Most Important\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\n\n## less Important\nfrom functools import partial\nimport os\nfrom scipy import stats\nimport missingno as msno\nimport joblib\nimport tarfile\nimport shutil\nimport urllib\n\n## Sklearn\nfrom sklearn import datasets\n## Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n## Metrics\nfrom sklearn.metrics import accuracy_score\n\n## tensorflow & Keras\nimport tensorflow as tf    ## i will use tf for every thing and for keras using tf.keras","4d27f300":"train_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntrain_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/train')\n\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntrain_images_paths.head()","f7d6ece5":"img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1","2b1cc7da":"print('Number of Instances in train_set =>', len(train_images_paths))\nprint('Number of Instances in train_labels =>', len(train_labels))\n\nprint()\n\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is =>', img.shape)","0428012b":"import cv2\n","cb91bea3":"train_full_labels = train_labels['label'].values\n# train_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\ntrain_full_set = np.empty((13440, 32, 32, 1), dtype=np.float32)  #take only the binary channel\n\nfor idx, path in enumerate(train_images_paths):\n#     img = plt.imread(path)\n#     img = img[:,:,:3]\n#     train_full_set[idx] = img\n    img = cv2.imread(path, 2)\n    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n    train_full_set[idx] = img.reshape((32, 32, 1))\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint('train_full_labels.shape =>', train_full_labels.shape)","ab1fba45":"X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.2, shuffle=True, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)","3d6ca61d":"model = tf.keras.models.Sequential([\n#     tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu',input_shape=(32, 32, 3)),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu',input_shape=(32, 32, 1)),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(29, activation='softmax')\n \n])","7d7389be":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nearly_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","a8273834":"history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=10, batch_size=32, callbacks=[early_stopp])","737175ba":"pd.DataFrame(history.history).plot(figsize=(10, 6));","d0e7d64b":"loss_all_data, acc_all_data = model.evaluate(train_full_set, train_full_labels, verbose=0)\nprint('loss_all_data =>', loss_all_data)\nprint('acc_all_data =>', acc_all_data)","cd5a4900":"test_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\ntest_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()","311133bb":"print('Number of Instances in test_set is', len(test_images_paths))","0c920ae7":"# test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\ntest_full_set = np.empty((3360, 32, 32, 1), dtype=np.float32)  #take only the binary channel\n\nfor idx, path in enumerate(test_images_paths):\n#     img = plt.imread(path)\n#     img = img[:,:,:3]\n#     test_full_set[idx] = img\n    img = cv2.imread(path, 2)\n    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n    train_full_set[idx] = img.reshape((32, 32, 1))\n    \nprint('test_full_set.shape =>', test_full_set.shape)","001044bb":"y_preds_classes = np.argmax(model.predict(test_full_set), axis=-1)","b7e92565":"test_labels['label'] = y_preds_classes","b6cc1a2e":"test_labels","a51d3d70":"test_labels[['id', 'label']].to_csv('\/kaggle\/working\/submission.csv', index=False)","5829f32b":"## Explore the Data","4b2a4419":"## Evaluation on Testing DataSet","b85525e8":"## Data Preprocessing","4520bc70":"## Loading the Data and Look at the Big Picture","530d2fc5":"`Only for training here`","4dda792b":"## Model Training","8bb01347":"## Done :D","550e799c":"## Split the Data"}}