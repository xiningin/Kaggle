{"cell_type":{"2d0612c7":"code","2a1b70e1":"code","cc4470b1":"code","6b256be5":"code","a47cc497":"code","184a0ade":"code","f632e187":"code","379fef36":"code","aa7ba864":"code","a409bc69":"code","d7948478":"code","5186c871":"code","2b2e90f9":"code","04913454":"code","63475068":"code","078cf463":"code","5d8af2c8":"code","3dda8559":"code","49fdf847":"code","b22d8fdc":"code","3df2aa9e":"code","41343eb2":"code","e163e5b6":"code","5fbfd4d3":"code","cc79105b":"code","7d54b4af":"code","42917b78":"code","48472c9a":"code","38068e78":"code","f21f75ea":"code","04aa3439":"code","a94d8328":"code","8adbb4ff":"code","d602f1c7":"code","ca1033b7":"code","a09a16ff":"code","d26169d9":"code","69f11b97":"code","5bfe2d93":"code","ea21d31b":"code","10a94410":"code","3e601f1f":"code","9aa095e2":"code","79bb1372":"code","16c34ab2":"code","1bbdfad3":"code","f8489594":"code","6b762d78":"code","eb9a8843":"code","72ad2ab6":"code","4a5b02d7":"code","77d58c41":"code","17879839":"code","0387272c":"code","22f4b9aa":"code","3254839a":"code","77dd40c1":"code","9a3abc35":"code","3fc31c83":"code","ff274e8d":"code","aa391072":"code","8b13aaa4":"code","fb7bcd4d":"code","9ccc139c":"code","8dc6e6d4":"code","78b1569b":"code","b7554af6":"code","5b7af4ba":"code","7c2f3ca7":"code","4df3dd64":"code","c3529c37":"code","eb668d50":"code","d44c7842":"markdown","3a3be1f8":"markdown","ceaddd89":"markdown","547c0c78":"markdown","eac63624":"markdown","a8fa020e":"markdown","26dca2af":"markdown","12a0d2d9":"markdown","a36d3ddc":"markdown","e71d3860":"markdown","5ad5d29c":"markdown","8ebbf268":"markdown","926c4c8e":"markdown","b5c0259d":"markdown","5e55fbc4":"markdown","c53b53a4":"markdown","1df335ee":"markdown","5420205e":"markdown","214ac64d":"markdown","12b3ad15":"markdown","89ef679b":"markdown","e5ada621":"markdown","a2d1f72e":"markdown","e45d64c2":"markdown","59c81593":"markdown","cc33f999":"markdown","e959da30":"markdown","4ec913b8":"markdown","e601b9ce":"markdown","b8b8fdd1":"markdown","231f5e0c":"markdown","7dcdeb94":"markdown","47b9f678":"markdown","3492831e":"markdown","47e061a3":"markdown","46352922":"markdown","cc1b362b":"markdown","de72b1f9":"markdown","f01cbcbb":"markdown","60e8a632":"markdown","d010d351":"markdown","a131b2f7":"markdown","7385ac7c":"markdown","b737bdd0":"markdown","6977f148":"markdown","1447f526":"markdown","43ef407b":"markdown","15af29c2":"markdown","80b31c74":"markdown","d6ed60ac":"markdown","9cfea9b8":"markdown","9d803556":"markdown","fa2c6faf":"markdown","7f2d5e82":"markdown","d6e9ca32":"markdown","d5627cdf":"markdown","19523b63":"markdown","db68474e":"markdown","a38bd171":"markdown","30716925":"markdown","a1ecd46a":"markdown","8d0e46b9":"markdown","0dc6ed8a":"markdown","fdd0fa5a":"markdown","161e8ff2":"markdown","aa5fe3a9":"markdown","2b27a961":"markdown","b0bd7466":"markdown","9b35171f":"markdown","a050cf55":"markdown","55ea8045":"markdown","e4ec92b1":"markdown"},"source":{"2d0612c7":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, ElasticNetCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.stats.stats import pearsonr\nfrom IPython.display import HTML\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error, accuracy_score, classification_report","2a1b70e1":"df_day = pd.read_csv('https:\/\/raw.githubusercontent.com\/Machine-Learning-Wilp\/BikeSharing\/main\/day.csv')","cc4470b1":"df_day.head()","6b256be5":"df_hr = pd.read_csv('https:\/\/raw.githubusercontent.com\/Machine-Learning-Wilp\/BikeSharing\/main\/hour.csv')","a47cc497":"df_hr.head()","184a0ade":"df = pd.read_csv('https:\/\/raw.githubusercontent.com\/Machine-Learning-Wilp\/BikeSharing\/main\/hour.csv')","f632e187":"# 2.a \ndf.head()","379fef36":"# 2.b\ndf.describe()","aa7ba864":"# 2.b\ndf.shape","a409bc69":"# 2.c\ndf.info()","d7948478":"# 2.c\ndf.apply(lambda x: len(x.unique()))","5186c871":"df.select_dtypes(exclude=[np.number])","2b2e90f9":"sns.pairplot(df,vars=['temp','atemp','hum','windspeed','casual', 'registered','cnt'])\nplt.show()","04913454":"plt.figure(figsize=(25, 10))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'season', y = 'cnt', data = df)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'mnth', y = 'cnt', data = df)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = df)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'holiday', y = 'cnt', data = df)\nplt.subplot(2,3,5)\nsns.boxplot(x = 'weekday', y = 'cnt', data = df)\nplt.subplot(2,3,6)\nsns.boxplot(x = 'workingday', y = 'cnt', data = df)\nplt.show()","63475068":"df_c = df.copy()\ndf_c['holiday'] = df_c['holiday'].replace({0: 'not holiday',1: 'holiday'})","078cf463":"fig, ax = plt.subplots(figsize=(10,5))\nsns.barplot(x = 'holiday', y = 'cnt', data = df_c, ax=ax)\nax.set(title='Count of bikes during holidays vs not holidays')","5d8af2c8":"fig, ax = plt.subplots(figsize=(20,5))\nsns.barplot(data=df, x='weekday', y='cnt', ax=ax)\nax.set(title='Count of bikes during different days')","3dda8559":"sorted(df['weekday'].unique())","49fdf847":"df_c['weekend'] = df_c['weekday'].replace({0: 'weekend',6: 'weekend',1:'weekday',2:'weekday',3:'weekday',4:'weekday',5:'weekday'})\ndf_c['workingday'] = df_c['workingday'].replace({0: 'not workingday',1: 'workingday'})","b22d8fdc":"fig, ax = plt.subplots(figsize=(10,5))\nsns.barplot(x = 'weekend', y = 'cnt', data = df_c, ax=ax)\nax.set(title='Count of bikes during weekends vs weekdays')","3df2aa9e":"# 2. d. (ii) Effects of holiday vs weekend\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(20,5))\nsns.barplot(data=df_c, x='weekend', y='cnt', ax=ax1)\nsns.barplot(data=df_c, x='holiday', y='cnt', ax=ax2)\n\nfig, ax = plt.subplots(figsize=(20,5))\nsns.barplot(x = 'workingday', y = 'cnt', data = df_c, ax=ax)","41343eb2":"type_of_day = ['Weekends','Holiday'] \nX_axis = np.arange(2)\nplt.bar(range(2), [df_c[df_c['weekday'] ==6]['cnt'].sum() + df_c[df_c['weekday'] ==0]['cnt'].sum() ,df_c[df_c['holiday'] =='holiday']['cnt'].sum()])\nplt.xticks(X_axis, type_of_day)\nplt.xlabel(\"difference between holiday and weekends on the count\")\nplt.ylabel(\"cnt\")\nplt.show()","e163e5b6":"# 2. d. (iii) Effects of temp vs atemp\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(20,5))\nsns.scatterplot(x=df['temp'], y=df['cnt'], ax=ax1 ,color='red')\nax1.set(title=\"Relation between temperature and count\")\nsns.scatterplot(x=df['atemp'], y=df['cnt'], ax=ax2,color='pink')\nax2.set(title=\"Relation between feeling temperature and count\")","5fbfd4d3":"df_c['temp_diff'] = (df_c['temp'] - df_c['atemp']) \/ df_c['temp']\nfig, ax = plt.subplots(figsize=(20,5))\nsns.distplot(df_c['temp_diff'], ax=ax)","cc79105b":"df_c['temp'].corr(df_c['atemp'])","7d54b4af":"sns.lmplot(x='temp', y='atemp', data=df_c)","42917b78":"df[['temp','atemp']].plot(figsize=(20, 7), color=['red', 'pink'])","48472c9a":"df_c['sum_casual_registered'] = df_c['casual'] + df_c['registered']\ndf_c['count_difference'] = np.where(df_c['sum_casual_registered'] == df['cnt'], 0, 1)","38068e78":"print ('Total number of rows where count is not equal to sum of registered and casual users: '+str((df_c['count_difference'] != 0).sum()))","f21f75ea":"# 2. d. (v) Effects of temp, humidity, windspeed on count\nfig, (ax1,ax2,ax3) = plt.subplots(ncols=3, figsize=(20,5))\nsns.regplot(x=df['windspeed'], y=df['cnt'], ax=ax3)\nax3.set(title=\"Relation between windspeed and count\")\nsns.regplot(x=df['hum'], y=df['cnt'], ax=ax2 ,color='gray')\nax2.set(title=\"Relation between humidity and count\")\nsns.regplot(x=df['temp'], y=df['cnt'], ax=ax1 ,color='red')\nax1.set(title=\"Relation between temperature and count\")","04aa3439":"# 3.a.\ndf.isnull().sum()","a94d8328":"df_new=df[['season', 'yr', 'mnth', 'holiday', 'weekday','workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed','cnt']]","8adbb4ff":"print(\"Size of df_new before duplicate removal: \" + str(len(df_new)))","d602f1c7":"# removing duplicates\ndf_new = df_new.drop_duplicates()","ca1033b7":"print(\"Size of df_new after duplicate removal: \" + str(len(df_new)))","a09a16ff":"# Converting to 'category' data type \ndf_new['season']=df_new['season'].astype('category')\ndf_new['weathersit']=df_new['weathersit'].astype('category')\ndf_new['yr']=df_new['yr'].astype('category')\ndf_new['mnth']=df_new['mnth'].astype('category')\ndf_new['weekday']=df_new['weekday'].astype('category')\ndf_new['workingday']=df_new['workingday'].astype('category')","d26169d9":"df_new.head()","69f11b97":"# Performing outlier removal for the attributes with numeral values\n\ncolumn_list_outlier_removal = ['temp','atemp','hum','windspeed','cnt']\n\nfor column in column_list_outlier_removal:\n    Q1=df_new[column].quantile(0.25)\n    Q3=df_new[column].quantile(0.75)\n    IQR=Q3-Q1\n    LL= round(Q1 - 1.5*IQR,1) # Lower limit for 1.5IQR method\n    UL = round(Q3 + 1.5 *IQR,1) # Upper limit for 1.5IQR method\n    df_new[column] = np.where((df_new[column] > UL), UL, df_new[column])\n    df_new[column] = np.where((df_new[column] < LL), LL, df_new[column])","5bfe2d93":"# normalization\ncol_norm = ['temp','atemp','hum','windspeed','cnt']\nmin_max = MinMaxScaler()\nx = df_new[col_norm].values\nx_scaled = min_max.fit_transform(x)\ndf_temp = pd.DataFrame(x_scaled, columns=col_norm, index = df_new.index)\ndf_new[col_norm] = df_temp","ea21d31b":"df_new.head()","10a94410":"df_new.describe()","3e601f1f":"df_new.shape","9aa095e2":"# 3 . c \ncorr = df_new.corr()\nplt.figure(figsize=(15,15))\nsns.heatmap(corr, annot=True)\nplt.show()","79bb1372":"df_tgt=df_new['cnt']\ndf_remain=df_new.copy().drop(['cnt'],axis=1)\ncc_cut_off=.2\ncc_dic={}\nfor var in df_remain.columns:\n    cc_dic[var]=round(pearsonr(df_tgt,df_remain[var])[0],2)\ncc_dic = sorted(cc_dic.items(), key=lambda x: x[1], reverse=True)\nfor i in cc_dic:\n    print(\"Correlation between Count and \"+ i[0] + \" is \" + str(i[1]))","16c34ab2":"df_new_with_dummy = pd.get_dummies(df_new)","1bbdfad3":"df_new_with_dummy.head()","f8489594":"df_new_with_dummy.shape","6b762d78":"df_new_with_dummy.describe()","eb9a8843":"df_target=df_new_with_dummy['cnt']\ndf_feature=df_new_with_dummy.drop(['cnt'],axis=1)","72ad2ab6":"lr = LinearRegression()\nlr.fit(df_feature,df_target )\nrfe = RFE(lr, 15)\nrfe = rfe.fit(df_feature, df_target)","4a5b02d7":"lst_feature = list(zip(df_feature.columns,rfe.support_,rfe.ranking_))\nsel_dic = sorted(zip(df_feature.columns,rfe.ranking_), key=lambda x: x[1], reverse=True)\nhtml = [\"<table width=100%>\"]\nhtml.append(\"<tr>\")\nhtml.append(\"<td><strong>{0}<\/strong><\/td>\".format(\"Attribute\"))\nhtml.append(\"<td><strong>{0}<\/strong><\/td>\".format(\"Rank\"))\nhtml.append(\"<\/tr>\")            \nfor i in sel_dic:\n    html.append(\"<tr>\")\n    html.append(\"<td>{0}<\/td>\".format(i[0]))\n    html.append(\"<td>{0}<\/td>\".format(i[1]))\n    html.append(\"<\/tr>\") \nhtml.append(\"<\/table>\")\nHTML(''.join(html))","77d58c41":"sel_col = df_feature.columns[rfe.support_]\nsel_col = sel_col.to_list()","17879839":"sel_col.append('temp')","0387272c":"X = df_feature[sel_col]","22f4b9aa":"Y = df_target","3254839a":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) # 70% training and 30% test","77dd40c1":"X_train.shape","9a3abc35":"X_train.head()","3fc31c83":"X_train.describe()","ff274e8d":"X_test.shape","aa391072":"X_test.head()","8b13aaa4":"X_test.describe()","fb7bcd4d":"y_train.shape\n","9ccc139c":"y_train.head()","8dc6e6d4":"y_train.describe()","78b1569b":"y_test.shape","b7554af6":"y_test.head()","5b7af4ba":"y_test.describe()","7c2f3ca7":"models = [LinearRegression(),Ridge(),HuberRegressor(),ElasticNetCV(),DecisionTreeRegressor(),RandomForestRegressor(),ExtraTreesRegressor(),\n         GradientBoostingRegressor()]","4df3dd64":"performance = {}\ndict_error={}\nhtml = []\nfor model in models:\n    str_model = str(model).replace(\"(\",\"\").replace(\")\",\"\")\n    html.append(\"<table width=100%>\")\n    kfold = model_selection.KFold(n_splits=5)\n    pred = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring='neg_mean_squared_error')\n    cv_score = pred.mean()\n    clf=model\n    clf.fit(X_train,y_train)\n    test_pred=clf.predict(X_test)\n    error = y_test - test_pred\n    dict_error[str_model] = error\n    rmsle = np.sqrt(((test_pred - y_test) ** 2).mean())\n    performance[str_model] = {'accuracy':clf.score(X_test, y_test),'RMSLE':rmsle}\n    html.append(\"<tr>\")\n    html.append(\"<td><strong>{0}<\/strong><\/td>\".format(\"Model\"))\n    html.append(\"<td><strong>{0}<\/strong><\/td>\".format(str_model))\n    html.append(\"<\/tr>\")\n    html.append(\"<tr>\")\n    html.append(\"<td>{0}<\/td>\".format(\"CV Score\"))\n    html.append(\"<td>{0}<\/td>\".format(abs(cv_score)))\n    html.append(\"<\/tr>\")\n    html.append(\"<tr>\")\n    html.append(\"<td>{0}<\/td>\".format(\"Accuracy\"))\n    html.append(\"<td>{0}<\/td>\".format(clf.score(X_test, y_test)))\n    html.append(\"<\/tr>\")\n    html.append(\"<tr>\")\n    html.append(\"<td>{0}<\/td>\".format(\"RMSLE (loss function)\"))\n    html.append(\"<td>{0}<\/td>\".format(clf.score(X_test, y_test)))\n    html.append(\"<\/tr>\")\n    html.append(\"<tr>\")\n    html.append(\"<td>{0}<\/td>\".format(\"Mean Squared Error\"))\n    html.append(\"<td>{0}<\/td>\".format(str(np.sqrt(mean_squared_error(y_test, test_pred)))))\n    html.append(\"<\/tr>\")\n    html.append(\"<\/table>\")\n    html.append(\"<br\/>\")\n    html.append(\"<br\/>\")\nHTML(''.join(html))","c3529c37":"for key, value in dict_error.items():\n    print(key)\n    fig, ax = plt.subplots()\n    ax.scatter(y_test, value ,color = 'red')\n    ax.axhline(lw=3, color='black')\n    ax.set_xlabel('Observed')\n    ax.set_ylabel('Error')\n    plt.show()","eb668d50":"rmsle_frame=pd.DataFrame(performance)\nrmsle_frame.plot.bar(figsize=(20, 7))","d44c7842":"**ML Group 011**\n\n  KARTHIK S R **(2020fc04065)**  \n  RANGINENI SAISASIDHAR **(2020fc04066)**  \n  SHRUTI SINGH **(2020fc04067)**  ","3a3be1f8":"## 3. Data Pre-processing and cleaning   ","ceaddd89":"## 2. Data Visualization and exploration","547c0c78":"we are eliminating features using Recursive Feature Elimation and LinearRegression","eac63624":"**Removing redundant & unwanted columns**","a8fa020e":"List the feature based on rank","26dca2af":"**2. a. Print the confusion matrix. Provide appropriate analysis for the same.**","12a0d2d9":"for the purpose of finding the relationship let us assume a hypothesis that sum of casual and registered users is equal to count and test this hypothesis.","a36d3ddc":"Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv\n\n- instant: record index\n- dteday : date\n- season : season (1:winter, 2:spring, 3:summer, 4:fall)\n- yr : year (0: 2011, 1:2012)\n- mnth : month ( 1 to 12)\n- hr : hour (0 to 23)\n- holiday : weather day is holiday or not (extracted from [Web Link])\n- weekday : day of the week\n- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n- weathersit :  \n    1: Clear, Few clouds, Partly cloudy, Partly cloudy  \n    2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  \n    3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  \n    4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog  \n- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n- hum: Normalized humidity. The values are divided to 100 (max)\n- windspeed: Normalized wind speed. The values are divided to 67 (max)\n- casual: count of casual users\n- registered: count of registered users\n- cnt: count of total rental bikes including both casual and registered ","e71d3860":"**Error Analysis**","5ad5d29c":"**Correlational Analysis**","8ebbf268":"Model training done as part of 1.b. so let us compare the results","926c4c8e":"**Data Preporcessing**","b5c0259d":"weekday value ranges from 0 to 6, we can assume that 0 is sunday and 6 is saturday and hence 0 and 6 are the weekends","5e55fbc4":"**Feature Transformations**","c53b53a4":"**Select Columns**","1df335ee":"Target variable into Y","5420205e":"**4.b. Split the dataset into training and test sets.**","214ac64d":"**3.b. Apply the feature transformation techniques like Standardization, Normalization, etc. You are free to apply the appropriate transformations depending upon the structure and the complexity of your dataset.**","12b3ad15":"# Bike Sharing Dataset\n","89ef679b":"**2.d.  -  Determine the effect of holiday on the count of rental bikes**","e5ada621":"**Removing duplicates**","a2d1f72e":"**2.d. Try exploring the data and see what insights can be drawn from the dataset.** ","e45d64c2":"From dataset we know that 'temp','atemp','hum','windspeed','casual', 'registered','cnt' attributes are numerical values\nhence plotting pair plot to understand numerical data","59c81593":"**2.d. -  Identify the relationship between casual, registered and count.**","cc33f999":"Since we know from our correlation analysis, temperature is correlated to count. So we are adding the temperature attribute to the features selected by RFE","e959da30":"## 1. Import Libraries\/Dataset\n   ","4ec913b8":"**Converting to 'category' data type**","e601b9ce":"From above we can see that count is very less on holidays compared to weekends","b8b8fdd1":"**1.a. Perform Model Development using at least three models, separately. You are free to apply any Machine Learning Models on the dataset. Deep Learning Models are strictly not allowed.**","231f5e0c":"**1. Model Building**","7dcdeb94":"plotting the comparision of accuracy and RMSLE of the 4 models that we built","47b9f678":"### Part A (13 marks)\n\n1. Import Libraries\/Dataset  \n    a. Download the dataset  \n    b. Import the required libraries  \n\n2. Data Visualization and Exploration  \n   a. Print at least 5 rows for sanity check to identify all the features present in the dataset and if the target matches with them.  \n   b. Print the description and shape of the dataset.  \n   c. Provide appropriate visualization to get an insight about the dataset.  \n   d. Try exploring the data and see what insights can be drawn from the dataset.  \n      - Determine the effect of holiday on the count of rental bikes  \n      - Analyze the difference between holiday and weekends on the count.   \n      - Analyze the difference between temperature and feeling temperature.  \n      - Identify the relationship between casual, registered and count.  \n      - Identify the effect of:  \n        a. Humidity  \n        b. Windspeed  \n        c. Temperature  \n        on the count\n\n3. Data Pre-processing and cleaning  \n    a. Do the appropriate preprocessing of the data like identifying NULL or Missing Values if any, handling of outliers if present in the dataset, skewed data etc. Apply appropriate feature engineering techniques for them.  \n    b. Apply the feature transformation techniques like Standardization, Normalization, etc. You are free to apply the appropriate transformations depending upon the structure and the complexity of your dataset.  \n    c. Do the correlational analysis on the dataset. Provide a visualization for the same.  \n\n4. Data Preparation  \n    a. Do the final feature selection and extract them into Column X and the class label into Column into Y.  \n    b. Split the dataset into training and test sets.  \n\n### Part B (12 marks)  \n1. Model Building  \n    a. Perform Model Development using at least three models, separately. You are free to apply any Machine Learning Models on the dataset. Deep Learning Models are strictly not allowed.  \n    b. Train the model and print the training accuracy and loss values.  \n\n2. Performance Evaluation  \n    a. Print the confusion matrix. Provide appropriate analysis for the same.  \n    b. Do the prediction for the test data and display the results for the inference.   ","3492831e":"Create dataframe, X with Final features","47e061a3":"there are no null values","46352922":"**1.a. Download the dataset**","cc1b362b":"The heatmap shows which all variable are multicollinear in nature, and which variable have high collinearity with the target variable. From the above analysis we can see that the attributes are correlated with count in the following way based on correlation values,\n\n**Positive correlation:**  \n'temp' : 0.41  \n'atemp' : 0.41  \n'yr' : 0.25  \n'season' : 0.18  \n'mnth' : 0.12  \n'windspeed' : 0.1  \n'weekday' : 0.03  \n'workingday' : 0.02  \n   \n**Negative correlation:**  \n'holiday' : -0.03  \n'weathersit' : -0.14  \n'hum' : -0.33  \n\n There is a strong correlation between independant variables temp and atemp","de72b1f9":"From the above plot we can conclude that the count decreases on holidays","f01cbcbb":"**2.b. Print the description and shape of the dataset.**","60e8a632":"Get count of null values","d010d351":"**4. Data Preparation**","a131b2f7":"**4.a. Do the final feature selection and extract them into Column X and the class label into Column into Y.**","7385ac7c":"Since dataset 'hour.csv' is having the same data of 'day.csv' with hour split-up, we are considering 'hour.csv' for our analysis","b737bdd0":"From the above correlation analysis temp and atemp are **highly correlated** with approximately **98.78% \u2261 98.8% \u2261 99%** hence there is not much difference between the two attributes","6977f148":"## Part A","1447f526":"**2. Performance Evaluation**","43ef407b":"from above our hypothesis is proved to be true and the relationship between casual, registered and count is given by,  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Count = Casual + Registered**","15af29c2":"From the plot it is evident that it is normally distributed","80b31c74":"**2.a. Print at least 5 rows for sanity check to identify all the features present in the dataset and if the target matches with them.**","d6ed60ac":"from the above plots we have the following inferences,   \n* Count is less when humidity is less than 0.2, is high when humidity is between 0.4 and 0.8 and the count starts to reduce again when the humidity starts to increase above 0.8, hence they have strong non linear relationship.\n* As the windspeed increases the count decreases hence they are inversely proportional to each other.  \n* Count is low when temperature is low or very high but the count is high when temperature is at mean level hence they have strong non linear relationship.","9cfea9b8":"Create dummy attribute and drop original attribute for which the dummy was created","9d803556":"### Part B","fa2c6faf":"Checking the data which are not numbers","7f2d5e82":"**2. b. Do the prediction for the test data and display the results for the inference.**","d6e9ca32":"**2.d. -  Analyze the difference between temperature and feeling temperature.**","d5627cdf":"From the above graph it is seen that the model **GradientBoostingRegressor** is better than other models based on **high accuracy** and **low RMSLE** values.","19523b63":"**Feature engineering**","db68474e":"**2.d. -  Identify the effect of:**  \n        &nbsp;&nbsp;&nbsp;&nbsp;a. Humidity  \n        &nbsp;&nbsp;&nbsp;&nbsp;b. Windspeed  \n        &nbsp;&nbsp;&nbsp;&nbsp;c. Temperature   \n           &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on the count","a38bd171":"**Remove outliers**","30716925":"**Normalization**","a1ecd46a":"**2.d. -  Analyze the difference between holiday and weekends on the count.**","8d0e46b9":"**1.b. Import the required libraries**","0dc6ed8a":"**3.a. Do the appropriate preprocessing of the data like identifying NULL or Missing Values if any, handling of outliers if present in the dataset, skewed data etc. Apply appropriate feature engineering techniques for them.**","fdd0fa5a":"From the above plot it is evident that count reduces on weekends and holidays i.e., on non workingdays","161e8ff2":"**1.b. Train the model and print the training accuracy and loss values.**","aa5fe3a9":"**Dummy generation**","2b27a961":"For regression models confusion matrix is not applicable so we are comparing the accuracy\/score and RMSLE of the models that we built","b0bd7466":"Running Recursive Feature Elimation with the output number of the variable equal to 15","9b35171f":"**3.c. Do the correlational analysis on the dataset. Provide a visualization for the same.**","a050cf55":"**2.c. Provide appropriate visualization to get an insight about the dataset.**","55ea8045":"Building boxplot of all categorical variables againt the target variable 'cnt' to see how each of the predictor variable stackup against the target variable.","e4ec92b1":"The correlation of target attribute (cnt i.e., count) with other attributes"}}