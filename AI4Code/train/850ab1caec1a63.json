{"cell_type":{"a819483f":"code","4a66b370":"code","c76d5ce5":"code","0eac1de8":"code","28e450ba":"code","5996a63c":"code","ca776b99":"code","30b67afe":"code","188e7a02":"code","8df96a54":"code","76c9cd2a":"code","7cb07aed":"code","253d4a74":"code","6471f127":"code","44e8ef34":"code","03e35ba5":"code","5137524e":"code","8d632e4e":"code","3ddbc4f8":"code","4e45c09c":"code","9b288b09":"code","3af9d2e6":"code","f34ff822":"code","124bf04d":"code","75fd58e9":"code","661c2a24":"code","2959394a":"code","c4b395a1":"code","0698d42b":"code","9b339259":"code","f788bbf0":"code","c93b68eb":"code","4e8b5a6d":"code","fdfdf26f":"code","aae7495b":"code","671efc8c":"code","67a48234":"code","c027be61":"code","06ea4c96":"code","a30e5b15":"code","1d6a3eac":"code","1a2628c2":"code","e320363f":"code","fadbf7e2":"markdown","650337eb":"markdown","fb27f34b":"markdown","5073ccf5":"markdown","e79f3bf6":"markdown","6dde8eaa":"markdown","4ead3106":"markdown","6c965b38":"markdown","791a37b5":"markdown","6fcc4d9d":"markdown"},"source":{"a819483f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nimport os\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a66b370":"data = pd.read_csv('\/kaggle\/input\/diamonds\/diamonds.csv')\ndata.head(200)\n#data.info()","c76d5ce5":"#Plotting all data\ndata1 = data.loc[:,[\"x\",\"y\",\"z\"]]\ndata1.plot()","0eac1de8":"# Subplots\ndata1.plot(subplots= True)\nplt.show()","28e450ba":"# Scatter Plot\ndata1.plot(kind= \"scatter\", x=\"x\", y = \"y\")\nplt.show()","5996a63c":"# Hist Plot\ndata1.plot(kind = \"hist\", y = \"y\", bins= 50, range= (0,50), density = True)","ca776b99":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind =\"hist\", y= \"y\", bins = 50,range= (0,50),density = True, ax= axes[0])\ndata1.plot(kind =\"hist\", y= \"y\", bins = 50,range= (0,50),density = True, ax= axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt\n","30b67afe":"data.head()","188e7a02":"# \u0130ndexing Pandas Time Series\ntime_list= [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list)) # string\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","8df96a54":"data2 = data.head()\ndatetime = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(datetime)\ndata2[\"datetime\"] = datetime_object\n\n#lets make date as index\ndata2 = data2.set_index(\"datetime\")\ndata2","76c9cd2a":"# read data\n#data = pd.read_csv('\/kaggle\/input\/diamonds\/diamonds.csv')\n#data= data.set_index('index_name')\ndata.head()","7cb07aed":"# \u0130ndexing using square brackets\ndata[\"clarity\"][1]","253d4a74":"#Using column attribute and row label\ndata.clarity[1]","6471f127":"#Using loc accessor\ndata[\"clarity\"][1]","44e8ef34":"#Selecting only some columns\ndata[[\"clarity\",\"carat\"]]","03e35ba5":"#Diffirent between selecting columns : series and dataframes\nprint(type(data[\"clarity\"]))     #series\nprint(type([[\"clarity\"]]))       #data frames","5137524e":"# Slicing and indexing series\ndata.loc[1:10,\"carat\":\"clarity\"]","8d632e4e":"#Reverse slicing\ndata.loc[10:1:-1,\"carat\":\"clarity\"]","3ddbc4f8":"#From something to end\ndata.loc[1:10,\"clarity\":]","4e45c09c":"#Creating boolean series\nboolean =data.carat < 0.23\ndata[boolean]","9b288b09":"### Combinin filters\nfirst_filter = data.carat < 0.23\nsecond_filter = data.price < 350\ndata[first_filter & second_filter]","3af9d2e6":"# Filtering column based others\ndata.carat[data.price <350]","f34ff822":"#plain python functions\ndef div (n):\n    return n\/2\ndata.carat.apply(div)","124bf04d":"#Or we can use lambda function\ndata.carat.apply(lambda n : n\/2)","75fd58e9":"# Defining colmn using other columns\n# data = data.drop (\"x.y\",1) # Sutun silme komutu\ndata[\"x+y\"] =data.x + data.y\ndata.head()","661c2a24":"# Our index name is this:\n\n#print(data.index.name)\n# Lets change it\n\n#data.index.name= \"index_name\"\ndata.head()","2959394a":"data.head()\n# first copy of our data to data5 then change index\ndata5 = data.copy()\n#lets make index start from 150. It is n\u0131t remarkable change but it is just example\n#data5.index_name = range(150,800,1)\ndata5.head()","c4b395a1":"# We can make one of the column as index. I actuallly did it at the beginning of manipulating data frames with pandas section\n#It was like this\n#data= data.set_index(\"#\")\n#alse you can use\n#data.index = data(\"#\")","0698d42b":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('\/kaggle\/input\/diamonds\/diamonds.csv')\ndata.head()","9b339259":"# Setting index : color is outer cut is inner index\ndata1 = data.set_index ([\"color\",\"cut\"])\ndata1.head(100)\n#data1.loc[\"clarity\",\"carat\"] # how to indexes","f788bbf0":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"], \"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","c93b68eb":"#pivoting\ndf.pivot(index = \"treatment\",columns = \"gender\", values= \"response\")","4e8b5a6d":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n#lets unstack it","fdfdf26f":"# level determines indexes\ndf1.unstack(level=0)","aae7495b":" df1.unstack(level=1)","671efc8c":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","67a48234":"df","c027be61":"# df.pivot(index=\"treatment\",columns =\"gender\",values = \"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","06ea4c96":"# We will use df\ndf","a30e5b15":"# according to treatment make means of other features\ndf.groupby(\"treatment\").mean() # mean is aggregation \/ reduction method\n#there are other methods like sum, std, max or min","1d6a3eac":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max()","1a2628c2":"# Or we can choose multipe feature\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min()","e320363f":"df.info()\n# as you can see gender is object\n#However if we use groupby , we can convert it categorical data.\n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","fadbf7e2":"# Filtering data frames","650337eb":"# Categoricals and Groupby","fb27f34b":"# Hierarchical Indexing","5073ccf5":"# Slicing data frame","e79f3bf6":"# Melting Data Frames","6dde8eaa":"# Index object and labeled data","4ead3106":"# Stacking and Unstaking Dataframe","6c965b38":"# Pivoting Data Frames","791a37b5":"# Transforming data","6fcc4d9d":"# Man\u0131pulating Data Frames With Pandas"}}