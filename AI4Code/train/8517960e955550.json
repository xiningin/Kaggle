{"cell_type":{"11936cbb":"code","cd1368a3":"code","74ea079d":"code","11812782":"code","003cec96":"code","9dca3246":"code","0dca9e1f":"code","062d7cbe":"code","797c9d78":"code","de9eac45":"code","01f9114a":"code","26a68f30":"code","7897ee84":"code","c4851540":"code","882e7854":"code","b8ab216e":"code","e09be3bf":"code","b62bc4d1":"code","117dff8e":"code","41dfa5cc":"code","a8f9b724":"code","46f4ce2d":"code","5633963c":"code","0659e0ac":"code","c1463afd":"code","a4338e3d":"code","b774ead8":"markdown","8168d1b1":"markdown","2e8b3267":"markdown","1d68e4ad":"markdown","5ba69689":"markdown","1bd40688":"markdown","7afc365d":"markdown","15b2f4f1":"markdown","13436dbb":"markdown","c905f478":"markdown","670d5b8f":"markdown","dea7ec71":"markdown","1ceb0be5":"markdown","8a5e27c9":"markdown","1d77b84e":"markdown","0a03d8cc":"markdown","389c144f":"markdown","4c48a785":"markdown","f11e4072":"markdown","028caaf2":"markdown","a98da155":"markdown","f9149ae9":"markdown","09b0bd0e":"markdown","afaa8bc1":"markdown","f137f295":"markdown","ccef999c":"markdown","8d649809":"markdown","ca2da06e":"markdown","e53f5ca2":"markdown","36165e91":"markdown","2190c2d7":"markdown","a254f071":"markdown","e91995bb":"markdown","7af802da":"markdown","7e226f46":"markdown","0669ceb3":"markdown"},"source":{"11936cbb":"import pandas as pd\n\ntrain_df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv',usecols = ['Id','Pawpularity'])\ntrain_df.head()","cd1368a3":"import cv2\nimport random\n\nimage_1 = cv2.imread('..\/input\/petfinder-pawpularity-score\/train\/' +random.choice(train_df['Id']) + '.jpg' )\nimage_2 = cv2.imread('..\/input\/petfinder-pawpularity-score\/train\/' +random.choice(train_df['Id']) + '.jpg' )\n\nprint(image_1.shape)\nprint(image_2.shape)","74ea079d":"import numpy as np\nimport cv2\n\nfrom PIL import Image\n\n\npath = '..\/input\/petfinder-pawpularity-score\/train\/'\n\nimages = []\nlabels = []\n\nimage_heights = []\nimage_widths = []\n\ncount = 1\nMax_examples = 100\n\n\nfor id_,y in zip(train_df['Id'],train_df['Pawpularity']):\n    \n    img = cv2.imread(path + id_ + '.jpg', cv2.COLOR_BGR2RGB)\n    \n    images.append(img)\n    \n    image_heights.append(img.shape[0])\n    image_widths.append(img.shape[1])\n    \n    labels.append(y-1)\n    \n    if count == Max_examples:\n        break\n    \n    count+=1\n\navg_h = sum(image_heights)\/\/len(image_heights)\navg_w = sum(image_widths)\/\/len(image_widths)\n\n    \nprint(f'average image hieght is {avg_h}')\n\nprint(f'average image width is {avg_w}')\n","11812782":"X_train = []\n\nfor img in images:\n    \n    img = cv2.resize(img,(avg_h,avg_w),interpolation = cv2.INTER_AREA)\n    img = np.array(img)\n    img = img.astype('float32')\n    img \/= 255 \n    \n    X_train.append(img)\n    \nX_train = np.array(X_train)\nprint(X_train.shape)","003cec96":"IMG_SHAPE = (avg_w,avg_h,3)","9dca3246":"Y_train = np.array(labels)\n\nY_train = Y_train.reshape(100,1)\nprint(Y_train.shape)","0dca9e1f":"#end","062d7cbe":"import tensorflow as tf","797c9d78":"Pretrained_model = tf.keras.applications.resnet50.ResNet50(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","de9eac45":"Pretrained_model.trainable = False","01f9114a":"Pretrained_model.summary()","26a68f30":"# model \nInputs = tf.keras.Input(IMG_SHAPE)\n\nx = Pretrained_model(Inputs, training=False)\n\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\nx = tf.keras.layers.Dropout(0.2)(x)\nx =  tf.keras.layers.Dense(256)(x)\nx = tf.keras.layers.Dropout(0.1)(x)\nOutputs = tf.keras.layers.Dense(100)(x)\n\nModel = tf.keras.Model(Inputs, Outputs)","7897ee84":"Optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nLoss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\nMetrics=['accuracy']\n\nModel.compile(optimizer=Optimizer,\n              loss = Loss,\n              metrics = Metrics)","c4851540":"Model.summary()","882e7854":"callbacks =[tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=10, verbose=0,\n    mode='auto', baseline=None, restore_best_weights=False\n),\ntf.keras.callbacks.ModelCheckpoint(\n    filepath = '.\/model', monitor='val_loss', verbose=1, save_best_only=True,\n    save_weights_only=False, mode='auto', save_freq='epoch',\n    options=None\n)]","b8ab216e":"history = Model.fit(X_train, Y_train, epochs=10, \n                    validation_split = 0.1, verbose = 1,callbacks = callbacks)","e09be3bf":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='lower right')\n","b62bc4d1":"#end","117dff8e":"Pretrained_model.trainable = True","41dfa5cc":"len( Pretrained_model.layers)","a8f9b724":"\nstart_ = 100\n\nfor layer in Pretrained_model.layers[:start_]:\n    layer.trainable =  False","46f4ce2d":"\nOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\nLoss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\nMetrics=['accuracy']\n\nModel.compile(optimizer=Optimizer,\n              loss = Loss,\n              metrics = Metrics)","5633963c":"Model.summary()","0659e0ac":"history = Model.fit(X_train, Y_train, epochs=10, \n                    validation_split = 0.1, verbose = 1,callbacks = callbacks)","c1463afd":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='lower right')\n","a4338e3d":"#end","b774ead8":"### Now let's convert the images in the desired format ","8168d1b1":"### Un-freeze some layers of the model","2e8b3267":"#### The above method for preparing the data is very basic and high ram consuming, If we do not have access to high ram machines we should use the Image data generator, which loads the batch of images instead of loading all the images in the ram.\n\n#### Image data generator is an efficient approach but relatively complicated, here we are trying to explore and thus I have added this simple approach instead. \n","1d68e4ad":"### Let's prepare the y_train in the correct format ","5ba69689":"## Thank you for reading, please share your thoughts\/suggestions  ","1bd40688":"#### Now We are going to compile the model and set the hyperparameters for our model, here we will be using the adam optimizer and SparseCategoricalCrossentropy as a loss function.","7afc365d":"#### Now that the pre-trained model is ready we can start developing the main model here","15b2f4f1":"### Let's have a look at train.csv","13436dbb":"<center style=\"font-family:verdana;\"><h1 style=\"background: #f4c2c2 ;\">_<\/h1><\/center>","c905f478":"## Important NOTE   ","670d5b8f":"## Feature extraction : Freeze the convolutional base","dea7ec71":"### DONE","1ceb0be5":"## Let's start the training.","8a5e27c9":"<center><h1>Fine-tuning the pre-trained mode<\/h1><\/center>","1d77b84e":"### As we can see the performance is not so good but the model's performance can be increased significantly if\n\n* we use 100% of the data ( in the above example we used ~ 10% of the data )\n* we add more layers\n* We try different pre-trained model\n* We do long training of the model\n\n#### In the next section, we will try to improve the performance \n","0a03d8cc":"#### We can see the problem here, The input to the model is an image and the size of the input has to be constant, but in the dataset, we don't have all the images with the fixed dimensions, Well we can easily crop the image to the desired size.\n\n#### which brings us to our question what should be the size of the input image ?, It\u2019s very important that we find the correct size. If the image size is very small we are simply losing a lot of information and if the size is very high, that adds extra non-sence information (padding ) as well as a lot of processing overhead ( high ram consumption ). \n\n#### Here we will iterate through all the image\u2019s shapes and take the average of all and use that as the final image size. \n","389c144f":"#### freezing the layers prevents the layer\u2019s weight from being updated during the training. Because we want to use that information as it is.","4c48a785":"#### we have image id and its respective score in the train.csv","f11e4072":"# Starter\n\n\n#### Hello readers,\n\n#### In this notebook, we will try to explore different ways of developing the machine learning model for this competition.\n\n#### Few points to consider before we begin :\n\n* This notebook basically focuses on the CNN-based approaches.\n* We cover the topics like Transfer learning and Fine-tuning the pre-trained CNN models.\n* *THIS IS A DEMONSTRATION NOTEBOOK THEREFORE WE ONLY USE THE 100 IMAGES OTU OF ~9900 ( FOR FAST PROCESSING )*.\n* Note that because of the above reason the performance of the model is not the true indicator of its abilities.\n\n\n#### A brief about what we are going to cover in this notebook \n\n* Data analysis and preprocessing. \n* Transfer learning ( pre-trained model selection ).\n* Fine-tuning the pre-trained model.\n\n\n#### A brief about the approach we are taking :\n\n* As the score ranges from 1 to 100, i.e every image has a score between 1 to 100. We just need to find the score of an image. One possible approach is to treat the problem as a multiclass classification problem, where we have an image and we want to classify it as one of the 100 categories. \n\n#### Let\u2019s begin, Hope you enjoy this notebook! \n","028caaf2":"<center><h1>Transfer learning ( pre-trained model selection ) <\/h1><\/center>","a98da155":"<center style=\"font-family:verdana;\"><h1 style=\"background: #f4c2c2 ;\">_<\/h1><\/center>","f9149ae9":"#### Now that we have loaded the pre-trained model, We are just gonna use the learned information from this model by integrating the pre-trained model with our model.\n","09b0bd0e":"## Let's have look at performance ","afaa8bc1":"<center><h1>Data analysis and preprocessing  <\/h1><\/center>","f137f295":"#### Fine Tunning is the process of updating the weights of the pre-trained model in order to increase the accuracy, you can learn more about fine-tuning the pre-trained model here: https:\/\/www.pyimagesearch.com\/2019\/06\/03\/fine-tuning-with-keras-and-deep-learning\/ \n\n#### Similar to transfer learning in fine-tuning the pre-trained model is used, but here we allow the pre-trained model\u2019s layer's weights to get updated during the training.\n\n#### We can eighter train all the layers or we can train only a few layers.\n","ccef999c":"### Let's have a look at some images from the train folder ","8d649809":"#### we can see that there are 175 layers in the pre-trained model, here we will start fine-tuning the model from the 100th layer.\n","ca2da06e":"## Let's see the performance  ","e53f5ca2":"### simple explanation of the above model \n\n* Image enters into the model as a multidimensional array\n* We pass the image to pretrained mode \n* Pre-trained model returns the vectorized representation of the image \n* these vector passes through the Feedforward network \n* final output is generated \n","36165e91":"#### Transfer learning is the process of using the models that have been trained on the very large image datasets, And utilize the learned information (weights ) and model architecture for the give use cases. \n\n#### You can learn more about transfer learning here: https:\/\/machinelearningmastery.com\/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models\/\n\n#### let's start \n","2190c2d7":"<center style=\"font-family:verdana;\"><h1 style=\"background: #f4c2c2 ;\">_<\/h1><\/center>","a254f071":"#### As this is the demonstration we will only train this model for 10 epochs  \n\n## Let's start the training ;)\n","e91995bb":"#### There are a lot of pre-trained models that we can use, different models have different properties and we can select the model based on the use case. But ultimately it\u2019s a matter of trying, i.e we have to try and find the best model for our use-cases out of all the pre-trained models. \n\n#### you can find the pre-trained models here: https:\/\/keras.io\/api\/applications\/\n\n#### here we will be using resnet50 as the pre-trained model, you can learn more about resnet50 here: https:\/\/keras.io\/api\/applications\/resnet\/#resnet50-function\n","7af802da":"### Note :\n\n* We have seen the different approaches that we can use here in the context of CNN only.\n* One other approach that we can use is transformers, have a look here: https:\/\/keras.io\/examples\/vision\/image_classification_with_vision_transformer\/\n\n* The metadata can also be used for the training of the model.\n* Simple techniques like hyperparameter tunning, long training, image data extraction ... can be used to improve the model performance.\n\n\n","7e226f46":"#### defining the callbacks is very important, we can decide the behavior of the training.\n#### Tune the bellow parameters as needed.","0669ceb3":"### importent note: \n    \n#### now we are training a much larger model than before, we need to be careful while setting the learning rate of the model, the learning rate should be lower otherwise model could overfit very quickly.\n"}}