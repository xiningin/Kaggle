{"cell_type":{"9f5c0d7f":"code","d0450503":"code","ea1918b8":"code","702fa066":"code","fb0898ca":"code","c1162deb":"code","d7fad100":"code","45bf5fe1":"code","27f23e7c":"code","1fc195ef":"code","401de6cf":"code","b0f65134":"code","984c8ba3":"code","0a9580cb":"code","6a84884f":"code","ff02a252":"code","9a508aef":"code","ddf7a0d7":"code","fc64de39":"code","2ede3f48":"code","47140cf6":"code","8a766c6d":"code","7e7868d6":"code","f51c6291":"code","ea3d7765":"code","d534a960":"code","5556a84f":"code","287064be":"code","610de2c0":"code","c6288c6a":"code","0918c384":"code","62c518b1":"code","0217f397":"markdown","dbc42a81":"markdown","4c49dc8b":"markdown","4cac37ba":"markdown","db1a62df":"markdown","130147aa":"markdown","c3b81873":"markdown"},"source":{"9f5c0d7f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport sklearn\nimport optuna\nfrom plotly.subplots import make_subplots\nfrom pandas_profiling import ProfileReport\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import cross_val_score, learning_curve, ShuffleSplit\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess, Fourier\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\nfrom joblib import Parallel, delayed\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 100)","d0450503":"# read in files\nholiday_df = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/holidays_events.csv')\noil_df = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/oil.csv')\nstore_df = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/stores.csv')\ntrain_df = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/train.csv', dtype = {'store_nbr': 'category'})\ntest_df = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/test.csv', dtype = {'store_nbr': 'category'})","ea1918b8":"# overall sales trend\ndaily_sales_df = train_df[['date', 'sales']].groupby('date').mean().reset_index()\nfig = go.Figure(data=go.Scatter(x=daily_sales_df['date'], \n                                y=daily_sales_df['sales'],\n                                marker_color='red', text=\"sales\"))\nfig.show()","702fa066":"# extract date features\ntrain_df['year'] = pd.to_datetime(train_df['date']).dt.year\ntrain_df['month'] = pd.to_datetime(train_df['date']).dt.month\ntrain_df['day'] = pd.to_datetime(train_df['date']).dt.day\ntrain_df['day_of_week'] = pd.to_datetime(train_df['date']).dt.day_name()\n\n# sales by month\nby_month_df = train_df.groupby(['month'])['sales'].mean().reset_index()\nfig = px.bar(by_month_df, x='month', y='sales', color='sales', color_continuous_scale=\"darkmint\")\nfig.show()","fb0898ca":"# sales by day of month\nby_day_df = train_df.groupby(['day'])['sales'].mean().reset_index()\nfig = go.Figure(data=go.Scatter(x=by_day_df['day'], \n                                y=by_day_df['sales'],\n                                marker_color='red', text=\"sales\"))\nfig.show()","c1162deb":"# sales by day of week\nby_weekday_df = train_df.groupby(['day_of_week'])['sales'].mean()\nnew_order_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\nby_weekday_df = by_weekday_df.reindex(new_order_week, axis=0).reset_index()\nfig = px.bar(by_weekday_df, x='day_of_week', y='sales', color='sales', color_continuous_scale=\"darkmint\")\nfig.show()","d7fad100":"# holiday sales\nholiday_sales_df = pd.merge(daily_sales_df, holiday_df, on='date', how='inner')\nfig = px.scatter(holiday_sales_df, x='date', y='sales', size='sales', color='type')\nfig.show()","45bf5fe1":"train_df.groupby('date')","27f23e7c":"# school and office supply sales trend\n# This is the family that needs special attention\nschool_sales_df = train_df[train_df['family'] == 'SCHOOL AND OFFICE SUPPLIES']\ndaily_school_sales_df = school_sales_df.groupby(['date'])['sales'].mean().reset_index()\nfig = go.Figure(data=go.Scatter(x=daily_school_sales_df['date'], \n                                y=daily_school_sales_df['sales'],\n                                marker_color='red', text=\"sales\"))\nfig.show()\n# peaks appear in April, Augest, and Sept","1fc195ef":"# store\nstore_sales_df = pd.merge(train_df, store_df, on='store_nbr', how='inner')\ncity_sales_df = store_sales_df.groupby(['city'])['sales'].mean().reset_index()\nfig = px.bar(city_sales_df, x='city', y='sales', color = 'sales', color_continuous_scale=\"blues\")\nfig.show()","401de6cf":"# oil_price trend\nfig = go.Figure(data=go.Scatter(x=oil_df['date'], \n                                y=oil_df['dcoilwtico'],\n                                marker_color='red', text=\"sales\"))\nfig.show()","b0f65134":"# autocorrelation of oil price\ntmp_oil_df = oil_df.fillna(method = 'ffill')\n_ = plot_pacf(tmp_oil_df[1:]['dcoilwtico'], lags = 10)","984c8ba3":"# only keep national holiday for simplicity\nholiday_df = holiday_df[holiday_df['locale'] == 'National']\nholiday_df.drop(columns = ['locale', 'locale_name'], inplace = True)\n# drop duplicated holiday, leave the holiday with higher avg sales, which means more important holiday\ntmp_df = pd.merge(holiday_df, train_df.groupby('date')['sales'].mean().reset_index(), on = 'date', how = 'left')\nholiday_df = tmp_df.sort_values('sales').drop_duplicates(['date'], keep = 'last').drop(columns = ['sales', 'description'])\nholiday_df.rename(columns = {'type': 'holiday_type'}, inplace = True)\n# set date as index\nholiday_df['date'] = pd.to_datetime(holiday_df['date'])\nholiday_df.set_index(['date'], inplace = True) ","0a9580cb":"# preprocess oil data\noil_df.rename(columns = {'dcoilwtico': 'oil_price'}, inplace = True)\n# last 7 day avg price\noil_df['last7d_oil_price'] = oil_df['oil_price'].rolling(7).mean()\n# fill null with previous day oil price\noil_df = pd.DataFrame({'date': pd.date_range('2013-01-01', '2017-08-31').astype(str)}).merge(oil_df, on = 'date', how = 'left')\noil_df.fillna(method = 'ffill', inplace = True)\n# lag price\nfor lag in range(1, 4):\n    oil_df[f'oil_price_lag{lag}'] = oil_df['oil_price'].shift(lag)\n    oil_df[f'oil_price_lag{lag}'].fillna(oil_df['oil_price'], inplace = True)\n# set date as index\noil_df['date'] = pd.to_datetime(oil_df['date'])\noil_df.set_index(['date'], inplace = True) ","6a84884f":"# fourier features\nfourier = CalendarFourier(freq='W', order=4)\n\ndp = DeterministicProcess(index=pd.date_range('2017-04-01', '2017-08-31'),\n                          constant=False,\n                          order=1,\n                          seasonal=False,\n                          additional_terms=[fourier],\n                          drop=True)\ndp_df = dp.in_sample()\nfor i in range(1,4):\n    dp_df.rename(columns = {f'sin({i},freq=W-SUN)': f'sin{i}'}, inplace = True)\n    dp_df.rename(columns = {f'cos({i},freq=W-SUN)': f'cos{i}'}, inplace = True)","ff02a252":"# merge all datasets\ndf = pd.DataFrame(index = pd.date_range('2017-04-01', '2017-08-31')) # training start from 2017-04-01\nmerged_df = df.merge(holiday_df, left_index = True, right_index = True, how = 'left')\nmerged_df = merged_df.merge(oil_df, left_index = True, right_index = True, how = 'left')\nmerged_df = merged_df.merge(dp_df, left_index = True, right_index = True, how = 'left')\nmerged_df['transferred'].fillna(False, inplace = True)","9a508aef":"# date features\nmerged_df['month'] = pd.to_datetime(merged_df.index).month\nmerged_df['day'] = pd.to_datetime(merged_df.index).day\nmerged_df['day_of_week'] = pd.to_datetime(merged_df.index).day_name()\nmerged_df['is_school_day'] = (pd.to_datetime(merged_df.index).month.isin([3, 4, 8, 9])).astype(int)","ddf7a0d7":"# if is workday\nmerged_df['is_workday'] = 1\nmerged_df.loc[merged_df['day_of_week'].isin(['Saturday', 'Sunday']), 'is_workday'] = 0\n\nmerged_df.loc[merged_df['holiday_type'] == 'Bridge', 'is_workday'] = 0\nmerged_df.loc[merged_df['holiday_type'] == 'Work Day', 'is_workday'] = 1\nmerged_df.loc[merged_df['holiday_type'] == 'Transfer', 'is_workday'] = 0\nmerged_df.loc[(merged_df['holiday_type'] == 'Holiday') & (merged_df['transferred'] == False), 'is_workday'] = 0\nmerged_df.loc[(merged_df['holiday_type'] == 'Holiday') & (merged_df['transferred'] == True ), 'is_workday'] = 1\nmerged_df.drop(columns = ['transferred'], inplace = True)\n\nmerged_df = pd.get_dummies(merged_df, columns = ['holiday_type', 'day_of_week'])\nmerged_df.drop(columns = ['day_of_week_Monday'],inplace = True)","fc64de39":"train_date = ['2017-04-01', '2017-07-31'] # training date range\nvalid_date = ['2017-08-01', '2017-08-15'] # validation date range\ntest_date = ['2017-08-16', '2017-08-31'] # test date range","2ede3f48":"# split train, validation, and test\nX_train = merged_df[train_date[0]:train_date[1]]\nX_valid = merged_df[valid_date[0]:valid_date[1]]\nX_test = merged_df[test_date[0]:test_date[1]]\ny = train_df[['store_nbr', 'family', 'date', 'sales']].set_index(['store_nbr', 'family', 'date']).sort_index().unstack(['store_nbr', 'family'])\ny_train = y[train_date[0]:train_date[1]]\ny_valid = y[valid_date[0]:valid_date[1]]","47140cf6":"# use random forest for 'school and office supplies' only, and use ridge regression for other families\nclass CustomRegressor():\n    \n    def __init__(self, n_jobs=-1, verbose=0):\n        \n        self.n_jobs = n_jobs\n        self.verbose = verbose\n        self.estimators_ = None\n        \n    def _estimator_(self, X, y):\n    \n        warnings.simplefilter(action='ignore', category=FutureWarning)\n        if y.name[2] == 'SCHOOL AND OFFICE SUPPLIES':  \n            model = RandomForestRegressor(n_estimators = 225, n_jobs = -1) \n        else:  \n            model = Ridge(fit_intercept=True, solver='auto', alpha=0.5, normalize=True)    \n        model.fit(X, y)\n        return model\n\n    def fit(self, X, y):\n\n        self.estimators_ = Parallel(n_jobs=self.n_jobs, \n                              verbose=self.verbose,\n                              )(delayed(self._estimator_)(X, y.iloc[:, i]) for i in range(y.shape[1]))\n        return\n    \n    def predict(self, X):\n        \n        y_pred = Parallel(n_jobs=self.n_jobs, \n                          verbose=self.verbose)(delayed(e.predict)(X) for e in self.estimators_)\n        return np.stack(y_pred, axis=1)","8a766c6d":"# ridge + rf\nmodel = CustomRegressor()\nmodel.fit(X_train, y_train)\npred_df = pd.DataFrame(model.predict(X_valid),columns = y_train.columns, index = X_valid.index).stack(['store_nbr', 'family'])","7e7868d6":"# validation score\npred_df['sales'].clip(lower = 0, inplace = True)\npred_df['true_sales'] = y_valid.stack(['store_nbr', 'family']).values\nprint(mean_squared_log_error(pred_df['true_sales'], pred_df['sales']))\npred_df.groupby('family').apply(lambda r: mean_squared_log_error(r['sales'], r['true_sales']))","f51c6291":"# try lightgbm model \n# but lightgbm behaves worse than the above model, so do not run here\n# rename\n# for i in range(1,4):\n#     X_train.rename(columns = {f'sin({i},freq=W-SUN)': f'sin{i}'}, inplace = True)\n#     X_train.rename(columns = {f'cos({i},freq=W-SUN)': f'cos{i}'}, inplace = True)","ea3d7765":"# optuna for parameter tunning\ndef objective(trial):\n    param = {\n        \"objective\": \"binary\",\n        \"metric\": \"binary_logloss\",\n        \"verbosity\": -1,\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 100, 300),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 50, 100),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 20, 70),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    \n    lgb_reg = MultiOutputRegressor(lgb.LGBMRegressor(**param))\n    lgb_reg.fit(X_train, y_train)\n    pred_df = pd.DataFrame(lgb_reg.predict(X_valid),columns = y_train.columns, index = X_valid.index).stack(['store_nbr', 'family'])\n    pred_df['sales'].clip(lower = 0, inplace = True)\n    pred_df['true_sales'] = y_valid.stack(['store_nbr', 'family']).values\n    error = mean_squared_log_error(pred_df['true_sales'], pred_df['sales'])\n    return error\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=100)","d534a960":"# lgb_reg = MultiOutputRegressor(lgb.LGBMRegressor(**study.best_params))\n# lgb_reg.fit(X_train, y_train)","5556a84f":"# validation score\n# pred_df = pd.DataFrame(lgb_reg.predict(X_valid),columns = y_train.columns, index = X_valid.index).stack(['store_nbr', 'family'])\n# pred_df['sales'].clip(lower = 0, inplace = True)\n# pred_df['true_sales'] = y_valid.stack(['store_nbr', 'family']).values\n# print(mean_squared_log_error(pred_df['true_sales'], pred_df['sales']))\n# pred_df.groupby('family').apply(lambda r: mean_squared_log_error(r['sales'], r['true_sales']))","287064be":"# compare pred daily sales with actual daily sales\npred_vis_df = pred_df.reset_index().rename(columns = {'level_0': 'date'})\ndaily_vis_df =  pred_vis_df.groupby(['date'])[['sales', 'true_sales']].mean().reset_index()\ndaily_vis_df['day_of_week'] = daily_vis_df['date'].dt.day_name()\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=daily_vis_df['date'], \n                         y=daily_vis_df['sales'],\n                         marker_color='red', name=\"pred_sales\"))\nfig.add_trace(go.Scatter(x=daily_vis_df['date'], \n                         y=daily_vis_df['true_sales'],\n                         marker_color='blue', name=\"true_sales\"))\n# annotate days with bad predictions\nfig.add_annotation(x='2017-08-01', y=350, xref=\"x\", yref=\"y\", text=\"Tuesday\", showarrow=True, align=\"center\", arrowhead=2, \n                   arrowsize=1, arrowwidth=2, arrowcolor=\"#636363\", ax=0, ay=-30, bordercolor=\"#c7c7c7\", borderwidth=2,\n                   borderpad=4, bgcolor=\"#ca8ee8\", opacity=0.8)\nfig.add_annotation(x='2017-08-12', y=350, xref=\"x\", yref=\"y\", text=\"Saturday\", showarrow=True, align=\"center\", arrowhead=2, \n                   arrowsize=1, arrowwidth=2, arrowcolor=\"#636363\", ax=0, ay=-30, bordercolor=\"#c7c7c7\", borderwidth=2,\n                   borderpad=4, bgcolor=\"#ca8ee8\", opacity=0.8)\nfig.add_annotation(x='2017-08-13', y=350, xref=\"x\", yref=\"y\", text=\"Sunday\", showarrow=True, align=\"center\", arrowhead=2, \n                   arrowsize=1, arrowwidth=2, arrowcolor=\"#636363\", ax=0, ay=-30, bordercolor=\"#c7c7c7\", borderwidth=2,\n                   borderpad=4, bgcolor=\"#ca8ee8\", opacity=0.8)\nfig.show()","610de2c0":"# pay attention to school and office supply since it has lagre error in validation\nschool_pred_df = pred_vis_df[pred_vis_df['family'] == 'SCHOOL AND OFFICE SUPPLIES']\nschool_pred_df['2016_sales'] = train_df.loc[(train_df['date'].between('2016-08-01', '2016-08-15')) \n                                            & (train_df['family'] == 'SCHOOL AND OFFICE SUPPLIES'), 'sales'].values\ndaily_school_pred_df = school_pred_df.groupby(['date'])[['sales', 'true_sales', '2016_sales']].mean().reset_index()\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=daily_school_pred_df['date'], \n                         y=daily_school_pred_df['sales'],\n                         marker_color='red', name=\"pred_sales\"))\nfig.add_trace(go.Scatter(x=daily_school_pred_df['date'], \n                         y=daily_school_pred_df['true_sales'],\n                         marker_color='blue', name=\"true_sales\"))\nfig.add_trace(go.Scatter(x=daily_school_pred_df['date'], \n                         y=daily_school_pred_df['2016_sales'],\n                         marker_color='green', name=\"2016_sales\"))\nfig.show()\n# we underestimate the sales","c6288c6a":"model = CustomRegressor()\nmodel.fit(pd.concat([X_train, X_valid]), y[train_date[0]:valid_date[1]])\npred_df = pd.DataFrame(model.predict(X_test), columns = y_valid.columns, index = X_test.index).stack(['store_nbr', 'family'])","0918c384":"pred_df['sales'].clip(lower = 0, inplace = True)\nsubmit_df = pd.DataFrame({'id': [i for i in range(3000888, 3029400)], 'sales':pred_df['sales']})","62c518b1":"submit_df.to_csv(\"submission.csv\", index=False)","0217f397":"# Submission","dbc42a81":"# EDA","4c49dc8b":"# Error Analysis","4cac37ba":"# Modelling","db1a62df":"# Feature Engineering","130147aa":"## lgb","c3b81873":"## Ridge + RF"}}