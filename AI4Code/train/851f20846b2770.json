{"cell_type":{"089a87ce":"code","37b61cd1":"code","eba05d49":"code","5e6d4b13":"code","c8716fd4":"code","77346979":"code","48a3a0c9":"code","2a0891a6":"code","be48f79f":"code","9301bdb1":"code","42980d8e":"code","d0052328":"code","f812ef88":"code","6a85db82":"code","8217e9b1":"code","f16cca62":"code","847a84fd":"code","1d0c6378":"code","4a36a61c":"markdown","13747410":"markdown","93fbc806":"markdown","6c5f8bb8":"markdown","2291102d":"markdown","67cf58db":"markdown","3d19bb52":"markdown","0f5bee8d":"markdown","28488a9b":"markdown","28ccee2e":"markdown","9c1ab49c":"markdown","cbe45d78":"markdown","b24147d9":"markdown","7a927333":"markdown","8a63a2e9":"markdown","55714b61":"markdown"},"source":{"089a87ce":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nphysical_devices = tf.config.list_physical_devices('GPU') \ntf.config.experimental.set_memory_growth(physical_devices[0], True)\n\n\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfrom keras.callbacks import EarlyStopping","37b61cd1":"import os\n\n#classes = os.listdir(\"flowers\")\nflowers_path='..\/input\/flowers-recognition\/flowers\/flowers'\nclasses=os.listdir(flowers_path)\n\nclasses","eba05d49":"image_size = (128, 128)\nbatch_size = 32\n\n# https:\/\/keras.io\/api\/preprocessing\/image\/#image_dataset_from_directory-function\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    flowers_path,\n    validation_split=0.4,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    flowers_path,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)","5e6d4b13":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(classes[np.argmax(labels[i])])\n        plt.axis(\"off\")\n        ","c8716fd4":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.5),\n    ]\n)","77346979":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","48a3a0c9":"def make_model(input_shape, num_classes):\n    \n    inputs = keras.Input(shape=input_shape)\n\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(512, activation=\"relu\")(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dense(64, activation=\"relu\")(x)\n    x = layers.Dense(32, activation=\"relu\")(x)\n    x = layers.Dense(16, activation=\"relu\")(x)\n\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    outputs = layers.Dense(units, activation=activation)(x)\n    \n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=len(classes))\nmodel.summary()","2a0891a6":"epochs = 30\n\n# https:\/\/keras.io\/api\/callbacks\/\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nmodel.fit(\n    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n)","be48f79f":"model_json = model.to_json()\n\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","9301bdb1":"from tensorflow.keras.models import model_from_json\n\n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")","42980d8e":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        \n        pred = loaded_model.predict(np.array([images[i].numpy().astype(\"uint8\")]))\n        \n        plt.title(classes[np.argmax(pred)])\n        plt.axis(\"off\")","d0052328":"def make_model(input_shape, num_classes):\n    \n    inputs = keras.Input(shape=input_shape)\n\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(512, activation=\"relu\")(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n\n\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    outputs = layers.Dense(units, activation=activation)(x)\n    \n    return keras.Model(inputs, outputs)\n\n\nmodel3 = make_model(input_shape=image_size + (3,), num_classes=len(classes))\nmodel3.summary()","f812ef88":"epochs = 200\n\n# https:\/\/keras.io\/api\/callbacks\/\n\n#callbacks = [\n #   keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n#]\n\nes = EarlyStopping(monitor='val_accuracy', mode='max',min_delta=0.05, verbose=1, patience=20)\n\nmodel3.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory=model3.fit(\n    train_ds, epochs=epochs, callbacks=[es], validation_data=val_ds,\n)","6a85db82":"# Metrics\n\nfig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['loss'],\n    mode='lines+markers',\n    name='training loss'\n), row=1, col=1)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_loss'],\n    mode='lines+markers',\n    name='validation loss'\n), row=1, col=1)\n\n\nfig.add_trace(go.Scatter(\n    y=history.history['accuracy'],\n    mode='lines+markers',\n    name='training accuracy'\n), row=1, col=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_accuracy'],\n    mode='lines+markers',\n    name='validation accuracy'\n), row=1, col=2)\n\nfig.update_xaxes(title_text='Epoch')\n\nfig.update_layout(\n    title_text=\"Training History Metrics\",\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"right\", x=1)\n)\n\nfig.show()","8217e9b1":"\nplt.figure(figsize=(10, 10))\nfor images, labels in val_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        \n        pred = model3.predict(np.array([images[i].numpy().astype(\"uint8\")]))\n        \n        \n        \n        \n        y_test_inx= np.argmax(labels[i])#Transforma en arreglo creado con\" keras.utils.to_categorical\"al valor de indice \n        y_pred_inx= np.argmax(pred)\n        if int(y_pred_inx) == int(y_test_inx):\n            correct=\"Yes\"\n        else:\n            correct=\"No\"\n        \n        #plt.title(classes[np.argmax(pred)])\n        #plt.title(classes[y_test_inx])\n        plt.title(\"Pred: \" +str(classes[y_pred_inx])+\"  Correct: \"+correct)\n        \n        \n        plt.axis(\"off\")","f16cca62":"def plot_confussion_matrix(cm):\n\n    fig, ax = plt.subplots(figsize=(6, 6))\n    ax.imshow(cm)\n    ax.grid(False)\n    ax.set_xlabel('Predicted outputs')\n    ax.set_ylabel('Actual outputs')\n    ax.xaxis.set(ticks=range(5))\n    ax.yaxis.set(ticks=range(5))\n    #ax.set_ylim(9.5, -0.5)\n    for i in range(5):\n        for j in range(5):\n            ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n    plt.show()","847a84fd":"pred_list=[]#lista para guardar valores para matriz de confusion\ntest_list=[]#lista para guardar valores para matriz de confusion\nfor images, labels in val_ds:\n    for i in range(32):\n        pred = loaded_model.predict(np.array([images[i].numpy().astype(\"uint8\")]))\n        y_test_inx= np.argmax(labels[i])#Transforma en arreglo creado con\" keras.utils.to_categorical\"al valor de indice \n        y_pred_inx= np.argmax(pred)\n        pred_list.append(y_pred_inx)\n        test_list.append(y_test_inx)\n","1d0c6378":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(pred_list, test_list)\nplot_confussion_matrix(cm)","4a36a61c":"# Redes profundas de aprendizaje con Keras","13747410":"## DEFINIR MODELO","93fbc806":"# Train the model","6c5f8bb8":"# Load the model","2291102d":"## MATRIZ DE CONFUSION","67cf58db":"# Save the model","3d19bb52":"# Data Augmentation","0f5bee8d":"# Model","28488a9b":"# Imports","28ccee2e":"##  ENTRENAR MODELO","9c1ab49c":"![](oel.jpg)","cbe45d78":"![Simple vs Deep](simplevsdeep.png)","b24147d9":"## Muestra imagenes de datos de Train con el respectivo label","7a927333":"-------------------------------------------------------\n# --------------------  INICIA TAREA 11------------------\n-------------------------------------------------------","8a63a2e9":"# Load Data from directory","55714b61":"# Visualize the data"}}