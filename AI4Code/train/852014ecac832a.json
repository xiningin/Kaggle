{"cell_type":{"44835191":"code","33c74632":"code","b3a2f42c":"code","2c2b895d":"code","04a43e8b":"code","8e6dd044":"code","c99febac":"code","96b28cd6":"code","541cde48":"code","988a150c":"code","7f607a4b":"code","695502a6":"code","c47473ae":"code","4dd44f4d":"code","56a8ac38":"markdown","5b0d09a0":"markdown","db73a420":"markdown","db86145e":"markdown"},"source":{"44835191":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33c74632":"df = pd.read_csv('..\/input\/melbourne-housing-snapshot\/melb_data.csv')\ndf.describe()","b3a2f42c":"df.columns","2c2b895d":"#drop rows with missing data\ndf = df.dropna(axis=0)","04a43e8b":"#Define the prediction variable\ny = df.Price","8e6dd044":"# Define features that are used to predict the prediction variable or dependable variable\nfeatures = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\nX = df[features]\nX.describe()\n#X.head()","c99febac":"# Fit the Decision Tree Model\nmodel = DecisionTreeRegressor(random_state=1)\nmodel.fit(X,y)","96b28cd6":"#Predicting the values of the first 5 houses in the model\nprint('Predicting prizes for:')\nprint(X.head())\nmodel.predict(X.head())","541cde48":"# split data into test and validation data\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)","988a150c":"# Fit model with train data\n\nmodel = DecisionTreeRegressor()\nmodel.fit(train_X, train_y)","7f607a4b":"# get predictions and compare with validation data\n\nval_pred = model.predict(val_X)\nmean_absolute_error(val_pred, val_y)","695502a6":"# Write a function to return Mean absolute error (MAE) for different tree depth and absolute leave nodes\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    val_predictions = model.predict(val_X)\n    mae = mean_absolute_error(val_predictions, val_y)\n    return mae","c47473ae":"for max_leaf_nodes in [5,50,500,5000]:\n    mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print (f'Max leav_nodes: {max_leaf_nodes}.  Mean Absolute Error: {np.round(mae)} ')","4dd44f4d":"forest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(train_X,train_y)\nforest_pred = forest_model.predict(val_X)\nforest_mae = mean_absolute_error(forest_pred, val_y)\nprint(forest_mae)","56a8ac38":"**Instead of using just one decision tree, use a random forest, were many decision trees are run and the predictions are averaged - an ensemble run**","5b0d09a0":"**Finding best Prediction Tree depth using mean absolute error**","db73a420":"**Max leaf nodes of 500 is the best as this produces the lowest mean absolute error.**","db86145e":"The predictions are too good. Need to try model on some test data."}}