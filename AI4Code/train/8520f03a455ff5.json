{"cell_type":{"5cc96995":"code","b22a870f":"code","56bd0eb4":"code","98932c5b":"code","ae816788":"code","6436d599":"code","15503d20":"code","48e4726b":"code","d5f4bec8":"code","4c5ba66a":"code","5085b262":"markdown"},"source":{"5cc96995":"import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,GlobalAveragePooling2D,Dense,Flatten,Dropout\nfrom keras.layers.normalization import BatchNormalization","b22a870f":"#Importing the images\n\nimage_path = \"\/kaggle\/input\/stanford-dogs-dataset\/images\/Images\/\"\n\ncategories = os.listdir(image_path)\nbreeds=[]\nfor breed in categories:\n    a=breed[10:]\n    a=a.replace('_',' ')\n    a=a.lower()\n    breeds.append(a)\nprint(\"List of breeds = \",breeds[:20],\"\\n\\nNo. of breeds = \", len(categories))","56bd0eb4":"#Creating DataGenerators to get labels from image directories\n\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nimage_size=224  #for the inception model\n\ntrain_datagen=ImageDataGenerator(\n                        rescale=1.\/255,\n                        validation_split=0.2,\n                        horizontal_flip=True,\n                        width_shift_range=0.2,\n                        height_shift_range=0.2,\n                        shear_range=0.2,\n                        rotation_range=40,\n                        fill_mode='nearest'\n                        )\n\ntrain_generator=train_datagen.flow_from_directory(\n                        image_path, \n                        target_size=(image_size,image_size),\n                        subset='training',\n                        shuffle=True,\n                        batch_size=24,\n                        class_mode='categorical'\n                        )\n\nvalid_datagen=ImageDataGenerator(\n                        validation_split=0.2,\n                        rescale=1.\/255\n                        )\n\nvalid_generator=valid_datagen.flow_from_directory(\n                        image_path, \n                        target_size=(image_size,image_size),\n                        subset='validation',\n                        shuffle=False,\n                        batch_size=24,\n                        class_mode='categorical'\n                        )","98932c5b":"#Viewing some augmented images from the dataset with the correct label\n\nx,y = train_generator.next()\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\nfor i in range(0,10):\n    image = x[i]\n    plt.imshow(image)\n    c=0\n    for i in y[i]:\n        if i==0:\n            c+=1\n        else:break\n    label=labels[c][10:]\n    label=label.replace('_',' ')\n    label=label.lower()\n    plt.title(label)\n    plt.show()\n","ae816788":"#Applying transfer learning to build a model\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n#using pre-trained weights for the inception model\nlocal_weights_file = '..\/input\/inception\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nInception = InceptionV3(input_shape = (224,224,3), \n                                include_top = False, \n                                weights = local_weights_file)\n\n#building a sequential model with inception layer base and only an average pooling layer before the output layer\n\nmodel2=Sequential()\nmodel2.add(Inception)\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(1024,activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(1024,activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(GlobalAveragePooling2D())\nmodel2.add(Dense(512,activation='relu'))\nmodel2.add(Dense(len(breeds),activation='softmax'))\n\nmodel2.layers[0].trainable=False\n\nmodel2.compile(optimizer='sgd',\n             loss='categorical_crossentropy',\n             metrics=['accuracy']\n             )\n\nmodel2.summary()","6436d599":"#Training the model \ncallback=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3,min_delta=0,mode='auto',restore_best_weights=False,baseline=None)\n\nhistory=model2.fit_generator(train_generator,\n                   steps_per_epoch=688,\n                   epochs=20,\n                   validation_data=valid_generator,\n                   validation_steps=170,\n                   callbacks=[callback])","15503d20":"def plot_model(history):\n    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,4))\n    fig.suptitle('Model 2 Accuracy and Loss')\n\n    ax1.plot(history.history['accuracy'])\n    ax1.plot(history.history['val_accuracy'])\n    ax1.title.set_text('Accuracy')\n    ax1.set_ylabel('Accuracy')\n    ax1.set_xlabel('Epoch')\n    ax1.legend(['Train','Valid'],loc=4)\n\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.title.set_text('Loss')\n    ax2.set_ylabel('Loss')\n    ax2.set_xlabel('Epoch')\n    ax2.legend(['Train','Valid'],loc=1)\n\n    fig.show()\n\nplot_model(history)","48e4726b":"#Predicting a random image not present in the dataset\n\nfrom cv2 import imread\nfrom keras.applications.inception_v3 import preprocess_input\n\ndef predict(url, filename):\n    # download and save\n    os.system(\"curl -s {} -o {}\".format(url, filename))\n    img = Image.open(filename)\n    img = img.convert('RGB')\n    img = img.resize((image_size,image_size))\n    img.save(filename)\n    # show image\n    plt.figure(figsize=(4, 4))\n    plt.imshow(img)\n    plt.axis('off')\n    # predict\n    img = imread(filename)\n    img = preprocess_input(img)\n    probs = model2.predict(np.expand_dims(img, axis=0))\n    \n    dict1={}\n    for i,j in enumerate(probs[0]):\n        dict1[i]=j\n    \n    a=max(dict1.keys(), key=(lambda k: dict1[k]))\n    predicted_breed=labels[a][10:]\n    predicted_breed=predicted_breed.replace('_',' ')\n    predicted_breed=predicted_breed.lower()\n    print(predicted_breed)\n        \npredict(\"https:\/\/s3.amazonaws.com\/cdn-origin-etr.akc.org\/wp-content\/uploads\/2017\/11\/12224329\/Shih-Tzu-On-White-01.jpg\",\n                     \"test_image_1.jpg\")","d5f4bec8":"from sklearn.metrics import classification_report\n\nvalid_generator.reset()\npredictions=model2.predict_generator(valid_generator,steps=len(valid_generator))\ny=np.argmax(predictions,axis=1)\n\nprint('Classification Report')\nreport=classification_report(y_true=valid_generator.classes,y_pred=y,target_names=valid_generator.class_indices)\nprint(report)","4c5ba66a":"import pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nprint('Confusion Matrix')\n\ncm=confusion_matrix(valid_generator.classes,y)\ndf=pd.DataFrame(cm,columns=valid_generator.class_indices)\nplt.figure(figsize=(80,80))\nsns.heatmap(df,annot=True)","5085b262":"My attempt at the dog-breed classifier from the **Stanford Dog Breed Dataset**.\n\nAny advice to increase my model's accuracy much appreciated.\nEach epoch takes around 350s to train even after applying transfer learning, any way to reduce this?\nLet me know through the comments.\n\nPlease do up-vote if the notebook is useful to you or you fell it does a good job."}}