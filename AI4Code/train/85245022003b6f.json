{"cell_type":{"d8d59d07":"code","0e89fbb7":"code","2ab049d2":"code","6f033571":"code","95f0ff14":"code","d1e633f8":"code","0c5baefb":"code","debd70d2":"code","666d830a":"code","a92006ae":"code","b8023504":"markdown"},"source":{"d8d59d07":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e89fbb7":"#importing necessary libraries\nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\nimport tensorflow as tf  \nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model  \nfrom tensorflow.keras.optimizers import RMSprop\nfrom keras_preprocessing.image import ImageDataGenerator\n\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.preprocessing import image\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n\n#loading training and testing datasets\nX_train_data = np.load(\"..\/input\/mais202fall2021\/train_images.npy\")\ny_train_data = pd.read_csv(\"..\/input\/mais202fall2021\/train_labels.csv\")\nX_test_data = np.load(\"..\/input\/mais202fall2021\/test_images.npy\")\n\n\n\n#Normalizing the data for better neural network training\n\nX_train_data = X_train_data\/255\nX_test_data = X_test_data\/255\n\n#reshaping for CNN\nX_train_data = X_train_data.reshape((50000, 28, 28, 1))\nX_test_data = X_test_data.reshape((20000,28,28,1))\n\nprint(f\"Shape of training data: {X_train_data.shape}\")\nprint(f\"Shape of testing data: {X_test_data.shape}\")\n\ny_train_data = pd.DataFrame([y_train_data[\"label\"]])\ny_train_data = y_train_data.T\nprint(\"Training labels: \")\ny_train_data.head()\n","2ab049d2":"#Viewing a sample image\nplt.matshow(X_train_data[9]) ","6f033571":"CNN_model = Sequential([\n    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1),padding='valid',strides=(1,1)),\n    #layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu',padding='valid',strides=(1,1)),\n    layers.MaxPooling2D((2, 2),padding='valid',strides=None),\n    \n    layers.Dropout(0.5),\n    \n    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu',padding='valid',strides=(1,1)),\n    layers.MaxPooling2D((2, 2),padding='valid',strides=None),\n    \n    layers.Dropout(0.5),\n    \n\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(10, activation='softmax')\n    \n])\n","95f0ff14":"CNN_model.summary()","d1e633f8":"CNN_model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","0c5baefb":"CNN_model.fit(X_train_data,y_train_data,epochs=30,validation_split=0.2)","debd70d2":"print(CNN_model.history.history.keys())","666d830a":"plt.plot(CNN_model.history.history['accuracy'])\nplt.plot(CNN_model.history.history['val_accuracy'])\nplt.title(\"Accuracy of Training and Validation Set\")\nplt.ylabel(\"accuracy\")\nplt.xlabel(\"epoch\")\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","a92006ae":"y_test_results = CNN_model.predict(X_test_data)\ny_test = []\nfor i in range(0,20000):\n    y_test.append(np.argmax(y_test_results[i]))\n     \nID = []\nfor i in range(0,20000):\n    ID.append(i)\n\nsubmission = pd.DataFrame(ID,columns=[\"ID\"])\nsubmission[\"label\"] = y_test\nsubmission\n\nsubmission.to_csv('submission_w.csv',index=False)\n","b8023504":"**Creating the Neural Network Model**"}}