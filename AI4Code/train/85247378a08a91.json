{"cell_type":{"cd797de4":"code","99e75741":"code","8a0e41a7":"code","9cc6c243":"code","60e5776b":"code","736e0672":"code","6b3aad84":"code","c636a8b6":"code","48e19f40":"code","94629191":"code","6b8c707e":"code","b7c9deb9":"code","86bc3694":"code","efcb7cd6":"code","d32cd53b":"code","80ece60d":"code","84b1c889":"code","ffdf370d":"markdown","1084cfdf":"markdown","92845997":"markdown","2457e5be":"markdown","ddc860ed":"markdown","ede7e677":"markdown","b09464b0":"markdown","5c2b4e22":"markdown","760b48dc":"markdown","b5a210db":"markdown","53279e81":"markdown","99639546":"markdown","0941698c":"markdown","f445f561":"markdown"},"source":{"cd797de4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99e75741":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics","8a0e41a7":"# (a) - Load data and report sizes of training and testing datasets\ntrain_data = pd.read_csv('..\/input\/pcadata\/pca_train.csv')\ntest_data = pd.read_csv('..\/input\/pcadata\/pca_test.csv')\n\nprint('Size of Training dataset: ' + str(train_data.shape))\nprint('Size of Testing dataset: ' + str(test_data.shape))","9cc6c243":"# To identify the number of Class 0 and Class 1 samples in the training and testing sets\ntrain_class_0 = train_data.loc[train_data['Class'] == 0].shape[0]\ntrain_class_1 = train_data.loc[train_data['Class'] == 1].shape[0]\ntest_class_0 = test_data.loc[test_data['Class'] == 0].shape[0]\ntest_class_1 = test_data.loc[test_data['Class'] == 1].shape[0]\n\nprint('\\nTraining dataset:')\nprint('Number of samples with Class (0): ' + str(train_class_0))\nprint('Number of samples with Class (1): ' + str(train_class_1))\n\nprint('\\nTesting dataset:')\nprint('Number of samples with Class (0): ' + str(test_class_0))\nprint('Number of samples with Class (1): ' + str(test_class_1))\n","60e5776b":"\n# Normalize training data\nfor col in test_data.columns:\n  if col != 'Class':\n    test_data[col] = (test_data[col] - min(train_data[col]))\/(max(train_data[col]) - min(train_data[col]))\n\n# Normalize testing data\nfor col in train_data.columns:\n  if col != 'Class':\n    train_data[col] = (train_data[col] - min(train_data[col]))\/(max(train_data[col]) - min(train_data[col]))","736e0672":"train_covariance_matrix = train_data.iloc[:, :-1].cov()\nprint('\\nDimensions of co-variance matrix of training data set: ' + str(train_covariance_matrix.shape))\nprint('\\nPrinting first 5 rows and first 5 columns of the covariance matrix: ')\nprint(str(train_covariance_matrix.iloc[:5, :5]))","6b3aad84":"\nw, v = np.linalg.eig(train_covariance_matrix)\nprint('Size of co-variance matrix: ' + str(train_covariance_matrix.size))\nprint('Size of eigen-vectors: ' + str(v.size))\nprint('5 largest eigen values: ' + str(w[0:5]))","c636a8b6":"plt.bar(np.arange(w.shape[0]), w)\nplt.xlabel(\"Component Number\") \nplt.ylabel(\"Eigen Value\") \nplt.title(\"Bar plot of Eigen values\") \nplt.show()","48e19f40":"p = [2, 4, 8, 10, 20, 40, 60]\n\n# Using sklearn's KNeighborsClassifier for 5 neighbors and Euclidean distance metric\nknn_classifier = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\ntest_accuracy = {}\nnormal_train_x = train_data.iloc[:, :-1]\nnormal_test_x = test_data.iloc[:, :-1]\n\nfor p_comp_num in p:\n  # reducing dimensionality of training dataset\n  transformed_train_data_attributes = normal_train_x.dot(v[:, :p_comp_num])\n  # fitting the 5NN model\n  model = knn_classifier.fit(transformed_train_data_attributes, train_data['Class'])\n  # creating new test dataset using PCA\n  transformed_test_data_attributes = normal_test_x.dot(v[:, :p_comp_num])\n  # using the 5NN model to predict values\n  predicted_values = model.predict(transformed_test_data_attributes)\n  # calculating test accuracy\n  result = metrics.accuracy_score(test_data.iloc[:, -1], predicted_values)\n  test_accuracy[p_comp_num] = result\n\n  # (b) - (iv) - Point-1: Creating new_testing_dataset.csv for p=4\n  if p_comp_num == 4:\n    # (b) - (iv) - Point-1: Reposrting testing accuracy for p=4\n    print('Accuracy of NEW testing dataset when using PCA(p=4) with 5NN: ' + str(test_accuracy[4]))\n    test_p_4_df = transformed_test_data_attributes\n    test_p_4_df['true_Class'] = test_data.iloc[:, -1]\n    test_p_4_df['predicted_Class'] = predicted_values\n    test_p_4_df.to_csv('new_testing_dataset.csv')","94629191":"x = []\ny = []\nfor k, v in test_accuracy.items():\n  x.append(k)\n  y.append(v)\n\nplt.plot(x, y, marker='o')\nplt.xlabel('Number of components (p)')\nplt.ylabel('Test Accuracy')\nplt.title('Test Accuracy Plot')\nplt.show()","6b8c707e":"std_train_data = pd.read_csv('..\/input\/pcadata\/pca_train.csv')\nstd_test_data = pd.read_csv('..\/input\/pcadata\/pca_test.csv')","b7c9deb9":"for col in std_test_data.columns:\n  if col != 'Class':\n    std_test_data[col] = (std_test_data[col] - std_train_data.mean(axis = 0)[col])\/std_train_data[col].std()\n\nfor col in std_train_data.columns:\n  if col != 'Class':\n    std_train_data[col] = (std_train_data[col] - std_train_data.mean(axis = 0)[col])\/std_train_data[col].std()","86bc3694":"train_covariance_matrix = std_train_data.iloc[:, :-1].cov()\nprint('\\nDimensions of co-variance matrix of training data set: ' + str(train_covariance_matrix.shape))\nprint('\\nPrinting first 5 rows and first 5 columns of entire covariance matrix: ')\nprint(str(train_covariance_matrix.iloc[:5, :5]))","efcb7cd6":"\nw, v = np.linalg.eig(train_covariance_matrix)\nprint('Size of co-variance matrix: ' + str(train_covariance_matrix.size))\nprint('Size of eigen-vectors: ' + str(v.size))\nprint('5 largest eigen values: ' + str(w[0:5]))","d32cd53b":"\n\nplt.bar(np.arange(w.shape[0]), w)\nplt.xlabel(\"Component Number\") \nplt.ylabel(\"Eigen Value\") \nplt.title(\"Bar plot of Eigen values\") \nplt.show()\n","80ece60d":"p = [2, 4, 8, 10, 20, 40, 60]\n\n# Using sklearn's KNeighborsClassifier for 5 neighbors and Euclidean distance metric\nknn_classifier = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\ntest_accuracy = {}\nnormal_train_x = std_train_data.iloc[:, :-1]\nnormal_test_x = std_test_data.iloc[:, :-1]\n\nfor p_comp_num in p:\n  # reducing dimensionality of training dataset\n  transformed_train_data_attributes = normal_train_x.dot(v[:, :p_comp_num])\n  # fitting the 5NN model\n  model = knn_classifier.fit(transformed_train_data_attributes, train_data['Class'])\n  # creating new test dataset using PCA\n  transformed_test_data_attributes = normal_test_x.dot(v[:, :p_comp_num])\n  # using the 5NN model to predict values\n  predicted_values = model.predict(transformed_test_data_attributes)\n  # calculating test accuracy\n  result = metrics.accuracy_score(std_test_data.iloc[:, -1], predicted_values)\n  test_accuracy[p_comp_num] = result\n\n  # (c) - (iv) - Point-1: Creating new_testing_dataset.csv for p=4\n  if p_comp_num == 4:\n    # (c) - (iv) - Point-1: Reposrting testing accuracy for p=4\n    print('Accuracy of NEW testing dataset when using PCA(p=4) with 5NN: ' + str(test_accuracy[4]))\n    test_p_4_df = transformed_test_data_attributes\n    test_p_4_df['true_Class'] = std_test_data.iloc[:, -1]\n    test_p_4_df['predicted_Class'] = predicted_values\n    test_p_4_df.to_csv('new_standardize_testing_dataset.csv')\n\n    print(test_accuracy)","84b1c889":"x = []\ny = []\nfor k, v in test_accuracy.items():\n  x.append(k)\n  y.append(v)\n\nplt.plot(x, y, marker='o')\nplt.xlabel('Number of components (p)')\nplt.ylabel('Test Accuracy')\nplt.title('Test Accuracy Plot')\nplt.show()","ffdf370d":"# Co-variance Matrix (Test Data)","1084cfdf":"\n# Loading Test data","92845997":"# Pre-processing Data-Standardization","2457e5be":"# Pre-processing Data-Normalization","ddc860ed":"# Calculate eigen values and eigen vectors based on co-variance matrix (Test Data)","ede7e677":"# Combining PCA with KNN","b09464b0":"# Combining PCA with KNN","5c2b4e22":"# Data Exploring","760b48dc":"# Bar graph for eigen values","b5a210db":"# Point-2: Plot of p -> testing accuracy ","53279e81":"# Point-2: Plot of p -> testing accuracy ","99639546":"# Calculate eigen values and eigen vectors based on co-variance matrix","0941698c":"\n# Bar graph for eigen values","f445f561":"# Co-variance Matrix"}}