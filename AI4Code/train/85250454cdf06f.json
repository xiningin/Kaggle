{"cell_type":{"cec3f189":"code","1b85caae":"code","f914e368":"code","30da9716":"code","607a7816":"code","7ee723aa":"code","8dff31b4":"code","44141ec7":"code","a046a51e":"code","bb4efdc0":"code","e4a7c133":"code","897932a2":"code","86e47efc":"code","1acb1510":"code","1d4afd34":"code","1f42ec96":"code","ca3ea377":"code","2bdba42e":"code","2a207923":"code","fe043c25":"code","0b4d9dd6":"code","0d9834d1":"code","5b8db41f":"code","9f2ec294":"code","6c335f6b":"code","f9c16eee":"code","98dcb008":"code","c30f829f":"code","82f3a5bd":"code","922261c7":"code","0ed7c477":"code","1ba8047c":"code","bc6c8660":"code","a89e2d4b":"code","7137a59c":"code","16547df0":"code","b8562ec6":"code","477f20d1":"code","05d9874d":"code","8e6230a4":"code","58a6fd62":"code","c803edc5":"code","45461164":"code","a6d85499":"code","5965c0a8":"code","c39fc18c":"code","55d34325":"code","863acff1":"code","ec67747e":"code","d0a95c8f":"markdown","ac505ea5":"markdown","066e470e":"markdown","48d65525":"markdown","33213732":"markdown","2e9cd644":"markdown","d1dfe274":"markdown","5ca2704e":"markdown","a03cd51c":"markdown","5a8d1db1":"markdown","1ca8e736":"markdown","b408898a":"markdown","03918ce6":"markdown","2c866c7f":"markdown","010d39b6":"markdown","62b3c0ca":"markdown","aabcc7cb":"markdown","f0e417be":"markdown","2e252efb":"markdown","e4e56644":"markdown","a1224d53":"markdown","1f6769f2":"markdown","b0ba8ec0":"markdown","14a23629":"markdown","4ff818aa":"markdown","a2a182a4":"markdown","ad98f5c9":"markdown","318d4ac8":"markdown","1a402074":"markdown","2cecb81d":"markdown","fd94722f":"markdown","15932218":"markdown","b55f2331":"markdown","bbc3c16c":"markdown","c51f401b":"markdown","eda0df20":"markdown","d0e4e2f7":"markdown","34c401fd":"markdown","c8104be2":"markdown","9106bf47":"markdown","0de62df0":"markdown","6ae0c4d2":"markdown","cf79ca60":"markdown","d2a4ab79":"markdown","6d06c60f":"markdown"},"source":{"cec3f189":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as mpl\nimport plotly.graph_objects as go\nfrom scipy import stats \n\ntry:\n    import calmap\nexcept:\n    ! pip install calmap\n    import calmap\n\nplt.style.use('ggplot')\nmpl.rcParams['figure.dpi'] = 100\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n# don't use scientific notation\npd.set_option('display.float_format', lambda x: '%.3f' % x)\nDATA_DIR=\"..\/input\/m5-forecasting-accuracy\/\"","1b85caae":"calendar = pd.read_csv(f\"{DATA_DIR}calendar.csv\")\nsales = pd.read_csv(f\"{DATA_DIR}sales_train_validation.csv\")\nsub = pd.read_csv(f\"{DATA_DIR}sample_submission.csv\")\nprices = pd.read_csv(f\"{DATA_DIR}sell_prices.csv\")","f914e368":"sales.head()","30da9716":"calendar.head()","607a7816":"sub.head()","7ee723aa":"sales.shape","8dff31b4":"sales.dept_id.unique()","44141ec7":"sales.store_id.unique()","a046a51e":"sales.head()","bb4efdc0":"days = [col for col in sales.columns if \"d_\" in col]","e4a7c133":"total_per_day = pd.DataFrame()\ntotal_per_day['sales'] = sales[days].sum()\ntotal_per_day['date'] = calendar.date[:1913].values\ntotal_per_day['date_short'] =  total_per_day['date'].str[5:]\ntotal_per_day['date'] = pd.to_datetime(total_per_day['date'],format='%Y-%m-%d')\ntotal_per_day['day'] = total_per_day.date.dt.day\ntotal_per_day['month'] = total_per_day.date.dt.month_name()\ntotal_per_day['weekday'] = total_per_day.date.dt.weekday_name\ntotal_per_day['year'] = total_per_day.date.dt.year\n# to have dates as x-axis labels in decomposition plots\ntotal_per_day = total_per_day.set_index(\"date\")\ntotal_per_day.head()","897932a2":"calendar['date'] = pd.to_datetime(calendar['date'],format='%Y-%m-%d')","86e47efc":"import numpy as np                                                              \nimport seaborn as sns                                                           \nfrom scipy import stats                                                         \nimport matplotlib.pyplot as plt                                                 \n\nax = sns.distplot(total_per_day.sales)                                    \n\nmu, std = stats.norm.fit(total_per_day.sales)\n\n# Plot the histogram.\n# plt.hist(data, bins=25, density=True, alpha=0.6, color='g')\n\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = stats.norm.pdf(x, mu, std)\nax.plot(x, p, 'g')\nplt.title(\"Histogram of total daily sales\")\nplt.show()","1acb1510":"k2, p = stats.normaltest(total_per_day.sales)\nalpha = 1e-3\nprint(\"Normality test:\")\nif p < alpha:  # null hypothesis: x comes from a normal distribution\n    print(\"Data is normally distributed\")\nelse:\n    print(\"Data is NOT normally distributed\")","1d4afd34":"fig = go.Figure(layout={\"title\":{\n    'text': \"Daily total unit sales\",\"x\":0.5}})\nfig.add_trace(go.Scatter(x=total_per_day.index, y=total_per_day['sales'],\n                         mode='lines',marker_color='green',hovertext=total_per_day.index))\n    \nfig.show()","1f42ec96":"from statsmodels.tsa.seasonal import seasonal_decompose\n\n# daily measurements, season repeats every year\ndecompfreq = 366\nmodel = 'multiplicative'\nmpl.rcParams['figure.figsize'] = (15, 10)\ndecomposition = seasonal_decompose(\n    total_per_day['sales'],\n    freq=decompfreq)\nfig = decomposition.plot()","ca3ea377":"def values_on_bars():\n    for p in ax.patches:\n        ax.text(p.get_x() + p.get_width()\/2., p.get_height(), str(int(p.get_height())), \n        fontsize=12, ha='center', va='bottom')","2bdba42e":"mpl.rcParams['figure.figsize'] = (15, 5)\nax = sns.barplot(x='month',y='sales',data=total_per_day,ci=None)\nvalues_on_bars()\nplt.title(\"Average monthly sales\",fontsize=15)\nplt.show()","2a207923":"sns.barplot(x='weekday',y='sales',data=total_per_day)\nplt.title(\"Average sales by weekday\",fontsize=15)\nplt.show()","fe043c25":"total_cats = sales.groupby(\"cat_id\")[days].sum().T\ntotal_cats['date'] = list(calendar.date[:1913])\ntotal_cats['year'] = pd.to_datetime(total_cats['date'],format='%Y-%m-%d').dt.year\ntotal_cats = total_cats.groupby(\"year\").sum().apply(lambda x:x*100\/x.sum(),axis=1)\ntotal_cats","0b4d9dd6":"total_cats.plot(kind='bar', stacked=True, title=\"Category distribution over years (in %)\")\nplt.legend(title=\"Category\",bbox_to_anchor=(1,1))\nplt.show()","0d9834d1":"cats_per_store = sales.groupby([\"cat_id\",\"store_id\"])[days].sum().sum(axis=1).unstack(level=0).apply(lambda x:100*x\/x.sum(),axis=1)\ncats_per_store","5b8db41f":"cats_per_store.plot(kind='bar', stacked=True,title=\"Category distribution per stores (in %)\")\nplt.legend(title=\"Category\",bbox_to_anchor=(1,1))\nplt.show()","9f2ec294":"days = [col for col in sales.columns if \"d_\" in col]\ntotal_states = sales.groupby(\"state_id\")[days].sum().T\ntotal_states.index = pd.to_datetime(calendar.date[:1913])\ntotal_states.head()","6c335f6b":"total_states.describe()","f9c16eee":"fig = go.Figure(layout={\"title\":{\n    'text': \"Daily unit sales per state\",\"x\":0.5}})\nfor state in total_states.columns:\n    fig.add_trace(go.Scatter(x=total_states.index, y=total_states[state],\n                             mode='lines',hovertext=total_states.index,name=state))\n    \nfig.show()","98dcb008":"from statsmodels.tsa.seasonal import seasonal_decompose\ntrends_states = total_states.copy()\n# daily measurements, season repeats every year\ndecompfreq = 366\nmodel = 'multiplicative'\nmpl.rcParams['figure.figsize'] = (15, 5)\nfig = go.Figure(layout={\"title\":{\n    'text': \"Trends in sales per state\",\"x\":0.5}})\nfor state in total_states.columns:\n    decomposition = seasonal_decompose(\n        total_states[state],\n        freq=decompfreq)\n    fig.add_trace(go.Scatter(x=total_states.index, y=decomposition.trend,\n                             mode='lines',hovertext=total_states.index,name=state))\n    \nfig.show()","c30f829f":"total_stores = sales.groupby([\"store_id\"])[days].sum().T\ntotal_stores.index = calendar.date[:1913]\ntotal_stores.head()","82f3a5bd":"from statsmodels.tsa.seasonal import seasonal_decompose\ntrends_stores = total_stores.copy()\n# daily measurements, season repeats every year\ndecompfreq = 366\nmodel = 'multiplicative'\nmpl.rcParams['figure.figsize'] = (15, 5)\nfig = go.Figure(layout={\"title\":{\n    'text': \"Trends in sales per state\",\"x\":0.5}})\nfor state in total_stores.columns:\n    decomposition = seasonal_decompose(\n        total_stores[state],\n        freq=decompfreq)\n    fig.add_trace(go.Scatter(x=total_stores.index, y=decomposition.trend,\n                             mode='lines',hovertext=total_stores.index,name=state))\n    \nfig.show()","922261c7":"total_states = sales[sales.store_id!='CA_3'].groupby(\"state_id\")[days].sum().T\ntotal_states.index = calendar.date[:1913]\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ntrends_states = total_states.copy()\n# daily measurements, season repeats every year\ndecompfreq = 366\nmodel = 'multiplicative'\nmpl.rcParams['figure.figsize'] = (15, 5)\nfig = go.Figure(layout={\"title\":{\n    'text': \"Trends in sales per state\",\"x\":0.5}})\nfor state in total_states.columns:\n    decomposition = seasonal_decompose(\n        total_states[state],\n        freq=decompfreq)\n    fig.add_trace(go.Scatter(x=total_states.index, y=decomposition.trend,\n                             mode='lines',hovertext=total_states.index,name=state))\n    \nfig.show()","0ed7c477":"for state in [\"CA\",\"WI\",\"TX\"]:\n    print(\"State\",state)\n#     snaps_state = total_states[state]\n    snaps_state = calendar.set_index(\"date\")[\"snap_\"+state]\n    plt.figure(figsize=(15,5))\n    calmap.yearplot(snaps_state,year=2015)\n    plt.show()","1ba8047c":"total_states_with_calendar = total_states.T.reset_index().melt(id_vars='state_id',var_name='date',value_name='sales')\ntotal_states_with_calendar = pd.merge(total_states_with_calendar,calendar,on='date')\ntotal_states_with_calendar['date'] = pd.to_datetime(total_states_with_calendar['date'],format='%Y-%m-%d')\ntotal_states_with_calendar['snap'] = total_states_with_calendar.apply(lambda x:int(x[\"snap_\"+x['state_id']]==1),axis=1)\ntotal_states_with_calendar['isHoliday'] = total_states_with_calendar['event_name_1'].notna().astype(int)\ntotal_states_with_calendar = total_states_with_calendar.set_index(\"date\")","bc6c8660":"from scipy.stats import pearsonr     \npearsonr(total_states_with_calendar['sales'],total_states_with_calendar['snap'])","a89e2d4b":"total_states_with_calendar.groupby(\"snap\")['sales'].describe()","7137a59c":"sns.distplot(total_states_with_calendar.loc[total_states_with_calendar['snap']==0,'sales'])\nplt.title(\"Distribution of sales on days without food stamps\")\nplt.xlim([0,30000])\nplt.show()","16547df0":"sns.distplot(total_states_with_calendar.loc[total_states_with_calendar['snap']==1,'sales'])\nplt.title('Distribution of sales on days with food stamps')\nplt.xlim([0,30000])\nplt.show()","b8562ec6":"most_sold_products = sales.groupby(\"item_id\")[days].sum().stack().sum(level=0).sort_values(ascending=False)","477f20d1":"sales.groupby(\"item_id\")[days].sum().loc[['FOODS_3_090','FOODS_3_586','FOODS_3_252'],:]","05d9874d":"most_sold_products.head()","8e6230a4":"prices_desc = prices.groupby(\"item_id\")['sell_price'].describe().fillna(0)\nprices_desc['max_diff'] = prices_desc['max']-prices_desc['min']\nprices_desc.sort_values(by=\"max_diff\",ascending=False).head()","58a6fd62":"prices_desc[prices_desc['max_diff']==0].shape[0]\/prices_desc.shape[0]","c803edc5":"double_holidays = calendar[calendar.event_name_2.notnull()]","45461164":"double_holidays.head()","a6d85499":"total_per_day[total_per_day.index.isin(double_holidays.date)]","5965c0a8":"total_per_day.head()","c39fc18c":"total_per_day_with_calendar = pd.DataFrame()\ntotal_per_day_with_calendar['sales'] = sales[days].sum()\ntotal_per_day_with_calendar['date'] = calendar.date[:1913].values\ntotal_per_day_with_calendar = pd.merge(total_per_day_with_calendar,calendar,on='date')","55d34325":"holiday_sales_avg = total_per_day_with_calendar[total_per_day_with_calendar.event_name_1.notna()].groupby(['event_name_1'])['sales'].mean().sort_values(ascending=False)","863acff1":"calendar.event_name_1.unique()","ec67747e":"holiday_sales_avg","d0a95c8f":"## Seasonal decomposition","ac505ea5":"There were a few holidays that I didn't know before:\n* Chanukah - is a Jewish festival commemorating the rededication of the Second Temple in Jerusalem at the time of the Maccabean Revolt against the Seleucid Empire. It is also known as the Festival of Lights.\n* EidAlAdha - also called the \"Festival of the Sacrifice\", is the second of two Islamic holidays celebrated worldwide each year, and considered the holier of the two. It honours the willingness of Ibrahim to sacrifice his son as an act of obedience to God's command.\n* Purim - a Jewish holiday which commemorates the saving of the Jewish people from Haman, an Achaemenid Persian Empire official who was planning to kill all the Jews, as recounted in the Book of Esther.\n* Cinco de Mayo - an annual celebration held on May 5. The date is observed to commemorate the Mexican Army's victory over the French Empire at the Battle of Puebla, on May 5, 1862.\n* Eid al-Fitr - also called the \"Festival of Breaking the Fast\", is a religious holiday celebrated by Muslims worldwide that marks the end of the month-long dawn-to-sunset fasting of Ramadan. This religious Eid is the first and only day in the month of Shawwal during which Muslims are not permitted to fast.","066e470e":"Data seems to be roughly normally distributed, let's conduct a statistical test to confirm that.","48d65525":"There are 2 hobbies deparments, 2 household departments and 3 food departments. **Question:** How products from different department but the same category differ from each other?","33213732":"Which features should we drop:\n* `date` - stores the same information as `d`\n* `wday` - stores the same information as `weekday`\n* after adding `is_snap`, remove `snap_CA`, `snap_TX` and\t`snap_WI`","2e9cd644":"In every state there are different designated stamp days, but in all of them there are no stamp days in the second half of the month. <br>\nStamp days per state:\n* CA - 1 - 10\n* WI - 2,3,5,6,8,9,11,12,14,15 - pattern: a cycle of one day without stamps and two days with stamps\n* TX - 1,3,5,6,7,9,11,12,13,15","d1dfe274":"## Missing variables","5ca2704e":"Thanks to decomposition we can clearly see a moderately increasing trend - Walmart's sales are constantly rising. There is also strong seasonality - each month follows a similar pattern over years.","a03cd51c":"On average, sales are the lowest in May (32503) and the highest in August (35946). Overall, the differences are negligible.","5a8d1db1":"In the merged dataset, only columns related to events are missing and `sell_price`. In our case missing values are not just random errors in data collection. Conversely, they have particular meaning. Missing event means that there was no holiday that day and missing sell prices means that the given product was not sold on a given day. However, no products have gaps in sales in the test set, therefore in the modelling phase we need to decide what to do with that matter. For instance, we can remove all training examples when a product wasn't sold or try to interpolate the values based on its sales before and after the period when it wasn't sold. Both approaches should lead to better results compared to just leaving the values as they are.","1ca8e736":"Add a feature indicating if it's a food stamps in a given state - for California it doesn't matter if food stamps are eligible on a given day in another states.","b408898a":"1. M5 Participants Guide - https:\/\/mofc.unic.ac.cy\/m5-competition\/\n2. https:\/\/otexts.com\/fpp3\/tspatterns.html","03918ce6":"## Holidays","2c866c7f":"10% of products have always the same price","010d39b6":"We can observe that if we discard CA_3, the plots look pretty similar for all states. Therefore for the prediction it's much more important if the sales are from CA_3 or other stores than from which state the sales are.","62b3c0ca":"Days with stamps have higher mean and median - people buy more on days with stamps. There is a moderate linear relationship between sales and whether for the given day and state food stamps are allowed.","aabcc7cb":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\">Imports<\/a><\/span><\/li><li><span><a href=\"#Total-sales\" data-toc-modified-id=\"Total-sales-2\">Total sales<\/a><\/span><\/li><li><span><a href=\"#Seasonal-decomposition\" data-toc-modified-id=\"Seasonal-decomposition-3\">Seasonal decomposition<\/a><\/span><\/li><li><span><a href=\"#Categories\" data-toc-modified-id=\"Categories-4\">Categories<\/a><\/span><\/li><li><span><a href=\"#Sales-by-states\" data-toc-modified-id=\"Sales-by-states-5\">Sales by states<\/a><\/span><\/li><li><span><a href=\"#Sales-by-stores\" data-toc-modified-id=\"Sales-by-stores-6\">Sales by stores<\/a><\/span><\/li><li><span><a href=\"#SNAP-(food-stamps)\" data-toc-modified-id=\"SNAP-(food-stamps)-7\">SNAP (food stamps)<\/a><\/span><\/li><li><span><a href=\"#Products\" data-toc-modified-id=\"Products-8\">Products<\/a><\/span><\/li><li><span><a href=\"#Holidays\" data-toc-modified-id=\"Holidays-9\">Holidays<\/a><\/span><\/li><li><span><a href=\"#Missing-variables\" data-toc-modified-id=\"Missing-variables-10\">Missing variables<\/a><\/span><\/li><li><span><a href=\"#Encoding-categorical-variables\" data-toc-modified-id=\"Encoding-categorical-variables-11\">Encoding categorical variables<\/a><\/span><\/li><li><span><a href=\"#Feature-selection\" data-toc-modified-id=\"Feature-selection-12\">Feature selection<\/a><\/span><\/li><li><span><a href=\"#References\" data-toc-modified-id=\"References-13\">References<\/a><\/span><\/li><\/ul><\/div>","f0e417be":"The following are the dates with 2 events on the same day:","2e252efb":"## Imports","e4e56644":"The average daily sales on non-holidays are 34489 with standard deviation equal to 7133. Double holidays are clearly above that average.","a1224d53":"## Total sales","1f6769f2":"CA_3 obtains much larger sales then other stores in that state. CA_2 has a significant drop for most of 2014 and equally significant jump in 2015. TX_2 is calmly decreasing since mid-2013. WI_3 after initial peak in 2012, also dropped in later years.","b0ba8ec0":"US government provides food stamps for low-income households that allow buying some **selected** products for a discounted price. So probably on stamp days sales of those products might increase while sales of products that can't be bought by stamps stays similar to usual.","14a23629":"# Initial EDA & insights\n\nA good starting point for an analysis is always reading thoroughly the \"Overview\" and \"Data\" sections. The organizers also provide comprehensive M5 Participants Guide [1] which describes the dataset in details. However, naturally this notebook will touch upon the most important aspects.","4ff818aa":"Clearly, California obtains the best sales by a large margin. Texas was superior to Wisconsin up until mid-2014, but since than the latter has a steeper upwards trend. However, it is important to remember here that CA has 4 stores while TX and WI both have 3, so for better comparison we should average sales by number of stores.","a2a182a4":"## Encoding categorical variables\nMost of the variables in the competition are categorical so encoding them efficiently should play quite an important role.","ad98f5c9":"Not surprisingly, sales jump during weekends.","318d4ac8":"## Sales by states","1a402074":"\"The dataset involves the unit sales of 3,049 products, classified in 3 product categories (Hobbies, Foods, and Household) and 7 product departments, in which the above-mentioned categories are disaggregated.  The products are sold across ten stores, located in three States (CA, TX, and WI). \" [1]","2cecb81d":"Time series decomposition is helpful in time series analysis [2][3]. Every time series can be decomposed into three components:\n* trend - long-term increase or decrease in the data\n* seasonality - repeating short-term pattern with fixed frequency (e.g. days, weeks, months)\n* residual - random noise","fd94722f":"The next plot shows how sales were changing over years.","15932218":"I doubt if keeping `event_name_2` and `event_type_2`  makes sense because only 0.002 % of the dates have two events in one day.","b55f2331":"## Categories","bbc3c16c":"There are 5 days with sudden drops. Plotly creates interactive plots, so after hovering on these drops it becomes clear that all of them happen on Christmas Day. Apparently, it's the only day when Walmart stores are closed. Those are extreme outliers which should be removed in the modelling phase. Moreover, the second lowest value each year occurs around 28rd of November, Thanksigiving Day, when people stay home and celebrate with their families instead of shopping.","c51f401b":"## Feature selection","eda0df20":"Let's transform the data to get total daily sales. ","d0e4e2f7":"## SNAP (food stamps)","34c401fd":"To have a clear comparison we calculate sales distribution between categories in percentages.","c8104be2":"## Sales by stores","9106bf47":"In total there are 157 dates with a one event happening that day and 5 dates with two events happening on the same day.","0de62df0":"Cardinalities (number of unique categories for a given variable) of all variables are pretty small, apart from item_id and date. ","6ae0c4d2":"Products are out of stock for 20% of the time.","cf79ca60":"## Products","d2a4ab79":"## References","6d06c60f":"Categories distribution is roughly similar over years. \"Foods\" consitutes a vast majority (~70%) of overall sales, followed by \"Household\"."}}