{"cell_type":{"c2e76f62":"code","c32150a9":"code","61fbe2ef":"code","6ab29a67":"code","b050676a":"code","0332bffc":"code","2926635e":"code","3f5c4fb6":"code","d7f3a5f6":"code","eae9ba76":"code","0f19cfa9":"code","8bf310e4":"code","4c1f0a7d":"code","19cfe5b7":"code","dd3be1b0":"code","77705117":"code","d6ae5b5b":"markdown","4e440deb":"markdown","f3b98c66":"markdown","9722c761":"markdown","600058c8":"markdown","b5c329b1":"markdown","6fd7f085":"markdown","8ba67cfa":"markdown","f6b1ba0e":"markdown","9c7285a6":"markdown","0e16d229":"markdown","20ade214":"markdown","0a4bb537":"markdown"},"source":{"c2e76f62":"!pip install requests bs4 lxml wget","c32150a9":"import requests\nfrom bs4 import BeautifulSoup\nfrom multiprocessing import Pool\nfrom functools import partial\nimport os\nimport os.path as pth\nimport wget\nfrom zipfile import ZipFile","61fbe2ef":"def get_metadata(url, base_path='.\/'):\n    filename = url.split('\/')[-1]\n    full_filename = pth.join(base_path, filename)\n    if pth.exists(full_filename):\n        return full_filename, 1\n    wget.download(url, out=base_path)\n    ### If you can't use wget, you can use below blocked code\n    ### But It's much slower than wget...\n    # data = requests.get(url).data\n    # with open(full_filename, 'wb') as f:\n    #     f.write(data)\n    return full_filename, 0","6ab29a67":"target_url = 'https:\/\/storage.googleapis.com\/openimages\/web\/download.html'","b050676a":"page = requests.get(target_url).text\nsoup = BeautifulSoup(page, 'lxml')\nmain = soup.select_one('div.main')\nrows = main.select('div.row')\nrows = [row for row in rows \n            if row.select_one('div.col-10') and row.select_one('div.col-2.titlecol')]","0332bffc":"base_path = 'metadata\/'\nos.makedirs(base_path, exist_ok=True)","2926635e":"### !!!Remove!!! ###\n### Because of kaggle kernel disk space limit. \n### If you use this script, you must remove below line.\nrows = rows[:10] ### this line or cell must be removed!","3f5c4fb6":"for row in rows:\n    sub_name = row.select_one('div.col-2.titlecol').get_text().strip()\n    if sub_name:\n        sub_path = pth.join(base_path, sub_name)\n        os.makedirs(sub_path, exist_ok=True)\n        hrefs = [a.get('href') for a in row.select('a') if a.get('href')]\n        hrefs = [href for href in hrefs \n                    if href.endswith('.csv') or href.endswith('.txt')]      \n        if hrefs:\n            download_func = partial(get_metadata, base_path=sub_path)\n            pool = Pool(8)\n            for filename, status in pool.imap_unordered(download_func, hrefs):\n                if status == 0:\n                    print(filename + ' is saved.')\n                elif status == 1:\n                    print(filename + ' is already exist.')\n                else:\n                    print('???')\n                \n                ### !!!Remove!!! ###\n                ### Because of kaggle kernel disk space limit. \n                ### If you use this script, you must remove below line.\n                os.remove(filename) ### this line must be removed!\n            \n            pool.close()\n            pool.join()","d7f3a5f6":"base_path = pth.join('metadata', 'Segmentations')\nos.makedirs(base_path, exist_ok=True)\nbase_url = 'https:\/\/storage.googleapis.com\/openimages\/v5\/{}-masks\/{}-masks-{}.zip'","eae9ba76":"sub_list = ['train', 'validation', 'test']","0f19cfa9":"### !!!Remove!!! ###\n### Because of kaggle kernel disk space limit. \n### If you use this script, you must remove below line.\nsub_list = ['validation', 'test'] ### this line or cell must be removed!","8bf310e4":"for sub_name in sub_list:\n    sub_path = pth.join(base_path, sub_name)\n    os.makedirs(sub_path, exist_ok=True)\n    urls = [base_url.format(sub_name, sub_name, offset) \n            for offset in list(range(10))+['a','b','c','d','e','f']]\n    download_func = partial(get_metadata, base_path=sub_path)\n    pool = Pool(8)\n    for filename, status in pool.imap_unordered(download_func, urls):\n        if status == 0:\n            print(filename + ' is saved.')\n        elif status == 1:\n            print(filename + ' is already exist.')\n        else:\n            print('???')\n    pool.close()\n    pool.join()","4c1f0a7d":"for sub_name in sub_list:\n    sub_path = pth.join(base_path, sub_name)\n    zip_filename_list = [filename for filename in os.listdir(sub_path) if filename.endswith('.zip')]\n    for filename in zip_filename_list:\n        segment_zip_filename = pth.join(sub_path, filename)\n        with ZipFile(segment_zip_filename, 'r') as zip_ref:\n            zip_ref.extractall(sub_path)\n        os.remove(segment_zip_filename)\n        print(segment_zip_filename+ ' was extracted')","19cfe5b7":"!ls metadata","dd3be1b0":"!ls metadata\/Segmentations\/test | head","77705117":"### !!!Remove!!! ###\n### Because of kaggle kernel disk space limit. \n### If you use this script, you must remove below line.\n!rm -rf metadata\/ ### this line or cell must be removed!","d6ae5b5b":"# Download and Extract segmentation image file","4e440deb":"---","f3b98c66":"# Download metadata","9722c761":"### Download data","600058c8":"---\n# !!!Remove!!! \u2193","b5c329b1":"---\n# !!!Remove!!! \u2193","6fd7f085":"---","8ba67cfa":"---\n# !!!Remove!!! \u2193","f6b1ba0e":"### Extract image","9c7285a6":"---","0e16d229":"### Download zip","20ade214":"# Install and import package","0a4bb537":"# This code is useful if you download the metadata in your PC\n### **If you use this script, you have to remove some parts. (marked \"### !!!Remove!!! ###\")**\n\n##### This code based on web crawling. So this code is also good to study web crawling or data engineering :)\n---\n"}}