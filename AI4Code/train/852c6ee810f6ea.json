{"cell_type":{"ee829ecd":"code","b2665d4a":"code","475be158":"code","88de0072":"code","9df38387":"code","a34313aa":"code","dadeaf4f":"code","e7ee25ee":"markdown","32fe2f4b":"markdown","07b832d6":"markdown","df161a00":"markdown","70f03342":"markdown","798d2c34":"markdown"},"source":{"ee829ecd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n%matplotlib inline \nimport matplotlib.pyplot as plt\nimport os\n# Any results you write to the current directory are saved as output.\nfrom keras.layers import Layer\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.models import load_model\nfrom keras import callbacks\nimport os\nimport cv2\nimport string\nimport numpy as np\nfrom IPython.core.debugger import set_trace\n#Init main values\nsymbols = string.ascii_lowercase + \"0123456789\" # All symbols captcha can contain\nnum_symbols = len(symbols)\nimg_shape = (50, 200, 1)","b2665d4a":"def create_model():\n    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n\n    \n    \n    x = layers.Conv2D(16,\n               (3,3),\n               activation='relu',\n               padding='same',\n               name='Conv1')(img )\n    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n    \n    x = layers.Conv2D(32,\n               (3,3),\n               activation='relu',\n               padding='same',\n               name='Conv1')(img )\n    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n    \n    # Second conv block\n    x = layers.Conv2D(64,\n               (3,3),\n               activation='relu',\n               padding='same',\n               name='Conv2')(x)\n    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n    x = layers.BatchNormalization()(x)\n    # We have used two max pool with pool size and strides of 2.\n    # Hence, downsampled feature maps are 4x smaller. The number of\n    # filters in the last layer is 64. Reshape accordingly before\n    # passing it to RNNs\n    new_shape = ((50\/\/ 4), (200 \/\/ 4)*64)\n    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n    x = layers.Dense(64, activation='relu', name='dense1')(x)\n    x = layers.Dropout(0.2)(x)\n    \n    # RNNs\n    x = layers.Bidirectional(layers.LSTM(126,\n                                         return_sequences=True,\n                                        dropout=0.2))(x)\n\n    \n    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n    flat = layers.Flatten()(x)\n    outs = []\n    for _ in range(5):\n \n        dens1 = layers.Dense(64, activation='sigmoid')(flat)\n        drop = layers.Dropout(0.2)(dens1)\n        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n\n        outs.append(res)\n \n    # Compile model and return it\n    model = Model(img, outs)\n    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n  #  set_trace();\n    \n    return model","475be158":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport keras\nclass LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = {'batch':[], 'epoch':[]}\n        self.val_loss = {'batch':[], 'epoch':[]}\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses['batch'].append(logs.get('loss'))\n        self.val_loss['batch'].append(logs.get('val_loss'))\n\n    def on_epoch_end(self, batch, logs={}):\n        self.losses['epoch'].append(logs.get('loss'))\n        self.val_loss['epoch'].append(logs.get('val_loss'))\n\n    def loss_plot(self, loss_type):\n        iters = range(len(self.losses[loss_type]))\n        plt.figure()\n        # loss\n        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n        if loss_type == 'epoch':\n            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n        plt.grid(True)\n        plt.xlabel(loss_type)\n        plt.ylabel('acc-loss')\n        plt.legend(loc=\"upper right\")\n        plt.show()","88de0072":"def preprocess_data():\n    n_samples = len(os.listdir('..\/input\/captcha-version-2-images\/samples\/samples'))\n    X = np.zeros((n_samples, 50, 200, 1)) #1070*50*200\n    y = np.zeros((5, n_samples, num_symbols)) #5*1070*36\n\n    for i, pic in enumerate(os.listdir('..\/input\/captcha-version-2-images\/samples\/samples')):\n        # Read image as grayscale\n        img = cv2.imread(os.path.join('..\/input\/captcha-version-2-images\/samples\/samples', pic), cv2.IMREAD_GRAYSCALE)\n        pic_target = pic[:-4]\n        if len(pic_target) < 6:\n            # Scale and reshape image\n            img = img \/ 255.0\n            img = np.reshape(img, (50, 200, 1))\n            # Define targets and code them using OneHotEncoding\n            targs = np.zeros((5, num_symbols))\n            for j, l in enumerate(pic_target):\n                ind = symbols.find(l)\n                targs[j, ind] = 1\n            X[i] = img\n            y[:, i] = targs\n    \n    # Return final data\n    return X, y\n\nX, y = preprocess_data()\nX_train, y_train = X[:970], y[:, :970]\nX_test, y_test = X[970:], y[:, 970:]\nmodel=create_model()\n\n\nmodel.summary()","9df38387":"history = LossHistory()\nhist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]],validation_data=(X_test, [y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]]), batch_size=32, \n                 epochs=100,verbose=0,callbacks=[history])\nscore = model.evaluate(X_test, [y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]], verbose=0)\n\n# Define function to predict captcha\ndef predict(filepath):\n    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n    if img is not None:\n        img = img \/ 255.0\n    else:\n        print(\"Not detected\");\n    res = np.array(model.predict(img[np.newaxis, :, :, np.newaxis]))\n    ans = np.reshape(res, (5, 36))\n    l_ind = []\n    probs = []\n    for a in ans:\n        l_ind.append(np.argmax(a))\n        probs.append(np.max(a))\n\n    capt = ''\n    for l in l_ind:\n        capt += symbols[l]\n    return capt, sum(probs) \/ 5\n\nimport matplotlib.pyplot as plt\nimg=cv2.imread('..\/input\/captcha-version-2-images\/samples\/33f7m.png',cv2.IMREAD_GRAYSCALE)\nplt.imshow(img, cmap=plt.get_cmap('gray'))\nprint(predict('..\/input\/captcha-version-2-images\/samples\/33f7m.png'))\n\nhistory.loss_plot('epoch')","a34313aa":"import matplotlib.pyplot as plt\nimg=cv2.imread('..\/input\/captcha-version-2-images\/samples\/33f7m.png',cv2.IMREAD_GRAYSCALE)\nplt.imshow(img, cmap=plt.get_cmap('gray'))\nprint(predict('..\/input\/captcha-version-2-images\/samples\/33f7m.png'))\nhistory.loss_plot('epoch')","dadeaf4f":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model1.png',show_shapes=True)","e7ee25ee":"# **Create model for training**","32fe2f4b":"# **Setting loss definition**","07b832d6":"# **IMPORT DATA AND PROCESS IMAGE**","df161a00":"# Select one example","70f03342":"# **Tranining model and build prediction model**","798d2c34":"# **import library and import tools**"}}