{"cell_type":{"a1a1a9e0":"code","bdf3db13":"code","c65bc099":"code","e1d16d32":"code","14e10e80":"code","24a3d5e7":"code","5cb5a45c":"code","dfc755d9":"code","6d8a708f":"code","8d495148":"code","f626f7c6":"code","95359524":"code","f86b869f":"code","a81b2145":"code","36bb19c4":"code","a0e1eaeb":"code","dcaee41a":"code","50d2d35f":"code","b0fdc3e5":"markdown","a81c72a2":"markdown"},"source":{"a1a1a9e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bdf3db13":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import plot_importance","c65bc099":"train_data = pd.read_csv(\"\/kaggle\/input\/jane-street-market-prediction\/train.csv\")\nfeature_data = pd.read_csv(\"\/kaggle\/input\/jane-street-market-prediction\/features.csv\")\nexample_test =  pd.read_csv(\"\/kaggle\/input\/jane-street-market-prediction\/example_test.csv\")","e1d16d32":"print(train_data.shape)\ntrain_data.head()","14e10e80":"train_data.describe()","24a3d5e7":"train_data.isnull().sum()","5cb5a45c":"feature_data.head()","dfc755d9":"example_test.head()","6d8a708f":"resps = train_data[['resp_1','resp_2','resp_3','resp_4','resp']]\npd.plotting.scatter_matrix(resps, figsize=(6, 6))\nplt.show()","8d495148":"# train_data_noN = train_data.dropna()\n\ntrain_data.fillna(0,inplace=True)\ntrain_data_noN = train_data\ntrain_data = train_data_noN[train_data_noN['weight'] != 0]\nprint(train_data.shape)","f626f7c6":"feature_names = ['feature_'+str(i) for i in range(130)]\n\n# feature_names = [ 'feature_1', 'feature_2', 'feature_6', 'feature_9',\n#        'feature_10', 'feature_16', 'feature_20', 'feature_29', 'feature_37',\n#        'feature_38', 'feature_39', 'feature_40', 'feature_51', 'feature_52',\n#        'feature_53', 'feature_54', 'feature_69', 'feature_70', 'feature_71',\n#        'feature_83', 'feature_100', 'feature_109', 'feature_112',\n#        'feature_122', 'feature_123', 'feature_124', 'feature_126',\n#        'feature_128', 'feature_129','weight']\nprint(len(feature_names))","95359524":"\ntrain_data['action'] = (train_data_noN['resp'] > 0).astype('int') \n\n# X = train_data_noN.drop(['resp_1','resp_2','resp_3','resp_4','resp','weight','date','ts_id'],axis=1)\n\n# Y = train_data.loc[:, 'action']\nY = train_data.loc[:, 'resp']\nX= train_data.loc[:,feature_names]\nprint(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=15)","f86b869f":"# param = {'max_depth': 5, 'eta': 0.1, 'objective': 'binary:logistic','eval_metric':'auc'}\nparam = {'max_depth': 5, 'eta': 0.1}\nnum_round =500\n\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)\nevallist = [(dtest, 'eval'), (dtrain, 'train')]\nbst = xgb.train(param, dtrain, num_round,evallist,early_stopping_rounds=30, verbose_eval= 50)\nbst.save_model('xgb2.model')","a81b2145":"# fig,ax = plt.subplots(figsize=(25,50))\n# lgbm.plot_importance(bst, ax=ax,importance_type='gain',max_num_features=130)\n# plt.show()\nplot_importance(bst)\nplt.show()","36bb19c4":"\nbst = xgb.Booster({'nthread': 4})  # init model\nbst.load_model('xgb2.model')  # load data","a0e1eaeb":"to_action = lambda t: 1 * (t > 0)\n    ","dcaee41a":"test_data =  example_test.loc[:, feature_names]\n# test_data.head()\ntest_matrix = xgb.DMatrix(test_data )\n\ny_preds = bst.predict(test_matrix)\nprint(y_preds)\ny_preds = to_action(bst.predict(test_matrix))\nprint(y_preds)","50d2d35f":"import janestreet\nenv = janestreet.make_env() # ini tialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\n\nfor (test_df, sample_prediction_df) in iter_test:\n    if test_df['weight'].item() > 0:\n        test = test_df.loc[:, feature_names]\n        test = test.fillna(0)\n        #         print(X_test.shape)\n        test_matrix = xgb.DMatrix(test)\n        y_preds = to_action(bst.predict(test_matrix))\n        sample_prediction_df.action = y_preds.astype(int)  #make your 0\/1 prediction here\n    else:\n        sample_prediction_df.action = 0\n    env.predict(sample_prediction_df)","b0fdc3e5":"select some features, Reference\n[Jane Day 242 Feature Generation and Selection](https:\/\/www.kaggle.com\/rajkumarl\/jane-day-242-feature-generation-and-selection)","a81c72a2":"Thanks to the following notebooks I used as references\n\nhttps:\/\/www.kaggle.com\/archanabenur\/lightgbm-and-catboost-prediction\n\nhttps:\/\/www.kaggle.com\/arunamenon\/stock-price-jane-street-forecasting\/output\n\nhttps:\/\/www.kaggle.com\/kamalnaithani\/lightgbm-stock-prediction-1-1\n"}}