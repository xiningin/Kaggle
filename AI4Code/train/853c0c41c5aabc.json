{"cell_type":{"69d3e778":"code","5271e483":"code","bd5125a1":"code","825fecad":"code","cc017fc2":"code","e7f2ff77":"code","6dbf8e87":"code","b89e8967":"code","977421e8":"code","2e05a6bf":"code","bac1904c":"code","c23cc2c1":"code","8e530027":"code","21e26376":"code","d59230f5":"code","6f8299b3":"code","74f7b0f1":"code","88eec097":"markdown","6fabb09c":"markdown","b864abd4":"markdown","21dd504d":"markdown","594571b9":"markdown","84fe7f45":"markdown","2e5cea54":"markdown"},"source":{"69d3e778":"data_dir = \"\/kaggle\/input\/covid19-global-forecasting-week-1\/\"","5271e483":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport datetime\nimport tensorflow as tf\nimport math","bd5125a1":"train_df_raw = pd.read_csv(data_dir+\"train.csv\")\ntest_df_raw = pd.read_csv(data_dir+\"test.csv\")\nall_df = train_df_raw\ntest_df = test_df_raw","825fecad":"# paramerers\nmaxlen = 30\nhidden_number = 32\ninput_number = 5\noutput_number = 2\nbatch_size = 32\nepochs = 50\nlr = 0.001","cc017fc2":"def map_datetime(date):\n    return (date - datetime.datetime.strptime('2020-01-22', \"%Y-%m-%d\")).days\n\ndef to_datetime(date):\n    return datetime.datetime.strptime(date, \"%Y-%m-%d\")","e7f2ff77":"test_df = test_df.fillna({\"Province\/State\": \"NAN\"})\nall_df = all_df.fillna({\"Province\/State\": \"NAN\"})\n\nall_df[\"ConfirmedCases\"] = (all_df[\"ConfirmedCases\"] + 1).map(math.log10)\ncases_max = all_df[\"ConfirmedCases\"].max()\nfatal_max = all_df[\"Fatalities\"].max()\n\nall_df[\"Lat\"] = all_df[\"Lat\"]\/180.\nall_df[\"Long\"] = all_df[\"Long\"]\/180.\nall_df[\"ConfirmedCases\"] = all_df[\"ConfirmedCases\"] \/ cases_max\nall_df[\"Fatalities\"] = all_df[\"Fatalities\"] \/ fatal_max\n\nall_df[\"Date\"] = all_df[\"Date\"].map(to_datetime)\nall_df[\"Date_num\"] = all_df[\"Date\"].map(map_datetime)\ndate_max = all_df[\"Date_num\"].max()\nall_df[\"Date_num\"] = all_df[\"Date_num\"] \/ date_max\n\ndate_unit = all_df.iloc[1][\"Date_num\"] - all_df.iloc[0][\"Date_num\"]\n\nval_df = all_df[all_df[\"Date\"] > (all_df[\"Date\"].max() - datetime.timedelta(days=(maxlen+1)))]\ntrain_df = all_df.drop(all_df[all_df[\"Date_num\"] == all_df[\"Date_num\"].max()].index)","6dbf8e87":"test_df[\"Lat\"] = test_df[\"Lat\"]\/180.\ntest_df[\"Long\"] = test_df[\"Long\"]\/180.\ntest_df[\"Date\"] = test_df[\"Date\"].map(to_datetime)\ntest_df[\"Date_num\"] = test_df[\"Date\"].map(map_datetime)\ntest_df[\"Date_num\"] = test_df[\"Date_num\"] \/ date_max","b89e8967":"def make_sequences(train_df):\n    inputs = []\n    targets = []\n    for i in range(len(train_df) - maxlen - 1):\n        if train_df.iloc[i][\"Lat\"] == train_df.iloc[i+maxlen][\"Lat\"] and \\\n           train_df.iloc[i][\"Long\"] == train_df.iloc[i+maxlen][\"Long\"]:\n            inputs.append(np.array(train_df.iloc[i:i+maxlen][[\"Date_num\", \"Lat\", \"Long\", \"ConfirmedCases\", \"Fatalities\"]]).tolist())\n            targets.append(np.array(train_df.iloc[i+maxlen][[\"ConfirmedCases\", \"Fatalities\"]]).tolist())\n    return inputs, targets","977421e8":"train_inputs, train_targets = make_sequences(train_df)\nval_inputs, val_targets = make_sequences(val_df)","2e05a6bf":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.LSTM(hidden_number, batch_input_shape=[None, maxlen, input_number], return_sequences=True))\nmodel.add(tf.keras.layers.LSTM(hidden_number))\nmodel.add(tf.keras.layers.Dense(output_number, activation=\"sigmoid\"))\n\noptimizer = tf.keras.optimizers.Adam(lr=lr)\nmodel.compile(loss=\"mean_squared_error\", optimizer=optimizer)","bac1904c":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=5)\nhistory = model.fit(train_inputs, train_targets,\n                    batch_size=batch_size,\n                      epochs=epochs,\n                      validation_data=(val_inputs, val_targets),\n                      callbacks = [early_stopping]\n                      )","c23cc2c1":"results = []\nfor idx in test_df.groupby([\"Province\/State\", \"Country\/Region\"]).count().index:\n    test_df_on_idx = test_df[(test_df[\"Province\/State\"] == idx[0]) &\n                             (test_df[\"Country\/Region\"] == idx[1])]\n    train_df_on_idx = train_df[(all_df[\"Country\/Region\"] == idx[1]) &\n                               (all_df[\"Province\/State\"] == idx[0])]\n    inputs = np.array(train_df_on_idx[[\"Date_num\", \"Lat\", \"Long\", \"ConfirmedCases\", \"Fatalities\"]])[-maxlen:]\n    inputs = inputs.reshape(maxlen, input_number)\n    for day in range(43):\n        if int(1000000000*(datetime.timedelta(days=day) + test_df_on_idx[\"Date\"].min()).timestamp()) in train_df_on_idx[\"Date\"].values.tolist():\n            result = np.array(train_df_on_idx[train_df_on_idx[\"Date\"] == (datetime.timedelta(days=day) + test_df_on_idx[\"Date\"].min())][[\"Date\", \"Lat\", \"Long\", \"ConfirmedCases\", \"Fatalities\"]])[0, 3:]\n        else:\n            result = model.predict(np.array(inputs).reshape(1, maxlen, input_number)).reshape(-1)\n            inputs = np.concatenate((inputs[1:], np.append(inputs[-1, :3], result).reshape(1, input_number)), axis=0)\n        results.append([10**(result[0]*cases_max), result[1]*fatal_max])","8e530027":"submit_df = pd.read_csv(data_dir+\"submission.csv\", index_col=0)","21e26376":"submit_df","d59230f5":"cases = []\nfatals = []\nfor i in range(len(results)):\n    n = results[i][0] \n    f = results[i][1]\n    try:\n        cases.append(int(n))\n    except:\n        cases.append(0)\n    \n    try:\n        fatals.append(int(f))\n    except:\n        fatals.append(0)","6f8299b3":"submit_df[\"ConfirmedCases\"] = cases\nsubmit_df[\"Fatalities\"] = fatals","74f7b0f1":"submit_df.to_csv(\"submission.csv\")","88eec097":"# Make LSTM model\nIn this section, I made two layered simple LSTM model.","6fabb09c":"# Read dataset","b864abd4":"# Prediction phase","21dd504d":"# Preprocessing\n\nI Normalize the numeric values and make date column to the numeric values.   \nThe final day of the training dataset is used as the validation data.","594571b9":"# Preprocessing for LSTM\n\nReshape the dataset to sequences.  \n\nInput data components are Latitude, Longnitude, Date, ConfirmedCases, Fatalities.  \nOutput data components are ConfirmedCases, Fatalities.  \n","84fe7f45":"test dataframe is also preprocessed","2e5cea54":"Predict 43 days recursively by many-to-one LSTM model.  \nThe prediction step is one step. So, the prediction is recursively continued to predict 43 days cases."}}