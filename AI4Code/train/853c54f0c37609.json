{"cell_type":{"64f89685":"code","68654364":"code","893e93a3":"code","b026b3da":"code","2e5fc450":"code","8b425993":"code","00f1a2f9":"code","a90ca7e1":"code","465983f8":"code","1b9cf8cd":"code","cfcbb53b":"code","cc725611":"code","09a2f216":"code","d7d3c83f":"code","a676d59b":"code","74dad8b4":"code","4bcc7587":"code","5704b72b":"code","af6a32c6":"code","620c2894":"code","ee8fcda3":"code","a394a647":"code","fbdceb58":"code","29be7f60":"code","cdc5a10f":"code","d943374b":"code","009a9d01":"markdown","9f36d08e":"markdown","34bacd2f":"markdown"},"source":{"64f89685":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt","68654364":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf=[train,test]","893e93a3":"test['Survived']=np.nan","b026b3da":"train.info()\ntest.info()","2e5fc450":"for data in df:\n#     print(data.isnull().sum())\n#     data['Age'].fillna(data['Age'].mean(),inplace=True)\n    data['Embarked'].fillna(data['Embarked'].mode()[0],inplace=True)\n    data['Fare'].fillna(data['Fare'].mean(),inplace=True)\n    data['Cabin']=data['Cabin'].fillna(\"Unknown\")\n    data['Deck']=data['Cabin'].str.get(0)","8b425993":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nfor data in df:\n    data['Sex']=le.fit_transform(data['Sex'])\n    \n    data['Embarked']=le.fit_transform(data['Embarked'])\n    \n    data['Name']=data['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip())\n    Title_Dict = {}\n    Title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))\n    Title_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))\n    Title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))\n    Title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))\n    Title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))\n    Title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))\n    data['Title'] = data['Name'].map(Title_Dict)\n    data['Title']=le.fit_transform(data['Title'])\n    \n    data['Lastname']=data['Name'].apply(lambda x: str.split(x, \",\")[0])\n\n    data['Age'] = data.groupby('Title')['Age'].transform(lambda x: x.fillna(x.median()))\n    \n#     data['FareBin'] = pd.qcut(data['Fare'], 5)\n#     data['FareBin']=le.fit_transform(data['FareBin'])\n    \n    data['Fare']=(data['Fare']-data['Fare'].min())\/(data['Fare'].max()-data['Fare'].min())\n\n    data['FamilySize']=data['Parch']+data['SibSp']+1\n    \n    data['TravelAlone']=np.where(data['FamilySize']>1, 0, 1)\n    \n    data['Deck']=le.fit_transform(data['Deck'])\n    \n#     data['AgeBin'] = pd.qcut(data['Age'], 4)\n#     data['AgeBin']=le.fit_transform(data['AgeBin'])\n    \n#     Ticket_Count = dict(data['Ticket'].value_counts())\n#     data['TicketGroup'] = data['Ticket'].apply(lambda x:Ticket_Count[x])#.apply(label)\n    ","00f1a2f9":"train.info()\ntest.info()","a90ca7e1":"X= pd.concat([train, test])","465983f8":"DEFAULT_SURVIVAL_VALUE = 0.5\nX['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n\nfor grp, grp_df in X[['Survived','Name', 'Lastname', 'Fare', 'Ticket', 'PassengerId',\n                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Lastname', 'Fare']):\n    \n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                X.loc[X['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin==0.0):\n                X.loc[X['PassengerId'] == passID, 'Family_Survival'] = 0\n\nfor _, grp_df in X.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    X.loc[X['PassengerId'] == passID, 'Family_Survival'] = 1\n                elif (smin==0.0):\n                    X.loc[X['PassengerId'] == passID, 'Family_Survival'] = 0\n                        ","1b9cf8cd":"X.info()","cfcbb53b":"train=X[0:len(train)]\ntest=X[len(train):]\ntrain=train.drop(['PassengerId','Ticket',\"Cabin\",'Name','SibSp','Parch','Age','Fare','Lastname'],axis='columns')\ntest=test.drop(['PassengerId','Survived','Ticket',\"Cabin\",'Name','SibSp','Parch','Age','Fare','Lastname'],axis='columns')\ntrain.info()\ntest.info()","cc725611":"train.sample(10)","09a2f216":"X=train.drop(['Survived'],axis='columns').values\nY=train['Survived'].values\n# from sklearn.model_selection import train_test_split\n# x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)","d7d3c83f":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=5, test_size=0.2)","a676d59b":"from sklearn.ensemble import RandomForestClassifier\nbase_model=RandomForestClassifier()\nbase_model.fit(X,Y)","74dad8b4":"pred=base_model.predict(X)\n# pred=[int(round(x[0])) for x in pred]\n# print(pred[0:10])\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(Y,pred))\nfrom sklearn.metrics import accuracy_score\naccuracy_score(Y,pred)","4bcc7587":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nrandom_grid = {\n                 'bootstrap': [True, False],\n 'max_depth': [2,5,7,10,12,15],\n 'max_features': [3, 'sqrt','log2'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [1,2,3,4],\n 'n_estimators': [50,100,150,200,250,300,350],\n \"criterion\": [\"gini\", \"entropy\"]\n             }","5704b72b":"clf=RandomForestClassifier()\nrandom_model=RandomizedSearchCV(estimator = clf, param_distributions = random_grid,n_iter=700, cv = sss, verbose=2, n_jobs = -1)\nrandom_model.fit(X,Y)","af6a32c6":"print(random_model.best_score_)\nrandom_model.best_params_","620c2894":"best_random = random_model.best_estimator_\npred=best_random.predict(X)\n# pred=[int(round(x[0])) for x in pred]\n# print(pred[0:10])\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(Y,pred))\nfrom sklearn.metrics import accuracy_score\naccuracy_score(Y,pred)","ee8fcda3":"grid_param= {\n    'bootstrap': [False],\n    'max_depth': [4,5,6],\n    'max_features': [3],\n    'min_samples_leaf': [3,4,5],\n    'min_samples_split': [4],\n    'criterion': ['entropy'],\n    'n_estimators': [230,240,250]\n}","a394a647":"clf1=RandomForestClassifier()\ngrid_model = GridSearchCV(estimator = clf1, param_grid = grid_param, \n                          cv = sss, n_jobs = -1, verbose = 2)\ngrid_model.fit(X,Y)","fbdceb58":"print(grid_model.best_score_)\ngrid_model.best_params_","29be7f60":"best_grid = grid_model.best_estimator_\npred=best_grid.predict(X)\n# pred=[int(round(x[0])) for x in pred]\n# print(pred[0:10])\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(Y,pred))\nfrom sklearn.metrics import accuracy_score\naccuracy_score(Y,pred)","cdc5a10f":"preds=grid_model.predict(test.values)\npreds=[int(x) for x in preds]\nsamp=pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsamp[\"Survived\"]=preds\nsamp[\"Survived\"].value_counts()","d943374b":"samp.to_csv(\"output.csv\",index=False)","009a9d01":"# Model","9f36d08e":"# Feature Engineering","34bacd2f":"# Hyperparameter Tuning"}}