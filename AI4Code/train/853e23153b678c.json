{"cell_type":{"06085a67":"code","b0a40197":"code","ca4d2ee6":"code","dfc09d82":"code","8fcdc1e6":"code","49a3d5ca":"code","e41a38f0":"code","9367f503":"code","0534a095":"code","9a2754fd":"code","9ab56945":"code","9fa662a3":"code","41b83777":"code","161e3748":"code","d30f3b01":"code","05a9b09f":"code","fdc38273":"code","80bbd230":"code","575f7ad2":"code","f0a8cd7a":"code","c5ee0b6c":"code","954e533a":"markdown","a2f4d895":"markdown","30a39986":"markdown","f9cbe878":"markdown","f173662a":"markdown","5a97c6e8":"markdown","aa5b9d4a":"markdown","51103613":"markdown","33967557":"markdown"},"source":{"06085a67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b0a40197":"#IMPORTING LIBARIES\nimport tensorflow as tf \nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator","ca4d2ee6":"#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\ntraining_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","dfc09d82":"#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1.\/255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","8fcdc1e6":"#defining the CNN as a sequence of layers.\ncnn = tf.keras.models.Sequential()","49a3d5ca":"#adding 1st Convolutional layer\n#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))\n#activation function relu is applied to decrease any linearity that might have arrised while applying filters.","e41a38f0":"# applying max pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","9367f503":"#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","0534a095":"#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","9a2754fd":"#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())","9ab56945":"#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","9fa662a3":"#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))","41b83777":"#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","161e3748":"#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)","d30f3b01":"cnn.save('catdog_cnn_model.h5')","05a9b09f":"from keras.models import load_model \nclassifier = load_model('catdog_cnn_model.h5')","fdc38273":"import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","80bbd230":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg')","575f7ad2":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","f0a8cd7a":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg')","c5ee0b6c":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","954e533a":"# **0 MEANS CATS AND 1 MEANS DOGS**","a2f4d895":"Here we will apply the max pooling.Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map.","30a39986":"# **STEP - 2) APPLYING MAX POOLING**","f9cbe878":"# **STEP - 4 ) FULL CONNECTION**","f173662a":"# **STEP -3 ) FLATTENING**","5a97c6e8":"# **Addition of 2nd convolution layer.**","aa5b9d4a":"CNN IS DIVIDED INTO 4 STEPS\n\n* CONVOLUTION\n\n* POOLING\n\n* FLATTENING\n\n* FULL CONNECTION","51103613":"# # **STEP - 1) ADDING CONVOLUTIONAL LAYER**","33967557":"# **PREDICTING VALUES**"}}