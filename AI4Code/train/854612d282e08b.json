{"cell_type":{"8a21b58c":"code","55d48493":"code","fd0b4cc2":"code","1500776b":"code","41589f02":"code","1de6683a":"code","919fb41e":"code","d804a528":"code","5de322d2":"code","00ab7a15":"code","3c4667eb":"code","54ad6cc9":"code","787ad63c":"code","1dc82b4d":"code","7e330cd5":"code","ad5191bb":"code","eaf043b0":"code","eccde1f5":"code","c9ec6b2d":"code","31fa305f":"code","6d24a55b":"code","e545913a":"code","2f6874d3":"code","0ac37121":"code","d1d598ba":"code","c2c16a04":"code","6b09e3de":"code","0f787c8d":"code","8969fbb1":"code","0d7cf555":"code","a495b4e5":"code","fbdc8eb2":"code","655f8326":"markdown","de6c0ddc":"markdown","4ca243dd":"markdown","82dde7cc":"markdown","ab9e4715":"markdown","52482b97":"markdown","5eebb4cd":"markdown","662b3074":"markdown","b13cb082":"markdown","6a68e869":"markdown","eaacd0b8":"markdown","922d0812":"markdown","4344c4b8":"markdown","61c31c33":"markdown","05a1f3d8":"markdown","e4189196":"markdown","d8890952":"markdown","21b49298":"markdown","c5853846":"markdown","b92455c3":"markdown","3bad6ce8":"markdown","c0c01dac":"markdown","972cb385":"markdown","4b08ed36":"markdown","592028c6":"markdown","57dc3d3d":"markdown","bc13c552":"markdown","4aba359f":"markdown","3c481f46":"markdown","daf5b9a9":"markdown","e60f1424":"markdown","045b8a63":"markdown","47d03333":"markdown"},"source":{"8a21b58c":"import os\nimport numpy as np \nimport pandas as pd \nfrom sklearn import preprocessing\nfrom tqdm import tqdm_notebook #gives a progress bar\nimport seaborn as sns\n\n# Maps\nimport folium\nfrom folium.plugins import MarkerCluster\nfrom geopy.geocoders import Nominatim\n\n# Matplot\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nplt.style.use('seaborn-whitegrid')\nimport matplotlib.image as mpimg\n\n# NLP\/WordCloud\nimport nltk\nfrom collections import Counter\nimport regex as re\nfrom wordcloud import WordCloud\n\n#Images\nfrom PIL import Image\n\n# Additional Libraries\nimport warnings\nimport matplotlib.cbook\nwarnings.filterwarnings(\"ignore\")\nfrom scipy import stats\n\n# Load data\ndata = pd.read_csv('..\/input\/pakistan-startup-census\/Pakistan Startup Census.csv');","55d48493":"print(data.shape)\ndata.head()","fd0b4cc2":"data.info()","1500776b":"data = data.dropna(how='all')\nprint(data.shape)","41589f02":"data[['Name','Location','Tagline','Category','Website','Founded','Description']] = data[['Name','Location','Tagline','Category','Website','Founded','Description']].astype('string')\nprint(data.dtypes)","1de6683a":"# this will isolate only the year, which is all we want\ndata[['Founded','Month','Year']] = data.Founded.str.split(\" \", n=2,expand=True)\ndata = data[~data.Founded.str.contains(\"-\")]\n\ndata.loc[data['Year'].isnull(),'Year'] = data['Founded']\n\ndata = data.drop(['Founded','Month'], axis=1)\ndata = data.rename(columns={'Year':'Founded'})\n# strip empty spaces\ndata['Founded'] = data.Founded.str.strip()\ndata = data[data['Founded'].astype(bool)].reset_index()\ndata = data.drop('index', axis=1)\n\ndata['Founded'] = data['Founded'].astype('int')","919fb41e":"# create new dataset that drops any location not in Pakistan\na = [\"States\",'Raleigh', 'York','USA','Canada','England', 'California', 'Los','South','Amsterdam']\npak = data[~data.Location.str.contains('|'.join(a))]\n\n# Make location data only city names\ncity = set(['Karachi', 'Lahore', 'Islamabad','Faisalabad','Rawalpindi',\n        'Peshawar','Gujrat','Sialkot','Hyderabad','Multan','Sargodha',\n        'Faisalabad','Quetta','Wah','Gujranwala','Pakhtunkhwa'\n       ])\n\n\npak['City'] = pak.Location.str.extract('({0})'.format('|'.join(city)))","d804a528":"geolocator = Nominatim(user_agent=\"example\")\n\nlat = []\nlon = []\nfor j in pak['City']:\n    try:\n        loc = geolocator.geocode(j).raw\n        lat.append(loc['lat'])\n        lon.append(loc['lon'])\n    except:\n        lat.append(np.nan)\n        lon.append(np.nan)  \n        \n# convert to series and add as column in dataset\nla = pd.Series(lat)\nlo = pd.Series(lon)\n\npak['Lat'] = la.values\npak['Lon'] = lo.values\n\npak[['Lat','Lon']] = pak[['Lat','Lon']].astype(float)","5de322d2":"#add some noise to each item in the series because they won't all be at the exact same GPS\npak['Lat'] = pak['Lat'].apply(lambda x: x + np.random.rand()\/10.0)\npak['Lon'] = pak['Lon'].apply(lambda x: x + np.random.rand()\/10.0)\n\nprint(pak.shape)\npak.head()","00ab7a15":"startup_dist = data.loc[data['Founded'] >1999]\n\nplt.subplots(figsize=(18,10))\nstartup_dist.Founded.value_counts().plot(kind='bar', color='green')\nplt.xlabel(\"Year\", fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"Pakistani Startup Distribution\", fontsize=20);","3c4667eb":"# Pakistan Map\nPakistan = folium.Map(location=[30.5,69.5], tiles='cartodbpositron',\n                      min_zoom=3.5, max_zoom=12, zoom_start=5)","54ad6cc9":"mc = MarkerCluster()\n\nfor i in range(0,len(pak)):\n    mc.add_child(folium.Marker([pak.iloc[i]['Lat'], pak.iloc[i]['Lon']],\n                               tooltip = '<li><bold>City: ' +str(pak.iloc[i]['City'])+\n                                '<li><bold>Company: ' +str(pak.iloc[i]['Name'])+ \n                                '<li><bold>Website: ' +str(pak.iloc[i]['Website'])+ \n                                '<li><bold> Founded: ' +str(pak.iloc[i]['Founded']))\n                              )\n    \nPakistan.add_child(mc)\n\nPakistan","787ad63c":"x = pak.City.value_counts(normalize=True).round(3).tolist()\n\n\nplt.style.use('fivethirtyeight')\nplt.subplots(figsize=(14,7))\npak.City.value_counts(normalize=True).plot(kind='barh',color='green')\nfor i, v in enumerate(x):\n    plt.text(v+.0025, i, str(v*100)+'%', fontweight='bold',\n            Bbox = dict(facecolor = 'green', alpha =.2))\nplt.xlabel(\"City\", fontsize=14)\nplt.ylabel(\"Distribution of Startups\", fontsize=14)\nplt.title(\"Pakistani Startup Distribution\", fontsize=20);","1dc82b4d":"pak_g = pak.loc[pak['Founded'] >1999]","7e330cd5":"img = plt.imread('..\/input\/pakistan-photo\/pak_photo.jpeg')","ad5191bb":"pak_2000s = pak_g.loc[pak_g['Founded'] <2006]\n\nplt.style.use('default')\nplt.figure(figsize=(16, 8))\nax = sns.countplot(pak_2000s['City'], palette='hls')\n\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1,3,0,4.1])\n\nplt.xlabel('', fontsize=5)\nplt.ylabel(\"# of Startups\", fontsize=12)\nplt.title(\"2000-2005\", fontsize=20);","eaf043b0":"pak_2000ss = pak_g.loc[(pak_g['Founded']>2005) & (pak_g['Founded'] < 2011)]\n\nplt.figure(figsize=(18,10))\nax = sns.countplot(pak_2000ss['City'], palette='rocket')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2006-2010\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 6, 0, 6.2]);","eccde1f5":"pak_2011 = pak_g.loc[pak_g['Founded']==2011]\n\nplt.figure(figsize=(18,10))\nax = sns.countplot(pak_2011['City'], palette='hls')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2011\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 3, 0, 3.2]);","c9ec6b2d":"pak_2012 = pak_g.loc[pak_g['Founded']==2012]\n\nplt.figure(figsize=(18, 10))\nax = sns.countplot(pak_2012['City'], palette='rocket')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2012\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 4, 0, 4.2]);","31fa305f":"pak_2013 = pak_g.loc[pak_g['Founded']==2013]\n\nplt.figure(figsize=(18, 10))\nax = sns.countplot(pak_2013['City'], palette='hls')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2013\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 3, 0, 6.2]);","6d24a55b":"pak_2014 = pak_g.loc[pak_g['Founded']==2014]\n\nplt.figure(figsize=(18, 10))\nax = sns.countplot(pak_2014['City'], palette='hls')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2014\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 8, 0, 20]);","e545913a":"pak_2015 = pak_g.loc[pak_g['Founded']==2015]\n\nplt.figure(figsize=(18, 12))\nax = sns.countplot(pak_2015['City'], palette='rocket_r')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2015\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 7, 0, 45]);","2f6874d3":"pak_2016 = pak_g.loc[pak_g['Founded']==2016]\n\nplt.figure(figsize=(18,12))\nax = sns.countplot(pak_2016['City'], palette='Spectral')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2016\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 9, 0, 53]);","0ac37121":"pak_2017 = pak_g.loc[pak_g['Founded']==2017]\n\nplt.figure(figsize=(18,12))\nax = sns.countplot(pak_2017['City'], palette='hls')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2017\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 8, 0, 20]);","d1d598ba":"pak_2018 = pak_g.loc[pak_g['Founded']==2018]\n\nplt.figure(figsize=(18,12))\nax = sns.countplot(pak_2018['City'], palette='hls')\nplt.xlabel('', fontsize=14)\nplt.ylabel(\"# of Startups\", fontsize=14)\nplt.title(\"2018\", fontsize=20)\nplt.imshow(img, aspect='auto', alpha=155, extent=[-1, 4, 0, 4.2]);","c2c16a04":"cat_low = data['Category'].str.cat(sep=' ')\n    \ncat = re.sub(\"\\s*-\\s*\", \"\", cat_low)\ncat_words = re.sub('&',' ', cat)\n\ncat_tokens = re.findall('\\S+', cat_words)\nfor word in cat_tokens:\n    if len(word) < 3:\n        cat_tokens.remove(word)\n        \n#remove stop words\nstop_words = nltk.corpus.stopwords.words('english')\n\nbest_cat = []\nfor word in cat_tokens:\n    if word not in stop_words:\n        best_cat.append(word)","6b09e3de":"def i_wc(data,bgcolor,title):\n    plt.figure(figsize = (60,60))\n    wc = WordCloud(background_color = bgcolor, max_words = 200, max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.imshow(wc.recolor(colormap= 'terrain'))\n    plt.axis('off')\n\ni_wc(best_cat,'black','Common Words' )","0f787c8d":"tag_low = data['Tagline'].str.lower().str.cat(sep=' ')\n    \ntag_words = re.sub('[^A-Za-z]+', ' ', tag_low)\n\ntag_tokens = re.findall('\\w+', tag_words)\nfor word in tag_tokens:\n    if len(word) < 2:\n        tag_tokens.remove(word)\n\n\n#remove stop words\nstop_words = nltk.corpus.stopwords.words('english')\n\nbest_tag = []\nfor word in tag_tokens:\n    if word not in stop_words:\n        best_tag.append(word)","8969fbb1":"def t_wc(data,bgcolor,title):\n    plt.figure(figsize = (80,80))\n    wc = WordCloud(background_color = bgcolor, max_words = 1000, max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.imshow(wc.recolor(colormap= 'terrain'))\n    plt.axis('off')\n\nt_wc(best_tag,'black','Common Words' )","0d7cf555":"des_low = data['Description'].str.lower().str.cat(sep=' ')\n    \ndes_words = re.sub('[^A-Za-z]+', ' ', des_low)\n\ndes_tokens = re.findall('\\w+', des_words)\nfor word in des_tokens:\n    if len(word) < 2:\n        des_tokens.remove(word)\n\n\n#remove stop words\nstop_words = nltk.corpus.stopwords.words('english')\n\nbest_des = []\nfor word in des_tokens:\n    if word not in stop_words:\n        best_des.append(word)","a495b4e5":"pak_mask = np.array(Image.open('..\/input\/pakistan-img\/pak_flag.png'))","fbdc8eb2":"def d_wc(data,bgcolor,title):\n    plt.figure(figsize = (100,100))\n    wc = WordCloud(background_color = bgcolor, max_words = 20000, mask=pak_mask, max_font_size = 120)\n    wc.generate(' '.join(data))\n    plt.imshow(wc.recolor(colormap= 'Dark2_r'))\n    plt.axis('off')\n    plt.title(title, fontsize=18)\n\nd_wc(best_des,'white','Most Common Startup Descriptions' )","655f8326":"## Conclusion","de6c0ddc":"\ud83d\udccc **Note:** No startups inside Pakistan in 2001.\n","4ca243dd":"### 4.1 Map","82dde7cc":"Looks like most of the startups in Pakistan are concentrated in three cities, with a few others dispersed througout the country. It makes sense that most of the startups would be in Karachi and Lahore, the two largest cities in Pakistan, and that Islamabad, the capital, would house the third most. These cities likely have more people, resources, and opportunity. \n\nAdditionally, we can see that most of the startups are tech related and that the number of startups in the country really started to take off in the 2010s. \n\nHopefully, this industry will continue to grow and these companies will be able to contributions that impact Pakistan and the world. ","ab9e4715":"# <span style=\"color:darkgreen;font-family:georgia;\">5. Word Cloud<\/span>","52482b97":"It looks like the most popular cities for startups are:\n>1. Karachi\n>2. Lahore\n>3. Islamabad","5eebb4cd":"### 4.2  Startup City Distribution","662b3074":"<h1><center>\ud83c\uddf5\ud83c\uddf0 Pakistani Startups \ud83c\uddf5\ud83c\uddf0<\/center><\/h1>","b13cb082":"#### Here are some areas where we can make the data easier to work with:\n>* The last 150 rows or so are empty\n>* The data types need to be changed\n>* The location and timeline data needs to be cleaned\n","6a68e869":"Import image for bar chart background","eaacd0b8":"![startup_rocket.jpeg](attachment:f54634d6-719c-48b7-886e-08bd25881cf5.jpeg)","922d0812":"### 2.1 DateTime Data","4344c4b8":"**Next,convert data types to strings** \ud83e\uddf5","61c31c33":"I've recently gotten more interested in startup ecosystems around the world. Obviously, the U.S. has some big names, but as technology provides opportunity to more and more people I've been excited to see what kind of advancements will come from other continents. \n\nSo, when I found this dataset I jumped on it. I hope this notebook can help give some insight into the startup infrastructure inside Pakistan. ","05a1f3d8":"### Put Pakistani Flag in Background of all Barcharts","e4189196":"<blockquote>Then we're gonna add in some noise to the Latitude and Longitude columns because we don't want all of the locations to be right on top of each other.\n\n\n<div class=\"alert alert-block alert-info\"><b>Note:<\/b> This means the location data is not meant to be accurate at the street level. Just the city level.<\/div><\/blockquote>","d8890952":"### 2.2 Location Data","21b49298":"### Libraries \ud83d\udcda","c5853846":"### 5.2 Tagline","b92455c3":"**<span style=\"font-size:16px;\">Coordinates: \ud83c\udf10<\/span>**\n\nAdd `latitude` and `longitude` to the dataset for each city\n***","3bad6ce8":"<blockquote>We are going to be dealing mainly with startups that are located in Pakistan. So we can drop most of the locations outside of the country.<\/blockquote>","c0c01dac":"\ud83d\udea9 **Import image for WordCloud mask** \u2708\ufe0f","972cb385":"### 5.1 Industry ","4b08ed36":"Make `Founded` column readable \ud83d\udc53","592028c6":"# <span style=\"color:darkgreen;font-family:georgia;\">1. Introduction<\/span> ","57dc3d3d":"### 4.3 City Distribution By Year","bc13c552":"<b><span style=\"font-size:16px;\">To Do:<\/span><\/b>\n\n>We want to determine the number of companies founded in each year. We will only be including companies founded after 1999.  ","4aba359f":"## Clean the Data \ud83e\uddfd","3c481f46":"### 5.3 Description","daf5b9a9":"**First, drop all rows where there is no data** \u2b07","e60f1424":"# <span style=\"color:darkgreen;font-family:georgia;\">3. Timeline<\/span>","045b8a63":"# <span style=\"color:darkgreen;font-family:georgia;\">4. Location<\/span>","47d03333":"# <span style=\"color:darkgreen;font-family:georgia;\">2. Data<\/span>"}}