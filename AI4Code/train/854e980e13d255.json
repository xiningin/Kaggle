{"cell_type":{"4b078ed1":"code","a2a47744":"code","3972c9c8":"code","238c0b6e":"code","7f5add09":"code","0f7f1c06":"code","13e6040a":"code","84fad5e0":"code","f3b182e3":"code","7254978a":"code","5967e53a":"code","1351b62e":"code","bfc86fc1":"code","3dcf9519":"code","a471720d":"code","22901ae0":"code","7fcc5b91":"code","b9d54be2":"code","393f5ff4":"code","20897331":"code","79228ad8":"code","e06dd9c6":"code","c0fe09a3":"code","4c6371b7":"code","8df290ba":"code","f3c18b85":"code","5bab11ce":"code","411b2e91":"code","ecf1d352":"code","50829305":"code","56bcad14":"code","4311c085":"code","fa806dc2":"code","094d978c":"code","be716805":"code","3d672baf":"code","6a27ac0d":"code","1fbf25c4":"code","e89d9e94":"code","ef8e6c99":"code","1291ac4f":"code","0cd9dbca":"code","ea213565":"code","16616df1":"code","555ccf8a":"code","3c5bc791":"code","9e100156":"code","ad9e2110":"code","46be1f65":"code","a9374039":"code","39083ade":"code","9a49a593":"code","6a949296":"code","956f0ef5":"code","76647024":"code","d894a615":"code","67b8d5fa":"code","236ce07a":"code","4b3109f2":"code","3b6e61ff":"code","4dd6ca4c":"code","f626eeb9":"code","805c3ca9":"code","1ecfd869":"code","ad22bc90":"code","9d1d2bd7":"code","d1e89441":"code","dd3692c4":"code","5307818f":"code","ff14a7c6":"code","06470f35":"code","0b806d47":"markdown","fe9cf3ca":"markdown","8cbabde0":"markdown","a81d5474":"markdown","2c5a28d9":"markdown","30406529":"markdown","53eac49b":"markdown","75f9aefa":"markdown","a2a36d75":"markdown","91563ee3":"markdown","2ec07aec":"markdown","4c333752":"markdown","1167d4c7":"markdown"},"source":{"4b078ed1":"import tensorflow as tf\nimport keras\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import jaccard_score\n\nfrom scipy import stats\n\nimport seaborn as sns\n\nimport skimage\nfrom skimage.transform import rotate\n\nfrom tqdm import tqdm\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPool2D, UpSampling2D, GlobalMaxPool2D, GlobalAveragePooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import NASNetMobile, Xception, DenseNet121, MobileNetV2, InceptionV3, InceptionResNetV2, vgg16, resnet50, inception_v3, xception, DenseNet201\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import CSVLogger\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom datetime import datetime\n\nimport numpy as np\nimport os\nimport cv2\nimport pandas as pd\n# import imutils\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport pickle","a2a47744":"DATA_PATH = \"..\/input\/thai-mnist-classification\/\"\n\nTRAIN_PATH = DATA_PATH + \"train\/\"\nTEST_PATH = DATA_PATH + \"test\/\"\n\ndf1 = pd.read_csv(DATA_PATH + \"mnist.train.map.csv\")\ndf1.index = df1['id']\n\nx_resolution = 32\ny_resolution = 32\nbatch_size = 32\nbatch_size_generator = 32\nepoch = 20\nearlystopping = 60\nnan_index = 10","3972c9c8":"N = df1.shape[0]\nN","238c0b6e":"from skimage.morphology import convex_hull_image\nfrom skimage.util import invert","7f5add09":"def convex_crop(img,pad=20):\n    convex = convex_hull_image(img)\n    r,c = np.where(convex)\n    while (min(r)-pad < 0) or (max(r)+pad > img.shape[0]) or (min(c)-pad < 0) or (max(c)+pad > img.shape[1]):\n        pad = pad - 1\n    return img[min(r)-pad:max(r)+pad,min(c)-pad:max(c)+pad]","0f7f1c06":"temp_img = cv2.imread(\"..\/input\/thai-mnist-classification\/train\/59937745-b5e4-4f69-aee6-3e43a1381846.png\")\ntemp_img = cv2.cvtColor(temp_img,cv2.COLOR_BGR2GRAY)","13e6040a":"plt.gray()\nplt.imshow(temp_img)\ncrop_img = convex_crop(invert(temp_img),pad=20)\nplt.imshow(crop_img)\nprint(crop_img.shape)","84fad5e0":"def thes_resize(img,thes=40):\n    img = invert(img)\n    img = convex_crop(img,pad=20)\n    img = ((img > thes)*255).astype(np.uint8)\n    if(min(img.shape) > 300):\n        img = cv2.resize(img,(300,300))\n        img = ((img > thes)*255).astype(np.uint8)\n    if(min(img.shape) > 150):\n        img = cv2.resize(img,(150,150))\n        img = ((img > thes)*255).astype(np.uint8)\n    img = cv2.resize(img,(80,80))\n    img = ((img > thes)*255).astype(np.uint8)\n    img = cv2.resize(img,(50,50))\n    img = ((img > thes)*255).astype(np.uint8)\n    img = cv2.resize(img,(32,32))\n    img = ((img > thes)*255).astype(np.uint8)\n    \n    return img","f3b182e3":"plt.imshow(thes_resize(temp_img))","7254978a":"def read_image(path):\n    im = cv2.imread(path)\n    im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n    im = thes_resize(im)\n    return im","5967e53a":"x_s = 6\nfig = plt.figure(figsize=(24,16))\nfor i, path in enumerate(df1['id']):\n    if i == x_s**2:\n        break\n    output = read_image('..\/input\/thai-mnist-classification\/train\/' + path)\n    ax = fig.add_subplot(x_s,x_s,1+i)\n    ax.imshow(output)","1351b62e":"def load_image_1():\n    img_path = os.listdir(TRAIN_PATH)\n    label = []\n    train_img = np.empty((N, x_resolution, y_resolution), dtype=np.uint8)\n\n    for i, image in enumerate(tqdm(df1['id'])):\n        train_img[i] = read_image(TRAIN_PATH +image)\n        label.append(to_categorical(df1.category[image], num_classes=10))\n    \n    return np.array(train_img), np.array(label)\n\nX, Y = load_image_1()","bfc86fc1":"import pickle\npickle.dump((X, Y), open('data_training_32x32.data', 'wb'))","3dcf9519":"X, Y = pickle.load(open('..\/input\/model-image1\/data_training_32x32.data', 'rb'))","a471720d":"for i in X[0].flatten()[:100]:\n    if i != 0:\n        print(i)","22901ae0":"X.shape","7fcc5b91":"X = X \/ 255.\nX = X.reshape(-1,x_resolution,y_resolution,1)\nX.shape","b9d54be2":"for i in X[0].flatten()[:100]:\n    if i != 0:\n        print(i)","393f5ff4":"with tf.device('\/device:GPU:0'):\n    def get_model():\n        inputs = Input(shape=(x_resolution, y_resolution, 1))\n        \n        x = Conv2D(64, kernel_size=(5,5), activation='relu')(inputs)\n        x = MaxPool2D(pool_size=2)(x)\n        x = BatchNormalization()(x)\n        \n        x = Conv2D(128, kernel_size=(5,5), activation='relu')(x)\n        x = MaxPool2D(pool_size=2)(x)\n        x = BatchNormalization()(x)\n        \n        x = Flatten()(x)\n        x = Dense(128)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(64)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(10)(x)\n        outputs = Activation('softmax')(x)\n\n        model = Model(inputs=inputs, outputs=outputs)\n        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n        model.summary()\n\n        return model\n    \n    model_image = get_model()","20897331":"kfold = KFold(n_splits=10, random_state=42)\n\nnp.unique(Y, return_counts=True)","79228ad8":"df1['category'][:5]","e06dd9c6":"folder = 'crop_kfold_10_1'\nbest_model_filename = '.\/model_image_'+folder+'.h5'\nbest_model_filename_nokfold = '.\/model_image_splt_crop_1.h5'","c0fe09a3":"# x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n\n# EarlyStopper = EarlyStopping(patience=earlystopping, verbose=1, monitor='val_accuracy', mode='max')\n# Csv_logger = CSVLogger('.\/save.csv', append=True, separator=';')\n# Checkpoint = ModelCheckpoint(best_model_filename_nokfold, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max')\n\n# model_image.fit(x_train, y_train, \n#          validation_data=(x_valid, y_valid),\n#          batch_size=batch_size,\n#          epochs=300,\n#          verbose=1,\n#          callbacks=[EarlyStopper, Checkpoint, Csv_logger]\n#         )","4c6371b7":"val_acc = []\nfor count, (train_index, valid_index) in enumerate(kfold.split(X)):\n#     x_train = X[train_index]\n#     y_train = Y[train_index]\n#     x_valid = X[valid_index]\n#     y_valid = Y[valid_index]\n    \n    model_image.fit(X[train_index], Y[train_index], \n         validation_data=(X[valid_index], Y[valid_index]),\n         batch_size=batch_size,\n         epochs=epoch,\n         verbose=1\n        )\n    print(count+1)\n    score_1 = model_image.evaluate(X[train_index], Y[train_index])\n    score_2 = model_image.evaluate(X[valid_index], Y[valid_index])\n    print('========= Genearator Model =========')\n    print('Train loss :', score_1[0])\n    print('Train accuracy :', score_1[1]*100)\n    print('Valid loss :', score_2[0])\n    print('Valid accuracy :', score_2[1]*100)\n    val_acc.append(score_2[1])\n    print('\\n\\n')\n    \nmodel_image.save(best_model_filename)","8df290ba":"for num, i in enumerate(val_acc):\n    print('Fold :', num+1)\n    print('Accuracy :', i*100, '%')\n    print('=========================================')\n    \nprint('========= Last Genearator Model =========')\nresults = model_image.evaluate(X, Y)\nprint('Loss :', results[0])\nprint('Accuracy :', results[1]*100, '%')","f3c18b85":"# with tf.device('\/device:GPU:0'):\n#     for i, image in enumerate(tqdm(df1['id'])):\n#         y_pred = model_image.predict(np.array([X[i]]), verbose=0)\n#         if np.argmax(y_pred[0]) != np.argmax(Y[i]):\n#             s = np.empty((x_resolution,y_resolution,3))\n#             s[:, : , 0] = X[i].reshape(x_resolution,y_resolution)\n#             s[:, : , 1] = X[i].reshape(x_resolution,y_resolution)\n#             s[:, : , 2] = X[i].reshape(x_resolution,y_resolution)\n#             plt.imshow(s)\n#             print(np.argmax(y_pred[0]) , np.argmax(Y[i]))\n#             plt.show()","5bab11ce":"# df2 = pd.read_csv(DATA_PATH + \"train.rules.csv\")\n# df2.index = df2['id']\n# df2 = df2.fillna(nan_index)\n# df2","411b2e91":"# model_image = load_model('..\/input\/model-image1\/model_image_drop_1.h5')\n# model_image.summary()","ecf1d352":"# model_image.predict(np.array([X[0]]))[0]","50829305":"# def load_data():\n#     img_path = os.listdir(TRAIN_PATH)\n#     train_label = []\n#     train_index = []\n#     train_condition = []\n    \n#     for i, image in enumerate(tqdm(df2['id'])):\n#         train_label.append(df2.predict[image])\n#         train_index.append([])\n        \n#         if df2.feature1[image] != nan_index:\n#             image1 = read_image(TRAIN_PATH + df2.feature1[image])\n#             train_condition.append(to_categorical(np.argmax(model_image.predict(image1.reshape(1,x_resolution,y_resolution,1))[0]), num_classes=11))\n#         else:\n#             train_condition.append(to_categorical(nan_index, num_classes=11))\n            \n#         if df2.feature2[image] != nan_index:    \n#             image2 = read_image(TRAIN_PATH + df2.feature2[image])\n#             train_index[-1].append(np.argmax(model_image.predict(image2.reshape(1,x_resolution,y_resolution,1))[0]))\n#         else:\n#             train_index[-1].append(nan_index)\n            \n#         if df2.feature3[image] != nan_index:\n#             image3 = read_image(TRAIN_PATH + df2.feature3[image])\n#             train_index[-1].append(np.argmax(model_image.predict(image3.reshape(1,x_resolution,y_resolution,1))[0]))\n#         else:\n#             train_index[-1].append(nan_index)\n    \n#     return np.array(train_condition), np.array(train_index), np.array(train_label)\n\n# C_mae, X_mae, Y_mae = load_data()\n# X_mae[:10]","56bcad14":"# import pickle\n# pickle.dump((C_mae, X_mae, Y_mae), open('mae_data_training.data', 'wb'))","4311c085":"# Y_mae[:10]","fa806dc2":"# C_mae[:10]","094d978c":"# with tf.device('\/device:GPU:0'):\n#     def get_mae_model():\n#         condition = Input(shape=(11,))\n#         inputs = Input(shape=(2,))\n        \n#         y = Dense(64)(condition)\n#         y = BatchNormalization()(y)\n#         y = Dropout(0.2)(y)\n#         y = Dense(1)(y)\n#         y = BatchNormalization()(y)\n#         y = Dropout(0.2)(y)\n        \n#         x = concatenate([inputs, y])\n\n#         x = Dense(256)(x)\n#         x = Activation('relu')(x)\n#         x = BatchNormalization()(x)\n#         x = Dropout(0.2)(x)\n    \n#         x = Dense(128)(x)\n#         x = Activation('relu')(x)\n#         x = BatchNormalization()(x)\n#         x = Dropout(0.2)(x)\n        \n#         x = Dense(64)(x)\n#         x = Activation('relu')(x)\n#         x = BatchNormalization()(x)\n#         x = Dropout(0.2)(x)\n        \n#         x = Dense(16)(x)\n#         x = Activation('relu')(x)\n#         x = BatchNormalization()(x)\n#         x = Dropout(0.2)(x)\n        \n#         x = Dense(1)(x)\n#         outputs = Activation('relu')(x)\n\n#         model = Model(inputs=[condition, inputs], outputs=outputs)\n#         model.compile(loss='mean_absolute_error', optimizer='adam')\n#         model.summary()\n\n#         return model\n    \n#     model_mae = get_mae_model()","be716805":"# kfold = KFold(n_splits=10, random_state=42)\n\n# np.unique(Y_mae, return_counts=True)\n# Y_mae.shape","3d672baf":"# folder = 'drop_1'\n# best_model_filename = '.\/model_mae_'+folder+'.h5'\n\n# EarlyStopper = EarlyStopping(patience=earlystopping, verbose=1, monitor='val_loss', mode='min')\n# Csv_logger = CSVLogger('.\/save_mae.csv', append=True, separator=';')\n# Checkpoint = ModelCheckpoint(best_model_filename, verbose=1, monitor='val_loss', save_best_only=True, mode='min')","6a27ac0d":"# val_acc = []\n# for count, (train_index, valid_index) in enumerate(kfold.split(X_mae)):\n# #     x_train = X[train_index]\n# #     y_train = Y[train_index]\n# #     x_valid = X[valid_index]\n# #     y_valid = Y[valid_index]\n    \n#     model_mae.fit([C_mae[train_index], X_mae[train_index]], Y_mae[train_index], \n#          validation_data=([C_mae[valid_index], X_mae[valid_index]], Y_mae[valid_index]),\n#          batch_size=128,\n#          epochs=epoch,\n#          verbose=1\n#         )\n#     score = model_mae.evaluate([C_mae[valid_index], X_mae[valid_index]], Y_mae[valid_index])\n#     print(count+1)\n#     print('========= Genearator Model =========')\n#     print('Valid loss :', score)\n#     val_acc.append(score)\n#     print('\\n\\n')\n    \n# model_mae.save(best_model_filename)","1fbf25c4":"# for num, i in enumerate(val_acc):\n#     print('Fold :', num+1)\n#     print('Loss :', i, '%')\n#     print('=========================================')\n    \n# print('========= Last Genearator Model =========')\n# results = model_mae.evaluate([C_mae, X_mae], Y_mae)\n# print('Loss :', results)","e89d9e94":"def fucking_predict(c, x):\n    re = 0\n    if c == 10:\n        re = x[0]+x[1]\n    elif c == 0:\n        re = x[0]*x[1]\n    elif c == 1:\n        re = abs(x[0]-x[1])\n    elif c == 2:\n        re = (x[0]+x[1])*abs(x[0]-x[1])\n    elif c == 3:\n        re = abs(((x[1]*(x[1]+1)) - x[0]*(x[0]-1))\/2)\n    elif c == 4:\n        re = 50+(x[0]-x[1])\n    elif c == 5:\n        re = min(x[0], x[1])\n    elif c == 6:\n        re = max(x[0], x[1])\n    elif c == 7:\n        re = ((x[0]*x[1])%9)*11\n    elif c == 8:\n        re = ((x[0]**2)+1)*x[0] + x[1]*(x[1]+1)\n        re = re % 99\n    elif c == 9:\n        re = 50+x[0]\n    else:\n        print(\"fuck\")\n        \n    return int(re)","ef8e6c99":"model_image = load_model(best_model_filename_nokfold)\nbest_model_filename_nokfold","1291ac4f":"df3 = pd.read_csv(DATA_PATH + \"test.rules.csv\")\ndf3.index = df3['id']\ndf3 = df3.fillna(nan_index)\n\ndf_test = pd.read_csv(DATA_PATH + \"submit.csv\")","0cd9dbca":"image_name =[]\ntest_image = []\nfor i, image in enumerate(tqdm(os.listdir(TEST_PATH))):\n    image_name.append(image)\n    t = read_image(TEST_PATH + image)\n    t = t.astype(np.uint8)\n    t = t \/ 255.0\n    t = t.reshape(32,32,1)\n    test_image.append(t)\n    \ntest_image = np.array(test_image)\ntest_image.shape","ea213565":"image_name, test_image = pickle.load(open('..\/input\/model-image1\/test_data_32x32.data', 'rb'))","16616df1":"label = np.argmax(model_image.predict(test_image), axis=1)\nimage2number = {'image': image_name, 'category': label}\nimage2number = pd.DataFrame(image2number)\nimage2number.index = image2number['image']\nimage2number","555ccf8a":"import pickle\npickle.dump((image_name, test_image), open('test_data_32x32.data', 'wb'))","3c5bc791":"for i, (image, l) in enumerate(zip(test_image, label)):\n    plt.title(l, fontsize=64)\n    plt.imshow(image.reshape(32,32))\n    plt.show()","9e100156":"image2number.category['cb57fbac-b366-4359-9d89-40f048efedaf.png']","ad9e2110":"def test1():\n    N_test = 20000\n    img_path = os.listdir(TEST_PATH)\n    test_index = np.empty((N_test, 2), dtype=np.uint8)\n    test_condition = []\n    nan_label = []\n    \n    data = []\n    \n    for i, image in enumerate(tqdm(df3['id'])):\n        if df3.feature1[image] != nan_index:\n            image1 = df3.feature1[image]\n            test_condition.append(image2number.category[image1])\n        else:\n            test_condition.append(nan_index)\n            \n        if df3.feature2[image] != nan_index:    \n            image2 = df3.feature2[image]\n            test_index[i][0] = image2number.category[image2]\n        else:\n            test_index[i][0] = nan_index\n            \n        if df3.feature3[image] != nan_index:\n            image3 = df3.feature3[image]\n            test_index[i][1] = image2number.category[image3]\n        else:\n            test_index[i][1] = nan_index\n            \n        c = np.argmax(test_condition[-1])\n        x1 = test_index[-1][0]\n        x2 = test_index[-1][1]\n        data.append([c,x1,x2])\n        \n    return test_condition, np.array(test_index), data\n\nc_label, x_mix, data = test1()\n\nx1 = x_mix[:,0]\nx2 = x_mix[:,1]\n\ntest_index = np.empty((20000, 2))\nfor num, (i,j) in enumerate(zip(x1, x2)):\n    test_index[num, 0] = i\n    test_index[num, 1] = j\ntest_index","46be1f65":"# import pickle\n# pickle.dump((con, test_index), open('mae_data_fucking_testing.data', 'wb'))","a9374039":"# def test():\n#     img_path = os.listdir(TEST_PATH)\n#     test_index = []\n#     test_condition = []\n    \n#     data = []\n    \n#     for i, image in enumerate(tqdm(df3['id'])):\n#         if i == 20:\n#             break\n#         test_index.append([])\n#         if df3.feature1[image] != nan_index:\n#             image1 = cv2.imread(TEST_PATH + df3.feature1[image], 0)\/255.\n#             image1 = cv2.resize(image1, (x_resolution, y_resolution))\n#             image1 = image1.astype(np.uint8)\n#             test_condition.append(to_categorical(np.argmax(model_image.predict(image1.reshape(1,x_resolution,y_resolution,1))[0])), num_classes=11)\n#         else:\n#             test_condition.append(to_categorical(nan_index, num_classes=11))\n            \n#         if df3.feature2[image] != nan_index:    \n#             image2 = cv2.imread(TEST_PATH + df3.feature2[image], 0)\/255.\n#             image2 = cv2.resize(image2, (x_resolution, y_resolution))\n#             image2 = image2.astype(np.uint8)\n#             test_index[-1].append(np.argmax(model_image.predict(image2.reshape(1,x_resolution,y_resolution,1))[0]))\n#         else:\n#             test_index[-1].append(nan_index)\n            \n#         if df3.feature3[image] != nan_index:\n#             image3 = cv2.imread(TEST_PATH + df3.feature3[image], 0)\/255.\n#             image3 = cv2.resize(image3, (x_resolution, y_resolution))\n#             image3 = image3.astype(np.uint8)\n#             test_index[-1].append(np.argmax(model_image.predict(image3.reshape(1,x_resolution,y_resolution,1))[0]))\n#         else:\n#             test_index[-1].append(nan_index)\n            \n#         c = np.argmax(test_condition[-1])\n#         x1 = test_index[-1][0]\n#         x2 = test_index[-1][1]\n#         data.append([c,x1,x2])\n#     return np.array([test_condition, test_index]), data","39083ade":"# x_test, data_test = test()\n# x_test[1]","9a49a593":"# import pickle\n# pickle.dump(x_test, open('mae_data_testing.data', 'wb'))","6a949296":"fucking_sub = []\nfor c,x in zip(c_label,test_index):\n    fucking_sub.append(fucking_predict(c,x))\n\nfucking_sub[:20]","956f0ef5":"# y_sub = model_mae.predict(x_test)\n# y_sub","76647024":"# y_sub = np.argmax(axis=1)\n# y_sub","d894a615":"# for (c,x1,x2),y in zip(data, y_sub):\n#     print(c, x1, x2, ':',y)","67b8d5fa":"# submission = pd.Dataframe({'id': df3['id'], 'predict': y_sub})\nsubmission = pd.DataFrame({'id': df3['id'], 'predict': fucking_sub})\nsubmission","236ce07a":"submission.to_csv('submission_161020_'+folder+'.csv',index=False)","4b3109f2":"img_path = os.listdir(TEST_PATH)\nim = []\nfull_im = []\nfor i, image in enumerate(tqdm(img_path)):\n    image1 = read_image(TEST_PATH + '\/' + image)\n    full_im.append(cv2.resize(image1.copy()*255.0, (128,128)))\n    im.append(image1)","3b6e61ff":"im = np.array(im)","4dd6ca4c":"pickle.dump(im, open('Test_image_accuracy_32x32.data', 'wb'))","f626eeb9":"import pickle","805c3ca9":"im = pickle.load(open('Test_image_accuracy_32x32.data', 'rb'))\nim = np.array(im)","1ecfd869":"im = im\/255.","ad22bc90":"np.where(im==1)","9d1d2bd7":"im = im.reshape(-1,x_resolution,y_resolution,1)\nim.shape","d1e89441":"full_im[1]","dd3692c4":"model_image = load_model(best_model_filename)\nbest_model_filename","5307818f":"im = np.array(im)\nim.shape\npred = np.argmax(model_image.predict(im), axis=1)\npred[:20]","ff14a7c6":"for i, img in enumerate(pred):\n    plt.title(img, fontsize=64)\n    plt.imshow(full_im[i])\n    plt.show()","06470f35":"x_s = 18\nfig = plt.figure(figsize=(24,16))\nfor a in range(10):\n    count = 0\n    for i, img in enumerate(tqdm(pred)):\n        if img == a:\n            if count == x_s**2:\n                fig = plt.figure(figsize=(24,16))\n                count = 0\n            ax = fig.add_subplot(x_s,x_s,1+count)\n            ax.imshow(full_im[i])\n            count += 1","0b806d47":"# Model","fe9cf3ca":"# Submission","8cbabde0":"# Testing","a81d5474":"# Fucking Prediction Model","2c5a28d9":"array([3, 5, 1, 2, 2, 2, 5, 9, 8, 7, 1, 4, 3, 7, 8, 1, 1, 1, 5, 3])","30406529":"# KFold Image Training Process","53eac49b":"# Load Data","75f9aefa":"9, 9, 15, 8, 16, 9, 3, 8, 2, 8, 8, 15, 7, 9, 8, 3, 2, 2, 13, 13]","a2a36d75":"# Model MAE","91563ee3":"# Parameter","2ec07aec":"# Load Images","4c333752":"# KFold MAE Training Process","1167d4c7":"# Crop Images"}}