{"cell_type":{"5acc3b83":"code","978bb265":"code","2edee793":"code","b819f365":"code","745e6e74":"code","ef016a57":"code","eae655c1":"code","4c92b662":"code","baa0e2cb":"code","d7d6f2e1":"code","d2736c3b":"code","0495258e":"code","299239de":"code","7499e607":"code","596c0bd1":"markdown"},"source":{"5acc3b83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport json\nprint(os.listdir(\"..\/input\"))\nROOT_DIR = '..\/input'\nprint('root data dir:', os.listdir(ROOT_DIR))\nFLOWER_DATA_DIR = os.path.join(ROOT_DIR, 'oxford-102-flower-pytorch',\n                                  'flower_data', 'flower_data')\nprint('flower data dir:', os.listdir(FLOWER_DATA_DIR))\n# print(os.listdir(\"..\/input\/oxford-102-flower-pytorch\/flower_data\/flower_data\/cat_to_name.json\"))\n\n# Any results you write to the current directory are saved as output.","978bb265":"# Load label mapping\nLABEL_MAPPING_PATH = os.path.join(ROOT_DIR, 'oxford-102-flower-pytorch',\n                                  'flower_data', 'flower_data',\n                                  'cat_to_name.json')\nwith open(LABEL_MAPPING_PATH, 'r') as f:\n    cat_to_name = json.load(f)\n\ncat_to_name","2edee793":"# Kernel imports\nimport time\nimport json\n%config InlineBackend.figure_format = 'retina'\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.datasets import ImageFolder\nfrom collections import OrderedDict\nfrom PIL import Image\n\n# Check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif train_on_gpu:\n    print('CUDA is available!  Running on GPU ...')\nelse:\n    print('CUDA is not available.  Running on CPU ...')","b819f365":"# Configure Densnet model\ndensenet = {\n    'arch': 'densenet161_v2_unfreeze',\n    'model': models.densenet161(pretrained=True),\n    'reshape': {\n        'classifier': nn.Sequential(OrderedDict([\n            ('fc1', nn.Linear(2208, 102))\n        ]))\n    }\n}","745e6e74":"# Load model checkpoint\nOUTPUT_DIR = os.path.join(ROOT_DIR, 'image-classifier-project-pytorch-challenge')\n# Configure checkpoint model\nif train_on_gpu:\n    checkpoint = torch.load(f'{OUTPUT_DIR}\/densenet161_v2_unfreeze_model_12.pt')\nelse:\n    checkpoint = torch.load(f'{OUTPUT_DIR}\/densenet161_v2_unfreeze_model_12.pt',\n                            map_location='cpu')\nprint(checkpoint.keys())\n\n# Fully configure achitecture\nmodel = densenet['model']\nmodel.classifier = densenet['reshape']['classifier']\nmodel.load_state_dict(checkpoint['state_dict'])\nmodel.class_to_idx = checkpoint['class_to_idx']\nmodel.idx_to_class = {v: k for k, v in model.class_to_idx.items()}\nmodel.classifier","ef016a57":"# Data directory paths\nTRAIN_DIR = os.path.join(FLOWER_DATA_DIR, 'train')\nVALID_DIR = os.path.join(FLOWER_DATA_DIR, 'valid')\n\n# Load train and test data\ndef load_data(input_size=224):\n    '''Load data and crop to specified input_size.'''\n    # Define your transforms for the training and validation sets\n    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n\n    train_transforms = transforms.Compose([\n        transforms.RandomRotation(45),\n        transforms.RandomResizedCrop(input_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize\n    ])\n    valid_transforms = transforms.Compose([\n        transforms.Resize(400),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        normalize\n    ])\n\n    # Load the datasets with ImageFolder\n    train_data = ImageFolder(TRAIN_DIR, transform=train_transforms)\n    valid_data = ImageFolder(VALID_DIR, transform=valid_transforms)\n    \n    return train_data, valid_data","eae655c1":"# Prepare loading test images\nTEST_DIR = os.path.join(FLOWER_DATA_DIR, 'test')\ntest_image_files = os.listdir(TEST_DIR)\ntest_image_files[:10]\n","4c92b662":"# Load data\n_, valid_data = load_data()\n\n# Obtain a batch of images\nbatch_size = 12\nvalid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n\n# initialize lists to monitor test loss and accuracy\ntest_loss = 0.0\nclass_correct = list(0. for i in range(102))\nclass_total = list(0. for i in range(102))\n\ncriterion = nn.CrossEntropyLoss()\n\n# Use GPU if available, attach device to model accordingly\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nif train_on_gpu:\n    device = 'cuda'\nelse:\n    device = 'cpu'\nprint(f'Training model on {device}')\nmodel.to(device)\n\nmodel.eval() # prep model for evaluation\nfor data, target in valid_loader:\n    data, target = data.to(device), target.to(device)\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)\n    # compare predictions to true label\n    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n    # calculate test accuracy for each object class\n    for i in range(len(target)):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# calculate and print avg test loss\ntest_loss = test_loss\/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(102):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            str(i), 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","baa0e2cb":"def process_image(image):\n    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n        returns an Numpy array\n    '''\n    \n    # TODO: Process a PIL image for use in a PyTorch model\n    img = Image.open(image)\n    \n    # Resize\n    if img.size[0] > img.size[1]:\n        img.thumbnail((10000, 256))\n    else:\n        img.thumbnail((256, 10000))\n    \n    # Crop \n    left_margin = (img.width-224)\/2\n    bottom_margin = (img.height-224)\/2\n    right_margin = left_margin + 224\n    top_margin = bottom_margin + 224\n    img = img.crop((left_margin, bottom_margin, right_margin,   \n                      top_margin))\n    \n    # Normalize\n    img = np.array(img)\/255\n    mean = np.array([0.485, 0.456, 0.406]) #provided mean\n    std = np.array([0.229, 0.224, 0.225]) #provided std\n    img = (img - mean)\/std\n    \n    # Move color channels to first dimension as expected by PyTorch\n    img = img.transpose((2, 0, 1))\n    \n    return img","d7d6f2e1":"def predict(image_path, model, top_num=5):\n    # To cpu\n    model.to('cpu')\n    # Process image\n    img = process_image(image_path)\n    \n    # Numpy -> Tensor\n    image_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n    # Add batch of size 1 to image\n    model_input = image_tensor.unsqueeze(0)\n    \n    # Probs\n    probs = torch.softmax(model.forward(model_input), dim=1)\n    \n    # Top probs\n    top_probs, top_labs = probs.topk(top_num)\n    top_probs = top_probs.detach().numpy().tolist()[0] \n    top_labs = top_labs.detach().numpy().tolist()[0]\n    \n    # Convert indices to classes\n    idx_to_class = {val: key for key, val in    \n                                      model.class_to_idx.items()}\n    top_labels = [idx_to_class[lab] for lab in top_labs]\n    top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_labs]\n    return top_probs, top_labels, top_flowers","d2736c3b":"# Predict each image in test folder\npreds = list()\nnames = list()\nprobs = list()\nfor image_file in test_image_files:\n    image_path = os.path.join(TEST_DIR, image_file)\n    top_probs, top_labels, top_flowers = predict(image_path, model, top_num=1)\n    prob = top_probs[0]\n    label = top_labels[0]\n    name = top_flowers[0]\n    print(f'prediction for {image_file}: label = {label}, prob = {prob}, name = {name}')\n    probs.append(prob)\n    names.append(name)\n    preds.append(label)","0495258e":"# Store results in a dataframe\nresults = {\n    'file_name': test_image_files,\n    'label': preds,\n    'probability': probs,\n    'name': names\n}\nprediction_results = pd.DataFrame(results)\nprediction_results.head()","299239de":"# Transform into submission format\nsubmission_df = prediction_results.drop(['probability', 'name'], axis=1)\nsubmission_df = submission_df.rename(columns={'label' : 'id'})\nsubmission_df.head()","7499e607":"# Write results and submission to csv\nprediction_results.to_csv('test_data_predictions.csv', sep=',', index=False)\nsubmission_df.to_csv('densenet161_submission.csv', sep=',', index=False)","596c0bd1":"## Sanity Checking\nCheck against train data to verify that saved model was loaded correctly and runs as expected when predict images."}}