{"cell_type":{"760df8ab":"code","79e04d6b":"code","3cee4b1e":"code","52537ae7":"code","ffbced1a":"code","8b5a0b11":"code","3589a7bf":"markdown"},"source":{"760df8ab":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import average_precision_score\nimport lightgbm as lgb","79e04d6b":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","3cee4b1e":"X = pd.concat([\n    train.drop(columns=['ID_code', 'target']),\n    test.drop(columns=['ID_code'])\n], axis=0).values\ny = np.append(\n    np.zeros(len(train)),\n    np.ones(len(test))\n)","52537ae7":"%%time\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\nlgb_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n}\noof = np.zeros(len(y))\n\nfor trn_idx, val_idx in folds.split(X, y):\n    X_trn = X[trn_idx]\n    X_val = X[val_idx]\n    y_trn = y[trn_idx]\n\n    train_set = lgb.Dataset(X_trn, label=y_trn)\n    clf = lgb.train(lgb_params, train_set)\n    oof[val_idx] = clf.predict(X_val)\n    \nprint('MAP:', average_precision_score(y, oof))\nprint('AUC:', roc_auc_score(y, oof))","ffbced1a":"sns.distplot(oof[y==0], bins=100)\nsns.distplot(oof[y==1], bins=100)\nplt.show()","8b5a0b11":"oof_df = pd.DataFrame(data={0:oof[y==0], 1:oof[y==1]})\noof_df.describe(percentiles=np.linspace(0.1, 0.9, 9))","3589a7bf":"my conclusion: There is no need to use adversarial validation."}}