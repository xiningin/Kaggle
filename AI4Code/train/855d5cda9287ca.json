{"cell_type":{"5579712a":"code","62467868":"code","7874c931":"code","dd4d3f9b":"code","d1b87e22":"code","6dfcda2d":"code","bfd0a66a":"code","a1a0db6e":"code","e4343116":"code","53c56418":"code","7f4898a5":"code","1e1ccf0b":"code","7871a9a6":"code","debd5bc9":"code","a8fea2dc":"code","bb354a71":"code","0c3eaa60":"code","f0a227d5":"code","5b73fcab":"code","826f08f4":"code","25c3fd4a":"code","3073c341":"code","d4220410":"code","777eaaf3":"code","37d6b33b":"code","577f2629":"code","3c58dd3b":"code","79b37c59":"code","095efbea":"code","bb4404f1":"code","76196b57":"code","9c340e8f":"code","9e611653":"code","62af938b":"code","27e68157":"markdown","8c0fedea":"markdown","a7294004":"markdown","7608bdf6":"markdown","a9a46d52":"markdown","c8ca5197":"markdown","afc63dd2":"markdown","71e77776":"markdown","a22684be":"markdown","5681e03e":"markdown","67b2a4a8":"markdown","706c9f87":"markdown","01c6efae":"markdown","01552a9b":"markdown","ab5a6ee6":"markdown","c212f3df":"markdown","e9bd7bd0":"markdown","60e55232":"markdown","17ef0d2d":"markdown","cc7c1af0":"markdown","5bb4253e":"markdown","fd4f101a":"markdown","c2857b72":"markdown","70499319":"markdown","83eb1f02":"markdown","8419cdc8":"markdown","6c5c366f":"markdown","a82d3f2b":"markdown","6e818b88":"markdown","9ec70ece":"markdown","9fc4432b":"markdown","db25fdc2":"markdown","86cbc6fd":"markdown","fcb16df5":"markdown","1bb737ec":"markdown","a263b4bb":"markdown","4ab010af":"markdown","1be6d1d8":"markdown","b92ca28e":"markdown","0a49baaf":"markdown","d27f3c9b":"markdown"},"source":{"5579712a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('fivethirtyeight')","62467868":"train_df = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")","7874c931":"train_df.head()","dd4d3f9b":"train_df.shape","d1b87e22":"train_df.describe()","6dfcda2d":"train_df.drop(\"id\", axis=1, inplace=True)","bfd0a66a":"train_df.columns","a1a0db6e":"train_df.isna().sum().plot(kind=\"bar\")","e4343116":"train_df.dropna(inplace=True)","53c56418":"train_df.isna().sum() ","7f4898a5":"fig, axes = plt.subplots(4,4, figsize=(20,20))\naxes = axes.ravel()\nk = 0\nfor i in train_df.columns  :\n    sns.distplot(train_df[i], ax=axes[k])\n    k += 1 \nfig.suptitle(\"Distribution plot for each feature\")\nfig.tight_layout()","1e1ccf0b":"train_df.columns","7871a9a6":"# sns.pairplot(train_df, hue=\"song_popularity\");\n# Tried doing this to get an overview of relation between features but it is taking too long","debd5bc9":"plt.figure(figsize=(10,10))\n# Getting the Upper Triangle of the co-relation matrix\ncorr = train_df.corr()\nmatrix = np.triu(corr)\nsns.heatmap(corr, mask=matrix, annot=True, annot_kws={\"size\": 8}, cmap=\"coolwarm\", fmt='.1g');","a8fea2dc":"ax = sns.countplot(x=\"song_popularity\", data=train_df)\nfor p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100*p.get_height()\/len(train_df)), (p.get_x()+0.1, p.get_height()+5))","bb354a71":"sns.histplot(x=\"song_duration_ms\", data=train_df, hue=\"song_popularity\");","0c3eaa60":"ax = sns.histplot(x=\"acousticness\", data=train_df, hue=\"song_popularity\");","f0a227d5":"sns.distplot(np.log(train_df[\"acousticness\"]));","5b73fcab":"ax = sns.histplot(x=\"danceability\", data=train_df, hue=\"song_popularity\");","826f08f4":"sns.distplot(np.log(train_df[\"danceability\"]));","25c3fd4a":"ax = sns.histplot(x=\"energy\", data=train_df, hue=\"song_popularity\", bins=100);","3073c341":"sns.distplot(np.log(train_df[\"energy\"]));","d4220410":"ax = sns.histplot(x=\"loudness\", data=train_df, hue=\"song_popularity\", bins=100);","777eaaf3":"from sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler()\nnorm_loudness = min_max_scaler.fit_transform(train_df[\"loudness\"].values.reshape(-1,1))\n\nsns.distplot(np.log(norm_loudness+1));","37d6b33b":"ax = sns.histplot(x=\"instrumentalness\", data=train_df, hue=\"song_popularity\", bins=20)","577f2629":"train_df[\"instrumentalness\"].describe()","3c58dd3b":"sns.distplot(np.log(train_df[\"instrumentalness\"]));","79b37c59":"test_df = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")","095efbea":"test_df.head()","bb4404f1":"submission_df = pd.DataFrame(test_df[\"id\"])","76196b57":"submission_df.head()","9c340e8f":"submission_df[\"song_popularity\"] = [0 for i in submission_df.index]","9e611653":"submission_df","62af938b":"submission_df.to_csv(\"submission_all_0.csv\", index=False)","27e68157":"Around 4k missing values are present which is not much as compared to 40k rows, so let's just drop these null values for doing our EDA","8c0fedea":"Applying long norm transformation since negative values are present","a7294004":"## Visualizing distributions for all features","7608bdf6":"no idea on what to interpret out of this seems very skewed with one dip","a9a46d52":"### acousticness","c8ca5197":"**This distribution seems to be a bit similar to energy distribution but the range of values differ significantly i.e. energy varies from 0 to 1 while loudness ranges from -25 to 0**","afc63dd2":"---","71e77776":"### Energy","a22684be":"**Some useful insights**\n* Higher correlation between loudness and energy since more energetic the sound is more loud it is\n* audio_valence have a moderate correlation with danceability and loudness which could be happening since valence represents positivness of sound and positive songs does make one dance right ?\n![vibing](https:\/\/i.pinimg.com\/originals\/0c\/da\/fc\/0cdafcc8885f89fa4d4b4f28b10205ac.gif)","5681e03e":"---","67b2a4a8":"---","706c9f87":"## Feature Engineering \n\nto be done later","01c6efae":"### song_popularity\nThis is our target column","01552a9b":"We don't need \"id\" column so lets drop it","ab5a6ee6":"**Yuuummm I see some tasty tasty NaNs.... \ud83d\ude0b\ud83c\udf6a**","c212f3df":"**From this overall visualization, we can see that**\n1. Except **song_duration_ms**, most of the columnwise distribution of continuos attributes seems to be a **skewed distribution**\n2. column **instrumentalness** doesn't seem to be having a wide range of values\n3. column **key** is also a **ordinal** in nature as the order of key matters since it has some value \n4. **audio_mode** and **time_signature** are **binary** in nature \n5. target column **song_popularity** is also of a binary type having a bit of **imbalance** ","e9bd7bd0":"## Peeking into our data","60e55232":"---","17ef0d2d":"# Importing necessary libraries ","cc7c1af0":"**lot of songs seems to be having duration near 200sec which is ~3mins and irrespective of duration there are more number of unpopular songs which might have happened cuz of the imbalance in our data**\n\n","5bb4253e":"![image.png](attachment:00b151cf-987a-4edb-91d4-3bd0d34a17f5.png)\nits kinda obvious since around 60% of the data contains 0s so yea ! lol\n","fd4f101a":"Let's handle missing values","c2857b72":"# Data Visualization","70499319":"![image.png](attachment:1b63576e-1e87-40a4-a4ed-f341ec954bfb.png)\n\nIn this competition, you are supposed to predict the popularity of a song given features like acousticness, danceability, key, loudness, etc. but but but before that we will do some Exploratory Data Analysis to understand our data and relation between different attributes in our data","83eb1f02":"---\n## How does the song_popularity differes with each attribute ?\n---","8419cdc8":"---","6c5c366f":"---","a82d3f2b":"**Not much useful so lets apply some transformations**","6e818b88":"**Lot of songs seems to be having acousticness in the range of 0-0.1 but also there are some songs which are popular and a high acousticness in the range 0.8-1**","9ec70ece":"**danceability seems to be a bit right skewed but nothing more than that is seems to be weird or different here (except the fact that more unpopular songs are there as compared to popular songs**\n\n","9fc4432b":"### song_duration_ms","db25fdc2":"# Data preparation","86cbc6fd":"## Base model which predicts only 0s (since our data contains high amount of 0s)","fcb16df5":"**There's a large imabalance**","1bb737ec":"---","a263b4bb":"**So we have 40k rows and 15 columns out of which one is \"id\" column and one is \"song_popularity\" which is our target column**","4ab010af":"### danceability","1be6d1d8":"**Well seems like we have a approx normal distribution for instrumentalness using log transformation**","b92ca28e":"There seems to be a variety of ranges present in our data e.g. \"song_duration_ms\" is lying in between 25k-50k but on the other side \"acousticness\" is lying in range -0.01 to 1.\n\n**So later on, we should consider normalising our data before passing it into a model**","0a49baaf":"### Loudness","d27f3c9b":"## Column Descriptions:\n\nFollowing info is taken from this [discussion post](https:\/\/www.kaggle.com\/c\/song-popularity-prediction\/discussion\/301616) made by [Remek kinas](https:\/\/www.kaggle.com\/remekkinas)\n\n\n* Danceability: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n\n* Valence: Describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n* Energy: Represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n\n* Tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n\n* Loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n\n* Speechiness: This detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\nInstrumentalness: Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d.\n\n* Liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n\n* Acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n\n* Key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n\n* Mode: Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n\n* Duration: The duration of the track in milliseconds.\n\n* Time Signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n\n"}}