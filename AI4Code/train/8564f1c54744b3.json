{"cell_type":{"f01fdd5a":"code","f9be61f8":"code","714a7c73":"code","aea0a53e":"code","272ec199":"code","2e19f5f6":"code","4ae1f5e0":"code","33ab917d":"code","7dc4d054":"code","77962b5b":"code","7ffe8db5":"code","71517f40":"code","829dd7cd":"code","5fc327f9":"code","963080fe":"code","a873a319":"code","4aa0e087":"code","86e9a27b":"code","6d83b7d5":"code","36052335":"code","b40a6e7f":"code","f6af3450":"code","df963527":"code","95dc6efe":"code","02b999db":"code","1fcf9c09":"code","0585e793":"markdown","8cdb2ef8":"markdown","6b51201e":"markdown","fd226bf8":"markdown","5b42be7f":"markdown","cfffd961":"markdown","03f3205d":"markdown","234876f6":"markdown","9224b9e9":"markdown","3e4fee3d":"markdown"},"source":{"f01fdd5a":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport warnings\nwarnings.filterwarnings ('ignore')","f9be61f8":"#load data\ndataframe = pd.read_csv ('..\/input\/german-credit-data-with-risk\/german_credit_data.csv')","714a7c73":"dataframe.head()","aea0a53e":"dataframe.info()","272ec199":"print ('Unique value of Saving accounts\\n', dataframe['Saving accounts'].unique())\nprint ('Unique value of Checking account\\n', dataframe['Checking account'].unique())\nprint ('Unique value of Purpose\\n', dataframe['Purpose'].unique())","2e19f5f6":"dataframe[['Age', 'Credit amount', 'Duration']].describe()","4ae1f5e0":"#Check distribution of target\nsns.set_style (style = \"whitegrid\")\n\nplt.figure(figsize = (10, 5))\nsns.countplot(dataframe['Risk'])\nplt.title('Distribution of Target', color = 'blue', loc = 'center', fontsize = 20)\nplt.xlabel('Category of Risk', color = 'black', fontsize = 14)\nplt.ylabel('Count', color = 'black', fontsize = 14)\nplt.show()","33ab917d":"#Check Distribution of numeric features\nnumeric_features = ['Age', 'Credit amount', 'Duration']\nfig, ax = plt.subplots(1, 3, figsize=(15, 6))\ndataframe[numeric_features][dataframe['Risk'] == \"good\"].hist(bins=10, color = 'Blue', alpha=0.5, ax = ax)\ndataframe[numeric_features][dataframe['Risk'] == \"bad\"].hist(bins=10, color = 'Black', alpha=0.5, ax = ax)\nplt.show()","7dc4d054":"#Check distribution of feature\ncols = ['Sex', 'Job', 'Housing', 'Purpose']\n\nfig, axarr = plt.subplots(2, 3, figsize=(15, 15))\nfor i in cols:\n    index = cols.index(i)\n    plt.subplot(2, 3, index + 1)\n    sns.countplot(x = i, data = dataframe, hue=\"Risk\", palette = \"deep\")\n    plt.xticks(rotation=90)","77962b5b":"#Check outlier\nfig, axarr = plt.subplots(1, 3, figsize=(10, 5))\ncols = ['Age', 'Credit amount', 'Duration']\nfor i in cols:\n    index = cols.index(i)\n    plt.subplot(1,3,index + 1)\n    sns.boxplot(dataframe[i])","7ffe8db5":"#Drop unnecessary column\ndataframe.drop('Unnamed: 0', axis = 1, inplace = True)","71517f40":"#Handle Missing Value\ndataframe['Saving accounts'].fillna('None', inplace = True)\ndataframe['Checking account'].fillna('None', inplace = True)","829dd7cd":"print (\"Before handling ordinal type feature Saving accounts\", dataframe['Saving accounts'].unique())\nprint ('Before handling ordinal type feature Checking accounts', dataframe['Checking account'].unique())\nprint ('Before handling ordinal type feature Checking accounts', dataframe['Risk'].unique())","5fc327f9":"le = LabelEncoder()\ndataframe['Saving accounts'] = le.fit_transform(dataframe['Saving accounts'])\ndataframe['Checking account'] = le.fit_transform(dataframe['Checking account'])\ndataframe['Risk'] = le.fit_transform(dataframe['Risk'])\n\nprint (\"After handling ordinal type feature Saving accounts\", dataframe['Saving accounts'].unique())\nprint ('After handling ordinal type feature Checking accounts', dataframe['Checking account'].unique())\nprint ('After handling ordinal type feature Checking accounts', dataframe['Risk'].unique())","963080fe":"#Change data type Job\ndataframe['Job'] = dataframe['Job'].astype(object)","a873a319":"#Handling outlier\nQ1 = (dataframe[['Age', 'Credit amount', 'Duration']]).quantile(0.25)\nQ3 = (dataframe[['Age', 'Credit amount', 'Duration']]).quantile(0.75)\n\nIQR = Q3 - Q1\n\nmaximum = Q3 + (1.5*IQR)\nminimum = Q3 - (1.5*IQR)\n\nmore_than = (dataframe[['Age', 'Credit amount', 'Duration']] > maximum)\nlower_than = (dataframe[['Age', 'Credit amount', 'Duration']] < minimum)\n\ndataframe[['Age', 'Credit amount', 'Duration']] = dataframe[['Age', 'Credit amount', 'Duration']].mask(more_than, maximum, axis=1)\ndataframe[['Age', 'Credit amount', 'Duration']] = dataframe[['Age', 'Credit amount', 'Duration']].mask(lower_than, minimum, axis=1)","4aa0e087":"fig, axarr = plt.subplots(1, 3, figsize=(10, 5))\ncols = ['Age', 'Credit amount', 'Duration']\nfor i in cols:\n    index = cols.index(i)\n    plt.subplot(1,3,index + 1)\n    sns.boxplot(dataframe[i])","86e9a27b":"#One Hot Encoding\ndataframe = pd.get_dummies(dataframe)","6d83b7d5":"#Spliting Dataframe\nX = dataframe.drop('Risk', axis = 1)\ny = dataframe['Risk']","36052335":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","b40a6e7f":"print ('Size of X train', X_train.shape)\nprint ('Size of X test', X_test.shape)\nprint ('Size of y train', y_train.shape)\nprint ('Size of y test', y_test.shape)","f6af3450":"DecisionTree = DecisionTreeClassifier()\nDecisionTree.fit(X_train, y_train)\ny_pred_train = DecisionTree.predict(X_train)\ny_pred_test = DecisionTree.predict(X_test)\n\nprint ('Accuracy of model based on training set', accuracy_score(y_train, y_pred_train))\nprint ('Accuracy of model based on testing set', accuracy_score(y_test, y_pred_test))\n\nprint ('Classification report based on training set\\n',classification_report(y_train, y_pred_train))\nprint ('Classification report based on testing set\\n', classification_report(y_test, y_pred_test))\n\n# Form confusion matrix as a DataFrame\nconfusion_matrix_train_df = pd.DataFrame((confusion_matrix(y_train, y_pred_train)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_train_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Training Model\\n(Decision Tree)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()\n\nconfusion_matrix_testing_df = pd.DataFrame((confusion_matrix(y_test, y_pred_test)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_testing_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Testing Model\\n(Decision Tree)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()","df963527":"NaiveBayes = GaussianNB()\nNaiveBayes.fit(X_train, y_train)\ny_pred_train = NaiveBayes.predict(X_train)\ny_pred_test = NaiveBayes.predict(X_test)\n\nprint ('Accuracy of model based on training set', accuracy_score(y_train, y_pred_train))\nprint ('Accuracy of model based on testing set', accuracy_score(y_test, y_pred_test))\n\nprint ('Classification report based on training set\\n', classification_report(y_train, y_pred_train))\nprint ('Classification report based on testing set\\n', classification_report(y_test, y_pred_test))\n\n# Form confusion matrix as a DataFrame\nconfusion_matrix_train_df = pd.DataFrame((confusion_matrix(y_train, y_pred_train)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_train_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Training Model\\n(Naive Bayes Classifier)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()\n\nconfusion_matrix_testing_df = pd.DataFrame((confusion_matrix(y_test, y_pred_test)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_testing_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Testing Model\\n(Naive Bayes Classifier)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()","95dc6efe":"RandomForest = RandomForestClassifier()\nRandomForest.fit(X_train, y_train)\ny_pred_train = RandomForest.predict(X_train)\ny_pred_test = RandomForest.predict(X_test)\n\nprint ('Accuracy of model based on training set', accuracy_score(y_train, y_pred_train))\nprint ('Accuracy of model based on testing set', accuracy_score(y_test, y_pred_test))\n\nprint ('Classification report based on training set\\n', classification_report(y_train, y_pred_train))\nprint ('Classification report based on testing set\\n', classification_report(y_test, y_pred_test))\n\n# Form confusion matrix as a DataFrame\nconfusion_matrix_train_df = pd.DataFrame((confusion_matrix(y_train, y_pred_train)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_train_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Training Model\\n(Random Forest Classifier)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()\n\nconfusion_matrix_testing_df = pd.DataFrame((confusion_matrix(y_test, y_pred_test)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_testing_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Testing Model\\n(Random Forest Classifier)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()","02b999db":"LogisticReg = LogisticRegression()\nLogisticReg.fit(X_train, y_train)\ny_pred_train = LogisticReg.predict(X_train)\ny_pred_test = LogisticReg.predict(X_test)\n\nprint ('Accuracy of model based on training set', accuracy_score(y_train, y_pred_train))\nprint ('Accuracy of model based on testing set', accuracy_score(y_test, y_pred_test))\n\nprint ('Classification report based on training set\\n', classification_report(y_train, y_pred_train))\nprint ('Classification report based on training set\\n', classification_report(y_test, y_pred_test))\n\n# Form confusion matrix as a DataFrame\nconfusion_matrix_train_df = pd.DataFrame((confusion_matrix(y_train, y_pred_train)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_train_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Training Model\\n(Logistic Regression)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()\n\nconfusion_matrix_testing_df = pd.DataFrame((confusion_matrix(y_test, y_pred_test)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_testing_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Testing Model\\n(Logistic Regression)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()","1fcf9c09":"KNN = KNeighborsClassifier()\nKNN.fit(X_train, y_train)\ny_pred_train = KNN.predict(X_train)\ny_pred_test = KNN.predict(X_test)\n\nprint ('Accuracy of model based on training set', accuracy_score(y_train, y_pred_train))\nprint ('Accuracy of model based on testing set', accuracy_score(y_test, y_pred_test))\n\nprint ('Classification report based on training set\\n', classification_report(y_train, y_pred_train))\nprint ('Classification report based on testing set\\n', classification_report(y_test, y_pred_test))\n\n# Form confusion matrix as a DataFrame\nconfusion_matrix_train_df = pd.DataFrame((confusion_matrix(y_train, y_pred_train)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_train_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Training Model\\n(KNN Classifier)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()\n\nconfusion_matrix_testing_df = pd.DataFrame((confusion_matrix(y_test, y_pred_test)), ('Bad', 'Good'), ('Bad', 'Good'))\n# Plot confusion matrix\nplt.figure()\nheatmap = sns.heatmap(confusion_matrix_testing_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n\nplt.title('Confusion Matrix for Testing Model\\n(KNN Classifier)', fontsize=18, color='darkblue')\nplt.ylabel('True abel', fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.show()","0585e793":"## Load Dataframe","8cdb2ef8":"## Data Preprocessing","6b51201e":"It appears that the distribution of the targets is not quite balanced 700 for good risk and 300 risk. ","fd226bf8":"## Modelling","5b42be7f":"## Data Exploration","cfffd961":"* There are a feature type that doesn't match, that's a Job feature.\n* The saving account and checking account features have missing value.\n* There are a features that are not used, that's Unnamed: 0","03f3205d":"There is a tendency that bad risk will occur to people who are male, the type of work is 2,type housing is own housing, and the purpose of the credit loan is to pay off a car.","234876f6":"It can be seen that the features of saving and checking account are categorical data of ordinal type. So to handle it we need to use Labeling.\n\nMeanwhile, the Purpose feature is categorical data of nominal type. So to handle it we need one hot encoding","9224b9e9":"Feature Age, Credit amount and duration there doesn't appear to be any inclination towards the Risk Credit of customers.","3e4fee3d":"## Evaluation Model\n\nBased on the modeling above, we choose Logistic Regression. This is because the performance of the Logistic Regression model tends to be able to predict equally well in the training and testing phases. On the other hand, other algorithms tend to over-fit their performance."}}