{"cell_type":{"fd91b6bf":"code","98df6e4e":"code","591f21c3":"code","6afb3638":"code","c21b299d":"code","34219e01":"code","c54313c0":"code","ad63ab8b":"code","6a28ee04":"code","ad2b2fea":"code","924593a9":"code","b86df9f5":"code","bfb3f47e":"code","984ec518":"code","640be445":"code","91be8c28":"code","74dd204b":"code","40261d24":"code","81065c28":"code","6b9a79ea":"code","8c25dc4b":"code","257c715c":"markdown"},"source":{"fd91b6bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport random\n\nimport warnings\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\n\nimport lightgbm as lgb\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","98df6e4e":"warnings.filterwarnings(action='once')","591f21c3":"calendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv', parse_dates=['date'], index_col='date')\ncalendar.head(5)","6afb3638":"calendar.fillna('0', inplace=True)\n\nlabel_encoder = LabelEncoder()\nlabel_cols = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n\n# Apply label encoder \nfor col in label_cols:\n    calendar[col] = label_encoder.fit_transform(calendar[col])\n\ncalendar.head(5)","c21b299d":"calendar['is_weekend'] = calendar['wday'].apply(lambda x: 1 if x == 1 or x == 2 else 0)\nseasons = {1: 1, 2: 1, 12: 1, 3: 2, 4: 2, 5: 2, 6: 3, 7: 3, 8: 3, 9: 4, 10: 4, 11: 4 }\ncalendar['season'] = calendar['month'].apply(lambda x: seasons[x])\ncalendar.head()","34219e01":"calendar.info()","c54313c0":"calendar['wm_yr_wk'] = calendar['wm_yr_wk'].astype(np.int16)\ncalendar['wday'] = calendar['wday'].astype(np.int8)\ncalendar['month'] = calendar['month'].astype(np.int8)\ncalendar['year'] = calendar['year'].astype(np.int16)\ncalendar['snap_CA'] = calendar['snap_CA'].astype(np.int8)\ncalendar['snap_TX'] = calendar['snap_TX'].astype(np.int8)\ncalendar['snap_WI'] = calendar['snap_WI'].astype(np.int8)\ncalendar['is_weekend'] = calendar['is_weekend'].astype(np.int8)\ncalendar['season'] = calendar['season'].astype(np.int8)\ncalendar['event_name_1'] = calendar['event_name_1'].astype(np.int16)\ncalendar['event_type_1'] = calendar['event_type_1'].astype(np.int8)\ncalendar['event_name_2'] = calendar['event_name_2'].astype(np.int8)\ncalendar['event_type_2'] = calendar['event_type_2'].astype(np.int8)","ad63ab8b":"calendar.info()","6a28ee04":"train_data = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')\ntrain_data.head()","ad2b2fea":"def melt_item_group(group):\n    numcols = [f\"d_{day}\" for day in range(0,1941 + 1)]\n    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    \n    for day in range(1942, 1942 + 28):\n        group[f\"d_{day}\"] = np.nan\n\n    dt = pd.melt(\n        group,\n        id_vars = catcols,\n        value_vars = [col for col in group.columns if col.startswith(\"d_\")],\n        var_name = \"d\",\n        value_name = \"sales\"\n    )\n    return dt","924593a9":"prices = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nprices['wm_yr_wk'] = prices['wm_yr_wk'].astype(np.int16)\nprices['sell_price'] = prices['sell_price'].astype(np.float32)\nprices['wm_yr_wk'] = prices['wm_yr_wk'].astype(np.int16)\nprices.set_index(['store_id', 'item_id', 'wm_yr_wk'], inplace=True)\nprices = prices.sort_index()","b86df9f5":"prices.head()","bfb3f47e":"def convert_categorical_columns(df, columns):\n    for column in columns:\n        df[column] = df[column].astype('category')\n        df[column] = df[column].cat.codes\n        df[column] = df[column].astype('category')","984ec518":"def get_dataset_simple(df, label_column):\n    test_df = df.loc['d_1914':,:].copy()\n    \n    valid_df = df.loc['d_1914': 'd_1941',:].copy()\n    \n    train_df = df.loc[df.index[0]: 'd_1913',:].copy()\n    train_df.loc[:,label_column] = train_df.loc[:,label_column]\n    \n    return train_df, valid_df, test_df","640be445":"def get_dataset(df, label_column):\n    test_df = df.loc['d_1914':,:].copy()\n    \n    df_shape = df.loc[:'d_1941',:].shape\n    samples_idx = random.sample(range(df_shape[0]), int(0.2 * df_shape[0]))\n    \n    valid_idxs = samples_idx\n    \n    train_idxs = list(set(list(range(0, df_shape[0] ))) - set(samples_idx))\n    \n    return train_idxs, valid_idxs, test_df","91be8c28":"evaluation_data = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')\n\nevaluation_data.loc[:,'id'] = evaluation_data['id'].apply(lambda x: x[:-10] + 'validation')\nevaluation_data.set_index('id', inplace=True)\nevaluation_data = evaluation_data.loc[:,'d_1914': 'd_1941'].copy()\n\ndef get_rmse(submission_validation):\n    sub = submission_validation.set_index('id')\n    error = mean_squared_error(sub.values, evaluation_data.loc[sub.index,:].values)\n    return error","74dd204b":"def split_prediction(prediction):\n    columns = ['id'] + ['F%s' % i for i in range(1, 29)]\n    prediction = prediction.reset_index().set_index('id')\n    prediction_evaluation = prediction.loc[:,'d_1914':'d_1941'].reset_index().copy()\n    prediction_evaluation.columns = columns\n    \n    prediction_validation = prediction.loc[:,'d_1942':].reset_index().copy()\n    prediction_validation.columns = columns\n    prediction_validation.loc[:, 'id'] = prediction_validation['id'].str[:-10] + 'validation'\n    \n    return prediction_validation, prediction_evaluation","40261d24":"def create_price_features(group_df, horizon=28):\n    lag = horizon \/\/ 7\n    group_df['sell_price_diff_shift_1'] = group_df.groupby('id')['sell_price'].transform(lambda x: x - x.shift(1)).astype(np.float32)\n    group_df[f'sell_price_diff_shift_{horizon}'] = group_df.groupby('id')['sell_price'].transform(lambda x: x - x.shift(horizon)).astype(np.float32)\n    group_df['sell_price_diff_rolling_7'] = group_df.groupby('id')['sell_price'].transform(lambda x: x - x.rolling(7).mean()).astype(np.float32)\n    \n    group_df[f'sell_price_diff_shift_{horizon}_shift_1'] = group_df.groupby('id')['sell_price_diff_shift_1'].transform(lambda x: x.shift(horizon)).astype(np.float32)\n    group_df[f'sell_price_diff_shift_{horizon}_shift_{horizon}'] = group_df.groupby('id')[f'sell_price_diff_shift_{horizon}'].transform(lambda x: x.shift(horizon)).astype(np.float32)\n    group_df[f'sell_price_diff_shift_{horizon}_rolling_7'] = group_df.groupby('id')['sell_price_diff_rolling_7'].transform(lambda x: x.shift(horizon)).astype(np.float32)\n    \n    group_df[f'sell_price_diff_rolling_7_diff_rolling_7_shift{horizon}'] = group_df.groupby('id')['sell_price_diff_rolling_7'].transform(lambda x: x - x.shift(horizon)).astype(np.float32)","81065c28":"def get_created_features(horizon=28):\n    feature_columns = [\n        'sell_price_diff_shift_1',\n        'sell_price_diff_rolling_7',\n        f'sell_price_diff_shift_{horizon}',\n        f'sell_price_diff_shift_{horizon}_shift_1',\n        f'sell_price_diff_shift_{horizon}_shift_{horizon}',\n        f'sell_price_diff_shift_{horizon}_rolling_7', # ?\n        f'sell_price_diff_rolling_7_diff_rolling_7_shift{horizon}',\n    ]\n    return feature_columns","6b9a79ea":"%%time\n\nidx_feature = ['id']\ncategorical_feature = [\n    'dept_id' ,\n    'state_id',\n    #'wday',\n    #'month',\n    #'year',\n    'event_name_1',\n    'event_type_1',\n    'snap_CA',\n    'snap_TX',\n    'snap_WI',\n    'event_name_2',\n    'event_type_2',\n    'is_weekend',\n    'season',\n]\nfeature_columns = categorical_feature + [\n    'sales_shift_28',\n    'sales_mean_rolling_4_wday_shift_4',\n    'sales_mean_rolling_4_wday_shift_8',\n    'sell_price',\n]\n#train_generated_features = ['day_min', 'day_mean', 'day_max']\n\nlabel_column = 'sales'\n\ndummy_subm = pd.DataFrame(columns=['id'] + ['F%s' % i for i in range(1, 29)])\nsubmission_validation = dummy_subm.copy()\nsubmission_evaluation = dummy_subm.copy()\n\nsubmission_validation_lgb = dummy_subm.copy()\nsubmission_evaluation_lgb = dummy_subm.copy()\n\ngroups = train_data.groupby('store_id')\nlen_group = len(groups)\n\nfor i, (store_id, group) in enumerate(groups):\n    print(store_id)\n\n    group = melt_item_group(group)\n    group_df = group.join(calendar.set_index('d'), on='d')\n    del group\n\n    group_df.sales.fillna(0, inplace=True)\n    \n    group_df = group_df.set_index(['d'])\n    \n    # add features for unique store\n    group_df['sales_shift_28'] = group_df.groupby(['id'])['sales'].transform(lambda x: x.shift(28)).astype(np.float32)\n    \n    group_df['sales_mean_rolling_4_wday'] = group_df.groupby(['id', 'wday'])['sales'].transform(lambda x: x.rolling(4).mean()).astype(np.float32)\n    group_df['sales_mean_rolling_4_wday_shift_4'] = group_df.groupby(['id', 'wday'])['sales_mean_rolling_4_wday'].transform(lambda x: x.shift(4)).astype(np.float32)\n    group_df['sales_mean_rolling_4_wday_shift_8'] = group_df.groupby(['id', 'wday'])['sales_mean_rolling_4_wday'].transform(lambda x: x.shift(8)).astype(np.float32)\n\n    # add prices\n    print('add prices')\n    group_df = group_df.join(\n        prices.loc[store_id], on=['item_id', 'wm_yr_wk']\n    )\n    label_cols_prices = ['state_id', 'dept_id']\n    convert_categorical_columns(group_df, label_cols_prices)\n    \n    create_price_features(group_df)\n    feature_columns += get_created_features()\n    \n    # drop rows with na\n    group_df.dropna(inplace=True)\n    print('drop rows with na')\n\n    train_idxs, valid_idxs, test_df = get_dataset(\n        group_df[feature_columns + [label_column] + idx_feature],\n        label_column=label_column\n    )\n    \n    print('get_dataset_simple')\n    #key = all_id[:-10] + 'validation'\n    prediction = test_df.reset_index().set_index(['d', 'id',])['sales_mean_rolling_4_wday_shift_4']#.values.tolist()\n    prediction = prediction.unstack(level=0)\n    prediction_validation, prediction_evaluation = split_prediction(prediction)\n    \n    try:\n        #lgb\n        dtrain = lgb.Dataset(group_df.iloc[train_idxs][feature_columns], label=group_df.iloc[train_idxs][label_column], categorical_feature=categorical_feature)\n        dvalid = lgb.Dataset(group_df.iloc[valid_idxs][feature_columns], label=group_df.iloc[valid_idxs][label_column], categorical_feature=categorical_feature)\n\n        param = {\n            'boosting_type': 'gbdt',\n            'objective': 'tweedie',\n            #'tweedie_variance_power': 1.1,\n            'metric': 'rmse',\n            'subsample': 0.5,\n            'subsample_freq': 1,\n            'learning_rate': 0.03,\n            'num_leaves': 1024,\n            'min_data_in_leaf': 1024,\n            'feature_fraction': 0.2,\n            'max_bin': 10,\n            'boost_from_average': False,\n            'verbose': -1,\n            #'lambda_l1': 0.8,\n            #'lambda_l2': 0,\n            #'min_gain_to_split': 1.,\n            #'min_sum_hessian_in_leaf': 1e-3,\n        }\n        # https:\/\/lightgbm.readthedocs.io\/en\/latest\/index.html\n        bst = lgb.train(param, dtrain, valid_sets=[dvalid], num_boost_round = 2000, early_stopping_rounds=30, verbose_eval=True, categorical_feature=categorical_feature)\n\n        prediction_lgb = bst.predict(test_df.reset_index().set_index(['d', 'id',])[feature_columns])\n        prediction_lgb_df = test_df.reset_index()[['d', 'id']].copy()\n        prediction_lgb_df['prediction'] = prediction_lgb\n        prediction_lgb_df = prediction_lgb_df.set_index(['d', 'id',]).unstack(level=0).reset_index()\n        prediction_lgb_df.columns = ['id'] + ['d_{}'.format(i) for i in range(1914, 1970)]\n        prediction_validation_lgb, prediction_evaluation_lgb = split_prediction(prediction_lgb_df)\n    except Exception as e:\n        print(e)\n        prediction_validation_lgb = prediction_validation\n        prediction_evaluation_lgb = prediction_evaluation\n    finally:\n        submission_validation_lgb = submission_validation_lgb.append(prediction_validation_lgb)\n        submission_evaluation_lgb = submission_evaluation_lgb.append(prediction_evaluation_lgb)\n\n    submission_validation = submission_validation.append(prediction_validation)\n    submission_evaluation = submission_evaluation.append(prediction_evaluation)","8c25dc4b":"submission = submission_validation.append(submission_evaluation)\nsubmission.to_csv('\/kaggle\/working\/submission_mean.csv', index=False)\n\nsubmission_lgb = submission_validation_lgb.append(submission_evaluation_lgb)\nsubmission_lgb.to_csv('\/kaggle\/working\/submission_lgb.csv', index=False)","257c715c":"Final:\nlgb 7.161521607829326\nrmse 4.995158482142858\ngibrid 6.87113691931274\nCPU times: user 5min 40s, sys: 53.6 s, total: 6min 33s\nWall time: 3min 54s"}}