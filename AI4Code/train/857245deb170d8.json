{"cell_type":{"5566f71f":"code","eb5d8435":"code","68702b1e":"code","974354ef":"code","ebfadb4a":"code","ca988802":"code","959a0183":"markdown","b88442b9":"markdown","8fae2866":"markdown","c9b290ba":"markdown","729d6f78":"markdown","2f373354":"markdown"},"source":{"5566f71f":"##################################################\n# Imports\n##################################################\n\nimport numpy as np\nimport cv2\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport emoji\n\n\n##################################################\n# Params\n##################################################\n\nDATA_BASE_FOLDER = '\/kaggle\/input\/emojify-challenge'\n\n\n##################################################\n# Utils\n##################################################\n\ndef label_to_emoji(label):\n    \"\"\"\n    Converts a label (int or string) into the corresponding emoji code (string) ready to be printed\n    \"\"\"\n    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)","eb5d8435":"##################################################\n# Load dataset\n##################################################\n\ndf_train = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'train.csv'))\ny_train = df_train['class']\ndf_validation = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'validation.csv'))\ny_validation = df_validation['class']\nemoji_dictionary = {\n    '0': '\\u2764\\uFE0F',\n    '1': ':baseball:',\n    '2': ':smile:',\n    '3': ':disappointed:',\n    '4': ':fork_and_knife:'\n}\n\n# See some data examples\nprint('EXAMPLES:\\n####################')\nfor idx in range(10):\n    print(f'{df_train[\"phrase\"][idx]} -> {label_to_emoji(y_train[idx])}')","68702b1e":"# Load phrase representation\nx_train = np.load(\n    os.path.join(DATA_BASE_FOLDER, \n                 'train.npy')).reshape(len(df_train), -1)\nx_validation = np.load(\n    os.path.join(DATA_BASE_FOLDER, \n                 'validation.npy')).reshape(len(df_validation), -1)\nprint(f'Word embedding size: {x_train.shape[-1]}')","974354ef":"##################################################\n# Implement you model here\n##################################################\n\n\n\n","ebfadb4a":"##################################################\n# Evaluate the model here\n##################################################\n\n# Use this function to evaluate your model\ndef accuracy(y_pred, y_true):\n    '''\n    input y_pred: ndarray of shape (N,)\n    input y_true: ndarray of shape (N,)\n    '''\n    return (1.0 * (y_pred == y_true)).mean()\n\n# Report the accuracy in the train and validation sets.\n\n\n\n\n\n\n","ca988802":"##################################################\n# Save your test prediction in y_test_pred\n##################################################\n\ny_test_pred = None\n\n# Create submission\nsubmission = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\nx_test = np.load(os.path.join(DATA_BASE_FOLDER, 'test.npy')).reshape(len(submission), -1)\nif y_test_pred is not None:\n    submission['class'] = y_test_pred\nsubmission.to_csv('my_submission.csv', index=False)","959a0183":"# Welcome to the Emojify Challenge!","b88442b9":"# Word embeddings\n\nWords can be represented as n-dimentional vectors where the distance between points has a correspondence respect to similarity between word semantics (similar words are closer, while dissimilar ones are distant). This representation is known as word embeddings and here is extrapolated and pre-computed from the [GloVe](https:\/\/nlp.stanford.edu\/projects\/glove\/) model. \n\nHere is depicted an example of bi-dimensional word embeddings:\n![word embedding](https:\/\/shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com\/wp-content\/uploads\/2018\/01\/word-vector-space-similar-words.jpg)\n\nIn our case a single word is represented by a vector of length 25.\n\n# Phrase representation\n\nAll the phrases are padded to the phrase of maximum length, in this case `max_len = 10`, and each phrase is represented by the concatenation of his word embeddings (each phrase thus is a 10 * 25 = 250 dimentional vector).","8fae2866":"# Send the submission for the challenge","c9b290ba":"# Dataset","729d6f78":"# Model\n\nHere you have to implement a model (or more models, for finding the most accurate) for classification.\n\nYou can use the sklearn (or optionally other more advanced frameworks such as pytorch or tensorflow) package that contains a pool of models already implemented that perform classification. (SVMs, NNs, LR, kNN, ...)","2f373354":"# Evaluation"}}