{"cell_type":{"48b806f2":"code","33acd5ca":"code","01557523":"code","b0205585":"code","e4ca684f":"code","4f63f3ab":"code","5a2b610b":"code","cee3a1fe":"code","c1654d98":"markdown","5c7c1622":"markdown","593b44bd":"markdown"},"source":{"48b806f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as ml\nimport matplotlib.pyplot as plt\n%matplotlib inline\nml.style.use('ggplot')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33acd5ca":"test_data = pd.read_csv('\/kaggle\/input\/years-of-experience-and-salary-dataset\/Salary_Data.csv')\nprint(test_data.shape)\ntest_data.head(10)","01557523":"test_data.info()","b0205585":"test_data.describe()","e4ca684f":"class LinearRegression():\n    def __init__(self,fit_intercept=True):\n        self.numerator = 0\n        self.denominator = 0\n        self.b0 = 0\n        self.b1= 0\n        self.fit_intercept = fit_intercept\n    def fit(self,datax,datay):\n        # Mean of the input and output\n        meanx = np.mean(datax)\n        meany = np.mean(datay)\n        \n        # Total number of values\n        N = len(datax)      # datax must be an ndarray or a list.\n        \n        # Formula to calculate b1 and b0\n        '''Basic formula of the best fit line :\n            y = b0 + b1*x, where\n            \n            b0 = intercept\n            b1 = slope\n            \n            Now, b1 = [(Xi - X_bar)*(Yi - Y_bar)]\/[(Xi - X_bar)^2]\n                 b0 = Y_bar - (b1*X_bar)\n        '''\n        for i in range(N):\n            self.numerator += (datax[i] - meanx)*(datay[i] - meany)\n            self.denominator += (datax[i] - meanx)**2\n        self.b1 += self.numerator\/self.denominator\n        if self.fit_intercept == True:\n            self.b0 += meany - (self.b1*meanx)\n        else:\n            self.b0 = 0 \n        \n        return self\n    def predict(self,testx):\n        y = self.b1*testx + self.b0\n        return y","4f63f3ab":"X = np.array(test_data.iloc[:,0].values)\ny = np.array(test_data.iloc[:,1].values)\ntrainx,testx,trainy,testy = train_test_split(X,y,test_size=0.3,random_state=5)\n\nlr = LinearRegression(fit_intercept=True)\nlr.fit(trainx,trainy)\ny_pred = lr.predict(testx)\ny_pred","5a2b610b":"print(\"R2 Score for this model = \", r2_score(testy,y_pred))","cee3a1fe":"plt.figure(figsize=(10,5))\nplt.plot(testx,y_pred,color='blue',label=\"Best Fit Line\")\nplt.scatter(X,y,color='red',label=\"Data points\")\nplt.xlabel(\"YearsExperience\")\nplt.ylabel(\"Salary\")\nplt.title(\"PLOTTING THE BEST FIT CURVE\")\nplt.show()","c1654d98":"# LINEAR REGRESSION FROM SCRATCH\nWe create a class(just like in sklearn) and define two major methods :\n1. fit()\n2. predict()","5c7c1622":"# PLOTTING THE BEST FIT CURVE","593b44bd":"# TESTING"}}