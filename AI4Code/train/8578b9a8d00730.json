{"cell_type":{"340a04e8":"code","9ac18306":"code","4607ea83":"code","1d572a67":"code","d66b6a7b":"code","f1226cd7":"code","572f7052":"code","823e95c8":"code","ff2e60b5":"code","4eb0da52":"code","3c4d6230":"code","e4a20782":"code","d3bfc2ee":"code","76105423":"code","6f8e5fd2":"code","1d605060":"code","2564645c":"code","02e24e71":"code","00b15606":"markdown","082ae950":"markdown","767638e3":"markdown","9bc04382":"markdown"},"source":{"340a04e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9ac18306":"#  \/kaggle\/input\/food41\/images\/macarons\/2428554.jpg\n\n!nvidia-smi","4607ea83":"data_dir = '\/kaggle\/input\/food41\/images\/'","1d572a67":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","d66b6a7b":"datagen = ImageDataGenerator(rescale = 1.\/255, validation_split = 0.2)","f1226cd7":"train_data = datagen.flow_from_directory(data_dir, target_size = (250,250), batch_size = 32, class_mode = 'categorical',\n                                        subset = 'training')\n\nval_data = datagen.flow_from_directory(data_dir, target_size = (250,250), batch_size = 32, class_mode = 'categorical',\n                                        subset = 'validation')","572f7052":"ResNet_V2_50 = 'https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_50\/classification\/5'\nEfficientnet_b0 = \"https:\/\/tfhub.dev\/google\/efficientnet\/b0\/classification\/1\"","823e95c8":"import tensorflow_hub as hub","ff2e60b5":"model_ResNet = tf.keras.Sequential([\n    hub.KerasLayer(ResNet_V2_50, trainable = False, input_shape = (250,250,3), name = 'Resnet_V2_50'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(101, activation = 'softmax', name = 'Output_layer')\n])\n\nmodel_ResNet.compile(\n    optimizer = tf.keras.optimizers.Adam(),\n    loss = tf.keras.losses.CategoricalCrossentropy(),\n    metrics = ['accuracy']\n)","4eb0da52":"model_ResNet.summary()","3c4d6230":"tf.keras.utils.plot_model(model_ResNet)","e4a20782":"resnet_model = model_ResNet.fit(train_data, epochs = 10, verbose = 1) #5","d3bfc2ee":"model_ResNet.evaluate(val_data)","76105423":"model_Efficientnet = tf.keras.Sequential([\n    hub.KerasLayer(Efficientnet_b0, trainable = False, input_shape = (250,250,3), name = 'Resnet_V2_50'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(101, activation = 'softmax', name = 'Output_layer')\n])\n\nmodel_Efficientnet.compile(\n    optimizer = tf.keras.optimizers.Adam(),\n    loss = tf.keras.losses.CategoricalCrossentropy(),\n    metrics = ['accuracy']\n)","6f8e5fd2":"efficientnet_model = model_Efficientnet.fit(train_data, epochs = 10, verbose = 1)","1d605060":"model_Efficientnet.evaluate(val_data)","2564645c":"def plot_graph(history, history_1):\n    loss_res = history.history['loss']\n    loss_ef = history_1.history['loss']\n    \n    Accuracy_res = history.history['accuracy']\n    Accuracy_ef = history_1.history['accuracy']\n\n    epochs = range(len(history.history['loss']))\n\n    plt.plot(epochs, loss_res, label = 'ResNet Loss')\n    plt.plot(epochs, loss_ef, label = 'Efficientnet Loss')\n    plt.title('Epochs Vs Loss')\n    plt.xlabel('epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.figure()\n    plt.plot(epochs, Accuracy_res, label = 'ResNet Accuracy')\n    plt.plot(epochs, Accuracy_ef, label = 'Efficientnet Accuracy')\n    plt.title('Epochs Vs Accuracy')\n    plt.xlabel('epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()","02e24e71":"plot_graph(resnet_model, efficientnet_model)","00b15606":"## ***ResNet Model Building***","082ae950":"## ***Data Collection***","767638e3":"## ***Efficientnet Model Building***","9bc04382":"## ***Comparison Between Both Models***"}}