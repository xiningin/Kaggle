{"cell_type":{"fb4b5925":"code","f4edab90":"code","76958cd1":"code","e096912c":"code","4111cc2e":"code","c676ea4f":"code","7f696b61":"code","c73ffcc8":"code","7a406e7c":"code","133265c4":"code","4b524454":"code","3fb58f02":"code","401c8642":"code","e45d49f1":"code","941d5377":"code","843d0ba0":"code","2bd51046":"code","0a9b79cc":"code","c9da15ab":"code","0ecf30df":"code","fb2107d6":"markdown","9255fa2b":"markdown","a57b059d":"markdown","8583f30d":"markdown","fde8b3bc":"markdown","05f3484b":"markdown","a62ada46":"markdown","03f4fece":"markdown"},"source":{"fb4b5925":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4edab90":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n","76958cd1":"import os\nfrom pathlib import Path\n\nfile_path = Path('\/kaggle\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/')\nfile_content = list(file_path.glob(r'**\/*.png'))\n\n#create labels as per the label name\n\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_content))","e096912c":"file_content = pd.Series(file_content).astype(str)\nlabels = pd.Series(labels)","4111cc2e":"df = pd.concat([file_content, labels], axis=1)\ndf.columns = ['image', 'label']\ndf.head()","c676ea4f":"#shape of the dataset\n\ndf.shape","7f696b61":"fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(17,13), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.image[i]))\n    ax.set_title(df.label[i])\n    \nplt.show()","c73ffcc8":"df['label'].value_counts().plot.bar()\nprint(df['label'].value_counts())","7a406e7c":"df = df[df['label'].apply(lambda x: x[-2:] != 'GT')].reset_index(drop=True)\ndf.label.value_counts()","133265c4":"# split the data into training and validation set\n\n\nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test = train_test_split(df, test_size=0.3, random_state=42)\nx_train, x_val = train_test_split(x_train, test_size =0.3, random_state=42)\n\n","4b524454":"print(\"The shape of training data\", x_train.shape)\nprint(\"The shape of validation data\", x_val.shape)\nprint(\"The shape of test data\", x_test.shape)","3fb58f02":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1\/255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale=1\/255)\n\ntest_datagen = ImageDataGenerator(rescale=1\/255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=x_train,\n    x_col='image',\n    y_col='label',\n    target_size=(150,150),\n    class_mode='categorical' ,\n    batch_size = 128\n)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    dataframe = x_val,\n    x_col = 'image',\n    y_col = 'label',\n    target_size = (150,150),\n    class_mode = 'categorical',\n    batch_size = 64\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe = x_test,\n    x_col = 'image',\n    y_col = 'label',\n    target_size = (150,150),\n    class_mode = 'categorical',\n    batch_size = 64\n)","401c8642":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',\n                          input_shape=(150,150,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    #tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    #tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(9, activation='softmax')\n    \n])","e45d49f1":"model.summary()","941d5377":"from tensorflow.keras.optimizers import Adam\n\nmodel.compile(optimizer='adam',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\n","843d0ba0":"history = model.fit(train_generator,\n                   epochs=30,\n                   steps_per_epoch=34,\n                   validation_data = validation_generator,\n                   validation_steps = 30,\n                   verbose=1)\n\nmodel.save('fish-classification.h5')","2bd51046":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","0a9b79cc":"pred = model.predict(test_generator)\npred = np.argmax(pred, axis=1)\nlabels = train_generator.class_indices\nlabels = dict((v,k) for k, v in labels.items())\ny_pred = [labels[k] for k in pred]\n","c9da15ab":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint(classification_report(x_test.label, y_pred))\n\nprint(confusion_matrix(x_test.label, y_pred))\n","0ecf30df":"test_accuracy = model.evaluate(test_generator)[1]\n","fb2107d6":"## # # Model creation","9255fa2b":"The acccuracy of 94% has been achieved.","a57b059d":"# # # Visualizing the data ","8583f30d":"# # # Split the data","fde8b3bc":"Remove the ground truth as we dont need them.","05f3484b":"# # # Prediction","a62ada46":"# # # Import libraries","03f4fece":"Import all the necessary libraries. \n\nThere are 9 different fishes to classify."}}