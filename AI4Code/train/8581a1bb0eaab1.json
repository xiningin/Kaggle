{"cell_type":{"4fcb8522":"code","2388e193":"code","93145336":"code","82453e07":"code","d7711397":"code","ad667dd9":"code","0d9851de":"code","a5ccf745":"code","a20d7c1b":"code","351b436f":"code","019056e3":"code","7a92617b":"code","bc64bc09":"code","7ae5b9d0":"code","efe02f0d":"code","602fa5d4":"code","63857ecf":"code","15c5d333":"code","1a840ebb":"code","ab36fcaf":"code","42cd280e":"code","a5435656":"code","fededa70":"code","87f7519f":"code","fea2fd96":"code","c7326bc1":"code","b444d887":"code","a50cec43":"code","100843d9":"code","26b695d4":"code","32e3111b":"code","ac69f43b":"markdown","9b6a270a":"markdown","333f8c1c":"markdown","b5281863":"markdown","f8c5e27b":"markdown","9d09a6bc":"markdown","2f39dc81":"markdown","7325bace":"markdown","eae02da5":"markdown","a6c91676":"markdown","1609772e":"markdown","5bc8f968":"markdown","f0f4a4a7":"markdown","95b57496":"markdown","3fa974a1":"markdown","efd14247":"markdown","3a563cac":"markdown","b1edd1a0":"markdown","437398c8":"markdown","cecfe4ae":"markdown","252ded17":"markdown","a6f0e4d8":"markdown","58cb3565":"markdown","a0a55ad0":"markdown","4e3687c1":"markdown","58fef6b8":"markdown","83bf1a30":"markdown","5c40ae2b":"markdown","ecccecf2":"markdown","09b1abf0":"markdown","d9e33b20":"markdown","ad35e145":"markdown","c626cbeb":"markdown","58d347fd":"markdown","778efd62":"markdown"},"source":{"4fcb8522":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\npd.set_option('display.max_rows',100)\npd.set_option('display.max_columns',500)","2388e193":"cc = pd.read_csv('..\/input\/creditcard.csv')\ncc.head()","93145336":"cc.describe()","82453e07":"cc.dtypes","d7711397":"cc.Class = cc.Class.astype('category')","ad667dd9":"cc.isna().sum()","0d9851de":"cc.Class.value_counts()","a5ccf745":"plt.figure(figsize=(15,10))\ncor = cc.corr()\nsns.heatmap(data=cor)","a20d7c1b":"plt.figure(figsize = (15,5))\n\n# distibution of fraudulent transactions with time\nplt.subplot(1,2,1)\nplt.hist(cc[cc.Class == 1].Time)\nplt.title('Fraudulent Transactions')\nplt.xlabel('Time')\n\n# distibution of non fraudulent transactions with time\nplt.subplot(1,2,2)\nplt.hist(cc[cc.Class == 0].Time)\nplt.title('Non Fraudulent Transactions')\nplt.xlabel('Time')","351b436f":"def stdscaler(a):\n    temp = np.empty(a.shape[0])\n    avg = np.mean(a)\n    dev = np.std(a)\n    for i in range(a.shape[0]):\n        temp[i] = (a[i]-avg)\/dev\n    return temp","019056e3":"temp = stdscaler(cc.Amount.values)\ncc['Amount'] = temp\ncc.drop(['Time'],axis=1,inplace=True)","7a92617b":"i = 1\nplt.figure(figsize=(20,20))\nfor col in cc.columns:\n    plt.subplot(8,4,i)\n    plt.hist(cc[col])\n    plt.xlabel(col)\n    plt.subplots_adjust(hspace = 0.4)\n    i += 1","bc64bc09":"plt.scatter(cc.Class,cc.Amount)","7ae5b9d0":"x_train,x_test,y_train,y_test = train_test_split(cc.loc[:,cc.columns!='Class'],cc.loc[:,'Class'],test_size=0.2,random_state=0)\n","efe02f0d":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0, ratio = 1.0)\nx_train_os,y_train_os = sm.fit_sample(x_train,y_train)","602fa5d4":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=0).fit(x_train_os,y_train_os)\ny_test_probs = lr.predict_proba(x_test)[:,1]\ny_train_probs = lr.predict_proba(x_train)[:,1]","63857ecf":"from sklearn.metrics import precision_recall_curve,auc\nprecision_test,recall_test,thresholds_test = precision_recall_curve(y_test,y_test_probs)\narea_test = auc(recall_test,precision_test)\nprecision_tr,recall_tr,thresholds_tr = precision_recall_curve(y_train,y_train_probs)\narea_tr = auc(recall_tr,precision_tr)\nprint ('Area under precision recall curve for LR model for train set : ',area_tr)\nprint ('Area under precision recall curve for LR model for test set : ',area_test)","15c5d333":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(random_state=0).fit(x_train_os,y_train_os)\ny_test_probs = tree.predict_proba(x_test)[:,1]\ny_train_probs = tree.predict_proba(x_train)[:,1]","1a840ebb":"from sklearn.metrics import precision_recall_curve,auc\nprecision_test,recall_test,thresholds_test = precision_recall_curve(y_test,y_test_probs)\narea_test = auc(recall_test,precision_test)\nprecision_tr,recall_tr,thresholds_tr = precision_recall_curve(y_train,y_train_probs)\narea_tr = auc(recall_tr,precision_tr)\nprint ('Area under precision recall curve for tree model for train set : ',area_tr)\nprint ('Area under precision recall curve for tree model for test set : ',area_test)","ab36fcaf":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(random_state=0).fit(x_train_os,y_train_os)\ny_test_probs = forest.predict_proba(x_test)[:,1]\ny_train_probs = forest.predict_proba(x_train)[:,1]","42cd280e":"from sklearn.metrics import precision_recall_curve,auc\nprecision_test,recall_test,thresholds_test = precision_recall_curve(y_test,y_test_probs)\narea_test = auc(recall_test,precision_test)\nprecision_tr,recall_tr,thresholds_tr = precision_recall_curve(y_train,y_train_probs)\narea_tr = auc(recall_tr,precision_tr)\nprint ('Area under precision recall curve for RF model for train set : ',area_tr)\nprint ('Area under precision recall curve for RF model for test set : ',area_test)","a5435656":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier().fit(x_train_os,y_train_os)\ny_test_probs = knn.predict_proba(x_test)[:,1]\ny_train_probs = knn.predict_proba(x_train)[:,1]","fededa70":"from sklearn.metrics import precision_recall_curve,auc\nprecision_test,recall_test,thresholds_test = precision_recall_curve(y_test,y_test_probs)\narea_test = auc(recall_test,precision_test)\nprecision_tr,recall_tr,thresholds_tr = precision_recall_curve(y_train,y_train_probs)\narea_tr = auc(recall_tr,precision_tr)\nprint ('Area under precision recall curve for RF model for train set : ',area_tr)\nprint ('Area under precision recall curve for RF model for test set : ',area_test)","87f7519f":"import tensorflow\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras import regularizers\nnp.random.seed(0)\n\n# create neural network model with drop out regularisation and 2 hidden layers\nnn = Sequential()\nnn.add(Dense(x_train_os.shape[1],input_dim = x_train_os.shape[1],activation='relu'))\n#nn.add(Dropout(0.1))\nnn.add(Dense(20,activation='relu'))\nnn.add(Dropout(0.2))\nnn.add(Dense(10,activation='relu'))\n#nn.add(Dropout(0.1))\nnn.add(Dense(1,activation='sigmoid'))\n\n# compile model\nnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# fit model\nnn.fit(x_train_os,y_train_os,epochs=150,batch_size=10000,verbose=0)\n\ny_test_probs = nn.predict(x_test)\ny_train_probs = nn.predict(x_train)","fea2fd96":"from sklearn.metrics import precision_recall_curve,auc\nprecision_test,recall_test,thresholds_test = precision_recall_curve(y_test,y_test_probs)\narea_test = auc(recall_test,precision_test)\nprecision_tr,recall_tr,thresholds_tr = precision_recall_curve(y_train,y_train_probs)\narea_tr = auc(recall_tr,precision_tr)\nprint ('Area under precision recall curve for NN model for train set : ',area_tr)\nprint ('Area under precision recall curve for NN model for test set : ',area_test)","c7326bc1":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer","b444d887":"def auprc(y_test,y_probs):\n    precision,recall,thresholds = precision_recall_curve(y_test,y_probs)\n    return auc(recall,precision)\n\ncv_scorer = make_scorer(auprc)","a50cec43":"# choose hyperparameter value space\nestimators = [int(x) for x in np.linspace(200,500,num = 4)]\ndepths = [int(x) for x in np.linspace(25,100,num = 4)]\ndepths.append(None)\n\n# define parameter grid\nparam_grid2 = {\"n_estimators\": estimators,\n               \"max_depth\" : depths}\n\n# parameter tuning for model predicting casual cnt\nmodel_tuned = RandomForestClassifier(random_state=0)\ngrid_search_model = GridSearchCV(model_tuned,param_grid=param_grid2,scoring=cv_scorer,cv=3,n_jobs=-1)\ngrid_search_model.fit(x_train_os, y_train_os)","100843d9":"print ('Best params for RF model : ',grid_search_model.best_params_)\nprint ('Best AUPRC for RF model : ',grid_search_model.best_score_)","26b695d4":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators = grid_search_model.best_params_['n_estimators'],\n                                max_depth = grid_search_model.best_params_['max_depth'],\n                                random_state=0).fit(x_train_os,y_train_os)\ny_test_probs = forest.predict_proba(x_test)[:,1]\ny_train_probs = forest.predict_proba(x_train)[:,1]","32e3111b":"from sklearn.metrics import precision_recall_curve,auc\nprecision_test,recall_test,thresholds_test = precision_recall_curve(y_test,y_test_probs)\narea_test = auc(recall_test,precision_test)\nprecision_tr,recall_tr,thresholds_tr = precision_recall_curve(y_train,y_train_probs)\narea_tr = auc(recall_tr,precision_tr)\nprint ('Area under precision recall curve for RF model for train set : ',area_tr)\nprint ('Area under precision recall curve for RF model for test set : ',area_test)","ac69f43b":"#### **COMMENT** : Since the data is highly class imbalanced, we will have to oversample the data. Here SMOTE technique has been used to oversample the data as it proves to be the most effective one.","9b6a270a":"### **Model Selection**","333f8c1c":"#### **Distribution of all independent variables**","b5281863":"#### **Exploring time as a lever**","f8c5e27b":"#### **Check correlation between independent variables**","9d09a6bc":"### **Data exploration**","2f39dc81":"#### **MODEL 1** : Training a logistic regression model","7325bace":"### **Preparing the dataset**","eae02da5":"#### **Evaluation performance of NN Classifier using AUPRC**","a6c91676":"#### **Evaluation performance of Random Forest using AUPRC**","1609772e":"#### **COMMENT** : Since there is no specific different pattern of faudulent transactions with time, that shows fraud transcations aren't time dependent. Thus time won't play any role in determining if a transaction is fraud transaction.","5bc8f968":"#### **Evaluation performance of Decision Tree using AUPRC**","f0f4a4a7":"#### **Fine tuning the RF model using Grid Search CV using 3 set cross validation**","95b57496":"#### **COMMENT** : Since all variables are results of PCA and thus standardised, we will need to standardise 'Amount' as well","3fa974a1":"#### **MODEL 2** : Training a decision tree model","efd14247":"#### **COMMENT** : No missing values","3a563cac":"#### **MODEL 5** : Training a neural network classifier","b1edd1a0":"#### **COMMENT** :  Since class is a categorical variable, let's convert it into class 'category'","437398c8":"#### **COMMENT** : LR model has very high bias on both training and test sets but low variance.","cecfe4ae":"### **Import necessary libraries**","252ded17":"#### **Check for any missing data**","a6f0e4d8":"### **Read the data**","58cb3565":"#### **COMMENT** : Least bias and least overfitting","a0a55ad0":"#### **COMMENT** : Highly class imbalanced data","4e3687c1":"#### **COMMENT** : Perfectly uncorrelated dataset","58fef6b8":"#### **MODEL 4** : Training a KNN Classifier","83bf1a30":"### **Evaluation Metric** : Since the data we have is highly class imbalanced, thus we will use area under precision recall curve to evaluate the models' performances","5c40ae2b":"#### **COMMENT** : Tree has very low bias but overfitting much more than LR ","ecccecf2":"#### **Split into train and test data**","09b1abf0":"#### **Evaluation performance of LR using AUPRC**","d9e33b20":"#### **Training the RF model using best params**","ad35e145":"#### **Evaluation performance of best Random Forest model using AUPRC**","c626cbeb":"#### **COMMENT** : Clearly, variable amount has a few outliers. We are not gonna remove outliers here since they might give us important insights about the transaction being fraudulent or not.","58d347fd":"#### **Evaluation performance of KNN Classifier using AUPRC**","778efd62":"#### **MODEL 3** : Training a Random Forest Model"}}