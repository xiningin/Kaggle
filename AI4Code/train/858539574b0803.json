{"cell_type":{"ab3169d9":"code","2f41715b":"code","e48b017a":"code","9f5c9ce0":"code","ef06f4e4":"code","870cb39a":"code","ebe7aaa2":"code","e25debe2":"code","d1e7b204":"code","5343fcb3":"code","01f9bf14":"code","8537a909":"code","d2d128dd":"code","d52fb7f9":"code","080cde83":"code","37950845":"code","f199fe8b":"code","e8fd93ef":"code","2ddd275a":"code","a25e0c73":"code","b32bab8b":"code","9f7495d2":"code","ea556c0a":"code","d5353ac2":"code","44b0ad8e":"code","034c4476":"code","98d5fbd6":"code","d03c35b4":"code","25b1992f":"code","adf1aec8":"code","aba616dc":"code","c841432a":"code","2a823ff9":"code","a5915b3e":"code","3d263a41":"code","51a96ec6":"code","ae8e4dd7":"code","9e771592":"code","09de4f06":"code","78efa403":"code","aab896d7":"code","81ad4293":"code","4f1512a1":"code","5411b24c":"code","25f07cc2":"code","fc61be17":"code","458be8b8":"code","8f6103b6":"code","80b2f65b":"code","7a838c58":"code","a67344e7":"code","a70ba9ad":"code","ebf891b3":"code","800684ca":"markdown","de886660":"markdown","c245fc04":"markdown","3d65455d":"markdown","2f0038a4":"markdown","9e7c996c":"markdown","b7f37ab1":"markdown","04739678":"markdown","cf6fb098":"markdown","d3ba5797":"markdown","eb4bd627":"markdown","12f1815f":"markdown","1b5ee57f":"markdown","8779d5a8":"markdown","46c96a02":"markdown","7a92f48c":"markdown","0ad942c1":"markdown","b974fd9e":"markdown","a1b106ef":"markdown","385dcc7a":"markdown","33218616":"markdown","de7168e4":"markdown","c7c410a8":"markdown","0774b281":"markdown","5bc6b778":"markdown","fc0bbcdc":"markdown","c8f148b0":"markdown","40012007":"markdown","1a45bbe4":"markdown","c91f36e1":"markdown","d7a55687":"markdown","f91701e8":"markdown","104eb562":"markdown","80c1a38b":"markdown","7ff07a97":"markdown","38af7715":"markdown","99295965":"markdown","dcdbed82":"markdown","dc8f8530":"markdown","26055924":"markdown","58b98256":"markdown","73e3ae2b":"markdown","844a706f":"markdown","014311d5":"markdown","4740f620":"markdown","2c41d444":"markdown","701f9542":"markdown","f9e78e31":"markdown","96a2e290":"markdown","d2bfa995":"markdown","2f3cbf8c":"markdown","cee5cd85":"markdown","2a74af4a":"markdown","7bd2f5d1":"markdown","eafb0d7c":"markdown"},"source":{"ab3169d9":"# Suppress warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom IPython.display import HTML\n\n\nHTML('<iframe width=\"1280\" height=\"720\" src=\"https:\/\/www.youtube.com\/embed\/cP9gOrNssOA\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')\n\n","2f41715b":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n# This Python 3 environment comes with many helpful analytics libraries installed\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas import read_excel\n\n\npd.set_option('max_columns', 6000)","e48b017a":"# Installing the factor_analyzer library to test factor analysis.\n!pip install factor_analyzer\n","9f5c9ce0":"# import factor analyzer library\nfrom factor_analyzer import FactorAnalyzer\n\n# import hierarchical clustering libraries\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, precision_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import preprocessing\nfrom sklearn.metrics import silhouette_score\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.metrics import multilabel_confusion_matrix # interresting approach for multilabel\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, recall_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom numpy import mean, std\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","ef06f4e4":"file_name = '\/kaggle\/input\/ibopedtm\/Case - Data Science IBOPE.XLS'\nsheet_name = 'Informa\u00e7\u00f5es_Municipais'\ndf_ibope = read_excel(file_name, sheet_name=sheet_name, header=3)\ndf_ibope = df_ibope.drop(['C\u00f3digo'], 1)\ndf_ibope = df_ibope.set_index('Munic\u00edpio')","870cb39a":"df_ibope.rename(columns={'\u00c1rea (km\u00b2)':'\u00c1rea (km\u00b2)', 'Densidade demogr\u00e1fica, 2000':'Demographic density, 2000', 'Dist\u00e2ncia \u00e0 capital (km)':'Distance to capital (km)',\n       'Esperan\u00e7a de vida ao nascer, 2000':'Life expectancy at birth, 2000',\n       'Mortalidade at\u00e9 um ano de idade, 2000':'Mortality to one year old, 2000',\n       'Taxa de fecundidade total, 2000':'Total fertility rate, 2000',\n       'Percentual de pessoas de 25 anos ou mais analfabetas, 2000':'Percentage of people aged 25 and over who are illiterate, 2000',\n       'Renda per Capita, 2000':'Income per Capita, 2000', '\u00cdndice de Gini, 2000':'Gini Index, 2000',\n       'Intensidade da indig\u00eancia, 2000':'Intensity of indigence, 2000', 'Intensidade da pobreza, 2000':'Intensity of poverty, 2000',\n       '\u00cdndice de Desenvolvimento Humano Municipal, 2000':'Municipal Human Development Index, 2000',\n       'Taxa bruta de freq\u00fc\u00eancia \u00e0 escola, 2000':'Gross school attendance rate, 2000',\n       'Taxa de alfabetiza\u00e7\u00e3o, 2000':'Literacy rate, 2000',\n       'M\u00e9dia de anos de estudo das pessoas de 25 anos ou mais de idade, 2000':'Average years of schooling for people aged 25 or over, 2000',\n       'Popula\u00e7\u00e3o de 25 anos ou mais de idade, 1991':'Population aged 25 or over, 1991',\n       'Popula\u00e7\u00e3o de 25 anos ou mais de idade, 2000':'Population aged 25 or over, 2000',\n       'Popula\u00e7\u00e3o de 65 anos ou mais de idade, 1991':'Population aged 65 and over, 1991',\n       'Popula\u00e7\u00e3o de 65 anos ou mais de idade, 2000':'Population aged 65 and over, 2000', 'Popula\u00e7\u00e3o total, 1991':'Total population, 1991',\n       'Popula\u00e7\u00e3o total, 2000':'Total population, 2000', 'Popula\u00e7\u00e3o urbana, 2000':'Urban population, 2000',\n       'Popula\u00e7\u00e3o rural, 2000':'Rural population, 2000'}, inplace=True)","ebe7aaa2":"print(\"Data Description\", df_ibope.shape)","e25debe2":"total = df_ibope.isnull().sum().sort_values(ascending = False)\npercent = (df_ibope.isnull().sum()\/df_ibope.isnull().count()*100).sort_values(ascending = False)\nmissing_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","d1e7b204":"df_ibope.dtypes.value_counts()","5343fcb3":"features = df_ibope.columns.values[1:11]\nunique_max = []\nfor feature in features:\n    values = df_ibope[feature].value_counts()\n    unique_max.append([feature, values.max(), values.idxmax()])\nnp.transpose((pd.DataFrame(unique_max, columns=['Feature', 'Max duplicates', 'Value'])).\\\n            sort_values(by = 'Max duplicates', ascending=False).head(10))    ","01f9bf14":"df_ibope.head()","8537a909":"\n# =============================Factor Analysis==================================\n\n# Plot correlation matrix of indicators\nplt.figure(figsize=(25,50))\nsubjective_corr = df_ibope.corr()\nplt.figure(figsize=(20, 14))\nsns.heatmap(subjective_corr,\n            vmin=-1,\n            cmap='coolwarm',\n            annot=True);","d2d128dd":"\ndef plot_corr_municipio(municipio_name):\n    plt.figure(figsize=(10,16))\n    subjective_corr = df_ibope.T.corr()\n    sns.heatmap(subjective_corr[[municipio_name]].sort_values(by=[municipio_name],ascending=False));\n    \nplot_corr_municipio('S\u00e3o Paulo (SP)')","d52fb7f9":"from factor_analyzer.factor_analyzer import calculate_kmo\nkmo_all,kmo_model=calculate_kmo(df_ibope)\nkmo_model","080cde83":"\nfa = FactorAnalyzer()\nfa.fit(df_ibope, 10)\n\nev , v = fa.get_eigenvalues()\n\nev_df = pd.DataFrame(ev, columns=['Original_Eigenvalues'])\n\nprint('factors eigenvalues that are greater than one.  ', ev_df[ev_df['Original_Eigenvalues']>=1.0].shape[0])\nev_df","37950845":"# Create scree plot using matplotlib\nplt.figure(figsize=(25,10))\nplt.scatter(range(1,df_ibope.shape[1]+1),ev)\nplt.plot(range(1,df_ibope.shape[1]+1),ev)\nplt.hlines(1, 0, df_ibope.shape[1], colors='r')\nplt.title('Scree Plot')\nplt.xlabel('Factors')\nplt.ylabel('Eigenvalue')\nplt.grid()\nplt.show()\n","f199fe8b":"# Perform Factor Analysis\nfa = FactorAnalyzer(n_factors=4, rotation='varimax')\nfa.fit(df_ibope)\nloads = fa.loadings_\nloads = pd.DataFrame(loads, index=df_ibope.T.index)","e8fd93ef":"def color_factor_importance(val):\n    if np.abs(val) > 0.75:\n        color = 'green'\n    elif np.abs(val) > 0.5 and np.abs(val) <= 0.75:\n        color = 'blue'\n    else: \n        color = 'red'\n    return 'color: %s' % color\n\nloads.style.applymap(color_factor_importance)\n","2ddd275a":"communalities = fa.get_communalities()\ncommunalities = pd.DataFrame(communalities, index=df_ibope.T.index, columns=['communalities'])\ncommunalities.sort_values(by=['communalities'], ascending=True).head(8)","a25e0c73":"#Heatmap of loadings\nplt.figure(figsize=(30,25))\nsns.heatmap(loads, annot=True, cmap=\"YlGnBu\")","b32bab8b":"from sklearn.cluster import KMeans\n\n#=============================Cluster Analysis KMeans=================================\nwcss=[]\nfor i in range(1,21):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=42)\n    kmeans.fit(df_ibope)\n    wcss.append(kmeans.inertia_)","9f7495d2":"\nplt.figure(figsize=(25,10))\nplt.plot(range(1,21), wcss)\nplt.hlines(1, 0, df_ibope.shape[1], colors='r')\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","ea556c0a":"#Model Build\nkmeansmodel = KMeans(n_clusters= 4, init='k-means++', random_state=42)\ny_kmeans= kmeansmodel.fit_predict(df_ibope)\ndf_ibope['kmeans_cluster'] = y_kmeans","d5353ac2":"df_ibope['kmeans_cluster'].value_counts()","44b0ad8e":"df_ibope[df_ibope['kmeans_cluster']==1].reset_index()['Munic\u00edpio'].values.tolist() , df_ibope[df_ibope['kmeans_cluster']==3].reset_index()['Munic\u00edpio'].values.tolist()","034c4476":"\ndf_final_T = df_ibope\ndf_final_T.sort_values(\"kmeans_cluster\", inplace = True, ascending=True)\n# standardization along columns\ndf_final_std_ =(df_ibope-df_ibope.mean())\/df_ibope.std()\ndf_final_std_['kmeans_cluster'] = y_kmeans\ndf_final_std_.sort_values(\"kmeans_cluster\", inplace = True, ascending=True)\n\ndf_cluster_ = df_final_T.groupby('kmeans_cluster').mean()\ndf_cluster_std_ = df_final_std_.groupby('kmeans_cluster').mean()\n","98d5fbd6":"\n# drop single cluster\ndf_ibope = df_ibope[df_ibope['kmeans_cluster']!=1][df_ibope['kmeans_cluster']!=3]\ndf_final_T = df_ibope\ndf_ibope.shape","d03c35b4":"df_cluster_std_ = df_cluster_std_[df_cluster_std_.reset_index()['kmeans_cluster']!=1][df_cluster_std_.reset_index()['kmeans_cluster']!=3]","25b1992f":"df_ibope[df_ibope['kmeans_cluster']==0]['Income per Capita, 2000'].mean(), df_ibope[df_ibope['kmeans_cluster']==0]['Income per Capita, 2000'].std()","adf1aec8":"df_ibope[df_ibope['kmeans_cluster']==2]['Income per Capita, 2000'].mean(), df_ibope[df_ibope['kmeans_cluster']==2]['Income per Capita, 2000'].std()","aba616dc":"df_final_T.loc[df_final_T['kmeans_cluster'] ==2, 'kmeans_cluster'] =1","c841432a":"from sklearn.model_selection import train_test_split\n\ny = df_final_T['kmeans_cluster'].copy()\nX = df_final_T.copy()\nX.drop(columns='kmeans_cluster', inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n\nprint(\"y_train values \", y_train.value_counts())\nprint(\"y_test values \", y_test.value_counts())\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n","2a823ff9":"def evaluate_model(X, y, model):\n    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    return scores\n\nmodel = RandomForestClassifier(n_estimators=10)","a5915b3e":"model.fit(X_train, y_train)\nclf_prediction = model.predict(X_test)\nmulti_cfs_matrix = confusion_matrix(y_test, clf_prediction)\n # multilabel_confusion_matrix(y_test, clf_prediction)\n\nprint ('Acc:', accuracy_score(y_test, clf_prediction))\nprint ('F1 score:', f1_score(y_test, clf_prediction,average='weighted'))\nprint ('Sensitivity, recall:', recall_score(y_test, clf_prediction,\n                              average='weighted'))\nprint ('Precision:', precision_score(y_test, clf_prediction,\n                                    average='weighted'))\nprint ('\\n Classification report:\\n', classification_report(y_test, clf_prediction))\nprint ('\\n Confusion matrix:\\n',multi_cfs_matrix)\n","3d263a41":"\nreg_model = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train)\nscores = evaluate_model(X_train, y_train, reg_model)\n# summarize performance\nprint('AVG Accu: %.3f (%.3f)' % (mean(scores), std(scores)))\n","51a96ec6":"pred_OneVsRest = reg_model.predict(X_test)\nmulti_cfs_matrix = confusion_matrix(y_test, pred_OneVsRest)\nprint(multi_cfs_matrix)\nprint ('Acc:', accuracy_score(y_test, pred_OneVsRest))\nprint ('F1 score:', f1_score(y_test, clf_prediction,average='weighted'))\nprint ('Sensitivity, recall::', recall_score(y_test, pred_OneVsRest,\n                              average='weighted'))\nprint ('Precision:', precision_score(y_test, pred_OneVsRest,\n                                    average='weighted'))\nprint ('\\n Report Classification:\\n', classification_report(y_test, pred_OneVsRest))\nprint ('\\n Confussion Matrix:\\n',multi_cfs_matrix)\n","ae8e4dd7":"reg_oneVsone_prediction = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X_train, y_train)\nscores = evaluate_model(X_train, y_train, reg_oneVsone_prediction)\n# summarize performance\nprint('Acc avg: %.3f (%.3f)' % (mean(scores), std(scores)))\n","9e771592":"reg_predOneVsOne = reg_oneVsone_prediction.predict(X_test)\nmulti_cfs_matrix = confusion_matrix(y_test, reg_predOneVsOne)\n\n\nprint ('Acc:', accuracy_score(y_test, reg_predOneVsOne))\nprint ('F1 score:', f1_score(y_test, reg_predOneVsOne,average='weighted'))\nprint ('Recall:', recall_score(y_test, reg_predOneVsOne,\n                              average='weighted'))\nprint ('Precision:', precision_score(y_test, reg_predOneVsOne,\n                                    average='weighted'))\nprint ('\\n Classification report:\\n', classification_report(y_test, reg_predOneVsOne))\nprint ('\\n Confusion Matriz:\\n',multi_cfs_matrix)\n","09de4f06":"\nlist_recall = [recall_score(y_test, clf_prediction,average='weighted'),\n                     recall_score(y_test, reg_predOneVsOne,average='weighted'),\n                     recall_score(y_test, pred_OneVsRest,average='weighted')]\nperformance = pd.DataFrame(list_recall, columns=['Sensitivity\/Recall'])\n","78efa403":"colors = [\"purple\", \"green\", \"orange\"]\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel(\"Sensitivity\/Recall %\")\nplt.xlabel(\"Alg.\")\nplt.xticks(rotation=45)\nsns.barplot(x=list(['Random Forest', 'Reg. OneVsOne', 'Reg. OneVsRest']), y=list(performance['Sensitivity\/Recall']), palette=colors)\nplt.show()\n","aab896d7":"df_ibope[df_ibope['kmeans_cluster']==0][['Municipal Human Development Index, 2000', 'Literacy rate, 2000']].reset_index().sort_values(by=['Municipal Human Development Index, 2000', 'Literacy rate, 2000'],ascending=False).head(10)","81ad4293":"plt.figure(figsize=(16,5))\n\nplt.scatter(x = df_ibope[df_ibope['kmeans_cluster']==0]['Municipal Human Development Index, 2000'] ,y = df_ibope[df_ibope['kmeans_cluster']==0]['Literacy rate, 2000'], color = \"gray\", label=\"Cluster 0\" )\nplt.scatter(x = df_ibope[df_ibope['kmeans_cluster']==1]['Municipal Human Development Index, 2000'] ,y = df_ibope[df_ibope['kmeans_cluster']==1]['Literacy rate, 2000'], color = \"purple\", label=\"Cluster 1\" )\nplt.legend()\n\n","4f1512a1":"plt.figure(figsize=(16,5))\n\nplt.scatter(x = df_ibope[df_ibope['kmeans_cluster']==0]['Municipal Human Development Index, 2000'] ,y = df_ibope[df_ibope['kmeans_cluster']==0]['Income per Capita, 2000'], color = \"gray\", label=\"Cluster 0\" )\nplt.scatter(x = df_ibope[df_ibope['kmeans_cluster']==1]['Municipal Human Development Index, 2000'] ,y = df_ibope[df_ibope['kmeans_cluster']==1]['Income per Capita, 2000'], color = \"purple\", label=\"Cluster 1\" )\nplt.legend()\n\n","5411b24c":"##### **Factor 0** Most Populated Municipalities by adults mostly \n\ndef score_factor0( cluster):\n    df_ibope['score_factor0_cluster'+str(cluster)] = df_ibope[df_ibope['kmeans_cluster']==cluster]['Population aged 25 or over, 1991'] *loads.T['Population aged 25 or over, 1991'][0] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Population aged 25 or over, 2000']  *loads.T['Population aged 25 or over, 2000'][0] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Population aged 65 and over, 1991']  *loads.T['Population aged 65 and over, 1991'][0] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Population aged 65 and over, 2000']  *loads.T['Population aged 65 and over, 2000'][0] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Total population, 1991']  *loads.T['Total population, 1991'][0] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Total population, 2000']  *loads.T['Total population, 2000'][0] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Urban population, 2000']  *loads.T['Urban population, 2000'][0] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Rural population, 2000']  *loads.T['Rural population, 2000'][0]\n\nscore_factor0(0)     \nscore_factor0(1)    ","25f07cc2":"##### **Factor1 ** Developed Municipalities \n\ndef score_factor1( cluster):\n    df_ibope['score_factor1_cluster'+str(cluster)] = df_ibope[df_ibope['kmeans_cluster']==cluster]['Life expectancy at birth, 2000'] * loads.T['Life expectancy at birth, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Mortality to one year old, 2000'] * loads.T['Mortality to one year old, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Total fertility rate, 2000'] * loads.T['Total fertility rate, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Percentage of people aged 25 and over who are illiterate, 2000'] * loads.T['Percentage of people aged 25 and over who are illiterate, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Income per Capita, 2000'] * loads.T['Income per Capita, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Intensity of poverty, 2000'] * loads.T['Intensity of poverty, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Municipal Human Development Index, 2000'] * loads.T['Municipal Human Development Index, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Literacy rate, 2000'] * loads.T['Literacy rate, 2000'][1] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Average years of schooling for people aged 25 or over, 2000'] * loads.T['Average years of schooling for people aged 25 or over, 2000'][1]\nscore_factor1(0)       \nscore_factor1(1)","fc61be17":"def score_factor2( cluster):\n    df_ibope['score_factor2_cluster'+str(cluster)] = df_ibope[df_ibope['kmeans_cluster']==cluster]['Intensity of indigence, 2000'] * loads.T['Intensity of indigence, 2000'][2] \\\n    + df_ibope[df_ibope['kmeans_cluster']==cluster]['Intensity of poverty, 2000'] * loads.T['Intensity of poverty, 2000'][2]\nscore_factor2(0)       \nscore_factor2(1)","458be8b8":"def score_factor3( cluster):\n    df_ibope['score_factor3_cluster'+str(cluster)] = df_ibope[df_ibope['kmeans_cluster']==cluster]['\u00c1rea (km\u00b2)'] * loads.T['\u00c1rea (km\u00b2)'][3]\n      \nscore_factor3(0)       \nscore_factor3(1)","8f6103b6":"df_ibope[['score_factor0_cluster0' ]].reset_index().sort_values(by=['score_factor0_cluster0','Munic\u00edpio'],ascending=False).head(5)\n","80b2f65b":"df_ibope[['score_factor0_cluster1' ]].reset_index().sort_values(by=['score_factor0_cluster1','Munic\u00edpio'],ascending=False).head(5)\n","7a838c58":"df_ibope[['score_factor1_cluster0' ]].reset_index().sort_values(by=['score_factor1_cluster0','Munic\u00edpio'],ascending=False).head(5)\n","a67344e7":"df_ibope[['score_factor1_cluster1' ]].reset_index().sort_values(by=['score_factor1_cluster1','Munic\u00edpio'],ascending=False).head(5)\n","a70ba9ad":"df_ibope[['score_factor2_cluster0' ]].reset_index().sort_values(by=['score_factor2_cluster0','Munic\u00edpio'],ascending=False).head(5)\n","ebf891b3":"df_ibope[['score_factor2_cluster1' ]].reset_index().sort_values(by=['score_factor2_cluster1','Munic\u00edpio'],ascending=False).head(5)\n","800684ca":"### References\n- https:\/\/www.kaggle.com\/shrutimechlearn\/step-by-step-kmeans-explained-in-detail\n- https:\/\/www.datacamp.com\/community\/tutorials\/introduction-factor-analysis\n- https:\/\/devopedia.org\/factor-analysis\n- https:\/\/towardsdatascience.com\/factor-analysis-a-complete-tutorial-1b7621890e42\n- https:\/\/en.wikipedia.org\/wiki\/Factor_analysis#\n","de886660":"# Factor Analysis\nCONDUCTING FACTOR ANALYSIS\n- PROBLEM FORMULATION\n    - Classify Brazilian municipalities based on the available information \n    - Develop a classification model to calculate the probability that a given municipality belongs to one of the groups created.\n- CONSTRUCTION OF CORRELATION MATRIX\n- METHOD OF FACTOR ANALYSIS\n- DETERMINATION OF NUMBER OF FACTORS\n- ROTATION OF FACTORS\n- INTERPRETATION OF FACTORS\n    -  Interpret Factors(A factor can be interpreted in terms of the variables that load high on it. )","c245fc04":"# Highest scores on **Factor 2** Least Developed Municipalities per cluster.","3d65455d":"##### Choosing the right K\nThe way to evaluate the choice of K is made using a parameter known as WCSS. WCSS stands for Within Cluster Sum of Squares. It should be low. Here's the formula representation for example when K = 3\n\nSummation Distance(p,c) is the sum of distance of points in a cluster from the centroid.\n![](https:\/\/i.imgur.com\/5W63xul.png)\n\nThe Elbow Method is then used to choose the best K value. \nViewing the ELBOW method to obtain the ideal K value (clusters, which is 4)","2f0038a4":"### Top 10 Municipalities of the clusters with the best Municipal Human Development Index by Literacy Rate, 2000.","9e7c996c":"### Top 10 Municipalities of clusters with the best Municipal Human Development Index by Income per capita.\n\nCluster 0 concentrates the highest average of Municipalities with per capita income. Let's look at which Municipalities have the highest per capita income.","b7f37ab1":"# Correlations\nNow that we have dealt with the categorical variables and the outliers, let's continue with the EDA. One way to try and understand the data is by looking for correlations between the features and the target. We can calculate the Pearson correlation coefficient between every variable and the target using the .corr dataframe method.\n\nThe correlation coefficient is not the greatest method to represent \"relevance\" of a feature, but it does give us an idea of possible relationships within the data. Some [general interpretations of the absolute value of the correlation coefficent are](http:\/\/www.statstutor.ac.uk\/resources\/uploaded\/pearsons.pdf):\n\n- .00-.19 \u201cvery weak\u201d\n- .20-.39 \u201cweak\u201d\n- .40-.59 \u201cmoderate\u201d\n- .60-.79 \u201cstrong\u201d\n- .80-1.0 \u201cvery strong\u201d","04739678":"### Checking missing data in train\nnumber and percentage of missing values in each column.","cf6fb098":"# OneVsOneClassifier\n","d3ba5797":"### Duplicate values\nLet's now check how many duplicate values exists per columns.\n","eb4bd627":"#### Simple approachs\nThe Random Forest Classifier proved to be the best approach to classify clusters.","12f1815f":"# Case - Retail \n![](https:\/\/industrywired.com\/wp-content\/uploads\/2020\/02\/How_Supply-Chain-Automation-Affects-Retail-Industry.jpg)\n[source:](https:\/\/industrywired.com\/how-supply-chain-automation-affects-retail-industry\/)\n\nSlides Presentation: [Kaggle Days Meetup Delhi NCR- CaesarLupum](https:\/\/docs.google.com\/presentation\/d\/e\/2PACX-1vTA0kAKbN7BsweHXIZaeaTwdF2ySpgCb-Hy_b3dEA4eq7Txso3bRx2n2c_bCBOzlbOWb1kqxUmGfyD1\/pub?start=false&loop=false&delayms=3000)\n\n\n### You are responsible for the analysis that will serve as a foundation for the strategy of entering the Brazilian market of a large multinational retailer in the supermarket sector. \n* TASK 1 - Classify Brazilian municipalities based on the available information \n* TASK 2 - Develop a classification model to calculate the probability that a given municipality belongs to one of the groups created.\n* Which groups of municipalities should be the gateway to a company in the country? Why?\n\n","1b5ee57f":"Factor with values >0.75, factor loading its 'High'","8779d5a8":"### Adequacy Test\n\nBefore you perform factor analysis, you need to evaluate the \u201cfactorability\u201d of our dataset. Factorability means \"can we found the factors in the dataset?\". There are two methods to check the factorability or sampling adequacy:\n\n- Bartlett\u2019s Test\n- Kaiser-Meyer-Olkin Test","46c96a02":"# Interpretation of clusters","7a92f48c":"- step 1: Labeling data with Cluster Approach  ->  step 2: Validation of Classification  ->  step 2.2: Use FA scores for interpret new classification entries.\n-                              ```step 1: Labeling data with Cluster Approach  ->  step 1.1: Apply FA in entire data  ->  step 1.2: Use FA scores for interpret clusters\n``` \n\n\n\n","0ad942c1":"### Result of clustering\n4 clusters.","b974fd9e":"note:\n\n- The Gini Index - also known as the Gini Coefficient - is a mathematical instrument used to measure the social inequality of a given country, federative unit or municipality.\n- Intensity of indigence - identifies the poor as those who live in extreme poverty","a1b106ef":"### Choosing the Number of Factors\nFor choosing the number of factors, you can use the Kaiser criterion and scree plot. Both are based on eigenvalues","385dcc7a":"# Graph with the results generated from the models.\nThe following is a graph showing the sensitivity of each model presented, the best result was the Random Forest.","33218616":"# Classification Model\nWe use the labels of each cluster and will apply algorithms to generate probabilities and classify Municipalities into clusters.\n\nsimple pipeline-  simple classification modeling for our retail case.","de7168e4":"## Meetup #17 || Applying Factor Analysis in Classification Problems","c7c410a8":"# Final Report\n\n###  Which groups of municipalities should be the gateway to a company in the country? Why?\n\n\n##### **Factor 0** Most Populated Municipalities by adults mostly .\n##### **Factor1 ** Developed Municipalities.\n We want to choose hifg scores for factor 0,1. \n       \n##### **Factor 2** Less Developed Municipalities - Municipalities with high factor score for this factor can be indicative of not choose for the company.\n\nSome good choices:\n\n- Salvador (BA), Belo Horizonte (MG), Fortaleza (CE)\n\n\n- \u00c1guas de S\u00e3o Pedro (SP), S\u00e3o Caetano do Sul (SP), Niter\u00f3i (RJ), Santana de Parna\u00edba (SP), Santos (SP)\t\n","0774b281":"The score is created based on the value of the variables in the factor * (factor loads).\n\n- Score of **Factor 0** Most Populated Municipalities by adults mostly\n- Score of **Factor1** Developed Municipalities\n\n- Score of **Factor 2** Less Developed Municipalities\n- Score of **Factor 3** Municipalities far from the capital and \/ or with a large territorial extension and \/ or with a large area km (** 2)","5bc6b778":"#  Calculate Factor Scores\n\nThe factor scores for the i th factor may be estimated as follows:\n\u00a0\nFi = Wi1 X1 + Wi2 X2 + Wi3 X3 + . . . + Wik Xk","fc0bbcdc":"# Import libs","c8f148b0":"# Graph with factorial loads\n\nNow we make an interpretation of each of the generated factors, we observe the values of the factor loads, in the graph we can see that the **Factor 0** has 8 variables with values above abs (50%), whereas **Factor 1** has 9 latent variables above abs (60%), ***Factor 2** has 2 variables above abs (60%) and the **Factor 3** has 1 variable above abs (50%).\n\n\nWe will give an interpretation of each factor based on the highest values of the factor loads in each factor, we will consider values above abs (50%).\n\nnote: (hard work rename the factors)\nSo we have:\n\n##### **Factor 0** Most Populated Municipalities by adults mostly - with variables\n\n- Population aged 25 or over, 1991\n- Population aged 25 or over, 2000\n- Population aged 65 and over, 1991\n- Population aged 65 and over, 2000\n- Total population, 1991\n- Total population, 2000\n- Urban population, 2000\n- Rural population, 2000\n\n##### **Factor1 ** Developed Municipalities - with variables\n\n- Life expectancy at birth, 2000\n- Mortality to one year old, 2000\n- Total fertility rate, 2000\n- Percentage of people aged 25 and over who are illiterate, 2000\n- Income per Capita, 2000\n- Intensity of poverty, 2000\n- Municipal Human Development Index, 2000\n- Literacy rate, 2000\n- Average years of schooling for people aged 25 or over, 2000\n\n\n       \n##### **Factor 2** Less Developed Municipalities - with variables\n\n- Intensity of indigence, 2000\n- Intensity of poverty, 2000\n\n\n##### **Factor 3** Municipalities far from the capital and \/ or with a large territorial extension and \/ or with a large area km (** 2) - with variables\n- \u00c1rea (km\u00b2)\n\n\n` note: the naming of the factors is subjective. '', factor 3 its not important for us.","40012007":"## Performing Factor Analysis","1a45bbe4":"**varimax**: maximize variance of squared loadings\n\n>0.75 factor loading its 'Good'\n\n>0.5 <=0.75 factor loading its 'Moderage'\n\n<= 0.5 factor loading its 'Low'","c91f36e1":"# OneVsRestClassifier\n","d7a55687":"\nNow that we have the results for the factor and cluster analysis we want to interpret the results.\nNote that the most populous clusters are cluster 0,2.","f91701e8":"# RandomForestClassifier","104eb562":"# Creating a Factor Analysis score and choosing the municipalities with the best scores","80c1a38b":"## Standardization\nEach indicator has its own scale. For example, the proportion of the **rural population** in total is always greater than the **Municipal HDI**. To avoid that such a difference in scale leads to incomparable weights and unreliable conclusions, we must first standardize the data.","7ff07a97":"The higher a factor loading, the more important a variable is for said factor. A loading cutoff of **0.5** will be used here. \nThis cutoff determines which variables belong to which factor. For instance, we see that the first factor contains 8 variables.","38af7715":"### What is the Factor Analysis?\n> Factor analysis is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors.\n>  Factor analysis involves grouping similar variables into dimensions.  This process is used to identify latent variables or constructs.  The purpose of factor analysis is to reduce many individual items into a fewer number of dimensions.\n\n![image.png](https:\/\/res.cloudinary.com\/dchysltjf\/image\/upload\/f_auto,q_auto:best\/v1554830233\/1.png)\n[source](https:\/\/www.datacamp.com\/community\/tutorials\/introduction-factor-analysis)","99295965":"# SSL+ FA\n- **Step 1:** Labeling data with Cluster Approach - **Done**\n- **Step 2:** Validation of Classification - **Done**\n- **Step 1.1:** Apply FA in entire data - **Done**\n- **Step 1.2:**  Use FA scores for interpret clusters - **We're here**\n\n","dcdbed82":"### Column Type","dc8f8530":"# Highest scores of **Factor 0** Most Populated Municipalities by adults mostly  per cluste.","26055924":"We have 4 factors with eigenvalues greater than 1, this is our number of factors.","58b98256":"This value indicates that you can proceed with your planned factor analysis.","73e3ae2b":"**Determination Based on Eigenvalues.   Only factors with Eigenvalues greater than 1.0 are retained.**","844a706f":"We need to choose only 4 factors (or unobserved variables).","014311d5":"## Communalities\nDetermining the communalities** which is the proportion of variability of each variable that is explained by the factors.\n\nNote: The communalities value is the same, regardless of whether you use factorial loads of non-rotated factors or factorial loads of rotated factors for the analysis.","4740f620":"### What does KMeans do?\n\nK-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. \n\n\n#### Applications\nThe K-means clustering algorithm is used to find groups which have not been explicitly labeled in the data. ","2c41d444":"## * TASK 1 - Classify Brazilian municipalities based on the available information ","701f9542":"## Glimpse of Data\n\ndataset from ibope inteligencia.\n\n> Dataset with >5000 Brazilian municipalities, 23 measures.\n\n### Columns: \n- Area (km\u00b2)'\n- 'Demographic density, 2000'\n- 'Distance to capital (km)'\n- 'Life expectancy at birth, 2000'\n- 'Mortality to one year old, 2000'\n- 'Total fertility rate, 2000'\n- 'Percentage of people aged 25 and over who are illiterate, 2000'\n- 'Income per Capita, 2000'\n- 'Gini Index, 2000'\n- 'Intensity of indigence, 2000'\n- 'Intensity of poverty, 2000'\n- 'Municipal Human Development Index, 2000'\n- 'Gross school attendance rate, 2000'\n- 'Literacy rate, 2000'\n- 'Average years of schooling for people aged 25 or over, 2000'\n- 'Population aged 25 or over, 1991'\n- 'Population aged 25 or over, 2000'\n- 'Population aged 65 and over, 1991'\n- 'Population aged 65 and over, 2000'\n- 'Total population, 1991'\n- 'Total population, 2000'\n- 'Urban population, 2000'\n- 'Rural population, 2000'","f9e78e31":"# Highest scores of **Factor 1** Municipalities Developed by cluster","96a2e290":"# Using clustering\n\nNow we will use algorithms to define the groupings of the municipalities.","d2bfa995":"##### Rotation of Factors\n\n#### Varimax procedure. Axes maintained at right angles\n\t-Most common method for rotation. \n\t-An orthogonal method of rotation that minimizes the number of variables with high loadings on a factor. \n\t-Orthogonal rotation results in uncorrelated factors.  \n\n##### Oblique rotation. Axes not maintained at right angles\n\t-Factors are correlated. \n\t-Oblique rotation should be used when factors in the population are likely to be strongly correlated.\n    \n![image.png](attachment:image.png)\n[source](https:\/\/devopedia.org\/factor-analysis)\n  ","2f3cbf8c":"We will use Factor Analysis in order to identify latent factors in the variables, we want to know which variables influence the data the most.\n\n# Next, we will use these factors to identify the most significant clusters for the multinational retailer in our case.","cee5cd85":"### Kaiser-Meyer-Olkin (KMO)\nTest measures the suitability of data for factor analysis. \nIf the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy is small, then the correlations between pairs of variables cannot be explained by other variables and factor analysis may not be appropriate. \nKMO values range between 0 and 1. Value of KMO less than 0.6 is considered inadequate.","2a74af4a":"[Factor Analysis library](https:\/\/pypi.org\/project\/factor-analyzer\/) - python\n-> factor-analyzer 0.3.2","7bd2f5d1":"Income per Capita, 2000 mean for the clusters","eafb0d7c":"## Correlation between Municipalities\n\nIn the graph below we can see a correlation between municipalities."}}