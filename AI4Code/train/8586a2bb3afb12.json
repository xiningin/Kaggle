{"cell_type":{"63e5087b":"code","3cc42ef3":"code","734dcc74":"code","2a16d180":"code","bf7f1645":"code","86981348":"code","74dbfabe":"code","aace63a8":"code","99875dac":"code","0a1aa1e1":"code","7a98b974":"code","024eecf7":"code","6678cf75":"code","e58ae887":"code","cd10af78":"code","1bccf798":"code","0a69e533":"code","2fca1a81":"code","b9528043":"code","8376da5f":"code","e45850f2":"code","1f20ad7a":"code","2217d15a":"code","72cadd3d":"code","4149e269":"code","83413697":"code","e657020a":"code","3a519d55":"code","bbad3d4e":"markdown","5ecd57a5":"markdown","a84a9952":"markdown","687ca839":"markdown","f5aaa519":"markdown","5abe1cb4":"markdown","4f57640e":"markdown","55f5f361":"markdown","286bd873":"markdown","bcc3c3f6":"markdown"},"source":{"63e5087b":"%matplotlib inline\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 16\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tqdm import tqdm","3cc42ef3":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","734dcc74":"start = dt.datetime.now()","2a16d180":"!ls ..\/input\/keras-pretrained-models\/","bf7f1645":"cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)","86981348":"!cp ..\/input\/keras-pretrained-models\/xception* ~\/.keras\/models\/","74dbfabe":"!ls ~\/.keras\/models","aace63a8":"!ls ..\/input\/plant-seedlings-classification","99875dac":"CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\nNUM_CATEGORIES = len(CATEGORIES)","0a1aa1e1":"SAMPLE_PER_CATEGORY = 200\nSEED = 1987\ndata_dir = '..\/input\/plant-seedlings-classification\/'\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')\nsample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))","7a98b974":"sample_submission.head(2)","024eecf7":"for category in CATEGORIES:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))","6678cf75":"train = []\nfor category_id, category in enumerate(CATEGORIES):\n    for file in os.listdir(os.path.join(train_dir, category)):\n        train.append(['train\/{}\/{}'.format(category, file), category_id, category])\ntrain = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\ntrain.head(2)\ntrain.shape","e58ae887":"train = pd.concat([train[train['category'] == c][:SAMPLE_PER_CATEGORY] for c in CATEGORIES])\ntrain = train.sample(frac=1)\ntrain.index = np.arange(len(train))\ntrain.head(2)\ntrain.shape","cd10af78":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test\/{}'.format(file), file])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])\ntest.head(2)\ntest.shape","1bccf798":"def read_img(filepath, size):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)\n    img = image.img_to_array(img)\n    return img","0a69e533":"fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\ngrid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\ni = 0\nfor category_id, category in enumerate(CATEGORIES):\n    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n        ax = grid[i]\n        img = read_img(filepath, (224, 224))\n        ax.imshow(img \/ 255.)\n        ax.axis('off')\n        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n            ax.text(250, 112, filepath.split('\/')[1], verticalalignment='center')\n        i += 1\nplt.show();","2fca1a81":"np.random.seed(seed=SEED)\nrnd = np.random.random(len(train))\ntrain_idx = rnd < 0.8\nvalid_idx = rnd >= 0.8\nytr = train.loc[train_idx, 'category_id'].values\nyv = train.loc[valid_idx, 'category_id'].values\nlen(ytr), len(yv)","b9528043":"INPUT_SIZE = 299\nPOOLING = 'avg'\nx_train = np.zeros((len(train), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, file in tqdm(enumerate(train['file'])):\n    img = read_img(file, (INPUT_SIZE, INPUT_SIZE))\n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_train[i] = x\nprint('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))","8376da5f":"Xtr = x_train[train_idx]\nXv = x_train[valid_idx]\nprint((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\nxception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\ntrain_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\nvalid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\nprint('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\nprint('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))","e45850f2":"logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(train_x_bf, ytr)\nvalid_probs = logreg.predict_proba(valid_x_bf)\nvalid_preds = logreg.predict(valid_x_bf)","1f20ad7a":"print('Validation Xception Accuracy {}'.format(accuracy_score(yv, valid_preds)))","2217d15a":"cnf_matrix = confusion_matrix(yv, valid_preds)","72cadd3d":"abbreviation = ['BG', 'Ch', 'Cl', 'CC', 'CW', 'FH', 'LSB', 'M', 'SM', 'SP', 'SFC', 'SB']\npd.DataFrame({'class': CATEGORIES, 'abbreviation': abbreviation})","4149e269":"fig, ax = plt.subplots(1)\nax = sns.heatmap(cnf_matrix, ax=ax, cmap=plt.cm.Greens, annot=True)\nax.set_xticklabels(abbreviation)\nax.set_yticklabels(abbreviation)\nplt.title('Confusion Matrix')\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nfig.savefig('Confusion matrix.png', dpi=300)\nplt.show();","83413697":"x_test = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, filepath in tqdm(enumerate(test['filepath'])):\n    img = read_img(filepath, (INPUT_SIZE, INPUT_SIZE))\n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_test[i] = x\nprint('test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))","e657020a":"test_x_bf = xception_bottleneck.predict(x_test, batch_size=32, verbose=1)\nprint('Xception test bottleneck features shape: {} size: {:,}'.format(test_x_bf.shape, test_x_bf.size))\ntest_preds = logreg.predict(test_x_bf)","3a519d55":"test['category_id'] = test_preds\ntest['species'] = [CATEGORIES[c] for c in test_preds]\ntest[['file', 'species']].to_csv('submission.csv', index=False)","bbad3d4e":"## LogReg on Xception bottleneck features","5ecd57a5":"# Use Keras Pretrained Models dataset\nKernels can't use network connection to download pretrained keras model weights.\nThis dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \nYou can find more details [here](https:\/\/www.kaggle.com\/gaborfodor\/keras-pretrained-models).\n\nWe have to copy the pretrained models to the cache directory (~\/.keras\/models) where keras is looking for them.","a84a9952":"# Transfer learning with pretrained Keras models\n\nAlthough Kernel resources were increased recently we still can not train useful CNNs without GPU. Fortunately prediction is much faster (<1s\/image) making it possible to run meaningful experiments with Kaggle Kernels.","687ca839":"## Extract Xception bottleneck features","f5aaa519":"# Example images","5abe1cb4":"# Training sample","4f57640e":"## Create submission","55f5f361":"# Validation split","286bd873":"## Confusion matrix","bcc3c3f6":"# Check the plant seedlings"}}