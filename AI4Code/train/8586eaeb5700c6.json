{"cell_type":{"485574ab":"code","bcbd06ee":"code","ebc98ece":"code","a04e2954":"code","d4d6dab6":"code","fe5a885e":"code","cd44df0c":"code","e06ab78a":"code","1555fea0":"code","6ec5fd99":"code","b1e4d903":"code","29feff54":"code","34d87bd0":"code","aa04ce19":"code","3a6d14a7":"code","b7c0f47c":"code","06a2bf1c":"code","91aa5c5b":"code","2723355e":"code","db427746":"code","1bb0f65d":"code","866ca115":"code","b0edc68d":"code","96e738f8":"code","ad67ce7a":"code","4b1368d9":"code","e0fa26e4":"code","046d6790":"code","4abd4a0b":"code","df2cfa15":"code","a406733f":"code","6af93a33":"code","285cb371":"code","0db48913":"code","67202d2a":"code","63a5e721":"code","b3699f4d":"code","245d6c74":"code","8622c400":"code","1ebcba43":"code","73061af7":"code","c409fb61":"code","c49d90f3":"code","400a2beb":"code","59d3f159":"code","318f0c89":"code","677632cd":"code","840487eb":"code","9675777e":"code","0f42b47e":"code","7b2d2b9a":"code","4982ce1f":"code","d9502c41":"code","5b320edf":"code","ac94bcaa":"code","8d3843c6":"code","09712536":"code","a775e8ef":"code","4086186d":"code","69bd9125":"code","23b19cc3":"code","6d4f66a9":"code","72c027b8":"code","245dc4a0":"code","7195a311":"code","77dec8a7":"code","d8bb1b50":"code","b293da39":"code","b926d9be":"code","4adc0aaf":"code","c9df7aa4":"code","a4a03733":"code","c23923e0":"code","06d55091":"code","55138fb3":"code","bb327186":"code","7b29626a":"code","3dc4f68c":"code","fc33762f":"code","54434f6c":"code","696b7fda":"code","0b1b3b9d":"code","f3374191":"code","1cf1f70c":"code","5c39ef8c":"code","a3e5e84a":"code","eff66719":"code","092df772":"code","cf4271f8":"code","89586087":"code","206b1ae9":"code","0bb70dd4":"code","adc1ebec":"code","743f0d49":"markdown","9cf262b9":"markdown","873b414b":"markdown","2106fda7":"markdown","033bc907":"markdown","4b4d574b":"markdown","6237a129":"markdown","72f02a07":"markdown","d594b670":"markdown","e4062c41":"markdown","53b022d4":"markdown","719c8921":"markdown","129a92ff":"markdown","4b1b4bb3":"markdown","c25162df":"markdown","a30a5adf":"markdown","7fd8d360":"markdown","d21522ce":"markdown","ef4bc1c9":"markdown","79d2e9b4":"markdown","a943c938":"markdown","0926c3d2":"markdown","2c27b98b":"markdown","603b7df0":"markdown","f2debd99":"markdown"},"source":{"485574ab":"#!pip install -U tensorflow==2.0.0","bcbd06ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Input\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom xgboost import DMatrix\n\nprint('Tensorflow ', tf.__version__)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n#%matplotlib inline","ebc98ece":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    print('Running on TPU :', tpu.master())\n    \nexcept ValueError:\n    tpu = None\n    \nif tpu:\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    \nelse:\n    strategy = tf.distribute.get_strategy()\n    \nprint('Replicas: ', strategy.num_replicas_in_sync)","a04e2954":"train_data = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest_data = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/test.json', lines=True)","d4d6dab6":"submit = pd.read_csv('\/kaggle\/input\/stanford-covid-vaccine\/sample_submission.csv')","fe5a885e":"submit.head()","cd44df0c":"train_data.head()","e06ab78a":"print(train_data.shape)","1555fea0":"print(train_data.columns)","6ec5fd99":"def in_out_shape(data, input_shape=107, output_shape=68, contra=True):\n    if type(data) != 'list':\n        d = list(data)\n    else:\n        d = data\n        \n    if (input_shape == 107 and output_shape == 107 and contra == True)\\\n        or (input_shape == 68 and output_shape == 107):\n        \n        d = d[:68]\n        d.extend(d[:39])\n        return d\n    \n    elif (input_shape == 107 and output_shape == 68)\\\n        or (input_shape == 68 and output_shape == 68):\n        \n        d = d[:68]\n        return d\n    \n    elif input_shape == 107 and output_shape == 107 and contra == False:\n        d = d[:107]\n        return d\n    elif input_shape == 130 and output_shape == 130 and contra == False:\n        d = d[:130]\n        return d","b1e4d903":"def f1_ls_to_np(data, ishp, oshp, c):\n    d = in_out_shape(data, ishp, oshp, c)\n    ls = []\n    for i in range(len(d)):\n        if d[i] == 'A':\n            ls.append([1, 0, 0, 0])\n        elif d[i] == 'U':\n            ls.append([0, 1, 0, 0])\n        elif d[i] == 'G':\n            ls.append([0, 0, 1, 0])\n        else:\n            ls.append([0, 0, 0, 1])\n    ls = np.array(ls)\n    return ls\n\ndef bases(data, i_shp = 107, o_shp = 107, c = True):\n    obj = np.expand_dims(f1_ls_to_np(data[0], i_shp, o_shp, c), axis=0)\n    for i in range(1, len(data)):\n        obj = np.concatenate((obj, np.expand_dims(f1_ls_to_np(data[i], i_shp, o_shp, c), axis=0)))\n    return obj","29feff54":"def struct_1_hot(data, index, isp, test):\n    if test == True and isp == 107:\n        bases = ts_df_107.sequence[index]\n    elif test == True and isp == 130:\n        bases = ts_df_130.sequence[index]\n    else:\n        bases = train_data.sequence[index]\n    idxs = []\n    struct_1_hot = [i for i in range(0, len(data))]\n    for idx, item in enumerate(data):\n        if item == '.':\n            struct_1_hot[idx] = [0, 0, 0, 0, 0, 0]\n        elif item == '(':\n            idxs.append(idx)\n        elif item == ')':\n            first = idxs.pop()\n            second = idx\n            if bases[first] == 'U':\n                if bases[second] == 'G': # U-G\n                    struct_1_hot[first] = [1, 0, 0, 0, 0, 0]\n                    struct_1_hot[second] = [1, 0, 0, 0, 0, 0]\n                else: # U-A\n                    struct_1_hot[first] = [0, 0, 0, 1, 0, 0]\n                    struct_1_hot[second] = [0, 0, 0, 1, 0, 0]\n            elif bases[first] == 'G':\n                if bases[second] == 'U': # G-U\n                    struct_1_hot[first] = [0, 1, 0, 0, 0, 0]\n                    struct_1_hot[second] = [0, 1, 0, 0, 0, 0]\n                else: # G-C\n                    struct_1_hot[first] = [0, 0, 0, 0, 1, 0]\n                    struct_1_hot[second] = [0, 0, 0, 0, 1, 0]\n            elif bases[first] == 'A': # A-U\n                struct_1_hot[first] = [0, 0, 1, 0, 0, 0]\n                struct_1_hot[second] = [0, 0, 1, 0, 0, 0]\n            else: #C-G\n                struct_1_hot[first] = [0, 0, 0, 0, 0, 1]\n                struct_1_hot[second] = [0, 0, 0, 0, 0, 1]\n    return struct_1_hot\n\ndef f2_ls_to_np(data, index, isp, osp, c, t):\n    d = list(data)\n    d = struct_1_hot(d, index, isp, t)\n    d = in_out_shape(d, isp, osp, c)\n    d = np.array(d)\n    return d\n\ndef structs(data, isp = 107, osp = 107, c = True, t = False):\n    obj = np.expand_dims(f2_ls_to_np(data[0], 0, isp, osp, c, t), axis=0)\n    for i in range(1, len(data)):\n        obj = np.concatenate((obj, np.expand_dims(f2_ls_to_np(data[i], i, isp, osp, c, t), axis=0)))\n    return obj","34d87bd0":"def f3_ls_to_np(data, isp, osp, c):\n    d = in_out_shape(data, isp, osp, c)\n    ls = []\n    for i in range(len(d)):\n        if d[i] == 'E':#Dangling End\n            ls.append([1, 0, 0, 0, 0, 0])\n        elif d[i] == 'S':#Paired Stem\n            ls.append([0, 1, 0, 0, 0, 0])\n        elif d[i] == 'H':#Hairpin\n            ls.append([0, 0, 1, 0, 0, 0])\n        elif d[i] == 'B':#Bulge\n            ls.append([0, 0, 0, 1, 0, 0])\n        elif d[i] == 'x':#eXternal Loop\n            ls.append([0, 0, 0, 0, 1, 0])\n        else:# 'I' #Internal Loop\n            ls.append([0, 0, 0, 0, 0, 1])\n    ls = np.array(ls)\n    return ls\n\ndef loop_types(data, isp = 107, osp = 107, c = True):\n    obj = np.expand_dims(f3_ls_to_np(data[0], isp, osp, c), axis=0)\n    for i in range(1, len(data)):\n        obj = np.concatenate((obj, np.expand_dims(f3_ls_to_np(data[i], isp, osp, c), axis=0)))\n    return obj","aa04ce19":"# A = [1, 0, 0, 0]\n# U = [0, 1, 0, 0]\n# G = [0, 0, 1, 0]\n# C = [0, 0, 0, 1]\n\nf1 = train_data.sequence\n\nbases_68_107 = bases(f1, 107, 107, True)\n\nbases_68 = bases(f1, 68, 68, False)\n\nbases_107 = bases(f1, 107, 107, False)\nprint(bases_107.shape)","3a6d14a7":"print(bases_107)","b7c0f47c":"# U-G = [1, 0, 0, 0, 0, 0]\n# G-U = [0, 1, 0, 0, 0, 0]\n# A-U = [0, 0, 1, 0, 0, 0]\n# U-A = [0, 0, 0, 1, 0, 0]\n# G-C = [0, 0, 0, 0, 1, 0]\n# C-G = [0, 0, 0, 0, 0, 1]\n\n\nf2 = train_data.structure\n\nstructs_68_107 = structs(f2, 107, 107, True)\n\nstructs_68 = structs(f2, 68, 68, False)\n\nstructs_107 = structs(f2, 107, 107, False)\nprint(structs_107.shape)","06a2bf1c":"# E = [1, 0, 0, 0, 0, 0]\n# S = [0, 1, 0, 0, 0, 0]\n# H = [0, 0, 1, 0, 0, 0]\n# B = [0, 0, 0, 1, 0, 0]\n# X = [0, 0, 0, 0, 1, 0]\n# I = [0, 0, 0, 0, 0, 1]\n\nf3 = train_data.predicted_loop_type\n\nloop_types_68_107 = loop_types(f3, 107, 107, True)\n\nloop_types_68 = loop_types(f3, 68, 68, False)\n\nloop_types_107 = loop_types(f3, 107, 107, False)\nprint(loop_types_107.shape)","91aa5c5b":"def t_ls_to_np(data, isp, osp, c):\n    d = in_out_shape(data, isp, osp, c)\n    d = np.array(d)\n    d = np.expand_dims(d, axis=0)\n    return d\n\ndef target(data, isp = 68, osp = 107, c = True):\n    obj = t_ls_to_np(data[0], isp, osp, c)\n    for i in range(1, len(data)):\n        obj = np.concatenate((obj, t_ls_to_np(data[i], isp, osp, c)), axis=0)\n    return obj","2723355e":"t1 = train_data.reactivity\n\nreactivity_68_107 = target(t1, 68, 107, True)\n\nreactivity_68 = target(t1, 68, 68, False)\nprint(reactivity_68.shape)","db427746":"e1 = train_data.reactivity_error\n\ne1_68 = target(e1, 68, 68, False)\ne1_68.shape","1bb0f65d":"t2 = train_data.deg_Mg_pH10\n\ndeg_Mg_pH10_68_107 = target(t2, 68, 107, True)\n\ndeg_Mg_pH10_68 = target(t2, 68, 68, False)\nprint(deg_Mg_pH10_68.shape)","866ca115":"e2 = train_data.deg_error_Mg_pH10\n\ne2_68 = target(e2, 68, 68, False)\ne2_68.shape","b0edc68d":"t3 = train_data.deg_pH10\n\ndeg_pH10_68_107 = target(t3, 68, 107, True)\n\ndeg_pH10_68 = target(t3, 68, 68, False)\nprint(deg_pH10_68.shape)","96e738f8":"e3 = train_data.deg_error_pH10\n\ne3_68 = target(e3, 68, 68, False)\ne3_68.shape","ad67ce7a":"t4 = train_data.deg_Mg_50C\n\ndeg_Mg_50C_68_107 = target(t4, 68, 107, True)\n\ndeg_Mg_50C_68 = target(t4, 68, 68, False)\nprint(deg_Mg_50C_68.shape)","4b1368d9":"e4 = train_data.deg_error_Mg_50C\n\ne4_68 = target(e4, 68, 68, False)\ne4_68.shape","e0fa26e4":"t5 = train_data.deg_50C\n\ndeg_50C_68_107 = target(t5, 68, 107, True)\n\ndeg_50C_68 = target(t5, 68, 68, False)\nprint(deg_50C_68.shape)","046d6790":"e5 = train_data.deg_error_50C\n\ne5_68 = target(e5, 68, 68, False)\ne5_68.shape","4abd4a0b":"test_data.shape","df2cfa15":"test_data.head()","a406733f":"test_data.columns","6af93a33":"ts_df_107 = test_data[test_data['seq_length'] == 107][['id', 'sequence', 'structure', 'predicted_loop_type']].reset_index()\nts_df_107.head()","285cb371":"ts_df_107.columns","0db48913":"ts_df_130 = test_data[test_data['seq_length'] == 130][['id', 'sequence', 'structure', 'predicted_loop_type']].reset_index()\nts_df_130.head()","67202d2a":"id_col_107 = ts_df_107.id\nid_col_107.head()","63a5e721":"id_col_130 = ts_df_130.id\nid_col_130.head()","b3699f4d":"ts_f1_107 = ts_df_107.sequence\n\nts_f1_107 = bases(ts_f1_107, 107, 107, False)\nprint(ts_f1_107.shape)","245d6c74":"ts_f1_130 = ts_df_130.sequence\n\nts_f1_130 = bases(ts_f1_130, 130, 130, False)\nts_f1_130.shape","8622c400":"print(ts_f1_130)","1ebcba43":"ts_f2_107 = ts_df_107.structure\n\nts_f2_107 = structs(ts_f2_107, 107, 107, False, True)\nprint(ts_f2_107.shape)","73061af7":"ts_f2_130 = ts_df_130.structure\n\nts_f2_130 = structs(ts_f2_130, 130, 130, False, True)\nts_f2_130.shape","c409fb61":"ts_f3_107 = ts_df_107.predicted_loop_type\n\nts_f3_107 = loop_types(ts_f3_107, 107, 107, False)\nprint(ts_f3_107.shape)","c49d90f3":"ts_f3_130 = ts_df_130.predicted_loop_type\n\nts_f3_130 = loop_types(ts_f3_130, 130, 130, False)\nts_f3_130.shape","400a2beb":"_end = np.expand_dims(np.array([0, 0, 0, 0]), axis=0)\n\ndef get_rows(i):\n    rows = np.concatenate((_end, \\\n                           np.expand_dims(bases[i, 0, :], axis=0),\\\n                           np.expand_dims(bases[i, 1, :], axis=0),\\\n                           np.expand_dims(structs[i, 0, :], axis=0),\\\n                           np.expand_dims(loop_types[i, 0, :], axis=0)),\\\n                          axis=1)\n\n    for j in range(1, seq_len - 1):\n        row = np.concatenate((np.expand_dims(bases[i, j-1, :], axis=0), \\\n                              np.expand_dims(bases[i, j, :], axis=0),\\\n                              np.expand_dims(bases[i, j+1, :], axis=0),\\\n                              np.expand_dims(structs[i, j, :], axis=0),\\\n                              np.expand_dims(loop_types[i, j, :], axis=0)),\\\n                             axis=1)\n        rows = np.concatenate((rows, row), axis=0)\n\n    last = np.concatenate((np.expand_dims(bases[i, seq_len - 2, :], axis=0), \\\n                           np.expand_dims(bases[i, seq_len - 1, :], axis=0),\\\n                           _end,\\\n                           np.expand_dims(structs[i, seq_len - 1, :], axis=0),\\\n                           np.expand_dims(loop_types[i, seq_len - 1, :], axis=0)),\\\n                          axis=1)\n    rows = np.concatenate((rows, last), axis=0)\n    \n    return rows\n        \n\ndef samples():\n    feats = get_rows(0)\n    for i in range(1, len(bases)):\n        feat = get_rows(i)\n        feats = np.concatenate((feats, feat), axis=0)\n    return feats","59d3f159":"seq_len = 68\nbases = bases_68\nstructs = structs_68\nloop_types = loop_types_68\n\nfeatures = samples()\nfeatures.shape","318f0c89":"features[:5]","677632cd":"seq_len = 107\nbases = ts_f1_107\nstructs = ts_f2_107\nloop_types = ts_f3_107\n\nts_features_1 = samples()\nts_features_1.shape","840487eb":"ts_features_1[:5]","9675777e":"seq_len = 130\nbases = ts_f1_130\nstructs = ts_f2_130\nloop_types = ts_f3_130\n\nts_features_2 = samples()\nts_features_2.shape","0f42b47e":"ts_features = np.concatenate((ts_features_1, ts_features_2), axis=0)\nts_features.shape","7b2d2b9a":"f = features\nprint(f.shape)\nfeat_exp = []\nfor i in range(f.shape[0]):\n    strng = ''\n    for j in range(f.shape[1]):\n        strng += str(f[i][j])\n    feat_exp.append(strng)\nprint(feat_exp[:5], len(feat_exp))","4982ce1f":"t1 = np.reshape(reactivity_68, (163200,))\nt2 = np.reshape(deg_Mg_pH10_68, (163200,))\nt3 = np.reshape(deg_pH10_68, (163200,))\nt4 = np.reshape(deg_Mg_50C_68, (163200))\nt5 = np.reshape(deg_50C_68, (163200,))\n\ne1 = np.reshape(e1_68, (163200,))\ne2 = np.reshape(e2_68, (163200,))\ne3 = np.reshape(e3_68, (163200,))\ne4 = np.reshape(e4_68, (163200,))\ne5 = np.reshape(e5_68, (163200,))\n\nexp_df = pd.DataFrame({\n    'feat': feat_exp,\n    't1': t1,\n    'e1': e1,\n    't2': t2,\n    'e2': e2,\n    't3': t3,\n    'e3': e3,\n    't4': t4,\n    'e4': e4,\n    't5': t5,\n    'e5': e5\n})\nexp_df.head()","d9502c41":"exp_df.feat.nunique()","5b320edf":"f = ts_features\nprint(f.shape)\nts_feat_exp = []\nfor i in range(f.shape[0]):\n    strng = ''\n    for j in range(f.shape[1]):\n        strng += str(f[i][j])\n    ts_feat_exp.append(strng)\nprint(ts_feat_exp[:5], len(ts_feat_exp))","ac94bcaa":"ts_ft_df = pd.DataFrame({\n    'ts_feat': ts_feat_exp\n})\nts_ft_df.head()","8d3843c6":"def filtrate(t, e):\n    t = np.reshape(t, (163200, 1))\n    e = np.reshape(e, (163200, 1))\n    \n    e_fltr = np.squeeze(e <= 0.3)\n    \n    t = t[e_fltr]\n    \n    t_mean = np.mean(t)\n    t_std = np.std(t)\n    \n    t_fltr = np.abs(t - t_mean) < 3 * t_std\n    t_fltr = np.squeeze(t_fltr)\n    \n    t = t[t_fltr]\n    \n    return features[e_fltr][t_fltr], t","09712536":"def get_regressor():\n    inp = Input(shape=(input_vec,))\n    \n    regr = Dense(50)(inp)\n    regr = Dense(50)(regr)\n    regr = Dense(50)(regr)\n    outp = Dense(1)(regr)\n    \n    model = Model(inputs=inp, outputs=outp)\n    return model","a775e8ef":"input_vec = 24\n\nwith strategy.scope():\n    reg = get_regressor()\n    reg.compile(optimizer='adam', loss='mse')","4086186d":"X, y = filtrate(reactivity_68, e1_68)\nreg.fit(X, y, epochs=3)","69bd9125":"t1_pred = reg.predict(ts_features)\nt1_pred.shape","23b19cc3":"X, y = filtrate(deg_Mg_pH10_68, e2_68)\nreg.fit(X, y, epochs=3)\n\nt2_pred = reg.predict(ts_features)\nt2_pred.shape","6d4f66a9":"X, y = filtrate(deg_pH10_68, e3_68)\nreg.fit(X, y, epochs=3)\n\nt3_pred = reg.predict(ts_features)\nt3_pred.shape","72c027b8":"X, y = filtrate(deg_Mg_50C_68, e4_68)\nreg.fit(X, y, epochs=3)\n\nt4_pred = reg.predict(ts_features)\nt4_pred.shape","245dc4a0":"X, y = filtrate(deg_50C_68, e5_68)\nreg.fit(X, y, epochs=3)\n\nt5_pred = reg.predict(ts_features)\nt5_pred.shape","7195a311":"ids = []\nfor iden in id_col_107:\n    for i in range(107):\n        ids.append(iden + '_' + str(i))\nfor iden in id_col_130:\n    for i in range(130):\n        ids.append(iden + '_' + str(i))\nlen(ids)","77dec8a7":"final_df = pd.DataFrame({\n    'id_seqpos': ids, \n    'reactivity': np.squeeze(t1_pred), \n    'deg_Mg_pH10': np.squeeze(t2_pred),\n    'deg_pH10': np.squeeze(t3_pred),\n    'deg_Mg_50C': np.squeeze(t4_pred),\n    'deg_50C': np.squeeze(t5_pred)})\nfinal_df.head()","d8bb1b50":"final_df.to_csv('submission.csv', index=False)","b293da39":"final_df.reactivity.nunique()","b926d9be":"exp_df","4adc0aaf":"ts_ft_df","c9df7aa4":"final_df","a4a03733":"final_df['feat'] = ts_ft_df.ts_feat\nfinal_df","c23923e0":"final_df.drop('id_seqpos', axis=1, inplace=True)\nfinal_df = final_df.drop_duplicates()\nfinal_df","06d55091":"df = exp_df.merge(final_df, on='feat', how='left')\ndf","55138fb3":"df.isna().sum()","bb327186":"df = df.fillna(999)","7b29626a":"df.isna().sum()","3dc4f68c":"def corre(dataframe):\n    temList = []\n    for _, item in dataframe.iterrows():\n        t = item[0]\n        e = item[1]\n        p = item[2]\n        if p == 999:\n            temList.append(t)\n        elif t < p:\n            temList.append(t + e)\n        elif t > p:\n            temList.append(t - e)\n        else:\n            temList.append(t)\n    return temList","fc33762f":"df['t1_n'] = corre(df[['t1', 'e1', 'reactivity']])\ndf['t2_n'] = corre(df[['t2', 'e2', 'deg_Mg_pH10']])\ndf['t3_n'] = corre(df[['t3', 'e3', 'deg_pH10']])\ndf['t4_n'] = corre(df[['t4', 'e4', 'deg_Mg_50C']])\ndf['t5_n'] = corre(df[['t5', 'e5', 'deg_50C']])\ndf","54434f6c":"t1_n = np.array(df.t1_n)\nt2_n = np.array(df.t2_n)\nt3_n = np.array(df.t3_n)\nt4_n = np.array(df.t4_n)\nt5_n = np.array(df.t5_n)","696b7fda":"X, y = filtrate(t1_n, e1_68)\nreg.fit(X, y, epochs=3)\n\nt1_pred2 = reg.predict(ts_features)\nt1_pred.shape","0b1b3b9d":"X, y = filtrate(t2_n, e2_68)\nreg.fit(X, y, epochs=3)\n\nt2_pred2 = reg.predict(ts_features)\nt2_pred2.shape","f3374191":"X, y = filtrate(t3_n, e3_68)\nreg.fit(X, y, epochs=3)\n\nt3_pred2 = reg.predict(ts_features)\nt3_pred2.shape","1cf1f70c":"X, y = filtrate(t4_n, e4_68)\nreg.fit(X, y, epochs=3)\n\nt4_pred2 = reg.predict(ts_features)\nt4_pred2.shape","5c39ef8c":"X, y = filtrate(t5_n, e5_68)\nreg.fit(X, y, epochs=3)\n\nt5_pred2 = reg.predict(ts_features)\nt5_pred2.shape","a3e5e84a":"sub2_df = pd.DataFrame({\n    'id_seqpos': ids, \n    'reactivity': np.squeeze(t1_pred2), \n    'deg_Mg_pH10': np.squeeze(t2_pred2),\n    'deg_pH10': np.squeeze(t3_pred2),\n    'deg_Mg_50C': np.squeeze(t4_pred2),\n    'deg_50C': np.squeeze(t5_pred2)})\nsub2_df.head()","eff66719":"sub2_df.to_csv('submission_exp.csv', index=False)","092df772":"def err(","cf4271f8":"def rmse(y_true, y_pred):\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    return rmse","89586087":"regress = XGBRegressor()","206b1ae9":"params = {\n    'n_estimators': [3, 5, 10, 20],\n    'max_dapth': [3, 5, 10, 20],\n    'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n    'booster': ['gbtree', 'gblinear', 'dart'],\n    'gamma': [0.00001, 0.0001, 0.0005, 0.001, 0.005, 0.008, 0.01, 0.1], #Minimum LR required for the split in a tree\n    #'score': [rmse]\n}","0bb70dd4":"gs_cv = GridSearchCV(estimator=regress, param_grid=params)","adc1ebec":"gs_cv.fit(X, y)","743f0d49":"### Feature-2 \/\/ structures","9cf262b9":"# Test Data","873b414b":"### Target-2 \/\/ deg_Mg_pH10","2106fda7":"## Experimental File-process","033bc907":"# Target Extraction","4b4d574b":"### Feature-2 \/\/ Structure","6237a129":"## Test Features","72f02a07":"# File processing","d594b670":"### Feature-3 \/\/ Loop type","e4062c41":"# Model","53b022d4":"### Feature-3 \/\/ Loop type","719c8921":"# Feature Extraction","129a92ff":"# XGB Regressor","4b1b4bb3":"# Experimental","c25162df":"### Test Features","a30a5adf":"## Experimental fit-predict","7fd8d360":"### Target-1 \/\/ reactivity","d21522ce":"### Feature-1 \/\/ Base","ef4bc1c9":"### Target-5 \/\/ deg_50C","79d2e9b4":"# Continued Experiment","a943c938":"# Single Base Variable Approach","0926c3d2":"### Target-4 \/\/ deg_Mg_50C","2c27b98b":"## Filtration ","603b7df0":"### Feature-1 \/\/ bases","f2debd99":"### Target-3 \/\/ deg_pH10"}}