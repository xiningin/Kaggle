{"cell_type":{"f32ef6ab":"code","0bebbdd6":"code","a7333462":"code","ef73c26b":"code","f2928170":"code","a4d326e4":"code","5017f83d":"code","2e342714":"code","0fa1df07":"code","35e05201":"code","653ffdc9":"code","06f96d7b":"code","ac29f9de":"code","3392f9a6":"code","991c4e7b":"code","80a968f9":"code","6b16ed34":"code","9f00b1fc":"code","e01f5e15":"code","e607feef":"code","35b1cdc1":"code","76817e7a":"code","f69018c4":"code","571de4cc":"code","03836c3b":"code","a35554e8":"code","83f8e823":"code","0faaea60":"code","f28d5248":"code","e65d021a":"code","cdf8805d":"code","019486ce":"code","d1c5c20c":"code","10349eda":"code","1c026071":"code","e562b6ed":"code","ad626dbf":"code","a1dac4df":"code","00f04145":"code","c1d58792":"code","b8292f6b":"code","770a6df9":"code","3c01d1a0":"code","59f41696":"markdown","4214deb9":"markdown","a344b261":"markdown"},"source":{"f32ef6ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0bebbdd6":"import torch\nimport torchvision\nfrom torchvision.transforms import ToTensor, Normalize, Compose\nfrom torchvision.datasets import MNIST\n","a7333462":"mnist = MNIST(root='data', \n              train=True, \n              download=True,\n              transform=Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]))","ef73c26b":"len(mnist)","f2928170":"img, label = mnist[0]\nprint(label)\nprint(img[:,10:15,10:15])\ntorch.min(img), torch.max(img)","a4d326e4":"img.shape","5017f83d":"def denorm(x):\n  out = (x + 1) \/ 2\n  return out.clamp(0, 1)","2e342714":"import matplotlib.pyplot as plt\n%matplotlib inline","0fa1df07":"def show_img(img, label):\n    print('Label: ', label)\n    plt.imshow(img.permute(1,2,0), cmap = 'gray')","35e05201":"show_img(*mnist[0])","653ffdc9":"img_norm = denorm(img)","06f96d7b":"plt.imshow(img_norm[0], cmap='gray')","ac29f9de":"plt.imshow(img.permute(1,2,0), cmap = 'gray')","3392f9a6":"plt.imshow(img_norm.permute(1,2,0), cmap = 'gray')","991c4e7b":"from torch.utils.data import DataLoader\n\nbatch_size = 100\ndata_loader = DataLoader(mnist, batch_size, shuffle=True)","80a968f9":"for img_batch, label_batch in data_loader:\n    print('first batch')\n    print(img_batch.shape)\n    #print(img_batch[0].squeeze(0).shape)\n    plt.imshow(img_batch[0].permute(1,2,0), cmap='gray')\n    print(label_batch)\n    break","6b16ed34":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","9f00b1fc":"device","e01f5e15":"image_size = 784\nhidden_size = 256","e607feef":"import torch.nn as nn\nimport torch.nn.functional as F","35b1cdc1":"D = nn.Sequential(\n    nn.Linear(image_size, hidden_size),\n    nn.LeakyReLU(0.2),\n    nn.Linear(hidden_size, hidden_size),\n    nn.LeakyReLU(0.2),\n    nn.Linear(hidden_size, 1),\n    nn.Sigmoid()\n)","76817e7a":"D.to(device)","f69018c4":"latent_size = 64","571de4cc":"G = nn.Sequential(\n    nn.Linear(latent_size, hidden_size),\n    nn.ReLU(),\n    nn.Linear(hidden_size, hidden_size),\n    nn.ReLU(),\n    nn.Linear(hidden_size, image_size),\n    nn.Tanh()\n)","03836c3b":"#G.to(device)","a35554e8":"#G(torch.randn(2, latent_size)).reshape((-1, 28,28)).shape","83f8e823":"#plt.imshow(G(torch.randn(2, latent_size)).reshape((-1, 28,28)).detach()[1], cmap='gray')","0faaea60":"y = G(torch.randn(2, latent_size))\ngen_imgs = denorm(y.reshape((-1, 28,28)).detach())","f28d5248":"plt.imshow(gen_imgs[1], cmap='gray')","e65d021a":"G.to(device)","cdf8805d":"criterion = nn.BCELoss()\nd_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\ng_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)","019486ce":"def reset_grad():\n    d_optimizer.zero_grad()\n    g_optimizer.zero_grad()\n    \ndef train_discriminator(images):\n    # create labels, for real image label is 1, for fac=ke 0\n    \n    real_labels = torch.ones(batch_size, 1).to(device)\n    fake_labels = torch.zeros(batch_size, 1).to(device)\n    \n    # loss for real images\n    \n    outputs = D(images)\n    d_loss_real = criterion(outputs, real_labels)\n    real_score = outputs\n    \n    z = torch.randn(batch_size, latent_size).to(device)\n    fake_images = G(z)\n    outputs = D(fake_images)\n    d_loss_fake = criterion(outputs, fake_labels)\n    fake_score = outputs\n    \n    # Combine losses\n    \n    d_loss = d_loss_real + d_loss_fake\n    reset_grad()\n    # Compute gradients\n    \n    d_loss.backward()\n    #Adjust parameters using backpropagation\n    \n    d_optimizer.step()\n    \n    return d_loss, real_score, fake_score","d1c5c20c":"def train_generator():\n    # Generate fake images and calculate loss\n    z = torch.randn(batch_size, latent_size).to(device)\n    fake_images = G(z)\n    labels = torch.ones(batch_size, 1).to(device)\n    g_loss = criterion(D(fake_images), labels)\n\n    # Backprop and optimize\n    reset_grad()\n    g_loss.backward()\n    g_optimizer.step()\n    return g_loss, fake_images","10349eda":"import os\n\nsample_dir = 'samples'\nif not os.path.exists(sample_dir):\n    os.makedirs(sample_dir)","1c026071":"from IPython.display import Image\nfrom torchvision.utils import save_image\n\n# Save some real images\nfor images, _ in data_loader:\n    images = images.reshape(images.size(0), 1, 28, 28)\n    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'), nrow=10)\n    break\n   \nImage(os.path.join(sample_dir, 'real_images.png'))","e562b6ed":"sample_vectors = torch.randn(batch_size, latent_size).to(device)\n\ndef save_fake_images(index):\n    fake_images = G(sample_vectors)\n    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n    print('Saving', fake_fname)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=10)\n    \n# Before training\nsave_fake_images(0)\nImage(os.path.join(sample_dir, 'fake_images-0000.png'))","ad626dbf":"%%time\n\nnum_epochs = 300\ntotal_step = len(data_loader)\nd_losses, g_losses, real_scores, fake_scores = [], [], [], []\n\nfor epoch in range(num_epochs):\n    for i, (images, _) in enumerate(data_loader):\n        # Load a batch & transform to vectors\n        images = images.reshape(batch_size, -1).to(device)\n        \n        # Train the discriminator and generator\n        d_loss, real_score, fake_score = train_discriminator(images)\n        g_loss, fake_images = train_generator()\n        \n        # Inspect the losses\n        if (i+1) % 200 == 0:\n            d_losses.append(d_loss.item())\n            g_losses.append(g_loss.item())\n            real_scores.append(real_score.mean().item())\n            fake_scores.append(fake_score.mean().item())\n            print('Epoch [{}\/{}], Step [{}\/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n                          real_score.mean().item(), fake_score.mean().item()))\n        \n    # Sample and save images\n    save_fake_images(epoch+1)","a1dac4df":"# Save the model checkpoints \ntorch.save(G.state_dict(), 'G.ckpt')\ntorch.save(D.state_dict(), 'D.ckpt')","00f04145":"Image('.\/samples\/fake_images-0050.png')","c1d58792":"Image('.\/samples\/fake_images-0300.png')","b8292f6b":"import cv2\nimport os\nfrom IPython.display import FileLink\n\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\nfiles.sort()\n\nout = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 8, (302,302))\n[out.write(cv2.imread(fname)) for fname in files]\nout.release()\nFileLink('gans_training.avi')","770a6df9":"plt.plot(d_losses, '-')\nplt.plot(g_losses, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","3c01d1a0":"plt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real Score', 'Fake score'])\nplt.title('Scores');","59f41696":"torch.randn(2, latent_size) = This will generate 2, 64 unit long vector\n\n\nG(torch.randn(2, latent_size)) = This will generate 2, 784 long vectors\n\n\nG(torch.randn(2, latent_size)).reshape((-1, 28,28)) = This will generate 2, [1,28,28] pixel noisy random images","4214deb9":"Training Generator","a344b261":"Discriminator training"}}