{"cell_type":{"bb6e430b":"code","f9fdf6aa":"code","be0d467c":"code","b4d544b4":"code","7c99f36e":"code","8750e81a":"code","39c3e311":"code","a359c9dd":"code","cb98ed62":"code","5a4b1f79":"code","07c0b261":"code","16ec65e0":"code","1c69c68a":"code","9e0ab8c0":"code","8b6c2718":"code","a9974149":"markdown","057b14d1":"markdown","939b3185":"markdown","aba6299a":"markdown"},"source":{"bb6e430b":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Model\nimport tensorflow as tf\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom keras.models import Sequential\nimport keras \nfrom keras.layers import Dense, Flatten, Conv1D,MaxPooling1D, Dropout,BatchNormalization,Embedding,Concatenate, Activation,Input\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n","f9fdf6aa":"train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')","be0d467c":"# to prepare data, I use my simple package (to clean data and Onehot encode)\n!pip install git+https:\/\/github.com\/Lpourchot\/dfencoding.git","b4d544b4":"from dfencoding import utilities # Import package","7c99f36e":"# del dfe ","8750e81a":"train_dum = train.copy()\ntest_dum = test.copy()","39c3e311":"# The package works with Object for categories cleaning and encoding, so I need to change the type :\ntrain_dum = train_dum.iloc[:,1:].astype('str')\ntest_dum = test_dum.iloc[:,1:].astype('str')","a359c9dd":"dfe = utilities.dfencoding(train_dum,'target',test_dum, missing_value = 'Y', cat_limit = 150, dummies_limit = 150)","cb98ed62":"dfe.get_dummies() # OneHot encoding","5a4b1f79":"# Preparation of the files for training of the OneHot model :\nX_Onehot = dfe.data.iloc[:len(train_dum),1:]\ntest_Onehot = dfe.data.iloc[len(train_dum):,1:]\nprint(X_Onehot.shape)\nprint(test_Onehot.shape)","07c0b261":"# Preparation of the files without labelencoding for the 2 models (embedding and Conv1D) :\ntarget = pd.get_dummies(train['target'])\ny = train['target']\nX = train.iloc[:,1:-1]\ntest = test.iloc[:,1:]\n\n# To avoid negative values (for embedding), we just add 8 to all categories :\nX = X + 8\ntest = test + 8\nX.shape, test.shape, y.shape, target.shape","16ec65e0":"es = callbacks.EarlyStopping(\n                monitor = 'val_categorical_crossentropy', \n                min_delta = 0.0000001, \n                patience = 6,\n                mode = 'min',\n                baseline = None, \n                restore_best_weights = True,\n                verbose = 1)\n\nplateau  = callbacks.ReduceLROnPlateau(\n                monitor = 'val_categorical_crossentropy',\n                factor = 0.5, \n                patience = 3, \n                mode = 'min', \n                min_delt = 0.0000001,\n                cooldown = 0, \n                min_lr = 1e-7,\n                verbose = 1) \n\nmetrics = [tf.keras.metrics.CategoricalCrossentropy()]\nloss = tf.keras.losses.CategoricalCrossentropy(\n                from_logits=False,\n                label_smoothing=0,\n                reduction=\"auto\",\n                name=\"categorical_crossentropy\")\n","1c69c68a":"N_FOLDS = 20\nSEED = 2021\noof = np.zeros((X.shape[0],4))\npred = np.zeros((test.shape[0],4))\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(X, y)):\n    print(f\"===== FOLD {fold} =====\")\n       \n    x_tr = X.iloc[tr_idx] # X_train\n    x_Onehot_tr = X_Onehot.iloc[tr_idx] # X for Onehot encoding\n    y_tr = target.iloc[tr_idx] # y_train\n    x_ts = X.iloc[ts_idx] # X_valid\n    x_Onehot_ts = X_Onehot.iloc[ts_idx] # X_valid for Onehot encoding\n    y_ts = target.iloc[ts_idx] # y_valid\n\n    # API functional for OneHot\n    inputs_API_Onehot = Input(shape=(1285,), name = 'API_input_Onehot')\n    w = Dense(1285, activation=\"relu\")(inputs_API_Onehot)\n    w = Dropout(0.3)(w)\n    w = Dense(80, activation=\"relu\")(w)\n    w = Dropout(0.3)(w)\n    w = Dense(20, activation=\"relu\")(w)\n    outputs_API_Onehot = Dense(4, activation=\"relu\")(w)\n    \n    #API functional for Embedding\n    inputs_API_Embedding = Input(shape=(50,), name = 'API_input_Embedding')\n    x = Embedding(80, 10, input_length=50)(inputs_API_Embedding)\n    x = Flatten()(x)\n    x = Dense(80, activation=\"relu\")(x)\n    x = Dense(20, activation='relu')(x)\n    outputs_API_Embedding = Dense(4, activation='relu')(x)\n    \n    #API functional for Conv1D\n    inputs_API_Conv1D = Input(shape=(50,1), name = 'API_input_Conv1D') \n    v = Conv1D(\n            filters=512, #256\n            kernel_size=5, #4\n            padding='same', \n            activation='relu',\n            )(inputs_API_Conv1D)\n    v = MaxPooling1D(pool_size=3)(v)\n    v = Flatten()(v)\n    v = Dense(80, activation='relu')(v)\n    v = Dense(20, activation='relu')(v)\n    outputs_API_Conv1D = Dense(4, activation='relu')(v)\n    \n    # Final step with concatenation of Embedding and Conv1D :\n    z = Concatenate(axis=1)([outputs_API_Conv1D, outputs_API_Embedding,outputs_API_Onehot])\n    out = Dense(4, activation = 'softmax', name = 'out')(z)\n\n    # Creation of the merged model :\n    model_merged = Model(\n                 inputs=[inputs_API_Conv1D,inputs_API_Embedding,inputs_API_Onehot], \n                 outputs=out, \n                 name=\"model_merged\")\n    \n    # Compile and fit of the merged model :\n    model_merged.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),loss=loss ,metrics=metrics)\n    model_merged.fit(\n                    {'API_input_Conv1D':x_tr, 'API_input_Embedding':x_tr,'API_input_Onehot':x_Onehot_tr},\n                    {'out':y_tr},\n                    validation_data = ([x_ts,x_ts,x_Onehot_ts], y_ts),\n                    batch_size=256,\n                    epochs=50,\n                    verbose=1,\n                    callbacks=[es,plateau])\n    \n    oof[ts_idx] = model_merged.predict([x_ts,x_ts,x_Onehot_ts])\n    score = log_loss(y_ts, oof[ts_idx])\n    print(f\"FOLD {fold} Score {score}\\n\")\n    \n    pred += model_merged.predict([test,test,test_Onehot]) \/ N_FOLDS\n\nscore = log_loss(y, oof)\nprint(f\"Score total {score}\\n\")   ","9e0ab8c0":"submission = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')","8b6c2718":"submission_df = pd.DataFrame(pred)\nsubmission_df.columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4']\nsubmission_df['id'] = submission['id']\nsubmission_df = submission_df[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4']]\nsubmission_df.to_csv(\"submission_Keras_3.csv\", index=False)\ndisplay(submission_df.head())","a9974149":"<h3> Preparation for the Onehot encoding model","057b14d1":"<h2> Kfold for 3 streams API : Embedding + Conv1D + Onehot sequential","939b3185":"<h2> Basic data preparation","aba6299a":"<h3> Others preparation for Models Embedding and Conv1D"}}