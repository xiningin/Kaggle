{"cell_type":{"2cf1d977":"code","213d2b79":"code","dd31c0b1":"code","5ec5e24b":"code","63515238":"code","149fc805":"code","39be04c4":"code","7e76a609":"code","68ad935f":"code","44fbe528":"code","cad78eaa":"code","bec9bb3a":"code","56be88eb":"code","a8285fba":"code","1a41ad31":"code","2a293b40":"code","1ccd02e9":"code","f0632de6":"code","2b03917d":"code","394f884b":"code","8e20af14":"code","926d9b0e":"code","ea6faa48":"code","05c9e5e9":"code","b95e42a9":"code","1884108c":"code","605a474d":"code","b80c48c4":"code","f069fa72":"code","2a9c1ac5":"code","53b0c097":"code","24cd6004":"code","f27c271e":"code","62746357":"code","5dd1d06c":"code","c3addd94":"code","516f6e1e":"code","227a7e7a":"code","ca86efd8":"code","9c667ad9":"code","16dcc077":"code","c0d679b1":"markdown","036a30de":"markdown","2f1506db":"markdown","26d924e9":"markdown","1b2292dc":"markdown","edc3c20b":"markdown","c8318cec":"markdown","23e45242":"markdown","3bc8c9a1":"markdown","82a1627f":"markdown","d3b9c0bb":"markdown","d1179f80":"markdown","d501e376":"markdown","9e6aa638":"markdown","a15b30aa":"markdown","d1c564f3":"markdown","c7ed90f8":"markdown","49494b66":"markdown","24aab1e8":"markdown","fb50b745":"markdown","3eda7f01":"markdown","da1b573f":"markdown","cfe1985f":"markdown","dbbae60c":"markdown","a5cdc72c":"markdown","8347ef65":"markdown","4ae0f2a6":"markdown","5598ede1":"markdown","13dea678":"markdown","3047475f":"markdown","0868f35c":"markdown"},"source":{"2cf1d977":"import keras\nimport numpy as np \nimport pandas as pd \nimport zipfile\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.applications import VGG16, DenseNet201\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers","213d2b79":"with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\", 'r') as zip_ref:\n                zip_ref.extractall(\".\/\")\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\", 'r') as zip_ref:\n                zip_ref.extractall(\".\/\")","dd31c0b1":"print(\"Total train images\")\nprint(len([f for f in os.listdir('.\/train') if os.path.isfile(os.path.join('.\/train', f))]))\nprint(\"Total test images\")\nprint(len([f for f in os.listdir('.\/test1') if os.path.isfile(os.path.join('.\/test1', f))]))\n\nprint(\"Total train cats images\")\nprint(len([f for f in os.listdir('.\/train') if os.path.isfile(os.path.join('.\/train', f)) and 'cat' in f]))\nprint(\"Total train dogs images\")\nprint(len([f for f in os.listdir('.\/train') if os.path.isfile(os.path.join('.\/train', f)) and 'dog' in f]))\n\nprint(\"Total test cats images\")\nprint(len([f for f in os.listdir('.\/test1') if os.path.isfile(os.path.join('.\/test1', f)) and 'cat' in f]))\nprint(\"Total test dogs images\")\nprint(len([f for f in os.listdir('.\/test1') if os.path.isfile(os.path.join('.\/test1', f)) and 'dog' in f]))","5ec5e24b":"i = 0\nfor dirname, _, filenames in os.walk('.\/train'):\n    for filename in filenames:\n        print(os.path.join(filename))\n        img = plt.imread(os.path.join(dirname, filename))\n        print(img.shape)\n        plt.figure(i)\n        plt.imshow(img)\n        i+=1\n        if i==7:\n            break","63515238":"base_dir = '.\/'\n\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\ntest_dir = os.path.join(base_dir, 'test_dir')\nos.mkdir(test_dir)\n\ntrain_cats = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats) \ntrain_dogs = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs)\n\nval_cats = os.path.join(val_dir, 'cats')\nos.mkdir(val_cats) \nval_dogs = os.path.join(val_dir, 'dogs')\nos.mkdir(val_dogs)\n\ntest_cats = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats) \ntest_dogs = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs)","149fc805":"files = ['cat.{}.jpg'.format(i) for i in range(2000)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(train_cats, filename)\n    shutil.copyfile(src, dst)\n    \nfiles = ['cat.{}.jpg'.format(i) for i in range(2000, 3000)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(val_cats, filename)\n    shutil.copyfile(src, dst)\n    \nfiles = ['cat.{}.jpg'.format(i) for i in range(3000, 4000)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(test_cats, filename)\n    shutil.copyfile(src, dst)\n    \nfiles = ['dog.{}.jpg'.format(i) for i in range(2000)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(train_dogs, filename)\n    shutil.copyfile(src, dst)\n\nfiles = ['dog.{}.jpg'.format(i) for i in range(2000, 3000)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(val_dogs, filename)\n    shutil.copyfile(src, dst)\n    \nfiles = ['dog.{}.jpg'.format(i) for i in range(3000, 4000)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(test_dogs, filename)\n    shutil.copyfile(src, dst)","39be04c4":"print('Train cats: ', len(os.listdir(train_cats)))\nprint('Train dogs: ', len(os.listdir(train_dogs)))","7e76a609":"datagen = ImageDataGenerator(rescale=1.\/255)\nIMAGE_SIZE=(150,150)\nBATCH_SIZE=64\ntrain_generator = datagen.flow_from_directory(\n    train_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode='binary')   \n\nval_generator = datagen.flow_from_directory(\n    val_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode='binary')   ","68ad935f":"for data_batch, labels_batch in train_generator:\n    print('Data batch shape:', data_batch.shape)\n    print('Labels batch shape:', labels_batch.shape)\n    break;","44fbe528":"conv_base = VGG16(weights='imagenet',\n                 include_top=False,\n                 input_shape=(150, 150, 3))","cad78eaa":"conv_base.summary()","bec9bb3a":"conv_base.trainable = False","56be88eb":"model = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","a8285fba":"model.summary()","1a41ad31":"model.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=2e-5),\n             metrics=['acc'])","2a293b40":"callbacks_list = [\n    keras.callbacks.EarlyStopping(\n    monitor='acc',\n    patience=1),\n    keras.callbacks.ModelCheckpoint(\n    filepath='vgg16_standart.h5',\n    monitor='loss',\n    svae_best_only=True)\n]","1ccd02e9":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n\/\/BATCH_SIZE,\n    validation_steps=val_generator.n\/\/BATCH_SIZE,\n    epochs = 10,\n    callbacks = callbacks_list)","f0632de6":"acc = history.history['acc']\nval_acc=history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","2b03917d":"test_generator = datagen.flow_from_directory(\n    test_dir, \n    class_mode='binary',\n    batch_size=BATCH_SIZE,\n    target_size=IMAGE_SIZE,\n    shuffle=False)","394f884b":"test_acc, test_loss = model.evaluate_generator(test_generator, steps=test_generator.n\/\/BATCH_SIZE)\nprint('test acc:', test_acc)\nprint('test loss:', test_loss)","8e20af14":"train_datagen = ImageDataGenerator(\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    rotation_range = 30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2,\n    rescale=1.\/255)\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)","926d9b0e":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode='binary')\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode='binary') ","ea6faa48":"img = image.load_img('.\/train\/cat.1666.jpg', target_size=(150,150))\nx=image.img_to_array(img)\nx=x.reshape((1,) + x.shape)\n\ni=0 \nfor batch in train_datagen.flow(x, batch_size=1):\n    plt.figure(i)\n    imgplot=plt.imshow(image.array_to_img(batch[0]))\n    i+=1\n    if i%6==0:\n        break\nplt.show()","05c9e5e9":"conv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable=True\n    else:\n        layer.trainable=False","b95e42a9":"model.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=2e-5),\n             metrics=['acc'])","1884108c":"model.summary()","605a474d":"callbacks_list = [\n    keras.callbacks.EarlyStopping(\n    monitor='acc',\n    patience=1),\n    keras.callbacks.ModelCheckpoint(\n    filepath='vgg16_tuned.h5',\n    monitor='loss',\n    svae_best_only=True)\n]","b80c48c4":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n\/\/BATCH_SIZE,\n    validation_steps=val_generator.n\/\/BATCH_SIZE,\n    epochs = 20,\n    callbacks = callbacks_list)","f069fa72":"acc = history.history['acc']\nval_acc=history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","2a9c1ac5":"test_acc, test_loss = model.evaluate_generator(test_generator, steps=test_generator.n\/\/BATCH_SIZE)\nprint('test acc:', test_acc)\nprint('test loss:', test_loss)","53b0c097":"conv_base = DenseNet201(weights='imagenet',\n                 include_top=False,\n                 input_shape=(150, 150, 3))\n\nconv_base.trainable=False\n        \nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=2e-5),\n             metrics=['acc'])","24cd6004":"model.summary()","f27c271e":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n\/\/BATCH_SIZE,\n    validation_steps=val_generator.n\/\/BATCH_SIZE,\n    epochs = 10,\n    callbacks = callbacks_list)","62746357":"acc = history.history['acc']\nval_acc=history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","5dd1d06c":"test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.n\/\/BATCH_SIZE)\nprint('test acc:', test_acc)\nprint('test loss:', test_loss)","c3addd94":"conv_base.trainable=False\n\nfor layer in conv_base.layers[:-10]:\n    layer.trainable = False","516f6e1e":"model.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=2e-5),\n             metrics=['acc'])","227a7e7a":"model.summary()","ca86efd8":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n\/\/BATCH_SIZE,\n    validation_steps=val_generator.n\/\/BATCH_SIZE,\n    epochs = 20,\n    callbacks = callbacks_list)","9c667ad9":"acc = history.history['acc']\nval_acc=history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","16dcc077":"test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.n\/\/BATCH_SIZE)\nprint('test acc:', test_acc)\nprint('test loss:', test_loss)","c0d679b1":"Let's create 3 folders for training, testing and testing. We cannot take the test1 folder for testing, since the names of the files are number there.","036a30de":"# Data preprocessing","2f1506db":"Our models will be trained on a small amount of data so as not to waste a lot of time. \nCopying files to created dirs","26d924e9":"# Testing on test data","1b2292dc":"Prepare data for the VGG16 model.","edc3c20b":"Preparing test data","c8318cec":"I will try using DenseNet, as I have already worked with it, and it showed excellent accuracy.","23e45242":"![image.png](attachment:da8f777d-9b79-48dd-9721-019395749cae.png)","3bc8c9a1":"After additional training and augmentation, the accuracy has increased","82a1627f":"*with fine-tuning*","d3b9c0bb":"# Fine tuning","d1179f80":"I will also use data augmented dataset and finetuning","d501e376":"DenseNet performed better than VGG16","9e6aa638":"Sample photos","a15b30aa":"# DenseNet201","d1c564f3":"# VGG16 Model","c7ed90f8":"Let's see how many photos there are","49494b66":"We will perform turns, reversals, displacements of pictures","24aab1e8":"Freeze the layers","fb50b745":"*Without fine-tuning on augmented dataset*","3eda7f01":"# Training","da1b573f":"# Data augmentation","cfe1985f":"![image.png](attachment:59624b6e-d2a0-4908-babd-e4bac8406694.png)","dbbae60c":"here I reversed, at the beginning of the loss, and then the accuracy","a5cdc72c":"Freeze the layers from the 5th, last block. It is best to take these blocks, since the initial blocks encode more generalized features, and higher values \u200b\u200bencode features. We will not take more blocks so that there is no retraining.","8347ef65":"here I reversed, at the beginning of the loss, and then the accuracy","4ae0f2a6":"# Imports","5598ede1":"# Working with files","13dea678":"here I reversed, at the beginning of the loss, and then the accuracy","3047475f":"Adding callbacks","0868f35c":"Let's add our own fully connected classifier"}}