{"cell_type":{"519e4e8c":"code","65b931ca":"code","dd34b6de":"code","721a47ec":"code","52be29c8":"code","7f82c213":"code","299ab646":"code","7c8df3de":"code","0f1a3804":"markdown","0a168971":"markdown","990add6f":"markdown"},"source":{"519e4e8c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('\/kaggle\/input'))\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65b931ca":"import shutil\nfrom shutil import copyfile\n\n# delete temp dir\nif os.path.exists('\/kaggle\/temp\/'):\n    shutil.rmtree('\/kaggle\/temp\/')\n    \n# make directories\nos.mkdir('\/kaggle\/temp\/')\nos.mkdir('\/kaggle\/temp\/train')\nos.mkdir('\/kaggle\/temp\/valid')\nos.mkdir('\/kaggle\/temp\/train\/cat')\nos.mkdir('\/kaggle\/temp\/train\/dog')\nos.mkdir('\/kaggle\/temp\/valid\/cat')\nos.mkdir('\/kaggle\/temp\/valid\/dog')","dd34b6de":"import random\n\ndef train_valid_split(source, train_dir, valid_dir, valid_size):\n    # get files\n    files = []\n    for filename in os.listdir(source):\n        file = source + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n    \n    # train valid split\n    valid_size = int(len(files) * valid_size)\n    train_size = len(files) - valid_size\n    \n    # shuffle the dataset\n    shuffled_files = random.sample(files, len(files))\n    \n    train_set = shuffled_files[:train_size]\n    valid_set = shuffled_files[train_size:]\n    \n    for filename in train_set:\n        filepath = source + filename\n        destination = train_dir + filename\n        copyfile(filepath, destination)\n        \n    for filename in valid_set:\n        filepath = source + filename\n        destination = valid_dir + filename\n        copyfile(filepath, destination)\n    \nSOURCE = '\/kaggle\/input\/microsoft-catsvsdogs-dataset\/PetImages\/'\nTRAIN_DIR = '\/kaggle\/temp\/train\/'\nVALID_DIR = '\/kaggle\/temp\/valid\/'\n\ntrain_valid_split(SOURCE+'Cat\/', TRAIN_DIR + 'cat\/', VALID_DIR + 'cat\/', valid_size=0.2)\ntrain_valid_split(SOURCE+'Dog\/', TRAIN_DIR + 'dog\/', VALID_DIR + 'dog\/', valid_size=0.2)\n\nprint(len(os.listdir(TRAIN_DIR + 'cat\/')))\nprint(len(os.listdir(TRAIN_DIR + 'dog\/')))\nprint(len(os.listdir(VALID_DIR + 'cat\/')))\nprint(len(os.listdir(VALID_DIR + 'dog\/')))","721a47ec":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\ntrain_cat_images = os.listdir(os.path.join(TRAIN_DIR, 'cat'))\ntrain_dog_images = os.listdir(os.path.join(TRAIN_DIR, 'dog'))\n\npic_index+=8\nnext_cat_pix = [os.path.join(TRAIN_DIR, \"cat\", fname) for fname in train_cat_images[pic_index-8:pic_index]]\nnext_dog_pix = [os.path.join(TRAIN_DIR, \"dog\", fname) for fname in train_dog_images[pic_index-8:pic_index]]\n\nfor i, img_path in enumerate(next_cat_pix+next_dog_pix):\n    # Set up subplot; subplot indices start at 1\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n\nplt.show()","52be29c8":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255.) \ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, batch_size=128, class_mode='binary', target_size=(150, 150))\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255.)\nvalid_generator = valid_datagen.flow_from_directory(VALID_DIR, batch_size=128, class_mode='binary', target_size=(150, 150))","7f82c213":"import tensorflow as tf\nprint(tf.__version__)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","299ab646":"K = tf.keras.backend\nK.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cnn.h5\", save_best_only=True)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator, epochs=50, validation_data = valid_generator, callbacks=[early_stopping_cb, checkpoint_cb])","7c8df3de":"acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.show()\n\n# Plot training and validation loss per epoch\n\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\nplt.show()","0f1a3804":"# keras ImageGenerator API","0a168971":"# CNN Modeling","990add6f":"# Prepare Image Directories"}}