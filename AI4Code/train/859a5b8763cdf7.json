{"cell_type":{"2452bebc":"code","20ab16cf":"code","0374363f":"code","67326a32":"code","4a318984":"code","bb478a80":"code","08301a0b":"code","652c18d5":"code","602a16aa":"code","ef58a7cd":"code","cb7a69f7":"code","c74bcb85":"code","38f43f1a":"code","66a8b923":"code","384f1466":"code","e9ab37f8":"code","be202787":"code","dc357951":"markdown","60b21400":"markdown"},"source":{"2452bebc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20ab16cf":"dataset = \"\/kaggle\/input\/insurance\/insurance.csv\"\ndataset = pd.read_csv(dataset)\ndataset.head()","0374363f":"dataset.info()","67326a32":"for column in dataset.columns:\n    print(column, len(np.unique(dataset[column].to_numpy())))\n    ","4a318984":"# Let's convert the categorical data into numerical\ndataset[\"sex\"] = dataset[\"sex\"].map({\"female\":-1, \"male\":+1})\ndataset[\"smoker\"] = dataset[\"smoker\"].map({\"no\":-1, \"yes\":+1})","bb478a80":"dataset.iloc[:, ]","08301a0b":"# Converting the region categorical value to numerical using the (c-1) effect-encoding\ndataset_y = dataset.iloc[:, -1]\ndataset_x = pd.get_dummies(dataset.iloc[:, :-1], columns=[\"region\"])\ndataset_x.info()","652c18d5":"dataset_x.head()","602a16aa":"import torch\nfrom torch import Tensor\nfrom torch import nn\nfrom torch.utils.data import TensorDataset, DataLoader\n\npivot = int(len(dataset_x) * (0.8))","ef58a7cd":"milad = np.array([[1,2],[2,3]])\nrahim = np.array([9, 10])\nnp.concatenate([milad, rahim[:, None]], axis=1)","cb7a69f7":"from sklearn.preprocessing import StandardScaler\n# Normalize the dataset\n\nx_train = dataset_x.to_numpy()[:pivot, :]\ny_train = dataset_y.to_numpy()[:pivot]\n\nx_eval = dataset_x.to_numpy()[pivot:, :]\ny_eval = dataset_y.to_numpy()[pivot:]\n\nsc = StandardScaler()\ntemp = sc.fit_transform(np.concatenate([x_train, y_train[:, None]], axis=1))\nx_train, y_train = Tensor(temp[:, :-1]), Tensor(temp[:, -1])\n\ntemp = sc.transform(np.concatenate([x_eval, y_eval[:, None]], axis=1))\nx_eval, y_eval = Tensor(temp[:, :-1]), Tensor(temp[:, -1])\n\ntrain_data = TensorDataset(x_train, y_train)\neval_data = TensorDataset(x_eval, y_eval)","c74bcb85":"train_loader = DataLoader(train_data,\n                       batch_size = 128)\neval_loader = DataLoader(eval_data, \n                        batch_size = 64)","38f43f1a":"input_size = 9\nepochs = 5","66a8b923":"layers = []\nlayers.append(nn.Linear(input_size, 1000))\nlayers.append(nn.BatchNorm1d(1000))\nlayers.append(nn.ReLU())\nlayers.append(nn.Linear(1000, 1000))\nlayers.append(nn.ReLU())\nlayers.append(nn.Linear(1000, 1000))\nlayers.append(nn.ReLU())\nlayers.append(nn.Linear(1000, 1))\nmodel = nn.Sequential(*layers)\nprint(model)","384f1466":"criterian = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())\ntrain_losses = []\neval_losses = []","e9ab37f8":"for epoch in range(epochs):\n    model.train()\n    temp = []\n    for x_train, y_train in train_loader:\n        # Forward\n        out = model(x_train)\n        loss = criterian(y_train, out)\n        \n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        temp.append(loss.item())\n    \n    train_losses.append(np.mean(temp))\n    temp = []\n    model.eval()\n    for x_eval, y_eval in eval_loader:\n        out = model(x_eval)\n        temp.append(criterian(y_eval, out).item())\n    eval_losses.append(np.mean(temp))\n        \n    print(f\"({epoch+1:2}\/{epochs}): train_loss: {train_losses[-1]:.4f}, eval_loss: {eval_losses[-1]:.4f}\")","be202787":"from matplotlib import pyplot as plt\nplt.plot(list(range(epochs)), train_losses)\nplt.plot(list(range(len(eval_losses))), eval_losses)\n# plt.ylim(0.8, 1.1)\nplt.grid(alpha=0.5)\nplt.legend([\"train_loss\", \"eval_loss\"])\nplt.show()","dc357951":"## Building the model\nAt the moment we will try to build the model. It is simply a FFNN(Fed forward neyral network)","60b21400":"### Load the dataset\nInitially let's load the dataset and check the general conditions in the datset"}}