{"cell_type":{"b8e150e3":"code","40f39d2a":"code","6fe9dd78":"code","1c12ac74":"code","b83e283f":"code","638b9b8f":"code","afdc6f1e":"code","1762a271":"code","a9be070b":"markdown","37087e9f":"markdown","edce97f6":"markdown","f033214b":"markdown","e9c56ece":"markdown","e9c7f6e5":"markdown","5638829f":"markdown","07dc4854":"markdown"},"source":{"b8e150e3":"import warnings\nimport numpy as np\nimport pandas as pd\nfrom time import process_time\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom tensorflow.random import set_seed\nfrom keras.datasets import cifar10, mnist\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten","40f39d2a":"warnings.simplefilter(\"ignore\")\nrandom_state = 1\n\nnp.random.seed(random_state)\nset_seed(random_state)\n\n\nnp.set_printoptions(precision=5, suppress=True)","6fe9dd78":"def prepare_data(X, size, channels):\n    X = X.reshape(X.shape[0], size, size, channels)\n    X = X.astype(\"float32\")\n    return X\/255.","1c12ac74":"class cifar_():\n\n    def __init__(self, nb_classes=10,\n                 size=32,\n                 channels=3) -> None:\n\n        self.nb_classes = nb_classes\n        self.size = size\n        self.channels = channels\n\n    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\n    def train(self):\n        X_train = prepare_data(self.X_train, self.size, self.channels)\n        X_test = prepare_data(self.X_test, self.size, self.channels)\n        y_train = np_utils.to_categorical(self.y_train, self.nb_classes)\n        y_test = np_utils.to_categorical(self.y_test, self.nb_classes)\n        return X_train, X_test, y_train, y_test","b83e283f":"X_train = cifar_().train()[0]\nX_test = cifar_().train()[1]\nY_train = cifar_().train()[2]\nY_test = cifar_().train()[3]","638b9b8f":"class cnn():\n    def __init__(self, size, channels) -> None:\n        self.size = size\n        self.channels = channels\n\n    def fit(self, X_train, Y_train, X_test, Y_test):\n        model = Sequential()\n\n        model.add(Conv2D(32, (3, 3), input_shape=(\n            self.size, self.size, self.channels), kernel_initializer='he_uniform', padding='same'))\n        convout1 = Activation('relu')\n        model.add(convout1)\n        model.add(Conv2D(32, (3, 3), activation='relu',\n                         kernel_initializer='he_uniform', padding='same'))\n        model.add(MaxPooling2D((2, 2)))\n        model.add(Dropout(0.2))\n\n        model.add(Conv2D(64, (3, 3), activation='relu',\n                         kernel_initializer='he_uniform', padding='same'))\n        model.add(Conv2D(64, (3, 3), activation='relu',\n                         kernel_initializer='he_uniform', padding='same'))\n        model.add(MaxPooling2D((2, 2)))\n        model.add(Dropout(0.3))\n        model.add(Conv2D(128, (3, 3), activation='relu',\n                         kernel_initializer='he_uniform', padding='same'))\n        model.add(Conv2D(128, (3, 3), activation='relu',\n                         kernel_initializer='he_uniform', padding='same'))\n        model.add(MaxPooling2D((2, 2)))\n        model.add(Dropout(0.4))\n        model.add(Flatten())\n        D1 = (Dense(128, activation='relu', kernel_initializer='he_uniform'))\n        model.add(D1)\n        D2 = (Dense(128, activation='relu', kernel_initializer='he_uniform'))\n        model.add(D2)\n        model.add(Dense(10, activation='softmax'))\n\n        opt = SGD(lr=0.001, momentum=0.9)\n        model.compile(optimizer=opt,\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n\n        model.summary()\n\n        t0 = process_time()\n        model.fit(X_train, Y_train,\n                  batch_size=128,\n                  epochs=50,\n                  verbose=False,\n                  validation_data=(X_test, Y_test))\n        t1 = process_time()\n\n        score = model.evaluate(X_test,\n                               Y_test,\n                               verbose=0)\n\n        print('Test score:', score[0])\n        print('Test accuracy:', score[1])\n        print('Training time', t1-t0)","afdc6f1e":"model = cnn(32, 3)\nprint(model)","1762a271":"model.fit(X_train, Y_train, X_test, Y_test)","a9be070b":"### Author: [Seyedsaman Emami](https:\/\/github.com\/samanemami)\n\nIf you want to have this method or use the outputs of the notebook, you can fork the Notebook as following (copy and Edit Kernel).\n\n<img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F1101107%2F8187a9b84c9dde4921900f794c6c6ff9%2FScreenshot%202020-06-28%20at%201.51.53%20AM.png?generation=1593289404499991&alt=media\" alt=\"Copyandedit\" width=\"300\" height=\"300\" class=\"center\">\n\nI tried to keep everything as simple as possible, if you have any doubts or questions, please feel free to ask in the comments.","37087e9f":"# About this Script\n\n## Author: Seyedsaman Emami\n\nIn the following notebook, I considered the CIFAR10  type dataset which is a Image processing problem. \nFor the modeling, I defined CNN and trained them with the dataset.\nThe hyperparameters of the model are as follows;\n```Python\n{batch_size=128, epochs=50, optimizer='sgd'}\n```\n\nPlease find the model performance at the end in terms of the training time and model accuracy.\n\n<hr>\n\n## You can find some of my developments [here](https:\/\/github.com\/samanemami?tab=repositories).\n\n<hr>","edce97f6":"# Calling the model","f033214b":"# Training the model","e9c56ece":"# prepare_data","e9c7f6e5":"# Defining the cnn model","5638829f":"# Importing the libs","07dc4854":"# Reading and processing the dataset "}}