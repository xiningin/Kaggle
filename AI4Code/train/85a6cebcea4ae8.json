{"cell_type":{"070a3260":"code","4c1e3e4c":"code","b0b160d3":"code","7d9dbdd9":"code","361adb44":"code","3c46b1b1":"code","fa2f91c7":"code","0a84f118":"code","9f65540a":"code","57b10a08":"markdown","59a7ebfe":"markdown","c6efd756":"markdown","b763ed03":"markdown","16056490":"markdown","75ce7e3a":"markdown","c5b69b6d":"markdown","5d776920":"markdown","5013e578":"markdown","33126ad8":"markdown","080aeb3c":"markdown","64790e74":"markdown"},"source":{"070a3260":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn import  metrics\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix","4c1e3e4c":"X_train = pd.read_csv('..\/input\/kepler-labelled-time-series-data\/exoTrain.csv')\ny_train = X_train['LABEL']\nX_train = X_train.drop(columns=['LABEL'], axis=1)\nX_test = pd.read_csv('..\/input\/kepler-labelled-time-series-data\/exoTest.csv')\ny_test = X_test['LABEL']\nX_test = X_test.drop(columns=['LABEL'], axis=1)\nX_train.head()","b0b160d3":"scl = RobustScaler()\nscl.fit(X_train)\nX_train_scl = scl.transform(X_train)\nscl.fit(X_test)\nX_test_scl = scl.transform(X_test)","7d9dbdd9":"GB = GradientBoostingClassifier()\nGB.fit(X_train_scl, y_train)\nprediction_GB=GB.predict(X_test_scl)\ntrain_score_GB = GB.score(X_train_scl, y_train)\ntest_score_GB = GB.score(X_test_scl, y_test)\nprint(f\"Gradient Boosting train score: {train_score_GB}\")\nprint(f\"Gradient Boosting test score: {test_score_GB}\")\nprint(classification_report(y_test, prediction_GB))\n","361adb44":"DT = DecisionTreeClassifier()\nDT.fit(X_train_scl, y_train)\nprediction_DT=DT.predict(X_test_scl)\ntrain_score_DT = DT.score(X_train_scl, y_train)\ntest_score_DT = DT.score(X_test_scl, y_test)\nprint(f\"Decision Tree train score: {train_score_DT}\")\nprint(f\"Decision Tree test score: {test_score_DT}\")\nprint('Decision Tree Classifier')\nprint(classification_report(y_test, prediction_DT))","3c46b1b1":"AB = AdaBoostClassifier()\nAB.fit(X_train_scl, y_train)\nprediction_AB=AB.predict(X_test_scl)\ntrain_score_AB = AB.score(X_train_scl, y_train)\ntest_score_AB = AB.score(X_test_scl, y_test)\nprint(f\"AdaBoost train score: {train_score_AB}\")\nprint(f\"Adaboost test score: {test_score_AB}\")\nprint(classification_report(y_test, prediction_AB))\n","fa2f91c7":"RF = RandomForestClassifier()\nRF.fit(X_train_scl, y_train)\nprediction_RF=RF.predict(X_test_scl)\ntrain_score_RF = RF.score(X_train_scl, y_train)\ntest_score_RF = RF.score(X_test_scl, y_test)\nprint(f\"RF train score: {train_score_RF}\")\nprint(f\"RF test score: {test_score_RF}\")\nprint(classification_report(y_test, prediction_RF))\n","0a84f118":"BG = BaggingClassifier()\nBG.fit(X_train, y_train)\nprediction_BG=BG.predict(X_test)\ntrain_score_BG = BG.score(X_train, y_train)\ntest_score_BG = BG.score(X_test, y_test)\nprint(f\"BG train score: {train_score_BG}\")\nprint(f\"BG test score: {test_score_BG}\")\nprint(classification_report(y_test, prediction_BG))\n","9f65540a":"data = {'Gradient Boosting': {'Train': train_score_GB, 'Test': test_score_GB},\n        'Decision Tree': {'Train': train_score_DT, 'Test': test_score_DT},\n        'AdaBoost': {'Train': train_score_AB, 'Test': test_score_AB},\n        'Random Forest': {'Train': train_score_RF, 'Test': test_score_RF},\n        'Bagging': {'Train': train_score_BG, 'Test': test_score_BG}}\ndf = pd.DataFrame(data)\ndf = df.T\ndf ['sum'] = df.sum(axis=1)\ndf.sort_values('sum', ascending=False)[['Test','Train']].plot.bar() \nplt.ylabel('Score')","57b10a08":"# Step 3: Models performing","59a7ebfe":"## Model: Bagging","c6efd756":"## Model: Decision Tree","b763ed03":"I chose some kinds of models, for better understanding of how they work:\n* Gradient Boosting\n* Decision Trees\n* AdaBoost\n* Random Forest\n* Bagging","16056490":"As we can see on the diagram, used models performed good results. \nI will do some experiments with another models soon.","75ce7e3a":"## Model: Random Forest","c5b69b6d":"# Step 2: Standartization","5d776920":"# Step 4: Model compairing","5013e578":"# Step 1: Data preparation","33126ad8":"## Model: Gradient Boosting","080aeb3c":"I chose a robust scaler for standardization","64790e74":"## Model: AdaBoost"}}