{"cell_type":{"8a8ff719":"code","2f75b764":"code","10dabc1e":"code","f29f5754":"code","9af482f9":"code","d54c2569":"code","a47f838d":"code","30793b3c":"code","04af1caf":"code","b5707257":"code","e0e1b822":"code","4f55733f":"code","f3043f30":"code","d4131beb":"code","0fda820c":"code","bff68891":"code","c8b0b788":"code","73a36731":"code","a9751fa8":"code","1129c81e":"code","4bdff8f2":"code","d8580bb0":"code","2a7499fc":"code","0cdc9a9e":"code","1c5c0400":"code","52f02a0c":"code","1d169e0d":"code","57931641":"code","dca36708":"code","400ba434":"code","5ed59dc4":"code","db9b8262":"code","fdc607c2":"code","e143f8ad":"code","3ead3103":"code","d6a22e3a":"code","51ed8070":"code","bb106428":"code","987c65d2":"code","c4d54a61":"markdown","62bc0fd4":"markdown","22c63794":"markdown","7c51eee4":"markdown","a9483cd0":"markdown","1758014c":"markdown","673ba6e2":"markdown","fc149dcd":"markdown","72a50e4f":"markdown","b15f7545":"markdown","b88e00f7":"markdown","841798c6":"markdown","b8187107":"markdown"},"source":{"8a8ff719":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2f75b764":"import seaborn as sns\nimport matplotlib.pyplot as plt","10dabc1e":"train_df = pd.read_csv(\"..\/input\/titanic\/train.csv\",index_col=\"PassengerId\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\", index_col=\"PassengerId\")\ndf = pd.concat([train_df,test_df])\ntrain_df.shape, test_df.shape, df.shape","f29f5754":"df[\"fname\"] = df.Name.apply(lambda x: x.split(\",\")[0])\ndf[\"title\"] = df.Name.apply(lambda x: x.split(\",\")[1].split(\".\")[0])\ndf[\"familysize\"] = df.SibSp + df.Parch + 1\n#df[\"familyhead\"] = df[[\"Name\",\"familysize\"]].apply(lambda x: True if \"(\" in x[0] and x[1]>1 else False, axis=1)\n#df.familyhead.sum(), df[df.familysize>1].fname.nunique()","9af482f9":"def to_agegroup(age):\n    if pd.isnull(age):\n        return age\n    if age < 2: return 1\n    elif 2 <= age < 12: return 2\n    elif 12 <= age < 18: return 3\n    elif 18 <= age < 35: return 4\n    elif 35 <= age < 60: return 5\n    else: return 6\ndf[\"age_group\"] = df.Age.apply(to_agegroup)","d54c2569":"df.head()","a47f838d":"numeric_cols = df.select_dtypes(exclude=\"object\").columns\nobject_cols = df.select_dtypes(include=\"object\").columns","30793b3c":"data = {\"col\":[],\"count\":[],\"unique\":[],\"missing\":[]}\nfor col in object_cols:\n    data[\"col\"].append(col)\n    data[\"count\"].append(df[col].nunique())\n    data[\"unique\"].append(df[col].unique())\n    data[\"missing\"].append(df[col].isnull().sum())\npd.DataFrame(data)","04af1caf":"data = {\"col\":[],\"count\":[],\"unique\":[],\"missing\":[]}\nfor col in numeric_cols:\n    data[\"col\"].append(col)\n    data[\"count\"].append(df[col].nunique())\n    data[\"unique\"].append(df[col].unique())\n    data[\"missing\"].append(df[col].isnull().sum())\npd.DataFrame(data)","b5707257":"data = {\"col\":[],\"corr\":[]}\nfor col in numeric_cols:\n    data[\"col\"].append(col)\n    data[\"corr\"].append(abs(df[:-418].Survived.corr(df[:-418][col])))\npd.Series(data[\"corr\"],index=data[\"col\"]).sort_values().plot(kind=\"barh\",title=\"Numerical correlation\")","e0e1b822":"temp_df = df[:-418].copy()\nfor col in object_cols:\n    temp_df[col] = temp_df[col].astype(\"category\").cat.codes\ndata = {\"col\":[],\"corr\":[]}\nfor col in temp_df.columns:\n    data[\"col\"].append(col)\n    data[\"corr\"].append(abs(temp_df.Survived.corr(temp_df[col])))\npd.Series(data[\"corr\"],index=data[\"col\"]).sort_values().plot(kind=\"barh\", title=\"All in correlation\")","4f55733f":"plt.figure(figsize=(15,30))\nfor i,col in enumerate(df.columns):\n    plt.subplot(len(df.columns)\/\/3+1,3,i+1)\n    sns.countplot(data=df[:-418],hue=\"Survived\",x=col)\nsns.despine()","f3043f30":"df.describe()","d4131beb":"plt.figure(figsize=(15,13))\nfor i,col in enumerate(numeric_cols):\n    plt.subplot(len(numeric_cols)\/\/3+1,3,i+1)\n    sns.boxplot(x=df[col])\nsns.despine()","0fda820c":"df.groupby(\"Cabin\").agg(\"count\".split()).Name.plot(kind=\"barh\", figsize=(15,60))","bff68891":"# from here I found whom Name include bracket() is head \/ tickets buyer of a family\nc = \"Cabin Name familysize fname Survived Age\".split()\ndf[\"familysize\"] = df.SibSp + df.Parch + 1\ndf[c].sort_values(\"familysize fname\".split(), ascending=False).head(40)","c8b0b788":"temp_df = df.copy()\nfor col in object_cols:\n    temp_df[col] = temp_df[col].astype(\"category\").cat.codes\ndata = {\"col\":[],\"corr\":[]}\nfor col in temp_df.columns:\n    data[\"col\"].append(col)\n    data[\"corr\"].append(abs(temp_df.Age.corr(temp_df[col])))\npd.Series(data[\"corr\"],index=data[\"col\"]).sort_values().plot(kind=\"barh\", title=\"All in correlation (Age)\")","73a36731":"df.title.unique()","a9751fa8":"df.groupby(\"title\").agg(\"mean\").Age.plot(kind=\"barh\", title=\"Avg age by Title\")","1129c81e":"df[df.Age.isnull()].groupby(\"title\").Name.count().plot(kind=\"barh\", title=\"Null age count by title\")","4bdff8f2":"temp_columns = \"Age title\".split()\ntemp_df = df.groupby(\"title\").agg(\"mean\").Age\npre_age = df.Age.copy()\ndf.Age = df[temp_columns].apply(lambda x:temp_df[x[1]] if pd.isnull(x[0]) else x[0],axis=1)\npd.DataFrame({\"old\":pre_age.values,\"new\":df.Age.values}).transpose()","d8580bb0":"df.age_group = df.Age.apply(to_agegroup)\ndf.age_group.isnull().sum()","2a7499fc":"temp_df = df.copy()\nfor col in temp_df.columns:\n    temp_df[col] = temp_df[col].astype(\"category\").cat.codes\ndata = {\"col\":[],\"corr\":[]}\nfor col in temp_df.columns:\n    data[\"col\"].append(col)\n    data[\"corr\"].append(abs(temp_df.Fare.corr(temp_df[col])))\npd.Series(data[\"corr\"],index=data[\"col\"]).sort_values().plot(kind=\"barh\", title=\"All in correlation (Fare)\")","0cdc9a9e":"from statistics import mode\ncolumns = \"Embarked Fare Cabin Pclass\".split()\ntemp_df = df[columns].groupby(\"Pclass Embarked\".split()).agg(mode).Fare\ntemp_df.plot(kind=\"barh\")\n# help(mode)","1c5c0400":"def fillfare(x):\n    pclass, embarked = x[0], x[1]\n    return temp_df[(pclass,embarked)]\n\nnull_fare = df[df.Fare.isnull()].index\ndf.loc[null_fare,\"Fare\"] = df.loc[null_fare,[\"Pclass\",\"Embarked\"]].apply(fillfare,axis=1)\ndf.Fare.isnull().sum()","52f02a0c":"df.Embarked.fillna(\"S\",inplace=True)","1d169e0d":"data = {\"col\":[],\"count\":[],\"unique\":[],\"missing\":[]}\nfor col in df.columns:\n    data[\"col\"].append(col)\n    data[\"count\"].append(df[col].nunique())\n    data[\"unique\"].append(df[col].unique())\n    data[\"missing\"].append(df[col].isnull().sum())\npd.DataFrame(data)","57931641":"overall_survive_rate = df.Survived.sum()\/len(df[:-418])\ncolumns = \"Pclass Sex Ticket Cabin Embarked fname title age_group\".split()\nfor col in columns:\n    temp_df = df[:-418][[col,\"Survived\"]]\n    data = {\"unique\":[],\"count\":[],\"alive\":[],\"survive_rate\":[]}\n    for uniq in temp_df[col].unique():\n        if pd.isnull(uniq): \n            continue\n        count_, sum_ = temp_df.groupby(col).agg(\"count sum\".split()).loc[uniq]\n        survive_rate = 0\n        if sum_ != 0 and count_!=0:\n            survive_rate = sum_ \/ count_\n        data[\"unique\"].append(uniq)\n        data[\"count\"].append(count_)\n        data[\"alive\"].append(sum_)\n        data[\"survive_rate\"].append(survive_rate)\n        df.loc[df[col]==uniq, col] = survive_rate\n    print(col, \"==>\")\n    display(pd.DataFrame(data).head(3))\n    df[col] = df[col].apply(lambda x: overall_survive_rate if type(x)==str else x)","dca36708":"df.drop(\"Name SibSp Parch\".split(),axis=1,inplace=True)","400ba434":"# features scaling => X = (Xi - Xmean)\/std\ncolumns = \"Age Fare familysize\".split()\n#columns = df.columns.drop(\"Survived\")\nfor col in columns:\n    mean_, std_ = df[col].mean(), df[col].std()\n    df[col] = df[col].apply(lambda x: abs((x-mean_)\/std_))\n    ","5ed59dc4":"overall_survive_rate = df.Survived.sum()\/len(df[:-418])\ndf.Cabin.fillna(overall_survive_rate,inplace=True)\ndf.Embarked.fillna(overall_survive_rate,inplace=True)","db9b8262":"df.Survived.isnull().sum()","fdc607c2":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom termcolor import colored\n\ndef evaluate_models(X,y):\n    models = [\n        (\"LIR\",LinearRegression()),\n        (\"LOR\",LogisticRegression()),\n        (\"RFR\",RandomForestRegressor(n_estimators=100)),\n        (\"RFC\",RandomForestClassifier(n_estimators=100)),\n        (\"XGB\",XGBClassifier(learning_rate=0.01,max_depth=4,eval_metric=\"error\",n_estimators=100,use_label_encoder=False)),\n        (\"SVC\",SVC(gamma=0.1)),\n        (\"GBC\",GradientBoostingClassifier(n_estimators=100)),\n        (\"DTC\",DecisionTreeClassifier(max_leaf_nodes=500)),\n        (\"LDA\",LinearDiscriminantAnalysis()),\n        (\"KNC\",KNeighborsClassifier(leaf_size=13,n_neighbors=29,p=1)),\n        (\"GNB\",GaussianNB(var_smoothing=0.0533669923120631)),\n        (\"ETC\",ExtraTreesClassifier(max_depth=4,n_estimators=100)),\n        (\"BGC\",BaggingClassifier(max_samples=0.2,n_estimators=100)),\n    ]\n    for name,model in models:\n        results,times =[],10\n        for i in range(times):\n            train_X,test_X,train_y,test_y = train_test_split(X,y,test_size=0.2,train_size=0.8,random_state=666)\n            model.fit(train_X,train_y)\n            pred = model.predict(test_X).round(decimals=0)\n            results.append(accuracy_score(pred,test_y))\n        print(colored(f\"{name} Model accuracy:\",\"blue\"),sum(results)\/times)\n        #print(colored(\"Results:\",\"red\"),results)","e143f8ad":"import warnings\nwarnings.filterwarnings(\"ignore\", category=Warning)\n   \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, accuracy_score\n\nfeatures = df.columns.drop(\"Survived Sex fname familysize Cabin age_group\".split())\nfeatures = \"age_group  title Pclass Embarked\".split()\n#features = df.columns.drop(\"Survived Sex Age familysize Ticket Cabin\".split())\nX, y = df[:-418][features], df[:-418].Survived\n\nevaluate_models(X,y)","3ead3103":"from sklearn.model_selection import GridSearchCV\n#train_X,test_x,train_y,test_y\nparameters = {\n            'learning_rate': [0.01,0.02,0.03,0.04],\n            'subsample'    : [0.9, 0.5, 0.2, 0.1],\n            'n_estimators' : [100,150],#[100,500,1000, 1500],\n            'max_depth'    : [4,6,8],#[4,6,8,10]\n}\ngrid_GBR = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid = parameters, cv = 5, n_jobs=-1)\ngrid_GBR.fit(X,y)\ngrid_GBR.best_params_","d6a22e3a":"#List Hyperparameters that we want to tune.\nleaf_size = list(range(1,50,2))\nn_neighbors = list(range(1,30,2))\np=[1,2]\n#Convert to dictionary\nhyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n#Create new KNN object\nknn_2 = KNeighborsClassifier()\n#Use GridSearch\nclf = GridSearchCV(knn_2, hyperparameters, cv=10)\n#Fit the model\nbest_model = clf.fit(X,y)\nbest_model.best_params_","51ed8070":"params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\ngs_NB = GridSearchCV(estimator=GaussianNB(), \n                 param_grid=params_NB, \n                 cv=50,   # use any cross validation technique \n                 verbose=1, \n                 scoring='accuracy') \ngs_NB.fit(X,y)\ngs_NB.best_params_","bb106428":"#model = RandomForestRegressor(n_estimators=100)\nmodel = LinearRegression()\n#model = LinearDiscriminantAnalysis()\n#model = GradientBoostingClassifier()\n#model = XGBClassifier(learning_rate=0.01,max_depth=4,eval_metric=\"error\",n_estimators=100,use_label_encoder=False)\n#model = KNeighborsClassifier(leaf_size=13,n_neighbors=29,p=1)\nmodel.fit(X,y)\npred = model.predict(df[-418:][features]).round()\noutput = pd.DataFrame({\"PassengerId\":df[-418:].index,\"Survived\":pred})\noutput.Survived = output.Survived.astype(\"int\")\noutput.set_index(\"PassengerId\",inplace=True)\n#output.drop(\"index\",axis=1,inplace=True)\noutput.to_csv(\"submission.csv\")","987c65d2":"pd.read_csv(\".\/submission.csv\").transpose()","c4d54a61":"# Finalize model - RandomForest","62bc0fd4":"# Evaluate models","22c63794":"> I decide to fill null Age with groupby Title mean","7c51eee4":"# Transform features\nAfter analyzed dataset I decided to transform Name and famali member features","a9483cd0":"# Features scaling","1758014c":"# **Process Age**","673ba6e2":"# Convert label data to survived ratio","fc149dcd":"**Change label value by its ratio, how it's transformed**\nLet's say Sex feature Male label\nI will replace the Male label by male surviving rate\nand assign to others features label to make it more meaningfull than just a label","72a50e4f":"# Analyze and visualize data","b15f7545":"> From above graphs I found Embarked,Fare, Cabin and Pclass are related to each others","b88e00f7":"# Process Fare","841798c6":"**Find out best fit parameters**\nsource from: https:\/\/towardsdatascience.com\/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74","b8187107":"# Tuning models\n* fill in parameters manually\n* enter best parameters to upstage evaluate models"}}