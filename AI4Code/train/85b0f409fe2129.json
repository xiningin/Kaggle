{"cell_type":{"d4ee389a":"code","1a7ccc63":"code","c14f8d5d":"code","0cc3d500":"code","a5efea66":"code","c2d24395":"code","a3c56f94":"code","91dbf451":"code","980a5776":"code","37a3d08f":"code","fa92f3b6":"code","d0bbb9d4":"code","48243da8":"code","83f5f0a4":"code","191e8c73":"code","47ce4654":"code","a79972b8":"code","61aa4002":"code","a3fe938f":"code","fad6dda9":"markdown","de41d569":"markdown","dd182a56":"markdown","f45ed56d":"markdown","b8ca315d":"markdown","7c6dcda5":"markdown","7be548dc":"markdown","e67b9ddd":"markdown","6879bbb8":"markdown","f4120359":"markdown","7c024692":"markdown"},"source":{"d4ee389a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#load the libs\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport os\nprint(tf.__version__)\nprint(os.listdir(\"..\/input\"))\nprint(\"test\")","1a7ccc63":"#import data and define the classes\ntrain_data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\nclass_names = [0,1,2,3,4,5,6,7,8,9]\n\n#print out training data\nprint(train_data.shape)\nprint(train_data.head())","c14f8d5d":"from sklearn.model_selection import train_test_split\n\n#split out the data into features (pixel values) and categorical labels (digit values 0-9)\ntrain_x = train_data.iloc[:,1:].values.astype('float32') # all pixel values\ntrain_y = train_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n\ntest_x = test_data.iloc[:,].values.astype('float32') # all pixel values\n\n#reshape the features to be 28x28\ntrain_x = train_x.reshape(train_x.shape[:1] + (28, 28, 1))\ntest_x = test_x.reshape(test_x.shape[:1] + (28, 28, 1))\n\n#change the labels to be one-hot encoded\ntrain_y = keras.utils.to_categorical(train_y)\nnum_classes = train_y.shape[1]\n\n\n#normalize pixel values using minmax (values between 0 and 1 inclusive)\ntrain_x = train_x \/ 255\ntest_x = test_x \/ 255","0cc3d500":"keras.callbacks.TensorBoard(log_dir='.\/logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True, write_images=True)","a5efea66":"plt.figure()\nplt.imshow(train_x[0].reshape(28, 28))\nplt.colorbar()\nplt.grid(False)\nplt.show()\n\n#plot a group of features and labels to check data\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_x[i].reshape(28, 28), cmap=plt.cm.binary)\n    plt.xlabel(class_names[np.argmax(train_y[i])])\nplt.show()","c2d24395":"from keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.layers.normalization import BatchNormalization\n\n#define the model and layers\n\n#first layer\nlayer1= tf.keras.layers.Conv2D(32,kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',\n                          input_shape=(28,28,1))\nlayer2= tf.keras.layers.Conv2D(32,kernel_size=(3,3), activation='relu',kernel_initializer='he_normal')\nlayer3= tf.keras.layers.MaxPooling2D(pool_size=(2,2))\nlayer4= tf.keras.layers.Dropout(0.20)\n\n#second layer\nlayer5= tf.keras.layers.Conv2D(64,(3, 3),activation='relu',padding='same')\nlayer6= tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')\nlayer7= tf.keras.layers.MaxPooling2D(pool_size=(2,2))\nlayer8= tf.keras.layers.Dropout(0.25)\n\n\n\n## third layer\nlayer9= tf.keras.layers.Conv2D(128,(3, 3),activation='relu',padding='same')\nlayer10= tf.keras.layers.Dropout(0.25)\n\n#output layer\nlayer11= tf.keras.layers.Flatten()\nlayer12= tf.keras.layers.Dense(128,activation='relu')\n# layer12 = tf.keras.layers.BatchNormalization()\nlayer13= tf.keras.layers.Dropout(0.3)\nlayer14= tf.keras.layers.Dense(10, activation=tf.nn.softmax)\nmodel = keras.models.Sequential()\nmodel.add(layer1)\nmodel.add(layer2)\nmodel.add(layer3)\nmodel.add(layer4)\nmodel.add(layer5)\nmodel.add(layer6)\nmodel.add(layer7)\nmodel.add(layer8)\nmodel.add(layer9)\nmodel.add(layer10)\nmodel.add(layer11)\n# model.add(layer12)\nmodel.add(layer13)\nmodel.add(layer14)","a3c56f94":"model.summary()","91dbf451":"## save model to image\n\nfrom keras.utils import plot_model\nplot_model(model, to_file='model.png')","980a5776":"#compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#print a summary of the model\n","37a3d08f":"#train the model\nhist = model.fit(x=train_x, \n            y=train_y,\n            batch_size=128,\n            epochs=20,\n            verbose=1,\n            validation_split=0.15,\n            shuffle=True)\n","fa92f3b6":"test = layer1.get_weights()\ntest[0].shape","d0bbb9d4":"plt.imshow(train_x[10][:,:,0])","48243da8":"from numpy import array\nimport matplotlib.pyplot as plt\n\ndef plot_conv_weights():\n    W = layer1.get_weights()[0]\n    if len(W.shape) == 4:\n        W = np.squeeze(W)\n        for i in range(W.shape[0]):\n            print(i)\n            for j in range(W.shape[1]):\n                print(j)\n                a = array(W[i][j])\n                b = a.reshape(4,8)\n                plt.imshow(b, cmap='magma', interpolation='nearest')\n                name = str(i) + str(j) + \".png\"\n                plt.savefig(name)\n        \n\n            \nplot_conv_weights()","83f5f0a4":"lay.shape[0]","191e8c73":"#make predictions on the test features\npredictions = model.predict(test_x)","47ce4654":"def plot_value_array(i, predictions_array):\n    predictions_array = predictions_array[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1]) \n    predicted_label = np.argmax(predictions_array)\n    thisplot[predicted_label].set_color('red')\n\ndef plot_image(i, predictions_array, img):\n    img = img.reshape(img.shape[0] ,28, 28)\n    predictions_array, img = predictions_array[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img, cmap=plt.cm.binary)\n    predicted_label = np.argmax(predictions_array)\n    plt.xlabel(\"{} - prob:{:2.0f}%\".format(class_names[predicted_label], 100*np.max(predictions_array)), color='red')\n\n# Plot the first X test images, their predicted label, and the true label\n# Color correct predictions in blue, incorrect predictions in red\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions, test_x)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions)\nplt.show()","a79972b8":"print(hist.history['loss'])\nprint(hist.history['acc'])\nprint(hist.history['val_loss'])\nprint(hist.history['val_acc'])","61aa4002":"\nimport matplotlib.pyplot as plt\n\nfig, loss_ax = plt.subplots()\nacc_ax = loss_ax.twinx()\n\nloss_ax.plot(hist.history['loss'], 'y', label='train loss')\nloss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\nloss_ax.set_xlabel('epoch')\nloss_ax.set_ylabel('loss')\nloss_ax.legend(loc='upper right')\n\nacc_ax.plot(hist.history['acc'], 'b', label='train acc')\nacc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\nacc_ax.set_ylabel('accuracy')\nacc_ax.legend(loc='upper left')\n\nplt.show()","a3fe938f":"#submissions for Kaggle\n#cat_predictions = np.argmax(predictions, axis=1)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": np.argmax(predictions, axis=1)})\nsubmissions.to_csv(\"my_submissions.csv\", index=False, header=True)","fad6dda9":"This is my first submission and notebook on Kaggle. I'm still learning and any comments would be appreciated. Hope some may find this useful.","de41d569":"Import the MNIST data from input folder","dd182a56":"Create submission file for Kaggle","f45ed56d":"\n Make prediction on the test data","b8ca315d":"|Train the model using batch_size of 32 and up to 30 epochs (depending on improvement of validation accuracy).","7c6dcda5":"Plot a table of test features (images) and the predicted targets (digits). Display the confidence via probability of the prediction under each image.","7be548dc":"Compile and summarize the model. Use adam optimizer and categorical cross entropy for loss (takes input of one-hot encoded targets)","e67b9ddd":"View an example of one feature","6879bbb8":"Define the model using Keras and TensorFlow backend (channels first)","f4120359":"Process the data by splitting training data into features and labels. Then apply preprocessing to the data to get it ready for input into the model.","7c024692":"|Create Keras callbacks for use during training"}}