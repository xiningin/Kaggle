{"cell_type":{"6ea7b152":"code","69aca75c":"code","254231e4":"code","c4850443":"code","2228d367":"code","2f8fa290":"code","5e079c00":"code","8f5dd3bc":"code","c1633e02":"code","bc42fb38":"code","d394fe18":"code","448a7277":"code","85a69aad":"code","9acca0b2":"code","b835f955":"code","c29ee46f":"code","cfeaae99":"code","a484c59a":"code","416b7ec1":"code","a5de7d0c":"code","7ad2eb39":"code","ec27ecf2":"code","fc8a5416":"code","adb1d67e":"code","199fc934":"code","7973ef4e":"code","d52babce":"code","630517bd":"code","bb0a6d8d":"code","328ecc4f":"code","4ae723d6":"code","26109dc6":"code","dcc3643c":"code","655ba6df":"code","e4581c8c":"code","1cb8894c":"code","dba1ee6e":"code","52bfba50":"code","912f2253":"code","81f9b745":"code","cdd86aba":"code","6587d86b":"code","81ca0f27":"code","379a8e18":"code","69409b06":"code","34316c60":"code","d7bf5068":"code","660107d5":"code","b5039a5e":"code","68420cbd":"code","e3d932f8":"code","2b7d49e0":"code","9276b99f":"code","31679819":"code","9f87ce2c":"code","cdc6969f":"code","2dee7395":"code","abc68682":"code","68e1e5eb":"markdown","5f6b4010":"markdown","272ef0c3":"markdown","025097c3":"markdown","d4b7220e":"markdown","683a2eb6":"markdown","822888e3":"markdown","f3697721":"markdown","3f31d56c":"markdown","1a5c659c":"markdown","b8420565":"markdown","63b832c7":"markdown","27fc5410":"markdown","c627674b":"markdown","8ce26aa6":"markdown","d0e2a693":"markdown","0aed9608":"markdown"},"source":{"6ea7b152":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n#pd.set_option('display.max_rows', None)\n\nfrom glob import glob\nimport gc\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nimport plotly.express as px #Plotly Express\n\nfrom plotly.offline import iplot\n#to link plotly to pandas\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline = False, world_readable = True)\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set3')\n\nimport os\nprint(os.listdir('..\/input\/japan-secondhand-apartment-price-prediction\/'))\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))","69aca75c":"train_columns = ['ID','type','area','city_code','prefectures','city_name','area_name','near_station_name','near_station_min','floor','size','shape','frontage',\n                    'floor_area','build_year','build_type','usage','future_use','front_loc','front_type','front_m','city_plan',\n                   'build_ratio','area_ratio','trade_time','change','event','price_log']\ntest_columns = ['ID','type','area','city_code','prefectures','city_name','area_name','near_station_name','near_station_min','floor','size','shape','frontage',\n                    'floor_area','build_year','build_type','usage','future_use','front_loc','front_type','front_m','city_plan',\n                   'build_ratio','area_ratio','trade_time','change','event']","254231e4":"base_dir = '\/kaggle\/input\/japan-secondhand-apartment-price-prediction\/'\nbase_train = '\/kaggle\/input\/japan-secondhand-apartment-price-prediction\/train\/train\/'","c4850443":"%%time\ndf_paths = glob(base_train + '*.csv')\ntrain = []\nfor path in df_paths:\n    df = pd.read_csv(path)\n    train.append(df)\ntrain = pd.concat(train).reset_index(drop = True)\ntrain.columns = train_columns\nprint(train.shape)\ntrain.head()","2228d367":"test = pd.read_csv(base_dir + 'test.csv')\ntest.columns = test_columns\nprint(test.shape)\ntest.head()","2f8fa290":"sub = pd.read_csv(base_dir + 'sample_submission.csv')\nprint(sub.shape)\nsub.head()","5e079c00":"train.describe().T","8f5dd3bc":"train.info()","c1633e02":"missing = train.isna().sum().reset_index()\nmissing.columns = ['features', 'total_missing']\nmissing['percent'] = (missing['total_missing'] \/ len(train)) * 100\nmissing.index = missing['features']\ndel missing['features']\n\nmissing['total_missing'].iplot(kind = 'bar', \n                               title = 'Missing Values Plot in Trainset',\n                               xTitle = 'Features',\n                               yTitle = 'Count')\nmissing.T","bc42fb38":"test_missing = test.isna().sum().reset_index()\ntest_missing.columns = ['features', 'total_missing']\ntest_missing['percent'] = (test_missing['total_missing'] \/ len(train)) * 100\ntest_missing.index = test_missing['features']\ndel test_missing['features']\n\ntest_missing['total_missing'].iplot(kind = 'bar', \n                               title = 'Missing Values Plot in Testset',\n                               xTitle = 'Features',\n                               yTitle = 'Count')\ntest_missing.T","d394fe18":"drop_cols = missing[missing['percent'] > 95].index.tolist()\nprint(f\"Number of features to drop: {len(drop_cols)}\")\ntrain.drop(drop_cols, axis = 1, inplace = True)\ntest.drop(drop_cols, axis = 1, inplace = True)\ntrain.shape, test.shape","448a7277":"del missing, test_missing\ngc.collect()","85a69aad":"train['price_log'].iplot(kind = 'hist',\n                        bins = 100,\n                        xTitle = 'Price_log',\n                        linecolor = 'black',\n                        color = 'red',\n                        yTitle = 'count',\n                        title = 'Price Log Distribution'\n                        )","9acca0b2":"sns.boxplot(data = train, x = 'price_log');","b835f955":"train['floor'].value_counts().sort_values(ascending = True).iplot(kind = 'bar', \n                                                                  orientation = 'h',\n                                                                  yTitle = 'Floors',\n                                                                  title = 'Countplot of Apartment Floor'\n                                                                 )","c29ee46f":"print(train['type'].value_counts().__len__(), test['type'].value_counts().__len__())\nremove_cols = ['type']\ntrain.drop(remove_cols, axis = 1, inplace = True)\ntest.drop(remove_cols, axis = 1, inplace = True)","cfeaae99":"ax = sns.countplot(data = train, x = 'change')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","a484c59a":"train['size'].unique()","416b7ec1":"import re\n\ntrain['size'] = train['size'].apply(lambda x: re.sub(r'\\D+', '', str(x)))\ntest['size'] = test['size'].apply(lambda x: re.sub(r'\\D+', '', str(x)))\n\ntrain['size'] = train['size'].astype('int32')\ntest['size'] = test['size'].astype('int32')","a5de7d0c":"train['size'].iplot(kind = 'hist',\n                        bins = 100,\n                        xTitle = 'Size',\n                        linecolor = 'black',\n                        color = 'red',\n                        yTitle = 'count',\n                        title = 'Apartment Size Distribution'\n                        )","7ad2eb39":"sns.boxplot(data = train, x = 'size');","ec27ecf2":"px.scatter(data_frame = train, x = 'size', y = 'price_log', \n           color = 'price_log',\n          title = 'Size Vs Price')","fc8a5416":"train['floor'].unique()","adb1d67e":"train['num_bedrooms'] = train['floor'].apply(lambda x: str(x)[0])\ntrain['num_bedrooms'] = train['num_bedrooms'].apply(lambda x: int(x) if x.isdigit() else np.nan)\ntrain['num_bedrooms'].fillna(train['num_bedrooms'].median(), inplace = True)\n\ntest['num_bedrooms'] = test['floor'].apply(lambda x: str(x)[0])\ntest['num_bedrooms'] = test['num_bedrooms'].apply(lambda x: int(x) if x.isdigit() else np.nan)\ntest['num_bedrooms'].fillna(test['num_bedrooms'].median(), inplace = True)\ntrain['num_bedrooms'].value_counts(dropna = False), test['num_bedrooms'].value_counts(dropna = False)","199fc934":"categorical_features = [c for c in train.columns if train[c].dtype == 'object']\nnumerical_features = [c for c in train.columns if c not in categorical_features]\nnumerical_features, categorical_features, len(numerical_features), len(categorical_features)","7973ef4e":"df = train.sample(100000)\ndf.shape","d52babce":"temp = pd.pivot_table(data = df, columns = ['prefectures'], \n                      values = 'price_log', \n                      aggfunc = 'mean', fill_value = 0).T.sort_values(by = 'price_log')\ntemp.iplot(kind = 'bar', \n          title = 'Avg. Price by Prefectures',\n          xTitle = 'Prefectures',\n          yTitle = 'Avg. Price'\n          )","630517bd":"temp = pd.pivot_table(data = df, columns = ['floor'], \n                      values = 'price_log', \n                      aggfunc = 'median', fill_value = 0).T.sort_values(by = 'price_log')\ntemp.iplot(kind = 'bar', \n          title = 'Avg. Price by Floor',\n          xTitle = 'Floor',\n          yTitle = 'Avg. Price'\n          )","bb0a6d8d":"temp = pd.pivot_table(data = df, columns = ['build_year'], \n                      values = 'price_log', \n                      aggfunc = 'mean', fill_value = 0).T.sort_values(by = 'price_log')\ntemp.iplot(kind = 'bar', \n          title = 'Avg. Price by Build Year',\n          xTitle = 'Build Year',\n          yTitle = 'Avg. Price'\n          )","328ecc4f":"temp = pd.pivot_table(data = df, columns = ['build_type'], \n                      values = 'price_log', \n                      aggfunc = 'mean', fill_value = 0).T.sort_values(by = 'price_log')\ntemp.iplot(kind = 'bar', \n          title = 'Avg. Price by Build Type',\n          xTitle = 'Build Type',\n          yTitle = 'Avg. Price'\n          )","4ae723d6":"temp = pd.pivot_table(data = df, columns = ['build_ratio'], \n                      values = 'price_log', \n                      aggfunc = 'mean', fill_value = 0).T.sort_values(by = 'price_log')\ntemp.iplot(kind = 'bar', \n          title = 'Avg. Price by Build Ratio',\n          xTitle = 'Build Ratio',\n          yTitle = 'Avg. Price'\n          )","26109dc6":"px.scatter(data_frame = df, x = 'build_ratio', y = 'price_log', \n           color = 'price_log',\n          title = 'Build Ratio Vs Price Log')","dcc3643c":"temp = pd.pivot_table(data = train, columns = ['prefectures'], \n                      values = 'area_ratio', \n                      aggfunc = 'mean', fill_value = 0).T.sort_values(by = 'area_ratio')\ntemp.iplot(kind = 'bar', \n          title = 'Avg. Area Ratio by Prefectures',\n          xTitle = 'Prefectures',\n          yTitle = 'Avg. Area Ratio'\n          )","655ba6df":"px.scatter(data_frame = df, x = 'area_ratio', y = 'price_log', \n           color = 'price_log',\n          title = 'Area Ratio Vs Price Log')","e4581c8c":"corr = df[numerical_features].corr()\nprint(corr['price_log'].sort_values(ascending = False)[:5])","1cb8894c":"missing = train.isna().sum().reset_index()\nmissing['dtype'] = [train[c].dtype for c in missing['index']]\nmissing = missing[missing[0] > 0]\nmissing","dba1ee6e":"print('Imputing NaNs of object dtype by most occurances')\nfor c in missing['index'][missing['dtype'] == 'object']:\n    train[c] = train[c].fillna(train[c].value_counts().index[0])\n    test[c] = test[c].fillna(train[c].value_counts().index[0])\n    \nfor c in missing['index'][missing['dtype'] == 'float64']:\n    train[c] = train[c].fillna(train[c].mean())\n    test[c] = test[c].fillna(test[c].mean())\nprint('Imputing NaNs of float dtype by mean value')","52bfba50":"from scipy.stats import skew\n\nnum_feats = train.dtypes[train.dtypes != 'object'].index\n\n# Check how skewed they are\nskewed_feats = train[num_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\n\nplt.subplots(figsize = (30, 20))\nskewed_feats.plot(kind = 'bar', rot = 0);","912f2253":"numerical_features.remove('ID')\nnumerical_features.remove('price_log')\ntrain.drop(['ID'], axis = 1, inplace = True)\ntest.drop(['ID'], axis = 1, inplace = True)","81f9b745":"scl = StandardScaler()\ntrain[numerical_features] = scl.fit_transform(train[numerical_features])\ntest[numerical_features] = scl.transform(test[numerical_features])","cdd86aba":"lbl = LabelEncoder()\nfor c in categorical_features:\n    lbl.fit(list(train[c].astype(str).values) + list(test[c].astype(str).values))\n    train[c] = lbl.transform(list(train[c].astype(str).values))\n    test[c] = lbl.transform(list(test[c].astype(str).values))\nprint('Label Encoding Categorical Features done..')","6587d86b":"df = train.sample(frac = 0.2)\ndf.shape","81ca0f27":"features = categorical_features + numerical_features + ['price_log']\nmodel = TSNE(n_components = 2, random_state = 0, perplexity = 50)\nX = df[features].values\ntsne = model.fit_transform(X)\nprint('TSNE done..')\n\nscl = StandardScaler()\ns = scl.fit_transform(X)\npca = PCA(n_components = 10)\n\npca.fit(s)\npc = pca.transform(s)\nkmeans = KMeans(n_clusters = 5)\nkmeans.fit(pc)\n\ntsne_df = pd.DataFrame({'tsne1': tsne[:, 0], 'tsne2': tsne[:, 1], 'cluster': kmeans.labels_})\nsns.set_palette('Set1')\nsns.lmplot(data = tsne_df, x = 'tsne1', y = 'tsne2', hue = 'cluster', fit_reg = False)\nprint(np.sum(pca.explained_variance_ratio_))","379a8e18":"repeated = []\nfor c in df.columns:\n    counts = df[c].value_counts()\n    zeros = counts.iloc[0]\n    if zeros \/ len(df) * 100 > 99.94:\n        repeated.append(c)\nrepeated = list(repeated)\nif repeated:\n    train = train.drop(repeated, axis = 1)\n    X_sub = test.drop(repeated, axis = 1)","69409b06":"df = train.sample(frac = 0.5)\ndf.shape","34316c60":"X = df.drop('price_log', axis = 1)\ny = df['price_log']","d7bf5068":"target = train['price_log'].copy()\ntrain.drop(['price_log'], axis = 1, inplace = True)","660107d5":"Xtrain, Xvalid, ytrain, yvalid = train_test_split(train, target, test_size = 0.2, random_state = 2021)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","b5039a5e":"from mlxtend.regressor import StackingCVRegressor\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom sklearn.metrics import mean_absolute_error","68420cbd":"from lightgbm import LGBMRegressor\n\nlgbm = LGBMRegressor(\n               objective = 'regression', \n               num_leaves = 4,\n               learning_rate = 0.01, \n               n_estimators = 10000,\n               max_bin = 200, \n               bagging_fraction = 0.75,\n               bagging_freq = 5, \n               bagging_seed = 7,\n               feature_fraction = 0.2,\n               feature_fraction_seed = 7,\n               verbose = 1,\n            )\n\nlgbm_model = lgbm.fit(Xtrain, ytrain)\nlg_vpreds = lgbm_model.predict(Xvalid)\nprint((f\"LGBM MAE: {mean_absolute_error(yvalid, lg_vpreds)}\"))","e3d932f8":"lg_preds = lgbm_model.predict(test)\nsub['\u53d6\u5f15\u4fa1\u683c\uff08\u7dcf\u984d\uff09_log'] = lg_preds\nsub.to_csv('sub_lgbm.csv', index = False)\nsub.head()","2b7d49e0":"lgbm.plot_importance(lgbm_model)","9276b99f":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(\n                    learning_rate = 0.01, \n                    n_estimators = 5000,\n                    max_depth = 3, \n                    min_child_weight = 0,\n                    gamma = 0, subsample = 0.7,\n                    colsample_bytree = 0.7,\n                    objective = 'reg:squarederror', \n                    nthread = 1,\n                    scale_pos_weight = 1, \n                    seed = 27,\n                    reg_alpha = 0.00006\n                    )\nxgb_model = xgb.fit(Xtrain, ytrain)\nxg_vpreds = xgb_model.predict(Xvalid)\nprint((f\"XGBOOST MAE: {mean_absolute_error(yvalid, xg_vpreds)}\"))","31679819":"xg_preds = xgb_model.predict(test)\nsub['\u53d6\u5f15\u4fa1\u683c\uff08\u7dcf\u984d\uff09_log'] = xg_preds\nsub.to_csv('sub_xg.csv', index = False)\nsub.head()","9f87ce2c":"sub['\u53d6\u5f15\u4fa1\u683c\uff08\u7dcf\u984d\uff09_log'] = (lg_preds + xg_preds) \/ 2\nsub.to_csv('sub_en.csv', index = False)\nsub.head()","cdc6969f":"gbr = GradientBoostingRegressor(\n                    n_estimators = 10000,\n                    learning_rate = 0.05,\n                    max_depth = 4,\n                    max_features = 'sqrt',\n                    min_samples_leaf = 15, \n                    min_samples_split = 10, \n                    loss = 'huber', \n                    random_state = 42\n                    )\n\ngbr_model = gbr.fit(Xtrain, ytrain)\ngbr_vpreds = gbr_model.predict(Xvalid)\nprint((f\"GBR MAE: {mean_absolute_error(yvalid, gbr_vpreds)}\"))","2dee7395":"preds = gbr_model.predict(test)\nsub['\u53d6\u5f15\u4fa1\u683c\uff08\u7dcf\u984d\uff09_log'] = preds\nsub.to_csv('sub_gbr.csv', index = False)\nsub.head()","abc68682":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","68e1e5eb":"__This is a competition data organized by Nishika__","5f6b4010":"- Size feature is given as 'object' dtype which cannot be the case, as it must be in sq.f or sq.m\n- We will have to clean the data first and then change its dtype to int in both train and test","272ef0c3":"__Target Distribution__","025097c3":"__Average price is almost same over all the prefectures__","d4b7220e":"- Looks like there is only type of apartment in the dataset, we can remove this feature too","683a2eb6":"__Models__","822888e3":"- We shall remove the features which has all NaNs right away and also the feature 'area' which has 97% missing values","f3697721":"train['living'] = train['floor'].apply(lambda x: 1 if 'L' in  str(x) else 0)\ntrain['dining'] = train['floor'].apply(lambda x: 1 if 'D' in  str(x) else 0)\ntrain['kitchen'] = train['floor'].apply(lambda x: 1 if 'K' in  str(x) else 0)\ntrain['storage'] = train['floor'].apply(lambda x: 1 if 'S' in  str(x) else 0)\n\ntest['living'] = test['floor'].apply(lambda x: 1 if 'L' in  str(x) else 0)\ntest['dining'] = test['floor'].apply(lambda x: 1 if 'D' in  str(x) else 0)\ntest['kitchen'] = test['floor'].apply(lambda x: 1 if 'K' in  str(x) else 0)\ntest['storage'] = test['floor'].apply(lambda x: 1 if 'S' in  str(x) else 0)\n\ntrain.head(2), test.head()","3f31d56c":"There are lot of NaNs that needs to be taken care of!","1a5c659c":"__Feature Engineering__","b8420565":"__Standardize Numerical Features and Label Encode Categorical Features__","63b832c7":"- Good correlation between price and size","27fc5410":"- Check if the most recurrent value of the feature is repeated almost in all the instances. If it does then it drops these features because their values are almost the same for all instances and will not help in the learning process.","c627674b":"__Simple Clustering by TSNE__","8ce26aa6":"__Feature Engineering__\n- Let's take care of the NaNs first","d0e2a693":"- LDK is Living, Dining and Kitchen\n- 1 LDK means 1 Bedrooms with Living, Dining rooms and Kitchen\n- S is Storage room\n\n__Create features for number of bedrooms - numberical, whether there is living, dining, kitchen and storage rooms - categorical__","0aed9608":"__Correlation__"}}