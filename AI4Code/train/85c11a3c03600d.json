{"cell_type":{"99d97371":"code","2a574d3c":"code","78d30987":"code","088b8356":"code","4c2ca7ef":"code","31ef8f05":"code","b3e61924":"code","52dd38c7":"code","4a26113e":"code","1b021e79":"code","8d378996":"code","02d17338":"code","4564e8c8":"code","af805cca":"code","11b95f62":"code","26f283ab":"code","58c9ea6b":"code","f4db2282":"code","3436a6ef":"code","48ec12ce":"code","ef0bc626":"code","4a84be29":"code","65889067":"code","95ba8d63":"code","8a6fec7a":"code","17e6f99b":"code","ce836248":"code","74353b86":"code","9cfb4c0b":"code","bb42b481":"code","c0f7bbbb":"code","98c4687c":"markdown","3110bb4d":"markdown","0578b053":"markdown","fd0739da":"markdown","e7385c4f":"markdown","a310514b":"markdown","2fda4514":"markdown","a8f0647d":"markdown","c9c66589":"markdown","eeaaf753":"markdown","ca61f699":"markdown","2d07d898":"markdown","0dcc63ac":"markdown","14b53677":"markdown","8fdb7f1c":"markdown","9fec4b3a":"markdown"},"source":{"99d97371":"# Import Required Python Packages :\n\n# Scientific and Data Manipulation Libraries :\n\nimport numpy as np\nimport pandas as pd\n\n# Data Viz & Regular Expression Libraries :\n\nimport matplotlib.pyplot as plt\nget_ipython().run_line_magic('matplotlib', 'inline')\n\n# Scikit-Learn ML Libraries :\n\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\n# Garbage Collection Libraries :\n\nimport gc\n\n# Boosting Algorithm Libraries :\n\nfrom xgboost                          import XGBClassifier\nfrom catboost                         import CatBoostClassifier\nfrom lightgbm                         import LGBMClassifier\nfrom sklearn.ensemble                 import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics                  import accuracy_score\nfrom sklearn.model_selection          import StratifiedKFold,KFold","2a574d3c":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","78d30987":"# Load data \n\ntrain = pd.read_csv('..\/input\/customer\/Train.csv')\ntest = pd.read_csv('..\/input\/customer\/Test.csv')\nsub = pd.read_csv('..\/input\/customer\/sample_submission.csv')","088b8356":"# Python Method 1 : Displays Data Information :\n\ndef display_data_information(data, data_types, dataframe_name):\n    print(\" Information of \",dataframe_name,\": Rows = \",data.shape[0],\"| Columns = \",data.shape[1],\"\\n\")\n    data.info()\n    print(\"\\n\")\n    for VARIABLE in data_types :\n        data_type = data.select_dtypes(include=[ VARIABLE ]).dtypes\n        if len(data_type) > 0 :\n            print(str(len(data_type))+\" \"+VARIABLE+\" Features\\n\"+str(data_type)+\"\\n\"  )        \n\n# Display Data Information of \"train\" :\n\ndata_types  = [\"float32\",\"float64\",\"int32\",\"int64\",\"object\",\"category\",\"datetime64[ns]\"]\ndisplay_data_information(train, data_types, \"train\")","4c2ca7ef":"# Display Data Information of \"test\" :\n\ndisplay_data_information(test, data_types, \"test\")","31ef8f05":"# Python Method 2 : Displays Data Head (Top Rows) and Tail (Bottom Rows) of the Dataframe (Table) :\n\ndef display_head_tail(data, head_rows, tail_rows):\n    display(\"Data Head & Tail :\")\n    display(data.head(head_rows).append(data.tail(tail_rows)))\n#     return True\n\n# Displays Data Head (Top Rows) and Tail (Bottom Rows) of the Dataframe (Table)\n# Pass Dataframe as \"train\", No. of Rows in Head = 3 and No. of Rows in Tail = 2 :\n\ndisplay_head_tail(train, head_rows=3, tail_rows=2)","b3e61924":"display_head_tail(test, head_rows=3, tail_rows=2)","52dd38c7":"# Python Method 3 : Displays Data Description using Statistics :\n\ndef display_data_description(data, numeric_data_types, categorical_data_types):\n    \n    print(\"Data Description :\")\n    display(data.describe( include = numeric_data_types))\n    print(\"\")\n    display(data.describe( include = categorical_data_types))\n\n# Display Data Description of \"train\" :\n\ndisplay_data_description(train, data_types[0:4], data_types[4:7])","4a26113e":"# Display Data Description of \"test\" :\n\ndisplay_data_description(test, data_types[0:4], data_types[4:7])","1b021e79":"# Checking Percentage(%) of Common ID's  between train and test data using Unique train values :\n\nprint(np.intersect1d(train['ID'], test['ID']).shape[0]\/train['ID'].nunique())\ncommon_ids = len(set(test['ID'].unique()).intersection(set(train['ID'].unique())))\nprint(\"Common IDs : \",common_ids)\n\n# Data Leak as out of 2627 Rows , there are 2332 ID's in Common\n\nprint(\"Unique IDs : \",test.shape[0] - common_ids)","8d378996":"testx = pd.merge(test,train,how='left', on = 'ID')","02d17338":"# Python Method 4 : Removes Data Duplicates while Retaining the First one - Similar to SQL DISTINCT :\n\ndef remove_duplicate(data):\n    \n    print(\"BEFORE REMOVING DUPLICATES - No. of Rows = \",data.shape[0])\n    data.drop_duplicates(keep=\"first\", inplace=True) \n    print(\"AFTER REMOVING DUPLICATES  - No. of Rows = \",data.shape[0])\n    \n    return data\n\n# Remove Duplicates from \"train\" data :\n\ntrain = remove_duplicate(train)\n\n# No Duplicates at all !!!","4564e8c8":"# # Python Method 5 : Fills or Imputes Missing values with Various Methods : \n\n# def fill_missing_values(data, fill_value, fill_types, columns, dataframe_name):\n    \n#     print(\"Missing Values BEFORE REMOVAL in \",dataframe_name,\" data\")\n#     display(data.isnull().sum())\n#     for column in columns :\n        \n#         # Fill Missing Values with Specific Value :\n#         if \"Value_Fill\" in fill_types :\n#             data[ column ] = data[ column ].fillna(fill_value)\n# #             print(\"Value_Fill\")\n\n#         # Fill Missing Values with Forward Fill  (Previous Row Value as Current Row in Table) :\n#         if \"Forward_Fill\" in fill_types :\n#             data[ column ] = data[ column ].ffill(axis = 0)\n# #             print(\"Forward_Fill\")\n\n#         # Fill Missing Values with Backward Fill (Next Row Value as Current Row in Table) :\n#         if \"Backward_Fill\" in fill_types :\n#             data[ column ] = data[ column ].bfill(axis = 0)\n# #             print(\"Backward_Fill\")\n    \n#     print(\"Missing Values AFTER REMOVAL in \",dataframe_name,\" data\")\n#     display(data.isnull().sum())\n    \n#     return data\n\n# fill_types = [ \"Forward_Fill\"]\n# fill_value = 0\n# # Fills or Imputes Missing values in \"Registration_Date\" Column with \"Forward_Fill\" Method in \"train\" : \n# train = fill_missing_values(train, fill_value, fill_types, [\"Registration_Date\"],\"train\")\n\n# # Fills or Imputes Missing values in \"Registration_Date\" Column with \"Forward_Fill\" Method in \"train\" :\n# test  = fill_missing_values(test, fill_value, fill_types, [\"Registration_Date\"],\"test\")","af805cca":"# Let LightGBM Classifier Handle the Issues :","11b95f62":"# Python Method 6 : Displays Unique Values in Each Column of the Dataframe(Table) :\n\ndef display_unique(data):\n    for column in data.columns :\n        \n        print(\"No of Unique Values in \"+column+\" Column are : \"+str(data[column].nunique()))\n        print(\"Actual Unique Values in \"+column+\" Column are : \"+str(data[column].sort_values(ascending=True,na_position='last').unique() ))\n        print(\"NULL Values :\")\n        print(data[ column ].isnull().sum())\n        print(\"Value Counts :\")\n        print(data[column].value_counts())\n        print(\"\")\n        \n# Displays Unique Values in Each Column of \"train\" :\n# Check \"train\" data for Values of each Column - Long Form :\n\ndisplay_unique(train)\n\n# Display this info in a Table Format - Improvements coming In Part 2","26f283ab":"# Check \"train\" data for Values of each Column - Short Form :\n# Use Whichever you feel good working with :\n\nfor i in train:\n    print(f\"column {i} unique values {train[i].unique()}\")","58c9ea6b":"# Concatenate train and test data into single DataFrame - df :\n\ntrain['is_train'] = 1\ntest['is_train'] = 0\ndf = pd.concat([train,test])","f4db2282":"# Convert 2 Categorical(String) Columns 'City_Type','Employer_Category' using Label Encode Technique :\n# Docs : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html\n# Label encode category values\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfor i in ['Gender' , 'Ever_Married' , 'Graduated','Profession','Spending_Score','Var_1'  ]:\n    le = LabelEncoder()\n    df[i] = le.fit_transform(df[i].astype('str'))","3436a6ef":"# Mapping Values to Label ENCODED Values :\n\ndf['Segmentation'] = df['Segmentation'].map({'A':0,'B':1,'C':2,'D':3})","48ec12ce":"# Get Back train data from df with a condition on column is_train == 1 :\n\ntrain = df[df['is_train'] == 1]","ef0bc626":"# split train into 5 folds and apply random forest and check accuracy of each fold\n\npredictor_train = train.drop(['Segmentation','is_train','ID'],axis=1)\ntarget_train    = train['Segmentation']","4a84be29":"predictor_test = test.drop(['is_train','ID'],axis=1)","65889067":"def data_encoding( encoding_strategy , encoding_data , encoding_columns ):\n    \n    if encoding_strategy == \"LabelEncoding\":\n        Encoder = LabelEncoder()\n        for column in encoding_columns :\n            encoding_data[ column ] = Encoder.fit_transform(tuple(encoding_data[ column ]))\n        \n    elif encoding_strategy == \"OneHotEncoding\":\n#         display(encoding_data[encoding_columns])\n        encoding_data = pd.get_dummies( encoding_data  )\n        \n    elif encoding_strategy == \"TargetEncoding\":\n        ## Code Coming soon\n        print(\"TargetEncoding\")\n\n    else :\n        encoding_data = pd.get_dummies( encoding_data[encoding_columns]  )\n        \n    dtypes_list =['float64','float32','int64','int32']\n    # BEST CODE : 0.6872386379302422\n#     encoding_data.astype( dtypes_list[0] ).dtypes # UNCOMMENTED EARLIER\n    # NEW CODE : 0.6872386379302422 - NO CHANGE !!!\n    # encoding_data.astype( dtypes_list[0] ).dtypes - COMMENTED NOW\n    \n    return encoding_data\n\nencoding_columns  = [ \"Gender\", \"Ever_Married\" , \"Graduated\", \"Profession\" , \"Spending_Score\", \"Var_1\" ]\nencoding_strategy = [ \"OneHotEncoding\", \"LabelEncoding\", \"TargetEncoding\", \"ELSE\"]\n\npredictor_train_encode = data_encoding( encoding_strategy[1] , predictor_train , encoding_columns )\npredictor_test_encode  = data_encoding( encoding_strategy[1] , predictor_test ,  encoding_columns )","95ba8d63":"print(\"predictor_train_encode SHAPE   : \",predictor_train_encode.shape)\ndisplay(\"predictor_train_encode COLUMNS : \",predictor_train_encode.head())\n\nprint(\"predictor_test_encode SHAPE   : \",predictor_test_encode.shape)\ndisplay(\"predictor_test_encode COLUMNS : \",predictor_test_encode.head())","8a6fec7a":"# Mention Categorical Values of the Light GBM Model to Handle :\ncategorical_features = [\"Gender\", \"Ever_Married\" ,\"Graduated\" ,\"Profession\" ,\"Spending_Score\" ,\"Var_1\" ]\n\nlgb_model = LGBMClassifier()\n\n# Apply Stratified K-Fold Cross Validation where K=5 or n_splits=5 :\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10)\nacc = []\n\n# Pass predictor_train,target_train for Cross Validation :\nfor fold,(t_id,v_id) in enumerate(kf.split(predictor_train,target_train)):\n    \n    # Split train and validation data :\n    tx = predictor_train.iloc[t_id]; ty = target_train.iloc[t_id]\n    vx = predictor_train.iloc[v_id]; vy = target_train.iloc[v_id]\n    \n    # Train\/Fit the Data to LighGBM Model :\n    lgb_model.fit(tx,ty, categorical_feature = categorical_features )\n    \n    # Predict the Validation Data to Train LighGBM Model :\n    val_y = lgb_model.predict(vx)\n    \n    # Get Accuracy Score on Validation Data for Each Fold :\n    acc_score = accuracy_score(vy,val_y)\n    acc.append(acc_score)\n    print(f\"fold {fold} accuracy {acc_score}\")\n\n# Get Mean of Accuracy Score on Validation Data for All 5 Folds :\nprint(f\"Mean accuracy score {np.mean(acc)}\")","17e6f99b":"# Tuned the Hyperparameters of LighGBM Classifier :\nlgb_model = LGBMClassifier(\n                                   boosting_type='gbdt', \n                                   max_depth=15, \n                                   learning_rate=0.15, \n                                   objective='multiclass', # Multi Class Classification\n                                   random_state=100,  \n                                   n_estimators=1000 ,\n                                   reg_alpha=0, \n                                   reg_lambda=1, \n                                   n_jobs=-1\n                                 )","ce836248":"# Mention Categorical Values of the Light GBM Model to Handle :\ncategorical_features = [\"Gender\", \"Ever_Married\" ,\"Graduated\" ,\"Profession\" ,\"Spending_Score\" ,\"Var_1\" ]\n\n# Apply Stratified K-Fold Cross Validation where K=5 or n_splits=5 :\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10)\nacc = []\n\n# Pass predictor_train,target_train for Cross Validation :\nfor fold,(t_id,v_id) in enumerate(kf.split(predictor_train,target_train)):\n    \n    # Split train and validation data :\n    tx = predictor_train.iloc[t_id]; ty = target_train.iloc[t_id]\n    vx = predictor_train.iloc[v_id]; vy = target_train.iloc[v_id]\n    \n    # Train\/Fit the Data to LighGBM Model :\n    lgb_model.fit(tx,ty, categorical_feature = categorical_features )\n    \n    # Predict the Validation Data to Train LighGBM Model :\n    val_y = lgb_model.predict(vx)\n    \n    # Get Accuracy Score on Validation Data for Each Fold :\n    acc_score = accuracy_score(vy,val_y)\n    acc.append(acc_score)\n    print(f\"fold {fold} accuracy {acc_score}\")\n\n# Get Mean of Accuracy Score on Validation Data for All 5 Folds :\nprint(f\"Mean accuracy score {np.mean(acc)}\")","74353b86":"def model_train_predict_submit( Classifiers_model_name, model_name ,X_train, y_train, X_test, target):\n    \n    categorical_features = [\"Gender\", \"Ever_Married\" ,\"Graduated\" ,\"Profession\" ,\"Spending_Score\" ,\"Var_1\"  ]\n    Classifiers_model_name.fit( X_train, y_train , categorical_feature = categorical_features )\n    final_predictions = Classifiers_model_name.predict( X_test )\n    print(final_predictions)  \n   \n    Result_Promoted = pd.DataFrame({'ID': sub['ID'], target : final_predictions})\n    Result_Promoted[ target ]=Result_Promoted[ target ].map({0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\" })\n    print(Result_Promoted[ target ].unique())\n    Result_Promoted.to_csv(model_name +\"_Labelling=Yes_Scaling=Yes\"+\".csv\",index=False)\n    return Result_Promoted\n\nmodel_name       = \"LGBM_Tuned_BEST\"\nmodel_classifier = lgb_model\nsub = model_train_predict_submit( model_classifier, model_name, predictor_train_encode,target_train, predictor_test_encode, target = 'Segmentation')","9cfb4c0b":"sub1 = pd.merge(sub,testx,how='left',on='ID')\nsub1.head()","bb42b481":"sub['segmentation2'] = sub1['Segmentation_y']\nsub.head()","c0f7bbbb":"sub['segmentation2'] = sub['segmentation2'].fillna('x')\nfor i in range(len(sub)):\n    if sub.iloc[i,2] != 'x':\n        sub.iloc[i,1] = sub.iloc[i,2]\n        \nsub[['ID','Segmentation']].to_csv('FINAL_LGBM_BEST_SUBMISSION_TUNED.csv',index = False)","98c4687c":"### **<center>\ud83d\ude0a Reached Rank 6 - Top 5 Private Score - Thanks for reading Friends. See you all in Part 2 for more Analysis and Modelling - ENCOURAGE if you liked this Notebook \ud83d\ude0a<\/center>**\n\n### **<center>\ud83d\ude0a For Learning Purpose - You can still participate in your free time to see your Public and Private Scores & Rank, though it won't reflect on Leaderboard \ud83d\ude0a<\/center>**\n\n### **<center>\ud83d\ude0a Ask your doubts & Share your thoughts, ideas & feedbacks in Comments below \ud83d\ude0a<\/center>**","3110bb4d":"## 7.  Data Encoding - Label Encoding :","0578b053":"## 2. Perform EDA (Exploratory Data Analysis) - Understanding the Datasets :    \n\n### 2.1 Explore Train and Test Data and get to know what each Column \/ Feature denotes :","fd0739da":"## 8.  Create Baseline ML Model :","e7385c4f":"## 1.  Understand the Problem Statement & Import Packages and Datasets :","a310514b":"## Steps for Applied Machine Learning (ML) for Hackathons :\n\n1.  Understand the Problem Statement & Import Packages and Datasets.  \n\n2.  Perform EDA (Exploratory Data Analysis) - Understanding the Datasets :\n\n       *       Explore Train and Test Data and get to know what each Column \/ Feature denotes.\n       *       Check for Imbalance of Target Column in Datasets.\n       *       Visualize Count Plots & Unique Values to infer from Datasets.\n            \n3.  Remove Duplicate Rows from Train Data if present.\n\n4.  Fill\/Impute Missing Values Continuous - Mean\/Median\/Any Specific Value & Categorical - Others\/ForwardFill\/BackFill.\n\n5.  Feature Engineering \n\n      *       Feature Selection - Selection of Most Important Existing Features.\n      *       Feature Creation  - Creation  of New Feature from the Existing Features.\n      \n6.  Split Train Data into Train and Validation Data with Predictors(Independent) & Target(Dependent).      \n7.  Data Encoding - Label Encoding, OneHot Encoding and Data Scaling - MinMaxScaler, StandardScaler, RobustScaler\n8.  Create Baseline ML Model for Multi Class Classification Problem\n9.  Improve ML Model,Fine Tune with MODEL Evaluation METRIC - \"Accuracy\" and Predict Traget \"Outcome\"\n10. Result Submission, Check Leaderboard & Improve \"Accuracy\" Score","2fda4514":"## 6.  Split Train Data into Train and Validation Data with Predictors(Independent) & Target(Dependent) :","a8f0647d":"### Multi - Class Classification Problem - Target has more than 2 Categories - \n### Target - Segmentation has 4 Values of Customers ['D' 'A' 'B' 'C']","c9c66589":"![Customer_RANK.jpg](attachment:Customer_RANK.jpg)","eeaaf753":"## 5.  Feature Engineering\n\n### 5.1 Feature Selection - Selection of Most Important Existing Features\n### 5.2 Feature Creation  - Creation  of New Features from the Existing Features \/ Predictors :","ca61f699":"## 4.  Fill\/Impute Missing Values Continuous - Mean\/Median\/Any Specific Value & Categorical - Others\/ForwardFill\/BackFill :","2d07d898":"![Customer_Seg.jpg](attachment:Customer_Seg.jpg)","0dcc63ac":"## 3.  Remove Duplicate Rows from Train data if present :","14b53677":"### DATASET can be downloaded here -> https:\/\/www.kaggle.com\/vetrirah\/customer","8fdb7f1c":"## 10. Result Submission, Check Leaderboard & Improve \"ACCURACY\" :","9fec4b3a":"## 9. Improve ML Model,Fine Tune with MODEL Evaluation METRIC - \"Accuracy\" and Predict Target \"Segmentation\" :"}}