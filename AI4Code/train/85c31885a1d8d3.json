{"cell_type":{"0679762c":"code","9477d774":"code","94da8127":"code","be9aec4e":"code","271db24c":"code","5326880e":"code","3ffef01a":"code","d0aa73df":"code","faa249b4":"code","8336a43e":"code","df6af59c":"code","c661764a":"code","d2b74564":"markdown","3b40e412":"markdown","7ef9a80a":"markdown","e7fa245f":"markdown","306a2256":"markdown","aeea5e48":"markdown","dd343ea9":"markdown","457532fe":"markdown","a4ee81a5":"markdown"},"source":{"0679762c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9477d774":"import pandas as pd\nimport numpy as np\n","94da8127":"df = pd.read_csv('..\/input\/calculating-flow-rate-from-pressure-measurements\/merged_tables.csv')\ndf","be9aec4e":"df.shape","271db24c":"df.dtypes","5326880e":"df['pressure-in'] = df['pressure-in'].str.replace(',','.').astype(float)\ndf['pressure-out'] = df['pressure-out'].str.replace(',','.').astype(float)\ndf.dtypes","3ffef01a":"null= df.isna().sum()\ndf.drop('time',axis=1,inplace=True)\nper_null= df.isna().sum()\/df.isna().count()*100\nper_null= round(per_null, 1)\nmissing_data= pd.concat([null, per_null], axis=1,keys=['number of missing values', '% of missig values'])\nmissing_data","d0aa73df":"df=df.interpolate()\ndf","faa249b4":"X = df.drop('flow',axis=1)\ny = df['flow']","8336a43e":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV,train_test_split\ngrid = {\n    \"n_estimators\":[100, 200, 500, 1000],\n    \"max_depth\":[None, 5],\n    \"max_features\":[\"auto\"],\n    \"min_samples_split\":[4, 6],\n    \"min_samples_leaf\":[1, 2, 4]\n}\nnp.random.seed(42)\n\n# Split data into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nregressor = RandomForestRegressor()\n\n#setup grid search cv\ngs_regressor = GridSearchCV(\n                            estimator=regressor,\n                            param_grid=grid,\n                            cv=5,\n                            verbose=2\n                            )\n\ngs_regressor.fit(X_train,y_train)\n\n","df6af59c":"y_preds = gs_regressor.predict(X_test)","c661764a":"from sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_preds,y_test)","d2b74564":"# Check missing values\n**drop time feature because we need to preduict the flow only with pressure-in and pressure-out **","3b40e412":"# Using GridSearchCV to find best parameters for random forest regression","7ef9a80a":"# Type cast objects to float","e7fa245f":"# Fill missing values with interpolation \n* check missing values between two values\n* consider the difference between two values and the number of missing values between them\n* devide the difference to the number of missing values to figure out the steps\n* start from first value step by step to reach the next value\n","306a2256":"# Split features and target ","aeea5e48":"# Predict the flow and check the evaluation","dd343ea9":"# Read Data","457532fe":"# Import Libraries","a4ee81a5":"# Check feature types "}}