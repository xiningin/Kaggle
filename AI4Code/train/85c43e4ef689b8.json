{"cell_type":{"05552260":"code","3ab4d7da":"code","109508b6":"code","85678e00":"code","5ef4ef51":"code","c1fb0920":"code","1b189587":"code","df041abc":"code","7783d06d":"code","a28fed37":"code","4647c0e3":"code","fd34e7d9":"code","fdc30a25":"code","a778e636":"code","be5ddb1c":"code","2f3e7ba8":"code","b5791db2":"code","aee8c1e3":"code","fef92667":"code","2f5f5d60":"code","52bb400e":"code","3f3de1ae":"code","452ee486":"code","008088b3":"code","4a14112b":"code","9899b3e0":"code","c1ac5279":"code","d1e2752b":"code","7ddb9699":"code","9a6011db":"code","d22fb392":"code","132fc5d6":"code","9a80bc36":"code","f70c25c4":"code","c7899e34":"code","e1e65042":"code","74b95254":"code","ef3d6347":"code","22561b75":"code","747bd737":"code","9ae6c8ed":"markdown","1ca62a61":"markdown","9b900287":"markdown","e7b0d858":"markdown"},"source":{"05552260":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\n\nfrom functools import partial\nimport os\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n## Metrics\nfrom sklearn.metrics import accuracy_score\nimport cv2\nfrom skimage.morphology import skeletonize\nfrom skimage.util import invert\nimport keras\nfrom keras.models import Sequential\n\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense,Flatten","3ab4d7da":"test_images_path=Path('..\/input\/arabic-hwr-ai-pro-intake1\/test')\ntest_csv=pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\ntest_csv.head()\n","109508b6":"test_images_path = pd.Series(sorted(list(test_images_path.glob(r'*.png'))), name='Filepath').astype(str)\ntest_images_path","85678e00":"train_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntrain_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/train')\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntrain_images_paths.head()","5ef4ef51":"img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = cv2.imread(train_images_paths.iloc[img_index[i]])\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1","c1fb0920":"k= cv2.imread(train_images_paths.iloc[img_index[8]],cv2.IMREAD_GRAYSCALE)\n\nplt.imshow(k)\nk.shape","1b189587":"img2=cv2.bilateralFilter(k, 35, 95, 95)\nplt.imshow(img2, cmap=plt.cm.gray)\n","df041abc":"thresh = 127\nim_bw =cv2.adaptiveThreshold(img2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2.5)\nplt.imshow(im_bw, cmap=plt.cm.gray)\nprint(im_bw.shape)","7783d06d":"zz = cv2.bilateralFilter(k, 35, 95, 95)\nplt.imshow(cv2.bilateralFilter(k, 35, 95, 95))","a28fed37":"bw = cv2.adaptiveThreshold(zz, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2.5)\nplt.imshow(bw)","4647c0e3":"print(k.shape)","fd34e7d9":"im_bw=im_bw\/255\nplt.imshow(im_bw, cmap=plt.cm.gray)","fdc30a25":" np.unique(im_bw, return_counts=True)","a778e636":"from skimage.morphology import skeletonize\nfrom skimage.util import invert\nimage = invert(im_bw)\nplt.imshow(image, cmap=plt.cm.gray)","be5ddb1c":" np.unique(image, return_counts=True)","2f3e7ba8":"skeleton = skeletonize(image)\nplt.imshow(image, cmap=plt.cm.gray)","b5791db2":"plt.imshow(skeleton, cmap=plt.cm.gray)","aee8c1e3":"plt.imshow(cv2.imread(train_images_paths.iloc[img_index[2]]))","fef92667":"print('Number of Instances in train_set =>', len(train_images_paths))\nprint('Number of Instances in train_labels =>', len(train_labels))\n\nprint()\n\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is =>', img.shape)","2f5f5d60":"kernel = np.array([[0, -1, 0],\n                   [-1, 5,-1],\n                   [0, -1, 0]])","52bb400e":"train_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((13440, 32, 32,1), dtype=np.float32)\n\nfor idx, path in enumerate(train_images_paths):\n    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n#     im_bw = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2.5) \n    image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\/255\n#     image = invert(image_sharp)\n#     skeleton = skeletonize(image)\n    train_full_set[idx] = image_sharp[:,:,np.newaxis]\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint('train_full_labels.shape =>', train_full_labels.shape)","3f3de1ae":"plt.imshow(train_full_set[1],cmap=plt.cm.gray)","452ee486":"X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.2, shuffle=True, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)","008088b3":"y_train = keras.utils.np_utils.to_categorical(y_train, 29)\ny_valid = keras.utils.np_utils.to_categorical(y_valid, 29)","4a14112b":"y_train","9899b3e0":"model = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=3, padding='same', input_shape=(32, 32, 1), kernel_initializer='uniform', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='uniform', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='uniform', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='uniform', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(.15))\n#model.add(Dropout(.15))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(.10))\n#Fully connected final layer\nmodel.add(Dense(29, activation='softmax'))\n\n# Compile model\n#model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)","c1ac5279":"# model = Sequential()\n# model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(32, 32, 1)))\n# model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n# model.add(Dropout(0.2))\n\n# model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n# model.add(Dropout(0.2))\n\n# model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n# model.add(Dropout(0.25))\n\n# model.add(Flatten())\n\n# model.add(Dense(64, activation='relu'))\n# model.add(Dropout(.15))\n# #model.add(Dropout(.15))\n# model.add(Dense(32, activation='relu'))\n# model.add(Dropout(.10))\n\n# model.add(Dense(29, activation='softmax'))","d1e2752b":"from tensorflow import keras","7ddb9699":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","9a6011db":"model.summary()","d22fb392":"from keras.callbacks import ModelCheckpoint  ","132fc5d6":"\ncheckpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)","9a80bc36":"callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)","f70c25c4":"history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=200, batch_size=30, callbacks=[checkpointer,callback])","c7899e34":"pd.DataFrame(history.history).plot(figsize=(10, 6))","e1e65042":"test_full_set = np.empty((3360, 32, 32,1), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(test_images_path):\n    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n#     im_bw = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2.5) \n    image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\/255\n#     image = invert(image_sharp)\n#     skeleton = skeletonize(image)\n    test_full_set[idx] = image_sharp[:,:,np.newaxis]\nprint('test_full_set.shape =>', test_full_set.shape)","74b95254":"model.load_weights('weights.hdf5')","ef3d6347":"y_preds_classes = np.argmax(model.predict(test_full_set), axis=-1)","22561b75":"test_csv['label'] = y_preds_classes","747bd737":"test_csv[['id', 'label']].to_csv('\/kaggle\/working\/submission.csv', index=False)","9ae6c8ed":"## Model Training","1ca62a61":"## Split the Data","9b900287":"## Loading the Data and Look at the Big Picture","e7b0d858":"## Explore the Data"}}