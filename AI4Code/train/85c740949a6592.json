{"cell_type":{"2b8240bb":"code","2d29513a":"code","842d51d5":"code","4141f730":"code","b83e77e6":"code","0240e196":"code","f6e7f9a9":"code","d0b62172":"code","3f7131f7":"code","40a2c523":"code","9fdeff95":"markdown","e7114840":"markdown","50d4a95f":"markdown","8b693572":"markdown","71d19168":"markdown","7839016b":"markdown"},"source":{"2b8240bb":"!pip install pmdarima\n!pip install pydlm","2d29513a":"# libraries\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\n\nimport pmdarima as pm # using autoarima; can't be bothered with manual parameter search :)\nfrom fbprophet import Prophet\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom pydlm import dlm, seasonality\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nsns.set_style(\"whitegrid\")\nmpl.rcParams['figure.figsize'] = (15, 7)\n\n# PARAMETERS\nyears_to_predict = 3\nscale = True\n\nwarnings.filterwarnings(\"ignore\")","842d51d5":"scaler = MinMaxScaler(feature_range=(-1,1))\n\nclimate_df = pd.read_csv(\"\/kaggle\/input\/climate-change-earth-surface-temperature-data\/GlobalLandTemperaturesByCountry.csv\")\n\n# data subset -- that's what we'll be working with\naus_df = (\n    climate_df\n    .query(\"Country == 'Australia' & AverageTemperature == AverageTemperature & dt > '1980-01-01'\")\n    .assign(\n        date = lambda d: pd.to_datetime(d.dt),\n        k = lambda d: 273.15 + d.AverageTemperature,\n        latest_date = lambda d: d.date.max(),\n        years_back = lambda d: (d.latest_date - d.date).dt.days\/365.25,\n        group = lambda d: d.years_back.map(lambda x: \"test\" if x < years_to_predict else \"train\")\n    )\n    .sort_values(\"date\")\n    [[\"date\",\"k\",\"group\"]]\n)\n\nif scale:\n    scaler.fit(aus_df.query(\"group == 'train'\")[[\"k\"]])\n    aus_df[\"k\"] = np.squeeze(scaler.transform(aus_df[[\"k\"]]))\n\ntest_df, train_df = [x for _, x in aus_df.groupby(\"group\")]\n\nax = sns.lineplot(\"date\", \"k\", hue=\"group\", data=aus_df)\nax.set_title(\"Australian Monthly Temperatures\")\n;","4141f730":"# take a few minutes...\narima_model = pm.auto_arima(train_df.k, seasonal=True, m=12)","b83e77e6":"arima_forecasts_df = pd.DataFrame({\"k\": arima_model.predict(len(test_df)), \"group\": \"ARIMA\"})\narima_forecasts_df[\"date\"] = test_df[\"date\"].values\nax = sns.lineplot(\"date\", \"k\", hue=\"group\", data=pd.concat([aus_df.query(\"date > '2008'\"), arima_forecasts_df], axis=0))\nax.set_title(\"ARIMA Forecasts\")\n;","0240e196":"prophet_model = Prophet()\nprophet_model.fit(train_df.rename(columns={\"date\": \"ds\", \"k\": \"y\"}))\nprophet_forecasts_df = prophet_model.make_future_dataframe(periods=len(test_df), freq=\"m\", include_history=False)\nprophet_forecasts_df[\"ds\"] = prophet_forecasts_df[\"ds\"] + pd.offsets.MonthBegin(0)\nprophet_forecasts_df = (prophet_model\n                        .predict(prophet_forecasts_df)\n                        .rename(columns={\"ds\": \"date\", \"yhat\": \"k\"})\n                        .assign(group = \"Prophet\")\n                        [[\"date\", \"k\", \"group\"]])\n\nax = sns.lineplot(\"date\", \"k\", hue=\"group\", data=pd.concat([aus_df.query(\"date > '2008'\"), prophet_forecasts_df], axis=0))\nax.set_title(\"Prophet Forecasts\")\n;","f6e7f9a9":"# making a different training data\nforecast_n_steps = len(test_df)\nhistory_length = 100\n\n# create train\/validation\/prediction datasets\ntrain_matrix = np.empty((0, 1, history_length), float)\nlabel_matrix = np.empty((0, 1, forecast_n_steps), float)\nfor i in range(history_length, len(train_df)-forecast_n_steps):\n    train_matrix_iter = np.expand_dims(train_df[(i-history_length):i].k.values.reshape((1, history_length)), axis=0)\n    label_matrix_iter = np.expand_dims(train_df[i:(i+forecast_n_steps)].k.values.reshape((1, forecast_n_steps)), axis=0)\n    train_matrix = np.append(train_matrix, train_matrix_iter, axis=0)\n    label_matrix = np.append(label_matrix, label_matrix_iter, axis=0)\n\ntrain_matrix, test_matrix, train_label_matrix, test_label_matrix = train_test_split(train_matrix, label_matrix, train_size=0.8)   \n    \ntrain_ds = tf.data.Dataset.from_tensor_slices((train_matrix, train_label_matrix)).batch(10)\nvalid_ds = tf.data.Dataset.from_tensor_slices((test_matrix,  test_label_matrix)).batch(10)\nprediction_array = np.expand_dims(train_df.tail(history_length).k.values.reshape(1, history_length), axis=0)","d0b62172":"lstm_model = tf.keras.Sequential([\n    layers.LSTM(64, return_sequences=True, input_shape=(1, history_length)),\n    layers.LSTM(16, activation=\"relu\"),\n    #layers.Flatten(),\n    layers.Dense(forecast_n_steps, activation=\"tanh\")\n])\nlstm_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01), loss=\"mae\", metrics=[\"mse\"])\nlstm_model.fit(train_ds, epochs=100, verbose=0, validation_data=valid_ds);","3f7131f7":"lstm_forecasts_df = test_df.copy()\nlstm_forecasts_df[\"group\"] = \"LSTM\"\nlstm_forecasts_df[\"k\"] = np.squeeze(lstm_model.predict(prediction_array))\nax = sns.lineplot(\"date\", \"k\", hue=\"group\", data=pd.concat([aus_df.query(\"date > '2008'\"), lstm_forecasts_df], axis=0))\nax.set_title(\"LSTM Forecasts\")\n;","40a2c523":"(\n    pd.merge(\n        pd.concat([arima_forecasts_df, prophet_forecasts_df, lstm_forecasts_df], axis=0),\n        test_df.drop(\"group\", axis=1).rename(columns={\"k\": \"actual\"}), how=\"inner\", on =\"date\"\n    )\n    .assign(squared_error = lambda d: (d.k - d.actual)**2)\n    .groupby(\"group\")[\"k\"]\n    .mean()\n    .sort_values()\n)","9fdeff95":"# Approach 3: LSTM with TF\nThis approach turned out to be quite difficult to train!","e7114840":"# Comparison","50d4a95f":"# Approach 2: Prophet","8b693572":"# Neural Forecasting\n\nThe purpose of this notebook is to generate forecasts of Ausralian temperatures using (1) a standard ARIMA, (2), Prophet,  and (3) An LSTM model with Tensorflow. This notebook follows [NN tutorial](https:\/\/www.tensorflow.org\/tutorials\/structured_data\/time_series).","71d19168":"# Setup","7839016b":"# Approach 1: ARIMA"}}