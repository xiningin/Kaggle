{"cell_type":{"b0f3b6da":"code","9b635347":"code","6e983388":"code","7d0e8911":"code","c35efc63":"code","7e222280":"code","bea4ec5d":"code","66daac66":"code","144b9dd4":"code","6fcb75a6":"code","f145d08f":"code","9d55ffeb":"code","4abc8388":"code","55e45325":"code","83ecc84c":"markdown","2354e18c":"markdown","f61e071f":"markdown","661367ca":"markdown","bfd6577a":"markdown","148fc1fc":"markdown","cca8d95b":"markdown","ae9c55c6":"markdown","ee793691":"markdown"},"source":{"b0f3b6da":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport fastai\nfrom fastai.vision import *\nfrom fastai.callbacks import TrackerCallback, SaveModelCallback\nimport os\nfrom sklearn.model_selection import KFold\nfrom radam import *\nfrom csvlogger import *\nfrom mish_activation import *\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfastai.__version__","9b635347":"sz = 128\nbs = 128\nnfolds = 4 #keep the same split as the initial dataset\nfold = 0\nSEED = 2019\nTRAIN = '..\/input\/grapheme-imgs-128x128\/'\nLABELS = '..\/input\/bengaliai-cv19\/train.csv'\narch = models.resnet18\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","6e983388":"arch","7d0e8911":"df = pd.read_csv(LABELS)\nnunique = list(df.nunique())[1:-1]\nprint(nunique)\ndf.head()","c35efc63":"stats = ([0.0692], [0.2051])\ndata = (ImageList.from_df(df, path='.', folder=TRAIN, suffix='.png', \n        cols='image_id', convert_mode='L')\n        .split_by_idx(range(fold*len(df)\/\/nfolds,(fold+1)*len(df)\/\/nfolds))\n        .label_from_df(cols=['grapheme_root','vowel_diacritic','consonant_diacritic'])\n        .transform(get_transforms(do_flip=False,max_warp=0.1), size=sz, padding_mode='zeros')\n        .databunch(bs=bs)).normalize(stats)\n\ndata.show_batch()","7e222280":"class Head(nn.Module):\n    def __init__(self, nc, n, ps=0.5):\n        super().__init__()\n        layers = [AdaptiveConcatPool2d(), Mish(), Flatten()] + \\\n            bn_drop_lin(nc*2, 512, True, ps, Mish()) + \\\n            bn_drop_lin(512, n, True, ps)\n        self.fc = nn.Sequential(*layers)\n        self._init_weight()\n        \n    def _init_weight(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                torch.nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1.0)\n                m.bias.data.zero_()\n        \n    def forward(self, x):\n        return self.fc(x)\n\n#change the first conv to accept 1 chanel input\nclass Rnet_1ch(nn.Module):\n    def __init__(self, arch=arch, n=nunique, pre=True, ps=0.5):\n        super().__init__()\n        m = arch(True) if pre else arch()\n        \n        conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        w = (m.conv1.weight.sum(1)).unsqueeze(1)\n        conv.weight = nn.Parameter(w)\n        \n        self.layer0 = nn.Sequential(conv, m.bn1, nn.ReLU(inplace=True))\n        self.layer1 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n            m.layer1)\n        self.layer2 = nn.Sequential(m.layer2)\n        self.layer3 = nn.Sequential(m.layer3)\n        self.layer4 = nn.Sequential(m.layer4)\n        self.avgpool = nn.AdaptiveAvgPool2d((1,1)) # m.avgpool\n        \n        # nc = self.layer4[-1].weight.shape[0]\n        nc = 512\n        self.head1 = Head(nc,n[0])\n        self.head2 = Head(nc,n[1])\n        self.head3 = Head(nc,n[2])\n        to_Mish(self.layer0), to_Mish(self.layer1), to_Mish(self.layer2)\n        to_Mish(self.layer3), to_Mish(self.layer4)\n        \n    def forward(self, x):    \n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        # x = x.view(x.size(0),-1)\n        x1 = self.head1(x)\n        x2 = self.head2(x)\n        x3 = self.head3(x)\n        \n        return x1,x2,x3","bea4ec5d":"class Loss_combine(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, input, target):\n        x1,x2,x3 = input\n        y = target.long()\n        return 2.0*F.cross_entropy(x1,y[:,0]) + F.cross_entropy(x2,y[:,1]) + \\\n          F.cross_entropy(x3,y[:,2])","66daac66":"class Metric_idx(Callback):\n    def __init__(self, idx, average='macro'):\n        super().__init__()\n        self.idx = idx\n        self.n_classes = 0\n        self.average = average\n        self.cm = None\n        self.eps = 1e-9\n        \n    def on_epoch_begin(self, **kwargs):\n        self.tp = 0\n        self.fp = 0\n        self.cm = None\n    \n    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n        last_output = last_output[self.idx]\n        last_target = last_target[:,self.idx]\n        preds = last_output.argmax(-1).view(-1).cpu()\n        targs = last_target.long().cpu()\n        \n        if self.n_classes == 0:\n            self.n_classes = last_output.shape[-1]\n            self.x = torch.arange(0, self.n_classes)\n        cm = ((preds==self.x[:, None]) & (targs==self.x[:, None, None])) \\\n          .sum(dim=2, dtype=torch.float32)\n        if self.cm is None: self.cm =  cm\n        else:               self.cm += cm\n\n    def _weights(self, avg:str):\n        if self.n_classes != 2 and avg == \"binary\":\n            avg = self.average = \"macro\"\n            warn(\"average=`binary` was selected for a non binary case. \\\n                 Value for average has now been set to `macro` instead.\")\n        if avg == \"binary\":\n            if self.pos_label not in (0, 1):\n                self.pos_label = 1\n                warn(\"Invalid value for pos_label. It has now been set to 1.\")\n            if self.pos_label == 1: return Tensor([0,1])\n            else: return Tensor([1,0])\n        elif avg == \"micro\": return self.cm.sum(dim=0) \/ self.cm.sum()\n        elif avg == \"macro\": return torch.ones((self.n_classes,)) \/ self.n_classes\n        elif avg == \"weighted\": return self.cm.sum(dim=1) \/ self.cm.sum()\n        \n    def _recall(self):\n        rec = torch.diag(self.cm) \/ (self.cm.sum(dim=1) + self.eps)\n        if self.average is None: return rec\n        else:\n            if self.average == \"micro\": weights = self._weights(avg=\"weighted\")\n            else: weights = self._weights(avg=self.average)\n            return (rec * weights).sum()\n    \n    def on_epoch_end(self, last_metrics, **kwargs): \n        return add_metrics(last_metrics, self._recall())\n    \nMetric_grapheme = partial(Metric_idx,0)\nMetric_vowel = partial(Metric_idx,1)\nMetric_consonant = partial(Metric_idx,2)\n\nclass Metric_tot(Callback):\n    def __init__(self):\n        super().__init__()\n        self.grapheme = Metric_idx(0)\n        self.vowel = Metric_idx(1)\n        self.consonant = Metric_idx(2)\n        \n    def on_epoch_begin(self, **kwargs):\n        self.grapheme.on_epoch_begin(**kwargs)\n        self.vowel.on_epoch_begin(**kwargs)\n        self.consonant.on_epoch_begin(**kwargs)\n    \n    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n        self.grapheme.on_batch_end(last_output, last_target, **kwargs)\n        self.vowel.on_batch_end(last_output, last_target, **kwargs)\n        self.consonant.on_batch_end(last_output, last_target, **kwargs)\n        \n    def on_epoch_end(self, last_metrics, **kwargs): \n        return add_metrics(last_metrics, 0.5*self.grapheme._recall() +\n                0.25*self.vowel._recall() + 0.25*self.consonant._recall())","144b9dd4":"#fix the issue in fast.ai of saving gradients along with weights\n#so only weights are written, and files are ~4 times smaller\n\nclass SaveModelCallback(TrackerCallback):\n    \"A `TrackerCallback` that saves the model when monitored quantity is best.\"\n    def __init__(self, learn:Learner, monitor:str='valid_loss', mode:str='auto',\n                 every:str='improvement', name:str='bestmodel'):\n        super().__init__(learn, monitor=monitor, mode=mode)\n        self.every,self.name = every,name\n        if self.every not in ['improvement', 'epoch']:\n            warn(f'SaveModel every {self.every} is invalid, falling back to \"improvement\".')\n            self.every = 'improvement'\n                 \n    def jump_to_epoch(self, epoch:int)->None:\n        try: \n            self.learn.load(f'{self.name}_{epoch-1}', purge=False)\n            print(f\"Loaded {self.name}_{epoch-1}\")\n        except: print(f'Model {self.name}_{epoch-1} not found.')\n\n    def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n        \"Compare the value monitored to its best score and maybe save the model.\"\n        if self.every==\"epoch\": \n            #self.learn.save(f'{self.name}_{epoch}')\n            torch.save(learn.model.state_dict(),f'{self.name}_{epoch}.pth')\n        else: #every=\"improvement\"\n            current = self.get_monitor_value()\n            if current is not None and self.operator(current, self.best):\n                #print(f'Better model found at epoch {epoch} \\\n                #  with {self.monitor} value: {current}.')\n                self.best = current\n                #self.learn.save(f'{self.name}')\n                torch.save(learn.model.state_dict(),f'{self.name}.pth')\n\n    def on_train_end(self, **kwargs):\n        \"Load the best model.\"\n        if self.every==\"improvement\" and os.path.isfile(f'{self.name}.pth'):\n            #self.learn.load(f'{self.name}', purge=False)\n            self.model.load_state_dict(torch.load(f'{self.name}.pth'))","6fcb75a6":"model = Rnet_1ch()\nlearn = Learner(data, model, loss_func=Loss_combine(), opt_func=Over9000,\n        metrics=[Metric_grapheme(),Metric_vowel(),Metric_consonant(),Metric_tot()])\nlogger = CSVLogger(learn,f'log{fold}')\nlearn.clip_grad = 1.0\nlearn.split([model.head1])\nlearn.unfreeze()","f145d08f":"model","9d55ffeb":"learn.summary()","4abc8388":"learn.fit_one_cycle(10, max_lr=slice(0.2e-2,1e-2), wd=[1e-3,0.1e-1], pct_start=0.0, div_factor=100, \ncallbacks = [logger, SaveModelCallback(learn,monitor='metric_tot',mode='max',name=f'model_{fold}')])\n#metrics: Metric_grapheme, Metric_vowel, Metric_consonant, Metric_tot (competition metric)","55e45325":"torch.save(learn.model.state_dict(),'resnet18_model_fold_{}.pth'.format(fold))","83ecc84c":"# Loss","2354e18c":"Cross entropy loss is applied independently to each part of the prediction and the result is summed with the corresponding weight.","f61e071f":"# Disclaimer\nThis kernel is to use a different architecture `resnet18`, thanks to the nice kernel by [@iafoss](https:\/\/www.kaggle.com\/iafoss). `resnet18` is light and can be run very quickly for each epoch.\n\nThe original kernel using `densenet121` can be found [here](https:\/\/www.kaggle.com\/iafoss\/grapheme-fast-ai-starter-lb-0-9611).\n\n# Description\nGreetings, this kernel provides fast.ai starter code for Bengali.AI Handwritten Grapheme Classification competition.\n\nThe task proposed in this competition is recognition of handwritten Bengali letters. In contrast to similar competitions such as [mnist digit recognition](https:\/\/www.kaggle.com\/c\/digit-recognizer) or the recent [Kannada MNIST](https:\/\/www.kaggle.com\/c\/Kannada-MNIST), Bengali alphabet is quite complex and may include ~13,000 different grapheme variations. Fortunately, each grapheme can be decomposed into 3 parts: grapheme_root, vowel_diacritic, and consonant_diacritic (168, 11, and 7 independent classes, respectively). Therefore, the task of grapheme recognition is significantly simplified in comparison with 13k-way classification. Though, additional consideration may be required for this multitask classification, like checking if 3 independent models, or a single model one head, or a single model with 3 heads (this kernel) works the best. This kernel is mostly based on [my findings](https:\/\/www.kaggle.com\/c\/Kannada-MNIST\/discussion\/122430) in a recent Kannada MNIST toy competition.\n\nIn addition to this kernel I have prepared a [code](https:\/\/www.kaggle.com\/iafoss\/image-preprocessing-128x128) for data preprocessing and generation of cropped images rescaled to 128x128. Because the data has much higher resolution than MNIST or CIFAR, the things that work there may be less applicable to this data, while ImageNet based solutions should be more suitable. So, I've choosen DenseNet121 as a starter network. In addition to this kernel I will prepare a submission kernel posted separately.","661367ca":"# Training","bfd6577a":"# Data","148fc1fc":"# Model","cca8d95b":"The code below computes the competition metric and recall macro metrics for individual components of the prediction. The code is partially borrowed from fast.ai.","ae9c55c6":"The starter model is based on `resnet18`. Overall design is similar to the original kernel. The first conv is replaced to accommodate for 1 channel input, and the corresponding pretrained weights are summed. ReLU activation in the head is replaced by Mish, which works noticeably better for all tasks I checked it so far. Since each portion of the prediction (grapheme_root, vowel_diacritic, and consonant_diacritic) is quite independent concept, I create a separate head for each of them (though I didn't do a comparison with one head solution).","ee793691":"I have performed a check of different optimizers and schedules on a [similar task](https:\/\/www.kaggle.com\/c\/Kannada-MNIST\/discussion\/122430), and [Over9000 optimizer](https:\/\/github.com\/mgrankin\/over9000) cosine annealing **without warm-up** worked the best. Freezing the backbone at the initial stage of training didn't give me any advantage in that test, so here I perform the training straight a way with discriminative learning rate (smaller lr for backbone)."}}