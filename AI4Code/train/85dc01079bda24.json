{"cell_type":{"9c676bb5":"code","a65d4091":"code","b698e7ae":"code","61253d74":"code","21f09667":"code","67688b6a":"code","584a7c22":"code","0c2fd551":"code","166f8122":"code","72e722c6":"code","e8dd8983":"code","64d34352":"code","18de35ba":"code","6430bbb8":"markdown"},"source":{"9c676bb5":"import os\nimport sys\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFilter\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix\nimport matplotlib.pyplot as plt\n\nnp.random.seed(100)\nLEVEL = 'level_1'","a65d4091":"def read_all(folder_path, key_prefix=\"\"):\n    '''\n    It returns a dictionary with 'file names' as keys and 'flattened image arrays' as values.\n    '''\n    print(\"Reading:\")\n    images = {}\n    files = os.listdir(folder_path)\n    for i, file_name in tqdm_notebook(enumerate(files), total=len(files)):\n        file_path = os.path.join(folder_path, file_name)\n        image_index = key_prefix + file_name[:-4]\n        image = Image.open(file_path)\n        image = image.convert(\"L\")\n        images[image_index] = np.array(image.copy()).flatten()\n        image.close()\n    return images","b698e7ae":"languages = ['ta', 'hi', 'en']\n\nimages_train = read_all(\"..\/input\/level_1_train\/\"+LEVEL+\"\/\"+\"background\", key_prefix='bgr_') # change the path\nfor language in languages:\n  images_train.update(read_all(\"..\/input\/level_1_train\/\"+LEVEL+\"\/\"+language, key_prefix=language+\"_\" ))\nprint(len(images_train))\n\nimages_test = read_all(\"..\/input\/level_1_test\/kaggle_\"+LEVEL, key_prefix='') # change the path\nprint(len(images_test))","61253d74":"list(images_test.keys())[:5]","21f09667":"X_train = []\nY_train = []\nfor key, value in images_train.items():\n    X_train.append(value)\n    if key[:4] == \"bgr_\":\n        Y_train.append(0)\n    else:\n        Y_train.append(1)\n\nID_test = []\nX_test = []\nfor key, value in images_test.items():\n  ID_test.append(int(key))\n  X_test.append(value)\n  \n        \nX_train = np.array(X_train)\nY_train = np.array(Y_train)\nX_test = np.array(X_test)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","67688b6a":"scaler = StandardScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_test = scaler.transform(X_test)","584a7c22":"print(X_scaled_train.shape)","0c2fd551":"class FFSN_Generic:\n  \n  def __init__(self, n_inputs, hidden_sizes=[2]):#n_inputs----no. of featurees\n    self.nx = n_inputs\n    self.ny = 1\n    self.nh = len(hidden_sizes)\n    self.sizes = [self.nx] + hidden_sizes + [self.ny]\n    \n    self.W = {}\n    self.B = {}\n    for i in range(self.nh+1):\n      self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n      self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n  \n  def sigmoid(self, X):\n    return 1.0\/(1.0 + np.exp(-X))\n  \n  def forward_pass(self, X):\n    self.A = {}\n    self.H = {}\n    self.H[0] = X# X----(n,256)\n    for i in range(self.nh+1):\n      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]#  (n,256)*(256,2)----(n,2)\n      self.H[i+1] = self.sigmoid(self.A[i+1])\n    return self.H[self.nh+1]\n  \n  def grad_sigmoid(self, X):\n    return X*(1-X) \n    \n  def grad(self, X, Y):\n    self.forward_pass(X)\n    self.dW = {}\n    self.dB = {}\n    self.dH = {}\n    self.dA = {}\n    self.Y=Y.reshape(-1,1)\n    L = self.nh + 1\n    self.dA[L] = (self.H[L] - self.Y)#(900,1)\n    for k in range(L, 0, -1):\n      self.dW[k] = np.matmul(self.H[k-1].T, self.dA[k])#(2,900)*(900,1)---(2,1)\n      self.dB[k] = np.sum(self.dA[k],axis=0).reshape(1,-1)#(1,1)\n      self.dH[k-1] = np.matmul(self.dA[k], self.W[k].T)# (900,1)*(1,2)----(900,2)\n      self.dA[k-1] = np.multiply(self.dH[k-1], self.grad_sigmoid(self.H[k-1]))#(900,2)*(900,2)----(900,2)\n    \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, display_loss=False):\n    \n    # initialise w, b\n    if initialise:\n      for i in range(self.nh+1):\n        self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n        self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n      \n    if display_loss:\n      loss = {}\n    \n    for e in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      self.grad(X, Y)\n      \n        \n      m = X.shape[1]\n      for i in range(self.nh+1):\n        self.W[i+1] -= learning_rate * self.dW[i+1] \/ m\n        self.B[i+1] -= learning_rate * self.dB[i+1] \/ m\n      \n      if display_loss:\n        Y_pred = self.predict(X)\n        loss[e] = mean_squared_error(Y_pred, Y)\n    \n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      plt.ylabel('Mean Squared Error')\n      plt.show()\n      \n  def predict(self, X):\n    Y_pred = []\n    for x in X:\n      y_pred = self.forward_pass(x)\n      Y_pred.append(y_pred)\n    return np.array(Y_pred).squeeze()","166f8122":"print(X_scaled_train.shape, Y_train.shape)","72e722c6":"ff= FFSN_Generic(256,[5,5])\nff.fit(X_scaled_train, Y_train, epochs=1000,learning_rate=0.1,display_loss=True)","e8dd8983":"Y_pred_train=ff.predict(X_scaled_train)\nY_pred_train_binarised=(Y_pred_train>=0.5).astype('int').ravel()\nY_pred_test=ff.predict(X_scaled_test)\nY_pred_test_binarised=(Y_pred_test>=0.5).astype('int').ravel()\ntraining_accuracy=accuracy_score(Y_train,Y_pred_train_binarised)\nprint(training_accuracy)","64d34352":"\n# test_accuracy=accuracy_score(y_test,Y_pred_test_binarised)","18de35ba":"Y_pred_test = ff.predict(X_scaled_test)\nY_pred_binarised_test = (Y_pred_test >= 0.5).astype(\"int\").ravel()\n\nsubmission = {}\nsubmission['ImageId'] = ID_test\nsubmission['Class'] = Y_pred_binarised_test\n\nsubmission = pd.DataFrame(submission)\nsubmission = submission[['ImageId', 'Class']]\nsubmission = submission.sort_values(['ImageId'])\nsubmission.to_csv(\"submisision.csv\", index=False)","6430bbb8":"## Sample Submission"}}