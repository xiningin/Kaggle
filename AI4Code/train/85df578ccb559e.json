{"cell_type":{"27afffd7":"code","91061dee":"code","3b09f409":"code","e617e06d":"code","c0cbe002":"code","a50dc154":"code","2ec7ca80":"code","f9299f83":"code","666cdbd2":"code","f951d936":"code","9327ecfd":"code","3acda5a7":"code","afc0b2c9":"code","6628003d":"code","1b64d21b":"code","8322a69d":"code","0a696250":"code","94fd2897":"code","ca2a9989":"code","3f5fbb23":"code","fcf8c74a":"code","27589b02":"code","5d114036":"code","244062f7":"code","532b4503":"code","48d65ed9":"code","d8a51469":"code","fda12898":"code","1304275f":"code","3507a8eb":"code","eb459257":"code","28dd78e2":"code","254e0a04":"code","d71ae511":"code","5f62f94d":"code","7b5c8572":"code","a91af1cc":"code","44759c96":"code","ce6e4938":"code","00686a5b":"code","6a79395e":"code","ee19ffab":"code","b216ade7":"code","a742a1db":"code","d1815f59":"code","90550e78":"code","5013342c":"code","9053daff":"code","2ba5f044":"code","58a004b9":"code","7a485471":"code","582ef11d":"code","221fe7f2":"code","ca9134da":"code","559cf08b":"code","1a1f0dc1":"code","3707d4a5":"code","3db90fa8":"code","61884c4a":"code","26760efd":"code","27604693":"code","834db99b":"code","296e19c1":"code","81607dd2":"code","5f70efee":"code","37c192f5":"code","15faa533":"code","c1163bd4":"code","fbc7f641":"code","40960dec":"code","bf6b6bea":"code","0bd7cb88":"code","654f3cdf":"code","02d44bdc":"markdown","7ae0c86f":"markdown","b59f9d2c":"markdown","d968069e":"markdown","1823555d":"markdown","9d230581":"markdown","8227b356":"markdown","caf2443e":"markdown","113ca11c":"markdown","27365fed":"markdown","d2025fba":"markdown","487b16ef":"markdown","e5bd64da":"markdown","296f8ad8":"markdown","a21c9fa7":"markdown","8359be9c":"markdown","b80a97ec":"markdown","d727fb46":"markdown","43696762":"markdown","2b1d2aa3":"markdown","8283f67c":"markdown","58cb58e8":"markdown","0673a9b3":"markdown","1e93230d":"markdown","e89e9b8f":"markdown","66f81541":"markdown","8bb33df2":"markdown","ed15bafa":"markdown","414e0611":"markdown","3c40da7d":"markdown","7afc3f66":"markdown","c57f8427":"markdown","2379c57e":"markdown","1cbecacc":"markdown"},"source":{"27afffd7":"import warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\nimport os\nimport re\nimport numpy as np\nimport pandas as pd\nfrom tqdm.autonotebook import tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nimport unidecode\nimport codecs\nfrom wordcloud import WordCloud, STOPWORDS\nfrom fuzzywuzzy import fuzz\nimport cudf\nimport cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import Counter\nfrom cuml.common.sparsefuncs import csr_row_normalize_l2\nimport gc","91061dee":"np.random.seed(0)\nnlp = spacy.load('en')#, disable=[\"tagger\", \"parser\", \"ner\"])","3b09f409":"def plot_bar_chart(x, y, title, rotation_angle=45):\n    plt.figure(figsize = (20, 15))\n    sns.barplot(x=x, y=y).set_title(title)\n    plt.xticks(rotation=rotation_angle)\n    plt.show()","e617e06d":"def plot_images(dataframe, column_name, value):\n    '''\n    Plot images using image_path, based on the column & value filter\n    '''\n    plt.figure(figsize = (30, 30))\n    value_filter = dataframe[dataframe[column_name] == value]\n    image_paths = value_filter['image_path'].to_list()\n    print(f'Total images: {len(image_paths)}')\n    posting_id = dataframe['posting_id'].to_list()\n    for i, j in enumerate(zip(image_paths, posting_id)):\n        plt.subplot(10, 10, i + 1)\n        img = cv2.cvtColor(cv2.imread(j[0]), cv2.COLOR_BGR2RGB)\n        plt.title(j[1])\n        plt.axis(\"off\")\n        plt.tight_layout()\n        plt.imshow(img)","c0cbe002":"def plot_matched_images(images_path, posting_id):\n    plt.figure(figsize = (50, 50))\n    for i, j in enumerate(zip(images_path, posting_id)):\n        plt.subplot(10, 10, i + 1)\n        img = cv2.cvtColor(cv2.imread(j[0]), cv2.COLOR_BGR2RGB)\n        plt.title(j[1])\n        plt.axis(\"off\")\n        plt.tight_layout()\n        plt.imshow(img)","a50dc154":"def plot_images_by_label_group(label):\n    plt.figure(figsize = (30, 30))\n    label_filter = train_df[train_df['label_group'] == label]\n    image_paths = label_filter['image_path'].to_list()\n    print(f'Total images: {len(image_paths)}')\n    posting_id = label_filter['posting_id'].to_list()\n    for i, j in enumerate(zip(image_paths, posting_id)):\n        plt.subplot(10, 10, i + 1)\n        img = cv2.cvtColor(cv2.imread(j[0]), cv2.COLOR_BGR2RGB)\n        plt.title(j[1])\n        plt.axis(\"off\")\n        plt.tight_layout()\n        plt.imshow(img)","2ec7ca80":"def plot_images_by_phash(image_phash):\n    '''\n    Plots image by phash value from train_df dataframe\n    '''\n    plt.figure(figsize = (30, 30))\n    phash_filter = train_df[train_df['image_phash'] == image_phash]\n    image_paths = phash_filter['image_path'].to_list()\n    print(f'Total images: {len(image_paths)}')\n    posting_id = phash_filter['posting_id'].to_list()\n    for i, j in enumerate(zip(image_paths, posting_id)):\n        plt.subplot(10, 10, i + 1)\n        img = cv2.cvtColor(cv2.imread(j[0]), cv2.COLOR_BGR2RGB)\n        plt.title(j[1])\n        plt.axis(\"off\")\n        plt.tight_layout()\n        plt.imshow(img)","f9299f83":"def hamming_distance(phash1, phash2):\n    '''\n    helper function to calculate phash similarity\n    '''\n    phash1 = bin(int(phash1, 16))[2:].zfill(64)\n    phash2 = bin(int(phash2, 16))[2:].zfill(64)\n    distance = np.sum([i != j for i, j in zip(phash1, phash2)])\n    return distance","666cdbd2":"def hamming_distance_bin(phash1, phash2):\n    '''\n    helper function to calculate phash similarity\n    '''\n    return np.sum([i != j for i, j in zip(phash1, phash2)])","f951d936":"def get_record_from_df(dataframe, column_name, value):\n    '''\n    Returns records from dataframe for the given value & column\n    '''\n    return dataframe[dataframe[column_name] == value]\n    ","9327ecfd":"def cosine_similarity(string1, string2):\n    d1 = nlp(string1)\n    d2 = nlp(string2)\n    return d2.similarity(d2)","3acda5a7":"def find_matches(posting_id, dataframe, dist_thr=10, title_thr=60):\n    '''\n    posting_id: posting_id \n    dataframe: train\/test dataframe from which the phash & title can be pulled\n    dist_thr: phash distance\/score threshold\n    title_thr: title score threshold from 100\n    '''\n    results = {}\n    phash_value = dataframe[dataframe['posting_id'] == posting_id].image_phash.to_list()[0]\n    title_value = dataframe[dataframe['posting_id'] == posting_id].clean_title.to_list()[0]\n    print(title_value)\n    for i in dataframe.itertuples():\n        phash_dist = hamming_distance(phash_value, i.image_phash)\n        title_score = fuzz.token_set_ratio(title_value.lower(), i.clean_title.lower())\n\n        if phash_dist <= dist_thr:\n            # print(i.posting_id, \" ::: \", i.title, phash_dist)\n            # results.append([i.posting_id, i.image_path])\n            results[i.posting_id] = i.image_path\n            continue\n        \n        if title_score > title_thr:\n            # print(i.posting_id, \" ::: \", i.title, title_score)\n            # results.append([i.posting_id, i.image_path])\n            results[i.posting_id] = i.image_path\n    return results","afc0b2c9":"class ProductMatch:\n    '''\n    Aggregating phash | fuzzymatch | cosine similarity\n    '''\n    def __init__(self, cudf_df, pro_df):\n        self.vectorizer = TfidfVectorizer(stop_words='english')\n        self.tfidf_matrix = self.vectorizer.fit_transform(cudf_df['clean_title'])\n        self.pro_df = pro_df\n        \n        \n    def find_phash_fuzz_match(self, posting_id, dist_thr=10, title_thr=60):\n        phash_val = self.pro_df.loc[self.pro_df['posting_id'] == posting_id].hash.to_list()[0]\n        title_val = self.pro_df.loc[self.pro_df['posting_id'] == posting_id].clean_title.to_list()[0]\n\n        self.pro_df['image_phash_score'] = self.pro_df['hash'].apply(lambda x: hamming_distance_bin(phash_val, x))\n        self.pro_df['title_score'] = self.pro_df['clean_title'].apply(lambda x: fuzz.token_set_ratio(title_val, x))\n        self.pro_df.sort_values(by='title_score', ascending=False, inplace=True)\n        i_score = self.pro_df.loc[self.pro_df['image_phash_score'] <= dist_thr]\n        t_score = self.pro_df.loc[self.pro_df['title_score'] > title_thr]\n\n        self.fuz_ph = {**dict(zip(i_score.posting_id.to_list()[:50], i_score.image_path.to_list()[:50])), **dict(zip(\n            t_score.posting_id.to_list()[:50], t_score.image_path.to_list()[:50]))}\n\n        return self.fuz_ph\n    \n    \n    # Ref: https:\/\/medium.com\/rapids-ai\/natural-language-processing-text-preprocessing-and-vectorizing-at-rocking-speed-with-rapids-cuml-74b8d751812e\n    def efficient_csr_cosine_similarity(self, query, matrix_normalized=False):\n        query = csr_row_normalize_l2(query, inplace=False)\n        if not matrix_normalized:\n            self.tfidf_matrix = csr_row_normalize_l2(self.tfidf_matrix, inplace=False)\n        return self.tfidf_matrix.dot(query.T)\n\n    def cos_match(self, df, query, cos_thr=0.2, top_n=50):\n        query = self.pro_df.loc[self.pro_df['posting_id'] == query].clean_title.to_list()[0]\n        query_vec = self.vectorizer.transform(cudf.Series([query]))\n        similarities = self.efficient_csr_cosine_similarity(query_vec, matrix_normalized=True)\n        similarities = similarities.todense().reshape(-1)\n        best_idx = similarities.argsort()[-top_n:][::-1]\n        op_df = cudf.DataFrame({\n            'posting_id': df['posting_id'].iloc[best_idx],\n            # 'title': df['clean_title'].iloc[best_idx],\n            'image_path': df['image_path'].iloc[best_idx],\n            'similarity': similarities[best_idx]\n        })\n        cos_df = op_df.to_pandas()\n        cos_df = cos_df[~cos_df['posting_id'].isin([list(self.fuz_ph.keys())])]\n        cos_df = cos_df.loc[cos_df['similarity'] > cos_thr]\n        cos_df = dict(zip(cos_df.posting_id.to_list()[:50 - len(self.fuz_ph.keys())], cos_df.image_path.to_list()[:50 - len(self.fuz_ph.keys())]))\n        return cos_df","6628003d":"# Ref: https:\/\/medium.com\/rapids-ai\/natural-language-processing-text-preprocessing-and-vectorizing-at-rocking-speed-with-rapids-cuml-74b8d751812e\n\ndef efficient_csr_cosine_similarity(query, tfidf_matrix, matrix_normalized=False):\n    query = csr_row_normalize_l2(query, inplace=False)\n    if not matrix_normalized:\n        tfidf_matrix = csr_row_normalize_l2(tfidf_matrix, inplace=False)\n    return tfidf_matrix.dot(query.T)\n\ndef product_match(df, query, vectorizer, tfidf_matrix, top_n=50):\n    print(f\"Product match: {query}\")\n    query_vec = vectorizer.transform(cudf.Series([query]))\n    similarities = efficient_csr_cosine_similarity(query_vec, tfidf_matrix, matrix_normalized=True)\n    similarities = similarities.todense().reshape(-1)\n    best_idx = similarities.argsort()[-top_n:][::-1]\n    op_df = cudf.DataFrame({\n        'posting_id': df['posting_id'].iloc[best_idx],\n        'title': df['clean_title'].iloc[best_idx],\n        'image_path': df['image_path'].iloc[best_idx],\n        'similarity': similarities[best_idx]\n    })\n    return op_df","1b64d21b":"digit_check = re.compile('\\d')\ndef check_alpha_num(token):\n    # check if the token id alphanumeric\n    return bool(digit_check.search(token))","8322a69d":"def handle_consecutive_char(string):\n    # check & fix for 3 or more consecutive characters\n    return re.sub(r'(.)\\1+\\1+', r'\\1', string)","0a696250":"source_path = '..\/input\/shopee-product-matching'","94fd2897":"train_df = pd.read_csv(f'{source_path}\/train.csv')\ntest_df = pd.read_csv(f'{source_path}\/test.csv')\nsample_submission_df = pd.read_csv(f'{source_path}\/sample_submission.csv')","ca2a9989":"print(f'Is there any NaN values?: {train_df.isnull().values.any()}')","3f5fbb23":"tqdm.pandas()\ntrain_df['image_path'] = train_df['image'].progress_apply(lambda x: f\"{source_path}\/train_images\/{x}\")\ntest_df['image_path'] = test_df['image'].progress_apply(lambda x: f\"{source_path}\/test_images\/{x}\")","fcf8c74a":"tqdm.pandas()\ntrain_df['hash'] = train_df['image_phash'].progress_apply(lambda x: bin(int(x, 16))[2:].zfill(64))\ntest_df['hash'] = train_df['image_phash'].progress_apply(lambda x: bin(int(x, 16))[2:].zfill(64))","27589b02":"print(f'Trainset: {train_df.shape} \\nTestset: {test_df.shape}')","5d114036":"train_df.info()","244062f7":"test_df.info()","532b4503":"train_df.head()","48d65ed9":"test_df.head()","d8a51469":"label_group_count = train_df.groupby(['label_group']).size().reset_index()\nlabel_group_count.columns = ['label_group', 'count']\nlabel_group_count.sort_values(by='count', ascending=False, inplace=True)\nlabel_group_count","fda12898":"print(f'No. of Duplicate label group: {train_df[train_df[\"label_group\"].duplicated() == True].shape[0]}')","1304275f":"print(f\"Minimum product under single label group: {label_group_count['count'].min()}\\nMaximum product under single label group: {label_group_count['count'].max()}\")","3507a8eb":"x, y = label_group_count['label_group'][:50], label_group_count['count'][:50]\nplot_bar_chart(x, y, title='Label Group Chart')","eb459257":"train_df[train_df['label_group'] == 509010932]","28dd78e2":"hamming_distance('eab5c295966ac368', 'efc096b0d38e98c3')","254e0a04":"plot_images(train_df, 'label_group', 509010932)","d71ae511":"image_count = train_df.groupby(['image']).size().reset_index()\nimage_count.columns = ['image', 'count']\nimage_count.sort_values(by='count', ascending=False, inplace=True)\nimage_count","5f62f94d":"print(f'No. of Duplicate images: {train_df[train_df[\"image\"].duplicated() == True].shape[0]}')","7b5c8572":"x, y = image_count['image'][:50], image_count['count'][:50]\nplot_bar_chart(x, y, title='Image count')","a91af1cc":"tmp_image = train_df[train_df[\"image\"].duplicated() == True]\n\nfor i in tmp_image.itertuples():\n    cnt = len(set(train_df[train_df['image'] == i.image].image_phash.to_list()))\n    if cnt != 1:\n        print(f'phash mismatch: {i}')\n","44759c96":"plot_images(train_df, 'label_group', 159351600)","ce6e4938":"phash_count = train_df.groupby(['image_phash']).size().reset_index()\nphash_count.columns = ['image_phash', 'count']\nphash_count.sort_values(by='count', ascending=False, inplace=True)\nphash_count","00686a5b":"plot_images(train_df, 'image_phash', 'e992966d4ba49761')","6a79395e":"# calculating distance between 2 phash for similarity\ndistance = []\nfor i in phash_count['image_phash']:\n    d = hamming_distance('fad28daa2ad05595', i)\n    if d <10:\n        distance.append([i, d])\nprint(distance)","ee19ffab":"plot_images(train_df, 'image_phash', 'fad28daa2ad05595')","b216ade7":"plot_images(train_df, 'image_phash', 'f2728d8b8ad055b5')","a742a1db":"plot_images(train_df, 'image_phash', 'fad28dab22d05595')","d1815f59":"print(f'No. of Duplicate titles: {train_df[train_df[\"title\"].duplicated() == True].shape[0]}')","90550e78":"train_df[train_df[\"title\"].duplicated() == True]","5013342c":"train_df['title'][4]","9053daff":"tqdm.pandas()\ntrain_df['unicode_handled_title'] = train_df['title'].progress_apply(lambda x: unidecode.unidecode(codecs.decode(x, 'unicode_escape')))","2ba5f044":"train_df['unicode_handled_title'][4]","58a004b9":"title_data = ' '.join(i for i in train_df['unicode_handled_title'])","7a485471":"wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS).generate(title_data)\nplt.figure(figsize=(40, 30))\nplt.imshow(wordcloud)  \nplt.axis(\"off\")","582ef11d":"vectorizer = CountVectorizer(stop_words='english')\ncount_m = vectorizer.fit_transform(train_df['unicode_handled_title'])","221fe7f2":"count_df = pd.DataFrame({'tokens': vectorizer.get_feature_names(), 'count': count_m.toarray().sum(axis=0).tolist()})\ncount_df.sort_values(by='count', ascending=True, inplace=True)","ca9134da":"plt.figure(figsize = (15, 15))\nsns.pointplot(x=count_df['tokens'][:50], y=count_df['count'][:50], linestyles=\"-\")\nplt.xlabel(\"tokens\")\nplt.ylabel(\"frequency\")\nplt.xticks(rotation=90)\nplt.show()","559cf08b":"plt.figure(figsize = (15, 15))\nsns.pointplot(x=count_df['tokens'][-50:], y=count_df['count'][-50:], color = \"green\", linestyles=\"-\")\nplt.xlabel(\"tokens\")\nplt.ylabel(\"frequency\")\nplt.xticks(rotation=90)\nplt.show()","1a1f0dc1":"tqdm.pandas()\ntrain_df['clean_title'] = train_df['unicode_handled_title'].progress_apply(lambda x: ' '.join(handle_consecutive_char(i) for i in str(\n                re.sub('[^A-Za-z0-9]', ' ', x.lower().strip())).split() if i.strip() and not check_alpha_num(i.strip()) and not (i.strip(\n                ) == len(i.strip()) * i.strip()[0])))","3707d4a5":"result = find_matches('train_1638187876', train_df)\nplot_images(train_df, 'posting_id', 'train_1638187876')\nplot_matched_images(result.values(), result.keys())","3db90fa8":"result = find_matches('train_3193897481', train_df)\nplot_images(train_df, 'posting_id', 'train_3193897481')\nplot_matched_images(result.values(), result.keys())","61884c4a":"result = find_matches('train_2767483557', train_df)\nplot_images(train_df, 'posting_id', 'train_2767483557')\nplot_matched_images(list(result.values())[:50], list(result.keys())[:50])","26760efd":"# result = find_matches('train_2928592022', train_df)\n# plot_images(train_df, 'posting_id', 'train_2928592022')\n# plot_matched_images([i[1] for i in result], [i[0] for i in result])\nresult = find_matches('train_2406599165', train_df)\nplot_images(train_df, 'posting_id', 'train_2406599165')\nplot_matched_images(result.values(), result.keys())","27604693":"result = find_matches('train_4085449742', train_df)\nplot_images(train_df, 'posting_id', 'train_4085449742')\nplot_matched_images(result.values(), result.keys())","834db99b":"cudf_df = cudf.DataFrame(train_df)\nobj = ProductMatch(cudf_df, train_df)","296e19c1":"def con(obj, posting_id, df, dist_thr=10, title_thr=60, cos_thr=0.2):\n    ph = obj.find_phash_fuzz_match(posting_id, dist_thr=10, title_thr=60)\n    cs = obj.cos_match(df, posting_id, cos_thr=0.2, top_n=50)\n    return {**ph, **cs}","81607dd2":"%%time\nresult = con(obj, 'train_1638187876', cudf_df, dist_thr=10, title_thr=60, cos_thr=0.2)\nplot_matched_images(result.values(), result.keys())","5f70efee":"%%time\nresult = con(obj, 'train_3193897481', cudf_df, dist_thr=10, title_thr=60, cos_thr=0.2)\nplot_matched_images(result.values(), result.keys())","37c192f5":"result = con(obj, 'train_2767483557', cudf_df, dist_thr=10, title_thr=60, cos_thr=0.2)\nplot_matched_images(result.values(), result.keys())","15faa533":"result = con(obj, 'train_1827962737', cudf_df, dist_thr=10, title_thr=60, cos_thr=0.2)\nplot_matched_images(result.values(), result.keys())","c1163bd4":"result = con(obj, 'train_4085449742', cudf_df, dist_thr=10, title_thr=60, cos_thr=0.2)\nplot_matched_images(result.values(), result.keys())","fbc7f641":"tqdm.pandas()\ntest_df['unicode_handled_title'] = test_df['title'].progress_apply(lambda x: unidecode.unidecode(codecs.decode(x, 'unicode_escape')))\ntest_df['clean_title'] = test_df['unicode_handled_title'].progress_apply(lambda x: ' '.join(handle_consecutive_char(i) for i in str(\n                re.sub('[^A-Za-z]', ' ', x.lower().strip())).split() if i.strip() and not check_alpha_num(i.strip()) and not (i.strip(\n                ) == len(i.strip()) * i.strip()[0])))","40960dec":"cudf_test_df = cudf.DataFrame(test_df)\nobj = ProductMatch(cudf_test_df, test_df)","bf6b6bea":"tqdm.pandas()\ntest_df['matches'] = test_df['posting_id'].progress_apply(lambda x: ' '.join(con(obj, x, cudf_test_df, dist_thr=10, title_thr=60, cos_thr=0.2).keys()))","0bd7cb88":"submission_csv = pd.DataFrame({'posting_id': test_df['posting_id'].to_list(), 'matches': test_df['matches'].to_list()})\nsubmission_csv","654f3cdf":"submission_csv.to_csv('submission.csv', index=False)","02d44bdc":"[Read more about phash](https:\/\/en.wikipedia.org\/wiki\/Perceptual_hashing)","7ae0c86f":"Preparing image paths","b59f9d2c":"# RAPIDS TfidfVectorizer cosine similarity match","d968069e":"# Helper funtions","1823555d":"## Label Group","9d230581":"# Image phash","8227b356":"Title count","caf2443e":"* Calculating distance between 2 image phash for similarity\n* Considering fad28daa2ad05595 for reference to compare it with other hash for similarity\n* Higher score = less similar","113ca11c":"# Getting started with data","27365fed":"Check if same image have same phash","d2025fba":"Image count","487b16ef":"Handling unicode data","e5bd64da":"Cannot rely on phash similarity, title similarity along with phash can be considered","296f8ad8":"<h3 align=\"center\" style=\"background-color:green;\">WIP<\/h3> ","a21c9fa7":"<h3 align=\"center\" style=\"background-color:#003300;color:white;\">Thanks! More updates to come. WIP<\/h3> ","8359be9c":"# Product Match","b80a97ec":"This is based on the fuzzy matching + phash approach.","d727fb46":"Checking the similarity of image phash that falls under same group","43696762":"Earlier, we saw that phash similarity is not enough. Hence we considered the phash + title matching.\n\nPlotting matched products\/posting_id from the data frame for the given posting_id. Here, the results seem pretty interesting but ofcourse there are mismatched products in the results below.\n\nIn the below test, the first image is from the source posting_id and the images in the grid are the match from other records in the data frame.","2b1d2aa3":"**The results have improved after text cleaning**","8283f67c":"# Text cleaning","58cb58e8":"# Baseline","0673a9b3":"## Images","1e93230d":"Here, there is alot of numbers, punctuation, consecutive characters. Hence, cleaning this data.\n* Dropping all the alphanumeric tokens\n* Fixing consecutive characters\n* Applied regex to filter non-alphabetic content from tokens","e89e9b8f":"Here, I am trying TfidfVectorizer + cosine similarity with product titles. The results look reasonable and of course, the matched products that are returned seem correct as compare to the above approach results. And yes, there are mismatches. I need to experiment with the score threshold. ","66f81541":"Please check out my another kernel: [Locality Sensitive Hashing(LSH)](https:\/\/www.kaggle.com\/srcecde\/shoppee-locality-sensitive-hashing-lsh-jaccard)","8bb33df2":"# WordCloud","ed15bafa":"Label group count","414e0611":"* Perpetual hashing acts as the image fingerprint which is generated by analyzing the content of the mathematically. \n* Its a 64-bits representation. \n* We can calculate the distance between two phash using hamming distance to derive the semantics of both images. The lower the score; more they are likely to be identical. (The example is shown below)\n* It is also widely used for use-cases of copyright-infringement. ","3c40da7d":"All images belongs to different **posting_id** and visually they are same.","7afc3f66":"***Aggregating phash, fuzzymatch, cosine similarity***","c57f8427":"# Title","2379c57e":"# Import Libraries","1cbecacc":"* Here, we have visualised all the images from above mentioned phash values based on the hamming distance \n* It's visually similar except the watermark in the center part"}}