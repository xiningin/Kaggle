{"cell_type":{"21d3205e":"code","31f352de":"code","98d97f8c":"code","05851e36":"code","5bb1db94":"code","4c19fbfb":"code","1bf27408":"code","6b8e4a41":"code","2f7cec44":"code","f6691a0c":"code","5960e832":"code","449e8079":"code","22016efd":"code","29c0f767":"code","aa9f7c76":"code","5b5b9f99":"code","f174fbe0":"code","da648171":"code","55cea74d":"code","aa5eef7c":"code","452f2dc3":"code","5d97d6a0":"code","c10e68fc":"code","f2d894d0":"code","74c9904f":"code","70cc2704":"code","cb1815f8":"code","c7bd02aa":"code","354bce91":"code","0117c4f0":"code","40d87994":"code","52b9ed81":"code","15f03bc0":"code","32ef956d":"code","eb74ba06":"markdown","f34c1e31":"markdown","a4cd7e83":"markdown","e377454e":"markdown","c6fe7fc0":"markdown","c876cf3e":"markdown","b68154a9":"markdown","4513c8e0":"markdown","668a447d":"markdown","519f9753":"markdown"},"source":{"21d3205e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31f352de":"#importing libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#importing sklearn libraries\nimport sklearn\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nimport plotly.express as px","98d97f8c":"mall_df= pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\nmall_df.head()","05851e36":"#check the shape of dataset\n\nmall_df.shape","5bb1db94":"#check the info of dataset\n\nmall_df.info()","4c19fbfb":"#describe the dataframe\n\nmall_df.describe()","1bf27408":"#check all the columns\n\nmall_df.columns","6b8e4a41":"#checking null values\n\nmall_df.isnull().sum()","2f7cec44":"#percentage null values\n\n100*mall_df.isnull().sum()\/len(mall_df)","f6691a0c":"# checking duplicate values\n\nmall_df.duplicated(subset = 'CustomerID').sum()","5960e832":"# Box Plot\nplt.figure(figsize=(15, 5))\nfeatures = ['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)']\nfor i in enumerate(features):\n    ax = plt.subplot(1, 3, i[0]+1)\n    sns.boxplot(mall_df[i[1]])\n    plt.xticks(rotation=20)","449e8079":"# distribution Plot\nplt.figure(figsize=(15, 5))\nfeatures = ['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)']\nfor i in enumerate(features):\n    ax = plt.subplot(1, 3, i[0]+1)\n    sns.distplot(mall_df[i[1]])\n    plt.xticks(rotation=20)","22016efd":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,3,1)\nsns.boxplot(x=mall_df.Gender, y=mall_df.Age)\nplt.title('Age')\n\nplt.subplot(1,3,2)\nsns.boxplot(x=mall_df.Gender, y=mall_df['Annual Income (k$)'])\nplt.title('Annual Income (k$)')\n\nplt.subplot(1,3,3)\nsns.boxplot(x=mall_df.Gender, y=mall_df['Spending Score (1-100)'])\nplt.title('Spending Score (1-100)')\n\nplt.show()","29c0f767":"#scatter plot\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nsns.scatterplot(x=mall_df.Age,y=mall_df['Spending Score (1-100)'],hue=mall_df.Gender)\n\nplt.subplot(1,3,3)\nsns.scatterplot(x=mall_df.Age,y=mall_df['Annual Income (k$)'],hue=mall_df.Gender)\n\nplt.subplot(1,3,2)\nsns.scatterplot(x=mall_df['Annual Income (k$)'],y=mall_df['Spending Score (1-100)'],hue=mall_df.Gender)","aa9f7c76":"# creating a new df with only numerical column\nmall_df1= mall_df.drop(['CustomerID', 'Gender'], axis=1)\nmall_df1.head()","5b5b9f99":"#converting Gender Variable\n#Male - 1\n#Female -0\n'''''variablelist =  ['Gender']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Male': 1, \"Female\": 0})\n\n# Applying the function to the columns\nmall_df1[variablelist] = mall_df1[variablelist].apply(binary_map)\nmall_df1.head()'''","f174fbe0":"# initiate an object\nscaler= StandardScaler()\n\n# fit-transform data\nmall_df1_scaled= scaler.fit_transform(mall_df1)\nmall_df1_scaled.shape","da648171":"mall_df1_scaled= pd.DataFrame(mall_df1_scaled)\nmall_df1_scaled.columns = ['Age','Annual Income (k$)','Spending Score (1-100)']\nmall_df1_scaled.head()","55cea74d":"# function hopkin statistics\n\nfrom random import sample\nfrom numpy.random import uniform\nfrom math import isnan\nfrom sklearn.neighbors import NearestNeighbors\n \ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n        \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","aa5eef7c":"# Evaluate Hopkins Statistics\nprint('Hopkins statistics is: ', round(hopkins(mall_df1_scaled),2))","452f2dc3":"# single linkage\nmergings = linkage(mall_df1_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","5d97d6a0":"# complete linkage\nmergings = linkage(mall_df1_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","c10e68fc":"# 3 clusters\ncluster_labels = cut_tree(mergings, n_clusters=4).reshape(-1, )\ncluster_labels","f2d894d0":"# assign the label\nmall_df['cluster_labels'] = cluster_labels\nmall_df.head()","74c9904f":"mall_df['cluster_labels'].value_counts()","70cc2704":"# plot\nplt.title('Age')\nsns.boxplot(x='cluster_labels', y='Age', data=mall_df)\nplt.show()","cb1815f8":"# plot\nplt.title('Annual Income (k$)')\nsns.boxplot(x='cluster_labels', y='Annual Income (k$)', data=mall_df)\nplt.show()","c7bd02aa":"# plot\nplt.title('Spending Score (1-100)')\nsns.boxplot(x='cluster_labels', y='Spending Score (1-100)', data=mall_df)\nplt.show()","354bce91":"sns.countplot(data= mall_df , hue='Gender', x='cluster_labels').tick_params(axis='x', rotation = 45)","0117c4f0":"#scatter plot gdpp-child_mort\n\nfig = px.scatter(mall_df, x=\"Spending Score (1-100)\", y=\"Age\", color=\"cluster_labels\")\nfig.show()","40d87994":"#scatter plot gdpp-child_mort\n\nfig = px.scatter(mall_df, x=\"Spending Score (1-100)\", y=\"Annual Income (k$)\", color=\"cluster_labels\")\nfig.show()","52b9ed81":"#scatter plot gdpp-child_mort\n\nfig = px.scatter(mall_df, x=\"Annual Income (k$)\", y=\"Age\", color=\"cluster_labels\")\nfig.show()","15f03bc0":"mall_grouped= mall_df.groupby('cluster_labels')","32ef956d":"mall_grouped['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)'].mean().sort_values(by=['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)'], ascending=[True, True, True])","eb74ba06":"## Step 6: Hierarchical Clustering","f34c1e31":"## Step 5: Hopkins Statistics","a4cd7e83":"## Step 2: Data Cleaning","e377454e":"## Conclusion:","c6fe7fc0":"## Step 1: Reading and understanding data:","c876cf3e":"* Cluster 0 belong to Low Income and High Spending score people who are mostly young aged.\n* Cluster 1 belong to Average Income and Average Spending score people who are mostly old aged.\n* Cluster 2 belong to High Income and High Spending score people who are at their 30s.\n* Cluster 3 belongs to High Income and low spending score people who are mid aged.","b68154a9":"## Step 4: Preparing Data","4513c8e0":"### Scaling Data","668a447d":"Using Complete linkage, we will consider clusters=4.","519f9753":"## Step 3: Exploratory Data Analysis (EDA)"}}