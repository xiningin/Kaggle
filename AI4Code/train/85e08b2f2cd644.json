{"cell_type":{"c3143fe3":"code","d63cf9a5":"code","d860cba5":"code","acce7c61":"code","db49d57f":"code","f9bb35e3":"code","aacada2b":"code","394ddede":"code","9e54eca3":"code","60ebe5ca":"code","6d92a11c":"code","ef47bcca":"code","1b2f900e":"code","283dabf7":"code","7c376534":"code","9838fc9b":"code","f969dcc1":"code","034f195d":"code","a364b26e":"code","cc9e00e2":"code","7d3db056":"code","6b5e31bc":"code","b571ac4a":"code","d349b1fb":"code","df59c064":"code","25d775f7":"code","1ffc78da":"code","7386f66b":"code","6469e4ae":"code","fe1d33f6":"code","bc19c83e":"code","9202a4ab":"code","e5e12711":"code","1e2635f4":"code","838f518f":"code","16965aaa":"code","7bcf29c9":"code","d0ec6701":"code","dd405349":"code","9377e960":"code","1e4626fc":"code","9f7f3495":"code","593ea633":"code","ead1167f":"code","1c2d38dc":"code","6f05c139":"code","c1c0b562":"code","a79f8e01":"code","4e93470e":"code","5d6d57d8":"code","cca339ee":"code","727e6350":"code","da96e568":"code","09a164ed":"code","473d214d":"code","77b6486c":"code","a0dbed27":"code","a05cd383":"code","bca56c10":"code","5542a51b":"code","372fa7cf":"code","66478459":"code","b9277521":"code","f9b0e11b":"code","23d19969":"code","4654f10d":"code","5dc9e7e8":"code","99c99c16":"code","12e70dec":"code","7e166b9d":"code","cb7832b5":"code","9a04447b":"code","ea0421b4":"code","2836b2af":"code","c5190479":"markdown","e1a31172":"markdown","4e5ccf79":"markdown","8dba197d":"markdown","19f3e3ee":"markdown","cd41afce":"markdown","e8ca93c0":"markdown","0c8ec7fa":"markdown","544b8bd0":"markdown"},"source":{"c3143fe3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d63cf9a5":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\nfrom catboost import Pool","d860cba5":"train = pd.read_csv('\/kaggle\/input\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/test.csv')\nfulfilment_center = pd.read_csv('\/kaggle\/input\/fulfilment_center_info.csv')\nmeal_info = pd.read_csv('\/kaggle\/input\/meal_info.csv')","acce7c61":"train.info()","db49d57f":"test.info()","f9bb35e3":"test.head()","aacada2b":"fulfilment_center.head()","394ddede":"meal_info.head()","9e54eca3":"meal_info.info()","60ebe5ca":"train = pd.merge(train,fulfilment_center, on = 'center_id')\ntest = pd.merge(test,fulfilment_center, on = 'center_id')\n\ntrain = pd.merge(train,meal_info, on = 'meal_id')\ntest = pd.merge(test,meal_info, on = 'meal_id')","6d92a11c":"train.head()","ef47bcca":"train.info()","1b2f900e":"plt.figure(figsize = (16, 7))\nsns.lineplot(train['week'], train['num_orders'])","283dabf7":"plt.figure(figsize = (16, 7))\nsns.barplot(train['center_id'], train['num_orders'])\nplt.xticks(rotation = 90)","7c376534":"plt.figure(figsize = (16, 7))\nsns.lineplot(train['checkout_price'], train['num_orders'])","9838fc9b":"plt.figure(figsize = (16, 7))\nsns.barplot(train['category'], train['num_orders'])\nplt.xticks(rotation = '90')","f969dcc1":"plt.figure(figsize = (16, 7))\nsns.barplot(train['cuisine'], train['num_orders'])\n#plt.xticks(rotation = '90')","034f195d":"plt.figure(figsize = (16, 7))\nsns.barplot(train['region_code'], train['num_orders'])\n#plt.xticks(rotation = '90')","a364b26e":"plt.figure(figsize = (16, 7))\nsns.barplot(train['op_area'], train['num_orders'])\nplt.xticks(rotation = '90')","cc9e00e2":"plt.figure(figsize = (16, 7))\nsns.lineplot(train['city_code'], train['num_orders'])\nplt.xticks(rotation = '90')","7d3db056":"plt.figure(figsize = (16, 7))\nsns.boxplot(x = 'num_orders', data = train)","6b5e31bc":"plt.figure(figsize = (16, 7))\nsns.boxplot(x = 'region_code', data = train)","b571ac4a":"plt.figure(figsize = (16, 7))\nsns.jointplot(x = 'checkout_price', y = 'num_orders', data = train)","d349b1fb":"plt.figure(figsize = (16, 7))\nsns.jointplot(x = 'op_area', y = 'num_orders', data = train)","df59c064":"plt.figure(figsize = (16, 7))\nsns.jointplot(x = 'region_code', y = 'num_orders', data = train)","25d775f7":"plt.figure(figsize = (16, 7))\nsns.jointplot(x = 'city_code', y = 'num_orders', data = train)","1ffc78da":"plt.figure(figsize = (16, 7))\nsns.boxplot(x = 'category', y = 'num_orders', data = train)\nplt.xticks(rotation = 90)","7386f66b":"plt.figure(figsize = (16, 7))\nsns.boxplot(x = 'cuisine',y = 'num_orders',data = train)\nplt.xticks(rotation = 90)","6469e4ae":"sns.jointplot(x = 'center_id', y = 'num_orders', data = train)","fe1d33f6":"print(\"Total number of centers : \", train['center_id'].nunique())","bc19c83e":"print(\"Total Number of cities: \", train['city_code'].nunique())","9202a4ab":"fig, ax = plt.subplots(figsize = (5, 8))\nsns.countplot(y = train['category'], hue = train['cuisine'], ax = ax)\nplt.show()","e5e12711":"center_meal_train = (train['center_id'].astype(str) + \"_\" + train['meal_id'].astype(str)).unique()\nprint(\"There are\", len(center_meal_train), \"center-meal pairs in train data\")","1e2635f4":"center_meal_test = (test['center_id'].astype(str) + \"_\" + test['meal_id'].astype(str)).unique()\nprint(\"There are\", len(center_meal_test), \"center-meal pairs in train data\")","838f518f":"# check if test set has any new center-mean pair or not\nprint(\"There are\",len(set(center_meal_test) - set(center_meal_train)), \"New center-meal pairs in test dataset which are not present in train dataset\")\nprint(set(center_meal_test) - set(center_meal_train))","16965aaa":"test[(test['center_id'] == 73) & (test['meal_id'].isin([2956, 1571]))].shape[0]","7bcf29c9":"test[(test['center_id'] == 92) & (test['meal_id'].isin([2104]))].shape[0]","d0ec6701":"outlier_index = train[(train['num_orders'] > 15000)].index","dd405349":"train.drop(outlier_index, inplace = True)","9377e960":"train['train_or_test'] = 'train'\ntest['train_or_test'] = 'test'","1e4626fc":"train['num_orders'] = np.log1p(train['num_orders'])","9f7f3495":"total_data = train.append(test).reset_index(drop = True)[train.columns]","593ea633":"total_data = total_data.sort_values(['center_id', 'meal_id', 'week']).reset_index(drop = True)","ead1167f":"total_data['checkout_price'] = np.log1p(total_data['checkout_price'])\ntotal_data['base_price'] = np.log1p(total_data['base_price'])","1c2d38dc":"total_data['discount_on_base'] = (total_data['base_price'] - total_data['checkout_price']) \/ total_data['base_price']","6f05c139":"total_data[\"discount_ratio\"] = total_data[\"base_price\"] \/ total_data[\"checkout_price\"]","c1c0b562":"sns.distplot(total_data['discount_on_base'], bins = 500)\nplt.show()","a79f8e01":"total_data['price_last_curr_diff'] = (total_data['checkout_price'].shift(1) - total_data['checkout_price']).fillna(1)\/ total_data['checkout_price'].shift(1).fillna(1)","4e93470e":"for _, r in total_data.groupby(['center_id', 'meal_id'])['week'].first().reset_index().iterrows():\n    total_data.loc[(total_data['center_id'] == r['center_id']) & (total_data['meal_id'] == r['meal_id']) & (total_data['week'] == r['week']), 'price_last_curr_diff'] = total_data[(total_data['center_id'] == r['center_id']) & (total_data['meal_id'] == r['meal_id']) & (total_data['week'] != r['week'])]['price_last_curr_diff'].mean()\ntotal_data['price_last_curr_diff'] = total_data['price_last_curr_diff'].fillna(0)","5d6d57d8":"# Features constructed from previous sales values\n\n#Creating sales lag features\ndef create_sales_lag_feats(df, gpby_cols, target_col, lags):\n    gpby = df.groupby(gpby_cols)\n    for i in lags:\n        df['_'.join([target_col, 'lag', str(i)])] = \\\n                gpby[target_col].shift(i).values + np.random.normal(scale = 1.6, size = (len(df),))\n    return df\n\n# Creating sales exponentially weighted mean features\ndef create_sales_ewm_feats(df, gpby_cols, target_col, alpha = [0.9], shift = [1]):\n    gpby = df.groupby(gpby_cols)\n    for a in alpha:\n        for s in shift:\n            df['_'.join([target_col, 'lag', str(s), 'ewm', str(a)])] = \\\n                gpby[target_col].shift(s).ewm(alpha = a).mean().values\n    return df","cca339ee":"# Creating num_orders lag, rolling mean, rolling median, ohe features of the above train set\ntotal_data = create_sales_lag_feats(total_data, gpby_cols = ['center_id','meal_id'], target_col = 'num_orders', \n                               lags = [10, 11, 12])\n\ntotal_data = create_sales_ewm_feats(total_data, gpby_cols = ['center_id', 'meal_id'], \n                               target_col = 'num_orders',\n                               alpha=[0.5], \n                               shift=[10,11,12,13,14,15])","727e6350":"total_data.head()","da96e568":"### Center count features ###\ngdf = total_data.groupby([\"center_id\", \"week\"])[\"id\"].agg(['size']).reset_index()\ngdf.columns = [\"center_id\", \"week\", \"center_week_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"center_id\", \"week\"], how = \"left\")\n\ngdf = total_data.groupby([\"center_id\", \"category\"])[\"id\"].count().reset_index()\ngdf.columns = [\"center_id\", \"category\", \"center_cat_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"center_id\", \"category\"], how = \"left\")\n\ngdf = total_data.groupby([\"center_id\", \"category\", \"week\"])[\"id\"].count().reset_index()\ngdf.columns = [\"center_id\", \"category\", \"week\", \"center_cat_week_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"center_id\", \"category\", \"week\"], how = \"left\")\n\ngdf = total_data.groupby([\"center_id\", \"cuisine\"])[\"id\"].count().reset_index()\ngdf.columns = [\"center_id\", \"cuisine\", \"center_cui_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"center_id\", \"cuisine\"], how = \"left\")","09a164ed":"### Meal count features ###\ngdf = total_data.groupby([\"meal_id\"])[\"id\"].count().reset_index()\ngdf.columns = [\"meal_id\", \"meal_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"meal_id\"], how = \"left\")\n\ngdf = total_data.groupby([\"region_code\", \"meal_id\"])[\"id\"].count().reset_index()\ngdf.columns = [\"region_code\", \"meal_id\", \"region_meal_count\"]\ntotal_data= pd.merge(total_data,gdf, on = [\"region_code\", \"meal_id\"], how = \"left\")\n\ngdf = total_data.groupby([\"meal_id\", \"week\"])[\"id\"].count().reset_index()\ngdf.columns = [\"meal_id\", \"week\", \"meal_week_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"meal_id\", \"week\"], how = \"left\")\n\ngdf =total_data.groupby([\"center_type\", \"meal_id\", \"week\"])[\"id\"].count().reset_index()\ngdf.columns = [\"center_type\", \"meal_id\", \"week\", \"type_meal_week_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"center_type\", \"meal_id\", \"week\"], how = \"left\")\n\ngdf = total_data.groupby([\"region_code\", \"meal_id\", \"week\"])[\"id\"].count().reset_index()\ngdf.columns = [\"region_code\", \"meal_id\", \"week\", \"region_meal_week_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"region_code\", \"meal_id\", \"week\"], how = \"left\")\n\ngdf =total_data.groupby([\"city_code\", \"meal_id\", \"week\"])[\"id\"].count().reset_index()\ngdf.columns = [\"city_code\", \"meal_id\", \"week\", \"city_meal_week_count\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"city_code\", \"meal_id\", \"week\"], how = \"left\")","473d214d":"### Price rank ###\n\ntotal_data[\"meal_price_rank\"] = total_data.groupby(\"meal_id\")[\"checkout_price\"].rank()\ntotal_data[\"meal_city_price_rank\"] = total_data.groupby([\"meal_id\", \"city_code\"])[\"checkout_price\"].rank()\ntotal_data[\"meal_region_price_rank\"] = total_data.groupby([\"meal_id\", \"region_code\"])[\"checkout_price\"].rank()\ntotal_data[\"meal_week_price_rank\"] = total_data.groupby([\"meal_id\", \"week\"])[\"checkout_price\"].rank()\n\ntotal_data[\"center_price_rank\"] = total_data.groupby(\"center_id\")[\"checkout_price\"].rank()\ntotal_data[\"center_week_price_rank\"] = total_data.groupby([\"center_id\", \"week\"])[\"checkout_price\"].rank()\ntotal_data[\"center_cat_price_rank\"] = total_data.groupby([\"center_id\", \"category\"])[\"checkout_price\"].rank()","77b6486c":"### Week features ###\n\ngdf = total_data.groupby([\"meal_id\"])[\"checkout_price\"].agg([\"min\", \"max\", \"mean\", \"std\"]).reset_index()\ngdf.columns = [\"meal_id\", \"meal_price_min\", \"meal_price_max\", \"meal_price_mean\", \"meal_price_std\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"meal_id\"], how = \"left\")\n\ngdf = total_data.groupby([\"meal_id\"])[\"base_price\"].agg([\"min\", \"max\", \"mean\", \"std\"]).reset_index()\ngdf.columns = [\"meal_id\", \"disc_price_min\", \"disc_price_max\", \"disc_price_mean\", \"disc_price_std\"]\ntotal_data = pd.merge(total_data,gdf, on = [\"meal_id\"], how = \"left\")\n\ngdf = total_data.groupby([\"city_code\",\"meal_id\", \"week\"])[\"checkout_price\"].agg([\"min\", \"max\", \"mean\", \"std\"]).reset_index()\ngdf.columns = [\"city_code\", \"meal_id\", \"week\", \"meal_price2_min\", \"meal_price2_max\", \"meal_price2_mean\", \"meal_price2_std\"]\ntotal_data= pd.merge(total_data,gdf, on = [\"city_code\", \"meal_id\", \"week\"], how = \"left\")\n\ngdf = total_data.groupby([\"city_code\", \"category\"])[\"checkout_price\"].agg([\"mean\", \"std\"]).reset_index()\ngdf.columns = [\"city_code\", \"category\", \"meal_price3_mean\", \"meal_price3_std\"]\ntotal_datal = pd.merge(total_data,gdf, on = [\"city_code\", \"category\"], how = \"left\")","a0dbed27":"total_data['center_id'] = total_data['center_id'].astype(np.object)\ntotal_data['meal_id'] = total_data['meal_id'].astype(np.object)\ntotal_data['region_code'] = total_data['region_code'].astype(np.object)\ntotal_datal['city_code'] = total_data['city_code'].astype(np.object)","a05cd383":"train_data = total_data.loc[total_data['train_or_test'] == 'train', :]\ntest_data = total_data.loc[total_data['train_or_test'] == 'test', :]","bca56c10":"center_meal_mean = train_data.groupby(['center_id', 'meal_id'])['num_orders'].mean()\ncenter_meal_mean = center_meal_mean.reset_index()\ncenter_meal_mean = center_meal_mean.rename(columns = {'num_orders':'avg_orders'})\ntrain_data = pd.merge(train_data,center_meal_mean, how = 'left', left_on = ['center_id', 'meal_id'], right_on = ['center_id', 'meal_id'])\ntest_data = pd.merge(test_data,center_meal_mean, how = 'left', left_on = ['center_id', 'meal_id'], right_on = ['center_id', 'meal_id'])\ncenter_mean = train_data.groupby('center_id')['num_orders'].mean()\ncenter_mean = center_mean.reset_index()\ncenter_mean = center_mean.rename(columns = {'num_orders':'avg_center'})\ntrain_data = pd.merge(train_data,center_mean, how = 'left', left_on = ['center_id'], right_on = ['center_id'])\ntest_data = pd.merge(test_data,center_mean, how = 'left', left_on = ['center_id'], right_on = ['center_id'])\nmeal_mean = train_data.groupby('meal_id')['num_orders'].mean()\nmeal_mean = meal_mean.reset_index()\nmeal_mean = meal_mean.rename(columns = {'num_orders':'avg_meal'})\ntrain_data = pd.merge(train_data, meal_mean,how = 'left',left_on = ['meal_id'], right_on = ['meal_id'])\ntest_data = pd.merge(test_data, meal_mean,how = 'left',left_on = ['meal_id'], right_on = ['meal_id'])","5542a51b":"train_data.info()","372fa7cf":"test_data.info()","66478459":"avoid_column = ['id', 'num_orders', 'train_or_test']","b9277521":"features = [col for col in test_data.columns if col not in avoid_column]","f9b0e11b":"features","23d19969":"categorical_features_indices = np.where(train_data[features].dtypes == 'object')[0]\ncategorical_features_indices","4654f10d":"model = CatBoostRegressor(\n    iterations = 2000, \n    learning_rate = 0.02, \n    max_depth = 8, \n    l2_leaf_reg = 10, \n    loss_function = 'RMSE',\n    random_seed = 22,\n    od_type = 'Iter',\n    od_wait = 25,\n    verbose = 100,\n    use_best_model = True\n    )","5dc9e7e8":"errcb = []\ny_pred_test = []\n\nfold = KFold(n_splits = 5,shuffle = True, random_state = 22)\n\nfor train_index, test_index in fold.split(train_data[features],train_data['num_orders']):\n    X_train, X_valid = train_data[features].iloc[train_index], train_data[features].iloc[test_index]\n    y_train, y_valid = train_data['num_orders'][train_index],train_data['num_orders'][test_index]\n    model.fit(X_train,y_train,\n              cat_features = categorical_features_indices,\n              eval_set = (X_valid, y_valid),\n              early_stopping_rounds = 300,\n              verbose = 100)\n    preds = model.predict(X_valid)\n    print(\"err: \", np.sqrt(mean_squared_error(y_valid,preds)))\n    errcb.append(np.sqrt(mean_squared_error(y_valid,preds)))\n    p = model.predict(test_data[features])\n    y_pred_test.append(p)","99c99c16":"model.fit(X = train_data[features], y = train_data['num_orders'], cat_features = categorical_features_indices,\n          eval_set = (X_valid, y_valid), verbose = 100)","12e70dec":"pred = model.predict(test_data[features])","7e166b9d":"pred = (np.exp(pred) - 1)","cb7832b5":"submission = pd.DataFrame({'id':test['id'],'num_orders':pred})\nsubmission = submission[['id','num_orders']]\nsubmission.head()","9a04447b":"submission.to_csv('catboost_1.csv', index = False)","ea0421b4":"feature_score = pd.DataFrame(list(zip(train_data[features].dtypes.index, model.get_feature_importance(Pool(train_data[features], label=train_data['num_orders'], cat_features=categorical_features_indices)))),\n                columns=['Feature','Score'])\n\nfeature_score = feature_score.sort_values(by = 'Score', ascending = False, inplace = False, \n                                          kind = 'quicksort', na_position = 'last')","2836b2af":"plt.rcParams[\"figure.figsize\"] = (24,7)\nax = feature_score.plot('Feature', 'Score', kind = 'bar', color = 'c')\nax.set_title(\"Catboost Feature Importance Ranking\", fontsize = 14)\nax.set_xlabel('')\n\nrects = ax.patches\n\nlabels = feature_score['Score'].round(2)\n\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()\/2, height + 0.35, label, ha = 'center', va = 'bottom')\n\nplt.show()","c5190479":"#### Remove outlier","e1a31172":"#### EDA","4e5ccf79":"#### Some functions to create aggregated, rolling mean\/median, and exponentially weighted features.\n\nCode from : https:\/\/www.kaggle.com\/abhilashawasthi\/feature-engineering-lgb-model","8dba197d":"There should be 77*51 = 3927 center-meal pair, but we have 3597 pairs in train data, that means some centers did not sell some of the meals.\n\nThere should be 3597*145 = 521565 records in past 145 week data, but we have 456548 records. which means some centers did not sell some meal for some week or they stared selling some new type of meal after some weeks. Same with test data.\n\nTest set has only 3548 center-meal pair, that means some of the centers did not sell some type of meals in this 10 week.\n\nHere in the test set (future 10 week), center 73 started selling meal 2956 & 1571, center 92 started selling meal 2104, which they have never sold in last 145 weeks. There are only 13 records with unknown center-meal pair in test set.","19f3e3ee":"#### Feature Engineering","cd41afce":"We have 77 stores in 51 cities, so some city have more than 1 center.","e8ca93c0":"Removing outliers from num_orders field","0c8ec7fa":"We have removed outlier from check_out price and base price","544b8bd0":"### Catboost Model"}}