{"cell_type":{"961225f6":"code","e554bd91":"code","69d9bd70":"code","9e2594da":"code","8541706f":"code","4d8970b7":"code","d27fb90d":"code","796b67bb":"code","babd1598":"code","448a6c0c":"code","66ce32fa":"code","ef5dca64":"code","0417417f":"code","8a98369a":"code","ea6c27a4":"code","a0a83d08":"code","264c9036":"code","d61511b9":"code","af4fb2e3":"code","8f5e415a":"code","15dde5d0":"code","9ba4dcc9":"code","8fb4a146":"code","5c4d73e6":"code","6b7977c1":"code","094325d9":"code","e7ae6445":"code","b8de0d36":"code","4b93957b":"code","2813728d":"code","e95804d4":"code","1417ef56":"code","146bce4f":"code","6acdfed0":"code","545f75d8":"code","6f05f74c":"code","19c175e2":"code","daace832":"code","f208b458":"code","7bb84758":"code","c4691d4d":"code","44aec2bb":"code","1c6fd152":"code","1417c4de":"code","44a2e6f7":"code","de337471":"code","d486a0bb":"code","f2bc0b36":"code","ea95cbc8":"code","68906214":"code","24087d89":"code","470e8812":"code","c086897e":"code","0ad716f2":"code","12d29cf0":"code","445479d6":"code","b1f5bb2e":"code","37b1d967":"code","60eb61f2":"code","61e68e5a":"code","db9d2055":"code","835930bd":"code","3bfb82da":"code","98924b79":"code","32eb07a4":"code","199469e7":"code","beafff13":"code","0d294622":"code","4ab9ed05":"markdown","89c993e8":"markdown","51f90437":"markdown","17391c72":"markdown","e49c32c0":"markdown","ffa2da8c":"markdown","4304c1f8":"markdown","f2bdc122":"markdown","345d42dc":"markdown","ca990888":"markdown","2da2062e":"markdown","d33fee60":"markdown","13b78f20":"markdown","02b8decd":"markdown","8ef07e1f":"markdown","ae3d2153":"markdown","a27d4f08":"markdown","e5d0db32":"markdown","6e7f1aaa":"markdown","9ac7b682":"markdown","8f0e7d78":"markdown","779af428":"markdown","b5fe5638":"markdown","45cd4cd5":"markdown","6434b4a1":"markdown","3eecf474":"markdown","085b2c6b":"markdown","9ffe1436":"markdown","28dd479a":"markdown","d8312c0b":"markdown","ba64012f":"markdown","949d2fb8":"markdown","1b4c793f":"markdown","f92d6db9":"markdown","e2d12540":"markdown","b9e48218":"markdown","4a2b3f27":"markdown","9e80b6e1":"markdown","3cf8b350":"markdown","62c50655":"markdown","d55c993a":"markdown","beff5aa7":"markdown","806174d6":"markdown","b84e01b3":"markdown","4b3af991":"markdown","25d8b4b8":"markdown","d824586a":"markdown","a75bfc4b":"markdown","f85396bf":"markdown","fa85d6d0":"markdown","ee9fe5d7":"markdown","f330f499":"markdown","d7135a71":"markdown","3430c444":"markdown","21e010ca":"markdown","99ad00ce":"markdown","89cf2e16":"markdown"},"source":{"961225f6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n# importing our dataset\ndf = pd.read_csv('..\/input\/earthquake-19652016\/earthquake.csv')\n\n# to suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","e554bd91":"#%matplotlib qt\n%matplotlib inline\nimport plotly\nplotly.offline.init_notebook_mode()\nimport plotly.express as px\nimport plotly.graph_objects as go","69d9bd70":"df.info()    # This will show us the summary of our dataset","9e2594da":"df.head(10)","8541706f":"df.tail(10)","4d8970b7":"df.describe()","d27fb90d":"print(len(df))\nprint(df.shape)","796b67bb":"print(list(df.columns))","babd1598":"df['Type'].value_counts()","448a6c0c":"classification = pd.DataFrame({'Class': ['Great','Major','Strong','Moderate','Light','Minor'],\n                              'Magnitude': ['8 or more','7 - 7.9','6 - 6.9','5 - 5.9','4 - 4.9','3 - 3.9']})\nclassification","66ce32fa":"print(\"The number of Earthquakes classified as \\\"Great\\\"    :\",len(df[(df['Magnitude']>=8.0) & (df['Type']=='Earthquake')]))\nprint(\"The number of Earthquakes classified as \\\"Major\\\"    :\",len(df[(df['Magnitude']>=7.0) & (df['Magnitude']<=7.9) & (df['Type']=='Earthquake')]))\nprint(\"The number of Earthquakes classified as \\\"Strong\\\"   :\",len(df[(df['Magnitude']>=6.0) & (df['Magnitude']<7.0) & (df['Type']=='Earthquake')]))\nprint(\"The number of Earthquakes classified as \\\"Moderate\\\" :\",len(df[(df['Magnitude']>=5.0) & (df['Magnitude']<6.0) & (df['Type']=='Earthquake')]))\nprint(\"The number of Earthquakes classified as \\\"Light\\\"    :\",len(df[(df['Magnitude']>=4.0) & (df['Magnitude']<5.0) & (df['Type']=='Earthquake')]))\nprint(\"The number of Earthquakes classified as \\\"Minor\\\"    :\",len(df[(df['Magnitude']>=3.0) & (df['Magnitude']<4.0) & (df['Type']=='Earthquake')]))","ef5dca64":"print(\"Number of Earthquakes in the Northern Hemisphere:\",len(df[(df['Latitude']>=0.0) & (df['Type']=='Earthquake')]))\nprint(\"Number of Earthquakes in the Southern Hemisphere:\",len(df[(df['Latitude']<0.0) & (df['Type']=='Earthquake')]))\nprint()\nprint(\"Number of Nuclear Explosions in the Northern Hemisphere:\",len(df[(df['Latitude']>=0.0) & (df['Type']=='Nuclear Explosion')]))\nprint(\"Number of Nuclear Explosions in the Southern Hemisphere:\",len(df[(df['Latitude']<0.0) & (df['Type']=='Nuclear Explosion')]))\nprint()\nprint(\"Number of Explosions in the Northern Hemisphere:\",len(df[(df['Latitude']>=0.0) & (df['Type']=='Explosion')]))\nprint(\"Number of Explosions in the Southern Hemisphere:\",len(df[(df['Latitude']<0.0) & (df['Type']=='Explosion')]))\nprint()\nprint(\"Number of Rock Bursts in the Northern Hemisphere:\",len(df[(df['Latitude']>=0.0) & (df['Type']=='Rock Burst')]))\nprint(\"Number of Rock Bursts in the Southern Hemisphere:\",len(df[(df['Latitude']<0.0) & (df['Type']=='Rock Burst')]))","0417417f":"print(\"Number of Earthquakes in the Eastern Hemisphere:\",len(df[(df['Longitude']>=0.0) & (df['Type']=='Earthquake')]))\nprint(\"Number of Earthquakes in the Western Hemisphere:\",len(df[(df['Longitude']<0.0) & (df['Type']=='Earthquake')]))\nprint()\nprint(\"Number of Nuclear Explosions in the Eastern Hemisphere:\",len(df[(df['Longitude']>=0.0) & (df['Type']=='Nuclear Explosion')]))\nprint(\"Number of Nuclear Explosions in the Western Hemisphere:\",len(df[(df['Longitude']<0.0) & (df['Type']=='Nuclear Explosion')]))\nprint()\nprint(\"Number of Explosions in the Eastern Hemisphere:\",len(df[(df['Longitude']>=0.0) & (df['Type']=='Explosion')]))\nprint(\"Number of Explosions in the Western Hemisphere:\",len(df[(df['Longitude']<0.0) & (df['Type']=='Explosion')]))\nprint()\nprint(\"Number of Rock Bursts in the Eastern Hemisphere:\",len(df[(df['Longitude']>=0.0) & (df['Type']=='Rock Burst')]))\nprint(\"Number of Rock Bursts in the Western Hemisphere:\",len(df[(df['Longitude']<0.0) & (df['Type']=='Rock Burst')]))","8a98369a":"top_ten_eq = df[['Type','Magnitude']].sort_values(by='Magnitude',ascending = False).head(10)\ntop_ten_eq[top_ten_eq['Type']=='Earthquake']","ea6c27a4":"top_ten_ne = df[df['Type']=='Nuclear Explosion']\ntop_ten_ne[['Type','Magnitude']].sort_values(by='Magnitude',ascending=False).head(10)","a0a83d08":"top_e = df[df['Type']=='Explosion']\ntop_e[['Type','Magnitude']].sort_values(by='Magnitude',ascending=False).head(10)","264c9036":"df[df['Type']=='Rock Burst'][['Type','Magnitude']]","d61511b9":"df.head()","af4fb2e3":"df['Date'] = df['Date'] +  \" \" + df['Time']\ndel df['Time']\ndf.head()","8f5e415a":"df['Date'] = pd.to_datetime(df['Date'],errors = 'coerce')\ndf.head()\nselected_date = df[(df['Date']>='2016-06-01 15:00:00') & (df['Date']<='2016-06-01 23:00:00')]\nselected_date","15dde5d0":"print(selected_date['Type'].value_counts())","9ba4dcc9":"for i in selected_date[['Latitude','Longitude']]:\n    print(selected_date[i])","8fb4a146":"for i in selected_date['ID']:\n    print(i)","5c4d73e6":"#finding missing values\nmissing_values_count = df.isnull().sum()\nmissing_values_count","6b7977c1":"count_of_missing_values = missing_values_count.sum()\nprint('Total number of missing values : ',count_of_missing_values)","094325d9":"total_values = np.product(df.shape)\ntotal_missing = missing_values_count.sum()\nprint('percentage of missing value : %d'%((total_missing\/total_values)*100)+'%')","e7ae6445":"droping =df.dropna(axis =1)\ndroping.head()","b8de0d36":"print(\"Columns in original dataset: %d \\n\" %df.shape[1])\nprint(\"Columns with na's dropped: %d\" % droping.shape[1])","4b93957b":"# get a small subset from  the  dataset\nsubset_data = df.loc[:, 'Depth Error':'Root Mean Square']\nsubset_data","2813728d":"# replace all NA's the value that comes directly after it in the same column, \n# then replace all the reamining na's with 0\nbfill = subset_data.fillna(method = 'bfill', axis=0).fillna(0)\nbfill","e95804d4":"# replace all NA's the value that comes directly after it in the same column, \n# then replace all the reamining na's with 0\nffill =subset_data.fillna(method = 'ffill', axis=0).fillna(0)\nffill","1417ef56":"# replace all NAN's with 0\nsubset_data.fillna(0)","146bce4f":"bfill.isnull().sum()","6acdfed0":"ffill.isnull().sum()","545f75d8":"subset_data.isnull().sum()","6f05f74c":"# getting row number 0 with all its columns\ndf.loc[0,:]","19c175e2":"# Obtaining the columns of first 3 rows\ndf.loc[[0,1,2],:]","daace832":"# Using loc function in terms of range\ndf.loc[0:5,:]","f208b458":"# To retrieve values of specified single column\ndf.loc[0:10,'Magnitude']","7bb84758":"# To retrieve the values of specified multiple columns\ndf.loc[0:10,['Latitude', 'Longitude', 'Magnitude']]","c4691d4d":"# To retrieve the columns using range function\ndf.loc[0:10,'Date':'Magnitude']","44aec2bb":"df.columns","1c6fd152":"# To obtain the required columns in range\ndf.iloc[:,0:3]","1417c4de":"df.pivot_table(index = \"Type\", values = \"Magnitude\", aggfunc = max)","44a2e6f7":"df.pivot_table(index = \"Type\", values = \"Magnitude\", aggfunc = min)","de337471":"df = pd.read_csv('..\/input\/earthquake-19652016\/earthquake.csv')","d486a0bb":"df.columns   # Gives all columns in our dataset","f2bc0b36":"df = df[['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude']]\ndf.head()","ea95cbc8":"df['Date'].head()","68906214":"df['Date'].tail()","24087d89":"df['date_parsed'] = pd.to_datetime(df['Date'], infer_datetime_format=True, utc=True)\ndf['date_parsed']","470e8812":"day_of_year_earthquakes = df['date_parsed'].dt.year\nday_of_year_earthquakes","c086897e":"# remove na's\nday_of_year_earthquakes = day_of_year_earthquakes.dropna()\n\n# plot the day of the month (count x dates)\nsns.distplot(day_of_year_earthquakes, kde=False, axlabel='Years', color='r', vertical=False)","0ad716f2":"day_of_year_earthquakes.value_counts()","12d29cf0":"day_of_month_earthquakes = df['date_parsed'].dt.month\nday_of_month_earthquakes","445479d6":"# remove na's\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\n\n# plot the day of the month (count x dates)\nsns.distplot(day_of_month_earthquakes, kde=False, axlabel='Months', color = 'g')","b1f5bb2e":"day_of_month_earthquakes.value_counts()","37b1d967":"day_of_date_earthquakes = df['date_parsed'].dt.day\nday_of_date_earthquakes","60eb61f2":"# remove na's\nday_of_date_earthquakes = day_of_date_earthquakes.dropna()\n\n# plot the day of the month (count x dates)\nsns.distplot(day_of_date_earthquakes, kde=False, bins=31, axlabel='Dates', color = 'r')","61e68e5a":"day_of_date_earthquakes.value_counts()\n#day_of_date_earthquakes.value_counts().sort_index()   #sorted by index","db9d2055":"plt.xlabel(\"Depth of magnitude\")\nplt.ylabel(\"Count\")\nplt.hist(x=df.Magnitude)","835930bd":"sns.boxplot(x=df.Depth)","3bfb82da":"fig=px.box(data_frame=df,y='Magnitude')\nfig.show()","98924b79":"fig=px.scatter(data_frame=df,x='Magnitude',y='Depth')\nfig.show()","32eb07a4":"sns.regplot(df.Magnitude,df.Depth)","199469e7":"df2=pd.cut(df.Magnitude,[5,6,7,8,9])\ndf2","beafff13":"vc=df2.value_counts()\nvc","0d294622":"vc.plot(kind='pie',explode=[0,0,1,0],autopct='%.f',radius=1.5)","4ab9ed05":"EAST - WEST DISTRIBUTION","89c993e8":"   # Data analysis and visualisation plots on Earthquake Analysis","51f90437":"DISPLAYING LAST N ROWS","17391c72":"TYPES OF CALAMITY","e49c32c0":"Dropping NaN values","ffa2da8c":"Pie chart on magnitude","4304c1f8":" Filling NaN values by Filling Zero's","f2bdc122":"Top Ten Most Powerful Nuclear Explosion By MAGNITUDE","345d42dc":"Using loc function","ca990888":"# **DATA SORTING**","2da2062e":" Pivot Table","d33fee60":"Scatterplot on magnitude vs depth","13b78f20":"Extracting date","02b8decd":"The ulimate aim is to use and show how the earthquake dataset can be analyzed using numpy and pandas. [](http:\/\/)","8ef07e1f":"# 1) OVERVIEW","ae3d2153":"So we will start by importing all the important libraries or packages.","a27d4f08":"Using iloc function","e5d0db32":"- The top magnitude calamities in each category.\n- The geographic location more prone to each calamity.\n- The number of earthquakes occured in a specific time frame.\n- There  are many empty rows of this _ column, so we could have used Bfill or Ffill but it could have worked for less missing data but here so many data rows were missing so to clean the data we used fill method.\n- Using pivot table both max and min magnitude of various calamities have been observed.\n- On the basis of years, It has gradually increased till 2010 with the maximum in 2011 year and a slight decrease has occured since then.\n- On the basis of month, It is almost identical with march showing the highest.\n- On the basis of magnitude, The magnitude of the earthquakes which have occured is mostly having the values in the range of 5.5-6.5.\n- From the depth aspect, most of the earthquakes are having depth in the range 0-100.\n","6e7f1aaa":"Extracting month","9ac7b682":"Regression plot on magnitude vs depth","8f0e7d78":"Filling NaN values by Forward Filling method","779af428":"# **DATA FILTERING**","b5fe5638":"Top Rock Burst By MAGNITUDE","45cd4cd5":"Figure out the main features from earthquake data and create a object of that features, namely: Date, Time, Latitude, Longitude, Depth, Magnitude.","6434b4a1":"CLASSIFICATION OF CALAMITY BASED ON THE GEOGRAPHIC LOCATION","3eecf474":"COLUMN MERGING AND DATE-TIME FILTERING","085b2c6b":"Note:\n'loc' gets rows (or columns) with particular labels from the index.                                    'iloc' gets rows (or columns) at particular positions in the index (so it only takes integers).","9ffe1436":"Number of NaN values after filling with Zero's","28dd479a":"Top Ten Most Powerful Earthquake By MAGNITUDE","d8312c0b":"Histogram on magnitude","ba64012f":"Parsing of date","949d2fb8":" Filling NaN values by backward filling method","1b4c793f":"# **Aim**","f92d6db9":"Boxplot on magnitude","e2d12540":"CONCISE SUMMARY","b9e48218":"Number of NaN values after using 'ffill'","4a2b3f27":"# Data Cleaning","9e80b6e1":"# Accessing Data","3cf8b350":" Percentage of missing values in dataset\n","62c50655":"# Visualization Analysis","d55c993a":"Now time for some Statiscal  summary. ","beff5aa7":"NORTH - SOUTH DISTRIBUTION","806174d6":"                                                 Thank you","b84e01b3":"Top Ten Most Powerful Explosion By MAGNITUDE","4b3af991":"# Summary of the observation","25d8b4b8":"Extracting year","d824586a":"Number of NaN values after using 'bfill'","a75bfc4b":"DISPLAYING FIRST N ROWS","f85396bf":"CLASSIFICATION OF EARTHQUAKES BASED ON MAGNITUDE","fa85d6d0":"Boxplot on depth","ee9fe5d7":"Making subset of columns containing NaN Values","f330f499":"STATISTICAL SUMMARY","d7135a71":"DATAFRAME COLUMNS","3430c444":"DATAFRAME DIMENSIONS","21e010ca":"Note: For above output there is only one \"Rock Burst\" in our dataset.","99ad00ce":"Note: For both methods namely head() & tail() the default value will be 5.","89cf2e16":"Total number of missing values"}}