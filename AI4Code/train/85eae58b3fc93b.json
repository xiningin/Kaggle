{"cell_type":{"1c818fc3":"code","da16cf85":"code","9cf62aaa":"code","51ce3ca2":"code","f7178731":"code","f276477f":"code","162f177b":"code","82b0b446":"code","09d87de2":"code","f9754c4b":"code","22390d22":"code","683db4d7":"code","b319d825":"code","3ac5f1ef":"code","da4ea002":"code","57fe012f":"code","29c5585a":"code","11a88005":"code","d2a1d188":"code","6926cc28":"code","0f1f2b6e":"code","b0a9b2bc":"code","ee4444c4":"code","c695f9a7":"code","a02934dd":"code","a16392be":"code","6f1c72a5":"code","c37c986c":"code","04751d28":"code","d2984355":"code","55f356b3":"code","00abb83e":"markdown","6fdd697b":"markdown","75ce7876":"markdown","1cb8fcac":"markdown","9625f538":"markdown","df8e9e29":"markdown","b32b8e22":"markdown","b15f2432":"markdown","4b1c6820":"markdown","c6b2a798":"markdown","7135e02c":"markdown","c3acc96a":"markdown","d1640e03":"markdown","d1d0d03a":"markdown","232eb8cd":"markdown","6caaebb8":"markdown","b763818a":"markdown","f70b458b":"markdown","fbfefc62":"markdown","43c07cc8":"markdown","660040df":"markdown","60200182":"markdown","c40df795":"markdown","cd577da9":"markdown"},"source":{"1c818fc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da16cf85":"data = pd.read_csv('..\/input\/home-credit-default-risk\/application_train.csv')","9cf62aaa":"data.head()","51ce3ca2":"data.tail()","f7178731":"print(\"Size of dataframe:\", data.shape)","f276477f":"data.describe()","162f177b":"print(\"All column attributes:\")\nprint(data.columns.values)","82b0b446":"def missing_overview(data):\n    total_missing_values = data.isnull().sum(axis=0).sort_values(ascending=False)\n    missing_ratio = (data.isnull().sum() \/ data.isnull().count() * 100).sort_values(ascending=False)\n\n    return pd.concat([total_missing_values, missing_ratio], axis=1, keys=['total', 'missing_ratio'])\n\nprint(missing_overview(data).head(20))","09d87de2":"temp = data['TARGET'].value_counts()\ntarget_classes = pd.DataFrame({'class': temp.index,\n                               'amount': temp.values})\n\nplt.figure(figsize=(10, 6))\nplt.title(\"Percentage of classes\")\nplt.xlabel(\"class\")\nplt.ylabel(\"percent\")\nsns.barplot(x='class', y='amount', data=target_classes)\nplt.show()\n\nprint(\"It's seem that dataset is imbalanced, the number of class 0 dominates that of class 1.\")","f9754c4b":"missing_df = missing_overview(data)\nnum_of_severve_missing_cols = missing_df[missing_df['missing_ratio'] > 15].shape[0]\nprint(\"Number of column attributes have over 15% missing values:\", num_of_severve_missing_cols)\nprint(f\"It's about {num_of_severve_missing_cols \/ data.shape[1] * 100}% of columns\")","22390d22":"def column_with_target_stats(data, column, label_rotate=False, target=1):\n    \"\"\"\n    Use samples with TARGET=1 to show distribution of 'column' feature\n    \"\"\"\n    df = data[data['TARGET'] == target]\n    \n    fig, ax = plt.subplots(1, 3, figsize=(24, 6))\n    fig.suptitle(f\"Insight of {column} with TARGET={target}\")\n\n    temp = data[column].value_counts()\n    temp = pd.DataFrame({column: temp.index, 'count': temp.values})\n    temp = temp.sort_values(['count'], ascending=False).reset_index(drop=True)\n    s = sns.barplot(x=column, y='count', data=temp, ax=ax[0])\n    if label_rotate:\n        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    ax[0].set_title(\"Number of samples in total\")\n\n    temp = df[column].value_counts()\n    temp = pd.DataFrame({column: temp.index, 'count': temp.values})\n    temp = temp.sort_values(['count'], ascending=False).reset_index(drop=True)\n    s = sns.barplot(x=column, y='count', data=temp, ax=ax[1])\n    if label_rotate:\n        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    ax[1].set_title(\"Number of samples with TARGET=1\")\n\n    values = data[column].value_counts()\n    temp = {value: df[df[column] == value].shape[0] \/ count for value, count in values.items()}\n    temp = pd.DataFrame({column: temp.keys(), 'percent': temp.values()})\n    temp = temp.sort_values(['percent'], ascending=False).reset_index(drop=True)\n    s = sns.barplot(x=column, y='percent', data=temp, ax=ax[2])\n    if label_rotate:\n        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    ax[2].set_title(\"Percent of target with value 1 [%]\")\n\n    plt.show()","683db4d7":"column_with_target_stats(data, 'NAME_CONTRACT_TYPE', target=1)","b319d825":"column_with_target_stats(data, 'CODE_GENDER')","3ac5f1ef":"low_cardinality_cols = list((filter(lambda col: data[col].nunique() <= 10, data.columns)))\nprint(\"Low cardinality columns\")\nprint(low_cardinality_cols)","da4ea002":"column_with_target_stats(data, 'FLAG_OWN_CAR')","57fe012f":"column_with_target_stats(data, 'FLAG_OWN_REALTY')","29c5585a":"column_with_target_stats(data, 'FLAG_MOBIL')","11a88005":"column_with_target_stats(data, 'HOUSETYPE_MODE')","d2a1d188":"column_with_target_stats(data, 'EMERGENCYSTATE_MODE')","6926cc28":"column_with_target_stats(data, 'NAME_TYPE_SUITE', True)","0f1f2b6e":"column_with_target_stats(data, 'NAME_INCOME_TYPE', True)","b0a9b2bc":"column_with_target_stats(data, 'NAME_FAMILY_STATUS', True)","ee4444c4":"# Drop missing value\nmissing_data = missing_overview(data)\ndrop_df = data.drop(columns=missing_data[missing_data['total'] > 5].index)\nprint(\"Remain:\", drop_df.columns.values)","c695f9a7":"corrmat = drop_df.corr()\n\nplt.figure(figsize=(20, 12))\nsns.heatmap(corrmat, square=True)\nplt.show()","a02934dd":"# 10 features\/cols have the highest correlation coefficient values with target\ncols = corrmat.nlargest(10, 'TARGET').index\ntop10_corrmat = np.corrcoef(drop_df[cols].values.T)\nsns.set(font_scale=1.25)\nplt.figure(figsize=(12, 9))\nsns.heatmap(top10_corrmat, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","a16392be":"# Plot distribution of one feature\ndef plot_distribution(data, column, color='r'):\n    plt.figure(figsize=(10,6))\n    plt.title(f\"Distribution of {column}\")\n    sns.histplot(data[column].dropna(), color=color, kde=True, bins=100)\n    plt.show()\n\n# Plot distribution of multiple features, with TARGET = 1\/0 on the same graph\ndef plot_distribution_comp(data, columns, nrow=2):\n    t1 = data.loc[data['TARGET'] != 0]\n    t0 = data.loc[data['TARGET'] == 0]\n\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(nrow, 2, figsize=(12,6*nrow))\n\n    i = 0\n    for col in columns:\n        i += 1\n        plt.subplot(nrow, 2, i)\n        sns.kdeplot(t1[col], bw_adjust=0.1, label=\"TARGET = 1\")\n        sns.kdeplot(t0[col], bw_adjust=0.1, label=\"TARGET = 0\")\n        plt.xlabel(col, fontsize=12)\n        plt.ylabel('Density plot', fontsize=12)\n        plt.legend()\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='both', which='major', labelsize=12)\n    plt.show()","6f1c72a5":"plot_distribution(data, 'AMT_INCOME_TOTAL')","c37c986c":"plot_distribution(data, 'AMT_CREDIT')","04751d28":"plot_distribution(data, 'AMT_ANNUITY', 'b')","d2984355":"plot_distribution(data, 'AMT_GOODS_PRICE', 'y')","55f356b3":"cols = ['AMT_ANNUITY','AMT_GOODS_PRICE','DAYS_EMPLOYED', 'DAYS_REGISTRATION','DAYS_BIRTH','DAYS_ID_PUBLISH']\nplot_distribution_comp(data, cols, 3)","00abb83e":"Nearly half the number of attributes contain missing values severely (assume 15% is severe).\nThe target to be predicted is highly imbalanced, which can lead to inefficient prediction model","6fdd697b":"It's seem that the distributions of interval values from features remain between 2 sets of samples (TARGET=1 and TARGET=0) no matter of imbalancing shown previously.","75ce7876":"The data not follows normal distribution","1cb8fcac":"### Overview","9625f538":"Percentage of target classes","df8e9e29":"The percentage of not repayment among family-group is about 8% in average. **Single\/not married** gains the most percentage amount (10%), which is also reasonable somehow... **Civil marriage** is little higher.","b32b8e22":"## [Problem 1] Understanding the content of the competition\n\n*   Home Credit is a non-bank financial company, they provide installment financial loans to unbanked people who have no or little credit history.\n*   The competition seeks for Kagglers' support to learn deeper the costumer's data they have and from such predicts their clients' repayment abilities.\n*   The ability to predict this knowledge helps the company manage risk, understand more about their clients and ensure the services.\n\n","b15f2432":"### Check missing data","4b1c6820":"Maximum percent of missing samples is about 70% in total","c6b2a798":"Some issues\/questions:\n\n1.   TARGETs are imbalanced maybe because the data is collected among the same group of people or attributes.\n2.   Some features have fairly similar names or aspects of information. May be there is correlation among them\n3.   Does data follow some probability distribution?\n4.   Does imbalance TARGET spoil features' distribution?\n\n","7135e02c":"Mostly contracts made for employed clients, but 10% of them didn't repay their loans. However, the unemployed and maternity-leave population consist of small amount of samples but over 35% and 40% didn't repay, respectively. Seem reasonable...","c3acc96a":"## Preparing the dataset","d1640e03":"Consider other chance of correlationship","d1d0d03a":"Explore distribution of real-value column features","232eb8cd":"## [Problem 2] Understanding the overview of data","6caaebb8":"<a href=\"https:\/\/colab.research.google.com\/github\/thanhnguyen2612\/diveintocode-ml\/blob\/master\/ML_Week3_ass.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","b763818a":"According to heatmap, some positive correlating group of features:\n\n*   CNT_CHILDREN & CNT_FAM_MEMBERS & REGION_RATING_CLIENT\n*   FLAG_MOBIL & DAYS_LAST_PHONE_CHANGE, etc.","f70b458b":"Examine other columns:","fbfefc62":"The number of female clients is greater than male one. But males have a higher chance of not returning loans (10%) than females (7%) -> **CODE_GENDER** may affect **TARGET**","43c07cc8":"Cash loans contracts mostly occur in un-repayment events. However, **Revolving loans** still has a medium level of not repaying chance (4.5%) in comparison with **Cash loans** (8.5%)","660040df":"## [Problem 3] Defining issues","60200182":"# Exploratory data analysis Class assignment Credit information analysis","c40df795":"## [Problem 4] Data exploration","cd577da9":"All clients provide phone number..."}}