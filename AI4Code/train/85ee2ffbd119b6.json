{"cell_type":{"72fd4f73":"code","dd30e03f":"code","d481ae3b":"code","6db3980d":"code","de9aa3c9":"code","b5e2f226":"code","56e3df33":"code","4f72ebe3":"code","8fa86efd":"code","c977ef0d":"code","033372e4":"code","5e4af053":"code","c04815fa":"code","773e085b":"code","44de862e":"code","ed2b0999":"code","0502407d":"code","0ca72ed0":"code","d32ec26a":"code","ab99ea18":"code","cd75d3a2":"code","78ef4a72":"code","c0901731":"code","320e79dd":"code","399937ec":"markdown","64a28de8":"markdown","b80688bb":"markdown","ac54999f":"markdown","2696abb7":"markdown","03f6c4fc":"markdown","199c569d":"markdown","6f78f22e":"markdown","24cd5180":"markdown","aa90933d":"markdown","1bd01f85":"markdown","ef57111b":"markdown","a316bb0d":"markdown","f271cda0":"markdown","10c0c870":"markdown","1817622a":"markdown","01198216":"markdown","ca341a6a":"markdown","c55ac549":"markdown","7486d772":"markdown","436190c8":"markdown","699194c2":"markdown","e26bfc00":"markdown","25206b88":"markdown","967e64a3":"markdown","2eb389a0":"markdown"},"source":{"72fd4f73":"import torch\nimport torchvision\nfrom PIL import Image\nimport torch.nn\nimport numpy as np\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split as tts","dd30e03f":"torch.cuda.is_available()","d481ae3b":"%matplotlib inline\n\nfor i in range(0, 4):\n    image = Image.open('..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/Training_Data\/' + str(random.randint(1000*i, 1000*(i+2))))\n    print(image.format)\n    arr = np.array(image)\n    print(arr.shape)\n    plt.imshow(arr)\n    plt.show()\n    print(arr.max(), ', ', i)","6db3980d":"train = pd.read_csv('..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/train.csv')\ntest = pd.read_csv('..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/test.csv')","de9aa3c9":"train.code.value_counts()","b5e2f226":"X_train = []\n\nfor i in train.id:\n    img = Image.open('..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/Training_Data\/' + str(i))\n    img_n = np.asarray(img)\n    img_n = img_n\/255\n    img_n = (img_n - 0.5)\/0.5\n    X_train.append(img_n)    \n\ny_train = train.code","56e3df33":"X_train = np.array(X_train)\nX_train = X_train.astype(np.float32)\n\ny_train = np.array(y_train)\ny_train = y_train.astype(np.float32)\ny_train = y_train - 1 # to make the labels go from 0-14, to be consistent with Python's indexing convention for the softmax fn\n\nprint('Train set dims = ', (X_train.shape))","4f72ebe3":"plt.figure(figsize=(10,10))\nplt.subplot(2, 2, 1), plt.imshow(X_train[random.randint(1, 2500)], cmap='gray')\nplt.subplot(2, 2, 2), plt.imshow(X_train[random.randint(2501, 5000)], cmap='gray')\nplt.subplot(2, 2, 3), plt.imshow(X_train[random.randint(5001, 7500)], cmap='gray')\nplt.subplot(2, 2, 4), plt.imshow(X_train[random.randint(7501, 10000)], cmap='gray')","8fa86efd":"X_train.shape","c977ef0d":"from torch import nn\nfrom torch import optim","033372e4":"class Net(nn.Module):   \n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv_layers = nn.Sequential(\n\n            nn.Conv2d(1, 6, kernel_size=3, stride=1, padding=0),\n#             nn.LeakyReLU(0.01),\n            nn.ReLU(inplace = True),\n            \n            nn.Conv2d(6, 6, kernel_size=3, stride=1, padding=0),\n#             nn.LeakyReLU(0.01),\n            nn.ReLU(inplace = True),    \n            nn.MaxPool2d(kernel_size=2, stride=2),\n      \n            nn.Conv2d(6, 16, kernel_size=3, stride=1, padding=0),\n#             nn.LeakyReLU(0.01),\n            nn.ReLU(inplace = True),  \n            nn.MaxPool2d(kernel_size=2, stride=2) \n      )\n\n        self.FCL = nn.Sequential(\n            nn.Linear(3136, 500),\n#             nn.LeakyReLU(0.01),\n            nn.ReLU(inplace = True),\n            nn.Linear(500, 90),\n#             nn.LeakyReLU(0.01),\n            nn.ReLU(inplace = True),\n            nn.Linear(90, 15)\n#             nn.Softmax(dim = 1)\n      )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.reshape(x.size(0), -1)\n        x = self.FCL(x)\n        return x","5e4af053":"model = Net()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \nprint(model)","c04815fa":"X_train = X_train.reshape(10000, 1, 64, 64)\nX_train  = torch.from_numpy(X_train)\ny_train = y_train.astype(int)\ny_train = torch.from_numpy(y_train)","773e085b":"losses = []\nruns = []\n\nfor epoch in range(50):\n    running_loss = 0\n    for i in range(len(X_train)):\n\n        if torch.cuda.is_available():\n            X_train[i] = X_train[i].cuda()\n            y_train[i] = y_train[i].cuda()\n\n        optimizer.zero_grad()\n        X_train[i] = X_train[i].unsqueeze_(0)\n        y_train[i] = y_train[i].unsqueeze_(0)\n        output = model(X_train[i][None, ...].cuda()) \n\n        loss = criterion(output, y_train[[i]].long().cuda())     \n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 10000 == 9999:\n            print('[%d, %5d] loss: %.7f' %\n                  (epoch + 1, i + 1, running_loss \/ 10000))\n            losses.append(running_loss\/10000)\n            runs.append(epoch)\n            running_loss = 0.0\n            \n#     if losses[epoch] > losses[epoch - 1]:\n#         print(\"Loss value increased at epoch \", epoch + 1, \n#               \"! The least value of loss so far is \", losses[epoch - 1], \" and current value is \", losses[epoch])\n#         break","44de862e":"import copy\n\nruns_mod = copy.deepcopy(runs)\nfor i in range(len(runs)):\n    runs_mod[i] = runs[i] + 1\n\nplt.plot(runs_mod, losses)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"CrossEntropy Loss\")\nplt.show()","ed2b0999":"X_test = []\n\nfor i in test.id:\n    img = Image.open('..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/Testing_Data\/' + str(i))\n    img_n = np.asarray(img)\n    img_n = img_n\/255\n    img_n = (img_n - 0.5)\/0.5\n    X_test.append(img_n)\n\nX_test = np.array(X_test)\nX_test = X_test.astype(np.float32)\nX_test = X_test.reshape(5000, 1, 64, 64)\nX_test  = torch.from_numpy(X_test)","0502407d":"test_preds = model(X_test.cuda())","0ca72ed0":"from torch.nn import functional as F\n\np = F.softmax(test_preds).data","d32ec26a":"p = p.cpu()","ab99ea18":"code = []\n\nfor i in range(len(p)):\n    cache = np.argmax(p[i])\n    code.append(cache.item() + 1)","cd75d3a2":"print(\"The length of the set of predicted values is: \", len(code))\nprint(\"\\nValue vs. Value Counts:\")\nprint(pd.Series(code).value_counts())","78ef4a72":"test['code'] = code\ntest.head(10)","c0901731":"test.code.value_counts()","320e79dd":"test.to_csv('.\/submission.csv', index = False)","399937ec":"# Importing image labels & raw data\n\n`train.csv` contains 2 columns: `id` - which gives the name of the image in the `Training_Data` folder, and `code` - which contains the true encodings of the character in the image (as written in the introduction).\n\n`test.csv` will be used towards the end. It has only one column: `id`.","64a28de8":"The following cell will convert the predictions into a CPU Tensor from a GPU\/CUDA Tensor:","b80688bb":"Checking the distribution of the predicted labels:","ac54999f":"Note the fact that the choice of dimension needs to be explicitly specified. I am saved from that headache (for now) by the Jupyter kernel. Good guy Jupyter!\n\nThe `softmax` probability outputs are now passed through the `argmax` function, which returns the index of the element with the highest probability. This is great for us, since our encodings for the numerals are from 1-15. \n\n**HOWEVER**, the `argmax` function's outputs begin from `0` (as is the convention with Python), so care needs to be taken to append the correct values. This can easily be achieved adding 1 to the output.\n\n**ALSO**, since the input is a tensor, even though the `argmax` output is a single number, it will be of `dtype=<torch.Tensor>`. Since it doesn't make sense to append a `torch.Tensor` to a `DataFrame`, I'll need to pull the numeric value of the `argmax` output from the `torch.Tensor`. This is done by using the `.item()` method in `PyTorch`.","2696abb7":"# Fin!\n\nPlease consider checking out <a href = \"https:\/\/www.linkedin.com\/in\/utkarshc99\/\" target = \"_blank\">my LinkedIn profile<\/a>! I'll be glad to receive any feedback on this notebook, or even just to connect.\n\nPlease drop an upvote or a comment if you appreciate this submission!","03f6c4fc":"# Chinese Numbers MNIST\n\nThe <a href=\"https:\/\/www.kaggle.com\/c\/mnist-but-chinese\/data\" target =\"_blank\">dataset used<\/a> for this notebook was given as part of a <a href=\"https:\/\/www.kaggle.com\/c\/mnist-but-chinese\/leaderboard\" target =\"_blank\">Kaggle hackathon<\/a> by the **Consulting and Analytics Club, IIT Guwahati**  - of which I am a part. Originally collected by professors at the **Newcastle University**, it represents 10,000 training images and 5,000 test-set images. These are Chinese numerals, and are coded in the `.csv` files with the following convention:\n    \n    code ==> Number in image\n    1. 1 ==> 0\n    2. 2 ==> 1\n    3. 3 ==> 2\n    4. 4 ==> 3\n    5. 5 ==> 4\n    6. 6 ==> 5\n    7. 7 ==> 6\n    8. 8 ==> 7\n    9. 9 ==> 8\n    10. 10 ==> 9\n    11. 11 ==> 10\n    12. 12 ==> 100\n    13. 13 ==> 1,000\n    14. 14 ==> 10,000\n    15. 15 ==> 100,000,000\n    \nThe implementation in this notebook has been done in `PyTorch`, and uses a modified version of the `LeNet-5` CNN architecture (<a href = \"http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-98.pdf\" target = \"_blank\">original paper from 1998<\/a>) that I've explained later in the notebook.\n\nIt takes \"a while\" to train on a CPU, which is why training on a GPU is advised. It is assumed the reader is aware of the associated syntax and may consider adding the relevant changes - if needed and wherever required. \n\nAlternatively, I could run this NB on the Colab kernel, but I haven't been able to figure out a reliable way to import all the required data while working there. Please do mention in the comments if you have a way to do that.","199c569d":"# Choice of optimiser and loss function\n\nThe ***optimiser*** used is `optim.Adam`, with a learning-rate of `0.0005`, which is one of the better choices as per <a href = \"https:\/\/medium.com\/octavian-ai\/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2\" target=\"_blank\">this Medium article<\/a>. The Adam optimiser is generally deemed to converge faster than stochastic gradient descent, which is a major point in its favour.\n\nThe ***loss function*** used is `nn.CrossEntropyLoss` since this is a multi-class classification problem. Since it inherently includes a `softmax` operation, I didn't include a separate `softmax` layer in my network architecture earlier. It'll be included later on while making the predictions, along with `np.argmax`.","6f78f22e":"# Implementing a (very) modified `LeNet-5` architecture\n\n1. `3x3` conv, stride = `1` (`6` filters)\n2. `3x3` conv, stride = `1` (`6` filters)\n3. Max pooling, f = `2`, s = `2`\n4. `3x3` conv, stride = `1` (`16` filters)\n5. Max pooling, f = `2`, s = `2`\n6. FCL (`500` units)\n7. FCL (`90` units)\n8. Output layer (`15` units) ","24cd5180":"# Differences from the original `LeNet-5` paper:\n\n**1.** instead of average pooling, **max pooling** is used\n\n**2.** instead of `sigmoid` and `tanh` non-linearities, **`ReLU`** is used\n\n**3.** The number of units in each FCL is decided as per the 64x64 **size of the image data**, and also on the **nature of the characters used** in the Chinese language. The following were the justifications made in the original paper:\n\n\n   * The original `LeNet-5` paper specified that the first \"full-connected layer\" with `120` units <u>was in fact a convolution layer<\/u>, but since the kernel size matched the input size for that layer, it <u>functioned as a full-connected layer<\/u>. Here, **I explicitly state it as a FCL**, and <u>made it to have 500 units to capture **the finer details of Chinese writing**<\/u>.\n   * The choice of `84` units for the next FCL was based on the fact that <u>this model could be used to identify characters from a `7x12` bitmap<\/u> - not necessarily numerals but also \"stylised characters\", as they were called in the original paper.\n \n**4.** the kernel size is now `3x3` - since Chinese is a language with fine and distinct strokes, <u>which might be blurred and thus, hidden if I use a larger kernel<\/u>.\n\n**5.** the first `5x5` convolution is replaced by 2 consecutive `3x3` convolutions, to:\n\n  * <u>increase non-linearities<\/u> in the network, since there is an extra layer now. This helps to make the model a tiny bit more robust.\n  \n  * decrease number of trainable parameters, which <u>reduces overfitting<\/u> in the model and <u>increases computational efficiency<\/u>.","aa90933d":"Confirming if the GPU is available for training:","1bd01f85":"And finally, writing the `test` `DataFrame` to a `.csv`:","ef57111b":"***Sanity check*** - looking at the number of elements, and at the distribution of unique values.","a316bb0d":"`mean` and `std_dev` were taken as `0.5` and `0.5` - since the pixel values were scaled from `[0, 255]` to `[0, 1]`. I could go on and use the actual mean and standard deviation of the dataset, but this seems to work fine. I might try using that in the future and check what effect it has on the accuracy and loss landscape.","f271cda0":"These shapes confirm that the array is 64x64 in shape, with the training set having 10k samples.\n\nNow for a final look at the `X_train` array, to verify whether I've loaded the images correctly:","10c0c870":"# Training the model, setting no. of epochs\n\n### *NOTE: the following cell WILL take a lot of time to execute, if you're using a CPU.*\n\n*You may skip it if you wish, or use a GPU to speed up the training. I achieved an accuracy of about `93.5%` on <a href=\"https:\/\/www.kaggle.com\/c\/mnist-but-chinese\/leaderboard\" target=\"_blank\">the competition leaderboard<\/a> at around `16-17` epochs, so you may stop there, or push forward to see the effect of a longer training duration on the model's generalisability.*\n\nThis cell will show the `CrossEntropy` losses after every epoch (i.e. a full pass of the entire training set of 10,000 samples) It can be modified suitably to show changes in loss when the model is in-between epochs, though this will necessitate changes to the plotting function too.","1817622a":"# Making the submission file\n\nThe `submission.csv` needs to be in the given format: one column for `id` (which is also the file-name of the image in `.\/Testing_Data`) and one column for `code`, which includes the encodings of the predicted labels (as per the given naming convention).\n\nViewing the first 10 entries of the `DataFrame`:","01198216":"Some of the libraries I know that I'll be using right off the bat. A few might not even be required, but I'll keep them in the cell, because that gives an insight into my thought-process while making the model. Considering it'll increase the time taken to run the cell, not a very ideal thing to do - but few things in this world are.","ca341a6a":"# Plotting the changes in loss over the epochs\n\nExecute the following to plot the graph of loss against number of epochs - this depends on whichever point you chose to stop the execution of the previous cell. The model may be in-between epochs with its training, but it'll show the loss up until the last complete epoch only.","c55ac549":"# Making predictions on test-set\n\nThe model is now trained (to whatever epoch you stopped the execution of the training cell at) and can now be used to make predictions on the test set. The weights and biases of the trained model may be checked by calling `model.state_dict()\n\nConverting test dataset to `dtype=torch.Tensor`, and passing it through the model:","7486d772":"Now to finally train the model on the entire training set:","436190c8":"So the training set is pretty uniform, thankfully. No further preprocessing is required on this at least. Scrumptious.\n\nAlso a good thing because the training will be done pretty uniformly, which is good news for the model's generalisability.","699194c2":"This clearly shows that:\n1. the image is `64x64` (from `print(arr.shape)`)\n2. grayscale (from the fact that there's only one channel - nevermind what you see. `pyplot.plot` colormaps aren't the most reliable)\n3. is a `JPEG` (self-evident from the o\/p. Less evident from the beautiful `JPEG` artifacts, but evident nonetheless)\n\nFrom the max pixel value, it is fairly certain the range of intensities will be `0-255`.","e26bfc00":"The above is the raw output from the model, for the test set. This needs to be passed into the `nn.functional.softmax` function, so that probabilities (that sum up to 1) are returned.","25206b88":"# Visualisation\n\nThe following cell plots a set of five random samples from the `Training_Data` folder. This'll help identify basic truths about the image data that I'll be dealing with.","967e64a3":"Excellent :)))))","2eb389a0":"Performing necessary preprocessing on raw image data:\n\n1. **putting it into a `NumPy` array**: to ease mathematical operations\n2. **scaling**: brings the pixel values from `[0, 255]` to `[0, 1]`\n3. **Mean-normalisation**: brings the pixel values from `[0, 1]` to `[-1, 1]`"}}