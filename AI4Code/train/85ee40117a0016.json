{"cell_type":{"6e28e176":"code","74fb6ac5":"code","01e7f3df":"code","ecf5d1d8":"code","b7ea6bd4":"code","ab11d729":"code","9b421c8a":"code","364686ce":"code","b4e116de":"code","c837a6d0":"code","b7b291f2":"code","9f102b21":"code","b13899d6":"code","12f39f6f":"code","c5b93100":"code","2a0884e6":"code","38a4eb49":"code","98064699":"code","8992e13e":"code","937a4bf6":"markdown","38d8e3ed":"markdown","930e8303":"markdown"},"source":{"6e28e176":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport operator\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"..\/working\/\"))\n\nos.system(\"rm ..\/working\/*.hdf5\")","74fb6ac5":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntrue_result = pd.read_csv('..\/input\/gender_submission.csv')","01e7f3df":"import re\ndef clean_variable(df):\n    df.Age = df.Age.fillna(-0.5)\n    df.Age = pd.cut(df.Age, (-1,0,5, 13, 20, 30, 45, 65, 100), labels=['Unknown', 'Baby', 'Child', 'Teen', 'Young_Adult', 'Adult', 'Senior', 'Old'])\n    df.Embarked = df.Embarked.fillna('N')\n    df.Cabin = df.Cabin.fillna('N')\n    df.Cabin = df.Cabin.apply(lambda x: x[0])\n    df.Fare = df.Fare.fillna(-0.5)\n    df.Fare = pd.qcut(df['Fare'], 6)\n    df['Title'] = df.Name.apply(lambda x: x.split(', ')[1].split('.')[0])\n    df['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n    df['Single'] = 1\n    df['Single'].loc[df['Family_Size'] > 1] = 0 \n    df.Family_Size = pd.cut(df.Family_Size, (-1, 2, 4, 6, 8, 10), labels=['S','M', 'L', 'XL', 'XXL'])\n    df= df.drop(['Name', 'SibSp', 'Parch'], axis = 1)\n    return df\n\ntrain = clean_variable(train)\ntest = clean_variable(test)\ntrain.head()","ecf5d1d8":"# normalize the titles\nnormalized_titles = {\n    \"Capt\":\"Capt\",        \"Col\":\"Officer\",    \"Major\":\"Officer\",    \"Dr\":\"Officer\",              \"Rev\":\"Officer\",\n    \"Jonkheer\":\"Royalty\",    \"Don\":\"Royalty\",    \"Sir\" :\"Royalty\",     \"the Countess\":\"Royalty\",    \"Dona\":\"Royalty\",    \"Lady\" :\"Royalty\",\n    \"Mme\":\"Mrs\",             \"Ms\":\"Mrs\",         \"Mrs\" :\"Mrs\",\n    \"Mlle\":\"Miss\",           \"Miss\" :\"Miss\",\n    \"Mr\" :\"Mr\",\n    \"Master\" :\"Master\"\n    }\n# map the normalized titles to the current titles \ntrain.Title = train.Title.map(normalized_titles)\ntest.Title = test.Title.map(normalized_titles)","b7ea6bd4":"from sklearn import preprocessing\ndef encode_features(df_train, df_test):\n    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Title','Embarked']#,'Ticket'\n    df_combined = pd.concat([df_train[features], df_test[features]])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        df_train[feature] = le.transform(df_train[feature])\n        df_test[feature] = le.transform(df_test[feature])\n    return df_train, df_test\n    \ntrain, test = encode_features(train, test)\ntrain.head()","ab11d729":"### Create Dummy Variables for Categorical Data\ndef dummy_column(df, column_name):\n    df_dummy = pd.get_dummies(df[column_name], drop_first=True, prefix=column_name )\n    df = df.join(df_dummy)\n    df = df.drop([column_name], axis=1)\n    return df\n\ntrain = dummy_column(train, 'Pclass')\ntrain = dummy_column(train, 'Sex')\ntrain = dummy_column(train, 'Age')\ntrain = dummy_column(train, 'Family_Size')\ntrain = dummy_column(train, 'Embarked')\ntrain = dummy_column(train, 'Title')\ntrain = dummy_column(train, 'Cabin')\ntrain = dummy_column(train, 'Fare')\n\n\ntest = dummy_column(test, 'Pclass')\ntest = dummy_column(test, 'Sex')\ntest = dummy_column(test, 'Age')\ntest = dummy_column(test, 'Family_Size')\ntest = dummy_column(test, 'Embarked')\ntest = dummy_column(test, 'Title')\ntest = dummy_column(test, 'Cabin')\ntest = dummy_column(test, 'Fare')\n\ntest_list  = [col for col in train.columns if col not in  test.columns ]\ntrain_list = [col for col in test.columns if col not in  train.columns ]\n\nfor missing_col in test_list:\n    test[str(missing_col)] = 0\n    \nfor missing_col in train_list:\n    train[str(missing_col)] = 0\n    \n    \ncolumn_order = list(train.columns)\ntest = test[column_order]","9b421c8a":"X_all = train.drop(['Survived', 'PassengerId','Ticket'], axis=1)\ny_all = train['Survived']\n\nnum_test = 0.75\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=123)\nX_train.head()","364686ce":"print (\"Train Shape {}\".format(X_train.shape))\nprint (\"Train Label Shape {}\".format(y_train.shape))\nprint (\"Test Shape {}\".format(X_test.shape))\nprint (\"Test Label Shape {}\".format(y_test.shape))","b4e116de":"model = Sequential()\nmodel.add(Dense(32, input_dim = 40, activation = 'tanh'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(32, activation = 'tanh'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(16, activation = 'tanh'))\nmodel.add(Dense(8, activation = 'tanh'))\nmodel.add(Dense(4, activation = 'tanh'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","c837a6d0":"filepath=\"weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit(X_train, y_train, epochs=150, verbose=1, validation_data=(X_test,y_test), batch_size=128, shuffle=True, callbacks=callbacks_list)","b7b291f2":"import matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","9f102b21":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","b13899d6":"model.load_weights(\"weights.best.hdf5\")","12f39f6f":"ids = test['PassengerId']\npredictions = model.predict(test.drop(['PassengerId','Ticket', 'Survived'], axis=1))\nfinal_predictions = []","c5b93100":"for each in predictions:\n    if each[0] >= .75:\n        score = 1\n    else:\n        score = 0\n    final_predictions.append(score)","2a0884e6":"output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': final_predictions })\noutput.to_csv('mylastsub.csv', index = False)","38a4eb49":"output.Survived.value_counts()","98064699":"y_pred_id = output['PassengerId'].tolist()\ny_true_id = true_result['PassengerId'].tolist()\nprint('If PassengerId is in the right order: '+str(y_pred_id == y_true_id))","8992e13e":"test","937a4bf6":"> # **Load Data**","38d8e3ed":"> # **Clean Data**","930e8303":"# **Begin Model**"}}