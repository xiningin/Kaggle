{"cell_type":{"490bb21b":"code","faef941c":"code","d1f96cb1":"code","f795091d":"code","c72e00f3":"code","8f1cac89":"code","158d2799":"code","ee717ff8":"code","a5e9873c":"code","f748732b":"code","4c1f693f":"code","5661f0dd":"markdown","0e025adc":"markdown","bbd5e49c":"markdown","6036a97e":"markdown","cba0c883":"markdown","40d42ddc":"markdown"},"source":{"490bb21b":"import pandas as pd\n\ndf = pd.read_csv(\"..\/input\/league-of-legends-diamond-ranked-games-10-min\/high_diamond_ranked_10min.csv\", index_col=0)\npd.set_option('display.max_columns', None) # this basically makes so that we can see all the column when we do data.head(), just a preference of mine.\ndf.head(3)","faef941c":"df.dtypes","d1f96cb1":"df = df.astype(int)\ndf.dtypes","f795091d":"# Let's see if it worked for one column that was a float and should be a int now. \ndf[\"blueGoldPerMin\"].head(2)\n\n# Looks good!","c72e00f3":"df_blue = df[['blueWins','blueWardsPlaced','blueWardsDestroyed','blueFirstBlood','blueKills','blueDeaths','blueAssists','blueEliteMonsters','blueDragons','blueHeralds','blueTowersDestroyed','blueTotalGold','blueAvgLevel','blueTotalExperience','blueTotalMinionsKilled','blueTotalJungleMinionsKilled','blueGoldDiff','blueExperienceDiff','blueCSPerMin','blueGoldPerMin']]\n#df_red = df[['redWardsPlaced', 'redWardsDestroyed','redFirstBlood', 'redKills', 'redDeaths', 'redAssists','redEliteMonsters', 'redDragons', 'redHeralds', 'redTowersDestroyed','redTotalGold', 'redAvgLevel', 'redTotalExperience','redTotalMinionsKilled', 'redTotalJungleMinionsKilled', 'redGoldDiff','redExperienceDiff', 'redCSPerMin', 'redGoldPerMin']]\n\ndf_blue.head(3)","8f1cac89":"import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nnp.set_printoptions(precision=6, suppress=True)","158d2799":"X = df_blue.iloc[:,df_blue.columns != \"blueWins\"]\nY = df_blue.iloc[:, 0]\n\n#X.head()\n#Y.head()","ee717ff8":"lr = LogisticRegression()  # create object for the class\nlr.fit(X, Y)  # perform regression\nY_pred = lr.predict(X)  # make predictions","a5e9873c":"column_labels = np.array(X.columns.values) \ncolumn_labels # to remind us what each label is for each coefficient ","f748732b":"# Let's see the results of each variable\ncoef = lr.coef_\ncoef","4c1f693f":"lr.score(X, Y)","5661f0dd":"## Results\n\nThe coefficients are small enough that I would not try to make any assumptions here, I would rather get more data to see if it would make a statistical difference to show what are them most important factors in order to win a game in high diamond. \n\n# What else can be done?\n\nWe should test the model with a goodness of fit test and check for multicollinearity. From what I understand the .score(x,y) function from sklearn can be used as a goodness of fit test, so let's start with that; ","0e025adc":"# Winning Factors in high Diamond League of Legends Games\n\n\n**Preface:** I have 3 hours before I need to get back to my studies, so we'll see how far we can get with this.\n\n![](https:\/\/cdn.app.compendium.com\/uploads\/user\/a7c086f7-9adb-4d2c-90fa-e26177af8317\/c2dea8f7-8c26-44de-ae5f-5dc019485c8c\/Image\/60691dbc9e7de7390b93ea5284177459\/data_analytics_banner.png)\n\n## Intro \n* We will try to identify this by running a regression, to see if there are some factors that are exceptionally good indication of when you will win a game or not. \n* ***Note:*** The data is for the first 10 minutes of high elo (Diamond) games, so this could change after the 10 minute mark.\n* Let's start by arranging the data and the libraries needed.\n\n","bbd5e49c":"# Linear Regression Time!\n\nSo we need to establish the y and x variables. Y should in this case be if they won or not, to see what affects the winning in the high diamond games, then we set the rest of the variables as x variables. \n\nAs we have a binary result of win\/loss, let's use a Logistical Regression model. ","6036a97e":"### Final comments\nHere is where I'm leave it for this time because I need to get back to my uni studies. Will hopefully pick this up at a later point again, but might do it on a larger dataset.\n\n*Cheers.*\n\n![](https:\/\/pbs.twimg.com\/media\/DdtlqFdUQAIQbR5.jpg)\n","cba0c883":"## Result\nWith a score of 0.73 it would indicate that the coefficients are not fully explaining the outcome of the game, but they sure are something worth taking a look at as it is close to 1.0.\n\nNext thing would be to test for multicollinearity and see if the different variables truly are independant of each other. ","40d42ddc":"### Fix the type of Data\nTo make our regression, we need the data to be integers and not floats. So let's see if there are any columns we need to fix."}}