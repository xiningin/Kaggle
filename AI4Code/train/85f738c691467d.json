{"cell_type":{"ac1f99de":"code","ed008bb1":"code","b8397bf6":"code","81c5d48e":"code","4e1a970b":"code","2855152f":"code","7ad19d73":"code","a389c78f":"code","b79e5a4f":"code","970637c7":"code","da0467a8":"code","5a528ad0":"code","90b3bdbc":"code","bbe27747":"code","5fe40947":"code","d3b29644":"code","834949a0":"code","64af023a":"code","a232e199":"code","66da9c16":"code","053b6ee0":"code","9ad50c4a":"code","63a1bb35":"code","6c22d8d9":"code","319a7494":"code","9eeba0bc":"code","12cc4bdb":"code","4afc86aa":"code","7267db9d":"code","920ab2d0":"code","5bcba1e9":"code","678623c7":"code","9c0ac7fd":"code","ebb3cd17":"code","c32f727b":"code","f584e6bd":"code","e1548867":"code","5d5bbecc":"code","44940334":"code","1f67ed3b":"code","1565e70f":"code","367e0791":"code","40bdbdf2":"code","95e9b230":"code","4258150e":"code","ed57264f":"code","b4beeb9f":"code","dd548a9d":"code","f3542d82":"code","697c4ff4":"code","eb0bbe6f":"code","8389bb78":"code","b25a65ff":"code","a2bc61c0":"code","84d4468e":"code","24ddeb15":"code","c79700d1":"code","c93002cd":"code","bb89d869":"code","842e04dd":"code","7c458719":"code","4aa44bd2":"code","c9d92321":"code","92a75597":"code","2837b53f":"code","32ad9e36":"code","7ca3d56a":"code","71056305":"code","bc9e7be5":"code","98c77761":"code","23dcf295":"code","5c208db4":"code","7fb86995":"code","ade30a6b":"code","9bf5e454":"code","ff6be637":"code","37a73a60":"code","e4dff9fd":"code","ab8b6890":"code","d3e9356d":"code","972b55f0":"code","3fca3876":"code","b604dbf6":"code","4ebefe03":"code","841094c3":"code","4f6c6884":"code","6cac7c8e":"code","72ff031c":"code","d4e354e3":"code","dd4d9b15":"code","12ec7091":"code","727867a6":"code","d6492020":"code","5e042ef2":"code","7636e16a":"code","1ed08e71":"code","2e397773":"code","6ef9c466":"code","958f2796":"code","e2dded00":"code","734afd01":"code","6f17fe92":"code","adc15398":"code","900beaed":"code","c9c32c43":"code","296f111d":"code","443e0930":"code","4333aff2":"code","ee8b8c36":"code","e2faf838":"code","3b9fac60":"code","a518dc86":"code","7554abb3":"code","73395156":"code","ef521ebe":"code","83531083":"code","3bbb94c7":"code","642966d6":"code","93952b00":"code","c1ef8b01":"code","6729d374":"code","fe2936fa":"code","22630093":"code","ede3755f":"code","6667993c":"code","8afb126e":"code","2faa2f38":"code","d07fac31":"code","309eb130":"code","0c51dfe2":"code","95ec9f39":"code","d9c4834b":"code","b151024d":"code","63a21366":"code","7f65d8c0":"code","29d9efad":"code","a5561701":"code","d2f552aa":"code","c02dd9c3":"code","a697467e":"code","4cdf89c8":"code","20696551":"code","29ce67f4":"code","b23b7a47":"code","bb07dc6a":"code","c2058335":"code","b6d511b3":"code","db26f2d6":"code","cfd630f1":"code","4401c269":"code","d7650f31":"code","e6253c2b":"code","9a4e214b":"code","4f1cb250":"code","85172ef0":"code","3dce4d7e":"code","85206adf":"code","28391cb2":"code","cd1485fb":"code","938627d1":"code","e4cfa44b":"code","521e1a5b":"code","55b3aa29":"markdown","9929ede0":"markdown","e63cfe52":"markdown","ce26f57b":"markdown","36785b79":"markdown","6ed47233":"markdown","21aafde2":"markdown","81e8217e":"markdown","eea6d966":"markdown","caefbfde":"markdown","7092a6b6":"markdown","e99daa1f":"markdown","0a263215":"markdown","2c69c9cd":"markdown","19b3b8f0":"markdown","57eb36b2":"markdown","3dab28b7":"markdown","c4ac6722":"markdown","5354fdf4":"markdown","90ee3041":"markdown","bd44debe":"markdown","e33ba49c":"markdown","edce811c":"markdown","91a92c38":"markdown","619e3ad1":"markdown","777ad27d":"markdown","801b9ae4":"markdown","02f96120":"markdown","0879ee92":"markdown","1b8aaef6":"markdown","ca28c61b":"markdown","7b51ae2c":"markdown","387bf05d":"markdown","3e5ccda4":"markdown","455282df":"markdown","b8d8cb7e":"markdown","5e344a32":"markdown","b5fe5218":"markdown","0c9e88f9":"markdown","f943b0a9":"markdown","2d8af512":"markdown","1b947565":"markdown","b6cc28e6":"markdown","287cf8c0":"markdown","3a7296ca":"markdown"},"source":{"ac1f99de":"import numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport seaborn as sns","ed008bb1":"customers = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv')\nsellers = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv')\norder_reviews = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv')\norder_items = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv')\nproducts = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_products_dataset.csv')\ngeolocation = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv')\nproduct_category = pd.read_csv('..\/input\/brazilian-ecommerce\/product_category_name_translation.csv')\norders = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv')\npayments = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv')","b8397bf6":"datasets_names = ['orders', 'customers', 'order_reviews', 'order_items', 'products', 'payments']\nfor dataset in datasets_names:\n    print(\"Dataset {} has shape {}\".format(dataset, eval(dataset).shape))","81c5d48e":"def dtypes_pie(dset, axis):\n    x = dset.dtypes.value_counts()\n    labels = [y.name for y in x.index.values]\n    wedges, text, autotexts = axis.pie(x=x.values,labels=labels, autopct='%1.1f%%', explode=[0.05]*len(x), pctdistance=0.5)\n    axis.set_title('DF {}'.format(get_df_name(dset)))\n    axis.legend(wedges, labels,\n          title=get_df_name(dset),\n          loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\n\ndef get_df_name(df):\n    name =[x for x in globals() if globals()[x] is df][0]\n    return name","4e1a970b":"fig, axs = plt.subplots(1, 3, figsize=(20, 20))\ndtypes_pie(orders, axs[0])\ndtypes_pie(customers, axs[1])\ndtypes_pie(order_reviews, axs[2])\nfig, axs = plt.subplots(1, 3, figsize=(20, 20))\ndtypes_pie(order_items, axs[0])\ndtypes_pie(products, axs[1])\ndtypes_pie(payments, axs[2])","2855152f":"state_df = customers.groupby('customer_state').count()['customer_id'].reset_index()\ncity_df = customers.groupby('customer_city').count()['customer_id'].reset_index()\n\nplt.figure(figsize = (25,7))\n\nplt.subplot(121)\nbase_color = sns.color_palette()[0]\n\nsns.barplot(data = state_df.sort_values('customer_id', ascending = False), x = 'customer_state', y = 'customer_id', color = base_color)\nplt.title('Number of Customers Per State')\nplt.xlabel('State')\nplt.ylabel('Number of Customers')\n\nplt.subplot(122)\nbase_color = sns.color_palette()[0]\n\nsns.barplot(data = city_df.sort_values('customer_id', ascending = False).nlargest(10,'customer_id'), x = 'customer_id', y = 'customer_city', color = base_color)\nplt.title('Cities with the Most Customers')\nplt.xlabel('City')\nplt.ylabel('Number of Customers');","7ad19d73":"#merge on product id\nproduct_order_merge_df = pd.merge(order_items,products)\nproduct_order_merge_df","a389c78f":"\ntop_products = product_order_merge_df['product_category_name'].value_counts().reset_index().nlargest(10,'product_category_name')\nlowest_products = product_order_merge_df['product_category_name'].value_counts().reset_index().nsmallest(10,'product_category_name')\n\nplt.figure(figsize = (15,12))\nred_color = sns.color_palette()[3]\ngreen_color = sns.color_palette()[2]\n\nplt.subplot(211)\nsns.barplot(data = top_products, x = 'product_category_name', y = 'index', color = green_color)\nplt.title('Top 10 Products Ordered')\nplt.xlabel('Number of Orders')\nplt.ylabel('Product');\n\nplt.subplot(212)\nsns.barplot(data = lowest_products, x = 'product_category_name', y = 'index', color = red_color)\nplt.title('Lowest 10 Products Ordered')\nplt.xlabel('Number of Orders')\nplt.ylabel('Product');","b79e5a4f":"payments_types = payments['payment_type'].value_counts().reset_index()\n\nplt.figure(figsize = (25,7))\n\nplt.subplot(121)\nsns.barplot(data = payments_types, x = 'index', y = 'payment_type')\nplt.title('Orders by Payment type')\nplt.xlabel('Payment Type')\nplt.ylabel('Number of Orders');\n\n\nplt.subplot(122)\nsns.barplot(data = payments['payment_installments'].value_counts().reset_index(), x = 'index', y = 'payment_installments')\nplt.title('Count of Orders With Number of Payment Installments')\nplt.xlabel('Number of Payment Installments')\nplt.ylabel('Count of Orders');","970637c7":"product_reviews = pd.merge(product_order_merge_df,order_reviews)\nproduct_reviews.head(10)","da0467a8":"plt.title('Before Transformation')\nsns.distplot(product_reviews.groupby('review_score').count()['order_id'].reset_index())\nplt.show()","5a528ad0":"\ndf = product_reviews.groupby('review_score').count()['order_id'].reset_index()\ndf['log_reviewscore'] = np.log(df['review_score'])\ndf","90b3bdbc":"plt.title('After Transformation')\nsns.distplot(df['log_reviewscore'])\nplt.show()","bbe27747":"base_color = sns.color_palette()[0]\n\nplt.figure(figsize = (10,7))\nsns.barplot(data = product_reviews.groupby('review_score').count()['order_id'].reset_index(), x = 'review_score', y = 'order_id', color = base_color)\nplt.title('Order Count by Review Score')\nplt.xlabel('Order Count')\nplt.ylabel('Review Score');","5fe40947":"prd_rev_means = product_reviews.groupby('product_category_name').mean()['review_score'].reset_index()\ntop_10_ratings = prd_rev_means.sort_values('review_score', ascending = False).nlargest(10,'review_score')\nlowest_10_ratings = prd_rev_means.sort_values('review_score', ascending = False).nsmallest(10,'review_score')\n\nplt.figure(figsize = (10,12))\n\nsns.barplot(data = product_reviews.groupby('review_score').count()['order_id'].reset_index(), x = 'review_score', y = 'order_id', color = base_color)\nplt.title('Order Count by Review Score')\nplt.xlabel('Order Count')\nplt.ylabel('Review Score');\n\nplt.subplot(211)\nsns.barplot(data = top_10_ratings, x = 'review_score', y = 'product_category_name', color = green_color)\nplt.title('Top 10 Product Ratings')\nplt.xlabel('Average Rating (points)')\nplt.ylabel('Product Category Name');\n\n\nplt.subplot(212)\nsns.barplot(data = lowest_10_ratings, x = 'review_score', y = 'product_category_name', color = red_color)\nplt.title('Lowest 10 Product Ratings')\nplt.xlabel('Average Rating (points)')\nplt.ylabel('Product Category Name');","d3b29644":"order_items.info()\n# TARGET \"price\" is available here we need to join multiple tables to make best predictor list with order_id ","834949a0":"orders.info()\n\n# order_id , customer_id can be used to JOIN ","64af023a":"products.info()\n#product_id can be used to JOIN ","a232e199":"# Creating a master_dataframe1 joining products,orders,order_items \n\nmdf1=pd.merge(products,pd.merge(orders,order_items,on=\"order_id\",how='inner'),on=\"product_id\",how='inner')\n\n","66da9c16":"mdf1.head()","053b6ee0":"mdf1.shape\n\n#112650 rows 22 columns","9ad50c4a":"payments.describe(include='all').T","63a1bb35":"payments.shape","6c22d8d9":"payments.head(3)","319a7494":"# merging payments with master_dataframe1 as it seems making sense to create master_dataframe2 \n\nmdf2=pd.merge(payments,mdf1,on=\"order_id\",how='inner')\n\n","9eeba0bc":"mdf2.shape\n#117601 rows and 26 columns","12cc4bdb":"mdf2.head(3)","4afc86aa":"# merging product_category with master_dataframe2 as it seems making sense to create master_dataframe3 \n\nmdf3=pd.merge(mdf2,product_category,on=\"product_category_name\",how='inner')","7267db9d":"mdf3.info()","920ab2d0":"mdf3.shape\n# (115878, 27) rows x columns ","5bcba1e9":"mdf3=mdf3.drop([\"order_approved_at\",\"order_delivered_carrier_date\",\n          \"order_delivered_customer_date\",\"order_estimated_delivery_date\",\n          \"order_purchase_timestamp\",\"shipping_limit_date\",\n          ],axis=1)\n\n# Removing the date columns which dont add much to data ","678623c7":"mdf3.shape","9c0ac7fd":"mdf3.std()","ebb3cd17":"mdf3=mdf3.drop([\"order_id\",\"product_id\",\n          \"customer_id\",\"seller_id\",\n          \"order_item_id\"\n          ],axis=1)\n\n# dropping of the serial no like columns \n","c32f727b":"mdf3=mdf3.drop([\"product_category_name\"\n          ],axis=1)\n\n# dropping of the duplicate \"product_category_name\" column  ","f584e6bd":"mdf3.shape","e1548867":"mdf3.head()","5d5bbecc":"import matplotlib.pyplot as plt\nimport seaborn as sns\nmdf3_num=mdf3.select_dtypes(include=[np.number])\nmdf3_cat=mdf3.select_dtypes(include=[np.object])","44940334":"mdf3_cat.info()","1f67ed3b":"mdf3_cat.describe(include='all').T","1565e70f":"print(mdf3_cat[\"payment_type\"].value_counts())\nmdf3_cat[\"payment_type\"].value_counts().plot(kind=\"pie\",autopct=\"%1.2f%%\")","367e0791":"\nprint(mdf3_cat[\"order_status\"].value_counts())\nexplodetup=(0,2,2,2,2,2,2)\nplt.pie(x=mdf3_cat[\"order_status\"].value_counts(), autopct=\"%.1f%%\",explode=explodetup,pctdistance=1.1,startangle=45,radius=2)\nplt.show()","40bdbdf2":"print(mdf3_cat[\"product_category_name_english\"].value_counts().sort_values(ascending=False).head(10))\nmdf3_cat[\"product_category_name_english\"].value_counts().sort_values(ascending=False).head(10).plot(kind=\"pie\",autopct=\"%1.2f%%\")\n#top10categories","95e9b230":"print(mdf3_cat[\"product_category_name_english\"].value_counts().sort_values(ascending=False).tail(10))\nmdf3_cat[\"product_category_name_english\"].value_counts().sort_values(ascending=False).tail(10).plot(kind=\"pie\",autopct=\"%1.2f%%\")\n#last10categories","4258150e":"mdf3_num.describe().T","ed57264f":"#DISTPLOTS \n\nj=0\nplt.figure(figsize=(15,30))\nfor i in mdf3_num:\n    j=j+1\n    plt.subplot(6,2,j)\n    sns.distplot(mdf3_num[i])\nplt.show()\n\n'''\nSkewness is high therefore there is a need to clean data\n\n'''\n","b4beeb9f":"mdf3_cat.isnull().sum() # no nulls in categorical data","dd548a9d":"mdf3_num.isnull().sum() # few nulls in numerical data  \n","f3542d82":"# imputing null values \n\nmdf3_num[\"product_weight_g\"]=mdf3_num[\"product_weight_g\"].fillna(mdf3_num[\"product_weight_g\"].median())\nmdf3_num[\"product_length_cm\"]=mdf3_num[\"product_length_cm\"].fillna(mdf3_num[\"product_length_cm\"].median())\nmdf3_num[\"product_height_cm\"]=mdf3_num[\"product_height_cm\"].fillna(mdf3_num[\"product_height_cm\"].median())\nmdf3_num[\"product_width_cm\"]=mdf3_num[\"product_width_cm\"].fillna(mdf3_num[\"product_width_cm\"].median())\n\n\n","697c4ff4":"mdf3_num.isnull().sum()# nulls removed","eb0bbe6f":"j=0\nplt.figure(figsize=(15,30))\nfor i in mdf3_num:\n    j=j+1\n    plt.subplot(5,3,j)\n    sns.boxplot(mdf3_num[i])\nplt.show()\n\n# Boxplot shows the presence of few outliers ","8389bb78":"mdf3.shape","b25a65ff":"# removing outliers by iqr \n\nq1=mdf3.quantile(0.25)\nq3=mdf3.quantile(0.75)\niqr=q3-q1\n\nmdf3=mdf3[~((mdf3<(q1-1.5*iqr))|(mdf3>(q3+1.5*iqr))).any(axis=1)]","a2bc61c0":"mdf3.shape","84d4468e":"mdf3_num=mdf3.select_dtypes(include=[np.number])\nmdf3_cat=mdf3.select_dtypes(include=[np.object])","24ddeb15":"mdf3_num.shape,mdf3_cat.shape# outlier rows removed ","c79700d1":"j=0\nplt.figure(figsize=(15,30))\nfor i in mdf3_num:\n    j=j+1\n    plt.subplot(5,3,j)\n    sns.boxplot(mdf3_num[i])\nplt.show()\n\n","c93002cd":"mdf3_num.skew()\n#Skewness after outlier removal becomes good therefore no nedd for DATA TRANSFORMATIONS\n","bb89d869":"mdf3_num.head()","842e04dd":"plt.figure(figsize=(18,20))\nsns.heatmap(mdf3_num.corr(),annot=True)\nplt.show()","7c458719":"from scipy import stats\nfor i in mdf3_num.drop('price',axis=1).select_dtypes(include=np.number).columns:\n    s=stats.pearsonr(mdf3_num[i],mdf3_num['price'])\n    if(s[1]<0.05):\n        print(i,' affects price')\n    else:\n        print(i,' does not affect price') # drop payment_sequential\n        \n         ","4aa44bd2":"mdf3_num=mdf3_num.drop(\"payment_sequential\",axis=1)","c9d92321":"j=0\nplt.figure(figsize=(15,20))\nfor i in mdf3_num:\n    j=j+1\n    plt.subplot(6,2,j)\n    sns.scatterplot(mdf3_num['price'],mdf3_num[i])\nplt.show()\n\n# Not much data has a linear Relationship with Price therefore Regression analysis \n# should include multiple algorithms to gain some complex relationship","92a75597":"mdf3_cat.head()","2837b53f":"sns.barplot(mdf3_cat[\"payment_type\"],mdf3_num[\"price\"])","32ad9e36":"plt.figure(figsize=(10,7))\nsns.barplot(mdf3_cat[\"order_status\"],mdf3_num[\"price\"])","7ca3d56a":"mdf3_cat[\"product_category_name_english\"].value_counts()\n# 71 categories dont make sense thus removing the columnn\n","71056305":"mdf3_cat=mdf3_cat.drop(\"product_category_name_english\",axis=1)\n","bc9e7be5":"mdf3_cat.describe(include='all')","98c77761":"# Categorical Data Encoding \n\nenc=pd.get_dummies(data=mdf3_cat,drop_first=True)\nenc","23dcf295":"# \n","5c208db4":"mdf3_num.info()","7fb86995":"from statsmodels.formula.api import ols\nfrom statsmodels.stats.anova import anova_lm\n\nformula = 'payment_installments ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)\n","ade30a6b":"formula = 'product_name_lenght ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","9bf5e454":"formula = 'payment_value ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","ff6be637":"formula = 'product_description_lenght ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","37a73a60":"formula = 'product_photos_qty~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","e4dff9fd":"formula = 'product_weight_g ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","ab8b6890":"formula = 'product_length_cm ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","d3e9356d":"formula = 'product_height_cm ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","972b55f0":"\nformula = 'product_width_cm ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","3fca3876":"\nformula = 'freight_value ~ price'\nmodel = ols(formula,mdf3_num).fit()\nanova_lm(model, typ=2)","b604dbf6":"target=mdf3_num[\"price\"]\nmdf3_num=mdf3_num.drop(\"price\",axis=1)","4ebefe03":"mdf3_num.head()","841094c3":"stored_mean=mdf3_num.mean()\nstored_std=mdf3_num.std()\nmdf_test=mdf3_num\nmdf3_num.iloc[:]=mdf3_num.iloc[:].apply(lambda x: (x-x.mean())\/x.std() )","4f6c6884":"mdf3_num.head()","6cac7c8e":"# joining categorical and numerical dataframes to create a master_dataframe 4\n\nmdf4=pd.concat([mdf3_num,enc],axis=1)","72ff031c":"mdf4.head()","d4e354e3":"from sklearn.model_selection import train_test_split ","dd4d9b15":"X_train,X_test,Y_train,Y_test=train_test_split(mdf4,target,test_size=0.3,random_state=1)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","12ec7091":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols \n\nX_train=sm.add_constant(X_train)","727867a6":"SLR_m1=sm.OLS(Y_train,X_train).fit()\nprint(SLR_m1.summary())\n\n# we can see the r2 is low and there are many unlikey \n# variables in the data seen from p-value \n\n\n\n# Condition Number is 549 >100 Indicating Moderate Multicolinearity in data ","d6492020":"target.dtype # verified ","5e042ef2":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif=pd.DataFrame()\nvif[\"Vif\"]=[variance_inflation_factor(mdf4.values,i) for i in range(mdf4.shape[1])]\nvif[\"feature_name\"]=mdf4.columns\n\n","7636e16a":"vif[(vif[\"Vif\"]>5)]# High Multicolinearity","1ed08e71":"3 # drop these columns \n\nmdf4=mdf4.drop([\"payment_type_credit_card\",\"order_status_delivered\"],axis=1)","2e397773":"mdf4.shape","6ef9c466":"# Rebuilding Model \n\nX_train,X_test,Y_train,Y_test=train_test_split(mdf4,target,test_size=0.3,random_state=1)\nX_train=sm.add_constant(X_train)\nSLR_m2=sm.OLS(Y_train,X_train).fit()\nprint(SLR_m2.summary())\n\n#condition no comes close ~ 100 indicating lack of multicolinearity or very minute multicolinearity \n","958f2796":"# still we do need to do a feature selection as there are a lot of insignificant features \n#present indicated by p-value therefore we go for RFE.\nfrom sklearn.feature_selection import RFE \n","e2dded00":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()","734afd01":"rfe_m=RFE(estimator=lr,n_features_to_select=1)\nr=rfe_m.fit(X_train,Y_train)\nrank=r.ranking_\nrank","6f17fe92":"for i in range(len(r.ranking_)):\n    if rank[i]<=9:\n        print(rank[i],\" @ index :     \",i-1,\"       \",X_train.columns[i])\n        # Going for 9 best features ","adc15398":"mdf4.head()","900beaed":"mdf5=mdf4.iloc[:,[0,1,3,5,9,11,13,14,15]]\n\n","c9c32c43":"mdf5.head()","296f111d":"# Re-building the masterdataframe5 and the model after adequate feature selection techniques \n\n\nX_train,X_test,Y_train,Y_test=train_test_split(mdf5,target,test_size=0.3,random_state=1)\nX_train=sm.add_constant(X_train)\nX_test=sm.add_constant(X_test)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)\n\n\n\n","443e0930":"SLR_m3=sm.OLS(Y_train,X_train).fit()\nprint(SLR_m3.summary())\n\n\n# Condition no further reduded thus no multicolinearity in data now \n#also check the model for \n# Overfitting ","4333aff2":"X_train.shape,X_test.shape","ee8b8c36":"\n\nfrom sklearn.metrics import mean_squared_error","e2faf838":"Pred_train=SLR_m3.predict(X_train)\nmse_train=round(mean_squared_error(Y_train,Pred_train),4)\n\n\nPred_test=SLR_m3.predict(X_test)\nmse_test=round(mean_squared_error(Y_test,Pred_test),4)\n\nprint(\"MSE TRAIN  :\",mse_train,\"\\n\\nMSE TEST :\",mse_test)\n","3b9fac60":"rmse_train=round(np.sqrt(mse_train),4)\nrmse_test=round(np.sqrt(mse_test),4)\n\nprint(\"RMSE TRAIN  :\",rmse_train,\"\\n\\nRMSE TEST :\",rmse_test)\n\n# THis indicates good fit and no overfit of model","a518dc86":"#  no pattern observed b\/w idv and residuals Linearity Present \nj=0\nplt.figure(figsize=(15,20))\nfor i in X_train:\n    j=j+1\n    plt.subplot(5,2,j)\n    sns.scatterplot(X_train[i],SLR_m3.resid)\nplt.show()\n","7554abb3":"print(SLR_m3.summary())\n\n#Durbin Watson test says value ~2 thus no auto corelation","73395156":"import statsmodels.stats.api as sms\ntest=sms.het_breuschpagan(SLR_m3.resid,SLR_m3.model.exog)\ntest[2:]\n\n# as pval>0.05 therefore assumption is nullified so good\n","ef521ebe":"from scipy.stats import shapiro \nstat,pvalue=shapiro(SLR_m3.resid)\npvalue\n\n#p-val<0.05 therefore better model ","83531083":"print(\"The selected features explain \",round(SLR_m3.rsquared,3)*100,\"% of variation in data using LINEAR REGRESSION\")","3bbb94c7":"SLR_m3.summary()","642966d6":"#!pip install graphviz","93952b00":"#!pip install mat","c1ef8b01":"from sklearn.tree import export_graphviz\nimport IPython, graphviz, re\nfrom sklearn.tree import DecisionTreeRegressor","6729d374":"# Model Building using the above selcted features in X_train \n\ndt1 = DecisionTreeRegressor(max_depth=3).fit(X_train, Y_train)\ndt1.score(X_train, Y_train)\n\n","fe2936fa":"from sklearn.ensemble import RandomForestRegressor\n\nrf1= RandomForestRegressor(max_depth=3).fit(X_train, Y_train)\nrf1.score(X_train, Y_train)","22630093":"Pred_train_dt=dt1.predict(X_train)\nmse_train=round(mean_squared_error(Y_train,Pred_train_dt),4)\n\n\nPred_test_dt=dt1.predict(X_test)\nmse_test=round(mean_squared_error(Y_test,Pred_test_dt),4)\n\nprint(\"MSE TRAIN  :\",mse_train,\"\\n\\nMSE TEST :\",mse_test)\n\n","ede3755f":"rmse_train=round(np.sqrt(mse_train),4)\nrmse_test=round(np.sqrt(mse_test),4)\n\nprint(\"RMSE TRAIN  :\",rmse_train,\"\\n\\nRMSE TEST :\",rmse_test)\n\n# THis indicates good fit and no overfit of model","6667993c":"\nimportant_features = pd.DataFrame({'Features': X_train.columns, \n                                   'Importance': dt1.feature_importances_})\n\n# sort the dataframe in the descending order according to the feature importance\nimportant_features = important_features.sort_values('Importance', ascending = False)\n\n# create a barplot to visualize the features based on their importance\nsns.barplot(x = 'Importance', y = 'Features', data = important_features)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('Feature Importance', fontsize = 15)\nplt.xlabel('Importance', fontsize = 15)\nplt.ylabel('Features', fontsize = 15)\n\n# display the plot\nplt.show()","8afb126e":"print(dt1.decision_path(X_train))","2faa2f38":"\nprint(\"The selected features explain \",round(dt1.score(X_train, Y_train),3)*100,\"% of variation in data using DECISION TREE REGRESSOR \")","d07fac31":"#conda install graphviz","309eb130":"mdf5.head()","0c51dfe2":"# Removing the categorical features which cant be explained by CLUSTERING .\n\nmdf_clust1=mdf5.drop([\"payment_type_voucher\",\"order_status_invoiced\",\"order_status_processing\",\"order_status_shipped\"],axis=1)","95ec9f39":"mdf_clust1.shape","d9c4834b":"mdf5.shape","b151024d":"order_reviews.head()","63a21366":"order_reviews[\"review_score\"].shape","7f65d8c0":"order_reviews[\"review_score\"].isnull().sum()","29d9efad":"mdf_clust1[\"review_score\"]=order_reviews[\"review_score\"].iloc[0:70057]","a5561701":"customers.head()","d2f552aa":"customers.shape","c02dd9c3":"customers[\"customer_id\"].iloc[0:70057]","a697467e":"mdf_clust1.isnull().sum()","4cdf89c8":"mdf_clust1['review_score']=mdf_clust1['review_score'].fillna(mdf_clust1['review_score'].median())","20696551":"rs_mean=mdf_clust1['review_score'].mean()\nrs_std=mdf_clust1['review_score'].std()\nrs_mean,rs_std","29ce67f4":"mdf_clust1['review_score']=(mdf_clust1['review_score']-rs_mean)\/rs_std\n\n","b23b7a47":"# Now Cluster errors (WSS) to be calculated:\nfrom sklearn.cluster import KMeans \n#from sklearn.cluster import AgglomerativeClustering\nfrom sklearn.metrics import silhouette_score\n\ncluster_range=range(1,14)# assume for 15 clusters we do the initial \ncluster_errors=[]\n\nfor num_clust in cluster_range:\n    clusters=KMeans(num_clust,n_init=10)\n    clusters.fit(mdf_clust1)\n    labels=clusters.labels_\n    centroids=clusters.cluster_centers_\n    cluster_errors.append(clusters.inertia_)\ncluster_df=pd.DataFrame({\"num_clusters\":cluster_range,\n                         \"cluster_errors\":cluster_errors})\nprint(cluster_df,len(labels))","bb07dc6a":"labels","c2058335":"df_label1=pd.DataFrame(labels,columns=list(['labels']))\ndf_label1['labels']=df_label1['labels'].astype('category')\ndf_new1=mdf_clust1.join(df_label1)","b6d511b3":"df_new1.head()","db26f2d6":"#Centroid and cluster plot for 15 clusters \nfor i in range(len(df_new1['labels'].unique())):\n    plt.scatter(df_new1[df_new1['labels'] == i].iloc[:,1] , df_new1[df_new1['labels'] == i].iloc[:,3] , label=i)\n    plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')","cfd630f1":"plt.figure(figsize=(12,6))\nplt.plot(cluster_df[\"num_clusters\"],cluster_df[\"cluster_errors\"],marker='o')\n\n# seems perfect val for clustering n=3\n","4401c269":"# from the elbow plot kopt=3\n\nkm=KMeans(n_clusters=3,n_init=15,random_state=2345)\nkm.fit(mdf_clust1)\nlabels_kmeans=km.labels_","d7650f31":"silhouette_score(mdf_clust1,labels_kmeans,metric='euclidean')\n# a good silhoutette score observed ~ 1 that means clusters are far and distinct ","e6253c2b":"mdf_clust1['labels_kmeans']=labels_kmeans\ncentroids=km.cluster_centers_","9a4e214b":"for i in range(len(mdf_clust1['labels_kmeans'].unique())):\n    plt.scatter(mdf_clust1[mdf_clust1['labels_kmeans'] == i].iloc[:,1] , mdf_clust1[mdf_clust1['labels_kmeans'] == i].iloc[:,3] , label=i)\n    plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')","4f1cb250":"mdf_clust1[\"labels_kmeans\"].astype('object')","85172ef0":"mdf_clust1[\"labels_kmeans\"].value_counts().plot(kind='pie',autopct=\"%1.2f%%\")","3dce4d7e":"mdf_clust1.head(1)","85206adf":"mdf_clust1[\"payment_installments\"]=(mdf_clust1[\"payment_installments\"]*1.867684)+2.283169\nmdf_clust1[\"payment_value\"]=(mdf_clust1[\"payment_value\"]*67.801826)+102.440460\nmdf_clust1[\"product_description_lenght\"]=(mdf_clust1[\"product_description_lenght\"]*398.726426)+631.310733\nmdf_clust1[\"product_weight_g\"]=(mdf_clust1[\"product_weight_g\"]*741.170156)+753.733317\nmdf_clust1[\"freight_value\"]=(mdf_clust1[\"freight_value\"]*5.000022)+15.255222\nmdf_clust1[\"review_score\"]=(mdf_clust1[\"review_score\"]*1.1468052407033689)+4.442796579927773","28391cb2":"print(stored_mean,\"\\n\\n\",stored_std,\"\\n\\n\",rs_mean,\"\\n\\n\",rs_std)","cd1485fb":"mdf_clust1.head()","938627d1":"mdf_clust1[\"customer_id\"]=customers[\"customer_id\"].iloc[0:70057]","e4cfa44b":"'''\nThe average reviews given by customers in Cluster 0 and Cluster 2 is not the highest value \ntherefore those are our high priority customers for whom we want to maybe give some offers or get valid feedbacks \nfor a lesser review\n\n'''\nround(mdf_clust1.groupby([\"labels_kmeans\",])[\"review_score\"].mean())\n","521e1a5b":"'''\nSo the average (no of payment insatllment value) for Customers is most in Cluster 2 \nwhich is 6 therefore we can have additinal offers provided for them.\n\n'''\n\nround(mdf_clust1.groupby([\"labels_kmeans\",])[\"payment_installments\"].mean())","55b3aa29":"### BIVARIATE ANALYSIS","9929ede0":"### Check for Overfitting ","e63cfe52":"## Before Model Re-Building ","ce26f57b":"##### 1) Target variable Numeric","36785b79":"### Building Initial Cluster with n_cluster=15 ","6ed47233":"### 2) Auto-co-realtion of residuals","21aafde2":"## DECISION TREE REGRESSION","81e8217e":"#### 1) Linear Relationship between Dependent Variable and Independent Variable","eea6d966":"Bed and bath products are the top products ordered followed by beauty products, and sports leisure products.\n\nInsurance services have the lowest amount of products ordered, followed by kids clothes, and pc gaming products. \n\n","caefbfde":"### Building Base Model","7092a6b6":"### FIND OPTIMAL n_clusters values using ELBOW PLOT ","e99daa1f":"## CLUSTERING ","0a263215":"### SIGNIFICANCE TESTING ","2c69c9cd":"### 3) Test for Homoscaditicity","19b3b8f0":"### (STEP1) CREATING MASTER DATAFRAME ","57eb36b2":"# Exploration\n\n## Where do most customers come from?","3dab28b7":"### CATEGORICAL DATA ENCODING\n\n","c4ac6722":"### Kmeans Clustering","5354fdf4":"### After Model Re-Building  (  Assumptions  )","90ee3041":"### Scaling","bd44debe":"# What are the most common payment types?","e33ba49c":"### Train Test Split","edce811c":"### Categorical Data","91a92c38":"### Outlier Handling","619e3ad1":"## What are the top 10 most rated products?","777ad27d":"On the left, we see that credit cards take up most of the orders. In fact, they are more than 3 times more higher than any other payment type in the data set.\n\nOn the right, we see that the most common number of payment installments is 1. After that the amount of orders decreases as the number of payment installments increaces however, 8 and 10 payment installments rise a bit more.","801b9ae4":"## What are the most frequent items bought?","02f96120":"The highest amount of orders have 5 start reviews and as the ratings decrease so do the order counts, except for 1. A review score of 1 has more orders than 2 or 3.","0879ee92":"1. We can see that freight_value, product_width_cm, product_height_cm, product_length_cm, product_weight_g,\nproduct_photos_qty, product_description_length, product_name_length, payment_value, payment_sequential and payment_installments\nhave positive correlation with price. \n2. Among those, payment_value shows highest positive correlation while payment_sequential shows least correlation\n3. order_item_id is negatively correlated with price\n\nproduct_weight_g and freight_value, product_weight_g and product_width_cm, product_length_cm and product_width_cm,\nproduct_weight_g and product_height_cm are higtly correlated among each other\n\nWe are dropping product_weight_g, product_width_cm, payment_sequential, order_item_id, product_name_length, product_photos_qty","1b8aaef6":"Most customers are from the states and cities of Sao Paul, followed by Rio de Janeiro. This is not too suprising because the highest populations of people in Brazil are also from these states and cities.","ca28c61b":"### ACCURACY OF MODEL","7b51ae2c":"### Null Data Handling   ","387bf05d":"### Rebulidng model with Optimal value ","3e5ccda4":"##### 2) No Multicolinearity in data ","455282df":"# GENERALIZED (EDA)","b8d8cb7e":"###            Price Prediction","5e344a32":"### ASSUMPTIONS FOR LINEAR REGRESSION ","b5fe5218":"### Checking data for Overfitting by calculating (MSE, RMSE) : TEST\/TRAIN value ","0c9e88f9":"### Feature Selection ","f943b0a9":"## In-Depth(EDA)","2d8af512":"### (STEP2) UNIVARAITE ANALYSIS ","1b947565":"### 4) Test for Normality ","b6cc28e6":"### Numerical Data","287cf8c0":"### ACCURACY OF MODEL","3a7296ca":"### Unscaling the data"}}