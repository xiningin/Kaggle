{"cell_type":{"6f2bf544":"code","d7e3253d":"code","35561857":"code","254cd2b2":"code","c280ef72":"code","b2ba9886":"code","d1078239":"code","0504a58a":"code","da6bb5b5":"code","3cc178ce":"code","5cf5085c":"code","b405ab1e":"code","74e2d2f0":"code","06a1a195":"code","60cce23e":"code","35e94a59":"code","cfd557bf":"code","5ac2dfde":"code","fc79b10c":"code","b41b943c":"code","77cfb841":"code","ea5b8822":"code","97aa5bfe":"code","ab8a37c3":"code","a20117fa":"code","844a907b":"code","ed253aee":"code","0685b3bd":"code","0503924f":"code","9d3983ab":"code","ae264b4f":"code","6628bbc9":"code","22451ce2":"code","e2b43ea6":"code","f35f37aa":"code","ddc53cad":"code","eebe90dc":"code","4ddd2638":"code","3a7203aa":"code","2866cb05":"code","5a92012c":"code","96cff499":"code","732cd068":"code","4457ec40":"code","7e46d923":"code","13e1dbee":"code","a2181ec9":"code","7262cef5":"code","ed3f020d":"code","88c73254":"code","d2799c3c":"code","6b261037":"code","08a8c5b6":"code","d2c058fe":"code","e1a1ff0c":"code","7dc1e92e":"code","5cab1448":"code","4de56f45":"code","fb92151f":"code","0ac41c6c":"code","f7f56a15":"code","a4a9be4e":"code","a7c1fa19":"code","055e3f6a":"code","f5471fbf":"code","5bf9ea1e":"code","aa18af54":"code","95e68298":"markdown","bacbcb83":"markdown","c7e9f65f":"markdown","35050824":"markdown","5e3c345c":"markdown","11ab3c14":"markdown","049439b4":"markdown","de8d7532":"markdown","3082ccf1":"markdown","05236847":"markdown"},"source":{"6f2bf544":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7e3253d":"!pip install catboost","35561857":"# Importing libraries \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport xgboost\nimport warnings \n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\nfrom sklearn.linear_model import LassoCV, LinearRegression\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\nfrom catboost import CatBoostRegressor\n\nfrom scipy.stats import norm, skew\nfrom scipy.special import boxcox1p\n\n\npd.pandas.set_option('display.max_columns', None)\npd.pandas.set_option('display.max_rows', None)\n\nwarnings.filterwarnings('ignore')","254cd2b2":"# Reading train and test sets\n\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","c280ef72":"print(\"Shape of train data:\", train.shape)\nprint(\"Shape of test data:\", test.shape)","b2ba9886":"#Making a copy of training data\n\ntrain_copy = train.copy()\ntest_copy = test.copy()","d1078239":"# Printing numeric columns and its count\n\nnum_cols = train._get_numeric_data().columns \ndisplay(num_cols)\nprint()\nprint(\"Count: \", len(num_cols))","0504a58a":"# Drawing box plots to check for outliers\n\nplt.figure(figsize = (25,45))\nfor i in enumerate(num_cols):\n  plt.subplot(13,3,i[0]+1)\n  sns.boxplot(train[i[1]])\n  plt.xlabel(i[1])","da6bb5b5":"'''\ntrain[train['LotFrontage']>300]\ntrain[train['LotArea']>200000]\ntrain[train['MasVnrArea']>1400]\ntrain[train['BsmtFinSF1']>5000]\ntrain[train['BsmtFinSF2']>1200]\ntrain[train['TotalBsmtSF']>4000]\ntrain[train['1stFlrSF']>4000]\ntrain[train['2ndFlrSF']>2000]\ntrain[train['GrLivArea']>5000]\ntrain[train['GarageArea']>1300]\ntrain[train['WoodDeckSF']>800]\ntrain[train['MiscVal']>8000]\ntrain[train['SalePrice']>700000] '''","3cc178ce":"# Index's to be removed from train set\n\nindex = [712, 1219, 1416, 1200, 1345, 1458, 773, 1248, 1423, 628, 973, 1458, 1459]\ntrain = train.drop(labels = index, axis = 0)","5cf5085c":"print(\"Shape of train data:\", train.shape)\nprint(\"Shape of test data:\", test.shape)","b405ab1e":"#Printing columns with Null values for train data\n\nNull_train = train.isnull().sum()\nNull_train[Null_train > 0]","74e2d2f0":"#Creating a list of columns to be removed and removing from train and test sets, assuming the columns with highest number\n#of missing values are likely to be in Test set\n\ndrop_columns = ['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'Id']\ntrain = train.drop(drop_columns, axis =1)\ntest = test.drop(drop_columns, axis = 1)\n\nprint(\"Shape of train data:\", train.shape)\nprint(\"Shape of test data:\", test.shape)","06a1a195":"#Analysing the null data in training set\n\nNull_train_data = train[['LotFrontage', 'FireplaceQu', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n      'BsmtFinType2', 'Electrical', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond']]","60cce23e":"#Creating a function with name 'analysis' for extracting data type, unique and null count\n\ndef analysis(data):\n    return pd.DataFrame({\"Data Type\":data.dtypes, \"Unique Count\":data.apply(lambda x: x.nunique(),axis=0), \n                         \"Null Count\": data.isnull().sum() })","35e94a59":"analysis(Null_train_data)","cfd557bf":"Null_train_data[['LotFrontage', 'MasVnrArea', 'GarageYrBlt']].describe()","5ac2dfde":"#Replacing numeric Null vlaues for training set\n\ntrain['LotFrontage'] = train['LotFrontage'].fillna((train['LotFrontage'].mean()))\ntrain['MasVnrArea'] = train['MasVnrArea'].fillna((train['MasVnrArea'].mode()[0]))\ntrain['GarageYrBlt'] = train['GarageYrBlt'].fillna((train['GarageYrBlt'].mode()[0]))","fc79b10c":"#Printing columns with Null values for test data\n\nNull_test = test.isnull().sum()\nNull_test[Null_test > 0]","b41b943c":"#Analysing the null data in training set\n\nNull_test_data = test[['MSZoning', 'LotFrontage', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', \n                         'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2',\n                         'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual', 'Functional', \n                         'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCars','GarageArea', \n                         'GarageQual', 'GarageCond', 'SaleType']]\nanalysis(Null_test_data)","77cfb841":"#Lets understand the distribution on the integer values\n\nNull_test_data[['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n                'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea']].describe()","ea5b8822":"#Replacing numeric Null vlaues for testing set\n\ntest['LotFrontage'] = test['LotFrontage'].fillna(test['LotFrontage'].mean())\ntest['MasVnrArea'] = test['MasVnrArea'].fillna(test['MasVnrArea'].mode()[0])\ntest['BsmtFinSF1'] = test['BsmtFinSF1'].fillna(test['BsmtFinSF1'].mode()[0])\ntest['BsmtFinSF2'] = test['BsmtFinSF2'].fillna(test['BsmtFinSF2'].mode()[0])\ntest['BsmtUnfSF'] = test['BsmtUnfSF'].fillna(test['BsmtUnfSF'].mean())\ntest['TotalBsmtSF'] = test['TotalBsmtSF'].fillna(test['TotalBsmtSF'].mean())\ntest['BsmtFullBath'] = test['BsmtFullBath'].fillna(test['BsmtFullBath'].mode()[0])\ntest['BsmtHalfBath'] = test['BsmtHalfBath'].fillna(test['BsmtHalfBath'].mode()[0])\ntest['GarageYrBlt'] = test['GarageYrBlt'].fillna(test['GarageYrBlt'].mode()[0])\ntest['GarageCars'] = test['GarageCars'].fillna(test['GarageCars'].mode()[0])\ntest['GarageArea'] = test['GarageArea'].fillna(test['GarageArea'].mean())","97aa5bfe":"# Creating a function to filter records with mode correlation\n\ndef correlation(data, limit):\n  col = set()\n  corr_matrix = data.corr()\n  for i in range(len(corr_matrix)):\n    for j in range(i):\n      if (corr_matrix.iloc[i, j]) > limit:\n        col_name = corr_matrix.columns[i]\n        col.add(col_name)\n  return col","ab8a37c3":"# Getting correlated columns \n\ncorr_columns = correlation(train, 0.7)\ncorr_columns","a20117fa":"#Dropping MiscFeature and MiscVal as their contribution towards the sale values doesnt seem much\n\ntrain = train.drop(['1stFlrSF', 'GarageArea', 'TotRmsAbvGrd'], axis = 1)\ntest = test.drop(['1stFlrSF', 'GarageArea', 'TotRmsAbvGrd'], axis = 1)\ntrain.head()","844a907b":"# Separating target variable \n\nHouse_Price = pd.DataFrame(train['SalePrice'])\ntrain = train.drop(['SalePrice'], axis = 1)","ed253aee":"# Distribution of target variable \n\nsns.displot(House_Price['SalePrice'], kde = True, color = 'Green')","0685b3bd":"# Log transformation of target variable \nsns.displot(np.log(House_Price['SalePrice']), kde = True, color = 'Black')","0503924f":"# Applying log on target variable\n\nHouse_Price = pd.DataFrame(np.log(House_Price['SalePrice']))","9d3983ab":"print(\"Shape of train data:\", train.shape)\nprint(\"Shape of test data:\", test.shape)","ae264b4f":"data = pd.concat([train, test])\ndata.shape","6628bbc9":"#Generating new columns \n\n#data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\ndata['YrBltRemod'] = data['YearBuilt'] + data['YearRemodAdd']\ndata['TotalBathrooms'] = (data['FullBath'] + (0.5 * data['HalfBath']) +\n                               data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath']))\ndata['TotalPorchSf'] = (data['OpenPorchSF'] + data['3SsnPorch'] +\n                              data['EnclosedPorch'] + data['ScreenPorch'] +\n                              data['WoodDeckSF'])\n\n#data[\"LivLotRatio\"] = data['GrLivArea']\/data['LotArea']\n\ndata[\"TotalOutsideSF\"] = sum((data['WoodDeckSF'],data['OpenPorchSF'],data['EnclosedPorch'], data['ScreenPorch']))\n\ndata['HouseAge'] = data['YrSold'] - data['YearBuilt']\n\ndata['OverallCondQual'] = (data['OverallCond'] + data['OverallQual'])\/2","22451ce2":"data_num_cols = data._get_numeric_data().columns \ndata_num_cols","e2b43ea6":"# Checking skewness \n\nskewed_feats = data[data_num_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"Skewed features :\\n\")\n\nskewness = pd.DataFrame()\nskewness['Skew_value'] = skewed_feats\nskewness.head(10)","f35f37aa":"skew_features = ['MiscVal','PoolArea','LowQualFinSF','3SsnPorch','LotArea','KitchenAbvGr','BsmtFinSF2','EnclosedPorch',\n                 'ScreenPorch', 'BsmtHalfBath']","ddc53cad":"#Applying boxcox on numeric columns \n\nkewness = skewness[abs(skewness) > 0.70]\n\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n  \n    data[feat] = boxcox1p(data[feat], lam)","eebe90dc":"data_num_cols = data._get_numeric_data().columns \ndata_num_cols","4ddd2638":"data_cat_cols = data.columns.difference(data_num_cols)\ndata_cat_cols","3a7203aa":"#Separating both numeric and categorical data from set\n\ndata_num_data = data.loc[:, data_num_cols]\ndata_cat_data = data.loc[:, data_cat_cols]\n\nprint(\"Shape of num data:\", data_num_data.shape)\nprint(\"Shape of cat data:\", data_cat_data.shape)","2866cb05":"# Scaling numeric variables \n\ns_scaler = StandardScaler()\ndata_num_data_s = s_scaler.fit_transform(data_num_data)\n\ndata_num_data_s = pd.DataFrame(data_num_data_s, columns = data_num_cols)","5a92012c":"# Scaling categorical variables \n\ndata_cat_data = data_cat_data.fillna('NA')\n\nlabel = LabelEncoder()\ndata_cat_data = data_cat_data.astype(str).apply(LabelEncoder().fit_transform)","96cff499":"data_num_data_s.reset_index(drop=True, inplace=True)\ndata_cat_data.reset_index(drop=True, inplace=True)\n\ndata_new = pd.concat([data_num_data_s, data_cat_data], axis = 1)","732cd068":"train_new = data_new.loc[:1447,]\ntest_new = data_new.loc[1448:,]\n\nprint(\"Shape of train data:\", train_new.shape)\nprint(\"Shape of test data:\", test_new.shape)","4457ec40":"#Spliting data\n\nfrom sklearn.model_selection import train_test_split \n\ntrainx,valx,trainy,valy = train_test_split(train_new,House_Price,test_size=0.2,random_state=1234)\n#print(cust_data.shape)\nprint(trainx.shape)\nprint(valx.shape)","7e46d923":"# Hyperparameter tuning code\n\n'''\nparams = {\n    \"learning_rate\" : [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n    \"max_depth\" : [7, 10, 15, 20, 25],\n    \"min_child_weight\" : [1, 2, 3, 5, 7],\n    \"gamma\" : [0.1, 0.2, 0.3],\n    \"colasample_bytree\" : [0.2, 0.3, 0.4]\n}\n\nclassifier = xgboost.XGBRegressor()\n\ngrd_search = GridSearchCV(classifier, param_grid = params, n_jobs = -1, cv = 5, verbose = 3)\n\ngrd_search.fit(trainx, trainy)\n\ngrd_search.best_estimator_'''","13e1dbee":"# Model fitting\n\nxgb = xgboost.XGBRegressor(base_score=0.5, booster='gbtree', colasample_bytree=0.2,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             gamma=0.1, importance_type='gain', learning_rate=0.1,\n             max_delta_step=0, max_depth=10, min_child_weight=1, missing=1,\n             n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n             seed=None, silent=None, subsample=1, verbosity=1)\n\nxgb.fit(trainx,trainy)","a2181ec9":"# Model predictions\n\nxgb_train_pred = xgb.predict(trainx)\nxgb_val_pred = xgb.predict(valx)","7262cef5":"# Calculating RMSE values\n\nxgb_train_rmse = mean_squared_error(trainy, xgb_train_pred, squared=False)\nxgb_val_rmse = mean_squared_error(valy, xgb_val_pred, squared=False)\n\nprint(\"Train RMSE: \", xgb_train_rmse)\nprint(\"Test RMSE: \", xgb_val_rmse)","ed3f020d":"# Predicting on test values\n\nxgb_test_pred = xgb.predict(test_new)","88c73254":"# Storing values in a dataframe: submission_xgb\n\nsubmission_xgb = pd.DataFrame(test_copy[['Id']])\nsubmission_xgb['SalePrice'] = np.exp(xgb_test_pred)\nsubmission_xgb.head()","d2799c3c":"# Model fitting\n\nlasso_model = LassoCV(alphas = [1, 0.1, 0.001, 0.0005])\n\nlasso_model.fit(trainx, trainy)\nlasso_model.get_params()","6b261037":"# Model predictions\n\nlso_train_pred = lasso_model.predict(trainx)\nlso_val_pred = lasso_model.predict(valx)","08a8c5b6":"# Calculating RMSE values\n\nlso_train_rmse = mean_squared_error(trainy, lso_train_pred, squared=False)\nlso_val_rmse = mean_squared_error(valy, lso_val_pred, squared=False)\n\nprint(\"Train RMSE: \", lso_train_rmse)\nprint(\"Test RMSE: \",lso_val_rmse)","d2c058fe":"# Predicting on test values\n\nlso_test_pred = lasso_model.predict(test_new)","e1a1ff0c":"# Storing values in a dataframe: submission_ls\n\nsubmission_ls = pd.DataFrame(test_copy[['Id']])\nsubmission_ls['SalePrice'] = np.exp(lso_test_pred)\nsubmission_ls.head()","7dc1e92e":"# Model fitting\n\nlr = LinearRegression()\nlr.fit(trainx, trainy)","5cab1448":"# Model predictions\n\nlr_train_pred = lr.predict(trainx)\nlr_val_pred = lr.predict(valx)","4de56f45":"# Claculating RMSE values\n\nlr_train_rmse = mean_squared_error(trainy, lr_train_pred, squared=False)\nlr_val_rmse = mean_squared_error(valy, lr_val_pred, squared=False)\n\nprint(\"Train RMSE: \", lr_train_rmse)\nprint(\"Test RMSE: \",lr_val_rmse)","fb92151f":"# Predicting on test set\n\nlr_test_pred = lr.predict(test_new)","0ac41c6c":"# Storing values in a dataframe: submission_lr\n\nsubmission_lr = pd.DataFrame(test_copy[['Id']])\nsubmission_lr['SalePrice'] = np.exp(lr_test_pred)\nsubmission_lr.head()","f7f56a15":"# Model fitting\n\ncat = CatBoostRegressor(random_state=0,verbose=False, depth = 5, early_stopping_rounds=300, learning_rate= 0.1)\ncat.fit(trainx, trainy)","a4a9be4e":"# Model predictions\n\ncat_train_pred = cat.predict(trainx)\ncat_val_pred = cat.predict(valx)","a7c1fa19":"# Calculating RMSE values\n\ncat_train_rmse = mean_squared_error(trainy, cat_train_pred, squared=False)\ncat_val_rmse = mean_squared_error(valy, cat_val_pred, squared=False)\n\nprint(\"Train RMSE: \", cat_train_rmse)\nprint(\"Test RMSE: \",cat_val_rmse)","055e3f6a":"# Predicting on test set\n\ncat_test_pred = cat.predict(test_new)","f5471fbf":"# Storing values in a dataframe: submission_cat\n\nsubmission_cat = pd.DataFrame(test_copy[['Id']])\nsubmission_cat['SalePrice'] = np.exp(cat_test_pred)\nsubmission_cat.head()","5bf9ea1e":"submission_file = pd.DataFrame()\nsubmission_file['Id'] = test_copy['Id']\nsubmission_file['SalePrice'] = (submission_xgb['SalePrice']+submission_ls['SalePrice']+submission_lr['SalePrice']+submission_cat['SalePrice'])\/4\nsubmission_file.head()","aa18af54":"submission_file.to_csv(\"Submission.csv\", index = False)","95e68298":"### 3. Mutiple Linear Regression","bacbcb83":"### 2. Lasso","c7e9f65f":"## Models","35050824":"## Submission File","5e3c345c":"### 4. CatBoost","11ab3c14":"- Using above gridsearch cv, found optimal parameters and they mentioned below","049439b4":"Observations:\n- many attributes are having otuliers, so I have looked at each attribute individually and choosed records to be removed ","de8d7532":"Observations:\n- For 'LotFrintage' we can use Mean or Median as both are very close to each other\n- For 'GarageYrBlt' and 'MasVnrArea' lets use Mode to replace missing vlaues","3082ccf1":"### 1. XGBoost","05236847":"- Above four attribtues are having correlation greater than 0.7, will drop all except SalePrice"}}