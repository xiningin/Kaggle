{"cell_type":{"7ebd84e7":"code","f8258214":"code","b14fd327":"code","a4e495e8":"code","ec78a034":"code","28d280f5":"code","eb3c4816":"code","57d44a23":"code","916a7adf":"code","9975661d":"markdown","d636e86e":"markdown","9a542284":"markdown","f2581de5":"markdown"},"source":{"7ebd84e7":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler","f8258214":"dtrain = pd.read_parquet('..\/input\/dtrain-parquet\/dtrain.parquet')\ndtrain = dtrain[[c for c in dtrain.columns if 'feature' in c]]","b14fd327":"dtrain.isna().any(axis=1).sum() \/ dtrain.index.size","a4e495e8":"dtrain = dtrain.dropna()","ec78a034":"scaled = StandardScaler().fit_transform(dtrain)\nscaled[:, 0] = ((dtrain['feature_0'] - dtrain['feature_0'].mean()) \/ 2 * dtrain['feature_0'].std()).to_numpy()","28d280f5":"pca = PCA(n_components=.95).fit(scaled)","eb3c4816":"print(pca.explained_variance_ratio_.size)\n\npd.DataFrame(pca.explained_variance_ratio_.cumsum()).plot(style='.', legend=False)\nplt.xlabel('principal component #')\nplt.ylabel('explained variance')\nplt.show()","57d44a23":"pd.DataFrame({\n    'eigenvalues': pca.explained_variance_, \n    'explained variance': pca.explained_variance_ratio_,\n    'cumulative expl. var.': pca.explained_variance_ratio_.cumsum()\n})","916a7adf":"print(PCA(n_components=.99).fit(scaled).n_components_)","9975661d":"# PCA","d636e86e":"# Standardisation\nIn order to perform PCA we must first standardise the data; i.e. scale all features to the same dimension. `StandardScaler` does exactly this, scaling the standard deviation of each column to exactly 1 and the mean to exactly 0. It does so with:\n$z = (x_i - \\mu) \/ \\sigma$. Binary data (`feature_0`) cannot be handled like this, instead it has to be scaled by $2\\sigma$. See [Gelman and Hill, 2006, p. 57](https:\/\/doi.org\/10.1017\/CBO9780511790942).","9a542284":"A total of 38 principal components can already explain 95% of the variance in data. About 29% of the original amount of features!","f2581de5":"# Missing Values\n\nNote that `sklearn.decomposition.PCA` cannot handle missing values. I drop the incomplete observations here, but there are implementations of PPCA that are able to handle missing values. See https:\/\/stackoverflow.com\/a\/56576569\/1838257 for pointers."}}