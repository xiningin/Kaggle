{"cell_type":{"2d89d874":"code","840ccd4b":"code","e448ad72":"code","4321e434":"code","2f90b443":"code","75ed5fd7":"code","2ce72767":"code","233758bd":"code","a1210478":"code","177ae6a2":"code","dc462079":"code","a05467a9":"code","a0393a95":"code","e71af5c3":"code","913ee7eb":"code","b6b9c98b":"code","12bb62a0":"markdown","e202dac5":"markdown","ef6eff38":"markdown","0bc133ea":"markdown","010af8d0":"markdown","b5a070e5":"markdown","48229e55":"markdown","64fb2132":"markdown","ece12ffd":"markdown","d9441e18":"markdown","b24585ba":"markdown","cbf9ace9":"markdown","0f5b601f":"markdown","a0071bfc":"markdown","6a6aed95":"markdown","69c52ec4":"markdown","d7d2d64c":"markdown","0ec04a41":"markdown"},"source":{"2d89d874":"import pickle\n\nfrom pathlib import Path\nfrom pprint import pprint  # pprint is a function to pretty print dictionaries and lists\n\nlabels = pickle.load(Path('\/kaggle\/input\/cifar100\/meta').open('rb'))\npprint(labels, compact=True)","840ccd4b":"train_data = pickle.load(Path('\/kaggle\/input\/cifar100\/train').open('rb'), encoding='bytes')\nprint(f'Train Data Keys: {list(train_data.keys())}')\n\ntest_data = pickle.load(Path('\/kaggle\/input\/cifar100\/test').open('rb'), encoding='bytes')\nprint(f'Test Data Keys: {list(test_data.keys())}')","e448ad72":"import matplotlib.pyplot as plt\nimport torch\nfrom torchvision.utils import make_grid\n%matplotlib inline\n\nimages = train_data[b'data']\nprint(\"initial shape:\" ,images.shape)\n\n# TODO:\n# determine the correct shape of the data\n# reshape the data accordingly\n# display some images (transpose or permute the axes as necessary)\n# TASK START - Start coding here:\nraise NotImplementedError()\n# TASK END","4321e434":"import numpy as np\nimport torchvision.transforms as tt\n\nfrom typing import Union, Type\n\nfrom imgaug import augmenters as iaa\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\n\nclass CIFAR100(Dataset):\n    \n    def __init__(self, dataset_path: Path, image_transforms: tt.Compose, image_augmentations: Union[None, Type[iaa.Augmenter]] = None):\n        super().__init__()\n        data = pickle.load(dataset_path.open('rb'), encoding='bytes')\n        # TODO: store the images and the (fine) labels in class variables to be able to easily access them later on\n        # TASK START - Start coding here:\n        raise NotImplementedError()\n        # TASK END\n        \n        self.image_transforms = image_transforms\n        self.image_augmentations = image_augmentations\n        \n        assert len(self.images) == len(self.labels), \"Number of images and labels is not equal!\"\n        \n    def __len__(self) -> int:\n        # TODO: return the length of the dataset, i.e., the number of available images \n        # TASK START - Start coding here:\n        raise NotImplementedError()\n        # TASK END\n    \n    def __getitem__(self, index: int) -> tuple:\n        # TODO: write the data loading code:\n        # 1. get image and label for the corresponding index\n        # 2. reshape the image array into the correct shape\n        # 3. apply image augmentations *if* necessary (we should not augment the test data) - check if `self.image_augmentations` is not None\n        #    HINT: use something like the following line to augment a single image (within the if clause):\n        #              image = self.image_augmentations.augment_image(image)\n        # 4. transform the image to a tensor using the image_transforms\n        # 5. return a tuple of image and label\n        # TASK START - Start coding here:\n        raise NotImplementedError()\n        # TASK END\n","2f90b443":"image_transformations = tt.Compose([\n    tt.ToTensor(),\n    tt.Normalize((0.5074,0.4867,0.4411),(0.2011,0.1987,0.2025))\n])\n\ntrain_augmentations = iaa.Sequential([\n    iaa.Fliplr(0.5),\n    iaa.CropAndPad(percent=(-0.25, 0.25))\n])","75ed5fd7":"example_train_data = CIFAR100(Path('\/kaggle\/input\/cifar100\/train'), image_transformations, train_augmentations)\nexample_image, example_label = example_train_data[0]\nprint(f\"Image shape: {example_image.shape}\")                                    # Image shape: torch.Size([3, 32, 32])\nprint(f\"First pixel: {example_image[:,0,0]}\")                                   # First pixel: tensor([...])\nprint(f\"Class: {example_label} - {labels['fine_label_names'][example_label]}\")  # Class: 19 - cattle","2ce72767":"from torch.utils.data import DataLoader\n\ntrain_dataset = CIFAR100(Path('\/kaggle\/input\/cifar100\/train'), image_transformations, train_augmentations)\n# TODO: build the `train_data_loader` using the `DataLoader` class of PyTorch\n# TASK START - Start coding here:\nraise NotImplementedError()\n# TASK END\n\ntest_dataset = CIFAR100(Path('\/kaggle\/input\/cifar100\/test'), image_transformations)\n# TODO: build the `test_data_loader` using the `DataLoader` class of PyTorch\n# TASK START - Start coding here:\nraise NotImplementedError()\n# TASK END","233758bd":"import torch\nimport torch.nn as nn\nimport cifar100_resnets as models\n\n\nclass CIFAR100Net(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        # TODO:\n        # create the model by instantiating the recommended resnet 20 (save it as `self.feature_extractor`)\n        # set `num_classes` to the number of classes of CIFAR-100\n        # TASK START - Start coding here:\n        raise NotImplementedError()\n        # TASK END\n        \n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        # TODO: pass the images through the saved `self.feature_extractor` and return the result\n        # TASK START - Start coding here:\n        raise NotImplementedError()\n        # TASK END\n","a1210478":"test_net = CIFAR100Net()\ntest_batch_size = 2\ndummy_data = torch.rand((test_batch_size,3,32,32))\nresult = test_net(dummy_data)\n\nprint(\"Network output:\", result.shape)\n# Expected Output (otherwise something is wrong): Network output: torch.Size([2, 100])\n\nassert result.shape[0] == test_batch_size, \"the network should output one prediction for each sample in the batch\"\nassert result.shape[1] == 100, \"the network should output predictions for 100 classes\"","177ae6a2":"from typing import Type\nfrom torch.optim import Optimizer\n\nloss_function = nn.CrossEntropyLoss()\n\ndef train_for_one_iteration(network: Type[nn.Module], batch: tuple, optimizer: Type[Optimizer]) -> float:\n    images, labels = batch\n    # TODO:\n    # pass the images through the network (store the predictions in a variable)\n    # then calculate the loss using the loss_function based on the predictions and the labels\n    # TASK START - Start coding here:\n    raise NotImplementedError()\n    # TASK END\n    \n    # Here come the real weight adjustments, first zero gradients, then calculate derivatives, followed by the actual update of the optimizer\n    optimizer.zero_grad()  # this sets gradients to zero (e.g. to clean up from any previous backward passes)\n    loss.backward()        # calculate gradients for our network\n    optimizer.step()       # update all weights in our network according to the computed gradients\n    \n    return float(loss.item())\n    ","dc462079":"from tqdm.notebook import tqdm  # import a library for displaying a nice progressbar\n\nimport torch.nn.functional as F  # import torch functions, this contains softmax\n\ndef test_model(network: Type[nn.Module], data_loader: DataLoader) -> float:\n    num_correct_predictions = 0\n    device = get_device()\n    \n    for images, labels in tqdm(data_loader, desc=\"Testing...\", leave=False):\n        images = to_device(images, device)\n        labels = to_device(labels, device)\n        # TODO:\n        # 1. get the network predictions, by passing the images through our networks\n        # 2. calculate the output of the softmax function on our predictions (hint: do it on the dimension 1, which is the dimension of our 100 classes)\n        # 3. store the predicted class, by finding the argument with the maximum value for each sample (thus working on dimension 1 again)\n        # 4. count the cases where the predicted class is equal to the labels \n        # TASK START - Start coding here:\n        raise NotImplementedError()\n        # TASK END\n        num_correct_predictions += correct_predictions\n        \n        \n    accuracy = num_correct_predictions \/ len(data_loader.dataset)\n    return float(accuracy.item())\n        ","a05467a9":"def get_device() -> torch.device:\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    return torch.device(\"cpu\")\n\n\ndef to_device(data: torch.Tensor, device: torch.device) -> torch.Tensor:\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device)","a0393a95":"import statistics\n\nfrom collections import defaultdict\n\nfrom tqdm.notebook import trange\n\ndef train(train_data: DataLoader, test_data: DataLoader, network: Type[nn.Module], optimizer: Type[Optimizer], num_epochs: int) -> dict:\n    device = get_device()\n    metrics = defaultdict(list)\n    for epoch in trange(num_epochs, desc=\"Epoch: \"):\n        losses = []\n        with tqdm(total=len(train_data), desc=\"Iteration: \") as progress_bar:\n            for iteration, batch in enumerate(train_data):\n                batch = to_device(batch, device)\n                loss = train_for_one_iteration(network, batch, optimizer)\n                losses.append(loss)\n                progress_bar.update()\n                metrics[\"losses\"].append({\"iteration\": epoch * len(train_data) + iteration, \"value\": loss})\n\n            accuracy = test_model(network, test_data)\n            metrics['accuracy'].append({\"iteration\": (epoch + 1) * (len(train_data)), \"value\": accuracy})\n\n            progress_bar.set_postfix_str(f\"Epoch {epoch}, Mean Loss: {statistics.mean(losses):.2f}, Test Accuracy: {accuracy:.2f}\")\n    \n    return metrics","e71af5c3":"learning_rate = 0.001\nnum_epochs = 50","913ee7eb":"# create the network and make sure to transfer it to the GPU if a GPU is available\nnetwork = CIFAR100Net()\nnetwork = network.to(get_device())\n\n# create an optimizer for training, here we use Adam. However, you can also try other optimizers later on.\noptimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n\n# we are done with all setup and can start the training\nlogged_metrics = train(train_data_loader, test_data_loader, network, optimizer, num_epochs)","b6b9c98b":"def plot_metrics(metrics: dict):\n    # we prepare the plotting by creating a set of axes for plotting, we want to put each metric in its own plot in a separate row\n    # furthermore, all plots should share the same x-axis values\n    fig, axes = plt.subplots(len(metrics), 1, sharex=True, figsize=(10, 10))\n\n    # we want to have a set of distinct colors for each logged metric\n    colors = iter(plt.cm.rainbow(np.linspace(0, 1, len(metrics))))\n    \n    # TODO: (optional task)\n    # implement the actual plotting\n    # TASK START - Start coding here:\n    raise NotImplementedError()\n    # TASK END\n    plt.show()\n    \nplot_metrics(logged_metrics)","12bb62a0":"As we can see, this file contains a dictionary with all label names.\nOn the one hand the coarse label names of CIFAR-100\/20 and on the other hand the fine label names of CIFAR-100.  \nWe are interested in the fine labels CIFAR-100.\nThe list of fine labels does not only provide us the name of each class, we also receive the id of each class as the index of the label name in the list.\n\nAlright let's now have a look at the training and testing data:","e202dac5":"We are done with most of the coding.\nThe last things we need to do is the setup of all parts that can be changed without problem, namely setting of necessary hyperparameters, creation of the network, instantiation of the optimizer, transferring of the model to the GPU (if GPU is enabled).\n\n### Setting of Hyperparameters\n\nFirst, we are going to set some hyperparameters, such as the learning rate, the number of epochs we want to train the model.","ef6eff38":"# What now?\n\nWe are done with the second practical exercise.\nMake sure to remember the results you got using the parameters and default settings provided in this notebook.\nWe will have a question in the graded exercise about the value range you received (hint: it should be better than 30% accuracy)\n\nBut what can you do now?\nWell, if you want to play around with the network and make it perform even better, you can try to change some things here and there!\nSome suggestions for you:\n- add more data augmentations (have a look at the possible data augmentation strategies the [imgaug](https:\/\/imgaug.readthedocs.io\/en\/latest\/index.html) library provides)\n- add learning [rate scheduling](https:\/\/pytorch.org\/docs\/stable\/optim.html#how-to-adjust-learning-rate)!\n- you can also try to use a different network architecture!\n\nWhatever happens, have fun!","0bc133ea":"Now we should probably test our data loading based on these transform functions.\nTo do this, we can load the first image of the training dataset with the following code and check the result:","010af8d0":"As we can see, both files contain a dictionary with data.\nWe are mostly interested in the following keys: `fine_labels` and `data` because we will need the data from these lists to train our model.\n\nYou should play around with the data a bit more to get a feeling of the way it is saved.\nSuch information is important because otherwise, you will not be able to correctly load the data.\n\n# Task 2: Building the Data Loading\n\nBefore we can train anything, we need to explore the data a bit and create code for data loading.\nIn PyTorch, we can simply create a new subclass of the class `Dataset`.\nThe task of this class is to provide the training loop with the correct image and label if asked.\nThe dataset will also perform necessary image transformations, such as normalization and even augmentation.\n\nYour first task is to complete the code of our dataset class using the knowledge you gathered about our input data:","b5a070e5":"Now that we defined our dataset loader, we need to define two more things:\n1. the transformations to apply to our images\n1. some code that can be used to iterate over all images in an epoch.\n\n### Image Transformations\n\nWe will now investigate how we can define image transformations.\nPyTorch includes a set of predefined image [transformations](https:\/\/pytorch.org\/vision\/stable\/transforms.html#) that we can use to ease image loading.\nIn this example, we only use the tensor transformation which normalizes the values of the tensor into the range [0-1] and also transposes the tensor to the shape [`num_channels`, `height`, `width`].\nWe also add some image augmentations from the great [imgaug](https:\/\/imgaug.readthedocs.io\/en\/latest\/) library.\nHere, we add random horizontal flips and also random crops:","48229e55":"## Task 4b: Implement The Network Testing\n\nA full training consists of going through the entire train dataset multiple times (so called epochs).\nIn each iteration of an epoch, we forward a batch of our training data through the network and update the network (as implemented above).\nAt the end of each epoch, we should run our trained network on the test dataset to see how it performs on unseen data.\n\nFor testing, we run the data of the full test dataset through the network and calculate the prediction accuracy of our network:\n\nHere, you'll need to forward the images through the network, run the softmax function on the outputs to get a probability distribution, get the most probable class from the output of the network and the calculate the number of `correct_predictions`.","64fb2132":"To do a very basic test of our implementation, we can instantiate our network, and try to pass randomized data through it.\nRunning the following cell does that:","ece12ffd":"# Training an Image Classificaton Network on CIFAR-100 using PyTorch\n\nThis is the second practical exercise of our course [Applied Edge AI](https:\/\/learn.ki-campus.org\/courses\/edgeai-hpi2022).\nIn this exercise, we will introduce basic PyTorch functionalilty for the training of image classification models.\nWe will use the CIFAR-100 dataset as an example dataset because training on this dataset does not require too many resources and should easily be doable as an exercise.\n\nThis notebook contains code that is incomplete.\nPlease fill all gaps with your code and train a model.\nIn the graded quiz at the end of the week, we might ask some questions that deal with this exercise, so make sure to do the exercise (and have your output handy) **before** taking the quiz!","d9441e18":"# Optional Task: Rendering of Metrics\n\nLooking only at the output of the train metrics such as loss and accuracy provides us with some information about the progress and success of the training.\nTo gain more insights, it makes sense to also plot the training metrics to get a better visualization.\n\nThis is our final but **optional** task for this exercise.\nIf you want to skip this task, please continue to \"What now?\" below.\nWe are going to provide a solution for this task at the end of the week.\n\nWe can use the matplotlib library (that we already used above to plot our logged metrics.\nSince we are looking at a progression of values, it makes sense to use a [line-chart](https:\/\/pythonbasics.org\/matplotlib-line-chart\/) for such a plot.\nKeep in mind that the `train` method returns all logged metrics as a dictionary with each key holding a list of dictionaries, where each item of the list contains one key to indicate the iteration the value was logged on and the other key indicating the logged value.","b24585ba":"Now, it is time to build our training loop code.\nHere we go through our training dataset for a given amount of epochs.\nWe also management where our training will run (either on CPU, or on the GPU).\nWe already prepared all code for you, enjoy!","cbf9ace9":"Okay that was simple, wasn't it?\nIf you want to build more complex models it is really helpful to have a separate class for such a model!\n\n# Task 4: Training the network\n\nNow, we implemented the data loading and the neural network.\nWe need to implement our training code to be able to train our neural network.\nThe training of a neural network (as you know) involves the following compontents:\n\n1. Loss Function\n1. Backward Propagation\n1. Optimizer\n1. Iterative Process\n\nWe will now have a look at all these still missing parts.\n\n\n## Task 4a: Running one Iteration of the Train Process\n\nOne iteration includes a forward pass through our network, the calculation of the loss using a loss function (we are going to use softmax cross entropy for a multi-class classification problem ([PyTorch Documentation](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.CrossEntropyLoss.html)). After the calculation of the loss, we need to prepare the network for backpropagation. For this, we use the optimizer to zero the gradients stored in the network ([Pytorch Documentation](https:\/\/pytorch.org\/tutorials\/recipes\/recipes\/zeroing_out_gradients.html#zero-the-gradients-while-training-the-network)).\nOnce we cleared the gradients, we can run the backpropagation by calling backward on the obtained `loss`.\nAfter gradient calculation, we run the update rule of the optimizer.\nThat's it we ran one training iteration \\O\/\n\nAt the end of the function, we can return the calculated loss for logging of our current process.","0f5b601f":"## Data on CPU vs. GPU\n\nAnother thing, that we need to take care is handle where our data should live (either CPU or GPU).\nIn PyTorch, we have to handle this manually.\nHowever, it is a simple task to handle this.\nIn this task, we assume that we train on only one GPU.\nThus, we just need to check whether a GPU is available, if a GPU is available, we can transfer our data to the GPU by using a simple function right after loading:","a0071bfc":"# The CIFAR-100 Dataset\n\n![cifar100 image](https:\/\/web.stanford.edu\/~hastie\/CASI_files\/DATA\/cifar100.jpg)\n\nThe CIFAR-100 database is a dataset containing `100` classes, where each class contains `600` images, which are divided into `500` images for training and `100` images for testing.\nThe images have a resolution of `32x32` pixels.\nIf you want to know more about the CIFAR-100 dataset, please [click here](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html).\n\nWe will use this dataset to train an image classification model with 100 classes.  \nTo do this, we will build a deep learning network with PyTorch by following these steps:\n\n1. write code to load and prepare the data for training\n1. write code that defines the neural network we wish to use\n1. write code that performs the training and upate of our network using the data\n\n## Loading the Dataset\n\nWe already added the CIFAR-100 dataset as input to this notebook.\nYou can access the data via `\/kaggle\/input\/cifar100`.\nThere, you can find the files `meta`, `test`, and `train`.\n\nLet us first have a look at the `meta` file:","6a6aed95":"### Axis Order\n\nNote, that when working with deep learning frameworks, datasets, and image libraries the meaning of the array axes is quite important.\nThe libraries we use expect a certain order, since they need to \"know\" whether an array with a shape of 3x32x32 is one RGB image or three grayscale images.\nThus you often will recognize that a particular code, such as NCHW or NHWC is used to describe the expected order of axes.\nIn this code, the letters usually stand for the following:\n\n- N: *batch axes* (selecting one item along this axis would select one complete image)\n- C: *color\/channel axes*\n- H: *height axes*\n- W: *width axes*\n- D: *depth axes* (usually only used when working with 3d images or tensors)\n\n### Reordering the Axes\n\nWe need to figure out which format the axes are in, when loading the data, since the data we are loading from CIFAR is not shaped and ordered correctly yet.\nOur data loader should return the data of a single image in HWC format, thus it makes sense to store the data in NHWC format first (we can simply select one image with the `[]` operator in python).\n\nTherefore, we should do some more data exploration to figure out how the data is stored in the given files.\nHere, it makes sense to examine the `shape` of the stored arrays and visualize some images, because we will need to do this to successfully load the images in our data loader.\nAlso remember that the CIRAR data consists of RGB images (3 color channels) with a size of 32x32 pixels.\n\nThere are two options: visualize a single image (easier), or visualize a set of images (harder).\nIn the following we provide a few hints for both approaches to this task:\n\n- Load the image data from either `train_data` or `test_data` (already done below)\n- Determine the correct shape of the array and reshape it accordingly\n- (A) Single Image:\n    - Tranpose the array of all images to NHWC with [transpose](https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.transpose.html)\n    - Show one of the images with [plt.imshow](https:\/\/matplotlib.org\/stable\/api\/_as_gen\/matplotlib.pyplot.imshow.html)\n- (B) Set of Images:\n    - Create a figure with [plt.subplots](https:\/\/matplotlib.org\/stable\/api\/_as_gen\/matplotlib.pyplot.subplots.html)\n    - Add an empty list of ticks for x and y\n    - Create a torch tensor from a few images (e.g. 20) and use [make_grid](https:\/\/pytorch.org\/vision\/stable\/utils.html)\n    - Reorder the axes to the NHWC format with [permute](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.permute.html)\n    - Show the images with [plt.imshow](https:\/\/matplotlib.org\/stable\/api\/_as_gen\/matplotlib.pyplot.imshow.html)\n    \n# Task 1: Getting to Know the CIFAR-100 Dataset\n\nIn the following you can start programming a few codelines on your own to try to correctly visualize a few images in the dataset with one (or both) of the approaches described above.","69c52ec4":"Before starting the training below, you should enable the GPU acclerator in the sidebar on the right (you can open the sidebar by clicking on the |< Symbol in the top right, then select *Settings*, *Accelerator*, *GPU*).\n\nIf you have not done so at the beginning of working on this exercise (which is fine), this means the other cells need to be run again.\nTo do so, you can select *Run All* in the top toolbar.\nThe notebook should run most of the previous cells very quickly until the training below is executed.","d7d2d64c":"Following the preparation of the transforms, we build our dataset objects and put them into PyTorch [DataLoader](https:\/\/pytorch.org\/docs\/stable\/data.html) objects.\nA `DataLoader` is used to iterate over the given dataset. The dataloader prepares batches of a given batch size for us and can also help with shuffling the data.\n\nHave a look at the documentation of the data loader and create a meaningful data loader for train and test data:\n* Both loaders should use a batch size of `64`.\n* The *train data loader* should shuffle the data. (The test loader typically does not shuffle the data, but doing it there as well does not matter.)\n* Both loaders should use `num_workers=2` which uses multiple processes for preprocessing the data.","0ec04a41":"# Task 3: Defining the Neural Network\n\nNow that we have the data ready, we need to define the neural network we wish to use for training.\nHere, we can either define it completely by ourselves, or we can use a set of pre-defined methods for this.\n\nIn any way, we should always define at least the base network by ourselves.\nTo do this, PyTorch provides us with a base class that we can subclass, the [Module](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.Module.html).\nA module contains all code that is necessary to perform a forward pass through our model.\nIt makes sense to use a new subclass of the `Model` class because in that way we can distinguish between different tasks in a better way.\n\nYour task is to write a module that takes as input an image tensor and returns a tensor with the shape `[batch_size, 100]` (100 represents all possible classes).\nYou can either define your own Network (**not recommended**), or you use a pre-defined feature extractor (**recommended**).\nYou can find a list of pre-defined feature extractors that work nicely with the small images of CIFAR-100 [here](https:\/\/www.kaggle.com\/bartzi\/cifar100-resnets). Please use a ResNet-20 feature extractor here!\nYou can use another feature extractor, once you are done with all tasks of this notebook!"}}