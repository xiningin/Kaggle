{"cell_type":{"cc921ea1":"code","87d18425":"code","e3e793b0":"code","f9166309":"code","07ff6862":"code","040ce350":"code","46787fa3":"code","1b2c9b94":"code","b4a29de0":"code","135a0325":"code","bf567832":"code","2bec3361":"code","d79bed21":"code","aff42867":"code","846b15d6":"code","b5b4cf07":"code","af38a155":"code","692c0cbc":"code","5418efa7":"code","f1922278":"code","1470a000":"code","065f4945":"code","de1591d4":"code","a9f039d9":"code","34859fd9":"code","8720fb5d":"code","36fd025f":"code","dc1c3e9e":"code","da45ce7a":"code","66e266ff":"code","f8ab2d8a":"code","eb53c668":"code","44262879":"code","09f19c7b":"code","f0331778":"code","384f1155":"code","3451d55e":"code","ca353d50":"code","a5f8d265":"code","7a08fd64":"code","102aa6d5":"code","8bff9575":"code","61acc202":"code","cedeadf2":"code","4957a8b7":"markdown"},"source":{"cc921ea1":"import time\nt0 = time.time()","87d18425":"# First install recent version of Numba and HDBScan","e3e793b0":"!conda install -y --channel numba numba","f9166309":"!pip install hdbscan","07ff6862":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport time\nfrom sympy import isprime, primerange\nfrom math import sqrt\nfrom tqdm import tqdm\nimport numba\nimport hdbscan\nfrom sklearn.neighbors import KDTree\nfrom itertools import combinations, permutations\nfrom functools import lru_cache\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import collections  as mc\nimport warnings\nwarnings.filterwarnings('ignore')\nseed = 2019","040ce350":"# Part1: Find good score quickly\n# Wee need Numba 0.41 or higher.\nprint(numba.__version__)","46787fa3":"# Read cities and find primes\ncities = pd.read_csv('..\/input\/cities.csv')\ncities[\"X\"] = cities[\"X\"].astype(np.float64)\ncities[\"Y\"] = cities[\"Y\"].astype(np.float64)\nis_not_prime = np.array([0 if isprime(i) else 1 for i in cities.index], dtype=np.int32)\ncities[\"is_not_prime\"] = is_not_prime\ncities.head(10)","1b2c9b94":"# Fast distance and score thanks to Numba\n# Updated from: https:\/\/www.kaggle.com\/kostyaatarik\/not-a-3-and-3-halves-opt\nXY = np.stack((cities.X, cities.Y), axis=1)\n\n@numba.jit('f8(i4, i8[:])', nopython=True, parallel=False)\ndef distance_chunk(offset, chunk):\n    pure_distance = 0.0\n    for path_index in numba.prange(chunk.shape[0] - 1):\n        id_from, id_to = chunk[path_index], chunk[path_index+1]\n        xy_from, xy_to = XY[id_from], XY[id_to]\n        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n        distance = sqrt(dx * dx + dy * dy)\n        pure_distance += distance\n    return pure_distance\n\n\n@numba.jit('f8(i4, i8[:])', nopython=True, parallel=False)\ndef score_chunk(offset, chunk):\n    pure_distance, penalty = 0.0, 0.0\n    penalty_modulo = 9 - offset % 10\n    for path_index in numba.prange(chunk.shape[0] - 1):\n        id_from, id_to = chunk[path_index], chunk[path_index+1]\n        xy_from, xy_to = XY[id_from], XY[id_to]\n        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n        distance = sqrt(dx * dx + dy * dy)\n        pure_distance += distance\n        if path_index % 10 == penalty_modulo and is_not_prime[id_from]:\n            penalty += distance\n    return pure_distance + 0.1 * penalty\n\n\n@numba.jit('f8(i8[:])', nopython=True, parallel=False)\ndef score_path(path):\n    return score_chunk(0, path)\n\n\n@numba.jit('f8(i8[:])', nopython=True, parallel=False)\ndef distance_path(path):\n    return distance_chunk(0, path)","b4a29de0":"# Basic visualizations\n# Run DBScan to find out parts with similar densities\n# https:\/\/hdbscan.readthedocs.io\/en\/latest\/how_hdbscan_works.html\n# We expect long path within each cluster.\nclusterer = hdbscan.HDBSCAN(min_cluster_size=600, min_samples=1)\nclusterer.fit(cities[['X', 'Y']].values)\ncities['hc'] = clusterer.labels_\n# Display primes\/non primes and all\nfig, ax = plt.subplots(2, 2, figsize=(24, 18))\nd = cities[cities[\"is_not_prime\"] == 1].plot(kind=\"scatter\", x=\"X\", y=\"Y\", s=1, c=\"blue\", alpha=0.25, ax=ax[0][0], title=\"non primes: %d\" % (len(cities[cities[\"is_not_prime\"] == 1])))\nd = cities[cities[\"is_not_prime\"] == 0].plot(kind=\"scatter\", x=\"X\", y=\"Y\", s=1, c=\"r\", alpha=0.25, ax=ax[0][1], title=\"primes: %d\" % (len(cities[cities[\"is_not_prime\"] == 0])))\nd = cities.plot(kind=\"scatter\", x=\"X\", y=\"Y\", s=1, alpha=0.9, ax=ax[1][0], title=\"All: %d\" % (len(cities)))\nd = cities.plot(kind=\"scatter\", x=\"X\", y=\"Y\", s=1, c=cities['hc'], cmap=plt.cm.tab20, alpha=0.9, ax=ax[1][1], title=\"All with cluster by density: %d\" % (len(cities)))","135a0325":"# Functions to read\/write LKH tour and TSP file.\ndef write_lkh_files(lkh_df, filename_par, filename_tsp, filename_tour, filename_initial_tour=None, real=False, bw=False):\n    l = len(lkh_df)\n    \n    with open(filename_par, \"w\") as f:\n        f.write(\"PROBLEM_FILE = %s\\n\" % filename_tsp)\n        f.write(\"MOVE_TYPE = 8\\n\")\n        f.write(\"PATCHING_C = 3\\n\")\n        f.write(\"PATCHING_A = 2\\n\")\n        f.write(\"RUNS = 2\\n\")\n        f.write(\"OUTPUT_TOUR_FILE = %s\\n\" % filename_tour)\n        f.write(\"SEED = %d\\n\" % seed)\n        f.write(\"CANDIDATE_SET_TYPE = POPMUSIC\\n\")\n        f.write(\"POPMUSIC_SOLUTIONS = 12\\n\")   \n        f.write(\"POPMUSIC_SAMPLE_SIZE = 14\\n\")\n        f.write(\"POPMUSIC_TRIALS = 1000\\n\")\n        f.write(\"POPMUSIC_MAX_NEIGHBORS = 14\\n\")\n        f.write(\"INITIAL_PERIOD = 2500\\n\")\n        f.write(\"MAX_TRIALS = 1000\\n\")\n        f.write(\"INITIAL_TOUR_ALGORITHM = QUICK-BORUVKA\\n\")\n        if filename_initial_tour is not None:\n            f.write(\"INITIAL_TOUR_FILE = %s\\n\" % filename_initial_tour)\n        f.write(\"TRACE_LEVEL = 1\\n\")\n        if bw == True:\n            f.write(\"BWTSP = %d %d %d\\n\" % (len(lkh_df[lkh_df[\"is_not_prime\"] == 0]), 9, 9999999999))\n    \n    # LKH start with node 1\n    with open(filename_tsp, \"w\") as f:\n        f.write(\"NAME : SOLVER\\n\")\n        f.write(\"COMMENT : %d points\\n\" % l)\n        f.write(\"TYPE : TSP\\n\")\n        f.write(\"DIMENSION : %d\\n\" % l)\n        f.write(\"EDGE_WEIGHT_TYPE : EUC_2D\\n\")\n        f.write(\"NODE_COORD_TYPE : TWOD_COORDS\\n\")\n        f.write(\"NODE_COORD_SECTION\\n\")\n        for idx, row in lkh_df.iterrows():\n            if real:\n                f.write(\"%d %.12f %.12f\\n\" % (row[\"CityId\"] + 1, (row[\"X\"]), (row[\"Y\"])))\n            else:\n                f.write(\"%d %.9f %.9f\\n\" % (row[\"CityId\"] + 1, (row[\"X\"])*1000.0, (row[\"Y\"]*1000.0)))\n            \n# Read LKH with additional mapping\ndef read_lkh_tour(filename, mapping = None):\n    with open(filename, 'r') as f:\n        tour = []\n        i = 0\n        for line in f:\n            i = i + 1\n            if i > 6:\n                tour.append(line.rstrip('\\n'))\n        tour = [int(t) for t in tour if t != 'EOF']\n        tour = tour[:-1]\n    tour_map = [mapping[int(t)] for t in tour]\n    return tour_map\n\n# Back to original points for basic TSP, needed for BW\ndef lkh_ids_mapping(lkh_df):\n    mapping = {}\n    for idx, row in lkh_df.iterrows():\n        mapping[int(row[\"CityId\"] + 1)] = idx\n    return mapping\n\ndef read_cnc_tour(filename):\n    tour = open(filename).read().split()[1:]\n    tour = list(map(int, tour))\n    if tour[-1] == 0: tour.pop()\n    return tour\n\ndef write_lkh_tour(path, filename_tour, comment=\"None\"):\n    with open(filename_tour, \"w\") as f:\n        f.write(\"NAME : %s\\n\" % filename_tour)\n        f.write(\"COMMENT : %s\\n\" % comment)\n        f.write(\"COMMENT :\\n\")\n        f.write(\"TYPE : TOUR\\n\")\n        f.write(\"DIMENSION : %d\\n\" % len(path))\n        f.write(\"TOUR_SECTION\\n\")\n        for p in path:\n            f.write(\"%d\\n\" % p) \n        f.write(\"-1\\n\")\n        f.write(\"EOF\\n\")","bf567832":"# LKH3 supports constrained TSP\n# Download and Install LKH3 with gcc and CFLAGS for optimization. ","2bec3361":"%%bash -e\nwget http:\/\/akira.ruc.dk\/~keld\/research\/LKH-3\/LKH-3.0.5.tgz\n(tar xvfz LKH-3.0.5.tgz)\n(cd LKH-3.0.5 && make CC=gcc CFLAGS='-IINCLUDE -Ofast -march=native -mtune=native -fPIC')\n(cd LKH-3.0.5 && cp LKH ..\/)\nrm -rf LKH-3.0.5 LKH-3.0.5.tgz","d79bed21":"# Generate TSP and LKH files\nwrite_lkh_files(cities, \"cities.lkh.par\", \"cities.lkh.tsp\", \"cities.lkh.tour\",\n                filename_initial_tour=\"cities.cnc.lkh.tour\", real=False, bw=False)","aff42867":"# Download and Install concorde for an initial run that will generate: cities.cnc.lkh.tour\n# Concorde is fast and provides good initial tour for LKH","846b15d6":"%%bash -e\nif ! [[ -f .\/linkern ]]; then\n  wget http:\/\/www.math.uwaterloo.ca\/tsp\/concorde\/downloads\/codes\/src\/co031219.tgz\n  echo 'c3650a59c8d57e0a00e81c1288b994a99c5aa03e5d96a314834c2d8f9505c724  co031219.tgz' | sha256sum -c\n  tar xf co031219.tgz\n  (cd concorde && CFLAGS='-Ofast -march=native -mtune=native -fPIC' .\/configure)\n  (cd concorde\/LINKERN && make -j && cp linkern ..\/..\/)\n  rm -rf concorde co031219.tgz\nfi","b5b4cf07":"# Run concorde for 30 minutes","af38a155":"%%bash -e\nhead cities.lkh.tsp","692c0cbc":"%%bash\ntime .\/linkern -K 1 -s 2019 -S cities.cnc.tour -R 999999999 -t 1800 cities.lkh.tsp >cities.cnc.log","5418efa7":"# Results from concorde\ncnc_tour = np.array(read_cnc_tour(\"cities.cnc.tour\"))\ncnc_score = score_path(cnc_tour)\nprint(f'Concorde distance is {distance_path(cnc_tour):.2f} and score is {score_path(cnc_tour):.2f} in {1800\/60 :.1f} minutes')","f1922278":"# Save concorde tour as initial tour for LKH\nwrite_lkh_tour([p+1 for p in cnc_tour], \"cities.cnc.lkh.tour\")","1470a000":"# Run LKH with POPMUSIC initializer for 5h55min","065f4945":"%%bash -e\ntimeout 21300s .\/LKH cities.lkh.par","de1591d4":"# Results from LKH\nlkh_tour = np.array(read_lkh_tour(\"cities.lkh.tour\", mapping=lkh_ids_mapping(cities)))","a9f039d9":"# Go back to North pole\npath = np.concatenate([lkh_tour.copy(), np.array([0])])\nprint(path[0:10])\nprint(path[-10:])\nprint(f'LKH distance is {distance_path(path):.2f} and score is {score_path(path):.2f} in {21300\/60 :.1f} minutes')","34859fd9":"t1 = time.time()","8720fb5d":"# Numba optimized functions.\n# From: https:\/\/www.kaggle.com\/kostyaatarik\/not-a-3-and-3-halves-opt\n@numba.jit('f8(i8, i8, i8)', nopython=True, parallel=False)\ndef cities_distance(offset, id_from, id_to):\n    xy_from, xy_to = XY[id_from], XY[id_to]\n    dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n    distance = sqrt(dx * dx + dy * dy)\n    if offset % 10 == 9 and is_not_prime[id_from]:\n        return 1.1 * distance\n    return distance\n\n@numba.jit\ndef chunk_scores(chunk):\n    scores = np.zeros(10)\n    pure_distance = 0\n    for i in numba.prange(chunk.shape[0] - 1):\n        id_from, id_to = chunk[i], chunk[i+1]\n        xy_from, xy_to = XY[id_from], XY[id_to]\n        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n        distance = sqrt(dx * dx + dy * dy)\n        pure_distance += distance\n        if is_not_prime[id_from]:\n            scores[9-i%10] += distance\n    scores *= 0.1\n    scores += pure_distance\n    return scores\n\n# sort by distance\n@numba.jit('f8(i8[:])', nopython=True, parallel=False)\ndef sum_distance(ids):\n    res = 0\n    for i in numba.prange(len(ids)):\n        for j in numba.prange(i + 1, len(ids)):\n            res += cities_distance(0, ids[i], ids[j])\n    return res","36fd025f":"# Precomputes all permutations. Memory consuming but better for execution.\ndef not_trivial_permutations(iterable):\n    perms = permutations(iterable)\n    next(perms)\n    yield from perms\n\ndef _not_trivial_indexes_permutations(length):\n    return np.array([list(p) for p in not_trivial_permutations(range(length))], dtype=np.int64)\n\nMAX_PERMS=11\n\nPERMS_01 = _not_trivial_indexes_permutations(1)\nPERMS_02 = _not_trivial_indexes_permutations(2)\nPERMS_03 = _not_trivial_indexes_permutations(3)\nPERMS_04 = _not_trivial_indexes_permutations(4)\nPERMS_05 = _not_trivial_indexes_permutations(5)\nPERMS_06 = _not_trivial_indexes_permutations(6)\nPERMS_07 = _not_trivial_indexes_permutations(7)\nPERMS_08 = _not_trivial_indexes_permutations(8)\nPERMS_09 = _not_trivial_indexes_permutations(9)\nPERMS_10 = _not_trivial_indexes_permutations(10)\nPERMS_11 = _not_trivial_indexes_permutations(11)\n\n@numba.jit(nopython=True, parallel=False)\ndef not_trivial_indexes_permutations(length):\n    if length == 2:\n        return PERMS_02\n    elif length == 3:\n        return PERMS_03\n    elif length == 4:\n        return PERMS_04  \n    elif length == 5:\n        return PERMS_05  \n    elif length == 6:\n        return PERMS_06\n    elif length == 7:\n        return PERMS_07\n    elif length == 8:\n        return PERMS_08    \n    elif length == 9:\n        return PERMS_09\n    elif length == 10:\n        return PERMS_10 \n    elif length == 11:\n        return PERMS_11","dc1c3e9e":"@numba.jit\ndef chunk_scores2(chunk):\n    scores = np.zeros(10)\n    pure_distance = 0\n    for i in numba.prange(chunk.shape[0] - 1):\n        id_from, id_to = chunk[i], chunk[i+1]\n        xy_from, xy_to = XY[id_from], XY[id_to]\n        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n        distance = sqrt(dx * dx + dy * dy)\n        pure_distance += distance\n        if is_not_prime[id_from]:\n            scores[9-i%10] += distance\n    scores *= 0.1\n    scores += pure_distance\n    return scores\n\n@numba.jit(nopython=True, parallel=False)\ndef range_length(length):\n    return [p for p in range(length)]","da45ce7a":"# Run KDTree for nearest neighbours or each city by Nuplets\nkdt = KDTree(XY)\n# Stage 1 is around 13min, Stage2 is around 15min, Stage3 is around 100min\ncs = [2, 3, 4]\ncs_nearest = [17, 10, 8]\ncs_radius = [12, 10, 6]\ntuples = []\nfor c, n, r in zip(cs, cs_nearest, cs_radius):\n    print(f'\\nGenerating tuples for N={c} with nearest={n} and radius={r} ...')\n    Nuplets = set()\n    for city_id in tqdm(cities.index, mininterval=2.0):\n        dists, neibs = kdt.query([XY[city_id]], k=n)\n        for Nuplet in combinations(neibs[0], c):\n            if all(Nuplet):\n                Nuplets.add(tuple(sorted(Nuplet)))\n        if r > 0:\n            neibs = kdt.query_radius([XY[city_id]], r=r, count_only=False, return_distance=False)\n            for Nuplet in combinations(neibs[0], c):\n                if all(Nuplet):\n                    Nuplets.add(tuple(sorted(Nuplet)))\n    tuples.append(Nuplets)\n    print(f'{len(Nuplets)} cities for N={c} are selected.')\n\nfor t,i in zip(tuples, range(len(tuples))):\n    t = np.array(list(t))\n    distances = np.array(list(map(sum_distance, tqdm(t))))\n    order = distances.argsort()\n    tuples[i] = t[order]","66e266ff":"# Main function for local optimizations. It's a bit flat but it helps Numba to speed up.\n# It builds path chunks from Nuplets combinations, then tries chunk content permutations until score improves. \n@numba.jit(numba.int64[:](numba.int64[:], numba.int64[:,:], numba.int64, numba.int64), nopython=True, parallel=False)\ndef optN(path, tmptuples, max_chunk_len, full_reverse_rank):\n    path_index = np.argsort(path[:-1])\n    for iids in numba.prange(len(tmptuples)):\n        ids = tmptuples[iids]        \n        s = sorted(path_index[ids])\n        head, tail = path[s[0]-1], path[s[-1]+1]\n        # Build chunks\n        if len(s) == 2:\n            chunks = [path[s[0]:s[0]+1], \n                      path[s[0]+1:s[1]], \n                      path[s[1]:s[1]+1]]              \n        elif len(s) == 3:\n            chunks = [path[s[0]:s[0]+1], \n                      path[s[0]+1:s[1]], \n                      path[s[1]:s[1]+1], \n                      path[s[1]+1:s[2]],\n                      path[s[2]:s[2]+1]]             \n        elif len(s) == 4:         \n            chunks = [path[s[0]:s[0]+1], \n                      path[s[0]+1:s[1]], \n                      path[s[1]:s[1]+1], \n                      path[s[1]+1:s[2]],\n                      path[s[2]:s[2]+1],\n                      path[s[2]+1:s[3]],\n                      path[s[3]:s[3]+1]]\n        elif len(s) == 5:         \n            chunks = [path[s[0]:s[0]+1], \n                      path[s[0]+1:s[1]], \n                      path[s[1]:s[1]+1], \n                      path[s[1]+1:s[2]],\n                      path[s[2]:s[2]+1],\n                      path[s[2]+1:s[3]],\n                      path[s[3]:s[3]+1],\n                      path[s[3]+1:s[4]],\n                      path[s[4]:s[4]+1]]            \n        # Drop empty chunks        \n        chunks = [chunk for chunk in chunks if len(chunk)]\n        \n        if len(chunks) > max_chunk_len:\n            continue\n        \n        scores = [chunk_scores2(chunk) for chunk in chunks]\n        \n        lindexes_permutation = range_length(len(chunks))\n        # Inline score\n        lscore = 0.0\n        offset = s[0]-1\n        last_city_id = head\n        for iindex in numba.prange(len(lindexes_permutation)):\n            index = lindexes_permutation[iindex]\n            chunk = chunks[index]\n            chunk_scores_ = scores[index]\n            lscore += cities_distance(offset % 10, last_city_id, chunk[0])\n            lscore += chunk_scores_[(offset + 1) % 10]\n            last_city_id = chunk[-1]\n            offset += len(chunk)\n        default_score =  lscore + cities_distance(offset % 10, last_city_id, tail)\n        \n        best_score = default_score\n        nti = not_trivial_indexes_permutations(len(chunks))\n        for iindexes_permutation in numba.prange(len(nti)):\n            indexes_permutation = nti[iindexes_permutation]\n            # Inline score\n            lscore = 0.0\n            offset = s[0]-1\n            last_city_id = head\n            for iindex in numba.prange(len(indexes_permutation)):\n                index = indexes_permutation[iindex]\n                chunk = chunks[index]\n                chunk_scores_ = scores[index]\n                lscore += cities_distance(offset % 10, last_city_id, chunk[0])\n                lscore += chunk_scores_[(offset + 1) % 10]\n                last_city_id = chunk[-1]\n                offset += len(chunk)\n            score =  lscore + cities_distance(offset % 10, last_city_id, tail)\n            if score < best_score:\n                permutation = [chunks[i] for i in indexes_permutation]\n                # Concatenate permutation\n                tl = 0\n                for t in range(len(permutation)):\n                    tl = tl + len(permutation[t])\n                z = np.zeros(tl, dtype=np.int64)\n                tl = 0\n                for t in range(len(permutation)):\n                    z[tl:tl+len(permutation[t])] = permutation[t]\n                    tl = tl + len(permutation[t])\n                # Concatenate head\/tail\n                best_chunk = np.zeros(len(z) + 2, dtype=np.int64)\n                best_chunk[0] = head\n                best_chunk[1:-1] = z[:]\n                best_chunk[-1] = tail\n                best_score = score\n                \n        if best_score < default_score:\n            path[s[0]-1:s[-1]+2] = best_chunk\n            path_index = np.argsort(path[:-1])\n            print('New total score is ', score_path(path), ', Permutating path at indexes ', s, 'Progress: ', int(iids*100.0\/len(tmptuples)))\n            \n    return path.copy()","f8ab2d8a":"# Check if reverse path scores better\ndef check_reverse(p):\n    sr = score_path(p[::-1])\n    s = score_path(p)\n    if sr < s:\n        print(\"Reverse better than initial: %.1f vs %.1f\" % (sr, s))\n        return p[::-1]\n    else:\n        print(\"Reverse not better than initial: %.1f vs %.1f\" % (sr, s))\n        return p","eb53c668":"# Run local optimizations now\ninitial_path = check_reverse(path.copy())","44262879":"new_path = optN(initial_path, tuples[0], 11, 0)","09f19c7b":"print(f'Total score after stage 1 is {score_path(new_path):.2f} in {(time.time()-t1)\/60.0:.1f} min')","f0331778":"t2 = time.time()\nnew_path1 = optN(new_path.copy(), tuples[1], 11, 0)","384f1155":"print(f'Total score after stage 2 is {score_path(new_path1):.2f} in {(time.time()-t2)\/60.0:.1f} min')","3451d55e":"t3 = time.time()\nnew_path2 = optN(new_path1.copy(), tuples[2], 11, 0)","ca353d50":"print(f'Total score after stage 3 is {score_path(new_path2):.2f} in {(time.time()-t3)\/60.0:.1f} min')","a5f8d265":"print(f'Total local optimizations time is {(time.time()-t1)\/60.0:.1f} min')","7a08fd64":"print(f'Final score is {score_path(new_path2):.2f}')","102aa6d5":"# Output\npd.DataFrame({'Path': new_path2}).to_csv('submission.csv', index=False)","8bff9575":"# Path vizualization with clusters and starting tour in red\ndef plot_tour_extended(cities, ax, b=None, path=None, chunk_path=None):\n    ax.scatter(cities.X, cities.Y, c=cities.hc, cmap=plt.cm.tab20, s=1)\n    if b is not None:\n        cities_b = cities[cities[\"CityId\"].isin(b)]\n        ax.scatter(cities_b.X, cities_b.Y, s=16, c=\"orange\")\n    if path is not None:\n        lines = [[(cities.X[path[i]],cities.Y[path[i]]),(cities.X[path[i+1]],cities.Y[path[i+1]])] for i in range(0,len(path)-1)]\n        lc = mc.LineCollection(lines, linewidths=1, colors=\"gray\", alpha=0.7)\n        ax.add_collection(lc)\n        ax.autoscale()\n        # Start point\n        ax.scatter(cities.X[path[0]], cities.Y[path[0]], s=28, c=\"black\")\n    if chunk_path is not None:\n        lines = [[(cities.X[chunk_path[i]],cities.Y[chunk_path[i]]),(cities.X[chunk_path[i+1]],cities.Y[chunk_path[i+1]])] for i in range(0,len(chunk_path)-1)]\n        lc = mc.LineCollection(lines, linewidths=1, colors=\"r\")\n        ax.add_collection(lc)     \n    plt.show()\n    \nfig, ax = plt.subplots(1, 1, figsize=(20, 14))\nplot_tour_extended(cities, ax, b=None, path=new_path2, chunk_path=new_path2[0:500])","61acc202":"print(f'Total kernel time is {(time.time()-t0)\/60.0:.1f} min')","cedeadf2":"# Part 2: Fine tuning (to be continued)","4957a8b7":"This kernel provides an insight of the first part of my solution. It's a CPU kernel that computes everything without loading external data from any other kernel.  Main idea is to run local optimizations on initial path found by off-the-shelf solvers. It is designed for 9 hours runtime. In this part, we try to improve score as much as possible without any fine tuning. We limit and cache possible permutations. \n\n* First, we run [Concorde](http:\/\/www.math.uwaterloo.ca\/tsp\/concorde\/index.html) TSP solver followed by [LKH](http:\/\/akira.ruc.dk\/~keld\/research\/LKH-3\/) solver to get a pure TSP path without taking into account the prime penalty. \n* Second, we try several local combinations (pseudo K-opt) with penalty included. It is inspired from [this kernel](https:\/\/www.kaggle.com\/kostyaatarik\/not-a-3-and-3-halves-opt) that gives the basics.\n\n CPU native flags and Numba are used to speed up computations. Real benefits from Numba are only with **nopython** mode so all local optimization functions are designed with this mode. It makes python code not super readable but it's really faster. That's the way we can improve score by almost 1000 in just around 2 hours.\n \nSecond part (not in this Kernel) of the solution is fine tuning. We try to increase combinatory but on less data such as:\n* Area high density points (with HDBScan clusters) \n* Area with high penalties\n* ...\n"}}