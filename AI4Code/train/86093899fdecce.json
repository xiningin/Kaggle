{"cell_type":{"85f3c7fc":"code","b17dbcc1":"code","2f9b5d07":"code","75ba20b3":"code","f1d8a8aa":"code","433f9da0":"code","76af45dd":"code","7652dd71":"code","565b585a":"code","8234c074":"code","1556d959":"code","fcdb9424":"code","787e214e":"code","c4799125":"code","71ec19fc":"code","2471af74":"code","c8ee9182":"code","eb99759d":"code","4a7d28d5":"code","f1464963":"code","75507446":"code","75ecedb9":"code","72663280":"code","4d869ddf":"code","a7dde476":"code","2b535c4d":"code","3e3f2ae9":"code","582e45af":"code","af2252ca":"code","fb46cd98":"code","e6e2dd6f":"code","409811a3":"code","afdc0766":"code","b39000a9":"code","d8cbd3d5":"code","f1c13b2e":"code","f85e167a":"code","4b1c3db1":"code","870a5e6c":"code","f0dc2d7d":"code","54cb0da3":"code","654f3400":"code","5d0ef384":"code","3b891e4b":"code","b6fcdb78":"code","23144c48":"code","5924b520":"code","d9af45a3":"code","c4640c7d":"code","2354a824":"code","44509138":"code","4aa49425":"code","2cb4b506":"code","428f0e13":"code","b9d82cca":"code","dc1fe7f2":"markdown","85cc82e8":"markdown","55ca4dc0":"markdown","9ba5c07a":"markdown","6393b554":"markdown","51848796":"markdown","d7b60fb1":"markdown","da2e2e84":"markdown","5b7ec420":"markdown","8124d380":"markdown","9438b067":"markdown","74e98354":"markdown","0be7b96d":"markdown","457ff080":"markdown","e95fc404":"markdown","9d95eeb4":"markdown","a7a754f1":"markdown","90f98b22":"markdown","e9473eb5":"markdown","b921ee89":"markdown","bd9b6612":"markdown","9f02817e":"markdown","0fb4aa3f":"markdown","ebb0e9bc":"markdown","c7080c34":"markdown"},"source":{"85f3c7fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# import libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.tools import plotting\n\nplt.style.use(\"ggplot\")\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# from scipy import stats\nfrom scipy import stats\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b17dbcc1":"# read data as pandas data frame\ndata = pd.read_csv(\"..\/input\/data.csv\")\ndata = data.drop(['Unnamed: 32','id'],axis = 1)","2f9b5d07":"data.info()","75ba20b3":"data.info","f1d8a8aa":"data.head()","433f9da0":"data.shape","76af45dd":"# quick look to data\nprint(data.head())\nprint(data.shape) # (569, 31)\nprint(data.columns )","7652dd71":"type(data[\"diagnosis\"] == \"M\")","565b585a":"data[\"diagnosis\"] == \"M\"","8234c074":"data[data[\"diagnosis\"] == \"M\"].head()","1556d959":"data[data[\"diagnosis\"] == \"M\"].radius_mean","fcdb9424":"type(data[data[\"diagnosis\"] == \"M\"].radius_mean)","787e214e":"type(data[data[\"diagnosis\"] == \"M\"])","c4799125":"type(data[data[\"diagnosis\"] == \"M\"].radius_mean)","71ec19fc":"data[data[\"diagnosis\"] == \"M\"].radius_mean.head(20)","2471af74":"m = plt.hist(data[data[\"diagnosis\"] == \"M\"].radius_mean,bins=30,fc = (1,0,0,0.5),label = \"Malignant\")\nb = plt.hist(data[data[\"diagnosis\"] == \"B\"].radius_mean,bins=30,fc = (0,1,0,0.5),label = \"Bening\")\nplt.legend()\nplt.xlabel(\"Radius Mean Values\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of Radius Mean for Bening and Malignant Tumors\")\nplt.show()\nfrequent_malignant_radius_mean = m[0].max()\nprint(\"frequent_malignant_radius_mean: \",frequent_malignant_radius_mean)\nindex_frequent_malignant_radius_mean = list(m[0]).index(frequent_malignant_radius_mean) # m[0] is the index of histogram inside the bin \nprint(\"index_frequent_malignant_radius_mean: \", index_frequent_malignant_radius_mean)\nmost_frequent_malignant_radius_mean = m[1][index_frequent_malignant_radius_mean] # and m[1] is the value\nprint(\"Most frequent malignant radius mean is: \",most_frequent_malignant_radius_mean)","c8ee9182":"m","eb99759d":"frequent_malignant_radius_mean","4a7d28d5":"index_frequent_malignant_radius_mean","f1464963":"m","75507446":"m[0]","75ecedb9":"list(m[0]).index(frequent_malignant_radius_mean)","72663280":"m[1]","4d869ddf":"m = plt.hist(data[data[\"diagnosis\"] == \"M\"].radius_mean,bins=30,fc = (1,0,0,0.5),label = \"Malignant\")\nb = plt.hist(data[data[\"diagnosis\"] == \"B\"].radius_mean,bins=30,fc = (0,1,0,0.5),label = \"Bening\")\nplt.legend()\nplt.xlabel(\"Radius Mean Values\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of Radius Mean for Bening and Malignant Tumors\")\nplt.show()\nfrequent_malignant_radius_mean = m[0].max()\nindex_frequent_malignant_radius_mean = list(m[0]).index(frequent_malignant_radius_mean)\nmost_frequent_malignant_radius_mean = m[1][index_frequent_malignant_radius_mean]\nprint(\"Most frequent malignant radius mean is: \",most_frequent_malignant_radius_mean)","a7dde476":"data_bening = data[data[\"diagnosis\"] == \"B\"]\ndata_malignant = data[data[\"diagnosis\"] == \"M\"]\ndesc = data_bening.radius_mean.describe()\nQ1 = desc[4] # Q1\nQ3 = desc[6] # Q3\nIQR = Q3-Q1\nlower_bound = Q1 - 1.5*IQR\nupper_bound = Q3 + 1.5*IQR\nprint(\"Anything outside this range is an outlier: (\", lower_bound ,\",\", upper_bound,\")\")\n# data_bening[data_bening.radius_mean < lower_bound].radius_mean\nprint(\"Outliers: \",data_bening[(data_bening.radius_mean < lower_bound) | (data_bening.radius_mean > upper_bound)].radius_mean.values)","2b535c4d":"data_bening[(data_bening.radius_mean < lower_bound) | (data_bening.radius_mean > upper_bound)]","3e3f2ae9":"data_bening.head()","582e45af":"data_malignant.head()","af2252ca":"type(data_bening.radius_mean)","fb46cd98":"data_bening.radius_mean.describe()","e6e2dd6f":"desc","409811a3":"type(desc)","afdc0766":"melted_data = pd.melt(data,id_vars = \"diagnosis\",value_vars = ['radius_mean', 'texture_mean'])\nplt.figure(figsize = (15,10))\nsns.boxplot(x = \"variable\", y = \"value\", hue=\"diagnosis\",data= melted_data)\nplt.show()","b39000a9":"melted_data = pd.melt(data,id_vars = \"diagnosis\",value_vars = ['radius_mean', 'texture_mean'])\nmelted_data","d8cbd3d5":"type(data_bening.radius_mean)","f1c13b2e":"print(\"mean: \",data_bening.radius_mean.mean())\nprint(\"variance: \",data_bening.radius_mean.var())\nprint(\"standart deviation (std): \",data_bening.radius_mean.std())\nprint(\"describe method: \",data_bening.radius_mean.describe())","f85e167a":"plt.hist(data_bening.radius_mean,bins=50,fc=(0,1,0,0.5),label='Bening',normed = True,cumulative = True)\nsorted_data = np.sort(data_bening.radius_mean)\ny = np.arange(len(sorted_data))\/float(len(sorted_data)-1)\nplt.plot(sorted_data,y,color='red')\nplt.title('CDF of bening tumor radius mean')\nplt.show()","4b1c3db1":"print(len(sorted_data))\nprint(float(len(sorted_data)-1))\nprint(np.arange(len(sorted_data)\/float(len(sorted_data)-1)))","870a5e6c":"np.arange(357\/356.0)","f0dc2d7d":"mean_diff = data_malignant.radius_mean.mean() - data_bening.radius_mean.mean()\nvar_bening = data_bening.radius_mean.var()\nvar_malignant = data_malignant.radius_mean.var()\nvar_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) \/ float(len(data_bening)+ len(data_malignant))\neffect_size = mean_diff\/np.sqrt(var_pooled)\nprint(\"Effect size: \",effect_size)","54cb0da3":"plt.figure(figsize = (15,10))\nsns.jointplot(data.radius_mean,data.area_mean,kind=\"regg\")\nplt.show()","654f3400":"df = data.loc[:,[\"radius_mean\",\"area_mean\",\"fractal_dimension_se\"]]","5d0ef384":"df.head()","3b891e4b":"# Also we can look relationship between more than 2 distributions\nsns.set(style = \"white\")\ndf = data.loc[:,[\"radius_mean\",\"area_mean\",\"fractal_dimension_se\"]]\ng = sns.PairGrid(df,diag_sharey = False,) #Subplot grid for plotting pairwise relationships in a dataset.\ng.map_lower(sns.kdeplot,cmap=\"Blues_d\") #Plot with a bivariate function on the lower diagonal subplots.\n\n# Kernel Density Estimation (KDE) is a way to estimate the probability density function of a continuous random variable. \n# It is used for non-parametric analysis.\n\ng.map_upper(plt.scatter) #Plot with a bivariate function on the upper diagonal subplots.\ng.map_diag(sns.kdeplot,lw =3) #Plot with a univariate function on each diagonal subplot.\n# sns.kdeplot -- Fit and plot a univariate or bivariate kernel density estimate.\nplt.show()","b6fcdb78":"data.head(3)","23144c48":"data.corr()","5924b520":"f,ax=plt.subplots(figsize = (18,18))\nsns.heatmap(data.corr(),annot= True,linewidths=0.5,fmt = \".1f\",ax=ax) #Plot rectangular data as a color-encoded matrix.\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title('Correlation Map')\nplt.savefig('graph.png')\nplt.show()","d9af45a3":"print(np.cov(data.radius_mean,data.area_mean))\nprint(\"Covariance between radius mean and area mean: \",data.radius_mean.cov(data.area_mean))\nprint(\"Covariance between radius mean and fractal dimension se: \",data.radius_mean.cov(data.fractal_dimension_se))","c4640c7d":"p1 = data.loc[:,[\"area_mean\",\"radius_mean\"]].corr(method= \"pearson\")\np2 = data.radius_mean.cov(data.area_mean)\/(data.radius_mean.std()*data.area_mean.std())\nprint('Pearson correlation: ')\nprint(p1)\nprint('Pearson correlation: ',p2)","2354a824":"ranked_data = data.rank() #In statistics, \u201cranking\u201d refers to the data transformation \n# in which numerical or ordinal values are replaced by their rank when the data are sorted\n\nspearman_corr = ranked_data.loc[:,[\"area_mean\",\"radius_mean\"]].corr(method= \"pearson\")\nprint(\"Spearman's correlation: \")\nprint(spearman_corr)","44509138":"ranked_data.head()","4aa49425":"salary = [1,4,3,2,5,4,2,3,1,500]\n#salary=[1,1,2,2,3,3,4,4,5,500]\nprint(\"Mean of salary: \",np.mean(salary))","2cb4b506":"print(\"Median of salary: \",np.median(salary))","428f0e13":"statistic, p_value = stats.ttest_rel(data.radius_mean,data.area_mean)\nprint('p-value: ',p_value)","b9d82cca":"# parameters of normal distribution\nmu, sigma = 110, 20  # mean and standard deviation\ns = np.random.normal(mu, sigma, 100000)\nprint(\"mean: \", np.mean(s))\nprint(\"standart deviation: \", np.std(s))\n# visualize with histogram\nplt.figure(figsize = (10,7))\nplt.hist(s, 100, normed=False)\nplt.ylabel(\"frequency\")\nplt.xlabel(\"IQ\")\nplt.title(\"Histogram of IQ\")\nplt.show()","dc1fe7f2":"* P values is almost zero so we can reject null hypothesis.","85cc82e8":"<a id=\"5\"><\/a> <br>\n## CDF\n* **Cumulative Distribution Function** **is the probability that the variable takes a value less than or equal to x. P(X <= x)**\n* Lets explain in cdf graph of bening radiues mean\n* in graph, what is P(X<12)? The answer is 0.5. The probability that the variable takes a values less than or equal to 12(radius mean) is 0.5.\n* You can plot cdf with two different method","55ca4dc0":"* Spearman's correlation is little higher than pearson correlation\n    * **If relationship between distributions are non linear, spearman's correlation tends to better estimate the strength of relationship**\n    * **Pearson correlation can be affected by outliers. Spearman's correlation is more robust**. ","9ba5c07a":"<a id=\"2\"><\/a> <br>\n## Outliers\n* While looking histogram, as you can see there are rare values in bening distribution (green in graph)\n* There values can be errors or rare events.\n* These errors and rare events can be called **outliers**.\n* Calculating outliers: \n    * first we need to calculate first quartile (Q1)(25%)\n    * then find **IQR(inter quartile range) = Q3-Q1**\n    * finally compute **Q1 - 1.5*IQR** and **Q3 + 1.5*IQR**\n    * **Anything outside this range is an outlier**\n    * lets write the code for bening tumor distribution for feature radius mean","6393b554":"* What percentage of people should have an IQ score less than 80?\n* z = (110-80)\/20 = 1.5\n* Lets look at table of z score 0.4332. 43.32% of people has an IQ between 80 and mean(110).\n* If we subtract from 50% to 43.32%, we can find percentage of people have an IQ score less than 80.\n* 50-43.32 = 6.68. As a result, 6.68% of people have an IQ score less than 80.","51848796":"* Huge matrix that includes a lot of numbers\n* The range of this numbers are -1 to 1. \n* **Meaning of 1 is two variable are positively correlated with each other** like radius mean and area mean\n* **Meaning of zero is there is no correlation between variables** like radius mean and fractal dimension se\n* **Meaning of -1 is two variables are negatively correlated with each other** like radius mean and fractal dimension mean.Actually correlation between of them is not -1, it is -0.3 but the idea is that if sign of correlation is negative that means that there is negative correlation.","d7b60fb1":"* As it can be seen from histogram most of the people are cumulated near to 110 that is mean of our normal distribution\n* However what is the \"most\" I mentioned at previous sentence? What if I want to know what percentage of people should have an IQ score between 80 and 140?\n* We will use **z-score** the answer this question. \n      * z = (x - mean)\/std \n      * z1 = (80-110)\/20 = -1.5\n      * z2 = (140-110)\/20 = 1.5\n      * Distance between mean and 80 is 1.5 std and distance between mean and 140 is 1.5 std.\n      * If you look at z table, you will see that 1.5 std correspond to 0.4332\n <a href=\"https:\/\/ibb.co\/hys6OT\"><img src=\"https:\/\/preview.ibb.co\/fYzWq8\/123.png\" alt=\"123\" border=\"0\"><\/a>\n      * Lets calculate it with 2 because 1 from 80 to mean and other from mean to 140\n      * 0.4332 * 2 = 0.8664\n      * 86.64 % of people has an IQ between 80 and 140.\n  <a href=\"https:\/\/ibb.co\/fhc6OT\"><img src=\"https:\/\/preview.ibb.co\/bUi2xo\/hist.png\" alt=\"hist\" border=\"0\"><\/a>","da2e2e84":"<a id=\"3\"><\/a> <br>\n## Box Plot \n* You can see outliers also from box plots\n* We found 3 outliers in bening radius mean and in box plot there are 3 outliers.","5b7ec420":"* Lets look at other conclusions\n* From this graph you can see that radius mean of malignant tumors are bigger than radius mean of bening tumors mostly.\n* The bening distribution (green in graph) is approcimately bell-shaped that is shape of normal distribution (gaussian distribution)\n* Also you can find result like that most frequent malignant radius mean is 20.101999999999997  ","8124d380":"<a id=\"6\"><\/a> <br>\n## Effect size\n* One of the summary statistics.\n* **It describes the size of an effect. It is a simple way of quantifying the difference between the two groups..**\n* In an other saying, **effect size emphasizes the size of the difference**\n* Use **cohen effect size**\n* Cohen suggest that **if d(effect size)= 0.2, it is small effect size, d = 0.5 medium effect size, d = 0.8 large effect size.**\n* lets compare size of the effect between bening radius mean and malignant radius mean\n* Effect size is 2.2 that is too big and says that two groups are different from each other as we expect. Because our groups are bening radius mean and malignant radius mean that are different from each other\n\n* Effect size is a quantitative measure of the magnitude of the experimenter effect. The larger the effect size the stronger the relationship between two variables. You can look at the effect size when comparing any two groups to see how substantially different they are.\n\n* How is effect size calculated?\n* In statistics analysis, the effect size is usually measured in three ways: (1) standardized mean difference, (2) odd ratio, (3) correlation coefficient. The effect size of the population can be known by dividing the two population mean differences by their standard deviation.","9438b067":"<a id=\"13\"><\/a> <br>\n## Hypothesis Testing\n* Classical Hypothesis Testing\n* We want to answer this question: **\"given a sample and an apparent effect, what is the probability of seeing such an effect by chance\"**\n\n* **The second step is to define the null hypothesis that is model of the system based on the assumption that the apparent effect is not real. A null hypothesis is a type of hypothesis used in statistics that proposes that no statistical significance exists in a set of given observations. The null hypothesis is a hypothesis in which people try to disprove it. An alternative hypothesis is a hypothesis that people want to try to prove it.** \n\n\n* **Third step is to compute p-value that is the probability of seeing the apparent effect if the null hypothesis is true. Suppose we have a null hypothesis test. Then we calculate the p-value. If the p-value is less than or equal to a threshold, we reject the null hypothesis. If the p-value is low, the effect is said to be statistically significant which means that it is unlikely to have occurred by chance. Therefore we can say that the effect is more likely to appear in the larger population.**\n\n**If the p-value is low, the effect is said to be statistacally significant that means that it is unlikely to have occured by chance. Therefore we can say that the effect is more likely to appear in the larger population.**\n* Lets have an example. Null hypothesis: world is flatten. Alternative hypothesis: world is round. Several scientists set out to disprove the null hypothesis. This eventually led to the refection of the null hypothesis and acceptance of the alternative hypothesis.\n* Other example. \"this effect is real\" this is null hypothesis. Based on that assumption we compute the probability of the apparent effect. That is the p-value. If p-value is low, we conclude that null hypothesis is unlikely to be true.\n* Now lets make our example:\n    * I want to learn that area radius mean and area mean related with each other? My null hypothesis is that \"relationship between radius mean and area mean is zero (No relationship between them) in tumor population'.\n    * Now we need to refute this null hypothesis in order to demonstrate that radius mean and area mean are related. (actually we know it from our previous experiences)\n    * lets find p-value (probability value) ","74e98354":"<a id=\"9\"><\/a> <br>\n## Covariance\n* **Covariance is measure of the tendency of two variables to vary together**\n* **So covariance is maximized if two vectors are identical**\n* **Covariance is zero if they are orthogonal**.\n* **Covariance is negative if they point in opposite direction**\n* Lets look at covariance between radius mean and area mean. Then look at radius mean and fractal dimension se\n","0be7b96d":"# To be continued...","457ff080":"<a id=\"1\"><\/a> <br>\n## Histogram\n* **How many times each value appears in dataset**. **This description is called the distribution of variable**\n* Most common way to represent distribution of varible is histogram that is graph which shows frequency of each value.\n* Frequency = number of times each value appears\n* Example: [1,1,1,1,2,2,2]. Frequency of 1 is four and frequency of 2 is three.","e95fc404":"* Mean of salary is 52.5 so the boss thinks that oooo I gave a lot of salary to my employees. And do not makes raise in their salaries. However as you know this is not fair and 500(salary) is outlier for this salary list.\n* **Median avoids outliers**","9d95eeb4":"<a id=\"14\"><\/a> <br>\n## Normal(Gaussian) Distribution and z-score\n* Also called **bell shaped distribution**\n* Instead of making formal definition of gaussian distribution, I want to explain it with an example.\n* The classic example for gaussian is IQ score.\n    * In the world lets say average IQ is 110.\n    * There are few people that are super intelligent and their IQs are higher than 110. It can be 140 or 150 but it is rare.\n    * Also there are few people that have low intelligent and their IQ is lower than 110. It can be 40 or 50 but it is rare.\n    * From these information we can say that mean of IQ is 110. And lets say standard deviation is 20.\n    * **Mean and standard deviation is parameters of normal distribution**.\n    * Lets create 100000 sample and visualize it with histogram.\n","a7a754f1":"<a id=\"12\"><\/a> <br>\n## Mean VS Median\n* Sometimes instead of mean we need to use median. I am going to explain why we need to use median with an example\n* Lets think that there are 10 people who work in a company. Boss of the company will make raise in their salary if their mean of salary is smaller than 5\n","90f98b22":"# Conclusion\n* If you have any question or advise, I will be very happy to hear them.","e9473eb5":"* Now median of the salary is 3 and it is less than 5 and employees will take raise in their sallaries and they are happy and this situation is fair :)","b921ee89":"<a id=\"4\"><\/a> <br>\n## Summary Statistics\n* Mean\n* Variance: spread of distribution\n* Standart deviation square root of variance\n* Lets look at **summary statistics** of bening tumor radiance mean","bd9b6612":"# Introduction\nBasic statistic for beginners\n* [Histogram](#1)\n* [Outliers](#2)\n* [Box Plot ](#3)\n* [Summary Statistics](#4)\n* [CDF](#5)\n* [Effect size](#6)\n* [Relationship Between Variables](#7)\n* [Correlation](#8)\n* [Covariance](#9)\n* [Pearson Correlation](#10)\n* [Spearman's Rank Correlation](#11)\n* [Mean VS Median](#12)\n* [Hypothesis Testing](#13)\n* [Normal(Gaussian) Distribution and z-score](#14) \n","9f02817e":"<a id=\"8\"><\/a> <br>\n## Correlation\n* **Strength of the relationship between two variables**\n* Lets look at correlation between all features.","0fb4aa3f":"<a id=\"7\"><\/a> <br>\n## Relationship Between Variables\n* **We can say that two variables are related with each other, if one of them gives information about others**\n* For example, price and distance. If you go long distance with taxi you will pay more. Therefore we can say that price and distance are positively related with each other.\n* Scatter Plot\n* Simplest way to check relationship between two variables\n* Lets look at relationship between radius mean and area mean\n* In scatter plot you can see that when radius mean increases, area mean also increases. Therefore, they are **positively correlated** with each other.\n* There is no correlation between area mean and fractal dimension se. Because when area mean changes, fractal dimension se is not affected by change of area mean","ebb0e9bc":"<a id=\"11\"><\/a> <br>\n## Spearman's Rank Correlation\n* **Pearson correlation works well if the relationship between variables are linear and variables are roughly normal**.** *But it is not robust, if there are outliers***\n* **To compute spearman's correlation we need to compute rank of each value**\n","c7080c34":"<a id=\"10\"><\/a> <br>\n## Pearson Correlation\n* **Division of covariance by standard deviation of variables**\n* Lets look at pearson correlation between radius mean and area mean\n* First lets use .corr() method that we used actually at correlation part. In correlation part we actually used pearson correlation :) \n* p1 and p2 are the same. In p1 we use corr() method, **in p2 we apply definition of pearson correlation (cov(A,B)\/(std(A)*std(B)))**\n* *As we expect pearson correlation between area_mean and area_mean is 1 that means that they are same distribution*\n* Also pearson correlation between area_mean and radius_mean is 0.98 that means that they are positively correlated with each other and relationship between of the is very high.\n* To be more clear what we did at correlation part and pearson correlation part is same.\n\n* The Pearson correlation evaluates the linear relationship between two continuous variables. A relationship is linear when a change in one variable is associated with a proportional change in the other variable. Correlation coefficients only measure linear (Pearson) or monotonic (Spearman) relationships."}}