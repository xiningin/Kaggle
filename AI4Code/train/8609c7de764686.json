{"cell_type":{"c04898e7":"code","d094d199":"code","1d66e199":"code","9f7e2332":"code","f40ab378":"code","ad2f6594":"code","205b9308":"code","17858c9d":"code","c92982b0":"code","5b122597":"code","ce1d23af":"code","3a2354f8":"code","8ab8ee1c":"code","ad08b200":"code","80e81733":"code","e4e45f26":"code","e17894fa":"code","3510574a":"code","a024e488":"markdown","2de1fc2b":"markdown","4cb1ea9e":"markdown"},"source":{"c04898e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d094d199":"df_true = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/True.csv\")\ndf_fake = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/Fake.csv\")","1d66e199":"df_true.head()","9f7e2332":"df_true[\"true\"] = 1\ndf_fake[\"true\"] = 0\n\ndf = pd.concat([df_true,df_fake])\ndf.head()","f40ab378":"df[\"title\"] = df[\"title\"]+\" \"+df[\"text\"]+\" \"+df[\"subject\"]\ndf.head()","ad2f6594":"del df['date']\ndel df['text']\ndel df['subject']","205b9308":"df.head()","17858c9d":"import matplotlib.pyplot as plt \nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nplt.figure(figsize = (20,20))","c92982b0":"wc = WordCloud (max_words = 30000, stopwords = set(stopwords.words(\"english\"))).generate(\" \".join(df.title))\nplt.imshow(wc)","5b122597":"import re\nfrom nltk.stem.porter import PorterStemmer\nX = df.title.values\ny = df.true.values\n","ce1d23af":"ps = PorterStemmer()\n\ncorpus = []\n\nfor i in range (len(X)):\n    sent = re.sub(\"[^A-Za-z]\", \" \", X[i])\n    sent = sent.lower().split()\n    sent = [word for word in sent if word not in set(stopwords.words('english'))]\n    sent = \" \".join(sent)    \n    corpus.append(sent)","3a2354f8":"len(corpus)","8ab8ee1c":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(max_features = 10000)\nX_processed = cv.fit_transform (corpus).toarray()","ad08b200":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size= 0.2,random_state = 10)","80e81733":"test_size = 0.2\nX_train = X_processed[:int(len(X_processed)*(1-test_size))]\nX_test = X_processed[int(len(X_processed)*(1-test_size)):]\ny_train = y[:int(len(X_processed)*(1-test_size))]\ny_test = y[int(len(X_processed)*(1-test_size)):]\n","e4e45f26":"from sklearn.model_selection import StratifiedKFold\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = 10)\ncvscores = []\n\nfor train, test in kfold.split(X_train, y_train):\n    ann = Sequential ()\n    ann.add(Dense(output_dim = 128,  activation = 'relu', input_dim = 10000))\n    ann.add(Dense(output_dim = 4,  activation = 'relu', input_dim = 10000))\n    ann.add(Dense(units = 1 , activation = 'sigmoid'))\n\n    ann.compile (optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    ann.fit(X_train[train], y_train[train], batch_size = 100,epochs = 5)\n    \n    scores = ann.evaluate(X_train[test], y_train[test], verbose=0)\n    print(\"%s: %.2f%%\" % (ann.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)","e17894fa":"print(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))","3510574a":"y_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","a024e488":"# Splitting the Data in train and test sets","2de1fc2b":"**Calculating the the Accuracy in the Test Set**","4cb1ea9e":"# Training model in multiple folds"}}