{"cell_type":{"fdb92f34":"code","aeec9768":"code","25ec9151":"code","c8d4e976":"code","5d5a5946":"code","fa8c3d80":"code","a909a18e":"code","d2076487":"code","95d59910":"code","afc72172":"code","4b0d4b99":"code","84c00be6":"code","0ada3b22":"code","7c4c319b":"code","95a3356e":"code","271280c6":"code","6d36d43e":"markdown","5ce25010":"markdown","bc4e26da":"markdown","9bffc1eb":"markdown","66b91354":"markdown","5da0432c":"markdown","7265a931":"markdown"},"source":{"fdb92f34":"import tensorflow as tf\n#let's create our data generator \nimage_generator = tf.keras.preprocessing.image.ImageDataGenerator()\ntest_path = '..\/input\/intel-image-classification\/seg_test\/seg_test'\ntrain_path = '..\/input\/intel-image-classification\/seg_train\/seg_train'\nimage_size = 150\ntrain_generator = image_generator.flow_from_directory(\n        train_path,\n        target_size=(image_size, image_size),\n        batch_size=128,\n        class_mode='categorical')\nval_generator = image_generator.flow_from_directory(\n        test_path,\n        target_size=(image_size, image_size),\n        batch_size=128,\n        class_mode='categorical')","aeec9768":"number_of_classes = 6","25ec9151":"number_of_epochs = 10\ndef scheduler(epoch, lr):\n    if epoch % 3 ==0:\n        return lr*tf.math.exp(-0.1)\n    else:\n        return lr\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n    scheduler, verbose=2\n)","c8d4e976":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\n#Conv2D with stride 2 works as a MaxPooling layer\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), strides = 2, activation = 'relu'))\n\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu'))\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(number_of_classes, activation = 'softmax'))\n\nmodel.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","5d5a5946":"history = model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(train_generator),\n        epochs=number_of_epochs, validation_data = val_generator, callbacks = [lr_scheduler])","fa8c3d80":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\ndef graph_accuracy(history, number_of_epochs, model_name, fig=None, create_new_graph = False):\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    epochs = list(range(1, number_of_epochs+1))\n    if create_new_graph == True and fig==None:\n        fig = make_subplots(rows=1, cols=2,  subplot_titles=(\"Accuracy\", \"Validation Accuracy\"))\n        fig.add_trace(go.Scatter(x=epochs, y=accuracy, name= model_name),row=1, col=1)\n        fig.add_trace(go.Scatter(x=epochs, y=val_accuracy, name =model_name),row=1, col=2)\n        fig.update_layout(height=400, width=1000)\n    else:\n        fig.add_trace(go.Scatter(x=epochs, y=accuracy, name= model_name),row=1, col=1)\n        fig.add_trace(go.Scatter(x=epochs, y=val_accuracy, name = model_name),row=1, col=2)\n    fig.show()\n    return fig\nfig = graph_accuracy(history, number_of_epochs, model_name = \"CNN model\", create_new_graph = True)   ","a909a18e":"# it would be better to change our generator to a new one\n#where we add \"preprocessing_function=preprocess_input\" in the arguments\n#this function changes the image to the format the module requires \nfrom tensorflow.keras.applications.resnet50 import preprocess_input \nimage_generator_resnet50 = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)","d2076487":"train_generator_resnet50 = image_generator_resnet50.flow_from_directory(\n        train_path,\n        target_size=(image_size, image_size),\n        batch_size=128,\n        class_mode='categorical')\nval_generator_resnet50 = image_generator_resnet50.flow_from_directory(\n        test_path,\n        target_size=(image_size, image_size),\n        batch_size=128,\n        class_mode='categorical')","95d59910":"model_resnet50 = tf.keras.Sequential()\n\n#here we add our pre-trained model\n#include_top = False means that the don't include the pre-trained Dense classification layer \n#so we can train our own\n\n#weights = 'imagenet' means that we use weights from the imagenet competitions\n#we can also load pre-trained weights from datasets on Kaggle\nmodel_resnet50.add(tf.keras.applications.ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet'))\n\n#here we create our classification layer with weights that we will train\nmodel_resnet50.add(tf.keras.layers.Dense(number_of_classes, activation = 'softmax'))\n\n#we also need to set the previous layers to non-trainable\nmodel_resnet50.layers[0].trainable = False\n\n#summaty is a very usefull method because be can better understand how the model works\n#by looking at the amount of trainable and non-trainable parameters\nmodel_resnet50.summary()","afc72172":"model_resnet50.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nhistory_resnet50 = model_resnet50.fit_generator(\n        train_generator_resnet50,\n        steps_per_epoch=len(train_generator_resnet50),\n        epochs=number_of_epochs, validation_data = val_generator_resnet50, callbacks = [lr_scheduler])","4b0d4b99":"fig = graph_accuracy(history_resnet50, number_of_epochs, model_name = \"Resnet50 model\", fig = fig, create_new_graph = False)","84c00be6":"model_incv3 = tf.keras.Sequential()\nmodel_incv3.add(tf.keras.applications.inception_v3.InceptionV3(include_top = False, pooling = 'avg', weights = 'imagenet'))\nmodel_incv3.add(tf.keras.layers.Dense(number_of_classes, activation = 'softmax'))\nmodel_incv3.layers[0].trainable = False\nmodel_incv3.summary()","0ada3b22":"model_incv3.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","7c4c319b":"from tensorflow.keras.applications.inception_v3 import preprocess_input as pre_in_incv3\nimage_generator_incv3 = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=pre_in_incv3)\ntrain_generator_incv3 = image_generator_incv3.flow_from_directory(\n        train_path,\n        target_size=(image_size, image_size),\n        batch_size=128,\n        class_mode='categorical')\nval_generator_incv3 = image_generator_incv3.flow_from_directory(\n        test_path,\n        target_size=(image_size, image_size),\n        batch_size=128,\n        class_mode='categorical')","95a3356e":"history_incv3 = model_incv3.fit_generator(\n        train_generator_incv3,\n        steps_per_epoch=len(train_generator_incv3),\n        epochs=number_of_epochs, validation_data = val_generator_incv3, callbacks = [lr_scheduler])","271280c6":"fig = graph_accuracy(history_incv3, number_of_epochs, model_name = \"Inception3 model\", fig = fig, create_new_graph = False)","6d36d43e":"Now let's create our new model.","5ce25010":"As we can see the results without transfer learning are not great. Although it is possible to better our own model even further I think it would be interesting to use transfer learning.\n\n# **Step 3**: the resnet50 model\n\nWhat is transfer learning? Basically we use weights from an already pretrained model, delete the top layer and add our own final dense layer with our own classes. ","bc4e26da":"# **Step 4**: Inception v3 model","9bffc1eb":"# **Step 1**: data loading \n\nFirstly we need to load our data using ImageDataGenerator from Keras. It is faster than loading the data manually and we can add data augmentation(which is making small changes to our data to encrease the dataset's size, for example rotating it or changing it's brightness).","66b91354":"Comparing the models we can see that the resnet50 one did a better job.","5da0432c":"# **Step 2**: a simple CNN model\n\nIn this model I will use CNN with a few Conv2d layers, adding a LearningRateScheduler, which will reduce the learning rate every 3 epochs. ","7265a931":"When using ImageDataGenerator you can use .fit_generator instead of just .fit.\n\nHere steps_per_epoch is (the amount of images)\/(the amount of epochs)"}}