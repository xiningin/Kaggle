{"cell_type":{"bbc39c50":"code","a0439d55":"code","101dfc52":"code","3793a30d":"code","d271ef66":"code","84b6d36f":"code","090545bc":"code","166b6754":"code","4843dd30":"code","28ee4d04":"code","4085b7e6":"code","7370ab08":"code","5c1ffc3f":"code","851595d1":"code","726ebceb":"code","d9183fe4":"code","719643c2":"code","ddf8c89e":"code","05f3ee46":"code","8df643b3":"code","1776981b":"markdown","6fb565e3":"markdown","433fbfe0":"markdown","beb2d9f6":"markdown","352f4519":"markdown","517e0836":"markdown","bbd1a726":"markdown"},"source":{"bbc39c50":"# Importing the required libraries and dataset\nimport os\nimport itertools\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Hide all TensorFlow debugging logs\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.datasets import cifar100\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications import densenet\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","a0439d55":"# Load dataset and pre-process data\n(X_train, y_train), (X_test, y_test) = cifar100.load_data()\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","101dfc52":"# Split the data into test and validation data\nX_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.7)","3793a30d":"# Dataset class labels\nlabels =  ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', \n           'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', \n           'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', \n           'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', \n           'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', \n           'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n           'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', \n           'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', \n           'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']","d271ef66":"# Visualize several images and their classes from the training set\nplt.figure(figsize=(20, 3))\n\nfor i in range(10):\n    plt.subplot(1, 10, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train[i], cmap=\"gray\")\n    plt.xlabel(labels[y_train[i].astype(int)[0]])\n    \nplt.show()","84b6d36f":"# Convert labels to one hot encoding matrix\ny_train = to_categorical(y_train, 100)\ny_test = to_categorical(y_test, 100)\ny_valid = to_categorical(y_valid, 100)","090545bc":"# Function for model building\ndef build_model(input_shape, n_classes):\n    \"\"\"\n    Build model from DenseNet. Retrain last 5 layers and adds 2 Dense layers.\n    :param input_shape: shape of single image\n    :param n_classes: number of classes for prediction\n    :return model: compiled model\n    \"\"\"\n    base_model = densenet.DenseNet121(input_shape=input_shape,\n                                      weights=\"imagenet\",\n                                      include_top=False,\n                                      pooling='avg')\n\n    for layer in base_model.layers[:-5]:\n        layer.trainable = False\n\n    for layer in base_model.layers[-5:]:\n        layer.trainable = True\n\n    x = base_model.output\n\n    x = Dense(128)(x)\n    x = Activation('relu')(x)\n    predictions = Dense(n_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model","166b6754":"# Build model and get summary\nmodel = build_model(input_shape=(32, 32, 3), n_classes=len(labels))\nmodel.summary()","4843dd30":"# Generate augmented images\ndatagen = ImageDataGenerator(\n    height_shift_range=0.2,\n    width_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    rotation_range=40,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest',\n)\n\ndatagen.fit(X_train)","28ee4d04":"# Set checkpointer and train model\nmodel_checkpointer = ModelCheckpoint('cifar100_best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=128, shuffle=True), validation_data=(X_valid, y_valid), epochs=150, verbose=1,  \n               callbacks=[EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=15), model_checkpointer])","4085b7e6":"# Show Loss and Accuracy Plots\nfig, ax = plt.subplots(2, 1)\n\nax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation Loss\",axes=ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training Accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r', label=\"Validation Accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","7370ab08":"# Evaluate model on validation data\n_, evaluation_score = model.evaluate(X_test, y_test)\nprint(f'Evaluation Score: {int(evaluation_score * 100)} %')","5c1ffc3f":"# Get classification report\npred = np.argmax(model.predict(X_test), axis=1)\ntest_y = np.argmax(y_test, axis=1)\n\nprint(classification_report(test_y, pred, labels=list(range(len(labels)))))","851595d1":"# Download image with bicycle from custom data\nload_img('..\/input\/bicycle\/8195dKteEvL._SL1500_.jpg')","726ebceb":"# Get the names of the class labels\nlabels_names = []\nfor i in range(len(labels)):\n    labels_names += [i]\n    \nreverse_mapping = dict(zip(labels_names, labels)) \n\ndef mapper(value):\n    return reverse_mapping[value]","d9183fe4":"# Pre-process image\nimage_1 = load_img('..\/input\/bicycle\/8195dKteEvL._SL1500_.jpg', target_size=(32, 32))\nimage_1 = img_to_array(image_1) \nimage_1 = image_1 \/ 255.0\nprediction_image_1 = np.array(image_1)\nprediction_image_1 = np.expand_dims(image_1, axis=0)","719643c2":"# Get prediction\nprediction_1 = model.predict(prediction_image_1)\nvalue_1 = np.argmax(prediction_1)\nname_1 = mapper(value_1)\nprint(f'Prediction is {name_1}.')","ddf8c89e":"# Download second image with bicycle from custom data\nload_img('..\/input\/bicycle\/hybrid-sports-bike-road-cr.jpg')","05f3ee46":"# Pre-process one more image\nimage_2 = load_img('..\/input\/bicycle\/8195dKteEvL._SL1500_.jpg', target_size=(32, 32))\nimage_2 = img_to_array(image_2) \nimage_2 = image_2 \/ 255.0\nprediction_image_2 = np.array(image_2)\nprediction_image_2 = np.expand_dims(image_2, axis=0)","8df643b3":"# Get prediction\nprediction_2 = model.predict(prediction_image_2)\nvalue_2 = np.argmax(prediction_2)\nname_2 = mapper(value_2)\nprint(f'Prediction is {name_2}.')","1776981b":"<a id=\"2\"><\/a>\n<h3 style='background:CornflowerBlue; border:0; color:white'><center>Import and Pre-Processing<center><h3>","6fb565e3":"<a id=\"3\"><\/a>\n<h3 style='background:CornflowerBlue; border:0; color:white'><center>Build and Train model<center><h3>","433fbfe0":"**CIFAR-100** is a dataset that contains 60,000 color images of 32x32 pixels with 3 channels, the dataset contains 20 superclasses and 100 object classes. The training dataset contains 50,000 images and the test dataset contains 10,000 images. More information on the dataset can be obtained from the link: https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\n\nThis notebook provides a baseline for solving the problem of multi-label classification using Transfer Learning with Convolutional Neural Network in TensorFlow.\n\nSeveral images of bicycles from Google Search are used to predict the trained model.","beb2d9f6":"<a id=\"5\"><\/a>\n<h3 style='background:CornflowerBlue; border:0; color:white'><center>Evaluate Model on Custom Images<center><h3>","352f4519":"<a id=\"4\"><\/a>\n<h3 style='background:CornflowerBlue; border:0; color:white'><center>Evaluate Model<center><h3>","517e0836":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:CornflowerBlue; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation<\/center><\/h3>\n\n* [Introduction](#1)\n* [Import and Pre-Processing](#2)\n* [Build and Train model](#3)\n* [Evaluate Model](#4)\n* [Evaluate Model on Custom Images](#5)","bbd1a726":"<a id=\"1\"><\/a>\n<h3 style='background:CornflowerBlue; border:0; color:white'><center>Introduction<center><h3>"}}