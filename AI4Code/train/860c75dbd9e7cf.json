{"cell_type":{"6a665755":"code","4f711c21":"code","01be90d0":"code","171333db":"code","6242190f":"code","e64261cd":"code","8b21eb16":"code","ce172677":"code","31726f0f":"code","d20c2c34":"code","a6282b52":"code","866ece27":"code","3769cbc5":"code","02f0fcbc":"code","aad78540":"code","a2e94388":"code","cbc121d0":"code","4d46141c":"code","344daadb":"code","842dfc3d":"code","fa398e48":"code","c4045113":"code","a11d90af":"code","5fe2a4a5":"code","f3ec1d0d":"code","ffaf1f1b":"markdown","c81eb833":"markdown","0da03dd4":"markdown","e2844f75":"markdown","d273c58c":"markdown","80187001":"markdown","52063e9d":"markdown","68717740":"markdown","90e11c17":"markdown","f710bdf1":"markdown","e4c79127":"markdown","39e665a7":"markdown","86c9fa5e":"markdown","a0dc9183":"markdown","5db3d47a":"markdown","ce264f14":"markdown","08d312e8":"markdown","d80123d6":"markdown"},"source":{"6a665755":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport cv2\nimport random\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom keras.preprocessing.image import load_img, ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom tensorflow.keras.optimizers import *","4f711c21":"tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nlen(tf.config.list_physical_devices(\"GPU\"))","01be90d0":"BATCH_SIZE = 128\n\nseed = 666\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)                      \nrandom.seed(666)","171333db":"path_df = pd.DataFrame(columns = [\"img_path\", \"label\"])\n\nfor flower_type in os.listdir(\"..\/input\/flowers-recognition\/flowers\"):\n    \n    temp = pd.DataFrame(columns = [\"img_path\", \"label\"])\n    img_path = glob.glob(f\"..\/input\/flowers-recognition\/flowers\/{flower_type}\/*.jpg\")   \n    temp[\"img_path\"] = img_path\n    temp[\"label\"] = flower_type\n    \n    path_df = pd.concat([path_df, temp])\n    \npath_df.reset_index(drop = True, inplace = True)","6242190f":"fig = plt.figure(1, figsize = (16, 16))\nfig.suptitle(\"Training Set Images (Sample)\")\n\nfor i in range(100):\n    \n    ind = random.randint(0, len(path_df))\n\n    plt.subplot(10, 10, i + 1)\n    image = load_img(path_df[\"img_path\"][ind])\n    plt.imshow(image)\n    plt.title(path_df[\"label\"][ind])\n    plt.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","e64261cd":"train_data, test_data = train_test_split(path_df, \n                                         test_size = 0.1, \n                                         stratify = path_df[\"label\"], \n                                         random_state = seed, \n                                         shuffle = True)\n\ntrain_data, val_data = train_test_split(train_data, \n                                        test_size = 0.12, \n                                        stratify = train_data[\"label\"], \n                                        random_state = seed, \n                                        shuffle = True)\n\nprint(f\"Training set ratio: {len(train_data)\/ len(path_df)}\")\nprint(f\"Validation set ratio: {len(val_data)\/ len(path_df)}\")\nprint(f\"Test set ratio: {len(test_data)\/ len(path_df)}\")","8b21eb16":"INPUT_SHAPE = (227, 227, 3)\nNUM_CLASSES = 5","ce172677":"def AlexNet_func(input_shape = INPUT_SHAPE, num_classes = NUM_CLASSES):\n    \n    kernel_init = tf.keras.initializers.RandomNormal(mean = 0, stddev = 0.01, seed = seed)\n    \n    \n    inputs = Input(shape = input_shape)\n    \n    conv1 = Conv2D(filters = 96, kernel_size = (11, 11), strides = 4, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"zeros\", name = \"conv1\")(inputs)\n    conv1 = Lambda(tf.nn.local_response_normalization)(conv1)\n    conv1 = MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\")(conv1)\n    \n    \n    conv2 = Conv2D(filters = 256, kernel_size = (5, 5), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\", name = \"conv2\")(conv1)\n    conv2 = Lambda(tf.nn.local_response_normalization)(conv2)\n    conv2 = MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\")(conv2)\n    \n    \n    conv3 = Conv2D(filters = 384, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"zeros\", name = \"conv3\")(conv2)\n    conv4 = Conv2D(filters = 384, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\",name = \"conv4\")(conv3)\n    conv5 = Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\", name = \"conv5\")(conv4)\n    conv5 = MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\")(conv5)\n    \n    \n    dense1 = Flatten()(conv5)\n    dense1 = Dense(units = 4096, kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\", name = \"fc6\")(dense1)\n    dense1 = Dropout(0.5)(dense1)\n    \n    dense2 = Dense(units = 4096, kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\", name = \"fc7\")(dense1)\n    dense2 = Dropout(0.5)(dense2)    \n\n    dense3 = Dense(units = num_classes, kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\", activation = \"softmax\", name = \"fc8\")(dense2)\n    \n    \n    model = Model(inputs = inputs, outputs = dense3)\n    \n    return model","31726f0f":"optimizer = SGD(learning_rate = 0.01, momentum = 0.9, decay = 0.0005)","d20c2c34":"tf.keras.backend.clear_session()\n\nmodel = AlexNet_func(num_classes = 1000)\n\nmodel.summary()","a6282b52":"def AlexNet(input_shape = INPUT_SHAPE, num_classes = NUM_CLASSES):\n    \n    kernel_init = tf.keras.initializers.RandomNormal(mean = 0, stddev = 0.01, seed = seed)\n    \n    model = Sequential(\n        [\n            Conv2D(filters = 96, kernel_size = (11, 11), strides = 4, padding = \"same\", \n                   activation = \"relu\",  kernel_initializer = kernel_init, \n                   bias_initializer = \"zeros\", input_shape = input_shape, name = \"conv1\"),\n            Lambda(tf.nn.local_response_normalization),\n            MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\"),\n            \n            Conv2D(filters = 256, kernel_size = (5, 5), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\", name = \"conv2\"),\n            Lambda(tf.nn.local_response_normalization),\n            MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\"),\n            \n            Conv2D(filters = 384, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"zeros\", name = \"conv3\"),\n            Conv2D(filters = 384, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\",name = \"conv4\"),\n            Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   bias_initializer = \"ones\", name = \"conv5\"),\n            MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\"),\n            \n            Flatten(),\n            Dense(units = 4096, kernel_initializer = kernel_init, \n                  bias_initializer = \"ones\", name = \"fc6\"),\n            Dropout(0.5),\n            Dense(units = 4096, kernel_initializer = kernel_init, \n                  bias_initializer = \"ones\", name = \"fc7\"),\n            Dropout(0.5),\n            Dense(units = num_classes, kernel_initializer = kernel_init, \n                  bias_initializer = \"ones\", activation = \"softmax\", name = \"fc8\")            \n        ]\n    )\n    \n    return model","866ece27":"tf.keras.backend.clear_session()\n\nmodel = AlexNet(num_classes = 1000)\n\nmodel.summary()","3769cbc5":"def AlexNet2(input_shape = INPUT_SHAPE, num_classes = NUM_CLASSES):\n    \n    kernel_init = tf.keras.initializers.RandomNormal(mean = 0, stddev = 0.01, seed = seed)\n    \n    model = Sequential(\n        [\n            Conv2D(filters = 96, kernel_size = (11, 11), strides = 4, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, \n                   input_shape = input_shape, name = \"conv1\"),\n            Lambda(tf.nn.local_response_normalization),\n            MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\"),\n            \n            Conv2D(filters = 256, kernel_size = (5, 5), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, name = \"conv2\"),\n            Lambda(tf.nn.local_response_normalization),\n            MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\"),\n            \n            Conv2D(filters = 384, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, name = \"conv3\"),\n            Conv2D(filters = 384, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, name = \"conv4\"),\n            Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, padding = \"same\", \n                   activation = \"relu\", kernel_initializer = kernel_init, name = \"conv5\"),\n            MaxPool2D(pool_size = (3, 3), strides = 2, padding = \"valid\"),\n            \n            Flatten(),\n            Dense(units = 4096, kernel_initializer = kernel_init, name = \"fc6\"),\n            Dropout(0.5),\n            Dense(units = 4096, kernel_initializer = kernel_init, name = \"fc7\"),\n            Dropout(0.5),\n            Dense(units = num_classes, kernel_initializer = kernel_init, \n                  activation = \"softmax\", name = \"fc8\")            \n        ]\n    )\n    \n    return model","02f0fcbc":"tf.keras.backend.clear_session()\n\nmodel = AlexNet2()\n\nmodel.summary()","aad78540":"train_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range = 15, \n    zoom_range = 0.15,\n    horizontal_flip = True\n)\n\nval_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n)","a2e94388":"train_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_data,\n    x_col = \"img_path\",\n    y_col = \"label\",\n    class_mode = \"categorical\",\n    target_size = (227, 227),\n    batch_size = BATCH_SIZE,\n    seed = 666,\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe = val_data,\n    x_col = \"img_path\",\n    y_col = \"label\",\n    class_mode = \"categorical\",\n    target_size = (227, 227),\n    batch_size = BATCH_SIZE,\n    seed = 666,\n    shuffle = False\n)","cbc121d0":"reduce_lr = ReduceLROnPlateau(\n    monitor = \"val_accuracy\", \n    patience = 3,\n    verbose = 1, \n    factor = 0.8, \n    min_lr = 0.000000001\n)","4d46141c":"# model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics = \"accuracy\")\nmodel.compile(loss = \"categorical_crossentropy\", optimizer = Adam(learning_rate=0.0001), metrics = \"accuracy\")\n\n\nhistory = model.fit(train_generator, batch_size = BATCH_SIZE, epochs = 30,\n                    validation_data = (val_generator),\n                    callbacks = [reduce_lr])","344daadb":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","842dfc3d":"test_generator = test_datagen.flow_from_dataframe(\n    dataframe = test_data,\n    x_col = \"img_path\",\n    y_col = \"label\",\n    class_mode = \"categorical\",\n    target_size = (227, 227),\n    batch_size = BATCH_SIZE,\n    seed = 666,\n    shuffle = False\n)","fa398e48":"test_pred = model.predict(test_generator, steps = np.ceil(test_data.shape[0] \/ BATCH_SIZE))\ntest_data.loc[:, \"test_pred\"] = np.argmax(test_pred, axis = 1)\n\nlabels = dict((v, k) for k, v in test_generator.class_indices.items())\n\ntest_data.loc[:, \"test_pred\"] = test_data.loc[:, \"test_pred\"].map(labels)","c4045113":"labels.keys()","a11d90af":"fig, ax = plt.subplots(figsize = (9, 6))\n\ncm = confusion_matrix(test_data[\"label\"], test_data[\"test_pred\"])\n\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"])\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nax.set_title(\"Test Set\")\nplt.show()","5fe2a4a5":"test_errors = test_data[(test_data.label) != (test_data.test_pred)].reset_index(drop = True)\ntest_errors","f3ec1d0d":"fig = plt.figure(1, figsize = (24, 20))\n\nfor i in range(109):\n    \n    plt.subplot(11, 10, i + 1)\n    image = load_img(test_errors.img_path[i])\n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.title(f\"True Value: {test_errors['label'][i]} \\nPrediction: {test_errors['test_pred'][i]}\")    \n    \nplt.tight_layout()\nplt.show()","ffaf1f1b":"## Architecture","c81eb833":"# Implementation on Keras (Functional API)","0da03dd4":"In this notebook,\n\nI will implement Alexnet on keras with using both functional API and sequential API.","e2844f75":"# Readings \/ Resources","d273c58c":"# Visualization Images","80187001":"# Implementation on Keras (Sequential)","52063e9d":"# AlexNet ","68717740":"> We initialized the weights in each layer from a zero-mean Gaussian distribution with standard deviation 0.01.\n \n> We initialized the neuron biases in the second, fourth, and fifth convolutional layers, as well as in the fully-connected hidden layers, with the constant 1. This initialization accelerates the early stages of learning by providing the ReLUs with positive inputs.\n \n> We initialized the neuron biases in the remaining layers with the constant 0.\n\n**from paper*","90e11c17":"## Paper","f710bdf1":"> Response-normalization layers follow the first and second convolutional layers.\n\n> Max-pooling layers, of the kind described in Section 3.4, follow both response-normalization layers as well as the fifth convolutional layer.\n \n> The ReLU non-linearity is applied to the output of every convolutional and fully-connected layer.\n\n\n**from paper*","e4c79127":"# Introduction","39e665a7":"> We trained a large, deep convolutional neural network to classify the 1.2 million\n> high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5%\n> and 17.0% which is considerably better than the previous state-of-the-art. The\n> neural network, which has 60 million parameters and 650,000 neurons, consists\n> of five convolutional layers, some of which are followed by max-pooling layers,\n> and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected\n> layers we employed a recently-developed regularization method called \u201cdropout\u201d\n> that proved to be very effective. We also entered a variant of this model in the\n> ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%,\n> compared to 26.2% achieved by the second-best entry.\n\nhttps:\/\/papers.nips.cc\/paper\/2012\/file\/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf","86c9fa5e":"# Preparation","a0dc9183":"# Prediction","5db3d47a":"https:\/\/paperswithcode.com\/method\/alexnet\n\nhttps:\/\/papers.nips.cc\/paper\/2012\/file\/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n\nhttp:\/\/d2l.ai\/chapter_convolutional-modern\/alexnet.html\n\nhttps:\/\/github.com\/duggalrahul\/AlexNet-Experiments-Keras\n\nhttp:\/\/www.cs.toronto.edu\/~guerzhoy\/tf_alexnet\/\n\nhttps:\/\/www.kaggle.com\/blurredmachine\/alexnet-architecture-a-complete-guide\n\n\n**My similar works with image data;**\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/mnist-cnn-data-augmentation\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/mnist-lenet-5-implementation-on-keras\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/dogs-cats-vgg16-implementation-transfer-learning","ce264f14":"I just modified Alexnet architecture. I remove bias initializer parameter, its default value is zeros.\n\nWe won't expect perfect score at the end. Let's see how its results.","08d312e8":"**From paper:**\n\n![](https:\/\/production-media.paperswithcode.com\/methods\/Screen_Shot_2020-06-22_at_6.35.45_PM.png)\n\n*https:\/\/paperswithcode.com\/method\/alexnet\n\n\n![](https:\/\/miro.medium.com\/max\/2000\/1*2DT1bjmvC-U-lrL7tpj6wg.png)\n\n*https:\/\/towardsdatascience.com\/illustrated-10-cnn-architectures-95d78ace614d","d80123d6":"> We trained our models using stochastic gradient descent with a batch size of 128 examples, momentum of 0.9, and weight decay of 0.0005.\n \n> We used an equal learning rate for all layers, which we adjusted manually throughout training.\n \n> The heuristic which we followed was to divide the learning rate by 10 when the validation error rate stopped improving with the current learning rate.\n \n> The learning rate was initialized at 0.01 and reduced three times prior to termination\n\n\n**from paper*"}}