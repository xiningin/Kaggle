{"cell_type":{"47961b42":"code","73a5c560":"code","45807332":"code","9654536a":"code","979b076f":"code","a6a4ca18":"code","03bc6052":"code","c7834018":"code","3ee4b7d8":"code","735774db":"code","309f8dc4":"code","bc9b26ab":"code","407209fd":"code","d2395917":"code","bac39879":"code","055fb57d":"code","5c211e39":"code","4625b4c1":"code","45c301f4":"code","057ee3cf":"code","0e5bac9a":"code","f20de315":"code","aea7fa58":"code","3a96c9ea":"code","496a7bbe":"code","ff180329":"code","821ac8f3":"code","9c609ccd":"code","4adb47f6":"code","bc63a719":"code","16ac6f52":"code","fc6e6c94":"code","e4e6a01b":"code","3f979900":"code","25e74c57":"code","11c620fe":"code","4396b9cc":"code","9c518c2f":"code","752383e5":"markdown","76b0b1d1":"markdown","bb472993":"markdown","ac487298":"markdown","24a685b9":"markdown","0f6c9872":"markdown","b8382fb2":"markdown","1f882a8b":"markdown","52ed1a83":"markdown","0cc3d9a5":"markdown","2518aca2":"markdown","dd8d2078":"markdown","ac640cb3":"markdown","74fa6564":"markdown","0675273f":"markdown","cdefbba2":"markdown","230c82d5":"markdown","2a7fabc7":"markdown","a34ded7f":"markdown","cf3ae1a5":"markdown","8428a378":"markdown","e960571c":"markdown","9093f6e9":"markdown","9e4cf948":"markdown","1a2248b8":"markdown","0e35e68e":"markdown","3268f2ca":"markdown","b13177b1":"markdown","9203d098":"markdown","e60bbe7e":"markdown","680f4f7b":"markdown","ac820721":"markdown","aab27bec":"markdown","9df3716c":"markdown","1a342079":"markdown","85b80cbe":"markdown","3d7aeda1":"markdown","b1405a52":"markdown","a9e64544":"markdown","6ec8b83b":"markdown","b264229f":"markdown","360434df":"markdown","42514b37":"markdown","c28f7e1f":"markdown","ec36f227":"markdown","ed7c113c":"markdown"},"source":{"47961b42":"import numpy as np # for math operations\nfrom scipy import stats, signal # for some probability operations\nimport cv2 # for image reading and conversions\nimport matplotlib.pyplot as plt # for image display\nimport os # for file handling\nimport urllib3 # to read data from a url\nfrom tqdm import tqdm\n\n# read data files from the Tea-Time dataset\ntea_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/tea-time'):\n    for filename in filenames:\n        tea_files.append(str(os.path.join(dirname, filename)))\ntea_files.sort()\nprint(tea_files[0])\n\n# read data files from the People-Clothing-Segmentation dataset\ncloth_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/people-clothing-segmentation\/jpeg_images\/IMAGES'):\n    for filename in filenames:\n        cloth_files.append(str(os.path.join(dirname, filename)))\ncloth_files.sort()\nprint(cloth_files[0])","73a5c560":"# The Image\nimage = cv2.imread(cloth_files[1], 0)\nimage = cv2.resize(image, (275, 410))\nplt.figure(figsize=(5,8))\nplt.imshow(image, cmap='gray', vmin=0, vmax=255)\nplt.show()","45807332":"# The Filter\nmask = cv2.imread(tea_files[8], 0)\nplt.figure(figsize=(5,8))\nplt.imshow(mask, cmap='gray', vmin=0, vmax=255)\nplt.show()","9654536a":"# trimmed mask\nmask1 = mask[325:520, 220:415]\n# resize to a smaller mask for better compute speed\nmask1 = cv2.resize(mask1, (31,31))\nplt.figure(figsize=(2,2))\nplt.imshow(mask1, cmap='gray', vmin=0, vmax=255)\nplt.show()","979b076f":"print(image.shape, mask1.shape)","a6a4ca18":"%%time\n# Perform cross-correlation by sliding the mask over the image pixel-by-pixel\n# after correlation, the resulting shape will be image shape minus mask shape\nresult_rows = image.shape[0] - mask1.shape[0]\nresult_columns = image.shape[1] - mask1.shape[1]\nresult = np.zeros([result_rows, result_columns])\n\n# normalize mask before processing\nmask1 = mask1\/255.0\n\n# start cross-correlation\nfor r in tqdm(range(result_rows)):\n    for c in range(result_columns):\n        # now we are at result[r][c]\n        val = np.multiply(image[r:r+mask1.shape[0], c:c+mask1.shape[1]], mask1)\n        val = np.sum(np.ravel(val))\n        # replace result value with val\n        # normalize it with respect to mask size\n        result[r][c] = val \/ np.prod(mask1.shape)\n\nplt.figure(figsize=(5,8))\nplt.imshow(result, cmap='gray', vmin=0, vmax=255)\nplt.show()","03bc6052":"# read an image\nimage = cv2.imread(cloth_files[1], 0)\n\n# copy image as mask\n# normalize mask values\nmask = image[:] \/ 255\n\n# do pixel-wise multiplication\nresult = np.array(np.multiply(image,mask), dtype= np.uint8)\n\n# display the result\n_,(ax1, ax2) = plt.subplots(1,2, figsize=(10,8))\nax1.imshow(image, cmap='gray', vmin=0, vmax=255)\nax2.imshow(result, cmap='gray', vmin=0, vmax=255)\nax1.set_title('Original Image')\nax2.set_title('Autocorrelated Image')\nplt.show()\n","c7834018":"image.max(), mask.max(), result.max()","3ee4b7d8":"# Let's visualize a small portion of image to gain some idea\n_,(ax1, ax2) = plt.subplots(1,2, figsize=(10,8))\nax1.imshow(image[0:140,200:340], cmap='gray', vmin=0, vmax=255)\nax2.imshow(result[0:140,200:340], cmap='gray', vmin=0, vmax=255)\nax1.set_title('A part in Original Image')\nax2.set_title('A part in Autocorrelated Image')\nplt.show()","735774db":"plt.figure(figsize=(10,4))\n# histogram of original image \nintensity,count = np.unique(image, return_counts=True)\nplt.plot(intensity, count, '--g', label='original')\n# histogram of autocorrelated image\nintensity,count = np.unique(result, return_counts=True)\nplt.plot(intensity, count, '--r', label='autocorrelated')\nplt.title('Histogram of Image & Autocorrelated verion')\nplt.xlabel('Intensity Values')\nplt.ylabel('Frquency of occurrence')\nplt.legend()\nplt.show()","309f8dc4":"# define separate functions for both convolution and cross-correlation \n# so that they will be very handy in the future.\n\n\ndef cross_correlate(img, mask, padding='valid'):\n    \"\"\"\n    The function uses padding to return the required image size.\n    Mask is expected to be smaller than or equal to Image by size.\n    Mask should have odd-numbered-shapes to do meaningful padding.\n    Mask needs not to be square in shape\n    Input image and mask should be in grayscale (for simplicity)\n    \"\"\"\n    if mask.shape[0]>img.shape[0] or mask.shape[1]>img.shape[1]:\n        raise Exception('Mask is bigger than Image!')\n    if len(mask.shape)>2 or len(img.shape)>2:\n        raise Exception('Please convert inputs to grayscale!')\n    \n    result_size = [0,0]\n    \n    # valid padding - returns image of smaller size than the original\n    if padding=='valid':\n        result_size[0] = img.shape[0] - mask.shape[0] + 1\n        result_size[1] = img.shape[1] - mask.shape[1] + 1\n        padded = img[:] # to have a common variable during convolution\n        \n    else:\n        pad_size = [0,0] \n        padded_size = [0,0]\n        # full padding - returns bigger image than the original\n        if padding=='full':\n            pad_size[0] = mask.shape[0] - 1\n            pad_size[1] = mask.shape[1] - 1\n            result_size[0] = img.shape[0] + mask.shape[0] - 1\n            result_size[1] = img.shape[1] + mask.shape[1] - 1\n        # same padding - returns image of size equal to original image\n        if padding=='same':\n            pad_size[0] = int((mask.shape[0] - 1)\/2)\n            pad_size[1] = int((mask.shape[1] - 1)\/2)\n            result_size[0] = img.shape[0]\n            result_size[1] = img.shape[1] \n        padded_size[0] = img.shape[0] + pad_size[0]*2\n        padded_size[1] = img.shape[1] + pad_size[1]*2\n        # formulate a dummy padded image\n        padded = np.zeros(padded_size)\n        # pad the input image\n        if pad_size[0] == 0:\n            padded[:,pad_size[1]:-pad_size[1]] = img[:]\n        elif pad_size[1] == 0:\n            padded[pad_size[0]:-pad_size[0],:] = img[:]\n        else:\n            padded[pad_size[0]:-pad_size[0],pad_size[1]:-pad_size[1]] = img[:]\n        \n    \n    # formulate a dummy result\n    result = np.zeros(result_size)\n    \n    # peform cross-correlation\n    for r in tqdm(range(result.shape[0])):\n        for c in range(result.shape[1]):\n            # we are now at result[r][c]\n            val = np.multiply(padded[r:r+mask.shape[0],c:c+mask.shape[1]], mask)\n            val = np.sum(np.ravel(val))\n            result[r][c] = val\n    \n    return result\n                  \ndef convolve(img, mask, padding='valid'):\n    flipped = mask[::-1, ::-1]\n    # once mask is double-flipped, convolution resembles cross-correlation\n    return cross_correlate(img, flipped, padding)","bc9b26ab":"# create a 5 x 5 random filter\nmask = np.random.random([5,5])\nmask","407209fd":"plt.imshow(mask, cmap='gray')\nplt.show()","d2395917":"# an image\nimage = cv2.imread(cloth_files[50], 0)\nplt.imshow(image, cmap='gray', vmin=0, vmax=255)\nplt.show()","bac39879":"# perform convolution on above image and mask\nres = convolve(image, mask) \/ np.prod(mask.shape)\nplt.imshow(res, cmap='gray', vmin=0, vmax=255)\nplt.title('Convolved Image Result')\nplt.show()","055fb57d":"# formulate a simple image \nimage = np.arange(25).reshape(5,-1)\nplt.imshow(image, cmap='gray')\nplt.title('Image')\nplt.show()\n\nmask = np.random.random([5,5])\nplt.imshow(mask, cmap='gray')\nplt.title('Mask')\nplt.show()","5c211e39":"paddings = ['valid', 'same', 'full']\nfor padding in paddings:\n    result1 = convolve(image, mask, padding)\n    result2 = convolve(mask, image, padding)\n    # are both results the same?\n    print('Convolution: %s padding'%padding)\n    print('Is it Commutative?: ', end='')\n    print((np.float16(result1)==np.float16(result2)).all())\n\n    # display the results\n    _, (ax1, ax2) = plt.subplots(1,2)\n    ax1.imshow(result1, cmap='gray')\n    ax1.set_title('Convolution: image * mask')\n\n    ax2.imshow(result2, cmap='gray')\n    ax2.set_title('Convolution: mask * image')\n    plt.suptitle('%s padding'%padding)\n    plt.show()","4625b4c1":"paddings = ['valid', 'same', 'full']\nfor padding in paddings:\n    result1 = cross_correlate(image, mask, padding)\n    result2 = cross_correlate(mask, image, padding)\n    # are both results the same?\n    print('Cross-correlation: %s padding'%padding)\n    print('Is it Commutative?: ', end='')\n    # are both results the same?\n    print((np.float16(result1)==np.float16(result2)).all())\n\n    # display the results\n    _, (ax1, ax2) = plt.subplots(1,2)\n    ax1.imshow(result1, cmap='gray')\n    ax1.set_title('Cross-corr: image * mask')\n\n    ax2.imshow(result2, cmap='gray')\n    ax2.set_title('Cross-corr: mask * image')\n    plt.suptitle('Cross-correlation {:} padding'.format(padding))\n    plt.show()","45c301f4":"# define three images\na = np.random.random((7,7))\nb = np.random.random((5,5))\nc = np.random.random((3,3))\n\n# display the images\n_, (ax1, ax2, ax3) = plt.subplots(1,3)\nax1.imshow(a, cmap='gray')\nax1.set_title('image \"a\"')\n\nax2.imshow(b, cmap='gray')\nax2.set_title('image \"b\"')\n\nax3.imshow(c, cmap='gray')\nax3.set_title('image \"c\"')\nplt.show()","057ee3cf":"# perform convolution\npadding='full'\nresult1 = convolve(convolve(a,b, padding), c, padding)\nresult2 = convolve(a, convolve(b,c, padding), padding)\n# are both results the same?\nprint((np.float16(result1)==np.float16(result2)).all()) \n\n# display the results\n_, (ax1, ax2) = plt.subplots(1,2)\nax1.imshow(result1, cmap='gray')\nax1.set_title('Convol: (a * b) * c')\n\nax2.imshow(result2, cmap='gray')\nax2.set_title('Convol: a * (b * c)')\nplt.show()","0e5bac9a":"# perform Cross-correlation\npadding='full'\nresult1 = cross_correlate(cross_correlate(a,b, padding), c, padding)\nresult2 = cross_correlate(a, cross_correlate(b,c, padding), padding)\n\n# are both results the same?\nprint((np.float16(result1)==np.float16(result2)).all()) \n\n# display the results\n_, (ax1, ax2) = plt.subplots(1,2)\nax1.imshow(result1, cmap='gray')\nax1.set_title('Cross-corr: (a * b) * c')\n\nax2.imshow(result2, cmap='gray')\nax2.set_title('Cross-corr: a * (b * c)')\nplt.show()","f20de315":"# define one image and two masks; \n# masks must be of same shape\na = np.random.random((5,5))\nb = np.random.random((3,3))\nc = np.random.random((3,3))\n\n# display the images\n_, (ax1, ax2, ax3) = plt.subplots(1,3)\nax1.imshow(a, cmap='gray')\nax1.set_title('image \"a\"')\n\nax2.imshow(b, cmap='gray')\nax2.set_title('image \"b\"')\n\nax3.imshow(c, cmap='gray')\nax3.set_title('image \"c\"')\nplt.show()","aea7fa58":"# perform convolution\npaddings= ['valid', 'same', 'full']\nfor padding in paddings:\n    result1 = convolve(a, (b+c), padding)\n    result2 = convolve(a,b,padding) + convolve(a,c,padding)\n    # are both results the same?\n    print('Convolution: %s padding'%padding)\n    print('Is it Distributive?: ', end='')\n    print((np.float16(result1)==np.float16(result2)).all()) \n\n    # display the results\n    _, (ax1, ax2) = plt.subplots(1,2)\n    ax1.imshow(result1, cmap='gray')\n    ax1.set_title('Convol: a * (b+c)')\n\n    ax2.imshow(result2, cmap='gray')\n    ax2.set_title('Convol: (a*b) + (a*c)')\n    plt.suptitle('Convolution {} padding'.format(padding))\n    plt.show()","3a96c9ea":"# perform Cross-correlation\npaddings= ['valid', 'same', 'full']\nfor padding in paddings:\n    result1 = cross_correlate(a, (b+c), padding)\n    result2 = cross_correlate(a,b,padding) + convolve(a,c,padding)\n    # are both results the same?\n    print('Cross-correlation: %s padding'%padding)\n    print('Is it Distributive?: ', end='')\n    print((np.float16(result1)==np.float16(result2)).all()) \n\n    # display the results\n    _, (ax1, ax2) = plt.subplots(1,2)\n    ax1.imshow(result1, cmap='gray')\n    ax1.set_title('Cross-corr: a * (b+c)')\n\n    ax2.imshow(result2, cmap='gray')\n    ax2.set_title('Cross-corr: (a*b) + (a*c)')\n    plt.suptitle('Cross_correlation {} padding'.format(padding))\n    plt.show()","496a7bbe":"# have an image and a mask\na = np.random.random((5,5))\nb = np.random.random((3,3))\n\nplt.imshow(a, cmap='gray')\nplt.title('Image')\nplt.show()\n\nplt.imshow(b, cmap='gray')\nplt.title('Filter')\nplt.show()","ff180329":"# declare a scalar\nk = 5\n# perform convolution\npaddings= ['valid', 'same', 'full']\nfor padding in paddings:\n    result1 = convolve(k*a, b, padding)\n    result2 = convolve(a, k*b, padding)\n    result3 = k*convolve(a, b, padding)\n    # are both results the same?\n    print('Convolution: %s padding'%padding)\n    print('Convolution has Scalar property: ', end=' ')\n    print((np.float16(result1)==np.float16(result2)).all(), end=' ') \n    print((np.float16(result1)==np.float16(result3)).all()) \n\n    # display the results\n    _, (ax1, ax2, ax3) = plt.subplots(1,3)\n    ax1.imshow(result1, cmap='gray')\n    ax1.set_title('Convol: ka * b')\n\n    ax2.imshow(result2, cmap='gray')\n    ax2.set_title('Convol: a * kb')\n    \n    ax3.imshow(result3, cmap='gray')\n    ax3.set_title('Convol: k(a * b)')\n    plt.suptitle('Convolution {} padding'.format(padding))\n    plt.show()","821ac8f3":"# declare a scalar\nk = 5\n# perform cross-correlation\npaddings= ['valid', 'same', 'full']\nfor padding in paddings:\n    result1 = cross_correlate(k*a, b, padding)\n    result2 = cross_correlate(a, k*b, padding)\n    result3 = k*cross_correlate(a, b, padding)\n    # are both results the same?\n    print('Cross_correlation: %s padding'%padding)\n    print('Cross_correlation has Scalar property: ', end=' ')\n    print((np.float16(result1)==np.float16(result2)).all(), end=' ') \n    print((np.float16(result1)==np.float16(result3)).all()) \n\n    # display the results\n    _, (ax1, ax2, ax3) = plt.subplots(1,3)\n    ax1.imshow(result1, cmap='gray')\n    ax1.set_title('Cross_corr: ka * b')\n\n    ax2.imshow(result2, cmap='gray')\n    ax2.set_title('Cross_corr: a * kb')\n    \n    ax3.imshow(result3, cmap='gray')\n    ax3.set_title('Convol: k(a * b)')\n    plt.suptitle('Cross_corr {} padding'.format(padding))\n    plt.show()","9c609ccd":"# create an impulse function with central pixel possessing the max value\n# and remaining pixels the min value\ne = np.zeros((9,9))\ne[e.shape[0]\/\/2, e.shape[1]\/\/2] = 1\n\n# create an image\na = np.random.random((5,5))\n\nresult = convolve(e, a, padding='valid')\n# is the result same as input image?\nprint('Convolution has Impulse property: ', end=' ')\nprint((np.float16(result)==np.float16(a)).all()) \n\n# display the results\n_, (ax1, ax2, ax3) = plt.subplots(1,3)\nax1.imshow(e, cmap='gray')\nax1.set_title('Impulse')\n\nax2.imshow(a, cmap='gray')\nax2.set_title('Input image')\n    \nax3.imshow(result, cmap='gray')\nax3.set_title('Convol: e * a')\nplt.show()","4adb47f6":"result = cross_correlate(e, a, padding='valid')\n# is the result same as input image?\nprint('Cross-correlation has Impulse property: ', end=' ')\nprint((np.float16(result)==np.float16(a)).all()) \n\n# display the results\n_, (ax1, ax2, ax3) = plt.subplots(1,3)\nax1.imshow(e, cmap='gray')\nax1.set_title('Impulse')\n\nax2.imshow(a, cmap='gray')\nax2.set_title('Input image')\n    \nax3.imshow(result, cmap='gray')\nax3.set_title('Cross_corr: e * a')\nplt.show()","bc63a719":"# create an impulse function with central pixel possessing the max value\n# and remaining pixels the min value\ne = np.zeros((155,125))\ne[e.shape[0]\/\/2, e.shape[1]\/\/2] = 1\n\n# read an image from input files\nimg = cv2.imread(cloth_files[80],0)\nimg = cv2.resize(img,(125,155))\nconv_result = convolve(e, img, padding='same')\ncc_result = cross_correlate(e, img, padding='same')\n\n# display the results\n_, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(12,4))\nax1.imshow(e, cmap='gray')\nax1.set_title('Impulse, e')\nax1.axis('off')\n\nax2.imshow(img, cmap='gray')\nax2.set_title('Input image')\nax2.axis('off')\n    \nax3.imshow(conv_result, cmap='gray')\nax3.set_title('Convol: img * e')\nax3.axis('off')\n\nax4.imshow(cc_result, cmap='gray')\nax4.set_title('Cross-corr: img * e')\nax4.axis('off')\nplt.show()","16ac6f52":"img = cv2.imread(cloth_files[90],0)\nimg = img[30:300,150:350]\nplt.imshow(img, cmap='gray')\nplt.show()","fc6e6c94":"# a function for moving average filter\ndef moving_avg(size=3):\n    mask = np.ones((size,size))\n    # normalize the filter\n    return mask \/ np.sum(mask)\n    \n# read an image from input files\nimg = cv2.imread(cloth_files[90],0)\nimg = img[30:300,150:350]\n# create three different sized filters\nmask3 = moving_avg(3)\nmask5 = moving_avg(5)\nmask7 = moving_avg(7) \n\n# print a mask for better understanding\nprint('This is a 3x3 moving average filter')\nprint(mask3)\nplt.imshow(mask3, cmap='gray', vmin=0, vmax=1)\nplt.show()\n\n# display the images\n_, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(16,5))\nax1.imshow(img, cmap='gray')\nax1.set_title('Original Image')\nax1.axis('off')\n\nax2.imshow(convolve(img,mask3,padding='same'), cmap='gray')\nax2.set_title('Blurred with 3x3 mask')\nax2.axis('off')\n    \nax3.imshow(convolve(img,mask5,padding='same'), cmap='gray')\nax3.set_title('Blurred with 5x5 mask')\nax3.axis('off')\n\nax4.imshow(convolve(img,mask7,padding='same'), cmap='gray')\nax4.set_title('Blurred with 7x7 mask')\nax4.axis('off')\nplt.show()","e4e6a01b":"# A simple N-sized gaussian kernel with standard deviation STD\ndef gaussian(size=3,std=1.0):\n    k = signal.gaussian(size,std=std)\n    # obtain 2D kernel from 1D kernel\n    kernel = np.outer(k,k)\n    # normalize the values\n    return kernel \/ np.sum(kernel)","3f979900":"# read an image from input files\nimg = cv2.imread(cloth_files[90],0)\nimg = img[30:300,150:350]\n# create three different sized filters with some common std \n# the mask values can be varied with std\nmask3 = gaussian(size=3, std=0.83)\nmask5 = gaussian(size=5, std=1.03)\nmask7 = gaussian(size=7, std=1.40)\n\ni=1\nfor mask in [mask3,mask5,mask7]:    # print a mask for better understanding\n    i += 2\n    print('This is a {}x{} Gaussian filter'.format(i,i))\n    print(mask)\n    plt.imshow(mask, cmap='gray')\n    plt.show()\n\n# display the images\n_, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(16,5))\nax1.imshow(img, cmap='gray')\nax1.set_title('Original Image')\nax1.axis('off')\n\nax2.imshow(convolve(img,mask3,padding='same'), cmap='gray')\nax2.set_title('Gaussian-Blurred with 3x3 mask')\nax2.axis('off')\n    \nax3.imshow(convolve(img,mask5,padding='same'), cmap='gray')\nax3.set_title('Gaussian-Blurred with 5x5 mask')\nax3.axis('off')\n\nax4.imshow(convolve(img,mask7,padding='same'), cmap='gray')\nax4.set_title('Gaussian-Blurred with 7x7 mask')\nax4.axis('off')\nplt.show()","25e74c57":"horiz_edge = np.array([[-1,-1,-1],\n                        [0,0,0],\n                        [1,1,1]])\nverti_edge = horiz_edge.T\nboth_edge = horiz_edge + verti_edge\n\n# display the filters\n# display the images\n_, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(12,4))\nax1.imshow(horiz_edge, cmap='gray')\nax1.set_title('Horizontal edge filter')\n\nax2.imshow(verti_edge, cmap='gray')\nax2.set_title('Vertical edge filter')\n    \nax3.imshow(both_edge, cmap='gray')\nax3.set_title('All edge filter')\nplt.show()\n\n# read an image from input files\nimg = cv2.imread(tea_files[120],0)\n#img = img[30:300,150:350]\n\n# display the images\n_, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(16,6))\nax1.imshow(img, cmap='gray')\nax1.set_title('Original Image')\nax1.axis('off')\n\nax2.imshow(convolve(img,horiz_edge,padding='same'), cmap='gray')\nax2.set_title('Horizontal Edges')\nax2.axis('off')\n    \nax3.imshow(convolve(img,verti_edge,padding='same'), cmap='gray')\nax3.set_title('Vertical Edges')\nax3.axis('off')\n\nax4.imshow(convolve(img,both_edge,padding='same'), cmap='gray')\nax4.set_title('Horiz + Verti Edges')\nax4.axis('off')\nplt.show()","11c620fe":"%%time\n# a 2D filter of size 11*11\nmask = np.ones((11,11))\nmask = mask \/ np.sum(mask)\nimage = cv2.imread(cloth_files[40],0)\nresult_2D = convolve(image,mask,padding='same')\n# display the result\nplt.imshow(result_2D, cmap='gray')\nplt.show()","4396b9cc":"%%time\n# a 1D filter of size 11*1\nmask = np.ones((11,1)) \nmask = mask \/ np.sum(mask)\nimage = cv2.imread(cloth_files[40],0)\n# do TWO convolutions one with column vector and another with a row vector\nresult_1D = convolve(convolve(image,mask,padding='same'), mask.T,padding='same')\n# display the result\nplt.imshow(result_1D, cmap='gray')\nplt.show()","9c518c2f":"(np.float16(result_1D) == np.float16(result_2D)).all()","752383e5":"For the sake of simplicity, we may trim the above mask on all sides to have a smaller mask. ","76b0b1d1":"## 5. Moving Average Filter","bb472993":"In Gaussian Filter, we could recall that we have formulated a 2D filter by performing an outer product with two instances of an identical 1D filter. \n\nMoreover, the above edge filters can also be separated into 1D filters that are not identical. As an optimization and simplication step, a filter, if possible, must be broken down into smaller-dimensional filters.","ac487298":"## 1. Cross-Correlation","24a685b9":"Cross-correlation is NOT distributive. We have to perform the operations as intended.","0f6c9872":"Two datasets both containing JPEG images are available now for our image processing tasks. ","b8382fb2":"Plot a histogram to know how far the values are stretched during autocorrelation","1f882a8b":"## 2. Auto-Correlation","52ed1a83":"Yes. Both the results are same. Convolution is commutative!\n\n*Take-away: The order of image and mask is not required. We can call an image as a mask and a mask as an image. So the two images can be interchanged.*\n\nWhat about cross-correlation?","0cc3d9a5":"Edge filters are yet another popular filters category. They find either horizontal edges or vertical edges, or both the horizontal and vertical edges. These filters are high-pass filters since they pass the high-frequency components (edges) and block low-frequency components (other than edges). In the resulting image, edges retain high intensity values (close to MAX) while the remaining portions possess negligible intensity values (close to MIN).","2518aca2":"It can be observed that Gaussian filter smoothens the image while retaining most finer details compared to moving average filter.","dd8d2078":"Cross-correlation double flips the input image when processed with an impulse function. Let's have a real-life image to have better visualization!","ac640cb3":"Autocorrelated image seems to have attained some enhancement by increasing contrast and darkening to some extent. Autocorrelation is widely used in signal processing, but rarely in computer vision applications.","74fa6564":"## 3. Convolution","0675273f":"**Associative Property:**\n\na ~ (b ~ c) = (a ~ b) ~ c\n\na, b, c are three images under processing","cdefbba2":"Let's test the above function by passing an image and a mask","230c82d5":"# Computer Vision For Everyone With Python\n\n### In this Computer Vision series, I publish a set of Python hands-on articles that cover both traditional image processing and deep learning based computer vision!\n\n### I welcome you all!","2a7fabc7":"Convolution operation is widely used in signal processing over cross-correlation thanks to its great mathematical properties! Let's look at those properties and compare convolution and cross-correlation with respect to grayscale images.","a34ded7f":"Do necessary imports and download image data!","cf3ae1a5":"Evidently, convolution is distributive! \n\n*Takeaway: We can split operations or merge operations whenever possible.*\n\nWhat about cross-correlation?","8428a378":"**Commutative Property:**\n\na ~ b = b ~ a\n\nwhere \na - refers to image\nb - refers to mask\n(~) - refers to convolution operation","e960571c":"#### Thank you for your time!","9093f6e9":"##### Contents\n1. Cross-Correlation\n2. Auto-Correlation\n3. Convolution\n4. Properties of Convolution\n5. Moving Average Filter\n6. Gaussian Filter\n7. Edge Filter\n8. Separable Filters","9e4cf948":"**Scalar Property:**\n\nka ~ b = a ~ kb = k (a ~ b)\n\nIf there is a scalar, it can be multiplied either with image or with mask before doing convolution, or, alternatively, it can be multiplied with the result after doing convolution.","1a2248b8":"## 6. Gaussian Filter","0e35e68e":"**Moving Average filter**","3268f2ca":"Yes! Convolution is associative. \n\n*Take-away: The order of convolution operation does not matter. A series of Masks can be convolved first before making final convolution with an Image.*\n\nWhat about Cross-convolution?","b13177b1":"Here, unfortunately, NumPy beats us on Matrix multiplication. 2D convolution is a single-pass code, but tedious. 1D convolution is a two-pass code but mathematically simple. In the above processes, NumPy uses a highly-optimized method to do high-dimensional matrix multiplication efficiently. Hence, more time is spent with separable filters but not with 2D filter. Our complexity claim can be proved if use a naive-for-loop to iterate over rows and columns to do matrix multiplication.\n\nPython libraries and frameworks such as NumPy, TensorFlow, PyTorch and SciPy are using their best optimization algorithms such as Fast Fourier Transforms, BLAS wherever possible to do efficient processing.\n\nOkay. Let's return back to our separable filters. Are both the results same?","9203d098":"**Distributive Property**\n\na ~ (b + c) = (a ~ b)+ (a ~ c)\n\nIt states that two filters (of same shape) can be added together and then convolved with the image. Or, alternatively, the image can be convolved with two filters separately and then added together to achieve the same result.","e60bbe7e":"Now, what are the sizes of our image and mask?","680f4f7b":"## 7. Edge Filter","ac820721":"That's remarkable! Cross-correlation fulfills scalar property.","aab27bec":"Correlation is the process of manipulating two images by overlapping each other. In Cross-correlation, one image is specifically called *image* and the another is called *filter \/ mask \/ kernel* in the computer vision domain. The Manipulation here is a simple dot product between the image and the filter. If the filter size is different from the image size, the filter is slided over the image window-by-window to cover each and every pixel of image (and filter). The pixel values of filter are called *filter coefficients*. Since the filter coefficients DO NOT vary during window-sliding operation, this process can be generally termed *LINEAR FILTERING.*","9df3716c":"Moving average filter is also known as Box filter or Blurring filter or Smoothing filter. It is a square filter of size usually 3, 5, or 7. The pixel values of the filter are equal by value. This filter smoothens the input image and removes high-frequency edges from the image. Hence this filter comes under the category of low-pass filters. \n\nA low-pass filter allows low-frequency elements while filtering out high-frequency elements. A high-pass filter does a job quite opposite to that of a low-pass filter.","1a342079":"Cross-correlation is NOT commutative! ","85b80cbe":"Gaussian filter is also a low-pass smoothing filter, but it could retain some minor details unlike a moving-average filter. It gives more weightage to central pixel and as the distance goes on, weightage is NORMALLY fallen down. Gaussian filter is widely used in digital camera \/ image processing industry to remove certain noises, to do downsampling and upsampling, and to do anti-alaising. ","3d7aeda1":"Datasets Used:\n\n1. [Tea Time - Kaggle Dataset](https:\/\/www.kaggle.com\/rajkumarl\/tea-time)\n\n2. [People Clothing Segmentation - Kaggle Dataset](https:\/\/www.kaggle.com\/rajkumarl\/people-clothing-segmentation)\n\nReferences:\n\n1. [Computer Vision: Algorithms and Applications, 2nd ed. - Richard Szeliski Textbook](https:\/\/szeliski.org\/Book\/)\n\n2. [Deep Learning for Computer Vision - NPTEL Course](https:\/\/nptel.ac.in\/courses\/106\/106\/106106224\/)\n\n3. [Cross-correlation vs Auto-correlation - Tutorial](https:\/\/www.statisticshowto.com\/cross-correlation\/)\n\n4. [Gaussian Filter - Wiki](https:\/\/en.wikipedia.org\/wiki\/Gaussian_blur)","b1405a52":"Auto-correlation is the process of correlating an image with itself. Hence the image becomes the mask!","a9e64544":"#### --------------------------------------------------\n#### *Articles So Far In This Series*\n#### -> [[Computer Vision] Basic Image Processing](https:\/\/www.kaggle.com\/rajkumarl\/computer-vision-basic-image-processing)\n#### -> [[Computer Vision] Linear Filtering](https:\/\/www.kaggle.com\/rajkumarl\/computer-vision-linear-filtering)\n#### --------------------------------------------------","6ec8b83b":"**Impulse Property**\n\ne ~ a = a\n\nwhere a refers to an image and e refers to an impulse function (can be 1D, 2D, or 3D)","b264229f":"## 4. Properties of Convolution","360434df":"Yes. Convolution satisfies Impulse property. Input image resembles the output image.\n\nDoes Cross-Correlation satisfy this property?","42514b37":"Great! Scalar multiplications do impose no effect on convolution process.\n\nWhat about cross-correlation?","c28f7e1f":"## 8. Separable Filters\n\nComputer Vision has found a drastic growth in recent times thanks to great compute capacities nowadays. However, the computation complexity should be kept as minimal as possible to handle resources efficiently. In this context, filters that are 'separable' must be broken down into smaller-dimensional vectors, convolved separately, and merged finally. \n\nFor instance, the moving average filter, Gaussian filter, edge filter that we have discussed above are all separable filters. These 2D filters can be broken down into two 1D filters such that the outer product of the 1D filter may result in the 2D filters.\n\nTime complexity in 2D filter convolution \n= O(image_width * image_height * filter_width * filter_height)\n\nTime complexity in 1D filter convolution \n= O(image_width * image_height * filter_width)\n\nLet's analyze time taken for convolution with 2D and 1D filters to attain same results.","ec36f227":"Convolution is a process alike cross-correlation except that the mask is double-flipped before processing. Convolution has some good mathematical properties over cross-correlation that makes it preferrable for certain image processing tasks. While convolving an image with a mask, the image may be padded with zeros or something to vary the output shape. \nThere are 3 possible types of padding:\n1. Valid Padding: If there is no padding, the return shape will be lesser than the original image shape. \nReturn shape  = original shape  - mask shape + 1\n2. Same Padding: If the image is padded such that the output shape is same as the input, it is called same padding.\nReturn shape = original shape\n3. Full Padding: If the image is fully padded such that each element of mask is convolved with each element of the image, the output shape will be bigger than the original image.\nReturn shape = original shape + mask shape - 1","ed7c113c":"Cross-correlation is not associative!"}}