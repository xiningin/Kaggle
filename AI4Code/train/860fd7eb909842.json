{"cell_type":{"f57838fe":"code","b380c40f":"code","34c95d03":"code","b772dbad":"code","b5dcc102":"code","f716ba50":"code","24f5ee66":"code","76a11ac7":"code","872533af":"code","e98b6ccd":"code","c92d76ff":"code","4f647524":"code","01b715ed":"code","d9642e29":"code","92e83867":"code","e15159a9":"markdown","7ee71c14":"markdown"},"source":{"f57838fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b380c40f":"df = pd.read_csv(r'\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv(r'\/kaggle\/input\/digit-recognizer\/test.csv')\ndf.head()","34c95d03":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","b772dbad":"x_train, x_test, y_train, y_test = train_test_split(df.drop('label', axis = 1), df['label'], test_size = 0.2)","b5dcc102":"# Let's print the shape of data after train test split\nx_train.shape, x_test.shape","f716ba50":"x_train = np.array(x_train).reshape(x_train.shape[0], 28, 28, 1)\nx_test = np.array(x_test).reshape(x_test.shape[0], 28, 28, 1)\n\ntest_array =  np.array(test).reshape(test.shape[0], 28, 28, 1)","24f5ee66":"x_train = x_train \/ 255.0\n\nx_test = x_test \/ 255.0\n\ntest_array = test_array \/ 255.0\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\ntest_array = test_array.astype('float32')","76a11ac7":"#Convert class vector to binary class matrices, It's simply like a one hot encoding\ny_train = keras.utils.to_categorical(y_train, 10)\n\ny_test = keras.utils.to_categorical(y_test, 10)","872533af":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.Convolution2D(20, (5,5), activation = 'relu', input_shape = (28, 28, 1)))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n\nmodel.add(keras.layers.Convolution2D(50,(5,5), activation = 'relu'))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(200, activation = 'relu'))\nmodel.add(keras.layers.Dense(10, activation = 'softmax'))\n","e98b6ccd":"model.summary()","c92d76ff":"model.compile(\n    loss = keras.losses.categorical_crossentropy,\n    optimizer = keras.optimizers.Adam(),\n    metrics = ['accuracy'])","4f647524":"history = model.fit(x_train, y_train, \n                   epochs = 12 , \n                   verbose = True,\n                    batch_size= 32,\n                   validation_split= 0.95)","01b715ed":"model.evaluate(x_test, y_test)","d9642e29":"pred = model.predict(test_array)","92e83867":"sub = pd.DataFrame()\nsub['ImageId'] = np.arange(1 , len(test)+1, 1)\nsub['Label'] = np.argmax(pred, axis = 1)\nsub.to_csv('.\/Submission.csv', index = False)","e15159a9":"We are going to split data with test size 20%","7ee71c14":"* To pass to our model we need to change the shape of our dataset"}}