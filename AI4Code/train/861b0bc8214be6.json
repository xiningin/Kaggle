{"cell_type":{"83989e4e":"code","d1552be3":"code","4bc7b68d":"code","a2a27dfc":"code","0787bc3a":"code","287d98f6":"code","2d97e4f3":"code","795ee9cc":"code","b7de341f":"code","042886a5":"code","aa9d35ae":"code","af316167":"code","5c028515":"code","ab52bdbe":"code","c5e45186":"code","aeafb7ee":"code","aa7eff1a":"code","39a48699":"code","c9d7a87f":"code","dec332e2":"code","1750200f":"code","e1872d20":"code","3f7a5f61":"code","917c7521":"code","e9aaabb0":"code","6ff97033":"code","0ab8d5db":"code","75ad62cc":"code","9af21a6f":"code","8bc98e14":"code","fbf188b2":"code","50c2e170":"code","6d6801af":"code","57f794c9":"code","ebc62218":"code","2e64861c":"code","0c376209":"code","9fc1fc6d":"code","3371c3cb":"code","dc44c746":"code","c8320139":"code","4706a0ed":"code","1324ae4f":"code","c017d2de":"code","baa67357":"code","4fa8674d":"code","57a8e79a":"markdown","2f69508b":"markdown","5b9a0f7b":"markdown","b0021985":"markdown","cc449d96":"markdown","c26df01c":"markdown","6810a0f8":"markdown","863f3dce":"markdown","057e4872":"markdown","98bc2bbf":"markdown","9cc143fd":"markdown","d87c8821":"markdown","296b9710":"markdown"},"source":{"83989e4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n%matplotlib inline","d1552be3":"train_data = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\ntest_data = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\n","4bc7b68d":"print(train_data.shape)\nprint(test_data.shape)","a2a27dfc":"train_data.columns","0787bc3a":"test_data.columns","287d98f6":"train_data.info()","2d97e4f3":"train_data.head()","795ee9cc":"tr_data = train_data.copy()\ntr_data = pd.get_dummies(tr_data, drop_first=True)\ntr_data.head()","b7de341f":"tr_data.shape","042886a5":"cols = tr_data.columns[1:15]\ncols","aa9d35ae":"fig, ax = plt.subplots(len(cols), figsize=(8,55))\nfig.subplots_adjust(hspace=1)\nfor i, c in enumerate(cols):\n    ax[i].scatter(tr_data[c], tr_data['SalePrice'])\n    ax[i].set_yticks(range(0, tr_data['SalePrice'].max(), 100000))\n    #ax[i].grid()\n    ax[i].set_title(c)\nplt.show()","af316167":"tr_data.describe()","5c028515":"#ax1=sns.boxplot(y='MSSubClass', data=tr_data)\nfig, ax = plt.subplots(len(cols[1:]),1, figsize=(6,30))\nfig.subplots_adjust(hspace=1)\nfor i, col in enumerate(cols[1:]):\n    plt.sca(ax[i])\n    #plt.figure(i)\n    sns.set(style=\"whitegrid\")\n    sns.boxplot(x=col, data=tr_data)\n    #.swarmplot(x=col, data=tr_data, color=\"gray\")    ","ab52bdbe":"fig, bx = plt.subplots(len(cols[1:]),1, figsize=(6,30))\nfig.subplots_adjust(hspace=1)\nfor i, col in enumerate(cols[1:]):\n    plt.sca(bx[i])\n    #plt.figure(i)\n    sns.set(style=\"whitegrid\")\n    sns.violinplot(x=col, data=tr_data, color='0.3')\n    #sns.swarmplot(x=col, color=\"k\", size=3, data=tr_data, ax = v.ax);","c5e45186":"outliers = []\n\n\n\noutliers.extend(tr_data[tr_data['OverallQual']==10][tr_data['SalePrice']<200_000].index.tolist())\noutliers.extend(tr_data[tr_data['LotArea']>100_000].index.tolist())\noutliers.extend(tr_data[tr_data['LotFrontage']>300].index.tolist())\noutliers.extend(tr_data[tr_data['YearBuilt']<1900][tr_data['SalePrice']>200_000].index.tolist())\noutliers.extend(tr_data[tr_data['YearRemodAdd']<2000][tr_data['SalePrice']>600_000].index.tolist())\noutliers.extend(tr_data[tr_data['MasVnrArea']==1600].index.tolist())\noutliers.extend(tr_data[tr_data['TotalBsmtSF']>3000][tr_data['SalePrice']<300_000].index.tolist())\noutliers.extend(tr_data[tr_data['1stFlrSF']>2700][tr_data['SalePrice']<500_000].index.tolist())\noutliers.extend(tr_data[tr_data['BsmtFullBath']==3.0].index.tolist())\noutliers.extend(tr_data[tr_data['GrLivArea']>3300][tr_data['SalePrice']<300_000].index.tolist())\noutliers.extend(tr_data[tr_data['FullBath']==0.0][tr_data['SalePrice']>300_000].index.tolist())\noutliers.extend(tr_data[tr_data['GarageArea']>1200][tr_data['SalePrice']<200_000].index.tolist())\noutliers.extend(tr_data[tr_data['OpenPorchSF']>500].index.tolist())\n\n","aeafb7ee":"outliers=np.unique(outliers)\nprint(outliers)\nprint(len(outliers))","aa7eff1a":"train_data.drop(outliers, axis=0, inplace=True)\ny = train_data['SalePrice']\ntrain_data.shape","39a48699":"df = pd.concat([train_data.drop(['SalePrice'], axis=1), test_data], join='outer')\ndf.drop(['Id'], axis=1)\ndf.shape","c9d7a87f":"df.MSSubClass.isna().sum()","dec332e2":"isEmpty = [x for x in df if df[x].isna().sum() != 0]\nprint(isEmpty)\n\ndata_float=[]\ndata_int = []\nfor x in isEmpty:\n    if df[x].dtype == 'float64':\n        print(x)\n        data_float.append(x)\n    if df[x].dtype == 'int64':\n        print(x)\n        data_int.append(x)\n\nprint(len(isEmpty))        \nprint(len(data_float))\nprint(len(data_int))","1750200f":"to_mode = [\n    'MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'Electrical', 'KitchenQual', 'Functional',\n    'SaleType', 'LotFrontage'\n]\n\nto_none = [\n    'Alley', 'MasVnrType', 'BsmtQual', 'BsmtExposure', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', \n    'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n    'MiscFeature'\n]\n\nto_zero = [\n    'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n    'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea'\n]","e1872d20":"for x in to_mode:\n    df[x+'for_na'] = df[x].apply(lambda a:0 if pd.isnull(a)==True else 1)\n    df[x] = df[x].fillna(df[x].mode()[0])\n    \ndf.shape","3f7a5f61":"for x in to_zero:\n    df[x+'for_na'] = df[x].apply(lambda a:0 if pd.isnull(a)==True else 1)\n    df[x] = df[x].fillna(df[x].mean())\nfor x in to_none:\n    df[x+'for_na'] = df[x].apply(lambda a:0 if pd.isnull(a)==True else 1)\n    df[x] = df[x].fillna('None')\n    \ndf.shape","917c7521":"df.isna().sum().sum()","e9aaabb0":"train_data.corr()[-1:]","6ff97033":"cols_to_drop = [ 'YrSold', 'MoSold', 'BsmtHalfBath', 'BsmtFinSF2', 'KitchenAbvGr',\n                'LowQualFinSF', 'BedroomAbvGr', '3SsnPorch', \n               ]\n","0ab8d5db":"train_data.corr()[-1:][cols_to_drop]","75ad62cc":"df.drop(cols_to_drop, axis=1, inplace=True)","9af21a6f":"df.shape","8bc98e14":"df = pd.get_dummies(df)\nprint(df.isna().sum().sum())\ndf.head(1)","fbf188b2":"df.shape","50c2e170":"X = df[:train_data.shape[0]]\ntrain = df[:train_data.shape[0]]\ntest = df[train_data.shape[0]:]","6d6801af":"train.shape, test.shape","57f794c9":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_absolute_error, r2_score\nfrom xgboost import XGBRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor","ebc62218":"X = StandardScaler().fit_transform(X)\ntest = StandardScaler().fit_transform(test)\nX.shape","2e64861c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)","0c376209":"#Ridge\nparams = {\n    'alpha': [25, 35],\n    'max_iter': [None, 1000, 5000],\n    'solver': ['svd', 'lsqr', 'sag', 'saga', 'sparse_cg', 'sparse_cg']\n}\n\nM1 = GridSearchCV(\n    Ridge(),\n    scoring='neg_mean_absolute_error',\n    param_grid=params,\n    cv=3,\n    n_jobs=-1,\n    verbose=1\n)\nM1.fit(X, y)\n\nprint(M1.best_estimator_)\n\nmean_absolute_error(y_test, M1.predict(X_test))","9fc1fc6d":"# Lasso\nparams = {\n    'alpha': [0.1, 1, 3],\n    'max_iter': [50000],\n}\n\nM2 = GridSearchCV(\n    Lasso(),\n    scoring='neg_mean_absolute_error',\n    param_grid=params,\n    cv=3,\n    n_jobs=-1,\n    verbose=1\n)\n\nM2.fit(X, y)\nprint(M2.best_estimator_)\n\nmean_absolute_error(y_test, M2.predict(X_test))","3371c3cb":"# SVC\nparams = {\n    'kernel': ['rbf', 'sigmoid', 'linear'],\n    'C'  : [0,0.5,1,4],\n    'gamma' : [None, 0.01, 0.1, 1, 3]  \n}\n\nM4 = GridSearchCV(\n    SVR(),\n    scoring='neg_mean_absolute_error',\n    param_grid=params,\n    cv=3,\n    n_jobs=-1,\n    verbose=1\n)\n\nM4.fit(X, y)\nprint(M4.best_estimator_)\n\nmean_absolute_error(y_test, M4.predict(X_test))","dc44c746":"#Gradient Boost\nparams = {\n    'n_estimators': [500],\n    'learning_rate': [0.01, 0.03, 0.1, 1],\n    'loss': ['ls'],\n}\n\nM5 = GridSearchCV(\n    GradientBoostingRegressor(),\n    scoring='neg_mean_absolute_error',\n    param_grid=params,\n    cv=3,\n    n_jobs=-1,\n    verbose=1\n).fit(X,y)\n\nprint(M5.best_estimator_)\n\nmean_absolute_error(y_test, M5.predict(X_test))","c8320139":"# XG boost\nparams = {\n    'learning_rate': [0.003, 0.01],\n    'n_estimators': [3000, 4000],\n    'max_depth': [2, 3],\n    'min_child_weight': [0, 1],\n    'gamma': [0],\n    'subsample': [0.5, 0.7],\n    'colsample_bytree':[0.5, 0.7],\n    'objective': ['reg:squarederror'],\n    'scale_pos_weight': [1, 2],\n    'reg_alpha': [0.00001, 0.001]\n}\n\nM6 = GridSearchCV(\n    XGBRegressor(),\n    scoring='neg_mean_absolute_error',\n    param_grid=params,\n    cv=3,\n    n_jobs=-1,\n    verbose=1\n).fit(X,y)\n\nprint(M6.best_estimator_)\n\nmean_absolute_error(y_test, M6.predict(X_test))","4706a0ed":"final_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.01, max_delta_step=0, max_depth=3,\n             min_child_weight=0, monotone_constraints='()',\n             n_estimators=3000, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n             tree_method='exact', validate_parameters=1, verbosity=None)\n\nfinal_model.fit(X,y)\nmean_absolute_error(y_test, final_model.predict(X_test))","1324ae4f":"preds = final_model.predict(test)\ntest.shape","c017d2de":"preds","baa67357":"submit_file = pd.read_csv('..\/input\/home-data-for-ml-course\/sample_submission.csv')\nsubmit_file['SalePrice'] = preds\nsubmit_file.to_csv('submission.csv', index=False)","4fa8674d":"submit_file","57a8e79a":"## __Limiting the outliers value__","2f69508b":"## __Finding the columns contains nan value__","5b9a0f7b":"## Reference:\n> ```House Prices Competition Kernel (top 3%)```  \n","b0021985":"### __Plotting the date from first 15 columns__","cc449d96":"## **__Description of the data__**","c26df01c":"## __Boxplot for finding outliers__","6810a0f8":"### __Checking the traning & testing dataframe columns__","863f3dce":"## __Dropping the rows which contains outlier values__","057e4872":"## __Define the best model & predicts the result__","98bc2bbf":"## __Applying Machine Learning algorithms__","9cc143fd":"### __Info regrading the dataframe__","d87c8821":"## __Dropping the less important features__","296b9710":"## __Handling the null values__"}}