{"cell_type":{"3a1936ae":"code","71554521":"code","5219892f":"code","d30f3f6d":"code","8ad16a62":"code","ed856139":"code","33ea396f":"code","cde2c0b1":"code","a3472df6":"code","d07f83b5":"code","5fe2c96e":"code","b2722d0e":"code","376a98d7":"code","351f9e12":"code","5d7f0c97":"code","02e017d3":"code","505a28b2":"code","533ec7e3":"code","90d2efdd":"code","667a5d5c":"code","a9111803":"code","f5e1e1d9":"markdown","e5b02f33":"markdown","60e80e69":"markdown","0b826804":"markdown","035ee122":"markdown","7863bb59":"markdown","0ab61623":"markdown","54f96172":"markdown","7053da54":"markdown","e0e91d22":"markdown","e601f6fc":"markdown","746ecc0a":"markdown","84714319":"markdown","a056f459":"markdown","e34fc4d9":"markdown","082cd9df":"markdown","58bfb907":"markdown","7251d903":"markdown","6c9848a3":"markdown","75240c80":"markdown","38f1524d":"markdown","3b2558d7":"markdown","9b61067b":"markdown","960d6b8e":"markdown","4d2ec50e":"markdown","3ac05a8c":"markdown","7e2d84f9":"markdown","a27db416":"markdown","6eef9d2c":"markdown","5786c662":"markdown","75a8f012":"markdown"},"source":{"3a1936ae":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)v\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns\n\nfrom keras.datasets import cifar10 # CIFAR-10 dataset\nfrom keras.utils import np_utils, plot_model # np_utils is used to do one-hot encoding\nfrom keras.optimizers import Adam # adam optmizer\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation, BatchNormalization # layers used in the neural network\nfrom keras.regularizers import l2 # l2 regularizer\nfrom keras.models import Sequential, load_model # the model used has the Sequential structure\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n","71554521":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()\nlabels = pd.read_csv('\/kaggle\/input\/cifar-10\/trainLabels.csv')","5219892f":"# Datasets shapes\nprint('Train dataset shape: {}'.format(X_train.shape))\nprint('Test dataset shape: {}'.format(X_test.shape))","d30f3f6d":"print('Amount of images in each class of the training dataset:')\nprint(labels.label.value_counts())","8ad16a62":"# Getting a dictionary with 3 images indexes for each label\nlabels_dict = {}\nfor label in labels.label.unique():\n    labels_dict[label] = list(labels[labels['label'] == label].index[0:3])\n    \n# Showing 3 images of every class\nfor key in labels_dict:\n    for i in range(3):\n        plt.subplot(330+ 1 + i)\n        plt.imshow(X_train[labels_dict[key][i]])\n    print('Class {}'.format(key))\n    plt.show()\n","ed856139":"# Initializing a ImageDataGenerator Objetc\nimage_data_generator = ImageDataGenerator(\n                rotation_range = 15, # degree angle for random rotations\n                horizontal_flip = True, # randomly flips the image horizontally\n                width_shift_range = 0.1, # fraction of total width shift\n                height_shift_range = 0.1 # fraction of total height shift\n                )\n\n# Fitting the Image Data Generator for the training images\n\nimage_data_generator.fit(X_train)","33ea396f":"training_generator = image_data_generator.flow(X_train, y_train, batch_size = 6)","cde2c0b1":"plt.figure(figsize=(10,5))\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    for x,y in training_generator:\n        plt.imshow(x[i].astype(np.uint8))\n        plt.axis('off')\n        break\nplt.tight_layout()\nplt.show()","a3472df6":"# Transform the data type to float 32 to performe the divison operation \nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n# Functions from numpy to calculate mean and std\nmean = np.mean(X_train)\nstd = np.std(X_train)\n\n# Applying the z-score\n\nX_train = (X_train-mean)\/(std+1e-7)\nX_test = (X_test-mean)\/(std+1e-7)","d07f83b5":"# every image has the same input_shape\ninput_shape = (32,32,3)\n\n# number of classes in the CIFAR-10\nn_classes = 10\n\n# applying the one-hot encoding\ny_train = np_utils.to_categorical(y_train,n_classes)\ny_test = np_utils.to_categorical(y_test,n_classes)","5fe2c96e":"def model():\n    # L2 \u03bb = 0.0005\n    regularizer = l2(0.0005)\n    \n    model = Sequential()\n    \n    model.add(Conv2D(32, (3,3), activation = 'relu', kernel_regularizer = regularizer, input_shape = input_shape, padding = 'same'))\n    model.add(BatchNormalization(axis = -1))\n    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    model.add(BatchNormalization(axis = -1))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    model.add(Dropout(0.1))\n    \n    model.add(Conv2D(64, (3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    model.add(BatchNormalization(axis = -1))\n    model.add(Conv2D(64,(3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    model.add(BatchNormalization(axis = -1))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    model.add(Dropout(0.1))\n    \n    model.add(Conv2D(128, (3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    model.add(BatchNormalization(axis = -1))\n    model.add(Conv2D(128,(3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    model.add(BatchNormalization(axis = -1))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    model.add(Dropout(0.1))\n    \n\n    \n    model.add(Flatten())\n    model.add(Dense(512, activation = 'relu', kernel_regularizer = regularizer))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(n_classes, activation = 'softmax'))\n    \n    return model\n    \nmodel = model()\n# Using keras Adam optimizer\nAdamOpt = Adam(lr = 0.0003)\n\nmodel.compile(optimizer = AdamOpt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel.summary()\n    \n    ","b2722d0e":"def comparison_model():\n    # No Regularizer\n    regularizer = None\n    \n    model = Sequential()\n    \n    model.add(Conv2D(32, (3,3), activation = 'relu', kernel_regularizer = regularizer, input_shape = input_shape, padding = 'same'))\n    # No batch normalization\n    #model.add(BatchNormalization(axis = -1))\n    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    #model.add(BatchNormalization(axis = -1))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    \n    # No dropout\n    #model.add(Dropout(0.1))\n    \n    model.add(Conv2D(64, (3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    #model.add(BatchNormalization(axis = -1))\n    model.add(Conv2D(64,(3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    #model.add(BatchNormalization(axis = -1))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    #model.add(Dropout(0.1))\n    \n    model.add(Conv2D(128, (3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    #model.add(BatchNormalization(axis = -1))\n    model.add(Conv2D(128,(3,3), activation = 'relu', kernel_regularizer = regularizer, padding = 'same'))\n    #model.add(BatchNormalization(axis = -1))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    #model.add(Dropout(0.1))\n    \n\n    \n    model.add(Flatten())\n    model.add(Dense(512, activation = 'relu', kernel_regularizer = regularizer))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.5))\n    model.add(Dense(n_classes, activation = 'softmax'))\n    \n    return model\n    \ncomparison_model = comparison_model()\n# Using keras Adam optimizer\nAdamOpt = Adam(lr = 0.001)\n\ncomparison_model.compile(optimizer = AdamOpt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    ","376a98d7":"# CallBack functions\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n\n# Training history\nhistory = model.fit(image_data_generator.flow(X_train,y_train, batch_size = 200), steps_per_epoch = len(X_train)\/200, epochs = 200, validation_data = (X_test,y_test), callbacks=[es, mc])\n\n","351f9e12":"# load the saved model\nsaved_model = load_model('best_model.h5')","5d7f0c97":"# CallBack functions\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=117)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n\n# Training history\n# 117 = number of epochs of the first model\ncomparison_history = comparison_model.fit(X_train, y_train, batch_size = 200, verbose = 1, epochs = 117, validation_data = (X_test,y_test), callbacks=[es, mc])\n","02e017d3":"def plotmodelhistory(history): \n    fig, axs = plt.subplots(1,2,figsize=(15,7)) \n    # summarize history for accuracy\n    axs[0].plot(history.history['accuracy']) \n    axs[0].plot(history.history['val_accuracy']) \n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['train', 'validate'], loc='upper left')\n    # summarize history for loss\n    axs[1].plot(history.history['loss']) \n    axs[1].plot(history.history['val_loss']) \n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['train', 'validate'], loc='upper left')\n    plt.show()\n\n# list all data in history\n\nplotmodelhistory(history)","505a28b2":"plotmodelhistory(comparison_history)","533ec7e3":"max_val_acc = max(history.history['val_accuracy'])\nmax_train_acc = max(history.history['accuracy'])\n\nmin_val_loss = min(history.history['val_loss'])\nmin_train_loss = min(history.history['loss'])\n\nprint('Validation set: \\nAccuracy: {}\\nLoss: {}'.format(max_val_acc,min_val_loss))\nprint()\nprint('Train set: \\nAccuracy: {}\\nLoss: {}'.format(max_train_acc,min_train_loss))\n","90d2efdd":"# Get the predictions probabilities\npredictions = model.predict(X_test)\n\n# Get the true predictions\ny_predictions = np.argmax(predictions, axis=1)\n\n# Remove the one-hot encoding from the test label\ny_true = np.argmax(y_test, axis=1)\n\n\n# Getting the confusion matrix\ncm = confusion_matrix(y_true, y_predictions)\n\n# Transform to DataFrame and change the names of indexes and columns\ncm = pd.DataFrame(cm)\n\ncm.rename(columns={0:'Airplane',\n                  1: 'Automobile',\n                  2: 'Bird',\n                  3: 'Cat',\n                  4: 'Deer',\n                  5: 'Dog',\n                  6: 'Frog',\n                  7: 'Horse',\n                  8: 'Ship',\n                  9: 'Truck'\n                        }, \n                 inplace=True)\ncm.rename(index={0:'Airplane',\n                  1: 'Automobile',\n                  2: 'Bird',\n                  3: 'Cat',\n                  4: 'Deer',\n                  5: 'Dog',\n                  6: 'Frog',\n                  7: 'Horse',\n                  8: 'Ship',\n                  9: 'Truck'\n                        }, \n                 inplace=True)","667a5d5c":"# Set the width and height of the figure\nplt.figure(figsize=(14,7))\n\n# Add title\nplt.title(\"Confusion matrix\")\n\n# Heatmap showing \nsns.heatmap(data=cm, annot=True, fmt=\"d\", linewidths=.5, cmap=\"YlGnBu\")\n\n# Add label for horizontal axis\nplt.xlabel(\"Predicted Label\")\nplt.xlabel(\"True Label Label\")\n\nplt.show()","a9111803":"print(classification_report(y_true, y_predictions))","f5e1e1d9":"We can use the class ImageDataGenerator from Keras to easily generate new training images from the CIFAR-10 dataset.","e5b02f33":"**3.4 Regularization**\n\nRegularization is a technique used to penalize complex models. Instead of simply aiming to minimize the loss function, we try to minimize the loss + complexity, witch is called structural risk minimization. The two most commom regularization functions are L1 and L2 regularization.\n\nThe L1 regularization adds the absolute value of magnitude of each coefficient in the neural network as penalty term to the loss function. The L2 function, instead, adds the squared magnitude of the coefficients as the penalty term.\n\nThe key difference between these techniques is that Lasso shrinks the less important feature\u2019s coefficient to zero thus, removing some feature altogether\n\n\n","60e80e69":"# 3. Tools Used","0b826804":"**6.2 Confusion Matrix**\n\nThe confusion matrix allows us to observe the predictions that were made correctly, as well as false positives and false negatives. The confusion matrix for the developed model is shown below.","035ee122":"Max pooling is a very commom operation in Machine Learning projects because it helps to make the representation approximately invariant to small changes of the input. This means that if we change the input by a small amount, the values of most of the pooled outputs do not change. Invariance to local changes can be a very useful property if we are more interested about wheter some feature is present then about where it is.\n\nBy applying pooling between separately parametrized convolutions, the model can learn to witch transformations it can become invariant to. For example, the model can become invariant to rotations apllied to the images. Max pooling helps prevent overfitting by providing an abstracted form of representation, as well as reducing the computational cost of the model.","7863bb59":"**3.1 Data Augmentation**\n\nData Augmentation is a commom technique used in Machine Learning projects to increase the amount of data applied in the training using the available data. In generating ew copies of training data, it's possibler to increase the generality of the model, thus reducing overfitting. When used in images, the most commom methods of data augmentation are rotation, zooming, height and width shifting, vertical and horizontal flipping, stretching, among others.","0ab61623":"# 2. Importing Data from CIFAR-10\n\n","54f96172":"# **7. Conclusions**","7053da54":"By looking at the amount of images in each class of the training dataset, we can determine a baseline accuracy, given by a model that always guesses a certain class. The value of this accuracy is given by 5000 \/ (10 * 5000) = 10%.\n\nSome of the images of each class is shown below.","e0e91d22":"# 5. Training the Neural Network","e601f6fc":"The classification report allows us to observe the other evaluation metrics for each of the classes: precision, recal F1-score and support.","746ecc0a":"The neural network has the Sequential type. This means that every layer is connected to the next in a unilateral sequence. The model architecture was developed through an iterative process. Like the hyperparameters, the chosen architecture strongly impacts the performance of the model. The neural network has 6 convolutional layers, a dense layer and a final classification layer. Max pooling, dropout and batch normalization operations are performed between some of these layers. The model architecture is illustrated below.\n\n* First, we have a convolutional layer with 32 neurons and the activation function ReLu (Rectified Linear Unit). This is a typical number of neurons, just as the activation function is also widely used in neural networks. The size of the kernel filter is 3x3 and was chosen according to the size of the input image. Then, the output of this layer is normalized by a Batch Normalization layer\n\n* The next layer repeats the pattern of the first, with the same number of neurons, the same size of the kernel filter and a layer of batch normalization in the output. Then, a Max Pooling operation is applied, which reduces the data dimensions to 16x16. A 10% dropout is then applied to avoid overfitting. This value was determined by an iterative process.\n\n* The next layers repeat the structure of the first two, changing only the number of neurons used. The number of neurons doubles every two layers. Meanwhile, the size of the data halves with each layer of Max Pooling\n\n* Finally, a Flatten layer is added, followed by a dense layer of 512 neurons. Batch normalization is performed again and a 50% dropout is added. The classification layer has the softmax activation function\n\n","84714319":"# **6. Results**\n\n**6.1 Accuracy over epochs**\n\nFrom the history obtained in the training process, we can plot graphs of the loss function and the accuracy of the training set and the test set over the epochs. We can see that the comparison model has a performance far inferior to the proposed model. In addition, we can see a big reduction in overfitting when implementing the techniques described in section 3.\n","a056f459":"First, we import the necessary libraries. The CIFAR-10 dataset can be found on the keras.datasets.","e34fc4d9":"# 1. Introdu\u00e7\u00e3o\n\n\nInspired by the way the human brain works as described by neuroscience in the 1960s, Artificial Intelligence scientists developed Artificial Neural Networks. These networks are based on artificial neurons, which can be described by input parameters, an activation function and output weights. Since the creation of such technology, researchers have become increasingly interested in these networks, particularly for their ability to perform distributed computing and to be able to learn rather complex functions. Currently, Artificial Neural Networks are one of the most popular and effective ways of implementing machine learning.\n\nConvolutional Neural Networks, in their turn, are a special type of Neural Networks specialized in processing data that have a matrix topology, for example, time series, audio data and, especially, images. The name of this type of network already indicates that it implements a special type of mathematical operation: convolution. Among the reasons for using these networks, instead of the conventional Neural Networks, we can highlight: the sparse interactions and the sharing of parameters. These two characteristics allow Convolutional Neural Networks to use less memory for training their learning function, in addition to using less time complexity.\n\nWithin this context, this work proposes to use the Convolutional Neural Networks to perform the image prediction of the [CIFAR-10](https:\/\/www.kaggle.com\/c\/cifar-10) data set. It is a dataset with 50,000 training images, divided into 10 classes. Using techniques such as Data Augmentation, MaxPooling, Dropouts, Batch Normalization and L2 Regularization, it was possible to avoid common problems such as Overfitting and achieve a prediction accuracy of up to 88.85%.\n\n\n","082cd9df":"****3.3 Dropouts****\n\nDropout is a very simple, popular and useful technique to combat the overfitting of models. Dropout works by ignoring randomly chosen nodes or convolutions for briefs parts of training. Specifically it makes each convolution or node find information that is useful for prediction in its own right, rather than allowing one node to dominate the prediction. This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In effect, each update to a layer during training is performed with a different \u201cview\u201d of the configured layer.\n\nDropout simulates a sparse activation from a given layer, which interestingly, in turn, encourages the network to actually learn a sparse representation as a side-effect.\n\nThe Dropout Rate is a hyperparameter that must be adjusted. A good rule of thumb is to divide the number of nodes in the layer before dropout by the proposed dropout rate and use that as the number of nodes in the new network. For example, a network with 64 nodes and a dropout rate of 0.5 will require 128 nodes.\n","58bfb907":"A comparison model was also developed. It has the same architecture as the first, however, no batch normalization or dropout layers are added. The purpose of this is to verify how important these tools are to avoid overfitting, in addition to improving the overall performance of the project.","7251d903":"![dropoutExample.png](attachment:dropoutExample.png)","6c9848a3":"![poolingExample.png](attachment:poolingExample.png)","75240c80":"Next, we get the train and test sets using the load_data function from the cifar10 and visualize the size of the datasets, as well as some of its images.","38f1524d":"For training the model, we used two callback functions. The first to perform the early stop (avoiding overfitting) if the loss validation function does not improve after 15 epochs. We also use the keras ModelCheckpoint to save the neural network weights for the best model found in the training process. The number of epochs used was 200. The batch size is one of the hyperparameters to be adjusted. A size of 128 seems adequate for the size of the data set used.\n\nFor training the comparison model, the augmented data set will not be used, according to the procedure described in section 3.1.","3b2558d7":"Next, we can see a few of the images that were generated.","9b61067b":"**6.4 Classification Report**","960d6b8e":"# 4. Creating the Model","4d2ec50e":"* After performing the modeling with the Convolutional Neural Networks and the prediction of the set of tests, an accuracy of 88.85% was obtained. Some reflections about the work, as well as possible improvements are indicated below.\n\n* The optimization of hyper parameters is a big step towards the general optimization of the model. Algorithms that perform such optimization could be applied to improve the overall accuracy of the model, such as a state space search.\n\n\n* We can see that by applying the techniques proposed in section 3, the overfitting has drastically reduced when compared to the comparison model. Although the comparison model has obtained a higher accuracy in the training set, such accuracy is not a valid metric for the evaluation of the model.\n\n* Some classes of similar animals, such as cats and dogs or horses and deers have obtained the highest amount of wrong predictions. This could be fixed with special data augmentation preprocessing for each of these classes.\n","3ac05a8c":"Before defining the model itself, we need to define the number of the classes, define the input shape of the images and apply the one-hot encoding to the labels.","7e2d84f9":"![dataAugm.png](attachment:dataAugm.png)","a27db416":"**3.5 Batch Normalization**\n\nJust as the data is normalized for the input layer, so that the range of values of the features is within a normal pattern, it is also possible to perform such normalization for the deeper layers. This process is called batch normalization. Batch normalization reduces the amount by what the hidden unit values shift around (covariance shift) and allows each layer of a network to learn by itself a little bit more independently of other layers.\n\nTo increase the stability of a neural network, batch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation. However, after this shift\/scale of activation outputs by some randomly initialized parameters, the weights in the next layer are no longer optimal. SGD ( Stochastic gradient descent) undoes this normalization if it\u2019s a way for it to minimize the loss function.\nConsequently, batch normalization adds two trainable parameters to each layer, so the normalized output is multiplied by a \u201cstandard deviation\u201d parameter (gamma) and add a \u201cmean\u201d parameter (beta). In other words, batch normalization lets SGD do the denormalization by changing only these two weights for each activation, instead of losing the stability of the network by changing all the weights.\n\nReference: https:\/\/towardsdatascience.com\/batch-normalization-in-neural-networks-1ac91516821c","6eef9d2c":"The best accuracy for the models developed for the training and validation sets is shown below:","5786c662":"We also would like to apply the z-score normalization to the training and testing datasets. The reason for this is because in the process of training the network, a lot of parameters (weights) are shared. The weights learned in the process are multiplied by the input data in order to cause activations. Ideally, each input in the neural network must have similar range of pixels. If the range of each input is very different, it becomes hard to train the model. Originally, the range of values that the image pixels can assume is between 0 and 225, but by applying the z-score normalization this range drops to between -XXX and YYY. \n\nThe z-score normalization is done accordingly to the following equation:\n\nz = (x - \u03bc)\/\u03c3, \n\nwhere:\n* \u03bc: Mean\n* \u03c3: Standart Deviation","75a8f012":"**3.2 Pooling**\n\nThe pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, max pooling operation reports the maximum output within a rectangular neighborhood."}}