{"cell_type":{"5fcb2b53":"code","3697caff":"code","b32d3d91":"code","b210d952":"code","895671c4":"code","558fa927":"code","0c1cc44a":"code","d48d373f":"code","983f6425":"code","077e7907":"code","dc4aeae4":"code","59040737":"code","89c20ba3":"code","ada4f49a":"code","9040f35d":"code","15f58ab2":"code","4769a08d":"code","330899ab":"code","6f7d4911":"code","632d97e6":"code","bd0497cb":"code","8f5e9a98":"code","deecd290":"code","756a1d0a":"code","8159965c":"code","5b00b165":"code","c98500fb":"code","15ef19be":"code","f234e70c":"code","f3e30056":"code","fdbfbe88":"code","734a981d":"code","69e75a7c":"markdown","f6235eb2":"markdown","68369b90":"markdown","9d1e9f94":"markdown","149de629":"markdown","948e7af5":"markdown","8bdb9be8":"markdown","11a42a1b":"markdown"},"source":{"5fcb2b53":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","3697caff":"data = pd.read_csv('..\/input\/paysim1\/PS_20174392719_1491204439457_log.csv', nrows=50000)","b32d3d91":"data","b210d952":"data.info()","895671c4":"data['isFraud'].value_counts()","558fa927":"{column: len(data[column].unique()) for column in data.columns}","0c1cc44a":"data['type'].unique()","d48d373f":"pd.get_dummies(data['type'], prefix='tp')","983f6425":"data","077e7907":"def onehot_encode(df, column, prefix):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=prefix)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","dc4aeae4":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    \n    # Drop step, nameOrig, and isFlaggedFraud columns\n    df = df.drop(['step', 'nameOrig', 'isFlaggedFraud'], axis=1)\n    \n    \n    # One-hot encode the type column\n    df = onehot_encode(df, column='type', prefix='tp')\n    \n    y = df['isFraud'].copy()\n    X = df.drop('isFraud', axis=1).copy()\n    \n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    \n    # Create a tokenizer and fit it to the customer data\n    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n    tokenizer.fit_on_texts(X_train['nameDest'])\n    \n    print(\"Total # of customers:\", len(tokenizer.word_index))\n    \n    \n    # Create tokenized customer lists\n    customers_train = tokenizer.texts_to_sequences(X_train['nameDest'])\n    customers_test = tokenizer.texts_to_sequences(X_test['nameDest'])\n    \n    \n    # Pad sequences\n    customers_train = tf.keras.preprocessing.sequence.pad_sequences(customers_train, maxlen=1)\n    customers_test = tf.keras.preprocessing.sequence.pad_sequences(customers_test, maxlen=1)\n    \n    \n    # Drop nameDest column\n    X_train = X_train.drop('nameDest', axis=1)\n    X_test = X_test.drop('nameDest', axis=1)\n    \n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n    \n    \n    return X_train, X_test, customers_train, customers_test, y_train, y_test","59040737":"X_train, X_test, customers_train, customers_test, y_train, y_test = preprocess_inputs(data)","89c20ba3":"customers_train","ada4f49a":"X_train","9040f35d":"y_train","15f58ab2":"train_df = pd.concat([X_train, pd.Series(np.squeeze(customers_train), name='customer'), y_train.reset_index(drop=True)], axis=1)","4769a08d":"train_df","330899ab":"train_df['isFraud'].value_counts()","6f7d4911":"print(\"Number of examples to sample:\", 34929 - 71)","632d97e6":"oversampled_data = train_df.query(\"isFraud == 1\").sample(34858, replace=True, random_state=123)","bd0497cb":"oversampled_data","8f5e9a98":"train_df = pd.concat([train_df, oversampled_data], axis=0).sample(frac=1.0, random_state=123).reset_index(drop=True)","deecd290":"train_df","756a1d0a":"train_df['isFraud'].value_counts()","8159965c":"customers_train = train_df['customer'].copy()\ny_train = train_df['isFraud'].copy()\nX_train = train_df.drop(['customer', 'isFraud'], axis=1).copy()","5b00b165":"# Inputs\nX_inputs = tf.keras.Input(shape=(10,), name='X_input')\ncustomer_inputs = tf.keras.Input(shape=(1,), name='customer_input')\n\n# X\nX_dense1 = tf.keras.layers.Dense(64, activation='relu', name='X_dense1')(X_inputs)\nX_dense2 = tf.keras.layers.Dense(64, activation='relu', name='X_dense2')(X_dense1)\n\n# customers\ncustomer_embedding = tf.keras.layers.Embedding(\n    input_dim=21018,\n    output_dim=64,\n    input_length=1,\n    name='customer_embedding'\n)(customer_inputs)\ncustomer_flatten = tf.keras.layers.Flatten(name='customer_flatten')(customer_embedding)\n\n# Concatenate\nconcat = tf.keras.layers.concatenate([X_dense2, customer_flatten], name='concatenate')\n\n# Output\noutputs = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(concat)\n\n\nmodel = tf.keras.Model(inputs=[X_inputs, customer_inputs], outputs=outputs)\n\nprint(model.summary())\ntf.keras.utils.plot_model(model)","c98500fb":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)","15ef19be":"history = model.fit(\n    [X_train, customers_train],\n    y_train,\n    validation_split=0.2,\n    class_weight={\n        0: 0.25,\n        1: 4.0\n    },\n    batch_size=32,\n    epochs=10,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=2,\n            restore_best_weights=True\n        )\n    ]\n)","f234e70c":"results = model.evaluate([X_test, customers_test], y_test, verbose=0)\nprint(\"Test Accuracy: {:.3f}%\".format(results[1] * 100))\nprint(\"     Test AUC: {:.3f}\".format(results[2] * 100))","f3e30056":"y_true = np.array(y_test)\n\ny_pred = np.squeeze(model.predict([X_test, customers_test]))\ny_pred = (y_pred >= 0.5).astype(np.int)\n\n\ncm = confusion_matrix(y_true, y_pred)\nclr = classification_report(y_true, y_pred, target_names=[\"Not Fraud\", \"Fraud\"])","fdbfbe88":"plt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\nplt.xticks(np.arange(2) + 0.5, [\"Not Fraud\", \"Fraud\"])\nplt.yticks(np.arange(2) + 0.5, [\"Not Fraud\", \"Fraud\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","734a981d":"print(\"Classification Report:\\n----------------------\\n\", clr)","69e75a7c":"# Training","f6235eb2":"# Handling Class Imbalance","68369b90":"# Preprocessing","9d1e9f94":"# Modeling","149de629":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/TncDz92WLiY","948e7af5":"# Task for Today  \n\n***\n\n## Mobile Payment Fraud Detection  \n\nGiven *synthetic data about mobile transactions*, let's try to detect the presence of **fraudulent activity**.\n\nWe will use a multi-input TensorFlow neural network to make our predictions. ","8bdb9be8":"# Results","11a42a1b":"# Getting Started"}}