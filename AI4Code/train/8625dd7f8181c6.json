{"cell_type":{"58f2e76d":"code","752473a7":"code","76296e78":"code","633989a3":"code","c226d508":"code","1cd022cd":"code","b7cc6b13":"code","16df4994":"code","258f5f87":"code","a6561c5f":"code","51003df3":"code","4bf50925":"code","86c87206":"code","3768d02d":"code","946a6aff":"code","f9b8f8ce":"code","267a1193":"code","fa0555da":"code","f2f7b706":"code","05a93436":"code","e1030984":"code","94ed2d19":"code","ab350e70":"code","fb2db055":"code","a86dcf00":"code","e1b15d7b":"code","354655b7":"code","2df11871":"code","a1cddd77":"code","796da41d":"code","713b5e48":"code","7c05ca28":"code","1b07802d":"code","ea2fcbcd":"markdown"},"source":{"58f2e76d":"import math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler","752473a7":"df = pd.read_csv(\"..\/input\/Churn_Modelling.csv\")","76296e78":"df.head()","633989a3":"geograpy_onehot = pd.get_dummies(df.Geography)\ndf = df.drop('Geography', axis=1)\ndf = df.join(geograpy_onehot)\n\ngender_onehot = pd.get_dummies(df.Gender)\ndf = df.drop('Gender', axis=1)\ndf = df.join(gender_onehot)\n\nlableenc = LabelEncoder()\ndf.Surname = lableenc.fit_transform(df.Surname)\n\ndf.head()","c226d508":"def split_train_test(dataset):\n    dataset_length = len(dataset.index)\n    train_length = dataset_length*0.8 - 1\n    train = df.loc[:train_length,:]\n    test = df.loc[train_length+1:,:]\n    return train, test","1cd022cd":"train, test = split_train_test(df)","b7cc6b13":"def split_fea_lab(dataset, features_col, labeles_col):\n    features = dataset.loc[:, features_col]\n    labeles = dataset.loc[:, [labeles_col]]\n    return features, labeles","16df4994":"features_col = df.columns\nfeatures_col = features_col.drop(['Exited', 'RowNumber', 'CustomerId'])\nlabels_col = 'Exited'\nfeatures, labels = split_fea_lab(train, features_col, labels_col)\ntest_features, test_labels = split_fea_lab(test, features_col, labels_col)","258f5f87":"scaler = MinMaxScaler()\nfeatures = scaler.fit_transform(features)\ntest_features = scaler.fit_transform(test_features)","a6561c5f":"def reshape_fea_lab(features, labels):\n    features =    features.T\n    labels =      labels.T\n    return features, labels","51003df3":"features, labels = reshape_fea_lab(features, labels)\ntest_features, test_labels = reshape_fea_lab(test_features, test_labels)","4bf50925":"def random_mini_batch(features, labels, mini_batch_size=64, seed=0):\n    m = features.shape[1]\n    mini_batches = []\n    \n    np.random.seed(seed)\n    \n    permutation = list(np.random.permutation(m))\n    shuffled_features = features[:, permutation]\n    shuffled_labels = labels.iloc[:, permutation]\n    \n    num_complete_mini_batches = math.floor(m\/mini_batch_size)\n    \n    for k in range(num_complete_mini_batches):\n        mini_batch_features = shuffled_features[:, k*mini_batch_size:(k+1)*mini_batch_size]\n        mini_batch_lables = shuffled_labels.iloc[:, k*mini_batch_size:(k+1)*mini_batch_size]\n        mini_batch = (mini_batch_features, mini_batch_lables)\n        mini_batches.append(mini_batch)\n        \n    if m%mini_batch_size !=0:\n        end = m - mini_batch_size * math.floor(m\/mini_batch_size)\n        mini_batch_features = shuffled_features[:, mini_batch_size*num_complete_mini_batches:]\n        mini_batch_lables = shuffled_labels.iloc[:, mini_batch_size*num_complete_mini_batches:]\n        mini_batch = (mini_batch_features, mini_batch_lables)\n        mini_batches.append(mini_batch)\n        \n    return mini_batches","86c87206":"mini_batches = random_mini_batch(features, labels)\nprint (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\nprint (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\nprint (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\nprint (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\nprint (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \nprint (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\nprint (\"mini batch sanity check: \" + str(mini_batches[0][0][0][0:3]))","3768d02d":"def parameter_initialization(n_x, n_h, n_y):\n    W1 = np.random.randn(n_h, n_x) * 0.01\n    b1 = np.zeros((n_h,1))\n    W2 = np.random.randn(n_y, n_h) * 0.01\n    b2 = np.zeros((n_y,1))\n    \n    assert (W1.shape == (n_h, n_x))\n    assert (b1.shape == (n_h,1))\n    assert (W2.shape == (n_y, n_h))\n    assert (b2.shape == (n_y,1))\n    \n    parameters = {\n        'W1':W1,\n        'b1':b1,\n        'W2':W2,\n        'b2':b2\n    }\n    return parameters","946a6aff":"n_x = features.shape[0]\nn_h = int(np.ceil((features.shape[0]+labels.shape[0])\/2))\nn_y = labels.shape[0]\nparameters = parameter_initialization(n_x, n_h, n_y)","f9b8f8ce":"def initialize_velocity(parameters):\n    L = len(parameters) \/\/ 2\n    v = {}\n    \n    for l in range(L):\n        v['dW'+str(l+1)] = np.zeros_like(parameters['W'+str(l+1)])\n        v['db'+str(l+1)] = np.zeros_like(parameters['b'+str(l+1)])\n        \n    return v","267a1193":"v = initialize_velocity(parameters)\nprint(\"v[\\\"dW1\\\"] = \" + str(v[\"dW1\"]))\nprint(\"v[\\\"db1\\\"] = \" + str(v[\"db1\"]))\nprint(\"v[\\\"dW2\\\"] = \" + str(v[\"dW2\"]))\nprint(\"v[\\\"db2\\\"] = \" + str(v[\"db2\"]))","fa0555da":"def sigmoid(x):\n    return 1\/(1+np.exp(-x))","f2f7b706":"def forward_propagation(features, parameters):\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    \n    Z1 = np.dot(W1, features) + b1\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(W2, A1) + b2\n    A2 = sigmoid(Z2)\n    \n    assert (A2.shape == (1, features.shape[1]))\n    \n    cache = {\n        'Z1':Z1,\n        'A1':A1,\n        'Z2':Z2,\n        'A2':A2\n    }\n    return A2, cache","05a93436":"A2, cache = forward_propagation(features, parameters)","e1030984":"def compute_cost(A2, labels):\n    m = labels.shape[1]\n    logprobs =  np.dot(labels, np.log(A2.T)) + np.dot(1-labels, np.log(1-A2.T))\n    cost = -(1\/m) * np.sum(logprobs)\n    assert(isinstance(cost, float))\n    return cost","94ed2d19":"cost = compute_cost(A2, labels)\nprint('cost ' + str(cost))","ab350e70":"def backward_propagation(cache, parameters, features, labels):\n    W1 = parameters['W1']\n    W2 = parameters['W2']\n    \n    A1 = cache['A1']\n    A2 = cache['A2']\n    \n    m = features.shape[1]\n    \n    dZ2 = A2-labels\n    dZ2 = np.array(dZ2)\n    dW2 = (1\/m)*np.dot(dZ2, A1.T)\n    db2 = (1\/m)* np.sum(dZ2, axis=1, keepdims=True)\n    \n    dZ1 = np.multiply(np.dot(dW2.T, dZ2), (1-np.power(A1,2)))\n    dZ1 = np.array(dZ1)\n    dW1 = (1\/m)*np.dot(dZ1, features.T)\n    db1 = (1\/m)*np.sum(dZ1, axis=1, keepdims=True)\n    \n    grads = {\n        'dW1':dW1,\n        'db1':db1,\n        'dW2':dW2,\n        'db2':db2\n    }\n    \n    return grads","fb2db055":"grads = backward_propagation(cache, parameters, features, labels)","a86dcf00":"def update_parameters_with_momentum(parameters, grads,v, beta, learning_rate=0.01):\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    \n    dW1 = grads['dW1']\n    db1 = grads['db1']\n    dW2 = grads['dW2']\n    db2 = grads['db2']\n    \n    v['dW1'] = beta*v['dW1'] + (1-beta)*dW1\n    v['db1'] = beta*v['db1'] + (1-beta)*db1\n    v['dW2'] = beta*v['dW2'] + (1-beta)*dW2\n    v['db2'] = beta*v['db2'] + (1-beta)*db2\n    \n    W1 = W1-learning_rate*v['dW1']\n    b1 = b1=learning_rate*v['db1']\n    W2 = W2-learning_rate*v['dW2']\n    b2 = b2-learning_rate*v['db2']\n    \n    parameters= {\n        'W1': W1,\n        'b1': b1,\n        'W2': W2,\n        'b2': b2\n    }\n    return parameters, v","e1b15d7b":"parameters, v = update_parameters_with_momentum(parameters, grads, v, beta=0.9)","354655b7":"def ANN_Model(features, labels, num_iterations, print_cost=False):\n    parameters = parameter_initialization(n_x,n_h,n_y)\n    v = initialize_velocity(parameters)\n    seed = 10\n    costs = []\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    \n    for i in range(0,num_iterations):\n        seed = seed+1\n        mini_batches = random_mini_batch(features=features, labels=labels, seed=seed)\n        \n        for mini_batch in mini_batches:\n            #mini batch\n            (mini_batch_features, mini_batch_lables) = mini_batch\n            \n            #forward propagation\n            A2, cache = forward_propagation(mini_batch_features, parameters)\n\n            #cost\n            cost = compute_cost(A2, mini_batch_lables)\n\n            #backward propagation\n            grads = backward_propagation(cache, parameters, mini_batch_features, mini_batch_lables)\n\n            #update parameters\n            parameters, v = update_parameters_with_momentum(parameters, grads, v, beta=0.9)\n\n        #print cost\n        if print_cost and i % 1000 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    \n    plt.plot(costs)\n    plt.ylabel('cost')\n    plt.xlabel('epochs (per 100)')\n    plt.title(\"Learning rate = 0.01\")\n    plt.show()\n            \n    return parameters","2df11871":"parameters = ANN_Model(features, labels, num_iterations=9000, print_cost=True)","a1cddd77":"def predict(parameters, features):\n    A2, cache = forward_propagation(features, parameters)\n    predictions = np.round(A2)\n    \n    return predictions","796da41d":"predictions = predict(parameters, features)","713b5e48":"print ('Training Accuracy: %d' % float((np.dot(labels,predictions.T) + np.dot(1-labels,1-predictions.T))\/float(labels.size)*100) + '%')","7c05ca28":"test_predictions = predict(parameters, test_features)","1b07802d":"print ('Testing Accuracy: %d' % float((np.dot(test_labels,test_predictions.T) + np.dot(1-test_labels,1-test_predictions.T))\/float(test_labels.size)*100) + '%')","ea2fcbcd":"**In this notebook i am going to implement ANN from scratch using numpy and pandas**\nI have implemented using numpy\n\n1. Random Mini batches.\n2. Forward propagation.\n3. Backward propagation.\n4. gradient descent with momentum.\n5. Parameter updatation."}}