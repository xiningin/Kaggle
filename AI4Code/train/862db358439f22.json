{"cell_type":{"a8a4365e":"code","2b0b1d5e":"code","c4f52bf5":"code","54f8a10e":"code","e97b4b49":"code","156d73c2":"code","b8978f18":"code","7624c50c":"code","d9a1ac75":"code","6faa3791":"code","b82f3136":"code","2e902862":"code","21b584eb":"code","32c1c6ee":"code","c608e525":"code","0259740e":"code","ed6a7d0c":"code","b2f429cd":"code","14d960cb":"code","bd2c93a5":"code","e3bd2511":"code","4f18ef43":"markdown","4659c7de":"markdown","564f8d77":"markdown","a78a2879":"markdown","598b1e6c":"markdown","7821b4d5":"markdown","7a9f72f8":"markdown","d2b9d24a":"markdown"},"source":{"a8a4365e":"import tensorflow as tf\nimport keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPool2D, UpSampling2D, GlobalMaxPool2D, GlobalAveragePooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import to_categorical, plot_model\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import NASNetMobile, Xception, DenseNet121, MobileNetV2, InceptionV3, InceptionResNetV2, vgg16, resnet50, inception_v3, xception, DenseNet201\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import CSVLogger\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import jaccard_score\n\nfrom scipy import stats\n\nimport seaborn as sns\n\nimport skimage\nfrom skimage.transform import rotate\n\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nimport numpy as np\nimport os\nimport cv2\nimport pandas as pd\n# import imutils\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport pickle\nimport torch","2b0b1d5e":"def get_video_filename(filenames):\n    date2clip = {}\n    for filename in filenames:\n        for path in os.listdir(filename):\n            if path == '.ipynb_checkpoints':\n                continue\n\n            path = filename+'\/'+path\n            int_path = int(path[-18:-4])\n            paths = range(int_path-50, int_path+50)\n            for i in paths:\n                if str(i) in date2clip.keys():\n                    int_path_date2clip = int(date2clip[str(i)][-18:-4])\n                    if abs(i - int_path) < abs(i - int_path_date2clip):\n                        date2clip[str(i)] = path\n                else:\n                    date2clip[str(i)] = path\n\n    def clip(filename, date2clip):\n        try:\n            return date2clip[filename]\n        except:\n            return 'Error'\n        \n    return lambda x: clip(x, date2clip)","c4f52bf5":"def get_data(condition):\n    df = pd.DataFrame({})\n    if condition == 'train':\n        for path in os.listdir('..\/input\/super-ai-engineer-denso-lasi\/train_csv'):\n            df = pd.concat([df, pd.read_csv('..\/input\/super-ai-engineer-denso-lasi\/train_csv\/' + path)])\n    if condition == 'test':\n        df = pd.read_csv('..\/input\/super-ai-engineer-denso-lasi\/test.csv')\n\n    # Drop sth shit\n    df.drop(columns=['s_equipment_control'], inplace=True)\n    df.rename(columns={'Unnamed: 0' : 'Ids'}, inplace=True)\n\n    # Create file_datetime for finding filename in clip\n    df['file_datetime'] = df['d_datetime'].replace({'-':'', ':':'', ' ':''}, regex=True)\n\n    # Get video filename\n    video_filenames = ['..\/input\/denso-videos\/denso-video', '..\/input\/densotest']\n    df['file_datetime'] = df['file_datetime'].apply(get_video_filename(video_filenames))\n    \n    df.index = df['Ids']\n    df.drop(columns='Ids', inplace=True)\n    \n    if condition == 'train':\n        df.drop(index=df.loc[df['has_actual_output'] == 'Corrupted Video'].index, inplace=True)\n        \n    return df","54f8a10e":"train = get_data('train')\ntest = get_data('test')","e97b4b49":"train","156d73c2":"test","b8978f18":"def get_image(df, condition='train'):\n    number = range(5)\n    file_datetime = df['file_datetime']\n    n_ct = df['n_ct']\n    cap = cv2.VideoCapture(file_datetime)\n    fps = 15\n    frames = []\n    \n    x_crop_start = 30\n    x_crop_end = 240\n    y_crop_start = 500\n    y_crop_end = 620\n    \n    for i in number:\n        ret, frame = cap.read()\n        if ret == False:\n            return 'Error'\n\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        frame = np.array(frame)\n        try:\n            if condition == 'test':\n                return frame[x_crop_start:x_crop_end, y_crop_start:y_crop_end, :]\n            \n            frames.append(frame[x_crop_start:x_crop_end, y_crop_start:y_crop_end, :])\n        except:\n            return 'Error'\n        \n    frames = np.array(frames)\n    return frames\n    \ndef get_image2df(df, condition='train'):\n    df['image'] = df.apply(lambda x: get_image(x, condition), axis=1)\n    df.drop(index=df.loc[df['image'] == 'Error'].index, inplace=True)\n    return df\n\ntrain = get_image2df(train)","7624c50c":"fig = plt.figure(figsize = (50,100))\nrows = train.loc[train['has_actual_output'] == 'Yes']['has_actual_output'].index\nnumber = 5\nfor i, row in enumerate(tqdm(rows[:number])):\n    im = np.array(train.loc[row]['image'])\n    fig.add_subplot(1, number, i+1)\n    plt.imshow(im[0])","d9a1ac75":"fig = plt.figure(figsize = (50,100))\nrows = train.loc[train['has_actual_output'] == 'No']['has_actual_output'].index\nnumber = 5\nfor i, row in enumerate(tqdm(rows[:number])):\n    im = np.array(train.loc[row]['image'])\n    fig.add_subplot(1, number, i+1)\n    plt.imshow(im[0])","6faa3791":"im = np.array(train.loc[45049]['image'][0])\nx_resolution, y_resolution, _ = im.shape\nx_resolution, y_resolution","b82f3136":"with tf.device('\/device:GPU:0'):\n    def get_model():\n        inputs = Input(shape=(x_resolution, y_resolution, 3))\n        \n        x = Conv2D(16, kernel_size=(5,5), activation='relu')(inputs)\n        x = MaxPool2D(pool_size=2)(x)\n        x = BatchNormalization()(x)\n        \n        x = Conv2D(32, kernel_size=(5,5), activation='relu')(x)\n        x = MaxPool2D(pool_size=2)(x)\n        x = BatchNormalization()(x)\n        \n        x = Flatten()(x)\n        x = Dense(32)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(16)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(1)(x)\n        outputs = Activation('sigmoid')(x)\n\n        model = Model(inputs=inputs, outputs=outputs)\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n        return model\n    \n    get_model().summary()\nplot_model(get_model(),show_shapes=True)","2e902862":"# X = np.array([i for i in train['image']])\n# y = train['has_actual_output'].replace({'No':0, 'Yes':1}, regex=True).to_numpy()\nX = []\ny = []\nfor i, out in zip(train['image'], train['has_actual_output'].replace({'No':0, 'Yes':1}, regex=True).to_numpy()):\n    for j in i:\n        X.append(j)\n        y.append(out)\n        \nX = np.array(X)\/255.\ny = np.array(y)\nX.shape, y.shape","21b584eb":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\nbatch_size = 32\nearlystopping = 50\nbest_model = 'best_model.h5'\n\nEarlyStopper = EarlyStopping(patience=earlystopping, verbose=1, monitor='val_accuracy', mode='max')\nCheckpoint = ModelCheckpoint(best_model, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max')\n\nprint('Train Size :',X_train.shape[0])\nprint('Validation Size :',X_valid.shape[0])","32c1c6ee":"model = get_model()\n\nmodel.fit(X_train, y_train, \n         validation_data=(X_valid, y_valid),\n         batch_size=batch_size,\n         epochs=200,\n         verbose=1,\n         callbacks=[EarlyStopper, Checkpoint]\n        )","c608e525":"model = load_model(best_model)\nloss_train, acc_train = model.evaluate(X_train, y_train, verbose=0)\nloss_valid, acc_valid = model.evaluate(X_valid, y_valid, verbose=0)\nloss_all, acc_all = model.evaluate(X, y, verbose=0)\nprint('Train Loss :', loss_train)\nprint('Train Accuracy :', acc_train*100)\nprint()\nprint('Valid Loss :', loss_valid)\nprint('Valid Accuracy :', acc_valid*100)\nprint()\nprint('All Loss :', loss_all)\nprint('All Accuracy :', acc_all*100)","0259740e":"model_submission = get_model()\n\nmodel_submission.fit(X, y,\n         batch_size=batch_size,\n         epochs=100,\n         verbose=1\n        )","ed6a7d0c":"loss_train, acc_train = model_submission.evaluate(X_train, y_train, verbose=0)\nloss_valid, acc_valid = model_submission.evaluate(X_valid, y_valid, verbose=0)\nloss_all, acc_all = model_submission.evaluate(X, y, verbose=0)\nprint('Train Loss :', loss_train)\nprint('Train Accuracy :', acc_train*100)\nprint()\nprint('Valid Loss :', loss_valid)\nprint('Valid Accuracy :', acc_valid*100)\nprint()\nprint('All Loss :', loss_all)\nprint('All Accuracy :', acc_all*100)","b2f429cd":"# 44845,48788 ---> Error\ntest = get_image2df(test, 'test')\nX_test = np.array([i for i in test['image']])\/255.\nactual_output = ['No' if i[0] < 0.5 else 'Yes' for i in model_submission.predict(X_test)]\nactual_output[:20]","14d960cb":"#Error\ndf_error = pd.DataFrame({'Ids':[44845,48788],\n                        'actual_output':['No','No']})\ndf_error","bd2c93a5":"submission = pd.DataFrame({'Ids': test.index})\nsubmission['actual_output'] = actual_output\n\n# Appending Error Clip\nsubmission = submission.append(df_error, ignore_index=True)\n\nsubmission = submission.sort_values(['Ids'])\nsubmission.to_csv('actual_output.csv', index=False)","e3bd2511":"import math\n\nfig = plt.figure(figsize = (50,100))\nsize = len(test.index)\nsize = int(math.sqrt(size))+1\nfor i, idx in enumerate(tqdm(test.index)):\n    im = np.array(test.loc[idx]['image'])\n    fig.add_subplot(size, size, i+1)\n    print_output = submission.loc[submission['Ids'] == idx]['actual_output'].to_numpy()[0]\n    plt.title(print_output, fontsize=70)\n    plt.imshow(im)","4f18ef43":"# Washing Machine Training","4659c7de":"# Load Clip Filename","564f8d77":"# Model","a78a2879":"# Predict","598b1e6c":"# Prepare Data For Training Model","7821b4d5":"# Submission Model","7a9f72f8":"# Prepare Data","d2b9d24a":"# Traning Process"}}