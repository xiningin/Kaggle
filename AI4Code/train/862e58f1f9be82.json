{"cell_type":{"09a8ca67":"code","fd019280":"code","44c073c9":"code","9261b349":"code","a16a12d3":"code","b0af8236":"code","105238bb":"code","3f912c4c":"code","58b9885b":"code","fe027ae6":"markdown","ebd98a0e":"markdown","cae5040e":"markdown"},"source":{"09a8ca67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fd019280":"import shutil\nfrom shutil import copyfile\n\n# delete temp dir\nif os.path.exists('\/kaggle\/temp\/'):\n    shutil.rmtree('\/kaggle\/temp\/')\n    \n# make directories\nos.mkdir('\/kaggle\/temp\/')\n\nTRAIN_DIR = '\/kaggle\/temp\/train\/'\nVALID_DIR ='\/kaggle\/temp\/valid\/'\n\nos.mkdir(TRAIN_DIR)\nos.mkdir(VALID_DIR)\n\nfor label in ['paper', 'rock', 'scissors']:\n    os.mkdir(TRAIN_DIR+label)\n    os.mkdir(VALID_DIR+label)","44c073c9":"import random\n\ndef train_valid_split(source, train_dir, valid_dir, valid_size):\n    # get files\n    files = []\n    for filename in os.listdir(source):\n        file = source + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n    \n    # train valid split\n    valid_size = int(len(files) * valid_size)\n    train_size = len(files) - valid_size\n    \n    # shuffle the dataset\n    shuffled_files = random.sample(files, len(files))\n    \n    train_set = shuffled_files[:train_size]\n    valid_set = shuffled_files[train_size:]\n    \n    for filename in train_set:\n        filepath = source + filename\n        destination = train_dir + filename\n        copyfile(filepath, destination)\n        \n    for filename in valid_set:\n        filepath = source + filename\n        destination = valid_dir + filename\n        copyfile(filepath, destination)\n    \nSOURCE = \"\/kaggle\/input\/rockpaperscissors\/\"\n\nfor label in ['paper', 'rock', 'scissors']:\n    print(label)\n    train_valid_split(SOURCE+label+'\/', TRAIN_DIR +label+'\/', VALID_DIR +label+'\/', valid_size=0.2)\n    print(len(os.listdir(TRAIN_DIR +label+'\/')))\n    print(len(os.listdir(VALID_DIR +label+'\/')))","9261b349":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimages = {label:os.listdir(os.path.join(TRAIN_DIR, label)) for label in  ['paper', 'rock', 'scissors']}\n\npic_index = 10\nnext_rock = [os.path.join(TRAIN_DIR, \"rock\", fname) for fname in images['rock'][pic_index-2:pic_index]]\nnext_paper = [os.path.join(TRAIN_DIR, \"paper\", fname) for fname in images['paper'][pic_index-2:pic_index]]\nnext_scissors = [os.path.join(TRAIN_DIR, \"scissors\", fname) for fname in images['scissors'][pic_index-2:pic_index]]\n\n\n# Set up matplotlib fig\nnrows = 2\nncols = 3\n\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\nfor i, img_path in enumerate(next_rock+next_paper+next_scissors):\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off')\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n\nplt.show()","a16a12d3":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255, rotation_range=40, width_shift_range=0.2,\n                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, target_size=(150,150), class_mode='categorical', batch_size=32)\nvalid_generator = valid_datagen.flow_from_directory(VALID_DIR, target_size=(150,150), class_mode='categorical', batch_size=32)\n","b0af8236":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n\nmodel.summary()","105238bb":"K = tf.keras.backend\nK.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cnn.h5\", save_best_only=True)\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator, epochs=100, validation_data = valid_generator, callbacks=[early_stopping_cb, checkpoint_cb])","3f912c4c":"acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.show()\n\n# Plot training and validation loss per epoch\n\nplt.plot(epochs, loss, 'r', label=\"Training Loss\")\nplt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\nplt.show()","58b9885b":"model = tf.keras.models.load_model(\"cnn.h5\") # rollback to best model\nmodel.evaluate(valid_generator)","fe027ae6":"# Convolutional Neural Network","ebd98a0e":"# keras ImageGenerator API","cae5040e":"# Prepare Image Directories"}}