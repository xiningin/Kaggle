{"cell_type":{"48d7fd79":"code","0d55871f":"code","b0901e9e":"code","106d8bd4":"code","409701b5":"code","ed831782":"code","41c30a5a":"code","76af9205":"code","fd31b30a":"code","cadea891":"code","cb3d9d5b":"code","f30e235b":"code","042ef962":"code","4bf2d394":"code","9a5b0277":"code","27748326":"code","db592db4":"code","c4c7662c":"code","87ceca36":"code","d0d4c29f":"code","1102f22d":"code","17c67971":"code","573b192f":"code","f58535ca":"markdown","b9466be5":"markdown","e5283486":"markdown","b484fce6":"markdown","25be2034":"markdown","5d69781b":"markdown","b7d89034":"markdown"},"source":{"48d7fd79":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report,accuracy_score\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\nimport shap\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d55871f":"data=pd.read_csv(\"..\/input\/disease-prediction-using-machine-learning\/Training.csv\")\ndata=data.drop(columns=['Unnamed: 133'])","b0901e9e":"y=data['prognosis']\nX=data.drop(columns=['prognosis'])","106d8bd4":"data.columns","409701b5":"X.columns[X.isna().any()].tolist()","ed831782":"X.head(3)","41c30a5a":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=5,test_size=0.25)","76af9205":"len(train_X),len(X)","fd31b30a":"random_f = RandomForestClassifier(n_estimators=50,max_depth=5,random_state=0).fit(train_X, train_y)\ny_pred=random_f.predict(val_X)\naccuracy_score(val_y, y_pred)","cadea891":"perm = PermutationImportance(random_f, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist())","cb3d9d5b":"feature_names = [i for i in X.columns if X[i].dtype in [np.int64]]\nlen(feature_names)","f30e235b":"# Create the data that we will plot\npdp_goals = pdp.pdp_isolate(model=random_f, dataset=val_X, model_features=feature_names, feature='weight_loss')\n\n# plot it\npdp.pdp_plot(pdp_goals, 'weight_loss')\nplt.show()","042ef962":"data.prognosis.unique()[0],data.prognosis.unique()[24],data.prognosis.unique()[28],data.prognosis.unique()[36]","4bf2d394":"row_to_show = 8\nnonzero=0\nnewi=0\nfor i in range(1230):\n    data_for_prediction = val_X.iloc[i]  # use 1 row of data here. Could use multiple rows if desired\n    data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n    x=random_f.predict_proba(data_for_prediction_array)\n    if np.count_nonzero(x)>nonzero:\n        nonzero=np.count_nonzero(x)\n        newi=i\n        print(nonzero)\n        print(i)","9a5b0277":"data_for_prediction = val_X.iloc[0]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\nrandom_f.predict_proba(data_for_prediction_array)","27748326":"# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(random_f)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)","db592db4":"explainer = shap.TreeExplainer(random_f)\nshap_values = explainer.shap_values(val_X,check_additivity=False)\nshap.summary_plot(shap_values[1], val_X)","c4c7662c":"tree_model = DecisionTreeClassifier(random_state=0, max_depth=10).fit(train_X, train_y)\ny_pred=tree_model.predict(val_X)\naccuracy_score(val_y, y_pred)","87ceca36":"values=np.unique(train_y)\nvalues[:5]","d0d4c29f":"Y_train=np.zeros(shape=(len(train_y),len(values)))\nk=0\nfor x in train_y:\n     for i in range(len(values)):\n            if x==values[i]:\n                tmp=list(np.zeros(41))\n                tmp[i]=1\n                Y_train[k]=tmp\n                k+=1\n\nY_train[0]","1102f22d":"model = Sequential()\nmodel.add(Dense(16, input_dim=132))\nmodel.add(Activation('tanh'))\nmodel.add(Dense(41))\nmodel.add(Activation('sigmoid'))\n\nsgd = SGD(lr=0.1)\nmodel.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer=sgd)\n\nmodel.fit(train_X, Y_train, batch_size=150, epochs=30,validation_split = 0.2)","17c67971":"test_values=np.unique(val_y)\ntest_values\n\nY_test=np.zeros(shape=(len(val_y),len(test_values)))\nk=0\nfor x in val_y:\n     for i in range(len(test_values)):\n            if x==test_values[i]:\n                tmp=list(np.zeros(41))\n                tmp[i]=1\n                Y_test[k]=tmp\n                k+=1\npre=model.predict_proba(val_X)","573b192f":"acc=0;\nfor i in range(len(pre)):\n    if pre[i].argmax() == Y_test[i].argmax() :\n        if pre[i].max() >= 0.6:\n            acc+=1\n\nacc=acc\/len(pre)\nacc","f58535ca":"## Decision tree","b9466be5":"### Let's check if any column has null values","e5283486":"## Permutation importance","b484fce6":"## SHAP values","25be2034":"## Partial dependence plots","5d69781b":"## Using a neural network","b7d89034":"### Splitting data and making a Random Forest classifier"}}