{"cell_type":{"6df5b228":"code","793f09c2":"code","a3a4b465":"code","96e3e4d1":"code","daea999f":"code","42a59ae7":"code","558904e7":"code","96e8f101":"code","a354ab82":"code","4ba680f9":"code","c33a1fbb":"code","a0808c56":"code","18602d20":"code","bacd674b":"code","36a10308":"code","f14634e1":"code","f0165d69":"code","7f271f99":"code","ba9849ff":"code","94f80b5f":"code","e94b0478":"markdown","fce6022e":"markdown","81b26745":"markdown","3e5d8b89":"markdown","2ecece55":"markdown","7941e327":"markdown","55d8c53e":"markdown","057b5c48":"markdown","65b7e501":"markdown","de840955":"markdown","8449bf26":"markdown","7259a53c":"markdown","c1b9769d":"markdown","d81ead42":"markdown","2e8127da":"markdown","a8db2876":"markdown"},"source":{"6df5b228":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ReduceLROnPlateau\n\nnp.random.seed(2)","793f09c2":"# Load the data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","a3a4b465":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"], axis = 1) # all except for label column\n\n\ng = sns.countplot(Y_train)\nY_train.value_counts() # ","96e3e4d1":"X_train.isnull().any().describe()","daea999f":"test.isnull().any().describe()","42a59ae7":"# from 0-255 to 0-1\nX_train = X_train \/ 255.0\ntest = test \/ 255.0","558904e7":"# Reshape image  (height = 28px, width = 28px , canal = 1)\n# use this reshaping for CNN in Section 2.1\n#X_train = X_train.values.reshape(-1,28,28,1)\n#test = test.values.reshape(-1,28,28,1)","96e8f101":"# use this reshape for \nX_train = X_train.values.reshape(-1,28,28)\ntest = test.values.reshape(-1,28,28)","a354ab82":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n#Y_train = to_categorical(Y_train, num_classes = 10) <- ","4ba680f9":"random_seed = 2\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.15, random_state=random_seed)","c33a1fbb":"#g = plt.imshow(X_train[0][:,:,0])","a0808c56":"## In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n#\n#model = Sequential()\n#model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n#                 activation ='relu', input_shape = (28,28,1))) #32 filters for the first conv2D layer\n#model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n#                 activation ='relu')) #32 filters for the 2nd conv2D layer\n#model.add(MaxPool2D(pool_size=(2,2))) #the area size pooled each time\n#model.add(Dropout(0.25)) #regularization parameter= proportion of nodes in the layer are randomly ignored (setting their weights to zero) for each training sample. \n#\n#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n#                 activation ='relu'))\n#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n#                 activation ='relu'))\n#model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n#model.add(Dropout(0.25))\n#\n#model.add(Flatten()) #to convert the final feature maps into a one single 1D vector\n#model.add(Dense(256, activation = \"relu\")) #activation function max(0,x), used to add non linearity to the network\n#model.add(Dropout(0.5))\n#model.add(Dense(10, activation = \"softmax\")) #outputs distribution of probability of each class","18602d20":"# Define the optimizer\n# loss function and an optimisation algorithm\n#optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0) # faster than Stochastic Gradient Descent ('sgd') optimizer\n","bacd674b":"# Compile the model\n#model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","36a10308":"# Set a learning rate annealer\n# reduce the LR by half if the accuracy is not improved after 3 epochs\n#learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n#                                            patience=3, \n#                                            verbose=1, \n#                                            factor=0.5, \n#                                            min_lr=0.00001)\n#epochs = 10 # \n#batch_size = 86","f14634e1":"#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n          validation_data = (X_val, Y_val), verbose = 2)","f0165d69":"class myCallback(tf.keras.callbacks.Callback):\n      def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('acc')>0.997):\n          print(\"\\nReached 99% accuracy so cancelling training!\")\n          self.model.stop_training = True","7f271f99":"callbacks = myCallback()\nmodel2 = tf.keras.models.Sequential([\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\n        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n    ])\n\nmodel2.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n# model fitting\nhistory = model2.fit(X_train, Y_train, epochs=30, callbacks=[callbacks])","ba9849ff":"# predict results\nresults = model2.predict(test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","94f80b5f":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","e94b0478":"No missing values in the train and test datasets.","fce6022e":"## 1.6 Splitting into training and valid\nation set","81b26745":"## 1.1 Load Data","3e5d8b89":"## 1.7 Example Images","2ecece55":"## 2.2 Alternative (Simpler) Model","7941e327":"# Submitting predictions","55d8c53e":"We have ap. even number of all digits","057b5c48":"## 1.5 Label encoding ","65b7e501":"We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]).\n(only needed for model from Section 2.1, not for 2.2 !)","de840955":"# 1. Data preparation","8449bf26":"Validation accuracy = 0.9905","7259a53c":"## 1.4 Reshaping","c1b9769d":"## 1.3 Grayscale Normalization","d81ead42":"## 1.2 Check for null values","2e8127da":"All data are in 28x28x1 3D matrices now (Keras requires one more dimension in the end which correspond to channels, only one channel is needed for gray scale images.","a8db2876":"# 2. Modeling\n## 2.1 CNN model "}}