{"cell_type":{"b3dc4505":"code","02cdbfd0":"code","18fbc091":"code","e324bbbf":"code","5ebbc08d":"code","002fab52":"code","4ca8a738":"code","865d3724":"code","6ae27d3a":"code","0b15d4e0":"code","5abbc564":"code","48650190":"code","e2b969b1":"code","c63319fb":"code","23a1c2c8":"code","659334bd":"code","a9bd91ff":"code","5453d94b":"code","c6aaae64":"code","f460ee85":"code","e7e49a7f":"code","17836b47":"code","47a7a005":"code","ec479d84":"code","f972cde7":"code","b6014f45":"code","171f8f78":"code","a5ec656f":"code","8e031500":"code","bd4e0911":"code","772ddf3c":"code","552a339f":"code","cc717583":"code","a95ad105":"code","689147bb":"code","7d331a9c":"code","f53ec6d3":"code","76bf7094":"code","3da1910e":"code","f70ee094":"code","9a354a33":"code","8fc8b117":"code","f5dede62":"code","7eb3768f":"code","44e473e5":"code","c1d648f8":"code","488c09b5":"code","20b5176d":"code","af95e94e":"code","bce399fe":"code","0a84bba5":"code","11a95201":"code","c08f7020":"code","65adbd27":"markdown","be7e220c":"markdown","a40a14b6":"markdown","cf0492c6":"markdown","d45594e9":"markdown","baba9e66":"markdown","3d35b7d5":"markdown","db6f9875":"markdown","0e2e1321":"markdown","360ef767":"markdown","29c7defc":"markdown","4bce3eac":"markdown","eb0fcff6":"markdown","48e87d6c":"markdown","fd62b84a":"markdown","88fbb5e1":"markdown","b4147525":"markdown","b0e5af04":"markdown","be5549a3":"markdown","78523674":"markdown","5d91ac32":"markdown","fa1d242d":"markdown","4169ff61":"markdown","56f7de94":"markdown"},"source":{"b3dc4505":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn')\nsns.set_context('talk')","02cdbfd0":"\ntest = pd.read_csv(\"..\/input\/blackfriday\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/blackfriday\/train.csv\")","18fbc091":"sns.boxplot(train[\"Purchase\"], orient='v')","e324bbbf":"q1,q3 = np.percentile(train[\"Purchase\"], [25,70])\niqr = q3 - q1\nlower_bound = q1 - (1.5 * iqr)\nupper_bound = q3 + (1.5 * iqr)\nprint(lower_bound)\nprint(upper_bound)","5ebbc08d":"train.drop(train[train[\"Purchase\"] > 20085.5].index, inplace = True)","002fab52":"user_id_mapping = {}\naverage_purchase_per_customer = train.groupby('User_ID')['Purchase'].mean()\nvalues = average_purchase_per_customer.iteritems()\nnp.percentile(average_purchase_per_customer, [5, 20, 50, 85, 100])","4ca8a738":"for key, val in values:\n    if val <= 6702:\n        user_id_mapping[key] = 1\n    elif val <= 7798:\n        user_id_mapping[key] = 2\n    elif val <= 9069:\n        user_id_mapping[key] = 3\n    elif val <= 10996:\n        user_id_mapping[key] = 4\n    else:\n        user_id_mapping[key] = 5   \n\ndef get_customer_category(user_id):\n    if user_id in user_id_mapping:\n        return user_id_mapping[user_id]\n    return 3","865d3724":"train['User_Category'] = [get_customer_category(train['User_ID'][i]) for i in train.index]\ntest['User_Category'] = [get_customer_category(test['User_ID'][i]) for i in test.index]","6ae27d3a":"product_id_mapping = {}\nproduct_id_avg_purchase = train.groupby('Product_ID')['Purchase'].mean()\nvalues = product_id_avg_purchase.iteritems()\nnp.percentile(product_id_avg_purchase, [30, 60, 75, 90, 100])","0b15d4e0":"for key, val in values:\n    if val <= 5792:\n        product_id_mapping[key] = 1\n    elif val <= 7527:\n        product_id_mapping[key] = 2\n    elif val <= 10069:\n        product_id_mapping[key] = 3\n    elif val <= 13562:\n        product_id_mapping[key] = 4\n    else:\n        product_id_mapping[key] = 5 \n    \ndef get_product_category(product_id):\n    if product_id in product_id_mapping:\n       return product_id_mapping[product_id]\n    return 2","5abbc564":"train['Product_Category'] = [get_product_category(train['Product_ID'][i]) for i in train.index]\ntest['Product_Category'] = [get_product_category(test['Product_ID'][i]) for i in test.index]","48650190":"train['source'] = 'train'\ntest['source'] = 'test'\ndata = pd.concat([train, test], sort=False)","e2b969b1":"data.isnull().sum()","c63319fb":"data['Product_Category_2']= \\\ndata['Product_Category_2'].fillna(-2).astype(\"int\")\ndata['Product_Category_3']= \\\ndata['Product_Category_3'].fillna(-2).astype(\"int\")","23a1c2c8":"sns.distplot(train[\"Purchase\"])","659334bd":"plt.figure(figsize = (23, 4))\n\nplt.subplot2grid((1, 3), (0, 0))\nsns.barplot('Age', 'Purchase', data = train, order = ['0-17', '18-25', '26-35', '36-45', '46-50', '51-55', '55+'])\n\nplt.subplot2grid((1, 3), (0, 1))\nsns.barplot('City_Category', 'Purchase', data = train, order = ['A', 'B', 'C'])\n\nplt.subplot2grid((1, 3), (0, 2))\nsns.barplot('Gender', 'Purchase', data = train)","a9bd91ff":"plt.figure(figsize = (20, 6))\n\nplt.subplot2grid((1, 2), (0, 0))\nsns.countplot(data['Product_Category_1'])\n\nplt.subplot2grid((1, 2), (0, 1))\nsns.barplot(data['Product_Category_1'], data['Purchase'])","5453d94b":"plt.figure(figsize = (20, 6))\n\nplt.subplot2grid((1, 2), (0, 0))\nsns.countplot(data['Product_Category_2'])\n\nplt.subplot2grid((1, 2), (0, 1))\nsns.barplot(data['Product_Category_2'], data['Purchase'])","c6aaae64":"plt.figure(figsize = (20, 6))\n\nplt.subplot2grid((1, 2), (0, 0))\nsns.countplot(data['Product_Category_3'])\n\nplt.subplot2grid((1, 2), (0, 1))\nsns.barplot(data['Product_Category_3'], data['Purchase'])","f460ee85":"plt.figure(figsize = (9,9))\nsns.set(font_scale=1)\nsns.heatmap(train.corr(), annot=True, cmap=\"Blues\")","e7e49a7f":"gender_dict = {'F': 0, 'M': 1}\ndata['Gender'] = data['Gender'].apply(lambda line: gender_dict[line])\ndata['Gender'].value_counts()","17836b47":"Age_dict = {'0-17': 15, '18-25': 21, '26-35': 30, '36-45': 40, '46-50': 48, '51-55': 53, '55+': 60}\ndata['Age'] = data['Age'].map(Age_dict)\ndata['Age'].value_counts()","47a7a005":"Stay_In_Current_City_Years_dict = {'0': 0, '1': 1, '2': 2, '3': 3, '4+': 4}\ndata['Stay_In_Current_City_Years'] = data['Stay_In_Current_City_Years'].map(Stay_In_Current_City_Years_dict)\ndata['Stay_In_Current_City_Years'].value_counts()","ec479d84":"data = pd.get_dummies(data,columns=[\"City_Category\"],drop_first=False)","f972cde7":"Product_Price_mean = data.groupby(['Product_ID'])['Purchase'].agg(['mean']).reset_index()\nProduct_Price_mean.rename(columns ={'mean': 'Product_Price_mean'}, inplace = True)\nProduct_Price_mean.head()","b6014f45":"data = pd.merge(data, Product_Price_mean)\ndata.loc[data['Product_Price_mean']!=data['Product_Price_mean'],'Product_Price_mean'] = 0","171f8f78":"train = data.loc[data['source'] == 'train']\ntest = data.loc[data['source'] == 'test']","a5ec656f":"submission = pd.DataFrame()\nsubmission['User_ID'] = test['User_ID']\nsubmission['Product_ID'] = test['Product_ID']","8e031500":"test.drop(['source','Purchase','Product_ID','User_ID'],axis=1,inplace=True)\ntrain.drop([\"source\"],axis=1,inplace=True)","bd4e0911":"from sklearn.model_selection import train_test_split\nX = train.drop(['Purchase','Product_ID','User_ID' ], axis =1)\ny = train['Purchase']\nX.shape","772ddf3c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30, random_state=942)","552a339f":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\n\ndf = pd.DataFrame(columns=['Model Name','RMSE Score','R2 score'])\n\ndef modelscore(target_test, predicted, i , df):\n    \n    #RMSE\n    mse = mean_squared_error(target_test, predicted)\n    rmse = np.sqrt(mse)\n    \n    #R2 score \n    r2score = r2_score(target_test, predicted)\n    \n    if(i == 0):\n        df = df.append({'Model Name': 'Linear Regressio', 'RMSE Score': rmse, 'R2 score': r2score}, ignore_index=True)\n    elif (i == 1):\n        df = df.append({'Model Name': 'Ridge Regression', 'RMSE Score': rmse, 'R2 score': r2score}, ignore_index=True)\n    elif (i == 2):\n        df = df.append({'Model Name': 'Lasso Regression', 'RMSE Score': rmse, 'R2 score': r2score}, ignore_index=True)\n    elif (i == 3):\n        df = df.append({'Model Name': 'Elastic Net Regression', 'RMSE Score': rmse, 'R2 score': r2score}, ignore_index=True)\n    elif (i == 4):\n        df = df.append({'Model Name': 'Decision Tree Regressor', 'RMSE Score': rmse, 'R2 score': r2score}, ignore_index=True)\n    print (df)\n    return df","cc717583":"from sklearn.linear_model import LinearRegression\nLR = LinearRegression(normalize=True)\nLR.fit(X_train, y_train)","a95ad105":"LRpred = LR.predict(X_test)   \nscores = cross_val_score(LR, X, y, scoring = 'r2', cv = 5)\nprint()\nprint (\"Linear Regression's Cross Validation Score:\", np.sqrt(scores).mean())\nprint()\ndf = modelscore(y_test, LRpred, 0, df)","689147bb":"rankings = LR.coef_.tolist()\nfeatures = list(X)\nd = dict(zip(features,rankings))\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd.sort_values([\"ranking\"], ascending=False)","7d331a9c":"alphas = 10**np.linspace(10,-2,100)*0.5\nfrom sklearn.linear_model import RidgeCV\nridgecv = RidgeCV(alphas = alphas, scoring = 'r2', normalize = True)\nridgecv.fit(X, y)\nridgecv.alpha_","f53ec6d3":"from sklearn.linear_model import Ridge\nRR = Ridge(alpha = ridgecv.alpha_, normalize = True)\nRR.fit(X_train, y_train)","76bf7094":"RRpred = RR.predict(X_test)\nscores = cross_val_score(RR, X, y, scoring = 'r2', cv = 5)\nprint()\nprint (\"Ridge Regression's Cross Validation Score:\", np.sqrt(scores).mean())\nprint()\ndf = modelscore(y_test, RRpred, 1, df)","3da1910e":"rankings = RR.coef_.tolist()\nfeatures = list(X)\nd = dict(zip(features,rankings))\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd.sort_values([\"ranking\"], ascending=False)","f70ee094":"alphas = 10**np.linspace(10,-2,100)*0.5\nfrom sklearn.linear_model import LassoCV\nlassocv = LassoCV(alphas = alphas, normalize = True)\nlassocv.fit(X, y)\nlassocv.alpha_","9a354a33":"from sklearn.linear_model import Lasso\nLaR = Lasso(alpha = lassocv.alpha_,normalize = True)\nLaR.fit(X_train, y_train)","8fc8b117":"LaRpred = LaR.predict(X_test)\n\nscores = cross_val_score(LaR, X, y, scoring = 'r2', cv = 5)\nprint()\nprint (\"Lasso Regression's Cross Validation Score:\", np.sqrt(scores).mean())\nprint()\n\ndf = modelscore(y_test, LaRpred, 2, df)","f5dede62":"rankings = LaR.coef_.tolist()\nfeatures = list(X)\nd = dict(zip(features,rankings))\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd.sort_values([\"ranking\"], ascending=False)","7eb3768f":"from sklearn.linear_model import ElasticNet\nENR = ElasticNet(alpha = 0.00001, l1_ratio = 0.9, max_iter = 5, normalize = True)\nENR.fit(X_train,y_train)","44e473e5":"ENRpred = ENR.predict(X_test)\nscores = cross_val_score(ENR, X, y, scoring = 'r2', cv = 5)\nprint()\nprint (\"Elastic Net Regression's Cross Validation Score:\", np.sqrt(scores).mean())\nprint()\ndf = modelscore(y_test, ENRpred, 3, df)","c1d648f8":"rankings = ENR.coef_.tolist()\nfeatures = list(X)\nd = dict(zip(features,rankings))\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd.sort_values([\"ranking\"], ascending=False)","488c09b5":"from sklearn.tree import DecisionTreeRegressor\nmodel = DecisionTreeRegressor(max_depth = 8, min_samples_leaf = 100, min_samples_split= 2, max_leaf_nodes = 500)\nmodel.fit(X_train, y_train)","20b5176d":"dtrpred = model.predict(X_test)\nscores = cross_val_score(model, X, y, scoring = 'r2', cv = 5)\nprint()\nprint (\"Decision Tree Regression's Cross Validation Score:\", np.sqrt(scores).mean())\nprint()\ndf = modelscore(y_test, dtrpred, 4, df)","af95e94e":"rankings = model.feature_importances_.tolist()\nfeatures = list(X)\nd = dict(zip(features,rankings))\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd = dict(zip(features,rankings))\nd = pd.DataFrame(list(d.items()), columns=[\"features\", \"ranking\"])\nd.sort_values([\"ranking\"], ascending=False)","bce399fe":"from xgboost.sklearn import XGBRegressor\nxgb_reg = XGBRegressor(learning_rate = 0.01 , n_estimators = 500, max_depth= 8)\nxgb_reg.fit(X_train, y_train)","0a84bba5":"y_pred = xgb_reg.predict(X_test)\ndf = modelscore(y_test, y_pred, 4, df)","11a95201":"test_target = xgb_reg.predict(test)  \nsubmission['Purchase'] = test_target\nsubmission.to_csv  ('checkscore.csv', index= False)","c08f7020":"import pandas as pd\ntest = pd.read_csv(\"..\/input\/blackfriday\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/blackfriday\/train.csv\")","65adbd27":"# Black Friday Sales Analysis","be7e220c":"Dealing with missing values","a40a14b6":"The total (train + test) number of Unique Product_ID = 3631 <br>\nThe total number of Unique Product_ID in the train dataset = 3631<br>\nThe total number of Unique Product_ID in the test dataset= 3631\n","cf0492c6":"### 3.1 Linear Regression ","d45594e9":"As an item can belong to more than one product category we are filling the missing values in Product_Category_2 and Product_Category_3 with -2 ","baba9e66":"### 3.5 Decision Tree Regressor ","3d35b7d5":"Label encoding age with a mid value in range. <br>\nAn assumption made : 0-17 age group is considered as a teenage group from 13-17","db6f9875":"### Adding a new column User_Category\n\n","0e2e1321":"### Adding a new column Product_Category ","360ef767":"RMSE on Test Data set: 2670.2065114129\n","29c7defc":"### 3.3 Lasso Regression ","4bce3eac":"Gender ","eb0fcff6":"#### Loading the Dataset ","48e87d6c":"The total (train + test) number of Unique User_ID = 5891 <br>\nThe total number of Unique User_ID in the train dataset = 5891<br>\nThe total number of Unique User_ID in the test dataset= 5891\n\n","fd62b84a":"### 3.2 Ridge Regression ","88fbb5e1":"#### Removing the Outliers ","b4147525":"#### A function to score the Models ","b0e5af04":"#### Label encoding or creating dummies for Categorical Variables","be5549a3":"### 3.4 Elastic Net ","78523674":"## 3. Data Modelling","5d91ac32":"## 1. Data Exploration","fa1d242d":"## 2. Data Pre-Processing","4169ff61":"<br>","56f7de94":"#### Combining the train and test datasets "}}