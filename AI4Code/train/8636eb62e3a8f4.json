{"cell_type":{"7b0e5ae2":"code","564a8440":"code","d18c2e2b":"code","4b113b28":"code","3735d7d0":"code","1b1de9c5":"code","9ac8e2a8":"code","dc6f8175":"code","5eacedb5":"code","df9b4739":"code","ea93d8a3":"code","d35e6eac":"code","48fcf00b":"code","ec69b0de":"markdown","16d21704":"markdown","f586f4ed":"markdown"},"source":{"7b0e5ae2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\nINPUT_DIR = \"..\/input\"\nDATA_LOC = f\"{INPUT_DIR}\/books.csv\"","564a8440":"books = pd.read_csv(DATA_LOC, index_col=0, error_bad_lines=False)\nbooks.columns","d18c2e2b":"books.head()","4b113b28":"error_row = pd.read_csv(DATA_LOC, skiprows=4011, nrows=1, header=None)","3735d7d0":"error_row","1b1de9c5":"books.shape","9ac8e2a8":"print('Before:\\n', books.language_code.value_counts())\nbooks['language_code'] = np.where(books.language_code.str.contains('en'), 'eng', books.language_code)\nprint('After:\\n', books.language_code.value_counts())","dc6f8175":"import matplotlib.pyplot as plt\n\naverage_rating_by_language = books[['language_code', 'average_rating']].groupby(['language_code']).mean().sort_values(by='average_rating', ascending=False)\ncounts_by_language = books.language_code.value_counts()\nlanguages_gt = counts_by_language[counts_by_language > 20]\nbooks_language_gt = books[books.language_code.isin(languages_gt.index)]\n\nfig = plt.figure()\nbooks_language_gt.boxplot(column='average_rating', by='language_code', figsize=(15, 8), rot=60)\nplt.show()","5eacedb5":"# select all as Series\nauthor_counts = books_language_gt.authors.value_counts().sort_values(axis='index').reset_index().rename(columns={'authors': 'counts', 'index': 'authors'})\nauthor_sums = books_language_gt[['authors', 'average_rating']].groupby(['authors']).sum()['average_rating'].sort_values(axis='index').reset_index()\nall_values = author_counts.merge(author_sums).sort_values(by='average_rating', ascending=False)\nall_values['author_average_rating'] = all_values['average_rating'] \/ all_values['counts']\nall_values.head()","df9b4739":"plot_df = all_values.head(10)\n\nplt.figure()\nx_lab = plot_df.authors\nx_ax = range(len(x_lab))\nplt.barh(x_ax, plot_df.author_average_rating)\nplt.yticks(x_ax, x_lab)\nplt.show()","ea93d8a3":"# https:\/\/matplotlib.org\/3.1.0\/gallery\/color\/named_colors.html\nimport matplotlib.colors as mcolors\nimport random\n\nrandom.seed(42)\nlanguage_codes = books_language_gt.language_code.unique()\nunique_language_codes = len(language_codes)\ncolor_list = list(mcolors.CSS4_COLORS.keys())\nshuffled_list = list(range(len(color_list)))\nrandom.shuffle(shuffled_list)\nfig = plt.figure(figsize=(10, 7))\nfor lang_code, color_idx in zip(language_codes, shuffled_list):\n    subset = books_language_gt.loc[books_language_gt.language_code==lang_code]\n    plt.scatter(subset['# num_pages'], subset.average_rating, c=color_list[color_idx], alpha=0.5)\nplt.legend(books_language_gt.language_code.unique())\nplt.show()","d35e6eac":"random.seed(42)\nlanguage_codes = books_language_gt.language_code.unique()\nunique_language_codes = len(language_codes)\ncolor_list = list(mcolors.CSS4_COLORS.keys())\nshuffled_list = list(range(len(color_list)))\nrandom.shuffle(shuffled_list)\nfig = plt.figure(figsize=(15, 7))\nfor lang_code, color_idx in zip(language_codes, shuffled_list):\n    subset = books_language_gt.loc[books_language_gt.language_code==lang_code]\n    sizes = subset.average_rating.apply(lambda x: (x ** x) \/ 2)\n    plt.scatter(subset['# num_pages'], subset.text_reviews_count, c=color_list[color_idx], alpha=0.2, s=sizes.values)\n\nplt.legend(books_language_gt.language_code.unique())\nplt.xlabel('Number of Pages')\nplt.ylabel('Number of Text Reviews')\nplt.title('Book Reviews by Language:\\nPages vs. Text Reviews\\nSized by Rating Score')\nplt.show()","48fcf00b":"books_language_gt.groupby('language_code').describe()","ec69b0de":"The difficult part with the chart above is that we don't get a good sense of book ratings by language code because they are too clustered and the datapoint sizes don't look that different. The only thing we can gather is that if a book has a high number of reviews, it is always a book written in English.","16d21704":"# Handling Erroneous Rows\nAs indicated by the output above, there are 5 rows that don't fit the structure of the rest of the data. For now, we can ignore these since it is so small.","f586f4ed":"# Seeing the errors\nWe can see one of the errors by having pandas read just one of the erroneous rows as indicated in the error message above"}}