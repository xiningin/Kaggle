{"cell_type":{"6ea15dd6":"code","77660d5a":"code","82d53593":"code","e8a424e1":"code","6d5128ab":"code","3d961c21":"code","e5ae6a45":"code","80ec5b9f":"code","1fec9f38":"code","99dcdfe6":"code","f2e00d33":"code","12f7d1da":"code","c1e2cc94":"code","26c91137":"code","3b768429":"code","da15a0ea":"code","01aaacaa":"code","0b1f52ec":"code","bb66d685":"code","5a44457e":"code","eaa027cb":"code","be80d870":"markdown","64483685":"markdown","3313a3de":"markdown","cb9e3039":"markdown","2e97129b":"markdown","8f3b9dfc":"markdown","ba791b32":"markdown","44b95f76":"markdown","84d8d717":"markdown","38d99b70":"markdown","e3d2b28e":"markdown"},"source":{"6ea15dd6":"import numpy as np\nimport pandas as pd\nimport os\nfrom fastai.vision import *","77660d5a":"print(os.listdir('..\/input\/severstal-steel-defect-detection'))","82d53593":"comp_dir = Path('..\/input\/severstal-steel-defect-detection')","e8a424e1":"train_df = pd.read_csv(comp_dir\/'train.csv')\ntrain_df.head(20)","6d5128ab":"labels = []\nfor i in range(len(train_df)):\n    if type(train_df.EncodedPixels[i]) == str:\n        labels.append(1)\n    else:\n        labels.append(0)\nlabels = np.array(labels)\nlabels = labels.reshape((int(len(train_df)\/4),4))","3d961c21":"print(labels.shape)","e5ae6a45":"label_0 = np.array(len(labels) - np.sum(np.sum(labels,axis=0)))\nbar_plot = np.append(label_0[None].T,np.sum(labels,axis=0))\nplt.bar(np.array(['none','0','1','2','3']),bar_plot)","80ec5b9f":"label_0\/len(train_df)","1fec9f38":"bar_plot[3]\/len(train_df)","99dcdfe6":"images_df = pd.DataFrame(train_df.iloc[::4,:].ImageId_ClassId.str[:-2].reset_index(drop=True))\nlabels_df = pd.DataFrame(labels.astype(int))","f2e00d33":"proc_train_df= pd.concat((images_df,labels_df),1)\nproc_train_df","12f7d1da":"data = (ImageList.from_df(proc_train_df,path=comp_dir,folder='train_images')\n        .split_by_rand_pct(0.2)\n        .label_from_df(cols=[1,2,3,4])\n        .transform(get_transforms())\n        .databunch(bs=16)\n       )","c1e2cc94":"#data.show_batch()","26c91137":"data.train_ds[0][0].shape","3b768429":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/tmp\/.cache\/torch\/checkpoints\/'):\n        os.makedirs('\/tmp\/.cache\/torch\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth'","da15a0ea":"from fastai.metrics import *\nlearn = cnn_learner(data,models.resnet50,metrics=accuracy_thresh)\nlearn.model_dir = Path('..\/models')","01aaacaa":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","0b1f52ec":"learn.fit_one_cycle(1,2e-2)","bb66d685":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","5a44457e":"learn.fit_one_cycle(5,slice(1e-6,1e-3))","eaa027cb":"print(learn.validate())","be80d870":"## Training a classifier\n\nLet's create a classifier using fastai.","64483685":"Let's now convert this to something fastai can view.","3313a3de":"We can see that the images have a fixed size of 256x1600.","cb9e3039":"### Conversion to classification\n\nI believe that one possible strategy for this competition would be to perhaps first create a classifier and have separate segmentation models for each of the defect types. As a first step to do this, I reformat the data, converting it into a multi-label classification problem.","2e97129b":"## EDA","8f3b9dfc":"Let's load into fastai:","ba791b32":"Let's look at the training set csv file:","44b95f76":"# Introduction\n\nWelcome to the Severstal: Steel Defect Detection competition. This competition is a two-fold competition: classify the type of steel defect, and also segment the parts of the image that contain the defect.\n\nIn this kernel, I will do a quick EDA and then I will convert to a classification problem for future kernels.\n","84d8d717":"Looking at this we can see that the format is to fill in the EncodedPixels columens only at the rows  for the identified class for the selected image. For example, 0002cc93b.jpg has a label of 1, 00031f466.jpg has no defects, and 0007a71bf.jpg has a label of 3.","38d99b70":"Lazy conversion to classification labels:","e3d2b28e":"1. Most common is no defect, and defect of type 2. In fact we see that 10% of the labels have no label and 10% have are label of type 2:\n\n"}}