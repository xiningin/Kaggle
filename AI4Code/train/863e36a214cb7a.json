{"cell_type":{"c12bdbf0":"code","01c7963d":"code","2963d1c3":"code","5287a4db":"code","66be783b":"code","ad302148":"code","17f8ae80":"code","f3b1f0a8":"code","4f0c68bc":"code","cf0e0cf9":"code","f3b86d55":"code","e736a77f":"code","64a7df69":"code","cf2a6f44":"code","a2ce6e2a":"code","152a9b99":"code","d43b5f76":"code","d55ad89f":"code","4245e3a0":"code","d1e2839d":"code","d4f0aecf":"code","bd1282f1":"code","c4d6c4d3":"code","a9f0bb27":"code","391e1c5d":"code","24571724":"code","4d3da3aa":"code","ffab92ce":"code","277f2543":"code","861072a9":"code","85ff2603":"code","fda019d1":"code","aa7d4821":"code","78e077c8":"code","ad46e622":"code","fcaecf98":"code","2699c789":"markdown","a80c1629":"markdown","33a814b6":"markdown","be4b307f":"markdown"},"source":{"c12bdbf0":"# import the required libraries\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","01c7963d":"# function that would read an image provided the image path, preprocess and return it back\n\ndef read_and_preprocess(img_path):\n    img = cv2.imread(img_path, cv2.IMREAD_COLOR) # reading the image\n    img = cv2.resize(img, (256, 256)) # resizing it (I just like it to be powers of 2)\n    img = np.array(img, dtype='float32') # convert its datatype so that it could be normalized\n    img = img\/255 # normalization (now every pixel is in the range of 0 and 1)\n    return img","2963d1c3":"X_train = [] # To store train images\ny_train = [] # To store train labels\n\n# labels -\n# 0 - Covid\n# 1 - Viral Pneumonia\n# 2 - Normal\n\ntrain_path = \"..\/input\/covid19-image-dataset\/Covid19-dataset\/train\/\" # path containing training image samples","5287a4db":"for folder in os.scandir(train_path):\n    for entry in os.scandir(train_path + folder.name):\n\n        X_train.append(read_and_preprocess(train_path + folder.name + '\/' + entry.name))\n        \n        if folder.name[0]=='C':\n            y_train.append(0)\n        elif folder.name[0]=='V':\n            y_train.append(1)\n        else:\n            y_train.append(2)","66be783b":"X_train = np.array(X_train)\nX_train.shape # We have 251 training samples in total","ad302148":"y_train = np.array(y_train)\ny_train.shape","17f8ae80":"covid_count = len(y_train[y_train==0])\npneumonia_count = len(y_train[y_train==1])\nnormal_count = len(y_train[y_train==2])\n\nplt.title(\"Train Images for Each Label\")\nplt.bar([\"Covid\", \"Viral Pneumonia\", \"Normal\"],[covid_count, pneumonia_count, normal_count])\n\n# We have more number of covid samples that Pneumonia and Normal","f3b1f0a8":"# Plotting 2 images per disease\n\nimport random\n\ntitle = {0:\"Covid\", 1:\"Viral Pneumonia\", 2:\"Normal\"}\n\nrows = 2\ncolumns = 3\n\nfor i in range(2):\n    \n    fig = plt.figure(figsize=(7,7))\n    \n    fig.add_subplot(rows, columns, 1)\n    pos = random.randint(0, covid_count)\n    plt.imshow(X_train[pos])\n    plt.title(title[y_train[pos]])\n    \n    fig.add_subplot(rows, columns, 2)\n    pos = random.randint(covid_count, covid_count+pneumonia_count)\n    plt.imshow(X_train[pos])\n    plt.title(title[y_train[pos]])\n    \n    fig.add_subplot(rows, columns, 3)\n    pos = random.randint(covid_count+pneumonia_count, covid_count+pneumonia_count+normal_count)\n    plt.imshow(X_train[pos])\n    plt.title(title[y_train[pos]])","4f0c68bc":"plt.imshow(X_train[0])","cf0e0cf9":"X_new = np.fliplr(X_train[0])\nplt.imshow(X_new)","f3b86d55":"X_aug = []\ny_aug = []\n\nfor i in range(0, len(y_train)):\n    X_new = np.fliplr(X_train[i])\n    X_aug.append(X_new)\n    y_aug.append(y_train[i])","e736a77f":"X_aug = np.array(X_aug)\ny_aug = np.array(y_aug)","64a7df69":"X_train = np.append(X_train, X_aug, axis=0) # appending augmented images to original training samples\nX_train.shape","cf2a6f44":"y_train = np.append(y_train, y_aug, axis=0)\ny_train.shape","a2ce6e2a":"X_val = [] # To store validation and test images\ny_val = [] # To store validation and test labels\n\nval_path = '..\/input\/covid19-image-dataset\/Covid19-dataset\/test\/'\n\nfor folder in os.scandir(val_path):\n    for entry in os.scandir(val_path + folder.name):\n\n        X_val.append(read_and_preprocess(val_path + folder.name + '\/' + entry.name))\n        \n        if folder.name[0]=='C':\n            y_val.append(0)\n        elif folder.name[0]=='V':\n            y_val.append(1)\n        else:\n            y_val.append(2)\n            \nX_val = np.array(X_val)\ny_val = np.array(y_val)","152a9b99":"X_val.shape # We have 66 images for validation and testing","d43b5f76":"covid_count = len(y_val[y_val==0])\npneumonia_count = len(y_val[y_val==1])\nnormal_count = len(y_val[y_val==2])\n\nplt.title(\"Validation Images for Each Label\")\nplt.bar([\"Covid\", \"Viral Pneumonia\", \"Normal\"],[covid_count, pneumonia_count, normal_count])\n\n# We have more number of covid samples that Pneumonia and Normal in test dataset as well","d55ad89f":"# Get the ResNet50 base model\nbasemodel = VGG16(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256, 256, 3)))","4245e3a0":"basemodel.summary()","d1e2839d":"# freeze the model weights\n\nfor layer in basemodel.layers:\n  layers.trainable = False","d4f0aecf":"# Add classification head to the base model\n\nheadmodel = basemodel.output\nheadmodel = Flatten(name= 'flatten')(headmodel)\nheadmodel = Dense(3, activation = 'softmax')(headmodel)\n\nmodel = Model(inputs = basemodel.input, outputs = headmodel)","bd1282f1":"model.summary()","c4d6c4d3":"opt = optimizers.Adam(learning_rate=0.0001)","a9f0bb27":"# compile the model\nmodel.compile(loss = 'sparse_categorical_crossentropy', optimizer=opt, metrics= [\"accuracy\"])","391e1c5d":"# use early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\nearlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n\n# save the best model with least validation loss\ncheckpointer = ModelCheckpoint(filepath=\"covid_classifier_weights.h5\", verbose=1, save_best_only=True)","24571724":"history = model.fit(X_train, y_train, epochs = 100, validation_data=(X_val, y_val), batch_size=16, shuffle=True, callbacks=[earlystopping, checkpointer])","4d3da3aa":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","ffab92ce":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","277f2543":"# save the model architecture to json file for future use\n\nmodel_json = model.to_json()\nwith open(\"covid_classifier_model.json\",\"w\") as json_file:\n  json_file.write(model_json)","861072a9":"# Load pretrained model (best saved one)\nwith open('covid_classifier_model.json', 'r') as json_file:\n    json_savedModel= json_file.read()\n# load the model  \nmodel = tf.keras.models.model_from_json(json_savedModel)\nmodel.load_weights('covid_classifier_weights.h5')\nmodel.compile(loss = 'sparse_categorical_crossentropy', optimizer=opt, metrics= [\"accuracy\"])","85ff2603":"predictions = model.predict(X_val)","fda019d1":"predictions.shape","aa7d4821":"# Obtain the predicted class from the model prediction\npredict = []\n\nfor i in predictions:\n  predict.append(np.argmax(i))\n\npredict = np.asarray(predict)","78e077c8":"# Obtain the accuracy of the model\nfrom sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_val, predict)\naccuracy","ad46e622":"# plot the confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_val, predict)\nplt.figure(figsize = (7,7))\nsns.heatmap(cm, annot=True, cmap='Blues')\n\n# The model misclassified one Normal case as Pneumonia","fcaecf98":"from sklearn.metrics import classification_report\n\nreport = classification_report(y_val, predict)\nprint(report)","2699c789":"## Loading the Validation and Test Images","a80c1629":"## Image Augmentation","33a814b6":"## Visualizing the Dataset","be4b307f":"## Evaluating the Saved Model Performance"}}