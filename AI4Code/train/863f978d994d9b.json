{"cell_type":{"30e17a90":"code","2261bcbc":"code","2feff894":"code","c3dcecb7":"code","b3a8ac6d":"code","d2f5ccc5":"code","6a84989c":"code","fe5403a2":"code","28865157":"markdown","fa9aa98a":"markdown","6d704bdc":"markdown","c7924274":"markdown","b5643661":"markdown","a47463ae":"markdown","7b3a5a91":"markdown","ac85f02b":"markdown","7133f14b":"markdown","701aa1b1":"markdown"},"source":{"30e17a90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\n\n#ui\nimport matplotlib.pyplot as plt\n\n#gc\nimport gc \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2261bcbc":"from IPython.display import clear_output\n!pip install keras-ocr --user\nclear_output()\n\nimport keras_ocr","2feff894":"#Code by Blue7Red https:\/\/www.kaggle.com\/rhythmcam\/ocr-basic-keras-ocr-usage\n\npath = Path('..\/input\/gorickyourself\/Ricks')\nfilepaths = list(path.glob(r'**\/*.png'))\nfilepaths = filepaths[:20] # total data size only 30 \ngc.collect()","c3dcecb7":"#Code by Blue7Red https:\/\/www.kaggle.com\/rhythmcam\/ocr-basic-keras-ocr-usage\n\ncolumn_filepath = pd.Series(filepaths, name='image_path').astype(str)\ntrain = pd.DataFrame(column_filepath)\ntrain= train.sample(frac = 1).reset_index(drop=True) # all shuffle \ntrain.head()","b3a8ac6d":"#Code by Blue7Red https:\/\/www.kaggle.com\/rhythmcam\/ocr-basic-keras-ocr-usage\n\n\nf,a = plt.subplots(nrows=2, ncols=3,figsize=(15, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(a.flat):\n    path = train.iloc[i][\"image_path\"]\n    print(\"path=\",path)\n    ax.imshow(keras_ocr.tools.read(path))\n    ax.set_title(\"image\")\n    \nplt.tight_layout()\nplt.show()","d2f5ccc5":"#Code by Blue7Red https:\/\/www.kaggle.com\/rhythmcam\/ocr-basic-keras-ocr-usage\n\nimage_path_list = train[:3][\"image_path\"]\nimages = [ keras_ocr.tools.read(image_path) for image_path in image_path_list]\n\ngc.collect()","6a84989c":"#Code by Blue7Red https:\/\/www.kaggle.com\/rhythmcam\/ocr-basic-keras-ocr-usage\n\npipeline = keras_ocr.pipeline.Pipeline() \nkeras_ocr_preds = pipeline.recognize(images)\n\ngc.collect()","fe5403a2":"#Code by Blue7Red https:\/\/www.kaggle.com\/rhythmcam\/ocr-basic-keras-ocr-usage\n\nfig,axs = plt.subplots(nrows = 3 , figsize = (20,20))\nfor ax , image,  pred in zip(axs , images , keras_ocr_preds):\n    keras_ocr.tools.drawAnnotations(image, pred, ax)\n    \ngc.collect()","28865157":"#Get image data using keras_ocr.","fa9aa98a":"#Drawing ocr info on the image","6d704bdc":"![](https:\/\/i.ytimg.com\/vi\/WtEhQvVUdH4\/maxresdefault.jpg)OCR - Optical Character Recognition (OCR).","c7924274":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #1E90FF;\"><b style=\"color:white;\">Optical Character Recognition - OCR)<\/b><\/h1><\/center>\n\n\n\"This project explores low cost methods for pre-training AI models for more complex problems. Generating training data with human work is very slow and costly, but if the problem can be simulated using other tools, then limitless, cheap and unique training data can be generated. This implementation generates images of letters to train a Keras model. After training exclusively on generated images, it is able to achieve 46% accuracy on a hand labeled set of images from building and road signs.\"\n\nhttps:\/\/github.com\/royceschultz\/Optical-Character-Recognition","b5643661":"#Acknowledgement:\n\nCode by Blue7Red https:\/\/www.kaggle.com\/rhythmcam\/ocr-basic-keras-ocr-usage\n","a47463ae":"#Change nrows to 3 instead of 6.","7b3a5a91":"#Show six Images.","ac85f02b":"#Your notebook tried to allocate more memory than is available. It has restarted.","7133f14b":"#Converting to dataframe and shuffle","701aa1b1":"#Getting ocr prediction using keras_ocr pipeline"}}