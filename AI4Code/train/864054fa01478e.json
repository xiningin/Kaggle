{"cell_type":{"2b038ae0":"code","30983f77":"code","fad70788":"code","8718f738":"code","03ab0794":"code","e099a8b9":"code","b9e6cb29":"code","4f5af64c":"code","d6c47a4d":"code","38e539ae":"code","692e9081":"code","56d505ae":"code","9cecaa5b":"code","9dda0199":"code","83384d5f":"code","d61ee7dc":"code","c95c9d52":"code","a7e18a22":"code","5465b046":"code","1a52f803":"code","5e2c5283":"code","1d54ad17":"code","412d3820":"code","e34a8841":"code","82a9ad6e":"code","e204c097":"code","4081b172":"code","75cb1465":"code","99d8b959":"code","6d3d178e":"code","53c5a892":"code","ec62e51d":"code","54ae4bc0":"code","acc01c85":"code","4cee65e8":"code","3db2389c":"code","810f94e2":"code","d5bf8633":"code","9b42a7b3":"code","27c4ba75":"code","c597ed5a":"code","80e91d95":"code","bc9dba91":"code","ccc014cd":"code","bec8fdac":"code","a72daa0c":"code","f1c760f7":"code","058c075b":"code","92f89cf6":"code","be55ef82":"code","5d23bb29":"code","5aeb531a":"code","c679d83c":"code","9ad817b4":"code","51b04de5":"code","972fefe1":"code","7c07f96d":"code","f4d2e6f1":"code","5e4cfa39":"code","45b3b876":"markdown","abdd9262":"markdown","30a66e31":"markdown","b412156e":"markdown","2b2a47bd":"markdown"},"source":{"2b038ae0":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom pdpbox import pdp, get_dataset, info_plots\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n\nimport string\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom collections import Counter\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nimport eli5\nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output.","30983f77":"df_kick = pd.read_csv(\"..\/input\/ks-projects-201801.csv\",parse_dates = [\"launched\", \"deadline\"])\n","fad70788":"df_kick.shape","8718f738":"df_kick.columns","03ab0794":"df_kick.info()","e099a8b9":"df_kick.tail()","b9e6cb29":"print(df_kick.shape)\ndf_kick = df_kick.dropna()\nprint(df_kick.shape)\n# projects = projects[projects[\"currency\"] == \"USD\"]\n# projects = projects[projects[\"state\"].isin([\"failed\", \"successful\"])]\n# projects = projects.drop([\"backers\", \"ID\", \"currency\", \"country\", \"pledged\", \"usd pledged\", \"usd_pledged_real\", \"usd_goal_real\"], axis = 1)","4f5af64c":"def syllable_count(word):\n    word = word.lower()\n    vowels = \"aeiouy\"\n    count = 0\n    if word[0] in vowels:\n        count += 1\n    for index in range(1, len(word)):\n        if word[index] in vowels and word[index - 1] not in vowels:\n            count += 1\n    if word.endswith(\"e\"):\n        count -= 1\n    if count == 0:\n        count += 1\n    return count\n","d6c47a4d":"## feature engineering\ndf_kick[\"syllable_count\"]   = df_kick[\"name\"].apply(lambda x: syllable_count(x))\ndf_kick[\"launched_month\"]   = df_kick[\"launched\"].dt.month\ndf_kick[\"launched_week\"]    = df_kick[\"launched\"].dt.week\ndf_kick[\"launched_day\"]     = df_kick[\"launched\"].dt.weekday\ndf_kick['launched_quarter'] = df_kick['launched'].dt.quarter\ndf_kick['launched_year']    = df_kick['launched'].dt.year\ndf_kick[\"is_weekend\"]       = df_kick[\"launched_day\"].apply(lambda x: 1 if x > 4 else 0)\ndf_kick[\"num_words\"]        = df_kick[\"name\"].apply(lambda x: len(x.split()))\ndf_kick[\"num_chars\"]        = df_kick[\"name\"].apply(lambda x: len(x.replace(\" \",\"\")))\ndf_kick[\"duration\"]         = df_kick[\"deadline\"] - df_kick[\"launched\"]\ndf_kick[\"duration\"]         = df_kick[\"duration\"].apply(lambda x: int(str(x).split()[0]))\ndf_kick[\"state\"]            = df_kick[\"state\"].apply(lambda x: 1 if x==\"successful\" else 0)\n\n#length of name\ndf_kick['name_len'] = df_kick.name.str.len()\n\n# presence of !\ndf_kick['name_exclaim'] = (df_kick.name.str[-1] == '!').astype(int)\n\n# presence of !\ndf_kick['name_question'] = (df_kick.name.str[-1] == '?').astype(int)\n\n# number of words in the name\ndf_kick['name_words'] = df_kick.name.apply(lambda x: len(str(x).split(' ')))\n\n# if name is uppercase\ndf_kick['name_is_upper'] = df_kick.name.str.isupper().astype(float)\n\n#additional features from goal, pledge and backers columns\ndf_kick.loc[:,'goal_reached'] = df_kick['pledged'] \/ df_kick['goal'] # Pledged amount as a percentage of goal.\n#The above field will be used to compute another metric\n# In backers column, impute 0 with 1 to prevent undefined division.\ndf_kick.loc[df_kick['backers'] == 0, 'backers'] = 1 \ndf_kick.loc[:,'pledge_per_backer'] = df_kick['pledged'] \/ df_kick['backers'] \n# Pledged amount per backer.\n#will create percentile buckets for the goal amount in a category\ndf_kick['goal_cat_perc'] =  df_kick.groupby(['category'])['goal'].transform(\n                     lambda x: pd.qcut(x, [0, .35, .70, 1.0], labels =[1,2,3]))\n\n#will create percentile buckets for the duration in a category\ndf_kick['duration_cat_perc'] =  df_kick.groupby(['category'])['duration'].transform(\n                     lambda x: pd.qcut(x, [0, .35, .70, 1.0], labels =False, duplicates='drop'))","38e539ae":"#creating a metric to see number of competitors for a given project in a given quarter\n#number of participants in a given category, that launched in the same year and quarter and in the same goal bucket\nks_particpants_qtr=df_kick.groupby(['category','launched_year','launched_quarter','goal_cat_perc']).count()\nks_particpants_qtr=ks_particpants_qtr[['name']]\n#since the above table has all group by columns created as index, converting them into columns\nks_particpants_qtr.reset_index(inplace=True)\n\n#creating a metric to see number of competitors for a given project in a given month\n#number of participants in a given category, that launched in the same year and month and in the same goal bucket\nks_particpants_mth=df_kick.groupby(['category','launched_year','launched_month','goal_cat_perc']).count()\nks_particpants_mth=ks_particpants_mth[['name']]\n#since the above table has all group by columns created as index, converting them into columns\nks_particpants_mth.reset_index(inplace=True)\n\n#creating a metric to see number of competitors for a given project in a given week\n#number of participants in a given category, that launched in the same year and week and in the same goal bucket\nks_particpants_wk=df_kick.groupby(['category','launched_year','launched_week','goal_cat_perc']).count()\nks_particpants_wk=ks_particpants_wk[['name']]\n#since the above table has all group by columns created as index, converting them into columns\nks_particpants_wk.reset_index(inplace=True)\n\n#renaming columns of the derived table\ncolmns_qtr=['category', 'launched_year', 'launched_quarter', 'goal_cat_perc', 'participants_qtr']\nks_particpants_qtr.columns=colmns_qtr\n\ncolmns_mth=['category', 'launched_year', 'launched_month', 'goal_cat_perc', 'participants_mth']\nks_particpants_mth.columns=colmns_mth\n\ncolmns_wk=['category', 'launched_year', 'launched_week', 'goal_cat_perc', 'participants_wk']\nks_particpants_wk.columns=colmns_wk\n","692e9081":"#creating 2 metrics to get average pledge per backer for a category in a year according to the goal bucket it lies in and the success rate ie average pledged to goal ratio for the category and goal bucket in this year\n#using pledge_per_backer (computed earlier) and averaging it by category in a launch year\nks_ppb_goal=pd.DataFrame(df_kick.groupby(['category','launched_year','goal_cat_perc'])['pledge_per_backer','goal_reached'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nks_ppb_goal.reset_index(inplace=True)\n#renaming column\nks_ppb_goal.columns= ['category','launched_year','goal_cat_perc','avg_ppb_goal','avg_success_rate_goal']\n\n#creating a metric: the success rate ie average pledged to goal ratio for the category in this year\nks_ppb_duration=pd.DataFrame(df_kick.groupby(['category','launched_year','duration_cat_perc'])['goal_reached'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nks_ppb_duration.reset_index(inplace=True)\n#renaming column\nks_ppb_duration.columns= ['category','launched_year','duration_cat_perc','avg_success_rate_duration']","56d505ae":"#creating 2 metrics to get average pledge per backer for a category in a year according to the goal bucket it lies in and the success rate ie average pledged to goal ratio for the category and goal bucket in this year\n#using pledge_per_backer (computed earlier) and averaging it by category in a launch year\nks_ppb_goal=pd.DataFrame(df_kick.groupby(['category','launched_year','goal_cat_perc'])['pledge_per_backer','goal_reached'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nks_ppb_goal.reset_index(inplace=True)\n#renaming column\nks_ppb_goal.columns= ['category','launched_year','goal_cat_perc','avg_ppb_goal','avg_success_rate_goal']\n\n#creating a metric: the success rate ie average pledged to goal ratio for the category in this year\nks_ppb_duration=pd.DataFrame(df_kick.groupby(['category','launched_year','duration_cat_perc'])['goal_reached'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nks_ppb_duration.reset_index(inplace=True)\n#renaming column\nks_ppb_duration.columns= ['category','launched_year','duration_cat_perc','avg_success_rate_duration']","9cecaa5b":"#merging the particpants column into the base table\ndf_kick = pd.merge(df_kick, ks_ppb_goal, on = ['category', 'launched_year','goal_cat_perc'], how = 'left')\ndf_kick = pd.merge(df_kick, ks_ppb_duration, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')","9dda0199":"#merging the particpants column into the base table\ndf_kick = pd.merge(df_kick, ks_particpants_qtr, on = ['category', 'launched_year', 'launched_quarter','goal_cat_perc'], how = 'left')\ndf_kick = pd.merge(df_kick, ks_particpants_mth, on = ['category', 'launched_year', 'launched_month','goal_cat_perc'], how = 'left')\ndf_kick = pd.merge(df_kick, ks_particpants_wk, on = ['category', 'launched_year', 'launched_week','goal_cat_perc'], how = 'left')","83384d5f":"#creating 2 metrics: mean and median goal amount\nmedian_goal_cat=pd.DataFrame(df_kick.groupby(['category','launched_year','duration_cat_perc'])['goal'].median())\n#since the above table has all group by columns created as index, converting them into columns\nmedian_goal_cat.reset_index(inplace=True)\n#renaming column\nmedian_goal_cat.columns= ['category','launched_year','duration_cat_perc','median_goal_year']\n\nmean_goal_cat=pd.DataFrame(df_kick.groupby(['category','launched_year','duration_cat_perc'])['goal'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nmean_goal_cat.reset_index(inplace=True)\n#renaming column\nmean_goal_cat.columns= ['category','launched_year','duration_cat_perc','mean_goal_year']","d61ee7dc":"#merging the particpants column into the base table\ndf_kick = pd.merge(df_kick, median_goal_cat, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')\ndf_kick = pd.merge(df_kick, mean_goal_cat, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')","c95c9d52":"print(df_kick.shape)\ndf_kick[:3]","a7e18a22":"# replacing all 'N,0\"' values in the country column with 'NZERO' to avoid discrepancies while one hot encoding\ndf_kick = df_kick.replace({'country': 'N,0\"'}, {'country': 'NZERO'}, regex=True)","5465b046":"list(df_kick)","1a52f803":"df_kick.columns","5e2c5283":"#selecting the needed fields only\n#this will lead to the final features list\n\n#creating a list of columns to be dropped\ndrop_columns= ['ID','name','launched','deadline','usd pledged','usd_pledged_real','pledge_per_backer','goal_reached']\n#dropping columns above\nkick = df_kick.copy()\ndf_kick.drop(drop_columns, axis=1, inplace=True)","1d54ad17":"#these functions will be used on the textual column entries to remove '&','-' or white spaces\ndef replace_ampersand(val):\n    if isinstance(val, str):\n        return(val.replace('&', 'and'))\n    else:\n        return(val)\n\ndef replace_hyphen(val):\n    if isinstance(val, str):\n        return(val.replace('-', '_'))\n    else:\n        return(val)    \n    \ndef remove_extraspace(val):\n        if isinstance(val, str):\n            return(val.strip())\n        else:\n            return(val) \n\ndef replace_space(val):\n        if isinstance(val, str):\n            return(val.replace(' ', '_'))\n        else:\n            return(val)","412d3820":"#apply those functions to all cat columns\n#this will remove special characters from the character columns.\n#Since these fields will be one-hot encoded, the column names so derived should be compatible with the requied format\ndf_kick['category'] = df_kick['category'].apply(remove_extraspace)\ndf_kick['category'] = df_kick['category'].apply(replace_ampersand)\ndf_kick['category'] = df_kick['category'].apply(replace_hyphen)\ndf_kick['category'] = df_kick['category'].apply(replace_space)\n\ndf_kick['main_category'] = df_kick['main_category'].apply(remove_extraspace)\ndf_kick['main_category'] = df_kick['main_category'].apply(replace_ampersand)\ndf_kick['main_category'] = df_kick['main_category'].apply(replace_hyphen)\ndf_kick['main_category'] = df_kick['main_category'].apply(replace_space)","e34a8841":"#missing value treatment\n# Check for nulls.\ndf_kick.isnull().sum()","82a9ad6e":"#creating a backup copy of the dataset\ndf_kick_copy= df_kick.copy()\n\ndf_kick_copy[:5]","e204c097":"for c in df_kick.columns:\n    #this gives us the list of columns and the respective data types\n    col_type = df_kick[c].dtype\n    #looking through all categorical columns in the list above\n    if col_type == 'object' :\n        a=df_kick[c].unique()\n        keys= range(a.shape[0])\n        #initiating a dictionary\n        diction={}\n        for idx,val in enumerate(a):\n        #looping through to create the dictionary with mappings\n            diction[idx] = a[idx]\n        #the above step maps integers to the values in the column\n        # hence inverting the key-value pairs\n        diction = {v: k for k, v in diction.items()}\n        print(diction)\n        # creating a dictionary for mapping the values to integers\n        df_kick_copy[c] = [diction[item] for item in df_kick_copy[c]] \n        # converting data type to 'category'\n        df_kick_copy[c] = df_kick_copy[c].astype('category')","4081b172":"# One-Hot encoding to convert categorical columns to numeric\nprint('start one-hot encoding')\n\ndf_kick_ip = pd.get_dummies(df_kick, prefix = [ 'category', 'main_category', 'currency','country'],\n                             columns = [ 'category', 'main_category', 'currency','country'])\n    \n#this will have created 1-0 flag columns (like a sparse matrix)    \nprint('ADS dummy columns made')","75cb1465":"df_kick_ip.columns","99d8b959":"#creating 2 arrays: features and response\n\n#features will have all independent variables\nfeatures=list(df_kick_ip)\nfeatures.remove('state')\n#response has the target variable\nresponse= ['state']","6d3d178e":"#creating a backup copy of the input dataset\ndf_kick_ip_copy= df_kick_ip.copy()","53c5a892":"df_kick_ip_copy.shape","ec62e51d":"# normalize the data attributes\ndf_kick_ip_scaled_ftrs = pd.DataFrame(preprocessing.normalize(df_kick_ip[features]))\ndf_kick_ip_scaled_ftrs.columns=list(df_kick_ip[features])","54ae4bc0":"df_kick_ip_scaled_ftrs[:3]\n#kick_projects_ip[features].shape","acc01c85":"#creating test and train dependent and independent variables\n#Split the data into test and train (30-70: random sampling)\n#will be using the scaled dataset to split \ntrain_ind, test_ind, train_dep, test_dep = train_test_split(df_kick_ip_scaled_ftrs, df_kick_ip[response], test_size=0.3, random_state=0)","4cee65e8":"from sklearn.neighbors import KNeighborsClassifier","3db2389c":"knn = KNeighborsClassifier()\nknn.fit(train_ind, train_dep)\n\nacc_knn = round(knn.score(test_ind, test_dep) * 100, 2)\nacc_knn","810f94e2":"import math","d5bf8633":"features_count = train_ind.shape[1]\n\nparameters_rf = {'n_estimators':[50], 'max_depth':[20], 'max_features': \n                     [math.floor(np.sqrt(features_count)), math.floor(features_count\/3)]}\n\ndef random_forest_classifier(features, target):\n    \"\"\"\n    To train the random forest classifier with features and target data\n    :param features:\n    :param target:\n    :return: trained random forest classifier\n    \"\"\"\n    clf = RandomForestClassifier(n_estimators=50,criterion='gini' ,max_depth=20, max_features=2)\n    clf.fit(features, target)\n    return clf","9b42a7b3":"trained_model_RF= random_forest_classifier(train_ind[features], train_dep[response])","27c4ba75":"# Predict the on the train_data\ntest_ind[\"Pred_state_RF\"] = trained_model_RF.predict(test_ind[features])\n\n# Predict the on the train_data\ntrain_ind[\"Pred_state_RF\"] = trained_model_RF.predict(train_ind[features])\n\n# Predict the on the train_data\ndf_kick_ip[\"Pred_state_RF\"] = trained_model_RF.predict(df_kick_ip_scaled_ftrs)","c597ed5a":"# Train and Test Accuracy\nprint (\"Train Accuracy :: \", accuracy_score(train_dep[response], trained_model_RF.predict(train_ind[features])))\nprint (\"Test Accuracy  :: \", accuracy_score(test_dep[response], trained_model_RF.predict(test_ind[features])))\nprint (\"Complete Accuracy  :: \", accuracy_score(df_kick_ip[response], trained_model_RF.predict(df_kick_ip_scaled_ftrs)))\nprint (\" Confusion matrix of complete data is\", confusion_matrix(df_kick_ip[response],df_kick_ip[\"Pred_state_RF\"]))","80e91d95":"## Feature importances\nftr_imp_rf=zip(features,trained_model_RF.feature_importances_)\nfor values in ftr_imp_rf:\n    print(values)","bc9dba91":"feature_imp_RF=pd.DataFrame(list(zip(features,trained_model_RF.feature_importances_)))\ncolumn_names_RF= ['features','RF_imp']\nfeature_imp_RF.columns= column_names_RF","ccc014cd":"feature_imp_RF= feature_imp_RF.sort_values('RF_imp',ascending=False)\nfeature_imp_RF[:15]","bec8fdac":"df_kick[df_kick['state']=='successful']['backers'].value_counts()","a72daa0c":"df_kick['pledged_log'] = np.log(df_kick['usd_pledged_real'] + 1)\ndf_kick['goal_log'] = np.log(df_kick['usd_goal_real'] + 1)\ndf_kick['backers_log'] = np.log(df_kick['backers'] + 1)\n","f1c760f7":"sns.distplot(df_kick['backers_log'],kde=False)","058c075b":"sns.distplot(df_kick['goal_log'],kde=False)","92f89cf6":"sns.distplot(df_kick['pledged_log'],kde=False)","be55ef82":"df_kick[df_kick['usd pledged']!=df_kick['usd_pledged_real']]\n#         , 'usd_goal_real'']]","5d23bb29":"df_kick.head()","5aeb531a":"features","c679d83c":"kick.columns","9ad817b4":"kick.state.value_counts()","51b04de5":"kick['pledged_log'] = np.log(kick['usd_pledged_real'] + 1)\nkick['goal_log'] = np.log(kick['usd_goal_real'] + 1)\nkick['backers_log'] = np.log(kick['backers'] + 1)\n","972fefe1":"sns.distplot(kick['backers_log'],kde=False)","7c07f96d":"sns.distplot(kick['pledged_log'],kde=False)","f4d2e6f1":"%matplotlib inline","5e4cfa39":"plt.figure(figsize=(20,10))\nfailed = kick[kick['state']==0][['pledged_log','backers_log']]\nsuccess = kick[kick['state']==1][['pledged_log','backers_log']]\n\nplt.scatter( failed['backers_log'],failed['pledged_log'], color='r', label='failed',alpha=0.3)\nplt.scatter( success['backers_log'],success['pledged_log'], color='g', label='successful',alpha=0.3)\n\nplt.xlabel('pledged_log')\nplt.ylabel('backers_log')\nplt.legend()\nplt.show()","45b3b876":"**Model Building**","abdd9262":"Key drivers from Random Forest","30a66e31":"**Dataset Preprocessing**","b412156e":"**Random Forest Classifier**","2b2a47bd":"**KNN**"}}