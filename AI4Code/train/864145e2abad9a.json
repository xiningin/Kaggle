{"cell_type":{"14da199e":"code","5297412b":"code","c73c0ae1":"code","7cc0bbb3":"code","e3602732":"code","4169c5c5":"code","439bf2f3":"code","5abdf85d":"code","ed5c1f9d":"code","2fc127bb":"code","5ee725a1":"code","3bdb77f9":"code","232fc91d":"code","df99a25e":"code","1f2f3933":"code","4bf98125":"code","74f80ef6":"code","43d455b0":"code","de70e402":"code","74b764af":"code","6ca1c5c7":"code","23f9093d":"code","f43b718b":"code","fbedee91":"code","446d92f4":"markdown","2e5d367d":"markdown","c55d35bd":"markdown","8ed11390":"markdown","378b6fec":"markdown","72df6281":"markdown","21ca5bfd":"markdown","58b4a995":"markdown","9e00582c":"markdown","3df57b08":"markdown","3c0fb48f":"markdown","749481c3":"markdown","346bb285":"markdown"},"source":{"14da199e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5297412b":"import pandas as pd\npd.options.display.max_colwidth = 80\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\n\nfrom sklearn.svm import SVC # SVM model with kernels\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')","c73c0ae1":"data = '\/kaggle\/input\/car-evaluation-data-set\/car_evaluation.csv'\n\nheader_list = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class value']\n\ncars = pd.read_csv(data, names=header_list, index_col=None)","7cc0bbb3":"cars.head()","e3602732":"cars.describe()","4169c5c5":"cars.info(), cars.shape","439bf2f3":"for column in cars.columns:\n    print(cars[column].value_counts(), '\\n') ","5abdf85d":"a = cars.loc[cars['doors'] == '2', ['lug_boot']]\nb = cars.loc[cars['doors'] == '3', ['lug_boot']]\nc = cars.loc[cars['doors'] == '4', ['lug_boot']]\nd = cars.loc[cars['doors'] == '5more', ['lug_boot']]\n\nprint(a['lug_boot'].value_counts(), '\\n\\n', b['lug_boot'].value_counts(), '\\n\\n', \n      c['lug_boot'].value_counts(), '\\n\\n', d['lug_boot'].value_counts())","ed5c1f9d":"X = cars.drop(['class value'], axis=1)\ny = cars['class value']\n\nX, y","2fc127bb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)","5ee725a1":"X_train.shape, X_test.shape","3bdb77f9":"y_train.shape, y_test.shape","232fc91d":"columns_encode = []\ncolumns_encode.append(header_list)\ncolumns_encode","df99a25e":"ordinal_encoder = OrdinalEncoder()\n\nX_train = ordinal_encoder.fit_transform(X_train, columns_encode)\nX_test = ordinal_encoder.transform(X_test)","1f2f3933":"X_train, X_train.shape","4bf98125":"y_train, y_train.shape","74f80ef6":"param_grid = [{'kernel': ['poly'], 'C' : [3, 5, 7, 9, 10]},\n             {'kernel' : ['rbf'], 'C' : [3, 5, 7, 9, 10], 'gamma' : [2, 4, 6, 8]}]\n\nsvm = SVC()","43d455b0":"grid_search = GridSearchCV(svm, param_grid, return_train_score=True)\n\ngrid_search.fit(X_train, y_train)","de70e402":"grid_search.best_params_","74b764af":"grid_search.best_estimator_","6ca1c5c7":"svm_y_pred = grid_search.predict(X_test)\n\naccuracy_score(y_test, svm_y_pred)","23f9093d":"svm_y_pred_train = grid_search.predict(X_train)\n\naccuracy_score(y_train, svm_y_pred_train)","f43b718b":"confusion_matrix(y_test, svm_y_pred)","fbedee91":"print(classification_report(y_test, svm_y_pred))","446d92f4":"### Exploring Data","2e5d367d":"#### Fetching Data","c55d35bd":"#### Estimated best hyperparameters for SVM","8ed11390":"#### Confusion Matrix","378b6fec":"#### Feature and Target vectors","72df6281":"### Encoding\n#### There are a limited number of possible values, each of which represents a category, which means that all the variables in dataset are of ordinal categorical data type. Most Machine Learning algorithms prefer to work with numbers, so let\u2019s convert these categories from text to numbers. For this, we can use Scikit-Learn\u2019s OrdinalEncoder class:","21ca5bfd":"### All needed imports for this notebook","58b4a995":"#### I had an idea that number of doors can somehow correlate with luggage capacity, but seems that *lug_boot* value does not depended on that","9e00582c":"#### Using GridSearch to find the best hyperparameters","3df57b08":"#### GridSearcg estimated the best model to be with polynomial kernel of ninth degree","3c0fb48f":"#### **Destribution frequency of values in each variable.** Judging by the output, *stratified sampling* is not needed since all data instances seem to be evenly good splitted","749481c3":"## Support Vector Machines - Nonlinear Classification\n### with GridSearch","346bb285":"### Accuracy of training test is a little bit higher, but it's clearly not overfit, so I guess tthe model did very good"}}