{"cell_type":{"2d7f41cf":"code","c347caea":"code","197980cb":"code","597516f4":"code","28ea77ca":"code","79350235":"code","463c113c":"code","7f7fdf89":"code","80eacb7b":"code","23b50602":"code","213814de":"code","6c8795ad":"code","af43dc22":"code","8f2cf94e":"code","d91fc638":"code","8ca99379":"code","84663b5a":"code","12903989":"code","91d803bf":"code","a5e886d6":"code","3824f97c":"code","21fbd451":"code","47de5ce7":"code","a4a8b87d":"code","8138f34b":"code","f7c934a3":"code","c4b8732d":"code","26a5675c":"code","c23e2384":"code","4a6fa216":"code","b11b8b36":"code","8bc33c2a":"code","b02e1d64":"code","16e0a60e":"code","30e61a16":"code","7136f650":"code","55bdeca5":"code","f3f4041f":"code","e9952a63":"code","69f7bee2":"code","e2cd5143":"code","15844abf":"code","9bb34111":"code","7b5293f7":"code","b60895c7":"code","31977119":"code","d30a4c01":"code","e12e9cca":"code","af34675a":"code","74bf32e7":"code","635ae4e1":"code","724f8e6e":"code","3b6dc65f":"code","20619ffe":"code","edc358d5":"code","3c261af6":"code","7848a7ad":"code","f5be044b":"code","a9ee5769":"code","6646846c":"code","4ce3d939":"code","68982a79":"code","0bbf880d":"code","dfe7e372":"code","da1d9451":"code","b908be1b":"code","79ff94e1":"code","478711d0":"code","39837e10":"code","f75663cb":"code","52cb2505":"code","1c71dc8d":"code","5e243b37":"code","7688ca72":"code","2387e18f":"code","f1ec3718":"code","ad94e554":"code","4b234ddb":"code","a9c311b3":"code","f7a64597":"code","2601e475":"code","7caee874":"code","3900fb4a":"code","06d51d08":"code","02723526":"code","b76a7692":"code","fdd32354":"code","00144427":"code","844ec982":"code","ee359f50":"code","1f1e4f20":"code","85cd3cfd":"code","67bcc65f":"code","968762ef":"code","807ff082":"code","2f026ff6":"code","e14ba7ef":"code","00708b85":"code","24e76518":"code","d8c27045":"code","161b8bc6":"code","2c57d9c7":"code","d852aa15":"code","46b770fb":"markdown","98f2bbd5":"markdown","f18ce18b":"markdown","79bc4b69":"markdown","e8c88a96":"markdown","1c8cbcb6":"markdown","ae19cc26":"markdown","6af8014b":"markdown","3fd1ee1b":"markdown","1453e937":"markdown","5093b43f":"markdown","0a4efefe":"markdown","c777285b":"markdown","fd8f1c17":"markdown","934c8868":"markdown","f150586d":"markdown","ee2ca1eb":"markdown","87d8b1f0":"markdown","6f8fae45":"markdown","a6406d82":"markdown","7e659271":"markdown","ddac9ef1":"markdown","278ac6a8":"markdown","a0c3dd36":"markdown","80bd2055":"markdown","c735a221":"markdown","cb695dbf":"markdown","a2bfae29":"markdown","5c363dfd":"markdown","b1fab6eb":"markdown","61c60b01":"markdown","bb30dd26":"markdown","2142741b":"markdown","6f0b50f0":"markdown","76e54c6a":"markdown","02a35de8":"markdown","f1106d60":"markdown","24478d45":"markdown","f52d3387":"markdown","c5c593e7":"markdown","07fee966":"markdown","b46bf967":"markdown","5d715da5":"markdown","a0189618":"markdown","29477063":"markdown","8cb604db":"markdown","4a2f2745":"markdown","7eb3896b":"markdown","a0aa73c3":"markdown","f6c8c569":"markdown","a72cd8fa":"markdown","6faae871":"markdown","89234c27":"markdown","bce187ff":"markdown","1f7a41b3":"markdown","2af6f45a":"markdown"},"source":{"2d7f41cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c347caea":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random","197980cb":"%config Completer.use_jedi = False\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(rc={'figure.figsize':(18,10)})\n\n# Colors\ncyan = '#00FFD1'\nred = '#FF007D'\nprussian = '#0075FF'\ngreen = '#EEF622'\nyellow = '#FFF338'\nviolet = '#9B65FF'\norange = '#FFA500'\nblue = '#00EBFF'\nvermillion = '#FF6900'\n\nred2 = '#FF2626'\nseagreen = '#28FFBF'\ngreen2 = '#FAFF00'\nnavyblue = '#04009A'\n\ndarkgreen = '#206A5D'\nlightgreen = '#CCF6C8'\npink = '#F35588'\nmauve = '#BAABDA'\nlightblue = '#1CC5DC'\nmustard = '#FDB827'\ndeeppurple = '#723881'\n\n\n\ncolor_list = [cyan,red,prussian,green,violet,orange,yellow,blue,vermillion,red2,seagreen,green2,navyblue,darkgreen,lightgreen,pink,mauve,lightblue,mustard,deeppurple]\nplt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_list)","597516f4":"import matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib\nimport re\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom IPython.display import Markdown, display","28ea77ca":"def printmd(string):\n    display(Markdown(string))","79350235":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","463c113c":"train.head()","7f7fdf89":"test.head()","80eacb7b":"train.columns","23b50602":"test.columns","213814de":"train.isnull().sum()","6c8795ad":"test.isnull().sum()","af43dc22":"#train_initial = train.copy()\n#test_initial = test.copy()","8f2cf94e":"train = train.drop(['Cabin'],axis=1)\ntest = test.drop(['Cabin'],axis=1)","d91fc638":"sns.displot(data=train['Age'],kde=True,height=6.5,color=random.choice(color_list));","8ca99379":"train['Age'] = train['Age'].fillna(train['Age'].mean())\ntest['Age'] = test['Age'].fillna(train['Age'].mean())","84663b5a":"train['Embarked'].mode()","12903989":"train['Embarked'] = train['Embarked'].fillna('S')","91d803bf":"sns.displot(train['Fare'],bins=25,color=random.choice(color_list));","a5e886d6":"test['Fare'] = test['Fare'].fillna(train['Fare'].mode()[0])","3824f97c":"train.isnull().sum()","21fbd451":"test.isnull().sum()","47de5ce7":"train['Family'] = train['SibSp']+train['Parch']\ntest['Family'] = test['SibSp']+test['Parch']\ntrain=train.drop(['SibSp','Parch'],axis=1)\ntest=test.drop(['SibSp','Parch'],axis=1)","a4a8b87d":"train['Fare'] = train['Fare'].astype('int32')\ntest['Fare'] = test['Fare'].astype('int32')","8138f34b":"train['Age'] = train['Age'].astype('int32')\ntest['Age'] = test['Age'].astype('int32')","f7c934a3":"Ticket_temp_train = train['Ticket'].value_counts()\nTicket_temp_test = test['Ticket'].value_counts()","c4b8732d":"Ticket_temp_train_df = pd.DataFrame({'ticket':Ticket_temp_train.index,'freq':Ticket_temp_train.values})\nTicket_temp_test_df = pd.DataFrame({'ticket':Ticket_temp_test.index,'freq':Ticket_temp_test.values})","26a5675c":"def analyse_tickets(freq_to_stop_at,dataframe):\n    flag = 'none'\n    for i in range(0,len(Ticket_temp_train_df.iloc[:,:])): # iterating a number range\n        ticket_name = Ticket_temp_train_df.iloc[i,0]\n        ticket_freq = Ticket_temp_train_df.iloc[i,1]\n\n        if(flag != ticket_freq):\n            flag=ticket_freq\n            printmd('---')\n            printmd('### Ticket frequency: **%d**'%(ticket_freq))\n            \n    \n        if (ticket_freq!=freq_to_stop_at-1):\n            printmd(' #### *Ticket Name:* **%s**'%(ticket_name))\n            display(dataframe.loc[dataframe['Ticket']==ticket_name])\n            print('\\n\\n')# End of one number\n        \n        else:\n            break","c23e2384":"analyse_tickets(6,train) # Enter frequency to stop at and dataframe to work with","4a6fa216":"c = -1\ntick_1 = {}\nfor i in range(0,len(train['Ticket'])):\n    c=c+1\n    match = re.search('^[a-zA-Z]+',train.loc[i,'Ticket'])\n    if (match):\n        tick_1[c] = match.group()","b11b8b36":"tick1_s = pd.Series(tick_1)","8bc33c2a":"tick_prefix_train = []\nfor i in range(0,len(train['Ticket'])):\n    match = re.search('^[a-zA-Z]+',train.loc[i,'Ticket'])\n    if (match):\n        tick_prefix_train.append(match.group())\n    else:\n        tick_prefix_train.append('Null')\n        \n        \ntick_prefix_test = []\nfor i in range(0,len(test['Ticket'])):\n    match = re.search('^[a-zA-Z]+',test.loc[i,'Ticket'])\n    if (match):\n        tick_prefix_test.append(match.group())\n    else:\n        tick_prefix_test.append('Null')","b02e1d64":"train['Ticket_prefix'] = tick_prefix_train\ntest['Ticket_prefix'] = tick_prefix_test","16e0a60e":"train.head()","30e61a16":"Ticket_pre_df = pd.DataFrame({'prefix':train['Ticket_prefix'].value_counts().index, 'freq':train['Ticket_prefix'].value_counts().values})","7136f650":"def analyse_prefix(freq_to_stop_at,dataframe):\n    # booll - enter True if you want null too\n    flag = 'none'\n    for i in range(1,len(Ticket_pre_df)): # iterating a number range\n        ticket_name = Ticket_pre_df.iloc[i,0]\n        ticket_freq = Ticket_pre_df.iloc[i,1]\n\n        if(flag != ticket_freq):\n            flag=ticket_freq\n            printmd('---')\n            printmd('### Ticket frequency: **%d**'%(int(ticket_freq)))\n            \n    \n        if (ticket_freq!=freq_to_stop_at-1):\n            printmd(' #### *Ticket Name:* **%s**'%(ticket_name))\n            display(dataframe.loc[dataframe['Ticket_prefix']==ticket_name])\n            print('\\n\\n')# End of one number\n        \n        else:\n            break","55bdeca5":"analyse_prefix(11,train) # first arg doesn't work here ##change","f3f4041f":"for i in range(0,len(Ticket_temp_train_df.iloc[:,:])):\n    if (Ticket_temp_train_df.loc[i,'freq'] == 1):\n        train['Ticket'] = train['Ticket'].replace([ Ticket_temp_train_df.loc[i,'ticket'] ],'ticketcount_1')\n        \nfor i in range(0,len(Ticket_temp_test_df.iloc[:,:])):\n    if (Ticket_temp_test_df.loc[i,'freq'] == 1):\n        test['Ticket'] = test['Ticket'].replace([ Ticket_temp_test_df.loc[i,'ticket'] ],'ticketcount_1')","e9952a63":"train.head()","69f7bee2":"train['Ticket'].value_counts()","e2cd5143":"name_titles_train = []\nfor i in range(0,len(train['Name'])):\n    title = (train.loc[i,'Name'].split(', ')[1]).split(' ')[0]\n    name_titles_train.append(title)\n\n\nname_titles_test = []\nfor i in range(0,len(test['Name'])):\n    title = (test.loc[i,'Name'].split(', ')[1]).split(' ')[0]\n    name_titles_test.append(title)","15844abf":"train['Title'] = name_titles_train\ntest['Title'] = name_titles_test","9bb34111":"train = train.drop(['Name'],axis=1)\ntest = test.drop(['Name'],axis=1)","7b5293f7":"train.head(7)","b60895c7":"# Categories\n\nfor i in (2,3,5,7,9,10):\n    c = train.columns[i]\n    printmd('### %s'%(c))\n    display(train[c].value_counts())\n    print(' ')","31977119":"def Mean_Encoding(column_name):\n    new_smooth_name = column_name+'_smean_encod'\n    \n    mean = train['Survived'].mean()\n    agg= train.groupby(column_name)['Survived'].agg(['count','mean'])\n    counts = agg['count']\n    means = agg['mean']\n    weight = 100\n    smooth = (counts*means + weight*mean)\/(counts+weight)\n    \n    train.loc[:,new_smooth_name] = train[column_name].map(smooth)\n    test.loc[:,new_smooth_name] = test[column_name].map(smooth)    \n    ","d30a4c01":"Mean_Encoding('Ticket')","e12e9cca":"Mean_Encoding('Ticket_prefix')","af34675a":"Mean_Encoding('Title')","74bf32e7":"test.isnull().sum()","635ae4e1":"sns.displot(data=train['Ticket_smean_encod'],kde=True,height=6.5,color=random.choice(color_list));","724f8e6e":"sns.displot(data=train['Ticket_prefix_smean_encod'],kde=True,height=6.5,color=random.choice(color_list));","3b6dc65f":"sns.displot(data=train['Title_smean_encod'],kde=True,height=6.5,color=random.choice(color_list));","20619ffe":"test['Ticket_smean_encod'] = test['Ticket_smean_encod'].fillna(train['Ticket_smean_encod'].mean())\ntest['Ticket_prefix_smean_encod'] = test['Ticket_prefix_smean_encod'].fillna(train['Ticket_prefix_smean_encod'].mean())\ntest['Title_smean_encod'] = test['Title_smean_encod'].fillna(train['Title_smean_encod'].mean())","edc358d5":"test.isnull().sum()","3c261af6":"# Sex\n\ntrain['Sex_female'] = pd.get_dummies(train.Sex, prefix='Sex')['Sex_female']\ntrain['Sex_male'] = pd.get_dummies(train.Sex, prefix='Sex')['Sex_male']\ntest['Sex_female'] = pd.get_dummies(test.Sex, prefix='Sex')['Sex_female']\ntest['Sex_male'] = pd.get_dummies(test.Sex, prefix='Sex')['Sex_male']","7848a7ad":"# Pclass\n\ntrain['Pclass_1'] = pd.get_dummies(train.Pclass, prefix='Pclass')['Pclass_1']\ntrain['Pclass_2'] = pd.get_dummies(train.Pclass, prefix='Pclass')['Pclass_2']\ntrain['Pclass_3'] = pd.get_dummies(train.Pclass, prefix='Pclass')['Pclass_3']\n\ntest['Pclass_1'] = pd.get_dummies(test.Pclass, prefix='Pclass')['Pclass_1']\ntest['Pclass_2'] = pd.get_dummies(test.Pclass, prefix='Pclass')['Pclass_2']\ntest['Pclass_3'] = pd.get_dummies(test.Pclass, prefix='Pclass')['Pclass_3']","f5be044b":"# Embarked\n\ntrain['Embarked_C'] = pd.get_dummies(train.Embarked, prefix='Embarked')['Embarked_C']\ntrain['Embarked_Q'] = pd.get_dummies(train.Embarked, prefix='Embarked')['Embarked_Q']\ntrain['Embarked_S'] = pd.get_dummies(train.Embarked, prefix='Embarked')['Embarked_S']\n\ntest['Embarked_C'] = pd.get_dummies(test.Embarked, prefix='Embarked')['Embarked_C']\ntest['Embarked_Q'] = pd.get_dummies(test.Embarked, prefix='Embarked')['Embarked_Q']\ntest['Embarked_S'] = pd.get_dummies(test.Embarked, prefix='Embarked')['Embarked_S']","a9ee5769":"train.columns","6646846c":"train.head()","4ce3d939":"fig, ax = plt.subplots(figsize=(18,16)) \nmy_c = sns.diverging_palette(20, 220, as_cmap=True)\nmask = np.triu(train.corr())\nsns.heatmap(train.corr(),cmap=my_c,linewidths=1.5,ax=ax,annot=True,center=0,square=True,mask=mask);","68982a79":"# df_train = train[['Age','Fare','Family','Ticket_smean_encod','Ticket_prefix_smean_encod','Title_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n#        'Embarked_Q','Survived']] # omitted extra dummy variables\n# df_test = test[['Age','Fare','Family','Ticket_smean_encod','Ticket_prefix_smean_encod','Title_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n#        'Embarked_Q']] # omitted extra dummy variables\n\n# df_train = train[['Age','Fare','Family','Ticket_prefix_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n#        'Embarked_Q','Survived']] # omitted extra dummy variables\n# df_test = test[['Age','Fare','Family','Ticket_prefix_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n#        'Embarked_Q']] # omitted extra dummy variables\n\n# 77.9 accuracy\ndf_train = train[['Age','Fare','Ticket_prefix_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n       'Embarked_Q','Survived']] # omitted extra dummy variables\ndf_test = test[['Age','Fare','Ticket_prefix_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n       'Embarked_Q']] # omitted extra dummy variables\n\n","0bbf880d":"import statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","dfe7e372":"fig, ax = plt.subplots(figsize=(16,14)) \nmy_c = sns.diverging_palette(20, 220, as_cmap=True)\nmask = np.triu(df_train.corr())\nsns.heatmap(df_train.corr(),cmap=my_c,linewidths=1.5,ax=ax,annot=True,center=0,square=True,mask=mask);\nplt.savefig('correlation.png')","da1d9451":"from sklearn.model_selection import train_test_split\n\nX = df_train.iloc[:,:-1]\ny = df_train.iloc[:,-1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","b908be1b":"X.head()","79ff94e1":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train.iloc[:,:6] = sc.fit_transform(X_train.iloc[:,:6])\nX_test.iloc[:,:6] = sc.transform(X_test.iloc[:,:6])","478711d0":"X_train.head()","39837e10":"sc = StandardScaler()\nX.iloc[:,:6] = sc.fit_transform(X.iloc[:,:6])\ndf_test.iloc[:,:6] = sc.transform(df_test.iloc[:,:6])","f75663cb":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(max_depth=13,random_state=0)\nrfc.fit(X_train,y_train)","52cb2505":"y_pred = rfc.predict(X_test.iloc[:,:])","1c71dc8d":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","5e243b37":"sc = StandardScaler()\nX.iloc[:,:6] = sc.fit_transform(X.iloc[:,:6])\ndf_test.iloc[:,:6] = sc.transform(df_test.iloc[:,:6])","7688ca72":"rfc = RandomForestClassifier()\nrfc.fit(X,y)","2387e18f":"y_pred = rfc.predict(df_test.iloc[:,:])","f1ec3718":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train,y_train)","ad94e554":"y_pred = lr.predict(X_test)","4b234ddb":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","a9c311b3":"lr = LogisticRegression()\nlr.fit(X,y)\n\ny_pred = lr.predict(df_test.iloc[:,:])\n","f7a64597":"from sklearn.ensemble import GradientBoostingClassifier","2601e475":"gbc = GradientBoostingClassifier(n_estimators=50, learning_rate=0.06,max_depth=5, random_state=0).fit(X_train, y_train)\n#gbc.score(X_test, y_test)","7caee874":"y_pred = gbc.predict(X_test)\naccuracy_score(y_test,y_pred)","3900fb4a":"gbc = GradientBoostingClassifier(n_estimators=50, learning_rate=0.06,max_depth=5, random_state=0).fit(X, y)\ny_pred = gbc.predict(df_test.iloc[:,:])","06d51d08":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)","02723526":"y_pred = gnb.predict(X_test)","b76a7692":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","fdd32354":"gnb = GaussianNB()\ngnb.fit(X, y)\ny_pred = gnb.predict(df_test.iloc[:,:])","00144427":"values = [i for i in range(1, 15, 1)] ## Max Depth","844ec982":"values","ee359f50":"train_scores = []\ntest_scores = []\n# evaluate a decision tree for each depth\nfor i in values:\n    # configure the model\n    model = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1,max_depth=i, random_state=0)\n    # fit model on the training dataset\n    model.fit(X_train, y_train)\n    # evaluate on the train dataset\n    train_yhat = model.predict(X_train)\n    train_acc = accuracy_score(y_train, train_yhat)\n    train_scores.append(train_acc)\n    # evaluate on the test dataset\n    test_yhat = model.predict(X_test)\n    test_acc = accuracy_score(y_test, test_yhat)\n    test_scores.append(test_acc)\n    # summarize progress\n    print('>%3f, train: %.3f, test: %.3f' % (i, train_acc, test_acc))","1f1e4f20":"# Max Depth\nplt.plot(values,train_scores,color=blue,label='Train');\nplt.plot(values,test_scores,color=red,label='Test');\nplt.legend();","85cd3cfd":"values = [i for i in range(75, 200, 5)] ## N Estimators","67bcc65f":"values","968762ef":"train_scores = []\ntest_scores = []\n# evaluate a decision tree for each depth\nfor i in values:\n    # configure the model\n    model = GradientBoostingClassifier(n_estimators=i, learning_rate=0.1,max_depth=5, random_state=0)\n    # fit model on the training dataset\n    model.fit(X_train, y_train)\n    # evaluate on the train dataset\n    train_yhat = model.predict(X_train)\n    train_acc = accuracy_score(y_train, train_yhat)\n    train_scores.append(train_acc)\n    # evaluate on the test dataset\n    test_yhat = model.predict(X_test)\n    test_acc = accuracy_score(y_test, test_yhat)\n    test_scores.append(test_acc)\n    # summarize progress\n    print('>%3f, train: %.3f, test: %.3f' % (i, train_acc, test_acc))","807ff082":"# n_estimators\nplt.plot(values,train_scores,color=blue,label='Train');\nplt.plot(values,test_scores,color=red,label='Test');\nplt.legend();","2f026ff6":"values = [i for i in np.linspace(0.01,0.1,30)] ## Learning Rate","e14ba7ef":"values","00708b85":"train_scores = []\ntest_scores = []\n# evaluate a decision tree for each depth\nfor i in values:\n    # configure the model\n    model = GradientBoostingClassifier(n_estimators=100, learning_rate=i,max_depth=5, random_state=0)\n    # fit model on the training dataset\n    model.fit(X_train, y_train)\n    # evaluate on the train dataset\n    train_yhat = model.predict(X_train)\n    train_acc = accuracy_score(y_train, train_yhat)\n    train_scores.append(train_acc)\n    # evaluate on the test dataset\n    test_yhat = model.predict(X_test)\n    test_acc = accuracy_score(y_test, test_yhat)\n    test_scores.append(test_acc)\n    # summarize progress\n    print('>%3f, train: %.3f, test: %.3f' % (i, train_acc, test_acc))","24e76518":"# Learning rate\nplt.plot(values,train_scores,color=blue,label='Train');\nplt.plot(values,test_scores,color=red,label='Test');\nplt.legend();","d8c27045":"gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.072069,max_depth=5, random_state=0)\ngbc.fit(X_train,y_train)\ny_pred = gbc.predict(X_test)\naccuracy_score(y_test,y_pred)","161b8bc6":"gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.072069,max_depth=5, random_state=0).fit(X, y)\ny_pred = gbc.predict(df_test.iloc[:,:])","2c57d9c7":"Submission = pd.DataFrame({'PassengerID': test.PassengerId, 'Survived': y_pred})","d852aa15":"Submission.to_csv('submission.csv', index=False)","46b770fb":"## 4. Naive Bayes","98f2bbd5":"### Mean Encoding for **Ticket**, **Ticket_prefix** and **Title** columns","f18ce18b":"## 3. XGBoost","79bc4b69":"### <span style=\"background-color:LightGreen;\">Actual<\/span>","e8c88a96":"### Testing accuracy","1c8cbcb6":"# **6. Models & Selection**","ae19cc26":"# **5. Feature Scaling**","6af8014b":"#### Getting Ticket prefix values","3fd1ee1b":"## Missing Values","1453e937":"### Max Depth","5093b43f":"### Embarked","0a4efefe":"## Column Transformations","c777285b":"Therefore,**n_estimators=100**","fd8f1c17":"-----------","934c8868":"### Ticket","f150586d":"# **7. Learning Curve Plot for XGBoost Hyperparameters**","ee2ca1eb":"# **Flow**\n\n 1. **Inputting & Importing**\n 2. **Data Preprocessing**\n    * Missing Values\n            a. Cabin\n            b. Age\n            c. Embarked\n            d. Fare\n    * Column Transformations\n            a. SibSp & Parch\n            b. Fare\n            c. Age\n            d. Ticket\n            e. Name\n    * Categorical Encoding\n            a. Mean Encoding \n            b. One hot Encoding\n        \n 3. **Correlation & Feature Selection**\n 4. **Splitting data**\n 5. **Feature Scaling**\n 6. **Models & Selection**\n 7. **Learning Curve for Hyperparameters**\n 8. **Final Model with Hyperparameters**\n 9. **Submission**","87d8b1f0":"### <span style=\"background-color:LightGreen;\">**Actual**<\/span>","6f8fae45":"# **4. Splitting data**","a6406d82":"## 1. Random Forest","7e659271":"## One Hot Encoding for **Sex**, **Embarked** and **Pclass** columns","ddac9ef1":"#### Missing values after mean Encoding","278ac6a8":"### Fare","a0c3dd36":"### Test","80bd2055":"## Categorical Encoding","c735a221":"### SibSp and Parch","cb695dbf":"### Age","a2bfae29":"### Test","5c363dfd":"### <span style=\"background-color:LightGreen;\">Actual<\/span> (For Submission)","b1fab6eb":"# **9. Submission**","61c60b01":"## 2. Logistic Regression","bb30dd26":"#### **Observations**","2142741b":"Grouping all unique tickets to a common value","6f0b50f0":"# **8. Final Model with hyperparameters**","76e54c6a":"# **1. Inputting & Importing**","02a35de8":"Therefore, **Max depth = 5**","f1106d60":"### Learning Rate","24478d45":"### Age","f52d3387":"* Some people have more than one cabin\n* Some people not from the same family are in the same cabin\n* should I age categorize?\n* There are hardly any cabin names for 3rd class passengers\n* 3rd class passengers usually travel in F and G (for the few data that is there)\n* passengers on the same ticket are mostly in the same cabin and belong to the same class\n\n**Berth numbers were given for some passengers. Odd for lower berths and even for upper berths.** [source](https:\/\/www.encyclopedia-titanica.org\/cabins.html)","c5c593e7":"From the following graphs, the point on the x axis where the Test graph peaks just before it begins to decrease afterwards, is where the value is best suited","07fee966":"- 20% **Age** values are missing \n- 0.2% **Embarked** values are missing \n- 77% **Cabin** values are missing -> deleting for now\n- **Fare** has just 1 missing value","b46bf967":"**This means that there are new unique values in the test dataset which weren't mapped to the smooth values we have here**","5d715da5":"### Testing Accuracy","a0189618":"### Name","29477063":"Therfore, **learning_rate=0.072069**","8cb604db":"### N Estimators","4a2f2745":"**Run only either one of these 4 models, and then the Submission section**","7eb3896b":"### Fare","a0aa73c3":"### Cabin","f6c8c569":"## Train Test Split","a72cd8fa":"# **3. Correlation and Feature Selection**","6faae871":"# **Conclusion**\n\nXGBoost works the best with 77.9% accuracy.","89234c27":"### Testing accuracy","bce187ff":"### <span style=\"background-color:LightGreen;\">Actual<\/span>","1f7a41b3":"# **2. Data Preprocessing**","2af6f45a":"### <span style=\"background-color:LightGreen;\">Actual<\/span>"}}