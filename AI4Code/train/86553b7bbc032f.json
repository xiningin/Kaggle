{"cell_type":{"fbc0bea0":"code","290d5c07":"code","e30e6420":"code","0e88a5e4":"code","ce988c8e":"code","6b2381e5":"code","967cdaec":"code","2a2967e7":"code","6b17fab6":"code","744cc44f":"code","5773352c":"code","fc5d54fd":"code","b6783396":"code","9541dd20":"code","748d8f9b":"code","9360c450":"code","1b5d7084":"code","3e5c66fb":"code","0ea2196d":"code","f4a4f751":"code","10752762":"code","e5f550ca":"code","94eb445f":"code","faa5108f":"code","8f6699d3":"code","c2e66252":"code","98abd2e1":"code","00bf3228":"code","9b661358":"code","90c6dfd3":"code","694c0e97":"code","fa22c2a5":"code","073d3b3f":"code","9bd856b8":"code","32275346":"code","6fe33a53":"code","19e6fdee":"code","8c60b963":"code","abf4117d":"code","cc83f7d5":"code","3a2f7881":"code","e392f261":"code","121447ee":"code","c6fd756e":"code","700272e5":"code","7a4fa6d9":"code","a1fce04d":"code","cce50f9b":"code","6717e091":"code","11c2b693":"code","f75eff95":"code","b27d994a":"code","89f3a06e":"code","df3ce835":"code","8c3edcba":"code","32b48ad1":"code","98880fc1":"code","407cc005":"code","c5ff7841":"code","13a9bcb1":"markdown","90d93217":"markdown","77204abf":"markdown","9fcd8374":"markdown","d4a81da7":"markdown","7f504e08":"markdown","920dfba0":"markdown","c1bed5ed":"markdown"},"source":{"fbc0bea0":"!pip install tqdm\n!pip install nltk\n!pip install wordcloud","290d5c07":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re\nfrom string import punctuation\nimport nltk\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom collections import Counter\nfrom bs4 import BeautifulSoup\n\n\nfrom wordcloud import WordCloud, STOPWORDS","e30e6420":"from tqdm import tqdm\ntqdm.pandas()","0e88a5e4":"pd.options.display.max_colwidth = None","ce988c8e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6b2381e5":"DATA_PATH = '\/kaggle\/input\/jigsaw-toxic-severity-rating'","967cdaec":"df = pd.read_csv(DATA_PATH + '\/validation_data.csv')\n# df = pd.read_csv(DATA_PATH + '\/comments_to_score.csv')\nprint(df.columns)\nprint(df.shape)","2a2967e7":"df.head(10)","6b17fab6":"df.info()","744cc44f":"df.isnull().sum()","5773352c":"target_cols = df.columns[1:]\ntarget_cols","fc5d54fd":"df_sub = pd.read_csv(DATA_PATH + '\/comments_to_score.csv')\ndf_sub.head()","b6783396":"# def text_cleaning(text, cols_name):\n    \n#     df[cols_name] = df[cols_name].apply(lambda x: x.lower())\n    \n#     return text","9541dd20":"# df_test['less_toxic'] = df_test['less_toxic'].progress_apply(text_cleaning, cols_name='less_toxic')\n# df_test['more_toxic'] = df_test['more_toxic'].progress_apply(text_cleaning, cols_name='more_toxic')\n\ndf['less_toxic'] = df['less_toxic'].apply(lambda x: x.lower())\ndf['more_toxic'] = df['more_toxic'].apply(lambda x: x.lower())","748d8f9b":"df.head()","9360c450":"def cleaned_text(phrase):\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    \n    template = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    phrase = template.sub(r'', phrase)\n    \n    soup = BeautifulSoup(phrase, 'lxml') # removes HTML tags\n    only_text = soup.get_text()\n    phrase = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    phrase = emoji_pattern.sub(r'', phrase)\n    \n    phrase = re.sub(r\"[^a-zA-Z\\d]\", \" \", phrase) #Remove special Charecters\n    phrase = re.sub(' +', ' ', phrase) #Remove Extra Spaces\n    phrase = phrase.strip() # remove spaces at the beginning and at the end of string\n    \n    return phrase","1b5d7084":"df['less_toxic'] = df['less_toxic'].progress_apply(cleaned_text)\ndf['more_toxic'] = df['more_toxic'].progress_apply(cleaned_text)","3e5c66fb":"df[5:10]","0ea2196d":"df['less_toxic'] = df['less_toxic'].progress_apply(lambda x: ''.join(string for string in x if not string.isdigit()))\ndf['more_toxic'] = df['more_toxic'].progress_apply(lambda x: ''.join(string for string in x if not string.isdigit()))","f4a4f751":"df[5:10]","10752762":"df.head().T","e5f550ca":"df.loc[df['less_toxic'].str.contains('\\n', case=False)]","94eb445f":"nltk.download('vader_lexicon')","faa5108f":"SIA = SentimentIntensityAnalyzer()","8f6699d3":"def polarity(x):\n    if type(x) == str:\n        return SIA.polarity_scores(x)\n    else:\n        return 1000","c2e66252":"df['less_toxic'][0]","98abd2e1":"df['more_toxic'][0]","00bf3228":"polarity(df['less_toxic'][0])","9b661358":"polarity(df['more_toxic'][0])","90c6dfd3":"# df_test_a = df_test.copy()","694c0e97":"for col in target_cols:\n    df[f'polarity_{col}'] = df[col].progress_apply(polarity)\n    \n    df[f\"negativity_{col}\"] = df[f'polarity_{col}'].apply(lambda x: x[\"neg\"])\n\n    df[f\"positivity_{col}\"] = df[f'polarity_{col}'].apply(lambda x: x[\"pos\"])\n\n    df[f\"neutrality_{col}\"] = df[f'polarity_{col}'].apply(lambda x: x[\"neu\"])\n\n    df[f\"compound_{col}\"] = df[f'polarity_{col}'].apply(lambda x: x[\"compound\"])","fa22c2a5":"df.head().T","073d3b3f":"results = Counter()","9bd856b8":"df['less_toxic'].str.lower().str.split().progress_apply(results.update)\ndf['more_toxic'].str.lower().str.split().progress_apply(results.update)","32275346":"count_words = pd.DataFrame.from_dict(results, orient='index').reset_index()","6fe33a53":"count_words.columns = ['words', 'count']","19e6fdee":"count_words.sort_values(by='count', ascending=False).head(20)","8c60b963":"df[df['less_toxic'].str.contains('wikipedia')]","abf4117d":"df = df[df['more_toxic'].str.contains('uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubnvvi uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubnvvi uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubnvvi uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfb') == False].copy()","cc83f7d5":"df.shape","3a2f7881":"plt.figure(figsize=(15,15))\ntext = ' '.join([abstract for abstract in df[\"less_toxic\"]])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False\n                      ,width=5000, height=5000\n                     ).generate(text)\nfig = plt.imshow(wordcloud)\nfig.axes.set_title('Common words in comments')\nplt.show()","e392f261":"plt.figure(figsize=(15,15))\ntext = ' '.join([abstract for abstract in df[\"more_toxic\"]])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False\n                      ,width=5000, height=5000\n                     ).generate(text)\nfig = plt.imshow(wordcloud)\nfig.axes.set_title('Common words in comments')\nplt.show()","121447ee":"delete_words = ['wikipedia', 'wiki']","c6fd756e":"df['less_toxic'] = df['less_toxic'].progress_apply(lambda x: ' '.join([word for word in nltk.word_tokenize(x) if word not in delete_words]))\ndf['more_toxic'] = df['more_toxic'].progress_apply(lambda x: ' '.join([word for word in nltk.word_tokenize(x) if word not in delete_words]))","700272e5":"def new_len(x):\n    if type(x) is str:\n        return len(x.split())\n    else:\n        return 0","7a4fa6d9":"df['num_of_words_less_toxic'] = df['less_toxic'].progress_apply(new_len)\ndf['num_of_words_more_toxic'] = df['more_toxic'].progress_apply(new_len)","a1fce04d":"df.head()","cce50f9b":"nums_less_toxic = df.query('num_of_words_less_toxic !=0')['num_of_words_less_toxic']\nnums_more_toxic = df.query('num_of_words_more_toxic !=0')['num_of_words_more_toxic']","6717e091":"nums = nums_less_toxic + nums_more_toxic","11c2b693":"len(nums)","f75eff95":"df.shape","b27d994a":"nums","89f3a06e":"plt.figure(figsize=(10,5))\nplt.title('Num of Words Less Toxic')\nplt.hist(df['num_of_words_less_toxic'], bins=100)\nplt.show()","df3ce835":"df['num_of_words_less_toxic'].value_counts()[:10]","8c3edcba":"plt.figure(figsize=(10,5))\nplt.title('Num of Words More Toxic')\nplt.hist(df['num_of_words_more_toxic'], bins=100)\nplt.show()","32b48ad1":"df['num_of_words_more_toxic'].value_counts()[:10]","98880fc1":"df[df['num_of_words_less_toxic']==0]","407cc005":"df[df['num_of_words_more_toxic']==0]","c5ff7841":"df.to_csv('clean_data.csv', index=False)","13a9bcb1":"# Remove Number in desc ","90d93217":"### Num of Words Less Toxic","77204abf":"### Wordcloud","9fcd8374":"### Num of Words More Toxic","d4a81da7":"### Number of words ","7f504e08":"# Decontracted","920dfba0":"# Text Processing\n\n- Lower Characters\n- Regex\n- Remove Numbers, Emojis, Punctuation, White Spaces","c1bed5ed":"# Sentiment and Polarity "}}