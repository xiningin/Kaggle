{"cell_type":{"6ef9e618":"code","f14e9027":"code","ccdfc92c":"code","1673b1e6":"code","bc36372a":"code","d7c234d4":"code","bafc67bd":"code","8bea9fd4":"code","5a09fba4":"code","7e85a34a":"code","02fc1f06":"code","fcc00889":"code","b93aeb50":"code","bd05f37b":"code","812968db":"code","a40797ef":"code","2011eb5d":"code","79f32698":"code","101eac99":"code","00b9aa96":"code","5c572e1a":"code","5d9df0d5":"code","88d6c6c8":"code","e38b0ac5":"code","c8c25d9a":"code","dcfb13e2":"markdown","a73e96e9":"markdown","bbe95d42":"markdown","337238f2":"markdown","2740c213":"markdown","7a1789e6":"markdown","20eb367e":"markdown","546615f8":"markdown","e96c1062":"markdown","e00d56bf":"markdown","b744f2b5":"markdown","e549a83a":"markdown","6f27bf3e":"markdown","088d28c5":"markdown","9f2651fa":"markdown","40ead826":"markdown","74be889d":"markdown","ffd3284e":"markdown","85ca0598":"markdown","ca9e4609":"markdown"},"source":{"6ef9e618":"import numpy as np \nimport pandas as pd \nimport datetime as dt\nimport seaborn as sns\nimport scipy\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import RegexpTokenizer\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nimport plotly.express as px\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import roc_curve, auc\nfrom textblob import TextBlob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import GridSearchCV\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore') \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n","f14e9027":"data = pd.read_csv('\/kaggle\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv',index_col =[0])","ccdfc92c":"df = data[['Review Text','Rating','Class Name','Age']]\ndf.head()","1673b1e6":"data.head(2)","bc36372a":"data.shape","d7c234d4":"data.info()","bafc67bd":"data.isnull().sum()\/len(data)*100","8bea9fd4":"data.groupby(['Rating', 'Recommended IND'])['Recommended IND'].count()","5a09fba4":"sns.set(rc={'figure.figsize':(11,4)})\npd.isnull(data).sum().plot(kind='bar')\nplt.ylabel('Number of missing values')\nplt.title('Missing Values per Feature');","7e85a34a":"plt.hist(data['Age'], color=\"red\", label = \"Age\")\nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.title(\"Age Distribution in Data\")","02fc1f06":"fig = plt.figure(figsize=(14, 9))\nplt.xticks(rotation=45)\nplt.xlabel('item ID')\nplt.ylabel('popularity')\nplt.title(\"Top 50 Popular Items\")\ndata['Clothing ID'].value_counts()[:50].plot(kind='bar');","fcc00889":"data = data[~data['Review Text'].isnull()]\n\ndata.shape","b93aeb50":"def punctuation_removal(messy_str):\n    clean_list = [char for char in messy_str if char not in string.punctuation]\n    clean_str = ''.join(clean_list)\n    return clean_str\ndata.shape","bd05f37b":"px.scatter(data, x=\"Age\", y=\"Positive Feedback Count\", facet_row=\"Recommended IND\", facet_col=\"Rating\",trendline=\"ols\",category_orders={\"Rating\": [1,2,3,4,5],'Recommended IND':[0,1]})","812968db":"\nvectorizer = CountVectorizer()\n# assign a shorter name for the analyze\n# which tokenizes the string\nanalyzer = vectorizer.build_analyzer()\n\ndef wordcounts(s):\n    c = {}\n    # tokenize the string and continue, if it is not empty\n    if analyzer(s):\n        d = {}\n        # find counts of the vocabularies and transform to array \n        w = vectorizer.fit_transform([s]).toarray()\n        # vocabulary and index (index of w)\n        vc = vectorizer.vocabulary_\n        # items() transforms the dictionary's (word, index) tuple pairs\n        for k,v in vc.items():\n            d[v]=k # d -> index:word \n        for index,i in enumerate(w[0]):\n            c[d[index]] = i # c -> word:count\n    return  c\n\n# add new column to the dataframe\ndata['Word Counts'] = data['Review Text'].apply(wordcounts)\ndata.head()","a40797ef":"# selecting some words to examine detailed \nselectedwords = ['awesome','great','fantastic','extraordinary','amazing','super',\n                 'magnificent','stunning','impressive','wonderful','breathtaking',\n                 'love','content','pleased','happy','glad','satisfied','lucky',\n                 'shocking','cheerful','wow','sad','unhappy','horrible','regret',\n                 'bad','terrible','annoyed','disappointed','upset','awful','hate']\n\ndef selectedcount(dic,word):\n    if word in dic:\n        return dic[word]\n    else:\n        return 0\n    \ndfwc = data.copy()  \nfor word in selectedwords:\n    dfwc[word] = dfwc['Word Counts'].apply(selectedcount,args=(word,))\n    \nword_sum = dfwc[selectedwords].sum()\nprint('Selected Words')\nprint(word_sum.sort_values(ascending=False).iloc[:5])\n\nprint('\\nClass Names')\nprint(data['Class Name'].fillna(\"Empty\").value_counts().iloc[:5])\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nwc0 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 ).generate_from_frequencies(word_sum)\n\ncn = data['Class Name'].fillna(\" \").value_counts()\nwc1 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 \n                     ).generate_from_frequencies(cn)\n\nax[0].imshow(wc0)\nax[0].set_title('Selected Words\\n',size=25)\nax[0].axis('off')\n\nax[1].imshow(wc1)\nax[1].set_title('Class Names\\n',size=25)\nax[1].axis('off')\n\n","2011eb5d":"data['polarity'] = data['Review Text'].map(lambda text: TextBlob(text).sentiment.polarity)\nsam = data.loc[data.polarity == 1,['Review Text']].sample(3).values\nnegative = (len(data.loc[data.polarity <0,['Review Text']].values)\/len(data))*100\npositive = (len(data.loc[data.polarity >0.5,['Review Text']].values)\/len(data))*100\nneutral  = len(data.loc[data.polarity >0 ,['Review Text']].values) - len(data.loc[data.polarity >0.5 ,['Review Text']].values)\nneutral = neutral\/len(data)*100\n\nfrom matplotlib import pyplot as plt \nplt.figure(figsize =(10, 7)) \nplt.pie([positive,negative,neutral], labels = ['Positive','Negative','Neutral']) ","79f32698":"# Rating of 4 or higher -> positive, while the ones with \n# Rating of 2 or lower -> negative \n# Rating of 3 -> neutral\ndata = data[data['Rating'] != 3]\ndata['Sentiment'] = data['Rating'] >=4\ndata.head()\n\n# split data\ntrain_data,test_data = train_test_split(data,train_size=0.8,random_state=0)\n# select the columns and \n# prepare data for the models \nX_train = vectorizer.fit_transform(train_data['Review Text'])\ny_train = train_data['Sentiment']\nX_test = vectorizer.transform(test_data['Review Text'])\ny_test = test_data['Sentiment']","101eac99":"start=dt.datetime.now()\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","00b9aa96":"start=dt.datetime.now()\nnb = MultinomialNB()\nnb.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","5c572e1a":"start=dt.datetime.now()\nsvm = SVC()\nsvm.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","5d9df0d5":"start=dt.datetime.now()\nnn = MLPClassifier()\nnn.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","88d6c6c8":"# define a dataframe for the predictions\ndf2 = train_data.copy()\ndf2['Logistic Regression'] = lr.predict(X_train)\ndf2['Naive Bayes'] = nb.predict(X_train)\ndf2['SVM'] = svm.predict(X_train)\ndf2['Neural Network'] = nn.predict(X_train)\ndf2.head()","e38b0ac5":"pred_lr = lr.predict_proba(X_test)[:,1]\nfpr_lr,tpr_lr,_ = roc_curve(y_test,pred_lr)\nroc_auc_lr = auc(fpr_lr,tpr_lr)\n\npred_nb = nb.predict_proba(X_test)[:,1]\nfpr_nb,tpr_nb,_ = roc_curve(y_test.values,pred_nb)\nroc_auc_nb = auc(fpr_nb,tpr_nb)\n\npred_svm = svm.decision_function(X_test)\nfpr_svm,tpr_svm,_ = roc_curve(y_test.values,pred_svm)\nroc_auc_svm = auc(fpr_svm,tpr_svm)\n\npred_nn = nn.predict_proba(X_test)[:,1]\nfpr_nn,tpr_nn,_ = roc_curve(y_test.values,pred_nn)\nroc_auc_nn = auc(fpr_nn,tpr_nn)\n\nf, axes = plt.subplots(2, 2,figsize=(15,10))\naxes[0,0].plot(fpr_lr, tpr_lr, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_lr))\naxes[0,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Logistic Regression')\naxes[0,0].legend(loc='lower right', fontsize=13)\n\naxes[0,1].plot(fpr_nb, tpr_nb, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nb))\naxes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Naive Bayes')\naxes[0,1].legend(loc='lower right', fontsize=13)\n\naxes[1,0].plot(fpr_svm, tpr_svm, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_svm))\naxes[1,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Support Vector Machine')\naxes[1,0].legend(loc='lower right', fontsize=13)\n\naxes[1,1].plot(fpr_nn, tpr_nn, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nn))\naxes[1,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Neural Network')\naxes[1,1].legend(loc='lower right', fontsize=13);","c8c25d9a":"import sklearn.metrics as mt\nprint(\"Logistic Regression\")\nprint(mt.classification_report(y_test, lr.predict(X_test)))\nprint(\"\\n Naive Bayes\")\nprint(mt.classification_report(y_test, nb.predict(X_test)))\nprint(\"\\n Support Vector Machine (SVM)\")\nprint(mt.classification_report(y_test, svm.predict(X_test)))\nprint(\"\\n Neural Network\")\nprint(mt.classification_report(y_test, nn.predict(X_test)))","dcfb13e2":"Regression","a73e96e9":"Count rating and recommended IND as recommended IND","bbe95d42":"# Data Modeling","337238f2":"Naive Bayes","2740c213":"most popular item","7a1789e6":"Dropping null values","20eb367e":"Importing modules and reading dataset","546615f8":"Neural Network","e96c1062":"Pi chart for polarity","e00d56bf":"The age distribution in data","b744f2b5":"Dropping Punctuation","e549a83a":"# Data Cleaning","6f27bf3e":"Checking For Missing Values and Handling it","088d28c5":"# Sentiment Analysis","9f2651fa":"Word Count and adding new feature","40ead826":"Support Vector Machine","74be889d":"Graphs","ffd3284e":"Read Dataset","85ca0598":"The amount of missing values per feature","ca9e4609":"To make graph adding results to data frame"}}