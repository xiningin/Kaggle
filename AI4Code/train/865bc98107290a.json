{"cell_type":{"45c0a4f4":"code","44028982":"code","42a54694":"code","bb788c6d":"code","9f971458":"code","3f1e32d1":"code","af876510":"code","f9d5ec74":"code","ec647cbe":"code","a798b510":"code","fa9e98ac":"code","cbfbb700":"code","924cd15d":"code","4b898201":"code","edcf9254":"code","de05962c":"code","9ad4b182":"code","620b9ac1":"code","efa5e025":"code","b60b8c11":"code","b72498ca":"code","c665bb83":"code","b517e4fe":"code","91a8428c":"code","5f5d390f":"code","d2b805a9":"code","02f64cee":"code","fcf52088":"code","49d3f0c6":"code","3acd50df":"code","5556a3ae":"code","43449e47":"code","8aeaa869":"code","15ab5df4":"code","f83d94be":"code","3c6ba3b6":"code","b3ab3d86":"code","90681bfb":"code","30fcdc14":"code","e706be29":"code","6440270a":"code","bb2ec8fa":"code","8c9f52c7":"code","c08f3575":"code","feb080b6":"code","29853280":"code","ccf478d9":"code","8d2413b2":"code","b8cf5e62":"code","f19f10f4":"code","943d7718":"code","7c1258a6":"code","71f7d0f6":"code","646282e9":"code","3f579ec5":"code","8090fcb2":"code","748cdfa7":"code","7b7c50d7":"code","8bbed691":"code","910328cb":"code","af568606":"markdown","c023a746":"markdown","1d139c4b":"markdown","0edcfae3":"markdown","b7137dc8":"markdown","804c0609":"markdown","7d3689b5":"markdown","f16f28a0":"markdown","496b78ca":"markdown","46093253":"markdown","2a193235":"markdown","2f88f670":"markdown","816ffab9":"markdown","4f03962b":"markdown","05ec5cbc":"markdown","481a20ab":"markdown","d7e8d808":"markdown","70061805":"markdown","ce8fa06f":"markdown","fb59a1ca":"markdown","07498030":"markdown","5ee601bd":"markdown","1bdcb9df":"markdown","930601c5":"markdown"},"source":{"45c0a4f4":"import pandas as pd\nfrom IPython.display import display\npd.options.display.max_columns = 500\npd.options.display.max_rows = 200\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom datetime import datetime\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nimport math","44028982":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        fname = (os.path.join(dirname, filename))\n        df = pd.read_csv(fname)\n# Any results you write to the current directory are saved as output.","42a54694":"df.describe()","bb788c6d":"sum(df['stalk-root'] == '?')","9f971458":"df.isna().sum()","3f1e32d1":"df.head()","af876510":"df.columns","f9d5ec74":"cols_convert = set(df.columns) - set(['class'])\ndf_new = pd.concat([df,pd.get_dummies(df[cols_convert],prefix = cols_convert)],axis=1)","ec647cbe":"df_new['Class'] = 1 # 1 means poisonous\nmask_edible = (df_new['class'] == 'e')\ndf_new.loc[mask_edible,'Class'] = 0","a798b510":"df_new","fa9e98ac":"df_final = df_new.drop(columns= df.columns)","cbfbb700":"df_final","924cd15d":"df_final.corr()\ncorrelation_with_target = df_final[df_final.columns[:]].corr()[['Class']]","4b898201":"correlation_with_target = correlation_with_target.reset_index()\ncorrelation_with_target.columns = ['Variable','Correlation']","edcf9254":"correlation_with_target","de05962c":"y_col = ['Class']\nmodelling_cols = [col for col in df_final.columns if not col in y_col ]","9ad4b182":"X_train, X_test, y_train, y_test =  train_test_split(df_final, df_final[y_col], random_state=1)","620b9ac1":"y_test.Class.value_counts()","efa5e025":"nb_model = GaussianNB()","b60b8c11":"nb_model.fit(X_train[modelling_cols], np.ravel(y_train))","b72498ca":"nb_y_predict = nb_model.predict(X_test[modelling_cols])","c665bb83":"print(accuracy_score(y_test, nb_y_predict))\nprint(roc_auc_score(y_test, nb_y_predict))\nprint(confusion_matrix(y_test, nb_y_predict))\nprint(classification_report(y_test,nb_y_predict))","b517e4fe":" knn_model = KNeighborsClassifier(n_neighbors=int(math.sqrt(len(X_train))))","91a8428c":"knn_model.fit(X_train[modelling_cols], np.ravel(y_train))","5f5d390f":"# By default 0.5\n# y_predict = model.predict(X_test[modelling_cols])\nknn_y_pred_proba = knn_model.predict_proba(X_test[modelling_cols])[:, 1]\nthresh = .5\nknn_y_predict = [1 if value > thresh else 0 for value in knn_y_pred_proba]","d2b805a9":"print(accuracy_score(y_test, knn_y_predict))\nprint(roc_auc_score(y_test, knn_y_pred_proba))\nprint(confusion_matrix(y_test, knn_y_predict))\nprint(classification_report(y_test,knn_y_predict))","02f64cee":"lr_model = LogisticRegression(random_state=1, solver='lbfgs')","fcf52088":"lr_model.fit(X_train[modelling_cols], np.ravel(y_train))","49d3f0c6":"# By default 0.5\n# y_predict = model.predict(X_test[modelling_cols])\nlr_y_pred_proba = lr_model.predict_proba(X_test[modelling_cols])[:, 1]\nthresh = .5\nlr_y_predict = [1 if value > thresh else 0 for value in lr_y_pred_proba]","3acd50df":"print(accuracy_score(y_test, lr_y_predict))\nprint(roc_auc_score(y_test, lr_y_pred_proba))\nprint(confusion_matrix(y_test, lr_y_predict))","5556a3ae":"print(classification_report(y_test,lr_y_predict))","43449e47":"svm_model = SVC(C=1.0, kernel='rbf', gamma = 'auto' ,random_state=1, probability= True)","8aeaa869":"svm_model.fit(X_train[modelling_cols], np.ravel(y_train))","15ab5df4":"svm_y_pred_proba = svm_model.predict_proba(X_test[modelling_cols])[:, 1]\nthresh = .5\nsvm_y_predict = [1 if value > thresh else 0 for value in svm_y_pred_proba]","f83d94be":"print(accuracy_score(y_test, svm_y_predict))\nprint(roc_auc_score(y_test, svm_y_pred_proba))\nprint(confusion_matrix(y_test, svm_y_predict))","3c6ba3b6":"print(classification_report(y_test,dt_y_predict))","b3ab3d86":"dt_model = DecisionTreeClassifier(random_state= 1)","90681bfb":"dt_model.fit(X_train[modelling_cols], np.ravel(y_train))","30fcdc14":"dt_y_pred_proba = dt_model.predict_proba(X_test[modelling_cols])[:, 1]\nthresh = .5\ndt_y_predict = [1 if value > thresh else 0 for value in dt_y_pred_proba]","e706be29":"print(accuracy_score(y_test, dt_y_predict))\nprint(roc_auc_score(y_test, dt_y_pred_proba))\nprint(confusion_matrix(y_test, dt_y_predict))","6440270a":"print(classification_report(y_test,dt_y_predict))","bb2ec8fa":"gb_model = GradientBoostingClassifier(learning_rate = 0.1, n_estimators = 100, random_state=1)","8c9f52c7":"gb_model.fit(X_train[modelling_cols], np.ravel(y_train))","c08f3575":"gb_y_pred_proba = gb_model.predict_proba(X_test[modelling_cols])[:, 1]\nthresh = .5\ngb_y_predict = [1 if value > thresh else 0 for value in gb_y_pred_proba]","feb080b6":"print(accuracy_score(y_test, gb_y_predict))\nprint(roc_auc_score(y_test, gb_y_pred_proba))\nprint(confusion_matrix(y_test, gb_y_predict))","29853280":"print(classification_report(y_test,gb_y_predict))","ccf478d9":"model = RandomForestClassifier(n_estimators =  100, n_jobs=-1, random_state=1)","8d2413b2":"model.fit(X_train[modelling_cols], np.ravel(y_train))","b8cf5e62":"# y_predict_train = model.predict(X_train[modelling_cols])\ny_pred_proba_train = model.predict_proba(X_train[modelling_cols])[:,1]\ny_predict_train = [1 if value >0.5 else 0 for value in y_pred_proba_train]\naccuracy_score(y_train, y_predict_train)\nroc_auc_score(y_train, y_pred_proba_train)\nconfusion_matrix(y_train, y_predict_train)","f19f10f4":"# By default 0.5\n# y_predict = model.predict(X_test[modelling_cols])\ny_pred_proba = model.predict_proba(X_test[modelling_cols])[:, 1]\nthresh = .5\ny_predict = [1 if value > thresh else 0 for value in y_pred_proba]","943d7718":"print(accuracy_score(y_test, y_predict))\nprint(roc_auc_score(y_test, y_pred_proba))\nprint(confusion_matrix(y_test, y_predict))","7c1258a6":"print(classification_report(y_test,y_predict))","71f7d0f6":"from pylab import rcParams\nrcParams['figure.figsize'] = 12, 9","646282e9":"feat_importances = pd.Series(model.feature_importances_, index=modelling_cols)\nfeat_importances.nlargest(15).plot(kind='barh', color = 'b')\nplt.title(\"Feature Importance Plot\")\nplt.xlabel(\"Feature Importance Score (Larger value indicates more important)\")\nplt.plot()","3f579ec5":"correlation_with_target","8090fcb2":"df_feature_imp = feat_importances.to_frame()\ndf_feature_imp = df_feature_imp.reset_index()\ndf_feature_imp.columns = ['Variable', 'Feature_Importance']\ndf_featuresImp_correlation = df_feature_imp.merge(correlation_with_target, how ='left')\ndf_featuresImp_correlation['Feature_Importance_New'] = np.where(df_featuresImp_correlation['Correlation']<0,-1*df_featuresImp_correlation['Feature_Importance'],df_featuresImp_correlation['Feature_Importance'])","748cdfa7":"df_featuresImp_correlation","7b7c50d7":"def diverging_bar_plot(df,variable_col, f_imp_col, mod_f_imp_col, corr_col, n_features):\n    # Prepare Data\n    print([x for x in df])\n    #x = df.loc[:, ['mpg']]\n    #df['mpg_z'] = (x - x.mean())\/x.std()\n    \n    df['colors'] = ['red' if x[corr_col] < 0 else 'green' for i,x in df.iterrows()]\n    df.sort_values(f_imp_col, inplace=True)\n    df = df.reset_index(drop=True)\n    #df.reindex(df[mod_f_imp_col].sort_values().index)\n    #SUBSET\n    df = df[-1*n_features:]\n    # Draw plot\n    plt.figure(figsize=(14,10), dpi= 80)\n    plt.hlines(y=df.index, xmin=0, xmax=df[mod_f_imp_col], color=df.colors, alpha=0.4, linewidth=5)\n    \n    # Decorations\n    plt.gca().set(ylabel='$Feature$', xlabel='$Feature Importance$')\n    plt.yticks(df.index, df[variable_col], fontsize=12)\n    plt.title('Feature Importance-Correlation Plot', fontdict={'size':20})\n    plt.grid(linestyle='--', alpha=0.5)\n    plt.show()\n    #plt.savefig(plot_dir + \"feat_importances_correlation_plot.png\", bbox_inches='tight')","8bbed691":"fig = diverging_bar_plot(df_featuresImp_correlation,'Variable','Feature_Importance','Feature_Importance_New','Correlation', 30)","910328cb":"df_final[['odor_n','Class']].describe()\nodor_check = pd.crosstab(df_final.odor_n, df_final.Class)\nprint(odor_check)\nprint(\"Around \" + str(odor_check[0][1]\/(odor_check[0][0] + odor_check[0][1])) +\" percent of odorless mushroom are poisonous\")\nprint(\"Around \" + str(odor_check[1][0]\/(odor_check[1][0] + odor_check[1][1])) +\" percent of mushrooms with Odor are edible\")\nprint(\"Combined %age \" + str((odor_check[0][1] + odor_check[1][0])\/(odor_check.values.sum())))\nprint(\"This proves our hypothesis true.\")","af568606":"## Test Data Metrics - Accuracy and ROC (Logistic Regression)","c023a746":"# Feature Importance","1d139c4b":"# Modeling","0edcfae3":"## Test Data Metrics - Accuracy and ROC (KNN)","b7137dc8":"## Training Data Metrics - Accuracy and ROC (Random Forest)","804c0609":"# Feature Importance with Correlation Plot - Diverging Bar Plot","7d3689b5":"## Random Forest","f16f28a0":"## Test Data Metrics - Accuracy and ROC (Random Forest)","496b78ca":"## Test Data Metrics - Accuracy and ROC (Naive Bayes)","46093253":"# Categorical Variable Conversion - One hot encoding","2a193235":"# Target Variable conversion to binary","2f88f670":"## Decision Tree","816ffab9":"## Test Data Metrics - Accuracy and ROC (Decision Tree)","4f03962b":"## KNN (K-Nearest Neigbours)","05ec5cbc":"## SVM - Support Vector Machine","481a20ab":"# Correlation","d7e8d808":"## Logistic Regression","70061805":"# Checking for missing Values","ce8fa06f":"## Naive Bayes","fb59a1ca":"## Test Data Metrics - Accuracy and ROC (SVM Classifier)","07498030":"## Having odour (more) suggests that the mushroom is not poisonous (low) and vice versa, lets validate it with some quick EDA.","5ee601bd":"## Gradient Boosting","1bdcb9df":"# Inference","930601c5":"## Test Data Metrics - Accuracy and ROC (Gradient Boost)"}}