{"cell_type":{"fa7f5bb4":"code","75bb0fa3":"code","b75044f3":"code","5e609b3f":"code","5c22aa18":"code","2f92ad9e":"code","a6b5af3f":"code","8bb44a4e":"code","4b17d7dc":"code","a085d75a":"code","45d7ecbf":"code","ccf5f4e3":"code","a6b4c579":"code","3c843b6e":"code","8ae98311":"code","edeef048":"code","cbbfa5ee":"code","aff3ef1f":"code","16f12e80":"code","f6bb70f1":"code","dbaec668":"code","a1ae6adc":"code","07546c3d":"code","fa497b8a":"code","216d03cd":"code","92b5b0f2":"code","a8c05697":"code","4bad8407":"code","8002a5e1":"code","c615e493":"code","a2662c21":"code","60a4584c":"markdown","52daeee9":"markdown","a4b7be3d":"markdown","ca26ffbf":"markdown","1f134141":"markdown","8e488149":"markdown","12ee5819":"markdown","627c5771":"markdown","c09877bc":"markdown","d4ac1d53":"markdown","64ef3655":"markdown","f097023f":"markdown","508a608d":"markdown","44367245":"markdown","3e4fee27":"markdown","eafb5cd9":"markdown","89b9cb49":"markdown","9adaaf1a":"markdown"},"source":{"fa7f5bb4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","75bb0fa3":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","b75044f3":"train.describe()","5e609b3f":"train.describe(include=['O'])","5c22aa18":"train.info()","2f92ad9e":"# Which columns of the traing set contain missing data\nt_size = len(train)\nnull_counts = train.isnull().sum().sort_values(ascending = False)\nnull_counts = pd.DataFrame({'column': null_counts.index, 'null values': null_counts.values})\nnull_counts['prz'] = null_counts['null values'] \/ t_size\nnull_counts[null_counts['null values']!=0]","a6b5af3f":"# look at numeric and categorical values separately \ndf_num = train[['Age','SibSp','Parch','Fare']]\ndf_cat = train[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]\n","8bb44a4e":"#distributions for all numeric variables \nfor i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()\n","4b17d7dc":"print(df_num.corr())\nnames = list(df_num.corr().axes[0])\n\n# Setting the labels of x axis and xticks\nplt.xticks(ticks=np.arange(len(names)),labels=names,rotation=90)\n# Setting the labels of y axis and yticks\nplt.yticks(ticks=np.arange(len(names)),labels=names)\n# use the imshow function to generate a heatmap\n# cmap parameter gives color to the graph\n# setting the interpolation will lead to different types of graphs\nheatmap = plt.imshow(df_num.corr(), cmap='gray_r',interpolation=\"nearest\")\nplt.colorbar(heatmap)","a085d75a":"print(train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean())\nprint(40*'-')\nprint(train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean())","45d7ecbf":"# compare survival rate across Age, SibSp, Parch, and Fare using averages \npd.pivot_table(train, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])","ccf5f4e3":"for i in df_cat.columns:\n    sns.barplot(df_cat[i].value_counts().index,df_cat[i].value_counts()).set_title(i)\n    plt.show()","a6b4c579":"# Comparing survival and each of these categorical variables \nprint(pd.pivot_table(train, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(train, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(train, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))","3c843b6e":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(test.describe())\nprint(80*'-')\nprint(test.info())\nprint(80*'-')\n# Which columns of the traing set contain missing data\nnull_counts = test.isnull().sum().sort_values(ascending = False)\nnull_counts = pd.DataFrame({'column': null_counts.index, 'null values': null_counts.values})\nnull_counts['prz'] = null_counts['null values'] \/len(test)\nprint(null_counts[null_counts['null values']!=0])\n","8ae98311":"#Dropping feature Ticket and Cabin\ntrain_df = train.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n#Converting feature Sex to int\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","edeef048":"freq_port = train_df.Embarked.dropna().mode()[0]\nprint(freq_port)\nmedian_fare = test_df.Fare.dropna().mode()[0]\nprint(median_fare)","cbbfa5ee":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    dataset['Fare'] = dataset['Fare'].fillna(median_fare)","aff3ef1f":"correlation = train_df.corr()\nc_test = test_df.corr()\nnames = list(correlation.axes[0])\n\nprint(correlation)\nprint(50*'-')\nprint(c_test)\n\n# Setting the labels of x axis and xticks\nplt.xticks(ticks=np.arange(len(names)),labels=names,rotation=90)\n# Setting the labels of y axis and yticks\nplt.yticks(ticks=np.arange(len(names)),labels=names)\n# use the imshow function to generate a heatmap\n# cmap parameter gives color to the graph\n# setting the interpolation will lead to different types of graphs\nheatmap = plt.imshow(correlation.corr(), cmap='RdBu',vmin =-1,vmax =1)\nplt.colorbar()\nplt.show()","16f12e80":"names = list(c_test.axes[0])\n# same thing for testdata\nplt.xticks(ticks=np.arange(len(names)),labels=names,rotation=90)\nplt.yticks(ticks=np.arange(len(names)),labels=names)\nheatmap = plt.imshow(c_test, cmap='RdBu',vmin =-1,vmax =1)\nplt.colorbar(heatmap)\nplt.show()","f6bb70f1":"# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')\ngrid = sns.FacetGrid(train_df, row='Pclass', col='SibSp', size=2.2, aspect=2)\ngrid.map(plt.hist, 'Age', alpha=.8, bins=10)\ngrid.add_legend()\n","dbaec668":"guess_ages = np.zeros((9,3))\n\nfor dataset in combine:\n    for i in range(0,9):\n        for j in range(0,3):\n            guess_df = dataset[(dataset['SibSp'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n            # print(guess_df.shape[0])\n            if guess_df.shape[0] == 0:\n                guess_df = dataset[dataset['Pclass'] == j+1]['Age'].dropna() \n            #print(\"SibSp: {}   Pclass: {}   median:{}\".format(i,j+1,guess_df.median()))\n            # print(guess_df)\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    # print(guess_ages)\n    for i in range(0,9):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.SibSp == i) & (dataset.Pclass == j+1),'Age'] = guess_ages[i,j]\n    print(dataset.info())\n    print(40*'-')\n    dataset['Age'] = dataset['Age'].astype(int)\n","a1ae6adc":"# function for standard heatmap heatmaps\ndef create_heatmap(data,color_scale,mytitle=''):\n    # Setting the labels of x axis and xticks\n    plt.xticks(ticks=np.arange(len(data.columns)),labels=data.columns,rotation=90)\n    # Setting the labels of y axis and yticks\n    plt.yticks(ticks=np.arange(len(data.index.values)),labels=data.index.values)\n    # use the imshow function to generate a heatmap\n    # cmap parameter gives color to the graph\n    # setting the interpolation will lead to different types of graphs\n    hp = plt.imshow(data, cmap=color_scale)\n    plt.colorbar(hp)\n    plt.title(mytitle)\n    plt.show()\n","07546c3d":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","fa497b8a":"title_df = train_df[['Survived','Title','Sex']].rename(columns = {'Sex':'female'})\ntitle_df['male'] =  (title_df['female'] + 1) % 2\ntitle_df = title_df.groupby('Title').agg('sum')\ntitle_df['total'] =  title_df['male'] + title_df['female']\ntitle_df = title_df.sort_values(by='total',ascending=False)\ntitle_df['total'].plot.bar()\nplt.show()","216d03cd":"title_df = train_df.copy()\ntitle_df['Title'] = title_df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntitle_df['Title'] = title_df['Title'].replace('Mlle', 'Miss')\ntitle_df['Title'] = title_df['Title'].replace('Ms', 'Miss')\ntitle_df['Title'] = title_df['Title'].replace('Mme', 'Mrs')\ntitle_df = title_df[['Survived','Title','Sex']].rename(columns = {'Sex':'female'})\ntitle_df['male'] =  (title_df['female'] + 1) % 2\ntitle_df = title_df.groupby('Title').agg('sum')\ntitle_df['total'] =  title_df['male'] + title_df['female']\ntitle_df = title_df.sort_values(by='total',ascending=False)\ntitle_df['total'].plot.bar()\nplt.show()","92b5b0f2":"title_ndf = title_df.copy()\nfor col in title_df.columns:\n    title_ndf[col] =  title_ndf[col]\/title_ndf['total']\ncreate_heatmap(title_ndf,'Greys','Title gender and survival split split')\ntitle_ndf","a8c05697":"expected_rates_by_gender = train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()\nsurvive_rate_male = expected_rates_by_gender['Survived'][0]\nsurvive_rate_female = expected_rates_by_gender['Survived'][1]","4bad8407":"title_ndf['expected_gender_surrviverate'] = survive_rate_male * title_ndf['male'] + survive_rate_female * title_ndf['female']\ntitle_ndf['diff_gender_surrviverate'] = title_ndf['Survived'] -title_ndf['expected_gender_surrviverate'] \ntitle_ndf['diff_gender_surrviverate'].plot.bar()\ntitle_ndf","8002a5e1":"women = train.loc[train.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\nmen = train.loc[train.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","c615e493":"ages_classes = []\ncounts = []\nsurvived = []\nrates = []\n\n\nfor i in range(0,9*2-1):\n    lower = i*5\n    upper = (i+1)*5\n    tmp = train.loc[(train.Age >= lower) & (train.Age < upper)]['Survived']\n    \n    if len(tmp) > 0:\n        ages_classes.append(str(lower) + '-' + str(upper))\n        counts.append(len(tmp))\n        survived.append(sum(tmp))\n        rates.append(sum(tmp)\/len(tmp))\n    else: \n        ages_classes.append(str(lower) + '-' + str(upper))\n        counts.append(0)\n        survived.append(0)\n        rates.append(0)\n\n# assign data of lists.  \ndata = {'Age Categorie': ages_classes , 'Total counts': counts, 'survived':survived, 'rates':rates}  \n# Create DataFrame  \ndf = pd.DataFrame(data) \nprint(df)\n\nax = plt.gca()\n\ndf.plot(kind=\"line\", x=\"Age Categorie\", y=\"survived\",ax=ax).set_title('survived')\ndf.plot(kind=\"line\", x=\"Age Categorie\", y=\"Total counts\",color=\"red\", ax=ax)\ndf.plot(kind=\"bar\", x=\"Age Categorie\", y=\"rates\").set_title('rates')\n\n","a2662c21":"male_ages_classes = []\nmale_counts = []\nmale_survived = []\nmale_rates = []\n\nfemale_ages_classes = []\nfemale_counts = []\nfemale_survived = []\nfemale_rates = []\n\nfor i in range(0,9*2-1):\n    lower = i*5\n    upper = (i+1)*5\n    tmp = train.loc[(train.Age >= lower) & (train.Age < upper) & (train.Sex == 'male')]['Survived']\n    \n    if len(tmp) > 0:\n        male_ages_classes.append(str(lower) + '-' + str(upper))\n        male_counts.append(len(tmp))\n        male_survived.append(sum(tmp))\n        male_rates.append(sum(tmp)\/len(tmp))\n    tmp = train.loc[(train.Age >= lower) & (train.Age < upper) & (train.Sex == 'female')]['Survived']\n    \n    if len(tmp) > 0:\n        female_ages_classes.append(str(lower) + '-' + str(upper))\n        female_counts.append(len(tmp))\n        female_survived.append(sum(tmp))\n        female_rates.append(sum(tmp)\/len(tmp))\n\n# assign data of lists.  \ndataM  = {'Age Categorie': male_ages_classes , 'Total counts': male_counts, 'survived':male_survived, 'rates':male_rates} \ndataF  = {'Age Categorie': female_ages_classes , 'Total counts': female_counts, 'survived': female_survived, 'rates':female_rates}  \n# Create DataFrame  \ndfM = pd.DataFrame(dataM) \ndfF = pd.DataFrame(dataF) \nprint(\"Male:\")\nprint(dfM)\nprint(\"\\n\")\nprint(\"Female:\")\nprint(dfF)\n\nax = plt.gca()\nax.axhline(dfM['survived'].mean(), color='green', linestyle='dotted', linewidth=2)\nax.axhline(dfF['survived'].mean(), color='pink',  linestyle='dotted', linewidth=2)\n\ndfM.plot(kind=\"line\", x=\"Age Categorie\", y=\"survived\",color=\"green\", ax=ax)\ndfF.plot(kind=\"line\", x=\"Age Categorie\", y=\"survived\",color=\"pink\", ax=ax)\n\n\nax = plt.gca()\nax.axhline(dfM['rates'].mean(), color='green', linestyle='dotted', linewidth=2)\ndfM.plot(kind=\"bar\", x=\"Age Categorie\", y=\"rates\",color=\"green\").set_title('rates Male')\nax = plt.gca()\nax.axhline(dfF['rates'].mean(), color='pink',  linestyle='dotted', linewidth=2)\ndfF.plot(kind=\"bar\", x=\"Age Categorie\", y=\"rates\",color=\"pink\").set_title('rates Female')\n\n","60a4584c":"# Titanic Project - Basic Data Visualisation and Analysis\n\nThis is my first Project on Kaggle and my first project using Jupyter\/Kaggle notebooks. Therefore I participated in  the Titanic Competition. The goal of the competition is to predict, whether a passanger on the titanic survied. For this task, you are given a data sample of 891 entries with information on e.g. age, sex, and whether the passenger survived. Based on this, you have to create a model to predict, who out of 418 different passengers has survived. \n\nDuring this competition, I learn the following things:\n\n* Using and documenting a project in a Jupyter\/Kaggle Notebook.\n* Submitting a model to the competition.\n* Creating a basic analysis (Data Cleaning, Data Exploration, Feature Engineering, Basic Model Building)\n\n# Outline\n0. **References**:\n    Due to this being my first project, I will use other Notebooks and sources. These are listed and explained here.\n    \n1. **Goal Setting**:\n    Inside this part, I will set some goals and ask questions, which I will try to solve by the end.\n    \n2. **Data Exploration**:\n    In this part, I will use Histograms and Correlation Maps to get more knowledge for the upcoming steps.\n    \n3. **Data Cleaning**:\n    There are a lot of cells with null values, which have to be dealt with before continuing.\n    \n-------------------------------------------------------------------------------------------------------\n### In progress\n\n4.  **Feature Engineering**:\n\tWithin this section, I will combine different columns of the given Data to generate new features.\n    \n5.  **Basic Model Building**:\n\tDuring this section, I am going to decide, which model to use in this use case.\n    \n6.  **Results**:\n\tIn the last part, I will sum up the results and facts I found during my analysis.","52daeee9":"### Filling up: Embarked and\n*S* is the most common value in Embarked. Filled missing values with *S*.\n\n","a4b7be3d":"## Analysis of Test Data\n\n### Methods\n* Checked the amounts of missing values\/data\n\n### Results\n\n* **Missing data and Null values**:\n    * The Dataset contains only 418 of the actual number of passengers on board the Titanic (2,224).\n    * There is some missing Data in Age, Embarked and Cabin:\n        * Cabin: 327 null values or 78.2%\n        * Age: 86 null values or 20.6% \n        * Fare: 1 null values or 0.24%\n\n\n","ca26ffbf":"### Dropping and Converting:","1f134141":"# 2. Understanding the Data\n## Loading the Data\n\nFirst, I need to load the used packages, libraries and data.","8e488149":"# 1. Goal Setting\nDuring this project, I want to answer the following questions:\n1. Did the wealthy survive more often?\n2. Does the saying \"children and woman first\" apply to this situation?\n3. Did the location of the cabins matter?\n\nAdditionally, I want to create a model with at least 70% accuracy. ","12ee5819":"========================================================================================","627c5771":"### Age corrolates with...\n\nFirst, I need to discover features, which correlate with age. For this task I will use the correlation by Pearson. I will use the test Data to get more insight.\n\n#### Results\n* Train dataset suggests a light correlation between *Age* and *Pclass* (-0.369)\n* Train dataset suggests a light correlation between *Age* and *SibSp* (-0.308)\n* Train dataset suggests a minor correlation between *Age* and *Parch* (-0.189)\n* Test dataset suggests a strong correlation between *Age* and *Pclass* (0.492) \n* Test dataset suggests a light correlation between *Age* and *Fare* (0.338) \n* Train dataset suggests a strong correlation between *Pclass* and *Fare* (-0.550) \n* Test dataset suggests a strong correlation between *Pclass* and *Fare* (-0.577) \n\n#### Conclusion\nBoth datasets (train and test) suggest a correlation between Age and Pclass. For the features *SibSp*, *Parch* and *Fare* are conflicting. For this usecase I will use *Pclass* and *SibSp* to predict the *age*. So here I choose a different approach as [Manav Sehgal](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions)\n\n**Reasons**:\n* The training dataset contains more rows than the test datase. Therefore I will go with the insights generated by the train set.\n* The correlation between *Parch* and *Age* is too low.\n* Both datasets show a huge correlation between *Pclass* and *Fare*. Hence I will not use both *Pclass* and *Fare* in one prediction.","c09877bc":"# 4. Feature Engineering \n## Tasks \n* Creating a new feature *Title* by extracting the title out of the feature *Name*.\n* Creating a new feature *Familiy* based on *Parch* and *SibSp*.\n* Creating a new feature *Age bands* to*.\n\nFor the new features I will have look at their correlation with the survival rate. Low correlation will be dropped.\n\n\n\n* I may want to create a new feature called Family based on Parch and SibSp to get total count of family members on board.\n* I may want to engineer the Name feature to extract Title as a new feature.\n* I may want to create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.\n* I may also want to create a Fare range feature if it helps our analysis.\n* I may also want to get the title of a Person and use this to create a new column (e.g. privileged)","d4ac1d53":"# 3.Data Cleaning \n\n**Dropping** not needed features helps to speed up our analysis:\n* Dropping  *Cabin* from the train set. It hast to many null values.\n* Dropping  *Cabin* from the train set. Too many duplicates.\n\n**Converting a categorical feature**:\n* Converting *Sex* to a numerical feature. This might be relevant for model algorithms.\n* Using *female=1* and *male=0*\n\n**Filling up** uncomplete Data\n\n* *Embarked* is not complete in the train dataset. Here I will fill the two missing values with the most occouring value.\n* *Fare* is not complete in the test dataset. Here I will fill the  missing value with the median of *Fare* in the test set.\n* *Age* is not complete, but an important feature. Therefore I will try to fill up the random column. For this task, I will consider three options:\n    1. Choosing a default value: e.g. 0 or the mean.\n    2. Choosing a random number in between the mean and the standard deviation.\n    3. Looking for correlating features in the dataset. then using the Median of similar data to get an estimation of the age.\n\n    Since 1. and 2. add noise to the dataset, I will use option 3. I personally never did this. Therefore I read the explanation in the notebook by [Manav Sehgal](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions) and tried to apply it by myself.\n\n\n","64ef3655":"### Age Prediction\n\nLargely taken over from [Manav Sehgal](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions) and applied to my features:\n* Create Histograms for the feautre *Age* with all combinations of *SibSp* and *Pclass* \n* Iterate over *SibSp* (0,1,2,3,4,6,8) and *Pclass* (1, 2, 3) to calculate guessed values of Age for the 7\\*3=21 combinations.\n* For simplification of implementation I iterated over range(0,9) instead of the actual values of *SibSp*. If there was no data for the *SibSp* value, I used the whole *Pclass* instead.\n\n","f097023f":"### Analysis of Numerical Data","508a608d":"========================================================================================","44367245":"## Creating Feature: *Title*\n### Method\n* I will extract the *Title* by splitting on a space\n* Count them\n* Significant values: at least 5% of total respective gender (in all cases execpte one doctor the title indicates the geneder)\n* combine alternatives like Mr, Mister\n* combine rest to rare\n* look at the correlation with and without gender\n    * use a heatmap with:\n    * index = title bands\n    * col\\[0\\] = male population normalized to own total \n    * col\\[1\\] = female population normalized to own total\n    * col\\[2\\] = general survival rate\n    * col\\[3\\] = filtered survival rate (by unsing dominante Sex)\n\n### Results\nThere are a lot of diffret titels used\n","3e4fee27":"=========================================================================================\n### Analysis of Cagegorial Data","eafb5cd9":"## Analysis of Training Data\n\n### Methods\n* Looked at the header of the training and test set\n* Checked the amounts of missing values\/data\n* Devided columns in *numerical* and *categorial* Data\n* Analytics for *numerical* Data  \n    * Created histograms\n    * Created heatmap for correlation\n    * Created pivottabels to compare *survival rates* across variables\n* Analytics for *categorial* Data  \n    * Used bar charts for description \n    * Used pivottabels to understand the relationship with *survival*\n\n### Results\n\n* **Missing data and Null values**:\n    * The Dataset contains only 891 of the actual number of passengers on board the Titanic (2,224).\n    * There is some missing Data in Age, Embarked and Cabin:\n        * Cabin: 687 null values or 77.1%\n        * Age: 177 null values or 19.9% \n        * Embarked: 2 null values or 0.22%\n* The feature *Ticket* has a high ration of duplicates (22%).\n* **Correlation Analysis**\n    * *Parch* and *SibSP* has a correlation. Families might have been traveling together.\n    * *Fare* has a low correlation with *Age*,*Parch* and *SibSP*. Therefore it might be usefull for Feature Engineering.\n    * Although most passengers were traveling in the 3. class, they had the least amount of survivors.\n    * Embarking in Southampton drastically lowers the chance of survival.\n    * *Cabin* does not provide anything good in its current state.\n","89b9cb49":"# 0. References:\n\nFirst I read the *Titanic Tutorial* by Alexis Cook (https:\/\/www.kaggle.com\/alexisbcook\/titanic-tutorial) to get started with kaggle.\nIn the following steps, I used the documentation of matplotlib and the following Notebooks:\n* [*the Beginner's Guide(Titanic)*](https:\/\/www.kaggle.com\/mohammadrezasalemi\/beginner-s-guide-titanic) by mohammadreza salemi\n* [*Titanic Project Example*](https:\/\/www.kaggle.com\/kenjee\/titanic-project-example) by Ken Jee \n* [*Titanic Data Science Solutions*](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions) by Manav Sehgal","9adaaf1a":"========================================================================================\n"}}