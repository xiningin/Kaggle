{"cell_type":{"cb75cc02":"code","1b5ce1d7":"code","b27890aa":"code","c2343038":"code","862acd94":"code","9ef5cd50":"code","670f07eb":"code","bc13e1ff":"code","7e142e76":"code","c89ed613":"code","6c26589f":"code","846eea8a":"code","1fe73b50":"code","d19147cf":"code","a25924d9":"code","ad1ed620":"code","c80da30d":"code","e2340fb9":"code","d9b76a8c":"code","7f5e5001":"code","583af04e":"code","c502ee81":"code","0f5d50a7":"code","65c2113b":"code","625ed7d5":"code","9ee5e07e":"code","74e3e66a":"code","63e881e6":"code","e7fb9349":"code","22f39419":"code","ddaa94ba":"code","4b39b6d6":"code","a103a493":"code","669531a1":"code","d553d67c":"code","686e8c02":"code","a6104ea4":"code","7d62df39":"code","d0fad7bc":"code","217a843a":"code","22d57328":"code","2995ab7f":"code","dd709411":"code","1bd4e2a0":"code","ffb1d9d0":"code","5dcd27cf":"code","0acc0da4":"code","542ccd88":"code","3ef7a8b3":"code","2391f0fa":"code","091c51dd":"code","e0455765":"code","d9263c86":"code","3e64717d":"code","c85da1fd":"code","78716877":"code","4af4c4d7":"code","536f95dc":"code","09d2f37a":"code","021bc759":"code","040dde0c":"code","3e9b6911":"code","58a4defa":"code","d2e2732b":"code","3dd8cf8b":"code","d23d2da0":"code","a83c0c71":"code","38ec7325":"code","b6b35aa3":"code","bf6957ab":"code","a2973a83":"code","3c81bfee":"code","0771b70e":"code","3f6f00ea":"code","2af8bdad":"code","31a36e4e":"code","a01add85":"code","4ed16c8e":"code","a6b468e2":"code","700ed3ab":"code","73e3c8ce":"code","5b9f6636":"code","e5f54192":"code","f3b0989c":"code","57574e5a":"code","44341c9e":"code","35b99f7b":"code","11ed0fdb":"code","61bb0ed1":"code","3dee5fdb":"code","fe808b50":"code","982cd061":"code","0eb4c45d":"code","709e35ab":"code","edd68139":"code","bd541b7c":"code","2c6dabbe":"code","ed05ec1f":"code","c947ec65":"code","42401c56":"code","2513b571":"code","992a9f93":"code","4caa0c61":"code","6b32b91c":"code","7389d6b4":"code","d1b60f5d":"code","d6f922dc":"code","820be967":"code","db968be8":"code","fa29bebd":"code","655cfc71":"markdown","5e9d1192":"markdown","20da5bf2":"markdown","f7a1e872":"markdown","c0fe8abd":"markdown","5116427c":"markdown","65b844a9":"markdown","29c787a0":"markdown","eed1039a":"markdown","beec2879":"markdown","c89d939e":"markdown","5df0186c":"markdown","5e54ef31":"markdown","5e72209c":"markdown","37242656":"markdown","27aec457":"markdown","9e6e6c89":"markdown","9079fab7":"markdown","53b85bbd":"markdown","ba23f416":"markdown","c22a43f8":"markdown","7a859b8a":"markdown","a173dd55":"markdown","a1ca198c":"markdown","ca727c86":"markdown","aa6777c0":"markdown","f823e028":"markdown","15599f94":"markdown","d6665f8a":"markdown","9cc00bd0":"markdown","3d51b13f":"markdown","32b09a1c":"markdown","56911b0a":"markdown","486adb28":"markdown","c8f09a86":"markdown","ed0567cb":"markdown","4a3de153":"markdown","ee5a0ce8":"markdown","10e689fe":"markdown","728bcba0":"markdown","e0a9f950":"markdown","e699cae1":"markdown","9e7c19dc":"markdown","dca88ba2":"markdown","60b3b69a":"markdown","99bde15a":"markdown","405224f5":"markdown","8fd85a89":"markdown","377ed23e":"markdown","b376682f":"markdown","fdb23cb8":"markdown","08fc6bf5":"markdown","b96a8d18":"markdown","ea842d9e":"markdown","086ba85d":"markdown","ee611e4c":"markdown","e0dab939":"markdown","b16fe1f0":"markdown","7f74b19d":"markdown","184cd40b":"markdown","ee139cc8":"markdown","1f74c5ba":"markdown","f58261c8":"markdown","341a8b71":"markdown","b4ee49a3":"markdown","a21a0d6e":"markdown","38796d8b":"markdown","4aa1087b":"markdown","d613f5d3":"markdown","3bdb4e80":"markdown","5111880c":"markdown"},"source":{"cb75cc02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport warnings\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nimport math\nimport seaborn as sns\nimport datetime as dt\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom scipy.stats import skew\nfrom IPython.display import Markdown, display, Image, display_html","1b5ce1d7":"sns.set()\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","b27890aa":"def read_csv(csv_path, missing_values=[]):\n    try:\n        df = pd.read_csv(csv_path, na_values=missing_values)\n        print(\"file read as csv\")\n        return df\n    except FileNotFoundError:\n        print(\"file not found\")\n\ndef save_csv(df, csv_path):\n    try:\n        df.to_csv(csv_path, index=False)\n        print('File Successfully Saved.!!!')\n        return df\n\n    except Exception:\n        print(\"Save failed...\")\n\n\ndef percent_missing(df: pd.DataFrame) -> float:\n\n        totalCells = np.product(df.shape)\n        missingCount = df.isnull().sum()\n        totalMissing = missingCount.sum()\n        return round((totalMissing \/ totalCells) * 100, 2)\ndef percent_missing_for_col(df: pd.DataFrame, col_name: str) -> float:\n        total_count = len(df[col_name])\n        if total_count <= 0:\n            return 0.0\n        missing_count = df[col_name].isnull().sum()\n\n        return round((missing_count \/ total_count) * 100, 2)\n\ndef drop_duplicates(df):\n    old = df.shape[0]\n    df.drop_duplicates(inplace=True)\n    new = df.shape[0]\n    count = old - new\n    if (count == 0):\n        print(\"No duplicate rows were found.\")\n    else:\n        print(f\"{count} duplicate rows were found and removed.\")\n\ndef fix_missing_mode(df, cols):\n    for col in cols:\n        mode = df[col].mode()[0]\n        count = df[col].isna().sum()\n        df[col] = df[col].fillna(mode)\n        if type(mode) == 'str':\n            print(f\"{count} missing values in the column {col} have been replaced by its mode value \\'{mode}\\'.\")\n        else:\n            print(f\"{count} missing values in the column {col} have been replaced by its mode value {mode}.\")\n\ndef fix_missing_value(df, col, value):\n    count = df[col].isna().sum()\n    df[col] = df[col].fillna(value)\n    if type(value) == 'str':\n        print(f\"{count} missing values in the column {col} have been replaced by \\'{value}\\'.\")\n    else:\n        print(f\"{count} missing values in the column {col} have been replaced by {value}.\")","c2343038":"class DataOverview:\n    \"\"\"\n    A class used to get some information about a given dataframe. \n    It extracts the number of rows and columns and \n    calculates the percent of missing values and unique values of each column.\n    \"\"\"\n    \n    def __init__(self, df):\n        \n        self.df = df\n    \n    def read_head(self, top=5):\n        return self.df.head(top)\n    \n    # returning the number of rows columns and column information\n    def get_info(self):\n        row_count, col_count = self.df.shape\n    \n        print(f\"Number of rows: {row_count}\")\n        print(f\"Number of columns: {col_count}\")\n        print(\"================================\")\n\n        return (row_count, col_count), self.df.info()\n    \n    def get_count(self, column_name):\n        return pd.DataFrame(self.df[column_name].value_counts())\n    \n    # getting the null count for every column\n    def get_null_count(self, column_name):\n        print(\"Null values count\")\n        print(self.df.isnull().sum())\n        return self.df.isnull().sum()\n    \n    # getting the percentage of missing values\n    def get_percent_missing(self):\n        percent_missing_info = percent_missing(self.df)\n        null_percent_df = pd.DataFrame(columns = ['column', 'null_percent'])\n        columns = self.df.columns.values.tolist()\n        null_percent_df['column'] = columns\n        null_percent_df['null_percent'] = null_percent_df['column'].map(lambda x: percent_missing_for_col(self.df, x))\n        \n        \n        return null_percent_df.sort_values(by=['null_percent'], ascending = False), percent_missing_info\n    \n    def percent_missing_values(self):\n\n        # Calculate total number of cells in dataframe\n        totalCells = np.product(self.df.shape)\n\n        # Count number of missing values per column\n        missingCount = self.df.isnull().sum()\n\n        # Calculate total number of missing values\n        totalMissing = missingCount.sum()\n\n        # Calculate percentage of missing values\n        print(\"The dataset contains\", round(((totalMissing\/totalCells) * 100), 2), \"%\", \"missing values.\")\n    \n\n    def count_missing_rows(self):\n\n        # Calculate total number rows with missing values\n        missing_rows = sum([True for idx,row in self.df.iterrows() if any(row.isna())])\n\n        # Calculate total number of rows\n        total_rows = self.df.shape[0]\n\n        # Calculate the percentage of missing rows\n        print(f\"{missing_rows} rows({round(((missing_rows\/total_rows) * 100), 2)}%) contain atleast one missing value.\")\n\n    def missing_values_table(self):\n        \n        df = self.df\n        # Total missing values\n        mis_val = df.isnull().sum()\n\n        # Percentage of missing values\n        mis_val_percent = 100 * mis_val \/ len(df)\n\n        # Data type of missing values\n        mis_val_dtype = df.dtypes\n        \n        # Total unique values in each column\n        unique_val = df.nunique()\n\n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent, unique_val, mis_val_dtype], axis=1)\n\n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Missing Values', 2: 'Unique Values',  3: 'Dtype',})\n\n        # Sort the table by percentage of missing descending and remove columns with no missing values\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,0] != 0].sort_values(\n        '% of Missing Values', ascending=False).round(2)\n        \n        # Reset the index as a column\n        mis_val_table_ren_columns.reset_index(inplace=True)\n        mis_val_table_ren_columns.rename(columns={'index': 'Columns'}, inplace=True)\n\n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n            \" columns that have missing values.\")\n\n        if mis_val_table_ren_columns.shape[0] == 0:\n            return\n\n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","862acd94":"base_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\"","9ef5cd50":"district = read_csv(f\"{base_path}\/districts_info.csv\")\ndistrict.head()","670f07eb":"# rows and columns in the df\ndistrict_overview = DataOverview(district)\ndisplay(district_overview.get_info())","bc13e1ff":"drop_duplicates(district)","7e142e76":"district_overview.percent_missing_values()\ndistrict_overview.count_missing_rows()","c89ed613":"district_overview.missing_values_table()","6c26589f":"# number of rows with missing values for the group('state', 'locale', 'pct_black\/hispanic')\nDataOverview(district[['state', 'locale', 'pct_black\/hispanic']]).count_missing_rows()\n","846eea8a":"\ncleaned_district = district[district['state'].notna()].reset_index(drop=True)","1fe73b50":"DataOverview(cleaned_district).missing_values_table()","d19147cf":"cleaned_district[\"pp_total_raw\"].value_counts()","a25924d9":"\ncleaned_district[\"pct_free\/reduced\"].value_counts()\n","ad1ed620":"\ncleaned_district[\"county_connections_ratio\"].value_counts()\n","c80da30d":"fix_missing_mode(cleaned_district, ['county_connections_ratio'])","e2340fb9":"DataOverview(cleaned_district).missing_values_table()","d9b76a8c":"# UTILITY FUNCTIONS\n\ndef get_mode_for_locale(df, locale, column):\n\n    filtered_df = df[df[\"locale\"] == locale]\n    _mode = filtered_df[column].mode().to_list()\n    \n    if len(_mode) > 0:\n        return _mode[0]\n    \n    return \"[0.0, 0.0[\"\n\ndef handle_missing_for_district(row):\n    \n    if str(row[\"pp_total_raw\"]) == \"nan\":\n        row[\"pp_total_raw\"] = get_mode_for_locale(cleaned_district, row[\"locale\"], \"pp_total_raw\")\n    \n    if str(row[\"pct_free\/reduced\"]) == \"nan\":\n        row[\"pct_free\/reduced\"] = get_mode_for_locale(cleaned_district, row[\"locale\"], \"pct_free\/reduced\")\n    \n    return row","7f5e5001":"cleaned_district = cleaned_district.apply(lambda row: handle_missing_for_district(row), axis=1)\ncleaned_district_overview = DataOverview(cleaned_district)\ncleaned_district_overview.missing_values_table()","583af04e":"fig, ax = plt.subplots(1, 2, figsize=(16,6))\n\nsns.countplot(data=cleaned_district, x='locale', palette='GnBu', ax=ax[0])\nsns.countplot(data=cleaned_district, x='pct_black\/hispanic', palette='GnBu', ax=ax[1])\nplt.show()","c502ee81":"fig, ax = plt.subplots(1, 2,figsize=(16,6))\nsns.countplot(data=cleaned_district, x='pct_free\/reduced', palette='GnBu', ax=ax[0])\nsns.countplot(data=cleaned_district, x='county_connections_ratio', palette='GnBu', ax=ax[1])\n","0f5d50a7":"fig, ax = plt.subplots(figsize=(16,6))\nsns.countplot(data=cleaned_district, y='pp_total_raw', palette='GnBu')\nplt.show()","65c2113b":"state_abb = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}","625ed7d5":"def calualte_mean_from_range(value: str):\n    min_range = eval(value.split(\", \")[0][1:])\n    max_range = eval(value.split(\", \")[1][:-1])\n    return round((min_range + max_range) \/ 2, 1)","9ee5e07e":"cleaned_district['pct_black\/hispanic_mean'] = cleaned_district['pct_black\/hispanic'].map(lambda x: calualte_mean_from_range(x))\ncleaned_district['pct_free\/reduced_mean'] = cleaned_district['pct_free\/reduced'].map(lambda x: calualte_mean_from_range(x))\ncleaned_district['pp_total_raw_mean'] = cleaned_district['pp_total_raw'].map(lambda x: calualte_mean_from_range(x))\ncleaned_district['county_connections_ratio_mean'] = cleaned_district['county_connections_ratio'].map(lambda x: calualte_mean_from_range(x))\ncleaned_district.head()","74e3e66a":"location_count_df = DataOverview(cleaned_district).get_count(\"state\")\n\nlocations = location_count_df.index.map(lambda x: state_abb[x]).to_list()\ndistrict_counts = location_count_df['state'].to_list()\n\nfig = px.choropleth(locations=locations, locationmode=\"USA-states\", color=district_counts, scope=\"usa\", color_continuous_scale='Gnbu')\nfig.show()","63e881e6":"state_pct_black_hispanic_agg = cleaned_district.groupby(\"state\").agg({\"pct_black\/hispanic_mean\": \"mean\"})\n\nlocations = state_pct_black_hispanic_agg.index.map(lambda x: state_abb[x]).to_list()\ncolors = state_pct_black_hispanic_agg['pct_black\/hispanic_mean'].to_list()\nstate_pct_black_hispanic_agg.sort_values(by=[\"pct_black\/hispanic_mean\"], ascending=False)\n\n\nfig = px.choropleth(locations=locations, locationmode=\"USA-states\", color=colors, scope=\"usa\", color_continuous_scale='Gnbu')\nfig.show()","e7fb9349":"state_expediutre_agg = cleaned_district.groupby(\"state\").agg({\"pp_total_raw_mean\": \"mean\"})\n\nlocations = state_expediutre_agg.index.map(lambda x: state_abb[x]).to_list()\ncolors = state_expediutre_agg['pp_total_raw_mean'].to_list()\n\nfig = px.choropleth(locations=locations, locationmode=\"USA-states\", color=colors, scope=\"usa\",  color_continuous_scale='Gnbu')\nfig.show()","22f39419":"pct_free_reduced_mean_agg = cleaned_district.groupby(\"state\").agg({\"pct_free\/reduced_mean\": \"mean\"})\n\nlocations = pct_free_reduced_mean_agg.index.map(lambda x: state_abb[x]).to_list()\ncolors = pct_free_reduced_mean_agg['pct_free\/reduced_mean'].to_list()\n\nfig = px.choropleth(locations=locations, locationmode=\"USA-states\", color=colors, scope=\"usa\",  color_continuous_scale='Gnbu')\nfig.show()","ddaa94ba":"def piePlot(data,title,legend):\n    plt=go.Pie(labels=data.index,values=data.values)\n    fig = go.Figure(data=plt)\n    fig.update_layout(\n    title=title,\n    legend_title=legend,\n    font=dict(\n        family=\"Roboto, monospace\",\n        size=18,\n        color=\"Black\"\n        )\n    )\n    \n    fig.show()\n    fig.data=[]\n    ","4b39b6d6":"data=cleaned_district.groupby('locale')[\"district_id\"].count()\n\npiePlot(data,\"Breakdown of locales of the districts\",\"Locale\")","a103a493":"data=cleaned_district.groupby('pct_black\/hispanic')[\"district_id\"].count()\n\npiePlot(data,\"Breakdown of demographics of the districts\",\"pct_black\/hispanic\")","669531a1":"data=cleaned_district.groupby('pct_free\/reduced')[\"district_id\"].count()\n\npiePlot(data,\"Breakdown of districts by the percentage of students eligible for free or reduced lunch\",\"pct_free\/reduced\")","d553d67c":"data=cleaned_district.groupby(['locale', 'pct_black\/hispanic', 'pct_free\/reduced'],as_index=False).count()\ndata[\"District Count\"]=data[\"district_id\"]\nfig = px.sunburst(data, color_continuous_scale='Blues', path=['locale', 'pct_black\/hispanic', 'pct_free\/reduced'],width=600, height=600, values='District Count')\n# fig.update_layout(uniformtext=dict(minsize=10))\n\nfig.update_traces(textinfo=\"label+percent parent\")\nfig.update_layout(title=\"Breakdown locale, pct_black\/hispanic and pct_free\/reduced in respective rings\",\n    font=dict(\n        family=\"Roboto, monospace\",\n        size=14,\n        color=\"Black\"\n    )\n)\nfig.show()","686e8c02":"data=cleaned_district.groupby(['pct_black\/hispanic', 'pct_free\/reduced'],as_index=False).count()\ndata[\"District Count\"]=data[\"district_id\"]\nfig = px.sunburst(data, color_continuous_scale='Blues', path=[ 'pct_black\/hispanic', 'pct_free\/reduced'],color='pct_free\/reduced',width=600, height=600, values='District Count')\n# fig.update_layout(uniformtext=dict(minsize=10))\n\nfig.update_traces(textinfo=\"label+percent parent\")\nfig.update_layout(title=\"Breakdown pct_black\/hispanic, pct_free\/reduced in respective rings\",\n    font=dict(\n        family=\"Roboto, monospace\",\n        size=14,\n        color=\"Black\"\n    )\n)\n\nfig.show()","a6104ea4":"product_df = read_csv(f\"{base_path}\/products_info.csv\")\nproduct_df.head()","7d62df39":"# rows and columns in the df\nproduct_overview = DataOverview(product_df)\ndisplay(product_overview.get_info())","d0fad7bc":"drop_duplicates(product_df)","217a843a":"product_overview.percent_missing_values()\nproduct_overview.count_missing_rows()","22d57328":"product_overview.missing_values_table()","2995ab7f":"product_df[pd.isna(product_df['Provider\/Company Name'])]","dd709411":"cleaned_product = product_df.dropna(subset=['Provider\/Company Name'])","1bd4e2a0":"DataOverview(cleaned_product).percent_missing_values()","ffb1d9d0":"def get_mode_for_company(df, comp_name, column):\n    filtered_df = df[ df[\"Provider\/Company Name\"] == comp_name]\n\n    _mode = filtered_df[column].mode().to_list()\n    if len(_mode) > 0:\n        return _mode[0]\n    \n    return None\n\ndef handle_missing_for_product(row):\n    \n    if str(row[\"Sector(s)\"]) == \"nan\":\n        row[\"Sector(s)\"] = get_mode_for_company(product_df, row[\"Provider\/Company Name\"], \"Sector(s)\")\n    \n    if str(row[\"Primary Essential Function\"]) == \"nan\":\n        row[\"Primary Essential Function\"] = get_mode_for_company(product_df, row[\"Provider\/Company Name\"], \"Primary Essential Function\")\n    \n    \n    return row\n","5dcd27cf":"cleaned_product = cleaned_product.apply(lambda row: handle_missing_for_product(row), axis=1 )","0acc0da4":"product_overview = DataOverview(cleaned_product)\nproduct_overview.missing_values_table()","542ccd88":"# since missing values of both columns exist together\ncleaned_product.dropna(subset=['Sector(s)'], inplace=True)","3ef7a8b3":"product_overview.missing_values_table()","2391f0fa":"cleaned_product['main_fun'] = cleaned_product['Primary Essential Function'].apply(lambda x: x.split(' - ')[0])\ncleaned_product['sub_fun'] = cleaned_product['Primary Essential Function'].apply(lambda x: x.split(' - ')[1])\n\ncleaned_product.drop(\"Primary Essential Function\", axis=1, inplace=True)","091c51dd":"cleaned_product.head()","e0455765":"display(DataOverview(cleaned_product).get_count(\"main_fun\"))\ndisplay(DataOverview(cleaned_product).get_count(\"sub_fun\"))","d9263c86":"fig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(data=cleaned_product, x='main_fun', palette='GnBu')\nplt.show()","3e64717d":"df = px.data.tips()\nsub_df = cleaned_product[['main_fun', 'sub_fun']]\nsub_df = sub_df.groupby(['main_fun', 'sub_fun']).size().reset_index(name='count')\nfig = px.sunburst(sub_df, path=['main_fun', 'sub_fun'], values='count')\nfig.show()","c85da1fd":"temp = []\n\nfor district in cleaned_district.district_id.unique():\n    df = pd.read_csv(f'{base_path}\/engagement_data\/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    temp.append(df)\n    \nengagement_df = pd.concat(temp)\nengagement_df = engagement_df.reset_index(drop=True)\nengagement_df.head()","78716877":"\nengagement_df.lp_id.nunique()","4af4c4d7":"cleaned_product['LP ID'].nunique()","536f95dc":"print(engagement_df.shape)\nengagement_df = engagement_df[engagement_df.lp_id.isin(cleaned_product['LP ID'].unique())]\nprint(engagement_df.shape)","09d2f37a":"# rows and columns in the df\nengagement_overview = DataOverview(engagement_df)\ndisplay(engagement_overview.get_info())","021bc759":"drop_duplicates(engagement_df)","040dde0c":"engagement_overview.percent_missing_values()","3e9b6911":"engagement_overview.missing_values_table()","58a4defa":"engagement_df.dropna(subset=['pct_access'], inplace=True)","d2e2732b":"engagement_overview.missing_values_table()","3dd8cf8b":"missing_engagement_index = engagement_df[pd.isna(engagement_df['engagement_index'])]\nmissing_engagement_index","d23d2da0":"print(missing_engagement_index.shape)\ntemp = missing_engagement_index[missing_engagement_index['pct_access'] == 0.0]\nprint(temp.shape)","a83c0c71":"engagement_df['engagement_index'].fillna(0.0, inplace=True)","38ec7325":"engagement_overview.missing_values_table()","b6b35aa3":"cleaned_product.rename(columns={\"LP ID\": \"lp_id\"}, inplace=True)","bf6957ab":"df = engagement_df.merge(cleaned_district, on='district_id')\ndf.head()","a2973a83":"df = df.merge(cleaned_product, on='lp_id')\ndf.head()","3c81bfee":"def lineTimePlot(column:str,value:str)->None:\n    line= df.groupby([column,\"time\"],as_index=False).agg('mean')\n    fig = px.line(line, x ='time', y =value, color=column, width=1000,facet_col_wrap=1)\n#     fig.add_vrect(x0=\"2020-03-04\", x1=\"2020-03-14\",annotation_text=\"States Announce State of Emergency\",fillcolor=\"yellow\", opacity=0.25, annotation_position=\"top right\", line_width=0)\n    fig.add_vrect(x0=\"2020-04-02\", x1=\"2020-03-16\",annotation_text=\"State Closure\",fillcolor=\"red\", opacity=0.25, line_width=0, annotation_position=\"top left\")\n    fig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-23\",annotation_text=\"Summer Holidays\",fillcolor=\"green\", opacity=0.25, line_width=0, annotation_position=\"top right\")\n    \n    fig.add_hline(y=line[value].mean(),annotation_position=\"top right\",annotation_text=\"Average \"+value )\n    fig.update_xaxes(rangeslider_visible=True)\n    fig.update_layout(title= \"Time Analysis of \"+value+ \" by \"+column,\n    font=dict(\n        family=\"Roboto, monospace\",\n        size=14,\n        color=\"Black\"\n    )\n)\n    fig.add_annotation(xref='x domain',\n    x=0.5,\n    yref='y domain',\n    y=-0.5, font=dict(size=10),\n                       showarrow=False,\n    text=\"State Closure Data taken from <a href='https:\/\/www.openicpsr.org\/openicpsr\/project\/119446\/version\/V75\/view;jsessionid=851ECB80E6CB42252D396C29564184DC'>COVID-19 US State Policy Database by openICPSR<\/a>\")\n    fig.add_annotation(xref='x domain',\n    x=0.5,\n    yref='y domain',\n    y=-0.55, font=dict(size=10),\n                       showarrow=False,\n    text=\"Holiday Data taken from  <a href='https:\/\/www.fcps.edu\/sites\/default\/files\/media\/forms\/19-20-standard-school-year-calendar.pdf'>FCPS 2019-2020 Standard School Year Calendar<\/a>. It is used as a source for an estimate\")\n    fig.show()\n    fig.data = []","0771b70e":"local_df = df[[\"locale\", \"pct_access\",\"engagement_index\"]]\nlocal_df_agg = local_df.groupby(\"locale\").agg({\"pct_access\": \"mean\",\"engagement_index\": \"mean\" })\n\nfig, ax = plt.subplots(1, 2, figsize=(16,4))\n\nsns.barplot(x=local_df_agg.index, y=\"pct_access\", data=local_df_agg, ax=ax[0], palette='GnBu')\nsns.barplot(x=local_df_agg.index, y=\"engagement_index\", data=local_df_agg, ax=ax[1], palette='GnBu')\n\nplt.show()","3f6f00ea":"lineTimePlot(\"locale\",'pct_access')\nlineTimePlot(\"locale\",'engagement_index')","2af8bdad":"demo_df =  df[[\"pct_black\/hispanic_mean\", \"pct_access\",\"engagement_index\"]]\n\ndemo_agg = demo_df.groupby(\"pct_black\/hispanic_mean\").agg({\"pct_access\": \"mean\",\"engagement_index\": \"mean\" })\n\nfig, ax = plt.subplots(1, 2, figsize=(16,4))\n\nsns.barplot(x=demo_agg.index, y=\"pct_access\", data=demo_agg, ax=ax[0], palette='GnBu')\nsns.barplot(x=demo_agg.index, y=\"engagement_index\", data=demo_agg, ax=ax[1], palette='GnBu')\n\nplt.show()","31a36e4e":"lineTimePlot(\"pct_black\/hispanic\",'pct_access')\nlineTimePlot(\"pct_black\/hispanic\",'engagement_index')","a01add85":"state_pct_df =  df[[\"state\", \"pct_access\"]]\nstate_eng_df =  df[[\"state\", \"engagement_index\"]]\n\nstate_pct_agg = state_pct_df.groupby(\"state\").agg({\"pct_access\": \"mean\" })\nstate_eng_agg = state_eng_df.groupby(\"state\").agg({\"engagement_index\": \"mean\" })\n\nstate_pct_agg = state_pct_agg.sort_values(by=[\"pct_access\"], ascending=False)\nstate_eng_agg = state_eng_agg.sort_values(by=[\"engagement_index\"], ascending=False)\n\nfig, ax = plt.subplots(figsize=(16,8))\nsns.barplot(x=\"pct_access\", y=state_pct_agg.index, data=state_pct_agg, palette='GnBu')\nplt.show()","4ed16c8e":"fig, ax = plt.subplots(figsize=(16,8))\nsns.barplot(x=\"engagement_index\", y=state_eng_agg.index, data=state_eng_agg, palette='GnBu')\nplt.show()","a6b468e2":"px.histogram(cleaned_district, x='state', color=\"locale\").update_xaxes(categoryorder='total ascending')","700ed3ab":"px.histogram(cleaned_district, x='state', color=\"pct_black\/hispanic\").update_xaxes(categoryorder='total ascending')","73e3c8ce":"lineTimePlot(\"pct_free\/reduced\",'pct_access')\nlineTimePlot(\"pct_free\/reduced\",'engagement_index')","5b9f6636":"product_df = df[['Provider\/Company Name', 'Product Name', 'pct_access', 'engagement_index']]\nproduct_df_agg = product_df.groupby('Product Name').agg({\"pct_access\": \"mean\", \"engagement_index\": \"mean\"})\nproduct_pct_access_agg = product_df_agg[['pct_access']].sort_values(by=\"pct_access\", ascending=False)\nproduct_eng_agg =  product_df_agg[['engagement_index']].sort_values(by=\"engagement_index\", ascending=False)","e5f54192":"fig, ax = plt.subplots(1, 2, figsize=(24,4))\n\nsns.barplot(x=product_pct_access_agg.head().index, y=\"pct_access\", data=product_pct_access_agg.head(), ax=ax[0], palette='GnBu')\nsns.barplot(x=product_eng_agg.head().index, y=\"engagement_index\", data=product_eng_agg.head(), ax=ax[1], palette='GnBu')\n\nplt.show()","f3b0989c":"main_funcs = list(df['main_fun'].unique())\n\nrow = len(main_funcs) \/\/ 2 \nif len(main_funcs) % 2 != 0:\n    row += 1\n    \nfig, ax = plt.subplots(row, 2, figsize=(24,16))\n\n\ntemp_df = df[['main_fun', 'engagement_index','Provider\/Company Name', 'Product Name']]\nfor i, func in enumerate(main_funcs):\n    temp_agg = temp_df[temp_df['main_fun'] == func].groupby('Product Name').agg({'engagement_index': \"mean\"})\n    temp_agg = temp_agg.sort_values(by='engagement_index', ascending=False)\n    \n    fig.tight_layout()\n    ax[i \/\/ 2, i%2].set_title(f'Top 5 in {func}', fontsize=16)\n    sns.barplot(x=temp_agg.head().index, y=\"engagement_index\", data=temp_agg.head(), ax=ax[i \/\/ 2, i%2], palette='GnBu')","57574e5a":"lineTimePlot(\"main_fun\",'pct_access')\nlineTimePlot(\"main_fun\",'engagement_index')","44341c9e":"lineTimePlot(\"Sector(s)\",'pct_access')\nlineTimePlot(\"Sector(s)\",'engagement_index')","35b99f7b":"def lineTimePlotVC(column:str,value:str)->None:\n\n    virtual_classroom_lp_id = cleaned_product[cleaned_product.sub_fun == 'Virtual Classroom']['lp_id'].unique()\n\n    # Remove weekends from the dataframe\n    df['weekday'] = pd.DatetimeIndex(df['time']).weekday\n    engagement_without_weekends = df[df.weekday < 5]\n    \n\n    engagement_without_weekends = engagement_without_weekends[engagement_without_weekends['lp_id'].isin(virtual_classroom_lp_id)]\n    \n    line= engagement_without_weekends.groupby([column,\"time\"],as_index=False).agg('mean')\n    fig = px.line(line, x ='time', y =value, color=column, width=1000,facet_col_wrap=1)\n    #     fig.add_vrect(x0=\"2020-03-04\", x1=\"2020-03-14\",annotation_text=\"States Announce State of Emergency\",fillcolor=\"yellow\", opacity=0.25, annotation_position=\"top right\", line_width=0)\n    fig.add_vrect(x0=\"2020-04-02\", x1=\"2020-03-16\",annotation_text=\"State Closure\",fillcolor=\"red\", opacity=0.25, line_width=0, annotation_position=\"top left\")\n    fig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-23\",annotation_text=\"Summer Holidays\",fillcolor=\"green\", opacity=0.25, line_width=0, annotation_position=\"top right\")\n\n    fig.add_hline(y=line[value].mean(),annotation_position=\"top right\",annotation_text=\"Average \"+value )\n    fig.update_xaxes(rangeslider_visible=True)\n    fig.update_layout(title= \"Time Analysis of \"+value+ \" by \"+column,\n    font=dict(\n        family=\"Roboto, monospace\",\n        size=14,\n        color=\"Black\"\n    ),\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.0,\n        xanchor=\"right\",\n        x=1,\n        font=dict(\n            size=10,\n            color=\"black\"\n        )\n    )\n    )\n    fig.for_each_trace(\n  lambda trace: trace.update(name=trace.name[:15]))\n    fig.add_annotation(xref='x domain',\n    x=0.5,\n    yref='y domain',\n    y=-0.5, font=dict(size=10),\n                       showarrow=False,\n    text=\"State Closure Data taken from <a href='https:\/\/www.openicpsr.org\/openicpsr\/project\/119446\/version\/V75\/view;jsessionid=851ECB80E6CB42252D396C29564184DC'>COVID-19 US State Policy Database by openICPSR<\/a>\")\n    fig.add_annotation(xref='x domain',\n    x=0.5,\n    yref='y domain',\n    y=-0.55, font=dict(size=10),\n                       showarrow=False,\n    text=\"Holiday Data taken from  <a href='https:\/\/www.fcps.edu\/sites\/default\/files\/media\/forms\/19-20-standard-school-year-calendar.pdf'>FCPS 2019-2020 Standard School Year Calendar<\/a>. It is used as a source for an estimate\")\n    fig.show()\n    fig.data = []","11ed0fdb":"lineTimePlotVC(\"Product Name\",'pct_access')\nlineTimePlotVC(\"Product Name\",'engagement_index')","61bb0ed1":"temp=df.groupby([\"district_id\",\"time\"]).agg(\"mean\")\nindex=temp.index.get_level_values(\"district_id\").unique().to_list()\ndistrict_engagement_series =[]\nfor ind in index:\n    frame = temp.loc[ind,[\"engagement_index\",\"pct_access\"]]\n    district_engagement_series.append(frame)","3dee5fdb":"del temp","fe808b50":"!pip install tslearn\nfrom tslearn.clustering import TimeSeriesKMeans\nfrom tslearn.utils import to_time_series_dataset","982cd061":"from sklearn.preprocessing import MinMaxScaler","0eb4c45d":"for i in range(len(district_engagement_series)):\n    scaler = MinMaxScaler()\n    district_engagement_series[i] = MinMaxScaler().fit_transform(district_engagement_series[i])\n\ndistrict_engagement_series=to_time_series_dataset(district_engagement_series)","709e35ab":"ks = range(1, 10)\ninertias = []\nfor k in ks:\n    # Create a KMeans instance with k clusters: model\n    model = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", max_iter=1,n_init=3,random_state=9)\n    \n    # Fit model to samples\n    model.fit(district_engagement_series)\n    \n    # Append the inertia to the list of inertias\n    inertias.append(model.inertia_)\n    \nplt.plot(ks, inertias, '-o', color='black')\nplt.xlabel('number of clusters, k')\nplt.title(\"Elbow Method for Finding Optimum Number of Clusters\")\nplt.ylabel('inertia')\nplt.xticks(ks)\nplt.show()","edd68139":"model = TimeSeriesKMeans(n_clusters=5, metric=\"dtw\", max_iter=1,n_init=3,random_state=9).fit(district_engagement_series)\nclusters=model.predict(district_engagement_series)","bd541b7c":"copy=df.copy()\nfor i in range (0,len(index)):\n    copy.loc[copy[\"district_id\"]==index[i],'cluster']=clusters[i]","2c6dabbe":"\n\nline=copy.groupby([\"time\",\"district_id\"],as_index=False).agg(\"mean\")\n\nfig = px.line(line, x ='time', y =\"engagement_index\", color=\"district_id\",facet_row=\"cluster\",height=1000,facet_col_wrap=1)\n\nfig.show()\nfig.data=[]","ed05ec1f":"\nline=copy.groupby([\"time\",\"district_id\"],as_index=False).agg(\"mean\")\n\nfig = px.line(line, x ='time', y =\"pct_access\", color=\"district_id\",facet_row=\"cluster\",height=1000,facet_col_wrap=1)\n\nfig.show()\nfig.data=[]","c947ec65":"copy.groupby(\"cluster\").agg(\"mean\").sort_values(\"pct_access\",ascending=True)","42401c56":"!pip install pycausalimpact\nfrom causalimpact import CausalImpact","2513b571":"policy_df = pd.read_csv('..\/input\/covid19-us-state-policy-database\/COVID-19_US_state_policy - State policy changes .csv')\npolicy_df = policy_df[['STATE', 'CLSCHOOL']]\npolicy_df.drop(df.index[[0, 1, 2, 3]])\npolicy_df = policy_df[policy_df.STATE.isin(df.state.unique())]\npolicy_df['CLSCHOOL'] = pd.to_datetime(policy_df['CLSCHOOL']).dt.day_of_year\npolicy_df.set_index('STATE', inplace=True)\npolicy_df","992a9f93":"x = df.groupby(['district_id', 'state']).agg({ 'engagement_index': 'mean', \n                                               'pct_access': 'mean', \n                                               'pct_black\/hispanic_mean': 'mean', })\nx = x.sort_values(by=['pct_black\/hispanic_mean'], ascending = False)\nx.head()","4caa0c61":"df_9536 = df[df.district_id==9043]\ndf_9536['time'] = pd.to_datetime(df_9536['time'])\ndf_9536['time'] = df_9536['time'].dt.day_of_year\ndf_9536 = df_9536.groupby(['time']).agg({ 'engagement_index': 'mean'})\ndf_9536","6b32b91c":"sns.set_theme(style='darkgrid')\nplt.figure(figsize=(15,8))\n\ns = sns.lineplot(data=df_9536, x=\"time\", y='engagement_index', linewidth=1)\ns.set_title('Time series data of engagement Index for district 9536', y=1.02, fontsize=15)\ns.set_xlabel('Date', fontsize=14, labelpad=15)\ns.set_ylabel('Engagement', fontsize=14, labelpad=15)\nplt.axvline(77, color='r', linewidth=1, linestyle='--')\nplt.show()","7389d6b4":"pre_period = [1, 77]\npost_period = [78, 366]\nci = CausalImpact(df_9536, pre_period, post_period)","d1b60f5d":"ci.plot()\nprint(ci.summary())\nprint(ci.summary(output='report'))","d6f922dc":"x.tail()","820be967":"df_1904\t = df[df.district_id==1904\t]\ndf_1904['time'] = pd.to_datetime(df_1904['time'])\ndf_1904['time'] = df_1904['time'].dt.day_of_year\ndf_1904 = df_1904.groupby(['time']).agg({ 'engagement_index': 'mean'})\ndf_1904","db968be8":"pre_period = [1, 77]\npost_period = [78, 366]\nci = CausalImpact(df_1904, pre_period, post_period)","fa29bebd":"ci.plot()\nprint(ci.summary())\nprint(ci.summary(output='report'))","655cfc71":"The rows left with missing values doesn't have either a common company name and\/or sector with the other non-missing rows. Therfore, we will drop them.","5e9d1192":"#### Products per sector vs. pct_access and engagement_index","20da5bf2":"School closures did not negatively impact student engagement in the 1904 district; instead, when schools were closed, student engagement increased significantly. It shows that COVID-19 and school closures have had a much greater negative effect on student engagement in areas where the population is predominantly black or Hispanic.","f7a1e872":"For further analysis we extracted new columns from columns having thier values definded in terms of range. We did this by calculating the (min_range + max_range) \/ 2","c0fe8abd":"From the missing table we can observe a pattern. The last 3 columns have the same number of missing values. This indicates that we should investigate to see if the all the missing values of these 3 columns exist together in the same rows.","5116427c":"#### Average of percentage of students in the districts eligible for free or reduced-price lunch  in each state","65b844a9":"#### Percentage of students eligible for free of reduced price lunch Breakdown\nThis can be an indicator of the economic level of the students at these districts and will be used as such in the following sections","29c787a0":"Now let's explore the impact of school closure on states with the most and least pct_black\/Hispanic; to check if covid 19 has disproportionately impacted student engagement with online learning platforms in areas where there are more Black or Hispanic Students.","eed1039a":"#### Top 5 engaged products per main function","beec2879":"### Duplicates","c89d939e":"## Problem Statement\n\nCurrent research shows educational outcomes are far from equitable. The imbalance was exacerbated by the COVID-19 pandemic. There's an urgent need to better understand and measure the scope and impact of the pandemic on these inequities.\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms.\n\nIn this notebook we will try to get insight on:\n* the state of digital learning in 2020 \n* how the engagement of digital learning relates to factors such as district demographics, broadband access, and state\/national level policies and events.","5df0186c":"Similar to the previous plot, Google products have a higher percentage access and engagement index in each main function category.","5e54ef31":"We will impute missing values in the column `Sector(s)` based on the mode value of the same `Provider\/Company Name`. Then we will impute missing values in the column `Primary Essential Function` based on the mode value of the same `Provider\/Company Name` and `Sector(s)`.","5e72209c":"#### Percentage access by demogrphics\nWe can see that districts with a 0.8-1 percentage of black\/hispanic students have a higher access percentage than their other counterparts. The districts with a 0.4-0.6 percentage of black\/hispanic students performed the worst. Districts with a 0.8-1 percentage of black\/hispanic students was hit the hardest with state closures but showed a great rebound with school opening in the fall with rates higher than before. Another range that was affected heavily is the districts with  0.4-0.6 percentage of black\/hispanic students though it did rebound after the summer holidays.\n\n#### Engagement Index by demographics\nSimilar to its access counterpart the figure shows that  districts with a 0.8-1 percentage of black\/hispanic students have a higher access percentage than their other counterparts. The districts with a 0.4-0.6 percentage of black\/hispanic students performed the worst. Districts with a 0.8-1 percentage of black\/hispanic students was hit the hardest with state closures but showed a great rebound with school opening in the fall with rates similar to before.","37242656":"### Number of school district in each state.\nTop states with most school districts are Connecticut,  Utah and Massachusetts\n","27aec457":"### Duplicates","9e6e6c89":"#### Percentage access by pct_free\/reduced\nWe can see that districts with a 0.8-1 percentage of pct_free\/reduced eligible students have a higher access percentage than their other counterparts on average. The districts with a 0.6-0.8 percentage of pct_free\/reduced eligible students had the worst access percentages. Districts with a 0.8-1 percentage oof pct_free\/reduced eligible students was hit the hardest with state closures but showed a rebound with school openings in the fall with rates that were only slightly lower than before. \n\n#### Engagement Index by pct_free\/reduced\nWe can see that districts with a 0.8-1 percentage of pct_free\/reduced eligible students have a engagement index than their other counterparts on average. The districts with a 0.6-0.8 percentage of pct_free\/reduced eligible students had the worst access percentages. Districts with a 0.8-1 percentage oof pct_free\/reduced eligible students was hit the hardest with state closures but showed a rebound with school openings in the fall but never recovered to the level before the closure.","9079fab7":"### Merging","53b85bbd":"### General statistics","ba23f416":"### Causal Inference","c22a43f8":"#### Number of counts for  pp_total_raw","7a859b8a":"### Missing values","a173dd55":"The product file `products_info.csv` includes information about the characteristics of the top 372 products with most users in 2020. The categories listed in this file are part of LearnPlatform's product taxonomy. Data were labeled by our team. Some products may not have labels due to being duplicate, lack of accurate url or other reasons.\n\n| Name                       | Description                                                                                                                                                                                                                                                                                                                    |\n|----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| LP ID                      | The unique identifier of the product                                                                                                                                                                                                                                                                                           |\n| URL                        | Web Link to the specific product                                                                                                                                                                                                                                                                                               |\n| Product Name               | Name of the specific product                                                                                                                                                                                                                                                                                                   |\n| Provider\/Company Name      | Name of the product provider                                                                                                                                                                                                                                                                                                   |\n| Sector(s)                  | Sector of education where the product is used                                                                                                                                                                                                                                                                                  |\n| Primary Essential Function | The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled |","a1ca198c":"# Exploratory Data Analysis of COVID-19 Impact on Digital Learning","ca727c86":"### Graphical analysis","aa6777c0":"## Merged Engagement Data","f823e028":"#### Locale Breakdown\nWe can see that the majority of our districts are in suburbs followed by rural,city then town. ","15599f94":"### Missing values","d6665f8a":"We used a public database of state policies  from [OPENICPSR](https:\/\/www.openicpsr.org\/openicpsr\/project\/119446\/version\/V75\/view;jsessionid=851ECB80E6CB42252D396C29564184DC?path=\/openicpsr\/119446\/fcr:versions\/V75\/COVID-19-US-State-Policy-Database-master&type=folder) to identify the dates of school closures in each state.","9cc00bd0":"### Graphical Analysis","3d51b13f":"#### Top 5 engaged products","32b09a1c":"#### Average of total hispanic or black communiuty in each state","56911b0a":"### Analysis","486adb28":"The clustering seems to have captured some patterns in our time series data sets as demonstrated in the graphs below. ","c8f09a86":"## Engagement data","ed0567cb":"### Missing values","4a3de153":"#### Breakdown of demographics overall\n\nThe plot show the number of districts by demographic, economic level as well as locale. For all locales except cities majority of the districts have a 0-0.2 percentage of students that are hispanic or black.Often we can see that a very high percentage of black or hispanic students(0.8-1) coincides with higher percentage of students eligible for lunch assistance than their lesser counterparts. This demonstrates racial bias to the economic status of the students.","ee5a0ce8":"#### Racial identity of students Breakdown\nWe can see that the majority of our districts have a percentage of 0%-0.2% hispanic\/black students with diminishing number of districts as we go up in the percentage of hispanic\/black students. ","10e689fe":"#### Count plots for  locale and pct_black\/hispanic","728bcba0":"Weekends are removed from this visualization for better understanding because students do not attend classes on weekends. Both pct_access and engagement_index have rose up after the pandemic. But the difference of the engagement_index is more bigger than that of pct_access. This indicates that even though students accessed these virtual classroom products befre the pandemic, they engaged with them much more after the pandemic started.","e0a9f950":"Let's see the ratio of each unique value in each of these columns.","e699cae1":"While looking at graphs and comparing pre and post-school closure can give a good idea of the impact school closure had on student engagement in district 9536. To increase confidence in our findings, we will use the Causal Impact library for our statistical analysis.","9e7c19dc":"### General statistics","dca88ba2":"Let's check the updated missing values table.","60b3b69a":"#### Products per main function vs. pct_access and engagement_index","99bde15a":"### Duplicates","405224f5":"The optimum number of clusters for our data set is 5 from our results of the elbow method. We will use this to fit our clustering algorithm. We are using a time series based kmeans for our data. The metric used for calculating distance is dynamic time warping which measures similarity between two temporal sequences. ","8fd85a89":"For better analysis we will concatenate all the dataframes read from the folder `engagement_data` vertically into a single dataframe. Note that since we have dropped some districts from the districts dataframe, engagement data about these districts will also be excluded.","377ed23e":"## Importing libraries","b376682f":"The report shows school closure has impacted engagement significantly in district 9536, which has a large percentage of students identified as Black or Hispanic. The probability of obtaining this effect by chance is very small, and therefore the causal effect can be considered statistically significant. Next, let's look at states with the least Black or Hispanic demographics.","fdb23cb8":"Since the product with missing value in the column `Provider\/Company Name` have also missing values for the columns `Sector(s)` and `Primary Essential Function`, we will drop it.","08fc6bf5":"### Cluster Analysis\n","b96a8d18":"We can see that the pct_free\/reduced_mean irrespective of the average spending can be seen as an indication of pct_access and engagement_index. This shows that though there is some investment in schools the students who are eligible for reduced lunches have difficulty in access and that due to covid they can't may not use the services at their schools to fill the gap.","ea842d9e":"Let's check the updated missing values table.","086ba85d":"As predicted these 57 rows contain all the missing values from the columns state', 'locale', and 'pct_black\/hispanic'. Since we have too many missing values in the same rows, we will remove them.","ee611e4c":"## Product information data","e0dab939":"#### Percentage access and Engagement Index in each state\nWe can see that North Dakota, Arizona, New York, District of Colombia and New Hemisphere have higher overall access percentage and Engagement Index than the other states. The reason for New Hemisphere, North Dakota and New York can be attributed to the fact that they are mainly rulalr areas as we can see from the follwing graphs, In the other hands Arizona and District of Colombia have a predominant black\/hispanic demographics, so this may attribute to a higher Engagement and Percentage access\n","b16fe1f0":"#### Number of counts for  pct_free\/reduced values and county_connections_ratio columns\nUnfortunately the county_connections_ratio columns is predominantly filled with '[0.18, 1[.\n[1, 2[ appears only in a single row only. so this column is no use to us","7f74b19d":"The engagement data are aggregated at school district level, and each file in the folder `engagement_data` represents data from one school district. The 4-digit file name represents `district_id` which can be used to link to district information in `district_info.csv`. The `lp_id` can be used to link to product information in `product_info.csv`.\n\n| Name             | Description                                                                                                    |\n|------------------|----------------------------------------------------------------------------------------------------------------|\n| time             | date in \"YYYY-MM-DD\"                                                                                           |\n| lp_id            | The unique identifier of the product                                                                           |\n| pct_access       | Percentage of students in the district have at least one page-load event of a given product and on a given day |\n| engagement_index | Total page-load events per one thousand students of a given product and on a given day                         |","184cd40b":"#### Percent Access By Locale\nThe figure shows that rural locales have a higher access percentage followed by towns with cities performing the worst. We can also see that cities were hit the hardest by state decisions for closure with access plummeting the hardest while the rest only showed a small decrease. The city shows almost half the access percentage to our highest access percentage(rural locale)\n\n#### Engagement Index by locale\nThis is a similar pattern with the percentage access with cities being the lowest and rural being the highest. And the effects of the state closures being hardest on the cities","ee139cc8":"## District information data","1f74c5ba":"## Utility Functions and Classes","f58261c8":"### General statistics","341a8b71":"## Overview of the data\nWhat datas are we going to use for analysis ?\n\n* engagement_data: each file represent data from school district, the 4-digit number file name represent district_id\n* products_info.csv: file includes information about the characteristics of the top 372 products with most users in 2020.\n* districts_info.csv : file includes information about the characteristics of school - - districts, including data from NCES and FCC.","b4ee49a3":"#### Average of total expediture in each state","a21a0d6e":"As shown above, most of the districts are located in suburb areas and have lower percentage of black or hispanic residents.","38796d8b":"#### Virtual classroom products per vs. pct_access and engagement_index","4aa1087b":"### Splitting Columns\nExtracting main_function and sub_function from \"Primary Essential Function\" column and dropping Primary Essential Function column","d613f5d3":"The district file `districts_info.csv` includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. In this data set, identifiable information about the school districts have been removed. An open source tool ARX (Prasser et al. 2020) have bben used to transform several data fields and reduce the risks of re-identification. For data generalization purposes some data points are released with a range where the actual value falls under. Additionally, there are many missing data marked as 'NaN' indicating that the data was suppressed to maximize anonymization of the dataset.\n\n| Name                   | Description                                                                                                                                                                                                                                                                              |\n|------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| district_id            | The unique identifier of the school district                                                                                                                                                                                                                                             |\n| state                  | The state where the district resides in                                                                                                                                                                                                                                                  |\n| locale                 | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.                                                                                                          |\n| pct_black\/hispanic     | Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data                                                                                                                                                                                       |\n| pct_free\/reduced       | Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data                                                                                                                                                                              |\n| countyconnectionsratio | ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.                                                                         |\n| pptotalraw             | Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district. |","3bdb4e80":"We will impute missing values in the columns `pp_total_raw` and `pct_free\/reduced` based on the mode value of the same `locale`. This is because we assume that there is some connection between the values of `pp_total_raw` and `pct_free\/reduced` that are in the same `locale`. For the column `county_connections_ratio`, we will impute its missing values by its mode as every value except one is equal to the mode.","5111880c":"#### Top 5 products with higher percentage access\nThe top 5 products with higher Percentage access are\n1. Google classroom\n2. Google docs\n3. Google Drive\n4. Youtube\n5. ClassLink\n\n#### Top 5 products with most engaged products are\n1. Google docs\n2. Google classroom\n3. Youtube\n4. Canvas\n5. Meet\n\nYou can obseve that most used products for online learning in terms of both higher percentage access and engagment index are from Google.\n\n"}}