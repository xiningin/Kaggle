{"cell_type":{"3950f95d":"code","275d4a04":"code","f3409394":"code","89dd6a5d":"code","5fefffb3":"code","e4a3435e":"code","3116ff2f":"code","a1b6c77e":"code","463d45f2":"code","389aaa4c":"code","df0593ef":"code","287f6860":"code","0bddfc1e":"code","68f07827":"code","fbcc0d5e":"code","594bb975":"code","cf76111c":"code","b3a07f7e":"code","146b3f4f":"code","5fbc0f71":"code","41b0887f":"code","029b23c0":"code","a42f4e4a":"code","52dc1c3a":"code","7ff52c7d":"code","8eeae2da":"code","42469614":"code","a2e11baf":"code","bf1226f2":"code","71bfb0a0":"code","cefdd5b0":"code","69fa7345":"code","0c045580":"code","2a71183f":"code","44dc5bd9":"code","4aed52ac":"code","adcf06ef":"code","d00fe9b2":"code","fa60db22":"code","ec8247c6":"code","ad3fc93b":"code","7b6d05c6":"code","a0171290":"code","4652566d":"code","9bc90402":"code","867bca92":"code","3034dd09":"code","19132b65":"code","c6c00e54":"code","e9cf820b":"code","64db32d4":"code","a65829b3":"code","cd3057ba":"code","e4ce5b60":"code","937883f9":"code","cfb2b1f2":"code","2f9670dd":"code","60d503cd":"code","d71ac802":"code","1cd249cf":"code","b35049a5":"code","b5fd4dcf":"code","0974c8ec":"code","161767c8":"code","e583036d":"code","6dee38a5":"code","f5ed2e74":"code","5a1ba2f4":"code","3a3f162b":"code","5bbf7d60":"code","7fd836c1":"code","e987d91b":"code","1b1376bd":"code","beb6976b":"code","17cd6a56":"code","719e4467":"code","b4ec6bd9":"code","f5fddac8":"code","80602725":"code","280b52c5":"code","645fea65":"code","09e4544a":"code","ab91aa13":"code","411a9f64":"code","fac3c134":"code","65a84628":"code","1475b133":"code","88000840":"code","61216660":"code","49c9c2b3":"code","04d929f0":"code","77e1b579":"code","e1a23dfd":"code","6ba86cff":"markdown","3cff7eee":"markdown","2dc2f724":"markdown","9b346782":"markdown","a45c93ff":"markdown","396d6233":"markdown","a8eb40f7":"markdown","7afddbf3":"markdown","3f56e092":"markdown","34591679":"markdown","628bee39":"markdown","d273a036":"markdown","efd9afcd":"markdown","e86572f7":"markdown","d74e1421":"markdown","752e0aec":"markdown","9299e4ad":"markdown","07d2d2f9":"markdown","d15f3d1d":"markdown","0714c3f9":"markdown","a91d7c0c":"markdown","27869095":"markdown","a6e75064":"markdown","b4303c15":"markdown","252f5350":"markdown","03456e9c":"markdown","029c2301":"markdown"},"source":{"3950f95d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","275d4a04":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","f3409394":"df = pd.read_csv('..\/input\/lending-club-loan-two-new-version\/lending_club_loan_two.csv')\ndf","89dd6a5d":"df.info()","5fefffb3":"sns.countplot(x='loan_status',data=df)","e4a3435e":"plt.figure(figsize=(12,4))\nsns.distplot(df['loan_amnt'],kde=False,bins=40)\nplt.xlim(0,45000)","3116ff2f":"df.corr()","a1b6c77e":"plt.figure(figsize=(12,7))\nsns.heatmap(df.corr(),annot=True,cmap='viridis')\nplt.ylim(10, 0)","463d45f2":"plt.figure(figsize=(14,6))\nsns.scatterplot(x='installment',y='loan_amnt',data=df,)","389aaa4c":"sns.boxplot(x='loan_status',y='loan_amnt',data=df)","df0593ef":"df.groupby('loan_status')['loan_amnt'].describe()","287f6860":"sorted(df['grade'].unique())","0bddfc1e":"sorted(df['sub_grade'].unique())","68f07827":"sns.countplot(x='grade',data=df,hue='loan_status')","fbcc0d5e":"plt.figure(figsize=(12,4))\nsubgrade_order = sorted(df['sub_grade'].unique())\nsns.countplot(x='sub_grade',data=df,order = subgrade_order,palette='coolwarm' )","594bb975":"plt.figure(figsize=(12,4))\nsubgrade_order = sorted(df['sub_grade'].unique())\nsns.countplot(x='sub_grade',data=df,order = subgrade_order,palette='coolwarm' ,hue='loan_status')","cf76111c":"f_and_g = df[(df['grade']=='G') | (df['grade']=='F')]\n\nplt.figure(figsize=(12,4))\nsubgrade_order = sorted(f_and_g['sub_grade'].unique())\nsns.countplot(x='sub_grade',data=f_and_g,order = subgrade_order,hue='loan_status')","b3a07f7e":"df['loan_status'].unique()","146b3f4f":"df['loan_repaid'] = df['loan_status'].map({'Fully Paid':1,'Charged Off':0})","5fbc0f71":"df[['loan_repaid','loan_status']]","41b0887f":"df.corr()['loan_repaid'].sort_values().drop('loan_repaid').plot(kind='bar')","029b23c0":"df.head()","a42f4e4a":"len(df)","52dc1c3a":"df.isnull().sum()","7ff52c7d":"100* df.isnull().sum()\/len(df)","8eeae2da":"df['emp_title'].nunique()","42469614":"df['emp_title'].value_counts()","a2e11baf":"df = df.drop('emp_title',axis=1)","bf1226f2":"sorted(df['emp_length'].dropna().unique())","71bfb0a0":"emp_length_order = [ '< 1 year',\n                      '1 year',\n                     '2 years',\n                     '3 years',\n                     '4 years',\n                     '5 years',\n                     '6 years',\n                     '7 years',\n                     '8 years',\n                     '9 years',\n                     '10+ years']","cefdd5b0":"plt.figure(figsize=(12,4))\n\nsns.countplot(x='emp_length',data=df,order=emp_length_order)","69fa7345":"plt.figure(figsize=(12,4))\nsns.countplot(x='emp_length',data=df,order=emp_length_order,hue='loan_status')","0c045580":"emp_co = df[df['loan_status']==\"Charged Off\"].groupby(\"emp_length\").count()['loan_status']","2a71183f":"emp_fp = df[df['loan_status']==\"Fully Paid\"].groupby(\"emp_length\").count()['loan_status']","44dc5bd9":"emp_len = emp_co\/emp_fp","4aed52ac":"emp_len","adcf06ef":"emp_len.plot(kind='bar')","d00fe9b2":"df = df.drop('emp_length',axis=1)","fa60db22":"df.isnull().sum()","ec8247c6":"df['purpose'].head(10)","ad3fc93b":"df['title'].head(10)","7b6d05c6":"df = df.drop('title',axis=1)","a0171290":"df['mort_acc'].value_counts()","4652566d":"print(\"Correlation with the mort_acc column\")\ndf.corr()['mort_acc'].sort_values()","9bc90402":"print(\"Mean of mort_acc column per total_acc\")\ndf.groupby('total_acc').mean()['mort_acc']","867bca92":"total_acc_avg = df.groupby('total_acc').mean()['mort_acc']","3034dd09":"total_acc_avg[2.0]","19132b65":"def fill_mort_acc(total_acc,mort_acc):\n    '''\n    Accepts the total_acc and mort_acc values for the row.\n    Checks if the mort_acc is NaN , if so, it returns the avg mort_acc value\n    for the corresponding total_acc value for that row.\n    \n    total_acc_avg here should be a Series or dictionary containing the mapping of the\n    groupby averages of mort_acc per total_acc values.\n    '''\n    if np.isnan(mort_acc):\n        return total_acc_avg[total_acc]\n    else:\n        return mort_acc","c6c00e54":"df['mort_acc'] = df.apply(lambda x: fill_mort_acc(x['total_acc'], x['mort_acc']), axis=1)","e9cf820b":"df.isnull().sum()","64db32d4":"df = df.dropna()","a65829b3":"df.isnull().sum()","cd3057ba":"df.select_dtypes(['object']).columns","e4ce5b60":"df['term'].value_counts()","937883f9":"# Or just use .map()\ndf['term'] = df['term'].apply(lambda term: int(term[:3]))","cfb2b1f2":"df = df.drop('grade',axis=1)","2f9670dd":"subgrade_dummies = pd.get_dummies(df['sub_grade'],drop_first=True)","60d503cd":"df = pd.concat([df.drop('sub_grade',axis=1),subgrade_dummies],axis=1)","d71ac802":"df.columns","1cd249cf":"df.select_dtypes(['object']).columns","b35049a5":"dummies = pd.get_dummies(df[['verification_status', 'application_type','initial_list_status','purpose' ]],drop_first=True)\ndf = df.drop(['verification_status', 'application_type','initial_list_status','purpose'],axis=1)\ndf = pd.concat([df,dummies],axis=1)","b5fd4dcf":"df['home_ownership'].value_counts()","0974c8ec":"df['home_ownership']=df['home_ownership'].replace(['NONE', 'ANY'], 'OTHER')\n\ndummies = pd.get_dummies(df['home_ownership'],drop_first=True)\ndf = df.drop('home_ownership',axis=1)\ndf = pd.concat([df,dummies],axis=1)","161767c8":"df['zip_code'] = df['address'].apply(lambda address:address[-5:])","e583036d":"dummies = pd.get_dummies(df['zip_code'],drop_first=True)\ndf = df.drop(['zip_code','address'],axis=1)\ndf = pd.concat([df,dummies],axis=1)","6dee38a5":"df = df.drop('issue_d',axis=1)","f5ed2e74":"df['earliest_cr_year'] = df['earliest_cr_line'].apply(lambda date:int(date[-4:]))\ndf = df.drop('earliest_cr_line',axis=1)","5a1ba2f4":"df.select_dtypes(['object']).columns","3a3f162b":"from sklearn.model_selection import train_test_split","5bbf7d60":"df = df.drop('loan_status',axis=1)","7fd836c1":"X = df.drop('loan_repaid',axis=1).values\ny = df['loan_repaid'].values","e987d91b":"# df = df.sample(frac=0.1,random_state=101)\nprint(len(df))","1b1376bd":"#CODE HERE","beb6976b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)","17cd6a56":"# CODE HERE","719e4467":"from sklearn.preprocessing import MinMaxScaler","b4ec6bd9":"scaler = MinMaxScaler()","f5fddac8":"X_train = scaler.fit_transform(X_train)","80602725":"X_test = scaler.transform(X_test)","280b52c5":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\nfrom tensorflow.keras.constraints import max_norm","645fea65":"model = Sequential()\n\n# https:\/\/stats.stackexchange.com\/questions\/181\/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n\n\n# input layer\nmodel.add(Dense(78,  activation='relu'))\nmodel.add(Dropout(0.2))\n\n# hidden layer\nmodel.add(Dense(39, activation='relu'))\nmodel.add(Dropout(0.2))\n\n# hidden layer\nmodel.add(Dense(19, activation='relu'))\nmodel.add(Dropout(0.2))\n\n# output layer\nmodel.add(Dense(units=1,activation='sigmoid'))\n\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam')","09e4544a":"model.fit(x=X_train, \n          y=y_train, \n          epochs=25,\n          batch_size=256,\n          validation_data=(X_test, y_test), \n          )","ab91aa13":"from tensorflow.keras.models import load_model","411a9f64":"model.save('full_data_project_model.h5')  ","fac3c134":"losses = pd.DataFrame(model.history.history)","65a84628":"losses[['loss','val_loss']].plot()","1475b133":"from sklearn.metrics import classification_report,confusion_matrix","88000840":"predictions = model.predict_classes(X_test)","61216660":"print(classification_report(y_test,predictions))","49c9c2b3":"confusion_matrix(y_test,predictions)","04d929f0":"import random\nrandom.seed(101)\nrandom_ind = random.randint(0,len(df))\n\nnew_customer = df.drop('loan_repaid',axis=1).iloc[random_ind]\nnew_customer","77e1b579":"model.predict_classes(new_customer.values.reshape(1,78))","e1a23dfd":"df.iloc[random_ind]['loan_repaid']","6ba86cff":"**TASK: Now check, did this person actually end up paying back their loan?**","3cff7eee":"# Project Tasks\n\n**Complete the tasks below! Keep in mind is usually more than one way to complete the task! Enjoy**\n\n-----\n------\n\n# Section 1: Exploratory Data Analysis\n\n**OVERALL GOAL: Get an understanding for which variables are important, view summary statistics, and visualize the data**\n\n\n----","2dc2f724":"# Lending Club Project\n\n## The Data\n\nWe will be using a subset of the LendingClub DataSet obtained from Kaggle: https:\/\/www.kaggle.com\/wordsforthewise\/lending-club\n\n\n\nLendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California.[3] It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. LendingClub is the world's largest peer-to-peer lending platform.\n\n### Our Goal\n\nGiven historical data on loans given out with information on whether or not the borrower defaulted (charge-off), can we build a model thatcan predict wether or nor a borrower will pay back their loan? This way in the future when we get a new potential customer we can assess whether or not they are likely to pay back the loan. Keep in mind classification metrics when evaluating the performance of your model!\n\nThe \"loan_status\" column contains our label.\n\n### Data Overview","9b346782":"### earliest_cr_line\n**TASK: This appears to be a historical time stamp feature. Extract the year from this feature using a .apply function, then convert it to a numeric feature. Set this new data to a feature column called 'earliest_cr_year'.Then drop the earliest_cr_line feature.**","a45c93ff":"## Train Test Split","396d6233":"## Loading the data and other imports","a8eb40f7":"**TASK: Perform a train\/test split with test_size=0.2 and a random_state of 101.**","7afddbf3":"## Categorical Variables and Dummy Variables\n\n**We're done working with the missing data! Now we just need to deal with the string values due to the categorical columns.**\n\n**TASK: List all the columns that are currently non-numeric. [Helpful Link](https:\/\/stackoverflow.com\/questions\/22470690\/get-list-of-pandas-dataframe-columns-based-on-data-type)**\n\n[Another very useful method call](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.select_dtypes.html)","3f56e092":"**TASK: OPTIONAL: Save your model.**","34591679":"# Missing Data\n\n**Let's explore this missing data columns. We use a variety of factors to decide whether or not they would be useful, to see if we should keep, discard, or fill in the missing data.**","628bee39":"----\n-----\nThere are many LendingClub data sets on Kaggle. Here is the information on this particular data set:\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>LoanStatNew<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>loan_amnt<\/td>\n      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>term<\/td>\n      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>int_rate<\/td>\n      <td>Interest Rate on the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>installment<\/td>\n      <td>The monthly payment owed by the borrower if the loan originates.<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>grade<\/td>\n      <td>LC assigned loan grade<\/td>\n    <\/tr>\n    <tr>\n      <th>5<\/th>\n      <td>sub_grade<\/td>\n      <td>LC assigned loan subgrade<\/td>\n    <\/tr>\n    <tr>\n      <th>6<\/th>\n      <td>emp_title<\/td>\n      <td>The job title supplied by the Borrower when applying for the loan.*<\/td>\n    <\/tr>\n    <tr>\n      <th>7<\/th>\n      <td>emp_length<\/td>\n      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.<\/td>\n    <\/tr>\n    <tr>\n      <th>8<\/th>\n      <td>home_ownership<\/td>\n      <td>The home ownership status provided by the borrower during registration\u00a0or obtained from the credit report.\u00a0Our values are: RENT, OWN, MORTGAGE, OTHER<\/td>\n    <\/tr>\n    <tr>\n      <th>9<\/th>\n      <td>annual_inc<\/td>\n      <td>The self-reported annual income provided by the borrower during registration.<\/td>\n    <\/tr>\n    <tr>\n      <th>10<\/th>\n      <td>verification_status<\/td>\n      <td>Indicates if income was verified by LC, not verified, or if the income source was verified<\/td>\n    <\/tr>\n    <tr>\n      <th>11<\/th>\n      <td>issue_d<\/td>\n      <td>The month which the loan was funded<\/td>\n    <\/tr>\n    <tr>\n      <th>12<\/th>\n      <td>loan_status<\/td>\n      <td>Current status of the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>13<\/th>\n      <td>purpose<\/td>\n      <td>A category provided by the borrower for the loan request.<\/td>\n    <\/tr>\n    <tr>\n      <th>14<\/th>\n      <td>title<\/td>\n      <td>The loan title provided by the borrower<\/td>\n    <\/tr>\n    <tr>\n      <th>15<\/th>\n      <td>zip_code<\/td>\n      <td>The first 3 numbers of the zip code provided by the borrower in the loan application.<\/td>\n    <\/tr>\n    <tr>\n      <th>16<\/th>\n      <td>addr_state<\/td>\n      <td>The state provided by the borrower in the loan application<\/td>\n    <\/tr>\n    <tr>\n      <th>17<\/th>\n      <td>dti<\/td>\n      <td>A ratio calculated using the borrower\u2019s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower\u2019s self-reported monthly income.<\/td>\n    <\/tr>\n    <tr>\n      <th>18<\/th>\n      <td>earliest_cr_line<\/td>\n      <td>The month the borrower's earliest reported credit line was opened<\/td>\n    <\/tr>\n    <tr>\n      <th>19<\/th>\n      <td>open_acc<\/td>\n      <td>The number of open credit lines in the borrower's credit file.<\/td>\n    <\/tr>\n    <tr>\n      <th>20<\/th>\n      <td>pub_rec<\/td>\n      <td>Number of derogatory public records<\/td>\n    <\/tr>\n    <tr>\n      <th>21<\/th>\n      <td>revol_bal<\/td>\n      <td>Total credit revolving balance<\/td>\n    <\/tr>\n    <tr>\n      <th>22<\/th>\n      <td>revol_util<\/td>\n      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.<\/td>\n    <\/tr>\n    <tr>\n      <th>23<\/th>\n      <td>total_acc<\/td>\n      <td>The total number of credit lines currently in the borrower's credit file<\/td>\n    <\/tr>\n    <tr>\n      <th>24<\/th>\n      <td>initial_list_status<\/td>\n      <td>The initial listing status of the loan. Possible values are \u2013 W, F<\/td>\n    <\/tr>\n    <tr>\n      <th>25<\/th>\n      <td>application_type<\/td>\n      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers<\/td>\n    <\/tr>\n    <tr>\n      <th>26<\/th>\n      <td>mort_acc<\/td>\n      <td>Number of mortgage accounts.<\/td>\n    <\/tr>\n    <tr>\n      <th>27<\/th>\n      <td>pub_rec_bankruptcies<\/td>\n      <td>Number of public record bankruptcies<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n\n---\n----","d273a036":"### verification_status, application_type,initial_list_status,purpose \n**TASK: Convert these columns: ['verification_status', 'application_type','initial_list_status','purpose'] into dummy variables and concatenate them with the original dataframe. Remember to set drop_first=True and to drop the original columns.**","efd9afcd":"# Creating the Model\n\n","e86572f7":"**TASK: Create predictions from the X_test set and display a classification report and confusion matrix for the X_test set.**","d74e1421":"----\n----\n\n# OPTIONAL\n\n## Grabbing a Sample for Training Time\n\n### OPTIONAL: Use .sample() to grab a sample of the 490k+ entries to save time on training. Highly recommended for lower RAM computers or if you are not using GPU.\n\n----\n----","752e0aec":"## Normalizing the Data\n\n**TASK: Use a MinMaxScaler to normalize the feature data X_train and X_test. Recall we don't want data leakge from the test set so we only fit on the X_train data.**","9299e4ad":"**TASK: Review the title column vs the purpose column. Is this repeated information?**","07d2d2f9":"# Section 3: Evaluating Model Performance.\n\n**TASK: Plot out the validation loss versus the training loss.**","d15f3d1d":"---\n**Let's now go through all the string features to see what we should do with them.**\n\n---\n\n\n### term feature\n\n**TASK: Convert the term feature into either a 36 or 60 integer numeric data type using .apply() or .map().**","0714c3f9":"**TASK: Convert the subgrade into dummy variables. Then concatenate these new columns to the original dataframe. Remember to drop the original subgrade column and to add drop_first=True to your get_dummies call.**","a91d7c0c":"**TASK: Set X and y variables to the .values of the features and label.**","27869095":"---\n---\n# Section 2: Data PreProcessing\n\n**Section Goals: Remove or fill any missing data. Remove unnecessary or repetitive features. Convert categorical string features to dummy variables.**\n\n","a6e75064":"**TASK: Import train_test_split from sklearn.**","b4303c15":"**TASK: Given the customer below, would you offer this person a loan?**","252f5350":"# GREAT JOB!","03456e9c":"**TASK: revol_util and the pub_rec_bankruptcies have missing data points, but they account for less than 0.5% of the total data. Go ahead and remove the rows that are missing those values in those columns with dropna().**","029c2301":"### grade feature\n\n**TASK: We already know grade is part of sub_grade, so just drop the grade feature.**"}}