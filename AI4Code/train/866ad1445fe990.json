{"cell_type":{"5d2cf113":"code","31663338":"code","2cb1c0da":"code","bea244bf":"code","09bd0259":"code","2ca65b22":"code","01c89668":"code","dc93aa06":"code","cd4785c4":"code","1a7b82d7":"code","0b6f4d6c":"code","be51c50f":"code","4004190e":"code","e93f3683":"code","cd9eece3":"code","44de19eb":"code","c2dcf192":"code","d5552c5c":"code","c4793377":"code","55bee221":"code","8c0e79bd":"code","bb5816ad":"markdown","0a8a3b10":"markdown","9688ef4c":"markdown","517f48b2":"markdown","3becf53f":"markdown","21aa740a":"markdown","9314b209":"markdown","4d930eda":"markdown","d7775147":"markdown","8537ac75":"markdown"},"source":{"5d2cf113":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31663338":"!pip install stable-baselines3[extra] pyvirtualdisplay gym[box2d] pyglet\n!apt-get install python-opengl -y","2cb1c0da":"import gym\nimport os\nfrom stable_baselines3 import PPO      #PPO -> Proximal Policy Optimization\nfrom stable_baselines3.common.vec_env import DummyVecEnv \nfrom stable_baselines3.common.evaluation import evaluate_policy  #to evaluate the model \nfrom stable_baselines3.common.callbacks import EvalCallback","bea244bf":"from pyvirtualdisplay import Display\ndisplay = Display(visible=0, size=(1024, 768))\ndisplay.start()\n\n\nfrom matplotlib import pyplot as plt, animation\n%matplotlib inline\nfrom IPython import display\n\ndef create_anim(frames, dpi, fps):\n    plt.figure(figsize=(frames[0].shape[1] \/ dpi, frames[0].shape[0] \/ dpi), dpi=dpi)\n    patch = plt.imshow(frames[0])\n    def setup():\n        plt.axis('off')\n    def animate(i):\n        patch.set_data(frames[i])\n    anim = animation.FuncAnimation(plt.gcf(), animate, init_func=setup, frames=len(frames), interval=fps)\n    return anim\n\ndef display_anim(frames, dpi=72, fps=60):\n    anim = create_anim(frames, dpi, fps)\n    return anim.to_jshtml()\n\ndef save_anim(frames, filename, dpi=72, fps=50):\n    anim = create_anim(frames, dpi, fps)\n    anim.save(filename)\n\n\nclass trigger:\n    def __init__(self):\n        self._trigger = True\n\n    def __call__(self, e):\n        return self._trigger\n\n    def set(self, t):\n        self._trigger = t","09bd0259":"environment_name = 'CarRacing-v0'    \nenv = gym.make(environment_name)","2ca65b22":"frames = []\nepisodes = 1\nfor episode in range(1, episodes+1):\n    state = env.reset()\n    done = False\n    score = 0\n    \n    while not done:\n        frames.append(env.render(mode='rgb_array'))\n        action = env.action_space.sample()\n        n_state, reward, done, info = env.step(action)\n        score += reward\n    print(\"Episode:{} Score:{}\".format(episode,score))\nenv.close()","01c89668":"display.HTML(display_anim(frames))","dc93aa06":"env = gym.make(environment_name)\nenv = DummyVecEnv([lambda: env])","cd4785c4":"# log_path = os.path.join('.\/Training\/Logs')\n# model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=log_path)\n# ppo_path = os.path.join('.\/Training\/Saved_Models\/PPO_car_best_Model')\n# eval_env = model.get_env()\n# eval_callback = EvalCallback(eval_env=eval_env, best_model_save_path=ppo_path,\n#                              n_eval_episodes=5,\n#                              eval_freq=50000,verbose=1,\n#                              deterministic=True, render=False)\n# model.learn(total_timesteps=1000000,callback=eval_callback)\n# ppo_path = os.path.join('.\/Training\/Saved_Models\/PPO_2m_Model_final')\n# model.save(ppo_path)","1a7b82d7":"ppo_path = os.path.join('..\/input\/car-racing-stable-baselines\/Training\/Saved_Models\/PPO_car_best_Model\/best_model.zip')","0b6f4d6c":"model = PPO.load(ppo_path, env=env)","be51c50f":"evalue = evaluate_policy(model, env, n_eval_episodes=10, render = True)\nenv.close()\nevalue","4004190e":"episodes = 1\nframes = []\nfor episode in range(1, episodes+1):\n    obs = env.reset()  #state = env.reset()\n    done = False\n    score = 0\n    \n    while not done:\n        frames.append(env.render(mode='rgb_array'))\n        action , _ = model.predict(obs) \n        obs, reward, done, info = env.step(action) \n        score += reward\n    print(\"Episode:{} Score:{}\".format(episode,score))\nenv.close()","e93f3683":"display.HTML(display_anim(frames))","cd9eece3":"ppo_path = os.path.join('..\/input\/car-racing-stable-baselines\/Training\/Saved_Models\/PPO_2m_Model_final.zip')","44de19eb":"fn_model = PPO.load(ppo_path, env=env)","c2dcf192":"evalue = evaluate_policy(fn_model, env, n_eval_episodes=10, render = True)\nenv.close()\nevalue","d5552c5c":"episodes = 1\nframes1 = []\nfor episode in range(1, episodes+1):\n    obs = env.reset()  #state = env.reset()\n    done = False\n    score = 0\n    \n    while not done:\n        frames1.append(env.render(mode='rgb_array'))\n        action , _ = fn_model.predict(obs) \n        obs, reward, done, info = env.step(action) \n        score += reward\n    print(\"Episode:{} Score:{}\".format(episode,score))\nenv.close()","c4793377":"display.HTML(display_anim(frames1))","55bee221":"filename = 'CarRacing-v0.mp4'\nsave_anim(frames, filename=filename)","8c0e79bd":"display.Video(filename, width=300, height=400)","bb5816ad":"<div class=\"alert alert-info\">  \n<h3><strong>3.Training Model<\/strong><\/h3>\n<\/div>","0a8a3b10":"<div class=\"alert alert-info\">  \n<h4><strong>5.Save Video(mp4) of Best Model<\/strong><\/h4>\n<\/div>","9688ef4c":"## Model was trained in first version of this notebook\n\n#### Model was uploaded using add data \n#### Trained for 1million steps there are two models \n#### 1. Best model at the time of training \n#### 2. Final model after 1m steps","517f48b2":"<div class=\"alert alert-info\">  \n<h5><strong>Best Model<\/strong><\/h5>\n<\/div>","3becf53f":"<div class=\"alert alert-info\">  \n<h3><strong>2.Test Environment<\/strong><\/h3>\n<\/div>","21aa740a":"### These are the steps used for training","9314b209":"<div class=\"alert alert-info\">  \n<h3><strong>4.Evaluating Models<\/strong><\/h3>\n<\/div>","4d930eda":"<div class=\"alert alert-info\">  \n<h3><strong>1.Import Dependencies<\/strong><\/h3>\n<\/div>","d7775147":"<div class=\"alert alert-info\">  \n<h5><strong>Final Model<\/strong><\/h5>\n<\/div>","8537ac75":"<div class=\"alert alert-info\">  \n<h4><strong>Testing Model<\/strong><\/h4>\n<\/div>"}}