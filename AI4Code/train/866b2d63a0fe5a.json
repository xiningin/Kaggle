{"cell_type":{"f2973845":"code","fd11054d":"code","c75a6848":"code","44e57ad7":"code","6993e88d":"code","099d6adf":"code","54987ee0":"code","ddb6c06e":"code","66ab727e":"code","6c1141fe":"code","dbda54c1":"code","4491bacc":"code","12a0acc4":"code","53340ef6":"code","02b98bde":"code","03dbddf3":"code","f7b00733":"code","9695e4ba":"code","a54fcdfb":"code","7f3cff7f":"code","be0e1a4c":"code","a41f3b23":"code","42c241a4":"code","59f67180":"code","38f8c5ba":"code","d8441fb3":"code","048b0b6f":"code","3374d4c6":"code","fd0af859":"code","c4aa722a":"code","533903ad":"code","65d9c591":"code","7455b18c":"code","43900282":"code","05e4d34f":"code","00035870":"code","9f9798a7":"code","335b8207":"code","ec27cc84":"code","01dc7a1e":"code","ea0a8f2c":"code","0c2d0937":"code","32d71e4f":"code","6b177626":"code","5d91d35d":"code","681195ad":"code","dcb59836":"code","f031a1b6":"code","741f7ad5":"code","0d6f1774":"code","c0856761":"code","28e96e24":"code","f00ec36b":"code","32011a9a":"code","0c2de952":"code","bcfd8f30":"code","db19d5ff":"code","cbce5702":"code","1b70bad5":"code","13cab672":"code","9074a872":"code","ef967e94":"code","bf6e523c":"code","b20e8534":"code","4a22973e":"code","cd818065":"code","4a5e1e44":"code","18a6125f":"code","e40ea3bf":"code","432ef6fa":"code","f150753d":"code","da0b4bb1":"code","2aacda60":"code","5ec8c10a":"code","bf51ad38":"code","05e23f1f":"code","2bdaf787":"code","41330a20":"code","00c5bca2":"code","707802c5":"code","f0bc5c12":"code","025a1b4f":"code","adaa0d70":"code","cf8a8108":"code","ab18b70a":"code","2139e198":"code","430511da":"code","0e3139cc":"markdown","ed1dc38e":"markdown","3f88dcdc":"markdown","92d5d947":"markdown","0aed796e":"markdown","27e97e69":"markdown","0b1a37f2":"markdown","798f8d93":"markdown","c1d3488f":"markdown","786b9b63":"markdown","4ee8fc22":"markdown","ec5034ed":"markdown","a812743d":"markdown","88048b3f":"markdown","0bc1e689":"markdown","a6d831aa":"markdown","4e74b63d":"markdown","d39a130e":"markdown","b7605415":"markdown","59a3bbd1":"markdown","8d3a8bb7":"markdown","22fcec18":"markdown","01a6a964":"markdown","393ceb4b":"markdown","105579f8":"markdown","e0686c80":"markdown","d29019e4":"markdown","99b93afb":"markdown","7104b255":"markdown","8dea791e":"markdown","2b6cada3":"markdown","51b28573":"markdown","703066bd":"markdown","f7394083":"markdown","9528176f":"markdown","8f594bf8":"markdown","c74738f8":"markdown","ef5d9472":"markdown","7099acde":"markdown","5b03c41f":"markdown","81432955":"markdown","2ad7b57a":"markdown","fb7f2c6f":"markdown","6d36d17b":"markdown","2f99990e":"markdown","9aaf3ed5":"markdown","eae03b43":"markdown","0e3df027":"markdown","0357fbe8":"markdown","98fa55f7":"markdown","aa52f41e":"markdown","305b3988":"markdown","6aa839b5":"markdown","e7aa7c34":"markdown","95ef70f3":"markdown","21fb3810":"markdown","50a9701e":"markdown","8fe0dd91":"markdown","4b59a267":"markdown","e53635ca":"markdown","7b07e6c8":"markdown","338dc803":"markdown","2447bd59":"markdown","42676cd0":"markdown","97521edf":"markdown","d2df9172":"markdown","2904d06d":"markdown","9ffec5e8":"markdown","7607130f":"markdown","aa323f15":"markdown","a330534c":"markdown","5238e6d4":"markdown","ffbb2159":"markdown","e2b808a4":"markdown","ec333362":"markdown","d476d928":"markdown","e705d005":"markdown","5b42ca6d":"markdown"},"source":{"f2973845":"#Importing Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import boxcox\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set()\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","fd11054d":"data_train=pd.read_csv(\"..\/input\/airline-passenger-satisfaction\/train.csv\")\ndata_test=pd.read_csv(\"..\/input\/airline-passenger-satisfaction\/test.csv\")\ndata_train.head()","c75a6848":"data_test.head()","44e57ad7":"data_train.columns","6993e88d":"data_test.columns","099d6adf":"print(f\"Train data has {data_train.shape[0]} rows and  {data_train.shape[1]} columns.\")\nprint(\"Distribution of target value:\\n\")\ndata_train.satisfaction.value_counts()","54987ee0":"print(f\"Test data has {data_test.shape[0]} rows and {data_test.shape[1]} columns.\")\nprint(\"Distribution of target value:\\n\")\ndata_test.satisfaction.value_counts()","ddb6c06e":"data=data_train.append(data_test)\ndata.head()","66ab727e":"data.shape","6c1141fe":"data.info()","dbda54c1":"data.describe().T","4491bacc":"data.satisfaction.unique()","12a0acc4":"data.isna().sum()","53340ef6":"data.duplicated().sum()","02b98bde":"data.nunique()","03dbddf3":"data.loc[data[\"Customer Type\"]==\"disloyal Customer\",\"Customer Type\"]=\"Disloyal Customer\"\ndata.loc[data[\"Type of Travel\"]==\"Business travel\",\"Type of Travel\"]=\"Business Travel\"","f7b00733":"plt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.countplot(x='satisfaction', data=data, palette=[\"#f08080\",\"#87cefa\"])\n\nplt.subplot(1, 2, 2)\nplt.pie(data['satisfaction'].value_counts(), labels=[\"neutral or dissatisfied\",\"satisfied\"], explode=[0, 0.05], autopct='%1.2f%%', shadow=True,colors=[\"lightcoral\",\"lightskyblue\"])\nplt.title('satisfaction', fontsize=15)\n\nplt.show()","9695e4ba":"categorics=['Gender', 'Customer Type','Type of Travel', 'Class','Inflight wifi service',\n       'Departure\/Arrival time convenient', 'Ease of Online booking',\n       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n       'Inflight entertainment', 'On-board service', 'Leg room service',\n       'Baggage handling', 'Checkin service', 'Inflight service',\n       'Cleanliness']\nfor i in categorics:\n  plt.figure(figsize=(16,6))\n  plt.subplot(1,2,1)\n  sns.countplot(x=data[i],palette=\"Pastel1\")\n\n  plt.subplot(1,2,2)\n  sns.countplot(x=data[i],hue=data.satisfaction, palette=[\"#f08080\",\"#87cefa\"])\n  plt.show()","a54fcdfb":"for i in ['Gender','Customer Type','Type of Travel','Class']:\n  categorics.remove(i)","7f3cff7f":"data[categorics].mean().sort_values(ascending=False)","be0e1a4c":"total = float(len(data))\nax = data[categorics].mean().sort_values(ascending=False).plot(kind=\"barh\",ylabel=\"Features\",colormap=\"Pastel1\",xticks=[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5],figsize=(14,6))\nplt.title('Average satisfaction ratings of services', fontsize=16)\nfor p in ax.patches:\n    count = '{:.1f}'.format(p.get_width())\n    x, y = p.get_x() + p.get_width()+0.15, p.get_y()\n    ax.annotate(count, (x, y), ha='right')\nplt.show()","a41f3b23":"ax = data[categorics].std().sort_values(ascending=False).plot(kind=\"barh\",ylabel=\"Features\",colormap=\"Pastel1\",figsize=(14,6))\nplt.title('Standard deviation of service ratings', fontsize=16)\nfor p in ax.patches:\n    count = '{:.1f}'.format(p.get_width())\n    x, y = p.get_x() + p.get_width()+0.05, p.get_y()\n    ax.annotate(count, (x, y), ha='right')\nplt.show()","42c241a4":"data[data[\"Class\"]==\"Business\"].mean()[4:18].plot(kind=\"barh\",legend=True,ylabel=\"Features\",colormap=\"Pastel2\",figsize=(14,6),label=\"Business Class\",title=\"Average satisfaction ratings of Business and Eco Class passengers\")\ndata[data[\"Class\"]==\"Eco\"].mean()[4:18].plot(kind=\"barh\",legend=True,colormap=\"Pastel1\",label=\"Eco Class\",xticks=[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5])\nplt.show()","59f67180":"plt.figure(figsize=(7,7))\nsns.catplot(y='Departure\/Arrival time convenient',col='Type of Travel',x ='Customer Type',\n            hue='satisfaction',row='Class', data=data, kind= 'bar',palette='Pastel1')\nplt.show()","38f8c5ba":"def percentage(x):\n  return round(100*x.count()\/data.shape[0],2)\ntable1=data.pivot_table(index=[\"Gender\"],columns=[\"satisfaction\"],aggfunc={\"satisfaction\":[\"count\",percentage]},fill_value=0)\ntable1","d8441fb3":"gender=\"female\"\nfor i,j,k,l in table1.values:\n  print(\"Satisfaction rate for {} is: {:.3f}\".format(gender,j\/(i+j)))\n  gender=\"male\"","048b0b6f":"plt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.pie(data.loc[data.Gender==\"Female\",'satisfaction'].value_counts(), labels=[\"neutral or dissatisfied\",\"satisfied\"], explode=[0, 0.05], autopct='%1.2f%%', shadow=True,colors=[\"lightcoral\",\"lightskyblue\"])\nplt.title('Satisfaction (Female)', fontsize=15)\n\nplt.subplot(1, 2, 2)\nplt.pie(data.loc[data.Gender==\"Male\",'satisfaction'].value_counts(), labels=[\"neutral or dissatisfied\",\"satisfied\"], explode=[0, 0.05], autopct='%1.2f%%', shadow=True,colors=[\"lightcoral\",\"lightskyblue\"])\nplt.title('Satisfaction (Male)', fontsize=15)\n\nplt.show()","3374d4c6":"data.pivot_table(index=[\"Customer Type\",\"Class\"],columns=[\"satisfaction\"],aggfunc={\"satisfaction\":[\"count\",percentage]})","fd0af859":"ax = data.pivot_table(index=[\"Customer Type\",\"Class\"],columns=[\"satisfaction\"],aggfunc={\"satisfaction\":\"count\"}).plot(kind=\"barh\",figsize=(24,6))\nplt.title('Satisfaction based on Customer Type and Class', fontsize=16)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n    x,y  = p.get_x() + p.get_width()+1000, p.get_y()\n    ax.annotate(percentage, (x, y),ha='right')\nplt.show()","c4aa722a":"data.pivot_table(index=[\"Type of Travel\",\"Class\"],columns=[\"satisfaction\"],aggfunc={\"satisfaction\":[\"count\",percentage]})","533903ad":"ax = data.pivot_table(index=[\"Type of Travel\",\"Class\"],columns=[\"satisfaction\"],aggfunc={\"satisfaction\":\"count\"}).plot(kind=\"barh\",figsize=(24,6))\nplt.title('Satisfaction based on Travel Type and Class', fontsize=16)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n    x,y  = p.get_x() + p.get_width()+1100, p.get_y()\n    ax.annotate(percentage, (x, y),ha='right')\nplt.show()","65d9c591":"data.pivot_table(index=[\"Gender\",\"Customer Type\"],columns=[\"Inflight wifi service\"],aggfunc={\"satisfaction\":[\"count\",percentage]})","7455b18c":"ax = pd.crosstab([data[\"Gender\"], data[\"Customer Type\"]],data[\"Inflight wifi service\"],\n            rownames=['Gender ', \" Customer Type\"],\n            colnames=[\"Inflight wifi service\"],\n            dropna=False).plot(kind=\"bar\",figsize=(30,6),rot=0)\nplt.title('Inflight wifi service ratings based on Gender and Customer Type', fontsize=16)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n    x, y = p.get_x() + p.get_width(), p.get_height()\n    ax.annotate(percentage, (x, y),ha='right')\nplt.show()","43900282":"data.pivot_table(index=\"Class\",columns=[\"Food and drink\"],aggfunc={\"satisfaction\":[\"count\",percentage]})","05e4d34f":"ax = pd.crosstab(data[\"Class\"],data[\"Food and drink\"],\n            rownames=['Class '],\n            colnames=['Food and drink'],\n            dropna=False).plot(kind=\"bar\",figsize=(30,6),rot=0)\nplt.title('Food and drink service points based on Class', fontsize=16)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n    x = p.get_x() + p.get_width()\n    y = p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()","00035870":"data.pivot_table(index=[\"Type of Travel\",\"Cleanliness\"],columns=['satisfaction'],aggfunc={\"satisfaction\":[\"count\",percentage]},fill_value=0)","9f9798a7":"ax = data.pivot_table(index=[\"Type of Travel\",\"Cleanliness\"],columns=[\"satisfaction\"],aggfunc={\"satisfaction\":\"count\"},fill_value=0).T.plot(kind=\"bar\",figsize=(30,6),rot=0)\nplt.title('Cleanliness service points based on Type of Travel and Satisfaction', fontsize=16)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n    x, y = p.get_x() + p.get_width(), p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()","335b8207":"data[\"Age Group\"]=pd.cut(data.Age,[np.min(data.Age),np.percentile(data.Age,25),np.percentile(data.Age,50),np.percentile(data.Age,75),np.max(data.Age)+1], right=False)","ec27cc84":"data[[\"Age\",\"Age Group\"]][:5]","01dc7a1e":"table2=data.pivot_table(index=[\"Age Group\"],columns=[\"satisfaction\"],aggfunc={\"satisfaction\":\"count\"},fill_value=0)\ntable2","ea0a8f2c":"ax = table2.plot(kind=\"bar\", figsize=(16,8), color=[\"#f08080\",\"#87cefa\"])\nplt.title('Satisfaction based on Age Groups', fontsize=16)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n    x, y = p.get_x() + p.get_width(), p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()","0c2d0937":"table3=data.pivot_table(index=[\"Age Group\"],columns=[\"Baggage handling\",],aggfunc={\"Baggage handling\":\"count\"})\ntable3","32d71e4f":"ax = table3.plot(kind=\"bar\",figsize=(26,6))\nplt.title('Baggage Handling service ratings based on Age Groups', fontsize=16)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n    x, y = p.get_x() + p.get_width(), p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()","6b177626":"data[(data['Departure Delay in Minutes'] == 0 ) & (data['Arrival Delay in Minutes'] == 0 )].groupby('satisfaction')[\"id\"].count().reset_index().set_index(\"satisfaction\")","5d91d35d":"numerics=['Departure Delay in Minutes', 'Arrival Delay in Minutes','Flight Distance',\"Age\"]\nsns.pairplot(data[[*numerics,\"satisfaction\"]],hue=\"satisfaction\")\nplt.show()","681195ad":"sns.boxplot(x=\"Age\",y=\"satisfaction\",data=data)\nplt.show()","dcb59836":"plt.figure(figsize=(20, 6))\nfor i,j in enumerate(numerics):\n  plt.subplot(1,len(numerics),i+1)\n  sns.boxplot(data[j])","f031a1b6":"fig, ax = plt.subplots(1,len(numerics),figsize=(20,5))\nfig.suptitle(\"Distribution of numeric features\",y=1)\nfor i,j in enumerate(numerics):\n  sns.distplot(x=data[j],ax=ax[i])\n  ax[i].set_xlabel(j)\nfig.tight_layout(pad=1.5)","741f7ad5":"sns.scatterplot(x=data['Arrival Delay in Minutes'],y=data['Departure Delay in Minutes'])\nplt.show()","0d6f1774":"data[['Arrival Delay in Minutes','Departure Delay in Minutes']].corr()","c0856761":"data.drop([\"Unnamed: 0\",\"id\",\"Age Group\"],axis=1,inplace=True)\ndata_backup=data.copy()\ndata.head()","28e96e24":"plt.figure(figsize=(22,10))\nsns.heatmap(data.corr(), vmin=-1, vmax=1, center=0,cmap=sns.diverging_palette(20, 220, n=200),square=True,annot=True,fmt='.2f',)\nplt.show()","f00ec36b":"data.drop([\"Arrival Delay in Minutes\",\"Departure Delay in Minutes\"],axis=1,inplace=True)","32011a9a":"data_temp=data.copy()\ndata_temp[\"satisfaction\"]=data_temp[\"satisfaction\"].map({\"satisfied\":1,\"neutral or dissatisfied\":0})\ndata_temp.corr()['satisfaction'].sort_values().drop('satisfaction').plot(kind='barh',title=\"Correlation with Satisfaction\")\nplt.show()","0c2de952":"data_temp.corr()['Online boarding'].sort_values().drop(['Online boarding','satisfaction']).plot(kind='barh',title=\"Correlation with Online Boarding service\")\nplt.show()","bcfd8f30":"sns.boxplot(x=data['Inflight wifi service'], y = data_temp['Online boarding'])\nplt.show()","db19d5ff":"data.head()","cbce5702":"#categorics\ndata[[\"Gender\",\"Customer Type\",\"Type of Travel\",\"Class\",\"satisfaction\"]].head()","1b70bad5":"#mapping ordinal features\ndata[\"Class\"] = data[\"Class\"].map({'Business':2, 'Eco Plus':1, 'Eco':0})\ndata[\"satisfaction\"]=data[\"satisfaction\"].map({\"satisfied\":1,\"neutral or dissatisfied\":0})","13cab672":"#for nominal features,\ndata_new=pd.get_dummies(data,drop_first=True)\n#i use drop_first parameter so my model does not get any confusion by counting some features second time\ndata_new.reset_index(inplace=True)\ndata_new.drop(\"index\",axis=1,inplace=True)\ndata_new.head()","9074a872":"data_new[[\"Gender_Male\",\"Customer Type_Loyal Customer\",\"Type of Travel_Personal Travel\",\"Class\",\"satisfaction\"]].head()","ef967e94":"df_local=data_new.copy()\ntemp = df_local.drop(\"satisfaction\", axis=1)\nlocal_outlier = LocalOutlierFactor(n_neighbors=2).fit_predict(temp)\noutlier_local=list(np.where(local_outlier == -1)[0])\ndel temp\nprint(f\"Outlier Count: {len(outlier_local)} \\nSample Count: {len(df_local)} \\nFraction: {round(len(outlier_local)\/len(df_local),3)}\")\ndf_local=df_local.drop(outlier_local).reset_index(drop=True)","bf6e523c":"#Log Transformation\ndf_log=df_local.copy()\ndf_log[\"Flight Distance\"]=np.log(df_log[\"Flight Distance\"])\ndf_log[\"Age\"]=np.log(df_log[\"Age\"])","b20e8534":"#Square-Root Transformation\ndf_sqrt=df_local.copy()\ndf_sqrt[\"Flight Distance\"]=np.sqrt(df_sqrt[\"Flight Distance\"])\ndf_sqrt[\"Age\"]=np.sqrt(df_sqrt[\"Age\"])","4a22973e":"#Box Cox Transformation\ndf_boxcox=df_local.copy()\ndf_boxcox[\"Flight Distance\"],lmbda=boxcox(df_boxcox[\"Flight Distance\"],lmbda=None)\ndf_boxcox[\"Age\"],lmbda=boxcox(df_boxcox[\"Age\"],lmbda=None)","cd818065":"#Flight Distance feature\nplt.figure(figsize=(20, 12))\n\nplt.subplot(2, 4, 1)\nplt.boxplot(df_local['Flight Distance'])\nplt.title('Flight Distance')\n\nplt.subplot(2, 4, 2)\nplt.boxplot(df_log[\"Flight Distance\"])\nplt.title('Flight Distance (Log Transformation)')\n\nplt.subplot(2, 4, 3)\nplt.boxplot(df_sqrt['Flight Distance'])\nplt.title('Flight Distance (Square Root Transformation)')\n\nplt.subplot(2, 4, 4)\nplt.boxplot(df_boxcox['Flight Distance']);\nplt.title('Flight Distance (Box Cox Transformation)')\n\nplt.subplot(2, 4, 5)\nplt.hist(df_local['Flight Distance'])\nplt.title('Flight Distance')\n\nplt.subplot(2, 4, 6)\nplt.hist(df_log[\"Flight Distance\"])\nplt.title('Flight Distance (Log Transformation)')\n\nplt.subplot(2, 4, 7)\nplt.hist(df_sqrt['Flight Distance'])\nplt.title('Flight Distance (Square Root Transformation)')\n\nplt.subplot(2, 4, 8)\nplt.hist(df_boxcox['Flight Distance']);\nplt.title('Flight Distance (Box Cox Transformation)')\n\nplt.show()","4a5e1e44":"#Age Feature\nplt.figure(figsize=(20, 12))\n\nplt.subplot(2, 4, 1)\nplt.boxplot(df_local['Age'])\nplt.title('Age')\n\nplt.subplot(2, 4, 2)\nplt.boxplot(df_log[\"Age\"])\nplt.title('Age (Log Transformation)')\n\nplt.subplot(2, 4, 3)\nplt.boxplot(df_sqrt['Age'])\nplt.title('Age (Square Root Transformation)')\n\nplt.subplot(2, 4, 4)\nplt.boxplot(df_boxcox['Age']);\nplt.title('Age (Box Cox Transformation)')\n\nplt.subplot(2, 4, 5)\nplt.hist(df_local['Age'])\nplt.title('Age')\n\nplt.subplot(2, 4, 6)\nplt.hist(df_log[\"Age\"])\nplt.title('Age (Log Transformation)')\n\nplt.subplot(2, 4, 7)\nplt.hist(df_sqrt['Age'])\nplt.title('Age (Square Root Transformation)')\n\nplt.subplot(2, 4, 8)\nplt.hist(df_boxcox['Age']);\nplt.title('Age (Box Cox Transformation)')\n\nplt.show()","18a6125f":"for j in [\"Flight Distance\",\"Age\"]:\n  transforms=[df_local[j], df_log[j], df_sqrt[j], df_boxcox[j]]\n  processes=[\"original\",\"log\",\"square root\",\"box cox\"]\n  for i,k in zip(transforms,processes):\n    print(f\"Normality for {j} Feature ({k}):\",stats.shapiro(i))","e40ea3bf":"X_train, X_test, y_train, y_test=train_test_split(df_local.drop(\"satisfaction\",axis=1),df_local[\"satisfaction\"],test_size=0.3,random_state=42)","432ef6fa":"print(\"Train size:\", X_train.shape)\nprint(\"Test size:\", X_test.shape)","f150753d":"scaler=MinMaxScaler()\nscaler.fit(X_train)\nX_train_scaled=scaler.transform(X_train)\nX_test_scaled=scaler.transform(X_test)","da0b4bb1":"#Creating a function that creates a dataframe for testing model performance\ndef model_perf(model,X_train,X_test,y_train,y_test,pred,model_name):\n  \"\"\"Takes the data, returns a dataframe that calculates the performance of the model\"\"\"\n  cv_results=cross_val_score(model,X_train,y_train,cv=5)\n  perf_df=pd.DataFrame({\"Mean_CV\":np.mean(cv_results),\"Std_CV\":np.std(cv_results),'Train_Score':model.score(X_train,y_train),\"Test_Score\":model.score(X_test,y_test),\"Precision_Score\":precision_score(y_test,pred),\"Recall_Score\":recall_score(y_test,pred),\"F1_Score\":f1_score(y_test,pred)},index=[model_name])\n  return perf_df","2aacda60":"nb=GaussianNB().fit(X_train_scaled,y_train)\npred_nb = nb.predict(X_test_scaled)\nperf_nb=model_perf(nb,X_train_scaled,X_test_scaled,y_train,y_test,pred_nb,\"Gaussian NB\")\nperf_nb","5ec8c10a":"svc=LinearSVC()\nparameters={\"C\":[0.01,0.1,1,10]}\nsearcher=GridSearchCV(svc,parameters,cv=5,n_jobs=-1).fit(X_train_scaled,y_train)\nbest_model_svc=searcher.best_estimator_\npred_svc = best_model_svc.predict(X_test_scaled)\nprint(\"Best Parameters:\",searcher.best_params_)\nperf_svc=model_perf(best_model_svc,X_train_scaled,X_test_scaled,y_train,y_test,pred_svc,\"Linear SVC\")\nperf_svc","bf51ad38":"log=LogisticRegression(random_state=42)\nparams={\"C\":[0.001,0.01,0.1,1,10],\"penalty\":[\"l1\",\"l2\"]}\nsearcher=GridSearchCV(log,params,cv=5,n_jobs=-1).fit(X_train_scaled,y_train)\nbest_model_log=searcher.best_estimator_\npred_log = best_model_log.predict(X_test_scaled)\nprint(\"Best Parameters:\",searcher.best_params_)\ny_pred_log_proba=best_model_log.predict_proba(X_test_scaled)[:,1]\nprint(\"ROC AUC Score:\",roc_auc_score(y_test,y_pred_log_proba))\nperf_log=model_perf(best_model_log,X_train_scaled,X_test_scaled,y_train,y_test,pred_log,\"Logistic Regression\")\nperf_log","05e23f1f":"knn=KNeighborsClassifier()\nparams={\"n_neighbors\":np.arange(3,10,2)}\nsearcher=GridSearchCV(knn,params,cv=5,n_jobs=-1).fit(X_train_scaled,y_train)\nbest_model_knn=searcher.best_estimator_\npred_knn = best_model_knn.predict(X_test_scaled)\nprint(\"Best Parameters:\",searcher.best_params_)\nperf_knn=model_perf(best_model_knn,X_train_scaled,X_test_scaled,y_train,y_test,pred_knn,\"KNN\")\nperf_knn","2bdaf787":"dt=DecisionTreeClassifier(random_state=42)\nparameters={\"max_depth\":[*range(3,10,2),None],\"max_features\":[*range(3,10,2),None],\"min_samples_leaf\":list(range(1,10,2)),\"criterion\":[\"gini\",\"entropy\"]}\nsearcher=GridSearchCV(dt,parameters,cv=5,n_jobs=-1).fit(X_train_scaled,y_train)\nbest_model_dt=searcher.best_estimator_\npred_dt = best_model_dt.predict(X_test_scaled)\nprint(\"Best Parameters:\",searcher.best_params_)\nperf_dt=model_perf(best_model_dt,X_train_scaled,X_test_scaled,y_train,y_test,pred_dt,\"Decision Tree\")\nperf_dt","41330a20":"classifiers=[(\"Logistic Regression\",best_model_log),(\"KNN\",best_model_knn),(\"Decision Tree\",best_model_dt)]\nvc=VotingClassifier(estimators=classifiers).fit(X_train_scaled,y_train)\npred_vc=vc.predict(X_test_scaled)\nperf_vc=model_perf(vc,X_train_scaled,X_test_scaled,y_train,y_test,pred_vc,\"Voting Classifier\")\nperf_vc","00c5bca2":"base_dt=DecisionTreeClassifier(random_state=42)\nbc=BaggingClassifier(base_estimator=base_dt,n_estimators=300,oob_score=True,n_jobs=-1).fit(X_train_scaled,y_train)\npred_bc=bc.predict(X_test_scaled)\nprint(\"OOB Score:\",bc.oob_score_)\nperf_bc=model_perf(bc,X_train_scaled,X_test_scaled,y_train,y_test,pred_bc,\"Bagging Classifier\")\nperf_bc","707802c5":"rf=RandomForestClassifier(random_state=42,n_estimators=300).fit(X_train_scaled,y_train)\npred_rf=rf.predict(X_test_scaled)\nperf_rf=model_perf(rf,X_train_scaled,X_test_scaled,y_train,y_test,pred_rf,\"Random Forest\")\nperf_rf","f0bc5c12":"base_ada_dt=DecisionTreeClassifier(max_depth=1,random_state=42)\nadb=AdaBoostClassifier(base_estimator=base_ada_dt,n_estimators=100).fit(X_train_scaled,y_train)\npred_adb=adb.predict(X_test_scaled)\ny_pred_adb_proba=adb.predict_proba(X_test_scaled)[:,1]\nprint(\"ROC AUC Score:\",roc_auc_score(y_test,y_pred_adb_proba))\nperf_adb=model_perf(adb,X_train_scaled,X_test_scaled,y_train,y_test,pred_adb,\"AdaBoost\")\nperf_adb","025a1b4f":"sgb=GradientBoostingClassifier(n_estimators=300,max_depth=11,subsample=0.8,max_features=0.6,random_state=42).fit(X_train_scaled,y_train) #Tuned parameters (with GridCV)\npred_sgb=sgb.predict(X_test_scaled)\nperf_sgb=model_perf(sgb,X_train_scaled,X_test_scaled,y_train,y_test,pred_sgb,\"Stochastic Gradient Boosting\")\nperf_sgb","adaa0d70":"xgb=XGBClassifier(random_state=42, max_depth=9, min_child_weight=3, n_estimators=100) #Tuned parameters (with GridCV)\nxgb.fit(X_train_scaled,y_train)\npred_xgb = xgb.predict(X_test_scaled)\nperf_xgb=model_perf(xgb,X_train_scaled,X_test_scaled,y_train,y_test,pred_xgb,\"XGBoost\")\nperf_xgb","cf8a8108":"pd.concat([perf_nb, perf_svc, perf_log, perf_knn, perf_dt, perf_vc, perf_bc, perf_rf, perf_adb, perf_sgb, perf_xgb])","ab18b70a":"perf_rf","2139e198":"print(classification_report(y_test,pred_rf))","430511da":"plt.figure(figsize=(12, 8))\ncf_matrix=confusion_matrix(y_test,pred_rf)\ngroup_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()\/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nax=sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues',xticklabels=[\"neutral or dissatisfied\",\"satisfied\"], yticklabels=[\"neutral or dissatisfied\",\"satisfied\"])\nax.set_xlabel('Predicted Label',fontsize = 15)\nax.set_ylabel('Actual Label',fontsize = 15)\nplt.show()","0e3139cc":"Checking outliers with boxplot","ed1dc38e":"**Feature Transformation**","3f88dcdc":"Looking at the data types, and descriptive statistics of features","92d5d947":"The assumptions of some machine learning models are based on the normality of features. I will try to make the distribution of my features look like a normal distribution with some transformation operations. Different methods can be used to see which one is better for the data. I will mostly check \"Flight_Distance' and \"Age\" columns.\n\nMethods i use:\n1. Log Transformation\n2. Square Root Transformation\n3. Box Cox Transformation","0aed796e":"**Feature Scaling**","27e97e69":"While there is a visible relationship between some numeric features (Arrival_Delay_in_Minutes and Departure_Delay_in_Minute), some are unrelated to each other (Flight_Distance and Age).","0b1a37f2":"**ATTRIBUTES:**\n\n>**Id:** Id number of the passengers\n\n>**Gender:** Gender of the passengers (Female, Male)\n\n>**Customer Type:** The customer type (Loyal customer, disloyal customer)\n\n>**Age:** The actual age of the passengers\n\n>**Type of Travel:** Purpose of the flight of the passengers (Personal Travel, Business Travel)\n\n>**Class:** Travel class in the plane of the passengers (Business, Eco, Eco Plus)\n\n>**Flight Distance:** The flight distance of this journey\n\n>**Inflight wifi service:** Satisfaction level of the inflight wifi service (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Departure\/Arrival time convenient:** Satisfaction level of Departure\/Arrival time convenient (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Ease of Online booking:** Satisfaction level of online booking (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Gate location:** Satisfaction level of Gate location (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Food and drink:** Satisfaction level of Food and drink service (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Online boarding:** Satisfaction level of online boarding (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied) \n\n>**Seat comfort:** Satisfaction level of Seat comfort (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Inflight entertainment:** Satisfaction level of inflight entertainment (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**On-board service:** Satisfaction level of On-board service (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Leg room service:** Satisfaction level of Leg room service (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Baggage handling:** Satisfaction level of baggage handling (1,2,3,4,5\/ 1=Least Satisfied to 5=Most Satisfied)\n\n>**Checkin service:** Satisfaction level of Check-in service (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Inflight service:** Satisfaction level of inflight service (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Cleanliness:** Satisfaction level of Cleanliness (0,1,2,3,4,5\/ 0=Not Applicable; 1=Least Satisfied to 5=Most Satisfied)\n\n>**Departure Delay in Minutes:** Minutes delayed when departure\n\n>**Arrival Delay in Minutes:** Minutes delayed when arrival\n\n>**Satisfaction:** \/output column\/ Airline satisfaction level ('satisfied', 'neutral or dissatisfied')","798f8d93":"I will use Local Outlier Factor Method to detect and drop outliers.","c1d3488f":"We can see that those who are loyal customers and in the business class are the passengers with the highest satisfaction rate (30.4%). Passengers who are loyal and in the eco class are the passengers with the highest dissatisfaction rate (27.5%).","786b9b63":"Removing [ 'Gender' , 'Customer_Type' , 'Type_of_Travel' , 'Class' ] features from categorics list so I only have categorical features having 0-1-2-3-4-5 scores can stay in list.","4ee8fc22":"Features that slightly correlates more with customer satisfaction are 'Inflight wifi service', 'Flight Distance', 'Cleanliness', 'Leg room service', 'On-board service', 'Seat comfort', 'Inflight entertainment',and 'Online boarding'.\n\nAmong features \"Online boarding\" has the maximum correlation to target, i will check its correlation with other features.","ec5034ed":"**Gaussian Naive Bayes**","a812743d":"As I knew it was not right to only look at accuracy when evaluating my model performance in classification problems, I also looked at precision, recall, and f1 score. I also checked the cross validation mean and the cross validation standard deviation to account for any deviations between results. As a result, all models performed well and close to each other. By considering F1 score; Bagging Classifier, Random forest, Stochastic Gradient Boosting and XGBoost have the highest scores. Classification report and confusion matrix of Random Forest model are shown below.","88048b3f":"Combining these two dataset into one","0bc1e689":"Visualizing Transformed Features","a6d831aa":"<h2> PRE-PROCESSING <\/h2>","4e74b63d":"**Visualizing target column**","d39a130e":"<h2>AIRLINE PASSENGER SATISFACTION DATASET<\/h2>","b7605415":"There are outliers in data. I will handle them later.","59a3bbd1":"As the score given to the Inflight wifi service increases, the range distributed to online boarding decreases and its score increases. People who gets better service of inflight wifi are more likely to give better rating for online boarding.","8d3a8bb7":"> It would be more meaningful if the data were divided into 3 groups as satisfied, neutral and dissatisfied passengers. It was difficult to draw meaningful conclusions as the inclusion of neutral passengers in the dissatisfied group increased the dissatisfaction rate for all services.\n\n> By looking at the visualizations and feature importances of model; services that affect satisfaction the most are Online boarding, Inflight wifi service, Inflight entertainment, Seat comfort, Cleanliness, and On board service.\n\n> Gender has no obvious effect on overall satisfaction and scores.\n\n> Passengers whose age is between 40 to 51 are more likely to be satisfied.\n\n> The majority of personal travel passengers are not satisfied, incentive campaigns can be organized for them.\n\n> While the business class passengers are generally satisfied, the majority of the eco class passengers are not. Extra services can be added for eco class.","22fcec18":"There are both numeric and object type features in data.","01a6a964":"When we look at the scores given to the baggage handling service by dividing the age groups, we can say that the scores are similar among age groups. I can say that age groups do not have an obvious effect on the scores.","393ceb4b":"Checking whether data has duplicate values","105579f8":"**Decision Tree**","e0686c80":"Female and male data amounts are close to each other. In the Customer Type feature, which is divided into two groups as Loyal customer and disloyal customer, the number of Loyal customers is more than the number of Disloyal customers. We can say that half of the Loyal customers are satisfied and half are neutral or dissatisfied. But in Disloyal customers, the number of satisfied passengers is less than the number of neutral or dissatisfied. Type of Travel feature consists of two categories as Personal and Business travel. It seems that the number of passengers making Business travel is higher than those making Personnel travel. While the number of satisfied passengers is higher in Business travel, the number of satisfied passengers is very low in Personal travel. Class features are divided into three categories: Eco, Business, and Eco Plus. While the number of passengers in the Business and Eco classes is close to each other, the number of passengers in the Eco Plus class is much less. While the majority of passengers in Business class are satisfied, the majority of passengers in Eco class are neutral or dissatisfied. In the other features, there are 6 categories from 1 to 5 (increasing satisfaction rates), while 0 represents unimplemented features. Neutral or dissatisfied passengers appear more in all categories of the Departure\/Arrival time convenient feature. As we can predict for other features, neutral or dissatisfied passengers are more at low satisfaction levels like 0-1-2 at the beginning, while satisfied passengers are more at high satisfaction levels like 4-5.","d29019e4":"Our target column consists of two categories which are \"neutral or dissatisfied\" and \"satisfied\". Neutral or dissatisfied passenger amount is higher in data. As shown in graph, we can say that we do not have any imbalance problem.","99b93afb":"Arrival_Delay_in_Minutes and Departure_Delay_in_Minutes columns show a maximum value at 0. As the delay minutes increase, occurrences decrease. We see that the values in the Flight_Distance column are mostly concentrated in the 0-1000 range. Also there are people of all ages in the data.","7104b255":"Checking null values","8dea791e":"While business travel passengers were more satisfied, personal travel passengers were more dissatisfied. Neutral or dissatisfied passengers give similar rates to cleanliness regardless of the type of travel. But among satisfied passengers, business travel passengers give more points to cleanliness. The number of passengers who are satisfied and make personal travel is quite low.","2b6cada3":"The number of passengers in the eco plus class is low in the data. The number of business class passengers and eco class passengers is very close to each other. Business class passengers seem to give more points to the food and drink service.","51b28573":"<h2> MODEL <\/h2>","703066bd":"I also checked the standard deviation to account for any deviations between ratings. They are close to each other.","f7394083":"**Splitting data**","9528176f":"**Ensemble Learning - XGBoost (Extreme Gradient Boosting)**","8f594bf8":"Data consists of the details of customers in an airline company who have already flown with them. The main purpose of this dataset is to predict whether a future customer would be satisfied with their service and which aspect of the services offered by them have to be emphasized more to generate more satisfied customers. Data consists of total 129880 observations (train data:103904, test data:25976) and 25 columns.","c74738f8":"**Ensemble Learning - Voting Classifier**","ef5d9472":"Even if I do transformation, my features still do not have a normal distribution. That's why I'm going to continue without transformation.","7099acde":"Models i use:\n* Gaussian Naive Bayes\n* Linear SVC\n* Logistic Regression\n* K-Nearest Neighbors\n* Decision Tree\n* Voting Classifier\n* Bagging Classifier\n* Random Forest\n* AdaBoost \n* Stochastic Gradient Boosting\n* XGBoost","5b03c41f":"<h2>CONCLUSION<\/h2>","81432955":"<h2> DATA VISUALIZATION <\/h2>","2ad7b57a":"**Ensemble Learning - Bagging Classifier**","fb7f2c6f":"Creating a pairplot to see the distribution of numeric features and their relation with other numeric features.","6d36d17b":"When we look at the satisfaction rates of women and men, we see that both are around 43-44%. There is no dominance in satisfaction by gender. The dissatisfaction rate is higher in both gender.","2f99990e":"* \"Ease of Online booking\" and \"Inflight wifi service\" are positive correlated with ratio 0.71.\n* \"Inflight entertainment\" and \"Food and drink\" are positive correlated with ratio 0.62.\n* \"Inflight entertainment\" and \"Seat comfort\" are positive correlated with ratio 0.61.\n* \"Inflight service\" and \"Baggage handling\" are positive correlated with ratio 0.63.\n* \"Cleanliness\" and \"Food and drink\" are positive correlated with ratio 0.66.\n* \"Cleanliness\" and \"Seat comfort\" are positive correlated with ratio 0.68.\n* \"Cleanliness\" and \"Inflight entertainment\" are positive correlated with ratio 0.69.\n\n'Departure delay in minutes' and 'Arrival delay in minutes' columns are highly positive correlated (0.97) as we have seen. Normally we should drop one of them. Since 'Arrival_Delay_in_Minutes' column has null values, it would be our first choice. But 'Departure delay in minutes' and 'Arrival_Delay_in_Minutes' columns have full of zero values, so they are not very important features in model. I will drop both of these columns.","9aaf3ed5":"**Ensemble Learning - Stochastic Gradient Boosting Classifier**","eae03b43":"**KNN**","0e3df027":"'Arrival_Delay_in_Minutes' column has 393 null values. I will deal with them later.","0357fbe8":"**Visualizing categorical features**","98fa55f7":"**Outlier Detection**","aa52f41e":"Checking number of unique elements in features","305b3988":"**Linear SVC**","6aa839b5":"**Encoding categoric features** ","e7aa7c34":"Arrival_Delay_in_Minutes and Departure_Delay_in_Minutes columns are highly positive correlated. Correlated features will be checked again with heatmap.","95ef70f3":"We use Feature Scaling to standardize the independent features in a fixed range so each feature contributes approximately to model. Due to my distribution, I can not use Standard Scaler. I use MinMax Scaler which transforms data range to (0,1).","21fb3810":"**Checking correlation to target**","50a9701e":"Checking Normality of transformed features","8fe0dd91":"**Ensemble Learning - Random Forest**","4b59a267":"**Visualizing numeric features**","e53635ca":"Business class passengers making business travel have the highest satisfaction rate (33.0%). Eco class passengers who make personal travel have the highest dissatisfaction rate (22.8%). We can say that travel type and class are both major factors in satisfaction.","7b07e6c8":"When we compare the scores given to the service based on gender and customer type, we see a similar distribution. Since the number of loyal customers is high in data, their ratio seems to be higher. Gender is not a discriminative factor in scores.","338dc803":"**Ensemble Learning - AdaBoost**","2447bd59":"Checking unique values of target column","42676cd0":"**Checking correlation between features by creating a heatmap**","97521edf":"**Dropping unnecessary columns**","d2df9172":"Let's visualize categorical features by count plot. First comparing their numbers, then comparing their amount with respect to the target column (satisfaction).","2904d06d":"Dividing age column to four groups by looking at the quartiles to check if any pattern will be seen in different groups","9ffec5e8":"There are two data available, train and test. I will check the first few rows and the column names of this data. For convenience, I will combine two data and continue my operations with a single data.","7607130f":"**Logistic Regression**","aa323f15":"The features with the highest average satisfaction rate are Inflight_service and Baggage_handling with average 3.6. The feature with the lowest satisfaction rate is Inflight_wifi_service with average 2.7.","a330534c":"When we look at the flights that do not delay on arrival and departure, the number of satisfied passenger still seems less.","5238e6d4":"We have to transform our categoric features to numerics so our model can understand better and learn from the features.","ffbb2159":"Splitting data into train and test with 0.7 train\/0.3 test ratio so i can train my model with train data, and then test its performance with test data.","e2b808a4":"We can see that Business Class passengers give higher ratings to services than Eco Class passengers.","ec333362":">For the Age column, we can see that the youngest passenger is 7 years old and the oldest passenger is 85 years old. Average age is 39. When we evaluate the quarters, we can observe that the age is evenly distributed.\n\n>For the Flight Distance column, we see that the minimum value is 414 and the maximum value is 4983. The average distance of flight is 1190. When we look at the quarters, we can say that there are outliers because there is too much difference between the 3rd quarter and the maximum value.\n\n>For the Departure Delay in Minutes and Arrival Delay in Minutes columns, the minimum value is 0 (which corresponds to no delay in that flights) and the maximum value is around 1500. When we examine the 3rd quarter and maximum values, we can see that there are too many outlier values. \n\n>There are many categorical features evaluated in 0-1-2-3-4-5 degrees. If we look at the averages of these ratings, the highest level of satisfaction is the Inflight service category with an average of 3.64, while the lowest is the Inflight wifi service category with an average of 2.72 points.","d476d928":"While the majority of passengers between the ages of [40,51) are satisfied, the rate of dissatisfaction is higher for passengers in other age ranges.","e705d005":"As we saw in the confusion matrix, the model predicted most of the data correctly. If we look at the wrong guesses,\n\n* Model guessed 395 of those who were actually 'neutral or dissatifisfied' wrong and said 'satisfied'. Their rate is 1.03% of the total data. \n* Model guessed 1023 of those who were actually 'satisfied' wrong and said 'neutral or dissatisfied'. Their rate is 2.66% of the total data.","5b42ca6d":"<h2>MODEL RESULTS<\/h2>"}}