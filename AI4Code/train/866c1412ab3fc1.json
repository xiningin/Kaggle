{"cell_type":{"e897e501":"code","0f67d2a0":"code","51d82df8":"code","a56cd25a":"code","49b0fc6c":"code","c5f836e1":"code","26701571":"code","2bc7cc06":"code","43b95e63":"code","835f6a70":"code","358f4dec":"code","fea8deaa":"code","5797eb4b":"code","03cad427":"code","675d652a":"code","f5ad3f64":"code","7c71e31f":"code","eb8d2137":"code","020187e2":"code","12c0c33d":"code","780a3039":"code","cd16b7f1":"code","c7d97884":"code","88cc267a":"code","0c641d19":"code","1003bf80":"code","7097d70e":"code","d8f7970f":"code","c3ed9be2":"code","e667295a":"code","cf729832":"code","41f9a4b2":"code","51f95c12":"code","93870790":"code","d0f04911":"code","a8e92097":"code","a4ec1ec3":"code","90cc2e3f":"code","d5005f50":"code","9536da66":"code","d201b044":"code","0d1784c7":"code","ae266cdb":"code","6a4090c0":"code","e162e7a1":"code","834f6d77":"code","22569ad3":"code","d12d95b8":"code","fc67df04":"code","3cea52cf":"code","24c2e088":"code","3141550b":"code","7892137c":"code","c66b4d69":"code","9f44d5aa":"code","b3688650":"code","7734ca22":"code","1a5be51f":"code","ace854d6":"code","dfaf1783":"code","31151c20":"code","eef86bc5":"code","a773c27b":"code","b0deee30":"code","355ca900":"code","3a4a771e":"code","2e250239":"code","0abf4e01":"code","32c611b2":"code","46323a1a":"code","29ffa69b":"code","c4a32aa3":"code","0b7513b0":"code","7d0d41ab":"code","20fb3a7b":"code","a5bbd1d0":"code","1b7020d8":"code","c89d7a24":"code","2bde4c29":"code","7c6874a0":"code","15640ca8":"code","0841c754":"code","dd9f6c8f":"code","0b2371a5":"code","b2134806":"code","16516d81":"code","d2ae1a4f":"code","e210c811":"code","63454613":"code","166cc371":"code","5170ff17":"code","40512cf6":"code","78eccf6d":"code","e8d6d0d8":"markdown","b73f7e5c":"markdown","4e82afae":"markdown","5f954b97":"markdown","11d57b61":"markdown","e46d2f73":"markdown","e7cd1de7":"markdown","578abf4d":"markdown","be40bc57":"markdown","b03b8f29":"markdown","e5730c5e":"markdown","139977d5":"markdown","80b9cbe4":"markdown","77f643e0":"markdown","c11d34cf":"markdown","058b9870":"markdown","e951a219":"markdown","5a628a1d":"markdown","caf814a7":"markdown","02b1edd4":"markdown","10bbcb64":"markdown","d3c75402":"markdown","2a0ffe56":"markdown","a2bcff2e":"markdown","7d77bdea":"markdown","03b180e4":"markdown","a16fe439":"markdown","bce8830e":"markdown","b0fb2590":"markdown","408c5ac9":"markdown","cd3cac87":"markdown","2860c232":"markdown","0f611054":"markdown","714d58a9":"markdown","1b657098":"markdown","6460af6e":"markdown","94ae4744":"markdown","dd2e5892":"markdown","f07279c7":"markdown","1fff8f59":"markdown","381f430e":"markdown","ba3df1d8":"markdown","493b492e":"markdown","49c94c5a":"markdown","9df251b8":"markdown","67cbdf2a":"markdown","4768dc8c":"markdown","4688f408":"markdown","4f756b7c":"markdown","eaa532d3":"markdown","7e675758":"markdown","fc4ae72e":"markdown","e5546431":"markdown","b6322f81":"markdown","45b54294":"markdown","b715e8bf":"markdown","82892fc7":"markdown","d6b233a1":"markdown","ba7be44e":"markdown","30ade933":"markdown","0a790cbd":"markdown","9f672a53":"markdown","7013a3d5":"markdown","129a68e9":"markdown","bbbb7d24":"markdown","facfb7dc":"markdown","1749c851":"markdown","4f3eeab9":"markdown"},"source":{"e897e501":"# Standard modules\nimport numpy as np\nimport pandas as pd\n\n# Missing Analysis & Pre-processing\nfrom sklearn.preprocessing import StandardScaler\nimport missingno as msno\n\n# Missing imputation\nfrom sklearn.experimental import enable_iterative_imputer \nfrom sklearn.impute import IterativeImputer as MICE\n\n# Model development\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Graphical modules\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Display module (show all dataset)\npd.options.display.max_columns = None\npd.options.display.max_rows = None\nfrom IPython.display import display","0f67d2a0":"# Importing raw dataset\ndataset_raw = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')","51d82df8":"# Drop unused columns\ndataset_raw.drop('Patient ID', axis=1, inplace=True)","a56cd25a":"# Change column names: uppercase become lowercase and '_' becomes ' '\nnew_columns = list()\n# Loop over all columns\nfor col in dataset_raw.columns:\n    new_columns.append(col.lower().replace(' ','_'))\n# Modify dataset columns\ndataset_raw.columns = new_columns","49b0fc6c":"# List to keep all categorical feature\ncat_vars = list()\n# Loop to evaluate if it's categorical\nfor j in dataset_raw.columns:\n    if len(dataset_raw[j].unique()) <= 5:\n        cat_vars.append(j)\n        print('Discrete variable - ',j)\nprint('This dataset have ',len(cat_vars), 'of ', len(dataset_raw.columns),' discrete variables with 5 or less categories.')","c5f836e1":"# Print categories for 'patient_age_quantile'\ndataset_raw['patient_age_quantile'].unique()","26701571":"# Eval categories for all discrete features\nfor c in cat_vars:\n    print(c, ' - ', dataset_raw[c].unique())","2bc7cc06":"# Conclusion 1, 2, 3 and 5 - Dropp columns\ncategorical_features_to_drop = ['mycoplasma_pneumoniae', 'd-dimer', 'partial_thromboplastin_time\\xa0(ptt)\\xa0','prothrombin_time_(pt),_activity', 'urine_-_sugar', 'urine_-_yeasts',\n                                'urine_-_granular_cylinders', 'urine_-_hyaline_cylinders', 'myeloblasts', 'fio2_(venous_blood_gas_analysis)', 'urine_-_esterase','parainfluenza_2',\n                                'urine_-_bile_pigments', 'urine_-_ketone_bodies', 'urine_-_protein', 'urine_-_urobilinogen', 'urine_-_nitrite']\ndataset_raw.drop(categorical_features_to_drop, axis=1, inplace=True)","43b95e63":"# Conclusion 4 - Input NaN for some columns in place of not_done\ndataset_raw['strepto_a'].replace('not_done',np.NaN, inplace=True)\ndataset_raw['urine_-_hemoglobin'].replace('not_done',np.NaN, inplace=True)","835f6a70":"# Verify discrete features columns after drop process\ncat_vars = list()\nfor j in dataset_raw.columns:\n    if len(dataset_raw[j].unique()) <= 5:\n        cat_vars.append(j)\n        print('Discrete variable - ',j)\nprint('This dataset have ',len(cat_vars), 'of ', len(dataset_raw.columns),' discrete variables with 5 or less categories.\\n\\n')\n\n# Verify discrete classes for each discrete var\nfor c in cat_vars:\n    print(c, ' - ', dataset_raw[c].unique())","358f4dec":"# Verify psedo discrete variables\nfor i in ['promyelocytes', 'myelocytes', 'metamyelocytes', 'vitamin_b12']:\n    print(i, ' - ', 100*round(dataset_raw[i].isna().sum()\/len(dataset_raw),3), ' % of missing, having ',len(dataset_raw)-dataset_raw[i].isna().sum(),' complete rows.')","fea8deaa":"dataset_raw.drop(['promyelocytes', 'myelocytes', 'metamyelocytes', 'vitamin_b12'], axis=1, inplace=True)","5797eb4b":"# How many nan have each column\nnan_per_column = pd.DataFrame(dataset_raw.isna().sum(),columns=['nanValues']).reset_index()\n\n# Calculate NaN % for each feature\nfor i in range(0,len(nan_per_column)):\n    nan_per_column.loc[i, 'nanValuesPct'] = 100*round(nan_per_column.loc[i, 'nanValues']\/len(dataset_raw),3)","03cad427":"# Plot - % of missing rows for each column\nplt.figure(figsize=(30,15))\nsns.barplot(x=\"index\", y=\"nanValuesPct\", data=nan_per_column)\nplt.xlabel('Variables', fontsize=20)\nplt.ylabel('Missing %', fontsize=20)\nplt.title('Missing Data Plot', fontsize=30)\nplt.yticks([0,10,20,30,40,50,60,70,80,90,100])\nplt.xticks(rotation=90);","675d652a":"len(dataset_raw.dropna(how='any'))","f5ad3f64":"# Print missing pct per column uniques\nprint(np.unique(nan_per_column['nanValuesPct']))","7c71e31f":"# conters\nt1 = 0\nt2 = 0\nt3 = 0\n\nfor i in range(0,len(nan_per_column)):\n    if nan_per_column.loc[i, 'nanValuesPct'] <= 76:\n        t1 += 1\n    elif nan_per_column.loc[i, 'nanValuesPct'] > 76 and nan_per_column.loc[i, 'nanValuesPct'] < 90.9:\n        t2 += 1\n    elif nan_per_column.loc[i, 'nanValuesPct'] >= 90.9:\n        t3 += 1\nprint('If I keep respectively based in T1, T1+T2, T3 and without threshold: ',t1,t1+t2,t3,t1+t2+t3)","eb8d2137":"# threshold proposed for features, keep in mind that this dataset have 4 target values\nrows_50_threshold = int((len(dataset_raw.columns)-4)\/2)\n\n# Eval row limit\nprint('50% of a sample in this dataset is: ', rows_50_threshold)","020187e2":"# Before removing\nrc = 0\npossible_rows = list()\nfor i in range(0, len(dataset_raw)):\n    if dataset_raw.iloc[i].isnull().sum() >= rows_50_threshold:\n        rc += 1\n    else:\n        possible_rows.append(i)\nprint('Of ', len(dataset_raw), ' total rows, I have ', rc,' rows with more than 50% of missing data, giving a ', len(dataset_raw)-rc,' rows that follows the recommendation for imputation\\n')\n\n# Number of columns with at least 10% of missing data to impute (being generous)\ndf_aux = dataset_raw.loc[possible_rows]\nmiss_less_10 = 0\nfor c in dataset_raw.columns:\n    if (df_aux[c].isna().sum()\/len(possible_rows)) == 0.0:\n        pass\n    elif (df_aux[c].isna().sum()\/len(possible_rows)) < 0.10:\n        miss_less_10 += 1\n        print(c, 'with ',df_aux[c].isna().sum(),' of missing data could be imputed')\n\n# Case proportions\nprint('\\n\\nPositive samples: ', sum(df_aux['sars-cov-2_exam_result'] == 'positive'),' and Negative samples:', sum(df_aux['sars-cov-2_exam_result'] == 'negative'), \n      ' - proportion [%]: ', round(100*sum(df_aux['sars-cov-2_exam_result'] == 'positive')\/len(df_aux),2))","12c0c33d":"# Possible variables to keep\ncols_to_keep = list()\nfor i in range(0,len(nan_per_column)):\n    if nan_per_column.loc[i, 'nanValuesPct'] < 90.9:\n        cols_to_keep.append(nan_per_column.loc[i,'index'])\n# Print how many variables I will keep  \nprint('Filter 1 - columns: ', len(cols_to_keep))","780a3039":"\n# Creating a aux dataframe with filtered columns, keeping control over raw dataset\ndf_aux = dataset_raw[cols_to_keep]\n# Eval limit\nrows_50_threshold = int((len(df_aux.columns)-4)\/2)\nprint('50% of a sample in this dataset is: ', rows_50_threshold)","cd16b7f1":"# Threshold T1 + T2 applying...\nrc = 0\npossible_rows = list()\nfor i in range(0, len(df_aux)):\n    if df_aux.iloc[i].isnull().sum() >= rows_50_threshold:\n        rc += 1\n    else:\n        possible_rows.append(i)\nprint('Of ', len(df_aux), ' total rows, I have ', rc,' rows with more than 50% of missing data, giving a ', len(df_aux)-rc,' rows that follows the recommendation for imputation\\n')\n# Number of columns with at least 10% of missing data to impute (being generous)\ndf_aux = df_aux.loc[possible_rows]\nmiss_less_15 = 0\nfor c in df_aux.columns:\n    if (df_aux[c].isna().sum()\/len(possible_rows)) == 0.0:\n        pass\n    elif (df_aux[c].isna().sum()\/len(possible_rows)) < 0.10:\n        miss_less_15 += 1\n        print(c, 'with ',df_aux[c].isna().sum(),' of missing data could be imputed')\n# Case proportions\nprint('\\n\\nPositive samples: ', sum(df_aux['sars-cov-2_exam_result'] == 'positive'),' and Negative samples:', sum(df_aux['sars-cov-2_exam_result'] == 'negative'), \n      ' - proportion: ', round(100*sum(df_aux['sars-cov-2_exam_result'] == 'positive')\/len(df_aux),2))","c7d97884":"# Renaming df\ndataset = df_aux\ndataset.index = range(0,len(dataset))","88cc267a":"# Counter\nrc = 0\n# Loop to verify complete rows\nfor i in range(0, len(dataset)):\n    if dataset.iloc[i].isnull().sum() == 0.0:\n        rc += 1\nprint('complete rows: ', rc)","0c641d19":"# Verify categorical columns after dropping\ncat_vars = list()\nfor j in dataset.columns:\n    if len(dataset[j].unique()) <= 5:\n        cat_vars.append(j)\nprint('This dataset have now',len(cat_vars), ' categorical variables of ',len(dataset),'\\n')\n\nfor c in cat_vars:\n    print(c, ' - ', dataset[c].unique())","1003bf80":"dataset.drop('bordetella_pertussis', axis=1, inplace=True)","7097d70e":"# Verify categorical columns after dropping\ncat_vars = list()\nfor j in dataset.columns:\n    if len(dataset[j].unique()) <= 5:\n        cat_vars.append(j)","d8f7970f":"# Changing string values to \nfor j in cat_vars:\n    if 'positive' in list(dataset[j].unique()):\n        dataset[j].replace('positive',1, inplace=True)\n    elif 'detected' in list(dataset[j].unique()):\n        dataset[j].replace('detected',1, inplace=True)\n    if 'negative' in list(dataset[j].unique()):\n        dataset[j].replace('negative',0, inplace=True) \n    elif 'not_detected' in list(dataset[j].unique()):\n        dataset[j].replace('not_detected',0, inplace=True)","c3ed9be2":"# Verify categorical columns after dropping\ncat_vars = list()\nfor j in dataset.columns:\n    if len(dataset[j].unique()) <= 5:\n        cat_vars.append(j)\nprint('This dataset have now',len(cat_vars), ' categorical variables of ',len(dataset),'\\n')\n\n# Print results\nfor c in cat_vars:\n    print(c, ' - ', dataset[c].unique())","e667295a":"# If a value is\nfor i in range(0, len(dataset)):\n    if pd.isna(dataset.loc[i, 'influenza_a,_rapid_test']) is False and pd.isna(dataset.loc[i, 'influenza_a']) is False:\n        if dataset.loc[i, 'influenza_a,_rapid_test'] != dataset.loc[i, 'influenza_a']:\n            print(i, 'sample have different for influenza A: ',dataset.loc[i, 'influenza_a'],' and test A: ', dataset.loc[i, 'influenza_a,_rapid_test'])\n    if pd.isna(dataset.loc[i, 'influenza_b,_rapid_test']) is False and pd.isna(dataset.loc[i, 'influenza_b']) is False:    \n        if dataset.loc[i, 'influenza_b,_rapid_test'] != dataset.loc[i, 'influenza_b']:\n            print(i, 'sample have different for influenza B: ',dataset.loc[i, 'influenza_b'],' and test B: ', dataset.loc[i, 'influenza_b,_rapid_test'])\n    ","cf729832":"# Dropping rapid test columns\ndataset.drop(['influenza_a,_rapid_test', 'influenza_b,_rapid_test'], axis=1, inplace=True)","41f9a4b2":"# Defining lists for each family column\ndetection_adenoviridae = ['adenovirus']\ndetection_coronaviridae = ['coronavirusoc43', 'coronavirus_hku1', 'coronavirusnl63', 'coronavirus229e']\ndetection_orthomyxoviridae = ['influenza_a', 'influenza_b', 'inf_a_h1n1_2009'] \ndetection_paramyxoviridae = ['parainfluenza_1', 'parainfluenza_3', 'parainfluenza_4']\ndetection_picornaviridae = ['rhinovirus\/enterovirus']\ndetection_pneumoviridae = ['respiratory_syncytial_virus', 'metapneumovirus']\ngroups_list = [detection_adenoviridae, detection_coronaviridae, detection_orthomyxoviridae, detection_paramyxoviridae, detection_picornaviridae, detection_pneumoviridae]\ngroups_cols = ['detection_adenoviridae', 'detection_coronaviridae', 'detection_orthomyxoviridae', 'detection_paramyxoviridae', 'detection_picornaviridae', 'detection_pneumoviridae']\n\n# Create the new columns \nfor family_group,family_col in zip(groups_list, groups_cols):\n    for i in range(0, len(dataset)):\n        for j in family_group:\n            if pd.isna(dataset.loc[i, j]) is False: # If it's nan can crash the comparison\n                if dataset.loc[i, j] == 1: # I need only one column to say if will be a 1 (family detection)\n                    dataset.loc[i,family_col] = 1\n                    break\n                else:\n                    dataset.loc[i,family_col] = 0","51f95c12":"# Dropping old species columns\ndrop_species_cols = detection_adenoviridae + detection_coronaviridae + detection_orthomyxoviridae + detection_paramyxoviridae + detection_picornaviridae + detection_pneumoviridae\ndataset.drop(drop_species_cols, inplace=True, axis=1)","93870790":"# Verify if new columns are statical features\ncat_vars = list()\nfor j in dataset.columns:\n    if len(dataset[j].unique()) <= 5:\n        print(j, ' - ', dataset[j].unique())\n        cat_vars.append(j)\nprint('This dataset have now',len(cat_vars), ' discrete variables of ',len(dataset),'\\n')","d0f04911":"# Num features\nnum_features = ['hematocrit',\n                'hemoglobin',\n                'platelets',\n                'mean_platelet_volume_',\n                'red_blood_cells',\n                'lymphocytes',\n                'mean_corpuscular_hemoglobin_concentration\\xa0(mchc)',\n                'leukocytes',\n                'basophils',\n                'mean_corpuscular_hemoglobin_(mch)',\n                'eosinophils',\n                'mean_corpuscular_volume_(mcv)',\n                'monocytes',\n                'red_blood_cell_distribution_width_(rdw)']\n# scaler object\nscaler = StandardScaler()\ndataset[num_features] = scaler.fit_transform(dataset[num_features])","a8e92097":"# Eval missing value for each column again\nnan_per_column = pd.DataFrame(dataset.isna().sum(),columns=['nanValues']).reset_index()\n\n# Calculate NaN %\nfor i in range(0,len(nan_per_column)):\n    nan_per_column.loc[i, 'nanValuesPct'] = 100*round(nan_per_column.loc[i, 'nanValues']\/len(dataset),3)\n    \n# Plot - % of missing rows for each column\nplt.figure(figsize=(20,10))\nsns.barplot(x=\"index\", y=\"nanValuesPct\", data=nan_per_column)\nplt.xlabel('Variables', fontsize=20)\nplt.ylabel('Missing %', fontsize=20)\nplt.title('Missing Data Plot after a cleaning phase', fontsize=30)\nplt.yticks([0,10,20,30,40,50,60,70,80,90,100])\nplt.xticks(rotation=90);","a4ec1ec3":"# Drop any NaN sample, creating a copy of my dataset\ndataset_complete = dataset.dropna(how='any').copy()\ndataset_complete.index = range(0, len(dataset_complete.index))\n\n# Show number of rows\nprint('Complete rows: ', len(dataset_complete), '| Keeped % rows:',100*round(len(dataset_complete)\/len(dataset),2))","90cc2e3f":"print('Positive cases: ', sum(dataset_complete['sars-cov-2_exam_result'] == 1),' | Negative cases: ', sum(dataset_complete['sars-cov-2_exam_result'] == 0),'\\n###')\nprint('Previous Positive cases: ', sum(dataset['sars-cov-2_exam_result'] == 1), ' | Keeped % for Positive cases: ',\n      100*round(sum(dataset_complete['sars-cov-2_exam_result'] == 1)\/sum(dataset['sars-cov-2_exam_result'] == 1), 2))","d5005f50":"# Nullity Matrix\nmsno.matrix(dataset, sort='ascending', figsize=(15, 10));","9536da66":"# Heatmap plot\nmsno.heatmap(dataset);","d201b044":"# Create a copy of my original dataset\ndataset_impute = dataset.copy()","0d1784c7":"# Apply MICE\ndataset_impute_complete = MICE(max_iter=150, verbose=1, random_state=1206).fit_transform(dataset_impute.values)\n\n# Turning into df again\ndataset_impute = pd.DataFrame(data=dataset_impute_complete, columns=dataset_impute.columns, index=dataset_impute.index)","ae266cdb":"# Create a copy of choice dataset\ndataset_choice = dataset_impute.copy()","6a4090c0":"# Data Task 1\ndataset_task1 = dataset_choice.drop(['patient_addmited_to_semi-intensive_unit_(1=yes,_0=no)',\n                                       'patient_addmited_to_intensive_care_unit_(1=yes,_0=no)',\n                                       'patient_addmited_to_regular_ward_(1=yes,_0=no)'], axis=1)\n# Data Task 2\ndataset_task2 = dataset_choice.drop(['sars-cov-2_exam_result'], axis=1)","e162e7a1":"# Create a new unique target column for Task 2\ntargets_task2 = ['patient_addmited_to_regular_ward_(1=yes,_0=no)',\n                 'patient_addmited_to_semi-intensive_unit_(1=yes,_0=no)',\n                 'patient_addmited_to_intensive_care_unit_(1=yes,_0=no)']\n\n## Evaluate the number of possibilities for three targets in a single column\npatient_addmited_possibilities = list()\nfor i in range(0, len(dataset_task2)):\n    possibility=str(int(dataset_task2.loc[i,targets_task2[0]])) + str(int(dataset_task2.loc[i,targets_task2[1]])) + str(int(dataset_task2.loc[i,targets_task2[2]]))\n    patient_addmited_possibilities.append(possibility)\n\n## Print result\nprint(sorted(set(patient_addmited_possibilities)))","834f6d77":"## Create the new column\ndataset_task2['patient_addmited_cats'] = patient_addmited_possibilities\n\n## Change the new column to num values\nfor i in range(0, len(dataset_task2)):\n    if dataset_task2.loc[i, 'patient_addmited_cats'] == '000':\n        dataset_task2.loc[i, 'patient_addmited_cats'] = 0\n    elif dataset_task2.loc[i, 'patient_addmited_cats'] == '100':\n        dataset_task2.loc[i, 'patient_addmited_cats'] = 1\n    elif dataset_task2.loc[i, 'patient_addmited_cats'] == '010':\n        dataset_task2.loc[i, 'patient_addmited_cats'] = 2\n    elif dataset_task2.loc[i, 'patient_addmited_cats'] == '001':\n        dataset_task2.loc[i, 'patient_addmited_cats'] = 3\n## See class distribution\ndataset_task2['patient_addmited_cats'].value_counts()","22569ad3":"# Drop residual cols in task 2 dataset\ndataset_task2.drop(targets_task2, axis=1, inplace=True)","d12d95b8":"# Create list of feature columns for each dataset\nfeatures = list(dataset_task1.drop(['sars-cov-2_exam_result'], axis=1).columns)","fc67df04":"# Separate numerical columns from cat columns to help some plots\nnum_features = ['hematocrit',\n                'hemoglobin',\n                'platelets',\n                'mean_platelet_volume_',\n                'red_blood_cells',\n                'lymphocytes',\n                'mean_corpuscular_hemoglobin_concentration\\xa0(mchc)',\n                'leukocytes',\n                'basophils',\n                'mean_corpuscular_hemoglobin_(mch)',\n                'eosinophils',\n                'mean_corpuscular_volume_(mcv)',\n                'monocytes',\n                'red_blood_cell_distribution_width_(rdw)']\n\ncat_features = ['patient_age_quantile',\n                'chlamydophila_pneumoniae',\n                'detection_adenoviridae',\n                'detection_coronaviridae',\n                'detection_orthomyxoviridae',\n                'detection_paramyxoviridae',\n                'detection_picornaviridae',\n                'detection_pneumoviridae']","3cea52cf":"# Eval 'sars-cov-2_exam_result' proportions\nprint('Positive case proportion - original dataset [%]: ', round(100*dataset_raw['sars-cov-2_exam_result'].value_counts()[1]\/dataset_raw['sars-cov-2_exam_result'].value_counts().sum(),2))\nprint('Positive case proportion - complete dataset [%]: ', round(100*dataset_complete['sars-cov-2_exam_result'].value_counts()[1]\/dataset_complete['sars-cov-2_exam_result'].value_counts().sum(),2))","24c2e088":"sns.pairplot(dataset_task1[['sars-cov-2_exam_result']+num_features], hue='sars-cov-2_exam_result');","3141550b":"# Correlation calculation\nspearman_corr = dataset_task1[num_features].corr('spearman')\n# Plot\nplt.figure(figsize=(20,10))\nsns.heatmap(spearman_corr, annot = True);","7892137c":"# Atualize both datasets\ndataset_task1.drop(['hematocrit'], axis=1, inplace=True)\ndataset_task2.drop(['hematocrit'], axis=1, inplace=True)","c66b4d69":"# Update features columns\nfeatures = list(set(features).difference(set(['hematocrit'])))\nnum_features = list(set(num_features).difference(set(['hematocrit'])))","9f44d5aa":"print('For both tasks I have ',len(features),' features.')","b3688650":"# PLOT - Barplots over our variables\nfig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20,15))\nr = 0 # Index row\nc = 0 # Index col\nfor f in cat_features:\n    # Count Plot\n    sns.countplot(x=f, hue='sars-cov-2_exam_result', data=dataset_task1,ax=axes[r][c])\n    # Plot configs\n    axes[r][c].legend(title='sars-cov-2_exam_result', loc='upper right')\n    # Index control\n    c += 1\n    if c > 1:\n        c = 0\n        r += 1\n\nplt.tight_layout()","7734ca22":"dataset_task1['detection_adenoviridae'].value_counts()","1a5be51f":"dataset_task1['chlamydophila_pneumoniae'].value_counts()","ace854d6":"dataset_task1.drop(['chlamydophila_pneumoniae', 'detection_adenoviridae'], axis=1, inplace=True)","dfaf1783":"# PLOT - Barplots over our variables\nfig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20,15))\nr = 0 # Index row\nc = 0 # Index col\nfor f in cat_features:\n    # Count Plot\n    sns.countplot(x=f, hue='patient_addmited_cats', data=dataset_task2,ax=axes[r][c])\n    # Plot configs\n    axes[r][c].legend(title='patient_addmited_cats', loc='upper right')\n    # Index control\n    c += 1\n    if c > 1:\n        c = 0\n        r += 1\n\nplt.tight_layout()","31151c20":"dataset_task2.drop(['chlamydophila_pneumoniae', 'detection_adenoviridae'], axis=1, inplace=True)","eef86bc5":"# Update cat features\ncat_features = list(set(cat_features).difference(set(['chlamydophila_pneumoniae', 'detection_adenoviridae'])))","a773c27b":"# update total features\nfeatures = num_features + cat_features","b0deee30":"# targets\ntarget1 = 'sars-cov-2_exam_result'\ntarget2 = 'patient_addmited_cats'","355ca900":"cat_features","3a4a771e":"num_features","2e250239":"# Print features for models\nprint('Features Num - ',len(num_features), ' | Features Cat - ', len(cat_features), ' | Total - ', len(cat_features)+len(num_features))","0abf4e01":"# TTSplit\nx_train, x_test, y_train, y_test = train_test_split(dataset_task1[num_features], dataset_task1[target1], test_size = 0.20, random_state = 1206, stratify=dataset_task1[target1])","32c611b2":"print(len(x_train))","46323a1a":"# create smote object\nsmt = SMOTE(k_neighbors=5, random_state=1206)\n\n# Do the process\nx_train, y_train = smt.fit_sample(x_train, y_train)","29ffa69b":"print(len(x_train))","c4a32aa3":"# Defining parameter range to grid search\nparam_gridSVM = {'C': [0.1, 1, 10, 100, 1000],\n                 'shrinking':[True, False],\n                 'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001, 0.0001], \n                 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}  \n\n# Best result found after grid search! This trick is to improve commit speed\nparam_gridSVM = {'C': [10], 'gamma': [0.1], 'kernel': ['rbf'], 'shrinking': [True]}\n\n# Define grid instance\ngridSVM = GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', random_state=101), param_grid=param_gridSVM, refit = True, verbose = 1, scoring='balanced_accuracy', n_jobs=3) \n\n# Initialize grid search, fitting the best model\ngridSVM.fit(x_train, y_train);","0b7513b0":"# print best parameter after tuning svm\nprint(gridSVM.best_params_)","7d0d41ab":"# print how our best model looks after hyper-parameter tuning \nprint(gridSVM.best_estimator_) ","20fb3a7b":"# Make predictions over test set\ny_pred_svm = gridSVM.predict(x_test)","a5bbd1d0":"# print classification report SVM\nprint(classification_report(y_test, y_pred_svm))","1b7020d8":"# Confusion Matrix SVM\n## original binary labels\nlabels = np.unique(y_test)\n## DF with C.M.\ncm = pd.DataFrame(confusion_matrix(y_test, y_pred_svm, labels=labels), index=labels, columns=labels)\n# Visualize labels\ncm.index = ['real: 0', 'real: 1']\ncm.columns = ['pred: 0', 'pred: 1']\n\n# CM visualization\ncm","c89d7a24":"# TTSplit\nx_train, x_test, y_train, y_test = train_test_split(dataset_task1[features], dataset_task1[target1], test_size = 0.20, random_state = 1206, stratify=dataset_task1[target1])\n\n# Create smote object\nsmt = SMOTE(k_neighbors=5, random_state=1206)\n\n# Do the process\nx_train, y_train = smt.fit_sample(x_train, y_train)\n\n# Defining parameter range to grid search\nparam_gridSVM = {'C': [0.1, 1, 10, 100, 1000],\n                 'shrinking':[True, False],\n                 'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001, 0.0001], \n                 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}  \n\n# Best result found after grid search! This trick is to improve commit speed\nparam_gridSVM = {'C': [10], 'gamma': [0.1], 'kernel': ['rbf'], 'shrinking': [True]}\n\n# Define grid instance\ngridSVM = GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', random_state=101), param_grid=param_gridSVM, refit = True, verbose = 1, scoring='balanced_accuracy', n_jobs=3) \n\n# Initialize grid search, fitting the best model\ngridSVM.fit(x_train, y_train);","2bde4c29":"# print best parameter after tuning svm\nprint(gridSVM.best_params_)","7c6874a0":"# Make predictions over test set\ny_pred_svm = gridSVM.predict(x_test)\n\n# print classification report SVM\nprint(classification_report(y_test, y_pred_svm))","15640ca8":"# Confusion Matrix SVM\n## original binary labels\nlabels = np.unique(y_test)\n## DF with C.M.\ncm = pd.DataFrame(confusion_matrix(y_test, y_pred_svm, labels=labels), index=labels, columns=labels)\n# Visualize labels\ncm.index = ['real: 0', 'real: 1']\ncm.columns = ['pred: 0', 'pred: 1']\n\n# CM visualization\ncm","0841c754":"# ttsplit\nx_train, x_test, y_train, y_test = train_test_split(dataset_task2[num_features], dataset_task2[target2], test_size = 0.20, random_state = 1206, stratify=dataset_task2[target2])","dd9f6c8f":"# create smote object\nsmt = SMOTE(k_neighbors=5, random_state=1206)\n\n# Do the process\nx_train, y_train = smt.fit_sample(x_train, y_train)","0b2371a5":"# Defining parameter range to grid search\nparam_gridSVM = {'C': [0.1, 1, 10, 100, 1000], \n                'shrinking':[True, False],\n                 'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001, 0.0001], \n                 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} \n\n# Best result found after grid search! This trick is to improve commit speed\nparam_gridSVM = {'C': [100], 'gamma': ['scale'], 'kernel': ['rbf'], 'shrinking': [True]}\n\n# Define grid instance\ngridSVM = GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', random_state=101), param_grid=param_gridSVM, refit = True, verbose = 1, scoring='balanced_accuracy', n_jobs=3) \n\n# Initialize grid search, fitting the best model\ngridSVM.fit(x_train, y_train)","b2134806":"# print best parameter after tuning \nprint(gridSVM.best_params_)","16516d81":"# print how our best model looks after hyper-parameter tuning \nprint(gridSVM.best_estimator_) ","d2ae1a4f":"# Make predictions over test set for both models\ny_pred_svm = gridSVM.predict(x_test)","e210c811":"# print classification report SVM\nprint(classification_report(y_test, y_pred_svm))","63454613":"# Confusion Matrix SVM\n## original binary labels\nlabels = np.unique(y_test)\n## DF with C.M.\ncm = pd.DataFrame(confusion_matrix(y_test, y_pred_svm, labels=labels), index=labels, columns=labels)\n\n# CM visualization\ncm","166cc371":"# TTSplit\nx_train, x_test, y_train, y_test = train_test_split(dataset_task2[features], dataset_task2[target2], test_size = 0.20, random_state = 1206, stratify=dataset_task2[target2])\n\n# Create smote object\nsmt = SMOTE(k_neighbors=5, random_state=1206)\n\n# Do the process\nx_train, y_train = smt.fit_sample(x_train, y_train)\n\n# Defining parameter range to grid search\nparam_gridSVM = {'C': [0.1, 1, 10, 100, 1000],\n                 'shrinking':[True, False],\n                 'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001, 0.0001], \n                 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}  \n\n# Best result found after grid search! This trick is to improve commit speed\nparam_gridSVM = {'C': [100], 'gamma': [0.1], 'kernel': ['rbf'], 'shrinking': [True]}\n\n# Define grid instance\ngridSVM = GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', random_state=101), param_grid=param_gridSVM, refit = True, verbose = 1, scoring='balanced_accuracy', n_jobs=3) \n\n# Initialize grid search, fitting the best model\ngridSVM.fit(x_train, y_train);","5170ff17":"# print best parameter after tuning svm\nprint(gridSVM.best_params_)","40512cf6":"# Make predictions over test set\ny_pred_svm = gridSVM.predict(x_test)\n\n# print classification report SVM\nprint(classification_report(y_test, y_pred_svm))","78eccf6d":"# Confusion Matrix SVM\n## original binary labels\nlabels = np.unique(y_test)\n## DF with C.M.\ncm = pd.DataFrame(confusion_matrix(y_test, y_pred_svm, labels=labels), index=labels, columns=labels)\n\n# CM visualization\ncm","e8d6d0d8":"Based in those answers, I will remove both categorical features for task 1 dataset.","b73f7e5c":"Based in [reference 7](http:\/\/terra-datasystems.com\/missing-data-analysis.html) and [reference 8](https:\/\/www.kaggle.com\/drewheasman\/missingness-analysis), both from the same author, and [reference 9](https:\/\/s3.amazonaws.com\/assets.datacamp.com\/production\/course_17404\/slides\/chapter2.pdf) This result shows that my dataset is definitely **not** a MCAR missing type given the lack of missing randomness.\n\nThe heatmap plot increase this answer:","4e82afae":"Given the fact that the original proportion was tresspassed, It's possible to say that I reduced imbalanced data a little bit (being optimistic).\n\n## Pairplot for numerical features","5f954b97":"## Results - Task 2\n- The model provides a good **recall** for '0': 96%, but for classes '1','2' and '3' worst results: 20%, 25% and 20% respectively. The accuracy was 80%, but this value is not reliable given the confusion matrix. Probably, given the small samples quantities for classes '1','2' and '3' SMOTE most generalize points for those categories based in '0'. Further study should be applied to understand better this Task.\n- Different from task 1, discrete features improve (a little bit) my model results.\n\n# Conclusions\nAll pipeline was explained during code development. I learned a lot (as I said before), principally missing data analysis. I can think several possibilities to improve my results:\n- Having a bigger dataset\n- Try \"total attack approach\" with all machine learning models through Hunga bunga package, even though SVM is highly recommended for applications with a low sample sizes.\n\nIn my Point of View, I had an awesome result in task 1. The task 2 was more complicate given the fact that I needed to predict a categorical feature with 4 classes. Some ways to improve my metrics in this task would be:\n- reducing class size (grouping some categories into one)\n- trying another ML models\n- Understand more the problem related to those target labels.\n\nLook that I'm really confident with my missing analysis, this part was really hard to understand and quite difficult to search.\n\nThe family taxonomy columns was a great idea in my opinion, but I think that those columns did not get any impact for task 1 model because:\n- Family could be a taxonomy group generic\n- The way that I picked my rows (I would make the same choice btw) could be decisive in those results\n\n## Summarizing\n**my best model for Task 1 used only numerical features and for Task 2 used discrete + numerical features. SMOTE improved my results for Task 1, but not for Task 2.**\n\nDespite not reaching great metrics, I believe that the architecture presented here demonstrates why I pick each result, graph and decision. Furthermore, I believe that for future databases this same architecture can be applied with a high level of confidence given its mathematical foundation principally missing data analysis, imputation and data exploration.\n\n#### Let's win this fight against Covid-19!","11d57b61":"## Count plot for discrete variables - Task 2","e46d2f73":"## Creating separate datasets for each task (changing only target variable)","e7cd1de7":"## Changing discrete values: negative\/not_detect becomes 0 and positive\/detected becomes 1","578abf4d":"For a better understandment of those graphs, look at [reference 10](https:\/\/medium.com\/ibm-data-science-experience\/missing-data-conundrum-exploration-and-imputation-techniques-9f40abe0fd87).\n### MNAR vs MAR\nThis is a subjective analysis. Given the fact that a **MNAR** classification depends exclusively from Hospital Albert Einstein. For example, I cannot assume that those samples were missing because a doctor\/nurse mistake or lack of measuring device. Given the nullity matrix and the heatmap I assume that my missing samples are **MAR** type. This allowsme to finally do some imputation.\n\nFrom [reference 6](https:\/\/bmcmedresmethodol.biomedcentral.com\/articles\/10.1186\/s12874-017-0442-1) to impute any data it's necessary to pass this pipeline:\n\n![image](https:\/\/user-images.githubusercontent.com\/32513366\/78102793-9130d380-73c1-11ea-94fc-ca775fdb61ba.png)\n\nChecking the boxes:\n- **Is it valid to ignore missing data (<5%)?**\n\n**NO**, given the fact that I will lose 32% of my samples.\n\n- **Too large proportions of missing data for each column (>40%)?**\n\n**NO**, considering that each variable have less than 40% of missing data (reading this paper, it's implicit that the author talks about the variable individualy).\n\nPS: Now you can see where I got one of my golden rules...\n\n- **It's data only missing on dependent variable (target)?**\n\n**NO**, my targets are complete!\n\n- **Is the MCAR assumption plausible?**\n\n**NO**, nullity matrix and heatmap explained this.\n\n- **Is the MNAR assumption plausible?**\n\n**NO**, as I said previously: based in MNAR definition, only the Hospital could define it.","be40bc57":"### Oversampling technique for trainset: SMOTE","b03b8f29":"Given my previous arguments during missing analysis, I will continue my study with imputed dataset!","e5730c5e":"### Verify that after this filter, any discrete variable become static (no variance):","139977d5":"Using those results I can have a possible dataset with only 532 rows, but more consistent and less sparse.","80b9cbe4":"## Assumption 2","77f643e0":"## Complete feature space\n\n### Train Test Split, SMOTE and GridSearchCV","c11d34cf":"Based in this result, I verify that I lost 32% of my samples. \n\n### What is the number of positive\/negative cases in this complete dataset?","058b9870":"### Model prediction and Metrics","e951a219":"### Grid Search Stratified KFold Cross Validation for SVM Classifier","5a628a1d":"### Before any column NaN filtering threshold, how many rows do I have to impute?\n\nEvaluate rows with less than 50% of missing.","caf814a7":"### Split a test set to verify the metrics","02b1edd4":"I will create a new column for each family, grouping species:\n- detection_adenoviridae\n- detection_coronaviridae\n- detection_orthomyxoviridae\n- detection_paramyxoviridae\n- detection_picornaviridae\n- detection_pneumoviridae\n\nThis procedure will: Decrease model's possible complexity from 14 features to 6 features and probably remove missing values given the family taxonomy approach","10bbcb64":"### How many NaN values have each column?\n\nIn my previous analysis, I just eliminated 21 columns because they present:\n- Too much missing data\n- Data invariance (only one class means a statical variable)\n\nLet's continue the missing analysis, the most important part for this challenge...","d3c75402":"## Eval missing samples for each column again","2a0ffe56":"# Task 2\n**Predict admission to general ward, semi-intensive unit or intensive care unit among confirmed COVID-19 cases. Based on the results of laboratory tests commonly collected among confirmed COVID-19 cases during a visit to the emergency room, would it be possible to predict which patients will need to be admitted to a general ward, semi-intensive unit or intensive care unit?**\n\n## Only numerical features\n### Split a test set to verify the metrics","a2bcff2e":"I will assume for task 2:\n- Category 0 implies not addmited ('000')\n- Category 1 implies regular ward ('100')\n- Category 2 implies semi-intensitve unit ('010')\n- Category 3 implies intensitve care unit ('001')","7d77bdea":"## MICE imputation","03b180e4":"## Count plot for discrete variables - Task 1","a16fe439":"Through this amount of plots, it's possible to see that some variables are highly correlated. Let's evaluate this through a correlation heatmap.\n\n## Correlation Heatmap for numerical features","bce8830e":"### Evaluate Metrics for imputed dataset\nEvaluating SVM model performance to answer the first task.","b0fb2590":"### Filter I: Remove 51 columns that have NaN values > T3 and verify samples quantity","408c5ac9":"## Impute missing data\n\nBefore any analysis or imputation, it's necessary to understand the missing types. From [reference 4](https:\/\/www.theanalysisfactor.com\/missing-data-mechanism\/):\n- **Missing Completely at Random (MCAR)**: there is NO relationship between the missingness of the data and any values, observed or missing. Those missing data points are a random subset of the data. There is nothing systematic going on that makes some data more likely to be missing than others.\n- **Missing at Random (MAR)**: there is a systematic relationship between the propensity of missing values and the observed data, but not the missing data. Whether an observation is missing has nothing to do with the missing values, but it does have to do with the values of an individual\u2019s observed variables.\n- **Missing Not at Random (MNAR)**: there is a relationship between the propensity of a value to be missing and its values. This is a case where the people with the lowest education are missing on education or the sickest people are most likely to drop out of the study. MNAR is called \u201cnon-ignorable\u201d because the missing data mechanism itself has to be modeled as you deal with the missing data. You have to include some model for why the data are missing and what the likely values are.\n\nGiven those definitions, I present a pipeline from [reference 5](https:\/\/towardsdatascience.com\/missing-data-cfd9dbfd11b7):\n![maPipe](https:\/\/user-images.githubusercontent.com\/32513366\/78101044-a6573380-73bc-11ea-97bc-4453b4d210a3.png)\n\nBasically, to do any imputation I need to evaluate if my missing values are **MAR**. This statement is based in [reference 6](https:\/\/bmcmedresmethodol.biomedcentral.com\/articles\/10.1186\/s12874-017-0442-1) (a really good paper that explain step by step how to do a complete missing data study).\n\nTo eval MNAR vs MAR vs MCAR is very subjective... There isn't any developed test to verify this, so will be necessary some qualitative study with some plots through ```missingno``` module.\n\n### MNAR vs MAR vs MCAR - Nullity Matrix\nThis plot shows as **black** observed data and **white** as NaN value.","cd3cac87":"## Results - Task 1\n- The SVM model had a great performance, with a recall (related to **FN error**) of 75% and a  accuracy ~93%. Some test that I didn't present here demonstrate that missing imputation + oversampling SMOTE helped the model improvement (got this idea from [Lucas Moda](https:\/\/www.kaggle.com\/lukmoda), thanks!)\n- The model is robust and could have future implementations given small datasets.\n- Even after a hard work to create the family column, my discrete variables didn't present any improvement in the model.\n\nProbably with more complete samples for those continuous features the model can be improved!","2860c232":"I got more than 300 new samples!","0f611054":"## Features Overview for model development","714d58a9":"Reminds that column is predicted and row is actual value.","1b657098":"# Predictive Analysis - General Infos\nFor both tasks, those infos are necessary to a better comprehension of what I did and why.\n\n## Why Support Vector Machine (SVM)\n- It's is a robust model, before deep learning explosion as one of the most used\n- Works really well with small datasets. This statement is not applied for Deep Learning models that requires a lot of data to work a correct generalization.\n- It's a powerful binary classifier and this problem is a binary classification (TASK 1). Nonetheless, can be applied for multi-class problem (TASK 2)\n\n## Measures againts imbalanced target class\nAll targets for task 1 and 2 are unbalanced, to avoid this I proposed:\n- Train\/Test split stratified\n- Stratified K-Fold Cross-Validation, keeping the proportion between train\/validation split\n- Cross Validation Analysis to avoid possible overfit due to small dataset\n- Score metrics - balanced accuracy\n- Use oversampling technique: SMOTE to increase my samples, turning my dataset more robust and balanced for target classes.\n- Evaluate confusion matrix results besides accuracy\n\n**PS**: Stratify keeps the same proportion for target categories in spliting process.\n\n**PS2**: Using SMOTE can be a necessary technique given the fact that I'm working with a small dataset (526 rows) and undersampling techiniques would reduce even more my samples.\n\n## Metrics details\nWill be evaluated **balanced accuracy** and a **confusion matrix report**. To understand the last one, let me explaing a binary confusion matrix:\n\n![cm](https:\/\/user-images.githubusercontent.com\/32513366\/77873202-aec63780-721f-11ea-9955-08e3860e2a01.PNG)\n\nColumn - Predicted value\nRow - Real value\n\nAs the target variable is medical in nature, each value in the confusion matrix has a meaning:\n- TP (True Positive): If a pacient present COVID-19 and the model predict correct\n- TN (True Negative): If a pacient don't present COVID-19 and the model predict correct\n- FP (False Positive): If a pacient don't present COVID-19 and the model says that he's infected\n- FN (False Negative): If a pacient present COVID-19, but the model says that he's fine\n\nGiven the actual world situation, I considered **FN error the worst**: the pacient infected getting out from the hospital could infect others. I will considered **recall** and **accuracy** as the most important measures for this study.","6460af6e":"# Impute or Not Impute? that is the question\n\nNow I have a decision to make:\n- A - Work with a complete dataset, dropping any NaN samples\n- B - Impute missing data\n\nLet's evaluate both separately. But first I will present my knowledge over some imputation practices:\n- Doing Average imputation you may be generalizing negative cases into positive cases, which can be considered an medical error. Even because, how can you extrapolate the values of a positive case only with values for negative cases?\n- Initially, this dataset have a great amount of missing values, imputation for 90% missing sample are not recommended at all!\n- I cleaned initially 21 static variables, a zero imputation without any data understand would input a useless feature into your model.\n- At all, it's not recommendate simple imputation.\n- Even through a Selected Case Average imputation (imputing negative cases with negative cases average and positive cases with positive cases average) can cause two problems such as: lack of a considerable samples (mainly for positive cases) to propose a representative average  or situations where positive cases do not even present samples to take the average.\n- Besides that Mean imputation or Zero imputation are not recommended given the diversity of imputation techniques in this field.\n- Even if your model have an accuracy\/recall of 90%, you really need to have confidence over your trainset.\n\nNow, Let's go back and analyze deeply this NaN cases matter to impute, now splitting the dataset.\n\n## Work with a complete dataset\n\n### What is the number of rows in this complete dataset?","94ae4744":"# An end-to-end Solution for covid-19 predictions\nby: Kaike W. Reis\n\n## Briefly overview\nDuring this notebook construction I learned a lot in Data Analytics! Here I present a solution for proposed tasks. But before you continue this reading, understand that this a complex challenge with commom problems in machine learning field such as:\n- **Great number of missing values and how you can solve it**\n- **Imbalanced label for covid-19 exams results**\n\nOthers situations will be describe during this notebook.\n\n## Steps\n- Missing Data Analysis & Pre-processing data\n- Data assumptions - a biological assessment to reduce missing values and data complexity\n- Impute or Not Impute? that is the question\n- Exploratory Data Analysis\n- Predictive Analysis: general infos\n- Model Development: Task 1\n- Model Development: Task 2\n- Conclusions\n\n## Notebook Libraries","dd2e5892":"Considere a correlation absolute value higher than 0.90 highly correlated:\n- 0.93: hemoglobin VS hematocrit\n\nLook that the correlated variables have a strong background: hematocrit ([volume percentage of red blood cells in blood](https:\/\/en.wikipedia.org\/wiki\/Hematocrit)) and hemoglobin are related to human blood. Because they are higher correlated, to decrease model complexity through similar variables, I will evaluate the possibility to remove one of each pair, reducing model noise.\nBased only in biological definition it's possible to defined the selected variables: I will keep  ```hemoglobin``` given your general definition.","f07279c7":"### Arguments to keep rapid test from this dataset\n- Divergent columns for both influenza types, so it's different collumns\n\n### Arguments to remove rapid test from this dataset\n- After a small research in [reference 1](https:\/\/en.wikipedia.org\/wiki\/Rapid_influenza_diagnostic_test#cite_note-pmid20409373-6), I verified that **influenza rapid test** is a fast way to diagnose antigen presence, technically the same results for ```influenza_a``` and ```influenza_b```.\n- Reading [reference 2](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC2954007\/) I verified that some papers presents those rapid tests as not confident at all, they mention that in outbreak situations would not be recommended for example (now we are living a outbreak).\n- Based in [reference 3](https:\/\/www.cdc.gov\/mmwr\/preview\/mmwrhtml\/mm5830a2.htm) depending on test type, it can be reliable or not \n\n### Assumption 2 - Conclusion\nGiven the lack of confidence in these rapid test variables I assume that ```influenza_a``` or ```influenza_b``` are more reliable and given the fact that they can be considerated the same:**I will remove those features**","1fff8f59":"### Missing imputation - SMOTE","381f430e":"Again, task two will be a imbalanced problem to solve...","ba3df1d8":"### Evaluate Metrics","493b492e":"From this result, I can imply some conclusions:\n\n**Conclusion 1**\n\nThe features\n- ```mycoplasma_pneumoniae```\n- ```d-dimer```\n- ```partial_thromboplastin_time (ptt)```\n- ```prothrombin_time_(pt),_activity```\n- ```urine_-_sugar``` \n\nare empty features, so should be drop!\n\n**Conclusion 2**\n\nThe features\n- ```urine_-_yeasts```\n- ```urine_-_granular_cylinders```\n- ```urine_-_hyaline_cylinders```\n- ```myeloblasts```\n- ```parainfluenza_2```\n- ```fio2_(venous_blood_gas_analysis)``` \n\nonly have one category besides \"nan\" (missing value). Because those variables doesn't have variation should be eliminate from the dataset!\n\n**Conclusion 3**\n\nThe features \n- ```urine_-_esterase```\n- ```urine_-_bile_pigments```\n- ```urine_-_ketone_bodies```\n- ```urine_-_protein```\n- ```urine_-_urobilinogen``` \n\nshows a *not_done category*. Well, a not_done implies a NaN... So a a NaN imputation over those variables results in **Conclusion 2** (no deviation), which means another drop. The variable ```urine_-_nitrite``` would be dropped by **Conclusion 1**.\n\n**Conclusion 4**\n\nI should impute NaN values in *not_done category* for ```strepto_a``` and ```urine_-_hemoglobin```.\n\n**Conclusion 5**\n\nIt's clear that urine data collect got some problems.\n\n#### Now, after those conclusions we can remove 17 features without any mathematical analysis!","49c94c5a":"### Metrics","9df251b8":"### How many complete rows do I have in this filtered dataset?","67cbdf2a":"# Task 1\n#### Predict confirmed COVID-19 cases among suspected cases. Based on the results of laboratory tests commonly collected for a suspected COVID-19 case during a visit to the emergency room, would it be possible to predict the test result for SARS-Cov-2 (positive\/negative)?\n\n\nThe discrete count plot presents a weird positive\/negative case distribution for the data (few samples are positive). Given this, I will evaluate models using: complete feature space and only numerical features (the same is valid for Task 2).\n\n## Only numerical features","4768dc8c":"### Metrics","4688f408":"Something important to note is there are some numerical columns that presents few values. For example\n- ```promyelocytes```\n- ```myelocytes```\n- ```metamyelocytes```\n- ```vitamin_b12```\n\nShows a restrict sample value... Let's understand the NaN size for each column!","4f756b7c":"## Standardization\n\nGiven the fact that I massively reduce the original dataset, for precaution I will apply a standardization.\n","eaa532d3":"### Grid Search Stratified KFold Cross Validation for SVM Classifier","7e675758":"Through those graphs I can see that: \n- ```chlamydophila_pneumoniae``` becames pratically a constant feature with only 1% for positives cases. So it's necessary to remove from both datasets (task 1 and 2) given no variance.\n- ```detection_adenoviridae``` (genus from only one virus specie) is almost constant for task 1 target. \n\nLet's see class distribution for ```detection_adenoviridae``` feature:\n","fc4ae72e":"### Phase Conclusion\n\n**Well, now we got a better missing perspective view!**\n\nI had to make a trade: lost tons of rows, more than 90% of my original dataset. But this is Ok! It's important to have confidence in your dataset before any model development.","e5546431":"This plot shows that are tons of missing values! Even after my previous cleaning. So before model development, I have to go deeply in this missing analysis, because to develop a model I need a complete dataset to train.\n\nFirst I have to decide what happens with our NaN values:\n- Get only complete samples to my model dataset?\n- Impute all missing values?\n\nWell, both solutions are not an option for me right now. The first one probably will select a complete dataset with 0 samples.","b6322f81":"### Which variable is continuous or discrete?","45b54294":"# Missing Data Analysis & Pre-processing data\n\n## Importing data","b715e8bf":"## Assumption 1\nBased in **Wikipedia pages** refered to those virus\/bacterias, I present the **Family Taxonomy** for each virus\/bacteria in this dataset (after the filter):\n\n![image](https:\/\/user-images.githubusercontent.com\/32513366\/78080117-efd75c80-7383-11ea-93b5-976d1cd4f328.png)","82892fc7":"### Model Predictions and Metrics","d6b233a1":"# Data assumptions - a biological assessment to reduce missing values and data complexity\n\nGiven the fact that our final dataset got some categorical variables related to: **detected or not** a type of virus\/bacteria, let's insert some **assumptions** for features\n- respiratory_syncytial_virus\n- influenza_a \n- influenza_b\n- parainfluenza_1\n- coronavirusnl63\n- rhinovirus\/enterovirus\n- coronavirus_hku1\n- parainfluenza_3\n- chlamydophila_pneumoniae\n- adenovirus\n- parainfluenza_4\n- coronavirus229e\n- coronavirusoc43 \n- inf_a_h1n1_2009\n- bordetella_pertussis\n- metapneumovirus\n- influenza_b,_rapid_test\n- influenza_a,_rapid_test\n\n\n## Assumptions\n\n- **Assumption 1**: They are here, because somehow they could influence in some respiratory disease\n- **Assumption 2**: Probably, ```influenza_a,_rapid_test``` and ```influenza_b,_rapid_test``` have the same results respectively for ```influenza_a``` and ```influenza_b```. So they need to become only two columns.\n- **Assumption 3**: I will combine those features in one column based in **Taxonomy Genus group**. The generic coluns will be binary where 1 means **have any of this Genus** and 0 means **got none of this Genus**.\n\n\n**PS 1**: Would exist an fourth assumption that given a biological background and **Assumption 1** I would combine the species related to **Bacterias** Kingdom in one column (based on the fact that I dropped this column it is not necessary).\n\n**PS 2**: Got this idea after a commentary by [Lucas Moda](https:\/\/www.kaggle.com\/lukmoda)\n\nThe image bellow shows a taxonomy pyramid:\n\n![gen](https:\/\/user-images.githubusercontent.com\/32513366\/78076320-93bd0a00-737c-11ea-881d-b9af626e86a2.jpg)\n\n[Image source](https:\/\/www.tes.com\/lessons\/cZH2FUDnGVZvyg\/classification-11)\n\n","ba7be44e":"Reminds that column is predicted and row is actual value.","30ade933":"# Exploratory Data Analysis\n\n## Eval COVID positive samples proportion","0a790cbd":"Knowing that from 47 discrete variables, 4 are target. We have 43 discrete features possibles to our model. Besides that, there is a discrete variable with more than 5 categories:\n\n```patient_age_quantile```\n\n### Understanding more those 43 discrete features ...","9f672a53":"Everyone except ```bordetella_pertussis``` have a binary nature, so let's remove it!","7013a3d5":"Based on previous results, **How much features I can keep with follow thresholds (cumulative speaking)?**:\n- T1 - features with 76% NaN values\n- T2 - features with NaN values between 76% and 90.9%\n- T3 - features with NaN values higher than 90.9%","129a68e9":"The second one: \"Impute all missing values\" can be complicated. In Missing Data Analysis (field that studies forms to impute a missing information) there are some golden rules (more like recommendations):\n- You need to understand if your data is Missing Completely at Random (MCAR), Missing at Random (MAR) or missing Not At Random (MNAR). Imputation methods are only applied for MAR cases.\n- Samples with more than 50% missing data should not be imputed\n- Columns with more than 40% should not be imputed\n\nFirst, I will analyze the second and third rules.\n\n### Evaluate: NaN samples [%] > 50% and NaN Columns [%] > 40%","bbbb7d24":"Most of my categorical features presents a similar pattern to ```chlamydophila_pneumoniae``` and ```detection_adenoviridae```. Both will be dropped by the same reasons for task 1 dataset.","facfb7dc":"Given the fact that all features have 98% of missing values I will drop them:","1749c851":"Not bad at all, given the fact that I lost more negative cases could be a good sign, because this situation decrease **imbalanced label problem**...","4f3eeab9":"## Complete feature space\n\n### Train Test Split, SMOTE and GridSearchCV"}}