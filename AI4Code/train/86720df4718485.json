{"cell_type":{"0d421a0a":"code","d5525ec4":"code","19bed9a3":"code","f2bb6e25":"code","f13f3c08":"code","17390715":"code","7685b22c":"code","6e5a1a1d":"code","3eda6038":"code","8eef2af5":"code","8dfad7d8":"code","f587f156":"code","a2a134b3":"code","03bcfd3f":"code","30b5329f":"code","9cc4b7c0":"code","4f5023a7":"code","9bd8e41d":"code","d643f8cb":"code","12f67634":"code","288d049a":"code","8eea1068":"code","da10b0eb":"code","e901a19f":"code","97d9118a":"code","9ea70f95":"code","014f4215":"code","becad118":"code","c3c27c73":"code","c40a15eb":"code","77c93a84":"code","b26762a5":"code","694fbd84":"code","da0fe234":"code","e0d2f46f":"markdown","d6d749d4":"markdown","2b7cc52e":"markdown"},"source":{"0d421a0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5525ec4":"df = pd.read_csv('..\/input\/translated-wikipedia-biographies\/Translated Wikipedia Biographies - EN_DE.csv', encoding='utf8')\npd.set_option('display.max_columns', None)\ndf.head()","19bed9a3":"nRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","f2bb6e25":"df.isnull().sum()","f13f3c08":"df[\"perceivedGender\"].value_counts()","17390715":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'red',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"perceivedGender\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Perceived Gender\")\nplt.show()","7685b22c":"df[\"entityName\"].value_counts()","6e5a1a1d":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'black',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"entityName\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Entity Name\")\nplt.show()","3eda6038":"!pip install stylecloud","8eef2af5":"import stylecloud\nfrom IPython.display import Image","8dfad7d8":"#Code by Kapa Kudaibergenov https:\/\/www.kaggle.com\/kapakudaibergenov\/stylecloud\/notebook\n\nconcat_translatedText = ' '.join([i for i in df.translatedText.astype(str)])\nprint(concat_translatedText[:1000])","f587f156":"#Code by Kapa Kudaibergenov https:\/\/www.kaggle.com\/kapakudaibergenov\/stylecloud\/notebook\n\nstylecloud.gen_stylecloud(text=concat_translatedText,\n                          icon_name='fas fa-biking',\n                          palette='cartocolors.qualitative.Bold_6',\n                          background_color='black',\n                          gradient='horizontal',\n                          size=1024)\n\nImage(filename=\".\/stylecloud.png\", width=1024, height=1024)","a2a134b3":"#Codes by Ragnar https:\/\/www.kaggle.com\/rowhitswami\/starter-load-stopwords\n\ndef get_stopwords_list(stop_file_path):\n    \"\"\"load stop words \"\"\"\n    \n    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n        stopwords = f.readlines()\n        stop_set = set(m.strip() for m in stopwords)\n        return list(frozenset(stop_set))","03bcfd3f":"stopwords_path = \"\/kaggle\/input\/translated-wikipedia-biographies\/Translated Wikipedia Biographies - EN_DE.csv\"\nstopwords = get_stopwords_list(stopwords_path)","30b5329f":"stopwords[0:10]","9cc4b7c0":"print(f\"Total number of stopwords: {len(stopwords)}\")","4f5023a7":"import io\nimport re\nimport shutil\nimport string\nimport tensorflow as tf\n\nfrom datetime import datetime\nfrom tensorflow.keras import Model, Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization","9bd8e41d":"from gensim.models import Word2Vec\nimport gensim","d643f8cb":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\ncorpus = ['Dank der von ihr entwickelten Methode zur Rekonstruktion untergegangener T\u00e4nze ',\n 'von denen die meisten vollst\u00e4ndig in Vergessenheit geraten waren.',\n 'Omaswa wurde ca. 1943 im Dorf Mukul',\n 'Er wurde w\u00e4hrend Francias Diktatur inhaftiert und nach zwanzig Jahren im Gef\u00e4ngnis erschossen',\n 'Deshalb hat er seinen Lebensunterhalt mit einer Vollzeitbesch\u00e4ftigung als Krankenhauspfleger verdient',\n 'weil sie die Veruntreuung von \u00f6ffentlichen Geldern durch den Sozialminister Gaston Gambor und den Minister f\u00fcr Wasser und Wald S\u00e9bastien Guipi anprangerte',\n 'Bi\u201c Ribeiro waren Jugendfreunde und Nachbarn in dieser Stadt',\n 'bevor sie sich an der Dominica Grammar School anmeldete, um ihre schulische Laufbahn 1981 abzuschlie\u00dfen']","12f67634":"stop_words = ['der',\n 'euer',\n 'zu',\n 'von',\n 'zur',\n 'im',\n 'und',\n 'nach',\n 'mit',\n 'als',\n 'weil',\n 'durch',\n 'f\u00fcr',\n 'in',\n 'an',\n 'ihre']","288d049a":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\ndef remove_stop_words(corpus):\n    results = []\n    for text in corpus:\n        tmp = text.split(' ')\n        for stop_word in stop_words:\n            if stop_word in tmp:\n                tmp.remove(stop_word)\n        results.append(\" \".join(tmp))\n        \n    return results","8eea1068":"corpus = remove_stop_words(corpus)","da10b0eb":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\nwords = []\nfor text in corpus:\n    for word in text.split(' '):\n        words.append(word)\n        \nwords = set(words)","e901a19f":"words","97d9118a":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\n\"\"\"Data Generation\"\"\"\n\nword2int = {}\n\nfor i,word in enumerate(words):\n    word2int[word] = i\n    \nsentences = []\nfor sentence in corpus:\n    sentences.append(sentence.split())\n    \nWINDOW_SIZE = 2\n\ndata = []\nfor sentence in sentences:\n    for idx, word in enumerate(sentence):\n        for neighbor in sentence[max(idx - WINDOW_SIZE, 0): min(idx + WINDOW_SIZE, len(sentence) + 1)]:\n            if neighbor !=word:\n                data.append([word, neighbor])","9ea70f95":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\nimport pandas as pd\nfor text in corpus:\n    print(text)\n\ndf = pd.DataFrame(data, columns = ['input', 'label'])","014f4215":"df.head(10)","becad118":"word2int","c3c27c73":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nx = tf.placeholder(shape=[None, 2], dtype=tf.float32)","c40a15eb":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\n\"\"\"Define Tensorflow Graph\"\"\"\n\nONE_HOT_DIM = len(words)\n\n# function to convert numbers to one hot vectors\ndef to_one_hot_encoding(data_point_index):\n    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n    one_hot_encoding[data_point_index] = 1\n    return one_hot_encoding\n\nX = [] # input word\nY = [] # target word\n\nfor x, y in zip(df['input'], df['label']):\n    X.append(to_one_hot_encoding(word2int[ x ]))\n    Y.append(to_one_hot_encoding(word2int[ y ]))\n\n# convert them to numpy arrays\nX_train = np.asarray(X)\nY_train = np.asarray(Y)\n\n# making placeholders for X_train and Y_train\nx = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\ny_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n\n# word embedding will be 2 dimension for 2d visualization\nEMBEDDING_DIM = 2 \n\n# hidden layer: which represents word vector eventually\nW1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\nb1 = tf.Variable(tf.random_normal([1])) #bias\nhidden_layer = tf.add(tf.matmul(x,W1), b1)\n\n# output layer\nW2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\nb2 = tf.Variable(tf.random_normal([1]))\nprediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n\n# loss function: cross entropy\nloss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n\n# training operation\ntrain_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)","77c93a84":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\n\"\"\"Training\"\"\"\n\nsess = tf.Session()\ninit = tf.global_variables_initializer()\nsess.run(init) \n\niteration = 20000\nfor i in range(iteration):\n    # input is X_train which is one hot encoded word\n    # label is Y_train which is one hot encoded neighbor word\n    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n    if i % 3000 == 0:\n        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))","b26762a5":"#Code by Anil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\n# Now the hidden layer (W1 + b1) is actually the word look up table\nvectors = sess.run(W1 + b1)\nprint(vectors)","694fbd84":"\"\"\"Word Vector in Table\"\"\"\n\nw2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\nw2v_df['word'] = words\nw2v_df = w2v_df[['word', 'x1', 'x2']]\nw2v_df","da0fe234":"\"\"\"Word Vector in 2D Chart\"\"\"\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nfor word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n    ax.annotate(word, (x1,x2 ))\n    \nPADDING = 1.0\nx_axis_min = np.amin(vectors, axis=0)[0] - PADDING\ny_axis_min = np.amin(vectors, axis=0)[1] - PADDING\nx_axis_max = np.amax(vectors, axis=0)[0] + PADDING\ny_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n \nplt.xlim(x_axis_min,x_axis_max)\nplt.ylim(y_axis_min,y_axis_max)\nplt.rcParams[\"figure.figsize\"] = (20,20)\n\nplt.show()","e0d2f46f":"#Acknowledgements:\n\nAnil Govind https:\/\/www.kaggle.com\/anilreddy8989\/stopwords-word2vector\n\nKapa Kudaibergenov https:\/\/www.kaggle.com\/kapakudaibergenov\/stylecloud\/notebook\n\nRagnar https:\/\/www.kaggle.com\/rowhitswami\/starter-load-stopwords   ","d6d749d4":"#That's funny: Real Madri is Perceived Gender!","2b7cc52e":"#Above TypeError: 'set' type is unordered.  Therefore, I couldn't make the Word Vector chart below."}}