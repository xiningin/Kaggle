{"cell_type":{"fffbfd85":"code","51712da7":"code","8733f69f":"code","efb1b71b":"code","a2cabfbc":"code","d07b21c7":"code","c24347ee":"code","1c4ece33":"code","77e8ddfb":"code","53b05efa":"code","879de528":"code","77179e73":"code","73ab43e4":"code","ca04530a":"code","9c5f38b1":"code","abe0b39a":"code","9b958a42":"code","b4de08b1":"code","daa32d0d":"code","9fe19c78":"markdown","44f81e73":"markdown","2877ab38":"markdown","36162433":"markdown","1673deeb":"markdown","97ea0239":"markdown","35a5fa65":"markdown","12fbc135":"markdown"},"source":{"fffbfd85":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcToCUTD2I5lj4H9e-AClxBLMTg0cqF2xOe2qT1xnUAzSa27gli7&usqp=CAU',width=400,height=400)","51712da7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8733f69f":"# Import Python Packages\n# PyTesseract and Tika-Python for OCR\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport PIL\nimport os\nfrom os import walk\nfrom shutil import copytree, ignore_patterns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nfrom wand.image import Image as Img\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)\n#mueller_report = pd.read_csv('..\/input\/data-science-cheat-sheets\/Interview Questions\/AI Questions.pdf') # one row per line","efb1b71b":"# Define helper function for plotting word clouds\ndef wordCloudFunction(df,column,numWords):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","a2cabfbc":"# Define helper function for plotting word bar graphs\ndef wordBarGraphFunction(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()","d07b21c7":"# Preview the data folder\ninputFolder = '..\/input\/'\nfor root, directories, filenames in os.walk(inputFolder):\n    for filename in filenames: \n        print(os.path.join(root,filename))\n        \n# Move data to folder with read\/write access\noutputFolder = '\/kaggle\/working\/pdfs\/'\nshutil.copytree(inputFolder,outputFolder,ignore=ignore_patterns('*.db'))\nfor root, directories, filenames in os.walk(outputFolder, topdown=False):\n    for file in filenames:\n        try:\n            shutil.move(os.path.join(root, file), outputFolder)\n        except OSError:\n            pass\nprint(os.listdir(outputFolder))","c24347ee":"# Look at page 3\npdf = os.path.join(outputFolder,'ifngamma.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/ifngamma3.jpg') # intro page to preview later","1c4ece33":"# Parse a PDF file and convert it to CSV using PyTesseract\nimport pytesseract\npdfimage = Image.open('\/kaggle\/working\/ifngamma3.jpg')\ntext = pytesseract.image_to_string(pdfimage)  \ndf = pd.DataFrame([text.split('\\n')])","77e8ddfb":"# Plot WordCloud of page 3\nplt.figure(figsize=(10,10))\nwordCloudFunction(df.T,0,10000000)\nplt.figure(figsize=(10,10))\nwordBarGraphFunction(df.T,0,\"Most Common Words on Page 3 of IFG_Gamma\")","53b05efa":"# Parse a PDF file and convert it to CSV using Tika-Python\n!pip install tika\nimport tika\nfrom tika import parser\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/ifngamma3.jpg') \ntext = parsed[\"content\"]\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 1:46], inplace=True, axis=1)","879de528":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p3\npdf = os.path.join(outputFolder,'ifngamma.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/ifngamma3.jpg')\npdfimage3 = Image.open('\/kaggle\/working\/ifngamma3.jpg')","77179e73":"# PDF to JPG for p2\npdf = os.path.join(outputFolder,'ifngamma.pdf[2]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/ifngamma2.jpg')\npdfimage2 = Image.open('\/kaggle\/working\/ifngamma2.jpg')\n\n# PDF to JPG for p8\npdf = os.path.join(outputFolder,'ifngamma.pdf[8]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/ifngamma8.jpg')\npdfimage8 = Image.open('\/kaggle\/working\/ifngamma8.jpg')","73ab43e4":"# Parse a PDF file and convert it to CSV using PyTesseract (p3)\ntext = pytesseract.image_to_string(pdfimage3)\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 27:], inplace=True, axis=1)\ndf.drop(df.iloc[:, :3], inplace=True, axis=1)\ndf.columns = range(df.shape[1])","ca04530a":"# Parse a PDF file and convert it to CSV using Tika-Python (p290-291)\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/ifngamma2.jpg')\nparsed2 = parser.from_file('\/kaggle\/working\/ifngamma8.jpg')\n\ntext = parsed[\"content\"]\ndf2 = pd.DataFrame([text.split('\\n')])\ndf2.drop(df2.iloc[:, 1:50], inplace=True, axis=1)\ndf2.drop(df2.iloc[:, 26:], inplace=True, axis=1)\ndf2.columns = range(df2.shape[1])\n\ntext = parsed2[\"content\"]\ndf3 = pd.DataFrame([text.split('\\n')])\ndf3.drop(df3.iloc[:, :50], inplace=True, axis=1)\ndf3.drop(df3.iloc[:, 22:], inplace=True, axis=1)\ndf3.columns = range(df3.shape[1])\n\ndfcombined = pd.concat([df, df2, df3]) # combine pages 289-291","9c5f38b1":"#Explore page 3 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 30 pages \nw, h = pdfimage3.size # crop image\npdfimage3.crop((0, 1240, w, h-1300)) # display exerpt of PDF","abe0b39a":"#Explore page 2 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 30 pages \nw, h = pdfimage2.size # crop image\npdfimage2.crop((0, 1240, w, h-1300)) # display exerpt of PDF","9b958a42":"# Pages 2, 3 and 8\ndfcombined.head() # preview csv of 289-291","b4de08b1":"# Clean up the notebook\n!apt-get install zip # install zip\n!zip -r pdfs.zip \/kaggle\/working\/pdfs\/ # zip up a few files\n!rm -rf pdfs\/* # remove everything else","daa32d0d":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRdze0IVZATkOD1BN7lxDIL0PwoyuqNZ1irbs-3JCStbd4FPxbn&usqp=CAU',width=400,height=400)","9fe19c78":"#Interferon-Gamma Testing for Bovine Tuberculosis - Monthly Reports from April 2016 \n\nThese monthly reports summarise the gamma tests completed \/ reported during that calendar month. The report also summarises tests for the whole calendar year to the end of the current month. While all effort is made to ensure the accuracy of the test data, small errors can occur and later corrected in subsequent reports.\n\nCattle interferon-gamma (IFNg) tests (and test outcome) carried out between 1st Jan and 31st Dec 2009. Tests are listed by country (England, Wales, Scotland) and by Animal Health Office (AHDO) and the reason for the test. Reports contain test data for the month, the calendar year to date and total tests since rollout (23rd Oct 2006). https:\/\/data.gov.uk\/dataset\/f48e8d0a-f527-4f69-8aff-b07db7c26f09\/interferon-gamma-testing-for-bovine-tuberculosis-monthly-reports-from-april-2016\n\n#Interferon gamma (IFN\u03b3)\n\nIt's a dimerized soluble cytokine that is the only member of the type II class of interferons. The existence of this interferon, which early in its history was known as immune interferon, was described by E. F. Wheelock as a product of human leukocytes stimulated with phytohemagglutinin, and by others as a product of antigen-stimulated lymphocytes. It was also shown to be produced in human lymphocytes or tuberculin-sensitized mouse peritoneal lymphocytes challenged with PPD; the resulting supernatants were shown to inhibit growth of vesicular stomatitis virus. Those reports also contained the basic observation underlying the now widely employed interferon gamma release assay used to test for tuberculosis. In humans, the IFN\u03b3 protein is encoded by the IFNG. https:\/\/en.wikipedia.org\/wiki\/Interferon_gamma","44f81e73":"#Codes from Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook","2877ab38":"#MY TIKA IS WORKING!","36162433":"bio-rad-antibodies.com","1673deeb":"Das War's Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","97ea0239":"#PDF to CSV\nConvert Page 3 of PDF to CSV (Method 1 of 2: PyTesseract)","35a5fa65":"slideserve.com","12fbc135":"I don't know how \"Clean up the Notebook' works. But I ran the cell."}}