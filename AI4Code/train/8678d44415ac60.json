{"cell_type":{"606ebdd9":"code","a33d9ac2":"code","3447ce0a":"code","8274698a":"code","9014b9f2":"code","4f96ae25":"code","3876a813":"code","d6e894aa":"code","beb29dab":"code","49363b91":"code","2f12e6de":"code","f106ec96":"code","e82fff2d":"code","f5b74b05":"code","0a21c483":"code","e57499e1":"code","e8a30403":"code","aea478f7":"code","d903724e":"code","06fb844f":"code","511eed1a":"code","8a948fa3":"code","92dd56e4":"code","54baeb2f":"code","a44107f2":"code","01ee80ef":"code","36bcb93f":"code","ab5e2545":"code","acba125e":"code","2209b21a":"code","63d1bf87":"code","0a70a78d":"code","755ce6bc":"code","b6619354":"code","95f6c48d":"code","d3d31610":"code","b09321e6":"code","82a5a3c1":"code","0b34e9c5":"code","d66671b3":"code","b6ebcf10":"code","596e8c5e":"code","71f039c5":"code","17d3d7b3":"markdown","2f20e70a":"markdown","4ed1b398":"markdown","96216284":"markdown","5a32c88f":"markdown","8af092c8":"markdown","0ab4189e":"markdown","0acbbe69":"markdown","bfb43774":"markdown"},"source":{"606ebdd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a33d9ac2":"train_data  = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","3447ce0a":"train_data.head(10)","8274698a":"train_data.dtypes","9014b9f2":"train_data.info()","4f96ae25":"train_data.describe()","3876a813":"train_data.shape","d6e894aa":"train_data.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1 , inplace=True)","beb29dab":"train_data.dtypes","49363b91":"train_data = pd.get_dummies(train_data)","2f12e6de":"train_data.dtypes","f106ec96":"train_data.head()","e82fff2d":"corrmat = train_data.corr()\ncorrmat","f5b74b05":"# import data visualization  library\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0a21c483":"f , ax = plt.subplots(figsize=(12,8))\nsns.heatmap(corrmat, ax=ax , cmap= 'PiYG', linewidths=0.1)\nplt.show()","e57499e1":"cg = sns.clustermap(corrmat  , cmap='RdPu', linewidths=0.1)\nplt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\ncg","e8a30403":"sns.pairplot(train_data)\nplt.show()","aea478f7":"sns.countplot(x=train_data[\"Age\"] , data=train_data)\nplt.show()","d903724e":"sns.countplot(x=train_data[\"Age\"] , hue=train_data[\"Survived\"], data=train_data)\nplt.show()","06fb844f":"sns.violinplot(x=train_data['Sex_male'] , y=train_data['Survived'], hue=None, data=train_data)\nplt.show()","511eed1a":"sns.violinplot(x=train_data['Sex_female'] , y=train_data['Survived'], hue=None, data=train_data)\nplt.show()","8a948fa3":"sns.countplot(x=train_data['Sex_male'] , hue=train_data['Sex_female'])\nplt.show()","92dd56e4":"sns.countplot(x=train_data['Pclass'] , hue=train_data['Survived'])\nplt.show()","54baeb2f":"sns.distplot(x=train_data['Age'], hist=True)\nplt.show()","a44107f2":"sns.distplot(x=train_data['Survived'] , hist=True)\nplt.show()","01ee80ef":"train_data.isnull().sum()","36bcb93f":"train_data['Age'].fillna(train_data['Age'].mean() , inplace=True)","ab5e2545":"train_data.isnull","acba125e":"train_data.isnull().sum()","2209b21a":"X=train_data.drop([\"Survived\"], axis=1)\ny = train_data[\"Survived\"]","63d1bf87":"from sklearn.model_selection import train_test_split","0a70a78d":"X_train ,X_test , y_train , y_test = train_test_split(X , y , test_size=0.3, random_state=0)","755ce6bc":"print(\" X_train shape\" , X_train.shape)\nprint(\"X_test shape\" , X_test.shape)\nprint(\"y_train test \" , y_train.shape)\nprint(\"y_test shape\" , y_test.shape)","b6619354":"from sklearn.svm import SVC\nmodel = SVC(C=.1 , kernel='linear', gamma=1)","95f6c48d":"model.fit(X_train , y_train)","d3d31610":"model.score(X_test , y_test)","b09321e6":"prediction = model.predict(X_test)","82a5a3c1":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,recall_score,f1_score","0b34e9c5":"print('confusion matrix', +confusion_matrix(prediction, y_test))","d66671b3":"print (\" accuracy score of the model \", +accuracy_score(prediction , y_test))","b6ebcf10":"classification_report(prediction, y_test)","596e8c5e":"print(\"f1_score\")\nf1_score(prediction,y_test )","71f039c5":"print(\"recall score\")\nrecall_score(prediction, y_test)","17d3d7b3":"# DATA CLEANING\n","2f20e70a":"# IMPORT DATA FILES","4ed1b398":"# SPLITING OF DATA INTO DEPENDENT AND INDEPENDENT VARIABLE","96216284":"# TRAIN-TEST-SPLIT","5a32c88f":"# DATA PREPROCESSING\n","8af092c8":"# DATA VISUALIZATION","0ab4189e":"# CHECKING FOR MISSING DATA\n","0acbbe69":"# MODEL PREPARATION","bfb43774":"# CORRELATION MATRIX"}}