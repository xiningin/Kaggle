{"cell_type":{"4ea5144e":"code","2b616c2f":"code","54a0d764":"code","6f2cb755":"code","4324428e":"code","994c56d7":"code","114f6ece":"code","b4107804":"code","0a31debc":"code","854d37e8":"code","bc3ea9b5":"code","4f4fe322":"code","4c9b5c0a":"code","c574856f":"code","aaa3948b":"code","1ee691d8":"code","13955b11":"code","5970ac57":"code","04567e1f":"code","1404545c":"code","0e7877e8":"markdown","5892420a":"markdown","6e0242b6":"markdown","b452c508":"markdown","a8dabf57":"markdown","65798370":"markdown","67edfdc0":"markdown","f1beb5d0":"markdown","3dbb07a5":"markdown","749065b2":"markdown","0e78d61b":"markdown","80f20e12":"markdown","324f5b89":"markdown","25c29231":"markdown","3cb16d6f":"markdown","4bfaa7f9":"markdown","5ef92966":"markdown","dec0e50a":"markdown","039ebf6e":"markdown","0ff9461d":"markdown","b317bd41":"markdown"},"source":{"4ea5144e":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics.regression import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LinearRegression, LassoCV, Lasso\nfrom sklearn.ensemble import RandomForestRegressor","2b616c2f":"data = pd.read_csv('..\/input\/winequality-white.csv')","54a0d764":"data.head()","6f2cb755":"data.info()","4324428e":"y = data.quality\nX=data.drop(columns='quality',axis=1)\nX_train, X_holdout, y_train, y_holdout = train_test_split(X,y,test_size=0.3,random_state = 17) # you code here\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train) # you code here\nX_holdout_scaled = scaler.transform(X_holdout) # you code here","994c56d7":"linreg = LinearRegression()\nlinreg.fit(X_train_scaled,y_train) # you code here\nlinreg.coef_","114f6ece":"from sklearn.metrics import mean_squared_error\nprint(mean_squared_error(y_train,linreg.predict(X_train_scaled)))\nprint(mean_squared_error(y_holdout,linreg.predict(X_holdout_scaled)))\n\n# print(\"Mean squared error (train): %.3f\" % # you code here\n# print(\"Mean squared error (test): %.3f\" % # you code here","b4107804":"feature_names=list(data.drop(columns='quality',axis=1).columns)\nfeature_names\nlinreg_coef = pd.DataFrame({'feature_name':feature_names,'weight':linreg.coef_}) # you code here\nlinreg_coef.sort_values('weight').reset_index() # you code here","0a31debc":"lasso1 = Lasso(alpha=0.01)\nlasso1.fit(X_train_scaled,y_train) # you code here","854d37e8":"lasso1_coef = pd.DataFrame({'feature_name':feature_names,'weight':lasso1.coef_}) # you code here\nlasso1_coef.sort_values('weight') # you code here","bc3ea9b5":"alphas = np.logspace(-6, 2, 200)\nlasso_cv = LassoCV(alphas=alphas,cv=5) # you code here\nlasso_cv.fit(X_train_scaled,y_train) # you code here","4f4fe322":"lasso_cv.alpha_\n","4c9b5c0a":"lasso_cv_coef = pd.DataFrame({'feature_name':feature_names,'weight':lasso_cv.coef_}) # you code here\nlasso_cv_coef.sort_values('weight') # you code here","c574856f":"print(mean_squared_error(y_train,lasso_cv.predict(X_train_scaled)))\nprint(mean_squared_error(y_holdout,lasso_cv.predict(X_holdout_scaled)))","aaa3948b":"forest = RandomForestRegressor(random_state=17) # you code here\nforest.fit(X_train_scaled,y_train) # you code here","1ee691d8":"print(\"Mean squared error (train): %.3f\" %mean_squared_error(y_train,forest.predict(X_train_scaled))) # you code here\nprint(\"Mean squared error (cv): %.3f\" %-cross_val_score(forest,X_train_scaled,y_train,cv=5,scoring='neg_mean_squared_error').mean())\nprint(\"Mean squared error (test): %.3f\" %mean_squared_error(y_holdout,forest.predict(X_holdout_scaled))) # you code here","13955b11":"\nforest_params = {'max_depth': list(range(10, 25)), \n                 'max_features': list(range(6,12))}\nlocally_best_forest = GridSearchCV(forest,param_grid=forest_params,cv=5,n_jobs=-1) # you code here\nlocally_best_forest.fit(X_train_scaled,y_train) # you code here","5970ac57":"locally_best_forest.best_params_, locally_best_forest.best_score_","04567e1f":"print(\"Mean squared error (train): %.3f\" %mean_squared_error(y_train,locally_best_forest.predict(X_train_scaled))) # you code here\nprint(\"Mean squared error (cv): %.3f\" %-cross_val_score(locally_best_forest,X_train_scaled,y_train,cv=5,scoring='neg_mean_squared_error').mean())\nprint(\"Mean squared error (test): %.3f\" %mean_squared_error(y_holdout,locally_best_forest.predict(X_holdout_scaled))) # you code here","1404545c":"best_rf=locally_best_forest.best_estimator_\nrf_importance = pd.DataFrame({'feature_name':feature_names,'weight':best_rf.feature_importances_})\nrf_importance.sort_values(by='weight') # you code here","0e7877e8":"**Sort features by their influence on the target feature (wine quality). Beware that both large positive and large negative coefficients mean large influence on target. It's handy to use `pandas.DataFrame` here.**\n\n**<font color='red'>Question 2:<\/font> Which feature this linear regression model treats as the most influential on wine quality?**","5892420a":"<center>\n<img src=\"https:\/\/habrastorage.org\/files\/fd4\/502\/43d\/fd450243dd604b81b9713213a247aa20.jpg\">\n## Open Machine Learning Course\n<center>Author: [Yury Kashnitsky](https:\/\/www.linkedin.com\/in\/festline\/), Data Scientist at Mail.ru Group <br>\n    All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/) license.\nYou may use this material for any purpose (you can edit, correct and use it as example) exept commercial use with mandatory citation of author.","6e0242b6":"**Train LassoCV with random_state=17 to choose the best value of $\\alpha$ in 5-fold cross-validation.**","b452c508":"**Output RF's feature importance. Again, it's nice to present it as a DataFrame.**<br>\n**<font color='red'>Question 7:<\/font> What is the most important feature, according to the Random Forest model?**","a8dabf57":"**Which feature is the least informative in predicting wine quality, according to this LASSO model?**","65798370":"**Tune the `max_features` and `max_depth` hyperparameters with GridSearchCV and again check mean cross-validation MSE and MSE on holdout set.**","67edfdc0":"**We are working with UCI Wine quality dataset (no need to download it \u2013 it's already there, in course repo and in Kaggle Dataset).**","f1beb5d0":"**<font color='red'>Question 5:<\/font> What are mean squared errors of RF model on the training set, in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","3dbb07a5":"## Linear regression","749065b2":"**Train a Random Forest with out-of-the-box parameters, setting only random_state to be 17.**","0e78d61b":"**<font color='red'>Question 4:<\/font> What are mean squared errors of tuned LASSO predictions on train and holdout sets?**","80f20e12":"## Random Forest","324f5b89":"**<font color='red'>Question 1:<\/font> What are mean squared errors of model predictions on train and holdout sets?**","25c29231":"**Train a LASSO model with $\\alpha = 0.01$ (weak regularization) and scaled data. Again, set random_state=17.**","3cb16d6f":"**<font color='red'>Question 3:<\/font> Which feature is the least informative in predicting wine quality, according to the tuned LASSO model?**","4bfaa7f9":"# <center> Assignment #6 (demo).\n## <center>  Exploring OLS, Lasso and Random Forest in a regression task\n    \n<img src=https:\/\/habrastorage.org\/webt\/-h\/ns\/aa\/-hnsaaifymavmmudwip9imcmk58.jpeg width=30%>\n\n**Fill in the missing code and choose answers in [this](https:\/\/docs.google.com\/forms\/d\/1aHyK58W6oQmNaqEfvpLTpo6Cb0-ntnvJ18rZcvclkvw\/edit) web form.**","5ef92966":"**Train a simple linear regression model (Ordinary Least Squares).**","dec0e50a":"**Make conclusions about the perdormance of the explored 3 models in this particular prediction task.**","039ebf6e":"## Lasso regression","0ff9461d":"**<font color='red'>Question 6:<\/font> What are mean squared errors of tuned RF model in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","b317bd41":"**Separate the target feature, split data in 7:3 proportion (30% form a holdout set, use random_state=17), and preprocess data with `StandardScaler`.**"}}