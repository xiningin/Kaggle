{"cell_type":{"9a9347f4":"code","5ddc8bb4":"code","f1473194":"code","bec87f0f":"code","49d3fa8e":"code","3bbe97b4":"code","b44c0799":"code","378e32fe":"code","140f1ef4":"code","9bc1b558":"code","57adab42":"code","9d764366":"code","6fc8d578":"code","25580e69":"code","de19bada":"code","963dfd1b":"code","c403ad61":"code","679b99cc":"code","8b84af9f":"code","7378506e":"code","743b4e07":"code","e7b48d50":"code","f5af3001":"code","67cc26ef":"markdown","b7828b59":"markdown","ad2c5e91":"markdown","9de83a14":"markdown"},"source":{"9a9347f4":"#import necessary packages\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom operator import itemgetter","5ddc8bb4":"df = pd.read_csv(\"..\/input\/data-scientist-role-in2020\/DataScience_jobs.csv\", index_col=0)","f1473194":"df.head()","bec87f0f":"df.info()","49d3fa8e":"df = df.dropna()","3bbe97b4":"df = df.apply(lambda x: x.astype(str).str.lower())","b44c0799":"df['experience'] = df['experience'].apply(lambda x: x.split(' ')[0])","378e32fe":"df['locations'] = df['locations'].apply(lambda x: x.split(','))","140f1ef4":"df['skills'] = df['skills'].apply(lambda x: x.split('\\n'))","9bc1b558":"df['roles'] = df['roles'].apply(lambda x: x.replace('sr data scientist','senior data scientist'))","57adab42":"df['roles'] = df['roles'].apply(lambda x: x.replace('sr. data scientist','senior data scientist'))","9d764366":"df.locations.apply(pd.Series).stack().str.strip().value_counts()[:10].plot.pie(figsize=(12,10),startangle=150,autopct='%1.1f%%',fontsize=15, shadow=True)\nplt.title(\"Location Wise Data scientist Jobs\",fontsize=22)","6fc8d578":"df[\"companies\"].value_counts()[:5].plot.pie(figsize=(12,10),explode=[0.03,0.04,0.05,0.06,0.07], startangle=50,autopct='%1.1f%%',fontsize=15)\nplt.title(\"Top 5 companies with Data Science opeanings\",fontsize=25)\ncentre_circle = plt.Circle((0,0),0.72,color='gray', fc='white',linewidth=1)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.axis('equal')\nplt.show()","25580e69":"plt.figure(figsize=(12, 8))\nax = sns.countplot(x=\"roles\", data=df, order = df['roles'].value_counts()[:10].index, palette=\"rocket\")\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext= (0, 10), textcoords = 'offset points')\nax.set_title(label='Data Scientist Roles', fontsize=20)\nax.set_xlabel(xlabel='Job roles', fontsize=16)\nax.set_ylabel(ylabel='Number of opeanings', fontsize=16)\nplt.xticks(rotation=90)","de19bada":"plt.figure(figsize=(12, 8))\nax = sns.countplot(x=\"experience\", data=df, order = df['experience'].value_counts()[:10].index, palette=\"deep\")\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext= (0, 10), textcoords = 'offset points')\nax.set_title(label='Desired Experience for Data science jobs', fontsize=20)\nax.set_xlabel(xlabel='Experiences', fontsize=16)\nax.set_ylabel(ylabel='Number of opeanings', fontsize=16)\nplt.xticks(rotation=90)","963dfd1b":"df.skills.apply(pd.Series).stack().value_counts()[:32].plot(kind=\"bar\",figsize=(18,6),fontsize=15,color=\"g\")\nplt.xticks(rotation=50,ha='right')\n#plt.title(\"Top Skills for Data science\",fontsize=25)\nplt.ylabel(\"No.of Vacancies\",fontsize=20)\nplt.xlabel(\"Top Skills for Data science\",fontsize=25)\nplt.show()","c403ad61":"#lets convert the skills column into a seperate DataFrame, which makes things easy for preo processing\ndf_skills=pd.DataFrame(df.skills.apply(pd.Series).stack().value_counts()).reset_index()\ndf_skills.columns=[\"skills\",\"count\"]\ndf_skills.head()","679b99cc":"languages={}\nlanguages[\"python\"]=df_skills[\"count\"][df_skills['skills'].str.contains('python', regex=True)].sum()\nlanguages[\"r\"]=df_skills[\"count\"][df_skills['skills'].str.contains('^r$', regex=True)].sum()\nlanguages[\"matlab\"]=df_skills[\"count\"][df_skills['skills'].str.contains('matlab', regex=True)].sum()\nlanguages[\"java\"]=df_skills[\"count\"][df_skills['skills'].str.contains('java$', regex=True)].sum()\nlanguages[\"c++\"]=df_skills[\"count\"][df_skills['skills'].str.contains('c\\+', regex=True)].sum()\nlanguages[\"sas\"]=df_skills[\"count\"][df_skills['skills'].str.contains('sas', regex=True)].sum()\nlanguages[\"sql\"]=df_skills[\"count\"][df_skills['skills'].str.contains('sql', regex=True)].sum()\n\n\n#to sort the dictionary\nlanguages=dict(sorted(languages.items(), key=itemgetter(1),reverse=True))","8b84af9f":"plt.bar(languages.keys(),languages.values(),color=[\"b\",\"r\",\"g\",\"y\",\"c\",\"pink\",\"m\"])\nplt.xticks(rotation=45,fontsize=15)\nplt.title(\"Programming languages for Data science\",fontsize=18)\nplt.show()\n","7378506e":"frameworks={}\nframeworks['tensorflow']=df_skills[\"count\"][df_skills['skills'].str.contains('tensor', regex=True)].sum()\nframeworks['keras']=df_skills[\"count\"][df_skills['skills'].str.contains('keras', regex=True)].sum()\nframeworks['pytorch']=df_skills[\"count\"][df_skills['skills'].str.contains('torch', regex=True)].sum()\nplt.bar(frameworks.keys(),frameworks.values(),color=[\"g\",\"b\",\"c\"],width=.5)\nplt.xticks(rotation=70,fontsize=15)\nplt.title(\"Deep learning Frameworks\",fontsize=20)\nplt.show()\n","743b4e07":"cloud={}\ncloud['aws']=df_skills[\"count\"][df_skills['skills'].str.contains('aws', regex=True)].sum()\ncloud['azure']=df_skills[\"count\"][df_skills['skills'].str.contains('azure', regex=True)].sum()\ncloud['gcp']=df_skills[\"count\"][df_skills['skills'].str.contains('gcp')].sum()\nplt.bar(cloud.keys(),cloud.values(),color=[\"m\",\"y\",\"pink\"],width=.45)\nplt.xticks(rotation=45,fontsize=15)\nplt.title(\"Clouds for Data Science\",fontsize=20)\nplt.show()","e7b48d50":"bigdata={}\nbigdata[\"spark\"]=df_skills[\"count\"][df_skills['skills'].str.contains('spark', regex=True)].sum()\nbigdata[\"hadoop\"]=df_skills[\"count\"][df_skills['skills'].str.contains('hadoop', regex=True)].sum()\nbigdata[\"hive\"]=df_skills[\"count\"][df_skills['skills'].str.contains('hive', regex=True)].sum()\nbigdata[\"kafka\"]=df_skills[\"count\"][df_skills['skills'].str.contains('kafka', regex=True)].sum()\n\nplt.bar(bigdata.keys(),bigdata.values(),color=[\"black\",\"purple\",\"grey\",\"blue\"],width=0.6)\nplt.xticks(rotation=45,fontsize=15)\nplt.title(\"Big Data technologies\",fontsize=20)\nplt.show()","f5af3001":"# tools\ntools={}\ntools[\"tableau\"]=df_skills[\"count\"][df_skills['skills'].str.contains('tableau', regex=True)].sum()\ntools[\"power_bi\"]=df_skills[\"count\"][df_skills['skills'].str.contains('power bi', regex=True)].sum()\n\n\nplt.bar(tools.keys(),tools.values(),color=[\"orange\",\"blue\"],width=(0.4))\nplt.xticks(rotation=45,fontsize=15)\nplt.title(\"Visualization Tools\",fontsize=20)\nplt.show()","67cc26ef":"## Conclusion:\n\n#### Now I am sure you might have got some idea about the data science job market in India and what are recruiters demading from you. You do not require all the skills mentioned here though. \n\n### Kindly Upvote my work if you like it :)\n\n> Here is my other work if you want to have a look: https:\/\/www.kaggle.com\/vikasbhadoria\/notebooks","b7828b59":"![image.png](attachment:image.png)","ad2c5e91":"# Data Science Job Market in India. ","9de83a14":"#### This notebook is to support my dataset, I have plotted some very useful graphs which can give a very good visualizations regarding the job market for Data science in India. You can have a look at the dataset and come out with your own outputs. These are visualizations every aspiring data scientist in India should have a look at.\n> Key finding from the dataset are:\n\n* The top cities in India with high job openings. \n* The best hiring companies for Data science in India\n* The most important coding languages for Data science.\n* The most important skills required.\n\n#### There are also some important feature engineering steps I have done befor starting the visualizations. So here we go."}}