{"cell_type":{"031cca42":"code","9049a358":"code","9a0dfc4b":"code","7ebddb92":"code","855feb37":"code","959b161b":"code","dcc7a785":"code","72f103ef":"code","1d43f56f":"code","ade9dfad":"code","eb30fda0":"code","1bb4cdff":"code","5a5b00bf":"code","2b81d679":"code","a3825ed0":"code","b648da1b":"code","060aa1cd":"code","54889251":"code","d7f15341":"code","801eda85":"code","7df10620":"code","7d383b39":"code","4c16249e":"code","5b9d90e6":"code","2792e31e":"code","bf7d2350":"code","7ab9909b":"code","567a9334":"code","9cf1c08c":"code","c9553d9e":"code","a08c4508":"code","a642fed8":"code","7e30bb20":"code","58b90488":"code","e88f0af4":"code","91a6f4b8":"code","097194a1":"code","bc88c6c7":"code","f3395a48":"code","de664af1":"code","17dbcd1a":"code","8df415e0":"code","c19af2be":"code","b779dfc6":"code","a82f8474":"code","330f645a":"code","ad9565c9":"code","e1d33427":"markdown","3f3dce87":"markdown","864c1dbc":"markdown","437eda1b":"markdown","d610db8b":"markdown","3a322ca9":"markdown","f64198f8":"markdown","ce1484ac":"markdown","e0aaaedb":"markdown","93d4a61c":"markdown","c4d9395d":"markdown","eedf1e87":"markdown","f359413f":"markdown","05fbc88e":"markdown","8a874659":"markdown","62d4e8cd":"markdown","7500ef6e":"markdown","09dc7a39":"markdown","efac0e84":"markdown","75d8c9a9":"markdown","fc2600df":"markdown","5b7fba55":"markdown","327c2412":"markdown","8754e6de":"markdown","cefb6e16":"markdown","b53fa74b":"markdown","e15e6cc5":"markdown"},"source":{"031cca42":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nimport xgboost\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","9049a358":"DATA_PATH = \"..\/input\/pima-indians-diabetes-database\/diabetes.csv\"","9a0dfc4b":"data = pd.read_csv(DATA_PATH)\ndata.head()","7ebddb92":"data.info()","855feb37":"data.describe()","959b161b":"columns_with_wrong_data = [\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]\n\ndef replace_func(x):\n    if x == 0:\n        return np.nan\n    return x\n\nfor column in columns_with_wrong_data:\n    data[column] = data[column].map(replace_func).values","dcc7a785":"print(data.isnull().sum())\ndata.isnull().sum().plot(kind = \"bar\")\nplt.title(\"NaN values Plot\")\nplt.show()","72f103ef":"counts = data[\"Outcome\"].value_counts()\ndiag_cols = [\"Non Diabetic\", \"Diabetic\"]\ndiag_counts = [counts[0], counts[1]]\n\nnd = (diag_counts[0] \/ sum(diag_counts))*100\nd = (diag_counts[1] \/ sum(diag_counts)) * 100\n\nprint(f\"Diabetic: {d}%\")\nprint(f\"Non Diabetic: {nd}%\")\n\nprint()\n\nplt.figure(figsize = (10, 8))\nsns.barplot(x = diag_cols, y = diag_counts)\nplt.show()","1d43f56f":"print(f\"Number of unique values in Pregnancies: {len(data.Pregnancies.unique())}\")\nprint(f\"Unique values in Pregnancies: {data.Pregnancies.unique()}\")","ade9dfad":"pd.crosstab(data[\"Pregnancies\"], data[\"Outcome\"])","eb30fda0":"data.groupby(by=\"Pregnancies\")[\"Outcome\"].sum().sort_values(ascending=False).plot(kind = \"bar\")\nplt.show()","1bb4cdff":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Glucose\"])\nplt.show(\"Glucose distribution plot\")\nplt.show()","5a5b00bf":"data[\"Glucose\"].isnull().sum()","2b81d679":"gluc_imputer = SimpleImputer(strategy=\"mean\")\ndata[\"Glucose\"] = gluc_imputer.fit_transform(data[\"Glucose\"].values.reshape(-1, 1)).copy()\ndata[\"Glucose\"].isnull().sum()","a3825ed0":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Glucose\"])\nplt.show(\"Glucose distribution plot after Imputing with mean\")\nplt.show()","b648da1b":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BloodPressure\"])\nplt.title(\"BloodPressure Distribution Plot\")\nplt.show()","060aa1cd":"data[\"BloodPressure\"].isnull().sum()","54889251":"bp_imputer = SimpleImputer(strategy=\"mean\")\ndata[\"BloodPressure\"] = bp_imputer.fit_transform(data[\"BloodPressure\"].values.reshape(-1, 1)).copy()\ndata[\"BloodPressure\"].isnull().sum()","d7f15341":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BloodPressure\"])\nplt.title(\"BloodPressure Distribution Plot after impution\")\nplt.show()","801eda85":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"SkinThickness\"])\nplt.title(\"SkinThickness Distribution Plot\")\nplt.show()","7df10620":"data[\"SkinThickness\"].isnull().sum()","7d383b39":"skt_imputer = SimpleImputer(strategy=\"median\")\ndata[\"SkinThickness\"] = skt_imputer.fit_transform(data[\"SkinThickness\"].values.reshape(-1, 1)).copy()\ndata[\"SkinThickness\"].isnull().sum()","4c16249e":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"SkinThickness\"])\nplt.title(\"SkinThickness Distribution Plot after impution\")\nplt.show()","5b9d90e6":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Insulin\"])\nplt.title(\"Insulin Distribution Plot\")\nplt.show()","2792e31e":"data[\"Insulin\"].isnull().sum()","bf7d2350":"percent_of_missing = (data[\"Insulin\"].isnull().sum() \/ data.shape[0]) *100\nprint(f\"{percent_of_missing}% of Insulin data is missing.\")","7ab9909b":"insulin_imputer = SimpleImputer(strategy=\"median\")\ndata[\"Insulin\"] = insulin_imputer.fit_transform(data[\"Insulin\"].values.reshape(-1, 1)).copy()\ndata[\"Insulin\"].isnull().sum()","567a9334":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Insulin\"])\nplt.title(\"Insulin Distribution Plot after imputing\")\nplt.show()","9cf1c08c":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BMI\"])\nplt.title(\"BMI Distribution Plot\")\nplt.show()","c9553d9e":"data[\"BMI\"].isnull().sum()","a08c4508":"bmi_imputer = SimpleImputer(strategy=\"mean\")\ndata[\"BMI\"] = bmi_imputer.fit_transform(data[\"BMI\"].values.reshape(-1, 1)).copy()\ndata[\"BMI\"].isnull().sum()","a642fed8":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BMI\"])\nplt.title(\"BMI Distribution Plot after imputation\")\nplt.show()","7e30bb20":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"DiabetesPedigreeFunction\"])\nplt.title(\"DiabetesPedigreeFunction Distribution Plot\")\nplt.show()","58b90488":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Age\"])\nplt.title(\"Age Distribution Plot\")\nplt.show()","e88f0af4":"continuous_data_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']","91a6f4b8":"plt.figure(figsize = (11,7))\nsns.heatmap(data[continuous_data_cols].corr(), center = 0, annot = True)\nplt.title(\"Correlation Plot\")\nplt.show()","097194a1":"plt.figure(figsize = (11,7))\nsns.pairplot(data[continuous_data_cols + [\"Outcome\"]], hue = \"Outcome\")\nplt.show()","bc88c6c7":"all_columns = list(data.columns)\nX = data[all_columns[:-1]]\ny = data[all_columns[-1]]","f3395a48":"models = {\n    \"xgb_classifier\": XGBClassifier(eval_metric=\"logloss\"),\n    \"rf_model\": RandomForestClassifier(random_state = 18),\n    \"svm_model\":SVC(),\n    \"logistic_regression\":LogisticRegression(),\n    \"ada_boost\": AdaBoostClassifier(RandomForestClassifier(random_state = 18))\n}\n\nfor model_name in models:\n    print(f\"Model Name: {model_name}\")\n    print(\"Cross validation Scores\")\n    cv_scores = cross_val_score(make_pipeline(StandardScaler(), models[model_name]), X, y, cv = 5)\n    print(f\"Min Score: {min(cv_scores)}\")\n    print(f\"Max Score: {max(cv_scores)}\")    \n    print(f\"Mean Score: {np.mean(cv_scores)}\")\n    print()","de664af1":"X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size = 0.2, random_state = 0)\nprint(f\"Train Data: {X_train.shape}, {y_train.shape}\")\nprint(f\"Train Data: {X_test.shape}, {y_test.shape}\")","17dbcd1a":"counter = Counter(y_train)\ncounter","8df415e0":"upsample = SMOTE()\nX_train, y_train = upsample.fit_resample(X_train, y_train)\ncounter = Counter(y_train)\nprint(counter)","c19af2be":"print(f\"Total Data after Upsampling: {len(X_train)}\")","b779dfc6":"print(f\"Train Data: {X_train.shape}, {y_train.shape}\")\nprint(f\"Train Data: {X_test.shape}, {y_test.shape}\")","a82f8474":"logistic_pipeline = make_pipeline(StandardScaler(), LogisticRegression())\nlogistic_pipeline.fit(X_train, y_train)\n\n# Accuray On Test Data\npredictions = logistic_pipeline.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy on Test Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y_test, predictions)}\")\nprint(f\"Recall Score: {recall_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nplot_confusion_matrix(logistic_pipeline, X_test, y_test)\nplt.title(\"Confusion Matrix for Test Data\")\nplt.show()\n\nprint()\n\n# Accuray On Whole Data\npredictions = logistic_pipeline.predict(X.values)\naccuracy = accuracy_score(y, predictions)\nprint(f\"Accuracy on Whole Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y, predictions)}\")\nprint(f\"Recall Score: {recall_score(y, predictions)}\")\nprint(f\"F1 Score: {f1_score(y, predictions)}\")\nplot_confusion_matrix(logistic_pipeline, X.values, y)\nplt.title(\"Confusion Matrix for Whole Data\")\nplt.show()","330f645a":"rf_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier(random_state = 18))\nrf_pipeline.fit(X_train, y_train)\n\n# Accuray On Test Data\npredictions = rf_pipeline.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy on Test Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y_test, predictions)}\")\nprint(f\"Recall Score: {recall_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nplot_confusion_matrix(rf_pipeline, X_test, y_test)\nplt.title(\"Confusion Matrix for Test Data\")\nplt.show()\n\nprint()\n\n# Accuray On Whole Data\npredictions = rf_pipeline.predict(X.values)\naccuracy = accuracy_score(y, predictions)\nprint(f\"Accuracy on Whole Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y, predictions)}\")\nprint(f\"Recall Score: {recall_score(y, predictions)}\")\nprint(f\"F1 Score: {f1_score(y, predictions)}\")\nplot_confusion_matrix(rf_pipeline, X.values, y)\nplt.title(\"Confusion Matrix for Whole Data\")\nplt.show()","ad9565c9":"ada_pipeline = make_pipeline(StandardScaler(), AdaBoostClassifier(RandomForestClassifier(random_state = 18)))\nada_pipeline.fit(X_train, y_train)\n\n# Accuray On Test Data\npredictions = ada_pipeline.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy on Test Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y_test, predictions)}\")\nprint(f\"Recall Score: {recall_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nplot_confusion_matrix(ada_pipeline, X_test, y_test)\nplt.title(\"Confusion Matrix for Test Data\")\nplt.show()\n\nprint()\n\n# Accuray On Whole Data\npredictions = ada_pipeline.predict(X.values)\naccuracy = accuracy_score(y, predictions)\nprint(f\"Accuracy on Whole Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y, predictions)}\")\nprint(f\"Recall Score: {recall_score(y, predictions)}\")\nprint(f\"F1 Score: {f1_score(y, predictions)}\")\nplot_confusion_matrix(ada_pipeline, X.values, y)\nplt.title(\"Confusion Matrix for Whole Data\")\nplt.show()","e1d33427":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>There are 5 missing data points in the Glucose column. From the distribution plot we can observe that there is no much skewness present in the data. So, let us replace the missing values with mean of the data.\n<\/div>","3f3dce87":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>We can notice that Logistic Regression, AdaBoost Model, RandomForest Model are performing better than remaining models.\n<\/div>","864c1dbc":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>There is no multicollinearity problem in this data.\n<\/div>","437eda1b":"<b>Analyzing Insulin Column<\/b>","d610db8b":"## Bivariate Analysis","3a322ca9":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>There are 35 missing data points in the BloodPressure column. From the distribution plot we can observe that there is no skewness present in the data. So, let us replace the missing values with mean of the data.\n<\/div>","f64198f8":"<b>Analyzing Glucose Column<\/b>","ce1484ac":"<b>Analyzing SkinThickness Column<\/b>","e0aaaedb":"## Logistic Regression","93d4a61c":"## Using Cross Validation for Base Model Selection","c4d9395d":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>From the above table we can observe that the minimum values for the features Glucose, BloodPressure, SkinThickness, Insulin, BMI is 0 which is impossible and doesn't make any sense. Thus let us replace the 0 in those feature with NaN, later with which we can deal in Univariate Analysis.\n<\/div>","eedf1e87":"<b>Analyzing BloodPressure Column<\/b>","f359413f":"## Upsampling using SMOTE","05fbc88e":"## Adaboost Classifier","8a874659":"## Univariate Analysis","62d4e8cd":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>From the above plot we can observe that the data is imbalanced. So we need to perform Upsampling.\n<\/div>","7500ef6e":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>From the above plot we can observe that the patients with less number of pregnancies ar more prone to diabetes.\n<\/div>","09dc7a39":"## RandomForest Classifier","efac0e84":"<b>Analyzing Age Column<\/b>","75d8c9a9":"## Splitting the data into train and test","fc2600df":"<b>Analyzing Pregnancies Column<\/b>","5b7fba55":"<b>Analyzing Outcome<\/b>","327c2412":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION<\/b><br\/>There are 227 missing data points in the SkinThickness column. From the distribution plot we can observe that the SkinThickness data right skewed. So, let us replace the missing values with median of the data.\n<\/div>","8754e6de":"<div style=\"color:black;background-color:lightblue;border-radius:10px;padding:20px;\">\n<b>RESULT<\/b><br\/>After extensive Data Analysis, Feature Engineering and Modeling. RandomForestClassifier out performed other models with a recall score of 0.80 and accuracy of 82.46% on test data and recall score of 0.96 and accuracy of 96.48% on whole data.\n    \n    \n<div align=\"center\" style=\"color:black;background-color:lightblue\">\n<b>Please do Upvote this notebook if you liked my work.<\/b>\n<\/div>\n<\/div>","cefb6e16":"## Exploring the data","b53fa74b":"<b>Analyzing BMI Column<\/b>","e15e6cc5":"## Diabetes Prediction: Extensive EDA, Feature Engineering, Visualizations and Modeling\n\n<div align=\"center\">\n    <img src=\"https:\/\/cdn-a.william-reed.com\/var\/wrbm_gb_food_pharma\/storage\/images\/publications\/food-beverage-nutrition\/nutraingredients-asia.com\/news\/regulation-policy\/fiji-s-diabetes-epidemic-nation-already-exceeding-who-s-predicted-rate-for-2030\/8258832-1-eng-GB\/Fiji-s-diabetes-epidemic-Nation-already-exceeding-WHO-s-predicted-rate-for-2030_wrbm_large.jpg\" alt=\"diabetes image\" width=\"500\" height=\"300\" style=\"border-radius:10px;\"\/>\n\n<\/div>\n\n<b>Data Dictionary<\/b>\n<ul>\n    <li>Pregnancies: Number of times pregnant<\/li>\n    <li>Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test<\/li>\n    <li>BloodPressure: Diastolic blood pressure (mm Hg)<\/li>\n    <li>SkinThickness: Triceps skin fold thickness (mm)<\/li>\n    <li>Insulin: 2-Hour serum insulin (mu U\/ml)<\/li>\n    <li>BMI: Body mass index (weight in kg\/(height in m)^2)<\/li>\n    <li>DiabetesPedigreeFunction: Diabetes pedigree function<\/li>\n    <li>Age: Age (years)<\/li>\n    <li>Outcome: Class variable (0 or 1)<\/li>\n<\/ul>"}}