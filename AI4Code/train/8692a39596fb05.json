{"cell_type":{"13845573":"code","0584de51":"code","30dcb85c":"code","314e419e":"code","163bf17d":"code","cc15779e":"code","d230f6d7":"code","a2a6d8e3":"code","f6cc2e13":"code","ec1b6e4e":"code","e14de232":"code","502645f3":"code","ada25cf1":"code","f595ef56":"code","47ffdc75":"code","dd5f0c30":"code","5dbed638":"code","8ac48461":"code","05420c3f":"code","fc316e30":"code","631ffaca":"code","8b7099f7":"code","181e7da6":"code","8b0ef6f0":"code","67ca58dd":"code","195f9b2d":"code","a63f826d":"code","ff46c148":"code","35524a6c":"code","96b526fd":"code","a9734752":"code","13f06c01":"code","f0d665e4":"code","f1b94f2e":"code","93334b2e":"code","fdeb569d":"code","f6320330":"code","2e398e8b":"code","65915839":"code","72af5806":"code","c99fc40f":"code","eb231583":"code","01f22580":"code","cfc0d25f":"code","62a64165":"code","393160f7":"code","a53a4615":"markdown","f5f2254b":"markdown","6fabf830":"markdown","a25e3e4f":"markdown","1d31fae8":"markdown","7ba0f1a6":"markdown","77c3ce97":"markdown","4eae63cc":"markdown","f70de66e":"markdown","c98afc78":"markdown","64d98c18":"markdown"},"source":{"13845573":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split","0584de51":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","30dcb85c":"import warnings\nwarnings.filterwarnings('ignore')","314e419e":"physical_devices = tf.config.list_physical_devices('GPU') \ntf.config.experimental.set_memory_growth(physical_devices[0], True)\nprint(physical_devices)","163bf17d":"df = pd.read_csv('\/kaggle\/input\/kc-house\/kc_house_data.csv')\ndf.head()","cc15779e":"print('Number of entries {}'.format(len(df)))\nprint('Column names in our dataset ->\\n', list(df.columns))","d230f6d7":"corr = df.corr()\nsns.set(font_scale = .7)\nplt.figure(figsize=(15,8))\nsns.heatmap(\n    corr,\n    annot= True,\n    fmt='.2f',\n    cmap='BuGn',\n)","a2a6d8e3":"# dropping high correlation columns, unused columns and target column\ndata = df.drop(['id','lat','long','price'],axis=1)\ndata.head()","f6cc2e13":"y = df[['price']]\ny.head()","ec1b6e4e":"data['date'] = data['date'].map(lambda x : int(x[:4]))\ndata[['date']].head()","e14de232":"data['selling_age'] = data['date'] - data['yr_built']\ndata['was_renovated'] = (data['yr_renovated'] != 0).astype(int)\ndata[['date','yr_built','yr_renovated','was_renovated','selling_age']].head()","502645f3":"data['bedrooms\/bathrooms'] = data['bedrooms'] + data['bathrooms']\ndata[['bedrooms','bathrooms','bedrooms\/bathrooms']].head()","ada25cf1":"data = data.drop(['date','yr_built','yr_renovated','bedrooms','bathrooms'],axis=1)\ndata.head()","f595ef56":"boxplot_columns = [\n'bedrooms\/bathrooms',\n'condition',\n'grade',\n'view',\n'floors',\n]\ncontinous_columns = [x for x in data.columns if x not in boxplot_columns]\ncontinous_columns","47ffdc75":"i = 0\nfor col in boxplot_columns:\n    i += 1\n    if(i % 2 == 1):\n        plt.figure(figsize=(16,15))\n    plt.subplot(int(len(boxplot_columns) \/ 2) + 1,2,i)\n    plt.title('{} vs price boxplot'.format(col))\n    plt.xlabel(col)\n    sns.boxplot(data[col],y['price'])\n    plt.xticks(\n        rotation=45, \n        horizontalalignment='right',\n        fontweight='light',  \n    )\ni = 0\nfor col in continous_columns:\n    i += 1\n    if(i % 2 == 1):\n        plt.figure(figsize=(16,15))\n    plt.subplot(int(len(continous_columns) \/ 2) + 1,2,i)\n    plt.title('{} vs price'.format(col))\n    plt.xlabel(col)\n    plt.ylabel('price')\n    sns.scatterplot(data[col],y['price'])\n    plt.xticks(\n        rotation=45, \n        horizontalalignment='right',\n        fontweight='light',  \n    )\nplt.show()","dd5f0c30":"categorical = [\n'waterfront',\n'was_renovated',\n'zipcode',\n'view',\n'condition'\n]\ncontinous = [ col for col in data.columns if col not in categorical]\ncontinous","5dbed638":"ss = preprocessing.StandardScaler()\nconti_array = ss.fit_transform(data[continous])\nconti_df = pd.DataFrame(conti_array,columns=continous)\nconti_df.head()","8ac48461":"zipcode = pd.get_dummies(data['zipcode'])\nzipcode.columns = ['Zip_'+str(i) for i in zipcode.columns]\nzipcode.head()","05420c3f":"view = pd.get_dummies(data['view'])\nview.columns = ['View_'+ str(i+1) for i in range(len(view.columns))]\nview.head()","fc316e30":"condition = pd.get_dummies(data['condition'])\ncondition.columns = ['Condition_' + str(i) for i in condition.columns]\ncondition.head()","631ffaca":"X = pd.concat([\n    conti_df,\n    data[['waterfront','was_renovated']],\n    view,\n    condition,\n    zipcode\n],axis=1)\nX.head()","8b7099f7":"X.columns","181e7da6":"y.head()","8b0ef6f0":"train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state = 69)\nprint('Training dataset shape {}'.format(train_x.shape))\nprint('Testing dataset shape {}'.format(test_x.shape))","67ca58dd":"# first linear regression using classic ML\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(train_x, train_y)","195f9b2d":"print('Training score -> {}'.format(lr.score(train_x, train_y)))\nprint('Testing score -> {}'.format(lr.score(test_x, test_y)))","a63f826d":"pred_train = lr.predict(train_x)\npred_test = lr.predict(test_x)\n\nprint('Training r2 score -> {}'.format(r2_score(train_y, pred_train)))\nprint('Testing r2 score -> {}'.format(r2_score(test_y, pred_test)))","ff46c148":"# using keras\nmodel = Sequential()\nmodel","35524a6c":"model.add(\n    Dense(\n        # one neuron will be used for this linear regression\n        1,\n        input_shape = (1,),\n        # linear regression\n        activation = 'linear'\n    )\n)","96b526fd":"optimizer = tf.keras.optimizers.Adam(0.05)\nmodel.compile(loss='mse',optimizer=optimizer,metrics=['mae'])","a9734752":"model.summary()","13f06c01":"weights = model.layers[0].get_weights()\nprint('bias ->\\n',weights[1])\nprint('weights ->\\n',weights[0])","f0d665e4":"history = model.fit(train_x['sqft_living15'],train_y, validation_split=0.2, epochs=300, verbose=1)","f1b94f2e":"# to visualize\ndef plot_history(history):\n    plt.figure(figsize=(15,15))\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Abs Error')\n    plt.plot(history.epoch, np.array(history.history['mae']),label='train_loss')\n    plt.plot(history.epoch, np.array(history.history['val_mae']),label='val_loss')\n    plt.legend()\n    plt.show()","93334b2e":"plot_history(history)","fdeb569d":"result = model.predict(train_x['sqft_living15'])\ntest_result = model.predict(test_x['sqft_living15']).flatten()\n\nprint('R2 score for train data using 1 neuron -> ',r2_score(train_y, result))\nprint('R2 score for test data using 1 neuron-> ',r2_score(test_y, test_result))","f6320330":"# using keras\nnn_model = Sequential()\nnn_model","2e398e8b":"# input layer\nnn_model.add(\n    Dense(\n        # 64 neurons will be used for this linear regression\n        64,\n        # input shape\n        input_shape = (X.shape[1],),\n        activation = tf.nn.relu\n    )\n)\n# hidden layer\nnn_model.add(\n    Dense(\n        # 64 neurons for hidden layer\n        64,\n        activation = tf.nn.relu\n    )\n)\n# output layer\nnn_model.add(\n    Dense(\n        # 1 neurons as output neuron\n        1\n    )\n)\n","65915839":"optimizer = tf.keras.optimizers.Adam(0.01)\nnn_model.compile(loss='mse',optimizer=optimizer,metrics=['mae'])","72af5806":"nn_model.summary()","c99fc40f":"weights = nn_model.layers[0].get_weights()\nprint('bias ->\\n',weights[1])\nprint('weights ->\\n',weights[0])","eb231583":"nn_history = nn_model.fit(train_x, train_y, validation_split=0.2, epochs=100, verbose=1)","01f22580":"plot_history(nn_history)","cfc0d25f":"nn_result = nn_model.predict(train_x)\nnn_test_result = nn_model.predict(test_x).flatten()\n\nprint('R2 score for train data using hidden layer -> ',r2_score(train_y, nn_result))\nprint('R2 score for test data using hidden layer -> ',r2_score(test_y, nn_test_result))","62a64165":"plt.figure(figsize=(24,8))\nplt.subplot(131)\nplt.title('Linear Regression using classic ML')\nplt.xlabel('predictions')\nplt.ylabel('true labels')\nplt.scatter(train_y,pred_train)\nplt.subplot(132)\nplt.xlabel('predictions')\nplt.ylabel('true labels')\nplt.title('Linear Regression using Single Neuron Networks')\nplt.scatter(train_y,result)\nplt.subplot(133)\nplt.xlabel('predictions')\nplt.ylabel('true labels')\nplt.title('Linear Regression using Neural Network with Hidden layer')\nplt.scatter(train_y,nn_result)\nplt.show()","393160f7":"plt.figure(figsize=(24,8))\nplt.subplot(131)\nplt.title('Linear Regression using classic ML')\nplt.xlabel('predictions')\nplt.ylabel('true labels')\nplt.scatter(test_y,pred_test,color='blue',label='Classic ML')\nplt.legend()\nplt.subplot(132)\nplt.xlabel('predictions')\nplt.ylabel('true labels')\nplt.title('Linear Regression using Single Neuron Networks')\nplt.scatter(test_y,test_result,color='grey',label='Neural Network with single neuron')\nplt.legend()\nplt.subplot(133)\nplt.title('Linear Regression using Neural Network with Hidden layer')\nplt.xlabel('predictions')\nplt.ylabel('true labels')\nplt.scatter(test_y,nn_test_result,color='green', label='Neural network with hidden layer')\nplt.legend()\nplt.show()","a53a4615":"# Creating Train and Test Data by preprocessing the data","f5f2254b":"# Linear regression using Neuron Network (Single Neuron)","6fabf830":"# Linear Regression using Neural Network (Hidden layer using Keras)","a25e3e4f":"Correlation Matrix","1d31fae8":"# Linear Regression using Classic ML (sklearn)","7ba0f1a6":"# Imports","77c3ce97":"# Feature vs Target Plots\n    Plotting every feature against house price to find relations\/patterns","4eae63cc":"# Feature Engineering\n    Use Sale Date, Year Built and Renovation data to create more features","f70de66e":"# Comparing predictions results\n    -> for three different implementations of linear regression","c98afc78":"# Read dataset","64d98c18":" Boxplot for categorical features and Scatter plot for continous features"}}