{"cell_type":{"775b261c":"code","fe60ffb2":"code","11bb9b46":"code","6e8a6922":"code","3145aba1":"code","758207da":"code","eb925f41":"code","fd78b133":"code","62c42918":"code","6bb55db0":"markdown","a4c049e3":"markdown","911adb2a":"markdown","865657f7":"markdown"},"source":{"775b261c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe60ffb2":"import torch\nimport torchvision\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image, ImageDraw\nimport xml.etree.ElementTree as ET\n\nimages_dir = '\/kaggle\/input\/gravel-sand-wood\/Dataset\/valid\/images\/'\nannotations_dir = '\/kaggle\/input\/gravel-sand-wood\/Dataset\/train\/labels\/'","11bb9b46":"sample_id = 40\n\nsample_image_path = f'\/kaggle\/input\/gravel-sand-wood\/Dataset\/valid\/images\/valid_{sample_id}.jpg'\nsample_annot_path = f'\/kaggle\/input\/gravel-sand-wood\/Dataset\/valid\/labels\/valid_{sample_id}.txt'","6e8a6922":"sample_image = Image.open(sample_image_path)\nsample_image","3145aba1":"with open(sample_annot_path) as annot_file:\n    print(''.join(annot_file.readlines()))","758207da":"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n    pretrained=True, progress=True, num_classes=91, pretrained_backbone=True)\n\nmodel","eb925f41":"model.eval()\n\nnp_sample_image = np.array(sample_image.convert(\"RGB\"))\n\ntransformed_img = torchvision.transforms.transforms.ToTensor()(\n        torchvision.transforms.ToPILImage()(np_sample_image))\n\nresult = model([transformed_img])\n\nresult","fd78b133":"COCO_INSTANCE_CATEGORY_NAMES = [\n     'caterpillar','__background__', 'vehicle', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N\/A', 'stop sign',\n    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n    'elephant', 'bear', 'zebra', 'giraffe', 'N\/A', 'backpack', 'umbrella', 'N\/A', 'N\/A',\n    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n    'bottle', 'N\/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N\/A', 'dining table',\n    'N\/A', 'N\/A', 'toilet', 'N\/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N\/A', 'book',\n    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']","62c42918":"cater_id = 1\ncater_boxes = [x.detach().numpy().tolist() for i, x in enumerate(result[0]['boxes']) if result[0]['labels'][i] == cater_id]\ncater_boxes","6bb55db0":"#Coco doesn't have Caterpillar. So, no box for now. ","a4c049e3":"#Since the rest of the script is to Parse xml, I couldn't apply to those files since I don't know how to make it.","911adb2a":"#Codes from https:\/\/www.kaggle.com\/mpwolke\/i-tawt-i-taw-a-puddy-tat-r-cnn-pytorch","865657f7":"![](https:\/\/gravelwood.com\/wp-content\/uploads\/2016\/06\/gravelwood-logo.png)gravelwood.com"}}