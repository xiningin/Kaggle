{"cell_type":{"399d7c1a":"code","4028a7d0":"code","84a94cf5":"code","159703f8":"code","b430d004":"code","752cc36c":"code","0a521b42":"code","1dacec92":"code","738c9a10":"code","209e4594":"code","c58f72f8":"code","05f8bb32":"code","23bb0ae4":"code","d7b3b3bf":"code","4709fc57":"code","61420aa5":"code","420564a0":"code","fc0017d0":"markdown","27940fab":"markdown","93de199d":"markdown","b7cc915b":"markdown","e8541f2e":"markdown","acf099ae":"markdown","43a8832f":"markdown","368ffe30":"markdown","79ba3833":"markdown","8010a14b":"markdown"},"source":{"399d7c1a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4028a7d0":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings; warnings.filterwarnings(action='once')\n\nlarge = 22; med = 16; small = 12\nparams = {'axes.titlesize': large,\n          'legend.fontsize': med,\n          'figure.figsize': (16, 10),\n          'axes.labelsize': med,\n          'axes.titlesize': med,\n          'xtick.labelsize': med,\n          'ytick.labelsize': med,\n          'figure.titlesize': large}\nplt.rcParams.update(params)\nplt.style.use('seaborn-whitegrid')\nsns.set_style(\"white\")\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","84a94cf5":"df = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\",header=0)\nwomen_df = df.drop(0,axis=0)[df.Q2 == 'Woman']\nw_stats_df = women_df.describe()\nw_stats_df","159703f8":"w_prof_df = women_df[(women_df.Q5 !='Student') & (women_df.Q5 != 'Currently not employed') ]\nw_prof_stats = w_prof_df.describe()","b430d004":"basic_stats = w_stats_df.loc['top',:]\nbasic_stats = basic_stats[['Q1','Q3','Q4','Q5','Q6','Q20','Q15','Q8','Q11']].rename( {'Q1': \"Age Group\",\\\n                                                                                   'Q3': 'Location',\\\n                                                                                   'Q4': 'Education',\\\n                                                                                   'Q5': 'Role',\\\n                                                                                   'Q6': 'Experience',\\\n                                                                                   'Q20': 'Industry',\\\n                                                                                   'Q15': 'ML Experience',\\\n                                                                                   'Q8':'Coding Language-Recommended',\\\n                                                                                     'Q11':'Computing Platform'})\n\n\nprof_demog = w_prof_stats.loc['top',['Q1','Q3','Q4','Q5','Q6','Q20']].rename( {'Q1': \"Age Group\",\\\n                                                                                   'Q3': 'Location',\\\n                                                                                   'Q4': 'Education',\\\n                                                                                   'Q5': 'Role',\\\n                                                                                   'Q6': 'Experience',\\\n                                                                                   'Q20': 'Industry'})\nprof_ml_stats =  w_prof_stats.loc['top',['Q15']].rename({'Q15':'ML Experience'})\nprof_ml_stats['Coding Language'] = w_prof_stats.loc['top',w_prof_stats.loc['freq':,'Q7_Part_1':'Q7_OTHER']\\\n                                                .transpose().sort_values(by = 'freq',ascending=False).iloc[0].name]\nprof_ml_stats['IDE'] = w_prof_stats.loc['top',w_prof_stats.loc['freq':,'Q9_Part_1':'Q9_OTHER']\\\n                                    .transpose().sort_values(by = 'freq',ascending=False).iloc[0].name]\n#basic_stats['Hosted Notebook'] = w_stats_df.loc['top',w_stats_df.loc['freq':,'Q10_Part_1':'Q10_OTHER'].transpose().sort_values(by = 'freq',ascending=False).iloc[0].name]\nprof_ml_stats['ML Frameworks'] =  w_prof_stats.loc['top',w_prof_stats.loc['freq':,'Q16_Part_1':'Q16_OTHER']\\\n                                                 .transpose().sort_values(by = 'freq',ascending=False).iloc[0].name]\nprof_ml_stats['ML Algorithms'] =  w_prof_stats.loc['top',w_prof_stats.loc['freq':,'Q17_Part_1':'Q17_OTHER']\\\n                                                 .transpose().sort_values(by = 'freq',ascending=False).iloc[0].name]\n#basic_stats['Cloud Platform'] =  w_stats_df.loc['top',w_stats_df.loc['freq':,'Q16_Part_1':'Q16_OTHER'].transpose().sort_values(by = 'freq',ascending=False).iloc[0].name]\nprof_ml_stats['ML Products'] =  w_prof_stats.loc['top',w_prof_stats.loc['freq':,'Q31_A_Part_1':'Q31_A_OTHER']\\\n                                               .transpose().sort_values(by = 'freq',ascending=False).iloc[0].name]","752cc36c":"fig,ax = plt.subplots(3)\nfig.set_size_inches(70,50)\nbasic_demographics = basic_stats[['Age Group','Location','Education','Role','Experience','Industry']]\ntable =  ax[0].table(cellText=[basic_demographics.apply(lambda x: x.replace(' ','\\n').replace('\/','\/\\n'))],\\\n                  colLabels = [x.replace(' ','\\n').replace('-','-\\n') for x in basic_demographics.index],\\\n                      colLoc='center',cellLoc='center',\\\n                      loc='center',bbox=(0.01,0.3,0.9,0.6))\ntable.auto_set_font_size(False)\ntable.set_fontsize(50)\nax[0].axis('off')\nax[0].axis('tight')\nax[0].set_title('Demographics-General',fontdict={'fontsize':100})\n\ntable =  ax[1].table(cellText=[prof_demog.apply(lambda x: x.replace(' ','\\n').replace('\/','\/\\n'))],\\\n                  colLabels = [x.replace(' ','\\n').replace('-','-\\n') for x in prof_demog.index],\\\n                      colLoc='center',cellLoc='center',\\\n                      loc='center',bbox=(0.01,0.3,0.9,0.6))\ntable.auto_set_font_size(False)\ntable.set_fontsize(50)\nax[1].axis('off')\nax[1].axis('tight')\nax[1].set_title('Demographics-Professional',fontdict={'fontsize':100})\n\ntable =  ax[2].table(cellText=[prof_ml_stats.apply(lambda x: x.replace(' ','\\n').replace('\/','\/\\n'))],\\\n                  colLabels = [x.replace(' ','\\n').replace('-','-\\n') for x in prof_ml_stats.index],\\\n                      colLoc='center',cellLoc='center',\\\n                      loc='center',bbox=(0.01,0.3,0.9,0.6))\ntable.auto_set_font_size(False)\ntable.set_fontsize(50)\nax[2].axis('off')\nax[2].axis('tight')\nax[2].set_title('Machine Learning-Professional',fontdict={'fontsize':100})\nplt.show()","0a521b42":"ds_rs_w_df = women_df[(women_df.Q5 == 'Data Scientist') | (women_df.Q5 == 'Research Scientist')]\nfig,((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\nfig.set_size_inches(50,50)\n#age groups\nax1.pie(ds_rs_w_df['Q1'].value_counts(),labels =ds_rs_w_df['Q1'].value_counts().index,\\\n        autopct='%d%%',colors=plt.cm.RdYlGn_r(np.linspace(1, 0.5, 11)),textprops={'fontsize': 30})\nax1.set_title('Age Groups',fontsize=60)\n'''#Role\nax2.pie(ds_rs_w_df['Q5'].value_counts(),labels=ds_rs_w_df['Q5'].value_counts().index,rotatelabels=True,\\\n        autopct='%d%%',colors=plt.cm.RdYlGn_r(np.linspace(1, 0.5, 15)),textprops={'fontsize': 25})\n\nax2.set_title('Roles',fontsize=20)'''\n\n#countries\ncdf = ds_rs_w_df[ds_rs_w_df.Q3 != 'Other']['Q3'].value_counts().sort_values(ascending=False).reset_index()\nax3.pie(cdf.iloc[0:10]['Q3'],labels=cdf.iloc[0:10]['index'],autopct='%d%%',\\\n        colors=plt.cm.RdYlGn_r(np.linspace(1, 0.5, 10)),textprops={'fontsize': 30})\nax3.set_title('Countries-Top 10',fontsize=60)\n\n#education levels\nax4.pie(ds_rs_w_df['Q4'].value_counts(),labels=ds_rs_w_df['Q4'].value_counts().index,\\\n        colors=plt.cm.RdYlGn_r(np.linspace(0.5, 2, 7)),autopct='%d%%',textprops={'fontsize': 30})\n\nax4.set_title('Education',fontsize=60)\n\n#Experience level\nax2.pie(ds_rs_w_df['Q6'].value_counts(),labels=ds_rs_w_df['Q6'].value_counts().index,\\\n        colors=plt.cm.RdYlGn_r(np.linspace(0.5, 2, 7)),autopct='%d%%',textprops={'fontsize': 30})\n\nax2.set_title('Experience Level',fontsize=60)\n#ax6.set_axis_off()\nplt.show()","1dacec92":"men_df = df.drop(0,axis=0)[df.Q2 == 'Man']\nfig,((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\nfig.set_size_inches(15,15)\n#countries\ncdf = women_df[women_df.Q3 != 'Other']['Q3'].value_counts().sort_values(ascending=False).reset_index()\nax1.pie(cdf.iloc[0:10]['Q3'],labels=cdf.iloc[0:10]['index'],autopct='%d%%',\\\n        colors=plt.cm.RdYlGn_r(np.linspace(1, 0.5, 10)),textprops={'fontsize': 12})\nax1.set_title('Countries-Top 10',fontsize=20)\n\n#countries\ncdf = men_df[men_df.Q3 != 'Other']['Q3'].value_counts().sort_values(ascending=False).reset_index()\nax2.pie(cdf.iloc[0:10]['Q3'],labels=cdf.iloc[0:10]['index'],autopct='%d%%',\\\n        colors=plt.cm.YlGnBu(np.linspace(0,0.7, 10)),textprops={'fontsize': 12},rotatelabels=True)\nax2.set_title('Countries-Top 10',fontsize=20)\n\n#Experience level\nax3.pie(women_df['Q6'].value_counts(),labels=women_df['Q6'].value_counts().index,\\\n        colors=plt.cm.RdYlGn_r(np.linspace(0.5, 2, 7)),autopct='%d%%',textprops={'fontsize': 12})\nax3.set_title('Experience Level',fontsize=20)\n#Experience level\nax4.pie(men_df['Q6'].value_counts(),labels=men_df['Q6'].value_counts().index,\\\n        colors=plt.cm.YlGnBu(np.linspace(0,0.7, 7)),autopct='%d%%',textprops={'fontsize': 12})\n\nax4.set_title('Experience Level',fontsize=20)\nplt.show()","738c9a10":"import itertools\nindustry_series = w_prof_df['Q20'].value_counts()\ncmp_size_series = w_prof_df.groupby('Q20')['Q21'].value_counts()\n\nind_size_ct = pd.crosstab(ds_rs_w_df['Q20'],ds_rs_w_df['Q21']).stack().reset_index(name='value')\n#fig,ax = plt.subplots()\nfig,ax = plt.subplots()\nfig.set_size_inches(10,10)\n#ax = ct_top10_ocp.plot.scatter('Q5','Q3',s=ct_top10_ocp.value\/2,color=plt.cm.Blues_r(np.linspace(0,0.9,150)))\nc=[np.linspace(i,0.5,5) for i in range(len(list(w_prof_df['Q21'].unique())))]\n#colors = list(itertools.chain.from_iterable(c))\n'''colors={'India':'#8dd3c7', 'Pakistan':'#ffffb3', 'Russia':'#bebada', \\\n        'Nigeria':'#fb8072', 'Japan':'#80b1d3', 'Egypt':'#fdb462',\n       'Brazil':'#b3de69', 'China':'#fccde5', 'United States of America':'#d9d9d9',\n       'United Kingdom of Great Britain and Northern Ireland':'#bc80bd'}'''\nax.scatter(ind_size_ct['Q21'],ind_size_ct['Q20'],s=ind_size_ct.value*10,alpha=0.7)#,color=ind_size_ct['Q21'].map(colors))\nax.tick_params(axis='x',labelrotation=90)\ndata = [[x] for x in list(pd.crosstab(ds_rs_w_df['Q20'],ds_rs_w_df['Q21']).idxmax(axis=1))]\ndata.reverse()\ntable = ax.table(cellText=data,\\\n                      colLabels=['Most Frequent Size of company'],\\\n                      fontsize=24,colLoc='center',cellLoc='center',\\\n                      loc='right',colWidths=[0.1],\\\n                        bbox=(1,0,0.5,1.055))\ntable.auto_set_font_size(False)\ntable.set_fontsize(15)\ntable.auto_set_column_width('Most Frequent Size of company')\n#table.scale(1,1.5)\nplt.show()","209e4594":"def get_sal_bin(sal_range):\n    #import pdb;pdb.set_trace()\n    try:\n        upper_range = int(sal_range.split('-')[1].replace(',','')) \n    except:\n        upper_range = 1000000 if sal_range == '>$1,000,000' else 0\n    if upper_range < 50000:\n        return '<50K'\n    elif 50000<=upper_range<100000:\n        return '50K-100K'\n    elif 100000<=upper_range<500000:\n        return '100K-500K'\n    elif 500000<=upper_range<1000000:\n        return '500K-1M'\n    elif upper_range >= 1000000:\n        return '>1M'\n\nct_role_sal = pd.crosstab(w_prof_df.Q5,w_prof_df['Q25'].apply(lambda x: get_sal_bin(x)))#.stack().reset_index(name='value')\n#w_prof_df['Q25'].unique()\nax = ct_role_sal.apply(lambda r: r\/r.sum()*100, axis =1)\\\n.plot(kind='barh',colormap =plt.get_cmap(\"Paired\"),figsize=(10,10),width=1,stacked=True)\nplt.legend(loc='upper right',bbox_to_anchor=(0.8, 0.5, 0.5, 0.5))\nplt.show()","c58f72f8":"cdf = w_prof_df[w_prof_df.Q3 != 'Other']['Q3'].value_counts().sort_values(ascending=False).reset_index()\nct_role_sal = pd.crosstab(w_prof_df[w_prof_df.Q3.isin(cdf[0:10]['index'])].Q3,w_prof_df[w_prof_df.Q3.isin(cdf[0:10]['index'])]['Q25'].apply(lambda x: get_sal_bin(x)))#.stack().reset_index(name='value')\n#w_prof_df['Q25'].unique()\nax = ct_role_sal.apply(lambda r: r\/r.sum()*100, axis =1)\\\n.plot(kind='barh',colormap =plt.get_cmap(\"Paired\"),figsize=(10,10),width=1,stacked=True)\nplt.legend(loc='upper right',bbox_to_anchor=(0.8, 0.5, 0.5, 0.5))\nplt.show()","05f8bb32":"# Code from Ruchi798's notebook\nimport palettable.scientific.sequential as palette\nfrom palettable.tableau import Tableau_20\nfrom matplotlib.ticker import FuncFormatter\n\ndef visualize_relation(start_slice, end_slice, new_col_names, old_col, new_col, xlabel, title, p1,p2,df,display_type):\n    #import pdb; pdb.set_trace()\n    df_sliced = df.loc[:,start_slice:end_slice]\n\n    df_sliced = df_sliced.rename(columns=new_col_names).fillna(0).replace('[^\\\\d]',1, regex=True)\n    df_sliced = df_sliced.join(df[old_col])\n\n    df_sliced_stats = pd.DataFrame()\n    for col in df_sliced.columns[:-1]:\n        df_sliced_stats[col] = df_sliced.groupby(old_col)[col].mean().values\n\n    df_sliced = df_sliced.rename(columns={old_col:new_col})\n    df_sliced_stats.index = df_sliced.groupby(new_col)[list(new_col_names.items())[0][1]].mean().index\n\n    cmap = sns.diverging_palette(p1, p2, as_cmap=True)\n    if display_type == 1:\n        display(df_sliced_stats.style.background_gradient(cmap, axis=0).format(\"{:.0%}\"))\n    else:\n        df_sliced_stats[new_col] = df_sliced_stats.index\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111)\n        for i in range(len(df_sliced_stats.columns[:-1])):\n            color = Tableau_20.hex_colors[i]\n            col = df_sliced_stats.columns[i]\n            df_sliced_stats.plot(kind=\"scatter\", x=col,y=new_col, color=color, label=col,ax=ax, s=100)\n\n        ax.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) \n        ax.set_xlabel(xlabel)\n        ax.legend(loc='upper right',bbox_to_anchor=(1.5, 1), frameon=False)\n        ax.set_title(title)\n        plt.show()\n","23bb0ae4":"new_col_names ={'Q17_Part_1': 'Lin\/Log Reg',\n                'Q17_Part_2': 'Dec Trees\/Random For',\n                'Q17_Part_3': 'GBM',\n                'Q17_Part_4': 'Bayesian Approaches',\n                'Q17_Part_5': 'Evolutionary Approaches',\n                'Q17_Part_6': 'Dense NN',\n                'Q17_Part_7': 'CNN',\n                'Q17_Part_8': 'GAN',\n                'Q17_Part_9': 'RNN',\n                'Q17_Part_10': 'Transformer Networks',\n                'Q17_Part_11': 'None',\n                'Q17_OTHER': 'Other'\n                }\n\nvisualize_relation('Q17_Part_1','Q17_OTHER', new_col_names, 'Q5', 'Role-Female', \"Usage of Models\", \"Role vs Model Used\", 240, 10,w_prof_df,1)\nprof_df_all = df.drop(0,axis=0)[(df.Q2 != 'Woman') & (df.Q5 !='Student') & (df.Q5 != 'Currently not employed')]\nvisualize_relation('Q17_Part_1','Q17_OTHER', new_col_names, 'Q5', 'Role-Male', \"Usage of Models\", \"Role vs Model Used\", 240, 10,prof_df_all,1)","d7b3b3bf":"list(w_stats_df.columns)","4709fc57":"combined_data = pd.read_csv(\"\/kaggle\/input\/kaggle-data-science-survey-20172021\/kaggle_survey_2017_2021.csv\")\ncombined_data.rename(columns={'-':'Year'},inplace=True)\ncombined_data.drop(0,axis=0,inplace=True)\ncombined_data = combined_data.astype({'Year':'int32'})\ncombined_data['Q2'] = combined_data.Q2.fillna('Prefer not to say').replace('Male','Man').replace('Female','Woman')\ncombined_data['Q25']= combined_data['Q25'].apply(lambda x :get_sal_bin(x))\ncombined_data.head()","61420aa5":"from matplotlib.ticker import MaxNLocator\n\nfig,(ax1,ax2) = plt.subplots(1,2)\nfig.set_size_inches(20,10)\ncombined_data[combined_data.Q2 == 'Woman'].groupby(['Year']).Q2.count().plot.line(ax=ax1)\ncombined_data[(combined_data.Q2 == 'Woman') & (combined_data.Q5 == 'Student')].groupby(['Year']).Q2.count().plot.line(ax=ax1)\ncombined_data[(combined_data.Q2 == 'Woman') & (combined_data.Q5 != 'Student') \\\n              & (combined_data.Q5 != 'Currently not employed') & (combined_data.Q5 != 'Not employed')].groupby(['Year']).Q2.count().plot.line(ax=ax1)\nax1.xaxis.set_major_locator(MaxNLocator(integer=True))\nfrom matplotlib.lines import Line2D\ncustom_lines = [Line2D([0], [0], color='blue', lw=4),\n                Line2D([0], [0], color='orange', lw=4),\n                Line2D([0], [0], color='green', lw=4)]\nax1.legend(custom_lines, ['All', 'Student', 'Professional'])\n\nsal_agg_year = pd.DataFrame(combined_data[combined_data.Q2 == 'Woman'].groupby(['Year'])['Q25'].value_counts()).rename(columns={'Q25':'Sal'}).reset_index()\nsal_agg_year.drop(sal_agg_year[sal_agg_year.Q25 == 'I do not wish to disclose my approximate yearly compensation'].index,inplace=True)\n\nax2 = sns.lineplot(data=sal_agg_year,x='Q25',y='Sal',hue='Year',linewidth=2,sort=True,palette=['#66c2a5','#fc8d62','#8da0cb','#e78ac3','#a6d854'])\nax2.tick_params(axis='x', rotation=90)\nax2.set(xlabel='Salary Range', ylabel='')\nplt.show()","420564a0":"combined_data_prof_w= combined_data[(combined_data.Q2 == 'Woman') & (combined_data.Q5 != 'Student') \\\n              & (combined_data.Q5 != 'Currently not employed') & (combined_data.Q5 != 'Not employed')]\ncombined_data_prof_w['Q5'] = combined_data_prof_w['Q5'].fillna('Other')\\\n                    .replace('Product Manager','Product\/Project Manager')\\\n                    .replace('Program\/Project Manager','Product\/Project Manager')\\\n                    .replace('Marketing Analyst','Business Analyst')\\\n                    .replace('Software Developer\/Software Engineer','Software Engineer')\\\n                    .replace('Programmer','Software Engineer')\\\n                    .replace('Engineer','Software Engineer')\\\n                    .replace('Developer Advocate','Developer Relations\/Advocacy')\\\n                    .replace('Scientist\/Researcher','Research Scientist')\\\n                    .replace('Research Assistant','Research Scientist')\\\n                    .replace('Researcher','Research Scientist')\\\n                    .replace('Computer Scientist','Research Scientist')\\\n                    .replace('Operations Research Practitioner','Research Scientist')\\\n                    .replace('Data Miner','Data Scientist')\\\n                    .replace('Predictive Modeler','Data Scientist')\\\n                    .replace('Consultant','Other')\\\n                    .replace('Chief Officer','Other')\\\n                    .replace('Manager','Product\/Project Manager')\\\n                    .replace('Salesperson','Other')\\\n                    .replace('Principal Investigator','Other')\\\n                    .replace('Data Journalist','Other')\n\n\nfig,(ax1) = plt.subplots(1,1)\nfig.set_size_inches(20,10)\n\nrole_trends = pd.DataFrame(combined_data_prof_w.groupby(['Year'])['Q5'].value_counts()).rename(columns={'Q5':'Count'}).reset_index()\nax1 = sns.lineplot(data=role_trends\\\n            ,x='Year',y='Count',hue='Q5',linewidth=3,sort=True,palette=['#a6cee3','#1f78b4',\\\n                                                                        '#b2df8a','#33a02c','#fb9a99',\\\n                                                                        '#e31a1c','#fdbf6f','#ff7f00',\\\n                                                                        '#cab2d6','#6a3d9a','#ffff99','#b15928'])\nax1.tick_params(axis='x', rotation=90)\nax1.xaxis.set_major_locator(MaxNLocator(integer=True))\nax1.set(xlabel='Role', ylabel='')\nax1.legend(loc='upper right')\nplt.show()\n#role_trends\n","fc0017d0":"There are some interesting findings when we compare the Women against the Male population\n1. While United States and India are the major contributors in terms of country-wise numbers the countries that stand out are <b>Taiwan and Indonesia<\/b> where the female population is much more actively involved than their male counterparts.\n2. In terms of Experience Level, female population is quite young with <b>27% being less than a year<\/b> and almost <b>6% has never written code<\/b>.\n3. The difference in population numbers increases even more at higher experience levels which indicates that Women joined the party pretty Late! but you know what they say... Better Late than Never :-)","27940fab":"From the above tiles we can see that\n1. Most of the women population are <b>Students<\/b> and most of them are from <b>India<\/b>. Interestingly, the professional community is dominated by <b>Data Scientists<\/b>.\n2. Obviously then the <i>Most Active Age Group<\/i> stands out to be <b>18-21 Years<\/b> and the age group as expected shifts towards <b>25-29 Years<\/b> in the professional community.\n3. Interestingly, most of them either have <b>Master's Degree<\/b> or are pursuing it. Women are putting lot of effort in educating themselves !!\n4. Most of them are from <b>Academia<\/b> and have <b>1-3 Years<\/b> of coding experience. Well that is understandable as the Data Science field\/community is pretty young overall.\n5. The choice of Coding Language is <b>Python<\/b> with <b>Scikit-learn<\/b>","93de199d":"<b>This next visualization deals with number of Data\/reasearch Scientists across various industries and company sizes. The table on the right shows the most frequent value in each category<\/b>\n1. As expected, <b>Academia<\/b> employs most number of Data scientists but they work in small groups and may be doing more focused research.\n2. We can also see that most of the industries have very small sizes despite the relatively large market of the industry itself. This may be attributed to the fact that industries frequently outsource Machine Learning work to small startups who specialize in such kind of work instead of investing in it from scratch.\n3. This is probably why we see that <b>Computers\/technology<\/b> industry, inspite of being gigantic in size, has most of companies with a relatively small size. This could further be validated if we have the data on the startup numbers and growth data for the start-ups in ML space.\n4. The only excpetions to 2 are <b>Accounting\/Finance, Government\/Public Service, Shipping, Manufacturing, etc.<\/b> Could this be due to the data sensitivity and relatively closed industry idealogy?","b7cc915b":"Quite oddly.... Women seem to be greatly underpaid where the salaries are less than **50K per annum** across all the roles. \nPart of this can be explained by the next visualization where we analyze the salaries by the Top 10 (by population) country and you can see that **India** where the majority of population resides has really low salaries. So that's bringing down the average across all the roles.\n\n**United States**  as one would expect is the destination in terms of salaries but Europe presents a different picture.\nAlthough **United Kingdom** is the 3rd largest contributor to the Women Professionals, **Germany** seems to be the destination in terms of attractive salaries.","e8541f2e":"We can notice few things regrading the general trends here:\n1. A lot of women took to studying, assuming in the related field post 2017. This really added to the workforce growth post 2020. However, the rate of growth for professionals is not same as students. \n2. 2019 saw major dips in terms of professionals and students. Can this be attributed to the pandemic? smilar trend is seen in salary growth too.\n3. Again the majority of women are earning under 50k per annum but post 2020 we have seen some groth in terms of salary. However, it still looks like the starting salary for women in this field stays below 50k.\n4. The last visualization points that women have been targeting roles like 'Data\/Reserach Scientist', 'Data Analyst' and 'Software Engineer' much more than other roles as these roles are seeing much more growth than others.","acf099ae":"Next we will try to analyze the Machine Learning algorithms, tools and cloud data for women and compare it with rest of the population.\nFirst up is a cross-tabulation of algorithms used across roles that these Women work in. As expected you would see that\n1. Most used algorithms are <b>Linear\/Logistic Regression, Decision Trees\/Random Forest and GBM<\/b>.\n2. <b>Evolutionary algorithms<\/b> are explored mostly by <b>Research scientists<\/b>; consistent with rest of the population.\n3. The areas where women seem to have taken different approach is that lot of females employed as <b>Developer Relations\/Advocacy<\/b> seem to favor <b>GAN & Transformer Networks<\/b> and lot of Women <b>Research Scientists<\/b> are exploring <b>Bayesian Techniques<\/b> which seems to be a favorite of <b>Statisticians<\/b> otherwise.","43a8832f":"Upon examining the demographics of the small subset of professionals who are employed as Data\/Reserach scientist we find that for this niche group...\n1. Although India and USA still account for more than 50% of the population, we can see that the 3rd largest contributor to the Data scientist position is <b> United Kingdom of Great Britain and Northern Ireland<\/b>.\n2. We can also see that women from other countries like France,Brazil and Germany are contributing significantly too.\n3. Almost 50% of the population has 3 or more years of experience. This is different from the earlier findings where 20s is the golden age. I guess experience is much more important in this field which is co-related to your age which is why more than 50% of the population is older than 30.","368ffe30":"**Trends...**","79ba3833":"AI & Machine Learning are the hottest technologies of 21st century. Everyone is jumping on the action. Ths notebook in particular analyzes the state of women in this particular field.\nMy plan is to start with simple demographics and summary of the data in general, dive into the specific demographics followed by technical depth in the community and summing it up with some general trends since 2017.","8010a14b":"Lets start with some basic information about the Women Kagglers....."}}