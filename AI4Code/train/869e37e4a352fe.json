{"cell_type":{"c5bef364":"code","21dddf07":"code","3538d0a1":"code","1e4a7354":"code","67a16292":"code","9ad3eb74":"code","df732658":"code","b28f2b4e":"code","5031499f":"code","3a4ff085":"code","50d2edd4":"code","7a7ad952":"markdown","576a4d2d":"markdown","a2c32337":"markdown","5919ece4":"markdown","7b2375fe":"markdown","cd04ee74":"markdown"},"source":{"c5bef364":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Import packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","21dddf07":"# Provide Data\nboston_dataset = load_boston()\nprint(boston_dataset.keys())\nboston = pd.DataFrame(boston_dataset.data, columns = \n                      boston_dataset.feature_names)\nboston['MEDV']=boston_dataset.target\nboston.columns = map(str.lower,boston.columns)","3538d0a1":"# Data Processing\nb_null = boston.isnull().sum()\nprint(b_null)","1e4a7354":"# Exploratory Data Analysis\nsns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.distplot(boston['medv'],bins=30)\nplt.savefig('Exploratory.png',dpi=500)\nplt.show()","67a16292":"# Correlation\ncorrelation_matrix = boston.corr().round(2)\nsns_plot=sns.heatmap(data=correlation_matrix, annot=True)","9ad3eb74":"# Variation\nplt.figure(figsize=(20,5))\nfeatures =['lstat','rm']\ntarget = boston['medv']\nfor i, col in enumerate(features):\n    plt.subplot(1,len(features),i+1)\n    x = boston[col]\n    y=target\n    plt.scatter(x,y,marker='o')\n    plt.title(col)\n    plt.xlabel(col)\n    plt.ylabel('medv')","df732658":"#prepare data for training model\nX = pd.DataFrame(np.c_[boston['lstat'],boston['rm']],\\\ncolumns =['lstat','rm'])\ny = boston['medv']","b28f2b4e":"#split train and test data\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3418,\\\n                                         random_state=0)","5031499f":"# Create Model and Fit\nmodel = LinearRegression().fit(X_train,y_train)","3a4ff085":"# Predict\ntrain_pred = model.predict(X_train)","50d2edd4":"# Model evaluation\nr_sq = model.score(X_train,y_train)\nprint('The model performance for training set')\nprint('--------------------------------------')\nprint('coefficient of determination:',r_sq)\nprint('Mean Absolute Error:',mean_absolute_error(y_train,train_pred))\nprint('Root Mean Squared Error:',np.sqrt\n      (mean_absolute_error(y_train,train_pred)))","7a7ad952":" ### Observations:\n We found that `rm` variable have strong correlation with our target `medv` which is (0.7). On the other hand, `lstat` have high negative correlation with 'rm' which is (-0.74). \nWe came to know that `rad` and `tax` have very strong correlation(0.91) which should be exclued in order not to have multicollinearity results in hich unstable parameter estimates which makes it very difficult to assess the effect of independent variables on dependent variables.\n\nLet's see how `rm` and `lstat` vary with `lstat'.","576a4d2d":"We would like to know the correlation between vairables to decide the featues for our model.If the value is close to 1, it means that there is a strong positive correlation between the two variables. When it is close to -1, the variables have a strong negative correlation.","a2c32337":"### Observations:\nThe prices increase as the value of `rm` increases linearly. The prices tend to decrease with an increase in `lstat`.\n> ","5919ece4":"After our analysis, we find that the values from `medv` is well distributed.","7b2375fe":"We find that there is no missing value in our dataframe. The next step is to do exploratory analysis before \ntraining our model.","cd04ee74":"With the `mean absolute error(MAE)`, we would expect it to be much larger than MAE due to the influence of outliers.The corresponding `root mean squared error(RMSE)` would be about 1.9, indicating that our model misses actual sale values by about $1.9****M."}}