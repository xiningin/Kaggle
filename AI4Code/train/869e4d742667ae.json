{"cell_type":{"ec9f8851":"code","e957499e":"code","867e1b28":"code","c005593c":"code","e8f09374":"code","5acd5ba4":"code","4639c209":"code","8be803f2":"code","75171249":"code","4fa4521d":"code","b839243e":"code","41c4cb43":"code","971e7a7e":"code","ad0b78a9":"code","e32915e3":"code","02a70585":"code","15f96d06":"code","4cd10e9e":"code","d51ded1c":"code","5b4bd9b4":"code","92ca092e":"code","8b13b61b":"code","58e36b56":"code","3a4a9a2f":"markdown","c1d8da8f":"markdown","a7c0a632":"markdown","18abe63c":"markdown","b90cbe20":"markdown","2a8c7ca9":"markdown","35ec8872":"markdown","f13cf40e":"markdown","2d335cae":"markdown","8703354e":"markdown","89758012":"markdown","1a430c83":"markdown","0a7928c5":"markdown","169ab58c":"markdown","173af60b":"markdown","55b2f078":"markdown"},"source":{"ec9f8851":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nfrom keras.callbacks import TensorBoard\nfrom keras import regularizers","e957499e":"data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","867e1b28":"print(data.shape)","c005593c":"print(data.head())","e8f09374":"print(data.info())","5acd5ba4":"fraud = data[data.Class==1]\nno_fraud = data[data.Class==0]\nprint(\"The shape of no_fraud data:\", no_fraud.shape)\nprint(\"The shape of fraud data:\", fraud.shape)","4639c209":"plt.figure(figsize=(12,5))\nsns.countplot(x=\"Class\", data=data)\nplt.title(\"Fraud vs No Fraud Transaction Distributions\")\nplt.xticks(range(2), [\"No Fraud\", \"Fraud\"])\nplt.show() ","8be803f2":"print(\"Non-Fraudulent Transaction\")\nprint(no_fraud.Amount.describe())\nprint(\"\\nFraudulent Transaction\")\nprint(fraud.Amount.describe())","75171249":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.distplot(no_fraud['Amount'])\nplt.title(\"Amount Distribution of Non-Fraudulent Transaction\")\n\nplt.subplot(1,2,2)\nsns.distplot(fraud['Amount'])\nplt.title(\"Amount Distribution of Fraudulent Transaction\")\n\nplt.show()","4fa4521d":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nplt.scatter(no_fraud.Time, no_fraud.Amount)\nplt.title(\"Time Distribution of Non-Fraudulent Transaction\")\nplt.xlabel(\"time\")\nplt.ylabel(\"amount\")\n\nplt.subplot(1,2,2)\nplt.scatter(fraud.Time, fraud.Amount)\nplt.title(\"Time Distribution of Fraudulent Transaction\")\nplt.xlabel(\"time\")\nplt.ylabel(\"amount\")\n\nplt.show()","b839243e":"data = data.drop(['Time'], axis=1)","41c4cb43":"from sklearn.preprocessing import StandardScaler\n\ndata['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))","971e7a7e":"from sklearn.model_selection import train_test_split\n\nX_train, X_test = train_test_split(data, test_size=0.2, random_state=42)\n\nX_train = X_train[X_train.Class==0]\nX_train = X_train.drop(['Class'], axis=1)\n\ny_test = X_test['Class']\nX_test = X_test.drop(['Class'], axis=1)\n\nX_train = X_train.values\nX_test = X_test.values","ad0b78a9":"print(\"Shape of X_train:\", X_train.shape)\nprint(\"Shape of X_test:\", X_test.shape)","e32915e3":"input_size = X_train.shape[1]\nencoding_size = 14","02a70585":"input_layer = Input(shape=(input_size, ))\n\nencoder_1 = Dense(encoding_size, activation=\"relu\", activity_regularizer=regularizers.l1(1e-5))(input_layer)\nencoder_2 = Dense(int(encoding_size \/ 2), activation=\"relu\")(encoder_1)\ndecoder_1 = Dense(encoding_size, activation='relu')(encoder_2)\noutput_layer = Dense(input_size, activation='relu')(decoder_1)\n\nautoencoder = Model(inputs=input_layer, outputs=output_layer)","15f96d06":"autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n\ntensorboard = TensorBoard(log_dir='.\/logs', write_images=True)\n\nhistory = autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test),\n                  callbacks=[tensorboard]).history","4cd10e9e":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right');\n\nplt.subplot(1,2,2)\nplt.plot(history['accuracy'])\nplt.plot(history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\n\nplt.show()","d51ded1c":"prediction = autoencoder.predict(X_test)","5b4bd9b4":"mse = np.mean(np.power(X_test - prediction, 2), axis=1)\nerror = pd.DataFrame({'reconstruction_error': mse, 'actual_class': y_test})","92ca092e":"without_fraud = error[error.actual_class==0]\nwith_fraud = error[error.actual_class==1]","8b13b61b":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.distplot(without_fraud[\"reconstruction_error\"])\nplt.title(\"Reconstruction error without fraud\")\n\nplt.subplot(1,2,2)\nsns.distplot(with_fraud[\"reconstruction_error\"])\nplt.title(\"Reconstruction error with fraud\")\n\nplt.show()","58e36b56":"from sklearn.metrics import confusion_matrix\ny_pred = [1 if e > 3 else 0 for e in error.reconstruction_error.values]\nprint('Confusion Matrix\\n' + str(confusion_matrix(y_test, y_pred)))","3a4a9a2f":"Input layer has 29 nodes. Hidden layers have 14, 7, 14 nodes respectively. Output layer has 29 nodes which is the same number of nodes with the input layer.","c1d8da8f":"# 5. Evaluation","a7c0a632":"I will use TensorBoard which is a visualization tool provided with TensorFlow so that we will be able to visualize training graph.","18abe63c":"Graph shows that the time is not related with the fraud activities, that's why I will drop \"time\" from the dataset.","b90cbe20":"There are not any null values in the dataset.","2a8c7ca9":"The model is trained with nonfraudulent transactions, and learned how to separate different examples (fraudulent cases).\nOn the other hand, the number of nonfraudulent cases that is predicted as fraud is quite high with 1235. This may be a problem. The model also could not catch 19 fraudulent transactions, and evaluated as nonfraudulent transaction, but the number is not high.","35ec8872":"Reconstruction error is quite high for the fraudulent cases since the model see these data points for the first time. Since we trained the model with just nonfraudulent cases, reconstruction error is quite low for nonfraudulent cases.","f13cf40e":"We want to detect anomalies in our dataset, that's why we need to train the model with just nonfrudulent data. After training, the model will be able to separate the nonfraudulent cases. It means reconstruction loss will be very low for nonfraudulent cases. If we pass fraud cases, we will get a high reconstruction loss value because the network fails to reconstruct the input that is considered an anomaly.","2d335cae":"### Scaling the Data","8703354e":"### Splitting the Data","89758012":"# 1.Reading and Understanding the Data ","1a430c83":"# 3. Data Preparation","0a7928c5":"There are 492 fraud cases and 284.315 nonfraudulent cases in the dataset. The percentage of no fraud cases is quite higher than fraud cases.","169ab58c":"# 4. Autoencoder Model","173af60b":"We need to scale \"amount\" column for optimal performance. Other columns of the dataset are already scaled.","55b2f078":"# 2. Exploratory Data Analysis"}}