{"cell_type":{"4cb608f8":"code","39dd14f5":"code","dcec9212":"code","b5589be6":"code","85d56547":"code","82ab9682":"code","cb8de866":"code","affec857":"code","0afacbca":"code","e1cb15f2":"code","c9f86c73":"code","306fec28":"code","53b4dd7d":"code","b308f389":"code","2215d6ca":"code","e4ddbd47":"code","37e18195":"code","9da80bff":"code","cd9ad200":"code","0ca48fcc":"code","2d0960b8":"code","38e80d18":"code","f3a4077b":"code","e0e13d3b":"code","5b088b60":"code","7300db02":"code","9b9cf26a":"code","d026fb18":"code","a25ff3f3":"code","84512720":"code","b36aeca1":"code","c42d1e33":"code","bca8b01b":"code","033cdbf6":"code","8bc8e055":"code","d2e62798":"code","1cb3d9e4":"code","bd4c6c3c":"code","3e83af99":"code","474ee4ca":"code","d8bc6e64":"code","8e5d5cd7":"code","f4c4db06":"code","d64e441a":"code","f747134f":"code","a77132db":"code","5526813e":"code","b179bb69":"markdown","fd7ed415":"markdown","9dd27767":"markdown","5a5ad2b5":"markdown","5cd831a9":"markdown","5a3db2a6":"markdown","c97ba177":"markdown","66873c9f":"markdown","e1e6ddca":"markdown","e21d5ba9":"markdown","2cd76224":"markdown","33ff7d7c":"markdown","0c107c8f":"markdown","d188141b":"markdown","82a7c3ee":"markdown","2b2ea111":"markdown","20f2f149":"markdown","7332d80f":"markdown","c37a97ef":"markdown","fef06b6b":"markdown","c5b1ab5c":"markdown","c149845e":"markdown","67785c73":"markdown","e23efe7a":"markdown","2db9ac7c":"markdown","09746509":"markdown","b791f1ae":"markdown","460b213e":"markdown","3ef7fc2c":"markdown","9d8c1a10":"markdown","66db8371":"markdown","dc80c5de":"markdown","5ff84c76":"markdown","88033d1a":"markdown","ec3124eb":"markdown","3715f22b":"markdown","995ec269":"markdown","02027c13":"markdown"},"source":{"4cb608f8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport os\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 20,8","39dd14f5":"train = pd.read_csv('..\/input\/into-the-future\/train.csv')\ntest = pd.read_csv('..\/input\/into-the-future\/test.csv')","dcec9212":"print(\"The shape of the training set is {}\".format(train.shape))\nprint(\"The shape of the test set is {}\".format(test.shape))","b5589be6":"train.isnull().sum()","85d56547":"test.isnull().sum()","82ab9682":"train.dtypes","cb8de866":"train['time'] = pd.to_datetime(train['time'])","affec857":"train.index = train.time\ntrain = train.drop(['time'], axis = 1)","0afacbca":"train = train.drop(['id'], axis = 1)\ntrain.head()","e1cb15f2":"X = train.iloc[:,0:1].values\ny = train.iloc[:,-1].values","c9f86c73":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","306fec28":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)","53b4dd7d":"y_pred_lr = lr.predict(X_test)","b308f389":"from sklearn.metrics import r2_score, mean_squared_error\nr2_score = r2_score(y_test, y_pred_lr)\nerror = np.sqrt(mean_squared_error(y_test, y_pred_lr))\nprint(\"R squared value for the Linear Regression model is {} and the root mean squared error in prediction is {}\".format(r2_score, error))","2215d6ca":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(lr, X_train, y_train, cv = 10)\nmean = score.mean()\nprint(\"The mean cross validation score for the model for 10 models is {}\".format(mean))","e4ddbd47":"from sklearn.preprocessing import PolynomialFeatures\npr = PolynomialFeatures(degree = 4)\nX_poly = pr.fit_transform(X)","37e18195":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size = 0.2, random_state = 0)","9da80bff":"lr2 = LinearRegression()\nlr2.fit(X_train, y_train)","cd9ad200":"y_pred_poly = lr2.predict(X_test)","0ca48fcc":"from sklearn.metrics import r2_score, mean_squared_error\nr2_score = r2_score(y_test, y_pred_poly)\nerror = np.sqrt(mean_squared_error(y_test, y_pred_poly))\nprint(\"The r squared value for the Polynomial Regression model is {} and the root mean squared error in prediction is {}\".format(r2_score, error))","2d0960b8":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(lr2, X_test, y_test, cv = 10)\nmean = score.mean()\nprint(\"The mean cross validation score for the model for 10 models is {}\".format(mean))","38e80d18":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","f3a4077b":"from sklearn.svm import SVR\nsvr = SVR(kernel = 'rbf')\nsvr.fit(X_train, y_train)","e0e13d3b":"y_pred_svr = svr.predict(X_test)","5b088b60":"from sklearn.metrics import r2_score, mean_squared_error\nr2_score = r2_score(y_test, y_pred_svr)\nerror = np.sqrt(mean_squared_error(y_test, y_pred_svr))\nprint(\"The r squared value for the Support Vector Regression model is {} and the root mean squared error in prediction is {}\".format(r2_score, error))","7300db02":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 10)\nrf.fit(X_train, y_train)","9b9cf26a":"y_pred_rf = rf.predict(X_test)","d026fb18":"from sklearn.metrics import r2_score, mean_squared_error\nr2_score = r2_score(y_test, y_pred_rf)\nerror = np.sqrt(mean_squared_error(y_test, y_pred_rf))\nprint(\"The r squared value for the Random Forest Regressor model is {} and the root mean squared error in prediction is {}\".format(r2_score, error))","a25ff3f3":"score = cross_val_score(rf, X_train, y_train, cv = 10)\nmean = score.mean()\nprint(\"The mean cross validation score for the model for 10 models is {}\".format(mean))","84512720":"n_estimators = [200,600,800,1000]\nmax_features = ['auto', 'sqrt']\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]","b36aeca1":"parameters = {'n_estimators': n_estimators,\n               'max_features': max_features}","c42d1e33":"from sklearn.model_selection import GridSearchCV\nrandomforest = GridSearchCV(estimator = rf, param_grid = parameters, cv = 10, n_jobs = -1)","bca8b01b":"randomforest.fit(X_train, y_train)","033cdbf6":"randomforest.best_params_","8bc8e055":"y_pred_rf = randomforest.predict(X_test)","d2e62798":"from sklearn.metrics import r2_score, mean_squared_error\nr2_score = r2_score(y_test, y_pred_rf)\nerror = np.sqrt(mean_squared_error(y_test, y_pred_rf))\nprint(\"The r squared value for the Random Forest Regressor model is {} and the root mean squared error in prediction is {}\".format(r2_score, error))","1cb3d9e4":"score = cross_val_score(rf, X_train, y_train, cv = 10)\nmean = score.mean()\nprint(\"The mean cross validation score for the model for 10 models is {}\".format(mean))","bd4c6c3c":"from xgboost import XGBRegressor\nXGB = XGBRegressor()\nXGB.fit(X_train, y_train)","3e83af99":"y_pred_xgb = XGB.predict(X_test)","474ee4ca":"from sklearn.metrics import r2_score, mean_squared_error\nr2_score = r2_score(y_test, y_pred_xgb)\nerror = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\nprint(\"The r squared value for the XGBoost Regressor model is {} and the root mean squared error in prediction is {}\".format(r2_score, error))","d8bc6e64":"test = pd.read_csv('..\/input\/into-the-future\/test.csv')","8e5d5cd7":"test['time'] = pd.to_datetime(test['time'])","f4c4db06":"test.index = test.time\ntest = test.drop(['time'], axis = 1)","d64e441a":"test.head()","f747134f":"X = test.iloc[:,1:2].values","a77132db":"test['predictions'] = randomforest.predict(X)","5526813e":"ids = test['id']\nfeature_2 = test['predictions']\nsubmission = pd.DataFrame({\"id\": ids, \"feature_2\": feature_2})\nsubmission.to_csv('Prediction2.csv')","b179bb69":"#### Tuning the parameters of the model","fd7ed415":"#### Getting the r squared and rmse values","9dd27767":"#### Using cross validation to get the accuracies","5a5ad2b5":"#### Getting the r squared and rmse values","5cd831a9":"#### Looking for null values","5a3db2a6":"#### Using cross validation to get the accuracies","c97ba177":"#### Predicting using the test dataset","66873c9f":"#### Predicting the test values","e1e6ddca":"#### Applying XGBoost Regressor to the dataset","e21d5ba9":"#### Applying Support Vector Regression Model to the dataset","2cd76224":"#### Looking at the data types","33ff7d7c":"#### The value of 4 has been obtained after looking at other degrees","0c107c8f":"#### Indexing the dataset by the time variable and removing the id variable","d188141b":"#### Using cross validation to get the accuracies","82a7c3ee":"#### Applying Polynomial Regression model to the dataset","2b2ea111":"#### Fitting the model","20f2f149":"#### Applying the Linear Regression model to the dataset","7332d80f":"#### Getting the matrix of features and target variables","c37a97ef":"#### Getting the r squared and rmse values","fef06b6b":"##### Importing the libraries","c5b1ab5c":"#### Predicting the results","c149845e":"#### Splitting into train and test dataset","67785c73":"#### Converting time variable from object to datetime","e23efe7a":"#### Using cross validation to get the accuracies","2db9ac7c":"#### Predicting the results","09746509":"#### Using Grid Search CV","b791f1ae":"#### Goal: The goal of the analysis is to predict the values of feature_2 based on the features","460b213e":"#### Applying the Random Forest Regressor model to the dataset","3ef7fc2c":"#### Getting the r squared and rmse values","9d8c1a10":"#### Getting the shape of the datasets","66db8371":"#### Using the Random Forest Regressor Model on the submission dataset","dc80c5de":"#### Getting the r squared and rmse values","5ff84c76":"#### Predicting the test values","88033d1a":"#### The rmse values for the models are:\n\n1. Linear Regression: 440\n2. Polynomial Regression: 185\n3. Support Vector Regressor: 1432\n4. Random Forest Regressor: 171\n5. XGBoost Regressor: 188","ec3124eb":"#### Predicting the values","3715f22b":"#### Predicting for the test set","995ec269":"#### Getting the data","02027c13":"#### Fitting the model"}}