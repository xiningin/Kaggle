{"cell_type":{"19e2476c":"code","f3ede73e":"code","93a7a9cb":"code","240911b3":"code","0f258657":"code","ebc48370":"code","9be9d490":"code","db222504":"code","0d68726e":"code","ebbfa88b":"code","18bb8bff":"code","3111121f":"code","8ad12fed":"code","4af0490e":"code","f82ed3a0":"code","775e7737":"code","51c33774":"code","6e5efecc":"code","66ba4980":"code","813bb6b3":"code","35e14b45":"code","fb6d13cc":"code","20c838f5":"code","3a72f7fe":"code","bf3c4827":"code","bd4ff6c3":"code","745f7e2e":"code","1915a4b2":"code","a8d58390":"code","b9723c8d":"code","51bbc6cb":"code","5079e5cc":"code","29fda482":"code","ff217645":"code","ead3ef00":"markdown","f569e7ee":"markdown","dc4f9929":"markdown","a0f10a10":"markdown","b6ad4663":"markdown","1e9a0b58":"markdown","ba65f3b2":"markdown","e282f32a":"markdown","ceda70f1":"markdown","ce45387c":"markdown","e24f1470":"markdown","e55536b1":"markdown","27ce147d":"markdown","d034a235":"markdown"},"source":{"19e2476c":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f3ede73e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","93a7a9cb":"dataset = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndataset.head()","240911b3":"dataset.shape","0f258657":"dataset.info()","ebc48370":"dataset.describe()","9be9d490":"dataset.isnull().any()","db222504":"sns.countplot(data=dataset,x='target')\nplt.xticks(ticks=[0,1],labels=[\"Haven't' Disease\", 'Have Disease'])","0d68726e":"num_have_disease = len(dataset[dataset['target']==1])\nnum_havenot_disease = len(dataset[dataset['target']==0])\npercent_have_disease = (num_have_disease\/len(dataset))*100\npercent_havenot_disease = (num_havenot_disease\/len(dataset))*100\nprint(\"Percentage of Patients Have Heart Disease: {:.2f}%\".format(percent_have_disease))\nprint(\"Percentage of Patients Haven't Heart Disease: {:.2f}%\".format(percent_havenot_disease))","ebbfa88b":"100 * (dataset.corr()['target'].sort_values())","18bb8bff":"plt.figure(figsize=(10,10))\nsns.heatmap(dataset.corr(),annot=True)","3111121f":"plt.figure(figsize=(5,5))\nsns.countplot(data=dataset,x='sex',hue='target')\nplt.xticks(ticks = [0,1], labels = ['Female','Male'])\nplt.legend([\"Haven't' Disease\", 'Have Disease'])","8ad12fed":"plt.scatter(x=dataset.age[dataset.target == 0] , y=dataset.thalach[dataset.target == 0],c='black')\nplt.scatter(x=dataset.age[dataset.target == 1] , y=dataset.thalach[dataset.target == 1],c='yellow')\nplt.xlabel('Age')\nplt.ylabel('Maximum Heart Rate')\nplt.legend([\"Haven't' Disease\", 'Have Disease'])","4af0490e":"dataset['cp'].value_counts()","f82ed3a0":"sns.countplot(data=dataset,x='cp',hue='target')\nplt.xlabel('Chest Pain')\nplt.legend([\"Haven't' Disease\", 'Have Disease'])","775e7737":"dataset.thal.value_counts()","51c33774":"sns.countplot(data=dataset,x='thal',hue='target')\nplt.xlabel('Thalassemia')\nplt.legend([\"Haven't' Disease\", 'Have Disease'])","6e5efecc":"cp = pd.get_dummies(dataset['cp'],prefix='cp')\nthal = pd.get_dummies(dataset['thal'],prefix='thal')\nslope = pd.get_dummies(dataset['slope'],prefix='slope')\n\nlst = [dataset,cp,thal,slope]\ndataset = pd.concat(lst,axis=1)\ndataset.head()","66ba4980":"dataset.shape","813bb6b3":"dataset.drop(columns=['cp','thal','slope'],axis=1,inplace=True)\ndataset.shape","35e14b45":"X = dataset.drop(['target'],axis=1)\ny = dataset['target']","fb6d13cc":"from sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42) ","20c838f5":"print(X_train.shape,X_test.shape)\nprint(y_train.shape,y_test.shape)","3a72f7fe":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.metrics import accuracy_score","bf3c4827":"log_clf = LogisticRegression(solver='liblinear')\nsvm_clf = SVC()\ntree_clf = DecisionTreeClassifier()\nknn_clf = KNeighborsClassifier(n_neighbors=5)\nrnd_clf = RandomForestClassifier(n_estimators=100)","bd4ff6c3":"log_clf.fit(X_train,y_train)\naccuracy_train = log_clf.score(X_train, y_train)\nprint('Accuracy for Training :',str(round(accuracy_train*100,2))+' Percentage')\n\ny_pred = log_clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint('Accuracy for Testing :',str(round(accuracy*100,2))+' Percentage')\n","745f7e2e":"svm_clf.fit(X_train,y_train)\naccuracy_train = svm_clf.score(X_train, y_train)\nprint('Accuracy for Training :',str(round(accuracy_train*100,2))+' Percentage')\n\ny_pred = svm_clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint('Accuracy for Testing :',str(round(accuracy*100,2))+' Percentage')\n","1915a4b2":"tree_clf.fit(X_train,y_train)\naccuracy_train = tree_clf.score(X_train, y_train)\nprint('Accuracy for Training :',str(round(accuracy_train*100,2))+' Percentage')\n\ny_pred = tree_clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint('Accuracy for Testing :',str(round(accuracy*100,2))+' Percentage')\n","a8d58390":"knn_clf.fit(X_train,y_train)\naccuracy_train = knn_clf.score(X_train, y_train)\nprint('Accuracy for Training :',str(round(accuracy_train*100,2))+' Percentage')\n\ny_pred = knn_clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint('Accuracy for Testing :',str(round(accuracy*100,2))+' Percentage')\n","b9723c8d":"rnd_clf.fit(X_train,y_train)\naccuracy_train = rnd_clf.score(X_train, y_train)\nprint('Accuracy for Training :',str(round(accuracy_train*100,2))+' Percentage')\n\ny_pred = rnd_clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint('Accuracy for Testing :',str(round(accuracy*100,2))+' Percentage')\n","51bbc6cb":"model = ['LogisticRegression','SVC','DecisionTreeClassifier','KNeighborsClassifier','RandomForestClassifier']\naccuracy = [90.16,70.49,81.97,68.85,88.52]","5079e5cc":"pd.DataFrame({'Name':model,'Accuracy':accuracy})","29fda482":"from sklearn.metrics import confusion_matrix,classification_report\nprint(classification_report(y_test,y_pred))","ff217645":"cm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm, annot=True)\nplt.title('Confusion Matrix')","ead3ef00":"# Modeling","f569e7ee":"## The Model","dc4f9929":"# Data Preparation","a0f10a10":"## Decision Tree Classifier","b6ad4663":"## Logistic Regression","1e9a0b58":"## K-Neighbors Classifier","ba65f3b2":"# Import the Libraries\n","e282f32a":"From Above table, we can see that Logistic Regression has better score on both test and train scores. So will evaluate our model on Logistic Regression.","ceda70f1":"## Support Vector Classifier","ce45387c":"## Spliting Dataset","e24f1470":"## Model Evaluations\n","e55536b1":"## Random Forest Classifier","27ce147d":"# Import the DataSet and Overview","d034a235":"Since 'cp', 'thal'and 'slope' are categorical variables\n...Change them into dummy variables"}}