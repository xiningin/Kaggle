{"cell_type":{"a9858899":"code","25d7c20d":"code","75daeb4b":"code","9d18ded8":"code","552fb1e2":"code","e17ad5fe":"code","f1128d25":"code","957a2219":"code","a465ca1d":"code","ca89080d":"code","d5f001e0":"code","6a83db9f":"code","df097057":"code","a57ca958":"code","545e5e33":"code","3d5a0772":"code","bcc7d2e5":"code","c2d19d59":"code","ea2445f2":"code","44cc46f7":"code","267b5671":"code","7b078035":"code","d5c5491b":"code","ab973537":"code","384e93bb":"code","76f7c1da":"code","13c0c535":"code","edc031d5":"code","ea23c2c7":"code","52bfb61f":"code","f79eee3c":"code","562e40b4":"code","13a89d28":"code","a0b8a017":"markdown","91218ffb":"markdown","6f89dcd8":"markdown","203708e4":"markdown","479de8c7":"markdown","a0416d30":"markdown","0e3032cf":"markdown","59421bcd":"markdown","163ad28d":"markdown","8b69198c":"markdown","f085e4ea":"markdown","9b9f06a8":"markdown","fe367d7a":"markdown","991e24a7":"markdown","6625b692":"markdown","8633546d":"markdown","7fd9b5e4":"markdown","a661e53f":"markdown","331b6f54":"markdown","bba62fcd":"markdown","48a5bd16":"markdown","e1631ceb":"markdown","4cfa398b":"markdown","a280e86b":"markdown","b04d53dd":"markdown","fd85cb89":"markdown","c24c6e8e":"markdown","2cb1a7e1":"markdown","2ceebe23":"markdown"},"source":{"a9858899":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","25d7c20d":"#Loading the necessary packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix","75daeb4b":"ship_wreck_train=pd.read_csv('..\/input\/titanic\/train.csv')\nship_wreck_test=pd.read_csv('..\/input\/titanic\/test.csv')\n ","9d18ded8":"ship_wreck_train.head()","552fb1e2":"sns.heatmap(ship_wreck_train.isnull(),cmap='viridis')","e17ad5fe":"sns.heatmap(ship_wreck_test.isnull(),cmap='viridis')","f1128d25":"#Initial Correlation Visualization\nfig=plt.figure(figsize=(12,7))\nsns.set_style('whitegrid')\nsns.heatmap(ship_wreck_train.corr(),annot=True,cmap='coolwarm',square=True,linewidths=1,linecolor='white')\n\n#Fare,Parch,Pclass,SibSp are correlated.\n#Note: This is based on the raw data correlation","957a2219":"#Sex Vs Survived\nsns.countplot(ship_wreck_train['Sex'],data=ship_wreck_train,hue='Survived')\n\nmale_survial_rate=(ship_wreck_train.groupby('Survived')['Sex'].describe().iloc[0,0]\/ship_wreck_train.shape[0])*100\nfemale_survial_rate=(ship_wreck_train.groupby('Survived')['Sex'].describe().iloc[1,0]\/ship_wreck_train.shape[0])*100\n\nprint(f\"Male survial rate {male_survial_rate}\")\nprint(f\"Female survial rate {female_survial_rate}\")\n","a465ca1d":"#Pclass Vs Survived\nsns.countplot(ship_wreck_train['Pclass'],data=ship_wreck_train,hue='Survived')","ca89080d":"sns.countplot(ship_wreck_train['SibSp'],data=ship_wreck_train,hue='Survived')\n#ship_wreck_train.groupby(['Survived','SibSp']).describe()['PassengerId','count'] ","d5f001e0":"sns.countplot(ship_wreck_train['Parch'],data=ship_wreck_train,hue='Survived')","6a83db9f":"ship_wreck_train.groupby(ship_wreck_train[ship_wreck_train['Age'].isna()]['Pclass']).describe()['PassengerId','count']","df097057":"sns.countplot(ship_wreck_train['Embarked'],data=ship_wreck_train,hue='Survived')","a57ca958":"#Creating new feature single as this has highest non survival rate based on 0 Parch and 0 SibSp\nship_wreck_train['Single'] = ship_wreck_train[['Parch','SibSp']].apply(lambda x:0 if ((x['Parch'] == 0) &(x['SibSp'] == 0)) else 1,axis=1)\nship_wreck_test['Single'] = ship_wreck_test[['Parch','SibSp']].apply(lambda x:0 if ((x['Parch'] == 0) &(x['SibSp'] == 0)) else 1,axis=1)","545e5e33":"pclass_1_median=ship_wreck_train[ship_wreck_train['Pclass'] == 1].median()\npclass_2_median=ship_wreck_train[ship_wreck_train['Pclass'] == 2].median()\npclass_3_median=ship_wreck_train[ship_wreck_train['Pclass'] == 3].median()\n\nage_nan_index = ship_wreck_train[ship_wreck_train['Age'].isna()].index\nfor index in age_nan_index:\n    median_value = ship_wreck_train['Age'][(ship_wreck_train['Pclass']== ship_wreck_train.iloc[index][\"Pclass\"])].median()\n    ship_wreck_train.loc[index,'Age'] = median_value","3d5a0772":"pclass_1_median=ship_wreck_test[ship_wreck_test['Pclass'] == 1].median()\npclass_2_median=ship_wreck_test[ship_wreck_test['Pclass'] == 2].median()\npclass_3_median=ship_wreck_test[ship_wreck_test['Pclass'] == 3].median()\n\nage_nan_index = ship_wreck_test[ship_wreck_test['Age'].isna()].index\nfor index in age_nan_index:\n    ship_wreck_test.loc[index,'Age']  = ship_wreck_test['Age'][(ship_wreck_test['Pclass']== ship_wreck_test.iloc[index][\"Pclass\"])].median()\n","bcc7d2e5":"fare_1QR = np.percentile(ship_wreck_train['Fare'],25)\nfare_2QR = np.percentile(ship_wreck_train['Fare'],50)\nfare_3QR = np.percentile(ship_wreck_train['Fare'],75)\nfare_IQR=fare_3QR-fare_1QR\nfare_maxQR=fare_3QR=(1.5*fare_IQR)\nprint(f\"Fare IQR: {fare_1QR}\\nFare 2QR: {fare_2QR}\\nFare 3QR: {fare_3QR}\\nFare IQR: {fare_IQR}\\nFare Maximum QR: {fare_maxQR}\")\n","c2d19d59":"#Filling missing Fare value in test data\nship_wreck_test[ship_wreck_test['Fare'].isnull() == True]","ea2445f2":"ship_wreck_test.loc[152,'Fare'] =ship_wreck_test[ship_wreck_test['Pclass'] == 3].median()['Fare']","44cc46f7":"#Encoding Fare\nship_wreck_train['Fare_groups']=pd.cut(ship_wreck_train['Fare'],5)\nship_wreck_test['Fare_groups']=pd.cut(ship_wreck_test['Fare'],5)","267b5671":"ship_wreck_train['Fare_groups_separation']=LabelEncoder().fit_transform(ship_wreck_train['Fare_groups'])\nship_wreck_test['Fare_groups_separation']=LabelEncoder().fit_transform(ship_wreck_test['Fare_groups'])","7b078035":"emabarked=pd.get_dummies(ship_wreck_train['Embarked'])\nfare_grp=pd.get_dummies(ship_wreck_train['Fare_groups_separation'])\nship_wreck_train['Sex']=pd.get_dummies(ship_wreck_train['Sex']).drop('male',axis=1)\n\nemabarked_test=pd.get_dummies(ship_wreck_test['Embarked'])\nfare_grp_test=pd.get_dummies(ship_wreck_test['Fare_groups_separation'])\nship_wreck_test['Sex']=pd.get_dummies(ship_wreck_test['Sex']).drop('male',axis=1)","d5c5491b":"ship_wreck_train=pd.concat([ship_wreck_train,emabarked,fare_grp],axis=1)\nship_wreck_test=pd.concat([ship_wreck_test,emabarked_test,fare_grp_test],axis=1)","ab973537":"\nfig=plt.figure(figsize=(10,7))\n#sns.set_style('whitegrid')\nsns.heatmap(ship_wreck_train.drop(['PassengerId','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Fare_groups'],axis=1).corr(),annot=True,cmap='coolwarm')\nplt.show()","384e93bb":"#Dropping uncorrelated predictors passengerId, Name\nship_wreck_train.drop(['PassengerId','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Fare_groups','Fare_groups_separation'],axis=1,inplace=True)\nship_wreck_test.drop(['PassengerId','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Fare_groups','Fare_groups_separation'],axis=1,inplace=True)","76f7c1da":"ship_wreck_train.head()","13c0c535":"X=ship_wreck_train.drop('Survived',axis=1)\ny=ship_wreck_train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","edc031d5":"logRg = LogisticRegression()\nlogRg.fit(X_train,y_train)\npredictions=logRg.predict(X_test)\nprint(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","ea23c2c7":"error_mean=[]\nfor i in range(1,30):\n    knn_classifier = KNeighborsClassifier(n_neighbors=i)\n    knn_classifier.fit(X_train,y_train)\n    predictions = knn_classifier.predict(X_test)\n    error_mean.append(np.mean(predictions != y_test))","52bfb61f":"plt.plot(range(1,30),error_mean)","f79eee3c":"knn_classifier = KNeighborsClassifier(n_neighbors=6)\nknn_classifier.fit(X_train,y_train)\npredictions=knn_classifier.predict(X_test)\nprint(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","562e40b4":"dTree = DecisionTreeClassifier()\ndTree.fit(X_train,y_train)\npredictions=dTree.predict(X_test)\nprint(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","13a89d28":"rndFClassifier = RandomForestClassifier(n_estimators=2)\nrndFClassifier.fit(X_train,y_train)\npredictions=rndFClassifier.predict(X_test)\nprint(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","a0b8a017":"2.2 Identify the null features","91218ffb":"****3.Understanding the data using Visualizations**","6f89dcd8":"Titanic Data Analysis\n\n    1. Undertsand the problem\n           a. Define a model that can predict which passengers survived the Titanic from the train data\n\n    2.Load data\n           2.1 View the data \n           2.2 Identify the null features\n    \n    3. Understanding the data using Visualizations\n            3.1 Performing initial correlation with the raw data without any preprocessing\n            3.2 Continuning the data visualization with individual predictors\n                3.2.1 Sex Vs Survived\n                3.2.2 Pclass Vs Survived\n                3.2.3 SibSp Vs Survived\n                3.2.4 Parch Vs Survived\n                3.2.5 Age Vs Survived\n\n    4. Data Preprocessing\n            4.1 Parch\/SibSp are correlated and shows that persons who are single has less survial rate\n            4.2 Filling missing Age\n            4.3 Fare\n            4.4 Encoding Sex,Fare and Embarked columns\n\n    5. Model Selection\n    \n    6. Fit, Predcit, Accuracy using different classification Models\n            6.1 LogisticRegression\n            6.2 KNeighborsClassifier\n                6.2.1 Iterate through n neighbors and find the mean for each prediction\n            6.3 DecisionTreeClassifier\n            6.4 RandomForestClassifier\n        \n    ","203708e4":"**#Observations:**\n1. Plcass 3 male has less survial rate.\n2. Next is Pclass 2 male has less surviva rate","479de8c7":"**3.2.4 Parch Vs Survived**","a0416d30":"**6. Fit, Predcit, Accuracy using different classification Models**","0e3032cf":" **3.2.2 Pclass Vs Survived**","59421bcd":"**3.2.5 Age Vs Survived**\n\nNote: There are 177 missing values and below are the count of missing values for each Pclass","163ad28d":"2.Load data","8b69198c":"**3.2.5 Embarked Vs Surived**","f085e4ea":"**#Observations:**\n1. No parents (single) has less survival rates \n2. And next is parent with single children has less survival rate","9b9f06a8":"**6.1 LogisticRegression**","fe367d7a":"**4.1 Parch\/SibSp are correlated and shows that persons who are single has less survial rate**","991e24a7":"**4.2 Filling missing Age**","6625b692":" **3.1 Performing initial correlation with the raw data without any preprocessing****","8633546d":"**Observations:*\n1. Embarked S has significant less survival rate\n2. So this feature that needs to be included and needs to be encoded","7fd9b5e4":"**5. Model Selection**","a661e53f":"**3.2.3 SibSp Vs Survived**","331b6f54":"6.2.1 Iterate through n neighbors and find the mean for each prediction","bba62fcd":"**6.2 KNeighborsClassifier**","48a5bd16":"**4. Data Preprocessing**","e1631ceb":"**#Observations:**\n1. Females has more survival rate than Males.\n2. This feature needs encoding to be included in the model\n3. But how much is the survial rate?","4cfa398b":"**4.3 Fare **\nThis is one of the correlated one based on the raw data. \nData needs to be preprocessed to be used in the model ","a280e86b":"**4.4 Encoding Sex,Fare and Embarked columns**","b04d53dd":"**3.2.1 Sex Vs Survived **\n","fd85cb89":" 2.1 View the data ","c24c6e8e":" **3.2 Continuning the data visualization with individual predictors**","2cb1a7e1":"**6.4 RandomForestClassifier**","2ceebe23":"**6.3 DecisionTreeClassifier**"}}