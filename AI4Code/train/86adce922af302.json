{"cell_type":{"6d4fa204":"code","1d085f80":"code","ea57a6db":"code","04f946b4":"code","76bdbf7c":"code","5a9b2868":"code","33e1f6de":"code","29c77a3b":"code","8c75b884":"code","61a7c7af":"code","6d26218e":"code","a20a83ea":"code","68cc31b9":"code","05757278":"code","e2a5cb59":"code","2f0c0048":"code","07a71ea9":"code","93f4f304":"code","e085f462":"code","daeb30fd":"code","f030c301":"code","6c4a1601":"code","ffb75ae3":"markdown"},"source":{"6d4fa204":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline","1d085f80":"# Load the data \nos.listdir('..\/input')\nsales_data = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nitem_cat = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nsample_submission = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\ntest_data = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\n","ea57a6db":"sales_data.head()","04f946b4":"test_data.head()","76bdbf7c":"sample_submission.head()","5a9b2868":"# Function that define all the EDA we need \ndef EDA(df):\n    print(\"HEAD OF THE DATA \")\n    print(df.head())\n    print(\"INFO\")\n    print(df.info())\n    print(\"Describe\")\n    print(df.describe())\n    print(\"Columns\")\n    print(df.columns)\n    print(\"Data Types\")\n    print(df.dtypes)\n    print(\"Missing Values\")\n    print(df.isnull().sum())\n    print(\"NULL values\")\n    print(df.isna().sum())\n    print(\"Shape Of Data\")\n    print(df.shape)","33e1f6de":"#Litle bit of exploration of data\n\nprint(\"Sales Data __________________________________\")\nEDA(sales_data)\nprint(\"Test data_____________________________\")\nEDA(test_data)\nprint(\"Item Categories_____________________________\")\nEDA(item_cat)\nprint(\"Items______________________________________\")\nEDA(items)\nprint(\"Shops_______________________________\")\nEDA(shops)\nprint(\"Sample Submission___________________________________\")\nEDA(sample_submission)\n\n","29c77a3b":"#we can see that 'date' column in sales_data is an object but if we want to manipulate  it or want to work on it someway then we have convert it on datetime format\nsales_data['date'] = pd.to_datetime(sales_data['date'],format = '%d.%m.%Y')","8c75b884":"sales_data.head()","61a7c7af":"#now we will create a pivot tabel by going so we get our data in desired form \n#we want get total count value of an item over the whole month for a shop \n# That why we made shop_id and item_id our indices and date_block_num our column \n# the value we want is item_cnt_day and used sum as aggregating function \ndataset = sales_data.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')","6d26218e":"dataset.head()","a20a83ea":"# lets reset our indices, so that data should be in way we can easily manipulate\ndataset.reset_index(inplace = True)","68cc31b9":"# lets check on our pivot table\ndataset.head(3)","05757278":"# Now we will merge our pivot table with the test_data because we want to keep the data of items we have\n# predict\ndataset = pd.merge(test_data,dataset,on = ['item_id','shop_id'],how = 'left')","e2a5cb59":"dataset.head()","2f0c0048":"# lets fill all NaN values with 0\ndataset.fillna(0,inplace = True)\n# lets check our data now \ndataset.head()","07a71ea9":"# we will drop shop_id and item_id because we do not need them\n# we are teaching our model how to generate the next sequence \ndataset.drop(['shop_id','item_id','ID'],inplace = True, axis = 1)\ndataset.head()","93f4f304":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(dataset.values[:,:-1],axis = 2)\n# the last column is our label\ny_train = dataset.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(dataset.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)\n","e085f462":"# importing libraries required for our model\nfrom keras import optimizers\nfrom keras.utils import plot_model\nfrom keras.models import Sequential, Model\nfrom keras.layers.convolutional import Conv1D, MaxPooling1D\nfrom keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Flatten, Dropout\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split","daeb30fd":"# DEFINE our model \nmodel_LSTM = Sequential()\nmodel_LSTM.add(LSTM(units =70,input_shape = (X_train.shape[1], X_train.shape[2])))\nmodel_LSTM.add(Dropout(0.4))\nmodel_LSTM.add(Dense(1))\n\nmodel_LSTM.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nmodel_LSTM.summary()\n","f030c301":"history_lstm = model_LSTM.fit(X_train,y_train,batch_size = 4000,epochs = 12)","6c4a1601":"# Plot the loss curves for training\nplt.plot(history_lstm.history['loss'], color='b', label=\"Training loss\")\nplt.legend(loc='best', shadow=True)","ffb75ae3":"### You can now import the predictions to the submission file "}}