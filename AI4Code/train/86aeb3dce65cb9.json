{"cell_type":{"71f0d13d":"code","52884614":"code","f0c98768":"code","0f022533":"code","ec324c70":"code","358094da":"code","53ddea55":"code","f6a02750":"code","d8fd60a6":"code","2c84996d":"code","b92dc0f6":"code","f49392e6":"code","ff85d791":"code","6397818d":"code","84c5cdb9":"code","5b2ccfb7":"code","2c1a4158":"code","78ad6100":"code","f439d460":"code","0ea5a5b0":"code","d74e0a07":"code","2bfaeeaa":"code","eeea2a09":"code","9addd18b":"code","f8824d4d":"code","d103c979":"code","63c104e7":"code","9ba7f3f9":"code","50000065":"code","7a569da8":"code","d21568d9":"code","1cc77267":"code","25e38ae6":"markdown","02ad6a5b":"markdown","aa6f771f":"markdown","bae4758b":"markdown","f821a62b":"markdown","2d29246e":"markdown","eb9be6f3":"markdown","0e7c1af2":"markdown","66465b39":"markdown"},"source":{"71f0d13d":"from keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import Model,layers\nimport tensorflow as tf\nimport keras\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport cv2\nimport os","52884614":"# Let's create a function to see some images \n\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder,filename))\n        if img is not None:\n            images.append(img)\n        if len(images)>3:\n            break\n    fig=plt.figure(figsize=(10,12))\n    xrange=range(1,5)\n    \n    for img,x in zip(images,xrange):\n        ax=fig.add_subplot(2,2,x)\n        ax.imshow(img)\n        ax.set_title(img.shape)","f0c98768":"load_images_from_folder(\"..\/input\/surface-crack-detection\/Positive\")","0f022533":"load_images_from_folder(\"..\/input\/surface-crack-detection\/Negative\")","ec324c70":"# Define a Callback class that stops training once accuracy reaches 99.9%\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.999):\n            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n            self.model.stop_training = True","358094da":"# You have to add Inception V3 files from \n# file--> add or upload data-->search by URL--> https:\/\/www.kaggle.com\/keras\/inceptionv3\n!ls \/kaggle\/input\n","53ddea55":"# Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '\/kaggle\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\n# Make all the layers in the pre-trained model non-trainable\nfor layer in pre_trained_model.layers:\n     layer.trainable = False\n        \n# Print the model summary\n# pre_trained_model.summary()","f6a02750":"# We will use the part of the pre_trained model from input later until the layer 'mixed7'\n# You can also choose different layer for starting\nlast_layer = pre_trained_model.get_layer('mixed7') \nlast_output = last_layer.output\n\n#Then we add our layers \n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout layer to prevent overfitting\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model(pre_trained_model.input, x)\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['accuracy'])\n    \nmodel.summary()","d8fd60a6":"# Create Data Generator\n# Split data train-validation sets by using validation_split=0.3\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255, validation_split=0.3)\n\ntrain_generator = train_datagen.flow_from_directory('..\/input\/surface-crack-detection',\n                                                     target_size=(150,150),\n                                                     batch_size=64,\n                                                     shuffle=True,\n                                                     class_mode='binary',\n                                                     subset='training')            \n","2c84996d":"validation_datagen = ImageDataGenerator(rescale = 1.\/255, validation_split=0.3)\n\nvalidation_generator =  validation_datagen.flow_from_directory('..\/input\/surface-crack-detection',\n                                                                target_size=(150,150),\n                                                                batch_size=128,\n                                                                class_mode='binary',\n                                                                subset='validation')          \n                                       ","b92dc0f6":"callbacks = myCallback()\n\nhistory = model.fit_generator(train_generator,\n            validation_data = validation_generator,\n            epochs = 3,\n            verbose = 1,\n            callbacks=[callbacks])","f49392e6":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\n\nplt.legend()\n\nplt.show()","ff85d791":"!pwd","6397818d":"model.save('\/kaggle\/working\/Crack_Detection_InceptionV3_model.h5')","84c5cdb9":"!ls \/kaggle\/working","5b2ccfb7":"# load model\n#from keras.models import load_model\n\n#model_inception = load_model('Crack_Detection_InceptionV3_model.h5')\n# summarize model.\n#model_inception.summary()","2c1a4158":"from tensorflow.keras.applications import VGG16\n\nweights_file='\/kaggle\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npretrained_model=VGG16(input_shape = (150, 150, 3), \n                        include_top = False, \n                        weights =None)\n\npretrained_model.load_weights(weights_file)\n\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\npretrained_model.summary()\n","78ad6100":"last_layer = pretrained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(1, activation='sigmoid')(x)           \n\nmodel_vgg = Model(pretrained_model.input, x) \n\n\nmodel_vgg.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['accuracy'])\n\n","f439d460":"train_datagen = ImageDataGenerator(rescale = 1.\/255, validation_split=0.3)\n\ntrain_generator = train_datagen.flow_from_directory('..\/input\/surface-crack-detection',\n                                                     target_size=(150,150),\n                                                     batch_size=64,\n                                                     shuffle=True,\n                                                     class_mode='binary',\n                                                     subset='training') \n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255, validation_split=0.3)\n\nvalidation_generator =  validation_datagen.flow_from_directory('..\/input\/surface-crack-detection',\n                                                                target_size=(150,150),\n                                                                batch_size=64,\n                                                                class_mode='binary',\n                                                                subset='validation')  ","0ea5a5b0":"callbacks = myCallback()\n\nhistory = model_vgg.fit_generator(train_generator,\n                                  validation_data = validation_generator,\n                                  epochs = 3,\n                                  verbose = 1,\n                                  callbacks=[callbacks])","d74e0a07":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\n\nplt.legend()\n\nplt.show()","2bfaeeaa":"model_vgg.save('\/kaggle\/working\/Crack_Detection_VGG16_model.h5')","eeea2a09":"!ls \/kaggle\/working","9addd18b":"# You have to add ResNet50 files from \n# file--> add or upload data-->search by URL--> https:\/\/www.kaggle.com\/keras\/resnet50\n","f8824d4d":"from tensorflow.keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.models import Sequential\nfrom keras.layers import Dense","d103c979":"train_datagen = ImageDataGenerator(validation_split=0.3,\n                                   preprocessing_function=preprocess_input) # don't use rescale = 1.\/255\n\ntrain_generator = train_datagen.flow_from_directory('..\/input\/surface-crack-detection',\n                                                     target_size=(224,224),\n                                                     batch_size=64,\n                                                     shuffle=True,\n                                                     class_mode='categorical',\n                                                     subset='training')\n\nvalidation_datagen = ImageDataGenerator(validation_split=0.3,\n                                        preprocessing_function=preprocess_input)\n\nvalidation_generator =  validation_datagen.flow_from_directory('..\/input\/surface-crack-detection',\n                                                                target_size=(224,224),\n                                                                batch_size=64,\n                                                                class_mode='categorical',\n                                                                subset='validation')     ","63c104e7":"model_res50 = Sequential()\n\nmodel_res50.add(ResNet50(\n    include_top=False,\n    pooling='avg',\n    weights='imagenet'\n    ))\n\nmodel_res50.add(Dense(2, activation='softmax'))\n\nmodel_res50.layers[0].trainable = False \n\nmodel_res50.summary()\n\n","9ba7f3f9":"steps_per_epoch_training = len(train_generator)\nsteps_per_epoch_validation = len(validation_generator)","50000065":"callbacks = myCallback()\n\nmodel_res50.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\n\nfit_history = model_res50.fit_generator(\n    train_generator,\n    steps_per_epoch=steps_per_epoch_training,\n    validation_steps=steps_per_epoch_validation,\n    epochs=7,\n    validation_data=validation_generator,\n    verbose=1,\n    callbacks=[callbacks]\n)","7a569da8":"acc = fit_history.history['accuracy']\nval_acc = fit_history.history['val_accuracy']\nloss = fit_history.history['loss']\nval_loss = fit_history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\n\nplt.legend()\n\nplt.show()","d21568d9":"model_res50.save('\/kaggle\/working\/Crack_Detection_ResNet50_model.h5')","1cc77267":"!ls \/kaggle\/working","25e38ae6":"## ResNet50 \n\nhttps:\/\/www.kaggle.com\/keras\/resnet50\n\nResNet, short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks. This model was the winner of ImageNet challenge in 2015. The fundamental breakthrough with ResNet was it allowed us to train extremely deep neural networks with 150+layers successfully. Prior to ResNet training very deep neural networks was difficult due to the problem of vanishing gradients. AlexNet, the winner of ImageNet 2012 and the model that apparently kick started the focus on deep learning had only 8 convolutional layers, the VGG network had 19 and Inception or GoogleNet had 22 layers and ResNet 152 had 152 layers. In this blog we will code a ResNet-50 that is a smaller version of ResNet 152 and frequently used as a starting point for transfer learning.","02ad6a5b":"# Libraries","aa6f771f":"## 2. VGG16\n\nhttps:\/\/www.kaggle.com\/keras\/vgg16\n\nThe input to conv1 layer is of fixed size 224 x 224 RGB image. The image is passed through a stack of convolutional (conv.) layers, where the filters were used with a very small receptive field: 3\u00d73 (which is the smallest size to capture the notion of left\/right, up\/down, center). In one of the configurations, it also utilizes 1\u00d71 convolution filters, which can be seen as a linear transformation of the input channels (followed by non-linearity). The convolution stride is fixed to 1 pixel; the spatial padding of conv. layer input is such that the spatial resolution is preserved after convolution, i.e. the padding is 1-pixel for 3\u00d73 conv. layers. Spatial pooling is carried out by five max-pooling layers, which follow some of the conv. layers (not all the conv. layers are followed by max-pooling). Max-pooling is performed over a 2\u00d72 pixel window, with stride 2.\n\nThree Fully-Connected (FC) layers follow a stack of convolutional layers (which has a different depth in different architectures): the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is the soft-max layer. The configuration of the fully connected layers is the same in all networks.\n\nAll hidden layers are equipped with the rectification (ReLU) non-linearity. It is also noted that none of the networks (except for one) contain Local Response Normalisation (LRN), such normalization does not improve the performance on the ILSVRC dataset, but leads to increased memory consumption and computation time.","bae4758b":"# Preparing the Dataset","f821a62b":"### How to Load a Model","2d29246e":"## 1. Inception V3 \n\nhttps:\/\/www.kaggle.com\/keras\/inceptionv3\n\nInception-v3 is a convolutional neural network that is 48 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. As a result, the network has learned rich feature representations for a wide range of images. The network has an image input size of 299-by-299.","eb9be6f3":"### How to Save a Model\n- Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later.\n\n- you have to load your model to local because in Kaggle your model will disappear after closed the session. :(","0e7c1af2":"## In this notebook, you will learn principally how to use\n \n- ImageDataGenerator,\n- Differents Pretrained Models\n\n<font color='red'> IF YOU FIND THIS NOTEBOOK HELPFUL, PLEASE LEAVE A UPVOTE :) THANKS IN ADVANCE <\/font>","66465b39":"## Conclusion\n\n- Apparently ResNet50 has the best result for this dataset.\n- But we can also get similar results with others by changing some hyperparameters "}}