{"cell_type":{"6e763ae8":"code","74aa25c2":"code","d6f2a00e":"code","49126804":"code","3946256e":"code","342f25c1":"code","970c6f0c":"code","1f0bad07":"code","b2f8c93e":"code","cb4bfae3":"code","4adf2008":"code","66a5b28d":"code","ec45f736":"code","e25a7cb4":"code","41097824":"code","fff927fd":"code","4e3ed3ba":"code","7be302f3":"code","34dc0f16":"code","627a7c8e":"code","8e30c14b":"code","a76a3f68":"code","fef3ec28":"code","81a61c5b":"code","29936628":"code","4a3ba16a":"code","68ed6ee2":"code","56df4e32":"code","3b2c7e60":"code","f95ea707":"code","884b05d6":"code","a809a303":"code","291c5e14":"code","a2589018":"code","94781a69":"code","b9d40e06":"code","a7c71125":"code","455def06":"code","e6fa3b0f":"code","792b09cc":"code","80e009bf":"code","ca65ae71":"code","a6d20cca":"code","e7b65e84":"code","21d3ce97":"code","a1e86c59":"code","ff46472d":"code","3fb1bcc8":"code","1316ed08":"code","17ce72af":"code","7f4e366a":"code","6021c794":"code","afd3d269":"code","d37713c8":"code","2da834cb":"code","d417f5bb":"code","1497bcef":"code","14e8d484":"markdown","fb722140":"markdown","aaa06812":"markdown","32a81d47":"markdown","44fddcd3":"markdown","ad647b21":"markdown","a001f7bc":"markdown","57bb8f9a":"markdown","a37262bd":"markdown","e45a07ca":"markdown","f512282b":"markdown","27c9100e":"markdown","ec0a0df7":"markdown","f7cadb3c":"markdown","69449303":"markdown","fa299cb3":"markdown","03f33f0b":"markdown","2a85becf":"markdown","f161be72":"markdown","23ac5e92":"markdown","05bfdbf4":"markdown","c898bb6f":"markdown","216d53f7":"markdown","83d3ef50":"markdown","7f5abb0c":"markdown","cee5e17f":"markdown","17342055":"markdown","48f2ffbd":"markdown"},"source":{"6e763ae8":"# Installing packages (If there are the following pakcages on the kaggle system, we can delete this section)\n!pip install pdpipe\n!pip install geopandas\n!pip install us","74aa25c2":"# Loading packages \nimport datetime as dt \nimport geopandas as gpd\nimport glob \nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport numpy as np \nimport pandas as pd \nimport pdpipe as pdp\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline\nimport re \nimport seaborn as sns \nimport us\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom plotly.subplots import make_subplots\nfrom sklearn.preprocessing import scale","d6f2a00e":"# Importing district.csv\ndf_district1 = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\ndf_district1","49126804":"# Excluding all \u201cNaN\u201d for the state column and remaining all other columns\ndf_district2 = df_district1.copy()\ndf_district2.dropna(subset=['state'], inplace=True)\n\n# Deleting the county_connections_ratio (All values are identical)\ndf_district2.drop(columns='county_connections_ratio', inplace=True)\ndf_district2","3946256e":"len(pd.unique(df_district1['state']))","342f25c1":"len(pd.unique(df_district1['district_id']))","970c6f0c":"# Checking the state differences between the original dataset and the dataset excluding NaN\nlen(pd.unique(df_district1['state']))-len(pd.unique(df_district2['state']))","1f0bad07":"# Checking the district differences between the original dataset and the dataset excluding NaN\nlen(pd.unique(df_district1['district_id']))-len(pd.unique(df_district2['district_id']))","b2f8c93e":"# Turning the two variables (black\/hispanic, reduced\/free) into likert scale\nlikert_scale = {'[0, 0.2[':'1', '[0.2, 0.4[':'2', '[0.4, 0.6[':'3', '[0.6, 0.8[':'4', '[0.8, 1[':'5'}\n# Changing the variable names\ndf_district2['pct_black\/hispanic'].replace(likert_scale, inplace=True)\ndf_district2['pct_free\/reduced'].replace(likert_scale, inplace=True)\n\n# Turning the pp_total variable into mid-point\npp_total = df_district2['pp_total_raw'].str.replace('[','').str.split(',', expand = True).astype(float)\ndf_district2['pp_total_raw'] = (pp_total[0]+pp_total[1])\/2\n\n# Reordering locale\ndf_district2['locale'] = df_district2['locale'].astype('category')\ndf_district2['locale'].cat.reorder_categories(['Rural', 'Town','Suburb','City'], inplace=True)\n\n# Dummy coding - locale\ndf_district2 = df_district2.join(df_district2['locale'].str.get_dummies())\ndf_district2","cb4bfae3":"# Adding state abbreviation into the dataset\nabbr = ['na']*len(df_district2)\ni=0\n\nfor s in df_district2['state']:\n  state=us.states.lookup(s)\n  abbr[i] = state.abbr\n  i += 1\n\ndf_district2['state_abbr'] = abbr\ndf_district2","4adf2008":"# Inspecting all the district per state\ndf_district2.groupby(\"state\")[\"district_id\"].apply(set).to_frame()","66a5b28d":"# Distribution and proportion of locale\nfig, (ax1, ax2) = plt.subplots(1,2)\nsns.countplot(x=\"locale\", data=df_district2, ax=ax1)\nax2.pie(df_district2['locale'].value_counts(),labels = df_district2['locale'].unique(), \n        colors=['tab:green','tab:blue','tab:red','tab:orange'], autopct='%1.1f%%')\nplt.show()","ec45f736":"# Distribution and proportion of black\/hispanic\nfig, (ax1, ax2) = plt.subplots(1,2)\nsns.countplot(x='pct_black\/hispanic', data=df_district2, ax=ax1).set_xticklabels(labels = [\"0-20%\",\"20-40%\",\"40-60%\",\"60-80%\",\"80-100%\"], rotation=45)\nax2.pie(df_district2['pct_black\/hispanic'].value_counts(),labels = [\"0-20%\",\"20-40%\",\"40-60%\",\"60-80%\",\"80-100%\"], autopct='%1.1f%%')\nplt.show()","e25a7cb4":"#Distribution of race\/ethnicity and locale\nsns.displot(data=df_district2, y='pct_black\/hispanic', hue= 'pct_black\/hispanic', col='locale', height=5, aspect=.8).set_yticklabels(labels = [\"0-20%\",\"20-40%\",\"40-60%\",\"60-80%\",\"80-100%\"])","41097824":"# Importing products.csv\ndf_products = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\ndf_products","fff927fd":"# Dividing sector(s) into dummy variables\ndf_sectors = df_products['Sector(s)'].str.get_dummies(sep=\"; \")\ndf_sectors.columns = [\"Sector_Corporate\",\"Sector_HigherEd\",\"Sector_Prek-12\"]\ndf_products = df_products.join(df_sectors)\ndf_products","4e3ed3ba":"df_products['primary_function_main'] = df_products['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\ndf_products['primary_function_sub1'] = df_products['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\ndf_products['primary_function_sub2'] = df_products['Primary Essential Function'].apply(lambda x: x.split(' - ')[-1] if x == x else x)\n\ndf_products","7be302f3":"df_length = len(df_products['primary_function_sub1'])\nfor i in range(df_length): \n  if df_products['primary_function_sub1'][i] == df_products['primary_function_sub2'][i]:\n     df_products['primary_function_sub2'][i] = None\ndf_products","34dc0f16":"# Deleting a duplicate column from the dataframe\ndf_products = df_products.drop([\"Primary Essential Function\"], axis=1)\ndf_products","627a7c8e":"# Checking whether every company's product name is same or not.\nlen(df_products[\"Product Name\"].unique())","8e30c14b":"# Checking whether every Provider\/Company Name is same or not\nlen(df_products[\"Provider\/Company Name\"].unique())","a76a3f68":"# Distribution of top 10 provider\/company names\n# explain where this 30 coming from \n# check this out\nsns.countplot(y='Provider\/Company Name', data=df_products, order=df_products[\"Provider\/Company Name\"].value_counts().index[:10])\nplt.title(\"Top 10 Provider\/Company Names\")\nplt.show()","fef3ec28":"# Subsetting top 10 provider\/company name\ndf_products2 = df_products[df_products[\"Provider\/Company Name\"].isin(list(df_products[\"Provider\/Company Name\"].value_counts().index[:10]))]\n\n# Reordering 'Sector(s)'\ndf_products2['Sector(s)'] = df_products2['Sector(s)'].astype('category')\ndf_products2['Sector(s)'].cat.reorder_categories(['PreK-12','PreK-12; Higher Ed; Corporate','PreK-12; Higher Ed'], inplace=True)","81a61c5b":"# Importing all files in the engagement folder and merging them into one file\nall_files = glob.glob(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\" + \"\/*.csv\")\n\nmerged_df = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    # add district_id from the data file name\n    df[\"district_id\"] = filename.replace(\"\\\\\", \"\/\").split(\"\/\")[-1].split(\".\")[0]\n    merged_df.append(df)\n\ndf_engagement = pd.concat(merged_df, axis=0, ignore_index=True)\n\ndf_engagement.head()","29936628":"# Checking the number of district id\nlen(df_engagement[\"district_id\"].unique())","4a3ba16a":"# Checking the number of lp id (products)\nlen(df_engagement[\"lp_id\"].unique())","68ed6ee2":"# Checking the types of variables\ndf_engagement.info()","56df4e32":"# Converting variable types\nconvert_dict = {'district_id': 'int64'}\ndf_engagement = df_engagement.astype(convert_dict)\ndf_engagement['time'] = pd.to_datetime(df_engagement['time'])\n\n# Checking the types of variables again\ndf_engagement.info()","3b2c7e60":"# Merging district data with engagement data by district_ID\nmerge_en_dist = pd.merge(df_engagement, df_district1, on='district_id')\nmerge_en_dist","f95ea707":"merge_en_dist = merge_en_dist.drop('pp_total_raw', 1)","884b05d6":"# Trying to think of how to merge engagement data with districts data set(Dana)\ndf_new_pro = df_products.rename(columns={'LP ID':'lp_id'})\n\n# Merging product data with engagement data by LPID(Dana)\nmerge_all = pd.merge(merge_en_dist, df_new_pro, on='lp_id')","a809a303":"len(merge_all[\"lp_id\"].unique())","291c5e14":"len(merge_all[\"Provider\/Company Name\"].unique())","a2589018":"len(merge_all[\"state\"].unique())","94781a69":"len(merge_all[\"district_id\"].unique())","b9d40e06":"# Checking the proportions of missingness\nmerge_all.isnull().sum() \/ len(merge_all)","a7c71125":"pct_time_mean_s = merge_all.groupby(['time', 'state'])['pct_access'].mean()\npct_time_mean_s = pct_time_mean_s.reset_index()\npct_time_mean_s","455def06":"fig = px.line(pct_time_mean_s, x=\"time\", y=\"pct_access\", color='state',title='Percentage of access in a given day in each state',\n               template=\"ggplot2\", width=2000, height=800)\nfig.show()","e6fa3b0f":"en_time_mean_s = merge_all.groupby(['time', 'state'])['engagement_index'].mean()\nen_time_mean_s = en_time_mean_s.reset_index()\nen_time_mean_s","792b09cc":"fig = px.line(en_time_mean_s, x=\"time\", y=\"engagement_index\", color='state',title='average page load of students in a given a day in each state',\n               template=\"ggplot2\", width=2000, height=800)\nfig.show()","80e009bf":"pct_time_mean_l = merge_all.groupby(['time', 'locale'])['pct_access'].mean()\npct_time_mean_l = pct_time_mean_l.reset_index()\npct_time_mean_l","ca65ae71":"fig = px.line(pct_time_mean_l, x=\"time\", y=\"pct_access\", color='locale',title='percentage of access in a given day by locale',\n               template=\"ggplot2\", width=2000, height=800)\nfig.show()","a6d20cca":"en_time_mean_l = merge_all.groupby(['time', 'locale'])['engagement_index'].mean()\nen_time_mean_l = en_time_mean_l.reset_index()\nen_time_mean_l","e7b65e84":"fig = px.line(en_time_mean_l, x=\"time\", y=\"engagement_index\", color='locale',title='average page load of students in a given a day by locale',\n               template=\"ggplot2\", width=2000, height=800)\nfig.show()","21d3ce97":"# use the desire columns: time, pct_access, City, Rural, Suburb, Town, state_abbr, Product Name\ndf_all = merge_all[['time','pct_access','locale','Provider\/Company Name','pct_black\/hispanic','pct_free\/reduced']]","a1e86c59":"# For each locale, aggregate their pct_access on each day\ndf_locale = df_all.groupby(['locale', 'time'], as_index=False).agg({'pct_access':'mean'})","ff46472d":"# Google dataset\nmask = df_all['Provider\/Company Name'].str.contains('Google')\ndf_all['Google'] = np.where(mask, 1, 0)\n# percentage of google for each subscale for each day\ndf_google = df_all.groupby(['locale', 'time'], as_index=False).agg({'Google':lambda x: sum(x)\/len(x)})#mean('pct_access')","3fb1bcc8":"# plot it\nimport plotly.express as px\nfig = px.line(df_locale, x=\"time\", y=\"pct_access\", color='locale',\n              labels = {\n                  'pct_access':'Access Index'\n              },\n              title='Percentage of students with at least one-page load event on a given day',\n               template=\"ggplot2\", width=1500, height=500)\nfig.show()","1316ed08":"# for city in locale == rural, the pct_black\/hispanic\ndf_rural_bh = df_all[df_all['locale'] == 'Rural']\ndf_rural_bh = df_rural_bh.groupby(['pct_black\/hispanic', 'time'], as_index=False).agg({'pct_access':'mean'})\n\ndf_suburb_bh = df_all[df_all['locale'] == 'Suburb']\ndf_suburb_bh = df_suburb_bh.groupby(['pct_black\/hispanic', 'time'], as_index=False).agg({'pct_access':'mean'})\n\ndf_city_bh = df_all[df_all['locale'] == 'City']\ndf_city_bh = df_city_bh.groupby(['pct_black\/hispanic', 'time'], as_index=False).agg({'pct_access':'mean'})\n\ndf_town_bh = df_all[df_all['locale'] == 'Town']\ndf_town_bh = df_town_bh.groupby(['pct_black\/hispanic', 'time'], as_index=False).agg({'pct_access':'mean'})","17ce72af":"fig = px.line(df_rural_bh, x=\"time\", y=\"pct_access\", color='pct_black\/hispanic',\n                            labels = {\n                  'pct_access':'Access Index'\n              },\n              title='Rural Area Percentage of Access on a Given Day',\n               template=\"ggplot2\", width=1500, height=500)\nfig.update_yaxes(range=[0, 3])\nfig.show()","7f4e366a":"fig = px.line(df_suburb_bh, x=\"time\", y=\"pct_access\", color='pct_black\/hispanic',\n                            labels = {\n                  'pct_access':'Access Index'\n              },\n              title='Suburb Area Percentage of Access on a Given Day',\n               template=\"ggplot2\", width=1500, height=500)\nfig.update_yaxes(range=[0, 3])\nfig.show()","6021c794":"fig = px.line(df_city_bh, x=\"time\", y=\"pct_access\", color='pct_black\/hispanic',\n                            labels = {\n                  'pct_access':'Access Index'\n              },\n              title='City Area Percentage of Access on a Given Day',\n               template=\"ggplot2\", width=1500, height=500)\nfig.update_yaxes(range=[0, 3])\nfig.show()","afd3d269":"fig = px.line(df_town_bh, x=\"time\", y=\"pct_access\", color='pct_black\/hispanic',\n                            labels = {\n                  'pct_access':'Access Index'\n              },\n              title='City Area Percentage of Access on a Given Day',\n               template=\"ggplot2\", width=1500, height=500)\nfig.update_yaxes(range=[0, 3])\nfig.show()","d37713c8":"# plot it\nfig = px.line(df_google, x=\"time\", y=\"Google\", color='locale',\n              labels = {\n                  'Google':'Percentage of Google Usage'\n              },\n              title='Percentage of Google usage on a given day',\n               template=\"ggplot2\", width=1500, height=500)\nfig.show()","2da834cb":"google_function = merge_all[merge_all['Provider\/Company Name'] == 'Google LLC'] \navg_google_func = google_function.groupby(['time', 'primary_function_sub1'])['pct_access'].mean()\navg_google_func = avg_google_func.reset_index()\navg_google_func","d417f5bb":"fig = px.line(avg_google_func, x=\"time\", y=\"pct_access\", color='primary_function_sub1',title='Average Percentage of Access of Google by its Funtion',\n               template=\"ggplot2\", width=2000, height=800)\nfig.show()","1497bcef":"data_to_submit = pd.DataFrame({\n    'district_id':df_district1['district_id'],\n    'district_id':merge_all['district_id']\n})\ndata_to_submit.to_csv('csv_to_submit.csv', index = False)","14e8d484":"According to all the above plots, we can see that the learning plat forms were used during the academic year. Its usage drops over the summer break season. From this, generally we can infer that the platforms were mostly used to support students learning during the school season.","fb722140":"#### Google products","aaa06812":"According to the missingness, we are going to use pct_access more than engagement index since there are less missing data. ","32a81d47":"####Trend of Average Percent Acess by Locale","44fddcd3":"* Districts located in suburban and city areas are likely to have higher portions of Black\/Hispanic populations.","ad647b21":"####Trend of Average Engagement Index by Locale","a001f7bc":"In the above plot shows how the general population looks like within each locale. 59.1% live in suburb then rural and city follows respectively.","57bb8f9a":"Based on the above plot, districts that are **rural** have the highest percentage of students with at least one-page load throughout the time, while **city** districts sometimes have the lowest. This result is the opposite to what we initially expected. \n\nIn the following section, we will see a more detailed picture for each locale category based on their percentage of black\/hispanic and percentage of free\/reduced cost lunch. We want to see if the result will also be unexpected. ","a37262bd":"#### Trend of Average Engement Index by State","e45a07ca":"Before we start, below analysis used Google data due to its highest usage among all the platforms. This can be seen in the above bar plot where the it shows the count of each platforms.","f512282b":"* The original dataset (distric.csv) has 24 states and 233 districts. \n* Once we exclude missing values in the 'state' column, we have 23 states and 176 districts.","27c9100e":"* The proportion of the Black\/Hispanic population in the districts, which account for 65.9% of the total districts, ranges from 0 to 20%.","ec0a0df7":"#Usage Trend over time","f7cadb3c":"The interesting fact about this plot is that the product google has been divided by its function. Here, we can see that among all the functions that google provide, 'Learning Management System' was the most used product. Referring that google product was used mostly during the academic years, this indicates that the product was used to facilitate students' learning. Seems like instructors were using google product to manage students during class sessions. \n\nAccording to https:\/\/elearningindustry.com\/google-classroom-a-free-learning-management-system-for-elearning\ngoogle classroom 'learning management system'(LMS) provides instructors to give out assignments through google docs(paperless), provide students' assignment deadline, and the collected students data give students feedback for their learning process. Another interesting fact about this platform is that it has a function to track students access to the platform. This indicates that it enables teachers to monitor students' activity and can give personalized guidance for them.  \nThis is very interesting and can be critical in learning platform industry. Due to covid-19, students had to take classes from home and because of that, teachers weren't able to manage students. From this, we can infer that instructors were trying to maintain student management by learning platforms. \n \nWhat we can take away from this graph is that among all the functions, LMS shows dominant usage among users. Since Goolge is one of the most used learning platforms, other platforms can improve LMS function or adopt LMS to improve their platforms and possibly help increase user nember as well.  ","69449303":"* Google LLC is the top provider among 291 companies. So we are going to focus on Google data to see how was the learning trend was like during 2020 and what we can learn from this company to possibly give information to improve other learning platforms. ","fa299cb3":"Since the data set contains multiple time stamps, we focused on students' usage over time. \nFor the analysis, we tried looking the data in different ways to see students behavioral trend and turned out that they all show similar trend over time. ","03f33f0b":"# Introduction","2a85becf":"### Preparations for Data Analysis","f161be72":"### Data management and visualization of **engagement** data sets","23ac5e92":"* Districts are not equally distributed. Some districts could be over-representative (e.g., Arizona, Florida, Minnesota, etc.) \nTherefore, to find general trend looking at locale level data might be more reasonable.","05bfdbf4":"$Problem Statement$\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow.\n\nThe purpose of the current Kaggle challenge is to investigate (1) the state of digital learning in 2020 and (2) how the engagement of digital learning relates to factors such as district demographics, broadband access, and state\/national level policies and events.\n\n$Questions$\n\n* During 2020 what type of learning platforms were used and which was dominant?\n* Within Google product what type of function was used the most?\n* How does student engagement with different types of education technology change over the course of the pandemic?\n* How does student engagement with online learning platforms looks like according to different geography and demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n\nParticipants of this Notebook\n* kaggle id\n* imda27(User ID 7381393), Meredith(User ID 8162594), kimyoungwon(User ID 7177865)\n\n* Names\n* Dana(Daeun) Im, Meredith Luo, Youngwon Kim  ","c898bb6f":"In the previous section, we found that Google is the most frequently appeared company in this dataset. Therefore, we want to explore whether the percentage of Google products usage changes throughout the pandemic period and whether the percentages are different among different locales. \n\nAs shown by the plot above, we can see that the percentage of Google products increased substantially starting from June to August, which should be during the summer break. Additionally, compared to city and suburb, town and rural areas used higher percentage of Google products.","216d53f7":"### Exploratory data analysis of the *merged dataset*\n\n\n","83d3ef50":"* Once we merge all three files, we have 369 different products, 289 providers\/companies, and 23 states, and 176 districts.\n* The total number of rows is 9,139,701.","7f5abb0c":"### Data management and visualization of **district.csv**\n\n","cee5e17f":"# Interesting fact about google by its function","17342055":"### Data management and visualization of **products_info.csv**","48f2ffbd":"#### Trend of Average Percent Access by State"}}