{"cell_type":{"83a4aa75":"code","573b0ae0":"code","4e08a60e":"code","3413e9a4":"code","d5d7eff8":"code","d73d86ed":"code","8581880f":"code","53eedf03":"code","19e1087f":"code","fad76239":"code","a5b6202d":"code","8e4d4859":"code","815feadc":"code","f9f72f29":"code","662caeb5":"code","fead04b4":"code","ee87c74d":"code","c867f03b":"code","1a70cebc":"code","3af36a33":"code","0c38f7dd":"code","1b935283":"code","c004f8e5":"code","82453686":"code","006e52c9":"code","7f62a52c":"code","1f7a45ee":"code","ff7aaf4a":"code","bac77855":"code","14fa1854":"code","005414ff":"code","81d618e9":"code","f3004e61":"code","70ea7703":"code","4efcd8ea":"code","a45ad713":"markdown","ce736438":"markdown","c0b6d62a":"markdown","322ebff2":"markdown","8c476b84":"markdown","1caf23b9":"markdown","875eb45c":"markdown"},"source":{"83a4aa75":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","573b0ae0":"df_train = pd.read_csv(\"..\/input\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/test.csv\")","4e08a60e":"df_train.head()","3413e9a4":"df_test.head()","d5d7eff8":"print(\"length of train dataset:\", len(df_train))\nprint(\"length of test dataset:\", len(df_test))","d73d86ed":"df_month_counts_train = pd.DataFrame(df_train['first_active_month'].value_counts())\ndf_month_counts_train = df_month_counts_train.reset_index()\ndf_month_counts_train.columns = ['first_active_month', 'count']\ndf_month_counts_train = df_month_counts_train.sort_values(by=['first_active_month'])\ndf_month_counts_train = df_month_counts_train.reset_index()\ndf_month_counts_train = df_month_counts_train.drop(columns=['index'])","8581880f":"df_month_counts_train.head()","53eedf03":"df_month_counts_train.sort_values(by=['first_active_month'], ascending=False).head()","19e1087f":"df_month_counts_test = pd.DataFrame(df_test['first_active_month'].value_counts())\ndf_month_counts_test = df_month_counts_test.reset_index()\ndf_month_counts_test.columns = ['first_active_month', 'count']\ndf_month_counts_test = df_month_counts_test.sort_values(by=['first_active_month'])\ndf_month_counts_test = df_month_counts_test.reset_index()\ndf_month_counts_test = df_month_counts_test.drop(columns=['index'])","fad76239":"df_month_counts_test.head()","a5b6202d":"df_month_counts_test.sort_values(by=['first_active_month'], ascending=False).head()","8e4d4859":"plt.figure(figsize=(15,10))\nsns.barplot(x=\"first_active_month\", y=\"count\", data=df_month_counts_train)\nplt.xticks(rotation= 90)\nplt.xlabel('Month')\nplt.ylabel('Count')\nplt.title('First Active Month Counts - Train Data')","815feadc":"plt.figure(figsize=(15,10))\nsns.barplot(x=\"first_active_month\", y=\"count\", data=df_month_counts_test)\nplt.xticks(rotation= 90)\nplt.xlabel('Month')\nplt.ylabel('Count')\nplt.title('First Active Month Counts - Test Data')","f9f72f29":"df_month_means = df_train.groupby(['first_active_month']).mean()\ndf_month_means = df_month_means.reset_index()\ndf_month_means = df_month_means.sort_values(by=['first_active_month'])\ndf_month_means = df_month_means.reset_index()\ndf_month_means = df_month_means.drop(columns=['index'])","662caeb5":"df_month_means","fead04b4":"plt.figure(figsize=(15,10))\nsns.barplot(x=\"first_active_month\", y=\"target\", data=df_month_means)\n#sns.relplot(x=\"first_active_month\", y=\"target\", kind=\"line\", data=df_month_means);\nplt.xticks(rotation= 90)\nplt.xlabel('Month')\nplt.ylabel('Target')\nplt.title('Monthly Customer Loyalty')","ee87c74d":"df_month_means.sort_values(by=['target']).head()","c867f03b":"plt.figure(figsize=(15,10))\nsns.violinplot(y=\"target\", data=df_train, palette=\"muted\")\nplt.title('Violin Plot for Customer Loyalty')","1a70cebc":"plt.figure(figsize=(15,10))\nsns.distplot(df_train[\"target\"]);\nplt.title('Histogram for Customer Loyalty')","3af36a33":"# Function: print_quantile_info(qu_dataset, qu_field)\n#   Print out the following information about the data\n#   - interquartile range\n#   - upper_inner_fence\n#   - lower_inner_fence\n#   - upper_outer_fence\n#   - lower_outer_fence\n#   - percentage of records out of inner fences\n#   - percentage of records out of outer fences\n# Input: \n#   - pandas dataframe (qu_dataset)\n#   - name of the column to analyze (qu_field)\n# Output:\n#   None\n\ndef print_quantile_info(qu_dataset, qu_field):\n    a = qu_dataset[qu_field].describe()\n    \n    iqr = a[\"75%\"] - a[\"25%\"]\n    print(\"interquartile range:\", iqr)\n    \n    upper_inner_fence = a[\"75%\"] + 1.5 * iqr\n    lower_inner_fence = a[\"25%\"] - 1.5 * iqr\n    print(\"upper_inner_fence:\", upper_inner_fence)\n    print(\"lower_inner_fence:\", lower_inner_fence)\n    \n    upper_outer_fence = a[\"75%\"] + 3 * iqr\n    lower_outer_fence = a[\"25%\"] - 3 * iqr\n    print(\"upper_outer_fence:\", upper_outer_fence)\n    print(\"lower_outer_fence:\", lower_outer_fence)\n    \n    count_over_upper = len(qu_dataset[qu_dataset[qu_field]>upper_inner_fence])\n    count_under_lower = len(qu_dataset[qu_dataset[qu_field]<lower_inner_fence])\n    percentage = 100 * (count_under_lower + count_over_upper) \/ a[\"count\"]\n    print(\"percentage of records out of inner fences: %.2f\"% (percentage))\n    \n    count_over_upper = len(qu_dataset[qu_dataset[qu_field]>upper_outer_fence])\n    count_under_lower = len(qu_dataset[qu_dataset[qu_field]<lower_outer_fence])\n    percentage = 100 * (count_under_lower + count_over_upper) \/ a[\"count\"]\n    print(\"percentage of records out of outer fences: %.2f\"% (percentage))","0c38f7dd":"# Function: remove_outliers_using_quantiles(qu_dataset, qu_field, qu_fence)\n#   1- Remove outliers according to the given fence value and return new dataframe.\n#   2- Print out the following information about the data\n#      - interquartile range\n#      - upper_inner_fence\n#      - lower_inner_fence\n#      - upper_outer_fence\n#      - lower_outer_fence\n#      - percentage of records out of inner fences\n#      - percentage of records out of outer fences\n# Input: \n#   - pandas dataframe (qu_dataset)\n#   - name of the column to analyze (qu_field)\n#   - inner (1.5*iqr) or outer (3.0*iqr) (qu_fence) values: \"inner\" or \"outer\"\n# Output:\n#   - new pandas dataframe (output_dataset)\n\ndef remove_outliers_using_quantiles(qu_dataset, qu_field, qu_fence):\n    a = qu_dataset[qu_field].describe()\n    \n    iqr = a[\"75%\"] - a[\"25%\"]\n    print(\"interquartile range:\", iqr)\n    \n    upper_inner_fence = a[\"75%\"] + 1.5 * iqr\n    lower_inner_fence = a[\"25%\"] - 1.5 * iqr\n    print(\"upper_inner_fence:\", upper_inner_fence)\n    print(\"lower_inner_fence:\", lower_inner_fence)\n    \n    upper_outer_fence = a[\"75%\"] + 3 * iqr\n    lower_outer_fence = a[\"25%\"] - 3 * iqr\n    print(\"upper_outer_fence:\", upper_outer_fence)\n    print(\"lower_outer_fence:\", lower_outer_fence)\n    \n    count_over_upper = len(qu_dataset[qu_dataset[qu_field]>upper_inner_fence])\n    count_under_lower = len(qu_dataset[qu_dataset[qu_field]<lower_inner_fence])\n    percentage = 100 * (count_under_lower + count_over_upper) \/ a[\"count\"]\n    print(\"percentage of records out of inner fences: %.2f\"% (percentage))\n    \n    count_over_upper = len(qu_dataset[qu_dataset[qu_field]>upper_outer_fence])\n    count_under_lower = len(qu_dataset[qu_dataset[qu_field]<lower_outer_fence])\n    percentage = 100 * (count_under_lower + count_over_upper) \/ a[\"count\"]\n    print(\"percentage of records out of outer fences: %.2f\"% (percentage))\n    \n    if qu_fence == \"inner\":\n        output_dataset = qu_dataset[qu_dataset[qu_field]<=upper_inner_fence]\n        output_dataset = output_dataset[output_dataset[qu_field]>=lower_inner_fence]\n    elif qu_fence == \"outer\":\n        output_dataset = qu_dataset[qu_dataset[qu_field]<=upper_outer_fence]\n        output_dataset = output_dataset[output_dataset[qu_field]>=lower_outer_fence]\n    else:\n        output_dataset = qu_dataset\n    \n    print(\"length of input dataframe:\", len(qu_dataset))\n    print(\"length of new dataframe after outlier removal:\", len(output_dataset))\n    \n    return output_dataset","1b935283":"print_quantile_info(df_train, \"target\")","c004f8e5":"df_train_new = remove_outliers_using_quantiles(df_train, \"target\", \"outer\")","82453686":"plt.figure(figsize=(15,10))\nsns.violinplot(y=\"target\", data=df_train_new, palette=\"muted\")\nplt.title('Violin Plot for Customer Loyalty After Removing Outer Data')","006e52c9":"plt.figure(figsize=(15,10))\nsns.distplot(df_train_new[\"target\"]);\nplt.title('Histogram for Customer Loyalty After Removing Outer Data')","7f62a52c":"sns.catplot(x=\"feature_1\", kind=\"count\", palette=\"ch:.25\", data=df_train);\nsns.catplot(x=\"feature_1\", kind=\"count\", palette=\"ch:.25\", data=df_test);","1f7a45ee":"sns.catplot(x=\"feature_2\", kind=\"count\", palette=\"ch:.25\", data=df_train);\nsns.catplot(x=\"feature_2\", kind=\"count\", palette=\"ch:.25\", data=df_test);","ff7aaf4a":"sns.catplot(x=\"feature_3\", kind=\"count\", palette=\"ch:.25\", data=df_train);\nsns.catplot(x=\"feature_3\", kind=\"count\", palette=\"ch:.25\", data=df_test);","bac77855":"sns.catplot(x=\"feature_1\", y=\"target\", kind=\"bar\", palette=\"ch:.25\", data=df_train);","14fa1854":"sns.catplot(x=\"feature_2\", y=\"target\", kind=\"bar\", palette=\"ch:.25\", data=df_train);","005414ff":"sns.catplot(x=\"feature_3\", y=\"target\", kind=\"bar\", palette=\"ch:.25\", data=df_train);","81d618e9":"df_feature_groups = df_train.groupby(['feature_1','feature_2','feature_3']).mean()\ndf_feature_groups = df_feature_groups.reset_index()\ndf_feature_groups.sort_values(\"target\")","f3004e61":"df_feature_groups[\"features\"] = df_feature_groups[\"feature_1\"].astype('str') + \"+\" + df_feature_groups[\"feature_2\"].astype('str') + \"+\" + df_feature_groups[\"feature_3\"].astype('str')","70ea7703":"df_feature_groups","4efcd8ea":"plt.figure(figsize=(15,10))\nsns.barplot(x=\"features\", y=\"target\", palette=\"ch:.25\", data=df_feature_groups)\nplt.xticks(rotation= 90)","a45ad713":"Note: There is a  sharp decrease and very low counts for 2018 data.","ce736438":"There are some insights for the card data (train.csv and test.csv). The details are in the notebook but mainly the followings are found:\n\n* There is a sharp decrease in the number of cards which start activity at 2018 (Figure: First Active Months Count).\n\n* The customer loyalty is much lower at 2012-04 when you compare it with other months (Figure: Monthly Customer Loyalty).\n\n* Customer loyalty increased continuosly after 2017-01. There is an obvious trend (Figure: Monthly Customer Loyalty).\n\n* Train and Test sets are divided very well according to the features distribution.\n\n* There is a correlation between features and customer loyalty. It is obvious in the last figure. ","c0b6d62a":"Note: It is obvious that customer loyalty values distribution is accumulated around the mean + median but there are some values look like potential outliers or at least should be taken into consideration for prediction.","322ebff2":"## Exploration and Visualization for Card Data","8c476b84":"Now lets validate it with further analysis by removing some extreme data.","1caf23b9":"Note:\n\nThere are two points to pay attention:\n\n1- What happened to customer loyalty at 2012-04? It is extremely low. It should be investigated.\n\n2- After 2017-01, there is a continous upper trend in customer loyalty.","875eb45c":"### Abstract"}}