{"cell_type":{"f03a8727":"code","f1d37029":"code","63469569":"code","f87f4585":"code","5230c01d":"code","a42006d8":"code","f869c570":"code","5fcf51fa":"code","646aa454":"code","2a0c5048":"code","da944dd6":"code","96a62f0c":"code","bf65f28c":"code","22506fe0":"code","7fea0d25":"code","360bb6ad":"code","a824ada7":"code","cf2ced04":"code","2b0a5b74":"code","d7c8443c":"code","52af332e":"code","a5c5f150":"code","7f768bdd":"code","5ea8abc9":"markdown","d0db3a7e":"markdown","26d0ba21":"markdown","02dd66eb":"markdown","3ebdc0ca":"markdown","d900dcc0":"markdown","8f5f2a8d":"markdown","52d67fd6":"markdown","d158cef8":"markdown","d0b1a96e":"markdown","4f65b90d":"markdown","96a8495b":"markdown"},"source":{"f03a8727":"# Imports\nimport numpy as np\nimport pandas as pd\nfrom keras import layers\nfrom keras_preprocessing.text import Tokenizer\nfrom keras_preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras import Sequential\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\n","f1d37029":"# Set random state for repeatable data\nnp.random.RandomState(21)\n\n# Set number of training samples, epochs and num words for tokenizer\ntraining_samples = 18000\nepochs = 5\nnumWords = 10000","63469569":"# Loading data to csv\ndf = pd.read_csv(r'..\/input\/trip-advisor-hotel-reviews\/tripadvisor_hotel_reviews.csv')\n# Lowercase columns\ndf.columns = df.columns.str.lower()","f87f4585":"print(df.head(5))","5230c01d":"print(len(df))","a42006d8":"print(f'Ratings: {sorted(df.rating.unique())}')","f869c570":"print(df.rating.value_counts())","5fcf51fa":"# Replace 1-5 rating to 0-2 sentiment where 0 is bad, 1 is neutral and 2 is good\ndef parseToSentiment(x):\n    if x == 5 or x == 4:\n        x = 2\n        return x\n    elif x == 3:\n        x = 1\n        return x\n    else:\n        x = 0\n        return x\n\n\ntoSentimentMap = map(parseToSentiment, df.rating)\n\n# Replace rating column\ndf.rating = list(toSentimentMap)","646aa454":"# Set columns for data and labels\ndata = df.review\nlabels = df.rating","2a0c5048":"print(f'Ratings: {sorted(df.rating.unique())}')","da944dd6":"# Use tokenizer on text date for vectorizing it to numbers\ntokenizer = Tokenizer(num_words=numWords)\ntokenizer.fit_on_texts(data)\nsequences = tokenizer.texts_to_sequences(data)\nword_index = tokenizer.word_index\ndata = pad_sequences(sequences)","96a62f0c":"print(data)","bf65f28c":"# Convert rating column to array and then with to_categorical convert it to binary class matrix\nlabels = np.asarray(labels)\nlabelsCategories = len(np.unique(labels))\nlabels = to_categorical(labels, labelsCategories)","22506fe0":"# Shuffle data\nindices = np.arange(len(data))\nnp.random.shuffle(indices)","7fea0d25":"# Apply shuffle on the data\ndata = data[indices]\nlabels = labels[indices]","360bb6ad":"# Split data to train and test\nX_train = data[:training_samples]\ny_train = labels[:training_samples]\nX_test = data[training_samples:]\ny_test = labels[training_samples:]","a824ada7":"# Embedding layer expects vocabulary size + 1 as input dimension\ninputDim = numWords + 1\n# For input length we need to use shape of one row of our data\ninputLength = len(X_train[0])","cf2ced04":"# Use Sequential model with one Embedding and two Convolutional layers and after them use 2 max pooling operations\n# ended with one Dense layer with softmax activation for multiclass classification\nmodel = Sequential()\nmodel.add(layers.Embedding(inputDim, 128, input_length=inputLength))\nmodel.add(layers.Conv1D(64, 7, activation='relu'))\nmodel.add(layers.MaxPool1D(5))\nmodel.add(layers.Conv1D(64, 7, activation='relu'))\nmodel.add(layers.GlobalMaxPooling1D())\nmodel.add(layers.Dense(3, activation=\"softmax\"))","2b0a5b74":"# For loss in multiclass classification problem we need to use categorical_crossentropy, as optimizer set rmsprop\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n","d7c8443c":"# Training model\nhistory = model.fit(X_train,\n                    y_train,\n                    epochs=epochs,\n                    batch_size=128,\n                    validation_split=0.2)","52af332e":"# Evalute model for accuracy and loss information\nprint(f'Model loss(1) and accuracy(2): {model.evaluate(X_test, y_test)}')","a5c5f150":"# Save metrics to variables and plot them\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","7f768bdd":"# Plotting with Plotly\n\nepochs = range(1, epochs + 1)\n\nfig = make_subplots(rows=2, cols=1, subplot_titles=('Loss', 'Accuracy'))\n\nfig.add_trace(\n    go.Scatter(x=list(epochs), y=loss, mode='lines+markers', name='Training loss'),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=list(epochs), y=val_loss, mode='lines+markers', name='Validation loss'),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=list(epochs), y=acc, mode='lines+markers', name='Training accuracy'),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=list(epochs), y=val_acc, mode='lines+markers', name='Validation accuracy'),\n    row=2, col=1\n)\n","5ea8abc9":"# Model accuracy: \n# - with parsing to sentiment ~82-85%\n# - without ~60-63%","d0db3a7e":"*Rating counts*","26d0ba21":"***Ratings range after replacing with sentiment***","02dd66eb":"# **Tokenizing**","3ebdc0ca":"***Data after tokenizing***","d900dcc0":"***Ratings range***","8f5f2a8d":"# **Evaluation and plotting**","52d67fd6":"# **Simple sentiment analisys model**","d158cef8":"# **Data info**","d0b1a96e":"***Total examples***","4f65b90d":"# **Model training**","96a8495b":"***First 5 rows***"}}