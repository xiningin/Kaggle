{"cell_type":{"c80cfdc1":"code","dcfba5cb":"code","5b414710":"code","3e3afa37":"code","b4b207f9":"code","7924921d":"code","bf0dd2f3":"code","0d9a2554":"code","27466b14":"code","e0acf0ec":"code","12cce9eb":"code","ae218a0d":"code","66c4c11a":"code","b6a0f7f3":"code","ac675e45":"code","9b976e6b":"code","1d13d1cb":"code","cb419e98":"code","af263129":"markdown","3696a539":"markdown","6f44db17":"markdown","8344fd30":"markdown","62f5d088":"markdown","d1890950":"markdown","16320873":"markdown","d02461ce":"markdown","35a50f05":"markdown","b5354f4a":"markdown","1290d330":"markdown","b939a407":"markdown","08e9a325":"markdown","4549145a":"markdown","68502004":"markdown","358d0f97":"markdown","f4755cff":"markdown","4157e410":"markdown","dd1e2ac4":"markdown","cee4bddf":"markdown","63802677":"markdown"},"source":{"c80cfdc1":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nimport numpy as np","dcfba5cb":"df = pd.DataFrame(columns=[\"path\",\"label\"])\n\npath = \"..\/input\/animal-image-datasetdog-cat-and-panda\/animals\/\"\n\nfor i in os.listdir(path + \"dogs\"):\n    df = df.append({\"path\":path+\"dogs\/\"+i,\"label\":\"dog\"},ignore_index=True)\n\nfor i in os.listdir(path + \"panda\"):\n    df = df.append({\"path\":path+\"panda\/\"+i,\"label\":\"panda\"},ignore_index=True)\n    \ndf.head(5)","5b414710":"plt.imread(df[df['label'] == 'dog'].iloc[0,0]).shape","3e3afa37":"img = plt.imread(df[df['label'] == 'dog'].iloc[0,0])\nimg_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,10),subplot_kw=dict(xticks=[],yticks=[]))\nax1.imshow(img)\nax1.set_title(\"RGB Image\")\nax2.imshow(img_gray,cmap=\"gray\")\n_=ax2.set_title(\"GRAY\")","b4b207f9":"img = plt.imread(df[df['label'] == 'panda'].iloc[2,0])\nimg_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,10),subplot_kw=dict(xticks=[],yticks=[]))\nax1.imshow(img)\nax2.imshow(img_gray,cmap=\"gray\")\nax1.set_title(\"RGB Image\")\n_=ax2.set_title(\"GRAY\")","7924921d":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","bf0dd2f3":"generator = ImageDataGenerator(validation_split=0.2)\ntrain = generator.flow_from_dataframe(df,x_col='path',y_col='label',color_mode=\"grayscale\",target_size=(128,128))","0d9a2554":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Bidirectional,LSTM,Lambda, GRU\nfrom tensorflow.keras.layers import Permute,GlobalMaxPool1D,Concatenate, Dense, BatchNormalization, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","27466b14":"input_ = Input(shape=(128,128,1))\nlambda_ = Lambda(lambda x: tf.squeeze(x,axis=3))(input_)\n\nlstm_ = Bidirectional(GRU(8,activation='relu',return_sequences=True))(lambda_)\n\npermute_=Permute((2,1),input_shape=(128,128))(lambda_)\nlstm_2 = Bidirectional(GRU(8,activation='relu',return_sequences=True))(permute_)\n\n\nlstm_ = BatchNormalization()(lstm_)\nmaxpool1 = GlobalMaxPool1D()(lstm_)\n\n\nlstm_2 = BatchNormalization()(lstm_2)\nmaxpool2 = GlobalMaxPool1D()(lstm_2)\n\n\nconcat_ = Concatenate(axis=1)([maxpool1,maxpool2])\ndense_1 = Dense(20,activation='relu')(concat_)\noutput_ = Dense(2,activation='softmax')(dense_1)\n\nmodel = Model(input_,output_)","e0acf0ec":"model.summary()","12cce9eb":"plot_model(model)","ae218a0d":"early = EarlyStopping(patience=4)\nreduce_lr = ReduceLROnPlateau(factor=0.1,patience=1)\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","66c4c11a":"history = model.fit(x=train,epochs=80,callbacks=[early,reduce_lr])","b6a0f7f3":"plt.figure(figsize=(15,6))\nplt.plot(history.history['loss'])\n_=plt.title(\"Losses plot\")","ac675e45":"print(\"Accuracy is: \",format(history.history['accuracy'][-1],\".2f\"))","9b976e6b":"index_class = {v:s for s,v in train.class_indices.items()}\ndef predict(path):\n    a = plt.imread(path)\n    a = cv2.resize(a, (128,128),interpolation = cv2.INTER_NEAREST)\n    a = cv2.cvtColor(a,cv2.COLOR_BGR2GRAY)\n    a = tf.expand_dims(a,axis=-1)\n    a = tf.expand_dims(a,axis=0)\n    a = np.argmax(model.predict(a))\n    return index_class[a]","1d13d1cb":"!curl -s https:\/\/yt3.ggpht.com\/ytc\/AAUvwnhbv9F6Du9P6GVUYfap8qBfe2_nUGqH6xm3HE9C3Q=s900-c-k-c0x00ffffff-no-rj --output tucker_budzyn.jpg\npath = \"tucker_budzyn.jpg\"\nplt.imshow(plt.imread(path))\nax = plt.gca()\nax.axes.xaxis.set_visible(False)\nax.axes.yaxis.set_visible(False)\nprint(f\"It's a {predict(path)}!\")","cb419e98":"!curl -s https:\/\/ichef.bbci.co.uk\/news\/549\/mcs\/media\/images\/77396000\/jpg\/_77396213_kung-fu-panda-21.jpg --output kunfu_panda.jpg\npath = \"kunfu_panda.jpg\"\nplt.imshow(plt.imread(path))\nax = plt.gca()\nax.axes.xaxis.set_visible(False)\nax.axes.yaxis.set_visible(False)\nprint(f\"It's a {predict(path)}!\")","af263129":"**Can our model predict the Dragon Warrior?**","3696a539":"# Animal Image Classification using Bidirectional GRU","6f44db17":"**Can our model predict Tucker Budzyn?**","8344fd30":"### Creating the model","62f5d088":"**Model fitting**","d1890950":"**Visualizing the model architecture**","16320873":"## Creating Image Data Generator\n**Let's create an Image Data Generator to feed our images to the model**","d02461ce":"**Defining predict function**","35a50f05":"**Creating DataFrame**","b5354f4a":"**Let's print the shape of an image from df**","1290d330":"**The idea is to scan the image completely in all four directions:**\n\n**Along height - forward and backward (as in Fig.1.)** <br>\n**Along width - forward and backward (as in Fig.2.)**\n\nWe'll feed a single channel image to two bidirectional GRU layers. The first BiGRU layer will take the image and scan it along height dimension. The second BiGRU will take a 90\u00b0 rotated version of the same image and scan it along width dimension.\n\nThe shape of the image is 2D, and is similar to the shape of the output from an embedding layer. Hence it can be fed to GRUs or LSTMs.","b939a407":"**Objective: To create a model that can identify dogs and pandas from images using bidirectional GRUs.**\n\n### Intution behind the idea:","08e9a325":"**Images of pandas**","4549145a":"**Model summary**","68502004":"**Defining Callbacks**","358d0f97":"**Note that it is an RGB image. We have to convert the RGB channels to a single channel before feeding to LSTMs**","f4755cff":"## Importing Libraries","4157e410":"**Images of dogs**","dd1e2ac4":"## Model Prediction","cee4bddf":"![elephant2.png](attachment:5fb50716-2aa0-451c-b5af-94a4f09c590e.png)","63802677":"# Thank you"}}