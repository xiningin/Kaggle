{"cell_type":{"55df2eea":"code","da73b9c7":"code","ef643190":"code","d316b7af":"code","38ae36dd":"code","d06a2569":"code","27fc139d":"code","7153c418":"code","d95df492":"code","9c14e8be":"code","76a7c1ea":"code","bfe53b2b":"code","80a4e729":"code","78c561e6":"code","de6cbfc2":"code","f56953bd":"code","0c698805":"code","e3235397":"code","2f4f7aad":"code","a0e47161":"code","2fd9a3f8":"code","e047a36b":"code","9ed8081a":"code","9db042a8":"code","2b63b181":"code","181921b0":"code","87d684c2":"code","6a144124":"code","3ea6d342":"code","606cd034":"code","968b4c57":"code","632fff47":"code","59bac2ee":"code","9f184e2d":"code","fc270989":"code","1a30c422":"code","3678610c":"code","eb5d8eb9":"code","8c88cf82":"code","977b1a19":"code","a3b97b12":"code","a105dffd":"code","2f18e1f9":"code","c0c18ede":"code","b7f0f820":"code","9dd5bae0":"code","7471a3d5":"code","337de321":"code","0b8b4beb":"code","515c8065":"code","e50d24f9":"code","ee9491aa":"code","dbf74323":"code","1eb4c8bb":"code","fa8cbbc8":"code","bf63c162":"code","ed1bc144":"code","ef20a81b":"code","e2447210":"code","7f70e745":"code","b3b28a3f":"code","febc77bb":"code","04e15115":"code","fb44f125":"code","00aae5c6":"code","47c2c7e4":"code","b8698d03":"code","cbd27478":"code","185f50ce":"code","099d002e":"code","8e5f85de":"code","ae5a4798":"markdown","a0dc04c2":"markdown","84dee09b":"markdown","fc77d3bd":"markdown","79f68f1c":"markdown","b1e0e4c7":"markdown","f70e31ef":"markdown","a995d859":"markdown","254bcaba":"markdown"},"source":{"55df2eea":"load_model = False              # False    #True\nKAGGLE = True                  #True   #False\n\n\nprint(\"load_model = \", load_model)\nprint(\"KAGGLE = \", KAGGLE)","da73b9c7":"if KAGGLE:\n    # This Python 3 environment comes with many helpful analytics libraries installed\n    # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n    # For example, here's several helpful packages to load\n\n    import numpy as np # linear algebra\n    import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n    # Input data files are available in the read-only \"..\/input\/\" directory\n    # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n    import os\n    \n    \n    \n#     > ls \/kaggle\n#     input\/  lib\/  working\/\n#     > pwd\n#     '\/kaggle\/working'\n#     > ls ..\/working\n#     __notebook_source__.ipynb\n\n\n\n#     ..\/input\/petfinder-pawpularity-score\/sample_submission.csv\n#     ..\/input\/mypetmodels\/mymodel_epoch8.pth\n#     ..\/input\/pythonbox\/Box-master\/.github\n#     ..\/input\/timmpackage\/pytorch-image-models-master\/\n#     ..\/working\n\n\n\n#     for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for dirname, _, filenames in os.walk('\/kaggle\/working'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n    # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n    # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","ef643190":"if KAGGLE: \n    root_dir = '\/kaggle\/input\/petfinder-pawpularity-score\/'\n#     model_dir = '\/kaggle\/input\/trainedModels\/'\n    model_dir = '..\/input\/mypetmodels'\nelse:\n    root_dir = '..\/ori_data\/petData\/'\n    model_dir = '.'\n\n        \n        \nprint(\"root_dir = \", root_dir)\nprint(\"model_dir = \", model_dir)","d316b7af":"# !pip install opencv-python\n# !pip install python-box timm pytorch-lightning==1.4.0 grad-cam ttach","38ae36dd":"# based on the post here: https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/275094\n\nimport sys\n\n\nif KAGGLE:\n#     sys.path.append(\"..\/input\/Box-master\/\")\n#     sys.path.append(\"..\/input\/pytorch-image-models-master\/\")\n    sys.path.append(\"..\/input\/pythonbox\/Box-master\/\")\n    sys.path.append(\"..\/input\/timmpackage\/pytorch-image-models-master\/\")\nelse:\n    packge_dir = '\/home1\/yhl\/jupyter\/petfinder\/packages_dir\/'\n    sys.path.append(packge_dir + \"Box-master\/\")\n    sys.path.append(packge_dir + \"pytorch-image-models-master\/\")","d06a2569":"import os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\nimport gc\n\nimport torch\nimport torchvision.transforms as T\nfrom torchvision.io import read_image\n\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import DataLoader, Dataset\n# from pytorch_grad_cam import GradCAMPlusPlus\n# from pytorch_grad_cam.utils.image import show_cam_on_image\n\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\nfrom pathlib import Path\nimport time\n\n\nwarnings.filterwarnings(\"ignore\")","27fc139d":"batch_size_train_val = 32   #32    #31\n#32\n#96   #64\n\nprint(\"batch_size_train_val = \", batch_size_train_val)","7153c418":"config = {'seed': 2021,\n#           'root': '\/kaggle\/input\/petfinder-pawpularity-score\/', \n          'root': root_dir, \n          'model_dir': model_dir,\n          'n_splits': 5,\n          'epoch': 20,\n          'trainer': {\n              'gpus': 1,\n              'accumulate_grad_batches': 1,\n              'progress_bar_refresh_rate': 1,\n              'fast_dev_run': False,\n              'num_sanity_val_steps': 0,\n              'resume_from_checkpoint': None,\n          },\n          'transform':{\n              'name': 'get_default_transforms',\n              'image_size': 224\n          },\n          'train_loader':{\n              'batch_size': batch_size_train_val,     #64,\n              'shuffle': True,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': True,\n          },\n          'val_loader': {\n              'batch_size': batch_size_train_val,     #64,\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'model':{\n#               'name': Path(model_dir) \/ 'swin_tiny_patch4_window7_224',\n              'name': 'swin_large_patch4_window7_224',     \n              #'resnet34', #'swin_large_patch4_window7_224', #'swin_tiny_patch4_window7_224',\n              'output_dim': 1\n          },\n          'optimizer':{\n              'name': 'optim.AdamW',\n              'params':{\n                  'lr': 1e-5\n              },\n          },\n          'scheduler':{\n              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n              'params':{\n                  'T_0': 20,\n                  'eta_min': 1e-4,\n              }\n          },\n          'loss': 'nn.BCEWithLogitsLoss',\n}\n\nconfig = Box(config)","d95df492":"print(config)","9c14e8be":"# print(config.optimizer.params.lr)\n# # 1e-05\n\n# print(config.seed)\n# # 2021","76a7c1ea":"# print(config.seed)\n# # 2021\n\ntorch.autograd.set_detect_anomaly(True)\nseed_everything(config.seed)","bfe53b2b":"train_df = pd.read_csv(os.path.join(config.root, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(config.root, \"test.csv\"))","80a4e729":"print(train_df.shape)\nprint(train_df.columns.values)\nprint(train_df.head(2))\n\nprint(\"\\n\")\nprint(test_df.shape)\nprint(test_df.columns.values)\nprint(test_df.head(2))","78c561e6":"train_df[\"imgPath\"] = train_df[\"Id\"].apply(lambda x: os.path.join(config.root, \"train\", x + \".jpg\"))\ntest_df[\"imgPath\"] = test_df[\"Id\"].apply(lambda x: os.path.join(config.root, \"test\", x + \".jpg\"))","de6cbfc2":"print(train_df.shape)\nprint(train_df.columns.values)\nprint(train_df.head(2))\n\nprint(\"\\n\")\nprint(test_df.shape)\nprint(test_df.columns.values)\nprint(test_df.head(2))","f56953bd":"rowsNum = train_df.shape[0]\nassert(rowsNum == 9912)\nprint(\"rowsNum = \", rowsNum)\n\n\nvalid_pct=0.2\nseed=999\nprint(\"valid_pct = \", valid_pct)\nprint(\"seed = \", seed)\nnp.random.seed(seed)\na = (np.random.rand(rowsNum) < valid_pct).astype(bool)\n\n\n# print(a.shape[0])\nassert(a.shape[0] == rowsNum)\nvalRowNum = np.sum(a)\nrealValPerc = np.sum(a)\/rowsNum\nprint(\"valRowNum = \", valRowNum)\nprint(\"realValPerc = \", realValPerc)\n\n\ntrain_df['valid_col'] = a\nfirst20_validCol = train_df['valid_col'].values[:20].astype('int') \ntarget20 = np.array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])\nprint( first20_validCol )\nassert( (first20_validCol == target20).all() )","0c698805":"print(train_df.shape)\nprint(train_df.columns.values)\nprint(train_df.head(2))\n\nprint(\"\\n\")\nprint(test_df.shape)\nprint(test_df.columns.values)\nprint(test_df.head(2))","e3235397":"train_df_train = train_df[train_df['valid_col'] == False]\ntrain_df_val = train_df[train_df['valid_col'] == True]\n\nprint('train_df.shape = ', train_df.shape)\nprint(\"train_df_train.shape = \", train_df_train.shape)\nprint(\"train_df_val.shape = \", train_df_val.shape)\nprint('test_df.shape = ', test_df.shape)\nassert(train_df.shape[0] == train_df_train.shape[0] + train_df_val.shape[0]) \nassert(train_df_val.shape[0] == valRowNum) ","2f4f7aad":"# # print(config.seed)\n# # # 2021\n\n# torch.autograd.set_detect_anomaly(True)\n# seed_everything(config.seed)","a0e47161":"# seed_everything??\n\n# # random.seed(seed)\n# # np.random.seed(seed)\n# # torch.manual_seed(seed)\n# # torch.cuda.manual_seed_all(seed)","2fd9a3f8":"# class PetfinderDataModule(LightningDataModule):\n#     def __init__(\n#         self,\n#         train_df,\n#         val_df,\n#         cfg,\n#     ):\n#         super().__init__()\n#         self._train_df = train_df\n#         self._val_df = val_df\n#         self._cfg = cfg\n\n#     def __create_dataset(self, train=True):\n#         return (\n#             PetfinderDataset(self._train_df, self._cfg.transform.image_size)\n#             if train\n#             else PetfinderDataset(self._val_df, self._cfg.transform.image_size)\n#         )\n\n#     def train_dataloader(self):\n#         dataset = self.__create_dataset(True)\n#         return DataLoader(dataset, **self._cfg.train_loader)\n\n#     def val_dataloader(self):\n#         dataset = self.__create_dataset(False)\n#         return DataLoader(dataset, **self._cfg.val_loader)","e047a36b":"class PetfinderDataset(Dataset):\n    def __init__(self, df, image_size=224):\n#         self._X = df[\"Id\"].values\n        self._X = df[\"imgPath\"].values\n    \n        self._y = None\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n            \n        self._transform = T.Resize([image_size, image_size])\n        \n        dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n        ]\n        self._dense_features = df[dense_features].values\n\n        \n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        image = read_image(image_path)\n        image = self._transform(image)\n        \n        features = self._dense_features[idx, :]\n        \n        if self._y is not None:\n            label = self._y[idx]\n            return image, label\n        else:\n            return image","9ed8081a":"class PetfinderDataModule(LightningDataModule):\n    def __init__(\n        self,\n        df,\n        is_valid,\n        cfg,\n    ):\n        super().__init__()\n        self._df = df\n        self._is_valid = is_valid\n        self._cfg = cfg\n\n    def __create_dataset(self):\n        return PetfinderDataset(self._df, self._cfg.transform.image_size)\n\n    def get_dataloader(self):\n        dataset = self.__create_dataset()\n        if self._is_valid==False:\n            return DataLoader(dataset, **self._cfg.train_loader)\n        else:\n            return DataLoader(dataset, **self._cfg.val_loader)        ","9db042a8":"print(config.train_loader)\nprint(config.val_loader)","2b63b181":"# 'train_loader': {'batch_size': 64,\n#                   'drop_last': True,\n#                   'num_workers': 4,\n#                   'pin_memory': False,\n#                   'shuffle': True},\n    \n# 'val_loader': {'batch_size': 64,\n#                 'drop_last': False,\n#                 'num_workers': 4,\n#                 'pin_memory': False,\n#                 'shuffle': False}}","181921b0":"# sample_dataloader = PetfinderDataModule(df, df, config).val_dataloader()\nis_valid = True\ntest_dataloader = PetfinderDataModule(test_df, is_valid, config).get_dataloader()\ntest_dataloader_bNum = len(test_dataloader)\nprint(\"test_dataloader_bNum = \", test_dataloader_bNum)\n\n\n\n# sample_dataloader = PetfinderDataModule(df, df, config).val_dataloader()\nis_valid = True\nval_dataloader = PetfinderDataModule(train_df_val, is_valid, config).get_dataloader()\nval_dataloader_bNum = len(val_dataloader)\nprint(\"val_dataloader_bNum = \", val_dataloader_bNum)\n\n\n# sample_dataloader = PetfinderDataModule(df, df, config).val_dataloader()\nis_valid = False\ntrain_dataloader = PetfinderDataModule(train_df_train, is_valid, config).get_dataloader()\ntrain_dataloader_bNum = len(train_dataloader)\nprint(\"train_dataloader_bNum = \", train_dataloader_bNum)\n\n\n# test_dataloader_bNum =  1\n# val_dataloader_bNum =  64\n# train_dataloader_bNum =  246","87d684c2":"# train_df.shape =  (9912, 16)\n# train_df_train.shape =  (7886, 16)\n# train_df_val.shape =  (2026, 16)\n# test_df.shape =  (8, 14)\n\nprint('train_df.shape = ', train_df.shape)\nprint(\"train_df_train.shape = \", train_df_train.shape)\nprint(\"train_df_val.shape = \", train_df_val.shape)\nprint('test_df.shape = ', test_df.shape)\n\nprint(\"\\n\")\nprint(\"train_dataloader_bNum = \", train_dataloader_bNum)\nprint(\"val_dataloader_bNum = \", val_dataloader_bNum)\nprint(\"test_dataloader_bNum = \", test_dataloader_bNum)\n\n\nprint(\"\\n\")\nprint(\"batch_size_train_val = \", batch_size_train_val)\n# assert(config.train_loader.batch_size == 64)\n# assert(config.val_loader.batch_size == 64)\nassert(config.train_loader.batch_size == batch_size_train_val)\nassert(config.val_loader.batch_size == batch_size_train_val)\nprint(\"train_dataloader_bNum*batch_size_train_val = \", train_dataloader_bNum*batch_size_train_val)\nprint(\"val_dataloader_bNum*batch_size_train_val = \", val_dataloader_bNum*batch_size_train_val)\nprint(\"(train_dataloader_bNum*batch_size_train_val-7886) = \", (train_dataloader_bNum*batch_size_train_val-7886) )\nprint(\"(val_dataloader_bNum*batch_size_train_val-2026) = \", (val_dataloader_bNum*batch_size_train_val-2026) )\ntrain_val_totalsum = (train_dataloader_bNum*batch_size_train_val + val_dataloader_bNum*batch_size_train_val)\nprint(\"(train_val_totalsum-9912) = \", (train_val_totalsum-9912) )\nprint(\"train_val_totalsum = \", train_val_totalsum)\n\n\n# print(\"\\n\")\n# # print(\"test_dataloader_bNum*batch_size_train_val = \", test_dataloader_bNum*batch_size_train_val)\n# print(\"type(test_oneBatch) = \", type(test_oneBatch))\n# print(\"test_oneBatch.shape = \", test_oneBatch.shape)\n\n\n\n# train_df.shape =  (9912, 16)\n# train_df_train.shape =  (7886, 16)\n# train_df_val.shape =  (2026, 16)\n# test_df.shape =  (8, 14)\n\n\n# train_dataloader_bNum =  246\n# val_dataloader_bNum =  64\n# test_dataloader_bNum =  1\n\n\n# batch_size_train_val =  32\n# train_dataloader_bNum*batch_size_train_val =  7872\n# val_dataloader_bNum*batch_size_train_val =  2048\n# (train_dataloader_bNum*batch_size_train_val-7886) =  -14\n# (val_dataloader_bNum*batch_size_train_val-2026) =  22\n# (train_val_totalsum-9912) =  8\n# train_val_totalsum =  9920","6a144124":"# oneBatch = iter(test_dataloader).next()\noneBatch = next(iter(test_dataloader))\n\n\nisTest = True\nprint(\"isTest = \", isTest)\nprint(\"type(oneBatch) = \", type(oneBatch))\n\n\nif isTest==False:\n#     print(type(oneBatch))\n    assert(type(oneBatch) == list)\n#     assert(type(oneBatch) == tuple)\n    oneBatchLen = len(oneBatch)\n    assert(oneBatchLen == 2)\n    print(\"len(oneBatch) = \", len(oneBatch))\n    images, labels = oneBatch\nelse:\n    assert(type(oneBatch) == torch.Tensor)\n    print(\"oneBatch.shape = \", oneBatch.shape)\n    images = oneBatch\n\n\nplt.figure(figsize=(12, 12))\n# for it, (image, label) in enumerate(zip(images[:16], labels[:16])):\nfor it, (image) in enumerate(images[:16]):\n    plt.subplot(4, 4, it+1)\n    plt.imshow(image.permute(1, 2, 0))\n    plt.axis('off')\n#     plt.title(f'Pawpularity: {int(label)}')","3ea6d342":"# oneBatch = iter(val_dataloader).next()\noneBatch = next( iter(val_dataloader) )\n\n\nisTest = False\nprint(\"isTest = \", isTest)\nprint(\"type(oneBatch) = \", type(oneBatch))\n\n\nif isTest==False:\n#     print(type(oneBatch))\n    assert(type(oneBatch) == list)\n#     assert(type(oneBatch) == tuple)\n    oneBatchLen = len(oneBatch)\n    assert(oneBatchLen == 2)\n    images, labels = oneBatch\nelse:\n    assert(type(oneBatch) == torch.Tensor)\n    images = oneBatch\n\n\nplt.figure(figsize=(12, 12))\nif isTest:\n    for it, (image) in enumerate(images[:16]):\n        plt.subplot(4, 4, it+1)\n        plt.imshow(image.permute(1, 2, 0))\n        plt.axis('off')\nelse:\n    for it, (image, label) in enumerate(zip(images[:16], labels[:16])):\n    # for it, (image) in enumerate(images[:16]):\n        plt.subplot(4, 4, it+1)\n        plt.imshow(image.permute(1, 2, 0))\n        plt.axis('off')\n        plt.title(f'Pawpularity: {int(label)}')","606cd034":"# https:\/\/stackoverflow.com\/questions\/21622193\/python-3-2-coroutine-attributeerror-generator-object-has-no-attribute-next\n# oneBatch = iter(train_dataloader).next()\noneBatch = next( iter(train_dataloader) )\n\n\nisTest = False\nprint(\"isTest = \", isTest)\nif isTest==False:\n#     print(type(oneBatch))\n    assert(type(oneBatch) == list)\n#     assert(type(oneBatch) == tuple)\n    oneBatchLen = len(oneBatch)\n    assert(oneBatchLen == 2)\n    images, labels = oneBatch\nelse:\n    assert(type(oneBatch) == torch.Tensor)\n    images = oneBatch\n\n\nplt.figure(figsize=(12, 12))\nif isTest:\n    for it, (image) in enumerate(images[:16]):\n        plt.subplot(4, 4, it+1)\n        plt.imshow(image.permute(1, 2, 0))\n        plt.axis('off')\nelse:\n    for it, (image, label) in enumerate(zip(images[:16], labels[:16])):\n    # for it, (image) in enumerate(images[:16]):\n        plt.subplot(4, 4, it+1)\n        plt.imshow(image.permute(1, 2, 0))\n        plt.axis('off')\n        plt.title(f'Pawpularity: {int(label)}')","968b4c57":"# IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n# IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\n# def get_default_transforms():\n#     transform = {\n#         \"train\": T.Compose(\n#             [\n#                 T.RandomHorizontalFlip(),\n#                 T.RandomVerticalFlip(),\n#                 T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n#                 T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n#                 T.ConvertImageDtype(torch.float),\n#                 T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n#             ]\n#         ),\n#         \"val\": T.Compose(\n#             [\n#                 T.ConvertImageDtype(torch.float),\n#                 T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n#             ]\n#         ),\n#     }\n#     return transform","632fff47":"# IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n# IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\n# def get_default_transforms():\n#     transform = {\n#         \"train\": T.Compose(\n#             [\n# #                 T.RandomHorizontalFlip(),\n# #                 T.RandomVerticalFlip(),\n# #                 T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n# #                 T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n#                 T.ConvertImageDtype(torch.float),\n# #                 T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n#             ]\n#         ),\n#         \"val\": T.Compose(\n#             [\n#                 T.ConvertImageDtype(torch.float),\n# #                 T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n#             ]\n#         ),\n#     }\n#     return transform","59bac2ee":"# IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n# IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\n# def get_default_transforms():\n#     transform = {\n#         \"train\": T.Compose(\n#             [\n# #                 T.RandomHorizontalFlip(),\n# #                 T.RandomVerticalFlip(),\n# #                 T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n# #                 T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n#                 T.ConvertImageDtype(torch.float),\n#                 T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n#             ]\n#         ),\n#         \"val\": T.Compose(\n#             [\n#                 T.ConvertImageDtype(torch.float),\n#                 T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n#             ]\n#         ),\n#     }\n#     return transform","9f184e2d":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\ndef get_default_transforms():\n    transform = {\n        \"train\": T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n#                 T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n        \"val\": T.Compose(\n            [\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n    }\n    return transform","fc270989":"print(\"config.model.output_dim = \", config.model.output_dim)","1a30c422":"class Model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n\n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n        )\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n        )\n\n    def forward(self, x):\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out","3678610c":"# class Model(pl.LightningModule):\n#     def __init__(self, cfg):\n#         super().__init__()\n#         self.cfg = cfg\n#         self.__build_model()\n# #         self._criterion = eval(self.cfg.loss)()\n# #         self.transform = get_default_transforms()\n# #         self.save_hyperparameters(cfg)\n\n#     def __build_model(self):\n#         self.backbone = create_model(\n#             self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n#         )\n#         num_features = self.backbone.num_features\n#         self.fc = nn.Sequential(\n#             nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n#         )\n\n#     def forward(self, x):\n#         f = self.backbone(x)\n#         out = self.fc(f)\n#         return out","eb5d8eb9":"def delete_folder(myDir):\n    import os\n    import sys\n    import shutil\n\n\n#     # myfile=\".\/swin_tiny_patch4_window7_224\/\"\n#     myDir = f'{config.model_dir}\/{config.model.name}'\n    print(\"myDir = \", myDir)\n\n    if os.path.isdir(myDir):\n    # #     os.remove(myDir)\n    #     os.rmdir(myDir)\n        shutil.rmtree(myDir) \n        print(\"%s folder is removed\" % myDir)\n    else:    ## Show an error ##\n        print(\"%s folder not found\" % myDir)\n        \n    \n    # importing os module\n    import os\n\n    try: \n        os.mkdir(myDir) \n        print(\"%s folder is created!\" % myDir)\n    except OSError as error: \n        print(error)  ","8c88cf82":"def cal_rmse(preds, labels):\n     return torch.sqrt(((labels - preds) ** 2).mean()).item()","977b1a19":"def train_val_share_step(batch, mode, loss_fn):\n    # mode: 'train', 'val'\n    images, labels = batch\n    labels = labels.float() \/ 100.0\n    images = get_default_transforms()[mode](images)\n\n#     if torch.rand(1)[0] < 0.5 and mode == 'train':\n#         mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n#         logits = self.forward(mix_images).squeeze(1)\n#         loss = self._criterion(logits, target_a) * lam + \\\n#             (1 - lam) * self._criterion(logits, target_b)\n#     else:\n#         logits = self.forward(images).squeeze(1)\n#         loss = self._criterion(logits, labels)\n\n    logits = model.forward(images).squeeze(1)\n    loss = loss_fn(logits, labels)\n#     loss = loss.item()\n\n    pred = logits.sigmoid().detach().cpu() * 100.\n    labels = labels.detach().cpu() * 100.\n    return loss, pred, labels","a3b97b12":"# def train_val_share_step(batch, mode):\n#     # mode: 'train', 'val'\n#     images, labels = batch\n#     labels = labels.float() \/ 100.0\n#     images = get_default_transforms()[mode](images)\n\n# #     if torch.rand(1)[0] < 0.5 and mode == 'train':\n# #         mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n# #         logits = self.forward(mix_images).squeeze(1)\n# #         loss = self._criterion(logits, target_a) * lam + \\\n# #             (1 - lam) * self._criterion(logits, target_b)\n# #     else:\n# #         logits = self.forward(images).squeeze(1)\n# #         loss = self._criterion(logits, labels)\n\n#     logits = model.forward(images).squeeze(1)\n#     loss = loss_fn(logits, labels)\n# #     loss = loss.item()\n\n#     pred = logits.sigmoid().detach().cpu() * 100.\n#     labels = labels.detach().cpu() * 100.\n#     return loss, pred, labels","a105dffd":"def get_min_minind(arr):\n    return np.min(arr), np.argmin(arr)","2f18e1f9":"def pred_for_test_dataloader(model, test_dataloader):\n    super_final_predictions = []\n\n    with torch.no_grad():  # *2\n        for org_images in test_dataloader:\n            test_batch_size = len(org_images)\n    # #         print(\"test_batch_size = \", test_batch_size)\n\n    #         images = model.transform['val'](org_images)\n            images = get_default_transforms()['val'](org_images)\n\n            images = images.to(model.device)\n            logits = model.forward(images).squeeze(1)\n            pred = logits.sigmoid().detach().cpu().numpy() * 100\n\n            super_final_predictions += list(pred)\n            \n    return super_final_predictions","c0c18ede":"def train_myModel(train_dataloader, val_dataloader, model, loss_fn, optimizer, num_epoches, earlyStopPatience, bestModelName):\n    train_loss_arr = []\n    val_loss_arr = []\n    val_rmse_arr = []\n    best_val_rmse = 2000\n    best_val_rmse_epoch = 0 \n\n    \n    # trainer.fit(model, train_dataloader, val_dataloader)\n    for epoch in range(num_epoches):\n        epoch_startTime = time.time()\n\n\n        # train:\n        model.train()  # *1\n        train_loss = []\n        for batch in tqdm(train_dataloader):\n            batch = [x.to(device) for x in batch]\n\n    #         x_train = x_train.to(device)\n    #         y_train = y_train.to(device)\n\n    #         y_hat = model(x_train)\n    #         loss = loss_fn(y_train, y_hat)\n    #         loss = loss.item()\n    #         # The item() method extracts the loss\u2019s value as a Python float. \n\n    \n#             loss, pred, label = train_val_share_step(batch, 'train')\n            loss, pred, label = train_val_share_step(batch, 'train', loss_fn)\n\n\n            train_loss.append( loss.item() )\n\n            loss.backward()        \t\t# *4\n            optimizer.step()        \t# *5\n            optimizer.zero_grad()        \t# *6\n        train_loss = torch.mean(torch.tensor(train_loss))\n        train_loss = train_loss.item()\n    #     print('train_loss: ', train_loss)\n\n\n        # validation:\n        model.eval()  # *3\n        with torch.no_grad():  # *2\n            val_loss = []\n            preds = []\n            labels = []\n            for batch in tqdm(val_dataloader):\n                batch = [x.to(device) for x in batch]\n    #         for x_val, y_val in tqdm(val_dataloader):\n    #             x_val = x_val.to(device)\n    #             y_val = y_val.to(device)\n\n    #             yhat = model(x_val)\n    #             val_loss_val = loss_fn(y_val, yhat).item()\n\n    \n#                 loss, pred, label = train_val_share_step(batch, 'val')\n                loss, pred, label = train_val_share_step(batch, 'val', loss_fn)\n\n\n                val_loss.append( loss.item() )\n                preds.append( pred )\n                labels.append( label )\n                \n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        val_rmse = cal_rmse(preds, labels)\n    #     print('val_loss: ', val_loss)\n    \n\n        val_loss = torch.mean(torch.tensor(val_loss))\n        val_loss = val_loss.item()\n\n\n\n\n        train_loss_arr.append(train_loss)\n        val_loss_arr.append(val_loss)\n        val_rmse_arr.append(val_rmse)\n\n        if val_rmse < best_val_rmse:\n            best_val_rmse = val_rmse\n            best_val_rmse_epoch = epoch\n            \n#             bestModelName = 'mymodel_epoch' + str(best_val_rmse_epoch) + '.pth'\n            torch.save(model, Path(myDir)\/bestModelName)\n    \n            print(f\"best model is saved.\")\n            print(\"bestModelName = \", bestModelName)\n            print(\"best_val_rmse_epoch = \", best_val_rmse_epoch)\n#             print(f\"best model {bestModelName} is saved.\")\n            \n\n\n        epoch_endTime = time.time()\n        delta = epoch_endTime - epoch_startTime\n        epochTimeInMin = delta\/60\n\n        print( f'epoch={epoch},  train_loss={train_loss},  val_loss={val_loss},  val_rmse={val_rmse}')\n        print( f'best_val_rmse_epoch={best_val_rmse_epoch},  best_val_rmse={best_val_rmse},  epochTimeInMin={epochTimeInMin}')\n\n        \n    print(\"\\n\")\n    print(\"all ecpoches finishes!\")    \n    res_df = pd.DataFrame()\n    res_df['epoch'] = range(num_epoches)\n    res_df['train_loss'] = train_loss_arr\n    res_df['val_loss'] = val_loss_arr\n    res_df['val_rmse'] = val_rmse_arr\n    \n    \n    minValRmse, minValRmseInd = get_min_minind(res_df['val_rmse'])\n    minValLoss, minValLossInd = get_min_minind(res_df['val_loss'])\n    bestValOneRow = (best_val_rmse_epoch, res_df['epoch'][minValRmseInd], minValRmse, \\\n                                          res_df['epoch'][minValLossInd], minValLoss) \n    print(bestValOneRow)\n    \n#     assert(minValRmseInd == best_val_rmse_epoch)\n#     assert(minValLossInd == minValLossInd)\n    if not (minValRmseInd == best_val_rmse_epoch) or not(minValLossInd == best_val_rmse_epoch):\n        print(\"Error: epochInd not equal!\")\n        print(\"best_val_rmse_epoch = \", best_val_rmse_epoch)\n        print(\"minValRmseInd = \", minValRmseInd)\n        print(\"minValLossInd = \", minValLossInd)\n        print(\"res_df = \", res_df)\n    \n    \n    return res_df, minValRmse, minValLoss, best_val_rmse_epoch","b7f0f820":"print(\"load_model = \", load_model)","9dd5bae0":"if KAGGLE:\n    # Making pretrained weights work without needing to find the default filename\n    if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n        \n#     ..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth\n    !cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'\n#     !cp '..\/input\/petnets\/swin_tiny_patch4_window7_224.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_tiny_patch4_window7_224.pth'","7471a3d5":"# Downloading: \"https:\/\/github.com\/SwinTransformer\/storage\/releases\/download\/v1.0.0\/swin_tiny_patch4_window7_224.pth\" to \/root\/.cache\/torch\/hub\/checkpoints\/swin_tiny_patch4_window7_224.pth","337de321":"# if load_model==False:\n#     if 'model' in locals():\n#         del model\n#     gc.collect()\n#     model  = None\n    \n\n#     model = Model(config)\n\n#     model = model.cuda()\n#     device = model.device\n#     print(\"device = \", device)","0b8b4beb":"if KAGGLE:\n    if load_model==False:\n        myDir = f'..\/working'\n    else:\n        myDir = f'{config.model_dir}'\nelse:\n    print(\"config.model_dir = \", config.model_dir)\n    print(\"config.model.name = \", config.model.name)\n    myDir = f'{config.model_dir}\/{config.model.name}'\n    \nprint(\"type(myDir) = \", type(myDir) ) \nprint(\"myDir = \", myDir)","515c8065":"print(\"load_model = \", load_model)\nprint(\"KAGGLE = \", KAGGLE)","e50d24f9":"if KAGGLE==False and load_model==False:\n    delete_folder(myDir)","ee9491aa":"# loss_fn = nn.MSELoss(reduction='mean')\n# optimizer = optim.SGD(model.parameters(), lr=1e-1)\n\nloss_fn = nn.BCEWithLogitsLoss()\n\nnum_epoches = 10\n#10   #15  #20\n\nearlyStopPatience = 3","dbf74323":"%%time\n\nimport gc\n\n\nif load_model==False:\n    model  = None\n    model = Model(config)\n    model = model.cuda()\n    device = model.device\n#     print(\"device = \", device)\n    \n    \n    # optimizer = torch.optim.Adam(pytorch_model.parameters(), lr=1e-5)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n\n    \n#      # bestModelName =  'mymodel_epoch8.pth'\n    bestModelName = 'mymodel_best.pth'\n    \n    train_res = train_myModel(train_dataloader, val_dataloader, model, loss_fn, optimizer, \\\n                                                   num_epoches, earlyStopPatience, bestModelName)\n    res_df, minValRmse, minValLoss, best_val_rmse_epoch = train_res   \n    \n    \n    print(\"\\n\")\n    print(\"pred for test dataset!\")    \n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    model  = None\n    \n    print(\"KAGGLE = \", KAGGLE)\n    print(\"myDir = \", myDir)\n    print(\"bestModelName = \", bestModelName)\n    model = torch.load( Path(myDir)\/bestModelName )\n    model = model.cuda().eval()\n    device = model.device\n    print(\"device = \", device)\n    \n    super_final_predictions = pred_for_test_dataloader(model, test_dataloader)\n\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n\nprint(\"\\n\")","1eb4c8bb":"if load_model==False:\n    print(\"best_val_rmse_epoch = \", best_val_rmse_epoch)\n    print(\"minValLoss = \", minValLoss)\n    print(\"minValRmse = \", minValRmse)\n    \n#     print(\"minValRmseInd = \", minValRmseInd)\n#     print(\"minValLossInd = \", minValLossInd)\n\n    print(res_df)\n    res_df[[\"train_loss\", \"val_loss\"]].plot()\n    res_df[[\"val_rmse\"]].plot()","fa8cbbc8":"# if load_model==False:\n#     # import pandas as pd\n\n#     # Calling DataFrame constructor\n#     res_df = pd.DataFrame()\n\n#     res_df['epoch'] = range(num_epoches)\n#     res_df['train_loss'] = train_loss_arr\n#     res_df['val_loss'] = val_loss_arr\n#     res_df['val_rmse'] = val_rmse_arr\n# #     res_df['val_rmse_norm'] = list( np.array(val_rmse_arr)\/100.0 )\n\n#     print(res_df)","bf63c162":"# if load_model==False:\n# #     # res_df.plot()\n# #     res_df[[\"train_loss\", \"val_loss\", \"val_rmse_norm\"]].plot()\n#     res_df[[\"train_loss\", \"val_loss\"]].plot()\n#     res_df[[\"val_rmse\"]].plot()","ed1bc144":"# print(res_df['val_rmse'])\n\n# print(\"\\n\")\n# print( np.min(val_rmse_arr) )\n# ind = np.argmin(val_rmse_arr)\n# print(ind)\n# print(res_df['epoch'][ind])","ef20a81b":"# print(res_df['val_loss'])\n\n# print(\"\\n\")\n# print( np.min(val_loss_arr) )\n# ind = np.argmin(val_loss_arr)\n# print(ind)\n# print(res_df['epoch'][ind])","e2447210":"# images = iter(test_dataloader).next()\nimages = next( iter(test_dataloader) )\n\nplt.figure(figsize=(12, 12))\n# for it, (image, label) in enumerate(zip(images[:16], labels[:16])):\nfor it, (image) in enumerate(images[:16]):\n    test_img = image\n    plt.subplot(4, 4, it+1)\n    plt.imshow(image.permute(1, 2, 0))\n    plt.axis('off')\n#     plt.title(f'Pawpularity: {int(label)}')","7f70e745":"#     > ls \/kaggle\n#     input\/  lib\/  working\/\n#     > pwd\n#     '\/kaggle\/working'\n#     > ls ..\/working\n#     __notebook_source__.ipynb\n\n\n\n#     ..\/input\/petfinder-pawpularity-score\/sample_submission.csv\n#     ..\/input\/mypetmodels\/mymodel_epoch8.pth\n#     ..\/input\/pythonbox\/Box-master\/.github\n#     ..\/input\/timmpackage\/pytorch-image-models-master\/\n#     ..\/working","b3b28a3f":"# if KAGGLE:\n#     if load_model==False:\n#         myDir = f'..\/working'\n#     else:\n#         myDir = f'{config.model_dir}'\n# else:\n#     myDir = f'{config.model_dir}\/{config.model.name}'\n\nprint(\"type(myDir) = \", type(myDir) ) \nprint(\"myDir = \", myDir)\nprint(\"bestModelName = \", bestModelName)","febc77bb":"# import gc\n\n# if 'model' in locals():\n#     del model\n# gc.collect()\n# model  = None","04e15115":"# from pathlib import Path\n\n# # https:\/\/pytorch.org\/tutorials\/beginner\/basics\/saveloadrun_tutorial.html\n\n# # # model = torch.load('model.pth')\n# # model = torch.load( Path(myDir)\/ 'mymodel.pth' )\n\n\n# # torch.save( model, Path(myDir)\/bestModelName )\n# model = torch.load( Path(myDir)\/bestModelName )","fb44f125":"# model = model.cuda().eval()\n# device = model.device\n# print(\"device = \", device)","00aae5c6":"# super_final_predictions = pred_for_test_dataloader(model, test_dataloader)","47c2c7e4":"print(len(super_final_predictions))\nprint(type(super_final_predictions))\n# print(super_final_predictions)\n\n# 8\n# <class 'list'>","b8698d03":"# print(\"test_df.shape = \", test_df.shape)\n# print(\"test_df.columns.values= \", test_df.columns.values )\n# print(\"\\n\")\n# print(test_df.head(5))\n\n\n# print(\"\\n\")\n# test_df[\"Pawpularity\"] = super_final_predictions\n# print(\"test_df.shape = \", test_df.shape)\n# print(\"test_df.columns.values= \", test_df.columns.values )\n\n\n# print(\"\\n\")\n# test_df = test_df[[\"Id\", \"Pawpularity\"]]\n# print(\"test_df.shape = \", test_df.shape)\n# print(\"test_df.columns.values= \", test_df.columns.values )\n# test_df.to_csv(\"submission.csv\", index=False)","cbd27478":"submit_test_df = pd.DataFrame()\nsubmit_test_df[\"Id\"] = test_df[\"Id\"]\nsubmit_test_df[\"Pawpularity\"] = super_final_predictions","185f50ce":"print(\"submit_test_df.shape = \", submit_test_df.shape)\nprint(\"submit_test_df.columns.values= \", submit_test_df.columns.values )\nsubmit_test_df.head()","099d002e":"submit_test_df.to_csv(\"submission.csv\", index=False)","8e5f85de":"print(\"Done!\")","ae5a4798":"# Model","a0dc04c2":"# Config","84dee09b":"# Submission Csv","fc77d3bd":"# Visualize data","79f68f1c":"# Read data","b1e0e4c7":"# Augmentation","f70e31ef":"# Train","a995d859":"# Dataset","254bcaba":"# Helper functions"}}