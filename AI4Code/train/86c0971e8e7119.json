{"cell_type":{"86861ce2":"code","c863646d":"code","143f1de2":"code","9b8bbe0a":"code","ba9ca0c6":"code","3847c833":"code","769659b4":"code","1b7ea13c":"code","8b1e5603":"code","2821a4df":"code","4b1bfcff":"code","f7118b78":"code","5f50a0b3":"code","fd0d4c09":"code","3e998030":"code","3eb7b922":"code","a6b94e8e":"code","2e208455":"code","9a506ca0":"code","23601384":"code","f4a0cec1":"code","3c793fde":"code","9890177d":"code","0573ab65":"code","86cbc9d5":"code","417e5e4b":"code","8881ac6c":"code","e3fc2513":"code","dc40e049":"code","306a8e24":"code","6932ae39":"markdown","8ac86ed7":"markdown","75681a80":"markdown","d2af6d1c":"markdown","37b9f864":"markdown","93bd3bba":"markdown","3e4113dd":"markdown","11ed8474":"markdown","4fa7bf09":"markdown","7492c926":"markdown","1c43ec85":"markdown","9aabec0a":"markdown","9ff6e505":"markdown","31d091ff":"markdown","8845da7b":"markdown","0d0cdda4":"markdown","8eb07c1c":"markdown","ece12abf":"markdown","e4f38975":"markdown","c1029fdd":"markdown","16d804ae":"markdown","2c36e312":"markdown","c814023d":"markdown","560970ae":"markdown","e426cfc7":"markdown","e09d414a":"markdown","3a76c714":"markdown","bc1b59bb":"markdown","06f4c858":"markdown","49a79cab":"markdown","7513bfd7":"markdown","a03fa05e":"markdown","b6c950bf":"markdown","308043ab":"markdown","cce6cad8":"markdown","4b5e379e":"markdown","5597cff2":"markdown","0fe5500c":"markdown","9c912d67":"markdown","b605e671":"markdown"},"source":{"86861ce2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Skip Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings(action = 'ignore', category = DeprecationWarning)\nwarnings.filterwarnings(action = 'ignore', category = FutureWarning)","c863646d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","143f1de2":"diabetes_data = pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndiabetes_data.head()","9b8bbe0a":"diabetes_data.describe(include = 'all')","ba9ca0c6":"diabetes_data.hist(figsize=(20,12))","3847c833":"cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction']\n\ndiabetes_data[cols] = diabetes_data[cols].astype(\"float\")\n\nfig = plt.figure(figsize=(25,100))\n\nfor i in range(0,len(cols)):\n    ax = fig.add_subplot(20, 2,i+1)\n    g = sns.distplot(diabetes_data[cols[i]], bins = 50)\n    plt.xlabel(cols[i],fontsize = 22)\n    plt.grid(True)","769659b4":"sns.distplot(diabetes_data[\"Glucose\"])","1b7ea13c":"diabetes_data.loc[diabetes_data[\"Glucose\"]<=50, \"Glucose\"] = np.NaN\ndiabetes_data.loc[diabetes_data[\"BloodPressure\"]<=40, \"BloodPressure\"] = np.NaN\ndiabetes_data.loc[diabetes_data[\"SkinThickness\"]<=10, \"SkinThickness\"] = np.NaN\ndiabetes_data.loc[diabetes_data[\"Insulin\"]<=50, \"Insulin\"] = np.NaN\ndiabetes_data.loc[diabetes_data[\"BMI\"]<=18, \"BMI\"] = np.NaN","8b1e5603":"# Replacing the blood pressure level lower than 40 with the \"mean\" of blood pressure\ndiabetes_data[\"Glucose\"] = diabetes_data[\"Glucose\"].fillna(diabetes_data[\"Glucose\"].mean())\ndiabetes_data[\"BloodPressure\"] = diabetes_data[\"BloodPressure\"].fillna(diabetes_data[\"BloodPressure\"].mean())\ndiabetes_data[\"SkinThickness\"] = diabetes_data[\"SkinThickness\"].fillna(diabetes_data[\"SkinThickness\"].mean())\ndiabetes_data[\"Insulin\"] = diabetes_data[\"Insulin\"].fillna(diabetes_data[\"Insulin\"].mean())\ndiabetes_data[\"BMI\"] = diabetes_data[\"BMI\"].fillna(diabetes_data[\"BMI\"].mean())\n","2821a4df":"df = diabetes_data.copy()","4b1bfcff":"bins = [0,20,30,40,50,60,70,80,100]\nlabels = [\"0-20\", \"20-30\",\"30-40\",\"40-50\",\"50-60\",\"60-70\",\"70-80\",\"80+\"]\ndf['Age Bracket'] = pd.cut(df[\"Age\"], bins, labels = labels)","f7118b78":"plt.figure(figsize = (8,5))\n\nsns.countplot(df[\"Age Bracket\"], hue = df[\"Outcome\"])","5f50a0b3":"bp_bins = [0,60,80,90,100]\nbp_labels = [\"Low BP\",\"Ideal BP\", \"Pre-high BP\", \"High BP\"]\ndf[\"BloodPressure Buckets\"] = pd.cut(df[\"BloodPressure\"], bp_bins, labels = bp_labels)","fd0d4c09":"df[\"BloodPressure Buckets\"].value_counts()","3e998030":"plt.figure(figsize = (8,6))\n\nsns.countplot(x = df[\"BloodPressure Buckets\"], hue = df[\"Outcome\"])\nsns.set(font_scale = 1.1)\n","3eb7b922":"plt.figure(figsize = (8,6))\n\nsns.countplot(x = df[\"Pregnancies\"], hue = df[\"Outcome\"])\nsns.set(font_scale = 1)\n","a6b94e8e":"glucose_bins = [0,115,180,380]\nglucose_labels = [\"Normal Levels\",\"Elevated Levels\", \"Severly Elevated\"]\ndf[\"Glucose Buckets\"] = pd.cut(df[\"Glucose\"], glucose_bins, labels = glucose_labels)","2e208455":"plt.figure(figsize = (8,6))\n\nsns.countplot(df[\"Glucose Buckets\"], hue = df[\"Outcome\"])\nsns.set(font_scale = 2.1)\n","9a506ca0":"sns.distplot(df[\"Insulin\"], bins = 20)","23601384":"sns.distplot(df[\"SkinThickness\"], bins = 20)","f4a0cec1":"bmi_bins = [0,18,20,25,30,35]\nbmi_labels = [\"Underweight\", \"Normal\", \"Overweight\", \"Obese\", \"Extremely Obese\"]\ndf[\"BMI Buckets\"] = pd.cut(df[\"BMI\"], bmi_bins, labels = bmi_labels)","3c793fde":"plt.figure(figsize = (8,6))\n\nsns.countplot(df[\"BMI Buckets\"], hue = df[\"Outcome\"])#, color = df[\"Outcome\"])\nsns.set(font_scale = 1.9)\n","9890177d":"\nfig = plt.figure(figsize=(30,110))\n\nfor i in range(0,len(cols)):\n    ax = fig.add_subplot(20, 2,i+1)\n    ax = sns.boxplot(x = df[cols[i]], hue = [\"Outcome\"], palette=\"Set3\") #, bins = 50)\n    plt.xlabel(cols[i],fontsize = 20)\n    plt.grid(True)","0573ab65":"plt.figure(figsize=(5, 4))\nax = sns.countplot(x = diabetes_data[\"Outcome\"]) #, y = len(diabetes_data))\nncount = len(diabetes_data)\n\nfor p in ax.patches:\n    x=p.get_bbox().get_points()[:,0]\n    y=p.get_bbox().get_points()[1,1]\n    ax.annotate('{:.1f}%'.format(100.*y\/ncount), (x.mean(), y), \n            ha='center', va='bottom') # set the alignment of the text\n    \n    \n# Code Reference: https:\/\/stackoverflow.com\/questions\/33179122\/seaborn-countplot-with-frequencies","86cbc9d5":"diabetes_data[\"Outcome\"].value_counts()\/(len(diabetes_data[\"Outcome\"]))*100","417e5e4b":"# Independent variables\nX = diabetes_data.drop(\"Outcome\", axis = 1)\n\n# Target variable\ny = diabetes_data[\"Outcome\"]","8881ac6c":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = 1234)","e3fc2513":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, roc_auc_score\ndef model_building(model, parameters = None, cv = 10, scale = False):\n    if parameters == None:\n        clf = model.fit(X_train, y_train)\n        actual_train = y_train\n        prediction_train = clf.predict(X_train)\n        actual_valid = y_valid\n        prediction_valid = clf.predict(X_valid)\n        \n        ####### Model Evaluation #######\n        print(\"---------\",model,\"-----------\")\n        print(\"----TRAINING REPORT------\\n\")\n        print(classification_report(actual_train, prediction_train, digits=4))\n        print(\"AUC-ROC Score: \",round(roc_auc_score(actual_valid, prediction_valid),2))\n        print()\n        print(\"----VALIDATION REPORT------\\n\")\n        print(classification_report(actual_valid, prediction_valid, digits=4))\n        print(\"AUC-ROC Score: \",round(roc_auc_score(actual_valid, prediction_valid),2))\n        print()\n        return(model, prediction_train, prediction_valid)\n    else:\n        model_cv = GridSearchCV(estimator = model, param_grid = parameters, cv = cv)\n        model_cv.fit(X_train, y_train)\n        actual_train = y_train\n        prediction_train = model.predict(X_train)\n        actual_valid = y_valid\n        prediction_valid = model.predict(X_valid)\n        \n        ####### Model Evaluation #######\n        print(\"---------\",model,\"-----------\")\n        print(\"----TRAINING REPORT------\\n\")\n        print(classification_report(actual_train, prediction_train, digits=4))\n        print(\"AUC-ROC Score: \",round(roc_auc_score(actual_valid, prediction_valid),2))\n        print()\n        print(\"----VALIDATION REPORT------\\n\")\n        print(classification_report(actual_valid, prediction_valid, digits=4))\n        print(\"AUC-ROC Score: \",round(roc_auc_score(actual_valid, prediction_valid),2))\n        print()\n        model = model_cv.best_estimator_\n    \n\n        return(model_cv, prediction_train, prediction_valid)","dc40e049":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier","306a8e24":"models = [LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(), AdaBoostClassifier()]\n# parameters = \nfor model in models :\n    \n    model, pred_train, pred_valid = model_building(model, cv=10)","6932ae39":"___","8ac86ed7":"## Concluding Notes:\n\n1. We have limited data; only 768. Had we had more data, our model performance would have been much better.\n2. Selection of performance metrics is necessary. Here, the problem statement had not mentioned about the metric. Hence we decided to go with F1-Score.","75681a80":"## Observations (at the time of running the script)\n\n1. We can see that AUC-ROC Score is the best for **Logistic Regression** with 77%, followed by **Random Forest Classifier** with 74%. However, it is necessary to look at other metrics as well.\n\n2. **Decision Tree Classifier** is the lowest performing model, as the accuracy is the lowest with 69%.\n\n3. If you notice, **Decision Tree Classifier** and **Random Forest Classifier** have all the training values as 1. This means that the model is overfitting in training dataset. And it makes sense as well, because these algorithms learn the data completely and shows uch classification report.\n\n4. **Logistic Regression** tends to *underfit*, as the training report is less than that of validation report, with 75% and 81% respectively. However, I would claim that this is the best performing model of all other models.\n\n5. If you look at **AdaBoost Classifier**, it tends to overfit the model, as the training accuracy is higher than the validation accuracy.","d2af6d1c":"### Observations:\n\nThere seems to be something odd with *BMI, BloodPressure, Glucose, Insulin*, and *SkinThickness*. All of them have values in 0s. Practically, this is not possible. Let's dig deeper into this.\n\n**Solution-** Replace these values using statistical techniques, preferably *mean*.","37b9f864":"___\n## 4. Glucose","93bd3bba":"### Model training and Evaluation","3e4113dd":"We can see that our dataset is fairly balanced. Hence, there is no need for us to perform SMOTE (synthetic minority oversampling technique).","11ed8474":"## 6. Skin Thickness","4fa7bf09":"![image.png](attachment:image.png)\n\nReference: https:\/\/cdn.viva.org.uk\/wp-content\/uploads\/2020\/07\/Blood-pressure-graph.jpg","7492c926":"# <center>Pima Indian Diabetes<\/center>\n\nThis dataset has been provided by **National Institute of Diabetes and Digestive and Kidney Diseases** on Kaggle to predict whether the patient has diabetes or not.\n\nThe data contains information about **FEMALES ABOVE 21 YEARS OF AGE ONLY.** It has mainly 8 independent features and 1 target variable, **OUTCOME** (1 or 0)\n\nThis notebook only consists of EDA; it does not contain any ML model techniques. This is a Binary Classification problem, where we can use a classification model to predict where the patient has diabetes or not. \n\nI will be uploading a notebook specifically on model building and optimization in coming days. Hope you like it! :)\n\n**03\/May\/2021 UPDATE:** I have also included model building in this notebook. Please find it below! :)","1c43ec85":"Unfortunately, I did not find anything that relates skin thickness to diabetes on the internet. I'm sure there is, although I'm not a medical practitioner. Hence it is better to not write something incorrect.","9aabec0a":"# <center>Exploratory Data Analysis<\/center>\n\nAll our features are numerical based, except the target variable. Hence, it is better to analyse them using *BINNING*, or *BUCKETING*.","9ff6e505":"___\n## 5. Insulin","31d091ff":"Creating a copy **df** specifically for EDA","8845da7b":"Hope this was helpful! :)\n\n# <center>End of the notebook<\/center>","0d0cdda4":"I did not really find anything on Insulin, because insulin measures are taken before and after the diabetes test. In this dataset, there is only one column of Insulin, without any description if this is pre-test results or post-test results.\n\nHence, I cannot comment about any trends or insights on Insulin.\n\n___\n\n","8eb07c1c":"## Solution\nInstead of dropping those rows, we could use them. This would be helpful for building ML models\n\n**mean** is a fairly better replacement than randomly imputing those values.\n___","ece12abf":"<div class=\"alert alert-block alert-info\"><b> \n\nQ. Why did we replace the numbers with NaN?\n\nA. If we had directly performed the **mean** operation, then even those values, which needed to be replaced, would have contributed to the mean. This would have been an *imperfect* mean.\n\nReplacing those values with *NaN*, and then taking the mean helps in getting us *true-mean*\n    <\/b><\/div>","e4f38975":"### Checking the distribution of the target variable, *Outcome*","c1029fdd":"The main insight is if the the BMI is *above Normal*, then a female is likely to be diagnosed with diabetes, especially the ones who are *Extremely Obese*.\n___\n","16d804ae":"As per the graph, females having *Pre-High Blood Pressure* and *High Blood Pressure* are at a higher risk of being diagnosed with diabetes. \n\nAs mentioned in this article, \"The condition occurs in as many as two-thirds of people with diabetes and places these individuals at twice the risk of heart disease than a person only dealing with high blood pressure.\" \n\nReference: https:\/\/www.canopyhealth.com\/en\/members\/articles\/high-blood-pressure-and-type-two-diabetes.html","2c36e312":"### Train Test Split\n\nWhenever we build a classification model, we should ensure to include the parameter **stratify**. What this does is instead of randomly splitting the dataset, *train_test_split* splits the training and validation datasets *in proportion with* as that of in the original dataset.\n","c814023d":"## Boxplots\n\nIt is always necessary to check the distribution of the data set. It helps us check for any outliers. Boxplot helps us do the same.","560970ae":"#### Strategy for each column mentioned above\n1. *Glucose* lower than 50 will be replaced by mean\n2. *BloodPressure* lower than 40 will be replaced by the mean\n3. *SkinThickiness* lower than 10 will be replaced by the mean\n4. *Insulin* lower than 50 will be replaced by the mean\n5. *BMI* lower than 18 will be replaced by the mean","e426cfc7":"Body mass index, (BMI), is a measure of body size. It combines a person\u2019s weight with their height. The results of a BMI measurement can give an idea about whether a person has the correct weight for their height.\n\nBMI is used as a diagnostic tool to screen potential weight problems in adults and in children. It is not the most accurate measure, although it helps to determine various health challenges.\n\nReference: https:\/\/www.medicalnewstoday.com\/articles\/323622#how-doctors-use-bmi","e09d414a":"Exactly what we had hypothesized. There are a lot of values which are 0s.\n\n#### A small summary of each graph\n1. *Glucose* - Having glucose level less than 50 is very dangerous and not possible\n2. *BloodPressure* - Having blood pressure lower than 40 is not possible.\n3. *SkinThickiness* - Skin thickness with 0 means the person does not have any skin. This has to be replaced.\n4. *Insulin* - The graph indicates that insulin levels are 0. Again, this case is not possible.\n5. *BMI* - The lowest BMI possible is around 18. Lower than that is not possible.\n\n\nNeither do I know what *DiabetesPedigreeFunction* is, nor the description of the data has mentioned what it is. Hence, I would not be making any changes here.\n___","3a76c714":"### 1. AGE","bc1b59bb":"# Model Building\n\n","06f4c858":"Based on the data, it can be seen that females tend to contract diabetes from their 30's. It is alarming that in the age bracket *30-40*, females having diabetes and not having diabetes are almost equal.\n\nSubsequently in the age brackets *40-50* and *50-60*, number of females having diabetes **surpases** the number of females that do not have diabetes. \n\nIf you notice, the rate at which females contract diabetes drastically increases from the age bracket *20-30* to rest of the brackets.","49a79cab":"___\n## 3. Pregnancies","7513bfd7":"Using the above reference chart, we can see that females with *Elevated Levels* and *Severly Elevated* of glucose have higher risk of being diagnosed with diabetes. And that makes sense as well.\n\nThe higher the sugar level (or glucose in medical terms), the higher the risk of being diagnosed with diabetes.","a03fa05e":"![bmi.jpg](attachment:bmi.jpg)\n\nReference: https:\/\/www.cdc.gov\/healthyweight\/images\/assessing\/bmi-adult-fb-600x315.jpg","b6c950bf":"Ladies who have had babies *more than 6 times* have higher risk of having diabetes.","308043ab":"___\n### 2. Blood Pressure\n\nSince the analysis of *Blood Pressure* can be easily interpretable using bucketing, it is best do the same way.\n\nThe figure below shows the correct ranges of blood pressure ranges.","cce6cad8":"### Separating the independent variables and target variable\n\n**NOTE**: We had used **df** which had been bucketed specifically for EDA and gather insights. For model building, we will be using **diabetes_data.**\n\nWe have already observed and changed the **diabetes_data**. Hence, we can directly start using the **diabetes_data.**","4b5e379e":"___\n## 7. BMI","5597cff2":"<div class = 'alert alert-block alert-warning'>\n    Choosing the correct metrics for model evaluation is a very important step for any model performance evaluation.\n    \n\n<\/div>\n<div class = 'alert alert-block alert-success'>In this case, since there is no metrics mentioned, we would consider <b>F1 Score<\/b> as our primary metrics, because it takes into account both False Positive and False Negative results. One may choose some other metrics as well.\n\n<\/div>","0fe5500c":"It is evident that there are outliers in the data, for eg.:\n1. *Insulin*: There are a lot of values beyond 500, which seems vague. We can either drop them, or consult a medical practioner for further information.\n2. *SkinThickness*: There is just one value that is 100. We can surely drop it.\n3. *DiabetesPedigreeFunction*: As I menioned above in the notebook, we do not have any information on this feature; neither in the data description, nor on the internet. Hence, I cannot determine the significance of this feature. Although, the distribution looks fair and I **assume** that there are no outliers. The are true values.\n\n\n\nThis mainly completes the extensive EDA on the dataset. If you like it, please feel free to hit the like and comment for any improvements.\n\n\n\n___","9c912d67":"This is a *BINARY CLASSIFICATION* problem, i.e. 1 or 0. Hence, we will be testing the model using following algorithma:\n\n1. Logistic Regression\n2. KNearest Neighbour Classifier \n3. Decision Tree Classifier \n4. Gradient Boost Classifier\n5. Random Forest Classifier\n\nOur target variable will be **OUTCOME.**","b605e671":"![glucode.jpg](attachment:glucode.jpg)\n\n\n\nReference: https:\/\/www.pinterest.com\/pin\/425168021046555513\/\n\n\nThe bucketing has been done using above chart"}}