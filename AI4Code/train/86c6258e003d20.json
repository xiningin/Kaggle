{"cell_type":{"d1f4666a":"code","1bf5df3e":"code","535d9d63":"code","3d91cd6a":"code","afc93d74":"code","c5bf7ef9":"code","f2e19fad":"code","9d99a739":"code","28a303c3":"code","e4fcb063":"code","733fba99":"code","bef9a3dc":"code","cc419807":"code","edf1c3ce":"code","6c4bbe0d":"code","b0f27a46":"code","36a4d0a2":"code","4b75ca82":"code","86a51ed8":"code","b6965bd5":"code","89a55de7":"code","12bf048d":"code","21c359dc":"code","d4282bed":"code","4b112e24":"code","64ea492a":"code","a11eac39":"code","c58522dc":"code","88cdfaa9":"code","bcc208de":"code","d1a4d674":"code","1f62e192":"code","be45d526":"code","839853eb":"code","d70416c5":"code","b4d2ed28":"code","42f982cc":"code","c5cb5f29":"code","752422a3":"code","25b28627":"markdown","633e9271":"markdown","a4182a23":"markdown","0d93eca2":"markdown"},"source":{"d1f4666a":"import os\nos.listdir('..\/input\/siim-medical-images\/dicom_dir')","1bf5df3e":"import cv2\nimport numpy as np\nimport pydicom as dicom","535d9d63":"im1 = dicom.read_file('..\/input\/siim-medical-images\/dicom_dir\/ID_0012_AGE_0061_CONTRAST_1_CT.dcm')","3d91cd6a":"print(im1.pixel_array)","afc93d74":"print(im1.pixel_array.shape)","c5bf7ef9":"import matplotlib.pyplot as plt\nplt.imshow(im1.pixel_array)\nplt.show()","f2e19fad":"im2 = dicom.read_file('..\/input\/siim-medical-images\/dicom_dir\/ID_0059_AGE_0074_CONTRAST_0_CT.dcm')","9d99a739":"print(im2.pixel_array)","28a303c3":"print(im2.pixel_array.shape)","e4fcb063":"import matplotlib.pyplot as plt\nplt.imshow(im2.pixel_array)\nplt.show()","733fba99":"import os\npath = '..\/input\/siim-medical-images\/dicom_dir'\n\nslices = []\nfor file in os.listdir(path):\n    slices.append(dicom.read_file(os.path.join(path,file)))","bef9a3dc":"slices[0].pixel_array","cc419807":"#pixel spacing\n#slice_thickness\n#axial_aspect_ratio\n#sagital_aspect_ratio\n#coronal_aspect_ratio\n\npixel_spacing = slices[0].PixelSpacing\nslice_thickness = slices[0].SliceThickness\n\nprint(pixel_spacing)\nprint(slice_thickness)","edf1c3ce":"axial_aspect_ratio = pixel_spacing[1]\/pixel_spacing[0]\nsagital_aspect_ratio = pixel_spacing[1]\/slice_thickness\ncoronal_aspect_ratio = slice_thickness\/pixel_spacing[0]\nprint(axial_aspect_ratio)\nprint(sagital_aspect_ratio)\nprint(coronal_aspect_ratio)","6c4bbe0d":"image_shape = list(slices[0].pixel_array.shape)\nprint(image_shape)","b0f27a46":"image_shape.append(len(slices))\nprint(image_shape)","36a4d0a2":"volume3d = np.zeros(image_shape)\nvolume3d","4b75ca82":"volume3d.shape","86a51ed8":"a = np.zeros([3,4,4])\na","b6965bd5":"for i,s in enumerate(slices):\n    #print(i,s.pixel_array)\n    array2D = s.pixel_array\n    volume3d[:,:,i] = array2D\n    \nprint(array2D.shape)\nprint(volume3d.shape)","89a55de7":"axial = plt.subplot(2,2,1)\nplt.title('Axial')\nplt.imshow(volume3d[:,:,image_shape[2]\/\/2])\naxial.set_aspect(axial_aspect_ratio)\n\nsagital = plt.subplot(2,2,2)\nplt.title('Sagital')\nplt.imshow(volume3d[:,image_shape[2]\/\/2,:])\nsagital.set_aspect(sagital_aspect_ratio)\n\ncoronal = plt.subplot(2,2,3)\nplt.title('Coronal')\nplt.imshow(volume3d[image_shape[2]\/\/2,:,:].T)\ncoronal.set_aspect(coronal_aspect_ratio)","12bf048d":"#features\nfeatures = volume3d\nfeatures.shape\nX = features.transpose(2,0,1)\nX.shape","21c359dc":"#labels\nlabels = []\nfor file in os.listdir(path):\n    labels.append(file.split('_')[-2])\n    \nY = np.array(labels)\nY.shape","d4282bed":"path = '..\/input\/siim-medical-images\/dicom_dir'","4b112e24":"import os\nimport cv2\nimport numpy as np\nimport pydicom as dicom\n\nimages = []\nfor file in os.listdir(path):\n    f = dicom.read_file(os.path.join(path,file)).pixel_array\n    fr = cv2.resize(f,(256,256))\n    images.append(fr)","64ea492a":"X = np.array(images)\nprint(X.shape)","a11eac39":"#labels\nlabels = []\nfor file in os.listdir(path):\n    labels.append(file.split('_')[-2])\n    \nY = np.array(labels)\nY.shape","c58522dc":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size=0.2)","88cdfaa9":"xtrain = xtrain.reshape(80, 256, 256,1)\nxtest = xtest.reshape(20, 256, 256,1)","bcc208de":"xtrain_n = xtrain\/xtrain.max()\nxtest_n = xtest\/xtest.max()","d1a4d674":"from keras.utils import np_utils\nytrain_h = np_utils.to_categorical(ytrain)\nytest_h = np_utils.to_categorical(ytest)","1f62e192":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Dropout,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras import regularizers","be45d526":"wd = 1e-4\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3) , padding='same' , kernel_regularizer=regularizers.l2(wd), input_shape=xtrain.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(64,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(256,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(512,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(1024,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(2,activation='softmax'))","839853eb":"model.summary()","d70416c5":"from keras import optimizers\nfrom keras import metrics\n\nmodel.compile(optimizer='sgd',loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])","b4d2ed28":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rotation_range=10,\n                             width_shift_range=0.1,\n                             height_shift_range=0.2,\n                             zoom_range=0.3,\n                             horizontal_flip=True)","42f982cc":"model.fit(datagen.flow(xtrain_n, ytrain_h,batch_size=15), epochs=100, validation_data=(xtest_n,ytest_h))","c5cb5f29":"print(model.evaluate(xtrain_n,ytrain_h))","752422a3":"print(model.evaluate(xtest_n,ytest_h))","25b28627":"**Extract Features of all available data**","633e9271":"**If image shapes are different**","a4182a23":"**View of images**","0d93eca2":"**Train your model to identify contrast or non-contrast readings**"}}