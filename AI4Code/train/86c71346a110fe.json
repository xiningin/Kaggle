{"cell_type":{"dfbf5ea1":"code","a7e12c9f":"code","4d56596e":"code","9a723eed":"code","094b541a":"code","1be41977":"code","47f7acac":"code","08d5dd2d":"code","0ccf3dc0":"code","628a9121":"code","d6b6717d":"code","80d287a0":"code","bd2a27e9":"code","bce1e778":"code","cbc93805":"code","bba90d95":"code","09c769fd":"code","be8645e4":"code","b83b8394":"code","513ed9e9":"code","ffbc2eed":"code","8982bd93":"code","75a1c406":"code","f700cd99":"code","ab964a6a":"code","c2649e22":"markdown","1ec7a2df":"markdown","4f9c1b4f":"markdown","b683468a":"markdown","57fa32a1":"markdown","7a910542":"markdown","a4a490d7":"markdown","c149e58d":"markdown","318ff08c":"markdown","a51a98f2":"markdown","1dce40c5":"markdown","fa2dfb9a":"markdown","585d9e6c":"markdown","4a3cc82b":"markdown","b507a5b4":"markdown","46eda439":"markdown"},"source":{"dfbf5ea1":"# Import Modules\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn.preprocessing as pre\nfrom scipy.special import inv_boxcox\nfrom scipy.stats import boxcox","a7e12c9f":"# read File\n\nData_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id')\nData_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col='Id')\nSubmission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","4d56596e":"Data_train.head()","9a723eed":"Data_test.head()","094b541a":"Submission.head()","1be41977":"Data_train.isnull().sum()","47f7acac":"Data_train.info()","08d5dd2d":"Data_test.info()","0ccf3dc0":"#Correlation map to see how features are correlated with SalePrice\nCor_heat = Data_train.corr()\nplt.figure(figsize=(16,16))\nsns.heatmap(Cor_heat, vmax=0.9, square=True)","628a9121":"# Drop Missing value\n# I drop these because they had so many missing value and lower corr with sale price\n\nColumns = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n\nData_train = Data_train.drop(Columns, axis=1)\nData_train.head()","d6b6717d":"# Encode Categorical features to numerical features with get dummies from pandas\n\nData_train = pd.get_dummies(Data_train)\nData_train = Data_train.fillna(method='ffill')\nData_train.head()","80d287a0":"## Basic Distribution\n\nprint('Skew Value : ' + str(Data_train.SalePrice.skew()))\nsns.distplot(Data_train.SalePrice)","bd2a27e9":"f = plt.figure(figsize=(16,16))\n\n# log 1 Transform\nax = f.add_subplot(221)\nL1p = np.log1p(Data_train.SalePrice)\nsns.distplot(L1p,color='b',ax=ax)\nax.set_title('skew value Log 1 transform: ' + str(np.log1p(Data_train.SalePrice).skew()))\n\n# Square Log Transform\nax = f.add_subplot(222)\nSRT = np.sqrt(Data_train.SalePrice)\nsns.distplot(SRT,color='c',ax=ax)\nax.set_title('Skew Value Square Transform: ' + str(np.sqrt(Data_train.SalePrice).skew()))\n\n# Log Transform\nax = f.add_subplot(223)\nLT = np.log(Data_train.SalePrice)\nsns.distplot(LT, color='r',ax=ax)\nax.set_title('Skew value Log Transform: ' + str(np.log(Data_train.SalePrice).skew()))\n\n# Box Cox Transform\nax = f.add_subplot(224)\nBCT,fitted_lambda = boxcox(Data_train.SalePrice,lmbda=None)\nsns.distplot(BCT,color='g',ax=ax)\nax.set_title('Skew Value Box Cox Transform: ' + str(pd.Series(BCT).skew()))","bce1e778":"## Lets see what most important features we have\n\nIF = Cor_heat['SalePrice'].sort_values(ascending=False).head(10).to_frame()\nIF.head(4)","cbc93805":"# make Models\n\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score","bba90d95":"# Split The data\n\nTrain = Data_train.drop('SalePrice', axis=1)\nTest = Data_train.SalePrice","09c769fd":"# Assign the distribution of Sale Price\n\nfeature_SP = {'Log Transform': LT,\n              'Square Root Transform': SRT,\n              'Box-Cox Transform':BCT,\n              'Log 1 Transform': L1p}","be8645e4":"from sklearn.model_selection import cross_val_score, cross_val_predict\n\n# Perform 5-fold CV\n\nreg = LinearRegression()\nlcv = LassoCV()\nrcv = RidgeCV()\n\nalg = [reg, lcv, rcv]\n    \nfor y in alg:\n    print(str(y.__class__.__name__) + ' results')\n    for key, value in feature_SP.items():\n        Test = value\n        score = np.sqrt(-cross_val_score(y, Train, Test, scoring='neg_mean_squared_error', cv=5))\n        print('RMSE with ' + str(key) + ' : ' + str(np.mean(score)))","b83b8394":"Columns = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n\nData_test = Data_test.drop(Columns, axis=1)\nData_test.head()\n\n# Fill Missing Value\nData_test = pd.get_dummies(Data_test)\nData_test = Data_test.fillna(method='ffill')\nData_test.head()","513ed9e9":"Train.head()","ffbc2eed":"d1 = Train.columns\nd2 = Data_test.columns\n\nout = []\n\nfor x in d1:\n    if x in d2:\n        pass\n    else:\n        out.append(x)\n\nprint(out)\nprint(len(out))","8982bd93":"Data_trains = Train.drop(out, axis=1)\nData_trains.shape","75a1c406":"# Use data trains as train\nTrain = Data_trains\n# Best Alg = Ridge CV\nmodel = rcv\n# X_train\nX_train = Train\n# Y_train = Box Cox Sale Price\nTest = BCT\ny_train = Test\n# X_test\nX_test = Data_test\n# Y_pred\nmodel.fit(X_train, y_train)\ny_pred = inv_boxcox(model.predict(X_test), fitted_lambda)\ny_pred","f700cd99":"Submission['SalePrice'] = y_pred\nSubmission.head()","ab964a6a":"Submission.to_csv(\"Final Submission File.csv\",index=False)","c2649e22":"Haiii Kagglers, in this kernel i will show you how to deal with regression problem.\nToday i will be using 3 algorithm, Linear regression, Lasso CV, and Ridge CV.\nlet's get started.","1ec7a2df":"There is 1460 rows in total, and we also got few columns with missing value. So i'm going to drop few column with missing value more than 50%, but first let's make sure they are not important feature to our target column.\nLet's check the correlation.","4f9c1b4f":"Lets take a look at the distribution in our target column, Sale Price.","b683468a":"The best distribution value is with Box Cox Transform with value -0.008, this is the best distribution for our target dataset. But just to make sure we are going to perform validation score with all these transformation.","57fa32a1":"## Perform Prediction\n\nLet's treat the test data in the same way we treat train data by droping few columns, Performing Feature Engineering and fill some missing value.","7a910542":"## Feature Engineering\n\nAfter performing cleansing, we have to encode the categorical data and fill some missing value on the dataset","a4a490d7":"I'm not sure what are these columns, but i think the dataset generate this when we perform encoding to our dataset, don't worry and just drop them.","c149e58d":"There is something wrong here, the total of columns are different in both dataset, we cant perform any prediction like this. Let's check what columns is in train dataset but not in test dataset. ","318ff08c":"Skew value is 1.8, which is bad, this could affect the accuracy in the models. lets Transform this column and lets see if we can find the closest skew value to zero (the best distribution)","a51a98f2":"## Import Modules","1dce40c5":"## Quick Look\nLets take a quick look at the dataset","fa2dfb9a":"The lowest RMSE score is 0.05 with RidgeCV algorithm and Box Cox Transform, this is the combination we are going use to perform prediction in test dataset.","585d9e6c":"## Building Models\n\nLet's try building a models","4a3cc82b":"## End\n\nThat is how you handle regression problem.\nThank you :)","b507a5b4":"Now the train dataset have 254 columns, it the same count as test dataset. Now let's perform prediction on the test dataset, remember the best algorithm is ridge CV and the best transformation is Box Cox Transformation, let's apply those rule here.","46eda439":"## Data Cleansing"}}