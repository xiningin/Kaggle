{"cell_type":{"0678958a":"code","75f38c04":"code","7cdbe7a1":"code","d9253075":"code","9e4bbf88":"code","1dbcebd0":"code","6fafd52c":"code","67fa9ae0":"code","358a144d":"markdown"},"source":{"0678958a":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom xgboost import XGBClassifier","75f38c04":"df = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nnumerical_cols = ['Age', 'Fare', 'SibSp', 'Parch']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfinal_predictions = []; scores=[]; acc_scores=[]\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBClassifier(random_state=fold, objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    loss = log_loss(yvalid, preds_valid)\n    accuracy = accuracy_score(yvalid, preds_valid)\n    print(fold, loss)\n    scores.append(loss)\n    acc_scores.append(accuracy)\n    \nprint(np.mean(scores), np.std(scores))\nprint(f\"CV score (accuracy): {np.mean(acc_scores):.3f}\")","7cdbe7a1":"# standardization\ndf = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nnumerical_cols = ['Age', 'Fare', 'SibSp', 'Parch']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfinal_predictions = []; scores=[]; acc_scores=[]\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n\n    scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n    \n    model = XGBClassifier(random_state=fold, objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    loss = log_loss(yvalid, preds_valid)\n    accuracy = accuracy_score(yvalid, preds_valid)\n    print(fold, loss)\n    scores.append(loss)\n    acc_scores.append(accuracy)\n    \nprint(np.mean(scores), np.std(scores))\nprint(f\"CV score (accuracy): {np.mean(acc_scores):.3f}\")","d9253075":"# log transformation\ndf = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nnumerical_cols = ['Age', 'Fare', 'SibSp', 'Parch']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfor col in numerical_cols:\n    df[col] = np.log1p(df[col])\n    df_test[col] = np.log1p(df_test[col])\n    \nfinal_predictions = []; scores=[]; acc_scores=[]\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n\n    scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n    \n    model = XGBClassifier(random_state=fold, objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    loss = log_loss(yvalid, preds_valid)\n    accuracy = accuracy_score(yvalid, preds_valid)\n    print(fold, loss)\n    scores.append(loss)\n    acc_scores.append(accuracy)\n    \nprint(np.mean(scores), np.std(scores))\nprint(f\"CV score (accuracy): {np.mean(acc_scores):.3f}\")","9e4bbf88":"# one hot encoding \ndf = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nnumerical_cols = ['Age', 'Fare', 'SibSp', 'Parch']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfinal_predictions = []; scores=[]; acc_scores=[]\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n\n    xtrain = pd.concat([xtrain, xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest, xtest_ohe], axis=1)\n    \n    xtrain = xtrain.drop(object_cols, axis=1)\n    xvalid = xvalid.drop(object_cols, axis=1)\n    xtest = xtest.drop(object_cols, axis=1)\n    \n    model = XGBClassifier(random_state=fold, objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    loss = log_loss(yvalid, preds_valid)\n    accuracy = accuracy_score(yvalid, preds_valid)\n    print(fold, loss)\n    scores.append(loss)\n    acc_scores.append(accuracy)\n    \nprint(np.mean(scores), np.std(scores))\nprint(f\"CV score (accuracy): {np.mean(acc_scores):.3f}\")","1dbcebd0":"preds = np.column_stack(final_predictions)\npreds = [*map(lambda x:np.argmax(np.bincount(x)), preds)]","6fafd52c":"sample_submission.Survived = preds\nsample_submission.to_csv(\"submission.csv\", index=False)","67fa9ae0":"sample_submission","358a144d":"Inherited from https:\/\/www.kaggle.com\/abhishek\/competition-part-2-feature-engineering\n\n- Ordinal encoder\n- Label encoder\n- One hot encoder"}}