{"cell_type":{"279d88c0":"code","c7c72f37":"code","c3dc4cbc":"code","1d21f0cd":"code","8ccaece1":"code","ade5e0dc":"code","6f9af8bd":"code","5745ffba":"code","78032cf0":"code","c3a6356e":"code","2b7d1c16":"code","d237fdb0":"code","56817c00":"code","67ef8424":"code","3e9d5f13":"code","3768156f":"code","a2479b07":"code","f920d56e":"code","214987ac":"code","92c6aab6":"code","908c516e":"code","2bde925b":"code","5e303571":"code","64676f16":"code","f56a877f":"code","a185c203":"code","c005b912":"code","7298b662":"code","5dcb4f16":"code","0fd60089":"code","9dc13154":"markdown","a3f10736":"markdown","7ce9480a":"markdown"},"source":{"279d88c0":"# Import required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nimport cv2\nfrom keras.callbacks import Callback\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dense\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import roc_curve,auc, confusion_matrix","c7c72f37":"print (\"Number of train files:\",len(os.listdir(\"..\/input\/train\")))\nprint (\"Number of test files:\",len(os.listdir(\"..\/input\/test\")))\n\ndftrain=pd.read_csv(\"..\/input\/train_labels.csv\",dtype=str)\ndftrain.head()","c3dc4cbc":"print(\"Counts of negative and postive labels in training data:\")\ndftrain.groupby(['label']).count()","1d21f0cd":"def add_ext(id):\n    return id+\".tif\"\n\ndftrain[\"id\"]=dftrain[\"id\"].apply(add_ext)\n\ndef addpath(col):\n    return '..\/input\/train\/' + col \n\ndftrain['Path']=dftrain['id'].apply(addpath)\ndftrain.head()","8ccaece1":"## function to plot historgrams\n\ndef plothist(plot_img,axnum):\n    color = ('b','g','r')\n    for j,col in enumerate(color):\n         histr = cv2.calcHist([plot_img],[j],None,[256],[0,256])\n         ax[axnum,i].plot(histr,color = col)\n         ax[axnum,i].set_xlim([0,256])\n         ax[axnum,i].set_xlabel(\"Pixel Values\")\n         ax[axnum,0].set_ylabel(\"# of Pixels\")\n    return ","ade5e0dc":"## print a sample of the images\nnums = [76, 46, 69, 20, 17] # random.sample(range(1, 100), 5)\nnum_pics = len(nums)\nf,ax = plt.subplots(3,num_pics,figsize=(15,15))\n\nfor i in range(5):\n    img = plt.imread(dftrain.iloc[nums[i]]['Path'])\n   # ax[i].imshow(img)\n   # ax[i].set_title(dfdata.iloc[i]['label'],fontweight=\"bold\", size=20)\n    ax[0,i].imshow(img)\n    ax[0,i].set_title(dftrain.iloc[i]['label'],fontweight=\"bold\", size=20)\n    # Create a Rectangle patch\n    rect = patches.Rectangle((32,32),32,32,linewidth=3,edgecolor='r',facecolor='none')\n    # Add the patch to the Axes\n    ax[0,i].add_patch(rect)\n    ## plot histograms of full image and cancer patch\n    plothist(img,1)\n    plothist(img[32:64, 32:64],2)\n    \nplt.show() ","6f9af8bd":"## use flow from directory\ndatagen=ImageDataGenerator(rescale=1.\/255.,validation_split=0.2)","5745ffba":"batch_size = 20\nimage_size = (96,96)\n\ntrain_generator=datagen.flow_from_dataframe(\ndataframe=dftrain,\ndirectory=\"..\/input\/train\/\",\nx_col=\"id\",\ny_col=\"label\",\nsubset=\"training\",\nbatch_size=batch_size,\nseed=42,\nshuffle=True,\nclass_mode='categorical', #class_mode=\"binary\",\ntarget_size=image_size)\n\nvalidation_generator=datagen.flow_from_dataframe(\ndataframe=dftrain,\ndirectory=\"..\/input\/train\/\",\nx_col=\"id\",\ny_col=\"label\",\nsubset=\"validation\",\nbatch_size=batch_size,\nseed=42,\nshuffle=True,\nclass_mode='categorical', #class_mode=\"binary\",\ntarget_size=image_size)","78032cf0":"kernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()\n\nmodel.compile('Adam', loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","c3a6356e":"kernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()\n\nmodel.compile(Adam(0.0001), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n","2b7d1c16":"trainstep=train_generator.n\/\/train_generator.batch_size\nvalstep=validation_generator.n\/\/validation_generator.batch_size\n\nfilepath=\"weights-best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nhistory=model.fit_generator(generator=train_generator,\n                    steps_per_epoch=trainstep,\n                    validation_data=validation_generator,\n                    validation_steps=valstep,\n                    epochs=20,\n                    callbacks=[checkpoint]\n)","d237fdb0":"# plot learning curves\nfilepath=\"weights-best.hdf5\"\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","56817c00":"## Create test generator and evaluate model \n\nmodel.load_weights(filepath) #load saved weights\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\n\ntest_generator=datagen.flow_from_dataframe(\ndataframe=dftrain,\ndirectory=\"..\/input\/train\/\",\nx_col=\"id\",\ny_col=\"label\",\nsubset=\"validation\",\nbatch_size=5,   # want to divide num samples evenly \nseed=42,\nshuffle=False,  # don't shuffle\nclass_mode='categorical', #class_mode=\"binary\",\ntarget_size=image_size)\n","67ef8424":"scores = model.evaluate_generator(test_generator)\nprint('Test loss:', round(100*scores[0],2))\nprint('Test accuracy:', round(100*scores[1],2))\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","3e9d5f13":"test_labels = test_generator.classes\ny_preds = model.predict_generator(test_generator,verbose=1,steps=test_generator.n\/5)\n","3768156f":"y_pred_keras=np.argmax(y_preds, axis=-1)\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(test_labels, y_pred_keras)\nauc_keras = auc(fpr_keras, tpr_keras)\nprint('AUC score :', + auc_keras)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(test_labels, y_pred_keras))","a2479b07":"# plot ROC curve\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","f920d56e":"classes=list((test_generator.class_indices).values())\ncm=confusion_matrix(test_labels,y_pred_keras)\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes)\nplt.yticks(tick_marks, classes)\nplt.imshow(cm, cmap=plt.cm.Blues)\nprint(cm)","214987ac":"len(test_generator.filenames)","92c6aab6":"test_frame=pd.DataFrame({'id':(test_generator.filenames)})\ntest_frame['true_label']=test_labels\ntest_frame['predicted'] = y_pred_keras\ntest_frame['no_cancer'] = y_preds[:,0]\ntest_frame['cancer'] = y_preds[:,1]\ntest_frame['Path']=test_frame['id'].apply(addpath)","908c516e":"incorrect_preds=(test_frame[test_frame.true_label != test_frame.predicted]).head()\nno_cancer=incorrect_preds.nlargest(3, columns='no_cancer')\nno_cancer","2bde925b":"cancer=(incorrect_preds.nlargest(3, columns='cancer'))[(incorrect_preds.true_label==0)]\ncancer_list=cancer['id'].values.tolist()\ncancer","5e303571":"## plot the \"most incorrect\" images\n\nf,ax = plt.subplots(1,2,figsize=(15,15))\n\nfor i in range(len(cancer)):\n    img = plt.imread(cancer.iloc[i]['Path'])\n    ax[i].imshow(img)\n    ax[i].set_title(cancer.iloc[i]['true_label'],fontweight=\"bold\", size=20)  \n    \nplt.show() \n\nf,ax = plt.subplots(1,2,figsize=(15,15))\n\nfor i in range(2):\n    img = plt.imread(no_cancer.iloc[i]['Path'])\n    ax[i].imshow(img)\n    ax[i].set_title(no_cancer.iloc[i]['true_label'],fontweight=\"bold\", size=20)  \n","64676f16":"## look at the \"most correct\" submission\nno_cancer_true=test_frame.nlargest(3, columns='no_cancer')\ncancer_true=test_frame.nlargest(3, columns='cancer')\nno_cancer_true.head()","f56a877f":"cancer_true.head()","a185c203":"## plot the \"most incorrect\" images\n\nf,ax = plt.subplots(1,3,figsize=(15,15))\n\nfor i in range(3):\n    img = plt.imread(cancer_true.iloc[i]['Path'])\n    ax[i].imshow(img)\n    ax[i].set_title(cancer_true.iloc[i]['true_label'],fontweight=\"bold\", size=20)  \n    \nplt.show() \n\nf,ax = plt.subplots(1,3,figsize=(15,15))\n\nfor i in range(3):\n    img = plt.imread(no_cancer_true.iloc[i]['Path'])\n    ax[i].imshow(img)\n    ax[i].set_title(no_cancer_true.iloc[i]['true_label'],fontweight=\"bold\", size=20)  \n","c005b912":"test_results=pd.DataFrame({'id':os.listdir(\"..\/input\/test\/\")})\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\n\nsubmit_generator=datagen.flow_from_dataframe(\ndataframe=test_results,\ndirectory=\"..\/input\/test\/\",\nx_col=\"id\",\nbatch_size=2,   # want to divide num samples evenly \nshuffle=False,  # don't shuffle\nclass_mode=None,\ntarget_size=image_size)","7298b662":"## use 0.5 as threshold to assign to class 0 or 1 \ny_test_prob=model.predict_generator(submit_generator,verbose=1,steps=submit_generator.n\/2)\ny_test_pred=np.argmax(y_test_prob, axis=-1)  #y_test_prob.round()","5dcb4f16":"results = pd.DataFrame({'id':(submit_generator.filenames)})\n\ndef remove_ext(id):\n    return (id.split('.'))[0]\nresults['id']=results['id'].apply(remove_ext)","0fd60089":"results['label'] = y_test_pred\nresults.to_csv(\"submission.csv\",index=False)\nresults.head()","9dc13154":"thank you to @fmarazzi for CNN architecture:\nhttps:\/\/www.kaggle.com\/fmarazzi\/baseline-keras-cnn-roc-fast-5min-0-8253-lb\n","a3f10736":"Generate perdictions for submission","7ce9480a":"**Reference Material:**\n\nI found the following kernels and resources very helpful as I worked through my first Kaggle entry! Thank you!\n\nhttps:\/\/www.kaggle.com\/vbookshelf\/cnn-how-to-use-160-000-images-without-crashing <br>\nhttps:\/\/www.kaggle.com\/fmarazzi\/baseline-keras-cnn-roc-fast-10min-0-925-lb <br>\n (more to come)\n"}}