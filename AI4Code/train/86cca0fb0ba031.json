{"cell_type":{"71432ed0":"code","992baa15":"code","5471cd58":"code","99694c80":"code","2c982c04":"code","dbb3fb72":"code","56d8260b":"code","51f140f6":"code","eb6035ac":"code","dea10491":"code","4cb3ac6a":"code","ee4f6c39":"code","bfeb3ddc":"code","c54de595":"code","cd2f2ec5":"code","7dfd3f85":"code","f99f3692":"code","e31ea014":"code","e6bc6333":"code","0cc490e4":"code","84afed82":"code","75ccc9b4":"code","11d78a17":"code","1be2a8c6":"code","1adb68ef":"code","78cc2782":"code","100590b9":"code","d1634aeb":"code","2c8debc0":"markdown","b28b368e":"markdown","81979784":"markdown","149556bf":"markdown","925317ac":"markdown","7259e262":"markdown","1c6666ea":"markdown","3b15c8e9":"markdown","7cae98f9":"markdown","c00f9472":"markdown","19753cfc":"markdown","3cc6ba3b":"markdown","d3cf9740":"markdown","72c7dd42":"markdown"},"source":{"71432ed0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","992baa15":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nimport string\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.utils as ku \nimport tensorflow as tf","5471cd58":"train_path=\"\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\"\ntest_path=\"\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv\"\n\ntrain_data = pd.read_csv(train_path, encoding='latin_1')\ntest_data = pd.read_csv(test_path, encoding='latin_1')","99694c80":"train_data.head(1)","2c982c04":"# Check the columns and the types\ntrain_data.info()","dbb3fb72":"# Check the size of the dataset\ntrain_data.shape","56d8260b":"#Check the null values\ntrain_data.isna().sum()","51f140f6":"train_data = train_data[['OriginalTweet', 'Sentiment']]\ntrain_data.head()","eb6035ac":"# categories of sentiments\nnp.unique(train_data['Sentiment'])","dea10491":"sns.countplot(y='Sentiment', data=train_data)\nplt.title(\"Number of Sentiments in train data\")","4cb3ac6a":"sns.countplot(y='Sentiment', data=test_data)\nplt.title(\"Number of Sentiments in test data\")","ee4f6c39":"# Sentiments in train data\nlabels=['Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', 'Positive']\nsizes = [\n         train_data[train_data['Sentiment'] == 'Extremely Negative'].shape[0], \n         train_data[train_data['Sentiment'] == 'Extremely Positive'].shape[0],\n         train_data[train_data['Sentiment'] == 'Negative'].shape[0], \n         train_data[train_data['Sentiment'] == 'Neutral'].shape[0],\n         train_data[train_data['Sentiment'] == 'Positive'].shape[0]\n        ]\nplt.pie(sizes,labels=labels, data=train_data, autopct='%1.2f%%', shadow=True, startangle=90)\nplt.title(\"Sentiments percentages in train data\")\nplt.axis(\"equal\")","bfeb3ddc":"# Sentiments in train data\nlabels=['Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', 'Positive']\nsizes = [\n         test_data[test_data['Sentiment'] == 'Extremely Negative'].shape[0], \n         test_data[test_data['Sentiment'] == 'Extremely Positive'].shape[0],\n         test_data[test_data['Sentiment'] == 'Negative'].shape[0], \n         test_data[test_data['Sentiment'] == 'Neutral'].shape[0],\n         test_data[test_data['Sentiment'] == 'Positive'].shape[0]\n        ]\nplt.pie(sizes,labels=labels, data=test_data, autopct='%1.2f%%', shadow=True, startangle=90)\nplt.title(\"Sentiments percentages in test data\")\nplt.axis(\"equal\")","c54de595":"pd.set_option('display.max_colwidth', -1)","cd2f2ec5":"stop_words = stopwords.words(\"english\")","7dfd3f85":"# clean unwanted text like stopwords, @(Mention), https(url), #(Hashtag), punctuations\ndef removeUnwantedText(text):\n    #remove urls\n    text = re.sub(r'http\\S+', \" \", text)\n    \n    #remove mentions\n    text = re.sub(r'@\\w+',' ',text)\n    \n    #remove hastags\n    text = re.sub(r'#\\w+', ' ', text)\n    \n    #remove html tags\n    text = re.sub('r<.*?>',' ', text)\n    \n     #remove stop words \n    text = text.split()\n    text = \" \".join([word for word in text if not word in stop_words])\n    \n    for punctuation in string.punctuation:\n        text = text.replace(punctuation, \"\")\n    \n    return text","f99f3692":"train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(lambda x: removeUnwantedText(x))\ntest_data['OriginalTweet'] = test_data['OriginalTweet'].apply(lambda x: removeUnwantedText(x))","e31ea014":"# For sentiments, as these are categories, so lets do LabelEncoding for this\nlabel_encoder = LabelEncoder()\ntrain_data['Encoded_Sentiment'] = label_encoder.fit_transform(train_data['Sentiment'])\ntest_data['Encoded_Sentiment'] = label_encoder.fit_transform(test_data['Sentiment'])","e6bc6333":"train_data.head()","0cc490e4":"x_train = train_data['OriginalTweet']\ny_train = train_data['Encoded_Sentiment']\n\nx_test = test_data['OriginalTweet']\ny_test = test_data['Encoded_Sentiment']","84afed82":"train_sequence_length = np.max(x_train.apply(lambda x: len(x)))\ntest_sequence_length = np.max(x_test.apply(lambda x: len(x)))","75ccc9b4":"# Which sentence is having maximum length\nmax_sequence_len = train_sequence_length\nif test_sequence_length > train_sequence_length:\n    max_sequence_len = test_sequence_length\nmax_sequence_len","11d78a17":"train_tokenizer = Tokenizer()\n\ntrain_tokenizer.fit_on_texts(x_train) # Assign number to text\ntotal_words = len(train_tokenizer.word_index) + 1\n\n# create input sequences using list of tokens\ntrain_tokens = train_tokenizer.texts_to_sequences(x_train)\n\n#Make all text of same length\ntrain_input_sequences = pad_sequences(train_tokens, maxlen=max_sequence_len, padding='pre')","1be2a8c6":"test_tokenizer = Tokenizer()\n\ntest_tokenizer.fit_on_texts(x_test) # Assign number to text\n\n# create input sequences using list of tokens\ntest_tokens = test_tokenizer.texts_to_sequences(x_test)\n\n#Make all text of same length\ntest_input_sequences = pad_sequences(test_tokens, maxlen=max_sequence_len, padding='pre')","1adb68ef":"# As we have 5 different sentiments\ntrain_labels = ku.to_categorical(y_train, 5)\ntest_labels = ku.to_categorical(y_test, 5)","78cc2782":"model = tf.keras.Sequential([\n    Embedding(total_words, 16, input_length=max_sequence_len),\n    Bidirectional(LSTM(256, return_sequences=True)),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    Dense(64, activation='relu'),\n    Dense(5, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","100590b9":"history = model.fit(train_input_sequences, train_labels, epochs=20, verbose=1, \n                    validation_data=(test_input_sequences, test_labels))","d1634aeb":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","2c8debc0":"**4. Percentage of sentiments appearance**","b28b368e":"**5. Remove unwanted text**","81979784":"**Different Sentiments with values**\n1. Extremely Negative --> 0 \n2. Extremely Postive --> 1\n3. Negative --> 2\n4. Neutral --> 3\n5. Positive --> 4","149556bf":"**Import necessary libraries**","925317ac":"**8. Model creation**","7259e262":"**1. Go through the data - shape, columns, values, different labels**","1c6666ea":"**3. Get only desired columns**","3b15c8e9":"**Observation:** The sentiments are divided into 5 categories: 'Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', and 'Positive'","7cae98f9":"**7. Preprocess the data**","c00f9472":"**2. Handle missing values**","19753cfc":"**Let us handle original tweets part**","3cc6ba3b":"**Observation:** we can see that here \"Location\" field is having null value, but we only need \"OrginalTweet\" and \"Sentiment\" column for this, rest features doesn't make any difference.","d3cf9740":"**Observation:** Most of the tweets are positive app. 27.75% followed by Negative sentiments 24.10%","72c7dd42":"**6. As machine learning models only understands numeric, so do transformations**"}}