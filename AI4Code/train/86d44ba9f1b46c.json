{"cell_type":{"0aaa727e":"code","5372cca9":"code","affa043c":"code","ed5145a9":"code","e5aaa58a":"code","85172d99":"code","334bb934":"code","c7604717":"code","74309504":"code","7d22d029":"code","82247229":"code","a0a9c41d":"code","c6683c48":"code","6547e426":"code","e1446ace":"code","85649d94":"code","78d8d6bb":"code","bf0f041c":"code","cbf731df":"code","825c1259":"code","04a8d297":"code","1607793f":"code","56b86770":"code","4f720200":"code","fecf5fad":"code","e2a9d2a2":"code","3075de33":"code","8cd7502b":"code","9a262a4d":"code","a0fc2332":"code","59596fac":"code","76855090":"code","b0712e55":"code","fc7bb475":"code","fe6b4145":"code","85cd7ce8":"code","3af906e5":"code","26268c4f":"code","208d5550":"code","29accdd4":"code","f42f0c91":"code","0f72cb8b":"code","eb567be8":"markdown","f1b259d0":"markdown","cf2ff427":"markdown","7b1e1ec9":"markdown","1a51ce02":"markdown","98d9ee9c":"markdown","c8f9f28e":"markdown","9349d5ff":"markdown","db3f5ad7":"markdown","cbf3eecc":"markdown","60fc3bdb":"markdown","1bdb2e4a":"markdown","95dff6bd":"markdown","4a8e70d8":"markdown","aefe43fe":"markdown","9f632531":"markdown","ce086ffc":"markdown","4a1abd62":"markdown","73fdf833":"markdown","99f3cf73":"markdown","b0deac94":"markdown","8453d2f6":"markdown","8075659a":"markdown","ba3a7939":"markdown","bfb2d39a":"markdown","5ef88b67":"markdown","6ba2dcc5":"markdown","066e2b71":"markdown","e0ce2deb":"markdown","9fff38c6":"markdown","5e342151":"markdown","030abf02":"markdown","1802a5bd":"markdown"},"source":{"0aaa727e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5372cca9":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n!pip install impyute","affa043c":"data = pd.read_csv('..\/input\/song-popularity-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/song-popularity-prediction\/test.csv')","ed5145a9":"data_original = data.copy()\ntest_original = test.copy()","e5aaa58a":"data.head(10)","85172d99":"test.head()","334bb934":"test.shape","c7604717":"data.columns","74309504":"test.columns","7d22d029":"data.shape","82247229":"test.shape","a0a9c41d":"data['song_popularity'].value_counts()","c6683c48":"data['song_popularity'].value_counts(normalize=True)\n\n","6547e426":"data['song_popularity'].value_counts().plot.bar()","e1446ace":"columns = [feature for feature in data.columns]\ncat_var = []\nnum_var = []\nfor i in columns:\n    if data[i].nunique()<15:\n        cat_var.append(i)\n    else:\n        num_var.append(i)","85649d94":"cat_var\n","78d8d6bb":"num_var","bf0f041c":"data['key'].value_counts(normalize=True).plot.bar(figsize=(20,10), title='key')\nplt.show()\ndata['audio_mode'].value_counts(normalize=True).plot.bar(title='audio_mode')\nplt.show()\ndata['time_signature'].value_counts(normalize=True).plot.bar(title='time_signature')\nplt.show()\n","cbf731df":"sns.distplot(data['song_duration_ms'])\nplt.show()\ndata['song_duration_ms'].plot.box(figsize = (16,5))\nplt.show()","825c1259":"data.boxplot(column = 'song_duration_ms', by='song_popularity',figsize=(16,5))\nplt.show()","04a8d297":"num_var","1607793f":"data.boxplot(column = 'energy', by='song_popularity',figsize=(16,5))\nplt.show()","56b86770":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndata.notna()\nsns.distplot(data['acousticness'])\nplt.show()\nsns.distplot(data['danceability'])\nplt.show()","4f720200":"\nsns.distplot(data['energy'])\nplt.show()\nsns.distplot(data['instrumentalness'])\nplt.show()\nsns.distplot(data['speechiness'])\nplt.show()\n\n","fecf5fad":"sns.distplot(data['loudness'])\nplt.show()\nsns.distplot(data['tempo'])\nplt.show()\nsns.distplot(data['audio_valence'])\nplt.show()\n\n\n\n","e2a9d2a2":"sns.distplot(data['liveness'])\nplt.show()","3075de33":"cat_var","8cd7502b":"audio_mode=pd.crosstab(data['audio_mode'],data['song_popularity'])\naudio_mode.div(audio_mode.sum().astype(float), axis=0).plot(kind=\"bar\",figsize=(4,4))\nplt.show()\n\n## 1 implies the song is popular and 0 implies the song is not popular\n","9a262a4d":"key=pd.crosstab(data['key'],data['song_popularity'])\ntime_signature=pd.crosstab(data['time_signature'],data['song_popularity'])\nkey.div(key.sum(1).astype(float), axis=0).plot(kind=\"bar\",figsize=(10,6))\nplt.show()\ntime_signature.div(time_signature.sum(1).astype(float), axis=0).plot(kind='bar',figsize=(10,6))\nplt.show()\n","a0fc2332":"data.groupby('song_popularity')['song_duration_ms'].mean().plot.bar()\n","59596fac":"data.describe()","76855090":"bins=[0,166254,193165,215116,491671]\ngroup=['Short_25','Average\/mean','Long_75','Very Long']\ndata['duration_bin']=pd.cut(data['song_duration_ms'],bins,labels=group)\nduration_bin=pd.crosstab(data['duration_bin'],data['song_popularity'])\nduration_bin.div(duration_bin.sum(1).astype(float), axis=0).plot(kind='bar')\nplt.xlabel('song_duration_ms')\nP=plt.ylabel('percentage')","b0712e55":"bins=[0,0.424760,0.570951,0.718464,0.957131]\ngroup=['very less','Average\/mean','good','highest']\ndata['dance_bin']=pd.cut(data['danceability'],bins,labels=group)\ndance_bin=pd.crosstab(data['dance_bin'],data['song_popularity'])\ndance_bin.div(dance_bin.sum(1).astype(float), axis=0).plot(kind='bar')\nplt.xlabel('danceability')\nP=plt.ylabel('percentage')","fc7bb475":"bins=[0,0.539276,0.683932,0.870503,1.039741]\ngroup=['very less','Average\/mean','good','highest']\ndata['energy_bin']=pd.cut(data['energy'],bins,labels=group)\nenergy_bin=pd.crosstab(data['energy_bin'],data['song_popularity'])\nenergy_bin.div(dance_bin.sum(1).astype(float), axis=0).plot(kind='bar')\nplt.xlabel('energy')\nP=plt.ylabel('percentage')","fe6b4145":"matrix = data.corr()\nf, ax = plt.subplots(figsize=(15,10))\nsns.heatmap(matrix,vmax=.8,square=True,cmap='BuPu', annot = True)","85cd7ce8":"data.isnull().sum()","3af906e5":"cat_var","26268c4f":"data['key'].value_counts().sort_values()","208d5550":"data['audio_mode'].value_counts(normalize=True)","29accdd4":"data['time_signature'].value_counts(normalize=True).sort_values()","f42f0c91":"X = data.drop(['duration_bin','energy_bin','dance_bin','song_popularity'],axis=1)\ny=data['song_popularity']","0f72cb8b":"import sklearn\nfrom sklearn.impute import KNNImputer\n","eb567be8":"For numerical variables: imputation using KNNimputer and Iterative Imputer\n\nFor categorical variables: imputation using Mode","f1b259d0":"# Independent variable ( Numerical )","cf2ff427":"![Screenshot 2022-01-22 at 12.34.22 AM.png](attachment:0d08c01b-a8fc-4727-89d6-ee6eb175ad93.png)","7b1e1ec9":"the songs which have ```energy``` between 25 percentile and mean are more popular than the rest!","1a51ce02":"### Observations:\n\n* There are total of ```15``` columns : ```10``` continous , ```3``` categorical ```1``` id and ```1``` target column\n* ```song_popularity column``` is the target variable which is only available in the ```train``` dataset.\n* Train dataset contain ```527,813``` observation with ```32,178```  missing values.\n* 8 different rows have null values with maximum missings values in ```song_duration_ms``` column.","98d9ee9c":"the features ```time_signature``` and ```key``` have more values for song not-being-popular for almost all the keys and time signatures.\n\n##### nothing is really coming up from the data!!","c8f9f28e":"```audio_mode``` doesn't provide us very good insight","9349d5ff":"cv: int, cross-validation generator or an iterable, default=None\n\n    Determines the cross-validation splitting strategy. Possible inputs for cv are:\n\n        None, to use the default 5-fold cross validation,\n\n        int, to specify the number of folds in a (Stratified)KFold,\n\n        CV splitter,\n\n        An iterable that generates (train, test) splits as arrays of indices.\n\nbelow : cv =5, implies stratified Kfold is happening","db3f5ad7":"X_knn_imputed.loc[:, :] = knn_imp.fit_transform(X_knn_imputed)","cbf3eecc":"# PLEASE UPVOTE IF YOU FIND THIS NOTEBOOK HELPFUL !","60fc3bdb":"from sklearn.ensemble import ExtraTreesRegressor, RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\n\n# Set global configs\ncv = 5\nscoring = \"roc_auc\"\nstate = 1121218\nforest = RandomForestClassifier()\n\n        \n# Store KNN scores\nknn_scores = pd.DataFrame()\nn_neighbors = [2, 3, 5, 7, 9]\nfor k in n_neighbors:\n    pipe = make_pipeline(KNNImputer(n_neighbors=k), forest)\n    knn_scores[f\"KNN(k = {k})\"] = cross_val_score(\n        pipe, X, y, scoring=scoring, cv=cv\n    )\n\n\n# Plot\nfig, ax = plt.subplots(figsize=(14, 8))\n\nmeans, errors = knn_scores.mean().sort_values(ascending=False), knn_scores.std()\nmeans.plot.barh(xerr=errors, ax=ax)\n\nax.set_title(\"Diabetes Dataset Classification With Different Imputation Methods\")\nax.set_xlabel(\"roc_auc\")\nax.set_yticks(np.arange(means.shape[0]))\n\nplt.tight_layout(pad=1)\nplt.show();","1bdb2e4a":"![Screenshot 2022-01-22 at 12.34.33 AM.png](attachment:fcf345df-d1d7-4161-8ac0-35e33dc86dff.png)","95dff6bd":"knn_imp = KNNImputer(n_neighbors=2)\nX_knn_imputed = X.copy(deep=True)","4a8e70d8":"most of the ```time_signature``` has value as ```3```.\n\nmost of the songs have their ```audio_mode``` as ```0```.\n\nthe top 3 ```key``` are ```0,6``` and ```10```.","aefe43fe":"we can see that there are both ```popular``` and ```unpopular``` songs with very high ```song_duration_ms```, which appear to be the outliers here.","9f632531":"# Reading data","ce086ffc":"the songs which have ```song_duration_ms``` between average and long most popular, around ```40%``` of the songs are popular.","4a1abd62":"# Understanding the data","73fdf833":"n_neighbors = [2,3,5,7,9]\n\nfig, ax = plt.subplots(figsize=(32, 16))\n# Plot the original distribution\nsns.kdeplot(X.song_duration_ms, label=\"Original Distribution\")\nfor k in n_neighbors:\n    knn_imp = KNNImputer(n_neighbors=k)\n    X_knn_imputed.loc[:, :] = knn_imp.fit_transform(X)\n    sns.kdeplot(X_knn_imputed.song_duration_ms, label=f\"Imputed Dist with k={k}\")\n\nplt.legend();","99f3cf73":"# PLEASE UPVOTE IF YOU FIND THIS NOTEBOOK HELPFUL !\n","b0deac94":"# Categorical Independent Variable vs Target Variable\n","8453d2f6":"```k=2``` is the best choice here","8075659a":"We will predict the ```sing_popularity``` using the model","ba3a7939":"the songs which have very ```high danceability``` are more popular than the rest with around ```40%``` of the songs popular","bfb2d39a":"Almost ```63.56%``` of the songs are ```unpopular``` and ```36.44%``` are poular","5ef88b67":"#### song popularity 0 indicates that the song is not popular and 1 indicates that the song is popular","6ba2dcc5":"none of the features have very ```high correlation```  as none of the feature have pearson correlation greater than ```0.75```","066e2b71":"# Independent Variable (categorical)","e0ce2deb":"# Missing value imputation\n","9fff38c6":"we can see the feature ```song_duration_ms``` contains a lot of outliers","5e342151":"# Numerical Independent Variable vs Target Variable\n","030abf02":"we will try to find the relation between the categorical and target variable","1802a5bd":"knn_scores.mean().sort_values(ascending=False)"}}