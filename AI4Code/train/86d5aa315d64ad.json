{"cell_type":{"a9ef1bbe":"code","e1f66d68":"code","d972a22f":"code","a60a829c":"code","d4254ab4":"code","1fb44b00":"code","6266d799":"code","b78db469":"code","de3e6f9c":"code","bfaf61fa":"code","925b8a62":"code","c6e4b2a0":"code","e0679f0b":"code","0f1697c8":"code","96a179a2":"code","59066fd2":"code","32462f36":"code","a051ede2":"code","d6792fb7":"markdown","4d0e89a8":"markdown","b4d667af":"markdown","12719d58":"markdown","a2135a60":"markdown"},"source":{"a9ef1bbe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e1f66d68":"#visulization \nimport matplotlib.pyplot as plt\n#splitting\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n#feature scaling\nfrom sklearn.preprocessing import StandardScaler\n#Keras libraries and packages\nimport keras\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential \nfrom keras.layers import Dense,Activation,Embedding,Flatten, LeakyReLU,PReLU,ELU,BatchNormalization, Dropout\n#confustion matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score","d972a22f":"churn_data = pd.read_csv(\"..\/input\/churn-modelling\/Churn_Modelling.csv\")\nprint(churn_data.shape)","a60a829c":"churn_data.head(10)","d4254ab4":"#creating copy of raw data\nchurn = pd.DataFrame.copy(churn_data)","1fb44b00":"#removing unimportant features : first 3 columns\ndrop_column = [\"RowNumber\",\"CustomerId\", \"Surname\"]\nchurn.drop(drop_column, axis=1, inplace=True)","6266d799":"churn.shape","b78db469":"# creating dummy variables for Geography and Gender\ngeography = pd.get_dummies(churn[\"Geography\"],drop_first=True)\ngender = pd.get_dummies(churn[\"Gender\"],drop_first=True)","de3e6f9c":"# combining to in 'x' dataframe\nchurn = pd.concat([churn,geography,gender], axis=1)\nprint(churn.info())","bfaf61fa":"# now drop original geography & gender columns\ndrop_geo_gen = [\"Geography\",\"Gender\"]\nchurn.drop(drop_geo_gen, axis=1, inplace=True)","925b8a62":"# defining X and Y\nx = pd.DataFrame.copy(churn)\nx = x.drop([\"Exited\"],axis=1)\ny = pd.DataFrame.copy(churn[\"Exited\"])","c6e4b2a0":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)","e0679f0b":"# feature scaling\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","0f1697c8":"# creating custom functon for iterations to tune hyper parameters\ndef create_model(layers, activation):\n    model = Sequential()\n    for i, nodes in enumerate(layers):\n        if i==0:\n            model.add(Dense(nodes,input_dim=x_train.shape[1]))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n        else:\n            model.add(Dense(nodes))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n            \n    model.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid')) # Note: no activation beyond this point\n    \n    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n    return model\n    \nmodel = KerasClassifier(build_fn=create_model, verbose=0)\n\n\nlayers = [[20], [40, 20], [45, 30, 15]]\nactivations = ['sigmoid', 'relu']\nparam_grid = dict(layers=layers, activation=activations, batch_size = [128, 256], epochs=[30])\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n\ngrid_result = grid.fit(x_train, y_train)\n\nprint(grid_result.best_score_,grid_result.best_params_)","96a179a2":"#predicting test set\ny_pred = grid.predict(x_test)\ny_pred = (y_pred>0.5)","59066fd2":"#confusion matrix\ncm = confusion_matrix(y_test,y_pred)\ncm","32462f36":"# accuracy score of test data\nscore = accuracy_score(y_pred,y_test) \nscore","a051ede2":"# Make a prediction using the Random Forest on the wanted columns\npredictions = grid.predict(x_test)\n\n# Our predictions array is comprised of 0's and 1's (Dead or Survived)\npredictions[:20]","d6792fb7":"# Submission ","4d0e89a8":"# Loading dataset","b4d667af":"# Splitting train and test","12719d58":"# Evaluting model","a2135a60":"# Building model "}}