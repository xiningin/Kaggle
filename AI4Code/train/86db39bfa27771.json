{"cell_type":{"cb16fa9c":"code","fa157eda":"code","f1465f98":"code","aa1a097f":"code","94c7fb32":"code","628984c6":"code","fbc9c485":"code","f041e384":"code","f94d9e2c":"markdown","1011fc78":"markdown","a80179d2":"markdown","3b433159":"markdown","0d9a0ba4":"markdown","362cc0bb":"markdown","f137b732":"markdown","eb957137":"markdown","efe285ca":"markdown","ac7c59d0":"markdown","b3ad5362":"markdown"},"source":{"cb16fa9c":"# These are the models from the original code of Alex Lekv\n\n#kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# build our model scoring function\n#def cv_rmse(model):\n#    rmse = np.sqrt(-cross_val_score(model, X, y,\n                                    scoring=\"neg_mean_squared_error\",\n                                    cv=kfolds))\n#    return rmse\n\n\n# setup models    \n#alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n#alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n#e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n#e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n\n#ridge = make_pipeline(RobustScaler(),\n#                      RidgeCV(alphas=alphas_alt, cv=kfolds))\n\n#lasso = make_pipeline(RobustScaler(),\n#                      LassoCV(max_iter=1e7, alphas=alphas2,\n#                              random_state=42, cv=kfolds))\n\n#elasticnet = make_pipeline(RobustScaler(),\n#                           ElasticNetCV(max_iter=1e7, alphas=e_alphas,\n#                                        cv=kfolds, l1_ratio=e_l1ratio))\n\n#svr = make_pipeline(RobustScaler(),\n#                    SVR(C=20, epsilon=0.008, gamma=0.0003, ))\n\n\n#gbr = GradientBoostingRegressor(learning_rate=0.05,\n#                                n_estimators=3000,\n#                                max_depth=4, max_features='sqrt',\n#                                min_samples_leaf=15, min_samples_split=10,\n#                                loss='huber', random_state=42)\n\n\n#lightgbm = LGBMRegressor(objective='regression',\n#                         num_leaves=4,\n#                         learning_rate=0.01,\n#                         n_estimators=5000,\n#                         max_bin=200,\n#                         bagging_fraction=0.75,\n#                         bagging_freq=5,\n#                         bagging_seed=7,\n#                         feature_fraction=0.2,\n#                         feature_fraction_seed=7,\n#                         verbose=-1,\n                         # min_data_in_leaf=2,\n                         # min_sum_hessian_in_leaf=11\n#                         )\n\n\n#xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n#                       max_depth=3, min_child_weight=0,\n#                       gamma=0, subsample=0.7,\n#                       colsample_bytree=0.7,\n#                       objective='reg:squarederror', nthread=-1,\n#                       scale_pos_weight=1, seed=27,\n#                       reg_alpha=0.00006,\n#                       random_state=42)\n\n\n#cb = CatBoostRegressor(iterations=2000,\n#                             learning_rate=0.01,\n#                             depth=12,\n#                             loss_function='RMSE',\n#                             random_seed = 42,\n#                             bagging_temperature = 0.2,\n#                             metric_period = 100,\n#                             verbose=0)\n\n\n# stack\n#stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet,\n#                                            gbr, lightgbm, xgboost),\n#                                            meta_regressor=xgboost,\n#                                            use_features_in_secondary=True, random_state=42)\n","fa157eda":"# The original function to blend models with different weight for each model\n# In all notebooks I have found the blending weights are quite similar...The best?\n\n#def blend_models_predict(X=X):\n#    return ((0.1* elastic_model_full_data.predict(X)) + \n#            (0.1 * lasso_model_full_data.predict(X)) + \n#            (0.05 * ridge_model_full_data.predict(X)) + \n#            (0.1 * svr_model_full_data.predict(X)) + \n#            (0.1 * gbr_model_full_data.predict(X)) + \n#            (0.15 * xgb_model_full_data.predict(X)) + \n#            (0.1 * lgb_model_full_data.predict(X)) + \n#            (0.3 * stack_gen_model.predict(np.array(X))))\n","f1465f98":"# My modified blend function without LGBMRegressor, adding Random Forest and CatBoost\n\n#def blend_models_predict(X, arr):\n#    return ((arr[0] * elastic_model_full_data.predict(X)) + \n#            (arr[1] * lasso_model_full_data.predict(X)) + \n#            (arr[2] * ridge_model_full_data.predict(X)) + \n#            (arr[3] * svr_model_full_data.predict(X)) + \n#            (arr[4] * gbr_model_full_data.predict(X)) + \n#            (arr[5] * rf_model_full_data.predict(X)) + \n#            (arr[6] * xgb_model_full_data.predict(X)) + \n#            (arr[7] * cb_model_full_data.predict(X)) + \n#            (arr[8] * stack_gen_model.predict(np.array(X))))\n","aa1a097f":"#def rd_model(fname):\n#    return pickle.load(open(fname, 'rb'))\n\n#def wr_model(model, fname):\n#    pickle.dump(model, open(fname, 'wb'))\n\n# Save Models for later use, without running everything from beginning\n#nf=\"Test34\"\n\n#wr_model(X, '.\/input\/'+nf+'X.sav')\n#wr_model(y, '.\/input\/'+nf+'y.sav')\n#wr_model(X_sub, '.\/input\/'+nf+'X_sub.sav')\n\n#wr_model(stack_gen_model, '.\/input\/'+nf+'stack.sav')\n#wr_model(elastic_model_full_data, '.\/input\/'+nf+'elastic.sav')\n#wr_model(lasso_model_full_data, '.\/input\/'+nf+'lasso.sav')\n#wr_model(ridge_model_full_data, '.\/input\/'+nf+'ridge.sav')\n#wr_model(svr_model_full_data, '.\/input\/'+nf+'svr.sav')\n#wr_model(gbr_model_full_data, '.\/input\/'+nf+'gbr.sav')\n#wr_model(rf_model_full_data, '.\/input\/'+nf+'rf.sav')\n#wr_model(xgb_model_full_data, '.\/input\/'+nf+'xgb.sav')\n#wr_model(cb_model_full_data, '.\/input\/'+nf+'cb.sav')\n\n\n# Read previously saved models \n#nf=\"Test33\"\n\n#X = rd_model('.\/input\/'+nf+'X.sav')\n#y = rd_model('.\/input\/'+nf+'y.sav')\n#X_sub = rd_model('.\/input\/'+nf+'X_sub.sav')\n\n#stack_gen_model = rd_model('.\/input\/'+nf+'stack.sav')\n#elastic_model_full_data = rd_model('.\/input\/'+nf+'elastic.sav')\n#lasso_model_full_data = rd_model('.\/input\/'+nf+'lasso.sav')\n#ridge_model_full_data = rd_model('.\/input\/'+nf+'ridge.sav')\n#svr_model_full_data = rd_model('.\/input\/'+nf+'svr.sav')\n#gbr_model_full_data = rd_model('.\/input\/'+nf+'gbr.sav')\n#rf_model_full_data = rd_model('.\/input\/'+nf+'rf.sav')\n#xgb_model_full_data = rd_model('.\/input\/'+nf+'xgb.sav')\n#cb_model_full_data = rd_model('.\/input\/'+nf+'cb.sav')\n","94c7fb32":"# The following lines are the first examples submitted where you can see how the final score change ONLY modifying the weights\n# MAE Mean Absolute Error on training data\n# elastic,lasso,ridge,svr,gbr,xgb,lgb,stack\n#arr=[0.10,0.10,0.05,0.10,0.10,0.15,0.10,0.30] # MAE 6908  -> 12213 Original weights from Alex \n#arr=[0.10,0.10,0.05,0.10,0.15,0.10,0.05,0.35] # MAE 6567  -> 12176 \n#arr=[0.10,0.10,0.05,0.10,0.20,0.05,0.05,0.35] # MAE 6398  -> 12163 \n#arr=[0.06,0.09,0.05,0.15,0.30,0.00,0.00,0.35] # MAE 5817  -> 12127.3\n#arr=[0.08,0.10,0.03,0.14,0.30,0.00,0.00,0.35] # MAE 5854  -> 12125.2\n","628984c6":"#def rmsle(y, y_pred):\n#    return np.sqrt(mean_squared_error(y_pred,y))\n\n#def print_sub(X_sub, arr):\n#    submission = pd.read_csv(\"sample_submission.csv\")\n#    submission.iloc[:, 1] = np.floor(np.expm1(blend_models_predict(X_sub, arr)))\n#    submission.to_csv(\"submission.csv\", index=False)\n#    print('\\nSaved submission')\n\n# RMSE is multiplied by 100 to better see differences\n# elastic,lasso,ridge,svr,gbr,rf,xgb,stack                                       RMSE compared with previous submissions\n#arr=[0.07,0.07,0.01,0.15,0.29,0.05,0.00,0.36] # MAE 5349 RMSE 4.780 -> 12092.5  9.095,0.710\n#............\n#arr=[0.09,0.09,0.01,0.15,0.30,0.01,0.00,0.35] # MAE 5569 RMSE 5.012 -> 12015.3  9.305,0.586,S0,M0\n#.......\n#arr=[0.09,0.09,0.01,0.15,0.30,0.01,0.00,0.35] # MAE 4064 RMSE 4.132 -> 11933.8  9.277,1.052,S1890,M1237\n#.........\n# Adding CatBoostRegressor and entering in 8th position\n# elastic,lasso,ridge,svr,gbr,rf,xgb,cb,stack\n#arr=[0.09,0.09,0.01,0.13,0.30,0.00,0.00,0.00,0.38] # MAE 3826 RMSE 3.927 -> 11911   9.342,1.113,S2079,M1346\n\n\n#if (round(sum(arr),2) == 1.00):\n#    print(\"Result...\")\n#    rm = rmsle(y, blend_models_predict(X, arr))*100\n#    ma = int(round(mean_absolute_error(np.expm1(y), np.floor(np.expm1(blend_models_predict(X, arr)))),0))\n#    print_sub(X_sub, arr)\n#    print('\\nMAE',ma,'RMSLE {:.3f}'.format(rm))\n#else:\n#    print(\"Error arr SUM :\",round(sum(arr),2))\n","fbc9c485":"# This is the code to compare RMSE between current submission and previous submissions\n\n#d5 = pd.read_csv('submission5.csv')    # last submission before using Alex code\n# intermediate submissions to evaluate how result is moving...\n#d6 = pd.read_csv('submission12092.csv') \n#d8 = pd.read_csv('submission12015.csv')\n\n#data = pd.read_csv('submission.csv')\n\n#rms5 = np.sqrt(mean_squared_error(np.log1p(data['SalePrice']), np.log1p(d5['SalePrice'])))*100\n#rms6 =np.sqrt(mean_squared_error(np.log1p(data['SalePrice']), np.log1p(d6['SalePrice'])))*100\n#stdf = (data['SalePrice']-d8['SalePrice']).std()\n#mae = mean_absolute_error(data['SalePrice'], d8['SalePrice'])\n\n#print('{:.3f}'.format(rms5)+','+'{:.3f}'.format(rms6)+','+'S{0:.0f}'.format(stdf)+','+'M{0:.0f}'.format(mae))\n","f041e384":"#This is the submission which give me the first position!\n#Weight are the same as before, but I use some tricks...\n#arr=[0.09,0.09,0.01,0.13,0.30,0.00,0.00,0.00,0.38] # MAE 3826 RMSLE 3.927 -> 11815.9 9.492,1.484,S3223,M1532\n","f94d9e2c":"# Model building, training and hyperparameters\n\nSame as features engineering.\nAll the model have the right selection of hyperparameters, if you try to change something you go in the wrong direction!\n\nWell this is not true for all the models.\n\nI could improve prediction in this way : \n- Changing max_depth and subsample in XGBRegressor (against the training prediction values and the original ones)\n- Add Random Forest Regressor\n- Add CatBoostRegressor (Very Slow!!!!)\n- Removing LGBMRegressor and adding Random Forest and CatBoost in the list of regressors parameter of StackingCVRegressor\n\nIt is obvious that StackingCVRegressor it is the most important model which makes the difference int the final prediction","1011fc78":"# Blend models - where I have improved my score\n\nThis is the most interesting part for me...\n\nIn all the notebooks I have read, after fitting the models with the features, there is the final prediction to submit blending the previous models in one model, which is simple the sum of each model weighted, in order that the final weight must be 1.","a80179d2":"# Features engineering\nNothing to say...\nNothing to touch...\n\nHe used all the features for a total of 331 features.\n\nI have tried to drop features without importance (using for example the features importance score of GBR and XGB) with no good results.\n\nThis features engineering is the result of hard and long work, so for my novice point of view is the maximum...","3b433159":"# Conclusion\nI am happy to have reached my real 8th position using only precious suggestions of other users and my intuitions, because I am new in this fantastic world.\nI want to thanks Kaggle Team and all the users which all gave me this opportunity to expand my knowledge.\nI hope to learn more and more, this world is immense as the universe!\n\nFederico Materi","0d9a0ba4":"![banner](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/5407\/media\/housesbanner.png)\n# Intro\nLess than one month ago Machine Learning, Deep Learning and data science in general were a black box for me.\nThen I discovered the fantastic world of Kaggle :\n Micro-courses (very well done), competitions and expecially the experiences of the users.\nUser's notebooks are everything you need to learn, practice and understand how to go ahead.\nWith the help of your notebooks, today I have reached the 1st position with a score of : 11815.94229","362cc0bb":"Wait a moment, these weights are the best ones?\n\nI changed the function so I could easily change the weights and test different values with big different results!","f137b732":"# Starting\nMy first submissions scores were around 21000, using only few important features (selected manually) and using Random Forest Regressor to predict results.\nThen I read and copy the \"Bible\" code from Alex Lekov : Stack&Blend LRs XGB LGB {House Prices K} v17 : https:\/\/www.kaggle.com\/itslek\/stack-blend-lrs-xgb-lgb-house-prices-k-v17\n\nRunning the code my score jumped to 12213, good job Alex!\n\nHow I could improve the code, so detailed and perfect?\n\nOne interesting thing I found is that this code is used from lot of users (expecially in House Price : Advance Regression Techniques Competition), with detailed explanation of features engineering, model building and hyperparameters selection.\nFeatures engineering is exactly the same, hyperparameters same for each models and so on...\nSo really I don't know who is the \"father\" if this code...\n","eb957137":"# First Results\nAs you can see in the code below the most important and peraphs strange result is the weight given to Gradient Boosting Regressor.\nIf you reduce the weight in favour of XGB for example, your score raises.\nAs I understood XGB should be better the GBR, so I believed not to increase to much GBR weight, but the scores obtained say the contrary...\nWell XGB plays a big role inside StackingCVRegressor, because is in the regressor's list and is the meta_regressor.\nI think is not necessary also in the blending process.\nAnother surprise is LGBMRegressor, his presence is not necessary at all.\nElastic, Lasso are necessary with roughly the same weight and Svr is more weighted than the first two, while ridge must be present but with very low weight.","efe285ca":"# Reaching the Top Ten\nIn the code below you can see better scores after adding Random Forest and later CatBoost.\nI could not submit each test, so I added to the previous MAE also RMSE (Root Mean Square) on training data to see how changing in MAE and RMSE were related to the final score.\nThese give you a little help, but they are too much correlated to the training data, so if MAE and RMSE go down does not mean that for sure the score will be reduced.\nSo I add also a RMSE comparison between different submissions with different score, so you can have a feeling if you are going in the right direction.\n\nUsing Random Forest and CatBoost only inside StackingCVRegressor I have reached the score of 11911.03292 - 8th position.","ac7c59d0":"# First position\nOnce I have reached the 8th position, I run all the code in the \"House Price : Advanced Regression Techniques\" competition.\nMy score was 0.11497 around 300-400 position.\nWhy?\nTrain and Test models are the same, change only the score metric.\nI tried the original code and obtain same result around 0.114...\nMost of the submissions are based on my original code, as I explained before...\nUnfortunately I found the solution which is a trick...\nIn the House Price : Advanced Regression Techniques competition lot of users, expecially top users - hope not everybody) use this trick :\n- Download some top submissions score from users public notebooks\n- Blend these submissions with your submissions making some adjustments\n- Blend the result submission with the top submission you have giving to your submission more weight\nResult : my score jumped from  0.11497 to 0.10329 - 14th position!\n\nI got this my best submission and blend with my real 11911 score - 8th position in this competition and....\n\nScore 11815.94229 - 1st Position\n","b3ad5362":"Now to easily test the blended model, first I saved all the models already fitted, so I could retrieve the models without running all the process again and also to save modifications made on the models."}}