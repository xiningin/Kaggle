{"cell_type":{"9c4d6951":"code","986b8751":"code","c45422d2":"code","c228dc9b":"code","7172be3e":"code","b97c39f7":"code","af70ba36":"code","41e9e002":"code","388d19c1":"code","48396ebf":"markdown","c1402840":"markdown","7b641a71":"markdown"},"source":{"9c4d6951":"#bring in data\nimport numpy as np\nfrom xgboost import XGBClassifier\n\nimport pandas as pd\nraw_training = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv\")\nraw_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv\")","986b8751":"#show data\ndisplay(raw_training.head())","c45422d2":"#pull out features and show\nX = raw_training.iloc[:, 1:76]\n\ndisplay(X.head())","c228dc9b":"#pull out responses and show\ny = raw_training.iloc[:, 76]\n\ndisplay(y.head())","7172be3e":"#best model is pasted below\nmodel = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.25, eta=0.1,\n              eval_metric='logloss', gamma=0, gpu_id=0, importance_type='gain',\n              interaction_constraints='', learning_rate=0.100000001,\n              max_delta_step=0, max_depth=9, min_child_weight=100, \n              monotone_constraints='()', n_estimators=100, n_jobs=2,\n              num_class=9, num_parallel_tree=1, objective='multi:softprob',\n              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=0.75, tree_method='gpu_hist', validate_parameters=1,\n              verbosity=None)","b97c39f7":"#fit best model\nmodel.fit(np.ascontiguousarray(X), np.ascontiguousarray(y))","af70ba36":"#grab test features\nX_test = raw_test.iloc[:,1:76]","41e9e002":"#predict probabilities on test data\ntest_pred = model.predict_proba(np.ascontiguousarray(X_test))\n\ntest_pred = pd.DataFrame(test_pred)","388d19c1":"#prepare output and save\noutput = pd.DataFrame(raw_test.iloc[:,0])\n\noutput = output.merge(test_pred, left_index = True, right_index = True)\n\noutput.columns = [\"id\", \"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\", \"Class_5\", \"Class_6\", \"Class_7\", \"Class_8\", \"Class_9\"]\n\noutput.to_csv('submission.csv', index=False)","48396ebf":"from xgboost import XGBClassifier\n\nxgbc = XGBClassifier(eval_metric = \"logloss\", objective = \"multi:softmax\", num_class = 9, tree_method = \"gpu_hist\")\n\nxgb_pars = {\n    \"max_depth\" : [9, 12],\n    \"min_child_weight\" : [100, 1000],\n    \"subsample\" : [.25, .5, .75],\n    \"colsample_bytree\" : [.25, .5, .75],\n    \"eta\" : [.1, .05, .01],\n}\n\nxgbc_gs = GridSearchCV(xgbc, param_grid = xgb_pars, cv = 2, scoring = \"neg_log_loss\")\n\nxgbc_gs.fit(np.ascontiguousarray(X), np.ascontiguousarray(y))\n\ndisplay(xgbc_gs.best_estimator_)\n\ndisplay(xgbc_gs.best_score_)\n\nXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.25, eta=0.1,\n              eval_metric='logloss', gamma=0, gpu_id=0, importance_type='gain',\n              interaction_constraints='', learning_rate=0.100000001,\n              max_delta_step=0, max_depth=9, min_child_weight=100, missing=nan,\n              monotone_constraints='()', n_estimators=100, n_jobs=2,\n              num_class=9, num_parallel_tree=1, objective='multi:softprob',\n              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=0.75, tree_method='gpu_hist', validate_parameters=1,\n              verbosity=None)\n\n-1.7486742511149402","c1402840":"This appraoch uses XGBClassifier and GridSearchCV to find a tuned model. GPU use is recommended.","7b641a71":"The snippet below is the grid search I used to find the tuned model.\n\ntree_method='gpu_hist' allows use of GPU from Kaggle. It is needed since we are training\/validating 200+ times.\n\ncv = 2 since the data is very large."}}