{"cell_type":{"bb3a20c0":"code","ca005d53":"code","d71aa755":"code","666d1703":"code","a4f62007":"code","3c611518":"code","002cbffb":"code","f8223c66":"code","9ef15d22":"code","60d27be6":"code","74128650":"code","af1e2c64":"code","ca924eae":"code","2e8f4164":"code","68b8b2f5":"code","1fed15e0":"code","66039e03":"markdown","8e5c54cf":"markdown","9c4c409f":"markdown","9d03500e":"markdown","b2356b6d":"markdown"},"source":{"bb3a20c0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\nque = pd.read_csv('..\/input\/questions.csv')\nans = pd.read_csv('..\/input\/answers.csv')\npro = pd.read_csv('..\/input\/professionals.csv')","ca005d53":"que.shape,ans.shape,pro.shape","d71aa755":"que_ans = que.merge(right=ans, how='inner', left_on='questions_id', right_on='answers_question_id')\nqa_pro = que_ans.merge(right=pro, left_on='answers_author_id', right_on='professionals_id')\nqa_pro.head()\n","666d1703":"pro_title=qa_pro.groupby('professionals_id')['questions_title'].apply(lambda x: \"%a\" % ','.join(x))","a4f62007":"pro_title=pd.DataFrame( pro_title)\npro_title","3c611518":"import re\n\ndef ngrams(string, n=3):\n    string = re.sub(r'[,-.\/]|\\sBD',r'', string)\n    ngrams = zip(*[string[i:] for i in range(n)])\n    return [''.join(ngram) for ngram in ngrams]\n\nprint('All 3-grams in \"McDonalds\":')\nngrams('McDonalds')\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n!pip install sparse_dot_topn\nimport sparse_dot_topn.sparse_dot_topn as ct\n\ndef awesome_cossim_top(A, B, ntop, lower_bound=0):\n    # force A and B as a CSR matrix.\n    # If they have already been CSR, there is no overhead\n    A = A.tocsr()\n    B = B.tocsr()\n    M, _ = A.shape\n    _, N = B.shape\n \n    idx_dtype = np.int32\n \n    nnz_max = M*ntop\n \n    indptr = np.zeros(M+1, dtype=idx_dtype)\n    indices = np.zeros(nnz_max, dtype=idx_dtype)\n    data = np.zeros(nnz_max, dtype=A.dtype)\n\n    ct.sparse_dot_topn(\n        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n        np.asarray(A.indices, dtype=idx_dtype),\n        A.data,\n        np.asarray(B.indptr, dtype=idx_dtype),\n        np.asarray(B.indices, dtype=idx_dtype),\n        B.data,\n        ntop,\n        lower_bound,\n        indptr, indices, data)\n\n    return csr_matrix((data,indices,indptr),shape=(M,N))\n\n\ndef get_matches_df(sparse_matrix, name_vectorQ,name_vectorR, top=100):\n    non_zeros = sparse_matrix.nonzero()\n    \n    sparserows = non_zeros[0]\n    sparsecols = non_zeros[1]\n    \n    if top<sparsecols.size:\n        nr_matches = top\n    else:\n        nr_matchesQ = sparserows.size\n        nr_matchesR =sparsecols.size\n    \n    left_row = np.empty([nr_matchesQ], dtype=object)\n    left_side = np.empty([nr_matchesQ], dtype=object)\n    right_row =np.empty([nr_matchesQ], dtype=object)\n    right_side = np.empty([nr_matchesQ], dtype=object)\n    similairity = np.zeros(nr_matchesQ)\n    \n    for index in range(0, nr_matchesQ):\n        #print(index,sparserows[index],name_vector[sparserows[index]])\n        left_row[index] =sparserows[index]\n        right_row[index] =sparsecols[index]\n        left_side[index] = name_vectorQ[sparserows[index]]\n        right_side[index] = name_vectorR[sparsecols[index]]\n        similairity[index] = sparse_matrix.data[index]\n    \n    return pd.DataFrame({'left_nr':left_row,\n                        'left_side': left_side,\n                         'right_nr':right_row,\n                          'right_side': right_side,\n                           'similarity': similairity})\n","002cbffb":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n\n\nvectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\ntfidf_Q = vectorizer.fit_transform(qa_pro.questions_title)\ntfidf_R =vectorizer.transform(pro_title.questions_title)","f8223c66":"import time\nt1 = time.time()\nmatches = awesome_cossim_top(tfidf_Q, tfidf_R.transpose(), 10, 0.5)\nt = time.time()-t1\nprint(\"SELFTIMED:\", t)","9ef15d22":"print( matches[:10] ),matches.shape","60d27be6":"matches_df = get_matches_df(matches, qa_pro.questions_title.values,pro_title.questions_title.values ,top=1000000)\nmatches_df = matches_df[matches_df['similarity'] < 0.99999] # Remove all exact matches\nmatches_df","74128650":"matches_df['left_nr']=pd.to_numeric(matches_df['left_nr'].values)\nmatches_df.info()","af1e2c64":"ma_pro=matches_df.merge( qa_pro,left_on='left_nr',right_index=True)","ca924eae":"ma_pro['right_nr']=pd.to_numeric(ma_pro['right_nr'].values)\n","2e8f4164":"ma_pro.merge(pro_title.reset_index(),left_on='right_nr',right_index=True)","68b8b2f5":"ma_pro.merge(pro_title.reset_index(),left_on='right_nr',right_index=True)[['left_side','professionals_id_x','professionals_id_y']]","1fed15e0":"matches = awesome_cossim_top(tfidf_R, tfidf_Q.transpose(), 30, 0.5)\n\nmatches_df = get_matches_df(matches, pro_title.questions_title.values,qa_pro.questions_title.values ,top=1000000)\nmatches_df = matches_df[matches_df['similarity'] < 0.99999] # Remove all exact matches\nmatches_df","66039e03":"# what questions did professionals answer","8e5c54cf":"# match questions > professionals\nlets make the slimmest possible model\nwe just train the professions on title\n","9c4c409f":"# If i would change one thing already is\nFIND RELATED QUESTIONS and ANSWERS\n\nsince i see alto of similar and double questions, i find it obvious to create an interface where you search for similar and related questions.\nThis seems to me somehting obvious, people are asking probably ten times the same questions, and all those questions have been answered already\nSo the chance a question has been answered before is i estimate 70%","9d03500e":"# how to interpretate the results\n\nquestion 2 has 4 professiols that answered similar questions","b2356b6d":"# merge questions with answers"}}