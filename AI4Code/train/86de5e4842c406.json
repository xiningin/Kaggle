{"cell_type":{"08ca8174":"code","a9bea82c":"code","68ae4651":"code","c85682d5":"code","cc3dad2b":"code","bb55c7cb":"code","c064d1f9":"code","2a2f4043":"code","f8b647a8":"code","b29ce4c9":"code","deb00ea6":"markdown"},"source":{"08ca8174":"import pandas as pd\nimport numpy as np\nimport io\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.svm import LinearSVC","a9bea82c":"train_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\npure_df = pd.read_csv('..\/input\/november21\/train.csv')\ntest_df['chunk'] = test_df.id \/\/ 60000","68ae4651":"def postprocess_separate(submission_df, test_df=None, pure_df=None):\n    \"\"\"Update submission_df so that the predictions for the two sides of the hyperplane don't overlap.\n    \n    Parameters\n    ----------\n    submission_df : pandas DataFrame with columns 'id' and 'target'\n    test_df : the competition's test data\n    pure_df : the competition's original training data\n    \n    From https:\/\/www.kaggle.com\/ambrosm\/tpsnov21-007-postprocessing\n    \"\"\"\n    if pure_df is None: pure_df = pd.read_csv('..\/input\/november21\/train.csv')\n    if pure_df.shape != (600000, 102): raise ValueError(\"pure_df has the wrong shape\")\n    if test_df is None: test_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\n    if test_df.shape[0] != submission_df.shape[0] or test_df.shape[1] != 101: raise ValueError(\"test_df has the wrong shape\")\n\n    # Find the separating hyperplane for pure_df, step 1\n    # Use an SVM with almost no regularization\n    model1 = make_pipeline(StandardScaler(), LinearSVC(C=1e5, tol=1e-7, penalty='l2', dual=False, max_iter=2000, random_state=1))\n    model1.fit(pure_df.drop(columns=['id', 'target']), pure_df.target)\n    pure_pred = model1.predict(pure_df.drop(columns=['id', 'target']))\n    #print((pure_pred != pure_df.target).sum(), (pure_pred == pure_df.target).sum()) # 1 599999\n    # model1 is not perfect: it predicts the wrong class for 1 of 600000 samples\n\n    # Find the separating hyperplane for pure_df, step 2\n    # Fit a second SVM to a subset of the points which contains the support vectors\n    pure_pred = model1.decision_function(pure_df.drop(columns=['id', 'target']))\n    subset_df = pure_df[(pure_pred > -5) & (pure_pred < 0.9)]\n    model2 = make_pipeline(StandardScaler(), LinearSVC(C=1e5, tol=1e-7, penalty='l2', dual=False, max_iter=2000, random_state=1))\n    model2.fit(subset_df.drop(columns=['id', 'target']), subset_df.target)\n    pure_pred = model2.predict(pure_df.drop(columns=['id', 'target']))\n    #print((pure_pred != pure_df.target).sum(), (pure_pred == pure_df.target).sum()) # 0 600000\n    # model2 is perfect: it predicts the correct class for all 600000 training samples\n    \n    pure_test_pred = model2.predict(test_df.drop(columns=['id', 'target'], errors='ignore'))\n    lmax, rmin = submission_df[pure_test_pred == 0].target.max(), submission_df[pure_test_pred == 1].target.min()\n    if lmax < rmin:\n        print(\"There is no overlap. No postprocessing needed.\")\n        return\n    # There is overlap. Remove this overlap\n    submission_df.loc[pure_test_pred == 0, 'target'] -= lmax + 1\n    submission_df.loc[pure_test_pred == 1, 'target'] -= rmin - 1\n    print(submission_df[pure_test_pred == 0].target.min(), submission_df[pure_test_pred == 0].target.max(),\n          submission_df[pure_test_pred == 1].target.min(), submission_df[pure_test_pred == 1].target.max())\n","c85682d5":"# name = name of chunk as in https:\/\/www.kaggle.com\/ambrosm\/tpsnov21-012-leaderboard-probing\n# len = number of samples in this chunk (len.sum() == 540000)\n# auc = public leaderboard score of this chunk\n# diff = difference of this chunk's auc score minus the baseline of 0.74723 = area of the added triangle\n# ratio = unused\n\nprobes_l = '''name\tlen\tauc\tdiff\tratio\n10H0\t30343\t74653\t-70\t -0.00231 \n17H0\t36335\t74671\t-52\t -0.00143 \n16H0\t41892\t74720\t-3\t -0.00007 \n13H0\t36383\t74724\t1\t 0.00003 \n18H0\t23746\t74729\t6\t 0.00025 \n11H0\t20501\t74732\t9\t 0.00044 \n14H0\t25270\t74747\t24\t 0.00095 \n12H0\t40308\t74763\t40\t 0.00099 \n15H0\t25965\t74762\t39\t 0.00150 \n'''\n\nprobes_r = '''\nname\tlen\tauc\tdiff\tratio\n10H1\t29657\t74695\t-28\t -0.00094 \n11H1\t39499\t74760\t37\t 0.00094 \n12H1\t19692\t74750\t27\t 0.00137 \n13H1\t23617\t74690\t-33\t -0.00140 \n14H1\t34730\t74735\t12\t 0.00035 \n15H1\t34035\t74815\t92\t 0.00270 \n16H1\t18108\t74682\t-41\t -0.00226 \n17H1\t23665\t74694\t-29\t -0.00123 \n18H1\t36254\t74683\t-40\t -0.00110 \n'''\n\nprobes_l_df = pd.read_csv(io.StringIO(probes_l), sep='\\t')\nprobes_r_df = pd.read_csv(io.StringIO(probes_r), sep='\\t')\n","cc3dad2b":"# Left side\nl_dict = {}\nplt.figure(figsize=(10,10))\nfor row in probes_l_df.itertuples():\n    #print(row)\n    y0 = row.diff \/ 100000 * 8\n    plt.plot([0, 0.25], [y0, y0+0.75], color='r') # parallel for all points with this auc difference\n    plt.plot([0, row.len\/270000], [row.len\/270000, 0], color='g') # all points for this row.len\n    x = (row.len\/270000 - y0) \/ 4\n    y = 3 * x + y0\n    plt.scatter([x], [y], color='k')\n    #print(f\"{row.name} {y\/x:.5f} {x\/(x+y):.5f}\")\n    l_dict[int(row.name[:2])] = x\/(x+y)\n    print(f\"{row.name[:2]}: {x\/(x+y):.5f},\")\nplt.plot([0, 0.25, 1], [0, 0.75, 1], color=\"y\", lw=1) # baseline roc curve (two segments)\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\") # diagonal\nplt.gca().set_aspect('equal')\nif False:\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\nelse:\n    plt.xlim([0.0, 0.2])\n    plt.ylim([0.0, 0.2])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver operating characteristic\")\nplt.legend(loc=\"lower right\")\nplt.show()\nl_dict","bb55c7cb":"# Right side\nr_dict = {}\nplt.figure(figsize=(10,10))\nfor row in probes_r_df.itertuples():\n    y0 = row.diff \/ 100000 * 8\n    plt.plot([0.25-y0, 1-y0], [0.75, 1], color='r') # parallel for all points with this auc difference\n    plt.plot([1-row.len\/270000, 1], [1, 1-row.len\/270000], color='g') # all points for this row.len\n    #x = (row.len\/270000 - y0) \/ 4\n    #y = 3 * x + y0\n    x = (4 - 3*row.len\/270000 - y0) \/ 4\n    y = 2 - row.len\/270000 - x\n    plt.scatter([x], [y], color='k')\n    #print(f\"{row.name} {y\/x:.5f} {x\/(x+y):.5f}\")\n    r_dict[int(row.name[:2])] = (1-x)\/(row.len\/270000)\n    print(f\"{row.name[:2]}: {r_dict[int(row.name[:2])]:.5f},\")\nplt.plot([0, 0.25, 1], [0, 0.75, 1], color=\"y\", lw=1) # baseline roc curve (two segments)\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\") # diagonal\nplt.gca().set_aspect('equal')\nif False:\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\nelse:\n    plt.xlim([0.8, 1])\n    plt.ylim([0.8, 1])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver operating characteristic\")\nplt.legend(loc=\"lower right\")\nplt.show()\nr_dict","c064d1f9":"baseline = pd.DataFrame({'id': test_df.id, 'target': 0})\npostprocess_separate(baseline, test_df=test_df.drop(columns='chunk'), pure_df=pure_df)\n","2a2f4043":"# 18 probabilities for the 18 half-chunks -> lb 0.75110\nsub = baseline.copy()\nfor chunk in range(10, 19):\n    sub.loc[(test_df.chunk == chunk) & (baseline.target < 0), 'target'] = l_dict[chunk]\n    sub.loc[(test_df.chunk == chunk) & (baseline.target >= 0), 'target'] = r_dict[chunk]\n\nsub['target']=sub['target'].rank(pct=True)\nsub.to_csv(f'submission_probed.csv', index=False)\nsub.head(20)","f8b647a8":"# 8 % of @jmcslk's submission (which has lb 0.74996) -> lb 0.75209\njmcslk_submission = pd.read_csv('..\/input\/tps-nov-2021-simple-single-nn-3\/submission.csv')\npostprocess_separate(jmcslk_submission, test_df=test_df.drop(columns='chunk'), pure_df=pure_df)\nsub_8b = sub.copy()\n\nsub_8b['target'] += jmcslk_submission.target.rank(pct=True)\n\nsub_8b.to_csv(f'submission_probed_blended_8b.csv', index=False)\nsub_8b.head(20)","b29ce4c9":"# 8 % of @sfktrkl's submission (which has lb 0.75002) -> lb 0.75204\nsfktrkl_submission = pd.read_csv('..\/input\/tps-nov-2021-power-averaging\/submission.csv')\npostprocess_separate(sfktrkl_submission, test_df=test_df.drop(columns='chunk'), pure_df=pure_df)\nsub_8c = sub.copy()\nsub_8c['target'] += sfktrkl_submission.target.rank(pct=True)\nsub_8c.to_csv(f'submission_probed_blended_8c.csv', index=False)\nsub_8c.head(20)\n","deb00ea6":"# Leaderboard Probing\n\nThis notebook is directly or indirectly based on work by @jmcslk, @criskiev, @grayjay, @javiervallejos, @adityasharma01, @sfktrkl, @motloch, @chaudharypriyanshu and others.\n\nWe first model the target distribution as a partition of 18 chunks, where each chunk has a fixed probability determined by [leaderboard probing](https:\/\/www.kaggle.com\/ambrosm\/tpsnov21-012-leaderboard-probing) and then blend the resulting model with the output of two [postprocessed](https:\/\/www.kaggle.com\/ambrosm\/tpsnov21-007-postprocessing) high-scoring public notebooks using the weights 91 : 8 : 1.\n"}}