{"cell_type":{"1529e9ef":"code","01ef7362":"code","6cdb3b53":"code","6a283b1c":"code","f9eeac4e":"code","7ad9a29c":"code","41f7d8a7":"code","f33fd8d3":"code","ea438faa":"code","b7cde26a":"code","aae10acf":"code","27e96ffc":"code","38ee1ab7":"code","4b9c7741":"code","cff14f55":"code","a7168a11":"code","927ff666":"code","5977d73d":"code","112764da":"code","cf8e0c84":"code","5d9f1807":"code","3f29e641":"code","a8d7e6a0":"code","3107c89f":"markdown","248ca6e9":"markdown","42226893":"markdown","0f0895ce":"markdown","b8e91ca2":"markdown","7cb70510":"markdown","fa99f831":"markdown","1ce46a47":"markdown","5d58fa80":"markdown","6cb42d41":"markdown","db4328bd":"markdown","d6cfe8d0":"markdown","6a47b6ea":"markdown","30429dac":"markdown","8bf71c10":"markdown","ce6e12c8":"markdown","202dcd8f":"markdown","81721f87":"markdown","e0b0662e":"markdown","5f5eaed7":"markdown","fc1fe758":"markdown","1a3b19e5":"markdown","fd1e7368":"markdown","18d99771":"markdown","b3794d3d":"markdown","660b13d5":"markdown","601737fd":"markdown","3c3ccf27":"markdown","641a76f3":"markdown","5502e048":"markdown","97b1d1dc":"markdown","de9f8316":"markdown","4c11ce93":"markdown","8c94e56b":"markdown","809788aa":"markdown","f3564219":"markdown"},"source":{"1529e9ef":"# Import libraries \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"..\/input\"))","01ef7362":"# Read our data\ndata = pd.read_csv('..\/input\/IPG2211A2N.csv',index_col=0)\ndata.head()","6cdb3b53":"# Change our data index from string to datetime\ndata.index = pd.to_datetime(data.index)\ndata.columns = ['Energy Production']\ndata.head()","6a283b1c":"# Import Plotly & Cufflinks libraries and run it in Offline mode\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\npy.enable_mpl_offline()\n\nimport cufflinks as cf\ncf.go_offline()","f9eeac4e":"# Now, plot our time serie\ndata.iplot(title=\"Energy Production Between Jan 1939 to May 2019\")","7ad9a29c":"# We'll use statsmodels to perform a decomposition of this time series\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nresult = seasonal_decompose(data, model='multiplicative')\n\nfig = result.plot()","41f7d8a7":"py.iplot_mpl(fig)\n# Try \"py.plot_mpl(fig)\" on your local Anaconda, it'll show greater plot than this one","f33fd8d3":"!pip install pmdarima","ea438faa":"# Kaggle doesn't have the up-to-date version of Scipy, so we need to upgrade it in order to use pmdarima library\n!pip install --upgrade scipy","b7cde26a":"# The Pmdarima library for Python allows us to quickly perform this grid search \nfrom pmdarima import auto_arima","aae10acf":"stepwise_model = auto_arima(data, start_p=1, start_q=1,\n                           max_p=3, max_q=3, m=12,\n                           start_P=0, seasonal=True,\n                           d=1, D=1, trace=True,\n                           error_action='ignore',  \n                           suppress_warnings=True, \n                           stepwise=True)","27e96ffc":"print(stepwise_model.aic())","38ee1ab7":"# For the Test: we'll need to chop off a portion of our latest data, say from 2016, Jan.\ntest = data.loc['2016-01-01':]\n\n# Fore the Train: we'll train on the rest of the data after split the test portion\ntrain = data.loc['1939-01-01':'2015-12-01']","4b9c7741":"stepwise_model.fit(train)","cff14f55":"future_forecast = stepwise_model.predict(n_periods=41)\nprint(future_forecast)","a7168a11":"future_forecast = pd.DataFrame(future_forecast, index=test.index, columns=['Prediction'])","927ff666":"pd.concat([test, future_forecast], axis=1).iplot()","5977d73d":"pd.concat([data,future_forecast],axis=1).iplot()","112764da":"stepwise_model.fit(data)","cf8e0c84":"future_forecast_1year = stepwise_model.predict(n_periods=13)","5d9f1807":"# For a year forecasting, we need 13 rows from 2019-05-01 to 2020-05-01\nnext_year = [pd.to_datetime('2019-05-01'),\n            pd.to_datetime('2019-06-01'),\n            pd.to_datetime('2019-07-01'),\n            pd.to_datetime('2019-08-01'),\n            pd.to_datetime('2019-09-01'),\n            pd.to_datetime('2019-10-01'),\n            pd.to_datetime('2019-11-01'),\n            pd.to_datetime('2019-12-01'),\n            pd.to_datetime('2020-01-01'),\n            pd.to_datetime('2020-02-01'),\n            pd.to_datetime('2020-03-01'),\n            pd.to_datetime('2020-04-01'),\n            pd.to_datetime('2020-05-01')]","3f29e641":"future_forecast_1year = pd.DataFrame(future_forecast_1year, index=next_year, columns=['Prediction'])","a8d7e6a0":"pd.concat([data,future_forecast_1year],axis=1).iplot()","3107c89f":"The data frame is ready now!\n\nLet's plot the data and move on to creating a proper model for our prediction.","248ca6e9":"Plot a better decompositioned charts using Plotly:","42226893":"## Decomposition","0f0895ce":"A few hints about auto_arima method:\n\n* **trace**: *bool* \/ whether to print status on the fits (**I'd like to see what's actually happening behind the code, so I enable it. You can eliminate this parameter to skip these lines and save your time**)\n* **error_action**: *str* \/ warn or raise or ignore , if unabe to fit an ARIMA due to stationarity issue\n* **suppress_warnings**: *bool* \/ Many warnings might be thrown inside of statsmodels, so we'll try to squelch them all.\n* **stepwise**: *bool* \/ The algorithm can be significantly faster than fitting all hyper-parameter combinations and is less likely to over-fit the mode.","b8e91ca2":"### Forecasting example for the next year","7cb70510":"## Seasonal ARIMA (SARIMA) & Grid Search","fa99f831":"For instance, let's forecast the \"energy production\" for the next year:","1ce46a47":"* **Create** a data frame contains our prediction (future_forecast):","5d58fa80":"## Train Test Split","6cb42d41":"* For the **Test**: we'll need to chop off a portion of our latest data, say from 2016, Jan.\n* Fore the **Train**: we'll train on the rest of the data after splitting up the test portion.","db4328bd":"From 2016-01-01 to 2019-05-01 (*the latest update from the source*), we have 41 rows:","d6cfe8d0":"The plot itself shows us that we have a 'seasonal' component in our time series, which means we need to choose p,d,q for ARIMA and P,D,Q for SARIMA","6a47b6ea":"* **Compare** *future_forecast* with the *entire data set* to get a larger picture of the context of our prediction:","30429dac":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)","8bf71c10":"* **Concatenate** *future_forecast* and *test data frame* together and plot the result:","ce6e12c8":"## Plot the Data","202dcd8f":"#### Pmdarima library is not available in Kaggle by default, so we'll need to install it for this Kernel","81721f87":"Okay, we have **evaluated** our model and it seems quite acceptable.\n\n* It's time to refit our model in the entire data set and then forecast the real future!","e0b0662e":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)","5f5eaed7":"Seems okay to me, right? :)","fc1fe758":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)","1a3b19e5":"So, it's a two-featured data frame:\n* As the data set reference, the second column is '*energy production*'.\n* The *Date* is in index now and has a string type. Then we'll also need to change its type from string to datetime","fd1e7368":"Great! we can fit the model now","18d99771":"This Kernel is based on **Jose Marcial** blog post: [Link](https:\/\/medium.com\/@josemarcialportilla\/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c)\n\nHe's a great *data scientist* & *teacher* in the field. If you would love to learn this Kernel with more details, follow that link. You may even find his brilliant courses on udemy website: [Link](https:\/\/www.udemy.com\/user\/joseportilla\/)\n\nOkay, let's get started.","b3794d3d":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)","660b13d5":"The **AIC** (*Akaike information criterion*) is an **estimator** of the relative quality of statistical models for a given set of data. AIC estimates the quality of each model, relative to each of the other models.\n\nThe **AIC** value allow us to **compare** how well a model fits the data. Models that have a better fit while using fewer features, will receive a better AIC score (*lower*) than similar models that utilize more features.","601737fd":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)","3c3ccf27":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)","641a76f3":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)","5502e048":"## Start & Process","97b1d1dc":"## Evaluation","de9f8316":"## INTRO (acknowledgement)","4c11ce93":"## Train Model","8c94e56b":"We'll need to *deconstruct* our time series into several components: **Seasonal**, **Trend** and **Residual**. There are a few ways to do that, but the most easy one is using **statsmodels**.","809788aa":"Let's do the **grid search** now!","f3564219":"![](https:\/\/drive.google.com\/uc?id=1PuQ33oL0QErS0P9knYqVS9634NVD-Y88)"}}