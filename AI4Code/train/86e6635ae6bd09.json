{"cell_type":{"4587a265":"code","16473619":"code","b64d32f9":"code","7e15ae62":"code","1f45c0e6":"code","900ca8f6":"code","20af8e23":"code","4a6a0d9b":"code","9f117a4c":"code","df8c7dd1":"code","682fe6a1":"code","cecb132f":"code","8d84a7d6":"code","7e08d464":"code","0d38e35e":"code","2d6bddf7":"code","259880cc":"code","0d86547e":"code","207e0305":"code","bd9d24d9":"code","4a19ebbc":"code","b73e394b":"code","5f4cbcbc":"code","f8a03f0b":"code","99aa8705":"code","a539ded2":"code","8be1fac3":"code","9b5351a4":"code","a39fdb2e":"code","1e039b49":"code","a4f44ba4":"code","9139cba8":"markdown","635fccf0":"markdown","1f375f9f":"markdown","3525a40e":"markdown","6f627e8a":"markdown","cd34a285":"markdown","57c47477":"markdown","ef793901":"markdown","56e84126":"markdown","c07681f1":"markdown","10d1fd69":"markdown","814ae859":"markdown","b8bcf401":"markdown","c291efe5":"markdown","f9fd8066":"markdown","3c5b49a6":"markdown","d101463e":"markdown","fbdaa23a":"markdown","47003100":"markdown","a2d24e70":"markdown","79148a2f":"markdown","e7e3394d":"markdown","2d67407a":"markdown","cf1ca606":"markdown","047e7956":"markdown","a1228175":"markdown","8cb11671":"markdown","68a30068":"markdown","88a452f7":"markdown","f0004cd2":"markdown","81ecbe49":"markdown","4b668e2d":"markdown","6c9e75d8":"markdown"},"source":{"4587a265":"import numpy as np","16473619":"## Scalar\na =1;a","b64d32f9":"## Vector or 1D Tensor\nnp.ones((3,),dtype='int')","7e15ae62":"## Matrics or 2D Tensor\nnp.ones((3,3),dtype='int')","1f45c0e6":"## 3D Tensor\nnp.ones((3,3,3),dtype='int')","900ca8f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20af8e23":"df_raw = pd.read_csv('\/kaggle\/input\/titanic\/train.csv',index_col='PassengerId')\ndf_raw.head()","4a6a0d9b":"df_raw.shape","9f117a4c":"df_raw.describe()","df8c7dd1":"### No. of people Survived , Dead \ndf_raw['Survived'].plot(kind='hist')","682fe6a1":"## Probability of Survival based on Age \ndf_raw[['Sex','Survived']].groupby(['Sex']).mean().plot(kind='bar')","cecb132f":"## Age mixture of passengers\ndf_raw[['Age','Survived']].groupby(['Age']).count().hist(bins=10)\n## Here we are observing a huge spike in lower Age group","8d84a7d6":"## No. of Babies(<2) on ship\ndf_raw[df_raw['Age'] < 2]","7e08d464":"df_raw.Embarked.unique()","0d38e35e":"## Probability of survival based on Passenger class\ndf_raw[['Pclass','Survived']].groupby(['Pclass']).mean().plot(kind='bar')","2d6bddf7":"## No. of Passengers in each class\ndf_raw[['Pclass']].plot(kind='hist')","259880cc":"## Find Missing Data\ndf_raw.isnull().sum()","0d86547e":"## Drop most Missing Column\ndf_raw.drop(['Cabin'], axis=1,inplace=True)","207e0305":"## Fill Missing Values\ndf_raw['Age'].fillna(df_raw['Age'].mean(),inplace=True)","bd9d24d9":"## Drop Na values\ndf_raw.dropna(inplace=True)","4a19ebbc":"df_raw.isnull().sum()","b73e394b":"df_raw.info()","5f4cbcbc":"## Drop unncecessary columns\ndf_raw.drop(['Name','Ticket'],axis=1,inplace=True)","f8a03f0b":"## Convert Text to Numbers\ndf_raw['Sex'] = df_raw['Sex'].map({'male':0,'female':1})","99aa8705":"## One hot encoding\nembarked = pd.get_dummies(df_raw['Embarked'])\ndf_raw.drop(['Embarked'],axis=1,inplace=True)","a539ded2":"df_processed = pd.concat([df_raw,embarked], axis=1)\ndf_processed.head()","8be1fac3":"x = df_processed.drop(['Survived'],axis=1)\ny = df_processed['Survived']","9b5351a4":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(x,y,stratify=y)","a39fdb2e":"from sklearn.tree import DecisionTreeClassifier, plot_tree\nmodel = DecisionTreeClassifier(criterion='entropy', max_depth=3)\nmodel.fit(x_train,y_train)","1e039b49":"(model.predict(x_val) == y_val).sum()*100\/len(x_val)","a4f44ba4":"import matplotlib.pyplot as plt\nplt.figure (figsize=(100,100))\nplot_tree(model,feature_names=x.columns,class_names=['Dead','Survived']);","9139cba8":"# Data Leakage\/Bias","635fccf0":"**To Train the model, there are a broad range of tools supporting this process, spanning from open-source machine and deep learning frameworks like Spark* ML, sk-learn*, Keras*, TensorFlow*, CNTK*, or BigDL to specialized training platforms like Tesla DOJO. They are done on general GPU or specialized chips like TPU\/NPU, which are high computation devices**","1f375f9f":"## Great sources for learning AI\n\n1. MIT lecturers by Andrej karpathy. link:https:\/\/www.youtube.com\/watch?v=NfnWJUyUJYU&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC\n\n1. Machine learning class by Andrev NG. link:https:\/\/www.youtube.com\/watch?v=PPLop4L2eGk&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN\n\n1. Practical Deep Learning for Coders by Jeremy Howard. link:https:\/\/www.youtube.com\/watch?v=_QUEXsHfsA0&list=PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM","3525a40e":"*AI  is a group of algorithms that can modify its algorithms and create new algorithms in response to learned inputs and data as opposed to relying solely on the inputs it was designed to recognize as triggers. This ability to change, adapt and grow based on new data, is described as \u201cintelligence.\u201d*\n\n**Y = F(x1,x2,.....xn)**\n","6f627e8a":"<img src=\"https:\/\/itpeernetwork.intel.com\/wp-content\/uploads\/sites\/38\/2018\/06\/Typical-Stages-in-an-AI-Journey.jpg\" width=1000 height=400 \/>","cd34a285":"<table><tr>\n<td> <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/en\/7\/70\/Terminator1984movieposter.jpg\" alt=\"Drawing\" style=\"width: 250px;\"\/> <\/td>\n<td> <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/en\/3\/3b\/Movie_poster_i_robot.jpg\" alt=\"Drawing\" style=\"width: 250px;\"\/> <\/td>\n<td> <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/en\/a\/aa\/Tamil-endhiran.jpg\" alt=\"Drawing\" style=\"width: 250px;\"\/> <\/td>\n<td> <img src=\"https:\/\/www.hollywoodreporter.com\/wp-content\/uploads\/2011\/10\/ra-one-poster_349x466.jpg?w=681&h=383&crop=1\" alt=\"Drawing\" style=\"width: 250px;\"\/> <\/td>\n<\/tr><\/table>","57c47477":"<img src=\"https:\/\/i2.wp.com\/vinodsblog.com\/wp-content\/uploads\/2018\/11\/Classification-vs-Regression1.png?resize=1300%2C729&ssl=1\" width=900 height=400\/>\n","ef793901":"## Factors used to evaluate use cases for fastest business impact are\n1. **Data Availability**\n1. **Clean Data**\n1. **Existing Technology**","56e84126":"<img src=\"https:\/\/sn3301files.storage.live.com\/y4miq1CKNiiwPihXb2wg-xyiMcyFwm2bbRiWVmn8eS5psrLLVCnByTRWPmKw0WI-ollZuFRcH-nmHhGkVXac50DiEcrNUZSrJT9WEPczwprXURZbgWRSfpM9qA5gAnF63c7lT4LNj4-Fkw6vXDt7_f_iP_P962PlCmF7wdg6cBCij0-oTtQPIqv8jBYA5hqWwk7?width=1120&height=601&cropmode=none\" width=\"800\" height=\"601\" \/>","c07681f1":"### Numpy\n**NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I\/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.**","10d1fd69":"**Neural Net Tank:**\nhttps:\/\/www.jefftk.com\/p\/detecting-tanks","814ae859":"# Matrices\/ Tensors","b8bcf401":"## Data Cleaning","c291efe5":"**GPT-3's full version has a capacity of 175 billion machine learning parameters.**","f9fd8066":"<img src=\"https:\/\/sn3301files.storage.live.com\/y4mDPuaAwoLA1htZ79wLiR6oMWdP1w5XxqhCdDo9bw4UBS3FfHR-bdavx49u3PQiMURFjUGIOiDLxtXGd8h5i5giBIYmZP2Uw7W8h54F7ky-OlnQLWaviODfyVXIKAV9NQdX1tkZNGHrzn_pKOLgWWWwuQvsdtv7cIgMfICdXJHIXhXr9xoeSZTYgsOXtTTm38F?width=854&height=441&cropmode=none\" width=\"854\" height=\"441\" \/>","3c5b49a6":"\n<div class=\"header\">\n    <h1 align=\"center\">AI Tools for Enterprise: From Concept to Deployment<\/h1>\n<\/div>","d101463e":"## Titanic Dataset","fbdaa23a":"### Implement\n**Implementing AI into a production environment can be as challenging as the development process. Due to advent of Edge devices and processing of data on edge due to privacy concerns, providing optimized user experience is essential across various platforms. Cross platform Neural compilers like ONNX, optimizers like OPENVIMO for intel, TensorRT for nvidia needs to be integrated.**","47003100":"**It is a serious problem for at least 3 reasons:**\n\n1. **It is a problem if you are running a machine learning competition. Top models will use the leaky data rather than be good general model of the underlying problem.**\n1. **It is a problem when you are a company providing your data. Reversing an anonymization and obfuscation can result in a privacy breach that you did not expect.**\n1. **It is a problem when you are developing your own predictive models. You may be creating overly optimistic models that are practically useless and cannot be used in production.**","a2d24e70":"## AI as universal function approximator","79148a2f":"### Read the data into a Pandas Dataframe","e7e3394d":"### Proving Your Use Case (Pilot)\n**Next, you will work through model development where data scientist will build and test multiple models to identify the appropriate data science methodology that provides the highest level of accuracy.**","2d67407a":"## Explorative data Analysis","cf1ca606":"# Introduction: \n\n### Domains\n<img src=\"https:\/\/ars.els-cdn.com\/content\/image\/3-s2.0-B9780128095195000028-f02-01-9780128095195.jpg\" width=500 height=400\/>\n","047e7956":"### Train, Test and Validation Dataset\n<img src=\"https:\/\/miro.medium.com\/max\/2512\/1*HEe_oHZHToY8oD1RoShHGg.png\" width=1000 height=400 \/>","a1228175":"## Data Preparation","8cb11671":"<img src=\"https:\/\/www.oreilly.com\/library\/view\/natural-language-processing\/9781491978221\/assets\/nlpp_0106.png\" width=1000 height=400\/>\n","68a30068":"### Pandas\n**Pandas is a Python package built on top of Numpy that provides fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive.**","88a452f7":"## Future of AI: Explainability \/ Interpretability","f0004cd2":"### CPU vs GPU\n<img src=\"https:\/\/i2.wp.com\/www10.mcadcafe.com\/blogs\/jeffrowe\/files\/2017\/03\/CPU-and-GPU.png?w=925&ssl=1\" width=\"820\" height=\"601\" \/>\n\n<img src=\"https:\/\/www.jeremyjordan.me\/content\/images\/2018\/01\/Screen-Shot-2017-11-07-at-12.32.19-PM.png\" width=\"820\" height=\"601\" \/>\n","81ecbe49":"# AI production life cycle","4b668e2d":"<img src=\"https:\/\/static01.nyt.com\/images\/2021\/08\/17\/business\/16tesla-autopilot02\/merlin_160149285_a8f68208-032e-494e-a04a-1615954c8582-jumbo.jpg?quality=90&auto=webp\" width=\"820\" height=\"601\" \/>","6c9e75d8":"**Interpretability is crucial for trusting AI and machine learning.**"}}