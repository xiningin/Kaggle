{"cell_type":{"05e50f22":"code","ac491a23":"code","2ea1b1aa":"code","bd89428c":"code","8da59d2c":"code","3c28bfda":"code","346dbf14":"code","d058ccda":"code","41a62ade":"code","e1e6b544":"code","9b9f30ae":"code","e98cf369":"code","fc88138b":"code","d8f9b7c2":"code","51f3e203":"code","ca1eb0a1":"code","a4334f66":"code","eb2ac8c3":"code","04b24d02":"code","7503570e":"code","d5708308":"code","91cec12b":"code","99108e89":"code","d309e170":"code","4fd8f454":"code","c7e8e258":"code","9612cd66":"code","7492605c":"code","57968e95":"code","811a0b2a":"code","8e15e542":"code","b4ccf93c":"code","37651dd1":"code","ccc21743":"code","64d2565e":"code","6500a712":"code","8abbd87a":"code","2b048697":"code","c539eafc":"code","4e12ac61":"code","d04b1a61":"code","e550d4d4":"code","337d0b86":"code","02346f28":"code","79120127":"code","318754b2":"code","6a8bbcf0":"code","331510d4":"code","983b4738":"code","8299686c":"code","9b1be50b":"code","7b3fceb7":"code","eec28934":"code","d65a0b1c":"code","c43864fd":"code","f868f401":"code","52f9ab15":"code","b9f1495d":"code","691d075a":"code","6b100bbf":"code","4e275256":"code","ac57ccfb":"code","f99be80b":"code","cb52795b":"code","a00f3ccc":"code","429913af":"code","95fd7696":"code","8824aba3":"code","87b92f90":"code","7ca12c6e":"code","030f37f0":"code","6621cb13":"code","5dad25c3":"code","b9b2f48f":"code","f016a7b1":"code","e7fbf436":"code","2d4a3fe6":"code","04ad75be":"code","4e07838e":"code","a4c08767":"code","fc394239":"code","0377f6c2":"code","ba9ec5b0":"code","3e2c15ec":"code","d48e9eff":"code","d823fb24":"code","81e3c10c":"code","dad343f2":"code","ed444422":"code","b719cbf1":"code","edc8ecc3":"code","c52675a9":"code","95105b3e":"code","ecf77595":"code","bed4cbcb":"code","e64009b6":"code","89497637":"code","8fa23f07":"code","8cfa77f0":"code","1642f502":"code","0ea6ecb8":"code","392e5f12":"code","d9cb2f1f":"code","86e20f70":"code","d9f3d7c6":"code","fc78f6e1":"code","001c712f":"code","87a82ed9":"code","2f133eb8":"markdown","d8e99581":"markdown","92c5cce5":"markdown","8dccc005":"markdown","d0844766":"markdown","71557efb":"markdown","bfa17231":"markdown","ad82a6e9":"markdown","0d174271":"markdown","70b8cafa":"markdown","5f228204":"markdown","19c8ec10":"markdown","23240ec5":"markdown","30b4dd10":"markdown","f083bf4b":"markdown","e1bf2315":"markdown","981b769b":"markdown","d91127a9":"markdown","a9587c5f":"markdown","493e66e4":"markdown","ded5d714":"markdown","e44e1953":"markdown","f1d58faa":"markdown","e9c3b3b7":"markdown","3f3918d3":"markdown","3558ade7":"markdown","d515a977":"markdown","18fe9058":"markdown","7606005c":"markdown","269cdfd8":"markdown","820bbec7":"markdown","39d86996":"markdown","2f11945b":"markdown","76e252e4":"markdown","55da72fa":"markdown","3c5f2e20":"markdown","95cb87c3":"markdown","d5bbf6cd":"markdown","8f37dfe7":"markdown","1dc81a6b":"markdown","c7feb813":"markdown","e8589064":"markdown","273d9118":"markdown","d4215a72":"markdown","c8a2c7c9":"markdown","6599361e":"markdown","397b88fa":"markdown","51da552e":"markdown","87d5935d":"markdown","f4dee27a":"markdown","5bf90bed":"markdown","71922937":"markdown","8941e8bf":"markdown","9a7f94aa":"markdown","9678db17":"markdown","30f7f4ac":"markdown","a2ecc799":"markdown","ac351cf2":"markdown","79f8770c":"markdown","40aebb56":"markdown","10c8052d":"markdown","d081b425":"markdown","59bf846e":"markdown","547a2a9a":"markdown","6a6378a8":"markdown","00df92ed":"markdown","a0b3d00f":"markdown","5cc5ffdb":"markdown","f3fb93ec":"markdown","7e585658":"markdown","792f5034":"markdown","78cfca96":"markdown","40b48e31":"markdown","a6d3bc24":"markdown","76ec6102":"markdown","c696e436":"markdown","2e92491b":"markdown","38ee2fdc":"markdown"},"source":{"05e50f22":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# scaling \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n# kmeans clustering \nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom yellowbrick.cluster import SilhouetteVisualizer\n\n# multivariate linear regression\nfrom sklearn import linear_model\n\n# geo data\nimport geopandas as gpd\nfrom geopandas import GeoDataFrame as gdf\nimport plotly.express as px","ac491a23":"data_path = '..\/input\/unsupervised-learning-on-country-data'","2ea1b1aa":"data = pd.read_csv(\n    f'{data_path}\/Country-data.csv')","bd89428c":"# quick view of columns and values\ndata.head()","8da59d2c":"# how many columns and rows in dataframe\ndata.shape","3c28bfda":"# are there any missing values?\ndata.isnull().sum()","346dbf14":"# are there duplicate values?\nformat(len(data[data.duplicated()]))","d058ccda":"# standard statistical measures\ndata.describe(percentiles = [.25, .5, .75, .90 ,.95, .99])","41a62ade":"plt.figure(figsize=(12,5))\nplt.title(\"Child Mortality: Death of children under 5 years of age per 1000 live births\")\nax = sns.histplot(data[\"child_mort\"])","e1e6b544":"plt.figure(figsize=(12,5))\nplt.title(\"Exports: Exports of goods and services per capita. Given as %age of the GDP per capita\")\nax = sns.histplot(data[\"exports\"])","9b9f30ae":"plt.figure(figsize=(12,5))\nplt.title(\"Imports: Imports of goods and services per capita. Given as %age of the GDP per capita\")\nax = sns.histplot(data[\"imports\"])","e98cf369":"plt.figure(figsize=(12,5))\nplt.title(\"Health: Total health spending per capita. Given as %age of GDP per capita\")\nax = sns.histplot(data[\"health\"])","fc88138b":"plt.figure(figsize=(12,5))\nplt.title(\"Income: Net income per person\")\nax = sns.histplot(data[\"income\"])","d8f9b7c2":"plt.figure(figsize=(12,5))\nplt.title(\"Inflation: The measurement of the annual growth rate of the Total GDP\")\nax = sns.histplot(data[\"inflation\"])","51f3e203":"plt.figure(figsize=(12,5))\nplt.title(\"Life expectancy: The average number of years a new born child would live if the current mortality patterns are to remain the same\")\nax = sns.histplot(data[\"life_expec\"])","ca1eb0a1":"plt.figure(figsize=(12,5))\nplt.title(\"New Population(?) :The number of children that would be born to each woman if the current age-fertility rates remain the same.\")\nax = sns.histplot(data[\"total_fer\"])","a4334f66":"plt.figure(figsize=(12,5))\nplt.title(\"GDP: The GDP per capita. Calculated as the Total GDP divided by the total population.\")\nax = sns.histplot(data[\"gdpp\"])","eb2ac8c3":"# pearson\nplt.figure(figsize=(15,10))\nsns.heatmap(data.corr(method='pearson', min_periods=1),annot=True)","04b24d02":"# kendall\nplt.figure(figsize=(15,10))\nsns.heatmap(data.corr(method='kendall', min_periods=1),annot=True)","7503570e":"# spearman\nplt.figure(figsize=(15,10))\nsns.heatmap(data.corr(method='spearman', min_periods=1),annot=True)","d5708308":"# eliminate the column that contains the country information, as only numeric values should be used in this case for unsupervised learning\ndataset = data.drop(['country'], axis =1)\ndataset.head()","91cec12b":"# columns argument ==> we'll use this later to create a new dataframe with the rescaled data \ncolumns = dataset.columns\n\n# the scaler to use will be \nscaler = MinMaxScaler()\n\n# 'scaler' is for the rescaling technique, 'fit' function is to find the x_min and the x_max, 'transform' function applies formula to all elements of data\nrescaled_dataset_minmax = scaler.fit_transform(dataset)\nrescaled_dataset_minmax","99108e89":"# in standardisation, all features will be transformed to have the properties of standard normal distribution with mean=0 and standard deviation=1\n# \n# columns argument ==> we'll use this later to create a new dataframe with the rescaled data \ncolumns = dataset.columns\n\n# the scaler to use will be \nscaler = StandardScaler()\n\n# 'scaler' is for the rescaling technique, 'fit' function is to find the x_min and the x_max, 'transform' function applies formula to all elements of data\nrescaled_dataset_standard = scaler.fit_transform(dataset)\nrescaled_dataset_standard","d309e170":"# minmax\n# we need to create a new dataframe with the column lables and the rescaled values \ndf_minmax = pd.DataFrame(data= rescaled_dataset_minmax , columns = columns )\ndf_minmax","4fd8f454":"# standardisation\n# we need to create a new dataframe with the column lables and the rescaled values \ndf_standard = pd.DataFrame(data= rescaled_dataset_standard , columns = columns)\ndf_standard","c7e8e258":"plt.scatter(df_standard['gdpp'], df_standard['child_mort'],color = 'black')\nplt.scatter\n\nplt.xlabel('GDP per Person')\nplt.ylabel('Child Mortality')","9612cd66":"plt.scatter(df_minmax['gdpp'], df_minmax['child_mort'],color = 'black')\nplt.scatter\n\nplt.xlabel('GDP per Person')\nplt.ylabel('Child Mortality')","7492605c":"# import PCA \nfrom sklearn.decomposition import PCA\n\n# fit and transform\npca = PCA()\npca.fit(df_standard)\npca_data_standard = pca.transform(df_standard)\n\n# percentage variation \nper_var = np.round(pca.explained_variance_ratio_*100, decimals =1)\nlabels = ['PC' + str(x) for x in range (1, len(per_var)+1)]\n\n# plot the percentage of explained variance by principal component\nplt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label = labels)\nplt.ylabel('Percentage of Explained Variance')\nplt.xlabel('Principal Component')\nplt.title('Scree Plot')\nplt.show()\n\n# plot pca\npca_df_standard = pd.DataFrame(pca_data_standard, columns = labels)\nplt.scatter(pca_df_standard.PC1, pca_df_standard.PC2)\nplt.title('PCA')\nplt.xlabel('PC1 - {0}%'.format(per_var[0]))\nplt.ylabel('PC2 - {0}%'.format(per_var[1]))","57968e95":"# import PCA \nfrom sklearn.decomposition import PCA\n\n# fit and transform\npca = PCA()\npca.fit(df_minmax)\npca_data_minmax = pca.transform(df_minmax)\n\n# percentage variation \nper_var = np.round(pca.explained_variance_ratio_*100, decimals =1)\nlabels = ['PC' + str(x) for x in range (1, len(per_var)+1)]\n\n# plot the percentage of explained variance by principal component\nplt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label = labels)\nplt.ylabel('Percentage of Explained Variance')\nplt.xlabel('Principal Component')\nplt.title('Scree Plot')\nplt.show()\n\n# plot pca\n\npca_df_minmax = pd.DataFrame(pca_data_minmax, columns = labels)\nplt.scatter(pca_df_minmax.PC1, pca_df_minmax.PC2)\nplt.title('PCA')\nplt.xlabel('PC1 - {0}%'.format(per_var[0]))\nplt.ylabel('PC2 - {0}%'.format(per_var[1]))","811a0b2a":"# dataframe with PC1, PC2, P3, PC4\ndata2 = pca_df_standard.drop(['PC5','PC6','PC7','PC8','PC9'], axis = 1)\ndata2","8e15e542":"km = KMeans (\n    n_clusters = 3, # number of clusters\/centroids to create\n    init = 'random', # \u2018random\u2019: choose n_clusters observations (rows) at random from data for the initial centroids\n    n_init = 10, # this is the default value. This is the number of times the k-means algorithm will be run with different centroid seeds\n    max_iter = 300, # this is the default value. This is the maximum number of iterations of the k-means algorithm for a single run.\n    tol = 1e-4, # this is the default value. This is the relative tolerance with regards to Frobenius norm of the difference in the cluster centers of two consecutive iterations to declare convergence.\n    random_state = 0 # this is the default value. Determines random number generation for centroid initialization. Use an int to make the randomness deterministic.\n)","b4ccf93c":"# normalised dataset\n# method to compute the clusters and assign the labels\ny_predicted_minmax = km.fit_predict(df_minmax) # fit_predict --> Compute cluster centers and predict cluster index for each sample.\ny_predicted_minmax","37651dd1":"# standardised dataset\n# method to compute the clusters and assign the labels\ny_predicted_standard = km.fit_predict(df_standard) # fit_predict --> Compute cluster centers and predict cluster index for each sample.\ny_predicted_standard","ccc21743":"# data2 is the original dataset with standard scaling and 4 principal components found with PCA\n# method to compute the clusters and assign the labels\ny_predicted_data2 = km.fit_predict(data2) # fit_predict --> Compute cluster centers and predict cluster index for each sample.\ny_predicted_data2","64d2565e":"# add the cluster column to the dataframe \ndf_minmax['cluster'] = y_predicted_minmax\ndf_minmax.head()","6500a712":"# add the cluster column to the dataframe \ndf_standard['cluster'] = y_predicted_standard\ndf_standard.head()","8abbd87a":"# add the cluster column to the dataframe (dataset does not include feature 'country')\ndataset['cluster'] = y_predicted_data2\ndataset.head()","2b048697":"# calculate Sum of Squared Errors (SSE), also called distorsions,  for a range of number of cluster - with df scaled with StandardScaler\n\nsse = []\nfor i in range(1, 11):\n    km = KMeans(\n        n_clusters=i, init='random',\n        n_init=10, max_iter=300,\n        tol=1e-04, random_state=0\n    )\n    km.fit(df_standard)\n    sse.append(km.inertia_)\n\n# plot\nplt.plot(range(1, 11), sse, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('SSE')\nplt.show()","c539eafc":"# calculate Sum of Squared Errors (SSE), also called distorsions, for a range of number of cluster - with df scaled with MinMax\n\nsse = []\nfor i in range(1, 11):\n    km = KMeans(\n        n_clusters=i, init='random',\n        n_init=10, max_iter=300,\n        tol=1e-04, random_state=0\n    )\n    km.fit(df_minmax)\n    sse.append(km.inertia_)\n\n# plot\nplt.plot(range(1, 11), sse, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('SSE')\nplt.show()","4e12ac61":"# calculate Sum of Squared Errors (SSE), also called distorsions, for a range of number of cluster - with df scaled with StandardScaler + PCA\nsse = []\nfor i in range(1, 11):\n    km = KMeans(\n        n_clusters=i, init='random',\n        n_init=10, max_iter=300,\n        tol=1e-04, random_state=0\n    )\n    km.fit(dataset)\n    sse.append(km.inertia_)\n\n# plot\nplt.plot(range(1, 11), sse, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('SSE')\nplt.show()","d04b1a61":"# calculate Silhoutte Score - stardardised\nscore = silhouette_score(df_standard, km.labels_, metric='euclidean')\nprint('Silhouette Score: %.3f' % score)\n\n# A value near 0 represents overlapping clusters with samples very close to the decision boundary of the neighboring clusters. ","e550d4d4":"fig,ax = plt.subplots(2,2, figsize = (15,8))\nfor i in [2,3,4,5]:\n\n    # create kmeans instance for different numbers of clusters\n    km = KMeans(n_clusters=i, init= 'random', n_init =10, max_iter = 300, random_state = 0)\n    q, mod = divmod(i,2)\n    \n    #create visualiser\n    visualizer = SilhouetteVisualizer(km, colors = 'yellowbrick', ax=ax[q-1][mod])\n    visualizer.fit(df_standard)","337d0b86":"# Calculate Silhoutte Score - normalised\nscore = silhouette_score(df_minmax, km.labels_, metric='euclidean')\nprint('Silhouette Score: %.3f' % score)\n\n# # A value near 0 represents overlapping clusters with samples very close to the decision boundary of the neighboring clusters. ","02346f28":"fig,ax = plt.subplots(2,2, figsize = (15,8))\nfor i in [2,3,4,5]:\n\n    # create kmeans instance for different numbers of clusters\n    km = KMeans(n_clusters=i, init= 'random', n_init =10, max_iter = 300, random_state = 0)\n    q, mod = divmod(i,2)\n    \n    #create visualiser\n    visualizer = SilhouetteVisualizer(km, colors = 'yellowbrick', ax=ax[q-1][mod])\n    visualizer.fit(df_minmax)","79120127":"# Calculate Silhoutte Score - stardardised + PCA\nscore = silhouette_score(dataset, km.labels_, metric='euclidean')\nprint('Silhouette Score: %.3f' % score)\n\n# A value near 0 represents overlapping clusters with samples very close to the decision boundary of the neighboring clusters. ","318754b2":"fig,ax = plt.subplots(2,2, figsize = (15,8))\nfor i in [2,3,4,5]:\n\n    # create kmeans instance for different numbers of clusters\n    km = KMeans(n_clusters=i, init= 'random', n_init =10, max_iter = 300, random_state = 0)\n    q, mod = divmod(i,2)\n    \n    #create visualiser\n    visualizer = SilhouetteVisualizer(km, colors = 'yellowbrick', ax=ax[q-1][mod])\n    visualizer.fit(dataset)","6a8bbcf0":"# load example dataset from seaborn \nsns.get_dataset_names()\n\n# plot\nsns.load_dataset('penguins')\nsns.pairplot(df_standard, hue=\"cluster\")\n\n# title\nplt.suptitle('Pair Plot of Clusters by Feature', \n             size = 20);","331510d4":"# load example dataset from seaborn \nsns.get_dataset_names()\n\n# plot\nsns.load_dataset('penguins')\nsns.pairplot(df_minmax, hue=\"cluster\")\n\n# title\nplt.suptitle('Pair Plot of Clusters by Feature', \n             size = 20);","983b4738":"# load example dataset from seaborn \nsns.get_dataset_names()\n\n# plot\nsns.load_dataset('penguins')\nsns.pairplot(dataset, hue=\"cluster\")\n\n# title\nplt.suptitle('Pair Plot of Clusters by Feature', \n             size = 20);","8299686c":"# add cluster column to original dataset with countries and non-scaled values\ndata['cluster'] = y_predicted_standard.tolist()\ndata","9b1be50b":"# load example dataset from seaborn \nsns.get_dataset_names()\n\n# plot\nsns.load_dataset('penguins')\nsns.pairplot(data, hue=\"cluster\")\n\n# title\nplt.suptitle('Pair Plot of Clusters by Feature', \n             size = 20);","7b3fceb7":"# table of clusters showing mean values per cluster and per feature\nclusters_table = pd.pivot_table(data, index=['cluster'])\nclusters_table","eec28934":"# cluster 0 \ncluster_0 = data.loc[data['cluster'] == 0]\n\n# list of countries in this country\ncluster_0.country.unique()","d65a0b1c":"# cluster 1 \ncluster_1 = data.loc[data['cluster'] == 1]\n\n# list of countries in this country\ncluster_1.country.unique()","c43864fd":"# cluster 2 \ncluster_2 = data.loc[data['cluster'] == 2]\n\n# list of countries in this country\ncluster_2.country.unique()","f868f401":"# load example data from geodataframe \nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nworld.head()","52f9ab15":"# look at country names from gpd list\nprint(sorted(world['name'].unique()))\n\n# look at country names for analysis list\nprint(sorted(data['country'].unique()))","b9f1495d":"# compare 2 lists to idenitfy country names that need to be adjusted\nworld_list = ['Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bangladesh', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan', 'Bolivia', 'Bosnia and Herz.', 'Botswana', 'Brazil', 'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Central African Rep.', 'Chad', 'Chile', 'China', 'Colombia', 'Congo', 'Costa Rica', 'Croatia', 'Cuba', 'Cyprus', 'Czechia', \"C\u00f4te d'Ivoire\", 'Dem. Rep. Congo', 'Denmark', 'Djibouti', 'Dominican Rep.', 'Ecuador', 'Egypt', 'El Salvador', 'Eq. Guinea', 'Eritrea', 'Estonia', 'Ethiopia', 'Falkland Is.', 'Fiji', 'Finland', 'Fr. S. Antarctic Lands', 'France', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Greece', 'Greenland', 'Guatemala', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Honduras', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan', 'Kazakhstan', 'Kenya', 'Kosovo', 'Kuwait', 'Kyrgyzstan', 'Laos', 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Lithuania', 'Luxembourg', 'Macedonia', 'Madagascar', 'Malawi', 'Malaysia', 'Mali', 'Mauritania', 'Mexico', 'Moldova', 'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Myanmar', 'N. Cyprus', 'Namibia', 'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'North Korea', 'Norway', 'Oman', 'Pakistan', 'Palestine', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda', 'S. Sudan', 'Saudi Arabia', 'Senegal', 'Serbia', 'Sierra Leone', 'Slovakia', 'Slovenia', 'Solomon Is.', 'Somalia', 'Somaliland', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Syria', 'Taiwan', 'Tajikistan', 'Tanzania', 'Thailand', 'Timor-Leste', 'Togo', 'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Turkmenistan', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States of America', 'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela', 'Vietnam', 'W. Sahara', 'Yemen', 'Zambia', 'Zimbabwe', 'eSwatini']\ndata_list = ['Afghanistan', 'Albania', 'Algeria', 'Angola', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan', 'Bolivia', 'Bosnia and Herzegovina', 'Botswana', 'Brazil', 'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde', 'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia', 'Comoros', 'Costa Rica', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia', 'Fiji', 'Finland', 'France', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Greece', 'Grenada', 'Guatemala', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan', 'Kazakhstan', 'Kenya', 'Kiribati', 'Kuwait', 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Lithuania', 'Luxembourg', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta', 'Mauritania', 'Mauritius', 'Moldova', 'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Namibia', 'Nepal', 'Netherlands', 'New Zealand', 'Niger', 'Nigeria', 'Norway', 'Oman', 'Pakistan', 'Panama', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Qatar', 'Romania', 'Russia', 'Rwanda', 'Samoa', 'Saudi Arabia', 'Senegal', 'Serbia', 'Seychelles', 'Sierra Leone', 'Singapore', 'Slovenia', 'Solomon Islands', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Tajikistan', 'Tanzania', 'Thailand', 'Timor-Leste', 'Togo', 'Tonga', 'Tunisia', 'Turkey', 'Turkmenistan', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States', 'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela', 'Vietnam', 'Yemen', 'Zambia']\n\nlist_difference = []\nfor item in world_list:\n  if item not in data_list:\n    list_difference.append(item)\n\nprint(list_difference)","691d075a":"# update names on world gdp dataset to match with df\nworld['name'] = world['name'].replace(\n    ['Bosnia and Herz.', 'Central African Rep.', 'Congo', \"C\u00f4te d'Ivoire\", 'Dem. Rep. Congo', 'Dominican Rep.', 'Eq. Guinea', 'Macedonia', 'Myanmar', 'N. Cyprus', 'S. Sudan', 'Slovakia', 'Solomon Is.', 'United States of America'],\n    ['Bosnia and Herzegovina','Central African Republic','Congo, Rep.',\"Cote d'Ivoire\",'Congo, Dem. Rep.','Dominican Republic','Equatorial Guinea','Macedonia, FYR','Myanmar','Cyprus','Sudan','Slovak Republic','Solomon Islands','United States'])\n\n# check output\nworld.name.unique()","6b100bbf":"# change column name\nworld_copy = world.copy()\nworld_copy.rename(columns = {'name' : 'country'}, inplace = True)\nworld_copy.head()\n\n# append geodataframe data with data_combined data\nworld_data = pd.merge(\n        data,\n        world_copy,\n        on='country',\n        how= 'inner'\n)\n\n# convert df into geodf\nworld_data = gdf(world_data)\n\n# plot \nimport geoplot\nimport mapclassify\ncluster = world_data['cluster']\n\n\n# Note: this code sample requires geoplot>=0.4.0.\ngeoplot.choropleth(\n    world_data, \n    hue=cluster,\n    cmap='Greys', \n    figsize=(16, 8),\n    legend = True\n)","4e275256":"# df without these features \ndataset_reduced = data.drop(['country','life_expec','total_fer','income'], axis =1)\ndataset_reduced.head()","ac57ccfb":"# scale with standard scaling\ncolumns = dataset_reduced.columns\n\n# the scaler to use will be \nscaler = StandardScaler()\n\nrescaled_dataset_reduced = scaler.fit_transform(dataset_reduced)\nrescaled_dataset_reduced","f99be80b":"# standardisation\n# we need to create a new dataframe with the column lables and the rescaled values \ndf_reduced = pd.DataFrame(data= rescaled_dataset_reduced , columns = columns)\ndf_reduced\n","cb52795b":"# run the model with the standardised reduced dataset\n# method to compute the clusters and assign the labels\ny_predicted_reduced = km.fit_predict(df_reduced) \ny_predicted_reduced","a00f3ccc":"# add the cluster column to the dataframe \ndf_reduced['cluster'] = y_predicted_reduced\ndf_reduced.head()","429913af":"# calculate Sum of Squared Errors (SSE), also called distorsions, for a range of number of cluster - with df scaled with StandardScaler + PCA\nsse = []\nfor i in range(1, 11):\n    km = KMeans(\n        n_clusters=i, init='random',\n        n_init=10, max_iter=300,\n        tol=1e-04, random_state=0\n    )\n    km.fit(df_reduced)\n    sse.append(km.inertia_)\n\n# plot\nplt.plot(range(1, 11), sse, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('SSE')\nplt.show()","95fd7696":"# df cluster 2 \ndf3 = data[data.cluster == 2]\n\n# load example dataset from seaborn \nsns.get_dataset_names()\n\n# plot\nsns.load_dataset('penguins')\nsns.pairplot(df3, hue='cluster')\n\n# title\nplt.suptitle('Cluster 2 by Feature', \n             size = 20);","8824aba3":"# import data\nmpi_data = pd.read_csv(\"\/kaggle\/input\/mpi\/MPI_national.csv\")\nmpi_data","87b92f90":"# drop columns\nmpi_data_short =  mpi_data.drop(['ISO','Headcount Ratio Urban','Intensity of Deprivation Urban','Headcount Ratio Rural','Intensity of Deprivation Rural'], axis=1)\n\n# rename column\nmpi_data_short.rename(\n    columns = {'Country':'country',\n               'MPI Urban':'mpi_urban',\n               'MPI Rural':'mpi_rural'\n              },\n    inplace = True)\n\n# head\nmpi_data_short.head(3)","7ca12c6e":"plt.figure(figsize=(12,5))\nplt.title('MPI Urban')\nax = sns.histplot(mpi_data_short['mpi_urban'])","030f37f0":"plt.figure(figsize=(12,5))\nplt.title('MPI Rural')\nax = sns.histplot(mpi_data_short['mpi_rural'])","6621cb13":"# append data df with mpi_data df\ncombined = pd.merge(\n    data,\n    mpi_data_short,\n    on='country',\n    how='inner'\n)\n\n# check\ncombined.head()","5dad25c3":"# pearson\nplt.figure(figsize=(15,10))\nsns.heatmap(combined.corr(method='pearson', min_periods=1),annot=True)","b9b2f48f":"# create linear regression class object \nreg = linear_model.LinearRegression()\n\n# libraries for plotting of residual plots\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols","f016a7b1":"#fit simple linear regression model\nmodel = ols('mpi_urban ~ child_mort', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'child_mort', fig=fig)","e7fbf436":"# fit simple linear regression model\nmodel = ols('mpi_urban ~ exports', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'exports', fig=fig)","2d4a3fe6":"# fit simple linear regression model\nmodel = ols('mpi_urban ~ health', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'health', fig=fig)","04ad75be":"# fit simple linear regression model\nmodel = ols('mpi_urban ~ imports', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'imports', fig=fig)","4e07838e":"#fit simple linear regression model\nmodel = ols('mpi_urban ~ income', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'income', fig=fig)","a4c08767":"#fit simple linear regression model\nmodel = ols('mpi_urban ~ inflation', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'inflation', fig=fig)","fc394239":"#fit simple linear regression model\nmodel = ols('mpi_urban ~ life_expec', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'life_expec', fig=fig)","0377f6c2":"#fit simple linear regression model\nmodel = ols('mpi_urban ~ total_fer', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'total_fer', fig=fig)","ba9ec5b0":"#fit simple linear regression model\nmodel = ols('mpi_urban ~ gdpp', data=combined).fit()\n\n#view model summary\nprint(model.summary())\n\n#define figure size\nfig = plt.figure(figsize=(12,8))\n\n#produce regression plots\nfig = sm.graphics.plot_regress_exog(model, 'gdpp', fig=fig)","3e2c15ec":"# train model\nreg.fit(combined[['child_mort','exports','health','imports','income','inflation','life_expec','total_fer','gdpp']],combined.mpi_urban)","d48e9eff":"# accuracy assessment\n# R-squared: indicates the proportion of variance in y (mpi_urban), explained by x (other features selected)\nreg.score(combined[['child_mort','exports','health','imports','income','inflation','life_expec','total_fer','gdpp']],combined.mpi_urban)","d823fb24":"# accuracy assessment\n# adjusted R-squared: The adjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in a regression model.\n1 - (1-reg.score(combined[['child_mort','exports','health','imports','income','inflation','life_expec','total_fer','gdpp']],combined.mpi_urban))*(len(combined.mpi_urban)-1)\/(len(combined.mpi_urban)-combined[['child_mort','exports','health','imports','income','inflation','life_expec','total_fer','gdpp']].shape[1]-1)","81e3c10c":"# train model\nreg.fit(combined[['exports','health','imports','inflation','gdpp']],combined.mpi_urban)","dad343f2":"# accuracy assessment\n# adjusted R-squared: The adjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in a regression model.\n1 - (1-reg.score(combined[['exports','health','imports','inflation','gdpp']],combined.mpi_urban))*(len(combined.mpi_urban)-1)\/(len(combined.mpi_urban)-combined[['exports','health','imports','inflation','gdpp']].shape[1]-1)","ed444422":"# train model\nreg.fit(combined[['child_mort','total_fer']],combined.mpi_urban)\n\n# accuracy assessment\n# adjusted R-squared: The adjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in a regression model.\n1 - (1-reg.score(combined[['child_mort','total_fer']],combined.mpi_urban))*(len(combined.mpi_urban)-1)\/(len(combined.mpi_urban)-combined[['child_mort','total_fer']].shape[1]-1)","b719cbf1":"mpi_data_short.head()","edc8ecc3":"# append clusters 0 and 1\nsub_cluster = cluster_0.append(cluster_1, ignore_index = True)\nsub_cluster.head()\n","c52675a9":"# append df with cluster 0 and 1 with mpi_data df\nsub_cluster_mpi = pd.merge(\n    sub_cluster,\n    mpi_data_short,\n    on='country',\n    how='inner'\n)\n\nsub_cluster_mpi.head()","95105b3e":"# eliminate the column that contains the country information and cluster as only numeric values should be used in this case for unsupervised learning\nsub_cluster_data = sub_cluster_mpi.drop(['country','cluster','exports','health','imports','income','inflation','life_expec','total_fer','mpi_rural'], axis =1)\n\n\n# columns argument ==> we'll use this later to create a new dataframe with the rescaled data \ncolumns = sub_cluster_data.columns\n\n# the scaler to use will be \nscaler = StandardScaler()\n\n# 'scaler' is for the rescaling technique, 'fit' function is to find the x_min and the x_max, 'transform' function applies formula to all elements of data\nrescaled_sub_cluster_data = scaler.fit_transform(sub_cluster_data)\nrescaled_sub_cluster_data\n\n# we need to create a new dataframe with the column lables and the rescaled values \ndf_sub_cluster = pd.DataFrame(data= rescaled_sub_cluster_data , columns = columns)\ndf_sub_cluster","ecf77595":"km2 = KMeans (\n    n_clusters = 3, # number of clusters\/centroids to create\n    init = 'random', # \u2018random\u2019: choose n_clusters observations (rows) at random from data for the initial centroids\n    n_init = 10, # this is the default value. This is the number of times the k-means algorithm will be run with different centroid seeds\n    max_iter = 300, # this is the default value. This is the maximum number of iterations of the k-means algorithm for a single run.\n    tol = 1e-4, # this is the default value. This is the relative tolerance with regards to Frobenius norm of the difference in the cluster centers of two consecutive iterations to declare convergence.\n    random_state = 0 # this is the default value. Determines random number generation for centroid initialization. Use an int to make the randomness deterministic.\n)","bed4cbcb":"# method to compute the clusters and assign the labels\ny_predicted_sub = km2.fit_predict(df_sub_cluster)\ny_predicted_sub","e64009b6":"# add the cluster column to the dataframe \ndf_sub_cluster['sub_clusters'] = y_predicted_sub\ndf_sub_cluster.head()","89497637":"# calculate Sum of Squared Errors (SSE), also called distorsions,  for a range of number of cluster - with df scaled with StandardScaler\n\nsse = []\nfor i in range(1, 11):\n    km2 = KMeans(\n        n_clusters=i, init='random',\n        n_init=10, max_iter=300,\n        tol=1e-04, random_state=0\n    )\n    km2.fit(df_sub_cluster)\n    sse.append(km2.inertia_)\n\n# plot\nplt.plot(range(1, 11), sse, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('SSE')\nplt.show()","8fa23f07":"# bring dataset with real values\n# add cluster column to original dataset with countries and non-scaled values\nsub_cluster_mpi['sub_clusters'] = y_predicted_sub.tolist()\nsub_cluster_mpi","8cfa77f0":"# bring dataset with real values\n# add cluster column to original dataset with countries and non-scaled values\n# eliminate the column that contains the country information and cluster as only numeric values should be used in this case for unsupervised learning\nsub_cluster_narrow = sub_cluster_mpi.drop(['exports','health','cluster','imports','income','inflation','life_expec','total_fer','mpi_rural'], axis =1)\nsub_cluster_narrow.head()","1642f502":"# load example dataset from seaborn \nsns.get_dataset_names()\n\n# plot\nsns.load_dataset('penguins')\nsns.pairplot(sub_cluster_narrow, hue=\"sub_clusters\")\n\n# title\nplt.suptitle('Pair Plot of Sub Clusters by Feature', \n             size = 20);","0ea6ecb8":"# change column name\nworld_copy = world.copy()\nworld_copy.rename(columns = {'name' : 'country'}, inplace = True)\nworld_copy.head()\n\n# append geodataframe data with data_combined data\nworld_data = pd.merge(\n        sub_cluster_narrow,\n        world_copy,\n        on='country',\n        how= 'inner'\n)\n\n# convert df into geodf\nworld_data = gdf(world_data)\n\n# plot \nimport geoplot\nimport mapclassify\nclusters = world_data['sub_clusters']\n\n\n# Note: this code sample requires geoplot>=0.4.0.\ngeoplot.choropleth(\n    world_data, \n    hue=clusters,\n    cmap='Greys', \n    figsize=(12, 6),\n    legend = True\n)","392e5f12":"# sub_cluster 0 \nsub_cluster_0 = sub_cluster_narrow.loc[sub_cluster_narrow['sub_clusters'] == 0]\n\n# list of countries in this country\nsub_cluster_0.country.unique()","d9cb2f1f":"# Declaring the figure or the plot (y, x) or (width, height)\nplt.figure(figsize=[14, 10])\n\n# Passing the parameters to the bar function, this is the main function which creates the bar plot\n# For creating the horizontal make sure that you append 'h' to the bar function name\nplt.barh(sub_cluster_0['country'], sub_cluster_0['mpi_urban'], label = \"MPI urban\", color = 'r')\n# Creating the legend of the bars in the plot\nplt.legend()\n# Namimg the x and y axis\nplt.xlabel('MPI')\nplt.ylabel('Countries')\n# Giving the tilte for the plot\nplt.title('MPI by Country')\n\n# Displaying the bar plot\nplt.show()","86e20f70":"# Declaring the figure or the plot (y, x) or (width, height)\nplt.figure(figsize=[14, 10])\n\n# Passing the parameters to the bar function, this is the main function which creates the bar plot\n# For creating the horizontal make sure that you append 'h' to the bar function name\nplt.barh(sub_cluster_0['country'], sub_cluster_0['child_mort'], label = \"Child Mortality\", color = 'g')\n# Creating the legend of the bars in the plot\nplt.legend()\n# Namimg the x and y axis\nplt.xlabel('Child Mortality')\nplt.ylabel('Countries')\n# Giving the tilte for the plot\nplt.title('Child Mortality by Country')\n\n# Displaying the bar plot\nplt.show()","d9f3d7c6":"# sub_cluster 1 \nsub_cluster_1 = sub_cluster_narrow.loc[sub_cluster_narrow['sub_clusters'] == 1]\n\n# list of countries in this country\nsub_cluster_1.country.unique()","fc78f6e1":"# Declaring the figure or the plot (y, x) or (width, height)\nplt.figure(figsize=[14, 10])\n\n# Passing the parameters to the bar function, this is the main function which creates the bar plot\n# For creating the horizontal make sure that you append 'h' to the bar function name\nplt.barh(sub_cluster_1['country'], sub_cluster_1['mpi_urban'], label = \"MPI urban\", color = 'r')\n# Creating the legend of the bars in the plot\nplt.legend()\n# Namimg the x and y axis\nplt.xlabel('MPI')\nplt.ylabel('Countries')\n# Giving the tilte for the plot\nplt.title('MPI by Country')\n\n# Displaying the bar plot\nplt.show()","001c712f":"# Declaring the figure or the plot (y, x) or (width, height)\nplt.figure(figsize=[14, 10])\n\n# Passing the parameters to the bar function, this is the main function which creates the bar plot\n# For creating the horizontal make sure that you append 'h' to the bar function name\nplt.barh(sub_cluster_1['country'], sub_cluster_1['child_mort'], label = \"Child Mortality\", color = 'g')\n# Creating the legend of the bars in the plot\nplt.legend()\n# Namimg the x and y axis\nplt.xlabel('Child Mortality')\nplt.ylabel('Countries')\n# Giving the tilte for the plot\nplt.title('Child Mortality by Country')\n\n# Displaying the bar plot\nplt.show()","87a82ed9":"# sub_cluster 2 \nsub_cluster_2 = sub_cluster_narrow.loc[sub_cluster_narrow['sub_clusters'] == 2]\n\n# list of countries in this country\nsub_cluster_2.country.unique()","2f133eb8":"**Findings** \n\nAre there feature(s) that we could do without due to having high correlation with another feature?\n\nAfter looking at Pearson, Kendall and Spearman correlation, we can see that there are a few features that might be considered for elimination due to high correlation.\n\n- life_expect, due to high correlation with child mortality\n- total_fertility, due to high correlation with child mortality\n- income, due to high correlation with gdpp\n","d8e99581":"**Cluster 1: This cluster is characterised by having the most negative values: high child mortality, lowest economic development, low gdpp, exports and imports, lowest life expectancy**\n\n- child mortality, highest\n- exports, lowest\n- gdpp, lowest\n- health, same as cluster 0\n- imports, lowest\n- income, significantly lower than other clusters\n- inflation, highest\n- life_expect, +50 years\n- total_fer, highest, 5 children per woman (number of children that would be born to each woman if the current age-fertility rates remain the same)","92c5cce5":"### <a id='31'>3.1. Data description<\/a>","8dccc005":"## <a id='7'>7. Further analysis to complement clustering <\/a>\n\n","d0844766":"**Feature Description** \n\n* ISO: Unique ID for country\n* Country: country name\n* MPI Urban: Multi-dimensional poverty index for urban areas within the country\n* Headcount Ratio Urban: Poverty headcount ratio (% of population listed as poor) within urban areas within the country\n* Intensity of Deprivation Urban: Average distance below the poverty line of those listed as poor in urban areas\n* MPI Rural: Multi-dimensional poverty index for rural areas within the country\n* Headcount Ratio Rural: Poverty headcount ratio (% of population listed as poor) within rural areas within the country\n* Intensity of Deprivation Rural: Average distance below the poverty line of those listed as poor in rural areas\n\n\nFor the purpose of this analysis we will focus on **MPI Urban** and **MPI Rural**. This is because the MPI measure reflects both:\n\na) the incidence of poverty (the percentage of the population who are poor) and, \n\nb) the intensity of poverty (the percentage of deprivations suffered by each person or household on average). M0 is calculated by multiplying the incidence (H) by the intensity (A). M0 = H x A.","71557efb":"#### With standardised data + PCA","bfa17231":"#### PCA with data scaled with MinMaxScaler","ad82a6e9":"**Findings**\n\nAfter running the K-Means model with the a normalised dataset, a standardised dataset, and a PCA with 4 components (with standardised scaling) we can see that the optimal number of clusters is still 3 with different levels of inertia. Two clusters could also be considered as per results of dataset after PCA.","0d174271":"#### With normalised data","70b8cafa":"### <a id='72'>7.2. Further analysis of clusters<\/a>","5f228204":"#### Visualise clusters by feature, scaled data with StandardScaler and with reduction of features with PCA","19c8ec10":"We identified that there are about 2 or 3 clusters with high levels of overlapping, therefore we need to explore further analysis that can help us answer the question at hand with more supporting evidence. \n\nFor this we'll incorporate a new feature called **Multidimensional Poverty Index (MPI)** from the [Multidimensional Poverty Measures](http:\/\/www.kaggle.com\/ophi\/mpi) dataset. \n\n*The global Multidimensional Poverty Index (MPI) is an international measure of acute multidimensional poverty covering over 100 developing countries. \nIt complements traditional monetary poverty measures by capturing the acute deprivations in health, education, and living standards that a person faces simultaneously. Read more about the MPI [here](http:\/\/ophi.org.uk\/multidimensional-poverty-index\/).*\n\nThe MPI will act as the Dependent Variable (DV) and the data we already been working on will act as the Independent Variables (IV). We'll use Multiple Linear Regression as a way to quantify the relationship between several IV and a DV. ","23240ec5":"## <a id='5'>5. Model: K-Means Clustering<\/a>","30b4dd10":"### <a id='51'>5.1. Model set up<\/a>","f083bf4b":"Because we've decided to do further analysis of clusters 0 and 1 in 7.4. Further clustering of clusters, we'll dedicate this step to further analysing cluster 2, to further understand how is it composed and if there are countries in this clusters which might be reconsidered for the final recomendation of funding. ","e1bf2315":"We'll run a simple linear regression model for all features (IV) from the original dataset and use MPI urban as the DV.","981b769b":"#### Visualise clusters by feature, scaled data with MinMaxScaler (normalisation)","d91127a9":"**Findings** \n\nOutliers found in features in this cluster are generally more positive and distant from values from clusters 0 and 1. Countries in this cluster are not going to be considered for funding. ","a9587c5f":"**Feature Description** \n\n* country:      Name of the country\n\n* child_mort:   Death of children under 5 years of age per 1000 live births\n\n* exports:      Exports of goods and services per capita. Given as %age of the GDP per capita\n\n* health:       Total health spending per capita. Given as %age of GDP per capita\n\n* imports:      Imports of goods and services per capita. Given as %age of the GDP per capita\n\n* Income:       Net income per person\n\n* Inflation:    The measurement of the annual growth rate of the Total GDP\n\n* life_expec:   The average number of years a new born child would live if the current mortality patterns are to remain the same\n\n* total_fer:    The number of children that would be born to each woman if the current age-fertility rates remain the same\n\n* gdpp:         The GDP per capita. Calculated as the Total GDP divided by the total population","493e66e4":"## <a id='4'>4. Data evaluation and reduction<\/a>","ded5d714":"**Findings**\n\n* Multicollinearity: Income and GDP per Person (gdpp) show high multicollinearity with MPI urban.\n\n* Heteroscedasticity: Based on the interpretation of the 'Residuals vs Feature\" plot these are the features that might show heteroscedasticity: child_mort, income, total,fert, life_expec (\"cone\" shape of fitted values as opposed to randomly scattered).\n\n\n","e44e1953":"**Findings**\n\nLooking at the data distribution we can see that there are some features that do indeed have outliers.\n\nFor the purpose of this analysis, outliers will not be removed since they could be considered very informative in that they could point out countries that are in critical condition and in need of help.\n\nFor example, Child Mortality is a strong indicator of poverty and necessity, so the outliers in this feature show that there are countries with a higher than normal\/critical number in child mortality.\n ","f1d58faa":"#### Look for additional countries from other clusters","e9c3b3b7":"**Cluster 2: This cluster is characterised by showing really strong or positive values such as good economic development, high life expectancy, low child mortality**\n\n\n- child mortality, lowest\n- exports,  highest\n- gdpp, highest by a lot\n- health, higher than both other clusters\n- imports, highest\n- income, significantly higher than other clusters\n- inflation, lowest\n- life_expect, +80 years\n- total_fer, lowest age-fertility rate, 1 child per woman (number of children that would be born to each woman if the current age-fertility rates remain the same)\n","3f3918d3":"Why scale the data in this case? \n\n* the features have incomparable units (metrics are percentages, dollar values, whole numbers)\n* the range values of the features also vary (one for example is 0 to 200, and another 0 to 100,000), so here for example, a change of 50 in one feature is quite significant, whereas in another it is almost unnoticeable\n* this level of variance can negatively impact the performance of this model, as this model is based on measuring distances, it can do this by giving more weight to some features \n* by scaling we are removing potential bias that the model can have towards features with higher magnitudes\n","3558ade7":"**Findings**\n\nSilhouette Scores are very close to 0 indicating that clusters are overlapping. An increase in clusters (to 5 for example) shows that there are negative values in the scale, meaning that this n of clusters might have samples that have been assigned to the wrong cluster.","d515a977":"## <a id='intro'>1. Intoduction<\/a>","18fe9058":"### <a id='73'>7.3. Linear and Multivariate regression<\/a>","7606005c":"### <a id='73a'>7.3.a. Linear regression<\/a>","269cdfd8":"**About this Notebook**\n\nThis notebook is a deliverable from my experience being a part of the **BIPOC programme** here at Kaggle. I applied to the Kaggle BIPOC programme because I want to develop skills to create impactful use of data to help society and its members thrive and progress their quality of life. This particular case was very interesting to me because having worked in the NfP\/education\/D&I sectors before, I came across similar cases where this application of ML would have been *very* useful to support my stakeholders.\n\nThis is a comprehensive notebook in which I explore many alternatives at every step of the analysis. This notebook provides a range of approaches and my interpretation of them, as opposed to a clear-cut, *straight to the point* notebook with an efficient solution. This has helped me learn about more tools, practice coding, and develop my analytical thinking. I added notes about my **Findings** throughout the notebook and links to the sources that have helped towards its development. \n\nI'd also like to give a special thanks to my mentor Frank for his guidance in this programme and for his help in this and my other notebooks and all the learnings that came with them. \n\n","820bbec7":"- <a href='#intro'>1. Introduction<\/a>\n- <a href='#2'>2. Libraries and datasets<\/a>\n     - <a href='#21'>2.1 Import libraries and packages<\/a>\n     - <a href='#22'>2.2 Import data<\/a>\n- <a href='#3'>3. Data description and distribution<\/a>\n    - <a href='#31'>3.1. Data description<\/a> \n    - <a href='#32'>3.2. Data distribution<\/a>\n- <a href='#4'>4. Data evaluation and reduction<\/a>\n    - <a href='#41'>4.1. Correlation<\/a>\n    - <a href='#42'>4.2. Scaling<\/a> \n    - <a href='#43'>4.3. PCA: Principal Component Analysis<\/a> \n- <a href='#5'>5. Model: K-Means Clustering<\/a>\n    - <a href='#51'>5.1. Model set up<\/a>\n    - <a href='#52'>5.2. Optimal number of clusters: Elbow Method<\/a>\n    - <a href='#53'>5.3. Optimal number of clusters: Silhouette Method<\/a>\n- <a href='#6'>6. Cluster analysis<\/a>\n    - <a href='#61'>6.1. Cluster plotting and visualisation<\/a>\n    - <a href='#62'>6.2. Cluster characteristics<\/a>\n    - <a href='#63'>6.3. Cluster descriptions<\/a>\n    - <a href='#64'>6.4. Clusters and their location in the world<\/a>   \n- <a href='#7'>7. Further analysis to complement clustering <\/a>\n    - <a href='#71'>7.1. Dropping features with high correlation<\/a>   \n    - <a href='#72'>7.2. Further analysis of clusters<\/a>  \n    - <a href='#73'>7.3. Linear and Multivariate regression<\/a>\n        - <a href='#73a'>7.3.a. Linear regression<\/a>\n        - <a href='#73b'>7.3.b. Multivariate regression<\/a>\n    - <a href='#74'>7.4. Further clustering of clusters<\/a>   \n- <a href='#8'>8. Answer to the question and learnings<\/a>\n- <a href='#9'>9. References<\/a>","39d86996":"### <a id='71'>7.1. Dropping features with high correlation<\/a>\n\n","2f11945b":"### <a id='62'>6.2. Cluster characteristics<\/a>","76e252e4":"### <a id='42'>4.2. Scaling<\/a>","55da72fa":"#### Comparing scaling methods","3c5f2e20":"We can use the findings that we've found so far to narrow our features and run a new clustering model.\n\nWe'll include countries listed on clusters 0 and 1 and combine them to work on a new dataset. The features that we will use to cluster this new dataset are \n\n* child_mort: child mortality is a strong indicator of need for development aid\n* gdpp: to include a monetary measure more related to traditional measures of poverty\/development \n* MPI urban: captures not only the proportion of the population in poverty but also the intensity of these deprivations","95cb87c3":"\nWe've evaluated the results of the clustering by: \n\n  a) plotting the relationship of features by cluster in Cluster plotting\n\n  b) comparing average values of each feature in Cluster characteristics\n\n\nBased on an initial assessment of the average values of each cluster, *Cluster 1* could be focus for further analysis. However, when we plot the clusters and look at the graphs, we see that there is overlapping of clusters as well as spread out clusters.\n\nUtilising PCA as an alternative did not result in a significant difference.\n\nWe've been able to identify some patters in the data and group countries into 3 clusters. However, we should not rely solely on this result to make the recommendation of countries that should receive funding. There are a few alternatives to explore before we can make this recommendation. \n\nThe implementation of a clustering model in this case did not bring up patters that we might have not found otherwise, in a way, it only confirmed general knowledge of intuition about this topic. The clustering can be considered as a preprocessing step and further analysis is required. Here are some alternatives to explore:\n","d5bbf6cd":"#### With all features of the original dataset","8f37dfe7":"## <a id='9'>9. References<\/a>","1dc81a6b":"### <a id='53'>5.3. Optimal number of clusters: Silhouette Method<\/a>","c7feb813":"**Answer to the question**\n\nRecommended countries to allocate funding for development aid: \n\n* Countries listed on sub cluster 2, with most critical results based on MPI, child mortality and GDP\/person: Benin, Burkina Faso, Burundi, Central African Republic, Chad, Cote d'Ivoire, Gambia, Guinea, Guinea-Bissau,Haiti, Mali, Mozambique, Niger, Nigeria, Sierra Leone.\n\n* Countries listed on sub clusters 0 and 1, with critieral results of MPI: Liberia and Tmor-Leste, and child mortality: Cameroon.\n\n\n**Learnings**\n\n* The clustering method alone was not sufficient to provide a final recommendation, however it did contribute to guide actions for further analysis and explore the data in more detail. \n\n* Further analysis could be done by adding more features related to the context and constraints that the recommended countries might be facing, or systemic challenges that could hinder funding value. Issues like corruption, political\/civic society crisis\/ natural disasters and other risks could expand this analysis to develop a more suitable criteria for funding depending on the current context of a country beyond these macro indicators.\n","e8589064":"#### With features with highest R-squared value found on linear regression","273d9118":"**Findings**\n\nAfter running the model with 2 types of scaling and using PCA, we can see there tends to be overlapping between clusters.\nCluster 2 is more spread out and clusters 0 and 1 tend to overlap.","d4215a72":"**Findings**\n\n* small dataset\n* no missing values\n* no duplicate values\n* some outliers and skewed distribution","c8a2c7c9":"**Findings** \n\nDropping the features identified as having high correlation earlier in this notebook has resulted in 2 clusters with high inertia. There are no significant changes compared to what we have found in previous steps. ","6599361e":"**Findings**\n\n* With all features of the original dataset: the adjusted R-squared value is >80% which is considered a good result, but we need to consider that there are features included there which show multicolliearity and heteroscedasticity. This means that the model might not have been well-fitted. This is because every time you add a predictor to a model, the R-squared increases, even if due to chance alone. Consequently, a model with more terms may appear to have a better fit simply because it has more terms, but this does not necessarily mean it is the best selection of features.\n\n* Without features with multicollinearity and heteroscedasticity: the adjusted R-squared value significantly decreases to 39% if we only select the features that did not have multicollinearity and heteroscedasticity when running simple linear regression with them. \n\n* With features with highest R-squared value found on simple linear regression: the adjusted R-squared value is of 79%. Based on initial correlation analysis of these features, they have high positive correlation.","397b88fa":"## <a id='8'>8. Answer to the question and learnings<\/a>","51da552e":"#### PCA with data scaled with StandardScaler","87d5935d":"**Libraries and Code**\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.cluster.KMeans.html\n\nhttps:\/\/seaborn.pydata.org\/generated\/seaborn.load_dataset.html\n\nhttps:\/\/seaborn.pydata.org\/generated\/seaborn.pairplot.html\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n\nPCA in Python:  https:\/\/www.youtube.com\/watch?v=Lsue2gEM9D0 , https:\/\/www.youtube.com\/watch?v=SBYdqlLgbGk\n\nhttps:\/\/geopandas.org\/docs\/user_guide\/mapping.html\n\n**PCA**\n\nhttps:\/\/builtin.com\/data-science\/step-step-explanation-principal-component-analysis\n\nhttps:\/\/online.stat.psu.edu\/stat505\/lesson\/11\/11.4\n\n\n**Similar Cases**\n\nhttps:\/\/upzoning.berkeley.edu\/download\/Classifying_Neighborhoods_Methodology.pdf\n\n\n**K-Means Model**\n\nhttps:\/\/www.youtube.com\/watch?v=EItlUEPCIzM&list=LL&index=1\n\nhttps:\/\/towardsdatascience.com\/k-means-clustering-with-scikit-learn-6b47a369a83c\n\nhttps:\/\/medium.com\/analytics-vidhya\/why-is-scaling-required-in-knn-and-k-means-8129e4d88ed7\n\nhttps:\/\/developer.squareup.com\/blog\/so-you-have-some-clusters-now-what\/\n\n\n**Visualisations**\n\nhttps:\/\/towardsdatascience.com\/visualizing-data-with-pair-plots-in-python-f228cf529166\n\nhttps:\/\/towardsdatascience.com\/mastering-the-bar-plot-in-python-4c987b459053\n\n\n**Silhouette Score**\n\nhttps:\/\/dzone.com\/articles\/kmeans-silhouette-score-explained-with-python-exam\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.silhouette_score.html\n\n\n\n**Linear Regression**\n\nhttps:\/\/www.statology.org\/adjusted-r-squared-in-python\/\n\nhttps:\/\/statisticsbyjim.com\/regression\/interpret-r-squared-regression\/\n\nhttps:\/\/www.statology.org\/residual-plot-python\/\n\nhttps:\/\/www.statology.org\/heteroscedasticity-regression\/\n\nhttps:\/\/towardsdatascience.com\/how-do-you-check-the-quality-of-your-regression-model-in-python-fa61759ff685\n\n\n\n\n\n\n\n\n","f4dee27a":"### <a id='74'>7.4. Further clustering of clusters<\/a>","5bf90bed":"# Using ML to Allocate Funding for Development Aid\n\n### Find here: Unsupervised Learning with K-Means Clustering, Cluster Analysis, Regression","71922937":"#### Scale the data: StandardScaler (standardised)","8941e8bf":"### <a id='64'>6.4. Clusters and their location in the world<\/a>","9a7f94aa":"**Background**\n\nAccording to the International Monetary Fund (IMF), *development aid* is aid given by governments and other agencies to support the economic, environmental, social, and political development of developing countries.\n\n\n**Problem Statement (taken from Dataset)**\n\nHELP International have been able to raise around 10 million dollars. Now the CEO of the NGO needs to decide how to use this money strategically and effectively. \n\nSo, the CEO has to make decision to choose the countries that are in the direst need of aid. \n\nHence, the goal is to categorise the countries using some socio-economic and health factors that determine the overall development of the country. Then you need to suggest the countries which the CEO needs to focus on the most.\n\n### Which countries should receive funding and why?","9678db17":"**Findings**\n\nAfter completing the clustering of clusters exercise we can see that countries listed on sub_cluster 2 have the most critical measures of child_mortality, MPI and gdpp.\n","30f7f4ac":"#### With standardised data\n\n","a2ecc799":"### <a id='52'>5.2. Optimal number of clusters: Elbow Method<\/a>","ac351cf2":"#### Visualise clusters by feature, scaled data with StandardScaler (standardisation)","79f8770c":"### <a id='32'>3.2. Data distribution<\/a>","40aebb56":"### <a id='21'>2.1. Import libraries and packages<\/a>","10c8052d":"#### Without features with multicollinearity and heteroscedasticity","d081b425":"**Findings**\n\nAfter doing PCA with both standardised and normalised versions of the original dataset, we can see that there are 4 principal components can explain about 90% of the distribution of the original data.\n","59bf846e":"### <a id='423'>4.3. PCA: Principal Component Analysis<\/a>","547a2a9a":"## <a id='2'>2. Libraries and datasets<\/a>","6a6378a8":"#### Visualise clusters by feature, original data with no scaling","00df92ed":"### <a id='73b'>7.3.b. Multivariate regression<\/a>","a0b3d00f":"**Findings**\n\nMPI urban and rural have high correlation. MPI urban to be considered as DV.\nFeatures with high correlation with MPI urban are child_mort, income, life_expect, total_fer, gdpp.\nWe'll keep child_mort and not use life_expect and total_fer as they are highly correlated and there might be *multicollinearity* between them. \n","5cc5ffdb":"## <a id='3'>3. Data description and distribution<\/a>","f3fb93ec":"## <a id='6'>6. Cluster analysis<\/a>","7e585658":"**Cluster 0: This cluster is characterised by showing average values for all features when comparing with other clusters**\n\n- child mortality,    avg\n- exports,            avg\n- gdpp,               avg\n- health,             same as cluster 1\n- imports,            avg\n- income,             avg\n- inflation,          avg\n- life_expect,        +70 years\n- total_fer,          avg, 2 children per woman (number of children that would be born to each woman if the current age-fertility rates remain the same)","792f5034":"### <a id='22'>2.2. Import data<\/a>","78cfca96":"#### Scaled dataframes","40b48e31":"#### Scale the data: MinMaxScaler (normalised)","a6d3bc24":"**Findings**\n\n* Countries in Cluster 2 (characterised by showing really strong or positive values such as good economic development, high life expectancy, low child mortality) are located in North America, Europe, Oceania and a couple in Asia. \n* Countries in Cluster 1 (characterised by having the most negative values: high child mortality, lowest economic development) are located across Africa and Asia.\n* Countries in Cluster 0 (characterised by showing average values for all features when comparing with other clusters) are located across South America, parts of Africa, Europe and Asia.\n\nBlank spaces (like Mexico) are of countries with no available data.","76ec6102":"#### Run model with different versions of the dataset","c696e436":"### <a id='63'>6.3. Cluster descriptions<\/a>","2e92491b":"### <a id='41'>4.1. Correlation<\/a>","38ee2fdc":"### <a id='61'>6.1. Cluster plotting and visualisation<\/a>"}}