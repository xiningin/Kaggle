{"cell_type":{"9b209f62":"code","f191c01f":"code","e3950773":"code","649d67c5":"code","57edd9f8":"code","d6fb14d7":"code","093c9a4f":"code","730f7ef4":"code","91e1b9a0":"code","dfd2f4e8":"code","3eb59446":"code","7c43765b":"code","f4d2e84b":"code","7b1fa0d2":"code","fa0cd70b":"code","96d91b92":"code","f732fcf4":"code","85b261ab":"code","da9c6f31":"code","d043109b":"code","e3ea1c29":"code","cc001e5c":"code","1bc6d9d0":"code","5317ff8f":"code","59738dea":"code","e0d3b75c":"code","377b77f0":"code","7f88cf95":"code","92d6929e":"code","fe36e11b":"code","c50e644d":"code","dbbe58fc":"code","ce53be82":"code","6dd92bc2":"code","b19c16a4":"code","840ef29a":"code","d5b797c4":"code","19024c43":"code","8f78b29e":"code","5a9f0d96":"code","c307dd1a":"code","bcd90025":"code","be093d1b":"code","ee5dc6d8":"code","72a2b293":"code","08c9b83c":"code","980fc8fa":"code","8853cafb":"code","b081f81f":"code","8e554838":"code","138f8a46":"code","8b088deb":"code","1411b984":"code","62a365b0":"code","f24c6066":"code","014567c3":"code","f58c46b4":"code","d9077201":"code","b352e92c":"code","0063bdff":"markdown","a0ccc48f":"markdown","3d951953":"markdown","2d7f9e92":"markdown","9b97f264":"markdown","bb68f4ff":"markdown","b496d63c":"markdown","dd592f07":"markdown","de456dda":"markdown","26c32c9f":"markdown","a9c697ce":"markdown","6352987f":"markdown","a68ac4f0":"markdown","472bf8fe":"markdown","ee532912":"markdown","993c790c":"markdown","2dd5df00":"markdown"},"source":{"9b209f62":"import pandas as pd","f191c01f":"housing = pd.read_csv(\"..\/input\/real-estate-dataset\/data.csv\")","e3950773":"housing.head()","649d67c5":"housing.info()","57edd9f8":"housing['CHAS'].value_counts()","d6fb14d7":"housing.describe()","093c9a4f":"%matplotlib inline","730f7ef4":"# # For plotting histogram\nimport matplotlib.pyplot as plt\nhousing.hist(bins=50, figsize=(20, 15))","91e1b9a0":"# For learning purpose\nimport numpy as np\ndef split_train_test(data, test_ratio):\n    np.random.seed(42)\n    shuffled = np.random.permutation(len(data))\n    print(shuffled)\n    test_set_size = int(len(data) * test_ratio)\n    test_indices = shuffled[:test_set_size]\n    train_indices = shuffled[test_set_size:] \n    return data.iloc[train_indices], data.iloc[test_indices]","dfd2f4e8":"# train_set, test_set = split_train_test(housing, 0.2)","3eb59446":"# print(f\"Rows in train set: {len(train_set)}\\nRows in test set: {len(test_set)}\\n\")","7c43765b":"from sklearn.model_selection import train_test_split\ntrain_set, test_set  = train_test_split(housing, test_size=0.2, random_state=42)\nprint(f\"Rows in train set: {len(train_set)}\\nRows in test set: {len(test_set)}\\n\")","f4d2e84b":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing['CHAS']):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","7b1fa0d2":"strat_test_set['CHAS'].value_counts()","fa0cd70b":"strat_train_set['CHAS'].value_counts()","96d91b92":" 95\/7","f732fcf4":"376\/28","85b261ab":"housing = strat_train_set.copy()","da9c6f31":"corr_matrix = housing.corr()\ncorr_matrix['MEDV'].sort_values(ascending=False)","d043109b":"from pandas.plotting import scatter_matrix\nattributes = [\"MEDV\", \"RM\", \"ZN\", \"LSTAT\"]\nscatter_matrix(housing[attributes], figsize = (12,8))","e3ea1c29":"housing.plot(kind=\"scatter\", x=\"RM\", y=\"MEDV\", alpha=0.8)","cc001e5c":"housing[\"TAXRM\"] = housing['TAX']\/housing['RM']","1bc6d9d0":"housing.head()","5317ff8f":"corr_matrix = housing.corr()\ncorr_matrix['MEDV'].sort_values(ascending=False)","59738dea":"housing.plot(kind=\"scatter\", x=\"TAXRM\", y=\"MEDV\", alpha=0.8)","e0d3b75c":"housing = strat_train_set.drop(\"MEDV\", axis=1)\nhousing_labels = strat_train_set[\"MEDV\"].copy()","377b77f0":"# To take care of missing attributes, you have three options:\n#     1. Get rid of the missing data points\n#     2. Get rid of the whole attribute\n#     3. Set the value to some value(0, mean or median)","7f88cf95":"a = housing.dropna(subset=[\"RM\"]) #Option 1\na.shape\n# Note that the original housing dataframe will remain unchanged","92d6929e":"housing.drop(\"RM\", axis=1).shape # Option 2\n# Note that there is no RM column and also note that the original housing dataframe will remain unchanged","fe36e11b":"median = housing[\"RM\"].median() # Compute median for Option 3","c50e644d":"housing[\"RM\"].fillna(median) # Option 3\n# Note that the original housing dataframe will remain unchanged","dbbe58fc":"housing.shape","ce53be82":"housing.describe() # before we started filling missing attributes","6dd92bc2":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\nimputer.fit(housing)","b19c16a4":"imputer.statistics_","840ef29a":"X = imputer.transform(housing)","d5b797c4":"housing_tr = pd.DataFrame(X, columns=housing.columns)","19024c43":"housing_tr.describe()","8f78b29e":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nmy_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    #     ..... add as many as you want in your pipeline\n    ('std_scaler', StandardScaler()),\n])","5a9f0d96":"housing_num_tr = my_pipeline.fit_transform(housing)","c307dd1a":"housing_num_tr.shape","bcd90025":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n# model = LinearRegression()\n# model = DecisionTreeRegressor()\nmodel = RandomForestRegressor()\nmodel.fit(housing_num_tr, housing_labels)","be093d1b":"some_data = housing.iloc[:5]","ee5dc6d8":"some_labels = housing_labels.iloc[:5]","72a2b293":"prepared_data = my_pipeline.transform(some_data)","08c9b83c":"model.predict(prepared_data)","980fc8fa":"list(some_labels)","8853cafb":"from sklearn.metrics import mean_squared_error\nhousing_predictions = model.predict(housing_num_tr)\nmse = mean_squared_error(housing_labels, housing_predictions)\nrmse = np.sqrt(mse)","b081f81f":"rmse","8e554838":"from sklearn.metrics import r2_score","138f8a46":"# 1 2 3 4 5 6 7 8 9 10\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(model, housing_num_tr, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)","8b088deb":"rmse_scores","1411b984":"def print_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean: \", scores.mean())\n    print(\"Standard deviation: \", scores.std())","62a365b0":"print_scores(rmse_scores)","f24c6066":"from joblib import dump, load\ndump(model, 'Dragon.joblib')","014567c3":"X_test = strat_test_set.drop(\"MEDV\", axis=1)\nY_test = strat_test_set[\"MEDV\"].copy()\nX_test_prepared = my_pipeline.transform(X_test)\nfinal_predictions = model.predict(X_test_prepared)\nfinal_mse = mean_squared_error(Y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nprint(final_predictions, list(Y_test))","f58c46b4":"final_rmse","d9077201":"prepared_data[0]","b352e92c":"from joblib import dump, load\nimport numpy as np\nmodel = load('Dragon.joblib') \nfeatures = np.array([[-5.43942006, 4.12628155, -1.6165014, -0.67288841, -1.42262747,\n       -11.44443979304, -49.31238772,  7.61111401, -26.0016879 , -0.5778192 ,\n       -0.97491834,  0.41164221, -66.86091034]])\nmodel.predict(features)","0063bdff":"## Trying out Attribute combinations","a0ccc48f":"## Saving the model","3d951953":"## Scikit-learn Design","2d7f9e92":"## Using better evaluation technique - Cross Validation","9b97f264":"## Evaluating the model","bb68f4ff":"## Using the model","b496d63c":"2nd Method for Training And Testing","dd592f07":"## Creating a Pipeline","de456dda":"## Boston House - Price Predictor","26c32c9f":"## Testing the model on test data","a9c697ce":"Primarily, two types of feature scaling methods:\n1. Min-max scaling (Normalization)\n    (value - min)\/(max - min)\n    Sklearn provides a class called MinMaxScaler for this\n    \n2. Standardization\n    (value - mean)\/std\n    Sklearn provides a class called StandardScaler for this","6352987f":"## Feature Scaling","a68ac4f0":"Primarily, three types of objects\n1. Estimators - It estimates some parameter based on a dataset. Eg. imputer. It has a fit method and transform method. Fit method - Fits the dataset and calculates internal parameters\n\n2. Transformers - transform method takes input and returns output based on the learnings from fit(). It also has a convenience function called fit_transform() which fits and then transforms.\n\n3. Predictors - LinearRegression model is an example of predictor. fit() and predict() are two common functions. It also gives score() function which will evaluate the predictions.","472bf8fe":"## Train-Test Splitting","ee532912":"## Selecting a desired model for Dragon Real Estates","993c790c":"## Looking for Correlations","2dd5df00":"## Missing Attributes"}}