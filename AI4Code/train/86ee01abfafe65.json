{"cell_type":{"493bdc0b":"code","e4ad3a95":"code","9102975a":"code","44354ef0":"code","5b74ac8c":"code","4d4ee1a0":"code","547a8838":"code","6e2c21bc":"code","50452571":"code","e18e2474":"code","24081292":"code","39f9a262":"code","2a6a8e89":"code","3b699f53":"code","6e18ad94":"code","968e97af":"code","6e51f51c":"code","cfb9e7bb":"code","ca79741a":"code","cba14750":"code","24fa396c":"code","59a8c657":"code","b172af1a":"code","97dac6ee":"code","dd4dd69b":"code","1378eaac":"code","bea8f0ab":"code","ae847a18":"code","f94e91bf":"code","31f06b41":"code","398ed21f":"code","b4d263ca":"code","61c32bf8":"code","b8cc4f4f":"code","c705995a":"code","74fbec1a":"code","27efc773":"code","f0160794":"code","9eee9845":"code","fc840576":"code","2250194e":"code","d97f2efa":"code","39548313":"code","556d7ffd":"code","48e498dc":"code","ce081917":"code","7a50a16d":"code","11f78be0":"code","ce85ad98":"code","6181e73f":"code","7b9b5bdb":"code","38db8251":"code","6d999283":"code","d80c2fae":"code","49a0477a":"markdown","a126d206":"markdown","544b3122":"markdown","bb70fbb7":"markdown","769ba06b":"markdown","d5818a44":"markdown","9240a314":"markdown","a76ecb09":"markdown","60f0e1c1":"markdown","a95e52d4":"markdown","e6b7f424":"markdown","b77cc840":"markdown","bdd53b9f":"markdown","3d5c4f55":"markdown","7961acda":"markdown","df0d1d60":"markdown","096d01fb":"markdown","7ff0c70d":"markdown","58120d70":"markdown","119ef0ac":"markdown","352140e5":"markdown","39d41727":"markdown","f3598608":"markdown","e98c05de":"markdown","d6104da0":"markdown","5a54cdbc":"markdown","fdd8e8f8":"markdown"},"source":{"493bdc0b":"# Numerical libraries\nimport numpy as np   \n\n# Import Linear Regression machine learning library\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.preprocessing import Imputer\n\nfrom sklearn.preprocessing import Normalizer\n\n# to handle data in form of rows and columns \nimport pandas as pd    \n\n# importing ploting libraries\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt   \n%matplotlib inline\n#importing seaborn for statistical plots\nimport seaborn as sns","e4ad3a95":"df = pd.read_csv(\"..\/input\/Automobile_data.csv\",na_values=['?'])","9102975a":"df.head()","44354ef0":"df.info()","5b74ac8c":"df.describe()","4d4ee1a0":"na_cols = {}\nfor col in df.columns:\n    missed = df.shape[0] - df[col].dropna().shape[0]\n    if missed > 0:\n        na_cols[col] = missed\n\nna_cols","547a8838":"sum(df.isnull().any())\n#sum(df.isnull().any())","6e2c21bc":"df[np.any(df[df.columns[2:]].isnull(), axis=1)]","50452571":"df[['normalized-losses','bore','stroke','horsepower','peak-rpm']] = df[['normalized-losses','bore','stroke','horsepower','peak-rpm']].astype('float64')","e18e2474":"df.info()","24081292":"df_1 = df.copy()","39f9a262":"df_1.head()","2a6a8e89":"# Imputting Missing value\nimp = Imputer(missing_values='NaN', strategy='mean' )\ndf_1[['normalized-losses','bore','stroke','horsepower','peak-rpm','price']] = imp.fit_transform(df_1[['normalized-losses','bore','stroke','horsepower','peak-rpm','price']])\ndf_1.head()\n#########################################################################################################################","3b699f53":"df_1['num-of-doors'] = df_1['num-of-doors'].fillna('four')","6e18ad94":"# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder = LabelEncoder()\nfor i in ['make','fuel-type','aspiration', 'num-of-doors','body-style','drive-wheels','engine-location','engine-type','num-of-cylinders','fuel-system']:\n    df_1[i] = labelencoder.fit_transform(df_1[i])\ndf_1.head()","968e97af":"df_1.shape","6e51f51c":"%matplotlib inline","cfb9e7bb":"from matplotlib import pyplot as plt\n","ca79741a":"categorical = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'engine-location',\n               'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']\nfig, axs = plt.subplots(nrows=3, ncols=3, figsize=(18, 12))\nfor col, ax in zip(categorical[1:], axs.ravel()):\n    sns.countplot(x=col, data=df, ax=ax)\n","cba14750":"df_1.corr()","24fa396c":"from matplotlib import pyplot as plt\nplt.figure(figsize=(15, 15))\nax = sns.heatmap(df_1.corr(), vmax=.8, square=True, fmt='.2f', annot=True, linecolor='white', linewidths=0.01)\nplt.title('Cross correlation between numerical')\nplt.show()\n","59a8c657":"## Above graph shows Wheel base , Length , Width are highly correlated. \n## Highway mpg and city mpg is also highly correlated. \n## Compression ratio and fuel type is also correlated \n## Engine size and horse power is also correlated\ndf_2 = df_1.drop(['length','width','city-mpg','fuel-type','horsepower'],axis=1)\ndf_2.head()","b172af1a":"from matplotlib import pyplot as plt\nplt.figure(figsize=(15, 15))\nax = sns.heatmap(df_2.corr(), vmax=.8, square=True, fmt='.2f', annot=True, linecolor='white', linewidths=0.01)\nplt.title('Cross correlation between numerical')\nplt.show()\n","97dac6ee":"sns.lmplot(x= 'curb-weight' , y='price', data=df_2)","dd4dd69b":"sns.lmplot(x= 'engine-size' , y='price', hue = 'num-of-doors', data=df_2)","1378eaac":"sns.lmplot(x= 'horsepower' , y='price',hue = 'fuel-system', data=df)","bea8f0ab":"sns.lmplot(x= 'highway-mpg' , y='price', data=df)","ae847a18":"X = df_2.drop('price',axis =1)\nX.head()","f94e91bf":"# Lets use 80% of data for training and 20% for testing\n\nimport sklearn\nY = df_2['price']\nX = df_2.drop('price',axis =1)\n\nx_train, x_test, y_train,  y_test = sklearn.model_selection.train_test_split(X, Y,train_size=0.8, test_size=0.2, random_state=0)\n","31f06b41":"# Fitting Multiple Linear Regression to the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nlm_1 = regressor.fit(x_train, y_train)","398ed21f":"lm_1.score(x_train,y_train)","b4d263ca":"lm_1.score(x_test,y_test)","61c32bf8":"df_2.shape","b8cc4f4f":"df_3 = df_2.copy()","c705995a":"# Replace '-' in column names with '_'\nnames = []\nfor name in df_3.columns:\n    names.append(name.replace('-', '_'))\n\ndf_3.columns = names","74fbec1a":"df_3.info()","27efc773":"import statsmodels.formula.api as smf\n\nlm0 = smf.ols(formula= 'price ~ symboling+normalized_losses+make+aspiration+num_of_doors+body_style+drive_wheels+engine_location+wheel_base+height+curb_weight+engine_type+num_of_cylinders+engine_size+fuel_system+bore+stroke+compression_ratio+peak_rpm' , data =df_3).fit()\n","f0160794":"lm0.params","9eee9845":"print(lm0.summary())","fc840576":"from sklearn.preprocessing import Normalizer\n# Normalizing Data\nnor = Normalizer()\ndf_4 = nor.fit_transform(df_2)\n","2250194e":"col = []\nfor i in df_2.columns:\n    col.append(i.replace('-', '_'))  ","d97f2efa":"df_4 = pd.DataFrame(df_4 , columns  = col)\ndf_4.head()","39548313":"# Lets use 80% of data for training and 20% for testing\n\nimport sklearn\nY_1 = df_4['price']\nX_1 = df_4.drop('price',axis =1)\n\nx_train_1, x_test_1, y_train_1,  y_test_1 = sklearn.model_selection.train_test_split(X_1, Y_1,train_size=0.8, test_size=0.2, random_state=0)\n","556d7ffd":"# Fitting Multiple Linear Regression to the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nlm_2 = regressor.fit(x_train_1, y_train_1)\n","48e498dc":"pred_train_y = regressor.predict(x_train_1)\npred_test_y = regressor.predict(x_test_1)","ce081917":"lm_2.score(x_train_1,y_train_1)","7a50a16d":"lm_2.score(x_test_1,y_test_1)","11f78be0":"mse = np.mean((pred_test_y -y_test_1)**2)\nmse","ce85ad98":"## Residual Vs fitted plot - \nx_plot = plt.scatter(pred_test_y,(pred_test_y - y_test_1),c='b')\nplt.hlines(y=0,xmin = 0 , xmax = 1)\nplt.title('Residual plot')","6181e73f":"import statsmodels.formula.api as smf\n\nlm1 = smf.ols(formula= 'price ~ symboling+normalized_losses+make+aspiration+num_of_doors+body_style+drive_wheels+engine_location+wheel_base+height+curb_weight+engine_type+num_of_cylinders+engine_size+fuel_system+bore+stroke+compression_ratio+peak_rpm' , data =df_4).fit()\n","7b9b5bdb":"lm2 = smf.ols(formula= 'price ~ symboling+normalized_losses+make+aspiration+num_of_doors+drive_wheels+engine_location+wheel_base+height+curb_weight+engine_type+num_of_cylinders+engine_size+fuel_system+bore+stroke+compression_ratio+peak_rpm' , data =df_4).fit()","38db8251":"lm3 = smf.ols(formula= 'price ~ aspiration+num_of_doors+wheel_base+curb_weight+engine_size+fuel_system+bore+stroke+peak_rpm' , data =df_4).fit()","6d999283":"lm3.params","d80c2fae":"print(lm3.summary())","49a0477a":"##  Exploratory Data Analysis","a126d206":"## Import libraries","544b3122":"## <font color='green'>Data Dictionary<\/font>\n### Input variables\n\n 01. **symboling**:            [its assigned insurance risk rating -> [-3, -2, -1, 0, 1, 2, 3]] \n 02. **normalized-losses**:    [average loss payment per insured vehicle year -> continuous from 65 to 256.]  \n 03. make:                     [ Manufacturer name eg : alfa-romero, audi, bmw, chevrolet, dodge, honda,isuzu etc. ]\n 04. fuel-type:                [diesel, gas]\n 05. aspiration:               [std, turbo]\n 06. num-of-doors:             [four, two].\n 07. body-style:               [hardtop, wagon, sedan, hatchback, convertible]\n 08. drive-wheels:             [4wd, fwd, rwd]\n 09. engine-location:          [front, rear]\n 10. wheel-base:               [continuous from 86.6 120.9]\n 11. length:                   [continuous from 141.1 to 208.1]\n 12. width:                    [continuous from 60.3 to 72.3]\n 13. height:                   [continuous from 47.8 to 59.8]\n 14. curb-weight:              [continuous from 1488 to 4066]\n 15. engine-type:              [dohc, dohcv, l, ohc, ohcf, ohcv, rotor]\n 16. num-of-cylinders:         [eight, five, four, six, three, twelve, two]\n 17. engine-size:              [continuous from 61 to 326]\n 18. fuel-system:              [1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi]\n 19. bore:                     [continuous from 2.54 to 3.94]\n 20. stroke:                   [continuous from 2.07 to 4.17]\n 21. compression-ratio:        [continuous from 7 to 23]\n 22. horsepower:               [continuous from 48 to 288]\n 23. peak-rpm:                 [continuous from 4150 to 6600]\n 24. city-mpg:                 [continuous from 13 to 49]\n 25. highway-mpg:              [continuous from 16 to 54]\n \n ## Output Variable\n  price:                    [continuous from 5118 to 45400]\n","bb70fbb7":"### a. Analyse Data\n","769ba06b":"### d. Visualize data\n### <font color='red'> 5.Analyse the data distribution for the various attributes and share your observations. <\\font>","d5818a44":"#### This clearly shows the number of rows and columns having missing or NA values. ","9240a314":"### b. Refine & Transform\n","a76ecb09":"#### Categorical features distributions:","60f0e1c1":"## Model Builduing Part -2 ","a95e52d4":"##                                                Load data\n","e6b7f424":"## Attributes which has stronger relationship with price - \n\n## 1. Curb-Weight\n## 2. Engine-Size\n## 3. Horsepower\n## 4. Mpg(City \/ Highway mpg)\n## 5. Lenght\/ Width ","b77cc840":"## Training of the model","bdd53b9f":"## Split data into training and test data","3d5c4f55":"## R^2  = 0.98 for Train data","7961acda":"#### The above dataset has 205 rows and 26 columns which is not a good sample. We can say that it is not a good representative of the universe","df0d1d60":"#### Max Cars are running on Gas\n#### Max Cars have engine in front\n#### Max Cars have 4 cylinders\n#### Max Cars have mpfi as fuel system","096d01fb":"### There is no pattern so we can infer that data is linear and there is no Heteroskedasticity issue","7ff0c70d":"## The Above results shows Multi Linear Regression Model  with R^2  = 0.974 ","58120d70":"## Above graphs and HeatMap shows that - \n###  Wheel base , Length , Width are highly correlated. \n### Highway mpg and city mpg is also highly correlated. \n### Compression ratio and fuel type is also correlated \n### Engine size and horse power is also correlated","119ef0ac":"##### This data set consists of three types of entities:\n##### (a) the specification of an auto in terms of various characteristics \n##### (b)its assigned insurance risk rating\n##### (c) its normalized losses in use as compared to other cars.  ","352140e5":"<img src='Large10.jpg'>","39d41727":"### Linear Regression could be the best algorithm to solve such problem with better accuracy as most of the attributes (Independent Variables) follow Linear pattern with Dependent variable i.e. (Price)","f3598608":"## R^2  = 0.96 for Test data","e98c05de":"## Linear model using OLS - ","d6104da0":"###     *****Top Selling Car Manufacturer is **Toyota**\n","5a54cdbc":"# Title : 1985 Auto Imports Database Analyses ","fdd8e8f8":"### Analyse Dataset - \n##### 4 .How many records are available in the data set and how many attributes. Do you think the depth (number of records) is sufficient given the breadth? In other words, is the sample likely to be a good representative of the universe?"}}