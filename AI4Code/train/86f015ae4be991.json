{"cell_type":{"a917ebac":"code","4f153a2a":"code","0ca0d254":"code","02d6a17d":"code","c08136fa":"code","91df9093":"code","8a2792c5":"code","bbd5fbe5":"code","f2211210":"code","db926029":"code","fb35ff9d":"code","3e138162":"code","7cee8753":"code","ec4d95e1":"code","d1f3bfc9":"code","baba866f":"code","9a3c62e6":"code","3a337f5d":"code","09a27602":"code","5c480612":"code","e07a95ce":"code","fe0863be":"code","87bdc539":"code","db9783e8":"code","9c17947a":"code","386cb19b":"code","7c34fa08":"code","9f0f0e28":"code","e64df971":"code","682e1d3c":"code","c35931af":"code","45b0c956":"code","378f122a":"code","3b48bd74":"code","dd23dcc4":"code","2e95e0f5":"code","6b6a2d17":"code","e38e1795":"code","9ac74431":"markdown","16248eb2":"markdown","96a322d0":"markdown","0eb38051":"markdown","3dfefd8b":"markdown","ec8fc9b7":"markdown","aaa05f24":"markdown","b6ef500c":"markdown","b0490b96":"markdown","938d0e8b":"markdown","0baadcf0":"markdown","1bc1d1d7":"markdown","83393525":"markdown","e2f1aa41":"markdown"},"source":{"a917ebac":"pip install catalyst=='20.07'","4f153a2a":"# Python \nimport os\nimport warnings\nimport logging\nfrom typing import Mapping, List, Union, Optional, Tuple\nfrom pprint import pprint\n\n# Numpy, Pandas, Sklearn\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# PyTorch \nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# Transformers \nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\n# Catalyst\nimport catalyst\nfrom catalyst.dl import SupervisedRunner\n# this will appear in Catalyst 20.08\n# from catalyst.dl.callbacks.metrics.accuracy import MultiLabelAccuracyCallback\nfrom catalyst.dl.callbacks import OptimizerCallback, CheckpointCallback, InferCallback\nfrom catalyst.dl.utils import plot_metrics\nfrom catalyst.utils import set_global_seed, prepare_cudnn","0ca0d254":"catalyst.__version__","02d6a17d":"MODEL_NAME = 'distilbert-base-uncased' # pretrained model from Transformers\nLOG_DIR = \".\/logdir\"                   # for training logs and tensorboard visualizations\nNUM_EPOCHS = 3                         # smth around 2-6 epochs is typically fine when finetuning transformers\nBATCH_SIZE = 96                        # depends on your available GPU memory (in combination with max seq length)\nMAX_SEQ_LENGTH = 256                   # depends on your available GPU memory (in combination with batch size)\nLEARN_RATE = 3e-5                      # learning rate is typically ~1e-5 for transformers\nACCUM_STEPS = 4                        # one optimization step for that many backward passes\nSEED = 17                              # random seed for reproducibility","c08136fa":"# to reproduce, download the data and customize this path\nPATH_TO_DATA = '..\/input\/jigsaw-toxic-comment-classification-challenge\/'\nTEXT_FIELD = 'comment_text'\nTARGET_FIELDS = ['toxic','severe_toxic','obscene','threat','insult', 'identity_hate']\nNUM_CLASSES = len(TARGET_FIELDS)\nPRED_THRES = 0.4   ","91df9093":"train_df = pd.read_csv(PATH_TO_DATA + 'train.csv.zip', index_col='id')\ntest_df = pd.read_csv(PATH_TO_DATA + 'test.csv.zip', index_col='id')","8a2792c5":"train_df.info()","bbd5fbe5":"test_df.info()","f2211210":"train_df.head(2)","db926029":"X_train, X_valid, y_train, y_valid = train_test_split(train_df[TEXT_FIELD],\n                                                      train_df[TARGET_FIELDS], \n                                                      test_size=0.1, \n                                                      random_state=17)\nX_test = test_df[TEXT_FIELD]","fb35ff9d":"len(X_train), len(X_valid), len(X_test)","3e138162":"class TextClassificationDataset(Dataset):\n    \"\"\"\n    Wrapper around Torch Dataset to perform text classification\n    \"\"\"\n    def __init__(self,\n                 texts: List[str],\n                 labels: np.ndarray = None,\n                 max_seq_length: int = 512,\n                 model_name: str = 'distilbert-base-uncased'):\n        \"\"\"\n        Args:\n            texts (List[str]): a list with texts to classify or to train the\n                classifier on\n            labels List[str]: \n            max_seq_length (int): maximal sequence length in tokens,\n                texts will be stripped to this length\n            model_name (str): transformer model name, needed to perform\n                appropriate tokenization\n\n        \"\"\"\n\n        self.texts = texts\n        self.labels = labels\n        self.max_seq_length = max_seq_length\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        # suppresses tokenizer warnings\n        logging.getLogger(\n            \"transformers.tokenization_utils\").setLevel(logging.FATAL)\n\n    def __len__(self):\n        \"\"\"\n        Returns:\n            int: length of the dataset\n        \"\"\"\n        return len(self.texts)\n\n    def __getitem__(self, index) -> Mapping[str, torch.Tensor]:\n        \"\"\"Gets element of the dataset\n\n        Args:\n            index (int): index of the element in the dataset\n        Returns:\n            Single element by index\n        \"\"\"\n\n        # encoding the text\n        x = self.texts[index]\n        \n        # a dictionary with `input_ids` and `attention_mask` as keys\n        output_dict = self.tokenizer.encode_plus(\n            x,\n            add_special_tokens=True,\n            pad_to_max_length=True,\n            max_length=self.max_seq_length,\n            return_tensors=\"pt\",\n            return_attention_mask=True\n        )\n        \n        # for Catalyst, there needs to be a key called features\n        output_dict['features'] = output_dict['input_ids'].squeeze(0)\n        del output_dict['input_ids']\n        \n        # encoding target\n        if self.labels is not None:\n            output_dict[\"targets\"] = torch.from_numpy(self.labels[index]).float()\n\n        return output_dict","7cee8753":"train_dataset = TextClassificationDataset(\n    texts=X_train.values.tolist(),\n    labels=y_train.values,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)\n\nvalid_dataset = TextClassificationDataset(\n    texts=X_valid.values.tolist(),\n    labels=y_valid.values,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)\n\ntest_dataset = TextClassificationDataset(\n    texts=X_test.values.tolist(),\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)","ec4d95e1":"train_df.iloc[0]","d1f3bfc9":"pprint(train_dataset[0])","baba866f":"train_val_loaders = {\n    \"train\": DataLoader(dataset=train_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=True),\n    \"valid\": DataLoader(dataset=valid_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=False)    \n}","9a3c62e6":"class BertForSequenceClassification(nn.Module):\n    \"\"\"\n    Simplified version of the same class by HuggingFace.\n    See transformers\/modeling_distilbert.py in the transformers repository.\n    \"\"\"\n\n    def __init__(self, pretrained_model_name: str, num_classes: int = None, dropout: float = 0.3):\n        \"\"\"\n        Args:\n            pretrained_model_name (str): HuggingFace model name.\n                See transformers\/modeling_auto.py\n            num_classes (int): the number of class labels\n                in the classification task\n        \"\"\"\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(\n            pretrained_model_name, num_labels=num_classes)\n\n        self.model = AutoModel.from_pretrained(pretrained_model_name,\n                                                    config=config)\n#         self.pre_classifier = nn.Linear(config.hidden_size, config.hidden_size)\n        self.classifier = nn.Linear(config.hidden_size, num_classes)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, features, attention_mask=None, head_mask=None):\n        \"\"\"Compute class probabilities for the input sequence.\n\n        Args:\n            features (torch.Tensor): ids of each token,\n                size ([bs, seq_length]\n            attention_mask (torch.Tensor): binary tensor, used to select\n                tokens which are used to compute attention scores\n                in the self-attention heads, size [bs, seq_length]\n            head_mask (torch.Tensor): 1.0 in head_mask indicates that\n                we keep the head, size: [num_heads]\n                or [num_hidden_layers x num_heads]\n        Returns:\n            PyTorch Tensor with predicted class probabilities\n        \"\"\"\n        assert attention_mask is not None, \"attention mask is none\"\n        \n        bert_output = self.model(input_ids=features,\n                                            attention_mask=attention_mask,\n                                            head_mask=head_mask)\n        # we only need the hidden state here and don't need\n        # transformer output, so index 0\n        seq_output = bert_output[0]  # (bs, seq_len, dim)\n        # mean pooling, i.e. getting average representation for all tokens\n        pooled_output = seq_output.mean(axis=1)  # (bs, dim)\n        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n        logits = self.classifier(pooled_output)  # (bs, dim)\n\n        return logits","3a337f5d":"model = BertForSequenceClassification(pretrained_model_name=MODEL_NAME,\n                                      num_classes=NUM_CLASSES)","09a27602":"# d = next(iter(train_val_loaders['train']))\n# p = model(d['features'], d['attention_mask'])\n# criterion(p, d['targets'])","5c480612":"criterion = torch.nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)","e07a95ce":"from catalyst.core import MetricCallback\nfrom catalyst.utils.torch import get_activation_fn\n\ndef preprocess_multi_label_metrics(\n    outputs: torch.Tensor,\n    targets: torch.Tensor,\n    weights: Optional[torch.Tensor] = None,\n) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    General preprocessing and check for multi-label-based metrics.\n    Args:\n        outputs (torch.Tensor): NxK tensor that for each of the N examples\n            indicates the probability of the example belonging to each of\n            the K classes, according to the model.\n        targets (torch.Tensor): binary NxK tensor that encodes which of the K\n            classes are associated with the N-th input\n            (eg: a row [0, 1, 0, 1] indicates that the example is\n            associated with classes 2 and 4)\n        weights (torch.Tensor): importance for each sample\n    Returns:\n        processed ``outputs`` and ``targets``\n        with [batch_size; num_classes] shape\n    \"\"\"\n    if not torch.is_tensor(outputs):\n        outputs = torch.from_numpy(outputs)\n    if not torch.is_tensor(targets):\n        targets = torch.from_numpy(targets)\n    if weights is not None:\n        if not torch.is_tensor(weights):\n            weights = torch.from_numpy(weights)\n        weights = weights.squeeze()\n\n    if outputs.dim() == 1:\n        outputs = outputs.view(-1, 1)\n    else:\n        assert outputs.dim() == 2, (\n            \"wrong `outputs` size \"\n            \"(should be 1D or 2D with one column per class)\"\n        )\n\n    if targets.dim() == 1:\n        targets = targets.view(-1, 1)\n    else:\n        assert targets.dim() == 2, (\n            \"wrong `targets` size \"\n            \"(should be 1D or 2D with one column per class)\"\n        )\n\n    if weights is not None:\n        assert weights.dim() == 1, \"Weights dimension should be 1\"\n        assert weights.numel() == targets.size(\n            0\n        ), \"Weights dimension 1 should be the same as that of target\"\n        assert torch.min(weights) >= 0, \"Weight should be non-negative only\"\n\n    assert torch.equal(\n        targets ** 2, targets\n    ), \"targets should be binary (0 or 1)\"\n\n    return outputs, targets, weights\n\ndef multi_label_accuracy(\n    outputs: torch.Tensor,\n    targets: torch.Tensor,\n    threshold: Union[float, torch.Tensor],\n    activation: Optional[str] = None,\n) -> torch.Tensor:\n    \"\"\"\n    Computes multi-label accuracy for the specified activation and threshold.\n    Args:\n        outputs (torch.Tensor): NxK tensor that for each of the N examples\n            indicates the probability of the example belonging to each of\n            the K classes, according to the model.\n        targets (torch.Tensor): binary NxK tensort that encodes which of the K\n            classes are associated with the N-th input\n            (eg: a row [0, 1, 0, 1] indicates that the example is\n            associated with classes 2 and 4)\n        threshold (float): threshold for for model output\n        activation (str): activation to use for model output\n    Returns:\n        computed multi-label accuracy\n    \"\"\"\n    outputs, targets, _ = preprocess_multi_label_metrics(\n        outputs=outputs, targets=targets\n    )\n    activation_fn = get_activation_fn(activation)\n    outputs = activation_fn(outputs)\n\n    outputs = (outputs > threshold).long()\n    output = (targets.long() == outputs.long()).sum().float() \/ np.prod(\n        targets.shape\n    )\n    return output\n\n\nclass MultiLabelAccuracyCallback(MetricCallback):\n    \"\"\"Accuracy metric callback.\n    Computes multi-class accuracy@topk for the specified values of `topk`.\n    .. note::\n        For multi-label accuracy please use\n        `catalyst.dl.callbacks.metrics.MultiLabelAccuracyCallback`\n    \"\"\"\n\n    def __init__(\n        self,\n        input_key: str = \"targets\",\n        output_key: str = \"logits\",\n        prefix: str = \"multi_label_accuracy\",\n        threshold: float = None,\n        activation: str = \"Sigmoid\",\n    ):\n        \"\"\"\n        Args:\n            input_key (str): input key to use for accuracy calculation;\n                specifies our `y_true`\n            output_key (str): output key to use for accuracy calculation;\n                specifies our `y_pred`\n            prefix (str): key for the metric's name\n            threshold (float): threshold for for model output\n            activation (str): An torch.nn activation applied to the outputs.\n                Must be one of ``\"none\"``, ``\"Sigmoid\"``, or ``\"Softmax\"``\n        \"\"\"\n        super().__init__(\n            prefix=prefix,\n            metric_fn=multi_label_accuracy,\n            input_key=input_key,\n            output_key=output_key,\n            threshold=threshold,\n            activation=activation,\n        )","fe0863be":"os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"    # can be changed in case of multiple GPUs onboard\nset_global_seed(SEED)                       # reproducibility\nprepare_cudnn(deterministic=True)           # reproducibility","87bdc539":"%%time\n# here we specify that we pass masks to the runner. So model's forward method will be called with\n# these arguments passed to it. \nrunner = SupervisedRunner(\n    input_key=(\n        \"features\",\n        \"attention_mask\"\n    )\n)\n\n\n# model training\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loaders=train_val_loaders,\n    callbacks=[\n        MultiLabelAccuracyCallback(threshold=PRED_THRES),\n        OptimizerCallback(accumulation_steps=ACCUM_STEPS)\n    ],\n    logdir=LOG_DIR,\n    num_epochs=NUM_EPOCHS,\n    verbose=True\n)","db9783e8":"!du -hc $LOG_DIR","9c17947a":"!ls $LOG_DIR\/checkpoints","386cb19b":"!nvidia-smi","7c34fa08":"torch.cuda.empty_cache()","9f0f0e28":"!nvidia-smi","e64df971":"plot_metrics(\n    logdir=LOG_DIR,\n    step='epoch',\n    metrics=['accuracy']\n)","682e1d3c":"test_loaders = {\n    \"test\": DataLoader(dataset=test_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=False) \n}","c35931af":"%%time\nrunner.infer(\n    model=model,\n    loaders=test_loaders,\n    callbacks=[\n        CheckpointCallback(\n            resume=f\"{LOG_DIR}\/checkpoints\/best.pth\"\n        ),\n        InferCallback(),\n    ],   \n    verbose=True\n)","45b0c956":"predicted_probs = runner.callbacks[0].predictions['logits']","378f122a":"predicted_probs.shape","3b48bd74":"sample_sub_df = pd.read_csv(PATH_TO_DATA + 'sample_submission.csv.zip',\n                           index_col='id')","dd23dcc4":"sample_sub_df.head(2)","2e95e0f5":"sample_sub_df[TARGET_FIELDS] = predicted_probs","6b6a2d17":"sample_sub_df.to_csv('submissions.csv')","e38e1795":"!head -3 submissions.csv","9ac74431":"# The model","16248eb2":"**Create Torch Datasets with train, validation, and test data.**","96a322d0":"# Inference for the test set","0eb38051":"To run Deep Learning experiments, Catalyst resorts to the [`Runner`](https:\/\/catalyst-team.github.io\/catalyst\/api\/dl.html#catalyst.dl.core.runner.Runner) abstraction, in particular, to [`SupervisedRunner`](https:\/\/catalyst-team.github.io\/catalyst\/api\/dl.html#module-catalyst.dl.runner.supervised).\n\n`SupervisedRunner` implements the following methods:\n - `train` - starts the training process of the model\n - `predict_loader` - makes a prediction on the whole loader with the specified model\n - `infer` - makes the inference on the model\n \nTo train the model within this interface you pass the following to the `train` method:\n - model (`torch.nn.Module`) \u2013 PyTorch model to train\n - criterion (`nn.Module`) \u2013 PyTorch criterion function for training\n - optimizer (`optim.Optimizer`) \u2013 PyTorch optimizer for training\n - loaders (dict) \u2013 dictionary containing one or several `torch.utils.data.DataLoader` for training and validation\n - logdir (str) \u2013 path to output directory. There Catalyst will write logs, will dump the best model and the actual code to train the model\n - callbacks \u2013 list of Catalyst callbacks\n - scheduler (`optim.lr_scheduler._LRScheduler`) \u2013 PyTorch scheduler for training\n - ...\n \nIn our case we'll pass the created `DistilBertForSequenceClassification` model, cross-entropy criterion, Adam optimizer, scheduler and data loaders that we created earlier. Also, we'll be tracking accuracy and thus will need `AccuracyCallback`. To perform batch accumulation, we'll be using `OptimizationCallback`.\n\nThere are many more useful [callbacks](https:\/\/catalyst-team.github.io\/catalyst\/api\/dl.html#module-catalyst.dl.callbacks.checkpoint) implemented, also check out [Catalyst examples](https:\/\/github.com\/catalyst-team\/catalyst\/tree\/master\/examples\/notebooks).","3dfefd8b":"## Model training\n\nFirst we specify optimizer and scheduler (pure PyTorch). Then Catalyst stuff.","ec8fc9b7":"One of the training dataset instances:","aaa05f24":"**Setup**","b6ef500c":"Now that we have predicted probabilities, let's finally create a submission file.","b0490b96":"Let's create a Torch loader for the test set and launch `infer` to actually make predictions fot the test set. First, we load the best model checkpoint, then make inference with this model.","938d0e8b":"**Finally, we define standard PyTorch loaders. This dictionary will be fed to Catalyst.**","0baadcf0":"# <center> DistilBERT for multilabel classification with Catalyst and HuggingFace\n##  <center>  Toxic comments classification","1bc1d1d7":"**Dataset**\n\nToxic comments - [competition](https:\/\/www.kaggle.com\/c\/jigsaw-toxic-comment-classification-challenge).\nGiven text of a comment, we need to classify it into several toxicity categories: 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', or 'identity_hate'.","83393525":"## Torch Dataset\n\nThis is left for user to be defined. Catalyst will take care of the rest. ","e2f1aa41":"Implementation of multilabel accuracy is under development in Catalyst, so we've copied the code for `MultiLabelAccuracyCallback` and dependencies here (branch [metrics-update-2](https:\/\/github.com\/catalyst-team\/catalyst\/blob\/feature\/metrics-update-2\/catalyst\/dl\/callbacks\/metrics\/accuracy.py))."}}