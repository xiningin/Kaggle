{"cell_type":{"e3310dc8":"code","077d3e6e":"code","881f6dbd":"code","5f9538ba":"code","58d65b07":"code","04c64815":"code","b7bfcf72":"code","daaaddc5":"code","5dfd8ef1":"code","edaf7f37":"code","f2a43440":"code","ad95eaf7":"code","f21afb03":"code","7dd0cfe4":"code","ec52f511":"code","630de30a":"code","1c32e7ba":"code","0c1ba36a":"code","05b799b6":"code","a8e5ce60":"code","fb4a8559":"code","5863d724":"code","79e25f21":"code","4ee84380":"code","3ed2d7c1":"markdown","680efda2":"markdown","e6c35a39":"markdown","900441ed":"markdown","dfd09a4f":"markdown","c4f06d22":"markdown","159ebac4":"markdown","4b2ce889":"markdown","00dacd34":"markdown","3e0fe951":"markdown","153ae20c":"markdown","b558464b":"markdown","2a1d9f5f":"markdown"},"source":{"e3310dc8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits import mplot3d\nimport warnings\n\nwarnings.filterwarnings('ignore')","077d3e6e":"df=pd.read_csv('..\/input\/nslkdd\/kdd_train.csv')\ndf.head()","881f6dbd":"df.info()","5f9538ba":"print('number of classes:', df['labels'].nunique())\nprint('')\nlabel_counts = df['labels'].value_counts()\nplt.figure(figsize=(18,6));\nsns.barplot(y=label_counts.index, x=label_counts.values, color='Grey');\nplt.title('values per class');\ndisplay(label_counts)\n\n#binary traffic proportions\nbinary_class = []\nfor label in df['labels']:\n    if label !='normal':\n        binary_class.append('malicious')\n    else:\n        binary_class.append('normal')\nbinary_class = pd.Series(binary_class)\nplt.figure()\nbinary_class.value_counts().plot(kind='pie', label='traffic proportions', autopct='%.2f%%' );","58d65b07":"df['protocol_type'].value_counts()","04c64815":"df['service'].value_counts()","b7bfcf72":"#how many different categories in column 'service'\nprint('number of categories in column \\'service\\':', df['service'].nunique())","daaaddc5":"df['flag'].value_counts()","5dfd8ef1":"#summary statistics\ndisplay(df.iloc[:,:10].describe())\ndisplay(df.iloc[:,10:17].describe())\ndisplay(df.iloc[:,17:24].describe())\ndisplay(df.iloc[:,24:31].describe())\ndisplay(df.iloc[:,31:36].describe())\ndisplay(df.iloc[:,36:].describe())","edaf7f37":"numeric_columns = []\ncategorical_columns = []\nfor column in df.columns:\n    if df[column].dtype != 'object':\n        numeric_columns.append(column)\n    else:\n        categorical_columns.append(column)\n\ncategorical_columns = categorical_columns[:-1]       \nlabels=df['labels'].unique()","f2a43440":"#distribution boxenplots (per class)\nfor column in numeric_columns:\n    plt.figure(figsize=(18,7))\n    sns.boxenplot(x='labels', y=df[column], data=df);\n    plt.title(column);\n    #for label in labels:\n    #    plt.figure(figsize=(18,7))\n    #    sns.kdeplot(df[column][df['labels']==label]);\n    #    plt.title(label);","ad95eaf7":"#feature means (per class)\ngroup_mean = df.groupby(by='labels').mean()\nfor column in numeric_columns:\n    plt.figure(figsize=(16,5));\n    sns.barplot(y=group_mean[column].squeeze().index, x=group_mean[column].squeeze().values, \n                color='Gray');\n    plt.title(column);","f21afb03":"#correlation heatmap\nplt.figure(figsize=(18,12));\nsns.heatmap(df.corr(), annot=True, fmt='1.1f');","7dd0cfe4":"#column 'num_outbound_cmds' is zero everywhere, we will delete it\ndf.drop(columns='num_outbound_cmds', inplace=True)\n\n#remove from list of numeric columns\nnumeric_columns.remove('num_outbound_cmds')","ec52f511":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.decomposition import PCA\n\n#standardize data\ndf_num = df[numeric_columns].copy()\nsc = StandardScaler()\ndf_num = sc.fit_transform(df_num)\n\n#ordinalize labels\nordinal = OrdinalEncoder()\nord_labels = ordinal.fit_transform(df['labels'].values[:,np.newaxis])\nord_labels = np.squeeze(ord_labels.astype(int))\n\n#PCA\npca = PCA()\ndf_pca = pca.fit_transform(df_num)\n\n#PCA 3d-scatterplot\nplt.figure(figsize=(12,6));\nax=plt.axes(projection='3d')\nax.scatter(df_pca[:,0], df_pca[:,1], df_pca[:,2], \n           c=ord_labels, cmap='winter');\nplt.title('3D PCA Visualization');\n\n#explained variance\nvar_index = np.arange(pca.explained_variance_.shape[0])+1\nplt.figure(figsize=(14,6));\nsns.barplot(x=var_index, y=pca.explained_variance_ratio_, color='gray');\nplt.title('Explained Variance Ratio');\nplt.figure(figsize=(14,6));\nsns.lineplot(x=var_index, y=pca.explained_variance_ratio_.cumsum());\nplt.title('Cumulative Explained Variance Ratio');","630de30a":"from sklearn.preprocessing import LabelEncoder\n\nenc = LabelEncoder()\ny = enc.fit_transform(df['labels'])\nx = np.arange(y.shape[0])\n\nplt.figure(figsize=(18,8));\nsns.lineplot(x=x[:800], y=y[:800]); #for visual clarity, only a small slice is selected\nplt.title('traffic in time')\n\nclass_labels = pd.DataFrame(data=enc.classes_,columns=['class'])\nclass_labels['label'] = np.unique(y)\ndisplay(class_labels)","1c32e7ba":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, BatchNormalization, Dropout\n#from tensorflow.keras.layers.core import Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import accuracy_score, f1_score\n#from tensorflow.keras.metrics import ","0c1ba36a":"from sklearn.preprocessing import StandardScaler\n\ndummies = pd.get_dummies(df[categorical_columns])\nx = pd.concat((df[numeric_columns], dummies), axis=1).values\n\nenc_bin = LabelEncoder()\ny_bin = enc_bin.fit_transform(binary_class)\nenc_multi = LabelEncoder()\ny_multi = enc_multi.fit_transform(df['labels'].values)\n\n# for manual train_test_split, splitting indices instead of actual values\nnp.random.RandomState(seed=0)\ntrain_indexes = np.random.choice(np.arange(x.shape[0]), size=x.shape[0]*8\/\/10, replace=False)\ntest_indexes = np.delete(np.arange(x.shape[0]), np.arange(x.shape[0])[train_indexes])\nprint('train size:', train_indexes.shape[0])\nprint('test size:  ', test_indexes.shape[0])\n\nx_tr = x[train_indexes]\nx_ts = x[test_indexes]\ny_bin_tr =y_bin[train_indexes]\ny_bin_ts =y_bin[test_indexes]\ny_multi_tr = y_multi[train_indexes]\ny_multi_ts = y_multi[test_indexes]\n\n# scale x\nsc=StandardScaler()\nx_tr = sc.fit_transform(x_tr)\nx_ts = sc.transform(x_ts)\n\n#make x 3-dimensional for the CNN to process\nx_tr = x_tr[:,:,np.newaxis]\nx_ts = x_ts[:,:,np.newaxis]","05b799b6":"model=Sequential()\nmodel.add(Conv1D(128,2, activation='relu',input_shape=x_tr[0].shape))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv1D(256,2, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(2))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.4))\n\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","a8e5ce60":"early_stop = EarlyStopping(patience=5,verbose=1)\nmodel.fit(x_tr, y_bin_tr, epochs=50, validation_split=0.1, batch_size=16, callbacks=[early_stop])","fb4a8559":"pred = model.predict(x_ts)\npred_d = []\nfor prediction in pred:\n    if prediction <0.5:\n        pred_d.append(0)\n    else:\n        pred_d.append(1)\n        \npred = np.array(pred_d)\nprint('accuracy:', accuracy_score(y_bin_ts, pred))\nprint('f1-score:', f1_score(y_bin_ts, pred, average='macro'))","5863d724":"model1=Sequential()\nmodel1.add(Conv1D(180,2, activation='relu',input_shape=x_tr[0].shape))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool1D(2))\nmodel1.add(Dropout(0.2))\n\nmodel1.add(Conv1D(300,2, activation='relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool1D(2))\nmodel1.add(Dropout(0.4))\n\nmodel1.add(Flatten())\nmodel1.add(Dense(256, activation='relu'))\nmodel1.add(Dropout(0.4))\n\nmodel1.add(Dense(len(np.unique(enc.classes_)),activation='softmax'))\n\nmodel1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel1.summary()","79e25f21":"early_stop = EarlyStopping(patience=4,verbose=1)\nmodel1.fit(x_tr, y_multi_tr, epochs=30, validation_split=0.1, batch_size=16, callbacks=[early_stop])","4ee84380":"pred = model1.predict(x_ts)\npred = np.argmax(pred,axis=1)\n\nprint('accuracy:', accuracy_score(y_multi_ts, pred))\nprint('f1-score:', f1_score(y_multi_ts, pred, average='weighted'))","3ed2d7c1":"#### Data Exploration","680efda2":"##### Multiclass Classification","e6c35a39":"We'll try both multiclass and binary classification. In the case of binary, we will cluster all malicious data in a single class, using the 'binary_class' variable that we created earlier.\n\nFirst, let's prepare the data","900441ed":"From the explained variance graphs we see that our 3-dimensional scatterplot captured only a small portion of the information. It would take at least 10-15 Principal Components to capture a meaningfull amount of the information. We could make a few more 3d scatterplots with other Principal Components but again, as seen in the explained variance graphs, these would offer far less insight than the first three components.","dfd09a4f":"Unique values and value counts of categorical variables:","c4f06d22":"# CNNs for Intrusion Detection","159ebac4":"##### Binary Classification","4b2ce889":"PCA visualization:","00dacd34":"###### (work in progress)","3e0fe951":"Numerical features--> summary statistics, distribution boxenplots (per class), feature means (per class), and correlation heatmap:","153ae20c":"How many classes and how many values per class:","b558464b":"### CNN Classification","2a1d9f5f":"Time series graph"}}