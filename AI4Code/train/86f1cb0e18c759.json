{"cell_type":{"10354fa3":"code","15360684":"code","c9ea41d1":"code","9fe8cf7b":"code","82f6e64d":"code","4af234d5":"code","82362519":"code","d3c5b3db":"code","66ae36dc":"code","13d8dd7c":"code","ec278a81":"code","c200255b":"code","6f157296":"code","61c7c40d":"code","e7778a7d":"code","e1ba9d9c":"code","3c26c4fe":"code","b0993f0e":"code","3cc454eb":"code","046ba76a":"code","2ab5ebba":"code","facaf001":"code","02bc298b":"code","1bbe0a81":"code","69944f49":"code","b61832a2":"code","6ef18b01":"code","e3139a98":"code","e4518705":"code","8d0b701f":"code","d0a0c829":"code","a003eeb2":"code","15b408de":"code","07cb1c53":"code","10768e20":"code","59f0ead4":"code","2349ac51":"code","b2d6500d":"code","62c4f039":"code","e73466dc":"code","26a89e83":"code","42332c56":"code","57cc4c2a":"code","718b803d":"code","081142ac":"code","af5ef5e8":"code","86af09ce":"code","3bc80b92":"code","48786d5a":"code","d69e4287":"code","1a7ef0d3":"code","9b5b502f":"code","61c0e94b":"code","3a2987fb":"code","303f4a41":"code","9aa6041b":"code","a8ee79dd":"code","df2fcaf1":"code","032e21e9":"code","59b55693":"code","9c9227be":"code","7c70aaf1":"code","8d108d9d":"code","4b2d5378":"code","43c08446":"code","da4fe233":"code","adff4053":"code","87e363dc":"code","27d49083":"code","2b44de27":"code","0d087393":"code","2b252f50":"code","076574d9":"code","03a61813":"code","a9bac553":"markdown","aa34a6aa":"markdown","28fafe4e":"markdown","9bd49c97":"markdown","4fb237d9":"markdown","f90199c4":"markdown","f2bb657d":"markdown","ba2fa679":"markdown","48c119cc":"markdown","f7a664e2":"markdown","5634ee4d":"markdown","71dfe0f6":"markdown","3ab17b17":"markdown","c366b5ec":"markdown","4b8e54cf":"markdown","2427b846":"markdown","cebeb815":"markdown","301ed173":"markdown","e01a61ca":"markdown","925b2948":"markdown","471066aa":"markdown","4f8c0279":"markdown","e33d08a5":"markdown","512940d1":"markdown","a1f97b42":"markdown","f9c6187f":"markdown","43e53a00":"markdown","126ec7fb":"markdown","f797107f":"markdown","af816612":"markdown","314f94d0":"markdown","ee73168d":"markdown","d4944b46":"markdown","e71e6bec":"markdown","a3c1ee55":"markdown","9b22c223":"markdown","e20fe87b":"markdown","4a03e925":"markdown","55c8edcc":"markdown","008499b7":"markdown","f93b89ae":"markdown","fd6a44f1":"markdown","fd26e0eb":"markdown","1a9e04bb":"markdown","340b6168":"markdown"},"source":{"10354fa3":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n%matplotlib inline\nsns.set_style('darkgrid')","15360684":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","c9ea41d1":"print(\"Shape of Data is ==> \",df.shape)","9fe8cf7b":"df.info()","82f6e64d":"df.describe().T","4af234d5":"for i in df.columns:\n    print(i)","82362519":"df.rename({'DiabetesPedigreeFunction':'DPF'},inplace = True,axis =1)\ndf.head()","d3c5b3db":"df.dtypes","66ae36dc":"def std_based(col_name,df):\n    mean = df[col_name].mean()\n    std = df[col_name].std()\n    cut_off = std * 3\n    lower, upper = mean - cut_off, mean + cut_off\n    new_df = df[(df[col_name] < upper) & (df[col_name] > lower)]\n    return new_df","13d8dd7c":"df.isnull().sum()","ec278a81":"df['Pregnancies'].describe()","c200255b":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Pregnancies'],ax=axes[0],color='m')\naxes[0].set_title('Distribution of Pregnancy',fontdict={'fontsize':8})\naxes[0].set_xlabel('Pregnancy Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Pregnancies',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","6f157296":"#Treating Outlier and then verifying it\n\ndf = std_based('Pregnancies',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Pregnancies'],ax=axes[0],color='red')\naxes[0].set_title('Distribution of Pregnancy',fontdict={'fontsize':8})\naxes[0].set_xlabel('Pregnancy Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Pregnancies',data=df,ax=axes[1],orient = 'v',color='yellow')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","61c7c40d":"df['Glucose'].describe()","e7778a7d":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Glucose'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of Glucose',fontdict={'fontsize':8})\naxes[0].set_xlabel('Glucose Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Glucose',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","e1ba9d9c":"df.Glucose = df.Glucose.replace(0,df.Glucose.mean())\ndf.head()","3c26c4fe":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Glucose'],ax=axes[0],color='r')\naxes[0].set_title('Distribution of Glucose',fontdict={'fontsize':8})\naxes[0].set_xlabel('Glucose Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Glucose',data=df,ax=axes[1],orient = 'v',color='y')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","b0993f0e":"df.BloodPressure.describe()","3cc454eb":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BloodPressure'],ax=axes[0],color='m')\naxes[0].set_title('Distribution of BloodPressure',fontdict={'fontsize':8})\naxes[0].set_xlabel('BloodPressure Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BloodPressure',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","046ba76a":"df.BloodPressure = df.BloodPressure.replace(0,df.BloodPressure.median())\ndf.head()","2ab5ebba":"df  = std_based('BloodPressure',df)","facaf001":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BloodPressure'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of BloodPressure',fontdict={'fontsize':8})\naxes[0].set_xlabel('BloodPressure Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BloodPressure',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","02bc298b":"df.SkinThickness.describe()","1bbe0a81":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['SkinThickness'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of SkinThickness',fontdict={'fontsize':8})\naxes[0].set_xlabel('SkinThickness Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('SkinThickness',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","69944f49":"df.SkinThickness = df.SkinThickness.replace(0,df.SkinThickness.mean())\ndf.head()","b61832a2":"df = std_based(\"SkinThickness\",df)","6ef18b01":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['SkinThickness'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of SkinThickness',fontdict={'fontsize':8})\naxes[0].set_xlabel('SkinThickness Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('SkinThickness',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","e3139a98":"df.Insulin.describe()","e4518705":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Insulin'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of Insulin',fontdict={'fontsize':8})\naxes[0].set_xlabel('Insulin Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Insulin',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","8d0b701f":"df.Insulin = df.Insulin.replace(0,df.Insulin.median())\ndf.head()","d0a0c829":"df = std_based('Insulin',df)","a003eeb2":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Insulin'],ax=axes[0],color='r')\naxes[0].set_title('Distribution of Insulin',fontdict={'fontsize':8})\naxes[0].set_xlabel('Insulin Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Insulin',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","15b408de":"df.BMI.describe()","07cb1c53":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BMI'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of BMI',fontdict={'fontsize':8})\naxes[0].set_xlabel('BMI Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BMI',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","10768e20":"df.BMI = df.BMI.replace(0,df.BMI.mean())\ndf.head()","59f0ead4":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BMI'],ax=axes[0],color='m')\naxes[0].set_title('Distribution of BMI',fontdict={'fontsize':8})\naxes[0].set_xlabel('BMI Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BMI',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","2349ac51":"df.DPF.describe()","b2d6500d":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['DPF'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of DPF',fontdict={'fontsize':8})\naxes[0].set_xlabel('DPF Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('DPF',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","62c4f039":"df = std_based('DPF',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['DPF'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of DPF',fontdict={'fontsize':8})\naxes[0].set_xlabel('DPF Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('DPF',data=df,ax=axes[1],orient = 'v')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","e73466dc":"df.Age.describe()","26a89e83":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Age'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of Age',fontdict={'fontsize':8})\naxes[0].set_xlabel('Age Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Age',data=df,ax=axes[1],orient = 'v')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","42332c56":"df = std_based('Age',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Age'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of Age',fontdict={'fontsize':8})\naxes[0].set_xlabel('Age Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency\/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Age',data=df,ax=axes[1],orient = 'v')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()","57cc4c2a":"df.head()","718b803d":"df.shape","081142ac":"df.info()","af5ef5e8":"df.var()","86af09ce":"df.drop('DPF',axis = 1,inplace=True)","3bc80b92":"df.Outcome.value_counts()","48786d5a":"sns.countplot(df['Outcome']).set_title('Distribution of Outcome')\nplt.show()","d69e4287":"x=df.iloc[:,:-1].values\ny=df.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20, random_state = 0)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","1a7ef0d3":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\nx_train_std = ss.fit_transform(x_train)\nx_test_std = ss.transform(x_test)","9b5b502f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nknn = KNeighborsClassifier()\n\nparam_grid = {'n_neighbors':[5,10,15,25,30,50]}\n\ngrid_knn = GridSearchCV(knn,param_grid,scoring='accuracy',cv = 10,refit = True)","61c0e94b":"grid_knn.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_knn.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_knn.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_knn.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_knn.score(x_test_std,y_test))","3a2987fb":"probs = grid_knn.predict_proba(x_test_std)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\nplt.figure(dpi=100)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","303f4a41":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\n\nparam_grid = {'criterion':['gini','entropy'],'max_depth':np.arange(2,10),'min_samples_leaf':[0.2,0.4,0.6,0.8,0.9,1]}\n\ngrid_dtc = GridSearchCV(dtc,param_grid,scoring='accuracy',cv = 10,refit = True)","9aa6041b":"grid_dtc.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_dtc.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_dtc.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_dtc.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_dtc.score(x_test_std,y_test))","a8ee79dd":"probs = grid_dtc.predict_proba(x_test_std)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\nplt.figure(dpi=100)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","df2fcaf1":"from sklearn.svm import SVC\n\nsvc = SVC(probability=True)\n\nparam_grid = {'kernel':['rbf','linear'],'C':[0.01,0.1,1,0.001],'gamma':[0.1,0.01,0.2,0.4]}\n\ngrid_svc = GridSearchCV(svc,param_grid,scoring='accuracy',cv = 10,refit = True)","032e21e9":"grid_svc.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_svc.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_svc.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_svc.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_svc.score(x_test_std,y_test))","59b55693":"probs = grid_svc.predict_proba(x_test_std)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\nplt.figure(dpi=100)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","9c9227be":"from sklearn.ensemble import VotingClassifier\n\nclassifiers = [('knn',grid_knn),('tree',grid_dtc),('svc',grid_svc)]\n\nvtc = VotingClassifier(classifiers)","7c70aaf1":"vtc.fit(x_train_std,y_train)\nprint(\"Accuracy on Test set ==> \", vtc.score(x_test_std,y_test))","8d108d9d":"from sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\n\nfor i in range(2,7):\n    rfe = RFE(estimator=RandomForestClassifier(),n_features_to_select=i, verbose=0)\n    rfe.fit(x_train_std,y_train)\n    print(f\"Accuracy with Feature {i} ==>\",metrics.accuracy_score(y_test, rfe.predict(x_test_std)))","4b2d5378":"rfe = RFE(estimator=RandomForestClassifier(),n_features_to_select=5, verbose=0)\nrfe.fit(x_train_std,y_train)","43c08446":"print(\"Important Features are ==> \",list(df.columns[:7][rfe.support_]))","da4fe233":"x=df.loc[:,list(df.columns[:7][rfe.support_])].values\ny=df.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20, random_state = 0)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\nx_train_std = ss.fit_transform(x_train)\nx_test_std = ss.transform(x_test)","adff4053":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\n\nparam_grid = {'n_estimators':[200,500,1000],\n              'max_depth':[2,3,4,5],\n              'min_samples_leaf':[0.2,0.4,0.6,0.8,1],\n              'max_features':['auto','sqrt'],\n              'criterion':['gini','entropy']}\n\ngrid_rfc = RandomizedSearchCV(rfc,param_grid,n_iter=20,scoring='accuracy',cv = 10,refit = True)","87e363dc":"grid_rfc.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_rfc.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_rfc.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_rfc.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_rfc.score(x_test_std,y_test))","27d49083":"probs = grid_rfc.predict_proba(x_test_std)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\nplt.figure(dpi=100)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","2b44de27":"import xgboost as xgb\n\nxgbcl = xgb.XGBClassifier()\n\nparam_grid = {'booster':['gbtree','gblinear'],\n             'colsample_bytree':[0.4,0.6,0.8,1],\n             'learning_rate':[0.01,0.1,0.2,0.4],\n             'max_depth':[2,3,4,6],\n             'n_estimators':[200,300,400,500],\n              'subsample':[0.4,0.6,0.8,1]}\n\ngrid_xgb = RandomizedSearchCV(xgbcl,param_grid,n_iter=30,scoring='accuracy',cv = 10,refit = True)","0d087393":"grid_xgb.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_xgb.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_xgb.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_xgb.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_xgb.score(x_test_std,y_test))","2b252f50":"probs = grid_xgb.predict_proba(x_test_std)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\nplt.figure(dpi=100)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","076574d9":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nclassifier = Sequential()\n\nclassifier.add(Dense(units= 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))\nclassifier.add(Dense(units= 6, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nclassifier.fit(x_train_std, y_train, batch_size = 10, epochs = 100)\n","03a61813":"y_pred_test = classifier.predict(x_test_std)\ny_pred_test=y_pred_test>0.5\n\ny_pred_train = classifier.predict(x_train_std)\ny_pred_train=y_pred_train>0.5\n\nprint(\"Accuracy on Train Set ==> \",metrics.accuracy_score(y_train,y_pred_train))\nprint(\"Accuracy on Test Set ==> \",metrics.accuracy_score(y_test,y_pred_test))","a9bac553":"<font color = 'blue'> Well, done with Glucose also,Let us see next. <\/font>","aa34a6aa":"**Please observe the scale at Y axis to see if outliers has been treated to some extent :) **","28fafe4e":"Well things is fine here, Let us see for Outliers.","9bd49c97":"**<font color = 'red'> Variance is varying to a greater extent, So i will standardize.<\/font>** I am removing dpf because variance is very low.","4fb237d9":"## Spliting Data","f90199c4":"**I will change DiabtesPedigreeFunction to DPF for conviniene**","f2bb657d":"**We need to look at BP=0**","ba2fa679":"We can see that minimum is 0 which may be considered as no Pregnancy, But maximum is 17 which is not making sense. Let us see distribution and also boxplot for outliers","48c119cc":"**Let us check column names first and manipulate if any change needed.**","f7a664e2":"# Introduction\n\nLet us  do some EDA to see behaviour of data which will help in Preprocessing.","5634ee4d":"**We can see SVC is doing better than KNN and Decision Tree. Let us combine these models and see if we can improve accuracy.**","71dfe0f6":"<font color = 'blue'> There is no outlier and also distribution is normal , So i will treat 0 with mean value.<\/font>","3ab17b17":"We can see that Outcome is balance so we need not to **Stratify** data.","c366b5ec":"**Sometime keeping unwanted variable increase variance in model. Let us see if we can improve accuracy by removing them.**","4b8e54cf":"# SVC","2427b846":"# Feature Selection\n\nLet us first use RFE to select important features.","cebeb815":"# ANN","301ed173":"**<font color='red'> It looks like there is no missing values. But in descriptive statistics we have seen that some variables have minimum = 0 and pregnancy variable has maximum = 17 which is not making sense. So let us explore these variables and treat them accordingly.<\/font>**\n\n**Please note that in my last 3 notebooks we have seen that variables are following normal distribution , So with Statistical Evidence we can fill values using Mean, Median and Mode.**\n\nOther Notebook in this series are ==>\n\n1. [Univariate Statistical Analysis](https:\/\/www.kaggle.com\/ravichaubey1506\/univariate-statistical-analysis-on-diabetes)\n2. [Multivariate Staistical Analysis](https:\/\/www.kaggle.com\/ravichaubey1506\/multivariate-statistical-analysis-on-diabetes)\n3. [Inferencial Statistics](https:\/\/www.kaggle.com\/ravichaubey1506\/inferential-statistics-on-diabetes)","e01a61ca":"<font color = 'blue'> Glucose = 0, does not make any sense. <\/font>","925b2948":"**We can see there are many outliers. So i will fill 0 with Median of Insulin. I will also treat Outliers after removing zero.**","471066aa":"# XGBoost Classifier","4f8c0279":"**Can you see , I am using plot twice one before treating and another after treatment. Look at changes :), Let us see next variable.**","e33d08a5":"**Let us check datatypes of variables**","512940d1":"Well , Let us see next one.","a1f97b42":"Outliers are present at higher end. Let us treat them.","f9c6187f":"# KNN\n\nI will not use linear classifier, Please see my 2nd notebook to find why i am not using?","43e53a00":"I have made 4 notebook on this dataset to show Statistics and Machine Learning. You can read all of them here ==>\n\n1. [Univariate Statistical Analysis](https:\/\/www.kaggle.com\/ravichaubey1506\/univariate-statistical-analysis-on-diabetes)\n2. [Multivariate Staistical Analysis](https:\/\/www.kaggle.com\/ravichaubey1506\/multivariate-statistical-analysis-on-diabetes)\n3. [Inferencial Statistics](https:\/\/www.kaggle.com\/ravichaubey1506\/inferential-statistics-on-diabetes)\n4. [Predective Modelling on Diabtes](https:\/\/www.kaggle.com\/ravichaubey1506\/predictive-modelling-knn-ann-xgboost\/)","126ec7fb":"**SVC is doing good till now. Let us see if Random Forest, XGBoost and ANN can help to achieve more accuracy.**","f797107f":"Let us take a look for outliers.","af816612":"## Among all SVC, Random Forest and XGBoost Classifiers are doing well.\n\nI have made 4 notebook on this dataset to show Statistics and Machine Learning. You can read all of them here ==>\n\n1. [Univariate Statistical Analysis](https:\/\/www.kaggle.com\/ravichaubey1506\/univariate-statistical-analysis-on-diabetes)\n2. [Multivariate Staistical Analysis](https:\/\/www.kaggle.com\/ravichaubey1506\/multivariate-statistical-analysis-on-diabetes)\n3. [Inferencial Statistics](https:\/\/www.kaggle.com\/ravichaubey1506\/inferential-statistics-on-diabetes)\n4. [Predective Modelling on Diabtes]()\n\n## Please upvote my Notebook, if it is useful for you. Thank you for reading.","314f94d0":"# Preprocessing\n\nYou might get confuse what is difference between Data Cleaning and Data Preprocessing?\n\nWell Data Preprocessing is beyong Data Cleaning is used to Make data tidy. Data Preprocessing is used to make data in way such that we can fit model to it.","ee73168d":"*<font color = 'blue'> Well, we are done with Pregnancy variable. Let us see next one. <\/font>*","d4944b46":"**Everything is perfect.**","e71e6bec":"**<font color = 'red'> Now we are done with missing value and Outliers. Let us take a look at data and then move ahead with other steps.**","a3c1ee55":"# Data Cleaning","9b22c223":"**Everything is fine. Let us move to next step. There is no categorical variable, So we need not to worry about encoding. **","e20fe87b":"# Decision Tree Classifier","4a03e925":"# Voting Classifier","55c8edcc":"## Statistical Assumption\n\nLet us check for some assumption like variance. Distribution is absolutely fine. We have already seen in other notebooks.","008499b7":"Let us look at 0 SkinThickness.","f93b89ae":"** Outliers are considerable, So i will replace zero with mean. **","fd6a44f1":"# Random Forest Classifier","fd26e0eb":"## Missing Values & Outliers\n\nLet us look to missing values and handle them. \nFirst I create function to handle outliers.Standard deviation based detection.","1a9e04bb":"### Summary\n\nData is related to healthcare Industry having 768 observations with 9 variable. Target variable is Outcome. It looks like there is no missing value, and boolean, float , integers are different datatypes available. Well descriptive analysis shows that variable Glucose, BoodPressure,SckinThickness, Insulin and BMI have minimum value 0 which does not make any sense, these values are either missing or outliers, But i am not going to alter them so that i can see actual statistics of Data. I can see in Pregnancies column, minimum is 0 (May be this is sign for no pregnancy) which is considerable, But maximum month of pregnancy is 17 which does not make any sense. Variance among different predictor variable is varying at large scale , Scaling data will be helpful for Predective modelling.","340b6168":"It looks like there are few Outliers at both higher end and lower end. But at higher end maximum BP is 122, So it is considerable. Now at lower end BP near 25 is not making sense. So i will treat missing value with medium and then i will also treat outliers."}}