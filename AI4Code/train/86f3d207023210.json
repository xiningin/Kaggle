{"cell_type":{"22d46550":"code","9a429728":"code","b6a41d4e":"code","7b151696":"code","f6e8edfe":"code","71d6fe22":"code","9842d191":"code","03076122":"code","af6e2600":"code","9587a24f":"code","ae8ac2d9":"code","dedd38cf":"code","13362d2e":"code","09ca7cba":"code","06153c5f":"code","631ff6c0":"code","b4e4236a":"code","16b5e4fe":"code","044587de":"code","f3725caa":"code","176e04dd":"code","8c99c8db":"code","0bdb8d91":"markdown","1537c3cb":"markdown","b09bf106":"markdown","bc106fbf":"markdown","a95adb8c":"markdown","b134aed3":"markdown","674ea54e":"markdown","b4ef5c9f":"markdown","213e0df9":"markdown","77fee9bd":"markdown","8f6f7693":"markdown","f845a09d":"markdown","4eb0aceb":"markdown","a5611c72":"markdown","9640820c":"markdown","0c71677e":"markdown","9e8f82b8":"markdown","65289d98":"markdown","a47c82a8":"markdown","3bde72c0":"markdown","b3698886":"markdown","9f4ef649":"markdown"},"source":{"22d46550":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#plotting libs\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#sklearn lib\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.pipeline import Pipeline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9a429728":"hd = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\nprint(hd.head())\nprint(hd.shape)","b6a41d4e":"print(\"Missing data: \\n\")\nprint(str(hd.isnull().sum()))","7b151696":"labels=[\"Male\", \"Female\"] #x-axis label\nmale = [hd[(hd[\"target\"]==0)&(hd[\"sex\"]==1)][\"target\"].count(), hd[(hd[\"target\"]==0)&(hd[\"sex\"]==0)][\"target\"].count()] #bars for males\nfemale = [hd[(hd[\"target\"]==1)&(hd[\"sex\"]==1)][\"target\"].count(), hd[(hd[\"target\"]==1)&(hd[\"sex\"]==0)][\"target\"].count()] #bars for females\nprint(male)\nprint(female)\nx = np.arange(len(labels)) #label locations\nwidth=0.35 #bar widths\n\nsumM = male[0]+female[0]\nsumF = male[1]+female[1]\n\nrelm = [male[0]\/sumM, male[1]\/sumF]\nrelf = [female[0]\/sumM, female[1]\/sumF]\n\nfig = plt.figure(figsize=(14,8))\nax = fig.subplots()\nrects1 = ax.bar(x - width\/2, male, width, label='Male')\nrects2 = ax.bar(x + width\/2, female, width, label='Female')\nprint(male[0]+female[0])\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend([\"no disease\", \"disease\"])\n\ndef autolabel(rects):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n        \nautolabel(rects1)\nautolabel(rects2)\n\nfig.tight_layout()\nplt.show()","f6e8edfe":"hd[\"age_groups\"] = hd[\"age\"].apply(lambda x: 0 if x<6 else (1 if x < 18 else (2 if x < 30 else (3 if x < 50 else (4 if x < 65 else 5)))))\nhd","71d6fe22":"fig = plt.figure(figsize=(14,8))\nsns.distplot(hd[\"age\"])","9842d191":"fig = plt.figure(figsize=(14,8))\nsns.countplot(hd[\"age_groups\"], hue=hd[\"target\"])\nprint(hd[\"age_groups\"].value_counts())","03076122":"print(hd[\"fbs\"].value_counts())","af6e2600":"fig = plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.countplot(hd[hd[\"sex\"]==1][\"fbs\"], hue=hd[\"target\"])\nplt.title(\"Male\")\nplt.gca().set_ylim(0,100)\n\nplt.subplot(1,2,2)\nsns.countplot(hd[hd[\"sex\"]==0][\"fbs\"], hue=hd[\"target\"])\nplt.title(\"Female\")\nplt.gca().set_ylim(0,100)","9587a24f":"print(\"fbs==0: {} % \\nfbs==1: {} %\".format(hd[hd[\"fbs\"]==0][\"fbs\"].count()\/len(hd[\"fbs\"]), hd[hd[\"fbs\"]==1][\"fbs\"].count()\/len(hd[\"fbs\"])))","ae8ac2d9":"fig = plt.figure(figsize=(14,6))\nsns.countplot(hd[\"exang\"], hue=hd[\"target\"])","dedd38cf":"fig = plt.figure(figsize=(14,6))\nplt.subplot(2,1,1)\nsns.boxplot(hd[hd[\"target\"]==0][\"oldpeak\"])\nplt.xlim(0, 8)\nplt.title(\"no disease\")\n\nplt.subplot(2,1,2)\nsns.boxplot(hd[hd[\"target\"]==1][\"oldpeak\"])\nplt.xlim(0, 8)\nplt.title(\"has disease\")\nplt.subplots_adjust(hspace=0.4)","13362d2e":"fig = plt.figure(figsize=(14,6))\nsns.countplot(hd[\"cp\"], hue=hd[\"target\"])","09ca7cba":"fig = plt.figure(figsize=(14,6))\nplt.subplot(2,1,1)\nsns.boxplot(hd[hd[\"target\"]==0][\"chol\"])\nplt.xlim(0, 600)\nplt.title(\"no disease\")\n\nplt.subplot(2,1,2)\nsns.boxplot(hd[hd[\"target\"]==1][\"chol\"])\nplt.xlim(0, 600)\nplt.title(\"has disease\")\nplt.subplots_adjust(hspace=0.4)","06153c5f":"fig = plt.figure(figsize=(14,6))\nplt.subplot(2,1,1)\nsns.boxplot(hd[hd[\"target\"]==0][\"thalach\"])\nplt.xlim(60, 210)\nplt.title(\"no disease\")\n\nplt.subplot(2,1,2)\nsns.boxplot(hd[hd[\"target\"]==1][\"thalach\"])\nplt.xlim(60, 210)\nplt.title(\"has disease\")\nplt.subplots_adjust(hspace=0.4)","631ff6c0":"fig = plt.figure(figsize=(14,6))\nplt.subplot(2,1,1)\nsns.boxplot(hd[hd[\"target\"]==0][\"trestbps\"])\nplt.xlim(90, 210)\nplt.title(\"no disease\")\n\nplt.subplot(2,1,2)\nsns.boxplot(hd[hd[\"target\"]==1][\"trestbps\"])\nplt.xlim(90, 210)\nplt.title(\"has disease\")\nplt.subplots_adjust(hspace=0.4)","b4e4236a":"fig = plt.figure(figsize=(16,8))\nWe wouldsns.heatmap(hd.corr().sort_values(\"target\", ascending=False)[[\"target\"]], annot=True) #select only the target feature and sort the correlation","16b5e4fe":"pd.get_dummies(hd[\"cp\"], prefix=\"cp\")\npd.get_dummies(hd[\"thal\"], prefix=\"thal\")\npd.get_dummies(hd[\"slope\"], prefix=\"slope\")\nhd = pd.concat([hd, pd.get_dummies(hd[\"cp\"], prefix=\"cp\"), pd.get_dummies(hd[\"thal\"], prefix=\"thal\"), pd.get_dummies(hd[\"slope\"], prefix=\"slope\")], axis=1)\nhd.drop([\"cp\", \"thal\", \"slope\"], axis=1, inplace=True)\nhd","044587de":"x = hd.drop([\"target\", \"age_groups\"], axis=1)\ny = hd[\"target\"]\nscalar = StandardScaler()\n\nlr = LogisticRegression()\n\npipeline = Pipeline([('transformer', scalar), ('estimator', lr)])\n\n#lr.fit(x_train,y_train)\n#acc = lr.score(x_test,y_test)*100\nacc = cross_val_score(pipeline, x, y, cv=5)\n\nprint(acc)\nprint(\"Accuracy: {:.3f} (+\/- {:.3f})\".format(acc.mean(), acc.std()*2))","f3725caa":"scoreList = []\nfor i in range(2,31):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    cv = StratifiedKFold(n_splits=5)\n    pipeline = Pipeline([('transformer', scalar), ('estimator', knn)])\n\n    acc = cross_val_score(pipeline, x, y, cv=cv, scoring=\"f1\")\n    scoreList.append(acc.mean())\n    #print(acc)\n    print(\"Accuracy: {:.3f} (+\/- {:.3f})  Neighbors: {}\".format(acc.mean(), acc.std()*2,i))\n\nprint(\"\\nMax accuracy achieved: {:.3f}\".format(max(scoreList)))\nplt.figure(figsize=(16,8))\nplt.plot(scoreList)","176e04dd":"rf = RandomForestClassifier(n_estimators=100, max_depth=5, n_jobs=-1)\ncv = StratifiedKFold(n_splits=7)\npipeline = Pipeline([('transformer', scalar), ('estimator', rf)])\n\nacc = cross_val_score(pipeline, x, y, cv=cv, scoring=\"f1\")\nscoreList.append(acc.mean())\n#print(acc)\nprint(\"Accuracy: {:.3f} (+\/- {:.3f})\".format(acc.mean(), acc.std()*2))","8c99c8db":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\nrf.fit(x_train, y_train)\n\nfi = pd.DataFrame(rf.feature_importances_, index = x.columns, columns=['importance']).sort_values('importance', ascending=False)\nplt.figure(figsize=(20,8))\nsns.heatmap(fi, annot=True, cmap=sns.diverging_palette(10, 140, s=90, l=60, as_cmap=True))","0bdb8d91":"So this dataset contains information mostly for people aged 40+.","1537c3cb":"Interesting. Quite a lot people have a heart disease without having an exercise induced angina.","b09bf106":"The trestbps basically tells us nothing but the thalach feature can do this. From this plot we see that a person with a heart disease will also achieve a higher maximum heart rate.\n\nFrom this point we could do furter analysis e.g. take a look at the distrbution of the thalach feature for each age group separated by our target or create scatter plots for different combinations of features and see who has a disease and who has no disease. Instead we will now create a few models and compare their predictions. We can select our features based on the correlation with our target feature.","bc106fbf":"# Models","a95adb8c":"It would be interesting to see if there is a connection between exang (excersice induced angina) and the target.","b134aed3":"It is very interesting that there are so many people with a heart disease in group 3 (30 <= x < 50). Since there are just 87 people in this group there is a chance that what we see is completely random. This can be checked by calculating the p-value.","674ea54e":"Explore the feature importance for the random forest.","b4ef5c9f":"# Load dataset","213e0df9":"As we could already say in the beginning thalach and oldpeak are among the most important features while fbs or slope is among the least important ones. So for this task a random forest or a knn should be used in order to achieve a high accuracy.","77fee9bd":"Here we can't draw any conclusion since the fbs feature is heavily imbalanced as this shows:","8f6f7693":"Convert categorical features into dummy variables.","f845a09d":"Check if there is missing data.","4eb0aceb":"Here we see nothing significant by which we can say wether a person has a disease or not. Maybe we could say anything about it in combination with another feature.\n\nNow plot the thalach and trestbps features.","a5611c72":"# Random Forests","9640820c":"Here is some information on the features:\n1.  **age** in years\n2.  **sex** (1 = male; 0 = female)\n3.  **cp** chest pain type (4 values)\n4.  **trestbps** resting blood pressure (in mm Hg on admission to the hospital)\n5.  **chol** serum cholestoral in mg\/dl\n6.  **fbs** (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n7.  **restecg** resting electrocardiographic results (3 values; 0,1,2)\n8.  **thalach** maximum heart rate achieved\n9.  **exang** exercise induced angina (1 = yes; 0 = no)\n10. **oldpeak** ST depression induced by exercise relative to rest\n11. **slope** the slope of the peak exercise ST segment\n12. **ca** number of major vessels (0-3) colored by flourosopy\n13. **thal** 3 = normal; 6 = fixed defect; 7 = reversable defect\n14. **target** 1 or 0","0c71677e":"We would use the features with the highest correlation with our target but instead we will use all features for our model and afterwards take a look at the feature importance. For a selection with a correlation matrix the correlation between the features should be considered too.","9e8f82b8":"This plot shows that the chance that a female has a heart disease is higher than for a male. Plot the samething for the age feature ubt first divide into groups. ","65289d98":"From this plot it would be save to assume that if someone experiences chest pain than it is likely that this person also has a heart disease. But since there are a lot of diseases that cause chest pain we can't say for sure that it is a heart disease.","a47c82a8":"# KNN","3bde72c0":"Since there are no missing values there is no need to fill up anything.","b3698886":"So people with a heart dieases usually have a lower peak in comparison to people with no disease. There are alos just a few outliers which can be removed.","9f4ef649":"# LogisticRegression"}}