{"cell_type":{"ea2f9177":"code","a0c3f3c2":"code","7498a7ff":"code","adadda94":"code","99ef2399":"code","a6605377":"code","55a7292b":"code","57db6381":"code","0ead2407":"code","ada26abb":"code","0ce1815e":"code","a7e36242":"code","eb367636":"code","58bd1e13":"code","1aafb1bf":"code","0eaecbc4":"code","f5d21fa4":"code","094c4231":"code","e6fc13e8":"code","b641b4eb":"code","27235f1d":"code","78ef1db4":"code","2d4e72dd":"code","1902e544":"code","e1df3842":"code","c145737b":"code","7bd11335":"code","01645565":"code","c540383f":"code","7e8e8be8":"code","66d523b9":"code","ebbaaf47":"code","9240e23f":"code","ee7024bf":"code","c19cc7b1":"code","6bbdf472":"code","7821e49b":"code","87585614":"code","e16a3acf":"code","5fec1fe0":"code","95f6bf41":"markdown","910cde31":"markdown","a5663d97":"markdown","6af12d5c":"markdown","a1d147f8":"markdown","a206d093":"markdown","73d13b6f":"markdown","946073f1":"markdown","e77dbba2":"markdown","274b7a1d":"markdown"},"source":{"ea2f9177":"import pandas as pd\nimport numpy as np\nimport datatable as dt\nimport optuna\n\nimport gc; gc.enable()","a0c3f3c2":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","7498a7ff":"PATH = '..\/input\/dataprep-nov21\/gauss.parquet'\nX = pd.read_parquet(PATH)\n\nX.head()","adadda94":"PATH = '..\/input\/dataprep-nov21\/target.parquet'\npred = pd.read_parquet(PATH)\n\npred.head()","99ef2399":"M, N = X.shape[0], pred.shape[0]\nM, N, M-N","a6605377":"X = reduce_memory_usage(X)\ny = pred.target\n\ntrain = X.head(N)\ntest = X.tail(M-N)\n\ndel X; gc.collect()","55a7292b":"train.head()","57db6381":"from matplotlib import pyplot as plt\nimport seaborn as sns; sns.set()\n%matplotlib inline","0ead2407":"from sklearn.model_selection import train_test_split","ada26abb":"from sklearn.metrics import roc_auc_score, balanced_accuracy_score\nfrom sklearn.linear_model import LogisticRegression","0ce1815e":"PATH = '..\/input\/reliefe-nov21\/fi.parquet'\nfi = pd.read_parquet(PATH)\nfi.head()","a7e36242":"keep_cols = fi.sort_values(by='med_rank').head(20)['index'].tolist()","eb367636":"train = train[keep_cols]\ngc.collect()","58bd1e13":"_, X_train, _, y_train = train_test_split(train.values, y.values, \n                                          test_size=0.2, random_state=42, stratify=y.values)\ndel _; gc.collect()\n\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, \n                                          test_size=0.5, random_state=42, stratify=y_train)\ngc.collect()","1aafb1bf":"X_train = pd.DataFrame(X_train, columns=train.columns.tolist())\nX_test = pd.DataFrame(X_test, columns=train.columns.tolist())","0eaecbc4":"X_train.head()","f5d21fa4":"X_train.shape","094c4231":"!pip install cleanlab","e6fc13e8":"from cleanlab.classification import LearningWithNoisyLabels","b641b4eb":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline","27235f1d":"scaler = RobustScaler()\nclf = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1)\npipe = make_pipeline(scaler, clf)\n\npipe.fit(X_train, y_train)\n\n# predict on train\/test\ny_hat = pipe.predict_proba(X_train)[:,1]\npred = pipe.predict_proba(X_test)[:,1]\n\n# metrics\nprint(\"Orig. Train AUC:\", roc_auc_score(y_train, y_hat))\nprint(\"Orig. Train Acc:\", balanced_accuracy_score(y_train, y_hat > 0.5))\nprint()\nprint(\"Test AUC:\", roc_auc_score(y_test, pred))\nprint(\"Test Acc:\", balanced_accuracy_score(y_test, pred > 0.5))","78ef1db4":"# initialize\ny_new = y_train\n\n# repeated experiments with label updates to see if we can filter out noisy labels\n# and to see the downstream effects of the performance on the test-set\nfor k in range(5):\n    print(f'Trial {k}:')\n    scaler = RobustScaler()\n    base = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1)\n    clf = LearningWithNoisyLabels(clf=base, seed=42, pulearning=True, prune_method='both', n_jobs=1)\n    pipe = make_pipeline(scaler, clf)\n    pipe.fit(X_train.values, y_new)\n    \n    # predict on train\/test\n    y_hat = pipe.predict_proba(X_train)[:,1]\n    pred = pipe.predict_proba(X_test)[:,1]\n    \n    # metrics\n    print()\n    print(\"Orig. Train AUC:\", roc_auc_score(y_train, y_hat))\n    print(\"Orig. Train Acc:\", balanced_accuracy_score(y_train, y_hat > 0.5))\n    print()\n    print(\"New Train AUC:\", roc_auc_score(y_new, y_hat))\n    print(\"New Train Acc:\", balanced_accuracy_score(y_new, y_hat > 0.5))\n    print()\n    print(\"Test AUC:\", roc_auc_score(y_test, pred))\n    print(\"Test Acc:\", balanced_accuracy_score(y_test, pred > 0.5))\n    print()\n    print(f'\\tMasked: {clf.noise_mask.sum()} out of {X_train.shape[0]}')\n    print()\n    print('=='*30)\n    print()\n    \n    # update labels\n    y_new = (0.5*y_hat + 0.5*y_new > 0.9).astype(np.int)\n#     del clf; gc.collect()","2d4e72dd":"from umap import UMAP","1902e544":"mapper = UMAP(n_components=2, n_neighbors=50, random_state=2021)\nmapper.fit(X_train)\n\nembedded = mapper.transform(X_train)\n\nSIZE = (13, 8)\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","e1df3842":"embedded = mapper.transform(X_test)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","c145737b":"mapper = UMAP(n_components=2, n_neighbors=50, random_state=2021)\nmapper.fit(X_train, y_train)\n\nembedded = mapper.transform(X_train)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","7bd11335":"embedded = mapper.transform(X_test)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","01645565":"y_new = pipe.predict(X_train.values)\n\nmapper = UMAP(n_components=2, n_neighbors=50, random_state=2021)\nmapper.fit(X_train, y_new)\n\nembedded = mapper.transform(X_train)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","c540383f":"embedded = mapper.transform(X_test)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","7e8e8be8":"embedded = mapper.transform(X_train)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","66d523b9":"from sklearn.mixture import BayesianGaussianMixture","ebbaaf47":"gmm = BayesianGaussianMixture(n_components=2, random_state=42)\ngmm.fit(embedded)","9240e23f":"labels = gmm.predict(embedded)\nlabels","ee7024bf":"from sklearn.metrics import homogeneity_score","c19cc7b1":"homogeneity_score(y_new, labels)","6bbdf472":"mapper = UMAP(n_components=2, n_neighbors=50, random_state=2021)\nmapper.fit(X_train, labels)\n\nembedded = mapper.transform(X_train)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","7821e49b":"embedded = mapper.transform(X_test)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()","87585614":"X = X_train.append(X_test, ignore_index=True)\ny_mask = np.append(labels, y_test*0-1)","e16a3acf":"mapper = UMAP(n_components=2, n_neighbors=50, random_state=2021)\nmapper.fit(X, y_mask)\n\nembedded = mapper.transform(X_train)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_train, alpha=0.5, cmap='plasma')\nplt.show()\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=labels, alpha=0.5, cmap='plasma')\nplt.show()","5fec1fe0":"embedded = mapper.transform(X_test)\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=y_test, alpha=0.5, cmap='plasma')\nplt.show()\n\nplt.figure(figsize=SIZE)\nplt.scatter(embedded[:,0], embedded[:,1], c=gmm.predict(embedded), alpha=0.5, cmap='plasma')\nplt.show()","95f6bf41":"# WORK IN PROGRESS\n\nCheck back for updates!","910cde31":"## Metric Learning w\/ UMAP (given cleaned labels)","a5663d97":"## Sample for Small-Scale Experiments","6af12d5c":"## Q: Can we detect the noisy labels in the test-set?","a1d147f8":"## Data Prep","a206d093":"## Manifold Embedding w\/ UMAP","73d13b6f":"## Import Packages","946073f1":"## Metric Learning w\/ UMAP (given noisy labels)","e77dbba2":"## Downcasting","274b7a1d":"## Label Denoising Experiments"}}