{"cell_type":{"b2a05c10":"code","674db204":"code","edb7d538":"code","6050fbf1":"code","cfeb0077":"code","3914b7ac":"code","75252a0f":"code","68d22dd0":"code","c00e1226":"code","06fd89db":"code","ef0b030e":"code","5e549f0c":"markdown","947e66fa":"markdown","61a6cb96":"markdown","ed696119":"markdown","7986f0f7":"markdown","983c356a":"markdown","79fd23fa":"markdown","b944902e":"markdown"},"source":{"b2a05c10":"# Imports\nimport numpy as np \nimport pandas as pd \nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.optimizers import *\nfrom keras.initializers import *\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n\n# Get data\ndf = pd.read_csv('\/kaggle\/input\/cardiovascular-disease-dataset\/cardio_train.csv', delimiter=';')\ndf.drop('id', axis=1, inplace=True)\ndf.head()","674db204":"df.describe()","edb7d538":"df[df['ap_lo'] >= df['ap_hi']]","6050fbf1":"df.drop(df[df[\"ap_lo\"] > df[\"ap_hi\"]].index, inplace=True)\ndf.drop(df[df[\"ap_lo\"] <= 30].index, inplace=True)\ndf.drop(df[df[\"ap_hi\"] <= 40].index, inplace=True)\ndf.drop(df[df[\"ap_lo\"] >= 200].index, inplace=True)\ndf.drop(df[df[\"ap_hi\"] >= 250].index, inplace=True)\ndf[['ap_lo', 'ap_hi']].describe()","cfeb0077":"X = df.drop('cardio', axis=1)\nY = df['cardio']\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\ns = StandardScaler()\nx_train = s.fit_transform(x_train)\nx_test = s.transform(x_test)\n\n# Split train set in train and validation set:\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25, random_state=0)","3914b7ac":"# Silence warnings\nimport warnings as w\nw.simplefilter('ignore')\n\n\ndef create_model():\n    # Hyperparameter:\n    init_w = glorot_uniform(seed=0)\n    loss = \"binary_crossentropy\"\n    optimizer = Adadelta()\n    \n    # Defining the model:\n    model = Sequential()\n\n    model.add(Dense(50, kernel_initializer=init_w, input_shape=(x_train.shape[1],)))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(Dropout(rate=0.1))\n\n    model.add(Dense(25, kernel_initializer=init_w))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(Dropout(rate=0.1))\n\n    model.add(Dense(12, kernel_initializer=init_w))\n    model.add(LeakyReLU())\n\n    model.add(Dense(1, kernel_initializer=init_w))\n    model.add(Activation(\"sigmoid\"))\n    \n    model.summary()\n    \n    # Training\n    model.compile(\n        loss=loss,\n        optimizer=optimizer,\n        metrics=[\"accuracy\"])\n\n    return model","75252a0f":"nn = create_model()\nnn.fit(\n    x=x_train,\n    y=y_train,\n    verbose=2,\n    epochs=50,\n    batch_size=256,\n    validation_data=[x_valid, y_valid])","68d22dd0":"# Testing\ntest_score = nn.evaluate(x_test, y_test)\nprint(\"Testing Acc:\", test_score[1])","c00e1226":"y_pred = nn.predict(x_test)\ncm = confusion_matrix(y_test, y_pred.round())\nprint(\"Confusion Matrix:\", \"\\n\", cm)","06fd89db":"tpr, fpr, threshold = roc_curve(y_test, y_pred)\nauc_score = roc_auc_score(y_test, y_pred)\nprint(\"AUC-score:\", auc_score)","ef0b030e":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.plot(tpr, fpr)\nplt.show()","5e549f0c":"To me this looks pretty ok.\nHints and advice would be welcome. (I evaluated the hyperparameter that worked best for me beforehand with some runs of a GridSearch. This is not in the kernel, because of the required runtime. If you want me to share my code for the GridSearch or KFold, feel free to tell me. I am going to put it online then.)","947e66fa":"### Classifikation of a cardiovascular desease with a Neuronal Network\nThis is my first kernel here on kaggle. \nIn this kernel I only drop some data with medically impossible value. There is few data analysis or visualisation, because there are some great examples in other kernels. Furthermore I am not experienced in data engeneering  (maybe you can give me some hints ;) and some things i tried beforehand had no positive impact towards the accuracy of my network.","61a6cb96":"Now it is time to get our X and Y, to split the data in train and test sets and to scale it.","ed696119":"Higher diastolic than systolic blood pressure is impossible, too.\nSo let's remove these.","7986f0f7":"As you can see the min and max values of 'ap_hi' and 'ap_lo' are medically not possible.","983c356a":"Defining the NN is the next step.","79fd23fa":"Thank you for visiting my very first Kernel :)","b944902e":"We get an accuricy on the test set between: **73.3% - 73.7%**"}}