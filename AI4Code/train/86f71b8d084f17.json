{"cell_type":{"d598fee7":"code","f973075e":"code","6255a5fd":"code","02646126":"code","34305fa6":"code","411cd99b":"code","692e4463":"code","8c5fe4e3":"code","41bc59fa":"code","d7f6ca11":"code","f52a284d":"code","99fdc29e":"code","1eb9604e":"code","4c9e2089":"code","d81da3f9":"code","5674de14":"code","2ff0e9dd":"code","dfa3ac93":"code","3eba9393":"code","7c6799d3":"code","43d2b5c2":"code","217cd9d2":"code","154b5675":"code","283cce12":"code","e4b0da10":"code","3b8c0ab4":"code","856148eb":"code","9addb03e":"code","5cdfa795":"code","a9e24b81":"code","f22ba8f1":"code","10e9e7e9":"code","6265e13e":"code","4981be73":"code","1813f64e":"code","96375bc7":"code","984e92c6":"code","5952a43e":"code","9f376ef0":"code","d952631a":"code","ca1e9251":"code","bca38537":"code","8791e2c8":"code","011c354a":"code","eb971e2b":"code","1935bbe9":"code","5002f63e":"markdown","32eb6c97":"markdown","920942b4":"markdown","6d89f0cf":"markdown","a97523dc":"markdown","75cc46ef":"markdown","14e4e51c":"markdown","87aa54ce":"markdown","4ded48b8":"markdown","16dd25ed":"markdown","af5bdb69":"markdown","9fdda3d8":"markdown","b8bcba89":"markdown","bd7d721d":"markdown","7edf5d6e":"markdown","e01dd7dd":"markdown","472f723e":"markdown","4cc72129":"markdown","2b737897":"markdown","78222be6":"markdown","806fb987":"markdown","31bd3c46":"markdown","68570511":"markdown","3916605c":"markdown"},"source":{"d598fee7":"# Caricamento delle librerie\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GRU, Embedding\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","f973075e":"import pandas as pd\nfrom sklearn.model_selection import train_test_split","6255a5fd":"dataset = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv', encoding='utf-8')\ndataset.head()# mostra le rpime righe del set di dati","02646126":"from sklearn.preprocessing import LabelEncoder","34305fa6":"# associa a ogni parere valutazione un numero intero come etichetta (in questo caso 0 o 1)\nle = LabelEncoder()\ny = le.fit_transform(dataset.sentiment)\ndataset.sentiment = y\ndataset.head","411cd99b":"from sklearn.utils import shuffle","692e4463":"dataset=np.array(dataset)","8c5fe4e3":"dataset.shape","41bc59fa":"# mescola in modo pseudo-casuale i dati (con lo stesso random_state si trovano gli stessi risultati)\ndataset = shuffle(dataset, random_state=232)","d7f6ca11":"# divide il dataset in una parte utilizzata per l'addestramento e una per il test\npercentuale_training = 0.5\nsplit = int(dataset.shape[0]*percentuale_training)\ntrain,test = dataset[:split,:],dataset[split:,:]","f52a284d":"# separa le etichette dal testo della recensione\nx_train_text = train[:,0]\nx_test_text = test[:,0]\n\ny_train = train[:,1] #qui meglio definirle label \ny_test = test[:,1]","99fdc29e":"print(\"Train-set size: \", len(y_train))\nprint(\"Test-set size:  \", len(y_test))","1eb9604e":"x_train_text.shape","4c9e2089":"# Visualizza un esempio di recensione positiva e la relativa etichetta\nx_test_text[1]","d81da3f9":"y_test[1]","5674de14":"num_words = 10000\ntokenizer = Tokenizer(num_words=num_words)","2ff0e9dd":"%%time\n# ricombina insieme i soli insiemi di testo\ndata_text = x_train_text + x_test_text\ntokenizer.fit_on_texts(data_text)","dfa3ac93":"#if num_words is None:\n#    num_words = len(tokenizer.word_index)","3eba9393":"tokenizer.word_index","7c6799d3":"# definiamo un nuovo vettore che contiene i testi convertiti\nx_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n# visualizziamo un esempio del set di training\nx_train_text[1]","43d2b5c2":"# e la sua corrispondente conversione \nnp.array(x_train_tokens[1])","217cd9d2":"# convertiamo anche i testi del set di test\nx_test_tokens = tokenizer.texts_to_sequences(x_test_text)","154b5675":"# Per prima cosa contiamo il numero di token in tutte le sequenze nel set di dati\nnum_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\nnum_tokens = np.array(num_tokens)\n# e ne calcoliamo media e deviazione standard\nprint(np.mean(num_tokens))\nprint(np.std(num_tokens))","283cce12":"# il numero massimo di token \u00e8\nprint(np.max(num_tokens))\n# e noi scegliamo come massimo la media pi\u00f9 due deviazioni stardard in modo da avere il 95% dei dati\nmax_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\nmax_tokens = int(max_tokens)\nprint(max_tokens)\n# e verifichiamo la percentuale dei dati inclusi \nprint(np.sum(num_tokens < max_tokens) \/ len(num_tokens))","e4b0da10":"# questa operazione di riempimento o troncamento viene eseguita con una fuzione di libreria\npad = 'pre'\nx_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n                            padding=pad, truncating=pad)\nx_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n                           padding=pad, truncating=pad)","3b8c0ab4":"# adesso i set hanno tutti la stessa dimensione\nprint(x_train_pad.shape)\nprint(x_test_pad.shape)","856148eb":"# ne visualizziamo uno come esempio prima\nprint(np.array(x_train_tokens[1]))\nprint(\"In questo caso sono stati aggiunti degli zeri prima\")\n# e dopo l'operazione\nprint(x_train_pad[1])","9addb03e":"idx = tokenizer.word_index\ninverse_map = dict(zip(idx.values(), idx.keys()))","5cdfa795":"# definiamo una funzione che esegua la corrispondenza\ndef tokens_to_string(tokens):\n    # Map from tokens back to words.\n    words = [inverse_map[token] for token in tokens if token != 0]\n    \n    # Concatenate all words.\n    text = \" \".join(words)\n\n    return text","a9e24b81":"# visualizziamo un esempio iniziale \nprint(x_train_text[1])\n# e la sua ricostruzione\ntokens_to_string(x_train_tokens[1])","f22ba8f1":"model = Sequential()","10e9e7e9":"embedding_size = 8\nmodel.add(Embedding(input_dim=num_words,\n                    output_dim=embedding_size,\n                    input_length=max_tokens)) # a questo livello corrispondono input_dim * output_dim parametri ","6265e13e":"model.add(GRU(units=16, return_sequences=True))# ogni livello ha un numero di parametri pari a 3*(n^2+nm+2n) dove n \u00e8 il numero di unit\u00e0 e m il numero di input\nmodel.add(GRU(units=8, return_sequences=True))\nmodel.add(GRU(units=4))\nmodel.add(Dense(1, activation='sigmoid'))","4981be73":"model.summary()","1813f64e":"tf.keras.utils.plot_model(model)","96375bc7":"batch_size = 256\nepochs = 5\nvalidation_split = 0.05","984e92c6":"optimizer = Adam(learning_rate=1e-3)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])","5952a43e":"%%time\nhistory = model.fit(x_train_pad, y_train.astype('float32'),validation_split=validation_split,\n           epochs=epochs, batch_size=batch_size)","9f376ef0":"# Visualizza gli andamenti accuratezza e perdita durante l'addestramento\nfig = plt.figure(figsize=(15, 5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\n\nfig.savefig('metrics.png')#deve essere chiamato prima di show() altrimenti il file.png rimane vuoto\nfig.show()","d952631a":"%%time\nresult = model.evaluate(x_test_pad, y_test.astype('float32'),batch_size=batch_size)","ca1e9251":"print(\"Accuracy: {0:.2%}\".format(result[1]))","bca38537":"%%time\ny_pred = model.predict(x=x_test_pad[0:1000])\ny_pred = y_pred.T[0]","8791e2c8":"cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\ncls_true = np.array(y_test[0:1000])","011c354a":"incorrect = np.where(cls_pred != cls_true)\nincorrect = incorrect[0]","eb971e2b":"# il numero di testi mal classificati \u00e8\nlen(incorrect)\n# visualizziamo un esempio\nidx = incorrect[0]\nprint(idx)\n\n# il testo classificato male \u00e8\ntext = x_test_text[idx]\nprint(text)","1935bbe9":"# valore vero e la corrispondente predizione\nprint(y_pred[idx])\nprint(cls_true[idx])","5002f63e":"Per mostrare un esempio di testo classificato erroneamente, calcoliamo prima la classificazione prevista per i primi 1000 testi nel set di test.","32eb6c97":"Le principali modifiche rispetto al codice di partenza riguardano\n\n*   la traduzione in italiano dei commenti, mentre si rimanda al testo originale per le dettagliate spiegazioni inziali, soprattutto sulle Reti Neurali Ricorsive;\n*   il diverso file contente i dati di partenza, che nel caso in esame \u00e8 un file .csv che comprende sia il set di traning sia quello di test, e da cui questo seguono anche alcune differenze nella suddivisione di tali set;\n*   \u00e8 stato scelto questo set iniziale di dati https:\/\/www.kaggle.com\/lakshmi25npathi\/imdb-dataset-of-50k-movie-reviews perch\u00e9 al tempo stesso compatto e con una dimensione ridotta;\n*   alcuni aggiornamenti di funzioni e comandi obsoleti;\n*   sono state aumentate le dimensioni dei batch in modo da velocizzare le prime esecuzioni.\n\n","920942b4":"I valori dele previsioni sono numeri compresi tra 0,0 e 1,0. Usiamo un cutoff\/soglia e diciamo che tutti i valori superiori a 0,5 vengono considerati 1,0 e tutti i valori inferiori a 0,5 vengono considerati 0,0. Questo ci d\u00e0 una \"classe\" prevista di 0,0 o 1,0 che confrontiamo con i valori veri","6d89f0cf":"Possiamo quindi utilizzare il tokenizer per convertire tutti i testi nel training-set in elenchi di questi token.","a97523dc":"Il tokenizer deve essere adattato al set di dati: esegue la scansione di tutto il testo, rimuove i caratteri indesiderati come la punteggiatura e lo converte in caratteri minuscoli. Il tokenizer crea quindi un vocabolario di tutte le parole univoche insieme a varie strutture di dati per l'accesso ai dati.\n\nA questo livello stiamo semplicemente costruendo un vocabolario e vogliamo che sia il pi\u00f9 completo possibile, per questo il tokenizer \u00e8 applicato all'intero set di dati in modo che raccolga le parole sia dai dati di addestramento che di test. La rete neurale effettiva sar\u00e0 poi addestrata solo sul training-set.","75cc46ef":"If you want to use the entire vocabulary then set `num_words=None` above, and then it will automatically be set to the vocabulary-size here. (This is because of Keras' somewhat awkward implementation.)","14e4e51c":"Possiamo quindi esaminare il vocabolario che \u00e8 stato creato dal tokenizer e che \u00e8 ordinato dal numero di occorrenze delle parole nel set di dati. Questi numeri interi sono chiamati indici di parole o \"token\" perch\u00e9 identificano in modo univoco ogni parola nel vocabolario.","87aa54ce":"## Addestramento del modello\n\nDefiniamo i parametri del training e in particolare la percentuale di dati che vogliamo usare nel set di validation per evitar l'overfitting","4ded48b8":"Un altro esempio analogo \u00e8 disponibile a questo indirizzo\n\nhttps:\/\/towardsdatascience.com\/a-complete-step-by-step-tutorial-on-sentiment-analysis-in-keras-and-tensorflow-ea420cc8913f\n\nQuello che segue \u00e8 un esempio in italiano dove per\u00f2 il set di dati utilizzato \u00e8 gi\u00e0 codificato\n\nhttps:\/\/blog.profession.ai\/come-creare-una-rete-neurale-per-la-sentiment-analysis-con-keras\/\n\n","16dd25ed":"Quando si riempiono o si troncano le sequenze che hanno una lunghezza diversa, \u00e8 necessario determinare se si desidera eseguire questo riempimento o troncare 'pre' o 'post'. Se una sequenza viene troncata, significa che una parte della sequenza viene semplicemente buttata via. Se una sequenza viene riempita, significa che vengono aggiunti degli zeri alla sequenza.\n\nQuindi la scelta di \"pre\" o \"post\" pu\u00f2 essere importante perch\u00e9 determina se eliminiamo la prima o l'ultima parte di una sequenza durante il troncamento e determina se aggiungiamo zeri all'inizio o alla fine della sequenza durante il riempimento. Ci\u00f2 pu\u00f2 confondere la rete neurale ricorrente.","af5bdb69":"Possiamo quindi ottenere indici per tutti i testi che sono stati classificati in modo errato confrontando tutte le \"classi\" di questi due array.","9fdda3d8":"### Riempimento e troncamento dei dati\n\nLa rete neurale ricorrente pu\u00f2 accettare sequenze di lunghezza arbitraria come input, ma per utilizzare un intero batch di dati, le sequenze devono avere la stessa lunghezza. Per ottenere questo risultato facciamo un compromesso e useremo una lunghezza di sequenza che copra la maggior parte delle sequenze nel set di dati: troncheremo le sequenze pi\u00f9 lunghe e aggiungeremo elementi a quelle pi\u00f9 corte.","b8bcba89":"![by-nc.eu.png](data:image\/png;base64,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)","bd7d721d":"\n\n# Sentiment Analysis con l'IMDB - A. Piccione\n","7edf5d6e":"In questo caso usiamo il metodo dell'embedding per rappresentare variabili discrete come vettori continui.\n\nIn pratica realizziamo una rappresentazione vettoriale continua e a bassa dimensione (nel nostro caso embedding_size) di un insieme di variabili discrete (nel nostro caso le 10000 parole tradotte in token). Questo metodo \u00e8 utile perch\u00e9 permette di ridurre la dimensionalit\u00e0 delle variabili categoriali e rappresentare in modo significativo le categorie nello spazio trasformato, cercando i vicini pi\u00f9 prossimi nell'insieme di partenza.\n\nLa dimensione del vettore di embedding \u00e8 tipicamente tra 100 e 300, ma sembra funzionare ragionevolmente bene con valori piccoli per l'analisi del sentiment.\n\nPer approfondire:\n\n* https:\/\/towardsdatascience.com\/neural-network-embeddings-explained-4d028e6f0526 \n* https:\/\/keras.io\/api\/layers\/core_layers\/embedding\/","e01dd7dd":"## Caricamento dei dati\n\nUseremo un set di dati composto da 50000 recensioni di film da IMDB. Keras ha una funzione integrata per scaricare un set di dati simile, ma pi\u00f9 piccolo in cui il testo del set di dati \u00e8 gi\u00e0 stato preprocessato; dal momento che questa operazione di analisi del \u00e8 uno degli aspetti pi\u00f9 interessanti, in questo esempio scarichiamo il set con tutti i dati effettivi di 84 MB (il set di dati \u00e8 gi\u00e0 asssociato a questo codice).","472f723e":"## Creazione del modello\n","4cc72129":"### Tokenizer mappa inversa\n\nVogliamo ora poter ricostruire un testo a partire dai token","2b737897":"## License (MIT)\n\nCopyright (c) 2018 by [Magnus Erik Hvass Pedersen](http:\/\/www.hvass-labs.org\/)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and\/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","78222be6":"Utilizziamo poi delle reti neurali ricorrenti (RNN) che prevedono collegamenti all\u2019indietro o verso lo stesso livello. In questa tipologia di reti l\u2019output di un neurone pu\u00f2 influenzare se stesso, in uno step temporale successivo o pu\u00f2 influenzare neuroni della catenza precedente che a loro volta interferiranno con il comportamento del neurone su cui si chiude il loop. Sono presenti diverse implentazioni di questi modelli, qui usiamo la Gated Recurrent Unit.\n\nCi sono tre livelli GRU (https:\/\/keras.io\/api\/layers\/recurrent_layers\/gru\/) della rete, ognuno dei quali ha una frase come output e alla fine un livello Dense che avr\u00e0 come output valori da 0.0 a 1.0 e che servono per classificare il testo","806fb987":"## Analisi dell'addestramento e verifica dei risultati","31bd3c46":"## Preparazione dei dati","68570511":"Questo \u00e8 un esempio basato sul lavoro *Natural Language Processing*\ndi [Magnus Erik Hvass Pedersen](http:\/\/www.hvass-labs.org\/)\n\/ [GitHub](https:\/\/github.com\/Hvass-Labs\/TensorFlow-Tutorials) \/ [Video su YouTube](https:\/\/www.youtube.com\/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ) e disponibile nel dettaglio a questo indirizzo\n\nhttps:\/\/colab.research.google.com\/github\/Hvass-Labs\/TensorFlow-Tutorials\/blob\/master\/20_Natural_Language_Processing.ipynb","3916605c":"### Tokenizer\n\nUna rete neurale non pu\u00f2 funzionare direttamente su stringhe di testo, quindi dobbiamo convertirla in qualche modo. Ci sono due passaggi in questa conversione, il primo passaggio \u00e8 chiamato \"tokenizer\" che converte le parole in numeri interi e viene eseguito sul set di dati prima che venga immesso nella rete neurale. Il secondo passaggio \u00e8 una parte integrata della rete neurale stessa ed \u00e8 chiamato strato \"incorporamento\", descritto pi\u00f9 avanti.\n\nPossiamo istruire il tokenizzatore a utilizzare solo ad es. le 10.000 parole pi\u00f9 popolari dal set di dati."}}