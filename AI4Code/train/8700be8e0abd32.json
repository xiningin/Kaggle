{"cell_type":{"96c52dd5":"code","829a2788":"code","1c8a9cea":"code","bfff5b82":"code","4fc1b584":"code","614c04d9":"code","7f3bad5a":"code","d34b0b60":"code","7a8ba93c":"code","ff0ba3da":"code","0ff13521":"code","777678bb":"code","aaa1f266":"code","2c755551":"code","32bbfe3d":"markdown"},"source":{"96c52dd5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport string\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files t","829a2788":"test_df = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\ntrain_df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","1c8a9cea":"import re\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    \n    return text\n  \n  \ntrain_df['clean_text'] = train_df['text'].apply(lambda x: clean_text(x))\ntest_df['clean_text'] = test_df['text'].apply(lambda x: clean_text(x))\n\ntrain_df.head()","bfff5b82":"#train['filtered_tweet'] = train['text'].apply(lambda x: clean_text(x)).str.split()\nS_concat = pd.concat([train_df.clean_text, test_df.clean_text])\n\nl_all_words = []\nfor i in S_concat:\n    l_all_words = l_all_words + i.split(\" \")\n\nl_attributes = list(set(l_all_words))\n\nprint(\"Length of all_words: \", len(l_all_words))\nprint(\"Length of attributes: \", len(l_attributes))","4fc1b584":"def add_att_to_df(df_original, df, att):\n    #\u628aatt\u88e1\u7684\u6240\u6709\u5b57\u52a0\u5230\u7279\u5fb5\u88e1\n    l = []\n    \n    for i in att:\n        df[i] = 0\n        l = l + [0]\n                 \n    for i in range(len(df_original)):\n        df.loc[i] = l\n\n    return df\n\ndef text_to_n_att(df_original, df_att):\n\n    for i in range(len(df_original)): #i = 0\u5230\u6578\u64da\u7e3d\u6578\n      for j in range(len(df_original.clean_text[i].split(' '))): #j = 0\u5230\u6578\u64da\u300ci\u300d\u7684clean_text\u8a5e\u7684\u7e3d\u6578\n        a = df_original.clean_text[i].split(' ')[j] # a = \u7b2cj\u500b\u8a5e\n        df_att.loc[i, a] = 1 #row\u300c\u6578\u64dai\u300d column\u300ca\u300d \u6539\u62101\n    return df_att","614c04d9":"new_train_df = pd.DataFrame()\nadd_att_to_df(train_df, new_train_df, l_attributes)\nnew_train_df = text_to_n_att(train_df, new_train_df)\n\nnew_test_df = pd.DataFrame()\nadd_att_to_df(test_df, new_test_df, l_attributes)\nnew_test_df = text_to_n_att(test_df, new_test_df)\n\nnew_train_df","7f3bad5a":"training_size = int(len(train_data) * 3 \/ 4)\nprint(training_size)\n\nX_train = train_data[ : training_size]\nX_valid = train_data[training_size : ]\nX_test = new_test_df.to_numpy() #test_df \u6c92\u6709target\u6240\u4ee5\u662f\u5f9e 5 \u958b\u59cb\ny_train = train_labels[ : training_size].reshape(-1,1)\ny_valid = train_labels[training_size : ].reshape(-1,1)\n\nprint(X_train, '\\n')\nprint(X_valid, '\\n')\nprint(y_train, '\\n')\nprint(y_valid, '\\n')","d34b0b60":"from sklearn.svm import SVC\nsvm=SVC(probability=True,decision_function_shape='ovr')\nsvm.fit(X_train,y_train)","7a8ba93c":"from sklearn.model_selection import cross_val_score\nAscore_svm = cross_val_score(svm,X_train,y_train,cv = 3,scoring = \"accuracy\")","ff0ba3da":"np.average(Ascore_svm)","0ff13521":"X_test\nsvm.predict([X_valid[236]])","777678bb":"from sklearn.metrics import accuracy_score\nfor clf in (svm):\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_valid)\n    print(clf,__class__.__name__,accuracy_score(X_valid,y_pred))","aaa1f266":"svm.predict([X_test[3]])\n60\nresult_df = pd.DataFrame(columns = ['id', 'target'])\nfor index in range(len(X_test)):\n    result_df.loc[index] = [test_df.id[index], svm.predict([X_test[index]])]","2c755551":"len(X_test[0])","32bbfe3d":"SVC"}}