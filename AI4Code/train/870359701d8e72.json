{"cell_type":{"7c6c1f55":"code","9fab06c6":"code","d48027dc":"code","303221f0":"code","0561c698":"code","244cf887":"code","84351b3e":"code","6b586c1d":"code","50d22715":"code","b53fd85f":"code","31661dbf":"code","7108a413":"code","68afb07f":"code","bb20d3ac":"code","380f50bf":"code","684751d0":"code","2900bc24":"code","1a06495c":"code","b77e41bc":"code","0fd94ec6":"code","6dc83566":"code","a1490846":"code","aea5ebbf":"code","aa150a55":"code","e41c3c0f":"code","606e0dc5":"code","95c23171":"code","98f09ca2":"code","fda92298":"code","cec80846":"code","4d266506":"code","d34c3f45":"code","15c9082f":"code","cfddc1d1":"code","565338bd":"code","74790df0":"code","e2efc532":"code","d1d5db29":"code","c596ab50":"code","9786c5bc":"code","da7871c0":"code","e4158944":"code","b96044d7":"code","1481c0c7":"code","d8298d2b":"code","4a4e2587":"code","7947a321":"code","e02c9138":"code","52d49c07":"code","9dd1ada6":"code","41ceb095":"code","184d2d15":"code","2f03c4c7":"code","bccf0847":"code","5f359de4":"code","8c87e4c0":"code","e8d12386":"code","bae22f9a":"code","9d1e9af4":"code","57135bbe":"code","ed200df7":"code","1e621b77":"code","372fcdb2":"code","123f662b":"code","7972a5dc":"code","eab00b2e":"code","326debd4":"code","03a91600":"code","ac7493cb":"code","6a263613":"code","cbb4d8fb":"code","0c001709":"code","3161c2ec":"code","ea4d11af":"code","7ab43452":"code","0fbccf3d":"code","1b8a96f8":"code","08b45a9a":"code","314971ee":"code","24287bad":"code","01d06e36":"code","578805c5":"code","7c9a9270":"code","57cab550":"code","21258ab9":"code","3ffa5aac":"code","45f73577":"code","16e09a2a":"code","6b51d493":"code","f5323cab":"code","ae93f933":"code","906f4089":"code","ef67ad46":"code","d6da73a8":"code","11260deb":"code","57e24d30":"code","11acd27e":"code","a91fe785":"code","fda42b3d":"code","04f0859e":"code","fcf3dc07":"code","f12d5eb4":"code","96baf1c5":"code","e90a71fe":"code","96e6e2b1":"code","66b2c642":"code","4c3c072e":"code","c1d227bc":"code","c09a82a1":"code","175abb48":"code","a89f7a57":"code","0bb24131":"code","96069aa1":"code","c825f344":"code","dee39e26":"code","fe1d3598":"code","10acd8c1":"code","92331e81":"code","4ff41ab7":"code","69c371b2":"code","3b45fd2e":"code","f8f34794":"code","3f103222":"code","0984872c":"code","fbdc334c":"code","1d8b8aad":"code","884a2a50":"code","022e2424":"code","b0982055":"code","01b61101":"code","773bf4e1":"code","32e598fd":"code","675512d4":"markdown","66655e61":"markdown","5581cdc6":"markdown","e46cd318":"markdown","ee527314":"markdown","a3c26890":"markdown","14e6cb9c":"markdown","ebc195d5":"markdown","5ea980aa":"markdown","b82815c3":"markdown","a141138e":"markdown","2d5c26b2":"markdown","64e4780a":"markdown","399493f0":"markdown","a23dfa02":"markdown","f913bc0e":"markdown","bf2b1b5b":"markdown","f004ca5e":"markdown","77be4f52":"markdown","f0f266cc":"markdown","ade79fd2":"markdown","955dcfed":"markdown","f0253c61":"markdown","b462e706":"markdown","dbd86fb3":"markdown","a69c9966":"markdown","8b7dd14e":"markdown","3d96f1bd":"markdown","35be8ea2":"markdown","971f54e3":"markdown","3c1ab269":"markdown","b1e75687":"markdown","2c08f2a2":"markdown","a24772c9":"markdown","31683598":"markdown","91f25f75":"markdown","5c6b5eb3":"markdown","5e52c46d":"markdown","b01a5ebc":"markdown","7d6953ba":"markdown","18f6aca1":"markdown","caedbfd9":"markdown","9719d6a8":"markdown","cfcb1431":"markdown","baf48f98":"markdown","fbb12d64":"markdown","7b6e18fb":"markdown","cf8acf09":"markdown","8791044e":"markdown","af6395a0":"markdown","fccaa2fa":"markdown","a14ee78f":"markdown","912e8def":"markdown","d145b4ab":"markdown","dd8def8a":"markdown","0f4ca3e9":"markdown","a7610f5f":"markdown","b0a2bbf6":"markdown","5d36ed75":"markdown","b2eb2719":"markdown","388e6adf":"markdown","083bd71e":"markdown","31a477f8":"markdown","145d8193":"markdown","c5846a37":"markdown","0b7362b7":"markdown","b0b2f9d6":"markdown","407817d3":"markdown","0170811c":"markdown","261df5a1":"markdown","238d3549":"markdown","5e182e19":"markdown","326406a7":"markdown","ecbea097":"markdown","e868afe0":"markdown","cd818801":"markdown","8fcbb4d6":"markdown","2f44b40a":"markdown","abee22f7":"markdown","51246ebe":"markdown","b3e9a2a3":"markdown","ead4d4b8":"markdown","ddafeee0":"markdown","9b6f1ec1":"markdown","ff2b275d":"markdown","66caeb06":"markdown","ba585642":"markdown","b84dbd2d":"markdown","8a3a7a3f":"markdown","aa651805":"markdown","0b3ffd34":"markdown","bd51f381":"markdown","5cea0a43":"markdown","d3873bb6":"markdown","90ae6902":"markdown","c36639e7":"markdown","c1d87ac3":"markdown","7c49b559":"markdown","f29d7c06":"markdown","1a900e44":"markdown","6fa213c1":"markdown","db8d3595":"markdown","d8021e8f":"markdown","a3966b7f":"markdown","a7fdbf21":"markdown","091ee5b0":"markdown","55f44e8e":"markdown"},"source":{"7c6c1f55":"import numpy as np\nimport pandas as pd \nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale, StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import plot_confusion_matrix, confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report, precision_recall_curve, auc\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nimport missingno as msno\n\nimport warnings\nwarnings.simplefilter(action = 'ignore')","9fab06c6":"diabetes = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\n","d48027dc":"diabetes.head()","303221f0":"diabetes.info()","0561c698":"diabetes.describe([0.10, 0.25, 0.40, 0.50,0.70, 0.90,0.95, 0.99]).T","244cf887":"df = diabetes.copy()\ndf[\"Outcome\"].value_counts()","84351b3e":"df.corr()","6b586c1d":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","50d22715":"df.head()","b53fd85f":"df.groupby(\"Outcome\").agg({\"Pregnancies\":\"mean\"})","31661dbf":"df.groupby(\"Outcome\").agg({\"Age\":\"mean\"})","7108a413":"df.groupby(\"Outcome\").agg({\"Age\":\"max\"})","68afb07f":"df.groupby(\"Outcome\").agg({\"Insulin\": \"mean\"})","bb20d3ac":"df.groupby(\"Outcome\").agg({\"Insulin\": \"max\"})","380f50bf":"df.groupby(\"Outcome\").agg({\"Glucose\": \"mean\"})","684751d0":"df.groupby(\"Outcome\").agg({\"Glucose\": \"max\"})","2900bc24":"df.groupby(\"Outcome\").agg({\"BMI\": \"mean\"})","1a06495c":"df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","b77e41bc":"df.isnull().sum()","0fd94ec6":"msno.bar(df);","6dc83566":"def median_target(sfy):   \n    temp = df[df[sfy].notnull()]\n    temp = temp[[sfy, 'Outcome']].groupby(['Outcome'])[[sfy]].median().reset_index()\n    return temp\n\ncolumns = df.columns\ncolumns = columns.drop(\"Outcome\")\nfor i in columns:\n    median_target(i)\n    df.loc[(df['Outcome'] == 0 ) & (df[i].isnull()), i] = median_target(i)[i][0]\n    df.loc[(df['Outcome'] == 1 ) & (df[i].isnull()), i] = median_target(i)[i][1]","a1490846":"df.head()","aea5ebbf":"df.isnull().sum()","aa150a55":"sns.set(font_scale=0.7) \nfig, axes = plt.subplots(nrows=int(len(df.columns)\/2), ncols=2,figsize=(7,12))\nfig.tight_layout()\nfor ax,col in zip(axes.flatten(),df.columns):\n    sns.boxplot(x=df[col],ax=ax)","e41c3c0f":"for feature in df:\n    \n    Q1 = df[feature].quantile(0.05)\n    Q3 = df[feature].quantile(0.95)\n    IQR = Q3-Q1\n    upper = Q3 + 1.5*IQR\n    \n    if df[(df[feature] > upper)].any(axis=None):\n        print(feature,\"yes\")\n    else:\n        print(feature, \"no\")","606e0dc5":"Q1 = df.Insulin.quantile(0.25)\nQ3 = df.Insulin.quantile(0.75)\nIQR = Q3-Q1\nlower = Q1 - 1.5*IQR\nupper = Q3 + 1.5*IQR\ndf.loc[df[\"Insulin\"] > upper,\"Insulin\"] = upper","95c23171":"Q1 = df.SkinThickness.quantile(0.25)\nQ3 = df.SkinThickness.quantile(0.75)\nIQR = Q3-Q1\nlower = Q1 - 1.5*IQR\nupper = Q3 + 1.5*IQR\ndf.loc[df[\"SkinThickness\"] > upper,\"SkinThickness\"] = upper","98f09ca2":"from sklearn.neighbors import LocalOutlierFactor\nlof = LocalOutlierFactor(n_neighbors = 20, contamination = 0.1)\nlof.fit_predict(df)\ndf_scores = lof.negative_outlier_factor_\ndf_scores = pd.DataFrame(np.sort(df_scores))\ndf_scores.plot(stacked=True, xlim=[0,60], style='.-'); # first 20 rows\n    \ndf_scores[0:20]","fda92298":"df_scores.iloc[4,:]","cec80846":"threshold = np.sort(df_scores)[4]\nnew_df = df[np.array(df_scores > threshold)]\nnew_df.info()","4d266506":"df = new_df\ndf.describe().T","d34c3f45":"NewBMI = pd.Series([\"Underweight\", \"Normal\", \"Overweight\", \"Obesity 1\", \"Obesity 2\", \"Obesity 3\"], dtype = \"category\")\ndf[\"NewBMI\"] = NewBMI\ndf.loc[df[\"BMI\"] < 18.5, \"NewBMI\"] = NewBMI[0]\ndf.loc[(df[\"BMI\"] > 18.5) & (df[\"BMI\"] <= 24.9), \"NewBMI\"] = NewBMI[1]\ndf.loc[(df[\"BMI\"] > 24.9) & (df[\"BMI\"] <= 29.9), \"NewBMI\"] = NewBMI[2]\ndf.loc[(df[\"BMI\"] > 29.9) & (df[\"BMI\"] <= 34.9), \"NewBMI\"] = NewBMI[3]\ndf.loc[(df[\"BMI\"] > 34.9) & (df[\"BMI\"] <= 39.9), \"NewBMI\"] = NewBMI[4]\ndf.loc[df[\"BMI\"] > 39.9 ,\"NewBMI\"] = NewBMI[5]","15c9082f":"df.head()","cfddc1d1":"def set_insulin(row):\n    if row[\"Insulin\"] >= 16 and row[\"Insulin\"] <= 166:\n        return \"Normal\"\n    else:\n        return \"Abnormal\"\n    \ndf = df.assign(NewInsulinScore=df.apply(set_insulin, axis=1))\ndf.head()","565338bd":"NewGlucose = pd.Series([\"Low\", \"Normal\", \"Overweight\", \"Secret\", \"High\"], dtype = \"category\")\ndf[\"NewGlucose\"] = NewGlucose\ndf.loc[df[\"Glucose\"] <= 70, \"NewGlucose\"] = NewGlucose[0]\ndf.loc[(df[\"Glucose\"] > 70) & (df[\"Glucose\"] <= 99), \"NewGlucose\"] = NewGlucose[1]\ndf.loc[(df[\"Glucose\"] > 99) & (df[\"Glucose\"] <= 126), \"NewGlucose\"] = NewGlucose[2]\ndf.loc[df[\"Glucose\"] > 126 ,\"NewGlucose\"] = NewGlucose[3]","74790df0":"df.head()","e2efc532":"df = pd.get_dummies(df, columns =[\"NewBMI\",\"NewInsulinScore\", \"NewGlucose\"], drop_first = True)","d1d5db29":"df.head()","c596ab50":"categorical_df = df[['NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret']]","9786c5bc":"categorical_df.head()","da7871c0":"X_ = df.drop(['NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret'], axis = 1)\n","e4158944":"X_.head()","b96044d7":"df = pd.concat([X_,categorical_df], axis = 1)","1481c0c7":"df.head()","d8298d2b":"y = df['Outcome']\nX = df.drop('Outcome', axis = 1)\nX.head()","4a4e2587":"MinMax = MinMaxScaler(feature_range = (0, 1)).fit(X)\nX_st = MinMax.transform(X)\nX_st = pd.DataFrame(X_st, columns = X.columns)\nX_st.head()","7947a321":"sdf = pd.concat([X_st, y], axis = 1)\nsdf.describe().T\n","e02c9138":"avg_accuracies={}\naccuracies={}\nroc_auc={}\npr_auc={}","52d49c07":"def cal_score(name,model,folds):\n    scores = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n    avg_result = []\n    for sc in scores:\n        scores = cross_val_score(model, X_st, y, cv = folds, scoring = sc)\n        avg_result.append(np.average(scores))\n    df_avg_score = pd.DataFrame(avg_result)\n    df_avg_score = df_avg_score.rename(index={0: 'Accuracy',\n                                             1:'Precision',\n                                             2:'Recall',\n                                             3:'F1 score',\n                                             4:'Roc auc'}, columns = {0: 'Average'})\n    avg_accuracies[name] = np.round(df_avg_score.loc['Accuracy'] * 100, 2)\n    values = [np.round(df_avg_score.loc['Accuracy'] * 100, 2),\n            np.round(df_avg_score.loc['Precision'] * 100, 2),\n            np.round(df_avg_score.loc['Recall'] * 100, 2),\n            np.round(df_avg_score.loc['F1 score'] * 100, 2),\n            np.round(df_avg_score.loc['Roc auc'] * 100, 2)]\n    plt.figure(figsize = (15, 8))\n    sns.set_palette('mako')\n    ax = sns.barplot(x = ['Accuracy', 'Precision', 'Recall', 'F1 score', 'Roc auc'], y = values)\n    plt.yticks(np.arange(0, 100, 10))\n    plt.ylabel('Percentage %', labelpad = 10)\n    plt.xlabel('Scoring Parameters', labelpad = 10)\n    plt.title('Cross Validation ' + str(folds) + '-Folds Average Scores', pad = 20)\n    for p in ax.patches:\n        ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 1.02))\n    plt.show()","9dd1ada6":"def conf_matrix(ytest, pred):\n    plt.figure(figsize = (15, 8))\n    global cm1\n    cm1 = confusion_matrix(ytest, pred)\n    ax = sns.heatmap(cm1, annot = True, cmap = 'Blues')\n    plt.title('Confusion Matrix', pad = 30)","41ceb095":"def metrics_score(cm):\n    total = sum(sum(cm))\n    accuracy = (cm[0, 0] + cm[1, 1]) \/ total\n    precision = cm[1, 1] \/ (cm[0, 1] + cm[1, 1])\n    sensitivity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n    f1 = 2 * (precision * sensitivity) \/ (precision + sensitivity)\n    specificity = cm[0,0] \/ (cm[0, 1] + cm[0, 0])\n    values = [np.round(accuracy * 100, 2),\n            np.round(precision * 100, 2),\n            np.round(sensitivity * 100, 2),\n            np.round(f1 * 100, 2),\n            np.round(specificity * 100, 2)]\n    plt.figure(figsize = (15, 8))\n    sns.set_palette('magma')\n    ax = sns.barplot(x = ['Accuracy', 'Precision', 'Recall', 'F1 score', 'Specificity'], y = values)\n    plt.yticks(np.arange(0, 100, 10))\n    plt.ylabel('Percentage %', labelpad = 10)\n    plt.xlabel('Scoring Parameter', labelpad = 10)\n    plt.title('Metrics Scores', pad = 20)\n    for p in ax.patches:\n        ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 1.02))\n    plt.show()","184d2d15":"def plot_roc_curve(fpr, tpr):\n    plt.figure(figsize = (8, 6))\n    plt.plot(fpr, tpr, color = 'Orange', label = 'ROC')\n    plt.plot([0, 1], [0, 1], color = 'black', linestyle = '--')\n    plt.ylabel('True Positive Rate', labelpad = 10)\n    plt.xlabel('False Positive Rate', labelpad = 10)\n    plt.title('Receiver Operating Characteristic (ROC) Curve', pad = 20)\n    plt.legend()\n    plt.show()","2f03c4c7":"def plot_precision_recall_curve(recall, precision):\n    plt.figure(figsize=(8,6))\n    plt.plot(recall, precision, color='orange', label='PRC')\n    plt.ylabel('Precision',labelpad=10)\n    plt.xlabel('Recall',labelpad=10)\n    plt.title('Precision Recall Curve',pad=20)\n    plt.legend()\n    plt.show()","bccf0847":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nlog_model = LogisticRegression()\nlog_model.fit(X_train, y_train)\nprediction1 = log_model.predict(X_test)\naccuracy1 = log_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy1 * 100)","5f359de4":"accuracies['Linear Regression'] = np.round(accuracy1 * 100, 2)","8c87e4c0":"conf_matrix(y_test, prediction1)","e8d12386":"metrics_score(cm1)","bae22f9a":"cal_score('Linear Regression', log_model, 5)","9d1e9af4":"probs = log_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc1 = roc_auc_score(y_test, probs)\nroc_auc['Linear Regression'] = np.round(auc1, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc1)\nfpr1, tpr1, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr1, tpr1)","57135bbe":"precision1, recall1, _ = precision_recall_curve(y_test, probs)\nauc_score1 = auc(recall1, precision1)\npr_auc['Linear Regression'] = np.round(auc_score1, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score1)\nplot_precision_recall_curve(recall1, precision1)","ed200df7":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nKNN_model = KNeighborsClassifier()\nKNN_model.fit(X_train, y_train)\nprediction2 = KNN_model.predict(X_test)\naccuracy2 = KNN_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy2 * 100)","1e621b77":"accuracies['KNeighbors Classifier'] = np.round(accuracy2 * 100, 2)","372fcdb2":"conf_matrix(y_test, prediction2)","123f662b":"metrics_score(cm1)","7972a5dc":"cal_score('KNeighbors Classifier', KNN_model, 5)","eab00b2e":"probs = KNN_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc2 = roc_auc_score(y_test, probs)\nroc_auc['KNeighbors Classifier'] = np.round(auc2, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc2)\nfpr2, tpr2, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr2, tpr2)","326debd4":"precision2, recall2, _ = precision_recall_curve(y_test, probs)\nauc_score2 = auc(recall2, precision2)\npr_auc['KNeighbors Classifier'] = np.round(auc_score2, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score2)\nplot_precision_recall_curve(recall2, precision2)","03a91600":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nSVC_model = SVC(probability = True)\nSVC_model.fit(X_train, y_train)\nprediction3 = SVC_model.predict(X_test)\naccuracy3 = SVC_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy3 * 100)","ac7493cb":"accuracies['Support Vector Machine Classifier'] = np.round(accuracy3 * 100, 2)","6a263613":"conf_matrix(y_test, prediction3)","cbb4d8fb":"metrics_score(cm1)","0c001709":"cal_score('Support Vector Machine Classifier', SVC_model, 5)","3161c2ec":"probs = SVC_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc3 = roc_auc_score(y_test, probs)\nroc_auc['Support Vector Machine Classifier'] = np.round(auc3, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc3)\nfpr3, tpr3, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr3, tpr3)","ea4d11af":"precision3, recall3, _ = precision_recall_curve(y_test, probs)\nauc_score3 = auc(recall3, precision3)\npr_auc['Support Vector Machine Classifier'] = np.round(auc_score3, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score3)\nplot_precision_recall_curve(recall3, precision3)","7ab43452":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nCART_model = DecisionTreeClassifier(max_depth = 10, min_samples_split = 50)\nCART_model.fit(X_train, y_train)\nprediction4 = CART_model.predict(X_test)\naccuracy4 = CART_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy4 * 100)","0fbccf3d":"accuracies['Classification and Regression Tree'] = np.round(accuracy4 * 100, 2)","1b8a96f8":"conf_matrix(y_test, prediction4)","08b45a9a":"metrics_score(cm1)","314971ee":"cal_score('Classification and Regression Tree', CART_model, 5)","24287bad":"probs = CART_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc4 = roc_auc_score(y_test, probs)\nroc_auc['Desicion Tree Classifier']=np.round(auc4, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc4)\nfpr4, tpr4, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr4, tpr4)","01d06e36":"precision4, recall4, _ = precision_recall_curve(y_test, probs)\nauc_score4 = auc(recall4, precision4)\npr_auc['Desicion Tree Classifier'] = np.round(auc_score4, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score4)\nplot_precision_recall_curve(recall4, precision4)","578805c5":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nrf_model = RandomForestClassifier(max_features = 8, min_samples_split = 12, n_estimators = 120)\nrf_model.fit(X_train, y_train)\nprediction5 = rf_model.predict(X_test)\naccuracy5 = rf_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy5 * 100)","7c9a9270":"accuracies['Random Forests'] = np.round(accuracy5 * 100, 2)","57cab550":"conf_matrix(y_test, prediction5)","21258ab9":"metrics_score(cm1)","3ffa5aac":"cal_score('Random Forests', rf_model, 5)","45f73577":"probs = rf_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc5 = roc_auc_score(y_test, probs)\nroc_auc['Random Forests Classifier']=np.round(auc5, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc5)\nfpr5, tpr5, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr5, tpr5)","16e09a2a":"precision5, recall5, _ = precision_recall_curve(y_test, probs)\nauc_score5 = auc(recall5, precision5)\npr_auc['Random Forests'] = np.round(auc_score5,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score5)\nplot_precision_recall_curve(recall5, precision5)","6b51d493":"feature_imp = pd.Series(rf_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","f5323cab":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\ngbm_model = GradientBoostingClassifier(learning_rate = 0.01, max_depth = 2, n_estimators = 500)\ngbm_model.fit(X_train, y_train)\nprediction6 = gbm_model.predict(X_test)\naccuracy6 = gbm_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy6 * 100)","ae93f933":"accuracies['Gradient Boosting Machines'] = np.round(accuracy6 * 100, 2)","906f4089":"conf_matrix(y_test, prediction6)","ef67ad46":"metrics_score(cm1)","d6da73a8":"cal_score('Gradient Boosting Machines', gbm_model, 5)","11260deb":"probs = gbm_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc6 = roc_auc_score(y_test, probs)\nroc_auc['Gradient Boosting Machine Classifier'] = np.round(auc6, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc6)\nfpr6, tpr6, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr6, tpr6)","57e24d30":"precision6, recall6, _ = precision_recall_curve(y_test, probs)\nauc_score6 = auc(recall6, precision6)\npr_auc['Gradient Boosting Machine Classifier'] = np.round(auc_score6, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score6)\nplot_precision_recall_curve(recall6, precision6)","11acd27e":"feature_imp = pd.Series(gbm_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","a91fe785":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nxgb_model = XGBClassifier(learning_rate = 0.01,max_depth = 3, n_estimators = 500, subsample = 1 )\nxgb_model.fit(X_train, y_train)\nprediction7 = xgb_model.predict(X_test)\naccuracy7 = xgb_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy7 * 100)","fda42b3d":"accuracies['XGBoost Classifier'] = np.round(accuracy7 * 100, 2)","04f0859e":"conf_matrix(y_test, prediction7)","fcf3dc07":"metrics_score(cm1)","f12d5eb4":"cal_score('XGBoost Classifier', xgb_model, 5)","96baf1c5":"probs = xgb_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc7 = roc_auc_score(y_test, probs)\nroc_auc['XGB Machine Classifier']=np.round(auc7, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc7)\nfpr7, tpr7, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr7, tpr7)","e90a71fe":"precision7, recall7, _ = precision_recall_curve(y_test, probs)\nauc_score7 = auc(recall7, precision7)\npr_auc['XGB Machine Classifier'] = np.round(auc_score7, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score7)\nplot_precision_recall_curve(recall7, precision7)","96e6e2b1":"feature_imp = pd.Series(gbm_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","66b2c642":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nlgbm_model = LGBMClassifier(learning_rate = 0.1, max_depth = 1, n_estimators = 200)\nlgbm_model.fit(X_train, y_train)\nprediction8 = lgbm_model.predict(X_test)\naccuracy8 = lgbm_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy8 * 100)","4c3c072e":"accuracies['LightGBM Classifier'] = np.round(accuracy8 * 100, 2)","c1d227bc":"conf_matrix(y_test, prediction8)","c09a82a1":"metrics_score(cm1)","175abb48":"cal_score('LightGBM Classifier', lgbm_model, 5)","a89f7a57":"probs = lgbm_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc8 = roc_auc_score(y_test, probs)\nroc_auc['LightGBM Classifier'] = np.round(auc8, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc8)\nfpr8, tpr8, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr8, tpr8)","0bb24131":"precision8, recall8, _ = precision_recall_curve(y_test, probs)\nauc_score8 = auc(recall8, precision8)\npr_auc['LightGBM Classifier'] = np.round(auc_score8, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score8)\nplot_precision_recall_curve(recall8, precision8)","96069aa1":"feature_imp = pd.Series(gbm_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","c825f344":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\ncatboost_model = CatBoostClassifier(depth = 8, iterations = 100, learning_rate = 0.1)\ncatboost_model.fit(X_train, y_train)\nprediction9 = catboost_model.predict(X_test)\naccuracy9 = catboost_model.score(X_test, y_test) \nprint ('Model Accuracy:', accuracy9 * 100)","dee39e26":"accuracies['CatBoost Classifier'] = np.round(accuracy9 * 100, 2)","fe1d3598":"conf_matrix(y_test, prediction9)","10acd8c1":"metrics_score(cm1)","92331e81":"cal_score('CatBoost Classifier', catboost_model, 5)","4ff41ab7":"probs = catboost_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc9 = roc_auc_score(y_test, probs)\nroc_auc['CatBoost Classifier']=np.round(auc9, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc9)\nfpr9, tpr9, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr9, tpr9)","69c371b2":"precision9, recall9, _ = precision_recall_curve(y_test, probs)\nauc_score9 = auc(recall9, precision9)\npr_auc['CatBoost Classifier'] = np.round(auc_score9, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score9)\nplot_precision_recall_curve(recall9, precision9)","3b45fd2e":"feature_imp = pd.Series(gbm_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","f8f34794":"models_tuned = [\n    log_model,\n    KNN_model,\n    SVC_model,\n    CART_model,\n    rf_model,\n    gbm_model,\n    catboost_model,\n    lgbm_model,\n    xgb_model]\n\nresult = []\nresults = pd.DataFrame(columns = [\"Models\",\"Accuracy\"])\n\nfor model in models_tuned:\n    names = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    result = pd.DataFrame([[names, acc * 100]], columns = [\"Models\", \"Accuracy\"])\n    results = results.append(result)\nresults","3f103222":"plt.figure(figsize = (15, 8))\nsns.set_palette('cividis')\nax = sns.barplot(x = list(accuracies.keys()), y = list(accuracies.values()))\nplt.yticks(np.arange(0, 100, 10))\nplt.ylabel('Percentage %', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Accuracy Scores Comparison', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 1.02))\nplt.show()","0984872c":"plt.figure(figsize = (15, 8))\nsns.set_palette('viridis')\nax=sns.barplot(x = list(avg_accuracies.keys()), y = list(avg_accuracies.values()))\nplt.yticks(np.arange(0, 100, 10))\nplt.ylabel('Percentage %', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Average Accuracy Scores Comparison', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x() + 0.3, p.get_height() + 1.02))\nplt.show()","fbdc334c":"plt.figure(figsize = (8, 6))\nsns.set_palette('Set1')\nplt.plot(fpr1, tpr1, label = 'Linear Regression')\nplt.plot(fpr2, tpr2, label = 'KNeiihbors Classifier')\nplt.plot(fpr3, tpr3, label = 'SVM')\nplt.plot(fpr4, tpr4, label = 'Decision Tree')\nplt.plot(fpr5, tpr5, label = 'Random Forests')\nplt.plot(fpr6, tpr6, label = 'Gradient Boosting MachineC')\nplt.plot(fpr7, tpr7, label = 'XGBoost')\nplt.plot(fpr8, tpr8, label = 'LightGBM')\nplt.plot(fpr9, tpr9, label = 'CatBosst')\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.ylabel('True Positive Rate', labelpad = 10)\nplt.xlabel('False Positive Rate', labelpad = 10)\nplt.title('Receiver Operating Characteristic (ROC) Curves', pad = 20)\nplt.legend()\nplt.show()","1d8b8aad":"plt.figure(figsize = (15, 8))\nsns.set_palette('magma')\nax = sns.barplot(x = list(roc_auc.keys()), y = list(roc_auc.values()))\n#plt.yticks(np.arange(0,100,10))\nplt.ylabel('Score', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Area under the ROC Curves (AUC)', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 0.01))\nplt.show()","884a2a50":"plt.figure(figsize = (8, 6))\nsns.set_palette('Set1')\nplt.plot(recall1, precision1, label = 'Linear Regression PRC')\nplt.plot(recall2, precision2, label = 'KNN PRC')\nplt.plot(recall3, precision3, label = 'SVM PRC')\nplt.plot(recall4, precision4, label = 'CART PRC')\nplt.plot(recall5, precision5, label = 'Random Forests PRC')\nplt.plot(recall6, precision6, label = 'GBM PRC')\nplt.plot(recall7, precision7, label = 'XGB PRC')\nplt.plot(recall5, precision5, label = 'LGBM PRC')\nplt.plot(recall6, precision6, label = 'CatBoost PRC')\nplt.ylabel('Precision', labelpad = 10)\nplt.xlabel('Recall', labelpad = 10)\nplt.title('Precision Recall Curves', pad = 20)\nplt.legend()\nplt.show()","022e2424":"plt.figure(figsize = (15, 8))\nsns.set_palette('mako')\nax = sns.barplot(x = list(pr_auc.keys()), y = list(pr_auc.values()))\nplt.ylabel('Score', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Area under the PR Curves (AUCPR)', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 0.01))\nplt.show()","b0982055":"X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size = 0.20, random_state = 5)\nrf_model = RandomForestClassifier(max_features = 8, min_samples_split = 12, n_estimators = 120)\nrf_model.fit(X_train, y_train)\nprediction5 = rf_model.predict(X_test)\naccuracy5 = rf_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy5 * 100)","01b61101":"conf_matrix(y_test, prediction5)","773bf4e1":"metrics_score(cm1)","32e598fd":"cal_score('Random Forests', rf_model, 10)","675512d4":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","66655e61":"1. Plotting Confusion Matrix to describe the performance of Random Forest Classifier on a set of test data.","5581cdc6":"Storing model accuracy to plot for comparison with other Machine Learning models.","e46cd318":"* Plotting the average of different metrics scores for further evaluation.","ee527314":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Linear Regression Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","a3c26890":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","14e6cb9c":"### Defining function to plot ROC Curve.","ebc195d5":"## Correlation:","5ea980aa":"Storing model accuracy to plot for comparison with other Machine Learning models.","b82815c3":"1. Plotting Confusion Matrix to describe the performance of Random Forest Classifier on a set of test data.","a141138e":"\nPlotting the ROC Curve of the machine learning models for comparison.","2d5c26b2":"Plotting different metrics scores for the LGBM Classifier for evaluation.","64e4780a":"###  As a result of our analysis, it was seen that there were outliers in two variables. These values are filled with threshold values.","399493f0":"1. Plotting Confusion Matrix to describe the performance of Random Forest Classifier on a set of test data.","a23dfa02":"1. Plotting Confusion Matrix to describe the performance of CART Classifier on a set of test data.","f913bc0e":"\nPlotting the average accuracy metric score of the machine learning models for comparison.","bf2b1b5b":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of XGBM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","f004ca5e":"* Plotting the average of different metrics scores for further evaluation.","77be4f52":"## 4. Classification and Regression Tree:\n\n\nDecision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.","f0f266cc":"Plotting different metrics scores for the Random Forest Classifier for evaluation.","ade79fd2":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of CatBoost Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","955dcfed":"## 5. Random Forests:\n\n\nA Random Forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.","f0253c61":"## 1. Logistic Regression Classifier:","b462e706":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of LGBM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","dbd86fb3":"## Feature Importance:","a69c9966":"Plotting different metrics scores for the KNN Classifier for evaluation.","8b7dd14e":"# Overview","3d96f1bd":"### Visualization of outliers in all columns with boxplot.","35be8ea2":"## 8. Light GBM","971f54e3":"Plotting the AUC values of ROC Curve of the machine learning models for comparison.","3c1ab269":"* Plotting the average of different metrics scores for further evaluation.","b1e75687":"Storing model accuracy to plot for comparison with other Machine Learning models.","2c08f2a2":"### Defining variables to store the outputs.**","a24772c9":"Plotting different metrics scores for the CART Classifier for evaluation.","31683598":"Plotting the AUC values of PR Curve of the machine learning models for comparison.","91f25f75":"### Defining function to create Confusion Matrix.","5c6b5eb3":"## Feature Importance:","5e52c46d":"## Missing Values","b01a5ebc":"## Feature Importance:","7d6953ba":"Storing model accuracy to plot for comparison with other Machine Learning models.","18f6aca1":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","caedbfd9":"Plotting different metrics scores for the CatBoost Classifier for evaluation.","9719d6a8":"* Plotting the average of different metrics scores for further evaluation.","cfcb1431":"* Plotting the average of different metrics scores for further evaluation.","baf48f98":"1. Plotting Confusion Matrix to describe the performance of KNN Classifier on a set of test data.","fbb12d64":"Plotting different metrics scores for the Linear Regression Classifier for evaluation.","7b6e18fb":"Plotting different metrics scores for the SVM Classifier for evaluation.","cf8acf09":"1. Plotting Confusion Matrix to describe the performance of CatBoost Classifier on a set of test data.","8791044e":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of SVM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","af6395a0":"## Random Forests:\n\n\nA Random Forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.","fccaa2fa":"1. Plotting Confusion Matrix to describe the performance of GBM Classifier on a set of test data.","a14ee78f":"###  Visualization of the Missing Values","912e8def":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Random Forest Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","d145b4ab":"* Plotting the average of different metrics scores for further evaluation.","dd8def8a":"The data in the insulin variable was divided into normal and abnormal groups and a new variable called NewInsulinScore was created.","0f4ca3e9":"# Machine Learning:\n\n\n### We will train out data on different machine learning models and use different techniques on each model and then compare our finding at the end to determine which model is working best for out data.\n","a7610f5f":"* Plotting the average of different metrics scores for further evaluation.","b0a2bbf6":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","5d36ed75":"## Final Model:","b2eb2719":"\nPlotting the PR Curve of the machine learning models for comparison.","388e6adf":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of KNN Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","083bd71e":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of CART Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","31a477f8":"Storing model accuracy to plot for comparison with other Machine Learning models.","145d8193":"# Load libraries\n","c5846a37":"## 7. XGBoost:","0b7362b7":"1. Plotting Confusion Matrix to describe the performance of XGBM Classifier on a set of test data.","b0b2f9d6":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","407817d3":"## Feature Importance:","0170811c":"Storing model accuracy to plot for comparison with other Machine Learning models.","261df5a1":"KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.","238d3549":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","5e182e19":"## 3. Support Vector Machine Classifier:\n","326406a7":"Plotting different metrics scores for the Random Forest Classifier for evaluation.","ecbea097":"## Feature Importance:","e868afe0":"## Performance Comparison\n\nPlotting the accuracy metric score of the machine learning models for comparison.","cd818801":"##  Feature Engineering\n\n\n","8fcbb4d6":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","2f44b40a":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of GBM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","abee22f7":"* Plotting the average of different metrics scores for further evaluation.","51246ebe":"Storing model accuracy to plot for comparison with other Machine Learning models.","b3e9a2a3":"# Local Outlier Factor (LOF)","ead4d4b8":"# Splitting Dataset\n### Splitting the target variable in y and all the other features in X","ddafeee0":"Storing model accuracy to plot for comparison with other Machine Learning models.","9b6f1ec1":"## 6. Gradient Boosting Machines","ff2b275d":"# One Hot Encoding\n\nWith the One Hot Encoding method, the values in categorical variables have been converted into numerical expressions.","66caeb06":"# Standardization:","ba585642":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","b84dbd2d":"# Read data","8a3a7a3f":"The data in the glucose variable were divided into groups according to general standards and a new variable named NewGlucose was defined.","aa651805":"* Plotting the average of different metrics scores for further evaluation.","0b3ffd34":"Storing model accuracy to plot for comparison with other Machine Learning models.","bd51f381":"## 9. CatBoost","5cea0a43":"## 2. KNNeighbors Classifier:","d3873bb6":"### Defining function to calculate the Cross-Validation score.\n\n\n","90ae6902":"Plotting different metrics scores for the GBM Classifier for evaluation.","c36639e7":"### Defining function to plot Precision-Recall Curve.","c1d87ac3":"# - - - -  REPORTING  - - - -\n\n\n\n### Our aim in this study was to estimate the probability of diabetes disease by using different classification models on the 'diabetes' data set.\n\n### First the data set read and displayed.\n\n###  Missing values were filled with the median values of the variables in which they were found.\n\n###  Then outliers were detected and suppressed.\n\n### Then, the values in the variables were divided into groups according to general health standards and new variables were created.\n\n### Values in all variables are standardized from 0 to 1.\n\n### Then results were with 9 different classification models predicted.\n\n### Predictions were evaluated with different metrics. Alle results were visualisated.\n\n### Finally, an prediction of over 91% was achieved with the random forests model.\nl","7c49b559":"1. Plotting Confusion Matrix to describe the performance of LGBM Classifier on a set of test data.","f29d7c06":"Plotting different metrics scores for the XGBM Classifier for evaluation.","1a900e44":"The missing data are assigned the median values of the variable in which they are located.","6fa213c1":"\n\n\n## -----   Model Performance and Comparison   -----\n\n### To measure the performance of a model, we need several elements\n\n**Confusion matrix** : also known as the error matrix, allows visualization of the performance of an algorithm\n\n    True Positive (TP) : Diabetic correctly identified as diabetic\n    True Negative (TN) : Healthy correctly identified as healthy\n    False Positive (FP) : Healthy incorrectly identified as diabetic\n    False Negative (FN) : Diabetic incorrectly identified as healthy\n\n**Metrics**\n\n    Accuracy : (TP + TN) \/ (TP + TN + FP +FN)\n    Precision : TP \/ (TP + FP)\n    Recall : TP \/ (TP + FN)\n    F1 score : 2 x ((Precision x Recall) \/ (Precision + Recall))\n\n","db8d3595":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","d8021e8f":"### Defining function to calculate the Metrics Scores.","a3966b7f":"* Plotting the average of different metrics scores for further evaluation.","a7fdbf21":"The BMI variable is divided into groups according to general standards and a new categorical variable named NewBMI is created.","091ee5b0":"1. Plotting Confusion Matrix to describe the performance of SVM Classifier on a set of test data.","55f44e8e":"\n\n# DIABETES\n\n### The unprocessed dataset was acquired from UCI Machine Learning organisation. This dataset is preprocessed by me, originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to accurately predict whether or not, a patient has diabetes, based on multiple features included in the dataset. \n\n\n### Number of Instances: 768\n### Number of Attributes: 8 plus class\n### For Each Attribute: (all numeric-valued)\n\n***Pregnancies**:                Number of times pregnant \n\n***Glucose**    :                Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\n***BloodPressure**:              Diastolic blood pressure (mm Hg)\n\n***SkinThickness**:              Triceps skin fold thickness (mm)\n\n***Insulin**:                    2-Hour serum insulin (mu U\/ml)\n\n***BMI**:                        Body mass index (weight in kg\/(height in m)^2)\n\n***DiabetesPedigreeFunction**:   Diabetes pedigree function\n\n***Age**:                        Age (years)\n\n***Outcome**:                    Class variable (0 or 1)\n\n***Missing Attribute Values**: Yes\n\n### Class Distribution: (class value 1 is interpreted as \"tested positive for diabetes\")\n\n\n### Attributes Normal Value Range:\n\n***Glucose: Glucose (< 140) = Normal, Glucose (140-200) = Pre-Diabetic, Glucose (> 200) = Diabetic\n\n\n***BloodPressure: B.P (< 60) = Below Normal, B.P (60-80) = Normal, B.P (80-90) = Stage 1 Hypertension, B.P (90-120) = Stage 2 Hypertension, B.P (> 120) = Hypertensive Crisis\n\n\n***SkinThickness: SkinThickness (< 10) = Below Normal, SkinThickness (10-30) = Normal, SkinThickness (> 30) = Above Normal\n\n\n***Insulin: Insulin (< 200) = Normal, Insulin (> 200) = Above Normal\n\n\n***BMI: BMI (< 18.5) = Underweight, BMI (18.5-25) = Normal, BMI (25-30) = Overweight, BMI (> 30) = Obese*\n\n\n\n\n### Class Value Number of instances\n*0 : 500\n\n*1 : 268"}}