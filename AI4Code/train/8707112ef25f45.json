{"cell_type":{"c01b0b8e":"code","5db11a23":"code","8ec7cd2f":"code","aa53d7a3":"code","d86dd880":"code","06feffb1":"code","07b5f4d3":"code","0d7453f9":"code","cc07dae0":"code","4bb38c7a":"code","e2852a61":"code","dd27ade0":"code","1005c3f5":"code","f87371c7":"code","47c0dd32":"code","320b02ec":"code","95e0df88":"code","9de86b0d":"code","63525159":"code","cd3c10f3":"code","d434cc3a":"code","e3067d47":"code","d32cc95b":"code","1970cc86":"code","c7c57412":"code","dd52e7d6":"code","05b23cd7":"code","f260955e":"code","f5c28211":"code","89772e1c":"code","1a99eed4":"code","f9f08ac0":"code","52eaca98":"code","6967ff96":"code","72883435":"code","d6e1c79e":"code","4b81ec24":"code","629ea9a8":"code","bbb31110":"code","15f99f91":"code","f1851f40":"code","7ebba2d0":"code","1d6d9c40":"code","21cc0776":"code","8015eff8":"code","c49f048d":"code","73d93eb0":"code","fefb7d4d":"code","52890721":"code","f267c3df":"code","98bce290":"code","c1bd7347":"code","1962a3c6":"code","bec2442d":"code","999876c5":"code","f5696da5":"code","e1782b6e":"code","0ece2515":"markdown","906be777":"markdown","a6d6609e":"markdown","cda09a2e":"markdown","d52bfdc5":"markdown","9735eedc":"markdown","25226c39":"markdown","b36952f4":"markdown","f5a32718":"markdown","9aa49201":"markdown","8d58cf75":"markdown","df701fe0":"markdown","76818942":"markdown","4920c451":"markdown","3cd0cf88":"markdown","0597a928":"markdown","85d97af4":"markdown","0b25ceb2":"markdown","0a838da7":"markdown","61ded407":"markdown","94150fe7":"markdown","5c3b0c5a":"markdown","f7fe6b0b":"markdown","a558a789":"markdown","cd6c3423":"markdown","992ae2e8":"markdown","bb392d1a":"markdown","ca93eda2":"markdown","4a84ddd7":"markdown","757e008b":"markdown","5f7a497b":"markdown","00166eea":"markdown","99552348":"markdown","6c2e4472":"markdown","7b4ee82a":"markdown","504740b8":"markdown","5d8b4e59":"markdown"},"source":{"c01b0b8e":"# Getting the data \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5db11a23":"pip install sweetviz","8ec7cd2f":"#Libraries\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pandas_profiling as pandas_pf\nimport sweetviz as sv\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nimport warnings\nwarnings.filterwarnings('ignore')","aa53d7a3":"# reading the given data set\n\ntrain_df = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/test.csv')\n\ntrain_df.head()","d86dd880":"# Data Info\ntrain_df.info()\nprint('-'*50)\ntest_df.info()","06feffb1":"# Dropping test column from test data set as it doesnt have any influence\n\ntest_df.drop('id', axis = 1, inplace = True)","07b5f4d3":"# Statistical summary of the columns\n\ntrain_df.describe()","0d7453f9":"# Shape of the data\n\nprint('Size of train data:{0}'.format(train_df.shape))\nprint('Size of test data:{0}'.format(test_df.shape))","cc07dae0":"# Finding missing value percentage\n\nprint(round(train_df.isnull().sum()\/len(train_df)),2)\nprint('-'*50)\nprint(round(test_df.isnull().sum()\/len(train_df)),2)","4bb38c7a":"# Plotting a heat map to see the correlation between variables\n\nplt.figure(figsize = (20,10))\n\nsns.heatmap(train_df.corr(), annot = True, cmap = 'YlGnBu')","e2852a61":"# Using SweetViz to for EDA\n\nreport = sv.analyze(train_df)","dd27ade0":"# To show report in new tab\n\n# report.show_html('Report.html')\n\n# Displaying report in notebook\nreport.show_notebook()","1005c3f5":"# comparing test and train data\n\ncompare_report = sv.compare([train_df, 'Train_Data'], [test_df, 'Test_Data'])","f87371c7":"# Displaying report\ncompare_report.show_notebook()","47c0dd32":"# We will add another column with the name of price range so that it will be easy for interpreatation\n\nprice_map = {0:'Low Cost', 1:'Medium Cost', 2:'High Cost', 3:'Expensive'}\n\ntrain_df['price_range_cat'] = train_df['price_range'].map(price_map)","320b02ec":"# Plotting price distribution for different battey power\n\nsns.barplot(x= 'price_range_cat', y = 'battery_power', data = train_df, order=['Low Cost', 'Medium Cost', 'High Cost', 'Expensive']\n           , palette = 'Set1')\n\nplt.title('Price Distribution for different Battery power ',fontsize = 15)\nplt.ylabel('Average Battrty Power(mAh)',fontsize = 15)\nplt.xlabel('Price Class', fontsize = 15)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\nplt.show()","95e0df88":"train_df['battery_power'].groupby(train_df['price_range_cat']).mean()","9de86b0d":"# Creating Crosstabluation for WiFi and BlueTooth\n\n100*pd.crosstab(train_df['blue'], train_df['wifi'], rownames=['Bluetooth'],margins = True, margins_name = 'Total',\n                 normalize = True).round(3)","63525159":"# Subsetting the data to identify which price class of phone dont have WiFi and Bluetooth\n\nsub_df = train_df[(train_df['wifi']==0) & (train_df['blue']==0)]\nsub_df.head()","cd3c10f3":"# Value COunt\n\nsub_df['price_range_cat'].value_counts()","d434cc3a":"# Plotting Phone's not having Bluetooth and WiFi\n\nsub_df['price_range_cat'].value_counts().plot(kind='barh')\n\nplt.title(\"Phone's not having Bluetooth and WiFi\")\nplt.xlabel('Total Count', fontsize = 15)\nplt.ylabel('Category of Phone', fontsize = 15)\nplt.show()","e3067d47":"# Plotting Avg Mobile Weight across different phone category\n\nsns.barplot(x='price_range_cat', y='mobile_wt', data = train_df, order=['Low Cost', 'Medium Cost', 'High Cost', 'Expensive'],\n            palette='Set1')\n\nplt.title('Avg Mobile Weight across different phone category')\nplt.xlabel('Phone Class', fontsize = 15)\nplt.ylabel('Avg Mobile Weight', fontsize = 15)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\nplt.show()","d32cc95b":"# Mean across different price class\n\ntrain_df['mobile_wt'].groupby(train_df['price_range_cat']).mean()","1970cc86":"# Drawing distribution across different price range\n\ng = sns.FacetGrid(train_df, col = 'price_range',height=2.5, aspect=1)\ng.map(plt.hist, 'ram', alpha = 0.5, bins = 20,edgecolor=\"black\", color = 'g')\nplt.show()","c7c57412":"# Plotting Battery Duration for Different Cores\n\nsns.lineplot(x='n_cores', y='talk_time', data= train_df,ci =None )\nplt.ylim([0,20])\n\nplt.title('Battery Duration for Different Cores')\nplt.xlabel('Number of Cores', fontsize = 15)\nplt.ylabel('Battey Duration', fontsize = 15)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\nplt.show()","dd52e7d6":"# Mean for Different price class\n\ntrain_df['talk_time'].groupby(train_df['price_range_cat']).mean()","05b23cd7":"# Dropping price_range_cat column as it was only used for EDA purpose\n\ntrain_df.drop('price_range_cat', axis = 1, inplace = True)","f260955e":"# Outlier Analysis:\n\nplt.figure\n\nfor i, col in enumerate(train_df.columns):\n    plt.figure(i)\n    sns.boxplot(train_df[col])","f5c28211":"# Splitting independent and dependent varaibles\n\nX = train_df.drop('price_range', axis = 1)\ny = train_df['price_range']","89772e1c":"# Creating training and test data\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, train_size= 0.7, test_size= 0.3, random_state = 0)","1a99eed4":"# Storing the column names  for train and test\nX_train_col = X_train.columns\n\nX_test_col = X_test.columns","f9f08ac0":"# We will convert the data into array as it will optimize more\n\nX_train, y_train = np.array(X_train), np.array(y_train)","52eaca98":"# Using Standard Scaler to scale\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","6967ff96":"# Reverting narray to DataFrame\n\nX_train = pd.DataFrame(X_train, columns = X_train_col)\nX_test = pd.DataFrame(X_test, columns = X_test_col)","72883435":"#define model and model parameters\nmodel = LogisticRegression()\npenalty = ['l2','l1']\nc_values = [100, 10, 1.0, 0.1, 0.01]\n\n#define grid\ngrid = dict(C = c_values, penalty = penalty)\ncv = KFold(n_splits = 5)\n\ngrid_search = GridSearchCV(estimator = model, param_grid = grid, cv = cv, n_jobs = -1)\ngrid_result = grid_search.fit(X_train, y_train)","d6e1c79e":"#Mean cross-validated score of the best_estimator\n\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","4b81ec24":"# Creating model with the defined parameters\n\nlr = LogisticRegression(C=100, penalty = 'l2')\nlr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)","629ea9a8":"# Let's see the results\n\nprint('Accuracy of the Logistic Regression is {0}'.format(round(accuracy_score(y_test, lr_predict),2)))\nlr_accuracy = accuracy_score(y_test, lr_predict)\nprint('-'*50)\nprint('\\n')\nprint('Model Report:')\nprint('-'*50)\nprint(classification_report(y_test, lr_predict))","bbb31110":"#define model and model parameters\n\nmodel = RandomForestClassifier(class_weight='balanced')\n\nmax_depth = [4,8,10]\ncriterion = ['gini','entropy']\nmin_samples_split = [2,3,5,7,9]\nmax_features = [5, 10]\n\n#define grid\ngrid = dict(max_depth = max_depth, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features)\ncv = KFold(n_splits = 5)\n\ngrid_search = GridSearchCV(estimator = model, param_grid = grid, cv = cv,n_jobs = -1)\ngrid_result = grid_search.fit(X_train, y_train)","15f99f91":"#Mean cross-validated score of the best_estimator\n\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","f1851f40":"# Creating model with the defined parameters\n\nrfc = RandomForestClassifier(criterion = 'entropy', max_depth = 10, max_features = 10, min_samples_split = 5)\nrfc.fit(X_train, y_train)\nrfc_predict = rfc.predict(X_test)","7ebba2d0":"# Let's see the results\n\nprint('Accuracy of the Random Forest is {0}'.format(round(accuracy_score(y_test, rfc_predict),3)))\nrfc_accuracy = accuracy_score(y_test, rfc_predict)\nprint('-'*50)\nprint('\\n')\nprint('Model Report:')\nprint('-'*50)\nprint(classification_report(y_test, rfc_predict))","1d6d9c40":"# define model and model parameters\n\nmodel = GaussianNB()\nvar_smoothing = np.logspace(0,-9, num=100)\n\n# define grid\ngrid = dict(var_smoothing = var_smoothing)\ncv = KFold(n_splits = 5)\n\ngrid_search = GridSearchCV(estimator = model, param_grid = grid,n_jobs = -1, cv = cv)\ngrid_result = grid_search.fit(X_train, y_train)","21cc0776":"# Mean cross-validated score of the best_estimator\n\nprint(\"Best %f using %s\"%(grid_result.best_score_, grid_result.best_params_))","8015eff8":"# Creating model with the defined parameters\n\ngnb = GaussianNB(var_smoothing = 0.23)\ngnb.fit(X_train, y_train)\ngnb_predict = gnb.predict(X_test)","c49f048d":"# Let's see the results\n\nprint('Accuracy of the GaussainNB is {0}'.format(round(accuracy_score(y_test, gnb_predict),3)))\ngnb_accuracy = accuracy_score(y_test, gnb_predict)\nprint('-'*50)\nprint('\\n')\nprint('Model Report:')\nprint('-'*50)\nprint(classification_report(y_test, gnb_predict))","73d93eb0":"# define model and model parameters\nmodel = SVC(kernel='rbf')\nC = [50, 10, 1.0, 0.1, 0.01]\ncv = KFold(n_splits = 5)\n\n# define grid\ngrid = dict(C = C)\n\ngrid_search = GridSearchCV(estimator = model, param_grid = grid, cv = cv, n_jobs = -1)\ngrid_result = grid_search.fit(X_train, y_train)","fefb7d4d":"# Mean cross-validated score of the best_estimator\n\nprint(\"Best %f using %s\"%(grid_result.best_score_, grid_result.best_params_))","52890721":"# Creating model with the defined parameters\n\nsvc = SVC(kernel = 'rbf', C = 1)\nsvc.fit(X_train, y_train)\nsvc_predict = svc.predict(X_test)","f267c3df":"# Let's see the results\n\nprint('Accuracy of the SVC is {0}'.format(round(accuracy_score(y_test, svc_predict),3)))\nsvc_accuracy = accuracy_score(y_test, svc_predict)\nprint('-'*50)\nprint('\\n')\nprint('Model Report:')\nprint('-'*50)\nprint(classification_report(y_test, svc_predict))","98bce290":"# define model and parameters\n\nmodel = GradientBoostingClassifier()\nlearning_rate = [0.001, 0.01, 0.1]\nsubsample = [0.5, 0.7, 1.0]\ncv = KFold(n_splits = 5)\n\n#Define Grid\ngrid = dict(learning_rate=learning_rate, subsample=subsample)\ngrid_search = GridSearchCV(estimator = model, param_grid = grid, cv=cv, n_jobs = -1)\ngrid_result = grid_search.fit(X_train, y_train)","c1bd7347":"# Mean cross-validated score of the best_estimator\n\nprint(\"Best %f using %s\"%(grid_result.best_score_, grid_result.best_params_))","1962a3c6":"# Creating model with the defined parameters\n\nsgb = GradientBoostingClassifier(learning_rate = 0.1, subsample = 0.7)\nsgb.fit(X_train, y_train)\nsgb_predict = sgb.predict(X_test)","bec2442d":"# Let's see the results\n\nprint('Accuracy of the Gradient Boosting is {0}'.format(round(accuracy_score(y_test, sgb_predict),3)))\nsgb_accuracy = accuracy_score(y_test, sgb_predict)\nprint('-'*50)\nprint('\\n')\nprint('Model Report:')\nprint('-'*50)\nprint(classification_report(y_test, sgb_predict))","999876c5":"# Creating a dataframe to summaries accuracy of different model\n\nmodel_summary = pd.DataFrame({\n    'ML Models':['Logistic Regression', 'Random Forest', 'GaussianNB', 'SVM', 'Gradient Boosting'],\n    'Accuracy':[lr_accuracy, rfc_accuracy, gnb_accuracy, svc_accuracy, sgb_accuracy]\n})\nmodel_summary['Accuracy'] = round(model_summary['Accuracy'],2)\nmodel_summary.sort_values(['Accuracy'], inplace = True, ascending = False)\nmodel_summary.reset_index(drop = True,inplace = True)\nmodel_summary","f5696da5":"# Creating permutation importance n fitting\n\nprem = PermutationImportance(estimator = lr, random_state = 42)\nprem.fit(X_train, y_train)","e1782b6e":"# Finding out the top KPI's\n\neli5.show_weights(estimator=prem, feature_names = X_test.columns.tolist())","0ece2515":"## Stochastic Gradient Boosting","906be777":"**Inference**:\nTop 3 KPI's are:\n1. RAM\n2. Battery Power\n3. Pixel Height\n<br>\nThat influence the price class of the phone","a6d6609e":"### What is the average battery power for each price class of mobile?","cda09a2e":"**Assumption**\n- As far we have seen most of the people look into\n    - Battery power\n    - DualSim (Maybe)\n    - Internal Memory\n    - Camera Pixel\n    - Number of cores\n    - RAM\n    <br>\n   <br>\n Based on the above mentioned factor we are going to see if there is any strong corelation or are they any other factors that also influence\n    ","d52bfdc5":"### Does having more cores\/price influence battery duration?","9735eedc":"## Logistic Regression","25226c39":"# Scaling","b36952f4":"## SVM","f5a32718":"The black line on the bars is the error bar, they are graphical representation of the varibality of the data and used on graphs to indicate the error or uncertainty in a reported measurement.\n- https:\/\/stackoverflow.com\/questions\/58362473\/what-does-black-lines-on-a-seaborn-barplot-mean#:~:text=This%20is%20the%20error%20bar,Standard%20Deviation%20or%20STD%20line.&text=Size%20of%20confidence%20intervals%20to%20draw%20around%20estimated%20values.&text=If%20None%2C%20no%20bootstrapping%20will,bars%20will%20not%20be%20drawn.","9aa49201":"## Gaussian NB","8d58cf75":"**Inference**:<br>\nRAM Ranges for different phone range\n- Low Cost: 0-2000 MB\n- Medium Cost: 500-3000 MB\n- High Cost: 1000-4000MB\n- Expensive: 2000-4000MB\n\nSo Basically expensive phones have High RAM","df701fe0":"<h1>Upvote if you like my work\u2764\ufe0f<br>\nIf you have any queries, doubt or any suggestion feel free to drop it in comment section<h1>","76818942":"**Inference**:\nIt can be noted expensive mobile phones have slightly less weight ","4920c451":"- As expected Expensive Mobile have more average battery power i.e. 1380 mAh\n- Medium and High cost mobile have are in the same range\n- Low Cost phones have average battery power low i.e. 1117 mAh","3cd0cf88":"# Train - Test Split","0597a928":"# Topics\n1. Importing Libraries\n2. Loading and data Understanding\n3. Analysis & Visualization of the data\n    - What is the average battery power for each price class of mobile?\n    - Do all mobile phone which have Wifi have bluetooth?\n    - Is the weight less for expensive Phones?\n    - Influence of RAM on price range\n    - Does having more cores\/price influence battery duration?\n    - Outlier Analysis  \n4. Train-Test split\n5. Scaling\n6. Model Building\n    - Logistic Regression\n    - Random Forest\n    - Gaussain NB\n    - SVM\n    - Gradient Boosting\n7. Summary","85d97af4":"# Loading and data understanding","0b25ceb2":"**Inference**\n- Count for most the classes with 2 values is 50-50\n- Battery power has positive correlation of 0.21 with power range\n- ~33% of the phone have clock speed in range 0.5GHz - 1.0GHz (Since the unit is not mentioned we will assume it to be GHz)\n- ~36% of phones have less than 2MP of front camera\n- Only 24% of phones dont have 3G\n<br><br>\nLet's explore somemore section in detail","0a838da7":"# Importing Libraries\n","61ded407":"*For anyone who is interested on SweetViz here are links that will be helpful:*\n \n* https:\/\/pypi.org\/project\/sweetviz\/\n* https:\/\/towardsdatascience.com\/sweetviz-automated-eda-in-python-a97e4cabacde\n* https:\/\/towardsdatascience.com\/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34","94150fe7":"**Inference**:\n- There is no significant effect of cores on battery duration as suspected\n- On a average the battery duration is 11hrs\n- There is not much effect of price on battery duration","5c3b0c5a":"__Note__:<br>\nHere we will consider accuracy as metric of comparsion rather than presion\/recall because:\n - The target class is almost balanced\n - Here we are not specifically focusing on one category of phone but instead looking at all, if we want to target one specific category then we can focus on it by using recall\/precsion and adjusting it accordingly","f7fe6b0b":"**Inference:**\n- Couldn't Identify any specfic pattern, when we see the crosstab there is ~25% for each category\n- It was bit strange to note that there 116 expensive phones neither have Bluetooth nor Wifi","a558a789":"### Is the weight less for expensive Phones?","cd6c3423":"**Inference**:\nThere are no outliers in the data","992ae2e8":"**Inference**\n- All the dtypes look in the correct format\n- We can note that there is a ID column in test dataframe which is absent in train\n- The target variable with value of 0(low cost), 1(medium cost), 2(high cost) and 3(very high cost).","bb392d1a":"### SweetViz","ca93eda2":"__Note__:<br>\nWe are just going to use train data for our model building purpose and not consider the test data, as the test data does not have the target varaible coulmn and we cannot compare our model answers to right answers\n","4a84ddd7":"# Model Building","757e008b":"There is no missing values in the data and there is no need for cleaning of missing values","5f7a497b":"# Summary","00166eea":"### Do all mobile phone which have Wifi have bluetooth?","99552348":"### Influence of RAM on price range","6c2e4472":"**Inferance**:\n- Front camera mega pixels has a strong positive correlation with Primary Camera Mega Pixels as most of the consumers are looking for camera with high mega pixels\n- Having 4G and 3G are strongly related\n- We can see strong corelation of price with RAM and it as major influence\n- Battery power also has influence of price","7b4ee82a":"We can see that Logistic Regression has highest accuracy, based on this lets explore which are the important attributes that contribute more","504740b8":"# Analysis & Visualization of the data","5d8b4e59":"## Random Forest"}}