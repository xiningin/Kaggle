{"cell_type":{"7ccd4078":"code","ec519485":"code","bb0f5b0d":"code","0ca88544":"code","bfa15da8":"code","26ce349a":"code","95e9e5f2":"code","dc0d7295":"code","b8c3616c":"code","3275569a":"code","dcaa7758":"code","5bb5b4b9":"code","d966523e":"code","a305e782":"code","f9186bb8":"code","691722d2":"code","f097af45":"markdown","edabf521":"markdown","fa515c1c":"markdown","a726f5ee":"markdown","9ce64f9d":"markdown","f9e9de3d":"markdown","ab10ca29":"markdown","4945c30f":"markdown","4188e65d":"markdown","a2041712":"markdown","7325ce39":"markdown","f280af8c":"markdown","69cd1394":"markdown","25e9ca10":"markdown","12345ae7":"markdown","4e24c12a":"markdown","fc3abd93":"markdown","bffc901c":"markdown","0b632837":"markdown","0adffa77":"markdown","4f034ac3":"markdown","bc6642d3":"markdown","be2a0cd0":"markdown","0d9fb33a":"markdown","816520ff":"markdown","d88841d4":"markdown"},"source":{"7ccd4078":"#!pip install wordcloud  # install wordcloud - run this once\nimport pandas as pd \nfrom urllib.request import Request, urlopen # for opening a connection to a website\nfrom bs4 import BeautifulSoup #web scraping \nimport folium #map visualization\nimport html\nimport sys # mostly used for debugging purposes\n#matplotlib for graphs\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n%matplotlib inline \nimport seaborn as sns\nimport re\n    ","ec519485":"df = pd.read_csv('..\/input\/bournemouth_venues.csv')\n\nprint(\"Infomation abut the dataset:\\n\")\ndf.info()\n\nprint(\"\\nFirst few rows of the dataset:\\n\")\nprint(df.head())\n\n","bb0f5b0d":"df.tail()","0ca88544":"df = df.rename(columns={\n'Venue Name': 'Name',\n'Venue Category': 'Category',\n'Venue Latitude': 'Latitude',\n'Venue Longitude': 'Longitude'})","bfa15da8":"# In excel you could use a pivot table to summarise the \"Venue Name\" column and find the number of occurances of each venue name. \n#Lets use something similar in pandas:\n\n#create a pivot table to count the number of occurances in the \"Name\" column\ndf_pivot = pd.pivot_table(df, index=['Name'], aggfunc='count')\n\n#Filter our pivot table to only show venues that occur more than once\ndf_pivot_filter = df_pivot[df_pivot.Category > 1]\n\n\nTotal_venues = len(df.Name) #total number of venues in our data\nchain_venues = len(df_pivot_filter.Category) #of those venues how many of them are part of a chain?\n\nprint(f\"In total we have {Total_venues} venues. Of these venues, {chain_venues} of them are part of a chain\")","26ce349a":"#First generate a wordcloud of all the Categories\n\n#Lets grab the Category column and put it into a list.\ncata_list = df[\"Category\"].values.tolist()\n\n#Go through the list and remove all leading and trailing white space. \ncata_list = [ele.strip(\" \") for ele in cata_list]\n\n\n#Go through the list and unify any double barral words\ncata_list = [ele.replace(\" \",\"\") for ele in cata_list]\n\n#finally convert the list to a long string, seperated by a space\ncata_list = ' '.join(cata_list)\n\n\n#******The plot*******\n\n#create a new figure instance\nfig = plt.figure(figsize=(7,7))\n\n#create a new axes for this plot. its a single graph so subplots are not needed\nax = fig.add_axes([1,1,1,1])\n\n#Create the wordcloud object\nwordcloudobj = WordCloud(width=500, height=500,\n               margin=0, max_font_size=100, min_font_size=12,\n               background_color=\"lightyellow\", collocations = False).generate(cata_list)\n\n#plot details\nax.set_title(\"WordCloud of different category types\")\nax.axis(\"off\") #turn off axis\n\n# show plot\nax.imshow(wordcloudobj, interpolation='bilinear') # Display the generated image:\n","95e9e5f2":"#plotting a bar graph for number of occurances of category type\n\n#create a pivot table to count the number of occurances in the \"category\" column\ndf_catapivot = pd.pivot_table(df, index=['Category'], aggfunc='count')\nprint(df_catapivot.head())","dc0d7295":"#we have df_catapivot as seen above we will clean this to prepare for bar plot:\n\n#drop lat long columns:\ndel df_catapivot[\"Latitude\"]\ndel df_catapivot[\"Longitude\"]\n\n#rename \"Name\" colum to \"count\" as, that is what its showing\ndf_catapivot = df_catapivot.rename(columns={'Name': 'Count'})\n\n#set an integer index and keep the former index as a new column\ndf_catapivot = df_catapivot.reset_index(drop=False)\n\nprint(df_catapivot.head())","b8c3616c":"# And now for the bar plot\n\n# Close previous figure:\nplt.close(fig)\n\n#create a new figure instance\nfig = plt.figure(figsize=(7,7))\n\n#create a new axes for this plot. \nax = fig.add_axes([1,1,1,1])\n\n#plot the bar plot using seaborn\nsns.barplot(df_catapivot[\"Category\"],df_catapivot[\"Count\"])","3275569a":"#filter the dataframe to remove all X values with count = 1\ndf_catapivot_filt = df_catapivot[df_catapivot.Count > 1]\n\n\n# And finally plotting the bar plot with filtered data\n\n# Close previous figure:\nplt.close(fig)\n\n#create a new figure instance\nfig = plt.figure(figsize=(7,7))\n\n#create a new axes for this plot. \nax = fig.add_axes([1,1,1,1])\n\n#details\n\n#set title\nax.set_title(\"Count of the different venue types in Bournemouth\")\n#rotate x-axis labels\nfor label in ax.xaxis.get_ticklabels():\n    label.set_rotation(90)\n\n\n#plot the bar plot using seaborn\nsns.barplot(df_catapivot_filt[\"Category\"],df_catapivot_filt[\"Count\"])","dcaa7758":"\n    \n#First we need to center out map on Bournemouth. A simple google search reveals:\n#\"The latitude of Bournemouth, UK is 50.720806, and the longitude is -1.904755.\"\n\nBournemouth_coord = (50.720806, -1.904755)\n\n# create empty map zoomed in on Bournemouth\nbournemap = folium.Map(location=Bournemouth_coord, zoom_start=12)\n\nrownum = len(df[\"Name\"])\ni = 0\n\nfor i in range(0,rownum):    \n\n    name = df.loc[i,\"Name\"]\n    cate = df.loc[i,\"Category\"]\n    text = str(name + \" (\" + cate + \")\")\n    folium.CircleMarker(\n        [df.loc[i,\"Latitude\"], df.loc[i,\"Longitude\"]],\n        radius=8,\n        popup = html.escape(text),\n        color='blue',\n        fill_color='green',\n        fill=True,\n        fill_opacity=0.7,\n        clustered_marker = True\n        ).add_to(bournemap)\n    \n    i += 1\n\n\n#display our map\nprint(\"Map of Bournemouth with venue locations\")\ndisplay(bournemap)\n\n\n\n\n\n","5bb5b4b9":"print(\"The pivot table - showing venues that are part of a chain of venues\")\nprint(df_pivot_filter)","d966523e":"print(\"Resetting the Index whilst keeping the original index but as a new column\")\ndf_pivot_filter = df_pivot_filter.reset_index(drop=False)\nprint(df_pivot_filter)","a305e782":"#Now Make a copy of our df:\ndfbs = df\n\n#Add a new column \"rating\"\ndfbs[\"Review\"] = \"\"\n\n#Now loop through \"df_pivot_filter\" and drop all rows containing the same venues \nrow = 0\nfor chain in df_pivot_filter[\"Name\"]:\n    dfbs = dfbs[dfbs.Name != chain] #remove the rows contianing chain (which are the chain venues)\n    row +=1\n    \n#we have removed rows. we need to reset the index\ndfbs = dfbs.reset_index(drop=True)\n\n#upon testing the code it was noticed that certain strings (Lola\u2019s) threw errors.\n#Need to loop through and remove all instances of \"\u2019\"\n\n\n\n\ni = 0\n\nfor i in range (len(dfbs[\"Name\"])):\n    \n    venue = dfbs.loc[i,\"Name\"]\n    \n    #check if the string venue has \"\u2019\"  and if so replace with\"'\"\n    venue = venue.replace(\"\u2019\",\"'\")\n\n    #we wil effectivly do a google search. so we will constuct this here:\n    #we search for: \"UK Bournemouth venueName\" - this should give us a side box with venue details in google\n    location = \"UK Bournemouth \" + venue\n    \n    #constructing the weblink\n    web = \"https:\/\/www.google.com\/search?safe=active&source=hp&ei=bo4vXfiVIY-yUtPGomg&q=\"\n    web_full = web + location.replace(\" \",\"+\")\n    \n    #sending a request using urllib with added headers to ensure we get a connection\n    #the header just tells the wepage that we are accessing it using mozilla verion 5.0\n    req = Request(web_full, headers={'User-Agent': 'Mozilla\/5.0'})\n    \n    \n    \n    \n    \n    #open the webpage and read\n    page = urlopen(req).read()\n    \n    #using beautiful soup turn the html of the page into a soup format \n    soup = BeautifulSoup(page, 'html.parser')\n    \n    \n    \n    #Once we grab the review data, we check it its a value or \"none\"\n    #if it is \"none\", we get an attribute error which we will except and go on to store \"nan\"\n    try:\n        data1 = soup.find('span', attrs={'class': 'oqSTJd'})\n        score = data1.text.strip() # strip() is used to remove starting and trailing\n        \n        dfbs.loc[i,\"Review\"] = score  #store the score into dfbs\n        \n    except AttributeError:\n        dfbs.loc[i,\"Review\"] = 0.0 # since no score was available, set score to 0\n        \n    i +=1\n\n    \n#show the first fiew rows of our dataframe\nprint(dfbs.head())\n\n\n\n\n\n\n\n","f9186bb8":"#we know we have some points that have this sort of shape: 8.3\/10\n#we need to take the 8.3 and divde by 10 then * by 5 to get a out of 5 score. then store this as a float:\n#We can use regex to extract everything behind the \/10\n#some regex to ensure we grab the data in the correct format:\npullrule = '([0-9]+.[0-9]+)' # REGEX RULE: example: 4.8\ncheckrule = '([0-9]+.[0-9]+\/)' # REGEX RULE: example: 4.8\/\ni = 0\n\n#loop through the Review data\nfor i in range(len(dfbs[\"Review\"])):\n    \n    data = str(dfbs.loc[i,\"Review\"]) #convert data into string so we can use REGEX on it\n    is_check = re.match(checkrule, data) #check if \"\/\" exists in data - returns boolean\n    \n    #check if \"\/\" exists in string:\n    if is_check:\n        # use pullrule to extract everything behind \"\/\" eg 4.8\/10 -> 4.8\n        score_fmt = re.findall(pullrule, data)#find the REGEX match, store into score_fmt\n        x  = float(score_fmt[0]) \/ 2\n        \n        dfbs.loc[i,\"Review\"] = x #take first element of list + convert to float' and store back into df\n        i += 1\n    else:     \n        dfbs.loc[i,\"Review\"] = float(data) #convert back to float\n        i += 1\n    \n\n","691722d2":"dfbs.head()","f097af45":"# Analysis: Most popular venue categories\nNow we will have a look into the venue categories and gain insight into the most popular venue types. we will do this by plotting a world cloud as well as a bar chart of the most popular types.","edabf521":"# Bournemouth Venues Analysis\n<a>https:\/\/www.kaggle.com\/r3w0p4\/bournemouth-venues<\/a>\n","fa515c1c":"# Cleaning the data","a726f5ee":"# Analysis: Map Visualization of venue locations","9ce64f9d":"# LOADING DATA INTO A DATAFRAME","f9e9de3d":"Here we import the libraries. The reasoning behind why certain libraries are being used will be explained later. ","ab10ca29":"Just from looking at the geospatial plots and no prior knowledge of Bournemouth, you can see where the Town center is from the concentrated positioning of these venues. Its interesting to note that these points are all focused around the town center which itself is within the bounds of the green parks of bournemouth. This coupled with the scattered venues along the beach further indicate that this town is heavily focused on tourism. It would be interesting to see this compared to busy cities like central London or Manchester as i would expect there to be venues in rows along the close compact streets rather than exploiting the natural beauty as Bournemouth does.","4945c30f":"Our df_catapivot dataframe was formed from a pivot table operation. we can see the index is the category and the other columns are the number of occurances. lets clean this dataframe to make it more clear on whats going on","4188e65d":"The data appears, at a first glance, to be in a suitable format. Lets check the last rows of the dataframe to see if there are in NaN elements:","a2041712":"Now we read the csv file and display some infomation about the dataframe as well as the first few rows of the dataset.","7325ce39":"# INTRODUCTION\nThis kernel will present an analysis from Kaggle's dataset Bournemouth Venues\" (see link above). We have a dataset with venues in the city of Bournemouth. Our first task would be to load the csv file into a dataframe and see what we will work with. Then we will brainstorm some ideas on visualizing this data. ","f280af8c":"Now I want to use follium to plot a map visualization of the different venues. We will gain some insight to where different venues are located in contrast to each other and generally in the town.\n","69cd1394":"this worked well however now we have a \"review\" column containing 0. These 0 values are venues with no reviews\/unable to get a review\nFurthermore, we have datapoints (\"4.0\")  that are strings and finally some points which look like this: 8.3\/10.\n\nThis requires some data cleaning. so we end up with a column of datatype float.","25e9ca10":"# Analysis: Count  unique venues vs \"chain\" venues\nFrom the dataset we a mixture of venue types from hotels to cafes. There could be a possibiility of finding multiple venues thats are part of a chain like starbucks or McDonalds. Lets look into this and see how many unique venues we have.","12345ae7":"It seems okay. However we may run into formatting issues later so we will deal with the data cleaning there and then since at the moment theres not alot more I can do apart from renaming teh column headers:","4e24c12a":"Now we have a dataframe including review data from google, fully formatted and cleaned:","fc3abd93":"# Analysis Brainstorm","bffc901c":"I think it will be interesting to investigate the following:\n- A count of number of unique venues vs \"chain\" venues\n- a worldcloud of venue category showing popularity of the different types\n- a map view of the town showing markers of the different venues to see how far away they are in relation to the town and each other\n- use beautifulSoup to grab review data for each unique venue (we wont be interested in chain venues because who wants to eat McDonalds on a holiday?? Go try new unique local things!!) from google and plot on a map. Perhaps use the review score and plot on the map - colour coded. \n\n\n\nHowever before we do any of this we need to ensure our data is in a suitable format and check if it needs cleaning.","0b632837":"As you can see, we have a number of venues and their correspoinding catagory. We also have a geospatial co-ordinate for each venue. From this I am thinking about a map and venues which may have reviews and possibly a count on the most popular categories. ","0adffa77":"This is a dataframe. Lets reset the index while keeping the current index as this is the list of chain venues","4f034ac3":"*****************************************************\nNOTE: if there are errors in the below code.\nREASON: Kaggle Kernels does not have internet access turned on by default. You may have to fork it and run it with the internet option selected on the setting pane. Otherwise run the code locally .\n****************************************************","bc6642d3":"# Review data intergration and analysis using Beautiful Soup","be2a0cd0":"As you can see, there are a number of places which may have a similar level of popularity compared to other cataegories. We can look into this further by plotting a bar chart showing the count against category type:","0d9fb33a":"Now i want to loop through the data and for each unique (non chain) venue, i will use BeautifulSoup to effectivly:\n    - search the venue name on google\n    - search for googles sidebar which displays infomation about a location including any review\n    - Extract this review data (should be a value from 1-5)\n    - save it as a new column in our dataframe\n    - plot a follium mapplot of the Town and plot them colour coded with respect to their rating. \n    \nREMEMBER! we are not interested in these chain venues. so we wont be considering them in this part.\nWe have a dataframe that has been filtered using a pivot table which shows the venues that occur more than once\nlets loop through this pivot table and drop those rows. \nThen use our new dataframe to loop through and grab review data. \n\nLets have a look at this pivot table:\n    ","816520ff":"At this point the data analysis has gone beyond the scope of the original data. \nIt would be interesting to see how the review data differs from region to region in the town as well as the spread of reviews across the town in general. \n\nOne way this could be done is by color coding by using a map() function (which i've come across in p5.js) and  map \"review\" to \"RGB COLOR\". A such:\n\ndef mapping(n, start1, stop1, start2, stop2):\n    return ((n-start1)\/(stop1-start1))*(stop2-start2)+start2\n    \n    \n\nSo effectivly i will have bluer colours representing venues whos catagory falls within the less common sort. And more redder colours representing venues whos catagory falls within the more common sort (as revealed by our above bar chart)\n\nUpon further reading, follium only allows discrete colors when assigning them to the\"fill_circle\" parameter. So in this case we could create a dictionary: \n\nd = {\"black\":0,\n     \"darkpurple\":1\n     \"blue\":2,\n     \"green\":3,\n     \"orange\":4,\n     \"red\":5,\n     \nThis way we could assign a color based on the rating Then finally plot the map in follium.","d88841d4":"Insight gained. We see a large number of X values however most of them have count = 1. And we are, after all, interested in the more popular ones.\nlets plot this again, but filter the dataframe to remove all X values with count = 1."}}