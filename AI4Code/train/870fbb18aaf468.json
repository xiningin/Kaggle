{"cell_type":{"0431b249":"code","2f814bf9":"code","73a48c2b":"code","29f70480":"code","de715253":"code","b9b046d1":"code","f5adc65e":"code","67c45c04":"code","8a724ea2":"code","005fa6d0":"code","cfe8825d":"markdown","f6d67a89":"markdown","961f09a3":"markdown","d8cea451":"markdown","473afccb":"markdown","24fbfbba":"markdown","152d6e76":"markdown","978ae52d":"markdown"},"source":{"0431b249":"!pip install timm","2f814bf9":"import numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport cv2\nimport math\n\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, cross_val_score\n\n# Metric\nfrom sklearn.metrics import f1_score, accuracy_score\n\n# Augmentation\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","73a48c2b":"seed = 415\n\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","29f70480":"path = '..\/input\/classify-leaves'\nlabels_file_path = os.path.join(path, 'train.csv')\nsample_submission_path = os.path.join(path, 'test.csv')\n\ndf = pd.read_csv(labels_file_path)\nsub_df = pd.read_csv(sample_submission_path)\nlabels_unique = df['label'].unique()\n\n\nle = LabelEncoder()\nle.fit(df['label'])\ndf['label'] = le.transform(df['label'])\nlabel_map = dict(zip(le.classes_, le.transform(le.classes_)))\nlabel_inv_map = {v: k for k, v in label_map.items()}","de715253":"def get_train_transforms():\n    return albumentations.Compose(\n        [\n            albumentations.Resize(320, 320),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.Rotate(limit=180, p=0.7),\n            albumentations.RandomBrightnessContrast(),\n            albumentations.ShiftScaleRotate(\n                shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n            ),\n            albumentations.Normalize(\n                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n                max_pixel_value=255.0, always_apply=True\n            ),\n            ToTensorV2(p=1.0),\n        ]\n    )\n\ndef get_valid_transforms():\n    return albumentations.Compose(\n        [\n            albumentations.Resize(320, 320),\n            albumentations.Normalize(\n                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n                max_pixel_value=255.0, always_apply=True\n            ),\n            ToTensorV2(p=1.0)\n        ]\n    )","b9b046d1":"class LeafDataset(Dataset):\n    def __init__(self, images_filepaths, labels, transform=None):\n        self.images_filepaths = images_filepaths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.labels[idx]\n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        return image, label\n\ndef accuracy(output, target):\n    y_pred = torch.softmax(output, dim=1)\n    y_pred = torch.argmax(y_pred, dim=1).cpu()\n    target = target.cpu()\n\n    return accuracy_score(target, y_pred)\n\n\ndef calculate_f1_macro(output, target):\n    y_pred = torch.softmax(output, dim=1)\n    y_pred = torch.argmax(y_pred, dim=1).cpu()\n    target = target.cpu()\n\n    return f1_score(target, y_pred, average='macro')\n\n\nclass MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] \/ metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )\n    \ndef adjust_learning_rate(optimizer, epoch, params, batch=0, nBatch=None):\n    \"\"\" adjust learning of a given optimizer and return the new learning rate \"\"\"\n    new_lr = calc_learning_rate(epoch, params['lr'], params['epochs'], batch, nBatch)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = new_lr\n    return new_lr\n\n\n\"\"\" learning rate schedule \"\"\"\ndef calc_learning_rate(epoch, init_lr, n_epochs, batch=0, nBatch=None, lr_schedule_type='cosine'):\n    if lr_schedule_type == 'cosine':\n        t_total = n_epochs * nBatch\n        t_cur = epoch * nBatch + batch\n        lr = 0.5 * init_lr * (1 + math.cos(math.pi * t_cur \/ t_total))\n    elif lr_schedule_type is None:\n        lr = init_lr\n    else:\n        raise ValueError('do not support: %s' % lr_schedule_type)\n    return lr","f5adc65e":"params = {\n    'model': 'seresnext50_32x4d',\n    # 'model': 'resnet50d',\n    'device': device,\n    'lr': 1e-3,\n    'batch_size': 64,\n    'num_workers': 0,\n    'epochs': 50,\n    'out_features': df['label'].nunique(),\n    'weight_decay': 1e-5\n}","67c45c04":"class LeafNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'],\n                 pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, out_features)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\ndef train(train_loader, model, criterion, optimizer, epoch, params):\n    metric_monitor = MetricMonitor()\n    model.train()\n    nBatch = len(train_loader)\n    stream = tqdm(train_loader)\n    for i, (images, target) in enumerate(stream, start=1):\n        images = images.to(params['device'], non_blocking=True)\n        target = target.to(params['device'], non_blocking=True)\n        output = model(images)\n        loss = criterion(output, target)\n        f1_macro = calculate_f1_macro(output, target)\n        acc = accuracy(output, target)\n        metric_monitor.update('Loss', loss.item())\n        metric_monitor.update('F1', f1_macro)\n        metric_monitor.update('Accuracy', acc)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        lr = adjust_learning_rate(optimizer, epoch, params, i, nBatch)\n        stream.set_description(\n            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(\n                epoch=epoch,\n                metric_monitor=metric_monitor)\n        )\n    return metric_monitor.metrics['Accuracy'][\"avg\"]\n\ndef validate(val_loader, model, criterion, epoch, params):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    with torch.no_grad():\n        for i, (images, target) in enumerate(stream, start=1):\n            images = images.to(params['device'], non_blocking=True)\n            target = target.to(params['device'], non_blocking=True)\n            output = model(images)\n            loss = criterion(output, target)\n            f1_macro = calculate_f1_macro(output, target)\n            acc = accuracy(output, target)\n            metric_monitor.update('Loss', loss.item())\n            metric_monitor.update('F1', f1_macro)\n            metric_monitor.update('Accuracy', acc)\n            stream.set_description(\n                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(\n                    epoch=epoch,\n                    metric_monitor=metric_monitor)\n            )\n    return metric_monitor.metrics['Accuracy'][\"avg\"]","8a724ea2":"# kf = StratifiedKFold(n_splits=5)\n\n\n# for k, (train_index, test_index) in enumerate(kf.split(df['image'], df['label'])):\n#     train_img, valid_img = df['image'][train_index], df['image'][test_index]\n#     train_labels, valid_labels = df['label'][train_index], df['label'][test_index]\n\n#     train_paths = '..\/input\/classify-leaves\/' + train_img\n#     valid_paths = '..\/input\/classify-leaves\/' + valid_img\n#     test_paths = '..\/input\/classify-leaves\/' + sub_df['image']\n\n#     train_dataset = LeafDataset(images_filepaths=train_paths.values,\n#                                 labels=train_labels.values,\n#                                 transform=get_train_transforms())\n#     valid_dataset = LeafDataset(images_filepaths=valid_paths.values,\n#                                 labels=valid_labels.values,\n#                                 transform=get_valid_transforms())\n#     train_loader = DataLoader(\n#         train_dataset, batch_size=params['batch_size'], shuffle=True,\n#         num_workers=params['num_workers'], pin_memory=True,\n#     )\n\n#     val_loader = DataLoader(\n#         valid_dataset, batch_size=params['batch_size'], shuffle=False,\n#         num_workers=params['num_workers'], pin_memory=True,\n#     )\n#     model = LeafNet()\n#     model = nn.DataParallel(model)\n#     model = model.to(params['device'])\n#     criterion = nn.CrossEntropyLoss().to(params['device'])\n#     optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n\n#     for epoch in range(1, params['epochs'] + 1):\n#         train(train_loader, model, criterion, optimizer, epoch, params)\n#         acc = validate(val_loader, model, criterion, epoch, params)\n#         torch.save(model.state_dict(), f\".\/checkpoints\/{params['model']}_{k}flod_{epoch}epochs_accuracy{acc:.5f}_weights.pth\")\n","005fa6d0":"train_img, valid_img = df['image'], df['image']\ntrain_labels, valid_labels = df['label'], df['label']\n\ntrain_paths = '..\/input\/classify-leaves\/' + train_img\nvalid_paths = '..\/input\/classify-leaves\/' + valid_img\ntest_paths = '..\/input\/classify-leaves\/' + sub_df['image']\n\nmodel_name = ['seresnext50_32x4d', 'resnet50d']\nmodel_path_list = [\n    '..\/input\/checkpoints\/seresnext50_32x4d_0flod_50epochs_accuracy0.97985_weights.pth',\n    '..\/input\/checkpoints\/seresnext50_32x4d_1flod_50epochs_accuracy0.97872_weights.pth',\n    '..\/input\/checkpoints\/seresnext50_32x4d_2flod_36epochs_accuracy0.97710_weights.pth',\n    '..\/input\/checkpoints\/seresnext50_32x4d_3flod_40epochs_accuracy0.98303_weights.pth',\n    '..\/input\/checkpoints\/seresnext50_32x4d_4flod_46epochs_accuracy0.97899_weights.pth',\n    '..\/input\/checkpoints\/resnet50d_0flod_40epochs_accuracy0.98087_weights.pth',\n    '..\/input\/checkpoints\/resnet50d_1flod_46epochs_accuracy0.97710_weights.pth',\n    '..\/input\/checkpoints\/resnet50d_2flod_32epochs_accuracy0.97656_weights.pth',\n    '..\/input\/checkpoints\/resnet50d_3flod_38epochs_accuracy0.97953_weights.pth',\n    '..\/input\/checkpoints\/resnet50d_4flod_50epochs_accuracy0.97791_weights.pth',\n]\n\nmodel_list = []\nfor i in range(len(model_path_list)):\n    if i < 5:\n        model_list.append(LeafNet(model_name[0]))\n    if 5 <= i < 10:\n        model_list.append(LeafNet(model_name[1]))\n    model_list[i] = nn.DataParallel(model_list[i])\n    model_list[i] = model_list[i].to(params['device'])\n    init = torch.load(model_path_list[i])\n    model_list[i].load_state_dict(init)\n    model_list[i].eval()\n    model_list[i].cuda()\n\n    \nlabels = np.zeros(len(test_paths)) # Fake Labels\ntest_dataset = LeafDataset(images_filepaths=test_paths,\n                            labels=labels,\n                            transform=get_valid_transforms())\ntest_loader = DataLoader(\n    test_dataset, batch_size=128, shuffle=False,\n    num_workers=10, pin_memory=True\n)\n\n\npredicted_labels = []\npred_string = []\npreds = []\n\nwith torch.no_grad():\n    for (images, target) in test_loader:\n        images = images.cuda()\n        onehots = sum([model(images) for model in model_list]) \/ len(model_list)\n        for oh, name in zip(onehots, target):\n            lbs = label_inv_map[torch.argmax(oh).item()]\n            preds.append(dict(image=name, labels=lbs))\n\ndf_preds = pd.DataFrame(preds)\nsub_df['label'] = df_preds['labels']\nsub_df.to_csv('submission.csv', index=False)\nsub_df.head()","cfe8825d":"\u628a\u6570\u636e\u8bfb\u8fdb\u6765\uff0c\u5e76\u4e14\u628alabel\u641e\u5b9a\u3002","f6d67a89":"# \u6d4b\u8bd5\u548c\u63d0\u4ea4\n\n\u63d0\u4ea4\u7528\u7684\u4ee3\u7801\uff0c\u7528\u4e86\u4e24\u4e2a\u6a21\u578bseresnext50_32x4d\u548cresnet50d\u3002","961f09a3":"# \u53c2\u6570\u8bbe\u7f6e \n\n\u6240\u6709\u6a21\u578b\u90fd\u7528\u7684\u76f8\u540c\u7684\u53c2\u6570 \u5176\u5b9e\u8fd9\u91cc\u5e94\u8be5\u9488\u5bf9\u4e0d\u540c\u6a21\u578b\u8c03\u6574\u7684","d8cea451":"# \u8bad\u7ec3\n\n\u4e3a\u4e86\u66f4\u5feb\u6211\u5c31\u6ce8\u91ca\u6389\u4e86\uff0c\u6709\u5174\u8da3\u53ef\u4ee5\u8dd1\u4e00\u4e0b\u3002","473afccb":"\u611f\u8c22Neko Kiku\u63d0\u4f9b\u7684baseline\uff0c\u672c\u6587\u4f7f\u7528\u4e86\u5176\u4e2d\u4e0a\u4f20\u7684\u6570\u636e\u96c6\u3002\n\n#### \u672c\u6587\u7684\u4e3b\u8981\u601d\u8def\u5982\u4e0b\uff1a\n\n* \u6570\u636e\u589e\u5f3a\uff1a\nresize 320, HorizontalFlip, VerticalFlip, Rotate, RandomBrightnesContrasr, ShiftScaleRotate, Normalize\n* \u6a21\u578b\uff1a\nseresnext50\u548cresnet50\n* \u4f18\u5316\u5668\uff1a\nAdamW CosineAnnealingLR\n* \u5176\u4ed6\uff1a\n5\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0c \u6700\u7ec8\u7ed3\u679c\u4e3a\u4e94\u6298\u51c6\u786e\u7387\u6700\u9ad8\u5e73\u5747\uff0c \u4e24\u4e2a\u7f51\u7edc\u5404\u81ea\u5e73\u5747\u540e\u518d\u505a\u5e73\u5747\u3002\nloss\u5c31\u662fCrossEntropy\u3002\n\n### \u6709\u4efb\u4f55\u95ee\u9898\u6b22\u8fce\u8ba8\u8bba\uff0c\u6211\u6bd4\u8f83\u61d2\u5f88\u591a\u4e1c\u897f\u6ca1\u6709\u8be6\u7ec6\u5199\u3002","24fbfbba":"# \u6570\u636e\u589e\u5f3a","152d6e76":"\u56fa\u5b9a\u968f\u673a\u79cd\u5b50\uff0c\u4fdd\u8bc1\u7ed3\u679c\u53ef\u590d\u73b0\u3002","978ae52d":"\u5b9a\u4e49Dataset\uff0c\u8fd8\u6709\u51c6\u786e\u7387\u4e4b\u7c7b\u7684\u51fd\u6570\u3002"}}