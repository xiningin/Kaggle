{"cell_type":{"2bf543c8":"code","b3ef57a0":"code","e39689c2":"code","7171ade1":"code","43cd0a29":"code","d67462bd":"code","6915247b":"code","a8aaa290":"code","2ae933e8":"code","ebb276ff":"code","fcf5004c":"code","b9b27ee6":"code","dce4bd54":"code","e71d7517":"code","a8454342":"code","898842ad":"code","c87fb42a":"code","c974fe5f":"code","4ed85b3b":"code","d0f61d68":"markdown","b1cdf076":"markdown","cae98af3":"markdown","c844135e":"markdown","defc9637":"markdown","130667ab":"markdown"},"source":{"2bf543c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing #for labelling data\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b3ef57a0":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","e39689c2":"test.head()\n","7171ade1":"le = preprocessing.LabelEncoder() #we will be using label encoder for labelling classes","43cd0a29":"le.fit(train.species)\nLabels=le.transform(train.species) # will get labels\nClasses=le.classes_\ntest_ids = test.id                       ","d67462bd":"train.head() # need to remove id and species column ","6915247b":"train=train.drop(['id','species'],axis=1)\ntest=test.drop(['id'],axis=1)","a8aaa290":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nclf=RandomForestClassifier()","2ae933e8":" X_train, X_test, y_train, y_test = train_test_split(train, Labels, test_size=0.30, random_state=42)","ebb276ff":"clf.fit(X_train,y_train)","fcf5004c":"Predicted=clf.predict(X_test)","b9b27ee6":"from sklearn.metrics import accuracy_score\nacc = accuracy_score(y_test, Predicted)\nacc","dce4bd54":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis","e71d7517":"clf1=LinearDiscriminantAnalysis()","a8454342":"clf1.fit(X_train,y_train)","898842ad":"Predictedlda=clf.predict(X_test)\naccLda= accuracy_score(y_test, Predictedlda)\naccLda","c87fb42a":"Finalpredictions= clf1.predict_proba(test)","c974fe5f":"Finalpredictions.shape","4ed85b3b":"Submit = pd.DataFrame(Finalpredictions, columns=Classes)\nSubmit.insert(0, 'id', test_ids)\nSubmit.reset_index()\n\n\n#submission.to_csv('submission.csv', index = False)\nSubmit.to_csv('leaf_classification.csv', index = False)\nSubmit.tail()","d0f61d68":"# Splitting Data into test and train","b1cdf076":"# Preparing the data \nWe will be labelling the data according to the species column\n","cae98af3":"# Predicting on test data","c844135e":"# Both algorithms are almost similar accuracy about 82 % ","defc9637":"# Classifiers\nWe are going to use basically two classifiers:RandomForest and LDA and compare both the algorithms","130667ab":"# Loading the Data "}}