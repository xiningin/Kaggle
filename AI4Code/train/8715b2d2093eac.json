{"cell_type":{"68efe06f":"code","3042f446":"code","98d5bbca":"code","ec079399":"code","9f4b1ce5":"code","72e56ec6":"code","58701169":"code","5c6172f3":"code","039ebb71":"code","2303d39e":"code","c9dadf48":"code","069fc8fb":"code","218af479":"code","4718209e":"code","e6ffbe5f":"code","dd999959":"code","55682bf4":"code","b804443b":"code","6b54476f":"code","cf6bdb48":"code","6cf77383":"code","0b4e8dd3":"code","6f4e76aa":"code","aa0ab1a6":"code","80b21a27":"code","4223dd3d":"code","e42e7376":"code","47a02c13":"code","dcccfc99":"code","23213a09":"code","c580c963":"code","33f9aaab":"code","bc0df83d":"code","403c53d8":"code","f4c609fb":"code","634ba26c":"code","40e628b0":"code","ecc34327":"code","e5679bf3":"code","97687272":"code","e68ec415":"code","df066ac9":"code","35d35a92":"markdown","03429013":"markdown","71d4fa02":"markdown","48456d53":"markdown","04c03f5c":"markdown","11eb2538":"markdown","851d1c1c":"markdown","0442b5aa":"markdown","e948fad7":"markdown","24d90212":"markdown","05e4c7bb":"markdown","d7e4ccf7":"markdown","636409ac":"markdown","db42e7bd":"markdown"},"source":{"68efe06f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\nimport PIL.Image\nimport cv2\nimport plotly.express as px\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2\nAUTOTUNE = tf.data.experimental.AUTOTUNE","3042f446":"train_df = pd.read_csv('..\/input\/happy-whale-and-dolphin\/train.csv')\ntrain_df.head()","98d5bbca":"species_count = train_df.groupby('species')['individual_id'].agg(species_count= 'count').reset_index()\nno_of_individuals = train_df.groupby('individual_id')['image'].agg(no_of_individuals='count').reset_index()\n\ntrain = pd.merge(train_df, species_count, on=['species'], how='inner')\ntrain = pd.merge(train, no_of_individuals, on=['individual_id'], how='inner')\n\ntrain.head()","ec079399":"px.bar(species_count.sort_values(by='species_count', ascending=False), x='species', y='species_count', color='species')","9f4b1ce5":"px.pie(train, names='species')","72e56ec6":"# Check if there are any individual_id's having different naming conventions\n\nset(train[train['species']=='killer_whale']['individual_id'].unique()).intersection(set(train[train['species']=='kiler_whale']['individual_id'].unique()))","58701169":"set(train[train['species']=='bottlenose_dolphin']['individual_id'].unique()).intersection(set(train[train['species']=='bottlenose_dolpin']['individual_id'].unique()))","5c6172f3":"px.bar(train.groupby('species')['individual_id'].nunique().reset_index().rename(columns={'individual_id':'no_of_individuals'}).sort_values(by='no_of_individuals', ascending=False), \n       x='species', y='no_of_individuals', color='species')","039ebb71":"px.bar(train[train.species=='bottlenose_dolphin'], x='individual_id', y='no_of_individuals', title='bottlenose_dolphin distribution')","2303d39e":"px.bar(train[train.species=='kiler_whale'], x='individual_id', y='no_of_individuals', title='Killer whale distribution')","c9dadf48":"px.bar(species_count.sort_values(by='species_count', ascending=False), x='species', y='species_count', color='species')","069fc8fb":"# (reference:- https:\/\/www.kaggle.com\/ruchi798\/and-identification-eda-augmentation)\n\ndef path(group,group_type):\n    PATH = \"..\/input\/happy-whale-and-dolphin\/train_images\"\n    \n    #species\n    if group_type=='species':\n        z = train['image'][train['species']==group].values \n    \n    #ID\n    if group_type=='id':\n        z = train['image'][train['individual_id']==group].values \n   \n    image_names = []\n    for filename in z:\n        fullpath = os.path.join(PATH, filename)\n        image_names.append(fullpath)\n    return image_names\n\n\n\ndef display_multiple_imgs(group, group_type, rows, cols):\n    \n    image_paths = path(group, group_type)\n    image_paths = np.random.choice(image_paths, rows*cols)\n    \n    figure, ax = plt.subplots(nrows=rows,ncols=cols,figsize=(16,8))\n    plt.suptitle(group, fontsize=20)\n    for ind,image_path in enumerate(image_paths):\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n        image = cv2.resize(image, (1200, 800))\n        try:\n            ax.ravel()[ind].imshow(image)\n            ax.ravel()[ind].set_axis_off()\n        except:\n            continue;\n    plt.tight_layout()\n    plt.show()","218af479":"for species in train['species'].unique():\n    print('\\n\\n')\n    display_multiple_imgs(species, 'species', 2, 2)","4718209e":"label_names = train_df['individual_id'].unique()\nlabel_names","e6ffbe5f":"label_to_index = dict((name, index) for index,name in enumerate(label_names))\n# label_to_index","dd999959":"all_image_labels = [label_to_index[i] for i in train_df['individual_id']]\nall_image_labels[:20]","55682bf4":"train_df['label'] = all_image_labels\ntrain_df.head()","b804443b":"all_image_paths = ['..\/input\/happy-whale-and-dolphin\/train_images\/' + img for img in train_df['image']]\nall_image_paths[:10]","6b54476f":"image_count = len(all_image_paths)\nimage_count","cf6bdb48":"def preprocess_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [224, 224])\n    image \/= 255.0  # normalize to [0,1] range\n\n    return image","6cf77383":"def load_and_preprocess_image(path):\n    image = tf.io.read_file(path)\n    return preprocess_image(image)","0b4e8dd3":"image_path = all_image_paths[0]\nlabel = all_image_labels[0]\n\nplt.imshow(load_and_preprocess_image(image_path))\nplt.grid(False)\nplt.title(label_names[label].title())\nprint()","6f4e76aa":"path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\nimage_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\nlabel_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\nimage_label_ds = tf.data.Dataset.zip((image_ds, label_ds))","aa0ab1a6":"BATCH_SIZE = 32\n\nds = image_label_ds.shuffle(buffer_size=1024)\nds = ds.batch(BATCH_SIZE)\nds = ds.prefetch(buffer_size=AUTOTUNE)\nds","80b21a27":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n\nbase_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\nbase_model.trainable=True\n\nprediction_layer = tf.keras.layers.Dense(len(label_names))","4223dd3d":"inputs = tf.keras.Input(shape=(224, 224, 3))\nx = preprocess_input(inputs)\nx = base_model(x, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\n\n\n\noutputs = prediction_layer(x)\n\nmodel = tf.keras.Model(inputs, outputs)","e42e7376":"model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","47a02c13":"model.summary()","dcccfc99":"# model.fit(ds, epochs=10)","23213a09":"sample_submission_df = pd.read_csv('..\/input\/happy-whale-and-dolphin\/sample_submission.csv')\nsample_submission_df.head()","c580c963":"test = pd.read_csv('..\/input\/happy-whale-and-dolphin\/sample_submission.csv')","33f9aaab":"test_image_paths = ['..\/input\/happy-whale-and-dolphin\/test_images\/' + img for img in sample_submission_df['image']]\ntest_path_ds = tf.data.Dataset.from_tensor_slices(test_image_paths)\ntest_image_ds = test_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\ntest_ds = test_image_ds.batch(32).prefetch(buffer_size=AUTOTUNE)","bc0df83d":"%%time\n\npred = model.predict(test_ds)","403c53d8":"# pred = pred.argsort(axis=1)[:,::-1]\n# pred = pred[:,0:5]","f4c609fb":"# index_to_label = {v: k for k, v in label_to_index.items()}\n# predictions = [None] * len(pred)\n\n# for i in range(len(pred)):\n#     row = [None] * 5\n    \n#     for j in range(5):\n#         row[j] = index_to_label[pred[i][j]]\n        \n#     predictions[i] = \" \".join(row)","634ba26c":"# sample_submission_df['predictions'] = predictions\n# sample_submission_df['predictions'].head()","40e628b0":"# sample_submission_df.to_csv('submission.csv', index=False)","ecc34327":"def rotate_values(x):\n    xcopy = x.split()\n    temp = xcopy[4]\n    xcopy[4] = xcopy[0]\n    xcopy[0] = temp\n    xcopy = \" \".join(xcopy)\n    return xcopy","e5679bf3":"submission_df = pd.read_csv('\/kaggle\/input\/happy-whale-and-dolphin\/sample_submission.csv')","97687272":"submission_df[\"predictions\"] = submission_df[\"predictions\"].apply(lambda x: rotate_values(x))","e68ec415":"submission_df.head()","df066ac9":"submission_df.to_csv('submission.csv', index=False)","35d35a92":"### Species Distribution\nLet's look at the distribution of the different speicies in the training set\n\n","03429013":"# Preprocessing and Model Building","71d4fa02":"Same above chart via Pie chart","48456d53":"### Individuals Distribution\n","04c03f5c":"Let's look at the distribution of different species\n","11eb2538":"# Train a model","851d1c1c":"# Model 2","0442b5aa":"# Images","e948fad7":"### Visualize some sample images of different species","24d90212":"# EDA","05e4c7bb":"## Model 1","d7e4ccf7":"# Create a dataset","636409ac":"# Submission","db42e7bd":"Looks like we do not have any overlap :)"}}