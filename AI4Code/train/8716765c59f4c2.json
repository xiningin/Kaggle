{"cell_type":{"cbff5a10":"code","6cce179e":"code","930fb83e":"code","e82c52e9":"code","e5441189":"code","448d5c5a":"code","39d3ee98":"code","413824b8":"code","540bb8cb":"code","9a1e5b5c":"code","74cf1ff6":"code","55fd3db4":"code","7df213bd":"code","74a709be":"code","96771446":"code","935bd696":"code","02f914c9":"code","f1a108fc":"code","9ab8e7f2":"code","1ff25320":"code","f136c09a":"code","68176872":"code","e076b170":"code","8df23d90":"code","88ff8e4c":"code","4c552ca0":"code","c122a0c0":"code","fcc070a7":"code","f5bbbd94":"code","f6f02131":"code","ef692e91":"code","343d4a4b":"code","e9a314c0":"code","4a88cd3f":"code","462cca5d":"code","d7c9b307":"code","841cf039":"code","13f29ef5":"code","3e485b95":"code","ab38bdc1":"code","0d544920":"code","bfbb21bb":"code","2f38353c":"code","c5c7a02f":"code","b96d36b5":"code","8d8b5596":"code","45866e54":"code","966f7344":"code","eaa7d835":"code","65c57659":"code","efebf1a8":"code","1300f46e":"code","e9a322a6":"code","62f127fb":"code","dc5e83c5":"code","5d5910af":"code","164039d0":"code","f896ead5":"code","1ab87bbd":"code","0f2dcdbd":"code","b56ee9ff":"code","dc95f5d2":"code","1612e7c7":"code","21fbb2c0":"code","2f6c38d1":"code","9d51d765":"code","f1d04051":"code","15adde34":"code","4dbdb4f4":"code","cba1404e":"code","6125a8ac":"code","0759b2d6":"code","2a865e76":"code","d3cdbb10":"code","039daeb2":"code","ca6b5cca":"code","7e7abb88":"code","fab26269":"code","b731501f":"code","d03fc2b9":"code","0703f54c":"code","49a190a5":"code","3181f42e":"markdown","8295c103":"markdown","dd1e02ce":"markdown","3053db2b":"markdown","e18dd284":"markdown","cafabd78":"markdown","6bcec8de":"markdown","f21967de":"markdown","863037ae":"markdown","0c597b22":"markdown","a91920a9":"markdown","9aca2125":"markdown","aac25a2b":"markdown","ea09e2e4":"markdown","4488c4ac":"markdown","07c96d12":"markdown","da801bec":"markdown","c0435448":"markdown","c00f7cb7":"markdown","82658294":"markdown","b5a87d21":"markdown","4557ab01":"markdown","e9ff921d":"markdown","95211879":"markdown","35a45060":"markdown","5786ec6a":"markdown","7a0801ea":"markdown","a7d9be44":"markdown","581cfbed":"markdown","17cb4453":"markdown","6b49c158":"markdown","3b411927":"markdown","549ffb23":"markdown","4414199f":"markdown","367345a1":"markdown","b570bd45":"markdown","4432afc3":"markdown","56834a5e":"markdown","7fb0387f":"markdown","c166614e":"markdown","a75df56b":"markdown","2e1af747":"markdown","10da78cf":"markdown","6ddc6766":"markdown","7cef31aa":"markdown","9d56ba19":"markdown","fd2ea50f":"markdown","176d74ec":"markdown","e7447f1f":"markdown","a34bef82":"markdown","01b682c9":"markdown","b14f7bec":"markdown","94205727":"markdown","4ba9dcc9":"markdown","4c0a1e3a":"markdown","30ca7f4c":"markdown","ef4634a7":"markdown","36c73785":"markdown","b9c0bd87":"markdown","7d00eaeb":"markdown","d3a509fb":"markdown","5c51381c":"markdown","da19894f":"markdown","cbe17b90":"markdown","ca55fb70":"markdown","7d2b1f7e":"markdown","5df08d97":"markdown","deb6dbea":"markdown","40a54bc0":"markdown","30c4216d":"markdown","2a3711b4":"markdown","f7407350":"markdown","3d1900a9":"markdown","6b5ad508":"markdown","6f109a98":"markdown","d870530b":"markdown"},"source":{"cbff5a10":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n!pip install calplot\nimport calplot\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n!pip install chart_studio \nimport chart_studio.plotly as py\nimport plotly.graph_objs as go","6cce179e":"\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","930fb83e":"calendar = pd.read_csv('\/\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\nsales_train_validation = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv')\nsell_prices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nsales_train_evaluation = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')","e82c52e9":"sales_train_validation.head()","e5441189":"[column_train,row_train] = sales_train_validation.shape\ncolumn_train,row_train","448d5c5a":"print(len(sales_train_validation.id.str.contains('validation')))\nprint(len(sales_train_validation.id.unique()))","39d3ee98":"print(len(sales_train_validation.id.unique()))\nprint(len(sales_train_validation.item_id.unique()))\nprint(sales_train_validation.dept_id.unique())\nprint(sales_train_validation.cat_id.unique())\nprint(sales_train_validation.store_id.unique())\nprint(sales_train_validation.state_id.unique())","413824b8":"df = sales_train_validation\ndf1 = sales_train_validation.set_index('id').drop(['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], axis=1).transpose()\ndf1.head()","540bb8cb":"n = len(calendar) - len(df1)\ndf2 = calendar[['date', 'd']].set_index('d').iloc[:-n]\ndf3 = pd.concat([df2,df1], axis=1).set_index('date')\ndf3","9a1e5b5c":"fig = plt.figure(figsize=(16,30))\nfor i,j in zip(df3.sample(n=20, axis=1), range(20)):\n    ax=plt.subplot(10,2,j + 1) \n    df3[[i]].plot(ax=ax)\nplt.show()","74cf1ff6":"df4 = pd.concat([df[['id','item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].set_index('id'),df3.transpose()], axis=1)\ndf4","55fd3db4":"unique_units = df4.state_id.value_counts()\nprint('The count of total number of unique items is:\\n', unique_units)\nunique_units.plot(title='Distribution of Total items by State', kind='pie', autopct='%1.1f%%', figsize=(10,6))\nplt.show()","7df213bd":"Total_Sales = df4.groupby('state_id').sum().sum(axis=1)\nTotal_Sales.plot(title='Distribution of Total sales by State', kind='pie', autopct='%1.1f%%', figsize=(10,6))\nplt.show()","74a709be":"df4.groupby(['cat_id']).sum().transpose().sum().plot(title='Sales Distribution by category', kind='pie', autopct='%1.1f%%',\n        shadow=True, figsize=(10,6))\nplt.show()","96771446":"cat_dist = df4.groupby(['cat_id','state_id']).sum().sum(axis=1).unstack('cat_id')\n(cat_dist.transpose() \/ cat_dist.transpose().sum()).transpose().plot(kind='bar')\nplt.show()","935bd696":"df4.groupby(['dept_id']).sum().transpose().sum().plot(title='Sales Distribution by sub category', kind='pie', autopct='%1.1f%%',\n        shadow=True, figsize=(10,6))\nplt.show()","02f914c9":"dept_dist = df4.groupby(['dept_id','state_id']).sum().sum(axis=1).unstack('dept_id')\n(dept_dist.transpose() \/ dept_dist.transpose().sum()).transpose().iplot(kind='bar')","f1a108fc":"df4.groupby(['store_id']).sum().transpose().sum().plot(title='Sales Distribution by store', kind='pie', autopct='%1.1f%%',\n        shadow=True, figsize=(10,6))\nplt.show()","9ab8e7f2":"store_state_dist = df4.groupby(['store_id','state_id']).sum().sum(axis=1).unstack('store_id')\n(store_state_dist.transpose() \/ store_state_dist.transpose().sum()).transpose().iplot(\n    kind='bar', title='Sales distribution of stores in each state')\nplt.show()","1ff25320":"dept_store_dist = df4.groupby(['dept_id','store_id']).sum().sum(axis=1).unstack('dept_id')\n(dept_store_dist.transpose() \/ dept_store_dist.transpose().sum()).transpose().iplot(\n    kind='bar', title='Sales Distribution of Sub Categories by Store_ID')\nplt.show()","f136c09a":"sell_prices['wm_yr_wk'] = sell_prices['wm_yr_wk'].astype(str)\n\nsell_prices['month'] = sell_prices['wm_yr_wk'].str[0:1]\nsell_prices['year'] = sell_prices['wm_yr_wk'].str[1:3]\nsell_prices['year'] = '20' + sell_prices['year'].astype(str)\nsell_prices['week'] = sell_prices['wm_yr_wk'].str[3:5]\nsell_prices['state_id'] = sell_prices['store_id'].str.split('_', 1).str[0]\nsell_prices['cat_id'] = sell_prices['item_id'].str.split('_', 1).str[0]\nsell_prices['dept_id'] = sell_prices['item_id'].str.split('_').str[0] + '_' + sell_prices['item_id'].str.split('_').str[1]\n\nsell_prices.drop('wm_yr_wk', axis=1, inplace=True)","68176872":"sell_prices.head()","e076b170":"sell_prices['sell_price'].plot(kind='hist', figsize=(10,5), bins=20)\nplt.show()","8df23d90":"sell_prices.groupby(['year','state_id']).mean().unstack('state_id').boxplot(\n    figsize=(10,3), vert=False)\nplt.show()","88ff8e4c":"sell_prices.groupby(['year','store_id']).mean().unstack('store_id').boxplot(figsize=(10,7), vert=False)\nplt.show()","4c552ca0":"sell_prices.groupby(['year','cat_id']).mean().unstack('cat_id').boxplot(figsize=(12,3), vert=False)\nplt.show()","c122a0c0":"sell_prices.groupby(['year','dept_id']).mean().unstack('dept_id').boxplot(figsize=(12,4), vert=False)\nplt.show()","fcc070a7":"sell_prices.groupby(['week','year']).mean().unstack('week').boxplot(figsize=(10,12), vert=False)\nplt.show()","f5bbbd94":"sell_prices.groupby(['week','year']).mean().unstack('year').boxplot(figsize=(14,5), vert=False)\nplt.show()","f6f02131":"calendar.head()","ef692e91":"event_1 = pd.merge(calendar[['date','weekday','month','year','d']], \n                   calendar[['d','event_name_1','event_type_1']].dropna(), on='d')\nprint(event_1)\nprint(\"There are 162 events in the calender dateset\")","343d4a4b":"event_1.groupby(['event_type_1','year'])['event_name_1'].size().unstack(\n    'event_type_1').iplot(kind='barh', title='Event Type 1')\nplt.show()","e9a314c0":"event_1.groupby(['month','year'])['event_name_1'].size().unstack('year').iplot(\n    kind='bar', title='Events 1 by Month')\nplt.show()","4a88cd3f":"event_1.groupby(['weekday','year'])['event_name_1'].size().unstack('year').iplot(\n    kind='bar', title='Event 1 by day of the Week')\nplt.show()","462cca5d":"event_2 = pd.merge(calendar[['date','weekday','month','year','d']], \n                   calendar[['d','event_name_2','event_type_2']].dropna(), on='d')\nprint(event_2)\nprint(\"There are 5 Event 2 in the calendar dataset\")","d7c9b307":"event_2.groupby(['event_type_2','year'])['event_name_2'].size().unstack(\n    'event_type_2').iplot(kind='barh', title='Event 2')\nplt.show()","841cf039":"event_2.groupby(['month','year'])['event_name_2'].size().unstack('year').iplot(\n    kind='barh', title='Event 2 by month of the Year')\nplt.show()","13f29ef5":"event_2.groupby(['weekday','year'])['event_name_2'].size().unstack('year').iplot(\n    kind='barh', title='Event 2 by day of the week')\nplt.show()","3e485b95":"pd.merge(calendar[['date','weekday','month','year','d']], \n                   calendar[['d','event_name_1','event_type_1','event_name_2','event_type_2']].dropna(), on='d')","ab38bdc1":"snap = pd.merge(calendar[['date','weekday','month','year','d']], \n                   calendar[['d','snap_CA','snap_TX','snap_WI']].loc[~(calendar[['snap_CA','snap_TX','snap_WI']]==0).all(axis=1)], \n                on='d')\nsnap","0d544920":"snap_CA = snap.groupby(['snap_CA','year']).size()[1].to_frame().reset_index().rename(columns={0:'CA'})\nsnap_TX = snap.groupby(['snap_TX','year']).size()[1].to_frame().reset_index().rename(columns={0:'TX'})\nsnap_WI = snap.groupby(['snap_WI','year']).size()[1].to_frame().reset_index().rename(columns={0:'WI'})\n\npd.merge(pd.merge(snap_CA,snap_TX,on='year'),snap_WI,on='year').set_index(\n    'year').iplot(kind='barh', title='SNAP Days')\nplt.show()","bfbb21bb":"snap_CA_1 = snap.groupby(['snap_CA','month']).size()[1].to_frame().reset_index().rename(columns={0:'CA'})\nsnap_TX_1 = snap.groupby(['snap_TX','month']).size()[1].to_frame().reset_index().rename(columns={0:'TX'})\nsnap_WI_1 = snap.groupby(['snap_WI','month']).size()[1].to_frame().reset_index().rename(columns={0:'WI'})\n\npd.merge(pd.merge(snap_CA_1,snap_TX_1,on='month'),snap_WI_1,on='month').set_index(\n    'month').iplot(kind='barh', title='SNAP Days by month of the year')\nplt.show()","2f38353c":"snap.groupby(['snap_CA','month','year']).size()[1].unstack('year').iplot(\n    kind='bar', title='CA SNAP Days by month')\nplt.show()","c5c7a02f":"snap.groupby(['snap_TX','month','year']).size()[1].unstack('year').iplot(\n    kind='bar', title='TX SNAP Days by month')\nplt.show()","b96d36b5":"snap.groupby(['snap_WI','month','year']).size()[1].unstack('year').iplot(\n    kind='bar', title='WI SNAP Days by month')\nplt.show()","8d8b5596":"snap.groupby(['snap_CA','weekday','year']).size()[1].unstack('year').iplot(\n    kind='barh', title='CA SNAP Days by day of the Week')\nplt.show()","45866e54":"snap.groupby(['snap_TX','weekday','year']).size()[1].unstack('year').iplot(\n    kind='barh', title='TX SNAP Days by day of the Week')\nplt.show()","966f7344":"snap.groupby(['snap_WI','weekday','year']).size()[1].unstack('year').iplot(\n    kind='barh', title='WI SNAP Days by day of the Week')\nplt.show()","eaa7d835":"pd.merge(calendar[['date','weekday','month','year','d']], \n                   calendar[['d','snap_CA','snap_TX','snap_WI']].loc[\n                       (calendar[['snap_CA','snap_TX','snap_WI']]==1).all(axis=1)], \n                on='d')","65c57659":"days = list(pd.to_datetime(calendar.date))\nevents = pd.Series(list(calendar.snap_CA), index=days)\n\ncalplot.calplot(events, cmap='RdBu', colorbar=False)\nplt.show()","efebf1a8":"days = list(pd.to_datetime(calendar.date))\nevents = pd.Series(list(calendar.snap_TX), index=days)\n\ncalplot.calplot(events, cmap='RdBu', colorbar=False)\nplt.show()","1300f46e":"days = list(pd.to_datetime(calendar.date))\nevents = pd.Series(list(calendar.snap_WI), index=days)\n\ncalplot.calplot(events, cmap='RdBu', colorbar=False)\nplt.show()","e9a322a6":"cummulative_sales = df3.transpose().sum().to_frame().rename(columns={0:'cummulative_sales'})\ncummulative_sales.head()","62f127fb":"cummulative_sales.iplot(title='Time Series Plots - Cummulative Sales')\nplt.show()","dc5e83c5":"result = seasonal_decompose(cummulative_sales[\n    'cummulative_sales'].values, period=7, model='additive')\nplt.rcParams.update({'figure.figsize': (12,8)})\nresult.plot().suptitle('Additive Decomposition', fontsize=22)\nplt.show()","5d5910af":"df3.index = pd.to_datetime(df3.index)\ndf5 = pd.concat([df[['id','item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].set_index('id'),\n                 df3.groupby(pd.Grouper(freq='1M')).sum().transpose()], axis=1)","164039d0":"df5.groupby('state_id').sum().transpose().iplot(title='Time Series Plots - Statewise')\nplt.show()","f896ead5":"result = seasonal_decompose(df.groupby(\n    'state_id').sum().transpose().CA.values, period=7, model='additive')\nplt.rcParams.update({'figure.figsize': (12,8)})\nresult.plot().suptitle('Time Series of CA', fontsize=22)\nplt.show()","1ab87bbd":"result = seasonal_decompose(df4.groupby(\n    'state_id').sum().transpose().TX.values, period=7, model='additive')\nplt.rcParams.update({'figure.figsize': (12,8)})\nresult.plot().suptitle('Time Series of TX', fontsize=22)\nplt.show()","0f2dcdbd":"result = seasonal_decompose(df4.groupby(\n    'state_id').sum().transpose().WI.values, period=7, model='additive')\nplt.rcParams.update({'figure.figsize': (12,8)})\nresult.plot().suptitle('Time Series of WI', fontsize=22)\nplt.show()","b56ee9ff":"df5.groupby(['state_id','cat_id']).sum().transpose().CA.iplot(title='CA sales by Category')\nplt.show()","dc95f5d2":"df5.groupby(['state_id','cat_id']).sum().transpose().TX.iplot(title='TX sales by Category')\nplt.show()","1612e7c7":"df5.groupby(['state_id','cat_id']).sum().transpose().WI.iplot(title='WI sales by Category')\nplt.show()","21fbb2c0":"df5.groupby(['state_id','store_id']).sum().transpose().CA.iplot(title='CA sales by Stores')\nplt.show()","2f6c38d1":"df5.groupby(['state_id','store_id']).sum().transpose().TX.iplot(title='TX sales by Store')\nplt.show()","9d51d765":"df5.groupby(['state_id','store_id']).sum().transpose().WI.iplot(title='WI sales by Store')\nplt.show()","f1d04051":"df5.groupby(['store_id']).sum().transpose().iplot(title='Sales by Stores')\nplt.show()","15adde34":"df7 = pd.merge(calendar[['date','weekday','month','year']], \n                   pd.concat([df2,df1], axis=1), on='date').set_index('date')\ndf7.head()","4dbdb4f4":"df7.drop(['month'], axis=1).groupby(['weekday','year']).sum().sum(axis=1).unstack(\n    'weekday').iplot(kind='bar', title='Sales by day of the Week')\nplt.show()","cba1404e":"df7.drop(['weekday'], axis=1).groupby(['month','year']).sum().sum(axis=1).unstack(\n    'month').iplot(kind='bar', title='Sales by Month')\nplt.show()","6125a8ac":"days = list(pd.to_datetime(cummulative_sales.index))\nevents = pd.Series(list(cummulative_sales.cummulative_sales), index=days)\n\ncalplot.calplot(events, cmap='CMRmap')\nplt.show()","0759b2d6":"cummulative_sales.iplot(kind='hist')\nplt.show()","2a865e76":"cummulative_sales_1 = pd.merge(calendar, cummulative_sales.reset_index(), on='date')\ncummulative_sales_1.head()","d3cdbb10":"cummulative_sales_1.groupby(['weekday']).mean()['cummulative_sales'].plot(kind='barh', figsize=(12,6))\nplt.axvline(x=cummulative_sales_1.cummulative_sales.mean(), color='k', linestyle='--')\nplt.show()","039daeb2":"cummulative_sales_2 = cummulative_sales_1.groupby(['weekday']).mean()['cummulative_sales'].reset_index()\ncummulative_sales_2.loc[cummulative_sales_2.weekday=='Saturday']['cummulative_sales'].values","ca6b5cca":"cummulative_sales_2.loc[\n    (cummulative_sales_2.weekday=='Saturday') | (cummulative_sales_2.weekday=='Sunday')].mean()","7e7abb88":"event_days_sales = cummulative_sales_1[\n    ((cummulative_sales_1.event_name_1.notnull()) | (cummulative_sales_1.event_name_2.notnull()))]\ncummulative_sales_1[\"weekend_precede_event\"] = np.nan\n\ndef update_weekend_precede_event(week_e,wday,e1,e2):\n    e2 = '_' + e2 if type(e2) == str else ''\n    drift = e1 + e2\n    if wday == 1:\n        cummulative_sales_1.loc[\n            (cummulative_sales_1['wm_yr_wk']==week_e)&(cummulative_sales_1[\n                'wday']==1),\"weekend_precede_event\"] = drift\n    else:\n        cummulative_sales_1.loc[\n            (cummulative_sales_1[\n                'wm_yr_wk']==week_e)&((cummulative_sales_1['wday']==1)|(cummulative_sales_1[\n                'wday']==2)),\"weekend_precede_event\"] = drift\n        \n_ = event_days_sales.apply(lambda row : update_weekend_precede_event(row[\n    'wm_yr_wk'],row['wday'],row['event_name_1'], row['event_name_2']),axis = 1)","fab26269":"cummulative_sales_1.head()","b731501f":"cummulative_sales_1.groupby(['weekend_precede_event','weekday'])[\n    'cummulative_sales'].mean().unstack('weekday').mean(axis=1).sort_values(ascending = False).plot(kind='bar', figsize=(16,6))\nplt.axhline(y=cummulative_sales_2.loc[\n    (cummulative_sales_2.weekday=='Saturday') | (\n        cummulative_sales_2.weekday=='Sunday')].mean().values, color='black', linestyle='--')\nplt.show()","d03fc2b9":"snap_1 = pd.merge(snap, cummulative_sales, on='date')\nsnap_1","0703f54c":"snap_CA_1 = pd.merge(snap[['date','snap_CA']], df4.groupby([\n    'state_id']).sum().T['CA'].reset_index().rename(\n    columns={'index':'date'}), on='date').groupby(['snap_CA']).mean().reset_index()\nsnap_CA_1.columns = ['snap', 'CA_sales']\nsnap_TX_1 = pd.merge(snap[['date','snap_TX']], df4.groupby([\n    'state_id']).sum().T['TX'].reset_index().rename(\n    columns={'index':'date'}), on='date').groupby(['snap_TX']).mean().reset_index()\nsnap_TX_1.columns = ['snap', 'TX_sales']\nsnap_WI_1 = pd.merge(snap[['date','snap_WI']], df4.groupby([\n    'state_id']).sum().T['WI'].reset_index().rename(\n    columns={'index':'date'}), on='date').groupby(['snap_WI']).mean().reset_index()\nsnap_WI_1.columns = ['snap', 'WI_sales']","49a190a5":"pd.merge(pd.merge(snap_CA_1,snap_TX_1, on='snap'),snap_WI_1, on='snap').set_index('snap').T.plot(\n    kind='bar', figsize=(10,8), title='Snap Days effect')\nplt.axhline(y=df4.groupby(['state_id']).sum().mean(axis=1).to_frame().T.CA.values, color='red', linestyle='--')\nplt.text(0,df4.groupby(['state_id']).sum().mean(axis=1).to_frame().T.CA.values,'Average sales in CA', size=14)\nplt.axhline(y=df4.groupby(['state_id']).sum().mean(axis=1).to_frame().T.TX.values, color='k', linestyle='--')\nplt.text(0.5,df4.groupby(['state_id']).sum().mean(axis=1).to_frame().T.TX.values,'Average sales in TX', size=14)\nplt.axhline(y=df4.groupby(['state_id']).sum().mean(axis=1).to_frame().T.WI.values, color='blue', linestyle='--')\nplt.text(1.5,df4.groupby(['state_id']).sum().mean(axis=1).to_frame().T.WI.values,'Average sales in WI', size=14)\nplt.show()","3181f42e":"## Lets visualize the dataset","8295c103":"* There is monthly seasonality in FOODS category\n* The trend of FOODS and HOUSEHOLD is increasing while that of HOBBIES is flat","dd1e02ce":"There are 30,490 unique items in the datasets.","3053db2b":"# Time Series Analysis","e18dd284":"Each state has similar pattern of sales by sub category with FOODS_3 contibuting to the major share. TX has the highest contribution from FOODS_3 category in comparison to other states. ","cafabd78":"## Sales by day of the year","6bcec8de":"All the events were on Sunday every year.","f21967de":"Trend of all the three categories are increasing.","863037ae":"## Plotting the sales of events","0c597b22":"Store CA_3 has the highest share of sales with 17.0% share.","a91920a9":"There are 3,049 unique item_id, 7 unique dept_id, 3 unique cat_id, 10 unique store_id and 3 unique state_id.\nThis data set belongs to three states of US, CA (California), TX (Texas) & WI (Wisconsin).","9aca2125":"* FOODS_3 has the highest contibution to sales with 49.3% share followed by FOODS_2 and FOODS_1\n* HOUSEHOLD_1 has the highest contibution to sales in the HOUSEHOLD category with 17.5% share followed by HOUSEHOLD_2\n* HOBBIES_1 has the highest contibution to sales in the HOBBIES category with 8.5% share followed by HOBBIES_2","aac25a2b":"In the calendar dataset there are 5 days at which both event 1 and event 2 fell on the same day.","ea09e2e4":"Average sales on Saturday is 41,546.894","4488c4ac":"* 2011, 2013, 2014 & 2016 had one cultural event 2\n* 2014 had one religious event 2","07c96d12":"* The Time Series plot of the cummulative sales shows that there is an increasing trend in the cummulative sales with seasonality.\n* There is one day every year at which the sale is almost equal to 0, the day is 25th December.","da801bec":"# Impact of Events","c0435448":"Thus, except for WI in other states the trend of the categories are either decreasing or flat.","c00f7cb7":"* In all the states SNAP days fall on the first half of the month\n* In all the states SNAP days are organized on same day of the month","82658294":"CA has the highest contibution to sales of unique items with 40% contibution, while the remaining has 30% contibution each. ","b5a87d21":"# Calendar View of SNAP Days in each of the states","4557ab01":"* Trend of CA_1, CA_2 & CA_4 is increasing while the trend of CA_3 is slightly decreasing\n* Trend of CA_2 is increasing rapidly in the recent year in comparison to other stores","e9ff921d":"* There is variation in selling prices in each of the store\n* Store WI_1 has the highest average selling price, also it has the closest range of average selling price\n* Store TX_2 has the lowest average selling price and it has the largest range of average selling price\n* Stores WI_1, WI_2, WI_3, TX_3, CA_2 has sales of costly items\n* Stores TX_1, TX_2, CA_1, CA_3, CA_4 has sales of both costly and cheap items","95211879":"## CA","35a45060":"There are 10 SNAP Days every month for all the states. ","5786ec6a":"* Almost all of the items has the selling price in the range of \\\\$0-\\\\$20\n* Most of the items has the selling price in the range of \\\\$0-\\\\$10","7a0801ea":"There are on average 6 cultural, 10 national, 10 Religious and 3 sporting events in a year.","a7d9be44":"## Evaluation Metrics\nThis competition uses a Weighted Root Mean Squared Scaled Error (RMSSE).","581cfbed":"We can see that on 15 of the events, the sales is greater than the average sales. Thus, is a spike in sales on 15 events.","17cb4453":"* Saturday & Sunday has the highest sales in any week\n* Tuesday, Wednesday & Thursday has the lowest sales in any week","6b49c158":"* Month 2 i.e., February has the highest number of events and months 8 & 9 i.e., August & September has the lowest number of events.","3b411927":"* Trend of WI is increasing at much faster rate than CA & TX\n* There is strong monthly seasonality in CA & TX","549ffb23":"## Variation of Selling Prices across different Time Frames ","4414199f":"# Analysis of Selling Prices","367345a1":"Highly Influenced by : https:\/\/www.kaggle.com\/anirbansen3027\/m5-forecasting-exhaustive-eda-beginner","b570bd45":"* The avg selling price is higher at the begining and latter part of the year\n* In middle of the year i.e., between the week 15 and week 28, there is dip in the avg selling price\n* The range of selling price is closest in the weeks 5 to 8 and 25 to 30","4432afc3":"# **Problem Statement**\nIn this competition, the fifth iteration, you will use hierarchical sales data from Walmart, the world\u2019s largest company by revenue, to forecast daily sales for the next 28 days. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. Together, this robust dataset can be used to improve forecasting accuracy.\n\n**How much camping gear will one store sell each month in a year?** ","56834a5e":"There is a consolidation in the selling price, as with increase in year the avg selling price is also increasing. Also, the range of selling is decreasing with increase in year. ","7fb0387f":"* From the histogram we can see that there is only 5 days in the dataset which is oulier","c166614e":"# Summary Statistics","a75df56b":"43.6%, 28.8% and 27.6% of the total sales has been from CA, TX and WI respectively.","2e1af747":"# Importing Files","10da78cf":"* There is a high weekly correlation in sales\n* In a month most of the sales happens in latter part of the month\n* There is one day every year when sales is 0, the day is 25th Dec","6ddc6766":"## TX","7cef31aa":"* Most of the sales happens on Saturday & Sunday in a week","9d56ba19":"#  Loading Libraries","fd2ea50f":"* Since most of the sales happens on weekends, so to see the effect of the events we needs to map the sale of all the events that happens on Monday to weekends","176d74ec":"* In CA CA_3 has the highest share of sales with 39% share follwed by CA_1, CA_2 and CA_4\n* In TX TX_2 has the highest share of sales with 38.17% share follwed by TX_3 and TX_1\n* In WI WI_2 has the highest share of sales with 36.11% share follwed by WI_3 and WI_1","e7447f1f":"* The time series has an increasing Trend\n* There is a strong weekly seasonilty","a34bef82":"* There is a spike in sales on SNAP days at all the sales.\n* WI has highest increase in SNAP days compared to CA & TX","01b682c9":"Visualization of time series of 20 random item to see pattern.","b14f7bec":"# SNAP Days","94205727":"First, I loaded the sales_train_validation dataset which is our main datasets and contains the historical daily unit sales data per product and store for 1,913 days from 29-Jan-2011.","4ba9dcc9":"## Effect of SNAP days","4c0a1e3a":"* The average selling price of all the itmes is highest in WI followed by CA and TX\n* WI has the closest range of selling price whereas TX has the largest range of selling price\n* The range of avg. selling price of all the items is between \\\\$4.15-\\\\$4.50 ","30ca7f4c":"* June, July, August & September has the highest sales in a year\n* January, February & December has the lowest sales in a year","ef4634a7":"Lets change the date columns from the current format of \"d_\" to date time format \"dd-mm-yyyy\" for time series analysis.","36c73785":"## Event 1 & Event 2","b9c0bd87":"# Events","7d00eaeb":"* Trend of HOUSEHOLD category is increasing\n* Trend of FOODS category is decreasing\n* Trend of HOBBIES category is flat","d3a509fb":"From the above we can see that some of the items has been selling for the compltete period of the datasets, but some where introduced latter and some were discontinued.","5c51381c":"* In the HOBBIES category the HOBBIES_1 sub category is expensive while HOBBIES_2 sub category is the cheapest\n* In the HOUSEHOLD category the HOUSEHOLD_2 sub category is expensive while HOUSEHOLD_1 sub category is cheap\n* In the FOODS category the FOODS_2 sub category is expensive followed by FOODS_3 and FOODS_1","da19894f":"# Content:\n1. Loading Libraries\n2. Importing files\n3. Summary Statistics\n4. Analysis of Selling Prices\n5. Time Series Analysis \n6. Impact of Events\n7. Impact of SNAP days","cbe17b90":"## Data\n* **calendar.csv** - Contains information about the dates on which the products are sold.\n* **sales_train_validation.csv** - Contains the historical daily unit sales data per product and store [d_1 - d_1913]\n* **sample_submission.csv** - The correct format for submissions. Reference the Evaluation tab for more info.\n* **sell_prices.csv** - Contains information about the price of the products sold per store and date.\n* **sales_train_evaluation.csv** - Includes sales [d_1 - d_1941] (labels used for the Public leaderboard)","ca55fb70":"Average sales on Saturday & Sunday is 41,338.458.","7d2b1f7e":"* The trend for CA & WI is icreasing while that of TX is decreasing\n* CA has the highest fluctuation in sales among the three states","5df08d97":"* FOOD_3 has the highest contibution of sales in all the stores with WI_3 has the highest contribution where FOODS_3 contribute to 54.76% of the total sales.\n* All the stores has the similar pattern of sales of sub categories expect CA_2, where contribution by FOODS_1 is more than FOODS_2","deb6dbea":"* Trend of all the three stores are increasing\n* Trend of WI_2 is increasing at much faster rate than that of WI_1 & WI_3","40a54bc0":"I am assumung that the trend of the Time Series is linear and thus is using additive decomposition to decompose the Times Series to the components: Level, Trend, Seasonality and Noise for futher analysis.","30c4216d":"## WI","2a3711b4":"* HOUSEHOLD is the most expensive category with highest avg. selling price and close range\n* FOODS is the cheapest category with lowest avg. selling price and close range","f7407350":"Each state has similar pattern of sales by category with FOODS contibuting to the major share. WI has the highest contribution from FOODS category in comparison to other states. ","3d1900a9":"* Most of the events are organized on Sunday and Monday\n* Friday and Saturday has the least number of the events","6b5ad508":"* Trend of TX_3 is increasing while that of TX_1 & TX_2 is decreasing\n* Trend of TX_2 is decreasing at a much faster rate than that of TX_1","6f109a98":"68.6%, 22.0% and 9.3% of the total sales has been from the categories FOODS, HOUSEHOLD and HOBBIES respectively.","d870530b":"The sales_train_validation dataset has 30,490 rows and 1,919 columns."}}