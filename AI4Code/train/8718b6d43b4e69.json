{"cell_type":{"d7a0a506":"code","047e50c5":"code","410b318b":"code","f6040cf0":"code","79fc5633":"code","80a4122c":"code","21c68c56":"code","385e9112":"code","5294104b":"code","1c3ee5f3":"code","97b08ec7":"code","8d7c99be":"code","beed556a":"code","33b21e42":"code","16b155f9":"code","ae42b147":"code","fe3db025":"code","ca2642e1":"code","8cf34d47":"code","9cbd523f":"code","8c76c86a":"code","2e5b5590":"code","2137cce2":"code","2f566ba2":"code","af6c0155":"code","8d9143bd":"code","d1db9ae4":"code","17149dbb":"code","724d2226":"code","67b90151":"code","e2802393":"code","9a75942e":"code","94da15d5":"code","56491863":"code","15cf01bd":"code","7580da9e":"code","04dec008":"markdown","eae70bd5":"markdown","f2809cfc":"markdown"},"source":{"d7a0a506":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","047e50c5":"movies = pd.read_csv(\"..\/input\/movies_metadata.csv\");\nratings = pd.read_csv(\"..\/input\/ratings_small.csv\");\nkeywords_plot = pd.read_csv(\"..\/input\/keywords.csv\");\ncredits = pd.read_csv(\"..\/input\/credits.csv\");\nrate = pd.read_csv(\"..\/input\/ratings.csv\");\nlinks = pd.read_csv(\"..\/input\/links.csv\");","410b318b":"#let's vizualise MOVIES Data Frame and clean this data set to find Top 3 Revenue Movies.\nmovies","f6040cf0":"#Column-Wise\nmovies.isnull().sum()","79fc5633":"# checking the percentage of null values\nround(100*(movies.isnull().sum()\/len(movies.index)),2)","80a4122c":"# We wiil drop the Columns which have null values more than 0.1%\n## These Columns are : 'belongs_to_collection','homepage','overview','release_date','tagline','runtime','status'\n# We will even drop Poster Path and Overview as these are not required columns\nmovies = movies.drop(['belongs_to_collection','homepage','overview','release_date','tagline','poster_path','overview','runtime','status'],axis=1)\nmovies","21c68c56":"# there might be some null values still, so let us check the % of null values present still\nround(100*(movies.isnull().sum()\/len(movies.index)),2)","385e9112":"movies.shape","5294104b":"# Now we will drop the NULL Values in the Rows\nmovies = movies[~np.isnan(movies.revenue)]\nmovies","1c3ee5f3":"movies.shape","97b08ec7":"round(100*(movies.isnull().sum()\/len(movies.index)),2)","8d7c99be":"movies = movies[movies.isnull().sum(axis=1)<=5]\nmovies","beed556a":"movies.original_language.describe()","33b21e42":"# So we set all the missing values in the Data frame with en\nmovies.loc[pd.isnull(movies['original_language']),['original_language']] = 'en'\nmovies","16b155f9":"movies.isnull().sum()","ae42b147":"movies.imdb_id.describe()","fe3db025":"#we replace the NULL Values with the most frequent 'tt1180333', but we should not do that. So either we drop that column or we replace it with most frequent ID\n#movies.loc[pd.isnull(movies['imdb_id']),['imdb_id']] = 'tt1180333'\n#movies\n#Instead of Imputing Values, we try to delete the Rows where imdb_id is a Null Value\nmovies = movies[movies['imdb_id'].notnull()]","ca2642e1":"movies","8cf34d47":"# Now let's check wether we have any null value or not\nmovies.isnull().sum()","9cbd523f":"# % for null values\nround(100*(movies.isnull().sum()\/len(movies.index)),2)","8c76c86a":"# Now the Data is Clean of any Missing Values.\n# So, Top 3 revenues movies:\nmovies = movies.sort_values(by = 'revenue',ascending=False)\nmovies","2e5b5590":"#Top 3 Revenue Movie\ntop3revenue = movies.loc[:3,]\ntop3revenue","2137cce2":"\nmovies.drop_duplicates(subset = None,keep='first',inplace=True)\nmovies\n","2f566ba2":"movies.set_index(['id'])","af6c0155":"#Top 10 movies according to Revenue.\nmovies.iloc[:10,]","8d9143bd":"ratings","d1db9ae4":"ratings.isnull().sum()\n#We see that It is one of the cleaned data frames.\n#Next Step we think of is to Merge\/Concat the Data Frame. What do you think....should we Merge or Concat??","17149dbb":"top10 = ratings.sort_values(by='rating',ascending=False)\ntop10 = top10.iloc[:10,]\ntop10","724d2226":"#top 10 movies\ntop10 = top10.drop(['timestamp'],axis=1)\ntop10","67b90151":"#Now let's dive into other Data Frames too!\nkeywords_plot","e2802393":"keywords_plot.isnull().sum()","9a75942e":"round(100*(keywords_plot.isnull().sum()\/len(keywords_plot.index)),2)","94da15d5":"#Let's split the data and Apply a ML Model to predict the imdb_score for the testing data!","56491863":"movies.drop(['vote_count'],axis=1)","15cf01bd":"X = movies.loc[:,:'video'].as_matrix()\ny = movies['vote_average']","7580da9e":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\nprint(X_train.shape,X_test.shape)\nprint(y_train.shape,y_test.shape)","04dec008":"Hope you like It!","eae70bd5":"**Now We will Look onto Ratings Data Frame and try to clean the Data Set to find the Top 10 rated Movies****","f2809cfc":"# One thing to observe is that it is a Categorical Data and, So we either we Use Hot Encoding to to convert the dtype() or use a more Complexed behaviour Model."}}