{"cell_type":{"11866bf5":"code","9dd3c304":"code","56545aa0":"code","7d6fcac3":"code","c3252030":"code","ff3e0328":"code","a33721d1":"code","b993a681":"code","6cb9c63c":"code","c30b62eb":"code","2be12ad9":"code","3bf87325":"code","ac658c0c":"code","d277e27d":"code","ab059c58":"markdown","f3ca223e":"markdown","edad8d8a":"markdown"},"source":{"11866bf5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9dd3c304":"import numpy as np\nimport pandas as pd\nimport lightgbm as LGB  \nfrom sklearn.metrics import roc_auc_score, make_scorer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom itertools import product\n\n","56545aa0":"train = pd.read_csv('\/kaggle\/input\/cat-in-the-dat\/train.csv')\n\ntrain.head()","7d6fcac3":"test = pd.read_csv('\/kaggle\/input\/cat-in-the-dat\/test.csv')\n\ntest.head()","c3252030":"train_size=train.shape[0]\ntest_size=test.shape[0]\nprint('Train size = ' + str(train_size))\nprint('Test size = ' + str(test_size))","ff3e0328":"y_train_tmp=train['target']\n\nwhole_dataset=pd.concat([train.drop('target',axis=1), test], axis=0)\nwhole_dataset = whole_dataset.drop(['id', ], axis=1)\nwhole_dataset.head()","a33721d1":"whole_dataset.isnull().sum()","b993a681":"OneHot=OneHotEncoder(drop='first', sparse=True)\nOneHot.fit(whole_dataset)\nOH_train_tmp=OneHot.transform(whole_dataset.iloc[:train_size,:])\nOH_test=OneHot.transform(whole_dataset.iloc[train_size:,:])\n","6cb9c63c":"OH_train, OH_val, y_train, y_val = train_test_split(OH_train_tmp, y_train_tmp, test_size=0.05, random_state=9)\n","c30b62eb":"\nlgb_train = LGB.Dataset(OH_train, y_train)  \nlgb_eval = LGB.Dataset(OH_val, y_val, reference=lgb_train) \nparams = {  \n    'boosting_type': 'gbdt',  \n    'objective': 'binary',  \n    'metric': 'auc', \n    'max_depth': 2,  \n    'learning_rate': 0.3,  \n    'feature_fraction': 0.2,\n    'is_unbalance': True  \n}  ","2be12ad9":"gbm = LGB.train(params,  \n          lgb_train,  \n          num_boost_round=10000,  \n          valid_sets=[lgb_train, lgb_eval, ],  \n          early_stopping_rounds=500,\n          verbose_eval=200) ","3bf87325":"y_train_pred_lgb=gbm.predict(OH_train, num_iteration=gbm.best_iteration)\ny_val_pred_lgb=gbm.predict(OH_val, num_iteration=gbm.best_iteration)\nprint(\"Training auc : \",roc_auc_score(y_train, y_train_pred_lgb))\nprint(\"Val auc : \",roc_auc_score(y_val, y_val_pred_lgb))","ac658c0c":"y_test_pred_lgb=gbm.predict(OH_test, num_iteration=gbm.best_iteration) ","d277e27d":"y_test_pred = y_test_pred_lgb\nsubmission=pd.DataFrame({'id': np.arange(300000, 500000,1), 'target':y_test_pred})\nsubmission.to_csv('submission.csv', index=False)","ab059c58":"# Import libraries and files","f3ca223e":"# One Hot Encoding","edad8d8a":"# Model"}}