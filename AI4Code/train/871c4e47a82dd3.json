{"cell_type":{"31374741":"code","9e78f77e":"code","112ba412":"code","6b8a9db8":"code","aaf4555f":"code","290f3401":"code","75bb5ad2":"code","e58b79b9":"code","c4e987a0":"code","e4046435":"code","837170f4":"code","c6223d71":"code","7667418c":"code","8f347368":"code","408212a9":"code","f7dea10c":"code","fda83860":"code","b8c5fc18":"code","9ec361cf":"code","f4b810c8":"code","2afbfa1d":"code","0da9ff10":"code","a04332bd":"code","514c6298":"code","e049238e":"code","2fdc3f2b":"code","9791a802":"code","d74df978":"code","025392fb":"code","ca4b3abf":"code","3d07f7b4":"code","3ab313ef":"code","4362e8a4":"code","bdaeeabf":"code","7de41a92":"code","9186e960":"code","f67575c0":"code","5ee2a95b":"code","d8786b31":"code","dd14bd92":"code","f776a282":"code","3f8260db":"code","0ba9f06b":"code","19f8d323":"code","91c9ea7b":"code","e2e14ee1":"code","74a05bbd":"code","e92d6fe7":"code","9b64d777":"code","a43c5fa5":"code","b73f462f":"code","96c0a559":"code","97a106f6":"code","3bf1552c":"code","7fb28b6d":"code","ed02f348":"code","e8fd7443":"code","93dded1e":"code","71290239":"code","74eed65c":"code","63018997":"code","9df0a86b":"code","13853e5d":"code","3a71f44a":"code","6bd94da3":"code","b7f4a64a":"code","bb6f40a3":"code","b741b9b1":"code","5a8c1290":"markdown","ee231b35":"markdown","2c3c3076":"markdown","b4277848":"markdown","769e98e0":"markdown","f2a50872":"markdown","86b2033d":"markdown","42ef1960":"markdown","2768244f":"markdown","4828ac24":"markdown","929b80ea":"markdown","a4553637":"markdown","031ac43d":"markdown","761d2997":"markdown","f8bb124a":"markdown","a6a06cd6":"markdown","698a70c8":"markdown","294574e1":"markdown","e4532057":"markdown","8d1e505d":"markdown","d30cda47":"markdown","ade34671":"markdown","ca3b99b0":"markdown","ec73e2c8":"markdown","ff377b53":"markdown","fa22ee3d":"markdown","43728074":"markdown","ff8dca6a":"markdown"},"source":{"31374741":"#import the libraries we need\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","9e78f77e":"#train_set\ndf_train = pd.read_csv('..\/input\/machine-learning-on-titanic-data-set\/train.csv')\n\n#test_set\ndf_test = pd.read_csv('..\/input\/machine-learning-on-titanic-data-set\/test.csv') \n\n#y_test data\ndf_y_test = pd.read_csv('..\/input\/machine-learning-on-titanic-data-set\/gender_submission.csv') #It shows y_test data","112ba412":"#now we join y_test data to df_test dataframe\n\ndf_test['Survived'] = df_y_test['Survived']","6b8a9db8":"df = pd.concat([df_train,df_test])","aaf4555f":"df.head()","290f3401":"#So we can set passenger Id as index.\n\ndf.set_index('PassengerId')","75bb5ad2":"df.head()","e58b79b9":"df.describe()","c4e987a0":"df.info()","e4046435":"df.isnull().sum()","837170f4":"#Make a Function to calculate the percent of missing data in each columns (feature) and then sort it\ndef missing_percent(df):\n    nan_percent= 100*(df.isnull().sum()\/len(df))\n    nan_percent= nan_percent[nan_percent>0].sort_values()\n    return nan_percent\nmissing_percent(df)","c6223d71":"df[df['Fare'].isnull()]","7667418c":"df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda val: val.fillna(val.mean()))","8f347368":"missing_percent(df)","408212a9":"df_train[df_train['Embarked'].isnull()]","f7dea10c":"df= df.dropna(axis=0, subset=['Embarked'])","fda83860":"missing_percent(df)","b8c5fc18":"df[df['Age'].isnull()]","9ec361cf":"plt.figure(figsize=(12,6))\n\nsns.histplot(df_train['Age'],palette=\"mako\")","f4b810c8":"df['Age'] = df['Age'].transform(lambda val: val.fillna(val.mean()))","2afbfa1d":"missing_percent(df)","0da9ff10":"df.drop('Cabin', axis =1, inplace= True)","a04332bd":"missing_percent(df)","514c6298":"df.drop(['Name','Ticket'], axis = 1, inplace=True)","e049238e":"df.head()","2fdc3f2b":"df.corr()['Survived'].sort_values()","9791a802":"plt.figure(figsize=(7.5,7.5))\n\nsns.heatmap(df.corr())","d74df978":"df.value_counts('Survived')","025392fb":"plt.figure(figsize=(10,5))\n\nsns.barplot(x = ['Dead', 'Survived'], y = df['Survived'].value_counts(), palette=\"mako\")","ca4b3abf":"plt.figure(figsize=(10,5))\n\nsns.barplot(data = df, x='Sex', y='Survived', palette=\"mako\")","3d07f7b4":"plt.figure(figsize=(10,5))\n\nsns.barplot(data = df, x='Pclass', y='Survived', palette=\"mako\")","3ab313ef":"plt.figure(figsize=(10,5))\n\nsns.barplot(data = df, x='Embarked', y='Survived',palette=\"mako\")","4362e8a4":"plt.figure(figsize=(10,5))\n\nsns.scatterplot(data = df, x = 'Age', y = 'Fare', hue='Survived',palette=\"mako\")","bdaeeabf":"df[df['Survived'] == 1]['Age'].mean()","7de41a92":"df[df['Survived'] == 0]['Age'].mean()","9186e960":"df[df['Survived'] == 1]['Sex'].value_counts()","f67575c0":"df[df['Survived'] == 0]['Sex'].value_counts()","5ee2a95b":"a1 = df[(df['Survived'] == 1) & (df['Sex'] == 'male')]['Fare'].mean()","d8786b31":"a2 = df[(df['Survived'] == 0) & (df['Sex'] == 'male')]['Fare'].mean()","dd14bd92":"a3 = df[(df['Survived'] == 1) & (df['Sex'] == 'female')]['Fare'].mean()","f776a282":"a4 = df[(df['Survived'] == 0) & (df['Sex'] == 'female')]['Fare'].mean()","3f8260db":"Survived_Fare = pd.DataFrame({'':['Survived men Fare','Dead men Fare','Survived women Fare','Dead women Fare'],\n                                'Value':[a1,a2,a3,a4]})\nSurvived_Fare","0ba9f06b":"Survived_Fare.plot.bar()","19f8d323":"df.info()","91c9ea7b":"df['Survived'] = df['Survived'].apply(str)","e2e14ee1":"df.info()","74a05bbd":"df['Pclass'] = df['Pclass'].apply(str)","e92d6fe7":"df.info()","9b64d777":"#Seperate the columns with object type\n\ndf_num = df.select_dtypes(exclude='object')\ndf_obj = df.select_dtypes(include='object')","a43c5fa5":"df_obj.drop('Survived', axis = 1, inplace=True)","b73f462f":"#transform to Dummy variable\n\ndf_obj = pd.get_dummies(df_obj, drop_first=True)","96c0a559":"#Join the columns\n\nFinal_df = pd.concat([df_num, df_obj,df['Survived']], axis=1)\nFinal_df.set_index('PassengerId')","97a106f6":"#X : Features\n#y : Target variable\n\nX = Final_df.drop('Survived', axis = 1)\ny = Final_df['Survived']","3bf1552c":"#we use train_test_split from sklearn.model_selection to devide dataset to train and test set.\n\nfrom sklearn.model_selection import train_test_split\n\n#train set in a bigger sample of dataset that model uses to learn.\n#test set in smaller sample of dataset that model should be evaluated in.\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state=101)","7fb28b6d":"#we use StandardScaler from sklearn.preprocessing to make dataset values standard\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler= StandardScaler()\n\nscaler.fit(X_train)","ed02f348":"X_train","e8fd7443":"from sklearn.linear_model import LogisticRegression\n\nLogistic_model = LogisticRegression(max_iter=4000) #our model is a Logistic Regression\n\nLogistic_model.fit(X_train,y_train)","93dded1e":"y_pred = Logistic_model.predict(X_test)","71290239":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix, precision_score, recall_score","74eed65c":"confusion_matrix(y_test, y_pred)","63018997":"\nplot_confusion_matrix(Logistic_model, X_test, y_test)","9df0a86b":"accuracy_score(y_test, y_pred)","13853e5d":"precision_score(y_test, y_pred,average='macro')","3a71f44a":"recall_score(y_test, y_pred, average='macro')","6bd94da3":"from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, plot_roc_curve","b7f4a64a":"plot_precision_recall_curve(Logistic_model, X_test, y_test)","bb6f40a3":"plot_roc_curve(Logistic_model, X_test, y_test)","b741b9b1":"pd.DataFrame({ '':['Accuracy','precision','recall'],\n             'Value': [accuracy_score(y_test, y_pred),precision_score(y_test, y_pred,average='macro')\n              ,recall_score(y_test, y_pred, average='macro')]})","5a8c1290":"Most of Cabin values are null. So we decide to remove this columns of dataframe.","ee231b35":"Pclass should not be integer. It's a categorical variable and it's not calculatable.","2c3c3076":"In this notebook we use Titanic dataset to predict who will survive! It just a case study to use ML algorithm and get more familiar with models!\n\nBefore we use Linear Regression, Polynomial Regression & Regularization and now we are going to use Classification algorithms! Now we start with Logistic Regression.\n\n![image.png](attachment:image.png)\n\nLogistic Regression is suitable for Categorical target variables. Logistic Regression helps us in many fileds such as Medical and health, Psychology and social science. For example we can make a model that predict having diabetes based on daily activity.\n\nYou can learn more about Logistic regression here: https:\/\/en.wikipedia.org\/wiki\/Logistic_regression","b4277848":"Also \"Name\" and \"ticket number\" are not important or effective on model. So we can drop them too.","769e98e0":"## 6.2 Predict","f2a50872":"## 7.3 Recall score","86b2033d":"Now we handle all missing data and we can go on!","42ef1960":"More than 80% survived people were female. ","2768244f":"It seems like the people who pay more fare had a better chanse for being survived.","4828ac24":"# 1. Importing Data and first review\n\nWe have 3 csv files. As we will see train set and test set are seperate. So we import them seperatly.","929b80ea":"# 5. Scaling Data","a4553637":"## 7.4 Curves and AUC","031ac43d":"Survived = 1 if they survived and 0 if they did not.\n\nPclass = Passenger class (1 as 1st, 2 as 2nd, 3 as 3rd)\n\nName = passenger's name\n\nSex = passenger's sex\n\nAge = passenger's age\n\nsibsp = Number of Siblings\/Spouses Aboard\n\nparch = Number of Parents\/Children Aboard\n\nTicket = Ticket Number\n\nFare = Passenger Fare (British pound)\n\ncabin = Cabin\n\nembarked = Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n","761d2997":"# 6. Build the model\n## 6.1 Train","f8bb124a":"Fare is the money that passenger pay. So it really dependes on Passenger class. So based on passneger class mean of fare we can fill this value.","a6a06cd6":"# 3. Categorical Variables","698a70c8":"Survived should not be integer. It's a categorical variable and it's not calculatable.","294574e1":"# 7. Evaluate model","e4532057":"There were 815 people dead and 492 survived.","8d1e505d":"These rows has the same ticket number. So they Embarked place is same too! But we don't have more information about these 2 rows. So we decide to drop these 2.","d30cda47":"It seems that passenger class effect on being survived. (Money can hold you alive :D)","ade34671":"# 4. Split Data to Train & Test","ca3b99b0":"## 7.2 Precision score","ec73e2c8":"# 3. Exploratory data analysis","ff377b53":"## 7.1 Accuracy","fa22ee3d":"We can fill age values with mean of other rows because of normal distribution that data has.","43728074":"# 2. Cleaning Data (Missing data)","ff8dca6a":"Now we should use transform our object type data to dummy variables."}}