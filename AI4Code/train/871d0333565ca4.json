{"cell_type":{"3d702a5a":"code","53f06f9f":"code","51cf3aee":"code","bcc38f0c":"code","3b5b0afa":"code","f77ad7e8":"code","62af8593":"code","920b2a91":"code","a647891b":"code","98577733":"code","d9099121":"code","a0c56c84":"code","87f9f781":"code","18ab7f84":"code","ae006ca9":"code","91cc2401":"code","91de854c":"markdown","840bc54b":"markdown","c56d8813":"markdown","92037655":"markdown"},"source":{"3d702a5a":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn import preprocessing","53f06f9f":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","51cf3aee":"\nlearning_rate = 0.5\ntraining_epochs = 1000\nbatch_size = 80\ndrop_prob = 0.3\nScaler = preprocessing.StandardScaler()","bcc38f0c":"train_data=pd.read_csv('train data.csv',header=None, usecols=range(1,9), skiprows=range(0,1))\ntest_data=pd.read_csv('test data.csv',header=None, usecols=range(1,8), skiprows=range(0,1))","3b5b0afa":"x_train_data=train_data.loc[:,0:7]\ny_train_data=train_data.loc[:,8]\n\nx_train_data=np.array(x_train_data)\ny_train_data=np.array(y_train_data)\nx_train_data = Scaler.fit_transform(x_train_data)\n\nx_train_data=torch.FloatTensor(x_train_data)\ny_train_data=torch.FloatTensor(y_train_data)\n","f77ad7e8":"train_dataset = torch.utils.data.TensorDataset(x_train_data, y_train_data)","62af8593":"data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)","920b2a91":"linear1 = torch.nn.Linear(7,4,bias=True)\nlinear2 = torch.nn.Linear(4,4,bias=True)\nlinear3 = torch.nn.Linear(4,4,bias=True)\nlinear4 = torch.nn.Linear(4,4,bias=True)\nlinear5 = torch.nn.Linear(4,1,bias=True)\nrelu = torch.nn.ReLU()\ndropout = torch.nn.Dropout(p=drop_prob)","a647891b":"\ntorch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\ntorch.nn.init.xavier_uniform_(linear4.weight)\ntorch.nn.init.xavier_uniform_(linear5.weight)","98577733":"model = torch.nn.Sequential(linear1,relu,dropout,\n                            linear2,relu,dropout,\n                            linear3,relu,dropout,\n                            linear4,relu,dropout,\n                            linear5).to(device)","d9099121":"\nloss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","a0c56c84":"total_batch = len(data_loader)\nmodel.train()\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        X = X.to(device)\n        Y = Y.to(device)\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Learning finished')","87f9f781":"# Test the model using test sets\nwith torch.no_grad():\n  model.eval()\n  x_test_data=test_data.loc[:,:]\n  x_test_data=np.array(x_test_data)\n  x_test_data = Scaler.transform(x_test_data)\n  x_test_data=torch.from_numpy(x_test_data).float().to(device)\n\n  prediction = model(x_test_data)\n  prediction","18ab7f84":"correct_prediction = prediction.cpu().numpy().reshape(-1,1)","ae006ca9":"submit=pd.read_csv('submit sample.csv')\nsubmit","91cc2401":"for i in range(len(correct_prediction)):\n  submit['Expected'][i]=correct_prediction[i].item()\n\nsubmit","91de854c":"\ub370\uc774\ud130 \ub85c\ub4dc","840bc54b":"5\uac1c\uc758 layer","c56d8813":"\ubaa8\ub378\ud559\uc2b5","92037655":"\ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815"}}