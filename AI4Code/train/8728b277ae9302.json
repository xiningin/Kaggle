{"cell_type":{"7a45d1e0":"code","5ca0e052":"code","89c414ef":"code","54a6ada5":"code","417d5d1c":"code","fcb6e7eb":"code","54fd9644":"code","68aba23f":"code","f1994a99":"code","13916214":"code","f98af6fc":"code","bdd57bf3":"code","b51949f4":"code","da1a79a7":"code","f6c43f82":"code","79bf9474":"code","8535ba28":"code","ead18be1":"code","f9d33f67":"code","162ff114":"code","16c6ea5f":"markdown","9543317c":"markdown","9f7d86b8":"markdown","3a00af9c":"markdown","bb953415":"markdown","d295e33d":"markdown","30d0d8fa":"markdown","369dd8c1":"markdown","b4d38af5":"markdown","96ca6ab9":"markdown","06e3b66f":"markdown","762bacc1":"markdown"},"source":{"7a45d1e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas_profiling import ProfileReport # Quick EDA (explorative data analysis)\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","5ca0e052":"# File names for train, test and random submission\ntrain_csv = \"train.csv\"\ntest_csv = \"test.csv\"\nrandom_submission_csv = \"random_submission.csv\" ","89c414ef":"# Load the csv's to dataframes and show them\n\ndf_random_submission = pd.read_csv(os.path.join(dirname, random_submission_csv))\ndf_train = pd.read_csv(os.path.join(dirname, train_csv))\ndf_test = pd.read_csv(os.path.join(dirname, test_csv))\n\ndisplay(df_train)\ndisplay(df_test)\ndisplay(df_random_submission)","54a6ada5":"# Setting minimal=False in the following line will give you richer information \nprofile = ProfileReport(df_train, title=\"Train Set Profiling Report\",  minimal=True) \nprofile.to_widgets()","417d5d1c":"# Survival rate in each Pclass\ndf_train.groupby(\"Pclass\")[\"Survived\"].mean().plot(kind=\"barh\")","fcb6e7eb":"# Do more analysis\n","54fd9644":"# This cell is just for demostration purpose. Skip\/delete as needed.\n# Suppose you think that survival rate is higher if Tickets starts with \"CA\" \ndf_train[\"Ticket_CA\"] = df_train[\"Ticket\"].apply(lambda x: int(x.startswith(\"CA\")))\ndf_test[\"Ticket_CA\"] = df_test[\"Ticket\"].apply(lambda x: int(x.startswith(\"CA\")))\n\ndf_train[\"Ticket_CA\"].describe()","68aba23f":"# Do more engineering\n","f1994a99":"# Modify as needed\nfeature_cols = [ 'Pclass', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Fare']","13916214":"# Create dataframes with the necessary columns\ndf_train_feature = df_train[feature_cols]\ndf_test_feature = df_test[feature_cols]","f98af6fc":"# Get columns with any null values\ntrain_null_cols = df_train_feature.columns[df_train_feature.isnull().sum() > 0]\ntest_null_cols = df_test_feature.columns[df_test_feature.isnull().sum() > 0]\nnull_cols = sorted(list(set(train_null_cols).union(set(test_null_cols))))\nprint(null_cols)","bdd57bf3":"# Check the data types of null columns\ndf_train_feature[null_cols].dtypes","b51949f4":"# Fill in the average value for Age and Fare\nnumeric_cols = [\"Age\", \"Fare\"]\nmean_vals = df_train_feature[numeric_cols].mean()\nmean_dict = dict(zip(numeric_cols, mean_vals))\nprint(mean_dict)\n\ndf_train_feature.fillna(mean_dict, inplace=True)\ndf_test_feature.fillna(mean_dict, inplace=True)","da1a79a7":"# Check if null values are filled\nprint(df_train_feature.columns[df_train_feature.isnull().sum() > 0])\nprint(df_test_feature.columns[df_test_feature.isnull().sum() > 0])","f6c43f82":"# One-hot encode the string variables\n# Hint: Make sure train and test sets have identical columns after encoding\ndf_train_encoded = pd.get_dummies(df_train_feature)\ndf_test_encoded = pd.get_dummies(df_test_feature)\n\n\ndisplay(df_train_encoded)\ndisplay(df_test_encoded)","79bf9474":"# Modify below to your favorite algorithm\nlr = LogisticRegression(solver='liblinear')\nlr.fit(X=df_train_encoded, y=df_train[\"Survived\"])","8535ba28":"pred = lr.predict(df_test_encoded)","ead18be1":"display(pred)","f9d33f67":"df_submit = pd.DataFrame(columns=['PassengerId', 'Survived'])\ndf_submit[\"PassengerId\"] = df_test[\"PassengerId\"]\ndf_submit[\"Survived\"] = pred","162ff114":"# Files named submission.csv gets submitted automatically by pressing the Submit button on right column\ndf_submit.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","16c6ea5f":"# (Optional) Feature engineering\n\n- If you found anything interesting during EDA, let's create features from your findings to make better predictions","9543317c":"# Create submission file","9f7d86b8":"# (Optional) Handle missing values\n\n- Some algorithms don't allow missing values in their inputs -> Impute them with appropriate values\n- Modify the imputation method below as needed","3a00af9c":"# Make predictions","bb953415":"# Starter Code","d295e33d":"# (Optional) Encode string variables to numeric features\n\n- Some model algorithms require all input features to be numeric\n- We need to encode the string features to numeric features","30d0d8fa":"# Profiling\n\n- This is a profiling report of the train set\n- Take a look into it and see if you can find some interesting stuff on the data","369dd8c1":"# Import libraries and set parameters","b4d38af5":"# EDA (Explorative Data Analsis)\n\n- Dig into the data to see if you can find any relationship with the features and the target variable (i.e. Survived)\n- Be creative. Come up with hypotheses and verify them with data.\n- If you are uncomfortable with coding, feel free to download the datasets and explore with your favorite tool (e.g. Excel)","96ca6ab9":"# Train a model\n\n- Use any algorithm you want to get better predictions\n- You can also tune your hyperparameters if necessary","06e3b66f":"# Feature selection\n\n- Select features you want to include in the predictive model based on your EDA results","762bacc1":"# Load data"}}