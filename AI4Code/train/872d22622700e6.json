{"cell_type":{"4768b730":"code","18469b6c":"code","ac09bc92":"code","34040d00":"code","ce3309d6":"code","3985538e":"code","9b9f254e":"code","3e5eaa8d":"code","633067dd":"code","8632bb71":"code","ac1f8307":"code","1f29f03c":"code","d8261add":"code","42194e10":"code","65c3dd05":"code","b924f3ba":"code","4e554ab0":"code","c812103a":"code","3db2d110":"code","c30a5253":"code","db13b289":"code","13a83d01":"code","39abc727":"code","e542c889":"code","dfe3f6f3":"code","43036897":"code","b14ffc4e":"code","db83c3a0":"code","4f3e973c":"code","e1224578":"code","64d9ff88":"code","581a35af":"code","e9638e2a":"code","a9e9833f":"code","20821481":"code","4c95fe74":"code","2a1c227b":"code","dfd8226a":"code","f93affff":"code","b498b915":"code","17def31d":"code","249e2187":"code","cb38d62a":"code","1131f7e6":"code","bd1bfa85":"code","c3471517":"code","1e9feef9":"code","14c3f0cc":"code","b844cdcb":"code","0795698d":"code","969caa24":"code","91f5cec3":"code","f5a81d42":"code","cddd7067":"code","d8d506f6":"code","a95776e7":"code","c3d8aa1c":"code","894a5bbd":"code","0f468e75":"code","3f822c63":"code","3cf86556":"code","50eba6de":"code","1a6336a6":"code","90c5fcf4":"code","418ce009":"code","15951fb4":"code","0a77c189":"code","7a077e3d":"code","bd3af509":"code","fd44407c":"code","ebf0042a":"code","bbef4250":"markdown","5454414a":"markdown","31c5e656":"markdown","f481bd1f":"markdown","d92d0caa":"markdown","9c165bb9":"markdown","1ae584cc":"markdown","79ad056f":"markdown","3cee3b5d":"markdown","9f234c83":"markdown","ca5cc5cb":"markdown","7d6a3824":"markdown","8c77888c":"markdown","b8c288ae":"markdown","1d579686":"markdown","636bb82b":"markdown","8aef3f27":"markdown","4f00a77d":"markdown","16cd7370":"markdown","bc68af88":"markdown","ccded78e":"markdown","07215260":"markdown","80010091":"markdown","59e8db1b":"markdown","1c5192b9":"markdown"},"source":{"4768b730":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18469b6c":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\n\n# opencv for image analysis\nimport cv2\nimport urllib","ac09bc92":"from bokeh.plotting import figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs","34040d00":"!cp -r \"\/kaggle\/input\/kerasretinanet\/keras-retinanet\" .","ce3309d6":"# install retinanet\n!git clone https:\/\/github.com\/fizyr\/keras-retinanet.git\n%cd keras-retinanet\/\n\n!pip install .\n\n!python setup.py build_ext --inplace","3985538e":"import tensorflow as tf\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\nimport urllib\nfrom tqdm.notebook import tqdm","9b9f254e":"train = pd.read_csv(\"\/kaggle\/input\/global-wheat-detection\/train.csv\")  \ntrain_data_folder = \"\/kaggle\/input\/global-wheat-detection\/train\/\"\ntest_data_folder = \"\/kaggle\/input\/global-wheat-detection\/test\/\"\n","3e5eaa8d":"train.head()","633067dd":"print(\"Dataset shape: {}\".format(train.shape))","8632bb71":"# check for missing values\ntrain.isnull().sum()","ac1f8307":"train['width'].value_counts()","1f29f03c":"train['height'].value_counts()","d8261add":"# take random index\nseed = 42\nrng = np.random.RandomState(seed)","42194e10":"def show_images(df):\n    # print a few images together with box\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15), sharex=True, sharey=True)\n\n    for r in range(nrows):\n        for c in range(ncols):\n            ridx = rng.choice(range(df.shape[0]))\n            img_name = df.iloc[ridx]['image_id']\n\n            image = plt.imread(train_data_folder+img_name+'.jpg')\n\n            axs[r, c].imshow(image)\n            axs[r, c].axis('off')\n            \n    plt.suptitle('Wheat head images')\n    plt.show() ","65c3dd05":"# check a few random image to check the dataset.\nshow_images(train)","b924f3ba":"df_analysis=pd.DataFrame()\ndf_analysis['image_id']=train['image_id'].apply(lambda x: x+'.jpg')\n\n# extract the fields for use\nbbox = train.bbox.str.split(\",\",expand=True)\ndf_analysis['xmin'] = bbox[0].str.strip('[ ').astype(float)\ndf_analysis['ymin'] = bbox[1].str.strip(' ').astype(float)\ndf_analysis['xmax'] = bbox[2].str.strip(' ').astype(float)+df_analysis['xmin']\ndf_analysis['ymax'] = bbox[3].str.strip(' ]').astype(float)+df_analysis['ymin']\ndf_analysis['class']= 0\n\n# show the data frame\ndf_analysis.head()","4e554ab0":"# take random index\n# draw box on a random image\nseed = 42\nrng = np.random.RandomState(seed)","c812103a":"def show_images_with_box(df):\n    # print a few images together with box\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15), sharex=True, sharey=True)\n\n    for r in range(nrows):\n        for c in range(ncols):\n            ridx = rng.choice(range(df.shape[0]))\n            img_name = df.iloc[ridx]['image_id']\n      \n            image = plt.imread(train_data_folder+img_name)\n                        \n            # find all the records of the provided image and draw box on the wheat heads\n            chosen_image = df.loc[df[\"image_id\"]==img_name,[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n            bbox_array   = np.array(chosen_image.values.tolist())\n\n            for bbox in bbox_array:\n                image = cv2.rectangle(image, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color = (255,255,255), thickness=3) \n\n            axs[r, c].imshow(image)\n            axs[r, c].axis('off')\n            \n    plt.suptitle('Images with Box')\n    plt.show() ","3db2d110":"show_images_with_box(df_analysis)","c30a5253":"# lets plot images with high box counts (I am not stiching the boxes, as displaying them takes lot of time)\ndef show_images(se, start_idx, str_plot):\n    # print a few images from the provided Series\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+se.index[idx])\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"box_count=\"+str(se.iloc[idx])\n            axs[r, c].set_title(title)\n            \n            idx = idx+1\n    plt.suptitle(str_plot)","db13b289":"# lets see how the image box counts are ditributed.\nimg_freq=df_analysis['image_id'].value_counts()\nimg_freq[:10]","13a83d01":"n, bins, patches = plt.hist(x=img_freq, bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.grid(axis='y', alpha=0.75)\nplt.xlabel('Box Count')\nplt.ylabel('Frequency')\nplt.title('Image Box Distribution')\nplt.text(23, 45, r'$\\mu=15, b=3$')\nmaxfreq = n.max()\n# Set a clean upper y-axis limit.\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)","39abc727":"import seaborn as sns\n\nsns.set_style('darkgrid')\nsns.distplot(img_freq)","e542c889":"# lets plot images with high box counts (I am not drawing the boxes, as displaying them takes some time)\ndef show_images(se, start_idx, str_plot):\n    # print a few images from the provided Series\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+se.index[idx])\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"box_count=\"+str(se.iloc[idx])\n            axs[r, c].set_title(title)\n            \n            idx = idx+1\n    plt.suptitle(str_plot)\n    ","dfe3f6f3":"show_images(img_freq, start_idx=0, str_plot='Images with max box counts')","43036897":"show_images(img_freq, start_idx=(len(img_freq)-1-16), str_plot='Images with lowest box counts')","b14ffc4e":"box_width=(df_analysis['xmax']-df_analysis['xmin']).sort_values()\nbox_height=(df_analysis['ymax']-df_analysis['ymin']).sort_values()","db83c3a0":"box_width","4f3e973c":"# plot box width\nn, bins, patch = plt.hist(x=box_width, bins=50, color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.grid(axis='y', alpha=0.75)\nplt.xlabel('Box Width')\nplt.ylabel('Frequency')\nplt.title('Box Width Distribution')\nplt.text(23, 45, r'$\\mu=15, b=3$')\nmaxfreq = n.max()\n# Set a clean upper y-axis limit.\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)","e1224578":"sns.set_style('darkgrid')\nsns.distplot(box_width)","64d9ff88":"# plot box height\nn, bins, patch = plt.hist(x=box_height, bins=50, color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.grid(axis='y', alpha=0.75)\nplt.xlabel('Box Height')\nplt.ylabel('Frequency')\nplt.title('Box Height Distribution')\nplt.text(23, 45, r'$\\mu=15, b=3$')\nmaxfreq = n.max()\n# Set a clean upper y-axis limit.\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)","581a35af":"sns.set_style('darkgrid')\nsns.distplot(box_height)","e9638e2a":"df_analysis['width']=df_analysis['xmax']-df_analysis['xmin']\ndf_analysis['height']=df_analysis['ymax']-df_analysis['ymin']\n\ndf_analysis.sort_values(by='width', inplace=True)\ndf_analysis.reset_index(inplace = True, drop = True)","a9e9833f":"df_analysis.head()","20821481":"df_analysis.tail()","4c95fe74":"# function to print images with highest box width size. \ndef show_box_width(df, start_idx, str_plot):\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = plt.imread(train_data_folder+df.iloc[idx].image_id)\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"box width=\"+str(df.iloc[idx]['width'])\n            axs[r, c].set_title(title)\n                        \n            # find all the records of the provided image and draw box on the wheat heads\n            w, h, w1, h1 = df.iloc[idx][[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n         \n            img = cv2.rectangle(img, (int(w), int(h)), (int(w1), int(h1)), color = (255,255,255), thickness=3) \n\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            idx = idx+1\n    plt.suptitle(str_plot)","2a1c227b":"show_box_width(df_analysis, len(box_height)-16, 'Images with highest box width size')","dfd8226a":"show_box_width(df_analysis, 0, 'Images with lowest box width size')","f93affff":"# get image brightness using opencv\ndef get_image_brightness(img):\n    image = cv2.imread(img)\n    # convert to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n    # get average brightness\n    return int(np.array(gray).mean())","b498b915":"# create a data frame with unique image names\ndf_img=pd.DataFrame()\n\ndf_img['image']=df_analysis['image_id'].unique()","17def31d":"df_img['brightness'] = df_img['image'].apply(lambda x: get_image_brightness(train_data_folder+x))","249e2187":"df_img.sort_values(by='brightness', inplace=True)\ndf_img.reset_index(inplace = True, drop = True)\ndf_img.head()","cb38d62a":"df_img.tail()","1131f7e6":"# function to print images with highest box width size. \ndef show_image_brightness(df, start_idx, str_plot):\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+df.iloc[idx]['image'])\n            axs[r, c].imshow(img)\n            title=\"brightness=\"+str(df.iloc[idx]['brightness'])\n            axs[r, c].set_title(title)\n\n            axs[r, c].axis('off')\n            idx = idx+1\n    plt.suptitle(str_plot)","bd1bfa85":"show_image_brightness(df_img, df_img.shape[0]-16,'most brightest images')","c3471517":"show_image_brightness(df_img, 0,'most darkest images')","1e9feef9":"def get_percentage_of_green_pixels(img):\n    image = cv2.imread(img)\n    # convert to HSV\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    \n    # get the green mask\n    hsv_lower = (40, 40, 40) \n    hsv_higher = (70, 255, 255)\n    green_mask = cv2.inRange(hsv, hsv_lower, hsv_higher)\n    \n    return round(float(np.sum(green_mask)) \/ 255 \/ (1024 * 1024), 2)","14c3f0cc":"# function to show images with highest box width size. \ndef show_images_green_pixels(df, start_idx, str_plot):\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+df.iloc[idx]['image'])\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"green pix=\"+str(df.iloc[idx]['green'])\n            axs[r, c].set_title(title)\n\n            axs[r, c].axis('off')\n            idx = idx+1\n    plt.suptitle(str_plot)","b844cdcb":"df_img['green'] = df_img['image'].apply(lambda x: get_percentage_of_green_pixels(train_data_folder+x))","0795698d":"df_img.sort_values(by='green', inplace=True)\ndf_img.reset_index(inplace = True, drop = True)\ndf_img.head()","969caa24":"df_img.tail()","91f5cec3":"sns.set_style('darkgrid')\nsns.distplot(df_img['green'])","f5a81d42":"# display the greenest images\nshow_images_green_pixels(df_img, df_img.shape[0]-16,'most green images')","cddd7067":"# display the less green(yellow) images\nshow_images_green_pixels(df_img, 0,'most yellow images')","d8d506f6":"test_data=[]\nfor root, dirs, files in os.walk(test_data_folder):\n    for file in files:\n        test_data.append(file)","a95776e7":"print('test data count: {}'.format(len(test_data)))","c3d8aa1c":"# display test data\ndef show_test_data(tdata):\n    nrows=2\n    ncols=5\n    fig, axs = plt.subplots(nrows, ncols, figsize=(20, 8), squeeze=False)\n    idx = 0\n    \n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(test_data_folder+tdata[idx])\n            axs[r, c].imshow(img)\n            \n            axs[r, c].axis('off')\n            \n            idx = idx+1\n            \n    plt.suptitle(\"Test data\")","894a5bbd":"show_test_data(test_data)","0f468e75":"# check the GPU details\n!nvidia-smi","3f822c63":"# creating a model using retinanet\n#!keras_retinanet\/bin\/train.py --random-transform --gpu 0 --weights {PRETRAINED_MODEL} --lr {LR} --batch-size {BATCH_SIZE} --steps {STEPS} --epochs {EPOCHS} csv out_final.csv classes.csv\n# this will create resnet50_csv_02.h5 as an output model.","3cf86556":"# using a pre trained retinanet model first to try\nmodel = models.load_model(\"\/kaggle\/input\/retinanet-model1\/resnet50_csv_02.h5\", backbone_name='resnet50')\nmodel = models.convert_model(model)","50eba6de":"def predict(image):\n    image = preprocess_image(image.copy())\n    #image, scale = resize_image(image)\n\n    boxes, scores, labels = model.predict_on_batch(\n    np.expand_dims(image, axis=0)\n  )\n\n    #boxes \/= scale\n\n    return boxes, scores, labels","1a6336a6":"THRES_SCORE = 0.55\n\ndef draw_detections(image, boxes, scores, labels):\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n        if score < THRES_SCORE:\n            break\n\n        color = label_color(label)\n\n        b = box.astype(int)\n        draw_box(image, b, color=color)\n\n        caption = \"{:.3f}\".format(score)\n        draw_caption(image, b, caption)","90c5fcf4":"def show_detected_objects(image_name):\n    img_path = test_data_folder+'\/'+image_name\n  \n    image = read_image_bgr(img_path)\n    #image = cv2.imread(img_path)\n\n    boxes, scores, labels = predict(image)\n    \n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    draw_detections(draw, boxes, scores, labels)\n    plt.figure(figsize=(8,6))\n    plt.axis('off')\n    plt.imshow(draw)\n    plt.show()","418ce009":"for img in test_data:\n    show_detected_objects(img)","15951fb4":"preds=[]\nimgid=[]\nfor img in test_data:\n    img_path = test_data_folder+'\/'+img\n    image = read_image_bgr(img_path)\n    boxes, scores, labels = predict(image)\n    boxes=boxes[0]\n    scores=scores[0]\n    for idx in range(boxes.shape[0]):\n        if scores[idx]>THRES_SCORE:\n            box,score=boxes[idx],scores[idx]\n            imgid.append(img.split(\".\")[0])\n            preds.append(\"{} {} {} {} {}\".format(score, int(box[0]), int(box[1]), int(box[2]-box[0]), int(box[3]-box[1])))\n    ","0a77c189":"sub={\"image_id\":imgid, \"PredictionString\":preds}\nsub=pd.DataFrame(sub)\nsub.head()","7a077e3d":"sub_=sub.groupby([\"image_id\"])['PredictionString'].apply(lambda x: ' '.join(x)).reset_index()\nsub_","bd3af509":"samsub=pd.read_csv(\"\/kaggle\/input\/global-wheat-detection\/sample_submission.csv\")\nsamsub.head()","fd44407c":"for idx,imgid in enumerate(samsub['image_id']):\n    samsub.iloc[idx,1]=sub_[sub_['image_id']==imgid].values[0,1]\n    \nsamsub.head()","ebf0042a":"samsub.to_csv('\/kaggle\/working\/submission.csv',index=False)","bbef4250":"**In this kernel first I will explore the data sets to understand the data in details to find its hidden features (EDA) of this wheat image data set.**","5454414a":"**Many of the images are too dark to be analyzed, so there brightness need to be increased.**","31c5e656":"**lets create a new data frame with the required fields in a usable manner for EDA\n**","f481bd1f":"**So most of the images are having box count in range 10 to 80.**","d92d0caa":"**Check Box height distribution**","9c165bb9":"Analysis of images w.r.t green and yellow (mature) wheat heads.","1ae584cc":"**Need to make a object detection model using keras RetinaNet **","79ad056f":"# **Load Dataset**","3cee3b5d":"From the above images its clear that w.r.t the Box width values few of the boxes are valid and few are covering multiple heads.\nSo this needs an correction in the image source.","9f234c83":"Most of the box above does not cover any wheat head. So here we can actually ignore this boxes.","ca5cc5cb":"**Data Augmentataion need to be implemented, because **\n- image count is less\n- many images are too dark \n- few images are too bright.","7d6a3824":"**TBD:\nFrom the above detection its clear that source images needs augmentation, such that model can be more robust.\nBecause there are many miss classification\/prediction for the wheat heads.**\n","8c77888c":"**This data set contains the image names, image shape, bbox (xmin, ymin, width, height) as the location of every wheat head sqaure.**","b8c288ae":"# Exploring the wheat head count distribution in the data set ","1d579686":"** Exploring the Box size's to get some understanding of its accuracy and distribution **","636bb82b":"This shows that there is a large percentage of image's in this data set are in the mature state.","8aef3f27":"**Explore the Dark and Bright images**","4f00a77d":"**check if all the image Width & Height values are the same**","16cd7370":"**Check the test data**","bc68af88":"Lets draw the box around the wheat heads to visualize and validate the data.","ccded78e":"After going over the images it's visible that there are various kind of images present in this data set.\n* few images are having many wheat heads and few are very less or no heads.\n* some of the images are taken in dark and some images are taken in a very high lighting condition. \n* there are images of green wheat heads and yellow heads (mature).\n\n** will explore the data more now with visualizatiin **","07215260":"Use retinanet for creating model for object detection ","80010091":"If you like this kernel please upvote. \nI have learned from various exsting kernels, perticularly https:\/\/www.kaggle.com\/aleksandradeis\/globalwheatdetection-eda, please upvote this also.","59e8db1b":"**Lets understand the image box count distribution**","1c5192b9":"From the log its visible that one image '35b935b6c.jpg' is having max 116 boxes and in the lower side few are only having one box."}}