{"cell_type":{"6fa6c755":"code","0619a4ac":"code","2ece16b7":"code","47918ede":"code","63ebf5d5":"code","c8af8b48":"code","e095d8cd":"code","293b1c31":"code","eee57501":"code","0a160d6a":"code","a26e3359":"code","475630ce":"code","cecfa279":"code","3dc3267c":"code","9a645612":"code","92fcc0d6":"code","2a410072":"code","54a34a21":"code","4de9d680":"code","5a1375cf":"code","316fb050":"code","34d07eef":"code","9350ae35":"code","39aa4618":"code","af9d935a":"code","2f645e8a":"code","a60eb4ad":"code","978bd6dc":"code","a781e949":"code","6793ad0f":"code","5f075520":"code","7db67a9a":"code","538f23fc":"code","3c5b0035":"code","2f1c1d56":"code","184ac757":"code","fded682c":"code","4486044b":"code","e7e3adc3":"code","ed01d29f":"code","a776acd6":"code","f8fc7fe9":"code","d1e8d35f":"code","7b78f018":"code","d82319ad":"code","b5f94327":"code","5f337b24":"code","445c0404":"code","94a8bf07":"code","c3178a63":"code","9dd21231":"code","5eef2a85":"code","6e9f49c2":"code","c3ef87f0":"code","feb8bbba":"code","ce67ed2f":"code","388fb00c":"code","653a8e55":"code","bc089767":"markdown","12ef7e28":"markdown","ce380d78":"markdown","88510b6a":"markdown","c84e432e":"markdown","a6127287":"markdown","ca89b89f":"markdown","a741261b":"markdown","c2499e6f":"markdown","f1a46e24":"markdown","b426f570":"markdown","1b8db97d":"markdown","0ec8c428":"markdown","d4a3ef2f":"markdown","afc739f1":"markdown","56c8a6da":"markdown","a24e823d":"markdown","da330d16":"markdown","f63bf92b":"markdown"},"source":{"6fa6c755":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0619a4ac":"import warnings\nwarnings.filterwarnings('ignore')","2ece16b7":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-mar-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv\")","47918ede":"train","63ebf5d5":"test","c8af8b48":"train_copy = train.copy()\ntest_copy = test.copy()","e095d8cd":"train.drop(['id'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)","293b1c31":"import seaborn as sns\nimport matplotlib.pyplot as plt","eee57501":"catcols = [col for col in train.columns if col.startswith('cat')]\ncontcols = [col for col in train.columns if col.startswith('cont')]","0a160d6a":"for col in catcols:\n    plt.title(f'Count plot of {col}')\n    sns.countplot(train[col])\n    plt.show()","a26e3359":"for col in contcols:\n    plt.title(f'Distplot of {col}')\n    sns.distplot(train[col])\n    plt.show()","475630ce":"sns.countplot(train['target'])","cecfa279":"train.isnull().sum().any()","3dc3267c":"test.isnull().sum().any()","9a645612":"from sklearn.preprocessing import LabelEncoder","92fcc0d6":"cols_ca = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat11', 'cat12',\n          'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']","2a410072":"le = LabelEncoder()\n\nfor col in cols_ca:\n    train[col] = le.fit_transform(train[col])\n    test[col] = le.transform(test[col])","54a34a21":"le_1 = LabelEncoder()\n\ntrain['cat10'] = le_1.fit_transform(train['cat10'])\ntest['cat10'] = le_1.fit_transform(test['cat10'])","4de9d680":"corr = train.corr()\nplt.figure(figsize=(25,25))\nsns.heatmap(corr, annot=True, cmap='coolwarm', square=True)\nplt.show()","5a1375cf":"train_ = train.copy()\ntest_ = test.copy()","316fb050":"len(train_.columns)","34d07eef":"x_train_ = train_.drop('target', axis=1)\nx_test_ = test_","9350ae35":"def correlation(dataset, threshold):\n    col_corr = set() # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n                colname = corr_matrix.columns[i] # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    del dataset[colname] # deleting the column from the dataset\n    return dataset","39aa4618":"x_train = correlation(x_train_, 0.4)\nx_test = correlation(x_test_, 0.4)","af9d935a":"x_train = pd.DataFrame(x_train, columns=x_train_.columns)\nx_test = pd.DataFrame(x_test, columns=x_test_.columns)\n\ny_train = pd.DataFrame(train['target'], columns=['target'])","2f645e8a":"print(len(x_train.columns)) ","a60eb4ad":"x_train.columns","978bd6dc":"x_test.columns","a781e949":"sns.countplot(y_train['target'])","6793ad0f":"from imblearn.over_sampling import SMOTE","5f075520":"smote = SMOTE()\n\nx_train, y_train = smote.fit_resample(x_train, y_train)","7db67a9a":"sns.countplot(y_train['target'])","538f23fc":"from sklearn.model_selection import train_test_split","3c5b0035":"x_train_, x_val, y_train_, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=56)","2f1c1d56":"from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier","184ac757":"from sklearn.metrics import classification_report, roc_auc_score, f1_score","fded682c":"def model_selection(x_train_, x_val, y_train_, y_val, model):\n  model = model()\n  model.fit(x_train_, y_train_)\n\n  pred = model.predict(x_val)\n\n  f1 = f1_score(y_val, pred)\n  roc = roc_auc_score(y_val, pred)\n  report = classification_report(y_val, pred)\n  train_score = model.score(x_train_, y_train_)\n  val_score = model.score(x_val, y_val)\n\n  print('F1 Score:', f1)\n  print('\\n')\n  print('ROC AUC Score:', roc)\n  print('\\n')\n  print('Classification report:', report)\n  print('\\n')\n  print('Train Score:', train_score*100)\n  print('\\n')\n  print('Val Score:', val_score*100)\n  print('\\n')\n  print('Is overfitting:', True if train_score>val_score else False)\n  print('\\n')\n  print('Overfitting by:',train_score*100-val_score*100)","4486044b":"extratrees = model_selection(x_train_, x_val, y_train_, y_val, ExtraTreesClassifier)\nextratrees","e7e3adc3":"gradient = model_selection(x_train_, x_val, y_train_, y_val, GradientBoostingClassifier)\ngradient","ed01d29f":"random = model_selection(x_train_, x_val, y_train_, y_val, RandomForestClassifier)\nrandom","a776acd6":"xgb = model_selection(x_train_, x_val, y_train_, y_val, XGBClassifier)\nxgb","f8fc7fe9":"lgbm = model_selection(x_train_, x_val, y_train_, y_val, LGBMClassifier)\nlgbm","d1e8d35f":"logistic = model_selection(x_train_, x_val, y_train_, y_val, LogisticRegression)\nlogistic","7b78f018":"catboost = model_selection(x_train_, x_val, y_train_, y_val, CatBoostClassifier)\ncatboost","d82319ad":"ridge = model_selection(x_train_, x_val, y_train_, y_val, RidgeClassifier)\nridge","b5f94327":"sgd = model_selection(x_train_, x_val, y_train_, y_val, SGDClassifier)\nsgd","5f337b24":"from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold","445c0404":"from scipy.stats import uniform as sp_randFloat\nfrom scipy.stats import randint as sp_randInt","94a8bf07":"model = CatBoostClassifier()","c3178a63":"parameters = {'depth'         : sp_randInt(4, 10),\n              'learning_rate' : sp_randFloat(),\n              'iterations'    : sp_randInt(100, 1000)\n              }","9dd21231":"cv = StratifiedKFold(n_splits=5)","5eef2a85":"search = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n                               cv = cv, n_iter = 10, n_jobs=-1)\n\nsearch.fit(x_train, y_train)","6e9f49c2":"print('Best Params:', search.best_params_)\nprint('\\n')\nprint('Best Score:', search.best_score_)","c3ef87f0":"model = CatBoostClassifier(depth=7, iterations=1000, learning_rate=0.49811995148302424)\nmodel.fit(x_train, y_train)","feb8bbba":"pred = model.predict(x_test)\npred","ce67ed2f":"sample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsample","388fb00c":"Submission = pd.DataFrame({'id':test_copy['id'], 'target':pred})\nSubmission","653a8e55":"Submission.to_csv('\/kaggle\/working\/Submission.csv')","bc089767":"# Saving the submission file","12ef7e28":"there is some imbalance in the data lets fix this using SMOTE","ce380d78":"lets encode categorical data to numeric data","88510b6a":"# Hyper parameter tuning","c84e432e":"as we can see from the corr plot, there are many features with high correlation lets remove them","a6127287":"now our data is balanced","ca89b89f":"dropping the id-columns","a741261b":"# Model Building and Training","c2499e6f":"lets check for null values","f1a46e24":"feature imbalance","b426f570":"# Splitting training data into training and validation sets","1b8db97d":"# Predictions","0ec8c428":"# Saving a copy of the datsets","d4a3ef2f":"# **Loading the datasets**","afc739f1":"# **EDA**","56c8a6da":"I will use CatBoostClassifier because it has a good f1 and auc score and the overfitting rate is low","a24e823d":"checking feature correlation","da330d16":"# **Data Processing**","f63bf92b":"# Model Selection"}}