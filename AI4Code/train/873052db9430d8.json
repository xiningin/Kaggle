{"cell_type":{"350489a6":"code","696b4c7d":"code","bffcaaac":"code","449bdc11":"code","040c2709":"code","49da031f":"code","91e496bc":"code","6f9286c3":"code","dd28330d":"code","00b3e09c":"code","0e076ea1":"code","b21129a7":"code","b0dda16d":"code","5482b727":"code","88f3478b":"code","25651765":"code","03c58ca2":"code","9301d776":"code","915c31fc":"code","f2295eb7":"code","2b69d5cf":"code","51504edc":"code","4dd3b557":"code","7d45e446":"code","f446401c":"code","df7098dc":"code","4e631bfc":"code","db28879a":"code","5e4f469a":"code","43ce0acb":"code","dc4e6ce4":"code","1280aa89":"code","93f0b58d":"code","6c85428a":"code","363d1b8c":"code","703fa6d3":"code","7b4c6b29":"code","10801436":"code","fb9208de":"code","dacaa484":"code","b1be4453":"code","b8df75d1":"code","7e646b8e":"code","889428ea":"code","c160df64":"code","cc6b5bb7":"code","37293f15":"code","37ea924d":"code","afee1b63":"code","e34e65b7":"code","c8921ab3":"code","15330b1a":"code","5e1498e6":"code","7f74189d":"code","4c106910":"code","6801dbf7":"code","0a0337ae":"code","707f8e97":"code","493ea0a5":"code","00f89eca":"code","8013cee0":"code","57f3075d":"code","ab2738b8":"code","43e45be0":"code","358105bc":"code","64cd9741":"code","0ee0125b":"code","0d0c1f29":"code","1198ac26":"code","63742448":"code","62ce9800":"code","39b28c0e":"code","2036228f":"code","2d65dac6":"code","4b94e86b":"code","9471e27b":"code","21955a27":"markdown","d016e525":"markdown","c30e8a9b":"markdown","4ac9130e":"markdown","9e073463":"markdown","9dca1e47":"markdown","7854cb44":"markdown","b789b4e1":"markdown","c1e61769":"markdown","a07422f4":"markdown","5b15fd68":"markdown","d408a882":"markdown","2739f5d2":"markdown","5b625c0c":"markdown","a2753423":"markdown","d62be459":"markdown","5e045dcd":"markdown","4fb13407":"markdown","e78995a7":"markdown","6d614432":"markdown","c7e4f2ec":"markdown","1e88d21c":"markdown","f4295d89":"markdown","d3961fe1":"markdown","840a9cc7":"markdown","a15d030d":"markdown","e3b3cfd6":"markdown","ad708a53":"markdown","aebb0a9f":"markdown","4114de50":"markdown","3d675de1":"markdown","f41b65af":"markdown","87eb4681":"markdown","4ec5d1fb":"markdown"},"source":{"350489a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","696b4c7d":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","bffcaaac":"hour = pd.read_csv(\"\/kaggle\/input\/rental-bike-sharing\/hour.csv\")\nday = pd.read_csv(\"\/kaggle\/input\/rental-bike-sharing\/day.csv\")","449bdc11":"hour.head()","040c2709":"day.head()","49da031f":"print(\"Shape of hour data: {}\".format(hour.shape))\nprint(\"Shape of Day data: {}\".format(day.shape))","91e496bc":"hour_features = hour.drop(\"cnt\", axis = 1).columns\nhour_features","6f9286c3":"# Data types\nhour.dtypes","dd28330d":"print(hour[\"yr\"].value_counts())\nprint(hour[\"season\"].value_counts())","00b3e09c":"from datetime import datetime\nfrom dateutil import parser","0e076ea1":"# Missing values\nplt.figure(figsize = (8,6))\nhour.isna().sum().plot() # NO missing Values\nplt.title(\"Missing Values\")\nplt.show()","b21129a7":"hour.head()","b0dda16d":"hour[\"registered\"].min(), hour[\"registered\"].max(),","5482b727":"# Let us take a look at the Regsitered count targets distribution\nhour.groupby(pd.cut(hour[\"registered\"], bins = range(0,1000,50)))[\"registered\"].count().hist()","88f3478b":"# BEfore moving on let us create the Test dataset\nhour.shape\n\nfrom sklearn.model_selection import train_test_split\ntrain_hour, test_hour = train_test_split(hour, test_size = 0.2, random_state = 12)\n\ntrain_hour.shape, test_hour.shape","25651765":"# Using Train set for further analysis\ntrain_hour.head()","03c58ca2":"def hour_transformer(x):\n    if x >=4 and x <=7:\n        return \"Early_Morning\"\n    elif x>=8 and x<=12:\n        return \"Morning\"\n    elif x >= 13 and x <=16:\n        return \"Afternoon\" \n    elif x >=17 and x <=20:\n        return \"Evening\"\n    elif x>=21 or x <=3:\n        return \"Night\"\n","9301d776":"## Transformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n\nclass dataset_transformer(BaseEstimator, TransformerMixin):\n    def __init__(self, transform_cols = 1, drop_cols = 1, transform_season = 1, tranform_weathersit = 1, transform_weekday = 1, add_hour_of_day = 1, drop_originals = 0):\n        self.transform_cols = transform_cols\n        self.drop_cols = drop_cols\n        self.transform_season = transform_season\n        self.transform_weathersit = tranform_weathersit\n        self.transform_weekday = transform_weekday\n        self.add_hour_of_day = add_hour_of_day\n        self.drop_originals = drop_originals\n        return None\n    def fit(self, X, y = None):\n        return self\n    def transform(self, X, y = None):\n        transformed_df = X.copy()\n        if self.transform_cols:\n                if self.drop_cols:\n                    transformed_df.drop(\"instant\", axis = 1, inplace = True)\n                if self.transform_season:\n                    transformed_df[\"season_tr\"] = transformed_df[\"season\"].map({1:'winter', 2:'summer', 3:'spring', 4:'fall'})\n                if self.transform_weathersit:\n                    transformed_df[\"weathersit_tr\"] = transformed_df[\"weathersit\"].map({1:'Clear', 2:'Mist', 3:'Light_Snow', 4:'Heavy_Rain'})\n                if self.transform_weekday:\n                    transformed_df[\"weekday_tr\"] =  transformed_df[\"weekday\"].transform(lambda x: 0 if (x == 0 or x == 6) else 1)\n                if self.add_hour_of_day:\n                    transformed_df[\"hour_of_day_tr\"] = transformed_df[\"hr\"].transform(lambda x: hour_transformer(x))\n                if self.drop_originals:\n                    transformed_df.drop([\"season\", \"weathersit\", \"weekday\", \"hr\"], axis = 1, inplace = True)\n        return transformed_df\n\n    \n        ","915c31fc":"col_trans = dataset_transformer(drop_originals = 1)\ntrain_hour_tr = col_trans.transform(train_hour)\ntrain_hour_tr.head()","f2295eb7":"# Looking at the summary stats\ntrain_hour_tr.describe()\nprint(\"The average registered count of the training dataset %.0f\" %(train_hour_tr[\"registered\"].mean()))\nprint(\"The average registered count of the Testing dataset %.0f\" %(test_hour_tr[\"registered\"].mean()))","2b69d5cf":"# Check if the holiday represents the weekdays and weekends \npd.crosstab(train_hour_tr[\"holiday\"],train_hour_tr[\"weekday_tr\"])","51504edc":"# Registered count in weekdays and weekends\nplt.title(\"Registrations on weekdays vs weekends\")\nax = sns.barplot(x = \"weekday_tr\", y = \"registered\", data = train_hour_tr)\nax.set_xticklabels({'Weekend':0, 'Weekday':1}.keys())\nplt.show()","4dd3b557":"# We will use MannWhitneyU test to see if the registrations change with the weekday or weekend\n# Even though MannWhitneyU test does not expect the dependent variable to be normally distributed, let us still go ahead and check if it is normally distributed.\nsns.displot(data = train_hour_tr, x = \"registered\", hue = \"weekday_tr\", kind = 'kde', legend = False)\nplt.xlabel(\"Registrations\")\nplt.legend({\"Weekend\":0, \"Weekday\":1}.keys())\nplt.show()","7d45e446":"# CHecking for Skewness of values\nfrom scipy.stats import skewtest, skew\nfor i in train_hour_tr[[\"temp\", \"atemp\", \"registered\", \"casual\"]].columns:\n    print(i,':', skewtest(train_hour_tr[i]).pvalue, ['Skewed' if skewtest(train_hour_tr[i]).pvalue <= 0.05 else 'Normal'])\nprint(\"**********************************************\")\nfor i in train_hour_tr[[\"temp\", \"atemp\", \"registered\", \"casual\"]].columns:\n    print(i,':', skew(train_hour_tr[i]))\n    \n# H0 - This function tests the null hypothesis that the skewness of the population that the sample was drawn from is the same as that of a corresponding normal distribution.","f446401c":"hour_df = train_hour_tr[[\"registered\"]].copy()\nhour_df[\"registered_norm\"] = np.sqrt(hour_df[\"registered\"])\nhour_df","df7098dc":"sns.displot(data = hour_df, x = \"registered_norm\", kind = \"kde\")\nplt.show()","4e631bfc":"train_hour_tr[\"registered_norm\"] = hour_df[\"registered_norm\"].copy()\ntrain_hour_tr","db28879a":"sns.displot(data = train_hour_tr, x = \"registered_norm\", hue = \"weekday_tr\", kind = 'kde', legend = False)\nplt.xlabel(\"Registrations\")\nplt.legend({\"Weekend\":0, \"Weekday\":1}.keys())\nplt.show()","5e4f469a":"from scipy.stats import mannwhitneyu\n_, pval = mannwhitneyu(train_hour_tr[train_hour_tr.weekday_tr == 0][\"registered\"], train_hour_tr[train_hour_tr.weekday_tr == 1][\"registered\"])\nprint(\"p-value of test is %.4f. Hence, the null hypo is %s.\" %(pval, 'rejected' if pval <=0.05 else 'not rejected'))\n#The Mann-Whitney U test is a nonparametric test of the null hypothesis that the distribution underlying sample x is the same as the distribution underlying sample y. It is often used as a test of of difference in location between distributions.","43ce0acb":"train_hour_tr.head()","dc4e6ce4":"sns.barplot(data = train_hour_tr, x = \"holiday\", y = 'registered', hue = 'workingday')\nplt.show()","1280aa89":"train_hour_tr.groupby(['holiday', 'workingday',\"weekday_tr\"])[\"registered\"].count()","93f0b58d":"sns.barplot(data = train_hour_tr, x = 'hour_of_day_tr', y = 'registered', hue = 'weekday_tr')\nplt.title(\"Registrations by Hour of day\")\nplt.show()","6c85428a":"plt.figure(figsize  = (20,8))\nax1 = plt.subplot(211)\nsns.regplot(data = train_hour_tr, x = train_hour_tr['atemp'], y = 'registered', marker = 'o', scatter_kws={'color':'y'},line_kws={'color':'r'})\nax2 = plt.subplot(212)\nsns.scatterplot(data = train_hour_tr, x = train_hour_tr['atemp'], y = 'hour_of_day_tr', hue = train_hour_tr['registered'], size = train_hour_tr['registered'])\n# plt.title(\"Registration by feeling temperature\")\nplt.show()","363d1b8c":"train_hour_tr.head()","703fa6d3":"sns.barplot(data = train_hour_tr, x = 'weathersit_tr', y  = 'registered')\nplt.show()","7b4c6b29":"train_hour_tr[[\"weathersit_tr\",'registered']].groupby([\"weathersit_tr\"]).agg(['min',\"max\",\"mean\"])","10801436":"# Encoding categorical values\ntrain_hour_tr_encoded = pd.get_dummies(train_hour_tr.drop('dteday', axis = 1), drop_first= True)\ntrain_hour_tr_encoded.head()","fb9208de":"train_hour_tr_encoded.columns.to_list()","dacaa484":"cat_cols = [\"holiday\",\"workingday\",'weekday_tr',\n 'season_tr_spring',\n 'season_tr_summer',\n 'season_tr_winter',\n 'weathersit_tr_Heavy_Rain',\n 'weathersit_tr_Light_Snow',\n 'weathersit_tr_Mist',\n 'hour_of_day_tr_Early_Morning',\n 'hour_of_day_tr_Evening',\n 'hour_of_day_tr_Morning',\n 'hour_of_day_tr_Night']\n","b1be4453":"# Checking the MannWhitneyU test p-values for each categorical column\nfor i in cat_cols:\n    _,pval = mannwhitneyu(train_hour_tr_encoded[train_hour_tr_encoded[i] == 0][\"registered\"], train_hour_tr_encoded[train_hour_tr_encoded[i] == 1][\"registered\"])\n    print(\"p-value for field :%s is %.3f, null hyp %s\" %(i, pval, 'rejected' if pval<=0.05 else 'not rejected'))","b8df75d1":"train_hour_tr_encoded = train_hour_tr_encoded.drop(['yr', 'mnth'], axis = 1)\nnum_cols = ['temp', 'atemp', 'hum', 'windspeed', 'registered']","7e646b8e":"train_hour_tr_num = train_hour_tr_encoded[num_cols].copy()\ntrain_hour_tr_num","889428ea":"# Corelations matrix for data\nplt.figure(figsize = (8,6))\nsns.heatmap(train_hour_tr_encoded[num_cols].corr(method = 'spearman'), annot = True, cmap = 'RdYlGn') # Spearmann since,the target variable is not normally distributed\nplt.show()","c160df64":"from statsmodels.api import OLS\nmodel = OLS(train_hour_tr_encoded[\"registered\"], train_hour_tr_encoded.drop([\"registered\", 'cnt', 'casual', 'registered_norm'],axis =1))\nres = model.fit()\nprint(res.summary())","cc6b5bb7":"col_list  = ['temp', 'hum']\n\nmodel = OLS(train_hour_tr_encoded[\"registered\"], train_hour_tr_encoded.drop([\"registered\", 'cnt', 'casual', 'registered_norm'],axis =1)[col_list])\nres = model.fit()\nprint(res.summary())","37293f15":"from sklearn.ensemble import ExtraTreesRegressor\netr = ExtraTreesRegressor(random_state = 23)\n\ntrain_hour_tr_encoded.head()\n\nX = train_hour_tr_encoded.drop([\"casual\", \"registered\", \"cnt\",\"registered_norm\",\"atemp\"], axis = 1)\ny = train_hour_tr_encoded[\"registered\"]","37ea924d":"etr.fit(X,y)\nfeat_imp = pd.Series(etr.feature_importances_, index= list(X.columns))\nfeat_imp.nlargest(10).plot(kind ='bar')\nplt.show()","afee1b63":"feat_imp.nlargest(10)","e34e65b7":"import eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.ensemble import RandomForestRegressor","c8921ab3":"X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.2)\nmodel = RandomForestRegressor(random_state  = 23).fit(X_train, y_train)\nperm = PermutationImportance(model, random_state = 23).fit(X_val,y_val)\n\neli5.show_weights(perm,feature_names = X_val.columns.to_list())","15330b1a":"features = [\"hour_of_day_tr_Evening\", \"temp\", \"hour_of_day_tr_Night\",\"hour_of_day_tr_Early_Morning\", \"hum\", \"workingday\", \"windspeed\"]","5e1498e6":"X_sel = X[features]","7f74189d":"X_train, X_val, y_train, y_val = train_test_split(X_sel, y, test_size = 0.2, random_state = 23)","4c106910":"# Linear Regressor\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nlr.coef_, lr.intercept_","6801dbf7":"y_train_pred = lr.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nerr = np.sqrt(mean_squared_error(y_train_pred, y_train))\nprint(\"Training error : %.3f\" %(err))","0a0337ae":"sns.displot((y_train - y_train_pred))\nplt.show()","707f8e97":"sns.scatterplot(x = y_train_pred, y =  y_train)\nplt.show()","493ea0a5":"# lets us check the error in Validation set\ny_val_pred_lr = lr.predict(X_val)\nerr = np.sqrt(mean_squared_error(y_val, y_val_pred_lr))\nprint(\"Validation error : %.3f\" %(err))","00f89eca":"sns.displot((y_val - y_val_pred_lr))\nplt.show()","8013cee0":"sns.scatterplot(x = y_val_pred_lr, y =  y_val)\nplt.show()","57f3075d":"## Random Forest Regressor\nrf = RandomForestRegressor()\nrf.fit(X_train, y_train)\n\ny_train_pred_rf = rf.predict(X_train)\nerr = np.sqrt(mean_squared_error(y_train_pred_rf, y_train))\nprint(\"Training error : %.3f\" %(err))","ab2738b8":"sns.displot(y_train - y_train_pred_rf)\nplt.show()","43e45be0":"y_val_pred_rf = rf.predict(X_val)\nerr = np.sqrt(mean_squared_error(y_val_pred_rf, y_val))\nprint(\"Validation error : %.3f\" %(err))","358105bc":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV","64cd9741":"# Tuning Random Forest\nrf.get_params()\n\nparam_grid = [{\"max_depth\": range(5,45,5),\n               \"min_samples_split\": range(10,210, 10),\n               \"n_estimators\": range(100,1010,10),\n              \"bootstrap\": [True, False]}]\n\nrSearch = RandomizedSearchCV(rf, param_grid, cv = 5, scoring = 'neg_mean_squared_error', n_jobs =-1, verbose = 2)\nrSearch.fit(X_train, y_train)","0ee0125b":"for param,result in zip(rSearch.cv_results_[\"params\"], rSearch.cv_results_[\"mean_test_score\"]):\n    print(param, np.sqrt(-result))","0d0c1f29":"rSearch.best_estimator_, np.sqrt(-rSearch.best_score_)","1198ac26":"final_model = rSearch.best_estimator_\nfinal_model.fit(X_train, y_train)\n\ny_train_pred = final_model.predict(X_train)\ntr_err = np.sqrt(mean_squared_error(y_train, y_train_pred))\nprint(\"Training Error after tuning :  %.3f\" %(tr_err))","63742448":"y_val_pred_rf = final_model.predict(X_val)\nval_err = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\nprint(\"Validation Error after tuning:  %.3f\" %(val_err))","62ce9800":"# Performance on Test \ntest_hour.head()","39b28c0e":"test_hour_tr = col_trans.transform(test_hour)\ntest_hour_tr_encoded = pd.get_dummies(test_hour_tr.drop('dteday', axis = 1), drop_first= True)\ntest_hour_fin = test_hour_tr_encoded.drop([\"casual\", \"registered\", \"cnt\",\"atemp\"], axis = 1)\ny_test = test_hour_tr_encoded[\"registered\"]","2036228f":"X_test = test_hour_fin[features]\nX_test.head()","2d65dac6":"y_test_pred = final_model.predict(X_test)\n\ntest_err = np.sqrt(mean_squared_error(y_test, y_test_pred))\n\nprint(\"Testing error: %.3f\" %(test_err))","4b94e86b":"sns.displot( y_test - y_test_pred)\nplt.show()","9471e27b":"# Standard error of mean\nfrom scipy import stats\nconf = 0.95 \nsq_errs = (y_test  - y_test_pred) ** 2\ndof = len(sq_errs)-1\nmean_of_sq_errors = sq_errs.mean()\nstandard_error_of_mean = stats.sem(sq_errs) # Standard_Dev\/sq.root of sample size\n\n#The confidence Interval of the error\nnp.sqrt(stats.t.interval(conf, dof, loc = mean_of_sq_errors, scale = standard_error_of_mean))","21955a27":"There are more registrations on the weekdays than on the weekends. One reason could be is may be people rely on bikes for daily workplace commute.","d016e525":"## Data Transformation","c30e8a9b":"The resgitrations are more when the weather is clear or there is misty. However, it is highly unpredictable when it rains though.","4ac9130e":"## Importing Libraries","9e073463":"The non-holiday days have more bookings. This also provides some evidence that the people mostly rely on the bikes for daily commute to workplace. The Weekday\/Weekend relationship with the registrations also signified so.","9dca1e47":"Data is not normally distributed. So, let us transform the data.","7854cb44":"### Feature Selection","b789b4e1":"We will confirm this relation by checking the correlation coefficient for continuous variables","c1e61769":"The Linear regression scores does not vary much between training and validation set. Lets explore other models ","a07422f4":"***Even though the dependent variable is not normally distributued, the Mann-whitneyU test does not require the target to be normally ditributed.***","5b15fd68":"### Testing for hypothesis, does the registered counts change with weekdays","d408a882":"### Registrations by weather","2739f5d2":"The weekends do not count as holidays. However, there are 412 weekday holidays in the 2 years","5b625c0c":"## Data Loading","a2753423":"#### Holidays vs Registrations","d62be459":"The Random forest is overfitting the data. However, the validation score is still better than the Linear Regression","5e045dcd":"The errors or residuals are normally distributed","4fb13407":"Hence, there is indeed a difference in the registered counts between weekdays and weekends","e78995a7":"**Ideas**\n1. Divide hour of day into 5 categories \n* Early Morning - 4th hour to 7th hour \n* Morning - 8th hour to 12th hour\n* Afternoon - 13th hour to 16th hour\n* Evening - 17th hour to 20th hour\n* Night - 21st hour to 3rd hour\n\n2. Divide Weekday - Weekday or Weekend\n3. Season, Weather Sit - Change it to OHE as the it is not an ordinal data\n","6d614432":"The default assumption or null hypothesis is that there is no difference between the distributions of the data samples. Rejection of this hypothesis suggests that there is likely some difference between the samples.\n\nExcept for HEavy rain, looks like all other categorical value seem to have an impact n the registerations","c7e4f2ec":"### Feature Selection using permutation importances","1e88d21c":"### Feature Description\n- instant: record index (Irrelevant)\n- dteday : date \n- season : season (1:winter, 2:spring, 3:summer, 4:fall) \n- yr : year (0: 2011, 1:2012) \n- mnth : month ( 1 to 12) \n- hr : hour (0 to 23) \n- holiday : weather day is holiday or not \n- weekday : day of the week \n- workingday : if day is neither weekend nor holiday is 1, otherwise is 0. \n- weathersit : \n    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale) \n- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale) \n- hum: Normalized humidity. The values are divided to 100 (max) \n- windspeed: Normalized wind speed. The values are divided to 67 (max) \n- casual: count of casual users \n- registered: count of registered users \n- cnt: count of total rental bikes including both casual and registered \n ","f4295d89":"The regplot shows that the registrations will increase as the temperature increases.","d3961fe1":"## EDA","840a9cc7":"The least populated class of registered count has only 1 occurence. SO we cannot use a Stratified Sampling approach.\nWe will use the simple random sampling to create the test set\n","a15d030d":"### Registrations by temperature","e3b3cfd6":"Only 2 of the columns, i.e atemp and humidity are moderately correlated with registrations. ","ad708a53":"* There are more registrations in the evening than anytime in the day. \n\n* Night bookings are fewer than the other times in weekdays. However, in weekends, early morning registrations are fewer.\n\n* Weekday Evenings are booked more often than the mornings. May be people commute to home\/nearby areas (from workplace) during the evenings. \n\n* Weekend afternoons also see more registrations than any other time in the weekends.","aebb0a9f":"Early Morning - 4th hour to 7th hour\n\nMorning - 8th hour to 12th hour\n\nAfternoon - 13th hour to 16th hour\n\nEvening - 17th hour to 20th hour\n\nNight - 21st hour to 3rd hour","4114de50":"**The registered count is not normally distributed, as confirmed by skewtest**","3d675de1":"### Registrations by Hour of Day","f41b65af":"### Using ExtraTreeRegressor to check feature importances    ","87eb4681":"#### Tranformation of test dataset","4ec5d1fb":"### Summary\n\nAfter the feature selection, the below variables were found out to be important that the others\n\n* hour_of_day_tr_Evening\n* temp\n* hour_of_day_tr_Night\n* hour_of_day_tr_Early_Morning\n* hum\n* workingday\n* windspeed\n\nThough the Linear Regressor was stable between the train and test samples, a Random Forest Regressor predict with least error. The score further improved after the hyperparamter tuning using Randomised Search CV and the best estimator was used to check the score\/performance of the test data. \n\nHowever, the prediction errors can be in the range of 100 to 109.\n\nNext Steps - A more confident result could be obained if GridSearchCV were tried instead of RandomizedSearchCV in the hyperparamter tuning and if other models could be explored.\nSimilar model should be created for \"Casual\" counts and then the \"Registered\" and the \"Casual\" can be summed up to determine the \"Cnt\" i.e. the total count.\n"}}