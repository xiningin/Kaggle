{"cell_type":{"cce0c5fb":"code","8f79401f":"code","d95eb059":"code","0154b232":"code","be567d32":"code","801d5b5c":"code","8c345f93":"code","a7cd550d":"code","e3ef0f14":"code","5b4b6324":"markdown","f7abd5c4":"markdown","9d98fdb3":"markdown","c357065d":"markdown","627f2ee2":"markdown"},"source":{"cce0c5fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os","8f79401f":"train_transaction = pd.read_csv('..\/input\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/test_transaction.csv', index_col='TransactionID')\n\ntrain_identity = pd.read_csv('..\/input\/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/test_identity.csv', index_col='TransactionID')\n\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='TransactionID')\n\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\ndel train_transaction, test_transaction, train_identity, test_identity","d95eb059":"def make_duplicate_feature(df, cols_to_match, window_size=3):\n    \"\"\"\n    Counts the number of duplicate transactions in a temporal window\n    of width 2*window_size.\n    \n    Parameters:\n    -----------\n    df : pd.DataFrame, \n        The dataset.\n        \n    cols_to_match : list,\n        Columns which are required to be equal to be considered a match. \n        \n    window_size : (float, int)\n        Controls the size of the window (in minutes) to search for\n        duplicates.\n\n    Returns:\n    --------\n    duplicate_counts : list,\n        List of length df.shape[0] which counts the duplicate transactions.\n    \"\"\"\n    window_size = window_size * 60 #\u00a0convert to seconds\n    df['TransactionDT'] = df['TransactionDT']\n    # Thanks to WeNYoBen on SO for speeding this bit up: https:\/\/stackoverflow.com\/questions\/57101482\/counting-duplicate-row-within-a-rolling-window-of-a-pandas-df\n    s = pd.Series(df[cols_to_match].apply(tuple,1).map(hash).values,\n                  index=df.TransactionDT)\n    duplicate_count = [sum(s.loc[x-window_size:x+window_size]==y)-1 for x ,y in zip(s.index,s)]\n    \n    return duplicate_count","0154b232":"cols = ['TransactionAmt','ProductCD','card1','card2','card3',\n        'card4','card5','card6','addr1','addr2']\n\ntest['duplicate_count'] = make_duplicate_feature(test, cols_to_match=cols)\ntrain['duplicate_count'] = make_duplicate_feature(train, cols_to_match=cols)","be567d32":"train[train['duplicate_count']>0].head()","801d5b5c":"for df, name in zip([train,test], ['train','test']):\n    num_duplicates = df[df['duplicate_count']>0].shape[0] \/ df.shape[0]\n    print(f'{num_duplicates*100:.2f} % transactions have duplicates in the {name} set.')","8c345f93":"train.groupby('duplicate_count').mean()['isFraud']","a7cd550d":"# its important to look at the count, small counts are unreliable\ntrain.groupby('duplicate_count').count()['isFraud']","e3ef0f14":"plt.plot(train.groupby('duplicate_count').mean()['isFraud'], color='k')\nplt.ylabel('Fraction fraudulent')\nplt.xlabel('Duplicate count')\nplt.xlim(0, 40)","5b4b6324":"# Counting 'duplicate' transactions\n\nIt's been noted [publically](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/105261#latest-605153) that there are some duplicate transactions in the databases. In this kernel I show how you can make a feature which counts the number of duplicate transactions in a given time window. \n\n**Notes:**\n- This is not a fast implementation, some vectorized method using pandas methods would be better. Please share if you are able to speed up this implementation. \n- I haven't tested this feature yet. Still struggling with a CV mechanism to use! Please share if you find it improves your CV.\n- You can tune the window_size.","f7abd5c4":"####\u00a0Percentage of transactions which have duplicates\n\nA significant number of transactions have duplicates. There is a large difference between train and test sets.","9d98fdb3":"#### How fraudlent are duplicate transactions\n\nFeatures with a duplicate appear to be more likely to be a fraudulent. Some binning of this feature may help.","c357065d":"## Quick analysis of the new feature.","627f2ee2":"##### And a graph of this table to help with visualisation"}}