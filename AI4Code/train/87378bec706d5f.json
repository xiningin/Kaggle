{"cell_type":{"648f6c6a":"code","b24642d6":"code","a6bf3d89":"code","67f6a579":"code","e305c9a7":"code","dad324fa":"code","1cd349ab":"code","32cdeeb8":"code","c11216a7":"code","8a0525a1":"code","de6dbd39":"code","3be6a6f8":"code","316c46b8":"code","6cdd5322":"code","ea9a6141":"code","9d3623b6":"code","5e9d78f1":"code","ae969866":"code","a2f27e12":"code","00fb7171":"code","66659fb4":"code","54261aaa":"code","898b50f7":"code","907c185c":"code","2737db68":"code","335e4564":"code","2c475731":"code","c5a2c09e":"code","0caef5dd":"code","4763bbc9":"code","2aa7e937":"code","83e8af54":"code","f4f648e4":"code","0441b1c7":"markdown","2e9373cb":"markdown","b76d29f1":"markdown","ae23e7c2":"markdown","ecc6edf3":"markdown"},"source":{"648f6c6a":"from scipy.stats import kurtosis, iqr, skew, gmean, hmean, mode, normaltest, shapiro, ks_2samp\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\nfrom logging import getLogger, Formatter, StreamHandler, FileHandler, INFO, ERROR\nfrom sklearn.compose import make_column_selector as selector\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nimport os, gc, sys, time, random, math\nfrom contextlib import contextmanager\nfrom matplotlib import pyplot as plt\nfrom IPython.display import display\nfrom scipy import stats, special\nfrom sklearn import set_config\nfrom functools import partial\nimport lightgbm as lgb\nimport seaborn as sns\nimport pandas as pd\nimport typing as tp\nimport numpy as np\nimport warnings\n\n\nwarnings.simplefilter('ignore')\n%matplotlib inline","b24642d6":"def init_logger():\n    handler = StreamHandler()\n    handler.setLevel(ERROR)\n    handler.setFormatter(Formatter(LOGFORMAT))\n    fh_handler = FileHandler('{}.log'.format(MODELNAME))\n    fh_handler.setFormatter(Formatter(LOGFORMAT))\n    logger.setLevel(ERROR)\n    logger.addHandler(handler)\n    logger.addHandler(fh_handler)\n    \n@contextmanager\ndef timer(name : tp.Text):\n    t0 = time.time()\n    yield\n    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n\nCOMPETITION = 'WIDS2021'\nlogger = getLogger(COMPETITION)\nLOGFORMAT = '%(asctime)s %(levelname)s %(message)s'\nMODELNAME = 'LGBMCV'\ninit_logger()","a6bf3d89":"train = pd.read_csv('..\/input\/widsdatathon2021\/TrainingWiDS2021.csv', index_col=[0])\ntest = pd.read_csv('..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv', index_col=[0])\ntest_id = test.encounter_id.values\ny = train.diabetes_mellitus.values\ndel train['diabetes_mellitus']","67f6a579":"train = train.rename(columns={'pao2_apache':'pao2fio2ratio_apache','ph_apache':'arterial_ph_apache'})\ntest = test.rename(columns={'pao2_apache':'pao2fio2ratio_apache','ph_apache':'arterial_ph_apache'})\ntrain.loc[train.age == 0, 'age'] = np.nan\ntrain = train.drop(['readmission_status','encounter_id','hospital_id'], axis=1)\ntest = test.drop(['readmission_status','encounter_id','hospital_id'], axis=1)\ntrain = train.replace([np.inf, -np.inf], np.nan)\ntest = test.replace([np.inf, -np.inf], np.nan)","e305c9a7":"min_max_feats=[f[:-4] for f in train.columns if f[-4:]=='_min']\nfor col in min_max_feats:\n    train.loc[train[f'{col}_min'] > train[f'{col}_max'], [f'{col}_min', f'{col}_max']] = train.loc[train[f'{col}_min'] > train[f'{col}_max'], [f'{col}_max', f'{col}_min']].values\n    test.loc[test[f'{col}_min'] > test[f'{col}_max'], [f'{col}_min', f'{col}_max']] = test.loc[test[f'{col}_min'] > test[f'{col}_max'], [f'{col}_max', f'{col}_min']].values\n","dad324fa":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    display(train.head(2))\n    display(train.describe())\n    display(test.head(2))\n    display(test.describe())\n","1cd349ab":"lbls = {}\nfor col in train.select_dtypes(exclude = np.number).columns.tolist():\n    le = LabelEncoder().fit(pd.concat([train[col].astype(str),test[col].astype(str)]))   \n    train[col] = le.transform(train[col].astype(str))\n    test[col] = le.transform(test[col].astype(str))\n    lbls[col] = le\nprint('Categorical columns:', list(lbls.keys()))","32cdeeb8":"print(f'Percent of Nans in Train Data : {round(train.isna().sum().sum()\/len(train), 2)}')\nprint(f'Percent of Nans in Test  Data : {round(test.isna().sum().sum()\/len(test), 2)}')","c11216a7":"train['comorbidity_score'] = train['aids'].values * 23 + train['cirrhosis'] * 4  + train['hepatic_failure'] * 16 + train['immunosuppression'] * 10 + train['leukemia'] * 10 + train['lymphoma'] * 13 + train['solid_tumor_with_metastasis'] * 11\ntest['comorbidity_score'] = test['aids'].values * 23 + test['cirrhosis'] * 4  + test['hepatic_failure'] * 16 + test['immunosuppression'] * 10 + test['leukemia'] * 10 + test['lymphoma'] * 13 + test['solid_tumor_with_metastasis'] * 11\ntrain['comorbidity_score'] = train['comorbidity_score'].fillna(0)\ntest['comorbidity_score'] = test['comorbidity_score'].fillna(0)\ntrain['gcs_sum'] = train['gcs_eyes_apache']+train['gcs_motor_apache']+train['gcs_verbal_apache']\ntest['gcs_sum'] = test['gcs_eyes_apache']+test['gcs_motor_apache']+test['gcs_verbal_apache']\ntrain['gcs_sum'] = train['gcs_sum'].fillna(0)\ntest['gcs_sum'] = test['gcs_sum'].fillna(0)\ntrain['apache_2_diagnosis_type'] = train.apache_2_diagnosis.round(-1).fillna(-100).astype('int32')\ntest['apache_2_diagnosis_type'] = test.apache_2_diagnosis.round(-1).fillna(-100).astype('int32')\ntrain['apache_3j_diagnosis_type'] = train.apache_3j_diagnosis.round(-2).fillna(-100).astype('int32')\ntest['apache_3j_diagnosis_type'] = test.apache_3j_diagnosis.round(-2).fillna(-100).astype('int32')\ntrain['bmi_type'] = train.bmi.fillna(0).apply(lambda x: 5 * (round(int(x)\/5)))\ntest['bmi_type'] = test.bmi.fillna(0).apply(lambda x: 5 * (round(int(x)\/5)))\ntrain['height_type'] = train.height.fillna(0).apply(lambda x: 5 * (round(int(x)\/5)))\ntest['height_type'] = test.height.fillna(0).apply(lambda x: 5 * (round(int(x)\/5)))\ntrain['weight_type'] = train.weight.fillna(0).apply(lambda x: 5 * (round(int(x)\/5)))\ntest['weight_type'] = test.weight.fillna(0).apply(lambda x: 5 * (round(int(x)\/5)))\ntrain['age_type'] = train.age.fillna(0).apply(lambda x: 10 * (round(int(x)\/10)))\ntest['age_type'] = test.age.fillna(0).apply(lambda x: 10 * (round(int(x)\/10)))\ntrain['gcs_sum_type'] = train.gcs_sum.fillna(0).apply(lambda x: 2.5 * (round(int(x)\/2.5))).divide(2.5)\ntest['gcs_sum_type'] = test.gcs_sum.fillna(0).apply(lambda x: 2.5 * (round(int(x)\/2.5))).divide(2.5)\ntrain['apache_3j_diagnosis_x'] = train['apache_3j_diagnosis'].astype('str').str.split('.',n=1,expand=True)[0]\ntrain['apache_2_diagnosis_x'] = train['apache_2_diagnosis'].astype('str').str.split('.',n=1,expand=True)[0]\ntest['apache_3j_diagnosis_x'] = test['apache_3j_diagnosis'].astype('str').str.split('.',n=1,expand=True)[0]\ntest['apache_2_diagnosis_x'] = test['apache_2_diagnosis'].astype('str').str.split('.',n=1,expand=True)[0]\ntrain['apache_3j_diagnosis_split1'] = np.where(train['apache_3j_diagnosis'].isna() , np.nan , train['apache_3j_diagnosis'].astype('str').str.split('.',n=1,expand=True)[1]  )\ntest['apache_3j_diagnosis_split1']  = np.where(test['apache_3j_diagnosis'].isna() , np.nan , test['apache_3j_diagnosis'].astype('str').str.split('.',n=1,expand=True)[1]  )\ntrain['apache_2_diagnosis_split1'] = np.where(train['apache_2_diagnosis'].isna() , np.nan , train['apache_2_diagnosis'].apply(lambda x : x % 10)  )\ntest['apache_2_diagnosis_split1']  = np.where(test['apache_2_diagnosis'].isna() , np.nan , test['apache_2_diagnosis'].apply(lambda x : x % 10) )\n\nIDENTIFYING_COLS = ['age_type', 'height_type',  'ethnicity', 'gender', 'bmi_type'] \ntrain['profile'] = train[IDENTIFYING_COLS].apply(lambda x: hash(tuple(x)), axis = 1)\ntest['profile'] = test[IDENTIFYING_COLS].apply(lambda x: hash(tuple(x)), axis = 1)\nprint(f'Number of unique Profiles : {train[\"profile\"].nunique()}')\n","8a0525a1":"df = pd.concat([train['icu_id'], test['icu_id']])\nagg = df.value_counts().to_dict()\ntrain['icu_id_counts'] = np.log1p(train['icu_id'].map(agg))\ntest['icu_id_counts'] = np.log1p(test['icu_id'].map(agg))\ndf = pd.concat([train['age'], test['age']])\nagg = df.value_counts().to_dict()\ntrain['age_counts'] = np.log1p(train['age'].map(agg))\ntest['age_counts'] = np.log1p(test['age'].map(agg))\ntrain[\"diff_bmi\"] = train['bmi'].copy() \ntrain['bmi'] = train['weight']\/((train['height']\/100)**2)\ntrain[\"diff_bmi\"] = train[\"diff_bmi\"]-train['bmi']\ntest[\"diff_bmi\"] = test['bmi'].copy()\ntest['bmi'] = test['weight']\/((test['height']\/100)**2)\ntest[\"diff_bmi\"] = test[\"diff_bmi\"]-test['bmi']\ntrain['pre_icu_los_days'] = train['pre_icu_los_days'].apply(lambda x:special.expit(x) )\ntest['pre_icu_los_days']  = test['pre_icu_los_days'].apply(lambda x:special.expit(x) )\ntrain['abmi'] = train['age']\/train['bmi']\ntrain['agi'] = train['weight']\/train['age']\ntest['abmi'] = test['age']\/train['bmi']\ntest['agi'] = test['weight']\/train['age']","de6dbd39":"d_cols = [c for c in train.columns if(c.startswith(\"d1\"))]\nh_cols = [c for c in train.columns if(c.startswith(\"h1\"))]\ntrain[\"dailyLabs_row_nan_count\"] = train[d_cols].isna().sum(axis=1)\ntrain[\"hourlyLabs_row_nan_count\"] = train[h_cols].isna().sum(axis=1)\ntrain[\"diff_labTestsRun_daily_hourly\"] = train[\"dailyLabs_row_nan_count\"] - train[\"hourlyLabs_row_nan_count\"]\ntest[\"dailyLabs_row_nan_count\"] = test[d_cols].isna().sum(axis=1)\ntest[\"hourlyLabs_row_nan_count\"] = test[h_cols].isna().sum(axis=1)\ntest[\"diff_labTestsRun_daily_hourly\"] = test[\"dailyLabs_row_nan_count\"] - test[\"hourlyLabs_row_nan_count\"]","3be6a6f8":"lab_col = [c for c in train.columns if((c.startswith(\"h1\")) | (c.startswith(\"d1\")))]\nlab_col_names = list(set(list(map(lambda i: i[ 3 : -4], lab_col))))\n\nprint(\"len lab_col\",len(lab_col))\nprint(\"len lab_col_names\",len(lab_col_names))\nprint(\"lab_col_names\\n\",lab_col_names)","316c46b8":"first_h = []\nfor v in lab_col_names:\n    first_h.append(v+\"_started_after_firstHour\")\n    colsx = [x for x in test.columns if v in x]\n    train[v+\"_nans\"] = train.loc[:, colsx].isna().sum(axis=1)\n    test[v+\"_nans\"] = test.loc[:, colsx].isna().sum(axis=1)\n    train[v+\"_d1_value_range\"] = train[f\"d1_{v}_max\"].subtract(train[f\"d1_{v}_min\"])    \n    train[v+\"_h1_value_range\"] = train[f\"h1_{v}_max\"].subtract(train[f\"h1_{v}_min\"])\n    train[v+\"_d1_h1_max_eq\"] = (train[f\"d1_{v}_max\"]== train[f\"h1_{v}_max\"]).astype(np.int8)\n    train[v+\"_d1_h1_min_eq\"] = (train[f\"d1_{v}_min\"]== train[f\"h1_{v}_min\"]).astype(np.int8)\n    train[v+\"_d1_zero_range\"] = (train[v+\"_d1_value_range\"] == 0).astype(np.int8)\n    train[v+\"_h1_zero_range\"] =(train[v+\"_h1_value_range\"] == 0).astype(np.int8)\n    train[v+\"_tot_change_value_range_normed\"] = abs((train[v+\"_d1_value_range\"].div(train[v+\"_h1_value_range\"])))#.div(df[f\"d1_{v}_max\"]))\n    train[v+\"_started_after_firstHour\"] = ((train[f\"h1_{v}_max\"].isna()) & (train[f\"h1_{v}_min\"].isna())) & (~train[f\"d1_{v}_max\"].isna())\n    train[v+\"_day_more_extreme\"] = ((train[f\"d1_{v}_max\"]>train[f\"h1_{v}_max\"]) | (train[f\"d1_{v}_min\"]<train[f\"h1_{v}_min\"]))\n    train[v+\"_day_more_extreme\"].fillna(False)    \n    test[v+\"_d1_value_range\"] = test[f\"d1_{v}_max\"].subtract(test[f\"d1_{v}_min\"])   \n    test[v+\"_h1_value_range\"] = test[f\"h1_{v}_max\"].subtract(test[f\"h1_{v}_min\"])\n    test[v+\"_d1_h1_max_eq\"] = (test[f\"d1_{v}_max\"]== test[f\"h1_{v}_max\"]).astype(np.int8)\n    test[v+\"_d1_h1_min_eq\"] = (test[f\"d1_{v}_min\"]== test[f\"h1_{v}_min\"]).astype(np.int8)\n    test[v+\"_d1_zero_range\"] = (test[v+\"_d1_value_range\"] == 0).astype(np.int8)\n    test[v+\"_h1_zero_range\"] =(test[v+\"_h1_value_range\"] == 0).astype(np.int8)\n    test[v+\"_tot_change_value_range_normed\"] = abs((test[v+\"_d1_value_range\"].div(test[v+\"_h1_value_range\"])))\n    test[v+\"_started_after_firstHour\"] = ((test[f\"h1_{v}_max\"].isna()) & (test[f\"h1_{v}_min\"].isna())) & (~test[f\"d1_{v}_max\"].isna())\n    test[v+\"_day_more_extreme\"] = ((test[f\"d1_{v}_max\"]>test[f\"h1_{v}_max\"]) | (test[f\"d1_{v}_min\"]<test[f\"h1_{v}_min\"]))\n    test[v+\"_day_more_extreme\"].fillna(False)\n\ntrain[\"total_Tests_started_After_firstHour\"] = train[first_h].sum(axis=1)\ntest[\"total_Tests_started_After_firstHour\"] = test[first_h].sum(axis=1)\ngc.collect()\ntrain[\"total_Tests_started_After_firstHour\"].describe()","6cdd5322":"groupers = ['apache_3j_diagnosis', 'profile']\n\nfor g in groupers:\n    for v in lab_col_names:\n        temp = pd.concat([train[[f\"d1_{v}_max\",g]], test[[f\"d1_{v}_max\",g]]], axis=0).groupby(g)[f\"d1_{v}_max\"].mean().to_dict()\n        train[f'mean_diff_d1_{v}_{g}_max'] = train[f\"d1_{v}_max\"]-train[g].map(temp)\n        test[f'mean_diff_d1_{v}_{g}_max'] = test[f\"d1_{v}_max\"]-test[g].map(temp)\n        temp = pd.concat([train[[f\"d1_{v}_min\",g]], test[[f\"d1_{v}_min\",g]]], axis=0).groupby(g)[f\"d1_{v}_min\"].mean().to_dict()   \n        train[f'mean_diff_d1_{v}_{g}_min'] = train[f\"d1_{v}_min\"]-train[g].map(temp)\n        test[f'mean_diff_d1_{v}_{g}_min'] = test[f\"d1_{v}_min\"]-test[g].map(temp)\n        temp = pd.concat([train[[f\"h1_{v}_max\",g]], test[[f\"h1_{v}_max\",g]]], axis=0).groupby(g)[f\"h1_{v}_max\"].mean().to_dict()   \n        train[f'mean_diff_h1_{v}_{g}_max'] = train[f\"h1_{v}_max\"]-train[g].map(temp)\n        test[f'mean_diff_h1_{v}_{g}_max'] = test[f\"h1_{v}_max\"]-test[g].map(temp)\n        temp = pd.concat([train[[f\"h1_{v}_min\",g]], test[[f\"h1_{v}_min\",g]]], axis=0).groupby(g)[f\"h1_{v}_min\"].mean().to_dict()   \n        train[f'mean_diff_h1_{v}_{g}_min'] = train[f\"h1_{v}_min\"]-train[g].map(temp)\n        test[f'mean_diff_h1_{v}_{g}_min'] = test[f\"h1_{v}_min\"]-test[g].map(temp)\ngc.collect()","ea9a6141":"train['diasbp_indicator'] = (\n(train['d1_diasbp_invasive_max'] == train['d1_diasbp_max']) & (train['d1_diasbp_noninvasive_max']==train['d1_diasbp_invasive_max'])|\n(train['d1_diasbp_invasive_min'] == train['d1_diasbp_min']) & (train['d1_diasbp_noninvasive_min']==train['d1_diasbp_invasive_min'])|\n(train['h1_diasbp_invasive_max'] == train['h1_diasbp_max']) & (train['h1_diasbp_noninvasive_max']==train['h1_diasbp_invasive_max'])|\n(train['h1_diasbp_invasive_min'] == train['h1_diasbp_min']) & (train['h1_diasbp_noninvasive_min']==train['h1_diasbp_invasive_min'])\n).astype(np.int8)\n\n\ntrain['mbp_indicator'] = (\n(train['d1_mbp_invasive_max'] == train['d1_mbp_max']) & (train['d1_mbp_noninvasive_max']==train['d1_mbp_invasive_max'])|\n(train['d1_mbp_invasive_min'] == train['d1_mbp_min']) & (train['d1_mbp_noninvasive_min']==train['d1_mbp_invasive_min'])|\n(train['h1_mbp_invasive_max'] == train['h1_mbp_max']) & (train['h1_mbp_noninvasive_max']==train['h1_mbp_invasive_max'])|\n(train['h1_mbp_invasive_min'] == train['h1_mbp_min']) & (train['h1_mbp_noninvasive_min']==train['h1_mbp_invasive_min'])\n).astype(np.int8)\n\ntrain['sysbp_indicator'] = (\n(train['d1_sysbp_invasive_max'] == train['d1_sysbp_max']) & (train['d1_sysbp_noninvasive_max']==train['d1_sysbp_invasive_max'])|\n(train['d1_sysbp_invasive_min'] == train['d1_sysbp_min']) & (train['d1_sysbp_noninvasive_min']==train['d1_sysbp_invasive_min'])|\n (train['h1_sysbp_invasive_max'] == train['h1_sysbp_max']) & (train['h1_sysbp_noninvasive_max']==train['h1_sysbp_invasive_max'])|\n(train['h1_sysbp_invasive_min'] == train['h1_sysbp_min']) & (train['h1_sysbp_noninvasive_min']==train['h1_sysbp_invasive_min'])   \n).astype(np.int8)\n\ntrain['d1_mbp_invnoninv_max_diff'] = train['d1_mbp_invasive_max'] - train['d1_mbp_noninvasive_max']\ntrain['h1_mbp_invnoninv_max_diff'] = train['h1_mbp_invasive_max'] - train['h1_mbp_noninvasive_max']\ntrain['d1_mbp_invnoninv_min_diff'] = train['d1_mbp_invasive_min'] - train['d1_mbp_noninvasive_min']\ntrain['h1_mbp_invnoninv_min_diff'] = train['h1_mbp_invasive_min'] - train['h1_mbp_noninvasive_min']\ntrain['d1_diasbp_invnoninv_max_diff'] = train['d1_diasbp_invasive_max'] - train['d1_diasbp_noninvasive_max']\ntrain['h1_diasbp_invnoninv_max_diff'] = train['h1_diasbp_invasive_max'] - train['h1_diasbp_noninvasive_max']\ntrain['d1_diasbp_invnoninv_min_diff'] = train['d1_diasbp_invasive_min'] - train['d1_diasbp_noninvasive_min']\ntrain['h1_diasbp_invnoninv_min_diff'] = train['h1_diasbp_invasive_min'] - train['h1_diasbp_noninvasive_min']\ntrain['d1_sysbp_invnoninv_max_diff'] = train['d1_sysbp_invasive_max'] - train['d1_sysbp_noninvasive_max']\ntrain['h1_sysbp_invnoninv_max_diff'] = train['h1_sysbp_invasive_max'] - train['h1_sysbp_noninvasive_max']\ntrain['d1_sysbp_invnoninv_min_diff'] = train['d1_sysbp_invasive_min'] - train['d1_sysbp_noninvasive_min']\ntrain['h1_sysbp_invnoninv_min_diff'] = train['h1_sysbp_invasive_min'] - train['h1_sysbp_noninvasive_min']\n\ntest['diasbp_indicator'] = (\n(test['d1_diasbp_invasive_max'] == test['d1_diasbp_max']) & (test['d1_diasbp_noninvasive_max']==test['d1_diasbp_invasive_max'])|\n(test['d1_diasbp_invasive_min'] == test['d1_diasbp_min']) & (test['d1_diasbp_noninvasive_min']==test['d1_diasbp_invasive_min'])|\n(test['h1_diasbp_invasive_max'] == test['h1_diasbp_max']) & (test['h1_diasbp_noninvasive_max']==test['h1_diasbp_invasive_max'])|\n(test['h1_diasbp_invasive_min'] == test['h1_diasbp_min']) & (test['h1_diasbp_noninvasive_min']==test['h1_diasbp_invasive_min'])\n).astype(np.int8)\n\n\ntest['mbp_indicator'] = (\n(test['d1_mbp_invasive_max'] == test['d1_mbp_max']) & (test['d1_mbp_noninvasive_max']==test['d1_mbp_invasive_max'])|\n(test['d1_mbp_invasive_min'] == test['d1_mbp_min']) & (test['d1_mbp_noninvasive_min']==test['d1_mbp_invasive_min'])|\n(test['h1_mbp_invasive_max'] == test['h1_mbp_max']) & (test['h1_mbp_noninvasive_max']==test['h1_mbp_invasive_max'])|\n(test['h1_mbp_invasive_min'] == test['h1_mbp_min']) & (test['h1_mbp_noninvasive_min']==test['h1_mbp_invasive_min'])\n).astype(np.int8)\n\ntest['sysbp_indicator'] = (\n(test['d1_sysbp_invasive_max'] == test['d1_sysbp_max']) & (test['d1_sysbp_noninvasive_max']==test['d1_sysbp_invasive_max'])|\n(test['d1_sysbp_invasive_min'] == test['d1_sysbp_min']) & (test['d1_sysbp_noninvasive_min']==test['d1_sysbp_invasive_min'])|\n (test['h1_sysbp_invasive_max'] == test['h1_sysbp_max']) & (test['h1_sysbp_noninvasive_max']==test['h1_sysbp_invasive_max'])|\n(test['h1_sysbp_invasive_min'] == test['h1_sysbp_min']) & (test['h1_sysbp_noninvasive_min']==test['h1_sysbp_invasive_min'])   \n).astype(np.int8)\n\ntest['d1_mbp_invnoninv_max_diff'] = test['d1_mbp_invasive_max'] - test['d1_mbp_noninvasive_max']\ntest['h1_mbp_invnoninv_max_diff'] = test['h1_mbp_invasive_max'] - test['h1_mbp_noninvasive_max']\ntest['d1_mbp_invnoninv_min_diff'] = test['d1_mbp_invasive_min'] - test['d1_mbp_noninvasive_min']\ntest['h1_mbp_invnoninv_min_diff'] = test['h1_mbp_invasive_min'] - test['h1_mbp_noninvasive_min']\ntest['d1_diasbp_invnoninv_max_diff'] = test['d1_diasbp_invasive_max'] - test['d1_diasbp_noninvasive_max']\ntest['h1_diasbp_invnoninv_max_diff'] = test['h1_diasbp_invasive_max'] - test['h1_diasbp_noninvasive_max']\ntest['d1_diasbp_invnoninv_min_diff'] = test['d1_diasbp_invasive_min'] - test['d1_diasbp_noninvasive_min']\ntest['h1_diasbp_invnoninv_min_diff'] = test['h1_diasbp_invasive_min'] - test['h1_diasbp_noninvasive_min']\n\ntest['d1_sysbp_invnoninv_max_diff'] = test['d1_sysbp_invasive_max'] - test['d1_sysbp_noninvasive_max']\ntest['h1_sysbp_invnoninv_max_diff'] = test['h1_sysbp_invasive_max'] - test['h1_sysbp_noninvasive_max']\ntest['d1_sysbp_invnoninv_min_diff'] = test['d1_sysbp_invasive_min'] - test['d1_sysbp_noninvasive_min']\ntest['h1_sysbp_invnoninv_min_diff'] = test['h1_sysbp_invasive_min'] - test['h1_sysbp_noninvasive_min']\n\n\nfor v in ['albumin','bilirubin','bun','glucose','hematocrit','pao2fio2ratio','arterial_ph','resprate','sodium','temp','wbc','creatinine']:\n    train[f'{v}_indicator'] = (((train[f'{v}_apache']==train[f'd1_{v}_max']) & (train[f'd1_{v}_max']==train[f'h1_{v}_max'])) |\n                 ((train[f'{v}_apache']==train[f'd1_{v}_max']) & (train[f'd1_{v}_max']==train[f'd1_{v}_min'])) |\n                 ((train[f'{v}_apache']==train[f'd1_{v}_max']) & (train[f'd1_{v}_max']==train[f'h1_{v}_min'])) |\n                 ((train[f'{v}_apache']==train[f'h1_{v}_max']) & (train[f'h1_{v}_max']==train[f'd1_{v}_max'])) |\n                 ((train[f'{v}_apache']==train[f'h1_{v}_max']) & (train[f'h1_{v}_max']==train[f'h1_{v}_min'])) |\n                 ((train[f'{v}_apache']==train[f'h1_{v}_max']) & (train[f'h1_{v}_max']==train[f'd1_{v}_min'])) |\n                 ((train[f'{v}_apache']==train[f'd1_{v}_min']) & (train[f'd1_{v}_min']==train[f'd1_{v}_max'])) |\n                 ((train[f'{v}_apache']==train[f'd1_{v}_min']) & (train[f'd1_{v}_min']==train[f'h1_{v}_min'])) |\n                 ((train[f'{v}_apache']==train[f'd1_{v}_min']) & (train[f'd1_{v}_min']==train[f'h1_{v}_max'])) |\n                 ((train[f'{v}_apache']==train[f'h1_{v}_min']) & (train[f'h1_{v}_min']==train[f'h1_{v}_max'])) |\n                 ((train[f'{v}_apache']==train[f'h1_{v}_min']) & (train[f'h1_{v}_min']==train[f'd1_{v}_min'])) |\n                 ((train[f'{v}_apache']==train[f'h1_{v}_min']) & (train[f'h1_{v}_min']==train[f'd1_{v}_max'])) \n                ).astype(np.int8)\n    test[f'{v}_indicator'] = (((test[f'{v}_apache']==test[f'd1_{v}_max']) & (test[f'd1_{v}_max']==test[f'h1_{v}_max'])) |\n                 ((test[f'{v}_apache']==test[f'd1_{v}_max']) & (test[f'd1_{v}_max']==test[f'd1_{v}_min'])) |\n                 ((test[f'{v}_apache']==test[f'd1_{v}_max']) & (test[f'd1_{v}_max']==test[f'h1_{v}_min'])) |\n                 ((test[f'{v}_apache']==test[f'h1_{v}_max']) & (test[f'h1_{v}_max']==test[f'd1_{v}_max'])) |\n                 ((test[f'{v}_apache']==test[f'h1_{v}_max']) & (test[f'h1_{v}_max']==test[f'h1_{v}_min'])) |\n                 ((test[f'{v}_apache']==test[f'h1_{v}_max']) & (test[f'h1_{v}_max']==test[f'd1_{v}_min'])) |\n                 ((test[f'{v}_apache']==test[f'd1_{v}_min']) & (test[f'd1_{v}_min']==test[f'd1_{v}_max'])) |\n                 ((test[f'{v}_apache']==test[f'd1_{v}_min']) & (test[f'd1_{v}_min']==test[f'h1_{v}_min'])) |\n                 ((test[f'{v}_apache']==test[f'd1_{v}_min']) & (test[f'd1_{v}_min']==test[f'h1_{v}_max'])) |\n                 ((test[f'{v}_apache']==test[f'h1_{v}_min']) & (test[f'h1_{v}_min']==test[f'h1_{v}_max'])) |\n                 ((test[f'{v}_apache']==test[f'h1_{v}_min']) & (test[f'h1_{v}_min']==test[f'd1_{v}_min'])) |\n                 ((test[f'{v}_apache']==test[f'h1_{v}_min']) & (test[f'h1_{v}_min']==test[f'd1_{v}_max'])) \n                ).astype(np.int8)","9d3623b6":"more_extreme_cols = [c for c in train.columns if(c.endswith(\"_day_more_extreme\"))]\ntrain[\"total_day_more_extreme\"] = train[more_extreme_cols].sum(axis=1)\ntest[\"total_day_more_extreme\"] = test[more_extreme_cols].sum(axis=1)\ntrain[\"d1_resprate_div_mbp_min\"] = train[\"d1_resprate_min\"].div(train[\"d1_mbp_min\"])\ntrain[\"d1_resprate_div_sysbp_min\"] = train[\"d1_resprate_min\"].div(train[\"d1_sysbp_min\"])\ntrain[\"d1_lactate_min_div_diasbp_min\"] = train[\"d1_lactate_min\"].div(train[\"d1_diasbp_min\"])\ntrain[\"d1_heartrate_min_div_d1_sysbp_min\"] = train[\"d1_heartrate_min\"].div(train[\"d1_sysbp_min\"])\ntrain[\"d1_hco3_div\"]= train[\"d1_hco3_max\"].div(train[\"d1_hco3_min\"])\ntrain[\"d1_resprate_times_resprate\"] = train[\"d1_resprate_min\"].multiply(train[\"d1_resprate_max\"])\ntrain[\"left_average_spo2\"] = (2*train[\"d1_spo2_max\"] + train[\"d1_spo2_min\"])\/3\ntest[\"d1_resprate_div_mbp_min\"] = test[\"d1_resprate_min\"].div(test[\"d1_mbp_min\"])\ntest[\"d1_resprate_div_sysbp_min\"] = test[\"d1_resprate_min\"].div(test[\"d1_sysbp_min\"])\ntest[\"d1_lactate_min_div_diasbp_min\"] = test[\"d1_lactate_min\"].div(test[\"d1_diasbp_min\"])\ntest[\"d1_heartrate_min_div_d1_sysbp_min\"] = test[\"d1_heartrate_min\"].div(test[\"d1_sysbp_min\"])\ntest[\"d1_hco3_div\"]= test[\"d1_hco3_max\"].div(test[\"d1_hco3_min\"])\ntest[\"d1_resprate_times_resprate\"] = test[\"d1_resprate_min\"].multiply(test[\"d1_resprate_max\"])\ntest[\"left_average_spo2\"] = (2*test[\"d1_spo2_max\"] + test[\"d1_spo2_min\"])\/3\ntrain[\"total_chronic\"] = train[[\"aids\",\"cirrhosis\", 'hepatic_failure']].sum(axis=1)\ntrain[\"total_cancer_immuno\"] = train[[ 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis']].sum(axis=1)\ntest[\"total_chronic\"] = test[[\"aids\",\"cirrhosis\", 'hepatic_failure']].sum(axis=1)\ntest[\"total_cancer_immuno\"] = test[[ 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis']].sum(axis=1)\ntrain[\"has_complicator\"] = train[[\"aids\",\"cirrhosis\", 'hepatic_failure',\n                            'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis']].max(axis=1)\ntest[\"has_complicator\"] = test[[\"aids\",\"cirrhosis\", 'hepatic_failure',\n                            'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis']].max(axis=1)\ngc.collect()\ntrain[[\"has_complicator\",\"total_chronic\",\"total_cancer_immuno\",\"has_complicator\"]].describe()\n","5e9d78f1":"train['apache_3j'] = np.where(train['apache_3j_diagnosis_type']<0 , np.nan ,\n                            np.where(train['apache_3j_diagnosis_type'] < 200, 'Cardiovascular' , \n                            np.where(train['apache_3j_diagnosis_type'] < 400, 'Respiratory' , \n                            np.where(train['apache_3j_diagnosis_type'] < 500, 'Neurological' , \n                            np.where(train['apache_3j_diagnosis_type'] < 600, 'Sepsis' , \n                            np.where(train['apache_3j_diagnosis_type'] < 800, 'Trauma' ,  \n                            np.where(train['apache_3j_diagnosis_type'] < 900, 'Haematological' ,         \n                            np.where(train['apache_3j_diagnosis_type'] < 1000, 'Renal\/Genitourinary' ,         \n                            np.where(train['apache_3j_diagnosis_type'] < 1200, 'Musculoskeletal\/Skin disease' , 'Operative Sub-Diagnosis Codes' ))))))))\n                                    )\ntest['apache_3j'] = np.where(test['apache_3j_diagnosis_type']<0 , np.nan ,\n                            np.where(test['apache_3j_diagnosis_type'] < 200, 'Cardiovascular' , \n                            np.where(test['apache_3j_diagnosis_type'] < 400, 'Respiratory' , \n                            np.where(test['apache_3j_diagnosis_type'] < 500, 'Neurological' , \n                            np.where(test['apache_3j_diagnosis_type'] < 600, 'Sepsis' , \n                            np.where(test['apache_3j_diagnosis_type'] < 800, 'Trauma' ,  \n                            np.where(test['apache_3j_diagnosis_type'] < 900, 'Haematological' ,         \n                            np.where(test['apache_3j_diagnosis_type'] < 1000, 'Renal\/Genitourinary' ,         \n                            np.where(test['apache_3j_diagnosis_type'] < 1200, 'Musculoskeletal\/Skin disease' , 'Operative Sub-Diagnosis Codes' ))))))))\n                                    )","ae969866":"trainf = pd.read_pickle('..\/input\/featxx\/X.pkl')\ntestf = pd.read_pickle('..\/input\/featxx\/X_test.pkl')\ntrainf = trainf.rename(columns={'pao2_apache':'pao2fio2ratio_apache','ph_apache':'arterial_ph_apache'})\ntestf = testf.rename(columns={'pao2_apache':'pao2fio2ratio_apache','ph_apache':'arterial_ph_apache'})","a2f27e12":"train.shape, test.shape, trainf.shape, testf.shape","00fb7171":"col_order = train.columns.tolist()\ntrain = train[col_order]\ntest = test[col_order]\ncol_order = trainf.columns.tolist()\ntrainf = trainf[col_order]\ntestf = testf[col_order]","66659fb4":"train = pd.concat([trainf.reset_index(drop=True),train.reset_index(drop=True)], axis=1)\ntest =  pd.concat([testf.reset_index(drop=True),test.reset_index(drop=True)], axis=1)\ntrain= train.fillna(0); test= test.fillna(0)\ngc.collect()\ntrain.shape, test.shape","54261aaa":"Cols = list(train.columns)\nfor i,item in enumerate(train.columns):\n    if item in train.columns[:i]: Cols[i] = \"toDROP\"\ntrain.columns = Cols\ntest.columns = Cols\ntrain = train.drop(\"toDROP\",1)\ntest = test.drop(\"toDROP\",1)\ntrain.shape, test.shape","898b50f7":"col_order = train.columns.tolist()\ntrain = train[col_order]\ntest = test[col_order]","907c185c":"drop_cols = ['abmi', 'age_type', 'aids', 'albumin_apache', 'albumin_h1_value_range', 'albumin_h1_zero_range','albumin_tot_change_value_range_normed', 'apache_3j_diagnosis-cat_age', 'apache_post_operative','apache_post_operative_std_d1_temp_max', 'arf_apache_std_d1_hemaglobin_max', 'arterial_pco2_d1_h1_max_eq','arterial_pco2_d1_h1_min_eq', 'arterial_pco2_d1_zero_range', 'arterial_pco2_h1_zero_range','arterial_ph_apache', 'arterial_ph_d1_h1_max_eq', 'arterial_ph_d1_value_range', 'arterial_ph_d1_zero_range','arterial_ph_h1_zero_range', 'arterial_po2_d1_h1_max_eq', 'arterial_po2_d1_h1_min_eq', 'arterial_po2_d1_value_range', 'bilirubin_h1_value_range', 'bilirubin_h1_zero_range','bilirubin_tot_change_value_range_normed', 'bmi_type', 'bun_d1_h1_max_eq', 'bun_d1_zero_range','bun_h1_value_range', 'bun_h1_zero_range', 'calcium_d1_zero_range', 'calcium_h1_value_range','calcium_h1_zero_range', 'creatinine_h1_zero_range', 'd1_albumin_min', 'd1_arterial_pco2_min','d1_arterial_ph_max', 'd1_arterial_ph_min', 'd1_calcium_max', 'd1_diasbp_max', 'd1_diasbp_min','d1_hematocrit_min', 'd1_inr_max', 'd1_inr_min', 'd1_mbp_invasive_max', 'd1_mbp_invasive_min', 'd1_mbp_max','d1_mbp_min', 'd1_mbp_noninvasive_max', 'd1_mbp_noninvasive_min', 'd1_pao2fio2ratio_max', 'd1_pao2fio2ratio_min', 'd1_platelets_max', 'd1_resprate_max', 'd1_sysbp_invasive_min', 'd1_temp_min','d1_wbc_min', 'diasbp_d1_h1_max_eq', 'diasbp_d1_zero_range', 'diasbp_invasive_d1_h1_max_eq','diasbp_invasive_d1_value_range', 'diasbp_invasive_d1_zero_range', 'diasbp_invasive_h1_value_range','diasbp_invasive_h1_zero_range', 'diasbp_noninvasive_d1_h1_max_eq', 'diasbp_noninvasive_d1_zero_range','diasbp_noninvasive_h1_zero_range', 'diff_bmi', 'elective_surgery_mean_d1_sysbp_min', 'gcs_unable_apache','h1_albumin_max', 'h1_albumin_min', 'h1_arterial_pco2_max', 'h1_arterial_pco2_min', 'h1_arterial_ph_min','h1_arterial_po2_max', 'h1_bilirubin_max', 'h1_bun_max', 'h1_creatinine_min', 'h1_diasbp_noninvasive_max','h1_heartrate_max', 'h1_heartrate_min', 'h1_hemaglobin_min', 'h1_hematocrit_max', 'h1_hematocrit_min','h1_lactate_max', 'h1_lactate_min', 'h1_mbp_invasive_max', 'h1_mbp_invasive_min', 'h1_mbp_max', 'h1_mbp_min','h1_mbp_noninvasive_max', 'h1_mbp_noninvasive_min', 'h1_pao2fio2ratio_max', 'h1_pao2fio2ratio_min','h1_platelets_max', 'h1_platelets_min', 'h1_resprate_max', 'h1_resprate_min', 'h1_sodium_max','h1_spo2_max', 'h1_spo2_min', 'h1_sysbp_max', 'h1_sysbp_min', 'h1_sysbp_noninvasive_max','h1_sysbp_noninvasive_min', 'h1_temp_max', 'h1_temp_min', 'h1_wbc_max', 'h1_wbc_min', 'hco3_d1_h1_max_eq','hco3_d1_h1_min_eq', 'hco3_h1_value_range', 'hco3_h1_zero_range', 'heartrate_d1_zero_range','heartrate_h1_zero_range', 'height', 'hemaglobin_d1_value_range', 'hemaglobin_d1_zero_range','hematocrit_apache', 'hematocrit_d1_h1_min_eq', 'hematocrit_d1_value_range', 'hematocrit_d1_zero_range','inr_d1_h1_max_eq', 'inr_d1_h1_min_eq', 'inr_d1_value_range', 'inr_d1_zero_range', 'inr_day_more_extreme','inr_h1_value_range', 'inr_h1_zero_range', 'inr_started_after_firstHour', 'intubated_apache_mean_d1_spo2_max','lactate_h1_value_range', 'lactate_h1_zero_range', 'lymphoma', 'map_apache', 'mbp_d1_zero_range','mbp_h1_zero_range', 'mbp_invasive_d1_h1_min_eq', 'mbp_invasive_d1_value_range', 'mbp_invasive_d1_zero_range','mbp_invasive_h1_zero_range', 'mbp_noninvasive_d1_h1_max_eq', 'mbp_noninvasive_d1_h1_min_eq','mbp_noninvasive_d1_zero_range', 'mbp_noninvasive_h1_zero_range', 'mean_diff_d1_inr_min','mean_diff_h1_bilirubin_min', 'mean_diff_h1_inr_max', 'paco2_apache', 'paco2_for_ph_apache','pao2fio2ratio_apache', 'pao2fio2ratio_h1_value_range', 'pao2fio2ratio_h1_zero_range','rank_frqenc_leukemia', 'wbc_h1_value_range','platelets_d1_value_range', 'platelets_h1_zero_range', 'potassium_d1_h1_max_eq','potassium_h1_value_range','potassium_h1_zero_range', 'rank_frqenc_apache_2_diagnosis', 'resprate_apache', 'resprate_d1_h1_min_eq','resprate_d1_zero_range', 'sodium_d1_h1_min_eq', 'sodium_d1_zero_range','spo2_d1_h1_max_eq','sysbp_d1_zero_range', 'sysbp_h1_zero_range', 'sysbp_invasive_d1_h1_min_eq','sysbp_invasive_d1_zero_range','sysbp_noninvasive_d1_h1_min_eq', 'sysbp_noninvasive_d1_zero_range','sysbp_noninvasive_h1_zero_range','temp_d1_zero_range', 'ventilated_apache_std_d1_glucose_min', 'wbc_apache', 'wbc_d1_h1_min_eq','wbc_d1_value_range', 'wbc_d1_zero_range', 'wbc_h1_zero_range', 'gcs_eyes_apache_mean_d1_bun_min','rank_frqenc_aids']","2737db68":"drop_cols = list(set(drop_cols))\nprint(len(drop_cols))","335e4564":"cats = ['elective_surgery', 'icu_id', 'arf_apache', 'intubated_apache', 'ventilated_apache', 'cirrhosis','hepatic_failure', 'immunosuppression', 'leukemia', 'solid_tumor_with_metastasis', 'apache_3j_diagnosis_x','apache_2_diagnosis_x', 'apache_3j', 'apache_3j_diagnosis_split1', 'apache_2_diagnosis_split1', 'gcs_sum_type','hospital_admit_source', 'glucose_rate', 'glucose_wb', 'gcs_eyes_apache', 'glucose_normal', 'total_cancer_immuno','gender', 'total_chronic', 'icu_stay_type', 'apache_2_diagnosis_type', 'apache_3j_diagnosis_type']\nlen(cats)","2c475731":"for col in cats:\n    train_only = list(set(train[col].unique()) - set(test[col].unique()))\n    test_only = list(set(test[col].unique()) - set(train[col].unique()))\n    both = list(set(test[col].unique()).union(set(train[col].unique())))\n    train.loc[train[col].isin(train_only), col] = np.nan\n    test.loc[test[col].isin(test_only), col] = np.nan\n    try:\n        lbl = OrdinalEncoder(dtype='int')\n        train[col] = lbl.fit_transform(train[col].astype('str').values.reshape(-1,1))\n        test[col] = lbl.transform(test[col].astype('str').values.reshape(-1,1))\n    except:\n        lbl = OrdinalEncoder(dtype='int')\n        train[col] = lbl.fit_transform(train[col].astype('str').fillna('-1').values.reshape(-1,1))\n        test[col] = lbl.transform(test[col].astype('str').fillna('-1').values.reshape(-1,1))\n    temp = pd.concat([train[[col]], test[[col]]], axis=0)\n    temp_mapping = temp.groupby(col).size()\/len(temp)\n    temp['enc'] = temp[col].map(temp_mapping)\n    temp['enc'] = stats.rankdata(temp['enc'])\n    temp = temp.reset_index(drop=True)\n    train[f'rank_frqenc_{col}'] = temp[['enc']].values[:train.shape[0]]\n    test[f'rank_frqenc_{col}'] = temp[['enc']].values[train.shape[0]:]               \n    test[col] = test[col].astype('category')\n    train[col] = train[col].astype('category')\n","c5a2c09e":"drop_cols = list(set(drop_cols))\nprint(len(drop_cols))\ntrain = train.drop(drop_cols, axis=1)\ntest = test.drop(drop_cols, axis=1)\ntrain.shape, test.shape","0caef5dd":"def reduce_mem_usage(df: pd.DataFrame,\n                     verbose: bool = True) -> pd.DataFrame:\n    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n\n                if (c_min > np.iinfo(np.int32).min\n                      and c_max < np.iinfo(np.int32).max):\n                    df[col] = df[col].astype(np.int32)\n                elif (c_min > np.iinfo(np.int64).min\n                      and c_max < np.iinfo(np.int64).max):\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (c_min > np.finfo(np.float16).min\n                        and c_max < np.finfo(np.float16).max):\n                    df[col] = df[col].astype(np.float16)\n                elif (c_min > np.finfo(np.float32).min\n                      and c_max < np.finfo(np.float32).max):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    reduction = (start_mem - end_mem) \/ start_mem\n\n    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n    if verbose:\n        print(msg)\n\n    return df","4763bbc9":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\ngc.collect()\ntrain.shape, test.shape","2aa7e937":"evals = {}\nevals['lgb'] = {}\nlparams = {}\n\nseeds = [0, 1]\nnfold = [5, 5]\nstratified=[False, False]\nshuffle=[True, True]\nn_estimators = 30000\nearly_stopping_rounds = 300\nverbose_eval = 0\nlearning_rate = 0.01\nreg_alpha = [0.4, 1]\nreg_lambda = [0.7, 1]\nsubsample = [0.45, 1]\ncolsample_bytree = [0.3, 0.225]\nmax_depth = -1\nverbose = -1\nn_jobs = 4\n\nlparams[0] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               num_leaves= 200,\n               max_bin=500,\n               min_child_weight= 0.035,\n               subsample= subsample[0],\n               colsample_bytree= colsample_bytree[0],\n               min_data_in_leaf= 150,\n               max_depth= max_depth,\n               bagging_seed= seeds[0],\n               reg_alpha= reg_alpha[0],\n               reg_lambda= reg_lambda[0],\n               verbose= verbose,\n               seed= seeds[0],\n               n_jobs= n_jobs,)\n\nlparams[1] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               n_estimators= n_estimators,\n               subsample= subsample[1],\n               colsample_bytree= colsample_bytree[1],\n               max_depth= max_depth,\n               bagging_seed= seeds[1],\n               reg_alpha= reg_alpha[1],\n               reg_lambda= reg_lambda[1],\n               verbose= verbose,\n               seed= seeds[1],\n               n_jobs= n_jobs,)\n\ntest_preds = np.zeros(len(test))    \ndtrain = lgb.Dataset(train, y)\ndtest = test.copy()\ntestlen = test.shape[0]\ndel train, test, trainf, testf\ngc.collect()\n\n","83e8af54":"for i, seed in enumerate(seeds):\n    print(f'Training Model with SEED : {seed}')\n    evals['lgb'][i] = lgb.cv(lparams[i],\n                             dtrain,\n                             nfold=nfold[i], \n                             stratified=stratified[i],\n                             shuffle=shuffle[i],\n                             num_boost_round=n_estimators,\n                             early_stopping_rounds=early_stopping_rounds,\n                             verbose_eval=verbose_eval,\n                             return_cvbooster=True,\n                             seed = seed,\n                             show_stdv=True)\n    print(f'SEED {i} Average fold  AUC {np.round(max(evals[\"lgb\"][i][\"auc-mean\"]),5)}')\n    test_preds += stats.rankdata(np.mean(evals['lgb'][i]['cvbooster'].predict(dtest, num_iteration=evals['lgb'][i]['cvbooster'].best_iteration), axis=0)) \/ (testlen * len(seeds))","f4f648e4":"submission = pd.DataFrame.from_dict({\n    'encounter_id':test_id,\n    'diabetes_mellitus':test_preds,\n})\nsubmission.to_csv('submission.csv', index=False)\n","0441b1c7":"Reordering Columns again!","2e9373cb":"Part of FE is done in another notebook and saved in a dataset because of Memory issues. Most of Them are from [Kain's work](http:\/\/) and are two types of features: \n* data grouped by a categorical feature then mean and std of numerical columns are calculated.\n* New categorical columns created by adding two categorical columns.","b76d29f1":"**The following features are dropped with permutation importance and target permutations based on [https:\/\/www.kaggle.com\/ogrellier](https:\/\/www.kaggle.com\/ogrellier)'s work and some are highly correlated features or features with different distribution in train and test data**","ae23e7c2":"My first step in this competition was analyzing Last year's WIDS competition and after some EDA and comparing Data in hope of using 2020's data for augmenting 2021's, I reached to a conclusion that might be obvious for last year's participants. WIDS 2021 Train data is the combination of WIDS 2020's Train and Test Data with some features dropped. So the simplest path forward was checking solutions and features from last year's top solutions. My base for this notebook is [Kain's work (5 place)](https:\/\/www.kaggle.com\/kainsama\/single-lgbm-v0-1-0) and [Dan Ofer's works (1 place)](https:\/\/www.kaggle.com\/danofer\/wids-2020-competitive-1st-place-component). Also Features are borrowed from [jayjay75's work (3 place)](https:\/\/www.kaggle.com\/jayjay75\/3rd-place-nn-wids2020?scriptVersionId=29209297) and some ideas are based on [dynamic24's write-up (6 place)](https:\/\/www.kaggle.com\/c\/widsdatathon2020\/discussion\/133509).","ecc6edf3":"**Dropping Duplicated Columns**"}}