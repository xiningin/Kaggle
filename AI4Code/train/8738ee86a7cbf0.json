{"cell_type":{"db315e0b":"code","a8afe4f4":"code","3474d665":"code","aa01323e":"code","b3d47655":"code","3ac2d2f5":"code","b0651991":"code","67d455da":"code","9375f743":"code","1895f62e":"code","30b8e3d9":"code","9fb8d482":"markdown","5a087c62":"markdown","33a36345":"markdown","45d21e15":"markdown","f7584b3e":"markdown","0f023af2":"markdown","7093018f":"markdown","2cdcda52":"markdown"},"source":{"db315e0b":"!pip install -U efficientnet","a8afe4f4":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\n\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina'\n\nfolder = '\/kaggle\/input\/plant-pathology-2020-fgvc7'","3474d665":"Y = pd.read_csv(os.path.join(folder,'train.csv'))\ntrain_id = Y['image_id']\nY = Y[Y.columns[1:]] # remove image_id column\nY = Y.values # convert to array","aa01323e":"def image_resize(size, img_id):\n    '''\n    resize all images to same dimensions\n    amended from https:\/\/www.kaggle.com\/shawon10\/plant-pathology-classification-using-densenet121\n    '''\n    images=[]\n    for i, name in enumerate(img_id):\n        path=os.path.join(folder,'images',name+'.jpg')\n        img=cv2.imread(path)\n        image=cv2.resize(img,(size,size),interpolation=cv2.INTER_AREA)\n        images.append(image)\n        # print processing counter\n        if i%200==0:\n            print(i, 'images processed')\n    return images\n\n\nX = image_resize(100, train_id)\nX = np.array(X)","b3d47655":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=0)","3ac2d2f5":"aug = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                          width_shift_range=0.2, # Range for random horizontal shifts\n                          height_shift_range=0.2, # Range for random vertical shifts\n                          zoom_range=0.2, # Range for random zoom\n                          horizontal_flip=True, # Randomly flip inputs horizontally\n                          vertical_flip=True) # Randomly flip inputs vertically\n\ntrain_flow = aug.flow(X_train, Y_train, batch_size=32)","b0651991":"def model(input_shape, classes):\n    '''\n    transfer learning from imagenet's weights, using Google's efficientnet7 architecture\n    top layer (include_top) is removed as the number of classes is changed\n    '''\n    base = efn.EfficientNetB7(input_shape=input_shape, weights='imagenet', include_top=False)\n\n    model = Sequential()\n    model.add(base)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['accuracy'])\n    return model\n\n# each pic has been resized to 100x100, and with 3 channels (RGB)\ninput_shape = (100,100,3)\nclasses = 4\nmodel = model(input_shape, classes)\nmodel.summary()","67d455da":"# for every epoch, the total original images will be augmented randomly\nmodel.fit_generator(train_flow,\n                    steps_per_epoch=32,\n                    epochs=15,\n                    verbose=1,\n                    validation_data=(X_val, Y_val),\n                    use_multiprocessing=True,\n                    workers=2)","9375f743":"def plot_validate(model, loss_acc):\n    '''\n    Plot model accuracy or loss for both train and test validation per epoch\n    model : fitted model\n    loss_acc : input 'loss' or 'acc' to plot respective graph\n    '''\n    history = model.history.history\n\n    if loss_acc == 'loss':\n        axis_title = 'loss'\n        title = 'Loss'\n        epoch = len(history['loss'])\n    elif loss_acc == 'acc':\n        axis_title = 'accuracy'\n        title = 'Accuracy'\n        epoch = len(history['loss'])\n\n    plt.figure(figsize=(15,4))\n    plt.plot(history[axis_title])\n    plt.plot(history['val_' + axis_title])\n    plt.title('Model ' + title)\n    plt.ylabel(title)\n    plt.xlabel('Epoch')\n\n    plt.grid(b=True, which='major')\n    plt.minorticks_on()\n    plt.grid(b=True, which='minor', alpha=0.2)\n\n    plt.legend(['Train', 'Test'])\n    plt.show()\n\n\nplot_validate(model, 'acc')\nplot_validate(model, 'loss')","1895f62e":"# read in test images & resize\nY_test = pd.read_csv(os.path.join(folder,'test.csv'))\ntest_id = Y_test['image_id']\nX_test = image_resize(100, test_id)\nX_test = np.array(X_test)\nprint('Test images done')","30b8e3d9":"# get prediction probabilities for each class\npredict_prob = model.predict(X_test)\n\ndf_predict_prob = pd.DataFrame(predict_prob, columns=['healthy','multiple_diseases','rust','scab'])\n\n# join both image_id & df_predict_prob together for submission\nframe = [test_id, df_predict_prob]\ndf_submission = pd.concat(frame, axis=1)\ndf_submission.to_csv(r'submisson.csv', index=False)\n# df_submission.to_csv(r'\/kaggle\/working\/submisson.csv', index=False)","9fb8d482":"# Image Resizing","5a087c62":"# Plot Training Curves","33a36345":"# Image Augmentation","45d21e15":"# Model Training","f7584b3e":"# Train-Test Split","0f023af2":"# Prediction","7093018f":"# Load Labels","2cdcda52":"# Model Architecture"}}