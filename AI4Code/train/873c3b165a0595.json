{"cell_type":{"4093cf2b":"code","4174a547":"code","1e8671eb":"code","323d9753":"code","bd29a51b":"code","81e510ad":"code","677207f5":"code","8702f01d":"code","4ad9c927":"code","0e943d97":"code","0f5ffd63":"markdown"},"source":{"4093cf2b":"import os\nimport pandas as pd\nimport numpy as np\nfrom glob import  glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.dataset import Subset\nfrom torchvision import transforms as T\nfrom torch import nn\nfrom torchvision.models import resnet50\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\n\ndevice = (torch.device('cuda') if torch.cuda.is_available()\n          else torch.device('cpu'))\nprint(f'Training on device {device}.')\n\nseed = 42\ntorch.manual_seed(seed)\n\ndataset_dir = '..\/input\/petfinder-pawpularity-score\/'\nphoto_dir = '..\/input\/petfinder-pawpularity-score\/train\/'\n\nphoto_pathes = glob(os.path.join(photo_dir,'**.jpg'))\nmodel_name = 'resnet50_pretrained'\nmodel_path = model_name","4174a547":"train_df = pd.read_csv(os.path.join(dataset_dir,'train.csv'))","1e8671eb":"#imgs = torch.stack([img for img,_ in dataset],dim=3)\n#imgs.view(3,-1).mean(dim=1)\n#imgs.view(3,-1).std(dim=1)\n\nIMG_MEAN = [0.5188, 0.4840, 0.4462]\nIMG_STD = [0.2640, 0.2596, 0.2617]\n\ndef to_img_path(object_id):\n    return os.path.join(photo_dir,f'{object_id}.jpg')\n\nclass Petdataset(Dataset):\n    def __init__(self,df,is_train):\n        self.df = df\n        self.is_train = is_train\n        \n    def __getitem__(self,index):\n        \n        self.obj_path = to_img_path(self.df['Id'].iat[index])\n        img = Image.open(self.obj_path)\n        size = (224,224)\n        additional_items = (\n            [T.Resize(size)]\n            if not self.is_train\n            else [\n                T.RandomVerticalFlip(p=0.5),\n                T.RandomHorizontalFlip(p=0.5),\n                T.Resize(size)\n            ]\n        )\n        self.converter = T.Compose([*additional_items,T.ToTensor(),T.Normalize(mean=IMG_MEAN,std=IMG_STD)])\n        img = self.converter(img)\n        if self.is_train:\n            label = self.df['Pawpularity'].iat[index]\n            label = torch.tensor([label]).to(torch.float)\n            return img,label\n        else:\n            return img\n        \n    def __len__(self):\n        return len(self.df)","323d9753":"class EarlyStopping:\n    \n    def __init__(self,patience,verbose,path):\n        self.patience = patience\n        self.verbose = verbose\n        self.path = path\n        self.counter = -1\n        self.best_score = None\n        self.early_stop = False\n        \n    def __call__(self,val_loss,model):\n        \n        if self.best_score is None:\n            self.best_score = val_loss\n            self.checkpoint(val_loss,model)\n        \n        if val_loss < self.best_score:\n            self.best_score = val_loss\n            self.checkpoint(val_loss,model)\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n                \n        return self.path\n    \n    def checkpoint(self,val_loss,model):\n        torch.save(model.state_dict(),self.path)\n        self.best_score = val_loss","bd29a51b":"num_bins = int(1+np.log2(len(train_df)))\ntrain_df['bins'] = pd.cut(train_df['Pawpularity'],bins=num_bins,labels=False)\nKF = StratifiedKFold(n_splits=3,random_state=seed,shuffle=True)\n\ndataset = Petdataset(df=train_df,is_train=True)","81e510ad":"import datetime\n\ndef training_loop(n_epochs,optimizer,model,loss_fn,train_loader,val_loader,model_path,fold):\n    \n    model.train()\n    \n    earlystopping = EarlyStopping(patience=10,verbose=False,path=model_path)\n    \n    for epoch in range(1,n_epochs+1):\n        loss_train = 0.0\n        \n        for imgs,labels in train_loader:\n            imgs = imgs.to(device)\n            labels = labels.to(device)\n            outputs = model(imgs)\n            loss = loss_fn(outputs,labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            loss_train += loss.item()\n            \n        with torch.no_grad():\n            loss_val = 0.0\n            for imgs,labels in val_loader:\n                imgs = imgs.to(device)\n                labels = labels.to(device)\n                outputs = model(imgs)\n                loss = loss_fn(outputs,labels)\n                loss_val += loss.item()\n                \n        print('{},{} Fold,{} Epoch, Training loss {:.2f}, Val loss {:.2f}'.format(\n        datetime.datetime.now(),fold,epoch,\n        loss_train\/len(train_loader),\n        loss_val\/len(val_loader)\n        ))\n            \n        earlystopping((loss_val\/len(val_loader)),model)\n        if earlystopping.early_stop:\n            print('{} Fold,{} Epoch ,Early Stopping'.format(fold,epoch-earlystopping.patience))\n            break","677207f5":"model_list = []\n\nfor fold,(train_index,val_index) in enumerate(KF.split(train_df,train_df['bins'])):\n        train_dataset = Subset(dataset,train_index)\n        train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n        val_dataset = Subset(dataset,val_index)\n        val_loader = DataLoader(val_dataset,batch_size=128,shuffle=True)\n        \n        model_path = model_name+str(fold)+'.pt'\n        \n        model = resnet50()\n        model.load_state_dict(torch.load('..\/input\/resnet50\/resnet50.pth'))\n        model.fc = nn.Linear(in_features=2048,out_features=1,bias=True)\n        model.to(device)\n\n        optimizer = torch.optim.Adam(params=model.parameters(),lr=1e-4)\n        criterion = nn.MSELoss()        \n        \n        training_loop(\n            n_epochs=200,\n            optimizer=optimizer,\n            model=model,\n            loss_fn=criterion,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_path=model_path,\n            fold=fold\n        )\n        model_list.append(model_path)","8702f01d":"photo_dir = '..\/input\/petfinder-pawpularity-score\/test'\ntest_df = pd.read_csv(os.path.join(os.path.join(dataset_dir,'test.csv')))\ntest_dataset = Petdataset(df=test_df,is_train=False)\ntest_loader = torch.utils.data.DataLoader(test_dataset,batch_size=256,shuffle=False)","4ad9c927":"test_df['Pawpularity'] = 0\n\nfor i in model_list:\n    model.load_state_dict(torch.load(i))\n    predicts = np.empty(0)\n    with torch.no_grad():\n        for imgs in test_loader:\n            imgs = imgs.to(device)\n            outputs = model(imgs)\n            predicts = np.append(predicts,np.array(outputs.cpu()))\n            \n    test_df['Pawpularity'] += predicts\n    \ntest_df['Pawpularity'] = test_df['Pawpularity']\/3\nsub = test_df[['Id','Pawpularity']]\nsub.loc[sub['Pawpularity']<0,'Pawpularity'] = 0\nsub.loc[sub['Pawpularity']>100,'Pawpularity'] = 100","0e943d97":"sub.to_csv('submission.csv',index=False)","0f5ffd63":"If this notebook is useful for you in anyway, please give an upvote or commenting your gratitude on the notebook in the reference section."}}