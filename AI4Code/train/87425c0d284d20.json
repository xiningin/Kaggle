{"cell_type":{"4d3f6a4c":"code","83afe693":"code","db99c0a0":"code","e615cac5":"code","e61e70e8":"code","0532f01d":"code","5fee3bc3":"code","a830af8c":"code","f9bc157c":"code","79fdaf76":"code","40c8c676":"code","3d87a3c0":"code","db426770":"code","efe33f88":"code","9398a81a":"code","8305f0dd":"code","4ceb8d49":"code","881d0370":"code","4bf03e65":"code","07beee43":"code","508d422b":"code","4801bf97":"code","c4fe06ef":"code","369fd8e0":"code","9ce18ed2":"code","f941e861":"code","a202f9d3":"code","e4fa8f05":"code","81c7e35b":"code","335274ec":"code","21a7fd88":"code","2b277276":"code","a49ebee7":"code","e7d74212":"code","d964c3a9":"code","3da14598":"code","1f44564c":"code","a31596ad":"code","7719d1b3":"code","d892e28d":"code","0e4917a3":"code","f9b5f070":"code","e528d4d5":"code","657e6c37":"code","9286622b":"code","8c14c8f2":"code","d61bba25":"code","aa0bb455":"code","0312e5c1":"code","67f19c5a":"code","8e2bdcd7":"code","47d49e7d":"code","00a5c918":"code","e7f4268f":"code","e4689cc2":"code","873dc103":"code","d64c7a6a":"code","4f9ba994":"code","2e7de26c":"code","40929d79":"code","062fc2cc":"code","04551b7e":"code","a23dc675":"code","5e67e3a1":"code","37441452":"code","37ce0702":"code","12213ead":"code","a3b522b1":"code","52ce0b6f":"code","7d597b5f":"code","54ece524":"code","f3881eca":"code","e74828b4":"code","d7b66b95":"code","6988892f":"code","b9f78810":"code","e37dd9ba":"code","0fd7d009":"code","a5ff8908":"code","ea868920":"code","b2c8eaab":"code","e07b5057":"code","c7ef364c":"code","e61aee19":"code","ddf7147d":"code","c1a9be23":"code","7b5b80f9":"code","3ca725a6":"code","3a6eb953":"code","eefdc997":"code","45fd16c6":"code","f96b44ca":"code","3f2de496":"code","cb68b87c":"code","8032bae3":"code","511bdffd":"code","28486db9":"code","0aa4571d":"code","0568acbf":"code","10dbc8ee":"code","4adae1dc":"code","5e6fd960":"code","7d5f6016":"code","db0fa901":"code","393e013d":"code","7d5a2425":"code","0d595281":"code","0bfa2f3d":"code","099a6a7f":"code","dc7edb9f":"code","cefe91a8":"code","356cf4dd":"code","3816902e":"code","0fe5680b":"code","d2552956":"code","5301b751":"markdown","854262ff":"markdown","1bf8e642":"markdown","e29b5199":"markdown","69cd8c31":"markdown","055a1f22":"markdown","0bbf4625":"markdown","9fc04cb8":"markdown","1a2ca2e6":"markdown","81b90887":"markdown"},"source":{"4d3f6a4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83afe693":"train=pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntest=pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')","db99c0a0":"train.shape","e615cac5":"train.head()","e61e70e8":"train.isnull().sum()","0532f01d":"(train.isnull().sum()\/len(train.index))*100","5fee3bc3":"# Dropping rows having null values\n\ntrain=train.dropna(axis=0).reset_index(drop=True)","a830af8c":"(train.isnull().sum()\/len(train.index))*100","f9bc157c":"train['image_name']=train['image_name'].apply(lambda x:x+'.jpg')","79fdaf76":"test['image_name']=test['image_name'].apply(lambda x:x+'.jpg')","40c8c676":"sample_df=pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","3d87a3c0":"sample_df.head()","db426770":"train.target.value_counts()","efe33f88":"train.target.unique()","9398a81a":"import matplotlib.pyplot as plt\nimport seaborn as sns","8305f0dd":"sns.countplot(train.target)","4ceb8d49":"# import seaborn as sns\n# import matplotlib.pyplot as plt\n# import tensorflow as tf\n\n# from keras_preprocessing.image import ImageDataGenerator\n# # from keras.applications.densenet import DenseNet121\n# from keras.layers import Dense, GlobalAveragePooling2D\n# from keras.models import Model\n# from keras import backend as K\n\n# from keras.models import load_model","881d0370":"# importing few important libraries for pre-processing,generator and model building\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# from keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\n\nfrom tensorflow.keras.models import load_model","4bf03e65":"\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input,Add,Dense,Activation,ZeroPadding2D,BatchNormalization\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\n# from keras.applications import resnet50\n# from keras.applications.resnet50 import preprocess_input\nK.set_image_data_format('channels_last')\nK.set_learning_phase","07beee43":"import os","508d422b":"from tensorflow.keras.applications.resnet50  import ResNet50","4801bf97":"def checkLeakage(df1,df2,patient):\n    df1_unique = set(df1[patient].values)\n    df2_unique = set(df2[patient].values)\n    \n    patients_in_train_test = list(df1_unique.intersection(df2_unique))\n    if len(patients_in_train_test)>0:\n        leakage = True# boolean (true if there is at least 1 patient in both groups)\n        print(patients_in_train_test)\n    else:\n        leakage=False\n    \n    \n    return leakage","c4fe06ef":"checkLeakage(train,test,'patient_id')","369fd8e0":"def train_val_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 240, target_h = 240):\n        print(\"getting train generator...\") \n    # normalize images\n        image_generator = ImageDataGenerator(\n            samplewise_center=True,\n            samplewise_std_normalization= True,\n            zoom_range=0.2,\n            shear_range=0.2,\n            validation_split=0.25)\n    \n    # flow from directory with specified batch size\n    # and target image size\n        train_generator = image_generator.flow_from_dataframe(\n            dataframe=train,\n            directory=image_dir,\n            validation_split=0.25,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode='raw',\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            validate_filenames=True,\n            subset='training',\n            target_size=(target_w,target_h))\n        \n        valid_generator=image_generator.flow_from_dataframe(\n            dataframe=train,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            validate_filenames=False,\n            batch_size=32,\n            shuffle=False,\n            class_mode='raw',\n            seed=seed,\n            subset='validation',\n            target_size=(target_w,target_h))\n        \n        return train_generator,valid_generator\n    \n    ","9ce18ed2":"IMAGE_DIR = \"..\/input\/siim-isic-melanoma-classification\/jpeg\/train\"\n","f941e861":"os.makedirs('saved_models_noFold')","a202f9d3":"def get_model():\n    \n#     image_input=Input(shape=(240, 240, 3))\n    base_model= ResNet50(weights='imagenet',include_top=False,input_shape=(240,240,3))\n    for layer in base_model.layers:\n        layer.trainable=False\n        \n#     Get base model output\n\n    base_model_output=base_model.output\n    \n#     Adding our own layers\n\n    x=GlobalAveragePooling2D()(base_model_output)\n#     adding fully connected layers\n\n    x=Dense(512,activation='relu')(x)\n    x=Dense(1,activation='sigmoid',name='fcnew')(x)\n    \n    model=Model(base_model.input,x)\n    \n    return model","e4fa8f05":"get_model()","81c7e35b":"# Creating a function control gradient descent rate\n# Initially we will keep the loss high \n# will decrease it with the training\ndef lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr\n","335274ec":"from sklearn.utils import class_weight","21a7fd88":"train_data,valid_data=train_val_generator(train, IMAGE_DIR, \"image_name\", 'target')","2b277276":"train_data.labels","a49ebee7":"class_weights = class_weight.compute_class_weight('balanced',np.unique(train_data.labels),train_data.labels)","e7d74212":"class_weights_map={0:class_weights[0],1:class_weights[1]}","d964c3a9":"class_weight_map={}","3da14598":"import tensorflow","1f44564c":"import math","a31596ad":"# get model\n\nmodel=get_model()\n\nbatch_size=32\n\n\n\n# Compile the model\n\nmodel.compile(loss='binary_crossentropy',optimizer ='sgd',metrics=[tf.keras.metrics.AUC()])\n\nmodel.summary()","7719d1b3":"\n\ncheckpoint = tensorflow.keras.callbacks.ModelCheckpoint('saved_models_noFold'+'.h5', verbose=1,save_best_only=True)\n\ncallbacks_list = [checkpoint]\n\n# model.compile(loss=get_weighted_loss(pos_weights,neg_weights),optimizer ='sgd',metrics=['accuracy'])\n\n\n\nhistory = model.fit_generator(train_data,\n                              validation_data=valid_data,\n                              steps_per_epoch=int(math.ceil(1. * len(train_data)\/\/ batch_size)),\n                              validation_steps=int(math.ceil(1. * len(valid_data)\/\/ batch_size)),\n                              callbacks=callbacks_list,\n                              class_weight=class_weights_map,\n#                                   workers=1,                        # maximum number of processes to spin up when using process-based threading\n#                                   use_  multiprocessing=False,\n                              epochs =10)\n\n","d892e28d":"model.load_weights(\"saved_models_noFold.h5\")","0e4917a3":"# Writing test generator\ndef test_generator(df,image_dir, x_col, shuffle=False, seed=1, target_w = 240, target_h = 240):\n        print(\"getting test generator...\") \n        print(image_dir)\n    # normalize images\n        image_generator = ImageDataGenerator(rescale=1\/255)\n        \n        \n        test_generator = image_generator.flow_from_dataframe(\n            dataframe=test,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=None,\n#             classes=['test'],\n#             x_col=x_col,\n#             y_col=y_cols,\n            class_mode=None,\n#             batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n        \n        return test_generator\n","f9b5f070":"test_path='..\/input\/siim-isic-melanoma-classification\/jpeg\/test'","e528d4d5":"test.head()","657e6c37":"test_gen=test_generator(test,test_path, \"image_name\",target_w = 240, target_h = 240)","9286622b":"# type(test_gen)","8c14c8f2":"predicted_vals = model.predict_generator(test_gen,verbose=1)","d61bba25":"test.shape","aa0bb455":"len(predicted_vals)","0312e5c1":"l=test['image_name'].apply(lambda x:x.split('.jpg'))","67f19c5a":"img=[im[0] for im in l]","8e2bdcd7":"img.index","47d49e7d":"img","00a5c918":"test_sub=test['image_name']","e7f4268f":"img","e4689cc2":"submission_df=pd.DataFrame({'image_name':img})","873dc103":"submission_df.head()","d64c7a6a":"submission_df['target']=predicted_vals","4f9ba994":"submission_df.to_csv('submission.csv', index=False)","2e7de26c":"!ls -ltr\n","40929d79":"sample_df.head()","062fc2cc":"test_sub['target']=pd.DataFrame(data=predicted_vals)","04551b7e":"test_sub.head()","a23dc675":"predicted_class_indices = np.argmax(predicted_vals, axis=1)\n# labels = train_gen.class_indices\npredictions = [labels[k] for k in predicted_class_indices]\n\ntest_df['target'] = pd.DataFrame(data=predictions)\n# submission_df.to_csv('submission.csv', index=False)","5e67e3a1":"# Compile the model\n    model.compile(loss='binary_crossentropy',optimizer ='sgd',metrics=[tf.keras.metrics.AUC()])\n    # CREATE CALLBACKS\n\t\n    checkpoint = keras.callbacks.ModelCheckpoint('model_'+str(fold_var)+'.h5', verbose=1,save_best_only=True)\n    \n    callbacks_list = [checkpoint]\n    \n    train_data_generator=train_val_generator(train, IMAGE_DIR, \"image_name\", 'target')\n    \n    history = model.fit_generator(train_data_generator,validation_data=valid_data_generator,\n                                  steps_per_epoch=int(math.ceil(1. * X_train.shape[0] \/\/ batch_size)),\n                                  validation_steps=int(math.ceil(1. * X_Val.shape[0] \/\/ batch_size)),\n                                  callbacks=callbacks_list,\n                                  class_weight=class_weights,\n#                                   workers=1,                        # maximum number of processes to spin up when using process-based threading\n                                  use_multiprocessing=False,\n                                  epochs =10)\n    \n    # LOAD BEST MODEL to evaluate the performance of the model\n   \n\t\n    model.load_weights(\"model_\"+str(fold_var)+\".h5\")\n\t","37441452":"# Implementing stratified K-fold for best model\n\nfrom sklearn.model_selection import StratifiedKFold","37ce0702":"X =train.loc[:, ~train.columns.isin(['target'])].copy()\ny = train['target']\nskf = StratifiedKFold(n_splits=10,shuffle=False)\nskf.get_n_splits(X, y)","12213ead":"X.index\n","a3b522b1":"y.index","52ce0b6f":"print(skf)","7d597b5f":"X.head()","54ece524":"y.value_counts()","f3881eca":"import os","e74828b4":"os.makedirs('saved_models')","d7b66b95":"!cd ..\/..\/outputs\/saved_models\n# ..\/input\/siim-isic-melanoma-classification","6988892f":"!ls -ltr","b9f78810":"!cd saved_models","e37dd9ba":"!ls -ltr\n!pwd","0fd7d009":"# create the base pre-trained model\n# base_model = DenseNet121(weights='.\/nih\/densenet.hdf5', include_top=False)\n\n# x = base_model.output\n\n# # add a global spatial average pooling layer\n# x = GlobalAveragePooling2D()(x)\n\n# # and a logistic layer\n# predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n\n# model = Model(inputs=base_model.input, outputs=predictions)\n# model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input,Add,Dense,Activation,ZeroPadding2D,BatchNormalization\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\n# from keras.applications import resnet50\n# from keras.applications.resnet50 import preprocess_input\nK.set_image_data_format('channels_last')\nK.set_learning_phase","a5ff8908":"from tensorflow.keras.applications.resnet50  import ResNet50\n# from tensorflow.keras.preprocessing import image\n# from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions","ea868920":"from tensorflow.keras import backend\n","b2c8eaab":"tf.keras.applications.ResNet50","e07b5057":"\ndef get_model():\n    \n#     image_input=Input(shape=(240, 240, 3))\n    base_model= ResNet50(weights='imagenet',include_top=False,input_shape=(240,240,3))\n    for layer in base_model.layers:\n        layer.trainable=False\n        \n#     Get base model output\n\n    base_model_output=base_model.output\n    \n#     Adding our own layers\n\n    x=GlobalAveragePooling2D()(base_model_output)\n#     adding fully connected layers\n\n    x=Dense(512,activation='relu')(x)\n    x=Dense(1,activation='sigmoid',name='fcnew')(x)\n    \n    model=Model(base_model.input,x)\n    \n    return model","c7ef364c":" model=get_model()","e61aee19":"# Writing function so that we speed up training \n# We will keep the learning rate high when the loss is high \n# As the loss decreases we will reduce the learning rate\n\n","ddf7147d":"from sklearn.utils import class_weight","c1a9be23":"VALIDATION_ACCURACY = []\nVALIDAITON_LOSS = []\n\nsave_dir = 'saved_models'\nfold_var = 1\n","7b5b80f9":"image_generator = ImageDataGenerator(\n            samplewise_center=True,\n            samplewise_std_normalization= True,\n            zoom_range=0.2,\n            shear_range=0.2)","3ca725a6":"import keras","3a6eb953":"train.shape","eefdc997":"import math","45fd16c6":"for train_index, val_index in skf.split(X, y):\n#     print(\"TRAIN:\", train_index, \"val:\", val_index)\n    batch_size=32\n    X_train, X_Val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n    train_df=pd.concat([X_train, y_train],axis=1)\n    val_df=pd.concat([X_Val, y_val],axis=1)\n#     train_generator,valid_generator =train_val_generator(train_df, IMAGE_DIR, \"image_name\", 'target',val_df)\n    train_data_generator = image_generator.flow_from_dataframe(train_df,\n                                                               directory = IMAGE_DIR,\n                                                               x_col = \"image_name\",\n                                                               y_col = \"target\",\n                                                               class_mode = \"raw\",\n                                                               batch_size=batch_size, target_size=(240,240),\n                                                               shuffle = True)\n    \n    valid_data_generator  = image_generator.flow_from_dataframe(val_df, \n                                                                directory = IMAGE_DIR,\n                                                                x_col = \"image_name\",\n                                                                y_col = \"target\",\n                                                                class_mode = \"raw\", \n                                                                batch_size=batch_size, \n                                                                target_size=(240,240),\n                                                                shuffle = True)\n    \n    class_weights = class_weight.compute_class_weight('balanced',np.unique(train_data_generator.labels),train_data_generator.labels)\n# create model \n    model=get_model()\n\n# Compile the model\n    model.compile(loss='binary_crossentropy',optimizer ='sgd',metrics=[tf.keras.metrics.AUC()])\n    # CREATE CALLBACKS\n\t\n    checkpoint = keras.callbacks.ModelCheckpoint('model_'+str(fold_var)+'.h5', verbose=1,save_best_only=True)\n    \n    callbacks_list = [checkpoint]\n    \n    history = model.fit_generator(train_data_generator,validation_data=valid_data_generator,\n                                  steps_per_epoch=int(math.ceil(1. * X_train.shape[0] \/\/ batch_size)),\n                                  validation_steps=int(math.ceil(1. * X_Val.shape[0] \/\/ batch_size)),\n                                  callbacks=callbacks_list,\n                                  class_weight=class_weights,\n#                                   workers=1,                        # maximum number of processes to spin up when using process-based threading\n                                  use_multiprocessing=False,\n                                  epochs =10)\n    \n    # LOAD BEST MODEL to evaluate the performance of the model\n   \n\t\n    model.load_weights(\"model_\"+str(fold_var)+\".h5\")\n\t\n    results = model.evaluate(valid_data_generator)\n    \n    results = dict(zip(model.metrics_names,results))\n\t\n    VALIDATION_ACCURACY.append(history.history['val_loss'])\n    VALIDATION_LOSS.append(history.history['val_acc'])\n\t\n    fold_var += 1\n    \n","f96b44ca":"train_generator,valid_generator =train_val_generator(train, IMAGE_DIR, \"image_name\", 'target')","3f2de496":"\nx, y = train_generator.__getitem__(0)\nplt.imshow(x[0]);","cb68b87c":"import glob","8032bae3":"# print(glob.glob(\"..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/*.jpg\"))\n\ndef compute_class_freqs(labels):\n    \"\"\"\n    Compute positive and negative frequences for each class.\n\n    Args:\n        labels (np.array): matrix of labels, size (num_examples, num_classes)\n    Returns:\n        positive_frequencies (np.array): array of positive frequences for each\n                                         class, size (num_classes)\n        negative_frequencies (np.array): array of negative frequences for each\n                                         class, size (num_classes)\n    \"\"\"\n    \n    # total number of patients (rows)\n    N = labels.shape\n    \n    \n    positive_frequencies = np.sum(labels,axis=0)\/N[0]\n    negative_frequencies = (N[0]-np.sum(labels,axis=0))\/N[0]\n\n    return positive_frequencies, negative_frequencies","511bdffd":"# Function to get weight loss which we will be used for training model\n\ndef get_weighted_loss(pos_weights,neg_weight,epsilon=1e-7):\n    def weighted_loss(pred_pos,pred_neg):\n        loss=0#initialising the loss to 0\n        loss +=  K.mean(pos_weights * np.array(train['target'])*K.log(y_pred_1+epsilon) + neg_weights*(1- np.array(train['target'])*K.log(1-y_pred_2+epsilon)))\n        return loss       \n        \n    return weighted_loss","28486db9":"# create the base pre-trained model\n# base_model = DenseNet121(weights='.\/nih\/densenet.hdf5', include_top=False)\n\n# x = base_model.output\n\n# # add a global spatial average pooling layer\n# x = GlobalAveragePooling2D()(x)\n\n# # and a logistic layer\n# predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n\n# model = Model(inputs=base_model.input, outputs=predictions)\n# model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))\n\nfrom keras import layers\nfrom keras.layers import Input,Add,Dense,Activation,ZeroPadding2D,BatchNormalization\nfrom keras import optimizers\nfrom keras.layers import Dense,Dropout,Flatten\n# from keras.applications import resnet50\n# from keras.applications.resnet50 import preprocess_input\nK.set_image_data_format('channels_last')\nK.set_learning_phase\n","0aa4571d":"from keras.applications import ResNet50\n# from tensorflow.keras.preprocessing import image\n# from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions","0568acbf":"# ! wget https:\/\/storage.googleapis.com\/tensorflow\/keras-applications\/resnet\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5","10dbc8ee":"\n\ndef get_model():\n    \n    base_model= ResNet50(weights='imagenet',include_top=False)\n    for layer in base_model.layers:\n        layer.trainable=False\n        \n#     Get base model output\n\n    base_model_output=base_model.output\n    \n#     Adding our own layers\n\n    x=GlobalAveragePooling2D()(base_model_output)\n#     adding fully connected layers\n\n    x=Dense(512,activation='relu')(x)\n    x=Dense(1,activation='sigmoid',name='fcnew')(x)\n    \n    model=Model(input=base_model.input,output=x)\n    \n    return model","4adae1dc":"set(train_generator.labels)","5e6fd960":"freq_pos, freq_neg = compute_class_freqs(train_generator.labels)\nfreq_pos","7d5f6016":"freq_neg","db0fa901":"pos_weights = freq_neg\nneg_weights = freq_pos\npos_contribution = freq_pos * pos_weights \nneg_contribution = freq_neg * neg_weights","393e013d":"pos_weights","7d5a2425":"from sklearn.utils import class_weight","0d595281":"class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_generator.labels),\n                                                 train_generator.labels)","0bfa2f3d":"class_weights","099a6a7f":"class_weights={0:class_weights[0],1:class_weights[1]}","dc7edb9f":"# y_pred_1  = K.constant(pos_weights*np.array(train['target']).reshape(33126,1))","cefe91a8":"\n# y_pred_2  = K.constant(neg_weights*np.array(train['target']).reshape(33126,1))","356cf4dd":"# data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n# data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n# plt.xticks(rotation=90)\n# f = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)","3816902e":"# get model\n\nmodel=get_model()\n\n# Compile the model\n\nmodel.compile(loss='binary_crossentropy',optimizer ='sgd',metrics=['accuracy'])\n\n# model.compile(loss=get_weighted_loss(pos_weights,neg_weights),optimizer ='sgd',metrics=['accuracy'])\n\nmodel.summary()","0fe5680b":"history = model.fit_generator(train_generator, \n                              steps_per_epoch=100,\n                              class_weight=class_weights,\n                              epochs =10)","d2552956":"plt.plot(history.history['loss'])\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.title(\"Training Loss Curve\")\nplt.show()","5301b751":"### Reading Data","854262ff":"#### In the first part we will do build model without using any folds ,however in the second part we will improve it using stratified K-fold","1bf8e642":"## Checking Data leakage\n\nThere is a possible case that the image can be of same patient in training and test data ,we avoid it ","e29b5199":"# Preparing Images","69cd8c31":"## Train and Validation Generator","055a1f22":"There is high class imbalance ,we will try to deal with this using weighted loss ","0bbf4625":"## Checking class imbalance","9fc04cb8":"### As I will be using Keras to for implement Image Datagenerator and model building ,so the image so I will append .jpg in file ,so that it can be used with flow_from_dataframe method","1a2ca2e6":"### Checking for null values in data","81b90887":"### Importing important Libraries\n\n"}}