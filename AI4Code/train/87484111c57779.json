{"cell_type":{"0dd5d7cf":"code","8faf8871":"code","159a7761":"code","8baa77e6":"code","408bbb7d":"code","2a9760a0":"code","41f65cec":"code","c987bf0f":"code","cbceee6f":"code","cb4b0fff":"code","42cf0856":"code","16d94fff":"code","baa3964c":"code","192e5e77":"code","24bde09d":"code","bd0daf34":"code","a8e507d0":"code","a7495524":"code","272cbcb6":"code","a4967911":"code","b23ec47e":"code","c5a22b8e":"code","20dfa2f2":"code","d8df49ea":"code","d9095db5":"code","897f5242":"code","5c536fe1":"markdown"},"source":{"0dd5d7cf":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n!pip install py7zr\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom py7zr import unpack_7zarchive\nimport shutil\nimport os\nshutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\n","8faf8871":"shutil.unpack_archive('\/kaggle\/input\/cifar-10\/train.7z', '\/kaggle\/working')","159a7761":"train_dir = os.listdir(\".\/train\");\ntrain_dir_len = len(train_dir)\nprint(\".\\\\train:\\t\",train_dir_len)\nprint(\"files:\\t\\t\",train_dir[:3])","8baa77e6":"train_labels = pd.read_csv('\/kaggle\/input\/cifar-10\/trainLabels.csv',dtype=str)\ntrain_images = pd.DataFrame(columns = ['id','label','path'],dtype=str)\ntest_labels = pd.read_csv('\/kaggle\/input\/cifar-10\/sampleSubmission.csv')\ntrain_labels.info()","408bbb7d":"path_base = '\/kaggle\/working\/train\/'\n\nfor index in range(0,train_dir_len):\n    path = path_base + str(index+1)+'.png'\n    if os.path.exists(path):\n        train_images = train_images.append([{ 'id': str(train_labels['id'].iloc[index]),'path': path, 'label':train_labels['label'].iloc[index]}])\n        \ntrain_images.head(2)","2a9760a0":"train_images.head(2)","41f65cec":"display_groupby = train_images.groupby(['label']).count()\ndisplay_groupby.head(10)","c987bf0f":"class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\nfor name in  class_names:\n    index = class_names.index(name)\n    train_images.loc[train_images.label==name,'label'] = str(index)\n        \ndisplay_groupby = train_images.groupby(['label']).count()\ndisplay_groupby.head(10)","cbceee6f":"path_base = '\/kaggle\/working\/train'\nbatch_size = 64\ntrain_data_generator = ImageDataGenerator(\n            rescale=1.\/255.,\n            validation_split=0.2,\n            horizontal_flip=True\n            )\ntrain_generator = train_data_generator.flow_from_dataframe(dataframe=train_images,\n            directory=\".\/train\/\",\n            x_col=\"path\",\n            y_col=\"label\",\n            subset=\"training\",\n            batch_size=batch_size,\n            shuffle=True,\n            target_size=(32,32),\n            class_mode=\"categorical\")","cb4b0fff":"num_classes  = 10","42cf0856":"validation_generator = train_data_generator.flow_from_dataframe(dataframe=train_images,\n            directory=\".\/train\/\",\n            x_col=\"path\",\n            y_col=\"label\",\n            subset=\"validation\",\n            batch_size=batch_size,\n            shuffle=True,\n            target_size=(32,32),\n            class_mode=\"categorical\")","16d94fff":"train_size = len(train_generator.filenames)\nvalidation_size = len(validation_generator.filenames)\nprint('validation_size:\\t',validation_size)\nprint('train_size:\\t\\t',train_size)","baa3964c":"index = 0    \nfig = plt.figure(figsize = (16,10))\nfor item in train_images.values[:20]:\n    index += 1\n    plt.subplot(5, 5, index)\n    test_path = item[2]\n    test_image = load_img(test_path, target_size=(32,32))\n    plt.imshow(test_image)\n    plt.colorbar()\n    plt.grid(False)\n    plt.axis(\"off\")\n    plt.title(class_names[int(item[1])])\nplt.show()","192e5e77":"keras.backend.clear_session()\n\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32,  3)))\n\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Conv2D(64, (2, 2), activation='relu',padding='same'))\nmodel.add(keras.layers.MaxPooling2D(1, 1))\nmodel.add(keras.layers.Dropout(0.1))\n\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same'))\nmodel.add(keras.layers.MaxPooling2D(2, 2))\nmodel.add(keras.layers.Dropout(0.2))\n\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Conv2D(64, (2, 2), activation='relu',padding='same'))\nmodel.add(keras.layers.MaxPooling2D(1, 1))\nmodel.add(keras.layers.Dropout(0.1))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(64, activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Dropout(0.2))\n\nmodel.add(keras.layers.Dense(10, activation=\"softmax\"))\n\nmodel.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n          optimizer=keras.optimizers.RMSprop(lr=0.001, decay = 1e-3, momentum = 0.3),\n          metrics=['accuracy'])\n    \nmodel.input ","24bde09d":"\nhistory = model.fit(train_generator, \n                    steps_per_epoch=(train_size\/\/batch_size),\n                    epochs= 5,\n                    validation_data=validation_generator,\n                   validation_steps=(validation_size\/\/batch_size)\n                   )","bd0daf34":"test_labels.head(2)","a8e507d0":"if os.path.exists(\".\/test\"):\n    shutil.rmtree(\".\/test\")\nif os.path.exists(\".\/train\"):\n    shutil.rmtree(\".\/train\")\nif not os.path.exists(\".\/data\"):\n    os.mkdir(\".\/data\")\n\nshutil.unpack_archive('\/kaggle\/input\/cifar-10\/test.7z', '\/kaggle\/working\/data')","a7495524":"test_dir = os.listdir(\".\/data\/test\");\ntest_dir_len = len(test_dir)\nprint('min:\\t',min(test_dir))\nprint('max:\\t',max(test_dir))\nprint(\".\\\\test:\\t\",test_dir_len)\nprint(\"files:\\t\\t\",test_dir[:3])","272cbcb6":"test_data_generator = ImageDataGenerator(rescale=1.\/255.)\ntest_generator = test_data_generator.flow_from_directory(directory='\/kaggle\/working\/data',\n            batch_size=batch_size,\n            shuffle=False,color_mode='rgb',\n            target_size=(32,32),\n            class_mode=None)","a4967911":"predict_test = model.predict_generator(test_generator)","b23ec47e":"predict_generator = np.argmax(predict_test, axis=1)\nprint(class_names)\npredict_generator[:2],[class_names[int(i)] for i in predict_generator[:2]]","c5a22b8e":"submission = pd.DataFrame(columns = ['id','label'],dtype=str)\nsubmission[\"label\"] = [class_names[int(i)] for i in predict_generator]\nsubmission[\"id\"] = [ (''.join(filter(str.isdigit, name ))) for name in test_generator.filenames]\nsubmission.head(101)","20dfa2f2":" submission.values[50:100]","d8df49ea":"index = 0    \nfig = plt.figure(figsize = (16,10))\nfor item in submission.values[50:70]:\n    index += 1\n    plt.subplot(5, 5, index)\n    test_path = '\/kaggle\/working\/data\/test\/'+item[0]+'.png'\n    test_image = load_img(test_path, target_size=(32,32))\n    plt.imshow(test_image)\n    plt.colorbar()\n    plt.grid(False)\n    plt.axis(\"off\")\n    plt.title(item[1])\nplt.show()","d9095db5":"submission.to_csv(\"submission.csv\",index=False)","897f5242":" shutil.rmtree(\".\/data\")","5c536fe1":"CIFAR-10  is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. It was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton."}}