{"cell_type":{"3fcce943":"code","3bd511ac":"code","a766ff2c":"code","782d8285":"code","931b1a54":"code","fb2d2b05":"code","688f1d2f":"code","cd393d67":"code","af314424":"code","518de4db":"code","ffa60270":"code","4f8c9d7b":"code","ad825930":"code","4a260b5f":"code","440af4be":"code","faa1ccfb":"code","72712a1d":"code","a6c47d47":"code","6464bcb7":"code","29056570":"code","fb6eab94":"code","3fc31628":"code","154fe639":"code","f869f7df":"code","ad1ff45d":"code","f0171b63":"code","ddc87c30":"code","4bd8b3be":"code","c215e1e0":"code","e3566863":"code","63de17a7":"markdown","185ed5b5":"markdown","7a2c8d67":"markdown","9457f41f":"markdown","f5097acc":"markdown","66594293":"markdown"},"source":{"3fcce943":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3bd511ac":"import zipfile\nwith zipfile.ZipFile(\"\/kaggle\/input\/instacart-market-basket-analysis\/aisles.csv.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\".\/\")\nwith zipfile.ZipFile(\"\/kaggle\/input\/instacart-market-basket-analysis\/orders.csv.zip\",\"r\") as zip_ref:    \n    zip_ref.extractall(\".\/\")\nwith zipfile.ZipFile(\"\/kaggle\/input\/instacart-market-basket-analysis\/departments.csv.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\".\/\")\nwith zipfile.ZipFile(\"\/kaggle\/input\/instacart-market-basket-analysis\/products.csv.zip\",\"r\") as zip_ref:    \n    zip_ref.extractall(\".\/\")\nwith zipfile.ZipFile(\"\/kaggle\/input\/instacart-market-basket-analysis\/order_products__train.csv.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\".\/\")\nwith zipfile.ZipFile(\"\/kaggle\/input\/instacart-market-basket-analysis\/order_products__prior.csv.zip\",\"r\") as zip_ref:    \n    zip_ref.extractall(\".\/\")\n    \n# zip \uc555\ucd95\ud480\uae30\n# \ud604\uc7ac\uc704\uce58\uc778 output_kaggle\uc5d0 csv \ud30c\uc77c \uc800\uc7a5","a766ff2c":"import pandas as pd\naisles = pd.read_csv('aisles.csv')\norders = pd.read_csv('orders.csv')\nproducts = pd.read_csv('products.csv')\ndepartments = pd.read_csv('departments.csv')\norder_products__prior = pd.read_csv('order_products__prior.csv')\norder_products__train = pd.read_csv('order_products__train.csv')","782d8285":"aisles","931b1a54":"departments","fb2d2b05":"products\n# products\uc5d0 aisle\uacfc department\uac00 \uc5f0\uacb0\ub418\uc5b4 \uc788\uc74c.","688f1d2f":"df_product1 = pd.merge(products, aisles, on=\"aisle_id\")\ndf_product1","cd393d67":"df_product2 = pd.merge(df_product1, departments, on=\"department_id\")\ndf_product2\n# product_id\ub97c key\ub85c \uc0ac\uc6a9\ud558\uc5ec aisles,departments\ub97c products\uc5d0 merge.","af314424":"orders","518de4db":"orders['user_id'].value_counts()\n# \uc8fc\ubb38\ub0b4\uc5ed\uc744 user_id\ub85c count \ud574\ubcf4\uba74 206209\uba85\uc758 \uace0\uac1d \uc815\ubcf4\uac00 \uc788\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc74c.\n# \uac01 \uace0\uac1d \ud55c\uba85\ub2f9 \uc8fc\ubb38\uac74\uc218\uac00 4\ubc88\uc5d0\uc11c \ubd80\ud130 100\ubc88\uae4c\uc9c0 \uc788\uc74c.\n# \ucd1d \uc8fc\ubb38\uac74\uc218\ub294 3421083\uac1c","ffa60270":"orders.eval_set.value_counts()\n# \ucd1d 206209\uba85\uc758 \uace0\uac1d \uc911 train \ud560 \uace0\uac1d\uc740 131209\uba85\uc774\uace0 test\ud560 \uace0\uac1d\uc740 75000\uba85\uc774\ub2e4.","4f8c9d7b":"order_products__prior\n# \uc6d0\ubcf8 \ub370\uc774\ud130(\ubaa8\uc9d1\ub2e8)\n# fit, predict \ubaa8\ub378 \uac80\uc99d \ub05d\ub09c\ud6c4\uc5d0","ad825930":"order_products__train\n# \ubaa8\ub378 \uac80\uc99d\uc744 \uc704\ud55c \uc0d8\ud50c \ub370\uc774\ud130(\ud45c\ubcf8)","4a260b5f":"df_product2","440af4be":"df_order_product = pd.merge(order_products__train, df_product2, on=\"product_id\")\ndf_order_product","faa1ccfb":"df0 = pd.merge(orders, df_order_product, on=\"order_id\")\ndf0\n# \ubaa8\ub4e0 \ub370\uc774\ud130 \ub2e4 merge \ud55c \uac83.","72712a1d":"df.keys()\n# order_number: \uc8fc\ubb38\ud55c \ud69f\uc218\n# order_dow: \uc8fc\ubb38\ud55c \uc694\uc77c\n# order_hour_of_day: \ud558\ub8e8 \uc911 \uc8fc\ubb38\ud55c \uc2dc\uac01","a6c47d47":"# columns \uc815\ub9ac\ud558\uae30(\uc21c\uc11c\ubcc0\uacbd, \uc0ad\uc81c)\n\ndf1 = df0[['user_id', 'order_id', 'order_number', 'order_dow',\n       'order_hour_of_day',\n       'add_to_cart_order', 'reordered', 'product_id', 'product_name', 'aisle_id', 'aisle',\n       'department_id', 'department']]\n\n# days_since_prior_order: \ubaa9\ud45c\uac00 \ub2e4\uc74c\uc5d0 \uc8fc\ubb38\ud560 \uac83\uc774 \ubb34\uc5c7\uc77c\uc9c0 \uc608\uce21\ud558\ub294 \uac83\uc774\uae30 \ub54c\ubb38\uc5d0 \ud544\uc694\uc5c6\ub294 \uceec\ub7fc\uac19\uc74c.","6464bcb7":"df['eval_set'].value_counts()\n# df\ub294 orders\uc5d0\uc11c train \ub370\uc774\ud130\ub9cc \ubaa8\uc544\ub193\uc740 \uac83.\n# ['eval_set'] \uceec\ub7fc \uc0ad\uc81c\ud574\ub3c4 \ub428.","29056570":"df1\n# \uc804\ucc98\ub9ac \ub05d","fb6eab94":"df1.keys()\n\n# \uc885\uc18d\ubcc0\uc218: 'reordered' \n# 0,1\ub85c \ub098\ub204\uc5b4\uc9c0\ub294 \ubc94\uc8fc\ud615 \ubcc0\uc218\n\n# \ub3c5\ub9bd\ubcc0\uc218: 'user_id', 'order_id', 'order_number', 'order_dow', 'order_hour_of_day','product_id', 'product_name', 'aisle_id', 'aisle', 'department_id', 'department'\n# \uc5f0\uc18d\ud615\uacfc \ubc94\uc8fc\ud615\uc774 \uc11e\uc5ec\uc788\uc74c.","3fc31628":"df2 = df1[['user_id', 'order_number', 'order_dow', 'order_hour_of_day', 'product_name', 'aisle', 'department', 'reordered']]\ndf2","154fe639":"df2.to_csv('df2.csv')\n\n# jamovi\ub85c \ud655\uc778\ud574\ubcf4\uae30","f869f7df":"# Elbow Method\nfrom sklearn.cluster import KMeans\ndistortions = []\nfor i in range(1,5):\n    kmeans = KMeans(n_clusters=i, n_init=10, max_iter=300)\n    kmeans.fit(df2)\n    distortions.append(kmeans.inertia_)\n\nimport matplotlib.pyplot as plt\nplt.plot(range(1,5), distortions, marker='o')\nplt.show()  # \uaebd\uc778 \ubd80\ubd84 \ucc3e\uae30\n\n# # Silhouette\n# from sklearn.cluster import KMeans\n# kmeans = KMeans(n_clusters=2, max_iter=300)\n# labels = kmeans.fit_predict(squad)\n# target = pd.DataFrame(kmeans.labels_, columns=['reordered'])","ad1ff45d":"# \uc885\uc18d\ubcc0\uc218, \ub3c5\ub9bd\ubcc0\uc218 \uc9c0\uc815\ud558\uae30\ny = df2['reordered']\nx = df2[['user_id', 'order_number', 'order_dow', 'order_hour_of_day', 'product_name', 'aisle', 'department']]\nx_dummies = pd.get_dummies(x[['order_dow','order_hour_of_day','product_name','aisle','department']], drop_first=True)\nnew_x = pd.concat([df2['user_id'],x_dummies],axis=1)\n\nfrom sklearn.model_selection import train_test_split\nx_train0, x_test0, y_train0, y_test0 = train_test_split(new_x, y, test_size=0.5)\n\n# sample size\ub85c \ub370\uc774\ud130 \uc591 \uc904\uc774\uae30(0.25 \uc218\uc900)\n# \ubaa8\ub378\ub9c1 \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \uc704\ud55c \ucabc\uac1c\uae30 \uc791\uc5c5\nx_train, x_test, y_train, y_test = train_test_split(x_train0, y, test_size=0.3)\n\n# StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.fit_transform(x_test)","f0171b63":"x_train = pd.read_csv('')\nx_test\ny_train\ny_test","ddc87c30":"# VotingClassifier() with No_params\n# voting(hard, soft)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nclflog = LogisticRegression()\nclfrf = RandomForestClassifier()\nclfgn = GaussianNB()\nclfsvc = SVC()\nclfknn = KNeighborsClassifier()\n\nfrom sklearn.ensemble import VotingClassifier\neclf_h = VotingClassifier(estimators = [('lr',clflog),('rf',clfrf),('gnb',clfgn),('svc',clfsvc),('knn',clfknn)], voting='hard')\neclf_s = VotingClassifier(estimators = [('lr',clflog),('rf',clfrf),('gnb',clfgn),('svc',clfsvc),('knn',clfknn)], voting='soft')\n\nfrom sklearn.metrics import classification_report\nmodels = [clflog, clfrf, clfgn, clfsvc, clfknn, eclf_h, eclf_s]\n\nfor model in models:\n    model.fit(x_train,y_train)\n    predictions = model.predict(x_test)\n    score = model.score(x_test,y_test)\n    print(classification_report(y_test,predictions))","4bd8b3be":"# VotingClassifier(hard)\n# GridSearchCV\n# best_params_\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nclflog = LogisticRegression()\nclfrf = RandomForestClassifier()\nclfgn = GaussianNB()\nclfsvc = SVC()\nclfknn = KNeighborsClassifier()\n\nfrom sklearn.ensemble import VotingClassifier\neclf_h = VotingClassifier(estimators = [('lr',clflog),('rf',clfrf),('gnb',clfgn),('svc',clfsvc),('knn',clfknn)],voting='hard')\nc_params = [0.001,0.01,0.1,1,5,10.50,100,300,500,1000]\nparams = {\n    'lr__solver':['liblinear','lbfgs','saga'], \n    'lr__penalty':['l1','l2','elasticnet'], \n    'lr__C':c_params,\n    'rf__criterion':['gini','entropy'],\n    'rf__min_samples_leaf':[1,2,3,4,5],\n    'rf__n_estimators':[100,150,200],\n    # 'gnb__':[], \ud30c\ub77c\ubbf8\ud130 \uc9c0\uc815\ud560 \ud544\uc694 \uc5c6\ub294\ub4ef.. \uadf8\ub0e5 default\ub85c\n    'svc__C':c_params,\n    'svc__gamma':[0.001,0.01,0.1,1,10],\n    'svc__kernel':['rbf','sigmoid'],\n    'svc__decision_function_shape':['ovo'],\n    'knn__n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n    'knn__weights':['uniform','distance']\n}\n\n# In your example, the cv=5, so the data will be split into train and test folds 5 times. \n# The model will be fitted on train and scored on test. \n# These 5 test scores are averaged to get the score.\nfrom sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(estimator = eclf_h, param_grid=params, cv=5, n_jobs=-1)\ngrid = grid.fit(x_train,y_train)\ngrid.best_params_     # VotingClassifier\uc758 best_params_\uc758 \uc758\ubbf8\ub294 lr, rf, gnb, svc, knn \ub2e4\ud568\uaed8 \uc0ac\uc6a9 \ud560\ub54c\uc758 \ucd5c\uc801\uc758 \ud30c\ub77c\ubbf8\ud130\ub77c\ub294 \ub73b.","c215e1e0":"# VotingClassifier(hard)\uc758 score with best_params_\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nclflog = LogisticRegression()\nclfrf = RandomForestClassifier()\nclfgn = GaussianNB()\nclfsvc = SVC()\nclfknn = KNeighborsClassifier()\n# \uc544\ub798\ucc98\ub7fc best_params \ub123\uc5b4\uc8fc\uc5b4\uc57c \ud568\n# clflog = LogisticRegression(C=5.0, penalty='l2', solver='liblinear')\n# clfdt = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=5)\n\nfrom sklearn.ensemble import VotingClassifier\neclf_h = VotingClassifier(estimators = [('lr',clflog),('rf',clfrf),('gnb',clfgn),('svc',clfsvc),('knn',clfknn)], voting='hard')\neclf_h.fit(x_train,y_train)\ny_pred = eclf_h.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))\n\nprint(eclf_h.score(x_test,y_test))","e3566863":"# VotingClassifier(soft)\n# \uc704\uc5d0\uaebc \ub530\ub77c\ud558\uae30\n\neclf_s = VotingClassifier(estimators = [('lr',clflog),('rf',clfrf),('gnb',clfgn),('svc',clfsvc),('knn',clfknn)], voting='soft')","63de17a7":"# \ub370\uc774\ud130\uc14b \ubd84\uc11d\n\n* \ubaa9\ud45c\ub294 \uc0ac\uc6a9\uc790\uc758 \ub2e4\uc74c \uc8fc\ubb38\uc5d0 \uc5b4\ub5a4 \uc81c\ud488\uc774 \uc788\uc744\uc9c0 \uc608\uce21\ud558\ub294 \uac83.\n* 20 \ub9cc \uba85 \uc774\uc0c1\uc758 Instacart \uc0ac\uc6a9\uc790.\n* 3 \ubc31\ub9cc \uac1c \uc774\uc0c1\uc758 \uc2dd\ub8cc\ud488 \uc8fc\ubb38 \uc0d8\ud50c\uc774 \ud3ec\ud568. \n* \uac01 \uc0ac\uc6a9\uc790\uc5d0 \ub300\ud574 \uc8fc\ubb38\ub9c8\ub2e4 \uad6c\ub9e4 \ud55c \uc81c\ud488 \uc21c\uc11c\uc640 \ud568\uaed8 4 ~ 100 \uac1c\uc758 \uc8fc\ubb38\uc744 \uc81c\uacf5. \n* \uc8fc\ubb38\ud55c \uc8fc\uc640 \uc2dc\uac04 \ubc0f \uc8fc\ubb38 \uac04\uc758 \uc0c1\ub300\uc801 \uc2dc\uac04 \uce21\uc815 \uac12\ub3c4 \uc81c\uacf5.","185ed5b5":"# Modeling\n# Sample data(order_products__train)\n# df1","7a2c8d67":"# Ensemble\n1. Voting\n2. Bagging","9457f41f":"## 1. VotingClassifier()","f5097acc":"# PreProcessing","66594293":"# sample"}}