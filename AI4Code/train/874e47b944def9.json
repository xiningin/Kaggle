{"cell_type":{"68beafb7":"code","89503da8":"code","50d836b7":"code","abdc8d62":"code","810d5467":"code","7957867d":"code","3bcaf230":"code","64086510":"code","0d3d893a":"code","b63f94ce":"code","b7b42f35":"markdown","4cf61455":"markdown","5e49870c":"markdown"},"source":{"68beafb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89503da8":"def process(text):\n    with open (text, \"r\", encoding = \"ISO-8859-1\") as file:\n        data=file.readlines()\n        script = \"\"\n        for i in data:\n            i = i.lower().replace('\"', '').replace(\"\\n\", \" \\n \")\n            if i.strip() != \"\":\n                script += \"\".join(i).replace(\"\\n\",\" \\n \")\n        return script","50d836b7":"df = process(\"..\/input\/10kgnad\/train.csv\") \nprint(df[0:2000])","abdc8d62":"Text_Data = df\n\ncharindex = list(set(Text_Data))\ncharindex.sort() \nprint(charindex)\n\nnp.save(\"charindex.npy\", charindex)\n\nprint(len(Text_Data))","810d5467":"from csv import QUOTE_NONE","7957867d":"#Code by Sohier Dane  https:\/\/www.kaggle.com\/sohier\/function-for-formatting-the-text-reading-the-files\/notebook?select=English.csv\n\ndef read_and_reformat(csv_path):\n    df = pd.read_csv(csv_path,\n                     sep='|',\n                     encoding='iso-8859-1',\n                     dtype=object,\n                     header=None,\n                     quoting=QUOTE_NONE,\n                     names=['Sport', 'Magnetresonanz', 'nicht_operiert_werden'])    \n    df['nicht_operiert_werden'] = df['nicht_operiert_werden'].str.replace('#NAME\\?', '')\n    df['nicht_operiert_werden'] = df['nicht_operiert_werden'].str.strip(',')\n    return df","3bcaf230":"df = read_and_reformat('..\/input\/10kgnad\/train.csv')\ndf.head()","64086510":"df.info()","0d3d893a":"df[df.isnull().any(axis=1)]","b63f94ce":"df.loc[9227]","b7b42f35":"Citation: Dietmar Schabus, Marcin Skowron, Martin Trapp\n\nOne Million Posts: A Data Set of German Online Discussions\n\nProceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)\npp. 1241-1244 - Tokyo, Japan, August 2017\n\nhttps:\/\/ofai.github.io\/million-post-corpus\/#citation\n\nhttps:\/\/github.com\/OFAI\/million-post-corpus","4cf61455":"#Since I was not able to read the data with the regular pd read. I tried to make some different thing. It was expected to run python code\/extract_dataset_from_sqlite.py corpus.sqlite3 articles.csv to extract the articles.  ","5e49870c":"#Das ist alles."}}