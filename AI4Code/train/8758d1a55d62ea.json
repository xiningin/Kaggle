{"cell_type":{"ccf775ac":"code","1c10b847":"code","a8fd15f5":"code","4e6ec8a8":"code","bbe88086":"code","471af4cf":"code","5cc1025c":"code","0fc32e2e":"code","fa18dcf0":"code","39acaebf":"code","c07920cc":"code","0c338078":"code","52840a37":"code","bd246642":"code","250fc941":"code","4b3e8e60":"code","fba37903":"code","a3ad56d7":"code","9b780d5a":"code","e20eeb03":"code","2efb991a":"code","a714dbb1":"code","46a1414f":"code","af609499":"code","b38bc387":"code","9ca8ef9f":"code","29ea998c":"code","59fbc4dc":"code","84455e5f":"code","3339636f":"code","ae80328d":"code","cfb9b513":"code","acad0fa5":"code","61b6125c":"code","9c594216":"code","4697c22d":"code","cac2db75":"code","5f8a83f2":"code","5b5099d8":"code","65d61ed3":"code","b109ea84":"code","c7c9d010":"code","a1c7fb62":"code","8b9db26a":"code","53c163eb":"code","25f9b399":"code","d849f297":"code","8e32d7ea":"code","db07481f":"code","06605857":"code","ca514609":"code","b9fe702e":"code","de364df9":"code","1bae4e00":"code","7ed7aa39":"code","bb770ede":"code","b32edd11":"code","80ffa700":"code","3af3829a":"code","d4b5b550":"code","66fd84c1":"code","373e24b8":"code","4a5be27d":"markdown","094d788e":"markdown","50fba5f3":"markdown"},"source":{"ccf775ac":"# for hyper parameter search\n!pip install optuna","1c10b847":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a8fd15f5":"import pyarrow.parquet as pq","4e6ec8a8":"from pathlib import Path","bbe88086":"class DataPaths(object):\n    TRAIN_PARQUET_PATH = Path('..\/input\/train.parquet')\n    TRAIN_METADATA_PATH = Path('..\/input\/metadata_train.csv')\n    TEST_PARQUET_PATH = Path('..\/input\/test.parquet')\n    TEST_MATADATA_PATH = Path('..\/input\/metadata_test.csv')","471af4cf":"train_meta_df = pd.read_csv('..\/input\/metadata_train.csv')","5cc1025c":"train_meta_df[:10]","0fc32e2e":"# for debug\n# train_meta_df = train_meta_df.iloc[:1200]","fa18dcf0":"train_meta_df.info()","39acaebf":"train_meta_df.describe()","c07920cc":"from scipy import signal","0c338078":"import pywt","52840a37":"# WAVELET_WIDTH = 30","bd246642":"from sklearn.preprocessing import FunctionTransformer","250fc941":"subset_train = pq","4b3e8e60":"class SummaryTransformer(FunctionTransformer):\n    def __init__(self, \n                 kw_args=None, inv_kw_args=None):\n        validate = False\n        inverse_func = None\n        accept_sparse = False\n        pass_y = 'deprecated'\n        super().__init__(self.f, inverse_func, validate, accept_sparse, pass_y, kw_args, inv_kw_args)\n    \n    def f(self, X):\n        avgs = np.mean(X)\n        stds = np.std(X)\n        maxs = np.max(X)\n        mins = np.min(X)\n        medians = np.median(X)\n        return np.array([avgs, stds, maxs, mins, medians])","fba37903":"# class WaevletSummaryTransformer(FunctionTransformer):\n#     def __init__(self, wavelet_width,\n#                  kw_args=None, inv_kw_args=None):\n#         validate = False\n#         inverse_func = None\n#         accept_sparse = False\n#         pass_y = 'deprecated'\n#         self.wavelet_width = wavelet_width\n#         super().__init__(self.f, inverse_func, validate, accept_sparse, pass_y, kw_args, inv_kw_args)\n    \n#     def f(self, X):\n# #         wavelets = signal.cwt(X, signal.ricker, np.arange(1, self.wavelet_width + 1))\n#         wavelets, _ = pywt.cwt(X, np.arange(1, self.wavelet_width + 1), 'mexh')\n#         avgs = np.mean(wavelets, axis=1)\n#         stds = np.std(wavelets, axis=1)\n#         maxs = np.max(wavelets, axis=1)\n#         mins = np.min(wavelets, axis=1)\n#         medians = np.median(wavelets, axis=1)\n#         return np.concatenate([avgs, stds, maxs, mins, medians])","a3ad56d7":"class SpectrogramSummaryTransformer(FunctionTransformer):\n    def __init__(self, sample_rate, fft_length, stride_length,\n                 kw_args=None, inv_kw_args=None):\n        validate = False\n        inverse_func = None\n        accept_sparse = False\n        pass_y = 'deprecated'\n        self.sample_rate = sample_rate\n        self.fft_length = fft_length\n        self.stride_length = stride_length\n        super().__init__(self.f, inverse_func, validate, accept_sparse, pass_y, kw_args, inv_kw_args)\n    \n    def f(self, X):\n        X = self.to_spectrogram(X)\n        avgs = np.mean(X, axis=1)\n        stds = np.std(X, axis=1)\n        maxs = np.max(X, axis=1)\n        mins = np.min(X, axis=1)\n        medians = np.median(X, axis=1)\n        return np.concatenate([avgs, stds, maxs, mins, medians])\n\n    def to_spectrogram(self, series):\n        f, t, Sxx = signal.spectrogram(series, fs=self.sample_rate, nperseg=self.fft_length,\n                                   noverlap=self.fft_length - self.stride_length, window=\"hanning\", axis=0,\n                                   return_onesided=True, mode=\"magnitude\", scaling=\"density\")\n        return Sxx","9b780d5a":"from typing import List","e20eeb03":"from sklearn.base import TransformerMixin","2efb991a":"train_meta_df.columns","a714dbb1":"def read_column(parquet_path, column_id):\n    return pq.read_pandas(parquet_path, columns=[str(column_id)]).to_pandas()[str(column_id)]","46a1414f":"import itertools","af609499":"from tqdm import tqdm_notebook","b38bc387":"from multiprocessing.pool import Pool","9ca8ef9f":"class FeatureExtractor(object):\n    def __init__(self, transformers):\n        self.transformers: List[TransformerMixin] = transformers\n        self._parquet_path = None\n        self._meta_df = None\n    \n    def fit(self, parquet_path, meta_df):\n        pass\n    \n    def from_signal(self, parquet_path, signal_id):\n        return [ transformer.transform(read_column(parquet_path, signal_id).values)  \n                                          for transformer in self.transformers]\n    \n    def from_measurement(self, measure_id):\n        temp = np.concatenate(\n            list(itertools.chain.from_iterable(\n                [ self.from_signal(self._parquet_path, signal_id) for signal_id \n                 in self._meta_df[self._meta_df[\"id_measurement\"] == measure_id].signal_id\n                ]\n            ))\n        )\n        return temp\n    \n    def transform(self, parquet_path, meta_df, n_jobs=2):\n        self._parquet_path = parquet_path\n        self._meta_df = meta_df\n        with Pool(n_jobs) as pool:\n            rows = pool.map(self.from_measurement, self._meta_df.id_measurement.unique())\n        return np.vstack(rows)","29ea998c":"N_MEASUREMENTS = 800000","59fbc4dc":"TOTAL_DURATION = 20e-3","84455e5f":"sample_rate = N_MEASUREMENTS \/ TOTAL_DURATION","3339636f":"# wavelet transform takes too much time\n# extractor = FeatureExtractor([SummaryTransformer(), WaevletSummaryTransformer(WAVELET_WIDTH), SpectrogramSummaryTransformer(\n#     sample_rate= sample_rate, fft_length=200, stride_length=100)])","ae80328d":"extractor = FeatureExtractor([SummaryTransformer(), SpectrogramSummaryTransformer(\n    sample_rate= sample_rate, fft_length=200, stride_length=100)])","cfb9b513":"X = extractor.transform(DataPaths.TRAIN_PARQUET_PATH, train_meta_df, n_jobs=4)","acad0fa5":"X.shape","61b6125c":"from sklearn.metrics import matthews_corrcoef","9c594216":"from lightgbm import LGBMClassifier","4697c22d":"import optuna","cac2db75":"y = train_meta_df.target[list(range(train_meta_df.signal_id.values[0], \n                                        train_meta_df.signal_id.values[-1], 3))]","5f8a83f2":"RANDOM_STATE=10","5b5099d8":"from sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer","65d61ed3":"from imblearn.pipeline import make_pipeline, Pipeline","b109ea84":"from imblearn.over_sampling import SMOTE","c7c9d010":"def objective(trial:optuna.trial.Trial):\n    boosting_type = trial.suggest_categorical(\"boosting_type\", ['gbdt', 'dart'])\n    num_leaves = trial.suggest_int('num_leaves', 30, 80)\n    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 100)\n#     max_depth = trial.suggest_int('max_depth', )\n    lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-5, 1e-2)\n    lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-5, 1e-2)\n#     num_iterations = trial.suggest_int(\"num_iterations\", 100, 500)\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n    smoth_n_neighbors = trial.suggest_int('smoth_n_neighbors', 5, 10)\n    \n    sampler = SMOTE(random_state=RANDOM_STATE, k_neighbors=smoth_n_neighbors)    \n    clf = LGBMClassifier(boosting_type=boosting_type, num_leaves=num_leaves, \n                        learning_rate=learning_rate, reg_alpha=lambda_l1, \n                        min_child_samples=min_data_in_leaf,\n                         reg_lambda=lambda_l2, random_state=RANDOM_STATE)\n#     fit_params = {\"early_stopping_rounds\":20, \n#                  \"eval_metric\": matthews_corrcoef}\n    pipeline = make_pipeline(sampler, clf)\n    scores = cross_validate(pipeline, X, y, verbose=1,  \n                  n_jobs=-1, scoring=make_scorer(matthews_corrcoef), cv=5)\n    return - scores[\"test_score\"].mean()\n    ","a1c7fb62":"study = optuna.create_study()","8b9db26a":"study.optimize(objective, n_trials=20)","53c163eb":"study.best_params","25f9b399":"study.best_value","d849f297":"best_params = study.best_params","8e32d7ea":"best_params[\"random_state\"] = RANDOM_STATE","db07481f":"sampler = SMOTE(random_state=RANDOM_STATE, k_neighbors=best_params[\"smoth_n_neighbors\"])    ","06605857":"clf = LGBMClassifier(**best_params)","ca514609":"pipeline = Pipeline([(\"sampler\", sampler), (\"clf\", clf)])","b9fe702e":"pipeline.fit(X, y, clf__eval_metric=matthews_corrcoef, \n       clf__verbose=1)","de364df9":"test_meta_df = pd.read_csv(DataPaths.TEST_MATADATA_PATH)","1bae4e00":"# test_meta_df = test_meta_df.iloc[:15]","7ed7aa39":"test_meta_df.shape","bb770ede":"X = extractor.transform(DataPaths.TEST_PARQUET_PATH, test_meta_df, n_jobs=4)","b32edd11":"predictions = clf.predict(X)","80ffa700":"submit_df = pd.DataFrame()","3af3829a":"submit_df[\"signal_id\"] = test_meta_df.signal_id","d4b5b550":"submit_df[\"target\"] = np.repeat(predictions, 3)","66fd84c1":"submit_df[:10]","373e24b8":"submit_df.to_csv(\"submission.csv\", index=None)","4a5be27d":"# feature extraction","094d788e":"## train model","50fba5f3":"## predict"}}