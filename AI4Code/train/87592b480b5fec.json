{"cell_type":{"37f16f37":"code","a808f002":"code","6f18c915":"code","1fbdb433":"code","4ac255dc":"code","7d488660":"code","8812a6a8":"code","4eae5cfc":"code","76bcc10e":"code","98b09f86":"code","88f69679":"code","2953f65a":"code","b68f6ca3":"code","e63d53e3":"code","9662b6b0":"code","236c4cd3":"markdown","3b6ca77e":"markdown","0903bf2c":"markdown","bc4a406e":"markdown","dba8c0bf":"markdown","8834027e":"markdown","2c653ea1":"markdown","e609f4c9":"markdown","ea4ac223":"markdown","8fd21b38":"markdown","33061103":"markdown","6330e08f":"markdown","6e75abd1":"markdown","93f06c0e":"markdown","7903b85d":"markdown"},"source":{"37f16f37":"from sklearn.preprocessing import LabelEncoder\n\ndef encode_data(df):\n    '''\n    The function does not return, but transforms the input pd.DataFrame\n    \n    Encodes the Costa Rican Household Poverty Level data \n    following studies in https:\/\/www.kaggle.com\/mlisovyi\/categorical-variables-in-the-data\n    and the insight from https:\/\/www.kaggle.com\/c\/costa-rican-household-poverty-prediction\/discussion\/61403#359631\n    \n    The following columns get transformed: edjefe, edjefa, dependency, idhogar\n    The user most likely will simply drop idhogar completely (after calculating houshold-level aggregates)\n    '''\n    \n    yes_no_map = {'no': 0, 'yes': 1}\n    \n    df['dependency'] = df['dependency'].replace(yes_no_map).astype(np.float32)\n    \n    df['edjefe'] = df['edjefe'].replace(yes_no_map).astype(np.float32)\n    df['edjefa'] = df['edjefa'].replace(yes_no_map).astype(np.float32)\n    \n    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])","a808f002":"import numpy as np # linear algebra\nimport pandas as pd \n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline ","6f18c915":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","1fbdb433":"train.info()","4ac255dc":"cat_cols = train.select_dtypes(include=['object', 'category'])","7d488660":"cat_cols.head(10)","8812a6a8":"def plot_value_counts(series, title=None):\n    '''\n    Plot distribution of values counts in a pd.Series\n    '''\n    _ = plt.figure(figsize=(12,6))\n    z = series.value_counts()\n    sns.barplot(x=z, y=z.index)\n    _ = plt.title(title)\n    \nplot_value_counts(train['edjefe'], 'Value counts of edjefe')\nplot_value_counts(train['edjefa'], 'Value counts of edjefa')","4eae5cfc":"# Family member counts\nhogar_df = train[[f_ for f_ in train.columns if f_.startswith('hogar_')]]\n# Family member type of this person\nparentesco_df = train[[f_ for f_ in train.columns if f_.startswith('parentesco')]]\n\n# Family status dataset\nfamily_status = pd.concat([cat_cols, train[['female', 'male', 'parentesco1', 'meaneduc']], hogar_df], axis =1)","76bcc10e":"family_status.head(5)","98b09f86":"# this is a hand-picked example to illustrate the point\nfamily_status.query('idhogar == \"2b58d945f\"')","88f69679":"# this is a hand-picked example to illustrate the point\nfamily_status.query('idhogar == \"200099351\"')","2953f65a":"family_status.query('(edjefe==\"no\" & edjefa==\"no\")').head()","b68f6ca3":"family_status.query('(edjefe==\"yes\") | (edjefa==\"yes\")').head(20)","e63d53e3":"plot_value_counts(train['dependency'], 'Value counts of dependency')","9662b6b0":"train[['dependency', 'SQBdependency']].head(20)","236c4cd3":"So it seems that `'yes'` means *the head has education, but the years are not specified*. In such case, the suggestion can be either to encode a dummy value (1?) or better the mean within a category. \n\nThe alternative would be to try to deduce the age from the `meaneduc` and `SQBmeaned`. This is trivial for houshoulds of a single person, possible fo 2 adult people (up to ambiguity, which of 2 values corresponds to the head) and impossible(?) for more than2 adults in the houshold.\n\nOne can also use `instlevelX` for imputation\n\n# dependency","3b6ca77e":"So, both variables are basically a number with precence of `'yes'` and `'no'` classes. Let's figure out what do those mean...","0903bf2c":"## How about 'yes' values?","bc4a406e":"The observation at this stage: **very often `edjefe\/edjefa` variable is encoded to `'no'` in the case, when household head  is of opposite gender.**\n\nFor example, if the household head is male, then `edjefa == 'no'` (person with `Id == 'ID_ec05b1a7b'` is the head and is a male):","dba8c0bf":"# Prepare environment and read in the data","8834027e":"# edjefe and edjefa\nLet's start with these two, as they are easier. A brief reminder:\n> `edjefe`, years of education of male head of household\n\n> `edjefa`, years of education of female head of household\n","2c653ea1":"What are those? I assume, in this case the household head either does not have education or did not provide this info. \n\nOne might want to differentiate such `'no'` values from the previously discussed type, as the meaning is different. In such case, the  suggestion would be to encode for the head of the household the value of 0 and -1 for the `'no'` values of the type that was discussed first. \n\nBut **if one simply fills `'no'` with 0, there will be no critical change in the behaviour**.\n\nIn either case, the advantage that one gains over simple label encoding is that one preserves the internal order of classes, while label encoding could encode `8` as `8` and `10` as `1`","e609f4c9":"## Replace 'no' with 0 or NaN?\nIn most cases, yes. But there are exceptions, when both `edjefe` and `edjefa`  are equal to `'no'`:","ea4ac223":"# UNDER CONSTRUCTION!","8fd21b38":"This variable is so far unclear to me. The `'SQBdependency'` seems to suggest that providers of the data assumed that `'no' == 0` and `'yes' == 1`, is a reasonable imputation and I see no reason to argue with them about it :)","33061103":"Let's study them one-by-one\n# idhogar\nThis one is clear - that's a unique identifier for a household. Most likely one does not want to use it in training, but rather to group on it to get accumulated household statistics. Therefore, it does not matter much what you do with it- you can keep it as a string, you can label-encode it. But the set of unique values is huge and this will lead to the large number of OHE feature observed by @Ishaan","6330e08f":"# Study of categorical varibales\n\nIn several first kernels that appeared by now peopel use LabelEncoding to transform categorical features in the data into something that can be digested by a model. I suppose this was not done on purpose, but rather to have a quick first iteration\n\n# UPDATE: There was a clarification on values corresponding to 'yes'\/'no' labels\nIn the Welcome discussion thread @Louis Tajerina clarified the occurance of the categorical `yes\/no` values: https:\/\/www.kaggle.com\/c\/costa-rican-household-poverty-prediction\/discussion\/61403#359631.\n\nAs an outcome, I provide a very basic encoding function to encode categoricals into reasonable integer dummies. There are ideas in the notebook on how to improve it further with more advanced imputations.\n","6e75abd1":"For example, if the household head is female, then `edjefe == 'no'` (person with `Id == 'ID_c51c0afa1'` is the head and is a male):","93f06c0e":"Ok, so there are 5 columns with categorical data. Let's have a quick look at what are those. Most first kernel use label encoding. And there was an explicit mention in [this kernel by Ishaan Jain](https:\/\/www.kaggle.com\/ishaan45\/eda-for-a-good-cause), that OHE leads to an explosion in the number of features. Let's understand why...\n\n## Check categorical variables","7903b85d":"# Outdated\n\nThe purpose of this kernel is to have a look at those features and come up with a smarter encoding. The outline goes line this:\n- [Check categorical variables](#Check-categorical-variables)\n- [idhogar](#idhogar)\n- [edjefe and edjefa](#edjefe-and-edjefa)\n - [Replace 'no' with 0 or NaN?](#Replace-'no'-with-0-or-NaN?)\n - [How about 'yes' values?](#How-about-'yes'-values?)\n- [dependency](#dependency)\n\nAs an outcome, I provide a very basic encoding function to encode categoricals into reasonable integer dummies. There are ideas in the notebook on how to improve it further with more advanced imputations."}}