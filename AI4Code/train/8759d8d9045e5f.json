{"cell_type":{"79633a70":"code","e7f729bb":"code","8c539d9a":"code","d8be5520":"code","d7539533":"code","7810b3f3":"code","d3c2053c":"code","eec2fbcd":"code","17af1f74":"code","4555fa22":"code","50a5c5bb":"code","52d508ff":"code","b64d67df":"code","5575d94f":"code","6102484b":"code","88a38ba6":"code","f6490f96":"code","56dd6c85":"code","4b80c024":"code","6184446e":"code","0e22c6ee":"code","90e9d29b":"code","358ced7e":"code","bde8abdb":"code","972255b6":"code","de8289e9":"code","acf42220":"code","9f4a2335":"code","f1f4ce95":"code","1fcc290c":"code","93dbfaf4":"code","5a907ba0":"code","8c7b0def":"code","61dd7457":"code","4bf5f9ce":"code","2ec48406":"code","13482e7f":"code","e101a038":"code","fde36ddd":"code","c824b1ac":"code","ca8a6d6a":"code","c1ca1a5f":"code","935b37a7":"code","23502ac0":"code","52356259":"code","e1544768":"code","e2f56487":"code","145f7880":"code","5775054b":"markdown","c7ddca00":"markdown","3bd13745":"markdown","7f9d1ebe":"markdown","e35817f4":"markdown","619f08bd":"markdown","1cb3ac30":"markdown","2818b36a":"markdown","4aa0ed34":"markdown","18a2e069":"markdown","af6a939b":"markdown","f57d91a3":"markdown","8fd67060":"markdown","12cb489a":"markdown","905a1303":"markdown","8201ed1c":"markdown","797d8bd6":"markdown","58749c9e":"markdown","4ed7e1d8":"markdown","6a1cdaf1":"markdown","da1a3b82":"markdown","1d4a7f1f":"markdown","7cc82782":"markdown","edcfa64a":"markdown"},"source":{"79633a70":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","e7f729bb":"train_data = pd.read_csv('..\/input\/widsdatathon2021\/TrainingWiDS2021.csv')\ntest_data = pd.read_csv('..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv')","8c539d9a":"print('There are '\n     + str(len(train_data.encounter_id.unique()))\n     + ' instances on the training set.')\n\nprint('There are '\n     + str(len(test_data.encounter_id.unique()))\n     + ' instances on the test set.')","d8be5520":"print('If we dropped all rows with missing values, there would be only '\n     + str(len(train_data.dropna()))\n     + ' rows left on the training set')","d7539533":"# Number of different hospitals in the training set:\nlen(train_data.hospital_id.unique())","7810b3f3":"# Number of different hospitals in the test set:\nlen(test_data.hospital_id.unique())","d3c2053c":"# Number of hospitals that are on the test set and are not in the training set\nlen(set(test_data.hospital_id.unique()) - set(train_data.hospital_id.unique()))","eec2fbcd":"# Let's see how the hospital ids in the training set are distributed\nnp.sort(train_data.hospital_id.unique())","17af1f74":"# Let's see how the hospital ids in the test set are distributed\nnp.sort(test_data.hospital_id.unique())","4555fa22":"demographic_features = ['age', \n                        'bmi', \n                        'elective_surgery',\n                        'ethnicity', \n                        'gender', \n                        'height', \n                        'hospital_admit_source', \n                        'icu_admit_source', \n                        'icu_stay_type', \n                        'icu_id', \n                        'icu_stay_type', \n                        'icu_type', \n                        'pre_icu_los_days', \n                        'readmission_status',\n                        'weight']\n\nprint('If we dropped all rows with missing demographic values, there would be only '\n     + str(len(train_data[demographic_features].dropna()))\n     + ' ('\n     + str(round(100*len(train_data[demographic_features].dropna())\/len(train_data),2))\n     + '%) rows left on the training set')","50a5c5bb":"# Checking age distribution on the training set\nplt.hist(train_data.age, bins=[10,20,30,40,50,60,70,80,90,100,110])","52d508ff":"# Checking age distribution on the test set\nplt.hist(test_data.age, bins=[10,20,30,40,50,60,70,80,90,100,110])","b64d67df":"print(\"There are \" \n      + str(train_data.age.isnull().sum())\n      + \" null values on for the age feature in the training set. It represents \"\n      + str(round(100*train_data.age.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.age.isnull().sum())\n      + \" null values on for the age feature in the test set. It represents \"\n      + str(round(100*test_data.age.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","5575d94f":"# Checking BMI distribution on the training set\nplt.hist(train_data.bmi, bins=[20,25,30,35,40,45,50,55,60,65,70])","6102484b":"# Checking BMI distribution on the test set\nplt.hist(test_data.bmi, bins=[20,25,30,35,40,45,50,55,60,65,70])","88a38ba6":"print(\"There are \" \n      + str(train_data.bmi.isnull().sum())\n      + \" null values on for the BMI feature in the training set. It represents \"\n      + str(round(100*train_data.bmi.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.bmi.isnull().sum())\n      + \" null values on for the BMI feature in the test set. It represents \"\n      + str(round(100*test_data.bmi.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","f6490f96":"print('On the training set, '\n      + str(round(100*train_data.elective_surgery.sum()\/len(train_data.encounter_id.unique()),2))\n      + ' % of the patients were in the hospital for an elective surgery.')\n\nprint('On the test set, '\n      + str(round(100*test_data.elective_surgery.sum()\/len(test_data.encounter_id.unique()),2))\n      + ' % of the patients were in the hospital for an elective surgery.')","56dd6c85":"print(\"There are \" \n      + str(train_data.elective_surgery.isnull().sum())\n      + \" null values on for the elective_surgery feature in the training set. It represents \"\n      + str(round(100*train_data.elective_surgery.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.elective_surgery.isnull().sum())\n      + \" null values on for the elective_surgery feature in the test set. It represents \"\n      + str(round(100*test_data.elective_surgery.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","4b80c024":"train_data.ethnicity.value_counts()","6184446e":"train_data.ethnicity.isnull().sum()","0e22c6ee":"test_data.ethnicity.value_counts()","90e9d29b":"test_data.ethnicity.isnull().sum()","358ced7e":"train_data.gender.value_counts()","bde8abdb":"train_data.gender.isnull().sum()","972255b6":"test_data.gender.value_counts()","de8289e9":"test_data.gender.isnull().sum()","acf42220":"# Checking height distribution on the training set\nplt.hist(train_data.height, bins=[130,135,140,145,150,155,160,170,175,180,185,190,195,200,205])","9f4a2335":"# Checking height distribution on the test set\nplt.hist(test_data.height, bins=[130,135,140,145,150,155,160,170,175,180,185,190,195,200,205])","f1f4ce95":"print(\"There are \" \n      + str(train_data.height.isnull().sum())\n      + \" null values on for the height feature in the training set. It represents \"\n      + str(round(100*train_data.height.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.height.isnull().sum())\n      + \" null values on for the height feature in the test set. It represents \"\n      + str(round(100*test_data.height.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","1fcc290c":"train_data.height.mean()","93dbfaf4":"test_data.height.mean()","5a907ba0":"train_data.hospital_admit_source.value_counts()","8c7b0def":"test_data.hospital_admit_source.value_counts()","61dd7457":"print(\"There are \" \n      + str(train_data.hospital_admit_source.isnull().sum())\n      + \" null values on for the hospital_admit_source feature in the training set. It represents \"\n      + str(round(100*train_data.hospital_admit_source.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.hospital_admit_source.isnull().sum())\n      + \" null values on for the hospital_admit_source feature in the test set. It represents \"\n      + str(round(100*test_data.hospital_admit_source.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","4bf5f9ce":"train_data.icu_admit_source.value_counts()","2ec48406":"test_data.icu_admit_source.value_counts()","13482e7f":"print(\"There are \" \n      + str(train_data.icu_admit_source.isnull().sum())\n      + \" null values on for the icu_admit_source feature in the training set. It represents \"\n      + str(round(100*train_data.icu_admit_source.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.icu_admit_source.isnull().sum())\n      + \" null values on for the icu_admit_source feature in the test set. It represents \"\n      + str(round(100*test_data.icu_admit_source.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","e101a038":"plt.hist(train_data.pre_icu_los_days, bins=[0,1,2,3,4,5,6,7,8,9,10,15,20,30])","fde36ddd":"plt.hist(test_data.pre_icu_los_days, bins=[0,1,2,3,4,5,6,7,8,9,10,15,20,30])","c824b1ac":"print(\"There are \" \n      + str(train_data.pre_icu_los_days.isnull().sum())\n      + \" null values on for the pre_icu_los_days feature in the training set. It represents \"\n      + str(round(100*train_data.pre_icu_los_days.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.pre_icu_los_days.isnull().sum())\n      + \" null values on for the pre_icu_los_days feature in the test set. It represents \"\n      + str(round(100*test_data.pre_icu_los_days.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","ca8a6d6a":"train_data.readmission_status.value_counts()","c1ca1a5f":"test_data.readmission_status.value_counts()","935b37a7":"print(\"There are \" \n      + str(train_data.readmission_status.isnull().sum())\n      + \" null values on for the readmission_status feature in the training set. It represents \"\n      + str(round(100*train_data.readmission_status.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.readmission_status.isnull().sum())\n      + \" null values on for the readmission_status feature in the test set. It represents \"\n      + str(round(100*test_data.readmission_status.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","23502ac0":"plt.hist(train_data.weight, bins=[0,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200])","52356259":"plt.hist(test_data.weight, bins=[0,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200])","e1544768":"print(\"There are \" \n      + str(train_data.weight.isnull().sum())\n      + \" null values on for the weight feature in the training set. It represents \"\n      + str(round(100*train_data.weight.isnull().sum()\/len(train_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")\n\nprint(\"There are \" \n      + str(test_data.weight.isnull().sum())\n      + \" null values on for the weight feature in the test set. It represents \"\n      + str(round(100*test_data.weight.isnull().sum()\/len(test_data.encounter_id.unique()),2))\n      + \"% of the total instances.\")","e2f56487":"test_data.weight.mean()","145f7880":"train_data.diabetes_mellitus.value_counts()","5775054b":"### 2.2.14 Weight\nThe weight (body mass in kilograms) of the person on unit admission","c7ddca00":"### 2.2.7 Hospital Admit Source\nThe location of the patient prior to being admitted to the hospital","3bd13745":"### 2.2.9 ICU Id\nA unique identifier for the unit to which the patient was admitted. This feature is not relevant","7f9d1ebe":"They look pretty similar, this should't be an issue.","e35817f4":"### 2.2.5 Gender","619f08bd":"### 2.2.13 Readmission status\nWhether the current unit stay is the second (or greater) stay at an ICU within the same hospitalization","1cb3ac30":"### 2.2.8 ICU Admit Source\nThe location of the patient prior to being admitted to the unit","2818b36a":"## 2.2 Demographic features","4aa0ed34":"This represents a 93\/7 train-test split","18a2e069":"### 2.2.2 BMI","af6a939b":"### 2.2.3 Elective surgery","f57d91a3":"The following categories are not included in the test data:\n* Acute Care\/Floor\n* PACU\n* ICU\n* Observation\n* Other","8fd67060":"## 2.3 Target variable: *diabetes_mellitus*\nWhether the patient has been diagnosed with diabetes mellitus, a chronic disease.","12cb489a":"# 1. Understanding the competition\n\nOur first step regards an understanding of the competition requirements and the data that was provided. The main information we may retrieve from the competition description include:\n\n* We are given data from the first 24 hours of a pacient admitted to an intensive care unit (ICU)\n* Our aim is to determin whether the patient has been diagnosed with a particular type of diabetes\n* Our submissions will be evaluated on the Area under the Receiver Operating Characteristic **(ROC)** curve between the predicted and the observed target (diabetes_mellitus_diagnosis)\n\nCompetition organizers provide us with 5 files, which are described as follows:\n\n* *TrainingWiDS2021.csv* - the training data (size=130,157)\n* *UnlabeledWiDS2021.csv* - test data\n* *SampleSubmissionWiDS2021.csv* - a sample submission file in the correct format\n* *SolutionTemplateWiDS2021.csv* - a list of all the rows (and encounters) that should be in our submissions\n* *DataDictionaryWiDS2021.csv* - supplemental information about the data\n\nIn the next sections, we will be examining the training data file, with support from the data dictionary.","905a1303":"### 2.2.1 Age\nRegards the age of the patient on unit admission. It is a numeric variable.","8201ed1c":"## *Note: This notebook is still under construction*","797d8bd6":"### 2.2.4 Ethnicity","58749c9e":"They look pretty similar, this shoudn't be an issue.","4ed7e1d8":"# 2. Exploring the features\n## 2.1 Identifier features\n\nThe data dictionary describes seven categories for the features, excluding the target variable. The first category regards the identifier features: *encounter_id* and *hospital_id*.","6a1cdaf1":"This is a very skewed variable, but distributions look similar.","da1a3b82":"### 2.2.6 Height","1d4a7f1f":"### 2.2.12 Pre-ICU length of stay days\nThe length of stay of the patient between hospital admission and unit admission","7cc82782":"### 2.2.10 ICU Stay Type\nThis feature is not relevant.\n","edcfa64a":"### 2.2.11 ICU Type\nA classification which indicates the type of care the unit is capable of providing. This feature is not relevant.\n"}}