{"cell_type":{"5e9389d2":"code","587c9a6d":"code","3f27b4d3":"code","016c7940":"code","4718d70d":"code","9412771e":"code","eec12977":"code","78fe309c":"code","b39eb142":"code","d7a290c6":"code","20a707c9":"code","4a756eeb":"code","c3f466c3":"code","979571a2":"code","0443516b":"code","7c5b718e":"code","be176510":"code","21fa79ba":"code","83551889":"code","2c2194cd":"code","fd48ab66":"code","8bc8a9e1":"code","ce2d5f51":"code","64278f04":"code","1987915a":"code","2b3a7246":"code","c007e013":"code","129923b3":"code","fb8ede66":"code","1b30d1a7":"code","a279ee6e":"code","9e3ac619":"code","17774d36":"code","bebbeffd":"code","448e0a9b":"code","14079649":"code","d7bcd9e9":"code","dbebf30b":"code","899bbfc7":"code","c055f4d6":"code","c2a5ac8f":"code","1cdd490c":"code","1267c4f6":"code","cea17e64":"code","efdb254e":"code","3f5a413b":"code","d1d83720":"code","9b8ab511":"code","a2bdd94e":"code","7b6c486c":"code","3d446bf2":"code","bd3dca70":"code","a0120453":"code","2d2307b3":"code","b217d480":"code","cb6b5e9c":"code","668c0fd7":"code","8feae6e8":"code","d0796e68":"code","09f7be59":"code","607e558c":"code","28fde1bc":"code","20177d42":"code","bbe75133":"code","dae7f36e":"code","408314af":"code","a01d813b":"code","bc77fd09":"code","5679ade8":"code","882cb3fd":"code","fd8a8dec":"code","7b952fe5":"code","17689830":"code","2a71aa36":"code","9c598ab9":"code","aa8db8a1":"code","fb3d941e":"code","e93e6c7e":"code","1a897757":"code","7fa79621":"code","ec46ab2c":"code","8d16bcf0":"code","bee82b16":"code","3cb3365b":"code","154fb10f":"code","c9226c46":"code","036dd079":"code","bab7d26c":"code","348c2751":"code","ca64ad93":"code","bcec9a39":"code","8b049e61":"code","0f8daa66":"code","16febb94":"code","8a8ef46c":"code","45f88942":"code","7bd37e12":"code","e220eae3":"code","7d323e87":"code","959ebbf1":"code","bc5d252c":"code","f6ed4e72":"code","5b04c9bd":"code","3525220d":"code","62d80546":"code","dc97df00":"code","98eea6b5":"markdown","64adc6cc":"markdown","b62aed80":"markdown","990ce4f5":"markdown","5b9f8314":"markdown","31d95177":"markdown","3bb1296f":"markdown","338d8d06":"markdown","e4397720":"markdown","50370c7e":"markdown","605c30a7":"markdown","20d217a4":"markdown","14250f6f":"markdown","f4621133":"markdown","2fbefb02":"markdown","e61d646f":"markdown","6e5afb19":"markdown","5fe05fa3":"markdown","a0fcdc12":"markdown","14685692":"markdown","b8f422c7":"markdown","8a4d97d9":"markdown","9c29f5a3":"markdown","8c2543b7":"markdown","6d04e8aa":"markdown","6070c970":"markdown","78b76aa7":"markdown","ebaa989f":"markdown","097e3f69":"markdown","c0991687":"markdown","0440f1c0":"markdown","f06b8a39":"markdown","f6bf6428":"markdown","46b4f245":"markdown","76ee4cf0":"markdown","ca1813bd":"markdown","178f6bcd":"markdown","ba2b1196":"markdown","59385478":"markdown","b7855e7b":"markdown","508a5b67":"markdown","40386227":"markdown","d0388cc9":"markdown","e3b27bca":"markdown","105f5969":"markdown","cb20a73c":"markdown","87dd7f5a":"markdown","951746b0":"markdown","13e8c8b3":"markdown","f0ffcac4":"markdown","f1386394":"markdown","eafec353":"markdown","d949b36a":"markdown","cb410540":"markdown","4da4bfe4":"markdown","87f51860":"markdown","4ccbbfc3":"markdown","0c45a6bf":"markdown","cc875f43":"markdown","324b9c9a":"markdown","510307f7":"markdown","80fe6e05":"markdown","91d9b843":"markdown","00d496b3":"markdown","ba17c267":"markdown","d6a9e9ce":"markdown","e7a0e843":"markdown","b6ba6d3d":"markdown","f98857eb":"markdown","1e3894d6":"markdown","f1292f22":"markdown","d737c3f6":"markdown","9f6bd014":"markdown","b2e02e71":"markdown","aa4b72c6":"markdown","72c8fe03":"markdown","312b506b":"markdown","ddbae32e":"markdown","ccd921e6":"markdown","3012a9f2":"markdown","db0a0ddc":"markdown","77851419":"markdown","b52a8cbe":"markdown","2944cdf6":"markdown","94cf1e80":"markdown","08ef5224":"markdown","5a1de60a":"markdown","a6a100a7":"markdown","ab4c7030":"markdown"},"source":{"5e9389d2":"# Import modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport catboost as cat\nfrom catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nimport warnings\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support)\nfrom sklearn.model_selection import train_test_split\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","587c9a6d":"pd.options.display.max_columns = None\npd.options.display.max_rows = None","3f27b4d3":"# Training dataset\ntrain = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/training_v2.csv\")\n# Testing dataset\ntest = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/unlabeled.csv\")","016c7940":"test.head()","4718d70d":"train.head()","9412771e":"train.shape","eec12977":"train.info()","78fe309c":"train.isnull().sum(axis=0)\/len(train.index) * 100","b39eb142":"plt.figure(figsize=(24,6))\n(train.isnull().sum(axis=0)\/len(train.index) * 100).plot(kind='bar')\nplt.show()","d7a290c6":"train.describe()","20a707c9":"dictionary = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/WiDS Datathon 2020 Dictionary.csv\")","4a756eeb":"dictionary.head()","c3f466c3":"dictionary.Category.value_counts()","979571a2":"def selectCategory(df,category):\n    \"\"\"\n    This function will return the dataset\n    with information about the specified\n    category\n    \"\"\"\n    return df[df.Category==category]","0443516b":"cols = selectCategory(dictionary,\"GOSSIS example prediction\")","7c5b718e":"cols","be176510":"print(cols[\"Description\"].values[0])","21fa79ba":"if \"pred\" not in train.columns:\n    print(\"Column not present\")","83551889":"train.shape, dictionary.shape","2c2194cd":"cols = selectCategory(dictionary,\"APACHE grouping\")","fd48ab66":"cols","8bc8a9e1":"train[[\"apache_3j_bodysystem\",\"apache_2_bodysystem\"]].head(10)","ce2d5f51":"train[[\"apache_3j_bodysystem\",\"apache_2_bodysystem\"]][train[\"apache_3j_bodysystem\"] != train[\"apache_2_bodysystem\"]].head(20)","64278f04":"# Columns to drop\ntoDrop = []\ntoDrop.append(\"apache_2_bodysystem\")","1987915a":"cols = selectCategory(dictionary,\"APACHE prediction\")","2b3a7246":"cols","c007e013":"for i in cols.Description.values:\n    print(i)","129923b3":"sns.heatmap(train[[\"apache_4a_hospital_death_prob\",\"apache_4a_icu_death_prob\"]].corr(),annot=True)","fb8ede66":"toDrop.append(\"apache_4a_hospital_death_prob\")","1b30d1a7":"cols = selectCategory(dictionary,\"identifier\")\n\ncols","a279ee6e":"for i in cols.Description.values:\n    print(i)","9e3ac619":"train.encounter_id.nunique(),train.hospital_id.nunique(),train.patient_id.nunique(),len(train.index)","17774d36":"toDrop.append(\"encounter_id\")\ntoDrop.append(\"patient_id\")","bebbeffd":"cols = selectCategory(dictionary,\"APACHE comorbidity\")\n\ncols","448e0a9b":"for col in cols[\"Variable Name\"].values:\n    train[col] = train[col].fillna(0)","14079649":"cols = selectCategory(dictionary,\"labs blood gas\")\n\ncols","d7bcd9e9":"for i in range(len(cols.index)):\n    print(\"{}: {}\".format(cols[\"Variable Name\"].values[i],cols.Description.values[i]))","dbebf30b":"plt.figure(figsize=(10,10))\nsns.heatmap(abs(train[cols[\"Variable Name\"]].corr()),annot=True)\nplt.show()","899bbfc7":"for col in cols[\"Variable Name\"].values:\n    if col.startswith(\"d1_\"):\n        print(\"Column to delete: {}\".format(col))\n        toDrop.append(col)","c055f4d6":"cols = selectCategory(dictionary,\"demographic\")\n\ncols","c2a5ac8f":"train.hospital_death.value_counts(normalize=True).plot(kind='bar')","1cdd490c":"sns.distplot(train[\"age\"])","1267c4f6":"sns.distplot(train[train[\"hospital_death\"]==0][\"bmi\"],hist=False)\nsns.distplot(train[train[\"hospital_death\"]==1][\"bmi\"],hist=False)","cea17e64":"def bmiCategory(bmi):\n    if bmi < 18.5:\n        return \"underweight\"\n    elif bmi < 24.9:\n        return \"normal\"\n    elif bmi < 29.9:\n        return \"overweight\"\n    else:\n        return \"obese\"\n\ntrain[\"bmi_category\"] = train[\"bmi\"].apply(bmiCategory)","efdb254e":"test[\"bmi_category\"] = test[\"bmi\"].apply(bmiCategory)","3f5a413b":"train[\"bmi_category\"].value_counts(normalize=True).plot(kind='bar')","d1d83720":"sns.catplot(x=\"bmi_category\",y=\"hospital_death\",kind=\"bar\",data=train)","9b8ab511":"toDrop.append(\"bmi\")","a2bdd94e":"train.elective_surgery.value_counts(normalize=True).plot(kind='bar')","7b6c486c":"sns.countplot(x=\"elective_surgery\",hue=\"hospital_death\",data=train)","3d446bf2":"train.groupby(\"elective_surgery\")[\"hospital_death\"].sum()\/train.groupby(\"elective_surgery\")[\"hospital_death\"].count() * 100","bd3dca70":"sns.catplot(x=\"elective_surgery\",y=\"hospital_death\",kind=\"bar\",data=train)","a0120453":"train[\"ethnicity\"].value_counts(normalize=True).plot(kind='bar')","2d2307b3":"sns.catplot(x=\"ethnicity\",y=\"hospital_death\",kind=\"bar\",data=train,aspect=1.8)\nplt.show()","b217d480":"toDrop.append(\"ethnicity\")","cb6b5e9c":"train[\"gender\"].value_counts(normalize=True).plot(kind='bar')","668c0fd7":"sns.catplot(x=\"gender\",y=\"hospital_death\",kind=\"bar\",data=train)\nplt.show()","8feae6e8":"toDrop.append(\"gender\")","d0796e68":"sns.distplot(train[train[\"hospital_death\"]==0][\"height\"],hist=False)\nsns.distplot(train[train[\"hospital_death\"]==1][\"height\"],hist=False)","09f7be59":"toDrop.append(\"height\")","607e558c":"train[\"hospital_admit_source\"].value_counts(normalize=True).plot(kind='bar')","28fde1bc":"sns.catplot(x=\"hospital_admit_source\",y=\"hospital_death\",kind=\"bar\",data=train,aspect=1.8)\nplt.xticks(rotation=90)\nplt.show()","20177d42":"train[\"icu_admit_source\"].value_counts(normalize=True).plot(kind='bar')","bbe75133":"sns.catplot(x=\"icu_admit_source\",y=\"hospital_death\",kind=\"bar\",data=train,aspect=1.8)\nplt.xticks(rotation=90)\nplt.show()","dae7f36e":"if \"icu_admit_type\" not in train.columns:\n    print(\"Column not found\")","408314af":"train.icu_id.nunique()","a01d813b":"train[\"icu_stay_type\"].value_counts(normalize=True).plot(kind='bar')","bc77fd09":"sns.catplot(x=\"icu_stay_type\",y=\"hospital_death\",kind=\"bar\",data=train,aspect=1.8)\nplt.xticks(rotation=90)\nplt.show()","5679ade8":"toDrop.append(\"icu_stay_type\")","882cb3fd":"train[\"icu_type\"].value_counts(normalize=True).plot(kind='bar')","fd8a8dec":"sns.catplot(x=\"icu_type\",y=\"hospital_death\",kind=\"bar\",data=train,aspect=1.8)\nplt.xticks(rotation=90)\nplt.show()","7b952fe5":"sns.boxplot(train[\"pre_icu_los_days\"])","17689830":"sns.distplot(train[\"pre_icu_los_days\"])","2a71aa36":"sns.distplot(train[train[\"hospital_death\"]==0][\"pre_icu_los_days\"])","9c598ab9":"sns.distplot(train[train[\"hospital_death\"]==1][\"pre_icu_los_days\"])","aa8db8a1":"train[\"readmission_status\"].value_counts(normalize=True).plot(kind='bar')","fb3d941e":"toDrop.append(\"readmission_status\")","e93e6c7e":"sns.distplot(train[train[\"hospital_death\"]==0][\"weight\"],hist=False)\nsns.distplot(train[train[\"hospital_death\"]==1][\"weight\"],hist=False)","1a897757":"toDrop.append(\"weight\")","7fa79621":"cols = selectCategory(dictionary,\"APACHE covariate\")\n\ncols","ec46ab2c":"plt.figure(figsize=(20,20))\nsns.heatmap(abs(train[cols[\"Variable Name\"]].corr()),annot=True)\nplt.show()","8d16bcf0":"toDrop.append(\"ventilated_apache\")\ntoDrop.append(\"gcs_eyes_apache\")\ntoDrop.append(\"gcs_verbal_apache\")\ntoDrop.append(\"apache_3j_diagnosis\")","bee82b16":"cols = selectCategory(dictionary,\"vitals\")\n\nplt.figure(figsize=(20,20))\nsns.heatmap(abs(train[cols[\"Variable Name\"]].corr()),annot=True)\nplt.show()","3cb3365b":"toDrop.append(\"h1_sysbp_noninvasive_max\")\ntoDrop.append(\"h1_sysbp_noninvasive_min\")\ntoDrop.append(\"h1_mbp_noninvasive_max\")\ntoDrop.append(\"h1_mbp_noninvasive_min\")\ntoDrop.append(\"h1_diasbp_noninvasive_max\")\ntoDrop.append(\"h1_diasbp_noninvasive_min\")","154fb10f":"cols = selectCategory(dictionary,\"labs\")\n\nplt.figure(figsize=(20,20))\nsns.heatmap(abs(train[cols[\"Variable Name\"]].corr()),annot=True)\nplt.show()","c9226c46":"for col in cols[\"Variable Name\"].values:\n    if col.startswith(\"d1_\"):\n        print(\"Column to delete: {}\".format(col))\n        toDrop.append(col)","036dd079":"print(\"Total columns to drop: {}\".format(len(toDrop)))","bab7d26c":"# Drop columns\ntrain.drop(toDrop,axis=1,inplace=True)","348c2751":"train.shape","ca64ad93":"for col in train.columns:\n    print(col)","bcec9a39":"categoricals_features = [\"hospital_id\", \"hospital_admit_source\",\n                         \"icu_admit_source\",\"icu_id\",\"icu_type\",\n                         \"apache_3j_bodysystem\",\"bmi_category\"]","8b049e61":"for cat in categoricals_features:\n    print(\"{}: {}\".format(cat,train[cat].nunique()))","0f8daa66":"# This cell is taken from \n# https:\/\/www.kaggle.com\/jayjay75\/wids2020-lgb-starter-adversarial-validation\n\n# categorical feature need to be transform to numeric for mathematical purpose.\n# different technics of categorical encoding exists here we will rely on our model API to deal with categorical\n# still we need to encode each categorical value to an id , for this purpose we use LabelEncoder\n\nprint('Transform all String features to category.\\n')\nfor usecol in categoricals_features:\n    train[usecol] = train[usecol].astype('str')\n    test[usecol] = test[usecol].astype('str')\n    \n    #Fit LabelEncoder\n    le = LabelEncoder().fit(\n            np.unique(train[usecol].unique().tolist()+\n                      test[usecol].unique().tolist()))\n\n    #At the end 0 will be used for null values so we start at 1 \n    train[usecol] = le.transform(train[usecol])+1\n    test[usecol]  = le.transform(test[usecol])+1\n    \n    train[usecol] = train[usecol].replace(np.nan, 0).astype('int').astype('category')\n    test[usecol]  = test[usecol].replace(np.nan, 0).astype('int').astype('category')","16febb94":"train[categoricals_features].isna().sum(axis=0)","8a8ef46c":"X_train = train.drop(\"hospital_death\",axis=1)\ny_train = train[\"hospital_death\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.20, random_state=2020)","45f88942":"# function to evaluate the score of our model\ndef eval_auc(pred,real):\n    false_positive_rate, recall, thresholds = roc_curve(real, pred)\n    roc_auc = auc(false_positive_rate, recall)\n    return roc_auc","7bd37e12":"train_pool = Pool(data=X_train,label = y_train,cat_features=categoricals_features)\ntest_pool = Pool(data=X_test,label = y_test,cat_features=categoricals_features)\n\nmodel_basic = CatBoostClassifier(iterations=100,custom_metric='AUC:hints=skip_train~false', \n                                 metric_period=2,task_type=\"GPU\")\nmodel_basic.fit(train_pool,plot=True,eval_set=test_pool)","e220eae3":"print(model_basic.get_best_score())","7d323e87":"# model = CatBoostClassifier(eval_metric='AUC:hints=skip_train~false',task_type=\"GPU\",\n#                           depth=9, iterations=800, learning_rate = 0.1,\n#                           custom_metric = 'AUC:hints=skip_train~false')\n\n# train_pool = Pool(data=X_train,label = y_train,cat_features=categoricals_features)\n# test_pool = Pool(data=X_test,label = y_test,cat_features=categoricals_features)\n# model.fit(train_pool,plot=True,eval_set=test_pool)\n\n# Uncomment this cell to perform grid search\n# The results I found are:\n\n# Best model params: \n# {'depth': 9, 'iterations': 800, 'learning_rate': 0.1, 'custom_metric': 'AUC:hints=skip_train~false'}\n\n# grid = {'learning_rate': [0.06, 0.08, 0.1, 0.12, 0.14],\n#         'depth': [7, 9, 11, 13],\n#         \"iterations\": [400, 600, 800, 1000],\n#        \"custom_metric\":['Logloss:hints=skip_train~false', 'AUC:hints=skip_train~false']}\n\ngrid = {'learning_rate': [0.08, 0.1],\n        'depth': [7, 9],\n        \"iterations\": [600,800]}#,\n       #\"custom_metric\":['Logloss:hints=skip_train~false', 'AUC:hints=skip_train~false']}\n\nX_train = train.drop(\"hospital_death\",axis=1)\ny_train = train[\"hospital_death\"]\ntrain_pool = Pool(data=X_train,label = y_train,cat_features=categoricals_features)\n\n# model = CatBoostClassifier(eval_metric='AUC:hints=skip_train~false',task_type=\"GPU\")\nmodel = CatBoostClassifier(eval_metric='AUC:hints=skip_train~false',task_type=\"GPU\",\n                          custom_metric='AUC:hints=skip_train~false')\n\ngrid_search_result = model.grid_search(grid, \n                                       train_pool,\n                                       plot=True,\n                                       refit = True,\n                                       partition_random_seed=2020\n                                    )\n\n# print(\"Best model params: \\n\",grid_search_result[\"params\"])","959ebbf1":"print(model.get_best_score())","bc5d252c":"feature_importances = model.get_feature_importance(train_pool)\nfeature_names = X_train.columns\nfor score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n    if score > 0.05:\n        print('{0}: {1:.2f}'.format(name, score))","f6ed4e72":"testEncounterId = test.encounter_id","5b04c9bd":"test.drop(toDrop,axis=1,inplace=True)","3525220d":"test[\"hospital_death\"] = model.predict(test.drop([\"hospital_death\"],axis=1),prediction_type='Probability')[:,1]","62d80546":"test[\"encounter_id\"] = testEncounterId","dc97df00":"test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"submission.csv\",index=False)","98eea6b5":"There are 2 columns - `apache_3j_bodysystem` and `apache_2_bodysystem` which belong to this category. Both of them provide the admission diagnosis group for APACHE II and III, respectively. \n\n**APACHE** or Acute Physiology and Chronic Health Evaluation is another ICU scoring system which provides information about the severity of disease and risk of deaths in the first 24 hours of patient's admission to an ICU. The range lies between 0 and 71 (integers), higher the number, greater the risk of death.\n\nSince both columns are effectively APACHE columns, it can be expected that both of them have high correlation. The same is seen as per [this report](https:\/\/pubmed.ncbi.nlm.nih.gov\/11579607):\n\n> \"Results: Both systems showed a significant association between higher scores and higher mortality. The APACHE II system under-predicted the actual hospital mortality rate. The APACHE III systems had a higher discriminative power (area 0.7462) than the APACHE II systems (area 0.6856; p < 0.05).\"\n\nThis shows that APACHE III is a better score than APACHE II. Thus, whenever required, we will prefer APACHE III over APACHE II. This will also help in reducing multi-correlation between columns.","64adc6cc":"Let's now refer to the dictionary file to get a better understanding of various columns present in the dataset.","b62aed80":"The first thing that we observe is that there are large number of outliers. Let's analyse this column based on the target variable.","990ce4f5":"As we saw above, bmi in itself was not having any major effect, but as soon as we converted it to the categories, we can see that some categories like `underweight` have a larger ratio of hospital deaths and thus would be a better choice than bmi.","5b9f8314":"# Predicting Patient Survival in ICU\n\n## Project Description\n\nWhenever a patient is moved to the ICU or Intensive Care Unit, it suggests that the patient's health can rapidly deteriorate and hence, the urgency and the type of treatment is decided upon observing the patient.\n\n \nGiven the data about various measurements of a patient within the first 24 hours of being\nadmitted to an intensive care ward, if we can predict the survival probability of a patient, then\nwe can respond to threats in advance and give the patient more advanced form of care if\npossible, so as to increase the chances of survival. This will improve the mortality rate in hospitals. A stark point to note in this scenario, as is the case in various medical problems, the\ndata is highly imbalanced. \n\n## Overview\n\nThe challenge is to create a model that uses data from the first 24 hours of intensive care to predict patient survival. MIT's GOSSIS community initiative, with privacy certification from the Harvard Privacy Lab, has provided a dataset of more than 130,000 hospital Intensive Care Unit (ICU) visits from patients, spanning a one-year timeframe. This data is part of a growing global effort and consortium spanning Argentina, Australia, New Zealand, Sri Lanka, Brazil, and more than 200 hospitals in the United States.","31d95177":"### APACHE grouping","3bb1296f":"Here we are using label encoding to convert all the categorical features into numerical features.","338d8d06":"There are about 55% male and 45% female patients which shows that in terms of gender, the dataset is about balanced.","e4397720":"We can see that about 9% of the patients who were admitted not for an elective surgery died, whereas the percentage is 3% in case when the patients were admitted for an elective surgery. This might be because elective surgeries are usually not very serious in nature.\n\nNext, let's look at the ethnicity column.","50370c7e":"### Labs","605c30a7":"Next, we will look at `pre_icu_los_days` column.","20d217a4":"Now that we have carried out the EDA part, the next step to carry is Data Pre-processing in order to convert the columns to their proper datatype.","14250f6f":"We can see that most patients are between the age of 50 to 90, which clearly shows a skewed distribution.","f4621133":"As we can see, the percentage of deaths are about uniform for each ethnicity, and thus, ethnicity column can be dropped from the dataframe.","2fbefb02":"Just like in the case of height, weight also does not seem to have a significant effect on the target variable and can be dropped (anyways we are thinking of taking into account the bmi).","e61d646f":"Let's go over each category one by one.","6e5afb19":"As we can see, this column has only value 0 which means that it does not provide any extra information and thus, can be dropped.","5fe05fa3":"We will use AUC as the evaluation metric. We won't be using accuracy since we are dealing with an imbalanced dataset.","a0fcdc12":"We can see that around 80% patients were not admitted for elective surgery. Let's see if there is any correlation between this feature and the target feature.","14685692":"**We don't really need to deal with missing values here since we are planning to use Boosting models like CatBoost which work fine with missing values.**\n\nBut, we can still use techniques like `SimpleImputer` if we are using other ML algorithms. (Not done here)","b8f422c7":"The next column we will be focusing on is `elective_surgery`.","8a4d97d9":"All of the above features provide information about the specific disease that a patient was diagnosed with. While there can be some correlation between these features based on symptoms, it's better to keep all of them as it is. We can also fill the missing values with 0 in the case of each of these features.","9c29f5a3":"## Data Pre-processing","8c2543b7":"Since we can see some correlation in daily and hourly attributes, we can drop the daily attributes and focus on hourly features. The reason being that the hourly features will be available much sooner than daily ones and that's why, based on those features, the suitable action can be taken much sooner.","6d04e8aa":"As we can see from the description, these set of features provide information about the patient's vitals during the first hour and the first 24 hours of their stay. Let's see if there is any correlation in these columns.","6070c970":"As we can see, it has far less unique values meaning that it might be conveying important information about the specific icu in which the patient was admitted and can have some effect on the target variable.","78b76aa7":"### Demographic","ebaa989f":"As we can see, height is not having any significant effect on the target column and thus can be dropped.\n\nNext, we will look at `hospital_admit_source` column which gives information about where the patient was before getting admitted to the hospital.","097e3f69":"As we can see, there are some columns which have large percentage of missing values.","c0991687":"The main difference, as we can see, is that in case of hospital deaths, the number of days is much lower.","0440f1c0":"We can see that there is a larger proportion (close to 80%) of patients from one specific ethnicity. This also shows that if we use this to train our model, we might end up with higher bias towards ethnicity, which is not desirable.","f06b8a39":"### Labs blood gas","f6bf6428":"There are 91.7k samples and 186 columns.","46b4f245":"Next, we will look at `icu_type` column.","76ee4cf0":"Next, let's explore the `gender` column.","ca1813bd":"As we can see, the 2 columns in the above category provide information about the mortality of a patient. Again, we can expect some correlation for both the columns. Let's verify the same.","178f6bcd":"Because of the extensive EDA, we have come up with 59 columns which can be dropped. We have also added one extra column (`bmi_category`) which, as we saw earlier, provides better information than bmi. Now, we can further process these columns and fit a classification model.","ba2b1196":"## Model Training & Evaluation","59385478":"As we can see, there is no significant effect of gender on the `hospital_death` column and thus, can be dropped.\n\nNow, let's look at the `height` column.","b7855e7b":"As expected, most patients from accident\/emergency and OR\/recovery are admitted to the ICU.","508a5b67":"### APACHE comorbidity","40386227":"The next column (the last one in this category) that we will explore is `weight`.","d0388cc9":"Next we will go over the `bmi` column.","e3b27bca":"As we would expect, age is important.\n\nThe top features are precalculated predictors of risk of death (which likely take age into account).\n\nWe see that there's a difference between hospitals , although it's not an especially clear or linear feature. One explanation may be differences in skill of departments\/doctors inside each hospital, with these \"latent\"\/hidden variables interacting with other factors in our dataset","105f5969":"As we can see, we have some id columns - `encounter_id`, `patient_id`, `hospital_id`, `icu_id`\n\nThere are some columns like `readmission_status` which only have value 0 and can be ignored since they don't provide any extra information.\n\nWe also have the target column - `hospital_death` which is already numerical (0 and 1)\n\nOther important columns we have are:\n\n1. `age` - Age of the patient\n2. `bmi` - BMI of the patient (Since we already have information about BMI, we can ignore height and weight)\n3. `elective_surgery` - Categorical feature\n\netc.\n\nWe also have some features providing apache scores.","cb20a73c":"As we can see above, there are some high correlation columns, but since these are vitals about patients, it's better to not drop them for now.\n\nBut, we can still drop the following columns:\n\n1. `h1_sysbp_noninvasive_max`\n2. `h1_sysbp_noninvasive_min`\n3. `h1_mbp_noninvasive_max`\n4. `h1_mbp_noninvasive_min`\n5. `h1_diasbp_noninvasive_max`\n6. `h1_diasbp_noninvasive_min`","87dd7f5a":"From the above correlation heatmap, we can drop the following columns:\n\n1. `d1_sodium_min`\n2. `d1_sodium_max`\n3. `d1_wbc_max`\n4. `d1_wbc_min`\n5. `d1_platelets_max`\n6. `d1_platelets_min`\n7. `d1_lactate_max`\n8. `d1_lactate_min`\n9. `h1_hco3_max`\n10. `h1_hco3_min`\n11. `d1_bun_max`\n12. `d1_bun_min`\n13. `d1_bilrubin_min`\n14. `d1_bilrubin_max`\nand so on...\n\nOn a more general level, we can decide to drop all the daily attributes and only keep the hourly features.","951746b0":"Next, we will look at `readmission_status` column.","13e8c8b3":"The next step is to use an ML algorithm for training. Let's start with a simple CatBoost algorithm.","f0ffcac4":"Let's first make the list of categorical and numerical features.","f1386394":"We can clearly see a variation in percentage of deaths for different ICU admit sources and thus, it is a feature which we cannot drop.\n\nNext, we will explore the `icu_admit_type` column.","eafec353":"## Exploratory Data Analysis","d949b36a":"As we can see, the specified column is actually not present in the dataframe, which raises an important concern that **there are columns in the dictionary which are not present in the dataframe.**","cb410540":"Let's go over each column in this category, one by one. We will start off with `hospital_death` which is our target column as well.","4da4bfe4":"Out of the 186 features, 8 are of `object` data types. These can be categorical features.","87f51860":"### Vitals","4ccbbfc3":"The category column gives information about the category of the feature.","0c45a6bf":"The next column we will go over is the `age` column which describes the age of the patient.","cc875f43":"Notice that there is no significant difference in distribution of bmi for target variable.\n\nWe can see that there is a higher distribution of bmi lying in \"overweight\" (25.0 to 29.9), \"obese\" (30.0 and above) and the \"normal\" (18.5 to 24.9), in the same order. We can verify the same as follows.","324b9c9a":"### APACHE covariate","510307f7":"Next we will look at `icu_stay_type` column.","80fe6e05":"There is a significant variation in percentage of hospital deaths for the ICU types which means that there is an effect of the ICU type on the target variable.","91d9b843":"We will next separate out the target column from the training dataset.","00d496b3":"From the above bar graph, we can clearly see the imbalance in the dataset.","ba17c267":"We can see that `encounter_id` and `patient_id` are unique for every data point and thus, do not provide any extra information and can be dropped. `hospital_id` can convey information about the facilities, doctors, etc. available at a specific hospital.","d6a9e9ce":"Next, we will convert these categorical features into numerical features. First, let's check the number of categories in each of these categorical features.","e7a0e843":"## Submission","b6ba6d3d":"GOSSIS score refers to the **Global Open Source Severity of Illness Score** which gives an idea about how severe a patient is. We can try comparing this particular feature with the `hospital_death` column to if there is any correlation between the 2 columns.","f98857eb":"Let's first verify that there are no missing values in categorical columns.","1e3894d6":"We can see that there is a correlation of 0.88 between both the columns. Since we are more interested in cases dealing with ICU, we can drop the `apache_4a_hospital_death_prob` column.","f1292f22":"And there we go! We have finally found the second column which was present in the dictionary but not in the columns :)","d737c3f6":"The above plot does not provide us information about the proportion of deaths with respect to elective surgery. Let's try and obtain that.","9f6bd014":"As we can see above, there is a clear imbalance in the distribution of ICU types, with Med-Surg ICU being about 55%.","b2e02e71":"### Identifier","aa4b72c6":"We can see the same above. There are actually 186 columns in the dataset but 188 in the dictionary. This means that there is one more column which is missing in the dataframe but present in the dictionary.","72c8fe03":"We can see that most patients (roughly 55%) were present in the emergency department before getting admitted to the hospital.\n\nLet's check if this has any effect on the target variable.","312b506b":"### GOSSIS example prediction","ddbae32e":"For the other categories, we will simply look at the correlation since they are more important and considering them one by one will take a lot of time.","ccd921e6":"As we can see, around 90% of the values are from `admit` category, which clearly shows the imbalance.","3012a9f2":"As we can see, we are now left with 128 columns only, which is a significantly smaller number than what we had in the beginning (187).","db0a0ddc":"Now that we have the trained model, let's find the feature importances.","77851419":"There is no significant variation in percentage hospital deaths for the 3 icu stay types and can be dropped.","b52a8cbe":"We have mainly two categories of features in the dataset. One which have more than 50% missing values and the second which have less than 20% missing values. This clearly shows the variation in the dataset's features in terms of missing value percentages.","2944cdf6":"We can clearly see a variation in percentage of deaths for different hospital admit sources and thus, it is a feature which we cannot drop.\n\nNext, we will look at `icu_admit_source` column.","94cf1e80":"We can also carry out hyperparameter tuning in order to obtain better parameters.","08ef5224":"Next, we will look at `icu_id` column. We will check if it is unique for every data point or if it conveys some information, just like `hospital_id` did.","5a1de60a":"As we can see from the above columns, in most cases the values in both columns is same. The `Sepsis` and `Cardiovascular` actually can be explained based on the fact that cardiovascular diseases or cardiac dysfunction is a consequence of severe sepsis.\n\n`Neurological` and `Neurologic` are essentially the same body systems.\n\nSince we are preferring APACHE III over APACHE II, we can drop the `apache_2_bodysystem` column.","a6a100a7":"### APACHE prediction","ab4c7030":"From the above correlation heatmap, we can see that there is high correlation between some columns. Based on the same, we will drop the following columns:\n\n1. `ventilated_apache`\n2. `gcs_eyes_apache`\n3. `gcs_verbal_apache`\n4. `apache_3j_diagnosis`"}}