{"cell_type":{"953e261f":"code","097e3198":"code","0a470595":"code","c76665df":"code","4faf7f4c":"code","5618c246":"code","8f0b88e2":"code","7e438441":"code","834ef4e7":"code","b982b084":"code","9fe3e80c":"code","887b9d9c":"code","a3527a77":"code","5b8f4289":"code","9ce073c8":"code","c0569573":"code","83caa2a4":"code","47bd01ac":"code","ce5dc45a":"code","db7f39bf":"code","63907f03":"code","58a8b2c8":"code","5668cf16":"code","b08cd031":"code","771edd64":"code","dea149bc":"code","ac481735":"code","c55c9c97":"code","f03e3173":"code","3c70edfd":"code","74a8b377":"code","5a5c4bc6":"code","a7e87a4c":"code","d692e4c0":"code","3328a5a7":"markdown","37e3e3c0":"markdown","91c06cd2":"markdown","93bc69dc":"markdown","d3b819d0":"markdown","afe50353":"markdown","9a56b513":"markdown","c5336f3f":"markdown","7c8e651b":"markdown","4f590eb0":"markdown","058873eb":"markdown","03da323b":"markdown","1f5a9a7d":"markdown","acf6e443":"markdown","50c0883f":"markdown","c550f91f":"markdown","e840ce41":"markdown","9c8229a8":"markdown","89c58a3e":"markdown","30b59ead":"markdown","d811260b":"markdown","010cb1ef":"markdown","335a3a5f":"markdown","d07b8033":"markdown","bb878afc":"markdown","e2efa5ac":"markdown"},"source":{"953e261f":"from IPython.display import YouTubeVideo\n\nYouTubeVideo('mPFq5KMxKVw', width=800, height=450)\n","097e3198":"YouTubeVideo('3_2TnCqBFcY', width=800, height=450)","0a470595":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNetV2, VGG19\nfrom tensorflow.keras.models import Sequential\nfrom keras import regularizers\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, InputLayer, Reshape, Conv1D, MaxPool1D, SeparableConv2D\nimport time\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import cross_validate, train_test_split\nimport matplotlib.pyplot as plt\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c76665df":"import shutil\nprint(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/\"))\n\nbase_dir = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/'\nwork_dir = 'work\/'\n#os.mkdir(work_dir)\n\nbase_dir_A = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\/' \nbase_dir_B = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected\/'\n\nwork_dir_A = 'work\/A\/'\n#os.mkdir(work_dir_A)\nwork_dir_B = 'work\/B\/'\n#os.mkdir(work_dir_B)","4faf7f4c":"train_dir = os.path.join(work_dir, 'train')\n#os.mkdir(train_dir)\n\nvalidation_dir = os.path.join(work_dir, 'validation')\n#os.mkdir(validation_dir)\n\ntest_dir = os.path.join(work_dir, 'test')\n#os.mkdir(test_dir)\n\nprint(\"New directories for train, validation, and test created\")\ntrain_pos_dir = os.path.join(train_dir, 'pos')\n#os.mkdir(train_pos_dir)\ntrain_neg_dir = os.path.join(train_dir, 'neg')\n#os.mkdir(train_neg_dir)\n\nvalidation_pos_dir = os.path.join(validation_dir, 'pos')\n#os.mkdir(validation_pos_dir)\nvalidation_neg_dir = os.path.join(validation_dir, 'neg')\n#os.mkdir(validation_neg_dir)\n\ntest_pos_dir = os.path.join(test_dir, 'pos')\n#os.mkdir(test_pos_dir)\ntest_neg_dir = os.path.join(test_dir, 'neg')\n#os.mkdir(test_neg_dir)\n\nprint(\"Train, Validation, and Test folders made for both A and B datasets\")","5618c246":"i = 0\n      \nfor filename in os.listdir(base_dir_A): \n    dst =\"pos\" + str(i) + \".jpg\"\n    src =base_dir_A + filename \n    dst =work_dir_A + dst \n          \n       # rename() function will \n       # rename all the files \n    shutil.copy(src, dst) \n    i += 1\n\n\nj = 0\n\nfor filename in os.listdir(base_dir_B): \n    dst =\"neg\" + str(j) + \".jpg\"\n    src =base_dir_B + filename \n    dst =work_dir_B + dst \n          \n    # rename() function will \n    # rename all the files \n    shutil.copy(src, dst) \n    j += 1       \n        \nprint(\"Images for both categories have been copied to working directories, renamed to A & B + num\")","8f0b88e2":"fnames = ['pos{}.jpg'.format(i) for i in range(3000)]\nfor fname in fnames:\n    src = os.path.join(work_dir_A, fname)\n    dst = os.path.join(train_pos_dir, fname)\n    shutil.copyfile(src, dst)\n\nfnames = ['pos{}.jpg'.format(i) for i in range(3000, 4000)]\nfor fname in fnames:\n    src = os.path.join(work_dir_A, fname)\n    dst = os.path.join(validation_pos_dir, fname)\n    shutil.copyfile(src, dst)\n\nfnames = ['pos{}.jpg'.format(i) for i in range(4000, 4500)]\nfor fname in fnames:\n    src = os.path.join(work_dir_A, fname)\n    dst = os.path.join(test_pos_dir, fname)\n    shutil.copyfile(src, dst)\n","7e438441":"\nfnames = ['neg{}.jpg'.format(i) for i in range(3000)]\nfor fname in fnames:\n    src = os.path.join(work_dir_B, fname)\n    dst = os.path.join(train_neg_dir, fname)\n    shutil.copyfile(src, dst)\n\nfnames = ['neg{}.jpg'.format(i) for i in range(3000, 4000)]\nfor fname in fnames:\n    src = os.path.join(work_dir_B, fname)\n    dst = os.path.join(validation_neg_dir, fname)\n    shutil.copyfile(src, dst)\n\nfnames = ['neg{}.jpg'.format(i) for i in range(4000, 4500)]\nfor fname in fnames:\n    src = os.path.join(work_dir_B, fname)\n    dst = os.path.join(test_neg_dir, fname)\n    shutil.copyfile(src, dst)\n    \nprint(\"Train, validation, and test datasets split and ready for use\")\nprint('total training pos images:', len(os.listdir(train_pos_dir)))\nprint('total training neg images:', len(os.listdir(train_neg_dir)))\nprint('total validation pos images:', len(os.listdir(validation_pos_dir)))\nprint('total validation neg images:', len(os.listdir(validation_neg_dir)))\nprint('total test pos images:', len(os.listdir(test_pos_dir)))\nprint('total test neg images:', len(os.listdir(test_neg_dir)))","834ef4e7":"train_datagen = ImageDataGenerator(rescale=1.0\/255.0, validation_split=0.33)","b982b084":"train_generator = train_datagen.flow_from_directory(directory= train_dir,             \n                                                     target_size=(128, 128),\n                                                     class_mode='binary',\n                                                     subset='training',\n                                                    shuffle=True,\n                                                     batch_size=32\n                                 )\n\nvalid_generator = train_datagen.flow_from_directory(directory= validation_dir,\n                                                      target_size=(128, 128),\n                                                     class_mode='binary',\n                                                           shuffle = True,\n                                                     subset='validation',\n                                                     batch_size=32,\n                                                    \n                                                     )\n\n\nclasses = ['Parasitized', 'Uninfected']\n","9fe3e80c":"sample_training_images, train_label = next(train_generator)","887b9d9c":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout() \n    plt.show()","a3527a77":"print('Random Display of Cell images')\nplotImages(sample_training_images[:5])\n","5b8f4289":"input_length = 128,128,3\n\nds_model = Sequential()\nds_model.add(Conv2D(16,(3,3),activation='relu',input_shape=(128,128,3)))\nds_model.add(MaxPool2D(2,2))\nds_model.add(Dropout(0.2))\n\nds_model.add(Conv2D(32,(3,3),activation='relu'))\nds_model.add(MaxPool2D(2,2))\nds_model.add(Dropout(0.2))\n\nds_model.add(SeparableConv2D(64,(3,3),activation='relu'))\nds_model.add(MaxPool2D(2,2))\nds_model.add(Dropout(0.3))\n\nds_model.add(SeparableConv2D(128,(3,3),activation='relu'))\nds_model.add(MaxPool2D(2,2))\nds_model.add(Dropout(0.3))\n\nds_model.add(Flatten())\nds_model.add(Dense(64,activation='relu'))\nds_model.add(Dropout(0.5))\n\nds_model.add(Dense(1,activation='sigmoid'))\n\nopt = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\nds_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\nds_model.summary()","9ce073c8":"early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)","c0569573":"history = ds_model.fit_generator(train_generator,\n                              epochs=20,\n                              steps_per_epoch= len(train_generator),\n                              validation_data = (valid_generator),\n                              callbacks = [early_stop]\n                              #verbose=1\n                              )","83caa2a4":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(history)","47bd01ac":"ds_model_name = 'dsmalaria_predsmodel.h5'\nds_model.save_weights(ds_model_name)","ce5dc45a":"model = Sequential()\nmodel.add(MobileNetV2(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.layers[0].trainable = False\n\nopt = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","db7f39bf":"history = model.fit_generator(train_generator,\n                              epochs=20,\n                              steps_per_epoch= len(train_generator),\n                              validation_data = (valid_generator),\n                              callbacks = [early_stop],\n                              verbose=1\n                              )","63907f03":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(history)","58a8b2c8":"model_name = 'malaria_predsmodel.h5'\nmodel.save_weights(model_name)","5668cf16":"vgg_model = Sequential()\nvgg_model.add(VGG19(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\nvgg_model.add(Flatten())\nvgg_model.add(Dense(256,activation='relu'))\nvgg_model.add(Dense(64,activation='relu'))\nvgg_model.add(Dense(1,activation = 'sigmoid'))\n\nvgg_model.layers[0].trainable = False\n\nopt = tf.keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999)\nvgg_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\nvgg_model.summary()","b08cd031":"vgg_history = vgg_model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              epochs=20,\n                              validation_steps = len(valid_generator),\n                                      validation_data = valid_generator,\n                              callbacks = [early_stop],\n                                      verbose=1\n                                     )","771edd64":"vgg_model_name = 'vgg_malaria_predsmodel.h5'\nmodel.save_weights(vgg_model_name)","dea149bc":"def visualize_training(vgg_history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(vgg_history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(vgg_history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(vgg_history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(vgg_history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(vgg_history)","ac481735":"inception_model = Sequential()\ninception_model.add(tf.keras.applications.InceptionV3(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\ninception_model.add(Flatten())\ninception_model.add(Dense(64,activation='relu'))\ninception_model.add(Dense(1,activation = 'sigmoid'))\n\ninception_model.layers[0].trainable = False\n\nopt = tf.keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999)\n\ninception_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\ninception_model.summary()","c55c9c97":"inception_history = inception_model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              epochs=20,\n                              validation_data=valid_generator,\n                              callbacks = [early_stop],\n                                                  verbose=1\n                                     )","f03e3173":"inception_model_name = 'inceptionv3_malaria_predsmodel.h5'\nmodel.save_weights(inception_model_name)","3c70edfd":"def visualize_training(inception_history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(inception_history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(inception_history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(inception_history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(inception_history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(inception_history)","74a8b377":"eval_datagen = ImageDataGenerator(rescale=1.\/255)\neval_generator = eval_datagen.flow_from_directory(\n        test_dir,target_size=(128, 128),\n        batch_size=32,\n        class_mode='binary')\neval_generator.reset()    \npred = ds_model.predict_generator(eval_generator,1000,verbose=1)\nprint(\"Predictions finished\")\n  \nimport matplotlib.image as mpimg\nfor index, probability in enumerate(pred):\n    image_path = test_dir + \"\/\" +eval_generator.filenames[index]\n    img = mpimg.imread(image_path)\n    \n    plt.imshow(img)\n    print(eval_generator.filenames[index])\n    if probability > 0.5:\n        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n    else:\n        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n    plt.show()","5a5c4bc6":"eval_datagen = ImageDataGenerator(rescale=1.\/255)\neval_generator = eval_datagen.flow_from_directory(\n        test_dir,target_size=(128, 128),\n        batch_size=32,\n        class_mode='binary')\neval_generator.reset()    \npred = model.predict_generator(eval_generator,1000,verbose=1)\nprint(\"Predictions finished\")\n  \nimport matplotlib.image as mpimg\nfor index, probability in enumerate(pred):\n    image_path = test_dir + \"\/\" +eval_generator.filenames[index]\n    img = mpimg.imread(image_path)\n    \n    plt.imshow(img)\n    print(eval_generator.filenames[index])\n    if probability > 0.5:\n        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n    else:\n        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n    plt.show()","a7e87a4c":"eval_datagen = ImageDataGenerator(rescale=1.\/255)\neval_generator = eval_datagen.flow_from_directory(\n        test_dir,target_size=(128, 128),\n        batch_size=32,\n        class_mode='binary')\neval_generator.reset()    \npred = vgg_model.predict_generator(eval_generator,1000,verbose=1)\nprint(\"Predictions finished\")\n  \nimport matplotlib.image as mpimg\nfor index, probability in enumerate(pred):\n    image_path = test_dir + \"\/\" +eval_generator.filenames[index]\n    img = mpimg.imread(image_path)\n    \n    plt.imshow(img)\n    print(eval_generator.filenames[index])\n    if probability > 0.5:\n        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n    else:\n        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n    plt.show()","d692e4c0":"eval_datagen = ImageDataGenerator(rescale=1.\/255)\neval_generator = eval_datagen.flow_from_directory(\n        test_dir,target_size=(128, 128),\n        batch_size=32,\n        class_mode='binary')\neval_generator.reset()    \npred = inception_model.predict_generator(eval_generator,1000,verbose=1)\nprint(\"Predictions finished\")\n  \nimport matplotlib.image as mpimg\nfor index, probability in enumerate(pred):\n    image_path = test_dir + \"\/\" +eval_generator.filenames[index]\n    img = mpimg.imread(image_path)\n    \n    plt.imshow(img)\n    print(eval_generator.filenames[index])\n    if probability > 0.5:\n        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n    else:\n        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n    plt.show()","3328a5a7":"# Save Model","37e3e3c0":"# Save InceptionV3","91c06cd2":"# Uninfected Images","93bc69dc":"![Malaria_cycle](https:\/\/i1.wp.com\/www.malariasite.com\/wp-content\/uploads\/2015\/02\/EID_lec17_slide8-large.jpg?resize=799%2C664&ssl=1)","d3b819d0":"# InceptionNet","afe50353":"# Image Augmentation","9a56b513":"# Checking Trained Data on Test Data","c5336f3f":"# InceptionV3\n\n![architecture](https:\/\/miro.medium.com\/max\/960\/1*gqKM5V-uo2sMFFPDS84yJw.png)","7c8e651b":"# Depth-Wise Separable CNN (DS-CNN)\n\nThis model is faster form of convolution model \nYou can understand more about this [here](https:\/\/www.youtube.com\/watch?vT7o3xvJLuHk&t=12s)","4f590eb0":"# Loading Libraries","058873eb":"# Beginner's intro to Malaria","03da323b":"# DS-CNN","1f5a9a7d":"# VGG-19","acf6e443":"# Save VGG model","50c0883f":"# Dataset preprocessing","c550f91f":"# VGG-19\n\n![vgg_architecture](https:\/\/www.researchgate.net\/profile\/Clifford_Yang\/publication\/325137356\/figure\/fig2\/AS:670371271413777@1536840374533\/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means.jpg)","e840ce41":"# Importing Prerequisite Libraries","9c8229a8":"# MobileNet","89c58a3e":"# Displaying The Images","30b59ead":"***Big thanks to Medium article of Adrian Yijie Xu for excellent [article](https:\/\/medium.com\/gradientcrescent\/building-a-malaria-classifier-with-keras-background-implementation-d55c32773afa), \nDo check it out!!***\n ***","d811260b":"# MobileNet Model Developement\n\n***Here I will be using MobileNetV2 architecture below I will be showing architecture of different MobileNet models***\n\n![mobilenet](https:\/\/miro.medium.com\/max\/1882\/1*bqE59FvgpvoAQUMQ0WEoUA.png)","010cb1ef":"# Model metrics plot","335a3a5f":"# Metrics Plot","d07b8033":"# InceptionV3 metrics plot","bb878afc":"# Parasitized Images","e2efa5ac":"# Getting Started with Transfer Learning"}}