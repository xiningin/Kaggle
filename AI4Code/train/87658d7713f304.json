{"cell_type":{"3b0e9188":"code","250260f2":"code","5d0aa3ec":"code","3b6f0ab1":"code","9e1bac01":"code","28209daf":"code","6cea121d":"code","5c4466f8":"code","824d385e":"code","285d531d":"code","1064253f":"code","1c9849f5":"code","d2166ebc":"code","5261190c":"code","c9ba5e17":"code","6a983d8e":"code","9a66f67c":"code","1b7c191f":"code","ccb866f6":"code","68e8ff93":"code","6f9ce94b":"code","59226c10":"code","a46c2ae3":"code","f826bdaa":"code","d4c1a36d":"code","0f7f383f":"code","5922a6ed":"code","880dd35d":"code","2c2c4496":"code","97ea8be1":"code","9cfd4772":"code","4c198f70":"markdown","e0c4c1e1":"markdown","534789da":"markdown","8bb13089":"markdown","3bbf1a3b":"markdown","2ff6d5cd":"markdown","3c5d7dfd":"markdown","2a2e07db":"markdown","7d0c9ac8":"markdown","a329cf3c":"markdown","ed6e05a6":"markdown","8910a9e7":"markdown","00c63de5":"markdown","865305b6":"markdown","0c723fd7":"markdown","9ad77c21":"markdown"},"source":{"3b0e9188":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport pandas as pd\npd.set_option('display.max_rows', None)\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns \nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\".\"))\n['gender_submission.csv','train.csv','test.csv']","250260f2":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","5d0aa3ec":"print(train.info())\nprint(\"*\"*30)\nprint(test.info())\nprint(\"\\n\")","3b6f0ab1":"all_data = pd.concat([train,test],axis=0,ignore_index=True)\nall_data.drop(\"Survived\",inplace=True,axis=1)\nprint(all_data.info())","9e1bac01":"####Survived\n\nprint(\"\\n\")\nprint(\"About Survived\")\nprint(\"*\"*30)\nprint(train[\"Survived\"].value_counts())\n","28209daf":"####Pclass\nprint(\"\\n\")\nprint(\"About Pclass\")\nprint(\"*\"*30)\nprint(all_data[\"Pclass\"].value_counts())","6cea121d":"####Name\nprint(\"\\n\")\nprint(\"About Name\")\nprint(\"*\"*30)\nall_data[\"Title\"] = [i.split('.')[0] for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.split(',')[1] for i in all_data[\"Title\"]]\nprint(all_data[\"Name\"].value_counts())","5c4466f8":"all_data[\"Name\"] = [i.replace(\"Mr\",\"1\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Miss\",\"5\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace('Mrs',\"2\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Master\",\"4\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Dr\",\"3\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Rev\",\"1\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Col\",\"3\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Mlle\",\"2\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Ms\",\"3\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Major\",\"3\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Dona\",\"2\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Don\",\"1\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Capt\",\"1\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Lady\",\"2\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Jonkheer\",\"2\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Mme\",\"3\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"the Countess\",\"3\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace(\"Sir\",\"3\") for i in all_data[\"Name\"]]\nall_data[\"Name\"] = [i.replace('1s',\"2\") for i in all_data[\"Name\"]]","824d385e":"print(all_data[\"Name\"].value_counts())\nall_data = pd.get_dummies(data = all_data,columns=[\"Name\"])\nall_data.drop(\"Title\",axis = 1,inplace=True)","285d531d":"###Sex\nprint(\"\\n\")\nprint(\"About Sex\")\nprint(\"*\"*30)\n#print(all_data[\"Sex\"].isnull().sum())\nprint(all_data[\"Sex\"].value_counts())\nall_data = pd.get_dummies(data=all_data,columns=[\"Sex\"])","1064253f":"###Age\nprint(\"\\n\")\nprint(\"About Age\")\nprint(\"*\"*30)\nprint(\"sum of null : \"+str(all_data[\"Age\"].isnull().sum()))","1c9849f5":"###SibSp \nprint(\"\\n\")\nprint(\"About SibSp\")\nprint(\"*\"*30)\n#print(all_data[\"SibSp\"].isnull().sum())\nprint(all_data[\"SibSp\"].value_counts())","d2166ebc":"###Parch\u3000\nprint(\"\\n\")\nprint(\"About Parch\")\nprint(\"*\"*30)\nprint(all_data[\"Parch\"].isnull().sum())","5261190c":"###Ticket\nprint(\"\\n\")\nprint(\"About Ticket\")\nprint(\"*\"*30)\nprint(all_data[\"Ticket\"].isnull().sum())","c9ba5e17":"###Fare\nprint(\"\\n\")\nprint(\"About Fare\")\nprint(\"*\"*30)\nprint(all_data[all_data[\"Fare\"].isnull()])","6a983d8e":"###Cabin\nprint(\"\\n\")\nprint(\"About Cabin\")\nprint(\"*\"*30)\nprint(all_data[\"Cabin\"].isnull().sum())","9a66f67c":"###Embarked\nprint(\"\\n\")\nprint(\"About Embarked\")\nprint(\"*\"*30)\nprint(all_data[\"Embarked\"].isnull().sum())","1b7c191f":"print(\"\\n\")\nprint(\"*\"*30)\nprint(\"Ticket data\")\nprint(\"*\"*30)\nall_data.drop(\"Ticket\",axis=1,inplace=True)\nprint(\"Ticket data droped. Because the thing learned for Ticket data is no. cheap or noble? this learn for Fare data.\")","ccb866f6":"print(\"\\n\")\nprint(\"*\"*30)\nprint(\"Fare data\")\nprint(\"*\"*30)\nprint(\"Pclass of Fare's NaN : \"+str(all_data.Pclass[all_data[\"PassengerId\"]==1044]))\nprint(\"Fare of Pclass'3 mean : \"+str(all_data.Fare[all_data[\"Pclass\"]==3].mean()))\nprint(\"Fare of Pclass'3 median : \"+str(all_data.Fare[all_data[\"Pclass\"]==3].median()))\nprint(\"Fare of Pclass'3 max : \"+str(all_data.Fare[all_data[\"Pclass\"]==3].max()))\nprint(\"Fare of Pclass'3 min : \"+str(all_data.Fare[all_data[\"Pclass\"]==3].min()))","68e8ff93":"all_data.Fare.fillna(all_data.Fare.median(),inplace=True)","6f9ce94b":"print(\"*\"*30)\nprint(\"Embarked data\")\nprint(\"*\"*30)\nprint(all_data.Embarked.value_counts(dropna=False))\nprint(\"\\n\")\nprint(all_data[all_data[\"Embarked\"].isnull()])\nprint(\"\\n\")\nprint(\"About S of Fare\")\nprint(all_data.Fare[all_data[\"Embarked\"]==\"S\"].mean())\nprint(all_data.Fare[all_data[\"Embarked\"]==\"S\"].max())\nprint(all_data.Fare[all_data[\"Embarked\"]==\"S\"].min())\nprint(\"\\n\")\nprint(\"About C of Fare\")\nprint(all_data.Fare[all_data[\"Embarked\"]==\"C\"].mean())\nprint(all_data.Fare[all_data[\"Embarked\"]==\"C\"].max())\nprint(all_data.Fare[all_data[\"Embarked\"]==\"C\"].min())\nprint(\"\\n\")\nprint(\"About Q of Fare\")\nprint(all_data.Fare[all_data[\"Embarked\"]==\"Q\"].mean())\nprint(all_data.Fare[all_data[\"Embarked\"]==\"Q\"].max())\nprint(all_data.Fare[all_data[\"Embarked\"]==\"Q\"].min())","59226c10":"all_data.Embarked.fillna(all_data.Embarked.mode()[0],inplace=True)\nall_data = pd.get_dummies(data=all_data,columns=[\"Embarked\"])","a46c2ae3":"print(\"*\"*30)\nprint(\"Cabin data\")\nprint(\"*\"*30)\nall_data.drop(\"Cabin\",axis=1,inplace=True)","f826bdaa":"all_data[\"Family_size\"] = all_data[\"SibSp\"] + all_data[\"Parch\"]+1\nall_data[\"IsAlone\"] = 1\nall_data['IsAlone'].loc[all_data['Family_size'] > 1] = 0","d4c1a36d":"print(\"Age data\")\nprint(\"*\"*30)\n\n\nall_data = all_data.drop(\"PassengerId\",axis=1)\n\ndf_train = all_data[:891]\ndf_test = all_data[891:]\n\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef age_not(df):\n\n    Age_N = df[df.Age.isnull()]\n    Age_N_2 = Age_N.drop(\"Age\",axis=1)\n    Age = df[df.Age.notnull()]\n\n    X = Age.drop(\"Age\",axis=1)\n    y = Age.Age\n\n    RFR = RandomForestRegressor(random_state=0)\n    RFR.fit(X,y)\n    answer = RFR.predict(Age_N_2)\n    df.loc[df.Age.isnull(), \"Age\"] = answer\n\n    return df\n\nage_not(df_train)\nage_not(df_test)","0f7f383f":"PassengerId = test.PassengerId\n\nX = df_train\ny = train.Survived\n\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\ndf_test = sc.transform(df_test)","5922a6ed":"from sklearn import svm\nfrom sklearn.metrics import accuracy_score\n\nclf = svm.SVC(C=1.0,kernel=\"linear\")\nclf.fit(X_train,y_train)\nR_0 = clf.predict(X_test)\nprint(\"SVM : \"+str(accuracy_score(R_0,y_test)))","880dd35d":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(penalty='l2', C=100, random_state=0)\nlr.fit(X_train,y_train)\nR_1 = lr.predict(X_test)\nprint(\"Logistic : \"+str(accuracy_score(R_1,y_test)))","2c2c4496":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(random_state=0)\nrandom_forest.fit(X_train,y_train)\nR_2 = random_forest.predict(X_test)\nprint(\"RandomForest : \"+str(accuracy_score(R_2,y_test)))","97ea8be1":"from sklearn.neighbors import KNeighborsClassifier\n\nMax = 0\n\nfor i in range(1,len(X_train)):\n    knc = KNeighborsClassifier(n_neighbors=15)\n    knc.fit(X_train,y_train)\n    R_3 = knc.predict(X_test)\n    M = accuracy_score(R_3,y_test)\n    if M > Max:\n        k = i\n        Max = M\nprint(\"K\u8fd1\u508d\u6cd5 : \"+str(Max))\nprint(k)\n","9cfd4772":"print(\"*\"*30)\nprint(\"submit\")\nprint(\"*\"*30)\n\ntest_predict = lr.predict(df_test)\ndata = {'PassengerId':PassengerId,'Survived':test_predict}\nsubmission = pd.DataFrame(data=data,dtype=int)\nsubmission.PassengerId = submission.PassengerId.astype(int)\nsubmission.Survived = submission.Survived.astype(int)\nsubmission.to_csv(\"titanic5_submission.csv\",index = False)","4c198f70":"arrange data","e0c4c1e1":"LogisticRegression","534789da":"replace man is 0,women is 1,special is 3,master is 4,Miss,5","8bb13089":"data's infomation","3bbf1a3b":"apply number to NaN","2ff6d5cd":"apply the center of mean and median ","3c5d7dfd":"At first, I import things.","2a2e07db":"conect data","7d0c9ac8":"the nearest Fare is C.","a329cf3c":"submit : The most number is lr!!","ed6e05a6":"SVM","8910a9e7":"study start","00c63de5":"RandomForest","865305b6":"many many many...","0c723fd7":"name data","9ad77c21":"KNeighbors"}}