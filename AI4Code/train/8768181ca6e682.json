{"cell_type":{"7abbc469":"code","969d5419":"code","4aa40b40":"code","735502b5":"code","bab3241b":"code","108a42f6":"code","b913981a":"code","613062a7":"code","04aa1809":"code","5f275d45":"code","2ac08bef":"code","ac01fb5e":"code","b7ace76a":"code","3674369a":"code","231176bf":"code","c8585a7e":"code","b0f8135b":"code","e1d1326a":"code","fcdda993":"code","f6383e66":"code","345b9902":"code","7444f6e1":"code","c3d61fef":"code","7e1d64ca":"code","99b829e6":"code","3f8a9d46":"code","57ccbbd7":"code","4c8c39e7":"code","2fd5aff3":"code","d99527c3":"code","f1088840":"code","d419f636":"code","85f3b5c6":"code","cb431a1a":"code","e2f2acd0":"code","8d6956c6":"code","cbe1f088":"code","07e8a036":"code","c56f42c6":"code","b28a7514":"code","129c1504":"code","78f0e87e":"code","e3323ee7":"code","1dc180a2":"code","6ab965b5":"code","be55fe20":"code","6da6cf12":"code","8db159a6":"code","ad2d1e6e":"code","d4cb8fa6":"code","697f3a27":"code","648b99f2":"code","0c883e68":"code","dccc4eb6":"code","c94bdbc3":"code","e1c0b751":"code","92c44796":"code","e437dcdb":"code","34ab5bb1":"code","634498ca":"code","abc06dc0":"code","6fbf2717":"code","3711fec6":"code","7c15ca52":"code","c5a5acb7":"code","911b58f9":"code","1f354f06":"code","5054babb":"code","8f875a75":"code","5a330090":"code","9ac82cbf":"code","1c255390":"code","dfb556c2":"code","31982e09":"code","a8545ca5":"code","07fda6f1":"code","9aebc420":"code","b1b2dff3":"code","85573a5e":"code","1082588a":"code","44cb46cc":"code","d7356ded":"code","f4bc504d":"code","89190744":"code","fb8f4bf3":"code","4f142941":"code","c7be8800":"code","43c62b37":"code","5dc47bc7":"code","e67a0332":"code","7c832ebf":"code","7f3d335f":"code","acab520f":"markdown","256caa89":"markdown","a2f195b6":"markdown","72be332d":"markdown","c075638b":"markdown","068d3d9c":"markdown","08b8e3dc":"markdown","fa64228f":"markdown","1c32e942":"markdown","0656f791":"markdown"},"source":{"7abbc469":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","969d5419":"# importing useful libraries\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport plotly.express as px\nimport plotly.graph_objects as go\nsns.color_palette('bright')\nsns.set(style='darkgrid',rc = {'figure.figsize':(15,8)})\nfrom plotly.offline import iplot\nfrom sklearn.pipeline import make_pipeline \n%matplotlib inline\nprint(\"Ready,set,go....\")","4aa40b40":"#reading data set\ndf = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndftest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(df.shape)\nprint(dftest.shape)\n","735502b5":"#checking head \ndf.head()","bab3241b":"#checking head\ndftest.head()","108a42f6":"#describing the data\ndf.describe()","b913981a":"#describing the data\ndftest.describe()","613062a7":"#checking info\ndf.info()","04aa1809":"#checking info\ndftest.info()","5f275d45":"# checking for any NaN values\ndf.isna().any()","2ac08bef":"# checking for any NaN values\ndftest.isna().any()","ac01fb5e":"#checking for number of null values\ndf.isnull().sum().sort_values(ascending=False)","b7ace76a":"#checking for number of null values\ndftest.isnull().sum().sort_values(ascending=False)","3674369a":"#visuvalising the  null values\nplt.figure(figsize=(10,8))\nsns.heatmap(df.isnull(),cmap='viridis')\nplt.title('Heatmap for checking Null Values')\nplt.show()","231176bf":"#visuvalising the  null values\nplt.figure(figsize=(10,8))\nsns.heatmap(dftest.isnull(),cmap='viridis')\nplt.title('Heatmap for checking Null Values')\nplt.show()","c8585a7e":"#dropping cabin values in df and dftest\n#more nan values\n\ndf.drop('Cabin',axis=1,inplace = True)\ndftest.drop('Cabin',axis=1,inplace = True)","b0f8135b":"#checking head after dropping values\ndf.head()","e1d1326a":"#checking head after dropping values\ndftest.head()","fcdda993":"#checking pair plot\nsns.pairplot(df)","f6383e66":"#visulaising the target value\nplt.figure(figsize=(10,8))\nsns.catplot(x='Survived',data = df,kind = 'count')\nplt.show()","345b9902":"#passenger class count\nsns.catplot(data=df,x='Pclass',kind= 'count')\n","7444f6e1":"\nsns.catplot(data=dftest,x='Pclass',kind= 'count')\n","c3d61fef":"sns.countplot(df['Parch'])","7e1d64ca":"sns.countplot(data=df,x='Parch',hue='Sex')","99b829e6":"px.bar(data_frame=df,x='Pclass',y='Age',color='Sex')","3f8a9d46":"px.scatter(data_frame = df,x='Age',color='Sex')","57ccbbd7":"px.scatter(data_frame = dftest,x='Age',color='Sex')","4c8c39e7":"\npx.scatter(data_frame = dftest,x='Age',color='Pclass',template='plotly_dark')","2fd5aff3":"px.scatter(data_frame = dftest,x='Age',color='Pclass',template='plotly_dark')","d99527c3":"px.scatter(data_frame = dftest,x='Age',color='Parch')","f1088840":"px.scatter(data_frame=df,x='Fare',template='plotly_dark')","d419f636":"px.scatter(data_frame=dftest,x='Fare',template='plotly_dark')","85f3b5c6":"#plot for setting age values \n#using box plot for getting median values \n#filling nan values using median values\nsns.boxplot(x = \"Pclass\",y = \"Age\",data = df)","cb431a1a":"#using plotly.express\nfig = px.box(df, x='Pclass',y='Age',points='all',template='plotly_dark')\nfig.show()","e2f2acd0":"#using plotly.express\nfig = px.box(dftest, x='Pclass',y='Age',points='all')\nfig.show()","8d6956c6":"px.imshow(df.corr(),template='plotly_dark',title='Heat map with correlation')","cbe1f088":"#visuvalising the  null values\nplt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),cmap='viridis',annot = True,linewidths=1)\nplt.title('Heatmap for checking coefficent of co-relation')\nplt.show()","07e8a036":"#dropping Age because of negative corelation\ndf.drop('Age',axis=1,inplace = True)\ndftest.drop('Age',axis=1,inplace = True)","c56f42c6":"#describing the embarked\ndf.Embarked.describe()","b28a7514":"#filling it with most repated value\ndf.Embarked.fillna(value = 'S',inplace = True)","129c1504":"#checking \ndf.Embarked.describe()","78f0e87e":"#descrbing the Fare\ndf.Fare.describe()","e3323ee7":"dftest.Fare.describe()","1dc180a2":"dftest.Fare.fillna(value = 35.6,inplace=True)","6ab965b5":"#visuvalising the  null values\nplt.figure(figsize=(10,8))\nsns.heatmap(dftest.isnull(),cmap='viridis')\nplt.title('Heatmap for checking Null Values')\nplt.show()","be55fe20":"#visuvalising the  null values\nplt.figure(figsize=(10,8))\nsns.heatmap(df.isnull(),cmap='viridis')\nplt.title('Heatmap for checking Null Values')\nplt.show()","6da6cf12":"#dropping values\ndf.drop(['Name','Ticket','PassengerId'],axis=1,inplace = True)\ndftest.drop(['Name','Ticket','PassengerId'],axis=1,inplace = True)","8db159a6":"df.head()","ad2d1e6e":"dftest.head()","d4cb8fa6":"#dropping fare because of negative corelation with Pclass\ndf.drop(['Fare'],axis=1,inplace = True)\ndftest.drop(['Fare'],axis=1,inplace = True)","697f3a27":"#encoding sex and embarked\nsex_dummies = pd.get_dummies(df[\"Sex\"],drop_first=True)\nEmbarked_dummies = pd.get_dummies(df[\"Embarked\"],drop_first=True)","648b99f2":"#encoding sex and embarked\nsex_dummies_t = pd.get_dummies(dftest[\"Sex\"],drop_first=True)\nEmbarked_dummies_t = pd.get_dummies(dftest[\"Embarked\"],drop_first=True)","0c883e68":"#dropping original columns\ndf.drop(['Sex','Embarked',],axis=1,inplace = True)\ndftest.drop(['Sex','Embarked'],axis=1,inplace = True)","dccc4eb6":"#concatening dummies\ndf = pd.concat([df,sex_dummies,Embarked_dummies],axis=1)\ndftest = pd.concat([dftest,sex_dummies_t,Embarked_dummies_t],axis=1)","c94bdbc3":"#checking head()\ndf.head()","e1c0b751":"#checking test head\ndftest.head()","92c44796":"X= df.drop('Survived',axis=1)\ny = df['Survived']","e437dcdb":"#train_test_split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.drop('Survived',axis=1), df[\"Survived\"], test_size = 1\/3, random_state = 69)\n#printing the shapes of training and testing data\nprint(\"X_training set shape{},X_testing set shape{}\".format(X_train.shape,X_test.shape))\nprint(\"y_training set shape{},y_testing set shape{}\".format(y_train.shape,y_test.shape))","34ab5bb1":"#logistic regression\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nlr = LogisticRegression()\nlr_cv = LogisticRegressionCV()\nlr.fit(X_train,y_train)","634498ca":"predicitions = lr.predict(X_test)\n#evaluvating classification models\nfrom sklearn.metrics import confusion_matrix, accuracy_score,classification_report,plot_confusion_matrix\nprint(confusion_matrix(y_test, predicitions))\nprint(accuracy_score(y_test, predicitions))\nprint(classification_report(y_test,predicitions))\n\n","abc06dc0":"mat = confusion_matrix(y_test, predicitions)\nplt.figure(figsize=(12,8))\nsns.heatmap(data=mat, annot=True, cmap=\"icefire\", xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.title('Confusion Matrix for Logistic regression')\nplt.show()","6fbf2717":"#using cv\nlr_cv = LogisticRegressionCV(cv=10,random_state=69)\nlr_cv.fit(X_train,y_train)","3711fec6":"predicitions = lr_cv.predict(X_test)\n#evaluvating classification models\nfrom sklearn.metrics import confusion_matrix, accuracy_score,classification_report,plot_confusion_matrix\nprint(confusion_matrix(y_test, predicitions))\nprint(accuracy_score(y_test, predicitions))\nprint(classification_report(y_test,predicitions))","7c15ca52":"mat = confusion_matrix(y_test, predicitions)\nplt.figure(figsize=(12,8))\nsns.heatmap(data=mat, annot=True, cmap=\"icefire\", xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.title('Confusion Matrix for Logistic regression')\nplt.show()","c5a5acb7":"#for getting understanding about logistic regression\n#help(lr)","911b58f9":"from sklearn.model_selection import GridSearchCV","1f354f06":"gd = GridSearchCV(estimator=lr,\n                 param_grid={'C':np.arange(0,2.5,0.1),\n                            'solver':[ 'lbfgs', 'liblinear', 'sag', 'saga'],\n                             'penalty':['l1', 'elasticnet'] \n                            },\n                   cv = 15\n         )","5054babb":"#fitting the data\ngd.fit(X,y)","8f875a75":"#getting best score and best values\nprint(\"best parameters ;{}\".format(gd.best_params_))\nprint(\"best score:{}\".format(gd.best_score_))\nprint(\"best model:{}\".format(gd.best_estimator_))","5a330090":"from sklearn.ensemble import RandomForestClassifier\nrc = RandomForestClassifier()\nrc.fit(X_train,y_train)","9ac82cbf":"predicitions = rc.predict(X_test)\n#evaluvating classification models\nfrom sklearn.metrics import confusion_matrix, accuracy_score,classification_report,plot_confusion_matrix\nprint(confusion_matrix(y_test, predicitions))\nprint(accuracy_score(y_test, predicitions))\nprint(classification_report(y_test,predicitions))","1c255390":"mat = confusion_matrix(y_test, predicitions)\nplt.figure(figsize=(12,8))\nsns.heatmap(data=mat, annot=True, cmap=\"icefire\", xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.title('Confusion Matrix for Random forset')\nplt.show()","dfb556c2":"#help(rc)","31982e09":"gd = GridSearchCV(\n                    estimator=rc,\n                    cv = 10,\n                    param_grid = {\n                        'n_estimators':[50,75,100,125,150,175,200,250,500,750,1000],\n                        'max_depth':[2,3,4,5,6]\n                    }\n)","a8545ca5":"gd.fit(X,y)","07fda6f1":"#getting best values\nprint(\"best parameters ;{}\".format(gd.best_params_))\nprint(\"best score:{}\".format(gd.best_score_))\nprint(\"best model:{}\".format(gd.best_estimator_))","9aebc420":"from xgboost import XGBClassifier,XGBRFClassifier\nxgb = XGBClassifier(verbosity = 0)\nxgb.fit(X_train,y_train)","b1b2dff3":"predicitions = xgb.predict(X_test)\n#evaluvating classification models\nfrom sklearn.metrics import confusion_matrix, accuracy_score,classification_report,plot_confusion_matrix\nprint(confusion_matrix(y_test, predicitions))\nprint(accuracy_score(y_test, predicitions))\nprint(classification_report(y_test,predicitions))","85573a5e":"mat = confusion_matrix(y_test, predicitions)\nplt.figure(figsize=(12,8))\nsns.heatmap(data=mat, annot=True, cmap=\"icefire\", xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.title('Confusion Matrix for Xgbclassifier')\nplt.show()","1082588a":"xbgr = XGBRFClassifier(verbosity = 0)\nxbgr.fit(X_train,y_train)\npredicitions = xbgr.predict(X_test)\n#evaluvating classification models\nfrom sklearn.metrics import confusion_matrix, accuracy_score,classification_report,plot_confusion_matrix\nprint(confusion_matrix(y_test, predicitions))\nprint(accuracy_score(y_test, predicitions))\nprint(classification_report(y_test,predicitions))","44cb46cc":"mat = confusion_matrix(y_test, predicitions)\nplt.figure(figsize=(12,8))\nsns.heatmap(data=mat, annot=True, cmap=\"icefire\", xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.title('Confusion Matrix for Xgb random forset')\nplt.show()","d7356ded":"#help(xgb)","f4bc504d":"gd = GridSearchCV(\n                  estimator=xgb,\n                    param_grid={\n                        'n_estimators' :[100,200,300,400,1000],\n                        'max_depth':[3,5,7,9],\n                        'gamma' : range(1,5) }\n                        ,cv = 15\n)","89190744":"gd.fit(X,y)","fb8f4bf3":"#getting best score and best values\nprint(\"best parameters ;{}\".format(gd.best_params_))\nprint(\"best score:{}\".format(gd.best_score_))\nprint(\"best model:{}\".format(gd.best_estimator_))","4f142941":"#help(xbgr)","c7be8800":"gd = GridSearchCV(\n                  estimator=xbgr,\n                    param_grid={\n                        'n_estimators' :[100,150,200,250],\n                        'max_depth':[3,5,7,9],\n                        'gamma' : range(1,5) }\n                        ,cv = 10\n)\n\n\n","43c62b37":"gd.fit(X,y)","5dc47bc7":"#getting best score and best values\nprint(\"best parameters ;{}\".format(gd.best_params_))\nprint(\"best score:{}\".format(gd.best_score_))\nprint(\"best model:{}\".format(gd.best_estimator_))","e67a0332":"model = RandomForestClassifier(max_depth=3, n_estimators=100)\nmodel.fit(X_train,y_train)\nresults = model.predict(dftest)","7c832ebf":"reslut = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nreslut.head()","7f3d335f":"reslut.Survived = results\nreslut.to_csv('reslut_01.csv', index=False)","acab520f":"<h3>Cleaning Null Values<\/h3>","256caa89":"<h2>Final Model<\/h2>","a2f195b6":"<h3>Train Test Split <\/h3>","72be332d":"<h1>2.EDA<\/h1>","c075638b":"<h2>Models and there performance<\/h2>","068d3d9c":"<h3>Making Training Data Ready<\/h3>","08b8e3dc":"<h2>Random Forest Classifier<\/h2>","fa64228f":"<h2>LogisticRegression<\/h2>","1c32e942":"<h1>1. Understanding the given Data<\/h1>","0656f791":"<h2>XGBoost<\/h2>"}}