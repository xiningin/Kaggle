{"cell_type":{"2fd38baf":"code","968ebe5e":"code","9240d252":"code","a76c23a0":"code","7d998518":"code","44a77e50":"code","4ba72f4e":"code","3d0365bd":"code","6fe7e75a":"code","be2a3da4":"code","50d2ce32":"code","1a492a6e":"code","d431adcf":"code","de612217":"code","4598d987":"code","57d19898":"code","168a6e9f":"code","a5ecd263":"code","83725724":"code","75443abd":"code","8262b53d":"markdown","5f6d387c":"markdown","a669b680":"markdown","2a5f3ba6":"markdown","f854706b":"markdown","a6d748b8":"markdown","a0c106b9":"markdown","b3e6b609":"markdown","6067c42e":"markdown","98c98644":"markdown","ca8909f5":"markdown","1c587a05":"markdown","46c652de":"markdown"},"source":{"2fd38baf":"import cv2\nimport os\nimport numpy as np \nimport pandas as pd \nimport datetime\nimport random\n\nimport subprocess\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold, cross_val_score, KFold,StratifiedKFold \n\nfrom pathlib import Path\nfrom collections import Counter","968ebe5e":"data = []\ndatetime_object = datetime.date.today() #I need it to save file bc I will train a lot \nprint ('datetime_object',datetime_object)\ndata = pd.read_csv('..\/input\/dataset\/aug_digit_data13.csv')\nprint ('data',data.head(4))\n","9240d252":"labels = []\nimages = []\n\nlabels = data.iloc[: ,0].to_list() #If you want to take 100 image to test, use data.iloc[: 100 ,0].to_list()\nimages = data.iloc[: ,1].to_list()\nprint ('\\nThe number of data', len(labels))\nmax_str_len = max([len(str(label)) for i,label in enumerate(labels)])\nprint ('max_str_len',max_str_len)\n\ndata = [] #This code here for not exploding the RAM","a76c23a0":"t = []\nfor i,image in enumerate(images):\n    image = np.array(image.split(' '), dtype = float)\n    t.append(image)\nimages = []","7d998518":"images = t\nt = []\nprint ('len images', len(images))","44a77e50":"\nfor label in labels:\n    label = label.split(\"'\")[1]\n    t.append(label)\nlabels = t\nt = []","4ba72f4e":"images = np.array(images).reshape(-1, 128, 32, 1)","3d0365bd":"X_train, X_valid, y_train, y_valid = train_test_split(images, labels, train_size= 0.8, shuffle = True)\n\nimages = []\nlabels = [] #This code here for not exploding the RAM\n\nprint ('\\nlen(X_train)',len(X_train))\nprint ('len(X_valid)',len(X_valid))\nprint ('\\n X_train.shape',X_train.shape)\nprint ('\\n X_valid.shape',X_valid.shape)","6fe7e75a":"plt.figure(num='char',figsize=(9,18))\nfor i in range(9):\n    rand = random.randint(0, len(X_train))\n    plt.subplot(3,3,i+1) \n    plt.title(y_train[rand])\n    plt.imshow(np.squeeze(X_train[rand,:,:,]))\n    plt.axis('off')\nplt.show()","be2a3da4":"alphabets = '0123456789'\nprint ('the number of characters:', len(alphabets))\nnum_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\nnum_of_timestamps = 31  # max length of predicted labels # \u0110\u1eb7t num_of_timestamps <= shape(last Dense model)\n\n\ndef label_to_num(label):\n    label_num = []\n    for ch in label:\n        label_num.append(alphabets.find(ch))\n        \n    return np.array(label_num)\n\ndef num_to_label(num):\n    ret = \"\"\n    for ch in num:\n        if ch == -1:  # CTC Blank\n            break\n        else:\n            ret+=alphabets[ch]\n    return ret","50d2ce32":"train_y = np.ones([len(X_train), max_str_len]) * -1\ntrain_label_len = np.zeros([len(X_train), 1])\ntrain_input_len = np.ones([len(X_train), 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([len(X_train)])\n\nfor i in range(len(X_train)):\n    train_label_len[i] = len(y_train[i])\n    train_y[i, 0:len(y_train[i])]= label_to_num(y_train[i])  \n\nprint ('len train_y',len(train_y))","1a492a6e":"valid_y = np.ones([len(X_valid), max_str_len]) * -1\nvalid_label_len = np.zeros([len(X_valid), 1])\nvalid_input_len = np.ones([len(X_valid), 1]) * (num_of_timestamps-2)\nvalid_output = np.zeros([len(X_valid)])\n\nfor i in range(len(X_valid)):\n    valid_label_len[i] = len(y_valid[i])\n    valid_y[i, 0:len(y_valid[i])]= label_to_num(y_valid[i])  \n    \nprint ('len valid_y', len(valid_y))\n#print('\\n True label_train  : ',y_train[10] , '\\ntrain_y : ',train_y[10],'\\ntrain_label_len : ',train_label_len[10], '\\ntrain_input_len : ', train_input_len[10])","d431adcf":"def build_digit_model(alphabets, max_str_len, img_width = 128,img_height = 32):\n    # Inputs to the model\n\n    input_img = layers.Input(\n        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n    )\n    \n    # First conv block\n    x = layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv1\",\n    )(input_img)\n    x = layers.MaxPooling2D((2, 2),strides = 2, name=\"pool1\")(x)\n\n    # Second conv block\n    x = layers.Conv2D(\n        128,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv2\",\n    )(x)\n    x = layers.MaxPooling2D((2, 2), strides = 2, name=\"pool2\")(x)\n\n    # Third conv block\n    x = layers.Conv2D(\n        256,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv3\",\n    )(x)\n    \n    #x = layers.Dropout(0.5)(x)\n\n    # Fourth conv block\n    x = layers.Conv2D(\n        256,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv4\",\n    )(x)\n\n    x = layers.MaxPooling2D((1, 2), name=\"pool4\")(x)\n\n    # Fifth conv block\n    x = layers.Conv2D(\n        512,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv5\",\n    )(x)\n\n    x = layers.BatchNormalization(name=\"BatchNormalization_1\")(x)\n    \n\n    # Sixth conv block\n    x = layers.Conv2D(\n        512,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv6\",\n    )(x)\n\n    x = layers.BatchNormalization(name=\"BatchNormalization_2\")(x)\n\n    x = layers.MaxPooling2D((1, 2), name=\"pool6\")(x)\n\n    # Seventh conv block\n    x = layers.Conv2D(\n        512,\n        (2, 2),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"valid\",\n        name=\"Conv7\",\n    )(x)\n\n\n    # The number of filters in the last layer is 512. Reshape accordingly before\n    # passing the output to the RNN part of the model\n\n    new_shape = (31,512) #Kh\u00f4ng c\u1ea7n downsampling #N\u00ean coi shape l\u1edbp tr\u01b0\u1edbc\n\n    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n\n    def attention_rnn(inputs):\n         #inputs.shape = (batch_size, time_steps, input_dim)\n        input_dim = int(inputs.shape[2])\n        timestep = int(inputs.shape[1])\n        a = layers.Permute((2, 1))(inputs)\n        a = layers.Dense(timestep, activation='softmax')(a) #\/\/ Alignment Model + Softmax\n        a = layers.Lambda(lambda x: keras.backend.mean(x, axis=1), name='dim_reduction')(a)\n        a = layers.RepeatVector(input_dim)(a)\n        a_probs = layers.Permute((2, 1), name='attention_vec')(a)\n        output_attention_mul = layers.multiply([inputs, a_probs], name='attention_mul') #\/\/ Weighted Average \n        return output_attention_mul\n\n    x = attention_rnn(x)\n    \n    # RNNs\n    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n\n    # Output layer\n    y_pred = layers.Dense(len(alphabets) + 1 , activation=\"softmax\", name=\"last_dense\")(x) # y pred\n    digit_model = keras.models.Model(inputs=input_img, outputs=y_pred, name=\"functional_1\")\n\n    def ctc_lambda_func(args):\n        y_pred, labels, input_length, label_length = args\n        # the 2 is critical here since the first couple outputs of the RNN\n        # tend to be garbage\n        y_pred = y_pred[:, 2:, :]\n        return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n    labels = layers.Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n\n    ctc_loss = keras.layers.Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n    digit_model_CTC = keras.models.Model(inputs=[input_img, labels, input_length, label_length], outputs=ctc_loss, name = \"ocr_model_v1\")\n    \n    return digit_model, digit_model_CTC\n\ndigit_model, digit_model_CTC = build_digit_model(alphabets = alphabets, max_str_len = max_str_len)\ndigit_model_CTC.summary()","de612217":"epochs = 100\nbatch_size = 128\nearly_stopping_patience = 17\n\ndef scheduler(epoch):\n    if epoch <= 15:\n        return 1e-3  \n    elif 15 < epoch <= 20:\n        return 1e-4\n    else:\n        return 1e-5\n\n# Add early stopping\nmy_callbacks = [\n    tf.keras.callbacks.LearningRateScheduler(scheduler),\n    tf.keras.callbacks.ModelCheckpoint(filepath='.\/model_digit\/digit_model_{epoch:02d}_'+str(datetime_object)+'.h5', \n                                    save_freq='epoch',\n                                    monitor='val_loss',\n                                    mode='min',\n                                    save_best_only=True,\n                                    period = 5),\n    tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n    )\n]\n\ndigit_model_CTC.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, \n                    optimizer=keras.optimizers.Adam(),                  \n                    )\n\nhistory = digit_model_CTC.fit(x=[X_train, train_y, train_input_len, train_label_len], y=train_output, \n                validation_data=([X_valid, valid_y, valid_input_len, valid_label_len], valid_output),\n                epochs = epochs, \n                batch_size = batch_size,\n                callbacks = my_callbacks,\n                )\n\n\n# list all data in history\nprint(history.history.keys())\n\n# summarize history for loss\n\nfig, ax = plt.subplots()\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.savefig('.\/model_digit\/digit_model_{}_loss.png'.format(datetime_object))\nplt.show()\n\n\nwith open('.\/model_digit\/digit_model_{}.txt'.format(datetime_object), 'w', encoding='utf-8') as f:\n    f.write('len(X_train): {} \\nlen (X_valid): {} \\n'.format(len(X_train), len (X_valid)))\n    f.write('max_str_len: {} \\nnum_of_characters: {} \\nnum_of_timestamps: {} \\n'.format(max_str_len,num_of_characters,num_of_timestamps))\n    f.write('batch_size: {} \\nepochs: {} \\n'.format(batch_size,epochs) )","4598d987":"digit_model.save('.\/model_digit\/digit_model_last_{}.h5'.format(datetime_object))","57d19898":"def avg_wer(wer_scores, combined_ref_len):\n    return float(sum(wer_scores)) \/ float(combined_ref_len)\n\n\ndef _levenshtein_distance(ref, hyp):\n\n    m = len(ref)\n    n = len(hyp)\n\n    # special case\n    if ref == hyp:\n        return 0\n    if m == 0:\n        return n\n    if n == 0:\n        return m\n\n    if m < n:\n        ref, hyp = hyp, ref\n        m, n = n, m\n\n    # use O(min(m, n)) space\n    distance = np.zeros((2, n + 1), dtype=np.int32)\n\n    # initialize distance matrix\n    for j in range(0,n + 1):\n        distance[0][j] = j\n\n    # calculate levenshtein distance\n    for i in range(1, m + 1):\n        prev_row_idx = (i - 1) % 2\n        cur_row_idx = i % 2\n        distance[cur_row_idx][0] = i\n        for j in range(1, n + 1):\n            if ref[i - 1] == hyp[j - 1]:\n                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n            else:\n                s_num = distance[prev_row_idx][j - 1] + 1\n                i_num = distance[cur_row_idx][j - 1] + 1\n                d_num = distance[prev_row_idx][j] + 1\n                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n\n    return distance[m % 2][n]\n\n\ndef word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    ref_words = reference.split(delimiter)\n    hyp_words = hypothesis.split(delimiter)\n\n    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n    return float(edit_distance), len(ref_words)\n\n\ndef char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    join_char = ' '\n    if remove_space == True:\n        join_char = ''\n\n    reference = join_char.join(filter(None, reference.split(' ')))\n    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n\n    edit_distance = _levenshtein_distance(reference, hypothesis)\n    return float(edit_distance), len(reference)\n\n\ndef wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n  \n    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n                                         delimiter)\n\n    if ref_len == 0:\n        raise ValueError(\"Reference's word number should be greater than 0.\")\n\n    wer = float(edit_distance) \/ ref_len\n    return wer\n\n\ndef cer(reference, hypothesis, ignore_case=False, remove_space=False):\n \n    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n                                         remove_space)\n\n    if ref_len == 0:\n        raise ValueError(\"Length of reference should be greater than 0.\")\n\n    cer = float(edit_distance) \/ ref_len\n    return cer","168a6e9f":"preds = digit_model.predict(X_valid)\n#print('\\n preds',preds)\ndecoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n                                   greedy=False,beam_width=5,top_paths=1)[0][0])\n# If you want to you greedy, just set greedy = True\n                                                                \n#print ('\\n decoded',decoded)\nprediction = []\nfor i in range(len(X_valid)):\n    prediction.append(num_to_label(decoded[i]))\n    \n#print ('\\n predict',num_to_label(decoded[0]))\n\ny_true = y_valid\ncorrect_char = 0\ntotal_char = 0\ncorrect = 0\ntest_cer, test_wer = [], []\n\nfor i in range(len(X_valid)):\n    pr = prediction[i]\n    tr = y_true[i]\n    total_char += len(tr)\n    \n    for j in range(min(len(tr), len(pr))):\n        if tr[j] == pr[j]:\n            correct_char += 1\n            \n    if pr == tr :\n        correct += 1 \n    \n    test_cer.append(cer(tr, pr))\n    test_wer.append(wer(tr, pr))\n                  \navg_cer = sum(test_cer)\/len(test_cer)   \navg_wer = sum(test_wer)\/len(test_wer)\n\nprint ('Average CER: %.2f%%' %(avg_cer*100))\nprint ('Average WER: %.2f%%' %(avg_wer*100))\nprint('Correct characters predicted : %.2f%%' %(correct_char*100\/total_char))\nprint('Correct words predicted      : %.2f%%' %(correct*100\/len(X_valid)))","a5ecd263":"with open('.\/model_digit\/digit_model_{}.txt'.format(datetime_object), 'a', encoding='utf-8') as f:\n    f.write('\\nAverage CER: %.2f%%' %(avg_cer*100))\n    f.write('\\nAverage WER: %.2f%%' %(avg_wer*100))\n    f.write('\\nCorrect characters predicted : %.2f%%' %(correct_char*100\/total_char))\n    f.write('\\nCorrect words predicted      : %.2f%%' %(correct*100\/len(X_valid)))","83725724":"for index in range (20):\n    i = random.randint(0, len(X_valid))\n    print ('true label',y_valid[i])\n    print ('predicted',prediction[i],'\\n')","75443abd":"preds = digit_model.predict(X_valid)\n#print('\\n preds',preds)\ndecoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n                                   greedy=True,)[0][0])\n# If you want to you greedy, just set greedy = True\n                                                                \n#print ('\\n decoded',decoded)\nprediction = []\nfor i in range(len(X_valid)):\n    prediction.append(num_to_label(decoded[i]))\n    \n#print ('\\n predict',num_to_label(decoded[0]))\n\ny_true = y_valid\ncorrect_char = 0\ntotal_char = 0\ncorrect = 0\ntest_cer, test_wer = [], []\n\nfor i in range(len(X_valid)):\n    pr = prediction[i]\n    tr = y_true[i]\n    total_char += len(tr)\n    \n    for j in range(min(len(tr), len(pr))):\n        if tr[j] == pr[j]:\n            correct_char += 1\n            \n    if pr == tr :\n        correct += 1 \n    \n    test_cer.append(cer(tr, pr))\n    test_wer.append(wer(tr, pr))\n                  \navg_cer = sum(test_cer)\/len(test_cer)   \navg_wer = sum(test_wer)\/len(test_wer)\n\nprint ('Average CER: %.2f%%' %(avg_cer*100))\nprint ('Average WER: %.2f%%' %(avg_wer*100))\nprint('Correct characters predicted : %.2f%%' %(correct_char*100\/total_char))\nprint('Correct words predicted      : %.2f%%' %(correct*100\/len(X_valid)))\n\nfor index in range (20):\n    i = random.randint(0, len(X_valid))\n    print ('true label',y_valid[i])\n    print ('predicted',prediction[i],'\\n')","8262b53d":"You can find the code I used to generate pictures of multi digit from MNIST dataset [here](https:\/\/www.kaggle.com\/bomaich\/multi-digit-images-generate-mnist) \nI also made a notebook to train model with `png` input [here](https:\/\/www.kaggle.com\/bomaich\/simple-multi-digit-recognition-mnist)\n\nBut that notebook is not fit with what I am doing right now, so I will create this notebook with some new features\n1. The input is in `.csv` file\n2. New model (stronger)\n3. New way to evaluate the model (CER, WER)\n4. It's easier to apply into your project\n5. Using beam search instead of greedy\n**After all, it's better**","5f6d387c":"Visualize some train data","a669b680":"# EVALUATE ON VALID SET","2a5f3ba6":"# BUILD CRNN + CTC LOSS MODEL + ATTENTION\n\n* y_true: tensor (samples, max_string_length) containing the truth labels.\n* y_pred: tensor (samples, time_steps, num_categories) containing the prediction, or output of the softmax.\n* input_length: tensor (samples, 1) containing the sequence length of slices coming out from RNN for each batch item in y_pred.\n* label_length: tensor (samples, 1) containing the sequence length of label for each batch item in y_true.\n\n**We need 2 model. The final model with CTC loss is for trainning and the model is for testing anf inferencing**","f854706b":"# LOAD DATASET\nIn short, this dataset in `.csv` file includes over 100000 multi_digit images (1,3,4,5,7 digits per image).\nRecently, I have changed my data stucture with 80% data generated from MNIST and 20% real life data (20000 images from 225 real life images with augmentation)\n\nThere are 2 columns: image (array) and label \n\nMy images had been preprocessing as my previous notebook [here](https:\/\/www.kaggle.com\/bomaich\/multi-digit-images-generate-mnist):\n1. Data augmentation (add noise)\n2. Resize, transpose and normalize image\n\n\nI also used a lot of Data Augmentation methods for my project like:\n1. Add blob & line noise \n2. Random cutout (horizontal and vertical)\n3. Elastics Transformation (10% of data)\n4. Rotate digit (random -10,10 degree)\n5. Scale and Rotate on the whole image","a6d748b8":"You may see some silly lines of code like whay is t = []. That's for the memory","a0c106b9":"## Create metrics for evaluating \n1. CER\n2. WER\n3. Levenshtein distance\n4. Correct characters rate\n5. Correct words rate","b3e6b609":"## Visualize on valid set ","6067c42e":"# PREPARE FOR CTC LOSS\nI have done a notebook [here](datetime_object)\n\n* train_y contains the true labels converted to numbers and padded with -1. \n* The length of each label is equal to max_str_len.\n* train_label_len contains the length of each true label (without padding)\n* train_input_len contains the length of each predicted label. \n* The length of all the predicted labels is constant i.e number of timestamps - 2.\n* train_output is a dummy output for ctc loss.","98c98644":"# TRAINING","ca8909f5":"# SPLIT DATA INTO TRAIN_VALID SET\nSplit data using SKlearn. \n\nI got some issue with RAM. I guess that bc my variable's memory is huge so I have to delete some variables and it works. But I have to find out another way to combat with this ","1c587a05":"<a href=\".\/model_word\/word_model_15_2021-10-01.h5\"> Download File <\/a>","46c652de":"Here I will compare the performance of greedy and beam search\nUnlike my prediction. Greedy is compelling but in my real project Beam search is better"}}