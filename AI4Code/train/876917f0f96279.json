{"cell_type":{"0f4d8959":"code","842281f3":"code","eae01e79":"code","b5242809":"code","5ce183f5":"code","a8084629":"code","188c0b5e":"code","7e95655b":"code","9b078019":"code","9b870d02":"code","85acb709":"code","0a668dfa":"code","46e9c5cb":"code","1838cf41":"code","58a13a82":"code","321abfdd":"code","247dbffa":"code","24062b68":"code","d38cbe01":"code","f38fcac9":"code","a01cf6bc":"code","bb4f2233":"code","a60c3143":"code","1b59c2c6":"code","2e1c65ad":"code","67af24e2":"code","2f55db01":"code","0ca1ac81":"code","f3089d98":"code","88f1e1e9":"code","5d1f476b":"code","58254ee9":"code","3965e12b":"code","8d028cc5":"code","06d7dee8":"code","ac788f83":"code","adbb59f7":"code","01269b0e":"code","2fc93f99":"code","5e5eb6f7":"code","722466f5":"markdown","9a4554aa":"markdown","63d29f50":"markdown","1150c7d2":"markdown","a3dae340":"markdown","0bd374cd":"markdown","456a5119":"markdown","93c38a44":"markdown","21209b62":"markdown","510a9eca":"markdown","db101714":"markdown","aea95b06":"markdown"},"source":{"0f4d8959":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","842281f3":"data = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\")\nprint (data.shape)\ndata.head(5)","eae01e79":"data.info()","b5242809":"movies = data[data['type']=='Movie'].reset_index()\nmovies = movies.drop(columns = ['duration','country','date_added','release_year','show_id','type','index','listed_in'])","5ce183f5":"movies['director'] = movies['director'].fillna(\"\")\nmovies['cast'] = movies['cast'].fillna(\"\")\nmovies['combined'] = movies['description']+movies['cast']+movies['director']\nmovies.head(5)","a8084629":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfv = TfidfVectorizer(min_df = 3,max_features = None,analyzer = 'word',token_pattern = 'r\\w{1,}', ngram_range = (1,3), stop_words = 'english')","188c0b5e":"movies['combined'] = movies['combined'].fillna(\"\")","7e95655b":"tfv_matrix = tfv.fit_transform(movies['combined'])\nfrom sklearn.metrics.pairwise import sigmoid_kernel\nsig = sigmoid_kernel(tfv_matrix,tfv_matrix)\nsig[0]\nindices = pd.Series(movies.index,index = movies['title']).drop_duplicates()\nindices","9b078019":"def recommend(title,sig=sig):\n    idx = indices[title]\n    sig_scores = list(enumerate(sig[idx]))\n    sig_scores = sorted(sig_scores,key = lambda x:x[1], reverse = True)\n    sig_scores = sig_scores[1:11]\n    movies_indices = [i[0] for i in sig_scores]\n    return movies['title'].iloc[movies_indices]","9b870d02":"recommend('Zulu Man in Japan')","85acb709":"recommend('Zubaan')","0a668dfa":"recommend('The Cakemaker')","46e9c5cb":"shows = data[data['type']=='TV Show'].reset_index()\nshows = shows.drop(columns = ['duration','country','date_added','release_year','show_id','type','index','listed_in'])","1838cf41":"shows['director'] = shows['director'].fillna(\"\")\nshows['cast'] = shows['cast'].fillna(\"\")\nshows['combined'] = shows['cast']+shows['director']+shows['description']","58a13a82":"shows.head()","321abfdd":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfv = TfidfVectorizer(min_df = 3,max_features = None,analyzer = 'word',token_pattern = 'r\\w{1,}', ngram_range = (1,3), stop_words = 'english')\nshows['combined'] = shows['combined'].fillna(\"\")","247dbffa":"tfv_matrix_shows = tfv.fit_transform(shows['combined'])\nfrom sklearn.metrics.pairwise import sigmoid_kernel\nsig = sigmoid_kernel(tfv_matrix_shows,tfv_matrix_shows)\nsig[0]\nindices = pd.Series(shows.index,index = shows['title']).drop_duplicates()\nindices","24062b68":"def recommend(title,sig=sig):\n    idx = indices[title]\n    sig_scores = list(enumerate(sig[idx]))\n    sig_scores = sorted(sig_scores,key = lambda x:x[1], reverse = True)\n    sig_scores = sig_scores[1:11]\n    shows_indices = [i[0] for i in sig_scores]\n    return shows['title'].iloc[shows_indices]","d38cbe01":"recommend(\"Friends\")","f38fcac9":"recommend(\"Crash Landing on You\")","a01cf6bc":"movies.head(5)","bb4f2233":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(stop_words='english')\n\n\nmovies['combined'] = movies['combined'].fillna('')\ntfidf_matrix = tfidf.fit_transform(movies['combined'])\n\n\ntfidf_matrix.shape","a60c3143":"tfidf.get_feature_names()[5000:5010]","1b59c2c6":"from sklearn.metrics.pairwise import linear_kernel\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_sim.shape","2e1c65ad":"cosine_sim[1]","67af24e2":"indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()\nindices","2f55db01":"def recommendations(title, cosine_sim=cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    movie_indices = [i[0] for i in sim_scores]\n    return movies['title'].iloc[movie_indices]\n","0ca1ac81":"recommendations('Zulu Man in Japan')","f3089d98":"recommendations(\"Zubaan\")","88f1e1e9":"recommendations(\"Sanju\")","5d1f476b":"shows.head(5)","58254ee9":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(stop_words='english')\n\n\nshows['combined'] = shows['combined'].fillna('')\ntfidf_matrix = tfidf.fit_transform(shows['combined'])\n\n\ntfidf_matrix.shape","3965e12b":"tfidf.get_feature_names()[5000:5010]","8d028cc5":"from sklearn.metrics.pairwise import linear_kernel\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_sim.shape","06d7dee8":"cosine_sim[1]","ac788f83":"indices = pd.Series(shows.index, index=shows['title']).drop_duplicates()\nindices","adbb59f7":"def recommendations(title, cosine_sim=cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    shows_indices = [i[0] for i in sim_scores]\n    return shows['title'].iloc[shows_indices]","01269b0e":"recommendations(\"Friends\")","2fc93f99":"recommendations(\"Crash Landing on You\")","5e5eb6f7":"recommendations(\"It's Okay to Not Be Okay\")","722466f5":"# TV Shows set","9a4554aa":"# TV Shows set","63d29f50":"**My experience can vote for this recommendation model better than the first one**","1150c7d2":"# Content Based Recommendation System\n","a3dae340":"# Movie set* ****","0bd374cd":"**My Kdrama addicted brain is absolutely in favour of these recommendations more than the first one**","456a5119":"So, I am going to use TF-IDF  technique to make two different recommendation models with sigmoid kernel fucntion and one with linear cosine similarity and let's see which one is better.\n****","93c38a44":"**Personally , I don't feel that these recommendations are good enough to consider. So, I am doing the same method but this time using Cosine similarities with linear kernel**","21209b62":"# Movies set* ","510a9eca":"**1. Content based recommendation system using sigmoid kernel to find the similarities**","db101714":"****I am dividing 2 different sets one for movie recommendations and one for TV\/Shows. Also I am using a combined function to compute the similarity****","aea95b06":"**# So, overall I would say that the 2nd one is better. I would also try to make this better in future.** Thank you for viewing this notebook\ud83d\ude0a\ud83d\ude0a"}}