{"cell_type":{"fdb680d4":"code","419c0593":"code","b9b68054":"code","af1c3b4a":"code","55123a87":"code","5722e6dc":"code","33a95df9":"code","553866a1":"code","d7becb7c":"code","5851fd23":"code","0d03cb6b":"code","01bbf2ee":"code","e62c6d7a":"code","0b0219e6":"code","59dded0f":"code","29a13d1e":"markdown","a0cfae16":"markdown","e73799c4":"markdown","b182ba27":"markdown","c12df6f8":"markdown","bcbd44c6":"markdown"},"source":{"fdb680d4":"!pip install mosestokenizer","419c0593":"import re\nimport sys\nimport mosestokenizer\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom pprint import pprint\nfrom mosestokenizer import MosesTokenizer, MosesDetokenizer","b9b68054":"print('Python version:', sys.version)\nprint('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Moses Tokenizer version:', mosestokenizer.__version__)\n\ntqdm.pandas()","af1c3b4a":"df_train = pd.read_csv('\/kaggle\/input\/scl-2021-ds\/train.csv')\ndf_train","55123a87":"df_test = pd.read_csv('\/kaggle\/input\/scl-2021-ds\/test.csv')\nX_test = df_test['raw_address'].tolist()\nX_test[:10]","5722e6dc":"sr_label = df_train['POI\/street'].str.split('\/', expand=True)\ndf_train['POI'] = sr_label[0]\ndf_train['street'] = sr_label[1]\ndel df_train['POI\/street']\ndel df_train['id']\ndf_train","33a95df9":"tokenizer = MosesTokenizer('id')\ndetokenizer = MosesDetokenizer('id')\n\nabbreviations = []\npoi_pairs = []\nstreet_pairs = []\n\ndef get_abbr(partial: str, full: str):\n    abbr = []\n    # 1. Skip empty\n    if partial == '':\n        return abbr\n    # 2. Skip exactly same\n    if partial == full:\n        return abbr\n\n    # 2.5.1. Get token\n    partial_tokens = tokenizer(partial)\n    full_tokens = tokenizer(full)\n    # 2.5.2 Remove \",\" and \".\" from each token\n    for i in range(len(full_tokens)):\n        full_tokens[i] = re.sub(r'[,\\.]', '', full_tokens[i])\n    for i in range(len(partial_tokens)):\n        partial_tokens[i] = re.sub(r'[,\\.]', '', partial_tokens[i])\n\n    # 3. Handle 1 partial token\n    if len(partial_tokens) == 1:\n        # check exactly same\n        if partial_tokens[0] not in full_tokens:\n            # check starts with\n            for full_token in full_tokens:\n                # naive assumption\n                if partial_tokens[0].startswith(full_token):\n                    abbr.append([full_token, partial_tokens[0]])\n        return abbr\n\n    # 4. Handle multiple partial tokens\n\n    # 4.1. Skip if all partial tokens is in full tokens\n    total_partial_in_full = 0\n    for partial_token in partial_tokens:\n        # assuming each token is unique\n        if partial_token in full_tokens:\n            total_partial_in_full += 1\n    if total_partial_in_full == len(full_tokens):\n        return abbr\n\n    # 4.2 Get partial position in full\n    partial_position_in_full = []\n    for partial_token in partial_tokens:\n        try:\n            # means token is same\n            position = full_tokens.index(partial_token)\n            partial_position_in_full.append(position)\n        except ValueError:\n            for i, full_token in enumerate(full_tokens):\n                # naive assumption\n                if partial_token.startswith(full_token):\n                    position = i\n                    partial_position_in_full.append(position)\n                    break\n        except Exception as ex:\n            print(partial, full)\n            print(ex)\n            print('-'*50)\n    # If all position found, then we find abbr pair \n    if len(partial_position_in_full) == len(partial_tokens):\n        for idx, partial_token in zip(partial_position_in_full, partial_tokens):\n            if full_tokens[idx] != partial_token:\n                abbr.append([full_tokens[idx], partial_token])\n\n    return abbr\n\ndef process_row(row):\n    # 1. Get column\n    raw_address = row['raw_address']\n    poi = row['POI']\n    street = row['street']\n\n    # 2. Get abbreviation\n    abbr = get_abbr(poi, raw_address) + get_abbr(street, raw_address)\n\n    # 3. Remove dirty abbreviation\n    cleaned_abbr = {}\n    for short, full in abbr:\n        # 3.1. Ensure use str\n        short, full = str(short), str(full)\n        # 3.2. skip short character\n        if len(short) < 2:\n            continue\n        # 3.3. skip abbr containing number & \".\"\n        re_result = re.search(r'[(\\d\\.)+]', full)\n        if re_result is not None:\n            continue\n        # 3.4. remove \"-\" and \",\" if appear on last char\n        if full[-1] == '-' or full[-1] == ',':\n            full = full[:-1]\n        # 3.5. Remove multiple \"'\"\n        full = re.sub(r\"'{2,}\", '', full)\n        # 3.5. Remove '\"'\n        short = re.sub(r'\"', '', short)\n        full = re.sub(r'\"', '', full)\n\n        cleaned_abbr[full] = short\n\n    # 4. Shorten POI & street with abbrevation\n    poi_tokens = tokenizer(poi)\n    for i in range(len(poi_tokens)):\n        if poi_tokens[i] in cleaned_abbr:\n            poi_tokens[i] = cleaned_abbr[poi_tokens[i]]\n    row['POI'] = poi_tokens\n\n    street_tokens = tokenizer(street)\n    for i in range(len(street_tokens)):\n        if street_tokens[i] in cleaned_abbr:\n            street_tokens[i] = cleaned_abbr[street_tokens[i]]\n    row['street'] = street_tokens\n\n    # 5. Convert dict to list\n    for full, short in cleaned_abbr.items():\n        abbreviations.append([short, full])\n\n    # 6. Get sentence pair\n    if poi != '':\n        poi_pairs.append([detokenizer(row['POI']), poi])\n    if street != '':\n        street_pairs.append([detokenizer(row['street']), street])\n\n    # 6. Return transformed row\n    return row","553866a1":"df_train = df_train.progress_apply(process_row, axis=1)\npprint(abbreviations[:10])","d7becb7c":"from collections import Counter\nabbreviations = [f'{short}${full}' for short, full in abbreviations]\n\nabbr_occurance = dict(Counter(abbreviations))\nabbreviations = sorted(abbr_occurance.items(), key=lambda x:x[1], reverse=True)\n\nabbreviations = [\n    [*pair.split('$'), occurance] for pair, occurance in abbreviations\n]\n\nprint('Total abbreviation:', len(abbreviations))\npprint(abbreviations[:10])","5851fd23":"# https:\/\/stackoverflow.com\/a\/3847585\/1191103\ndef contains(small, big):\n    for i in range(len(big)-len(small)+1):\n        for j in range(len(small)):\n            if big[i+j] != small[j]:\n                break\n        else:\n            return i, i+len(small)\n    return False\n\n# NER tag\n# 1. POI\n# 2. street\n# 3. misc\ntotal_tag_success = 0\ntotal_tag_fail = 0\n\ndef ner_tagging(row):\n    global total_tag_success\n    global total_tag_fail\n    raw_address = row['raw_address']\n    poi = row['POI']\n    street = row['street']\n\n    poi_position = contains(poi, raw_address)\n    street_position = contains(street, raw_address)\n\n    ner_tag = ['misc' for _ in range(len(raw_address))]\n    if poi_position is not False and poi_position != (0, 0):\n        total_tag_success += 1\n        for i in range(*poi_position):\n            ner_tag[i] = 'POI'\n    elif len(poi) > 0:\n        total_tag_fail += 1\n\n    if street_position is not False and street_position != (0, 0):\n        total_tag_success += 1\n        for i in range(*street_position):\n            ner_tag[i] = 'street'\n    elif len(street) > 0:\n        total_tag_fail += 1\n\n    return ner_tag","0d03cb6b":"df_train['raw_address'] = df_train['raw_address'].progress_apply(tokenizer)\n\ndf_train['ner_tag'] = df_train.progress_apply(ner_tagging, axis=1)\nprint('Total tag success:', total_tag_success)\nprint('Total tag fail:', total_tag_fail)","01bbf2ee":"df_train.to_pickle('train.pickle')\ndf_train","e62c6d7a":"df_abbreviations = pd.DataFrame(abbreviations, columns=['short', 'full', 'occurance'])\ndf_abbreviations.to_csv('abbreviations.csv', index=False)\ndf_abbreviations","0b0219e6":"df_poi_pairs = pd.DataFrame({\n    'short': [p[0] for p in poi_pairs],\n    'full': [p[1] for p in poi_pairs],\n})\ndf_poi_pairs.to_csv('poi_pairs.csv', index=False)\ndf_poi_pairs","59dded0f":"df_street_pairs = pd.DataFrame({\n    'short': [s[0] for s in street_pairs],\n    'full': [s[1] for s in street_pairs],\n})\ndf_street_pairs.to_csv('street_pairs.csv', index=False)\ndf_street_pairs","29a13d1e":"# 1. Library","a0cfae16":"# 3B. Get abbreviations occurance  ","e73799c4":"# 3A. Get abbreviation","b182ba27":"# 2. Dataset","c12df6f8":"# 5. Save data","bcbd44c6":"# 4. Get NER tag"}}