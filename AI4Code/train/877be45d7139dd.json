{"cell_type":{"4ac2b36b":"code","a620f2bd":"code","d262a91b":"code","307b9613":"code","120d6c93":"code","b09abeeb":"code","594f1983":"code","2f5df664":"code","2d1359aa":"code","cab3559e":"code","13223d0f":"code","ffc29d4f":"markdown","d65fb6bf":"markdown","ee06fea2":"markdown","97a331f1":"markdown","232d3337":"markdown","803253ab":"markdown","4a2abe40":"markdown","198de09a":"markdown","7547d25e":"markdown","ad3741a2":"markdown"},"source":{"4ac2b36b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nnp.random.seed = 45\nimport sklearn\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n!pip install iterative-stratification\ntrain_features = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_features.csv\")\ntrain_targets_scored = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_targets_scored.csv\")","a620f2bd":"COLS = ['cp_type','cp_dose']\nFE = []\nfor col in COLS:\n    for mod in train_features[col].unique():\n        FE.append(mod)\n        train_features[mod] = (train_features[col] == mod).astype(int)\ndel train_features['sig_id']\ndel train_features['cp_type']\ndel train_features['cp_dose']\nFE+=list(train_features.columns) \ndel train_targets_scored['sig_id']","d262a91b":"X = np.array(train_features.to_numpy(), dtype=np.float)\ny = np.array(train_targets_scored.to_numpy(), dtype=np.float)","307b9613":"from skmultilearn.model_selection import iterative_train_test_split\nX_train, y_train, X_val, y_val = iterative_train_test_split(X, y, test_size = 0.1)\nX_train.shape,y_train.shape,X_val.shape,y_val.shape","120d6c93":"print(X_val.shape,y_val.shape)\nprint(X_val[:2])\ny_val[:1]","b09abeeb":"k=4","594f1983":"for i in range(k):\n    np.random.shuffle(X_train)\n    np.random.shuffle(y_train)\n    X_, y_, X_test, y_test = iterative_train_test_split(X_train,y_train, test_size = 0.2)\n    print(X_.shape,y_.shape,X_test.shape,y_test.shape)\n    print(\"model.fit(X_,y_)\")\n    print(\"model log loss evaluation for {} fold is {}\".format(i+1,np.random.rand(1)))","2f5df664":"print(\"hold out data of shape x: {} y: {} model log loss evaluation is {}\".format(X_val.shape,y_val.shape,np.random.rand(1)))","2d1359aa":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nimport numpy as np\n\n\nmskf = MultilabelStratifiedKFold(n_splits=2, shuffle=True)\n\nfor train_index, test_index in mskf.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)","cab3559e":"from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n\nrmskf = RepeatedMultilabelStratifiedKFold(n_splits=2,n_repeats=2, random_state=0)\n\nfor train_index, test_index in rmskf.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)","13223d0f":"from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n\nmsss  = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5, random_state=0)\n\nfor train_index, test_index in msss.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)","ffc29d4f":"# Data to numpy arrays","d65fb6bf":"<h2 style=\"background-color:DodgerBlue; color:white\" >Diffrent Validation Schema for multilabel<\/h2>\n<h1>Bonus <span class=\"label label-default\">hold out set for validation<\/span><\/h1>\n<h1>1 : <span class=\"label label-default\">Custom created k fold cross validation <\/span><\/h1>\n<h1>2 : <span class=\"label label-default\">MultilabelStratifiedKFold<\/span><\/h1>\n<h1>3 : <span class=\"label label-default\">RepeatedMultilabelStratifiedKFold<\/span><\/h1>\n<h1>4 : <span class=\"label label-default\">MultilabelStratifiedShuffleSplit<\/span><\/h1>","ee06fea2":"# k fold cross validation \n","97a331f1":"# freature engineering ","232d3337":"# RepeatedMultilabelStratifiedKFold\n\nRepeats Mulilabel Stratified K-Fold n times with different randomization\n    in each repetition.","803253ab":"# model hold out validation","4a2abe40":"# load modules and data","198de09a":"# MultilabelStratifiedKFold\n\nMultilabel stratified K-Folds cross-validator\n    Provides train\/test indices to split multilabel data into train\/test sets.\n    This cross-validation object is a variation of KFold that returns\n    stratified folds for multilabel data. The folds are made by preserving\n    the percentage of samples for each label.","7547d25e":"# hold out set for validation ","ad3741a2":"# MultilabelStratifiedShuffleSplit\n\nMultilabel Stratified ShuffleSplit cross-validator\n    Provides train\/test indices to split data into train\/test sets.\n    This cross-validation object is a merge of MultilabelStratifiedKFold and\n    ShuffleSplit, which returns stratified randomized folds for multilabel\n    data. The folds are made by preserving the percentage of each label.\n    Note: like the ShuffleSplit strategy, multilabel stratified random splits\n    do not guarantee that all folds will be different, although this is\n    still very likely for sizeable datasets."}}