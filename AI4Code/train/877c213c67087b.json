{"cell_type":{"5c67846a":"code","54145f00":"code","726b67a6":"code","6874ce9c":"code","991da8ac":"code","d82cf225":"code","52f707d9":"code","c284306c":"code","d6629f98":"code","4ddad96f":"code","c6bc5a7a":"code","463bf3c7":"code","df3b675b":"code","0de6f052":"code","cd39e14d":"code","bcd0e7e2":"code","8147b2fb":"code","93b24329":"code","274c530c":"code","f404f918":"code","b81356db":"code","d7d72dce":"code","d6e6995d":"markdown","4ec0b753":"markdown","56dcce72":"markdown","38aef6af":"markdown","97450c74":"markdown","95302467":"markdown","e9c706c1":"markdown","c2d24bb3":"markdown","7753868e":"markdown","80955f88":"markdown","7559ccc7":"markdown"},"source":{"5c67846a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n# Any results you write to the current directory are saved as output.","54145f00":"from __future__ import print_function\n\nimport time\nfrom PIL import Image\nimport numpy as np\n\nfrom keras import backend\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\n\nfrom scipy.optimize import fmin_l_bfgs_b\nfrom scipy.misc import imsave","726b67a6":"height = 512\nwidth = 512\n\ncontent_image_path = \"..\/input\/Monogatari.png\"\ncontent_image = Image.open(content_image_path)\ncontent_image = content_image.resize((width, height))\n#Don't mind this final line of code, I simply added it to be able to make a comparison in the end  of the kernel\nfinal_test = Image.open(content_image_path).resize((width,height))\n\ncontent_image","6874ce9c":"style_image_path = \"..\/input\/Wave.jpg\"\nstyle_image = Image.open(style_image_path)\nstyle_image = style_image.resize((width, height))\nstyle_image","991da8ac":"content_array = np.asarray(content_image, dtype='float32')\ncontent_array = np.expand_dims(content_array, axis=0)\nprint(content_array.shape)\n\nstyle_array = np.asarray(style_image, dtype='float32')\nstyle_array = np.expand_dims(style_array, axis=0)\nprint(style_array.shape)","d82cf225":"Nothing too shabby up till now, we just prepared our images.\nNow we'll be subtracting the mean RGB values from the images to normalize them a bit, and turn them into BGR values which was used in the original paper the author cites.","52f707d9":"content_array[:, :, :, 0] -= 103.939\ncontent_array[:, :, :, 1] -= 116.779\ncontent_array[:, :, :, 2] -= 123.68\n#Turning RGB to BGR\ncontent_array = content_array[:, :, :, ::-1]\n\nstyle_array[:, :, :, 0] -= 103.939\nstyle_array[:, :, :, 1] -= 116.779\nstyle_array[:, :, :, 2] -= 123.68\n#Turning RGB to BGR\nstyle_array = style_array[:, :, :, ::-1]","c284306c":"content_image = backend.variable(content_array)\nstyle_image = backend.variable(style_array)\ncombination_image = backend.placeholder((1, height, width, 3))","d6629f98":"input_tensor = backend.concatenate([content_image,\n                                    style_image,\n                                    combination_image], axis=0)","4ddad96f":"model = VGG16(input_tensor=input_tensor, weights='imagenet',\n              include_top=False)","c6bc5a7a":"layers = dict([(layer.name, layer.output) for layer in model.layers])\nlayers","463bf3c7":"content_weight = 0.025\nstyle_weight = 5.0\ntotal_variation_weight = 1.0","df3b675b":"loss = backend.variable(0.)","0de6f052":"def content_loss(content, combination):\n    return backend.sum(backend.square(combination - content))\n\nlayer_features = layers['block2_conv2']\ncontent_image_features = layer_features[0, :, :, :]\ncombination_features = layer_features[2, :, :, :]\n\nloss += content_weight * content_loss(content_image_features,\n                                      combination_features)","cd39e14d":"def gram_matrix(x):\n    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n    gram = backend.dot(features, backend.transpose(features))\n    return gram","bcd0e7e2":"def style_loss(style, combination):\n    S = gram_matrix(style)\n    C = gram_matrix(combination)\n    channels = 3\n    size = height * width\n    return backend.sum(backend.square(S - C)) \/ (4. * (channels ** 2) * (size ** 2))\n\nfeature_layers = ['block1_conv2', 'block2_conv2',\n                  'block3_conv3', 'block4_conv3',\n                  'block5_conv3']\nfor layer_name in feature_layers:\n    layer_features = layers[layer_name]\n    style_features = layer_features[1, :, :, :]\n    combination_features = layer_features[2, :, :, :]\n    sl = style_loss(style_features, combination_features)\n    loss += (style_weight \/ len(feature_layers)) * sl","8147b2fb":"def total_variation_loss(x):\n    a = backend.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n    return backend.sum(backend.pow(a + b, 1.25))\n\nloss += total_variation_weight * total_variation_loss(combination_image)","93b24329":"grads = backend.gradients(loss, combination_image)","274c530c":"outputs = [loss]\noutputs += grads\nf_outputs = backend.function([combination_image], outputs)\n\ndef eval_loss_and_grads(x):\n    x = x.reshape((1, height, width, 3))\n    outs = f_outputs([x])\n    loss_value = outs[0]\n    grad_values = outs[1].flatten().astype('float64')\n    return loss_value, grad_values\n\nclass Evaluator(object):\n\n    def __init__(self):\n        self.loss_value = None\n        self.grads_values = None\n\n    def loss(self, x):\n        assert self.loss_value is None\n        loss_value, grad_values = eval_loss_and_grads(x)\n        self.loss_value = loss_value\n        self.grad_values = grad_values\n        return self.loss_value\n\n    def grads(self, x):\n        assert self.loss_value is not None\n        grad_values = np.copy(self.grad_values)\n        self.loss_value = None\n        self.grad_values = None\n        return grad_values\n\nevaluator = Evaluator()","f404f918":"x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n\niterations = 15\n\nfor i in range(iterations):\n    print('Start of iteration', i)\n    start_time = time.time()\n    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n                                     fprime=evaluator.grads, maxfun=20)\n    print('Current loss value:', min_val)\n    end_time = time.time()\n    print('Iteration %d completed in %ds' % (i, end_time - start_time))","b81356db":"x = x.reshape((height, width, 3))\nx = x[:, :, ::-1]\nx[:, :, 0] += 103.939\nx[:, :, 1] += 116.779\nx[:, :, 2] += 123.68\nx = np.clip(x, 0, 255).astype('uint8')\n\nImage.fromarray(x)","d7d72dce":"final_test","d6e6995d":"Turning it all into one singular tensor which VGG can use.","4ec0b753":"Defining gradients for the optimization problem.   \n(The algorithm uses these to see how much they changing to get some idea of what the hell it's doing)","56dcce72":"These variables were defined by the author of the article.  \nThey are all up to personal choice however, you can play around with them however you'd like.","38aef6af":"The code is from an interesting article I found on using machine learning and common algorithms. \nYou can find the article [here. ](https:\/\/harishnarayanan.org\/writing\/artistic-style-transfer\/)  \nI highly encourage you to go and check out the article as It will explain the steps much much better than I can. I'm only a beginner and I like the intuative feel for explaining things rather than long mathematical explanations.  \nIf you want to know how it does it, go to the article, if you're curious on what each individual part does, keep going.\nI used my own images in the kernel, but feel free to either copy or fork the kernel to try it with your own images :)  ","97450c74":"As the author puts it, this is to add a bit of normalization to the optimization problem we have on hand.  \nYou can play with the  \"total_variation_weight\" to get a more more apealing model for you.\n","95302467":"If you're familiar with machine learning and such, you probably used the \".fit\" function a lot for your transfer learning apps and such.  \nWell this is basically that function opened up and showing you what happens under the hood.","e9c706c1":"We take the Eucledian distance between the content and the combination image here to define the loss function.","c2d24bb3":"He then runs his iterations (The fit analogy was kind of a sloppy one for the above cell but you get the point) and combination image pops out","7753868e":"This is again to calculate the loss of the style from the \"Style image\".  \nIt's the same principle idea as the \"content loss\" function","80955f88":"This gram matrix as the author puts it allows us to compute the features that are closely related in terms of their occurences with each other.  \nAs I mentioned I won't go into huge detail, this is just me trying to explain it in a beginner level understanding.","7559ccc7":"We then use these arrays to define variables in Keras\u2019 backend."}}