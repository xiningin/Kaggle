{"cell_type":{"bc66d40d":"code","f548e556":"code","cbb88077":"code","d4d6583f":"code","32dcacc4":"code","3cb144d7":"code","f15e3947":"code","5fc0008d":"code","cde0859c":"code","c2621394":"code","6853cd0d":"code","1a17bf34":"code","3ae600b7":"code","a9f59cd3":"code","29b0576f":"code","6c9c5b54":"code","85f4ddb9":"code","462a4349":"code","152f3228":"code","dba10804":"code","34e64683":"code","7a61d3dc":"code","d6c98fcb":"code","d40cd810":"code","97c5a3ec":"code","63b1e771":"code","ed9f5d5b":"code","9b26efc2":"markdown","49aee02a":"markdown","fbf18de5":"markdown","d1663b58":"markdown","3b7c6bba":"markdown","f50fc99e":"markdown","6dd6ebf9":"markdown","9743793e":"markdown","427219a6":"markdown","b636e531":"markdown","fcb76fb1":"markdown","1e9be5b4":"markdown","2bad4eb4":"markdown","09d66f77":"markdown","e424a47d":"markdown","d93090e8":"markdown","37185d8f":"markdown","5614dcf7":"markdown","b8f2643e":"markdown","7f898268":"markdown","82358357":"markdown","46ee58a5":"markdown","56e19769":"markdown","9be1c545":"markdown"},"source":{"bc66d40d":"import numpy as np\nimport pandas as pd\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings('ignore')","f548e556":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","cbb88077":"df[df.columns].isnull().sum()","d4d6583f":"df.columns","32dcacc4":"df.hist(bins = 50, figsize = (20,20))\nplt.show()","3cb144d7":"df['Time'].hist(bins = 425, figsize = (15,5))\nplt.show()","f15e3947":"Data = df.loc[(df['Time']>18103) & (df['Time']<105172),:]\nData_test = df.loc[(df['Time']<18104) | (df['Time']>105171),:] \n\nData['Time'].hist(bins = 213, figsize = (15,5))\nData_test['Time'].hist(bins = 450, figsize = (15,5))\nplt.show()","5fc0008d":"Data = Data.reset_index()\nData = Data.drop('index', axis =1)\n\nData_test = Data_test.reset_index()\nData_test = Data_test.drop('index', axis = 1)","cde0859c":"normal = Data.loc[Data['Class'] == 0, :]\nnormal.describe()","c2621394":"fraud = Data.loc[Data['Class'] == 1, :]\nfraud.describe()","6853cd0d":"plt.figure(figsize=(20,50))\ni=1\nfor feature in normal.columns:\n    plt.subplot(11,3,i)\n    plt.hist(normal[feature], bins = 100)\n    plt.hist(fraud[feature],bins = 100)\n    plt.title(feature)\n    i=i+1\nplt.tight_layout()\nplt.show()","1a17bf34":"features = Data.columns[:-1]\n\nplt.figure(figsize=(20,50))\ni=1\nfor feature in features:\n    plt.subplot(11,3,i)\n    sns.kdeplot(normal[feature], shade= True)\n    sns.kdeplot(fraud[feature], shade= True)\n    i=i+1\n    plt.tight_layout()\nplt.show()","3ae600b7":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats.mstats import winsorize\n\n#scale between (0,1)\nData_norm = MinMaxScaler().fit_transform(Data.iloc[:,:-1])\nData_norm = pd.DataFrame(Data_norm)\nData_norm['Class'] = Data['Class']\nnormal = Data_norm.loc[Data_norm['Class'] == 0, :]\nfraud = Data_norm.loc[Data_norm['Class'] == 1, :]","a9f59cd3":"columns = [1,2,3,4,5,7,9,10,11,12,14,16,17,18,29]","29b0576f":"Data = Data_norm.sample(frac = .2, random_state = 42)\nX = Data.loc[:,columns]\ny = Data['Class']\nprint(X.shape)\nprint(y.shape)","6c9c5b54":"classifiers = {\n    \"ISOLATION FOREST\":IsolationForest(n_estimators=155, max_samples=len(X), \n                                       contamination=.00194,random_state=42, verbose=0),\n    \"LOCAL OUTLIER FACTOR\":LocalOutlierFactor(n_neighbors=200, algorithm='auto', leaf_size=230, \n                            metric='euclidean', p=1, metric_params=None, contamination=.0021),\n    \"ONE CLASS SVM\":OneClassSVM(kernel='rbf', degree=3, gamma = 'auto', nu=0.00215, max_iter=-1)\n}","85f4ddb9":"for i, (clf_name,clf) in enumerate(classifiers.items()):\n    #Fit the data and tag outliers\n    if clf_name == \"LOCAL OUTLIER FACTOR\":\n        y_pred = clf.fit_predict(X)\n        scores_prediction = clf.negative_outlier_factor_\n    elif clf_name == \"ONE CLASS SVM\":\n        clf.fit(X)\n        y_pred = clf.predict(X)\n    else:    \n        clf.fit(X)\n        scores_prediction = clf.decision_function(X)\n        y_pred = clf.predict(X)\n    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n    y_pred[y_pred == 1] = 0\n    y_pred[y_pred == -1] = 1\n    n_errors = (y_pred != y).sum()\n    # Run Classification Metrics\n    print(\"{} number of errors: {}\".format(clf_name,n_errors))\n    print(pd.crosstab(y, y_pred)) \n    print('silhouette coefficient:',round(metrics.silhouette_score(Data, y_pred, metric='euclidean'), 3))\n    print('Adjusted Rand index   :',round(metrics.adjusted_rand_score(y, y_pred),3))\n    print(\"Classification Report :\") \n    print(classification_report(y,y_pred))","462a4349":"pip install pyod","152f3228":"from pyod.models.auto_encoder import AutoEncoder\nfrom sklearn.decomposition import PCA","dba10804":"pca = PCA(2)\nx_pca = pca.fit_transform(X)\nx_pca = pd.DataFrame(x_pca)\nx_pca.columns = ['pc1', 'pc2']\n\nplt.figure(figsize=(12,8))\nplt.title('Sample Distribution on First 2 PCAs by Class Color')\nplt.scatter(x_pca['pc1'], x_pca['pc2'], alpha = .6, c=y)\nplt.show()","34e64683":"clf1 = AutoEncoder(hidden_neurons =[15, 10, 6, 2, 2, 6, 10, 15], epochs = 26, contamination = .002)\nclf1.fit(X)","7a61d3dc":"y_scores = clf1.decision_scores_\ny_scores = clf1.decision_function(X)  #map all points to one a line\ny_scores = pd.Series(y_scores)","d6c98fcb":"plt.figure(figsize=(15,50))\nplt.axvline(23.5, color = 'b', alpha = .9)\nplt.hist(y_scores, bins=1000)  \nplt.title(\"Histogram for Model Clf1 Anomaly Scores\")\nplt.show()","d40cd810":"x_pca['clf1_score'] = y_scores\nx_pca['cluster'] = np.where(x_pca['clf1_score'] < 23.5, 0, 1)\nx_pca['cluster'].value_counts()","97c5a3ec":"Class = y.reset_index()\nClass = Class.drop('index', axis =1)\nx_pca['Class'] = Class","63b1e771":"n_errors = (x_pca.cluster != x_pca.Class).sum()\nprint(\"AutoEncoder number of errors: {}\".format(n_errors))\nprint(pd.crosstab(x_pca.Class, x_pca.cluster))\nprint('silhouette coefficient:',round(metrics.silhouette_score(x_pca, x_pca.cluster, metric='euclidean'), 3))\nprint('Adjusted Rand index   :',round(metrics.adjusted_rand_score(x_pca.Class, x_pca.cluster),3))\nprint(\"Classification Report :\")\nprint(classification_report(x_pca.Class, x_pca.cluster))","ed9f5d5b":"plt.figure(figsize=(12,8))\nplt.title('Sample Distribution on First 2 PCAs by Prediction Color')\nplt.scatter(x_pca['pc1'], x_pca['pc2'], alpha = .6, c=x_pca['cluster'])\nplt.show()","9b26efc2":"## Modeling\n\nLets realize that we are looking for a needle in a hay barn.  99.83% of the data are normal transactions.  We could balance the data by oversampling or undersampling.  But we want our models to be able to produce results in the real word not just in testing environment. This is why we should use the unbalanced data, in order to better simulate real world cases. If our model can identify even a fraction of fraud cases, it is adding value.  ","49aee02a":"Lets use AutoEncoder to reduce the dimensions in the hidden layers.  ","fbf18de5":"# Credit Card Anomaly Detection with Unsupervised Learning \n\n## Context\nIt is important that banks are able to recognize fraudulent credit card transactions so their customers are not charged for the items. If your credit card information is compromised, a fraudster can buy it on the dark web and use it to make large purchases. The swindler can flip items quickly at low prices while make lots of money since its 100% profit.    \n\nBut when you discover the charges on your card, you will have to dispute it.  Almost all the time, banks side with the individual person.  The store the fraudster bought from will have to absorb this cost.  The stores will stop doing business with the banks if that cost gets too high.  Banks want to keep their customers and therefore have an incentive to look  for robust models that can predict fraudulent transactions.    \n\n## Supervised or Unsupervised Learning?\n\n#### What is supervised?  \nTraditional supervised learning is when one tries to fit some feature matrix X to a target.  The model will adjust the weights according to some type of cost function.  In regression the sum of the squared residuals are minimized. And in Classification some type of impurity or enthalpy is used to determine the rule for branches to split on.  They initialize with random weights and checks its predicted vector against the target vector and then adjust the weights incrementally,always checking with the target vector, until a stopping condition is reached.    \n\nYou need a lot of labeled data in order to be able to build this type of model and have it performs well.  You also have to continually train and update the model to keep up with changes in behavior of individuals over time.  If the data is stale, you will not get good results.  It takes a lot of time and engineering to produce good quality labeled data and can become expensive.   \n\n\n#### Why unsupervised learning?\nUnsupervised learning are models that don\u2019t take the y(target) as an argument.  It does not fit the data so you don\u2019t need the ground truth to make predictions.  Banks are in a similar situation where they don\u2019t know if a transaction is fraud when the transaction is happening.  \n\nThe unsupervised models will take a feature matrix X and make labels based on unseen structures and hidden correlations within the feature space.\n\n## Unsupervised Anomaly Models\n\nA newer way to approach the problem is called outlier detection.  Assume the fraud detection data are just points distributed in n-dimenstional space and can be transformed to a Gaussian.  If there is a delta between the behavior of fraudsters and regular customers, and this delta is statistically significant, then you should be able to detect it with the right features and even get probabilites with Null hypothesis test.   The anomalous nature of the fraud transaction will result in a data point far away from the centroid of the normal transactions.  \n\nOur unsupervised anomaly models will take all the points in the original feature space and use algorithms to return a surjective mapping of all points onto one dimensional line called anomaly score.  Then, in this lower subspace, it will make the decision of whether or not the point is anonymous and produce a label.  \n\n### Isolation Forest Algorithm \n\nA newer technique used to detect anomalies is called Isolation Forests. The algorithm works because anomalies are data points that are far from regular ones. As a result, anomalies are susceptible to a mechanism called isolation.\n\nThe algorithm isolates points by randomly selecting a feature and then split on values between the maximum and minimum values of the feature until the points are isolated from each other.  Isolating anomalous observations is easier because only a few generations are needed to separate those cases from the normal observations. On the other hand, isolating normal observations require many more generations. Therefore, an anomaly score is calculated as the path length required to separate a given observation.\n\nThis algorithm has low computation complexity and use less memory. It builds a good performing model with a small number of trees using fixed sub-sample sizes, regardless of the size of a data set.\n\n### Local Outlier Factor Algorithm\n\nThe LOF algorithm is an unsupervised outlier detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outlier point that have a substantially lower density than their neighbors.\n\nThe parameter for number of neighbors is typically chosen to be greater than the minimum number of objects a cluster has to contain, so that other objects can be local outliers relative to this cluster, and smaller than the maximum number of close by objects that can potentially be local outliers.\n\n### One Class SVM\n\nOneClassSVM is unsupervised learning algorithms designed for outlier detection.  The model is trained on \u2018healthy\u2019 data.  The algorithm learns on the normal transactions and creates a model that contains a representation of the data.  When introduced to observations that are far away, it will be labels as outlier and return a negative number.  When introduced to observations that are close, it will be labeled as inlier, a positive number.\n\n### Autoencoders\n\nAutoencoders are a type of neural network that is used for unsupervised learning.  They also don\u2019t require the conventional y.   Often, autoencoders have the same number of output nodes as input nodes, while the hidden layers have less nodes.   The hidden layers will extract the essential information of the input.  This condition forces the hidden layers to learn most of the pattern in the data and ignore the \u201cnoises\u201d.  This is similar to Principal Component Analysis(PCA).  The difference being, PCAs is a linear transformation and autoencoders use non-linear and complex techniques.\n\n## Code Sections\nLoad Data\n\nEDA and Feature selection\n\nModeling and Evaluation\n\nConclusion\n\nReferences","d1663b58":"Here we select for the features that make sense in this data.","3b7c6bba":"### Conclusion\nResults of the models, the labels, can be treated as a new categorical feature to be used in supervised training.  If in some random forest a branch is split on this feature because it reduced enthalpy the most in that generation, then we can say these models have made some amount of contribution.  In the future I will incorporate DBSCAN which is another density based algorithm like LOF. \n\nAnomaly detection is a large subject.  The methods used to identify them vary greatly depending on the type of anomalous activity.  In this project, all of the models with the exception of One Class SVM showed good promise as anomaly detectors.  The scores indicates LOF(density based) performs best for the type of attack pattern presented this data set.  ","f50fc99e":"As you can see there was only 61 fraud out of 28,927 transaction. Isolation forest is doing great. But LOF is even better! The scores can be tuned depending if we are interested in higher recall or precision. It depends on the type of fraud the bank is looking for.  \n\n","6dd6ebf9":"Next let's see how we can use AutoEncoder to produce a label step by step.   ","9743793e":"It is very difficult to detect fraud transaction because in addition to severe class imbalance there is also severe class overlap.  Fraud transactions are mixed in with the normal ones.  It is important to go through the features one by one and make sure its appropriate to pass it to the models.  \n\nWe want enough features to be able to say something about the distribution but don't want too many as this will introduce noise.   ","427219a6":"\n## References\nThese are not my original ideas.  This is my current understanding on the subject after consulting the blogs and videos below.  \n\nhttps:\/\/www.youtube.com\/watch?v=5p8B2Ikcw-k&t=762s, Elena Sharova\n\nhttps:\/\/www.youtube.com\/watch?v=rHSpab1Wi9k&t=924s,Leela Senthil Nathan\n\nhttps:\/\/www.youtube.com\/watch?v=RyFQXQf4w4w&t=319s,Jan Van Der Vegt\n\nhttps:\/\/github.com\/krishnaik06\/Credit-Card-Fraudlent, Krish C Naik\n\nhttps:\/\/neurospace.io\/blog\/2019\/03\/predicting-credit-card-fraud-with-unsupervised-learning\/,  Maria Jensen ","b636e531":"Time!","fcb76fb1":"We need to further reduce rows in the data but while retaining the meaningful information.  This is just to save time during training.  ","1e9be5b4":"### Load Data","2bad4eb4":"The points far away from the mean of the distribution are outliers.  Lets look at a graph and decide what score to use in order to produce the labels.  ","09d66f77":"Clearly, it looks like there are cycles.  We take a complete cycle.    ","e424a47d":"Choose parameters in a way that makes sense.   ","d93090e8":"Fraud is also very hard to detect because they are hiding in a lower dimensional subspace.  By looking at the kernel densities of the features we can select for features that can help to identify fraud transactions.   ","37185d8f":"Lets check out the scores.","5614dcf7":"Lets take a look at our sample in the 1st and 2nd PCA so we can get a general idea of the distribution. ","b8f2643e":"I think 23.5 looks about right.","7f898268":"When looking at the descriptive statistics you can tell the centroid of the the two group are quite different . Also notice the standard deviation in PCA_1, which holds most of the variation, is 1.8 for normal calss while standard deviation fraud class at 7 can be considered extream. \n\nLets take closer look at our features.  ","82358357":"Please up vote if you read this far.  The technique may yield a few extra basis points.  This is my current understanding.  Please let me know if you think I have some misunderstanding on the subject.  I would enjoy learning more about techniques to map data from higher dimensions to lower ones. ","46ee58a5":"## EDA and Feature Selection\nAre there any missing values?","56e19769":"It may seem obvious where the outliers are but it can be hard for an algorithm.  We are only looking at it in 2 dimensions but there are 13 more unseen cardinal directions.  ","9be1c545":"Great! Lets get general idea of the features in the data.  "}}