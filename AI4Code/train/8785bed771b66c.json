{"cell_type":{"7f941757":"code","0ea56ea7":"code","4d9d18f6":"code","b64beb2a":"code","10f6c495":"code","7c69f813":"code","828b715a":"code","4abe2cbc":"code","5af057b0":"code","2e69bd3f":"code","c176cf9a":"code","a0a9c903":"code","c0b99e93":"code","cb561e70":"code","1df0aec6":"code","922df8e3":"code","69371f12":"code","61a2bf5e":"code","5a47ae1b":"code","5b7e8e06":"code","08405825":"code","e9efd631":"code","982ce5b6":"code","023d83d5":"code","4913472d":"code","0eb54f1b":"code","7378da5d":"code","6531243f":"code","31462db4":"code","3ff34e39":"code","ff089134":"code","39280979":"code","3f0ef0a4":"code","15e76b12":"code","b4d4bd6b":"code","220f51c3":"code","0b157764":"code","4be99042":"code","50e3062e":"code","520ebc47":"markdown","01ddabe5":"markdown","e9b71dbe":"markdown","1d183eb4":"markdown","3dc5c7c0":"markdown","b4a0e04b":"markdown","2fb9410f":"markdown","cd1b47b4":"markdown","5c583521":"markdown","d1fbd59f":"markdown","a55293e3":"markdown","0c669338":"markdown","ca3ab770":"markdown","08220d8c":"markdown","56420e93":"markdown","38f99a3a":"markdown","e2b658d2":"markdown","d01a103c":"markdown","4865e167":"markdown"},"source":{"7f941757":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","0ea56ea7":"data = pd.read_csv(\"..\/input\/cancer-classification\/cancer_classification.csv\")","4d9d18f6":"data.head()","b64beb2a":"data.info()","10f6c495":"data.describe().transpose()","7c69f813":"plt.figure(figsize=(12,7))\nsns.set_context(\"paper\", font_scale=1.5)\nsns.countplot(\"benign_0__mal_1\", data=data, color=\"pink\")\nplt.title(\"Malignancy vs Benign\")\nplt.xlabel(\"Malignancy - No:0, Yes:1\")","828b715a":"plt.figure(figsize=(15,7))\nsns.set_context(\"paper\")\nsns.heatmap(data.corr(), cmap=\"coolwarm\")","4abe2cbc":"plt.figure(figsize=(15,8))\ndata.corr()[\"benign_0__mal_1\"].sort_values().plot(kind=\"bar\", color=\"pink\")","5af057b0":"from sklearn.model_selection import train_test_split","2e69bd3f":"X = data.drop(\"benign_0__mal_1\", axis=1).values\ny = data[\"benign_0__mal_1\"].values","c176cf9a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)","a0a9c903":"from sklearn.preprocessing import MinMaxScaler","c0b99e93":"scaler = MinMaxScaler()","cb561e70":"X_train = scaler.fit_transform(X_train)","1df0aec6":"X_test = scaler.transform(X_test)","922df8e3":"from tensorflow.keras.models import Sequential","69371f12":"from tensorflow.keras.layers import Dense,Dropout","61a2bf5e":"X_train.shape","5a47ae1b":"model = Sequential()\n\nmodel.add(Dense(30, activation=\"relu\"))\nmodel.add(Dense(15, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")","5b7e8e06":"model.fit(x=X_train, y=y_train,epochs=600, validation_data=(X_test, y_test))","08405825":"losses = pd.DataFrame(model.history.history)","e9efd631":"losses","982ce5b6":"losses.plot()","023d83d5":"model = Sequential()\n\nmodel.add(Dense(30, activation=\"relu\"))\nmodel.add(Dense(15, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")","4913472d":"from tensorflow.keras.callbacks import EarlyStopping","0eb54f1b":"early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=25)","7378da5d":"model.fit(x=X_train, y=y_train,epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])","6531243f":"model_loss = pd.DataFrame(model.history.history)","31462db4":"model_loss","3ff34e39":"model_loss.plot()","ff089134":"from tensorflow.keras.layers import Dropout","39280979":"model = Sequential()\n\nmodel.add(Dense(30, activation=\"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(15, activation=\"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")","3f0ef0a4":"model.fit(x=X_train, y=y_train,epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])","15e76b12":"model_loss = pd.DataFrame(model.history.history)","b4d4bd6b":"model_loss","220f51c3":"model_loss.plot()","0b157764":"prediction = model.predict_classes(X_test)","4be99042":"from sklearn.metrics import classification_report, confusion_matrix","50e3062e":"print(classification_report(y_test, prediction))\nprint(confusion_matrix(y_test, prediction))","520ebc47":"### Getting ready for modeling. Setting X variable and y variable for train and test data.","01ddabe5":"# Description:\n### Using predictive models can be benefial to the healthcare industry. New technologies, such as deep neural network, can help healthcare professionals to predict cells, if they were maglignant or benign. It takes years of training for physicians to be able to diagnose cancer. Having a reliable predictive model can positively impact the efficiency of healthcare. By no means can the model replace physicians, predictive models can help physicians to prioritize their workload and focus on high-risk patients. This interesting project will use deep neural network with early stopping and dropout on the cancer dataset. ","e9b71dbe":"### An overview of the type of data","1d183eb4":"### Importing from tensorflow.keras libraries ","3dc5c7c0":"### Dropping the \"benign_0__mal_\" in X variable as it is the target feature in this predictive model. ","b4a0e04b":"### Importing libraries","2fb9410f":"# Project Objective:\n### To develop a predictive model using deep neural network to predict if the cell is malignant or benign. The target feature or the y-variable is \"benign_0__mal_1\". ","cd1b47b4":"# Potential Impact\n### Potential positive impact included healthcare resouce allocation strategy, improve efficiency and the process of diagnosing a patient, and help physicians to prioritize their workload. Early recognition and diagnosis can significantly improve the chance of survival and recovery. ","5c583521":"### A quick glance at the correlations between features","d1fbd59f":"### Adding dropput setting at 0.5, which is arbitrary.","a55293e3":"### With early stopping added to the model, the validation losses is better than the previous","0c669338":"### Test size is set at 25% of the data. Random state will be used so the random sequence will be the same each time. It is set at 101, which is an arbitrary number. ","ca3ab770":"### Basic descriptive analysis","08220d8c":"### Visualizing the loss values","56420e93":"### Adding early stopping to the model","38f99a3a":"### Since this is a small dataset, 30 neurons will be used and then reduced to half for the second layer. Rectified linear unit will be used as the activation and Sigmoid as the final layer. Binary_crossentropy will be used as loss function as this is a binary classification. Adam will be used, which is the common optimizer. ","e2b658d2":"### The graph below shows the significant impact on validation loss when early stopping and dropout included","d01a103c":"### Preprocessing the data using scaler. ","4865e167":"# Process:\n### This interesting project will start off with basic descriptive analysis, followed by exploratory data analysis, data visualization, preprocessing the data using a scaler, setting up train & test data, finally fit the data into the model. This project will be concluded with metrics, such as classification report and confusion matrix to evaluate the model's performance. "}}