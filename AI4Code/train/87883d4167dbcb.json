{"cell_type":{"64b85499":"code","71e73aab":"code","0ea3a433":"code","8c53db84":"code","ed4af221":"code","381c7468":"code","34d59c47":"code","bf4eb57d":"code","8e82707d":"code","f67200b7":"code","63987ad9":"code","3cb7d68e":"code","742aed14":"code","e0af757e":"code","98a02550":"code","40f3a36e":"code","9537a08e":"code","99563a56":"code","c1769632":"code","80db0415":"code","71cff66e":"code","c5935155":"code","88e50848":"code","38791ace":"code","5f3e7491":"code","3f09a4d5":"code","4267cf0d":"code","04aff684":"code","ea908d7e":"code","9e8cf818":"code","10e806d8":"code","1498bf8e":"code","c8829f4e":"code","a2397ec5":"code","47dbbb12":"code","db7f762f":"code","1b876d75":"code","1e2e7aed":"code","4d80d03c":"code","4cfe8593":"code","46b588e9":"code","277e5dfd":"code","00390487":"code","5591af89":"code","7bb6a9dc":"code","52f29d6b":"code","efb66e5f":"code","cc86c2f2":"code","52acc6dc":"code","2e54f5a2":"code","5f6e9e3a":"code","12f13cb2":"code","5a8fac56":"code","02a0b75e":"code","03ca3f95":"code","8c4576a8":"code","1eb360ef":"code","3c84651f":"code","af08c1c4":"code","1091f575":"code","2301ad38":"code","2b299c46":"code","6c64110d":"code","6a704fcb":"code","b60303ab":"code","4935d3ae":"code","79c0ee1e":"code","a33492a4":"code","55d93fca":"code","a40abded":"code","8b8bc76e":"code","67c5b977":"code","65b00bcc":"code","d351c03b":"code","dec266cb":"code","45ee2280":"code","46e9b1f2":"code","40acfefc":"code","a46c78df":"code","4c4a674c":"code","f18ab502":"code","6e67d603":"code","f89676dd":"code","e4662b8e":"code","b7b93fea":"code","1cf5a6cf":"code","0ab303ef":"code","585433b6":"code","27c0757f":"code","247256d5":"code","57aa475e":"code","fbe3730f":"code","876341a6":"code","9a37c5fe":"code","c558401f":"code","f82746f4":"code","929e0fdf":"markdown","7fc09c59":"markdown","b0b551ab":"markdown","22d1bbef":"markdown","da7c1d40":"markdown","97a22c44":"markdown","fbda1220":"markdown","e8da0b83":"markdown"},"source":{"64b85499":"#Import all the necessary packages needed for your problem\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport pandas as pd\nimport numpy as np\nimport os ","71e73aab":"#As there are two folder storing their file path in two different variables\nTrain_female_path=\"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Train\/Female\"\nTrain_male_path=\"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Train\/Male\"\nValidation_female_path=\"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Validation\/Female\"\nValidation_male_path=\"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Validation\/Male\"\nTest_female_path=\"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Test\/Female\"\nTest_male_path=\"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Test\/Male\"","0ea3a433":"#Creating a list to store all the training male and female filepaths\n\nfemale_train_files=[]\nfemale_train=list()\nmale_train=list()\n# listdir lists all the files in the given file path and stores it in the list\nfemale_train_files=os.listdir(Train_female_path)\nmale_train_files=os.listdir(Train_male_path)\n# As for now we only get the file name as in (01.jpg) so appending the file path with the filename\nfor i in range(len(os.listdir(Train_female_path))):\n    female_train.append(Train_female_path+\"\/\"+str(female_train_files[i]))\nfor i in range(len(os.listdir(Train_male_path))):\n    male_train.append(Train_male_path+\"\/\"+str(male_train_files[i]))\n  ","8c53db84":"# Checking for the entire size of the training data\nlen(female_train)+len(male_train)","ed4af221":"Train_df=pd.DataFrame()","381c7468":"# Creating a training data frame with female images path and their target value as Female\nTrain_df=pd.DataFrame({\"ID\":female_train,\"Target\":\"Female\"})","34d59c47":"len(Train_df)","bf4eb57d":"Train_df[\"ID\"][0],Train_df[\"Target\"][0]","8e82707d":"# Creating Dataframe from male file path and assigning their as Male\nMale_df=pd.DataFrame({\"ID\":male_train,\"Target\":\"Male\"})","f67200b7":"# Combining the male and female training dataframe\nTrain_df=Train_df.append(Male_df,ignore_index=False)","63987ad9":"len(Train_df)","3cb7d68e":"# Shuffling the entire data frame as their in the female first and male last order\nTrain_df=Train_df.sample(frac=1)","742aed14":"Train_df.head()","e0af757e":"#Fetching all the file names from Training dataframe and storing it as list\nAll_training_files=[fname for fname in Train_df[\"ID\"]]","98a02550":"All_training_files[:7]","40f3a36e":"# Converting the target variable to num py\nlabels=Train_df[\"Target\"].to_numpy()","9537a08e":"labels[:10]","99563a56":"# Finding the unique values in the labels as there is only two target that needs to be predicted\ntrue_labels=np.unique(labels)","c1769632":"len(true_labels)","80db0415":"labels[1]==true_labels","71cff66e":"boolean_labels=[labels == true_labels for labels in labels]\nlen(boolean_labels)","c5935155":"print(labels[0])\nprint(np.where(true_labels[0]==labels[0]))\nprint(boolean_labels[0].argmax())\nprint(boolean_labels[0].astype(int))\n","88e50848":"boolean_labels[0]","38791ace":"Train_df.tail()","5f3e7491":"# Creating the Feature variable and Target variable\nX=All_training_files\ny=boolean_labels","3f09a4d5":"# Experimenting with 10k samples \nNUM_IMAGES=10000","4267cf0d":"female_val_files=[]\nfemale_val=list()\nmale_val=list()\n#Storing  all the files in given file path into two variables\nfemale_val_files=os.listdir(Validation_female_path)\nmale_val_files=os.listdir(Validation_male_path)\n# Appending the filepath with the file name\nfor i in range(len(os.listdir(Validation_female_path))):\n    female_val.append(Validation_female_path+\"\/\"+str(female_val_files[i]))\nfor i in range(len(os.listdir(Validation_male_path))):\n    male_val.append(Validation_male_path+\"\/\"+str(male_val_files[i]))\n  ","04aff684":"female_val[1]","ea908d7e":"# Creating a dataframe for male and female\nValid_df=pd.DataFrame({\"ID\":female_val,\"Target\":\"Female\"})\nnew_val_row=pd.DataFrame({\"ID\":male_val,\"Target\":\"Male\"})\n# Combining the both \nValid_df=Valid_df.append(new_val_row,ignore_index=True)\n","9e8cf818":"Valid_df.head()","10e806d8":"#Shuffling the data\nValid_df=Valid_df.sample(frac=1)","1498bf8e":"Valid_df.tail()","c8829f4e":"# Getting  all the file paths from validation dataframe\nAll_val_files=[fname for fname in Valid_df[\"ID\"]]","a2397ec5":"All_val_files[:5]","47dbbb12":"val_labels=Valid_df[\"Target\"].to_numpy()\nval_labels[:10]","db7f762f":"val_true_labels=np.unique(val_labels)\nlen(val_true_labels)","1b876d75":"boolean_val_labels=[labels==val_true_labels for labels in val_labels ]\nboolean_val_labels[:10]","1e2e7aed":"# Splitting data into training and validation set\nX_train,y_train=All_training_files[:NUM_IMAGES],boolean_labels[:NUM_IMAGES]\nX_val,y_val=All_val_files[:2000],boolean_val_labels[:2000]","4d80d03c":"len(X_train)","4cfe8593":"IMG_SIZE=224\n# Creating a function that can preprocess the data\ndef preprocess_data(image_path,img_size=IMG_SIZE):\n    #Reading the image path\n    image=tf.io.read_file(image_path)\n    #Turning the image into numerical tensors of colour channel\n    image=tf.image.decode_jpeg(image,channels=3)\n    #Converting the colour channels from 0-255 values to 0-1\n    image=tf.image.convert_image_dtype(image,tf.float32)\n    #Resize our images into the desired value 224\n    image=tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n    return image","46b588e9":"#Function to return a tuple of preprocessed image in form tensors and their respective labels\ndef get_image_label(image_path,label):\n    image=preprocess_data(image_path)\n    return image,label","277e5dfd":"# Function to change all our X and y into data batches\nBATCH_SIZE=32\ndef create_data_batches(X,y=None,batch_size=BATCH_SIZE,valid_data=False,test_data=False):\n    # if it is training data then there won't be lables\n    if test_data==True:\n        print(\"Create test data batches....\")\n        data=tf.data.Dataset.from_tensor_slices((tf.context(X)))\n        data_batch=data.map(preprocess_data).batch(BATCH_SIZE)\n        return data_batch\n    # if it is valid data\n    elif valid_data==True:\n        print(\"Create validation data batches.....\")\n        data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n        data_batch=data.map(get_image_label).batch(BATCH_SIZE)\n        return data_batch\n    # if it is training data\n    else:\n        print(\"Creating training data batches....\")\n        data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n        data=data.map(get_image_label)\n        data_batch=data.batch(BATCH_SIZE)\n        return data_batch\n        ","00390487":"len(X_train),len(X_val)","5591af89":"# Create training and validation data batches\ntrain_data=create_data_batches(X_train,y_train)\nval_data=create_data_batches(X_val,y_val,valid_data=True)\n","7bb6a9dc":"train_data.element_spec,val_data.element_spec","52f29d6b":"import matplotlib.pyplot as plt\ndef show_25_images(images,label):\n    # setup a figure \n    plt.figure(figsize=(10,10))\n    # loop through 25 images\n    for i in range(25):\n        # Create subplots (5 rows,5 columns)\n        ax=plt.subplot(5,5,i+1)\n        # Display an image\n        plt.imshow(images[i])\n        # Add image label as title\n        plt.title(true_labels[label[i].argmax()])\n        # Turn the grid lines off\n        plt.axis(\"off\")","efb66e5f":"len(val_data)","cc86c2f2":"# Unbatch the data using as_numpy_iterator\ntrain_images,train_labels=next(train_data.as_numpy_iterator())\n# Now lets visualize the images in the training batch\nshow_25_images(train_images,train_labels)","52acc6dc":"# Now lets visualize the images in the validation batch\nval_images,val_labels=next(val_data.as_numpy_iterator())\nshow_25_images(val_images,val_labels)","2e54f5a2":"\n\n# Setting up a input shape\nINPUT_SHAPE=[None,IMG_SIZE,IMG_SIZE,3]\n\n# Settion up a output shape\nOUTPUT_SHAPE=len(true_labels)\n\n# Model URL\nMODEL_URL=\"https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_130_224\/classification\/4\"","5f6e9e3a":"# Building a keras model\ndef create_model(input_shape=INPUT_SHAPE,output_shape=OUTPUT_SHAPE,model_url=MODEL_URL):\n    model=tf.keras.Sequential([\n        hub.KerasLayer(MODEL_URL),\n        tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n                             activation=\"softmax\")\n    ])\n    \n    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n      optimizer=tf.keras.optimizers.Adam(),\n      metrics=[\"accuracy\"]\n\n  )\n\n    # Build the model\n    model.build(INPUT_SHAPE)\n\n    return model","12f13cb2":"model=create_model()\nmodel.summary()","5a8fac56":"%load_ext tensorboard","02a0b75e":"# Create a early stopping callback\nearly_stopping=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=3)","03ca3f95":"NUM_EPOCHS=100","8c4576a8":"import datetime\n# Create a function to build a TensorBoard Callback\ndef create_tensorboard_callback():\n    # Create a log directory for storing TensorBoard logs\n    logdir=os.path.join(\".\/kaggle\/working\/\",\n                      # Make it so the logs gets tracked whenever we run the expirement\n                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n    return tf.keras.callbacks.TensorBoard(logdir) ","1eb360ef":"# Build a function to train a model and return a trained model\ndef train_model():\n    # Create a model\n    model=create_model()\n\n    # Create a new session everytime we train a model\n    tensorboard=create_tensorboard_callback()\n\n    # Fit the model to the data passing it the callbacks we created\n    model.fit(x=train_data,\n            epochs=NUM_EPOCHS,\n            validation_data=val_data,\n            validation_freq=1,\n            callbacks=[tensorboard,early_stopping])\n    return model\n  ","3c84651f":"model=train_model()","af08c1c4":"len(val_data)","1091f575":"# Make Predictions on the validation data\npredictions=model.predict(val_data,verbose=1)\n","2301ad38":"predictions[:10]","2b299c46":"predictions.shape","6c64110d":"print(predictions[0])\nprint(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\nprint(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {true_labels[np.argmax(predictions[0])]}\")","6a704fcb":"\n# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return true_labels[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])\npred_label","b60303ab":"len(val_data)","4935d3ae":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n    \n    images = []\n    labelss = []\n    # Loop through unbatched data\n    for image, label in data.unbatch().as_numpy_iterator():\n        images.append(image)\n        labelss.append(true_labels[np.argmax(label)])\n    return images, labelss\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]","79c0ee1e":"len(val_images)","a33492a4":"def plot_pred(prediction_probabilities, labels, images, n=0):\n    \n    pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n    # Get the pred label\n    pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n    if pred_label == true_label:\n        color = \"green\"\n    else:\n        color = \"red\"\n\n    plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n                                      np.max(pred_prob)*100,\n                                      true_label),\n                                      color=color)","55d93fca":"len(predictions)","a40abded":"len(val_labels)","8b8bc76e":"plot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images)","67c5b977":"model.evaluate(val_data)\n","65b00bcc":"len(X)","d351c03b":"X=All_training_files[:90000]\ny=boolean_labels[:90000]","dec266cb":"X_val,y_val=All_val_files,boolean_val_labels","45ee2280":"# Creating full training and validation data batches\nFull_training_data=create_data_batches(X,y)\nFull_validation_data=create_data_batches(X_val,y_val,valid_data=True)","46e9b1f2":"len(Full_training_data)","40acfefc":"full_model=create_model()","a46c78df":"# Create full model callbacks\n\n# TensorBoard callback\nfull_model_tensorboard = create_tensorboard_callback()\n\n# Early stopping callback\nfull_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n                                                             patience=3)","4c4a674c":"NUM_EPOCHS","f18ab502":"full_model.fit(x=Full_training_data,\n            epochs=NUM_EPOCHS,\n            validation_data=Full_validation_data,\n            validation_freq=1,\n            callbacks=[early_stopping])\n    ","6e67d603":"# Storing all the test file paths \nfemale_test_files=[]\nfemale_test=list()\nmale_test=list()\nfemale_test_files=os.listdir(Test_female_path)\nmale_test_files=os.listdir(Test_male_path)\nfor i in range(len(os.listdir(Test_female_path))):\n    female_test.append(Test_female_path+\"\/\"+str(female_test_files[i]))\nfor i in range(len(os.listdir(Test_male_path))):\n    male_test.append(Test_male_path+\"\/\"+str(male_test_files[i]))\n  ","f89676dd":"#Creating a test Dataframe\nTest_df=pd.DataFrame()\nTest_df=pd.DataFrame({\"ID\":female_test,\"Target\":\"Female\"})\nnew_test_row=pd.DataFrame({\"ID\":male_test,\"Target\":\"Male\"})\nTest_df=Test_df.append(new_test_row,ignore_index=False)\n#Shuffling the data frame\nTest_df=Test_df.sample(frac=1)","e4662b8e":"Test_df.head()","b7b93fea":"len(Test_df)","1cf5a6cf":"X_test,y_test=Test_df[\"ID\"][:10000],Test_df[\"Target\"][:10000]","0ab303ef":"len(X_test)","585433b6":"test_data=create_data_batches(X_test,y_test)","27c0757f":"# Making Predictions on the entire data set\ntest_predictions=full_model.predict(test_data,verbose=1)","247256d5":"test_predictions.shape","57aa475e":"test_images,test_labels=unbatchify(test_data)","fbe3730f":"plot_pred(prediction_probabilities=test_predictions,\n          labels=test_labels,\n          images=test_images,n=200)","876341a6":"def show_test_25_images(images,label,predictions):\n    # setup a figure \n    plt.figure(figsize=(10,10))\n    # loop through 25 images\n    for i in range(25):\n        # Create subplots (5 rows,5 columns)\n        ax=plt.subplot(5,5,i+1)\n        # Display an image\n        plot_test_pred(prediction_probabilities=predictions, labels=label, images=images, n=i)\n        \n        # Turn the grid lines off\n        plt.axis(\"off\")","9a37c5fe":"plot_pred(prediction_probabilities=test_predictions, labels=test_labels, images=test_images, n=0)","c558401f":"def plot_test_pred(prediction_probabilities, labels, images, n=0):\n    \n    pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n    # Get the pred label\n    pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n    \n    color = \"green\"\n\n    plt.title(\"{} {:2.0f}%\".format(pred_label,\n                                      np.max(pred_prob)*100),\n                                      color=color)","f82746f4":"show_test_25_images(images=test_images,label=test_labels,predictions=test_predictions)","929e0fdf":"## Visualizing the data batches","7fc09c59":"## The Workflow\/Steps Followed in this Notebook for a simple Image Classification using Keras\n\n> Step 1 : Getting the data ready\n\n> Step 2 : Turning the data into tensors\n\n> Step 3 : Building the model \n\n> Step 4 : Making predictions on the test data\n\n","b0b551ab":"As the training,validation,test data each has two different folders named Male and Female we need to combine them and make them as a single data frame for training,validation,test data frame ","22d1bbef":"## Step 2: Turning the data into tensors","da7c1d40":"## **Step 1:Getting the data ready**","97a22c44":"## Step 3: Making Predictions on the entire test data set","fbda1220":"## Step 3: Building a machine learning model","e8da0b83":"## **Note:** \nI tried training my model with the entire training dataset (i.e 160k images) and the kaggle kernel CPU is filled up so I would recommend training with less than 100k images"}}