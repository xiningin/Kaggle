{"cell_type":{"849f63c3":"code","45943fb3":"code","8c67e218":"code","6114065f":"code","13deef41":"code","bf032019":"code","fb8ce58b":"code","fc74ddf8":"code","b69374fa":"code","929bfd4f":"code","a1d27171":"code","26e7c1c3":"code","e67b978f":"code","659cc6e6":"code","e17687cc":"code","c1853d01":"code","e5ed9b6d":"code","4be10707":"code","d2825cd6":"code","664479fa":"code","d6bb46f7":"code","a68299ee":"code","d4c2dc7e":"markdown","30669819":"markdown","bf0765c1":"markdown","8ad12361":"markdown","3bda3d5d":"markdown","4b1e32a1":"markdown","a6ac7ff2":"markdown"},"source":{"849f63c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","45943fb3":"import pandas as pd\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","8c67e218":"train_df=pd.read_hdf(\"..\/input\/nlp-itba-2019\/train_data_NLP_ITBA_2019.hdf\",mode='r',key=\"df\")\nvalid_df=pd.read_hdf(\"..\/input\/nlp-itba-2019\/valid_data_NLP_ITBA_2019.hdf\",mode='r',key=\"df\")\ntest_df=pd.read_hdf(\"..\/input\/nlp-itba-2019\/test_data_NLP_ITBA_2019.hdf\",mode='r',key=\"df\")","6114065f":"train_df.head()","13deef41":"tfidf=TfidfVectorizer(min_df=0,max_df=1.0)","bf032019":"X_train=tfidf.fit_transform(train_df[\"text_proc\"].tolist())\nX_val=tfidf.transform(valid_df[\"text_proc\"].tolist())\ny_train=train_df[\"gold_label\"].tolist()\ny_val=valid_df[\"gold_label\"].tolist()","fb8ce58b":"X_train.shape","fc74ddf8":"import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation,Dropout\nfrom keras.regularizers import l2\nimport keras\n\nenc = OneHotEncoder(handle_unknown='ignore')\ny_train_oh=enc.fit_transform(np.array(y_train).reshape(-1,1))\ny_val_oh=enc.transform(np.array(y_val).reshape(-1,1))\nreg=l2()\nmodel = Sequential([\n    Dense(100, input_shape=(X_train.shape[1],),kernel_initializer=keras.initializers.glorot_normal()),\n    Dropout(0.3),\n    Activation('relu'),\n    Dense(3),\n    Activation('softmax')])\nmodel.summary()","b69374fa":"from keras.optimizers import RMSprop,Adam,Nadam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n#opt=RMSprop()\nopt=Nadam()\ncheckpoint = ModelCheckpoint(\"best-RP.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nes = EarlyStopping(monitor='val_acc', patience=10)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['acc'])","929bfd4f":"model.fit(X_train, y_train_oh, epochs=1000, batch_size=1024,validation_data=[X_val,y_val_oh],callbacks=[checkpoint, es])","a1d27171":"model.load_weights(\"best-RP.hdf5\")","26e7c1c3":"X_test=tfidf.transform(test_df[\"text_proc\"].tolist())","e67b978f":"y_pred=model.predict(X_test).argmax(axis=-1)","659cc6e6":"y_pred","e17687cc":"enc.categories_","c1853d01":"submissions=list()\nfor pred in y_pred:\n    submissions.append(enc.categories_[0][pred])","e5ed9b6d":"submissions[0:3]","4be10707":"test_df.head()","d2825cd6":"test_df[\"gold_label\"]=submissions","664479fa":"test_df.head()","d6bb46f7":"output_df=test_df.drop(columns=[\"text\",\"text_proc\"])\noutput_df.head()","a68299ee":"output_df.to_csv(\"submission_NN.csv\")","d4c2dc7e":"Salvamos el archivo con las clasificaciones","30669819":"Predecimos las catagor\u00edas y nos quedamos con el \u00edndice argmax","bf0765c1":"Insertamos las clasificaciones en el dataframe de test y dropeamos las columnas que no queremos en el csv de salida.","8ad12361":"Convertimos \u00edndice a categor\u00eda","3bda3d5d":"Convertimos los textos de test a TFIDF","4b1e32a1":"Revisamos a qu\u00e9 categor\u00eda corresponde cada \u00edndice","a6ac7ff2":"Cargamos los datos"}}