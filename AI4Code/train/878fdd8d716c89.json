{"cell_type":{"2970f5fa":"code","e410557f":"code","19e964ee":"code","d9f3efc3":"code","7a11d594":"code","7e7b3bab":"code","af7f9529":"code","d1abf67f":"code","8485fe1c":"code","7a0cc7cd":"code","04f26750":"code","77017295":"code","2ea2a4ec":"code","5f6fd53b":"code","c76fe479":"code","6e67de50":"code","e4751b48":"code","c7e083ba":"code","8d2c4977":"code","2c8beb31":"code","b33023e0":"code","df7d3fa9":"code","a1e9503b":"code","4027b8e3":"code","48d11aef":"code","4fb72a3e":"code","54a0013b":"code","301cea8b":"code","e7d40428":"code","413147e3":"code","515cf2fa":"code","5c5cdd9b":"code","d8a8a4be":"markdown","3d492b6f":"markdown","5fb185c4":"markdown","8f43619c":"markdown","21362099":"markdown","09697a62":"markdown","fce79fcc":"markdown","a3a20c30":"markdown","2d77b208":"markdown","ce16f1b9":"markdown","f24e594e":"markdown","e8310eaa":"markdown","cd20112e":"markdown","94a7760f":"markdown","a260bc2f":"markdown","088adfbc":"markdown","f6c67f2a":"markdown","da74b12f":"markdown","c25cd03a":"markdown","98417bc7":"markdown","e00434d6":"markdown","36f5e62e":"markdown"},"source":{"2970f5fa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #count plot\n\nimport plotly.plotly as py #plotly library\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n\nimport os\nprint(os.listdir(\"..\/input\"))","e410557f":"data_train = pd.read_csv('..\/input\/train.csv')\n\ndata_test = pd.read_csv('..\/input\/test.csv')","19e964ee":"data_train.info()\n\nprint()\n\ndata_test.info()","d9f3efc3":"data_train.head()","7a11d594":"data_test.head()\n\n#As you see, there isn't \"Survived\" column in test data because it requested from us. ","7e7b3bab":"#Drop unneed columns and save\n\ndata_train.drop([\"Name\",\"Cabin\",\"Ticket\",\"Embarked\"],axis = 1,inplace = True)\n\ndata_test.drop([\"Name\",\"Cabin\",\"Ticket\",\"Embarked\"],axis = 1,inplace = True)","af7f9529":"#Split dataframe into 'survived' and 'not survived' so we will use these easily at data visualization\n\ndata_survived = data_train[data_train['Survived'] == 1].sort_values('Age') #dataframe that only has datas from survived peoples \n\ndata_not_survived = data_train[data_train['Survived'] == 0].sort_values('Age')\n\n#We will use this serie at line plot\n\nsurvived_age_number = data_survived.Age.value_counts(sort = False,dropna = True)#How many survived people are from which age\n\nnot_survived_age_number = data_not_survived.Age.value_counts(sort = False,dropna = True)\n\ndisplay(survived_age_number)\n\nnot_survived_age_number","d1abf67f":"#0.42,0.67 .. values at tail of serie and this is a wrong sort.Lets fix it.\n\na = survived_age_number.tail(4)#put values into a.\n\nsurvived_age_number.drop([0.42,0.67,0.83,0.92],inplace = True)#delete these values from tail of serie\n\nsurvived_age_number = pd.concat([a,survived_age_number],axis=0)#attach a to head of serie\n\nsurvived_age_number #Done","8485fe1c":"#trace1 is green line and trace2 is red line.\n\ntrace1 = go.Scatter(\n    x = survived_age_number.index,\n    y = survived_age_number,\n    opacity = 0.75,\n    name = \"Survived\",\n    mode = \"lines\",\n    marker=dict(color = 'rgba(0, 230, 0, 0.6)'))\n\ntrace2 = go.Scatter(\n    x = not_survived_age_number.index,\n    y = not_survived_age_number,\n    opacity=0.75,\n    name = \"Not Survived\",\n    mode = \"lines\",\n    marker=dict(color = 'rgba(230, 0, 0, 0.6)'))\n\ndata = [trace1,trace2]\nlayout = go.Layout(title = 'Age of Survived and not-Survived People in Titanic',\n                   xaxis=dict(title='Age'),\n                   yaxis=dict( title='Count'),)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","7a0cc7cd":"sns.countplot(data_survived.Pclass)\nplt.title('Passenger Class of Survived People')\nplt.show()","04f26750":"sns.countplot(data_not_survived.Pclass)\nplt.title('Passenger Class of Not Survived People')\nplt.show()","77017295":"sns.countplot(data_survived.Sex)\nplt.title('Gender of Survived People')\nplt.show()","2ea2a4ec":"sns.countplot(data_not_survived.Sex)\nplt.title('Gender of Not Survived People')\nplt.show()","5f6fd53b":"data_train.head()","c76fe479":"data_train_x = data_train #We should prepare x and y data for train classification\n\ndata_train_x.Sex = [1 if i == 'male' else 0 for i in data_train_x.Sex] #Transform strings to integers\n\ndata_train_y = data_train_x.Survived #y is our output  \n\ndata_train_x.drop(['PassengerId','Survived'], axis = 1,inplace = True)#drop passenger\u0131d and survived because they will not use while training\n\ndata_train_x.fillna(0.0,inplace = True) #fill NaN values with zero.We write '0.0' because we want to fill with float values \n\n#normalization :  i encountered 'to make conform to or reduce to a norm or standard' definition when i search normalization on google.\n#But if you ask simply definition i say that : 'to fit values between 0 and 1'\n#Normalization formula : (data - min)\/(max-min) \n\ndata_train_x = (data_train_x - np.min(data_train_x))\/(np.max(data_train_x) - np.min(data_train_x)).values","6e67de50":"#We repeat same process to test dataset\n\ndata_test.Sex = [1 if i == 'male' else 0 for i in data_test.Sex]\n\nPassengerId = data_test['PassengerId'].values\n\ndata_test.drop(['PassengerId'], axis = 1,inplace = True)\n\ndata_test.fillna(0.0,inplace = True)\n\ndata_test = (data_test - np.min(data_test))\/(np.max(data_test) - np.min(data_test)).values","e4751b48":"#Split train data in order to reserve %80 of train data for test .You don't confuse this test data is for check.\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(data_train_x,data_train_y,test_size = 0.2,random_state=1)\n\nscore_list = [] #to keep scores of algorithms","c7e083ba":"from sklearn.linear_model import LogisticRegression #importing logistic regression model\n\nlr = LogisticRegression()\n\nlr.fit(x_train,y_train)#fit or train data\n\nprint('Logistic Regression Score : ',lr.score(x_test,y_test))#Ratio of correct predictions\n\nscore_list.append(lr.score(x_test,y_test))","8d2c4977":"#this is our real prediction part\n\nlr.fit(data_train_x,data_train_y)\n\nlr_prediction = lr.predict(data_test)","2c8beb31":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\n\nknn.fit(x_train,y_train)\n\nprint('K-Nearest Neighbors Score : ',knn.score(x_test,y_test))\n\nscore_list.append(knn.score(x_test,y_test))","b33023e0":"knn.fit(data_train_x,data_train_y)\n\nknn_prediction = knn.predict(data_test)","df7d3fa9":"from sklearn.svm import SVC\n\nsvm = SVC(random_state = 1)\n\nsvm.fit(x_train,y_train)\n\nprint('Support Vector Machine Score : ',svm.score(x_test,y_test))\n\nscore_list.append(svm.score(x_test,y_test))","a1e9503b":"svm.fit(data_train_x,data_train_y)\n\nsvm_prediction = svm.predict(data_test)","4027b8e3":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(x_train,y_train)\n\nprint('Naive Bayes Score : ',nb.score(x_test,y_test))\n\nscore_list.append(nb.score(x_test,y_test))","48d11aef":"nb.fit(data_train_x,data_train_y)\n\nnb_prediction = nb.predict(data_test)","4fb72a3e":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\n\ndt.fit(x_train,y_train)\n\nprint('Decision Tree Score : ',dt.score(x_test,y_test))\n\nscore_list.append(dt.score(x_test,y_test))","54a0013b":"dt.fit(data_train_x,data_train_y)\n\ndt_prediction = dt.predict(data_test)","301cea8b":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 22,random_state = 40)\n\nrf.fit(x_train,y_train)\n\nprint('Random Forest Score : ',rf.score(x_test,y_test))\n\nscore_list.append(rf.score(x_test,y_test))","e7d40428":"rf.fit(data_train_x,data_train_y)\n\nrf_prediction = rf.predict(data_test)","413147e3":"pr_dict = {'Logistic Regression' : lr_prediction,'KNN' : knn_prediction,'SVM' : svm_prediction,\n           'Naive Bayes' : nb_prediction,'Decision Tree' : dt_prediction, 'Random Forest' : rf_prediction}\n\nall_predictions = pd.DataFrame(pr_dict)\n\nall_predictions","515cf2fa":"final_prediction = [] #final prediction list\n\n#i : range columns , j : range rows\n\nfor i in all_predictions.values:\n    sum_zero_score = 0 #summary of zero scores\n    \n    sum_one_score = 0 #summary of one scores\n    \n    for j in range(5):\n        if i[j]==0:\n            sum_zero_score += score_list[j]\n        else:\n            sum_one_score += score_list[j]\n    \n    if sum_zero_score >= sum_one_score:\n        final_prediction.append(0)\n    else:\n        final_prediction.append(1)\n    ","5c5cdd9b":"output = {'PassengerId' : PassengerId,'Survived' : final_prediction}\n\nsubmission = pd.DataFrame(output)\n\nsubmission.to_csv('output.csv', index = False)","d8a8a4be":"### Decision Tree <a id=\"17\"><\/a> <br>","3d492b6f":"### Random Forest <a id=\"18\"><\/a> <br>","5fb185c4":"## Data Visualization<a id=\"7\"><\/a> <br>\n\nOur datas are ready for data visualization.Let's make plots to better understand data.","8f43619c":"## A Quik View of Data <a id=\"5\"><\/a> <br>\n\nLet's look at data quickly to understand the content.\n","21362099":"# The End\n\n\nIf you see any mistake or lack please tell me with comment. Especially  mistakes about language . Thank you.  \ud83d\ude0a","09697a62":"## Cleaning Data <a id=\"6\"><\/a> <br>\n\nAs you see the datasets have NaN values(this means like empty),unneeded features and object datatype.We should fix them and clean data in order to use classification algorithms.Because the algorithms don't understand 'male' or 'female' .If we transform these to mathematical form (1 and 0) the algorithms work well.","fce79fcc":"# Introduction<a id=\"1\"><\/a> <br>\n\nHello everyone, this is my first competition's solution.The data is about titanic casualties.There are features about casualities in dataset.The aim is predict situation of people who don't known survive or not survive.\n\n* [Introduction](#1)\n    * [Import Libraries](#2)\n    * [Load Data](#3)\n* [Exploratory Data Analysis](#4)\n    * [A Quik View of data](#5)\n    * [Cleaning data for Data Visualisation](#6)\n    * [Data Visualization](#7)\n        * [Line Plot](#8)\n        * [Count Plots](#9)\n\n* [Classification](#10)\n    * [Preparing data for Classification](#11)\n    * [Implementing Classification Algorithms](#12)\n        * [Logistic Regression](#13)\n        * [K-Nearest Neighbors](#14)\n        * [Support Vector Machine](#15)\n        * [Naive Bayes](#16)\n        * [Decision Tree](#17)\n        * [Random Forest](#18)\n    * [Compare and Compound Classificaton Algorithms](#19)\n    * [Preparing Output](#20)\n","a3a20c30":"# Exploratory Data Analysis<a id=\"4\"><\/a> <br>","2d77b208":"# Classification<a id=\"10\"><\/a> <br>","ce16f1b9":"### Logistic Regression<a id=\"13\"><\/a> <br>","f24e594e":"**We have 3 dataset in working directory : **\n\n* train : To train classification models.We know output.\n* test : To test classification models and create a prediction output.\n* gender_submission : A sample of output format.","e8310eaa":"### Support Vector Machine<a id=\"15\"><\/a> <br>","cd20112e":"### Line Plot<a id=\"8\"><\/a> <br>","94a7760f":"### Naive Bayes<a id=\"16\"><\/a> <br>","a260bc2f":"## Preparing data for Classification<a id=\"11\"><\/a> <br>","088adfbc":"## Preparing Output<a id=\"20\"><\/a> <br>","f6c67f2a":"### Count Plots<a id=\"9\"><\/a> <br>","da74b12f":"## Compare and Compound Classificaton Algorithms<a id=\"19\"><\/a> <br>\n\nTo determine the best predict,we will compare all predictions and select final prediction by scores.","c25cd03a":"## Implementing Classification Algorithms<a id=\"12\"><\/a> <br>","98417bc7":"## Load  data<a id=\"3\"><\/a> <br>","e00434d6":"## Import Libraries<a id=\"2\"><\/a> <br>","36f5e62e":"### K-Nearest Neighbors<a id=\"14\"><\/a> <br>"}}