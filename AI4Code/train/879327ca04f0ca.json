{"cell_type":{"1d5fd64e":"code","d9963fa6":"code","c2769734":"code","89f09091":"code","e7486e3c":"code","537b6ea6":"code","62d6d9ab":"code","3bd4cbb5":"code","082dc00f":"code","8df05410":"code","a73ff7ad":"code","cf45a071":"code","0848b71f":"code","fcfb8a22":"code","6b8ea2a2":"code","c1682719":"code","e088f238":"code","2505a6da":"code","bebfcf81":"code","d327e78b":"code","2473f43e":"code","28f1f3a3":"code","eb013c10":"code","7352ab04":"code","1d6393e1":"code","a0c23afa":"code","6adcd668":"code","2388e031":"code","48db6d8f":"code","bcd60bdf":"code","1da6af5e":"code","475d21ed":"code","795d8fd4":"code","4633222b":"code","19591236":"code","aa2d7de3":"code","2fbfd10b":"code","5479c836":"code","44cde4b8":"code","a9034ee7":"code","baa30c9e":"code","351dfcc1":"code","f071d202":"code","7fd14464":"code","6323f7a2":"code","07f3384f":"code","5f313c47":"code","5b154f9c":"code","bdb4253e":"code","98ee1c33":"code","f79fecc1":"code","acef6cce":"code","2e6566c1":"code","425453f3":"code","e6c77ab9":"code","d5eb2b61":"code","76b11881":"code","64ab311c":"code","9dd51e2c":"markdown","201d9fd4":"markdown","36c83a34":"markdown","5b13daf7":"markdown","2785f07b":"markdown","24a6d702":"markdown","fdbeecf2":"markdown","b31268ba":"markdown","5d8840bf":"markdown","b23fdfbb":"markdown","96638992":"markdown","fb256704":"markdown","851ad70a":"markdown","9f1ab1be":"markdown","85b0a54f":"markdown","944ecbc6":"markdown","d65ee0f1":"markdown","bff3328e":"markdown","693fb22d":"markdown","fe9d9807":"markdown","be262b82":"markdown","96d66197":"markdown","343027e2":"markdown","67e43494":"markdown","348e1faa":"markdown","ed2a63e0":"markdown","17ffa942":"markdown","3644b7d6":"markdown","16e83c83":"markdown","c4a80855":"markdown","c0fed52e":"markdown","23bf54cf":"markdown","5fad47e3":"markdown","269482e3":"markdown","35356e23":"markdown","989b1123":"markdown","e50188a2":"markdown","909f3806":"markdown","99d0789b":"markdown","3ca6a80e":"markdown","760008fe":"markdown","47fe3b44":"markdown","33befcf3":"markdown","642391a1":"markdown","135efe26":"markdown","3f58ebb6":"markdown","66190f07":"markdown","c968be50":"markdown","caaf34d0":"markdown","7e2c766e":"markdown","a3196750":"markdown","4849a568":"markdown","29fe938c":"markdown","212b3134":"markdown"},"source":{"1d5fd64e":"import tensorflow as tf\nprint(tf.__version__)","d9963fa6":"from sklearn.datasets import make_circles\n\n# Make 1000 examples\nn_samples = 1000\n\n# Create circles\nX, y = make_circles(n_samples, \n                    noise=0.03, \n                    random_state=42)","c2769734":"# Check out the features\nX","89f09091":"# See the first 10 labels\ny[:10]","e7486e3c":"# Make dataframe of features and labels\nimport pandas as pd\ncircles = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"label\":y})\ncircles.head()","537b6ea6":"# Check out the different labels\ncircles.label.value_counts()","62d6d9ab":"# Visualize with a plot\nimport matplotlib.pyplot as plt\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu);","3bd4cbb5":"# Check the shapes of our features and labels\nX.shape, y.shape","082dc00f":"# Check how many samples we have\nlen(X), len(y)","8df05410":"# View the first example of features and labels\nX[0], y[0]","a73ff7ad":"# Set random seed\ntf.random.set_seed(42)\n\n# 1. Create the model using the Sequential API\nmodel_1 = tf.keras.Sequential([\n  tf.keras.layers.Dense(1)\n])\n\n# 2. Compile the model\nmodel_1.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n                optimizer=tf.keras.optimizers.SGD(),\n                metrics=['accuracy'])\n\n# 3. Fit the model\nmodel_1.fit(X, y, epochs=5)","cf45a071":"# Train our model for longer (more chances to look at the data)\nmodel_1.fit(X, y, epochs=200, verbose=0) # set verbose=0 to remove training updates\nmodel_1.evaluate(X, y)","0848b71f":"# Set random seed\ntf.random.set_seed(42)\n\n# 1. Create the model (same as model_1 but with an extra layer)\nmodel_2 = tf.keras.Sequential([\n  tf.keras.layers.Dense(1), # add an extra layer\n  tf.keras.layers.Dense(1) \n])\n\n# 2. Compile the model\nmodel_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                optimizer=tf.keras.optimizers.SGD(),\n                metrics=['accuracy'])\n\n# 3. Fit the model\nmodel_2.fit(X, y, epochs=100, verbose=0) # set verbose=0 to make the output print less","fcfb8a22":"# Evaluate the model\nmodel_2.evaluate(X, y)","6b8ea2a2":"# Set random seed\ntf.random.set_seed(42)\n\n# 1. Create the model (this time 3 layers)\nmodel_3 = tf.keras.Sequential([\n  tf.keras.layers.Dense(100), # add 100 dense neurons\n  tf.keras.layers.Dense(10), # add another layer with 10 neurons\n  tf.keras.layers.Dense(1)\n])\n\n# 2. Compile the model\nmodel_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                optimizer=tf.keras.optimizers.Adam(), # use Adam instead of SGD\n                metrics=['accuracy'])\n\n# 3. Fit the model\nmodel_3.fit(X, y, epochs=100, verbose=0) # fit for 100 passes of the data","c1682719":"# Evaluate the model\nmodel_3.evaluate(X, y)","e088f238":"import numpy as np\n\ndef plot_decision_boundary(model, X, y):\n  \"\"\"\n  Plots the decision boundary created by a model predicting on X.\n  This function has been adapted from two phenomenal resources:\n   1. CS231n - https:\/\/cs231n.github.io\/neural-networks-case-study\/\n   2. Made with ML basics - https:\/\/github.com\/GokuMohandas\/MadeWithML\/blob\/main\/notebooks\/08_Neural_Networks.ipynb\n  \"\"\"\n  # Define the axis boundaries of the plot and create a meshgrid\n  x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n  y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                       np.linspace(y_min, y_max, 100))\n  \n  # Create X values (we're going to predict on all of these)\n  x_in = np.c_[xx.ravel(), yy.ravel()] # stack 2D arrays together: https:\/\/numpy.org\/devdocs\/reference\/generated\/numpy.c_.html\n  \n  # Make predictions using the trained model\n  y_pred = model.predict(x_in)\n\n  # Check for multi-class\n  if len(y_pred[0]) > 1:\n    print(\"doing multiclass classification...\")\n    # We have to reshape our predictions to get them ready for plotting\n    y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n  else:\n    print(\"doing binary classifcation...\")\n    y_pred = np.round(y_pred).reshape(xx.shape)\n  \n  # Plot decision boundary\n  plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n  plt.xlim(xx.min(), xx.max())\n  plt.ylim(yy.min(), yy.max())","2505a6da":"# Check out the predictions our model is making \nplot_decision_boundary(model_3, X, y)","bebfcf81":"# Set random seed\ntf.random.set_seed(42)\n\n# Create some regression data\nX_regression = np.arange(0, 1000, 5)\ny_regression = np.arange(100, 1100, 5)\n\n# Split it into training and test sets\nX_reg_train = X_regression[:150]\nX_reg_test = X_regression[150:]\ny_reg_train = y_regression[:150]\ny_reg_test = y_regression[150:]\n\n# Recreate the model\nmodel_3 = tf.keras.Sequential([\n  tf.keras.layers.Dense(100),\n  tf.keras.layers.Dense(10),\n  tf.keras.layers.Dense(1)\n])\n\n# Change the loss and metrics of our compiled model\nmodel_3.compile(loss=tf.keras.losses.mae, # change the loss function to be regression-specific\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=['mae']) # change the metric to be regression-specific\n\n# Fit our model to the data\nmodel_3.fit(X_reg_train, y_reg_train, epochs=100)","d327e78b":"# Make predictions with our trained model\ny_reg_preds = model_3.predict(y_reg_test)\n\n# Plot the model's predictions against our regression data\nplt.figure(figsize=(10, 7))\nplt.scatter(X_reg_train, y_reg_train, c='b', label='Training data')\nplt.scatter(X_reg_test, y_reg_test, c='g', label='Testing data')\nplt.scatter(X_reg_test, y_reg_preds.squeeze(), c='r', label='Predictions')\nplt.legend();","2473f43e":"# Set the random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_4 = tf.keras.Sequential([\n  tf.keras.layers.Dense(1, activation=tf.keras.activations.linear), # 1 hidden layer with linear activation\n  tf.keras.layers.Dense(1) # output layer\n])\n\n# Compile the model\nmodel_4.compile(loss=tf.keras.losses.binary_crossentropy,\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model_4.fit(X, y, epochs=100)","28f1f3a3":"# Check out our data\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu);","eb013c10":"# Check the deicison boundary (blue is blue class, yellow is the crossover, red is red class)\nplot_decision_boundary(model_4, X, y)","7352ab04":"# Set random seed\ntf.random.set_seed(42)\n\n# Create a model with a non-linear activation\nmodel_5 = tf.keras.Sequential([\n  tf.keras.layers.Dense(1, activation=tf.keras.activations.relu), # can also do activation='relu'\n  tf.keras.layers.Dense(1) # output layer \n])\n\n# Compile the model\nmodel_5.compile(loss=tf.keras.losses.binary_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model_5.fit(X, y, epochs=100)","1d6393e1":"# Set random seed\ntf.random.set_seed(42)\n\n# Create a model\nmodel_6 = tf.keras.Sequential([\n  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, 4 neurons, ReLU activation\n  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, 4 neurons, ReLU activation\n  tf.keras.layers.Dense(1) # ouput layer\n])\n\n# Compile the model\nmodel_6.compile(loss=tf.keras.losses.binary_crossentropy,\n                optimizer=tf.keras.optimizers.Adam(lr=0.001), # Adam's default learning rate is 0.001\n                metrics=['accuracy'])\n\n# Fit the model\nhistory = model_6.fit(X, y, epochs=100)","a0c23afa":"# Evaluate the model\nmodel_6.evaluate(X, y)","6adcd668":"# Check out the predictions using 2 hidden layers\nplot_decision_boundary(model_6, X, y)","2388e031":"# Set random seed\ntf.random.set_seed(42)\n\n# Create a model\nmodel_7 = tf.keras.Sequential([\n  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation\n])\n\n# Compile the model\nmodel_7.compile(loss=tf.keras.losses.binary_crossentropy,\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=['accuracy'])\n\n# Fit the model\nhistory = model_7.fit(X, y, epochs=100, verbose=0)\n\n# Evaluate our model\nmodel_7.evaluate(X, y)","48db6d8f":"# View the predictions of the model with relu and sigmoid activations\nplot_decision_boundary(model_7, X, y)","bcd60bdf":"# Create a toy tensor (similar to the data we pass into our model)\nA = tf.cast(tf.range(-10, 10), tf.float32)\nA","1da6af5e":"# Visualize our toy tensor\nplt.plot(A);","475d21ed":"# Sigmoid - https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/activations\/sigmoid\ndef sigmoid(x):\n  return 1 \/ (1 + tf.exp(-x))\n\n# Use the sigmoid function on our tensor\nsigmoid(A)","795d8fd4":"# Plot sigmoid modified tensor\nplt.plot(sigmoid(A));","4633222b":"# ReLU - https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/activations\/relu\ndef relu(x):\n  return tf.maximum(0, x)\n\n# Pass toy tensor through ReLU function\nrelu(A)","19591236":"# Plot ReLU-modified tensor\nplt.plot(relu(A));","aa2d7de3":"# Linear - https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/activations\/linear (returns input non-modified...)\ntf.keras.activations.linear(A)","2fbfd10b":"# Does the linear activation change anything?\nA == tf.keras.activations.linear(A)","5479c836":"# How many examples are in the whole dataset?\nlen(X)","44cde4b8":"\n# Split data into train and test sets\nX_train, y_train = X[:800], y[:800] # 80% of the data for the training set\nX_test, y_test = X[800:], y[800:] # 20% of the data for the test set\n\n# Check the shapes of the data\nX_train.shape, X_test.shape # 800 examples in the training set, 200 examples in the test set","a9034ee7":"# Set random seed\ntf.random.set_seed(42)\n\n# Create the model (same as model_7)\nmodel_8 = tf.keras.Sequential([\n  tf.keras.layers.Dense(4, activation=\"relu\"), # hidden layer 1, using \"relu\" for activation (same as tf.keras.activations.relu)\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(1, activation=\"sigmoid\") # output layer, using 'sigmoid' for the output\n])\n\n# Compile the model\nmodel_8.compile(loss=tf.keras.losses.binary_crossentropy,\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), # increase learning rate from 0.001 to 0.01 for faster learning\n                metrics=['accuracy'])\n\n# Fit the model\nhistory = model_8.fit(X_train, y_train, epochs=25)","baa30c9e":"# Evaluate our model on the test set\nloss, accuracy = model_8.evaluate(X_test, y_test)\nprint(f\"Model loss on the test set: {loss}\")\nprint(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")","351dfcc1":"# Plot the decision boundaries for the training and test sets\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"Train\")\nplot_decision_boundary(model_8, X=X_train, y=y_train)\nplt.subplot(1, 2, 2)\nplt.title(\"Test\")\nplot_decision_boundary(model_8, X=X_test, y=y_test)\nplt.show()","f071d202":"# You can access the information in the history variable using the .history attribute\npd.DataFrame(history.history)","7fd14464":"# Plot the loss curves\npd.DataFrame(history.history).plot()\nplt.title(\"Model_8 training curves\")","6323f7a2":"# Set random seed\ntf.random.set_seed(42)\n\n# Create a model (same as model_8)\nmodel_9 = tf.keras.Sequential([\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\n# Compile the model\nmodel_9.compile(loss=\"binary_crossentropy\", # we can use strings here too\n              optimizer=\"Adam\", # same as tf.keras.optimizers.Adam() with default settings\n              metrics=[\"accuracy\"]) \n\n# Create a learning rate scheduler callback\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch\/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch\/20) every epoch\n\n# Fit the model (passing the lr_scheduler callback)\nhistory = model_9.fit(X_train, \n                      y_train, \n                      epochs=100,\n                      callbacks=[lr_scheduler])","07f3384f":"# Checkout the history\npd.DataFrame(history.history).plot(figsize=(10,7), xlabel=\"epochs\");","5f313c47":"# Plot the learning rate versus the loss\nlrs = 1e-4 * (10 ** (np.arange(100)\/20))\nplt.figure(figsize=(10, 7))\nplt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\nplt.xlabel(\"Learning Rate\")\nplt.ylabel(\"Loss\")\nplt.title(\"Learning rate vs. loss\");","5b154f9c":"\n# Example of other typical learning rate values\n10**0, 10**-1, 10**-2, 10**-3, 1e-4","bdb4253e":"# Set the random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_10 = tf.keras.Sequential([\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\n# Compile the model with the ideal learning rate\nmodel_10.compile(loss=\"binary_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.02), # to adjust the learning rate, you need to use tf.keras.optimizers.Adam (not \"adam\")\n                metrics=[\"accuracy\"])\n\n# Fit the model for 20 epochs (5 less than before)\nhistory = model_10.fit(X_train, y_train, epochs=20)","98ee1c33":"# Evaluate model on the test dataset\nmodel_10.evaluate(X_test, y_test)","f79fecc1":"# Plot the decision boundaries for the training and test sets\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"Train\")\nplot_decision_boundary(model_10, X=X_train, y=y_train)\nplt.subplot(1, 2, 2)\nplt.title(\"Test\")\nplot_decision_boundary(model_10, X=X_test, y=y_test)\nplt.show()","acef6cce":"# Check the accuracy of our model\nloss, accuracy = model_10.evaluate(X_test, y_test)\nprint(f\"Model loss on test set: {loss}\")\nprint(f\"Model accuracy on test set: {(accuracy*100):.2f}%\")","2e6566c1":"# Create a confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n# Make predictions\ny_preds = model_10.predict(X_test)\n\n# Create confusion matrix\nconfusion_matrix(y_test, y_preds)","425453f3":"# View the first 10 predictions\ny_preds[:10]","e6c77ab9":"# View the first 10 test labels\ny_test[:10]","d5eb2b61":"# Convert prediction probabilities to binary format and view the first 10\ntf.round(y_preds)[:10]","76b11881":"# Create a confusion matrix\nconfusion_matrix(y_test, tf.round(y_preds))","64ab311c":"# Note: The following confusion matrix code is a remix of Scikit-Learn's \n# plot_confusion_matrix function - https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.plot_confusion_matrix.html\n# and Made with ML's introductory notebook - https:\/\/github.com\/GokuMohandas\/MadeWithML\/blob\/main\/notebooks\/08_Neural_Networks.ipynb \nimport itertools\nfigsize = (10, 10)\n\n# Create the confusion matrix\ncm = confusion_matrix(y_test, tf.round(y_preds))\ncm_norm = cm.astype(\"float\") \/ cm.sum(axis=1)[:, np.newaxis] # normalize it\nn_classes = cm.shape[0]\n\n# Let's prettify it\nfig, ax = plt.subplots(figsize=figsize)\n# Create a matrix plot\ncax = ax.matshow(cm, cmap=plt.cm.Blues) # https:\/\/matplotlib.org\/3.2.0\/api\/_as_gen\/matplotlib.axes.Axes.matshow.html\nfig.colorbar(cax)\n\n# Create classes\nclasses = False\n\nif classes:\n  labels = classes\nelse:\n  labels = np.arange(cm.shape[0])\n\n# Label the axes\nax.set(title=\"Confusion Matrix\",\n       xlabel=\"Predicted label\",\n       ylabel=\"True label\",\n       xticks=np.arange(n_classes),\n       yticks=np.arange(n_classes),\n       xticklabels=labels,\n       yticklabels=labels)\n\n# Set x-axis labels to bottom\nax.xaxis.set_label_position(\"bottom\")\nax.xaxis.tick_bottom()\n\n# Adjust label size\nax.xaxis.label.set_size(20)\nax.yaxis.label.set_size(20)\nax.title.set_size(20)\n\n# Set threshold for different colors\nthreshold = (cm.max() + cm.min()) \/ 2.\n\n# Plot the text on each cell\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n  plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n           horizontalalignment=\"center\",\n           color=\"white\" if cm[i, j] > threshold else \"black\",\n           size=15)","9dd51e2c":"It looks like we need to get our predictions into the binary format (0 or 1).\n\nBut you might be wondering, what format are they currently in?\n\nIn their current format (9.8526537e-01), they're in a form called **prediction probabilities**.\n\nYou'll see this often with the outputs of neural networks. Often they won't be exact values but more a probability of how likely they are to be one value or another.\n\nSo one of the steps you'll often see after making predicitons with a neural network is converting the prediction probabilities into labels.\n\nIn our case, since our ground truth labels (y_test) are binary (0 or 1), we can convert the prediction probabilities using to their binary form using tf.round().","201d9fd4":"How does the ReLU-modified tensor look?","36c83a34":"What gives?\n\nIt seems like our model is the same as the one in the [TensorFlow Playground](https:\/\/playground.tensorflow.org\/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,4&seed=0.93799&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&regularizationRate_hide=true&batchSize_hide=true) but model it's still drawing straight lines...\n\nIdeally, the yellow lines go on the inside of the red circle and the blue circle.\n\nOkay, okay, let's model this circle once and for all.\n\nOne more model (I promise... actually, I'm going to have to break that promise... we'll be building plenty more models).\n\nThis time we'll change the activation function on our output layer too. Remember the architecture of a classification model? For binary classification, the output layer activation is usually the [Sigmoid activation function.](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/math\/sigmoid)","5b13daf7":"Now we've got a function to plot our model's decision boundary (the cut off point its making between red and blue dots), let's try it out.","2785f07b":"\nOkay, our model performs a little worse than guessing.\n\nLet's remind ourselves what our data looks like.","24a6d702":"A classification problem involves predicting whether something is one thing or another.\n\nFor example, you might want to:\n\n* Predict whether or not someone has heart disease based on their health parameters. This is called binary classification since there are only two options.\n* Decide whether a photo of is of food, a person or a dog. This is called multi-class classification since there are more than two options.\n* Predict what categories should be assigned to a Wikipedia article. This is called multi-label classification since a single article could have more than one category assigned.\n\nIn this notebook, we're going to work through a number of different classification problems with TensorFlow. In other words, taking a set of inputs and predicting what class those set of inputs belong to.","fdbeecf2":"A straight (linear) line!\n\nNice, now let's recreate the sigmoid function and see what it does to our data. You can also find a pre-built sigmoid function at tf.keras.activations.sigmoid.","b31268ba":"Beautiful. This is the ideal plot we'd be looking for when dealing with a classification problem, loss going down, accuracy going up.\n\n> \ud83d\udd11 Note: For many problems, the loss function going down means the model is improving (the predictions it's making are getting closer to the ground truth labels).\n\n# **Finding the best learning rate**\nAside from the architecture itself (the layers, number of neurons, activations, etc), the most important hyperparameter you can tune for your neural network models is the **learning rate**.\n\nIn model_8 you saw we lowered the Adam optimizer's learning rate from the default of 0.001 (default) to 0.01.\n\nAnd you might be wondering why we did this.\n\nPut it this way, it was a lucky guess.\n\nI just decided to try a lower learning rate and see how the model went.\n\nNow you might be thinking, \"Seriously? You can do that?\"\n\nAnd the answer is yes. You can change any of the hyperparamaters of your neural networks.\n\nWith practice, you'll start to see what kind of hyperparameters work and what don't.\n\nThat's an important thing to understand about machine learning and deep learning in general. It's very experimental. You build a model and evaluate it, build a model and evaluate it.\n\nThat being said, I want to introduce you a trick which will help you find the optimal learning rate (at least to begin training with) for your models going forward.\n\nTo do so, we're going to use the following:\n\n* A learning rate **callback**.\n    * You can think of a callback as an extra piece of functionality you can add to your model while its training.\n* Another model (we could use the same ones as above, we we're practicing building models here).\n* A modified loss curves plot.\n\nWe'll go through each with code, then explain what's going on.\n\n> \ud83d\udd11 Note: The default hyperparameters of many neural network building blocks in TensorFlow are setup in a way which usually work right out of the box (e.g. the Adam optimizer's default settings can usually get good results on many datasets). So it's a good idea to try the defaults first, then adjust as needed.","5d8840bf":"Wonderful, now we've created some data, let's look at the features (X) and labels (y).","b23fdfbb":"So we've got as many X values as we do y values, that makes sense.\n\nLet's check out one example of each.","96638992":"Alright, looks like we're dealing with a **binary classification** problem. It's binary because there are only two labels (0 or 1).\n\nIf there were more label options (e.g. 0, 1, 2, 3 or 4), it would be called **multiclass classification**.\n\nLet's take our visualization a step further and plot our data.","fb256704":"# **Typical architecture of a classification neural network**\nThe word typical is on purpose.\n\nBecause the architecture of a classification neural network can widely vary depending on the problem you're working on.\n\nHowever, there are some fundamentals all deep neural networks contain:\n\n* An input layer.\n* Some hidden layers.\n* An output layer.\n\nMuch of the rest is up to the data analyst creating the model.\n\nThe following are some standard values you'll often use in your classification neural networks\n\n![image.png](attachment:6e45c0c8-09bb-47e2-b987-a66cb8c41a3d.png)\n\nTable 1: Typical architecture of a classification network. Source: Adapted from page 295 of Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aur\u00e9lien G\u00e9ron\n\nDon't worry if not much of the above makes sense right now, we'll get plenty of experience as we go through this notebook.","851ad70a":"Even after 200 passes of the data, it's still performing as if it's guessing.\n\nWhat if we added an extra layer and trained for a little longer?","9f1ab1be":"Okay, so it makes sense now the model doesn't really learn anything when using only linear activation functions, because the linear activation function doesn't change our input data in anyway.\n\nWhere as, with our non-linear functions, our data gets manipulated. A neural network uses these kind of transformations at a large scale to figure draw patterns between its inputs and outputs.\n\nNow rather than dive into the guts of neural networks, we're going to keep coding applying what we've learned to different problems but if you want a more in-depth look at what's going on behind the scenes, check out the Extra Curriculum section below.\n\n> \ud83d\udcd6 Resource: For more on activation functions, check out the [machine learning cheatsheet page](https:\/\/ml-cheatsheet.readthedocs.io\/en\/latest\/activation_functions.html#) on them.","85b0a54f":"Ahh, it seems our predictions aren't in the format they need to be.\n\nLet's check them out.","944ecbc6":"And let's see how our model is making predictions on it.","d65ee0f1":"Okay, we've seen some of our data and labels, how about we move towards visualizing?\n\n> \ud83d\udd11 Note: One important step of starting any kind of machine learning project is to become one with the data. And one of the best ways to do this is to visualize the data you're working with as much as possible. The data explorer's motto is \"visualize, visualize, visualize\".\n\nWe'll start with a DataFrame.","bff3328e":"Okay, the predictions aren't perfect (if the predictions were perfect, the red would line up with the green), but they look better than complete guessing.\n\nSo this means our model must be learning something...\n\nThere must be something we're missing out on for our classification problem.\n# **The missing piece: Non-linearity**\nOkay, so we saw our neural network can model straight lines (with ability a little bit better than guessing).\n\nWhat about non-straight (non-linear) lines?\n\nIf we're going to model our classification data (the red and clue circles), we're going to need some non-linear lines.\n\n> \ud83d\udd28 Practice: Before we get to the next steps, I'd encourage you to play around with the TensorFlow Playground (check out what the data has in common with our own classification data) for 10-minutes. In particular the tab which says \"activation\". Once you're done, come back.\n\nDid you try out the activation options? If so, what did you find?\n\nIf you didn't, don't worry, let's see it in code.\n\nWe're going to replicate the neural network you can see at this link: [TensorFlow Playground](https:\/\/playground.tensorflow.org\/#activation=linear&batchSize=1&dataset=circle&regDataset=reg-plane&learningRate=0.01&regularizationRate=0&noise=0&networkShape=1&seed=0.09561&showTestData=false&discretize=false&percTrainData=70&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularizationRate_hide=true&discretize_hide=true&regularization_hide=true&dataset_hide=true&noise_hide=true&batchSize_hide=true).\n\nThe main change we'll add to models we've built before is the use of the activation keyword.","693fb22d":"Hmm... still not learning...\n\nWhat we if increased the number of neurons and layers?\n\nSay, 2 hidden layers, with ReLU, pronounced \"rel-u\", (short for rectified linear unit), activation on the first one, and 4 neurons each?\n\nTo see this network in action, check out the [TensorFlow Playground demo](https:\/\/playground.tensorflow.org\/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.001&regularizationRate=0&noise=0&networkShape=4,4&seed=0.93799&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&regularizationRate_hide=true&batchSize_hide=true&dataset_hide=true).\n\nLet's try.","fe9d9807":"And how does it look?","be262b82":"A non-straight (non-linear) line!\n\nOkay, how about the [ReLU function](https:\/\/machinelearningmastery.com\/rectified-linear-activation-function-for-deep-learning-neural-networks\/#:~:text=The%20rectified%20linear%20activation%20function,otherwise%2C%20it%20will%20output%20zero.) (ReLU turns all negatives to 0 and positive numbers stay the same)?","96d66197":"Nice! With a little higher learning rate (0.02 instead of 0.01) we reach a higher accuracy than model_8 in less epochs (20 instead of 25).\n\n> \ud83d\udee0 Practice: Now you've seen an example of what can happen when you change the learning rate, try changing the learning rate value in the [TensorFlow Playground](https:\/\/playground.tensorflow.org\/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.03154&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&regularizationRate_hide=true&problem_hide=true) and see what happens. What happens if you increase it? What happens if you decrease it?","343027e2":"Hmm, it looks like our inputs are unmodified...","67e43494":"# **Creating data to view and fit**\nWe could start by importing a classification dataset but let's practice making some of our own classification data.\n\n> \ud83d\udd11 Note: It's a common practice to get you and model you build working on a toy (or simple) dataset before moving to your actual problem. Treat it as a rehersal experiment before the actual experiment(s).\n\nSince classification is predicting whether something is one thing or another, let's make some data to reflect that.\n\nTo do so, we'll use Scikit-Learn's make_circles() function.","348e1faa":"Now our model has finished training, let's have a look at the training history.","ed2a63e0":"Looking at the accuracy metric, our model performs poorly (50% accuracy on a binary classification problem is the equivalent of guessing), but what if we trained it for longer?","17ffa942":"Okay, it seems like our model is learning something (the mae value trends down with each epoch), let's plot its predictions","3644b7d6":"Still!\n\nWe've pulled out a few tricks but our model isn't even doing better than guessing.\n\nLet's make some visualizations to see what's happening.\n\n> \ud83d\udd11 Note: Whenever your model is performing strangely or there's something going on with your data you're not quite sure of, remember these three words: **visualize, visualize, visualize**. Inspect your data, inspect your model, inpsect your model's predictions.\n\nTo visualize our model's predictions we're going to create a function plot_decision_boundary() which:\n\n* Takes in a trained model, features (X) and labels (y).\n* Creates a meshgrid of the different X values.\n* Makes predictions across the meshgrid.\n* Plots the predictions as well as a line between the different zones (where each unique class falls).\n\nIf this sounds confusing, let's see it in code and then see the output.\n\n> \ud83d\udd11 Note: If you're ever unsure of what a function does, try unraveling it and writing it line by line for yourself to see what it does. Break it into small parts and see what each part outputs.","16e83c83":"\nHow about a confusion matrix?\n\n\n\nAnatomy of a confusion matrix (what we're going to be creating). Correct predictions appear down the diagonal (from top left to bottom right).\n\nWe can make a confusion matrix using Scikit-Learn's confusion_matrix method.","c4a80855":"Nice! From the plot, can you guess what kind of model we might want to build?\n\nHow about we try and build one to classify blue or red dots? As in, a model which is able to distinguish blue from red dots.\n\n> \ud83d\udee0 Practice: Before pushing forward, you might want to spend 10 minutes playing around with the TensorFlow Playground. Try adjusting the different hyperparameters you see and click play to see a neural network train. I think you'll find the data very similar to what we've just created.\n\n# **Input and output shapes**\nOne of the most common issues you'll run into when building neural networks is shape mismatches.\n\nMore specifically, the shape of the input data and the shape of the output data.\n\nIn our case, we want to input X and get our model to predict y.\n\nSo let's check out the shapes of X and y.","c0fed52e":"Alright, we can see the highest numbers are down the diagonal (from top left to bottom right) so this a good sign, but the rest of the matrix doesn't really tell us much.\n\nHow about we make a function to make our confusion matrix a little more visual?","23bf54cf":"As you you see the learning rate exponentially increases as the number of epochs increases.\n\nAnd you can see the model's accuracy goes up (and loss goes down) at a specific point when the learning rate slowly increases.\n\nTo figure out where this infliction point is, we can plot the loss versus the log-scale learning rate.","5fad47e3":"# **Evaluating and improving our classification model**\nIf you answered the question above, you might've picked up what we've been doing wrong.\n\nWe've been evaluating our model on the same data it was trained on.\n\nA better approach would be to split our data into training, validation (optional) and test sets.\n\nOnce we've done that, we'll train our model on the training set (let it find patterns in the data) and then see how well it learned the patterns by using it to predict values on the test set.\n\nLet's do it.","269482e3":"Well, it looks like we're getting a straight (linear) line prediction again.\n\nBut our data is non-linear (not a straight line)...\n\nWhat we're going to have to do is add some non-linearity to our model.\n\nTo do so, we'll use the activation parameter in on of our layers.","35356e23":"Great, now we've got training and test sets, let's model the training data and evaluate what our model has learned on the test set.","989b1123":"Still not even as good as guessing (~50% accuracy)... hmm...?\n\nLet's remind ourselves of a couple more ways we can use to improve our models.\n\n# **Improving a model**\nTo improve our model, we can alter almost every part of the 3 steps we went through before.\n\n1. **Creating a model** - here you might want to add more layers, increase the number of hidden units (also called neurons) within each layer, change the activation functions of each layer.\n1. **Compiling a model** - you might want to choose a different optimization function (such as the Adam optimizer, which is usually pretty good for many problems) or perhaps change the learning rate of the optimization function.\n1. **Fitting a model** - perhaps you could fit a model for more epochs (leave it training for longer).\n\n![image.png](attachment:28c1b2a1-cb8f-4ebb-a9ae-ef38904971ca.png)\n\nThere are many different ways to potentially improve a neural network. Some of the most common include: increasing the number of layers (making the network deeper), increasing the number of hidden units (making the network wider) and changing the learning rate. Because these values are all human-changeable, they're referred to as hyperparameters) and the practice of trying to find the best hyperparameters is referred to as hyperparameter tuning.\n\nHow about we try adding more neurons, an extra layer and our friend the Adam optimizer?\n\nSurely doing this will result in predictions better than guessing...","e50188a2":"Now we've estimated the ideal learning rate (we'll use 0.02) for our model, let's refit it","909f3806":"What about our test labels?","99d0789b":"Another non-straight line!\n\nWell, how about TensorFlow's [linear activation function](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/activations\/linear)?","3ca6a80e":"Looks like our model is trying to draw a straight line through the data.\n\nWhat's wrong with doing this?\n\nThe main issue is our data isn't separable by a straight line.\n\nIn a regression problem, our model might work. In fact, let's try it.","760008fe":"Check that out! How cool. With a few tweaks, our model is now predicting the blue and red circles almost perfectly.\n\n# **Plot the loss curves**\nLooking at the plots above, we can see the outputs of our model are very good.\n\nBut how did our model go whilst it was learning?\n\nAs in, how did the performance change everytime the model had a chance to look at the data (once every epoch)?\n\nTo figure this out, we can check the **loss curves** (also referred to as the **learning curves**).\n\nYou might've seen we've been using the variable history when calling the fit() function on a model (fit() returns a History object).\n\nThis is where we'll get the information for how our model is performing as it learns.\n\nLet's see how we might use it.","47fe3b44":"100% accuracy? Nice!\n\nNow, when we started to create model_8 we said it was going to be the same as model_7 but you might've found that to be a little lie.\n\nThat's because we changed a few things:\n\n* The activation parameter - We used strings (\"relu\" & \"sigmoid\") instead of using library paths (tf.keras.activations.relu), in TensorFlow, they both offer the same functionality.\n* The learning_rate (also lr) parameter - We increased the learning rate parameter in the Adam optimizer to 0.01 instead of 0.001 (an increase of 10x).\n    * You can think of the learning rate as how quickly a model learns. The higher the learning rate, the faster the model's capacity to learn, however, there's such a thing as a too high learning rate, where a model tries to learn too fast and doesn't learn anything. We'll see a trick to find the ideal learning rate soon.\n* The number of epochs - We lowered the number of epochs (using the epochs parameter) from 100 to 25 but our model still got an incredible result on both the training and test sets.\n    * One of the reasons our model performed well in even less epochs (remember a single epoch is the model trying to learn patterns in the data by looking at it once, so 25 epochs means the model gets 25 chances) than before is because we increased the learning rate.\n\nWe know our model is performing well based on the evaluation metrics but let's see how it performs visually.","33befcf3":"And as we can see, almost perfect again.\n\nThese are the kind of experiments you'll be running often when building your own models.\n\nStart with default settings and see how they perform on your data.\n\nAnd if they don't perform as well as you'd like, improve them.\n\nLet's look at a few more ways to evaluate our classification models.\n\n# **More classification evaluation methods**\nAlongside the visualizations we've been making, there are a number of different evaluation metrics we can use to evaluate our classification models.\n\n![image.png](attachment:acf03b84-7af0-4c54-a1ad-4147fc40f650.png)\n\n> \ud83d\udd11 Note: Every classification problem will require different kinds of evaluation methods. But you should be familiar with at least the ones above.\n\nLet's start with accuracy.\n\nBecause we passed [\"accuracy\"] to the metrics parameter when we compiled our model, calling evaluate() on it will return the loss as well as accuracy.","642391a1":"Nice! It looks like our model is almost perfectly (apart from a few examples) separating the two circles.\n\n> \ud83e\udd14 Question: What's wrong with the predictions we've made? Are we really evaluating our model correctly here? Hint: what data did the model learn on and what did we predict on?\n\nBefore we answer that, it's important to recognize what we've just covered.\n\n> \ud83d\udd11 Note: The combination of linear (straight lines) and non-linear (non-straight lines) functions is one of the key fundamentals of neural networks.\n\nThink of it like this:\n\nIf I gave you an unlimited amount of straight lines and non-straight lines, what kind of patterns could you draw?\n\nThat's essentially what neural networks do to find patterns in data.\n\nNow you might be thinking, \"but I haven't seen a linear function or a non-linear function before...\"\n\nOh but you have.\n\nWe've been using them the whole time.\n\nThey're what power the layers in the models we just built.\n\nTo get some intuition about the activation functions we've just used, let's create them and then try them on some toy data.","135efe26":"Wonderful! Now we can use the confusion_matrix function","3f58ebb6":"What kind of labels are we dealing with?","66190f07":"To figure out the ideal value of the learning rate (at least the ideal value to begin training our model), the rule of thumb is to take the learning rate value where the loss is still decreasing but not quite flattened out (usually about 10x smaller than the bottom of the curve).\n\nIn this case, our ideal learning rate ends up between 0.01 ($10^{-2}$) and 0.02\n\n![image.png](attachment:4223ab08-412c-4d13-8578-f0e75d8f865c.png)\n\nThe ideal learning rate at the start of model training is somewhere just before the loss curve bottoms out (a value where the loss is still decreasing).","c968be50":"Alright, so we've got two X features which lead to one y value.\n\nThis means our neural network input shape will has to accept a tensor with at least one dimension being two and output a tensor with at least one value.\n\n> \ud83e\udd14 Note: y having a shape of (1000,) can seem confusing. However, this is because all y values are actually scalars (single values) and therefore don't have a dimension. For now, think of your output shape as being at least the same value as one example of y (in our case, the output from our neural network has to be at least one value).\n\n# **Steps in modelling**\nNow we know what data we have as well as the input and output shapes, let's see how we'd build a neural network to model it.\n\nIn TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n\n1. **Creating a model** - piece together the layers of a neural network yourself (using the functional or sequential API) or import a previously built model (known as transfer learning).\n1. **Compiling a model** - defining how a model's performance should be measured (loss\/metrics) as well as defining how it should improve (optimizer).\n1. **Fitting a model** - letting the model try to find patterns in the data (how does X get to y).\n\nLet's see these in action using the Sequential API to build a model for our regression data. And then we'll step through each.","caaf34d0":"Woah! It looks like our model is getting some incredible results, let's check them out.","7e2c766e":"How does this look?","a3196750":"We're still hitting 50% accuracy, our model is still practically as good as guessing.\n\nHow do the predictions look?","4849a568":"Let's see how the predictions look.","29fe938c":"Inspecting the outputs, we can see the loss values going down and the accuracy going up.\n\nHow's it look (visualize, visualize, visualize)?","212b3134":"Hmm, where do these numbers come from?"}}