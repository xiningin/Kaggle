{"cell_type":{"2fee32b0":"code","1879bf4b":"code","a409a0b6":"code","5cace951":"code","417cf3b3":"code","31e4d082":"code","9a9cef82":"code","b263566a":"code","db98559f":"code","27fe8323":"code","c4991937":"code","5c6ca946":"code","4e6e6ab8":"code","4bf83e85":"code","8ef81055":"code","7da106a6":"code","95caa974":"code","9cb79f68":"code","cb6b5367":"code","b32536a7":"code","1ffe7347":"code","86b5b925":"code","ca46d6e5":"code","83e2fb97":"code","ef7a1564":"code","679318d6":"markdown","913bea90":"markdown"},"source":{"2fee32b0":"import numpy as np\nimport pandas as pd\nimport torch\nimport random\n\nrandom.seed(777)\ntorch.manual_seed(777)\ntorch.cuda.manual_seed_all(777)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","1879bf4b":"train = pd.read_csv('..\/input\/termprojectfoodwaste\/train.csv')\ntest = pd.read_csv('..\/input\/termprojectfoodwaste\/test.csv')\nsubmit = pd.read_csv('..\/input\/termprojectfoodwaste\/sample_submit.csv')","a409a0b6":"train","5cace951":"from sklearn.preprocessing import LabelEncoder\nclassle = LabelEncoder()\nif test['\uc2dc\uad70\uad6c\uba85'].dtype == 'object' and train['\uc2dc\uad70\uad6c\uba85'].dtype == 'object':\n    classle.fit(pd.concat([train['\uc2dc\uad70\uad6c\uba85'], test['\uc2dc\uad70\uad6c\uba85']]))\n    train['\uc2dc\uad70\uad6c\uba85'] = classle.transform(train['\uc2dc\uad70\uad6c\uba85'])\n    test['\uc2dc\uad70\uad6c\uba85'] = classle.transform(test['\uc2dc\uad70\uad6c\uba85'])","417cf3b3":"train_y = train['\ubc30\ucd9c\ub7c9(kg)']\ntrain_x = train.drop(['\ubc30\ucd9c\ub7c9(kg)','\ubc30\ucd9c\ub144\ub3c4'], axis =1)\ntest_x = test.drop(['\ubc30\ucd9c\ub144\ub3c4'], axis =1)","31e4d082":"train.\uc2dc\uad70\uad6c\uba85.unique()","9a9cef82":"def outlier_iqr(data):\n  q1, q3 = np.percentile(data, [10, 90])\n  iqr = q3-q1\n  lower = q1- (iqr*1.5)\n  upper = q3 + (iqr*1.5)  \n  return np.where((data > upper) | (data < lower))","b263566a":"outlier0 = outlier_iqr(train_x.loc[train_x['\uc2dc\uad70\uad6c\uba85']==0]['\ubc30\ucd9c\ub7c9\ube44\uc728(%)'])[0]","db98559f":"for i in range (1,28):\n    outlier1 = outlier_iqr(train_x.loc[train_x['\uc2dc\uad70\uad6c\uba85']==i]['\ubc30\ucd9c\ub7c9\ube44\uc728(%)'])[0]\n    outlier0 = np.concatenate([outlier0, outlier1], axis=0)","27fe8323":"outlier2 = outlier_iqr(train_x.loc[train_x['\uc2dc\uad70\uad6c\uba85']==0]['\ubc30\ucd9c\ud69f\uc218\ube44\uc728(%)'])[0]","c4991937":"for i in range (1,28):\n    outlier3 = outlier_iqr(train_x.loc[train_x['\uc2dc\uad70\uad6c\uba85']==i]['\ubc30\ucd9c\ud69f\uc218\ube44\uc728(%)'])[0]\n    outlier2 = np.concatenate([outlier2, outlier3], axis=0)","5c6ca946":"outlier4 = outlier_iqr(train_x.loc[train_x['\uc2dc\uad70\uad6c\uba85']==0]['\ubc30\ucd9c\ud69f\uc218'])[0]","4e6e6ab8":"for i in range (1,28):\n    outlier5 = outlier_iqr(train_x.loc[train_x['\uc2dc\uad70\uad6c\uba85']==i]['\ubc30\ucd9c\ud69f\uc218'])[0]\n    outlier4 = np.concatenate([outlier4, outlier5], axis=0)","4bf83e85":"outlier_index = set(np.concatenate([outlier0, outlier2, outlier4], axis=0))","8ef81055":"for i in outlier_index:\n  train_x = train_x.drop(index=i, axis = 0)\n  train_y= train_y.drop(index=i, axis = 0)","7da106a6":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\ntrain_x_sc = sc.fit_transform(train_x)\ntest_x_sc= sc.transform(test_x)","95caa974":"train_x_tensor = torch.FloatTensor(np.array(train_x_sc)).to(device)\ntest_x_tensor = torch.FloatTensor(np.array(test_x_sc)).to(device)\ntrain_y_tensor = torch.FloatTensor(np.array(train_y.values).reshape(-1,1)).to(device)\n\n#train_x_tensor = torch.FloatTensor(np.array(train_x)).to(device)\n#test_x_tensor = torch.FloatTensor(np.array(test)).to(device)\n#train_y_tensor = torch.FloatTensor(np.array(train_y.values).reshape(-1,1)).to(device)","9cb79f68":"class NN(torch.nn.Module):\n    def __init__(self):\n        super(NN, self).__init__()\n        self.linear1 = torch.nn.Linear(10, 1024, bias = True)\n        self.linear2 = torch.nn.Linear(1024, 1024, bias = True)\n        self.linear3 = torch.nn.Linear(1024, 512, bias = True)\n        self.linear4 = torch.nn.Linear(512, 256, bias = True)\n        self.linear5 = torch.nn.Linear(256, 1, bias = True)\n        #self.linear6 = torch.nn.Linear(56, 56, bias = True)\n        #self.linear7 = torch.nn.Linear(56, 1, bias = True)\n        torch.nn.init.xavier_uniform_(self.linear1.weight)\n        torch.nn.init.xavier_uniform_(self.linear2.weight)\n        torch.nn.init.xavier_uniform_(self.linear3.weight)\n        torch.nn.init.xavier_uniform_(self.linear4.weight)\n        torch.nn.init.xavier_uniform_(self.linear5.weight)\n\n\n        self.bn1=torch.nn.BatchNorm1d(1024)\n        self.bn2=torch.nn.BatchNorm1d(1024)\n        self.bn3=torch.nn.BatchNorm1d(512)\n        self.bn4=torch.nn.BatchNorm1d(256)\n\n        \n        self.dropout=torch.nn.Dropout()\n        self.relu = torch.nn.ReLU()\n        self.sigmoid = torch.nn.Sigmoid()\n    \n    def forward(self, x):\n        out = self.linear1(x)\n        \n        out=self.bn1(out)\n        out = self.relu(out)\n        out=self.dropout(out)\n        out = self.linear2(out)\n        out=self.bn2(out)\n        out = self.relu(out)\n        out=self.dropout(out)\n        out = self.linear3(out)\n        out=self.bn3(out)\n        out = self.relu(out)\n        out=self.dropout(out)\n        out = self.linear4(out)\n        out= self.bn4(out)\n        out = self.relu(out)\n        out=self.dropout(out)\n        out = self.linear5(out)\n        #out = self.relu(out)\n        #out = self.linear6(out)\n        #out = self.relu(out)\n        #out = self.linear7(out)\n        return out\n    \nmodel = NN().to(device)","cb6b5367":"loss = torch.nn.MSELoss().to(device) #\ud68c\uadc0 \uc774\ubbc0\ub85c mseloss \uc0ac\uc6a9\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)","b32536a7":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error","1ffe7347":"from sklearn.metrics import r2_score\n\nmodel.train()\ntrain_epoch = 5000 #\uc804\ucc98\ub9ac \ucd94\uac00 \uc9c4\ud589 \ud6c4 epoch \uc99d\uac00\uc2dc\ud0a4\uba74\uc11c \ud559\uc2b5\uc2dc loss\uac00 \ub354 \uc791\uc544\uc9c0\ub294 \uacb0\uacfc\ub97c \uc5bb\uc5b4\uc11c \ubcc0\uacbd\nfor epoch in range(1,train_epoch + 1):\n    optimizer.zero_grad()\n    hypothesis = model(train_x_tensor)\n    \n    cost = loss(hypothesis, train_y_tensor)\n    cost.backward()\n    optimizer.step()\n    if epoch % 1000 == 0:\n        model.eval()\n        with torch.no_grad():\n            test_prediction = model(test_x_tensor)\n            train_prediction = model(train_x_tensor)\n            accuracy = r2_score(train_y, train_prediction.detach().cpu())\n            RMSE_train = mean_absolute_error(train_y, train_prediction.detach().cpu())\n            print('train_acc:', '{:.9f}'.format(accuracy), 'train_rmse:', '{:.9f}'.format(RMSE_train))","86b5b925":"model.eval()\nwith torch.no_grad():\n    prediction = model(test_x_tensor)","ca46d6e5":"submit['\ubc30\ucd9c\ub7c9(kg)'] = prediction.detach().cpu().numpy()","83e2fb97":"submit","ef7a1564":"submit.to_csv('submission.csv', index= False) #2429","679318d6":"\uc218\uc815 \ubc0f\ucd94\uac00\ub41c \ubd80\ubd84\n====\n\n\uc77c\uc790\ubcc4 \uc74c\uc2dd\ubb3c\uc4f0\ub808\uae30 \ubc30\ucd9c\ub7c9\uc5d0 \uc788\uc5b4\uc11c \uc911\uc694\ud55c \uac83\uc740 \uc8fc\uae30\uc131\uc5d0 \uad00\ud55c feature\ub4e4\uc744 \ub0a8\uae30\ub294 \uac83\uc774 \ub354 \ud6a8\uacfc\uc801\uc778 \uc608\uce21\uc744 \ud560 \uc218 \uc788\ub2e4\uace0 \uc0dd\uac01\ud558\uc600\uc2b5\ub2c8\ub2e4. \uadf8\ub798\uc11c \ubc30\ucd9c\ub144\ub3c4\uc5d0 \uad00\ud55c \ub370\uc774\ud130\ub294 \uc624\ud788\ub824 \uc815\ud655\ud55c \uc608\uce21\uc744 \ubc29\ud574\ud55c\ub2e4\uace0 \ud310\ub2e8\ud558\uc600\uae30 \ub54c\ubb38\uc5d0 train \ubc0f test\uc5d0\uc11c \uc81c\uac70\ud558\uc600\uc2b5\ub2c8\ub2e4.","913bea90":"\ucd94\uac00\ub41c \ubd80\ubd84\n====\n\uac01 \uc2dc\uad70\ubcc4 \ub370\uc774\ud130 \uc911\uc5d0\uc11c \ud2b9\uc815 \ub0a0\uc758 \ub370\uc774\ud130\uc14b\uc73c\ub85c\ub294 \uc54c \uc218 \uc5c6\ub294 \uc694\uc778\ub4e4\ub85c \uc778\ud574\uc11c \ud2b9\uc815 \ub0a0\uc758 \ubc30\ucd9c\uacfc \uad00\ub828\ub41c \ub370\uc774\ud130\uac00 \ubcc0\ud560 \uc218 \uc788\ub2e4\uace0 \uc0dd\uac01\ud588\uae30 \ub54c\ubb38\uc5d0 \uac01 \uc2dc\uad70\ubcc4 \ub370\uc774\ud130 \uc911 \ub108\ubb34 \ub9ce\uc774 \ubc30\ucd9c\ub418\uc5c8\uac70\ub098 \ub108\ubb34 \uc801\uac8c \ubc30\ucd9c\ub41c \uacbd\uc6b0\uc758 \ub370\uc774\ud130\ub97c \uc81c\uac70\ud558\uc5ec \ud559\uc2b5\uc744 \uc9c4\ud589\ud560 \uacbd\uc6b0 \ub354\uc6b1 \uc815\ud655\ud55c \uc608\uce21\uc774 \uac00\ub2a5\ud558\ub2e4\uace0 \ud310\ub2e8\ud558\uc600\uae30 \ub54c\ubb38\uc5d0 \ub2e4\uc74c\uacfc \uac19\uc740 \ucf54\ub4dc\ub97c \uc791\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n\uc5b4\ub290 \uc815\ub3c4\uae4c\uc9c0 outlier\ub85c \ubcf4\uace0 \uc81c\uac70\ub97c \ud560 \uac83\uc778\uc9c0 \uc9c1\uc811 \ubc94\uc704\ub97c \ubc14\uafb8\uba74\uc11c \uc608\uce21\uacb0\uacfc\ub97c \ubcf4\uba74\uc11c \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.  \n1. 25\/75\n2. 10\/90\n3. 5\/95\n\n\uc774\ub807\uac8c \uc138\uac00\uc9c0 \uacbd\uc6b0\ub85c \uc9c4\ud589\ud55c \uacb0\uacfc 2\ubc88\uc9f8 \uacbd\uc6b0\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 \uc131\ub2a5 \uac1c\uc120\uc774 \ub098\ud0c0\ub098 2\ubc88 \uac12\uc744 \uac00\uc9c0\uace0 \uc774\uc0c1\uce58 \uc81c\uac70\ub97c \uc9c4\ud589 \ud55c \ud6c4 \ud559\uc2b5\uc744 \ud558\uc600\uc2b5\ub2c8\ub2e4."}}