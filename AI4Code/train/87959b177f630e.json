{"cell_type":{"4dc9b04e":"code","2a6f0bcc":"code","37b677c0":"code","b0a4518a":"code","0fae2929":"code","8f006dbe":"code","4b00dace":"code","968b3dd3":"code","9d7f9dbd":"code","98642925":"code","b2631daa":"code","3c1e7db9":"code","3242a673":"code","1c8b446b":"code","d5c09dee":"code","74fe9843":"code","0a10a589":"code","16e6f45c":"code","42883260":"code","c5cf6520":"code","592034f9":"code","310d018c":"code","198f4dc2":"code","940bf855":"code","6ba55b69":"code","5a831843":"code","52091a14":"code","d6cf6665":"code","440ca286":"code","48b670d7":"code","0a41af17":"markdown","5740f004":"markdown","072307aa":"markdown","d04e5fd8":"markdown"},"source":{"4dc9b04e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2a6f0bcc":"dataset=pd.read_csv(\"\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","37b677c0":"dataset.corr()","b0a4518a":"quality = dataset[\"quality\"].values\ncategory = []\nfor num in quality:\n    if num<5:\n        category.append(\"Bad\")\n    elif num>6:\n        category.append(\"Good\")\n    else:\n        category.append(\"Mid\")","0fae2929":"category = pd.DataFrame(data=category, columns=[\"category\"])\ndata = pd.concat([dataset,category],axis=1)\ndata.drop(columns=\"quality\",axis=1,inplace=True)","8f006dbe":"data","4b00dace":"plt.figure(figsize=(10,6))\nsns.countplot(data[\"category\"],palette=\"muted\")\ndata[\"category\"].value_counts()","968b3dd3":"plt.figure(figsize=(12,6))\nsns.heatmap(data.corr(),annot=True)","9d7f9dbd":"X=data.iloc[:,:-1].values\nX","98642925":"Y=data.iloc[:,-1].values","b2631daa":"Y1=data.iloc[:,-1].values","3c1e7db9":"Y","3242a673":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\n\nX = scaler.transform(X)\n","1c8b446b":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_y =LabelEncoder()\nY= labelencoder_y.fit_transform(Y)","d5c09dee":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2,random_state=0)","74fe9843":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train,y_train)\npred_svc =svc.predict(X_test)","0a10a589":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(y_test,pred_svc))","16e6f45c":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=250)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)\nprint(classification_report(y_test, pred_rfc))","42883260":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train,y_train)\npred_knn=knn.predict(X_test)\nprint(classification_report(y_test, pred_knn))","c5cf6520":"Y1=Y1.reshape(1599,-1)","592034f9":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\nY1 = ohe.fit_transform(Y1).toarray()\nY1.shape\n#X_val.shape","310d018c":"from sklearn.model_selection import train_test_split                 #importing train_test_split from sklearn to split data\nx_train,x_test,y_train,y_test=train_test_split(X,Y1,shuffle=True,test_size=0.20,random_state=90) #split the data in 80:20 ratio ","198f4dc2":"x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.05, random_state=90)","940bf855":"#Neural Network Dependencies\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.activations import relu,softmax","6ba55b69":"model = Sequential()\nmodel.add(Dense(32, input_dim=11, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))","5a831843":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","52091a14":"from keras.callbacks import ModelCheckpoint\ncheckpointer=ModelCheckpoint(filepath='Convolutional.hdf5',verbose=1,save_best_only=True)\nhistory = model.fit(x_train, y_train, epochs=500, batch_size=64,validation_data=(x_val,y_val))","d6cf6665":"score=model.evaluate(x_test,y_test,verbose=1)               #evaluates the model\naccuracy=100*score[1]                                       \nprint('Test accuracy is %.4f%%' % accuracy)","440ca286":"score=model.evaluate(x_train,y_train,verbose=1)               #evaluates the model\naccuracy=100*score[1]                                       \nprint('Test accuracy is %.4f%%' % accuracy)","48b670d7":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","0a41af17":"# SUPPORT VECTOR MACHINES","5740f004":"# NEURAL NETWORKS","072307aa":"# KNN ","d04e5fd8":"# RANDOM FOREST"}}