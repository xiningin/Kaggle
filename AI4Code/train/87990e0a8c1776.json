{"cell_type":{"6caae98f":"code","9cd48dc2":"code","993c3f57":"code","81f21e89":"code","faeb76aa":"code","3048977b":"code","cc5fb928":"code","da265de4":"code","3d2bf485":"code","5117e354":"code","96c281a6":"code","2ec5cad8":"code","8068446e":"code","ac556a8a":"code","55fed51a":"code","02909b8b":"code","f942ee32":"code","187dbd36":"code","95c580c0":"code","9543e831":"code","cf15ee25":"code","17f0062c":"code","43f371d8":"code","49e700bf":"code","aa9bd5c1":"code","6edab75d":"code","5533d173":"code","74ca0b23":"code","2ccf3b8b":"code","94ee6180":"code","6b8d0e11":"code","cc7d2ad5":"code","45619c65":"code","cbd027d8":"code","2afd9d17":"code","ccb9e2dd":"code","7f4e4fd4":"code","77ead8d8":"code","dd7577a4":"code","4e3c6939":"code","7a4e32eb":"code","97fe98c9":"code","4c615a3d":"code","f3879937":"code","67f7aca1":"code","3c69a759":"code","be7eb283":"code","c86a9d4d":"code","cffed348":"code","f0de3e80":"code","b2b8f5a3":"markdown","534305f6":"markdown","053f9b71":"markdown","bcbb081d":"markdown","27d8adaa":"markdown","4c49f756":"markdown","7be9fd02":"markdown","0314bbd9":"markdown","3b2f2082":"markdown"},"source":{"6caae98f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils import estimator_html_repr\nfrom IPython.core.display import HTML\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import linear_model\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.utils import estimator_html_repr\nfrom IPython.core.display import HTML\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.base import TransformerMixin,BaseEstimator,ClassifierMixin\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.feature_selection import SelectKBest, f_regression, chi2,f_classif\nfrom sklearn.impute import KNNImputer\nfrom sklearn.experimental import enable_iterative_imputer \nfrom sklearn.impute import IterativeImputer\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom catboost import CatBoostClassifier\n%matplotlib inline","9cd48dc2":"df = pd.read_csv('..\/input\/iba-ml2-mid-project\/train.csv',index_col= 'Id')","993c3f57":"df.head()","81f21e89":"df.info()","faeb76aa":"df.describe()","3048977b":"# finding the data types\ndf.dtypes.value_counts()","cc5fb928":"# finding the unique values for all columns\ndf.apply(pd.Series.nunique, axis = 0)","da265de4":"#identifying missing values \ndf.isnull().sum()","3d2bf485":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","5117e354":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","96c281a6":"missing_values = missing_values_table(df)\nmissing_values.head(20)","2ec5cad8":"# Distribution of the Target Column, which identifies that this is a imbalanced dataset\nsns.countplot(df['defaulted_on_loan'])","8068446e":"#looking for corralation between columns\nsns.heatmap(df.corr())","ac556a8a":"#cleaning data and replacing wrongly placed ',' with the '.'\ndf['credit_line_utilization'] = (df['credit_line_utilization'].replace(',','.', regex=True).astype(float))","55fed51a":"df['number_of_previous_late_payments_90_days_or_more'].describe()","02909b8b":"df['number_of_previous_late_payments_up_to_59_days'].describe()","f942ee32":"df['number_of_previous_late_payments_up_to_89_days'].describe()","187dbd36":"#as we can see there are anomalies in dataset, mean and max value has huge difference , it would create issue for dataset, that is why I will replace max values with the NAN","95c580c0":"df['number_of_previous_late_payments_up_to_89_days'].replace(to_replace = [98,96], value = np.nan,inplace = True)\ndf['number_of_previous_late_payments_up_to_59_days'].replace(to_replace = [98,96], value = np.nan,inplace = True)\ndf['number_of_previous_late_payments_90_days_or_more'].replace(to_replace = [98,96], value = np.nan,inplace = True)","9543e831":"df['credit_line_utilization'].describe()","cf15ee25":"#removing outliers in credit_line_utilization\ndf['credit_line_utilization'][df['credit_line_utilization']>(df['credit_line_utilization'].std()+df['credit_line_utilization'].median())] = np.nan","17f0062c":"df['ratio_debt_payment_to_income'].describe()","43f371d8":"df['ratio_debt_payment_to_income'][df['ratio_debt_payment_to_income']>30]","49e700bf":"#removing outliers in 'ratio_debt_payment_to_income'\ndf['ratio_debt_payment_to_income'][df['ratio_debt_payment_to_income']>30] = np.nan","aa9bd5c1":"df['monthly_income'][df['monthly_income']>35000] = np.nan","6edab75d":"sns.scatterplot(data = df,y = 'age',x = 'number_of_credit_lines',hue = 'defaulted_on_loan')","5533d173":"sns.scatterplot(data = df,x = 'age',y = 'monthly_income',hue = 'defaulted_on_loan')","74ca0b23":"#removing outliers from age\ndf['age'][df['age']>100] = np.nan","2ccf3b8b":"#removing outliers from 'number_of credit_lines' column\ndf['number_of_credit_lines'][df['number_of_credit_lines']>35 ] = np.nan","94ee6180":"#creating new column for 'debt_payment','other_loans' and 'late_payments' as per domain knowledge\ndf['debt_payment'] = df['ratio_debt_payment_to_income']*df['monthly_income']\ndf['other_loans'] = df['number_of_credit_lines'] - df['real_estate_loans']\ndf['late_payments'] = df['number_of_previous_late_payments_up_to_89_days'] + df['number_of_previous_late_payments_90_days_or_more'] + df['number_of_previous_late_payments_up_to_59_days'] ","6b8d0e11":"#checking amount of missing values in new columns\ndf.isnull().sum()","cc7d2ad5":"#identifying the categorical and numeric values,'number_dependent_family_members' was identified to be categorical for proper missing value handling technique \ncategorical = ['number_dependent_family_members']\nnumeric = ['monthly_income','number_of_credit_lines','ratio_debt_payment_to_income','age','credit_line_utilization','debt_payment','real_estate_loans','number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days','number_of_previous_late_payments_90_days_or_more','late_payments']","45619c65":"X = df.drop(columns = ['defaulted_on_loan'])\ny = df['defaulted_on_loan']","cbd027d8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)","2afd9d17":"#Building pipeline \ncategorical_transformer=Pipeline(steps=[\n    ('impute', IterativeImputer(random_state = 42)), \n])\n\nnumeric_transformer=Pipeline(steps=[\n    ('scaler',QuantileTransformer(n_quantiles  = 10000)),\n    ('impute', IterativeImputer(random_state = 42,max_iter = 40)),\n    \n\n])\n\ncolumn_transformer=ColumnTransformer(transformers=[\n    ('numeric', numeric_transformer, numeric),\n    ('categorical', categorical_transformer, categorical)\n])\n\nmodel_pipeline=Pipeline(steps=[\n    ('preprocessing', column_transformer),\n('classifier', xgb.XGBClassifier(seed=2,n_estimators=190,max_depth=2, learning_rate=0.1,eval_metric = 'auc',use_label_encoder=False)) \n\n  ])\n\n\nmodel_pipeline.fit(X_train, y_train)\nprint(classification_report(y_test, model_pipeline.predict(X_test)))","ccb9e2dd":"#presenting the result from first pipeline\nprediction = model_pipeline.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, prediction)\nsns.set()\n\nplt.plot(fpr, tpr)\n\nplt.plot(fpr, fpr, linestyle = '--', color = 'k')\n\nplt.xlabel('False positive rate')\n\nplt.ylabel('True positive rate')\n\nAUROC = np.round(roc_auc_score(y_test, prediction), 4)\n\nplt.title(f'ROC curve; AUROC: {AUROC}');\n\nplt.show()","7f4e4fd4":"#identifying the existing parameters for the pipeline\nmodel_pipeline.get_params()","77ead8d8":"#identifying the importance of features\nmodel_pipeline.steps[1][1].feature_importances_","dd7577a4":"importance = model_pipeline.steps[1][1].feature_importances_\n# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","4e3c6939":"param_space={ \n                'classifier__n_estimators': [1000],\n             'classifier__learning_rate':[0.1],\n             'classifier__booster': ['gbtree'],\n             'classifier__max_delta_step': [0],\n             'classifier__subsample': [1],\n             'classifier__scale_pos_weight': [4],\n             'classifier__max_depth':[3],\n             'classifier__min_child_weight':[1],\n             'classifier__gamma': [0],\n                'classifier__subsample':[0.7],\n             'classifier__colsample_bytree':[0.7],\n             'classifier__reg_alpha':[100],\n             'classifier__objective': ['binary:logistic',],\n             'preprocessing__numeric__impute__max_iter': [40],\n             'preprocessing__numeric__impute__imputation_order': ['arabic'],\n             'preprocessing__numeric__impute__initial_strategy': ['median','mean'],\n             'preprocessing__numeric__impute__sample_posterior': [False]            \n             }  ","7a4e32eb":"gridsearch=GridSearchCV(model_pipeline, param_space, cv=StratifiedKFold(n_splits=2, shuffle=True, random_state=42), scoring='roc_auc')\n# gridsearch = RandomizedSearchCV(model_pipeline, param_space, cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=42), scoring='roc_auc')","97fe98c9":"#gridsearch.fit(X_train, y_train)\ngridsearch.fit(X, y)","4c615a3d":"#finding best parameters for the pipeline\ngridsearch.best_params_","f3879937":"#predicting result using the best parameters\nprediction = gridsearch.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, prediction)\nsns.set()\n\nplt.plot(fpr, tpr)\n\nplt.plot(fpr, fpr, linestyle = '--', color = 'k')\n\nplt.xlabel('False positive rate')\n\nplt.ylabel('True positive rate')\n\nAUROC = np.round(roc_auc_score(y_test, prediction), 4)\n\nplt.title(f'ROC curve; AUROC: {AUROC}');\n\nplt.show()","67f7aca1":" test = pd.read_csv('..\/input\/iba-ml2-mid-project\/test.csv',index_col= 'Id')","3c69a759":"test['debt_payment'] = test['ratio_debt_payment_to_income']*test['monthly_income']\ntest['other_loans'] = test['number_of_credit_lines'] - test['real_estate_loans']\ntest['late_payments'] = test['number_of_previous_late_payments_up_to_89_days'] + test['number_of_previous_late_payments_90_days_or_more'] + test['number_of_previous_late_payments_up_to_59_days'] ","be7eb283":"#transofrming strings to float\n#cleaning data and replacing wrongly placed ',' with the '.'\ntest['credit_line_utilization'] = (test['credit_line_utilization'].replace(',','.', regex=True).astype(float))","c86a9d4d":"test_prediction = gridsearch.predict_proba(test)[:,1]","cffed348":"result = test\nresult['Predicted'] = test_prediction\nresult = result['Predicted']","f0de3e80":"result.to_csv('Result.csv',index=True)","b2b8f5a3":"Optimization of the pipeline using GridSearchCV","534305f6":"Loading dataset","053f9b71":"using test dataset to obtain required results for submission","bcbb081d":"data above shows that it is imbalanced dataset","27d8adaa":"Outiler detection and handling\nNote: not used isolation forest for more accurate data handling and not to lose the data by masking","4c49f756":"Dividing the data and building the pipeline","7be9fd02":"data handling\n","0314bbd9":"Performing an Exploratory Data Analysis (\u201cEDA\u201d) on the dataset","3b2f2082":"hyperparameters tuning using GridSearchCV"}}