{"cell_type":{"283f4dd2":"code","b7c2f975":"code","2ecac063":"code","af8ad9f6":"code","7a01c64a":"code","9fb9843c":"code","2817e614":"code","4d3aea9c":"code","42624583":"code","0f67bc3e":"code","c1fdb491":"code","6fd53be8":"code","74da2cd9":"code","f4170775":"code","1bd7f387":"code","bceeec0c":"code","e2e8d6de":"markdown","e277a3f0":"markdown","62a0575b":"markdown","7cedd749":"markdown","044b071c":"markdown","3a506ada":"markdown","c3efad00":"markdown","13afe2f9":"markdown","0a4bfc9a":"markdown","f04de15e":"markdown"},"source":{"283f4dd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport nltk\nfrom nltk import word_tokenize\nimport string\nfrom collections import defaultdict\nnltk.download('punkt')\nimport random\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ncorpus = ''\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        with open(os.path.join(dirname, filename), 'r') as f:\n            for line in f.readlines():\n                if '----------' in line:\n                    break\n                corpus += line.strip()\n                corpus += ' '\n            f.close()\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7c2f975":"len(corpus)","2ecac063":"n_grams = 2","af8ad9f6":"def clean_up(corpus):\n    corpus = word_tokenize(corpus.lower())\n    table = str.maketrans('', '', string.punctuation)\n    corpus = [w.translate(table) for w in corpus]\n    corpus = [w for w in corpus if w] # not empty\n    return corpus","7a01c64a":"corpus = clean_up(corpus)\nlen(corpus)","9fb9843c":"markov_matrix = dict()\nfor i in range(0, len(corpus) - n_grams):\n    curr_state = corpus[i:i + n_grams]\n    next_state = corpus[i + n_grams:i + n_grams + n_grams]\n    curr_state = ' '.join(curr_state)\n    next_state = ' '.join(next_state)\n    if curr_state not in markov_matrix:\n        markov_matrix[curr_state] = defaultdict(int)\n    markov_matrix[curr_state][next_state] += 1","2817e614":"for curr_state, list_next_states in markov_matrix.items():\n    tot_next_states = sum(list(list_next_states.values()))\n    for next_state in list_next_states.keys():\n        markov_matrix[curr_state][next_state] \/= tot_next_states","4d3aea9c":"def generate_text(seed='the adventure', size=10):\n    story = seed + ' '\n    curr_state = ' '.join(seed.split()[-2:])\n    for _ in range(size):\n        transition_sequence = markov_matrix[curr_state]\n        next_state = random.choices(list(transition_sequence.keys()),\n                                    list(transition_sequence.values()))\n        next_state = ' '.join(next_state)\n        story += next_state + ' '\n        curr_state = next_state\n    return story[:-1]","42624583":"print(generate_text('here they are', 100))","0f67bc3e":"print(generate_text('the angle', 100))","c1fdb491":"print(generate_text('my name is conan doyle', 100))","6fd53be8":"print(generate_text('at that moment', 100))","74da2cd9":"print(generate_text('my work', 100))","f4170775":"for i in range(10):\n    print(i, generate_text('my name', 10))","1bd7f387":"for i in range(10):\n    print(i, generate_text('conan doyle', 10))","bceeec0c":"for i in range(10):\n    print(i, generate_text('sherlock holmes', 10))","e2e8d6de":"## Testing \"sherlock holmes\" 10 times","e277a3f0":"# Conclusion","62a0575b":"# Clean up the corpus","7cedd749":"This is just an idea of making a language model using Markov Chain property: next state is dependent solely current state. It's not perfect now, but this model is a baseline for something bigger if you had idea. Good luck.","044b071c":"## Testing random generate story from seed words","3a506ada":"## Testing with \"my name\" 10 times","c3efad00":"# Count number of 2-grams transition","13afe2f9":"## Testing with \"conan doyle\" - the author of Sherlock Holmes 10 times","0a4bfc9a":"# Testing models","f04de15e":"# Calculate the probability to go from curr_state to next_state"}}