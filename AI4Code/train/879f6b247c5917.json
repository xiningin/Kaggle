{"cell_type":{"76ca5e37":"code","62b91038":"code","e25f3d22":"code","afabad23":"code","5ed5668b":"code","93aa9984":"code","5e346323":"code","5f840779":"code","d19bcea5":"code","42092bef":"code","301dd1a9":"code","82ba15ce":"code","fe1cd1dc":"code","837aa302":"code","4171555f":"code","6fa09bc8":"code","2bf360af":"markdown","88f74f41":"markdown","e4eb0969":"markdown","de638262":"markdown","dba41c27":"markdown","47bd26f2":"markdown","75789854":"markdown","c440e68c":"markdown","1b7fb339":"markdown","32fcdedc":"markdown"},"source":{"76ca5e37":"import numpy as np\nimport pandas as pd\nimport warnings\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 22})\nwarnings.filterwarnings(\"ignore\")\n\n# Load the engagement file \nengagement_list = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning'):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n        if file[-4:] == '.csv' and filename not in ['products_info.csv','districts_info.csv']:\n            district_id = int(filename.split('.')[0])\n            df = pd.read_csv(file)\n            df['district_id'] = district_id\n            engagement_list.append(df)\n\nengagement_data = pd.concat(engagement_list)\n# Lodd the product information file \nproducts_info = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')\n# Load the districts information file \ndistricts_info = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\n\nprint(f'There are {engagement_data.shape[0]} rows and {engagement_data.shape[1]} columns in the engagement dataset.\\n')\nprint(f'There are {products_info.shape[0]} rows and {products_info.shape[1]} columns in the products dataset.\\n')\nprint(f'There are {districts_info.shape[0]} rows and {districts_info.shape[1]} columns in the districts info dataset.')","62b91038":"# Delete products that there Functions are unknown \nproducts_info = products_info[products_info['Primary Essential Function'].notna()]\n# Delete rows that do not mention the product name \nproducts_info = products_info[products_info['Product Name'].notna()]\n\n# Rename the product id column so it can be joined later with \n# the engagement dataframe \nproducts_info.rename(columns={'LP ID':'lp_id'}, inplace=True)\n\n# TBD later on \nproducts_info['Product Category'] = np.NaN\n\n# Split the Primary Essential Function to Primary Function \n# and Secondary Function \nprimary_functions = []\nsecondary_functions = []\nfor row in products_info['Primary Essential Function']:\n    primary_functions.append(row.split('-')[0])\n    secondary_functions.append(row.split('-')[1])\nproducts_info['Primary Function'] = primary_functions\nproducts_info['Secondary Function'] = secondary_functions \n\n# One-hot encode the Educational sectors that the product is used\nproduct_sectors = products_info['Sector(s)'].str.get_dummies(sep=\"; \")\nproducts_info = pd.concat([products_info,product_sectors], axis = 1)\n\n# Delete the Primary Essential Function column since its not needed now  \ndel products_info['Primary Essential Function']\ndel products_info['Sector(s)']\nproducts_info","e25f3d22":"# Delete rows where the district_id is not available \ndistricts_info = districts_info[districts_info['state'].notna()]\n\ncolumns = ['pct_black\/hispanic','county_connections_ratio','pct_free\/reduced','pp_total_raw']\n\ndef data_wrangling(df,column): \n    '''\n    Calculates the midpoint of variables where their values \n    are given as a range. \n    '''\n    ls = []\n    x = 'avg_' + str(column) \n    df[x] = np.NaN\n    for row in df[column]:\n        if type(row) == float:\n            # Append NA so the length is the same and \n            # replace later with the column avg \n            ls.append(np.NaN) \n        else:\n            ls.append((float(row.split('[')[1].split(',')[0]) + float(row.split('[')[1].split(',')[1])) \/ 2)\n    ls = [round(x,2) for x in ls]\n    df[x] = ls  \n                   \n    del df[column]\n    return df\n\nfor column in columns:\n    districts_info = data_wrangling(districts_info,column)\n\n# Replace NAs with the average values per state and locale \ndistricts_info['avg_pp_total_raw'] = districts_info.groupby(['state','locale'])['avg_pp_total_raw'].\\\n                                     fillna(int(districts_info['avg_pp_total_raw'].mean()))\n\ndistricts_info['avg_pct_free\/reduced'] = districts_info.groupby(['state','locale'])['avg_pct_free\/reduced'].\\\n                                         fillna(round(districts_info['avg_pct_free\/reduced'].mean(),2))\n\ndistricts_info['avg_county_connections_ratio'] = districts_info.groupby(['state','locale'])['avg_county_connections_ratio'].\\\n                                                 fillna(districts_info['avg_county_connections_ratio'].mean())\n\n# Add another column for the % of people that are not black\/hispanic \ndistricts_info['avg_pct_other'] = 1 - districts_info['avg_pct_black\/hispanic']\ndistricts_info.head()","afabad23":"# Inner join the engagement dataframe with the products_info dataframe \n# Engagement data that do not contain state\/product will be dropped \nengagement_data =  engagement_data.merge(products_info, on='lp_id', how='inner')\n\n# Inner join the engagement dataframe with the ditricts_info dataframe \nengagement_data = engagement_data.merge(districts_info, on = 'district_id', how = 'inner')","5ed5668b":"# Summary statistics for the engagment dataframe after the joins \nengagement_data.describe()","93aa9984":"# Black \/ hispanic population per state \nfrom matplotlib import pyplot as plt\navg_pct = districts_info.groupby(['state'])['avg_pct_black\/hispanic'].mean().sort_values(ascending = True)\navg_pct.T.plot(kind = \"barh\", figsize=(22, 13))\nplt.suptitle(\"Black \/ Hispanic population percentage per (school district) State\", fontsize = 31)","5e346323":"# Summary Statistics per state \nstates_summary = pd.DataFrame()\nstates_summary['observations'] = engagement_data.groupby(['state'])['state'].count().sort_values(ascending = False)\nstates_summary['start_date'] = engagement_data.groupby('state')['time'].min()\nstates_summary['end_date'] = engagement_data.groupby('state')['time'].max()\nstates_summary['locales'] = engagement_data.groupby(['state'])['locale'].nunique()\nstates_summary['products_used'] = engagement_data.groupby(['state'])['lp_id'].nunique()\nstates_summary['product_usage_ratio'] = round((states_summary['products_used'] \/ len(products_info)) * 100,2)\nstates_summary['product_categories'] = np.NaN\nstates_summary","5f840779":"# Top 20 products used \nprodcut_popularity = engagement_data.groupby(['Product Name'])['Product Name'].count()\\\n                                .sort_values(ascending = False)\n\nprodcut_popularity[:20].T.plot(kind = \"bar\", figsize=(22, 12))\nplt.suptitle(\"Top 20 most used products\", fontsize = 31)","d19bcea5":"# Top 20 products with the highetst engagement index \nprodcut_engagement_index = engagement_data.groupby(['Product Name'])['engagement_index'].mean()\\\n                                .sort_values(ascending = False)\n\nprodcut_engagement_index[:20].T.plot(kind = \"bar\", figsize=(22, 12))\nplt.suptitle(\"Engagemnt Index for the top 20 products\", fontsize = 31)","42092bef":"import matplotlib.pyplot as plt\nstate_avg_engagement_idx = engagement_data.groupby(['state'])['engagement_index'].mean().sort_values(ascending = False)\nstate_avg_engagement_idx.T.plot(kind = \"bar\", figsize=(22, 13))\nplt.suptitle(\"Average Engagement Index per State\", fontsize = 31)","301dd1a9":"locale_avg_engagement_idx = engagement_data.groupby(['locale'])['engagement_index'].mean().sort_values(ascending = False)\nlocale_avg_engagement_idx.T.plot(kind = \"bar\", figsize=(20, 8))\nplt.suptitle(\"Average Engagement Index per Locale\", fontsize = 30)","82ba15ce":"state_locale_avg_engagement_idx = engagement_data.groupby(['state','locale'])['engagement_index'].mean().sort_values(ascending = True)\nstate_locale_avg_engagement_idx.T.plot(kind = \"barh\", figsize=(23, 25))\nplt.suptitle(\"Engagement Index per State and Locale\", fontsize = 32)","fe1cd1dc":"# Engagement index as a function of time \nengagement_data['time'] = pd.to_datetime(engagement_data['time'])\nengagement_data.sort_values(by='time') # This now sorts in date order\n\ndaily_avg_engagement_idx = engagement_data.groupby(['time'])['engagement_index'].mean().sort_values()\ndaily_avg_engagement_idx.T.plot(kind = \"line\", figsize=(15, 7))","837aa302":"mask = (engagement_data['time'] > '2020-01-01') & (engagement_data['time'] <= '2020-02-01')\nmask = engagement_data.loc[mask]\nmask.groupby(['time'])['engagement_index'].mean().sort_values().T.plot(kind = \"line\", figsize=(15, 7))","4171555f":"black_hispanic_engagement = engagement_data.groupby(['avg_pct_black\/hispanic'])['engagement_index'].mean().sort_values(ascending = False)\nblack_hispanic_engagement.T.plot(kind = 'bar',stacked = True, figsize=(18, 7))","6fa09bc8":"avg_state_pct_BlackHispanic = engagement_data['avg_pct_black\/hispanic'].mean() \navg_BlackHispanic_engagement_index = engagement_data.groupby(['avg_pct_black\/hispanic'])['engagement_index'].mean().mean() \n\nprint(f'The average percentage of black\/hispanic ethnicities per state is {round(avg_state_pct_BlackHispanic,2) * 100}% with \\\nan average engagement index of {round(avg_BlackHispanic_engagement_index,2)}')","2bf360af":"# EDA - DEMOGRAPHICS AND USER BEHAVIOR #","88f74f41":"# EDA - ENGAGEMENT SECTION #","e4eb0969":"## Please \ud83d\udc4d and let me know that you want to see more, so i know to update this notebook with further data \/ analysis and modelling.   ","de638262":"### Zooming in the first month, we can indeed see that the activity occurs in the weekdays. Additionally, the dataset comprises of time-series data. A seasonal ARIMA model can be used to model the future engagement index both on a per state and locale level.","dba41c27":"## Observations:\n* At first the engagemnent was lower (could be either because students \/ institution did not quickly utilize online learning or deifferent locales shut down at different periods)\n* Around mid-February, where most places were on lockdown, the engagement index doubled. \n* Overall, there is high activity over the weekdays, with extreme spikes during the weekends (students spend less time studying over the weekends, regardles of the Covid pandemic)\n* Near summer, the engagement index started to diminish, since most educational institutions were closed. \n","47bd26f2":"# EDA - PRODCUTS SECTION #","75789854":"### Observations:\n* North Dakota has the least amount of data out of the featured states (check how many educational instituions present)\n* Most states have data for the full year, although many of them were not on lockdown but for a few months (investigate)\n* Almost all states have used to some capacity all the available tools for digitial (distance) learning.  \n* \n*\n\n### TO DO:\n* Check land capacity and population per state\n* Break down per state -> locale\n*","c440e68c":"# Preprocessing the products_info dataframe #","1b7fb339":"### It seems that on average the rural areas have a higer engagement index. This could be becuase people living away from the cities were using digital channels for learning from before. Overall, its worth investigating how the engagement index per locale changes as a function of time, since some locales might adjusted to online-learning faster than others.  ","32fcdedc":"# Preprocessing the districts_info dataframe "}}