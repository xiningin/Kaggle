{"cell_type":{"211d89ce":"code","a56990fb":"code","5cd26160":"code","b2675b8a":"code","de84b850":"code","ab6e4ab1":"code","66aca7fe":"code","6332abcb":"code","062748d1":"code","ba05a6ab":"code","7102b1b0":"code","c0372dd6":"code","a031b04d":"code","cffc272b":"code","5196bdcd":"code","6100382f":"code","e08d38d2":"markdown","0b833022":"markdown","554466e3":"markdown"},"source":{"211d89ce":"!pip install pandarallel python-chess","a56990fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re\nimport matplotlib.pyplot as plt\nimport random\nfrom tqdm import tqdm\nfrom pandarallel import pandarallel\nfrom multiprocessing import  Pool\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nimport chess\n\nrandom.seed(420)\nnp.random.seed(420)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cd26160":"tqdm.pandas()\npandarallel.initialize(progress_bar=True)","b2675b8a":"df = pd.read_csv(\"\/kaggle\/input\/chess-evaluations\/chessData.csv\")","de84b850":"values = {\n    \"P\": 1,\n    \"R\": 5,\n    \"B\": 3,\n    \"N\": 3,\n    \"K\": 0, # 0 since both sides have one king\n    \"Q\": 9\n}\nfor k, v in list(values.items()):\n    values[k.lower()] = -v\n\ndef material_advantage(fen, pat=re.compile(r\"[a-zA-Z]\"), val=values):\n    return sum(map(val.get, re.findall(pat, fen.split(' ')[0])))\n\ndef material_advantage_with_cutoff(fen):\n    return min(2, max(-2, material_advantage(fen)))\n\ndef clamp(bot, top):\n    return lambda num: min(top, max(bot, num))\n\ndef win_lose_draw(evaluation):\n    if evaluation < -10:\n        return 0\n    if evaluation < -1.5:\n        return 1\n    if evaluation < 1.5:\n        return 2\n    if evaluation < 10:\n        return 3\n    return 4\n\ndef tan_eval_categories(evaluation):\n    if evaluation < -.5:\n        return 0\n    if evaluation > .5:\n        return 1\n    return 2\n\ndef eval_to_int(evaluation):\n    try:\n        res = int(evaluation)\n    except ValueError:\n        res = 10000 if evaluation[1] == '+' else -10000\n    return res \/ 100\n\ncount_pieces = lambda fen, pat=re.compile(r\"[a-zA-Z]\"): len(re.findall(pat, fen.split(' ')[0]))\ntransform_eval = lambda x: np.arctan(x \/ 3)\nuntransform_eval = lambda x: 3 * np.tan(x)","ab6e4ab1":"# Don't generate unneeded fields to speed up execution\ndf[\"Pieces\"] = df[\"FEN\"].parallel_map(count_pieces)\ndf[\"Evaluation\"] = df[\"Evaluation\"].parallel_map(eval_to_int)\ndf[\"Normalized Evaluation\"] = transform_eval(df[\"Evaluation\"])\n# df[\"Material advantage\"] = df[\"FEN\"].parallel_map(material_advantage)\n# df[\"Cutoff Material advantage\"] = df[\"Material advantage\"].parallel_map(clamp(-2, 2))\n# df[\"Win Lose Draw\"] = df[\"Evaluation\"].parallel_map(win_lose_draw)\ndf[\"Normalized WLD\"] = df[\"Normalized Evaluation\"].parallel_map(tan_eval_categories)","66aca7fe":"bdf = df[df[\"Pieces\"] >= 5].groupby(\"Pieces\").apply(lambda x: x.sample(n=80000)).reset_index(drop=True)\nbbdf = bdf.groupby(\"Normalized WLD\").apply(lambda x: x.sample(n=400000)).reset_index(drop=True)","6332abcb":"plt.hist(bbdf[\"Normalized Evaluation\"])\nplt.show()","062748d1":"# r1bqk2r\/pp2ppbp\/2np1np1\/8\/4P3\/2N3P1\/PPP1NPBP\/R1BQK2R b KQkq - 4 8\ndef to_bitboard(fen):\n    boards = np.zeros((29, 8, 8), dtype=np.uint8)\n    board = chess.Board(fen)\n\n    piece_to_layer = {\n        'R': 1,\n        'N': 2,\n        'B': 3,\n        'Q': 4,\n        'K': 5,\n        'P': 6,\n        'p': 7,\n        'k': 8,\n        'q': 9,\n        'b': 10,\n        'n': 11,\n        'r': 12\n    }\n\n    piece_to_material = {\n        'R': 5,\n        'N': 3,\n        'B': 3,\n        'Q': 9,\n        'K': 0,\n        'P': 1,\n        'p': -1,\n        'k': 0,\n        'q': -9,\n        'b': -3,\n        'n': -3,\n        'r': -5\n    }\n\n    color = bool(board.turn)\n\n    cr = board.castling_rights\n    wkcastle = bool(cr & chess.H1)\n    wqcastle = bool(cr & chess.A1)\n    bkcastle = bool(cr & chess.H8)\n    bqcastle = bool(cr & chess.A8)\n\n    boards[0, :, :]  = color\n    boards[25, :, :] = wkcastle\n    boards[26, :, :] = wqcastle\n    boards[27, :, :] = bkcastle\n    boards[28, :, :] = bqcastle\n\n    material = 0\n\n    piece_map = board.piece_map()\n    for i, p in piece_map.items():\n        rank, file = to_square(i)\n        piece = p.symbol()\n        # Mark the position of the piece on the bitboard\n        boards[piece_to_layer[piece], rank, file] = 1\n        material += piece_to_material[piece]\n        # Attack maps\n        for sq in board.attacks(i):\n            attack_rank, attack_file = to_square(sq)\n            boards[piece_to_layer[piece]+12, attack_rank, attack_file] = 1\n\n    return boards\n\ndef to_square(number):\n    rank, file = divmod(number, 8)\n    return 7 - rank, file","ba05a6ab":"l = len(bbdf)\nbbdf = bbdf.sample(frac=1)\ntrain_df, test_df, cv_df = bbdf[:int(.8 * l)], bbdf[int(.8 * l): int(.9 * l)], bbdf[int(.9 * l):]","7102b1b0":"import gc\ngc.collect()","c0372dd6":"class ChessDataset(Dataset):\n    def __init__(self, df):\n        self.fens = torch.from_numpy(np.array([*map(to_bitboard, df[\"FEN\"])], dtype=np.uint8))\n        self.evals = torch.Tensor([[x] for x in df[\"Normalized Evaluation\"]])\n        self._len = len(self.evals)\n        \n    def __len__(self):\n        return self._len\n    \n    def __getitem__(self, index):\n        return self.fens[index], self.evals[index]\n\nd_train, d_test, d_cv = map(ChessDataset, [train_df, test_df, cv_df])","a031b04d":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Beeg model\n# model = nn.Sequential(\n#     nn.Conv2d(in_channels = 25, out_channels=200, kernel_size=5, padding=2),\n#     nn.ReLU(),\n#     nn.AvgPool2d(2, stride=(2, 2)),\n#     nn.BatchNorm2d(200),\n#     nn.Conv2d(200, 400, kernel_size=3, padding=1),\n#     nn.Flatten(),\n#     nn.Dropout(.1),\n#     nn.Linear(6400, 100),\n#     nn.Dropout(.6),\n#     nn.Tanh(),\n#     nn.Linear(100, 1)\n# ).to(device)\n\n# Architecture partially yoinked from geohotz\nmodel = nn.Sequential(\n    nn.Conv2d(29, 32, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 32, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 64, kernel_size=3, stride=2),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 128, kernel_size=3, stride=2),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Conv2d(128, 128, kernel_size=2, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Conv2d(128, 128, kernel_size=2, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Conv2d(128, 256, kernel_size=2, stride=2),\n    nn.Flatten(),\n    nn.Dropout(.5),\n    nn.Linear(256, 1)\n).to(device)\n\ndef init_weights(m):\n    try:\n        nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n    except Exception:\n        return\n\nmodel.apply(init_weights)\n    \n# model(next(iter(cv_loader))[0].float())","cffc272b":"cv_loader = DataLoader(dataset=d_cv, batch_size=512, shuffle=False, num_workers=1)\ntrain_loader = DataLoader(dataset=d_train, batch_size=512, shuffle=True, num_workers=1)\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters())","5196bdcd":"train_losses = []\ncv_losses = []\n\nfor epoch in range(40):\n    model.train()\n    running_loss = []\n    for data, target in train_loader:\n        optimizer.zero_grad()\n        data, target = data.to(device), target.to(device)\n        y_pred = model(data.float())\n        loss = criterion(y_pred, target)\n        running_loss.append(loss.item())\n        loss.backward()\n        optimizer.step()\n    train_losses.append(sum(running_loss) \/ len(running_loss))\n    print(f\"[TRAIN] epoch: {epoch:5}, loss: {train_losses[-1]:10}\", end=\"\\t\")\n    \n    with torch.no_grad():\n        model.eval()\n        running_loss = []\n        for data, target in cv_loader:\n            data, target = data.to(device), target.to(device)\n            y_pred = model(data.float())\n            loss = criterion(y_pred, target)\n            running_loss.append(loss.item())\n        cv_losses.append(sum(running_loss) \/ len(running_loss))\n        print(f\"[CV] epoch: {epoch:5}, loss: {cv_losses[-1]:10}\")","6100382f":"train_losses = np.array(train_losses)\ncv_losses = np.array(cv_losses)\nepochs = np.array([*range(1, len(train_losses) + 1)])\nplt.plot(epochs, train_losses)\nplt.plot(epochs, cv_losses)\nplt.legend([\"Train Loss\", \"CV Loss\"])\nplt.show()","e08d38d2":"Take a stratified sample based on pieces on the board and the category of the evaluation","0b833022":"The normalized evaluations are somewhat uniformly distributed.","554466e3":"Generate computed features of\n* Pieces on the board\n* Evaluation in pawns\n* Material advantage using accepted valuations of pieces\n* Cutoff material advantage - material advantage capped to 2 pawns\n* Win Lose Draw - put position into categories:\n  0. Black is absurdly winning\n  1. Black is convincingly winning\n  2. Drawish\n  3. White is convincingly winning\n  4. White is absurdly winning\n* Normalized Evaluation - arctan(evaluation in pawns \/ 3)\n* Normalized WLD - divide into three groups stratified by normalized evaluation\n  \nUsing material advantages however may be misleading since if a piece was just taken, the material advantage found by counting pieces and their values will yield a result that could be anywhere from 1 to 9 pawns off. This can introduce a lot of noise and detracts away from those positions where there truly is a material advantage."}}