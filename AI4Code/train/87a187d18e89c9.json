{"cell_type":{"8ac22109":"code","d0eef79e":"code","8cc6b0bf":"code","f326caa6":"code","537e31de":"code","839158c8":"code","7c8aa6e7":"code","d496934e":"code","290f32a5":"code","e987b9ae":"code","33a4836e":"code","5cdd52d4":"code","f5af0eb7":"code","701918ab":"code","eae54b98":"code","19b3116d":"code","ad3a7768":"code","72f1835b":"code","fe128bf1":"markdown"},"source":{"8ac22109":"import os\n\nTF_FOLDER = 'TF23_SSD_RESNET50' \nWORKSPACE = 'helmet'\nPROJECT = 'detector'\n\n# Bounding Box classes\nCLASSES = ['helmet','head','person'] \n\nRUN_DIR = os.getcwd() # Current dir\nTF_DIR = RUN_DIR + \"\/\" + TF_FOLDER\nTF_PROJECT_DIR = TF_DIR + \"\/\" + WORKSPACE + \"\/\" + PROJECT\nMODELS_DIR = RUN_DIR + \"\/\" + TF_FOLDER + \"\/models\"\nRESEARCH_DIR = MODELS_DIR + \"\/research\"\n\n# Pre-Trained model from Tensorflow 2 model zoo\nPRE_MODEL_FILE = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'\nPRE_MODEL_URL = 'http:\/\/download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'\nPRE_MODEL_TYPE = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8'\nPRE_MODEL_CHECKPOINT = PRE_MODEL_TYPE + '\/checkpoint\/ckpt-0'\nMY_PRE_MODEL_DIR = TF_PROJECT_DIR + '\/models\/ssd_resnet50_v1_fpn'\n\n# Kaggle dataset paths\nDATA_XML_DIR = '\/kaggle\/input\/hard-hat-detection\/annotations\/'\nDATA_IMAGES_DIR = '\/kaggle\/input\/hard-hat-detection\/images\/'\n\nSTEPS = 10000\nCHECKPOINT_EVERY = 1000\nBATCH_SIZE = 4\n","d0eef79e":"# Create project folder and install Tensorflow 2.3\nimport pathlib\nimport sys\nfrom os import path\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n!mkdir -p $TF_FOLDER\n%cd $TF_FOLDER\n!{sys.executable} -m pip install --upgrade tensorflow","8cc6b0bf":"# Tensorflow version check (Tested to work with 2.3.0)\n!{sys.executable} -c 'import tensorflow as tf; print(tf.__version__)' ","f326caa6":"# Download and extract Tensorflow models\nimport tensorflow as tf\n\ntf.get_logger().setLevel('ERROR') # Suppress TensorFlow logging\n\ndef download_model(model_url):    \n    model_dir = tf.keras.utils.get_file('tf_models.zip', model_url, extract=True, archive_format='zip', cache_subdir=TF_DIR)\n    return str(model_dir)\n\nTF_MODEL_PATH = TF_DIR + '\/tf_models.zip'\n\nif not path.isfile(TF_MODEL_PATH):\n    PATH_TO_MODEL_DIR = download_model('https:\/\/github.com\/tensorflow\/models\/archive\/master.zip')\n\nPATH_TO_EXT_MODEL_DIR = TF_DIR + \"\/models-master\"    \n\nif not path.isdir(MODELS_DIR):\n    os.rename(PATH_TO_EXT_MODEL_DIR, MODELS_DIR)","537e31de":"%cd $RESEARCH_DIR\nsys.path.append(RESEARCH_DIR)\n!protoc object_detection\/protos\/*.proto --python_out=.","839158c8":"# COCO API installation\n%cd $RESEARCH_DIR\n!git clone https:\/\/github.com\/cocodataset\/cocoapi.git\n%cd cocoapi\/PythonAPI\n!make\n!cp -r pycocotools $RESEARCH_DIR","7c8aa6e7":"#Install the Object Detection API\n%cd $RESEARCH_DIR\nAPI_FILE = RESEARCH_DIR + \"\/object_detection\/packages\/tf2\/setup.py\"\n!cp $API_FILE .\n!{sys.executable} -m pip install .","d496934e":"# Create folders for splitting the data\n%cd $TF_DIR\n!mkdir -p $WORKSPACE\n%cd $WORKSPACE\n!mkdir -p $PROJECT\n%cd $PROJECT\n!mkdir -p images\n%cd images\nSPLIT_DIR = os.getcwd()\n!mkdir -p train\n!mkdir -p test","290f32a5":"# Split PascalVOC-format datas for training and testing\nimport re\nfrom shutil import copyfile\nimport math\nimport random\n\n\ndef iterate_dir(source_images, source_xml, dest, ratio, copy_xml):\n    source_images = source_images.replace('\\\\', '\/')\n    source_xml = source_xml.replace('\\\\', '\/')\n    dest = dest.replace('\\\\', '\/')\n    train_dir = os.path.join(dest, 'train')\n    test_dir = os.path.join(dest, 'test')\n\n    if os.listdir(train_dir):\n        print('train - directory not Empty, Clean it before split!')\n        return\n\n    if os.listdir(test_dir):\n        print('test - directory not Empty, Clean it before split!')\n        return\n    \n    if not os.path.exists(train_dir):\n        os.makedirs(train_dir)\n    if not os.path.exists(test_dir):\n        os.makedirs(test_dir)\n\n    images = [f for f in os.listdir(source_images)\n              if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(.jpg|.jpeg|.png)$', f)]\n\n    num_images = len(images)\n    num_test_images = math.ceil(ratio*num_images)\n\n    for i in range(num_test_images):\n        idx = random.randint(0, len(images)-1)\n        filename = images[idx]\n        copyfile(os.path.join(source_images, filename),\n                 os.path.join(test_dir, filename))\n        if copy_xml:\n            xml_filename = os.path.splitext(filename)[0]+'.xml'\n            copyfile(os.path.join(source_xml, xml_filename),\n                     os.path.join(test_dir,xml_filename))\n        images.remove(images[idx])\n\n    for filename in images:\n        copyfile(os.path.join(source_images, filename),\n                 os.path.join(train_dir, filename))\n        if copy_xml:\n            xml_filename = os.path.splitext(filename)[0]+'.xml'\n            copyfile(os.path.join(source_xml, xml_filename),\n                     os.path.join(train_dir, xml_filename))\n\niterate_dir(DATA_IMAGES_DIR, DATA_XML_DIR, SPLIT_DIR, 0.1, True)","e987b9ae":"# Write Classes to TF_PROJECT_DIR\/Annotations\/label_map.pbtxt\n\n%cd $TF_PROJECT_DIR\n!mkdir -p annotations\n\ndef label_map(objname, LABEL_MAP_FILE, NEXT):\n    with open(LABEL_MAP_FILE, 'a') as the_file:\n        the_file.write('item\\n')\n        the_file.write('{\\n')\n        the_file.write('id : {}'.format(int(NEXT)))\n        the_file.write('\\n')\n        the_file.write(\"name : '{0}'\".format(str(objname)))\n        the_file.write('\\n')\n        the_file.write('}\\n')\n\nLABEL_MAP_FILE = TF_PROJECT_DIR + '\/annotations\/label_map.pbtxt'\nNEXT = 1\n\nif not path.isfile(LABEL_MAP_FILE):\n    for CLASS in CLASSES:        \n        label_map(CLASS, LABEL_MAP_FILE, NEXT)\n        NEXT = NEXT + 1\n","33a4836e":"# Write tfrecord - files\nimport glob\nimport pandas as pd\nimport io\nimport xml.etree.ElementTree as ET\nimport tensorflow as tf\nfrom PIL import Image\nfrom object_detection.utils import dataset_util, label_map_util\nfrom collections import namedtuple\n\nlabel_map = label_map_util.load_labelmap(LABEL_MAP_FILE)\nlabel_map_dict = label_map_util.get_label_map_dict(label_map)\n\ntf.compat.v1.disable_eager_execution() \ntf.compat.v1.reset_default_graph()\npng_img_pl = tf.compat.v1.placeholder(tf.string)\npng_enc = tf.image.decode_png(png_img_pl, channels = 3)\n    # Set how much quality of image you would like to retain while conversion\npng_to_jpeg = tf.image.encode_jpeg(png_enc, format = 'rgb', quality = 100)\n\ndef xml_to_csv(path):\n\n    xml_list = []\n    for xml_file in glob.glob(path + '\/*.xml'):\n        tree = ET.parse(xml_file)\n        root = tree.getroot()\n        for member in root.findall('object'):\n            value = (root.find('filename').text,\n                         int(root.find('size').find('width').text),\n                         int(root.find('size').find('height').text),\n                         member[0].text,\n                         int(member.find(\"bndbox\").find('xmin').text),\n                         int(member.find(\"bndbox\").find('ymin').text),\n                         int(member.find(\"bndbox\").find('xmax').text),\n                         int(member.find(\"bndbox\").find('ymax').text)\n                        )\n            xml_list.append(value)\n    column_name = ['filename', 'width', 'height',\n                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n    xml_df = pd.DataFrame(xml_list, columns=column_name)\n    return xml_df\n\n\ndef class_text_to_int(row_label):\n    return label_map_dict[row_label]\n\n\ndef split(df, group):\n    data = namedtuple('data', ['filename', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\ndef is_png_image(filename):\n    ext = os.path.splitext(filename)[1].lower()\n    return ext == '.png'\n\ndef convert_png_to_jpeg(img):\n    with tf.compat.v1.Session() as sess:    \n        return sess.run(png_to_jpeg, feed_dict = {png_img_pl: img})\n\n\ndef create_tfrec_file(group, path):\n    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n        image_data = fid.read()\n        \n        if is_png_image(os.path.join(path, '{}'.format(group.filename))): # If files are .png - format convert them on the fly\n            image_data = convert_png_to_jpeg(image_data)\n\n        encoded_jpg = image_data    \n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    width, height = image.size\n\n    filename = group.filename.encode('utf8')\n    image_format = b'jpg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    for index, row in group.object.iterrows():\n        xmins.append(row['xmin'] \/ width)\n        xmaxs.append(row['xmax'] \/ width)\n        ymins.append(row['ymin'] \/ height)\n        ymaxs.append(row['ymax'] \/ height)\n        classes_text.append(row['class'].encode('utf8'))\n        classes.append(class_text_to_int(row['class']))\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image\/height': dataset_util.int64_feature(height),\n        'image\/width': dataset_util.int64_feature(width),\n        'image\/filename': dataset_util.bytes_feature(filename),\n        'image\/source_id': dataset_util.bytes_feature(filename),\n        'image\/encoded': dataset_util.bytes_feature(encoded_jpg),\n        'image\/format': dataset_util.bytes_feature(image_format),\n        'image\/object\/bbox\/xmin': dataset_util.float_list_feature(xmins),\n        'image\/object\/bbox\/xmax': dataset_util.float_list_feature(xmaxs),\n        'image\/object\/bbox\/ymin': dataset_util.float_list_feature(ymins),\n        'image\/object\/bbox\/ymax': dataset_util.float_list_feature(ymaxs),\n        'image\/object\/class\/text': dataset_util.bytes_list_feature(classes_text),\n        'image\/object\/class\/label': dataset_util.int64_list_feature(classes),\n    }))\n    return tf_example\n\n\ndef create_tfrecord(OUTPUT,INPUT_IMAGE,INPUT_XML):        \n    writer = tf.io.TFRecordWriter(OUTPUT)\n    path = os.path.join(INPUT_IMAGE)\n    examples = xml_to_csv(INPUT_XML)\n    grouped = split(examples, 'filename')\n    for group in grouped:\n        tf_ref_file = create_tfrec_file(group, path)\n        writer.write(tf_ref_file.SerializeToString())        \n    print('Successfully created the TFRecord file: {}'.format(OUTPUT))\n    writer.close()\n\n#Train\nINPUT_IMAGE_DIR = SPLIT_DIR + \"\/train\" \nINPUT_XML_DIR = INPUT_IMAGE_DIR \nOUTPUT_FILE = TF_PROJECT_DIR + \"\/annotations\/train.record\" \nif not path.isfile(OUTPUT_FILE):\n    create_tfrecord(OUTPUT_FILE,INPUT_IMAGE_DIR,INPUT_XML_DIR)\n\n#Test\nINPUT_IMAGE_DIR = SPLIT_DIR + \"\/test\" \nINPUT_XML_DIR = INPUT_IMAGE_DIR \nOUTPUT_FILE = TF_PROJECT_DIR + \"\/annotations\/test.record\" \nif not path.isfile(OUTPUT_FILE):\n    create_tfrecord(OUTPUT_FILE,INPUT_IMAGE_DIR,INPUT_XML_DIR)\n","5cdd52d4":"import shutil\n\nshutil.rmtree(SPLIT_DIR) # We do not need these anymore\n\n%cd $TF_DIR\n!mkdir -p pre-trained-models\n%cd pre-trained-models\nPRE_MODEL_DIR = os.getcwd() # Current dir","f5af0eb7":"# Download and extract models\nimport tensorflow as tf\n\ndef download_pre_model(pre_model_url):    \n    model_dir = tf.keras.utils.get_file(PRE_MODEL_FILE, pre_model_url, extract=True, cache_subdir=PRE_MODEL_DIR)\n    return str(model_dir)\n\nPRE_MODEL_PATH = PRE_MODEL_DIR +'\/'+ PRE_MODEL_FILE\n\nif not path.isfile(PRE_MODEL_PATH):\n    PATH_TO_PRE_MODEL_DIR = download_pre_model(PRE_MODEL_URL)","701918ab":"if path.isfile(PRE_MODEL_PATH):\n    os.remove(PRE_MODEL_PATH) # extracted, so not needed anymore\n    \n%cd $TF_PROJECT_DIR\n!mkdir -p models\n%cd models\n!mkdir -p $MY_PRE_MODEL_DIR\n%cd $MY_PRE_MODEL_DIR\n\nPATH_TO_PRE_PIPELINE_INPUT = PRE_MODEL_DIR + \"\/\" + PRE_MODEL_TYPE + \"\/pipeline.config\"\nPATH_TO_PRE_PIPELINE_OUTPUT = MY_PRE_MODEL_DIR + \"\/pipeline.config\"\n\nif not path.isfile(PATH_TO_PRE_PIPELINE_OUTPUT):\n    copyfile(PATH_TO_PRE_PIPELINE_INPUT, PATH_TO_PRE_PIPELINE_OUTPUT)","eae54b98":"# Change some variables in pipeline_config\nimport string\n\ndef in_pipeline_change(filename, old_string, new_string):    \n    with open(filename) as f:\n        s = f.read()\n        if old_string not in s:\n            print('\"{old_string}\" not found in {filename}.'.format(**locals()))\n            return\n    \n    with open(filename, 'w') as f:\n        print('Changing \"{old_string}\" to \"{new_string}\" in {filename}'.format(**locals()))\n        s = s.replace(old_string, new_string, 1)\n        f.write(s)\n\n\nCLASS_COUNT = len(CLASSES)\nNUM_CLASSES = \"num_classes: \" + str(CLASS_COUNT)\nBATCHSIZE = \"batch_size: \" + str(BATCH_SIZE)\nCHECKPOINT = 'fine_tune_checkpoint: \"' + PRE_MODEL_DIR + '\/' + PRE_MODEL_CHECKPOINT + '\"'\nCHECKPOINT_TYPE = 'fine_tune_checkpoint_type: \"detection\"'\nTPU = 'use_bfloat16: false' # Set true if you train with TPU\nLABEL_MAP_FILE = 'label_map_path: \"' + TF_PROJECT_DIR + '\/annotations\/label_map.pbtxt\"'\nTRAINING_FILE = 'input_path: \"' + TF_PROJECT_DIR + '\/annotations\/train.record\"'\nTESTING_FILE = 'input_path: \"' + TF_PROJECT_DIR + '\/annotations\/test.record\"'\n\nPIPELINE_FILE = MY_PRE_MODEL_DIR + \"\/pipeline.config\"\n\nin_pipeline_change(PIPELINE_FILE, 'num_classes: 90', NUM_CLASSES)\nin_pipeline_change(PIPELINE_FILE, 'batch_size: 64', BATCHSIZE)\nin_pipeline_change(PIPELINE_FILE, 'fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"', CHECKPOINT)\nin_pipeline_change(PIPELINE_FILE, 'fine_tune_checkpoint_type: \"classification\"', CHECKPOINT_TYPE)\nin_pipeline_change(PIPELINE_FILE, 'use_bfloat16: true', TPU)\nin_pipeline_change(PIPELINE_FILE, 'label_map_path: \"PATH_TO_BE_CONFIGURED\"', LABEL_MAP_FILE) \nin_pipeline_change(PIPELINE_FILE, 'label_map_path: \"PATH_TO_BE_CONFIGURED\"', LABEL_MAP_FILE) \nin_pipeline_change(PIPELINE_FILE, 'input_path: \"PATH_TO_BE_CONFIGURED\"', TRAINING_FILE) \nin_pipeline_change(PIPELINE_FILE, 'input_path: \"PATH_TO_BE_CONFIGURED\"', TESTING_FILE)\n\n","19b3116d":"# Train model\n\n%cd $TF_PROJECT_DIR\nTF2_MODEL_TRAINER_SOURCE = RESEARCH_DIR + \"\/object_detection\/model_main_tf2.py\"\nTF2_MODEL_TRAINER_DEST = TF_PROJECT_DIR + \"\/model_main_tf2.py\"\ncopyfile(TF2_MODEL_TRAINER_SOURCE, TF2_MODEL_TRAINER_DEST)\n\nMY_PRE_MODEL_PILELINEFILE = MY_PRE_MODEL_DIR + '\/pipeline.config'\n\ndef train_tf2_model(TF2_MODEL_TRAINER_DEST, MY_PRE_MODEL_DIR, MY_PRE_MODEL_PILELINEFILE):\n    \n    !{sys.executable} $TF2_MODEL_TRAINER_DEST --model_dir=$MY_PRE_MODEL_DIR --pipeline_config_path=$MY_PRE_MODEL_PILELINEFILE --num_train_steps=$STEPS --checkpoint_every_n=$CHECKPOINT_EVERY\n    \ntrain_tf2_model(TF2_MODEL_TRAINER_DEST, MY_PRE_MODEL_DIR, MY_PRE_MODEL_PILELINEFILE)\n","ad3a7768":"# Export model\nfrom IPython.lib import backgroundjobs as bg\n\njobs = bg.BackgroundJobManager()\n\n%cd $TF_PROJECT_DIR\nTF2_MODEL_EXPORT_SOURCE = RESEARCH_DIR + \"\/object_detection\/exporter_main_v2.py\"\nTF2_MODEL_EXPORT_DEST = TF_PROJECT_DIR + \"\/exporter_main_v2.py\"\ncopyfile(TF2_MODEL_EXPORT_SOURCE, TF2_MODEL_EXPORT_DEST)\n\nMY_PRE_MODEL_PILELINEFILE = MY_PRE_MODEL_DIR + '\/pipeline.config'\n\ndef export_tf2_model(TF2_MODEL_EXPORTER, MY_PRE_MODEL_PILELINEFILE, TRAINED_MODEL_DIR):\n    \n    %run $TF2_MODEL_EXPORTER --input_type=image_tensor --pipeline_config_path=$MY_PRE_MODEL_PILELINEFILE --trained_checkpoint_dir=$TRAINED_MODEL_DIR --output_directory=.\/models\/exported-model\n    \njobs.new('export_tf2_model(TF2_MODEL_EXPORT_DEST, MY_PRE_MODEL_PILELINEFILE, MY_PRE_MODEL_DIR)')\njobs.status()","72f1835b":"# Evaluate model\n\neval_jobs = bg.BackgroundJobManager()\n\n%cd $TF_PROJECT_DIR\nTF2_MODEL_TRAINER_SOURCE = RESEARCH_DIR + \"\/object_detection\/model_main_tf2.py\"\nTF2_MODEL_TRAINER_DEST = TF_PROJECT_DIR + \"\/model_main_tf2.py\"\ncopyfile(TF2_MODEL_TRAINER_SOURCE, TF2_MODEL_TRAINER_DEST)\n\nMY_PRE_MODEL_PILELINEFILE = MY_PRE_MODEL_DIR + '\/pipeline.config'\n\ndef eval_tf2_model(TF2_MODEL_TRAINER_DEST, MY_PRE_MODEL_DIR, MY_PRE_MODEL_PILELINEFILE):\n    \n    !{sys.executable} $TF2_MODEL_TRAINER_DEST --model_dir=$MY_PRE_MODEL_DIR --pipeline_config_path=$MY_PRE_MODEL_PILELINEFILE --checkpoint_dir=$MY_PRE_MODEL_DIR    \n    \neval_jobs.new('eval_tf2_model(TF2_MODEL_TRAINER_DEST, MY_PRE_MODEL_DIR, MY_PRE_MODEL_PILELINEFILE)')\neval_jobs.status()\n","fe128bf1":"BBox helmet detector with Tensorflow (>=) 2.3 and Retinanet (SSD with Resnet 50 v1) Object detection model on COCO 2017 dataset\n- Suggested Metrics in last cell"}}