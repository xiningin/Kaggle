{"cell_type":{"8f34f29d":"code","42b3d1c1":"code","f7dfe306":"code","be598b98":"code","81784d4c":"code","9eb00cf0":"code","b3d5bc4d":"code","202be7c6":"code","d84c4b54":"code","7d904b79":"code","31b04a36":"code","477759d1":"code","c564188a":"code","be6dd70e":"code","297a7fca":"code","86acb662":"code","956421a5":"code","f57ddade":"code","71c6c578":"code","fdd194f3":"code","3a687d50":"code","99037f62":"code","8af8f1bb":"code","cbaa768f":"code","03768b3c":"code","a24dce57":"code","35ca1850":"code","3cf30b61":"code","71960ecb":"code","d6445d1c":"code","23309a3a":"code","c50f097b":"code","09c949f2":"code","8bed0330":"code","c50b3fc6":"code","d446c919":"code","89998f24":"code","26243865":"code","312ac1a0":"code","395a53d2":"code","4a440b15":"code","64a05278":"code","3fd8d577":"code","4162b386":"code","52fc6c68":"code","450a43d4":"code","32c5f19d":"code","d9ad92dd":"code","9661cafd":"code","4fcdd884":"code","27928239":"code","67e18669":"code","02fd9f6c":"code","58c5b67b":"code","94d4904e":"code","7892ace1":"code","6d9f3d22":"code","3f7538ef":"code","fad1b582":"code","70339660":"code","9539a77c":"code","1d4e2447":"code","cfb29775":"code","09f809d5":"code","66488e21":"code","bee2dfa6":"code","51f40ec2":"code","c1367f52":"code","d47dcdf7":"code","ca665946":"code","2a34e16d":"code","a82c06e1":"code","3901552b":"code","741ae898":"code","fd9bab1b":"code","32d5281a":"code","7747696d":"code","03f3c3b6":"code","842abb7c":"code","c49d5152":"code","6309a33f":"code","4429756d":"code","77726dcc":"code","25fe1988":"code","019089ac":"markdown","407c4fed":"markdown","e7414479":"markdown","3c007bd5":"markdown","ad09dd4b":"markdown","ddc66dbc":"markdown","df7c5fa1":"markdown","5a0603c0":"markdown","1719fa0d":"markdown","9e098da5":"markdown","33bab19c":"markdown","d4b8ed40":"markdown","7a921d16":"markdown","be1f30bf":"markdown","8a74375b":"markdown","fc2edeb1":"markdown","c9b618b9":"markdown"},"source":{"8f34f29d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.metrics import precision_recall_curve, auc, roc_curve\n\nfrom scipy import interp\nimport math\nfrom scipy.stats import norm\nfrom scipy import stats\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings('ignore') # Disabling warnimgs for clearer outputs\npd.options.display.max_columns = 50 # Pandas option to increase max number of columns to display\nplt.style.use('ggplot') # Setting default plot style\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42b3d1c1":"train_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n# combine = [train_df, test_df]\n\nprint(\"Shape of train data\", train_df.shape)\nprint(\"Shape of test data\", test_df.shape)","f7dfe306":"## Columns in the dataset\ntrain_df.info()","be598b98":"train_df.head()","81784d4c":"## Dropping columns from both the datasets. They are of no particular use\ntrain_df = train_df.drop(['Ticket', 'Cabin', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin', 'PassengerId'], axis=1)","9eb00cf0":"## Quick summary of the dataset\ntrain_df.describe()","b3d5bc4d":"## Distribution of 'Survived' class\nprint(\"# Distribution of 'Survived' class:\\n\",train_df['Survived'].value_counts())\nprint(\"% Records survived: \", round((train_df['Survived'].value_counts()[1]\/len(train_df))*100,2))\n#histogram\ntrain_df['Survived'].hist()","202be7c6":"## Missing data in train data\ntrain_df.isnull().sum()[train_df.isnull().sum()>0]","d84c4b54":"## Missing data in test data\ntest_df.isnull().sum()[test_df.isnull().sum()>0]","7d904b79":"## Fare\ntest_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\n\n## Embarked\ntrain_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])","31b04a36":"train_df['title']=train_df['Name'].apply(lambda x: x.split('.')[0].split(',')[1].strip())\ntest_df['title']=test_df['Name'].apply(lambda x: x.split('.')[0].split(',')[1].strip())","477759d1":"train_df['title'].unique()","c564188a":"newTitles = {\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"}\n\n#Copied","be6dd70e":"train_df['title'] = train_df['title'].map(newTitles)\ntest_df['title'] = test_df['title'].map(newTitles)","297a7fca":"train_df.groupby(['title','Sex']).Age.mean().plot(kind='barh')","86acb662":"def newAge (cols):\n    title=cols[0]\n    Sex=cols[1]\n    Age=cols[2]\n    if pd.isnull(Age):\n        if title=='Master' and Sex==\"male\":\n            return 4.57\n        elif title=='Miss' and Sex=='female':\n            return 21.8\n        elif title=='Mr' and Sex=='male': \n            return 32.37\n        elif title=='Mrs' and Sex=='female':\n            return 35.72\n        elif title=='Officer' and Sex=='female':\n            return 49\n        elif title=='Officer' and Sex=='male':\n            return 46.56\n        elif title=='Royalty' and Sex=='female':\n            return 40.50\n        else:\n            return 42.33\n    else:\n        return Age\n    \n#copied","956421a5":"train_df['Age'] = train_df[['title','Sex','Age']].apply(newAge, axis=1)\ntest_df['Age'] = test_df[['title','Sex','Age']].apply(newAge, axis=1)","f57ddade":"## Missing data in train data\ntrain_df.isnull().sum()[train_df.isnull().sum()>0]","71c6c578":"## Missing data in test data\ntest_df.isnull().sum()[test_df.isnull().sum()>0]","fdd194f3":"train_df.info()","3a687d50":"## Univariate plots: Frequency\n\ndef plotFrequency(cats,train_df,test_df):\n    #\"A plot for visualize categorical data, showing both absolute and relative frequencies\"\n    \n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    axes = axes.flatten()\n    \n    total = float(len(train_df[cats]))\n    sns.countplot(train_df[cats].sort_values (), palette='plasma', ax= axes[0])\n    \n    ax = axes[0]\n    \n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x() + p.get_width() \/ 2.,\n                height + 10,\n                '{:1.2f}%'.format((height \/ total) * 100),\n                ha=\"center\")\n    \n    ax.set_ylabel('count', fontsize=15)\n        \n    total2 = float(len(test_df[cats]))\n    sns.countplot(test_df[cats].sort_values (), palette='plasma', ax= axes[1])\n    \n    ax2 = axes[1]\n    \n    for p in ax2.patches:\n        height2 = p.get_height()\n        ax2.text(p.get_x() + p.get_width() \/ 2.,\n                height2 + 10,\n                '{:1.2f}%'.format((height2 \/ total2) * 100),\n                ha=\"center\")\n    \n    ax2.set_ylabel('count', fontsize=15)","99037f62":"# Selecting categorical data for univariate analysis\ncatg = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n\nfor ctg in catg:\n    plotFrequency(ctg, train_df, test_df)","8af8f1bb":"def plotsurvival(cats, data, cols):\n    #\"A plot for bivariate analysis\"\n    fig, axes = plt.subplots(math.ceil(len(cats) \/ cols), cols, figsize=(20*(cols\/3), 12*(cols\/3)))\n    axes = axes.flatten()\n\n    for ax, cat in zip(axes, cats):\n        if cat == 'Survived':\n            sns.countplot(train_df[cat], ax=ax)\n\n        else:\n\n            sns.countplot(x=cat,\n                          data=data,\n                          hue='Survived',\n                          ax=ax)\n            ax.legend(title='Survived?',\n                      loc='upper right',\n                      labels=['No', 'Yes'])\n\n        plt.ylabel('Count', fontsize=15)","cbaa768f":"plotsurvival(catg, train_df, cols =3)","03768b3c":"train_df['Family'] = train_df['SibSp'] + train_df['Parch']\ntest_df['Family'] = test_df['SibSp'] + test_df['Parch']","a24dce57":"sns.countplot(x='Family', data=train_df, hue='Survived')\nplt.legend(title='Survived?', loc='upper right', labels=['No', 'Yes'])","35ca1850":"def fam_size (cols):\n    if cols==0:\n        return 'No family'\n    elif cols>=1 and cols<=3:\n        return 'Small family'\n    else:\n        return 'Large family'","3cf30b61":"train_df['Fam_size'] = train_df['Family'].apply(fam_size)\ntest_df['Fam_size'] = test_df['Family'].apply(fam_size)","71960ecb":"sns.countplot(x='Fam_size', data=train_df, hue='Survived')\nplt.legend(title='Survived?', loc='upper right', labels=['No', 'Yes'])","d6445d1c":"train_df = train_df.drop('Family', axis=1)\ntest_df = test_df.drop('Family', axis=1)","23309a3a":"train_df.info()","c50f097b":"test_df.info()","09c949f2":"## Dropping columns from both the datasets\ntrain_df = train_df.drop(['Name'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)","8bed0330":"## LabelEncoding 'Sex' feature\n\ntrain_df['Sex'] = train_df['Sex'].replace(['male'], 0)\ntrain_df['Sex'] = train_df['Sex'].replace(['female'], 1)\n\ntest_df['Sex'] = test_df['Sex'].replace(['male'], 0)\ntest_df['Sex'] = test_df['Sex'].replace(['female'], 1)","c50b3fc6":"def plot_3chart(df, feature):\n    import matplotlib.gridspec as gridspec\n    from matplotlib.ticker import MaxNLocator\n    # Creating a customized chart. and giving in figsize and everything.\n    fig = plt.figure(constrained_layout=True, figsize=(12, 8))\n    # creating a grid of 3 cols and 3 rows.\n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n\n    # Customizing the histogram grid.\n    ax1 = fig.add_subplot(grid[0, :2])\n    # Set the title.\n    ax1.set_title('Histogram')\n    # plot the histogram.\n    sns.distplot(df.loc[:, feature],\n                 hist=True,\n                 kde=True,\n                 fit=norm,\n                 ax=ax1,\n                 color='#e74c3c')\n    ax1.legend(labels=['Normal', 'Actual'])\n\n    # customizing the QQ_plot.\n    ax2 = fig.add_subplot(grid[1, :2])\n    # Set the title.\n    ax2.set_title('Probability Plot')\n    # Plotting the QQ_Plot.\n    stats.probplot(df.loc[:, feature].fillna(np.mean(df.loc[:, feature])),\n                   plot=ax2)\n    ax2.get_lines()[0].set_markerfacecolor('#e74c3c')\n    ax2.get_lines()[0].set_markersize(12.0)\n\n    # Customizing the Box Plot.\n    ax3 = fig.add_subplot(grid[:, 2])\n    # Set title.\n    ax3.set_title('Box Plot')\n    # Plotting the box plot.\n    sns.boxplot(df.loc[:, feature], orient='v', ax=ax3, color='#e74c3c')\n    ax3.yaxis.set_major_locator(MaxNLocator(nbins=24))\n\n    plt.suptitle(f'{feature}', fontsize=24)","d446c919":"plot_3chart(train_df, 'Age')\nplot_3chart(train_df, 'Fare')","89998f24":"# Listing most related continious values to target.\ntrain_corr = train_df[['Survived', 'Age', 'Fare']].corr(method='spearman'\n                                                       ).abs().unstack().sort_values(kind='quicksort', ascending=False).reset_index()\n\ntrain_corr.rename(columns={\n    'level_0': 'Feature A',\n    'level_1': 'Feature B',\n    0: 'Correlation Coefficient'}, inplace=True)\n\ntrain_corr[(train_corr['Feature A'] == 'Survived')].style.background_gradient(cmap='summer_r')","26243865":"## Bucketing Age\ntrain_df['AgeBin'], bins = pd.qcut(train_df['Age'],q = 5, retbins=True, labels=False)\ntest_df['AgeBin'] = pd.cut(test_df['Age'],bins = bins, labels=False, include_lowest = True)","312ac1a0":"train_df = train_df.drop('Age', axis=1)\ntest_df = test_df.drop('Age', axis=1)","395a53d2":"## Bucketing Fare\ntrain_df['FareBin'], bins2 = pd.qcut(train_df['Fare'],q = 5, retbins=True, labels=False)\ntest_df['FareBin'] = pd.cut(test_df['Fare'],bins = bins2, labels=False, include_lowest = True)","4a440b15":"train_df = train_df.drop('Fare', axis=1)\ntest_df = test_df.drop('Fare', axis=1)","64a05278":"# Listing most related continious values to target.\ntrain_corr = train_df[['Survived', 'AgeBin', 'FareBin']].corr(method='spearman'\n                                                       ).abs().unstack().sort_values(kind='quicksort', ascending=False).reset_index()\n\ntrain_corr.rename(columns={\n    'level_0': 'Feature A',\n    'level_1': 'Feature B',\n    0: 'Correlation Coefficient'}, inplace=True)\n\ntrain_corr[(train_corr['Feature A'] == 'Survived')].style.background_gradient(cmap='summer_r')","3fd8d577":"train_df.info()","4162b386":"# train_sex = pd.get_dummies(train_df['Sex'], prefix='Sex')\n# test_sex = pd.get_dummies(test_df['Sex'], prefix='Sex')\n\ntrain_embk = pd.get_dummies(train_df['Embarked'], prefix='Embarked')\ntest_embk = pd.get_dummies(test_df['Embarked'], prefix='Embarked')\n\ntrain_title = pd.get_dummies(train_df['title'], prefix='Title')\ntest_title = pd.get_dummies(test_df['title'], prefix='Title')\n\ntrain_fam = pd.get_dummies(train_df['Fam_size'], prefix='Fam')\ntest_fam = pd.get_dummies(test_df['Fam_size'], prefix='Fam')","52fc6c68":"train_df2 = pd.concat([train_df, train_embk, train_title, train_fam], axis =1)\ntest_df2 = pd.concat([test_df, test_embk, test_title, test_fam], axis =1)\n\ntrain_df2 = train_df2.drop(['Embarked','title', 'Fam_size'], axis=1)\ntest_df2 = test_df2.drop(['Embarked','title', 'Fam_size'], axis=1)","450a43d4":"train_df2.info()","32c5f19d":"test_df2.info()","d9ad92dd":"X_train_1 = train_df2.drop(\"Survived\", axis=1)\nY_train_1 = train_df2[\"Survived\"]\nX_test  = test_df2\nX_train_1.shape, Y_train_1.shape, X_test.shape","9661cafd":"from sklearn.model_selection import train_test_split\nX_train, X_valid, Y_train, Y_valid = train_test_split(X_train_1, Y_train_1, test_size=0.20, random_state=42)","4fcdd884":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nimport xgboost\nimport lightgbm as lgb\n\nfrom mlxtend.classifier import StackingClassifier\n\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, learning_curve, cross_validate, train_test_split, KFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, plot_roc_curve, auc, make_scorer\nfrom sklearn.model_selection import GridSearchCV\n\nimport time","27928239":"## Function to get cross validated scores for each estimator\n\ndef model_check(X, y, estimators, cv):\n    model_table = pd.DataFrame()\n\n    row_index = 0\n    for est in estimators:\n\n        MLA_name = est.__class__.__name__\n        model_table.loc[row_index, 'Model Name'] = MLA_name\n\n        cv_results = cross_validate(est, X, y, cv=cv,\n            scoring='accuracy',\n            return_train_score=True,\n            n_jobs=-1\n        )\n\n        model_table.loc[row_index, 'Train Accuracy Mean'] = cv_results['train_score'].mean()\n        model_table.loc[row_index, 'Test Accuracy Mean'] = cv_results['test_score'].mean()\n        model_table.loc[row_index, 'Test Std'] = cv_results['test_score'].std()\n        model_table.loc[row_index, 'Time'] = cv_results['fit_time'].mean()\n\n        row_index += 1\n\n    model_table.sort_values(by=['Test Accuracy Mean'],ascending=False, inplace=True)\n\n    return model_table","67e18669":"## Classifiers\n\ncv = StratifiedKFold(10, shuffle=True, random_state=42)\n\nlogreg = LogisticRegression(n_jobs=-1, solver='newton-cg')\n\nsvc = SVC(probability=True)\n\nknn = KNeighborsClassifier(n_neighbors = 6)\n\ngaussianNB = GaussianNB()\n\nperceptron = Perceptron()\n\nlinear_svc = LinearSVC()\n\nsgd = SGDClassifier()\n\ndecision_tree = DecisionTreeClassifier()\n\nrandom_forest = RandomForestClassifier(criterion='gini',\n                                       n_estimators=1750,\n                                       max_depth=7,\n                                       min_samples_split=6,\n                                       min_samples_leaf=6,\n                                       max_features='auto',\n                                       oob_score=True,\n                                       random_state=42,\n                                       n_jobs=-1,\n                                       verbose=0)\n\nxg_boost = xgboost.XGBClassifier(n_estimators=2800, min_child_weight=0.1,\n                                 learning_rate=0.002,\n                                 max_depth=2,\n                                 subsample=0.47,\n                                 colsample_bytree=0.35,\n                                 gamma=0.4,\n                                 reg_lambda=0.4,\n                                 random_state=42,\n                                 n_jobs=-1)\n\nlgbm = lgb.LGBMClassifier(max_bin=4,num_iterations=550,\n                        learning_rate=0.01,\n                        max_depth=3,\n                        num_leaves=7,\n                        colsample_bytree=0.35,\n                        random_state=42,\n                        n_jobs=-1)\n\ngbClassifier = GradientBoostingClassifier(random_state=42)\n\nmlp = MLPClassifier(random_state=42)\n\nestimators = [logreg, svc, knn, gaussianNB, perceptron, linear_svc, sgd, decision_tree, random_forest, xg_boost, lgbm, gbClassifier, mlp]","02fd9f6c":"raw_models = model_check(X_train_1, Y_train_1, estimators, cv)\ndisplay(raw_models.style.background_gradient(cmap='summer_r'))","58c5b67b":"sclf = StackingClassifier(classifiers= [xg_boost, svc, random_forest],\n                         use_probas= True,\n                         meta_classifier= lgbm)","94d4904e":"sclf_score = cross_val_score(sclf, X_train_1, Y_train_1, cv = 3, scoring='accuracy')\n\nprint(\"sclf score: \", sclf_score.mean())\nprint(\"sclf score std: \", sclf_score.std())","7892ace1":"def m_roc(estimators, cv, X, y):\n\n    fig, axes = plt.subplots(math.ceil(len(estimators) \/ 2),\n                             2,\n                             figsize=(25, 50))\n    axes = axes.flatten()\n\n    for ax, estimator in zip(axes, estimators):\n        tprs = []\n        aucs = []\n        mean_fpr = np.linspace(0, 1, 100)\n\n        for i, (train, test) in enumerate(cv.split(X, y)):\n            estimator.fit(X.loc[train], y.loc[train])\n            viz = plot_roc_curve(estimator,\n                                 X.loc[test],\n                                 y.loc[test],\n                                 name='ROC fold {}'.format(i),\n                                 alpha=0.3,\n                                 lw=1,\n                                 ax=ax)\n            interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n            interp_tpr[0] = 0.0\n            tprs.append(interp_tpr)\n            aucs.append(viz.roc_auc)\n\n        ax.plot([0, 1], [0, 1],\n                linestyle='--',\n                lw=2,\n                color='r',\n                label='Chance',\n                alpha=.8)\n\n        mean_tpr = np.mean(tprs, axis=0)\n        mean_tpr[-1] = 1.0\n        mean_auc = auc(mean_fpr, mean_tpr)\n        std_auc = np.std(aucs)\n        ax.plot(mean_fpr,\n                mean_tpr,\n                color='b',\n                label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' %\n                (mean_auc, std_auc),\n                lw=2,\n                alpha=.8)\n\n        std_tpr = np.std(tprs, axis=0)\n        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n        ax.fill_between(mean_fpr,\n                        tprs_lower,\n                        tprs_upper,\n                        color='grey',\n                        alpha=.2,\n                        label=r'$\\pm$ 1 std. dev.')\n\n        ax.set(xlim=[-0.02, 1.02],\n               ylim=[-0.02, 1.02],\n               title=f'{estimator.__class__.__name__} ROC')\n        ax.legend(loc='lower right', prop={'size': 18})\n    plt.show()","6d9f3d22":"m_roc(estimators, cv, X_train_1, Y_train_1)","3f7538ef":"def plot_learning_curve(estimators,\n                        X,\n                        y,\n                        ylim=None,\n                        cv=None,\n                        n_jobs=None,\n                        train_sizes=np.linspace(.1, 1.0, 5)):\n\n    fig, axes = plt.subplots(math.ceil(len(estimators) \/ 2),\n                             2,\n                             figsize=(25, 50))\n    axes = axes.flatten()\n\n    for ax, estimator in zip(axes, estimators):\n\n        ax.set_title(f'{estimator.__class__.__name__} Learning Curve')\n        if ylim is not None:\n            ax.set_ylim(*ylim)\n        ax.set_xlabel('Training examples')\n        ax.set_ylabel('Score')\n\n        train_sizes, train_scores, test_scores, fit_times, _ = \\\n            learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                           train_sizes=train_sizes,\n                           return_times=True)\n        train_scores_mean = np.mean(train_scores, axis=1)\n        train_scores_std = np.std(train_scores, axis=1)\n        test_scores_mean = np.mean(test_scores, axis=1)\n        test_scores_std = np.std(test_scores, axis=1)\n\n        # Plot learning curve\n\n        ax.fill_between(train_sizes,\n                        train_scores_mean - train_scores_std,\n                        train_scores_mean + train_scores_std,\n                        alpha=0.1,\n                        color='r')\n        ax.fill_between(train_sizes,\n                        test_scores_mean - test_scores_std,\n                        test_scores_mean + test_scores_std,\n                        alpha=0.1,\n                        color='g')\n        ax.plot(train_sizes,\n                train_scores_mean,\n                'o-',\n                color='r',\n                label='Training score')\n        ax.plot(train_sizes,\n                test_scores_mean,\n                'o-',\n                color='g',\n                label='Cross-validation score')\n        ax.legend(loc='best')\n        ax.yaxis.set_major_locator(MaxNLocator(nbins=24))\n\n    plt.show()","fad1b582":"plot_learning_curve(estimators,\n                    X_train_1,\n                    Y_train_1,\n                    ylim=None,\n                    cv=cv,\n                    n_jobs=-1,\n                    train_sizes=np.linspace(.1, 1.0, 10))","70339660":"def f_imp(estimators, X, y, bins):\n    \n    fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n    axes = axes.flatten()\n\n    for ax, estimator in zip(axes, estimators):\n\n        try:\n            estimator.fit(X, y)\n            feature_imp = pd.DataFrame(sorted(\n                zip(estimator.feature_importances_, X.columns)),\n                                       columns=['Value', 'Feature'])\n\n            sns.barplot(x=\"Value\",\n                        y=\"Feature\",\n                        data=feature_imp.sort_values(by=\"Value\",\n                                                     ascending=False),\n                        ax=ax,\n                        palette='plasma')\n            plt.title('Features')\n            plt.tight_layout()\n            ax.set(title=f'{estimator.__class__.__name__} Feature Impotances')\n            ax.xaxis.set_major_locator(MaxNLocator(nbins=bins))\n        except:\n            continue\n    plt.show()","9539a77c":"# f_imp(estimators, X_train_1, Y_train_1, 14)","1d4e2447":"# Logistic Regression\n\nstartTime = time.time()\n\nlogreg2 = LogisticRegression()\nlogreg2.fit(X_train, Y_train)\n\nprint(\"Logistic regression accuracy: \", cross_val_score(logreg2, X_train_1, Y_train_1, scoring='accuracy', n_jobs=-1, cv=10).mean())\n\nacc_log = round((cross_val_score(logreg2, X_train_1, Y_train_1, scoring='accuracy', n_jobs=-1, cv=10).mean())*100,2)\n\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","cfb29775":"# Using GridSearchCV to identify the best parameters\n\nstartTime = time.time()\nest_s = LogisticRegression(n_jobs=-1)\nparamt = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100], 'solver': ['newton', 'lbfgs', 'liblinear']}\n\ngs = GridSearchCV(cv=10, estimator=est_s,\n            param_grid=paramt, refit=True, scoring='accuracy',\n            error_score=0)\n\ngs.fit(X_train_1, Y_train_1)\n\nprint(\"Best params: \", gs.best_params_)\nprint(\"Best score: \", gs.best_score_)\n\nlogreg2 = gs.best_estimator_\n\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","09f809d5":"# coeff_df = pd.DataFrame(train_df.columns.delete(0))\n# coeff_df.columns = ['Feature']\n# coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\n# coeff_df.sort_values(by='Correlation', ascending=False)","66488e21":"# Support Vector Machines\n\nstartTime = time.time()\nsvc = SVC()\nsvc.fit(X_train, Y_train)\n\nprint(\"Support Vector Machines accuracy: \", cross_val_score(svc, X_train_1, Y_train_1, scoring='accuracy', n_jobs=-1, cv=10).mean())\n\nacc_svc = round((cross_val_score(svc, X_train_1, Y_train_1, scoring='accuracy', n_jobs=-1, cv=10).mean())*100,2)\n\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","bee2dfa6":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler","51f40ec2":"# Using GridSearchCV to identify the best parameters\n\n# try standard scaler\n\nstartTime = time.time()\nest_s = SVC()\nparamt = {'C': [0.001,0.01,0.1,1,10,100], 'kernel': ['linear','poly','rbf','sigmoid'], 'degree':[1,2,3]}\n\ngs = GridSearchCV(cv=10, estimator=est_s,\n            param_grid=paramt, refit=True, scoring='accuracy',\n            error_score=0)\n\ngs.fit(X_train_1, Y_train_1)\n\nprint(\"Best params: \", gs.best_params_)\nprint(\"Best score: \", gs.best_score_)\n\nsvc2 = gs.best_estimator_\n\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","c1367f52":"# KNN\n\nstartTime = time.time()\nknn = KNeighborsClassifier(n_neighbors = 6)\nknn.fit(X_train, Y_train)\n# Y_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_knn)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","d47dcdf7":"# Gaussian Naive Bayes\n\nstartTime = time.time()\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\n# Y_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_gaussian)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","ca665946":"# Perceptron\n\nstartTime = time.time()\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\n# Y_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_perceptron)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","2a34e16d":"# Linear SVC\n\nstartTime = time.time()\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\n# Y_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_linear_svc)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","a82c06e1":"# Stochastic Gradient Descent\n\nstartTime = time.time()\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\n# Y_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_sgd)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","3901552b":"# Decision Tree\n\nstartTime = time.time()\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\n# Y_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_decision_tree)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","741ae898":"# Random Forest\n\nstartTime = time.time()\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n# Y_pred = random_forest.predict(X_test)\nprint(\"Random forest train score: \", round(random_forest.score(X_train, Y_train),3))\nacc_random_forest = round(random_forest.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Random forest validation score: \",acc_random_forest)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","fd9bab1b":"# Xgboost\n\nstartTime = time.time()\nxg_boost = xgboost.XGBClassifier()\nxg_boost.fit(X_train, Y_train)\n# Y_pred = xg_boost.predict(X_test)\nprint(\"Xgboost train score: \",round(xg_boost.score(X_train, Y_train),3))\nacc_xg_boost = round(xg_boost.score(X_valid, Y_valid) * 100, 2)\n      \nprint(\"Xgboost validation score: \", acc_xg_boost)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","32d5281a":"# LGB\n\nstartTime = time.time()\nlg = lgb.LGBMClassifier(max_bin=4,\n                        num_iterations=550,\n                        learning_rate=0.0114,\n                        max_depth=3,\n                        num_leaves=7,\n                        colsample_bytree=0.35,\n                        random_state=42,\n                        n_jobs=-1)\nlg.fit(X_train, Y_train)\nacc_lgb = round(lg.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_lgb)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","7747696d":"# Gradient Boosting Classifier\n\nstartTime = time.time()\ngb = GradientBoostingClassifier(random_state=42)\ngb.fit(X_train, Y_train)\nacc_gb = round(gb.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_gb)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","03f3c3b6":"# MLP Classifier\n\nstartTime = time.time()\nmlp = MLPClassifier(random_state=42)\nmlp.fit(X_train, Y_train)\nacc_mlp = round(mlp.score(X_valid, Y_valid) * 100, 2)\n\nprint(\"Validation accuracy: \",acc_mlp)\nexecutionTime = (time.time() - startTime)\nprint('Execution time in seconds: ' + str(round(executionTime,3)))","842abb7c":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree', 'XGBoost'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree, acc_xg_boost]})\nmodels.sort_values(by='Score', ascending=False)","c49d5152":"# # https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py\n\n# startTime = time.time()\n\n# # The scorers can be either be one of the predefined metric strings or a scorer\n# # callable, like the one returned by make_scorer\n# scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n\n# # Setting refit='AUC', refits an estimator on the whole dataset with the parameter setting that has the best cross-validated AUC score.\n# # That estimator is made available at ``gs.best_estimator_`` along with parameters like ``gs.best_score_``, ``gs.best_params_`` and ``gs.best_index_``\n\n# gs = GridSearchCV(RandomForestClassifier(n_jobs = -1, criterion = 'gini', max_features = 'auto', random_state = 42, oob_score=True, min_samples_split=6, min_samples_leaf=6),\n#                   param_grid={\n#                       'n_estimators': range(10,110,20),\n#                       'max_depth': [5,7]},\n#                   scoring = 'accuracy', return_train_score=True)\n# gs.fit(X_train_1, Y_train_1)\n# results = gs.cv_results_\n\n# executionTime = (time.time() - startTime)\n# print('Execution time in seconds: ' + str(round(executionTime,3)))","6309a33f":"# gs.best_params_","4429756d":"# plt.figure(figsize=(13, 13))\n# plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\", fontsize=16)\n\n# plt.xlabel(\"n_estimators\")\n# plt.ylabel(\"Score\")\n\n# ax = plt.gca()\n# ax.set_xlim(100, 1500)\n# ax.set_ylim(0.75, 1)\n\n# # Get the regular numpy array from the MaskedArray\n# X_axis = np.array(results['param_n_estimators'].data, dtype=float)\n\n# for scorer, color in zip(sorted(scoring), ['g', 'k']):\n#     for sample, style in (('train', '--'), ('test', '-')):\n#         sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n#         sample_score_std = results['std_%s_%s' % (sample, scorer)]\n#         ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n#                         sample_score_mean + sample_score_std,\n#                         alpha=0.1 if sample == 'test' else 0, color=color)\n#         ax.plot(X_axis, sample_score_mean, style, color=color,\n#                 alpha=1 if sample == 'test' else 0.7,\n#                 label=\"%s (%s)\" % (scorer, sample))\n\n#     best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n#     best_score = results['mean_test_%s' % scorer][best_index]\n\n#     # Plot a dotted vertical line at the best score for that scorer marked by x\n#     ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n#             linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n#     # Annotate the best score for that scorer\n#     ax.annotate(\"%0.2f\" % best_score,\n#                 (X_axis[best_index], best_score + 0.005))\n\n# plt.legend(loc=\"best\")\n# plt.grid(False)\n# plt.show()","77726dcc":"# plt.figure(figsize=(12,8))\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.title('ROC Curve')\n\n# plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n# labels = []\n\n# fpr, tpr, _ = roc_curve(Y_valid, xg_boost.predict_proba(X_valid)[:,1])\n# roc_auc = auc(fpr, tpr)\n# plt.plot(fpr, tpr, lw=1, color='r')\n# labels.append(\"AUC = {}\".format(np.round(roc_auc, 4)))\n\n# fpr2, tpr2, _ = roc_curve(Y_valid, logreg.predict_proba(X_valid)[:,1])\n# roc_auc = auc(fpr2, tpr2)\n# plt.plot(fpr2, tpr2, lw=1, color='g')\n# labels.append(\"AUC = {}\".format(np.round(roc_auc, 4)))\n\n# plt.legend(['random AUC = 0.5'] + labels)","25fe1988":"# pr, re, _ = precision_recall_curve(Y_valid, xg_boost.predict_proba(X_valid)[:,1])\n# plt.figure(figsize=(12,8))\n# plt.plot(re, pr)\n# plt.title('PR Curve (AUC {})'.format(auc(re, pr)))\n# plt.xlabel('Recall')\n# plt.ylabel('Precision')","019089ac":"Distribution across test and train dataset is comparable","407c4fed":"\nIt seems, \"Fare\" and \"Age\" have no strong linear relation with \"Survival\" outcomes even with Spearman correlation. We're going to bin these variables to get better results","e7414479":"## Reading the train and test dataset","3c007bd5":"## ROC Curve","ad09dd4b":"### ROC'S of the Models","ddc66dbc":"### <b>Insights<\/b>:\n* We see that 'Age' column has missing values in the train data\n* Approx 38% passengers in the train dataset have survived. Currently not planning to do any down-sampling or up-sampling","df7c5fa1":"### Filling missing values","5a0603c0":"### Learning Curves of the Models","1719fa0d":"### Multi-metric evaluation on cross_val_score and GridSearchCV for Random Forest classifier","9e098da5":"Insights:\n1. Chances of survival increases as PClass decreases\n2. Females have a higher chance of survival as compared to males\n3. Chances of survival are lower for Parch and SibSp. Can do some feature engg. here to improve the distinction between survival class 0 and 1\n4. Embarked field also has shows difference in chances of survival. Not planning on making any changes to this feature","33bab19c":"### Feature Importances","d4b8ed40":"## Precision Recall Curve","7a921d16":"# Titanic Survival Prediction\n\nThere are some really amazing notebooks that have covered this problem very well. I have gone through multiple such notebooks to create this version. Thanks to all Kagglers who have shared their work so that others can learn!","be1f30bf":"### Individual classifiers:\nCan use them to tweak them and find the best parameters\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/grid_search.html#multimetric-grid-search\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html\nhttps:\/\/www.kaggle.com\/harshkothari21\/100-accurate-results-with-eda-all-ml-models#MinMaxScaler\nhttps:\/\/www.kaggle.com\/datafan07\/my-journey-to-top-2-eda-with-several-approaches\nhttps:\/\/www.kaggle.com\/trilokigupta\/titanic-survival-prediction","8a74375b":"### Dealing with misisng values","fc2edeb1":"### EDA and Feature Engineering","c9b618b9":"Note: 'Age', 'Embarked' and 'Fare' columns have missing values"}}