{"cell_type":{"1d4f833f":"code","58768e04":"code","c2029325":"code","653834ef":"code","9ca7e076":"code","52cec2cd":"code","1a7355de":"markdown"},"source":{"1d4f833f":"import random","58768e04":"class Env:\n    def __init__(self):\n        self.targets = [i for i in range(0,100,10)]\n        self.reset()\n        \n    # atualiza o estado de acordo com a a\u00e7\u00e3o\n    def step(self, action):\n        self.last_target = action\n        print(f'Env: o alvo {action} foi atingido')\n        return action == self.target\n        \n    # retorna um alvo aleatorio\n    def get_random_target(self):\n        return random.randint(0,len(self.targets))\n    \n    # restaura o estado inicial do ambiente\n    def reset(self):\n        # escolhe um dos alvos para ser o objetivo\n        self.target = random.randint(0,len(self.targets))\n        print(f'Env: o alvo premiado \u00e9 o {self.target}')\n        self.last_target = None","c2029325":"class Agent:\n    def __init__(self, env):\n        self.env = env\n        \n    def calc_new_target(self, reward):\n        reward = 'esquerda' if reward > 0 else 'direita'\n        direction = -1 if reward == 'direita' else 1\n        \n        print(f'Agent: o angulo foi ajustado para a {reward}')\n        return self.env.last_target + direction\n        \n    # baseado no conhecimento do agente, retorna qual a\u00e7\u00e3o devera ser tomada no estado atual\n    def chose(self, reward=None):\n        new_target = self.env.get_random_target()\n        if self.env.last_target is not None: # caso n\u00e3o seja o primeiro tiro\n            new_target = self.calc_new_target(reward)\n        \n        print(f'Agent: o alvo escolhido foi o {new_target}')\n        return new_target","653834ef":"class Actuator:\n    def __init__(self,env):\n        self.env = env\n    \n    # executa a a\u00e7\u00e3o\n    # true = alvo certo\n    # false = alvo errado\n    def act(self, action):\n        print(f'Actuator: disparando no alvo {action}')\n        return self.env.step(action)","9ca7e076":"class Sensor:\n    def __init__(self,env):\n        self.env = env\n    \n    # calcula a recompensa da a\u00e7\u00e3o no estado atual\n    def calc_reward(self):\n        reward = self.env.target - self.env.last_target\n        print(f'Sensor: recompensa pelo disparo = {reward}')\n        return reward","52cec2cd":"env = Env()\nagent = Agent(env)\nactuator = Actuator(env)\nsensor = Sensor(env)\n\ntarget = agent.chose()\nis_end = actuator.act(target)\nwhile not is_end:\n    reward = sensor.calc_reward()\n    target = agent.chose(reward)\n    is_end = actuator.act(target)\nprint('O alvo premiado foi atingido!')    ","1a7355de":"![image.png](attachment:image.png)\n<p>O ambiente \u00e9 composto por um campo com 10 alvos dispostos a cada 10\u00ba de um campo de vis\u00e3o de 90\u00ba<\/p>\n<p>O agente \u00e9 atirador<\/p>\n<p>O sensor \u00e9 o olho do atirador<\/p>\n<p>O atuador \u00e9 o arco e flecha<\/p>\n<p>No inicio da rodada um dos alvos \u00e9 definido como premiado e o objetivo do agente \u00e9 acerta-lo<\/p>"}}