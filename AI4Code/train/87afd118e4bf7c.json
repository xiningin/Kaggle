{"cell_type":{"4a5f17bf":"code","59f729f0":"code","913cb16d":"code","430e647d":"code","74676997":"code","8d6311cd":"code","a434458f":"code","d645118b":"code","b4cab626":"code","e4f51648":"markdown","9a040324":"markdown","d433d1ec":"markdown","141e5ee9":"markdown","b8ccd3ea":"markdown","96ed67e4":"markdown","e0a3147b":"markdown","9b14cd4a":"markdown"},"source":{"4a5f17bf":"!pip install --upgrade pip\n!pip uninstall -y allennlp\n!pip install transformers==4.1.1 typer\n!pip install -U pytorch-lightning\n!pip install https:\/\/github.com\/veritable-tech\/pytorch-lightning-spells\/archive\/master.zip","59f729f0":"!mkdir -p \/src\/finetuning-t5\n!git clone https:\/\/github.com\/ceshine\/finetuning-t5.git -b master \/src\/finetuning-t5","913cb16d":"%cd \/src\/finetuning-t5\/mnli\n%git checkout 13b9351","430e647d":"!mkdir -p data\/kaggle\n!cp -r \/kaggle\/input\/multinli-nyu\/* data\/multinli_1.0\/\n!ls data\/kaggle\/","74676997":"!mkdir -p cache\/kaggle\/\n!python preprocess\/preprocess_mnli.py\n!mkdir cache\/multinli\n!python preprocess\/tokenize_dataset.py multinli --tokenizer-name google\/t5-v1_1-base","8d6311cd":"!SEED=333 python train.py --batch-size 64 --grad-accu 1 --max-len 128 --epochs 2 --t5-model google\/t5-v1_1-base \\\n    --lr 1e-3 --dataset multinli --disable-progress-bar --valid-frequency 0.5 --full-model","a434458f":"!python evaluate.py cache\/t5-v1_1-base_best --corpus multinli --split-name test_matched --batch-size 32","d645118b":"!python evaluate.py cache\/t5-v1_1-base_best --corpus multinli --split-name test_mismatched --batch-size 32","b4cab626":"!mv cache\/tb_logs \/kaggle\/working\n!mv cache\/t5-v1_1-base_best \/kaggle\/working","e4f51648":"## Export the Tensorboard log files and the trained model","9a040324":"## Preprocess the dataset","d433d1ec":"## Calculate accuracy of the \"mismatched\" dev set","141e5ee9":"## Fine-tune the model","b8ccd3ea":"## Prepare the environment","96ed67e4":"## Get the code","e0a3147b":"## Calculate accuracy of the \"matched\" dev set","9b14cd4a":"[T5 v1.1 models were trained with the multitask objective, so it'll be harder to get good results with simple finetuning procedure.](https:\/\/github.com\/google-research\/text-to-text-transfer-transformer\/blob\/master\/released_checkpoints.md#t511) This notebook conducts an experiment to find the level of accuracy we can get with a naive finetuning scheme.\n\nIn my experiment, AdaFactor with a custom learning rate schedule has been shown to perform better than AdamW and AdaFactor with the built-in schedule."}}