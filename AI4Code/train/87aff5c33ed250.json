{"cell_type":{"19e07081":"code","0ed49528":"code","f9ce5cac":"code","fb7c8228":"code","97a08fc4":"code","977dbd43":"code","6634531b":"code","13c491bc":"code","bafae2d4":"code","4e2cc553":"code","e00bf00f":"code","1bbcf465":"code","676bb0c5":"code","f8b56178":"code","1ed6eea3":"code","2adeeedc":"markdown","7c9ce18a":"markdown"},"source":{"19e07081":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import  tqdm\nprint(os.listdir(\"..\/input\"))\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten,GlobalAvgPool2D\nfrom keras.layers import Conv2D, MaxPooling2D\nimport keras\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications import Xception\nfrom keras.applications import InceptionV3\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, accuracy_score\nimport time","0ed49528":"df = pd.read_csv(\"..\/input\/labels.csv\")\ndf.info()","f9ce5cac":"# sam = pd.read_csv(\"..\/input\/sample_submission.csv\")\n# sam.head(5)","fb7c8228":"breed_ls = list(df.groupby('breed').count().sort_values(by='id', ascending=False).index)","97a08fc4":"import random\nimport cv2\nfrom keras.preprocessing import image\n\ndef getRandomImageList(breed_name, no_of_samples=60):\n    global df\n    random_images = []\n    for index, row in df.iterrows():\n        if row['breed'] == breed_name:\n            random_images.append(row['id'])\n    random_images = random.sample(random_images, no_of_samples)\n    return random_images\n\ndef readImgResize(name,path,dim=150):\n    img = cv2.imread(path+name)\n    img = cv2.resize(img,(dim,dim))\n    return image.img_to_array(img)","977dbd43":"INPUT_SIZE = 150\nnum_class=NUM_CLASSES=120\nsamples = 65\n\n\nimage_label = []\nnum = 0\nimport tqdm\nfor i,breed in tqdm.tqdm( enumerate(breed_ls[:num_class])):\n\n    ls = getRandomImageList(breed,samples) \n    image_label.extend(ls)\n    ","6634531b":"new_df = pd.DataFrame({\"id\":image_label})\nnew_df = pd.merge(new_df, df, how='inner', on=['id'])","13c491bc":"\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncat = le.fit_transform(new_df.breed)\nfrom keras.utils.np_utils import to_categorical\nmat = to_categorical(cat)\n\ntraining_data = np.zeros(shape=(len(new_df.id),INPUT_SIZE,INPUT_SIZE,3))\n\nfor i,j in tqdm.tqdm(enumerate(new_df[\"id\"])):\n    training_data[i]=readImgResize(j+\".jpg\",path=\"..\/input\/train\/\")\n    \n\n","bafae2d4":"# from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten,GlobalAvgPool2D\nfrom keras.layers import Conv2D, MaxPooling2D\nimport keras\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( training_data, mat, test_size=0.05, random_state=11)\ndel training_data, mat, new_df, df","4e2cc553":"from matplotlib import pyplot as plt\nplt.figure(figsize=(15,7))\nfor i in range(6):\n    idx = random.randint(0,len(X_train))\n    name = le.inverse_transform(y_train[idx].argmax())\n    plt.subplot(2,3,i+1)\n    plt.imshow(X_train[idx]\/255)\n    plt.xlabel(str(name))\n","e00bf00f":"from keras.models import Model\nfrom keras.optimizers import adam\n\ndef getModel(model_name,epochs=5):\n    im_size = 150\n    global X_train\n    global y_train\n    \n    global X_test\n    global y_test\n    \n    base_model = model_name(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n\n    # Add a new top layer\n    x = base_model.output\n    x = Flatten()(x)\n    predictions = Dense(num_class, activation='softmax')(x)\n\n    # This is the model we wi`l train\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    # First: train only the top layers (which were randomly initialized)\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(adam(lr=0.000001),loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.fit(X_train\/255, y_train, epochs=epochs, validation_data=(X_test\/255, y_test), verbose=1)\n    \n    return(model)","1bbcf465":"xcep = getModel(Xception,epochs=60)","676bb0c5":"del X_train,X_test,y_train,y_test","f8b56178":"te = os.listdir(\"..\/input\/test\/\")\nte_in = np.zeros((len(te),150,150,3))\nfor num , i in enumerate(te):\n    img = readImgResize(i,path=\"..\/input\/test\/\")\/255\n    te_in[num]=img\n    ","1ed6eea3":"pred = xcep.predict(te_in)\nsubmission = pd.DataFrame(pred , columns =le.classes_.tolist())\nsubmission[\"id\"]=[i.split(\".\")[0] for i in os.listdir(\"..\/input\/test\/\")]\nsubmission = submission[[\"id\"]+submission.columns[:-1].tolist()]\nsubmission.sort_values(['id'])\nsubmission.to_csv(\"submission.csv\",index = False)","2adeeedc":"**Aim**: To get pretrained imagenet features generated by Xception on the dataset and train a softmax layer for classification. ","7c9ce18a":"The model seems to be working fine. It requires a bit more training before it starts overfitting and as of now the losses of training and validation data are of similar magnititude. Hope to see how this network performs when we use image augmentation and around 150 epochs. "}}