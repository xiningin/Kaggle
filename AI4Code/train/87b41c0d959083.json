{"cell_type":{"79b1ddda":"code","a189079b":"code","6de0129a":"code","44f76c18":"code","42fdc966":"code","eb8954b8":"code","d1d36c29":"code","0e7da92c":"code","a72900db":"code","9eef7238":"code","c07132aa":"code","1576fbcd":"code","532df186":"code","54a7963a":"code","11fa8be2":"code","c8d961f9":"code","02b1ae73":"code","50f821e0":"code","44726b57":"markdown","473c0505":"markdown","f070d50f":"markdown","c56a2798":"markdown","90bd37e0":"markdown","a84ecbb0":"markdown"},"source":{"79b1ddda":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.naive_bayes import MultinomialNB","a189079b":"# Load in data\ndf = pd.read_csv('..\/input\/heart.csv')","6de0129a":"df.head(10)","44f76c18":"# Convert target to bool\ndf['target'] = df['target'].astype('bool')","42fdc966":"df.dtypes","eb8954b8":"# Summary Statistics\ndf.describe().round(decimals = 2)","d1d36c29":"# Correlation\ndf.corr()","0e7da92c":"# Correlation heatmap\nf, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(df.corr(), cmap='YlGnBu', annot=True, linewidths=0.5, fmt='.1f', ax=ax)\nplt.show()","a72900db":"# Look for missing data\ndf.info()","9eef7238":"# cp has the strongest correlation with target, so let's look at that\ndf['cp'].value_counts()","c07132aa":"# And thalach\ndf['thalach'].plot(kind=\"hist\", bins=20)","1576fbcd":"# Split training and testing\ndf_x = df.drop(['target'], axis=1)\nx = df_x.values\ny = df['target'].values\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .2)","532df186":"# Train the model\ngnb = MultinomialNB()\ngnb.fit(x_train, y_train)","54a7963a":"# Test accuracy\nprint('Naive Bayes Score: %.3f' % gnb.score(x_test,y_test))","11fa8be2":"# Train the model\ndt = tree.DecisionTreeClassifier()\ndt.fit(x_train, y_train)","c8d961f9":"# Test accuracy\nprint('Decision Tree Score: %.3f' % dt.score(x_test,y_test))","02b1ae73":"# Train the model\nrfc = RandomForestClassifier()\nrfc.fit(x_train, y_train)","50f821e0":"# Test accuracy\nprint('Random Forest Score: %.3f' % rfc.score(x_test,y_test))","44726b57":"**Three different classification algorithms on the heart disease dataset**","473c0505":"**Modeling**\n\nFirst with Naive Bayes classification","f070d50f":"Random Forest Classifier","c56a2798":"Exploratory data analysis","90bd37e0":"No missing data","a84ecbb0":"Decision Tree"}}