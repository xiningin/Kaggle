{"cell_type":{"0d6412c7":"code","f06d404b":"code","ca376c7a":"code","e0581d0f":"code","b443bf78":"code","c152d074":"code","0c18c095":"code","831fcb79":"code","24095925":"code","9a8306a0":"code","987cc72b":"code","a32c542f":"code","eee7dd42":"code","e0118e69":"code","40d1b5e8":"code","56a9b5e9":"code","305e3f2a":"code","ad7c2032":"code","71a371d8":"code","9e4632ea":"code","b0d90d83":"code","501716a2":"code","de2d104a":"code","4cac3a71":"markdown"},"source":{"0d6412c7":"import os\nimport glob\nimport numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import Input, Model\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalMaxPool2D, Dropout","f06d404b":"#first we must get one list with all images path\ntest = glob.glob('..\/input\/fingers\/test\/*')\ntrain = glob.glob('..\/input\/fingers\/train\/*')","ca376c7a":"#Then we can make  our dataset, we'll separate the number of fingers from the hand's side (L\/R)\ndef make_df(list_images):\n    df = pd.DataFrame()\n    df['side'] = [i.split('.')[2][-1:] for i in list_images]\n    df['fingers'] = [(i.split('.')[2][-2]) for i in list_images]\n    df['image'] = [i.split('\/')[-1] for i in list_images]\n    return df","e0581d0f":"#just creating out dataset with the previous function\ndf_train = make_df(train)\ndf_test = make_df(test)","b443bf78":"#Here we apply label encoder into out labels (it's not necessary on fingers, you could use just astype)\nlb_side = LabelEncoder()\nlb_fingers = LabelEncoder()\n\ndf_train['side'] = lb_side.fit_transform(df_train['side'])\ndf_train['fingers'] = lb_fingers.fit_transform(df_train['fingers'])\n\ndf_test['side'] = lb_side.transform(df_test['side'])\ndf_test['fingers'] = lb_fingers.transform(df_test['fingers'])","c152d074":"#Here we create a dict with our classes\nmapping_fingers = dict(zip(lb_fingers.classes_, range(len(lb_fingers.classes_))))\nprint(mapping_fingers)\n\nmapping_side = dict(zip(lb_side.classes_, range(len(lb_side.classes_))))\nprint(mapping_side)","0c18c095":"#applying OHE to create a OHE vector for side label\nonehot_side = to_categorical(df_train['side'].values)\ndf_train['side'] = onehot_side.tolist()\ndf_train","831fcb79":"#The same as above but with test partition\nonehot_side = to_categorical(df_test['side'].values)\ndf_test['side'] = onehot_side.tolist()\ndf_test","24095925":"# We can use ImageDataGenerator and flow_from_dataframe to create a generator for our data\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255.0,\n                                                        preprocessing_function=None,\n                                                        data_format=None,\n                                                    )\n\ntrain_data = datagen.flow_from_dataframe(\n    df_train,\n    directory= '..\/input\/fingers\/train',\n    x_col=\"image\",\n    y_col= ['fingers','side'],\n    color_mode=\"grayscale\",\n    target_size = (128,128),\n    class_mode=\"multi_output\",\n    batch_size=32,\n    shuffle=False,#Not necessary here\n    seed=40,\n)","9a8306a0":"datagen_valid = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255.0,\n                                                        preprocessing_function=None,\n                                                        data_format=None,\n                                                    )\n\nvalid_data = datagen_valid.flow_from_dataframe(\n    df_test,\n    directory= '..\/input\/fingers\/test',\n    x_col=\"image\",\n    y_col= ['fingers','side'],\n    color_mode=\"grayscale\",\n    target_size = (128,128),\n    class_mode='multi_output',\n    batch_size=32,\n    shuffle=False,\n    seed=40,\n)","987cc72b":"num_sides = len(df_train.side.value_counts())\nnum_fingers = len(df_train.fingers.value_counts())\nnum_sides,num_fingers","a32c542f":"# Building our model!\n\ndef conv_block(inp, filters=32, bn=True, pool=True):\n    layer_base = Conv2D(filters=filters, kernel_size=3, activation='relu')(inp)\n    if bn:\n        layer_base = BatchNormalization()(layer_base)\n    if pool:\n        layer_base = MaxPool2D()(layer_base)\n    return layer_base\n \ninput_layer = Input(shape=(128, 128, 1))\ntlayer = conv_block(input_layer, filters=32, bn=False, pool=False)\ntlayer = conv_block(tlayer, filters=32*2)\ntlayer = conv_block(tlayer, filters=32*3)\ntlayer = conv_block(tlayer, filters=32*4)\ntlayer = conv_block(tlayer, filters=32*5)\ntlayer = conv_block(tlayer, filters=32*6)\nbottleneck = GlobalMaxPool2D()(tlayer)\n \n# for fingers prediction\ntlayer = Dense(units=128, activation='relu')(bottleneck)\nfingers_output = Dense(units=num_fingers, activation='softmax', name='fingers_output')(tlayer)\n \n# for side prediction\ntlayer = Dense(units=128, activation='relu')(bottleneck)\nside_output = Dense(units=num_sides, activation='softmax', name='side_output')(tlayer)\n\n \nmodel = Model(inputs=input_layer, outputs=[fingers_output, side_output])\nmodel.compile(optimizer='adam',\n              loss={'fingers_output': 'sparse_categorical_crossentropy', 'side_output': 'categorical_crossentropy'},\n              metrics={'fingers_output': 'accuracy', 'side_output': 'accuracy'})","eee7dd42":"#Our model Plot Model\ndot_img_file = 'model_1.png'\ntf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)","e0118e69":"#Let's traaaaaain!\nhistory = model.fit(\n    train_data,\n    steps_per_epoch=train_data.samples\/\/train_data.batch_size,\n    epochs=5,\n    validation_data=valid_data, validation_steps=valid_data.samples\/\/valid_data.batch_size,\n    verbose=1\n)","40d1b5e8":"#Simple evaluation\nmodel.evaluate(valid_data, steps=valid_data.samples\/\/valid_data.batch_size)","56a9b5e9":"inv_side = {v: k for k, v in mapping_side.items()}\ninv_fingers = {v: k for k, v in mapping_fingers.items()}","305e3f2a":"# Function to predict new images\ndef run_prediction(path_test,fingers_dict,side_dict):\n    image = tf.keras.preprocessing.image.load_img(\n       path_test , grayscale=False, color_mode=\"grayscale\", target_size=(128,128), interpolation=\"nearest\"\n    )\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = np.array([input_arr\/255])  # Convert single image to a batch.\n    predictions = model.predict(input_arr)\n    num = fingers_dict[np.argmax(predictions[0][0])]\n    side = side_dict[np.argmax(predictions[1][0])]\n    return num + side","ad7c2032":"#Actually it's not necessary to do this (you can run using a generator with more than one image), but i like this type of prediction to be sure that everything if ok\ntrue_label, pred_label = [], []\nfor image in tqdm(df_test['image']):\n    image = '..\/input\/fingers\/test\/' + image\n    true_label.append(image.split('.')[2][-2:])\n    pred_label.append(run_prediction(image,inv_fingers,inv_side))","71a371d8":"df_pred = pd.DataFrame()\ndf_pred['Prediction'] = pred_label\ndf_pred['Label'] = true_label","9e4632ea":"lb = LabelEncoder()\nlb.fit(df_pred['Label'])\ndf_pred['Prediction'] =  lb.transform(df_pred['Prediction'])\ndf_pred['Label'] = lb.transform(df_pred['Label'])","b0d90d83":"#Let's see our score!\naccuracy_score(df_pred['Label'],df_pred['Prediction'])","501716a2":"#Let's run one prediction!\nrun_prediction('..\/input\/fingers\/test\/0027029b-4c3c-4785-bc1b-b8141331a108_3R.png',inv_fingers,inv_side)","de2d104a":"model.save('model.h5')","4cac3a71":"## Let's predict the number of fingers and the left\/right hand with a multi-output model using keras!\n![image.png](attachment:161af438-06e6-4d5d-a832-fe23b3fddb2e.png)"}}