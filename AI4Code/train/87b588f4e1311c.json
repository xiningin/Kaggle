{"cell_type":{"ef4b168d":"code","b21c8756":"code","191aa2f2":"code","94d3cfa7":"code","39a0ef0a":"code","d16a9be4":"code","bb448d00":"code","214b28f3":"code","e4a34d8a":"code","512f987c":"code","1b485774":"code","23009bd1":"code","6b42dbea":"code","b921d792":"code","3fae75ae":"code","789b180e":"code","902d917e":"code","e4b2f105":"code","d88b9484":"code","6e16cb35":"code","dd76b957":"code","a8ac6dd1":"code","ca4ccdf6":"markdown","8751e482":"markdown","24863a67":"markdown","50670d92":"markdown","abe6485e":"markdown","e111b2a3":"markdown","4a2820a6":"markdown"},"source":{"ef4b168d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_predict, GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b21c8756":"df = pd.read_csv(os.path.join(dirname, filename))\ndf.columns","191aa2f2":"df['BPLevel'].value_counts()","94d3cfa7":"df_obj = df.select_dtypes(['object'])\ndf[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())","39a0ef0a":"for col in df_obj.columns:\n    print(col)\n    print(df[col].value_counts())\n    print('======================================')","d16a9be4":"df['RegularMedicine'].replace('o', 'no', inplace =True)\ndf['Pdiabetes'].replace('0', 'no', inplace = True)\ndf['BPLevel'].replace('low', 'Low', inplace=True)\ndf['BPLevel'].replace('high', 'High', inplace=True)","bb448d00":"sns.countplot(x = 'Diabetic', data=df)","214b28f3":"multinary_columns = ['Age', 'BPLevel', 'PhysicallyActive', 'JunkFood', 'Stress']\nmultinary = pd.get_dummies(df[multinary_columns], drop_first=True)\npreg = pd.get_dummies(df['Pregancies'],prefix='Pregnancies',drop_first= True)","e4a34d8a":"multinary_columns.append('Pregancies')\nnumerical_clos = [col for col in df.columns if col not in multinary_columns]","512f987c":"new_df = pd.concat([multinary, preg, df[untouched_clos]], axis=1)","1b485774":"binary_columns = ['Diabetic', 'Pdiabetes', 'RegularMedicine', 'Alcohol', 'Smoking', 'highBP', 'Family_Diabetes']\ntwo_values_cols = ['UriationFreq', 'Gender']","23009bd1":"for col in binary_columns:\n    new_df[col] = new_df[col].apply(lambda x: 0 if x=='no' else 1)\nnew_df['UriationFreq'] = new_df['UriationFreq'].apply(lambda x: 0 if x=='not much' else 1)\nnew_df['Gender'] = new_df['Gender'].apply(lambda x: 0 if x=='Female' else 1)","6b42dbea":"import matplotlib.pyplot as pyplot\n\ndf.hist(figsize=(15,15))\npyplot.show()","b921d792":"new_df.fillna(new_df.mean(), inplace=True)","3fae75ae":"X = new_df.iloc[:, 0:-1]\ny = new_df.iloc[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=21)","789b180e":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","902d917e":"knn_cls = KNeighborsClassifier()\nknn_cls.fit(X_train, y_train)\ny_pred = knn_cls.predict(X_test)\nprint(classification_report(y_test, y_pred))","e4b2f105":"rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\nrnd_clf.fit(X_train, y_train)\ny_pred_rf = rnd_clf.predict(X_test)\nprint(classification_report(y_test, y_pred_rf))","d88b9484":"param_grid = [\n    {'n_estimators': [ 300, 400, 500, 600],\n    'max_features':[10,12,14,16,18,20,22,24,26,28,29]}\n#     {'bootstrap':[False],\n#     'n_estimators': [100, 200, 300, 400, 500, 600],\n#     'max_features':[2,4,6,8,10,12,14,16,18,20,22,24,26,28,29]}\n]\n\ngrid_search = GridSearchCV(rnd_clf, param_grid, cv=5, n_jobs=-1)\ngrid_search.fit(X_train, y_train)","6e16cb35":"final_model = grid_search.best_estimator_","dd76b957":"y_pred_grid = final_model.predict(X_test)","a8ac6dd1":"print(classification_report(y_test, y_pred_grid))","ca4ccdf6":"## Using grid search to find the best parameters for random forest classifier","8751e482":"## Creating a dataframe of catagorical varaibles","24863a67":"## filling the null values with mean","50670d92":"### printing the columns with binary or multinary values","abe6485e":"### replaceing the wrong value in three categorical variables","e111b2a3":"## adding dummy variables for columns with multinary values\n### for pregnancies the range is between 0 and 4 included","4a2820a6":"### concatinating all variables into one dataframe"}}