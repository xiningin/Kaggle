{"cell_type":{"733f2eef":"code","af81e52f":"code","501a5c1d":"code","14dbf96a":"code","7b5eb4a4":"code","54d437bc":"code","e20028df":"markdown","4107aba9":"markdown","7644aa54":"markdown","d7431153":"markdown","67caa63f":"markdown","d71b468e":"markdown","df47fe05":"markdown","e289dc90":"markdown","1722a98f":"markdown","cd24c3c5":"markdown","7033cd3f":"markdown","e1b2ae5e":"markdown","6619b5b8":"markdown","b6aa5442":"markdown","d96425e2":"markdown"},"source":{"733f2eef":"#\u00a0First understand the data\n\nimport pandas as pd\n\ndf = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\") # Read the CSV file\nprint(df.count()) # Show the count of not null rows by columns\n#df.head()","af81e52f":"#\u00a0Statistics\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nfig = plt.figure(figsize=(18, 6))\n\nplt.subplot2grid((2,3), (0, 0))\ndf.Survived.value_counts(normalize=True).plot(kind=\"bar\", alpha=0.5)\nplt.title(\"Survived\")\n\nplt.subplot2grid((2,3), (0, 1))\nplt.scatter(df.Survived, df.Age, alpha=0.1)\nplt.title(\"Age wrt Survived\")\n\nplt.subplot2grid((2,3), (0, 2))\nplt.scatter(df.Survived, df.Parch, alpha=0.1)\nplt.title(\"Parch wrt Survived\")\n\nplt.show() # Show the plot","501a5c1d":"import pandas as pd\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()\n\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","14dbf96a":"# Clean the data (replace N\/A value, convert string to integer)\ndef clean_data(data):\n    data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())\n    data['Age'] = data['Age'].fillna(data['Age'].dropna().median())\n    \n    data.loc[data['Sex'] == \"male\", \"Sex\"] = 0\n    data.loc[data['Sex'] == \"female\", \"Sex\"] = 1\n    \n    data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\")\n    data.loc[data['Embarked'] == \"S\", \"Embarked\"] = 0\n    data.loc[data['Embarked'] == \"C\", \"Embarked\"] = 1\n    data.loc[data['Embarked'] == \"Q\", \"Embarked\"] = 2","7b5eb4a4":"import pandas as pd\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\n\n# Load the data set\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n# Make some cleaning\nclean_data(train_data)\n\n#\u00a0Make some split on the data set\ntarget = train_data['Survived'].values\nfeatures = train_data[[\"Pclass\", \"Age\", \"Fare\", \"Embarked\", \"Sex\", \"SibSp\", \"Parch\"]].values\ntarget_train, target_test, features_train, features_test = train_test_split(target, features, test_size=0.1)\n\n#\u00a0For understanding => printing of the result\n# print(target_train)\n# print(target_test)\n# print(features_train)\n# print(features_test)\n\n#\u00a0Apply our linear_model on the data split\nclassifier = linear_model.LogisticRegression()\nclassifier_ = classifier.fit(features, target)\n\nclassifier2_ = classifier.fit(features_train, target_train)\n\n#\u00a0See the score on the trainning data we have on it\nprint('Difference between all the dataset and the split dataset:')\nprint(\"Full data: \", classifier_.score(features, target))\nprint(\"Split data\", classifier2_.score(features_train, target_train))\n\n# See the score on the test data we have on it\nprint('Difference between the 2 models after trainning on the same data set test:')\nprint(\"Full data: \", classifier_.score(features_test, target_test))\nprint(\"Split data\", classifier2_.score(features_test, target_test))\n\n# Make some split on the data set\ntarget2 = train_data['Survived'].values\nfeatures2 = train_data[[\"Pclass\", \"Age\", \"Fare\", \"Embarked\"]].values\nclassifier = linear_model.LogisticRegression()\nclassifier2_ = classifier.fit(features2, target2)\nprint('Without 3 colomn:')\nprint(classifier2_.score(features2, target2))\n\n# Make some split on the data set\ntarget3 = train_data['Survived'].values\nfeatures3 = train_data[[\"Pclass\", \"Fare\", \"Embarked\"]].values\nclassifier = linear_model.LogisticRegression()\nclassifier3_ = classifier.fit(features3, target3)\nprint('Without 4 colomn:')\nprint(classifier3_.score(features3, target3))","54d437bc":"import pandas as pd\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\n\n# Load the data set\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n# Make some cleaning\nclean_data(train_data)\n\n# Make some split on the data set\ntarget = train_data['Survived'].values\nfeatures = train_data[[\"Pclass\", \"Age\", \"Fare\", \"Embarked\", \"Sex\", \"SibSp\", \"Parch\"]].values\ntarget_train, target_test, features_train, features_test = train_test_split(target, features, test_size=0.1)\n\n# For understanding => printing of the result\n# print(target_train)\n# print(target_test)\n# print(features_train)\n# print(features_test)\n\n# Apply our linear_model on the data split\nclassifier = linear_model.LogisticRegression()\nclassifier_ = classifier.fit(features, target)\n\nclassifier2_ = classifier.fit(features_train, target_train)\n\n# See the score on the trainning data we have on it\nprint('Difference between all the dataset and the split dataset:')\nprint(\"Full data: \", classifier_.score(features, target))\nprint(\"Split data\", classifier2_.score(features_train, target_train))\n\n# See the score on the test data we have on it\nprint('Difference between the 2 models after trainning on the same data set test:')\nprint(\"Full data: \", classifier_.score(features_test, target_test))\nprint(\"Split data\", classifier2_.score(features_test, target_test))\n\n# Make some split on the data set\ntarget2 = train_data['Survived'].values\nfeatures2 = train_data[[\"Pclass\", \"Age\", \"Fare\", \"Embarked\"]].values\nclassifier = linear_model.LogisticRegression()\nclassifier2_ = classifier.fit(features2, target2)\nprint('Without 3 colomn:')\nprint(classifier2_.score(features2, target2))\n\n# Make some split on the data set\ntarget3 = train_data['Survived'].values\nfeatures3 = train_data[[\"Pclass\", \"Fare\", \"Embarked\"]].values\nclassifier = linear_model.LogisticRegression()\nclassifier3_ = classifier.fit(features3, target3)\nprint('Without 4 colomn:')\nprint(classifier3_.score(features3, target3))","e20028df":"<h2>Decision Trees Models<\/h2>","4107aba9":"Conclusion about the Models","7644aa54":"We have to make the knn model","d7431153":"<h2>kNN Models<\/h2>","67caa63f":"This one I don't know if we have to keep it, or move it the model => the smallest models that we can find","d71b468e":"<h2>Exploratory Data Analysis<\/h2>","df47fe05":"<h3>Function of normalizing and cleaning the data (we have to found an other one solution...<\/h3>","e289dc90":"<h3>Count data's repartion in the dataset<\/h3>","1722a98f":"We have to split it to make the part of analyse","cd24c3c5":"<h3>Statistics<\/h3>\n<p>In order to choose the related attributs<\/p>","7033cd3f":"<h2>Linear Models<\/h2>","e1b2ae5e":"<h2>Effect of sample size and selection of attributes on models<\/h2>","6619b5b8":"<h2>Work with models<\/h2>","b6aa5442":"<h2>Naive Bayes<\/h2>","d96425e2":"<h1>Projet Kaggle Titanic competition<\/h1>\n<ul>\n    <li>Exploratory Data Analysis<\/li>\n    <li>Work with models<\/li>\n        <ul>\n            <li>kNN Models<\/li>\n            <li>Linear Models<\/li>\n            <li>Decision Trees Models<\/li>\n            <li>Naive Bayes<\/li>\n        <\/ul>\n    <li>Conclusion about the Models<\/li>\n    <li>Effect of sample size and selection of attributes on models<\/li>\n<\/ul>"}}