{"cell_type":{"19be4594":"code","b481becd":"code","1a84e59b":"code","6fb71183":"code","db4842b2":"code","2a75ade2":"code","3ec4a3ea":"code","7394c2ba":"code","cbbc6323":"code","acac3dd8":"code","2d2d0c2c":"code","0ba7eb08":"markdown","c0515759":"markdown","2c06691d":"markdown","7f61093a":"markdown","eb9ff174":"markdown","e69f9770":"markdown"},"source":{"19be4594":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import rankdata\n\ndef MSE(X,Y,W):\n    return((1\/X.shape[0])*Loss(Y,getPred(X,W)))\n\ndef getPred(x,W):\n    return(np.matmul(x,W))\n# The basic loss, sum over the difference of y-ypred\ndef Loss(y,ypred):\n    l=(y-ypred)**2\n    return(l.sum())\n\ndef GradDesc(X,Y,learnRate=0.01,epochs=2000,reg=0):\n    \n    global cacheLoss\n    cacheLoss=[None]*epochs\n    #scaling\n    x_train_scaled=np.array(X)\n    y_train=np.array(Y)\n    y_train=y_train.reshape(-1,1)\n    #scaling\n    \n   # Random Initialization of Weights\n    Weights=np.random.rand(x_train_scaled.shape[1])\n    \n    Weights=np.array(Weights)\n    Weights=Weights.reshape(-1,1)\n    m=x_train_scaled.shape[0]\n    \n    for i in range(epochs):\n        \n        predictions=getPred(x_train_scaled,Weights)\n        cacheLoss[i]=Loss(y_train,predictions)\n        \n        Weights[0]=Weights[0]-(1\/m)*learnRate*(np.matmul(x_train_scaled[:,0].transpose(),predictions-y_train))\n        \n        for j in range(1,len(Weights)):\n            \n            Weights[j]=Weights[j]-(1\/m)*learnRate*(np.matmul(x_train_scaled[:,j].transpose(),predictions-y_train)+sum(np.dot(Weights[j],reg)))\n    return(Weights)\n\ndef getRidgeLambda(x,y,X_Validate,Y_Validate):\n    \n    bestMSE=10e100\n    \n    lamList=[l*0.05 for l in range(0,300)]\n\n    global ridgeLambda\n    \n    for l in lamList:\n        Wr=GradDesc(x,y,reg=l)\n        if MSE(X_Validate,Y_Validate,Wr)< bestMSE:\n            bestMSE=MSE(X_Validate,Y_Validate,Wr)\n            ridgeLambda=l\n          \n    \n    return(ridgeLambda)\n\ndef ridge_cv (vec, X, y, X_test, folds, stratified ):\n    kf = StratifiedKFold(n_splits=FOLDS,shuffle=True,random_state=123)\n    val_scores = []\n    rmse_scores = []\n    X_less_toxics = []\n    X_more_toxics = []\n\n    preds = []\n    for fold, (train_index,val_index) in enumerate(kf.split(X,stratified)):\n        X_train, y_train = X[train_index], y[train_index]\n        X_val, y_val = X[val_index], y[val_index]\n        #ridgeLambda = getRidgeLambda(X_train,y_train,X_val,y_val)\n        #ridgeLambda\n        model = Ridge(solver='sag',max_iter=2000,tol=1e-5)\n        model.fit(X_train, y_train)\n\n        rmse_score = mean_squared_error ( model.predict (X_val), y_val, squared = False) \n        rmse_scores.append (rmse_score)\n\n        X_less_toxic = vec.transform(df_val['less_toxic'])\n        X_more_toxic = vec.transform(df_val['more_toxic'])\n\n        p1 = model.predict(X_less_toxic)\n        p2 = model.predict(X_more_toxic)\n\n        X_less_toxics.append ( p1 )\n        X_more_toxics.append ( p2 )\n\n        # Validation Accuracy\n        val_acc = (p1< p2).mean()\n        val_scores.append(val_acc)\n\n        pred = model.predict (X_test)\n        preds.append (pred)\n\n        print(f\"FOLD:{fold}, rmse_fold:{rmse_score:.5f}, val_acc:{val_acc:.5f}\")\n\n    mean_val_acc = np.mean (val_scores)\n    mean_rmse_score = np.mean (rmse_scores)\n\n    p1 = np.mean ( np.vstack(X_less_toxics), axis=0 )\n    p2 = np.mean ( np.vstack(X_more_toxics), axis=0 )\n\n    val_acc = (p1< p2).mean()\n\n    print(f\"OOF: val_acc:{val_acc:.5f}, mean val_acc:{mean_val_acc:.5f}, mean rmse_score:{mean_rmse_score:.5f}\")\n    \n    preds = np.mean ( np.vstack(preds), axis=0 )\n    \n    return p1, p2, preds\n","b481becd":"df_val = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\ndf_test = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")","1a84e59b":"jc_train_df = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\nprint(f\"jc_train_df:{jc_train_df.shape}\")","6fb71183":"toxic = 1.0\nsevere_toxic = 2.0\nobscene = 1.0\nthreat = 1.0\ninsult = 1.0\nidentity_hate = 2.0\n\ndef create_train (df):\n    df['y'] = df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].max(axis=1)\n    df['y'] = df[\"y\"]+df['severe_toxic']*severe_toxic\n    df['y'] = df[\"y\"]+df['obscene']*obscene\n    df['y'] = df[\"y\"]+df['threat']*threat\n    df['y'] = df[\"y\"]+df['insult']*insult\n    df['y'] = df[\"y\"]+df['identity_hate']*identity_hate\n    \n    \n    \n    df = df[['comment_text', 'y', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].rename(columns={'comment_text': 'text'})\n\n    #undersample non toxic comments  on Toxic Comment Classification Challenge\n    min_len = (df['y'] >= 1).sum()\n    df_y0_undersample = df[df['y'] == 0].sample(n=int(min_len*1.5),random_state=201)\n    df = pd.concat([df[df['y'] >= 1], df_y0_undersample])\n                                                \n    return df\n \njc_train_df = create_train (jc_train_df)\n                           \ndf = jc_train_df\nprint(df['y'].value_counts())\n","db4842b2":"FOLDS = 7\n\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(3, 6) )\nX = vec.fit_transform(df['text'])\ny = df[\"y\"].values\nX_test = vec.transform(df_test['text'])\n\nstratified = np.around ( y )\njc_p1, jc_p2, jc_preds =  ridge_cv (vec, X, y, X_test, FOLDS, stratified )","2a75ade2":"juc_train_df = pd.read_csv(\"..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv\")\nprint(f\"juc_train_df:{juc_train_df.shape}\")\njuc_train_df = juc_train_df.query (\"toxicity_annotator_count > 5\")\nprint(f\"juc_train_df:{juc_train_df.shape}\")\n\njuc_train_df['y'] = juc_train_df[[ 'severe_toxicity', 'obscene', 'sexual_explicit','identity_attack', 'insult', 'threat']].sum(axis=1)\n\njuc_train_df['y'] = juc_train_df.apply(lambda row: row[\"target\"] if row[\"target\"] <= 0.5 else row[\"y\"] , axis=1)\njuc_train_df = juc_train_df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\nmin_len = (juc_train_df['y'] > 0.5).sum()\ndf_y0_undersample = juc_train_df[juc_train_df['y'] <= 0.5].sample(n=int(min_len*1.5),random_state=201)\njuc_train_df = pd.concat([juc_train_df[juc_train_df['y'] > 0.5], df_y0_undersample])\n\ndf = juc_train_df\nprint(df['y'].value_counts())","3ec4a3ea":"FOLDS = 7\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(3, 6) )\nX = vec.fit_transform(df['text'])\ny = df[\"y\"].values\nX_test = vec.transform(df_test['text'])\n\nstratified = (np.around ( y, decimals = 1  )*10).astype(int)\njuc_p1, juc_p2, juc_preds =  ridge_cv (vec, X, y, X_test, FOLDS, stratified )","7394c2ba":"rud_df = pd.read_csv(\"..\/input\/ruddit-jigsaw-dataset\/Dataset\/ruddit_with_text.csv\")\nprint(f\"rud_df:{rud_df.shape}\")\nrud_df['y'] = rud_df['offensiveness_score'].map(lambda x: 0.0 if x <=0 else x)\nrud_df = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})\nmin_len = (rud_df['y'] < 0.5).sum()\nprint(rud_df['y'].value_counts())","cbbc6323":"FOLDS = 7\ndf = rud_df\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(3, 6) )\nX = vec.fit_transform(df['text'])\ny = df[\"y\"].values\nX_test = vec.transform(df_test['text'])\n\nstratified = (np.around ( y, decimals = 1  )*10).astype(int)\nrud_p1, rud_p2, rud_preds =  ridge_cv (vec, X, y, X_test, FOLDS, stratified )","acac3dd8":"jc_max = max(jc_p1.max() , jc_p2.max())\njuc_max = max(juc_p1.max() , juc_p2.max())\nrud_max = max(rud_p1.max() , rud_p2.max())\n\n\np1 = jc_p1\/jc_max + juc_p1\/juc_max + rud_p1\/rud_max\np2 = jc_p2\/jc_max + juc_p2\/juc_max + rud_p2\/rud_max\n\nval_acc = (p1< p2).mean()\njc_p1\njc_p2\njuc_p1\njuc_p2\nrud_p1\nrud_p2\njc_max\njuc_max\nrud_max\np1\np2\n\nprint(f\"Ensemble: val_acc:{val_acc:.5f}\")","2d2d0c2c":"score = jc_preds\/jc_max + juc_preds\/juc_max + rud_preds\/rud_max  \n## to enforce unique values on score\ndf_test['score'] = rankdata(score, method='ordinal')\n\ndf_test[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\n\ndf_test.head()","0ba7eb08":"# Submission","c0515759":"# How far can we push linear models in LB ? :)\n\ncheck out these forerunners too\n\n\n* https:\/\/www.kaggle.com\/steubk\/jrsotc-ridgeregression\n\nDone:- Modified the code from steubk with more folds 5 to 6 and ngram range from 4,6 to 3,6-> improved val acc by 0.00111 and LB by 0.005 - current LB 0.830\nToDo:- Planning to add RidgeLambda and see\n\n","2c06691d":"## Ensemble","7f61093a":"## Model Ruddit: Norms of Offensiveness for English Reddit Comments\n\nUsing data from [Ruddit](https:\/\/github.com\/hadarishav\/Ruddit)","eb9ff174":"# Model Unintended Bias in Toxicity Classification\n\nUsing data from [Unintended Bias in Toxicity Classification](https:\/\/www.kaggle.com\/c\/jigsaw-unintended-bias-in-toxicity-classification\/data)\n","e69f9770":"# Model Toxic Comment Classification Challenge\n\nUsing data from [Toxic Comment Classification Challenge](https:\/\/www.kaggle.com\/c\/jigsaw-toxic-comment-classification-challenge)"}}