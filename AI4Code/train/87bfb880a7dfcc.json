{"cell_type":{"518baec6":"code","2faa1794":"code","f2c32a80":"code","eb3f1c4b":"code","239b3c00":"code","4d8232d5":"code","49e85f2e":"code","4972b30c":"code","008a6d9d":"code","cea27c28":"code","7fc1297d":"code","bb8cba62":"code","8ba34ccc":"code","e07347c6":"code","51fde928":"code","25485a4a":"code","a7a629a1":"code","ca6f2744":"code","72f50874":"code","449e0d4c":"code","636e04bd":"code","e840be62":"code","d7c611c4":"code","e0e7ded9":"code","a8c2335c":"code","8aa44688":"code","d2604d08":"code","31f509be":"code","69b19cb2":"code","de52502d":"code","e79ac728":"code","7d118de7":"code","358ec346":"code","a96e6156":"code","3cbda8af":"code","5caeaa65":"code","37c3246f":"code","5d526803":"code","d8121304":"code","eb6d53bb":"code","bcce9ac6":"code","53f531e5":"code","ca8cb591":"code","fc2b900c":"code","005654c5":"code","9d4a9e7e":"code","2cc8f366":"code","09958055":"code","468b4ab0":"code","2d556c22":"code","9adf29b1":"code","d54d3f61":"code","3e04c266":"code","7a663423":"code","0a775b2d":"code","c0bfc72b":"code","868a4140":"code","c245b085":"code","e7871a65":"code","589bf0a2":"code","a0dba1b4":"code","59cb0bf1":"code","f7ae04fb":"code","ca98a8ad":"code","a8c5be1b":"markdown","2e201077":"markdown","0545a132":"markdown","85ae515a":"markdown","5992a559":"markdown","e98f4c05":"markdown","19b715f8":"markdown","83c46632":"markdown","6d8e3af3":"markdown","5332680f":"markdown","e85b21c9":"markdown","e42c5bb8":"markdown","d239fe1c":"markdown","929d9222":"markdown","8db4e531":"markdown","ea2d403c":"markdown","148f92ad":"markdown","8250a1fe":"markdown","6283f0e4":"markdown","313db77c":"markdown","2243e261":"markdown","3de6512c":"markdown","a22e629c":"markdown","34d69a41":"markdown","c3f27b6f":"markdown","58179d17":"markdown","7720ebde":"markdown","c0113b31":"markdown","51d8cc77":"markdown","f6b94dd0":"markdown"},"source":{"518baec6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2faa1794":"import random as rnd\n\n#Visualizition \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#machine Learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n","f2c32a80":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ncombine = [train_df,test_df]\n","eb3f1c4b":"print(train_df.columns.values)","239b3c00":"#Categorial Feuatues : Survived,Pclass,Sex\n#Numerical Features: Countinous:Age,Fare  Discrete:Parch,Sibsp\ntrain_df.head()","4d8232d5":"train_df.tail()","49e85f2e":"train_df.info()\nprint('##'*40)\ntest_df.info()","4972b30c":"train_df.describe()","008a6d9d":"train_df[['Pclass','Survived']].groupby(['Pclass'],as_index = False).mean().sort_values(by='Survived',ascending=False)","cea27c28":"train_df[['Sex','Survived']].groupby(['Sex'],as_index=False).mean().sort_values(by='Survived',ascending =False)","7fc1297d":"train_df[['SibSp','Survived']].groupby(['SibSp'],as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","bb8cba62":"train_df[['Parch','Survived']].groupby(['Parch'],as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","8ba34ccc":"g =sns.FacetGrid(train_df,col='Survived')\ng.map(plt.hist,\"Age\",bins=20)\nh = sns.FacetGrid(train_df,col='Pclass')\nh.map(plt.hist,\"Age\",bins=30)\ne= sns.FacetGrid(train_df,col='Embarked')\ne.map(plt.hist,'Age',bins=40)","e07347c6":"grid = sns.FacetGrid(train_df,col='Survived',row='Pclass',height=2.2,aspect=1.6)\ngrid.map(plt.hist,\"Age\",alpha =1,bins=20)","51fde928":"grid = sns.FacetGrid(train_df,row=\"Embarked\",height=2.2,aspect=1.6)\ngrid.map(sns.pointplot,'Pclass','Survived','Sex',palette = 'deep')\ngrid.add_legend()","25485a4a":"grid = sns.FacetGrid(train_df,row=\"Embarked\",col='Survived',height=2.2,aspect=1.6)\ngrid.map(sns.barplot,'Sex','Fare',alpha =1 ,ci=None)","a7a629a1":"print(\"Data Shape Before Correction  : \")\nprint(\"train_data Shape :\",train_df.shape)\nprint(\"test_data Shape : \",test_df.shape)\nprint(\"Combine 0 Shape: \",combine[0].shape)\nprint(\"Combine 1 Shape : \",combine[1].shape)","ca6f2744":"train_df = train_df.drop([\"Ticket\",\"Cabin\"],axis=1)\ntest_df = test_df.drop([\"Ticket\",'Cabin'],axis=1)\ncombine = [train_df,test_df]","72f50874":"print(\"Data Shape after Correction  : \")\nprint(\"train_data Shape :\",train_df.shape)\nprint(\"test_data Shape : \",test_df.shape)\nprint(\"Combine 0 Shape: \",combine[0].shape)\nprint(\"Combine 1 Shape : \",combine[1].shape)","449e0d4c":"# Fetch Titles from Name \nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.',expand=False)\npd.crosstab(train_df[\"Title\"],train_df['Sex'])","636e04bd":"# Remove rare Titels From Dataset\nfor dataset in combine:\n    dataset['Title'] =dataset['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Rare')\n    dataset['Title']=dataset['Title'].replace('Mlle','Miss')\n    dataset['Title']=dataset['Title'].replace('Ms','Miss')\n    dataset['Title']=dataset['Title'].replace('Mme','Mrs')\n    \ntrain_df[[\"Title\",'Survived']].groupby(['Title'],as_index=False).mean()","e840be62":"# Normalize titles \ntitle_maping = {'Mr':1,\"Miss\":2,'Mrs':3,'Master':4,'Rare':5}\nfor dataset in combine:\n    dataset['Title']= dataset['Title'].map(title_maping)\n    dataset['Title'] = dataset['Title'].fillna(0)\ntrain_df.head()","d7c611c4":"test_df.head()","e0e7ded9":"#Remove Name and ID from Dataset\ntrain_df = train_df.drop(['PassengerId','Name'],axis=1)\ntest_df = test_df.drop(['Name'],axis=1)","a8c2335c":"combine =[train_df,test_df]\ntrain_df.shape , test_df.shape","8aa44688":"train_df.head()","d2604d08":"test_df.head()","31f509be":"#map female to 1 and male to 0 in dataset\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female':1,'male':0}).astype(int)\ntrain_df.head()","69b19cb2":"grid = sns.FacetGrid(train_df,col='Pclass',row='Sex',height=2.2,aspect=1.6)\ngrid.map(plt.hist,'Age',bins =20,alpha =.7)\ngrid.add_legend()","de52502d":"guess_ages = np.zeros((2,3))\nguess_ages","e79ac728":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","7d118de7":"train_df['AgeBand'] = pd.cut(train_df['Age'],5)\ntrain_df[['AgeBand','Survived']].groupby(['AgeBand'],as_index = False).mean().sort_values(by='AgeBand',ascending=True)","358ec346":"for  dataset in combine:\n    dataset.loc[dataset['Age'] <= 16 ,'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32),'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48),'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64),'Age'] = 3\n    dataset.loc[dataset['Age'] > 64,'Age'] = 4\n    \ntrain_df.head()\n    ","a96e6156":"train_df = train_df.drop(['AgeBand'] ,axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","3cbda8af":"for dataset in combine: \n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\ntrain_df[['FamilySize','Survived']].groupby(['FamilySize'],as_index=False).mean().sort_values(by='Survived',ascending = False)","5caeaa65":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize']==1,'IsAlone']= 1\ntrain_df[['IsAlone','Survived']].groupby('IsAlone',as_index=False).mean()","37c3246f":"train_df = train_df.drop(['Parch','SibSp','FamilySize'],axis=1)\ntest_df = test_df.drop(['Parch','SibSp','FamilySize'],axis=1)\ncombine = [train_df,test_df]\ntrain_df.head()","5d526803":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\ntrain_df.loc[:,['Age*Class','Age','Pclass']].head()","d8121304":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","eb6d53bb":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)","bcce9ac6":"train_df[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean().sort_values(by='Survived',ascending = False)","53f531e5":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map({'S':0,'C':1,'Q':2}).astype(int)","ca8cb591":"train_df.head()","fc2b900c":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","005654c5":"train_df['FareBand'] = pd.qcut(train_df['Fare'],4)\ntrain_df[['FareBand','Survived']].groupby(by='FareBand',as_index=False).mean().sort_values(by='Survived',ascending =True)","9d4a9e7e":"for dataset in combine:\n    dataset.loc[dataset['Fare'] <= 7.91,'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.45) ,'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.45) & (dataset['Fare'] >= 31) ,'Fare'] = 2\n    dataset.loc[dataset['Fare'] > 31 ,'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df,test_df]\ntrain_df.head()","2cc8f366":"test_df.head(10)","09958055":"X_train = train_df.drop('Survived', axis=1)\nY_train = train_df['Survived']\nX_test = test_df.drop('PassengerId',axis=1).copy()\nX_train.shape,Y_train.shape,X_test.shape\n","468b4ab0":"logreg = LogisticRegression()\nlogreg.fit(X_train,Y_train)\nY_predict = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train,Y_train) * 100,2)\nacc_log","2d556c22":"coeff_df =  pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df['Correlation'] = pd.Series(logreg.coef_[0])\ncoeff_df.sort_values(by='Correlation',ascending=False)","9adf29b1":"svc = SVC()\nsvc.fit(X_train,Y_train)\nY_predict = svc.predict(X_test)\nacc_svc = round(svc.score(X_train,Y_train) * 100,2)\nacc_svc","d54d3f61":"knn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train,Y_train)\nY_predict = knn.predict(X_test)\nacc_knn = round(knn.score(X_train,Y_train) * 100 ,2)\nacc_knn","3e04c266":"gaussian = GaussianNB()\ngaussian.fit(X_train,Y_train)\ngaussian.predict(X_test)\nacc_guassian =round(gaussian.score(X_train,Y_train)*100,2)\nacc_guassian","7a663423":"perceptron = Perceptron()\nperceptron.fit(X_train,Y_train)\nY_predict = perceptron.predict(X_test)\nacc_percptron = round(perceptron.score(X_train,Y_train)*100,2)\nacc_percptron","0a775b2d":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train,Y_train)\nY_predict = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train,Y_train) * 100 ,2)\nacc_linear_svc\n","c0bfc72b":"sgd =SGDClassifier()\nsgd.fit(X_train,Y_train)\nY_predict = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train,Y_train)*100,2)\nacc_sgd","868a4140":"decision_tree =DecisionTreeClassifier()","c245b085":"decision_tree.fit(X_train,Y_train)\nY_predict = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train,Y_train)* 100,2)","e7871a65":"acc_decision_tree","589bf0a2":"random_forest = RandomForestClassifier()\nrandom_forest.fit(X_train,Y_train)\nY_predict = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train,Y_train)*100,2)\nacc_random_forest","a0dba1b4":"models = pd.DataFrame({'model':['Support Vector Machines','KNN','Logistic Regression','Random Forest','Navie Bayes','Precptron','Stochastic Gradiant Decent','Linear SVC','Decision Tree'],\n                      'Score':[acc_svc,acc_knn,acc_log,acc_random_forest,acc_guassian,acc_percptron,acc_sgd,acc_linear_svc,acc_decision_tree]})\nmodels.sort_values(by='Score',ascending =False)","59cb0bf1":"subbmision = pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':Y_predict})","f7ae04fb":"subbmision.head()","ca98a8ad":"subbmision.to_csv('\/kaggle\/working\/__notebook_source__.ipynb',index=False)","a8c5be1b":"# Fill Null Age Values","2e201077":"# **Percptron**","0545a132":"# Categorize Fare","85ae515a":"# Fetch Titles From Name Columns","5992a559":"# Make X_train , Y_train ,X_test","e98f4c05":"Import Train and Test Data to Document","19b715f8":"# Decision Tree Classifier","83c46632":"# **# Data Visualization**","6d8e3af3":"# Fill Null Embarked","5332680f":"# **Random Forest **","e85b21c9":"# **Data Correction**","e42c5bb8":"# **Gaussina Navie Bayes**","d239fe1c":"# Methods : \n    1-Random Number between mean and std\n    2-More detail Geussing with involving Parameters such Pclass,Gender \n    3-Mix Method 1,2\n    We are using Method 2","929d9222":"# **Linear SVC**","8db4e531":"# map female to 1 and male to 0 in dataset","ea2d403c":"# Detremine Age Band","148f92ad":"# KNN Neighbors****","8250a1fe":"# Model Evalution","6283f0e4":"# Fill Null Fare","313db77c":"# Normalize titles ","2243e261":"# Age * Class","3de6512c":"# Family Size","a22e629c":"# **Complete Dataset Where Null Values**","34d69a41":"# Stochastic Gradiant Desent","c3f27b6f":"Remove Useless Columns","58179d17":"# Support Vector Machines\n","7720ebde":"# Convert Port To Int","c0113b31":"# Remove Name and ID from Dataset","51d8cc77":"# Remove rare Titels From Dataset","f6b94dd0":"# Logistic Regression"}}