{"cell_type":{"faed6b03":"code","846851ac":"code","5f7b92dd":"code","be88836c":"code","68fd0c2f":"code","e01b3a67":"code","d322704c":"code","ed272489":"code","57752867":"code","3c866b1e":"code","d8818832":"code","12cc4687":"code","172fff2c":"code","62bb46b8":"code","14d5afdb":"code","41c39a88":"code","d91d5688":"code","5749b6d6":"code","7c0e8d92":"code","0e9c8ee5":"code","27a93aa6":"code","746a7d89":"code","f0a2f9ac":"code","6d14bf87":"code","d19774c6":"code","e5c5c2fa":"code","a4399213":"code","51b4e93f":"code","48dd32c3":"code","eda1407e":"code","e26d46f3":"code","a5c930e2":"code","5a84f9d4":"code","f2e88f6d":"code","62d1a5b0":"code","3b23a435":"code","480bc62b":"code","5025e62d":"code","3436577d":"code","707f3894":"code","c9f012d5":"code","3b35e439":"code","551b19c5":"code","2c24299f":"code","047f0895":"code","6ae2fee8":"code","450f92a5":"code","49fea38b":"code","b786a3ab":"code","7c6939b7":"code","038f4921":"code","cfda0601":"code","43a88480":"code","e1236d97":"code","29d793b0":"code","35ada981":"code","d464d487":"code","73a4f7d3":"code","1063fb0d":"code","091b7216":"code","d76b740d":"code","9ed13589":"code","efd3f77c":"code","18971162":"code","e35cc9b3":"code","24ead6f0":"code","41ec358b":"code","138e8fd9":"code","ad649bcb":"code","ef6a2b00":"code","4e6b5f92":"code","af9f7eef":"code","bc13ff1c":"code","4e1f72ba":"code","f7a050b3":"code","4dd95f0d":"code","69682183":"code","cdd94983":"code","60c12e95":"code","884c5632":"code","0f502984":"code","6f7f3baa":"code","2ffa6d29":"code","af0cfb8e":"code","de844022":"code","1de2cb17":"code","e4166e01":"markdown","a65bc8a9":"markdown","278576f4":"markdown","d9c6d965":"markdown","197b6107":"markdown","61688e98":"markdown","37e026f8":"markdown","aa0f72b2":"markdown","fd13593c":"markdown","11afa684":"markdown","fe26e8db":"markdown","537dd852":"markdown","5837686e":"markdown"},"source":{"faed6b03":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","846851ac":"train = pd.read_csv('\/kaggle\/input\/janatahack-mobility-analysis\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/janatahack-mobility-analysis\/test.csv')\nsubmit = pd.read_csv('\/kaggle\/input\/janatahack-mobility-analysis\/sample_submission.csv')","5f7b92dd":"print(train.shape)\nprint(test.shape)","be88836c":"train","68fd0c2f":"train.dtypes","e01b3a67":"train.isna().sum()","d322704c":"sns.distplot(train['Trip_Distance'],kde = False,norm_hist=False)","ed272489":"train['Trip_Distance'].max()\ntrain['Trip_Distance'].min()","57752867":"train['Type_of_Cab'].unique()","3c866b1e":"sns.countplot(train['Type_of_Cab'])","d8818832":"train['Type_of_Cab'].isna().sum()","12cc4687":"#train['Customer_Since_Months'].astype(int)\ntrain['Customer_Since_Months'].value_counts()\nsns.countplot(train['Customer_Since_Months'])","172fff2c":"train['Destination_Type'].unique()","62bb46b8":"sns.countplot(train['Destination_Type'])","14d5afdb":"train['Destination_Type'].value_counts()","41c39a88":"train.Cancellation_Last_1Month.value_counts()","d91d5688":"sns.countplot(train.Cancellation_Last_1Month)","5749b6d6":"var = [train['Var1'],train['Var2'],train['Var3']]\nfor variables in var:\n    sns.distplot(variables)\n    plt.show()","7c0e8d92":"sns.countplot(train['Gender'])","0e9c8ee5":"sns.countplot(train['Surge_Pricing_Type'])","27a93aa6":"train.dropna()","746a7d89":"df = train.append(test)","f0a2f9ac":"test.shape","6d14bf87":"test.isna().sum()","d19774c6":"df.isna().sum()","e5c5c2fa":"sns.countplot(df['Destination_Type'])","a4399213":"df['Destination_Type'].fillna(df['Destination_Type'].mode(),inplace = True)","51b4e93f":"sns.countplot(df['Cancellation_Last_1Month'])","48dd32c3":"df['Cancellation_Last_1Month'].isna().sum()","eda1407e":"df[df['Type_of_Cab'].isna() == True]","e26d46f3":"sns.countplot(df['Type_of_Cab'])","a5c930e2":"df['Type_of_Cab'] = df['Type_of_Cab'].fillna('F')","5a84f9d4":"sns.countplot(df['Type_of_Cab'])","f2e88f6d":"df['Customer_Since_Months'].value_counts()","62d1a5b0":"df[df['Customer_Since_Months'].isna() == True]","3b23a435":"df[df['Customer_Since_Months'].isna() == False].mean()","480bc62b":"sns.countplot(df['Customer_Since_Months'])","5025e62d":"df['Customer_Since_Months'].fillna(10.0,inplace = True)","3436577d":"df.columns","707f3894":"print(\"Minimum Value\",df['Life_Style_Index'].min())\nprint(\"Maximum Value\",df['Life_Style_Index'].max())\nprint(\"Average Value\",df['Life_Style_Index'].mean())\nsns.distplot(df['Life_Style_Index'])","c9f012d5":"sns.countplot(df['Confidence_Life_Style_Index'])","3b35e439":"df.groupby('Confidence_Life_Style_Index')['Life_Style_Index'].median()","551b19c5":"print(df['Life_Style_Index'].mean())\ndf['Life_Style_Index'].median()","2c24299f":"df['Life_Style_Index'].fillna(df['Life_Style_Index'].mean(),inplace = True)\ndf['Confidence_Life_Style_Index'].fillna('D',inplace = True)","047f0895":"print(df['Var1'].mean())\nprint(df['Var1'].median())","6ae2fee8":"sns.distplot(df['Var1'])","450f92a5":"df['Var1'].value_counts()","49fea38b":"df[['Var1','Var2','Var3']].corr()","b786a3ab":"df.groupby('Var1')[['Var2','Var3']].mean()","7c6939b7":"df['Var1'].fillna(64,inplace = True)","038f4921":"df.isna().sum()","cfda0601":"df[['Var1','Var2','Var3']] = df[['Var1','Var2','Var3']].astype(int)","43a88480":"df['Customer_Since_Months'] = df['Customer_Since_Months'].astype(int)","e1236d97":"categorical = ['Type_of_Cab','Confidence_Life_Style_Index','Destination_Type','Gender']","29d793b0":"from sklearn import preprocessing \n  \n\nlabel_encoder = preprocessing.LabelEncoder() \nfor i in categorical:\n    df[i]= label_encoder.fit_transform(df[i]) ","35ada981":"df","d464d487":"trains = df[df['Surge_Pricing_Type'].isna() == False]\ntests = df[df['Surge_Pricing_Type'].isna() == True]","73a4f7d3":"trains['Surge_Pricing_Type'] = trains['Surge_Pricing_Type'].astype(int)","1063fb0d":"trains","091b7216":"tests","d76b740d":"trains.to_csv('train.csv',index = False)\ntests.to_csv('test.csv',index = False)","9ed13589":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score","efd3f77c":"categorical = ['Type_of_Cab','Confidence_Life_Style_Index','Destination_Type','Gender']","18971162":"trains.columns","e35cc9b3":"train_x = trains.drop(columns=['Surge_Pricing_Type','Trip_ID'],axis=1)\ntrain_y = trains['Surge_Pricing_Type']","24ead6f0":"test_x = tests.drop(columns=['Surge_Pricing_Type','Trip_ID'],axis=1)","41ec358b":"trains","138e8fd9":"#import h2o\n#h2o.init()\n#train1 = h2o.H2OFrame(train)\n#test1 = h2o.H2OFrame(tests)\n#train1.columns\n#y = 'Surge_Pricing_Type'\n#x = train1.col_names\n#x.remove(y)\n#train1['Surge_Pricing_Type'] = train1['Surge_Pricing_Type'].asfactor()\n#train1['Surge_Pricing_Type'].levels()\n#from h2o.automl import H2OAutoML\n#aml = H2OAutoML(max_models = 20,max_runtime_secs=2000, seed = 42)\n#aml.train(x = x, y = y, training_frame = train1)\n#preds = aml.predict(test1)\n#ans=h2o.as_list(preds) \n#submit['target'] = ans['predict']\n#submit.to_csv('Solution_of_H20_EDA.csv',index=False)","ad649bcb":"def extra_tree(Xtrain,Ytrain,Xtest):\n    extra = ExtraTreesClassifier()\n    extra.fit(Xtrain, Ytrain) \n    extra_prediction = extra.predict(Xtest)\n    return extra_prediction\n\ndef Xg_boost(Xtrain,Ytrain,Xtest):\n    xg = XGBClassifier(loss='exponential', learning_rate=0.05, n_estimators=1000, subsample=1.0, criterion='friedman_mse', \n                                  min_samples_split=2, \n                                  min_samples_leaf=5, min_weight_fraction_leaf=0.0, max_depth=10, min_impurity_decrease=0.0, \n                                  min_impurity_split=None, \n                                  init=None, random_state=None, max_features=None, verbose=1, max_leaf_nodes=None, warm_start=False, \n                                  presort='deprecated', \n                                  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n    xg.fit(Xtrain, Ytrain) \n    xg_prediction = xg.predict(Xtest)\n    return xg_prediction\ndef LGBM(Xtrain,Ytrain,Xtest):\n    lgbm = LGBMClassifier(boosting_type='gbdt', num_leaves=40,\n                            max_depth=5, learning_rate=0.05, n_estimators=1000, subsample_for_bin=200, objective='binary', \n                            min_split_gain=0.0, min_child_weight=0.001, min_child_samples=10,\n                            subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0,\n                            reg_lambda=0.0, random_state=None, n_jobs=1, silent=True, importance_type='split')\n    #lgbm = LGBMClassifier(n_estimators= 500)\n    lgbm.fit(X_train, Y_train)\n    lgbm_preds = lgbm.predict(X_test)\n    return lgbm_preds","ef6a2b00":"#target = 'Surge_Pricing_Type'\n#scoring_parameter = 'balanced-accuracy'","4e6b5f92":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom lightgbm import LGBMClassifier\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.feature_selection import SelectFwe, f_regression\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom tpot.builtins import OneHotEncoder, StackingEstimator","af9f7eef":"#pred_xg = Xg_boost(X_train,Y_train,X_test)\n#pred_et = extra_tree(X_train,Y_train,X_test)\n#pred_l = LGBM(X_train,Y_train,X_test)","bc13ff1c":"#submit['target'] = pred_xg\n#print(submit['target'].unique())\n#submit.to_csv('XG.csv',index = False)","4e1f72ba":"#submit['target'] = pred_et\n#print(submit['target'].unique())\n#submit.to_csv('ET.csv',index = False)","f7a050b3":"#from sklearn.linear_model import LogisticRegression\n#clf = LogisticRegression(random_state=0).fit(train_x, train_y)\n#ans = clf.predict(test_x)","4dd95f0d":"#submit['Surge_Pricing_Type'] = ans\n##print(submit['Surge_Pricing_Type'].unique())\n#submit.to_csv('LR.csv',index = False)","69682183":"#from sklearn.ensemble import RandomForestClassifier\n#rf = RandomForestClassifier(n_estimators=10).fit(train_x, train_y)\n#prediction_of_rf = rf.predict(test_x)\n#submit['Surge_Pricing_Type'] = prediction_of_rf\n#print(submit['Surge_Pricing_Type'].unique())\n#submit.to_csv('RF.csv',index = False)","cdd94983":"#submit['Surge_Pricing_Type'] = nri\n#submit.to_csv('Dknn.csv',index = False)","60c12e95":"target_map = {1:0, 2:1, 3:2}\ntarget_map_inverse = {0:1, 1:2, 2:3}","884c5632":"trains[\"Surge_Pricing_Type\"] = trains[\"Surge_Pricing_Type\"].map(target_map)","0f502984":"features = [col for col in trains.columns if col not in [\"Trip_ID\", \"Surge_Pricing_Type\"]]\ntarget = trains[\"Surge_Pricing_Type\"]","6f7f3baa":"param = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.5,\n    'boost': 'gbdt',\n    'feature_fraction': 0.7,\n    'learning_rate': 0.005,\n    'num_class':3,\n    'metric':'multi_logloss',\n    'max_depth': 8,  \n    'num_leaves': 70,\n    'min_data_in_leaf':40,\n    'objective': 'multiclass',\n    'scale_pos_weight':1,\n    'device':'gpu',\n    'verbosity': 1\n}","2ffa6d29":"import lightgbm as lgb\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split","af0cfb8e":"folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1048)\npredictions = np.zeros((len(tests), 3))\nfeature_importance_df = pd.DataFrame()\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(trains.values, target.values)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(trains.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(trains.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 1000000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n    predictions_val = np.argmax(clf.predict(trains.iloc[val_idx][features], num_iteration=clf.best_iteration), axis=1)\n    \n    print(\"CV score: {:<8.5f}\".format(sklearn.metrics.accuracy_score(predictions_val, target.iloc[val_idx])))\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(tests[features], num_iteration=clf.best_iteration) \/ folds.n_splits","de844022":"cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n        .groupby(\"Feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:150].index)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\nplt.figure(figsize=(10,10))\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('Features importance (averaged\/folds)')\nplt.tight_layout()\n#plt.savefig('FI.png')","1de2cb17":"predictions_test = np.argmax(predictions, axis=1)\nsubmit[\"Surge_Pricing_Type\"] = predictions_test\nsubmit[\"Surge_Pricing_Type\"] = submit[\"Surge_Pricing_Type\"].map(target_map_inverse)\nsubmit.to_csv(\"janatahack_mobility_solution.csv\", index=False)\n","e4166e01":"# Project Objective","a65bc8a9":"* The distribution is not normal","278576f4":"trains = trains.drop(columns = ['Trip_ID'],axis = 1)\ntests = tests.drop(columns = ['Trip_ID'],axis = 1)","d9c6d965":"Majority is Type B","197b6107":"The maximum distance that the customers are travelling is 110 while minimum is 0.5","61688e98":"Customer using cab services since n months; 0 month means current month\n\n\nSo, more use from 10 months","37e026f8":"**Trip_ID  **              =    ID for TRIP (Can not be used for purposes of modelling)\n\nTrip_Distance          =    The distance for the trip requested by the customer\n\nType_of_Cab            =    Category of the cab requested by the customer\n\nCustomer_Since_Months  =    Customer using cab services since n months; 0 month means current month\n\nLife_Style_Index       =    Proprietary index created by Sigma Cabs showing lifestyle of the customer based on their behaviour\n\nConfidence_Life_Style_Index    =    Category showing confidence on the index mentioned above\n\nDestination_Type       =    Sigma Cabs divides any destination in one of the 14 categories.\n\nCustomer_Rating        =    Average of life time ratings of the customer till date\n\nCancellation_Last_1Month    =    Number of trips cancelled by the customer in last 1 month\n\nVar1, Var2 and Var3    =     Continuous variables masked by the company. Can be used for modelling purposes\n\nGender                 =        Gender of the customer\n\nSurge_Pricing_Type     =   Predictor variable can be of 3 types\n\n","aa0f72b2":"Sigma Cab Private Limited - \n    \nCab aggregator service. Their customers can download their app on smartphones and book a cab from any where in the cities they operate in. They, in turn search for cabs from various service providers and provide the best option to their client across available options. They have been in operation for little less than a year now. During this period, they have captured surge_pricing_type from the service providers.\n\nThe task is to help them in predicting the surge_pricing_type pro-actively. This would in turn help them in matching the right cabs with the right customers quickly and efficiently.\n","fd13593c":"Model building","11afa684":"A,B,C,D,E are the categories of cab\n","fe26e8db":"# Data Dictionary","537dd852":"Missing values are found in Type_of_cab ( object ), Customer_Since_Months ( Float ), Life_Style_Index ( Float ), Confidence_Life_Style_Index ( Float ) and var1 ( Float )","5837686e":"MODELS"}}