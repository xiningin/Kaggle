{"cell_type":{"b28b7603":"code","26bdc8c6":"code","dbf9a9f8":"code","3fa37aa5":"code","d822a48f":"code","7dae4324":"code","5f9963fb":"code","4b66b81a":"code","ff70a24d":"code","f08cb4df":"code","7dd07d7d":"code","0fbea6a8":"code","acda8555":"code","2e1ced0c":"code","4ad03264":"code","109bd2db":"code","df674b02":"code","e42d63b5":"code","e1029ac3":"markdown","ff81d74c":"markdown","bd31edad":"markdown","087af152":"markdown","19d7a06d":"markdown","da54132a":"markdown","2f0aa2b5":"markdown","5a52111e":"markdown","a7022273":"markdown","36cd87c0":"markdown","c50559dd":"markdown","51ac7f3d":"markdown","81f7052d":"markdown","e24f0af5":"markdown","9d9cc947":"markdown","916f67f4":"markdown","2d244a67":"markdown"},"source":{"b28b7603":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\nimport cv2\nimport sklearn\nimport seaborn as sb\n\nfrom skimage.color import rgb2gray\nfrom skimage.filters import laplace, sobel, roberts\n# Any results you write to the current directory are saved as output.","26bdc8c6":"print('Sobel operator:\\n',np.matrix([[1,0,-1],[2,0,-2],[1,0,-1]]))\nprint('Laplacian operator:\\n',np.matrix([[0,-1,0],[-1,4,-1],[0,-1,0]]))","dbf9a9f8":"s_path ='..\/input\/blur_dataset_scaled\/sharp\/'\ndf_path='..\/input\/blur_dataset_scaled\/defocused_blurred\/'\nmot_path ='..\/input\/blur_dataset_scaled\/motion_blurred\/'\n\nimg_paths = ['..\/input\/blur_dataset_scaled\/sharp\/89_IPHONE-6S_S.jpeg','..\/input\/blur_dataset_scaled\/defocused_blurred\/89_IPHONE-6S_F.jpeg','..\/input\/blur_dataset_scaled\/motion_blurred\/89_IPHONE-6S_M.jpeg']\n \ndef show_images(path):\n    plt.figure(figsize=(10,10))\n    for i in range(len(path)):\n        x=plt.imread(path[i])\n        plt.subplot(1, 3, i+1)\n        plt.imshow(x)\n        plt.xticks([])\n        plt.yticks([])\n    plt.tight_layout()\n    plt.show()\nshow_images(img_paths)","3fa37aa5":"def show_images(path):\n    plt.figure(figsize=(10,10))\n    for i in range(len(path)):\n        x=cv2.imread(path[i],0)\n        l = laplace(x)\n        plt.subplot(1, 3, i+1)\n        plt.imshow(l,cmap='gray')\n        plt.xticks([])\n        plt.yticks([])\n    plt.tight_layout()\n    plt.show()\nshow_images(img_paths)","d822a48f":"def show_images(path):\n    plt.figure(figsize=(10,10))\n    for i in range(len(path)):\n        x=cv2.imread(path[i],0)\n        l = sobel(x)\n        plt.subplot(1, 3, i+1)\n        plt.imshow(l,cmap='gray')\n        plt.xticks([])\n        plt.yticks([])\n    plt.tight_layout()\n    plt.show()\nshow_images(img_paths)","7dae4324":"def show_images(path):\n    plt.figure(figsize=(10,10))\n    for i in range(len(path)):\n        x=cv2.imread(path[i],0)\n        l = roberts(x)\n        plt.subplot(1, 3, i+1)\n        plt.imshow(l,cmap='gray')\n        plt.xticks([])\n        plt.yticks([])\n    plt.tight_layout()\n    plt.show()\nshow_images(img_paths)","5f9963fb":"sharp_images = os.listdir(s_path)\ndefocused = os.listdir(df_path)\nmotion_blurred = os.listdir(mot_path)","4b66b81a":"def get_data(path,images):\n    features=[]\n    for img in images:\n        feature=[]\n        image_gray = cv2.imread(path+img,0)\n        lap_feat = laplace(image_gray)\n        sob_feat = sobel(image_gray)\n        rob_feat = roberts(image_gray)\n        feature.extend([img,lap_feat.mean(),lap_feat.var(),np.amax(lap_feat),\n                        sob_feat.mean(),sob_feat.var(),np.max(sob_feat),\n                        rob_feat.mean(),rob_feat.var(),np.max(rob_feat)])\n        \n        features.append(feature)\n    return features\n","ff70a24d":"sharp_features = get_data(s_path,sharp_images)\ndefocused_features = get_data(df_path,defocused)\nmotion_blur_features = get_data(mot_path,motion_blurred)","f08cb4df":"sharp_df = pd.DataFrame(sharp_features)\nsharp_df.drop(0,axis=1,inplace=True)\nsharp_df.head()","7dd07d7d":"defocused_df = pd.DataFrame(defocused_features)\ndefocused_df.drop(0,axis=1,inplace=True)\ndefocused_df.head()","0fbea6a8":"motion_df = pd.DataFrame(motion_blur_features)\nmotion_df.drop(0,axis=1,inplace=True)\nmotion_df.head()","acda8555":"label = ['Sharp_images','Defocused_images','Mtion_blurred_images']\nno_images=[len(sharp_features),len(defocused_features),len(motion_blur_features)]","2e1ced0c":"def plot_bar_x():\n    # this is for plotting purpose\n    index = np.arange(len(label))\n    plt.bar(index, no_images)\n    plt.xlabel('Image_type', fontsize=10)\n    plt.ylabel('No of Images', fontsize=10)\n    plt.xticks(index, label, fontsize=10, rotation=0)\n    plt.title('Data Visualization')\n    plt.show()\nplot_bar_x()","4ad03264":"from sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score, classification_report\nimages=pd.DataFrame()\n\nimages = images.append(sharp_df)\nimages = images.append(defocused_df)\nall_features = np.array(images)\ny_f = np.concatenate((np.ones((sharp_df.shape[0], )), np.zeros((defocused_df.shape[0], ))), axis=0)\n\nx_train,x_valid,y_train,y_valid = train_test_split(all_features,y_f,test_size=0.33,stratify=y_f)\n\nsvm_model = svm.SVC(C=100,kernel='linear')\nsvm_model.fit(x_train,y_train)\npred =svm_model.predict(x_valid)\nprint('Accuracy:',accuracy_score(y_valid,pred))\nprint('Confusion matrix:\\n',confusion_matrix(y_valid,pred))\nprint('F1_score:',f1_score(y_valid,pred))\nprint('Classification_report:\\n',classification_report(y_valid,pred))","109bd2db":"svm_model = svm.SVC(C=100,kernel='rbf')\nsvm_model.fit(x_train,y_train)\npred =svm_model.predict(x_valid)\nprint('Accuracy:',accuracy_score(y_valid,pred))\nprint('Confusion matrix:\\n',confusion_matrix(y_valid,pred))\nprint('F1_score:',f1_score(y_valid,pred))\nprint('Classification_report:\\n',classification_report(y_valid,pred))","df674b02":"images=pd.DataFrame()\n\nimages = images.append(sharp_df)\nimages = images.append(defocused_df)\nimages = images.append(motion_df)\nall_features = np.array(images)\ny_f = np.concatenate((np.ones((sharp_df.shape[0], )), np.zeros((defocused_df.shape[0]+motion_df.shape[0], ))), axis=0)\n\nx_train,x_valid,y_train,y_valid = train_test_split(all_features,y_f,test_size=0.33,stratify=y_f)\n\nsvm_model = svm.SVC(C=100,kernel='rbf')\nsvm_model.fit(x_train,y_train)\npred =svm_model.predict(x_valid)\nprint('Accuracy:',accuracy_score(y_valid,pred))\nprint('Confusion matrix:\\n',confusion_matrix(y_valid,pred))\nprint('F1_score:',f1_score(y_valid,pred))\nprint('Classification_report:\\n',classification_report(y_valid,pred))","e42d63b5":"from keras.utils import to_categorical\nimages=pd.DataFrame()\n\nimages = images.append(sharp_df)\nimages = images.append(defocused_df)\nimages = images.append(motion_df)\nall_features = np.array(images)\ny_f = np.concatenate((np.zeros((sharp_df.shape[0], )), np.ones((defocused_df.shape[0], )), 2*np.ones((motion_df.shape[0], ))), axis=0)\n\nx_train,x_valid,y_train,y_valid = train_test_split(all_features,y_f,test_size=0.33,stratify=y_f)\n\nsvm_model = svm.SVC(C=100,kernel='rbf')\nsvm_model.fit(x_train,y_train)\npred =svm_model.predict(x_valid)\nprint('Accuracy:',accuracy_score(y_valid,pred))\nprint('Confusion matrix:\\n',confusion_matrix(y_valid,pred))\ny_valid_cat = to_categorical(y_valid, num_classes=3)\npred_cat = to_categorical(pred, num_classes=3)\nprint('F1_score:',f1_score(y_valid_cat,pred_cat, average='weighted'))\nprint('Classification_report:\\n',classification_report(y_valid_cat,pred_cat))\n","e1029ac3":"Change the kernel as one of the best non-linear kernel 'rbf'","ff81d74c":"### Roberts feature visualization","bd31edad":"**Lets try the classification between sharp and defocused**","087af152":"A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side.","19d7a06d":"### Support Vector Machine","da54132a":"### Sobel feature visualization","2f0aa2b5":"### Feature Engineering:\nThe mean, variance,maximum of the edge detected feature matrix are take for each image applied on sobel and lapaclacian edge detection","5a52111e":"**Sobel Edge operator**\nIt is a edge detection operator based on gradient method i.e., the first order derivative method. Along x or along y or bi-directional. The edges are detected by convolving the kernel with actual image.\nThe sobel operator kernel used here is bi-directional\n\n**Roberts Edge Operator**\nIt is similar to Sobel operator gives the gradient magnitude highlighting the edges\n\n**Laplacian Edge operator**\nIt is also an edge detection operator based on gradient methos but it calculated the second dervative od the data . It internally calls the sobel operator for first derivative.\n\n**Why Derivative?**\nThe edges can be deteced by finding the local maxima or minima of it's first derivative\nThe edges can be deteced by finding the zero-crossing of it's second derivative \n","a7022273":"## *If you like it, please UPVOTE*","36cd87c0":"**Lets try the classification between all the three**","c50559dd":"**Lets try the classification between sharp and 'defocused & motion-blur'**","51ac7f3d":"#### Features selected:\nThe images losses it's edges due to defocus and so the features are selected as edges through sobel and laplacian operators","81f7052d":"It has two types\n1. HArd Margin - the data can be classified by a line or hyperplane but without error added to the algorithm\n2. Soft margin -  the data can be classified by a line or hyperplane but with error added to the algorithm\n\nIf the data cannot be clssified by a line .. It maps the data to higher dimension where it can calssify using the plane\/ hyperplane\n","e24f0af5":"This is because the features extracted are not much of a difference between motion blurred and the sharp images","9d9cc947":"## Blur Detection via Classification","916f67f4":"#### Dataset:\nIt is a image blur data from kaggle and it has 3 types of a same image\n1. Sharp image \n2. Defocused image\n3. Motion blurred image","2d244a67":"### Laplacian feature visualization"}}