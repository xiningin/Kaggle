{"cell_type":{"804a76fa":"code","1f10ba72":"code","419adbb9":"code","fd44ba5f":"code","636430c7":"code","efa25bb1":"code","f0186c38":"code","88cd6142":"code","43a9e240":"code","a3f7a2fc":"code","80138338":"code","bc5844f3":"code","eff8662f":"code","33632776":"code","166c45ae":"code","dcaf89e6":"code","39349972":"code","e768e8f2":"code","195ba306":"code","19a57df1":"code","c23a66e5":"code","78df7a64":"code","df9d9008":"code","ae4265c6":"code","5df2cc31":"code","77128614":"code","b5577b11":"code","8f0bb3c0":"code","24a9c160":"code","fb711fef":"markdown","121c42af":"markdown","7f6160bb":"markdown","750511c5":"markdown","756e079d":"markdown","0bfa63bd":"markdown","ec88438f":"markdown","c613824b":"markdown","5772fb03":"markdown","14076277":"markdown","5a429335":"markdown","aaf63579":"markdown","2a539e85":"markdown","a4bd290e":"markdown","b74425c1":"markdown","55aab673":"markdown","dfb2987e":"markdown","33f63e9d":"markdown","d64e254f":"markdown","bb8ffb64":"markdown","0df0afcf":"markdown","1628f25b":"markdown","51f2416b":"markdown","e56535cb":"markdown"},"source":{"804a76fa":"import pandas as pd\npd.options.display.float_format = '{:.2f}'.format\nimport numpy as np\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport os\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.cluster import KMeans\nimport plotly as py\nimport plotly.graph_objs as go\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1f10ba72":"# Leitura do conjunto de dados\nfinal = pd.read_csv('\/kaggle\/input\/eleicao_2018_apuracao_final.csv', sep=';', encoding='latin-1')\n\n# Visualiza\u00e7\u00e3o das informa\u00e7\u00f5es sobre as vari\u00e1veis\nfinal.info()","419adbb9":"def filtro(dataset):# Filtro por Estado e Situa\u00e7\u00e3o\n    dataset = dataset[dataset['SG_UF'].isin(['SP', 'MG'])  & (dataset['DS_SITUACAO_CANDIDATURA'] == 'APTO')]\n\n    # Filtro por Situa\u00e7\u00e3o Deferida\n    dataset = dataset[dataset['DS_DETALHE_SITUACAO_CAND'].isin(['DEFERIDO','DEFERIDO COM RECURSO'])]\n\n    # Filtro por Cargo\n    dataset = dataset[dataset['DS_CARGO'].isin(['SENADOR','DEPUTADO FEDERAL','DEPUTADO ESTADUAL'])]\n\n    # Visualiza\u00e7\u00e3o das informa\u00e7\u00f5es sobre as vari\u00e1veis\n    return dataset","fd44ba5f":"final = filtro(final)","636430c7":"def imputa_dados_despesa(data):\n    dataset = data.copy()\n    # Separando um conjunto de dados para modelagem\n    dataset_desp_pred = dataset[(dataset['Receita_Total'].notna()) & (dataset['Despesa_Total'].notna())]\n\n    X = dataset_desp_pred.iloc[:, -2:-1].values\n    \n    y = dataset_desp_pred.iloc[:, -1].values\n\n    # Dividindo o conjunto de dados em treino e teste\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12345)\n\n    # Ajustando o modelo de \u00c1rvore de Regress\u00e3o\n    regressor = DecisionTreeRegressor(random_state=12345)\n    regressor.fit(X_train, y_train)\n\n    # Predizendo resultados de teste\n    y_pred = regressor.predict(X_test)\n\n    # Avaliando o \u00edndice de acertos\n    print('Valor do r\u00b2: ', round(r2_score(y_test , y_pred),2))\n\n    # Inputando DESPESAS missing onde RECEITA NOT NULL\n    dataset_desp_inpute = dataset[(dataset['Receita_Total'].notna()) & (dataset['Despesa_Total'].isna())]\n    X = dataset_desp_inpute.iloc[:, -2:-1].values\n    y = dataset_desp_inpute.iloc[:, -1].values\n\n    # Resultado dos valores preditos\n    dataset['Despesa_Total'][(dataset['Receita_Total'].notna()) & (dataset['Despesa_Total'].isna())] =  regressor.predict(X)\n\n    return dataset","efa25bb1":"def imputa_dados_receita(data):\n    dataset = data.copy()\n    # Separando um conjunto de dados para modelagem\n    dataset_rec_pred = dataset[(dataset['Despesa_Total'].notna()) & (dataset['Receita_Total'].notna())]\n    X = dataset_rec_pred.iloc[:, -1:].values\n    y = dataset_rec_pred.iloc[:, -2].values\n\n    # Dividindo o conjunto de dados em treino e teste\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12345)\n\n    # Ajustando o modelo de \u00c1rvore de Regress\u00e3o\n    regressor = DecisionTreeRegressor(random_state=12345)\n    regressor.fit(X_train, y_train)\n\n    # Predizendo resultados de teste\n    y_pred = regressor.predict(X_test)\n\n    # Evaluating\n    print('Valor do r\u00b2: ', round(r2_score(y_test , y_pred),2))\n    # =============================================================================\n\n    # Inputando DESPESAS missing onde RECEITA NOT NULL\n    dataset_desp_inpute = dataset[(dataset['Despesa_Total'].notna()) & (dataset['Receita_Total'].isna())]\n    X = dataset_desp_inpute.iloc[:, -1:].values\n    y = dataset_desp_inpute.iloc[:, -2].values\n\n\n    dataset['Receita_Total'][(dataset['Despesa_Total'].notna()) & (dataset['Receita_Total'].isna())] =  regressor.predict(X)\n    return dataset","f0186c38":"def imputa_media(data):\n    dataset = data.copy()\n    receitas_inpute = dataset.groupby('SG_PARTIDO', as_index=False)['Receita_Total'].mean()\n    despesas_inpute = dataset.groupby('SG_PARTIDO', as_index=False)['Despesa_Total'].mean()\n\n\n    dataset = dataset.merge(receitas_inpute, how='left', on='SG_PARTIDO')\n    dataset = dataset.merge(despesas_inpute, how='left', on='SG_PARTIDO')\n\n    dataset = dataset.rename(columns={'Receita_Total_x':'Receita_Total', 'Despesa_Total_x':'Despesa_Total'})\n    dataset['Receita_Total'] = np.where(dataset['Receita_Total'].isna(), dataset['Receita_Total_y'], dataset['Receita_Total'])\n    dataset['Despesa_Total'] = np.where(dataset['Despesa_Total'].isna(), dataset['Despesa_Total_y'], dataset['Despesa_Total'])\n\n    dataset = dataset.iloc[:,0:-2]\n    return dataset","88cd6142":"final = imputa_dados_despesa(final)\n\nfinal = imputa_dados_receita(final)\n\nfinal = imputa_media(final)","43a9e240":"situacoes = {\n    0:\"ELEITO\",\n    1:\"N\u00c3O ELEITO\"\n}","a3f7a2fc":"from sklearn import tree\nimport graphviz \n\nclass ModelMaker():\n    def _load_data(self, data):\n        dataset = data.copy()\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(dataset.loc[:, dataset.columns.difference(['target', 'situacao',\"SG_PARTIDO\", \"DS_CARGO\", \"NM_CANDIDATO\"])], dataset[\"target\"], test_size=0.3, random_state=42)\n        \n        \n    def __init__(self, sklearn_load_ds):\n        self._load_data(sklearn_load_ds)\n    \n    \n    def classify(self, model=LogisticRegression(random_state=42)):\n        model.fit(self.X_train, self.y_train)\n        y_pred = model.predict(self.X_test)\n        self.model = model\n        \n        class_names = np.unique([situacoes[i] for i in self.y_train])\n        feature_names = self.X_train.columns\n        \n        dot_data = tree.export_graphviz(model, out_file=None,\n                                        class_names=class_names,\n                                        feature_names=feature_names,\n                                        max_depth=5)\n        graph = graphviz.Source(dot_data)\n        \n        png_bytes = graph.pipe(format='png')\n        with open('dtree_pipe.png','wb') as f:\n            f.write(png_bytes)\n\n        from IPython.display import Image\n        display(Image(png_bytes))\n   \n        print('Accuracy: {}'.format(accuracy_score(self.y_test, y_pred)))\n        return self\n\n    def predict(self, data):\n        dataset = data.copy()\n        y_labels = self.clf.predict(dataset.loc[:, dataset.columns.difference(['target', 'situacao',\"SG_PARTIDO\", \"DS_CARGO\", \"NM_CANDIDATO\"])])\n        dataset[\"km_clust\"] = y_labels\n        dataset[\"predict\"] = self.model.predict(dataset.loc[:, dataset.columns.difference(['target', 'situacao',\"SG_PARTIDO\", \"DS_CARGO\", \"NM_CANDIDATO\"])])\n        return dataset\n        \n    def cluster(self, output='add'):\n        n_clusters = len(np.unique(self.y_train))\n        clf = KMeans(n_clusters = n_clusters, random_state=42)\n        clf.fit(self.X_train)\n        y_labels_train = clf.labels_\n        y_labels_test = clf.predict(self.X_test)\n        self.clf = clf\n        \n        if output == 'add':\n            self.X_train['km_clust'] = y_labels_train\n            self.X_test['km_clust'] = y_labels_test\n        elif output == 'replace':\n            self.X_train = y_labels_train[:, np.newaxis]\n            self.X_test = y_labels_test[:, np.newaxis]\n        else:\n            raise ValueError('output should be either add or replace')\n        return self","80138338":"final[\"situacao\"] = np.where(final['DS_SIT_TOT_TURNO'] == 'N\u00c3O ELEITO', 'N\u00c3O ELEITO', 'ELEITO')\nfinal[\"target\"]   =  pd.factorize(final['situacao'], sort=True)[0]\ndataset = final[['Despesa_Total', 'Receita_Total', 'Votos', \"target\", \"situacao\", \"SG_PARTIDO\", \"DS_CARGO\", \"NM_CANDIDATO\"]]","bc5844f3":"\ndataset.groupby([\"target\", \"situacao\"]).nunique()","eff8662f":"## realizando cluster e aplicando um modelo DecisionTreeClassifier\n\nmodel = ModelMaker(dataset).cluster(output=\"add\").classify(model=DecisionTreeClassifier(max_depth=30))\nX = model.predict(dataset)","33632776":"def plot_kmeans(data, label1, label2, titulo):\n    dataset = data.copy()\n    fig, ax = plt.subplots(2, 1, figsize=(16,12))\n\n    dataset['situacao'] = dataset['target'].map(situacoes)\n    dataset['km_clust'] = dataset['km_clust'].map({ 0:\"CLUSTER 1\", 1:\"CLUSTER 2\" })\n\n    sns.scatterplot(x=label1, y=label2, hue=\"situacao\", data=dataset, ax=ax[0], s=100, color=\".2\")\n    \n    sns.scatterplot(x=label1, y=label2, hue=\"km_clust\", data=dataset, ax=ax[1], s=100, color=\".2\")\n\n\n    ax[0].set_xlabel(label1, fontsize=15)\n    ax[0].set_ylabel(label2, fontsize=15)\n    ax[1].set_xlabel(label1, fontsize=15)\n    ax[1].set_ylabel(label2, fontsize=15)\n    ax[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n    ax[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n    ax[0].set_title('Atual', fontsize=18)\n    ax[1].set_title('Cluster', fontsize=18)\n    fig.suptitle(titulo, fontsize=20)\n","166c45ae":"plot_kmeans(X, \"Receita_Total\", \"Despesa_Total\",\"Receita x Despesas\")","dcaf89e6":"plot_kmeans(X, \"Receita_Total\", \"Votos\",\"Receita x Votos\")","39349972":"plot_kmeans(X, \"Despesa_Total\", \"Votos\",\"Despesa x Votos\")","e768e8f2":"# mapeando qual a situa\u00e7\u00e3o para o valor predit\nX['situacao_predita'] = X['predict'].map(situacoes)\n\n# criando uma tabela cruzada\npd.crosstab(X[\"situacao\"], X[\"situacao_predita\"])","195ba306":"df_sem_definicao = pd.read_csv('\/kaggle\/input\/eleicao_2018_sem_definicao.csv', sep=';', encoding='latin-1')\ndf_sem_definicao = filtro(df_sem_definicao)\ndf_sem_definicao = imputa_media(df_sem_definicao)\ndf_sem_definicao['Receita_Total'][df_sem_definicao['Receita_Total'].isna()] =  df_sem_definicao[\"Receita_Total\"].mean()\ndf_sem_definicao['Despesa_Total'][df_sem_definicao['Despesa_Total'].isna()] =  df_sem_definicao[\"Despesa_Total\"].mean()\n\ndf_sem_definicao[\"situacao\"] = np.where(df_sem_definicao['DS_Sit_Tot_Turno_OLD'] == 'N\u00c3O ELEITO', 'N\u00c3O ELEITO', 'ELEITO')\ndf_sem_definicao[\"target\"] =  np.where(df_sem_definicao['situacao'] == 'N\u00c3O ELEITO', 1, 0)\n\ndf_sem_definicao = df_sem_definicao[['Despesa_Total', 'Receita_Total', 'Votos', \"target\", \"situacao\", \"SG_PARTIDO\", \"DS_CARGO\", \"NM_CANDIDATO\"]]","19a57df1":"X = model.predict(df_sem_definicao)","c23a66e5":"plot_kmeans(X, \"Receita_Total\", \"Despesa_Total\",\"Receita x Despesas\")","78df7a64":"plot_kmeans(X, \"Receita_Total\", \"Votos\",\"Receita x Votos\")","df9d9008":"plot_kmeans(X, \"Despesa_Total\", \"Votos\",\"Despesa x Votos\")","ae4265c6":"# mapeando qual a situa\u00e7\u00e3o para o valor predit\nX['situacao_predita'] = X['predict'].map(situacoes)\n\n# criando uma tabela cruzada\npd.crosstab(X[\"situacao\"], X[\"situacao_predita\"])","5df2cc31":"pd.set_option('display.max_rows', len(X))\n\nX[[\"NM_CANDIDATO\", \"SG_PARTIDO\", \"DS_CARGO\", \"situacao\",\"situacao_predita\"]]","77128614":"# =============================================================================\n# Utilizando o dataset \"final\" como modelo\n# =============================================================================\nfinal_modelo = final[['DS_CARGO','Votos','Receita_Total', 'Despesa_Total','DS_SIT_TOT_TURNO']]\n\nfinal_modelo['DS_SIT_TOT_TURNO'] = np.where(final_modelo['DS_SIT_TOT_TURNO'].isin(['N\u00c3O ELEITO']),0,1)\n\n# =============================================================================\n#  Vari\u00e1veis Dummies\n# =============================================================================\ndf_modelo = pd.get_dummies(final_modelo, columns=['DS_CARGO'], drop_first=True)\n\ncolunas = df_modelo.columns.tolist()\ncols = colunas[4:] + colunas[:4]\ndf_modelo = df_modelo[cols]\n \nX = df_modelo.iloc[:, :-1].values\ny = df_modelo.iloc[:, -1].values\n\n# =============================================================================\n# Teste e Treino\n# =============================================================================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12345)\n\n# =============================================================================\n# Normaliza\u00e7\u00e3o dos dados\n# =============================================================================\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# =============================================================================\n# Cassificador Random Forest\n# =============================================================================\nclassifier = RandomForestClassifier(n_estimators=300, criterion='entropy', random_state = 12345)\nclassifier.fit(X_train, y_train)\n\n# =============================================================================\n# Predizendo resultados\n# =============================================================================\ny_pred_final = classifier.predict(X_test)\n\n# =============================================================================\n# Matrix de Confus\u00e3o\n# =============================================================================\n\ncm = confusion_matrix(y_test, y_pred_final)\n\nesp = cm[0,0] \/ (cm[0,0] + cm[1,0])\nsens = cm[1,1] \/ (cm[0,1] + cm[1,1])\n\nprint('Sensibilidade: ' + str(round(sens,2)) +'\\nEspecificidade: ' + str(round(esp,2)))\n","b5577b11":"sem_def = pd.read_csv('\/kaggle\/input\/eleicao_2018_sem_definicao.csv', sep=';', encoding='latin-1')\n\n# =============================================================================\n# Aplicando Filtros\n# =============================================================================\nsem_def_filtrado = filtro(sem_def)\ncol = sem_def_filtrado.columns.to_list()\ncol = col[:-4] + col[-1:] + col[-4:-1]\nsem_def_filtrado = sem_def_filtrado[col]\n\nsem_def_filtrado = imputa_dados_despesa(sem_def_filtrado)\nsem_def_filtrado = imputa_media(sem_def_filtrado)\n\n# Filtrando onde n\u00e3o existe m\u00e9dia de valores por partido, pois todos do partido s\u00e3o missing values\nsem_def_filtrado['Receita_Total'] = np.where(sem_def_filtrado['Receita_Total'].isna(), sem_def_filtrado['Receita_Total'].mean(), sem_def_filtrado['Receita_Total'])\nsem_def_filtrado['Despesa_Total'] = np.where(sem_def_filtrado['Despesa_Total'].isna(), sem_def_filtrado['Despesa_Total'].mean(), sem_def_filtrado['Despesa_Total'])\n\n# =============================================================================\n# Definindo o Modelo\n# =============================================================================\nmodelo_pred = sem_def_filtrado[['DS_CARGO','Votos','Receita_Total', 'Despesa_Total']]\nmodelo_pred = pd.get_dummies(modelo_pred, columns=['DS_CARGO'], drop_first=True)\ncolunas = modelo_pred.columns.tolist()\ncols = colunas[3:] + colunas[:3]\nmodelo_pred = modelo_pred[cols]\n \nX = modelo_pred.iloc[:, :].values\n\n# =============================================================================\n# Normalizando os dados\n# =============================================================================\nsc = StandardScaler()\nX = sc.fit_transform(X)\n\n# =============================================================================\n# Predizendo os resultados\n# =============================================================================\ny_pred_sem_def = classifier.predict(X)\n\n# =============================================================================\n# Criando vari\u00e1vel de teste para avalia\u00e7\u00e3o do resultado\n# =============================================================================\nsem_def_filtrado['y_test'] = np.where(sem_def_filtrado['DS_Sit_Tot_Turno_OLD'].isin(['N\u00c3O ELEITO']),0,1)\ny_test = sem_def_filtrado['y_test'].values\n\n# =============================================================================\n# Matrix de Confus\u00e3o\n# =============================================================================\ncm = confusion_matrix(y_test, y_pred_sem_def)\n\nesp = cm[0,0] \/ (cm[0,0] + cm[1,0])\nsens = cm[1,1] \/ (cm[0,1] + cm[1,1])\n\nprint('Sensibilidade: ' + str(round(sens,2)) +'\\nEspecificidade: ' + str(round(esp,2)))\nprint('Acur\u00e1cia: ', round(accuracy_score(y_test, y_pred_sem_def),2))","8f0bb3c0":"sem_def_filtrado['Resultado_Final'] = y_pred_sem_def\nevalu = sem_def_filtrado[['DS_CARGO','Votos', 'Receita_Total', 'Despesa_Total', 'DS_Sit_Tot_Turno_OLD','y_test','Resultado_Final']]\nevalu.head(15)","24a9c160":"sem_def_filtrado[['NM_CANDIDATO', 'SG_PARTIDO']][sem_def_filtrado['Resultado_Final'] == 1]","fb711fef":"# 3. Decision Tree Bin\u00e1ria <a name=\"3\"><\/a>","121c42af":"## 1.4 Aplica\u00e7\u00e3o das fun\u00e7\u00f5es de inpute onde h\u00e1 missing values","7f6160bb":"## 2.1 Limpando os dados","750511c5":"### Apresenta\u00e7\u00e3o gr\u00e1fica do modelo","756e079d":"## 3.1 Modelo para \u00c1rvore de Classifica\u00e7\u00e3o","0bfa63bd":"## 2.2 Aplicando o modelo","ec88438f":"<img style=\"float: left;\" src=\"http:\/\/sindser.org.br\/s\/wp-content\/uploads\/2013\/09\/iesb1.jpg\"  width=\"300\" height=\"300\">\n\n## Instituto de Educa\u00e7\u00e3o Superior de Bras\u00edlia\n## P\u00f3s Gradua\u00e7\u00e3o em Ci\u00eancia de Dados\n## Data Mining e Machine Learning I","c613824b":"### Aplicando o Modelo","5772fb03":"# 4. Conclus\u00e3o  <a name=\"4\"><\/a>","14076277":"## 3.2 Aplica\u00e7\u00e3o do Modelo no dataset *eleicao_2018_sem_definicao*","5a429335":"## 1.2 Fun\u00e7\u00e3o com \u00c1rvore de Regress\u00e3o para predizer valor de Despesa Total missing com base na Receita Total existente","aaf63579":"## 3.4 Nomes dos candidatos que seriam eleitos segundo modelo de classifica\u00e7\u00e3o","2a539e85":"## 1.3 Fun\u00e7\u00e3o para inserir valores onde h\u00e1 missings pela m\u00e9dia agrugada por partido","a4bd290e":"## 1.1 Aplicando Filtros por Estado, Situa\u00e7\u00e3o e Cargo","b74425c1":"### Limpando os dados","55aab673":"## 2.3 Apresenta\u00e7\u00e3o grafica do modelo","dfb2987e":"# 1. Dados  <a name=\"1\"><\/a>","33f63e9d":"## 1.2 Fun\u00e7\u00e3o com \u00c1rvore de Regress\u00e3o para predizer valor de Receita Total missing com base na Despesa Total existente","d64e254f":"<h3><center><font size=\"3\">Leandro Alencar \u2013 1931133007<\/font><\/center><\/h3>\n<br>Leandro Alencar \u2013 1931133007\n<br>Maycon Alves \u2013 1931133015\n<br>Nilson Michiles - 1931133032<br>\n<\/font><\/center><\/h3>\n\n","bb8ffb64":"## 3.3 Criando coluna de resultado para compara\u00e7\u00e3o visual com coluna de teste (DS_Sit_Tot_Turno_OLD)","0df0afcf":"# 2. K-means  <a name=\"2\"><\/a>","1628f25b":"----\n# Table of contents\n* [Bibliotecas e Depend\u00eancias](#0)\n* [Dados](#1)\n* [K-means](#2)\n* [Decision Tree](#3)\n* [Conclus\u00e3o](#4)\n","51f2416b":" ## Prevendo o resultado para o dataset *eleicao_2018_sem_definicao*","e56535cb":"# Bibliotecas e Depend\u00eancias <a name=\"0\"><\/a>"}}