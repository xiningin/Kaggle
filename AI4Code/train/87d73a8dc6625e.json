{"cell_type":{"058212e3":"code","637be1b3":"code","b3ced98b":"code","c4eb097b":"code","28a3b263":"code","ddb34187":"code","c7679c18":"code","f72cf6b6":"code","bbd15c79":"code","8f62bbb5":"code","891da2e4":"code","d86954a5":"code","40663549":"code","4385910b":"code","c317aa5c":"code","1bd964f2":"code","efc96e28":"code","9a8da67d":"code","27f842e4":"code","597c2099":"code","c68e07e5":"code","2bfaa3a7":"code","a6933782":"code","d3a23136":"code","9315b643":"code","2c70e3c0":"code","1e482604":"markdown","78329e40":"markdown","64f4855c":"markdown","30766195":"markdown","784dab03":"markdown"},"source":{"058212e3":"import os\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom sklearn.metrics import confusion_matrix\nfrom keras.layers import GlobalAveragePooling2D, Dropout,Activation\nfrom keras.models import Model\n# np.random.seed(2)\n\nfrom keras.utils.np_utils import to_categorical\n\nimport itertools\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","637be1b3":"train = \"..\/input\/seti-data\/primary_small\/train\"\n\nbp = \"..\/input\/seti-data\/primary_small\/train\/brightpixel\/\"\nnb = \"..\/input\/seti-data\/primary_small\/train\/narrowband\/\"\nnbd = \"..\/input\/seti-data\/primary_small\/train\/narrowbanddrd\/\"\nnoise = \"..\/input\/seti-data\/primary_small\/train\/noise\/\"\nspnb = \"..\/input\/seti-data\/primary_small\/train\/squarepulsednarrowband\/\"\nsqu = \"..\/input\/seti-data\/primary_small\/train\/squiggle\/\"\nsspnb = \"..\/input\/seti-data\/primary_small\/train\/squigglesquarepulsednarrowband\/\"\n\n\nbp_path = os.listdir(bp)\nnb_path = os.listdir(nb)\nnbd_path = os.listdir(nbd)\nnoise_path = os.listdir(noise)\nspnb_path = os.listdir(spnb)\nsqu_path = os.listdir(squ)\nsspnb_path = os.listdir(sspnb)","b3ced98b":"categories = [bp,nb,nbd,noise,spnb,squ,sspnb]\npath = [bp_path,nb_path,nbd_path,noise_path,spnb_path,squ_path,sspnb_path]\n\ntitles = [\"BrightPixel\",\"NarrowBand\",\"NarrowBandDRD\",\"Noise\",\"SPNB\",\"Squibble\",\"SSPNB\"]\n\ndef load_img(path):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (400, 400))\n    return image[...,::-1]","c4eb097b":"plt.figure(figsize = (30,30))\nfor i in range(7):\n    plt.subplot(1,8,i+1)\n    plt.imshow(load_img(categories[i] + path[i][1]))\n    plt.title(titles[i])\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","28a3b263":"def load_img(path):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (400, 400))\n    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n#     print(labels)\n    return gray[...,::-1]","ddb34187":"plt.figure(figsize = (30,30))\nfor i in range(7):\n    plt.subplot(1,8,i+1)\n    plt.imshow(load_img(categories[i] + path[i][1]), cmap=\"binary\")\n    plt.title(titles[i])\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","c7679c18":"def load_img(path):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (400, 400))\n#     gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    edge = cv2.Canny(image,50,100, apertureSize=3)\n    return edge[...,::-1]\n","f72cf6b6":"plt.figure(figsize = (25,25))\nfor i in range(7):\n    plt.subplot(1,8,i+1)\n    plt.imshow(load_img(categories[i] + path[i][1]), cmap=\"binary\")\n    plt.title(titles[i])\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","bbd15c79":"def load_img(path):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (400, 400))\n#     gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n#     edge = cv2.Canny(image,50,100, apertureSize=3)\n    blur = cv2.GaussianBlur(image,(5,5),0)\n    return blur[...,::-1]\n","8f62bbb5":"plt.figure(figsize = (25,25))\nfor i in range(7):\n    plt.subplot(1,8,i+1)\n    plt.imshow(load_img(categories[i] + path[i][1]), cmap=\"binary\")\n    plt.title(titles[i])\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","891da2e4":"classes = [\"brightpixel\",\n            \"narrowband\",\n            \"narrowbanddrd\",\n            \"noise\",\n            \"squarepulsednarrowband\",\n            \"squiggle\",\n            \"squigglesquarepulsednarrowband\"]\nnum_images = 2\nfor _class in classes:\n    # start off by observing images\n    path = os.path.join(train, _class)\n    image_files = os.listdir(path)\n    random_images = random.sample(range(0, len(image_files)-1), num_images)\n    fig, axes = plt.subplots(nrows=1, ncols=num_images, figsize=(12, 14), squeeze=False)\n    fig.tight_layout()\n    for l in range(1):\n        for m in range(num_images):\n            axes[l][m].imshow(cv2.imread(os.path.join(path, image_files[random_images[m]]), 0), cmap=\"gray\")\n            axes[l][m].axis(\"off\")\n            axes[l][m].set_title(_class)\n# done displaying","d86954a5":"training_data = []\nIMG_SIZE = 196\n\ndatadir = \"..\/input\/seti-data\/primary_small\/train\/\"\ncategories = [\"brightpixel\",\"narrowband\",\"narrowbanddrd\",\"noise\",\"squarepulsednarrowband\",\"squiggle\",\"squigglesquarepulsednarrowband\"]\n\ndef create_training_data():\n    for category in categories:\n        path = os.path.join(datadir, category)\n        class_num = categories.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)\n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n                training_data.append([new_array,class_num])\n            except:\n                pass\ncreate_training_data()","40663549":"training_data = np.array(training_data)\nprint(training_data.shape)","4385910b":"import random\n\nnp.random.shuffle(training_data)\nfor sample in training_data[:10]:\n    print(sample[1])","c317aa5c":"X = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(5600, IMG_SIZE, IMG_SIZE, 3)\ny = np.array(y)","1bd964f2":"print(X.shape)\nprint(y.shape)","efc96e28":"import plotly.graph_objs as go \nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode()\n\na,b = np.unique(y, return_counts = True)\ntrace = go.Bar(x = categories, y = b)\ndata = [trace]\nlayout = {\"title\":\"Categories vs Images Distribution\",\n         \"xaxis\":{\"title\":\"Categories\",\"tickangle\":45},\n         \"yaxis\":{\"title\":\"Number of Images\"}}\nfig = go.Figure(data = data,layout=layout)\niplot(fig)","9a8da67d":"X = X\/255.0","27f842e4":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.08, random_state=42)","597c2099":"print(\"Shape of test_x: \",X_train.shape)\nprint(\"Shape of train_y: \",y_train.shape)\nprint(\"Shape of test_x: \",X_test.shape)\nprint(\"Shape of test_y: \",y_test.shape)","c68e07e5":"from keras.utils.np_utils import to_categorical\n\ny_train = to_categorical(y_train, num_classes = 7)\ny_test = to_categorical(y_test, num_classes = 7)","2bfaa3a7":"print(\"Shape of test_x: \",X_train.shape)\nprint(\"Shape of train_y: \",y_train.shape)\nprint(\"Shape of test_x: \",X_test.shape)\nprint(\"Shape of test_y: \",y_test.shape)","a6933782":"print(np.unique(y_train, return_counts = True))\nprint(np.unique(y_test, return_counts = True))","d3a23136":"model = keras.applications.VGG16(input_shape = (28,28,1), weights = 'imagenet',include_top=False)\n\nfor layer in model.layers:\n    layer.trainable = False\n\nlast_layer = model.output\n\n# add a global spatial average pooling layer\nx = GlobalAveragePooling2D()(last_layer)\n\n# add fully-connected & dropout layers\nx = Dense(4096, activation='relu',name='fc-1')(x)\nx = Dropout(0.2)(x)\nx = Dense(4096, activation='relu',name='fc-2')(x)\nx = Dropout(0.2)(x)\n\n# x = Dense(4096, activation='relu',name='fc-3')(x)\n# x = Dropout(0.2)(x)\n\n# a softmax layer for 7 classes\nnum_classes = 7\nout = Dense(num_classes, activation='softmax',name='output_layer')(x)\n\n# this is the model we will train\nmodel2 = Model(inputs=model.input, outputs=out)\n\nmodel2.summary()","9315b643":"model2.compile(optimizer='adam',\n              loss ='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\n\n# hist = model2.fit(X_train,y_train, batch_size=30, epochs = 100, validation_data = (X_test,y_test), callbacks=[early_stopping])\nhist = model2.fit(X_train,y_train, batch_size=30, epochs = 30, validation_data = (X_test,y_test))","2c70e3c0":"# Visualizing the training. \n\nepochs = 30\n\n# The uncomment everything in this cell and run it.\n\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nxc = range(epochs)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","1e482604":"## Introduction.\n\n### What is [SETI](https:\/\/www.seti.org\/)\n\n- SETI stands for **Search for Extraterrestrial Intelligence** is a collective term for scientific searches for intelligent extraterrestrial life, for example, monitoring electromagnetic radiation for signs of transmissions from civilizations on other planets\n\n- The SETI Institute is a not-for-profit research organization incorporated in 1984 whose mission is to explore, understand, and explain the origin and nature of life in the universe, and to apply the knowledge gained to inspire and guide present and future generations. It aims for discovery and for sharing knowledge as scientific ambassadors to the public, the press, and the government. SETI stands for the \"search for extraterrestrial intelligence\".\n\n- Source: [SETI institute](https:\/\/en.wikipedia.org\/wiki\/SETI_Institute)","78329e40":"![radio-signals-outer-space-alien-life.jpg](attachment:radio-signals-outer-space-alien-life.jpg)\n\nSource: [Canadian Astronomers](https:\/\/greatlakesledger.com\/2019\/08\/20\/canadian-astronomers-spotted-mysterious-radio-signals-from-outer-space-possibly-linked-to-alien-life\/) ","64f4855c":"### Let's try with dark background:\n\nCredit: [Karthik Reddy](https:\/\/www.kaggle.com\/karthikreddy25\/seti-image-analysis-and-pre-processing)","30766195":"### Preparing Training Data","784dab03":"### Different classes in the Dataset.\n\n- As these names are quite long I will categorize them as the following abbreviations. \n\n- `BrightPixel` : bp\n\n- `NarrowBand` : nb\n\n- `NarrowBandDRD` : nbd\n\n- `Noise` : noise\n\n- `Square Pulsed NarrowBand` : spnb\n\n- `Squibble` : squ\n\n- `Single Square Pulsed NarrowBand` : sspnb\n"}}