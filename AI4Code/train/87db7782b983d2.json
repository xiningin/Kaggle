{"cell_type":{"772cedd0":"code","6ccb12ce":"code","d0f74eb2":"code","eb0327a9":"code","38da08ec":"code","95b25827":"code","42f9961a":"code","4a1b0f4a":"code","9bc276b7":"code","0e452ae8":"code","bfa86e19":"code","03f5e3ab":"code","8eefb2d4":"code","3826793a":"code","df1f6d59":"markdown","cd22ed06":"markdown","8c1d0f24":"markdown","5b8f86e1":"markdown","75745426":"markdown","9d65812f":"markdown"},"source":{"772cedd0":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom keras import backend as K\n\nfrom keras.datasets import mnist\nfrom keras.layers import (Activation, BatchNormalization, Concatenate, Dense,\n                          Dropout, Flatten, Input, Lambda, Reshape)\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical","6ccb12ce":"'''The Dimensions of the traget images'''\nimg_rows = 28\nimg_cols = 28\nchannels = 1\n\nimg_shape = (img_rows , img_cols , channels)\n\nz_dim = 100 #random noise input for generator \n\nnum_classes = 10 #no. of classes to predict for semi supervised algo\n","d0f74eb2":"class Dataset:\n    def __init__(self, num_labeled):\n\n        self.num_labeled = num_labeled                                   \n\n        (self.x_train, self.y_train), (self.x_test,                      \n                                       self.y_test) = mnist.load_data()\n\n        def preprocess_imgs(x):\n            x = (x.astype(np.float32) - 127.5) \/ 127.5                   \n            x = np.expand_dims(x, axis=3)                                \n            return x\n\n        def preprocess_labels(y):\n            return y.reshape(-1, 1)\n\n        self.x_train = preprocess_imgs(self.x_train)                     \n        self.y_train = preprocess_labels(self.y_train)\n\n        self.x_test = preprocess_imgs(self.x_test)                       \n        self.y_test = preprocess_labels(self.y_test)\n\n    def batch_labeled(self, batch_size):\n        idx = np.random.randint(0, self.num_labeled, batch_size)         \n        imgs = self.x_train[idx]\n        labels = self.y_train[idx]\n        return imgs, labels\n\n    def batch_unlabeled(self, batch_size):\n        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], \n                                batch_size)\n        imgs = self.x_train[idx]\n        return imgs\n\n    def training_set(self):\n        x_train = self.x_train[range(self.num_labeled)]\n        y_train = self.y_train[range(self.num_labeled)]\n        return x_train, y_train\n\n    def test_set(self):\n        return self.x_test, self.y_test","eb0327a9":"num_labeled = 100\n\ndataset = Dataset(num_labeled)","38da08ec":"def build_generator(z_dim):\n\n    model = Sequential()\n    model.add(Dense(256 * 7 * 7, input_dim=z_dim))                           \n    model.add(Reshape((7, 7, 256)))\n\n    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n\n    model.add(BatchNormalization())                                          \n\n    model.add(LeakyReLU(alpha=0.01))                                         \n\n    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')) \n\n    model.add(BatchNormalization())                                          \n\n    model.add(LeakyReLU(alpha=0.01))                                         \n\n    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))  \n\n    model.add(Activation('tanh'))                                            \n\n    return model","95b25827":"def build_discriminator_net(img_shape):\n    model = Sequential()\n    \n    model.add(Conv2D(32,\n                     kernel_size = 3,\n                     strides=3,\n                    input_shape=img_shape,\n                    padding='same'))\n    \n    model.add(LeakyReLU(alpha=0.01))\n    \n    model.add(Conv2D(64,\n                     kernel_size = 3,\n                     strides=3,\n                    input_shape=img_shape,\n                    padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    model.add(Conv2D(128,\n                     kernel_size = 3,\n                     strides=3,\n                    input_shape=img_shape,\n                    padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Dropout(0.5))\n    \n    model.add(Flatten())\n    model.add(Dense(num_classes))\n    \n    return model\n    ","42f9961a":"def build_discriminator_supervised(discriminator_net):\n    model = Sequential()\n    model.add(discriminator_net)\n    model.add(Activation('softmax'))\n    \n    return model","4a1b0f4a":"def build_discriminator_unsupervised(discriminator_net):\n    model = Sequential()\n    model.add(discriminator_net)\n    \n    def predict(x):\n        # Transform distribution over real classes into a binary real-vs-fake probability\n        prediction = 1.0 - (1.0 \/\n                            (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n        return prediction\n\n        return prediction\n    model.add(Lambda(predict))\n    \n    return model","9bc276b7":"def build_gan(generator, discriminator):\n\n    model = Sequential()\n\n    model.add(generator)                                                    \n    model.add(discriminator)\n\n    return model\n\n                  ","0e452ae8":"# Core Discriminator network:\n# These layers are shared during supervised and unsupervised training\ndiscriminator_net = build_discriminator_net(img_shape)\n\n# Build & compile the Discriminator for supervised training\ndiscriminator_supervised = build_discriminator_supervised(discriminator_net)\ndiscriminator_supervised.compile(loss='categorical_crossentropy',\n                                 metrics=['accuracy'],\n                                 optimizer=Adam())\n\n# Build & compile the Discriminator for unsupervised training\ndiscriminator_unsupervised = build_discriminator_unsupervised(discriminator_net)\ndiscriminator_unsupervised.compile(loss='binary_crossentropy',\n                                   optimizer=Adam())","bfa86e19":"generator = build_generator(z_dim)\n\n# Keep Discriminator\u2019s parameters constant for Generator training\ndiscriminator_unsupervised.trainable = False\n\n# Build and compile GAN model with fixed Discriminator to train the Generator\n# Note that we are using the Discriminator version with unsupervised output\ngan = build_gan(generator, discriminator_unsupervised)\ngan.compile(loss='binary_crossentropy', optimizer=Adam())","03f5e3ab":"supervised_losses = []\niteration_checkpoints = []\n\n\ndef train(iterations, batch_size, sample_interval):\n\n    # Labels for real images: all ones\n    real = np.ones((batch_size, 1))\n\n    # Labels for fake images: all zeros\n    fake = np.zeros((batch_size, 1))\n\n    for iteration in range(iterations):\n\n      \n\n        # Get labeled examples\n        imgs, labels = dataset.batch_labeled(batch_size)\n\n        # One-hot encode labels\n        labels = to_categorical(labels, num_classes=num_classes)\n\n        # Get unlabeled examples\n        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n\n        # Generate a batch of fake images\n        z = np.random.normal(0, 1, (batch_size, z_dim))\n        gen_imgs = generator.predict(z)\n\n        # Train on real labeled examples\n        d_loss_supervised, accuracy = discriminator_supervised.train_on_batch(imgs, labels)\n\n        # Train on real unlabeled examples\n        d_loss_real = discriminator_unsupervised.train_on_batch(\n            imgs_unlabeled, real)\n\n        # Train on fake examples\n        d_loss_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n\n        d_loss_unsupervised = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n      \n        # Generate a batch of fake images\n        z = np.random.normal(0, 1, (batch_size, z_dim))\n        gen_imgs = generator.predict(z)\n\n        # Train Generator\n        g_loss = gan.train_on_batch(z, np.ones((batch_size, 1)))\n\n        if (iteration + 1) % sample_interval == 0:\n\n            # Save Discriminator supervised classification loss to be plotted after training\n            supervised_losses.append(d_loss_supervised)\n            iteration_checkpoints.append(iteration + 1)\n\n            # Output training progress\n            print(\n                \"%d [D loss supervised: %.4f, acc.: %.2f%%] [D loss unsupervised: %.4f] [G loss: %f]\"\n                % (iteration + 1, d_loss_supervised, 100 * accuracy,\n                   d_loss_unsupervised, g_loss))","8eefb2d4":"iterations = 8000\nbatch_size = 32\nsample_interval = 800\n\n# Train the SGAN for the specified number of iterations\ntrain(iterations, batch_size, sample_interval)","3826793a":"x, y = dataset.test_set()\ny = to_categorical(y, num_classes=num_classes)\n\n_, accuracy = discriminator_supervised.evaluate(x, y)      1\nprint(\"Test Accuracy: %.2f%%\" % (100 * accuracy))","df1f6d59":"# Generator","cd22ed06":"![07fig02_alt-2.jpg](attachment:07fig02_alt-2.jpg)","8c1d0f24":"# Training","5b8f86e1":"# SGAN \n\n> Semi-supervised learning is one of the most promising areas of practical application of GANs. Unlike supervised learning, in which we need a label for every example in our dataset, and unsupervised learning, in which no labels are used, semi-supervised learning has a class label for only a small subset of the training dataset. By internalizing hidden structures in the data, semi-supervised learning strives to generalize from the small subset of labeled data points to effectively classify new, previously unseen examples. Importantly, for semi-supervised learning to work, the labeled and unlabeled data must come from the same underlying distribution.\n\n> The lack of labeled datasets is one of the main bottlenecks in machine learning research and practical applications. Although unlabeled data is abundant (the internet is a virtually limitless source of unlabeled images, videos, and text), assigning class labels to them is often prohibitively expensive, impractical, and time-consuming. It took two and a half years to hand-annotate the original 3.2 million images in the ImageNet\u2014a database of labeled images that helped enable many of the advances in image processing and computer vision in the last decade.\n\n> Semi-Supervised GAN (SGAN) is a Generative Adversarial Network whose Discriminator is a multiclass classifier. Instead of distinguishing between only two classes (real and fake), it learns to distinguish between N + 1 classes, where N is the number of classes in the training dataset, with one added for the fake examples produced by the Generator.\n\n> For example, the MNIST dataset of handwritten digits has 10 labels (one label for each numeral, 0 to 9), so the SGAN Discriminator trained on this dataset would predict between 10 + 1 = 11 classes. In our implementation, the output of the SGAN Discriminator will be represented as a vector of 10 class probabilities (that sum up to 1.0) plus another probability that represents whether the image is real or fake.\n\n> Turning the Discriminator from a binary to a multiclass classifier may seem like a trivial change, but its implications are more far-reaching than may appear at first glance. Let\u2019s start with a diagram.the following shows the SGAN architecture.\n\n","75745426":"# Importing Libraries","9d65812f":"# Discriminator"}}