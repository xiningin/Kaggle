{"cell_type":{"46745f5c":"code","052e581f":"code","96e58b80":"code","8958f666":"code","bb83da6a":"code","403453af":"code","705f848b":"code","c4ac5ca0":"code","1e7f69e8":"code","65cfdd66":"code","9bbe4b20":"code","65f799b7":"code","ca4fe3dc":"code","f99ac85a":"code","d5174cf7":"markdown","2594e5f9":"markdown","018d52a9":"markdown","95a0d50e":"markdown","a7f70481":"markdown","413538f4":"markdown","e23fb4d0":"markdown","8271403c":"markdown","48891c5d":"markdown","33c4cd1e":"markdown"},"source":{"46745f5c":"import pandas as pd\ndf =pd.read_csv('..\/input\/BreadBasket_DMS.csv')\ndf2 = df['Time'].str[0:5].str.split(':',n=1,expand=True)\ndf2[[0,1]] = df2[[0,1]].apply(pd.to_numeric)\ndf2[1] = df2[1]*10\/6\nhighmask = df2[1] > 50\nlowmask = df2[1] < 50\ndf2.loc[highmask, 1] = 50\ndf2.loc[lowmask, 1] = 0\ndf2[0] = (df2[0].astype(str)+'.'+df2[1].astype(str).str[0:1]).astype(float)\ndf = pd.concat([df,df2], axis=1, sort=False)\ndf.pop(1)\ndf.head()","052e581f":"timelist = df[0].unique().tolist()\n#df[0].value_counts()","96e58b80":"allitems = df['Item'].unique().tolist()\n","8958f666":"newdic = {}\nfor i in range(len(allitems)):\n    filt = df['Item'].str.contains(allitems[i])\n    newdf = df[filt]\n    meandf = newdf['Time'].str[0:5].str.split(':',n=1,expand=True)\n    meandf[[0,1]] = meandf[[0,1]].apply(pd.to_numeric)\n    meandf[1] = meandf[1]*10\/6\n    meandf[0] = (meandf[0].astype(str)+'.'+meandf[1].astype(str).str[0:1]).astype(float)\n    count = meandf[0].count()\n    mean = meandf[0].mean()\n    std = meandf[0].std()\n    newdic[allitems[i]]=(mean,std,count)","bb83da6a":"Results = pd.DataFrame(newdic, index=('Mean Time', 'Time STD', 'Transaction Count')).T","403453af":"print(Results.sort_values(by=['Transaction Count'], ascending=False).head())","705f848b":"orderresults = Results.sort_values(by=['Mean Time'], ascending=True)\norderlist = orderresults.index.values\ntop = Results.sort_values(by='Transaction Count', ascending=False)\ntoplist= top.index.values\ntoplist = toplist[:26]\ntoplist\norderedtop = []\np = 0\nwhile p < len(orderlist):\n    if orderlist[p] in toplist:\n        orderedtop.append(orderlist[p])\n    p+=1\norderedtop.remove('NONE')","c4ac5ca0":"orderedtopprice = {'Pastry':2,'Toast':1.50,'Medialuna':2,'Baguette':3,'Farm House':4,'Bread':1.50,'Coffee':1,'Scandinavian':2,'Jam':0.50,'Muffin':2,'Spanish Brunch':12,'Cookies':2,'Juice':2,'Scone':2,'Hot chocolate':3,'Fudge':5,'Tea':1.50,'Brownie':2,'Tiffin':1,'Sandwich':4.5,'Alfajores':3,'Cake':3,'Soup':3,'Truffles':3,'Coke':1}","1e7f69e8":"finaldict = {}\ndf4 = pd.DataFrame()\ndfmean = pd.DataFrame()\ni = 0\nwhile i < len(allitems):\n    filt = df['Item'].str.contains(allitems[i])\n    df3 = df[filt]\n    newseries = pd.Series(df3[0].value_counts(),name=allitems[i])\n    average = newseries.max()\n    meanseries = newseries\/average\n    df4 = pd.concat([df4,newseries], axis=1, sort=False)\n    dfmean = pd.concat([dfmean,meanseries],axis=1,sort=False)\n    i+=1\n\n    ","65cfdd66":"df5 = df4.drop([1.0,7.0,7.5,19.0,18.5,19.5,20.0,21.5,22.0,22.5,20.5,23.0,23.5])\ndfmean = dfmean.drop([1.0,7.0,7.5,19.0,18.5,19.5,20.0,21.5,22.0,22.5,20.5,23.0,23.5])","9bbe4b20":"df6 = df5[orderedtop]\ndfmean = dfmean[orderedtop]","65f799b7":"import seaborn as sns\nimport matplotlib.pyplot as plt\ndfmean = dfmean.fillna(0)\nheatmap = dfmean.T\ndf6 = df6.fillna(0)\nheatmap2 = df6.T\nplt.subplots(figsize=(20,15))\nsns.heatmap(heatmap, annot=False, fmt=\"g\", cmap='viridis')\n","ca4fe3dc":"plt.subplots(figsize=(20,15))\nsns.heatmap(heatmap2, annot=False, fmt=\"g\", cmap='viridis')","f99ac85a":"df7 =df6\nfor i in range(len(orderedtop)):\n    df7[orderedtop[i]] = df7[orderedtop[i]]*orderedtopprice[orderedtop[i]]\npriceadjusted = df7.T\nplt.subplots(figsize=(20,15))\nsns.heatmap(priceadjusted, annot=False, fmt=\"g\", cmap='viridis')","d5174cf7":"**To begin:**\n*\nThis is my second time ever working with pandas so there may be a decent amount of unnecessary code. A lot of these lines were quick practices that I forgot to clean up.*\n\nAnyways, I am interested in seeing how the flow of purchases occurs over time at this bakery. The first thing was to standardize the time points by half hour for ease of use later on. ","2594e5f9":"But that doesn't really matter if coffee only earns you 50 cents while a sandwich earns you 5 bucks! So here is the heatmap of revenue by item throughout the day based on what I assumed the prices for each item was.  From this you can see what items to focus on at what times of day and how you could adjust prices in a worthwhile way. In addition, you could think of certain deals like a coffee and a cookie for 10% off to take advantage of the trends seen here. ","018d52a9":"I then used the data from that to determine what the top 25 items purchased were and then put them in order based on when they were bought most.","95a0d50e":"Got rid of extraneous values","a7f70481":"Next I made a list of all of the item names and proceeded to get some standard statistical info about the transactions of each item (average time purchased, number of transactions, etc.) and made a new dataframe from this.","413538f4":"This map then shows the overall transaction number, all it really says is that coffee and bread are by far the most sold items.","e23fb4d0":"And then made some heatmaps! Time is the bottom axis (in military). The first map shows when each of the top 25 items was bought most frequently, with one being the highest amount and 0 being the lowest. This helps show the trend of sales throughout the day. You can see that toast is bought in the morning, sandwiches are bought in the afternoon, coffee is bought all day, and cookies are bought during only breakfast and lunch time.","8271403c":"I then made a new dataframe containing the number of purchases for each item at every time window found (eg. 10:00-10:30)","48891c5d":"For the purposes of a later graph I made up prices for each item. Maybe there is a menu online somewhere I could get real numbers, but I gave it my best guess.","33c4cd1e":"Reordered the dataframe based on average time bought"}}