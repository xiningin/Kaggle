{"cell_type":{"1a85e8c8":"code","b4397d77":"code","7d8773f5":"code","7742f9e2":"code","df1a0deb":"code","42bf6cf7":"code","5e1d9ac1":"code","1c2e2bb2":"code","7d811a3a":"code","676fc87f":"code","08d74215":"code","9cb727c9":"code","c0ff91a5":"code","8cd311b6":"code","a1733eb2":"code","a3175012":"code","6769e058":"code","b2b60ea2":"markdown"},"source":{"1a85e8c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b4397d77":"data=pd.read_excel('..\/input\/Data_OpelCorsa.xlsx')","7d8773f5":"data.head()","7742f9e2":"#Preprocessing Ad\u0131m 2: phone number, area code, state \u00f6zniteliklerinin kald\u0131r\u0131lmas\u0131\ndata.drop('Column1', axis = 1, inplace = True)\ndata.drop('baslik', axis = 1, inplace = True)\ndata.drop('ilce', axis = 1, inplace = True)\ndata.drop('mahalle', axis = 1, inplace = True)\ndata.drop('para_birimi', axis = 1, inplace = True)\ndata.drop('ilan_no', axis = 1, inplace = True)\ndata.drop('ilan_tarihi', axis = 1, inplace = True)\ndata.drop('marka', axis = 1, inplace = True)\nprint(\"After Dataset preprocessing: \" + str(data.shape))","df1a0deb":"data.head()","42bf6cf7":"\nprint('Original Features:\\n', list(data.columns), '\\n')\ndata= pd.get_dummies(data)\nprint('Features after One-Hot Encoding:\\n', list(data.columns))","5e1d9ac1":"# Scatter Plot \ndata.plot(kind='scatter', x='fiyat', y='yil',alpha = 0.5,color = 'red')\nplt.xlabel('price')              # label = name of label\nplt.ylabel('year')\nplt.title('Fiyat ve yil Scatter Plot') \n\ndata.plot(kind='scatter', x='fiyat', y='km',alpha = 0.5,color = 'grey')\nplt.xlabel('price')              # label = name of label\nplt.ylabel('km')\nplt.title('Fiyat ve km Scatter Plot') \ndata.plot(kind='scatter', x='fiyat', y='motor_gucu_hp',alpha = 0.5,color = 'green')\nplt.xlabel('price')              # label = name of label\nplt.ylabel('machine power')\nplt.title('fiyat ve motor_gucu_hp Scatter Plot') \n\n","1c2e2bb2":"# Importing the dataset\nX = data.iloc[:, data.columns != 'fiyat']\ny = data.fiyat\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","7d811a3a":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","676fc87f":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\n\n# define base model\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(30, input_dim=120, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(output_dim = 120, init = 'uniform', activation = 'relu'))\n    model.add(Dense(output_dim = 120, init = 'uniform', activation = 'relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='mse',\n                optimizer='adam',\n                metrics=['mae'] )\n    return model\n\nmodel = baseline_model()\nmodel.summary()\n","08d74215":"from __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\n\nprint(tf.__version__)\n\n# Display training progress by printing a single dot for each completed epoch\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 500\n\n# Store training stats\nhistory = model.fit(X_train, y_train, epochs=EPOCHS,\n                    validation_split=0.2, verbose=0,\n                    callbacks=[PrintDot()])","9cb727c9":"test_predictions = model.predict(X_test).flatten()\n\nplt.scatter(y_test, test_predictions)\nplt.xlabel('True Values [1000$]')\nplt.ylabel('Predictions [1000$]')\nplt.axis('equal')\nplt.xlim(plt.xlim())\nplt.ylim(plt.ylim())\n_ = plt.plot([-100, 100], [-100, 100])","c0ff91a5":"error = test_predictions - y_test\nplt.hist(error, bins = 50)\nplt.xlabel(\"Prediction Error [1000 TL]\")\n_ = plt.ylabel(\"Count\")","8cd311b6":"error = np.sum(np.sqrt(test_predictions - y_test))","a1733eb2":"error\/len(data)","a3175012":"from sklearn.metrics import r2_score","6769e058":"r2_score(y_test, test_predictions)","b2b60ea2":"Convert categorical data to 1 and 0. "}}