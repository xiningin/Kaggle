{"cell_type":{"86630d5e":"code","450056a6":"code","6762b8e9":"code","e76ed126":"code","8e7b2ad9":"code","1450fa27":"code","726d2d06":"code","a476fd53":"code","5f4cf798":"markdown","8a0cae49":"markdown"},"source":{"86630d5e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport h5py\nimport gc\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\n#models\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_v3 import InceptionV3","450056a6":"train_datagen = ImageDataGenerator(#data_format='channels_first',\n                                  validation_split=0.2,\n                                  samplewise_center = True,\n                                  samplewise_std_normalization = True)\n\ntrain_generator = train_datagen.flow_from_directory(directory=\"..\/input\/food41\/images\/\",\n                                                    subset=\"training\",\n                                                    batch_size=64,\n                                                    shuffle=True,\n                                                    class_mode=\"categorical\",\n                                                    target_size=(299,299),\n                                                    seed=42)\n\nvalid_generator=train_datagen.flow_from_directory(directory=\"..\/input\/food41\/images\/\",\n                                                  subset=\"validation\",\n                                                  batch_size=64,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=(299,299),\n                                                  seed=42)","6762b8e9":"incnet = InceptionV3(weights='imagenet', include_top=False, input_tensor=layers.Input(shape=(299, 299, 3)))\nx = incnet.output\nx = layers.AveragePooling2D(pool_size=(8, 8))(x)\nx = layers.Dropout(.2)(x)\nx = layers.Flatten()(x)\noutput = layers.Dense(101, init='glorot_uniform', activation='softmax', kernel_regularizer=regularizers.l2(.0005))(x)\n\nmodel = models.Model(inputs=incnet.input, outputs=output)\nmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])","e76ed126":"gc.collect()","8e7b2ad9":"early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\ncheckpoint_callback = ModelCheckpoint('InceptionNet.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nhistory = model.fit_generator(train_generator,\n                            validation_data=valid_generator,\n                            epochs=10,workers=0,use_multiprocessing=False, callbacks=[early_stopping_callback, checkpoint_callback])","1450fa27":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['acc', 'val_acc'])\nplt.show()","726d2d06":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","a476fd53":"# model.save(\"InceptionNet.h5\")","5f4cf798":"Load images from folder using generator (it will be useful if we add data)","8a0cae49":"InceptionNet"}}