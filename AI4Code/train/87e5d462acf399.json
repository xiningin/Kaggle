{"cell_type":{"e594ea06":"code","dd0929ba":"code","93e71c9c":"code","0a5e130f":"code","4e8da53f":"code","62626aca":"code","210bdab3":"code","2a7b961e":"code","6a3b84ea":"code","1f84c332":"code","9b7cfcf0":"code","897ff1c4":"code","7feb14f4":"code","a134fbe6":"code","15bc5112":"code","9407ced1":"code","7b1705c4":"code","87f22790":"code","48c21c42":"code","3a2788b1":"code","e3586622":"code","cfdd2018":"code","e591156c":"code","5dbe47ae":"code","fa42f89b":"code","a25c1f6e":"code","b41252d7":"code","24f8ddb5":"code","6c6302f6":"code","1a0e3d9f":"code","51135bbf":"code","258b2529":"code","2842b0a5":"code","7c1e185d":"code","e17b22be":"code","21a2a146":"code","b3f70f68":"code","d19a9c2a":"code","4e8c564e":"code","b8e716a5":"code","e61789a9":"code","a002ce9e":"code","fab4e39a":"code","584d0375":"code","d6230445":"code","db2e86bc":"code","f9d0c8fa":"code","73bab820":"code","b5a8f6b3":"code","443d9bef":"code","72d4551e":"code","cf9129c2":"code","8bcf3e2f":"code","38a78c20":"code","e8bba5dc":"code","300a7d91":"code","3270e783":"code","84d38df2":"code","f1f4197b":"code","94af9e4f":"code","73e5c240":"code","ff82de84":"code","fa04c4d2":"code","9e278fc3":"code","907ef210":"code","b0ba988c":"code","b8b8d3ff":"code","b69d2c24":"code","6bc69fcb":"code","edd961d0":"code","3844246f":"code","a7892e5f":"code","3c012f24":"code","71ea2b5f":"code","3c18beec":"code","b8b23d2a":"code","2cf27eee":"code","3c009663":"code","b43028b3":"code","dec20c53":"code","69214094":"code","1cbe0bc3":"code","2b6f4477":"code","e6874028":"code","7a8cc363":"code","239dea73":"code","ca1d909f":"code","538b1cca":"code","85e76e7b":"code","2b0cd799":"code","b794e8f2":"code","b9fd1295":"code","86a2a814":"code","22f7f394":"code","47e5c18c":"code","bf62c6e9":"code","3f40ee95":"code","066e9974":"code","f2b83eba":"markdown","aee488c7":"markdown","e0bd26fa":"markdown","9fca1f34":"markdown","1571f794":"markdown","44792cd2":"markdown","43245416":"markdown","027bd07f":"markdown","f4b87f1d":"markdown","c947998e":"markdown","db16e860":"markdown","84c02717":"markdown","37c61ac3":"markdown","0b8ecd74":"markdown","8fc8c7ab":"markdown","8ba0b01f":"markdown"},"source":{"e594ea06":"cd","dd0929ba":"import os\nos.listdir('\/tmp\/..\/')","93e71c9c":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nprint('Files in this directory:',os.listdir('..\/kaggle\/input'))","0a5e130f":"def f(x):\n    display(x)","4e8da53f":"images_list = os.listdir(\"..\/kaggle\/input\/train\/\")\nprint('Total number of training images:',len(images_list))","62626aca":"train_labels_df = pd.read_csv(\"..\/kaggle\/input\/train_labels.csv\")\nprint(\"Total number of labels for training images: \",len(train_labels_df))","210bdab3":"train_labels_df.columns.tolist()","2a7b961e":"print('First image id in training images:',images_list[0])\nprint(\"First image id in taining_labels csv:\", train_labels_df.iloc[0,0])","6a3b84ea":"img = cv2.imread('..\/kaggle\/input\/train\/'+ images_list[0]) #opencv color order BGR\nrgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)     #opencv BGR format   ","1f84c332":"print('shape of img:',img.shape)","9b7cfcf0":"plt.imshow(rgb_img) #matplotlib color order RGB","897ff1c4":"print(type(train_labels_df.iloc[0,1]))\ntrain_labels_df.iloc[0,1]","7feb14f4":"print(type(train_labels_df.iloc[:,1]))\ntrain_labels_df.iloc[:,1]","a134fbe6":"total_images = train_labels_df.iloc[:,0].tolist()\nprint('Total no of images: ', len(total_images))\nnon_tumor_images = train_labels_df[train_labels_df.iloc[:,1] == 0]['id'].tolist()\nprint('No. of non-tumor images:',len(non_tumor_images))\ntumor_images = train_labels_df[train_labels_df.iloc[:,1] == 1]['id'].tolist()\nprint('No. of tumor images:',len(tumor_images))\n","15bc5112":"train_labels_df['label'].value_counts()","9407ced1":"# '.tif' is not there at the end of image ids in train_label.csv\ntum_img = cv2.imread('..\/kaggle\/input\/train\/' + tumor_images[550] + '.tif')\ntum_img_grey = cv2.imread('..\/kaggle\/input\/train\/' + tumor_images[550] + '.tif', cv2.IMREAD_GRAYSCALE)\ntum_img = cv2.cvtColor(tum_img, cv2.COLOR_BGR2RGB)\n\nnon_tum_img = cv2.imread('..\/kaggle\/input\/train\/' + non_tumor_images[250] + '.tif')\nnon_tum_img = cv2.cvtColor(non_tum_img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(tum_img)","7b1705c4":"plt.imshow(tum_img_grey)","87f22790":"tum_img_grey.shape","48c21c42":"plt.imshow(tum_img_grey, cmap = 'gray')","3a2788b1":"non_tum_img.shape","e3586622":"plt.imshow(non_tum_img)","cfdd2018":"#AfterWork-  write functions given an 'img id' it shld return 0\/1","e591156c":"print(images_list[0])\nprint(total_images[0])","5dbe47ae":"train_labels_df.iloc[:,0] = [train_labels_df.iloc[:,0][i] + '.tif' for i in range(len(train_labels_df.iloc[:,0]))]","fa42f89b":"train_labels_df.head()","a25c1f6e":"new_df = train_labels_df.copy()\nnew_df.head()","b41252d7":"train_images = new_df.iloc[:,0].tolist()","24f8ddb5":"# column_names = [f'p{i}' for i in range(1, 48*48 +1)]\n# column_names[-1]\n# df1 = pd.DataFrame(columns = column_names)\n# df1.head()","6c6302f6":"# # df1['index'] = [i for i in range(0,220025)]\n# # df1['index'] = list(range(0,120025))\n# df1['index']\n# f(df1.head())\n# f(df1.tail())","1a0e3d9f":"p = cv2.imread('..\/kaggle\/input\/train\/' + train_images[0], cv2.IMREAD_GRAYSCALE)\nplt.imshow(p, cmap='gray')\np.shape","51135bbf":"plt.imshow(p[31:79,31:79], cmap = 'gray')\np[31:79,31:79].shape","258b2529":"def crop(img):\n    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n    crop_img = image[31:79,31:79]\n    return crop_img\n    ","2842b0a5":"x = crop('..\/kaggle\/input\/train\/'+train_images[0])\nprint('shape of x is:', x.shape)","7c1e185d":"from numpy import newaxis\ndef crop_image(img):\n    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n    crop_img = image[31:79,31:79]\n    crop_img = crop_img[:,:,newaxis]    \n    return crop_img","e17b22be":"eg = crop_image('..\/kaggle\/input\/train\/' + train_images[0])\nprint('shape of this image is:', eg.shape)\neg","21a2a146":"from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","b3f70f68":"\nclassifier = Sequential()\nclassifier.add(Convolution2D(32,3,3, input_shape = (48,48,1), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Convolution2D(64,3,3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Convolution2D(128,3,3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Convolution2D(256,3,3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Flatten())\nclassifier.add(Dense(output_dim = 256, activation = 'relu'))\nclassifier.add(Dense(output_dim = 128, activation = 'relu'))\nclassifier.add(Dense(output_dim = 64, activation = 'relu'))\nclassifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n\nclassifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n","d19a9c2a":"# def process(img):\n#     img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n#     img.resize((img.shape[0]*img.shape[1]))\n# #     return img","4e8c564e":"# x = process('..\/kaggle\/\/input\/train\/' + train_images[0])\n# print('x from (96,96) shape to (96*96): ',x)","b8e716a5":"# for i in range(220025):\n#     row = process('..\/input\/train\/' + train_images[i])\n#     df1.loc[i] = row","e61789a9":"from sklearn.utils import shuffle\nshuffled_data =shuffle(new_df)","a002ce9e":"shuffled_data.head()","fab4e39a":"len(shuffled_data)","584d0375":"features = [crop_image('..\/kaggle\/input\/train\/' + i) for i in  shuffled_data.iloc[:,0].tolist()]\nprint('Input features is a list containing ' + str(len(features)) + ' arrays')","d6230445":"print('shape of each example is:',features[0].shape)","db2e86bc":"labels = shuffled_data.iloc[:,1].tolist()\nprint(\"labels is a list of ouput labels containing 0's and 1's\")","f9d0c8fa":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.3)","73bab820":"print('Length of x_train', len(x_train))\nprint('Length of y_train', len(y_train))\nprint('Length of x_val', len(x_val))\nprint('Length of y_val', len(y_val))","b5a8f6b3":"print('No. of tumor examples in y_train =', sum(y_train))\nprint('No. of non-tumor examples in y_train =', len(y_train) - sum(y_train))\nprint('No. of tumor examples in y_val =', sum(y_val))\nprint('No. of non-tumor examples in y_val =', len(y_val) - sum(y_val))","443d9bef":"print('type of x_train is:', type(x_train))\nprint('type of y_train is:', type(y_train))\nprint('type of x_val is:', type(x_val))\nprint('type of y_val is:', type(y_val))","72d4551e":"x_train = np.array(x_train)\/255\nx_val = np.array(x_val)\/255","cf9129c2":"x_train","8bcf3e2f":"print('shape of x_train is:', x_train.shape)\nprint('shape of x_val is:', x_val.shape)","38a78c20":"\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(shear_range = 0.2, zoom_range = 0.2,\n                   horizontal_flip = True)\nclassifier.fit_generator(datagen.flow(x_train, y_train, batch_size=20),\n                    steps_per_epoch=len(x_train) \/ 20, epochs = 70)","e8bba5dc":"# c = np.reshape(y, y.shape + (1,))  -> (48,48) to (48,48,1)","300a7d91":"weights = classifier.weights\nweights","3270e783":"predictions = classifier.predict(x_val)\npredictions","84d38df2":"predictions.shape","f1f4197b":"predictions.resize(66008,)","94af9e4f":"predictions","73e5c240":"y_val_pred = list(predictions)","ff82de84":"y_val_predicted = [1  if i > 0.5 else 0 for i in y_val_pred]\ny_val_predicted2 = [1  if i > 0.1 else 0 for i in y_val_pred]\n\nsum(y_val_predicted)","fa04c4d2":"sum(y_val_predicted2)","9e278fc3":"np.unique(y_val_pred)","907ef210":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_val, y_val_predicted)","b0ba988c":"from sklearn.metrics import accuracy_score\naccuracy_score(y_val, y_val_predicted)","b8b8d3ff":"x_val2 = x_val\ndatagen.fit(x_val2)","b69d2c24":"predictions2 = classifier.predict(x_val2)\npredictions2","6bc69fcb":"sum(predictions2)","edd961d0":"np.unique(predictions2)","3844246f":"predictions2.shape","a7892e5f":"predictions2.resize(66008,)\npredictions2.shape","3c012f24":"y_val_pred3 = list(predictions2)","71ea2b5f":"y_val_predicted3 = [1  if i > 0.5 else 0 for i in y_val_pred3]","3c18beec":"sum(y_val_predicted3)","b8b23d2a":"np.unique(y_val_predicted3)","2cf27eee":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_val, y_val_predicted3)","3c009663":"from sklearn.metrics import accuracy_score\naccuracy_score(y_val, y_val_predicted3)","b43028b3":"classifier2 = Sequential()\n\nclassifier2.add(Convolution2D(32,3,3, input_shape = (48,48,1), activation = 'relu'))\nclassifier2.add(MaxPooling2D(pool_size=(2,2)))\nclassifier2.add(Dropout(0.2))\n\nclassifier2.add(Convolution2D(64,3,3, activation = 'relu'))\nclassifier2.add(MaxPooling2D(pool_size=(2,2)))\nclassifier2.add(Dropout(0.2))\nclassifier2.add(Convolution2D(128,3,3, activation = 'relu'))\nclassifier2.add(MaxPooling2D(pool_size=(2,2)))\nclassifier2.add(Dropout(0.2))\n\nclassifier2.add(Convolution2D(256,3,3, activation = 'relu'))\nclassifier2.add(MaxPooling2D(pool_size=(2,2)))\nclassifier2.add(Dropout(0.2))\n\nclassifier2.add(Flatten())\nclassifier2.add(Dense(output_dim = 256, activation = 'relu'))\nclassifier2.add(Dropout(0.2))\nclassifier2.add(Dense(output_dim = 128, activation = 'relu'))\nclassifier2.add(Dropout(0.2))\nclassifier2.add(Dense(output_dim = 64, activation = 'relu'))\nclassifier2.add(Dropout(0.2))\nclassifier2.add(Dense(output_dim = 1, activation = \"sigmoid\"))\n\nclassifier2.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n\nclassifier2.summary()","dec20c53":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale = 1.\/255, shear_range = 0.2, zoom_range = 0.2,\n                   horizontal_flip = True)\ndatagen.fit(x_train)\nclassifier2.fit_generator(datagen.flow(x_train, y_train, batch_size=20),\n                    steps_per_epoch=len(x_train) \/ 20, epochs = 20)","69214094":"weights2 = classifier2.weights\nweights2","1cbe0bc3":"predictions4 = classifier.predict(x_val)\npredictions4","2b6f4477":"predictions4.resize(66008,)\npredictions4","e6874028":"y_val_pred4 = list(predictions4)\ny_val_predicted4 = [1  if i > 0.5 else 0 for i in y_val_pred4]\nsum(y_val_predicted4)\n","7a8cc363":"np.unique(y_val_pred4)","239dea73":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_val, y_val_predicted4)","ca1d909f":"from sklearn.metrics import accuracy_score\naccuracy_score(y_val, y_val_predicted4)","538b1cca":"test_images = os.listdir(\"..\/kaggle\/input\/test\/\")\nprint('Total number of training images:',len(test_images))\n","85e76e7b":"test_features = [crop_image('..\/kaggle\/input\/test\/' + i) for i in  test_images]\ntest_features = np.array(test_features)\ntest_features = test_features\/255\ntest_features[0]\ntest_features.shape","2b0cd799":"test_preds = classifier.predict(test_features)\ntest_preds.resize(57458,)\ntest_preds = list(test_preds)\ntest_values = [1  if i > 0.5 else 0 for i in test_preds]","b794e8f2":"sum(test_values)","b9fd1295":"df = {}\ndf['id'] = [i.split('.')[0] for i in test_images]\ndf['label'] = test_preds","86a2a814":"test_images[0]","22f7f394":"import pandas as pd","47e5c18c":"DataFrame = pd.DataFrame.from_dict(df)\nDataFrame","bf62c6e9":"submission_file = pd.read_csv('..\/kaggle\/input\/sample_submission.csv')","3f40ee95":"submission = DataFrame\nsubmission.to_csv('predictions.csv', columns=['label']) ","066e9974":"submission.head()","f2b83eba":"No. of positive and negative examples","aee488c7":"Total number of labels for training images:  220025","e0bd26fa":"But shape of data should be (examples, height, width, channels) which means its an array.\n\nList doesn't have any shape. It only has length. \n\nSo, we need to convert list into array.","9fca1f34":"After rescaling:\n    Epoch 1\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.5090 - acc: 0.7600\nEpoch 2\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4840 - acc: 0.7770\nEpoch 3\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4756 - acc: 0.7820\nEpoch 4\/20\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4696 - acc: 0.7858\nEpoch 5\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4642 - acc: 0.7887\nEpoch 6\/20\n7701\/7700 [==============================] - 77s 10ms\/step - loss: 0.4602 - acc: 0.7915\nEpoch 7\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4551 - acc: 0.7943\nEpoch 8\/20\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4519 - acc: 0.7961\nEpoch 9\/20\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4471 - acc: 0.7982\nEpoch 10\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4451 - acc: 0.7990\nEpoch 11\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4424 - acc: 0.8010\nEpoch 12\/20\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4379 - acc: 0.8037\nEpoch 13\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4363 - acc: 0.8040\nEpoch 14\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4348 - acc: 0.8050\nEpoch 15\/20\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4319 - acc: 0.8061\nEpoch 16\/20\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4286 - acc: 0.8081\nEpoch 17\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4279 - acc: 0.8082\nEpoch 18\/20\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4246 - acc: 0.8098\nEpoch 19\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4228 - acc: 0.8117\nEpoch 20\/20\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4224 - acc: 0.8110\n    \n    ","1571f794":"Issue - training images ends with .tif, train_labels.csv 1st column id doesn't end with .tif","44792cd2":"Adding '.tif' at the end of each id in train_labels.csv","43245416":"If we use dropout:\nEpoch 1\/20\n7701\/7700 [==============================] - 83s 11ms\/step - loss: 0.6758 - acc: 0.5944\nEpoch 2\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6754 - acc: 0.5945\nEpoch 3\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6753 - acc: 0.5945\nEpoch 4\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6753 - acc: 0.5945\nEpoch 5\/20\n7701\/7700 [==============================] - 80s 10ms\/step - loss: 0.6753 - acc: 0.5945\nEpoch 6\/20\n7701\/7700 [==============================] - 78s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 7\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 8\/20\n7701\/7700 [==============================] - 78s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 9\/20\n7701\/7700 [==============================] - 80s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 10\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 11\/20\n7701\/7700 [==============================] - 78s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 12\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 13\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 14\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 15\/20\n7701\/7700 [==============================] - 78s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 16\/20\n7701\/7700 [==============================] - 78s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 17\/20\n7701\/7700 [==============================] - 80s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 18\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 19\/20\n7701\/7700 [==============================] - 78s 10ms\/step - loss: 0.6752 - acc: 0.5945\nEpoch 20\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.6752 - acc: 0.5945\n\n    ","027bd07f":"WARNING:tensorflow:From \/opt\/conda\/lib\/python3.6\/site-packages\/tensorflow\/python\/ops\/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1\/20\n7701\/7700 [==============================] - 79s 10ms\/step - loss: 0.5148 - acc: 0.7533\nEpoch 2\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4845 - acc: 0.7763\nEpoch 3\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4765 - acc: 0.7813\nEpoch 4\/20\n7701\/7700 [==============================] - 75s 10ms\/step - loss: 0.4717 - acc: 0.7839\nEpoch 5\/20\n7701\/7700 [==============================] - 76s 10ms\/step - loss: 0.4640 - acc: 0.7881\nEpoch 6\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4588 - acc: 0.7918\nEpoch 7\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4549 - acc: 0.7935\nEpoch 8\/20\n7701\/7700 [==============================] - 75s 10ms\/step - loss: 0.4515 - acc: 0.7958\nEpoch 9\/20\n7701\/7700 [==============================] - 77s 10ms\/step - loss: 0.4471 - acc: 0.7990\nEpoch 10\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4446 - acc: 0.7992\nEpoch 11\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4417 - acc: 0.8008\nEpoch 12\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4387 - acc: 0.8026\nEpoch 13\/20\n7701\/7700 [==============================] - 76s 10ms\/step - loss: 0.4366 - acc: 0.8041\nEpoch 14\/20\n7701\/7700 [==============================] - 73s 10ms\/step - loss: 0.4346 - acc: 0.8042\nEpoch 15\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4335 - acc: 0.8065\nEpoch 16\/20\n7701\/7700 [==============================] - 75s 10ms\/step - loss: 0.4318 - acc: 0.8068\nEpoch 17\/20\n7701\/7700 [==============================] - 76s 10ms\/step - loss: 0.4299 - acc: 0.8077\nEpoch 18\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4273 - acc: 0.8098\nEpoch 19\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4265 - acc: 0.8092\nEpoch 20\/20\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4254 - acc: 0.8100","f4b87f1d":"#Visualize one image","c947998e":"So, the training accuracy is_ : 81%","db16e860":"['id', 'label']","84c02717":"70 epochs:\n    Epoch 1\/70\n7701\/7700 [==============================] - 82s 11ms\/step - loss: 0.5062 - acc: 0.7616\nEpoch 2\/70\n7701\/7700 [==============================] - 77s 10ms\/step - loss: 0.4801 - acc: 0.7792\nEpoch 3\/70\n7701\/7700 [==============================] - 76s 10ms\/step - loss: 0.4716 - acc: 0.7844\nEpoch 4\/70\n7701\/7700 [==============================] - 75s 10ms\/step - loss: 0.4653 - acc: 0.7875\nEpoch 5\/70\n7701\/7700 [==============================] - 75s 10ms\/step - loss: 0.4597 - acc: 0.7914\nEpoch 6\/70\n7701\/7700 [==============================] - 75s 10ms\/step - loss: 0.4532 - acc: 0.7930\nEpoch 7\/70\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4507 - acc: 0.7965\nEpoch 8\/70\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4478 - acc: 0.7970\nEpoch 9\/70\n7701\/7700 [==============================] - 74s 10ms\/step - loss: 0.4443 - acc: 0.7986\nEpoch 10\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4417 - acc: 0.8000\nEpoch 11\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4396 - acc: 0.8020\nEpoch 12\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4368 - acc: 0.8027\nEpoch 13\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4355 - acc: 0.8034\nEpoch 14\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4331 - acc: 0.8049\nEpoch 15\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4326 - acc: 0.8062\nEpoch 16\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4308 - acc: 0.8074\nEpoch 17\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4284 - acc: 0.8081\nEpoch 18\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4275 - acc: 0.8079\nEpoch 19\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4263 - acc: 0.8102\nEpoch 20\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4253 - acc: 0.8097\nEpoch 21\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4237 - acc: 0.8102\nEpoch 22\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4256 - acc: 0.8103\nEpoch 23\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4219 - acc: 0.8122\nEpoch 24\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4224 - acc: 0.8116\nEpoch 25\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4212 - acc: 0.8129\nEpoch 26\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4191 - acc: 0.8143\nEpoch 27\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4233 - acc: 0.8120\nEpoch 28\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4212 - acc: 0.8130\nEpoch 29\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4216 - acc: 0.8128\nEpoch 30\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4172 - acc: 0.8150\nEpoch 31\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4169 - acc: 0.8152\nEpoch 32\/70\n7701\/7700 [==============================] - 73s 10ms\/step - loss: 0.4172 - acc: 0.8148\nEpoch 33\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4166 - acc: 0.8150\nEpoch 34\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4148 - acc: 0.8159\nEpoch 35\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4176 - acc: 0.8140\nEpoch 36\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4148 - acc: 0.8172\nEpoch 37\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4170 - acc: 0.8172\nEpoch 38\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4126 - acc: 0.8180\nEpoch 39\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4140 - acc: 0.8167\nEpoch 40\/70\n7701\/7700 [==============================] - 70s 9ms\/step - loss: 0.4122 - acc: 0.8184\nEpoch 41\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4107 - acc: 0.8188\nEpoch 42\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4123 - acc: 0.8179\nEpoch 43\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4115 - acc: 0.8192\nEpoch 44\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4089 - acc: 0.8207\nEpoch 45\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4077 - acc: 0.8213\nEpoch 46\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4159 - acc: 0.8165\nEpoch 47\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4083 - acc: 0.8201\nEpoch 48\/70\n7701\/7700 [==============================] - 70s 9ms\/step - loss: 0.4160 - acc: 0.8166\nEpoch 49\/70\n7701\/7700 [==============================] - 70s 9ms\/step - loss: 0.4075 - acc: 0.8206\nEpoch 50\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4052 - acc: 0.8214\nEpoch 51\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4040 - acc: 0.8219\nEpoch 52\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4112 - acc: 0.8196\nEpoch 53\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4110 - acc: 0.8212\nEpoch 54\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4087 - acc: 0.8188\nEpoch 55\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4108 - acc: 0.8180\nEpoch 56\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4030 - acc: 0.8228\nEpoch 57\/70\n7701\/7700 [==============================] - 69s 9ms\/step - loss: 0.4039 - acc: 0.8220\nEpoch 58\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.4001 - acc: 0.8241\nEpoch 59\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.3999 - acc: 0.8239\nEpoch 60\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4069 - acc: 0.8219\nEpoch 61\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4046 - acc: 0.8223\nEpoch 62\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4039 - acc: 0.8219\nEpoch 63\/70\n7701\/7700 [==============================] - 73s 9ms\/step - loss: 0.4040 - acc: 0.8230\nEpoch 64\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4014 - acc: 0.8239\nEpoch 65\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4095 - acc: 0.8220\nEpoch 66\/70\n7701\/7700 [==============================] - 70s 9ms\/step - loss: 0.4034 - acc: 0.8231\nEpoch 67\/70\n7701\/7700 [==============================] - 72s 9ms\/step - loss: 0.3996 - acc: 0.8233\nEpoch 68\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4069 - acc: 0.8228\nEpoch 69\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4079 - acc: 0.8212\nEpoch 70\/70\n7701\/7700 [==============================] - 71s 9ms\/step - loss: 0.4022 - acc: 0.8237","37c61ac3":"Total number of training images: 220025","0b8ecd74":"So, we need to convert the shape fr_m (48,48) to (48,48,1)","8fc8c7ab":"Files in this directory: ['test', 'train_labels.csv', 'train', 'sample_submission.csv']","8ba0b01f":"Input features shape should be (examples, height, width, channels). For example (220025, 48, 48, 1)"}}