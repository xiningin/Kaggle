{"cell_type":{"c1a0b46f":"code","a9036e3f":"code","8c1cef4c":"code","6e70def2":"code","ec920bcf":"code","c245938d":"code","ee0976ae":"code","59a9f332":"code","9d4f3288":"code","608c3beb":"code","3315afa0":"code","805f3b88":"code","acf80d24":"code","41388ec7":"code","987b18d1":"code","887c9675":"code","e77264d8":"code","af6aab39":"code","910a5323":"code","4d787748":"code","5348094d":"code","a19c3851":"code","33c63cad":"code","dc159c41":"code","d5009df8":"code","8e602804":"code","127b952e":"code","da9d113d":"code","8a9e1707":"code","a72483c1":"code","3f511f72":"code","094f021e":"code","1120e1e2":"code","b5608027":"code","384acfb1":"code","c673cb86":"code","0808f014":"code","17c0c891":"code","f187fce2":"code","acafcc40":"code","883a699b":"code","913ec2bf":"code","60a507ec":"code","0e43208c":"code","94534c69":"code","44152081":"code","0d54f6f9":"code","3637dc72":"code","0cff2a05":"code","258085ea":"code","d1bca1b5":"code","c7f53594":"code","5eaad1ff":"code","8f7c82a7":"code","8068fe78":"code","0600011b":"code","d406eed6":"markdown"},"source":{"c1a0b46f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a9036e3f":"from __future__ import absolute_import, division, print_function, unicode_literals\ntry:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\nimport tensorflow as tf\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\n\nmpl.rcParams['figure.figsize'] = (8, 6)\nmpl.rcParams['axes.grid'] = False","8c1cef4c":"tf.__version__","6e70def2":"train = pd.read_csv('\/kaggle\/input\/ltfs-2\/train_fwYjLYX.csv')\ntest = pd.read_csv('\/kaggle\/input\/ltfs-2\/test_1eLl9Yf.csv')","ec920bcf":"train['application_date']=pd.to_datetime(train['application_date'],format=\"%Y-%m-%d\")\ntest['application_date']=pd.to_datetime(test['application_date'],format=\"%Y-%m-%d\")","c245938d":"train=train.groupby(['application_date','segment']).sum().reset_index()\n\n","ee0976ae":"train['weekday']=train['application_date'].apply(lambda x : x.weekday())\ntrain['day']=train['application_date'].apply(lambda x : x.day)\ntrain['month']=train['application_date'].apply(lambda x : x.month)\n#train['year']=train['application_date'].apply(lambda x : x.year)\n\ntest['weekday']=test['application_date'].apply(lambda x : x.weekday())\ntest['day']=test['application_date'].apply(lambda x : x.day)\ntest['month']=test['application_date'].apply(lambda x : x.month)\n#test['year']=test['application_date'].apply(lambda x : x.year)","59a9f332":"train_seg1 = train[train['segment']==1]\ntrain_seg2 = train[train['segment']==2]","9d4f3288":"idx = pd.date_range('2017-04-01', '2019-07-05')\ntrain_seg1.index=train_seg1.application_date\ntrain_seg1.drop(['application_date'],axis=1,inplace=True)\ntrain_seg1=train_seg1.reindex(idx,method='ffill')\ntrain_seg1.head()","608c3beb":"idx = pd.date_range('2017-04-01', '2019-07-23')\ntrain_seg2.index=train_seg2.application_date\ntrain_seg2.drop(['application_date'],axis=1,inplace=True)\ntrain_seg2=train_seg2.reindex(idx,method='ffill')\ntrain_seg2.head()","3315afa0":"idx = pd.date_range('2019-07-06', '2019-10-24')\ntest.index=test.application_date\ntest.drop(['application_date'],axis=1,inplace=True)\n#test=test.reindex(idx,method='ffill')\ntest.head()","805f3b88":"test.head()","acf80d24":"train_seg1.head()","41388ec7":"features_considered = ['case_count','weekday','day','month']\ntarget = ['case_count']","987b18d1":"features_s1 = train_seg1[features_considered]\nfeatures_s1.head()","887c9675":"features_s2 = train_seg2[features_considered]\nfeatures_s2.head()","e77264d8":"features_s1.plot(subplots=True)","af6aab39":"features_s2.plot(subplots=True)","910a5323":"train_seg1_split = int(int(train_seg1.shape[0])\/1.2)\ntrain_seg2_split = int(int(train_seg2.shape[0])\/1.2)","4d787748":"TRAIN_SPLIT_s1=train_seg1_split\nTRAIN_SPLIT_s2=train_seg2_split","5348094d":"dataset_s1 = features_s1.values\n#data_mean_s1 = dataset_s1[:TRAIN_SPLIT_s1].mean(axis=0)\n#data_std_s1 = dataset_s1[:TRAIN_SPLIT_s1].std(axis=0)\n#dataset_s1 = (dataset_s1-data_mean_s1)\/data_std_s1","a19c3851":"dataset_s2 = features_s2.values\n#data_mean_s2 = dataset_s2[:TRAIN_SPLIT_s2].mean(axis=0)\n#data_std_s2 = dataset_s2[:TRAIN_SPLIT_s2].std(axis=0)\n#dataset_s2 = (dataset_s2-data_mean_s2)\/data_std_s2","33c63cad":"dataset_s2[0]","dc159c41":"#data_mean_s2","d5009df8":"dataset_s1[4]","8e602804":"\ndef split_sequences(sequences, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequences)):\n    # find the end of this pattern\n        end_ix = i + n_steps\n    # check if we are beyond the dataset\n        if end_ix > len(sequences):\n            break\n    # gather input and output parts of the pattern\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n        X.append(seq_x)\n        y.append(seq_y)\n    return np.array(X), np.array(y)","127b952e":"train_seg1.head()","da9d113d":"dataset_s1[0]","8a9e1707":"dataset_s2[0]","a72483c1":"in_seq1_s1 = np.array(list(train_seg1['weekday']))\nin_seq2_s1 = np.array(list(train_seg1['day']))\nin_seq3_s1 = np.array(list(train_seg1['month']))\n#in_seq4_s1 = np.array(list(train_seg1['year']))\nout_seq_s1 = np.array(list(train_seg1['case_count']))\n#in_seq1 = np.array([1,2,3])\n#in_seq2 = np.array([5,6,7])\n#in_seq3 = np.array([8,9,0])\n\nin_seq1_s1 = in_seq1_s1.reshape((len(in_seq1_s1), 1))\nin_seq2_s1 = in_seq2_s1.reshape((len(in_seq2_s1), 1))\nin_seq3_s1 = in_seq3_s1.reshape((len(in_seq3_s1), 1))\n#in_seq4_s1 = in_seq4_s1.reshape((len(in_seq4_s1), 1))\nout_seq_s1 = out_seq_s1.reshape((len(out_seq_s1), 1))\n\n#dataset_s1 = np.hstack((in_seq1_s1, in_seq2_s1, in_seq3_s1,in_seq4_s1,out_seq_s1))\ndataset_s1 = np.hstack((in_seq1_s1, in_seq2_s1, in_seq3_s1,out_seq_s1))\nn_steps = 10\n# convert into input\/output\nX_s1, y_s1 = split_sequences(dataset_s1, n_steps)\n\n","3f511f72":"in_seq1_s2 = np.array(list(train_seg2['weekday']))\nin_seq2_s2 = np.array(list(train_seg2['day']))\nin_seq3_s2 = np.array(list(train_seg2['month']))\n#in_seq4_s2 = np.array(list(train_seg2['year']))\nout_seq_s2 = np.array(list(train_seg2['case_count']))\n#in_seq1 = np.array([1,2,3])\n#in_seq2 = np.array([5,6,7])\n#in_seq3 = np.array([8,9,0])\n\nin_seq1_s2 = in_seq1_s2.reshape((len(in_seq1_s2), 1))\nin_seq2_s2 = in_seq2_s2.reshape((len(in_seq2_s2), 1))\nin_seq3_s2 = in_seq3_s2.reshape((len(in_seq3_s2), 1))\n#in_seq4_s2 = in_seq4_s2.reshape((len(in_seq4_s2), 1))\nout_seq_s2 = out_seq_s2.reshape((len(out_seq_s2), 1))\n\n#dataset_s2 = np.hstack((in_seq1_s2, in_seq2_s2, in_seq3_s2,in_seq4_s2,out_seq_s2))\ndataset_s2 = np.hstack((in_seq1_s2, in_seq2_s2, in_seq3_s2,out_seq_s2))\nn_steps = 10\n# convert into input\/output\nX_s2, y_s2 = split_sequences(dataset_s2, n_steps)\n#n_features_s2 = X_s2.shape[2]\n#n_input_s2 = X_s2.shape[1] * X_s2.shape[2]\n#X_s2 = X_s2.reshape((X_s2.shape[0], n_input_s2))\n\n\n","094f021e":"X_s2.shape","1120e1e2":"test_s1 = test[test['segment']==1]\n#x_input_test_s1 = [[x,y,z,z1] for x,y,z,z1 in zip(list(test_s1['weekday']),list(test_s1['day']),list(test_s1['month']),list(test_s1['year']))]\nx_input_test_s1 = [[x,y,z] for x,y,z in zip(list(test_s1['weekday']),list(test_s1['day']),list(test_s1['month']))]\n\ntest_s2 = test[test['segment']==2]\nx_input_test_s2 = [[x,y,z] for x,y,z in zip(list(test_s2['weekday']),list(test_s2['day']),list(test_s2['month']))]","b5608027":"x_input_test_final_s1 = []\ni = 1\nthval = len(x_input_test_s1)-n_steps\n#print(thval)\nfor x in range(len(x_input_test_s1)):\n    #print(thval-x,thval)\n    if (thval-x)<0:\n        #print(x_input_test_final_s1[-1])\n        val = x_input_test_s1[x:x+10] + list([x_input_test_s1[x]])*np.abs(thval-x)\n        x_input_test_final_s1.append(val)\n    else:\n        x_input_test_final_s1.append(x_input_test_s1[x:x+10])     ","384acfb1":"x_input_test_final_s1[-3]","c673cb86":"len(x_input_test_final_s1[-1])","0808f014":"x_input_test_final_s2 = []\ni = 1\nthval = len(x_input_test_s2)-n_steps\n#print(thval)\nfor x in range(len(x_input_test_s2)):\n    #print(thval-x,thval)\n    if (thval-x)<0:\n        #print(x_input_test_final_s1[-1])\n        val = x_input_test_s2[x:x+10] + list([x_input_test_s2[x]])*np.abs(thval-x)\n        x_input_test_final_s2.append(val)\n    else:\n        x_input_test_final_s2.append(x_input_test_s2[x:x+10])     ","17c0c891":"print(X_s1.shape, y_s1.shape)\n# summarize the data\nfor i in range(len(X_s1)):\n    print(X_s1[i], y_s1[i])","f187fce2":"print(X_s2.shape, y_s2.shape)\n# summarize the data\nfor i in range(len(X_s2)):\n    print(X_s2[i], y_s2[i])","acafcc40":"train_seg2.tail()","883a699b":"#n_features_s1,n_features_s2","913ec2bf":"n_features_s1 = X_s1.shape[2]\n#n_input_s1 = X_s1.shape[1] * X_s1.shape[2]\n#X_s1 = X_s1.reshape((X_s1.shape[0], n_input_s1))\n\nmodel = tf.keras.Sequential()\n#model.add(tf.keras.layers.Dense(100, activation='relu', input_dim=n_input_s1))\n#model.add(tf.keras.layers.Dense(1))\n#model.add(tf.keras.layers.GRU(20, return_sequences=True))\nmodel.add(tf.keras.layers.LSTM(100, activation='relu', return_sequences=True,input_shape=(n_steps, n_features_s1)))\n#model.add(tf.keras.layers.Dense(30,  activation='relu'))\n#model.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.LSTM(50, activation='relu'))\n#model.add(tf.keras.layers.Dropout(0.5))\n#model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1)))\n#model.add(tf.keras.layers.LSTM(25, activation='tanh'))\nmodel.add(tf.keras.layers.Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.fit(X_s1, y_s1, epochs=1000,verbose=0)","60a507ec":"results_s1 = []\nfor input_val in x_input_test_final_s1:\n    val = np.array(input_val)\n    yhat = val.reshape((1, n_steps, n_features_s1))\n    #yhat = val.reshape((1, n_input_s1))\n    yhat = model.predict(yhat)\n    results_s1.append(yhat[0][0])","0e43208c":"results_s1","94534c69":"train_seg1.tail(25)","44152081":"x_input_test_final_s1","0d54f6f9":"n_features_s2 = X_s2.shape[2]\n#n_input_s1 = X_s1.shape[1] * X_s1.shape[2]\n#X_s1 = X_s1.reshape((X_s1.shape[0], n_input_s1))\n\nmodel_s2 = tf.keras.Sequential()\n#model.add(tf.keras.layers.Dense(100, activation='relu', input_dim=n_input_s1))\n#model.add(tf.keras.layers.Dense(1))\n#model.add(tf.keras.layers.GRU(20, return_sequences=True))\nmodel_s2.add(tf.keras.layers.LSTM(100, activation='relu',return_sequences=True, input_shape=(n_steps, n_features_s2)))\n#model_s2.add(tf.keras.layers.Dense(30,  activation='relu'))\n#model_s2.add(tf.keras.layers.Dropout(0.5))\nmodel_s2.add(tf.keras.layers.LSTM(50, activation='relu'))\n#model_s2.add(tf.keras.layers.Dropout(0.5))\n#model_s2.add(tf.keras.layers.LSTM(50, activation='tanh',return_sequences=True, input_shape=(n_steps, n_features_s2)))\n#model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1)))\n#model_s2.add(tf.keras.layers.LSTM(25, activation='tanh'))\nmodel_s2.add(tf.keras.layers.Dense(1))\nmodel_s2.compile(optimizer='adam', loss='mse')\n\nmodel_s2.fit(X_s2, y_s2, epochs=1000,verbose=0)","3637dc72":"x_input = np.array([[ 5,  6,  7],[ 6,  7,  7],[ 0,  8,  7]])","0cff2a05":"results_s2 = []\nfor input_val in x_input_test_final_s2:\n    val = np.array(input_val)\n    yhat = val.reshape((1, n_steps, n_features_s2))\n    #yhat = val.reshape((1, n_input_s2))\n    yhat = model_s2.predict(yhat)\n    results_s2.append(yhat[0][0])","258085ea":"results_s2","d1bca1b5":"x_input_test_final_s2","c7f53594":"train_seg2.tail(45)","5eaad1ff":"test_s1['case_count']= results_s1\ntest_s2['case_count']= results_s2\nsubmission = pd.concat([test_s1,test_s2])","8f7c82a7":"submission = submission.reset_index().sort_values('id')[['id','application_date','segment','case_count']]\nsubmission.head()","8068fe78":"submission.to_csv('submission.csv',index=False)","0600011b":"submission.shape","d406eed6":"# Time series forecasting"}}