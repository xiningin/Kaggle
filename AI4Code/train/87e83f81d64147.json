{"cell_type":{"6d59a0ab":"code","480f1979":"code","8c2ff3e1":"code","c22cf3e1":"code","375500a2":"code","b97e7e6b":"code","f275cdb2":"code","9ef46c8c":"code","984f3836":"code","db0c8e87":"code","7045ae2c":"code","4735fe56":"code","5a6d1801":"code","0edf51e0":"code","5f3823ae":"code","359d34c0":"code","c800b515":"code","10e7a39f":"code","95b15bc8":"code","f2273ffc":"code","09d41afe":"code","4455e6fc":"code","b8a59d75":"code","0cf8e3d6":"code","0bba2941":"code","273e8a37":"code","d8a587b4":"code","438954db":"code","5024362f":"code","70370aa8":"code","c3427744":"code","41be45d3":"code","ed98e80f":"code","54922b17":"code","5fbbb2f8":"code","3d214586":"code","bdec30f8":"code","0dfcee0b":"code","87b01efd":"code","79d60199":"code","f61c08a1":"code","fbedea2c":"code","69643b8c":"code","fe3e7d78":"code","ca42b512":"code","35aa33ff":"code","cc9b146f":"code","19524a55":"markdown","fa7e6051":"markdown","6d2f1c65":"markdown","2455ca5c":"markdown","640e0c37":"markdown","1023a827":"markdown","5641417f":"markdown","369d2ec0":"markdown","1cd4551e":"markdown","ccdae7e7":"markdown","31a462e3":"markdown","0eeccb17":"markdown","139ac59f":"markdown","a843206c":"markdown","a30aae47":"markdown","ef06f5dc":"markdown","26a4b7ad":"markdown","c08a34f7":"markdown","1cc94cee":"markdown","203727b5":"markdown","57798cb1":"markdown","2e0f3c77":"markdown","f9f140d6":"markdown","15ca5791":"markdown","9227d923":"markdown","66024ed4":"markdown","5e379a25":"markdown","fa4c69e5":"markdown","adca251b":"markdown","508f0432":"markdown","cf22c1b9":"markdown","d4a55aa4":"markdown","7f84a353":"markdown","01f4137a":"markdown"},"source":{"6d59a0ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","480f1979":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ncombine = [train,test]","8c2ff3e1":"print(train.info())\nprint('_'*40)\nprint(test.info())","c22cf3e1":"train.describe()","375500a2":"train.describe(include=['O'])","b97e7e6b":"round(train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending = False),2)","f275cdb2":"round(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending = False),2)","9ef46c8c":"round(train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending = False),2)","984f3836":"round(train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending = False),2)","db0c8e87":"train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending = False)","7045ae2c":"train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending = False)","4735fe56":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist,'Age', bins=40)","5a6d1801":"g = sns.FacetGrid(train, col='Pclass', hue='Survived')\n#g = sns.FacetGrid(train, col='Survived', row='Pclass')\ng.map(plt.hist, 'Age', alpha=.5,bins=20)\ng.add_legend()","0edf51e0":"g = sns.FacetGrid(train, col='Survived', hue='Pclass')\ng.map(plt.hist, 'Age', alpha=.5,bins=20)\ng.add_legend()","5f3823ae":"g = sns.FacetGrid(train, col='Embarked')\n#g = sns.FacetGrid(train, row='Embarked', size=2.5,aspect=2)\ng.map(sns.pointplot, 'Pclass','Survived','Sex',palette='deep')\ng.add_legend()","359d34c0":"g = sns.FacetGrid(train, col='Embarked')\ng.map(sns.pointplot, 'Sex','Survived','Pclass',palette='deep')\ng.add_legend()","c800b515":"g = sns.FacetGrid(train, col='Embarked', hue='Survived', palette={0: 'yellow', 1: 'red'})\n#g = sns.FacetGrid(train, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ng.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ng.add_legend()","10e7a39f":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","95b15bc8":"pd.crosstab(test['Title'], test['Sex'])","f2273ffc":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Capt','Col','Countess','Don','Jonkheer','Lady',\n                                          'Major','Rev','Dr','Sir','Dona'],'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle','Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms','Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme','Mrs')\n    \nround(train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean(),2)","09d41afe":"title_mapping = {'Mrs':1, 'Miss':2, 'Master':3, 'Mr':4, 'Rare':5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title']","4455e6fc":"train.info()","b8a59d75":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female':1, 'male':0})\n\ntrain.head()","0cf8e3d6":"train_df = train.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test.drop(['Name', 'PassengerId'], axis=1)\ncombine_df = [train_df,test_df]","0bba2941":"g = sns.FacetGrid(train_df, row='Pclass',col='Sex', size=3, aspect=1.6)\ng.map(plt.hist, 'Age', bins=20)","273e8a37":"age_guess = np.zeros((2,3))\n\nfor dataset in combine_df:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            guess_age = guess.median()\n\n            # Convert random age float to nearest .5 age\n            age_guess[i,j] = int( guess_age\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = age_guess[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)","d8a587b4":"freq_emb = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine_df:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_emb)","438954db":"train_df[['Survived','Embarked']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","5024362f":"for dataset in combine_df:\n    dataset.Embarked=dataset.Embarked.map({'C':1, 'Q':2, 'S':3}).astype(int)\n\ntrain_df.head()","70370aa8":"train_df.info()\nprint(\"-\"*40)\ntest_df.info()","c3427744":"test_df.Fare.fillna(test_df.Fare.dropna().median(),inplace=True)\ntest_df.info()","41be45d3":"train_df = train_df.drop(['Ticket','Cabin'],axis=1)\ntest_df = test_df.drop(['Ticket','Cabin'],axis=1)","ed98e80f":"# Split train data into validation and training data\nfrom sklearn.model_selection import train_test_split\n\nX_train_all = train_df.drop('Survived', axis=1)\nY_train_all = train_df.Survived\nX_test = test_df.copy()\n\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train_all, Y_train_all,random_state=1, test_size=0.2)\nX_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape","54922b17":"# Logistic Regression\nfrom sklearn.metrics import f1_score\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_val)\nlog_score = logreg.score(X_val,Y_val)\nlog_score, f1_score(Y_val, Y_pred, average='binary') ","5fbbb2f8":"coef = pd.DataFrame(train_df.columns.delete(0))\ncoef.columns = ['Feature']\ncoef['Coefficient'] = pd.Series(logreg.coef_[0])\ncoef.sort_values(by='Coefficient', ascending=False)","3d214586":"# Support Vector Machine\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_val)\nsvc_score = svc.score(X_val,Y_val)\nsvc_score, f1_score(Y_val, Y_pred, average='binary') ","bdec30f8":"# k-Nearest Neighbors\n\nknn = KNeighborsClassifier()\nknn.fit(X_train,Y_train)\nY_pred = knn.predict(X_val)\nknn_score = knn.score(X_train, Y_train)\nknn_score, f1_score(Y_val, Y_pred, average='binary')","0dfcee0b":"# Gaussian Naive Bayes\n\ngnb = GaussianNB()\ngnb.fit(X_train,Y_train)\nY_pred = gnb.predict(X_val)\ngnb_score = gnb.score(X_val, Y_val)\ngnb_score, f1_score(Y_val, Y_pred, average='binary')","87b01efd":"# Perceptron\n\nperc = Perceptron()\nperc.fit(X_train,Y_train)\nY_pred = perc.predict(X_val)\nperc_score = perc.score(X_val, Y_val)\nperc_score, f1_score(Y_val, Y_pred, average='binary')","79d60199":"# Linear SVC\n\nlsvc = LinearSVC()\nlsvc.fit(X_train,Y_train)\nY_pred = lsvc.predict(X_val)\nlsvc_score = lsvc.score(X_val, Y_val)\nlsvc_score, f1_score(Y_val, Y_pred, average='binary')","f61c08a1":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train,Y_train)\nY_pred = sgd.predict(X_val)\nsgd_score = sgd.score(X_val, Y_val)\nsgd_score, f1_score(Y_val, Y_pred, average='binary')","fbedea2c":"# Decision Tree\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train,Y_train)\nY_pred = dt.predict(X_val)\ndt_score = round(dt.score(X_val, Y_val),4)\ndt_score, f1_score(Y_val, Y_pred, average='binary')","69643b8c":"# Random Forest\n\nrf = RandomForestClassifier()\nrf.fit(X_train,Y_train)\nY_pred = rf.predict(X_val)\nrf_score = round(rf.score(X_val, Y_val),4)\nrf_score, f1_score(Y_val, Y_pred, average='binary')","fe3e7d78":"# Random Forest n_estimators=100\n\nrf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_train,Y_train)\nY_pred = rf.predict(X_val)\nrf_score = round(rf.score(X_val, Y_val),4)\nrf_score, f1_score(Y_val, Y_pred, average='binary')","ca42b512":"# #XGBoost\n\nfrom xgboost import XGBClassifier\nxgbr = XGBClassifier(n_estimators=1000, learn_rate=0.05, random_state=1)\nxgbr.fit(X_train,Y_train)\nY_pred = xgbr.predict(X_val)\nxgbr_score = round(xgbr.score(X_val, Y_val),4)\nxgbr_score, f1_score(Y_val, Y_pred, average='binary')","35aa33ff":"model = LogisticRegression()\nmodel.fit(X_train_all,Y_train_all)\npred = model.predict(X_test)","cc9b146f":"output = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': pred\n})\n\noutput.to_csv('submission1.1.csv', index=False)","19524a55":"# 'Normalise' titles","fa7e6051":"Explore correlations between Survived and categrical features: Pclass","6d2f1c65":"# k-Nearest Neighbors","2455ca5c":"# Quantify categorical features: \nName: extraxt titles and quanitfy","640e0c37":"# Models \nPrepare training and test data.","1023a827":"# Farebands instead of fare?","5641417f":"Drop Cabin feature","369d2ec0":"Quantify the categorical features: Sex","1cd4551e":"# Decision Tree","ccdae7e7":"Explore correlations between Survived and categrical features: Age","31a462e3":"Fill the single missing value in Fare feature in the test dataset with the most common occurance","0eeccb17":"# Gaussian Naive Bayes","139ac59f":"Quantify the categorical features: title","a843206c":"Correlating Pclass and Age ","a30aae47":"# Support Vector Machines","ef06f5dc":"# Logistic Regression","26a4b7ad":"Explore correlations between Survived and categrical features: Sex","c08a34f7":"# Perceptron","1cc94cee":"Select model and make prediction: Random Forest is selected\n","203727b5":"Correlating Embarked, Fare, Sex and Survived","57798cb1":"Explore correlations between Survived and categrical features: SibSp","2e0f3c77":"# Linear SVC","f9f140d6":"# Explore correlations between Survived and categrical features: Parch","15ca5791":"Quantify Embarked feature","9227d923":"Correlating Embarked, Pclass, Sex and Survived","66024ed4":"# Random Forest","5e379a25":"# Key info:\n1. Survival rate is 32.46%\n\n# List assumptions about the features and relationships.\n1.\n2.\n3...","fa4c69e5":"# Stochastic Gradient Descent","adca251b":"Age: guessing age values  using other corelated feaatures.","508f0432":"Explore correlations between Survived and categrical features: Embarked","cf22c1b9":"Embarked: fill the two missing values with the most common occurance.","d4a55aa4":"## Handling missimg values.","7f84a353":"# Coefficient of the features","01f4137a":"Create a copy of the data, and drop Name and PassngerID columns."}}