{"cell_type":{"072816dc":"code","9779be7e":"code","4b04c55a":"code","e9be88f2":"code","71274040":"code","8aac8d20":"code","f8923514":"code","1a19256b":"code","eb853b34":"code","5548f29b":"code","107e9b9e":"code","2f9d9749":"code","0c558250":"code","953a3408":"code","5178023d":"code","3596f497":"code","10b409ae":"code","136aad04":"code","12dcad8b":"code","4a76c2c7":"code","0a88f9b9":"code","9b933399":"code","e0025ff0":"code","59661583":"code","e3ebca61":"markdown","826b7d05":"markdown","d2951e84":"markdown","a23c294b":"markdown","4ca2f636":"markdown"},"source":{"072816dc":"# read data\nimport pandas as pd\n\ntrain_data=pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data=pd.read_csv('..\/input\/titanic\/test.csv')\n","9779be7e":"# take a look at train data \ntrain_data.head()","4b04c55a":"#take a look at test data\ntest_data.head()","e9be88f2":"import seaborn as sns\nimport matplotlib.pyplot as plt","71274040":"#first to take a visual of null data\n\nsns.heatmap(train_data.isnull())","8aac8d20":"train_data.info()","f8923514":"#view some relationships between the data\nplt.figure(figsize=(14,7))\n#plt.set_title(\"Pclass vs survived\")\nsns.scatterplot(y=train_data.Pclass,x=train_data.PassengerId,hue=train_data.Survived)\n#as we likely to see people with lower Pclass is likely to survive","1a19256b":"sns.lmplot(data=train_data,x='PassengerId',y='Fare',hue='Survived',)\n#here the regression line says people who paid more price has slightly more chances to survived then the people who paid less","eb853b34":"train_data[['Sex','Survived']].groupby('Sex',as_index=False).mean()\n#females as more likely to survive than males ","5548f29b":"train_data[['Embarked','Survived']].groupby('Embarked',as_index=False).mean()\n# C are more likely to survie than Q and S","107e9b9e":"sns.lmplot(data=train_data,x='PassengerId',y='Age',hue='Survived',)\n#by regression line we can see that the age shows a deflection in surviaval rate initially ,\n#but later on it just equals to the regression line of those who lost their lives\n#we can say age is also use to determined the survival rate","2f9d9749":"train_data[['Survived','SibSp']].groupby('SibSp',as_index=False).mean()\n# clearly survival rate is well dependent on no of siblings board on the ship","0c558250":"sns.lmplot(data=train_data,x='PassengerId',y='SibSp',hue='Survived',)\n# we can say is someone has 1 or 2 sibling there is better chance of surviving","953a3408":"train_data[['Parch','Survived']].groupby('Parch').mean()","5178023d":"cols_to_be_dropped=['Cabin','Ticket','Name']\n#cabin is discarded as we dont have too much data in it .. nearly 80% of data is missing refilling the data can lead to mislead \n#accruacy of the model\n# Ticket is discarded as the survival rate cant be dependent upon ticket no\n# Name of a person is Discarded as it also cant be the deciding factor in the survival .","3596f497":"# dropped the column that decided to be dropped after the visualisation\ntrain_data.drop(cols_to_be_dropped,axis=1,inplace=True)\ntest_data.drop(cols_to_be_dropped,axis=1,inplace=True)","10b409ae":"# import the things needed for the data cleaning\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# find out the numerical columns in the data\ny=train_data.Survived\nX=train_data.drop('Survived',axis=1)\n\nnumerical_column=[col for col in X.columns if X[col].dtype in ['int64','float64']]\n\n#find the categorical column in the data\ncategorical_column=list(set(X.columns)-set(numerical_column))\nprint(\"Numerical columns\",numerical_column,'\\n','Categorical columns',categorical_column)","136aad04":"from sklearn.ensemble import RandomForestClassifier\n# use to predict based upon the classes\n\nfrom sklearn.model_selection import train_test_split\n# use to split the data to validate\n\nfrom sklearn.model_selection import cross_val_score\n# check the validation score","12dcad8b":"y=train_data.Survived\n#set the target\n\nX=train_data.drop('Survived',axis=1)\n#set the features of the model\n\ntrain_X,valid_X,train_y,valid_y=train_test_split(X,y,random_state=42,test_size=0.33)\n#split the data ","4a76c2c7":"# Function to get the cross validation accuracy\ndef get_cross_val_score(n,X,y):\n    #n is number of estimators that a model should take \n    # X is the features \n    # y is the set target\n    \n    # numerical preprocessors with strategy mean\n    numerical_preprocess=SimpleImputer(strategy='mean')\n    \n    # categorical preprocessor { we can choose to use label encode on SEX but it cant be considered that what is more significiant\n    # male or female , same apply for Embarked}\n    # there is no data leakage {Target leakage and train test combination leakage}\n    categorical_preprocess=Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent')),\n                                      ('HotEncoder',OneHotEncoder())])\n    \n    # not use columntransformer to transform column and create parent preprocessor\n    preprocessor=ColumnTransformer([('numerical',numerical_preprocess,numerical_column),\n                            ('categorical',categorical_preprocess,categorical_column)])\n    \n    #finally create a pipeline that do the automated task for you\n    global final_pipeline\n    final_pipeline=Pipeline(steps=[('preprocessor',preprocessor),('model',RandomForestClassifier(n_estimators=n,random_state=0))])\n    \n    #return the cross validation score \n    # we only take 5 fold of the traninng data\n    # and doing it in this way help us to make a better model in terms of accuracy \n    # increase and decrease the cross validation folds to maximize accuracy\n    return cross_val_score(final_pipeline,X,y,cv=5,scoring='accuracy').mean()","0a88f9b9":"# for checking what is the best number of n_estimators that can predict the best\n#for i in range(400,500,10):\n#    print(get_cross_val_score(i,train_X,train_y,valid_X,valid_y))","9b933399":"print(\"The cross validation score for 400 estimators is \",get_cross_val_score(400,X,y))\n# get the cross validation score","e0025ff0":"#train the model on training set\nfinal_pipeline.fit(X,y)\n# make predictions using the pipeline\n# on checking we found out that the model have 87% accuracy on test set \ntest_preds=final_pipeline.predict(test_data)\n\n#setting the data to submit the file\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                       'Survived': test_preds})\noutput","59661583":"# making the submission\noutput.to_csv('submission.csv', index=False)","e3ebca61":"# Predictions","826b7d05":"# Cleaning of Data","d2951e84":"# Titanic Competition ","a23c294b":"# Visualization of data","4ca2f636":"# Model"}}