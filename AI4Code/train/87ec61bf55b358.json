{"cell_type":{"ba0130e0":"code","75959817":"code","4690dc36":"code","965ab74f":"code","da0af8af":"code","692ff8cf":"code","e0cb4a6b":"code","8df40f5f":"code","60d07208":"code","acd988a0":"code","cfeadd2d":"code","d6bcb923":"code","1bd7c0c9":"code","482ccc06":"markdown","1e399fb4":"markdown","891bdc44":"markdown","d1eb943a":"markdown","5277494e":"markdown","03d28da3":"markdown","46a7d32e":"markdown","0438c75f":"markdown","984c02d6":"markdown"},"source":{"ba0130e0":"import pandas as pd\nimport numpy as np\nfrom keras.layers import Activation, Dense, Dropout\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\n%pylab inline","75959817":"# load training data\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","4690dc36":"# check shape of training data\ntrain.shape # (42000, 785)\n\n# Dividing dataset into training and CV data using (80:20) ratio\nnum_train = int(0.8 * train.shape[0])\nX = (train.iloc[:num_train, 1:]).values # first 80% examples\nX_cv = (train.iloc[num_train:, 1:]).values # rest examples\n\n# observing the dataset\nprint(X.shape)\nprint(X)","965ab74f":"# get labels from 1st column of each row\nlabels = train.iloc[:, 0].values\n\n# encoding for training data\ny = np.zeros((num_train, 10))\nfor i in range(num_train):\n    y[i][labels[i]] = 1;\n\nnum_cv = train.shape[0] - num_train\n# encoding for cv data\ny_cv = np.zeros((num_cv, 10))\nfor i in range(num_cv):\n    y_cv[i][labels[num_train + i]] = 1\n    \n# training labels\nprint(y)\n\nprint(\"---------------------------------------------\")\n\n# cv labels\nprint(y_cv)","da0af8af":"model = Sequential([\n    # input layer\n    Dense(32, input_dim=784),\n    Activation('sigmoid'),\n    Dropout(0.25), # 25% dropout rate to prevent overfitting\n    # hidden layer\n    Dense(32),\n    Activation('sigmoid'),\n    Dropout(0.25),\n     # hidden layer\n    Dense(32),\n    Activation('sigmoid'),\n    Dropout(0.25),\n     # hidden layer\n    Dense(32),\n    Activation('sigmoid'),\n    Dropout(0.25),\n    # output layer (10 nodes)\n    Dense(10),\n    Activation('sigmoid'),\n])","692ff8cf":"# compiling model\nmodel.compile(optimizer = 'adadelta',\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])","e0cb4a6b":"# training the model\nhist = model.fit(X, y, epochs = 50, batch_size = 32, verbose = 0)\nprint('done')","8df40f5f":"score = model.evaluate(X_cv,y_cv,batch_size = 32, verbose = 0)\nprint(score)","60d07208":"info = hist.history\nplt.plot(info['loss'])","acd988a0":"yPred = model.predict_classes(test)\nprint(yPred)","cfeadd2d":"np.savetxt('submission.csv', np.c_[range(1, len(yPred) + 1), yPred], delimiter=',', header='ImageId,Label', comments='', fmt='%d')","d6bcb923":"! ls","1bd7c0c9":"sample = pd.read_csv('..\/input\/sample_submission.csv')\nsample","482ccc06":"## Saving the predictions as a CSV file","1e399fb4":"## Load training and test data","891bdc44":"## Creating the Neural Network using Keras","d1eb943a":"## Predicting from the test data","5277494e":"## Plotting the cost function","03d28da3":"## Compiling and training the model to verify tests","46a7d32e":"## Evaluating model on Cross validation set","0438c75f":"It is clearly visible that the first column of each row contains the label, so we seperate it out, and then perform **One-hot encoding**","984c02d6":"Split training data into training data and cross validation data"}}