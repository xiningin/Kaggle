{"cell_type":{"fc9ea7c5":"code","2c595a79":"code","36be7ba0":"code","fc38193d":"code","9e4ff097":"code","d03fda86":"code","28bc3c88":"code","9ac2cf6b":"code","023cae09":"code","6563448b":"code","557bd104":"code","56b04726":"code","9223360d":"code","f81e69a7":"code","05771ae4":"code","a8c98ea9":"code","ed3cd943":"code","d096f36a":"markdown","21e6e030":"markdown","6bb068aa":"markdown","4426fd4f":"markdown","15998c6c":"markdown","b32f5626":"markdown"},"source":{"fc9ea7c5":"import gc\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom scipy.stats import skew\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import QuantileTransformer\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import VotingClassifier","2c595a79":"train_df = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntrain_df.set_index('id', inplace=True)\nprint(f\"train_df: {train_df.shape}\")\ntrain_df.head()","36be7ba0":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\ntest_df.set_index('id', inplace=True)\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","fc38193d":"features = test_df.columns.tolist()\n\ntrain_df['num_missing'] = train_df[features].isna().sum(axis=1)\ntrain_df['num_missing_std'] = train_df[features].isna().std(axis=1).astype('float')\ntrain_df['median'] = train_df[features].median(axis=1)\ntrain_df['std'] = train_df[features].std(axis=1)\ntrain_df['min'] = train_df[features].abs().min(axis=1)\ntrain_df['max'] = train_df[features].abs().max(axis=1)\ntrain_df['sem'] = train_df[features].sem(axis=1)\n\ntest_df['num_missing'] = test_df[features].isna().sum(axis=1)\ntest_df['num_missing_std'] = test_df[features].isna().std(axis=1).astype('float')\ntest_df['median'] = test_df[features].median(axis=1)\ntest_df['std'] = test_df[features].std(axis=1)\ntest_df['min'] = test_df[features].abs().min(axis=1)\ntest_df['max'] = test_df[features].abs().max(axis=1)\ntest_df['sem'] = test_df[features].sem(axis=1)\n\nprint(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")\ntrain_df.head()","9e4ff097":"dataframe = pd.DataFrame(train_df.groupby(['num_missing'])['claim'].mean())\ndataframe['non-claim'] = 1 - dataframe['claim']\ndataframe['ratio'] = np.log(dataframe['claim'] \/ dataframe['non-claim'])\nratio_mapping = dataframe['ratio'].to_dict()\n\ntrain_df['woe'] = train_df['num_missing'].map(ratio_mapping)\ntest_df['woe'] = test_df['num_missing'].map(ratio_mapping)\ntest_df.fillna(-1, inplace=True)\nprint(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")\n\ndel dataframe\ngc.collect()","d03fda86":"skewed_feat = train_df[features].skew()\nskewed_feat = [*skewed_feat[abs(skewed_feat.values) > 1].index]\n\nfor feat in tqdm(skewed_feat):\n    median = train_df[feat].median()\n    train_df[feat] = train_df[feat].fillna(median)\n    test_df[feat] = test_df[feat].fillna(median)","28bc3c88":"rest_cols = [col for col in features if col not in skewed_feat]\n\nfor feat in tqdm(rest_cols):\n    mean = train_df[feat].mean()\n    train_df[feat] = train_df[feat].fillna(mean)\n    test_df[feat] = test_df[feat].fillna(mean)","9ac2cf6b":"features = [col for col in train_df.columns if col not in ['num_missing','num_missing_std','claim']]\n\nfor col in tqdm(features):\n    transformer = QuantileTransformer(n_quantiles=5000, \n                                      random_state=42, \n                                      output_distribution=\"normal\")\n    \n    vec_len = len(train_df[col].values)\n    vec_len_test = len(test_df[col].values)\n\n    raw_vec = train_df[col].values.reshape(vec_len, 1)\n    test_vec = test_df[col].values.reshape(vec_len_test, 1)\n    transformer.fit(raw_vec)\n    \n    train_df[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_df[col] = transformer.transform(test_vec).reshape(1, vec_len_test)[0]\n\nprint(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")","023cae09":"def kmeans_fet(train, test, features, n_clusters):\n    \n    train_ = train[features].copy()\n    test_ = test[features].copy()\n    data = pd.concat([train_, test_], axis=0)\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(data)\n    \n    train[f'clusters_k'] = kmeans.labels_[:train.shape[0]]\n    test[f'clusters_k'] = kmeans.labels_[train.shape[0]:]\n    return train, test","6563448b":"train_df, test_df = kmeans_fet(train_df, test_df, features, n_clusters=4)\n\nXtrain = train_df.loc[:, train_df.columns != 'claim'].copy()\nYtrain = train_df['claim'].copy()\nXtest = test_df.copy()\n\nprint(f\"Xtrain: {Xtrain.shape} \\nYtrain: {Ytrain.shape} \\nXtest: {Xtest.shape}\")\n\ndel train_df\ndel test_df\ngc.collect()","557bd104":"lgb_params1 = {\n    'metric' : 'auc',\n    'objective' : 'binary',\n    'n_estimators': 10000, \n    'learning_rate': 0.0223, \n    'importance_type': 'gain',\n    'min_child_weight': 256,\n    'min_child_samples': 20, \n    'reg_alpha': 10, \n    'reg_lambda': 0.1, \n    'subsample': 0.6, \n    'subsample_freq': 1, \n    'colsample_bytree': 0.4\n}\n\nlgb_params2 = {\n    'metric' : 'auc',\n    'objective' : 'binary',\n    'n_estimators' : 5000,\n    'learning_rate' : 0.095,\n    'importance_type': 'gain',\n    'max_depth' : 3,\n    'num_leaves' : 7,\n    'reg_alpha' : 18,\n    'reg_lambda' : 17,\n    'colsample_bytree' : 0.3,\n    'subsample' : 0.5\n}\n\nlgb_params3 = {\n    'metric' : 'auc',\n    'objective' : 'binary',\n    'n_estimators': 10000, \n    'learning_rate': 0.12230165751633416, \n    'importance_type': 'gain',\n    'num_leaves': 1400, \n    'max_depth': 8, \n    'min_child_samples': 3100, \n    'reg_alpha': 10, \n    'reg_lambda': 65, \n    'min_split_gain': 5.157818977461183, \n    'subsample': 0.5, \n    'subsample_freq': 1, \n    'colsample_bytree': 0.2\n}\n\nxgb_params1 = {\n    'eval_metric': 'auc', \n    'objective': 'binary:logistic', \n    'tree_method': 'hist', \n    'use_label_encoder': False,\n    'n_estimators': 10000, \n    'learning_rate': 0.01063045229441343, \n    'gamma': 0.24652519525750877, \n    'max_depth': 4, \n    'min_child_weight': 366, \n    'subsample': 0.6423040816299684, \n    'colsample_bytree': 0.7751264493218339, \n    'colsample_bylevel': 0.8675692743597421, \n    'lambda': 0, \n    'alpha': 10\n}\n\nxgb_params2 = {\n    'eval_metric': 'auc',\n    'objective': 'binary:logistic',\n    'tree_method': 'hist',\n    'use_label_encoder': False,\n    'n_estimators': 10000,\n    'learning_rate': 0.01187431306013263,\n    'max_depth': 3,\n    'subsample': 0.5,\n    'colsample_bytree': 0.5,\n    'n_jobs': -1\n}","56b04726":"estimators=[\n    ('lgb11', LGBMClassifier(**lgb_params1, random_state=17)), \n    ('lgb12', LGBMClassifier(**lgb_params1, random_state=23)), \n    ('lgb21', LGBMClassifier(**lgb_params2, random_state=31)), \n    ('lgb22', LGBMClassifier(**lgb_params2, random_state=37)),\n    ('lgb31', LGBMClassifier(**lgb_params3, random_state=7)),\n    ('lgb32', LGBMClassifier(**lgb_params3, random_state=11)),\n    ('xgb11', XGBClassifier(**xgb_params1, random_state=41)),\n    ('xgb12', XGBClassifier(**xgb_params1, random_state=47)),\n    ('xgb13', XGBClassifier(**xgb_params1, random_state=61)),\n    ('xgb21', XGBClassifier(**xgb_params2, random_state=53)),\n    ('xgb22', XGBClassifier(**xgb_params2, random_state=59)),\n    ('xgb23', XGBClassifier(**xgb_params2, random_state=67))\n]","9223360d":"model = VotingClassifier(estimators=estimators, \n                         voting='soft', \n                         verbose=True)\nmodel.fit(Xtrain, Ytrain)","f81e69a7":"y_pred = model.predict_proba(Xtrain)[:,-1]\nroc_auc_score(Ytrain, y_pred)","05771ae4":"y_pred_final = model.predict_proba(Xtest)[:,-1]","a8c98ea9":"np.savez_compressed('.\/VC_Meta_Features.npz',\n                    y_pred_meta_vc=y_pred, \n                    y_pred_final_vc=y_pred_final)","ed3cd943":"submit_df = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\nsubmit_df['claim'] = y_pred_final\nsubmit_df.to_csv(\"Voting_Submission.csv\", index=False)\nsubmit_df.head(10)","d096f36a":"## Model Hyperparameters","21e6e030":"## Voting Classifier","6bb068aa":"## Create submission files","4426fd4f":"## Import libraries","15998c6c":"## Feature Engineering","b32f5626":"## Load source datasets"}}