{"cell_type":{"05143420":"code","7eb1a7c1":"code","b07ddfe0":"code","1d039fc4":"code","0c7c96f5":"code","77088381":"code","760d9308":"code","a998f922":"code","dc36dfd7":"code","92c69d86":"code","3fc6a7b9":"code","71a6db0e":"code","c2be20d8":"code","bff16bba":"code","f4c47fc3":"code","8c77b25f":"code","21705bba":"code","16305722":"code","233ae14c":"code","ec88c99d":"code","f649b165":"markdown","97f41faa":"markdown","795c9744":"markdown","e4deffb7":"markdown","562a0b55":"markdown","6f317f29":"markdown","8062eae4":"markdown","ef771a45":"markdown"},"source":{"05143420":"import sys\n!cp ..\/input\/rapids\/rapids.0.15.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","7eb1a7c1":"import sys\nimport numpy as np\nimport pandas as pd\nimport gc\nfrom sklearn.metrics import f1_score,roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_absolute_error\nimport cudf\nfrom cuml.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","b07ddfe0":"train_df = pd.read_csv('..\/input\/conways-reverse-game-of-life-2020\/train.csv')\ntest_df = pd.read_csv(\"..\/input\/conways-reverse-game-of-life-2020\/test.csv\")\nprint(train_df.shape)\nprint(test_df.shape)","1d039fc4":"sample_size = 50000\ntrain = train_df.drop([\"id\",'delta'], axis=1)  #Let's drop delta first, And we will use it in the later version.\ntrain_x = train.iloc[:sample_size,625:].astype('int32') #Only use part of data for this demo. For quick update and modify.\ntrain_y = train.iloc[:sample_size,:625].astype('int32')\ntest = test_df.drop([\"id\",'delta'], axis=1)\ntest_x = test.iloc[:,:]","0c7c96f5":"view_size = 1\nsize = 25\n\nown_cell_pos = [[i\/\/25,i%25] for i in range(625)]\nown_cell_pos_rec = [[pos[0] + size, pos[1] + size] for pos in own_cell_pos]\n\n#Get train obs\ntrain_sample = np.array(train_x.iloc[:sample_size,:]).reshape(sample_size,25,25)\ntile_obs_layer = np.tile(train_sample, [1, 3, 3])\nown_cell_obs_layer = [np.sum(np.array([tile_obs_layer[i,pos[0] - view_size: pos[0] + view_size + 1, pos[1] - view_size: pos[1] + view_size + 1] \n                                       for pos in own_cell_pos_rec]).reshape(625,9),axis=1) for i in range(sample_size)]\n\ndeltas = train_df['delta'][:sample_size].values\ndeltas_ = np.array([[delta]*625 for delta in deltas]).reshape(sample_size,625,1)\n\norigin_loc =  train_sample.reshape(sample_size,625,1)\nown_cell_obs_layer =  np.array(own_cell_obs_layer).reshape(sample_size,625,1)\n\ntrain_df = np.concatenate((own_cell_obs_layer,deltas_),axis=2).astype('int32')\ntrain_df = np.concatenate((train_df,origin_loc),axis=2).astype('int32')\nprint('train_set shape',train_df.shape)\ntrain_target = np.array(train_y)\n\n\n#Get test obs\ntest_set = np.array(test_x.iloc[:,:]).reshape(test_x.shape[0],25,25)\norigin_loc =  test_set.reshape(test_x.shape[0],625,1)\n\ntile_obs_layer = np.tile(test_set, [1, 3, 3])\nown_cell_obs_layer = [tile_obs_layer[:,pos[0] - view_size: pos[0] + view_size + 1, pos[1] - view_size: pos[1] + view_size + 1] for pos in own_cell_pos_rec]\nown_cell_obs_layer = [np.sum(np.array([tile_obs_layer[i,pos[0] - view_size: pos[0] + view_size + 1, pos[1] - view_size: pos[1] + view_size + 1] \n                                       for pos in own_cell_pos_rec]).reshape(625,9),axis=1) for i in range(test_x.shape[0])]\ndeltas = test_df['delta'][:].values\ndeltas_ = np.array([[delta]*625 for delta in deltas]).reshape(test_x.shape[0],625,1)\n\nown_cell_obs_layer =np.array(own_cell_obs_layer).reshape(test_x.shape[0],625,1)\ntest_df = np.concatenate((own_cell_obs_layer,deltas_),axis=2).astype('int32')\ntest_df = np.concatenate((test_df,origin_loc),axis=2).astype('int32')\n\nprint('test_set shape',test_df.shape)\n\ndel own_cell_obs_layer,deltas_","77088381":"train_target = train_target.reshape(sample_size,625,1)","760d9308":"#features = ['locate_'+str(c) for c in range(9)] +['delta']+['start']\nfeatures = ['round_num','delta','origin','start']\n\nall_train = np.concatenate((train_df,train_target),axis=2)\n\ntrain_df = pd.DataFrame(all_train.reshape(sample_size*625,4)).astype('float32')\ntrain_df.columns = features\n\ntest_df = pd.DataFrame(test_df.reshape(test_df.shape[0]*625,3)).astype('float32')\ntest_df.columns = features[:-1]\n\n# target_df = pd.DataFrame(train_target.reshape(sample_size*625,1)).astype('float32')\n# target_df.columns = ['stop']\n\npredictions = np.zeros(test_df.shape[0])","a998f922":"train_df.head()","dc36dfd7":"test_df.head()","92c69d86":"Target = 'start'","3fc6a7b9":"features = ['round_num','delta','origin']","71a6db0e":"NUM_FOLDS = 5\nskf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n\ntest_df = cudf.from_pandas(test_df)\n\noof_preds = np.zeros(sample_size*625)\ny_test = np.zeros(test_df.shape[0])\n\nfor fold, (train_ind, val_ind) in enumerate(skf.split(train_df.values, train_df['delta'].values)):\n    \n    tr_df, val_df = train_df.iloc[train_ind], train_df.iloc[val_ind]\n    print('Fold', fold )\n\n    tr_df = cudf.from_pandas( tr_df )\n    val_df   = cudf.from_pandas( val_df )\n\n    model = RandomForestRegressor(\n            n_estimators=35,\n            rows_sample = 0.35,\n            max_depth=18,\n            max_features=\"auto\",        \n            split_algo=0,\n            bootstrap=False, #Don't use repeated rows, this is important to set to False to improve accuracy\n        ).fit( tr_df[features], tr_df[Target])\n        \n    pred = model.predict( val_df[features] ).to_array()\n    oof_preds[val_ind] = pred\n        \n    y_test += model.predict( test_df[features] ).to_array() \/ NUM_FOLDS\n    del model; _=gc.collect()\n    \n#y_test = np.round( y_test )","c2be20d8":"# for i in tqdm(range(95,100)):\n#     threshold = np.percentile(oof_preds,i)\n#     mae_loss = mean_absolute_error(train_df[Target].values, np.array([1 if pred > threshold else 0 for pred in oof_preds]))\n#     if mae_loss<min_mae:\n#         min_mae = mae_loss\n#         min_threshold = threshold\n#         print(i)\n# print('min_mae:',min_mae,'min_threshold:',min_threshold)","bff16bba":"predictions = y_test","f4c47fc3":"threshold = np.percentile(predictions,94)\n\n#result =[1 if pred >  threshold[i%625] else 0 for i,pred in enumerate(predictions)]\nresult = [1 if pred > threshold else 0 for pred in predictions]\nprint(predictions[:10])\nsubmit = pd.read_csv(\"..\/input\/conways-reverse-game-of-life-2020\/sample_submission.csv\")\n\nids = submit.iloc[:,0].values\nids = ids.reshape(ids.shape[0],1)\n\nsub = np.array(predictions).reshape(test_x.shape[0],test_x.shape[1])\nsub = np.hstack((ids,sub))\n\nsubmission = pd.DataFrame(sub)\nsubmission.columns = submit.columns[:]\nsubmission.index = submit.index\n","8c77b25f":"submission.to_csv('submission.csv',index=False)","21705bba":"plt.imshow(submission.iloc[3,1:].values.reshape(25,25)) #predict","16305722":"plt.imshow(test_x.iloc[3,:].values.reshape(25,25)) #origin","233ae14c":"print(submission.iloc[2,1:].values.sum()\/625)\nprint(test_x.iloc[2,:].values.sum()\/625)","ec88c99d":"submission.to_csv('submission.csv',index=False)","f649b165":"## Build the model","97f41faa":"## Get sum of value around each cell","795c9744":"A rough version, welcome to refine it.\n\nAnd it based on [RandomForest on GPU in 3 minutes](https:\/\/www.kaggle.com\/titericz\/randomforest-on-gpu-in-3-minutes)\n\nThanks Chris Deotte for the contribute to RAPIDS.","e4deffb7":"# **The Game of Life**\n\n### Using random_forest model to predict the reverse.\n\n### Thanks for upvote:)","562a0b55":"# Display the result","6f317f29":"![](https:\/\/lh3.googleusercontent.com\/IqAXHpoVZ6FFYuHRatwjmlk-7XaQXqhEE3Bm8x8Qx3tEWZam16cjfYzXJidKi74fmNk)","8062eae4":"## Load dataset","ef771a45":"## Import some library.\n"}}