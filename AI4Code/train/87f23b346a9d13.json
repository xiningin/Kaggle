{"cell_type":{"3814f88a":"code","9d582a25":"code","5734b74a":"code","821a921c":"code","ffd329e6":"code","39cf0672":"code","5c805768":"code","665c7e0c":"code","f39518fb":"code","06a9f1f3":"code","d4b00eed":"code","522ffbab":"code","9cc35a74":"code","b8dc6d91":"code","038b3362":"code","e8b1305d":"code","d96f0bbe":"code","f60405d7":"code","fe7a1dbc":"code","ba7fc448":"code","37c41256":"code","c5b93367":"markdown","930c8b7c":"markdown","5176ab7e":"markdown","a8500d99":"markdown","6e5b3719":"markdown","6b2c2fc3":"markdown","e91e3667":"markdown","97fc4582":"markdown","03b4dd09":"markdown","1b9631de":"markdown","2740f22c":"markdown","185e02f7":"markdown"},"source":{"3814f88a":"import numpy as np\nimport pandas as pd\n\nfrom scipy.stats import skew, boxcox\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder,RobustScaler, PowerTransformer, PolynomialFeatures\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.metrics import mean_squared_error, f1_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","9d582a25":"train = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest  = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\nsub = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv\")","5734b74a":"plt.subplots(figsize=(6,4))\nsns.countplot(x='Survived', data=train)\nplt.title(\"Count of Survival\")\nplt.show()","821a921c":"print(f\"{len(train[train['Survived']==1])\/len(train)}% survived\")","ffd329e6":"train.info()","39cf0672":"with sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(12, 10))\n    ax = sns.heatmap(train[['Survived','Pclass','Age','SibSp','Parch','Fare']].corr(method='spearman'), annot=True, square=True, vmin=-1, vmax=1)#","5c805768":"plt.subplots(figsize=(8,6))\nsns.countplot(x='Survived', data=train, hue='Sex')\nplt.title(\"Impact of Sex on Survival\")\nplt.show()","665c7e0c":"plt.subplots(figsize=(8,6))\nsns.countplot(x='Survived', data=train, hue='Embarked')\nplt.title(\"Impact of Embarked on Survival\")\nplt.show()","f39518fb":"plt.subplots(figsize=(8,6))\nsns.countplot(x='Survived', data=train, hue='Pclass')\nplt.title(\"Impact of Pclass on Survival\")\nplt.show()","06a9f1f3":"y = train.Survived.values\n\ntrain.drop(['Survived','PassengerId'], axis=1, inplace=True)\ntest.drop(['PassengerId'], axis=1, inplace=True)\nprint(f\"train size is : {train.shape}\")\nprint(f\"test size is : {test.shape}\")","d4b00eed":"df_na = (train.isnull().sum() \/ len(train)) * 100\ndf_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' : df_na})\nmissing_data.head(5)","522ffbab":"test.Cabin    = test.Cabin.fillna('0')\ntrain.Cabin   = train.Cabin.fillna('0')\n\ntrain.Ticket  = train.Ticket.fillna(train.Ticket.mode()[0])\ntest.Ticket   = test.Ticket.fillna(test.Ticket.mode()[0])\n\ntrain.Age      = train.Age.fillna(train.Age.median())\ntest.Age       = test.Age.fillna(train.Age.median())\n\ntrain.Embarked = train.Embarked.fillna(train.Embarked.mode()[0])\ntest.Embarked  = test.Embarked.fillna(train.Embarked.mode()[0])\n\ntrain.Fare     = train.Fare.fillna(train.Fare.mean())\ntest.Fare      = test.Fare.fillna(test.Fare.mean())","9cc35a74":"train.isnull().sum()","b8dc6d91":"train['Cabin_'] = train['Cabin'].map(lambda x: x[0].strip())\ntest['Cabin_'] = test['Cabin'].map(lambda x: x[0].strip())\n\ntrain['HasCabin'] = train.Cabin.apply(lambda x: 0 if x=='0' else 1).astype('category')\ntest['HasCabin'] = test.Cabin.apply(lambda x: 0 if x=='0' else 1).astype('category')\n\ntrain['Ticket_'] = train['Ticket'].str.replace('[^\\w\\s]','').replace(' ','').fillna('NA').replace('(\\d)', '', regex=True)\ntest['Ticket_'] = test['Ticket'].str.replace('[^\\w\\s]','').replace(' ','').fillna('NA').replace('(\\d)', '', regex=True)\n\ntrain['FirstName'] = train['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\ntest['FirstName'] = test['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\n\ntrain['IsWoman'] = (train['Sex']=='female').astype('category')\ntest['IsWoman'] = (test['Sex']=='female').astype('category')\n\ntrain['FamilySize'] = train['SibSp'] + train['Parch']\ntest['FamilySize'] = test['SibSp'] + test['Parch']\n\ntrain.drop(['Name','Cabin','Ticket'], axis=1, inplace=True)\ntest.drop(['Name','Cabin','Ticket'], axis=1, inplace=True)","038b3362":"numeric_feats = train.dtypes[(train.dtypes != \"object\") & (train.dtypes != 'category')].index.tolist()\nobject_feats  = train.dtypes[(train.dtypes == \"object\") | (train.dtypes == 'category')].index.tolist()\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nprint(skewness)\n\nfor i in skewness.index:\n    train[i]=np.log1p(train[i])\n    test[i]=np.log1p(test[i])","e8b1305d":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(handle_unknown='ignore'), object_feats),\n        ('num', RobustScaler() , numeric_feats)\n    ])","d96f0bbe":"clf = Pipeline(steps=[\n                    ('pre', preprocessor),\n                    ('a', LogisticRegression(random_state=42)),\n                    ])","f60405d7":"param_grid = {\n    'a__C': list(np.linspace(0.05, 0.07, 20)),\n    'a__max_iter': list(range(40, 120, 10)),\n    'a__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n}","fe7a1dbc":"a = GridSearchCV(clf, param_grid, scoring='accuracy', cv=10).fit(train, y)\na.best_estimator_","ba7fc448":"a.best_estimator_.fit(train, y)\npredictions = a.best_estimator_.predict(test)","37c41256":"sub['Survived'] = predictions\nsub.to_csv('submission.csv',index=False)","c5b93367":"# Feature Engineering","930c8b7c":"# Data pre-processing","5176ab7e":"# Imputing","a8500d99":"Passengers embarked in Q and C in train data survived in larger numbers than those embarked in S.","6e5b3719":"Fare, Age positively correlate with Survival, Pclass - negatively. \n\nInteresting correlation Pclass-Fare, likely meaning higher class number -- lower fare.","6b2c2fc3":"# Modeling","e91e3667":"Female passengers in train data survived in larger numbers than males.","97fc4582":"Pclass 3 has significantly less chances of survival than 1 and 2 passenger classes.","03b4dd09":"# Loading Libraries and Data","1b9631de":"# Related resources \n\nFeatures:\n* https:\/\/www.kaggle.com\/hiro5299834\/tps-apr-2021-single-decisiontreemodel\n* https:\/\/www.kaggle.com\/sociopath00\/random-forest-using-gridsearchcv\n* https:\/\/www.kaggle.com\/dwin183287\/tps-april-2021-models-feature-enginering\n* https:\/\/www.kaggle.com\/hiro5299834\/tps-apr-2021-voting-pseudo-labeling\n\nLogisticRegression tuning:\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html\n* https:\/\/stackoverflow.com\/questions\/21816346\/fine-tuning-parameters-in-logistic-regression\/2181881","2740f22c":"## Impact of categorical features on survival","185e02f7":"# EDA"}}