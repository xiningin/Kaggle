{"cell_type":{"61666b93":"code","2207b7e8":"code","df32b54e":"code","b8684f30":"code","3357c6a6":"code","b337ce02":"code","36fbedc6":"code","a2231c3c":"code","992c3cf2":"code","1080191a":"code","f3aee399":"code","3810965a":"code","8893e450":"code","6e6a2339":"code","8e1415ec":"code","b02ecb76":"code","5eb13254":"code","ba3a14c5":"code","487b7b0a":"code","b8bd23ed":"code","fbdb0a27":"code","e790b068":"code","2fe7348f":"code","8e1a4c00":"code","43070e44":"code","3eaaf8e6":"code","f69ea4f9":"code","77cb1d8f":"code","5d341c40":"code","8c08de18":"markdown","6d2a127d":"markdown","d7cac598":"markdown","c3fb38fb":"markdown","5247acef":"markdown","039bd141":"markdown","280508ba":"markdown","6dceb7b8":"markdown","ad0650a3":"markdown","09f771ef":"markdown","c04c1a24":"markdown","197411d2":"markdown","277511a3":"markdown","787697f6":"markdown"},"source":{"61666b93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn.linear_model","2207b7e8":"bienestar = pd.read_csv(\"..\/input\/dinerofelicidad\/FelicidadComunidades.csv\",delimiter=\";\",thousands='.',na_values=\"0\")\ndinero_hogar = pd.read_csv(\"..\/input\/dinerofelicidad\/RentaNetaMediaHogar.csv\",delimiter=\";\")\n","df32b54e":"# Mostrar los primeros elementos y los encabezados\ndinero_hogar.head(3)\n","b8684f30":"bienestar.head(3)","3357c6a6":"# Fusi\u00f3n de los dos data frames en uno. La \u00faltima columna es el tag.\ndinero = dinero_hogar.rename(columns={\"Comunidades y Ciudades Aut\u00f3nomas\":\"Comunidad\",\n                                     \"Renta Neta Media por hogar\":\"Renta\"})\ncomunidadraw = dinero.merge(bienestar, on=\"Comunidad\", how=\"left\")\n\n\n\n# Cambio las comas por punto y transformo en float la columna\ncomunidadraw[\"Felicidad\"] = [float(x.replace(',','.')) for x in comunidadraw['Felicidad en la vida']]\ndatos = comunidadraw.drop([\"Felicidad en la vida\"], axis=1)\ndatos\n","b337ce02":"# detecto y elimino Galicia posicion 11 considero que es un outlayer, ya que tiene valor 0\n\ncomunidades = comunidadraw.drop([11],axis=0)\n\ncomunidades.dtypes\n# variables\nX = np.c_[comunidades[\"Renta\"]]\ny = np.c_[comunidades[\"Felicidad\"]]","36fbedc6":"comunidades.plot(kind='scatter', x=\"Renta\", y=\"Felicidad\")\n","a2231c3c":"modelo = sklearn.linear_model.LinearRegression()","992c3cf2":"\nmodelo.fit(X,y)\n# Utilizamos el modelo para predecir todos los datos que tenermos.\ny_predic = modelo.predict(X)\n\nplt.plot(X, y_predic, color=\"blue\", linewidth=3)\nplt.scatter(X, y, color='red')\nplt.show()","1080191a":"Galicia = [[27862]]\nValencia = [[27948]]\nprint(modelo.predict(Galicia))\nprint(modelo.predict(Valencia))","f3aee399":"comunidadraw.describe()","3810965a":"comunidades2 = comunidadraw.drop([6],axis=0)\ncomunidades3 = comunidades2.drop([11],axis=0)\ncomunidades3.describe()","8893e450":"# Eliminando outlayers.\n\nmodelo2 = sklearn.linear_model.LinearRegression()\nX2 = np.c_[comunidades3[\"Renta\"]]\ny2 = np.c_[comunidades3[\"Felicidad\"]]","6e6a2339":"modelo2.fit(X2,y2)\n# Utilizamos el modelo para predecir todos los datos que tenermos.\ny_predic2 = modelo.predict(X2)\n\nplt.plot(X2, y_predic2, color=\"blue\", linewidth=3)\nplt.scatter(X2, y2, color='red')\nplt.show()","8e1415ec":"# Divisi\u00f3n no aleatoria de los datos del dataset. Los dos \u00faltimos registros quedan para pruebas\n# El resto queda para el entrenamiento.\n\nX_train = X[:-2]\nX_test = X[-2:]\ny_train = y[:-2]\ny_test = y[-2:]","b02ecb76":"modelorl = sklearn.linear_model.LinearRegression()\n\nmodelorl.fit(X_train,y_train)\n# Utilizamos el modelo para predecir todos los datos que tenermos.\ny_predic = modelorl.predict(X_test)\n\nplt.plot(X_test, y_predic, color=\"blue\", linewidth=3)\nplt.scatter(X_test, y_test, color='red')\nplt.show()","5eb13254":"# Selecci\u00f3n aleatoria con posible sesgo.\n\nfrom sklearn.model_selection import train_test_split\n\n# divisi\u00f3n datos\ncomuni_train, comuni_test = train_test_split(comunidades, test_size=0.2, random_state=42)\n\n# Descripci\u00f3n de los dos conjuntos obtenidos\nprint(comuni_train.describe())\nprint(comuni_test.describe())\n","ba3a14c5":"X_train = np.c_[comuni_train[\"Renta\"]]\ny_train = np.c_[comuni_train[\"Felicidad\"]]\nX_test = np.c_[comuni_test[\"Renta\"]]\ny_test = np.c_[comuni_test[\"Felicidad\"]]\n\n","487b7b0a":"modelo = sklearn.linear_model.LinearRegression()\n# Entrenamiento\nmodelo.fit(X_train,y_train)\n# Utilizamos el modelo para predecir todos los datos que tenermos.\ny_predic = modelo.predict(X_test)\n\nplt.plot(X_test, y_predic, color=\"blue\", linewidth=3)\nplt.scatter(X_test, y_test, color='red')\nplt.show()","b8bd23ed":"datos.head()\n","fbdb0a27":"# Al tener pocos datos, no podemos hacer demasiadas categorias.\ncomunidadraw[\"renta_cat\"] = pd.cut(comunidadraw[\"Renta\"],\n                                bins=[ 21000,31000, np.inf],\n                                labels=[2, 1])\ncomunidadraw","e790b068":"# Cuenta la proporci\u00f3n de categor\u00edas en el total de los datos.\n# En qu\u00e9 porcentaje est\u00e1 representada cada categor\u00eda en el total de datos.\ncomunidadraw[\"renta_cat\"].value_counts() \/ len(comunidades)","2fe7348f":"comunidadraw[\"renta_cat\"].hist()","8e1a4c00":"from sklearn.model_selection import StratifiedShuffleSplit\n# Problema al tener pocos datos, no es posible seleccionar una muestra de prueba que contenga\n# todas las categor\u00edas. Hay que categorizar menos estratos.\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(comunidadraw, comunidadraw['renta_cat']):\n    strat_train_set = comunidadraw.loc[train_index]\n    strat_test_set = comunidadraw.loc[test_index]\nprint(strat_train_set[\"renta_cat\"].value_counts() \/ len(strat_train_set))\nprint(strat_test_set[\"renta_cat\"].value_counts() \/ len(strat_test_set))","43070e44":"# divisi\u00f3n datos\n\nX3_train = np.c_[strat_train_set[\"Renta\"]]\ny3_train = np.c_[strat_train_set[\"Felicidad\"]]\nX3_test = np.c_[strat_test_set[\"Renta\"]]\ny3_test = np.c_[strat_test_set[\"Felicidad\"]]","3eaaf8e6":"import sklearn.neighbors\nmodelok = sklearn.neighbors.KNeighborsRegressor(n_neighbors=2)\n# modelok = sklearn.neighbors.KNeighborsClassifier(n_neighbors=2, weights=\"distance\")","f69ea4f9":"modelok.fit(X3_train, y3_train)\n\n# Predicci\u00f3n\ny3_predic = modelo.predict(y3_test)\n\n\nplt.scatter(X3_train, y3_train, color='red')\nplt.scatter(X3_test, y3_test, color='blue')\nplt.show()","77cb1d8f":"# Prediccion para Galicia\nprint(modelok.predict(Galicia))","5d341c40":"# Predicci\u00f3n para Valencia\nCatalunya = [[35030]]\nprint(modelok.predict(Valencia))\nprint(modelok.predict(Catalunya))","8c08de18":"# Visualizaci\u00f3n de datos","6d2a127d":"## Atenci\u00f3n\nObserva como la diferencia entre las caracter\u00edsticas de los datos de entrenamiento y los de prueba es grande.\nLa media es diferente.","d7cac598":"# Prueba con otro algoritmo\nCambio de algoritmo a el K-nearest neighbors.\nSe basa en asignar el valor medio de las distancias a los 3 (k=3) puntos m\u00e1s pr\u00f3ximos al punto que queremos predecir.\n","c3fb38fb":"## Propuesta... entrenar el modelo con datos difentes de los utilizados para evaluarlo\n\n#### Dividimos los datos en training\/testing\nX_train = X[:-2]\n\nX_test = X[-2:]\n\n\ny_train = y[:-2]\n\ny_test = y[-2:]","5247acef":"### Para reducir sesgo\nLa misma proporci\u00f3n de niveles de Renta del dataset completo, debe mantenerse en el dataset de prueba.\nVamos a crear 4 segmentos de ingresos medios, categor\u00edas. Para ajustar posibles errores de sesgo","039bd141":"# Preparaci\u00f3n de datos\nUnimos los dos dataframes en un unico dataframe","280508ba":"## Estratificamos teniendo en cuenta las categorias\nPara que la proporci\u00f3n de las categor\u00edas de rentas en el dataset original se mantenga en los datos de prueba.","6dceb7b8":"## Divisi\u00f3n de datos aleatoria\nHay que intentar que los datos de entrenamiento sean aleatorios y Se puede establecer una semilla para generar la seleccion aleatoria: random_state\n\nPuede ser suficiente si se dispone de muchos datos.\nPero si no son mucho es posible cometer un error de sesgo. Es decir, en el conjunto de prueba no est\u00e1n representados todos los casos en la misma proporci\u00f3n de significaci\u00f3n que en los datos completos.","ad0650a3":"# Cargar datos","09f771ef":"## Preparo los datos\nDatos vacios, **outlayers**","c04c1a24":"# Seleccion de un modelo lineal","197411d2":"# Entrenamiento del modelo","277511a3":"## Predicci\u00f3n para Galicia y Valencia","787697f6":"## Separaci\u00f3n m\u00e1s directa de los datos de entrenamiento y prueba\nCon valor aleatorio para cada ejecuci\u00f3n. Grupos diferentes\n"}}