{"cell_type":{"675f570b":"code","8a5f6e48":"code","7a665c61":"code","60942966":"code","d341af22":"code","9449f0d9":"code","b69a0849":"code","d954b230":"code","91fc1fa2":"code","bd647a34":"code","0163500a":"code","aaf5762c":"code","62931823":"code","1833eb0e":"code","ed21c197":"code","fc98cbf3":"code","d1c667f6":"code","c58ca1d3":"code","4f48794c":"code","789624fe":"markdown","c065e761":"markdown","20017427":"markdown","14d7755c":"markdown","e152a864":"markdown","945a4ca8":"markdown","5d369d40":"markdown","f1c57fd7":"markdown","068b4a2b":"markdown","29bd13e8":"markdown","6d9e4bd4":"markdown"},"source":{"675f570b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8a5f6e48":"df_train = pd.read_csv('..\/input\/train.csv')","7a665c61":"X_train = df_train.iloc[:, 1:]\nY_train = df_train.iloc[:, 0]","60942966":"X_train.head()","d341af22":"Y_train.head()","9449f0d9":"X_train = np.array(X_train)\nY_train = np.array(Y_train)","b69a0849":"X_train = X_train\/255.0","d954b230":"# dev-val split\nX_dev, X_val, Y_dev, Y_val = train_test_split(X_train, Y_train, test_size=0.03, shuffle=True, random_state=2019)\n\n#Reshape the arrays to match the input in tensorflow graph\nX_dev = X_dev.reshape((X_dev.shape[0], 28, 28, 1))\nX_val = X_val.reshape((X_val.shape[0], 28, 28, 1))","91fc1fa2":"def plot_digits(X, Y):\n    for i in range(20):\n        plt.subplot(4, 5, i+1)\n        plt.tight_layout()\n        plt.imshow(X[i].reshape((28, 28)), cmap='gray')\n        plt.title('Digit:{}'.format(Y[i]))\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","bd647a34":"plot_digits(X_train[-20:], Y_train[-20:])","0163500a":"x = tf.placeholder(dtype=tf.float32, shape=(None, 28, 28, 1), name='X')\ny = tf.placeholder(dtype=tf.float32, shape=(None, 10), name='Y')","aaf5762c":"conv1 = tf.layers.conv2d(x, filters=6, kernel_size=5, padding='same', strides=1, activation='relu', name='CONV1')\npool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, name='POOL1')\nconv2 = tf.layers.conv2d(pool1, filters=16, kernel_size=5, strides=1, activation='relu', name='CONV2')\npool2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2, name='POOL2')\nflatten1 = tf.layers.Flatten()(pool2)\nfc1 = tf.layers.Dense(120, activation='relu')(flatten1)\nfc2 = tf.layers.Dense(84, activation='relu')(fc1)\nout = tf.layers.Dense(10, activation='softmax')(fc2)","62931823":"batch_size = 100\nlearning_rate = 5e-4\nepochs = 20","1833eb0e":"cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=out, name='cost'))\nopt = tf.train.AdamOptimizer(learning_rate).minimize(cost)\nequal_pred = tf.equal(tf.argmax(y, 1), tf.argmax(out, 1))\nacc = tf.reduce_mean(tf.cast(equal_pred, tf.float32))","ed21c197":"init = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)","fc98cbf3":"T_dev = pd.get_dummies(Y_dev).values\nT_val = pd.get_dummies(Y_val).values\nfor epoch in range(epochs):\n    start_index = 0\n    s = np.arange(X_dev.shape[0])\n    np.random.shuffle(s)\n    X_dev = X_dev[s, :]\n    T_dev = T_dev[s]\n    while start_index < X_dev.shape[0]:\n        end_index = start_index + batch_size\n        if end_index > X_dev.shape[0]:\n            end_index = X_dev.shape[0]\n        x_dev = X_dev[start_index:end_index, :]\n        t_dev = T_dev[start_index:end_index]\n        dev_cost, dev_acc, _ = sess.run([cost, acc, opt], feed_dict={x:x_dev, y:t_dev})\n        start_index = end_index\n    dev_cost, dev_acc = sess.run([cost, acc], feed_dict={x:X_dev, y:T_dev})\n    val_cost, val_acc = sess.run([cost, acc], feed_dict={x:X_val, y:T_val})\n    print('Epoch:{0} Cost:{1:5f} Acc:{2:.5f} Val_Cost:{3:5f} Val_Accuracy:{4:.5f}'.\n          format(epoch+1, dev_cost, dev_acc, val_cost, val_acc))","d1c667f6":"X_test = pd.read_csv('..\/input\/test.csv')\nX_test = np.array(X_test)\nX_test = X_test \/ 255.0\nX_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\nT_test = sess.run([out], feed_dict={x:X_test})","c58ca1d3":"Y_test = np.argmax(T_test[0], axis=1)\nY_test[:5]","4f48794c":"df_out = pd.read_csv('..\/input\/sample_submission.csv')\ndf_out['Label'] = Y_test\ndf_out.to_csv('out.csv', index=False)","789624fe":"# Plot digits","c065e761":"# Hyperparameters","20017427":"# CNN Architecture\n\nWe will LeNet-5 CNN architeture to build our model.\n\n** LeNet - 5 Architecture: **\n\n![LeNet-5 Architecture](https:\/\/engmrk.com\/wp-content\/uploads\/2018\/09\/LeNet_Original_Image.jpg)\n\n** Convolution Operation: **\n\n![Convolution Operation](https:\/\/www.researchgate.net\/profile\/Ihab_S_Mohamed\/publication\/324165524\/figure\/fig3\/AS:611103423860736@1522709818959\/An-example-of-convolution-operation-in-2D-2.png)\n\n### Input : Flattened 784px grayscale images, which can be represented as dimension (n, 28, 28, 1)\n### Output: 0 - 9 \n\n### Let's decode the operations we will be performing in each layer \n** First Layer:  Convolutional Layer (CONV1): **\n* Parameters: Input (N) = 28, Padding (P) = 2, Filter (F) = 5 x 5, Stride (S) = 1\n* Conv Operation: ((N + 2P - F) \/ S) + 1 = ((28 + 4 - 5) \/ 1) + 1 = 28 x 28 \n* We will apply 6 filters \/ kernels so we will get a 28 x 28 x 6 dimensional output\n\n** Second Layer:  Average Pooling Layer (POOL1): **\n* Parameters: Input (N) = 28, Filter (F) = 2 x 2, Stride (S) = 2\n* AVG Pooling Operation: ((N + 2P -F) \/ S) + 1 = ((28 - 2) \/ 2) + 1 = 14 x 14\n* We will have a 14 x 14 x 6 dimensional output at the end of this pooling\n\n** Third Layer:  Convolutional Layer (CONV2): **\n* Parameters: Input (N) = 14, Filter (F) = 5 x 5, Stride (S) = 1\n* Conv Operation: ((N + 2P - F) \/ S) + 1 = ((14 - 5) \/ 1) + 1 = 10 x 10\n* We will apply 16 filters \/ kernels so we will get a 10 x 10 x 6 dimensional output \n\n** Fourth Layer: Average Pooling Layer (POOL2): **\n* Parameters: Input (N) = 10, Filter (F) = 2 x 2, Stride (S) = 2\n* AVG Pooling Operation: ((N + 2P -F) \/ S) + 1 = ((10 - 2) \/ 2) + 1 = 5 x 5\n* We will have a 5 x 5 x 16 dimensional output at the end of this pooling\n\n** Fifth Layer: Fully Connected layer(FC1): **\n* Parameters: W: 400 * 120, b: 120\n* We will have an output of 120 x 1 dimension\n\n** Sixth Layer: Fully Connected layer(FC2): **\n* Parameters: W: 120 * 84, b: 84\n* We will have an output of 84 x 1 dimension\n\n** Seventh Layer: Output layer(Softmax): **\n* Parameters: W: 84 * 10, b: 10\n* We will get an output of 10 x 1 dimension\n\nWe will tweak the pooling layers from average to max and activation functions.","14d7755c":"# Training the Model","e152a864":"# Normalization","945a4ca8":"# LeNet-5 CNN with TensorFlow:\n** I am developing a series of kernels for different Deep Learning Models: **\n\n* [L-Layered Neural Network from scratch](https:\/\/www.kaggle.com\/curiousprogrammer\/l-layered-neural-network-from-scratch)\n* [TensorFlow NN with Augmentation](https:\/\/www.kaggle.com\/curiousprogrammer\/digit-recognizer-tensorflow-nn-with-augmentation)\n* [Data Augmentation in Python, TF, Keras, Imgaug](https:\/\/www.kaggle.com\/curiousprogrammer\/data-augmentation-in-python-tf-keras-imgaug)\n* [Deep NN with Keras](https:\/\/www.kaggle.com\/curiousprogrammer\/deep-nn-with-keras-97-5) \n* CNN with TensorFlow - This one\n* CNN with Keras\n* AutoEncoders with TensorFlow\n* AutoEncoders with Keras\n* GANs with TensorFlow\n* GANs with Keras","5d369d40":"# Graph Creation - TF Layers","f1c57fd7":"# Input placeholder","068b4a2b":"# Cost, Accuracy, Optimizer","29bd13e8":"# Load Data","6d9e4bd4":"# Initialise the variables"}}