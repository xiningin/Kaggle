{"cell_type":{"ee6c40f5":"code","e842db19":"code","8cafd59a":"code","1e7bc987":"code","3bb51b9a":"code","e30758e8":"code","6cc20f14":"code","16305ee5":"code","a09d8c18":"code","2c1545e1":"code","415cbbbe":"code","9e242855":"code","91a0e3e3":"code","3e3f601a":"code","fe078e00":"code","6b60fb23":"code","4c461927":"markdown","423e3703":"markdown"},"source":{"ee6c40f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e842db19":"import pandas as pd\n\ndf=pd.read_csv(\"\/kaggle\/input\/time-series-for-avante\/Avante for timeseries.csv\",engine=\"python\",encoding=\"cp949\")\ndf=df.dropna()\ndf=df.drop([0])\ndf.head()","8cafd59a":"df[\"cnt\"]=df[\"cnt\"].astype(float)","1e7bc987":"df['\uc9d1\uacc4\uc6d4']=df['\uc9d1\uacc4\uc6d4'].astype(str)\ndf['Date'] = df['\uc9d1\uacc4\uc6d4'].str[0:4] + \"-\" + df['\uc9d1\uacc4\uc6d4'].str[4:6]+ \"-\" + \"01\"\ndf=df.drop(columns=['\uc9d1\uacc4\uc6d4'])\ndf['Date']=pd.to_datetime(df['Date'], format='%Y-%m-%d',errors='raise')","3bb51b9a":"df[\"\uae30\uc220\uc815\ubcf4\uad6c\ubd84\"].value_counts()","e30758e8":"\uc704\ud5d8\ub3c4 = 5.0\nR5_df = df[df['\uc704\ud5d8\ub3c4']==\uc704\ud5d8\ub3c4]\nR5_df\n# R5_df=df","6cc20f14":"R5_df=R5_df.groupby(by=['Date','\uc7a5\uce58(\uc18c)'], as_index=False).sum()\nR5_df = pd.DataFrame(R5_df)\n# R5_df=R5_df.drop(columns=['\uae30\uc220\uc815\ubcf4\uad6c\ubd84','car_grp','\ubd80\ud488\uba85','\ub0b4\uc218\uacc4','\uc7a5\uce58(\ub300)','\uc7a5\uce58(\uc911)','\uc704\ud5d8\ub3c4'])\n# R5_df\nR5_df","16305ee5":"import plotly.express as px\npx.line(data_frame=R5_df, x='Date', y='cnt', color='\uc7a5\uce58(\uc18c)')","a09d8c18":"R5_df_min = R5_df.groupby('\uc7a5\uce58(\uc18c)').agg({'cnt':'min'})\nR5_df_max = R5_df.groupby('\uc7a5\uce58(\uc18c)').agg({'cnt':'max'})\nR5_df_min.columns = ['min_r']\nR5_df_max.columns = ['max_r']\nR5_df2 = pd.concat([R5_df_min, R5_df_max], 1)","2c1545e1":"R5_df2 = R5_df2.reset_index(drop=False)\nR5_df_AA = pd.merge(R5_df, R5_df2, how='left', on='\uc7a5\uce58(\uc18c)')\nR5_df_AA['repair rate'] = (R5_df_AA['cnt'] - R5_df_AA['min_r']) \/ (R5_df_AA['max_r'] - R5_df_AA['min_r'])","415cbbbe":"R5_df_AA_pivot = R5_df_AA.pivot(index=\"\uc7a5\uce58(\uc18c)\", columns=\"Date\", values=\"repair rate\")\nR5_df_AA_pivot = R5_df_AA_pivot.fillna(0)\nR5_df_AA_pivot","9e242855":"from sklearn.cluster import DBSCAN\ndbscan = DBSCAN(eps=0.9, min_samples=2, metric='euclidean')\np = dbscan.fit_predict(R5_df_AA_pivot)\np","91a0e3e3":"R5_df_AA_pivot['cluster'] = p\nR5_df_AA_pivot['cluster'].value_counts()","3e3f601a":"temp = R5_df_AA_pivot.reset_index(drop=False)\ntemp = temp[['\uc7a5\uce58(\uc18c)', 'cluster']]\nR5_df_c = pd.merge(R5_df, temp, how='left', on='\uc7a5\uce58(\uc18c)')","fe078e00":"import plotly.express as px\ng1=px.line(data_frame=R5_df_c[R5_df_c['cluster']==0], x='Date', y='cnt', color='\uc7a5\uce58(\uc18c)')\ng1.show()","6b60fb23":"df[df[\"\uc7a5\uce58(\uc18c)\"]=='\uc778\ubc84\ud130\/\ucee8\ubc84\ud130']","4c461927":"# 1. \uc120\ud0dd\ucc28\ub7c9 \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30","423e3703":"# 2. \uc7a5\uce58(\uc18c) \uae30\uc900 \uc815\uaddc\ud654"}}