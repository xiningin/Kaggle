{"cell_type":{"48ac9b33":"code","af612571":"code","9177694e":"code","e10e5436":"code","a9877098":"code","122dec6b":"code","ccf211e6":"code","c103f398":"code","316aa072":"code","7618981f":"code","f02b4dc6":"code","5b999145":"code","3e1ede70":"code","288c10c5":"code","af681ce1":"code","8109766c":"code","88310b72":"code","b1cd42e9":"code","600d5d33":"code","6ced8197":"code","985c0a34":"code","320382d8":"code","081f77ec":"code","465fcb16":"code","e8e58090":"code","d76d896e":"code","bc0c33b4":"code","9721d80e":"code","061d6714":"code","062de03a":"code","4ea9d3b2":"code","d0be8447":"code","e5fff4e1":"code","f17362c7":"code","d9182f6b":"code","1bd11185":"code","19002a13":"code","b01cc712":"code","e100c749":"code","9059628e":"code","d81bcaa8":"markdown","4b93ab53":"markdown","657d4c89":"markdown","44499d71":"markdown","3c4ec8ca":"markdown","a4e31ddc":"markdown","e8e61eae":"markdown","bd0cb260":"markdown","5676cbb1":"markdown","68562b31":"markdown","7a47268a":"markdown","e8557d49":"markdown"},"source":{"48ac9b33":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af612571":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings(action='ignore') \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\n","9177694e":"df = pd.read_csv('\/kaggle\/input\/league-of-legends-diamond-ranked-games-10-min\/high_diamond_ranked_10min.csv')\ndf","e10e5436":"df.info()","a9877098":"df.describe()","122dec6b":"# blue wins \ub97c \uae30\uc900\uc73c\ub85c \uc0c1\uad00\uacc4\uc218 \ubd84\uc11d( blue wins \uc885\uc18d\ubcc0\uc218)\nfig = plt.figure(figsize=(4, 10))\nsns.heatmap(df.corr()[['blueWins']], annot=True)","ccf211e6":"df.columns","c103f398":"sns.histplot(x='blueGoldDiff', data=df, hue='blueWins', palette='RdBu', kde=True)","316aa072":"sns.histplot(x='blueKills', data=df, hue='blueWins', palette='RdBu', kde=True, bins=8)","7618981f":"sns.jointplot(x='blueKills', y='blueGoldDiff', data=df, hue='blueWins')","f02b4dc6":"sns.jointplot(x='blueExperienceDiff', y='blueGoldDiff', data=df, hue='blueWins')","5b999145":"sns.countplot(x='blueDragons', data=df, hue='blueWins', palette='RdBu')","3e1ede70":"sns.countplot(x='redDragons', data=df, hue='blueWins', palette='RdBu')","288c10c5":"sns.countplot(x='blueFirstBlood', data=df, hue='blueWins', palette='RdBu')","af681ce1":"print(df.columns)\nprint(len(df.columns))\n\n#Delete unnecessary columns to avoid multicollinearity\ndf.drop(['gameId', 'redFirstBlood', 'redKills', 'redDeaths',\n       'redTotalGold', 'redTotalExperience', 'redGoldDiff',\n       'redExperienceDiff'], axis=1, inplace=True)\nprint(df.columns)\nprint(len(df.columns))","8109766c":"X_num = df[['blueWardsPlaced', 'blueWardsDestroyed', \n       'blueKills', 'blueDeaths', 'blueAssists', 'blueEliteMonsters',\n       'blueTowersDestroyed', 'blueTotalGold',\n       'blueAvgLevel', 'blueTotalExperience', 'blueTotalMinionsKilled',\n       'blueTotalJungleMinionsKilled', 'blueGoldDiff', 'blueExperienceDiff',\n       'blueCSPerMin', 'blueGoldPerMin', 'redWardsPlaced', 'redWardsDestroyed',\n       'redAssists', 'redEliteMonsters', 'redTowersDestroyed', 'redAvgLevel', 'redTotalMinionsKilled',\n       'redTotalJungleMinionsKilled', 'redCSPerMin', 'redGoldPerMin']]\nX_cat = df[['blueFirstBlood', 'blueDragons', 'blueHeralds', 'redDragons', 'redHeralds']]\n\nscaler = StandardScaler()\nscaler.fit(X_num)\nX_scaled = scaler.transform(X_num)\nX_scaled = pd.DataFrame(X_scaled, index=X_num.index, columns=X_num.columns)\n\nX = pd.concat([X_scaled, X_cat], axis=1)\ny = df['blueWins']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","88310b72":"model_lr = LogisticRegression()\nmodel_lr.fit(X_train, y_train)\nscores = cross_val_score(model_lr, X_train,y_train, cv=10) # model, train, target, cross validation\nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))","b1cd42e9":"pred = model_lr.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(model_lr.score(X_test, y_test)*100, 2)))\nprint(classification_report(y_test, pred))","600d5d33":"model_coef = pd.DataFrame(data=model_lr.coef_[0], index=X.columns, columns=['Model Coefficient'])\nmodel_coef.sort_values(by='Model Coefficient', ascending=False, inplace=True)\nplt.bar(model_coef.index, model_coef['Model Coefficient'])\nplt.xticks(rotation=90)\nplt.grid()\nplt.show()","6ced8197":"model_xgb = XGBClassifier()\nmodel_xgb.fit(X_train, y_train)\nscores = cross_val_score(model_xgb, X_train,y_train, cv=10) # model, train, target, cross validation\nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))","985c0a34":"pred = model_xgb.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(model_xgb.score(X_test, y_test)*100, 2)))\n\nprint(classification_report(y_test, pred))","320382d8":"fig = plt.figure(figsize=(10, 10))\nplt.barh(X.columns, model_xgb.feature_importances_)","081f77ec":"dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\nscores = cross_val_score(dt, X_train,y_train, cv=10) # model, train, target, cross validation\nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))","465fcb16":"pred = dt.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(dt.score(X_test, y_test)*100, 2)))\nprint(classification_report(y_test, pred))","e8e58090":"fig = plt.figure(figsize=(10, 10))\nplt.barh(X.columns, dt.feature_importances_)","d76d896e":"best_Kvalue = 0\nbest_score = 0\nfor i in range(2,15):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred = knn.predict(X_test)\n    score = round(knn.score(X_test, y_test)*100,2)\n#     print(f\"Test Accuracy: {score}%, knn number {i}\")\n    if score > best_score:\n        \n        best_score = round(score)\n        best_Kvalue = i\n        \nprint(f\"Best KNN Value: {best_Kvalue}\")\nprint(f\"Test Accuracy: {best_score}%\")","bc0c33b4":"knn = KNeighborsClassifier(n_neighbors=best_Kvalue)\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\nprint(\"KNN Classifier report: \\n\\n\", classification_report(y_test, pred))","9721d80e":"svm = SVC(random_state=42, gamma=\"auto\")\nsvm.fit(X_train, y_train)\nscores = cross_val_score(svm, X_train,y_train, cv=10) \nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))\n","061d6714":"pred = svm.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(svm.score(X_test, y_test)*100, 2)))\nprint(\"SVM Classifier report: \\n\\n\", classification_report(y_test, pred))","062de03a":"rf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\nscores = cross_val_score(rf, X_train,y_train, cv=10) \nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))\n","4ea9d3b2":"ypred = rf.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(rf.score(X_test, y_test)*100, 2)))\nprint(\"Random Forest Classifier report: \\n\\n\", classification_report(y_test, ypred))","d0be8447":"fig = plt.figure(figsize=(10, 10))\nplt.barh(X.columns, rf.feature_importances_)","e5fff4e1":"ada=AdaBoostClassifier()\nada.fit(X_train, y_train)\nscores = cross_val_score(ada, X_train,y_train, cv=10) \nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))","f17362c7":"ypred = ada.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(ada.score(X_test, y_test)*100, 2)))\nprint(\"Random Forest Classifier report: \\n\\n\", classification_report(y_test, ypred))","d9182f6b":"fig = plt.figure(figsize=(10, 10))\nplt.barh(X.columns, ada.feature_importances_)","1bd11185":"bag=BaggingClassifier()\nbag.fit(X_train, y_train)\nscores = cross_val_score(bag, X_train,y_train, cv=10) \nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))\n","19002a13":"ypred = bag.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(bag.score(X_test, y_test)*100, 2)))\nprint(\"Random Forest Classifier report: \\n\\n\", classification_report(y_test, ypred))","b01cc712":"xtree=ExtraTreesClassifier()\nxtree.fit(X_train, y_train)\nscores = cross_val_score(xtree, X_train,y_train, cv=10) \nprint('cross-val-score \\n{}'.format(scores))\nprint('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))\n","e100c749":"ypred = xtree.predict(X_test)\nprint(\"Test Accuracy: {}%\".format(round(xtree.score(X_test, y_test)*100, 2)))\nprint(\"Random Forest Classifier report: \\n\\n\", classification_report(y_test, ypred))","9059628e":"fig = plt.figure(figsize=(10, 10))\nplt.barh(X.columns, xtree.feature_importances_)","d81bcaa8":"# RandomForestClassifier","4b93ab53":"#  LogisticRegression ","657d4c89":"# BaggingClassifier","44499d71":"# SVM","3c4ec8ca":"# KNN","a4e31ddc":"# AdaBoostClassifier","e8e61eae":"# preprocessing","bd0cb260":"# DecisionTreeClassifier","5676cbb1":"# EDA","68562b31":"# Visualization","7a47268a":"# XGBClassifier","e8557d49":"# ExtraTreesClassifier"}}