{"cell_type":{"13730fd2":"code","dc1d55ef":"code","0bd95be1":"code","62d40805":"code","0dbdbd88":"code","636c60a0":"code","84419e06":"code","5ece1d69":"code","920fbde5":"code","46d6d61e":"code","f8257c17":"code","4e69206b":"code","e619a831":"code","967ef081":"code","288e2343":"code","29057ecb":"markdown","a886edce":"markdown","ca6b1dee":"markdown","18a4c41b":"markdown","d0b6fb4f":"markdown","cb9a3d2b":"markdown"},"source":{"13730fd2":"# importing dataframes and array operations\nimport pandas as pd\nimport numpy as np\n# BeautifulSoup is used to remove html tags from the text\nfrom bs4 import BeautifulSoup \nimport re # for regular expression\n\n# Stopwords can be useful to undersand the semantics of the sentence.\n# Therefore stopwords are not removed while creating the word2vec model.\n# But they will be removed  while averaging feature vectors.\nfrom nltk.corpus import stopwords","dc1d55ef":"# reading .tsv file\ntrain = pd.read_csv(\"..\/input\/word2vec\/unlabeledTrainData.tsv\", header=0,\\\n                    delimiter=\"\\t\", quoting=3)","0bd95be1":"#visualize the context\ntrain.head()","62d40805":"# checking for Nan or empty strings\ntrain.isnull().sum()","0dbdbd88":"# This function converts a text to a sequence of words.\ndef review_wordlist(review, remove_stopwords=False):\n    # 1. Removing html tags\n    review_text = BeautifulSoup(review).get_text()\n    # 2. Removing non-letter.\n    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n    # 3. Converting to lower case and splitting\n    words = review_text.lower().split()\n    # 4. Optionally remove stopwords\n    if remove_stopwords:\n        stops = set(stopwords.words(\"english\"))     \n        words = [w for w in words if not w in stops]\n    #5. lemma\n    \n    return(words)","636c60a0":"# word2vec expects a list of lists.\n# Using punkt tokenizer for better splitting of a paragraph into sentences.\n\nimport nltk.data\n#nltk.download('popular')\n\ntokenizer = nltk.data.load('tokenizers\/punkt\/english.pickle')","84419e06":"# This function splits a review into sentences\ndef review_sentences(review, tokenizer, remove_stopwords=False):\n    # 1. Using nltk tokenizer\n    raw_sentences = tokenizer.tokenize(review.strip())\n    sentences = []\n    # 2. Loop for each sentence\n    for raw_sentence in raw_sentences:\n        if len(raw_sentence)>0:\n            sentences.append(review_wordlist(raw_sentence,\\\n                                            remove_stopwords))\n\n    # This returns the list of lists\n    return sentences","5ece1d69":"sentences = []\nprint(\"Parsing sentences from training set\")\nfor review in train[\"review\"]:\n    sentences += review_sentences(review, tokenizer)","920fbde5":"# Creating the model and setting values for the various parameters\nnum_features = 300  # Word vector dimensionality\nmin_word_count = 40 # Minimum word count\nnum_workers = 4     # Number of parallel threads\ncontext = 10        # Context window size\ndownsampling = 1e-3 # (0.001) Downsample setting for frequent words\n\n# Initializing the train model\nfrom gensim.models import word2vec\nprint(\"Training model....\")\nmodel = word2vec.Word2Vec(sentences,\\\n                          workers=num_workers,\\\n                          size=num_features,\\\n                          min_count=min_word_count,\\\n                          window=context,\n                          sample=downsampling)\n\n# To make the model memory efficient\nmodel.init_sims(replace=True)\n\n# Saving the model for later use. Can be loaded using Word2Vec.load()\nprint(\"Saving the model\")\nmodel_name = \"300features_40minwords_10context\"\nmodel.save(model_name)\n","46d6d61e":"# Few tests: This will print the odd word among them \nmodel.wv.doesnt_match(\"man woman king queen princess dog\".split())","f8257c17":"model.wv.doesnt_match(\"europe africa USA turkey\".split())","4e69206b":"model.wv.most_similar(\"best\")","e619a831":"model.wv.most_similar(\"boring\")","967ef081":"model.wv.most_similar_cosmul(positive=['man', 'woman'], negative=['princess'])","288e2343":"model.wv.syn0.shape","29057ecb":"# Reading the data","a886edce":"# Importing Libraries","ca6b1dee":"# model eval","18a4c41b":"# Pre-processing the reviews","d0b6fb4f":"# Purpose\nThe purpose of this kernel is to extract the vector for each word from large corpus ","cb9a3d2b":"# Model creation  "}}