{"cell_type":{"b82f405a":"code","81af65c3":"code","beb6b8c8":"code","933ffce5":"code","d0200205":"code","645b1854":"code","ef11fd54":"code","73a9a487":"code","38564b52":"code","b726b529":"code","1572e02c":"code","1674f426":"code","33612c77":"code","701cb3f3":"code","6bb08a9a":"code","6f8b665f":"code","98d8d041":"code","cc228667":"code","9e181391":"code","1355dbbc":"markdown","c5d303c4":"markdown","c1067be6":"markdown","b202e2bd":"markdown","44fa02d2":"markdown","31a312d8":"markdown","62c12120":"markdown","c2e66833":"markdown","89c7cf7e":"markdown","67755407":"markdown","1deada7f":"markdown","3911a20e":"markdown","3bcc42f9":"markdown","a3b8cbe9":"markdown","5087e086":"markdown","c4240ced":"markdown","12f02d5b":"markdown","3c5ad845":"markdown","dda24a56":"markdown","f9555d57":"markdown"},"source":{"b82f405a":"import numpy as np\nimport pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.patches as mpatches\nimport seaborn as sns","81af65c3":"test_data = pd.read_csv('..\/input\/teste-uci\/UCI\/adult_test.txt', names=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education.num\", \"marital.status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital.gain\", \"capital.loss\", \"hours.per.week\", \"native.country\", \"income\"], engine='python', na_values=\"?\").dropna()\nadult = pd.read_csv('..\/input\/adult-pmr3508\/train_data.csv', index_col='Id')","beb6b8c8":"print(adult.shape)\nadult.head()","933ffce5":"for coluna in adult.columns:\n   n_na = adult[coluna].isna().sum()\n   if n_na != 0:\n      print(coluna, n_na)","d0200205":"adult['workclass'].value_counts()","645b1854":"filtro = adult['workclass'] != '?'\nadult = adult[filtro]","ef11fd54":"sns.histplot(data=adult['age'], binwidth=10, binrange=(10, 100))\n# adult['age'] >= 20) & (adult['age'] < 31","73a9a487":"a = adult.groupby([pd.cut(adult['age'], np.arange(10, 90, 10))])['workclass'].count()\nc = adult.groupby([pd.cut(adult['age'], np.arange(10, 90, 10)), 'income'])['workclass'].count()\n\nlista_percentuais = []\nfor n in range(7):\n    x = c.iloc[2*n]\n    y = c.iloc[2*n + 1]\n    total = x+y\n    lista_percentuais.append((x\/total)*100)\n\n# sns.set_theme(style='whitegrid')\nplt.figure(figsize=(9,5))\nbarra1 = sns.barplot(x=a.index, y=[100]*7, color='green', saturation=0.5)\nbarra2 = sns.barplot(x=a.index, y=lista_percentuais, color='red', saturation=0.5)\nsuperior = mpatches.Patch(color='green', label='>50k')\ninferior = mpatches.Patch(color='red', label='<=50k')\nplt.ylabel('Propor\u00e7\u00e3o (%)')\nplt.legend(handles=[superior, inferior])\nplt.show()","38564b52":"filtro_male = adult['sex'] == 'Male'\nn_male = adult['sex'][filtro_male].count()\nfiltro_female = adult['sex'] == 'Female'\nn_female = adult['sex'][filtro_female].count()\n\ndata = [n_male, n_female]\nlabels = ['Male', 'Female']\n\nplt.pie(data, labels = labels, autopct='%.2f%%')\nplt.show()","b726b529":"a = adult.groupby(['sex'])['workclass'].count()\nc = adult.groupby(['sex', 'income'])['workclass'].count()\n\nlista_percentuais = []\nfor n in range(2):\n    x = c.iloc[2*n]\n    y = c.iloc[2*n + 1]\n    total = x+y\n    lista_percentuais.append((x\/total)*100)\n\n# sns.set_theme(style='whitegrid')\nplt.figure(figsize=(7,5))\nbarra1 = sns.barplot(x=a.index, y=[100]*2, color='yellow', saturation=0.8)\nbarra2 = sns.barplot(x=a.index, y=lista_percentuais, color='blue', saturation=0.5)\nsuperior = mpatches.Patch(color='yellow', label='>50k')\ninferior = mpatches.Patch(color='blue', label='<=50k')\nplt.ylabel('Propor\u00e7\u00e3o (%)')\nplt.legend(handles=[superior, inferior])\nplt.show()","1572e02c":"corr = adult.corr()\n# sns.set_theme('whitegrid')\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr, vmin=-1, vmax=1, center=0, annot=True, cmap=cmap)","1674f426":"adult_dummies = pd.get_dummies(adult, columns=['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country'])\nadult_dummies.head()","33612c77":"alvo = 'income'\nfeatures = adult.columns[:-1]\n\nXadult, Yadult = adult[features], adult[alvo]\n# Xadult.head()","701cb3f3":"from sklearn.preprocessing import OrdinalEncoder\nencoder = OrdinalEncoder()\nencoder.fit(Xadult)\nXencoded = pd.DataFrame(encoder.transform(Xadult), columns=Xadult.columns, index=Xadult.index)\nXencoded.head()","6bb08a9a":"from sklearn.preprocessing import Normalizer\n\nnormalizer = Normalizer()\nnormalizer.fit(Xencoded)\nXnorm = pd.DataFrame(normalizer.transform(Xencoded), columns=Xencoded.columns, index=Xencoded.index)\nXnorm.head()","6f8b665f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\nmelhor_acuracia = 0\nmelhor_k = 0\nfor k in range(1, 31):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(Xnorm, Yadult)\n\n    scores = cross_val_score(knn, Xnorm, Yadult, cv=5)\n    acuracia = scores.mean()\n    if acuracia > melhor_acuracia:\n        melhor_acuracia = acuracia\n        melhor_k = k\nprint(f'Melhor k = {melhor_k}')\nprint(f'Melhor acur\u00e1cia = {melhor_acuracia}')","98d8d041":"filtro = test_data['workclass'] != '?'\ntest_data = test_data[filtro]\n\nfeatures = test_data.columns[:-1]\nXtest, Ytest = test_data[features], test_data[alvo]\nYtest = pd.Series([x[:-1] for x in test_data['income']])\nYtest = pd.Series([x[1:] for x in Ytest])\nYtest = np.array(Ytest)\n# Xtest.head()\n\nencoder = OrdinalEncoder()\nencoder.fit(Xtest)\nXtest = pd.DataFrame(encoder.transform(Xtest), columns=Xtest.columns, index=Xtest.index)\n\nnormalizer = Normalizer()\nnormalizer.fit(Xtest)\nXtest = pd.DataFrame(normalizer.transform(Xtest), columns=Xtest.columns, index=Xtest.index)\nXtest.head()","cc228667":"from sklearn.metrics import accuracy_score\nYtestpred = knn.predict(Xtest)\n# Ytestpred\nknn_acuracia = accuracy_score(Ytest, Ytestpred)*100\ntaxa_erro = 100- knn_acuracia\nprint(f'Acur\u00e1cia do modelo: {round(knn_acuracia, 2)}%')\nprint(f'Taxa de erro emp\u00edrica: {round(taxa_erro, 2)}%')","9e181391":"from sklearn.metrics import confusion_matrix, precision_score, recall_score\nmatriz = confusion_matrix(Ytest, Ytestpred, labels=['<=50K', '>50K'])\n\nprecisao_maior = precision_score(y_true=Ytest, y_pred=Ytestpred, pos_label='<=50K')*100\nprecisao_menor = precision_score(y_true=Ytest, y_pred=Ytestpred, pos_label='>50K')*100\n\nrecall_maior = recall_score(y_true=Ytest, y_pred=Ytestpred, pos_label='<=50K')*100\nrecall_menor = recall_score(y_true=Ytest, y_pred=Ytestpred, pos_label='>50K')*100\n\nprint(f'Precis\u00e3o (<=50K): {round(precisao_maior, 2)}%')\nprint(f'Sensibilidade (<=50K): {round(recall_maior, 2)}%')\nprint(f'Precis\u00e3o (>50K): {round(precisao_menor, 2)}%')\nprint(f'Sensibilidade (>50K): {round(recall_menor, 2)}%')\npd.DataFrame(matriz, index=['<=50K', '>50K'], columns=['<=50K', '>50K'])","1355dbbc":"## 1.2. Sexo\n\nQuanto \u00e0 propor\u00e7\u00e3o de homens e mulheres, notamos que 66,92% das pessoas registradas s\u00e3o do sexo masculino e 33,08%, do sexo feminino.","c5d303c4":"Ent\u00e3o, olhamos para as primeiras linhas do dataset adult e para o seu formato, para termos uma ideia geral das informa\u00e7\u00f5es nele contidas. O dataset apresenta 32560 registros, cada um com 16 colunas.","c1067be6":"## 1. An\u00e1lise explorat\u00f3ria","b202e2bd":"Tamb\u00e9m podemos visualizar a propor\u00e7\u00e3o de pessoas de cada grupo de renda, separados por idade, como no gr\u00e1fico a seguir. As maiores concentra\u00e7\u00f5es de pessoas com renda acima de 50 mil d\u00f3lares encontram-se nos grupos de 30 a 70 anos de idade.","44fa02d2":"Com isso, optou-se pelo processo de Ordinal encoding, no qual cada valor poss\u00edvel de uma vari\u00e1vel categ\u00f3rica foi transformado em um valor inteiro. Tal processo foi aplicado ap\u00f3s a separa\u00e7\u00e3o das vari\u00e1veis independentes (X) da vari\u00e1vel dependente (Y).","31a312d8":"Entretanto, na coluna workclass, valores faltantes foram representados por ponto de interroga\u00e7\u00e3o.","62c12120":"Agora, testaremos o modelo de k=10 nos dados de teste. Para tanto, \u00e9 necess\u00e1rio fazer o mesmo pr\u00e9-processamento.","c2e66833":"Agora, checamos por valores faltantes. Nenhum foi encontrado pela fun\u00e7\u00e3o isna(), entretanto os valores faltantes podem estar sendo representados por um s\u00edmbolo n\u00e3o reconhecido por essa fun\u00e7\u00e3o.","89c7cf7e":"Tamb\u00e9m foi importante normalizar os dados do dataset, para que as diferentes escalas de cada coluna n\u00e3o fa\u00e7am com que uma tenha um peso maior que a outra.","67755407":"# KNN for Adult Dataset","1deada7f":"### 1.1. Idade\n\nNo histograma abaixo, podemos ver a distribui\u00e7\u00e3o de idades dos indiv\u00edduos registrados no dataset. Nota-se que a grande maioria tem enre 20 e 60 anos.","3911a20e":"Como apenas 1836 de 32560 registros (5,6%) carecem dessa informa\u00e7\u00e3o, podemos remov\u00ea-los sem perdas significativas para o dataset.","3bcc42f9":"### 1.3. Matriz de correla\u00e7\u00f5es\n\nPor meio da matriz de correla\u00e7\u00f5es, podemos identificar colunas com altamente correlacionadas. Pares (ou grupos maiores) de colunas linearmente dependentes entre si n\u00e3o acrescentam informa\u00e7\u00e3o ao dataset. Portanto, podemos remover (n-1) colunas de um grupo L.D. de n colunas para simplificar o modelo que ser\u00e1 constru\u00eddo.\nPor\u00e9m, como mostra a matriz de correla\u00e7\u00f5es, n\u00e3o existem colunas altamente relacionadas no dataset.","a3b8cbe9":"O objetivo deste trabalho \u00e9 a constru\u00e7\u00e3o de um modelo kNN a partir da base adult para prever se a renda anual das pessoas \u00e9 superior ou inferior a 50 mil d\u00f3lares. Primeiramente, ser\u00e1 feita uma an\u00e1lise explorat\u00f3rio dos dados. Em seguida, ser\u00e1 constru\u00eddo o modelo em si. ","5087e086":"Tamb\u00e9m podemos montar a matriz de confus\u00e3o (valores reais nas linhas e valores previstos nas colunas) e calcular os indicadores de precis\u00e3o e sensibilidade para cada label. Pelos indicadores, notamos que 94,12% dos registros <=50K foram identificados corretamente, sendo que 83,52% das vezes que o modelo fez essa previs\u00e3o, acertou. Analogamente, o modelo acertou 67,75% de suas previs\u00f5es >50K, identificando corretamente 39,94% desses registros.","c4240ced":"De forma an\u00e1loga ao que fizemos com as faixas et\u00e1rias, podemos visualizar a propor\u00e7\u00e3o de cada grupo de renda entre homens e mulheres, separadamente. Pelo gr\u00e1fico, notamos uma grande disparidade. Apenas cerca de 11% das mulheres pertence ao grupo que ganha mais de 50 mil d\u00f3lares. J\u00e1 entre os homens, cerca de 30% pertencem a esse grupo.","12f02d5b":"Ap\u00f3s as etapas de pr\u00e9-processamento, constru\u00edmos o modelo em si. Abaixo, foi feito um loop que constr\u00f3i modelos de KNN com k variando de 1 a 30. Para cada caso, \u00e9 feita valida\u00e7\u00e3o cruzada com 5 folds. O modelo com a melhor m\u00e9dia de acur\u00e1cia \u00e9 eleito o melhor. Nesse caso, o melhor modelo obtido foi com k=10. Sua acur\u00e1cia foi de cerca de 81,1%.","3c5ad845":"## 2. Modelo\n\nNesta etapa construiremos o modelo em si. \nPrimeiramente, todas as vari\u00e1veis independentes devem ser num\u00e9ricas para poderem ser interpretadas pelo modelo de k Nearest Neighbors. Para fazer essa transforma\u00e7\u00e3o, o ideal seria utilizar o processo de One-hot encoding para obter vari\u00e1veis dummy a partir das vari\u00e1veis categ\u00f3ricas. Entretanto, como mostra o c\u00f3digo abaixo, tal processo geraria um dataset com mais de 100 colunas, tornando o treinamento dos modelos lento demais.","dda24a56":"Ent\u00e3o, podemos aplicar o modelo ao conjunto de testes, fazer as previs\u00f5es e analisar os resultados. A acur\u00e1cia obtida foi de 81,32%.","f9555d57":"Primeiramente, carregamos as bibliotecas que ser\u00e3o usadas fazemos o upload dos datasets necess\u00e1rios (train_data.csv e test_data.csv)."}}