{"cell_type":{"0704d2ec":"code","e882c56e":"code","42ae1af8":"code","4253ed0a":"code","cbb7f779":"code","6e8e89fd":"code","5a0badea":"code","7fbbc26d":"code","abc5fb08":"code","f45414d2":"code","04b8ed33":"code","58e68f6e":"code","9bf025f4":"code","cd3743f2":"code","b3cb5a39":"code","658f7d00":"markdown","e0528ae7":"markdown","a3cd6020":"markdown","a301dd6e":"markdown","39b7c8e0":"markdown","bc199903":"markdown","43853dc9":"markdown"},"source":{"0704d2ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport missingno as msno\nfrom sklearn.feature_selection import mutual_info_regression, SelectKBest\nfrom sklearn.preprocessing import LabelEncoder\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e882c56e":"data = pd.read_csv('..\/input\/data.csv')\ndata.head()","42ae1af8":"print(f\"Number of rows: {data.shape[0]}\")\nprint(f\"Number of cols: {data.shape[1]}\")","4253ed0a":"def convert_currencies(x):\n    if type(x) is float:\n        return x\n    \n    multiply_by = 1000000 if 'M' in x else 1000\n    x = x.replace('M', '').replace('K','').replace('\u20ac','')\n    return float(x) * multiply_by","cbb7f779":"data['Wage'] = data['Wage'].apply(convert_currencies)\ndata['Value'] = data['Value'].apply(convert_currencies)\ndata['Release Clause'] = data['Release Clause'].apply(convert_currencies)\ndata.head()","6e8e89fd":"# Count the NaNs\nnan_count = data.isnull().sum()\ncols_with_nans = nan_count[nan_count > 0]\ncols_without_nans = nan_count[nan_count == 0]\n\nprint(f\"Number of columns with missing values:  {cols_with_nans.size} of {data.shape[1]}\")\nprint(f\"Number of columns with complete values: {cols_without_nans.size} of {data.shape[1]}\")","5a0badea":"# Plot the completeness of every column\nax = msno.bar(data)","7fbbc26d":"data.drop(columns='Loaned From', inplace=True)","abc5fb08":"data.dropna(axis=0, inplace=True)","f45414d2":"ax = msno.bar(data)","04b8ed33":"# Just use some selected features\nfeature_cols = ['Age','International Reputation','Reactions','Balance','Weak Foot','Skill Moves','Work Rate','Body Type','Finishing','ShortPassing','Volleys','Dribbling','Curve','BallControl','LongShots']\n\n# The target variable\nlabel_col = 'Value'\n\n# We need this as parameter for the mutual_info_regression method\ncategorical_cols = dt = [data.dtypes[t] == 'O' for t in data.dtypes.index if t in feature_cols]","58e68f6e":"# Create a label encoded data frame\ndata_enc = pd.DataFrame(columns=feature_cols)\ndata_enc\n\nfor col in feature_cols:\n    enc = LabelEncoder()\n    data_enc[col] = enc.fit_transform(data[col])\n    \ndata_enc[label_col] = enc.fit_transform(data[label_col])","9bf025f4":"X=data_enc[feature_cols]\ny=data_enc[\"Value\"]\n\nprint(f'Shape of X: {X.shape}')\nprint(f'Shape of y: {y.shape}')","cd3743f2":"mutual_infos=mutual_info_regression(X.values,y.values, discrete_features=categorical_cols)\n\nfeature_importances = {}\nfor i,f in enumerate(feature_cols):\n    feature_importances[f] = mutual_infos[i]    ","b3cb5a39":"sorted(feature_importances.items(), key=lambda kv: kv[1], reverse=True)","658f7d00":"# 3. Clean the dataset\n\nTodo:\n- Drop column 'Loaned from'\n- Drop all rows with NaNs","e0528ae7":"# 1. Loading the data and fix the data types","a3cd6020":"# Features, that could be important for the value of a player","a301dd6e":"# Findings\n\n- The column 'Loaned from' is extremely sparse\n- In the remaining columns more than 80% of the values are present.","39b7c8e0":"# 2. Check the quality\n\nTodo:\n- Count the NaNs per column\n- Plot the completeness of every column","bc199903":"# Feature importance\n\nNow that we have a clean dataset, we can check the feature importances\n\nTodo:\n- Choose a subset of features (to avoid performance problems in this notebook) \n- Label Encode all categorical features\n- Calculate the mutual information of all columns","43853dc9":"# Findings\n\n- Reactions, BallControl and ShortPassing seems to be important for a high value of a player"}}