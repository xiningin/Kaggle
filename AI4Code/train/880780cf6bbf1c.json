{"cell_type":{"d8f3cf77":"code","c4f9b126":"code","dbd02bfb":"code","3ef94f52":"code","c32d6246":"code","193c5fbe":"code","c8c7994a":"code","4da955c2":"code","5d8a8e19":"code","95733eb4":"code","24f92f80":"code","4fd1b6d6":"code","6bc7008f":"code","ea7b50b8":"code","2bff4a2f":"code","3fceda05":"code","ae0c169b":"code","dcb9565c":"code","b9dbf080":"code","a3e9ec4f":"code","649fd1b4":"code","ac939540":"code","f60bebda":"code","4ace63de":"code","c3310d82":"code","fcd2f250":"code","fc9a7fec":"code","8ae999b6":"code","ed9e1b93":"code","58ba133f":"code","06f23058":"code","66073cf7":"code","21ac75ab":"code","4ff059c5":"code","0a03a1a1":"code","c86bed9b":"code","b5872178":"code","512797f1":"markdown","fcc4a9b3":"markdown","a5db5675":"markdown","e3d75a0f":"markdown","c3b0b7ff":"markdown","b5a45987":"markdown","ba1ff694":"markdown","e1c8d861":"markdown","9d153eb6":"markdown","41ad258d":"markdown","565b4465":"markdown","90bad225":"markdown","cc9c4215":"markdown","4654fb66":"markdown","5a530d5c":"markdown","c3da1dce":"markdown","dc7f3fb1":"markdown","a2b58f80":"markdown","1a7a8bb6":"markdown","33390cc6":"markdown","6e6779a5":"markdown"},"source":{"d8f3cf77":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport category_encoders as ce #encoding\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA #dim red\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR \n\n\n\n%matplotlib inline\n\nimport warnings # current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings(\"ignore\")\n#import seaborn as sns\n#import matplotlib.pyplot as plt\nsb.set(style=\"white\", color_codes=True)","c4f9b126":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\niris = pd.read_csv(\"..\/input\/iris\/Iris.csv\") #load the dataset\niris.head()","dbd02bfb":"iris.shape #Shape of dataset","3ef94f52":"iris.columns # Cloumns present in dataset","c32d6246":"# Let's see how many examples we have of each species\niris[\"Species\"].value_counts()","193c5fbe":"iris.describe() # Describe statistics of the dataset","c8c7994a":"iris.info() # Informantion of dataset","4da955c2":"iris.isnull().sum() #checking for missng values","5d8a8e19":"x1=iris.SepalLengthCm\ny1=iris.SepalWidthCm\nx2=iris.PetalLengthCm\ny2=iris.PetalWidthCm\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\nplt.subplot(1,2,1)\nplt.scatter(x1,y1) \nplt.xlabel('SepalLengthCm')\nplt.ylabel('SepalWidthCm')\nplt.subplot(1,2,2)\nplt.scatter(x2, y2) # We'll plot a scatterplot of the Iris features using .plot\nplt.xlabel('PetalLengthCm')\nplt.ylabel('PetalWidthCm')\nplt.tight_layout(pad=5)","95733eb4":"# We can also use the seaborn library to make a similar plot\n# A seaborn jointplot shows bivariate scatterplots and univariate histograms in the same figure\nsb.jointplot(x1, y1, data=iris, size=5)\nsb.jointplot(x2, y2, data=iris, size=5)","24f92f80":"# One piece of information missing in the plots above is what species each plant is\n# We'll use seaborn's FacetGrid to color the scatterplot by species\nsb.FacetGrid(iris, hue=\"Species\", size=5) \\\n   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n   .add_legend()\nsb.FacetGrid(iris, hue=\"Species\", size=5) \\\n   .map(plt.scatter, \"PetalLengthCm\", \"PetalWidthCm\") \\\n   .add_legend()","4fd1b6d6":"# We can look at an individual feature in Seaborn through a boxplot\nsb.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)","6bc7008f":"# One way we can extend this plot is adding a layer of individual points on top of it through Seaborn's striplot\n# \n# We'll use jitter=True so that all the points don't fall in single vertical lines above the species\n#\n# Saving the resulting axes as ax each time causes the resulting plot to be shown on top of the previous axes\nax = sb.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)\nax = sb.stripplot(x=\"Species\", y=\"PetalLengthCm\", data=iris, jitter=True, edgecolor=\"gray\")","ea7b50b8":"# A violin plot combines the benefits of the previous two plots and simplifies them\n# Denser regions of the data are fatter, and sparser thiner in a violin plot\nsb.violinplot(x=\"Species\", y=\"PetalLengthCm\", data=iris, size=6)","2bff4a2f":"# A final seaborn plot useful for looking at univariate relations is the kdeplot,\n# which creates and visualizes a kernel density estimate of the underlying feature\nsb.FacetGrid(iris, hue=\"Species\", size=6) \\\n   .map(sb.kdeplot, \"PetalLengthCm\") \\\n   .add_legend()","3fceda05":"# Another useful seaborn plot is the pairplot, which shows the bivariate relation\n# between each pair of features\n# \n# From the pairplot, we'll see that the Iris-setosa species is separataed from the other\n# two across all feature combinations\nsb.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", size=3)","ae0c169b":"# The diagonal elements in a pairplot show the histogram by default\n# We can update these elements to show other things, such as a kde\nsb.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", size=3, diag_kind=\"kde\")","dcb9565c":"# Now that we've covered seaborn, let's go back to some of the ones we can make with Pandas\n# We can quickly make a boxplot with Pandas on each feature split out by species\niris.drop(\"Id\", axis=1).boxplot(by=\"Species\", figsize=(12, 6))","b9dbf080":"# One cool more sophisticated technique pandas has available is called Andrews Curves\n# Andrews Curves involve using attributes of samples as coefficients for Fourier series\n# and then plotting these\nfrom pandas.plotting import andrews_curves\nandrews_curves(iris.drop(\"Id\", axis=1), \"Species\")","a3e9ec4f":"# Another multivariate visualization technique pandas has is parallel_coordinates\n# Parallel coordinates plots each feature on a separate column & then draws lines\n# connecting the features for each data sample\nfrom pandas.plotting import parallel_coordinates\nparallel_coordinates(iris.drop(\"Id\", axis=1), \"Species\")","649fd1b4":"# A final multivariate visualization technique pandas has is radviz\n# Which puts each feature as a point on a 2D plane, and then simulates\n# having each sample attached to those points through a spring weighted\n# by the relative value for that feature\nfrom pandas.plotting import radviz\nradviz(iris.drop(\"Id\", axis=1), \"Species\")","ac939540":"X = iris.drop(['Species'],axis=1)\ny = iris.Species","f60bebda":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX=scaler.fit_transform(X)","4ace63de":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=20, stratify=y)","c3310d82":"knn = KNeighborsClassifier(7)\nknn.fit(X_train,y_train)\nprint(\"Train score before PCA\",knn.score(X_train,y_train))\nprint(\"Test score before PCA\",knn.score(X_test,y_test))","fcd2f250":"from sklearn.decomposition import PCA\npca = PCA()\nX_new = pca.fit_transform(X)","fc9a7fec":"pca.get_covariance()","8ae999b6":"explained_variance=pca.explained_variance_ratio_\nexplained_variance","ed9e1b93":"pca=PCA(n_components=3)\nX_new=pca.fit_transform(X)","58ba133f":"X_train_new, X_test_new, y_train, y_test = train_test_split(X_new, y, test_size = 0.3, random_state=20, stratify=y)","06f23058":"knn_pca = KNeighborsClassifier(7)\nknn_pca.fit(X_train_new,y_train)\nprint(\"Train score after PCA\",knn_pca.score(X_train_new,y_train))\nprint(\"Test score after PCA\",knn_pca.score(X_test_new,y_test))","66073cf7":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(max_iter = 500000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\naccuracy = model.score(X_test, y_test)\nprint(accuracy)","21ac75ab":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test,y_pred))","4ff059c5":"from sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\naccuracies.mean()","0a03a1a1":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nclassifier=GaussianNB()\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\nacc=accuracy_score(y_test, y_pred)\nprint(acc)","c86bed9b":"#set ids as PassengerId and predict survival \ny_test=pd.DataFrame(y_test)\nids = y_test.index\nids","b5872178":"#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'Id' : ids, 'Species': y_pred })\noutput.to_csv('submission.csv', index=False)","512797f1":"Attribute Information:\n1. sepal length in cm \n2. sepal width in cm \n3. petal length in cm \n4. petal width in cm \n5. class: (a)Iris Setosa (b) Iris Versicolour (c) Iris Virginica","fcc4a9b3":"Patal Length of \n- Setosa is b\/w 1 to 2 Cm & spread is narrow\n- Versicolor is b\/w 2.5 to 5.5 Cm & spread is little wide\n- Virginica is b\/w 4 to 7.5 & spread is little wide\n- There is overlap b\/w Versicolor& Virginica b\/w 4 to 5.5.","a5db5675":"About Petal Lenth data :\n- All 3 species data is having some outliers\n- All 3 species data is symmetical\n- Spread of Setosa is narrow compared with other two species.\n- Virginica data is little skewed on upper side.","e3d75a0f":"### Import the packages","c3b0b7ff":"## Data Loading and description","b5a45987":"### Import the data and Initial understanding of dataset","ba1ff694":"## Model using Naive Bayes Algorithm","e1c8d861":"## Model using SVM (Support Vector Machine)","9d153eb6":"<img src=\"https:\/\/miro.medium.com\/max\/1400\/0*QHogxF9l4hy0Xxub.png\" width=\"540\" height=\"450\" \/>","41ad258d":"## Iris Species Classification Problem","565b4465":"<img src=\"https:\/\/miro.medium.com\/max\/1400\/0*SHhnoaaIm36pc1bd\" width=\"540\" height=\"450\" \/>","90bad225":"No missing values","cc9c4215":"## Model using KNN with PCA","4654fb66":"## Data Visualization and EDA(Exploratory Data Analysis)","5a530d5c":"- There are 3 Species i.e. Setosa, Versicolor & Vriginica.\n- In Sepal data Setosa has clear split from the other two species (which have overalpped points).\n- In Petal data all the 3 species are having split from one another, wtith ovarlap b\/w versicolor & virginica.","c3da1dce":"- Data points of Sepal are spreaded all over. However, there is a split in data over top left corner side.\n- Data points of petal are splitted in to two clusters.","dc7f3fb1":"- Petal Length data points of setosa are denser at mean compared to other two species.","a2b58f80":"- Sepal data is normally distributed (data is almost symmentric about the mean & more data points are near mean).\n- Petal data is not normally distributed (not symmentric about the mean & data points near mean are not more than data points away from the mean).","1a7a8bb6":"## Model using KNN without PCA (Principal Component Analysis)","33390cc6":"## Model using Logistic Regression","6e6779a5":"### We'll plot a scatterplot of the Iris features using plt.scatter"}}