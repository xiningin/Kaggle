{"cell_type":{"9fe1a439":"code","9256b057":"code","326f74d4":"code","2ffdf155":"code","e528f40b":"code","d0fef298":"code","4bfd102c":"code","fdeddc4d":"code","cff3c7d9":"code","7eb00142":"code","4e8831c3":"code","68e3e98e":"code","09c314c2":"code","3cd159bb":"code","aba2a033":"code","bd28c330":"code","447f5421":"code","315fa915":"markdown","25f59886":"markdown","9dc6e53c":"markdown","96094eda":"markdown","9cb605a9":"markdown","879cdf63":"markdown","ff39d0d0":"markdown","d5ed2b41":"markdown","4bd50706":"markdown"},"source":{"9fe1a439":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob, re\nfrom sklearn import *\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\nfrom math import ceil\nimport time\nimport sys\nimport gc\nimport pickle\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\nimport jpholiday\nimport xgboost as xgb\nimport matplotlib\nfrom matplotlib import pylab as plt\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nmatplotlib.font_manager._rebuild()\nplt.rcParams[\"font.family\"] = \"IPAexGothic\"\n%matplotlib inline\n\nsns.set()\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_cross_validation_metric\nfrom fbprophet.diagnostics import cross_validation\nfrom fbprophet.diagnostics import performance_metrics\nfrom datetime import datetime\nimport datetime as dt\nimport datetime\nimport calendar\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\nimport lightgbm as lgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pytrends.request import TrendReq\nfrom datetime import date, timedelta\nfrom pandas.plotting import scatter_matrix\n","9256b057":"items = pd.read_csv('items.csv')\nshops = pd.read_csv('shops.csv')\ncats = pd.read_csv('item_categories.csv')\ntrain = pd.read_csv('sales_train.csv',parse_dates=[\"date\"])\ntest  = pd.read_csv('test.csv').set_index('ID')","326f74d4":"#refuce memory\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    return df","2ffdf155":"items.head()\ndel items['item_name']\ngc.collect()\ntrain = pd.merge(train, items, on= 'item_id', how='left')\ntest = pd.merge(test, items, on= 'item_id', how='left')\nreduce_mem_usage(train)\nreduce_mem_usage(test)","e528f40b":"#data details\ntrain.describe()","d0fef298":"#unique number\nprint('Unique shop_id number is', train.shop_id.nunique())\nprint('Unique item_id number is', train.item_id.nunique())\nprint('Unique item_category_id number is', train.item_category_id.nunique())","4bfd102c":"# add time features\ntrain['date_year'] = train['date'].dt.year\ntrain['date_quarter'] = train['date'].dt.quarter\ntrain['week_count'] = train['date'].dt.week\ntrain['date_month'] = train['date'].dt.month\ntrain['date_day'] = train['date'].dt.day\ntrain['date_dow'] = train['date'].dt.weekday","fdeddc4d":"#item_id per item_category_id\nx=train.groupby(['item_category_id']).count()\nx=x.sort_values(by='item_id',ascending=False)\nx=x.reset_index()\nplt.figure(figsize=(20,8))\nax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"item_id per item_category_id\")\nplt.ylabel('# of item_id', fontsize=12)\nplt.xlabel('item_category_id', fontsize=12)","cff3c7d9":"#ishop_id per item_category_id\nx=train.groupby(['item_category_id']).count()\nx=x.sort_values(by='shop_id',ascending=False)\nx=x.reset_index()\nplt.figure(figsize=(20,8))\nax= sns.barplot(x.item_category_id, x.shop_id, alpha=0.8)\nplt.title(\"shop_id per item_category_id\")\nplt.ylabel('# of shop_id', fontsize=12)\nplt.xlabel('item_category_id', fontsize=12)","7eb00142":"#box plot \nplt.rcParams[\"font.family\"] = \"IPAexGothic\"\n\nvar = 'item_category_id'\ndata = pd.concat([train['item_cnt_day'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(50, 10))\nfig = sns.boxplot(x=var, y=\"item_cnt_day\", data=data)\nfig.axis(ymin=0, ymax=1000);","4e8831c3":"#box plot \nplt.rcParams[\"font.family\"] = \"IPAexGothic\"\n\nvar = 'item_category_id'\ndata = pd.concat([train['item_cnt_day'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(40, 5))\nfig = sns.boxplot(x=var, y=\"item_cnt_day\", data=data)\nfig.axis(ymin=0, ymax=100);","68e3e98e":"plt.rcParams[\"font.family\"] = \"IPAexGothic\"\nx=train.groupby(['date_year']).mean()\nx=x.sort_values(by='item_cnt_day',ascending=False)\nx=x.reset_index()\n# #plot\nplt.figure(figsize=(10,10))\nax= sns.barplot(x.date_year, x.item_cnt_day, alpha=0.8)\nplt.title(\"item_cnt_day per date_year\")\nplt.ylabel('# of item_cnt_day', fontsize=12)\nplt.xlabel('date_year', fontsize=12)\n\nplt.show()","09c314c2":"plt.rcParams[\"font.family\"] = \"IPAexGothic\"\nx=train.groupby(['date_month']).mean()\nx=x.sort_values(by='item_cnt_day',ascending=False)\nx=x.reset_index()\n# #plot\nplt.figure(figsize=(10,10))\nax= sns.barplot(x.date_month, x.item_cnt_day, alpha=0.8)\nplt.title(\"item_cnt_day per date_month\")\nplt.ylabel('# of item_cnt_day', fontsize=12)\nplt.xlabel('date_month', fontsize=12)\n\nplt.show()","3cd159bb":"plt.rcParams[\"font.family\"] = \"IPAexGothic\"\nx=train.groupby(['date_day']).mean()\nx=x.sort_values(by='item_cnt_day',ascending=False)\nx=x.reset_index()\n# #plot\nplt.figure(figsize=(10,10))\nax= sns.barplot(x.date_day, x.item_cnt_day, alpha=0.8)\nplt.title(\"item_cnt_day per date_day\")\nplt.ylabel('# of item_cnt_day', fontsize=12)\nplt.xlabel('date_day', fontsize=12)\n\nplt.show()","aba2a033":"####In fact I usually do this after I create more features#####\n#features correlation\ncorrmat =train.corr()\nf, ax = plt.subplots(figsize=(10, 10))\nsns.set(font_scale=1.00)\nsns.heatmap(corrmat, vmax=.8, square=True,annot=True, fmt= '.2f')","bd28c330":"####In fact I usually do this after I create more features#####\ncols = ['item_cnt_day', 'item_id', 'item_price','shop_id'] \nsns.set(font_scale=1.25)\nsns.pairplot(train[cols], size=3)\nplt.show();","447f5421":"to be continue","315fa915":"# import","25f59886":"let's zoom in this details ","9dc6e53c":"some item_categories have many shops. top #17 we can figure out what category is\n\n","96094eda":"# Extract the data","9cb605a9":"some item_categories have many items.  top #17 \nwe can figure out what category is\n","879cdf63":"It seems the average number of sales(item_cnt day) is same in year","ff39d0d0":"#8#9#71 category items are sold a lot","d5ed2b41":"It seems the average number of sales(item_cnt day) is different is month","4bd50706":"It seems the average number of sales(item_cnt day) is different in a day"}}