{"cell_type":{"11691afe":"code","7e5ee1fb":"code","0f7ce40f":"code","edfcd3cf":"code","994a6517":"code","58cbd662":"code","324617db":"code","5ab0229f":"code","37364d37":"code","d6357ab3":"code","31f23ed1":"code","709ae0d9":"code","fa5c9857":"code","8380dd5c":"code","78c4a2a0":"code","25d95ed4":"code","79566d59":"code","b0668413":"code","6662031a":"code","fce30363":"code","21925c47":"code","9e7ff254":"code","066c6079":"code","c4d9d13b":"code","73303089":"code","ac6ea9b8":"code","abc998ca":"code","6bed6267":"code","4e177bb6":"code","ca4df9e3":"code","c8e15633":"markdown","c4d5754a":"markdown","b4e0f2ed":"markdown","2a171158":"markdown","878879c2":"markdown"},"source":{"11691afe":"import numpy as np    # linear algebra\nimport pandas as pd   # data processing\nimport matplotlib.pyplot as plt   # data visualization\nimport cv2            # image processing","7e5ee1fb":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Dense,MaxPooling2D, Dropout\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras import optimizers\nimport os","0f7ce40f":"pip install imutils","edfcd3cf":"from imutils import paths\nimage_paths = list(paths.list_images('..\/input\/leaf-count'))","994a6517":"x='..\/input\/leaf-count\/1\/1.png'\ny=x.split(os.path.sep)[-2]","58cbd662":"data = []\nlabels = []\nlabel_names = []\n\n\nfor i in image_paths:\n    image = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image,(80,80))\n    data.append(image)\n    label = i.split(os.path.sep)[-2]\n    labels.append(label)\n    label_names.append(label)","324617db":"import matplotlib.pyplot as plt","5ab0229f":"image1 = cv2.imread(\"..\/input\/leaf-count\/3\/10.png\")\nimage1 = cv2.resize(image1, (80,80))\nimage2 = cv2.imread(\"..\/input\/leaf-count\/2\/100.png\")\nimage2 = cv2.resize(image2, (80,80))\nimage3 = cv2.imread(\"..\/input\/leaf-count\/1\/106.png\")\nimage3 = cv2.resize(image3, (80,80))\nimage4 = cv2.imread(\"..\/input\/leaf-count\/6\/107.png\")\nimage4 = cv2.resize(image4, (80,80))","37364d37":"fig=plt.figure(figsize=(10, 10))\nimage = [image1,image2,image3,image4]\n\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    plt.imshow(image[i])\n    plt.axis('off')\n\nplt.show()","d6357ab3":"image1.shape","31f23ed1":"data2 = np.array(data)\nlabels2 = np.array(labels)","709ae0d9":"from sklearn.preprocessing import LabelBinarizer\nlb = LabelBinarizer()\nlabels2 = lb.fit_transform(labels2)\nprint(f\"total class number:{len(lb.classes_)}\")","fa5c9857":"from sklearn.model_selection import train_test_split","8380dd5c":"(X, x_val , Y, y_val) = train_test_split(data2, labels2, \n                                                    test_size=0.2,  \n                                                    stratify=labels2,\n                                                    random_state=0)","78c4a2a0":"(x_train, x_test, y_train, y_test) = train_test_split(X, Y, \n                                                    test_size=0.25, \n                                                    random_state=0)","25d95ed4":"print(f\"x_train examples: {x_train.shape}\\n x_test examples: {x_test.shape}\\n x_val examples: {x_val.shape}\")","79566d59":"print(x_train.shape,y_train.shape)","b0668413":"x_train2 = np.array(x_train)\/255\nx_train2 = x_train.reshape(-1,80,80,1)\ny_train2 = np.array(y_train)","6662031a":"x_val2 = np.array(x_val)\/255.0\nx_val2 = x_val.reshape(-1,80,80,1)\ny_val2 = np.array(y_val)","fce30363":"print(x_train2.shape,y_train2.shape)","21925c47":"x_val2.shape","9e7ff254":"model = Sequential()\n\nmodel.add(Conv2D(32, (3,3), padding =\"same\", activation = 'relu', input_shape=(80,80,1)))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(9, activation = 'softmax'))","066c6079":"model.summary()","c4d9d13b":"model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])","73303089":"history = model.fit(x_train2, y_train2, epochs=100, batch_size=32, validation_data = (x_val2, y_val2),verbose=1)","ac6ea9b8":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","abc998ca":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Training Loss vs Validation Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","6bed6267":"image3 = cv2.imread(\"..\/input\/leaf-count\/2\/10.png\")\nimage3 = cv2.resize(image3, (80,80))\nimage3 = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\nx= image3.reshape(1,80,80,1)\nx.shape\nplt.imshow(image3)","4e177bb6":"plt.figure(figsize=(10, 10))\n\npredictions = model.predict(x)\nprint(predictions)\n#ax = plt.subplot(10, 4)\nplt.imshow(predictions)\nplt.title('Predicted label:')\nplt.axis('off')\nplt.grid(True)","ca4df9e3":"df1 = pd.DataFrame(predictions)\ndf2 = df1.T\ndf2.columns = ['predict number']\ndf2['Leaf number'] = ['1','2','3','4','5','6','7','8','9+']\n\ndf2[[\"predict number\",\"Leaf number\"]].groupby([\"Leaf number\"], \n                                    as_index = True).mean().sort_values(by = \"predict number\",\n               axis = 0,\n               ascending = True).plot(kind=\"barh\",color=\"green\")\nplt.xlabel(\"Leaf count predictions\")","c8e15633":"Immutils is a series of convenience functions to make basic image processing functions such as translation, rotation, resizing and display matplotlib images easier with OpenCV.","c4d5754a":"Label encoder enables us to convert categorical paramaters to numerical paramaters. Numarical paramaters are useful for training algorithm.\nThe purpose of encoding label values is to ensure that the class with label value 9 does not appear to be more important than the class with label value 1.","b4e0f2ed":"grap the image paths and list them","2a171158":"we create data list and label list in the feature we use them for training","878879c2":"We arrange the data of the list type into an array."}}