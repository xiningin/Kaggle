{"cell_type":{"d5530def":"code","ec74805d":"code","fc304190":"code","d0f150f4":"code","a83fd01f":"code","cb800ca3":"code","6f002bd6":"code","007cff6f":"code","1d0e8a7b":"code","dd673a95":"code","f18feb02":"code","e6748a40":"code","55e20a8c":"code","04329b44":"code","0566539e":"code","26fbe098":"code","324e344d":"code","c8b486a8":"code","bee9544d":"code","c72887d7":"code","c662b361":"code","644d181f":"code","93956ecb":"code","495dc030":"code","349cd5ea":"code","107c1370":"code","c81f644e":"code","ccfa73f4":"code","c3fc1fdf":"code","fa75bfa6":"code","dac7327f":"code","dfe08e21":"code","ed5bb4cf":"code","c9242181":"code","37ba26e9":"code","ba66dced":"code","5e742280":"markdown","9506d8c5":"markdown","8c65e71e":"markdown","4b5f4ad8":"markdown","280b3e9f":"markdown","93916c31":"markdown","a66509cf":"markdown","2edd0d05":"markdown","219de58a":"markdown","554a9fab":"markdown","c10f50e4":"markdown","bd6af97a":"markdown","ba54ad4d":"markdown","1a67c4d6":"markdown"},"source":{"d5530def":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ec74805d":"df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nprint(list(df.columns))\n\n#rename the columns\ndf.rename(columns={'Q1':'age','Q3': 'country', 'Q4':'education','Q5':'role', 'Q6':'pg_exp', 'Q24':'compensation', 'Q25':'cost'}, inplace=True)\n\n#rename the countries to match the country references data type that will be used later\ndf.loc[df['country'] == 'United Kingdom of Great Britain and Northern Ireland',['country']] = 'United Kingdom'\ndf.loc[df['country'] == 'United States of America',['country']] = 'United States'\ndf.loc[df['country'] == 'Iran, Islamic Republic of...', ['country']] = 'Iran'\ndf.loc[df['country'] == 'Viet Nam', ['country']] = 'Vietnam'\ndf.loc[df['country'] == 'Republic of Korea', ['country']] = 'South Korea'","fc304190":"df.head()","d0f150f4":"df['country'].unique()","a83fd01f":"df.describe()","cb800ca3":"countries_summary = df.loc[1:, ['country']].groupby('country')['country'].count()\ncountries_summary_df = countries_summary.to_frame(name='respondents')\ncountries_summary_df.reset_index(inplace=True)\n\ncountries_summary_df","6f002bd6":"countries_df = pd.read_csv('\/kaggle\/input\/latitude-and-longitude-for-every-country-and-state\/world_country_and_usa_states_latitude_and_longitude_values.csv')\ncountries_df.head()\n#countries_df.query(\"country.str.contains('Korea')\", engine='python')","007cff6f":"#show the survey respondents' current residence\ncountries_summary_df = pd.merge(countries_summary_df, countries_df, on='country')\nfig = px.scatter_geo(countries_summary_df, lat=countries_summary_df.latitude, lon=countries_summary_df.longitude, color=\"country\",\n                     hover_name=\"country\", size=\"respondents\", title=\"Which country do the respondents reside\",\n                     projection=\"natural earth\")\nfig.show()","1d0e8a7b":"def change_range_values(x):\n    if (isinstance(x, float)):\n        return 0\n    \n    if (x == '> $500,000'):\n        return 500000\n    \n    if (x == '$100,000 or more ($USD)'):\n        return 100000\n        \n    l = []\n    for s in x.split('-'):\n        i = s.replace(',','').replace('$','').replace('>','')\n        if (i.isnumeric()):\n            l.append(int(i))\n        else:\n            return 0\n    \n    return np.mean(l)\n\ndf['compensation_mean'] = df.loc[:, 'compensation'].apply(lambda x: change_range_values(x))\ndf['cost_mean'] = df.loc[:, 'cost'].apply(lambda x: change_range_values(x))\n\ndf.loc[:, ['compensation', 'compensation_mean','cost','cost_mean']]\n\n#df['compensation_mean'].unique()","dd673a95":"#show the survey respondents' income\nwith_compensation_df = df.loc[df['compensation_mean'] > 0]\ncountries_income_summary_df = with_compensation_df.loc[1:,['country', 'compensation_mean']].groupby('country').agg({'compensation_mean':'mean'}).reset_index()\ncountries_income_summary_df = pd.merge(countries_income_summary_df, countries_df, on='country')\ncountries_income_summary_df\nfig = px.scatter_geo(countries_income_summary_df, lat=countries_income_summary_df.latitude, lon=countries_income_summary_df.longitude, color=\"country_code\",\n                     hover_name=\"country\", size=\"compensation_mean\", title=\"What is the average compensation of the respondents per country of residence?\",\n                     projection=\"natural earth\")\nfig.show()","f18feb02":"role_summary = df.loc[1:, ['role']].groupby(['role'])['role'].count()\nrole_summary_df = role_summary.to_frame(name='respondents')\nrole_summary_df.reset_index(inplace=True)\n\nrole_summary_df['percentage'] = role_summary_df['respondents'] \/ role_summary_df['respondents'].sum()\n\nrole_summary_df","e6748a40":"#show the education level of the respondents\nsns.set(rc={'figure.figsize':(30,20)})\nax = sns.barplot(x=\"percentage\", y=\"role\", data=role_summary_df)\nax.set_title('What are the roles of respondents', fontsize=20)","55e20a8c":"def get_sum(df, q, r, p='Part', o = 'OTHER'):\n    '''\n      df - the dataframe\n      q - the question number e.g. Q7\n      r - the range e.g. 1 to 12, to represent Q7_Part1 up to Q7_Part_11\n      o - this is the OTHER choice, e.g. Q7_OTHER\n    '''\n    c = []\n    k = []\n    for i in r:\n        s = q + '_' + p + '_' + str(i)\n        k.append(df[s].dropna().unique()[0])\n        c.append(df[s].notnull().sum())\n    return k,c","04329b44":"def get_language_reg(df, top):\n    k, c = get_sum(df, 'Q7', np.arange(1, 13))\n    d = {'language_reg': k, 'count': c}\n    df = pd.DataFrame(d)\n    df['percentage'] = df['count'] \/ df['count'].sum()\n    return df.nlargest(top, 'percentage')","0566539e":"def get_ide(df, top):\n    k, c = get_sum(df, 'Q9', np.arange(1, 12))\n    d = {'ide': k, 'count': c}\n    df = pd.DataFrame(d)\n    df['percentage'] = df['count'] \/ df['count'].sum()\n    return df.nlargest(top, 'percentage')","26fbe098":"def get_notebook(df, top):\n    k, c = get_sum(df, 'Q10', np.arange(1, 14))\n    d = {'notebook': k, 'count': c}\n    df = pd.DataFrame(d)\n    df['percentage'] = df['count'] \/ df['count'].sum()\n    return df.nlargest(top, 'percentage')","324e344d":"def get_visual(df, top):\n    k, c = get_sum(df, 'Q14', np.arange(1, 12))\n    d = {'visual': k, 'count': c}\n    df = pd.DataFrame(d)\n    df['percentage'] = df['count'] \/ df['count'].sum()\n    return df.nlargest(top, 'percentage')","c8b486a8":"pg_df = df.loc[~df['role'].isin(['Student','Other', 'Currently not employed']) & df['pg_exp'].isin(['5-10 years','10-20 years', '20+ years'])]","bee9544d":"# programming languages used by more experienced persons\n\nlanguage_reg_df = get_language_reg(pg_df, 3)\nlanguage_reg_df['Role'] = 'Professional'\nlanguage_reg_df = language_reg_df.drop(columns = ['count'])\n\nlanguage_reco = pg_df.groupby('Q8')['Q8'].count()\nlanguage_reco_df = language_reco.to_frame(name='count')\nlanguage_reco_df.reset_index(inplace=True)\nlanguage_reco_df['percentage'] = language_reco_df['count'] \/ language_reco_df['count'].sum()\nlanguage_reco_df = language_reco_df.nlargest(3, 'percentage')\n\nide_df = get_ide(pg_df, 3)\nide_df['Role'] = 'Professional'\nide_df = ide_df.drop(columns = ['count'])\n\nnotebook_df = get_notebook(pg_df, 3)\nnotebook_df['Role'] = 'Professional'\nnotebook_df = notebook_df.drop(columns = ['count'])\n\nvisual_df = get_visual(pg_df, 3)\nvisual_df['Role'] = 'Professional'\nvisual_df = visual_df.drop(columns = ['count'])\n\nsns.set(rc={'figure.figsize':(30,20)})\nfig, axs = plt.subplots(3, 2)\n\nsns.barplot(x=\"language_reg\", y=\"percentage\", data=language_reg_df, ax=axs[0,0])\naxs[0,0].set_title('Top 3 Languages Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"Q8\", y=\"percentage\", data=language_reco_df, ax=axs[0,1])\naxs[0,1].set_title('Top 3 Languages Recommended by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"ide\", y=\"percentage\", data=ide_df, ax=axs[1,0])\naxs[1,0].set_title('Top 3 IDEs Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"notebook\", y=\"percentage\", data=notebook_df, ax=axs[1,1])\naxs[1,1].set_title('Top 3 Hosted Notebooks Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"visual\", y=\"percentage\", data=visual_df, ax=axs[2,0])\naxs[2,0].set_title('Top 3 Visualization Tool Regularly Used by Users with 5 or more years of Experience');","c72887d7":"# hardware used by more experienced persons\ncomputing = pg_df.groupby('Q11')['Q11'].count()\ncomputing_df = computing.to_frame(name='count')\ncomputing_df.reset_index(inplace=True)\ncomputing_df['percentage'] = computing_df['count'] \/ computing_df['count'].sum()\ncomputing_df = computing_df.nlargest(3, 'percentage')\n\nk, c = get_sum(pg_df, 'Q12', np.arange(1, 4))\nd = {'hw_special': k, 'count': c}\nhw_special_df = pd.DataFrame(d)\nhw_special_df['percentage'] = hw_special_df['count'] \/ hw_special_df['count'].sum()\nhw_special_df = hw_special_df.nlargest(3, 'count')\n\ntpu = pg_df.groupby('Q13')['Q13'].count()\ntpu_df = tpu.to_frame(name='count')\ntpu_df.reset_index(inplace=True)\ntpu_df['percentage'] = tpu_df['count'] \/ tpu_df['count'].sum()\n\nsns.set(rc={'figure.figsize':(30,10)})\nfig, axs = plt.subplots(1, 3)\n\nax_q11 = sns.barplot(x=\"Q11\", y=\"percentage\", data=computing_df, ax=axs[0])\naxs[0].set_title('Top 3 Computing Platform Most Often Used by Users with 5 or more years of Experience')\nax_q11.set_xticklabels(ax_q11.get_xticklabels(), \n                          rotation=45, \n                          horizontalalignment='right')\nsns.barplot(x=\"hw_special\", y=\"percentage\", data=hw_special_df, ax=axs[1])\naxs[1].set_title('Top 3 Specialized Hardware Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"Q13\", y=\"percentage\", data=tpu_df, ax=axs[2])\naxs[2].set_title('No of times TPU is used by Users with 5 or more years of Experience');","c662b361":"# advanced topics\nmachine_learning_exp = pg_df.groupby('Q15')['Q15'].count()\nmachine_learning_exp_df = machine_learning_exp.to_frame(name='count')\nmachine_learning_exp_df.reset_index(inplace=True)\nmachine_learning_exp_df ['percentage'] = machine_learning_exp_df['count'] \/ machine_learning_exp_df['count'].sum()\n\nsns.set(rc={'figure.figsize':(30,30)})\nax = sns.barplot(x=\"percentage\", y=\"Q15\", data=machine_learning_exp_df)\nax.set_title('Years of Machine Learning Experience of Users with 5 or more years of Experience', fontsize=20);\n","644d181f":"# ML used by more experienced persons\nk, c = get_sum(pg_df, 'Q16', np.arange(1, 16))\nd = {'ml_framework': k, 'count': c}\nml_framework_df = pd.DataFrame(d)\nml_framework_df['percentage'] = ml_framework_df['count'] \/ ml_framework_df['count'].sum()\nml_framework_df = ml_framework_df.nlargest(3, 'percentage')\n\nk, c = get_sum(pg_df, 'Q17', np.arange(1, 12))\nd = {'ml_algo': k, 'count': c}\nml_algo_df = pd.DataFrame(d).nlargest(3, 'count')\n\nk, c = get_sum(pg_df, 'Q18', np.arange(1, 7))\nd = {'vision': k, 'count': c}\nvision_df = pd.DataFrame(d).nlargest(3, 'count')\n\nk, c = get_sum(pg_df, 'Q19', np.arange(1, 6))\nd = {'nlp': k, 'count': c}\nnlp_df = pd.DataFrame(d).nlargest(3, 'count')\n\nsns.set(rc={'figure.figsize':(30,20)})\nfig, axs = plt.subplots(2, 2)\n\nsns.barplot(x=\"ml_framework\", y=\"percentage\", data=ml_framework_df, ax=axs[0,0])\naxs[0,0].set_title('Top 3 ML Frameworks Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"ml_algo\", y=\"count\", data=ml_algo_df, ax=axs[0,1])\naxs[0,1].set_title('Top 3 ML Algo  Regularly Used by Users with 5 or more years of Experience')\n\nax_vision = sns.barplot(x=\"vision\", y=\"count\", data=vision_df, ax=axs[1,0])\naxs[1,0].set_title('Top 3 Computer Vision Methods Regularly Used by Users with 5 or more years of Experience')\nax_vision.set_xticklabels(ax_vision.get_xticklabels(), \n                          rotation=45, \n                          horizontalalignment='right')\n\nax_nlp = sns.barplot(x=\"nlp\", y=\"count\", data=nlp_df, ax=axs[1,1])\naxs[1,1].set_title('Top 3 NLP Regularly Used by Users with 5 or more years of Experience')\n\nax_nlp.set_xticklabels(ax_nlp.get_xticklabels(), \n                          rotation=45, \n                          horizontalalignment='right');\n","93956ecb":"k, c = get_sum(pg_df, 'Q26_A', np.arange(1, 12))\nd = {'cloud_computing_platform': k, 'count': c}\ncloud_computing_platform_df = pd.DataFrame(d)\ncloud_computing_platform_df['percentage'] = cloud_computing_platform_df['count'] \/ cloud_computing_platform_df['count'].sum()\ncloud_computing_platform_df = cloud_computing_platform_df.nlargest(3, 'count')\n\nk, c = get_sum(pg_df, 'Q27_A', np.arange(1, 12))\nd = {'cloud_computing_products': k, 'count': c}\ncloud_computing_products_df = pd.DataFrame(d)\ncloud_computing_products_df['percentage'] = cloud_computing_products_df['count'] \/ cloud_computing_products_df['count'].sum()\ncloud_computing_products_df = cloud_computing_products_df.nlargest(3, 'count')\n\nk, c = get_sum(pg_df, 'Q28_A', np.arange(1, 11))\nd = {'machine_learning_products': k, 'count': c}\nmachine_learning_products_df = pd.DataFrame(d)\nmachine_learning_products_df['percentage'] = machine_learning_products_df['count'] \/ machine_learning_products_df['count'].sum()\nmachine_learning_products_df = machine_learning_products_df.nlargest(3, 'count')\n\nk, c = get_sum(pg_df, 'Q29_A', np.arange(1, 18))\nd = {'big_data_products': k, 'count': c}\nbig_data_products_df = pd.DataFrame(d)\nbig_data_products_df['percentage'] = big_data_products_df['count'] \/ big_data_products_df['count'].sum()\nbig_data_products_df = big_data_products_df.nlargest(3, 'count')\n\nsns.set(rc={'figure.figsize':(30,20)})\nfig, axs = plt.subplots(2, 2)\n\nsns.barplot(x=\"cloud_computing_platform\", y=\"percentage\", data=cloud_computing_platform_df, ax=axs[0,0])\naxs[0,0].set_title('Top 3 Cloud Computing Platform Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"cloud_computing_products\", y=\"percentage\", data=cloud_computing_products_df, ax=axs[0,1])\naxs[0,1].set_title('Top 3 Cloud Computing Products Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"machine_learning_products\", y=\"percentage\", data=machine_learning_products_df, ax=axs[1,0])\naxs[1,0].set_title('Top 3 Machine Learning Products Regularly Used by Users with 5 or more years of Experience')\n\nsns.barplot(x=\"big_data_products\", y=\"percentage\", data=big_data_products_df, ax=axs[1,1])\naxs[1,1].set_title('Top 3 Machine Learning Products Regularly Used by Users with 5 or more years of Experience');","495dc030":"student_df = df.loc[df['role'].isin(['Student'])]\nstudent_df","349cd5ea":"#show the survey students' current residence\ncountries_student_summary = student_df.loc[:, ['country']].groupby('country')['country'].count()\ncountries_student_summary_df = countries_student_summary.to_frame(name='respondents')\ncountries_student_summary_df.reset_index(inplace=True)\ncountries_student_summary_df","107c1370":"countries_student_summary_df = pd.merge(countries_student_summary_df, countries_df, on='country')\nfig = px.scatter_geo(countries_student_summary_df, lat=countries_student_summary_df.latitude, lon=countries_student_summary_df.longitude, color=\"country_code\",\n                     hover_name=\"country\", size=\"respondents\", title=\"Which country do the students reside\",\n                     projection=\"natural earth\")\nfig.show()","c81f644e":"pg_exp = student_df.groupby('pg_exp')['pg_exp'].count()\npg_exp_df = pg_exp.to_frame(name='count')\npg_exp_df.reset_index(inplace=True)\npg_exp_df['percentage'] = pg_exp_df['count'] \/ pg_exp_df['count'].sum()\n\nsns.set(rc={'figure.figsize':(10,10)})\nax = sns.barplot(x=\"percentage\", y=\"pg_exp\", data=pg_exp_df)\nax.set_title('Years of Programming Experience', fontsize=20);","ccfa73f4":"#programming languages used by students\nlanguage_reg_student_df = get_language_reg(student_df, 3)\nlanguage_reg_student_df['Role'] = 'Student'\nlanguage_reg_student_df = language_reg_student_df.drop(columns = ['count'])\nmerge_language_reg = pd.concat([language_reg_df, language_reg_student_df])\n\ng = sns.catplot(data=merge_language_reg, kind=\"bar\", x=\"language_reg\", y=\"percentage\", hue=\"Role\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6);\ng.fig.suptitle('Comparison of Programming Languages Used by Professionals and Students');","c3fc1fdf":"ide_student_df = get_ide(student_df, 3)\nide_student_df = ide_student_df.drop(columns=['count'])\nide_student_df['Role'] = 'Student'\nmerge_ide_df = pd.concat([ide_df, ide_student_df])\ng = sns.catplot(data=merge_ide_df, kind=\"bar\", x=\"ide\", y=\"percentage\", hue=\"Role\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6);\ng.fig.suptitle('Comparison of IDE Used by Professionals and Students')\ng.set_xticklabels(rotation=90);","fa75bfa6":"notebook_student_df = get_notebook(student_df, 3)\nnotebook_student_df = notebook_student_df.drop(columns=['count'])\nnotebook_student_df['Role'] = 'Student'\nmerge_notebook_df = pd.concat([notebook_df, notebook_student_df])\ng = sns.catplot(data=merge_notebook_df, kind=\"bar\", x=\"notebook\", y=\"percentage\", hue=\"Role\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6);\ng.fig.suptitle('Comparison of Visualization Tools Used by Professionals and Students')\ng.set_xticklabels(rotation=90);","dac7327f":"visual_student_df = get_visual(student_df, 3)\nvisual_student_df = visual_student_df.drop(columns=['count'])\nvisual_student_df['Role'] = 'Student'\nmerge_visual_df = pd.concat([visual_df, visual_student_df])\ng = sns.catplot(data=merge_visual_df, kind=\"bar\", x=\"visual\", y=\"percentage\", hue=\"Role\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6);\ng.fig.suptitle('Comparison of Visualization Tools Used by Professionals and Students')\ng.set_xticklabels(rotation=90);","dfe08e21":"# advanced topics\nmachine_learning_exp = student_df.groupby('Q15')['Q15'].count()\nmachine_learning_exp_df = machine_learning_exp.to_frame(name='count')\nmachine_learning_exp_df.reset_index(inplace=True)\nmachine_learning_exp_df.reset_index(inplace=True)\nmachine_learning_exp_df['percentage'] = machine_learning_exp_df['count'] \/ machine_learning_exp_df['count'].sum()\n\nsns.set(rc={'figure.figsize':(10,10)})\nax = sns.barplot(x=\"percentage\", y=\"Q15\", data=machine_learning_exp_df)\nax.set_title('Years of Machine Learning Experience', fontsize=20);","ed5bb4cf":"total_cost_mean = df[df['cost_mean'] > 0].mean()\ncountries_income_summary_df['cost_over_compensation'] = total_cost_mean['cost_mean'] \/ countries_income_summary_df['compensation_mean'] \n#countries_income_summary_df","c9242181":"sns.set(rc={'figure.figsize':(30,20)})\n\ncountries_more_than_xpct = countries_income_summary_df[countries_income_summary_df['cost_over_compensation'] > 1]\nax = sns.barplot(x=\"country\", y=\"compensation_mean\", data=countries_more_than_xpct)\nax.set_title('Compensation vs Cost', fontsize=20)\nax.axhline(total_cost_mean['cost_mean']);","37ba26e9":"#show the survey respondents' cost\nwith_cost_df = df.loc[df['cost_mean'] > 0]\ncountries_cost_summary_df = with_cost_df.loc[1:,['country', 'cost_mean']].groupby('country').agg({'cost_mean':'mean'}).reset_index()\ncountries_cost_summary_df = pd.merge(countries_cost_summary_df, countries_df, on='country')\ncountries_cost_summary_df\nfig = px.scatter_geo(countries_cost_summary_df, lat=countries_cost_summary_df.latitude, lon=countries_cost_summary_df.longitude, color=\"country_code\",\n                     hover_name=\"country\", size=\"cost_mean\", title=\"How much have been spent on machine learning per country ?\",\n                     projection=\"natural earth\")\nfig.show()","ba66dced":"#show the company size vs cost on machine learning\nsns.set(rc={'figure.figsize':(15,10)})\nax = sns.barplot(x=\"Q20\", y=\"cost_mean\", data=with_cost_df)\nax.set_title('How much have been spent on machine learning per company size', fontsize=20);","5e742280":"Students may need to study SQL as an additional programming language. As for the IDE, Notebook and Visualization tool, the students are using the same tools as the professionals.","9506d8c5":"## Programming Languages\nThe top programming languages currently used by professionals are Python, R and SQL. These are also the languages that they are recommending. \nThe top IDE is Jupyter Notebook and the two most popular notebooks are Collab and Kaggle","8c65e71e":"# CONCLUSION\n\n  The survey shows that twenty five percent(25%) of the respondents are students.  Most of these students are from India.  The students use almost the same programming languages, IDE, Notebooks and Visualization as that of the professionals. They may need to include SQL language in the languages that they are using or studying.\n  In the area of machine learning\/cloud computing, the respondents have spent around 20,000 USD, which is quite high. This cost is around 100% of the average compensation of professionals in 21 countries.  Mostly likely this area is where the students need support. Or they may choose to apply in a large company who has been spending a huge amount in machine learning or cloud computing.","4b5f4ad8":"## Cloud Computing\n\nFor cloud computing the products and platforms used by professionals are AWS and GCP. For the big data the top 3 are MySql, Postgres and SQL Server.\n","280b3e9f":"## Machine Learning\n\nMany of the professionals are also new to machine learning. The most popular ML framework they used are Sckit-learn, Tensorflow and Keras. As for the ML algorithm, the most widely used are Linear or Logistic Regression, Decision Trees or Random Forests and Convolutional Neural Networks.","93916c31":"# INTRODUCTION","a66509cf":"## Hardware\n\nWhen learning data science, most of the professionals use only a personal computer or laptop and GPUs","2edd0d05":"As a person who is new to data science, I want to learn the programming languages that the professionals are using, so that I can focus on the \nsubjects that are used in the job.  In this analysis the professionals are those whose experience is 5 years or more.\nIn addition, I also want to know how much is the cost when learning these languages.\nI hope this analysis will help guide those students whose aspirations is to become a data scientist.","219de58a":"## Roles of the respondents\n\nMost of the respondents are students, followed by Data Scientists and Software Engineers.","554a9fab":"## Average Compensation Per Country of Residence\n\nThe average compensation that I used is the mean of the compensation range. Asian countries such as Sri Lanka, Iran, Bangladesh, Philippines, Indonesia, Vietnam, Pakistan, Nepal and India and African countries such as Morocco, Kenya and Nigeria belong to those with the lowest compensation.\n","c10f50e4":"# STUDENTS\n\nMajority of the students are from India and US.  Most of them have no experience or have less than 1 up to 2 years programming experience","bd6af97a":"# COST\n\nThe list of countries where the cost of learning is 45% of their income. Among these countries, the 3 countries below have lower compensation compared with the cost.\n\n* Bangladesh\n* Iran\n* Kenya","ba54ad4d":"# Professionals\n\nThe professionals are defined as those who are not students and not currently employed and has a years of experience in programming for 5 or more years. ","1a67c4d6":"## Programming Languages"}}