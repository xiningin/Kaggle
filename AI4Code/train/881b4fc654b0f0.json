{"cell_type":{"55237c86":"code","e71e6a3f":"code","90db2a59":"code","2e3ac304":"code","021e65a3":"code","8d747c3b":"code","e033977b":"code","10ac16be":"code","a5fad7bc":"code","991357a9":"code","2f704616":"code","a3b788c9":"code","955d5207":"markdown"},"source":{"55237c86":"import numpy as np\nimport pandas as pd \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tqdm import tqdm\nimport cv2 as cv\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","e71e6a3f":"main_folder = '..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\/'\ndf = pd.read_csv('..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\/labels.csv')\ndf = df[df.photo_quality==1]\ndf.head()","90db2a59":"'''\nFrom https:\/\/www.kaggle.com\/koshirosato\/bee-or-wasp-base-line-using-resnet50\n'''\nfor idx in tqdm(df.index):    \n    df.loc[idx,'path']=df.loc[idx,'path'].replace('\\\\', '\/') \n    \ndf.head()","2e3ac304":"df_test = df[df.is_final_validation==1].reset_index()\ndf_train = df[df.is_final_validation!=1].reset_index()\ndf_train.shape,df_test.shape","021e65a3":"df.label.value_counts().plot.pie(autopct='%1.1f%%')","8d747c3b":"'''\nFrom https:\/\/www.kaggle.com\/koshirosato\/bee-or-wasp-base-line-using-resnet50\n'''\nimg_size = 225\ndef create_datasets(df, img_size):\n    imgs = []\n    for path in tqdm(df['path']):\n        img = cv.imread(main_folder + path)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        img = cv.resize(img, (img_size,img_size))\n        imgs.append(img)\n        \n    imgs = np.array(imgs, dtype='float32')\n    imgs = imgs \/ 255.0\n    df = pd.get_dummies(df['label'])\n    return imgs, df\n\n\ntrain, df_train = create_datasets(df_train, img_size)\ntest, df_test = create_datasets(df_test, img_size)","e033977b":"model = Sequential()\nmodel.add(layers.Input(shape=(img_size,img_size,3)))\nmodel.add(tf.keras.applications.MobileNetV2(include_top=False,weights=\"imagenet\"))\nmodel.add(layers. GlobalAveragePooling2D())#BatchNormalization()\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(3,activation='softmax'))\nfor layer in model.layers[:1]:\n    layer.trainable = False\nmodel.summary()","10ac16be":"def scheduler(epoch, lr):\n    print(model.optimizer.lr.numpy())\n    if epoch < 5:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\nlr_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)","a5fad7bc":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('Best_model.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(train,df_train,batch_size=128,epochs=25,validation_split=0.1,callbacks=[checkpoint_cb,lr_cb],verbose=1)","991357a9":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n\nfig, axes = plt.subplots(1, 2, figsize=(15,5))\n\naxes[0].plot(epochs, acc, 'r-', label='Training Accuracy')\naxes[0].plot(epochs, val_acc, 'b--', label='Validation Accuracy')\naxes[0].set_title('Training and Validation Accuracy')\naxes[0].legend(loc='best')\n\naxes[1].plot(epochs, loss, 'r-', label='Training Loss')\naxes[1].plot(epochs, val_loss, 'b--', label='Validation Loss')\naxes[1].set_title('Training and Validation Loss')\naxes[1].legend(loc='best')\n\nplt.show()","2f704616":"model.evaluate(test,df_test,verbose=0)","a3b788c9":"# del model\n# import gc\n# gc.collect()","955d5207":"if `df = df[df.photo_quality==1]` dataset doesn't need sampling"}}