{"cell_type":{"878c980f":"code","27e3ef3b":"code","6a148979":"code","7ae66383":"code","7c5a56e3":"code","8d07f5aa":"code","dbd9dc85":"code","2595a1d1":"code","0faa2edc":"code","d7cee958":"code","5e553b8d":"code","979945af":"code","55e1742d":"code","dd91c441":"code","be34788c":"code","cd5099a0":"code","4c17e35f":"code","ce96b7de":"code","bdbdc531":"code","0774b876":"code","eb89f2d6":"code","845ad1d6":"code","765a5afa":"code","cc40676d":"code","f00b59b4":"code","12bf8d65":"code","f980776f":"markdown","a93cc23e":"markdown"},"source":{"878c980f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27e3ef3b":"#Import \ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","6a148979":"#Check train\ntrain.isnull().sum()","7ae66383":"#Check test\ntest.isnull().sum()","7c5a56e3":"from sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import cross_val_score","8d07f5aa":"full_data = [train, test]","dbd9dc85":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \n# Create new feature IsAlone from FamilySize\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \n# Remove all NULLS in the Embarked column\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","2595a1d1":"import re","0faa2edc":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\n# Create a new feature Title, containing the titles of passenger names\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)","d7cee958":"for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\ndataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')","5e553b8d":"for dataset in full_data:\n    dataset['Cabin'] = dataset['Cabin'].astype(str).str[0]","979945af":"train.head()","55e1742d":"y = train['Survived']\nX = train.drop(['Survived','Name','Ticket'], axis = 1)","dd91c441":"numerical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind in ['i','f'] and c !='PassengerId']\ncategorical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind not in ['i','f']]","be34788c":"numerical_features","cd5099a0":"categorical_features","4c17e35f":"#import train_test_split library\nfrom sklearn.model_selection import train_test_split\n\n# create train test split\nX_train, X_val, y_train, y_val = train_test_split( X,  y, test_size=0.3, random_state=0, stratify = y)","ce96b7de":"preprocessor = make_column_transformer(\n    \n    (make_pipeline(\n    SimpleImputer(strategy = 'median')\n        #,KBinsDiscretizer(n_bins=3)\n    ), numerical_features),\n    \n    (make_pipeline(\n    SimpleImputer(strategy = 'constant', fill_value = 'missing'),\n    OneHotEncoder(categories = 'auto', handle_unknown = 'ignore')), categorical_features),\n)","bdbdc531":"#from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","0774b876":"model_pipeline = make_pipeline(preprocessor,RandomForestClassifier(n_estimators = 200) )","eb89f2d6":"model_pipeline.fit(X_train, y_train)","845ad1d6":"X_prediction = model_pipeline.predict(X_train)","765a5afa":"print(f'Train : {model_pipeline.score(X_train, y_train):.3f}')","cc40676d":"print(f'Test : {model_pipeline.score(X_val, y_val):.3f}')","f00b59b4":"submission_prediction = model_pipeline.predict(test.drop(['Name','Ticket'], axis = 1)).astype(int)\n#","12bf8d65":"AllSub = pd.DataFrame({ 'PassengerId': test['PassengerId'],\n                       'Survived' : submission_prediction\n    \n})\n\nAllSub.to_csv(\"Solution_Pipeline_RF_IMproved.csv\", index = False)","f980776f":"New version","a93cc23e":"# Feature Engineering"}}