{"cell_type":{"3985ba03":"code","d4a44901":"code","8bfd96fd":"code","6a9c1079":"code","0f66b916":"code","6445cf5b":"code","e1e17316":"code","87006c6c":"code","40f59536":"code","780d6e5d":"code","a09a6b36":"code","a5eabb6b":"code","69705b6a":"code","ce596d90":"code","9588c476":"code","3942f85c":"code","2487c6bf":"code","5db35f08":"code","5221cae0":"code","e0b22f5e":"code","4a4c7db0":"code","706f4d45":"code","04a9ac41":"code","b4054fe5":"code","3a821981":"code","24341b0f":"code","713c34cc":"code","a2e5b621":"code","7e64eb15":"code","0e96dff5":"markdown"},"source":{"3985ba03":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2\nfrom skimage import io, transform\n\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport time\nimport copy","d4a44901":"!unzip ..\/input\/traffic-light-boxes-dataset-extraction\/output.zip > \/var\/null","8bfd96fd":"!ls dataset\/images\/ -l | wc -l","6a9c1079":"class TrafficLightDataset(Dataset):\n    def __init__(self, root_dir: str, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.df = pd.read_csv(os.path.join(self.root_dir, 'annotations.csv'))\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        bbox_path = os.path.join(self.root_dir, 'images', self.df.loc[idx, 'bbox_filename'])\n        bbox_img = cv2.imread(bbox_path)\n        bbox_img = cv2.cvtColor(bbox_img, cv2.COLOR_BGR2RGB)\n        \n        # classes: 0: go \/ green | 1: warning \/ orange | 2: stop \/ red\n        annotation = self.df.loc[idx, 'annotation_tag']\n        if annotation[:2] == 'go':\n            y = np.array([1, 0, 0], dtype=np.float32)\n        elif annotation[:7] == 'warning':\n            y = np.array([0, 1, 0], dtype=np.float32)\n        elif annotation[:4] == 'stop':\n            y = np.array([0, 0, 1], dtype=np.float32)\n            \n        sample = {'image': bbox_img, 'target': y}  # .reshape((-1, 1))\n            \n        if self.transform:\n            sample = self.transform(sample)\n        \n        return sample\n","0f66b916":"dataset = TrafficLightDataset('dataset')","6445cf5b":"len(dataset)","e1e17316":"def show_random_image():\n    idx = np.random.randint(0, len(dataset))\n    sample = dataset[idx]\n    \n    image = sample['image']\n    target = sample['target']\n    if isinstance(image, torch.Tensor):\n        image = image.numpy()\n        image = image.transpose((1, 2, 0))\n        target = target.numpy()\n    \n    plt.imshow(image)\n    img_cls = ['Green', 'Orange', 'Red'][target.argmax()]\n    plt.title(img_cls)\n    plt.show()\n","87006c6c":"show_random_image()","40f59536":"stats = [0, 0, 0]\nmin_shape = 5000\nfor idx in range(len(dataset)):\n    shape = dataset[idx]['image'].shape[0]\n    if shape < min_shape:\n        min_shape = shape\n    stats[dataset[idx]['target'].argmax()] += 1\n\nprint('stats:', stats)\nprint('min shape:', min_shape)\n","780d6e5d":"class Rescale(object):\n    \"\"\"\n    Rescale the image in a sample to a given size.\n    \"\"\"\n\n    def __init__(self, output_size: int):\n        self.output_size = output_size\n\n    def __call__(self, sample):\n        image, target = sample['image'], sample['target']\n        image = transform.resize(image, (self.output_size, self.output_size))\n\n        return {'image': image, 'target': target}\n    \nclass ToTensor(object):\n    \"\"\"\n    Convert ndarrays in sample to Tensors.\n    \"\"\"\n\n    def __call__(self, sample):\n        image, target = sample['image'], sample['target']\n\n        # swap color axis because\n        # numpy image: H x W x C\n        # torch image: C X H X W\n        image = image.transpose((2, 0, 1))\n        return {'image': torch.from_numpy(image),\n                'target': torch.from_numpy(target)}\n","a09a6b36":"trans = transforms.Compose([Rescale(28), ToTensor()])\ndataset = TrafficLightDataset('dataset', transform=trans)","a5eabb6b":"show_random_image()","69705b6a":"train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [4000, 1000, 1714])  #  [0.6, 0.15, 0.25]","ce596d90":"dataset[0]['target'].argmax(), dataset[1]['target'].argmax(), dataset[2]['target'].argmax(), dataset[3]['target'].argmax(), dataset[4]['target'].argmax()","9588c476":"train_dataset[0]['target'].argmax(), train_dataset[1]['target'].argmax(), train_dataset[2]['target'].argmax(), train_dataset[3]['target'].argmax(), train_dataset[4]['target'].argmax()","3942f85c":"train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\nvalidation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=True, num_workers=4)\ntest_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=4)","2487c6bf":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","5db35f08":"class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),  # 28*28*3 => 28*28*64\n            \n            nn.Conv2d(64, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),  # 28*28*64 => 14*14*128\n            \n            nn.Conv2d(128, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),  # 14*14*128 => 7*7*256\n        )\n        output_ft = 256 * 7 * 7\n        self.classifier = nn.Sequential(\n            nn.Linear(output_ft, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 3),\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n\n        return x\n","5221cae0":"def weights_init(m):\n    if isinstance(m, nn.Conv2d):\n        torch.nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            m.bias.data.fill_(0.01)\n    if isinstance(m, nn.Linear):\n        torch.nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            m.bias.data.fill_(0.01)\n","e0b22f5e":"def lr_decay(iteration, init_lr=0.001, decay=0.5, cycle=None):\n    if isinstance(cycle, int):\n        iteration = iteration % cycle\n    return init_lr \/ (1 + decay * iteration)\n","4a4c7db0":"def save_net(name: str):\n    if not os.path.isdir('models'):\n        os.mkdir('models', 0o777)\n    torch.save(net.state_dict(), 'models\/' + name + '.pt')","706f4d45":"experiences = {}","04a9ac41":"criterion = nn.BCEWithLogitsLoss()","b4054fe5":"def measure_accuracy(predictions, ground_truth):\n    return (predictions.argmax(1) == ground_truth.argmax(1)).sum().item() \/ predictions.shape[0]\n","3a821981":"def train_net(net, n_epochs, print_every=10, lr=0.001, lrd=False, lrd_cycle=None):\n\n    # prepare the net for training\n    net.train()\n    if not lrd:\n        optimizer = optim.Adam(net.parameters(), lr=lr)\n    losses = []\n    accuracies = []\n    \n    val_losses = []\n    val_accuracies = []\n\n    for epoch in range(n_epochs):  # loop over the dataset multiple times\n        \n        net.train()\n        if lrd:\n            new_lr = lr_decay(epoch, lr, cycle=lrd_cycle)\n            optimizer = optim.Adam(net.parameters(), lr=new_lr)\n        \n        running_loss = 0.0\n        running_acc = 0.0\n        \n        # train on batches of data, assumes you already have train_loader\n        for batch_i, data in enumerate(train_dataloader):\n            # get the input images and their corresponding labels\n            images = data['image']\n            labels = data['target']\n\n            # convert variables to floats for regression loss\n            if torch.cuda.is_available():\n                labels = labels.cuda().float()\n                images = images.cuda().float()\n            else:\n                labels = labels.type(torch.FloatTensor)\n                images = images.type(torch.FloatTensor)\n\n            # forward pass to get outputs\n            output = net(images)\n            \n            # calculate the loss between predicted and target keypoints\n            loss = criterion(output, labels)\n\n            # zero the parameter (weight) gradients\n            optimizer.zero_grad()\n            \n            # backward pass to calculate the weight gradients\n            loss.backward()\n\n            # update the weights\n            optimizer.step()\n            \n            # print loss statistics\n            running_loss += loss.item()\n            running_acc += measure_accuracy(output, labels)\n            if (batch_i + 1) % print_every == 0:\n                print('Epoch: {}, Batch: {}, Avg. Loss: {}, accuracy = {}'.format(epoch + 1, batch_i+1, running_loss\/print_every, running_acc\/print_every))\n                losses.append(running_loss\/print_every)\n                running_loss = 0.0\n                running_acc = 0.0\n\n        net.eval()\n        running_val_loss = 0.\n        running_val_acc = 0.\n        for batch_j, eval_data in enumerate(validation_dataloader):\n            images = eval_data['image']\n            labels = eval_data['target']\n\n            # convert variables to floats for regression loss\n            if torch.cuda.is_available():\n                labels = labels.cuda().float()\n                images = images.cuda().float()\n            else:\n                labels = labels.type(torch.FloatTensor)\n                images = images.type(torch.FloatTensor)\n\n            # forward pass to get outputs\n            output = net(images)\n\n            running_val_loss += criterion(output, labels)\n            running_val_acc += measure_accuracy(output, labels)\n\n        val_loss = running_val_loss \/ len(validation_dataloader)\n        val_losses.append(val_loss)\n        val_acc = running_val_acc \/ len(validation_dataloader)\n        val_accuracies.append(val_acc)\n\n        print('Epoch: {}, Avg. validation Loss: {}, validation accuracy = {}'.format(epoch + 1, val_loss, val_acc))\n        print('-' * 85)\n\n    print('Finished Training')\n    return losses, accuracies, val_losses, val_accuracies\n","24341b0f":"torch.cuda.empty_cache()","713c34cc":"net = Network()\nif torch.cuda.is_available():\n    net.cuda()\nnet.apply(weights_init)\nprint(net)\n","a2e5b621":"n_epochs = 30 # start small, and increase when you've decided on your model structure and hyperparams\n\nlosses, accuracies, val_losses, val_acc = train_net(net, n_epochs, print_every=20, lr=0.0001 , lrd=True, lrd_cycle=40)\nname = 'net_v4_cyclic_lrd_200'\nexperiences[name] = losses\n# save_net(name)\n","7e64eb15":"!rm -rf dataset\/","0e96dff5":"## Creating a dataset, dataloader and defining transformers"}}