{"cell_type":{"9438cbad":"code","8229b878":"code","ec39ddbf":"code","9ba0fd41":"code","d5d31a4b":"code","bf09af22":"code","ef9a63ec":"code","981452e4":"code","c7f4a32a":"code","4efa19d7":"code","1939caee":"code","b3ed8e7a":"code","a0db3101":"code","cf05e131":"code","38413db2":"code","400a1edf":"code","93128d2d":"code","ab48a529":"code","96acc881":"code","3539304d":"code","2be30c1f":"code","c5bbff9d":"code","b8bead79":"code","fe1a211f":"code","25ff71ba":"code","1189a038":"code","cf3f8658":"code","2a999b9c":"code","e6e9eb88":"code","b97b47a1":"code","02243caa":"code","0ab09710":"code","97596716":"code","65f23a59":"code","5f4b38e9":"code","f5d83017":"code","b8240690":"code","cba2ac61":"code","e8965b9f":"code","dce0420c":"code","bb659659":"code","27716d28":"code","76ad1fc4":"code","1c80a849":"code","3c885f58":"code","4cc17556":"code","9c209c89":"code","7e26d385":"code","aab82118":"code","52d01654":"code","efa879a2":"code","740b18e2":"code","bd151bc4":"code","b0a633a4":"code","b42f109b":"code","43bec8d5":"code","a090743c":"code","ce20d4ac":"code","9880131f":"code","53203cf9":"code","56640682":"code","ddca1993":"code","aa0c1aa5":"code","74843611":"code","76f5a4a3":"code","c5886c2b":"code","cc5f8a56":"code","33aba0b5":"markdown","b09e2884":"markdown","5b72798c":"markdown","e9317dde":"markdown","4e520720":"markdown","a3872ca3":"markdown","6328c448":"markdown"},"source":{"9438cbad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8229b878":"from datetime import datetime, timedelta\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n#from __future__ import division\nfrom datetime import datetime,timedelta\nimport plotly as py\n#import plotly.offline as pyoff\nimport plotly.graph_objs as go","ec39ddbf":"df = pd.read_csv('\/kaggle\/input\/retailtransactiondata\/Retail_Data_Transactions.csv')\ndf.head()","9ba0fd41":"df['trans_date']=pd.to_datetime(df['trans_date'])","d5d31a4b":"#no missing values\ndf.isna().sum()\/len(df)","bf09af22":"#number of unique customer id\ndf['customer_id'].nunique()","ef9a63ec":"#dataset has 5 years of data\ndf['trans_date'].min(),df['trans_date'].max()","981452e4":"import plotly.offline as pyoff\n\n#plot the histogram\n\n#most transactions are in $40-$80 range\nplot_data = [\n    go.Histogram(\n        x=df['tran_amount']\n    )\n]\n\nplot_layout = go.Layout(\n        title='Transaction amounts',\n        xaxis_title=\"Amount in $\",\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)\n#fig.show(\"png\")","c7f4a32a":"df_user=pd.DataFrame(df['customer_id'].unique())\ndf_user.columns=['customer_id']","4efa19d7":"df_max_purchase=df.groupby('customer_id')['trans_date'].max().reset_index()\ndf_max_purchase.head()","1939caee":"df_max_purchase.rename(columns={'trans_date':'max_trans_date'},inplace=True)","b3ed8e7a":"df_max_purchase['Recency'] = (df_max_purchase['max_trans_date'].max() - df_max_purchase['max_trans_date']).dt.days\ndf_max_purchase.head()","a0db3101":"df_user=pd.merge(df_user,df_max_purchase[['customer_id','Recency']],on='customer_id')\ndf_user.head()","cf05e131":"#a lot of transactions between 0 and 14 days from the max date in the dataset\nplot_data = [\n    go.Histogram(\n        x=df_user['Recency']\n    )\n]\n\nplot_layout = go.Layout(\n        title='Recency',\n        xaxis_title=\"Days\",\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)\n#fig.show(\"png\")","38413db2":"#running KMeans to assign recency score to each customer\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, silhouette_samples\n\nwcss = []\ndf_recency=df_user[['Recency']]\nfor k in range(1,11):\n    kmeans=KMeans(n_clusters=k, init=\"k-means++\", random_state =42,n_init=10,max_iter=300) \n    kmeans.fit(df_recency)\n    wcss.append(kmeans.inertia_) \nplt.plot(range(1,11), wcss, 'bx-')\n\nplt.xlabel('k')\nplt.ylabel('WCSS')\nplt.title('Selecting k with the Elbow Method')","400a1edf":"kmeans=KMeans(n_clusters=3, init=\"k-means++\", random_state =42,n_init=10,max_iter=300) \nkmeans.fit(df_user[['Recency']])","93128d2d":"print(silhouette_score(df_user[['Recency']], kmeans.labels_))","ab48a529":"df_user['RecencyCluster']=kmeans.predict(df_user[['Recency']])","96acc881":"def order_cluster(cluster_field_name, target_field_name,df,ascending):\n    new_cluster_field_name = 'new_' + cluster_field_name\n    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n    df_new['index'] = df_new.index\n    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n    df_final = df_final.drop([cluster_field_name],axis=1)\n    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n    return df_final\n\ndf_max_purchase = order_cluster('RecencyCluster', 'Recency',df_user,False)","3539304d":"#cluster 0 is our best customers in terms of recency. Good news: there are many of them\ndf_user.groupby('RecencyCluster')['Recency'].describe()","2be30c1f":"sns.boxplot(df_user['RecencyCluster'],df_user['Recency'])","c5bbff9d":"df_freq=df.groupby('customer_id')['trans_date'].count().reset_index()","b8bead79":"df_freq.rename(columns={'trans_date':'Frequency'},inplace=True)","fe1a211f":"df_user=pd.merge(df_user,df_freq,on='customer_id')\ndf_user.head()","25ff71ba":"#no large frequency values:customers didn't buy many items over those 5 years\nplot_data = [\n    go.Histogram(\n        x=df_user['Frequency']\n    )\n]\n\nplot_layout = go.Layout(\n        title='Frequency',\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)","1189a038":"kmeans=KMeans(n_clusters=3, init=\"k-means++\", random_state =42,n_init=10,max_iter=300) \nkmeans.fit(df_user[['Frequency']])\ndf_user['FrequencyCluster']=kmeans.predict(df_user[['Frequency']])\n\n#order the frequency cluster\ndf_user=order_cluster('FrequencyCluster','Frequency',df_user,True)","cf3f8658":"#even though the dataset has over 6K customers, they didn't make a lot of purchases and it's the non-recent customers who made\n#more purchases. \n#Maybe look at what has changed that they don't come back any more (quality of product,availability of product etc.?)\ndf_user.groupby('FrequencyCluster')['Frequency'].describe()","2a999b9c":"sns.boxplot(df_user['FrequencyCluster'],df_user['Frequency'])","e6e9eb88":"df_revenue=df.groupby('customer_id')['tran_amount'].sum().reset_index()","b97b47a1":"df_revenue.rename(columns={'tran_amount':'Revenue'},inplace=True)","02243caa":"df_user=pd.merge(df_user,df_revenue,on='customer_id')","0ab09710":"#there is 2 groups of customers based on revenue: avg spending around $500 and around $1300\nplot_data = [\n    go.Histogram(\n        x=df_user['Revenue']\n    )\n]\n\nplot_layout = go.Layout(\n        title='Revenue',\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)","97596716":"df_user.query(\"Revenue>500 and Revenue<600\")[['Frequency']].median()","65f23a59":"df_user.query(\"Revenue>500 and Revenue<600\")[['Recency']].median()","5f4b38e9":"df_user.query(\"Revenue>1300 and Revenue<1400\")[['Frequency']].median()","f5d83017":"df_user.query(\"Revenue>1300 and Revenue<1400\")[['Recency']].median()","b8240690":"kmeans=KMeans(n_clusters=3, init=\"k-means++\", random_state =42,n_init=10,max_iter=300) \nkmeans.fit(df_user[['Revenue']])\ndf_user['RevenueCluster']=kmeans.predict(df_user[['Revenue']])\n\n#order the frequency cluster\ndf_user=order_cluster('RevenueCluster','Revenue',df_user,True)","cba2ac61":"#cluster 2 brings the most revenue\ndf_user.groupby('RevenueCluster')['Revenue'].describe()","e8965b9f":"sns.boxplot(df_user['RevenueCluster'],df_user['Revenue'])","dce0420c":"df_user['Score']=df_user['RecencyCluster']+df_user['FrequencyCluster']+df_user['RecencyCluster']","bb659659":"df_user.groupby('Score')['Recency','Frequency','Revenue'].mean()","27716d28":"import pandasql as ps\n\nq1 = \"\"\"SELECT a.*,  \n        CASE WHEN Score in (1,3,4,5) THEN 'Mid' \n                 WHEN Score in (2,6) THEN 'High' \n                 ELSE 'Low' END as Segment\nfrom df_user a\"\"\"\n\ndf_user= ps.sqldf(q1, locals())","76ad1fc4":"plt.figure(figsize=(12,10))\nsns.scatterplot(x='Recency',y='Revenue',hue='Segment',data=df_user)","1c80a849":"plt.figure(figsize=(12,10))\nsns.scatterplot(x='Frequency',y='Revenue',hue='Segment',data=df_user)","3c885f58":"plt.figure(figsize=(12,10))\nsns.scatterplot(x='Frequency',y='Recency',hue='Segment',data=df_user)","4cc17556":"df['TransYearMonth']=df['trans_date'].map(lambda date:100*date.year + date.month)","9c209c89":"df_revenue_=df.groupby('TransYearMonth')['tran_amount'].sum().reset_index()\ndf_revenue_.columns=['TransYearMonth','Revenue']","7e26d385":"#revenue ranges within 15-20K range mostly but there are deeps in April 2013,2014 and we don't have data for April 2015 to \n#see if this pattern repeats. But since 2 years had a decrease, we might want to look into those months and see what's happening.\nplot_data = [\n    go.Scatter(\n        x=df_revenue_.query('TransYearMonth>201106 and TransYearMonth<201503')['TransYearMonth'],\n        y=df_revenue_['Revenue'],\n    )\n]\n\nplot_layout = go.Layout(\n        xaxis={\"type\": \"category\"},\n        title='Montly Revenue'\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)","aab82118":"df_revenue_['MonthlyGrowth']=df_revenue_['Revenue'].pct_change()\ndf_revenue_.head()","52d01654":"plot_data = [\n    go.Scatter(\n        x=df_revenue_.query(\"TransYearMonth < 201503 and TransYearMonth>201106\")['TransYearMonth'],\n        y=df_revenue_.query(\"TransYearMonth < 201503 and TransYearMonth>201106\")['MonthlyGrowth'],\n    )\n]\n\nplot_layout = go.Layout(\n        xaxis={\"type\": \"category\"},\n        title='Montly Growth Rate'\n    )\n\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)","efa879a2":"df.head()","740b18e2":"df_min_=df.groupby('customer_id')['trans_date'].min().reset_index()","bd151bc4":"df_min_.rename(columns={'trans_date':'minpurchase_date'},inplace=True)","b0a633a4":"df_min_['minpurchase_date']=df_min_['minpurchase_date'].map(lambda date:100*date.year + date.month)","b42f109b":"df=pd.merge(df,df_min_,on='customer_id')","43bec8d5":"df['UserType']='New'\ndf.loc[df['TransYearMonth']>df['minpurchase_date'],'UserType']='Existing'","a090743c":"df_user_type_revenue=df.groupby(['TransYearMonth','UserType'])['tran_amount'].sum().reset_index()\ndf_user_type_revenue.head()","ce20d4ac":"#new users don't generate much revenue at all\ndf_user_type_revenue.groupby('UserType')['tran_amount'].sum().reset_index()","9880131f":"#there aren't many new customers in this dataset\ndf.groupby('UserType')['customer_id'].count()","53203cf9":"#new customers steadily don't generate any increase or any significant revenue at all\n#Hence, the goal would be to retain existing customers\ndf_user_type_revenue = df_user_type_revenue.query(\"TransYearMonth != 201105 and TransYearMonth != 201503\")\nplot_data = [\n    go.Scatter(\n        x=df_user_type_revenue.query(\"UserType == 'Existing'\")['TransYearMonth'],\n        y=df_user_type_revenue.query(\"UserType == 'Existing'\")['tran_amount'],\n        name = 'Existing'\n    ),\n    go.Scatter(\n        x=df_user_type_revenue.query(\"UserType == 'New'\")['TransYearMonth'],\n        y=df_user_type_revenue.query(\"UserType == 'New'\")['tran_amount'],\n        name = 'New'\n    )\n]\n\nplot_layout = go.Layout(\n        xaxis={\"type\": \"category\"},\n        title='New vs Existing'\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)","56640682":"df_user_ratio=df.query(\"UserType=='New'\").groupby(['TransYearMonth'])['customer_id'].nunique()\/df.query(\"UserType=='Existing'\").groupby(['TransYearMonth'])['customer_id'].nunique()\ndf_user_ratio=df_user_ratio.reset_index()\ndf_user_ratio=df_user_ratio.dropna()\ndf_user_ratio.head()","ddca1993":"#there is close to zero acquisition of new customers after 2012\nplot_data = [\n    go.Bar(\n        x=df_user_ratio.query(\"TransYearMonth != 201105 and TransYearMonth != 201503\")['TransYearMonth'],\n        y=df_user_ratio.query(\"TransYearMonth != 201105 and TransYearMonth != 201503\")['customer_id'],\n    )\n]\n\nplot_layout = go.Layout(\n        xaxis={\"type\": \"category\"},\n        title='New Customer Ratio'\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig) ","aa0c1aa5":"df_purchase=df.groupby(['customer_id','TransYearMonth'])['tran_amount'].sum().reset_index()\ndf_purchase.head()","74843611":"#1 if customer was active that month, 0 if not\ndf_retention=pd.crosstab(df_purchase['customer_id'],df_purchase['TransYearMonth']).reset_index()\ndf_retention.head()","76f5a4a3":"months=df_retention.columns[2:]\n\nretention=[]\n\nfor i in range(len(months)-1):\n    retention_data={}\n    selected_month=months[i+1]\n    prev_month=months[i]\n    retention_data['TransYearMonth']=int(selected_month)\n    retention_data['TotalUserCount']=df_retention[selected_month].sum()\n    retention_data['RetainedUserCount']=df_retention[(df_retention[selected_month]>0) & df_retention[prev_month]>0][selected_month].sum()\n    retention.append(retention_data)","c5886c2b":"df_retention=pd.DataFrame(retention)\ndf_retention['RetentionRate']=df_retention['RetainedUserCount']\/df_retention['TotalUserCount']","cc5f8a56":"#deeps in monthly retention rate follow month with deep in monthly growth rate\nplot_data = [\n    go.Scatter(\n        x=df_retention.query(\"TransYearMonth != 201105 and TransYearMonth != 201503\")['TransYearMonth'],\n        y=df_retention.query(\"TransYearMonth != 201105 and TransYearMonth != 201503\")['RetentionRate'],\n    ),\n]\n\nplot_layout = go.Layout(\n        xaxis={\"type\": \"category\"},\n        title='Monthly retention rate'\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig) ","33aba0b5":"## Revenue","b09e2884":"Our most desirable group is with score 1 because they are recent, bought the same amount as everyone and generated us decent revenue so we want to encourage them to come back.\n\nA lot of missing opportunity to generate revenue on customers with score 3-6 because they bring high revenue but their recency is the problem. They buy on average around the same amount of items as most recent customers but could bring more revenue if we increase their recency through some marketing actions.\n\nFrequency seem to be the problem regardless of the score but it would also depend on the nature of the business to see if it's possible to increase the amount of purchases.","5b72798c":"customers in 500 revenue group didn't purchase many items and they aren't recent.\n\ncustomers in 1300 revenue group had more items purchased and they are more recent. We should concentrate on them to increase their frequency","e9317dde":"RFM\nLow Value: Customers who are less active than others, not very frequent buyer\/visitor and generates very low - zero - maybe negative revenue.\n\nMid Value: In the middle of everything. Often using our platform (but not as much as our High Values), fairly frequent and generates moderate revenue.\n\nHigh Value: The group we don\u2019t want to lose. High Revenue, Frequency and low Inactivity.\n\n## Recency","4e520720":"## Frequency","a3872ca3":"## Monthly retention rate","6328c448":"## New customer ratio"}}