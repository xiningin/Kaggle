{"cell_type":{"df7027e4":"code","aa316597":"code","116383ac":"code","6600e71c":"code","87ae9bd3":"code","ad807dca":"code","67cda451":"code","352ab3e9":"code","b1049d56":"code","122281a6":"code","faed671c":"code","ed070797":"code","0e108d28":"code","a8049bb6":"code","c1a7352c":"code","cf463b6c":"code","2e11b5a5":"code","9812a0c9":"code","958e24b7":"code","ff3da5ec":"code","9f07993b":"code","b879136b":"code","9df25e77":"code","8f5ac8c2":"code","f57d3d89":"code","e7392d5f":"code","17ee1652":"code","6899447c":"code","9c221580":"code","85dc6610":"code","0c646c8e":"code","294074ce":"code","37a5f147":"code","66c1fa45":"code","6e627da4":"code","a49f0e9d":"code","8a0215a4":"code","72cea068":"code","d26a3b1f":"code","554e0a30":"code","896790e3":"code","efebe5f0":"code","6c7168ae":"code","3b73425d":"code","4c0271d3":"code","334e2588":"code","443ace62":"code","87db90dd":"code","a29aa34e":"code","7e907278":"code","d48b1a19":"code","aaf64a96":"code","415fa240":"code","90afd258":"code","a9238f24":"code","1939f610":"code","4e0263be":"code","9437b648":"code","021ef474":"code","d4843fe9":"code","a5307ea4":"markdown","027366e7":"markdown","fe9ea5da":"markdown","24ed1f6a":"markdown","546749de":"markdown","a0f89480":"markdown","37120149":"markdown","77c09be8":"markdown","6f00ed4f":"markdown","a552d50a":"markdown"},"source":{"df7027e4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score","aa316597":"data_orig = pd.read_csv(\"..\/input\/train.csv\", sep=',')\ndata = data_orig","116383ac":"data = data.drop(['ID'], axis = 1)\ndata.head()","6600e71c":"df1 = data[data.Class == 0].sample(6000)\ndf2 = data[data.Class == 1].sample(6290)","87ae9bd3":"frames = [df1, df2]\nresult = pd.concat(frames)\nresult.head()","ad807dca":"result.info()","67cda451":"y=result['Class']","352ab3e9":"result.drop(['Class', 'Enrolled', 'MIC', 'MOC', 'MLU', 'Reason', 'Area',\n           'REG', 'MSA', 'State', 'Live', 'PREV', 'MOVE', 'Teen', 'Fill'],axis=1, inplace=True)","b1049d56":"result.drop(['Worker Class', 'Detailed', 'Schooling'],axis=1,inplace=True)","122281a6":"result.drop(['Married_Life', 'Full\/Part', 'Summary', 'Tax Status', 'COB FATHER', 'COB MOTHER', 'COB SELF', 'Hispanic'],axis=1,inplace=True)","faed671c":"result.info()\n#data.drop(['Tax Status', 'Married_Life', 'Full\/Part', 'Summary', 'Detailed', 'Schooling'],axis=1,inplace=True)","ed070797":"result.head()","0e108d28":"df = pd.get_dummies(result, columns = [ \"Sex\",  \"Own\/Self\",  \"Citizen\", \"Vet_Benefits\", \"Cast\"])","a8049bb6":"X = df\nX.head()","c1a7352c":"X.info()","cf463b6c":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)","2e11b5a5":"from sklearn import preprocessing\n#Performing Min_Max Normalization\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X_train)\nX_train = pd.DataFrame(np_scaled)\nnp_scaled_val = min_max_scaler.transform(X_val)\nX_val = pd.DataFrame(np_scaled_val)\nX_train.head()","9812a0c9":"np.random.seed(42)\nfrom sklearn.naive_bayes import GaussianNB as NB","958e24b7":"nb = NB()\nnb.fit(X_train,y_train)\nnb.score(X_val,y_val)","ff3da5ec":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n\ny_pred_NB = nb.predict(X_val)\nprint(confusion_matrix(y_val, y_pred_NB))","9f07993b":"print(classification_report(y_val, y_pred_NB))","b879136b":"from sklearn.neighbors import KNeighborsClassifier","9df25e77":"train_acc = []\ntest_acc = []\nfor i in range(1,15):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    acc_train = knn.score(X_train,y_train)\n    train_acc.append(acc_train)\n    acc_test = knn.score(X_val,y_val)\n    test_acc.append(acc_test)","8f5ac8c2":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(1,15),train_acc,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(1,15),test_acc,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score, test_score],[\"Train Accuracy\", \"Test Accuracy\"])\nplt.title('Accuracy vs K neighbors')\nplt.xlabel('K neighbors')\nplt.ylabel('Accuracy')","f57d3d89":"knn = KNeighborsClassifier(n_neighbors=12)\nknn.fit(X_train,y_train)\nknn.score(X_val,y_val)","e7392d5f":"y_pred_KNN = knn.predict(X_val)\ncfm = confusion_matrix(y_val, y_pred_KNN, labels = [0,1])\nprint(cfm)","17ee1652":"print(classification_report(y_val, y_pred_KNN))","6899447c":"from sklearn.linear_model import LogisticRegression","9c221580":"lg = LogisticRegression(solver = 'liblinear', C = 2, multi_class = 'ovr', random_state = 42)\nlg.fit(X_train,y_train)\nlg.score(X_val,y_val)","85dc6610":"lg = LogisticRegression(solver = 'lbfgs', C = 10, multi_class = 'multinomial', random_state = 42)\nlg.fit(X_train,y_train)\nlg.score(X_val,y_val)","0c646c8e":"y_pred_LR = lg.predict(X_val)\nprint(confusion_matrix(y_val, y_pred_LR))","294074ce":"print(classification_report(y_val, y_pred_LR))","37a5f147":"from sklearn.tree import DecisionTreeClassifier\n\ntrain_acc = []\ntest_acc = []\nfor i in range(1,15):\n    dTree = DecisionTreeClassifier(max_depth=i)\n    dTree.fit(X_train,y_train)\n    acc_train = dTree.score(X_train,y_train)\n    train_acc.append(acc_train)\n    acc_test = dTree.score(X_val,y_val)\n    test_acc.append(acc_test)","66c1fa45":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(1,15),train_acc,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(1,15),test_acc,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score, test_score],[\"Train Accuracy\", \"Validation Accuracy\"])\nplt.title('Accuracy vs Max Depth')\nplt.xlabel('Max Depth')\nplt.ylabel('Accuracy')","6e627da4":"from sklearn.tree import DecisionTreeClassifier\n\ntrain_acc = []\ntest_acc = []\nfor i in range(2,30):\n    dTree = DecisionTreeClassifier(max_depth = 6, min_samples_split=i, random_state = 42)\n    dTree.fit(X_train,y_train)\n    acc_train = dTree.score(X_train,y_train)\n    train_acc.append(acc_train)\n    acc_test = dTree.score(X_val,y_val)\n    test_acc.append(acc_test)","a49f0e9d":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(2,30),train_acc,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(2,30),test_acc,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score, test_score],[\"Train Accuracy\", \"Validation Accuracy\"])\nplt.title('Accuracy vs min_samples_split')\nplt.xlabel('Max Depth')\nplt.ylabel('Accuracy')","8a0215a4":"dTree = DecisionTreeClassifier(max_depth=6, random_state = 42)\ndTree.fit(X_train,y_train)\ndTree.score(X_val,y_val)","72cea068":"y_pred_DT = dTree.predict(X_val)\nprint(confusion_matrix(y_val, y_pred_DT))","d26a3b1f":"print(classification_report(y_val, y_pred_DT))","554e0a30":"from sklearn.ensemble import RandomForestClassifier","896790e3":"score_train_RF = []\nscore_test_RF = []\n\nfor i in range(1,18,1):\n    rf = RandomForestClassifier(n_estimators=i, class_weight=\"balanced\", random_state = 42)\n    rf.fit(X_train, y_train)\n    sc_train = rf.score(X_train,y_train)\n    score_train_RF.append(sc_train)\n    sc_test = rf.score(X_val,y_val)\n    score_test_RF.append(sc_test)","efebe5f0":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(1,18,1),score_train_RF,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(1,18,1),score_test_RF,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score,test_score],[\"Train Score\",\"Test Score\"])\nplt.title('Fig4. Score vs. No. of Trees')\nplt.xlabel('No. of Trees')\nplt.ylabel('Score')","6c7168ae":"for x in range(8, 25):\n    rf = RandomForestClassifier(n_estimators=x, class_weight=\"balanced\", random_state = 42)\n    rf.fit(X_train, y_train)\n    #print(rf.score(X_val,y_val), x)\n    y_pred_RF = rf.predict(X_val)\n    print(classification_report(y_val, y_pred_RF), x)","3b73425d":"rf = RandomForestClassifier(n_estimators=16, class_weight=\"balanced\", random_state = 42)\nrf.fit(X_train, y_train)\nprint(rf.score(X_val,y_val))\ny_pred_RF = rf.predict(X_val)\nprint(classification_report(y_val, y_pred_RF))","4c0271d3":"#y_pred_RF = rf.predict(X_val)\nconfusion_matrix(y_val, y_pred_RF)","334e2588":"print(classification_report(y_val, y_pred_RF))","443ace62":"ddf = pd.read_csv(\"..\/input\/test.csv\", sep=',')","87db90dd":"ddf = ddf.drop(['ID'], axis = 1)\nddf.head()","a29aa34e":"ddf.drop(['Enrolled', 'MIC', 'MOC', 'MLU', 'Reason', 'Area', 'REG', 'MSA', 'State', 'Live', 'PREV', 'MOVE', 'Teen', 'Fill'],axis=1, inplace=True)\nddf.drop(['Worker Class', 'COB FATHER', 'COB MOTHER', 'COB SELF', 'Hispanic', 'Detailed', 'Schooling'],axis=1,inplace=True)\nddf.drop(['Married_Life', 'Full\/Part', 'Summary',  'Tax Status'],axis=1,inplace=True)","7e907278":"ddf = pd.get_dummies(ddf, columns = [\"Sex\", \"Own\/Self\", \"Cast\", \"Vet_Benefits\", \"Citizen\"])","d48b1a19":"ddf.head()","aaf64a96":"from sklearn import preprocessing\n#Performing Min_Max Normalization\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(ddf)\ndataN1 = pd.DataFrame(np_scaled)\ndataN1.head()","415fa240":"#ddf.info()","90afd258":"X1 = dataN1","a9238f24":"rf = RandomForestClassifier(n_estimators=16, class_weight=\"balanced\", random_state = 42)\nrf.fit(X_train, y_train)\ny_fin = rf.predict(X1)","1939f610":"data1 = pd.read_csv(\"..\/input\/test.csv\", sep=',')","4e0263be":"dataf = data1['ID']","9437b648":"res1 = pd.DataFrame(y_fin)\nfinal = pd.concat([data1[\"ID\"], res1], axis=1).reindex()\nfinal = final.rename(columns={0: \"Class\"})\nlen(final)","021ef474":"final.to_csv('submission69.csv', index = False)","d4843fe9":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\ncreate_download_link(final)","a5307ea4":"## RANDOM FOREST","027366e7":"## NORMALIZATION","fe9ea5da":"## DECISION TREE CLASSIFIER","24ed1f6a":"## LOGISTIC REGRESSION","546749de":"## KNN ALGORITHM","a0f89480":"## SAMPLING","37120149":"# DATA PREPROCESSING","77c09be8":"# PREDICTION ON TEST DATA","6f00ed4f":"## NAIVE BAYES","a552d50a":"## TRAIN AND VALIDATION SPLIT"}}