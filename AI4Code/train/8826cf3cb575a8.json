{"cell_type":{"d2ae0c54":"code","c6644d34":"code","77eaa540":"code","d427c972":"code","c746803d":"code","5a2b04a9":"code","23d0db84":"code","eb7da635":"code","4dfb1e9d":"code","6c40e085":"code","07d374d2":"code","57a46fdd":"code","17fc258d":"code","3365b774":"code","2807095f":"code","a62c7732":"code","ceef8a64":"code","8e274ffe":"code","cad07d9a":"code","356e263b":"code","25b2cc5c":"code","c871fd29":"code","c58f62ae":"code","904e1a53":"code","096f039e":"code","4b1498f9":"markdown","a0ff6ddd":"markdown","bcda6728":"markdown"},"source":{"d2ae0c54":"import optuna\nimport xgboost as xgb\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split","c6644d34":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/train.csv')\ntest  = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/test.csv')\nsub = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/sample_submission.csv')","77eaa540":"columns = [col for col in train.columns.to_list() if col not in ['id','target']]","d427c972":"data=train[columns]\ntarget=train['target']","c746803d":"def objective(trial,data=data,target=target):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n    param = {\n        'tree_method':'gpu_hist', # GPU\u4f7f\u7528\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': 4000,\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }\n    model = xgb.XGBRegressor(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","5a2b04a9":"#study = optuna.create_study(direction='minimize')\n#study.optimize(objective, n_trials=50)\n#print('Number of finished trials:', len(study.trials))\n#print('Best trial:', study.best_trial.params)","23d0db84":"#study.trials_dataframe()","eb7da635":"#optuna.visualization.plot_optimization_history(study)","4dfb1e9d":"#optuna.visualization.plot_parallel_coordinate(study)","6c40e085":"#optuna.visualization.plot_slice(study)","07d374d2":"#optuna.visualization.plot_contour(study, params=['alpha',\n#                            'max_depth',\n#                            'lambda',\n#                            'subsample',\n#                            'learning_rate',\n#                            'subsample'])","57a46fdd":"#optuna.visualization.plot_param_importances(study)","17fc258d":"#optuna.visualization.plot_edf(study)","3365b774":"#study.best_params","2807095f":"Best_trial= {'lambda': 0.0042687338951820425,\n             'alpha': 6.2637008222060935,\n             'colsample_bytree': 0.4,\n             'subsample': 0.6,\n             'n_estimators': 4000,\n             'learning_rate': 0.01,\n             'max_depth': 11,\n             'random_state': 2020,\n             'min_child_weight': 171,\n             'tree_method':'gpu_hist'\n            }","a62c7732":"preds = np.zeros(test.shape[0])\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nrmse=[]\nmodels = []\nn=0\nfor trn_idx, test_idx in kf.split(train[columns],train['target']):\n    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n    y_tr,y_val=train['target'].iloc[trn_idx],train['target'].iloc[test_idx]\n    model = xgb.XGBRegressor(**Best_trial)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds+=model.predict(test[columns])\/kf.n_splits\n    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n    models.append(model)\n    print(n+1,rmse[n])\n    n+=1","ceef8a64":"np.mean(rmse)","8e274ffe":"preds","cad07d9a":"sub['target']=preds\nsub.to_csv('submission.csv', index=False)","356e263b":"import matplotlib.pyplot as plt","25b2cc5c":"_, ax = plt.subplots(figsize=(12, 5))\n\nxgb.plot_importance(models[0],\n                    ax=ax,\n                    importance_type='gain',\n                    show_values=False\n                    )\n\nplt.show()","c871fd29":"_, ax = plt.subplots(figsize=(12, 5))\n\nxgb.plot_importance(models[1],\n                    ax=ax,\n                    importance_type='gain',\n                    show_values=False\n                    )\n\nplt.show()","c58f62ae":"_, ax = plt.subplots(figsize=(12, 5))\n\nxgb.plot_importance(models[2],\n                    ax=ax,\n                    importance_type='gain',\n                    show_values=False\n                    )\n\nplt.show()","904e1a53":"_, ax = plt.subplots(figsize=(12, 5))\n\nxgb.plot_importance(models[3],\n                    ax=ax,\n                    importance_type='gain',\n                    show_values=False\n                    )\n\nplt.show()","096f039e":"_, ax = plt.subplots(figsize=(12, 5))\n\nxgb.plot_importance(models[4],\n                    ax=ax,\n                    importance_type='gain',\n                    show_values=False\n                    )\n\nplt.show()","4b1498f9":"# \u7279\u5fb4\u91cf\u91cd\u8981\u5ea6","a0ff6ddd":"# \u5b66\u7fd2","bcda6728":"# \u7d50\u679c\u3092\u53ef\u8996\u5316"}}