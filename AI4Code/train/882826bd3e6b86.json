{"cell_type":{"5f50ea6e":"code","321bbba6":"code","eb901b51":"code","14672ec8":"code","22f333fd":"code","68f83460":"code","089faa4e":"code","357919d7":"code","78cf065e":"code","6de31e84":"code","c8852cbd":"code","3d8ca60d":"code","12da081e":"code","a9d8e684":"markdown","386c8930":"markdown","e86dd737":"markdown","43a8e469":"markdown","e6420b7c":"markdown","831c4648":"markdown"},"source":{"5f50ea6e":"import os\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\nnp.random.seed(11) # It's my lucky number\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nimport itertools\n\nimport keras\nfrom keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras import backend as K\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.applications.resnet50 import ResNet50\nfrom keras import backend as K \n\nimport tensorflow as tf","321bbba6":"# Load the extension and start TensorBoard\n\n%load_ext tensorboard.notebook\n%tensorboard --logdir logs","eb901b51":"os.listdir('..\/input\/random-images')","14672ec8":"folder_benign = '..\/input\/skin-cancer-malignant-vs-benign\/data\/data\/benign'\nfolder_malignant = '..\/input\/skin-cancer-malignant-vs-benign\/data\/data\/malignant'\nfolder_outliers = '..\/input\/random-images\/'\nread = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n\n# Load in pictures\nims_benign = [read(os.path.join(folder_benign, filename)) for filename in os.listdir(folder_benign)]\nX_benign = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(folder_malignant, filename)) for filename in os.listdir(folder_malignant)]\nX_malignant = np.array(ims_malignant, dtype='uint8')\nims_outliers = [read(os.path.join(folder_outliers, filename)) for filename in os.listdir(folder_outliers)]\nX_outliers = np.array(ims_outliers, dtype='uint8')\n\n# Create labels\ny_benign = np.zeros(X_benign.shape[0])\ny_malignant = np.zeros(X_malignant.shape[0])\ny_outliers = np.ones(X_outliers.shape[0])\n\n# Merge data and shuffle it\nX = np.concatenate((X_benign, X_malignant), axis = 0)\ny = np.concatenate((y_benign, y_malignant), axis = 0)\ns = np.arange(X.shape[0])\nnp.random.shuffle(s)\nX = X[s]\ny = y[s]","22f333fd":"# With data augmentation to prevent overfitting \nX_scaled = X\/255.\nX_outliers = X_outliers\/255.","68f83460":"X_train, X_test, y_train, y_test= train_test_split(X_scaled, \n                                                 y,\n                                                 test_size=0.20,\n                                                 random_state=42)","089faa4e":"input_img = Input(shape=(224, 224, 3))  # adapt this if using `channels_first` image data format\n\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((4, 4), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((4, 4))(x)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\nautoencoder.summary()","357919d7":"tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs\")\n\nautoencoder.fit(X_train, X_train,\n                epochs=10,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(X_test, X_test),\n                callbacks=[tensorboard_callback])","78cf065e":"decoded_imgs = autoencoder.predict(X_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(1,n+1):\n    # display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(X_test[i].reshape(224, 224,3))\n    plt.plot()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(224, 224, 3))\n    plt.plot()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n\ndecoded_outliers = autoencoder.predict(X_outliers)\n\nn = 5\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i+1)\n    plt.imshow(X_outliers[i].reshape(224, 224,3))\n    plt.plot()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + n+1)\n    plt.imshow(decoded_outliers[i].reshape(224, 224, 3))\n    plt.plot()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","6de31e84":"decoded_train = autoencoder.predict(X_train)\n\n# Check average MSE for every mole in train set\nmses_train = []\nfor i in range(decoded_imgs.shape[0]):\n    mse = np.mean((X_train[i] - decoded_train[i]) ** 2 )\n    mses_train.append(mse)\nprint('Average MSE for mole train: ', np.mean(np.asarray(mses_train)))\n\n# Check average MSE for every mole in test set\nmses_moles = []\nfor i in range(decoded_imgs.shape[0]):\n    mse = np.mean((X_test[i] - decoded_imgs[i]) ** 2 )\n    mses_moles.append(mse)\nprint('Average MSE for mole test: ', np.mean(np.asarray(mses_moles)))\n\n# Check average MSE for every outlier\nmses_outliers = []\nfor i in range(decoded_outliers.shape[0]):\n    mse = np.mean((X_outliers[i] - decoded_outliers[i]) ** 2 )\n    mses_outliers.append(mse)\nprint('Average MSE for outliers: ', np.mean(np.asarray(mses_outliers)))","c8852cbd":"max(mses_train), max(mses_moles), min(mses_outliers)","3d8ca60d":"threshold_fixed = 0.04\nfig, ax = plt.subplots()\n\n# Plot threshold line\nfor i in range(len(mses_train)):\n    ax.plot(i, mses_train[i], marker='o', ms=3.5, linestyle='')\nfor i in range(len(mses_moles)):\n    ax.plot(i, mses_moles[i], marker='o', ms=3.5, linestyle='')\nfor i in range(len(mses_outliers)):\n    ax.plot(i, mses_outliers[i], marker='o', ms=3.5, linestyle='')\nax.hlines(threshold_fixed, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\nax.legend()\nplt.title(\"Reconstruction error for different classes\")\nplt.ylabel(\"Reconstruction error\")\nplt.xlabel(\"Data point index\")\nplt.show();","12da081e":"# save model\n# serialize model to JSON\nmodel_json = autoencoder.to_json()\n\nwith open(\"autoencoder.json\", \"w\") as json_file:\n    json_file.write(model_json)\n    \n# serialize weights to HDF5\nautoencoder.save_weights(\"autoencoder.h5\")\nprint(\"Saved model to disk\")","a9d8e684":"# Step 1 : importing Essential Libraries","386c8930":"# Step 6: Autoencoder\n","e86dd737":"# Step 2 : Loading pictures and making Dictionary of images and labels\nIn this step I load in the pictures and turn them into numpy arrays using their RGB values. As the pictures have already been resized to 100x75, there's no need to resize them. As the pictures do not have any labels, these need to be created. Finally, the pictures are added together to a big training set and shuffeled.","43a8e469":"# Step 4 : Normalization\nNormalize all Values of the pictures by dividing all the RGB values by 255","e6420b7c":"# Step 5 : Train Test Split\nIn this step we have splitted the dataset into training and testing set of 80:20 ratio","831c4648":"# Autoencoder"}}