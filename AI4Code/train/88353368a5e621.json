{"cell_type":{"35749799":"code","be6d4edd":"code","cb5b33a1":"code","7c7e149b":"code","75b4feff":"code","7c46d681":"code","ed925e6f":"code","bbe86a7b":"code","6d42d16d":"code","388dc3a8":"code","2e7c9766":"code","083132e2":"code","1846a2e6":"code","ac6a3dd6":"code","1e0c92ce":"code","388f49a6":"code","5d0ff62e":"code","787e19e1":"code","52834e75":"code","fa84019b":"code","c95cc09a":"code","259f2feb":"code","c59f90a8":"code","5473c420":"code","8fc8c291":"code","d87ec85b":"code","b2eba313":"code","27fe9d9d":"code","667373c2":"code","fd25a0b2":"code","965a5c2d":"code","400e5290":"code","0ec0e79f":"code","9f43c58b":"code","c1ff7f00":"code","932edebc":"code","fc50e19b":"markdown","665e9c76":"markdown","219a1202":"markdown","ec68d3ab":"markdown","6e76e6fe":"markdown","d49def2c":"markdown","6465e573":"markdown","db0ae2f6":"markdown","2c182137":"markdown","f8c2d19e":"markdown","92a602a7":"markdown","cadd69be":"markdown","2544d171":"markdown","5c305c47":"markdown","370304fd":"markdown","edf00340":"markdown","958b70f4":"markdown","71e48f03":"markdown","14b031a4":"markdown","ab4c7b01":"markdown","6a95f340":"markdown","a70025be":"markdown","002ed7eb":"markdown","b7a7d4e2":"markdown","6ceef1a5":"markdown","e0ded02c":"markdown","a8c883ae":"markdown","9d5543be":"markdown","913d5bb1":"markdown","7754402c":"markdown","9a204f68":"markdown","d9b5e06c":"markdown","ce9a4a39":"markdown","461c3915":"markdown","f52577ad":"markdown","e0cb2c1c":"markdown","c6eaf410":"markdown","cbe4bd70":"markdown","76afba11":"markdown","cff09d69":"markdown","967b82c1":"markdown","759e08b4":"markdown","9cc63f01":"markdown","c17e105d":"markdown","a9617de2":"markdown","412af5c1":"markdown","edeee8bd":"markdown","4499a3b7":"markdown","43e3e796":"markdown"},"source":{"35749799":"from IPython.display import YouTubeVideo\nfrom IPython import display","be6d4edd":"video_id = 'oKzNUGz21JM'\nYouTubeVideo(video_id, width = 800, height = 500)","cb5b33a1":"# Imports for data loading and array math\nimport numpy as np\nimport pandas as pd\n\n# Imports for\nfrom ipywidgets import interact\n\n# Imports for visualization\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\n\n# Imports for dimensionality reduction\nfrom sklearn.manifold import MDS, TSNE\n\n# Import for working with directories and files\nimport os\n\n# Import for working with vision applications of fastai\nfrom fastai.vision import *\n\n# Import for data split\nfrom sklearn.model_selection import train_test_split","7c7e149b":"sample_submission_path = '..\/input\/digit-recognizer\/sample_submission.csv'\ntrain_path = '..\/input\/digit-recognizer\/train.csv'\ntest_path = '..\/input\/digit-recognizer\/test.csv'","75b4feff":"train = pd.read_csv(train_path)\n\nX = train.iloc[:, 1:].values\nX = X.reshape((X.shape[0], 28, 28))\/255.\n\nY = train.iloc[:, 0].values\n\nX_test = pd.read_csv(test_path)\nX_test = X_test.values.reshape((X_test.shape[0], 28, 28))\/255.","7c46d681":"@interact\ndef plot_train_set(target = range(10), batch = (0, 263, 1)):\n    mpl.rcParams['figure.figsize'] = 6, 6\n    class_pictures = X[Y == target]\n    side = 3\n    for i in range(side):\n        for j in range(1, side + 1):\n            plt.subplot(side, side, i * side + j)\n            temp_index = batch * (side ** 2) + i * side + j - 1\n            if temp_index < class_pictures.shape[0]:\n                plt.imshow(class_pictures[temp_index], cmap = 'gray')","ed925e6f":"plot_train_set(target = 4, batch = 13)","bbe86a7b":"plot_train_set(target = 5, batch = 15)","6d42d16d":"plot_train_set(target = 6, batch = 13)","388dc3a8":"plot_train_set(target = 9, batch = 391)","2e7c9766":"@interact\ndef plot_test_set(batch = (0, 3100, 1)):\n    mpl.rcParams['figure.figsize'] = 6, 6\n    side = 3\n    for i in range(side):\n        for j in range(1, side + 1):\n            plt.subplot(side, side, i * side + j)\n            temp_index = batch * (side ** 2) + i * side + j - 1\n            if temp_index < X_test.shape[0]:\n                plt.imshow(X_test[temp_index], cmap = 'gray')","083132e2":"plot_test_set(batch = 13)","1846a2e6":"count = 1000\nembedding = MDS(n_components = 2, metric = True, random_state = 42)\nX_train_transformed = embedding.fit_transform(X[:count].reshape((count, 28 * 28)))","ac6a3dd6":"plt.style.use('seaborn-darkgrid')\nplt.rcParams['figure.figsize'] = 12, 10","1e0c92ce":"plt.scatter(X_train_transformed[:, 0], X_train_transformed[:, 1], c = Y[:count], cmap = plt.cm.get_cmap('tab10', 10))\nplt.title('linear MDS transformed')\nplt.xlabel('Axis 1')\nplt.ylabel('Axis 2')\nplt.colorbar(ticks = range(10));","388f49a6":"non_linear_embedding = MDS(n_components = 2, metric = False, random_state = 42)\nX_train_non_linear = embedding.fit_transform(X[:count].reshape((count, 28 * 28)))","5d0ff62e":"plt.scatter(X_train_non_linear[:, 0], X_train_non_linear[:, 1], c = Y[:count], cmap = plt.cm.get_cmap('tab10', 10))\nplt.title('non-linear MDS transformed')\nplt.xlabel('Axis 1')\nplt.ylabel('Axis 2')\nplt.colorbar(ticks = range(10));","787e19e1":"tsne_embedding = TSNE(n_components = 2, random_state = 42)\nX_train_tsne_transformed = tsne_embedding.fit_transform(X[:count].reshape((count, 28 * 28)))","52834e75":"plt.scatter(X_train_tsne_transformed[:, 0], X_train_tsne_transformed[:, 1], c = Y[:count], cmap = plt.cm.get_cmap('tab10', 10), s = 50)\nplt.title('t-SNE transformed')\nplt.xlabel('Axis 1')\nplt.ylabel('Axis 2')\nplt.colorbar(ticks = range(10));","fa84019b":"new_path = '..\/working\/'\nnew_train_path = new_path + 'train\/'\nnew_valid_path = new_path + 'valid\/'\nnew_test_path = new_path + 'test\/'","c95cc09a":"os.mkdir(new_train_path)\nos.mkdir(new_valid_path)\nos.mkdir(new_test_path)","259f2feb":"for target_label in [(str(i) + '\/') for i in range(10)]:\n    os.mkdir(new_train_path + target_label)\n    os.mkdir(new_valid_path + target_label)","c59f90a8":"X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size = 0.1, shuffle = True, random_state = 42, stratify = Y)","5473c420":"def save_image_data(X_data, path):\n    for i in range(X_data.shape[0]):\n        save_path = path + str(i) + '.png'\n        mpl.image.imsave(save_path, X_data[i])","8fc8c291":"for label in range(10):\n    X_data = X_train[y_train == label]\n    save_path = new_train_path + str(label) + '\/'\n    save_image_data(X_data, save_path)\n    \n    X_data = X_valid[y_valid == label]\n    save_path = new_valid_path + str(label) + '\/'\n    save_image_data(X_data, save_path)\n    \nsave_image_data(X_test, new_test_path)","d87ec85b":"data = ImageDataBunch.from_folder(new_path, test = 'test')","b2eba313":"data.show_batch(rows = 4, figsize = (8, 8))","27fe9d9d":"learner = cnn_learner(data, models.resnet18, metrics = accuracy)","667373c2":"learner.fit_one_cycle(5, 1e-3)","fd25a0b2":"learner.save('five_epochs')","965a5c2d":"interp = ClassificationInterpretation.from_learner(learner)","400e5290":"interp.plot_top_losses(12, figsize = (12, 12))","0ec0e79f":"interp.plot_confusion_matrix(figsize = (12, 12), dpi = 70)","9f43c58b":"learner.unfreeze()","c1ff7f00":"learner.fit_one_cycle(5, max_lr = slice(1e-5, 1e-4))","932edebc":"learner.save('unfreeze_5')","fc50e19b":"It can be seen from the graph above, that model makes mistakes not because of strange samples, but because of model's quality. Let's look at the confusion matrix of our model. ","665e9c76":"This notebook has 2 major goals:\n1. Make viewer more familiar with MNIST dataset by Exploratory Data Analysis and dimensionality reduction with visualization\n2. Make intro to Convolutional Neural Networks in Fastai library","219a1202":"At the first glance test data seems to be like train and is easily distinguishable. ","ec68d3ab":"t-SNE method projects all samples from the first space to the second randomly. Then it starts to move projected examples accordingly to the similarity of the examples in the first space. Similarity is measured by t-distribution. ","6e76e6fe":"In order to create train and validation sets we will shuffle our data and after it 90% of all training samples will go to the training set and 10% will go to the validation set. Also we will stratify our data by target variables, so our classes in the validation set were as balanced as they are in the training set.","d49def2c":"Let's load train and test data, reshape images to shape (28, 28) and normalize them by dividing data by maximum, which equals to 255. Then we will look at some samples of the train and test data.","6465e573":"* [Digit Recognizer Competition](https:\/\/www.kaggle.com\/c\/digit-recognizer)\n* [Video about Multi-dimensional Scaling (MDS)](https:\/\/youtu.be\/GEn-_dAyYME)\n* [Video about t-distributed Stochastic Neighbor Embedding (t-SNE)](https:\/\/youtu.be\/NEaUSP4YerM)\n* [Fastai documentation](https:\/\/docs.fast.ai\/)\n* [Article about residual neural nets](https:\/\/arxiv.org\/abs\/1512.03385)","db0ae2f6":"<font size = 3, font color = 'red'>Voting is appreciated.<\/font>","2c182137":"## Test","f8c2d19e":"## Create ImageDataBunch","92a602a7":"# Introduction","cadd69be":"t-SNE has much better results. It can be seen that some classes have totally separated from others and the area of overlap has decreased dramatically.","2544d171":"## Train","5c305c47":"# Acknowledgement","370304fd":"There are 3 files in the 'digit-recognizer' directory:\n* sample_submission.csv - contains sample submission for the competition \n* train.csv - contains train data\n* test.csv - contains test data\n\nTrain data table consist of 785 columns: 784 columns for each pixel of the image and 1 column for the target. Test data table has 784 columns and don't have target. Each pixel is the number in range [0; 255] inlcusive. ","edf00340":"# Content","958b70f4":"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.","71e48f03":"Data was loaded correctly.","14b031a4":"It can be seen from the confusion matrix, that most samples are categorized correctly. So, now we will try to imrove accuracy by unfreezing first layers of our model and tuning maximum learning rate.","ab4c7b01":"Now let's train our model with maximum learning rate equals to 1e-3 for 5 epochs. Method fit_one_cycle will explore learning rates less or equal than max_lr = 1e-3.","6a95f340":"In MDS images which were far from each other in the 784-d space will be far away from each other in the 2-d space. And images which were close to each other in the first space will be close to each other in the second space. ","a70025be":"## Create Folder","002ed7eb":"After the 4-th epoch accuracy has not growth a lot. Moreover, loss on train is greater than loss on validation, which means that we have to tune learning rate. Let's look at the errors of our model.","b7a7d4e2":"# Exploratory Data Analysis ","6ceef1a5":"### MNIST Introduction","e0ded02c":"Now we will create ImageDataBunch from our folder. After it we will check if the data was loaded correctly. ","a8c883ae":"I chose 10 times smaller maximum learning rate for the last layer and 100 times smaller maximum learning rate for the first layer. Other layers will have maximum learning rate between 1\u0435-5 and 1e-4.","9d5543be":"It can be seen from the table above, that accuracy has improved. It means, that unfreezing and training previous layers was quite useful.","913d5bb1":"In this notebook we will apply the concept of Transfer Learning and will use resnet18 model, which was pretrained om ImageNet data. We will replace its last layer with two layers. Last layer will have 10 output neurons, one for each category. At the beginning first layers will be frozen, which means that they won't train. Only the last two layers will train.","7754402c":"It can be seen from the graph above that 0s, 1s, 2s, 3s, 6s and 9s do not overlap. However, other digits seem to be not so well separated. For example, 7s overlap with 9s and 4s overlap with 9s. It's not so bad for linear MDS. Even by applying it we can have some results. But now let's try non-linear MDS. ","9a204f68":"## Create Model","d9b5e06c":"To summarize, with dimensionality reduction techniques we can transform our images with 784 pixels to 2-d space and still categorize them pretty well. Now let's try more sophisticated models called CNN. They will pay attention to the structure of the image.","ce9a4a39":"# Conclusion","461c3915":"For now we can say that our images do not realy need all 784 pixels to categorize them. Many pixels near the borders of the images are almost always black. That's why now we will try to reduce dimensionality of our image dataset from 784 to 2. After it we can plot them on the graph.","f52577ad":"# Imports","e0cb2c1c":"# Data Structure","c6eaf410":"### Multi-dimensional Scaling","cbe4bd70":"## Parameters Tuning","76afba11":"From the graph below it can be seen that results don't become better than in the previous case. Now let's apply t-SNE algorithm.","cff09d69":"## Visualization","967b82c1":"### t-distributed Stochastic Neighbor Embedding","759e08b4":"## Train Model","9cc63f01":"As it can be seen from the plots above digits are distinguashable. However there can be problems in some classes:\n* 4: It can be connected at it's upper part\n* 5: It mat be similar to 6, 0 or even 1 with angle\n* 6: it can be written without a space in center or even be like a comma\n* 9: If it doesn't have circle it can be like 1 and without connection at the upper part can be similar to 4","c17e105d":"1. MNIST is a simple data. MNIST digits can be classified even in 2-d space.\n2. Fastai CNN can achieve high accuracy (about 98%) on MNIST data by applying simple transfer learning.","a9617de2":"Before creating deep neural nets we must create data for the model. Fastai has many opportunities of creating data. We will be using method from_folder of class ImageDataBunch. At the beginning we must create folder, which will the structure below:\n* working\/\n    * train\/\n        * 0\/\n        * 1\/\n        * 2\/\n        * 3\/\n        * 4\/\n        * 5\/\n        * 6\/\n        * 7\/\n        * 8\/\n        * 9\/\n    * valid\/\n        * 0\/\n        * 1\/\n        * 2\/\n        * 3\/\n        * 4\/\n        * 5\/\n        * 6\/\n        * 7\/\n        * 8\/\n        * 9\/\n    * test\/","412af5c1":"# Fastai Convolutional Neural Network","edeee8bd":"* [Imports](#Imports)\n* [Data Structure](#Data-Structure)\n* [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n    * [Train](#Train)\n    * [Test](#Test)\n    * [Visualization](#Visualization)\n        * [Multi-dimensional Scaling](#Multi-dimensional-Scaling)\n        * [t-distributed Stochastic Neighbor Embedding](#t-distributed-Stochastic-Neighbor-Embedding)\n* [Fastai Convolutional Neural Network](#Fastai-Convolutional-Neural-Network)\n    * [Create Folder](#Create-Folder)\n    * [Create ImageDataBunch](#Create-ImageDataBunch)\n    * [Create Model](#Create-Model)\n    * [Train Model](#Train-Model)\n    * [Parameters Tuning](#Parameters-Tuning)\n* [Conclusion](#Conclusion)","4499a3b7":"In this section we will apply 2 methods of dimensionality reduction. They are called Multi-dimensional scaling (MDS) and t-distributed Stochastic Neighbor Embedding (t-SNE).","43e3e796":"Fastai library make applying deep learning easy. It has different modules. And one of them (vision module) we will be using in this notebook."}}