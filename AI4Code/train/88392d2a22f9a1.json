{"cell_type":{"2ed85d99":"code","0bd7d8ad":"code","896982c1":"code","8f807a20":"code","b18afe2b":"code","4af12875":"code","cd389680":"code","686492e8":"code","50ece391":"code","00815714":"code","c6144aae":"code","1aa6d41a":"code","5cb63476":"markdown","603d0dd0":"markdown","9b7d09b1":"markdown","83c82f31":"markdown","3b64c570":"markdown","8e9ad401":"markdown","9d355057":"markdown","1fefe4f5":"markdown","38c10ce9":"markdown","f6ef9f86":"markdown","b3677f6a":"markdown","f78d19c5":"markdown","046fce88":"markdown","e89bf144":"markdown","e8f67876":"markdown","c47bcbee":"markdown","e0774a13":"markdown","95556d6c":"markdown","9365fbf1":"markdown","2ac524ac":"markdown","6ef4e51d":"markdown"},"source":{"2ed85d99":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n","0bd7d8ad":"\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)\n\n# ao usar o Kaggle, o root deve apontar para '..\/input\/cifar10_pytorch\/data'\n\ntrainset = torchvision.datasets.CIFAR10(root='..\/input\/cifar10-pytorch\/cifar10_pytorch\/data', train=True,\n                                        download=False, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='..\/input\/cifar10-pytorch\/cifar10_pytorch\/data', train=False,\n                                       download=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","896982c1":"\n\nclass NetOrginal(nn.Module):\n    def __init__(self):\n        super(NetOrginal, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.conv2_bn = nn.BatchNorm2d(16)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = self.conv2_bn(x)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","8f807a20":"class CatAndDogNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=(5, 5), stride=2, padding=1)\n        self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=(3, 3), padding=1)\n        self.conv3_bn = nn.BatchNorm2d(32)\n\n        self.fc1 = nn.Linear(in_features= 32 * 3 * 3, out_features=500)\n        self.dropout = nn.Dropout(0.5)        \n        self.fc2 = nn.Linear(in_features=500, out_features=50)\n        self.fc3 = nn.Linear(in_features=50, out_features=10)\n\n        \n    def forward(self, X):\n        X = F.relu(self.conv1(X))\n        X = F.max_pool2d(X, 2)\n        \n        X = F.relu(self.conv3_bn(self.conv3(X)))\n        X = F.max_pool2d(X, 2)\n        \n#         print(X.shape)\n        X = X.view(X.shape[0], -1)\n        X = F.relu(self.fc1(X))\n        X = self.dropout(X)\n        X = F.relu(self.fc2(X))\n        X = self.fc3(X)\n        \n#         X = torch.sigmoid(X)\n        return X","b18afe2b":"class CnnTCC(nn.Module):\n    def __init__(self):\n        super(CnnTCC, self).__init__()\n        self.output_layer = 10\n        self.conv0 = nn.Sequential(\n            nn.Conv2d(3, 8, 8, 1, 1),\n            nn.BatchNorm2d(8, False)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(8, 16, 8, 1, 1),\n            nn.BatchNorm2d(16, False),\n            nn.MaxPool2d(2)\n        )\n        self.dense = nn.Sequential(\n            nn.Linear(4 * 22 * 22, 32),\n            nn.Tanh(),\n            nn.Linear(32, 32),\n            nn.Tanh(),\n            nn.Linear(32, self.output_layer),\n        )\n\n    def forward(self, x):\n        x = self.conv0(x)\n        x = self.conv2(x)\n        x = x.view(x.size(0), -1)\n        x = self.dense(x)\n        return F.softmax(x, dim=1)","4af12875":"class CNN_MNIST(torch.nn.Module):\n\n    def __init__(self):\n        super(CNN_MNIST, self).__init__()\n        # L1 ImgIn shape=(?, 28, 28, 1)\n        #    Conv     -> (?, 28, 28, 32)\n        #    Pool     -> (?, 14, 14, 32)\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n            torch.nn.Dropout(p=0.1))\n        # L2 ImgIn shape=(?, 14, 14, 32)\n        #    Conv      ->(?, 14, 14, 64)\n        #    Pool      ->(?, 7, 7, 64)\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n            torch.nn.Dropout(p=0.1))\n        # L3 ImgIn shape=(?, 7, 7, 64)\n        #    Conv      ->(?, 7, 7, 128)\n        #    Pool      ->(?, 4, 4, 128)\n        self.layer3 = torch.nn.Sequential(\n            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n            torch.nn.Dropout(p=0.1))\n\n        # L4 FC 3200 inputs -> 625 outputs\n        self.fc1 = torch.nn.Linear(3200, 625, bias=True)\n        torch.nn.init.xavier_uniform(self.fc1.weight)\n        self.layer4 = torch.nn.Sequential(\n            self.fc1,\n            torch.nn.ReLU(),\n            torch.nn.Dropout(p=0.1))\n        # L5 Final FC 625 inputs -> 10 outputs\n        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(out.size(0), -1)   # Flatten them for FC\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out","cd389680":"def train(net):\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n    net.to(device)\n\n    criterion = nn.CrossEntropyLoss().to(device)\n    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\n    for epoch in range(2):  # loop over the dataset multiple times\n\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data[0].to(device), data[1].to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            if i % 2000 == 1999:    # print every 2000 mini-batches\n                print('[%d, %5d] loss: %.3f' %\n                      (epoch + 1, i + 1, running_loss \/ 2000))\n                running_loss = 0.0\n\n    print('Finished Training')\n    return net","686492e8":"def test(net):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the network on the 10000 test images: %d %%' % (\n        100 * correct \/ total))\n    return correct \/ total","50ece391":"# display(print(\"Net Original\"))\n\n# times = 5\n# mean = 0\n\n# for _ in range(times):\n#     net_orginal = NetOrginal()\n#     net_orginal = train(net_orginal)\n#     mean += test(net_orginal)\n\n# display(print('Accuracy means: %d %%' % (\n#     100 * mean \/ times)))\n    ","00815714":"# display(print(\"Net Cat dog\"))\n\n# times = 5\n# mean = 0\n\n# for _ in range(times):\n#     net_cat_dog = CatAndDogNet()\n#     net_cat_dog = train(net_cat_dog)\n#     mean += test(net_cat_dog)\n\n# display(print('Accuracy means: %d %%' % (\n#     100 * mean \/ times)))","c6144aae":"# display(print(\"Net Cat dog\"))\n\n# times = 5\n# mean = 0\n\n# for _ in range(times):\n#     net_cnn_tcc = CnnTCC()\n#     net_cnn_tcc = train(net_cnn_tcc)\n#     mean += test(net_cnn_tcc)\n\n# display(print('Accuracy means: %d %%' % (\n#     100 * mean \/ times)))","1aa6d41a":"# display(print(\"Net CNN MNIST\"))\n\n# times = 5\n# mean = 0\n\n# for _ in range(times):\n#     net_cnn_mnist = CNN_MNIST()\n#     net_cnn_mnist = train(net_cnn_mnist)\n#     mean += test(net_cnn_mnist)\n    \n# display(print('Accuracy means: %d %%' % (\n#     100 * mean \/ times)))","5cb63476":"### Segunda Arquitetura","603d0dd0":"### Primeira Arquitetura\nhttps:\/\/www.kaggle.com\/hung96ad\/dogs-vs-cats-pytorch-cnn-without-transfer-learning","9b7d09b1":"### Treinando as 3 tipos de redes","83c82f31":"Esse modelo \u00e9 baseado em uma camada de convolu\u00e7\u00e3o seguido por uma batch normalization outra camada de convolu\u00e7\u00e3o seguida de uma batch normalization seguido de um max pool. Depois disso \u00e9 adicionado uma camada totalmete conectada composta de 3 lineares com fun\u00e7\u00e3o de ativa\u00e7\u00e3o tagente hiperbolica entre elas.\n\nNa saida da rede foi adicionado uma fun\u00e7\u00e3o de softmax.","3b64c570":"1. [1,  2000] loss: 2.267\n1. [1,  4000] loss: 2.218\n1. [1,  6000] loss: 2.186\n1. [1,  8000] loss: 2.162\n1. [1, 10000] loss: 2.146\n1. [1, 12000] loss: 2.132\n1. [2,  2000] loss: 2.101\n1. [2,  4000] loss: 2.097\n1. [2,  6000] loss: 2.077\n1. [2,  8000] loss: 2.071\n1. [2, 10000] loss: 2.057\n1. [2, 12000] loss: 2.060\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 42 %\n1. [1,  2000] loss: 2.269\n1. [1,  4000] loss: 2.216\n1. [1,  6000] loss: 2.183\n1. [1,  8000] loss: 2.148\n1. [1, 10000] loss: 2.121\n1. [1, 12000] loss: 2.113\n1. [2,  2000] loss: 2.079\n1. [2,  4000] loss: 2.081\n1. [2,  6000] loss: 2.062\n1. [2,  8000] loss: 2.061\n1. [2, 10000] loss: 2.049\n1. [2, 12000] loss: 2.057\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 43 %\n1. [1,  2000] loss: 2.270\n1. [1,  4000] loss: 2.217\n1. [1,  6000] loss: 2.181\n1. [1,  8000] loss: 2.153\n1. [1, 10000] loss: 2.121\n1. [1, 12000] loss: 2.112\n1. [2,  2000] loss: 2.083\n1. [2,  4000] loss: 2.074\n1. [2,  6000] loss: 2.054\n1. [2,  8000] loss: 2.050\n1. [2, 10000] loss: 2.035\n1. [2, 12000] loss: 2.027\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 44 %\n1. [1,  2000] loss: 2.274\n1. [1,  4000] loss: 2.223\n1. [1,  6000] loss: 2.180\n1. [1,  8000] loss: 2.152\n1. [1, 10000] loss: 2.127\n1. [1, 12000] loss: 2.108\n1. [2,  2000] loss: 2.080\n1. [2,  4000] loss: 2.072\n1. [2,  6000] loss: 2.072\n1. [2,  8000] loss: 2.060\n1. [2, 10000] loss: 2.054\n1. [2, 12000] loss: 2.050\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 43 %\n1. [1,  2000] loss: 2.273\n1. [1,  4000] loss: 2.226\n1. [1,  6000] loss: 2.197\n1. [1,  8000] loss: 2.161\n1. [1, 10000] loss: 2.147\n1. [1, 12000] loss: 2.127\n1. [2,  2000] loss: 2.101\n1. [2,  4000] loss: 2.093\n1. [2,  6000] loss: 2.080\n1. [2,  8000] loss: 2.076\n1. [2, 10000] loss: 2.066\n1. [2, 12000] loss: 2.055\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 42 %\n1. Accuracy means: 43 %","8e9ad401":"Esse modelo ela \u00e9 composta por 2 camadas de convolu\u00e7\u00e3o(convulucao, seguindo de uma relu, seguido de um max pool), depois pasando por uma batch normalization e depois passando por uma totalmente conectada composta por 3 camadas lineares com uma relu e um dropout entre elas.","9d355057":"https:\/\/towardsdatascience.com\/convolutional-neural-network-for-image-classification-with-implementation-on-python-using-pytorch-7b88342c9ca9","1fefe4f5":"### Terceira Arquitetura\n","38c10ce9":"Arquitetura utilizado no meu tcc","f6ef9f86":"### PyTorch e o m\u00f3dulo TorchVision para vis\u00e3o computacional","b3677f6a":"1. [1,  2000] loss: 1.943\n1. [1,  4000] loss: 1.663\n1. [1,  6000] loss: 1.547\n1. [1,  8000] loss: 1.473\n1. [1, 10000] loss: 1.434\n1. [1, 12000] loss: 1.417\n1. [2,  2000] loss: 1.327\n1. [2,  4000] loss: 1.311\n1. [2,  6000] loss: 1.301\n1. [2,  8000] loss: 1.247\n1. [2, 10000] loss: 1.237\n1. [2, 12000] loss: 1.218\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 57 %\n1. [1,  2000] loss: 1.984\n1. [1,  4000] loss: 1.682\n1. [1,  6000] loss: 1.591\n1. [1,  8000] loss: 1.510\n1. [1, 10000] loss: 1.480\n1. [1, 12000] loss: 1.407\n1. [2,  2000] loss: 1.337\n1. [2,  4000] loss: 1.329\n1. [2,  6000] loss: 1.293\n1. [2,  8000] loss: 1.282\n1. [2, 10000] loss: 1.261\n1. [2, 12000] loss: 1.253\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 56 %\n1. [1,  2000] loss: 1.936\n1. [1,  4000] loss: 1.678\n1. [1,  6000] loss: 1.564\n1. [1,  8000] loss: 1.502\n1. [1, 10000] loss: 1.434\n1. [1, 12000] loss: 1.418\n1. [2,  2000] loss: 1.330\n1. [2,  4000] loss: 1.323\n1. [2,  6000] loss: 1.304\n1. [2,  8000] loss: 1.272\n1. [2, 10000] loss: 1.240\n1. [2, 12000] loss: 1.228\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 57 %\n1. [1,  2000] loss: 1.962\n1. [1,  4000] loss: 1.659\n1. [1,  6000] loss: 1.557\n1. [1,  8000] loss: 1.491\n1. [1, 10000] loss: 1.472\n1. [1, 12000] loss: 1.406\n1. [2,  2000] loss: 1.347\n1. [2,  4000] loss: 1.328\n1. [2,  6000] loss: 1.329\n1. [2,  8000] loss: 1.290\n1. [2, 10000] loss: 1.243\n1. [2, 12000] loss: 1.248\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 55 %\n1. [1,  2000] loss: 1.939\n1. [1,  4000] loss: 1.676\n1. [1,  6000] loss: 1.573\n1. [1,  8000] loss: 1.506\n1. [1, 10000] loss: 1.445\n1. [1, 12000] loss: 1.402\n1. [2,  2000] loss: 1.351\n1. [2,  4000] loss: 1.325\n1. [2,  6000] loss: 1.282\n1. [2,  8000] loss: 1.237\n1. [2, 10000] loss: 1.237\n1. [2, 12000] loss: 1.240\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 57 %\n1. Accuracy means: 56 %","f78d19c5":"### Rede CNN original","046fce88":"1. [1,  2000] loss: 1.855\n1. [1,  4000] loss: 1.523\n1. [1,  6000] loss: 1.365\n1. [1,  8000] loss: 1.282\n1. [1, 10000] loss: 1.221\n1. [1, 12000] loss: 1.154\n1. [2,  2000] loss: 1.072\n1. [2,  4000] loss: 1.038\n1. [2,  6000] loss: 1.015\n1. [2,  8000] loss: 0.994\n1. [2, 10000] loss: 0.967\n1. [2, 12000] loss: 0.958\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 66 %\n1. [1,  2000] loss: 1.884\n1. [1,  4000] loss: 1.503\n1. [1,  6000] loss: 1.355\n1. [1,  8000] loss: 1.250\n1. [1, 10000] loss: 1.175\n1. [1, 12000] loss: 1.125\n1. [2,  2000] loss: 1.029\n1. [2,  4000] loss: 1.025\n1. [2,  6000] loss: 0.995\n1. [2,  8000] loss: 0.943\n1. [2, 10000] loss: 0.953\n1. [2, 12000] loss: 0.914\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 64 %\n1. [1,  2000] loss: 1.836\n1. [1,  4000] loss: 1.520\n1. [1,  6000] loss: 1.351\n1. [1,  8000] loss: 1.269\n1. [1, 10000] loss: 1.174\n1. [1, 12000] loss: 1.124\n1. [2,  2000] loss: 1.017\n1. [2,  4000] loss: 0.998\n1. [2,  6000] loss: 0.975\n1. [2,  8000] loss: 0.952\n1. [2, 10000] loss: 0.958\n1. [2, 12000] loss: 0.912\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 66 %\n1. [1,  2000] loss: 1.864\n1. [1,  4000] loss: 1.491\n1. [1,  6000] loss: 1.371\n1. [1,  8000] loss: 1.277\n1. [1, 10000] loss: 1.196\n1. [1, 12000] loss: 1.142\n1. [2,  2000] loss: 1.066\n1. [2,  4000] loss: 1.044\n1. [2,  6000] loss: 1.001\n1. [2,  8000] loss: 0.962\n1. [2, 10000] loss: 0.952\n1. [2, 12000] loss: 0.945\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 65 %\n1. [1,  2000] loss: 1.890\n1. [1,  4000] loss: 1.522\n1. [1,  6000] loss: 1.372\n1. [1,  8000] loss: 1.271\n1. [1, 10000] loss: 1.204\n1. [1, 12000] loss: 1.146\n1. [2,  2000] loss: 1.033\n1. [2,  4000] loss: 1.016\n1. [2,  6000] loss: 1.018\n1. [2,  8000] loss: 0.983\n1. [2, 10000] loss: 0.980\n1. [2, 12000] loss: 0.938\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 66 %\n1. Accuracy means: 65 %","e89bf144":"![modelo](https:\/\/miro.medium.com\/max\/3048\/1*JAoTFAsN5HCrRgrJPaBgrg.png)","e8f67876":"### Conclus\u00e3o","c47bcbee":"### Treinamento","e0774a13":"Com esse experimento foi possivel concluir que adi\u00e7\u00e3o de novos elementos nas camadas de uma rede neural podem ajudar e ao mesmo tempo podem atrapalhar um modelo. Isso vem com o fato de que muitos componentes podem fazer com que a rede fique especialista no problema, entretanto se colocar poucos componentes na  arqeuitetura da rede ela fica generica demais, podendo sofrer de overfitting ou underfitting ","95556d6c":"## Redes Neurais Convolucionais ","9365fbf1":"Fabricio Torquato - 153124","2ac524ac":"### Verificando a acur\u00e1cia do conjunto de teste","6ef4e51d":"1. [1,  2000] loss: 1.958\n1. [1,  4000] loss: 1.669\n1. [1,  6000] loss: 1.556\n1. [1,  8000] loss: 1.484\n1. [1, 10000] loss: 1.405\n1. [1, 12000] loss: 1.387\n1. [2,  2000] loss: 1.317\n1. [2,  4000] loss: 1.309\n1. [2,  6000] loss: 1.302\n1. [2,  8000] loss: 1.270\n1. [2, 10000] loss: 1.231\n1. [2, 12000] loss: 1.221\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 56 %\n1. [1,  2000] loss: 1.947\n1. [1,  4000] loss: 1.642\n1. [1,  6000] loss: 1.553\n1. [1,  8000] loss: 1.493\n1. [1, 10000] loss: 1.436\n1. [1, 12000] loss: 1.389\n1. [2,  2000] loss: 1.313\n1. [2,  4000] loss: 1.305\n1. [2,  6000] loss: 1.279\n1. [2,  8000] loss: 1.258\n1. [2, 10000] loss: 1.241\n1. [2, 12000] loss: 1.222\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 57 %\n1. [1,  2000] loss: 1.950\n1. [1,  4000] loss: 1.652\n1. [1,  6000] loss: 1.537\n1. [1,  8000] loss: 1.501\n1. [1, 10000] loss: 1.435\n1. [1, 12000] loss: 1.424\n1. [2,  2000] loss: 1.319\n1. [2,  4000] loss: 1.319\n1. [2,  6000] loss: 1.286\n1. [2,  8000] loss: 1.259\n1. [2, 10000] loss: 1.270\n1. [2, 12000] loss: 1.227\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 54 %\n1. [1,  2000] loss: 1.940\n1. [1,  4000] loss: 1.627\n1. [1,  6000] loss: 1.530\n1. [1,  8000] loss: 1.461\n1. [1, 10000] loss: 1.417\n1. [1, 12000] loss: 1.363\n1. [2,  2000] loss: 1.277\n1. [2,  4000] loss: 1.285\n1. [2,  6000] loss: 1.239\n1. [2,  8000] loss: 1.245\n1. [2, 10000] loss: 1.225\n1. [2, 12000] loss: 1.215\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 57 %\n1. [1,  2000] loss: 1.934\n1. [1,  4000] loss: 1.659\n1. [1,  6000] loss: 1.550\n1. [1,  8000] loss: 1.488\n1. [1, 10000] loss: 1.424\n1. [1, 12000] loss: 1.391\n1. [2,  2000] loss: 1.302\n1. [2,  4000] loss: 1.319\n1. [2,  6000] loss: 1.268\n1. [2,  8000] loss: 1.251\n1. [2, 10000] loss: 1.261\n1. [2, 12000] loss: 1.246\n1. Finished Training\n1. Accuracy of the network on the 10000 test images: 55 %\n1. Accuracy means: 56 %"}}