{"cell_type":{"8d73141d":"code","eee2cd70":"code","6c140377":"code","111cf9b1":"code","5b6aae3b":"code","3a25bdaf":"code","dfca874e":"code","78df6d9d":"code","a6b3fc1d":"code","0e55dadd":"code","3d6568e6":"code","63d234ef":"code","2317f477":"code","99bbd898":"code","bc909b66":"code","1886e776":"code","41fa2e85":"code","aeb216e4":"markdown","a854da38":"markdown","a579e961":"markdown","8d4924dd":"markdown","2c18f138":"markdown","ea1f2ed9":"markdown"},"source":{"8d73141d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eee2cd70":"import os\nimport glob\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import *","6c140377":"# setting up the base data_directory\ndata_directory = \"\/kaggle\/input\/fruit-recognition\/\"\n\n# creating a data pattern, the * is a wildcard. There are other wildcards too such as ? and [ranges]\ndata_pattern = os.path.sep.join([data_directory,\"*\/*.png\"])\nprint(data_pattern)","111cf9b1":"# glob() function allows you to find files recursively in python that match a specified pattern\nimage_paths = list(glob.glob(data_pattern))","5b6aae3b":"# showing the first 5 images in the list\nfor i in range(5):\n    print(image_paths[i])","3a25bdaf":"sample_image = load_img(image_paths[0])\nprint(f'Image type: {type(sample_image)}')\nprint(f'Image format: {sample_image.format}')\nprint(f'Image mode: {sample_image.mode}')\nprint(f'Image size: {sample_image.size}')","dfca874e":"# Convert image to array\nsample_image_array = img_to_array(sample_image)\nprint(f'Image array shape: {sample_image_array.shape}')\nplt.imshow(sample_image_array \/255.0)","78df6d9d":"# create scale factor so the pixels are between 0-1 instead of 0-255\nscale_factor = 1.0 \/ 255.0\n\n# create ImageDataGenerator\nimage_generator = ImageDataGenerator(horizontal_flip=True, rescale=scale_factor)\n\n# create DirectoryIterator\niterator = (image_generator.flow_from_directory(directory=data_directory, batch_size=10))","a6b3fc1d":"# iterate through a single batch of images by using a for loop\nfor batch, labels in iterator:\n    plt.figure(figsize=(5, 5))\n    for index, image in enumerate(batch, start=1):\n        ax = plt.subplot(5, 5, index)\n        plt.imshow(image)\n        plt.axis('off')\n        \n    plt.show()\n    # print the label at the bottom to see what the label looks like for a single batch, as we can see it is one-hot encoded\n    print(labels)\n    # break so that it only iterates through a single batch and then the for loop is over\n    break","0e55dadd":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf","3d6568e6":"# setting up the base data_directory\ndata_directory = \"\/kaggle\/input\/fruit-recognition\/\"\n\n# creating a data pattern, the * is a wildcard. There are other wildcards too such as ? and [ranges]\ndata_pattern = data_directory + \"*\/*.png\"\nprint(data_pattern)","63d234ef":"# creating ShuffleDataset\nimage_dataset = tf.data.Dataset.list_files(data_pattern)\nprint(image_dataset)","2317f477":"# need to iterate through the TakeDataset object using a for loop\nfor file_path in image_dataset.take(1):\n    sample_path = file_path.numpy()\n    print(f'Sample image path: {sample_path}')","99bbd898":"# creating a tf.Tensor by using tf.io.read_file\nsample_image = tf.io.read_file(sample_path)\nprint(f'Image type: {type(sample_image)}')","bc909b66":"# decode to png\nsample_image = tf.image.decode_png(sample_image, channels=3)\nprint(type(sample_image))\nsample_image","1886e776":"# show image, divide by 255 so that the range is 0-1 instead of 0-255\nplt.imshow(sample_image.numpy() \/ 255.0)","41fa2e85":"plt.figure(figsize=(5, 5))\nfor index, image_path in enumerate(image_dataset.take(10), start=1):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, channels=3)\n    image = tf.image.convert_image_dtype(image, np.float32)\n    \n    ax = plt.subplot(5, 5, index)\n    plt.imshow(image)\n    plt.axis('off')\n    \nplt.show()\nplt.close()","aeb216e4":"## Loading a Batch of Images","a854da38":"## Loading and Showing a single image","a579e961":"# Loading Images with tf_data api\nTo load individual images:\n* feed data_pattern into tf.data.Dataset.list_files\n* get path of an image by doing image_dataset.take(1).numpy()\n* do tf.io.read_file\n* tf.image.decode_png\n* convert to numpy, divide by 255\n* do plt.imshow()\n\nTo load batches\n* do image_dataset.take(10).numpy()\n* do tf.io.read_file(image_path)\n* do tf.image.decode_png(image, channels=3)\n* do tf.image.convert_image_dtype(image, np.float32)\n* do plt.imshow()","8d4924dd":"## Loading a Single Image","2c18f138":"# Keras API\nTo load individual images:\n* glob pattern to get list of items\n* load_image from one of the image paths from the list\n* show the image\n\nTo load batches\n* create ImageDataGenerator\n* do ImageDataGenerator.flow_from_directory\n* create for loop to iterate through the flow_from_directory item. Set \"break\" at the end of one iteration through the loop to get just one batch","ea1f2ed9":"## Loading and Showing a Batch of Images"}}