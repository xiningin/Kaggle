{"cell_type":{"a747c95f":"code","2d7196f7":"code","81c80748":"code","49dbdeaf":"code","633daf07":"code","460245b1":"code","7f6ea61d":"code","128c03d3":"code","6fa58b12":"code","7b7caf25":"code","ad32ad82":"code","ed0426e2":"code","253f2202":"code","a0d6f108":"code","2ca50c52":"code","e5af1dea":"code","57248aad":"code","102acb87":"code","c9fa3359":"code","32da6124":"code","67a94109":"code","3d8100a7":"code","e87ffe1c":"markdown","287288d8":"markdown","99a36b37":"markdown","6b7ed9b2":"markdown","71b32f9e":"markdown","c9a3e870":"markdown"},"source":{"a747c95f":"import numpy\nimport pandas as pd\n","2d7196f7":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier","81c80748":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndata=[train_data , test_data]\n","49dbdeaf":"train_data\ntest_data","633daf07":"women = train_data.loc[train_data.Sex=='female'][\"Survived\"]\nrate=sum(women)\/len(women)\n\nprint(rate)","460245b1":"men = train_data.loc[train_data.Sex =='male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(rate_men)","7f6ea61d":"age_ref=pd.DataFrame(data= [train_data.groupby('Pclass')['Age'].mean()], columns = train_data['Pclass'].unique())\nage_ref","128c03d3":"def fill_age(pclass,age):\n    if pd.isnull(age):\n        return age_ref[pclass]\n    else:\n        return age\nfor d in data:\n    d['Age']= train_data.apply(lambda x: fill_age(x['Pclass'],x['Age']),axis=1)\nfor d in data:\n    print(d.isnull().sum())\n    ","6fa58b12":"def fill_fare(fare):\n    if pd.isnull(fare):\n        return train_data['Fare'].mean()\n    else:\n        return fare\n    \ndef fill_embark(embarked):\n    if pd.isnull(embarked):\n        return train_data['Embarked'].mode().iloc[0]\n    else:\n        return embarked\nfor d in data:\n    d['Fare']=train_data.apply(lambda x : fill_fare(x['Fare']),axis=1)\n    d['Embarked']=train_data.apply(lambda x: fill_embark(x['Embarked']),axis=1)\n\nfor d in data:\n    print(d.isnull().sum())\n    ","7b7caf25":"for d in data:\n    d.drop(['Cabin'],axis=1,inplace=True)","ad32ad82":"for d in data:\n    print(d.isnull().sum())","ed0426e2":"title_list=list()\nfor d in data:\n    for title in d['Name']:\n        title=title.split('.')[0].split(',')[1]\n        title_list.append(title)\n    d['Title']=title_list\n    title_list=list()","253f2202":"for d in data:\n    print(d['Title'].value_counts())\n","a0d6f108":"train_data['Title']=train_data['Title'].replace([' Dr',' Rev',' Col',' Mlle',' Major',' Sir',' Lady',' Capt',' Mme',' Ms',' Don',' the Countess',' Jonkheer'],' Others')\ntrain_data['Title'].value_counts()\n","2ca50c52":"test_data['Title']=test_data['Title'].replace([' Col',' Rev',' Dr',' Dona',' Ms'], ' Others')\ntest_data['Title'].value_counts()","e5af1dea":"def get_size(df):\n    if df['SibSp']+df['Parch']+1==1:\n        return 'Single'\n    if df['SibSp']+df['Parch']+1>1:\n        return 'Small'\n    if df['SibSp']+df['Parch']+1>4:\n        return 'Big'\nfor d in data:\n    d['FamilySize']=d.apply(get_size,axis=1)\n    \nfor d in data:\n    d['IsAlone']=1\n    d['IsAlone'].loc[d['FamilySize']!='Single']=0","57248aad":"sex = pd.get_dummies(train_data['Sex'])\nembark = pd.get_dummies(train_data['Embarked'])\ntitle = pd.get_dummies(train_data['Title'])\nPclass = pd.get_dummies(train_data['Pclass'])\nFamilySize = pd.get_dummies(train_data['FamilySize'])\n\nsex2 = pd.get_dummies(test_data['Sex'])\nembark2 = pd.get_dummies(test_data['Embarked'])\ntitle2 = pd.get_dummies(test_data['Title'])\nPclass2 = pd.get_dummies(test_data['Pclass'])\nFamilySize2 = pd.get_dummies(test_data['FamilySize'])\n\nfor d in data:\n    d.drop(['Sex','Embarked','Name','Ticket','Title','FamilySize'],axis=1,inplace=True)\n    \ntrain_data = pd.concat([sex,embark,train_data,title,FamilySize],axis=1)\ntest_data = pd.concat([sex2,embark2,test_data,title2,FamilySize2],axis=1)","102acb87":"X = train_data.drop('Survived',axis=1)\ny = train_data['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","c9fa3359":"scaler = MinMaxScaler()\n\nscaler.fit(X_train)\n\nscaler.transform(X_train)\nscaler.transform(X_test)\nscaler.transform(test_data)","32da6124":"model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X_train, y_train)\ny_pred=model.predict(X_test)\n","67a94109":"print(classification_report(y_test,y_pred))\nprint('\\n')\nprint(confusion_matrix(y_test,y_pred))","3d8100a7":"predictions = model.predict(test_data)\npred_list = [int(x) for x in predictions]\n\ntest2 = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\noutput = pd.DataFrame({'PassengerId': test2['PassengerId'], 'Survived': pred_list})\noutput.to_csv('MySubmission3.csv', index=False)","e87ffe1c":"# Missing Values\n\n","287288d8":"# Data PreProcessing ","99a36b37":"Random Forest Modelling****","6b7ed9b2":"# Importing the DataSet","71b32f9e":"# Feature Scaling\n","c9a3e870":"# Importing the Libraries"}}