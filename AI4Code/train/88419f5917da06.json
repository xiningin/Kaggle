{"cell_type":{"b1c1b3d9":"code","e424ea33":"code","24b7f3c1":"code","a5839899":"code","340f343f":"code","09140eba":"code","663ddcfc":"code","5f649182":"code","04a6c43d":"code","69eb34b8":"code","823626b8":"code","7e5ca766":"code","fb1ba34d":"code","ed51b81d":"code","1e05f744":"code","6727967a":"code","b92156ce":"code","1283e7fc":"code","8358ef5d":"code","c9540cb2":"code","838ec9f2":"markdown","670ffbce":"markdown","8f9eda68":"markdown","6e66802c":"markdown","e225ab1b":"markdown","d530d263":"markdown","0aa4f5ff":"markdown","194d07de":"markdown","b3d144ed":"markdown","98ab2b1b":"markdown","45b8077a":"markdown","e713f198":"markdown","9b2b97eb":"markdown","1ac0c997":"markdown","c2dfabb7":"markdown","3b534fe8":"markdown"},"source":{"b1c1b3d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        assessment_dataset_path = os.path.join(dirname, filename)\n        assessment_data = pd.read_csv(assessment_dataset_path)\n\n# Any results you write to the current directory are saved as output.\nassessment_data.head()","e424ea33":"assessment_data = assessment_data.rename(columns = {'Date' : 'date', 'purchase_amonut' : 'purchase_amount'})\nassessment_data.head()","24b7f3c1":"print('Is there any missing value in the assessment data?',\n      assessment_data.isnull().values.any())","a5839899":"import time\nimport datetime\n\nnormalized_date = []\nmin_date = time.mktime(datetime.datetime.strptime(assessment_data.loc[0, 'date'], \"%m\/%d\/%Y\").timetuple())\nmax_date = time.mktime(datetime.datetime.strptime(assessment_data.loc[0, 'date'], \"%m\/%d\/%Y\").timetuple())\n\nfor i, row in assessment_data.iterrows():\n    timestamp = time.mktime(datetime.datetime.strptime(row['date'], \"%m\/%d\/%Y\").timetuple())\n    if min_date > timestamp:\n        min_date = timestamp\n    if max_date < timestamp:\n        max_date = timestamp\n    normalized_date.append(int(timestamp))\n    \nassessment_data['normalized_date'] = normalized_date\nassessment_data.head()","340f343f":"from datetime import datetime\n\ndate_domain = max_date - min_date\n\nfor i, row in assessment_data.iterrows():\n    assessment_data.loc[i, 'normalized_date'] = (int(row['normalized_date']) - min_date) \/ date_domain\n    \nassessment_data.head()","09140eba":"print('Starting date: ', datetime.fromtimestamp(min_date).date())\nprint('Ending date: ', datetime.fromtimestamp(max_date).date())\n\nprint('The number of records: ', len(assessment_data))\nprint('The number of unique user IDs: ', len(assessment_data['user_id'].unique()))\nprint('The number of unique devices: ', len(assessment_data['device'].unique()))\nprint('The number of unique locations: ', len(assessment_data['location'].unique()))","663ddcfc":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nplt.figure(figsize=(18,12))\nplot = sns.distplot(a=assessment_data[\"normalized_date\"]*4*31, kde=True, color='yellow')\nplot.set(xlabel ='The days from May 1 to August 31', ylabel ='The frequency of purchases')\nplt.show()","5f649182":"plt.figure(figsize=(18,12))\nplot = sns.distplot(a=assessment_data[\"purchase_amount\"], kde=True, color='orange')\nplot.set(xlabel ='The amount of purchase', ylabel ='Frequency')\nplt.show()","04a6c43d":"sizes = []\ndevices = assessment_data['device'].unique()\n\nfor device in devices:\n    sizes.append(len(assessment_data[assessment_data['device'] == device]))\n    \nsizes\n\nfig, ax = plt.subplots(figsize=(18,12))\n\nax.pie(sizes,\n       labels= devices,\n      autopct='%1.1f%%')\n\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","69eb34b8":"amounts = []\ndevices = assessment_data['device'].unique()\n\nfor device in devices:\n    amounts.append(assessment_data[assessment_data['device'] == device]['purchase_amount'].sum() \/\n                   len(assessment_data[assessment_data['device'] == device]))\n\nfig, ax = plt.subplots(figsize=(18,12))\n    \nax.pie(amounts,\n       labels= devices,\n      autopct='%1.1f%%')\n\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","823626b8":"amounts = []\nlocations = assessment_data['location'].unique()\n\nfor location in locations:\n    amounts.append(assessment_data[assessment_data['location'] == location]['purchase_amount'].sum())\n\nfig, ax = plt.subplots(figsize=(18,12))\n    \nax.pie(amounts,\n       labels= locations,\n      autopct='%1.1f%%')\n\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","7e5ca766":"amounts = []\nlocations = assessment_data['location'].unique()\n\nfor location in locations:\n    amounts.append(assessment_data[assessment_data['location'] == location]['purchase_amount'].sum() \/\n                  len(assessment_data[assessment_data['location'] == location]))\n\nfig, ax = plt.subplots(figsize=(18,12))\n    \nax.pie(amounts,\n       labels= locations,\n      autopct='%1.1f%%')\n\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","fb1ba34d":"plt.figure(figsize=(18,12))\nsns.scatterplot(x=assessment_data['location'], y=assessment_data[\"purchase_amount\"], hue=assessment_data['user_id'], legend = 'full')\nplt.legend(loc='lower left', bbox_to_anchor=(1, 0.5))\nplt.show()","ed51b81d":"plt.figure(figsize=(18,12))\nsns.scatterplot(x=assessment_data[\"normalized_date\"]*31*4, y=assessment_data[\"purchase_amount\"], hue=assessment_data[\"location\"])\nplt.legend(loc='lower left', bbox_to_anchor=(1, 0.5))\nplot.set(xlabel ='Day', ylabel ='The amount of purchase')\nplt.show()\n","1e05f744":"plt.figure(figsize=(18,12))\nsns.scatterplot(x=assessment_data['user_id'], y=assessment_data[\"purchase_amount\"], hue=assessment_data['device'], palette = 'Set2')\nplt.legend(loc='lower left', bbox_to_anchor=(1, 0.5))\nplt.show()","6727967a":"amounts = []\nusers = assessment_data['user_id'].unique()\n\nfor user in users:\n    amounts.append(assessment_data[assessment_data['user_id'] == user]['purchase_amount'].sum() \/\n                   len(assessment_data[assessment_data['user_id'] == user]))\n\nfig, ax = plt.subplots(figsize=(18,12))\n    \nax.pie(amounts,\n       labels= users,\n      autopct='%1.1f%%')\n\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","b92156ce":"plt.figure(figsize=(18,12))\n\nfor i in range(len(assessment_data['user_id'].unique())):\n    user_id = assessment_data['user_id'].unique()[i]\n    sns.lineplot(x=assessment_data[assessment_data['user_id'] == user_id]['normalized_date']*31*4, y='purchase_amount', data=assessment_data[assessment_data['user_id'] == user_id], legend='brief')\nplt.legend(loc='lower left', bbox_to_anchor=(1, 0.5))\nplt.show()\n# plot = sns.distplot(a=assessment_data[\"normalized_date\"]*4*31, kde=True, color='yellow')\n# plot.set(xlabel ='The days from May 1 to August 31', ylabel ='The frequency of purchases')\n# plt.show()","1283e7fc":"print('Average purchase amount: ', assessment_data['purchase_amount'].sum() \/ len(assessment_data))","8358ef5d":"print('Average sales amount per day: ', assessment_data['purchase_amount'].sum() \/ (31*4))\nprint('Average sales amount per week: ', assessment_data['purchase_amount'].sum() \/ (31*4\/7))\nprint('Average sales amount per month: ', assessment_data['purchase_amount'].sum() \/ 4)","c9540cb2":"print('Average sales amount per user: ', assessment_data['purchase_amount'].sum() \/ len(assessment_data['user_id'].unique()))\n\namounts = []\nusers = assessment_data['user_id'].unique()\n\nfor user in users:\n    amounts.append(assessment_data[assessment_data['user_id'] == user]['purchase_amount'].sum())\n\nprint('Minimum of total amount of purchases of users: ', np.min(amounts))    \nprint('Median of total amount of purchases of users: ', np.median(amounts))\nprint('Maximum of total amount of purchases of users: ', np.max(amounts))","838ec9f2":"Display the distribution of purchases by their amount during the time, colored based on their region.\n*In this plot, the conclusions of previously shown scatterplot could be tracked by their time of occurance.*","670ffbce":"The **normalized_date** contains normalized values (ranging from 0 to 1) corresponding to the date attribute of each record.","8f9eda68":"Depict the proportional total amount of purchases distribution in different regions.\n* It could be concluded that the biggest spending region is Tehran, which is twice bigger than the second region, Razavi Khorasan.\n* I could be concluded that Kerman is the smallest spending region.","6e66802c":"* So far, we know that the assessment data includes **786 purchases** made by **18 users** by **23 different devices** from **14 different locations** during **a four month period** from May 1 to August 31 in year 2014.","e225ab1b":"Depict the purchasing trend of every user over the time, distinguished by their color.\n* It could be concluded that most of the **big purchases** have been made about **end of the months** (the May, June and July).","d530d263":"Depict the average amount of purchases made by different users. It could be seen that **the biggest spending customer** is user ID 4, in contrary to user ID 15.","0aa4f5ff":"Depict the distribution of purchases made by each user (the horizontal axis) based on their amount (the vertical axis) colored by the device.\n* It could be concluded that every user has used multiple devices for different purchases.\n* Users with user IDs 1, 3, 11 and 12 have made outlier purchases (way out of their usual purchases amount range)","194d07de":"Depict the distribution of purchases based on their amount for each region, colored based on the user IDs.\n* It could be concluded that two biggest purchases have been made from Qom and Khuzestan (outliers).","b3d144ed":"Although the average amount of purchases made using all devices are almost the same,\n* It could be concluded that purchases with **bigger amounts** have been made using the **\"Windows Surface\"**. Also in the previously shown piechart it was concluded that the least frequently-used device is the \"Windows Surface\".\n* On the other hand, purchases with **smaller amounts** belong to the **\"Acer Aspire Notebook\"** users.","98ab2b1b":"Depict the average amount of purchases made in each region.\n* Although it was concluded in the previous piechart that Kerman is the smallest spending region, here it is shown that concerning the number of purchases, users from **Kerman** have made **the biggest purchases**, as well as **Fars**.\n","45b8077a":"* It could be concluded that the frequency of purchases has peaked in **the early days of June** and also in **the early days of July**.","e713f198":"**Here are the first 5 records of the Jabama assessment dataset.**\nIt looks like there is a misspelling in the last column's title!","9b2b97eb":"* It could be concluded that the **most frequently-used devices** are the **\"Macbook Pro\"** and the **\"Lenovo Thinkpad\"**. The least frequently-used device is **\"Windows Surface\"**.","1ac0c997":"* It could be concluded that **most of the purchases** have been made **around 100,000 (Rials)**, and purchases worth more than 400,000 (Rials) are rare.","c2dfabb7":"It is handier to manipulate or compare records' dates in a **datetime format** compared to the initial date format of the assessment data.","3b534fe8":"**The columns' titles are normalized.** Now, let us find out if there is any missing value in the dataset:"}}