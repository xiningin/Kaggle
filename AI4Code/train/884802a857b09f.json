{"cell_type":{"ee1d9514":"code","57e5ec3f":"code","cfa46a49":"code","e14acdac":"code","96652786":"code","a2c566f9":"code","a336f5cf":"code","a1e79fec":"code","fa5b9595":"code","16c6c7d3":"code","e3293c82":"code","da8a4a7d":"code","6f37d767":"code","a42fa3fd":"markdown","22be1397":"markdown","83ad76c3":"markdown","d3d60c13":"markdown","b0a184b7":"markdown","c7c952d7":"markdown","37914f3f":"markdown","ef3ea31c":"markdown","d7cae62a":"markdown","00ed0e87":"markdown","28c4ae98":"markdown","068c72ef":"markdown","110ebaba":"markdown"},"source":{"ee1d9514":"import math\nimport numpy as np\r\nimport pandas as pd\r\nimport plotly.express as px\r\nimport plotly.graph_objects as go\r\nimport plotly.figure_factory as ff\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.model_selection import train_test_split","57e5ec3f":"mean_01=np.array([1,1])\r\ncov_01=np.array([[1,-0.2],[-0.2,1]])\r\nmean_02=np.array([3,4])\r\ncov_02=np.array([[1,0.1],[0.1,1]])\r\nnp.random.seed(42)\r\ndata_01=np.random.multivariate_normal(mean_01,cov_01,500, check_valid= \"warn\")\r\ndata_02=np.random.multivariate_normal(mean_02,cov_02,500, check_valid= \"warn\")\r\ndata = np.vstack((data_01,data_02))\r\ndf_train = pd.DataFrame(data, columns = [\"Feature_1\", \"Feature_2\"])\r\ndf_train[\"class\"] = [0]*500 + [1]*500 ","cfa46a49":"fig = go.Figure(\n    layout = dict(\n        width = 800,\n        height = 800,\n        title_text = \"Visualization of the dataset\",\n        xaxis = dict(\n            title = dict(\n                text = \"Feature_1\"\n            )\n        ),\n        yaxis = dict(\n            title = dict(\n                text = \"Feature_2\"\n            )\n        )\n    )\n)\n\nscatter_trace_1 = go.Scatter(\n    x = df_train[\"Feature_1\"][:500],\n    y = df_train[\"Feature_2\"][:500],\n    mode = \"markers\",\n    name= \"Class A\",\n    hovertemplate = \"Feature_1: %{x}<br>Feature_2: %{y}\",\n    marker = dict(\n        size = 9,\n        opacity = .80,\n        color = \"lightblue\",\n        line = dict(\n            color = \"blue\",\n            width = 1,\n        )\n    )\n)\n\nfig.add_trace(scatter_trace_1)\nfig.show()","e14acdac":"# Importing the necessary modules\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import multivariate_normal\n \n \nplt.style.use('seaborn-dark')\nplt.rcParams['figure.figsize']=14,6\nfig = plt.figure()\n \n# Initializing the random seed\nrandom_seed=1000\n \n# List containing the variance\n# covariance values\ncov_val = [-0.1]\n \n# Setting mean of the distributino\n# to be at (0,0)\nmean = np.array([1,1])\n \n# Storing density function values for\n# further analysis\npdf_list = []\n \n# Iterating over different covariance values\nfor idx, val in enumerate(cov_val):\n     \n    # Initializing the covariance matrix\n    cov = np.array([[1, val], [val, 1]])\n     \n    # Generating a Gaussian bivariate distribution\n    # with given mean and covariance matrix\n    distr = multivariate_normal(cov = cov, mean = mean,\n                                seed = random_seed)\n     \n    # Generating a meshgrid complacent with\n    # the 3-sigma boundary\n    mean_1, mean_2 = mean[0], mean[1]\n    sigma_1, sigma_2 = cov[0,0], cov[1,1]\n     \n    x = np.linspace(-3*sigma_1, 3*sigma_1, num=100)\n    y = np.linspace(-3*sigma_2, 3*sigma_2, num=100)\n    X, Y = np.meshgrid(x,y)\n     \n    # Generating the density function\n    # for each point in the meshgrid\n    pdf = np.zeros(X.shape)\n    for i in range(X.shape[0]):\n        for j in range(X.shape[1]):\n            pdf[i,j] = distr.pdf([X[i,j], Y[i,j]])\n     \n    # Plotting the density function values\n    key = 131+idx\n    ax = fig.add_subplot(key, projection = '3d')\n    ax.plot_surface(X, Y, pdf, cmap = 'viridis')\n    plt.xlabel(\"x1\")\n    plt.ylabel(\"x2\")\n    plt.title(f'Covariance between x1 and x2 = {val}')\n    pdf_list.append(pdf)\n    ax.axes.zaxis.set_ticks([])\n \nplt.tight_layout()\nplt.show()\n \n# Plotting contour plots\nfor idx, val in enumerate(pdf_list):\n    plt.subplot(1,3,idx+1)\n    plt.contourf(X, Y, val, cmap='viridis')\n    plt.xlabel(\"x1\")\n    plt.ylabel(\"x2\")\n    plt.title(f'Covariance between x1 and x2 = {cov_val[idx]}')\nplt.tight_layout()\nplt.show()","96652786":"fig = go.Figure(\n    layout = dict(\n        width = 800,\n        height = 800,\n        title_text = \"Visualization of the dataset\",\n        xaxis = dict(\n            title = dict(\n                text = \"Feature_1\"\n            )\n        ),\n        yaxis = dict(\n            title = dict(\n                text = \"Feature_2\"\n            )\n        )\n    )\n)\n\nscatter_trace_1 = go.Scatter(\n    x = df_train[\"Feature_1\"][:500],\n    y = df_train[\"Feature_2\"][:500],\n    mode = \"markers\",\n    name= \"Class A\",\n    hovertemplate = \"Feature_1: %{x}<br>Feature_2: %{y}\",\n    marker = dict(\n        size = 9,\n        opacity = .80,\n        color = \"lightblue\",\n        line = dict(\n            color = \"blue\",\n            width = 1,\n        )\n    )\n)\n\nscatter_trace_2 = go.Scatter(\n    x = df_train[\"Feature_1\"][500:],\n    y = df_train[\"Feature_2\"][500:],\n    mode = \"markers\",\n    name= \"Class B\",\n    hovertemplate = \"Feature_1: %{x}<br>Feature_2: %{y}\",\n    marker = dict(\n        symbol = \"star-triangle-up\",\n        size = 10,\n        opacity = 0.65,\n        color =\"darkorange\",\n        line = dict(\n            color = \"red\",\n            width = 1,\n        )\n    )\n)\n\nfig.add_trace(scatter_trace_1)\nfig.add_trace(scatter_trace_2)\nfig.show()\n# fig.write_html(r\".\\expected outputs\\expectedoutput1.html\")","a2c566f9":"X = df_train[[\"Feature_1\",\"Feature_2\"]]\r\nY = df_train[[\"class\"]]\r\nX = np.hstack((np.ones((1000,1)),X.to_numpy()))\r\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y.to_numpy(), test_size=0.2, random_state=42)\r\nprint(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)","a336f5cf":"def hypothesis(x,theta):\n    sigmoid=(1.0\/(1.0 + np.exp(-1.0*np.dot(x,theta))))\n    return(sigmoid)\n\ndef error(X,Y,theta):\n    m=X.shape[0]\n    err=0\n    for i in range(m):\n        hx=hypothesis(X[i],theta)\n        err+=Y[i]*np.log2(hx) + (1-Y[i])*np.log2(1-hx)\n    err \/=m\n    return(-err)\n\ndef gradient(X,Y,theta):\n    grad=np.zeros((X.shape[1]))\n    m=X.shape[0]\n    fea=X.shape[1]\n    for i in range(m):\n        hx=hypothesis(X[i],theta)\n        for j in range(fea):\n            grad[j]+=(hx-Y[i])*X[i,j]\n    grad=grad\/m\n    return(grad)\n    \ndef gradient_ascent(X,Y,learning_rate=0.5):\n    theta=2*np.random.random(X.shape[1])\n    theta[0]=0\n    error_list=[]\n    acc_list=[]\n    theta_list = []\n    for i in range(100):\n        grad=gradient(X,Y,theta)\n        err=error(X,Y,theta)\n        error_list.append(err)\n        acc_list.append(accuracy(X,Y,theta))\n        theta_list.append(theta.copy())\n        for j in range(X.shape[1]):\n            theta[j]-=learning_rate*grad[j]\n    probabilty_list = predic_proba(X, theta)\n    return(theta, theta_list, error_list, acc_list, probabilty_list)\n\ndef predict(x,theta):\n    p=hypothesis(x,theta)\n    if p<0.5:\n        return 0\n    else:\n        return 1\n\ndef predic_proba(x,theta):\n    probabilty_list = []\n    for i in range(X.shape[0]):\n        probability = hypothesis(X[i],theta)\n        probabilty_list.append(probability)\n    return probabilty_list\n\n\ndef accuracy(X,Y,theta):\n    y_pred=[]\n    for i in range(X.shape[0]):\n        p=predict(X[i],theta)\n        y_pred.append(p)\n    y_pred=np.array(y_pred)\n    y_pred=y_pred.reshape((-1,1))\n    return(Y==y_pred).sum()\/X.shape[0]","a1e79fec":"theta, theta_list, error_list, acc_list, probabilty_list=gradient_ascent(X_train,Y_train)","fa5b9595":"fig = go.Figure(\n    layout = dict(\n        width = 800,\n        height = 800,\n        title_text = \"Visualising the error\",\n        xaxis = dict(\n            title = dict(\n                text = \"Iteration\"\n            )\n        ),\n        yaxis = dict(\n            title = dict(\n                text = \"Error (Negative of maximum likelihood)\"\n            )\n        )\n    )\n)\n\nfig.add_trace(go.Scatter(\n    x = [x for x in range(1,101,1)],\n    y = [x[0] for x in error_list],\n    mode = \"lines+markers\",\n    name= \"\",\n    marker = dict(\n        color = \"lightblue\",\n        line = dict(\n            color = \"blue\",\n            width = 1,\n        )\n    ),\n    hovertemplate = \"Iteration: %{x}<br>Error: %{y}\",\n))\n\nfig.show()\n# fig.write_html(r\".\\expected outputs\\expectedoutput2.html\")how()","16c6c7d3":"fig = go.Figure(\n    layout = dict(\n        width = 800,\n        height = 800,\n        title_text = \"Visualising the Accuracy\",\n        xaxis = dict(\n            title = dict(\n                text = \"Iteration\"\n            )\n        ),\n        yaxis = dict(\n            title = dict(\n                text = \"Accuracy\"\n            )\n        )\n    )\n)\n\nfig.add_trace(go.Scatter(\n    x = [x for x in range(1,101,1)],\n    y = acc_list,\n    mode = \"lines+markers\",\n    name= \"\",\n    marker = dict(\n        color = \"lightblue\",\n        line = dict(\n            color = \"blue\",\n            width = 1,\n        )\n    ),\n    hovertemplate = \"Iteration: %{x}<br>Accuracy: %{y}\",\n))\n\nfig.show()\n# fig.write_html(r\".\\expected outputs\\expectedoutput3.html\")","e3293c82":"print(\"The accuracy for the algorithm is:\",acc_list[-1])\r\nprint(\"The final theta parameters calculated are:\",theta)","da8a4a7d":"sliders_dict = {\n    'active': 0,\n    'yanchor': 'top',\n    'xanchor': 'left',\n    'currentvalue': {\n        'font': {'size': 20},\n        'prefix': 'No. of iterations:',\n        'visible': True,\n        'xanchor': 'right'\n    },\n    'transition': {'duration': 300, 'easing': 'linear'},\n    'pad': {'b': 10, 't': 50},\n    'len': 0.9,\n    'x': 0.1,\n    'y': 0,\n    'steps': []\n}\n\nframes = []\nfor i in range(100):\n    frame = go.Frame(\n        data = [scatter_trace_1, scatter_trace_2,\n            go.Scatter(\n                x = np.linspace(-3,7,2), \n                y = -1*(theta_list[i][0]+np.linspace(-4,8,2)*theta_list[i][1])\/theta_list[i][2],\n                mode = \"lines\",\n                name = \"Decision Boundry\",\n                hoverinfo = \"none\"\n            )\n        ],\n        name = str(i+1)\n    )\n    frames.append(frame)\n\nfor i in range(100):\n    slider_step = {'args': [\n        [i+1],{\n            'frame': {'duration': 300, 'redraw': True},\n            'mode': 'immediate',\n            'transition': {'duration': 300}\n        }],\n    'label': i+1,\n    'method': 'animate'}\n    sliders_dict['steps'].append(slider_step)\nfig = go.Figure(\n    data = [scatter_trace_1, scatter_trace_2, \n            go.Scatter(\n                x = np.linspace(-3,7,2), \n                y = -1*(theta_list[0][0]+np.linspace(-4,8,2)*theta_list[0][1])\/theta_list[0][2],\n                mode = \"lines\",\n                name = \"Decision Boundry\",\n                hoverinfo = \"none\"\n            )],\n    layout = go.Layout(updatemenus=[{\n        'buttons': [{\n            \"args\": [None,{\"fromcurrent\": True,\n                           \"transition\": {\"duration\": 50,\n                                          \"easing\": \"linear\"}}],\n            'label': 'Play',\n            'method': 'animate'\n        },\n        {\n            'args': [[None],{'frame': {'duration': 0, 'redraw': False},\n                             'mode': 'immediate',\n                             'transition': {'duration': 0}}],\n            'label': 'Pause',\n            'method': 'animate'\n        }],\n        'direction': 'left',\n        'pad': {'r': 10, 't': 87},\n        'showactive': False,\n        'type': 'buttons',\n        'x': 0.1,\n        'xanchor': 'right',\n        'y': 0,\n        'yanchor': 'top'\n    }]),\n    frames = frames\n)\nfig.update_layout(\n    width = 800,\n    height = 800,\n    title_text = \"Visualising the convergence of decision boundary\",\n    xaxis = dict(\n        range = [-3.5,7.5],\n        title = dict(\n            text = \"Feature_1\"\n        )\n    ),\n    yaxis = dict(\n        title = dict(\n            text = \"Feature_2\"\n        )\n    )\n)\nfig['layout']['sliders'] = [sliders_dict]\nfig.show()\n# fig.write_html(r\".\\expected outputs\\expectedoutput4.html\")\n","6f37d767":"fig = go.Figure(\n    layout = dict(\n        width = 800,\n        height = 800,\n        title_text = \"Visualization of the decision boundary\",\n        xaxis = dict(\n            range = [-4,8],\n            title = dict(\n                text = \"Feature_1\"\n            )\n        ),\n        yaxis = dict(\n            title = dict(\n                text = \"Feature_2\"\n            )\n        )\n    )\n)\n\nfig.add_trace(scatter_trace_1)\nfig.add_trace(scatter_trace_2)\n\nfig.add_trace(go.Scatter(\n    x = np.linspace(-3,7,2), \n    y = -1*(theta[0]+np.linspace(-4,8,2)*theta[1])\/theta[2],\n    mode = \"lines\",\n    name = \"Decision Boundry\",\n    hoverinfo = \"none\"\n))\n\nfig.show()\n# fig.write_html(r\".\\expected outputs\\expectedoutput5.html\")\nplt.show()","a42fa3fd":"# Loading the training dataset","22be1397":"For demonstration purposes, let us take a 2 dimensional dataset with tow features (Feature_1 and Feature_2) and consisting of two classes (Class A and Class B) having a distribution specifications as follows:\r\n\r\n**Class A:** The Class A is centred around the mean of (1,1) and has the covariance matrix [[1,-0.2],[-0.2,1]]\r\n\r\n**Class B:** The Class B is centred around the mean of (3,4) and has the covariance matrix [[1,0.1],[0.1,1]]\r\n\r\nDefintions: \r\n\r\n**Mean:** A Class with centre (x1, x2) as mean denotes that the average value along \"Feature_1\" is x1 and the average value along \"Feature_2\" is x2\r\n\r\nP.S: Since we would like to ensure that the outputs corrosponds to the desired output, we will also add the seed value of 42 while generating these distributions.\r\n\r\n","83ad76c3":"## Visalising accuracy over test set","d3d60c13":"## Training the model","b0a184b7":"# Machine Learning Model","c7c952d7":"# Plotting the decision boundry","37914f3f":"## Visualising the decision boundry over iterations","ef3ea31c":"## Defining the model","d7cae62a":"# Importing important libraries","00ed0e87":"## Visualising Error over training set","28c4ae98":"This notebook is a part of the OneML_ContriHub the link to which can be found [here](https:\/\/github.com\/ContriHUB\/OneML_ContriHub)","068c72ef":"# Visualising the dataset","110ebaba":"## Preparing training and test sets"}}