{"cell_type":{"84c31ce9":"code","142832f2":"code","ce03837d":"code","a1200b03":"code","5982f330":"code","991a3022":"code","efa48836":"code","57f1d40e":"code","5ba44081":"code","761641d1":"code","f92e7292":"code","3591a0c2":"code","6a2d0e85":"code","70cb55ca":"code","ad4c5cb8":"code","c7d472fd":"code","c88a1c84":"code","5ecfdb22":"code","c9d345ab":"code","2e4aef63":"code","17999a7f":"code","d3a45b8a":"code","9629997b":"markdown","755c977a":"markdown","937a6bf4":"markdown","50e4e7c6":"markdown","b4e67837":"markdown","e297835f":"markdown","c9a2721f":"markdown","0d924888":"markdown","26fbd8ce":"markdown","4f8ca2e2":"markdown","534e1ddd":"markdown","2ed5d108":"markdown","994f82ca":"markdown","47a6ac6d":"markdown"},"source":{"84c31ce9":"import pandas as pd\nimport numpy as np\nimport matplotlib as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nimport sklearn.metrics as metrics\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.decomposition import PCA\nimport scikitplot as skplt\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\nimport matplotlib.pyplot as plt","142832f2":"XY = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","ce03837d":"print(u'- El n\u00famero de filas en el dataset es: {}'.format(XY.shape[0]))\nprint(u'- El n\u00famero de columnas en el dataset es: {}'.format(XY.shape[1]))\nprint(u'- Los nombres de las variables son: {}'.format(list(XY.columns)))\nXY[:2]","a1200b03":"#definicion de funciones que se usaran \n\ndef NormalizeData(data):\n    return (data - np.min(data)) \/ (np.max(data) - np.min(data))\n\ndef repre_matriz_confusion(matriz):\n    df_matriz_confusion = pd.DataFrame(matriz,\n                     ['True Normal','True Fraud'],\n                     ['Pred Normal','Pred Fraud'])\n    plt.figure(figsize = (8,4))\n    sns.set(font_scale=1.4)\n    plt.title(u'Matriz de confusi\u00f3n')\n    _ = sns.heatmap(df_matriz_confusion, annot=True, annot_kws={\"size\": 16}, fmt='g')\n    \ndef reporting_modelo(y_reales, y_clase):\n    matriz_confusion = metrics.confusion_matrix(y_reales, y_clase)\n    roc_auc = metrics.roc_auc_score(y_reales, y_clase)\n    metrica_f1 = metrics.f1_score(y_reales, y_clase)\n    print(u'La AUC de la ROC es de: {}'.format(round(roc_auc,2)))\n    print(u'La F1 es de: {}'.format(round(metrica_f1,2)))\n    print(\"\\nAccuracy\\t{}\".format(round(metrics.accuracy_score(y_reales, y_clase),3)))  \n    print(\"Sensitividad\\t{}\".format(round(metrics.recall_score(y_reales, y_clase),3)))\n    print(u\"Precisi\u00f3n\\t{}\".format(round(metrics.precision_score(y_reales, y_clase),3)))   \n    repre_matriz_confusion(matriz_confusion)\n    \ndef repres_doble_hist(y_prob_pos, y_prob_neg):\n    \n    fig = plt.figure(figsize=(20,10))\n    ax = sns.distplot(y_prob_pos,norm_hist=True, bins=30, hist=False,\n    label='', kde_kws={\"color\": \"r\", \"lw\": 5})  \n    ax2 = ax.twinx()\n    sns.distplot(y_prob_neg,norm_hist=True ,ax=ax2, bins=30, hist=False,\n    label='', kde_kws={\"color\": \"g\", \"lw\": 2}) \n    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n    ax.figure.legend(['Clase fraudulenta', 'Clase no fraudulenta'])\n    new_style = {'grid': False}\n    plt.rc('axes', **new_style)\n    plt.title('Representaci\u00f3n de las probabilidades asignadas a ambas clases')\n    plt.show()","5982f330":"X = XY.drop('Class', axis=1)","991a3022":"y = XY['Class']","efa48836":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","57f1d40e":"#Grafico de fraudes vs no fraudes\nXY['Class'].value_counts().plot(kind='pie', figsize=(7,7))\nplt.title('Distribuci\u00f3n de transacciones', fontsize=20)\n#Como vemos, las clases est\u00e1n muy desbalanceadas ya que apenas hay casos fraudulentos.","5ba44081":"df_plt=XY[XY['Class']==0].sample(4000)\ndf_plt_pos=XY[XY['Class']==1].sample(60)\ndf_plt=pd.concat([df_plt,df_plt_pos])\ny_plt=df_plt['Class']\nX_plt=df_plt.drop('Class',axis=1)","761641d1":"pca2 = PCA(n_components=3)\nX_PCA = pca2.fit_transform(X_plt)","f92e7292":"fig = plt.figure(figsize=(10,7))\nax = Axes3D(fig)\nax.scatter(X_PCA[:,0], X_PCA[:,1], X_PCA[:,2], c=y_plt, cmap=plt.cm.get_cmap(\"bwr\"))\nax.set_xlabel('PC1')\nax.set_ylabel('PC2')\nax.set_zlabel('PC3')\nax.set_xticks([-75000,75000])\nax.set_title('Representaci\u00f3n 3D de las tres primeras componentes en un PCA')\nplt.show()","3591a0c2":"plt.figure(figsize=(12,8))\nplt.scatter(X_PCA[:,0], X_PCA[:,1], c=y_plt, cmap=plt.cm.get_cmap(\"Paired\", 2))\nplt.colorbar(ticks=range(2))\nplt.title('Representaci\u00f3n 2D de las dos primeras componentes de un PCA')\nplt.xlabel('PC1'); _=plt.ylabel('PC2')","6a2d0e85":"clf=LocalOutlierFactor(n_neighbors=10, \n                        algorithm='auto', \n                        leaf_size=30,\n                        metric='minkowski', \n                        p=2, \n                        metric_params=None, \n                        n_jobs=-1,\n                        novelty=False)","70cb55ca":"%%time\nclf.fit(X)","ad4c5cb8":"factores_lof = clf.negative_outlier_factor_\nfactores_lof","c7d472fd":"#Se pone el umbral en 2% como se mencion\u00f3 \nY_pred_clase = factores_lof.copy()\nY_pred_clase[factores_lof>=np.percentile(factores_lof,2.)] = 0\nY_pred_clase[factores_lof<np.percentile(factores_lof,2.)] = 1","c88a1c84":"#Se utiliza la funciona para ver como funciona el modelo ya definida\nreporting_modelo(y, Y_pred_clase) ","5ecfdb22":"Y_probs = NormalizeData(factores_lof)\nY_pred_prob_pos = NormalizeData(factores_lof)[np.where(y == 1)]\nY_pred_prob_neg = NormalizeData(factores_lof)[np.where(y == 0)]","c9d345ab":"repres_doble_hist(Y_pred_prob_pos, Y_pred_prob_neg)","2e4aef63":"Y_probs_1_0 = np.column_stack((Y_probs,list(map(lambda x: 1-x, Y_probs))))\nY_probs_1_0","17999a7f":"skplt.metrics.plot_cumulative_gain(y, Y_probs_1_0, figsize=(7,7))\nplt.show()","d3a45b8a":"skplt.metrics.plot_lift_curve(y, Y_probs_1_0, figsize=(15,7))\nplt.show()","9629997b":"Como vemos, con un dos por ciento de la muestra detectada como fraude, detectamos m\u00e1s del 50 % de las transacciones fraudulentas.","755c977a":"## Representaci\u00f3n de la ganancia a no tener modelo:\n\nEn este punto analizamos qu\u00e9 mejora nos da el modelo. Es decir, que ventaja tiene una empresa usando un modelo de detecci\u00f3n de anomal\u00edas a no usarlo.","937a6bf4":"En este punto, la empresa simplemente auditando un peque\u00f1o porcentaje de todas las transacciones totales, dar\u00eda con la mayor\u00eda de las transacciones fraudulentas. Esto ahorrar\u00eda tiempo y esfuerzo por muchos trabajadores, los cuales podr\u00edan dedicarse a otras tareas.","50e4e7c6":"Se crea un array con una estimaci\u00f3n de probabilidades de 1s y de 0s (tengo las de 1s, simplemente hay que crear otra como  \ud835\udc430=1\u2212\ud835\udc431","b4e67837":"El modelo asigna a la clase fraudulenta valores centrados en el 1 (an\u00f3malos). Por otro lado, la clase no fraudulenta tiene muchos valores en 0s y en 1s.","e297835f":"# Deteccion de anomalias\n### Este sistema nos muestra de forma negativa las anomalias encontradas en el dataset. Es decir que si queremos quedarnos con el 2% de puntos mas anomalos debemos segmetnar el dataset con el 2% de valores mas bajos  ","c9a2721f":"# Representaci\u00f3n de las probabilidades:","0d924888":"Description of the problem:\nPrediction of the probability of default of a customer.\n\nThe objective of the problem is to predict the probability of default of credit card customers. It is, therefore, a credit risk model.\n\nDataset description:\nIt has a total of 24 predictor variables X and a continuous variable to predict Y.\n\nThe total number of samples is 30,000 people.","26fbd8ce":"#### Se utilizara el modelo de LocalOutlier para como detector de anomalias en base a los vecinos. Se ajustan los datos a las features correspondientes a X","4f8ca2e2":"Podemos representar la ganancia acumulada que obtenemos entre tener modelo y no tenerlo:","534e1ddd":"# Classification problem using NEURAL NETWORK, Deep Learning","2ed5d108":"Y la curva de Lift, que es muy usada en los modelos de clasificaci\u00f3n, ya que nos indica para cada porcentaje de las transacciones m\u00e1s probables de ser fraude cu\u00e1l es la ganancia que obtenemos con el modelo. En este caso, si cogemos al 10 % de m\u00e1s transacciones m\u00e1s probables, mejoramos a una decisi\u00f3n aleatoria en un 1000 % aproximadamente.","994f82ca":"## 2.- Divisi\u00f3n del dataset en dos conjuntos (train + test)","47a6ac6d":"# Representaci\u00f3n del PCA de las clases"}}