{"cell_type":{"1be8ce00":"code","28d00bca":"code","04a2ece0":"code","839714f8":"code","3ddda2dd":"code","09770b69":"code","7151d186":"code","eb14326f":"code","fd873393":"code","431aa00b":"code","8311a764":"code","5463b1a3":"code","a8901371":"code","9838e0fb":"code","ae7c052f":"code","986aa6da":"code","a6c3be77":"code","180216b1":"code","bb7c6714":"code","171ddc27":"code","5cf83635":"code","23d77e65":"code","b3efdafe":"code","fc02025a":"code","7898f46c":"code","75fda5e3":"code","997213fe":"code","a92e019a":"code","9214cde4":"code","d5939d1d":"code","83039ed2":"code","dd877482":"code","ee8822d0":"code","05dea556":"code","cf98fc56":"code","55879169":"code","f2c36106":"code","cd31192a":"code","a2b4a5c2":"code","39128396":"code","4036a03a":"code","89ee7f07":"code","0ee02341":"code","97e1c547":"code","09d44dc5":"code","4d3d69e7":"code","e564eda1":"code","be8a5bdf":"code","19f7f723":"code","3017821e":"code","9180edbd":"code","e7ba78c4":"markdown","30ccafdb":"markdown","6d6bb29b":"markdown","027aec3f":"markdown","85b6d28c":"markdown","9d1f127b":"markdown","9b7ec33d":"markdown","43902d47":"markdown","2c244d06":"markdown"},"source":{"1be8ce00":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport sklearn\nimport sklearn.utils\nimport warnings\nimport sklearn.utils\n\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nfrom sklearn.preprocessing import *\nfrom xgboost import *\nplt.style.use('seaborn-whitegrid')\n\nimport matplotlib\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","28d00bca":"# read the data with pandas\ntrain_data = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')","04a2ece0":"train_data.tail(10)","839714f8":"train_data.shape","3ddda2dd":"train_data.info()","09770b69":"train_data.describe()","7151d186":"train_data['country'].value_counts(normalize=True)*100","eb14326f":"# Distribition of Data based on Country Value\nsns.catplot(x='country',kind='count',data=train_data)","fd873393":"# According to the mean value on info command, the mean sold_num is equal to '387'\ntrain_data[ (train_data.num_sold > 387) ]['country'].value_counts(normalize=True)*100","431aa00b":"# Extracting DMY values\ntrain_data[\"Day\"] = train_data[\"date\"].apply(lambda x: str(x)[-2:])\ntrain_data[\"Month\"] = train_data[\"date\"].apply(lambda x: str(x)[-5:-3])\ntrain_data[\"Year\"] = train_data[\"date\"].apply(lambda x: str(x)[:-6])","8311a764":"train_data.drop(['row_id'],axis=1, inplace=True)\ntrain_data.head(10)","5463b1a3":"dFeatures = ['Day','Month','Year']\ntrain_data[dFeatures] = train_data[dFeatures].astype('int64')","a8901371":"# Extracting Unique store names\ntrain_data['store'].unique()","9838e0fb":"# Monthly Num_sold Based on Region\nsns.catplot(x='Month', y='num_sold', hue='country' , kind=\"point\", data=train_data)","ae7c052f":"# Num_sold Distribition for 3 diffrent countries\n\nimport plotly.graph_objects as go\nimport plotly.offline as po\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.offline import iplot\n\nhist_data = [train_data[(train_data.country == 'Finland')]['num_sold'], train_data[(train_data.country == 'Norway')]['num_sold'] , train_data[(train_data.country == 'Sweden')]['num_sold']]\ngroup_labels = ['num_sold for Finland', 'num_sold for Norway', 'num_sold for Sweden']\nfig = ff.create_distplot(hist_data, group_labels, bin_size=0.3, show_hist=False, show_rug=True)\nfig.show()","986aa6da":"# yearly num_sold of each store\nfirst = go.Scatter(\n                    x = train_data[(train_data.store == 'KaggleMart')]['date'].values.astype(str),\n                    y = train_data[(train_data.store == 'KaggleMart')]['num_sold'],\n                    mode = 'lines',\n                    name = 'KM Sold-Nums Time Line'\n                  )\n\n\nsecond = go.Scatter(\n                    x = train_data[(train_data.store == 'KaggleRama')]['date'].values.astype(str),\n                    y = train_data[(train_data.store == 'KaggleRama')]['num_sold'],\n                    mode = 'lines',\n                    name = 'KR Sold-Nums Time Line'\n                  )\n\n\nlayout = go.Layout(\n                    xaxis = dict(title = 'Date'), # x-axis label\n                    yaxis = dict(title = 'Nums Sold'), # y-axis label   \n                 )\n\ndata = [first, second]  \nfig = go.Figure(data=data,layout=layout)\niplot(fig)","a6c3be77":"train_data.groupby( ['product' ,'country'])['num_sold'].mean()","180216b1":"from plotly.subplots import make_subplots\n# most sold product based on region\nstatus = ['Kaggle Sticker' , 'Kaggle Mug' , 'Kaggle Hat']\ncolors = ['#8BC34A','#FFB300','#FF7043']\n\n\n\n\nfig = make_subplots(\n                     rows=1, \n                     cols=3,\n                     subplot_titles=(\"Finland\", \"Norway\",\"Sweden\"),\n                     \n                     specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]]\n                   )\n\n# Subplot -  Add graph object trace to a figure\nfig.add_trace(go.Pie(\n                     values= train_data[(train_data.country == 'Finland')].groupby('product')['num_sold'].mean().values,\n                     labels= status,\n                     marker=dict(colors=colors),\n                     textinfo='label+percent'\n                    ),\n              row=1, col=1\n             )\n\nfig.add_trace(go.Pie(\n                     values= train_data[(train_data.country == 'Norway')].groupby('product')['num_sold'].mean().values,\n                     labels= status,\n                     marker=dict(colors=colors),\n                     textinfo='label+percent'\n                    ),\n              row=1, col=2\n             )\n\nfig.add_trace(go.Pie(\n                     values= train_data[(train_data.country == 'Sweden')].groupby('product')['num_sold'].mean().values,\n                     labels= status,\n                     marker=dict(colors=colors),\n                     textinfo='label+percent'\n                    ),\n              row=1, col=3\n             )\n\nfig.update_layout(\n                    title=dict(text = \"Most sold product based on region\",x=0.5,y=0.95),\n                    title_font_size=30\n                  )\n\nfig.show()","bb7c6714":"sns.catplot(x= 'Month', y='num_sold', kind='box', data=train_data , aspect = 3 , height=4)","171ddc27":"train_data.head(3)","5cf83635":"train_data.isnull().sum()\n# There is one row with null values","23d77e65":"t_corr = train_data.corr()\nplt.figure(figsize=(6,6))\nsns.heatmap(t_corr,annot=True,annot_kws={'size':10},cmap='Reds')","b3efdafe":"# Dropping the Date before training\ntrain_data = train_data.drop(['date'], axis =1)\ntrain_data.head(3)","fc02025a":"# Label Encoding \ntrain_data['Year']=train_data['Year'].map({2015:1, 2016:2, 2017:3 , 2018:4})\ntrain_data.head(3)","7898f46c":"# Encoding Categorical columns\nFeatures_2 = ['country', 'store', 'product']\ntrain_data = pd.get_dummies(train_data, Features_2)\ntrain_data.tail(3)","75fda5e3":"train_target = train_data['num_sold']\ntrain_target = pd.DataFrame(train_target, columns=['num_sold'])\ntrain_target.head(3)","997213fe":"train_target = pd.DataFrame(train_target, columns=['num_sold'])\ntrain_target.head(3)","a92e019a":"train_data.drop(['num_sold'],inplace=True,axis=1)\ntrain_data","9214cde4":"X_train, X_test, y_train, y_test = train_test_split(train_data, train_target, test_size=0.2, random_state=1)","d5939d1d":"model = XGBRegressor(random_state=1,tree_method='gpu_hist').fit(X_train, y_train)","83039ed2":"model.score(X_test,y_test)","dd877482":"# Run these lines to find best model\n# parameters = [{\n#                 'max_depth': np.arange(3,5,1),\n#                 'n_estimators': [1000],\n#                 'subsample': np.arange(0.1,1.0,0.1),\n#                 'eta': np.arange(0.1,1.0,0.1),\n#                 'colsample_bytree': np.arange(0.1,0.5,0.1),\n#                 'colsample_bylevel': np.arange(0.1,0.5,0.1),\n#                 'min_child_weight': np.arange(0,9,3),\n#                 'reg_lambda': np.arange(10,15,1),\n#                 'reg_alpha': np.arange(0.00,0.10,0.01),\n#                 'gamma': np.arange(0.0,1.0,0.2),\n#                 'booster': ['gbtree'],\n#                 'eval_metric': ['rmse'],\n#                 'tree_method': ['gpu_hist'],\n#                 'predictor': ['gpu_predictor']}]","ee8822d0":"# grid_search_model = GridSearchCV(estimator = model,\n#                            param_grid = parameters,\n#                            scoring = 'r2',\n#                            cv = 3,\n#                            n_jobs = -1,\n#                            verbose = 1)","05dea556":"# grid_search_model.fit(X_train, y_train)","cf98fc56":"# best_accuracy = grid_search_model.best_score_\n# print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))","55879169":"# best_parameters = grid_search_model.best_params_\n# print(\"Best Parameters:\", best_parameters)","f2c36106":"test_data[\"Day\"] = test_data[\"date\"].apply(lambda x: str(x)[-2:])\ntest_data[\"Month\"] = test_data[\"date\"].apply(lambda x: str(x)[-5:-3])\ntest_data[\"Year\"] = test_data[\"date\"].apply(lambda x: str(x)[:-6])","cd31192a":"test_data.drop(['row_id'],axis=1, inplace=True)\ntest_data.head(10)","a2b4a5c2":"dFeatures = ['Day','Month','Year']\ntest_data[dFeatures] = test_data[dFeatures].astype('int64')","39128396":"test_data.isnull().sum()","4036a03a":"test_data.info()","89ee7f07":"# Dropping the Date before training\ntest_data = test_data.drop(['date'], axis =1)\ntest_data.head(3)","0ee02341":"test_data['Year'].unique()","97e1c547":"test_data['Year']=test_data['Year'].map({2019:5})\ntest_data.head(3)","09d44dc5":"test_data = pd.get_dummies(test_data, Features_2)\ntest_data.tail(3)","4d3d69e7":"preds = model.predict(test_data)","e564eda1":"preds","be8a5bdf":"preds = pd.DataFrame(preds, columns=['num_sold'])","19f7f723":"ids = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\nids = ids['row_id']\nids.head(3)","3017821e":"preds = pd.concat([ids,preds], axis=1)\npreds.head(3)","9180edbd":"# Make Submission File\npreds = preds.to_csv('Result_2.csv',index=False)","e7ba78c4":"<center><h1>Kaggle-Tabular Playground Series : Jan 2022","30ccafdb":"# Handling Date DType","6d6bb29b":"1. **Hi kagglers** Happy New Year!\n1. hope you all having a good time, \n1. In this notebook i tried to briefly explore the dataset and also extract new features from it and ive used XGboost to train a regression model based on the Num_Sol values\n* if you find it usefull dont forget to upvote it\n*  good Luck","027aec3f":"# Checking the Correlation","85b6d28c":"#  Exploratory data analysis","9d1f127b":"# Test Data prep","9b7ec33d":"<html>\n    <center><img src='https:\/\/wpguynews.com\/wp-content\/uploads\/2021\/03\/content-marketing-examples-604a0b84e432c.png'>","43902d47":"# Regression Model ","2c244d06":"# Import Libraries"}}