{"cell_type":{"c83fea54":"code","b514f63e":"code","249ab118":"code","bcd69fc1":"code","ae7ff0bc":"code","26a90c16":"code","68e49b36":"code","b27897af":"code","eb1d7c55":"code","92b5a152":"code","6c39e2f3":"code","5ad72394":"code","5e646adf":"code","4be2725a":"code","788cde80":"code","1e60d2b3":"code","e5c6efa5":"code","f99acb51":"code","2a7b43c0":"code","57cb0147":"code","280880f4":"code","6fb0957f":"code","7b214ed6":"code","7487078c":"code","1a593192":"code","1397284f":"code","19e9098a":"code","faea209d":"code","92c207c8":"code","4ad6af66":"code","e877346b":"code","098e5a74":"code","3147a625":"code","a8a804d7":"code","e2f7e519":"code","6ca984c3":"code","3ec11dcb":"code","96eb9fd8":"code","c916033d":"code","dab513c0":"code","49db8398":"code","34b92d8a":"code","acc69169":"code","a2ea6c6e":"code","83cca1be":"code","2c8c3af2":"code","f66f11a5":"code","a75d82f3":"code","1c2d2737":"code","6decc053":"code","039f7f8f":"code","abb7619e":"code","b5d78a7f":"code","62e7928c":"code","cd5414de":"code","800b0217":"code","ef24218c":"code","f333bf93":"code","d2069a85":"code","910ca5b7":"code","194e5c96":"code","016beea2":"code","ec71b95a":"code","9295e5b1":"code","74a35fe5":"markdown","862a5bbc":"markdown","dabffcae":"markdown","a8dc37c8":"markdown","af916ad0":"markdown","6294c89d":"markdown","d8ca6eb5":"markdown","9e7e6296":"markdown","f5fbda09":"markdown","0f1f57c6":"markdown","0e927865":"markdown","5de74f36":"markdown","6adb79e7":"markdown","cf834c22":"markdown","f4450b21":"markdown","a3d12a69":"markdown","2b3af74b":"markdown"},"source":{"c83fea54":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b514f63e":"df=pd.read_csv(\"\/kaggle\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv\")","249ab118":"df.tail()","bcd69fc1":"df.info()","ae7ff0bc":"df.drop(df[df['Review Text'].isna()].index,inplace=True) #drop where there are no text","26a90c16":"blanks = []  # start with an empty list\n\nfor i,lb,rv in df[['Review Text','Title']].itertuples():  # iterate over the DataFrame\n    if type(rv)==str:            # avoid NaN values\n        if rv.isspace():         # test 'review' for whitespace\n            blanks.append(i)","68e49b36":"blanks #there are no blanks or space instead of NaN","b27897af":"df.info()","eb1d7c55":"#df[df['Rating']==3]","92b5a152":"df['Title']=df['Title'].apply(lambda x:\" \" if pd.isnull(x) else x) #replace null value with a space","6c39e2f3":"df.info()","5ad72394":"#df[df['Division Name'].isna()]","5e646adf":"df['Division Name'].fillna(df['Division Name'].mode()[0],inplace=True) # replace nan with most common value that occur","4be2725a":"df['Department Name'].fillna(df['Department Name'].mode()[0],inplace=True)","788cde80":"df['Class Name'].fillna(df['Class Name'].mode()[0],inplace=True)","1e60d2b3":"df.info() # data types are fine plus there are no null values left","e5c6efa5":"df.head()","f99acb51":"df['Title-Review Text']=df[['Title', 'Review Text']].apply(lambda x: ' '.join(x), axis=1)","2a7b43c0":"df.head(6)","57cb0147":"df.drop(\"Unnamed: 0\",axis=1,inplace=True)","280880f4":"df['Review']=df['Rating'].apply(lambda x: \"positive\" if x>3 else(\"negative\" if x<3 else(\"neutral\" if x==3 else x)))","6fb0957f":"df.head()","7b214ed6":"df=df.sort_values(\"Clothing ID\")\ndf.reset_index(drop=True,inplace=True)","7487078c":"df.iloc[18111:,:]['Clothing ID'].unique()","1a593192":"from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","1397284f":"#import nltk\n#nltk.download(\"stopwords\")\n#nltk.download('punkt')","19e9098a":"\"\"\"\nReference from Ken Jee : https:\/\/github.com\/PlayingNumbers\/ds_salary_proj\n\"\"\"\nwords = \" \".join(df['Title-Review Text'][df['Review']==\"positive\"])\n\ndef punctuation_stop(text):\n    \"\"\"remove punctuation and stop words\"\"\"\n    filtered = []\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(text)\n    for w in word_tokens:\n        if w not in stop_words and w.isalpha():\n            filtered.append(w.lower())\n    return filtered\n\n\nwords_filtered = punctuation_stop(words)\n\n\ntext = \" \".join([ele for ele in words_filtered])\n\nwc= WordCloud(background_color=\"white\", random_state=1,stopwords=STOPWORDS, max_words = 2000, width =1000, height = 1500)\nwc.generate(text)\n\nplt.figure(figsize=[10,10])\nplt.imshow(wc,interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","faea209d":"words = \" \".join(df['Title-Review Text'][df['Review']==\"negative\"])\n\nwords_filtered = punctuation_stop(words)\n\n\ntext = \" \".join([ele for ele in words_filtered])\n\nwc= WordCloud(background_color=\"white\", random_state=1,stopwords=STOPWORDS, max_words = 2000, width =1000, height = 1500)\nwc.generate(text)\n\nplt.figure(figsize=[10,10])\nplt.imshow(wc,interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","92c207c8":"words = \" \".join(df['Title-Review Text'][df['Review']==\"neutral\"])\n\nwords_filtered = punctuation_stop(words)\n\n\ntext = \" \".join([ele for ele in words_filtered])\n\nwc= WordCloud(background_color=\"white\", random_state=1,stopwords=STOPWORDS, max_words = 2000, width =1000, height = 1500)\nwc.generate(text)\n\nplt.figure(figsize=[10,10])\nplt.imshow(wc,interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","4ad6af66":"sns.barplot(x=\"Review\",y=\"Age\",data=df)","e877346b":"sns.barplot(x=\"Review\",y=\"Recommended IND\",data=df)","098e5a74":"sns.barplot(x=\"Review\",y=\"Positive Feedback Count\",data=df)","3147a625":"df.reset_index(drop=True,inplace=True)","a8a804d7":"from nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(df)):\n    review = re.sub('[^a-zA-Z]', ' ', df.loc[i,'Title-Review Text'])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","e2f7e519":"df['Title-Review Text']=corpus","6ca984c3":"df.columns","3ec11dcb":"df['Review']=df['Review'].apply(lambda x:0 if x==\"negative\" else(2 if x=='positive' else(1 if x=='neutral' else x)))","96eb9fd8":"#df=df.sort_values(\"Clothing ID\")\n#df.reset_index(drop=True,inplace=True)","c916033d":"words=df['Title-Review Text']\ny=df['Review']","dab513c0":"#words","49db8398":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_v=TfidfVectorizer(max_features=3000,ngram_range=(1,3))\nwords=tfidf_v.fit_transform(words).toarray()","34b92d8a":"X_train=words[:18111]\nX_test=words[18111:]\ny_train=y[:18111].values\ny_test=y[18111:].values","acc69169":"#pd.DataFrame(words).to_csv(\"words.csv\")","a2ea6c6e":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","83cca1be":"y_pred=classifier.predict(X_test)","2c8c3af2":"from sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","f66f11a5":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)","a75d82f3":"y_pred=classifier.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","1c2d2737":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(class_weight=\"balanced\")\nclassifier.fit(X_train, y_train)","6decc053":"y_pred=classifier.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","039f7f8f":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)","abb7619e":"y_pred=classifier.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","b5d78a7f":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)","62e7928c":"y_pred=classifier.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","cd5414de":"#from imblearn.combine import SMOTETomek","800b0217":"#smk = SMOTETomek(random_state=42)","ef24218c":"#X_train_res,y_train_res=smk.fit_sample(X_train,y_train)","f333bf93":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(class_weight=\"balanced\")\nclassifier.fit(X_train, y_train)","d2069a85":"y_pred=classifier.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","910ca5b7":"#import pickle \n#pickle.dump(classifier,open(\"model.pkl\",\"wb\"))","194e5c96":"#from sklearn.pipeline import Pipeline\n#from sklearn.feature_extraction.text import TfidfVectorizer\n#from sklearn.linear_model import LogisticRegression\n#text_clf_nb = Pipeline([('tfidf', TfidfVectorizer(max_features=3000,ngram_range=(1,3))),\n#                     ('clf', LogisticRegression(class_weight=\"balanced\")),\n#])\n#text_clf_nb.fit(X_train,y_train)","016beea2":"#import pickle \n#pickle.dump(text_clf_nb,open(\"model1.pkl\",\"wb\"))","ec71b95a":"#text_clf_nb.predict(X_test)","9295e5b1":"#df=pd.read_csv(\"women-clothing.csv\")\n#load=pickle.load(open('model1.pkl','rb'))","74a35fe5":"as we know that when the review are positive tend to recommend more then neutral then negative","862a5bbc":"we can see that positive feedback count vary slightly","dabffcae":"## XGboost","a8dc37c8":"# Data cleaning and Feature engineering","af916ad0":"This look like it has both complain as well as compliments","6294c89d":"# Eda","d8ca6eb5":"## Creating Pipeline","9e7e6296":"The words like love, top, perfect, great, etc are used for positive reviews ","f5fbda09":"Here we can see that there are word which look like complaint like fitting, material, look, size, etc are used","0f1f57c6":"## Gaussian Naive bayes","0e927865":"## Random Forest","5de74f36":"## Multinominal Naive bayes","6adb79e7":"# ML Algorithms","cf834c22":"# Data Preprocessing","f4450b21":"## Logistics Regression","a3d12a69":"###### As logistic regression has a better accuracy w.r.t 0 and 1 we will use logistic regression","2b3af74b":"looks like people of every age has reviewd equally at an average"}}