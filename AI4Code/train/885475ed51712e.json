{"cell_type":{"9936506c":"code","2e56b4e1":"code","7c4b6fd5":"code","e37aeb35":"code","6a0d91f3":"code","9bf80c41":"code","19feb836":"code","a0a7fbb8":"code","ee2cf0f6":"code","dd9a5c66":"code","a26a390f":"code","32a0925c":"code","5d54b4e3":"code","cf0fe948":"code","9a55c7d7":"code","95a352f7":"code","efd80358":"code","d23522c0":"code","d747d304":"code","8ad51221":"code","7314d928":"code","d31e8b8a":"code","1f89b106":"code","cd402416":"code","09eaf9c6":"code","394e285e":"code","0b42b9ec":"code","305bf764":"code","e1a57fae":"code","fae4bf3e":"code","bc62e1d3":"code","48b812bf":"code","4e993826":"code","a220bd66":"code","1be747f6":"code","fd03e3fd":"code","5fcec659":"code","cbb59bac":"code","64f72738":"code","f1230b26":"code","df10757a":"code","24944839":"code","3cdbbb27":"code","ab6af01d":"code","d5df0935":"code","1be348b2":"code","2df32971":"code","13da7cef":"code","2d32a4c5":"markdown","2685621d":"markdown","0a612e52":"markdown","2e68ee87":"markdown","f8d05cb9":"markdown","ccc017fd":"markdown","4366d935":"markdown","e81bff8a":"markdown","9aa696bb":"markdown","5185409b":"markdown","3d06ad2f":"markdown","3ebe6bf6":"markdown"},"source":{"9936506c":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport math\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\n#MUSIC PROCESS\nimport pydub\nfrom scipy.io.wavfile import read, write\nimport librosa\nimport librosa.display\nimport IPython\nfrom IPython.display import Audio\nimport scipy\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape,\\\nConv2DTranspose, LeakyReLU, Conv1D, AveragePooling1D, MaxPooling1D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","2e56b4e1":"Main_Video_Path = Path(\"..\/input\/real-life-violence-situations-dataset\/Real Life Violence Dataset\")","7c4b6fd5":"Video_Path = list(Main_Video_Path.glob(r\"*\/*.mp4\"))","e37aeb35":"Video_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Video_Path))","6a0d91f3":"Video_Path_Series = pd.Series(Video_Path,name=\"MP4\").astype(str)\nVideo_Labels_Series = pd.Series(Video_Labels,name=\"CATEGORY\")","9bf80c41":"Main_MP4_Data = pd.concat([Video_Path_Series,Video_Labels_Series],axis=1)","19feb836":"print(Main_MP4_Data.head(-1))","a0a7fbb8":"Violence_Data = Main_MP4_Data[Main_MP4_Data[\"CATEGORY\"] == \"Violence\"]\nNonViolence_Data = Main_MP4_Data[Main_MP4_Data[\"CATEGORY\"] == \"NonViolence\"]\n\nViolence_Data = Violence_Data.reset_index()\nNonViolence_Data = NonViolence_Data.reset_index()","ee2cf0f6":"print(Violence_Data.head(-1))","dd9a5c66":"print(NonViolence_Data.head(-1))","a26a390f":"FPS = 30\nDELAY = int(100\/FPS)\n# when it is necessary","32a0925c":"violence_frame_list = []\n\nfor file_video in Violence_Data.MP4:\n    Video_File_Path = file_video\n    \n    Video_Caption = cv2.VideoCapture(Video_File_Path)\n    Frame_Rate = Video_Caption.get(5)\n    \n    while Video_Caption.isOpened():\n        \n        Current_Frame_ID = Video_Caption.get(1)\n        \n        ret,frame = Video_Caption.read()\n        \n        if ret != True:\n            break\n            \n        if Current_Frame_ID % math.floor(Frame_Rate) == 0:\n            Frame_Resize = cv2.resize(frame,(64,64))\n            violence_frame_list.append(Frame_Resize)\n            \n            \n    Video_Caption.release()","5d54b4e3":"figure = plt.figure(figsize=(10,10))\nplt.imshow(violence_frame_list[32])\nplt.xlabel(violence_frame_list[32].shape)\nplt.ylabel(violence_frame_list[32].size)","cf0fe948":"figure = plt.figure(figsize=(10,10))\nplt.imshow(violence_frame_list[3])\nplt.xlabel(violence_frame_list[3].shape)\nplt.ylabel(violence_frame_list[3].size)","9a55c7d7":"figure = plt.figure(figsize=(10,10))\nplt.imshow(violence_frame_list[300])\nplt.xlabel(violence_frame_list[300].shape)\nplt.ylabel(violence_frame_list[300].size)","95a352f7":"figure,axis = plt.subplots(5,5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    \n    Img_Pick = violence_frame_list[i]\n    \n    ax.set_xlabel(Img_Pick.shape)\n    ax.imshow(Img_Pick)\n\nplt.tight_layout()\nplt.show()","efd80358":"X_2D_Violence = np.reshape(violence_frame_list, (5832, 64*64*3))","d23522c0":"print(np.shape(X_2D_Violence))","d747d304":"X_2D_Ones_Violence = np.concatenate((X_2D_Violence,np.ones((5832,1))), axis = 1)","8ad51221":"print(np.shape(X_2D_Ones_Violence))","7314d928":"X_4D_Violence = np.asarray(violence_frame_list)","d31e8b8a":"print(np.shape(X_4D_Violence))","1f89b106":"nonviolence_frame_list = []\n\nfor file_video in NonViolence_Data.MP4:\n    Video_File_Path = file_video\n    \n    Video_Caption = cv2.VideoCapture(Video_File_Path)\n    Frame_Rate = Video_Caption.get(5)\n    \n    while Video_Caption.isOpened():\n        \n        Current_Frame_ID = Video_Caption.get(1)\n        \n        ret,frame = Video_Caption.read()\n        \n        if ret != True:\n            break\n            \n        if Current_Frame_ID % math.floor(Frame_Rate) == 0:\n            Frame_Resize = cv2.resize(frame,(64,64))\n            nonviolence_frame_list.append(Frame_Resize)\n            \n            \n    Video_Caption.release()","cd402416":"figure = plt.figure(figsize=(10,10))\nplt.imshow(nonviolence_frame_list[32])\nplt.xlabel(nonviolence_frame_list[32].shape)\nplt.ylabel(nonviolence_frame_list[32].size)","09eaf9c6":"figure = plt.figure(figsize=(10,10))\nplt.imshow(nonviolence_frame_list[3])\nplt.xlabel(nonviolence_frame_list[3].shape)\nplt.ylabel(nonviolence_frame_list[3].size)","394e285e":"figure = plt.figure(figsize=(10,10))\nplt.imshow(nonviolence_frame_list[1000])\nplt.xlabel(nonviolence_frame_list[1000].shape)\nplt.ylabel(nonviolence_frame_list[1000].size)","0b42b9ec":"figure,axis = plt.subplots(5,5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    \n    Img_Pick = nonviolence_frame_list[i]\n    \n    ax.set_xlabel(Img_Pick.shape)\n    ax.imshow(Img_Pick)\n\nplt.tight_layout()\nplt.show()","305bf764":"X_2D_NonViolence = np.reshape(nonviolence_frame_list, (4985, 64*64*3))","e1a57fae":"print(np.shape(X_2D_NonViolence))","fae4bf3e":"X_2D_Zeros_NonViolence = np.concatenate((X_2D_NonViolence,np.zeros((4985,1))), axis = 1)","bc62e1d3":"print(np.shape(X_2D_Zeros_NonViolence))","48b812bf":"X_4D_NonViolence = np.asarray(nonviolence_frame_list)","4e993826":"print(np.shape(X_4D_NonViolence))","a220bd66":"X_Train = np.concatenate((X_2D_Ones_Violence,X_2D_Zeros_NonViolence),axis=0)","1be747f6":"print(np.shape(X_Train))","fd03e3fd":"np.random.shuffle(X_Train)","5fcec659":"X_Train = X_Train.astype(int)","cbb59bac":"print(X_Train)","64f72738":"Y_Train = X_Train[:,-1]","f1230b26":"print(Y_Train)","df10757a":"X_Train = np.delete(X_Train,-1,1)","24944839":"print(X_Train)","3cdbbb27":"Target_X = X_Train\nLabel_X = Y_Train","ab6af01d":"xTrain,xTest,yTrain,yTest = train_test_split(Target_X,Label_X,train_size=0.9,random_state=42,shuffle=True)","d5df0935":"print(xTrain.shape)\nprint(yTrain.shape)\nprint(xTest.shape)\nprint(yTest.shape)","1be348b2":"scaler = MinMaxScaler()\n\nxTrain = scaler.fit_transform(xTrain)\nxTest = scaler.fit_transform(xTest)","2df32971":"cartc = DecisionTreeClassifier(random_state=42).fit(xTrain,yTrain)\nrfc = RandomForestClassifier(random_state=42,verbose=False).fit(xTrain,yTrain)\ngbmc = GradientBoostingClassifier(verbose=False).fit(xTrain,yTrain)\nxgbc = XGBClassifier().fit(xTrain,yTrain)","13da7cef":"model_class = [cartc,rfc,gbmc,xgbc]\n\nfor model in model_class:\n    name = model.__class__.__name__\n    predict = model.predict(xTest)\n    R2CV = cross_val_score(model,xTest,yTest,cv=10,verbose=False).mean()\n    error = -cross_val_score(model,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\",verbose=False).mean()\n    print(name + \": \")\n    print(\"-\" * 10)\n    print(\"ACC-->\",accuracy_score(yTest,predict))\n    print(\"R2CV-->\",R2CV)\n    print(\"MEAN SQUARED ERROR-->\",np.sqrt(error))\n    print(\"-\" * 30)","2d32a4c5":"##### SPLITTING LABEL","2685621d":"##### TARGET AND LABELS","0a612e52":"#### NON-VIOLENCE TRANSFORMATION","2e68ee87":"# PATH, LABEL, TRANSFORMATION","f8d05cb9":"# PACKAGES AND LIBRARIES","ccc017fd":"##### MAIN TARGET","4366d935":"#### CONCAT VIOLENCE AND NON-VIOLENCE FOR SKLEARN","e81bff8a":"# DATA PROCESS","9aa696bb":"#### VIOLENCE TRANSFORMATION","5185409b":"# SKLEARN MODELS","3d06ad2f":"##### DELETING LABEL FROM MAIN TARGET","3ebe6bf6":"# SPLITTING TRAIN AND TEST FOR SKLEARN"}}