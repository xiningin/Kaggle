{"cell_type":{"5bc1c708":"code","2fe8c582":"code","0e5d2c14":"code","3b2e748f":"code","96f61c3a":"code","c85ec888":"code","069885c4":"code","cdf5b3da":"code","63af903a":"code","b0221dad":"code","f2243622":"code","a40cf9fb":"code","d2365072":"code","01df7000":"code","34ad816c":"code","e27d44a5":"code","68a3d6d8":"code","e66f3b57":"code","245642c2":"code","177f6d4e":"code","ca57fdbc":"code","6ff09034":"code","3592da44":"code","9d1c3ffc":"code","9ecd8638":"code","3309bf7d":"code","f215a7b9":"code","46224c83":"code","ed77b924":"code","422632b0":"code","2c64b4ab":"code","822ad9ec":"code","9bdbe9f2":"code","c3350cb1":"code","b9213728":"code","5cf35c1e":"markdown","c7236d99":"markdown","1a6bf31b":"markdown"},"source":{"5bc1c708":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2fe8c582":"import missingno as miss","0e5d2c14":"FILEPATH = '\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv'","3b2e748f":"df = pd.read_csv(FILEPATH)","96f61c3a":"df.describe()","c85ec888":"df.info()","069885c4":"df.sample(3)","cdf5b3da":"df.shape","63af903a":"# show 50-54 row\ndf[50:55]","b0221dad":"df.isnull().any().any()","f2243622":"df.isnull().any()","a40cf9fb":"df.isnull().any().any().sum()","d2365072":"miss.matrix(df)","01df7000":"miss.dendrogram(df)","34ad816c":"miss.bar(df)","e27d44a5":"df = df.drop(columns = ['Unnamed: 32'])","68a3d6d8":"diag_se = df['diagnosis'].value_counts()","e66f3b57":"diag_se","245642c2":"import seaborn as sns\n\nsns.barplot(diag_se.index, diag_se.values)","177f6d4e":"sns.heatmap(df.corr(), square = False, mask = False)","ca57fdbc":"from sklearn.model_selection import train_test_split","6ff09034":"y = df['diagnosis']\nX = df.drop(['diagnosis'], axis = 1)","3592da44":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 23)","9d1c3ffc":"def show_split_data(X_train, X_test, y_train, y_test):\n    \n    print(f'X train shape : {X_train.shape}')\n    print(f'Y train shape : {y_train.shape}')\n    print(f'X test shape  : {X_train.shape}')\n    print(f'Y test shape  : {y_train.shape}')","9ecd8638":"show_split_data(X_train, X_test, y_train, y_test)","3309bf7d":"# Confusion matrix\nfrom sklearn.metrics import confusion_matrix","f215a7b9":"import matplotlib.pyplot as plt\n\ndef show_confusion_matrix(_model_cm, title = None):\n    \n    f, ax = plt.subplots(figsize = (5, 5))\n    \n    sns.heatmap(_model_cm, annot = True, linewidth = 0, linecolor = 'red', fmt = 'g', ax = ax, cmap = 'Greens')\n    \n    # cmap colors:\n    # YlGnBu, Blues, BuPu, Greens\n    \n    plt.title(title + ' Confusion Matrix')\n    plt.xlabel('y Predict')\n    plt.ylabel('y test')\n    \n    plt.show()","46224c83":"def get_metrics(model_cm):\n    \n    total = sum(sum(model_cm))\n    \n    accuracy = (model_cm[0, 0] + model_cm[1, 1]) \/ total\n    accuracy = float(\"{:.2f}\".format(accuracy))\n\n    sensitivity = model_cm[0, 0] \/ (model_cm[0, 0] + model_cm[0, 1])\n    sensitivity = float(\"{:.2f}\".format(sensitivity))\n\n    specificity = model_cm[1, 1]\/(model_cm[1, 0] + model_cm[1, 1])\n    specificity = float(\"{:.2f}\".format(specificity))\n    \n    return accuracy, sensitivity, specificity","ed77b924":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)","422632b0":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report","2c64b4ab":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB","822ad9ec":"def predict_with_model(model):\n    \n    model = model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    return y_pred, accuracy","9bdbe9f2":"def show_metrics(model_cm):\n\n    total = sum(sum(model_cm))\n    \n    accuracy = (model_cm[0, 0] + model_cm[1, 1]) \/ total\n    accuracy = float(\"{:.2f}\".format(accuracy))\n\n    sensitivity = model_cm[0, 0] \/ (model_cm[0, 0] + model_cm[0, 1])\n    sensitivity = float(\"{:.2f}\".format(sensitivity))\n\n    specificity = model_cm[1, 1]\/(model_cm[1, 0] + model_cm[1, 1])\n    specificity = float(\"{:.2f}\".format(specificity))\n    \n    print(f'accuracy : {accuracy}, sensitivity : {sensitivity}, specificity : {specificity}')","c3350cb1":"best_model_accuracy = 0\nbest_model = None\n\nmodels = [\n    MLPClassifier(),\n    RandomForestClassifier(),\n    KNeighborsClassifier(),\n    LogisticRegression(solver = \"liblinear\"),\n    DecisionTreeClassifier(),\n    GaussianNB()\n]\n\nfor model in models:\n    \n    model_name = model.__class__.__name__\n\n    y_pred, accuracy = predict_with_model(model)\n    \n    print(\"-\" * 30)\n    print(model_name + \": \" )\n    \n    current_model_cm = confusion_matrix(y_test, y_pred)\n    show_metrics(current_model_cm)\n    \n    if(accuracy > best_model_accuracy):\n        best_model_accuracy = accuracy\n        best_model = model_name\n    \n    print(\"Accuracy: {:.2%}\".format(accuracy))\n    \n    show_confusion_matrix(current_model_cm, model_name)","b9213728":"print(\"Best Model : {}\".format(best_model))\nprint(\"Best Model Accuracy : {:.2%}\".format(best_model_accuracy))","5cf35c1e":"Predictor variable use in classifying breast cancer, its features are computed for each cell nucleus:\n1. id\n1. diagnosis\n1. radius_mean\n1. texture_mean\n1. perimeter_mean\n1. area_mean\n1. smoothness_mean\n1. compactness_mean\n1. concavity_mean\n1. concave points_mean\n1. symmetry_mean\n1. fractal_dimension_mean\n1. radius_se\n1. texture_se\n1. perimeter_se\n1. area_se\n1. smoothness_se\n1. compactness_se\n1. concavity_se\n1. concave points_se\n1. symmetry_se\n1. fractal_dimension_se\n1. radius_worst\n1. texture_worst\n1. perimeter_worst\n1. area_worst\n1. smoothness_worst\n1. compactness_worst\n1. concavity_worst\n1. concave points_worst\n1. symmetry_worst\n1. fractal_dimension_worst","c7236d99":"**To Do:**\n\n* Do more code cleanup\n* Do some clear documentation\n","1a6bf31b":"## Predict with various Algorithms"}}