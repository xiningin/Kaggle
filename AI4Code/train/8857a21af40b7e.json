{"cell_type":{"c40e828c":"code","95641f79":"code","3077379b":"code","b0a1e04d":"code","7b064ecd":"code","605962e1":"code","ad219a70":"code","cc358f1d":"code","b5edeca7":"code","d6cc8ed3":"code","b103128f":"code","37b498c1":"code","a98b003d":"code","f59ff646":"code","df4374c1":"code","20d41bec":"code","2215dee8":"code","f06b5dd7":"code","c676ac20":"code","e5f4185a":"code","bff8b6f1":"code","28dbd1af":"code","f8f78736":"markdown","4df01fcb":"markdown","aca6d6d9":"markdown","331175b9":"markdown","1467db0f":"markdown","11c8ddad":"markdown","81f35ae7":"markdown","51b9da0a":"markdown","3327623c":"markdown","c1f61198":"markdown","6f93a390":"markdown","adb1136f":"markdown","a56fb4c2":"markdown","1e08f998":"markdown","77b8ad0b":"markdown","18e3025a":"markdown","89dcb7b6":"markdown","daec79cb":"markdown","fcc5245b":"markdown","6cc337ab":"markdown","e92144ae":"markdown","d1a01f2d":"markdown","e647f757":"markdown"},"source":{"c40e828c":"import tensorflow as tf\nimport keras\nfrom keras.callbacks import *\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import *","95641f79":"traindata = pd.read_csv('.\/..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')","3077379b":"traindata.head(4)","b0a1e04d":"traindata.shape","7b064ecd":"f = plt.figure(figsize=(20,6))\nax = f.add_subplot(161)\nax2 = f.add_subplot(162)\nax3 = f.add_subplot(163)\nax4 = f.add_subplot(164)\nax5 = f.add_subplot(165)\nax6 = f.add_subplot(166)\nax.imshow(traindata.iloc[0].values[1:].reshape(28,28))\nax2.imshow(traindata.iloc[5].values[1:].reshape(28,28))\nax3.imshow(traindata.iloc[20].values[1:].reshape(28,28))\nax4.imshow(traindata.iloc[456].values[1:].reshape(28,28))\nax5.imshow(traindata.iloc[999].values[1:].reshape(28,28))\nax6.imshow(traindata.iloc[1500].values[1:].reshape(28,28))\nplt.show()","605962e1":"trainlabel=traindata['label'].values\ntraindata.drop('label',inplace=True,axis=1)\ntrainimages = traindata.values\n#reshape it to (28,28,1)-> (height,width,channels)\ntrainimages=trainimages.reshape(-1,28,28,1)","ad219a70":"testdata = pd.read_csv('.\/..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')","cc358f1d":"testlabel=testdata['label'].values\ntestdata.drop('label',inplace=True,axis=1)\ntestimages = testdata.values\ntestimages=testimages.reshape(-1,28,28,1)","b5edeca7":"from keras.preprocessing.image import ImageDataGenerator","d6cc8ed3":"traingen=ImageDataGenerator(rotation_range=20,\n                            zoom_range=0.1,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            shear_range=0.1,\n                            horizontal_flip=True,\n                            rescale=1\/255.0,#normalising the data\n                            validation_split=0.2 #train_val split\n                            )","b103128f":"traindata_generator = traingen.flow(trainimages,trainlabel,subset='training')\nvalidationdata_generator = traingen.flow(trainimages,trainlabel,subset='validation')","37b498c1":"testgen=ImageDataGenerator(rescale=1\/255.0)","a98b003d":"testdata_generator = testgen.flow(testimages,testlabel)","f59ff646":"model=Sequential([])\n\nmodel.add(Conv2D(64,(3,3),activation=\"relu\",input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),activation=\"relu\",input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(26,activation=\"softmax\"))\n\n","df4374c1":"model.summary()","20d41bec":"model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])","2215dee8":"# Define a Callback class that stops training once accuracy reaches 99.5%\nclass myCallback(Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('val_accuracy')>0.995):\n      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n      self.model.stop_training = True\ncallback=myCallback()","f06b5dd7":"dynamicrate = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)","c676ac20":"history=model.fit(traindata_generator,epochs=50,validation_data=validationdata_generator,callbacks=[callback,dynamicrate])","e5f4185a":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","bff8b6f1":"loss,accuracy = model.evaluate_generator(testdata_generator)","28dbd1af":"print(\"test accuracy: \"+ str(accuracy*100))","f8f78736":"Separating the labels into trainlabel and image pixels into trainimages","4df01fcb":"Creating the Neural Network using Keras","aca6d6d9":"1. Augmenting the training data\n2. Normalising pixel values from (0,255) to (0,1)\n3. Splitting the data into 80% training and 20% validation","331175b9":"Importing Image Data generator for data augmentation in run time.ImageDataGenerator allows us to augment images on runtime without affecting the local copies. It provides us an advantage of trying different augmentation techniques and can experiment it with its values","1467db0f":"# In this notebook, we will train the CNN to recognize Americal Sign Language, on dataset released by MNIST and improve the accuracy of the model by using:\n1. Data Augmentation\n2. Learning Rate Scheduler\n3. Batch Normalisation and Regularisation","11c8ddad":"Training Accuracy at the end of 15th epoch: 99.63\n\nValidation Accuracy at the end of 15th epoch: 99.76\n\nSince, validation accuracy has reached  above 99.5, callback function stopped further training of the model","81f35ae7":"**About Dataset:** Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions).","51b9da0a":"Importing the requried libraries for our task","3327623c":"Creating the test data Generator, we will only normalise it to (0,1)","c1f61198":"# # # Training the Model for 50 epochs","6f93a390":"# 1. Plotting training vs validation accuracy\n#  2. Plotting training vs validation loss\n","adb1136f":"Compiling the model, \n1. loss function: sparse_categorical_crossentropy since it is a multiclass classification model\n2. optimizer: adam\n3. metrics: accuracy-> no of images classified correctly","a56fb4c2":"It might occur that, we will overshoot the optima. Therefore, we should cancel training using callback, once the validation accuracy reaches 99.5 %","1e08f998":"Similiar to train data, First column represent labels while others represents its pixel values","77b8ad0b":"Lets look at some of the images from training data","18e3025a":"Structure of the Model and jouney of an image through Neural Network:","89dcb7b6":"Generating training and validation data from Image generator we created above","daec79cb":"![Image](https:\/\/www.kaggleusercontent.com\/kf\/23902291\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..b4PwWh0-JaEztBfEfxEvxg.R-XjDU5wnsx1xXkhlRqHs5HJNUhIFT33qWmyrKVIggB9AXKOMkL2FkyjBKxlwZOGmXXSgdUSPWyARbtEogVVIPiHkrpR2nYWnlo-lIrhSgRKeepXELPAjTRP9kyiFsGzGUMkHsElPncT_rZ9pqxjBkCGtNYIVqPhpKhBrASPPt7X2Ye69XEBEqMkFO2DrUSwceeRTruc-Y3tRKL6mWxuxFMrJQCETl8pzQe-dQb9ivOEHg_IQlyB0SsGHljdd8MXmv4Y5X-MA1EnFTz6ZkjlLjzfTjX_vuMAe7b1fdnuO7lJxMvR6wUH5qvu5oVkWHgw8MBhpOH1K9MDUJAYnM1-6417kkZtuIHY9KcJpdX3nv41vWxz-AmWKexJiN-HIRk4gVMSnzf9dwWaaznKKdAWYwPZdXkAS-NcKws2ylUS0EUFh-jXS9T4EUrTr9J6-9TCv707WOJola-Lfjk_CJEoeMdKkYVFSiraRVlEstwxLuavwkMUwRwBBuXaZm6STFvoEABiGgB_CiZkan41iO-Tiyg-lBpsICaj_-SKH6Vd0ijs8WSOzKDDWusI3NwtqqZOdamczkGVFUHHmubbS5KnqUdKIO4q-UctePM7lFqZUhKhsBuKdC_bHbWargINs-xyHZRXtOJwiDY7OVdpBkevbpNF7fmk0_lfNpTmGP7OdLC7UNB-gwd1M_vbjgPu5qxu.9kdSjumTYY33e-DaRJUX4Q\/__results___files\/__results___1_0.png)","fcc5245b":"To stop fluctuating between the accuracy, we will decrease the learning rate on each epoch","6cc337ab":"Loading the training dataset","e92144ae":"Test the model on test data using model.evulate_generator and pass the test data generator which we have already created above.\n\nIt returns two arguments \n1. Loss\n2. Accuracy","d1a01f2d":"Loading the test data","e647f757":"First Column of data corresponds to given label, while columns 1 to 785 represents its 784 pixel values. There are total 27455 images of size 28,28 and are in grayscale mode."}}