{"cell_type":{"f5d001c6":"code","7c3d8a55":"code","43736438":"code","b1743870":"code","ee9ca580":"code","65d43df6":"code","89ebd5eb":"markdown","effb2550":"markdown","4453cc6d":"markdown","328fecdd":"markdown","62474fa7":"markdown"},"source":{"f5d001c6":"def gender_features(word):\n    return {'last_letter': word[-1]}\ngender_features(\"yashvi\")","7c3d8a55":"from nltk.corpus import names\nlabeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n\nimport random\nrandom.shuffle(labeled_names)\n\n    ","43736438":"import nltk\nfeaturesets = [(gender_features(n), gender) for (n, gender) in labeled_names]\ntrain_set, test_set = featuresets[500:], featuresets[:500]\nclassifier = nltk.NaiveBayesClassifier.train(train_set)\n","b1743870":"classifier.classify(gender_features('Riya'))","ee9ca580":" print(nltk.classify.accuracy(classifier, test_set))","65d43df6":"classifier.show_most_informative_features(5)","89ebd5eb":"let's just test it out on some names that did not appear in its training data:","effb2550":"This listing shows that the names in the training set that end in \"a\" are female 33 times more often than they are male, but names that end in \"k\" are male 32 times more often than they are female. These ratios are known as **likelihood ratios**, and can be useful for comparing different feature-outcome relationships.","4453cc6d":"Male and female names have some distinctive characteristics. Names ending in a, e and i are likely to be female, while names ending in k, o, r, s and t are likely to be male. Let's build a classifier to model these differences more precisely.\n\nThe first step in creating a classifier is deciding what features of the input are relevant, and how to encode those features. For this example, we'll start by just looking at the final letter of a given name. The following feature extractor function builds a dictionary containing relevant information about a given name:","328fecdd":"Now that we've defined a feature extractor, we need to prepare a list of examples and corresponding class labels.","62474fa7":"Next, we use the feature extractor to process the names data, and divide the resulting list of feature sets into a training set and a test set. The training set is used to train a new \"naive Bayes\" classifier."}}