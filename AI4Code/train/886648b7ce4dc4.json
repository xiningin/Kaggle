{"cell_type":{"4ed5ceb7":"code","7264f905":"code","a50be58c":"code","b77fe09c":"code","d5a9e07a":"code","f7e0d22c":"code","38da1ab8":"code","029369d3":"code","6dc40c9b":"code","b0f9fa35":"code","5b883c48":"code","5b8872d8":"code","e63460ea":"code","0dab50d8":"code","8515cf0f":"code","85927deb":"code","6cb29d8d":"code","051d17f4":"code","e434725b":"code","eee32941":"code","c615c761":"code","09bf22eb":"code","de627333":"markdown","a5424728":"markdown","eb4e244e":"markdown","90512979":"markdown","e30c1127":"markdown","72df05c5":"markdown"},"source":{"4ed5ceb7":"import numpy as np\nimport pandas as pd\nimport numpy as np\nimport librosa.display\nfrom scipy import signal\nimport scipy.io.wavfile\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nimport os\nfrom IPython.display import Audio, IFrame, display","7264f905":"train_metadata = pd.read_csv('..\/input\/birdsong-recognition\/train.csv')","a50be58c":"train_metadata.head(1)","b77fe09c":"train_metadata['duration'].plot.box()\nplt.show()\nprint(train_metadata['duration'].describe())\n","d5a9e07a":"list_first=['buggna', 'brespa', 'rebwoo', 'comyel', 'bulori', 'y00475', 'hergul', 'bnhcow', 'whcspa', 'stejay', 'lesgol', 'houfin', 'pinwar', 'yebfly', 'easmea', 'cangoo', 'grtgra', 'westan', 'savspa', 'hamfly', 'veery', 'gnwtea', 'tuftit', 'aldfly', 'ovenbi1', 'warvir', 'blujay', 'winwre3', 'caster1', 'yerwar', 'orcwar', 'bkhgro', 'mouchi', 'amered', 'herthr', 'btnwar', 'osprey', 'wlswar', 'perfal', 'rocpig', 'whtspa', 'norpar', 'astfly', 'canwar', 'pilwoo', 'hoowar', 'amerob', 'swathr', 'normoc', 'whbnut', 'killde', 'greegr', 'louwat', 'haiwoo', 'marwre', 'wesmea', 'pibgre', 'houspa', 'boboli', 'eawpew', 'bushti', 'wilfly', 'balori', 'gockin', 'bewwre', 'grcfly', 'fiespa', 'norfli', 'wewpew', 'magwar', 'evegro', 'chswar', 'carwre', 'robgro', 'redcro']\nlist_second=['amegfi', 'bkbwar', 'chispa', 'woothr', 'moudov', 'vesspa', 'comrav', 'mallar3', 'pinsis', 'comter', 'bkcchi', 'purfin', 'norcar', 'barswa', 'indbun', 'greyel', 'reevir1', 'eastow', 'rewbla', 'annhum', 'horlar', 'swaspa', 'olsfly', 'houwre', 'ruckin', 'pasfly', 'buhvir', 'amepip', 'spotow', 'macwar', 'eucdov', 'canwre', 'dowwoo', 'sora', 'scoori', 'foxspa', 'bkpwar', 'wilsni1', 'blugrb1', 'daejun', 'norwat', 'gadwal', 'banswa', 'sonspa', 'lesyel', 'amecro', 'brdowl', 'logshr', 'comgra', 'comred', 'grhowl', 'brncre', 'gnttow', 'brnthr', 'snobun', 'linspa', 'rebnut', 'blkpho', 'cacwre', 'brthum', 'dusfly', 'yetvir', 'lazbun', 'buwwar', 'btywar', 'easblu', 'leafly', 'larspa', 'solsan', 'bktspa', 'scatan', 'rethaw', 'pingro', 'sposan', 'plsvir']\nlist_third=['easpho', 'leabit', 'casvir', 'greroa', 'calqua', 'coohaw', 'wooscj2', 'cedwax', 'yelwar', 'comgol', 'fiscro', 'comnig', 'labwoo', 'treswa', 'weskin', 'amewoo', 'commer', 'easkin', 'grycat', 'gryfly', 'clanut', 'rocwre', 'snogoo', 'belspa2', 'casfin', 'camwar', 'amekes', 'btbwar', 'lobdow', 'renpha', 'bawwar', 'leasan', 'amtspa', 'brwhaw', 'reshaw', 'grbher3', 'semsan', 'gocspa', 'prawar', 'juntit1', 'belkin1', 'cowscj1', 'bkchum', 'horgre', 'ribgul', 'lobcur', 'pecsan', 'comloo', 'grnher', 'cliswa', 'norsho', 'tunswa', 'semplo', 'yebsap', 'pygnut', 'lotduc', 'phaino', 'bkbmag1', 'rufhum', 'rusbla', 'merlin', 'sheowl', 'yehbla', 'baisan', 'saypho', 'buwtea', 'vigswa', 'pinjay', 'goleag', 'brebla', 'bkbcuc', 'palwar', 'wiltur', 'nutwoo', 'amebit', 'lesnig', 'bongul', 'wooduc', 'eursta', 'calgul', 'norpin', 'wesgre', 'truswa', 'ameavo', 'eargre', 'whtswi', 'sagthr', 'baleag', 'wesblu', 'doccor', 'amewig', 'whfibi', 'rebsap', 'rthhum', 'gcrfin', 'moublu', 'sagspa1', 'wessan', 'nrwswa', 'chukar', 'norhar2', 'chiswi', 'rebmer', 'lewwoo', 'swahaw', 'rinduc', 'rufgro', 'rudduc', 'shshaw', 'lecthr', 'hoomer', 'coshum', 'buffle', 'redhea']","f7e0d22c":"new_data=train_metadata[train_metadata[\"ebird_code\"].isin(list_first)].reset_index()\nnew_data.drop(['index'],axis=1,inplace=True)\nsubset=new_data[(new_data['duration']>10) & (new_data['duration']>4.0)]","38da1ab8":"subset.shape","029369d3":"bird_names=list(subset.loc[:,'ebird_code'].unique())\n#bird_names","6dc40c9b":"len(train_metadata.species.unique()),len(subset.species.unique())","b0f9fa35":"bird_indx=2 # bird index\nsample_no=10\n#print(len(subset.loc[subset['ebird_code']==bird_names[bird_indx]]))\n\naudio_filename=subset.loc[subset['ebird_code']==bird_names[bird_indx]][sample_no:sample_no+1].filename.values[0]\nfold_name=str(subset.loc[subset['filename']==audio_filename].ebird_code.values[0])\ninp_file='..\/input\/birdsong-recognition\/train_audio\/'+str(fold_name)+'\/'+str(audio_filename)\nprint(inp_file,audio_filename)\n\n# Load the audio file in librosa\nlibrosa_audio,librosa_sample_rate=librosa.load(inp_file)\nlibrosa.display.waveplot(librosa_audio, sr=librosa_sample_rate)\ndisplay(Audio(librosa_audio, rate=librosa_sample_rate))\n\n# Finding Amplitude array from the audio\ndb = librosa.core.amplitude_to_db(librosa_audio)\n\n# Finding the mean & std of the amplitude\nmean_db = np.abs(db).mean()\nstd_db = db.std()\nprint(mean_db,std_db)\n\n# Splitting the audio into non-silent intervls\naudio_split_intervals= librosa.effects.split(y=librosa_audio, top_db = mean_db - std_db)\n\n# removes silences from clip\nsilence_removed = []\nfor inter in audio_split_intervals:\n    silence_removed.extend(librosa_audio[inter[0]:inter[1]])\nsilence_removed = np.array(silence_removed)\nlibrosa.display.waveplot(silence_removed, sr=librosa_sample_rate)\ndisplay(Audio(silence_removed, rate=librosa_sample_rate))\n\n\n'''\n# using those silences from clip\nsilence_clip = librosa_audio[0:audio_split_intervals[0][0]]\nfor i in range(len(audio_split_intervals)-1):\n    silence_clip=np.append(silence_clip,librosa_audio[audio_split_intervals[i][1]:audio_split_intervals[i+1][0]])\n\ndisplay(Audio(silence, rate=librosa_sample_rate))\n'''\n\n\n#print(subset.loc[subset['filename']==audio_filename].duration.values[0])\n","5b883c48":"librosa.display.waveplot(silence_removed, sr=librosa_sample_rate)","5b8872d8":"librosa.display.waveplot(librosa_audio, sr=librosa_sample_rate)","e63460ea":"fft=np.fft.fft(silence_removed)\nmagnitude=np.abs(fft)\nfrequency=np.linspace(0,librosa_sample_rate,len(magnitude))\nleft_frequency=frequency[:int(len(frequency)\/2)]\nleft_magnitude=magnitude[:int(len(magnitude)\/2)]\nplt.plot(left_frequency,left_magnitude)\nplt.xlabel('frequency')\nplt.ylabel(\"Magnitude\")","0dab50d8":"orig_duration=librosa.get_duration(silence_removed)\nprint(orig_duration)","8515cf0f":"n_fft=2048\nhop_length=512\nstft=librosa.core.stft(silence_removed,hop_length=hop_length,n_fft=n_fft)\nspectogram=np.abs(stft)\n\nlog_spectogram=librosa.amplitude_to_db(spectogram) # Converting amplitude to decibels for clear visuals\n\nlibrosa.display.specshow(log_spectogram,sr=librosa_sample_rate,hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Frequency\")\nplt.colorbar()\nplt.show()","85927deb":"MFCCs=librosa.feature.mfcc(silence_removed,hop_length=hop_length,n_fft=n_fft,n_mfcc=13)\n\nlibrosa.display.specshow(MFCCs,sr=librosa_sample_rate,hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"MFCCs\")\nplt.colorbar()\nplt.show()\nMFCCs.shape","6cb29d8d":"import math\nfrom scipy.io.wavfile import write\nfrom numba import jit, prange\nfrom tqdm import tqdm\n\n\n#print(subset.loc[subset['filename']==audio_filename].duration.values[0])\n\n\n\n\n\n\n# Parameters for MFCC\nhop_length=512\nn_fft=2048\nn_mfcc=13\n#expected_no_mfccvec_per_segment=700\n\n# Storing the data\ndata = {\"mapping\":[], \"mfcc\":[],\"labels\":[]}\n\nSAMPLE_RATE=librosa_sample_rate\nprint(SAMPLE_RATE)\n\n#DURATION=subset.loc[subset['filename']==audio_filename].duration.values[0]# seconds\nDURATION=librosa.get_duration(silence_removed)\nSAMPLES_PER_SIGNAL=SAMPLE_RATE*DURATION # Varies as a function of duration if sample rate is fixed\nsegment_duration=5 # seconds\ntotal_samples_reqd_segment=SAMPLE_RATE*segment_duration\nnum_samples_per_segment=total_samples_reqd_segment\nexpected_no_mfccvec_per_segment=math.ceil(num_samples_per_segment\/hop_length)\n#num_samples_per_segment=math.ceil(expected_no_mfccvec_per_segment*hop_length)\nnum_segments=math.ceil(int(SAMPLES_PER_SIGNAL)\/num_samples_per_segment)\nprint(num_segments,SAMPLES_PER_SIGNAL,num_samples_per_segment,DURATION)\n\n# Sampling for multiple MFCCs\n\n\n#@autojit\nfor s in tqdm(prange(num_segments)):\n    start_sample=int(num_samples_per_segment*s) # For s=0: start\n    end_sample=start_sample+num_samples_per_segment # for s=0; start+no_of_samples\/segment\n    if end_sample>SAMPLES_PER_SIGNAL:\n        break\n    print(start_sample,end_sample,int((end_sample-start_sample)\/SAMPLE_RATE))\n\n    plt.figure(figsize=(12,3))\n    plt.plot(silence_removed,'r')\n    plt.plot(silence_removed[start_sample:end_sample],'g')\n    plt.show()\n    \n    mfcc=librosa.feature.mfcc(silence_removed[start_sample:end_sample],hop_length=hop_length,n_fft=n_fft,n_mfcc=n_mfcc) # Analyzing a slice of a signal \n    mfcc=mfcc.T \n    print(mfcc.shape)\n    librosa.display.specshow(mfcc,sr=SAMPLE_RATE,hop_length=hop_length)\n    plt.xlabel('mfcc')\n    plt.ylabel('time')\n    plt.colorbar()\n    plt.show()\n    \n    write(\"example\"+str(s)+\".wav\", librosa_sample_rate, librosa_audio[start_sample:end_sample])\n    #ipd.Audio(\"example.wav\")\n    \n    #print(\"segment_\"+str(s+1),mfcc.shape)\n    # Some times audio samples dont have expected length: so different shape of MFCC , so need to use expected_no_mfcvec_per_segment\n    # Store mfcc for segment if it has the expected length\n    if len(mfcc)==expected_no_mfccvec_per_segment+1:\n        print(\"pass\")\n        data[\"mfcc\"].append(mfcc.tolist())\n\n\n'''\n# Dividing audio into different segments\nnum_segments=2  # Lesser the no of segments, better capturing of the entire signal without miss\nSAMPLE_RATE=librosa_sample_rate\nDURATION=duration# seconds\nSAMPLES_PER_SIGNAL=SAMPLE_RATE*DURATION # Varies as a function of duration if sample rate is fixed\n\n\nnum_samples_per_segment=int(SAMPLES_PER_SIGNAL\/num_segments) # Varies as a function of duration \nexpected_no_mfccvec_per_segment=math.ceil(num_samples_per_segment\/hop_length) # hop_length is the measure of overlapping window--> so vector size will increase if hop_length is small (more overlapping)\nprint(f'sample\/signal:{SAMPLES_PER_SIGNAL},no_samples\/segment:{num_samples_per_segment},hop_length:{hop_length},expected_mfccs:{expected_no_mfccvec_per_segment}')\n'''\n\n'''\n# Sampling for multiple MFCCs\nfor s in range(num_segments):\n    start_sample=num_samples_per_segment*s # For s=0: start\n    end_sample=start_sample+num_samples_per_segment # for s=0; start+no_of_samples\/segment\n\n    plt.figure(figsize=(12,3))\n    plt.plot(librosa_audio,'r')\n    plt.plot(librosa_audio[start_sample:end_sample],'g')\n    plt.show()\n    \n    mfcc=librosa.feature.mfcc(librosa_audio[start_sample:end_sample],hop_length=hop_length,n_fft=n_fft,n_mfcc=n_mfcc) # Analyzing a slice of a signal \n    mfcc=mfcc.T \n    librosa.display.specshow(mfcc,sr=SAMPLE_RATE,hop_length=hop_length)\n    plt.xlabel('mfcc')\n    plt.ylabel('time')\n    plt.colorbar()\n    plt.show()\n    \n    write(\"example\"+str(s)+\".wav\", librosa_sample_rate, librosa_audio[start_sample:end_sample])\n    #ipd.Audio(\"example.wav\")\n    \n    #print(\"segment_\"+str(s+1),mfcc.shape)\n    # Some times audio samples dont have expected length: so different shape of MFCC , so need to use expected_no_mfcvec_per_segment\n    # Store mfcc for segment if it has the expected length\n    if len(mfcc)==expected_no_mfccvec_per_segment+1:\n        print(\"pass\")\n        data[\"mfcc\"].append(mfcc.tolist())\n    \n'''","051d17f4":"bird_classes={}\n\nfor ind,val in enumerate(bird_names):\n    bird_classes[val]=ind","e434725b":"bird_classes","eee32941":"from tqdm import tqdm\nimport json\n\n\n\ndef silenceremoval(audio_clip):\n\n    # Load the audio file in librosa\n    librosa_audio,librosa_sample_rate=librosa.load(audio_clip)\n\n    # Finding Amplitude array from the audio\n    db = librosa.core.amplitude_to_db(librosa_audio)\n\n    # Finding the mean & std of the amplitude\n    mean_db = np.abs(db).mean()\n    std_db = db.std()\n    print(mean_db,std_db)\n\n    # Splitting the audio into non-silent intervls\n    audio_split_intervals= librosa.effects.split(y=librosa_audio, top_db = mean_db - std_db)\n\n    # removes silences from clip\n    silence_removed = []\n    for inter in audio_split_intervals:\n        silence_removed.extend(librosa_audio[inter[0]:inter[1]])\n    silence_removed = np.array(silence_removed)\n    return silence_removed,librosa_sample_rate\n\n\n\n\n\nfeatures=[]\nind=0\nPar_Fold='..\/input\/birdsong-recognition'\ndata={\"features\":[],\"classes\":[]}\njson_file=\"data.json\"\n\nind1=0\n\n\n\n\nfor index,row in tqdm(subset.iterrows()):\n    if ind1==0:\n        try:\n            #print(ind1)\n            file_name=os.path.join(os.path.abspath(Par_Fold),str(\"train_audio\"),str(row['ebird_code']),str(row['filename']))\n            clas_name=row['species'] # Bird name\n            clas_no=bird_classes[row['ebird_code']] # get the number for the class \n            #print(clas_no)\n\n\n            # Parameters for MFCC\n            hop_length=512\n            n_fft=2048\n            n_mfcc=13\n            #expected_no_mfccvec_per_segment=700\n\n            # Storing the data\n            librosa_audio,librosa_sample_rate=silenceremoval(file_name)\n            #librosa_audio, librosa_sample_rate = librosa.load(file_name) # Librosa load . Constant Sample rate ~ 22000 Hz\n            SAMPLE_RATE=librosa_sample_rate # Defining the Sample rate\n\n            DURATION=librosa.get_duration(librosa_audio)\n            #DURATION=row['duration']# Duration in seconds\n            SAMPLES_PER_SIGNAL=SAMPLE_RATE*DURATION # Varies as a function of duration if sample rate is fixed\n            segment_duration=5 # seconds\n            total_samples_reqd_segment=SAMPLE_RATE*segment_duration\n            num_samples_per_segment=total_samples_reqd_segment\n            expected_no_mfccvec_per_segment=math.ceil(num_samples_per_segment\/hop_length)\n            #num_samples_per_segment=math.ceil(expected_no_mfccvec_per_segment*hop_length)\n            num_segments=math.ceil(int(SAMPLES_PER_SIGNAL)\/num_samples_per_segment)\n            #print(num_segments,SAMPLES_PER_SIGNAL,num_samples_per_segment,DURATION)\n            ind=0\n            #if ind<1:\n                # Sampling for multiple MFCCs\n            for s in range(0,(num_segments)):\n                #print(ind)\n                if ind > 5:\n                    break\n\n                start_sample=int(num_samples_per_segment*s) # For s=0: start\n                end_sample=start_sample+num_samples_per_segment # for s=0; start+no_of_samples\/segment\n                if end_sample>SAMPLES_PER_SIGNAL:\n                    break\n\n                #plt.figure(figsize=(12,3))\n                #plt.plot(librosa_audio,'r')\n                #plt.plot(librosa_audio[start_sample:end_sample],'g')\n                #plt.show()\n\n                mfcc=librosa.feature.mfcc(librosa_audio[start_sample:end_sample],hop_length=hop_length,n_fft=n_fft,n_mfcc=n_mfcc) # Analyzing a slice of a signal \n                mfcc=mfcc.T \n                #librosa.display.specshow(mfcc,sr=SAMPLE_RATE,hop_length=hop_length)\n                #plt.xlabel('mfcc')\n                #plt.ylabel('time')\n                #plt.colorbar()\n                #plt.show()\n\n                #write(\"example\"+str(s+1)+\".wav\", librosa_sample_rate, librosa_audio[start_sample:end_sample])\n                #ipd.Audio(\"example.wav\")\n                ind=ind+1\n                if len(mfcc)==expected_no_mfccvec_per_segment:\n                    #print(s,\"pass\",mfcc.shape)\n                    #features.append([mfcc.tolist(),clas_no])\n                    data[\"features\"].append(mfcc.tolist())\n                    data[\"classes\"].append(clas_no)\n        \n        except:\n            print(\"Something went wrong: next entry\")\n            pass\n            #break\n        \n    else:\n        break\n    #ind1+=1\n\n\nwith open(json_file,\"w\") as fp:\n    json.dump(data, fp, indent=4)\n    \n\n","c615c761":"\n\nlen(data['classes'])","09bf22eb":"print(1)","de627333":"*Two Label missing- Thats ok ..we can live with it *","a5424728":"## Initial Understanding of one of the audio files ","eb4e244e":"## Dividing an audio segment into multiple segment (train data size) for uniform MFCC vector length","90512979":"## Data Subsetting","e30c1127":"*Better Balance of data in Subset after subsetting*","72df05c5":"### Creating of clip with background removed[](http:\/\/)"}}