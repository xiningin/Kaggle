{"cell_type":{"8e561fe5":"code","c99d262d":"code","8e70d120":"code","afe067ce":"code","e5c7fe9b":"code","3afad237":"code","e0734662":"code","809332f2":"code","d83c355e":"code","f075ee21":"code","26b06010":"code","3d09c4c1":"code","93563bfa":"code","a2051892":"code","07e0e954":"code","2b769ea2":"code","61c918ef":"code","0e9b4147":"code","3c897cdf":"code","811503fa":"code","da650cdb":"code","a58fc1f1":"code","b460499a":"code","565bb75a":"code","b5f9d4ab":"code","b47eae39":"code","b207e635":"code","e004cda4":"code","25ef09d3":"code","1cf7a22c":"code","f966e69e":"code","36bc7169":"code","5948fcd8":"code","a8cd4aa7":"code","b9779774":"markdown","dcaecf5c":"markdown","1cbff40a":"markdown","8ad742d1":"markdown","60e5ba76":"markdown","b86b5b8f":"markdown","e202b44b":"markdown","994aa4c5":"markdown","9df5ec8c":"markdown","bd54dae6":"markdown","8784f6bc":"markdown","bf521c17":"markdown","94517c89":"markdown"},"source":{"8e561fe5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c99d262d":"import re\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport string\nfrom tensorflow import keras\nimport nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport collections","8e70d120":"stop_words = stopwords.words('english')\nstop_words.extend([\"uh\",\"oh\",\"okay\",\"im\",\"dont\"])","afe067ce":"stop_words","e5c7fe9b":"data =pd.read_csv(\"\/kaggle\/input\/the-office-lines\/the-office_lines.csv\")","3afad237":"data.shape","e0734662":"michael = data[data.Character == \"Michael\"].reset_index(drop=True)[:3000]\ndwight = data[data.Character == \"Dwight\"].reset_index(drop=True)[:3000]\njim = data[data.Character == \"Jim\"].reset_index(drop=True)[:3000]\npam = data[data.Character == \"Pam\"].reset_index(drop=True)[:3000]\n","809332f2":"michael = michael.Line\ndwight = dwight.Line\njim = jim.Line\npam = pam.Line\n","d83c355e":"sns.countplot(data.Season)","f075ee21":"plt.figure(figsize=(12,12))\nsns.countplot(data.Character[data.Character.isin(data.Character.value_counts()[:10].index)])\n","26b06010":"plt.figure(figsize=(12,12))\nplt.tight_layout()\nsns.countplot(data.Character[data.Character.isin(data.Character.value_counts()[-5:].index)])\n","3d09c4c1":"def clean_data(doc):\n    doc = \"\".join(doc)\n    doc = re.sub(r'[^\\w\\s]', '', doc)\n    tokens = doc.split()\n    tokens = [word.lower() for word in tokens]\n    tokens = [word for word in tokens if word.isalpha() ]\n    tokens = [word for word in tokens if not word in  stop_words]\n    text = \" \".join(tokens)\n    return tokens,text","93563bfa":"def generate_wordcloud(text):\n    word_cloud= WordCloud(width=1920,height=1080).generate(text)\n    plt.figure(figsize=(12,12))\n    plt.tight_layout(pad=0)\n    plt.axis(False)\n    plt.imshow(word_cloud)\n    \n    ","a2051892":"michael_tokens,michael_text = clean_data(michael)\ngenerate_wordcloud(michael_text)\n","07e0e954":"def mostcommon_words(tokens):\n    counter = collections.Counter(tokens)\n    most_common = counter.most_common(10)\n    keys = [key for key,val in most_common]\n    values = [val for key,val in most_common]\n    plt.figure(figsize=(8,8))\n    sns.barplot(keys,values)\n    plt.show()\n    \n    \nmostcommon_words(michael_tokens)","2b769ea2":"dwight_tokens,dwight_text = clean_data(dwight)\ngenerate_wordcloud(dwight_text)","61c918ef":"mostcommon_words(dwight_tokens)","0e9b4147":"jim_tokens,jim_text = clean_data(jim)\ngenerate_wordcloud(jim_text)","3c897cdf":"mostcommon_words(jim_tokens)","811503fa":"jim_tokens,jim_text = clean_data(pam)\ngenerate_wordcloud(pam_text)","da650cdb":"mostcommon_words(pam_tokens)","a58fc1f1":"def return_lines(tokens,length):\n    lines = []\n    for i in range(length,len(tokens)):\n        seq = tokens[i-length:i]\n        line  = \" \".join(seq)\n        lines.append(line)\n        \n    return lines","b460499a":"michael_lines = return_lines(michael_tokens,10)\n","565bb75a":"def prepare_data(data):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(data)\n    sequences = tokenizer.texts_to_sequences(data)\n    sequences = np.array(sequences)\n    X, y = sequences[:,:-1], sequences[:,-1]\n    vocab_size = len(tokenizer.word_index) + 1\n    return X,y,vocab_size,tokenizer","b5f9d4ab":"michael_X,michael_y,vocab_size,tokenizer = prepare_data(michael_lines)\nseq = michael_X.shape[1] ","b47eae39":"def model_rnn(X,y,epochs,vocab_size,seq):\n    model = keras.Sequential([keras.layers.Embedding(input_dim = vocab_size,output_dim=20,input_length=seq),\n                          keras.layers.Bidirectional(keras.layers.LSTM(100)),\n                          keras.layers.Dense(vocab_size,activation=\"softmax\")])\n    \n    \n    model.compile(loss=\"sparse_categorical_crossentropy\",metrics=\"accuracy\",optimizer=\"adam\")\n    early_stop = keras.callbacks.EarlyStopping(patience=5)\n    \n    model.fit(X,y,epochs=epochs,callbacks=early_stop)\n    \n    return model","b207e635":"model_michael = model_rnn(michael_X,michael_y,50,vocab_size,seq)","e004cda4":"seed_text = \"Dunder Mifflin\"\nnum_word = 20\ndef michael(seed_text,num_word,model):\n    for _ in range(num_word):\n        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n        tokens = pad_sequences([tokens],maxlen=seq,padding=\"post\")\n    \n        predicted = np.argmax(model.predict(tokens))\n        outputword = \"\"\n    \n        for word,index in tokenizer.word_index.items():\n            if predicted == index:\n                outputword = word\n                break\n            \n        seed_text += \" \" + outputword\n    return seed_text\n\nmichael(seed_text,num_word,model_michael)","25ef09d3":"dwight_tokens, dwight_text = clean_data(dwight)\ndwight_lines = return_lines(dwight_tokens,10)\ndwight_X,dwight_y,vocab_size,tokenizer = prepare_data(dwight_lines)\nseq = dwight_X.shape[1]\nmodel_dwight = model_rnn(dwight_X,dwight_y,50,vocab_size,seq)","1cf7a22c":"seed_text = \"Dunder Mifflin\"\nnum_word = 20\n\ndef dwight(seed_text,length,model):\n    for _ in range(length):\n        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n        padded = pad_sequences([tokens],maxlen=seq,padding=\"post\")\n        prediction = np.argmax(model.predict(padded))\n        outputword = \"\"\n        \n        for word,index in tokenizer.word_index.items():\n            if prediction == index:\n                outputword = word\n                break\n    \n        seed_text += \" \" + word\n    \n    return seed_text\n\nprint(dwight(seed_text,num_word,model_dwight))\n        ","f966e69e":"jim_tokens, jim_text = clean_data(jim)\njim_lines=return_lines(jim_tokens,10)\njim_X,jim_y,vocab_size,tokenizer=prepare_data(jim_lines)\nseq = jim_X.shape[1]\nmodel_jim = model_rnn(jim_X,jim_y,50,vocab_size,seq)","36bc7169":"seed_text = \"Dunder Mifflin\"\nnum_word = 20\n\ndef jim(seed_text,length,model):\n    for _ in range(length):\n        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n        padded = pad_sequences([tokens],maxlen=seq,padding=\"post\")\n        prediction = np.argmax(model.predict(padded))\n        outputword = \"\"\n        \n        for word,index in tokenizer.word_index.items():\n            if prediction == index:\n                outputword = word\n                break\n    \n        seed_text += \" \" + word\n    \n    \n    return seed_text\n\nprint(jim(seed_text,num_word,model_jim))\n","5948fcd8":"pam_tokens, pam_text = clean_data(pam)\npam_lines=return_lines(jim_tokens,10)\npam_X,pam_y,vocab_size,tokenizer=prepare_data(pam_lines)\nseq = pam_X.shape[1]\nmodel_pam = model_rnn(pam_X,pam_y,50,vocab_size,pam_X.shape[1])","a8cd4aa7":"seed_text = \"Dunder Mifflin\"\nnum_word = 20\n\ndef pam(seed_text,length,model):\n    for _ in range(length):\n        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n        padded = pad_sequences([tokens],maxlen=seq,padding=\"post\")\n        prediction = np.argmax(model.predict(padded))\n        outputword = \"\"\n        \n        for word,index in tokenizer.word_index.items():\n            if prediction == index:\n                outputword = word\n                break\n    \n        seed_text += \" \" + word\n    \n    \n    return seed_text\n\nprint(pam(seed_text,num_word,model_pam))\n","b9779774":"# **Importing Dataset**","dcaecf5c":"# **Importing Packages**","1cbff40a":"# **Most Common Words Dwight**","8ad742d1":"# **Michael Generate Text**","60e5ba76":"# **Most Common Words Jim**","b86b5b8f":"# **Generate Text for Each Character**","e202b44b":"# **Jim Generate Text**","994aa4c5":"# **Most Common Words Michael**","9df5ec8c":"# **Preparing Dataset**","bd54dae6":"# **EDA**","8784f6bc":"# **Pam Generate Text**","bf521c17":"# **Most Common Words Pam**","94517c89":"# **Dwight Generate Text**"}}