{"cell_type":{"49a6dd4a":"code","7976a91d":"code","e7e39263":"code","944ab15a":"code","e827ba25":"code","de7f4213":"code","8bb7a7b3":"code","48a2c51b":"code","f85eb46c":"code","50a2add2":"code","006cf691":"code","0be985d7":"code","5e422e08":"code","e630341e":"code","1efbd574":"code","b520cb02":"code","566e7359":"code","dab2dd33":"code","cada16ce":"code","1711309a":"code","2645c9b9":"code","e2a93fd4":"code","984d2c53":"code","e3ab7a68":"code","5ce3a5cb":"code","de861d81":"code","6e94c957":"code","5eb6ed34":"code","55b37b03":"code","ff452d21":"code","ea761172":"code","29235713":"code","8c139205":"code","a5ec7d02":"code","2b338388":"code","69a08013":"code","aca0bf15":"code","06959c74":"code","f2fa38c4":"code","5e056847":"code","84264e0c":"code","44ddf7d2":"code","0511a396":"code","3be202ce":"code","0cb2418d":"code","6e39c394":"code","3eea56d8":"code","6a0a2021":"code","e1a02884":"code","c3b0e615":"code","ef2186a0":"code","e030be84":"code","40470b33":"code","482e49e8":"code","ae739f69":"code","15952b79":"code","465d2b71":"code","2c1ac39b":"code","d3246cc6":"code","4f35dd78":"code","061705bc":"code","022d0c33":"code","ffde81b6":"code","068a73b0":"code","38b67773":"code","b8218ce7":"code","44598976":"code","25f17779":"code","222e8e16":"code","ffcdbe13":"markdown","6d302bb3":"markdown","1b743664":"markdown","c092e810":"markdown","2e3f23ef":"markdown","1a1709d2":"markdown","932ebff5":"markdown","0e1b66cc":"markdown","0ef1d0af":"markdown","cd923ab9":"markdown","512b0f36":"markdown","ecc6b8dd":"markdown","13ac25df":"markdown","eac61233":"markdown","76bb9845":"markdown","c6c86eda":"markdown","7735893c":"markdown","a7bab9cd":"markdown","3c8f0925":"markdown","dd03efd8":"markdown","e315dc0e":"markdown","8df175b3":"markdown","0fd34b41":"markdown","e91b3bce":"markdown","be36bfda":"markdown","2373d5cc":"markdown","107d49d0":"markdown","a8153e39":"markdown","3ec7c7c0":"markdown","46d6e58a":"markdown","27ad2ecc":"markdown","576de196":"markdown","c991e337":"markdown","89183e21":"markdown","5f1df7f5":"markdown","5fec09bc":"markdown","6f9d8d3e":"markdown","758ec6bd":"markdown","14023096":"markdown","10d9f4f3":"markdown","c64e8a4a":"markdown","b3c19196":"markdown","d18e9216":"markdown","09f4d845":"markdown","366ea19b":"markdown","fbeaed8c":"markdown","6cf1239a":"markdown","be8d12c9":"markdown","03d5e39b":"markdown","ea73d2b6":"markdown","8a65776e":"markdown","f4f74165":"markdown","c97cb269":"markdown"},"source":{"49a6dd4a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nprint(os.listdir(\"..\/input\"))\nPATH = '..\/input\/'\n# Any results you write to the current directory are saved as output.\nnp.random.seed(512)","7976a91d":"# https:\/\/nikgrozev.com\/2015\/06\/16\/fast-and-simple-sampling-in-pandas-when-loading-data-from-files\/ \n# Following the approach to index the rows in pandas skiprows. Trust me with the lenght or run:\n# train_lines = sum(1 for l in open(f'{PATH}train.csv'))\ntrain_lines = 629145481 - 1 # there needs to be some substraction (0 indexing)\n# if not using pandas with skiprows:\n#skridx = np.arange(0, train_lines, 2)\nsamp_length = 75000","e7e39263":"# I used the dtype options from aguiars kernel, as this apparently solved the memory overflow in kaggle kernel\ntrain = pd.read_csv(f'{PATH}train.csv', dtype={'acoustic_data': np.int16, \n                                               'time_to_failure': np.float64}) # something less than 5gb, actually - things were getting worse with skiprows, so now ... \ntest_ids = pd.read_csv(f'{PATH}sample_submission.csv') \n\n# Well decimating now here:\n","944ab15a":"# skridx = np.arange(0, train_lines, 2) # Decimate and hoping not to kill the memory again. \ntrain = train.iloc[::2, :]","e827ba25":"# Short overview over the file format, note everything is decimated a bit:\ntrain.head()","de7f4213":"# Many many samples\ntrain.shape","8bb7a7b3":"# We need to predict the time_to failure for simple snippets.\ntest_ids.head()","48a2c51b":"# 2624 test files.\ntest_ids.shape ","f85eb46c":"train['time_to_failure'].describe()","50a2add2":"train['acoustic_data'].describe()","006cf691":"unique_sampling_steps = np.unique(np.diff(np.round(train.time_to_failure, 9)))","0be985d7":"# We know there are several events. So a slightly different plot:\nplt.figure(figsize=(10,5))\nplt.subplot(121)\nplt.hist(unique_sampling_steps)\nplt.title('Steps with events')\nplt.subplot(122)\nplt.hist(unique_sampling_steps[unique_sampling_steps < 2])\nplt.title('Removing the long events.')\nplt.tight_layout()","5e422e08":"print(np.where(np.diff(np.round(train.time_to_failure[:100000], 5)))) # I.e. decreasing precision ","e630341e":"# Now lets have a look at the audio signal around failures, with the index we are not really caring about being one off..\n# looking for increasing times as there's a restart in the signal\nfailures = np.where(np.diff(train.time_to_failure) > 0)","1efbd574":"# Seems like there are 16 failures:\nprint(failures[0].shape)","b520cb02":"plt.figure(figsize=(15,10))\nfor ii, f_idx in zip(range(failures[0].shape[0]), failures[0]):\n    plt.subplot(4, 4, ii + 1)\n    plt.plot(np.arange(-samp_length, 100), train.acoustic_data[f_idx - samp_length : f_idx + 100])","566e7359":"plt.figure(figsize=(15,10))\nfor ii, f_idx in zip(range(failures[0].shape[0]), failures[0]):\n    plt.subplot(4, 4, ii + 1)\n    plt.plot(np.arange(-1200000, 0), train.acoustic_data[f_idx - 1200000 : f_idx])","dab2dd33":"n_rnd_samples = 1000\nrnd_sample_idx = np.random.randint(low=samp_length, high=train.shape[0], size=n_rnd_samples)","cada16ce":"variation = np.empty(n_rnd_samples)\n\nfor idx, samp in enumerate(rnd_sample_idx):\n    variation[idx] = np.max(train.time_to_failure[samp - samp_length : samp]) - np.min(train.time_to_failure[samp - samp_length : samp])","1711309a":"b = plt.hist(variation[variation < 4])","2645c9b9":"b = plt.hist(np.clip(train.acoustic_data, -200, 200), bins=50)","e2a93fd4":"from scipy.stats import spearmanr\nspike_size = 800\nspike_idx = np.abs(train.acoustic_data) > spike_size\n\nplt.figure(figsize=(15,5))\nspear = spearmanr(np.abs(train[spike_idx]['acoustic_data']), train[spike_idx]['time_to_failure'])\nplt.subplot(121)\nplt.scatter(np.abs(train[spike_idx]['acoustic_data']), train[spike_idx]['time_to_failure'])\nb = plt.title(f'Peaks and time to failure correlate with r ={spear[0]:.3f}')\nplt.subplot(122)\nb = plt.hist(train[spike_idx]['time_to_failure'])\nplt.tight_layout()","984d2c53":"t_t_f = np.empty(n_rnd_samples)\nm_a_d = np.empty(n_rnd_samples)\n\nfor idx, samp in enumerate(rnd_sample_idx):\n    t_t_f[idx] = np.median(train.time_to_failure[samp - samp_length : samp])\n    m_a_d[idx] = np.max(np.abs(train.acoustic_data[samp - samp_length : samp]))","e3ab7a68":"spear = spearmanr(np.array(t_t_f), np.array(m_a_d))\n\nplt.scatter(np.array(t_t_f), np.array(m_a_d))\nb = plt.title(f'Peaks and time to failure correlate with r = {spear[0]:.3f}')","5ce3a5cb":"def basic_properties(data):\n    properties = np.zeros(7)\n    # For many of the basic properties we use the abs, that is the amplitude\n    properties[:3] = list(np.percentile(np.abs(data), [25, 50, 75]))\n    \n    for n_f, jj in enumerate([np.mean, np.std, np.max, np.min]):\n        properties[3 + n_f] = jj(data)\n    return properties\n    \nt_t_f = np.empty(n_rnd_samples)\nm_a_d = np.empty((n_rnd_samples, 7))\n\nfor idx, samp in enumerate(rnd_sample_idx):\n    t_t_f[idx] = np.median(train.time_to_failure[samp - samp_length : samp])\n    m_a_d[idx, :] = basic_properties(np.abs(train.acoustic_data[samp - samp_length : samp]))","de861d81":"plt.figure(figsize=(25,20))\nfeat_names = ['25-percentile', '50-percentile', '75-percentile', 'mean', 'std', 'max', 'min']\nfor ii, fna in enumerate(feat_names):\n    ax = plt.subplot(3, 4, ii + 1)\n    sns.regplot(t_t_f, m_a_d[:, ii], ax=ax)\n    spear = spearmanr(np.array(t_t_f), np.array(m_a_d[:, ii]))\n    b = plt.title(f'{fna} and ttf correlate with r = {spear[0]:.3f}')","6e94c957":"t_t_f = np.empty(n_rnd_samples)\nm_a_d = np.hstack([m_a_d, np.zeros((m_a_d.shape[0],1))])\n\nfor idx, samp in enumerate(rnd_sample_idx):\n    t_t_f[idx] = np.median(train.time_to_failure[samp - samp_length : samp])\n    m_a_d[idx, 7] = np.sqrt(np.mean(train.acoustic_data[samp - samp_length : samp] ** 2))\n    ","5eb6ed34":"plt.figure(figsize=(15,5))\nax = plt.subplot(1, 2, 1)\nsns.regplot(t_t_f, m_a_d[:, 7], ax=ax)\nspear = spearmanr(np.array(t_t_f), np.array(m_a_d[:, 7]))\nb = plt.title(f'RMS and ttf correlate with r = {spear[0]:.3f}')\nax = plt.subplot(1, 2, 2)\nsns.regplot(m_a_d[:,3], m_a_d[:, 7], ax=ax)\nspear = spearmanr(m_a_d[:,3], np.array(m_a_d[:, 7]))\nb = plt.title(f'RMS and abs(mean) correlate with r = {spear[0]:.3f}')","55b37b03":"# This might use up a lot of memory... \ntrain['acoustic_diff'] = np.hstack([0, np.diff(train['acoustic_data'])])","ff452d21":"# simple description:\ntrain['acoustic_diff'].describe()","ea761172":"\ndef RMS(data):\n    return np.sqrt(np.mean(data**2))\n\ndef basic_properties_up(data):\n    properties = np.zeros(8)\n    # For many of the basic properties we use the abs, that is the amplitude\n    properties[:3] = np.percentile(data, [25, 50, 75])\n    \n    for n_f, jj in enumerate([np.mean, np.std, np.max, np.min, RMS]):\n        properties[3 + n_f] = jj(data)\n    return properties\n    \nt_t_f = np.empty(n_rnd_samples)\nm_a_d = np.empty((n_rnd_samples, 8))\n\nfor idx, samp in enumerate(rnd_sample_idx):\n    t_t_f[idx] = np.median(train.time_to_failure[samp - samp_length : samp])\n    m_a_d[idx, :] = basic_properties_up(train.acoustic_diff[samp - samp_length : samp])","29235713":"plt.figure(figsize=(25,20))\nfeat_names = ['25-percentile', '50-percentile', '75-percentile', 'mean', 'std', 'max', 'min', 'RMS']\nfor ii, fna in enumerate(feat_names):\n    ax = plt.subplot(3, 4, ii + 1)\n    sns.regplot(t_t_f, m_a_d[:, ii], ax=ax)\n    spear = spearmanr(np.array(t_t_f), np.array(m_a_d[:, ii]))\n    b = plt.title(f'{fna} and ttf correlate with r = {spear[0]:.3f}')","8c139205":"import librosa # Seems to be a common library for all thing auditory","a5ec7d02":"# Assuming that t_t_f is in seconds, yes, I'm lazy, still didn't look that up, shame on me:\nsr = round(1 \/ (train.iloc[0]['time_to_failure'] - train.iloc[1]['time_to_failure']))\nprint(sr)","2b338388":"(train.iloc[0]['time_to_failure'] - train.iloc[75000]['time_to_failure'])","69a08013":"def mfcc_wrap(data):\n    return librosa.power_to_db(librosa.feature.melspectrogram(data.values.astype('float32'), n_mels=25))","aca0bf15":"plt.figure(figsize=(15,10))\nfor ii, f_idx in zip(range(failures[0].shape[0]), failures[0]):\n    ax = plt.subplot(4, 4, ii + 1)\n    sns.heatmap(mfcc_wrap(train.acoustic_data[f_idx - samp_length : f_idx + 100]))","06959c74":"mfcc_wrap(train.acoustic_data[ : samp_length]).ravel().shape","f2fa38c4":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error","5e056847":"max_features = np.round(train.shape[0]\/ samp_length).astype(int)\nprint(f'We can create {max_features} unique samples. Maybe this gets us somewhere')","84264e0c":"def basic_properties_time(data):\n    properties = np.zeros(7)\n    # For many of the basic properties we use the abs, that is the amplitude\n    properties[:3] = np.percentile(data, [25, 50, 75])\n    \n    for n_f, jj in enumerate([np.mean, np.std, np.max, RMS]):\n        properties[3 + n_f] = jj(data)\n    return properties","44ddf7d2":"def basic_properties_diff(data):\n    properties = np.zeros(6)\n    properties[:2] = np.percentile(data, [25, 75])\n    \n    for n_f, jj in enumerate([np.min, np.std, np.max, RMS]):\n        properties[2 + n_f] = jj(data)\n    return properties","0511a396":"train =  train.drop(['acoustic_diff'], axis=1)","3be202ce":"n_samples = 15000\nX_time = np.zeros((n_samples, 7))\nX_diff = np.zeros((n_samples, 6))\nX_mfcc = np.zeros((n_samples, 3675))\ny = np.zeros((n_samples))","0cb2418d":"sample_idx = np.random.randint(low=samp_length, high=train.shape[0], size=n_samples)\n\nfor idx, samp in enumerate(sample_idx):\n    y[idx] = np.median(train.time_to_failure[samp - samp_length : samp])\n    X_time[idx, :] = basic_properties_time(np.abs(train.acoustic_data[samp - samp_length : samp]))\n    X_diff[idx, :] = basic_properties_diff(np.diff(train.acoustic_data[samp - samp_length : samp]))\n    X_mfcc[idx, :] = mfcc_wrap(train.acoustic_data[samp - samp_length : samp]).ravel()","6e39c394":"pred_mean = np.ones(y.shape) * np.mean(X_time[:, 3])","3eea56d8":"print(mean_absolute_error(y, pred_mean))","6a0a2021":"from sklearn.ensemble import RandomForestRegressor\n","e1a02884":"# Make pred_tree greater than 0\npred_time = cross_val_predict(RandomForestRegressor(n_estimators=100), X_time, y, cv=3)\npred_time[pred_time < 0] = 0","c3b0e615":"print(mean_absolute_error(y, pred_time))","ef2186a0":"pred_diff = cross_val_predict(RandomForestRegressor(n_estimators=100), X_diff, y, cv=3)\npred_diff[pred_diff < 0] = 0","e030be84":"print(mean_absolute_error(y, pred_diff))","40470b33":"# simple average:\nprint(mean_absolute_error(y, (pred_time + pred_diff)\/2))","482e49e8":"pred_comb = cross_val_predict(RandomForestRegressor(n_estimators=100), np.hstack([X_time, X_diff]), y, cv=3)","ae739f69":"pred_comb[pred_comb < 0] = 0\nprint(mean_absolute_error(y, pred_comb))","15952b79":"pred_mel = cross_val_predict(RandomForestRegressor(n_estimators=10, n_jobs=3), X_mfcc, y, cv=3)","465d2b71":"pred_mel[pred_mel < 0] = 0\nprint(mean_absolute_error(y, pred_mel))","2c1ac39b":"print(mean_absolute_error(y, (pred_mel + pred_comb)\/2))","d3246cc6":"data_rms = RMS(train.acoustic_data)\nprint(data_rms)","4f35dd78":"n_samples = 15000\nX_time = np.zeros((n_samples, 7))\nX_diff = np.zeros((n_samples, 6))\nX_mfcc = np.zeros((n_samples, 3675))\ny = np.zeros((n_samples))","061705bc":"sample_idx = np.random.randint(low=samp_length, high=train.shape[0], size=n_samples)\n\nfor idx, samp in enumerate(sample_idx):\n    y[idx] = np.median(train.time_to_failure[samp - samp_length : samp])\n    temp_data = train.acoustic_data[samp - samp_length : samp]\n    temp_rms = RMS(temp_data)\n    temp_data = temp_data * (data_rms\/temp_rms)\n    \n    X_time[idx, :] = basic_properties_time(np.abs(temp_data))\n    X_time[idx, -1] = temp_rms # keeping the old rms as a feature basic_properties_time(np.abs(temp_data))\n    X_diff[idx, :] = basic_properties_diff(np.diff(temp_data))\n    X_mfcc[idx, :] = mfcc_wrap(temp_data).ravel()","022d0c33":"pred_time = cross_val_predict(RandomForestRegressor(n_estimators=100), X_time, y, cv=3)\npred_time[pred_time < 0] = 0\nprint(mean_absolute_error(y, pred_time))","ffde81b6":"pred_diff = cross_val_predict(RandomForestRegressor(n_estimators=100), X_diff, y, cv=3)\npred_diff[pred_diff < 0] = 0\nprint(mean_absolute_error(y, pred_diff))","068a73b0":"pred_comb = cross_val_predict(RandomForestRegressor(n_estimators=100), np.hstack([X_time, X_diff]), y, cv=3)\npred_comb[pred_comb < 0] = 0\nprint(mean_absolute_error(y, pred_comb))","38b67773":"n_samples = 15000\nX_time = np.zeros((n_samples, 7))\nX_diff = np.zeros((n_samples, 6))\nX_mfcc = np.zeros((n_samples, 3675))\ny = np.zeros((n_samples))","b8218ce7":"sample_idx = np.random.randint(low=samp_length, high=train.shape[0], size=n_samples)\n\nfor idx, samp in enumerate(sample_idx):\n    y[idx] = np.median(train.time_to_failure[samp - samp_length : samp])\n    X_time[idx, :] = basic_properties_time(np.abs(train.acoustic_data[samp - samp_length : samp]))\n    X_diff[idx, :] = basic_properties_diff(np.diff(train.acoustic_data[samp - samp_length : samp]))\n    X_mfcc[idx, :] = mfcc_wrap(train.acoustic_data[samp - samp_length : samp]).ravel()","44598976":"model_basic = RandomForestRegressor(n_estimators=100)\nmodel_basic.fit(np.hstack([X_time, X_diff]), y)","25f17779":"submit_df = test_ids.copy()\nfor seg_id in test_ids.seg_id:\n    temp = pd.read_csv(f'{PATH}test\/{seg_id}.csv')\n    temp = temp.iloc[::2, :] # we've been using decimated data the whole time...\n    x_pred = np.zeros((1, 13))\n    x_pred[0, :7] = basic_properties_time(np.abs(temp.acoustic_data))\n    x_pred[0, 7:] = basic_properties_diff(np.diff(temp.acoustic_data))\n    X_pred = model_basic.predict(x_pred)\n    \n    submit_df.loc[test_ids.seg_id == seg_id, 'time_to_failure'] = np.max([0, X_pred])","222e8e16":"submit_df.to_csv('submission.csv', index=False)","ffcdbe13":"Another value I just remembered that is often used in the auditory domanin ist the RSM (root-squared-mean). Which should correlated highly with values in the above. But I'll but it in here as well. ","6d302bb3":"## Time and derivatives combined","1b743664":"## Do some random sampling again: Look at the max-values in an epoch and time_to_failure","c092e810":"Not really sure what to make off it... yet... this will happen another time...","2e3f23ef":"## Can Spikes tell us something about time_to_failure?\nOnly using absolute values for spikes","1a1709d2":"Some common features that are used in the auditory domain are time frequency estimates. I am pretty much agnosticly applying those here. I have some ideas how to implement them more nicely, especially for visualization, but again, some evening hack... ","932ebff5":"Kinda smooth plots before each event, not high value data. Just by eyeballing it seems like that there is a decay in high values, the closer we are to an earthquake. But well, this is not the best way to look at the data. \n\nAdditional point: We are not able to rely on too many data points before events to make our predictions. Rather (as the goal of the challenge is) we have to create a model to just predict the time before an event. \nCutting into samples could solve this maybe.\n\nWe also see that there are huge spikes in the data!","0e1b66cc":"## Side note\nI am not plotting the time series before the events, as those look pretty similar to the normal data. So there is not too much information to be gained by this. ","0ef1d0af":"# Let's try some really simple prediciton\nIn the prior version there was stuff done using fft features (which was probably quite wrong on many levels), it didn't do much too say the least^^\n\nBy looking at the other analysis, it was probably a relation between max values and time_to_failure","cd923ab9":"## Base line - what we definitely want to beat!","512b0f36":"# At last: Creating a simple submission","ecc6b8dd":"Some basic properties of change also correlate with time to failure. But without further analysis we cannot be sure, how unique those properties are! ","13ac25df":"## And the average","eac61233":"# Learn a bit more about acoustic data\n\n## Spikes\n\nWe have seen some huge spikes in the data. Are these common?","76bb9845":"We can actually see, that some really basic features (such as the max-value) has some predictive ability!","c6c86eda":"## And look at some more data before events:\nWell this is not very informative \/  representative.  ","7735893c":"## Redoing the basic features analysis:","a7bab9cd":"# Addendum 2: time-frequency features","3c8f0925":"Something more has to be done here! ... Probably understanding wise... ","dd03efd8":"A feature quite often used are mel frequencies. Do they work here? I don't know. Very often used in speech processing!\nWorking with defaults here. But let's see what happens in another domain, right before an event.\nBut we need a sampling rate here... ","e315dc0e":"Our goal is to predict one value for time_to_failure for each training segment. A question that came to my mind, also due to the different sampling rates: How much does time_to_failure vary in random 150.000 (or 75.000) sample pieces. ","8df175b3":"# Addendum 1\nUsing amplitude, power and other simple features deal with the data at hand directly. Another important feature of the audio signal could be the change over time. That is calculating the derivative, but now using the simple difference over time.  \n**Important now**: The decimation step in the beginning is now affecting the data!","0fd34b41":"### We are using very basic features, hoping that the distribution is the same, should not mean too much (I hope)","e91b3bce":"## Some things that might help\nWe can create 4194 unique samples. But I think random sampling from the data to create our test and validation sets might be the way to got. Let's see how far we can get! ","be36bfda":"# A last test - does normalization of batches help?","2373d5cc":"## The rescaled error values:","107d49d0":"Basically we are rescaling every batch in the training set by the factor data_rms \/ set_rms","a8153e39":"### Bottom line: Rescaling didn't help us ","3ec7c7c0":"# Earthquake prediction \n\nWell my first kernel, and just some work in progress (many a fast evening hacks ...)\n\nIdea collection and some stupid(?) modeling ideas.\n\nI had a look before at  https:\/\/www.kaggle.com\/jsaguiar\/seismic-data-exploration by aguiar, who points out many things, that could be an issue for this kernel... And I will sometimes refer to the quite nice analysis in the kernel. \n\n\nFirst things first:\n1. We got one big training file\n    * It's possible a concatenation of different experiments (see other kernels, different time steps?\n2. We got many small test sets.\n    * Of 150.000 data points of acoustic data\n\nLet's have a look at it.\nTo lower the memory burden a little bit, I am only reading every second row for now. Not sure about the effect on the data yet. (Doesn't work on the kernel, higher memory load, than without...)\n\n## TODO:\nGet that timing clear!","46d6e58a":"## Actually - not so much","27ad2ecc":"## We are now recreating the data set and look at a first basic preprocessing step","576de196":"#### Bottom line:\nTime derivative features seem to contain at least some more information","c991e337":"## Trees have been promising before","89183e21":"# And off to the leader board:","5f1df7f5":"Immediate question before going on with the training data: What is the length of each test set?\n``test_length = [pd.read_csv(f'{PATH}test\/{i}.csv').shape[0] for i in test_ids['seg_id']]``\n\nWell ... it's 150000, which can be found in many of the other kernels (i.e. aguiars). \nRunning the line above would be a waste of time :P ","5fec09bc":"And something is wrong. Let's just use the defaults and see how far we can get","6f9d8d3e":"## Punchline:\nSome basic features could actually do something already! We tried this already, see below Version 7, (LB=1.962)","758ec6bd":"We can see that there seems to be some relationship between spikes and time to failure.\nHuge spikes seem to occur somewhat more readily before failure events!\n\nBut also caution: Some spikes occur long before!","14023096":"A bit better still ...","10d9f4f3":"# Hm... some look at db in a 75000 sample","c64e8a4a":"# Learn a bit more about time to failure","b3c19196":"## A quick look a the mel frequencies","d18e9216":"But apparently, there are different  sampling periods (see the referred kernel...).  \nWe can also see this above.\n\nSo maybe later: Discretize the data a bit more (well here already half the data was skipped anyways...)\n\nStupid other idea: Strict discretization and clustering? ","09f4d845":"## Time derivative features:","366ea19b":"## Looking at the 150000 samples before each event:","fbeaed8c":"Apparently not","6cf1239a":" Next we have a look at another, question which is interesting for me: What is the sampling frequency. \n How many data points are in the acoustic data before a change in time_to_failure occurs?","be8d12c9":"# Extend the notion - can we use basic properties of the distribution?","03d5e39b":"At least better than baseline... ","ea73d2b6":"Still not having much of an idea about earthquake data, that seems to be a quite high sr. ","8a65776e":"However, it might be interesting to check whether normalizing the data to have the same RMS will have an effect on predictive ability (generalization etc.)","f4f74165":"# Predictions:","c97cb269":"# Data overview"}}