{"cell_type":{"89c705f6":"code","46b238be":"code","38400336":"code","15efd5c9":"code","8c96a8b0":"code","4c6e7497":"code","56bc524a":"code","a145733d":"code","b3c19744":"code","2bb2024c":"code","ad4cc741":"code","a91caeb8":"markdown","33e1a4a0":"markdown","67d1fd40":"markdown","75b7c42e":"markdown","d77688b5":"markdown","7589de56":"markdown","854fd074":"markdown","daf642d3":"markdown","4d6a7041":"markdown","302ac689":"markdown"},"source":{"89c705f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport os\nimport cv2\nfrom PIL import Image","46b238be":"X_train=np.load('..\/input\/kmnist-train-imgs.npz')['arr_0']\nX_train.shape","38400336":"import matplotlib.pyplot as plt\n\nfig,axes=plt.subplots(5,5,figsize=(15,15))\n\nfor r in range(5):\n    for c in range(5):\n        axes[r,c].imshow(X_train[np.random.randint(X_train.shape[0])])","15efd5c9":"img_rows = 28\nimg_cols = 28\nchannels = 1\nimg_shape = (img_rows, img_cols, channels)\nlatent_dim = 100","8c96a8b0":"def build_generator():\n    model = Sequential()\n    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n    model.add(Reshape((7, 7, 128)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n    model.summary()\n    noise = Input(shape=(latent_dim,))\n    img = model(noise)\n    return Model(noise, img)","4c6e7497":"def build_discriminator():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    model.summary()\n    img = Input(shape=img_shape)\n    validity = model(img)\n    return Model(img, validity)","56bc524a":"optimizer = Adam(0.0002, 0.5)","a145733d":"# build discriminator\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy',\n                      optimizer=optimizer,\n                      metrics=['accuracy'])\n\n# build generator\ngenerator = build_generator()\nz = Input(shape=(100,))\nimg = generator(z)\n\n# For the combined model we will only train the generator\ndiscriminator.trainable = False\n\n# The discriminator takes generated images as input and determines validity\nvalid = discriminator(img)\n\n# The combined model  (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer=optimizer)","b3c19744":"def train(epochs, batch_size, save_interval):\n    os.makedirs('images', exist_ok=True)        \n\n    X_train=np.load('..\/input\/kmnist-train-imgs.npz')['arr_0']\n\n    # Rescale -1 to 1\n    X_train = X_train \/ 127.5 - 1.\n    X_train = np.expand_dims(X_train, axis=3)\n\n    # Adversarial ground truths\n    valid = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n\n    for epoch in range(epochs):\n        # Select a random real images\n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        real_imgs = X_train[idx]\n\n        # Sample noise and generate a batch of fake images\n        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n        fake_imgs = generator.predict(noise)\n\n        # Train the discriminator\n        D_loss_real = discriminator.train_on_batch(real_imgs, valid)\n        D_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n        D_loss = 0.5 * np.add(D_loss_real, D_loss_fake)\n\n        # Train the generator\n        g_loss = combined.train_on_batch(noise, valid)\n\n        # If at save interval\n        if epoch % save_interval == 0:\n            # Print the progress\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, D_loss[0], 100 * D_loss[1], g_loss))\n            # Save generated image samples\n            show_imgs(epoch)","2bb2024c":"def show_imgs(epoch):\n    r, c = 5, 5\n    noise = np.random.normal(0, 1, (r * c, latent_dim))\n    gen_imgs = generator.predict(noise)\n\n    # Rescale images 0 - 1\n    gen_imgs = 0.5 * gen_imgs + 0.5\n\n    fig, axs = plt.subplots(r, c)\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n            axs[i, j].axis('off')\n            cnt += 1","ad4cc741":"start = time.time()\n\ntrain(epochs=100000, batch_size=32, save_interval=1000)\n\nend = time.time()\nelapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) \/ 60),\n                                                                     int((end - start) % 60))","a91caeb8":"# 1. Load the data","33e1a4a0":"#  4. Build a Generative model","67d1fd40":"# 10. Start training","75b7c42e":"# 5. Build a Discriminative Model","d77688b5":"# 9. Save and show generated images","7589de56":"# 7. Combine Discriminator and Generator model togather","854fd074":"# 3. Define Variables","daf642d3":"# 6. Choose Optimizer","4d6a7041":"# 8. Make a function to train a model","302ac689":"# 2. Visualize the Data"}}