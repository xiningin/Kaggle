{"cell_type":{"5e2d6d8a":"code","83ed2bd8":"code","594b5cb4":"code","2e13a700":"code","b47f5f9f":"code","f3998f24":"code","ff2d7bff":"code","6c7d1fd2":"code","63190f74":"code","482304b0":"code","33821d7c":"code","36f4b51d":"code","13b3faac":"code","73522d67":"code","d75f3396":"code","59fef25f":"code","c79b26c8":"code","b2ad05a0":"code","5340dff7":"code","f85a1f41":"code","3eef1e42":"code","454efe27":"code","2d0fc70c":"code","2f8a1072":"code","48f0f3d6":"code","dc498ca1":"code","48cedb47":"code","ab86f676":"code","38b643fe":"code","44151288":"code","ef63b674":"code","74456fe4":"markdown","2e55f95e":"markdown","bb543d8a":"markdown","25c8422c":"markdown","d0bfded5":"markdown","deb8a6c5":"markdown","1d1452b8":"markdown","2b0aa92c":"markdown","063c641c":"markdown","ed0c4118":"markdown","56caa399":"markdown","9454b995":"markdown","694602dd":"markdown","33d1e8ce":"markdown","2cdd12ec":"markdown","73ee55fd":"markdown","967d2bc4":"markdown","54251f0a":"markdown","4f982945":"markdown","41286c9e":"markdown","678bc445":"markdown","f60ad31d":"markdown","441bd3dd":"markdown","229770b5":"markdown","e1d4db22":"markdown","1ed53b57":"markdown","3df7cc8e":"markdown","e5a649b6":"markdown","300aebf5":"markdown"},"source":{"5e2d6d8a":"# Data Analysis\nimport pandas as pd\nimport numpy as np\n\n# Data Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Machine Learning\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n\n# Statistics\nfrom scipy import stats\nfrom scipy.stats import norm\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","83ed2bd8":"# Loading train data\ntrain_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\nprint(f'Shape of train data: {train_df.shape}')\ntrain_df.head()","594b5cb4":"# Loading test data\ntest_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nprint(f'Shape of test data: {test_df.shape}')\ntest_df.head()","2e13a700":"# Duplicates Check\nduplicate_ids = train_df.Id.duplicated().sum()\nprint(f'Total Duplicate Ids = {duplicate_ids}')","b47f5f9f":"# Using Ids as Indexes\nfor df in [train_df, test_df]:\n    df.set_index('Id', inplace=True)\ntrain_df.head()","f3998f24":"# Data Type Check\ndf = pd.DataFrame({'Column': train_df.columns, 'Dtype': train_df.dtypes.astype('str').tolist(), 'Sample1': train_df.loc[1].tolist(),\n                   'Sample2': train_df.loc[15].tolist(), 'Sample3': train_df.loc[100].tolist()})\nprint(df.to_string())","ff2d7bff":"# Converting 'MSSubClass' and 'MoSold' features to categorical features\nfor df in [train_df, test_df]:\n    df.replace({'MSSubClass': {20: 'SC20', 30: 'SC30', 40: 'SC40', 45: 'SC45', 50: 'SC50', 60: 'SC60', 70: 'SC70', 75: 'SC75',\n                               80: 'SC80', 85: 'SC85', 90: 'SC90', 120: 'SC120', 150: 'SC150', 160: 'SC160', 180: 'SC180', 190: 'SC190'}, \n                'MoSold': {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n                           7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}},\n               inplace=True)\ntrain_df[['MSSubClass', 'MoSold']].head()","6c7d1fd2":"# Missing Values Check\ntemp_train_df = train_df.drop(columns='SalePrice')\ncombined_df = pd.concat([temp_train_df, test_df])\nprint(f'Shape of combined data: {combined_df.shape}')\n\nmissing_values = combined_df.isnull().sum()\nmissing_values[missing_values>0]","63190f74":"# Filling the Missing Values\nMSZoning_series = combined_df.groupby('Neighborhood').MSZoning.agg(lambda x:x.value_counts().index[0])\nLotFrontage_series = combined_df.groupby('Neighborhood').LotFrontage.median()\n\ncombined_df_filled = combined_df.fillna({'Alley': 'None', 'FireplaceQu': 'None', 'PoolQC': 'None', 'Fence': 'None', 'MiscFeature': 'None',\n                                         'BsmtQual': 'None', 'BsmtCond': 'None', 'BsmtExposure': 'None', 'BsmtFinType1': 'None', 'BsmtFinType2': 'None', \n                                         'GarageType': 'None', 'GarageFinish': 'None', 'GarageQual': 'None', 'GarageCond': 'None', 'GarageYrBlt': 'None',\n                                         'BsmtFinSF1': 0, 'BsmtFinSF2':0, 'BsmtUnfSF':0, 'TotalBsmtSF':0, 'BsmtFullBath':0, 'BsmtHalfBath':0, \n                                         'Electrical': 'SBrkr', 'MasVnrType': 'None', 'MasVnrArea': 0, 'Exterior1st':'Other', 'Exterior2nd':'Other',\n                                         'KitchenQual': 'TA', 'Functional': 'Typ', 'SaleType':'Oth', 'GarageCars':0, 'GarageArea':0,\n                                         'MSZoning': combined_df['Neighborhood'].apply(lambda x: MSZoning_series[x]),\n                                         'LotFrontage': combined_df['Neighborhood'].apply(lambda x: LotFrontage_series[x])})\n\n# Dropping the 'Utilities' Column\ncombined_df_filled.drop(columns=['Utilities'], inplace=True)\n\nprint(f'There are {combined_df_filled.isnull().sum().sum()} missing values.')","482304b0":"# Dependent Variable Distribution Check\ntrain_df_filled = combined_df_filled.iloc[:len(train_df)]\ntrain_df_filled = pd.concat([train_df_filled, train_df['SalePrice']], axis=1)\ntest_df_filled = combined_df_filled.iloc[len(train_df):]\n\n# Figure\nplt.figure(figsize=(12, 4))\n\n# Distribution Plot\nplt.subplot(1, 2, 1)\nsns.distplot(train_df_filled['SalePrice'], fit=norm)\nplt.title('Distribution Plot')\n\n# Probability Plot\nplt.subplot(1, 2, 2)\nstats.probplot(train_df_filled['SalePrice'], plot=plt)\n\nplt.tight_layout()\nplt.show()","33821d7c":"# Applying Log-Transform\ntrain_df_filled['SalePrice'] = np.log1p(train_df_filled.SalePrice)\n\n# Figure\nplt.figure(figsize=(12, 4))\n\n# Distribution Plot\nplt.subplot(1, 2, 1)\nsns.distplot(train_df_filled['SalePrice'], fit=norm)\nplt.title('Distribution Plot')\n\n# Probability Plot\nplt.subplot(1, 2, 2)\nstats.probplot(train_df_filled['SalePrice'], plot=plt)\n\nplt.tight_layout()\nplt.show()","36f4b51d":"# Overview of the features based on their data type\nnumerical_features = train_df_filled.select_dtypes(include=np.number).columns\nprint(f'Numerical Features ({len(numerical_features)}):\\n{numerical_features}')\nprint('-'*80)\ncategorical_features = train_df_filled.select_dtypes(include=np.object).columns\nprint(f'Categorical Features ({len(categorical_features)}):\\n{categorical_features}')","13b3faac":"# Dividing features into groups for exploratory data analysis\n\n# Numerical Features' Groups\ngroup1 = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF']\ngroup2 = ['2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ngroup3 = ['GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold']\n\n# Categorical Features' Groups\ngroup4 = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2','BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl']  \ngroup5 = ['Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical']\ngroup6 = ['KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'MoSold', 'SaleType', 'SaleCondition']","73522d67":"# EDA of Group-1\nplt.figure(figsize=(18, 12))\n\ni = 1\nfor col in group1:\n    # Distribution Plot\n    plt.subplot(4, 6, i)\n    sns.distplot(train_df_filled[col])\n    plt.title('Distribution')\n    i += 1\n    \n    # Scatter Plot\n    plt.subplot(4, 6, i)\n    sns.scatterplot(data=train_df_filled, x=col, y='SalePrice', alpha=0.5)\n    plt.title('Relationship')\n    i += 1\n\nplt.tight_layout()\nplt.show()","d75f3396":"# EDA of Group-2\nplt.figure(figsize=(18, 12))\n\ni = 1\nfor col in group2:\n    # Distribution Plot\n    plt.subplot(4, 6, i)\n    sns.distplot(train_df_filled[col])\n    plt.title('Distribution')\n    i += 1\n    \n    # Scatter Plot\n    plt.subplot(4, 6, i)\n    sns.scatterplot(data=train_df_filled, x=col, y='SalePrice', alpha=0.5)\n    plt.title('Relationship')\n    i += 1\n\nplt.tight_layout()\nplt.show()","59fef25f":"# EDA of Group-3\nplt.figure(figsize=(18, 9))\n\ni = 1\nfor col in group3:\n    # Distribution Plot\n    plt.subplot(3, 6, i)\n    sns.distplot(train_df_filled[col])\n    plt.title('Distribution')\n    i += 1\n    \n    # Scatter Plot\n    plt.subplot(3, 6, i)\n    sns.scatterplot(data=train_df_filled, x=col, y='SalePrice', alpha=0.5)\n    plt.title('Relationship')\n    i += 1\n\nplt.tight_layout()\nplt.show()","c79b26c8":"# Removing Outliers\ntrain_df_cleaned = train_df_filled.drop(train_df_filled[(train_df_filled.LotFrontage>200)|\n                                                         (train_df_filled.LotArea>100000)|\n                                                         (train_df_filled.BsmtFinSF1>4000)|\n                                                         (train_df_filled.BsmtFinSF2>1200)|\n                                                         (train_df_filled.TotalBsmtSF>4000)|\n                                                         (train_df_filled['1stFlrSF']>4000)|\n                                                         (train_df_filled.GrLivArea>4000)|\n                                                         (train_df_filled.KitchenAbvGr==0)|\n                                                         (train_df_filled.GarageArea>1300)|\n                                                         ((train_df_filled.GarageArea>1000) & (train_df_filled.SalePrice<11.5))|\n                                                         (train_df_filled.WoodDeckSF>800)|\n                                                         (train_df_filled.OpenPorchSF>500)|\n                                                         (train_df_filled.EnclosedPorch>400)|\n                                                         (train_df_filled.MiscVal>3000)].index)\n\nprint(f'Reduction in train data is {np.round(100*(len(train_df_filled)-len(train_df_cleaned))\/len(train_df_filled), 2)}%')","b2ad05a0":"# Feature Engineering: Numerical Features\ntrain_df_fe1 = train_df_cleaned.copy()\ntest_df_fe1 = test_df_filled.copy()\n\nfor df in [train_df_fe1, test_df_fe1]:\n    # Updating Existing Features\n    df['BsmtFullBath'] = df['BsmtFullBath'].apply(lambda x: x if x==0 else 1)\n    df['BsmtHalfBath'] = df['BsmtHalfBath'].apply(lambda x: x if x==0 else 1)\n    df['HalfBath'] = df['HalfBath'].apply(lambda x: x if x==0 else 1)\n    df['BedroomAbvGr'] = df['BedroomAbvGr'].apply(lambda x: x if x<5 else 5)\n    df['KitchenAbvGr'] = df['KitchenAbvGr'].apply(lambda x: x if x<2 else 2)\n    df['Fireplaces'] = df['Fireplaces'].apply(lambda x: x if x<2 else 2)\n    df['GarageCars'] = df['GarageCars'].apply(lambda x: x if x<3 else 3)\n\n    # Creating New Features\n    df['Has_LowQualFinSF'] = df['LowQualFinSF'].apply(lambda x: x if x==0 else 1)\n    df['Has_3SsnPorch'] = df['3SsnPorch'].apply(lambda x: x if x==0 else 1)\n    df['Has_Pool'] = df['PoolArea'].apply(lambda x: x if x==0 else 1)\n\ntrain_df_fe1.shape","5340dff7":"# Skewness Check\nskewness = train_df_fe1.select_dtypes(exclude='object').skew()\nskewed_features = skewness[skewness>0.5]\nskewed_features","f85a1f41":"# Applying log transformation to the continuous variables that are skewed\nfeat_to_transform = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF',\n                     'TotalBsmtSF', '1stFlrSF', '2ndFlrSF','LowQualFinSF', 'GrLivArea', 'WoodDeckSF',\n                     'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n\ntrain_df_tfm = train_df_fe1.copy()\ntest_df_tfm = test_df_fe1.copy()\n\nfor df in [train_df_tfm, test_df_tfm]:\n    for col in feat_to_transform:\n        df[col] = np.log1p(df[col])\n\n# Plotting the before-after distribution of the transformed features\nplt.figure(figsize=(17, 15))\n\ni=1\nfor col in feat_to_transform:\n    # Before Transformation\n    plt.subplot(6, 6, i)\n    sns.distplot(train_df_fe1[col])\n    plt.title('Before')\n    i+=1\n    \n    # After Transformation\n    plt.subplot(6, 6, i)\n    sns.distplot(train_df_tfm[col])\n    plt.title('After')\n    i += 1\n\nplt.tight_layout()\nplt.show()","3eef1e42":"# EDA of Group-4\nplt.figure(figsize=(18, 16))\n\ni = 1\nfor col in group4:\n    # Count Plot\n    plt.subplot(5, 6, i)\n    sns.countplot(train_df_tfm[col])\n    plt.xticks(rotation=90)\n    plt.title('Distribution')\n    i += 1\n    \n    # Strip Plot\n    plt.subplot(5, 6, i)\n    sns.stripplot(data=train_df_tfm, x=col, y='SalePrice', alpha=0.5)\n    plt.xticks(rotation=90)\n    plt.title('Relationship')\n    i += 1\n\nplt.tight_layout()\nplt.show()","454efe27":"# EDA of Group-5\nplt.figure(figsize=(18, 16))\n\ni = 1\nfor col in group5:\n    # Count Plot\n    plt.subplot(5, 6, i)\n    sns.countplot(train_df_tfm[col])\n    plt.xticks(rotation=90)\n    plt.title('Distribution')\n    i += 1\n    \n    # Strip Plot\n    plt.subplot(5, 6, i)\n    sns.stripplot(data=train_df_tfm, x=col, y='SalePrice', alpha=0.5)\n    plt.xticks(rotation=90)\n    plt.title('Relationship')\n    i += 1\n\nplt.tight_layout()\nplt.show()","2d0fc70c":"# EDA of Group-6\nplt.figure(figsize=(18, 16))\n\ni = 1\nfor col in group6:\n    # Count Plot\n    plt.subplot(5, 6, i)\n    sns.countplot(train_df_tfm[col])\n    if col=='GarageYrBlt':\n        temp_lst = train_df_tfm.GarageYrBlt.unique()\n        ticks = range(1, len(temp_lst), 10)\n        labels = [temp_lst[i] for i in ticks]\n        plt.xticks(ticks=ticks, labels=labels, rotation=90)\n    else:\n        plt.xticks(rotation=90)\n    plt.title('Distribution')\n    i += 1\n    \n    # Strip Plot\n    plt.subplot(5, 6, i)\n    sns.stripplot(data=train_df_tfm, x=col, y='SalePrice', alpha=0.5)\n    if col=='GarageYrBlt':\n        plt.xticks(ticks=ticks, labels=labels, rotation=90)\n    else:\n        plt.xticks(rotation=90)\n    plt.title('Relationship')\n    i += 1\n\nplt.tight_layout()\nplt.show()","2f8a1072":"# Feature Engineering: Categorical Features\ntrain_df_fe2 = train_df_tfm.copy()\ntest_df_fe2 = test_df_tfm.copy()\n\nfor df in [train_df_fe2, test_df_fe2]:\n    # Updating Existing Features\n    df['MSSubClass'] = df['MSSubClass'].apply(lambda x: x if x in ['SC20', 'SC50', 'SC60'] else 'Other')\n    df['MSZoning'] = df['MSZoning'].apply(lambda x: 1 if x=='RL' else 0)\n    df['LandContour'] = df['LandContour'].apply(lambda x: 1 if x=='Lvl' else 0)\n    df['LotConfig'] = df['LotConfig'].apply(lambda x: 1 if x=='Inside' else 0)\n    df['Neighborhood'] = df['Neighborhood'].apply(lambda x: x if x in ['NAmes', 'CollgCr', 'OldTown', 'Edwards', 'Somerst', \n                                                                       'Gilbert', 'NridgHt', 'Sawyer', 'NWAmes'] else 'Other')\n    df['Condition1'] = df['Condition1'].apply(lambda x: 1 if x=='Norm' else 0)\n    df['Condition2'] = df['Condition2'].apply(lambda x: 1 if x=='Norm' else 0)\n    df['BldgType'] = df['BldgType'].apply(lambda x: 1 if x=='1Fam' else 0)\n    df['HouseStyle'] = df['HouseStyle'].apply(lambda x: x if x in ['1Story', '2Story'] else 'Other')\n    df['RoofStyle'] = df['RoofStyle'].apply(lambda x: 1 if x=='Gable' else 0)\n    df['RoofMatl'] = df['RoofMatl'].apply(lambda x: 1 if x=='CompShg' else 0)\n    df['Exterior1st'] = df['Exterior1st'].apply(lambda x: x if x in ['VinylSd', 'HdBoard', 'MetalSd', 'Wd Sdng', 'Plywood'] else 'Other')\n    df['Exterior2nd'] = df['Exterior2nd'].apply(lambda x: x if x in ['VinylSd', 'HdBoard', 'MetalSd', 'Wd Sdng', 'Plywood'] else 'Other')\n    df['MasVnrType'] = df['MasVnrType'].apply(lambda x: x if x in ['None', 'BrkFace'] else 'Other')\n    df['Foundation'] = df['Foundation'].apply(lambda x: x if x in ['PConc', 'CBlock'] else 'Other')\n    df['Heating'] = df['Heating'].apply(lambda x: 1 if x=='GasA' else 0)\n    df['Electrical'] = df['Electrical'].apply(lambda x: 1 if x=='SBrkr' else 0)\n    df['GarageType'] = df['GarageType'].apply(lambda x: x if x in ['Attchd', 'Detchd', 'None'] else 'Other')\n    df['MiscFeature'] = df['MiscFeature'].apply(lambda x: 0 if x=='None' else 1)\n    df['SaleType'] = df['SaleType'].apply(lambda x: 1 if x=='WD' else 0)\n    df['SaleCondition'] = df['SaleCondition'].apply(lambda x: 1 if x=='Normal' else 0)\n\ntrain_df_fe2.shape","48f0f3d6":"# Label Encoding\ntrain_df_encoded1 = train_df_fe2.copy()\ntest_df_encoded1 = test_df_fe2.copy()\n\nfor df in [train_df_encoded1, test_df_encoded1]:\n    df.replace({'Street': {'Grvl':0, 'Pave':1},\n                'Alley': {'None':0, 'Grvl':1, 'Pave':2},\n                'LotShape': {'Reg':0, 'IR1':1, 'IR2':2, 'IR3':3},\n                'LandSlope': {'Gtl':0, 'Mod':1, 'Sev':2},\n                'ExterQual': {'Po':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4},\n                'ExterCond': {'Po':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4},\n                'BsmtQual': {'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n                'BsmtCond': {'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n                'BsmtExposure': {'None':0, 'No':1, 'Mn':2, 'Av':3, 'Gd':4},\n                'BsmtFinType1': {'None':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6},\n                'BsmtFinType2': {'None':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6},\n                'HeatingQC': {'Po':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4},\n                'CentralAir': {'N':0, 'Y':1},\n                'KitchenQual': {'Po':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4},\n                'Functional': {'Sal':0, 'Sev':1, 'Maj2':2, 'Maj1':3, 'Mod':4, 'Min2':5, 'Min1':6, 'Typ':7},\n                'FireplaceQu': {'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n                'GarageFinish': {'None':0, 'Unf':1, 'RFn':2, 'Fin':3},\n                'GarageQual': {'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n                'GarageCond': {'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n                'PavedDrive': {'N':0, 'P':1, 'Y':2},\n                'PoolQC': {'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n                'Fence': {'None':0, 'MnWw':1, 'GdWo':2, 'MnPrv':3, 'GdPrv':4}}, inplace=True)","dc498ca1":"# Feature Engineering: Combining Multiple Features\ntrain_df_fe = train_df_encoded1.copy()\ntest_df_fe = test_df_encoded1.copy()\n\nfor df in [train_df_fe, test_df_fe]:\n    # Age of the house when sold\n    df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n    # Years passed after remodeling of the house when sold\n    df['HouseRemodAge'] = df['YrSold'] - df['YearRemodAdd']\n    # Age of garage when house was sold\n    df['GarageAge'] = df[['YrSold', 'GarageYrBlt']].apply(lambda row: 0 if row[1]=='None' else (row[0]-int(row[1])), axis=1)\n\n    # Overall rating\n    df['OverallRating'] = df['OverallQual']*df['OverallCond']\n    # Exterior rating\n    df['ExteriorRating'] = df['ExterQual']*df['ExterCond']\n    # Basement rating\n    df['BsmtRating'] = df['BsmtQual']*df['BsmtCond']\n    # Total basement finish area\n    df['BsmtFinSF'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n    # Basement finish type 1 score\n    df['BsmtFinScore1'] = df['BsmtFinSF1']*df['BsmtFinType1']\n    # Basement finish type 2 score\n    df['BsmtFinScore2'] = df['BsmtFinSF2']*df['BsmtFinType2']\n    # Total basement finish score\n    df['BsmtFinScore'] = df['BsmtFinScore1'] + df['BsmtFinScore2']\n    # Kitchen score\n    df['KitchenScore'] = df['KitchenAbvGr']*df['KitchenQual']\n    # Fireplace score\n    df['FireplaceScore'] = df['Fireplaces']*df['FireplaceQu']\n    # Garage rating\n    df['GarageRating'] = df['GarageQual']*df['GarageCond']\n    # Garage score\n    df['GarageScore'] = df['GarageArea']*df['GarageRating']\n    # Pool score\n    df['PoolScore'] = df['PoolArea']*df['PoolQC']\n\n    # Total living area\n    df['TotalLivArea'] = df['GrLivArea'] + df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'] \n    # Total porch area\n    df['TotalPorchArea'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n    # Total outside area\n    df['TotalOutArea'] = df['TotalPorchArea'] + df['WoodDeckSF'] + df['PoolArea'] + df['GarageArea']\n    # Total house area\n    df['TotalHouseArea'] = df['TotalOutArea'] + df['TotalLivArea']\n\n    # Whether house has masonry veneer\n    df['Has_MasVnr'] = df['MasVnrType'].apply(lambda x: 0 if x=='None' else 1)\n    # Whether house's basement is finished\n    df['Is_BsmtFin'] = df[['BsmtFinType1', 'BsmtFinType1']].apply(lambda row: 0 if (row[0]==1 and row[1]==1) else 1, axis=1)\n    # Whether house has a basement\n    df['Has_Bsmt'] = df['BsmtFinType1'].apply(lambda x: 0 if x==0 else 1)\n    # Whether house has a fireplace\n    df['Has_Fireplace'] = df['Fireplaces'].apply(lambda x: 0 if x==0 else 1)\n    # Whether house has a garage\n    df['Has_Garage'] = df['GarageType'].apply(lambda x: 0 if x=='None' else 1)\n    # Whether house has porch\n    df['Has_Porch'] = df['TotalPorchArea'].apply(lambda x: 0 if x==0 else 1)\n    # Whether house has a wood deck\n    df['Has_WoodDeck'] = df['WoodDeckSF'].apply(lambda x: 0 if x==0 else 1)\n    # Whether house has a fence\n    df['Has_Fence'] = df['Fence'].apply(lambda x: 0 if x==0 else 1)\n\n    # Garage average area per car\n    df['GarageArPCr'] = df[['GarageArea', 'GarageCars']].apply(lambda row: 0 if (row[0]==0 or row[1]==0) else (row[0]\/row[1]), axis=1)\n\ntrain_df_fe.shape","48cedb47":"# Feature Selection: Dropping Irrelevant Features\ntrain_df_fs = train_df_fe.copy()\ntest_df_fs = test_df_fe.copy()\n\nfor df in [train_df_fs, test_df_fs]:\n    df.drop(columns=['GarageYrBlt', 'MoSold', 'MSSubClass', 'Exterior2nd', 'MasVnrType', 'Foundation'], inplace=True)\n\n# One-Hot Encoding\ntrain_df_encoded2 = pd.get_dummies(train_df_fs, drop_first=True)\ntest_df_encoded2 = pd.get_dummies(test_df_fs, drop_first=True)\n\n# Preparing train-test arrays \nx_train = train_df_encoded2.drop(columns='SalePrice').values\ny_train = train_df_encoded2['SalePrice'].values\nx_test = test_df_encoded2.values\nprint(f'Shape: x_train{x_train.shape} x_test{x_test.shape} y_train{y_train.shape}')","ab86f676":"# Multiple Linear Regression\nmlr = LinearRegression()\ncv = KFold(n_splits=10, random_state=1, shuffle=True)\nscores = np.sqrt(-cross_val_score(mlr, x_train, y_train, cv=cv, scoring='neg_mean_squared_error'))\nprint(f'Multiple Linear Regression: RMSE={round(np.mean(scores), 4)}')","38b643fe":"# Ridge Regression (L2 Regularization)\nalphas = np.arange(1, 10, 1)\nridge = RidgeCV(alphas, normalize=True)\nridge.fit(x_train, y_train)\nbest_alpha = ridge.alpha_\n\niterations = 5\nfor i in range(iterations):\n    alphas = [best_alpha*x for x in np.arange(0.1, 2, 0.1)]\n    ridge = RidgeCV(alphas, normalize=True)\n    ridge.fit(x_train, y_train)\n    best_alpha = ridge.alpha_\n\nscores = np.sqrt(-cross_val_score(ridge, x_train, y_train, cv=cv, scoring='neg_mean_squared_error'))\nprint(f'Ridge Regression: Best Alpha={round(best_alpha, 4)} RMSE={round(np.mean(scores), 4)}')","44151288":"# Lasso Regression (L1 Regularization)\nlasso = LassoCV(alphas=None, max_iter=100000, normalize=True)\nlasso.fit(x_train, y_train)\nbest_alpha = lasso.alpha_\nscores = np.sqrt(-cross_val_score(lasso, x_train, y_train, cv=cv, scoring='neg_mean_squared_error'))\nprint(f'Lasso Regression: Best Alpha={round(best_alpha, 4)} RMSE={round(np.mean(scores), 4)}')","ef63b674":"# Predicting SalePrice of the test data using Lasso Regression\nlasso.fit(x_train, y_train)\ny_pred_log1p = lasso.predict(x_test)\ny_pred = np.expm1(y_pred_log1p)\n\n# Submitting Prediction\nsubmission = pd.DataFrame({'Id': test_df_encoded2.index, 'SalePrice': y_pred})\nsubmission.to_csv('submission.csv', index=False)\nprint('Submission is successful.')","74456fe4":"* The data type of each feature is appropriate.\n* We can observe from the data description that 'MSSubClass' and 'MoSold' columns are represented by numbers when they are neither numerical nor ordinal features. Therefore, let us first convert these features to categorical features.","2e55f95e":"## Dependent Variable Distribution","bb543d8a":"## Skewness","25c8422c":"## EDA: Numerical Features","d0bfded5":"# Data Loading","deb8a6c5":"## Missing Values","1d1452b8":"# Data Preprocessing\nSince categorical features can create redundant columns after one-hot encoding, they are inspected to understand their impact on SalePrice prediction. The following 6 out of 10 categorical features were identified as irrelevant based on intuition, EDA, and results of iterative prediction of SalePrice: GarageYrBlt, MoSold, MSSubClass, Exterior2nd, MasVnrType, and Foundation.","2b0aa92c":"## Feature Engineering: Numerical Features","063c641c":"## Feature Engineering: Categorical Features","ed0c4118":"## Ridge Regression (L2 Regularization)","56caa399":"# ML Modeling\n## Multiple Linear Regression","9454b995":"# Prediction","694602dd":"## EDA: Categorical Features","33d1e8ce":"## Outliers","2cdd12ec":"* **Feature Engineering**:\n    * Exterior1st: 'VinylSd', 'HdBoard', 'MetalSd', 'Wd Sdng', 'Plywood', and 'Other'\n    * Exterior2nd: 'VinylSd', 'HdBoard', 'MetalSd', 'Wd Sdng', 'Plywood', and 'Other'\n    * MasVnrType: 'None', 'BrkFace', and 'Other'\n    * Foundation: 'PConc', 'CBlock', and 'Other\n    * Heating: GasA(1) or Not(0)\n    * Electrical: SBrkr(1) or Not(0)","73ee55fd":"## Feature Engineering: Combining Multiple Features\nDuring feature engineering of numerical and categorical features above, we modified individual features to better predict our SalePrice. In this section, we will create new features by combining multiple existing features.","967d2bc4":"* **Outliers**:\n    * GarageArea>1300 and (GarageArea>1000 and SalePrice<11.5)\n    * WoodDeckSF>800\n    * OpenPorchSF>500\n    * EnclosedPorch>400\n    * MiscVal>3000\n* **Feature Engineering**:\n    * Has_3SsnPorch: Yes or No\n    * Has_Pool: Yes or No","54251f0a":"## Lasso Regression (L1 Regularization)","4f982945":"# Importing Necessary Libraries","41286c9e":"Thank you so much for your time. I hope it was worth it.\nIf you like my work, kindly consider upvoting. It means a lot.\nBeing a beginner, I genuinely encourage you to share any views or suggestions you might have on my work.\n\nThis was my second kaggle project. Do checkout my first notebook as well. https:\/\/www.kaggle.com\/pradneshlachake\/my-first-kaggle-project-titanic-disaster\n\nI highly recommend you to check out the following kernel. It helped me a lot in my work.\nhttps:\/\/www.kaggle.com\/juliencs\/a-study-on-regression-applied-to-the-ames-dataset","678bc445":"* **Outliers**:\n    * GrLivArea>4000\n    * KitchenAbvGr=0\n* **Feature Engineering**:\n    * Has_LowQualFinSF: Yes or No\n    * BsmtFullBath: Yes or No\n    * BsmtHalfBath: Yes or No\n    * HalfBath: Yes or No\n    * BedroomAbvGr: 5 or above = 5\n    * KitchenAbvGr: 2 or above = 2\n    * Fireplaces: 2 or above = 2\n    * GarageCars: 3 or above = 3","f60ad31d":"* **Outliers**:\n    * LotFrontage>200\n    * LotArea>100000\n    * BsmtFinSF1>4000\n    * BsmtFinSF2>1200\n    * TotalBsmtSF>4000\n    * 1stFlrSF>4000","441bd3dd":"# Data Cleaning and Feature Engineering","229770b5":"* **Feature Engineering**:\n    * MSSubClass: 'SC20', 'SC50', 'SC60', and 'Other' (Combining not so frequent categories into 'Other' category)\n    * MSZoning: RL(1) or Not(0)\n    * LandContour: Lvl(1) or Not(0)\n    * LotConfig: Inside(1) or Not(0)\n    * Neighborhood: 'NAmes', 'CollgCr', 'OldTown', 'Edwards', 'Somerst', 'Gilbert', 'NridgHt', 'Sawyer', 'NWAmes', and 'Other'\n    * Condition1: Norm(1) or Not(0)\n    * Condition2: Norm(1) or Not(0)\n    * BldgType: 1Fam(1) or Not(0)\n    * HouseStyle: '1Story', '2Story', and 'Other'\n    * RoofStyle: Gable(1) or Not(0)\n    * RoofMatl: CompShg(1) or Not(0)","e1d4db22":"* **Feature Engineering**:\n    * GarageType: 'Attchd', 'Detchd', 'None', and 'Other'\n    * MiscFeature: Available(1) or Not(0)\n    * SaleType: WD(1) or Not(0)\n    * SaleCondition: Normal(1) or Not(0)","1ed53b57":"## Label Encoding","3df7cc8e":"* Pandas data frame interpreted 'NA' as a missing value which is not the case for few features. The meaning of 'NA' as per the data description for some features are given below:\n    * Alley: No alley access\n    * BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2: No Basement\n    * FireplaceQu: No Fireplace\n    * GarageType, GarageFinish, GarageQual, GarageCond, GarageYrBlt: No Garage\n    * PoolQC: No Pool\n    * Fence: No Fence\n    * MiscFeature: No Miscellaneous Features\n    Let us fill 'None' in the above columns to represent an absence of the respective facility.\n* For unknown information on basement, columns 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', and 'BsmtHalfBath' will have 0 value.\n* For unknown information on the garage, columns 'GarageCars' and 'GarageArea' will have 0 value.\n* As 'SBrkr' is the most frequent category in the 'Electrical' column, it fills the missing values.\n* As 'TA' is the most frequent category in the 'KitchenQual' column, it fills the missing values.\n* By following the data description, we will fill the missing values as given below for their respective columns:\n    * 'MasVnrType': 'None'\n    * 'MasVnrArea': 0\n    * 'Exterior1st', 'Exterior2nd': 'Other'\n    * 'Functional': 'Typ'\n    * 'SaleType': 'Oth'\n* Neighbors are more likely to have the same zone and approximately the same linear feet of street-connected to the property. Therefore, we will go with the most frequent 'MSZoning' of the property's neighborhood and the median 'LotFrontage' of the property's neighborhood to fill the missing values.\n* 'Utilities' column has 2916 entries of 'AllPub' out of a total of 2919 entries. So, we will drop this column since it is not adding any value to our prediction.","e5a649b6":"As the SalePrice data is skewed, we will apply log transformation so that errors in predicting expensive houses and cheap houses will affect the result equally.","300aebf5":"Lasso regression can be seen to perform better than multiple linear regression and ridge regression. Lasso regression turns out to have 0 as the best alpha value, which signifies that there is no bias imposed, and results are improved solely because of lasso's feature selection ability."}}