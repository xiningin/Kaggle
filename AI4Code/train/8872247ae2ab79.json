{"cell_type":{"a2571267":"code","d926d5f5":"code","54dcd8c2":"code","0ed3e2aa":"code","27fb74a0":"code","cf8fa942":"code","9cd87afd":"code","2ab40605":"code","01564c51":"code","04dc8558":"code","0edc723c":"code","adf2416a":"code","17f1418a":"code","bb094cb2":"code","be723056":"code","addf5e42":"code","47d49155":"code","79e05424":"code","ebc9123f":"code","2de33b93":"code","73eaad51":"code","75092a51":"code","1bd1366a":"code","4f58ab8a":"code","cb88aa1e":"code","b45d133f":"code","39f648e8":"code","ce89bb0f":"code","e96be01f":"code","8eb3571d":"code","d920b4c7":"code","53fb32ce":"code","af30f17a":"code","4a73b362":"code","1cae1d06":"code","83e1fc78":"code","9fe22dca":"code","a0cd6c25":"code","e7c1b449":"code","99e63b0f":"code","00ee8cec":"code","46dbdba7":"code","1c8740d0":"code","07fde78c":"code","30994a38":"code","e0ae8e27":"code","ab7ebfb2":"code","65f67098":"code","f28838a6":"code","4575c25a":"code","6b4cc774":"code","051abb63":"code","77ba9bb5":"code","700454ca":"code","fa45b648":"code","f85e67d4":"code","bea737df":"markdown","7eac0491":"markdown","658ab10c":"markdown","f198bb36":"markdown","5855f243":"markdown","21af44c7":"markdown","d85ea3b9":"markdown","58e1c13e":"markdown","54b77b2f":"markdown","964048f9":"markdown","50d8703d":"markdown","3983aafd":"markdown","c291b57d":"markdown","e98feb5e":"markdown","d9e500f6":"markdown","17aed0db":"markdown","09657dd3":"markdown","2d323705":"markdown","3b5c5528":"markdown","1a5ce7e4":"markdown","c6575c06":"markdown","7c3eaf96":"markdown","016c7689":"markdown","fcb42e96":"markdown","e5b2f9d7":"markdown","9fc5c07d":"markdown"},"source":{"a2571267":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"..\/input\"))","d926d5f5":"vehicles_df = pd.read_csv('..\/input\/craigslistVehicles.csv')","54dcd8c2":"vehicles_df.info()","0ed3e2aa":"vehicles_df.head()","27fb74a0":"vehicles_df = vehicles_df.drop(columns=['city_url', 'image_url', 'lat', 'long'])","cf8fa942":"vehicles_df.shape","9cd87afd":"vehicles_df.drop_duplicates(subset='url')\nvehicles_df.shape","2ab40605":"vehicles_df.isnull().sum(axis=1).quantile(.95)","01564c51":"vehicles_df = vehicles_df[vehicles_df.isnull().sum(axis=1) < 9]\nvehicles_df.shape","04dc8558":"vehicles_df = vehicles_df[vehicles_df.price != 0]\nvehicles_df.shape","0edc723c":"plt.figure(figsize=(3,6))\nsns.boxplot(y='price', data=vehicles_df);","adf2416a":"vehicles_df = vehicles_df[vehicles_df.price < 100000]\nvehicles_df.shape","17f1418a":"plt.figure(figsize=(15,9))\nax = sns.countplot(x='year',data=vehicles_df);\nax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\",fontsize=10);","bb094cb2":"vehicles_df = vehicles_df[vehicles_df.year > 1985]\nvehicles_df.shape","be723056":"vehicles_df.odometer.quantile(.999)","addf5e42":"vehicles_df = vehicles_df[~(vehicles_df.odometer > 500000)]\nvehicles_df.shape","47d49155":"plt.figure(figsize=(3,6))\nsns.boxplot(y='odometer', data=vehicles_df);","79e05424":"vehicles_df.shape","ebc9123f":"sns.set(style=\"ticks\", color_codes=True)\nsns.pairplot(vehicles_df, hue=\"condition\");","2de33b93":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import train_test_split as split\nimport warnings\nfrom sys import modules","73eaad51":"vehicles_df_to_learn = vehicles_df[['odometer','year','price']]","75092a51":"vehicles_df_to_learn = vehicles_df_to_learn.dropna()\nvehicles_df_to_learn.shape","1bd1366a":"vehicles_df_train, vehicles_df_test = split(vehicles_df_to_learn, train_size=0.6, random_state=4222)","4f58ab8a":"X_train = vehicles_df_train[['odometer','year']]\ny_train = vehicles_df_train['price']","cb88aa1e":"cars_lm = LinearRegression(fit_intercept=True)","b45d133f":"cars_lm.fit(X_train, y_train)","39f648e8":"print(\"The model intercept is: {}\".format(cars_lm.intercept_))\nprint(\"The model coefficients are: {}\".format(cars_lm.coef_[0]))","ce89bb0f":"X_train['Price_prediction'] = cars_lm.predict(X_train)\nX_train.head()","e96be01f":"cars_train_rmse = np.sqrt(MSE(y_train, X_train['Price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_train_rmse))","8eb3571d":"cars_lm_test = LinearRegression()","d920b4c7":"X_test = vehicles_df_test[['odometer','year']]\ny_test = vehicles_df_test['price']","53fb32ce":"cars_lm_test.fit(X_test, y_test)","af30f17a":"X_test['price_prediction'] = cars_lm_test.predict(X_test)\nX_test.head()","4a73b362":"cars_test_rmse = np.sqrt(MSE(y_test, X_test['price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_test_rmse))","1cae1d06":"vehicles_df_to_learn2 = vehicles_df[['odometer','year','price', 'transmission', 'title_status', 'condition']]","83e1fc78":"vehicles_df_to_learn2.info()","9fe22dca":"vehicles_df_to_learn2 = vehicles_df[['odometer','year','price', 'transmission', 'title_status']]\nvehicles_df_to_learn2 = vehicles_df_to_learn2.dropna()\nvehicles_df_to_learn2.shape","a0cd6c25":"vehicles_df_to_learn2.head()","e7c1b449":"vehicles_df_to_learn2['transmission_automatic'] = vehicles_df_to_learn2['transmission'].apply(lambda x: 1 if x == 'automatic' else 0)\nvehicles_df_to_learn2['transmission_manual'] = vehicles_df_to_learn2['transmission'].apply(lambda x: 1 if x == 'manual' else 0)\nvehicles_df_to_learn2['transmission_other'] = vehicles_df_to_learn2['transmission'].apply(lambda x: 1 if x == 'other' else 0)","99e63b0f":"vehicles_df_to_learn2 = vehicles_df_to_learn2.reset_index()\nvehicles_df_to_learn2.head()","00ee8cec":"dum = pd.get_dummies(vehicles_df_to_learn2['title_status']).reset_index()","46dbdba7":"dum.head()","1c8740d0":"vehicles_df_to_learn2 = pd.merge(vehicles_df_to_learn2, dum, on='index')\nvehicles_df_to_learn2 = vehicles_df_to_learn2.drop(columns=['index', 'transmission', 'title_status'])","07fde78c":"vehicles_df_to_learn2.head()","30994a38":"vehicles_df_train2, vehicles_df_test2 = split(vehicles_df_to_learn2, train_size=0.6, random_state=4222)\nX_train2 = vehicles_df_train2[['odometer','year', 'transmission_automatic', 'transmission_manual', 'transmission_other', 'clean', 'lien', 'missing', 'parts only', 'rebuilt', 'salvage']]\ny_train2 = vehicles_df_train2['price']\ncars_lm2 = LinearRegression(fit_intercept=True)\ncars_lm2.fit(X_train2, y_train2)","e0ae8e27":"print(\"The model intercept is: {}\".format(cars_lm2.intercept_))\nprint(\"The model coefficients are: {}\".format(cars_lm2.coef_[0]))\nX_train2['Price_prediction'] = cars_lm2.predict(X_train2)\ncars_train_rmse2 = np.sqrt(MSE(y_train2, X_train2['Price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_train_rmse2))","ab7ebfb2":"cars_lm_test2 = LinearRegression()\nX_test2 = vehicles_df_test2[['odometer','year', 'transmission_automatic', 'transmission_manual', 'transmission_other', 'clean', 'lien', 'missing', 'parts only', 'rebuilt', 'salvage']]\ny_test2 = vehicles_df_test2['price']\ncars_lm_test2.fit(X_test2, y_test2)\nX_test2['price_prediction'] = cars_lm_test2.predict(X_test2)\nX_test2.head()\ncars_test_rmse2 = np.sqrt(MSE(y_test2, X_test2['price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_test_rmse2))","65f67098":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn import neighbors\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error ","f28838a6":"vehicles_df_knn_train, vehicles_df_knn_test = split(vehicles_df_to_learn, train_size=0.6, random_state=4222)\nX_first = vehicles_df_knn_train.drop('price', axis=1)\ny_first = vehicles_df_knn_train['price']\n\nX_second = vehicles_df_knn_test.drop('price', axis=1)\ny_second = vehicles_df_knn_test['price']","4575c25a":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nX_first_scaled = scaler.fit_transform(X_first)\nX_first = pd.DataFrame(X_first_scaled)\n\nX_second_scaled = scaler.fit_transform(X_second)\nX_second = pd.DataFrame(X_second_scaled)","6b4cc774":"rmse_val2 = [] #to store rmse values for different k\nfor K in range(20):\n    K += 1\n    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n\n    model.fit(X_first, y_first)  #fit the model\n    pred=model.predict(X_second) #make prediction on test set\n    error = sqrt(mean_squared_error(y_second, pred)) #calculate rmse\n    rmse_val2.append(error) #store rmse values\n    print('RMSE value for k= ' , K , 'is:', error)","051abb63":"#plotting the rmse values against k values\ncurve = pd.DataFrame(rmse_val2) #elbow curve \ncurve.plot()","77ba9bb5":"vehicles_df_to_learn2.head()","700454ca":"vehicles_df_knn_train2, vehicles_df_knn_test2 = split(vehicles_df_to_learn2, train_size=0.6, random_state=4222)\nX_first2 = vehicles_df_knn_train2.drop('price', axis=1)\ny_first2 = vehicles_df_knn_train2['price']\n\nX_second2 = vehicles_df_knn_test2.drop('price', axis=1)\ny_second2 = vehicles_df_knn_test2['price']","fa45b648":"scaler = MinMaxScaler(feature_range=(0, 1))\n\nX_first_scaled2 = scaler.fit_transform(X_first2)\nX_first2 = pd.DataFrame(X_first_scaled2)\n\nX_second_scaled2 = scaler.fit_transform(X_second2)\nX_second2 = pd.DataFrame(X_second_scaled2)","f85e67d4":"rmse_val3 = [] \nK = 2\nfor i in range(5):\n    K += 1\n    model2 = neighbors.KNeighborsRegressor(n_neighbors = K)\n    model2.fit(X_first2, y_first2)  \n    pred2=model2.predict(X_second2) \n    error2 = sqrt(mean_squared_error(y_second2, pred2)) \n    rmse_val3.append(error2) \n    print('RMSE value for k= ' , K , 'is:', error2)","bea737df":" Let us have a look at the error rate for different k values","7eac0491":"# 9 missing values per row or more are being dropped (~9300 rows dropped)","658ab10c":"# we can  see K neighbours 4-7 being the best predictor in terms of error\nThe rmse is also significantly lower than the simple linear regression","f198bb36":"we can see that the condition has 200000 nans and therefor we will not include this parameter atm","5855f243":"# Now we can start working on the columns that could[](http:\/\/) predict price - \n(final shape after cleaning - 474166, 18)","21af44c7":"only ~ 0.1% less mistake than previously\nlets do the same actions on the test data set","d85ea3b9":"# Lets drop duplicates, massive Nans and illogic pricings","58e1c13e":"Lets try and run the same model on additional categorical parameters:","54b77b2f":"Here is the second \"Pythonic\" way:","964048f9":"# Looking at the relevant years -","50d8703d":"Continuing with the simplicity - adding categorical parameters and lets see if the prediction improves:\n\ncondition\n\ntitle_status\n\ntransmission","3983aafd":"create train and test sets:","c291b57d":"# **Lets drop all useless columns at this stage (images, links etc)**","e98feb5e":"Preprocessing \u2013 Scaling the features","d9e500f6":"# The end for now.. Next steps would be adding more features and checking RMSE. Also run additional regression models to create a better prediction.","17aed0db":"Here is the first way to set dummies for categorical value:","09657dd3":"# Now we drop all prices that are equal to 0 (approximately 45k cars!) \n\n# +\n\n# all crazy high irrelevant prices of cars - above 100k (~460 prices) - some of those are just wrong due to an addition of 0 in comparison to the description","2d323705":"# We decide to keep only cars with year above the year of 1985 (~18k)","3b5c5528":"for now we will have to drop rows with odometer as Nan (just for simplicity)","1a5ce7e4":"# Odometer \/ Milage  (\"A typical mileage before overhaul for trucks is around 700K - 1000K miles\") - dropping all mileage above 1000k Miles - usually due to wrong adding 0 to the final result (~1150 cars).","c6575c06":"Continuing with the simplicity - applying a quick KNN regression:","7c3eaf96":"We still see K neihbours 4-6 being the best predictors, however adding the features actually created a larger mistake","016c7689":"# Start with a simple Linear Regression\nusing only numeric features","fcb42e96":"Finding average amount of Nans and dropping rows with more Nans than 95% quntile (9 missing values and more are dropped)","e5b2f9d7":"# In this Kernel I will conduct a rather simplified EDA and predict pricing results using several simple regression\nModels that will be used will be models such as - KNN, linear regression & simple tree regression\n\nChangelist commits - \n1. First EDA & data cleaning - commit\n2. Starting to work and predicting the price using a simple regression - commit\n3. Adding categorical features - commit\n4. Adding a KNN regression - commit","9fc5c07d":"A bit worth actually than the original test on the numerical datasets"}}