{"cell_type":{"c7868718":"code","bce80126":"code","18494d94":"code","27d006f3":"code","c863ef2b":"code","fe9c061a":"code","12d75622":"code","d8a9f206":"code","6c19ee75":"code","ebdf2401":"code","c6042205":"code","d7391932":"code","e5f6b808":"code","1824ec94":"code","24ba6276":"code","d08e66a5":"code","3e41d329":"code","0d391b9a":"code","0ac932b5":"markdown","0f6631b4":"markdown","def240f8":"markdown","365e262c":"markdown","32fae607":"markdown","dab2c76f":"markdown","eeacf1d0":"markdown","40b07fc8":"markdown","7b06d1c0":"markdown","30e1b2d9":"markdown","18c5060d":"markdown","94189d58":"markdown","32e6ed26":"markdown"},"source":{"c7868718":"import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","bce80126":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsubm = pd.read_csv('..\/input\/sample_submission.csv')\n\n# List all identities\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n\nlen(train),len(test)","18494d94":"train.head(3)","27d006f3":"print('Toxicity = 0.0 (No toxic) : {}\\n'.format(train['comment_text'][0]))\nprint('0.0 < Toxicity < 0.4 (Hard to say) : {}\\n'.format(train['comment_text'][11]))\nprint('0.5 < Toxicity < 0.9 (Toxic) : {}\\n'.format(train['comment_text'][13]))\nprint('Toxicity > 0.9 (Very Toxic) : {}\\n'.format(train['comment_text'][31]))","c863ef2b":"lens = train.comment_text.str.len()\nlens.min(), lens.mean(), lens.std(), lens.max()","fe9c061a":"lens.hist();","12d75622":"# Make sure all comment_text values are strings\ntrain['comment_text'] = train['comment_text'].astype(str)\n\n# And no missing values\nCOMMENT = 'comment_text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)\n\n# Convert taget and identity columns to booleans\ndef convert_to_bool(df, col_name):\n    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n    \ndef convert_dataframe_to_bool(df):\n    bool_df = df.copy()\n    for col in ['target'] + identity_columns:\n        convert_to_bool(bool_df, col)\n    return bool_df\n\ntrain = convert_dataframe_to_bool(train)","d8a9f206":"plt.bar(x=train['target'].value_counts().keys(), height=train['target'].value_counts().values, tick_label=train['target'].value_counts().keys());","6c19ee75":"import re, string\nre_tok = re.compile(f'([{string.punctuation}\u201c\u201d\u00a8\u00ab\u00bb\u00ae\u00b4\u00b7\u00ba\u00bd\u00be\u00bf\u00a1\u00a7\u00a3\u20a4\u2018\u2019])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","ebdf2401":"n = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train[COMMENT])\ntest_term_doc = vec.transform(test[COMMENT])","c6042205":"trn_term_doc, test_term_doc","d7391932":"def pr(y_i, y):\n    p = x[y==y_i].sum(0)\n    return (p+1) \/ ((y==y_i).sum()+1)","e5f6b808":"x = trn_term_doc\ntest_x = test_term_doc","1824ec94":"def get_mdl(y):\n    y = y.values\n    r = np.log(pr(1,y) \/ pr(0,y))\n    m = LogisticRegression(C=4, dual=True)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r","24ba6276":"label_cols = ['target']","d08e66a5":"preds = np.zeros((len(test), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_mdl(train[j])\n    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]","3e41d329":"submid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\nsubmission.columns =  ['id','prediction']\nsubmission.to_csv('submission.csv', index=False)","0d391b9a":"submission.head()","0ac932b5":"From now on we will treat the problem as a binary classification task.\n\n- Transform the target label to bool","0f6631b4":"The length of the comments varies a lot.","def240f8":"Fit a model for one dependent at a time:","365e262c":"## Introduction\n\n*Disclaimer: Adapted [kernel](https:\/\/www.kaggle.com\/jhoward\/nb-svm-strong-linear-baseline) from [Toxic Comment Classification Challenge](https:\/\/www.kaggle.com\/c\/jigsaw-toxic-comment-classification-challenge) to [Jigsaw Unintended Bias in Toxicity Classification](https:\/\/www.kaggle.com\/c\/jigsaw-unintended-bias-in-toxicity-classification\/overview)*\n\nThis kernel shows how to use NBSVM (Naive Bayes - Support Vector Machine) to create a strong baseline for the [Jigsaw Unintended Bias in Toxicity Classification](https:\/\/www.kaggle.com\/c\/jigsaw-unintended-bias-in-toxicity-classification\/overview) competition. NBSVM was introduced by Sida Wang and Chris Manning in the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classi\ufb01cation](https:\/\/nlp.stanford.edu\/pubs\/sidaw12_simple_sentiment.pdf). In this kernel, we use sklearn's logistic regression, rather than SVM, although in practice the two are nearly identical (sklearn uses the liblinear library behind the scenes).\n\nIf you're not familiar with naive bayes and bag of words matrices, I've made a preview available of one of fast.ai's upcoming *Practical Machine Learning* course videos, which introduces this topic. Here is a link to the section of the video which discusses this: [Naive Bayes video](https:\/\/youtu.be\/37sFIak42Sc?t=3745).","32fae607":"Here's some examples of comments\n- Toxicity = 0.0 (No toxic)\n- 0.0 < Toxicity < 0.4 (Hard to say)\n- 0.5 < Toxicity < 0.9 (Toxic)\n- Toxicity > 0.9 (Very Toxic)","dab2c76f":"This creates a *sparse matrix* with only a small number of non-zero elements (*stored elements* in the representation  below).","eeacf1d0":"## Looking at the data\n\n*Note: All the nominal attributes are represented by fractional values from the fraction of human raters who believed the attribute applied to the given comment.*\n\n- comment_text : Text field with the comment\n- target: Toxicity label to be predicted. Test set examples with target >= 0.5 will be considered to be in the positive class (toxic)\n\nThe data also has several additional toxicity subtype attributes. Models do not need to predict these attributes for the competition, they are included as an additional avenue for research. Subtype attributes are:\n\n- severe_toxicity\n- obscene\n- threat\n- insult\n- identity_attack\n- sexual_explicit\n\nAdditionally, a subset of comments have been labelled with a variety of identity attributes, representing the identities that are mentioned in the comment. \n\n- male\n- female\n- homosexual_gay_or_lesbian\n- christian\n- jewish\n- muslim\n- black\n- white\n- psychiatric_or_mental_illness\n\nThere is also some additional features\n\n- created_date \n- publication_id \t\n- parent_id \t\n- article_id \t\n- rating \t\n- funny \t\n- wow \t\n- sad \t\n- likes \t\n- disagree \t\n- sexual_explicit \t\n- identity_annotator_count \t\n- toxicity_annotator_count","40b07fc8":"We can then summarize the target.","7b06d1c0":"### Text representation: TF-IDF","30e1b2d9":"### Model: Na\u00efve Bayes + Logistic Regression (~SVM)\n\nHere's the basic naive bayes feature equation:","18c5060d":"And finally, create the submission file.","94189d58":"## Building the model\n\nWe'll start by creating a *bag of words* representation, as a *term document matrix*. We'll use ngrams, as suggested in the NBSVM paper.","32e6ed26":"It turns out that using TF-IDF gives even better priors than the binarized features used in the paper. I don't think this has been mentioned in any paper before, but it improves leaderboard score from 0.59 to 0.55."}}