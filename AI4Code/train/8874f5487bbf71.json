{"cell_type":{"f88a89e0":"code","c1c6dd51":"code","8e09e6a3":"code","ab51f373":"code","d4127d43":"code","ebb0eb8f":"code","7dc50281":"code","cb886670":"code","a21d4141":"code","df65e1ae":"code","561b37c9":"code","ab27043f":"code","98fb3650":"code","00e0987b":"code","4c6b2417":"code","3d38c2a1":"code","b03c6f6f":"code","65605422":"code","29e82aae":"code","236eaf0f":"code","bca1f68b":"code","94713fb2":"code","d691b216":"code","9e0a09a2":"code","3ae7bdfb":"code","733d4833":"code","42631ede":"code","1889c324":"code","1053a6bd":"code","22236eec":"code","057522d0":"code","7db7c525":"code","aac8a2d1":"markdown","94028d0d":"markdown","c12f632b":"markdown","4c730fc3":"markdown"},"source":{"f88a89e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1c6dd51":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","8e09e6a3":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","ab51f373":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","d4127d43":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","ebb0eb8f":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","7dc50281":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","cb886670":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head(3)","a21d4141":"print('\\n ### \ud6c8\ub828 \ub370\uc774\ud130\uc14b \uc815\ubcf4 ### \\n')\nprint(train.info())","df65e1ae":"train['Age'].fillna(train['Age'].mean(), inplace = True)","561b37c9":"train['Cabin'].fillna('N', inplace=True)\ntrain['Embarked'].fillna('N', inplace=True)\nprint('\ub370\uc774\ud130 Null \uac12 \uac1c\uc218: ', train.isnull().sum().sum())","ab27043f":"print('Sex \uac12 \ubd84\ud3ec :\\n', train['Sex'].value_counts())\nprint('\\nCabin \uac12 \ubd84\ud3ec: \\n', train['Cabin'].value_counts())\nprint('\\nEmbarked \uac12 \ubd84\ud3ec: \\n', train['Embarked'].value_counts())","98fb3650":"train['Cabin'] = train['Cabin'].str[:1]\nprint(train['Cabin'].head(3))","00e0987b":"train.groupby(['Sex','Survived'])['Survived'].count().to_frame()","4c6b2417":"sns.barplot(x='Sex', y='Survived', data=train)","3d38c2a1":"sns.barplot(x='Pclass', y='Survived', hue='Sex', data=train)","b03c6f6f":"def get_category(age):\n    cat = ''\n    if age <= -1 : cat = 'Unknown'\n    elif age <= 5 : cat = 'Baby'\n    elif age <= 12 : cat = 'Child'\n    elif age <= 18 : cat = 'Teenager'\n    elif age <= 25 : cat = 'Student'\n    elif age <= 35 : cat = 'Young Adult'\n    elif age <= 60: cat = 'Adult'\n    else : cat = 'Elderly'\n    \n    return cat","65605422":"plt.figure(figsize=(12, 6))","29e82aae":"group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']","236eaf0f":"train['Age_cat'] = train['Age'].apply(lambda x: get_category(x))\nsns.barplot(x='Age_cat', y='Survived', hue='Sex', data=train, order=group_names)\ntrain.drop('Age_cat', axis=1, inplace=True)","bca1f68b":"from sklearn.preprocessing import LabelEncoder\n\ndef encode_features(dataDF) :\n    features = ['Cabin', 'Sex', 'Embarked']\n    for feature in features:\n        le = LabelEncoder()\n        le = le.fit(dataDF[feature])\n        dataDF[feature] = le.transform(dataDF[feature])\n        \n    return dataDF\n\ntrain = encode_features(train)\ntrain.head()","94713fb2":"def fillna(df):\n    df['Age'].fillna(df['Age'].mean(), inplace=True)\n    df['Cabin'].fillna('N', inplace=True)\n    df['Embarked'].fillna('N', inplace=True)\n    df['Fare'].fillna(0, inplace=True)\n    return df","d691b216":"def drop_features(df):\n    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n    return df","9e0a09a2":"def format_features(df):\n    df['Cabin'] = df['Cabin'].str[:1]\n    features = ['Cabin', 'Sex', 'Embarked']\n    for feature in features:\n        le = LabelEncoder()\n        le.fit(df[feature])\n        df[feature] = le.transform(df[feature])\n    return df","3ae7bdfb":"def transform_features(df):\n    df = fillna(df)\n    df = drop_features(df)\n    df = format_features(df)\n    return df","733d4833":"titanic_df = pd.read_csv('..\/input\/titanic\/train.csv')\ny_titanic_df = titanic_df['Survived']\nX_titanic_df = titanic_df.drop(['Survived'], axis=1)\n\nX_titanic_df = transform_features(X_titanic_df)","42631ede":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size = 0.2, random_state = 11)","1889c324":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","1053a6bd":"dt_clf = DecisionTreeClassifier(random_state=11)\nrf_clf = RandomForestClassifier(random_state=11)\nlr_clf = LogisticRegression()","22236eec":"dt_clf.fit(X_train, y_train)\ndt_pred = dt_clf.predict(X_test)\nprint('DecisionTreeClassifier \uc815\ud655\ub3c4 : {0:.4f}'.format(accuracy_score(y_test, dt_pred)))","057522d0":"rf_clf.fit(X_train, y_train)\nrf_pred = rf_clf.predict(X_test)\nprint('RandomForestClassifier \uc815\ud655\ub3c4 : {0:.4f}'.format(accuracy_score(y_test,rf_pred)))","7db7c525":"lr_clf.fit(X_train, y_train)\nlr_pred = lr_clf.predict(X_test)\nprint('LogisticRegression \uc815\ud655\ub3c4 : {0:.4f}'.format(accuracy_score(y_test, lr_pred)))","aac8a2d1":"### *\uacb0\ub860 : RandomForest\uc758 \uc815\ud655\ub3c4\uac00 \uac00\uc7a5 \ub192\uc74c\uc744 \ubcfc \uc218 \uc788\uc74c.","94028d0d":"## 1. \ud29c\ud1a0\ub9ac\uc5bc","c12f632b":"## 1-1. \uc218\uc5c5 \uc751\uc6a9","4c730fc3":"### \u203b 2. Pclass - \uc0ac\ud68c\uc801 \uc9c0\uc704\n### \u203b 6. SibSp - \uc790\ub9e4 \ubc0f \ubc30\uc6b0\uc790\uc640 \ud568\uaed8 \uc2b9\uc120\ud55c \uc0ac\ub78c \uc218\n### \u203b 7. Parch - \ubd80\ubaa8 \ubc0f \uc544\uc774\ub4e4\uc758 \uc218"}}