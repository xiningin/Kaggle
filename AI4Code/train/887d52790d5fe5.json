{"cell_type":{"9437f757":"code","1ac037a7":"code","8d713b8c":"code","2b3e6c4e":"code","c6783098":"code","5297eed8":"code","28c9c5dd":"code","37d1acfd":"code","4292c828":"code","09bce83d":"code","319ecf6a":"markdown","2c4f4ae9":"markdown","106dae0f":"markdown","48d2b453":"markdown","1e30b037":"markdown","0fcd5af5":"markdown"},"source":{"9437f757":"import os,re,gc\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \n\nimport albumentations as albu\nimport tensorflow as tf \nfrom tensorflow.keras.applications import ResNet152","1ac037a7":"LABELS = np.array(['ETT - Abnormal', 'ETT - Borderline',\n       'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal',\n       'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present'])\n\nN_LABELS = 11 \nAUTO = tf.data.experimental.AUTOTUNE\n\nclass CONFIG: \n    tta = 5\n    batchsize = 32\n    imsize = (512,512)","8d713b8c":"## decoder \ndef decode_fn(path):\n    file_bytes = tf.io.read_file(path)\n    img = tf.io.decode_jpeg(file_bytes,channels=3)\n    img = tf.image.resize(img,CONFIG.imsize)\n    img = tf.cast(img,tf.uint8) \n    return img\n\n## Test Time Augmentation \ntransform = albu.Compose([\n    albu.HorizontalFlip(p=0.5),\n    albu.VerticalFlip(p=0.5),\n    albu.CLAHE(clip_limit=(1,10),p=1)\n])\n\ndef aug_fn(image):\n    aug_img = transform(image = image)[\"image\"]\n    aug_img = tf.cast(aug_img\/255, tf.float32)\n    aug_img = tf.image.resize(aug_img,CONFIG.imsize) \n    return aug_img\n\ndef process_data(image):\n    aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n    aug_img.set_shape((*CONFIG.imsize,3))\n    return aug_img\n\n## Make CLAHE Data \ndef make_clahe_dataset(paths,cache_dir=False):\n    if cache_dir:\n        os.makedirs(cache_dir,exist_ok=True)\n    dset = tf.data.Dataset.from_tensor_slices(paths)\n    dset = dset.map(decode_fn,num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache_dir else dset \n    dset = dset.map(process_data,num_parallel_calls=AUTO)\n    dset = dset.repeat()\n    dset = dset.batch(CONFIG.batchsize)\n    dset = dset.prefetch(AUTO)\n    return dset","2b3e6c4e":"sub_df = pd.read_csv(\"..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv\")\ntest_paths = \"..\/input\/ranzcr-clip-catheter-line-classification\/test\/\" + sub_df[\"StudyInstanceUID\"] + \".jpg\"\nclahe_dset = make_clahe_dataset(test_paths)","c6783098":"def view_image(ds,num=4):\n    print(ds)\n    fig = plt.figure(figsize=(22, 22))\n    images = next(iter(ds))\n    for i,img in enumerate(images):\n        if i == num:\n            break \n        img = img.numpy()\n        ax = fig.add_subplot(3,4,i+1,xticks=[],yticks=[])\n        ax.imshow(img)\n    plt.show()","5297eed8":"view_image(clahe_dset) ","28c9c5dd":"def create_model(config):\n    model = tf.keras.Sequential([\n        ResNet152(input_shape=(*config.imsize,3),\n                              weights=None,\n                              include_top=False),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(N_LABELS,activation=\"sigmoid\")\n    ])\n    model.summary()\n    return model","37d1acfd":"model = create_model(CONFIG)\nmodel.load_weights(\"..\/input\/model-clahe-512\/model_nb13_4_0.h5\")","4292c828":"TEST_NUM = sub_df.shape[0]\n\nsteps = (CONFIG.tta*TEST_NUM + CONFIG.batchsize - 1)\/\/CONFIG.batchsize\npred = model.predict(clahe_dset,steps=steps,verbose=1)[:CONFIG.tta*TEST_NUM]\npred = np.mean(pred.reshape((TEST_NUM,CONFIG.tta,N_LABELS),order = \"F\"),axis = 1)","09bce83d":"sub_df[LABELS] = pred\nsub_df.to_csv('submission.csv', index=False)\nsub_df.head()","319ecf6a":"# Configuration","2c4f4ae9":"# Inference","106dae0f":"# Show Image","48d2b453":"# Submission","1e30b037":"# Dataset","0fcd5af5":"# Model"}}