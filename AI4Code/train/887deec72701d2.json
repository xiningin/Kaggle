{"cell_type":{"7890e0d6":"code","9bbff89b":"code","7b918dd6":"code","00ce8e26":"code","96df1b77":"code","2dc3d415":"code","cc96f165":"code","63b862e5":"code","0e1d3d6e":"code","dec6f99f":"code","43e3f71c":"code","62a42ff8":"code","f9e7ff37":"code","2bd6e019":"code","1f1333c9":"code","57b0d467":"code","adc664b9":"code","cfc1123d":"code","4fa6b99c":"code","d1affe5c":"code","1bec8db9":"code","407e0911":"code","4d79c042":"code","54f0a683":"code","28d26118":"code","0dc80562":"code","ebed57d0":"code","1d7d8d0a":"code","303b6e41":"code","301b45d9":"code","670ea583":"code","88d62f33":"code","a1289cc2":"code","d4a3fcb4":"code","cb2ad227":"code","2c8b8ce3":"code","240ba175":"code","e1473f17":"code","10269ae6":"code","41b092fa":"code","8a82a9f4":"code","2f56bc0a":"code","4459b7d4":"code","11eeb5f9":"code","255ac349":"code","73c52dbb":"code","65f545a4":"code","f0ea0672":"code","e4461de9":"code","247ce08b":"markdown","8a2ad8cc":"markdown","29fc047d":"markdown","5e73a87f":"markdown","11df0b7c":"markdown","e04c7252":"markdown","a4d10886":"markdown","39aebdfb":"markdown","17121a0b":"markdown","54aba5b3":"markdown","7e9e9d37":"markdown","99861cd2":"markdown","093960e4":"markdown","97e2cb17":"markdown","d3ad1e4f":"markdown","9d93ef8e":"markdown","18c69b32":"markdown","d67d7ce9":"markdown","263daf3e":"markdown","5e02ac97":"markdown","d21dbdc1":"markdown","820fcfbe":"markdown","01a4d6c4":"markdown","acf64e15":"markdown","a915ba98":"markdown","7d368068":"markdown","8e84617c":"markdown","56d218e7":"markdown","ac217360":"markdown","afa23973":"markdown","f02f08fa":"markdown","cbe50a39":"markdown","59c62c99":"markdown","4ed94de8":"markdown","deb28a8f":"markdown","1fd2ee62":"markdown"},"source":{"7890e0d6":"# Import libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport seaborn as sns\nimport timeit\nfrom statsmodels.tools.eval_measures import mse, rmse\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score","9bbff89b":"# Import dataset.\ndf = pd.read_csv(\"..\/input\/Admission_Predict.csv\",sep = \",\")\ndf.head()","7b918dd6":"# Check for null values.\ndf.isnull().sum()\n\n# Drop 'Serial No.'\ndf = df.drop('Serial No.',axis=1)\n\n# Renaming columns.\ndf.columns = df.columns.str.strip()\ndf.columns = df.columns.str.replace(' ','_')","00ce8e26":"df.columns","96df1b77":"# Check if the data types are correct as per the meaning of each column.\ndf.info()","2dc3d415":"# Descriptive statistics.\ndf.describe()","cc96f165":"cols = ['GRE_Score','TOEFL_Score','University_Rating','SOP','LOR','CGPA','Chance_of_Admit']\n\nplt.figure(figsize=(6,40))\n\nfor i in range(len(cols)):\n    plt.subplot(7,1,i+1)\n    plt.hist(df[cols[i]],color='pink',alpha=0.75)\n    plt.title(\"Distribution of \" + cols[i])\n\nplt.show()","63b862e5":"cols = ['GRE_Score','TOEFL_Score','University_Rating','SOP','LOR','CGPA']\n\nplt.figure(figsize=(6,40))\n\nfor i in range(len(cols)):\n    plt.subplot(6,1,i+1)\n    plt.scatter(df['Chance_of_Admit'],df[cols[i]],color='brown')\n    plt.title(\"Correlation b\/w 'Chance_of_Admit' and '{}'\".format(cols[i]))\n\nplt.show()","0e1d3d6e":"# Visualize correlation between independant variables and the target variable. Here, the target variable is 'Chance_of_Admit'\nplt.figure(figsize=(8,6))\nsns.heatmap(df.corr(),annot = True)\nplt.show()","dec6f99f":"# Correlation factors for 'Chance_of_Admit'.\ndf.corr()['Chance_of_Admit'].sort_values(ascending=False)","43e3f71c":"from sklearn import linear_model\n\nX = df.drop(['Chance_of_Admit','Research'],axis = 1)\nY = df['Chance_of_Admit']\n\nmodel = linear_model.LinearRegression()\nmodel.fit(X,Y)\n\nprint('\\nCoefficients: \\n', model.coef_)\nprint('\\nIntercept: \\n', model.intercept_)","62a42ff8":"import statsmodels.api as sm\n\n# We need to manually add a constant in statsmodels' sm\nX = df.drop(['Chance_of_Admit','Research'],axis = 1)\nY = df['Chance_of_Admit']\n\nX = sm.add_constant(X)\nmodel1 = sm.OLS(Y, X).fit()\n\nmodel1.summary()","f9e7ff37":"X = df.drop(['Chance_of_Admit','Research','University_Rating','SOP'],axis = 1)\nY = df['Chance_of_Admit']\n\nX = sm.add_constant(X)\nmodel2 = sm.OLS(Y, X).fit()\n\nmodel2.summary()","2bd6e019":"performance_stats = pd.DataFrame()\n\n# This information is drawn from model1 and model2 summary tables above.\nperformance_stats['F-statistic'] = [259.9,389.9]\nperformance_stats['Adj_R-squared'] = [0.796,0.796]\nperformance_stats['AIC'] = [-1051,-1054]\nperformance_stats['BIC'] = [-1023,-1034]\n\nperformance_stats","1f1333c9":"# Transform to normal distribution using boxcox transformation.\nfrom scipy.stats import boxcox\nboxcox_Chance_of_Admit,_ = boxcox(df['Chance_of_Admit'])\nplt.figure(figsize=(6,5))\nplt.hist(boxcox_Chance_of_Admit)\nplt.show()\n","57b0d467":"df['boxcox_Chance_of_Admit'] = boxcox_Chance_of_Admit\n\nX = df.drop(['Chance_of_Admit','Research','University_Rating','SOP','boxcox_Chance_of_Admit'],axis = 1)\nY = df['boxcox_Chance_of_Admit']\n\nX = sm.add_constant(X)\nmodel3 = sm.OLS(Y, X).fit()\n\nmodel3.summary()","adc664b9":"# These values are taken from the above summary tables for model1, model2 and model3.\nperformance_statistics = pd.DataFrame()\nperformance_statistics['F-statistic'] = [259.9,389.9,443.2]\nperformance_statistics['Adj_R-squared'] = [0.796,0.796,0.816]\nperformance_statistics['AIC'] = [-1051,-1054,-1272]\nperformance_statistics['BIC'] = [-1023,-1034,-1252]\n\nperformance_statistics['Model'] = ['model1','model2','model3']\nperformance_statistics.set_index('Model')","cfc1123d":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['Chance_of_Admit','Research','University_Rating','SOP','boxcox_Chance_of_Admit'],axis = 1)\nY = df['boxcox_Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\nX_train = sm.add_constant(X_train)\n\nmodel4 = sm.OLS(y_train, X_train).fit()\nmodel4.summary()","4fa6b99c":"# We add constant to the model as it's a best practice to do so every time!\nX_test = sm.add_constant(X_test)\n\n# We are making predictions here\ny_preds = model4.predict(X_test)\n\nplt.scatter(y_test, y_preds)\nplt.plot(y_test, y_test, color=\"red\")\nplt.xlabel(\"true values\")\nplt.ylabel(\"predicted values\")\nplt.title(\"Admission: true and predicted values\")\nplt.show()","d1affe5c":"rmse_ols = rmse(y_test, y_preds)\n\nprint(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds)))\nprint(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds)))\nprint(\"Root mean squared error of the prediction is: {}\".format(rmse_ols))\nprint(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds) \/ y_test)) * 100))\n","1bec8db9":"# Transform to normal distribution using boxcox transformation.\nboxcox_TOEFL_Score,_ = boxcox(df['TOEFL_Score'])\nplt.figure(figsize=(6,5))\nplt.hist(boxcox_TOEFL_Score,color='purple',alpha=0.70)\nplt.title(\"Distribution of TOEFL_Score\")\nplt.show()\n\nboxcox_GRE_Score,_ = boxcox(df['GRE_Score'])\nplt.figure(figsize=(6,5))\nplt.hist(boxcox_GRE_Score,color='purple',alpha=0.70)\nplt.title(\"Distribution of GRE_Score\")\nplt.show()\n\nboxcox_CGPA,_ = boxcox(df['CGPA'])\nplt.figure(figsize=(6,5))\nplt.hist(boxcox_CGPA,color='purple',alpha=0.70)\nplt.title(\"Distribution of CGPA\")\nplt.show()\n\nboxcox_LOR,_ = boxcox(df['LOR'])\nplt.figure(figsize=(6,5))\nplt.hist(boxcox_LOR,color='purple',alpha=0.70)\nplt.title(\"Distribution of LOR\")\nplt.show()","407e0911":"df['boxcox_TOEFL_Score'] = boxcox_TOEFL_Score\ndf['boxcox_GRE_Score'] = boxcox_GRE_Score\ndf['boxcox_CGPA'] = boxcox_CGPA\ndf['boxcox_LOR'] = boxcox_LOR","4d79c042":"X1 = df.drop(['Chance_of_Admit','Research','University_Rating','SOP',\n             'TOEFL_Score','GRE_Score','CGPA','boxcox_Chance_of_Admit','LOR'],axis = 1)\nY1 = df['boxcox_Chance_of_Admit']\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size = 0.2, random_state = 450)\nX_train1 = sm.add_constant(X_train1)\n\nmodel5 = sm.OLS(y_train1, X_train1).fit()\nmodel5.summary()","54f0a683":"# We add constant to the model as it's a best practice to do so every time!\nX_test1 = sm.add_constant(X_test1)\n\n# We are making predictions here\ny_preds1 = model5.predict(X_test1)\n\nplt.scatter(y_test1, y_preds1)\nplt.plot(y_test1, y_test1, color=\"red\")\nplt.xlabel(\"true values\")\nplt.ylabel(\"predicted values\")\nplt.title(\"Admission: true and predicted values\")\nplt.show()","28d26118":"rmse_ols_Nor_dist = rmse(y_test1, y_preds1)\n\nprint(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test1, y_preds1)))\nprint(\"Mean squared error of the prediction is: {}\".format(mse(y_test1, y_preds1)))\nprint(\"Root mean squared error of the prediction is: {}\".format(rmse_ols_Nor_dist))\nprint(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test1 - y_preds1) \/ y_test1)) * 100))\n","0dc80562":"print(\"Root mean squared error of MODEL4 and MODEL5 are {}  and  {}\".format(rmse(y_test, y_preds),rmse(y_test1, y_preds1)))\n","ebed57d0":"X = df.drop(['Chance_of_Admit','Research','University_Rating','SOP',\n             'TOEFL_Score','GRE_Score','CGPA','boxcox_Chance_of_Admit','LOR'],axis = 1)\nY = df['boxcox_Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\nlireg = linear_model.LinearRegression()\nlireg.fit(X_train,y_train)\npred_test = lireg.predict(X_test)\n\nrmse_lireg = rmse(y_test, pred_test)\n\nprint(\"RMSE for the prediction of test data is\",rmse_lireg)","1d7d8d0a":"# KNN Regression model with cross validation.\nfrom sklearn import neighbors\n\nknn = neighbors.KNeighborsRegressor(n_neighbors=10)\nX = df.drop(['Chance_of_Admit','Research','University_Rating','SOP',\n             'TOEFL_Score','GRE_Score','CGPA','boxcox_Chance_of_Admit','LOR'],axis = 1)\nY = df['boxcox_Chance_of_Admit']\n\nscore = cross_val_score(knn, X, Y, cv=5)\nprint(\"Score : \",score)\nprint(\"Variance : \",score.std()**2)","303b6e41":"# KNN Regression model with weights parameter.\nknn_w = neighbors.KNeighborsRegressor(n_neighbors=10,weights='distance')\nX = df.drop(['Chance_of_Admit','Research','University_Rating','SOP',\n             'TOEFL_Score','GRE_Score','CGPA','boxcox_Chance_of_Admit','LOR'],axis = 1)\nY = df['boxcox_Chance_of_Admit']\n\nscore = cross_val_score(knn_w, X, Y, cv=5)\nprint(\"Score : \",score)\nprint(\"Variance : \",score.std()**2)","301b45d9":"# KNN Regression model with RMSE\nknn = neighbors.KNeighborsRegressor(n_neighbors=10)\nX = df.drop(['Chance_of_Admit','Research','University_Rating','SOP',\n             'TOEFL_Score','GRE_Score','CGPA','boxcox_Chance_of_Admit','LOR'],axis = 1)\nY = df['boxcox_Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\nknn.fit(X_train,y_train)\npred_train = knn.predict(X_train)\npred_test = knn.predict(X_test)\n\nrmse_knn = rmse(y_test, pred_test)\n\nprint(\"RMSE for the prediction of trained data is\",rmse(y_train, pred_train))\nprint(\"RMSE for the prediction of test data is\",rmse_knn)","670ea583":"data = df[['GRE_Score','TOEFL_Score','CGPA','LOR','Chance_of_Admit']]\ndata.loc[data['Chance_of_Admit']>=0.50,'Chance_of_Admit'] = 1\ndata.loc[data['Chance_of_Admit']<0.50,'Chance_of_Admit'] = 0\ndata['Chance_of_Admit'] = data['Chance_of_Admit'].astype('int')","88d62f33":"# Look at our data.\nplt.figure(figsize=(7,5))\n\nplt.scatter(\n    data[data['Chance_of_Admit'] == 1].CGPA,\n    data[data['Chance_of_Admit'] == 1].GRE_Score,\n    color='red'\n)\nplt.scatter(\n    data[data['Chance_of_Admit'] == 0].CGPA,\n    data[data['Chance_of_Admit'] == 0].GRE_Score,\n    color='blue'\n)\n\nplt.legend(['Get Admission', 'No Admission'])\nplt.title('\"Admission(YES\/NO)\" Characteristics for GREvsCGPA',fontsize=12)\nplt.xlabel('CGPA',fontsize=12)\nplt.ylabel('GRE_Score',fontsize=12)\nplt.show()\n\n\nplt.figure(figsize=(7,5))\n\nplt.scatter(\n    data[data['Chance_of_Admit'] == 1].CGPA,\n    data[data['Chance_of_Admit'] == 1].TOEFL_Score,\n    color='red'\n)\nplt.scatter(\n    data[data['Chance_of_Admit'] == 0].CGPA,\n    data[data['Chance_of_Admit'] == 0].TOEFL_Score,\n    color='blue'\n)\n\nplt.legend(['Get Admission', 'No Admission'])\nplt.title('\"Admission(YES\/NO)\" Characteristics for TOEFLvsCGPA',fontsize=12)\nplt.xlabel('CGPA',fontsize=12)\nplt.ylabel('TOEFL_Score',fontsize=12)\nplt.show()\n\n\nplt.figure(figsize=(7,5))\n\nplt.scatter(\n    data[data['Chance_of_Admit'] == 1].GRE_Score,\n    data[data['Chance_of_Admit'] == 1].TOEFL_Score,\n    color='red'\n)\nplt.scatter(\n    data[data['Chance_of_Admit'] == 0].GRE_Score,\n    data[data['Chance_of_Admit'] == 0].TOEFL_Score,\n    color='blue'\n)\n\nplt.legend(['Get Admission', 'No Admission'])\nplt.title('\"Admission(YES\/NO)\" Characteristics for GREvsTOEFL',fontsize=12)\nplt.xlabel('GRE_Score',fontsize=12)\nplt.ylabel('TOEFL_Score',fontsize=12)\nplt.show()","a1289cc2":"from sklearn.neighbors import KNeighborsClassifier\n\nX = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\nknc = KNeighborsClassifier(n_neighbors=5)\nknc.fit(X_train,y_train)\npredict_test_knc = knc.predict(X_test)\n\nprint(knc.predict([[337,118,9.65,4.5]]))\nprint(knc.predict_proba([[337,118,9.65,4.5]]))","d4a3fcb4":"# Confusion matrix\n\ncm_knc = confusion_matrix(y_test,predict_test_knc)\n\n# Visualization of Confusion matrix.\nf, ax = plt.subplots(figsize =(3,3))\nsns.heatmap(cm_knc,annot = True,linewidths=0.5,linecolor=\"orange\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"predictions\")\nplt.ylabel(\"Actuals\")\nplt.show()\n\n\nacu_score_knc = accuracy_score(y_test,predict_test_knc)\nscore_knc = knc.score(X_test,y_test)\n\n\nprint(\"precision_score: \", precision_score(y_test,predict_test_knc))\nprint(\"recall_score: \", recall_score(y_test,predict_test_knc))\n\n\nprint(\"f1_score: \",f1_score(y_test,predict_test_knc))\n\nprint(\"Accuracy Score:  \",acu_score_knc)","cb2ad227":"from sklearn.neighbors import KNeighborsClassifier\nfrom scipy import stats\n\nneighbors = KNeighborsClassifier(n_neighbors=5, weights='distance')\n\n# Our input data frame will be the z-scores this time instead of raw data.\nX = pd.DataFrame({\n    'GRE_Score': stats.zscore(data.GRE_Score),\n    'TOEFL_Score': stats.zscore(data.TOEFL_Score),\n    'CGPA': stats.zscore(data.CGPA),\n    'LOR': stats.zscore(data.LOR)\n})\n\n# Fit our model.\nY = data['Chance_of_Admit']\nneighbors.fit(X, Y)\n\nprint(neighbors.predict([[337,118,9.65,4.5]]))\nprint(neighbors.predict_proba([[337,118,9.65,4.5]]))","2c8b8ce3":"# Decision tree classifier.\nfrom sklearn import tree\n\n# A convenience for displaying visualizations.\nfrom IPython.display import Image\n\n# Packages for rendering our tree.\nimport pydotplus\nimport graphviz\n\nX = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\n# Initialize and train our tree.\ndecision_tree = tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_features=1,\n    max_depth=4,\n    random_state = 1337\n)\ndecision_tree.fit(X, Y)\n\n# Render our tree.\ndot_data = tree.export_graphviz(\n    decision_tree, out_file=None,\n    feature_names=X.columns,\n    class_names=['Get Admission', 'No Admission'],\n    filled=True\n)\ngraph = pydotplus.graph_from_dot_data(dot_data)\nImage(graph.create_png())","240ba175":"pred = decision_tree.predict(X)\n","e1473f17":"# Decision tree classifier.\n\n\nX = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\ndct = tree.DecisionTreeClassifier()\ndct.fit(X_train,y_train)\npredict_test_dct = dct.predict(X_test)\n\n# Confusion matrix\ncm_dct = confusion_matrix(y_test,predict_test_dct)\n\n# Visualization of Confusion matrix.\nf, ax = plt.subplots(figsize =(3,3))\nsns.heatmap(cm_dct,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"predictions\")\nplt.ylabel(\"Actuals\")\nplt.show()\n\nacu_score_dct = accuracy_score(y_test,predict_test_dct)\nscore_dct = dct.score(X_test,y_test)\n\nprint(\"precision_score: \", precision_score(y_test,predict_test_dct))\nprint(\"recall_score: \", recall_score(y_test,predict_test_dct))\n\nprint(\"f1_score: \",f1_score(y_test,predict_test_dct))\n\nprint(\"Accuracy Score:  \",acu_score_dct)\n","10269ae6":"# Decision tree Regressor.\nX = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\nmodel = tree.DecisionTreeRegressor()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\n\nrmse_dct = rmse(y_test, y_pred)\n\nprint(\"RMSE is : \",rmse_dct)","41b092fa":"from sklearn import ensemble\nfrom sklearn.model_selection import cross_val_score\n\nrfc = ensemble.RandomForestClassifier()\nX = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\nscore = cross_val_score(rfc, X, Y, cv=10)\nprint(\"Cross validation Score : \",score)\nprint(\"Variance : \",score.std()**2)","8a82a9f4":"X = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\nrfc1 = ensemble.RandomForestClassifier()\nrfc1.fit(X_train,y_train)\npredict_test_rfc = rfc1.predict(X_test)\n\n# Confusion matrix\ncm_rfc = confusion_matrix(y_test,predict_test_rfc)\n\n# Visualization of Confusion matrix.\nf, ax = plt.subplots(figsize =(3,3))\nsns.heatmap(cm_rfc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"predictions\")\nplt.ylabel(\"Actuals\")\nplt.show()\n\nacu_score_rfc = accuracy_score(y_test,predict_test_rfc)\nscore_rfc = rfc1.score(X_test,y_test)\n\nprint(\"precision_score: \", precision_score(y_test,predict_test_rfc))\nprint(\"recall_score: \", recall_score(y_test,predict_test_rfc))\n\nprint(\"f1_score: \",f1_score(y_test,predict_test_rfc))\n\nprint(\"Accuracy Score:  \",acu_score_rfc)","2f56bc0a":"from sklearn.svm import SVC\n\n# Instantiate our model and fit the data.\nX = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\nsvm = SVC(kernel = 'linear')\nsvm.fit(X_train,y_train)\npred = svm.predict(X_test)\n\n# Confusion matrix\ncm_svc = confusion_matrix(y_test,pred)\n\n# Visualization of Confusion matrix.\nf, ax = plt.subplots(figsize =(3,3))\nsns.heatmap(cm_svc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"predictions\")\nplt.ylabel(\"Actuals\")\nplt.show()\n\nacu_score_svc = accuracy_score(y_test,pred)\nscore_svc = svm.score(X_test,y_test)\n\nprint(\"precision_score: \", precision_score(y_test,pred))\nprint(\"recall_score: \", recall_score(y_test,pred))\n\nprint(\"f1_score: \",f1_score(y_test,pred))\n\nprint(\"Accuracy Score:  \",acu_score_svc)\n","4459b7d4":"from sklearn.svm import SVR\n\nX = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\nY = data['Chance_of_Admit']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 450)\n\nsvr = SVR()\nsvr.fit(X_train,y_train)\npred = svr.predict(X_test)\n\nrmse_svr = rmse(y_test, pred)\n\nprint(\"SVR Score is : \",svr.score(X, Y))\nprint(\"Cross validation score is : \",cross_val_score(svr, X, Y, cv=5))\nprint(\"Variance : \",cross_val_score(svr, X, Y, cv=5).std()**2)\nprint(\"RMSE is : \",rmse_svr)","11eeb5f9":"X = data[['GRE_Score','TOEFL_Score','CGPA','LOR']]\ny = data['Chance_of_Admit']","255ac349":"# Create training and test sets.\noffset = int(X.shape[0]*0.9)\n\n# Put 90% of the data in the training set.\nX_train, y_train = X[:offset], y[:offset]\n\n# And put 10% in the test set.\nX_test, y_test = X[offset:], y[offset:]","73c52dbb":"# We'll make 100 iterations, use 2-deep trees, and set our loss function.\nparams = {'n_estimators': 100,\n          'max_depth': 2,\n          'loss': 'deviance'}\n\n# Initialize and fit the model.\nclf = ensemble.GradientBoostingClassifier(**params)\nclf.fit(X_train, y_train)\n\npredict_train = clf.predict(X_train)\npredict_test = clf.predict(X_test)\n\n# Accuracy tables.\ntable_train = pd.crosstab(y_train, predict_train, margins=True)\ntable_test = pd.crosstab(y_test, predict_test, margins=True)\n\ntrain_tI_errors = table_train.loc[0,1] \/ table_train.loc['All','All']\ntrain_tII_errors = table_train.loc[1,0] \/ table_train.loc['All','All']\n\ntest_tI_errors = table_test.loc[0,1]\/table_test.loc['All','All']\ntest_tII_errors = table_test.loc[1,0]\/table_test.loc['All','All']\n\nprint((\n    'Training set accuracy:\\n'\n    'Percent Type I errors: {}\\n'\n    'Percent Type II errors: {}\\n\\n'\n    'Test set accuracy:\\n'\n    'Percent Type I errors: {}\\n'\n    'Percent Type II errors: {}'\n).format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n","65f545a4":"feature_importance = clf.feature_importances_\n\n# Make importances relative to max importance.\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\nplt.subplot(1, 2, 2)\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","f0ea0672":"y = [rmse_ols,rmse_lireg,rmse_knn,rmse_dct,rmse_svr]\nx = ['OLS','Linear_Reg','KNN','Dec_Tree','Support Vector']\nplt.bar(x,y)\nplt.ylabel(\"RMSE\")\nplt.title(\"RMSE w.r.t Regression Algorithms\")\nplt.show()","e4461de9":"y1 = [acu_score_knc,acu_score_dct,acu_score_rfc,acu_score_svc]\nx1 = ['KNN_Classifer','Dec_Tree','Random_Forest','Support_Vector']\nplt.bar(x1,y1)\nplt.ylabel(\"Accuracy Score\")\nplt.title(\"Accuracy score w.r.t Classification Algorithms\")\nplt.show()","247ce08b":"- We can use an F-test to compare two models if one of them is nested within the other. That is, if the feature set in a model is a subset of the feature set of the other, then we can use F-test. In this case, we say that the model with higher F statistic is superior to the other one.\n- We can also use adjusted R-squared. The higher adjusted R-squared, the better the model explains the target variable.\n- Using information criteria is also a common way of comparing different models and selecting the best one. Here, the two information criteria are Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC). Both take into consideration the sum of the squared errors (SSE), the sample size, and the number of parameters. The lower AIC and BIC, the better the model explains the target variable.","8a2ad8cc":"<b><font color='blue'>Model5: <font\/>Apply boxcox transformation to the features.","29fc047d":"<b>Evaluating performance by comparing <font color='blue'>model1<\/font> and <font color='blue'>model2","5e73a87f":"We can observe that RMSE for model5 is slightly decreased due to transforming independent variables(features) to normal distributions.","11df0b7c":"Still it is NOT a complete normal distribution but some what better than before. Let us rerun the model with the transformed target variable.","e04c7252":"<b><font color='blue'>Model3: <font\/>Apply boxcox transformation to the target variable.","a4d10886":"Let us change the column 'Chance_of_Admit' so that it holds boolean values(0 and 1) in order to use it for classification. <br\/>\n- Here on, when ever I create a classification model, I use the dataframe \"data\" which holds boolean value for 'Chance_of_Admit'.\n- When I create a regression model, I use the original data frame \"df\".","39aebdfb":"Wow!! After transforming target variable to normal distribution, model3's performance stats have been improved.<br\/>\nIt's time to make predictions now.","17121a0b":"Since we're now working with a binary outcome, we are using a classifier. Our loss function can be \"deviance\", or \"exponential\". Deviance is used for logistic regression, and we'll try that here.","54aba5b3":"From the above GRE_Score, TOEFL_Score and CGPA are some what normally distributed and the target variable 'Chance_of_Admit' is left skewed.<br\/>\nLet us observe the correlation between the target variable and independent variables.","7e9e9d37":"Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface. But they aren't quite a black box. We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees.","99861cd2":"<b><font color='blue'>Linear SVM","093960e4":"In the graph, we see that our model predicts the higher values of the target better than the lower values. By using visualizations like this, we can more intuitively understand the performance of the models. But, we need to find more accurate ways of assessing our models. Let us find out some metrics to evaluate how good the predictions are. Below are those metrics.","97e2cb17":"<b><font color='blue'>Gradient Boosting","d3ad1e4f":"From the above, it is observed that students with high scores of CGPA, GRE and TOEFL have more chances of getting admissions.","9d93ef8e":"<b><font color='blue'>Ensemble modeling: RandomForestClassifier with Cross validation","18c69b32":"It is clear that CGPA has highest correlation with Chance_of_Admit followed by GRE_Score and TOEFL_Score. <br\/>\nAlso, there is a little correlation of University_Rating, SOR and LOR with the target variable.","d67d7ce9":"From the above, p-values of GRE_Score, TOEFL_Score, LOR and CGPA are less than 0.05 and p-values of University_Rating and SOP are greater than 0.05.<br\/>\nThis implies that the coefficient of University_Rating and SOP are effectively zero from a statistical point of view. They are simply not significant, and we can say that it appears to be no relationship between Chance_of_Admit and the features (University_Rating, SOP). <br\/>\n\nLet us remove these 2 variables and see if there is an improvement in the model or not.","263daf3e":"<b><font color='blue'>KNN Classifier","5e02ac97":"<b><font color='blue'>Performance of all Classification models:","d21dbdc1":"<b><font color='blue'>KNN Regressor","820fcfbe":"<b>From the above, it is observed that all models have almost similar accuracy. Among them, KNN Classifier and Random Forest have better accuracy compared to others.","01a4d6c4":"<b><font color='blue'>Linear Regression","acf64e15":"<b><font color='blue'>SVM Regressor","a915ba98":"From the above, we observe that model2 is slightly better than model1(based on the 3 rules from the bullet points). <br\/>\nThe target variable(Chance_of_Admit) is skewed. Let us transform it to a normal distribution and test the model again.","7d368068":"<b><font color='blue'>Model1:<font\/> Linear Regression using statsmodels","8e84617c":"<b><font color='blue'>Performance of all Regression models:","56d218e7":"<b>From the above, it is observed that OLS and Linear Regression have low RMSE values. ","ac217360":"Above plots show that there is a linear relation between target variable and GRE_Score, TOEFL_Score and CGPA. However, let us statistically confirm this using a correlation matrix.","afa23973":"<b><font color='blue'>Simple Linear Regression with OLS(Ordinary Least Squares).<br\/><\/b>","f02f08fa":"<b><font color='blue'>Model4: Making predictions.","cbe50a39":"<b>Interpreting estimated coefficients.","59c62c99":"<b><font color='blue'>Visualize a Decision tree.","4ed94de8":"<b><font color='blue'>Model2:<font\/> Remove University_Rating and SOP","deb28a8f":"<b><font color='blue'>Decision Tree Classifier.","1fd2ee62":"<b>Linear regression equation with coefficients and intercept(from the above result) would be:<\/b><br\/>\nChance_of_Admit = 0.00227608GRE_Score + 0.00275344TOEFL_Score + 0.00606202University_Rating - 0.0019614SOP + 0.0227486LOR + 0.11987489CGPA - 1.4138594435308127<br\/>\n\nBut we are more interested in identifying the significance of these coefficients. We can determine this using Statistical T-test. Let us use \"statsmodels\" to get T-test, p values and many other statistical information."}}