{"cell_type":{"9d9b5aa2":"code","98a4b548":"code","6a9f219f":"code","ec7c8336":"code","d1a82451":"code","6362f8fd":"code","2b3621aa":"code","fd65be91":"code","a40e2e29":"code","f79a8853":"code","934cf1b5":"code","a17f9eaf":"code","c8f10d4e":"code","e3cb1257":"code","481d15d3":"code","a6c23092":"code","5fee71bb":"code","7200002f":"code","8c0e5659":"code","966e4d14":"code","78496d53":"code","c617a600":"code","6103c72f":"code","5ec23a69":"code","6344116e":"code","d57227f8":"code","02a0ce7b":"markdown"},"source":{"9d9b5aa2":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.nn.functional import softmax\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\nimport os\nimport pandas as pd\nfrom numpy import linalg as LA","98a4b548":"path = '..\/input\/2stage\/sol_set_tat2.txt'\nu_H = pd.read_csv(path, sep=\" \", header=None).values\n\n# recued model dim; nb of basis in cem setting\nnb_rdm = np.shape(u_H)[1]\nprint(\"nb_rdm\", nb_rdm)\nprint(\"u_H\", u_H)\n\npath = '..\/input\/2stage\/sol_set_test.txt'\nu_H_test = pd.read_csv(path, sep=\" \", header=None).values\n\n# recued model dim; nb of basis in cem setting\nnb_rdm_test = np.shape(u_H_test)[1]\nprint(\"nb_rdm_test\", nb_rdm_test)\nprint(\"u_H_test\", u_H_test)","6a9f219f":"plt.plot(u_H[280,:], \"b-\")\nplt.plot(np.mean(u_H, axis = 0), \"r-\")","ec7c8336":"print(\"L1 norm mean\", np.mean(LA.norm(u_H-np.mean(u_H, axis = 0), axis = 1, ord = 1)))\nprint(\"L2 norm mean\", np.mean(LA.norm(u_H-np.mean(u_H, axis = 0), axis = 1)))","d1a82451":"path = '..\/input\/2stage\/f_set_tat2.npy'\nffine = np.load(path)\nprint(\"ffine\", np.shape(ffine))\n\n\npath = '..\/input\/2stage\/f_set_test.npy'\nffine_test = np.load(path)\nprint(\"ffine_test\", np.shape(ffine_test))\n\nnb_samples = np.shape(ffine)[0]\nnb_times = np.shape(ffine)[1]\nnb_reduced = 75\n# nb_heads will be defined in the multihead section \nnb_takes = 1\n\na = 100\nb = 100\ndim_mesh = (a-1)*(b-1)\n\nfcoarse_reshape= np.reshape(ffine, (nb_samples, nb_times, a-1, b-1))\nprint(\"fcoarse_reshape\", np.shape(fcoarse_reshape))\nfcoarse_reshape_torch = torch.tensor(fcoarse_reshape, dtype=torch.float32)\n\n\nnb_samples_test = np.shape(ffine_test)[0]\nnb_times_test = np.shape(ffine_test)[1]\nfcoarse_reshape_test= np.reshape(ffine_test, (nb_samples_test, nb_times_test, a-1, b-1))\nprint(\"fcoarse_reshape_test\", np.shape(fcoarse_reshape_test))","6362f8fd":"np.mean(fcoarse_reshape)","2b3621aa":"# reduce the spatial dim of f (f projected on the fine mesh ) by max pooling\n# reshape the pooling output to a vector\n# batch_size: nb of samples\n# nb_channels: nb of time steps\n# dt: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1; can als be nb of samples, nb of time steps, d_reduced\n# output shape: nb of samples, nb of time steps, 81 (reduced dim due to the pooling)\n# no training included\nrand_factor = 1e-06\nclass PreProcessingData(nn.Module):\n    def __init__(self, bo):\n        super().__init__()\n        self.pool = nn.MaxPool2d(10,stride = 10)\n        self.bo = bo\n    # q = [q1; q2;...,qn]; dim: # model dim (d_model), # time steps\n    # note the values for Q K are all V which is model reduction coeff; \n    # there is no need to generate the random values for Q and K\n    # each row is: the query key and vals of a word\n    def forward(self, dt, batch_size, d_channels):\n        if self.bo:\n            dt = self.pool(dt)\n            dt = dt.view(batch_size, d_channels, -1)\n            return dt+torch.randn(batch_size, d_channels,  dt.size()[-1])*rand_factor\n        else:\n            return dt+torch.randn(batch_size, d_channels,  dt.size()[-1])*rand_factor\n\nmodel = PreProcessingData(True)\nout = model(fcoarse_reshape_torch, nb_samples, nb_times)  \nnp.shape(out)","fd65be91":"# class OneHeadAttention attention\n# # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# generate one head of the transformer (one layer)\n# output dim: nb_samples, nb of time steps, reduced dim encode for each time step\nclass OneHeadAttention(nn.Module):\n    def __init__(self, v, d_reduced, bo ):\n        super().__init__()\n        self.v = v\n        \n        self.preproc = PreProcessingData(bo)\n        self.vv = self.preproc(self.v, nb_samples, nb_times)\n        \n        self.d_model = self.vv.size()[-1]\n        \n        self.v_linear = nn.Linear(self.d_model, d_reduced)\n        self.q_linear = nn.Linear(self.d_model, d_reduced)\n        self.k_linear = nn.Linear(self.d_model, d_reduced)\n        \n    # self.vv: nb samples, nb time steps, 81 (reduced due to the max pooling, no training)\n    def forward(self):\n          \n        v = self.v_linear( self.vv )\n        k = self.k_linear( self.vv )\n        q = self.q_linear( self.vv )\n        qkt = torch.matmul(q, torch.transpose(k, 1, 2))\n\n        sm_qkt = softmax(qkt, 2)\n\n        out = torch.matmul(sm_qkt, v)\n        return out\n\nmodel = OneHeadAttention(fcoarse_reshape_torch, nb_reduced, True )\nout = model()  \nnp.shape(out)","a40e2e29":"# V1 OF HEAD 6 heads attention\n# need class OneHeadAttention\n# generate multi-head of one layer using OneHeadAttention; the nb of heads is fixed and is equal to 3 in this code\n# # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# output size: nb batches, time steps, reduced dim (note, equal to the encode dim of one head)\n\nnb_heads = 6\nclass MultiHeads(nn.Module):\n    def __init__(self, v, d_reduced, d_head, bo):\n        super().__init__()\n        self.v = v\n        self.head1 = OneHeadAttention(self.v, d_reduced, bo)\n        self.head2 = OneHeadAttention(self.v, d_reduced, bo)\n        self.head3 = OneHeadAttention(self.v, d_reduced, bo)\n        self.head4 = OneHeadAttention(self.v, d_reduced, bo)\n        self.head5 = OneHeadAttention(self.v, d_reduced, bo)\n        self.head6 = OneHeadAttention(self.v, d_reduced, bo)\n        \n        self.linear = nn.Linear(d_reduced*d_head, d_reduced)\n    def forward(self):\n        out1 = self.head1()\n        out2 = self.head2()\n        out3 = self.head3()\n        out4 = self.head4()\n        out5 = self.head5()\n        out6 = self.head6()\n        concat_out = torch.cat((out1, out2, out3, out4, out5, out6), dim = -1)\n        \n        out = self.linear(  concat_out )\n        \n        return out\nmodel = MultiHeads(fcoarse_reshape_torch, nb_reduced, nb_heads, True )\nout = model()  \nprint(out.size())","f79a8853":"# # V2 OF HEAD; 1 head attention\n# # need class OneHeadAttention\n# # generate multi-head of one layer using OneHeadAttention; the nb of heads is fixed and is equal to 3 in this code\n# # # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# # output size: nb batches, time steps, reduced dim (note, equal to the encode dim of one head)\n\n# nb_heads = 1\n# class MultiHeads(nn.Module):\n#     def __init__(self, v, d_reduced, d_head, bo):\n#         super().__init__()\n#         self.v = v\n#         self.head1 = OneHeadAttention(self.v, d_reduced, bo)\n        \n#         self.linear = nn.Linear(d_reduced*d_head, d_reduced)\n#     def forward(self):\n#         out1 = self.head1()\n# #         out2 = self.head2()\n# #         out3 = self.head3()\n# #         out4 = self.head4()\n# #         out5 = self.head5()\n# #         out6 = self.head6()\n# #         concat_out = torch.cat((out1, out2, out3, out4, out5, out6), dim = -1)\n        \n#         out = self.linear(  out1 )\n        \n#         return out\n# model = MultiHeads(fcoarse_reshape_torch, nb_reduced, nb_heads, True )\n# out = model()  \n# print(out.size())","934cf1b5":"# # V3 OF HEAD; 3 headS attention\n# # need class OneHeadAttention\n# # generate multi-head of one layer using OneHeadAttention; the nb of heads is fixed and is equal to 3 in this code\n# # # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# # output size: nb batches, time steps, reduced dim (note, equal to the encode dim of one head)\n\n# nb_heads = 3\n# class MultiHeads(nn.Module):\n#     def __init__(self, v, d_reduced, d_head, bo):\n#         super().__init__()\n#         self.v = v\n#         self.head1 = OneHeadAttention(self.v, d_reduced, bo)\n#         self.head2 = OneHeadAttention(self.v, d_reduced, bo)\n#         self.head3 = OneHeadAttention(self.v, d_reduced, bo)\n#         self.linear = nn.Linear(d_reduced*d_head, d_reduced)\n        \n#     def forward(self):\n#         out1 = self.head1()\n#         out2 = self.head2()\n#         out3 = self.head3()\n# #         out4 = self.head4()\n# #         out5 = self.head5()\n# #         out6 = self.head6()\n#         concat_out = torch.cat((out1, out2, out3), dim = -1)\n\n#         out = self.linear(  concat_out )\n        \n#         return out\n# model = MultiHeads(fcoarse_reshape_torch, nb_reduced, nb_heads, True )\n# out = model()  \n# print(out.size())","a17f9eaf":"# # V4 OF HEAD; 3 headS attention; dropout\n# # need class OneHeadAttention\n# # generate multi-head of one layer using OneHeadAttention; the nb of heads is fixed and is equal to 3 in this code\n# # # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# # output size: nb batches, time steps, reduced dim (note, equal to the encode dim of one head)\n\n# nb_heads = 3\n# class MultiHeads(nn.Module):\n#     def __init__(self, v, d_reduced, d_head, bo):\n#         super().__init__()\n#         self.v = v\n#         self.head1 = OneHeadAttention(self.v, d_reduced, bo)\n#         self.head2 = OneHeadAttention(self.v, d_reduced, bo)\n#         self.head3 = OneHeadAttention(self.v, d_reduced, bo)\n#         self.linear = nn.Linear(d_reduced*d_head, d_reduced)\n#         self.dropout = nn.Dropout(p = 0.5)\n#     def forward(self):\n#         out1 = self.head1()\n#         out2 = self.head2()\n#         out3 = self.head3()\n# #         out4 = self.head4()\n# #         out5 = self.head5()\n# #         out6 = self.head6()\n#         concat_out = torch.cat((out1, out2, out3), dim = -1)\n\n#         out = self.dropout(self.linear(  concat_out ))\n        \n#         return out\n# model = MultiHeads(fcoarse_reshape_torch, nb_reduced, nb_heads, True )\n# out = model()  \n# print(out.size())","c8f10d4e":"# # version 1 of LAYERS OF TRANSFORMERS: 3 layers transformer\n# # need class MultiHeads\n# # generate many layers; the nb of layers is fixed and is equal to 3\n# # # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# class EncoderLayer(nn.Module):\n#     def __init__(self, v, d_reduced, d_head, d_take):\n#         super().__init__()\n#         self.d_head = d_head\n#         # 3 layers of multiheads \n#         self.d_reduced = d_reduced\n#         self.layer1 = MultiHeads(v, self.d_reduced, self.d_head, True)\n        \n#         self.d_take = d_take\n    \n#     # output dim: (nb_batches, nb_time_steps, encode_dims (d_model) )\n#     def forward(self):\n#         out1 = self.layer1()\n        \n#         self.layer2 = MultiHeads(out1, self.d_reduced, self.d_head, False)\n#         out2 = self.layer2()\n\n#         self.layer3 = MultiHeads(out2, self.d_reduced, self.d_head, False)\n#         out3 = self.layer3()\n#         # out3 size: nb_samples, nb_time_steps, dim\n#         out = out3[:,-self.d_take:,:].view(nb_samples, -1)\n#         return out\n        \n# model = EncoderLayer(fcoarse_reshape_torch, nb_reduced, nb_heads, nb_takes)\n# out = model()  \n","e3cb1257":"# version 2 of LAYERS OF TRANSFORMERS: 1 layers transformer\n# need class MultiHeads\n# generate many layers; the nb of layers is fixed and is equal to 3\n# # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\nclass EncoderLayer(nn.Module):\n    def __init__(self, v, d_reduced, d_head, d_take):\n        super().__init__()\n        self.d_head = d_head\n        # 3 layers of multiheads \n        self.d_reduced = d_reduced\n        self.layer1 = MultiHeads(v, self.d_reduced, self.d_head, True)\n        \n        self.d_take = d_take\n    \n    # output dim: (nb_batches, nb_time_steps, encode_dims (d_model) )\n    def forward(self):\n        out1 = self.layer1()\n        \n        \n        # out3 size: nb_samples, nb_time_steps, dim\n        out = out1[:,-self.d_take:,:].view(nb_samples, -1)\n        return out\n        \nmodel = EncoderLayer(fcoarse_reshape_torch, nb_reduced, nb_heads, nb_takes)\nout = model()  \nprint(\"out\", np.shape(out))","481d15d3":"# # version 1 OF GENERATOR; nb_reduced = 20 and then l1,l2, l3, l4 4 layers of generations to generate from 20, 40, 60, 75\n# # global variables;\n# dim_G1L1 = 20\n# dim_G1L2 = 40\n# dim_G1L3 = 60\n\n# dim_D1L4 = 10\n# dim_D1L5 = 5\n\n\n\n# # output dim: nb samples, dim of reduced encoded\n# # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# class Generator(nn.Module):\n#     def __init__(self, d_reduced, d_head, d_take):\n#         super(Generator, self).__init__()\n#         self.d_reduced = d_reduced\n#         self.d_head = d_head\n#         self.d_take = d_take\n        \n#         self.l1 = nn.Linear(self.d_take*self.d_reduced,  dim_G1L1)\n#         self.l2 = nn.Linear(dim_G1L1,  dim_G1L2)\n#         self.l3 = nn.Linear(dim_G1L2,  dim_G1L3)\n#         self.l4 = nn.Linear(dim_G1L3,  nb_rdm)\n        \n        \n        \n#     def forward(self, v):\n#         self.encode = EncoderLayer(v, self.d_reduced, self.d_head, self.d_take)\n#         encode_out = self.encode()\n#         encode_out = self.l1(encode_out)\n#         encode_out = self.l2(encode_out)\n#         encode_out = self.l3(encode_out)\n#         G1out = self.l4(encode_out)\n                                \n#         return G1out\n\n# # output dim: nb samples,1\n# # input size: nb samples, dim of reduced encoded\n# class Discriminator(nn.Module):\n#     def __init__(self):\n#         super(Discriminator, self).__init__()\n\n#         self.l10 = nn.Linear(nb_rdm,  nb_rdm)\n#         self.l1 = nn.Linear(nb_rdm,  dim_G1L3)\n#         self.l2 = nn.Linear(dim_G1L3,  dim_G1L2)\n#         self.l3 = nn.Linear(dim_G1L2,  dim_G1L1)\n#         self.l31 = nn.Linear(dim_G1L1,  dim_D1L4)\n#         self.l4 = nn.Linear(dim_D1L4,  1)\n        \n#     # input size: nb_samples, nb_basis \n#     def forward(self, x):\n#         x = self.l10(x)\n#         x = self.l1(x)\n#         x = self.l2(x)\n#         x = self.l3(x)\n#         x = self.l31(x)\n#         x = self.l4(x)\n#         x = torch.sigmoid(x)\n        \n#         return x.view(-1, 1)\n\n\n# # model = Generator(fcoarse_reshape_torch, nb_reduced, nb_heads, nb_takes)\n# # Gout = model()  \n# # print(Gout.size())\n# # modelD = Discriminator()\n# # Dout = modelD(Gout)  \n# # print(Dout.size())","a6c23092":"# # version 2 OF GENERATOR; nb_reduced = 40 and then l1,1 layer of generation to generate from 40 to 75\n# # global variables;\n# dim_G1L1 = 20\n# dim_G1L2 = 40\n# dim_G1L3 = 60\n\n# dim_D1L4 = 10\n# dim_D1L5 = 5\n\n\n\n# # output dim: nb samples, dim of reduced encoded\n# # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# class Generator(nn.Module):\n#     def __init__(self, d_reduced, d_head, d_take):\n#         super(Generator, self).__init__()\n#         self.d_reduced = d_reduced\n#         self.d_head = d_head\n#         self.d_take = d_take\n        \n#         self.l1 = nn.Linear(self.d_take*self.d_reduced,  nb_rdm)\n        \n        \n        \n#     def forward(self, v):\n#         self.encode = EncoderLayer(v, self.d_reduced, self.d_head, self.d_take)\n#         encode_out = self.encode()\n#         G1out = self.l1(encode_out)\n                                \n#         return G1out\n\n# # output dim: nb samples,1\n# # input size: nb samples, dim of reduced encoded\n# class Discriminator(nn.Module):\n#     def __init__(self):\n#         super(Discriminator, self).__init__()\n\n#         self.l10 = nn.Linear(nb_rdm,  nb_rdm)\n#         self.l1 = nn.Linear(nb_rdm,  dim_G1L3)\n#         self.l2 = nn.Linear(dim_G1L3,  dim_G1L2)\n#         self.l3 = nn.Linear(dim_G1L2,  dim_G1L1)\n#         self.l31 = nn.Linear(dim_G1L1,  dim_D1L4)\n#         self.l4 = nn.Linear(dim_D1L4,  1)\n        \n#     # input size: nb_samples, nb_basis \n#     def forward(self, x):\n#         x = self.l10(x)\n#         x = self.l1(x)\n#         x = self.l2(x)\n#         x = self.l3(x)\n#         x = self.l31(x)\n#         x = self.l4(x)\n#         x = torch.sigmoid(x)\n        \n#         return x.view(-1, 1)\n\n\n# # model = Generator(fcoarse_reshape_torch, nb_reduced, nb_heads, nb_takes)\n# # Gout = model()  \n# # print(Gout.size())\n# # modelD = Discriminator()\n# # Dout = modelD(Gout)  \n# # print(Dout.size())","5fee71bb":"# version 3 OF GENERATOR; ONE HEAD ONLY; nb_reduced = 75 and then 1 layers of generations to generate from 75 to 75; \n# global variables;\ndim_G1L1 = 20\ndim_G1L2 = 40\ndim_G1L3 = 60\n\ndim_D1L4 = 10\ndim_D1L5 = 5\n\n\n\n# output dim: nb samples, dim of reduced encoded\n# input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\nclass Generator(nn.Module):\n    def __init__(self, d_reduced, d_head, d_take):\n        super(Generator, self).__init__()\n        self.d_reduced = d_reduced\n        self.d_head = d_head\n        self.d_take = d_take\n        \n#         self.l1 = nn.Linear(self.d_take*self.d_reduced,  dim_G1L1)\n#         self.l2 = nn.Linear(dim_G1L1,  dim_G1L2)\n#         self.l3 = nn.Linear(dim_G1L2,  dim_G1L3)\n        self.l4 = nn.Linear(self.d_take*self.d_reduced,  nb_rdm)\n        \n        \n        \n    def forward(self, v):\n        self.encode = EncoderLayer(v, self.d_reduced, self.d_head, self.d_take)\n        encode_out = self.encode()\n        G1out = self.l4(encode_out)\n                                \n        return G1out\n\n# output dim: nb samples,1\n# input size: nb samples, dim of reduced encoded\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.l10 = nn.Linear(nb_rdm,  nb_rdm)\n        self.l1 = nn.Linear(nb_rdm,  dim_G1L3)\n        self.l2 = nn.Linear(dim_G1L3,  dim_G1L2)\n        self.l3 = nn.Linear(dim_G1L2,  dim_G1L1)\n        self.l31 = nn.Linear(dim_G1L1,  dim_D1L4)\n        self.l4 = nn.Linear(dim_D1L4,  1)\n        \n    # input size: nb_samples, nb_basis \n    def forward(self, x):\n        x = self.l10(x)\n        x = self.l1(x)\n        x = self.l2(x)\n        x = self.l3(x)\n        x = self.l31(x)\n        x = self.l4(x)\n        x = torch.sigmoid(x)\n        \n        return x.view(-1, 1)\n\n\n# model = Generator(fcoarse_reshape_torch, nb_reduced, nb_heads, nb_takes)\n# Gout = model()  \n# print(Gout.size())\n# modelD = Discriminator()\n# Dout = modelD(Gout)  \n# print(Dout.size())","7200002f":"# version 4 OF GENERATOR; ONE or THREE HEADs; nb_reduced = 75 and then 2 layers of generations to generate from 75 to 75, I.E., 75-->75-->75; CORESP TO V2 OF HEAD\n# global variables;\ndim_G1L1 = 20\ndim_G1L2 = 40\ndim_G1L3 = 60\n\ndim_D1L4 = 10\ndim_D1L5 = 5\n\n\n\n# output dim: nb samples, dim of reduced encoded\n# input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\nclass Generator(nn.Module):\n    def __init__(self, d_reduced, d_head, d_take):\n        super(Generator, self).__init__()\n        self.d_reduced = d_reduced\n        self.d_head = d_head\n        self.d_take = d_take\n        \n#         self.l1 = nn.Linear(self.d_take*self.d_reduced,  dim_G1L1)\n#         self.l2 = nn.Linear(dim_G1L1,  dim_G1L2)\n#         self.l3 = nn.Linear(dim_G1L2,  dim_G1L3)\n        self.l4 = nn.Linear(self.d_take*self.d_reduced,  nb_rdm)\n        self.l5 = nn.Linear(nb_rdm,  nb_rdm)\n        \n        \n        \n    def forward(self, v):\n        self.encode = EncoderLayer(v, self.d_reduced, self.d_head, self.d_take)\n        encode_out = self.encode()\n        encode_out = self.l4(encode_out)\n        G1out = self.l5(encode_out)\n                                \n        return G1out\n\n# output dim: nb samples,1\n# input size: nb samples, dim of reduced encoded\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.l10 = nn.Linear(nb_rdm,  nb_rdm)\n        self.l1 = nn.Linear(nb_rdm,  dim_G1L3)\n        self.l2 = nn.Linear(dim_G1L3,  dim_G1L2)\n        self.l3 = nn.Linear(dim_G1L2,  dim_G1L1)\n        self.l31 = nn.Linear(dim_G1L1,  dim_D1L4)\n        self.l4 = nn.Linear(dim_D1L4,  1)\n        \n    # input size: nb_samples, nb_basis \n    def forward(self, x):\n        x = self.l10(x)\n        x = self.l1(x)\n        x = self.l2(x)\n        x = self.l3(x)\n        x = self.l31(x)\n        x = self.l4(x)\n        x = torch.sigmoid(x)\n\n        return x.view(-1, 1)\n\n\n\n# model = Generator(fcoarse_reshape_torch, nb_reduced, nb_heads, nb_takes)\n# Gout = model()  \n# print(Gout.size())\n# modelD = Discriminator()\n# Dout = modelD(Gout)  \n# print(Dout.size())","8c0e5659":"# # version 5 OF GENERATOR; ONE or THREE HEADs; nb_reduced = 75 and then 2 layers of generations to generate from 75 to 75, I.E., 75-->75-->75; CORESP TO V2 OF HEAD\n# # dropout at generator and combining heads \n# # global variables;\n# dim_G1L1 = 20\n# dim_G1L2 = 40\n# dim_G1L3 = 60\n\n# dim_D1L4 = 10\n# dim_D1L5 = 5\n\n\n\n# # output dim: nb samples, dim of reduced encoded\n# # input dim: (500, 15, 99, 99) nb samples, nb time steps, a-1, b-1\n# class Generator(nn.Module):\n#     def __init__(self, d_reduced, d_head, d_take):\n#         super(Generator, self).__init__()\n#         self.d_reduced = d_reduced\n#         self.d_head = d_head\n#         self.d_take = d_take\n        \n# #         self.l1 = nn.Linear(self.d_take*self.d_reduced,  dim_G1L1)\n# #         self.l2 = nn.Linear(dim_G1L1,  dim_G1L2)\n# #         self.l3 = nn.Linear(dim_G1L2,  dim_G1L3)\n#         self.l4 = nn.Linear(self.d_take*self.d_reduced,  nb_rdm)\n#         self.l5 = nn.Linear(nb_rdm,  nb_rdm)\n#         self.dropout = nn.Dropout(p = 0.5)\n        \n        \n#     def forward(self, v):\n#         self.encode = EncoderLayer(v, self.d_reduced, self.d_head, self.d_take)\n#         encode_out = self.encode()\n#         encode_out = self.dropout(self.l4(encode_out))\n#         G1out = self.dropout(self.l5(encode_out))\n                                \n#         return G1out\n\n# # output dim: nb samples,1\n# # input size: nb samples, dim of reduced encoded\n# class Discriminator(nn.Module):\n#     def __init__(self):\n#         super(Discriminator, self).__init__()\n\n#         self.l10 = nn.Linear(nb_rdm,  nb_rdm)\n#         self.l1 = nn.Linear(nb_rdm,  dim_G1L3)\n#         self.l2 = nn.Linear(dim_G1L3,  dim_G1L2)\n#         self.l3 = nn.Linear(dim_G1L2,  dim_G1L1)\n#         self.l31 = nn.Linear(dim_G1L1,  dim_D1L4)\n#         self.l4 = nn.Linear(dim_D1L4,  1)\n        \n#     # input size: nb_samples, nb_basis \n#     def forward(self, x):\n#         x = self.l10(x)\n#         x = self.l1(x)\n#         x = self.l2(x)\n#         x = self.l3(x)\n#         x = self.l31(x)\n#         x = self.l4(x)\n#         x = torch.sigmoid(x)\n\n#         return x.view(-1, 1)\n\n\n\n# # model = Generator(fcoarse_reshape_torch, nb_reduced, nb_heads, nb_takes)\n# # Gout = model()  \n# # print(Gout.size())\n# # modelD = Discriminator()\n# # Dout = modelD(Gout)  \n# # print(Dout.size())","966e4d14":"# prepare the training\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nu_H_torch = torch.tensor(u_H, dtype=torch.float32, device = device)\nfcoarse_reshape_torch = torch.tensor(fcoarse_reshape, dtype=torch.float32, device = device)\n\nlr = 0.0003\nbeta1 = 0.5\n\nnetG = Generator(nb_reduced, nb_heads, nb_takes).to(device)\nnetD = Discriminator().to(device)\n\ncriterion = nn.BCELoss()\n\noptimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n","78496d53":"# train D to get a better D first\nepochs = 100\nfor ep in range(epochs):\n    ############################\n    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n    ###########################\n    # train D with real; input u_H dim: batch size, nb basis\n    netD.zero_grad()\n    labels = torch.full((nb_samples, 1), 1, device=device)\n    \n    output = netD(u_H_torch)\n    errD_real = criterion(output, labels)\n    errD_real.backward()\n    # the average output (across the batch) of the discriminator for the all real batch. \n    # This should start close to 1 then theoretically converge to 0.5 when G gets better. \n    D_x = output.mean().item()\n    \n    # train with fake\n    fake = netG(fcoarse_reshape_torch)\n    labels.fill_(0)\n    # detach will reqiure NO gradient\n    \n    output = netD(fake.detach())\n    errD_fake = criterion(output, labels)\n    errD_fake.backward()\n    D_G_z1 = output.mean().item()\n    errD = errD_real + errD_fake\n    optimizerD.step()\n    \n    if ep % 10 == 0:\n        print('[%d] Loss_D: %.4f D(x): %.4f D(G(z)): %.4f'\n                  % (ep, errD.item(), D_x, D_G_z1))","c617a600":"# training\nepochs = 2500\nloss_D_set = []\nloss_G_set = []\nfor ep in range(epochs):\n    ############################\n    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n    ###########################\n    # train D with real; input u_H dim: batch size, nb basis\n    netD.zero_grad()\n    labels = torch.full((nb_samples, 1), 1, device=device)\n    output = netD(u_H_torch)\n    errD_real = criterion(output, labels)\n    errD_real.backward()\n    # the average output (across the batch) of the discriminator for the all real batch. \n    # This should start close to 1 then theoretically converge to 0.5 when G gets better. \n    D_x = output.mean().item()\n    \n    # train with fake\n    \n    fake = netG(fcoarse_reshape_torch)\n    labels.fill_(0)\n    # detach will reqiure NO gradient\n    output = netD(fake.detach())\n    errD_fake = criterion(output, labels)\n    errD_fake.backward()\n    D_G_z1 = output.mean().item()\n    errD = errD_real + errD_fake\n    loss_D_set.append(errD.item())\n    optimizerD.step()\n    \n    ############################\n    # (2) Update G network: maximize log(D(G(z)))\n    ###########################\n    netG.zero_grad()\n    labels.fill_(1)  # fake labels are real for generator cost\n    # Since we just updated D, perform another forward pass of all-fake batch through D    \n    # Calculate G's loss based on this output\n    output = netD(fake)\n    errG = criterion(output, labels)\n    loss_G_set.append(errG.item())\n    errG.backward()\n    # average discriminator outputs for the all fake batch. \n    # The first number is before D is updated and the second number is after D is updated. \n    # These numbers should start near 0 and converge to 0.5 as G gets better. \n    D_G_z2 = output.mean().item()\n    \n    optimizerG.step()\n\n    if ep % 100 == 0:\n        print('[%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f \/ %.4f'\n                  % (ep, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","6103c72f":"plt.plot(loss_D_set)\nplt.show()\nplt.plot(loss_G_set)\nplt.show()","5ec23a69":"outG = np.array(netG(fcoarse_reshape_torch).detach())\nplt.plot(u_H[100,:], \"r-\")\nplt.plot(outG[100,:], \"b-\")","6344116e":"print(\"L1 norm training\", np.mean(LA.norm(u_H-outG, axis = 1, ord = 1)))\nprint(\"L2 norm training\", np.mean(LA.norm(u_H-outG, axis = 1)))","d57227f8":"u_H_test_torch = torch.tensor(u_H_test, dtype=torch.float32, device = device)\nfcoarse_reshape_test_torch = torch.tensor(fcoarse_reshape_test, dtype=torch.float32, device = device)\noutG_test = np.array(netG(fcoarse_reshape_test_torch).detach())\nprint(\"L1 norm testing\", np.mean(LA.norm(u_H_test-outG_test, axis = 1, ord = 1)))\nprint(\"L2 norm testing\", np.mean(LA.norm(u_H_test-outG_test, axis = 1)))","02a0ce7b":"1. $6$ heads, $1$ layer and nb of reduced is equal to $20$. \n$L_1$ norm testing $5.943024160929824$\n$L_2$ norm testing $0.843793466442161$\n\n2. $3$ heads, $1$ layer and nb of reduced is equal to $40$; then $40, 60, 75$.\nL1 norm testing 3.6575742146939154\nL2 norm testing 0.5693827955547961\n\n3. $3$ heads, $1$ layer and nb of reduced is equal to $40$; then $40, 50, 60, 70, 75$.\nL1 norm testing 5.892637887206401\nL2 norm testing 0.8733909057241649\n\n4. $1$ head, $1$ layer and nb of reduced is equal to $75$; then ONE LAYER $75, 75$.\nL1 norm testing 4.457730482973083\nL2 norm testing 0.7144304588711031\n\n4.1 $6$ head (difference with 4), $1$ layer and nb of reduced is equal to $75$; then ONE LAYER $75, 75$.\nCompare to 4; the training is not good; seems that longer training will make this better\nL1 norm training 3.3722966909764525\nL2 norm training 0.5721519362195117\n\n5. $1$ head, $1$ layer and nb of reduced is equal to $75$; then TWO LAYER $75-->75-->75$.\nL1 norm testing 3.545499672931557\nL2 norm testing 0.549414816966618\n\n6. $3$ head, $1$ layer and nb of reduced is equal to $75$; then TWO LAYER $75-->75-->75$.\nL1 norm testing 3.237379606326087\nL2 norm testing 0.4942014560515833\n\n7. $3$ head, $1$ layer and nb of reduced is equal to $75$; then TWO LAYER $75-->75-->75$.\nReLUs are used at combining heads and frist 75 ---> 75 linear layer\nL1 norm testing 3.376117860343691\nL2 norm testing 0.5087644974323288\n\n8. $3$ head, $1$ layer and nb of reduced is equal to $75$; then TWO LAYER $75-->75-->75$.\ndropouts are used at combining heads and frist 75 ---> 75 linear layer\nL1 norm testing 8.110079345427293\nL2 norm testing 1.4909529028322355\nNot sure if failed due to the mis-use of the dropout function\n\n\n7. $3$ head, $1$ layer and nb of reduced is equal to $75$; \ntwo layers after concat; from d_reduced*d_head ---> 2*d_reduced ---> d_reduced\nthen TWO LAYER $75-->75-->75$\n\nReLUs are used at combining heads and frist 75 ---> 75 linear layer\nL1 norm testing 3.1449419005253083\nL2 norm testing 0.5011790415401082\n\n8.$3$ head, $1$ layer and nb of reduced is equal to $75$; compared to 7 (pooling are different)\ntwo layers after concat; from d_reduced*d_head ---> 2*d_reduced ---> d_reduced\n\nthen TWO LAYER $75-->75-->75$\nAVERAGE POOL (difference with 7)\nL1 norm testing 3.1958206570736762\nL2 norm testing 0.5000293122129135\n\n4.2 $6$ head (difference with 4), $1$ layer and nb of reduced is equal to $75$; then ONE LAYER $75, 75$.\nCompare to 4; the training is not good; seems that longer training will make this better; 2000 epochs \nL1 norm testing 2.949004405407101\nL2 norm testing 0.4740920027359995\n\n9. 6 heads; concate from 6*75--->3*75--->2*75--->1*75; one layer afterwards (75*75)\nL1 norm testing 3.766360662973743\nL2 norm testing 0.6293451880682172\n\n9.1\n6 heads; concate from 6*75--->3*75--->2*75--->1*75; one layer afterwards (75*75) 2000 epochs (ReLU)\nL1 norm testing 3.5053833140001087\nL2 norm testing 0.5474841715679664\n\n\n10. $6$ head (difference with 4), $1$ layer and nb of reduced is equal to $75$; then two LAYERs of  $75, 75$. 2500 epochs\nconverges fast; the diff with a slow converg one is the addition layer of 75, 75; but this one converges fast but result is not that good\nL1 norm testing 3.9214912109647058\nL2 norm testing 0.5774703958037964\n\n\nFailed\n1. $3$ head, $1$ layer and nb of reduced is equal to $75$; then TWO LAYER $75-->75-->75$. \nNormalization added to the discriminator; the training for both D(pretraing) and G are dead.\n\nConclusion:\n1. nb_reduced should be relative larger\n2. generation layers are relatively more important\n3. nb of heads also makes sense\n\n\n\n\n"}}