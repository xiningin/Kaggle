{"cell_type":{"d72b83b7":"code","e7389340":"code","234d7036":"code","dc6c4d4c":"code","5bd4eeef":"code","cf8c3bc5":"code","821236b5":"code","fd1d16e0":"code","5fd36ee2":"code","deb3a9ef":"code","2915f428":"code","9982e3cc":"code","b134db46":"code","d49fff5a":"markdown","f4006c03":"markdown"},"source":{"d72b83b7":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom fastai.vision.all import *\nfrom fastai.callback.hook import *","e7389340":"path = untar_data(URLs.CIFAR)","234d7036":"Path.BASE_PATH = path","dc6c4d4c":"path.ls()","5bd4eeef":"def get_dls(bs=64):\n    return DataBlock(\n    blocks = (ImageBlock(cls=PILImageBW), CategoryBlock),\n    get_items = get_image_files,\n    splitter = GrandparentSplitter(\"train\",\"test\"),\n    get_y = parent_label,\n    batch_tfms = Normalize()\n    ).dataloaders(path, bs=bs)","cf8c3bc5":"dls = get_dls()","821236b5":"dls.show_batch(max_n=16, figsize=(12,12))","fd1d16e0":"def conv(ni,nf,ks=3,act=True):\n    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks\/\/2)]\n    if act: layers.append(nn.ReLU())\n    layers.append(nn.BatchNorm2d(nf))\n    return nn.Sequential(*layers)","5fd36ee2":"def simple_cnn():\n    return sequential(\n    conv(1,8, ks=5),\n    conv(8,16),\n    conv(16,32),\n    conv(32,64),\n    conv(64,10, act=False),\n    Flatten()\n    )\n\ndef fit(epochs=1, lr=0.06):\n    learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,\n                   metrics=accuracy, cbs=ActivationStats(with_hist=True))\n    learn.fit_one_cycle(epochs, lr)\n    return learn","deb3a9ef":"learn = fit()","2915f428":"learn.recorder.plot_sched()","9982e3cc":"learn.activation_stats.color_dim(-4)","b134db46":"learn = fit(20, lr=0.11)","d49fff5a":"This notebook refferred to the following notebook.<br\/>\nhttps:\/\/www.kaggle.com\/stanislaurybachkin\/mnist-fast-ai","f4006c03":"# CIFAR10 fastai"}}