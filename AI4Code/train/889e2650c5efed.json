{"cell_type":{"ca66a338":"code","de568ea8":"code","1f02bc77":"code","2e55fb4c":"markdown","589e303b":"markdown","b165e284":"markdown","37f833b6":"markdown","a5cbbc16":"markdown","242f330f":"markdown","f0cf633d":"markdown","fb6681b8":"markdown","87b0bd0e":"markdown","ab38a3d6":"markdown","0967d1a5":"markdown","e3e26e7a":"markdown","3a309927":"markdown","b4425d3a":"markdown","b31d2dfb":"markdown","a51b4e87":"markdown","03404515":"markdown","659595c5":"markdown","e4321a2d":"markdown","92c09ebf":"markdown","3c246c04":"markdown","af90a3ea":"markdown","8d100395":"markdown","16e633ba":"markdown","33c983de":"markdown","f53dbc11":"markdown","e65e61ef":"markdown","52226f1b":"markdown","c6dc2453":"markdown","380670fc":"markdown","ffd566f7":"markdown","2249f46e":"markdown","6ab68c84":"markdown","b30c18bd":"markdown","565c0666":"markdown","6655b25f":"markdown","21e0ac61":"markdown","9f015c0f":"markdown","4f632286":"markdown","bfb8d8e0":"markdown","50193891":"markdown","2513e776":"markdown","f5dadf1a":"markdown","3843f390":"markdown","aecdfe91":"markdown"},"source":{"ca66a338":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.bar(['0', '1'], [0.35, 0.65])","de568ea8":"import seaborn\nfrom scipy.stats import binom\ndata=binom.rvs(n=17,p=0.7,loc=0,size=1010)\nax=seaborn.distplot(data,kde=True,color='pink',hist_kws={\"linewidth\": 22,'alpha':0.77})\nax.set(xlabel='Binomial',ylabel='Frequency')","1f02bc77":"import numpy as np\nsum(np.random.binomial(9, 0.1, 20000) == 0)\/20000","2e55fb4c":"Python binomial distribution tells us the probability how often there will be a success in \u2018n\u2019 independent experiments. Such experiments are yes-no questions. One example may be tossing a coin.","589e303b":"# Z-stat vs T-stat<a id=\"13\"><\/a>","b165e284":"### Standard Normal Distribution","37f833b6":"We get mean as 3, variance =  1.49 & standard deviation as 1.22 i.e., N ~ (3, 1.49). Now we will subtract the mean from every the data points, that is, x \u2013 \u03bc.\n\nWe will get a new data set mentioned below:\n\nX1 = {-2, -1, -1, 0, 0, 1, 1 ,1, 2,2} \u03bc as 0, but the variance and std dev still as 1.49 and 1.22 respectively i.e., N ~ (0, 1.49)\n\nSo in the next step of standardization, dividing all data points by the standard deviation, i.e., (x \u2013 \u03bc)\/\u03c3\n\nDividing each datapoint by 1.22(standard deviation) we get a new data set as :\n\nX2 = {-1.6, -0.82,  0, 0.82, 0, , 0.82,0,0.82, 0.82, 0 and 1.63.}\nNow if we calculate the mean as 1 i.e., N ~ (0, 1)","a5cbbc16":"- [Probability Density Function](#10)\n      Normal Distribution\n      Bernoulli\u2019s Distribution\n      Binomial Distribution\n      Uniform Distribution\n      Student\u2019s T Distribution\n      Poisson Distribution\n- [Z stat](#11)\n- [Hypothesis Testing](#12)\n- [Z-stats vs T-stats](#13)","242f330f":"# Hypothesis testing<a id=\"12\"><\/a>","f0cf633d":"### Question: \nA company drills 9 wild-cat oil exploration wells, each with an estimated probability of success of 0.1. What is the probability that all nine wells fail? \n### Solution:\nLet\u2019s do 20,000 trials of the model, and count the number that generates zero positive results.","fb6681b8":"**Note:** Suppose a binomial experiment consists of n trials and results in x successes. If the probability of success on an individual trial is \u2018P\u2019, binomial probability:\n\n#### b(x; n, P) = nCx * Px * ( \u20181\u2019 \u2013 P )n - x","87b0bd0e":"The z-score is calculated using the formula:\n\n            z = (X-\u03bc)\/\u03c3\n            \n**Where:**\n\n\u2022\t\u03c3 is the population standard deviation and\n\n\u2022\t\u03bc is the population mean.\n\nNote: The t-score is calculated using the formula:\n\n   T =  (X \u2013 \u03bc) \/ [ S\/\u221a(n) ]\n   \nWhere the standard deviation of the sample is S.\n\nNote: Like z-scores, t-scores are also a conversion of individual scores into a standard form. However, t-scores are used when you don\u2019t know the population standard deviation. You estimate by using your sample.","ab38a3d6":"Since the area under the curve must be equal to 1, and the length of the interval determines the height of the curve, the following figure shows a uniform distribution (a,b). \n\nNote that since the area needs to be 1. The height is set to 1\/(b\u2212a)1\/(b\u2212a).","0967d1a5":"![image.png](attachment:image.png)","e3e26e7a":"**When to use a t-tests vs. z-tests**\n\nthe t-test can be used when your sample:\n\n* Has a sample size below 30,\n* Has an unknown population standard deviation.\n\n![image.png](attachment:image.png)\n","3a309927":"## 2. Bernoulli Distribution<a id=\"222\"><\/a>","b4425d3a":"![image.png](attachment:image.png)","b31d2dfb":"Understanding Standardization in the context of statistics. Every distribution can be standardized. Let say if the mean and variance of a variable are \u03bc and \u03c32, respectively.\n\nStandardization is the process of transforming the distribution to one with a mean of 0 and a standard deviation of 1.\n\ni.e., ~(\u03bc, \u03c32 ) \u2192 ~ (0, 1)\n\nWhen a Normal Distribution is standardized, a result is called a Standard Normal Distribution.\n\ni.e., N~(\u03bc, \u03c32 ) \u2192 ~ N(0, 1)\nWe use the following formula for standardization:\n\n![image.png](attachment:image.png)","a51b4e87":"## 5. Poisson distribution <a id=\"555\"><\/a>","03404515":"**EXAMPLE:** \n\n\u2022\tIf we roll a die(numbered 1 to 8), then the probability of getting 1 is one out of 8.\n\n\u2022\tSimilarly, the probability of getting 2 to 6 is 1\/6. There is an equal chance to get each of 8 results (outcomes).","659595c5":"Let us understand the steps in Standardization with the help of a simple example.\n\nSuppose we have a dataset with elements\nX = {1,1,1,2,2,2,3,3,4,4,4,4,5}\nAnd uniformly distributed as:\n\n![image.png](attachment:image.png)","e4321a2d":"# Probability Density Function<a id=\"10\"><\/a>","92c09ebf":"## 1. Normal Distribution (Gaussian Distribution)<a id=\"111\"><\/a>\nNormal Distribution is one of the most common continuous probability distribution. This type of distribution is important in statistics and is often used to represent random variables whose distribution is not known.\n\nThis type of distribution is symmetric, and it's mean, median, and mode are equal.\n\nMathematically, Gaussian Distribution is represented as:\n\n                               N~(\u03bc, \u03c32 )\n                           \nWhere N stands for Normal, symbol ~ for distribution, whereas symbol \u03bc stands for mean and \u03c32 stands for the variance.\n![image.png](attachment:image.png)","3c246c04":"## 4. Uniform Distribution<a id=\"444\"><\/a>","af90a3ea":"Note: A z-test tells you how many standard deviations away from the mean your result is. You can use the z-table to determine what percentage of the population will fall below or above your result.","8d100395":"The cumulative distribution function (CDF) of a random variable is another method to describe the distribution of random variables.\n\nThe cumulative frequency is the sum of the frequencies. Cumulative frequency starts at the frequency of the 1st brand, and then we add the 2nd, then 3rd, and so on until it finishes 100%. For all kinds of random variables (discrete, continuous, and mixed), CDF can be defined.","16e633ba":"Using this standardized normal distribution makes inferences & predictions much easier.","33c983de":"Where x is a data element, \u03bc is mean & \u2018\u03c3\u2019 is the standard deviation, and Z is used to denote standardization, and Z is known as the z-score.\nWith the help of Z scores, we can come to know how far a value is from the mean. When you standardize a random variable, its \u03bc becomes 0, and its standard deviation becomes 1.\nIf the Z score of x is 0, then the value of x is equal to the mean.","f53dbc11":"![image.png](attachment:image.png)","e65e61ef":"**Z-tests**\n\n*  With the help of z-score, we can come to know how far the data point is from the mean in the standard deviation.\n A z-test compares a sample to a defined population and is typically used for dealing with problems relating to larger samples (n > 30).\n Z-score can also be used to test the hypothesis, and if the standard deviation is known, then it is beneficial.\n \n**T-tests**\n\n* Similar to the z-tests, t-tests are also used to test a hypothesis, but it is most useful when there is a need to know the significant difference between 2 independent sample groups.\n* In other words, the t-test asks whether the difference between the means of two groups is unlikely to have occurred because of the random chance. Usually, t-tests are the most appropriate when dealing with problems with a limited sample size (n < 30).","52226f1b":"### Empirical Formula\nThe empirical rule states that for the Normal Distribution, nearly all of the data will fall within three range of standard deviations of a mean. The empirical rule can be understood through the following:\n- 68% of the data falls within the 1st standard deviation from the mean.\n- 95% fall within two standard deviations.\n- 99.7% fall within three standard deviations.","c6dc2453":"A Probability Distribution is a mathematical function through which the probability of occurrence of different possible outcomes in an experiment can be calculated.\nIf the probability of an event is higher, it\u2019s more likely that the event will occur.\n\n**For Example:**\n\nWhile tossing a fair (unbiased) coin, there could be a chance of the possibility of two outcomes (\u201cheads\u201d and \u201ctails\u201d), which are equally probable. \n\nThe probability of getting a head or a tail is 50 % or 0.5.\n\n## Types of the probability distribution\n\nThere are many different types of probability distribution. Some of them which we will be covering in this blog are listed below:\n1. [Normal Distribution](#111)\n2. [Bernoulli\u2019s Distribution](#222)\n3. [Binomial Distribution](#333)\n4. [Uniform Distribution](#444)\n5. [Poisson Distribution](#555)\n\n**Expected value**\n\n-\tE(C) = C\n\nThe Expected Value of a Constant is only a value of a constant.\n\n-\tE (X + C) = E(X) + C\n-   E(CX) = cE(X)\n\nWe can \u201cpull\u201d a constant out of an expected value expression as a part of a sum with a random variable X.","380670fc":"![image.png](attachment:image.png)","ffd566f7":"## 3. Binomial Distribution<a id=\"333\"><\/a>\nThe binomial distribution is used when there is more than one outcome of a trial. These outcomes are labeled as \u201cSuccess\u201d and \u201cFailure.\u201d\nHere, the probability of both outcomes is the same for all the trials.\nEach trial is independent. The parameters of a binomial distribution are p and n, where p is the probability of success in the individual trial, and n is the total number of trials.","2249f46e":"![image.png](attachment:image.png)","6ab68c84":"Let us understand this with the easiest example where we can have the random variable X with distribution:\n\nX = {1, 2, 3, 4, 5}\n\nWhen we take the mean and the standard deviation of the above data set, we get mean(\u03bc) = 3 and standard deviation(\u03c3) = 1. \n\nWhen we plot it, we get a few distributions like this mentioned below:\n\n![image.png](attachment:image.png)\n\nThis Bell curve specifies the Gaussian distribution.","b30c18bd":"### Cumulative Density Function","565c0666":"Bernoulli distribution is a discrete probability distribution of a random variable that has only two outcomes., namely 1 (success) and 0 (failure). where n = 1 occurs with probability p and n = 0 (usually called a \u201cfailure\u201d) occurs with probability q = 1 \u2013 p, where 0 < p < 1.\n\nTherefore, the probability density function(PDF) & the graph for Bernoulli\u2019s Distribution is shown in the figure below:\n![image.png](attachment:image.png)","6655b25f":"![image.png](attachment:image.png)","21e0ac61":"In the above diagram, 1 refers to \u2018success\u2019 & 0 refers to the failure. The head and tail distribution in tossing a coin is an example of Bernoulli\u2019s Distribution with p = q = \u00bd.\n\nFor example, probability (p) of scoring a goal in the last 10 minutes is 0.35 (success); the probability of not scoring a goal in the previous 10 minutes (failure) is 1 - p = 0.65.\n\nPlotting Bernoulli distribution with probability for p = 0.65","9f015c0f":"- 99.7% fall within three standard deviations.\n\n\n- Approximately 68% of  the data falls within one standard deviation of a mean In mathematical notation, this is represented as \u03bc \u00b1 1\u03c3\n- \tAbout 95% of the data falls within 2 standard deviations of the mean (i.e., between the mean \u2013 2 times the standard deviation, & mean + 2 times the standard deviation). The mathematical notation for this is: \u03bc \u00b1 2\u03c3\n- \tApproximately 99.7% of the data lies in 3 standard deviation of a mean (i.e., between the mean \u20133 times the standard deviation and the mean + 3 times the standard deviation).\n- \tThe following notation is used to represent: \u03bc \u00b1 3\u03c3\n\nThe Empirical Rule is often used to forecast when obtaining the right data is difficult or impossible to get.","4f632286":"### Probability Density Function and Mass Function","bfb8d8e0":"![image.png](attachment:image.png)","50193891":"![image.png](attachment:image.png)","2513e776":"Probability density function and Probability mass function defines a Probability Distribution for a random variable.\nIf we know the variance and the mean of the dataset, then we can calculate the PDF and PMF. PDF and PMF tell how well data is distributed around mean and standard deviation within a particular curve.","f5dadf1a":"The probability distribution function of the continues uniform distribution:","3843f390":"Plotting it on a graph :\n\n![image.png](attachment:image.png)","aecdfe91":"# Z stat <a id=\"11\"><\/a>"}}