{"cell_type":{"5f5d442e":"code","c35cc416":"code","50462561":"code","c6883824":"code","afce8b8d":"code","26200180":"code","b394adda":"code","56654cb0":"code","c190bdf2":"code","687152df":"code","108f415d":"code","7549113d":"code","449679ca":"code","6f86299f":"code","e3824655":"code","4d066ba4":"code","64f44af4":"code","d48581ac":"code","fd5f07d1":"code","40ca368c":"code","e665030c":"code","25f125a7":"code","ac3f158d":"code","d7d5ce3d":"code","9aa33909":"code","d556a070":"code","21c4c034":"code","0930a48b":"code","ef2b7478":"code","38106106":"code","0be55f97":"code","215d278e":"code","8752c4c6":"code","94f67c29":"code","5748ee0b":"code","6d78fa1f":"code","c3fb9949":"code","b9823529":"code","1378f7a5":"code","7e463a8d":"code","e6b53d9d":"code","7ba7a590":"code","34c9c8a8":"code","09bf718d":"code","9382860b":"markdown","423b94bd":"markdown","2cec4a6d":"markdown"},"source":{"5f5d442e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom warnings import filterwarnings as filt\n\nfilt('ignore')\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (12,6)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c35cc416":"base_dir = \"\/kaggle\/input\/music-genre-classification\/\"\ntraindf = pd.read_csv(f'{base_dir}train.csv')\ntestdf = pd.read_csv(f'{base_dir}test.csv')","50462561":"traindf.head()","c6883824":"traindf['Artist Name'].value_counts()","afce8b8d":"y_train = traindf.Class\ntraindf = traindf.drop(['Class'], axis = 1)\ntrainIdx, testIdx = traindf.shape[0], testdf.shape[0]\ndf = pd.concat([traindf, testdf])\ndf.head()","26200180":"df.shape","b394adda":"null_feats = pd.DataFrame(df.isnull().sum(), columns = ['nans']).sort_values('nans', ascending = False)\nnull_feats['nans %'] = np.round(df.isnull().sum() \/ df.shape[0], 2)\nnull_feats.head()","56654cb0":"nulls = null_feats.index[:3]\nsns.kdeplot(df[nulls[0]])","c190bdf2":"sns.kdeplot(df[nulls[1]])","687152df":"sns.kdeplot(df[nulls[2]])","108f415d":"df[nulls].describe()","7549113d":"df[nulls] = df[nulls].fillna(df[nulls].mean())","449679ca":"df.isnull().sum()","6f86299f":"df.head()","e3824655":"df.groupby('Artist Name')['Popularity'].mean().sort_values(ascending = False).head(10)","4d066ba4":"df[df['Artist Name'] == 'The Weeknd, Ariana Grande']","64f44af4":"df['Solo'] = df['Artist Name'].apply(lambda x : 0 if len(x.split(',')) > 1 else 1 )\ndf.head()","d48581ac":"sns.kdeplot(df.loudness)","fd5f07d1":"import eli5\nfrom eli5.sklearn import PermutationImportance\nfrom pdpbox import pdp\nfrom sklearn.ensemble import RandomForestClassifier as rfc \nimport shap\n\ndef pdp_plot(col, val_x, val_y):\n    val_x = val_x.select_dtypes(exclude = 'object')\n    model = rfc(n_estimators = 100,random_state = 123).fit(val_x, val_y)\n    isolate = pdp.pdp_isolate(model, dataset= val_x, feature = col, model_features = val_x.columns)\n    pdp.pdp_plot(isolate, col);\n    \ndef pdp_interact(cols, val_x, val_y):\n    val_x = val_x.select_dtypes(exclude = 'object')\n    model = rfc(n_estimators = 100,random_state = 123).fit(val_x, val_y)\n    interact = pdp.pdp_interact(model, dataset= val_x, features=cols, model_features = val_x.columns)\n    pdp.pdp_interact_plot(interact, cols, plot_type='contour');\n            \ndef permImp(val_x, val_y):\n    val_x = val_x.select_dtypes(exclude = 'object')\n    model = rfc(n_estimators = 100,random_state = 123).fit(val_x, val_y)\n    perm = PermutationImportance(model).fit(val_x, val_y)\n    return eli5.show_weights(perm, feature_names = val_x.columns.tolist())\n\ndef force_plot(x_train, y_train, val_x):\n    x_train = x_train.select_dtypes(exclude = 'object')\n    val_x = val_x.select_dtypes(exclude = 'object')\n    model = rfc(n_estimators = 100,random_state = 123).fit(x_train, y_train)\n    explainer = shap.TreeExplainer(model)\n    samp = val_x.sample(n = 1)\n    shap_values = explainer.shap_values(samp)\n    return shap.force_plot(explainer.expected_value[-1], shap_values[-1], samp)\n    \ndef train_val_split(x, y, test_size = 0.2):\n    idx = x.sample(frac = test_size).index\n    x_test, y_test = x.iloc[idx], y.iloc[idx]\n    x_train, y_train = x.drop(idx), y.drop(idx)\n    return x_train, x_test, y_train, y_test\n    ","40ca368c":"x = df.reset_index(drop = True).iloc[:trainIdx]\nx_test = df.reset_index(drop = True).iloc[trainIdx: ]","e665030c":"train_x, val_x, train_y, val_y = train_val_split(x, y_train)\ntrain_x.shape, val_x.shape, train_y.shape, val_y.shape","25f125a7":"permImp(val_x, val_y)","ac3f158d":"pdp_plot('duration_in min\/ms', val_x, val_y)","d7d5ce3d":"classes = pd.read_csv(f\"{base_dir}submission.csv\").columns\nclasses = {key : val.split('_')[0] for key, val in enumerate(classes)}\nclasses","9aa33909":"pdp_interact(['duration_in min\/ms', 'Solo'], val_x, val_y)","d556a070":"shap.initjs()\nforce_plot(train_x, train_y, val_x)","21c4c034":"from scipy.stats import norm, skew\ndef plot(df, rc, kind = 'dist'):\n    fig, ax = plt.subplots(rc[0],rc[1])\n    fig.tight_layout()\n    cols = df.columns\n    ind = 0\n    for r in range(rc[0]):\n        for c in range(rc[1]):\n            if ind >= len(cols): break\n            x = df[cols[ind]]\n            if kind == 'dist':\n                sns.distplot(x, ax = ax[r,c], fit = norm)\n            elif kind == 'box':\n                sns.boxplot(x, ax = ax[r, c])\n            ind += 1","0930a48b":"train_x.head()","ef2b7478":"feats = [c for c in train_x.select_dtypes(exclude = 'object').columns if train_x[c].nunique() >= 10]\nplot(train_x[feats], [4,3])","38106106":"plot(train_x[feats], [4,3], 'box')","0be55f97":"def skew_score(df) : \n    df = df.select_dtypes(exclude = 'object')\n    return pd.DataFrame(np.abs(skew(df)), index = df.columns, columns = ['skew_score']).sort_values('skew_score', ascending = False)","215d278e":"skews = skew_score(train_x)\nhigh_skew_feats = skews[skews.skew_score > 0.5].index\nskews[skews.skew_score > 0.5]","8752c4c6":"train_artist_name, val_artist_name = train_x['Artist Name'], val_x['Artist Name']  \ntrain_song_name, val_song_name = train_x['Track Name'], val_x['Track Name']  \nfeats_to_drop = ['Artist Name', 'Track Name']\ntrain_x = train_x.drop(feats_to_drop, axis = 1)\nval_x = val_x.drop(feats_to_drop, axis = 1)","94f67c29":"train_x.head()","5748ee0b":"sns.scatterplot(data = train_x, x = 'Popularity', y ='loudness', hue = 'Solo')","6d78fa1f":"sns.scatterplot(data = train_x, x = 'Popularity', y ='duration_in min\/ms', hue = 'Solo')","c3fb9949":"from sklearn.linear_model import LogisticRegression as lrr\nfrom sklearn.ensemble import RandomForestClassifier as rfc \nfrom sklearn.naive_bayes import GaussianNB as gnb\nfrom sklearn.svm import SVC\nfrom xgboost import XGBRFClassifier as xgb \n\nfrom sklearn.model_selection import cross_val_score as cvs, GridSearchCV as gscv, StratifiedKFold as skf\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.preprocessing import StandardScaler as ss, MinMaxScaler as mms, RobustScaler as rs","b9823529":"def best_model(xt, yt, scaler = None):\n    models = [lrr(), SVC(), rfc(), gnb(), xgb()]\n    names = ['logistic regression','svm','random forest clf', 'naive bayes', 'xgboost']\n    scores = []\n    for model in models:\n        if scaler == 'std':\n            model = Pipeline(steps = [('std',ss()),('model',model)])\n        elif scaler == 'robust':\n            model = Pipeline(steps = [('robust',rs()),('model',model)])\n        elif scaler == 'mms':\n            model = Pipeline(steps = [('mms',mms()),('model',model)])\n        cv = skf(n_splits = 5, shuffle = True, random_state = True)\n        score = cvs(model, cv = cv, X = xt, y = yt, scoring = 'f1_micro').mean()\n        scores.append(score)\n    return pd.DataFrame(score, index = names, columns = ['f1_score']).sort_values('f1_score', ascending = True)\n\ndef get_score(xt, yt, model = lrr(), scaler = None):\n    if scaler == 'std':\n        model = Pipeline(steps = [('std',ss()),('model',model)])\n    elif scaler == 'robust':\n        model = Pipeline(steps = [('robust',rs()),('model',model)])\n    elif scaler == 'mms':\n        model = Pipeline(steps = [('mms',mms()),('model',model)])\n    cv = skf(n_splits = 5, shuffle = True, random_state = True)\n    auc = cvs(model, cv = cv, X = xt, y = yt).mean()\n    print(f\"Model score :==> {auc}\")\n    \ndef gridCv(xt, yt, model, params, scaler = None):\n    if scaler == 'std':\n        model = Pipeline(steps = [('std',ss()),('model',model)])\n    elif scaler == 'robust':\n        model = Pipeline(steps = [('robust',rs()),('model',model)])\n    elif scaler == 'mms':\n        model = Pipeline(steps = [('mms',mms()),('model',model)])\n    skcv = skf(n_splits = 5, shuffle = True, random_state = True)\n    cv = gscv(model, param_grid = params, cv = skcv , return_train_score = True)\n    cv.fit(xt,yt)\n    results = pd.DataFrame(cv.cv_results_).sort_values('mean_test_score', ascending = False)\n    results = results[['mean_test_score','mean_train_score','params']]\n    best_params = cv.best_params_\n    best_est = cv.best_estimator_\n    return best_est, best_params, results\n\ndef clf_report(yt, pred):\n    print(classification_report(yt, pred))\n","1378f7a5":"best_model(train_x, train_y)","7e463a8d":"best_model(train_x, train_y, 'std')","e6b53d9d":"best_model(train_x, train_y, 'robust')","7ba7a590":"best_model(train_x, train_y, 'mms')","34c9c8a8":"gridCv(train_x, train_y, gnb(), {})","09bf718d":"new_x = np.log1p(train_x[high_skew_feats])\nbest_model(new_x, train_y)","9382860b":"### Data cleaning and feature engg","423b94bd":"according the pd plot as the duration of the song increases (min\/ms), greater the change of being class 10, 8, 6, 5, 2, 1 ","2cec4a6d":"### Handling null values "}}