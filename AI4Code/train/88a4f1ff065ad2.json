{"cell_type":{"35a3f943":"code","a2adf533":"code","b60f127f":"code","6228ef94":"code","8dee150a":"code","718b0f3e":"code","d1aad951":"code","5ac4e9f8":"code","37813abc":"code","775b5e62":"code","ed4e0fc5":"code","f3f18f09":"code","30a38688":"code","7cd48c66":"code","7f2e979a":"code","1c6464fc":"code","c7c98476":"code","c3021009":"code","a76be811":"code","fd399e94":"code","37e666fe":"code","fc0acd7f":"code","4587a94a":"code","cdbc5080":"code","3ef75388":"code","32d7afbf":"code","80a68797":"code","c6aa66fb":"code","ccd11958":"code","8cdfe4a9":"code","3d66cc98":"code","5e797785":"code","f171cf86":"code","9e5c27bb":"code","bce53954":"code","f7f84ec6":"code","2be2f852":"code","a6a1bbfa":"code","c48a4cf4":"code","21e0b5e8":"code","0ada7a70":"code","bfccd0c2":"code","7183f0ef":"code","029954eb":"code","b16dd14d":"code","ebfc629a":"code","f6515075":"code","1e33e2f4":"code","2b8a6425":"code","d5eb6be9":"code","d009d715":"code","6f5e2748":"code","e9e3eb06":"code","20d27d04":"code","5094eeed":"code","b1400f33":"code","a38e26b6":"code","5077b289":"code","31234ba0":"code","1dfc0420":"code","a92626bf":"code","ab2629cd":"code","3ff40f88":"code","24db7788":"markdown","6db65a5b":"markdown","70cadeb9":"markdown","30409498":"markdown","86478b68":"markdown","cc57a0ef":"markdown","7d1bc1ee":"markdown","03aafbb8":"markdown","bab9e489":"markdown","00f96514":"markdown","6075684d":"markdown","b6e10f95":"markdown","10233899":"markdown","f81f921c":"markdown","5dab3fe5":"markdown","a48ed204":"markdown","4222e983":"markdown","115a255a":"markdown","8d6ce278":"markdown","96383b1b":"markdown","60e636e5":"markdown","8bbe7dbd":"markdown","350ae17f":"markdown","9f016b33":"markdown","04a11401":"markdown","701c30aa":"markdown","14b4b84f":"markdown","6adb0e51":"markdown","1f507065":"markdown","d7b8956c":"markdown","6064554f":"markdown","faac6bf5":"markdown","e9824d4c":"markdown","4aeff72b":"markdown"},"source":{"35a3f943":"import tensorflow as tf\nprint(tf.__version__)","a2adf533":"# Import the CIFAR-10 dataset and rescale the pixel values\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\nx_train = x_train \/ 255.0\nx_test = x_test \/ 255.0\n\n# Use smaller subset -- speeds things up\nx_train = x_train[:10000]\ny_train = y_train[:10000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]","b60f127f":"# Plot the first 10 CIFAR-10 images\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 10, figsize=(10, 1))\nfor i in range(10):\n    ax[i].set_axis_off()\n    ax[i].imshow(x_train[i])","6228ef94":"# Introduce function to test model accuracy\n\ndef get_test_accuracy(model, x_test, y_test):\n    test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n    print('accuracy: {acc:0.3f}'.format(acc=test_acc))","8dee150a":"# Introduce function that creates a new instance of a simple CNN\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n\ndef get_new_model():\n    model = Sequential([\n        Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), \n               activation='relu', name='conv_1'),\n        Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_2'),\n        MaxPooling2D(pool_size=(4, 4), name='pool_1'),\n        Flatten(name='flatten'),\n        Dense(units=32, activation='relu', name='dense_1'),\n        Dense(units=10, activation='softmax', name='dense_2')\n    ])\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","718b0f3e":"# Create an instance of the model and show model summary\n\nmodel = get_new_model()\nmodel.summary()","d1aad951":"# Test accuracy of the untrained model, around 10% (random)\n\nget_test_accuracy(model, x_test, y_test)","5ac4e9f8":"from tensorflow.keras.callbacks import ModelCheckpoint","37813abc":"# Create Tensorflow checkpoint object\ncheckpoint_path = \"modelcheckpoints\/checkpoint\"\n\ncheckpoint = ModelCheckpoint(filepath = checkpoint_path,\n                            frequency = 'epoch',\n                            save_weights_only = True,\n                            verbose = True)","775b5e62":"# Fit model, with simple checkpoint which saves (and overwrites) model weights every epoch\nmodel.fit(x = x_train, y = y_train,epochs = 3, callbacks = [checkpoint])\n","ed4e0fc5":"# Have a look at what the checkpoint creates\n!ls -lh modelcheckpoints","f3f18f09":"# Evaluate the performance of the trained model\nget_test_accuracy(model, x_test, y_test)\n","30a38688":"# Create a new instance of the (initialised) model, accuracy around 10% again\n\nmodel = get_new_model()\nget_test_accuracy(model, x_test, y_test)","7cd48c66":"# Load weights -- accuracy is the same as the trained model\nmodel.load_weights(checkpoint_path)\nget_test_accuracy(model, x_test, y_test)","7f2e979a":"! rm -r modelcheckpoints","1c6464fc":"from tensorflow.keras.callbacks import ModelCheckpoint","c7c98476":"# Create Tensorflow checkpoint object with epoch and batch details\n\ncheckpoint_5000_path = \"modelcheckpoints_5000\/checkpoint_{epoch:02d}\"\n\ncheckpoint_5000 = ModelCheckpoint(filepath = checkpoint_5000_path,\n                            save_frequency = 5000,\n                            save_weights_only = True,\n                            verbose = True)","c3021009":"# Create and fit model with checkpoint\nmodel = get_new_model()\nmodel.fit(x = x_train, y = y_train,\n          epochs = 3, \n          validation_data = (x_test,y_test),\n          batch_size = 10,\n          callbacks = [checkpoint_5000])","a76be811":"# Have a look at what the checkpoint creates\n!ls -lh modelcheckpoints_5000","fd399e94":"# Use tiny training and test set -- will overfit!\n\nx_train = x_train[:100]\ny_train = y_train[:100]\nx_test = x_test[:100]\ny_test = y_test[:100]","37e666fe":"# Create a new instance of untrained model\n\nmodel = get_new_model()","fc0acd7f":"!rm -r modelcheckpoints_best","4587a94a":"# Create Tensorflow checkpoint object which monitors the validation accuracy\n\ncheckpoint_best_path = \"modelcheckpoints_best\/checkpoint\"\n\ncheckpoint_best = ModelCheckpoint(filepath = checkpoint_best_path,\n                            save_frequency = 'epoch',\n                            save_weights_only = True,\n                            save_best_only = True,\n                            monitor = 'val_accuracy',\n                            verbose = 1)","cdbc5080":"# Fit the model and save only the weights with the highest validation accuracy\n\nhistory = model.fit(x = x_train, y = y_train,\n          epochs = 50, \n          validation_data = (x_test,y_test),\n          callbacks = [checkpoint_best])","3ef75388":"# Plot training and testing curves\n\nimport pandas as pd\n\ndf = pd.DataFrame(history.history)\ndf.plot(y=['accuracy', 'val_accuracy'])","32d7afbf":"# Inspect the checkpoint directory\n\n!ls -lh modelcheckpoints_best","80a68797":"# Create a new model with the saved weights\n\nnew_model = get_new_model()\nnew_model.load_weights(checkpoint_best_path)\nget_test_accuracy(model, x_test, y_test)","c6aa66fb":"! rm -r  modelcheckpoints_best","ccd11958":"from tensorflow.keras.callbacks import ModelCheckpoint","8cdfe4a9":"# Create Tensorflow checkpoint object\ncheckpoint_path = \"modelcheckpoints\/checkpoint\"\n\ncheckpoint = ModelCheckpoint(filepath = checkpoint_path,\n                            save_frequency = 'epoch',\n                            save_weights_only = False,\n                            monitor = 'val_accuracy',\n                            verbose = 1)\n","3d66cc98":"# Create and fit model with checkpoint\nmodel = get_new_model()\n\nhistory = model.fit(x = x_train, y = y_train,\n          epochs = 50, \n          validation_data = (x_test,y_test),\n          callbacks = [checkpoint])\n","5e797785":"# Have a look at what the checkpoint creates\n!ls modelcheckpoints\/checkpoint","f171cf86":"# Enter variables directory\n\n!ls modelcheckpoints\/checkpoint\/variables","9e5c27bb":"# Get the model's test accuracy\n\nget_test_accuracy(model, x_test, y_test)","bce53954":"# Delete model\n\nmodel","f7f84ec6":"del model","2be2f852":"from tensorflow.keras.models import load_model","a6a1bbfa":"# Reload model from scratch\n\nmodel=load_model(checkpoint_path)\n\nget_test_accuracy(model, x_test, y_test)","c48a4cf4":"# Save the model in .h5 format\n\nmodel.save('my_model.h5')","21e0b5e8":"# Inspect .h5 file\n\n!ls -lh my_model.h5","0ada7a70":"# Delete model\n\ndel model","bfccd0c2":"# Reload model from scratch\nmodel=load_model('my_model.h5')\n\nget_test_accuracy(model, x_test, y_test)\n","7183f0ef":"!ls","029954eb":"! rm -r modelcheckpoints\n! rm my_model.h5","b16dd14d":"from tensorflow.keras.applications import ResNet50\nmodel = ResNet50(weights='imagenet')","ebfc629a":"# Retrieve the image files\n\n!wget -q -O lemon.jpg --no-check-certificate \"https:\/\/docs.google.com\/uc?export=download&id=1JSgQ9qgi9nO9t2aGEk-zA6lzYNUT9vZJ\"\n!wget -q -O viaduct.jpg --no-check-certificate \"https:\/\/docs.google.com\/uc?export=download&id=1sQzMKmyCR5Tur19lP3n1IIlEMG_o6Mct\"\n!wget -q -O water_tower.jpg --no-check-certificate \"https:\/\/docs.google.com\/uc?export=download&id=1cPAQD1O6mAiMbg0fmG5HIk8OuO_BSC6J\"","f6515075":"# Import 3 sample ImageNet images\n\nfrom tensorflow.keras.preprocessing.image import load_img\n\nlemon_img = load_img('lemon.jpg', target_size=(224, 224))\nviaduct_img = load_img('viaduct.jpg', target_size=(224, 224))\nwater_tower_img = load_img('water_tower.jpg', target_size=(224, 224))","1e33e2f4":"# Useful function: presents top 5 predictions and probabilities\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\nimport pandas as pd\n\ndef get_top_5_predictions(img):\n    x = img_to_array(img)[np.newaxis, ...]\n    x = preprocess_input(x)\n    preds = decode_predictions(model.predict(x), top=5)\n    top_preds = pd.DataFrame(columns=['prediction', 'probability'],\n                             index=np.arange(5)+1)\n    for i in range(5):\n        top_preds.loc[i+1, 'prediction'] = preds[0][i][1]\n        top_preds.loc[i+1, 'probability'] = preds[0][i][2] \n    return top_preds","2b8a6425":"# Display image\nlemon_img","d5eb6be9":"# Display top 5 predictions\nget_top_5_predictions(lemon_img)\n","d009d715":"# Display image\n\nviaduct_img","6f5e2748":"# Display top 5 predictions\nget_top_5_predictions(viaduct_img)\n","e9e3eb06":"# Display image\n\nwater_tower_img","20d27d04":"# Display top 5 predictions\n\nget_top_5_predictions(water_tower_img)","5094eeed":"import tensorflow_hub as hub","b1400f33":"# Build Google's Mobilenet v1 model\n\nmodule_url = \"https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v1_050_160\/classification\/4\"\nmodel = Sequential([hub.KerasLayer(module_url)])\nmodel.build(input_shape=[None, 160, 160, 3])","a38e26b6":"# Retrieve the image files\n\n!wget -q -O lemon.jpg --no-check-certificate \"https:\/\/docs.google.com\/uc?export=download&id=1JSgQ9qgi9nO9t2aGEk-zA6lzYNUT9vZJ\"\n!wget -q -O viaduct.jpg --no-check-certificate \"https:\/\/docs.google.com\/uc?export=download&id=1sQzMKmyCR5Tur19lP3n1IIlEMG_o6Mct\"\n!wget -q -O water_tower.jpg --no-check-certificate \"https:\/\/docs.google.com\/uc?export=download&id=1cPAQD1O6mAiMbg0fmG5HIk8OuO_BSC6J\"","5077b289":"# Import and preprocess 3 sample ImageNet images\n\nfrom tensorflow.keras.preprocessing.image import load_img\n\nlemon_img = load_img(\"lemon.jpg\", target_size=(160, 160))\nviaduct_img = load_img(\"viaduct.jpg\", target_size=(160, 160))\nwater_tower_img = load_img(\"water_tower.jpg\", target_size=(160, 160))","31234ba0":"# Read in categories text file\n\nwith open('data\/imagenet_categories.txt') as txt_file:\n    categories = txt_file.read().splitlines()","1dfc0420":"# Useful function: presents top 5 predictions\n\nimport pandas as pd\n\ndef get_top_5_predictions(img):\n    x = img_to_array(img)[np.newaxis, ...] \/ 255.0\n    preds = model.predict(x)\n    top_preds = pd.DataFrame(columns=['prediction'],\n                             index=np.arange(5)+1)\n    sorted_index = np.argsort(-preds[0])\n    for i in range(5):\n        ith_pred = categories[sorted_index[i]]\n        top_preds.loc[i+1, 'prediction'] = ith_pred\n            \n    return top_preds","a92626bf":"lemon_img","ab2629cd":"viaduct_img","3ff40f88":"water_tower_img","24db7788":"#### Clear directory","6db65a5b":"#### Create new model, load weights","70cadeb9":"##### Image 3: water tower","30409498":"#### Create more customised checkpoint","86478b68":"These notebooks are part of Coding Tutorials of TensorFlow 2 for Deep Learning Specialization. I have just replicated it from the videos.","cc57a0ef":"#### Import and preprocess 3 sample images","7d1bc1ee":"#### Clear directory","03aafbb8":"#### Train model with checkpoints","bab9e489":"#### Create checkpoint that saves whole model, not just weights","00f96514":"The CIFAR-10 dataset consists of, in total, 60000 color images, each with one of 10 labels: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. For an introduction and a download, see [this link](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html).","6075684d":"#### Use MobileNet model to classify images","b6e10f95":"##### Image 2: viaduct","10233899":"##### Image 3: water tower","f81f921c":"##### Image 1: lemon","5dab3fe5":"#### Use the .h5 format to save model","a48ed204":"#### Import and build Tensorflow Hub MobileNet v1 model\n\nToday we'll be using Google's MobileNet v1 model, available on Tensorflow Hub. Please see the description on the [Tensorflow Hub page](https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v1_050_160\/classification\/4) for details on it's architecture, how it's trained, and the reference. If you continue using it, please cite it properly! The paper it comes from is:\n\nAndrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam: \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\", 2017.\n\nIn the coding tutorial on Coursera, this model is loaded directly from disk. On Colab, you will load the model from TensorFlow Hub.","4222e983":" ## Coding tutorials\n #### [1. Saving and loading model weights](#coding_tutorial_1)\n #### [2. Model saving criteria](#coding_tutorial_2)\n #### [3. Saving the entire model](#coding_tutorial_3)\n #### [4. Loading pre-trained Keras models](#coding_tutorial_4)\n #### [5. Tensorflow Hub modules](#coding_tutorial_5)","115a255a":"#### Clear directory","8d6ce278":"#### Import and build Keras ResNet50 model\n\nToday we'll be using the ResNet50 model designed by a team at Microsoft Research, available through Keras applications. Please see the description on the [Keras applications page](https:\/\/keras.io\/applications\/#resnet) for details. If you continue using it, please cite it properly! The paper it comes from is:\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. \"Deep Residual Learning for Image Recognition\", 2015.\n\nIn the coding tutorial on Coursera, this model is loaded directly from disk. On Colab, you will load the model using the Keras API.","96383b1b":"#### Create new model from scratch","60e636e5":"***\n<a id=\"coding_tutorial_5\"><\/a>\n## Tensorflow Hub modules","8bbe7dbd":"##### Image 1: lemon","350ae17f":"#### Introduce two useful functions","9f016b33":"#### Create simple convolutional neural network classifier","04a11401":"#### Work with model saving criteria","701c30aa":"***\n<a id=\"coding_tutorial_1\"><\/a>\n## Saving and loading model weights","14b4b84f":"***\n<a id=\"coding_tutorial_2\"><\/a>\n## Model saving criteria","6adb0e51":"# Saving and loading models","1f507065":"##### Image 2: viaduct","d7b8956c":"***\n<a id=\"coding_tutorial_4\"><\/a>\n## Loading pre-trained Keras models","6064554f":"***\n<a id=\"coding_tutorial_3\"><\/a>\n## Saving the entire model","faac6bf5":"#### Load and inspect CIFAR-10 dataset","e9824d4c":"#### Use ResNet50 model to classify images","4aeff72b":"#### Inspect what the checkpoint has created"}}