{"cell_type":{"76972b04":"code","dabd6cd2":"code","d623665b":"code","49d21600":"code","e1959f6d":"code","78889d52":"code","978d26c6":"code","1565e202":"code","224b00dc":"markdown","f05202e9":"markdown","043dcbf8":"markdown","5acaf4d6":"markdown","ff6ceb2d":"markdown"},"source":{"76972b04":"import numpy as np \nimport pandas as pd\nfrom collections import Counter","dabd6cd2":"# Reading the dataset\ntrain = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Setting the target\ny_train = train.SalePrice\n\n# Here I removed the columns that has categories differences with test dataset\ntrain.drop(['SalePrice','Utilities',\n 'Condition2',\n 'HouseStyle',\n 'RoofMatl',\n 'Exterior1st',\n 'Exterior2nd',\n 'Heating',\n 'Electrical',\n 'GarageQual',\n 'PoolQC',\n 'MiscFeature',\n ],axis = 1,inplace = True)\n\ntest.drop(['Utilities',\n 'Condition2',\n 'HouseStyle',\n 'RoofMatl',\n 'Exterior1st',\n 'Exterior2nd',\n 'Heating',\n 'Electrical',\n 'GarageQual',\n 'PoolQC',\n 'MiscFeature',\n ],axis = 1,inplace = True)\n","d623665b":"from sklearn.model_selection import train_test_split\n# Splitting the train dataset \nX_train, X_valid, y_train, y_valid = train_test_split(train, y_train,\n                                                      train_size=0.8, test_size=0.2,\n                                                      random_state=0)","49d21600":"# Let's divide numerical and categorical columns\n# numerical\nnum_cols = X_train.select_dtypes(include=['int','float64']).columns\n# categorical\ncat_cols = X_train.select_dtypes(include=['object']).columns","e1959f6d":"# Checking if both train and valid\/test have the same categories\n# columns_to_remove = []\n# for name in cat_cols:\n#     dif = len(set(Counter(X_train.loc[:,name])) - set(Counter(X_valid.loc[:,name])))\n#     if dif > 0:\n#         print(\"column : \",name,dif)\n#         columns_to_remove.append(name)\n# # columns_to_remove","78889d52":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='most_frequent')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols),\n        ('cat', categorical_transformer, cat_cols)\n    ])\n","978d26c6":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\n\n# tunning\n# for n in np.arange(0.01, 11, 1):\n#     n=format(n,\".3f\")\nevalset = [(X_train, y_train), (X_valid,y_valid)]\n\nmodel = XGBRegressor(n_estimators = 1000,learning_rate = 0.068,max_depth = 3,\n                         subsample = 0.8, random_state=0, colsample_bytree = 1,reg_alpha=31,\n                        )\n\nprocessing = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)\n                         ])\n\n# Fit the model\nprocessing.fit(X_train,y_train)\n\n# Predicting\npred = processing.predict(X_valid)\n\n# Metrics \n# I applied CV to get a better measuring of MEA\nscores = -1 * cross_val_score(processing, X_train, y_train,\n                              cv=3,\n                              scoring='neg_mean_absolute_error')\nmae = mean_absolute_error(pred,y_valid)\nprint(\"Mean Absolute Error:\", '\\t', mae, \"n:\")\nprint(\"MAE CV:\", '\\t\\t', scores.mean())","1565e202":"preds_test  = processing.predict(test)\n\noutput = pd.DataFrame({'Id': test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","224b00dc":"# Solution of Housing Prices Competition, Top 1%","f05202e9":"## 1. Cleaning","043dcbf8":"## 2. Pipeline","5acaf4d6":"## 3. Model","ff6ceb2d":"## 4. Outcomes"}}