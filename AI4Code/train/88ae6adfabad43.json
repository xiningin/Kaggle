{"cell_type":{"4d0638ed":"code","66a7297f":"code","77e4e240":"code","66693a08":"code","8b28a4dd":"code","49de131b":"code","77a60aca":"code","c687fd87":"code","cb9196d3":"code","de9cdce3":"code","0b306e21":"markdown","d27e93af":"markdown","d79d578b":"markdown","c13b04a6":"markdown","e02b2811":"markdown","af1a1f4b":"markdown"},"source":{"4d0638ed":"import os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, utils\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nseed = 69\n\ntorch.manual_seed(seed)\nnp.random.seed(seed)","66a7297f":"class MnistDataset(Dataset):\n    def __init__(self, csv_file, transform=None, train=True):\n        '''\n        Args:\n            csv_file (string)\n            tain (boolean)\n            transform (callable, optional)\n        '''\n        \n        self.mnist = pd.read_csv(csv_file)\n        self.train = train\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.mnist)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        if self.train:\n            label = self.mnist.iloc[idx][0]\n            label = np.array(label)\n\n            img = self.mnist.iloc[idx].values[1:]\n            img = img \/ 255 #normalize\n            sample = {\"label\":label, \"image\":img}\n            if self.transform:\n                sample = self.transform(sample)\n                \n        else:\n            img = self.mnist.iloc[idx].values\n            img = img \/ 255\n            sample = {\"image\": torch.from_numpy(img)}\n            \n\n            \n        return sample\n\nclass ToTensor(object):\n    def __call__(self, sample):\n        image, label = sample['image'], sample['label']\n\n        return {'image': torch.from_numpy(image),\n                'label': torch.from_numpy(label)}","77e4e240":"training_split = 0.8\nbatch_size = 32\n\n#load training and test data\nmnist_train_dataset = MnistDataset(\"..\/input\/digit-recognizer\/train.csv\", transform=transforms.Compose([ToTensor()]))\nmnist_test_dataset = MnistDataset(\"..\/input\/digit-recognizer\/test.csv\", train=False)\n\ntrain_length = int(training_split * len(mnist_train_dataset))\nvalidation_length = len(mnist_train_dataset) - train_length\n\n#split training data into train and validation\ntrain_dataset, validation_dataset = torch.utils.data.random_split(mnist_train_dataset, (train_length, validation_length))\n\n#create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(mnist_test_dataset, batch_size=1, shuffle=False)","66693a08":"imgs_ = 6\nfig = plt.figure()\nplt.figure(figsize=(15,imgs_))\nfor i in range(imgs_):\n    ax = plt.subplot(1, imgs_, i+1)\n    ax.set_title('sample #{}'.format(i))\n    plt.imshow(np.reshape(mnist_train_dataset[i][\"image\"], (28,28)), cmap='gray')\n    \nplt.show()","8b28a4dd":"learning_rate = 0.005\nmomentum = 0.5\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nclass MLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 50)\n        self.fc1_drop = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(50, 50)\n        self.fc2_drop = nn.Dropout(0.2)\n        self.fc3 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc1_drop(x)\n        x = F.relu(self.fc2(x))\n        x = self.fc2_drop(x)\n        return F.log_softmax(self.fc3(x), dim=1)\n\nmodel = MLP().to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\ncriterion = nn.CrossEntropyLoss()","49de131b":"def train(epoch, loader, log_interval=500):\n    # Set model to training mode\n    model.train()\n    \n    # Loop over each batch from the training set\n    for batch_idx, data in enumerate(train_loader):\n        \n        variables = data[\"image\"].float().to(device)\n        target = data[\"label\"].to(device)\n\n        # Zero gradient buffers\n        optimizer.zero_grad() \n        \n        # Pass data through the network\n        output = model(variables)\n        # Calculate loss\n        loss = criterion(output, target)\n\n        # Backpropagate\n        loss.backward()\n        \n        # Update weights\n        optimizer.step()\n        \n        if batch_idx % log_interval == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * batch_size, len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.data.item()))\n\ndef validate(loss, accuracy_list, loader):\n    model.eval()\n    val_loss, correct = 0, 0\n    \n    for data in loader:\n        variables = data[\"image\"].float().to(device)\n        target = data[\"label\"].to(device)\n        \n        \n        output = model(variables)\n        val_loss += criterion(output, target).data.item()\n        \n        pred = output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n\n    val_loss \/= len(loader)\n    loss.append(val_loss)\n\n    accuracy = 100. * correct.to(torch.float32) \/ len(loader.dataset)\n    accuracy_list.append(accuracy)\n    \n    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        val_loss, correct, len(loader.dataset), accuracy))","77a60aca":"epochs = 20\n\nloss_, acc_ = [], []\nfor epoch in range(1, epochs + 1):\n    train(epoch, train_loader)\n    validate(loss_, acc_ , validation_loader)","c687fd87":"model.eval()\noutput_list = []\nfor idx, data in enumerate(test_loader):\n    output = model(data[\"image\"].float().to(device))\n    output_list.append([idx+1, (output.data.max(1)[1].cpu().numpy().tolist()[0])])","cb9196d3":"len(output_list) == len(mnist_test_dataset)","de9cdce3":"#export to csv\npd.DataFrame(output_list, columns=[\"ImageId\", \"Label\"]).to_csv(\"predictions.csv\", index=False)","0b306e21":"# Visualize images","d27e93af":"# Define Train and Validation functions","d79d578b":"dataset https:\/\/www.kaggle.com\/c\/digit-recognizer\/data","c13b04a6":"# Running on test set","e02b2811":"# Training","af1a1f4b":"# create Model"}}