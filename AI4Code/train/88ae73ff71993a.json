{"cell_type":{"269b10ac":"code","068d6bb0":"code","07f4760e":"code","8e3d6c3a":"code","b13ec5fc":"code","b83fcba3":"code","41c61451":"code","4cbe9060":"code","9e8c7057":"code","c2501354":"code","b950a5f0":"code","f9ffa4bd":"code","d994653e":"code","43f011f7":"code","10254518":"code","ef4f59fb":"code","caeb7a72":"code","e29f0fbd":"code","84bec7a3":"code","8a594e9f":"markdown","301c7eba":"markdown","826d2173":"markdown","79ca5077":"markdown","b94371fe":"markdown","a76c8458":"markdown","84e06ba2":"markdown","b6ebbf05":"markdown","05bb232b":"markdown","39529e2a":"markdown","fa885475":"markdown"},"source":{"269b10ac":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n%matplotlib inline\nimport warnings      #to avoid warnings\nwarnings.filterwarnings('ignore')\n# importing data\ndata = pd.read_csv('..\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv')\nprint(f\"Let's see first 5 rows of the dataset.\")\ndata.head()","068d6bb0":"import pandas_profiling\ndata.profile_report()","07f4760e":"sns.set(style=\"whitegrid\",palette='Set2')","8e3d6c3a":"print(\"Distribution of boolean variables\")\nprint(' \u201c1\u201d means \u201cYes\u201d, \u201c0\u201d means \u201cNo\u201d')\nfig,axes = plt.subplots(nrows=2,ncols=3,figsize=(12,8))\nsns.countplot(data.TenYearCHD,ax=axes[0,0])\nsns.countplot(data.male,ax=axes[0,1])\naxes[0,1].set_xlabel(\"0 is female and 1 is male\")\nsns.countplot(data.currentSmoker,ax=axes[0,2])\nsns.countplot(data.BPMeds,ax=axes[1,0])\nsns.countplot(data.prevalentStroke,ax=axes[1,1])\nsns.countplot(data.prevalentHyp,ax=axes[1,2])\nplt.tight_layout()","b13ec5fc":"sns.set(style=\"darkgrid\",palette='Set1')\nprint(\"Distribution of continuous variables\")\nfig,axes = plt.subplots(nrows=4,ncols=2,figsize=(12,8))\nsns.distplot(data.age,ax=axes[0,0])\nsns.distplot(data.BMI,ax=axes[0,1])\nsns.distplot(data.glucose,ax=axes[1,0])\nsns.distplot(data.cigsPerDay,ax=axes[1,1])\nsns.distplot(data.sysBP,ax=axes[2,0])\nsns.distplot(data.diaBP,ax=axes[2,1])\nsns.distplot(data.totChol,ax=axes[3,0])\nsns.distplot(data.heartRate,ax=axes[3,1])\nplt.tight_layout()","b83fcba3":"#Plotting a linegraph to check the relationship between age and cigsPerDay, totChol, glucose.\ngraph_3 = data.groupby(\"age\").cigsPerDay.mean()\ngraph_4 = data.groupby(\"age\").totChol.mean()\ngraph_5 = data.groupby(\"age\").glucose.mean()\n\nplt.figure(figsize=(10,6))\nsns.lineplot(data=graph_3, label=\"cigsPerDay\")\nsns.lineplot(data=graph_4, label=\"totChol\")\nsns.lineplot(data=graph_5, label=\"glucose\")\nplt.title(\"Graph showing totChol and cigsPerDay in every age group.\",{'fontsize':18})\nplt.xlabel(\"age\", size=20)\nplt.ylabel(\"count\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12);","41c61451":"graph = data.groupby(\"age\",as_index=False).currentSmoker.sum()\nplt.figure(figsize=(10,6))\nsns.barplot(x=graph[\"age\"], y=graph[\"currentSmoker\"])\nplt.title(\"Graph showing which age group has more smokers.\",{'fontsize':18});","4cbe9060":"# Let's have a visual look at missing data\nmsno.matrix(data);","9e8c7057":"data.groupby('diabetes').mean()['glucose']","c2501354":"def impute_glucose(cols):\n    dia=cols[0]\n    glu=cols[1]\n    if pd.isnull(glu):\n        if dia == 0:\n            return 79\n        else:\n            return 170\n    else:\n        return glu\n\ndata['glucose'] = data[['diabetes','glucose']].apply(impute_glucose,axis=1)","b950a5f0":"#Another way to visualize missing data\nsns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='summer');","f9ffa4bd":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='most_frequent')\nimputer.fit(data)\nimputed_data = imputer.transform(data)\nimputed_data = pd.DataFrame(imputed_data,columns=data.columns)","d994653e":"print(\"just to cross-check all missing data is gone!\")\nmsno.bar(imputed_data);","43f011f7":"#Libraries needed for model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import cross_val_score","10254518":"#First split the data\nX_train, X_test, y_train, y_test = train_test_split(imputed_data.drop('TenYearCHD',axis=1), \n                                                    imputed_data['TenYearCHD'], test_size=0.30, \n                                                    random_state=101)\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\npredictions = logmodel.predict(X_test)\nprint(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","ef4f59fb":"print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, predictions)))","caeb7a72":"score=cross_val_score(LogisticRegression(),imputed_data.drop('TenYearCHD',axis=1),imputed_data['TenYearCHD'],cv=10)\nprint(f\"After k-fold cross validation score is {score.mean()}\")","e29f0fbd":"from sklearn.model_selection import GridSearchCV\nparameters = [{'penalty':['l1','l2']}, \n              {'C':[1, 10, 100, 1000]}]\ngrid_search = GridSearchCV(estimator = logmodel,  \n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 5,\n                           verbose=0)\ngrid_search.fit(X_train, y_train)\n# best score achieved during the GridSearchCV\nprint('GridSearch CV best score : {:.4f}\\n'.format(grid_search.best_score_))\n# print parameters that give the best results\nprint(f'Parameters that give the best results : {grid_search.best_params_}')","84bec7a3":"score2=cross_val_score(grid_search,imputed_data.drop('TenYearCHD',axis=1),imputed_data['TenYearCHD'],cv=10)\nprint(f\"After k-fold cross validation score is {score2.mean()}\")","8a594e9f":"# EDA","301c7eba":"# Handling missing values","826d2173":"> ## *Please upvote if you like my efforts and provide valuable suggestions!*","79ca5077":"## Using GridSearchCV","b94371fe":"# CONCLUSION:\n\n- Model accuracy score for logistic regression after cross-validation is 84.9% which is quite nice.\n- Using GridSearchCV does not improve accuracy on this particular data.","a76c8458":"**Cross-validation** is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. In k-fold cross-validation, you split the input data into k subsets of data (also known as folds). You train an ML model on all but one (k-1) of the subsets, and then evaluate the model on the subset that was not used for training. This process is repeated k times, with a different subset reserved for evaluation (and excluded from training) each time.","84e06ba2":"I will use **pandas_profiling** library to understand the data.\nIt is a nice alternative to using .info and .describe methods. Infact, it gives much more useful informations like % of mising values, mean, maximum, minimum, heatmap depicting correlation, etc.","b6ebbf05":"So, glucose feature has no missing data now.","05bb232b":"**Conclusions-**\n- Our data contains 4238 rows and 16 columns.\n- Seems like this data is already preprocessed as there is no categorical columns. Those features have been encoded already.\nNow, let's see missing values.\n- Columns having mising values are: 'education'(2.5%), 'cigsPerDay'(0.7%), 'BPMeds'(1.3%), 'totChol'(1.2%) and 'glucose'(**9.2%**).\nExcept the feature glucose all other missing values are less than 2% of data. We can drop all other missing values but in this project I choose to use SimpleImputer to impute them with most frequent value.\nAs for feature glucose, notice in heatmap that glucose is highly correlated with diabetes. So, I will use feature diabetes to fill missing values in glucose.","39529e2a":"\n**About the dataset:** Columns description-\n* Sex: male or female(Nominal)\n* Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\nBehavioral\n* Current Smoker: whether or not the patient is a current smoker (Nominal)\n* Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\nMedical( history)\n* BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n* Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n* Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n* Diabetes: whether or not the patient had diabetes (Nominal)\nMedical(current)\n* Tot Chol: total cholesterol level (Continuous)\n* Sys BP: systolic blood pressure (Continuous)\n* Dia BP: diastolic blood pressure (Continuous)\n* BMI: Body Mass Index (Continuous)\n* Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n* Glucose: glucose level (Continuous)\nPredict variable (desired target)\n* 10 year risk of coronary heart disease CHD (binary: \u201c1\u201d, means \u201cYes\u201d, \u201c0\u201d means \u201cNo\u201d)","fa885475":"# Creating Model"}}