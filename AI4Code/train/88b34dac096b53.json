{"cell_type":{"a7d85b65":"code","811d78e7":"code","aa2fc990":"code","07cac234":"code","1e9f9953":"code","d546cf57":"code","05511523":"code","e88480d1":"code","29241184":"code","ec6b70da":"code","eb0ed7f7":"code","d50bff18":"code","03eee954":"code","19bc4a3a":"code","e8ebf15e":"code","380952e3":"code","858c7f02":"code","585d3d54":"code","ed66132e":"code","6c1ee69a":"code","e68a3772":"code","73c6b1cb":"code","d681f215":"code","97c47f61":"code","fc1a277b":"code","3c76200a":"code","6ecb30c6":"code","b0fbb2a4":"code","061cc316":"code","60f39c65":"code","4fa8673a":"code","907dc10a":"code","95c65081":"code","9eb06972":"code","da8c8673":"code","f7125930":"code","7166764c":"code","ddacf4a1":"code","8016bda0":"code","7f8815d9":"code","c11f5344":"code","296c8531":"code","0924ed85":"code","4988f3b5":"code","7e0319db":"code","7d8d6c44":"code","4b2540a9":"code","3fbed881":"code","b2928fc1":"code","79032cd0":"code","bbc1e9e5":"code","57f275da":"code","75693f54":"code","d7859cee":"markdown","fbf813ac":"markdown","4566344c":"markdown","b08e3268":"markdown","8c47368c":"markdown","d7ea2db0":"markdown","433d4927":"markdown","6462c7dd":"markdown","a9d75571":"markdown","b49d4be4":"markdown","7e907dc0":"markdown","53e7a710":"markdown","3046c76c":"markdown","39168eae":"markdown","a3eceb47":"markdown","9ddb18bc":"markdown","b5e1499d":"markdown","c58530a6":"markdown","76e53a2b":"markdown","854ebe07":"markdown","2ae4f27f":"markdown","f2281ab9":"markdown","b1ea0498":"markdown","2739d535":"markdown","4748baac":"markdown","b5e39b6a":"markdown","652d21b4":"markdown"},"source":{"a7d85b65":"# Basic libraries\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Directry check\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","811d78e7":"# file\nimport zipfile\n\n# Data preprocessing\nimport datetime\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport folium\nimport seaborn as sns\n\n# Random forest\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.multioutput import MultiOutputRegressor\n\n# parameter opimization\nfrom sklearn.model_selection import GridSearchCV\n\n# Validation\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score","aa2fc990":"## Dataloading","07cac234":"# sample\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/sampleSubmission.csv.zip\")\nsample = pd.read_csv(zip_file.open('sampleSubmission.csv'))","1e9f9953":"# train\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/train.csv.zip\")\ntrain_df = pd.read_csv(zip_file.open(\"train.csv\"))","d546cf57":"# test\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/test.csv.zip\")\ntest_df = pd.read_csv(zip_file.open(\"test.csv\"))","05511523":"# location_Data\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/metaData_taxistandsID_name_GPSlocation.csv.zip\")\nloc_df = pd.read_csv(zip_file.open(\"metaData_taxistandsID_name_GPSlocation.csv\"))","e88480d1":"# sample_submission\nsample.head()","29241184":"# test_data\ntest_df.head()","ec6b70da":"# test_data size\ntest_df.shape","eb0ed7f7":"# train_data\ntrain_df.head()","d50bff18":"# train_data size\ntrain_df.shape","03eee954":"# train_data info\ntrain_df.info()","19bc4a3a":"# train_data null data\ntrain_df.isnull().sum()","e8ebf15e":"# train_data unique values\nfor i in range(train_df.shape[1]):\n    print('*'*50)\n    print(train_df.columns[i])\n    print(train_df.iloc[:,i].value_counts())","380952e3":"# test_data unique values\nfor i in range(test_df.shape[1]):\n    print('*'*50)\n    print(test_df.columns[i])\n    print(test_df.iloc[:,i].value_counts())","858c7f02":"# Time data preprocessing\ntrain_df[\"TIMESTAMP\"] = [float(time) for time in train_df[\"TIMESTAMP\"]]\ntrain_df[\"dt\"] = [datetime.datetime.fromtimestamp(time, datetime.timezone.utc) for time in train_df[\"TIMESTAMP\"]]","585d3d54":"# Time data\ntrain_df[\"dt\"].value_counts()","ed66132e":"# Time data preparation\ntrain_df[\"year\"] = train_df[\"dt\"].dt.year\ntrain_df[\"month\"] = train_df[\"dt\"].dt.month\ntrain_df[\"day\"] = train_df[\"dt\"].dt.day\ntrain_df[\"hour\"] = train_df[\"dt\"].dt.hour\ntrain_df[\"min\"] = train_df[\"dt\"].dt.minute\ntrain_df[\"weekday\"] = train_df[\"dt\"].dt.weekday","6c1ee69a":"train_df.head()","e68a3772":"# Time series visualization\npivot = pd.pivot_table(train_df, index='month', columns=\"year\", values=\"TRIP_ID\", aggfunc=\"count\").reset_index()\n\n# Visualization, per month count\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"month\"], pivot[2013], label=\"2013\")\n    plt.plot(pivot[\"month\"], pivot[2014], label=\"2014\")\n    plt.xlabel(\"month\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","73c6b1cb":"# weekday, groupby whole data\nweekday = pd.DataFrame(data=train_df.groupby(\"weekday\").TRIP_ID.count()).reset_index()\n\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    \n    plt.plot(weekday[\"weekday\"], weekday[\"TRIP_ID\"])\n    plt.xlabel(\"weekday\\n (0:Monday ~ 6:Sunday)\")\n    plt.ylabel(\"count\")\n    plt.ylim([200000, 300000])","d681f215":"### Call type\ncall_type = pd.DataFrame(data=train_df.groupby(\"CALL_TYPE\").TRIP_ID.count()).reset_index()\n\n# visualization\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.bar(call_type[\"CALL_TYPE\"], call_type[\"TRIP_ID\"])\n    plt.xlabel(\"CALL_TYPE\")\n    plt.ylabel(\"Count\")","97c47f61":"# 1st lon\nlists_1st_lon = []\nfor i in range(0,len(train_df[\"POLYLINE\"])):\n    if train_df[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lon.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[0]\n        lists_1st_lon.append(k)\n        \ntrain_df[\"lon_1st\"] = lists_1st_lon\n\n# 1st lat\nlists_1st_lat = []\nfor i in range(0,len(train_df[\"POLYLINE\"])):\n    if train_df[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[1]\n        lists_1st_lat.append(k)\n        \ntrain_df[\"lat_1st\"] = lists_1st_lat","fc1a277b":"# last long\nlists_last_lon = []\nfor i in range(0,len(train_df[\"POLYLINE\"])):\n        if train_df[\"POLYLINE\"][i] == '[]':\n            k=0\n            lists_last_lon.append(k)\n        else:\n            k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[-2]\n            lists_last_lon.append(k)\n\ntrain_df[\"lon_last\"] = lists_last_lon\n\n# last lat\nlists_last_lat = []\nfor i in range(0,len(train_df[\"POLYLINE\"])):\n    if train_df[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_last_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[-1]\n        lists_last_lat.append(k)\n        \ntrain_df[\"lat_last\"] = lists_last_lat","3c76200a":"# Delete lon & lat have \"0\".\ntrain_df = train_df.query(\"lon_last != 0\")","6ecb30c6":"train_df[\"lon_1st\"] = [float(k) for k in train_df[\"lon_1st\"]]\ntrain_df[\"lat_1st\"] = [float(k) for k in train_df[\"lat_1st\"]]\ntrain_df[\"lon_last\"] = [float(k) for k in train_df[\"lon_last\"]]\ntrain_df[\"lat_last\"] = [float(k) for k in train_df[\"lat_last\"]]","b0fbb2a4":"# Visualization, sampling 5000 datas.\nmapping_1st = pd.DataFrame({\n    \"date\":train_df.head(5000)[\"dt\"].values,\n    \"lat\":train_df.head(5000)[\"lat_1st\"].values,\n    \"lon\":train_df.head(5000)[\"lon_1st\"].values\n})\n\nmapping_last = pd.DataFrame({\n    \"date\":train_df.head(5000)[\"dt\"].values,\n    \"lat\":train_df.head(5000)[\"lat_last\"].values,\n    \"lon\":train_df.head(5000)[\"lon_last\"].values\n})\n\npor_map = folium.Map(location=[41.141412,-8.590324], tiles='Stamen Terrain', zoom_start=11)\n\nfor i, r in mapping_1st.iterrows():\n    folium.CircleMarker(location=[r[\"lat\"],r[\"lon\"]], radius=0.5, color=\"red\").add_to(por_map)\n\nfor i, r in mapping_last.iterrows():\n    folium.CircleMarker(location=[r[\"lat\"],r[\"lon\"]], radius=0.5, color=\"blue\").add_to(por_map)    \n    \npor_map","061cc316":"train_df[\"delta_lon\"] = train_df[\"lon_last\"] - train_df[\"lon_1st\"]\ntrain_df[\"delta_lat\"] = train_df[\"lat_last\"] - train_df[\"lat_1st\"]","60f39c65":"# sampling : 5,000 point\nsample = train_df.head(5000)\n\nwith plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(1,3,figsize=(20, 6))\n    \n    # plot\n    ax[0].scatter(sample[\"delta_lon\"], sample[\"delta_lat\"], s=3, c=\"red\")\n    ax[0].set_xlabel(\"delta longitude\")\n    ax[0].set_ylabel(\"delta_latitude\")\n    \n    # delta longitude distribution\n    ax[1].hist(sample[\"delta_lon\"], bins=30, color=\"red\")\n    ax[1].set_xlabel(\"delta longitude\")\n    ax[1].set_ylabel(\"count\")\n    ax[1].set_yscale(\"log\")\n    \n    # delta latitude distribution\n    ax[2].hist(sample[\"delta_lat\"], bins=30, color=\"red\")\n    ax[2].set_xlabel(\"delta latitude\")\n    ax[2].set_ylabel(\"count\")\n    ax[2].set_yscale(\"log\")","4fa8673a":"# monthly, delta longtitude & latitude boxplot\ntrain_df[\"month_str\"] = [str(i) for i in train_df[\"month\"]]","907dc10a":"with plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(1,2, figsize=(20,6))\n    # delta_lon\n    sns.boxplot(\"month_str\", \"delta_lon\", data=train_df, ax=ax[0])\n    ax[0].set_xlabel(\"month\")\n    ax[0].set_ylabel(\"delta_lon\")\n    ax[0].set_ylim([-0.3,0.3])\n    # delta_lat\n    sns.boxplot(\"month_str\", \"delta_lat\", data=train_df, ax=ax[1])\n    ax[1].set_xlabel(\"month\")\n    ax[1].set_ylabel(\"delta_lon\")\n    ax[1].set_ylim([-0.3,0.3])","95c65081":"# weekday, delta longtitude & latitude boxplot\ntrain_df[\"weekday_str\"] = [str(i) for i in train_df[\"weekday\"]]","9eb06972":"with plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(1,2, figsize=(20,6))\n    # delta_lon\n    sns.boxplot(\"weekday_str\", \"delta_lon\", data=train_df, ax=ax[0])\n    ax[0].set_xlabel(\"weekday\\n (0:Monday ~ 6:Sunday)\")\n    ax[0].set_ylabel(\"delta_lon\")\n    ax[0].set_ylim([-0.3,0.3])\n    # delta_lat\n    sns.boxplot(\"weekday_str\", \"delta_lat\", data=train_df, ax=ax[1])\n    ax[1].set_xlabel(\"weekday\\n (0:Monday ~ 6:Sunday)\")\n    ax[1].set_ylabel(\"delta_lon\")\n    ax[1].set_ylim([-0.3,0.3])","da8c8673":"# copy dataframe\ndf_ml = train_df.copy()\n\n# outlier is dropped\ndf_ml = df_ml.query(\"delta_lon <= 0.2 & delta_lon >= -0.2 & delta_lat <= 0.2 & delta_lat >= -0.2\")","f7125930":"# Call type <= 0.2 & delta_lon>=\nmap_call = {\"A\":1, \"B\":2, \"C\":3}\ndf_ml[\"Call_type\"] = df_ml[\"CALL_TYPE\"].map(map_call)\n\n# Origin_call\ndef origin_call_flg(x):\n    if x[\"ORIGIN_CALL\"] == None:\n        res = 0\n    else:\n        res = 1\n    return res\ndf_ml[\"ORIGIN_CALL\"] = df_ml.apply(origin_call_flg, axis=1)\n\n# Origin_stand\ndef origin_stand_flg(x):\n    if x[\"ORIGIN_STAND\"] == None:\n        res = 0\n    else:\n        res=1\n    return res\ndf_ml[\"ORIGIN_STAND\"] = df_ml.apply(origin_stand_flg, axis=1)\n\n# Day type\ndf_ml.drop(\"DAY_TYPE\", axis=1, inplace=True)\n\n# Missing data\ndef miss_flg(x):\n    if x[\"MISSING_DATA\"] == \"False\":\n        res = 0\n    else:\n        res = 1\n    return res\ndf_ml[\"MISSING_DATA\"] = df_ml.apply(miss_flg, axis=1)","7166764c":"df_ml = df_ml.sample(50000)","ddacf4a1":"X = df_ml[[\"Call_type\", 'ORIGIN_CALL', 'ORIGIN_STAND', 'MISSING_DATA', 'lon_1st', 'lat_1st', 'delta_lon', 'delta_lat']]","8016bda0":"y = df_ml[[\"lon_last\",\"lat_last\"]]","7f8815d9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","c11f5344":"forest = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=1))\n\n# Fitting\nforest = forest.fit(X_train, y_train)","296c8531":"y_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)","0924ed85":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","4988f3b5":"print(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred)))\nprint(\"MSE test;{}\".format(mean_squared_error(y_test, y_test_pred)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred)))\nprint(\"R2 score test:{}\".format(r2_score(y_test, y_test_pred)))","7e0319db":"# 1st lon\nlists_1st_lon = []\nfor i in range(0,len(test_df[\"POLYLINE\"])):\n    if train_df[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lon.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", test_df[\"POLYLINE\"][i]).split(\",\")[0]\n        lists_1st_lon.append(k)\n        \ntest_df[\"lon_1st\"] = lists_1st_lon\n\n# 1st lat\nlists_1st_lat = []\nfor i in range(0,len(test_df[\"POLYLINE\"])):\n    if test_df[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", test_df[\"POLYLINE\"][i]).split(\",\")[1]\n        lists_1st_lat.append(k)\n        \ntest_df[\"lat_1st\"] = lists_1st_lat","7d8d6c44":"# last long\nlists_last_lon = []\nfor i in range(0,len(test_df[\"POLYLINE\"])):\n        if test_df[\"POLYLINE\"][i] == '[]':\n            k=0\n            lists_last_lon.append(k)\n        else:\n            k = re.sub(r\"[[|[|]|]|]]\", \"\", test_df[\"POLYLINE\"][i]).split(\",\")[-2]\n            lists_last_lon.append(k)\n\ntest_df[\"lon_last\"] = lists_last_lon\n\n# last lat\nlists_last_lat = []\nfor i in range(0,len(test_df[\"POLYLINE\"])):\n    if test_df[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_last_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", test_df[\"POLYLINE\"][i]).split(\",\")[-1]\n        lists_last_lat.append(k)\n        \ntest_df[\"lat_last\"] = lists_last_lat","4b2540a9":"# changin type str \u21d2 float\ntest_df[\"lon_1st\"] = [float(k) for k in test_df[\"lon_1st\"]]\ntest_df[\"lat_1st\"] = [float(k) for k in test_df[\"lat_1st\"]]\ntest_df[\"lon_last\"] = [float(k) for k in test_df[\"lon_last\"]]\ntest_df[\"lat_last\"] = [float(k) for k in test_df[\"lat_last\"]]\n\n# Create delta parameter\ntest_df[\"delta_lon\"] = test_df[\"lon_last\"] - test_df[\"lon_1st\"]\ntest_df[\"delta_lat\"] = test_df[\"lat_last\"] - test_df[\"lat_1st\"]","3fbed881":"# copy dataframe\ndf_ml_t = test_df.copy()\n\n# Call type <= 0.2 & delta_lon>=\nmap_call = {\"A\":1, \"B\":2, \"C\":3}\ndf_ml_t[\"Call_type\"] = df_ml_t[\"CALL_TYPE\"].map(map_call)\n\n# Origin_call\ndf_ml_t[\"ORIGIN_CALL\"] = df_ml_t.apply(origin_call_flg, axis=1)\n\n# Origin_stand\ndf_ml_t[\"ORIGIN_STAND\"] = df_ml_t.apply(origin_stand_flg, axis=1)\n\n# Day type\ndf_ml_t.drop(\"DAY_TYPE\", axis=1, inplace=True)\n\n# Missing data\ndf_ml_t[\"MISSING_DATA\"] = df_ml_t.apply(miss_flg, axis=1)","b2928fc1":"X_Test = df_ml_t[[\"Call_type\", 'ORIGIN_CALL', 'ORIGIN_STAND', 'MISSING_DATA', 'lon_1st', 'lat_1st', 'delta_lon', 'delta_lat']]","79032cd0":"y_Test_pred = forest.predict(X_Test)","bbc1e9e5":"submit_lat = y_Test_pred.T[1]\nsubmit_lon = y_Test_pred.T[0]","57f275da":"submit = pd.DataFrame({\"TRIP_ID\":test_df[\"TRIP_ID\"],\n                     \"LATITUDE\":submit_lat,\n                     \"LONGITUDE\":submit_lon})","75693f54":"submit.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","d7859cee":"Data overview (site copy)<br>\n\nTRIP_ID: (String) It contains an unique identifier for each trip;<br>\n\nCALL_TYPE: (char) It identifies the way used to demand this service. It may contain one of three possible values:<br>\n\u2018A\u2019 if this trip was dispatched from the central;<br>\n\u2018B\u2019 if this trip was demanded directly to a taxi driver on a specific stand;<br>\n\u2018C\u2019 otherwise (i.e. a trip demanded on a random street).<br>\n\nORIGIN_CALL: (integer) It contains an unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip\u2019s customer if CALL_TYPE=\u2019A\u2019. Otherwise, it assumes a NULL value;<br>\n\nORIGIN_STAND: (integer): It contains an unique identifier for the taxi stand. It identifies the starting point of the trip if CALL_TYPE=\u2019B\u2019. Otherwise, it assumes a NULL value;<br>\n\nTAXI_ID: (integer): It contains an unique identifier for the taxi driver that performed each trip;<br>\n\nTIMESTAMP: (integer) Unix Timestamp (in seconds). It identifies the trip\u2019s start; <br>\n\nDAYTYPE: (char) It identifies the daytype of the trip\u2019s start. It assumes one of three possible values:<br>\n\u2018B\u2019 if this trip started on a holiday or any other special day (i.e. extending holidays, floating holidays, etc.);<br>\n\u2018C\u2019 if the trip started on a day before a type-B day;<br>\n\u2018A\u2019 otherwise (i.e. a normal day, workday or weekend).<br>\n\nMISSING_DATA: (Boolean) It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing<br>\n\nPOLYLINE: (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip\u2019s destination while the first one represents its start;","fbf813ac":"To predict the point(longitude & latitude), I tried  to change some feature categorical numerical values.\n- Call type : A: 1, B: 2, C:3\n- Origin_call : data exist: 1, null: 0\n- Origin stand : data exist: 1, null: 0\n- Day tyoe : Only A, so this variable is no used.\\\n- Missing data : True: 1, False=0\n\nAnd Exclude outliers\n- delta_lon & delta_lat : Over +0.2, or Under -0.2 is excluded.","4566344c":"# Prediction taxi trajectory","b08e3268":"### Prediction with Random forest regression","8c47368c":"### Validation","d7ea2db0":"I tried prediction, taxi service trajectory.\n\n### agenda\n- Data loading and Data check\n- EDA\n- Data preprocessing\n- Prediction with Random forest regression\n- Validation\n- Submitting","433d4927":"- It is widely distributed, and it can be confirmed that there are many places to get in and out of the city.","6462c7dd":"Distribution of travel distance and direction<br>\n\ndelta_lon = lon_last - lon_1st<br>\ndelta_lat = lat_last - kat_last<br>\n\nConfirming the plot and each distribution by sampling 5,000 point.","a9d75571":"- By month or weekday, delta longitude and delta latitude are not so different.","b49d4be4":"test data set preprocessing","7e907dc0":"Weekday distribution","53e7a710":"- delta longtitude & latitude can be random within \u00b10.2. Occasionally there are values that are significantly off.","3046c76c":"## EDA","39168eae":"Monthly deltadistribution.<br>\nVisualize the range from -0.3 to +0.3 because most of them are near fields.","a3eceb47":"MSE","9ddb18bc":"- May is the most, and August is the lowest.","b5e1499d":"Sampling 50000(\u22523%) data and Select ML parameters<br>\nSince 1.7 million data is too large and the calculation load is high, 20000 data is randomly selected.","c58530a6":"### Submitting","76e53a2b":"Sampling 1st & last ride coordinate and last coordinate","854ebe07":"## Libraries","2ae4f27f":"- Friday is the most.","f2281ab9":"## Data checking","b1ea0498":"- Call type B is the most.","2739d535":"This score may be leaking. However, only it is considered to be effective logic for predicting from test data.","4748baac":"### Time series visualization","b5e39b6a":"train test split","652d21b4":"### Data Preprocessing"}}