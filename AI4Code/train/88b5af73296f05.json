{"cell_type":{"5638ab54":"code","dc0b00b0":"code","55865a54":"code","1117ffbf":"code","260e91b9":"code","9c50d5ea":"code","2df8c9d6":"code","a4b32a25":"code","9e04b894":"code","b58e6928":"code","c42ac125":"code","20b59803":"code","9d96e180":"code","fc62594a":"code","58809c24":"code","a73b7bd8":"code","4a06fbff":"code","1a3b0063":"code","548a383b":"code","52258634":"code","4ddc11fe":"code","56403a96":"code","b4c59d58":"code","ae3c40dc":"code","3ad56c47":"code","666c5d48":"code","ce7fb498":"code","14a685c2":"code","4a6c7b64":"code","2f575b27":"code","b75a1725":"code","953c3379":"code","cc801ca7":"code","34d351d4":"code","a52dcfdd":"code","620740fe":"code","e72739c7":"code","04b9119b":"code","63044a4a":"code","714e54e7":"code","4f729379":"code","9fb44982":"code","0aa677fa":"code","5e37fe24":"code","7de8e9f9":"code","df9e0b7d":"code","dfc266ff":"code","f3a345e6":"code","1a2bb4fb":"code","5dc41e93":"code","5845f1d4":"markdown","78e7bde1":"markdown","cf3ed143":"markdown","2b0443b3":"markdown","223feb6a":"markdown","d61df3b1":"markdown","b0d6bde2":"markdown","90ac5bec":"markdown","80e04078":"markdown","212c5059":"markdown","e6d11d2f":"markdown","1ac76d1d":"markdown","d432a8ef":"markdown","e957628a":"markdown","86574283":"markdown","84fe2bd0":"markdown","93ecd673":"markdown","69e14a35":"markdown","6b26a154":"markdown","460b882e":"markdown","30d7b6ba":"markdown","89535077":"markdown","39148a87":"markdown","62fffbb1":"markdown","ce9f38c9":"markdown","94863c7c":"markdown","99c3cd07":"markdown","0bb470a9":"markdown","5c563958":"markdown","477411d3":"markdown","fd221c37":"markdown","a61bb3bc":"markdown","d5f366f6":"markdown","753f8699":"markdown","21add000":"markdown","caccc169":"markdown","d082c87e":"markdown","c9756b80":"markdown","5830d560":"markdown","3c5f2d4e":"markdown","ab2adbc3":"markdown","7052cd20":"markdown","c619a7bd":"markdown"},"source":{"5638ab54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc0b00b0":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","55865a54":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","1117ffbf":"for feature in ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']:\n    pivot_table = pd.pivot_table(data = train_data, index=feature, values=['Survived'])\n    print(pivot_table, '\\n')","260e91b9":"sns.barplot(x= 'Pclass', y = 'Survived', data = train_data)","9c50d5ea":"sns.barplot(x= 'Sex', y = 'Survived', data = train_data)","2df8c9d6":"sns.barplot(x= 'SibSp', y = 'Survived', data = train_data)","a4b32a25":"sns.barplot(x= 'Parch', y = 'Survived', data = train_data)","9e04b894":"sns.barplot(x= 'Embarked', y = 'Survived', data = train_data)","b58e6928":"train_data['Fare'].value_counts().sort_index(ascending=True)","c42ac125":"hiFare = train_data[(train_data['Fare'] >= 100)]['Survived']\nhiRate = sum(hiFare)\/len(hiFare)\n\nmedFare = train_data[(train_data['Fare'] <= 100) & (train_data['Fare'] >= 50)]['Survived'] \nmedRate = sum(medFare)\/len(medFare)\n                          \nloFare = hiiFare = train_data[(train_data['Fare'] <= 50)]['Survived']\nloRate = sum(loFare)\/len(loFare)\n\nprint('Fare > 100 Survival Rate:', hiRate)\nprint('Fare < 100 and > 50 Survival Rate:', medRate)\nprint('Fare < 50 Survival Rate:', loRate)","20b59803":"train_data['Cabin'].value_counts().sort_index(ascending=True)","9d96e180":"elderly = train_data[(train_data['Age'] >= 50)]['Survived']\neldRate = sum(elderly)\/len(elderly)\n\nadult = train_data[(train_data['Age'] <= 50) & (train_data['Age'] >= 18)]['Survived'] \nadRate = sum(adult)\/len(adult)\n                          \nchild = train_data[(train_data['Age'] <= 18)]['Survived']\nchRate = sum(child)\/len(child)\n\nprint('Age > 50 Survival Rate:', eldRate)\nprint('Age < 50 and > 18 Survival Rate:', adRate)\nprint('Age < 18 Survival Rate:', chRate)","fc62594a":"train_data['AgeBand'] = pd.cut(train_data['Age'], 6) \ntrain_data[['AgeBand', 'Survived']].groupby('AgeBand').mean()","58809c24":"sns.barplot(x = 'AgeBand', y = 'Survived', data=train_data)\nfig = plt.gcf()\nfig.set_size_inches(18.5, 5)\nplt.xlabel('Age Groups')","a73b7bd8":"train_data['FareBand'] = pd.cut(train_data['Fare'], 6)\ntrain_data[['FareBand', 'Survived']].groupby('FareBand').mean()","4a06fbff":"train_data['FareBand'] = pd.cut(train_data['Fare'], 4)\ntrain_data[['FareBand', 'Survived']].groupby('FareBand').mean()","1a3b0063":"sns.barplot(x = 'FareBand', y = 'Survived', data=train_data)\nfig = plt.gcf()\nfig.set_size_inches(18.5, 5)\nplt.xlabel('Fare Groups')","548a383b":"drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ntrain_data = train_data.drop(drop_elements, axis = 1)\ntrain_data.head()","52258634":"test_data = test_data.drop(['Name', 'Ticket', 'Cabin'], axis = 1)\ntest_data.head()","4ddc11fe":"sexMap = {'male':0, 'female':1}\ntrain_data['Sex'] = train_data['Sex'].map(sexMap)\ntrain_data.head()","56403a96":"test_data['Sex'] = test_data['Sex'].map(sexMap)\ntest_data.head()","b4c59d58":"embMap = {'C':0, 'Q':1, 'S':2}\ntrain_data['Embarked'] = train_data['Embarked'].map(embMap)\ntrain_data.head()","ae3c40dc":"test_data['Embarked'] = test_data['Embarked'].map(embMap)\ntest_data.head()","3ad56c47":"train_data = train_data.drop(['AgeBand', 'FareBand'], axis = 1)\ntrain_data.head()","666c5d48":"colormap = plt.cm.viridis\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_data.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","ce7fb498":"train_data['Family'] = train_data['SibSp'] + train_data['Parch']\ntrain_data.head()","14a685c2":"test_data['Family'] = test_data['SibSp'] + test_data['Parch']\ntest_data.head()","4a6c7b64":"train_data = train_data.drop(['Fare', 'SibSp', 'Parch'], axis=1)\ntrain_data.head()","2f575b27":"test_data = test_data.drop(['Fare', 'SibSp', 'Parch'], axis=1)\ntest_data.head()","b75a1725":"colormap = plt.cm.viridis\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_data.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","953c3379":"train_data = train_data.drop(['Family', 'Age', 'Embarked'], axis=1)\ntrain_data.head()","cc801ca7":"test_data = test_data.drop(['Family', 'Age', 'Embarked'], axis=1)\ntest_data.head()","34d351d4":"train_data.isna().sum()","a52dcfdd":"#df = pd.DataFrame(train_data['Embarked'])\n#median = df.median()\n#print(median)\n#train_data = train_data.fillna(train_data['Embarked'].median())\n#train_data.isna().sum()\ntrain_data.median()","620740fe":"#missingEmb = train_data['Embarked']\n#missingEmb = missingEmb.fillna(2.0)\n\n#missingAge = train_data['Age']\n#missingAge = missingAge.fillna(28.0)\n#train_data = train_data['Embarked'].fillna(2.0)\n#train_data['Embarked'] = missingEmb\n#train_data['Age'] = missingAge\n#train_data.isna().sum()\n#train_data.head()","e72739c7":"test_data.isna().sum()","04b9119b":"test_data.median()","63044a4a":"#missingAge = test_data['Age']\n#missingAge = missingAge.fillna(27.0)\n#test_data['Age'] = missingAge\ntest_data.isna().sum()","714e54e7":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\n\nlr = LinearRegression()\nknn = KNeighborsClassifier()\ntree = DecisionTreeClassifier()\nsgd = SGDClassifier()\n","4f729379":"features = ['Pclass', 'Sex']\nX=train_data[features]\ny=train_data['Survived']\n#X_test = test_data[features]","9fb44982":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n\nfrom sklearn.metrics import accuracy_score","0aa677fa":"lr.fit(X_train, y_train)\nlrPred = lr.predict(X_test)\nlrAcc = lr.score(X_test,y_test)\n#print('pred', lrPred)","5e37fe24":"knn.fit(X_train, y_train)\nknnPred = knn.predict(X_test)\nknnAcc = knn.score(X_test,y_test)","7de8e9f9":"tree.fit(X_train, y_train)\ntreePred = tree.predict(X_test)\ntreeAcc = tree.score(X_test,y_test)","df9e0b7d":"sgd.fit(X_train, y_train)\nsgdPred = sgd.predict(X_test)\nsgdAcc = sgd.score(X_test,y_test)","dfc266ff":"print(\"Linear Regression Score: \", lrAcc)\nprint(\"K Nearest Neighbors Score: \", knnAcc)\nprint(\"Decision Tree Score: \", treeAcc)\nprint(\"SGD Score: \", sgdAcc)","f3a345e6":"print('K Nearest Neighbors Accuracy: ', accuracy_score(knnPred, y_test))\n#print('Decision Tree Accuracy: ', accuracy_score(treePred, y_test))\nprint('SGD Accuracy: ', accuracy_score(sgdPred, y_test))","1a2bb4fb":"X_test = test_data[features]\ntree.fit(X_train, y_train)\ntreePred = tree.predict(X_test)\ntreeAcc = tree.score(X,y)","5dc41e93":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': treePred})\noutput.to_csv('hw_submission_two_features.csv', index=False)\nprint('Submission successfully saved.')","5845f1d4":"Train test split","78e7bde1":"Use pandas to cut series into 6 groups and group by mean, view survival rate for each band","cf3ed143":"\n\nThe other features have large value counts, we can group them instead to get a better idea of survival rate","2b0443b3":"* Passengers with 1 or 2 siblings or spouses appear more likely to live\n* Confidence intervals for 2 - 4 are very large, so the data is likely flawed","223feb6a":"* Sex and Survival seem highly correlated\n* P-class and survival seem correlated\n* Fare and P-Class are Highly Correlated - can be combined\n* SibSp and Parch are seem correlated - can be combined\n* Pclass and age seem correlated\n* SibSp and age seem correlated","d61df3b1":"Passengers 18 years and younger have a higher survival rate, suprisingly there isn't an increase in survival for passengers older than 50","b0d6bde2":"Survival rate goes down with passenger class","90ac5bec":"Graph of survival rate","80e04078":"We will fill the 2 missing values with the median, with more detailed analysis we could have a more specific prediction","212c5059":"Look at the survival rate for each feature, ignore names and ID","e6d11d2f":"Convert Sex to Numerical","1ac76d1d":"# Exploratory Data Analysis - Survival Rates","d432a8ef":"Passengers who embarked from Cherbourg seem more likely to survive","e957628a":"Read and store training set, view first 5 entries and number of features","86574283":"Pearson Correlation","84fe2bd0":"* Very large confidence intervals for 3 and 5 parents\/children\n* It seems passengers with no parents\/children were less likely to survive","93ecd673":"# Build Models","69e14a35":"Import and instantiate models we will be using","6b26a154":"Passengers who paid a higher fare were more likely to survive","460b882e":"Age ,Pclass, and Family now seem to be related, Age and Family have a low correlation to survival, so we will drop them\n* For this version we will drop Embarked as well","30d7b6ba":"Drop bands from earlier","89535077":"# Evaluate Models","39148a87":"# Feature Engineering and Feature Correlation","62fffbb1":"Combine SibSp and Parch","ce9f38c9":"Convert Embarked to Numerical","94863c7c":"* For the last group the confidence interval is quite high, there is likely missing values for that group\n* Overall survival decreases with age","99c3cd07":"Read and store testing set, view first 5 entries and number of features","0bb470a9":"Fit and test SGD Classifier","5c563958":"Fit and test Decision Tree","477411d3":"* There is a large confidence interval for the third group and no interval for the fourth group\n* First group is under 40% survival rate while the last group has 100% survival rate\n* Overall survival increases with Fare","fd221c37":"Refit data and rebuild model","a61bb3bc":"Females are much more likely to survive","d5f366f6":"Fit and test KNeighbors","753f8699":"Define features we will be using","21add000":"Before moving on, check and fill any missing values","caccc169":"Sometimes SGD will show a higher score, but this value is not consistent","d082c87e":"Drop Fare and use Pclass instead, drop SibSP and Parch as well","c9756b80":"Look at heatmap again","5830d560":"Fit and test Linear Regression","3c5f2d4e":"Note that the 5th band has missing values","ab2adbc3":"# Submission","7052cd20":"In order to use the heatmap to view correlation, we will need to drop features and convert the non-numerical data to numerical","c619a7bd":"# Import Libraries and Files"}}