{"cell_type":{"36bad1a3":"code","a7daaf84":"code","bd19b16d":"code","bf16bac6":"code","0912e47d":"code","1c081107":"code","d352a217":"code","35b357da":"code","6c1ffe7f":"code","de03333c":"code","f4942b3a":"code","8672bdc1":"code","cce98336":"code","f4a3816c":"code","c0c5eaa1":"code","bc9c8253":"code","ea958051":"code","843cba02":"code","9419be70":"code","45bf4fb9":"code","b32fe71f":"code","045e9aa5":"code","412f812e":"code","670e949d":"code","41ef3003":"code","870741a7":"code","47e665da":"code","26e00400":"code","c4f0ab23":"markdown","d4fc7f51":"markdown","2c58e33d":"markdown","786920d3":"markdown","4bb5852e":"markdown","d37782a2":"markdown","3150505a":"markdown"},"source":{"36bad1a3":"DEBUG = True","a7daaf84":"!pip -q install geffnet","bd19b16d":"import os\nimport sys\nimport time\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport albumentations as A\nimport geffnet\n\ndevice = torch.device('cuda')","bf16bac6":"kernel_type = '9c_b7ns_1e_640_ext_15ep'\nimage_size = 640\nuse_amp = False\ndata_dir = '..\/input\/jpeg-melanoma-768x768'\ndata_dir2 = '..\/input\/jpeg-isic2019-768x768'\nmodel_dir = '..\/input\/melanoma-winning-models'\nenet_type = 'efficientnet-b7'\nbatch_size = 16\nnum_workers = 4\nout_dim = 9\n\nuse_meta = False\nuse_external = '_ext' in kernel_type","0912e47d":"df_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ndf_test['filepath'] = df_test['image_name'].apply(lambda x: os.path.join(data_dir, 'test', f'{x}.jpg'))","1c081107":"df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ndf_train = df_train[df_train['tfrecord'] != -1].reset_index(drop=True)\n# df_train['fold'] = df_train['tfrecord'] % 5\ntfrecord2fold = {\n    2:0, 4:0, 5:0,\n    1:1, 10:1, 13:1,\n    0:2, 9:2, 12:2,\n    3:3, 8:3, 11:3,\n    6:4, 7:4, 14:4,\n}\ndf_train['fold'] = df_train['tfrecord'].map(tfrecord2fold)\ndf_train['is_ext'] = 0\ndf_train['filepath'] = df_train['image_name'].apply(lambda x: os.path.join(data_dir, 'train', f'{x}.jpg'))\n\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('seborrheic keratosis', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('lichenoid keratosis', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('solar lentigo', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('lentigo NOS', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('cafe-au-lait macule', 'unknown'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('atypical melanocytic proliferation', 'unknown'))\n\ndf_train['diagnosis'].value_counts()","d352a217":"if use_external:\n    df_train2 = pd.read_csv(os.path.join(data_dir2, 'train.csv'))\n    df_train2 = df_train2[df_train2['tfrecord'] >= 0].reset_index(drop=True)\n    df_train2['fold'] = df_train2['tfrecord'] % 5\n    df_train2['is_ext'] = 1\n    df_train2['filepath'] = df_train2['image_name'].apply(lambda x: os.path.join(data_dir2, 'train', f'{x}.jpg'))\n\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('NV', 'nevus'))\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('MEL', 'melanoma'))\n    df_train = pd.concat([df_train, df_train2]).reset_index(drop=True)\n\ndiagnosis2idx = {d: idx for idx, d in enumerate(sorted(df_train.diagnosis.unique()))}\ndf_train['target'] = df_train['diagnosis'].map(diagnosis2idx)\nmel_idx = diagnosis2idx['melanoma']\ndiagnosis2idx","35b357da":"class SIIMISICDataset(Dataset):\n    def __init__(self, csv, split, mode, transform=None):\n\n        self.csv = csv.reset_index(drop=True)\n        self.split = split\n        self.mode = mode\n        self.transform = transform\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        image = cv2.imread(row.filepath)\n        image = image[:, :, ::-1]\n\n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image'].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n\n        image = image.transpose(2, 0, 1)\n\n        if self.mode == 'test':\n            return torch.tensor(image).float()\n        else:\n            return torch.tensor(image).float(), torch.tensor(self.csv.iloc[index].target).long()","6c1ffe7f":"transforms_val = A.Compose([\n    A.Resize(image_size, image_size),\n    A.Normalize()\n])","de03333c":"df_show = df_train.sample(1000)\ndataset_show = SIIMISICDataset(df_show, 'train', 'val', transform=transforms_val)\n# dataset_show = CloudDataset(df_train, 'train', 'val', image_size, transform=None)\n# dataset_show = CloudDataset(df_test, 'test', 'test', image_size, transform=None)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        img, label = dataset_show[idx]\n        if use_meta:\n            img = img[0]\n        axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())\n        axarr[p].set_title(str(label))","f4942b3a":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim, n_meta_features=0, load_pretrained=False):\n\n        super(enetv2, self).__init__()\n        self.n_meta_features = n_meta_features\n        self.enet = geffnet.create_model(enet_type.replace('-', '_'), pretrained=load_pretrained)\n        self.dropout = nn.Dropout(0.5)\n\n        in_ch = self.enet.classifier.in_features\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def extract(self, x):\n        x = self.enet(x)\n        return x\n\n    def forward(self, x, x_meta=None):\n        x = self.extract(x).squeeze(-1).squeeze(-1)\n        x = self.myfc(self.dropout(x))\n        return x","8672bdc1":"def get_trans(img, I):\n    if I >= 4:\n        img = img.transpose(2,3)\n    if I % 4 == 0:\n        return img\n    elif I % 4 == 1:\n        return img.flip(2)\n    elif I % 4 == 2:\n        return img.flip(3)\n    elif I % 4 == 3:\n        return img.flip(2).flip(3)\n\n    \ndef val_epoch(model, loader, is_ext=None, n_test=1, get_output=False):\n    model.eval()\n    LOGITS = []\n    PROBS = []\n    TARGETS = []\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            \n            if use_meta:\n                data, meta = data\n                data, meta, target = data.to(device), meta.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I), meta)\n                    logits += l\n                    probs += l.softmax(1)\n            else:\n                data, target = data.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    logits += l\n                    probs += l.softmax(1)\n            logits \/= n_test\n            probs \/= n_test\n\n            LOGITS.append(logits.detach().cpu())\n            PROBS.append(probs.detach().cpu())\n            TARGETS.append(target.detach().cpu())\n\n    LOGITS = torch.cat(LOGITS).numpy()\n    PROBS = torch.cat(PROBS).numpy()\n    TARGETS = torch.cat(TARGETS).numpy()\n\n    if get_output:\n        return LOGITS, PROBS\n    else:\n        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n        auc = roc_auc_score((TARGETS==mel_idx).astype(float), LOGITS[:, mel_idx])\n        auc_20 = roc_auc_score((TARGETS[is_ext==0]==mel_idx).astype(float), LOGITS[is_ext==0, mel_idx])\n        return val_loss, acc, auc, auc_20","cce98336":"PROBS = []\ndfs = []\n\nfor fold in range(5):\n    i_fold = fold\n\n    df_valid = df_train[df_train['fold'] == i_fold]\n    if DEBUG:\n        df_valid = pd.concat([\n            df_valid[df_valid['target'] == mel_idx].sample(10),\n            df_valid[df_valid['target'] != mel_idx].sample(10)\n        ])\n    print(df_valid.shape)\n\n    dataset_valid = SIIMISICDataset(df_valid, 'train', 'val', transform=transforms_val)\n    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, num_workers=num_workers)\n\n    model = enetv2(enet_type, n_meta_features=0, out_dim=out_dim)\n    model = model.to(device)\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{i_fold}.pth')\n    state_dict = torch.load(model_file)\n    state_dict = {k.replace('module.', ''): state_dict[k] for k in state_dict.keys()}\n    model.load_state_dict(state_dict, strict=True)\n    model.eval()\n\n    this_LOGITS, this_PROBS = val_epoch(model, valid_loader, is_ext=df_valid['is_ext'].values, n_test=8, get_output=True)\n    PROBS.append(this_PROBS)\n    dfs.append(df_valid)\n    \ndfs = pd.concat(dfs).reset_index(drop=True)\ndfs['pred'] = np.concatenate(PROBS).squeeze()[:, mel_idx]","f4a3816c":"# Raw auc_all\nroc_auc_score(dfs['target'] == mel_idx, dfs['pred'])","c0c5eaa1":"# Rank per fold auc_all\ndfs2 = dfs.copy()\nfor i in range(5):\n    dfs2.loc[dfs2['fold']==i, 'pred'] = dfs2.loc[dfs2['fold']==i, 'pred'].rank(pct=True)\nroc_auc_score(dfs2['target'] == mel_idx, dfs2['pred'])","bc9c8253":"# Raw auc_2020\nroc_auc_score(dfs[dfs['is_ext']==0]['target']==mel_idx, dfs[dfs['is_ext']==0]['pred'])","ea958051":"# Rank per fold auc_2020\ndfs2 = dfs[dfs.is_ext==0].copy()\nfor i in range(5):\n    dfs2.loc[dfs2['fold']==i, 'pred'] = dfs2.loc[dfs2['fold']==i, 'pred'].rank(pct=True)\nroc_auc_score(dfs2['target'] == mel_idx, dfs2['pred'])","843cba02":"n_test = 8\ndf_test = df_test if not DEBUG else df_test.head(batch_size * 2)\ndataset_test = SIIMISICDataset(df_test, 'test', 'test', transform=transforms_val)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, num_workers=num_workers)","9419be70":"models = []\nfor i_fold in range(5):\n    model = enetv2(enet_type, n_meta_features=0, out_dim=out_dim)\n    model = model.to(device)\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{i_fold}.pth')\n    state_dict = torch.load(model_file)\n    state_dict = {k.replace('module.', ''): state_dict[k] for k in state_dict.keys()}\n    model.load_state_dict(state_dict, strict=True)\n    model.eval()\n    models.append(model)\nlen(models)","45bf4fb9":"OUTPUTS = []\nPROBS = []\n\nwith torch.no_grad():\n    for (data) in tqdm(test_loader):\n\n        if use_meta:\n            data, meta = data\n            data, meta = data.to(device), meta.to(device)\n            probs = torch.zeros((data.shape[0], out_dim)).to(device)\n            for I in range(n_test):\n                l = model(get_trans(data, I), meta)\n                probs += l.softmax(1)\n        else:\n            data = data.to(device)\n            probs = torch.zeros((data.shape[0], out_dim)).to(device)\n            for model in models:\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    probs += l.softmax(1)\n\n        probs \/= n_test * len(models)\n        PROBS.append(probs.detach().cpu())\n\nPROBS = torch.cat(PROBS).numpy()\nOUTPUTS = PROBS[:, mel_idx]","b32fe71f":"df_test['target'] = OUTPUTS\ndf_test[['image_name', 'target']].to_csv(f'submission.csv', index=False)","045e9aa5":"df_test[['image_name', 'target']].head()","412f812e":"df_test.shape","670e949d":"#patient test images processing\n# patient 1 image name\nin1 = 'hello'\n# patient 1 patient_id\npi1 = 'IP23232'\n# patient 1 sex\ns1 = 'male'\n# patient 1 age\na1 = 70.0\n# patient 1 anatom_site_general_challenge. where its located\nasgc1 = 'torso'\n# patient 1 image filepath\nf1 = '..\/input\/jpeg-melanoma-768x768\/test\/ISIC_0052060.jpg'\nimport csv\nwith open('datasettesting.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"image_name\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"width\", \"height\", \"filepath\"])\n    writer.writerow([in1,pi1, s1, a1, asgc1, 6000, 4000, f1])","41ef3003":"df_single_image = pd.read_csv('datasettesting.csv')\ndf_single_image","870741a7":"# as we only read a single image, so we don't need a dataloader\ndataset_test = SIIMISICDataset(df_single_image, 'test', 'test', transform=transforms_val)\nimage = dataset_test[0]  \nimage = image.to(device).unsqueeze(0)  # a single image need to be added a new axis to act like batch_size = 1","47e665da":"with torch.no_grad():\n    probs = torch.zeros((image.shape[0], out_dim)).to(device)\n    for model in models:\n        for I in range(n_test):\n            l = model(get_trans(image, I))\n            probs += l.softmax(1)\nprobs \/= len(models) * n_test","26e00400":"prediction = probs[:, mel_idx].item()\nprediction","c4f0ab23":"# 1st Place Solution Best Model Inference Code\n\nHi, all\n\nSome of our friends want to try our trained models on their own moles ;)\n\nSo we decide to publish this kernel.\n\nThis is our infernce code for one of our best single model (Effnet-B7 w\/ input size 640),\nwhich have a cv auc_all around `0.975` (validation on both 18,19,20) using chris's splits.\n\n(To see this auc_all score you only need to set `DEBUG = False` then rerun this kernel, it takes around 7h~ to compute the whole oof on kaggle kernel)\n\n\n# Usage\n\nOne can use this kernel to check your own moles by:\n\n* Take some pictures on your moles by your phone or camera.\n* Upload it to Kaggle Datasets (remember to make it private)\n* Fork this kernel\n* Add your uploaded dataset\n* Modify `Predict` Section to predict on your own pictures!\n\n# Thanks","d4fc7f51":"# Model","2c58e33d":"# Validation Function","786920d3":"# Infer Single Image","4bb5852e":"# Read CSV","d37782a2":"# Dataset","3150505a":"# Predict"}}