{"cell_type":{"81de7e67":"code","f6e25fa0":"code","22eaded1":"code","c9619a43":"code","f76d0d49":"code","fa23aac1":"code","b39751ce":"code","90b7f83b":"code","6a3002f3":"code","bc8e5d01":"code","e7b8fa17":"code","5df0d5cc":"code","f581f539":"code","7dac0073":"code","b2dafbd0":"code","29756913":"code","b6e6f227":"code","f8d82fff":"code","9491744b":"code","3df168a3":"code","b0e456e8":"code","6d196349":"code","5ec7ac1e":"code","29695da3":"code","38efc6dc":"code","30661379":"code","ac6303cb":"code","b1750854":"code","9749fc48":"code","0bc22323":"code","787b7e1f":"code","a01c71e3":"code","956717d5":"code","d086a1a6":"markdown","9f678970":"markdown","96996000":"markdown","7d516914":"markdown","dfde4fe7":"markdown","af878961":"markdown","049d1042":"markdown","8ba2fd4e":"markdown","f8f034d9":"markdown","f335b292":"markdown","fa98a729":"markdown","69d81405":"markdown","14e53570":"markdown","1ccfcd09":"markdown","c0c66a92":"markdown","c179733c":"markdown"},"source":{"81de7e67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#import cv2 as cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6e25fa0":"# Install FAST AI lib\n!pip install fastai2 -q","22eaded1":"!pip install opencv-contrib-python","c9619a43":"from fastai2.basics           import *\nfrom fastai2.medical.imaging  import *\nimport matplotlib.pyplot as plt\nimport cv2","f76d0d49":"# It is just to try some code to check \n# if fast ai is fast enough\nfn = Path('..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00026637202179561894768')\nfname = Path('..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00007637202177411956430\/13.dcm')\ndcom = fname.dcmread()\ndcom.show(scale=dicom_windows.lungs)","fa23aac1":"mask = dcom.mask_from_blur(dicom_windows.lungs)\nwind = dcom.windowed(*dicom_windows.lungs)\n\n_,ax = subplots(1,1)\nshow_image(wind, ax=ax[0])\nshow_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[0]);","b39751ce":"bbs = mask2bbox(mask)\nlo,hi = bbs\nshow_image(wind[lo[0]:hi[0],lo[1]:hi[1]]);","90b7f83b":"path = Path('..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00007637202177411956430\/')\ndef fix_pxrepr(dcm):\n    if dcm.PixelRepresentation != 0 or dcm.RescaleIntercept<-100: return\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000","6a3002f3":"#\n# Here to read iamges one by one \n# Modify it to call in loop for all directories and images in it\n# I have put only to call with one directory\n\ndef dcm_img(fn): \n    #fn = (path\/fn).with_suffix('.dcm')\n    fn = Path('..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00007637202177411956430\/'+fn+'.dcm')\n    try:\n        x = fn.dcmread()\n        fix_pxrepr(x)\n    except Exception as e:\n        pass\n    if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512))\n    \n    \n    return x\n    #return \n    #return TensorImage(px.to_3chan(dicom_windows.lungs, bins=None))","bc8e5d01":"# Gauusing blur\ndcom_img = dcm_img(str(1))\ngdcm = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 80) # using the brain for visualization purposes\n\n_,ax = subplots(1,2)\nshow_image(gdcm,ax[0]);\nshow_image(dcom_img.windowed(*dicom_windows.lungs),ax[1]);","e7b8fa17":"px = dcom_img.pixels.flatten()\nplt.hist(px, bins=50, color='c');","5df0d5cc":"# get image pixels directly from dcm image\ntensor_dicom = dcom_img.hist_scaled()\ntensor_dicom","f581f539":"#_,ax = subplots(1,2)\nplt.imshow(tensor_dicom)","7dac0073":"gdcm.save_jpg(path='test1.jpg' , wins=[dicom_windows.lungs,dicom_windows.lungs])\ndcom_img.save_jpg(path='test2.jpg' , wins=[dicom_windows.lungs,dicom_windows.lungs])","b2dafbd0":"# Load TIF image\nfrom PIL import Image \nimg1 = Image.open('test1.jpg')\nimg2 = Image.open('test2.jpg')\n\n#img3 = cv2.addWeighted ( img1,4, img2 ,-4 ,128)\n#plt.imshow(img3,cmap=plt.cm.bone)","29756913":"#print(gdcm.dtype)\nTensor.save_tif16(gdcm,'test.tif')\n#print(gdcm)","b6e6f227":"# Load TIF image\nfrom PIL import Image \ntf_file = Image.open('test.tif')\nprint(tf_file.shape)\nplt.imshow(tf_file,cmap=plt.cm.bone)","f8d82fff":"# Same image without Gaussian blur\n# As it is very visible that there is lot of extra\n# information which may not be good\n\ndcom_img1 = dcm_img(str(5))\n#gdcm = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 75) # using the brain for visualization purposes\nshow_image(dcom_img1.windowed(*dicom_windows.lungs));","9491744b":"dcom_img = dcm_img(str(13))\ngdcm = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 75) # using the brain for visualization purposes\n\n\n_,ax = subplots(1,2)\nshow_image(gdcm,ax[0]);\nshow_image(dcom_img.windowed(*dicom_windows.lungs),ax[1]);","3df168a3":"# read new image\ndcom_img = dcm_img(str(9))\n\nmask = dcom_img.mask_from_blur(dicom_windows.lungs, sigma=0.1, thresh=0.75, remove_max=False)\n#wind = dcom_img.windowed(*dicom_windows.lungs)\nwind = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 25)\n\n_,ax = subplots(1,2)\nshow_image(wind, ax=ax[0])\nshow_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[1]);","b0e456e8":"bbs = mask2bbox(mask)\nlo,hi = bbs\nshow_image(wind[lo[0]:hi[0],lo[1]:hi[1]]);","6d196349":"# Crop image using mask\nmask_img =  wind[lo[0]:hi[0],lo[1]:hi[1]]\n\n# convert into numpy if to use in TensorFlow\nmask_img_array = mask_img.numpy()\n#mask_img_array.shape\n\n# lets see\nplt.imshow(mask_img_array,cmap=plt.cm.bone)","5ec7ac1e":"import pydicom\n\npatient_dir = '..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00032637202181710233084'\n#patient_dir = '..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00007637202177411956430'\ndatasets = []\n\n# First Order the files in the dataset\nfiles = []\nfor dcm in list(os.listdir(patient_dir)):\n    files.append(dcm) \nfiles.sort(key=lambda f: int(re.sub('\\D', '', f)))\n\n# Read in the Dataset\nfor dcm in files:\n    path = patient_dir + \"\/\" + dcm\n    datasets.append(pydicom.dcmread(path))\n\n# Plot the images\nfig=plt.figure(figsize=(16, 6))\ncolumns = 10\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = datasets[i-1].pixel_array\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img, cmap=\"plasma\")\n    plt.title(i, fontsize = 9)\n    plt.axis('off');","29695da3":"# image_path should have dir and image id\n# e.g. - ID00007637202177411956430\/1\n\ndef dcm_img_dir(image_path): \n\n    #fn = Path('..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00007637202177411956430\/'+fn+'.dcm')\n    fn = Path('..\/input\/osic-pulmonary-fibrosis-progression\/train\/'+image_path+'.dcm')\n    try:\n        x = fn.dcmread()\n        fix_pxrepr(x)\n    except Exception as e:\n        pass\n    if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512))\n    \n    \n    return x","38efc6dc":"def get_img_array(dcom_img):\n         \n    mask = dcom_img.mask_from_blur(dicom_windows.lungs, sigma=0.1, thresh=0.75, remove_max=False)\n    #wind = dcom_img.windowed(*dicom_windows.lungs)\n    wind = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 25)\n\n    bbs = mask2bbox(mask)\n    lo,hi = bbs\n\n    # Crop image using mask\n    mask_img =  wind[lo[0]:hi[0],lo[1]:hi[1]]\n\n    # convert into numpy if to use in TensorFlow\n    mask_img_array = mask_img.numpy()\n    \n    return mask_img_array\n    ","30661379":"img_dir = 'ID00007637202177411956430\/'\nimg_path = img_dir + '1'\n\ndcom_img = dcm_img_dir(img_path)\nimg_array_1 = get_img_array(dcom_img)\nimg_array_1 = cv2.resize(img_array_1, (208, 511))","ac6303cb":"from skimage.transform import rescale, resize","b1750854":"img_dir = 'ID00007637202177411956430\/'\nimg_path = img_dir + '13'\n\ndcom_img = dcm_img_dir(img_path)\nimg_array_13 = get_img_array(dcom_img)\nimg_array_13_resize = resize(img_array_13, (208, 511))","9749fc48":"plt.imshow(img_array_13,cmap=plt.cm.bone)","0bc22323":"plt.imshow(img_array_13_resize,cmap=plt.cm.bone)","787b7e1f":"print(img_array_1.shape)\nprint(img_array_13.shape)","a01c71e3":"# lets see\n#plt.imshow(img_array,cmap=plt.cm.bone)\nimport cv2 ","956717d5":"sift = cv2.xfeatures2d.SIFT_create()\n\nkp_1, desc_1 = sift.detectAndCompute(img_array_1, None)\n\nkp_2, desc_2 = sift.detectAndCompute(img_array_13, None)\n\nindex_params = dict(algorithm=0, trees=5) \nsearch_params = dict() \nflann = cv2.FlannBasedMatcher(index_params, search_params)\n\nmatches = flann.knnMatch(desc_1, desc_2, k=2)\n\ngood_points = [] \nratio = 0.3 \n\nfor m, n in matches: \n    if m.distance < ratio*n.distance: \n        good_points.append(m) \n\nprint(len(good_points))","d086a1a6":"* DCM image to take Lungs window only to center it and then gaussina blur\n* Gaussian blur could be good hyperparameter\n\n* https:\/\/www.kaggle.com\/nxrprime\/fibrosis-eda-fast-ai\/notebook#Fast.ai!-(yay-:3)","9f678970":"# Example","96996000":"# Fixing DCM images\n* https:\/\/www.kaggle.com\/jhoward\/cleaning-the-data-for-rapid-prototyping-fastai\n\nOn fixing some dcm images , more details on above notebook","7d516914":"# Convert a DICOM image into tensors","dfde4fe7":"# Save as TIF","af878961":"##### dcom_img.pixel_array, dcom_img.pixel_array.shape\ntype(gdcm)","049d1042":"# Finding similarity in images","8ba2fd4e":"# Pixel Distribution","f8f034d9":"# To create tif\/jpeg image\n\n* It is to find what is the ways to have jpeg images\n* There are many EDA notebook , here I try to summarize on conversion after reading a 2 very good notebooks","f335b292":"def dcm_tfm(fn): \n    fn = (path\/fn).with_suffix('.dcm')\n    \n    try:\n        x = fn.dcmread()\n        fix_pxrepr(x)\n    except Exception as e:\n        pass\n    if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512))\n    px = x.scaled_px\n    \n    #img_tensor = TensorImage(px.to_3chan(dicom_windows.lungs,dicom_windows.subdural, bins=None))\n    \n    px.save_jpg('test.jpg',[dicom_windows.lungs,dicom_windows.subdural], bins=None)\n    \n    return 1\n    #return \n    #return TensorImage(px.to_3chan(dicom_windows.lungs, bins=None))","fa98a729":"# Masking\n\nAnother way is to crop part that is needed to measure.\nThat is onlt lungs capacity part","69d81405":"#dcm_tfm('4')\n#show_images(dcm_tfm('3'))","14e53570":"Reference:\n* https:\/\/www.kaggle.com\/nxrprime\/fibrosis-eda-fast-ai\/notebook#Fast.ai!-(yay-:3)\n* https:\/\/www.kaggle.com\/jhoward\/cleaning-the-data-for-rapid-prototyping-fastai","1ccfcd09":"# Save as JPG","c0c66a92":"# Visialize image from a patient","c179733c":"# Another example"}}