{"cell_type":{"7a856898":"code","cb507ae7":"code","13be6d18":"code","da5664c9":"code","c3c9580f":"code","ea342ee4":"code","d6a93c74":"code","bb3f24f4":"code","e25936e8":"code","8945cd73":"code","aa1503c2":"code","681210f8":"code","489a22ce":"code","b17a4503":"code","1a79d275":"code","ea7850a5":"code","2a50f1b9":"code","ca690586":"code","efc5d467":"code","84e332e1":"code","192494bb":"code","63ecd4c9":"code","e90e7c7b":"code","3fd21f53":"code","2c60743e":"code","88735d60":"code","eef40b7b":"code","610faedd":"code","a1979011":"code","3a9621a9":"code","dc0aed4e":"code","71952c65":"code","a2b7601e":"code","241bb92e":"markdown","0e42215d":"markdown","9aa5a00e":"markdown","5e97d447":"markdown","6261279b":"markdown","2969b97f":"markdown","8a51cceb":"markdown","075d0a54":"markdown","01fdce9a":"markdown","c82e78ec":"markdown","54419734":"markdown","062854e3":"markdown","c5924236":"markdown","8fe4fa98":"markdown"},"source":{"7a856898":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb507ae7":"trainDf=pd.read_csv(\"\/kaggle\/input\/anomaly-detection\/train.csv\")\nprint(trainDf.info())","13be6d18":"trainDf.head()","da5664c9":"import matplotlib.pyplot as plt\n#plt.scatter(trainDf['value'],trainDf[]['predicted'])\ncolors = np.where(trainDf[\"is_anomaly\"]==False,'b','r')\nplt.scatter(range(15830),trainDf['value'],c=colors)","c3c9580f":"plt.scatter(range(15830),(trainDf['predicted']-trainDf['value']),c=colors)","ea342ee4":"trainDf.sort_values('timestamp').head()","d6a93c74":"trainDf.value_counts('value')","bb3f24f4":"anomCol=[]\nfor i in range(15830):\n    if trainDf['value'][i]==30:\n        if trainDf['is_anomaly'][i]:\n            anomCol.append('r')\n        else:\n            anomCol.append('b')\nplt.scatter(range(251),trainDf[trainDf['value']==30]['predicted'],c=anomCol)","e25936e8":"trainDf[trainDf['value']==30].head(85)","8945cd73":"trainDf.value_counts('is_anomaly')","aa1503c2":"trainDf.head(10)","681210f8":"trainDf['value'].unique()","489a22ce":"trainDf['value']-trainDf['predicted']","b17a4503":"trainDf.corr()","1a79d275":"points=[]\ny=[]\nfor i in range(15830):\n    curr=[trainDf['value'][i],abs(trainDf['predicted'][i]-trainDf['value'][i])]\n    points.append(curr)\n    if trainDf['is_anomaly'][i]==False:\n        y.append(0)\n    else:\n        y.append(1)\nfrom sklearn import svm\nclf=svm.SVC(class_weight={0:4,1:95})\nclf.fit(points,y)","ea7850a5":"clf.predict([[20,100],[140,65]])","2a50f1b9":"from numpy import mean\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nscores = cross_val_score(clf, points, y, scoring='roc_auc', cv=cv, n_jobs=-1)\nprint('Mean ROC AUC: %.3f' % mean(scores))","ca690586":"from sklearn.metrics import f1_score\nprint(f1_score(y,clf.predict(points)))","efc5d467":"testDf=pd.read_csv(\"\/kaggle\/input\/anomaly-detection\/test.csv\")\nprint(testDf.head())","84e332e1":"print(testDf.info())","192494bb":"ans=[]\nfor i in range(3960):\n    curr=[testDf['timestamp'][i]]\n    is_anom=clf.predict([[testDf['value'][i],abs(testDf['predicted'][i]-testDf['value'][i])]])\n    if is_anom==0:\n        curr.append(False)\n    else:\n        curr.append(True)\n    ans.append(curr)\nansDf=pd.DataFrame(ans,columns=['timestamp','is_anomaly'])","63ecd4c9":"ansDf.head()\nansDf.value_counts('is_anomaly')","e90e7c7b":"ansDf.to_csv(\"answer.csv\",index=False)","3fd21f53":"colors = np.where(ansDf[\"is_anomaly\"]==False,'b','r')\nplt.scatter(range(3960),testDf['value'],c=colors)","2c60743e":"plt.scatter(range(3960),testDf['predicted'],c=colors)","88735d60":"colors = np.where(ansDf[\"is_anomaly\"]==False,'b','r')\nplt.scatter(range(3960),(testDf['predicted']-testDf['value']),c=colors)","eef40b7b":"again we see a prominent line at y=0. the anomalies predicted by our model seem pretty reasonable","610faedd":"testDf.info()","a1979011":"testDf.value_counts('value')","3a9621a9":"colors = []\nN=79.52\nfor i in range(3960):\n    if ansDf['is_anomaly'][i]==False and np.isclose(testDf['value'][i],N):\n        colors.append('b')\n    elif ansDf['is_anomaly'][i]==True and np.isclose(testDf['value'][i],N):\n        colors.append('r')\n#colors=getOutliers(20.003840)\n\nplt.scatter(range(168),testDf[np.isclose(testDf['value'],N)]['predicted'],c=colors)\n","dc0aed4e":"cnt=0\nfig, axs=plt.subplots(4,4,figsize=(50,40))\nfor N in testDf['value'].unique():\n    colors = []\n    #plt.subplot(4,4,cnt)\n    for i in range(3960):\n        if ansDf['is_anomaly'][i]==False and np.isclose(testDf['value'][i],N):\n            colors.append('b')\n        elif ansDf['is_anomaly'][i]==True and np.isclose(testDf['value'][i],N):\n            colors.append('r')\n    #colors=getOutliers(20.003840)\n    \n    axs[cnt\/\/4,cnt%4].scatter(range(len(colors)),testDf[np.isclose(testDf['value'],N)]['predicted'],c=colors)\n    cnt+=1","71952c65":"from sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.ensemble import IsolationForest\ndef getOutliers(N):\n    colors=[]\n    vals=[]\n    inds=[]\n    for i in range(3960):\n        if np.isclose(testDf['value'][i],N):\n            vals.append([testDf['predicted'][i]])\n            inds.append(i)\n    lof=LocalOutlierFactor(n_neighbors=30)\n    clf=IsolationForest()\n    pred=lof.fit_predict(vals)\n    #pred=clf.fit_predict(vals)\n    sz=len(pred)\n    for i in pred:\n        if i==1:\n            ansDf.loc[inds[i],'is_anomaly']=False\n            colors.append('b')\n        else:\n            ansDf.loc[inds[i],'is_anomaly']=True\n            colors.append('r')\n    return colors","a2b7601e":"ansDf.to_csv(\"answer.csv\",index=False)","241bb92e":"The test dataset has PERIODIC VALUES!!!. ","0e42215d":"We do it for all values. The anomalies predicted by our model look pretty reasonable except perhaps the last few graphs were the bottom most points are still blue.","9aa5a00e":"# Exploratory Data analysis.","5e97d447":"Plotted the values versus index graph for the training dataset. In general higher values correspond to higher probabilities of being anomaly.","6261279b":"The predicted values are not so periodic but they do have a the similar structuring.","2969b97f":"The periodic dataset has only few finite values repeating in it.","8a51cceb":"# Test dataset analysis","075d0a54":"Plotting predicted vs index plot for a fixed actual value of 30.The plot is surprising intuitively because of single anomaly(near predicted<20) however the topmost point is NOT AN ANOMALY despite the large deviation.","01fdce9a":"This code uses the unsupervised learning models to get anomalies. I tested it and the results were not so good however this is good enough for verifying our models.","c82e78ec":"It is reasonable to assume that the anomalous values would have significant deviation in predicted and actual than compared to the non-anomalous values. The plot suggests that in the training dataset the anomalous values have predicted value < actual value. This might not hold on the test dataset in general and adjusting our model to consider absolute deviations seems to be a reasonable idea. Further plots also reveal that the distribution of training and test dataset might actually be pretty different. ","54419734":"Ran the SVM model on the test dataset.","062854e3":"for one fixed value we get the index vs predicted value plot.","c5924236":"# Model fitting","8fe4fa98":"I decided to go for an Support Vector Machine classifier. due to the disparity between the training and test dataset(for e.g. the max value in test dataset is 80) KNN appears to be a pretty bad choice. \n\nFurther we apply SVM on a feature mapping of actual,abs(predValue-actual) because this particular choice exposes the anomalies better than (actual,predicted) as we saw in the Exploratory data analysis. \n\nHere we are dealing with an imbalanced dataset i.e the training samples have very few anomalies and a large number of normal datapoints therefore it is neccessary to provide weights to the SVM classifier because we are more interested in anomalies. The weights are assigned in inverse of the ratio of counts of anomaly and not anomaly respectively. "}}