{"cell_type":{"34fd90c6":"code","86fd3ff1":"code","a5bba3c9":"code","9caed3c3":"code","86d75e03":"code","d1eafb7d":"code","8f0147fb":"code","eb4c8f91":"code","409f1643":"code","d5f3049e":"code","3db8d30d":"code","79138c2d":"code","7190716a":"code","bc1880f2":"code","3c570652":"code","eb908e6d":"code","1f6796be":"code","7ad8f797":"code","fc9cd3d6":"code","c476cda7":"code","795d5860":"code","68d8be76":"code","b60ac651":"code","49ea7142":"code","1b2afc09":"code","e5d211d1":"code","51360059":"code","cb1017f6":"code","032c1979":"code","67de479d":"code","fb15e49b":"code","5cb81a16":"code","4fbd2733":"code","622078ab":"code","1e43de5a":"code","428a05a1":"code","3e1413a1":"code","e0a327c2":"code","ea509652":"code","b719f8ab":"code","a87a0fc8":"code","995c28ff":"code","00237cee":"code","bcb2ebd7":"code","8d9d460f":"code","84d64195":"code","469a103e":"code","8c9609b2":"code","eb410bec":"code","77df1deb":"code","89c84e93":"code","851901a3":"code","ef125952":"code","b6ebbde8":"code","2263b52f":"code","ad774053":"code","fb0b7ef3":"code","eb6443d5":"code","44b834d8":"code","e8d0631a":"code","c7f3e9b3":"code","7abb4a36":"code","1257d6db":"code","4c28a32d":"code","b93f7cde":"code","261e41df":"code","a13ba018":"code","26c1a624":"code","3f24393c":"code","5241356d":"code","88573878":"code","a74f8355":"markdown"},"source":{"34fd90c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86fd3ff1":"import numpy as np\nimport pandas as pd\nimport string\nimport pickle\nimport operator\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport codecs\nimport gc","a5bba3c9":"with codecs.open('\/kaggle\/input\/movie-dialog-corpus\/movie_lines.tsv','rb',encoding='utf-8',errors='ignore') as f:\n    lines=f.read().split('\\n')\n    \nconversations=[]\nfor line in lines:\n    data=line.split('\\t')\n    conversations.append(data)\n    ","9caed3c3":"conversations[:11]","86d75e03":"chats = {}\nfor tokens in conversations:\n    if len(tokens) > 4:\n        idx_L=tokens[0].find('L')\n        if idx_L !=-1:\n            idx=tokens[0][idx_L+1:]\n            chat = tokens[4]\n            chat=chat[:-2]\n            chats[int(idx)] = chat","d1eafb7d":"sorted_chats=sorted(chats.items(),key=lambda x:x[0])\nsorted_chats[:5]","8f0147fb":"conves_dict = {}\ncounter = 1\nconves_ids = []\nfor i in range(1, len(sorted_chats)+1):\n    if i < len(sorted_chats):\n        if (sorted_chats[i][0] - sorted_chats[i-1][0]) == 1:\n            # 1\u3064\u524d\u306e\u4f1a\u8a71\u306e\u982d\u306e\u6587\u5b57\u304c\u306a\u3044\u306e\u3092\u78ba\u8a8d\n            if sorted_chats[i-1][1] not in conves_ids:\n                conves_ids.append(sorted_chats[i-1][1])\n            conves_ids.append(sorted_chats[i][1])\n        elif (sorted_chats[i][0] - sorted_chats[i-1][0]) > 1:            \n            conves_dict[counter] = conves_ids\n            conves_ids = []\n        counter += 1\n    else:\n        pass","eb4c8f91":"conves_dict[3]","409f1643":"context_and_target=[]\nfor conves in conves_dict.values():\n    if len(conves) % 2 != 0:\n        conves = conves[:-1]\n    for i in range(0, len(conves), 2):\n        context_and_target.append((conves[i], conves[i+1]))","d5f3049e":"context_and_target[:5]","3db8d30d":"context, target = zip(*context_and_target)","79138c2d":"context = list(context)\ntarget = list(target)","7190716a":"context[:5]","bc1880f2":"target[:5]","3c570652":"import re\ndef clean_text(text):    \n\n    text = text.lower()    \n    text = re.sub(r\"i'm\", \"i am\", text)\n    text = re.sub(r\"he's\", \"he is\", text)\n    text = re.sub(r\"she's\", \"she is\", text)\n    text = re.sub(r\"it's\", \"it is\", text)\n    text = re.sub(r\"that's\", \"that is\", text)\n    text = re.sub(r\"what's\", \"that is\", text)\n    text = re.sub(r\"where's\", \"where is\", text)\n    text = re.sub(r\"how's\", \"how is\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"won't\", \"will not\", text)\n    text = re.sub(r\"can't\", \"cannot\", text)\n    text = re.sub(r\"n't\", \" not\", text)\n    text = re.sub(r\"n'\", \"ng\", text)\n    text = re.sub(r\"'bout\", \"about\", text)\n    text = re.sub(r\"'til\", \"until\", text)\n    text = re.sub(r\"[-()\\\"#\/@;:<>{}`+=~|.!?,]\", \"\", text)\n    \n    return text","eb908e6d":"tidy_target = []\nfor conve in target:\n    text = clean_text(conve)\n    tidy_target.append(text)","1f6796be":"tidy_target[:20]","7ad8f797":"tidy_context = []\nfor conve in context:\n    text = clean_text(conve)\n    tidy_context.append(text)","fc9cd3d6":"tidy_context[:20]","c476cda7":"bos = \"<BOS> \"\neos = \" <EOS>\"\nfinal_target = [bos + conve + eos for conve in tidy_target] \nencoder_inputs = tidy_context\ndecoder_inputs = final_target","795d5860":"encoder_text = []\nfor line in encoder_inputs:\n    data = line.split(\"\\n\")[0]\n    encoder_text.append(data)","68d8be76":"len(encoder_text)","b60ac651":"encoder_text[:5]","49ea7142":"decoder_text = []\nfor line in decoder_inputs:\n    data = line.split(\"\\n\")[0]\n    decoder_text.append(data)","1b2afc09":"len(decoder_text)","e5d211d1":"decoder_text[:5]","51360059":"full_text=encoder_text+decoder_text","cb1017f6":"from keras.preprocessing.text import Tokenizer\nVOCAB_SIZE = 15000\ntokenizer = Tokenizer(num_words=VOCAB_SIZE,oov_token='<OOV>')","032c1979":"tokenizer.fit_on_texts(full_text)\nword_index = tokenizer.word_index\nprint(len(word_index))\nword_index[bos]=len(word_index)+1\nword_index[eos]=len(word_index)+1","67de479d":"index2word = {}\nfor k, v in word_index.items():\n    if v < VOCAB_SIZE:\n        index2word[v] = k\n    if v > VOCAB_SIZE:\n        continue","fb15e49b":"len(index2word)","5cb81a16":"word2index = {}\nfor k, v in index2word.items():\n    word2index[v] = k","4fbd2733":"len(word2index)","622078ab":"encoder_sequences = tokenizer.texts_to_sequences(encoder_text)\ndecoder_sequences = tokenizer.texts_to_sequences(decoder_text)\n","1e43de5a":"encoder_sequences[:5]\n","428a05a1":"for seqs in encoder_sequences:\n    for seq in seqs:\n        if seq > VOCAB_SIZE:\n            print(seq)\n            break","3e1413a1":"VOCAB_SIZE = len(index2word) + 1\nVOCAB_SIZE","e0a327c2":"decoder_sequences[:5]","ea509652":"MAX_LEN = 20\nfrom keras.preprocessing.sequence import pad_sequences\nencoder_input_data = pad_sequences(encoder_sequences, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')\ndecoder_input_data = pad_sequences(decoder_sequences, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')","b719f8ab":"import numpy as np\n\nnum_samples = len(encoder_sequences)\ndecoder_output_data = np.zeros((num_samples, MAX_LEN, VOCAB_SIZE), dtype=\"float32\")","a87a0fc8":"for i, seqs in enumerate(decoder_input_data):\n    for j, seq in enumerate(seqs):\n        if j > 0:\n            decoder_output_data[i][j][seq] = 1","995c28ff":"decoder_output_data.shape","00237cee":"decoder_input_data[0]","bcb2ebd7":"del encoder_sequences\ndel decoder_sequences\ndel full_text\ndel encoder_text\ndel decoder_text\ndel tidy_context\ndel final_target\ndel tidy_target\ndel target\ndel context\ndel context_and_target\ndel conves_dict","8d9d460f":"gc.collect()","84d64195":"embeddings_index = {}\nwith open('\/kaggle\/input\/glove6b100dtxt\/glove.6B.100d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n    f.close()\n\nprint(\"Glove Loded!\")","469a103e":"embedding_dimention = 100\ndef embedding_matrix_creater(embedding_dimention, word_index):\n    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimention))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n          # words not found in embedding index will be all-zeros.\n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix","8c9609b2":"embedding_matrix = embedding_matrix_creater(embedding_dimention, word_index=word2index)\n","eb410bec":"from keras.layers import Embedding\nfrom keras.layers import Input, Dense, LSTM, TimeDistributed\nfrom keras.models import Model","77df1deb":"embed_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=embedding_dimention, trainable=True,)\nembed_layer.build((None,))\nembed_layer.set_weights([embedding_matrix])","89c84e93":"HIDDEN_DIM=300\n    \nencoder_inputs = Input(shape=(None, ), dtype='int32',)\nencoder_embedding = embed_layer(encoder_inputs)\nencoder_LSTM = LSTM(HIDDEN_DIM, return_state=True)\nencoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\nencoder_states=[state_h,state_c]\n\ndecoder_inputs = Input(shape=(None, ), dtype='int32',)\ndecoder_embedding = embed_layer(decoder_inputs)\ndecoder_LSTM = LSTM(HIDDEN_DIM, return_state=True, return_sequences=True)\ndecoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=encoder_states)\n\ndecoder_state_input_h=Input(shape=(HIDDEN_DIM,))\ndecoder_state_input_c=Input(shape=(HIDDEN_DIM,))\n\ndecoder_state_inputs=[decoder_state_input_h,decoder_state_input_c]\nnew_decoder_outputs,new_state_h,new_state_c=decoder_LSTM(decoder_embedding,initial_state=decoder_state_inputs)\n\ndecoder_states=[new_state_h,new_state_c]\nnew_decoder_outputs=TimeDistributed(Dense(VOCAB_SIZE,activation='softmax'))(new_decoder_outputs)\n\noutputs = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(decoder_outputs)\n\nmodel = Model([encoder_inputs, decoder_inputs], outputs)    \n \n    \n  ","851901a3":"model.summary()","ef125952":"from keras.utils import plot_model\nplot_model(model)","b6ebbde8":"plot_model(encoder_model)","2263b52f":"plot_model(decoder_model)","ad774053":"model.compile(optimizer='adam', loss ='categorical_crossentropy', metrics = ['accuracy'])","fb0b7ef3":"BATCH_SIZE = 128\nEPOCHS = 1","eb6443d5":"encoder_input_data.shape","44b834d8":"history = model.fit([encoder_input_data, decoder_input_data], \n                     decoder_output_data, \n                     epochs=EPOCHS, validation_split=0.2,                    \n                     batch_size=BATCH_SIZE)","e8d0631a":"model.save('my_model')","c7f3e9b3":"print(model.input)\nprint()\n\nprint(model.layers[0])\nprint(model.layers[1])\nprint(model.layers[2])\nprint(model.layers[3])\nprint(model.layers[4])\nprint(model.layers[5])","7abb4a36":"def encoder_decoder_model(model):\n    encoder_inputs=model.input[0]\n    embedding_layer=model.layers[2]\n    \n    encoder_embedding=embedding_layer(encoder_inputs)\n    encoder_lstm=model.layers[3]\n    encoder_output,state_h,state_c=encoder_lstm(encoder_embedding)\n    encoder_states=[state_h,state_c]\n    \n    decoder_inputs=model.input[1]\n    decoder_embedding=embedding_layer(decoder_inputs)\n    decoder_lstm=model.layers[4]\n    decoder_outputs,_,_=decoder_lstm(decoder_embedding, initial_state=encoder_states)\n    \n    \n    decoder_state_input_h=Input(shape=(300,))\n    decoder_state_input_c=Input(shape=(300,))\n    \n    decoder_state_inputs=[decoder_state_input_h,decoder_state_input_c]\n    new_decoder_outputs,new_state_h,new_state_c=decoder_lstm(decoder_embedding,initial_state=decoder_state_inputs)\n    decoder_states=[new_state_h,new_state_c]\n    new_decoder_outputs=model.layers[5](new_decoder_outputs)\n    \n\n    encoder_model=Model(encoder_inputs,encoder_states)\n    decoder_model=Model([decoder_inputs]+decoder_state_inputs,[new_decoder_outputs]+decoder_states)\n    \n    return encoder_model,decoder_model\n    \n    \n    \n    \n    \n    ","1257d6db":"encoder_model,decoder_model=encoder_decoder_model(model)","4c28a32d":"plot_model(encoder_model)","b93f7cde":"plot_model(decoder_model)","261e41df":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize=(10, 6))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\nplt.show()\nplt.savefig('model accuracy')","a13ba018":"plt.figure(figsize=(10, 6))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\nplt.show()\nplt.savefig('model loss')","26c1a624":"model.save('same_model.h5')","3f24393c":"def str_to_tokens(sentence:str):\n    \n    words=sentence.lower().split()\n    tokens_list=list()\n    for word in words:\n        tokens_list.append(tokenizer.word_index[word])\n    return pad_sequences([tokens_list],maxlen=20,padding='post')","5241356d":"sentences=[\"hey how are you\",\n           \"we should go out and play\",\n           \"voilence is bad we should never do it\",\n           \"sharing is caring\",\n           \"i am going to the football game, want to come?\"]\n\n","88573878":"for i in range(5):\n    states_values=encoder_model.predict(str_to_tokens(sentences[i]))\n    empty_target_seq=np.zeros((1,1))\n    empty_target_seq[0,0]=tokenizer.word_index[bos]\n    stop_condition=False\n    decoded_translation=\"\"\n    \n    while not stop_condition:\n        dec_outputs,h,c=decoder_model.predict([empty_target_seq]+states_values)\n        sampled_word_index=np.argmax(dec_outputs[0,-1,:])\n        \n        \n        sampled_word=None\n        for word,index in tokenizer.word_index.items():\n            if sampled_word_index==index:\n                decoded_translation+=' {}'.format(word)\n                sampled_word=word\n                \n        if sampled_word ==eos or len(decoded_translation.split())>20:\n            stop_condition=True\n        \n        \n        empty_target_seq=np.zeros((1,1))\n        \n        empty_target_seq[0,0]=sampled_word_index\n        #print(\"empty target sequence\",empty_target_seq)\n        states_values=[h,c]\n        \n    print(decoded_translation)","a74f8355":"# model training complete!! Time for predictions!!"}}