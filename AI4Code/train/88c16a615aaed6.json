{"cell_type":{"81c15267":"code","802ab74e":"code","5f2a3195":"code","6a22d80a":"code","d4273ce3":"code","6b8a0cf9":"code","467d166b":"code","849fa264":"code","ab760646":"code","b1b44d01":"code","c322c3c8":"code","fdf185c3":"code","8c9ccc40":"code","c486d4ef":"code","c97c66a6":"code","0d447c79":"code","8029064a":"code","e6eb9ee4":"code","83b7fb71":"code","1e3236da":"code","e257eb34":"code","40ad07d2":"code","f0ec12a7":"code","ad6e6bcc":"code","5a42a60d":"code","0d6890d1":"markdown","b6548da0":"markdown","3a5358c9":"markdown","c167cc54":"markdown","06a1f034":"markdown","8ab1d7f7":"markdown","493e1d1c":"markdown","fe9ab0ba":"markdown","e4eb921c":"markdown"},"source":{"81c15267":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pickle as pkl\nimport cv2\nimport os\nimport seaborn as sns\n\nfrom plotly import graph_objects as go\nfrom plotly import express as px\nfrom xml.etree import ElementTree as et\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nfrom keras.models import Sequential\nfrom keras.layers.experimental import preprocessing as ps\nfrom keras.layers.experimental import preprocessing as ps\nfrom keras.layers import Activation, Conv2D, BatchNormalization, Dense, Flatten, Dropout, MaxPooling2D\nfrom keras.callbacks import EarlyStopping\nfrom keras.losses import CategoricalCrossentropy\nfrom sklearn.metrics import confusion_matrix","802ab74e":"data = []\nlabel2category = {'with_mask': 0, 'without_mask': 1, 'mask_weared_incorrect': 2}\ncategory2label = {0: 'with_mask', 1: 'without_mask', 2: 'mask_weared_incorrect'}\ncategory2color = {0: (0,255,0), 1: (0,0,255), 2: (0,165,255)}","5f2a3195":"for dir, _, files in os.walk('\/kaggle\/input\/face-mask-detection\/annotations'):\n    for file_ in files:\n        dict_ = dict(img_path=None, objs=[])\n\n        path = os.path.join(dir, file_)\n        tree = et.parse(path)\n        dict_['img_path'] = os.path.join('\/kaggle\/input\/face-mask-detection\/images', tree.find('filename').text)\n        for obj in tree.findall('object'):\n            label = obj.find('name').text\n\n            xmin = int(obj.find('bndbox\/xmin').text)\n            ymin = int(obj.find('bndbox\/ymin').text)\n            xmax = int(obj.find('bndbox\/xmax').text)\n            ymax = int(obj.find('bndbox\/ymax').text)\n\n            dict_['objs'].append([xmin, ymin, xmax, ymax, label2category[label]])\n        data.append(dict_)","6a22d80a":"%%time\n\nplt.figure(figsize=(20,12))\n\nfor i, _data in enumerate(data[22:28]):\n    img = cv2.imread(_data['img_path'])\n    for (xmin, ymin, xmax, ymax, label) in _data['objs']:\n        cv2.rectangle(img , (xmin, ymin), (xmax, ymax), category2color[label], 2)\n        cv2.putText(img, str(label), (xmin+5, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, category2color[label], 2)\n    plt.subplot(2,3, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\nplt.show()","d4273ce3":"labels = []\nfor _data in data:\n    for (xmin, ymin, xmax, ymax, label) in _data['objs']:\n        label = category2label[label]\n        labels.append(label)\n\nlabels = np.array(labels)\nlabels_count = Counter(labels)\n\nplt.figure(figsize=(8,5))\nplt.title('Number of image tags')\n\nplt.barh(list(labels_count.keys()), list(labels_count.values()), color=['r', 'b', 'g'])\nfor i,v in enumerate(labels_count.values()):\n    plt.text(v, i, str(v))\nplt.show()","6b8a0cf9":"aug_model = Sequential()\naug_model.add(ps.RandomFlip())\naug_model.add(ps.RandomRotation(0.4))\n\ndef augment_data(input_img, aument_model, input_label=None, iterate=3):\n    img_list = []\n    label = []\n\n    label = None\n    for _ in range(iterate):\n        batch = tf.expand_dims(input_img, 0)\n        aug = aug_model(batch)\n        img_list.append(np.array(aug[0]))\n    return img_list","467d166b":"%%time\n\nx = []\ny = []\nIMG_SIZE = (64,64)\n\nfor _data in data:\n\n  img_path = _data['img_path']\n  for (xmin, ymin, xmax, ymax, label) in _data['objs']:\n    img = cv2.imread(img_path)\n    crop_img = img[ymin : ymax, xmin : xmax]\n    re_img = cv2.resize(crop_img, IMG_SIZE)\n    re_img = re_img\/255\n    target = to_categorical(label, num_classes=3)\n\n    if label == 2:\n      aug_img = augment_data(re_img, aug_model, iterate=10)\n      for aug in aug_img:\n        x.append(np.array(aug)); y.append(target)\n    elif label == 1:\n        aug_img = augment_data(re_img, aug_model, iterate=3)\n        for aug in aug_img:\n            x.append(np.array(aug)); y.append(target)\n    else:\n      x.append(re_img); y.append(target)","849fa264":"x = np.array(x)\ny = np.array(y)","ab760646":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)","b1b44d01":"print('x_train shape: {}'.format(x_train.shape))\nprint('x_test shape: {}'.format(x_test.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('y_test shape: {}'.format(y_test.shape))","c322c3c8":"def category_convert(data):\n    num = []\n    for i in range(len(data)):\n        num.append(category2label[data[i].argmax()])\n    counter = Counter(num)\n\n    return counter\n\ndef percent(df):\n    _sum = df.sum()\n    per = (df\/_sum) * 100\n    return per\n\ndef df_counter(train_counter, test_counter):\n    df = pd.DataFrame(columns=['train', 'test'])\n    for x in list(train_counter.keys()):\n        df.loc[x] = [train_counter[x], test_counter[x]]\n    return df","fdf185c3":"num_train = category_convert(y_train)\nnum_test = category_convert(y_test)","8c9ccc40":"df = df_counter(num_train, num_test)\ndf.plot(kind='barh')","c486d4ef":"p_train = percent(df['train'])\np_test = percent(df['test'])\n\nprint('in train data:\\n with mask: {:.2f} %, without mask: {:.2f} %, mask weared incorrect: {:.2f} %'\\\n      .format(p_train['with_mask'], p_train['without_mask'], p_train['mask_weared_incorrect']))\nprint('in test data:\\n with mask: {:.2f} %, without mask: {:.2f} %, mask weared incorrect: {:.2f} %'\\\n      .format(p_test['with_mask'], p_test['without_mask'], p_test['mask_weared_incorrect']))","c97c66a6":"model = Sequential()\n\nmodel.add(Conv2D(32, (3,3), input_shape=x_train.shape[1:], activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(1,1), padding='same'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3,3), input_shape=x_train.shape[1:], activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(1,1), padding='same'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3,3), input_shape=x_train.shape[1:], activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(1,1), padding='same'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.summary()","0d447c79":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","8029064a":"CALLBACKS = EarlyStopping(monitor='val_accuracy', patience=10)","e6eb9ee4":"%%time\n\nEPOCHS = 100\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=EPOCHS,\n    validation_data=(x_test, y_test),\n    callbacks=[CALLBACKS]\n)","83b7fb71":"model.evaluate(x_test, y_test)","1e3236da":"yhat = np.argmax(model.predict(x_test), axis=1)\ny = np.argmax(y_test, axis=1)","e257eb34":"sns.heatmap(confusion_matrix(yhat, y), annot=True, cmap='rainbow')\nplt.ylabel('Predicted output')\nplt.xlabel('True output')\nplt.show()","40ad07d2":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nl = history.history['loss']\nval_l = history.history['val_loss']\nepoch_len = range(1,len(l)+1)","f0ec12a7":"# plot the loss\n\nplt.plot(epoch_len, val_l, label='val_loss')\nplt.plot(epoch_len, l, label='loss')\nplt.xlabel('epoch')\nplt.ylabel('')\nplt.legend()\nplt.show()","ad6e6bcc":"# plot the accuracy\n\nplt.plot(epoch_len, val_acc, label='val_accuracy')\nplt.plot(epoch_len, acc, label='accuracy')\nplt.xlabel('epoch')\nplt.ylabel('')\nplt.legend()\nplt.show()","5a42a60d":"## uncomment the code below to save the model\n# model.save('Mask_detection_AI.h5')","0d6890d1":"## Plot the loss and accurcy of model","b6548da0":"cut only faces at the images","3a5358c9":"## Build our model","c167cc54":"we put the path and informations of images in a dictionary and we append them to 'data' list","06a1f034":"## Introduction\nIn this kernal we will going through the whole process of creating a AI on the 'mask_detect' dataset. we'll be analyzing, cleaning and visulizing the data in different forms to obtain hidden insights and create an accurate model. Also, if you like it, don't forget to upvote.\nthe complete project with 97% accuracy is in my github repository(link in profile).","8ab1d7f7":"## Split data","493e1d1c":"## Images visualization","fe9ab0ba":"## Import libraries","e4eb921c":"## Preprocess data"}}