{"cell_type":{"0949ba14":"code","4797c2c2":"code","8fa6c397":"code","ed65c371":"code","685238fd":"code","1120a8a2":"code","29251750":"code","8b1e54cf":"code","ef582059":"code","5dea3367":"code","3cce7448":"code","22c8419f":"code","080ccbea":"code","aa59494e":"code","dea6044e":"code","4abb9546":"code","f2dbd8aa":"code","81499a5b":"code","3cc5302c":"code","592e4468":"code","c885af51":"code","a31a96c8":"code","78dc76a9":"code","b62e6c0d":"markdown","3b6b6f7e":"markdown"},"source":{"0949ba14":"# Load package to display pictures and videos\nfrom IPython.display import Audio, Image, YouTubeVideo","4797c2c2":"# Display a video using the id which is the string between the = and & (if there is an &)\nYouTubeVideo(id='m_dBwwDJ4uo', width=600, height=400)","8fa6c397":"# Display a video using the id which is the string between the = and & (if there is an &)\nYouTubeVideo(id='P7h0JfQ-oHg', width=600, height=400)","ed65c371":"# Import specific packages and modules\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR\nfrom sklearn.metrics import mean_absolute_error\n\nimport os\nprint(os.listdir(\"..\/input\"))","685238fd":"# Gives number of rows without loading the file first\n! wc -l \"..\/input\/train.csv\"","1120a8a2":"# Load training data\n# I used float32 and not float64 (like the example) since I did not have the memory for float64.\ntrain = pd.read_csv(\"..\/input\/train.csv\", dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})","29251750":"# Display time_to_failure with more units of precision\npd.options.display.precision = 15","8b1e54cf":"train.head()","ef582059":"# Break approximately 600 million rows up into 150K segments.\nrows = 150_000\n\n# Determine how many EQUAL segments to divide total dataset into.\n# Following code takes the first [0] (or zero) column of the train data. Then divides by rows (or 150,000).\n# Then rounds the value down (or floor). Then sets the value as an integer. \nsegments = int(np.floor(train.shape[0] \/ rows))\nprint(segments)","5dea3367":"# Create an empty dataframe (X_train) which is the size of the dataset\/ 150000 or 4194 with ave, std, max, min columns.\n# Create another empty dataframe (y_train) with just the time to failure.\n# For both dataframes, index is set as range of the segments.\n# range() function returns a sequence of numbers with format range(start, stop, step) with start=1 and step=1 if not given\nX_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n                       columns=['ave', 'std', 'max', 'min'])\ny_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n                       columns=['time_to_failure'])","3cce7448":"# Empty dataframe for X_train\nX_train.head()","22c8419f":"# Empty dataframe for y_train\ny_train.head()","080ccbea":"# Calculate all the values for each of the 4194 segments in the X_train dataframe (mean, std, max, min).\n\n# tqdm make your loops show a smart progress meter\n\n# iloc is integer-location based indexing for selection by position\n# [segment*rows:segment*rows+rows] points to which data to apply calculation to\n# loops through all segments starting at 0 to 150k then 150k to 300k, etc.\n# For each segment, the mean, standard deviation, maximum and min are computed.\n\n# Fill in the time values for the y_train dataframe. .values[-1] will point to the last time value in the 150,000 segment\n\nfor segment in tqdm(range(segments)):\n    seg = train.iloc[segment*rows:segment*rows+rows]\n    x = seg['acoustic_data'].values\n    y = seg['time_to_failure'].values[-1]\n    \n    y_train.loc[segment, 'time_to_failure'] = y\n    \n    X_train.loc[segment, 'ave'] = x.mean()\n    X_train.loc[segment, 'std'] = x.std()\n    X_train.loc[segment, 'max'] = x.max()\n    X_train.loc[segment, 'min'] = x.min()","aa59494e":"# View the X_train dataframe after the engineered features added\nX_train.head()","dea6044e":"# View the y_train dataframe after calculation applied to it.\ny_train.head()","4abb9546":"# Create a StandardScaler model called scaler.\n# Normalize\/standardize (mean = 0 and standard deviation = 1) features before applying machine learning techniques.\nscaler = StandardScaler()\n\n# fit will apply the scaler model to the dataframe (X_train in this case)\nscaler.fit(X_train)\n\n# transform will look at the dataframe columns one by one and return back a series (or group of series) 'made' of scalars\nX_train_scaled = scaler.transform(X_train)\nprint(X_train_scaled)","f2dbd8aa":"# Create a model Nu Support Vector Regression\n# In simple regression we try to minimise the error rate. While in SVR we try to fit the error within a certain threshold.\n# NuSVR allows you to limit the number of support vectors used.\n# Create svm model and fit to the data\n# .flatten will return a copy of the array collapsed into one dimension\nsvm = NuSVR()\nsvm.fit(X_train_scaled, y_train.values.flatten())\n\n# Predict y (acoustic data) with the model\ny_pred = svm.predict(X_train_scaled)\nprint(y_pred)# Create a model Nu Support Vector Regression\n# In simple regression we try to minimise the error rate. While in SVR we try to fit the error within a certain threshold.\n# NuSVR allows you to limit the number of support vectors used.\n# Create svm model and fit to the data\n# .flatten will return a copy of the array collapsed into one dimension\nsvm = NuSVR()\nsvm.fit(X_train_scaled, y_train.values.flatten())\n\n# Predict y (acoustic data) with the model\ny_pred = svm.predict(X_train_scaled)\nprint(y_pred)","81499a5b":"# Plot y actual vs y predicted\n# Orange diagonal line is point of reference to compare acutal (on x-axis) vs predicted (on y-axis)\nplt.figure(figsize=(6, 6))\nplt.scatter(y_train.values.flatten(), y_pred)\nplt.xlim(0, 20)\nplt.ylim(0, 20)\nplt.xlabel('actual', fontsize=12)\nplt.ylabel('predicted', fontsize=12)\nplt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\nplt.show()","3cc5302c":"# Determine the score of the model\nscore = mean_absolute_error(y_train.values.flatten(), y_pred)\nprint(f'Score: {score:0.3f}')","592e4468":"# Read in the blank sample submission file\nsubmission = pd.read_csv('..\/input\/sample_submission.csv', index_col='seg_id')\nsubmission.head()","c885af51":"# Prepare the dataframe for the test segments so can apply svm model\nX_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)\nX_test.head()","a31a96c8":"# Read in each test segment, apply engineered features and put in dataframe.\nfor seg_id in X_test.index:\n    seg = pd.read_csv('..\/input\/test\/' + seg_id + '.csv')\n    \n    x = seg['acoustic_data'].values\n    \n    X_test.loc[seg_id, 'ave'] = x.mean()\n    X_test.loc[seg_id, 'std'] = x.std()\n    X_test.loc[seg_id, 'max'] = x.max()\n    X_test.loc[seg_id, 'min'] = x.min()\n\nX_test.head()","78dc76a9":"# Apply the model to the X_test dataframe by scaling then transforming it.\nX_test_scaled = scaler.transform(X_test)\nsubmission['time_to_failure'] = svm.predict(X_test_scaled)\n\n# Prepare submission for Kaggle\n# Best to use date and submssion\nsubmission.to_csv('submission_one_04_15.csv')","b62e6c0d":"In this competition, you will address when the earthquake will take place. Specifically, you\u2019ll predict the time remaining before laboratory earthquakes occur from real-time seismic data.\n\nHow is the data generated?\n- The data are from an experiment conducted on rock in a double direct shear geometry subjected to bi-axial loading, a classic laboratory earthquake model. (fig. a)\n- Two fault gouge layers are sheared simultaneously while subjected to a constant normal load and a prescribed shear velocity. The laboratory faults fail in repetitive cycles of stick and slip that is meant to mimic the cycle of loading and failure on tectonic faults. While the experiment is considerably simpler than a fault in Earth, it shares many physical characteristics. (fig. b)\n- Los Alamos' initial work showed that the prediction of laboratory earthquakes from continuous seismic data is possible in the case of quasi-periodic laboratory seismic cycles. In this competition, the team has provided a much more challenging dataset with considerably more aperiodic earthquake failures.\n- The seismic data is recorded using a piezoceramic sensor, which outputs a voltage upon deformation by incoming seismic waves. The seismic data of the input is this recorded voltage, in integers.\n- The acoustic data shows the movement of the ground up (positive) and ground down (negative).\n\nPublished work on the topic is in the following papers:\n- https:\/\/doi.org\/10.1002\/2017GL074677\n- https:\/\/doi.org\/10.1002\/2017GL076708\n- https:\/\/rdcu.be\/bdG8Y\n- https:\/\/rdcu.be\/bdG9r\n\nThese predictions are based solely on the instantaneous physical characteristics of the acoustical signal and do not make use of its history.","3b6b6f7e":"I am a newbie and this is the code that was created by the user: inversion.\nWould love comments and if anything looks improperly explained, please let me know in the comments.\nthanks!"}}