{"cell_type":{"c4d4530f":"code","26365345":"code","9686d232":"code","adf7a02b":"code","4fa3d664":"code","b8244cc7":"code","01f636d6":"code","dd39f0fe":"code","0bce6e58":"code","56ff20cb":"code","c150b074":"code","93b78edd":"code","b6ef7cc6":"markdown","bee1c8a4":"markdown","a8ecd919":"markdown","0c946e06":"markdown","a69d60c0":"markdown","662310fc":"markdown","7527f901":"markdown","0744b121":"markdown","aad10537":"markdown"},"source":{"c4d4530f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26365345":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn import tree\nimport matplotlib.pyplot as plt","9686d232":"data = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv');\nprint(data.head())","adf7a02b":"CATEGORIES = {\n    'class': ['e', 'p'],\n    'cap-shape': ['x', 'b', 'c', 'k', 's', 'f'], \n    'cap-surface': ['f', 'g', 'y', 's'], \n    'cap-color': ['n', 'b', 'c', 'g','r', 'p', 'u', 'e', 'w', 'y'], \n    'bruises': ['t', 'f'], \n    'odor': ['a', 'l', 'c', 'y', 'f', 'm', 'n', 'p', 's'],\n    'gill-attachment': ['a', 'd', 'f', 'n'], \n    'gill-spacing': ['c', 'w', 'd'], \n    'gill-size': ['b', 'n'],\n    'gill-color': ['k', 'n', 'b', 'h', 'g', 'r', 'o', 'p', 'u', 'e', 'w', 'y'],\n    'stalk-shape': ['e', 't'], \n    'stalk-root': ['b', 'c', 'u', 'e', 'z', 'r', '?'], \n    'stalk-surface-above-ring': ['f', 'y', 'k', 's'],\n    'stalk-surface-below-ring': ['f', 'y', 'k', 's'],\n    'stalk-color-above-ring': ['b', 'n', 'c', 'g', 'o', 'p', 'e', 'w', 'y'],\n    'stalk-color-below-ring': ['b', 'n', 'c', 'g', 'o', 'p', 'e', 'w', 'y'],\n    'veil-type': ['p', 'u'], \n    'veil-color': ['n', 'o', 'w', 'y'], \n    'ring-number': ['o', 'n', 't'],\n    'ring-type': ['c', 'e', 'f', 'l', 'n', 'p', 's', 'z'], \n    'spore-print-color': ['k', 'n', 'b', 'h', 'r', 'o', 'u', 'w', 'y'], \n    'population': ['a', 'c', 'n', 's', 'v', 'y'], \n    'habitat': ['g', 'l', 'm', 'p', 'u', 'w', 'd']  \n}","4fa3d664":"    \ndf = data\nfor feature, vocab in CATEGORIES.items():\n    df[feature] = df[feature].apply(lambda x: vocab.index(x))\ndf.head()","b8244cc7":"X = df.iloc[:, 1:23].values\ny = df.iloc[:, 0].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=40)\nX_train.shape","01f636d6":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(22,)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(2),\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","dd39f0fe":"model.fit(X_train, y_train, epochs=20)","0bce6e58":"y_predict = model.predict(X_test).argmax(axis=-1)\nmetrics = precision_recall_fscore_support(y_test, y_predict, average='binary')\nprint('Precision :', metrics[0])\nprint('Recall :', metrics[1])\nprint('Medida F1 :', metrics[2])\nprint('Error cuadratico medio: ', mean_squared_error(y_test, y_predict))\n","56ff20cb":"# Create a random forest Classifier. By convention, clf means 'Classifier'\nclf = RandomForestClassifier(n_jobs=2, random_state=0, n_estimators=1)\nclf.fit(X_train, y_train)","c150b074":"indice_tree = 0 # Which tree we want to plot\nfig, axes = plt.subplots(figsize = (20,20), dpi=800)\ntree.plot_tree(clf.estimators_[indice_tree],\n               feature_names = list(CATEGORIES.keys()), \n               class_names=['edible', 'poisonous'],\n               filled = True,\n               rounded = True);","93b78edd":"y_forrest_predict = clf.predict(X_test)\nmetrics = precision_recall_fscore_support(y_test, y_forrest_predict, average='binary')\nprint('Precision :', metrics[0])\nprint('Recall :', metrics[1])\nprint('Medida F1 :', metrics[2])\nprint('Error cuadratico medio: ', mean_squared_error(y_test, y_forrest_predict))","b6ef7cc6":"# Random Forrest\nAhora utilizando la misma informaci\u00f3n usamos el clasificador random forrest, como comentario importante hay que destacar la simplicidad de este clasificador no solo para hacer el codigo sino tambien para elegir hyperparametros.\nTambi\u00e9n se eligi\u00f3 un unico arbol como estimador dada la simplicidad del problema (y veremos que no hacen falta m\u00e1s).","bee1c8a4":"# Input\nAbrimos el dataset con la informaci\u00f3n suministrada por kaggle","a8ecd919":"Ahora generamos las metricas con ayuda de sklearn dado que la libreria de Keras no tiene soporte nativo para el F1 score","0c946e06":"Separamos los datos por un lado en test y train y por el otro en datos y labels (X e y)","a69d60c0":"# Importamos \nLas librerias necesarias para hacer los modelos que utilizaremos luego, ademas de las m\u00e9tricas para evaluar los resultados.","662310fc":"# Red Neuronal\n\nCreamos el modelo que consistir\u00e1 de el input (convertido a numeros anteriormente), una gran capa densa de 128 neuronas y una capa de salida con dos neuronas que corresponderan a cada una de las clases que se puede asignar a los hongos.\n\nEsta red es la primera planteada y no fue necesaria cambiarla (como suele ser el caso) para que se ajuste mejor al dataset. Se utiliza relu como funci\u00f3n de activaci\u00f3n y 20 ciclos de entrenamiento (de los cuales en realidad solo eran necesarios 10 aproximadamente).","7527f901":"Primero definimos categorias para armar el input despu\u00e9s","0744b121":"Convertimos los datos de *string* a *enteros* segun los posibles valores que pueden tomar","aad10537":"# Conclusiones\n\nSe puede observar que las predicciones dieron 100% correctas al igual que el clasificador de la red neuronal. En general veriamos resultados mejores en este ultimo clasificador pero debido a la facilidad del dataset no fue el caso. Esta facilidad viene dada no solo en cuanto a la predictibilidad sino tambien la limpieza del dataset y su muy buena documentaci\u00f3n que tampoco suele ser el caso mas normal."}}