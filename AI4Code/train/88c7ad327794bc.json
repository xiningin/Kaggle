{"cell_type":{"a2e3937f":"code","2a76cd08":"code","ca162f97":"code","5b59aa28":"code","0f98d229":"code","411d0f26":"code","9aadd826":"code","da7a5255":"code","c1b36458":"code","e477079a":"code","da33fc19":"code","a4aebb5b":"code","195d1615":"code","f4adc8d3":"code","7a275787":"code","645b1bda":"code","03a292c5":"code","eebf3b5a":"code","0fc9d50c":"code","477b432d":"code","45d5b045":"code","fa26f1c2":"code","c3cda55f":"code","01519549":"code","1e59e265":"code","4bf5e848":"code","0d978ff1":"code","12733d14":"code","781b2703":"markdown","ac44e0bb":"markdown","d5433b0b":"markdown","c4416a31":"markdown","be3558a2":"markdown","07276ccb":"markdown","475ed455":"markdown","957dd16d":"markdown","b8b60c57":"markdown","de0eaeac":"markdown","b442a47f":"markdown","858bf19e":"markdown","d36ee3b0":"markdown","d717516d":"markdown","0ee07a97":"markdown","56199d14":"markdown","5e590331":"markdown","976669f3":"markdown","064a76dd":"markdown","cc5deba0":"markdown","e36e2796":"markdown"},"source":{"a2e3937f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt \n","2a76cd08":"url='..\/input\/company-bankruptcy-prediction\/'\n\ndf=pd.read_csv(url+'data.csv')\ndf.head()\nprint(df.columns)","ca162f97":"df.shape","5b59aa28":"label=df['Bankrupt?']\nprint(label)\nlabel.value_counts()\n","0f98d229":"data=df.drop(['Bankrupt?'],axis=1)\nprint(data)","411d0f26":"from sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score\nTransf_pca = PCA(n_components= 10)\ndatanew = Transf_pca.fit_transform(data)\nprint(datanew)\ndatanew.shape\n#datanew shape(6819,10)","9aadd826":"label=pd.DataFrame(label)\nlabel.shape\nnewbase=np.concatenate((datanew,label),axis=1)\nprint(newbase)\nnewbase.shape\nnewbase=pd.DataFrame(newbase)\nprint(newbase.columns)\n","da7a5255":"dataset_selected1=newbase.loc[newbase[10].isin([1])]\ndataset_selected0=newbase.loc[newbase[10].isin([0])]\n\n\n#on va diviser dataset_selected1 en 2 partie data1 et label1\nlabel1=dataset_selected1[10]\ndata1=dataset_selected1.drop([10],axis=1)\n\n#on va diviser dataset_selected0 en 2 partie data0 et label0\nlabel0=dataset_selected0[10]\n#remplacer 0 par -1\nlabel0=label0-1\ndata0=dataset_selected0.drop([10],axis=1)","c1b36458":"from sklearn.model_selection import train_test_split\nx_train1,x_test1,y_train1,y_test1=train_test_split(data1,label1,test_size=0.33,random_state=0)\nfrom sklearn import svm\nmodel=svm.OneClassSVM(kernel='rbf',nu=1,gamma=0.00001)\nimport time\ndebut=time.time()\nmodel.fit(x_train1)\nfin=time.time()-debut","e477079a":"import numpy as np\ndata_tesst=np.concatenate((x_test1,data0),axis=0)\nlabel_tesst=np.concatenate((y_test1,label0),axis=0)\npred=model.predict(data_tesst)\n","da33fc19":"from sklearn.metrics import accuracy_score\nACC=accuracy_score(label_tesst,pred)*100\nprint('the accurency score is :')\nprint(ACC)","a4aebb5b":"from sklearn.metrics import classification_report\nprint(classification_report(label_tesst,pred))\n","195d1615":"from sklearn.metrics import confusion_matrix\nCM=confusion_matrix(label_tesst,pred)\nprint(CM)\n#heatmap de confusion matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nclass_names=[0,1] # name of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\n# CM1=pd.DataFrame(CM)\n# print(CM1)\nsns.heatmap(pd.DataFrame(CM), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\n#plt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","f4adc8d3":"print(newbase)\nlabel=newbase[10]\ndata=newbase.drop([10],axis=1)\nlabel.value_counts()","7a275787":"from imblearn.over_sampling import RandomOverSampler\nimport imblearn\nprint(imblearn.__version__)\n\n# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy='minority')\n\n# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy=1.0)\n\n# fit and apply the transform\nX_over, y_over = oversample.fit_resample(data, label)\n#compter combien de 1 et de 0 dans dataset\nlabel=y_over\ndata=X_over\nlabel =pd.DataFrame(label)\nlabel.value_counts()","645b1bda":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\ndtree = DecisionTreeClassifier()\nx_train,x_test,y_train,y_test = train_test_split(data,label,test_size = 0.3,random_state = 0)\nimport time\ndebut=time.time()\ndtree.fit(x_train,y_train)\nfin=time.time()-debut\nprediction = dtree.predict(x_test)","03a292c5":"from sklearn.metrics import accuracy_score\nACC=accuracy_score(y_test,prediction)*100\nprint('With decision tree accuracy is: ',ACC) # accuracy","eebf3b5a":"from sklearn.metrics import classification_report\nClass=classification_report(y_test,prediction)\nprint(Class)","0fc9d50c":"from sklearn.metrics import confusion_matrix\nCM=confusion_matrix(y_test,prediction)\nprint(CM)\n\n#heatmap de confusion matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nclass_names=[0,1] # name of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\n# CM1=pd.DataFrame(CM)\n# print(CM1)\nsns.heatmap(pd.DataFrame(CM), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\n#plt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n","477b432d":"from sklearn.metrics import roc_curve,auc\nfp, tp, thresholds=roc_curve(y_test,prediction,pos_label=1)\nprint(fp, tp)\nAUC=auc(fp, tp)*100\nprint(AUC)\n\n#tracer tp en fonction de fp\nimport matplotlib.pyplot as plt\nplt.plot(fp, tp, color='blue',label = 'AUC = %0.2f' % AUC)\nplt.title('Receiver Operating Characteristic')\n#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % AUC)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n","45d5b045":"from sklearn.tree import plot_tree\n#affichage plus grand pour une meilleure lisibilit\u00e9\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplot_tree(dtree)\nplt.show()","fa26f1c2":"from sklearn.metrics import f1_score\nf1score=f1_score(y_test,prediction)*100\nprint('f1_score is: ',f1score) ","c3cda55f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nrf = RandomForestClassifier(criterion = 'gini')\nx_train,x_test,y_train,y_test = train_test_split(data,label,test_size = 0.3,random_state =1)\nimport time\ndebut=time.time()\nrf.fit(x_train,y_train)\nfin=time.time()-debut\n\nprediction = rf.predict(x_test)","01519549":"from sklearn.metrics import accuracy_score\nACC=accuracy_score(y_test,prediction)*100\nprint('With random forest accuracy is: ',ACC) # accuracy","1e59e265":"from sklearn.metrics import classification_report\nClass=classification_report(y_test,prediction)\nprint(Class)","4bf5e848":"from sklearn.metrics import confusion_matrix\nCM=confusion_matrix(y_test,prediction)\nprint(CM)\n\n#heatmap de confusion matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nclass_names=[0,1] # name of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\n# CM1=pd.DataFrame(CM)\n# print(CM1)\nsns.heatmap(pd.DataFrame(CM), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\n#plt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n","0d978ff1":"from sklearn.metrics import roc_curve,auc\nfp, tp, thresholds=roc_curve(y_test,prediction,pos_label=1)\nprint(fp, tp)\nAUC=auc(fp, tp)*100\nprint(AUC)\n\n#tracer tp en fonction de fp\nimport matplotlib.pyplot as plt\nplt.plot(fp, tp, color='blue',label = 'AUC = %0.2f' % AUC)\nplt.title('Receiver Operating Characteristic')\n#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % AUC)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n","12733d14":"from sklearn.metrics import f1_score\nf1score=f1_score(y_test,prediction)*100\nprint('f1_score is: ',f1score) ","781b2703":"# reduction des demension \non ne peut pas utiliser lda dans ce probl\u00e9me car ona une classification binaire donc 2 classe (impossible d'appliquer lda puisque nbre de features in lda reduction \u00e9gale a nbre de classe -1 et donc 2-1=1 )\ndans ce cas on va utiliser pca et on va initialiser nbre de components avec un valeur comprise entre 0 et min(6819, 96)","ac44e0bb":"# OverSampling\n\non peut transformer unbalanced data to balanced data ","d5433b0b":"# report de prediction","c4416a31":"# report","be3558a2":"# unbalanced data\non constate qu'on a une base de donn\u00e9es d\u00e9siquilibres classe faillite 220 non faillite 6599 ==> on va appliquer svm mono classe","07276ccb":"# Confusion matrix","475ed455":"# F1_score","957dd16d":"# Roc curve","b8b60c57":"# Confusion matrix","de0eaeac":"# Roc curve","b442a47f":"ona \u00e9quilibre dataset","858bf19e":"# Classification SVM monoclass","d36ee3b0":"# Accurency","d717516d":"# calculer accurency","0ee07a97":"# accurency","56199d14":"# Random Forest","5e590331":"diviser la base en 2 partie : partie qui inclus les data qui on target 1 et partie inclus target 0 ","976669f3":"# confusion matrix","064a76dd":"# Decision tree","cc5deba0":"# Report","e36e2796":"===> on constate que auc=98% donc l'algorithme est tr\u00e9s performant"}}