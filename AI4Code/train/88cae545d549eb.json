{"cell_type":{"493944ea":"code","fcf410b9":"code","02157cea":"code","3fdbcb74":"code","27bdf87e":"code","56c83a32":"code","87137129":"code","314288a0":"code","aaa4feb5":"code","eab5f914":"code","4781cf1a":"code","a3358407":"code","5da141f6":"code","cc28becf":"code","041b8402":"code","db46bd66":"code","d88dab07":"code","35c09b4a":"code","cc6d74a5":"code","9e43c4ec":"code","14425b81":"code","1387adb5":"code","aaf45c5e":"code","04f9f482":"code","92d0aff6":"code","d3140654":"code","47962929":"code","b190da2b":"code","8252654f":"code","be06fd02":"code","e51f95f4":"code","853b2c8c":"code","733593b9":"code","81a854ec":"code","180d9ed5":"code","57ecaf3e":"code","46a5b280":"code","07bfbc68":"markdown","1ab369ae":"markdown","f397422c":"markdown","66ff3b2c":"markdown","b47cead6":"markdown","c36a75e8":"markdown","a217ed11":"markdown","750a1794":"markdown","7763fe00":"markdown","f88059aa":"markdown","fe05ba20":"markdown","8aa0f3d2":"markdown","4a1251ad":"markdown","bd19034f":"markdown"},"source":{"493944ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fcf410b9":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","02157cea":"df_train.head()","3fdbcb74":"df_train.info()","27bdf87e":"#Checking the % of Null Values\n\nround(df_train.isna().sum() \/ len(df_train.index)*100,2)","56c83a32":"df_train['Age'].fillna((df_train['Age'].mean()), inplace=True)","87137129":"plt.figure(figsize = (10,7))\nsns.countplot(x='Pclass',hue = 'Survived',data=df_train)","314288a0":"plt.figure(figsize = (10,7))\nsns.countplot(x='Sex',hue = 'Survived',data=df_train)","aaa4feb5":"counts, bins = np.histogram(df_train['Age'])\nplt.hist(bins[:-1], bins, weights=counts,histtype = 'bar',color = 'magenta')","eab5f914":"#Cabin column has lot of null values and its not serving any purpose for our analysis to dropping it from the dataframe\ndf_train = df_train.drop('Cabin',axis=1)","4781cf1a":"df_train.dropna()","a3358407":"m_sex = pd.get_dummies(df_train['Sex'],drop_first=True)\nm_embarked = pd.get_dummies(df_train['Embarked'],drop_first=True)","5da141f6":"df_train = df_train.drop(['Name','Sex','Ticket','Embarked'] , axis=1)","cc28becf":"# Concatinate main dataframe and dummy columns\ndf_train = pd.concat([df_train,m_sex,m_embarked],axis=1)","041b8402":"from sklearn.model_selection import train_test_split","db46bd66":"# Putting feature variable to X\nX = df_train.drop(['Survived'], axis=1)\n\nX.head()","d88dab07":"# Putting response variable to y\ny = df_train['Survived']\n\ny.head()","35c09b4a":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","cc6d74a5":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_train[['Age','Fare']] = scaler.fit_transform(X_train[['Age','Fare']])\n\nX_train.head()","9e43c4ec":"from sklearn.linear_model import LogisticRegression\nlm = LogisticRegression()\nlm.fit(X_train,y_train)","14425b81":"pred = lm.predict(X_test)\nX_test.head()","1387adb5":"pred","aaf45c5e":"df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","04f9f482":"df_test.head()","92d0aff6":"df_test['Age'].fillna((df_test['Age'].mean()), inplace=True)","d3140654":"df_test = df_test.drop('Cabin',axis=1)","47962929":"df_test.dropna()","b190da2b":"m_sex_test = pd.get_dummies(df_test['Sex'],drop_first=True)\nm_embarked_test = pd.get_dummies(df_test['Embarked'],drop_first=True)","8252654f":"df_test = df_test.drop(['Name','Sex','Ticket','Embarked'] , axis=1)","be06fd02":"# Concatinate main dataframe and dummy columns\ndf_test = pd.concat([df_test,m_sex_test,m_embarked_test],axis=1)","e51f95f4":"df_test['Fare'].fillna((df_test['Fare'].mean()), inplace=True)","853b2c8c":"test_pred = lm.predict(df_test)","733593b9":"test_pred.shape","81a854ec":"df_test_predicted = pd.DataFrame(test_pred, columns= ['Survived'])","180d9ed5":"df_test_new = pd.concat([df_test,df_test_predicted],axis=1 , join = 'inner')","57ecaf3e":"df_final = df_test_new[['PassengerId','Survived']]","46a5b280":"df_final.to_csv('titanic_pred_final.csv' , index=False)","07bfbc68":"## Maximum people on the ship was beloinging to Age Group 20-30","1ab369ae":"## Impute the Age column with  mean value of Age","f397422c":"## Some Charts for EDA","66ff3b2c":"## Perform same opertions on test data as we performed on train data set","b47cead6":"## It is clear that the highest mortality is amongst the passengers belonging to Class 3","c36a75e8":"**Checking the Missing Values in Data Frame**","a217ed11":"## Data Preparation","750a1794":"## Feature Scaling to bring all columns to same scale","7763fe00":"** Inspecting the dataframe**","f88059aa":"## Creating Dummy columns for Sex  and Embarked Columns","fe05ba20":"## It is clear that Age is having around 20% Missing values and Cabin is having around 77%","8aa0f3d2":"## Make Prediction on Train Set","4a1251ad":"## Model Building","bd19034f":"## Import the Test Data Set"}}