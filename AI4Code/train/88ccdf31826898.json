{"cell_type":{"3264c65a":"code","04b828fc":"code","7ca61f2d":"code","d9d1cead":"code","1c64f406":"code","52033a60":"code","5c22a410":"code","52f4a5e4":"code","fa57b7c1":"code","18dcbd2d":"code","6ad660d8":"code","e6c65ec6":"code","9591c18d":"code","1d51a34c":"code","38f2334f":"code","4a947b1a":"markdown","0cae06c0":"markdown","e8648dfd":"markdown","b12e1491":"markdown","44e0fb22":"markdown","b02159c2":"markdown","44400d26":"markdown","96670b8e":"markdown","6153b95e":"markdown","159ed7e2":"markdown","eb13488d":"markdown"},"source":{"3264c65a":"!unzip ..\/input\/denoising-dirty-documents\/sampleSubmission.csv.zip\n!unzip ..\/input\/denoising-dirty-documents\/test.zip\n!unzip ..\/input\/denoising-dirty-documents\/train.zip\n!unzip ..\/input\/denoising-dirty-documents\/train_cleaned.zip","04b828fc":"%matplotlib inline\n\nimport os\nimport glob\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dropout\nfrom keras.layers import UpSampling2D\nfrom keras.layers import Reshape\n\nfrom sklearn.model_selection import train_test_split","7ca61f2d":"def im_show(im_name):\n    plt.figure(figsize=(20,8))\n    img = cv2.imread(im_name, 0)\n    plt.imshow(img, cmap=\"gray\")\n    print(f\"[INFO] Image shape: {img.shape} \")\nim_show(\"train\/77.png\")\nim_show(\"train_cleaned\/77.png\")","d9d1cead":"TRAIN_IMAGES = glob.glob('train\/*.png')\nCLEAN_IMAGES = glob.glob('train_cleaned\/*.png')\nTEST_IMAGES = glob.glob('test\/*.png')\nprint(f\"[INFO] Number of train pictures: {len(TRAIN_IMAGES)}\")\nprint(f\"[INFO] Number of train_cleaned pictures: {len(CLEAN_IMAGES)}\")\nprint(f\"[INFO] Number of test pictures: {len(TEST_IMAGES)}\")","1c64f406":"IMG_W = 258\nIMG_H = 540\nBS = 20\nEPOCHS = 200","52033a60":"def load_image(path):\n    image_list = np.zeros((len(path), IMG_W, IMG_H, 1))\n    for i, fig in enumerate(path):\n        img = image.load_img(fig, color_mode='grayscale', target_size=(IMG_W, IMG_H))\n        x = image.img_to_array(img).astype('float32')\n        x = x \/ 255.0\n        image_list[i] = x\n    \n    return image_list","5c22a410":"x_train = load_image(TRAIN_IMAGES)\ny_train = load_image(CLEAN_IMAGES)\nx_test = load_image(TEST_IMAGES)\n\nprint(f\"[INFO] x_train shape: {x_train.shape}\")\nprint(f\"[INFO] y_train shape: {y_train.shape}\")\nprint(f\"[INFO] x_test shape: {x_test.shape}\")","52f4a5e4":"x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, \n                                                  random_state=42)\nprint(f\"[INFO] train shape: {x_train.shape} and {y_train.shape}\")\nprint(f\"[INFO] validation shape: {x_val.shape} and {y_val.shape}\")","fa57b7c1":"def create_deep_conv_ae():\n    input_layer = Input(shape=(IMG_W, IMG_H, 1))\n\n    # encoder\n    h = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n    h = MaxPooling2D((2, 2), padding='same')(h)\n\n    # decoder\n    h = Conv2D(64, (3, 3), activation='relu', padding='same')(h)\n    h = UpSampling2D((2, 2))(h)\n    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(h)\n\n    return Model(input_layer, output_layer)\n\nautoencoder = create_deep_conv_ae()\nautoencoder.compile(optimizer='adam', loss='mse')\nautoencoder.summary()","18dcbd2d":"early_stopping = EarlyStopping(monitor='val_loss',\n                                       min_delta=0,\n                                       patience=5,\n                                       verbose=1, \n                                       mode='auto')","6ad660d8":"history = autoencoder.fit(x_train, y_train,\n                         batch_size=BS,\n                         epochs=EPOCHS,\n                         validation_data=(x_val, y_val),\n                         callbacks=[early_stopping]\n                        )","e6c65ec6":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","9591c18d":"preds = autoencoder.predict(x_test)","1d51a34c":"def plot_digits(*args):\n    args = [x.squeeze() for x in args]\n    n = min([x.shape[0] for x in args])\n    \n    plt.figure(figsize=(2*n, 2*len(args)))\n    for j in range(n):\n        for i in range(len(args)):\n            ax = plt.subplot(len(args), n, i*n + j + 1)\n            plt.imshow(args[i][j])\n            plt.gray()\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n\n    plt.show()\n\nplot_digits(x_test[:5], preds[:5])","38f2334f":"ids = []\nvals = []\nfor i, f in enumerate(TEST_IMAGES):\n    file = os.path.basename(f)\n    imgid = int(file[:-4])\n    test_img = cv2.imread(f, 0)\n    img_shape = test_img.shape\n    print('processing: {}'.format(imgid))\n    print(img_shape)\n    preds_reshaped = cv2.resize(preds[i], (img_shape[1], img_shape[0]))\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\nprint('Writing to csv file')\npd.DataFrame({'id': ids, 'value': vals}).to_csv('submission.csv', index=False)","4a947b1a":"Made list of name files (images)","0cae06c0":"Load images","e8648dfd":"### Define constants","b12e1491":"### Traing model","44e0fb22":"## Un zip files","b02159c2":"## See what we have","44400d26":"# Import necessary modules","96670b8e":"### Make predict and submission. \n\nThe function \"plot_digits\" lets you see the results of our predictions. You need to add test and prediction images to plot_digits","6153b95e":"Split dataset to train and validation data","159ed7e2":"### Some training result","eb13488d":"# Build model"}}