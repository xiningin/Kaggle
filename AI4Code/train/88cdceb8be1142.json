{"cell_type":{"07f8a835":"code","9651491c":"code","adea2b13":"code","c70963ee":"code","4055dacd":"code","e8485b47":"code","e799fc40":"code","846d39d9":"code","2365399f":"code","3851baec":"code","f9535173":"code","58226948":"code","27ce4415":"code","cab40554":"code","d88b691d":"code","48dd4c2e":"code","3bc2daba":"code","8c1f1fa6":"code","183a1928":"code","b15d167a":"code","4c49b0a0":"code","d6228bd4":"markdown","46d69b4c":"markdown"},"source":{"07f8a835":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","9651491c":"df=pd.read_csv('..\/input\/league-of-legends-diamond-ranked-games-10-min\/high_diamond_ranked_10min.csv')","adea2b13":"df.head()","c70963ee":"df.info()","4055dacd":"df=df.drop(['gameId', 'redFirstBlood', 'redKills', 'redEliteMonsters', 'redDragons','redTotalMinionsKilled',\n       'redTotalJungleMinionsKilled', 'redGoldDiff', 'redExperienceDiff', 'redCSPerMin', 'redGoldPerMin', 'redHeralds',\n       'blueGoldDiff', 'blueExperienceDiff', 'blueCSPerMin', 'blueGoldPerMin', 'blueTotalMinionsKilled'],axis=1)","e8485b47":"df","e799fc40":"plt.figure(figsize=(16, 12))\nsns.heatmap(df.drop('blueWins', axis=1).corr(),cmap=\"mako\", annot=True, fmt='.2f', vmin=0);","846d39d9":"df=df.drop(['blueAvgLevel', 'redWardsPlaced', 'redWardsDestroyed', 'redDeaths', 'redAssists', 'redTowersDestroyed',\n       'redTotalExperience', 'redTotalGold', 'redAvgLevel'],axis=1)","2365399f":"df","3851baec":"corr=df.corr()\nplt.figure(figsize=(16, 12))\nsns.heatmap(corr,cmap=\"mako\", annot=True, fmt='.2f', vmin=0)","f9535173":"corr_list = df[df.columns[1:]].apply(lambda x: x.corr(df['blueWins']))\ncols = []\nfor col in corr_list.index:\n    if (corr_list[col]>0.2 or corr_list[col]<-0.2):\n        cols.append(col)\ncols","58226948":"df_final=df[cols]","27ce4415":"X=df_final.values\ny=df['blueWins'].values","cab40554":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nscaler = MinMaxScaler()\nscaler.fit(X)\nX = scaler.transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","d88b691d":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(random_state=0)\nlr.fit(X_train,y_train)\nprint(lr.score(X_test,y_test))","48dd4c2e":"import keras\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras import *","3bc2daba":"X_train.shape","8c1f1fa6":"model=Sequential()\n\nmodel.add(Dense(64,activation='relu',input_shape=(8,)))\n# model.add(Dense(64,activation='relu'))\n# model.add(Dense(32,activation='relu'))\n# model.add(Dense(32,activation='relu'))\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')\nmodel.summary()","183a1928":"hist=model.fit(X_train,y_train,\n    batch_size=128,\n    epochs=300,\n    verbose=1,\n    validation_split=0.2,\n    shuffle=True\n)","b15d167a":"res=hist.history\n\nplt.plot(res['accuracy'],label=\"accuracy\")\nplt.plot(res['val_accuracy'],label=\"val acc\")\nplt.plot(res['loss'],label='loss')\nplt.plot(res['val_loss'],label='val loss')\nplt.legend()\nplt.show()","4c49b0a0":"model.evaluate(X_test,y_test)","d6228bd4":"## Neural Network","46d69b4c":"## Logistic Regression"}}