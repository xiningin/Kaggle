{"cell_type":{"db0e2619":"code","dee025e4":"code","72196dd6":"code","1d93e43f":"code","d7243630":"code","73733920":"code","1879ad6a":"code","6126bc95":"code","0e80ff6d":"code","207c784f":"code","9b76449b":"code","4ab40ccc":"code","07a33eea":"code","7f652d9d":"code","f1431d03":"code","1becf0bf":"code","38b460fc":"code","4ab61899":"code","936d7b55":"code","297856f7":"code","2bd14623":"markdown","a04fb4e0":"markdown","92c468b0":"markdown"},"source":{"db0e2619":"#!pip install -U tensorflow","dee025e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time, gc\nimport tensorflow as tf\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom glob import glob\nimport cv2\nprint(tf.__version__)\n\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nimport matplotlib\nmatplotlib.use('Agg')\n\n# import the necessary keras and sklearn packages\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nimport random\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","72196dd6":"train_df_ = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\n#test_df_ = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/test.csv')\nclass_map_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/class_map.csv')\n#sample_sub_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv')","1d93e43f":"print(train_df_.head())","d7243630":"len(train_df_)","73733920":"print(class_map_df.head())","1879ad6a":"print(class_map_df.component_type.value_counts())","6126bc95":"class_map_df_root = class_map_df[class_map_df.component_type=='grapheme_root']\nclass_map_df_vowel = class_map_df[class_map_df.component_type=='vowel_diacritic']\nclass_map_df_cons = class_map_df[class_map_df.component_type=='consonant_diacritic']","0e80ff6d":"graphemeLB = LabelBinarizer()\nvowelLB = LabelBinarizer()\nconsonantLB = LabelBinarizer()\n\ngraphemeLB.fit(class_map_df_root.label)\nvowelLB.fit(class_map_df_vowel.label)\nconsonantLB.fit(class_map_df_cons.label)","207c784f":"print(len(vowelLB.classes_))\nprint(len(consonantLB.classes_))\nprint(len(graphemeLB.classes_))","9b76449b":"def read_data(nf):\n    nf=int(nf)\n    train_df = pd.read_feather(f'\/kaggle\/input\/bengaliaicv19feather\/train_image_data_{nf}.feather')\n    return train_df\n","4ab40ccc":"EPOCHS = 2\nINIT_LR = 1e-3\nBS = 64","07a33eea":"def build_model():\n    inputs = tf.keras.layers.Input(shape = (96, 96, 1))\n\n    x0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(inputs)\n    x0 = tf.keras.layers.BatchNormalization(axis=-1)(x0)\n    x0 = tf.keras.layers.MaxPooling2D((2, 2))(x0)\n    print(x0.shape)\n    x0 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(x0)\n    x0 = tf.keras.layers.BatchNormalization(axis=-1)(x0)\n    x0 = tf.keras.layers.MaxPooling2D((2, 2))(x0)\n    print(x0.shape)\n    x0 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(x0)\n    x0 = tf.keras.layers.BatchNormalization(axis=-1)(x0)\n    x0 = tf.keras.layers.MaxPooling2D((2, 2))(x0)\n    print(x0.shape)\n    x0 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(x0)\n    x0 = tf.keras.layers.BatchNormalization(axis=-1)(x0)\n    x0 = tf.keras.layers.MaxPooling2D((2, 2))(x0)\n    print(x0.shape)\n    x0 = tf.keras.layers.Dropout(rate=0.5)(x0)\n    print(x0.shape)\n    x0 = tf.keras.layers.Flatten()(x0)\n    print(x0.shape)\n    x = tf.keras.layers.Dense(1024, activation = tf.nn.relu)(x0)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(512, activation = tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(256, activation = tf.nn.relu)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    head_root = tf.keras.layers.Dense(168, activation = tf.nn.softmax,name=\"grapheme_output\")(x)\n    \n    x1 = tf.keras.layers.Dense(1024, activation = tf.nn.relu)(x0)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Dense(512, activation = tf.nn.relu)(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Dense(256, activation = tf.nn.relu)(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Dense(128, activation = tf.nn.relu)(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Dense(64, activation = tf.nn.relu)(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Dense(32, activation = tf.nn.relu)(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Dropout(rate=0.5)(x1)\n    head_vowel = tf.keras.layers.Dense(11, activation = tf.nn.softmax,name=\"vowel_output\")(x1)\n    \n    x2 = tf.keras.layers.Dense(1024, activation = tf.nn.relu)(x0)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Dense(512, activation = tf.nn.relu)(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Dense(256, activation = tf.nn.relu)(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Dense(128, activation = tf.nn.relu)(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Dense(64, activation = tf.nn.relu)(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Dense(32, activation = tf.nn.relu)(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Dropout(rate=0.5)(x2)\n    head_consonant = tf.keras.layers.Dense(7, activation = tf.nn.softmax,name=\"consonant_output\")(x2)\n\n    model = tf.keras.models.Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n    return model","7f652d9d":"model = build_model()\ntf.keras.utils.plot_model(model, to_file='model.png')\n# define two dictionaries: one that specifies the loss method for\n# each output of the network along with a second dictionary that\n# specifies the weight per loss\nlosses = {\n    \"grapheme_output\": \"categorical_crossentropy\",\n    \"vowel_output\": \"categorical_crossentropy\",\n    \"consonant_output\": \"categorical_crossentropy\"\n}\nlossWeights = {\"grapheme_output\": 1.0, \"vowel_output\": 1.0, \"consonant_output\":1.0}\n\n# initialize the optimizer and compile the model\nprint(\"[INFO] compiling model...\")\nopt = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,metrics=[\"accuracy\"])","f1431d03":"class MultiOutputDataGenerator(tf.keras.preprocessing.image.ImageDataGenerator):\n\n    def flow(self,\n             x,\n             y=None,\n             batch_size=32,\n             shuffle=True,\n             sample_weight=None,\n             seed=None,\n             save_to_dir=None,\n             save_prefix='',\n             save_format='png',\n             subset=None):\n\n        targets = None\n        target_lengths = {}\n        ordered_outputs = []\n        for output, target in y.items():\n            if targets is None:\n                targets = target\n            else:\n                targets = np.concatenate((targets, target), axis=1)\n            target_lengths[output] = target.shape[1]\n            ordered_outputs.append(output)\n\n\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n                                         shuffle=shuffle):\n            target_dict = {}\n            i = 0\n            for output in ordered_outputs:\n                target_length = target_lengths[output]\n                target_dict[output] = flowy[:, i: i + target_length]\n                i += target_length\n\n            yield flowx, target_dict","1becf0bf":"datagen = MultiOutputDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)","38b460fc":"IMG_SIZE = 96\nN_CHANNELS = 1\n\nhistories = []\n\nfor i in range(2):\n    graphemeLabels = []\n    vowelLabels = []\n    consonantLabels = []\n    X_train = pd.merge(read_data(i), train_df_, on='image_id').drop(['image_id','grapheme'], axis=1)[0:1000]\n    X_train=X_train.astype('uint8')\n    graphemeLabels = X_train.grapheme_root\n    vowelLabels = X_train.vowel_diacritic\n    consonantLabels = X_train.consonant_diacritic\n    X_train=X_train.drop([\"consonant_diacritic\",\"grapheme_root\",\"vowel_diacritic\"],axis=1)\n\n    # binarize all three sets of labels\n    print(\"[INFO] binarizing labels...\")\n    graphemeLabels = graphemeLB.transform(np.array(graphemeLabels))\n    vowelLabels = vowelLB.transform(np.array(vowelLabels))\n    consonantLabels = consonantLB.transform(np.array(consonantLabels))\n\n    print(graphemeLabels.shape)\n    print(vowelLabels.shape)\n    print(consonantLabels.shape)\n\n    print(\"[INFO] resizing train dataset...\")\n    X_train=np.array(X_train).reshape(-1,137,236,1)\n    print(X_train.shape)\n    resized_image=[]\n    for i in range(len(X_train)):\n        resized_img = tf.image.resize(X_train[i],[96,96])\n        resized_img=np.array(resized_img)\/255.\n        resized_image.append(resized_img)\n    resized_image = np.asarray(resized_image)\n\n    del X_train\n    gc.collect()\n\n    print(\"[INFO] Shape of resized image..\")  \n    print(resized_image.shape)\n\n    print(\"[INFO] Datagen on resized images...\") \n    datagen.fit(resized_image)\n   \n    print(\"[INFO] Model.fit starting...\")\n    history=model.fit_generator(datagen.flow(resized_image,{'grapheme_output': graphemeLabels, 'vowel_output': vowelLabels, 'consonant_output': consonantLabels},batch_size=BS),\n                   steps_per_epoch=len(resized_image) \/ BS, epochs=EPOCHS)\n    \n    del graphemeLabels\n    del vowelLabels\n    del consonantLabels\n    del resized_image\n    gc.collect()\n    histories.append(history)","4ab61899":"#print(\"[INFO] Now saving Model\")\n#model.save('Bengali_model_AugDS.h5')","936d7b55":"def plot_loss(his, epoch, title):\n    plt.style.use('ggplot')\n    fig=plt.figure()\n    \n    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\n    plt.plot(np.arange(0, epoch), his.history['grapheme_output_loss'], label='train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['vowel_output_loss'], label='train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['consonant_output_loss'], label='train_consonant_loss')\n    \n    #plt.plot(np.arange(0, epoch), his.history['val_grapheme_output_loss'], label='val_root_loss')\n    #plt.plot(np.arange(0, epoch), his.history['val_vowel_output_loss'], label='val_vowel_loss')\n    #plt.plot(np.arange(0, epoch), his.history['val_consonant_output_loss'], label='val_consonant_loss')\n    \n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.show()\n    fig.savefig('plot_loss.png')\n\n\ndef plot_acc(his, epoch, title):\n    plt.style.use('ggplot')\n    fig=plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['grapheme_output_accuracy'], label='train_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['vowel_output_accuracy'], label='train_vowel_accuracy')\n    plt.plot(np.arange(0, epoch), his.history['consonant_output_accuracy'], label='train_consonant_accuracy')\n    \n    #plt.plot(np.arange(0, epoch), his.history['val_grapheme_output_accuracy'], label='val_root_acc')\n    #plt.plot(np.arange(0, epoch), his.history['val_vowel_output_accuracy'], label='val_vowel_accuracy')\n    #plt.plot(np.arange(0, epoch), his.history['val_consonant_output_accuracy'], label='val_consonant_accuracy')\n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='upper right')\n    plt.show()\n    fig.savefig('plot_acc.png')","297856f7":"for dataset in range(2):\n    plot_loss(histories[dataset], EPOCHS, f'Training Dataset: {dataset}')\n    plot_acc(histories[dataset], EPOCHS, f'Training Dataset: {dataset}')","2bd14623":"## Simple model with multiple Outputs branching out from the Dense layers","a04fb4e0":"## Exploratory Data Analysis","92c468b0":"## Read image data from feather format, use ImageDataGenerator instance to create TF Dataset using from_generator, and do model.fit in a loop for the 4 sets of images"}}