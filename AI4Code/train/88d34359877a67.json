{"cell_type":{"781e7baa":"code","7d1e5ae6":"code","3c0a11fd":"code","fe38b41a":"code","63f8a87b":"code","09ae754b":"code","cfb43da7":"code","17e4ad97":"markdown","19e4ef66":"markdown","1be9ba17":"markdown"},"source":{"781e7baa":"import os\n\nfrom sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.pipeline import Pipeline","7d1e5ae6":"js_path = \"..\/input\/obfuscated-javascript-dataset\/JavascriptSamplesNotObfuscated\/JavascriptSamples\"\nobfuscated_js_path = \"..\/input\/obfuscated-javascript-dataset\/JavascriptSamplesObfuscated\/JavascriptSamplesObfuscated\"","3c0a11fd":"corpus = []\nlabels = []\nfile_types_and_labels = [(js_path,0), (obfuscated_js_path, 1)]","fe38b41a":"for files_path, label in file_types_and_labels:\n    files = os.listdir(files_path)\n    for file in files:\n    \n        file_path = files_path + \"\/\" + file\n        try:\n            with open(file_path, \"r\") as myfile:\n                data = myfile.read().replace(\"\\n\", \"\")\n                data = str(data)\n                corpus.append(data)\n                labels.append(label)\n        except Exception as e:\n            print(e)","63f8a87b":"len(corpus), len(labels)","09ae754b":"X_train, X_test, y_train, y_test = train_test_split(\n    corpus, labels, test_size=0.33, random_state=42\n)\n\ntext_clf = Pipeline(\n    [\n        (\"vect\", HashingVectorizer(input=\"content\",ngram_range=(1,3))),\n        (\"tfidf\", TfidfTransformer(use_idf=True,)),\n        (\"rf\", RandomForestClassifier(class_weight=\"balanced\")),\n    ]\n)\n","cfb43da7":"text_clf.fit(X_train, y_train)\ny_test_pred = text_clf.predict(X_test)\n\nprint(accuracy_score(y_test, y_test_pred))\nprint(confusion_matrix(y_test, y_test_pred))","17e4ad97":"We begin by importing standard Python libraries to analyze the files and set up machine\nlearning pipelines (Step 1). In Steps 2 and 3, we collect the non-obfuscated and obfuscated\nJavaScript files into arrays and assign them their respective labels. ","19e4ef66":"Having collected the data, we separate it into training and testing subsets (Step\n4). In addition, we set up a pipeline to apply NLP methods to the JavaScript code itself, and\nthen train a classifier\n\nFinally, we measure the performance of our classifier","1be9ba17":"Note that the main challenge in producing this classifier\nis producing a large and useful dataset. Ideas for solving this hurdle include collecting a\nlarge number of JavaScript samples and then using different tools to obfuscate these."}}