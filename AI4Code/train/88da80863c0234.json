{"cell_type":{"5a369f35":"code","8299ae0b":"code","ae91c0f8":"code","e8fc724d":"code","b1ab34dd":"code","9d5b5b0e":"code","bb3910f2":"code","fa99cbee":"code","ee256f07":"code","2c9c5101":"code","c87cdc8c":"code","92c48f48":"code","06938ce1":"code","e4bcf6da":"code","531082b4":"code","98ddcb11":"code","1487e77a":"code","e470b260":"code","9f914af9":"code","fa88fad3":"code","44a2273c":"code","2947eaf1":"code","948e8b10":"code","a5e97b49":"code","bdd40a35":"code","3b05f903":"code","3899b306":"code","eb25da4e":"code","bfc5b53a":"code","d6231e0e":"code","cd13a350":"code","b8b15181":"code","1ed9e194":"code","cf857855":"code","0035151e":"code","ec5265d3":"code","dc74c7dd":"code","fa1b54ca":"code","5fbfa58c":"code","13f781b4":"code","0f969536":"code","3f8b8be1":"code","2f30b821":"code","fb658d21":"code","73c4f8f2":"markdown","f34f7968":"markdown","12844c85":"markdown","4c511c3d":"markdown","8cd9c28e":"markdown","56db52ce":"markdown","804e31cc":"markdown","0a88fcd3":"markdown","0f14b5dc":"markdown","95f3bf39":"markdown","9f300ef7":"markdown"},"source":{"5a369f35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8299ae0b":"data = pd.read_csv('..\/input\/spotify-dataset-19212020-160k-tracks\/data.csv')\ndata_by_artist = pd.read_csv('..\/input\/spotify-dataset-19212020-160k-tracks\/data_by_artist.csv')\ndata_by_genres = pd.read_csv('..\/input\/spotify-dataset-19212020-160k-tracks\/data_by_genres.csv')\ndata_by_year   = pd.read_csv('..\/input\/spotify-dataset-19212020-160k-tracks\/data_by_year.csv')\ndata_w_genres  = pd.read_csv('..\/input\/spotify-dataset-19212020-160k-tracks\/data_w_genres.csv')","ae91c0f8":"data.head(2)","e8fc724d":"data.info()","b1ab34dd":"def split_columns(data):\n    categorical_col = data.select_dtypes(include=['object','category']).columns.tolist()\n    numerical_col = data.select_dtypes(include=['int64','float64']).columns.tolist()\n    return categorical_col,numerical_col\n    \n    ","9d5b5b0e":"categorical_col,numerical_col = split_columns(data)\ncategorical_col","bb3910f2":"\nnumerical_col","fa99cbee":"print(len(numerical_col))","ee256f07":"\nimport matplotlib.pyplot as plt\nfig, axes = plt.subplots(4, 4, figsize=(18, 16))\n\nfig.suptitle('Numerical columns histogram')\n\ni=0;\nj=0;\n\nfor key in numerical_col:\n    sns.histplot(data=data[key],ax=axes[i,j])\n    if(j<3):\n        j=j+1\n    elif(j==3):\n        j=0;\n        i=i+1\n    \n    \n","2c9c5101":"df2= data[numerical_col]\nfrom sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(df2)\ndf2 = pd.DataFrame(x_scaled,columns=numerical_col)\ndf2\nfig_dims = (5, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\n\nsns.heatmap(df2.corr(),ax=ax)","c87cdc8c":"# Correlation with popularity\n\n\ny_corr = df2.corr()\n(y_corr['popularity']).sort_values(ascending=False)\n","92c48f48":"data_by_artist.info()","06938ce1":"data_by_artist.head()","e4bcf6da":"categorical,numerical = split_columns(data_by_artist)\ncategorical","531082b4":"numerical","98ddcb11":"\ndf = data_by_year\ncat,num = split_columns(df)\n","1487e77a":"len(num)","e470b260":"import matplotlib.pyplot as plt\nfig, axes = plt.subplots(5,3, figsize=(18, 16))\n\nfig.suptitle('Numerical columns histogram')\n\ni=0;\nj=0;\n\nfor key in num:\n    if not key=='year':\n        sns.barplot(x=data['year'],y=data[key],ax=axes[i,j])\n        if(j<2):\n            j=j+1\n        elif(j==2):\n            j=0;\n            i=i+1\n    ","9f914af9":"data_by_genres.info()","fa88fad3":"data_by_genres['genres'].nunique()","44a2273c":"df = data_by_genres.sort_values(by=['popularity' \n                                   ],ascending=False)\ndf[['genres','popularity']].head(10)","2947eaf1":"df2 = data[numerical_col]\ndf2.head(10)","948e8b10":"data_by_year.head()\n","a5e97b49":"df = data_by_year[data_by_year['year']>2000]","bdd40a35":"df3 = data.sort_values(by=['popularity'],ascending=False)\ndf3[['name','year','artists']].head(10)","3b05f903":"df4 = data_by_artist.sort_values(by=['count'],ascending=False)\ndf4[['artists','count']].head(10)","3899b306":"df5 = df4[df4['count']>100]\ndf5 = df5.sort_values(by=['popularity','count'],ascending=False)\ndf5[['artists','popularity']].head(50)","eb25da4e":"df5.tail(5)","bfc5b53a":"genres = np.array(data_by_genres['genres'].unique())\ngenres","d6231e0e":"for genre in genres:\n    if \"tamil\" in genre:\n        print(genre)\n        ","cd13a350":"data_by_genres.info()","b8b15181":"#most popular song in the 00s\ndata_2000s = data[data['year']>(1999)]\ndata_2000s = data_2000s[data_2000s['year']<(2010)]\ndata_pop =data_2000s.sort_values(by=['popularity'],ascending=False)\ndata_pop[['artists','name','year']].head(50)","1ed9e194":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\n\nY = df2['popularity']\nX = df2.drop(columns=['popularity','mode','tempo','key'])\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","cf857855":"dcr = DecisionTreeRegressor()\nrf = RandomForestRegressor(max_depth=10)\ngb = GradientBoostingRegressor()\ndcr.fit(X_train,y_train)\nrf.fit(X_train,y_train)\ngb.fit(X_train,y_train)\n\n","0035151e":"dcr.score(X_test,y_test),rf.score(X_test,y_test),gb.score(X_test,y_test)","ec5265d3":"y_pred = rf.predict(X_test)\nmse = mean_squared_error(y_pred,y_test)\n","dc74c7dd":"fig_dims = (10, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\n\nx=[]\nfor i in range(len(y_test)):\n    x.append(i); \nplt.plot(x,y_test,'o')\nplt.plot(x,y_pred,'x')\nplt.legend(['Ground truth','Prediction'])","fa1b54ca":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler\nfeatures =['acousticness','danceability','energy','instrumentalness','liveness','speechiness','valence','popularity']\nX = data_by_genres[features]\nscaler = StandardScaler().fit(X)\nX = scaler.transform(X)\nX = pd.DataFrame(X,columns= features)\n\nsse = []\nmax_cluster = 50+1\nfor k in range(1, max_cluster):\n    kmeans = KMeans(n_clusters=k)\n    kmeans.fit(X)\n    sse.append(kmeans.inertia_)\nfig_dims = (15, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\nplt.style.use(\"fivethirtyeight\")\nplt.plot(range(1, max_cluster), sse)\nplt.xticks(range(1, max_cluster))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"SSE\")\nplt.show()","5fbfa58c":"\ndf = data_by_artist\ndf = df[df['count']>50 ]\n\ndf=df[df['popularity']>25]\narray = df['artists'].unique()\ndf","13f781b4":"dfcopy = df\ndf= df.drop(columns=['artists','key','mode','count','duration_ms','popularity'])\ncolumns = df.columns\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler().fit(df)\ndf = scaler.transform(df)\ndf = pd.DataFrame(df,columns=columns)\n","0f969536":"from sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(df,df)","3f8b8be1":"indices = pd.Series(df.index, index=dfcopy['artists']).drop_duplicates()","2f30b821":"def recommender(title,indices=indices,cosine_sim=cosine_sim,df=dfcopy):\n    artistID = indices[title]; # Get the artist id\n    # next, find the cosine similarity\n    artistsim = cosine_sim[artistID]\n    artistscores = list(enumerate(artistsim))\n    artistscores = sorted(artistscores,key=lambda x:x[1], reverse =True)\n    artistscores = artistscores[1:20]\n    similarartistindex = [i[0] for i in artistscores]\n    # with the index, now return the name of artist\n    \n     \n    return df['artists'].iloc[similarartistindex];","fb658d21":"recommender('Akon')","73c4f8f2":"# Least Popular Songs","f34f7968":"We have 5 different csv's, different information can be visualized from each.","12844c85":"# Artists with most content on spotify!","4c511c3d":"#  4. A simple recommendation system that suggest other artists given an artists ( a popular artist with more than 50 songs)\n","8cd9c28e":"# 3. Building a Popularity Prediction Model ( Regression)","56db52ce":"# Experimenting with Clusering of Genres using KMeans \n **Lets cluster the genres based on  accousticness, danceability, energy,loudness, tempo, popularity**","804e31cc":"# **Top 10 popular Songs**","0a88fcd3":"## Top 10 popular Genres ","0f14b5dc":"# 0. Loading the Data","95f3bf39":"# Top 50 **ARTISTS With 100+ songs**\n","9f300ef7":"# 1. EDA : Objectives\n\n    1. Study the variation in songs in terms of  \n            -  Year,Energy, Genres, tempo,etc.\n       Most popular and Most played\n            - Song, Artist, Genres\n     \n    2. How various variables affect the popularity of a song! (Trying to predict what is the recepie for a popular song)\n    3. Build a recommendation system  that suggests 5 close songs based on a given song or a genre ( This could be a classification problem!)\n  "}}