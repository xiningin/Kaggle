{"cell_type":{"553ea579":"code","1ac97229":"code","61ed2a2e":"code","b546ed32":"code","cf19b4e7":"code","59ee780a":"code","91de5318":"code","b1a99d55":"code","2a70ae4e":"code","4daaa206":"code","1dec9304":"code","3ee215fe":"markdown","1bd4291e":"markdown","bfb1ccca":"markdown","ad793235":"markdown","56c19837":"markdown","4e93ad88":"markdown","065b7948":"markdown"},"source":{"553ea579":"# \ub370\uc774\ud130 \ubd84\uc11d \ub77c\uc774\ube0c\ub7ec\ub9ac\nimport numpy as np\nimport pandas as pd\n\n# \uc2dc\uac01\ud654 \ub77c\uc774\ube0c\ub7ec\ub9ac\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# \ubaa8\ub378\ub9c1 \ub77c\uc774\ube0c\ub7ec\ub9ac\nfrom category_encoders.ordinal import OrdinalEncoder\nimport torch\n\n# \uae30\ud0c0 \ub77c\uc774\ube0c\ub7ec\ub9ac\nimport random\nimport os\nimport warnings\nwarnings.filterwarnings(action='ignore')","1ac97229":"import os\n\n# \ub370\uc774\ud130 \uacbd\ub85c \uc124\uc815\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","61ed2a2e":"# csv \ud30c\uc77c \ub85c\ub4dc\ntrain = pd.read_csv('\/kaggle\/input\/kakr-4th-competition\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/kakr-4th-competition\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/kakr-4th-competition\/sample_submission.csv')","b546ed32":"target = (train['income'] != '<=50K').astype(int)\ntrain.drop(['income'], axis=1, inplace=True)","cf19b4e7":"train.head()","59ee780a":"#model = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet18', pretrained=True)\n\n# model = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet34', pretrained=True)\n# model = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet50', pretrained=True)\n# model = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet101', pretrained=True)\n# model = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet152', pretrained=True)\n\n# model.eval()","91de5318":"from google.colab import drive\ndrivemount('\/content\/gdrive')","b1a99d55":"from torch import nn, optim\nfrom torch.utils.data import(Dataset, DataLoader, TensorDataset)\nimport tqdm\n\n# DataLoader \uc791\uc131\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\n\n# ImageFolder \ud568\uc218\ub97c \uc0ac\uc6a9\ud574\uc11c Dataset \uc791\uc131\ntrain_imgs = ImageFolder(\"\/content\/gdrive\/My Drive\/taco_and_burrito\/train\/\",\n                         transform=transforms.Compose([transforms.RandomCrop(224), transforms.ToTensor()]))\ntest_imgs = ImageFolder(\"\/content\/gdrive\/My Drive\/taco_and_burrito\/test\/\",\n                         transform=transforms.Compose([transforms.RandomCrop(224), transforms.ToTensor\n                                                       \n# DataLoader \uc791\uc131\ntrain_loader = DataLoader(train_imgs, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_imgs, batch_size=32, shuffle=False)","2a70ae4e":"# \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30\nfrom torchvision import models\n\n# \uc0ac\uc804 \ud559\uc2b5\uc774 \uc644\ub8cc\ub41c ResNet18 \ubd88\ub7ec\uc624\uae30\nnet = models.resnet18(pretrained=True)\n\n# \ubaa8\ub4e0 \ud30c\ub77c\ubbf8\ud130\ub97c \ubbf8\ubd84 \ub300\uc0c1\uc5d0\uc11c \uc81c\uc678\ud55c\ub2e4.\nfor p in net.parameters():\n    p.requires_grad = False\n\n# \ub9c8\uc9c0\ub9c9 \uc120\ud615 \uacc4\uce35\uc744 \ubcc0\uacbd\ud55c\ub2e4.\nfc_input_dim = net.fc.in_features\nnet.fc = nn.Linear(fc_input_dim, 2)","4daaa206":"# eval_net \ub9cc\ub4e4\uae30\ndef eval_net(net, data_loader, device=\"cpu\"):\n  # Dropout \ubc0f BatchNorm\uc744 \ubb34\ud6a8\ud654\n  net.eval()\n  ys = []\n  ypreds = []\n\n  for x, y in data_loader:\n    # to \uba54\uc11c\ub4dc\ub85c \uacc4\uc0b0\uc744 \uc2e4\ud589\ud560 \ub514\ubc14\uc774\uc2a4 \uc804\uc1a1\n    x = x.to(device)\n    y = y.to(device)\n    # \ud655\ub960\uc774 \uac00\uc7a5 \ud070 \ubd84\ub958\ub97c \uc608\uce21\n    # \uc5ec\uae30\uc120 forward(\ucd94\ub860) \uacc4\uc0b0\uc774 \uc804\ubd80\uc774\ubbc0\ub85c \uc790\ub3d9 \ubbf8\ubd84\uc5d0 \ud544\uc694\ud55c \ucc98\ub9ac\ub294 off\ub85c \uc124\uc815\ud574\uc11c \ubd88\ud544\uc694\ud55c \uacc4\uc0b0\uc744 \uc81c\ud55c\ub2e4.\n\n    with torch.no_grad():\n      _, y_pred = net(x).max(1)\n\n    ys.append(y)\n    ypreds.append(y_pred)\n\n  # \ubbf8\ub2c8 \ubc30\uce58 \ub2e8\uc704\uc758 \uc608\uce21 \uacb0\uacfc \ub4f1\uc744 \ud558\ub098\ub85c \ubb36\ub294\ub2e4\n  ys = torch.cat(ys)\n  ypreds = torch.cat(ypreds)\n\n  # \uc608\uce21 \uc815\ud655\ub3c4 \uacc4\uc0b0\n  acc = (ys == ypreds).float().sum() \/ len(ys)\n  return acc.item()","1dec9304":"# train_net \ub9cc\ub4e4\uae30\ndef train_net(net, train_loader, test_loader, only_fc=True,\n              optimizer_cls=optim.Adam,\n              loss_fn=nn.CrossEntropyLoss(),\n              n_iter=10, device=\"cpu\"):\n\n  train_losses = []\n  train_acc = []\n  val_acc = []\n\n  if only_fc:\n    # \ub9c8\uc9c0\ub9c9 \uc120\ud615 \uacc4\uce35\uc758 \ud30c\ub77c\ubbf8\ud130\ub9cc optimizer\uc5d0 \uc804\ub2ec\n    optimizer = optimizer_cls(net.fc.parameters())\n\n  else: optimizer = optimizer_cls(net.parameters())\n\n  for epoch in range(n_iter):\n    running_loss = 0.0\n    # \uc2e0\uacbd\ub9dd\uc744 \ud6c8\ub828 \ubaa8\ub4dc\ub85c \uc124\uc815\n    net.train()\n    n = 0\n    n_acc = 0\n    \n    # \uc2dc\uac04\uc774 \ub9ce\uc774 \uac78\ub9ac\ubbc0\ub85c tqdm\uc744 \uc0ac\uc6a9\ud574\uc11c \uc9c4\ud589 \ubc14\ub97c \ud45c\uc2dc\n    for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader), total=len(train_loader)):\n      xx = xx.to(device)\n      yy = yy.to(device)\n      h = net(xx)\n      loss = loss_fn(h, yy)\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n      running_loss += loss.item()\n      n += len(xx)\n      _, y_pred = h.max(1)\n      n_acc += (yy == y_pred).float().sum().item()\n\n    train_losses.append(running_loss\/i)\n\n    # \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uc608\uce21 \uc815\ud655\ub3c4\n    train_acc.append(n_acc \/ n)\n\n    # \uac80\uc99d \ub370\uc774\ud130\uc758 \uc608\uce21 \uc815\ud655\ub3c4\n    val_acc.append(eval_net(net, test_loader, device))\n\n    # epoch\uc758 \uacb0\uacfc \ud45c\uc2dc\n    print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)","3ee215fe":"# Modeling - unknown with Pytorch","1bd4291e":"# \ub77c\uc774\ube0c\ub7ec\ub9ac \ud638\ucd9c \ubc0f I\/O\n   \n    # numpy(Numerical Python)\n    C\uc5b8\uc5b4\ub85c \uad6c\ud604\ub41c Python \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c\uc368, \uace0\uc131\ub2a5\uc758 \uc218\uce58\uacc4\uc0b0\uc744 \uc704\ud574 \uc81c\uc791\ub410\ub2e4.\n    \ubca1\ud130, \ud589\ub82c \uc5f0\uc0b0\uc5d0 \uc788\uc5b4\uc11c \ub9e4\uc6b0 \ud3b8\ub9ac\ud55c \uae30\ub2a5\uc744 \uc81c\uacf5\ud55c\ub2e4.(\uae30\ubcf8\uc801\uc73c\ub85c array \ub2e8\uc704\ub85c \ub370\uc774\ud130 \uad00\ub9ac)\n    \n    # pandas\n    Python\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ub370\uc774\ud130\ubd84\uc11d \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c, \ud589\uacfc \uc5f4\ub85c \uc774\ub8e8\uc5b4\uc9c4 \ub370\uc774\ud130 \uac1d\uccb4\ub97c \ub9cc\ub4e4\uc5b4 \ub2e4\ub8f0 \uc218 \uc788\uac8c \ub418\uba70 \ubcf4\ub2e4 \uc548\uc815\uc801\uc73c\ub85c \ub300\uc6a9\ub7c9\uc758 \ub370\uc774\ud130\ub97c\uc744 \ucc98\ub9ac\ud558\ub294\ub370 \ub9e4\uc6b0 \ud3b8\ub9ac\ud55c \ub3c4\uad6c\uc774\ub2e4.\n    \n    # matplotlib\n    \ub2e4\uc591\ud55c \ub370\uc774\ud130\ub97c \ub9ce\uc740 \ubc29\ubc95\uc73c\ub85c \ub3c4\uc2dd\ud654 \ud560 \uc218 \uc788\ub3c4\ub85d \ud558\ub294 \ud30c\uc774\uc36c \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c\uc368, \ubcf8 \ub178\ud2b8\ubd81\uc5d0\uc11c\ub294 matplotlib\uc758 pyplot\ub97c \uc774\uc6a9\ud55c\ub2e4.(numpy \uc640 pandas\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \uc790\ub8cc\uad6c\uc870\ub97c \uc27d\uac8c \uc2dc\uac01\ud654 \ud560 \uc218 \uc788\ub2e4.)\n    \n    # pytorch\n    Python \uae30\ubc18\uc758 \uacfc\ud559 \uc5f0\uc0b0 \ud328\ud0a4\uc9c0\ub85c, \ub2e4\uc74c\uacfc \uac19\uc740 \ub450 \uc9d1\ub2e8\uc744 \ub300\uc0c1\uc73c\ub85c \ud55c\ub2e4.\n    * numpy\ub97c \ub300\uccb4\ud558\uba74\uc11c GPU\ub97c \uc774\uc6a9\ud55c \uc5f0\uc0b0\uc774 \ud544\uc694\ud55c \uacbd\uc6b0\n    * \ucd5c\ub300\ud55c\uc758 \uc720\uc5f0\uc131\uacfc \uc18d\ub3c4\ub97c \uc81c\uacf5\ud558\ub294 \ub525\ub7ec\ub2dd \uc5f0\uad6c \ud50c\ub7ab\ud3fc\uc774 \ud544\uc694\ud55c \uacbd\uc6b0\n    \n    # category_encoders\n    categorical \ubcc0\uc218\ub97c \ub2e4\uc591\ud55c \uae30\uc220\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc22b\uc790\ub85c \uc778\ucf54\ub529\ud558\uae30 \uc704\ud55c, scikit-learn \uc2a4\ud0c0\uc77c \ubcc0\ud658\uae30 set\uc774\ub2e4.\n    one-hot \ubc0f hashing \uc778\ucf54\ub354\ub294 \uae30\uc874 scikit-learn \ubc84\uc804\uacfc \uc720\uc0ac\ud55c \uae30\ub2a5\uc744 \uac00\uc9c0\uace0 \uc788\uc9c0\ub9cc, category_encoders \ub77c\uc774\ube0c\ub7ec\ub9ac\uc758 \ubcc0\ud658\uae30\ub294 \uba87 \uac00\uc9c0\uc758 \uc720\uc6a9\ud55c \uc18d\uc131\uc744 \uacf5\uc720\ud55c\ub2e4.\n    \n    * First-class support for pandas dataframes as an input (and optionally as output)\n    * Can explicitly configure which columns in the data are encoded by name or index, or infer non-numeric columns regardless of input type\n    * Can drop any columns with very low variance based on training set optionally\n    * Portability: train a transformer on data, pickle it, reuse it later and get the same thing out.\n    * Full compatibility with sklearn pipelines, input an array-like dataset like any other transformer\n       \n* numpy \ucc38\uace0 - https:\/\/www.flearning.net\/courses\/6\n* pandas \ucc38\uace0 - https:\/\/doorbw.tistory.com\/172\n* matplotlib \ucc38\uace0 - https:\/\/doorbw.tistory.com\/173\n* matplotlib \ucc38\uace02 - https:\/\/harryp.tistory.com\/870\n* pytorch \ucc38\uace0 - https:\/\/tutorials.pytorch.kr\/beginner\/blitz\/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n* category_encoders \ucc38\uace0 - https:\/\/contrib.scikit-learn.org\/category_encoders\/","bfb1ccca":"# [T-Academy X KaKr] BaseLine with PyTorch\n**Wonkwang University Dept. of Computer Software** Student **Jin-Woo Shin**","ad793235":"# \ucc38\uace0\n* [Basic EDA & LGBM Modeling](https:\/\/www.kaggle.com\/werooring\/basic-eda-lgbm-modeling-public-score-0-87714#%EB%AA%A8%EB%8D%B8%EB%A7%81-(Modeling))\n* [[KaKr]16 Lines Baseline \uc124\uba85 \ucd94\uac00 ver](https:\/\/www.kaggle.com\/subinium\/kakr-16-lines-baseline-ver)\n* [Pytorch \uba38\uc2e0\ub7ec\ub2dd \ud29c\ud1a0\ub9ac\uc5bc \uac15\uc758 1~8](https:\/\/wingnim.tistory.com\/entry\/Pytorch-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC-%EA%B0%95%EC%9D%98-0-Overview)\n* [\uce90\uae00\uacfc \uad6c\uae00 Colab \uc5f0\uacb0\ud574\uc8fc\uae30!](https:\/\/medium.com\/hyunjulie\/%EC%BA%90%EA%B8%80%EA%B3%BC-%EA%B5%AC%EA%B8%80-colab-%EC%97%B0%EA%B2%B0%ED%95%B4%EC%A3%BC%EA%B8%B0-6a274f6de81d)\n* [\ud30c\uc774\ud1a0\uce58 - \uc804\uc774 \ud559\uc2b5](https:\/\/truman.tistory.com\/227)","56c19837":"# \ubaa8\ub378\uc5d0 \uc801\ud569\ud55c Input \ud615\ud0dc\n* features(X)\uc640 target(y)\uc73c\ub85c \ub098\ub204\uc5b4 \ubaa8\ub378\uc5d0 Input\n* \uc6b0\ub9ac\uac00 \uc608\uce21\ud574\uc57c\ud558\ub294 income feature\ub97c \ub530\ub85c \ube80\ub2e4.","4e93ad88":"# \ud83d\udea7WORK UNDER PROGRESS\ud83d\udea7","065b7948":"### \uad6c\uae00 \ucf54\ub7a9 \uc5f0\uacb0 \uc218\uc815\uc911 \/ \ubaa8\ub378 \uc801\uc6a9 \ud559\uc2b5 \ubc0f \uc218\uc815\n* [\uce90\uae00\uacfc \uad6c\uae00 Colab \uc5f0\uacb0\ud574\uc8fc\uae30!](https:\/\/medium.com\/hyunjulie\/%EC%BA%90%EA%B8%80%EA%B3%BC-%EA%B5%AC%EA%B8%80-colab-%EC%97%B0%EA%B2%B0%ED%95%B4%EC%A3%BC%EA%B8%B0-6a274f6de81d)\n* [\ud30c\uc774\ud1a0\uce58 - \uc804\uc774 \ud559\uc2b5](https:\/\/truman.tistory.com\/227)"}}