{"cell_type":{"3fa3389a":"code","574022ce":"code","53d1d221":"code","bc2906b0":"code","7104f177":"code","19359711":"code","14e4fc9b":"code","be756ec8":"code","bddb3f4c":"markdown","260dc7e7":"markdown","082a799e":"markdown","c3b66269":"markdown","a74f9e06":"markdown","76ac89b2":"markdown","4b1d2198":"markdown","d047e883":"markdown","36bd1a9a":"markdown","66269c68":"markdown"},"source":{"3fa3389a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\nfrom fastai.tabular.all import *\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","574022ce":"TARGETS = ['Lake_Level', 'Flow_Rate']\n\nlake_data = pd.read_csv('..\/input\/acea-water-prediction\/Lake_Bilancino.csv')\nadd_datepart(lake_data, 'Date', drop = False)\nlake_data['Elapsed'] = lake_data['Elapsed'].astype('int64')\n\nFEATURES = list(set(lake_data.columns.tolist() + ['Month','Week','Day','Dayofyear']) - set(TARGETS)) ","53d1d221":"splits = IndexSplitter(lake_data.index[-370:])(range_of(lake_data))\n\ndls = TabularPandas(lake_data, procs=[Categorify, FillMissing,Normalize],\n                   cont_names = list(set(FEATURES)-set(['Date'])),\n                   y_names=TARGETS[0],\n                   splits=splits).dataloaders(bs=128)\n\nlearn = tabular_learner(dls, layers=[24,8,24], metrics=[rmse, mae], y_range=[242, 254])#, loss_func = F.l1_loss)\n\nlearn.fit_one_cycle(10, 1e-2)","bc2906b0":"plt.plot(learn.get_preds(ds_idx=1)[0].numpy())\nplt.plot(lake_data[TARGETS[0]].values[-370:])","7104f177":"TARGETS = ['Lake_Level', 'Flow_Rate']\n\nlake_data = pd.read_csv('..\/input\/acea-water-prediction\/Lake_Bilancino.csv')\n\nFEATURES = list(set(lake_data.columns) - set(TARGETS + ['Date']))\n\nroll720 = lake_data.copy()[FEATURES].rolling(20).mean()\nroll720.columns = [c + 'roll720' for c in FEATURES]\n\nroll360 = lake_data.copy()[FEATURES].rolling(360, win_type='triang').mean()\nroll360.columns = [c + 'roll360' for c in FEATURES]\n\nlake_data = pd.concat([roll720, roll360, lake_data], axis = 1).dropna().reset_index(drop = True)\n\nFEATURES_WO_DATE = lake_data.columns.tolist()\n\nadd_datepart(lake_data, 'Date', drop = False)\nlake_data['Elapsed'] = lake_data['Elapsed'].astype('int64')\n\n\nFEATURES = list(set(FEATURES_WO_DATE + ['Month','Week','Day','Dayofyear']) - set(TARGETS)) #\n\nlake_data.head()","19359711":"corr_lake = lake_data[FEATURES + TARGETS].corr()\n\nfig, ax = plt.subplots(figsize=(15,12)) \nsn.heatmap(corr_lake, annot=True, ax = ax)\nplt.show()","14e4fc9b":"splits = IndexSplitter(lake_data.index[-370:])(range_of(lake_data))\n\ndls = TabularPandas(lake_data, procs=[Categorify, FillMissing,Normalize],\n                   cont_names = list(set(FEATURES)-set(['Date'])),\n                   y_names=TARGETS[0],\n                   splits=splits).dataloaders(bs=128)\n\nlearn = tabular_learner(dls, layers=[24,8,24], metrics=[rmse, mae], y_range=[242, 254])#, loss_func = F.l1_loss)\n\nlearn.fit_one_cycle(10, 1e-2)","be756ec8":"plt.plot(learn.get_preds(ds_idx=1)[0].numpy())\nplt.plot(lake_data[TARGETS[0]].values[-370:])","bddb3f4c":"1. There is a slight improvement. ","260dc7e7":"Predict Lake_Level with a plain tabular neural net.\n\nTake the last 370 entries of the time series as validation set.","082a799e":"# About\n\nLet's try rolling average as feature to enhance lake level prediction.","c3b66269":"# Generate rolling features","a74f9e06":"Plot predictions of validation set vs. ground truth.","76ac89b2":"Plot predictions of validation set vs. ground truth.","4b1d2198":"Predict Lake_Level with a plain tabular neural net.\n\nOnce again, take the last 370 entries of the time series as validation set.","d047e883":"# Baseline\nBuild a baseline with the original features.","36bd1a9a":"Comparing rolling features with original features in correlation matrix.","66269c68":"=> roll360 features have a correlation between 0.4 and 0.5. That's not very strong but far higher than the original features (approx +\/-0.3)."}}