{"cell_type":{"a6fac1f8":"code","8a9d4d58":"code","96d65b54":"code","5e99055a":"code","a2cdc800":"code","1f018058":"code","40f44a03":"code","d6094f49":"code","b2109583":"code","d153145a":"code","ca592f7a":"code","6f5372c6":"code","5ede4d65":"code","77fdfa3e":"code","d46c893d":"code","be24b0f5":"code","6220e134":"code","a825df1d":"code","bee39d7b":"code","1475ab5c":"markdown","81669e14":"markdown","9f5c0341":"markdown","19e96f66":"markdown","a81cbab2":"markdown","7a63da69":"markdown","c36777df":"markdown","a46e818d":"markdown","0fe4d1a8":"markdown","f905e9bb":"markdown","aabfde11":"markdown","4a917307":"markdown","8f217496":"markdown","999be293":"markdown","407fe3c5":"markdown","323d5dfa":"markdown"},"source":{"a6fac1f8":"import keras\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \nfrom keras.models import Sequential \nfrom keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Flatten, Dense\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport os\nimport tensorflow as tf\nimport cv2\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport glob","8a9d4d58":"!pip install split-folders","96d65b54":"import splitfolders\n\ninput_dir = \"..\/input\/the-simpsons-characters-dataset\/simpsons_dataset\"\noutput_dir = \".\/data\"\n\nsplitfolders.ratio(input_dir, output=output_dir,seed=1337, ratio=(.9, 0.1))","5e99055a":"train_dir = \".\/data\/train\"\nval_dir = \".\/data\/val\"\ntest_dir = \".\/data\/test\"\n\nimage_size = (64, 64, 3)\n# number of epochs to train top model \nepochs = 50 #this has been changed after multiple model run \n# batch size used by flow_from_directory and predict_generator \nbatch_size = 100\n\nlabels = os.listdir(train_dir)","a2cdc800":"image_name = train_dir +\"\/lisa_simpson\/pic_0001.jpg\" #Image to be used as query\ndef plotLisa(image_location):\n    image = cv2.imread(image_name)\n    image = cv2.resize(image, (512,512))\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    return\nplotLisa(image_name)","1f018058":"train_datagen = ImageDataGenerator( rescale = 1.\/255,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    rotation_range=40,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2\n                                    )\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","40f44a03":"training_set =  train_datagen.flow_from_directory(\n                                                    train_dir,\n                                                    target_size=image_size[:2],\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    color_mode='rgb'\n\n)\n\nval_set =  test_datagen.flow_from_directory(\n                                                    val_dir,\n                                                    target_size=image_size[:2],\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    color_mode='rgb'\n\n)","d6094f49":"for data_batch, labels_batch in training_set:\n    print(data_batch.shape)\n    break","b2109583":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=image_size, activation=\"relu\"))\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(256, (3, 3), padding='same', activation=\"relu\")) \nmodel.add(Conv2D(256, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(labels), activation='softmax'))","d153145a":"model.summary()","ca592f7a":"model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])","6f5372c6":"checkpoint_filepath = \".\/model.h5\"\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=False,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)\n\ncallbacks = [\n             EarlyStopping(patience=5, monitor=\"val_accuracy\", mode=\"max\"),\n             model_checkpoint_callback,\n]","5ede4d65":"history = model.fit_generator(  training_set,\n                                epochs=epochs,\n                                validation_data=val_set,\n                                callbacks = callbacks\n)","77fdfa3e":"import matplotlib.pyplot as plt\n\nacc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, \"bo\", label=\"Tranning_acc\")\nplt.plot(epochs, val_acc, \"b\", label=\"validation_acc\")\nplt.legend()","d46c893d":"saved_model = keras.models.load_model('.\/model.h5')","be24b0f5":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np","6220e134":"img_path = \"..\/input\/the-simpsons-characters-dataset\/kaggle_simpson_testset\/kaggle_simpson_testset\/nelson_muntz_24.jpg\"\nimg = image.load_img(img_path, target_size=(64, 64, 3))\nplt.imshow(img)\nplt.show()","a825df1d":"def predict(img):\n    img_array = image.img_to_array(img)\n    img_batch = np.expand_dims(img_array, axis=0)\n    prediction = saved_model.predict(img_batch)\n    prediction = labels[np.argmax(prediction)]\n    return prediction","bee39d7b":"predict(img)","1475ab5c":"# Prediction","81669e14":"# Introduction\n\n## Introducing Convolutional Neural Networks (CNN)\n![](https:\/\/miro.medium.com\/max\/700\/0*78--J5vGoBls_Hbc.jpeg)<br>\n**CNN is a type of neural network model which allows us to extract higher representations for the image content. Unlike the classical image recognition where you define the image features yourself, CNN takes the image\u2019s raw pixel data, trains the model, then extracts the features automatically for better classification.**\n\nSource: [towardsdatascience](https:\/\/towardsdatascience.com\/understanding-cnn-convolutional-neural-network-69fd626ee7d4)","9f5c0341":"# Data Preparation\n## Spliting the data into 80:10:10(train:val:test)ratio using splitfolders module","19e96f66":"## Using Callbacks\n\nthe `fit()` method accepts a callbacks argument that lets you specify a list of objects that keras will call at the start and end of trainning, at the start and end of epochs.<br>\n\nfor example:\nthe `ModelCheckpoint` callbacks saves checkpoints of your model at regular intervals during trainning, by default at the end of epochs.\n","a81cbab2":"## Showing a random image","7a63da69":"# Predicting the Test Image","c36777df":" #### *Note:* we will not do data argmentaion to the valifdation data set as per my understanding it is not a good practice .","a46e818d":"## Visualizing the trend","0fe4d1a8":"### I will upload one more notebook by using pretrainned model and transfer learning to get more than 95%.<br>\n### I will also convert it into a  web app so that every one can use to contibute to my web app please follow this [Github Link](https:\/\/github.com\/everydaycodings\/Simpsons-Character-Image-Recognition)","f905e9bb":"## Trainning the model\nI am using `fit_generator()` to train my model you can also use `fit()` both are the same thing.","aabfde11":"# Viewing the test Image","4a917307":"# Data Argmentation\n### Creating more artificial data so that our model can learn fetures in a better way.","8f217496":"## Definning all the necessory values","999be293":"### By this simple steps we got a validation accuracy of more than 90% ","407fe3c5":"## Loading the best Saved model","323d5dfa":"# Model Creation\n### This is a very basic convent with 5 layers excluding output layer."}}