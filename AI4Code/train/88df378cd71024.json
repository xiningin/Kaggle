{"cell_type":{"b449dc8c":"code","2200cd60":"code","0407074b":"code","39ce951b":"code","317be883":"code","277e884c":"code","736a283b":"code","4078d32f":"code","7daaa8d3":"code","9af3ea61":"code","9230eb8b":"code","682dddb6":"code","3110bc3d":"code","a4e19080":"code","66936e29":"code","cb7f1ca9":"code","ac397682":"code","35978df7":"code","da0637d0":"code","12c60c5b":"code","ecc284e2":"code","4d3ef486":"code","46ac2ca1":"code","089f1a7a":"code","d8682718":"code","fb1b6159":"code","cd14d132":"code","1172fc57":"code","cf73473a":"code","076dce90":"code","1711e227":"markdown","3af3cd5b":"markdown","92b12d84":"markdown","15bbfb44":"markdown","5b12782b":"markdown","777cf40a":"markdown","7376bb77":"markdown","92db5a1e":"markdown","2cc02526":"markdown","3b6d9606":"markdown","d60e5806":"markdown","22543728":"markdown","5b4acc6c":"markdown","249d7517":"markdown","ce4538f0":"markdown","550082bd":"markdown","fb9e97f6":"markdown","eb88e4c5":"markdown","5ef51f24":"markdown"},"source":{"b449dc8c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\nimport sys\nimport datetime\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom textwrap import wrap\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2200cd60":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nhistory = pd.read_csv(\"..\/input\/historical_transactions.csv\",parse_dates=['purchase_date'])\nnew =pd.read_csv(\"..\/input\/new_merchant_transactions.csv\",parse_dates=['purchase_date'])\nhistory = history.loc[history.authorized_flag ==\"Y\",]","0407074b":"print(history.purchase_date.min(),history.purchase_date.max())\nprint(new.purchase_date.min(),new.purchase_date.max())","39ce951b":"print(new.purchase_date[new.month_lag==1].min(),new.purchase_date[new.month_lag==1].max())\nprint(new.purchase_date[new.month_lag==2].min(),new.purchase_date[new.month_lag==2].max())","317be883":"print(history.loc[history.month_lag==0,'purchase_date'].min())\nprint(history.loc[history.month_lag==0,'purchase_date'].max())","277e884c":"cardreferencedate = history.loc[history.month_lag==0,].groupby('card_id').agg({'purchase_date' : 'max'})\ncardreferencedate.reset_index(inplace=True)\ncardreferencedate['reference_date'] = cardreferencedate.purchase_date.apply(lambda x :x+ pd.offsets.MonthBegin())\ncardreferencedate['reference_date']=cardreferencedate['reference_date'].apply(lambda x: x.replace(hour=0, minute=0, second=0))\ncardreferencedate.head()","736a283b":"cardreferencedate.loc[:,'reference_date'].value_counts().sort_index().plot(kind='bar')","4078d32f":"new.loc[new.card_id.isin(cardreferencedate.card_id[cardreferencedate.reference_date=='2017-03-01 00:00:00']),]","7daaa8d3":"print(new.loc[new.card_id.isin(cardreferencedate.card_id[cardreferencedate.reference_date=='2017-03-01 00:00:00']),'purchase_date'].min())\nprint(new.loc[new.card_id.isin(cardreferencedate.card_id[cardreferencedate.reference_date=='2017-03-01 00:00:00']),'purchase_date'].max())","9af3ea61":"print(\"Number of cards with reference date\", len(cardreferencedate.index))\nprint(\"Number of cards in train\",len(train.index))\nprint(\"Number of cards in test\",len(test.index))\nprint(\"Number of unique cards in history\",len(history.card_id.unique()))","9230eb8b":"Nozeromonthlag = history.loc[~history.card_id.isin(cardreferencedate.card_id),'card_id'].unique()\nlen(Nozeromonthlag)","682dddb6":"history.loc[history.card_id=='C_ID_21117571cf','month_lag'].value_counts()","3110bc3d":"history.loc[history.card_id=='C_ID_21117571cf',]","a4e19080":"new.loc[new.card_id=='C_ID_21117571cf',]","66936e29":"Nozeromonthlagrefdate = history.loc[~history.card_id.isin(cardreferencedate.card_id),].groupby('card_id').agg({'month_lag' : 'max','purchase_date':'max'})\nNozeromonthlagrefdate.reset_index(inplace=True)\nNozeromonthlagrefdate['month_add'] = Nozeromonthlagrefdate.month_lag.apply(lambda x : abs(x))\nNozeromonthlagrefdate['reference_date'] = Nozeromonthlagrefdate.apply(lambda x: x['purchase_date'] + pd.DateOffset(months = x['month_add']), axis=1)\nNozeromonthlagrefdate['reference_date'] = Nozeromonthlagrefdate.reference_date.apply(lambda x :x+ pd.offsets.MonthBegin())\nNozeromonthlagrefdate['reference_date'] = Nozeromonthlagrefdate['reference_date'].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n","cb7f1ca9":"sum(Nozeromonthlagrefdate.card_id.isin(new.card_id))","ac397682":"Nozeromonthlagrefdate.loc[~Nozeromonthlagrefdate.card_id.isin(new.card_id),'reference_date'].value_counts().plot(kind='bar')","35978df7":"Nozeromonthlag_nonewtransaction_card_id =Nozeromonthlagrefdate.card_id[~Nozeromonthlagrefdate.card_id.isin(new.card_id)]","da0637d0":"Nozeromonthlag_nonewtransaction_card_agg=  history.loc[history.card_id.isin(Nozeromonthlag_nonewtransaction_card_id),].groupby(['card_id']).agg({'card_id': 'count','month_lag': ['min','max'],'purchase_date': ['min','max'] })","12c60c5b":"Nozeromonthlag_nonewtransaction_card_agg.head(50)","ecc284e2":"print(train.target.mean())\nprint(train.target[train.card_id.isin(Nozeromonthlag_nonewtransaction_card_id)].mean())","4d3ef486":"sns.boxplot(y=train.target[train.card_id.isin(Nozeromonthlag_nonewtransaction_card_id)])","46ac2ca1":"zeromonthlagmissinginnew= cardreferencedate.card_id[~cardreferencedate.card_id.isin(new.card_id)]\nlen(zeromonthlagmissinginnew)","089f1a7a":"cardreferencedate.drop(columns='purchase_date',inplace=True)\ncardreferencedate['category_month_lag'] =np.where(cardreferencedate.card_id.isin(zeromonthlagmissinginnew),1,0)\nNozeromonthlagrefdate['category_month_lag']= np.where(Nozeromonthlagrefdate.card_id.isin(Nozeromonthlag_nonewtransaction_card_id),3,2)\nNozeromonthlagrefdate.drop(columns=['month_lag','purchase_date','month_add'],inplace=True)\ncardreferencedate= pd.concat([cardreferencedate,Nozeromonthlagrefdate])\ncardreferencedate.to_csv(\"Cardreferencedate.csv\",index=False)\nlen(cardreferencedate.index)","d8682718":"cardreferencedate = pd.merge(cardreferencedate,train.loc[:,['card_id','target']],on='card_id',how='left')","fb1b6159":"cardreferencedate.head()","cd14d132":"sns.set(rc={'figure.figsize':(24,12)})\np1= sns.boxplot(x=cardreferencedate.reference_date,y=cardreferencedate.target)\nlabels = [item.get_text() for item in p1.get_xticklabels()]\nlabels =[ '\\n'.join(wrap(l, 10)) for l in labels ]\np1= p1.set_xticklabels(labels, rotation=90)","1172fc57":"sns.set(rc={'figure.figsize':(24,12)})\np1= sns.boxplot(x=cardreferencedate.category_month_lag,y=cardreferencedate.target)\n# labels = [item.get_text() for item in p1.get_xticklabels()]\n# labels =[ '\\n'.join(wrap(l, 10)) for l in labels ]\n# p1= p1.set_xticklabels(labels, rotation=90)","cf73473a":"sns.set(rc={'figure.figsize':(24,6)})  \nplt.subplot(1,2,1)\np1=cardreferencedate.loc[cardreferencedate.card_id.isin(train.card_id),'reference_date'].value_counts().sort_index().plot(kind='bar')\np1.set_title(\"Credit cardsreference date - Train\")\nplt.subplot(1,2,2)\np2=cardreferencedate.loc[cardreferencedate.card_id.isin(test.card_id),'reference_date'].value_counts().sort_index().plot(kind='bar')\np2.set_title(\"Credit cardsreference date - Test\")","076dce90":"testmissingnew = test.card_id[~test.card_id.isin(new.card_id)]\nlen(testmissingnew)","1711e227":"As explained the historical_transactions.csv and new_merchant_transactions.csv files contain information about each card's transactions. historical_transactions.csv contains up to 3 months' worth of transactions for every card at any of the provided merchant_ids. new_merchant_transactions.csv contains the transactions at new merchants (merchant_ids that this particular card_id has not yet visited) over a period of two months.\n","3af3cd5b":"Code below creates a  a data frame ' Nozeromonthlagrefdate' for those card_id's without any  0 values for Month_lag  based on the closest month_lag value to 0.","92b12d84":"The boxplot of target for card_id's based on the newly created category shows some difference in the mean values. But is this significant enough?\n\n***Multiple reference dates throws many questions about the dataset*.**\n\n* Does those card id's with an earlier reference date  have no transactions with their historical merchants subsequently ? or are they not included. Most of them have  transactions with new merchant id  for upto two months as is evident from the new merchant data.\n* Is the reference date just  a cut off  date to segregate historical transactions and new merchant transactions for every card id.\n* Will including the reference_date and new category  as a feature improve the RMSE ?\n\nPlease  share your thoughts on this.","15bbfb44":"**It's surprising that these cards have different reference date even though they don't have any new merchant transactions. This merits further probing as this goes against the assumption that  reference date is the cut off date for seggregating  historical and new transactions. .**","5b12782b":"About 32,368 cards are missing from the cardreferncedate we created (325,540 unique cards in history - 293,172).\n\nThis implies that these cards don't have any transaction records with month lag==0 .  These card ids's are stored in the array 'Nozeromonthlag'","777cf40a":"For those card id's with reference date 01- March-2017 the new merchant transactions happen in March & April 2017. It looks like the refernce date is a cut offf date for seggregating historical and new transactions.\nLet's confirm these by further exploratory analysis","7376bb77":"Month lag is defined in Data Dictionary .xls as the month lag to reference date. From the above results of the earliest purchase dates for month lag of 1 & 2 for new transactions  it looks like there are multiple reference dates.\nAs per the definition of month lag month lag of 0 would mean the last month of transactions in  historical transaction data for each card_id.\nLet's look at the earliest and the latest purchase dates for month lag of 0 in historical transactions.","92db5a1e":"The data frames are combined to form a data frame with reference_date value for each card_id in the historical transaction. We will also categorize the cards into four categories.\n* 0- Cards with Reference date based on **Month lag==0**  in historical transactions(cards in the cardsreferencedate dataframe) and having new merchant transactions \n* 1-  Cards with Reference date based on **Month lag==0**  in historical transactions(cards in the cardsreferencedate dataframe) and  **not** having new merchant transactions .\n* 2-  Cards with Reference date based on **Non zero month lag** in historical transactions(cards in the cardsreferencedate dataframe) and having new merchant transactions.\n* 3-  Cards with Reference date based on **Non zero month lag** in historical transactions(cards in the cardsreferencedate dataframe) and **not** having  new merchant transactions.","2cc02526":"From the above result it is clear that seggragation of transactions into new and historical starts from March 2017 .","3b6d9606":"This finding is confirmed by checking the transactions of card_id 'C_ID_21117571cf'.\nThere are no records for monthlag==0","d60e5806":"Let's examine the balance 5,789 cards reference dates ","22543728":"**This confrms that the refernce month could vary from February 2017 to February 2018**. \n \nLet's create a dataframe which captures the last purchase date for the month lag ==0 . Column ' refernce_ date' is the first date of the next month based on the month of the last purchase date for the month lag ==0","5b4acc6c":"About 70% of the card id's have March 1st 2018 as the reference date . Let's probe new transactions for those card id's having a refernce date of  March 1st 2017.","249d7517":"Let's check whether all card id's with non zero month lag appear in new merchant transaction. As shown below only 26,849 out of 32,638 appear in new list.","ce4538f0":"In many of the discussions and kernels for this competition the reference date was mentioned as end Feb 2018 or 1st March 2018.\nThis was based on the fact the the last transaction date in historical transactions is 28th feb 2018. \nIt's also assumed by many that the customer loyalty score is calculated as on this date. \n**This  is not true . There are multiple reference dates  as explained below ** .\n","550082bd":"Box plot shows there are no outliers  for cards with 1st March 2017 and 1st April 2017 reference dates. For other refernce dates  there is no major difference.\n","fb9e97f6":"The historical transactions for card_id=='C_ID_21117571cf' is below. Last transaction for this acrd is in Dec 2017 and the month lag is -2 which implies the reference date is Mar 01 ,2018","eb88e4c5":"From the above results it's not clear why the reference date for these cards are not 1st day of the month succeding their last transaction month . Since they don't have any new merchant transactions  further probing is not possible. But the mean customerloyalty scores of these cards is 0.53 which is significantly higher than -0.39 for  the target mean.","5ef51f24":"The new merchant transactions for the card is below. The transactions appear 2 month after the  refernce date. Hence we can assume that this card had no transactions during Jan & Feb 2018 , but had some new merchant transactions in April 2018. \n\n**This confirms our assumption that refernce date is a  cut off date for seggregating  historical and new transactions for a specific card.**\n"}}