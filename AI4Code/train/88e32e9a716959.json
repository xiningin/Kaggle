{"cell_type":{"09ea4dde":"code","19219555":"code","81db2a4f":"code","2a2ebfb1":"code","ca9ede1a":"code","baaca07b":"code","6f93767d":"code","085d7577":"code","5edb8ee0":"code","e1974358":"code","3f0def33":"code","3cefd8f1":"code","a8db3e02":"code","f8cc7648":"code","3595f0c7":"code","ffb51f15":"markdown","1925fe4f":"markdown","7a545a41":"markdown","e33eeea8":"markdown","53614ddc":"markdown","2abd1b83":"markdown","fe8ca447":"markdown"},"source":{"09ea4dde":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport json\n\nimport cv2\nimport glob\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.models import load_model\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize","19219555":"def mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 0;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 255:\n                    runStart = currentPixel;\n                    runLength = 1;\n                else:\n                    rle.append(str(runStart));\n                    rle.append(str(runLength));\n                    runStart = -1;\n                    runLength = 0;\n                    currentPixel = 0;\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor;\n            currentPixel+=1;\n\n    return \" \".join(rle)","81db2a4f":"def dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef iou_coef(y_true, y_pred, smooth=1):\n  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n  iou = K.mean((intersection + smooth) \/ (union + smooth), axis=0)\n  return iou\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\nclass FixedDropout(keras.layers.Dropout):\n    def _get_noise_shape(self, inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis] if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n        return tuple(noise_shape)\ndef dice_coef_rounded(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) \/ (K.sum(y_true_f) + K.sum(y_pred_f))\n    return score\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","2a2ebfb1":"custom_objects = custom_objects={\n    #'swish': tf.nn.swish,\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'iou_coef': iou_coef,\n    'bce_dice_loss': bce_dice_loss\n    #'GroupNormalization': GroupNormalization,\n    #'AccumOptimizer': Adam, # Placeholder, does not matter since we are not modifying the model\n    #'dice_coef_rounded': dice_coef_rounded\n    \n}\nunet = load_model('..\/input\/sartorius-segmentation-unet\/model.h5', custom_objects=custom_objects)\n\n#unet.summary()","ca9ede1a":"def build_rles(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","baaca07b":"sub_df = pd.read_csv('..\/input\/sartorius-cell-instance-segmentation\/sample_submission.csv')\nsub_df.head()","6f93767d":"IMG_SIZE=256\n# Get and resize test images\nsample_submission = pd.read_csv('..\/input\/sartorius-cell-instance-segmentation\/sample_submission.csv')\ntest_ids = sample_submission['id'].unique().tolist()\n\nX_test = np.zeros((sample_submission['id'].nunique(), IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\nprint('Getting and resizing test images ... ')\n\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = f'..\/input\/sartorius-cell-instance-segmentation\/test\/{id_}.png'\n    print(path)\n    img = imread(path)[:,:]\n    img = resize(img, (IMG_SIZE, IMG_SIZE), mode='constant', preserve_range=True)\n    img = np.expand_dims(img, axis = 2)\n    X_test[n] = img\n\nprint('Done!')\n\nprint(X_test.shape)","085d7577":"preds_test = unet.predict(X_test, verbose=1)","5edb8ee0":"threshold=0.5\nmax_images = 3\ngrid_width = 3\n\ngrid_height = int(max_images \/ grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(35, 35))\nfor i, idx in enumerate(preds_test[:max_images]):\n    ax = axs[i]\n    img = X_test[i]\n    ax.imshow(img)\n    \n    pred = (preds_test[i] > threshold).astype(np.float32)\n    ax.imshow(pred, alpha=0.4, cmap=\"Reds\")\n    \n    ax.axis('off')","e1974358":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in range(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (IMG_SIZE, IMG_SIZE,1), \n                                       mode='constant', preserve_range=True))\n    \npreds_test_upsampled[0].shape","3f0def33":"# Run-length encoding stolen from https:\/\/www.kaggle.com\/rakhlin\/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = (x > cutoff).astype(int)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)","3cefd8f1":"def post_process(probability,min_size=300):\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = []\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            a_prediction = np.zeros((520, 704), np.float32)\n            a_prediction[p] = 1\n            predictions.append(a_prediction)\n    return predictions","a8db3e02":"output_df = pd.DataFrame(data = None, columns = sample_submission.columns)\ncount = 0\n\nfor n, id_ in enumerate(test_ids):\n    probability_mask = cv2.resize(preds_test_upsampled[n], dsize=(704, 520), interpolation=cv2.INTER_LINEAR)\n    predictions = post_process(probability_mask)\n    rle = [list(prob_to_rles(predictions[i]))[0] for i in range(0, len(predictions))]\n    for i in range(0, len(rle)):\n        cell_annotations = ' '.join([str(x) for x in rle[i]])\n        output_df.loc[count] = id_,cell_annotations\n        count +=1\n        \noutput_df.to_csv('submission.csv', index = False)\noutput_df","f8cc7648":"def rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\n\ndef build_masks(labels,input_shape, colors=True):\n    height, width = input_shape\n    if colors:\n        mask = np.zeros((height, width, 3))\n        for label in labels:\n            mask += rle_decode(label, shape=(height,width , 3), color=np.random.rand(3))\n    else:\n        mask = np.zeros((height, width, 1))\n        for label in labels:\n            mask += rle_decode(label, shape=(height, width, 1))\n    mask = mask.clip(0, 1)\n    return mask","3595f0c7":"sample_filename = '7ae19de7bc2a'\nsample_image_df = output_df[output_df['id'] == sample_filename]\nsample_path = f\"..\/input\/sartorius-cell-instance-segmentation\/test\/{sample_image_df['id'].iloc[0]}.png\"\nsample_img = cv2.imread(sample_path)\nsample_rles = sample_image_df['predicted'].values\n\nsample_masks=build_masks(sample_rles,input_shape=(520, 704), colors=False)\n\n\nfig, axs = plt.subplots(figsize=(20, 20))\naxs.imshow(sample_img)\naxs.axis('off')\naxs.imshow(sample_masks, alpha=0.4, cmap=\"Reds\")\naxs.axis('off')\n\n","ffb51f15":"# UNET model","1925fe4f":"# References\nhttps:\/\/www.kaggle.com\/arunamenon\/cell-instance-segmentation-unet-eda\nhttps:\/\/www.kaggle.com\/meaninglesslives\/unet-with-efficientnet-encoder-in-keras\/notebook\n","7a545a41":"![download.jpg](attachment:626e6920-452c-46ce-aa9e-c8acd63728a5.jpg)","e33eeea8":"# Prediction ","53614ddc":"# Sartorius Segmentation By U-Net [Inference]\n","2abd1b83":"# Function","fe8ca447":"### Hi kagglers, This is `Inference` notebook using `Keras`.\n\n* [Sartorius Segmentation - Keras U-Net[Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-training)\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>"}}