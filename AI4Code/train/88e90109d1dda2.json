{"cell_type":{"0934cfe7":"code","85628ae2":"code","883ab268":"code","003d5c25":"code","6c71bb68":"code","1cc94867":"code","17af0be2":"code","f99be706":"code","5eb60098":"code","354b2b62":"code","f10536b9":"code","2be9434b":"code","e6ef156a":"code","df187b11":"code","31b8d51e":"code","845a70a8":"code","c803cc37":"code","cc7b7fc0":"code","de1ce60e":"code","cff4070b":"code","48224856":"code","a7a0b2d6":"code","a4e29802":"code","ed7a521f":"code","de4c6d66":"markdown","c4fbccdc":"markdown","ee55ff83":"markdown","7601b413":"markdown","57d24be6":"markdown","bc6c44d4":"markdown","f691bf18":"markdown","04b54b9a":"markdown","dda7bf57":"markdown","a9236ed2":"markdown","f40487c8":"markdown","7efbaa86":"markdown","7b3dee7a":"markdown","3619ce63":"markdown","e04808e5":"markdown"},"source":{"0934cfe7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","85628ae2":"### Importing Required Libraries ###\n\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create the Stacked LSTM model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom keras.layers import Dropout","883ab268":"#read the file\ndf = pd.read_csv(\"..\/input\/nifty50-stock-market-data\/SBIN.csv\")\n\n#print the head\ndf.head()","003d5c25":"#setting index as date\ndf['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\ndf.index = df['Date']\n\n#plot\nplt.figure(figsize=(20,8))\nplt.plot(df['Close'], label='Historical Close Price')","6c71bb68":"features = [\"Date\", \"Close\"]\nall_data = df[features]","1cc94867":"#setting index\nall_data.index = all_data.Date\nall_data.drop('Date', axis=1, inplace=True)","17af0be2":"all_data.head()","f99be706":"all_data.shape","5eb60098":"#creating training and validation sets\ndataset = all_data.values\n\ntrain = dataset[2000:4500,:]\nvalid = dataset[4500:,:]","354b2b62":"scaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(dataset)","f10536b9":"x_train, y_train = [], []\nfor i in range(90,len(train)):\n    x_train.append(scaled_data[i-90:i,0])\n    y_train.append(scaled_data[i,0])\nx_train, y_train = np.array(x_train), np.array(y_train)","2be9434b":"x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))","e6ef156a":"# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\nmodel.add(Dropout(rate = 0.2))\n\nmodel.add(LSTM(units=50, return_sequences = True))\nmodel.add(Dropout(rate = 0.2))\n\nmodel.add(LSTM(units=50, return_sequences = True))\nmodel.add(Dropout(rate = 0.2))\n\nmodel.add(LSTM(units=50, return_sequences = False))\nmodel.add(Dropout(rate = 0.2))\n\nmodel.add(Dense(1))","df187b11":"model.compile(loss='mean_squared_error', optimizer='adam')","31b8d51e":"model.fit(x_train, y_train, epochs=100, batch_size=64, verbose=1)","845a70a8":"#predicting test data values, using past 90 from the train data\ninputs = all_data[len(all_data) - len(valid)-90:].values\ninputs = inputs.reshape(-1,1)\ninputs  = scaler.transform(inputs)","c803cc37":"inputs.shape","cc7b7fc0":"X_test = []\nfor i in range(90,inputs.shape[0]):\n    X_test.append(inputs[i-90:i,0])\nX_test = np.array(X_test)","de1ce60e":"X_test","cff4070b":"X_test.shape","48224856":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\npreds = model.predict(X_test)\npreds = scaler.inverse_transform(preds)","a7a0b2d6":"preds","a4e29802":"rms=np.sqrt(np.mean(np.power((valid-preds),2)))","ed7a521f":"#for plotting\ntrain = all_data[2000:4500]\nvalid = all_data[4500:]\nvalid['Predictions'] = preds\nplt.figure(figsize=(20,8))\nplt.plot(train['Close'])\nplt.plot(valid['Close'], color = 'blue', label = 'Real Price')\nplt.plot(valid['Predictions'], color = 'red', label = 'Predicted Price')\nplt.title('SBIN price prediction')\nplt.legend()\nplt.show()","de4c6d66":"### Calculating the RMSE to evaluate the model performance","c4fbccdc":"### Feature Scaling","ee55ff83":"This data structure is needed to cover 90-days close price stamps, based on which RNN will predict the 91st day's close price. ","7601b413":"Using Mean Squared Error as Loss Function","57d24be6":"Compiling the model with **Stochastic Gradient Descent** algorithm ","bc6c44d4":"Selecting Close Price as feature and removing other columns from the data","f691bf18":"### Plotting the output","04b54b9a":"### Creating Sliding Window of 90 days","dda7bf57":"### Model Building","a9236ed2":"#### Data Reshaping ","f40487c8":"### LSTM-based Recurrent Neural Network (RNN) to predict SBIN (State Bank of India) stock price","7efbaa86":"Initializing the LSTM model and 2nd, 3rd and 4th LSTM layer each with a Dropout Layer. The layers contain 50 neurons and with a Dropout rate of 20%, twenty percent of 50 neurons will be ignored randomly during each iteration\n\nFinally, an output layer is added with 1 as an output dimension (as we are predicting the close price)","7b3dee7a":"**Reading SBIN data from NIFTY 50 dataset**","3619ce63":"Setting Date as Index. We will use **Close** Price for prediction","e04808e5":"### Preparing the Test data for prediction"}}