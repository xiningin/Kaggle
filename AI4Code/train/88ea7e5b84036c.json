{"cell_type":{"a9ce8214":"code","24b9ab89":"code","351d8517":"code","9cbf4344":"code","a32f8ee6":"code","0e3324db":"code","95d8253c":"code","285ea06b":"code","fb01f419":"code","79e885c9":"code","bc2102bf":"markdown","1dc6ed16":"markdown","a2ef4646":"markdown","51c58133":"markdown","278e000c":"markdown","920cfc48":"markdown","1ee107d1":"markdown","84898a9f":"markdown","f47d0bf1":"markdown","c297b166":"markdown"},"source":{"a9ce8214":"!pip install gdown","24b9ab89":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport gdown\nfrom zipfile import ZipFile","351d8517":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport gdown\nfrom zipfile import ZipFile\n","9cbf4344":"os.makedirs(\"celeba_gan\")\n\nurl = \"https:\/\/drive.google.com\/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\noutput = \"celeba_gan\/data.zip\"\ngdown.download(url, output, quiet=True)\n\nwith ZipFile(\"celeba_gan\/data.zip\", \"r\") as zipobj:\n    zipobj.extractall(\"celeba_gan\")","a32f8ee6":"dataset = keras.preprocessing.image_dataset_from_directory(\"celeba_gan\", label_mode=None, image_size=(64, 64), batch_size=5)\ndataset = dataset.map(lambda x: x \/ 255.0)\n\nfor x in dataset:\n    plt.axis(\"off\")\n    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n    break","0e3324db":"#Discriminator\ndiscriminator = keras.Sequential([keras.Input(shape=(64, 64, 3)),\n                                  layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n                                  layers.LeakyReLU(alpha=0.2),\n                                  layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n                                  layers.LeakyReLU(alpha=0.2),\n                                  layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n                                  layers.LeakyReLU(alpha=0.2),\n                                  layers.Flatten(),\n                                  layers.Dropout(0.2),\n                                  layers.Dense(1, activation=\"sigmoid\"),],name=\"discriminator\",)\ndiscriminator.summary()\n\n#Generator\nlatent_dim = 128\ngenerator = keras.Sequential([keras.Input(shape=(latent_dim,)),\n                              layers.Dense(8 * 8 * 128),\n                              layers.Reshape((8, 8, 128)),\n                              layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n                              layers.LeakyReLU(alpha=0.2),\n                              layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n                              layers.LeakyReLU(alpha=0.2),\n                              layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n                              layers.LeakyReLU(alpha=0.2),\n                              layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),],name=\"generator\",)\ngenerator.summary()\n","95d8253c":"class GAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n#for Sampling random vectors in the latent dimension\n    def train_step(self, real_images):\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n#Decode fake images from random vectors \n        generated_images = self.generator(random_latent_vectors)\n\n#Combine the above-mentioned generated images and real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n\n#Assemble labels discriminating real from fake images\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n#Add random noise to the the above-mentioned labels\n#This process is important. Without noize, this structure doesn't work.\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n#Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n\n#for Sampling random vectors in the latent dimension\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n#Assemble labels that the generator successfully deceives the discriminator into believing real images.\n        misleading_labels = tf.zeros((batch_size, 1))\n#Train the generator.\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\n            \"d_loss\": self.d_loss_metric.result(),\n            \"g_loss\": self.g_loss_metric.result(),\n        }\n\n","285ea06b":"#Create a Monitor for checking the prgoress.\nclass GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=3, latent_dim=128):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = keras.preprocessing.image.array_to_img(generated_images[i])\n            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))","fb01f419":"#It takes long time to train this model. To increase the epoch lets you get better images.\nepochs = 2\ngan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\ngan.compile(d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss_fn=keras.losses.BinaryCrossentropy(),)\ngan.fit(dataset, epochs=epochs, callbacks=[GANMonitor(num_img=5, latent_dim=latent_dim)])","79e885c9":"from IPython.display import Image, display\nchat_pics='..\/input\/generated-images2\/generated_images_epoch2.png'\nImage(chat_pics)","bc2102bf":"<B>6.Set classese: Generator decodes fake images and minizes the ratio that Discriminator classifies fake images and real images properly.<\/B>","1dc6ed16":"<b>4.Prepare 64 x 64 images and show one of them. <\/b>","a2ef4646":"<B>1. When you wanna do it on Kaggle, you should install Gdown for fetching files from Google Drive.<\/B>","51c58133":"<b>2.Import libraries.<\/b>","278e000c":"<B>7.This is not a pre-trained model. Let's train the DCGAN model.<\/B>","920cfc48":"<b>5.Build a discriminator and a generator.<\/b>","1ee107d1":"#### https:\/\/keras.io\/examples\/generative\/dcgan_overriding_train_step\/","84898a9f":"<b>3.Use face imagess of CelebA dataset.<\/b>","f47d0bf1":"#### <font color=\"red\">This notebook is referred from one of Keras Official Site sample codes.So this is note to myself.<\/font>\n  ","c297b166":"<B>8.After 2 epochs, this model generated those images.<\/B>\n##### They don't exist for real. They were created by DC-GAN model."}}