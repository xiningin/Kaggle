{"cell_type":{"5c8a4cae":"code","8e3bc9c6":"code","9718fe1d":"code","70a54743":"code","8b0a0b2f":"code","c77f381f":"code","27f822ea":"code","d684cc81":"code","ed12af44":"code","031e8d36":"code","cf68c8d8":"code","cffead80":"code","245b7638":"code","abb77584":"code","80b8c742":"code","ac4e48a7":"code","a5e60ae2":"code","7102a15f":"code","eb52e8e4":"markdown","ed078d60":"markdown","0e4f68a4":"markdown","35f7ee7f":"markdown"},"source":{"5c8a4cae":"import torch\nimport transformers\nimport torch.nn as nn\nimport torch.nn.functional as F","8e3bc9c6":"white_collar = [\"Accountant\",\"Market researcher\",\"Health services administrator\",\"Executive director\",\"Civil engineer\"\n                ,\"Attorney\",\"Software engineer\",\"Physician\"]\nblue_collar = [\"Warehouse associate\",\"Inspector\/packer\",\"Landscape laborer\",\"Refuse collector\"\n,\"Flooring installer\",\"Mechanic\",\"HVAC technician\",\"Electrician\"]","9718fe1d":"TOKENIZER = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","70a54743":"def tokenize(text):\n    tokens = TOKENIZER.encode_plus(\n            text,\n            None,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=512,\n            padding=\"max_length\"\n        )\n    return {\n        \"input_ids\":torch.tensor(tokens[\"input_ids\"]).unsqueeze(0),\n        \"token_type_ids\":torch.tensor(tokens[\"token_type_ids\"]).unsqueeze(0),\n        \"attention_mask\":torch.tensor(tokens[\"attention_mask\"]).unsqueeze(0)\n    }","8b0a0b2f":"bert = transformers.BertModel.from_pretrained('bert-base-uncased',output_hidden_states=True)","c77f381f":"def output_second_last_hidden_state(tokens):\n    out = bert(tokens[\"input_ids\"],attention_mask=tokens[\"attention_mask\"],token_type_ids=tokens[\"token_type_ids\"])\n    return out.hidden_states[-2].numpy()","27f822ea":"blue_collar_tokens = []\nwhite_collar_tokens = []","d684cc81":"for text in blue_collar:\n    with torch.no_grad():\n        tokens = tokenize(text)\n        embed = output_second_last_hidden_state(tokens)\n        blue_collar_tokens.append(embed)\nfor text in white_collar:\n    with torch.no_grad():\n        tokens = tokenize(text)\n        embed = output_second_last_hidden_state(tokens)\n        white_collar_tokens.append(embed)","ed12af44":"import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import LinearSVC\nimport pandas as pd","031e8d36":"combined = blue_collar_tokens + white_collar_tokens\ncombined = np.concatenate(combined).sum(axis=1)\nlabel = np.array([1 if i>7 else 0 for i in range(16)])","cf68c8d8":"pca = PCA(n_components=2)\ndr = pca.fit_transform(combined)\nplt.scatter(dr[:,0],dr[:,1],c=[1 if i>7 else 0 for i in range(16)])\nplt.show()","cffead80":"svc = LinearSVC()\nsvc.fit(combined,label)","245b7638":"def predict_class(text):\n    with torch.no_grad():\n        tokens = tokenize(str(text))\n        embed = output_second_last_hidden_state(tokens).sum(axis=1)\n        answer = svc.predict(embed)\n        if answer.item() == 0:\n            return \"Blue Collar\"\n        else:\n            return \"White Collar\"","abb77584":"test = [\"cleaner\",\"driver\",\"data scientist\",\"machine learning engineer\",\n        \"hawker\",\"farmer\",\"miner\",\"ceo\",\"cfo\",\"construction worker\",\n       \"research coordinator\",\"project manager\",\"electrical engineer\",\n        \"software developer\",\"service crew\",\"cook\",\"lab technician\",\"software developer\",\"Firefighter\"\n       ,\"janitor\",\"landscaper\",\"manufactoring worker\",\"Business executive\",\"Market researcher\",\"lawyer\",\"Architect\"]\nfor t in test:\n    print(t,\":\",predict_class(t))","80b8c742":"df = pd.read_csv(\"..\/input\/jobposts\/data job posts.csv\")\ndf = df.sample(100,random_state=42) # Sampling as currently code does not support batch operations and is slow","ac4e48a7":"df[\"class_collar\"] = df[\"Title\"].apply(predict_class)","a5e60ae2":"df","7102a15f":"df.to_csv(\"result.csv\",index=False)","eb52e8e4":"# This example aims to demostrate few shot learning classification for classifying job titltes into blue collar and white collar jobs\n## What is few shot learning?\nIt is learning from very few examples. In many cases a pretrained network\/embedding is used with many early layers frozen to prevent overfitting.\n## Dataset\nSince there is no Ground truth dataset we will use the few examples here.\n\nhttps:\/\/www.indeed.com\/career-advice\/finding-a-job\/difference-between-blue-and-white-collar-jobs\n\nNote there are only 8 blue collar and 8 white collar job titles.\n\n## Modelling\nIn this example we used BertBase and use it's second last hidden state as an **sentence** embedding. \n\nWe do this by using an average pool on the second last layer.\n\nThe benefit of using bert is that it works on sentences as well as requiring little to no text cleaning.(no out of vocab problem)\n\nWe then pass this embedding to an SVM using sklearn linearSVC.\n\nNote that it is also possible to finetune bert however it is not shown in this example.","ed078d60":"# Here is the training dataset manually extracted from Indeed\nYes this is the **entire** training set.","0e4f68a4":"# Test set results seems to be relatively good","35f7ee7f":"# As you can see they are fairly well separated from the embeddings"}}