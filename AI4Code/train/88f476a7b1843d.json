{"cell_type":{"3c6259ed":"code","def2aeb1":"code","683db73e":"code","5bd8ec64":"code","1a79f1c5":"code","8cfc3f96":"code","33c0f444":"code","248983e1":"code","7588012a":"code","07b7ab21":"code","938b329f":"code","9ad4142b":"code","46cff3a9":"code","5cb0a9cd":"code","201f00fa":"code","0c4ec21e":"code","25c3c26b":"code","784306dd":"code","d5f17a4c":"code","d44049b7":"code","9183e45a":"code","133250c1":"code","8365f881":"code","feff4ca9":"code","71922289":"code","cd378455":"code","76ba75df":"code","ab03fd1c":"code","fc80bc05":"code","aaa0fdba":"code","d8c0f5b2":"code","2c3368bf":"code","1643b928":"code","f2ffbea1":"code","486d88f0":"code","baf0c920":"code","1eef5e4c":"code","2c794f3e":"code","fb3172f6":"code","f75eb3f9":"code","49b0463a":"code","d9b84aba":"code","08ff8e90":"code","5c5e88af":"code","085a6ef5":"code","b41c7b99":"code","90b1c69f":"code","510cfdfa":"code","a404c117":"code","40051dd2":"code","09f137d7":"code","772a340c":"code","12877fd0":"code","c635e1d7":"code","0770b1fd":"code","bac0da27":"code","da4d063a":"code","d9390822":"code","28ac18ce":"code","9ba98057":"code","fdda0eaa":"code","d2f7ccfa":"code","16410466":"code","a710a7bd":"code","c71243b0":"code","f2620234":"code","eac8e3db":"code","a543948b":"code","b28c6eff":"code","e090e8a4":"code","f510fb38":"code","37397e3c":"code","9757df74":"code","3ecd00f6":"code","35788ff0":"code","2b5b0c86":"code","4ab4dca3":"code","1fc68347":"code","e928b373":"code","b97ade01":"code","d70ceed4":"code","a333127f":"code","44e02c1b":"code","d00e6a27":"code","e0df6d9b":"code","d82ca8d5":"code","2a538c47":"code","6eae28f5":"code","f342d61c":"code","ffdeb38e":"code","f9465a1e":"code","0dca56ff":"code","95fca7da":"code","1cc08ab2":"code","c9c0f21a":"code","b8326cee":"code","8342c93f":"code","b963e71a":"code","85b9efb0":"code","572e338a":"code","4701d533":"code","ee361745":"code","22359389":"code","344c1314":"code","229dd6f0":"code","a0ba3475":"code","17a2d3f8":"code","5304e725":"code","ce7a12b6":"code","ecb5c8d3":"code","8fdf4ec5":"code","728ebaa6":"code","9003de97":"code","65ecc10f":"code","b320751e":"code","f6616690":"code","cc48c155":"code","6591b505":"code","570ec03c":"code","947b8000":"code","64803a82":"code","3d4c6d65":"code","07da6ba0":"code","fe62d019":"code","f75944e0":"code","48877b4a":"code","5441679a":"code","d8d6a481":"code","70fa0e70":"code","6488d789":"code","deeaf221":"code","aa0ac1ca":"code","9d721db8":"code","cd300852":"code","24860c0d":"code","5de0d134":"code","eb5a902f":"code","707e5953":"code","ee8726bc":"code","c7d96e63":"code","86270cde":"code","efa95637":"code","281d5077":"code","18fc035e":"code","9d1f3a00":"code","eebf1eda":"code","740f5380":"code","1c6a963f":"code","c19a3fdf":"code","c34c2d63":"code","fb025f63":"code","fa79de5b":"code","f0baf474":"code","37e65fc1":"code","b66f7f6c":"code","b4929ca7":"code","9c6c2ef9":"code","427be111":"code","6177dd21":"code","6c81740c":"code","6878785c":"code","c915e549":"code","ab42e888":"code","c125aaee":"markdown","a29f3f06":"markdown","80de473e":"markdown","2bcf66de":"markdown","703b9835":"markdown","b2290727":"markdown","3cd75344":"markdown","58b14ca6":"markdown","53176ce9":"markdown","f800ec02":"markdown","fdc36dfc":"markdown","2901b31d":"markdown","39bc07b3":"markdown","325c4962":"markdown","b279dffc":"markdown","5a377211":"markdown","aaed6cab":"markdown","5dc032da":"markdown","82308500":"markdown","1be8b124":"markdown","c68f59da":"markdown","976eb789":"markdown","0c374a30":"markdown","fbe944ab":"markdown","bff8fc1c":"markdown","3505f9a0":"markdown","fe00a320":"markdown","cb6ee1c4":"markdown","9e619725":"markdown","1fe44a36":"markdown","d12927f8":"markdown","31312176":"markdown","10d4dd94":"markdown","ef358ee8":"markdown","0a1c434a":"markdown","c7d27332":"markdown","b87093d2":"markdown","04d3578a":"markdown","d31c5c7f":"markdown","5eeea229":"markdown","3f6bf7b5":"markdown","8aa1db68":"markdown","fce7e215":"markdown","55dfc9fc":"markdown","33b8594b":"markdown"},"source":{"3c6259ed":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\n%matplotlib inline","def2aeb1":"df = pd.read_csv(\"..\/input\/bike-sharing-demand\/train.csv\")","683db73e":"type(df)","5bd8ec64":"df.head()","1a79f1c5":"df.tail()","8cfc3f96":"df.shape","33c0f444":"df.columns","248983e1":"df.dtypes","7588012a":"df.info()","07b7ab21":"df['weather'][0:3]","938b329f":"df.weather[0:3]","9ad4142b":"df[['weather','season']][6:70]","46cff3a9":"df['weather'].value_counts()","5cb0a9cd":"df['season'].value_counts()","201f00fa":"df['weather'].value_counts(normalize=True)* 100","0c4ec21e":"pd.crosstab( df.season, df.weather )","25c3c26b":"pd.crosstab( df.season, df.\n        weather, normalize = \"index\" )","784306dd":"pd.crosstab( df.season, df.weather, normalize = \"columns\" )","d5f17a4c":"pd.crosstab( df.season, df.weather, normalize = \"all\" )","d44049b7":"Above_800_Registered= df[ df.registered >= 800]","9183e45a":"Above_800_Registered[0:]","133250c1":"len( Above_800_Registered )","8365f881":"df[ df.registered >= 800 ][[\"weather\",\"season\",\"holiday\"]]","feff4ca9":"df[ df.registered >=700 ][[\"season\",\"weather\"]].value_counts( )","71922289":"df[ df.registered >=700 ][[\"season\",\"weather\"]].value_counts( normalize = True )","cd378455":"df.weather.unique()","76ba75df":"df[ df.datetime.isnull() ][['weather','season','registered','casual','count']][0:5]","ab03fd1c":"df[ -df.datetime.isnull() ][['weather','season','registered','casual','count']][0:5]","fc80bc05":"df.groupby( 'season' )['count'].mean()","aaa0fdba":"df.groupby( 'weather' )['count'].mean()","d8c0f5b2":"registered_mean_df = df.groupby( ['weather','season'] )['registered'].mean().reset_index()\nregistered_mean_df","2c3368bf":"registered_mean_df = df.groupby( ['weather','season'] )['count'].mean().reset_index()\nregistered_mean_df","1643b928":"df.sort_values( 'count',ascending=False)","f2ffbea1":"df.sort_values( 'registered', ascending = False)","486d88f0":"single_column = df['season']\nsingle_column","baf0c920":"type(single_column)","1eef5e4c":"multiple_column = df[['season','weather','count']]\nmultiple_column","2c794f3e":"df.iloc[3]","fb3172f6":"df.iloc[[3, 5, 7]]","f75eb3f9":"df.iloc[[3, 4], [1, 2,6]]","49b0463a":"df.iloc[9:25, 2:5]","d9b84aba":"df.iloc[:, [1, 2]]","08ff8e90":"df.query('registered >= 600 and season == 4 and weather == 3 ')","5c5e88af":"df.loc[(df.registered>=500)&(df.season==4)&(df.casual<=10)]","085a6ef5":"df.temp.unique()","b41c7b99":"df[(df['temp']>=27) & (df['season']==3)  & (df['registered']>=800)]","90b1c69f":"sns.catplot(x=\"season\", y=\"weather\", data=df,dodge=True)","510cfdfa":"sns.catplot(x=\"weather\", y=\"count\", data=df)","a404c117":"sns.catplot(x=\"season\", y=\"count\", data=df)","40051dd2":"sns.catplot( x=\"count\",y=\"temp\", data=df)\nsns.set_context(\"paper\")","09f137d7":"sns.catplot(x=\"count\", y=\"registered\", data=df)","772a340c":"sns.catplot(x=\"count\", y=\"casual\", data=df)","12877fd0":"sns.set()\ndfpie=df.groupby('season').sum()\ndp=dfpie[['registered','casual']]","c635e1d7":"dp.plot.pie(autopct=\"%1f%%\", subplots=True)","0770b1fd":"dfpie2=df.groupby('weather').sum()\ndp2=dfpie2[['casual','registered']]\ndp2.plot.pie(autopct=\"%1f%%\", subplots=True)","bac0da27":"dfpie3=df.groupby(df['temp']>=25).sum()\ndp3=dfpie3[['registered','casual']]\ndp3.plot.pie(autopct=\"%.1f%%\", subplots=True)","da4d063a":"dfpie4=df.groupby(df['humidity']<=50).sum()\ndp4=dfpie4[['registered','casual']]\ndp4.plot.pie(autopct=\"%.1f%%\", subplots=True)","d9390822":"df['Hour'] = df.datetime.astype(str).str[11:13].astype(float)\ndf['Day'] = df.datetime.astype(str).str[8:10].astype(float)\ndf['Month'] = df.datetime.astype(str).str[5:7].astype(float)\ndf['Year'] = df.datetime.astype(str).str[0:4].astype(float)","28ac18ce":"df.drop(['datetime'], axis=1, inplace=True)\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf.tail(5)","9ba98057":"# check for data type\nprint(df.dtypes)","fdda0eaa":"df.isnull().sum()","d2f7ccfa":"df.shape","16410466":"corr = df.corr()\ncorr.shape","a710a7bd":"plt.figure(figsize=(25,25))\nsns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')","c71243b0":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","f2620234":"X = df.drop(['count','registered','casual'],axis=1)\ny = df['count']","eac8e3db":"X_train, X_test , y_train , y_test = train_test_split(X,y,test_size=0.25,random_state=26)","a543948b":"regressor = LinearRegression()\nregressor.fit(X_train, y_train)","b28c6eff":"predictions=regressor.predict(X_test)","e090e8a4":"X_test","f510fb38":"predictions[0]","37397e3c":"y_test","9757df74":"sns.histplot(y_test-predictions)","3ecd00f6":"regressor.intercept_","35788ff0":"regressor.coef_","2b5b0c86":"#Converting the coefficient values to a dataframe\ncoeffcients = pd.DataFrame([X_train.columns,regressor.coef_]).T\ncoeffcients = coeffcients.rename(columns={0: 'Attribute', 1: 'Coefficients'})\ncoeffcients","4ab4dca3":"from sklearn import metrics","1fc68347":"# Model prediction on train data\npredictions","e928b373":"# Model Evaluation\nprint('R^2:',metrics.r2_score(y_test, predictions))\nprint('MAE:',metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:',metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, predictions)))","b97ade01":"# Visualizing the differences between actual count and predicted count\nplt.scatter(y_test, predictions)\nplt.xlabel(\"Count\")\nplt.ylabel(\"Predicted Count\")\nplt.title(\"Count vs Predicted Count\")\nplt.show()","d70ceed4":"sns.displot(y_test-predictions)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","a333127f":"from sklearn.preprocessing import PolynomialFeatures","44e02c1b":"\"Creates a polynomial regression model for the given degree\"\npoly_features = PolynomialFeatures(degree=2)\n   \n# transform the features to higher degree features.\nX_train_quadratic = poly_features.fit_transform(X_train)\n   \n# fit the transformed features to Linear Regression\nquadratic = LinearRegression()\n\nquadratic.fit(X_train_quadratic, y_train)\n     \n# predicting on training data-set\ny_train_predicted = quadratic.predict(X_train_quadratic)\n   \n# predicting on test data-set\ny_test_predicted = quadratic.predict(poly_features.fit_transform(X_test))","d00e6a27":"metrics.r2_score(y_train, y_train_predicted)","e0df6d9b":"metrics.r2_score(y_test, y_test_predicted)","d82ca8d5":"# Visualizing the differences between actual Count and predicted values\nplt.scatter(y_test, y_test_predicted)\nplt.xlabel(\"Count\")\nplt.ylabel(\"Predicted Count\")\nplt.title(\"Count vs Predicted Count\")\nplt.show()","2a538c47":"sns.displot(y_test-y_test_predicted)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","6eae28f5":"\"Creates a polynomial regression model for the given degree\"\npoly_features = PolynomialFeatures(degree=3)\n   \n# transform the features to higher degree features.\nX_train_cubic = poly_features.fit_transform(X_train)\n   \n# fit the transformed features to Linear Regression\ncubic = LinearRegression()\n\ncubic.fit(X_train_cubic, y_train)\n     \n# predicting on training data-set\ny_train_predicted = cubic.predict(X_train_cubic)\n   \n# predicting on test data-set\ny_test_predicted = cubic.predict(poly_features.fit_transform(X_test))","f342d61c":"metrics.r2_score(y_train, y_train_predicted)","ffdeb38e":"metrics.r2_score(y_test, y_test_predicted)","f9465a1e":"# Visualizing the differences between actual Count and predicted values\nplt.scatter(y_test, y_test_predicted)\nplt.xlabel(\"Count\")\nplt.ylabel(\"Predicted Count\")\nplt.title(\"Count vs Predicted Count\")\nplt.show()","0dca56ff":"sns.displot(y_test-y_test_predicted)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","95fca7da":"\"Creates a polynomial regression model for the given degree\"\npoly_features = PolynomialFeatures(degree=4)\n   \n# transform the features to higher degree features.\nX_train_4 = poly_features.fit_transform(X_train)\n   \n# fit the transformed features to Linear Regression\nDegree_4 = LinearRegression()\n\nDegree_4.fit(X_train_4, y_train)\n     \n# predicting on training data-set\ny_train_predicted = Degree_4.predict(X_train_4)\n   \n# predicting on test data-set\ny_test_predicted = Degree_4.predict(poly_features.fit_transform(X_test))","1cc08ab2":"metrics.r2_score(y_train, y_train_predicted)","c9c0f21a":"metrics.r2_score(y_test, y_test_predicted)","b8326cee":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n#Ridge Regression\nrr = Ridge(alpha=0.01)\nrr.fit(X_train, y_train) \npred_train_rr= rr.predict(X_train)\nprint('mean_squared_error for train : ',np.sqrt(mean_squared_error(y_train,pred_train_rr)))\nprint('r2_score for train : ',r2_score(y_train, pred_train_rr))\n\npred_test_rr= rr.predict(X_test)\nprint('mean_squared_error for test : ',np.sqrt(mean_squared_error(y_test,pred_test_rr))) \nprint('r2_score for test :',r2_score(y_test, pred_test_rr))","8342c93f":"# Visualizing the differences between actual Count and predicted values\nplt.scatter(y_test, pred_test_rr)\nplt.xlabel(\"Count\")\nplt.ylabel(\"Predicted Count\")\nplt.title(\"Count vs Predicted Count\")\nplt.show()","b963e71a":"sns.displot(y_test-pred_test_rr)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","85b9efb0":"from sklearn.linear_model import Lasso\n#Lasso Regression\nmodel_lasso = Lasso(alpha=0.01)\nmodel_lasso.fit(X_train, y_train) \npred_train_lasso= model_lasso.predict(X_train)\nprint('mean_squared_error for train : ',np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\nprint('r2_score for train : ',r2_score(y_train, pred_train_lasso))\n\npred_test_lasso= model_lasso.predict(X_test)\nprint('mean_squared_error for test : ',np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \nprint('r2_score for test :',r2_score(y_test, pred_test_lasso))","572e338a":"# Visualizing the differences between actual Count and predicted values\nplt.scatter(y_test, pred_test_lasso)\nplt.xlabel(\"Count\")\nplt.ylabel(\"Predicted Count\")\nplt.title(\"Count vs Predicted Count\")\nplt.show()","4701d533":"sns.displot(y_test-pred_test_lasso)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","ee361745":"from sklearn.linear_model import ElasticNet\n#Elastic Net\nmodel_enet = ElasticNet(alpha = 0.01)\nmodel_enet.fit(X_train, y_train) \npred_train_enet= model_enet.predict(X_train)\nprint('mean_squared_error for train : ',np.sqrt(mean_squared_error(y_train,pred_train_enet)))\nprint('r2_score for train : ',r2_score(y_train, pred_train_enet))\n\npred_test_enet= model_enet.predict(X_test)\nprint('mean_squared_error for test : ',np.sqrt(mean_squared_error(y_test,pred_test_enet)))\nprint('r2_score for test :',r2_score(y_test, pred_test_enet))","22359389":"# Visualizing the differences between actual Count and predicted values\nplt.scatter(y_test, pred_test_enet)\nplt.xlabel(\"Count\")\nplt.ylabel(\"Predicted Count\")\nplt.title(\"Count vs Predicted Count\")\nplt.show()","344c1314":"sns.displot(y_test-pred_test_enet)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","229dd6f0":"import warnings\nwarnings.filterwarnings('ignore')","a0ba3475":"from sklearn.neighbors import KNeighborsClassifier","17a2d3f8":"knn = KNeighborsClassifier(  )\n#n_neighbors = 5","5304e725":"knn.fit(X_train, y_train)","ce7a12b6":"y_pred = knn.predict(X_test)","ecb5c8d3":"knn.score(X_train, y_train)","8fdf4ec5":"knn.score(X_test, y_test)","728ebaa6":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","9003de97":"print(classification_report(y_test, y_pred))","65ecc10f":"error_rate = []\n\nfor i in range(1,20):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","b320751e":"plt.figure(figsize=(10,6))\nplt.plot(range(1,20),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","f6616690":"knn = KNeighborsClassifier(n_neighbors=12)","cc48c155":"knn.fit(X_train, y_train)","6591b505":"y_pred = knn.predict(X_test)","570ec03c":"knn.score(X_train, y_train)","947b8000":"knn.score(X_test, y_test)","64803a82":"# Training the Decision Tree Regression model on the whole dataset\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(X_train, y_train)","3d4c6d65":"y_pred=regressor.predict(X_test)","07da6ba0":"# Visualising the Decision Tree Regression results (higher resolution)\n\nplt.scatter(y_test, y_pred)\n\n","fe62d019":"sns.displot(y_test-y_pred)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","f75944e0":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nprint('mean_squared_error for test : ',np.sqrt(mean_squared_error(y_test,y_pred))) \nprint('r2_score for test :',r2_score(y_test, y_pred))","48877b4a":"# for 10 trees\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nregressor.fit(X_train,y_train)","5441679a":"y_pred=regressor.predict(X_test)\ny_pred","d8d6a481":"# Visualising the Decision Tree Regression results (higher resolution)\n\nplt.scatter(y_test, y_pred)\n","70fa0e70":"sns.displot(y_test-y_pred)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","6488d789":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nprint('mean_squared_error for test : ',np.sqrt(mean_squared_error(y_test,y_pred))) \nprint('r2_score for test :',r2_score(y_test, y_pred))","deeaf221":"# for 100 trees\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\nregressor.fit(X_train,y_train)","aa0ac1ca":"y_pred=regressor.predict(X_test)\ny_pred","9d721db8":"# Visualising the Decision Tree Regression results (higher resolution)\n\nplt.scatter(y_test, y_pred)\n","cd300852":"sns.displot(y_test-y_pred)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","24860c0d":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nprint('mean_squared_error for test : ',np.sqrt(mean_squared_error(y_test,y_pred))) \nprint('r2_score for test :',r2_score(y_test, y_pred))","5de0d134":"# for 300 trees\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 300, random_state = 0)\nregressor.fit(X_train,y_train)","eb5a902f":"y_pred=regressor.predict(X_test)\ny_pred","707e5953":"# Visualising the Decision Tree Regression results (higher resolution)\n\nplt.scatter(y_test, y_pred)\n","ee8726bc":"sns.displot(y_test-y_pred)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","c7d96e63":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nprint('mean_squared_error for test : ',np.sqrt(mean_squared_error(y_test,y_pred))) \nprint('r2_score for test :',r2_score(y_test, y_pred))","86270cde":"!pip install xgboost\nimport xgboost as xgb\nfrom sklearn.model_selection import cross_val_score, KFold","efa95637":"reg_mod = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.08,\n    subsample=0.75,\n    colsample_bytree=1, \n    max_depth=7,\n    gamma=0,\n)\nreg_mod.fit(X_train, y_train)","281d5077":"#After training the model, we'll check the model training score.\nscores = cross_val_score(reg_mod, X_train, y_train,cv=10)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","18fc035e":"reg_mod.fit(X_train,y_train)\n\npredictions = reg_mod.predict(X_test)","9d1f3a00":"rmse = np.sqrt(mean_squared_error(y_test, predictions))\nprint(\"RMSE: %f\" % (rmse))","eebf1eda":"from sklearn.metrics import r2_score\nr2 = np.sqrt(r2_score(y_test, predictions))\nprint(\"R_Squared Score : %f\" % (r2))","740f5380":"plt.figure(figsize=(10, 5), dpi=80)\nsns.lineplot(x='temp', y='count', data=df)","1c6a963f":"plt.figure(figsize=(10, 5), dpi=80)\nsns.lineplot(x='weather', y='count', data=df)","c19a3fdf":"plt.figure(figsize=(10, 5), dpi=80)\nsns.lineplot(x='season', y='count', data=df)","c34c2d63":"plt.figure(figsize=(300, 150), dpi=80)\nx_ax = range(len(y_test))\nplt.plot(x_ax, y_test, label=\"test\")\nplt.plot(x_ax, predictions, label=\"predicted\")\n\nplt.legend()\nplt.show()","fb025f63":"df_x_test=pd.read_csv(\"..\/input\/bike-sharing-demand-test\/test.csv\")","fa79de5b":"df_x_test['Hour'] = df_x_test.datetime.astype(str).str[11:13].astype(float)\ndf_x_test['Day'] = df_x_test.datetime.astype(str).str[8:10].astype(float)\ndf_x_test['Month'] = df_x_test.datetime.astype(str).str[5:7].astype(float)\ndf_x_test['Year'] = df_x_test.datetime.astype(str).str[0:4].astype(float)","f0baf474":"df_x_test.drop(['datetime'], axis=1, inplace=True)\ndf_x_test.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf_x_test.tail(5)","37e65fc1":"X_test=df_x_test","b66f7f6c":"predictions = reg_mod.predict(X_test)","b4929ca7":"predictions","9c6c2ef9":"# for 300 trees\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 300, random_state = 0)\nregressor.fit(X_train,y_train)","427be111":"y_pred=regressor.predict(X_test)\ny_pred","6177dd21":"plt.plot(predictions,y_pred,'b+')","6c81740c":"len(predictions[predictions<0])","6878785c":"# Equalize negative values with zero\npredictions[predictions<0]=0","c915e549":"plt.plot(predictions,y_pred,'g.')","ab42e888":"r2 = np.sqrt(r2_score(predictions, y_pred))\nprint(\"R_Squared Score : %f\" % (r2))","c125aaee":"## Random Forest Regression","a29f3f06":"###### by analyzing the 'count-temp' diagram: most people rent a bike in temperature between 15-30","80de473e":"###### the information of the 3th and 4th row ,and the first,second and the 6th columns...","2bcf66de":"# Loading Test Datas","703b9835":"# Polynomial regression ","b2290727":"# Load and Prepare Data","3cd75344":"## Decision Tree Model","58b14ca6":"## KNN Regression","53176ce9":"####  The plot fits with a good approximation on the line y=x ,so the result for the test data (with equalizing negative values with 0), is acceptable... ","f800ec02":"###### by looking at the' weather-count' diagram,we conclude that the most counted bikes are in weather 1.","fdc36dfc":"###### the information of the third , 5th and the 7th rows...","2901b31d":"###### the  highest mean registered bikes is in season3(autumn) and weather1(Clear, Few clouds, Partly cloudy, Partly cloudy )\n###### and the lowest one is in season1(spring) and weather3(Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds )\n","39bc07b3":"## Model (SLR) Evaluation","325c4962":"### 1-XGBoost  =>  R^2_Score = 0.976\n### 2-RandomForest(100 tree) => R^2_Score=0.949\n### 3-RandomForest(300 tree) => R^2_Score=0.948\n### 4-RandomForest(10 tree) => R^2_Score=0.944\n### 5-DesicionTree => R^2_Score= 0.883\n### 6-Polynominal(Degree=3) Regression => R^2_Score=0.623\n### 7-Polynominal(Degree=2) Regression => R^2_Score=0.54\n### 8-LinearRegression , Ridge , Lasso , ElasticNet   => R^2_Score=0.388   !not acceptable!\n### 9-Polynominal(Degree=4) Regression => R^2_Score= -42.998  :)))))   !not acceptable!","b279dffc":"# RandomForest (with 300 trees ) For The Test Data :","5a377211":"###### Fortunately we have no null items :)","aaed6cab":"# EDA Using pandas","5dc032da":"## Working on number of Trees (300)","82308500":"# XGBoost Regression For The Test Data :","1be8b124":"# Best Model (R^2 Squared Score) :","c68f59da":"# Importing the libraries","976eb789":"###### the information of the first and the second columns ...","0c374a30":"## Working on number of Trees (100)","fbe944ab":"## XGBoost Regression","bff8fc1c":"## Ridge Regression","3505f9a0":"##### As you have observed more the number of trees, the more accurate is our result.","fe00a320":"###### we see the distribution of data by the 'season-count' diagram. ","cb6ee1c4":"## Get the Dataset Ready For Machine Learning :","9e619725":"## Linear Regression","1fe44a36":"# Visualization","d12927f8":"# Information About Features of Dataset:\n###### datetime - hourly date + timestamp  \n###### season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n###### holiday - whether the day is considered a holiday\n###### workingday - whether the day is neither a weekend nor holiday\n###### weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n###### 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n###### 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n###### 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n###### temp - temperature in Celsius\n###### atemp - \"feels like\" temperature in Celsius\n###### humidity - relative humidity\n###### windspeed - wind speed\n###### casual - number of non-registered user rentals initiated\n###### registered - number of registered user rentals initiated\n###### count - number of total rentals\n","31312176":"## Lasso Regression","10d4dd94":"## Optimal value of K","ef358ee8":"###### 13 days have a greater registered bikes than 800","0a1c434a":"# SELECTING WITH loc AND iloc :","c7d27332":"<img src = \"https:\/\/www.pyimagesearch.com\/wp-content\/uploads\/2019\/01\/python_ml_header.png\" width=40%>\n","b87093d2":"## ElasticNet Model","04d3578a":"###### the information of the third row...","d31c5c7f":"###### consist of 10886 rows and 12 columns","5eeea229":"###### the information of rows of 9-24 and  columns of 2-4...","3f6bf7b5":"##### but we have problems with negative values...","8aa1db68":"# Query()","fce7e215":"##### By looking at the result,we try the XGBoost and RandomForest Regression for the test datas ;","55dfc9fc":"## Decision Tree Regression","33b8594b":"##### The plot fits well on the line y=x ,so the result for the test data is acceptable..."}}