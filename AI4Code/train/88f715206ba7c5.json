{"cell_type":{"3aa2597d":"code","996b193d":"code","b01014d4":"code","68b21da7":"code","2f1256ca":"code","9390bd16":"code","aa7915e4":"code","8ec23aa8":"code","ad9acf6e":"code","7082a145":"code","3cb50fdd":"code","bce044a6":"code","ec9cdcc4":"code","efcc3b73":"code","dacb6793":"code","6dadd572":"code","12fd8236":"code","5fad3e25":"code","4a4baf82":"code","4e36a2ef":"code","c135ac04":"code","8117602c":"markdown","6c7f7c6c":"markdown","085f3246":"markdown","21efffa8":"markdown","e600a9d0":"markdown","f0a5bb28":"markdown","dfb5b8f6":"markdown","29c8f6ef":"markdown","bc9e6b1d":"markdown","3bc37adf":"markdown"},"source":{"3aa2597d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","996b193d":"train = pd.read_csv(\"..\/input\/Kannada-MNIST\/train.csv\")\ntest = pd.read_csv(\"..\/input\/Kannada-MNIST\/test.csv\")","b01014d4":"Y = train[\"label\"]\n\n# Drop 'label' column\nX = train.drop(labels = [\"label\"],axis = 1) ","68b21da7":"# Normalize the data\nX = X \/ 255.0\ntest = test \/ 255.0","2f1256ca":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX = X.values.reshape(-1,28,28,1)","9390bd16":"X.shape","aa7915e4":"#Dropping id column\nx_test=test.drop('id', axis=1).iloc[:,:].values\nx_test = x_test.reshape(x_test.shape[0], 28, 28,1)\nx_test.shape","8ec23aa8":"import matplotlib.pyplot as plt\n%matplotlib inline","ad9acf6e":"plt.figure(num='digit',figsize=(9,9))\nfor i in range(9):\n    plt.subplot(3,3,i+1) \n    plt.title(Y[i])\n    plt.imshow(np.squeeze(X[i,:,:,]))\nplt.show()","7082a145":"# Converting dependent variables into categorical data\nfrom keras.utils.np_utils import to_categorical\nY = to_categorical(Y, num_classes = 10)","3cb50fdd":"# Splitting dataset into taining and validation set\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.1, random_state=42)","bce044a6":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU\nfrom keras.layers import LeakyReLU\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nhidden_unit = 32\nkernel_size = 3\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same' , activation ='relu',input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same' , activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same' , activation ='relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same' , activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same' , activation ='relu'))\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same' , activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(pool_size=(1,2), strides=(1,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(TimeDistributed(Flatten()))\nmodel.add(Bidirectional(GRU(hidden_unit,return_sequences=True)))\nmodel.add(Flatten())\nmodel.add(Dense(256 , activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation = \"softmax\"))","ec9cdcc4":"datagen = ImageDataGenerator(  \n        rotation_range=10,  \n        zoom_range = 0.1,\n        width_shift_range=0.1,  \n        height_shift_range=0.1, \n        horizontal_flip=False,  \n        vertical_flip=False)  \ndatagen.fit(X_train)","efcc3b73":"optimizer = RMSprop(lr=0.005, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nlearning_rate = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nepochs = 50\nbatch_size = 128","dacb6793":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate])","6dadd572":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n","12fd8236":"from sklearn.metrics import confusion_matrix\nimport itertools\nplt.figure(num='digit',figsize=(9,9))\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10))","5fad3e25":"#Display some error results \nerrors = (Y_pred_classes - Y_true != 0)\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    plt.figure(num='digit',figsize=(9,9))\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","4a4baf82":"# predict results\nresults = model.predict(x_test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"label\") ","4e36a2ef":"submission = pd.read_csv('..\/input\/Kannada-MNIST\/sample_submission.csv')\nsubmission['label'] = results","c135ac04":"submission.to_csv(\"submission.csv\",index=False)","8117602c":"Submit the results","6c7f7c6c":"Data Loading","085f3246":"Let's plot and see the dataset","21efffa8":"Use Keras Data Generator to create more data","e600a9d0":"Let's plot the loss and accuracy curves for training and validation to see how our model performed","f0a5bb28":"Let's plot confusion matrix and see how our model is performing on validation dataset","dfb5b8f6":"# CRNN : CNN + RNN\nCRNN is a network that combines CNN and RNN to process images containing sequence information such as letters.\n\nIt is mainly used for OCR technology and has the following advantages.\n\n    End-to-end learning is possible.\n    Sequence data of arbitrary length can be processed because of LSTM which is free in size of input and output sequence.\n    There is no need for a detector or cropping technique to find each character one by one.\n\nYou can use CRNN for OCR, license plate recognition, text recognition, and so on. It depends on what data you are training.\n\n## Model\n![image.png](attachment:image.png)\n\n## Layers\n\nThere are mainly three layers in CRNN architecture\n\n### Convolutional Layer\n\nExtracts features through CNN Layer (VGGNet, ResNet ...).\n\n### Recurrent Layer\n\nSplits the features into a certain size and inserts them into the input of the Bidirectional LSTM or GRU.\n\n### Transcription Layer\n\nConversion of Feature-specific predictions to Label using CTC (Connectionist Temporal Classification).\n","29c8f6ef":"**I hope you liked the notebook.\nIf you find this notebook useful please upvote!!!**","bc9e6b1d":"Preparing dataset","3bc37adf":"### Things to do next \nThe fllowing tweak can be implemented on architecure to get better result.\n- Add more LSTM network\n- Impelement and use CTC loss \n- Different activation function"}}