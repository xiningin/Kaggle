{"cell_type":{"df728e0f":"code","9f1323ab":"code","d423baf6":"code","582cb6b2":"code","bfe2070e":"code","7ee0f38d":"code","107d698e":"code","a0d7f58a":"code","7fe0823c":"code","4bfc8d01":"code","6af3b96f":"code","e5d2ef25":"code","7afa4ad4":"code","20f94778":"code","c7750f8f":"code","81fe043c":"code","85864c00":"code","946dafbb":"code","2aaeb8f9":"code","0ba82315":"code","36310d69":"code","32340b45":"code","5e7b3444":"code","b331106d":"code","ebf7d4da":"code","cfe1d096":"code","22f485f5":"code","1e6c6862":"code","ac376990":"code","5467ec20":"markdown","4c5e02f2":"markdown","824ac5f8":"markdown","cc4365fd":"markdown","8e340fd6":"markdown","fb5e488c":"markdown"},"source":{"df728e0f":"# enable showing live \"loss plot\" inside notebook\n!pip install livelossplot","9f1323ab":"%%capture\n!conda install -y -c conda-forge jax jaxlib flax optax datasets transformers\n!conda install -y importlib-metadata\n!pip install -U dm-haiku","d423baf6":"# TPU setup\nimport os\nif 'TPU_NAME' in os.environ:\n    import requests\n    if 'TPU_DRIVER_MODE' not in globals():\n        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475\/requestversion\/tpu_driver_nightly'\n        resp = requests.post(url)\n        TPU_DRIVER_MODE = 1\n\n    from jax.config import config\n    config.FLAGS.jax_xla_backend = \"tpu_driver\"\n    config.FLAGS.jax_backend_target = os.environ['TPU_NAME']\n    print('Registered TPU:', config.FLAGS.jax_backend_target)\nelse:\n    print('No TPU detected. Can be changed under \"Runtime\/Change runtime type\".')\n\n# Module check\nimport jax\nimport flax\nimport haiku as hk\n\nfor _m in (jax, flax, hk):\n    print(f'{_m.__name__}: {_m.__version__}')\njax.local_devices()","582cb6b2":"from functools import partial\n\nimport jax\nfrom jax import random, grad, jit, vmap, flatten_util, nn\nfrom jax.experimental import optimizers  # change due to version difference\nfrom jax.config import config\nimport jax.numpy as np\n\nimport haiku as hk\nfrom haiku._src import utils\n\nfrom livelossplot import PlotLosses\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm as tqdm\nimport cv2\nimport imageio\nimport glob\nfrom IPython.display import clear_output\nimport pickle\nfrom skimage.metrics import structural_similarity as ssim_fn\n\nrng = jax.random.PRNGKey(42)","bfe2070e":"#ls ..\/input\/pull-phototourism-images\/sacre_coeur\/dense\/images\nDATASET = 'sacre'\nposedir = f'..\/input\/phototourism\/phototourism\/sacre' # Directory condtains [bds.npy, c2w_mats.npy, kinv_mats.npy, res_mats.npy]\nimgdir = f'..\/input\/pull-phototourism-images\/sacre_coeur\/dense\/images' # Directory of images","7ee0f38d":"posedata = {}\nfor f in os.listdir(posedir):\n    if '.npy' not in f:\n        continue\n    z = np.load(os.path.join(posedir, f))\n    posedata[f.split('.')[0]] = z\nprint('Pose data loaded - ', posedata.keys())\n\nimgfiles = sorted(glob.glob(imgdir + '\/*.jpg'))\nprint(f'{len(imgfiles)} images')","107d698e":"@jit\ndef get_rays(c2w, kinv, i, j):\n#     i, j = np.meshgrid(np.arange(W), np.arange(H), indexing='xy')\n    pixco = np.stack([i, j, np.ones_like(i)], -1)\n    dirs = pixco @ kinv.T\n#     dirs = np.stack([(i-W*.5)\/focal, -(j-H*.5)\/focal, -np.ones_like(i)], -1)\n    rays_d = np.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)\n    rays_o = np.broadcast_to(c2w[:3,-1], rays_d.shape)\n    return np.stack([rays_o, rays_d], 0)\n\n\ndef normalize(x):\n    return x \/ np.linalg.norm(x)\n\n\ndef viewmatrix(z, up, pos):\n    vec2 = normalize(z)\n    vec1_avg = up\n    vec0 = normalize(np.cross(vec1_avg, vec2))\n    vec1 = normalize(np.cross(vec2, vec0))\n    m = np.stack([vec0, vec1, vec2, pos], 1)\n    return m\n\n\ndef ptstocam(pts, c2w):\n    tt = np.matmul(c2w[:3,:3].T, (pts-c2w[:3,3])[...,np.newaxis])[...,0]\n    return tt\n\n\ndef poses_avg(poses):\n    center = poses[:, :3, 3].mean(0)\n    vec2 = normalize(poses[:, :3, 2].sum(0))\n    up = poses[:, :3, 1].sum(0)\n    return viewmatrix(vec2, up, center)\n\n\ndef render_path_spiral(c2w, up, rads, focal, zrate, rots, N):\n    \"\"\"\n    enumerate list of poses around a spiral\n    used for test set visualization\n    \"\"\"\n    render_poses = []\n    rads = np.array(list(rads) + [1.])\n    for theta in np.linspace(0., 2. * np.pi * rots, N+1)[:-1]:\n        c = np.dot(c2w[:3,:4], np.array([np.cos(theta), -np.sin(theta), -np.sin(theta*zrate), 1.]) * rads) \n        z = normalize(c - np.dot(c2w[:3,:4], np.array([0,0,-focal, 1.])))\n        render_poses.append(viewmatrix(z, up, c))\n    return render_poses","a0d7f58a":"def get_example(img_idx, split='train', downsample=4):\n    sc = .05\n    \n    # first 20 are test, next 5 are validation, the rest are training:\n    # https:\/\/github.com\/tancik\/learnit\/issues\/3\n    if 'train' in split:\n        img_idx = img_idx + 25\n    if 'val' in split:\n        img_idx = img_idx + 20\n        \n    # uint8 --> float\n    img = imageio.imread(imgfiles[img_idx])[...,:3]\/255.\n    \n    # WHAT DO THESE MATRICES MEAN???\n    # (4, 4)\n    c2w = posedata['c2w_mats'][img_idx]\n    # (3, 3)\n    kinv = posedata['kinv_mats'][img_idx]\n    c2w = np.concatenate([c2w[:3,:3], c2w[:3,3:4]*sc], -1)\n    # (2, )\n    bds = posedata['bds'][img_idx] * np.array([.9, 1.2]) * sc\n    H, W = img.shape[:2]\n    \n    # (0, 4, 8, ..., H)\n    # WHAT ARE THE PURPOSES OF THIS MATRIX???\n    i, j = np.meshgrid(np.arange(0,W,downsample), np.arange(0,H,downsample), indexing='xy')\n    \n    test_images = img[j, i]\n    test_rays = get_rays(c2w, kinv, i, j)\n    return test_images, test_rays, bds","7fe0823c":"def render_rays(\n        rnd_input, model, params, \n        bvals, rays, near, far, \n        N_samples, rand=False, allret=False\n    ):\n    rays_o, rays_d = rays\n\n    # Compute 3D query points\n    z_vals = np.linspace(near, far, N_samples) \n    if rand:\n        z_vals += random.uniform(rnd_input, shape=list(rays_o.shape[:-1]) + [N_samples]) * (far-near)\/N_samples\n    # r(t) = o + t*d\n    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n    \n    # Run network\n    pts_flat = np.reshape(pts, [-1,3])\n    if bvals is not None:\n        pts_flat = np.concatenate([np.sin(pts_flat @ bvals.T), \n                                np.cos(pts_flat @ bvals.T)], axis=-1)\n        \n    raw = model.apply(params, pts_flat)\n    raw = np.reshape(raw, list(pts.shape[:-1]) + [4])\n    \n    # Compute opacities and colors\n    rgb, sigma_a = raw[...,:3], raw[...,3]\n    sigma_a = jax.nn.relu(sigma_a)\n    rgb = jax.nn.sigmoid(rgb) \n    \n    # Do volume rendering\n    dists = np.concatenate([z_vals[..., 1:] - z_vals[..., :-1], np.broadcast_to([1e10], z_vals[...,:1].shape)], -1) \n    alpha = 1. - np.exp(-sigma_a * dists)\n    trans = np.minimum(1., 1. - alpha + 1e-10)\n    trans = np.concatenate([np.ones_like(trans[...,:1]), trans[...,:-1]], -1)  \n    weights = alpha * np.cumprod(trans, -1)\n    \n    rgb_map = np.sum(weights[...,None] * rgb, -2) \n    acc_map = np.sum(weights, -1)\n    \n    if False:\n        rgb_map = rgb_map + (1.-acc_map[..., None])\n    \n    if not allret:\n        return rgb_map\n    \n    depth_map = np.sum(weights * z_vals, -1) \n\n    return rgb_map, depth_map, acc_map\n\n\ndef render_fn_inner(rnd_input, model, params, bvals, rays, near, far, rand, allret, N_samples):\n    return render_rays(rnd_input, model, params, bvals, rays, near, far, \n                       N_samples=N_samples, rand=rand, allret=allret)\n\n# optimize render_fn_inner by JIT (func in, func out)\nrender_fn_inner = jit(render_fn_inner, static_argnums=(1, 7, 8, 9))\n\n\ndef render_fn(rnd_input, model, params, bvals, rays, near, far, N_samples, rand):\n    chunk = 5\n    for i in range(0, rays.shape[1], chunk):\n        out = render_fn_inner(rnd_input, model, params, bvals, rays[:,i:i+chunk], near, far, rand, True, N_samples)\n        if i==0:\n            rets = out\n        else:\n            rets = [np.concatenate([a, b], 0) for a, b in zip(rets, out)]\n    return rets","4bfc8d01":"class Model(hk.Module):\n    def __init__(self):\n        super().__init__()\n        self.width = 256\n        self.depth = 6\n        self.use_viewdirs = False\n                \n    def __call__(self, coords, view_dirs=None):\n        sh = coords.shape\n        if self.use_viewdirs:\n            viewdirs = None\n            viewdirs = np.repeat(viewdirs[...,None,:], coords.shape[-2], axis=-2)\n            viewdirs \/= np.linalg.norm(viewdirs, axis=-1, keepdims=True)\n            viewdirs = np.reshape(viewdirs, (-1,3))\n            viewdirs = hk.Linear(output_size=self.width\/\/2)(viewdirs)\n            viewdirs = jax.nn.relu(viewdirs)\n        coords = np.reshape(coords, [-1,3])\n        \n        # positional encoding\n        x = np.concatenate([np.concatenate([np.sin(coords*(2**i)), np.cos(coords*(2**i))], axis=-1) for i in np.linspace(0,8,20)], axis=-1)\n\n        for _ in range(self.depth-1):\n            x = hk.Linear(output_size=self.width)(x)\n            x = jax.nn.relu(x)\n            \n        if self.use_viewdirs:\n            density = hk.Linear(output_size=1)(x)\n            x = np.concatenate([x,viewdirs], axis=-1)\n            x = hk.Linear(output_size=self.width)(x)\n            x = jax.nn.relu(x)\n            rgb = hk.Linear(output_size=3)(x)\n            out = np.concatenate([density, rgb], axis=-1)\n        else:\n            out = hk.Linear(output_size=4)(x)\n        out = np.reshape(out, list(sh[:-1]) + [4])\n        return out","6af3b96f":"batch_size = 64\nN_samples = 128\ninner_step_size = 1\n\nmodel = hk.without_apply_rng(hk.transform(lambda x, y=None: Model()(x, y)))\n\nmse_fn = jit(lambda x, y: np.mean((x - y)**2))\npsnr_fn = jit(lambda x, y: -10 * np.log10(mse_fn(x, y)))\n\n@jit\ndef single_step(rng, image, rays, params, bds):\n    def sgd(param, update):\n        return param - inner_step_size * update\n    \n    rng, rng_inputs = jax.random.split(rng)\n    def loss_model(params):\n        g = render_rays(rng_inputs, model, params, None, rays, bds[0], bds[1], N_samples, rand=True)\n        return mse_fn(g, image)\n    \n    model_loss, grad = jax.value_and_grad(loss_model)(params)\n    new_params = jax.tree_multimap(sgd, params, grad)\n    return rng, new_params, model_loss\n\ndef update_network_weights(rng, images, rays, params, inner_steps, bds):\n    for _ in range(inner_steps):\n        rng, rng_input = random.split(rng)\n        idx = random.randint(rng_input, shape=(batch_size,), minval=0, maxval=images.shape[0])\n        image_sub = images[idx,:]\n        rays_sub = rays[:,idx,:]\n        \n        rng, params, loss = single_step(rng, image_sub, rays_sub, params, bds)\n    return rng, params, loss","e5d2ef25":"plt_groups = {'Train PSNR':[], 'Test PSNR':[]}\nplotlosses_model = PlotLosses(groups=plt_groups)","7afa4ad4":"max_iters = 150000\n\ninner_update_steps = 64\nlr = 5e-4\n\nexp_name = f'{DATASET}_ius_{inner_update_steps}_ilr_{inner_step_size}_olr_{lr}_bs_{batch_size}'\nexp_dir = f'checkpoint\/phototourism_checkpoints\/{exp_name}\/'\n\nif not os.path.exists(exp_dir):\n    os.makedirs(exp_dir)\n\nparams = model.init(rng, np.ones((1,3)))\n\nopt = optimizers.adam(lr)\nopt_state = opt.init_fun(params)\n\ntest_inner_steps = 64\n\n\ndef update_model(rng, params, opt_state, image, rays, bds):\n    rng, new_params, model_loss = update_network_weights(rng, image, rays, params, inner_update_steps, bds)\n    \n    def calc_grad(params, new_params):\n        return params - new_params\n    model_grad = jax.tree_multimap(calc_grad, params, new_params)\n    \n    updates, opt_state = opt.update(model_grad, opt_state)\n    params = optimizers.apply_updates(params, updates)\n    return rng, params, opt_state, model_loss\n\n@jit\ndef update_model_single(rng, params, opt_state, image, rays, bds):\n    rng, new_params, model_loss = single_step(rng, image, rays, params, bds)\n    \n    def calc_grad(params, new_params):\n        return params - new_params\n    model_grad = jax.tree_multimap(calc_grad, params, new_params)\n    \n    updates, opt_state = opt.update(model_grad, opt_state)\n    params = optimizers.apply_updates(params, updates)\n    return rng, params, opt_state, model_loss\n\n\n\nplt_groups['Train PSNR'].append(exp_name+f'_train')\nplt_groups['Test PSNR'].append(exp_name+f'_test')\nstep = 0\n\ntrain_psnrs = []\nrng = jax.random.PRNGKey(0)\n\ntrain_steps = []\ntrain_psnrs_all = []\ntest_steps = []\ntest_psnrs_all = []\nfor step in tqdm(range(max_iters)):\n    try:\n        rng, rng_input = jax.random.split(rng)\n        img_idx = random.randint(rng_input, shape=(), minval=0, maxval=len(imgfiles)-25)        \n        images, rays, bds = get_example(img_idx, downsample=1)\n    except:\n        print('data loading error')\n        raise\n        continue\n        \n\n    images = np.reshape(images, (-1,3))\n    rays = np.reshape(rays, (2,-1,3))\n\n    if inner_update_steps == 1:\n        rng, rng_input = random.split(rng)\n        idx = random.randint(rng_input, shape=(batch_size,), minval=0, maxval=images.shape[0])\n        rng, params, opt_state, loss = update_model_single(rng, params, opt_state, \n                                                           images[idx,:], rays[:,idx,:], bds)\n    else:\n        rng, params, opt_state, loss = update_model(rng, params, opt_state, \n                                                    images, rays, bds)\n    train_psnrs.append(-10 * np.log10(loss))\n    \n    # track model loss\n    if step % 250 == 0:\n        plotlosses_model.update({exp_name+'_train':np.mean(np.array(train_psnrs))}, current_step=step)\n        train_steps.append(step)\n        train_psnrs_all.append(np.mean(np.array(train_psnrs)))\n        train_psnrs = []\n        \n    # run validation\n    if step % 500 == 0 and step != 0:\n        test_psnr = []\n        for ti in range(5):\n            test_images, test_rays, bds = get_example(ti, split='val', downsample=2)\n\n            test_images, test_holdout_images = np.split(test_images, [test_images.shape[1]\/\/2], axis=1)\n            test_rays, test_holdout_rays = np.split(test_rays, [test_rays.shape[2]\/\/2], axis=2)\n\n            test_images_flat = np.reshape(test_images, (-1,3))\n            test_rays = np.reshape(test_rays, (2,-1,3))\n\n            rng, test_params, test_inner_loss = update_network_weights(rng, test_images_flat, test_rays, params, test_inner_steps, bds)\n\n            test_result = np.clip(render_fn(rng, model, test_params, None, test_holdout_rays, bds[0], bds[1], N_samples, rand=False)[0], 0, 1)\n            test_psnr.append(psnr_fn(test_holdout_images, test_result))\n        test_psnr = np.mean(np.array(test_psnr))\n\n        test_steps.append(step)\n        test_psnrs_all.append(test_psnr)\n        \n        plotlosses_model.update({exp_name+'_test':test_psnr}, current_step=step)\n        plotlosses_model.send()\n\n        plt.figure(figsize=(15,5))   \n        plt.subplot(1,3, 1)\n        plt.imshow(test_images)\n        plt.subplot(1,3, 2)\n        plt.imshow(test_holdout_images)\n        plt.subplot(1,3, 3)\n        plt.imshow(test_result)\n        plt.show()\n        \n    # save model checkpoint + render sample view on test set for model check\n    if step % 10000 == 0 and step != 0:\n        test_images, test_rays, bds = get_example(0, split='test')\n        test_images_flat = np.reshape(test_images, (-1,3))\n        test_rays = np.reshape(test_rays, (2,-1,3))\n        rng, test_params_1, test_inner_loss = update_network_weights(rng, test_images_flat, test_rays, params, test_inner_steps, bds)\n\n        test_images, test_rays, bds = get_example(1, split='test')\n        test_images_flat = np.reshape(test_images, (-1,3))\n        test_rays = np.reshape(test_rays, (2,-1,3))\n        rng, test_params_2, test_inner_loss = update_network_weights(rng, test_images_flat, test_rays, params, test_inner_steps, bds)\n        \n        poses = posedata['c2w_mats']\n        c2w = poses_avg(poses)\n        focal = .8\n        render_poses = render_path_spiral(c2w, c2w[:3,1], [.1, .1, .05], focal, zrate=.5, rots=2, N=120)\n        \n        bds = np.array([5., 25.]) * .05\n        H = 128\n        W = H*3\/\/2\n        f = H * 1.\n        kinv = np.array(\n            [1.\/f, 0, -W*.5\/f,\n             0, -1.\/f, H*.5\/f,\n             0, 0, -1.]\n        ).reshape([3,3])\n        i, j = np.meshgrid(np.arange(0,W), np.arange(0,H), indexing='xy')\n        renders = []\n        for p, c2w in enumerate(tqdm(render_poses)):\n            rays = get_rays(c2w, kinv, i, j)\n            interp = p \/ len(render_poses)\n            interp_params = jax.tree_multimap(lambda x, y: y*p\/len(render_poses) + x*(1-p\/len(render_poses)), test_params_1, test_params_2)\n            result = render_fn(rng, model, interp_params, None, rays, bds[0], bds[1], N_samples, rand=False)[0]\n            renders.append(result)\n        \n        renders = (np.clip(np.array(renders), 0, 1)*255).astype(np.uint8)\n        imageio.mimwrite(f'{exp_dir}render_sprial_{step}.mp4', renders, fps=30, quality=8)\n        \n        plt.plot(train_steps, train_psnrs_all)\n        plt.savefig(f'{exp_dir}train_curve_{step}.png')\n        \n        plt.plot(test_steps, test_psnrs_all)\n        plt.savefig(f'{exp_dir}test_curve_{step}.png')\n        \n        with open(f'{exp_dir}checkpount_{step}.pkl', 'wb') as file:\n            pickle.dump(params, file)","20f94778":"from flax import linen as nn","c7750f8f":"nn.Dense?","81fe043c":"class ModelFlax(nn.Module):\n    width = 256\n    depth = 6\n    \n    @nn.compact\n    def __call__(self, coords):\n        sh = coords.shape\n        coords = np.reshape(coords, [-1,3])\n        \n        # positional encoding\n        x = np.concatenate([np.concatenate([np.sin(coords*(2**i)), np.cos(coords*(2**i))], axis=-1) for i in np.linspace(0,8,20)], axis=-1)\n\n        for idx in range(self.depth-1):\n            #x = hk.Linear(output_size=self.width)(x)\n            x = nn.Dense(self.depth, name=f'fc{idx}')(x)\n            x = nn.relu(x)\n\n        #out = hk.Linear(output_size=4)(x)\n        out = nn.Dense(4, name='fc_last')(x)\n        out = np.reshape(out, list(sh[:-1]) + [4])\n        return out","85864c00":"model = ModelFlax()\nkey1, key2 = random.split(jax.random.PRNGKey(0))\ndummy_x = random.normal(key1, (1, 3))\nparams = model.init(key2, dummy_x)","946dafbb":"dummy_x = \nModelFlax.init","2aaeb8f9":"model = hk.without_apply_rng(hk.transform(lambda x, y=None: ModelHaiku()(x, y)))\nparams = model.init(rng, np.ones((1,3)))\n","0ba82315":"class ModelHaiku(hk.Module):\n    def __init__(self):\n        super().__init__()\n        self.width = 256\n        self.depth = 6\n                \n    def __call__(self, coords):\n        sh = coords.shape\n        coords = np.reshape(coords, [-1,3])\n        \n        # positional encoding\n        x = np.concatenate([np.concatenate([np.sin(coords*(2**i)), np.cos(coords*(2**i))], axis=-1) for i in np.linspace(0,8,20)], axis=-1)\n\n        for _ in range(self.depth-1):\n            x = hk.Linear(output_size=self.width)(x)\n            x = jax.nn.relu(x)\n\n        out = hk.Linear(output_size=4)(x)\n        out = np.reshape(out, list(sh[:-1]) + [4])\n        return out","36310d69":"## OLD JAX + HAIKU\ndef single_step(rng, image, rays, params, bds):\n    def sgd(param, update):\n        return param - inner_step_size * update\n    \n    rng, rng_inputs = jax.random.split(rng)\n    def loss_model(params):\n        g = render_rays(rng_inputs, model, params, None, rays, bds[0], bds[1], N_samples, rand=True)\n        return mse_fn(g, image)\n    \n    model_loss, grad = jax.value_and_grad(loss_model)(params)\n    new_params = jax.tree_multimap(sgd, params, grad)\n    return rng, new_params, model_loss\n\n\nmodel = hk.without_apply_rng(hk.transform(lambda x, y=None: ModelHaiku()(x, y)))\nparams = model.init(rng, np.ones((1,3)))\nopt = optimizers.adam(lr)\nopt_state = opt.init_fun(params)\nupdates, opt_state = opt.update(model_grad, opt_state)\nparams = optimizers.apply_updates(params, updates)","32340b45":"## NEW JAX + HAIKU\nlr = 1e-3\nnum_steps = 3\n\nmodel = hk.without_apply_rng(hk.transform(lambda x: ModelHaiku()(x)))\nparams = model.init(rng, np.ones((1,3)))\nopt_init, opt_update, get_params = optimizers.adam(lr)\nopt_state = opt_init(params)\n\n\ndef single_step_v2(step, rng, image, rays, bds, opt_state):\n    def loss_model(params):\n        g = render_rays(rng_inputs, model, params,\n                        None, rays, bds[0], bds[1], \n                        N_samples, rand=True)\n        return mse_fn(g, image)\n    rng, rng_inputs = jax.random.split(rng)\n    value, grads = jax.value_and_grad(loss_model)(get_params(opt_state))\n    opt_state = opt_update(step, grads, opt_state)\n    return value, opt_state","5e7b3444":"rng = jax.random.PRNGKey(0)\n\nfor istep in range(num_steps):\n    rng, rng_input = jax.random.split(rng)\n    img_idx = random.randint(rng_input, shape=(), minval=0, maxval=len(imgfiles)-25)\n    images, rays, bds = get_example(img_idx, downsample=1)\n    images = np.reshape(images, (-1,3))\n    rays = np.reshape(rays, (2,-1,3))\n    rng, rng_input = random.split(rng)\n    idx = random.randint(rng_input, shape=(batch_size,), minval=0, maxval=images.shape[0])\n    loss, opt_state = single_step_v2(istep, rng, images[idx,:], rays[:,idx,:], bds, opt_state)","b331106d":"## NEW JAX + FLAX!\nlr = 1e-3\nnum_steps = 3\n\n# model = hk.without_apply_rng(hk.transform(lambda x: ModelHaiku()(x)))\n# params = model.init(rng, np.ones((1,3)))\n\nmodel = ModelFlax()\nkey1, key2 = random.split(jax.random.PRNGKey(0))\ndummy_x = random.normal(key1, (1, 3))\nparams = model.init(key2, dummy_x)\n\nopt_init, opt_update, get_params = optimizers.adam(lr)\nopt_state = opt_init(params)\n\n\ndef single_step_v2(step, rng, image, rays, bds, opt_state):\n    def loss_model(params):\n        g = render_rays(rng_inputs, model, params,\n                        None, rays, bds[0], bds[1], \n                        N_samples, rand=True)\n        return mse_fn(g, image)\n    rng, rng_inputs = jax.random.split(rng)\n    value, grads = jax.value_and_grad(loss_model)(get_params(opt_state))\n    opt_state = opt_update(step, grads, opt_state)\n    return value, opt_state","ebf7d4da":"opt_state","cfe1d096":"rng = jax.random.PRNGKey(0)\n\nfor istep in range(num_steps):\n    rng, rng_input = jax.random.split(rng)\n    img_idx = random.randint(rng_input, shape=(), minval=0, maxval=len(imgfiles)-25)\n    images, rays, bds = get_example(img_idx, downsample=1)\n    images = np.reshape(images, (-1,3))\n    rays = np.reshape(rays, (2,-1,3))\n    rng, rng_input = random.split(rng)\n    idx = random.randint(rng_input, shape=(batch_size,), minval=0, maxval=images.shape[0])\n    loss, opt_state = single_step_v2(istep, rng, images[idx,:], rays[:,idx,:], bds, opt_state)","22f485f5":"opt_state","1e6c6862":"# access param by layer name\nget_params(opt_state)['params']['fc0']","ac376990":"model.get_variable(name='fc_last')","5467ec20":"### 4. Training Loop","4c5e02f2":"### 1. Helper Functions for Loading Data","824ac5f8":"## THINGS TO DO??\n\n### Existing NeRF\n1. Rewrite the model into FLAX (otherwise cant work with Flax-CLIP?) (Haiku seems like functional, but Flax is OOP?)\n2. Rewrite training loop into FLAX (does FLAX provide abstraction for writing training loop?? current training loop is pretty low-level)\n3. Refactor the notebook code --> module code\n    - render scene, visualizing, animation ... etc.\n4. Dataloading for our concerned dataset\n5. consolidate all controllabe params in a class (e.g. `Config`)\n\n\n### NeRF --> DietNeRF\n1. Change sampling to 8 samples only\n2. Add CLIP into the training loop for a new loss function\n3. Check if DietNeRF can get comparable result to NeRF\n\n### Optional?\n1. Understand what the hell each operations are doing? (e.g. `get_rays` ... etc)\n2. Add W&B for visualization?\n3. Super large scale NeRF(ssssss) training --> get huge samples of scene for POC\n4. Optimize bottleneck operations by `jax.vmap`, `jax.pmap`","cc4365fd":"### 2. NeRF Renderer","8e340fd6":"### 1. PLAYGROUND\n- optimizers API: https:\/\/jax.readthedocs.io\/en\/latest\/_modules\/jax\/experimental\/optimizers.html#adam","fb5e488c":"### 3. NeRF Model Architecture"}}