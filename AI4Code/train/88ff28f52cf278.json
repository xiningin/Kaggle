{"cell_type":{"38307ab3":"code","8da5d9d9":"code","e947e362":"code","d0a3b00f":"code","02f96c1d":"code","84644ac5":"code","19c71690":"code","b57c82b7":"code","9b6bdbcf":"code","f671955f":"code","56dbabd3":"code","31163fb3":"code","1eca5b30":"code","bfef96be":"code","88f23ffa":"code","1dc53c22":"code","67db7f57":"code","037bc2a3":"code","c5e707ce":"code","29a4d1a6":"code","85c73fa6":"code","ecb5970a":"code","6f9768fb":"code","1a02b5fb":"code","b6bb802b":"code","ebf253fb":"code","b5e78ccd":"markdown","b3d3f2cf":"markdown","a3bbd9cc":"markdown","63d84e17":"markdown","58ce55a8":"markdown","a1e88966":"markdown","86bb21e7":"markdown","61659035":"markdown","58b9b7db":"markdown","96fdb6a3":"markdown"},"source":{"38307ab3":"# Importing basic libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Importing the Titanic dataset\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8da5d9d9":"train_file_path = '\/kaggle\/input\/titanic\/train.csv'\ntrain_data = pd.read_csv(train_file_path)\ntest_file_path = '\/kaggle\/input\/titanic\/test.csv'\ntest_data = pd.read_csv(test_file_path)","e947e362":"train_data.head()","d0a3b00f":"train_data.dtypes","02f96c1d":"train_data[train_data.columns[1:]].corr()['Survived'][:]","84644ac5":"train_data.info()\nprint(\"-\"*100)\ntest_data.info()","19c71690":"print(train_data['Age'].describe())\nprint(\"-\"*100)\nprint(train_data['Fare'].describe())","b57c82b7":"import seaborn as sns","9b6bdbcf":"#Percentage of factor of each feature on the chances of survival","f671955f":"datasets = [train_data, test_data]","56dbabd3":"train_data.dropna(subset = [\"Embarked\"], inplace=True)","31163fb3":"for dataset in datasets:\n    dataset['Family Members'] = dataset['SibSp'] + dataset['Parch'] + 1","1eca5b30":"for dataset in datasets:\n    dataset['Boarded Alone'] = 0\n    dataset.loc[dataset['Family Members'] == 1, 'Boarded Alone'] = 1","bfef96be":"for dataset in datasets:\n    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].mean())\n    dataset['Categorical Fare'] = pd.qcut(dataset['Fare'], 4)\n    dataset['Age'] = dataset['Age'].fillna(dataset['Age'].mean())\n    dataset['Categorical Age'] = pd.qcut(dataset['Age'], 4)","88f23ffa":"def edit_cabin(dataset):\n    dataset[\"Cabin\"] = dataset[\"Cabin\"].fillna(\"Suite\")\n    dataset.loc[~dataset[\"Cabin\"].isin([\"Suite\"]), \"Cabin\"] = \"Regular\"\n    return dataset\n\ntrain_data = edit_cabin(train_data)\ntest_data = edit_cabin(test_data)","1dc53c22":"train_data.info()","67db7f57":"import re as re\n\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor dataset in datasets:\n    dataset['Title'] = dataset['Name'].apply(get_title)","037bc2a3":"train_data.info()","c5e707ce":"y_train = train_data['Survived']\nX_train = train_data.drop(['Survived', 'Name', 'Ticket', 'PassengerId', 'Age', 'Fare', 'SibSp', 'Parch'], axis=1)\nX_valid = test_data.drop(['Name', 'Ticket', 'PassengerId', 'Age', 'Fare', 'SibSp', 'Parch'], axis=1)","29a4d1a6":"X_train.head()","85c73fa6":"categorical_cols = [\"Sex\", \"Embarked\", \"Cabin\", \"Categorical Fare\", \"Categorical Age\", \"Title\"]","ecb5970a":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder","6f9768fb":"categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, categorical_cols)\n    ])","1a02b5fb":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=0)\n\nrf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\nrf_pipeline.fit(X_train, y_train)","b6bb802b":"submission = rf_pipeline.predict(X_valid)","ebf253fb":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': submission})\noutput.to_csv('lester_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","b5e78ccd":"# Prediction with Ensemble Learning and Stacking","b3d3f2cf":"# Data Preprocessing\n#Age: Simple Imputer\n#Sex, Embarked, Room Type: One Hot Encode\n#Remove two rows where embarked is empty\n#Cabin, or suite: If null, suite, else cabin","a3bbd9cc":"A general sense of the data is acquired. From the information above, the following can be inferred.\n* The categorical values of Sex, the type of Room (Cabin or Suite), and place of Embarkment can be encoded using the One Hot Encoder. \n* Due to the huge difference in range, numerical values such as the passenger's age and ticket fare can be normalized converted to categorical values. \n* Other numerical values such as the passenger's class and the number of family members can be left as is since it can act as Label Encoded values.\n* Features such as the Name and the Ticket Number can be dropped from the data set as these have unique values.","63d84e17":"From the first few rows of the dataset, it could be possible to create a separate column on the number of family members that the passenger was on board with from the SibSp and Parch columns, as family members tend to stick together (whether surviving or not).\n\nDepending on the values of the Ticket Number and Title of the Name, there could also be a possibility to use these as another categorical column.","58ce55a8":"Categorical Columns are the Name, Sex, Ticket Number, Cabin Type, and Place of Embarkment.\n\nNumerical Columns are the Class, Age, ","a1e88966":"With 891 entries, the Age, Cabin Type, and Place of Embarkment have missing values. \n\nSince the place of embarkment has only two missing values, these rows can be dropped. However, the Age column can be filled in by Feature Engineering. \n\nMoreover, the Titanic was said to hold passengers in rooms that had three different classes of cabins. Otherwise, the passenger was placed in a First Class Suite. The empty values in the Cabin column could probably infer that the passenger was placed in a Suite.","86bb21e7":"# Data Visualization\nSection is currently in progress","61659035":"# Introduction\nFor this dataset, we try to explore the possibility of one surviving the Titanic. This activity is practically just to get our hands dirty and get an idea on how Kaggle works, and how to join competitions.","58b9b7db":"# Competition Submission","96fdb6a3":"# Dataset Analysis\nTo get an idea on what preprocessing techniques can be done, it is important to see first the information that the dataset contains. \nSome of the things that one usually looks for here are (but not limited to): \n* Possibilities for Feature Engineering\n* Features are numerical and categorical\n* Unique values in categorical columns\n* Columns that have missing values\n* Correlation of each feature with the survival prediction"}}