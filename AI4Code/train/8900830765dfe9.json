{"cell_type":{"5232c8db":"code","19597b7b":"code","90e2b4b3":"code","83e342f1":"code","5fd4e860":"code","2639c3dc":"code","cf8cbd54":"code","75da626d":"code","7e2ed368":"code","9307a222":"code","4cab1180":"code","6b75c6f3":"code","d581e45b":"code","9564831e":"code","ef8f3305":"code","729dca38":"code","ded4cbe4":"code","f38230f7":"code","3bd6a647":"code","a9fc36db":"code","d0b3b9eb":"code","0b30cc69":"code","3c4a9696":"code","243adff8":"code","eec272ac":"code","01cfcfb2":"code","752d6458":"code","c79453c0":"code","5b7e4474":"code","3b0aa251":"code","8214b61e":"code","4286c73a":"code","68009788":"code","67433ee5":"code","4d952ec4":"code","34114390":"code","58319771":"code","dcdcd2e7":"code","4f2d8fa2":"code","76ec3393":"code","00a26bf4":"code","52b6900a":"code","dff12d79":"code","e914015b":"code","dd8cdba3":"code","3b8b67ff":"code","3e280736":"code","3db72791":"code","479469eb":"code","d7cadd4b":"code","ce01be93":"code","61a07180":"code","a5095047":"code","cdb957ef":"code","45fe1752":"code","af51ba4e":"code","5c0356cb":"code","482e1a72":"code","1e6d7a3c":"code","d6197a79":"code","e330d944":"code","c07aa92b":"code","a49c3768":"code","99513ad1":"code","7b655f17":"code","18ca1865":"code","92abf7e9":"code","1cdc3cb9":"code","e23f9588":"code","002ed171":"code","a19e776f":"code","4e4b1d14":"code","a4630db4":"code","f84aa731":"code","2c8f9098":"code","79319e65":"code","89375e49":"code","43aeb5bc":"code","bfc71bba":"code","307315ef":"code","62d99a9b":"code","d60f6f03":"code","90b0916a":"code","0df39277":"code","876a6c86":"code","d4e0db4f":"code","066277fe":"code","684ab686":"code","207a3e51":"code","25ba5f60":"code","5f892f14":"code","f2ae979a":"code","e7999408":"code","af2b5bd8":"code","20844ad9":"code","a8490a7d":"code","bcab2555":"code","42d10e82":"code","76dce8cd":"code","fa03266a":"code","1dc684ac":"code","8955f82e":"code","7b3e987e":"code","e81544f1":"code","c69d96ef":"code","f0c1a073":"code","99359570":"code","20b2a1dc":"code","4bb90575":"code","d5f6c3b2":"code","1f6640e4":"code","59e49539":"code","ab366477":"code","05407d90":"code","ab3b2f9e":"code","edb33f1c":"code","01ad1518":"code","fdc1ccf6":"code","8e8e8a3b":"code","331da24e":"code","fd25e5b1":"code","4f511834":"code","ab6af0fd":"code","d8b59937":"code","d0c7f5da":"code","cfd332b7":"code","e973e8ab":"code","66d34103":"code","acaa02f1":"code","4f6f6689":"code","92bd25a6":"code","e3ef6571":"code","e5abdc6f":"code","badd268d":"code","91349717":"code","2eb5fb1f":"markdown","3c3ded7e":"markdown","c8de98aa":"markdown","ba9be74b":"markdown","d54b0eca":"markdown","acd19094":"markdown"},"source":{"5232c8db":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","19597b7b":"\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom pandas import Series,DataFrame\nfrom pylab import rcParams\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn import metrics\n%matplotlib inline\n\nimport os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#import seaborn as sns\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","90e2b4b3":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv',)\ncombined = [train_data,test_data]\ntrain_data.head()\n","83e342f1":"test_data.head()","5fd4e860":"train_data.columns.tolist()\n","2639c3dc":"train_data.shape","cf8cbd54":"train_data.Parch.value_counts()\n\n","75da626d":"train_data.Embarked.value_counts()\n","7e2ed368":"train_data.groupby('Survived').mean()\n","9307a222":"train_data.groupby(['Pclass']).mean()\n","4cab1180":"train_data.groupby('Pclass')['Survived'].value_counts()\n","6b75c6f3":"train_data.groupby('Sex')['Survived'].value_counts()\n","d581e45b":"train_data.groupby('Parch')['Survived'].value_counts()\n","9564831e":"train_data.shape","ef8f3305":"train_data.groupby('Embarked')['Survived'].value_counts()\n","729dca38":"#Seeing Correlation between the column items and its values","ded4cbe4":"train_data.corr()","f38230f7":"from string import ascii_letters\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(style=\"white\")\n\n# Generate a large random dataset\nrs = np.random.RandomState(33)\nd = pd.DataFrame(data=rs.normal(size=(100, 26)),\n                 columns=list(ascii_letters[26:]))\n\n# Compute the correlation matrix\ncorr = train_data.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\nplt.show()","3bd6a647":"train_data.info()\n","a9fc36db":"train_data.Cabin.head()","d0b3b9eb":"train_data.Cabin.isnull().value_counts()\n","0b30cc69":"train_data.Pclass.isnull().value_counts()\n","3c4a9696":"pd.crosstab(train_data['Pclass'],train_data['Survived'].astype(bool)).plot(kind='bar')\nplt.show()","243adff8":"pd.crosstab(train_data['Sex'],train_data['Survived'].astype(bool)).plot(kind='bar')\nplt.show()","eec272ac":"#Creating a factorplot, charting the number of male and female passengers\nsns.factorplot('Sex',data=train_data,kind='count')\nplt.show()","01cfcfb2":"pd.crosstab(train_data['Embarked'],train_data['Survived'].astype(bool)).plot(kind='bar')\nplt.show()\n","752d6458":"train_data.groupby('Embarked')['Survived'].value_counts()\n","c79453c0":"    \nsns.factorplot('Pclass',data=train_data,hue='Sex',kind='count')\nplt.show()","5b7e4474":"#Function to detect if a person is a man, woman or child.\ndef man_wom_chi(passenger):\n    age=passenger['Age']\n    sex=passenger['Sex']\n    \n    return 'child' if age < 16 else sex\n\n#Using Pandas' apply method to create a new column \"Person\"\ntrain_data['Person'] = train_data.apply(man_wom_chi,axis=1)\ntrain_data.groupby('Person')['Survived'].value_counts()\n","3b0aa251":"train_data.groupby('Person')['Survived'].value_counts()\n","8214b61e":"sns.factorplot('Pclass',data=train_data,hue='Person',kind='count')\n","4286c73a":"def man_wom_chi(passenger):\n    age=passenger['Age']\n    sex=passenger['Sex']\n    \n    return 'child' if age < 16 else sex\n\n#Using Pandas' apply method to create a new column \"Person\"\ntest_data['Person'] = test_data.apply(man_wom_chi,axis=1)","68009788":"#Adding the number of family a passenger had onboard\ntrain_data['Alone'] = train_data.SibSp + train_data.Parch\ntest_data['Alone'] = test_data.SibSp + test_data.Parch","67433ee5":"train_data['Alone'].loc[train_data['Alone']>0] = 'No'\n\ntrain_data['Alone'].loc[train_data['Alone']==0] = 'Yes'\n\n\n","4d952ec4":"test_data['Alone'].loc[test_data['Alone']>0] = 'No'\n\ntest_data['Alone'].loc[test_data['Alone']==0] = 'Yes'","34114390":"train_data.head()\n","58319771":"test_data.head()","dcdcd2e7":"sns.factorplot('Pclass',data=train_data,hue='Alone',kind='count')\n","4f2d8fa2":"sns.factorplot('Alone','Survived',data=train_data)\n","76ec3393":"sns.factorplot('Pclass','Survived',hue='Person',data=train_data)\n","00a26bf4":"train_data.drop(['Name','Cabin'],axis=1,inplace=True)\ntest_data.drop(['Name','Cabin'],axis=1,inplace=True)","52b6900a":"train_data.isnull().count()","dff12d79":"#def normalize(train_):\n#    result = df.copy()\n#    for feature_name in df.columns:\n#        max_value = df[feature_name].max()\n#        min_value = df[feature_name].min()\n#        result[feature_name] = (df[feature_name] - min_value) \/ (max_value - min_value)\n#    return result","e914015b":"#test_data[\"Age\"]=((test_data[\"Age\"]-test_data[\"Age\"].min())\/(test_data[\"Age\"].max()-test_data[\"Age\"].min()))","dd8cdba3":"#test_data[\"Fare\"]=((test_data[\"Fare\"]-test_data[\"Fare\"].min())\/(test_data[\"Fare\"].max()-test_data[\"Fare\"].min()))","3b8b67ff":"#train_data[\"Age\"]=((train_data[\"Age\"]-train_data[\"Age\"].min())\/(train_data[\"Age\"].max()-train_data[\"Age\"].min()))","3e280736":"train_data.head()","3db72791":"#train_data[\"Fare\"]=((train_data[\"Fare\"]-train_data[\"Fare\"].min())\/(train_data[\"Fare\"].max()-train_data[\"Fare\"].min()))","479469eb":"\nY=train_data['Survived']\n","d7cadd4b":"Y.head()\n","ce01be93":"\nPclass_dummies=pd.get_dummies(train_data.Pclass,prefix='Pclass').iloc[:,:]\ntrain_data=pd.concat([train_data,Pclass_dummies],axis=1)","61a07180":"\nPclass_dummies=pd.get_dummies(test_data.Pclass,prefix='Pclass').iloc[:,:]\ntest_data=pd.concat([test_data,Pclass_dummies],axis=1)","a5095047":"train_data.head()","cdb957ef":"test_data.head()","45fe1752":"train_data.shape","af51ba4e":"Person_dummies=pd.get_dummies(train_data.Person,prefix='Person').iloc[:,:]\ntrain_data=pd.concat([train_data,Person_dummies],axis=1)","5c0356cb":"train_data.head()\n","482e1a72":"Person_dummies=pd.get_dummies(test_data.Person,prefix='Person').iloc[:,:]\ntest_data=pd.concat([test_data,Person_dummies],axis=1)\ntest_data.head()","1e6d7a3c":"Embarked_dummies=pd.get_dummies(train_data.Embarked,prefix='Embarked').iloc[:,:]\ntrain_data=pd.concat([train_data,Embarked_dummies],axis=1)","d6197a79":"train_data.head()","e330d944":"Embarked_dummies=pd.get_dummies(test_data.Embarked,prefix='Embarked').iloc[:,:]\ntest_data=pd.concat([test_data,Embarked_dummies],axis=1)","c07aa92b":"test_data.head()","a49c3768":"Alone_dummies=pd.get_dummies(train_data.Alone,prefix='Alone').iloc[:,1:]\ntrain_data=pd.concat([train_data,Alone_dummies],axis=1)\n","99513ad1":"train_data.head()","7b655f17":"Alone_dummies=pd.get_dummies(test_data.Alone,prefix='Alone').iloc[:,1:]\ntest_data=pd.concat([test_data,Alone_dummies],axis=1)","18ca1865":"test_data.head()","92abf7e9":"train_data.drop(['Ticket'],axis=1,inplace=True)\ntest_data.drop(['Ticket'],axis=1,inplace=True)","1cdc3cb9":"train_data.head()\n","e23f9588":"test_data.head()","002ed171":"train_data.columns.tolist()\n","a19e776f":"train_data.shape","4e4b1d14":"test_data.shape","a4630db4":"#SibSp_dummies=pd.get_dummies(train_data.SibSp,prefix='SibSp').iloc[:,:]\n#train_data=pd.concat([train_data,SibSp_dummies],axis=1)","f84aa731":"#SibSp_dummies=pd.get_dummies(test_data.SibSp,prefix='SibSp').iloc[:,:]\n#test_data=pd.concat([test_data,SibSp_dummies],axis=1)","2c8f9098":"train_data['Parch'].value_counts()\n","79319e65":"Parch_dummies=pd.get_dummies(train_data.Parch,prefix='Parch').iloc[:,:]\ntrain_data=pd.concat([train_data,Parch_dummies],axis=1)","89375e49":"Parch_dummies=pd.get_dummies(test_data.Parch,prefix='Parch').iloc[:,:]\ntest_data=pd.concat([test_data,Parch_dummies],axis=1)","43aeb5bc":"test_data['Parch'].value_counts()\n","bfc71bba":"train_data.head()","307315ef":"test_data.head()","62d99a9b":"train_data.drop(['Pclass','Parch','Embarked','Person','Alone'],axis=1,inplace=True)\ntest_data.drop(['Pclass','Parch','Embarked','Person','Alone'],axis=1,inplace=True)\n","d60f6f03":"Sex_dummies=pd.get_dummies(train_data.Sex,prefix='Sex').iloc[:,1:]\ntrain_data=pd.concat([train_data,Sex_dummies],axis=1)","90b0916a":"Sex_dummies=pd.get_dummies(test_data.Sex,prefix='Sex').iloc[:,1:]\ntest_data=pd.concat([test_data,Sex_dummies],axis=1)","0df39277":"train_data.drop(['PassengerId','Sex'],axis=1,inplace=True)\no=[]\no=test_data['PassengerId'] \n\ntest_data.drop(['PassengerId','Sex'],axis=1,inplace=True)\n","876a6c86":"train_data.head()","d4e0db4f":"test_data.head()","066277fe":"from sklearn import tree, metrics, model_selection, preprocessing\nfrom IPython.display import Image, display","684ab686":"train_data.drop(['Survived'],axis=1,inplace=True)\n","207a3e51":"train_data.columns.tolist()\n","25ba5f60":"test_data.columns.tolist()\n","5f892f14":"\ntrain_data['Fare']=train_data['Fare'].apply(np.ceil)\n","f2ae979a":"test_data['Fare']=test_data['Fare'].apply(np.ceil)","e7999408":"train_data.drop(['Age','Person_child','Parch_4','Parch_5','Parch_6','Person_female','Person_male'],axis=1,inplace=True)","af2b5bd8":"test_data.drop(['Age','Person_child','Parch_4','Parch_5','Parch_6','Parch_9','Person_female','Person_male'],axis=1,inplace=True)\n","20844ad9":"train_data.head()","a8490a7d":"train_data['Fare'] = train_data['Fare'].astype(int) \n#test_data['Fare'] = test_data['Fare'].astype(int)","bcab2555":"test_data['Fare']=test_data['Fare'].fillna(2)\ntest_data['Fare'].isnull().value_counts()","42d10e82":"#train_data['Age'].isnull().value_counts()","76dce8cd":"#train_data['Age'] = train_data['Age'].astype(int) \n#test_data['Age']=test_data['Age'].astype(int)\n","fa03266a":"#test_.fillna(0) \n\ntest_data['Fare'] = test_data['Fare'].astype(int)\n","1dc684ac":"test_data['Fare']=test_data['Fare'].fillna(2)\ntest_data['Fare'].isnull().value_counts()","8955f82e":"train_data.head()","7b3e987e":"train_data.shape","e81544f1":"test_data.shape","c69d96ef":"X = train_data\n\n","f0c1a073":"# split data randomly into 70% training and 30% test\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.05, random_state=0)","99359570":"from sklearn import svm","20b2a1dc":"train_data","4bb90575":"svc = svm.SVC(kernel='poly', C=1).fit(X_train, Y_train)\n","d5f6c3b2":"dtree=tree.DecisionTreeClassifier(criterion='entropy',max_depth=7,random_state=0)\ndtree.fit(X_train,Y_train)","1f6640e4":"y_pred=dtree.predict(X_test)\nimport sklearn.metrics\nfrom sklearn.metrics import accuracy_score","59e49539":"count_misclassified=(Y_test != y_pred)\nprint('Misclassified_samples:{}'.format(count_misclassified))\naccuracy=metrics.accuracy_score(Y_test,y_pred)\nprint('Accuracy:{:.2f}'.format(accuracy))","ab366477":"import sklearn.metrics","05407d90":"sklearn.metrics.confusion_matrix(Y_test,y_pred)\n","ab3b2f9e":"\nfrom sklearn.model_selection import cross_val_score\nscores=cross_val_score(estimator=dtree,\n                      X=X,\n                      y=Y,\n                      scoring='accuracy',\n                      cv=10)\n\nprint('accuracy per fold')\nprint(scores)\nprint('average_accuarcy:',scores.mean())","edb33f1c":"test_data.head()","01ad1518":"\nfrom xgboost import XGBClassifier\n","fdc1ccf6":"\nm2=XGBClassifier(n_estimator=16)\nm2.fit(X_train,Y_train)\nprint(accuracy_score(Y_test,m2.predict(X_test)))\n","8e8e8a3b":"\n## checking with AdaBOOSTClassifier\nimport pandas\nfrom sklearn import model_selection\nfrom sklearn.ensemble import AdaBoostClassifier\nseed =7\nnum_trees= 20\nkfold = model_selection.KFold(n_splits=10,random_state=seed)\nmodel= AdaBoostClassifier(n_estimators=num_trees,random_state=seed)\nresults = model_selection.cross_val_score(model,X,Y,cv=kfold)\nprint(results.mean())","331da24e":"# Checking with Gradient Boost Classifier\n\nimport pandas\nfrom sklearn import model_selection\nfrom sklearn.ensemble import GradientBoostingClassifier\nseed =7\nnum_trees= 100\nkfold = model_selection.KFold(n_splits=10,random_state=seed)\nmodel_GB= GradientBoostingClassifier(n_estimators=num_trees,random_state=seed)\nresults = model_selection.cross_val_score(model,X,Y,cv=kfold)\nprint(results.mean())\nmodel_GB.fit(X_train, Y_train)\n","fd25e5b1":"SEED=42\ncross_valid_scores = {}\n\nfrom sklearn.ensemble import RandomForestClassifier\nparameters = {\n    \"n_estimators\": [25,23],\n    \"max_depth\": [5,7,10]\n}\nfrom sklearn.ensemble import RandomForestClassifier\nmodel_random_forest = RandomForestClassifier(\n    random_state=SEED,\n    class_weight='balanced',\n)\n\nmodel_random_forest = GridSearchCV(\n   model_random_forest, \n    parameters, \n   cv=5,\n    scoring='accuracy',\n)\n\nmodel_random_forest.fit(X_train, Y_train)\n\nprint('-----')\nprint(f'Best parameters {model_random_forest.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_random_forest.best_score_:.3f}'\n)\ncross_valid_scores['random_forest'] = model_random_forest.best_score_\nprint('-----')","4f511834":"def set_seed(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n    \n\nSEED = 44\nset_seed(SEED)\nimport xgboost as xgb\nparameters = {\n    'max_depth':  [7, 10,15,20],\n    'n_estimators': [16,4,20,25,40],\n    'learning_rate': [0.05,0.01,.005]\n}\n\nmodel_xgb = xgb.XGBClassifier(\n    random_state=SEED,\n)\n\nmodel_xgb = GridSearchCV(\n   model_xgb, \n   parameters, \n    cv=5,\n   scoring='accuracy',\n)\n\nmodel_xgb.fit(X_train, Y_train)\n\nprint('-----')\nprint(f'Best parameters {model_xgb.best_params_}')\n#print( f'Mean cross-validated accuracy score of the best_estimator: ' + 3   f'{model_xgb.best_score_:.3 f}'cross_valid_scores['xgboost'] = model_xgb.best_score_)\nprint('-----')","ab6af0fd":"train_data","d8b59937":"pd.DataFrame(cross_valid_scores, index=['cross_valid_score']).T\n","d0c7f5da":"test_data.head()","cfd332b7":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=40,n_jobs=1,max_depth=7)\nclf.fit(X_train, Y_train)\n","e973e8ab":"\nmodel=LogisticRegression()\nmodel=model.fit(X_train,Y_train)","66d34103":"#from sklearn.neighbors import KNeighborsClassifier\n\n#model = KNeighborsClassifier(n_neighbors=5)\n\n# Train the model using the training sets\n#model.fit(X_train,Y_train\n#         )\n","acaa02f1":"test_data.drop(['PassengerId'],axis=1,inplace=True)\npreds = svc.predict(test_data)\n#preds = preds.astype(np.int16)","4f6f6689":"preds = preds.astype(np.int16)\ntest_data['PassengerId'] = o\nsubmission = pd.DataFrame(\n        {\n            'PassengerId': test_data[\"PassengerId\"], \n            'Survived': preds\n        }\n    )\nsubmission.to_csv(f\"submission_svc_2.csv\", index=False)\n    \n","92bd25a6":"submission.shape","e3ef6571":"m2=XGBClassifier(n_estimator=44,max_depth=7)\nm2.fit(X_train,Y_train)\nprint(accuracy_score(Y_test,m2.predict(X_test)))","e5abdc6f":"from sklearn.ensemble import RandomForestClassifier\n","badd268d":"clf = RandomForestClassifier(n_estimators=77,n_jobs=1,max_depth=7)\n","91349717":"clf.fit(X_train, Y_train)\n","2eb5fb1f":"X = train_data","3c3ded7e":"stock = np.array(train_data)\n\nopeningPrice = stock[:, 1]\nclosingPrice = stock[:, 5]\n\nopeningPriceTrain, openingPriceTest, closingPriceTrain, closingPriceTest = \\\n    train_test_split(openingPrice, closingPrice, test_size=0.25, random_state=42)\n\nopeningPriceTrain = openingPriceTrain.reshape(openingPriceTrain.size,1)\nopeningPriceTrain = openingPriceTrain.astype(np.float64, copy=False)\n\nclosingPriceTrain = closingPriceTrain.reshape(closingPriceTrain.size,1)\nclosingPriceTrain = closingPriceTrain.astype(np.float64, copy=False)\n\nopeningPriceTest = openingPriceTest.reshape(openingPriceTest.size,1)\nopeningPriceTest = openingPriceTest.astype(np.float64, copy=False)\n\nnp.isnan(openingPriceTrain).any(), np.isnan(closingPriceTrain).any(), np.isnan(openingPriceTest).any()\n\n","c8de98aa":"# Model Training","ba9be74b":"# Data cleaning","d54b0eca":"# Visualizing Correlation between the column items and its values","acd19094":"#  Data Exploration"}}