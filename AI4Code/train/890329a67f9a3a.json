{"cell_type":{"d33a83c4":"code","e183406c":"code","4e44fee2":"code","c79448a5":"code","d0a58716":"code","99e17d5d":"code","16a3a552":"code","85c4440d":"code","3372a8f9":"code","b8969666":"code","9d661b26":"code","052dded5":"code","13d90c41":"code","594a38ab":"code","008caa84":"code","99950671":"code","43b01a3c":"code","c2dd29e7":"code","1afa9bc9":"code","b203c61c":"code","5e79ff36":"code","a05ae82b":"code","7e718431":"code","10ca99c1":"code","4e1a0b3d":"code","e2f1c72e":"code","c572786a":"code","7dbf86c2":"code","077ea0c5":"code","57e752ec":"code","e3a98c7c":"code","8ad50bab":"code","ea3c68f3":"code","8220e359":"markdown","9e015c7d":"markdown","80a9bb47":"markdown","a37cc027":"markdown","df1871f3":"markdown","de95772d":"markdown","8da1be49":"markdown","f1d35457":"markdown","ef1cb38b":"markdown","9dbc6832":"markdown","225501d6":"markdown","01bb81c0":"markdown","e6a7097b":"markdown","bc7d8d36":"markdown","f0905446":"markdown"},"source":{"d33a83c4":"!pip install scikit-gstat","e183406c":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nfrom scipy.interpolate import Rbf, interp2d\nimport datetime\n\n# For import data\nimport os\n\n# Geostatistical analysis\nimport skgstat as skg\nfrom skgstat import Variogram, OrdinaryKriging\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nplt.style.use('ggplot')\n%env SKG_SUPPRESS = true\nimport warnings\nwarnings.simplefilter('ignore')","4e44fee2":"indicator_name = 'PM2.5' # 'PM2.5' or 'PM10'\ntime_interval='H' # 'H' (hour) or D' (day)\ntype_agg='mean' # 'mean' or 'max'","c79448a5":"#datetime_analysis = '2021-11-16 10:00:00'\n#datetime_analysis = '2021-11-27 09:00:00'  # maximum value after 2021-11-16\n#datetime_analysis = '2021-11-12 18:00:00'\n#datetime_analysis = '2021-01-23 18:00:00'  # maximum value","d0a58716":"# Import files with data from Kaggle dataset\ndataset_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        dataset_files.append(os.path.join(dirname, filename))\ndataset_files","99e17d5d":"len(dataset_files)","16a3a552":"# Data from SaveEcoBot\nstations_about = pd.read_csv('..\/input\/air-quality-monitoring\/saveecobot_city_about_stations.csv', header=0, sep=';')\nstations_about = stations_about[stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\nstations_about","85c4440d":"def get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    # Transform indicator to SaveEcoBot variants\n    if indicator_name=='PM2.5':\n        indicator_name = 'pm25'\n    elif indicator_name=='PM10':\n        indicator_name = 'pm10'\n    \n    # Get codes station\n    id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = stations_about.loc[num,'id_ecocity']\n    if not np.isnan(id_station_ecocity):\n        id_station_ecocity = int(id_station_ecocity)\n        id_station = \"EcoCity_\" + str(id_station_ecocity)\n    else: id_station = \"SaveEcoBot_\" + str(id_station_saveecobot)\n    #print(num, id_station_saveecobot, id_station_ecocity, id_station)\n        \n    df = pd.read_csv(f\"..\/input\/air-quality-monitoring\/data_saveecobot_{id_station_saveecobot}.csv\")\n    #display(df.head())\n    df = df[df['indicator_code']==indicator_name]\n    #display(df.head())\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    #df = df.dropna().reset_index(drop=True)\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    #display(df.head())\n    # Data processing - converting data to average or maximum values per given time_interval\n    #df = df.resample('H').mean()\n    if type_agg == 'mean':\n        df = df.resample(time_interval).mean()\n    else:\n        # type_agg == 'max'\n        df = df.resample(time_interval).max()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n\n    if df.shape[1] > 1:\n        # Resample is successfull\n        #display(df.head())\n        df['network'] = str(stations_about.loc[num,'network'])\n        df['id_station'] = id_station\n        df['lat'] = float(stations_about.loc[num,'lat'])\n        df['lng'] = float(stations_about.loc[num,'lng'])\n        print(f\"Number of data for {num}th station #{id_station} is {len(df)}\")\n        #display(df)\n        #print(df.info())   \n    else:\n        print(f\"Data for {num}th station #{id_station} is bad\")\n        df = pd.DataFrame()\n    return df","3372a8f9":"%%time\ndf = pd.DataFrame()\nln = 0\nfor i in range(len(stations_about)):\n    df_i = get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, i)\n    #df_i.info()\n    if len(df) > 0:\n        #ln += len(df_i)\n        #print('\\n',ln)\n        df = pd.concat([df, df_i], ignore_index=True)\n    else: df = df_i\ndf = df.dropna().reset_index(drop=True)\ndf","b8969666":"df.info()","9d661b26":"# Data from SaveEcoBot\necocity_stations_about = pd.read_csv('..\/input\/air-quality-monitoring-from-ecocity\/ecocity_about_stations_2021.csv', header=0, sep=';')\necocity_stations_about","052dded5":"ecocity_stations_about_region = ecocity_stations_about[ecocity_stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\necocity_stations_about_region['id_ecocity'] = ecocity_stations_about_region['id_ecocity'].astype('int')\necocity_stations_about_region","13d90c41":"def get_data_for_indicator_of_station_from_ecocity(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    #id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = int(stations_about.loc[num,'id_ecocity'])\n    \n    # Find file name\n    for i in range(len(dataset_files)):\n        if dataset_files[i].find(str(id_station_ecocity))>0:\n            file_name = dataset_files[i]\n    \n    df = pd.read_csv(file_name)\n    #display(df)\n    df = df[df['indicator_name']==indicator_name]\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    df = df.resample('H').mean()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n    df['network'] = str(stations_about.loc[num,'network'])\n    #df['id_station_ecocity'] = id_station_ecocity\n    df['id_station'] = \"EcoCity_\" + str(id_station_ecocity)\n    df['lat'] = float(stations_about.loc[num,'lat'])\n    df['lng'] = float(stations_about.loc[num,'lng'])\n    #print(f\"Number of data for {num}th station #{id_station_saveecobot} in SaveEcoBot and #{id_station_ecocity} in EcoCity is {len(df)}\")\n    #display(df)\n    return df","594a38ab":"%%time\ndf2 = pd.DataFrame()\nfor i in range(len(ecocity_stations_about_region)):\n    df_i = get_data_for_indicator_of_station_from_ecocity(ecocity_stations_about_region, indicator_name, i)\n    if len(df2) > 0:\n        df2 = pd.concat([df2, df_i], ignore_index=True)\n    else: df2 = df_i\ndf2","008caa84":"df2.info()","99950671":"# Drop data on stations of the EcoCity network from SaveEcoBot \n# with datetime which equal datetime of data from EcoCity\nif len(df)>0:\n    len_before = len(df)\n    for id_station in df2['id_station'].unique().tolist():\n        print(id_station)\n        ds_list = df2[df2['id_station']==id_station]['ds'].tolist()\n        df = df.drop(df[(df.id_station == id_station) & (df.ds.isin(ds_list))].index)\n    len_after = len(df)\n    print(f\"Number of data before the dropping duplicates - {len_before}, after - {len_after}\")","43b01a3c":"if len(df)>0:\n    df = pd.concat([df, df2], ignore_index=True)\nelse: df = df2\ndf","c2dd29e7":"df.info()","1afa9bc9":"df.describe()","b203c61c":"print('Download data via API of the Center for Hydrometeorology in Vinnytsia region (http:\/\/meteo.vn.ua\/api\/api.php)....under development')\n# myfile = requests.get('http:\/\/meteo.vn.ua\/api\/api')\n# open('filename', 'wb').write(myfile.content)\n# data_meteo = pd.read_json('filename')\n# data_meteo.tail(5)","5e79ff36":"# Selection data for interpolation\nprint(df)\nif type_agg == 'mean':\n    datetime_analysis = 'all time'  \n    data = df[['ds','value', 'id_station']].groupby(by=['ds']).mean()\n    data = data.reset_index(drop=True)\n    data = pd.merge(data, df[['ds','id_station', 'lat', 'lng', 'network']], how = 'left', on = 'id_station').drop_duplicates().reset_index(drop=True)\nelse:\n    # type_agg == 'max':\n    datetime_analysis = 'all time'  \n    data = df[['value', 'id_station']].groupby(by=['id_station']).max()\n    data = data.reset_index(drop=False)\n    data = pd.merge(data, df[['id_station', 'lat', 'lng', 'network']], how = 'left', on = 'id_station').drop_duplicates().reset_index(drop=True)\n\nind = []\nfor i in range(0,29000):\n    ind.append(i)\n    data.drop(axis = 0, index = ind ,inplace = True)\nx = data.lng.values\ny = data.lat.values\nz = data.value.values\nfig = plt.figure()\nplt.scatter(x, y)\nplt.title(f'Stations in Vinnytsia region with data for {indicator_name} in {datetime_analysis}')\ndisplay(data)\nplt.show()","a05ae82b":"df = data[['lat', 'lng', 'value']]\ndf.columns = ['x', 'y', 'z']\ndf","7e718431":"%%time\n# Calculation variogram\nV = skg.Variogram(df[['x', 'y']].values, df['z'].values, normalize = False)\nprint(V)\nV.maxlag = 2\nV.n_lags = 9\nV.bin_func = 'kmeans'","10ca99c1":"# Variogram visualization\nV.plot()\nplt.close","4e1a0b3d":"V.n_lags = 1\nV.maxlag = 5\nV.bin_func = 'kmeans'\nV.plot()\nplt.close()","e2f1c72e":"# Visualization of the variograms for different models\nfig, _a = plt.subplots(2,3, figsize=(18, 10), sharex=True, sharey=True)\naxes = _a.flatten()\nfor i, model in enumerate(('spherical', 'exponential', 'gaussian', 'matern', 'stable', 'cubic')):\n    V.model = model\n    V.plot(axes=axes[i], hist=False, show=False)\n    axes[i].set_title('Model: %s; RMSE: %.2f' % (model, V.rmse))","c572786a":"V.model = 'stable'\nok = OrdinaryKriging(V, min_points=3, max_points=5, mode='estimate')\nxx, yy = np.mgrid[0:99:100j, 0:99:100j]\nfield = ok.transform(xx.flatten(), yy.flatten()).reshape(xx.shape)\ns2 = ok.sigma.reshape(xx.shape)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\nart = axes[0].matshow(field.T, origin='lower', cmap='plasma')\naxes[0].set_title('Interpolation')\naxes[0].plot(df.x, df.y, '+k')\naxes[0].set_xlim((0,100))\naxes[0].set_ylim((0,100))\nplt.colorbar(art, ax=axes[0])\nart = axes[1].matshow(s2.T, origin='lower', cmap='YlGn_r')\naxes[1].set_title('Kriging Error')\nplt.colorbar(art, ax=axes[1])\naxes[1].plot(df.x, df.y, '+w')\naxes[1].set_xlim((0,100))\naxes[1].set_ylim((0,100));","7dbf86c2":"def interpolate(V, ax):\n    # Thanks to https:\/\/scikit-gstat.readthedocs.io\/en\/latest\/tutorials\/02_variogram_models.html\n    \n    xx, yy = np.mgrid[0:99:100j, 0:99:100j]\n    ok = OrdinaryKriging(V, min_points=5, max_points=15, mode='exact')\n    field = ok.transform(xx.flatten(), yy.flatten()).reshape(xx.shape)\n    art = ax.matshow(field, origin='lower', cmap='plasma')\n    ax.set_title('%s model' % V.model.__name__)\n    plt.colorbar(art, ax=ax)\n    return field","077ea0c5":"fields = []\nfig, _a = plt.subplots(2,3, figsize=(18, 12), sharex=True, sharey=True)\naxes = _a.flatten()\nfor i, model in enumerate(('spherical', 'exponential', 'gaussian', 'matern', 'stable', 'cubic')):\n    V.model = model\n    fields.append(interpolate(V, axes[i]))","57e752ec":"# Data interpolation\nf = interp2d(x, y, z, kind='linear')  # \u2018linear\u2019, \u2018cubic\u2019, \u2018quintic\u2019\nf","e3a98c7c":"# Calculation of values for a regular network of points\nmarginx = 0.001\nmarginy = 0.0001\nX = np.linspace(data.lng.min()*(1-marginx), data.lng.max()*(1+marginx), 100)\nY = np.linspace(data.lat.min()*(1-marginy), data.lat.max()*(1+marginy), 100)\nZ = f(X, Y)\nZ[0]","8ad50bab":"# Coordinates of stations - from EcoCity or no\nxseb = data[data['network']!=\"Eco-City\"]['lng'].values\nyseb = data[data['network']!=\"Eco-City\"]['lat'].values\nnumseb = data[data['network']!=\"Eco-City\"]['id_station'].astype('str').values\nxeco = data[data['network']==\"Eco-City\"]['lng'].values\nyeco = data[data['network']==\"Eco-City\"]['lat'].values\nnumeco = data[data['network']==\"Eco-City\"]['id_station'].astype('str').values","ea3c68f3":"# Visualization\nfig = plt.figure(figsize=(12,10))\nplt.contourf(X, Y, Z)\n\nplt.scatter(xseb, yseb, c='gray', s=100, label='SaveEcoBot')\nfor i in range(len(xseb)):\n    plt.annotate(\"  \"+numseb[i], xy=(xseb[i], yseb[i]), textcoords='data')\n    \nplt.scatter(xeco, yeco, c='k', s=100, label='EcoCity')\nplt.colorbar()\nfor i in range(len(xeco)):\n    plt.annotate(\"  \"+numeco[i], xy=(xeco[i], yeco[i]), textcoords='data')\n\nplt.axis()\ntype_agg_str = 'average' if type_agg=='mean' else 'maximum'\ntime_agg_str = 'hour' if time_interval=='H' else 'D'\nplt.title(f'Stations in Vinnytsia region with {type_agg_str} data per {time_agg_str} for {indicator_name} in {datetime_analysis} (maximum value = {round(data.value.max(),2)})')\nplt.legend(loc='best')\nplt.grid()\nplt.show()","8220e359":"## 3. Geostatistical analysis with SciKit-GStat<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","9e015c7d":"# Visualization of the variogram with others parameters\n","80a9bb47":"### 2.3 Download data from the Center for Hydrometeorology in Vinnytsia region (under development)<a class=\"anchor\" id=\"2.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","a37cc027":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","df1871f3":"# Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)","de95772d":"**Thanks to https:\/\/www.kaggle.com\/vbmokin\/geostatistical-analysis-with-scikit-gstat**","8da1be49":"## 4. Linear interpolation with scipy.interpolate.interp2d<a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","f1d35457":"<a class=\"anchor\" id=\"0\"><\/a>\n# Air Quality City - 2D Analysis for Vinnytsia city with:\n* Geostatistical analysis with SciKit-GStat\n* Interpolation scipy.interpolate.interp2d","ef1cb38b":"## 2. Download data<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","9dbc6832":"### 2.1 Download data from SaveEcoBot<a class=\"anchor\" id=\"2.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","225501d6":"### 2.4 Selection data for interpolation<a class=\"anchor\" id=\"2.4\"><\/a>\n\n[Back to Table of Contents](#0.1)","01bb81c0":"### 2.2 Download data from EcoCity<a class=\"anchor\" id=\"2.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","e6a7097b":"## Acknowledgements\n\n### Geostatistical analysis with SciKit-GStat from the [Tutorial](https:\/\/scikit-gstat.readthedocs.io\/en\/latest\/tutorials\/tutorials.html) from \n\n**Mirko M\u00e4licke, Egil M\u00f6ller, Helge David Schneider, & Sebastian M\u00fcller. (2021, May 28).**\n\n    mmaelicke\/scikit-gstat: A scipy flavoured geostatistical variogram analysis toolbox (Version v0.6.0). Zenodo. \n\nhttp:\/\/doi.org\/10.5281\/zenodo.4835779\n\n\n### Notebooks:\n* [Geostatistical analysis with SciKit-GStat](https:\/\/www.kaggle.com\/vbmokin\/geostatistical-analysis-with-scikit-gstat)\n* [Air Quality in City - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-city-2d-analysis)\n* [Air Quality in Region - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-region-2d-analysis)\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/eda-for-tabular-data-advanced-techniques)\n* [COVID in UA: Prophet with 4, Nd seasonality](https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality)\n\n### Kaggle Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)\n\n### Other open data:\n* [Open data of the Vinnytsia City Council](https:\/\/opendata.gov.ua\/dataset\/pibehb-3a6pydhehocti-test)\n* [API of the Center for Hydrometeorology in Vinnytsia region](http:\/\/meteo.vn.ua\/api\/api.php)","bc7d8d36":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","f0905446":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n   - [Download data from SaveEcoBot](#2.1)\n   - [Download data from EcoCity](#2.2)\n   - [Download data from the Center for Hydrometeorology in Vinnytsia region (under development)](#2.3)\n   - [Selection data for interpolation](#2.4)   \n1. [Geostatistical analysis with SciKit-GStat](#3)\n1. [Linear interpolation with scipy.interpolate.interp2d](#4)"}}