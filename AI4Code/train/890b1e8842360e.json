{"cell_type":{"94191649":"code","ec3f8e18":"code","53a244c8":"code","7e564d81":"code","63088b0b":"code","aeaa42a6":"code","75b7f56c":"code","b1ba3e74":"code","412bcee7":"code","6b650162":"code","3c4dff62":"code","d68cd2e4":"code","64127ef0":"code","e67614b7":"code","b6893fde":"code","47ddbaeb":"code","d678afdd":"code","d6ac6c25":"code","2b633b6e":"code","f61614e7":"code","57bd0cc3":"code","b5b857a8":"code","01477481":"code","1c602ecc":"code","cd1266f8":"code","0c9bd38a":"code","01f210e7":"code","47d58eb2":"code","b72a544a":"code","fe1114ec":"code","8ac52afc":"code","72d8a4c9":"code","3bab4d23":"code","f03e420f":"markdown","7c6a24a7":"markdown","c0177336":"markdown","8dd1303c":"markdown","f9a0fdd6":"markdown","cf70de91":"markdown","f6b59f56":"markdown","cbe85be3":"markdown","64519924":"markdown","9cebab37":"markdown","b1cdaffc":"markdown","e0938fd1":"markdown","d2b351ef":"markdown"},"source":{"94191649":"%matplotlib inline\n\nimport os\nimport math\nimport copy\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\n\n# import skimage\nfrom skimage.io import imread\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","ec3f8e18":"EPOCHS = 5\nUSE_GPU = True","53a244c8":"labels_df = pd.read_csv(\"..\/input\/train_labels.csv\")","7e564d81":"labels_df.head()","63088b0b":"labels_df[\"label\"].value_counts().plot(kind=\"pie\")","aeaa42a6":"train_indices, test_indices = train_test_split(labels_df.index, test_size=0.25)","75b7f56c":"train_indices.shape, test_indices.shape","b1ba3e74":"class HistopathologicCancerDataset(torch.utils.data.Dataset):\n    \"\"\"\n    This is our custom dataset class which will load the images, perform transforms on them,\n    and load their corresponding labels.\n    \"\"\"\n    \n    def __init__(self, img_dir, labels_csv_file=None, transform=None):\n        self.img_dir = img_dir\n        \n        if labels_csv_file:\n            self.labels_df = pd.read_csv(labels_csv_file)\n        else:\n            self.images = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(\".tif\")]\n            \n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        try:\n            img_path = os.path.join(\n                self.img_dir,\n                \"{}.tif\".format(self.labels_df.iloc[idx, 0])\n            )\n        except AttributeError:\n            img_path = self.images[idx]\n\n#         print(\"img_path:\", img_path)\n        img = imread(img_path)\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        sample = {\n            \"image\": img,\n        }\n        try:\n            sample[\"label\"] = self.labels_df.loc[idx, \"label\"]\n            sample[\"id\"] = self.labels_df.loc[idx, \"id\"]\n        except AttributeError:\n            sample[\"id\"] = os.path.basename(self.images[idx]).replace(\".tif\", \"\")\n        \n        return sample\n    \n    def __len__(self):\n        try:\n            return self.labels_df.shape[0]\n        except AttributeError:\n            return len(self.images)","412bcee7":"transform_pipe = torchvision.transforms.Compose([\n    torchvision.transforms.ToPILImage(), # Convert np array to PILImage\n    \n    # Resize image to 224 x 224 as required by most vision models\n    torchvision.transforms.Resize(\n        size=(224, 224)\n    ),\n    \n    # Convert PIL image to tensor with image values in [0, 1]\n    torchvision.transforms.ToTensor(),\n    \n    torchvision.transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])","6b650162":"train_data = HistopathologicCancerDataset(\n    img_dir=\"..\/input\/train\/\",\n    labels_csv_file=\"..\/input\/train_labels.csv\",\n    transform=transform_pipe\n)","3c4dff62":"train_loader = torch.utils.data.DataLoader(\n    train_data,\n    batch_size=64,\n    sampler=torch.utils.data.SubsetRandomSampler(\n        train_indices\n    )\n#     shuffle=True,\n#     num_workers=8\n)","d68cd2e4":"test_loader = torch.utils.data.DataLoader(\n    train_data,\n    batch_size=64,\n    sampler=torch.utils.data.SubsetRandomSampler(\n        test_indices\n    )\n#     shuffle=True,\n#     num_workers=8\n)","64127ef0":"dataloaders = {\n    \"train\": train_loader,\n    \"test\": test_loader\n}","e67614b7":"class Flatten(torch.nn.Module):\n    \"\"\"\n    Custom flatten module like what is available in Keras.\n    \"\"\"\n    \n    def forward(self, input):\n        return input.view(input.size(0), -1)","b6893fde":"# model = torch.nn.Sequential(\n#     torch.nn.Conv2d(\n#         in_channels=3,\n#         out_channels=8,\n#         kernel_size=3,\n#     ),\n#     torch.nn.MaxPool2d(\n#         kernel_size=2\n#     ),\n#     torch.nn.ReLU(),\n    \n#     torch.nn.Conv2d(\n#         in_channels=8,\n#         out_channels=16,\n#         kernel_size=3\n#     ),\n#     torch.nn.MaxPool2d(\n#         kernel_size=2\n#     ),\n#     torch.nn.ReLU(),\n    \n#     torch.nn.Conv2d(\n#         in_channels=16,\n#         out_channels=32,\n#         kernel_size=3\n#     ),\n#     torch.nn.MaxPool2d(\n#         kernel_size=2\n#     ),\n#     torch.nn.ReLU(),\n    \n#     torch.nn.Conv2d(\n#         in_channels=32,\n#         out_channels=64,\n#         kernel_size=3\n#     ),\n#     torch.nn.MaxPool2d(\n#         kernel_size=2\n#     ),\n#     torch.nn.ReLU(),\n    \n#     Flatten(),\n    \n#     torch.nn.Linear(\n#         in_features=1024,\n#         out_features=1\n#     ),\n#     torch.nn.Sigmoid()\n# )","47ddbaeb":"# model = torchvision.models.resnet50(pretrained=True)\nmodel = torchvision.models.resnet50()","d678afdd":"model","d6ac6c25":"model.fc = torch.nn.Sequential(\n    torch.nn.Linear(\n        in_features=2048,\n        out_features=1\n    ),\n    torch.nn.Sigmoid()\n)","2b633b6e":"model","f61614e7":"# out = model(train_data[0][\"image\"].view(1, 3, 224, 224))","57bd0cc3":"# out.shape","b5b857a8":"# Some utils functions.\n# Seems like PyTorch does not auto-infer tensor shapes in a sequential model, so we need to figure the shapes ourself.\n\ndef compute_conv2d_output_dimensions(Hin, Win, kernel_size, padding=(0, 0), dilation=(1, 1), stride=(1, 1)):\n    Hout = math.floor(((Hin + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) \/ stride[0]) + 1)\n    Wout = math.floor(((Win + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) \/ stride[1]) + 1)\n    return Hout, Wout\n\n\ndef compute_maxpooling2d_output_dimensions(Hin, Win, kernel_size, stride=None, padding=(0, 0), dilation=(1, 1)):\n    if stride is None:\n        stride = kernel_size\n    \n    Hout = math.floor(((Hin + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) \/ stride[0]) + 1)\n    Wout = math.floor(((Win + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) \/ stride[1]) + 1)\n    return Hout, Wout","01477481":"# compute_conv2d_output_dimensions(96, 96, (3, 3))","1c602ecc":"# compute_maxpooling2d_output_dimensions(94, 94, kernel_size=(2, 2))","cd1266f8":"if USE_GPU:\n    model = model.cuda() # Should be called before instantiating optimizer according to docs: https:\/\/pytorch.org\/docs\/stable\/nn.html\n\noptimizer = torch.optim.Adam(model.parameters())\ncriterion = torch.nn.BCELoss()\n\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_acc = 0.0\n\nfor i in range(EPOCHS):\n    for phase in [\"train\", \"test\"]:\n        if phase == \"train\":\n            model.train()\n        else:\n            model.eval()\n        \n        samples = 0\n        loss_sum = 0\n        correct_sum = 0\n        for j, batch in enumerate(dataloaders[phase]):\n            X = batch[\"image\"]\n            labels = batch[\"label\"]\n            if USE_GPU:\n                X = X.cuda()\n                labels = labels.cuda()\n\n            optimizer.zero_grad()\n\n            with torch.set_grad_enabled(phase == 'train'):\n                y = model(X)\n                loss = criterion(\n                    y, \n                    labels.view(-1, 1).float()\n                )\n\n                if phase == \"train\":\n                    loss.backward()\n                    optimizer.step()\n                    \n                loss_sum += loss.item() * X.shape[0] # We need to multiple by batch size as loss is the mean loss of the samples in the batch\n                samples += X.shape[0]\n                num_corrects = torch.sum((y >= 0.5).float() == labels.view(-1, 1).float())\n                correct_sum += num_corrects\n                \n                # Print batch statistics every 50 batches\n                if j % 50 == 49 and phase == \"train\":\n                    print(\"{}:{} - loss: {}, acc: {}\".format(\n                        i + 1, \n                        j + 1, \n                        float(loss_sum) \/ float(samples), \n                        float(correct_sum) \/ float(samples)\n                    ))\n                \n        # Print epoch statistics\n        epoch_acc = float(correct_sum) \/ float(samples)\n        epoch_loss = float(loss_sum) \/ float(samples)\n        print(\"epoch: {} - {} loss: {}, {} acc: {}\".format(i + 1, phase, epoch_loss, phase, epoch_acc))\n        \n        # Deep copy the model\n        if phase == \"test\" and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts, \"resnet50.pth\")","0c9bd38a":"# torch.save(best_model_wts, \"resnet50.pth\")","01f210e7":"model1 = torchvision.models.resnet50()\nmodel1.fc = torch.nn.Sequential(\n    torch.nn.Linear(\n        in_features=2048,\n        out_features=1\n    ),\n    torch.nn.Sigmoid()\n)\nmodel1.load_state_dict(torch.load(\"resnet50.pth\"))","47d58eb2":"test_data = HistopathologicCancerDataset(\n    img_dir=\"..\/input\/test\/\",\n    transform=transform_pipe\n)","b72a544a":"test_loader1 = torch.utils.data.DataLoader(\n    test_data,\n    batch_size=64,\n#     shuffle=True,\n#     num_workers=8\n)","fe1114ec":"model1.eval()\nif USE_GPU:\n    model1 = model1.cuda()\n\nids_all = []\npredictions = []\n\nfor j, batch in enumerate(test_loader1):\n    X = batch[\"image\"]\n    ids = batch[\"id\"]\n    if USE_GPU:\n        X = X.cuda()\n    \n    for _id in ids:\n        ids_all.append(_id)\n\n    with torch.set_grad_enabled(False):\n        y_pred = model1(X)\n        predictions.append((y_pred >= 0.5).float().cpu().numpy())\n        \nprint(\"Done making predictions!\")","8ac52afc":"submissions = pd.DataFrame({\n    \"id\": ids_all,\n    \"label\": np.concatenate(predictions).reshape(-1,).astype(\"int\")\n}).set_index(\"id\")","72d8a4c9":"submissions.head()","3bab4d23":"submissions.to_csv(\"submissions.csv\")","f03e420f":"**Model training**","7c6a24a7":"**Reconstruct model from saved weights**","c0177336":"**Image tranformation pipeline**","8dd1303c":"**Configurations**","f9a0fdd6":"**Make sure we are not having the imbalanced classification problem**","cf70de91":"**Replace the final fully connected layer to suite the problem**","f6b59f56":"**Make predictions**","cbe85be3":"**The training dataset loader will randomly sample from the train samples**","64519924":"**Train test split for model selection**","9cebab37":"**The training dataset loader will randomly sample from the test samples**","b1cdaffc":"**Load labels**","e0938fd1":"**Persist latest model**","d2b351ef":"**Model definition**"}}