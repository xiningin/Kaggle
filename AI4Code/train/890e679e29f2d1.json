{"cell_type":{"80af8391":"code","05fc4e48":"code","00b05b3f":"code","406a0578":"code","75e38d2d":"code","d54fed8b":"code","1a36a895":"code","8cd841c7":"code","7fcfb1cd":"code","febe25c2":"code","7564c64d":"code","e549555d":"code","77a94ef0":"code","17ed2525":"code","c92b6a8d":"code","4cbacde1":"code","a40cb300":"code","8846b8f6":"code","a8804e1b":"code","6282719f":"code","b396d2ff":"code","532357cb":"markdown","2bdb08c7":"markdown","040047a7":"markdown","13a8ece2":"markdown","3f10c5e0":"markdown","da33edf1":"markdown","8f5dcad5":"markdown","bac62e46":"markdown","ea7a67ff":"markdown"},"source":{"80af8391":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05fc4e48":"df= pd.read_csv('..\/input\/leaf-classification\/train.csv.zip', index_col='id')\ndf","00b05b3f":"for col in df.columns:\n    if df[col].isna().sum() > 0:\n        print(col, df[col].isna().sum()   \/len(df))","406a0578":"df.species.value_counts()","75e38d2d":"len(df.species.unique())","d54fed8b":"y=df.species\ny.head()","1a36a895":"X = df.drop(columns = 'species', axis=1)\nX.head()","8cd841c7":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder= LabelEncoder().fit(y)\nlabeled_species= label_encoder.transform(y)","7fcfb1cd":"classes=list(label_encoder.classes_)\nclasses","febe25c2":"parameters = parameters = {\n    'n_estimators': list(range(200,401,100)),\n    'learning_rate':[l\/1000 for l in range (5,15,10)],\n    'max_depth': list(range(6,20,5)) \n}           \nparameters","7564c64d":"from sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import log_loss\n\ngsearch = GridSearchCV(estimator=XGBClassifier(),\n                       param_grid = parameters, \n                       scoring= 'neg_log_loss',\n                       n_jobs=4,cv=5, verbose=7)","e549555d":"gsearch.fit(X,labeled_species)","77a94ef0":"best_n_estimators = gsearch.best_params_.get('n_estimators')\nbest_n_estimators","17ed2525":"best_learning_rate = gsearch.best_params_.get('learning_rate')\nbest_learning_rate","c92b6a8d":"best_max_depth = gsearch.best_params_.get('max_depth')\nbest_max_depth","4cbacde1":"final_model = XGBClassifier(n_estimators=best_n_estimators,\n                            learning_rate=best_learning_rate,\n                            max_depth=best_max_depth)","a40cb300":"final_model.fit(X, labeled_species)","8846b8f6":"test = pd.read_csv('..\/input\/leaf-classification\/test.csv.zip',index_col='id')","a8804e1b":"pred_test=final_model.predict_proba(test)\npred_test.shape","6282719f":"pred_test","b396d2ff":"output = pd.DataFrame(pred_test, columns=classes)\noutput.insert(0, 'id', test.index)\noutput.reset_index()\n\noutput.to_csv('submission.csv', index=False)\nprint('done')\noutput","532357cb":"# Define GridSearchCV for hypter-parameter tuning","2bdb08c7":"# Predict the test data","040047a7":"> There's no missing value ","13a8ece2":"# Build and fit the final model with the best parameters","3f10c5e0":"# Load data","da33edf1":"# Define Parameters","8f5dcad5":"# Label Encoding ","bac62e46":"# Fit the model ","ea7a67ff":"# Get the best parameters"}}