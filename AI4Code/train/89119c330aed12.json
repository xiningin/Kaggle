{"cell_type":{"08cc13ea":"code","594841e4":"code","0b715838":"code","39262a25":"code","85fe4ac2":"code","3f3c9430":"code","e8a4bc9c":"code","852360d0":"code","37ce4aa1":"code","1cf60795":"code","c3139bb0":"code","f1ac9f30":"code","2ce4b7fa":"code","3d342969":"code","4da8bca4":"code","0920206e":"code","41d2f9b9":"markdown","587fa24c":"markdown","792762dc":"markdown","fef3dfca":"markdown"},"source":{"08cc13ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","594841e4":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport sys\nimport matplotlib","0b715838":"path = '\/kaggle\/input\/boston-house-prices\/housing.csv'\nheader_names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \n              'DIS', 'RAD', 'TAX', 'PTRATION', 'B', 'LSTAT', 'PRICE']\ndf = pd.read_csv(path, names=header_names, delim_whitespace=True)\ndf.shape","39262a25":"df.head()","85fe4ac2":"df.describe()","3f3c9430":"x = df.loc[:, 'ZN':'LSTAT']\ny = df.loc[:, 'PRICE']\nx.shape, y.shape","e8a4bc9c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)","852360d0":"from sklearn import preprocessing\nscalar = preprocessing.StandardScaler()\nX_train = pd.DataFrame(scalar.fit_transform(X_train), columns=header_names[1:-1], index=X_train.index)\nX_test = pd.DataFrame(scalar.transform(X_test), columns=header_names[1:-1], index=X_test.index)","37ce4aa1":"X_train","1cf60795":"X_train['price'] = y_train\nX_test['price'] = y_test\nX_train.shape, X_test.shape","c3139bb0":"X_train","f1ac9f30":"from sklearn.metrics import mean_squared_error\n\ndef my_sgd(X_train, learning_rate=0.2, n_epochs=1000, sample_size=40):\n    n_cols = X_train.shape[1]\n    columns = X_train.columns.values\n    w = np.random.randn(n_cols - 1)\n    b = np.random.randn(1)\n    \n    for epoch in range(n_epochs):\n        # Get Sample\n        sample = X_train.sample(sample_size)\n        x = sample.loc[:, columns[:-1]].values\n        y = sample.loc[:, columns[-1]].values\n        \n        loss = 0\n        \n        y_pred = []\n        sq_loss = []\n        \n        for i in range(sample_size):\n            p = x[i]\n            q = y[i]\n            \n            # calculate error\n            pred = np.dot(x[i], w.T) + b\n            error = y[i] - pred\n            \n            # changes\n            lw = (-2 * x[i] * error) \/ sample_size\n            lb = (-2 * error) \/ sample_size\n            \n            # update\n            w = w - learning_rate * lw\n            b = b - learning_rate * lb\n            \n            # predict new\n            pred_new = np.dot(x[i], w.T)\n            y_pred.append(pred_new)\n        \n        # loss\n        loss = mean_squared_error(y_pred, y)\n        \n        # print\n        print(f'epoch: {epoch}, loss: {loss:.03f}')\n        \n        # learning rate decay\n        learning_rate \/= 1.02\n        \n    return w, b","2ce4b7fa":"w, b = my_sgd(X_train)","3d342969":"def predict(X, w, b):\n    y_pred = []\n    y_actual = []\n    columns = X.columns.values\n    for i in range(len(X)):\n        sample = X.loc[:, columns[:-1]].values\n        sample_y = X.loc[:, columns[:-1]].values\n        x = sample[i]\n        pred = np.asscalar(np.dot(x, w.T) + b)\n        y_pred.append(pred)\n        \n    return np.array(y_pred)\n\ny_pred_test = predict(X_test, w, b)\ny_pred_test","4da8bca4":"y_test_actual = X_test.loc[:, X_test.columns.values[-1]].values\ny_test_actual","0920206e":"from matplotlib.pyplot import figure\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(25,6))\nplt.plot(y_test_actual, label='Actual')\nplt.plot(y_pred_test, label='Predicted')\nplt.legend(prop={'size': 16})\nplt.show()\nprint('Mean Squared Error :',mean_squared_error(y_test_actual, y_pred_test))","41d2f9b9":"### Stochastic Gradient Descent","587fa24c":"### Data","792762dc":"### SGD Implementation Reference:\nhttps:\/\/towardsdatascience.com\/implementing-sgd-from-scratch-d425db18a72c","fef3dfca":"CRIM: per capita crime rate by town\n\nZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n\nINDUS: proportion of non-retail business acres per town\n\nCHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n\nNOX: nitric oxides concentration (parts per 10 million)\n\nRM: average number of rooms per dwelling\n\nAGE: proportion of owner-occupied units built prior to 1940\n\nDIS: weighted distances to \ufb01ve Boston employment centers\n\nRAD: index of accessibility to radial highways\n\nTAX: full-value property-tax rate per $10,000\n\nPTRATIO: pupil-teacher ratio by town 12. B: 1000(Bk\u22120.63)2 where Bk is the proportion of blacks by town 13. \n\nLSTAT: % lower status of the population\n\nMEDV: Median value of owner-occupied homes in $1000s\n\nWe can see that the input attributes have a mixture of units."}}