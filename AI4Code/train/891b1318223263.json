{"cell_type":{"0bd6890c":"code","4a559769":"code","53f21ca2":"code","99562330":"code","1339de6b":"code","0a564d06":"code","bc336aa4":"code","737a5a5a":"code","74d22878":"code","21948fc2":"code","54bbd97b":"code","96b7533d":"code","6bb5a980":"code","6e87087f":"code","0ad2c513":"code","7d9eb0b8":"code","80bc82bf":"code","85c87cbf":"code","00bb9081":"markdown","dce2fe27":"markdown","0b224e77":"markdown","6fe76aaf":"markdown","6dcff8a4":"markdown","7f9ac070":"markdown","fd06451b":"markdown","0078ba44":"markdown","7a2f36a9":"markdown"},"source":{"0bd6890c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","4a559769":"train = pd.read_csv('\/kaggle\/input\/cifar10-mu\/train.csv', dtype=str)\nprint(train.shape)","53f21ca2":"train.head()","99562330":"y_train = train.label\n\n(train.label.value_counts() \/ len(train)).to_frame().sort_index(ascending=True)","1339de6b":"sample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(6,6))\n\nfor i, row in sample.iterrows():\n\n    img = mpimg.imread(f'\/kaggle\/input\/cifar10-mu\/train_images\/{row.filename}')    \n    label = row.label\n\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n        \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","0a564d06":"train_df, valid_df = train_test_split(train, test_size=0.2, random_state=1, stratify=train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","bc336aa4":"train_datagen = ImageDataGenerator(rescale=1\/255)\nvalid_datagen = ImageDataGenerator(rescale=1\/255)","737a5a5a":"BATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = '\/kaggle\/input\/cifar10-mu\/train_images\/',\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)\n\nvalid_loader = train_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = '\/kaggle\/input\/cifar10-mu\/train_images\/',\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)","74d22878":"TR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","21948fc2":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same', input_shape=(32,32,3)),\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    BatchNormalization(),\n\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    Dense(10, activation='softmax')\n])\n\ncnn.summary()","54bbd97b":"opt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","96b7533d":"%%time \n\nh1 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 20,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","6bb5a980":"history = h1.history\nprint(history.keys())","6e87087f":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","0ad2c513":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","7d9eb0b8":"%%time \n\nh2 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 20,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","80bc82bf":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","85c87cbf":"cnn.save('cifar10_model_v01.h5')\npickle.dump(history, open(f'cifar10_history_v01.pkl', 'wb'))","00bb9081":"# Load Training DataFrame","dce2fe27":"# Import Packages","0b224e77":"# Label Distribution","6fe76aaf":"# View Sample of Images","6dcff8a4":"# Train Network","7f9ac070":"# Save Model and History","fd06451b":"# Data Generators","0078ba44":"# **CIFAR10 Training Notebook**\n### **Sara Manrriquez**","7a2f36a9":"# Build Network"}}