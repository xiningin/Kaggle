{"cell_type":{"74b2b1fb":"code","6bec08fa":"code","2f3493e4":"code","8a86364c":"code","7e815ade":"code","36ac1123":"code","d29c8f95":"code","7b6f6ef3":"code","986d88d9":"code","f44eced2":"code","c88f562c":"code","5bdb21d3":"code","d0a53887":"code","6892e985":"code","8d3a4c92":"code","90d9a162":"code","8610eaf5":"code","ab764ebe":"code","bea0aa98":"code","7c743846":"code","fec1e190":"code","9ff72362":"code","f68913e9":"code","af783904":"code","c77713c3":"code","6b286744":"code","e60a73e0":"code","14f8be03":"code","69f5af4e":"code","85c4bed7":"code","0d42ef19":"code","7e5f8eff":"code","4652b7af":"code","8310bd49":"code","f2a6b401":"code","1396fb30":"code","27c021d3":"code","6db66dba":"code","0b27f4e8":"code","c47d3fd8":"code","06a32198":"code","0136af3a":"code","9d5793d9":"code","7869656f":"code","0123419d":"code","2f3a9e47":"code","4cd7d6aa":"code","0097a67e":"code","d1128225":"code","567312c9":"code","8284b44d":"code","09a28ee3":"code","e55379c9":"code","eb120423":"code","09f8cbbd":"code","082c6207":"code","315ae099":"code","131b11f5":"code","139a2fa2":"code","a5962bad":"code","96256d78":"code","7b62b67f":"code","37b9be2f":"code","57eedb70":"code","0a2f536b":"code","c4294dd9":"code","170afca6":"code","9c5163ea":"code","9c766d4e":"code","4c79c79a":"code","6586db26":"code","69a17b35":"code","93afe2e4":"code","410dd0d9":"code","524de602":"code","a2dfb8f6":"code","628ab272":"code","401bf2ea":"code","c18584e6":"code","2a20dfcb":"code","ecfc3c85":"code","b2d85d38":"code","f6ca5440":"code","b7f127b4":"code","3c1dee2a":"code","5fcd6cd7":"markdown","75107342":"markdown","972bf32c":"markdown","7a713441":"markdown","ab0f2dbb":"markdown","5d7bff9e":"markdown","34220204":"markdown","537661bf":"markdown","225ebd75":"markdown","5283d74e":"markdown","33cb61a2":"markdown","1e7ef810":"markdown","16d703b0":"markdown","08927d85":"markdown","5d9195b9":"markdown","b125a86e":"markdown","10c91db3":"markdown","a3dee04c":"markdown","58ac89aa":"markdown","1440a5f8":"markdown","0e73ae73":"markdown","4ac4c212":"markdown","d61e4830":"markdown","d329e7d0":"markdown","1cdb291d":"markdown","b99fcf7b":"markdown","2d8fd084":"markdown","b7c9af4a":"markdown","c1189079":"markdown","82f8fbc9":"markdown","f97ee593":"markdown","afb4d733":"markdown","b9c61967":"markdown","6d9f8d9b":"markdown","100af29c":"markdown","7253f2f8":"markdown"},"source":{"74b2b1fb":"import pandas as pd\nimport numpy as np\nimport time\nimport datetime as dt\nimport sklearn.cluster as cluster\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6bec08fa":"retail = pd.read_csv(\"..\/input\/ecommerce-data\/data.csv\",encoding='cp874')\nretail.head()","2f3493e4":"retail.shape","8a86364c":"retail.info()","7e815ade":"retail.isna().sum().sort_values(ascending=False)","36ac1123":"pd.DataFrame(data = (retail.isna().sum() \/ retail.shape[0]) * 100, index = retail.columns, columns = ['% Null Values'])","d29c8f95":"retail.dropna(subset=['CustomerID'],how='any',inplace=True)\nretail.shape","7b6f6ef3":"retail.isna().sum()","986d88d9":"retail.duplicated().sum()","f44eced2":"retail.drop_duplicates(inplace=True)","c88f562c":"retail.shape","5bdb21d3":"retail = retail[retail['Quantity'] > 0]","d0a53887":"retail.shape","6892e985":"pd.DataFrame(data=[retail['InvoiceNo'].nunique(),retail['StockCode'].nunique(),retail['CustomerID'].nunique()],columns=['Count'],\n                   index=['Number of Transactions','Number of Unique Products Bought','Number of Unique Customers'])","8d3a4c92":"retail['InvoiceDate'] = retail['InvoiceDate'].astype('datetime64')\nretail['InvoiceDate'].max()","90d9a162":"now = dt.date(2011,12,9)\nprint(now)","8610eaf5":"retail['Date'] = retail['InvoiceDate'].apply(lambda x: x.date())","ab764ebe":"retail.head()","bea0aa98":"recency_df = retail.groupby(by='CustomerID', as_index=False)['Date'].max()\nrecency_df.columns = ['CustomerID','LastPurshaceDate']\nrecency_df.head()","7c743846":"recency_df['Recency'] = recency_df['LastPurshaceDate'].apply(lambda x: (now - x).days)\nrecency_df.head()","fec1e190":"recency_df.drop('LastPurshaceDate',axis=1,inplace=True)\nrecency_df.head()","9ff72362":"temp = retail.copy()\ntemp.drop_duplicates(['InvoiceNo','CustomerID'],keep='first',inplace=True)\nfrequency_df = temp.groupby(by=['CustomerID'], as_index=False)['InvoiceNo'].count()\nfrequency_df.columns = ['CustomerID','Frequency']\nfrequency_df.head()","f68913e9":"retail['TotalCost'] = retail['Quantity'] * retail['UnitPrice']","af783904":"retail.head()","c77713c3":"monetary_df = retail.groupby(by='CustomerID',as_index=False).agg({'TotalCost': 'sum'})\nmonetary_df.columns = ['CustomerID','Monetary']\nmonetary_df.head()","6b286744":"rfm_df = recency_df.merge(frequency_df,on='CustomerID').merge(monetary_df,on='CustomerID')\nrfm_df.set_index('CustomerID',inplace=True)\nrfm_df.head()","e60a73e0":"pareto_cutoff = rfm_df['Monetary'].sum() * 0.8\nprint(\"The 80% of total revenue is: \",round(pareto_cutoff,2))","14f8be03":"customers_ranked = rfm_df\ncustomers_ranked['Rank'] = customers_ranked['Monetary'].rank(ascending=False)\ncustomers_ranked.head()","69f5af4e":"customers_ranked.sort_values(by='Rank',ascending=True,inplace=True)\ncustomers_ranked.head()","85c4bed7":"# Get top 20% of the customers\ntop_20_cutoff = 4339 * 20 \/100\ntop_20_cutoff","0d42ef19":"# Sum the monetary values over the customer with rank <= 868\nrevenueByTop20 = customers_ranked[customers_ranked['Rank'] <= 868]['Monetary'].sum()\nrevenueByTop20","7e5f8eff":"quantiles = rfm_df.quantile(q=[0.25,0.5,0.75])\nquantiles","4652b7af":"quantiles.to_dict()","8310bd49":"# Arguments (x = value, p = recency, monetary_value, frequency, d = quartiles dict)\ndef RScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 4\n    elif x <= d[p][0.50]:\n        return 3\n    elif x <= d[p][0.75]: \n        return 2\n    else:\n        return 1","f2a6b401":"# Arguments (x = value, p = recency, monetary_value, frequency, k = quartiles dict)\ndef FMScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 1\n    elif x <= d[p][0.50]:\n        return 2\n    elif x <= d[p][0.75]: \n        return 3\n    else:\n        return 4","1396fb30":"# Create rfm segmentation table\nrfm_segmentation = rfm_df\nrfm_segmentation['R_Quartile'] = rfm_segmentation['Recency'].apply(RScore, args=('Recency',quantiles,))\nrfm_segmentation['F_Quartile'] = rfm_segmentation['Frequency'].apply(FMScore, args=('Frequency',quantiles,))\nrfm_segmentation['M_Quartile'] = rfm_segmentation['Monetary'].apply(FMScore, args=('Monetary',quantiles,))","27c021d3":"rfm_segmentation.head()","6db66dba":"rfm_segmentation['RFMScore'] = rfm_segmentation.R_Quartile.map(str) \\\n                            + rfm_segmentation.F_Quartile.map(str) \\\n                            + rfm_segmentation.M_Quartile.map(str)\nrfm_segmentation.head()","0b27f4e8":"rfm_segmentation[rfm_segmentation['RFMScore']=='444'].sort_values('Monetary', ascending=False).head(10)","c47d3fd8":"print(\"Best Customers: \",len(rfm_segmentation[rfm_segmentation['RFMScore']=='444']))\nprint('Loyal Customers: ',len(rfm_segmentation[rfm_segmentation['F_Quartile']==4]))\nprint(\"Big Spenders: \",len(rfm_segmentation[rfm_segmentation['M_Quartile']==4]))\nprint('Customers at risk of churning: ', len(rfm_segmentation[rfm_segmentation['RFMScore']=='244']))\nprint('Almost Churned Customers: ',len(rfm_segmentation[rfm_segmentation['RFMScore']=='144']))\nprint('Churned Customers: ',len(rfm_segmentation[rfm_segmentation['RFMScore']=='111']))","06a32198":"rfm_data = rfm_df.drop(['R_Quartile','F_Quartile','M_Quartile','RFMScore','Rank'],axis=1)\nrfm_data.head()","0136af3a":"features = rfm_data.columns","9d5793d9":"sns.pairplot(rfm_data,diag_kind='kde')","7869656f":"sns.heatmap(rfm_data.corr(),annot=True)","0123419d":"from sklearn.preprocessing import PowerTransformer\npt = PowerTransformer()\nrfm_data = pd.DataFrame(pt.fit_transform(rfm_data))\nrfm_data.columns = features\nrfm_data.head()","2f3a9e47":"sns.pairplot(rfm_data,diag_kind='kde')","4cd7d6aa":"sns.heatmap(rfm_data.corr(),annot=True)","0097a67e":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nrfm_scaled = sc.fit_transform(rfm_data)\nrfm_scaled[:5]","d1128225":"from sklearn.decomposition import PCA\n\npca = PCA()\npca_transformed_data = pca.fit_transform(rfm_scaled)","567312c9":"pca.explained_variance_","8284b44d":"var_exp = pca.explained_variance_ratio_\nvar_exp","09a28ee3":"pca.components_","e55379c9":"np.cumsum(var_exp)","eb120423":"plt.figure(figsize=(6,4))\nplt.bar(range(3), var_exp, alpha=0.5, align='center', label='Individual explained variance')\nplt.step(range(3), np.cumsum(var_exp), where='mid', label='Cumulative explained variance')\nplt.ylabel('Explained Variance Ratio')\nplt.xlabel('Principal Components')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()","09f8cbbd":"X = rfm_scaled.copy()\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(X)","082c6207":"df_pca = pd.DataFrame(df_pca)\ndf_pca.head()","315ae099":"X = df_pca.copy()","131b11f5":"from sklearn.cluster import KMeans\n\ncluster_range = range(1, 15)\ncluster_errors = []\ncluster_sil_scores = []\n\nfor num_clusters in cluster_range:\n  clusters = KMeans( num_clusters, n_init = 100,init='k-means++',random_state=0)\n  clusters.fit(X)\n  labels = clusters.labels_                     # capture the cluster lables\n  centroids = clusters.cluster_centers_         # capture the centroids\n  cluster_errors.append( clusters.inertia_ )    # capture the intertia\n\n# combine the cluster_range and cluster_errors into a dataframe by combining them\nclusters_df = pd.DataFrame({ \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors} )\nclusters_df[0:10]","139a2fa2":"# Elbow plot\n\nplt.figure(figsize=(12,6))\nplt.plot(clusters_df['num_clusters'], clusters_df['cluster_errors'], marker = \"o\" )\nplt.xlabel('Number of Clusters')\nplt.ylabel('Cluster Errors')","a5962bad":"for k in range(2,16):\n    cluster = KMeans(n_clusters=k, random_state=0)\n    labels = cluster.fit_predict(df_pca)\n    \n    sil_avg = silhouette_score(df_pca, labels)\n    print('For',k,'clusters, average silhoutte score =',sil_avg)","96256d78":"kmeans = KMeans(n_clusters=4)\nkmeans = kmeans.fit(df_pca)\nlabels = kmeans.predict(df_pca)\ncentroids = kmeans.cluster_centers_\n\nprint('Centroid Values:')\nprint(centroids)","7b62b67f":"# creating new column in df_pca dataframe for cluster number  \ndf_pca['Cluster'] = labels\ndf_pca.head()","37b9be2f":"df_pca['Cluster'].value_counts()","57eedb70":"sns.pairplot(df_pca,diag_kind='kde',hue='Cluster')","0a2f536b":"df_pca.boxplot(by='Cluster', figsize=(15, 10))\nplt.show()","c4294dd9":"customers_grouped = pd.DataFrame(pt.inverse_transform(rfm_data),columns=rfm_data.columns,index=rfm_df.index)\ncustomers_grouped['Cluster'] = df_pca['Cluster'].values\ncustomers_grouped['RFMScore'] = rfm_segmentation['RFMScore'].values\ncustomers_grouped.head()","170afca6":"top_spenders_and_loyal_customers = customers_grouped[(customers_grouped['RFMScore'] == '444') | (customers_grouped['RFMScore'] == '443') | (customers_grouped['RFMScore'] == '434')]\ntop_spenders_and_loyal_customers","9c5163ea":"customers_churned = customers_grouped[(customers_grouped['RFMScore'] == '111') | (customers_grouped['RFMScore'] == '112') | (customers_grouped['RFMScore'] == '121')]\ncustomers_churned","9c766d4e":"customers_at_risk_of_churning = customers_grouped[(customers_grouped['RFMScore'] == '144') | (customers_grouped['RFMScore'] == '143') | (customers_grouped['RFMScore'] == '134') | (customers_grouped['RFMScore'] == '133') | (customers_grouped['RFMScore'] == '142') | (customers_grouped['RFMScore'] == '124')]\ncustomers_at_risk_of_churning","4c79c79a":"new_customers_or_avg_spenders = customers_grouped[(customers_grouped['RFMScore'] == '422') | (customers_grouped['RFMScore'] == '411') | (customers_grouped['RFMScore'] == '412') | (customers_grouped['RFMScore'] == '421') | (customers_grouped['RFMScore'] == '413') | (customers_grouped['RFMScore'] == '431')]\nnew_customers_or_avg_spenders","6586db26":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_roc_curve","69a17b35":"y = df_pca['Cluster']","93afe2e4":"X_train, X_test, y_train, y_test = train_test_split(df_pca, y, test_size=0.3, random_state=42, stratify=y)","410dd0d9":"lr = LogisticRegression(max_iter=1000,random_state=0)\nlr.fit(X_train, y_train)","524de602":"y_test_predicted = lr.predict(X_test)\ny_train_predicted = lr.predict(X_train)","a2dfb8f6":"accuracy_train = accuracy_score(y_train, y_train_predicted)\naccuracy_test = accuracy_score(y_test, y_test_predicted)\nprint('Train Set Accuracy for Power Transformed Data:',round(accuracy_train*100,2),'%')\nprint('Test Set Accuracy for Power Transformed Data:',round(accuracy_test*100,2),'%')","628ab272":"kf= KFold(shuffle=True, n_splits=5, random_state=0)\nscore = cross_val_score(lr, df_pca, y, cv=kf, scoring='f1_weighted')\nprint('Bias Error:',1-np.mean(score))\nprint('Variance Error:',np.std(score,ddof=1))","401bf2ea":"cm = confusion_matrix(y_test, y_test_predicted)\nprint(cm)","c18584e6":"print(classification_report(y_test,y_test_predicted))","2a20dfcb":"from sklearn.naive_bayes import GaussianNB","ecfc3c85":"nb = GaussianNB()\nscore = cross_val_score(nb, df_pca, y, cv=kf, scoring='f1_weighted')\nprint('Bias Error:',1-np.mean(score))\nprint('Variance Error:',np.std(score,ddof=1))","b2d85d38":"nb.fit(X_train,y_train)","f6ca5440":"y_train_predicted = nb.predict(X_train)\ny_test_predicted = nb.predict(X_test)\n\naccuracy_train = accuracy_score(y_train, y_train_predicted)\naccuracy_test = accuracy_score(y_test, y_test_predicted)\n\nprint('Train Set Accuracy for Power Transformed Data:',round(accuracy_train*100,2),'%')\nprint('Test Set Accuracy for Power Transformed Data:',round(accuracy_test*100,2),'%')","b7f127b4":"print(confusion_matrix(y_test, y_test_predicted))","3c1dee2a":"print(classification_report(y_test, y_test_predicted))","5fcd6cd7":"## Monetary\nMonetary attribute answers the question: **How much money did the customer spent over time?**\n\nTo do that, first, we will create a new column total cost to have the total price per invoice.","75107342":"Now that we knew our customers segments we can choose how to target or deal with each segment.\n\nFor example:\n\n**Best Customers - Champions**: Reward them. They can be early adopters to new products. Suggest them to share your products with their friends or family using \"Referral Program\" feature and when any of their referrals make their first purchase then they will also get some cashback or discount on products. It will help to increase conversion rates.\n\n**Loyal Customers and Big Spenders**: Recommend your annual or quarterly membership program to them with additional benefits. By doing so, they will shop more frequently and for more amount.  \n\n**Customers at the risk of churning**: Suggest your \"Referral Program\" and \"Annual Membership Program\" both to prevent these customers from churning as they were frequent and high spenders in the past. These should be focussed upon more.\n\n**Almost Churned Customers**: Send them personalized emails and encourage them to shop. Along with that, recommend your top benefits program as they were also the best customers in the past.\n\n**Churned Customers**: They probably bought once or very few times and they bought for very less amount. These should not be focussed more as they are already churned.","972bf32c":"Best Recency score = 4: most recently purchased. <br>\nBest Frequency score = 4: most quantity purchase. <br>\nBest Monetary score = 4: spent the most.\n\nLet's see who are our **Champions** (Top 10 customers).","7a713441":"#### We observe that the revenue generated by 20% of the top customers is somewhat less than 80% of the total revenue. However, these two numbers are not exactly the same always but they are very close to each other in our case. So, it gave us a good indication of Pareto's rule holding true.","ab0f2dbb":"### *Inferences:*\n- All the features are highly right skewed.","5d7bff9e":"# Create RFM Table","34220204":"### *Inferences:*\n- There is high positive correlation between Frequency and Monetary features after applying Power transformation.","537661bf":"### Applying RFM Score Formula","225ebd75":"### Creation of RFM segmentation table","5283d74e":"**How many customers do we have in each segment?**","33cb61a2":"## Customer segments with RFM Model\nBefore moving to customer segments, Let's see the application of Pareto Principle \u2013 commonly referred to as the 80-20 rule on our dataset by applying it to our RFM variables.\n\nPareto\u2019s rule says **80% of the results come from 20% of the causes**.\n\nSimilarly, **20% customers contribute to 80% of your total revenue**. Let's verify that because that will help us know which customers to focus on when marketing new products.","1e7ef810":"### Dropping the rows with null values in CustomerID column","16d703b0":"### Conclusion\nTo gain even further insight into customer behavior, we can dig deeper in the relationship between RFM variables.  \n\nRFM model can be used in conjunction with certain predictive models like **K-means clustering**, **Logistic Regression** and **Recommendation Engines** to produce better informative results on customer behavior.\n\nWe will go for K-means since it has been widely used for Market Segmentation and it offers the advantage of being simple to implement.","08927d85":"The simplest way to create customers segments from RFM Model is to use **Quartiles**. We assign a score from 1 to 4 to Recency, Frequency and Monetary. Four is the best\/highest value, and one is the lowest\/worst value. A final RFM score is calculated simply by combining individual RFM score numbers.\n\nNote: Quintiles (score from 1-5) offer better granularity, in case the business needs that but it will be more challenging to create segments since we will have 5 * 5 * 5 possible combinations. So, we will use quartiles.","5d9195b9":"### Checking the null values in the dataset","b125a86e":"We will create two segmentation conditions, one for recency and other for fequency and monetary. It's because high recency is bad, while high frequency and monetary value is good.","10c91db3":"- #### Precision = TruePositives \/ (TruePositives + FalsePositives)\n\n- #### Recall = TruePositives \/ (TruePositives + FalseNegatives)","a3dee04c":"### Removing the cancelled orders from the dataset","58ac89aa":"#### Inferences:\n- **Loyal Customers and Big Spenders**: Reward them. They can be early adopters to new products. Suggest them to share your products with their friends or family using \"Referral Program\" feature and when any of their referrals make their first purchase then they will also get some cashback or discount on products. It will help to increase conversion rates. Recommend your annual or quarterly membership program to them with additional benefits. By doing so, they will shop more frequently and for more amount.\n\n- **Customers Churned**: They probably bought once or very few times and they bought for very less amount. These should not be focussed more as they are already churned.\n\n- **Customers at the risk of churning**: Suggest your \"Referral Program\" and \"Annual Membership Program\" both to prevent these customers from churning as they were frequent and high spenders in the past. These should be focussed upon the most to avoid churning.\n\n- **New customers or Average Spenders**: Customers in this category are either new customers who shopped recently but they didn't spend much or the customers who shop frequently but spend very less amount. These customers should also be focussed more as they can turn out to be the best customers in the future by giving them relevant offers and discounts so that they will shop for more and more.","1440a5f8":"### *Inferences:*\n- We observe from the elbow plot a sharp bend after the number of clusters increase by 2.\n- Silhoutte Score is also the highest for 2 clusters.\n- But, there is also a significant reduce in cluster error as number of clusters increase from 2 to 4 and after 4, the reduction is not much.\n- So, we will choose n_clusters = 4 to properly segment our customers.","0e73ae73":"Now that we have the score of each customer, we can represent our customer segmentation.<br>\nFirst, we need to combine the scores (R_Quartile, F_Quartile,M_Quartile) together.","4ac4c212":"# RFM Analysis\nRFM (**Recency, Frequency, Monetary**) analysis is a customer segmentation technique that uses past purchase behaviour to divide customers into groups. <br> RFM helps divide customers into various categories or clusters to identify customers who are more likely to respond to promotions and also for future personalization services.\n- RECENCY (R): Days since last purchase \n- FREQUENCY (F): Total number of purchases \n- MONETARY VALUE (M): Total money this customer spent.\n\nWe will create those 3 customer attributes for each customer.","d61e4830":"#### Around 25% of transactions do not have a CustomerID and 2.68% of transactions do not have a Description of product.","d329e7d0":"### Applying 80-20 rule","1cdb291d":"### *Inferences:*\n- There is some decent positive correlation between Monetary and Frequency features.","b99fcf7b":"# K-Means Clustering","2d8fd084":"#### RFM Quartiles","b7c9af4a":"## Recency\nTo calculate recency, we need to choose a date point from which we evaluate **how many days ago was the customer's last purchase**.","c1189079":"### Checking duplicate rows in the dataset","82f8fbc9":"## Frequency\nFrequency helps us to know **how many times a customer purchased from us**. To do that we need to check how many invoices are registered by the same customer.","f97ee593":"# Modelling","afb4d733":"## Logistic Regression","b9c61967":"# Conclusion\nWe saw that using classification models like Logisitc Regression and Naive Bayes, we predicted the clusters for customers using RFM dataset as independent variables and Cluster as the target variable. The clusters predicted by the classification models perfectly aligns with K-Means clustering. So, we can conclude that our clusters are correct.","6d9f8d9b":"# PCA\n\nApplying PCA to reduce the the dimensions and the correlation between Frequency and Monetary features.","100af29c":"## Naive Bayes","7253f2f8":"### We will apply Power Transformation to convert these features into a normal distribution."}}