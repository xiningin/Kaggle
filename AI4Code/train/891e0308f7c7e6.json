{"cell_type":{"4a4df77e":"code","8b76ef71":"code","c8cfce29":"code","f91c1c29":"code","9a4c9003":"code","3d6c731d":"code","4150033d":"code","30282fe7":"code","838ee79a":"code","4b9fb58f":"code","dfebc3e2":"code","e22daa96":"code","0eed6704":"code","27513c18":"code","16057461":"code","3023176c":"code","5d5a4984":"markdown","5535be44":"markdown","e62dfe77":"markdown","ec9dd13f":"markdown","cb095b43":"markdown","5d29bbb8":"markdown","9a22e849":"markdown","ccfa3bcf":"markdown","c0a41e68":"markdown","1c7bc19b":"markdown","928f378d":"markdown","0cac9ce7":"markdown","6c35f986":"markdown","625d50cf":"markdown","eee2a37b":"markdown","e26d4915":"markdown","83017dc7":"markdown","1f228b72":"markdown","5078efc7":"markdown","a641c055":"markdown","76aae2c2":"markdown","d7272e7c":"markdown","a5b03717":"markdown","83ca80d9":"markdown","87f0e05d":"markdown"},"source":{"4a4df77e":"#Importing Requierd Libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\n\n# for Interactive Shells\nfrom IPython.display import display\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\n#removing warnings\nimport sys\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n    \n# sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report \n\n# to depict tree_prediction\n! pip install pydotplus\nfrom pydotplus import graph_from_dot_data\nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image\n\n#secrets\nfrom kaggle_secrets import UserSecretsClient\nsecret_label = \"notebook_secret\"\nsecret_value = UserSecretsClient().get_secret(secret_label)","8b76ef71":"#loading data\ntry:\n    df = pd.read_csv('\/kaggle\/input\/avocado-prices\/avocado.csv')\nexcept:\n    df = pd.read_csv('avocado.csv')\n    \n#making a function for examining data\ndef data_research(data, data_name='data'):\n    #basic\n    print(f'Examining \"{data_name}\"')\n    display(data.head())\n    display(data.info())\n    display(data.describe( include='all'))\n    display(data.columns)\n    \n    #duplicates\n    duplicates = data.duplicated().sum()\n    if duplicates > 0:\n        print('There are no duplicated entries.')\n    else:\n        print(f'There are {duplicates} duplicates.')\n        \n    #missing\n    data_missing = pd.DataFrame(round(data.isnull().sum() \/ data.shape[0] * 100, 2))\n    if data_missing[0].sum() > 0:\n        print(f'Missing values in the \"{data_name}\":')\n        data_missing.plot(kind='bar')\n    else:\n        print(f'There are no missing values in \"{data_name}\".')\n    \n    #unique values\n    for i in data.columns:\n        if data[i].dtype == 'object' or data[i].dtype == 'str':\n            print(data[i].unique())\n    \ndata_research(df, data_name='Avocado dataset')","c8cfce29":"df.columns = df.columns.str.lower()\ndf.drop('unnamed: 0', axis=1, inplace=True)\ndf.columns","f91c1c29":"for i in df.columns:\n    if i == 'date':\n        df[i] = df[i].astype('datetime64[ns]')\n    elif df[i].dtype == 'object':\n        df[i] = df[i].astype('category')\n\nnumeric_columns = ['averageprice', 'total volume',\n                   '4046', '4225', '4770',\n                   'total bags', 'small bags',\n                   'large bags', 'xlarge bags']\ncategorical_columns = ['region', 'type']\ndata_columns = ['data', 'year']\ndisplay(df.info())","9a4c9003":"# distributions\ndef dist_custom(dataset, columns_list, rows, cols, suptitle):\n    fig, axs = plt.subplots(rows, cols,figsize=(16,16))\n    fig.suptitle(suptitle,y=0.92, size=16)\n    axs = axs.flatten()\n    for i, data in enumerate(columns_list):\n        sns.distplot(dataset[data], ax=axs[i])\n        axs[i].set_title(data + ', skewness is '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))\n        \ndist_custom(dataset=df, columns_list=numeric_columns, rows=3, cols=3, suptitle='Distibution for each variable')","3d6c731d":"# outliers\ndef boxplots_custom(dataset, columns_list, rows, cols, suptitle):\n    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(16,12))\n    fig.suptitle(suptitle,y=0.93, size=16)\n    axs = axs.flatten()\n    for i, data in enumerate(columns_list):\n        if i % 3 == 0:\n            axs[i].set_ylabel('The number of entries')\n        sns.boxplot( data=dataset[data], orient='h', ax=axs[i])\n        axs[i].set_title(data)\n        \nboxplots_custom(dataset=df, columns_list=numeric_columns, rows=3, cols=3, suptitle='Boxplots before deleting outliers')","4150033d":"# deleting outliers\nQ1 = df[numeric_columns].quantile(0.25)\nQ3 = df[numeric_columns].quantile(0.75)\nIQR = Q3 - Q1\nprint('Here we will get IQR for each column\\n',IQR)\n\ndf_filtered = df[~((df[numeric_columns] < (Q1 - 1.5 * IQR)) |(df[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\ndisplay(df_filtered.shape)","30282fe7":"boxplots_custom(dataset=df_filtered, \n                columns_list=numeric_columns, \n                rows=3, cols=3, suptitle='Boxplots after deleting outliers')","838ee79a":"df_filtered['month'] = df_filtered['date'].astype('datetime64[M]')\ndf_filtered['week'] = df_filtered['date'].astype('datetime64[W]')\nbins = [0.48, 1.52, 1.78, 1.9, 2.49]\nlabels = [\"low\",\"mean\",\"high\",'expensive']\ndf_filtered['price_types'] = pd.cut(df['averageprice'], bins=bins, labels=labels)\ndf_filtered.head()","4b9fb58f":"# Initialize figure with subplots\nfig = make_subplots(\n    rows=2, cols=2, subplot_titles=(\"Daily average prices\", \"Weekly average prices\",\n                                    \"Monthly average prices\", \"Average prices per years\")\n                                        )\n\ndatasets = []\nfor i in ['date','week','month','year']:\n    datasets.append(round(df_filtered.groupby(i)['averageprice'].mean().reset_index(),3))\nr, c = 1,1 #rows, cols\n    \nfor i, d in enumerate(datasets):\n    # Add traces\n    fig.add_trace(go.Scatter(x=d.iloc[:,0], y=d['averageprice']), row=r, col=c)\n    fig.update_xaxes(title_text='Per ' + d.iloc[:,0].name,row=r, col=c)\n    fig.update_yaxes(title_text=\"The sum of avarage price\", row=r, col=c)\n    if i == 1:\n        r, c = 2, 1\n    else:\n        c += 1\n    \n# Update title and height\nfig.update_layout(showlegend=False, title_text=\"Customizing Subplot Axes\", height=700)\n\nfig.show()","dfebc3e2":"# Initialize figure with subplots\nfig = make_subplots(\n    rows=1, cols=2, subplot_titles=(\"Daily average prices\", \n                                    \"Monthly average prices\"))\n\ndatasets = []\nfor i in ['date','month']:\n    for j in ['conventional', 'organic']:\n        datasets.append(round(df_filtered.query('type == @j').groupby(i)['averageprice'].mean().reset_index(),3))\nr, c = 1,1\nlegend_ = ['conventional', 'organic']\nfor i, d in enumerate(datasets):\n    # Add traces\n    fig.add_trace(go.Scatter(x=d.iloc[:,0], y=d['averageprice'], name=legend_[i%2]+' per ' + d.iloc[:,0].name), row=r, col=c)\n    fig.update_xaxes(title_text='Per ' + d.iloc[:,0].name,row=r, col=c)\n    fig.update_yaxes(title_text=\"The sum of avarage price\", row=r, col=c)\n    if i == 1:\n        c += 1\n    \n# Update title and height\nfig.update_layout(showlegend=True, title_text=\"Daily and monthly avarage prices for conventional and organic types\", height=700)\n\nfig.show()","e22daa96":"# histograms\nparam_graphs = df_filtered.hist(numeric_columns, figsize=(16, 10), bins=20)\nplt.suptitle(\"Hists after removing outliers\", y=0.96, size=16)\nfor axis in param_graphs.flatten():\n    axis.set_ylabel('frequency')\nplt.show()","0eed6704":"columns_for_research = ['averageprice', 'total volume', '4046','4225','4770', 'type']\ng = sns.pairplot(data=df_filtered[columns_for_research], hue=\"type\")\ng.fig.suptitle(\"Distributions and scatter plots for each variable depending on type\", y=1.01, size=16)\nfor ax in g.axes.flat: \n    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.show()","27513c18":"ten_largest_volume_regions = df_filtered.groupby(['region'])['total volume'].sum().sort_values(ascending=False).reset_index().head(10)\nfig = px.bar(ten_largest_volume_regions,x='region', y='total volume', title='Top ten regions with the greatest total volume over the time')\nfig.show()","16057461":"df_count_type = df_filtered.groupby(['price_types', 'type'])['date'].count().reset_index()\n\nplt.figure(figsize=(10, 5))\nsns.countplot(x='price_types', alpha=0.7, hue='type', \n                  data=df_filtered)\nplt.legend( bbox_to_anchor=(1.1, 1.1), loc='upper left')\nplt.xlabel('Price types'), plt.ylabel('Amount')\nplt.title('Relation between type and average price', size=16, y=1.01);","3023176c":"# calculating the correlation matrix\ncorr = df_filtered.corr()\nmatrix = np.triu(corr)\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr, vmax=1.0, vmin=-1.0, \n            fmt='.1g', annot=True, mask = matrix)\n\nplt.title('Correlation matrix', size=16)\nplt.show()","5d5a4984":"><div style=\"background-color: #FBFFEE;\">\n><div style=\"font-weight: bold;font-size:20px\">Observations:<\/div>\n><ul style=\"font-size:18px;\">\n From the lineplots above:\n><li>At the daily and monthly average price we see  a decline in price in January 2016-2017 y. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops; <\/li>\n><li>At the average price per year chart we see a steady decline from 2015 to 2016 y. <\/li>\n><li>  After that there is an increase, the peak is in 2017 year.<\/li>\n><\/ul>\n><\/div>","5535be44":"><div style=\"font-size:16px\">2.2.2 Categorical columns<\/div>\nBarplots","e62dfe77":"><div style=\"background-color: #FBFFEE;\">\n><div style=\"font-weight: bold;font-size:20px\">Conclusion:<\/div>\n><ul style=\"font-size:18px;\">\n> At this stage:\n><li> examined the data;<\/li>\n><li> renamed column name and drop the unecessary column 'Unnamed: 0';<\/li>\n><li> changed dtypes;<\/li>\n><li> observed the kind of disributions and calculated the skewness value for each numeric column;<\/li>\n><li> plotted boxcharts before and after removing outliers;<\/li>\n><li> added new columns for the further research.<\/li>\n>Now we're going to make Exploratory Data Analysis\u27a1\n><\/ul>\n><\/div>","ec9dd13f":"<a id=\"sub-31\"><\/a>\n><div style=\"font-weight: bold;font-size:20px\">2.1 Research of daily, monthly and per year average price<\/div>\n><div style=\"font-size:16px\">\nLet's create new dataset with avarage avocado price per day, month and year. After that we'll create lineplots with the use of plotly.express and analyze it<\/div>","cb095b43":"<a id=\"sub-32\"><\/a>\n><div style=\"font-weight: bold;font-size:20px\">2.2 Examining features<\/div>\n><div style=\"font-size:16px\"> At this step we'll analyse the categorical and numeric variables<\/div>","5d29bbb8":"><div style=\"font-size:16px\">2.2.1 Numeric columns<\/div>\nHistograms, scatterplots","9a22e849":"><div style=\"background-color: #FBFFEE;\">\n><div style=\"font-weight: bold;font-size:20px\">Observations:<\/div>\n><ul style=\"font-size:18px;\">\n From the lineplots above:\n><li>At the daily and monthly average price we see  a decline in price in January 2016-2017 y. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops; <\/li>\n><li>At the average price per year chart we see a steady decline from 2015 to 2016 y. <\/li>\n><li>  After that there is an increase, the peak is in 2017 year.<\/li>\n><\/ul>\n><\/div>","ccfa3bcf":"<a id=\"section-end\"><\/a>\n<div style=\"font-size:40px\" align=center>Work in Progress\n<img src=\"https:\/\/i.pinimg.com\/564x\/9a\/42\/79\/9a4279006e123929b83ad139c42c5da6.jpg\" width=50>\n\n<\/div>\n\n><div style=\"background-color: #FBFFEE;\">\n><ul style=\"font-size:20px;\">\n <b>Thank you<\/b> so much for reading my project. \n <br>Please, UPvote, if you like it or find it usefull!\ud83c\udf40\n\n><\/ul>\n><\/div>","c0a41e68":"Distributions  and scatter plot for each variable according to type variable","1c7bc19b":"<a id=\"sub-33\"><\/a>\n><div style=\"font-weight: bold;font-size:20px\">2.3 The Correlation matrix<\/div>\n><div style=\"font-size:16px\"> Correlation matrix depicts the correlation coefficients between all pairs of features in the data.\n>\n> We use the Pearson correlation coefficient, which is a measure of the linear association between two variables. It has a value between -1 and 1 where:\n>\n><li>-1 indicates a perfectly negative linear correlation between two variables<\/li>\n><li>0 indicates no linear correlation between two variables<\/li>\n><li>1 indicates a perfectly positive linear correlation between two variables<\/li><\/div>","928f378d":"<a id=\"section-end\"><\/a>\n<div style=\"font-weight: bold;font-size:40px\">The overall conclusion<\/div>\n\n><div style=\"background-color: #FBFFEE;\">\n><ul style=\"font-size:20px;\">\n\n\n><\/ul>\n><\/div>","0cac9ce7":"><div style=\"background-color: #FBFFEE;\">\n><div style=\"font-weight: bold;font-size:20px\">Observations<\/div>\n><ul style=\"font-size:18px;\">\n>\n>Looks much better now! But nevertheless we see some outliers even in filtered data. It will be great to scale the features at the step of building model.\nWe'll use filtered data further\n> \n><\/ul>\n><\/div>","6c35f986":" <div style=\"font-size:16px\">For Skewed distributions we'll use Inter-Quartile Range (IQR) proximity rule.<\/div>","625d50cf":"><div style=\"background-color: #FBFFEE;\">\n><div style=\"font-weight: bold;font-size:20px\">Observations<\/div>\n><ul style=\"font-size:18px;\">\n><center><img src=\"https:\/\/i.pinimg.com\/originals\/c2\/1e\/cb\/c21ecb47122ea4d8eeab4d9ae968cc36.jpg\", width=650><\/center>\nWe've examined data:\n<br>- There are 18249 entries and 14 columns, one column is an index, so it is needed to drop it;\n<br>- No missing or duplicated values and errors (at the first glance), all unique values are correct and don't repeat;\n<br>- There are some columns, which datatypes are should be changed.<br>\nAt the next step we'll study and preprocess outliers, rename column names and change datatypes.\n><\/ul>\n><\/div>","eee2a37b":"<a id=\"sub-22\"><\/a>\n<div style=\"font-weight: bold;font-size:20px\">1.2 Data preproccessing<\/div>","e26d4915":"<a id=\"sub-21\"><\/a>\n<div style=\"font-weight: bold;font-size:20px\">1.1 Basic information<\/div>","83017dc7":"><div style=\"background-color: #FBFFEE;\">\n><div style=\"font-weight: bold;font-size:20px\">BIG observations about all the above:<\/div>\n><ul style=\"font-size:18px;\">\n><li>At the daily and monthly average price we see  a decline in price in January 2016-2017 y. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops; <\/li>\n><li>At the average price per year chart we see a steady decline from 2015 to 2016 y. <\/li>\n><li>  After that there is an increase, the peak is in 2017 year.<\/li>\n><\/ul>\n><\/div>","1f228b72":"<div style=\"font-weight: bold;font-size:16px\">1.2.1 Renaming columns and drop the unecessary one<\/div>","5078efc7":"<div style=\"font-weight: bold;font-size:16px\">1.2.3 Getting known with the kind of distrubutions<\/div>","a641c055":"<a id=\"section-three\"><\/a>\n<div style=\"font-weight: bold;font-size:30px\">Step 2: EDA<\/div>","76aae2c2":"<div style=\"font-size:16px\">\n<b>Conclusion:<\/b> all features are skewed to the left, there is no Normal Distribution.\n\nLet's examine outliers with the use of boxplots.<\/div>\n","d7272e7c":"<a id=\"section-two\"><\/a>\n<div style=\"font-weight: bold;font-size:30px\">Step 1: Examining Data<\/div>","a5b03717":"<div style=\"font-weight: bold;font-size:16px\">1.2.2 Changing data types<\/div>","83ca80d9":"<a id=\"sub-23\"><\/a>\n<div style=\"font-weight: bold;font-size:20px\">1.3 Making additional columns to filtered data<\/div>\n\nWe already have information about day and year of price scanning, nor let's add additional columns for the further cohort research:\n- week;\n- month.","87f0e05d":"<div style=\"font-weight: bold;font-size:40px\">Introduction<\/div>\n\n><div style=\"background-color: #FBFFEE;\">\n><ul style=\"font-size:20px;\">\n Hello everyone!\n>    \n>    I believe that the best approach to learn is to learn what you're passionate about.\n>So, I'm passionate about healthy food \ud83e\udd51 Let's learn together and investigate avocado prices!\n>We will discover this question with the use of EDA (the second step) and ML methods (the third step).\n>    \n>Many thanks to the \u0441reator of this dataset,\n><br>If you like this project, please, support me - UPvote!\ud83d\ude03\n\n<center><img src=\"https:\/\/i.pinimg.com\/564x\/cf\/c4\/f1\/cfc4f1cfd6d9af866b8cd3ace353b6d5.jpg\" width=300><\/center>\n\n\n<\/ul>\n<\/div>\n\n\n<div style=\"font-weight: bold;font-size:30px\">Data columns description & libraries<\/div>\n\n><div style=\"background-color: #FBFFEE;\">\n><ul style=\"font-size:18px;\">\n<li> Date - The date of the observation<\/li>\n<li> AveragePrice - the average price of a single avocado<\/li>\n<li> type - conventional or organic<\/li>\n<li> year - the year<\/li>\n<li> Region - the city or region of the observation<\/li>\n<li> Total Volume - Total number of avocados sold<\/li>\n<li> 4046 - Total number of avocados with PLU 4046 sold<\/li>\n<li> 4225 - Total number of avocados with PLU 4225 sold<\/li>\n<li> 4770 - Total number of avocados with PLU 4770 sold<\/li>\n<\/ul>\n<\/div>\n\n<br><div style=\"font-weight: bold;font-size:30px\">Table of Contents<\/div>\n\n* [Step 1: Examining Data](#section-two)\n    - [Basic information](#sub-21)\n    - [Data preproccessing](#sub-22)\n    - [Making additional columns](#sub-23)\n\n* [Step 2: EDA](#section-three)\n    - [2.1 Research of daily, monthly and per year average price](#sub-31)\n    - [2.2 Examining features](#sub-32)\n    - [2.3 The correlation matrix](#sub-33)\n    \n* [Step 3: Regression](#section-four)\n    - [2.1 Research of daily, monthly and per year average price](#sub-31)\n    - [2.2 Examining features](#sub-32)\n    - [2.3 The correlation matrix](#sub-33)\n* [Overall Conclusion](#section-end)\n    "}}