{"cell_type":{"f5bc57f0":"code","c5ccc744":"code","d9a3bc81":"code","b16c17b4":"code","7063199f":"code","fb9e5cd5":"code","452c152f":"code","3519ee88":"code","0a36dabd":"code","0950a584":"code","77e6ce95":"code","cd6ecbb7":"code","e4eb6b3a":"code","a28dee4b":"code","a56eea77":"code","6494c6f7":"code","3e27cf2d":"code","e1fdd689":"code","d4d10261":"code","31026310":"code","ddd3cf49":"code","1d4de3b3":"code","76ceab63":"markdown","ebe48c50":"markdown","0d9d5b2e":"markdown","d2dcdb94":"markdown","62645c6c":"markdown","d3635fd9":"markdown","cb072232":"markdown","f4d363e4":"markdown","46c07e42":"markdown","58820b2c":"markdown","8d7524a3":"markdown","aa6f0fd2":"markdown","abd7c6dd":"markdown","21493557":"markdown","199856e7":"markdown","26d88792":"markdown","33f7625e":"markdown"},"source":{"f5bc57f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c5ccc744":"import numpy as np \nimport pandas as pd\nimport pandas\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n%matplotlib inline\nimport seaborn as sns; sns.set()\n\nfrom sklearn import tree\nimport graphviz \nimport os\nimport preprocessing \n\nimport numpy as np \nimport pandas as pd \nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nfrom pandas_profiling import ProfileReport\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, f_classif\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\n\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom xgboost import plot_tree, plot_importance\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d9a3bc81":"dataset = pandas.read_csv('\/kaggle\/input\/fifa-world-cup\/WorldCups.csv')\ndataset.sample(10)","b16c17b4":"dataset.info()","7063199f":"def bar_plot(variable):\n    # get feature\n    var = dataset[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    if variable == \"Attendance\":\n        varValue = varValue[:15]\n    \n    # visualize\n    plt.figure(figsize = (20,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}:\\n{}\".format(variable,varValue))","fb9e5cd5":"categorical = (dataset.dtypes == \"object\")\ncategorical_list = list(categorical[categorical].index)\n\nprint(\"Categorical variables:\")\nprint(categorical_list)","452c152f":"sns.set_style('darkgrid')\nfor c in categorical_list:\n    bar_plot(c)","3519ee88":"numerical_int64 = (dataset.dtypes == \"int64\")\nnumerical_int64_list = list(numerical_int64[numerical_int64].index)\n\nprint(\"Numerical variables:\")\nprint(numerical_int64_list)","0a36dabd":"def plot_hist(variable):\n    plt.figure(figsize = (20,3))\n    plt.hist(dataset[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} Distribution with Histogram\".format(variable))\n    plt.show()","0950a584":"for n in numerical_int64_list:\n    plot_hist(n)","77e6ce95":"plt.figure(figsize=(25,15))\n\nplt.subplot(2,2,1)\nsns.histplot(dataset['Year'], color = 'red', kde = True).set_title('Year Interval and Counts')\n\nplt.subplot(2,2,2)\nsns.histplot(dataset['GoalsScored'], color = 'green', kde = True).set_title('GoalsScored Interval and Counts')\n\nplt.subplot(2,2,3)\nsns.histplot(dataset['QualifiedTeams'], kde = True, color = 'blue').set_title('QualifiedTeams Interval and Counts')\n\nplt.subplot(2,2,4)\nsns.histplot(dataset['MatchesPlayed'], kde = True, color = 'black').set_title('MatchesPlayed Interval and Counts')","cd6ecbb7":"features = dataset.columns\nsns.set_style('darkgrid')\nsns.pairplot(dataset[features])","e4eb6b3a":"sns.pairplot(dataset, hue = 'Winner')","a28dee4b":"dataset.corr()","a56eea77":"plt.figure(figsize=(12,8)) \nsns.heatmap(dataset.corr(), annot=True, cmap='Dark2_r', linewidths = 2)\nplt.show()","6494c6f7":"sns.set_style('darkgrid')\naxes = pandas.plotting.scatter_matrix(dataset, alpha = 0.3, figsize = (10,7), diagonal = 'kde' ,s=80)\ncorr = dataset.corr().values\n\nplt.xticks(fontsize =10,rotation =0)\nplt.yticks(fontsize =10)\nfor ax in axes.ravel():\n    ax.set_xlabel(ax.get_xlabel(),fontsize = 15, rotation = 60)\n    ax.set_ylabel(ax.get_ylabel(),fontsize = 15, rotation = 60)\n# put the correlation between each pair of variables on each graph\nfor i, j in zip(*np.triu_indices_from(axes, k=1)):\n    axes[i, j].annotate(\"%.3f\" %corr[i, j], (0.8, 0.8), xycoords=\"axes fraction\", ha=\"center\", va=\"center\")","3e27cf2d":"plt.figure(figsize=(20,15))\nplt.subplot(2,2,1)\nsns.barplot(x = 'Winner', y = 'Year', data = dataset, palette=\"cubehelix\")\nplt.subplot(2,2,2)\nsns.barplot(x = 'Winner', y = 'GoalsScored', data = dataset, palette=\"Oranges\")\nplt.subplot(2,2,3)\nsns.barplot(x = 'Winner', y = 'QualifiedTeams', data = dataset, palette=\"Oranges\")\nplt.subplot(2,2,4)\nsns.barplot(x = 'Winner', y = 'MatchesPlayed', data = dataset, palette=\"cubehelix\")","e1fdd689":"\nplt.figure(figsize=(20,15))\nplt.subplot(2,2,1)\nsns.barplot(x = 'Winner', y = 'Year', data = dataset, palette=\"rocket_r\")\nplt.subplot(2,2,2)\nsns.barplot(x = 'Winner', y = 'GoalsScored', data = dataset, palette=\"rocket_r\")\nplt.subplot(2,2,3)\nsns.barplot(x = 'Winner', y = 'QualifiedTeams', data = dataset, palette=\"rocket_r\")\nplt.subplot(2,2,4)\nsns.barplot(x = 'Winner', y = 'MatchesPlayed', data = dataset, palette=\"rocket_r\")\n","d4d10261":"\nplt.figure(figsize=(20,15))\nplt.subplot(2,2,1)\nsns.barplot(x = 'Winner', y = 'Year', data = dataset, palette=\"gist_ncar_r\")\nplt.subplot(2,2,2)\nsns.barplot(x = 'Winner', y = 'GoalsScored', data = dataset, palette=\"gist_ncar_r\")\nplt.subplot(2,2,3)\nsns.barplot(x = 'Winner', y = 'QualifiedTeams', data = dataset, palette=\"gist_ncar_r\")\nplt.subplot(2,2,4)\nsns.barplot(x = 'Winner', y = 'MatchesPlayed', data = dataset, palette=\"gist_ncar_r\")\n\n","31026310":"plt.figure(figsize=(20,15))\nplt.subplot(2,2,1)\nsns.distplot(dataset['Year'], color=\"red\").set_title('Year Interval')\nplt.subplot(2,2,2)\nsns.distplot(dataset['GoalsScored'], color=\"green\").set_title('GoalsScored Interval')\nplt.subplot(2,2,3)\nsns.distplot(dataset['QualifiedTeams'], color=\"blue\").set_title('QualifiedTeams Interval')\nplt.subplot(2,2,4)\nsns.distplot(dataset['MatchesPlayed'], color=\"black\").set_title('MatchesPlayed Interval')","ddd3cf49":"plt.figure(1, figsize=(5,5))\nplt.title(\"Distribution of Winners\")\ndataset['Winner'].value_counts().plot.pie(autopct=\"%1.1f%%\")","1d4de3b3":"import pandas_profiling as pp\npp.ProfileReport(dataset)","76ceab63":"<a id=\"2\"><\/a> \n# L\u00ea e apresenta informa\u00e7\u00f5es sobre o Dataset","ebe48c50":"A proposta deste dabook \u00e9 explorar ferramentas de visualiza\u00e7\u00e3o de dados e datasets dos Kaggle.","0d9d5b2e":"<a id=\"6\"><\/a> \n### Vari\u00e1veis Num\u00e9ricas","d2dcdb94":"<a id=\"4\"><\/a> \n## An\u00e1lise das Vari\u00e1veis","62645c6c":"### D\u00favidas, pergunte no final. D\u00ea seu feedback :-)","d3635fd9":"<a id=\"8\"><\/a> \n# Visualiza\u00e7\u00e3o","cb072232":"<a id=\"16\"><\/a> \n# Conclusion","f4d363e4":"Neste databook foi examinado o DataSet Fifa World Cups: an\u00e1lise explorat\u00f3ria dos dados e visualiza\u00e7\u00e3o. \n","46c07e42":"*** Categorical Variables:** ['Species']\n\n*** Numerical Variables:** ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']","58820b2c":"<a id=\"9\"><\/a> \n# PERFIL Pandas","8d7524a3":"<a id=\"1\"><\/a> \n# Importando Bibliotecas Necess\u00e1rias","aa6f0fd2":"Content:\n\n1. [Importing the Necessary Libraries](#1)\n1. [Read Datas & Explanation of Features & Information About Datasets](#2)\n   1. [Variable Descriptions](#3)\n   1. [Univariate Variable Analysis](#4)\n      1. [Categorical Variables](#5)\n      1. [Numerical Variables](#6)\n1. [Correlation](#7)\n1. [Data Visualization](#8)\n1. [Pandas Profiling](#9)\n1. [Conclusion](#10)      ","abd7c6dd":"<a id=\"7\"><\/a> \n# Correla\u00e7\u00e3o","21493557":"<a id=\"3\"><\/a> \n## Descri\u00e7\u00e3o das Vari\u00e1veis","199856e7":"Pandas profiling \u00e9 uma biblioteca bem \u00fatil que gera relat\u00f3rios sobre os dados. Com ele pode-se recuperar os tipos de dados, sua  distribui\u00e7\u00e3o e v\u00e1rias informa\u00e7\u00f5es estat\u00edsticas. A ferramenta tem muitas t\u00e9cnicas para preapra\u00e7\u00e3o dos dados. Bibliotecas gr\u00e1ficas envolvendo mapas de caracter\u00edsticas e correla\u00e7\u00e3o. Mais detalhes em: https:\/\/pandas-profiling.github.io\/pandas-profiling\/docs\/master\/rtd\/","26d88792":"# Explorando An\u00e1lise de Dados no Dataset Fifa World Cups usando o Kaggle e Colab","33f7625e":"<a id=\"5\"><\/a> \n### Vari\u00e1veis Categ\u00f3ricas"}}