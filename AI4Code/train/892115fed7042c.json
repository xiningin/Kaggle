{"cell_type":{"11de6ce9":"code","ccfb1df3":"code","e3fc18fd":"code","b202bd3a":"code","a414ff2e":"code","51c7f918":"code","11e45db0":"code","b28ba767":"code","58027125":"code","fe4f7817":"code","1aa76355":"code","817861bb":"code","871670b8":"code","a85ed3d5":"code","a308da24":"code","ea56616d":"code","32a678a6":"code","c865b501":"code","90cd0959":"code","ee8f6f6e":"code","2d6fdad0":"code","e6ea53f6":"code","8a20f611":"code","cfc242f9":"code","9014349e":"code","0a210328":"code","de0821ca":"code","0106f159":"code","b87f1be9":"markdown","6bb70f2b":"markdown","f528d5bb":"markdown","86fff36c":"markdown","355e95fd":"markdown","8c76be12":"markdown","60f85d9c":"markdown"},"source":{"11de6ce9":"# Import The Libraries\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import LabelBinarizer, StandardScaler\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.metrics import mean_squared_error , r2_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor","ccfb1df3":"housing = pd.read_csv('..\/input\/california-housing-prices\/housing.csv')\nhousing.head()","e3fc18fd":"# total_bedrooms attribute has nulls\nhousing.info()","b202bd3a":"housing.describe()","a414ff2e":"attributes = ['median_house_value', 'median_income',\n             'total_rooms', 'housing_median_age'] \n             \nplt.figure(figsize=(20, 20))             \nsns.pairplot(housing[attributes])             \nplt.show();","51c7f918":"# good relationship between median_income and median_house_value\nhousing.plot(kind='scatter', x='median_income', y='median_house_value',\n            alpha=0.1, figsize=(8,5))\nplt.show()","11e45db0":"# categorical attribute\nhousing['ocean_proximity'].value_counts()","b28ba767":"housing['rooms_per_household'] = housing['total_rooms']\/housing['households']\nhousing['bedrooms_per_room'] = housing['total_bedrooms']\/housing['total_rooms']\nhousing['population_per_household'] = housing['population']\/housing['households']","58027125":"housing.corr()['median_house_value'].sort_values(ascending=False)","fe4f7817":"housing.columns","1aa76355":"attr_names = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n               'total_bedrooms', 'population', 'households', 'median_income',\n               'ocean_proximity', 'rooms_per_household',\n               'bedrooms_per_room', 'population_per_household']\n\nX = housing[attr_names]\ny = housing['median_house_value']","817861bb":"# split Data 80% train , 20% test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","871670b8":"class DataFrameSelector(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n        \n    def fit(self, X, y=None):return self\n    \n    def transform(self, X):return X[self.attribute_names].values","a85ed3d5":"rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n# this component gives us the flexibility to add extra attributes to our pipeline\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, add_bedrooms_per_room = True):\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    \n    def fit(self, X, y=None):return self\n    \n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] \/ X[:, household_ix]\n        population_per_household = X[:, population_ix] \/ X[:, household_ix]\n        bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n\n        return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n        ","a308da24":"class MyLabelBinarizer(TransformerMixin):\n    \n    def __init__(self, *args, **kwargs):\n        self.encoder = LabelBinarizer(*args, **kwargs)\n    \n    def fit(self, x, y=0):\n        self.encoder.fit(x)\n        return self\n    \n    def transform(self, x, y=0):return self.encoder.transform(x)","ea56616d":"num_attribs = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n       'total_bedrooms', 'population', 'households', 'median_income']\n\ncat_attribs = [\"ocean_proximity\"]","32a678a6":"# our numerical pipeline\nnum_pipeline = Pipeline([\n                    ('selector', DataFrameSelector(num_attribs)),\n                    ('imputer', SimpleImputer(strategy=\"median\")),\n                    ('attribs_adder', CombinedAttributesAdder()),\n                    ('std_scaler', StandardScaler()),\n                ])","c865b501":"# our categorical pipeline\ncat_pipeline = Pipeline([\n    ('selector', DataFrameSelector(cat_attribs)),\n    ('label_binarizer', MyLabelBinarizer()),\n])","90cd0959":"full_pipeline = FeatureUnion(transformer_list=[\n    ('num_pipeline', num_pipeline),\n    ('cat_pipeline', cat_pipeline),\n])","ee8f6f6e":"X_train_prepared = full_pipeline.fit_transform(X_train)","2d6fdad0":"# LinearRegression Model\nlin_reg = LinearRegression()\nscores = cross_val_score(lin_reg, X_train_prepared, y_train,\n                        scoring=\"neg_mean_squared_error\", cv=10)\n\nrmse_scores = np.sqrt(-scores)\nprint(\"Mean:\\t\\t \", rmse_scores.mean(), \"\\nStandard Deviation:\", rmse_scores.std())","e6ea53f6":"# Decision Tree Regressor\ntree_reg = DecisionTreeRegressor()\nscores = cross_val_score(tree_reg, X_train_prepared, y_train,\n                        scoring=\"neg_mean_squared_error\", cv=10)\n\nrmse_scores = np.sqrt(-scores)\nprint(\"Mean:\\t\\t \", rmse_scores.mean(), \"\\nStandard Deviation:\", rmse_scores.std())","8a20f611":"# Gradient Boosting Regressor\ngrad_reg = GradientBoostingRegressor()\nscores = cross_val_score(grad_reg, X_train_prepared, y_train,\n                               scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(\"Mean:\\t\\t \", rmse_scores.mean(), \"\\nStandard Deviation:\", rmse_scores.std())","cfc242f9":"#Random Forest Regressor\nforest_reg = RandomForestRegressor()\nscores = cross_val_score(forest_reg, X_train_prepared, y_train,\n                               scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(\"Mean:\\t\\t \", rmse_scores.mean(), \"\\nStandard Deviation:\", rmse_scores.std())","9014349e":"param_grid = [\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]","0a210328":"forest_reg = RandomForestRegressor()\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                          scoring='neg_mean_squared_error')\ngrid_search.fit(X_train_prepared, y_train)","de0821ca":"cvres = grid_search.cv_results_\nprint(\"{}\\t\\t {}\\n\".format('Mean Score','Parameters'))\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    x = np.sqrt(-mean_score)\n    y = params\n    print(\"{:.2f}\\t {}\".format(x, y))\n  ","0106f159":"final_model = grid_search.best_estimator_\n\nX_test_prepared = full_pipeline.transform(X_test)\ny_pred = final_model.predict(X_test_prepared)\n\nprint('R-Squared:', r2_score(y_test, y_pred))\nprint(\"Root Mean Square Error:\", np.sqrt(mean_squared_error(y_test, y_pred)))","b87f1be9":"# ***Try various ML models***","6bb70f2b":"# **understand the dataset**","f528d5bb":"# ***Evaluate the model on the test set***","86fff36c":"# **Acquire the dataset**","355e95fd":"# **Pre-process the data**","8c76be12":"# pipeline","60f85d9c":"# **Fine tune our model with Hyper parameters**"}}