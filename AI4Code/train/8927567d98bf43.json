{"cell_type":{"c726a3e7":"code","967e3d6c":"code","a92a03b8":"code","76f267c9":"code","2afc41b2":"code","12c5c1e2":"code","ef84103e":"code","702494de":"code","fc19ca5e":"code","d8741670":"code","84cae38a":"markdown"},"source":{"c726a3e7":"import pandas as pd\n\ntrain_positive = pd.read_csv('..\/input\/arabic-sentiment-twitter-corpus\/train_Arabic_tweets_positive_20190413.tsv', sep='\\t', header=None)\ntrain_negative = pd.read_csv('..\/input\/arabic-sentiment-twitter-corpus\/train_Arabic_tweets_negative_20190413.tsv', sep='\\t', header=None)\ntrain = pd.concat([train_positive, train_negative],ignore_index=True )\ntrain.set_axis(['label', 'tweet'], axis=1, inplace=True)\n\ntest_positive = pd.read_csv('..\/input\/arabic-sentiment-twitter-corpus\/test_Arabic_tweets_positive_20190413.tsv', sep='\\t', header=None)\ntest_negative = pd.read_csv('..\/input\/arabic-sentiment-twitter-corpus\/test_Arabic_tweets_negative_20190413.tsv', sep='\\t', header=None)\ntest = pd.concat([test_positive, test_negative],ignore_index=True )\ntest.set_axis(['label', 'tweet'], axis=1, inplace=True)","967e3d6c":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline","a92a03b8":"from sklearn.svm import LinearSVC\n\nvectorizer = CountVectorizer()\nsvc = LinearSVC()\npipeline = make_pipeline(vectorizer, svc)\npipeline.fit(train.tweet, train.label)","76f267c9":"from sklearn import metrics\n\ndef print_report(pipe, x_test, y_test):\n    y_pred = pipe.predict(x_test)\n    report = metrics.classification_report(y_test, y_pred)\n    print(report)\n    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n\nprint_report(pipeline, test.tweet, test.label)","2afc41b2":"# eli5 helps to explore sklearn models.\nimport eli5\n# see weights for each feature.\neli5.show_weights(svc, vec=vectorizer, top=20)","12c5c1e2":"observation = test.iloc[1, :]\nprint(f\"true label: {observation['label']}\")\ndisplay(eli5.show_prediction(svc, observation['tweet'], vec=vectorizer))","ef84103e":"# try tf-idf vectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nTfidf_Vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=.01, max_df=.3)\nsvc = LinearSVC()\npipeline = make_pipeline(Tfidf_Vectorizer, svc)\npipeline.fit(train.tweet, train.label)","702494de":"print_report(pipeline, test.tweet, test.label)","fc19ca5e":"eli5.explain_weights(svc, vec=Tfidf_Vectorizer, top=20)","d8741670":"observation = test.iloc[1, :]\nprint('Actual label', observation['label'])\ndisplay(eli5.show_prediction(svc, observation['tweet'], vec=Tfidf_Vectorizer))","84cae38a":"**<h3>Text Classification<\/h3>**\n**<h5>This notebook contains a simple task of text classification for Arabic <br>\n    tweets using Support Vector Machine<\/h5>**"}}