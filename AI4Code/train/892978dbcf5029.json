{"cell_type":{"b66dbd39":"code","ef0c4428":"code","f2d218be":"code","85798d0d":"code","85ea85b4":"code","4e6f5fdb":"code","5f16fa2c":"code","9d67a6d9":"code","3a914052":"code","cdbd85f8":"code","d3554586":"code","a7204bb8":"code","b3a681ce":"code","bd9b3ad4":"code","81095032":"code","188f995f":"code","52d4b755":"code","29dca450":"code","bbca75b8":"code","75e12e32":"code","67365bf1":"code","3095b45d":"code","8af1881e":"code","451d24a8":"code","b28f9890":"code","dec0bf27":"code","86472e56":"code","74a77077":"code","2d2c6f75":"code","a5fd758a":"code","c6b5e2aa":"markdown","c4c3ba1d":"markdown","2a1dab33":"markdown","5950d91c":"markdown","a7176f20":"markdown","5feff507":"markdown","74678ba6":"markdown","1669710d":"markdown","a4328826":"markdown"},"source":{"b66dbd39":"import numpy as np \nimport pandas as pd\nimport os\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","ef0c4428":"direc = Path('..\/input\/fruits-recognition\/fruits_data\/train')\nfilepaths = list(direc.glob(r'**\/*.jpg'))\nfilename = list(map(lambda x: os.path.split(x)[1],filepaths))\n\n\nfilepaths = pd.Series(filepaths, name='FilePaths').astype(str)\nfilename = pd.Series(filename, name='filename').astype(str)\n\ntrain_imgdf = pd.merge(filepaths, filename, right_index = True, left_index = True)\n\ntrain_imgdf","f2d218be":"labels=pd.read_csv(r'..\/input\/fruits-recognition\/fruits_data\/Training_set.csv')\nlabels","85798d0d":"train_imgdf1 = pd.merge(train_imgdf, labels, on='filename')\ntrain_imgdf1 = train_imgdf1.drop('filename', axis=1)\ntrain_imgdf1","85ea85b4":"import matplotlib.pyplot as plt\nf,a = plt.subplots(nrows=5, ncols=8,figsize=(13, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(a.flat):\n    ax.imshow(plt.imread(train_imgdf1.FilePaths[i]))\n    ax.set_title(train_imgdf1.label[i])\n    \nplt.tight_layout()\nplt.show()","4e6f5fdb":"print(f\" Count of Rows : {train_imgdf1.shape[0]} \\n Count of Columns : {train_imgdf1.shape[1]} \")","5f16fa2c":"train_imgdf2 = train_imgdf1['label'].value_counts(ascending=True)\ntrain_imgdf2 = pd.DataFrame(train_imgdf2).reset_index()\ntrain_imgdf2 = train_imgdf2.rename(columns={\"index\": \"label\", \"label\": \"count\"})\ntrain_imgdf2","9d67a6d9":"x = train_imgdf2['label']\ny = train_imgdf2['count']\nplt.bar(x,y)\nplt.title(\"FRUITES\")\nplt.figure(figsize=(8,5))\nplt.show()","3a914052":"x_train, x_test = train_test_split(train_imgdf1, test_size=0.15, stratify=train_imgdf1['label'])\n\nprint(f'Shape of Training Data : ',x_train.shape)\nprint(f'Shape of Testing Data : ',x_test.shape)","cdbd85f8":"img_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n\nimg_size=(224, 224)    \n\nx_train = img_datagen.flow_from_dataframe(dataframe = x_train, x_col='FilePaths', y_col='label', target_size=img_size, color_mode='rgb',class_mode='categorical',batch_size=32,seed=42)\nx_test = img_datagen.flow_from_dataframe(dataframe = x_test, x_col='FilePaths', y_col='label', target_size=img_size,color_mode='rgb',class_mode='categorical',batch_size=32,seed=42)","d3554586":"model = keras.Sequential([\n\n    # First Convolutional Block\n    tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n                  # give the input dimensions in the first layer\n                  # [height, width, color channels(RGB)]\n                 input_shape=[224, 224, 3]),\n    tf.keras.layers.MaxPool2D(),\n\n    # Second Convolutional Block\n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n    tf.keras.layers.MaxPool2D(),\n\n    # Third Convolutional Block\n    tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n    tf.keras.layers.MaxPool2D(),\n\n    # Classifier Head\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation=\"relu\"),\n    tf.keras.layers.Dense(131, activation=\"softmax\"),\n])\nmodel.summary()\n\nmodel.compile(optimizer=\"adam\",\n             loss=\"binary_crossentropy\",\n             metrics=[\"accuracy\"])","a7204bb8":"Callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\nmodel_fit = model.fit(x_train,\n                      validation_data = x_test, \n                      epochs = 10, callbacks=Callback)","b3a681ce":"plt.plot(model_fit.history['loss'], label='train')\nplt.plot(model_fit.history['val_loss'], label='test')\nplt.legend()\nplt.show()","bd9b3ad4":"print('Model summary :')\nprint()\nmodel.summary()","81095032":"test_accuracy = model.evaluate(x_test)[1] * 100\nprint('Test accuracy is : ',test_accuracy, '%' )","188f995f":"direc2 = Path(r'..\/input\/fruits-recognition\/fruits_data\/test')\nfilepaths2 = list(direc2.glob(r'**\/*.jpg'))\nfilename2 = list(map(lambda x: os.path.split(x)[1],filepaths2))\n\n\nfilepaths2 = pd.Series(filepaths2, name='FilePaths').astype(str)\nfilename2 = pd.Series(filename2, name='filename').astype(str)\n\ntest_imgdf = pd.merge(filepaths2, filename2, right_index = True, left_index = True)\n\ntest_imgdf","52d4b755":"test_filenames = os.listdir(r'..\/input\/fruits-recognition\/fruits_data\/test')\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","29dca450":"test_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\ntest_generator = test_gen.flow_from_dataframe(\n    test_imgdf, \n    \"..\/input\/fruits-recognition\/fruits_data\/test\/\", \n    x_col='filename',\n    y_col=None,\n    target_size=img_size,\n    class_mode=None,\n    batch_size=32,\n    shuffle=None,\n    seed=42\n)","bbca75b8":"predict = model.predict(test_generator, steps=np.ceil(nb_samples\/32))","75e12e32":"x_train.class_indices.items()","67365bf1":"test_df['label'] = np.argmax(predict, axis=-1)","3095b45d":"label_map = dict((v,k) for k,v in x_train.class_indices.items())","8af1881e":"test_df['label'] = test_df['label'].replace(label_map)","451d24a8":"test_df","b28f9890":"labels2=pd.read_csv(r'..\/input\/fruits-recognition\/fruits_data\/Testing_set.csv')\nlabels2","dec0bf27":"test_imgdf1 = pd.merge(labels2, test_df, on='filename', how='left')\ntest_imgdf1","86472e56":"test_imgdf2 = test_imgdf1.copy()\ntest_imgdf2 = test_imgdf2.drop('filename', axis=1)\ntest_imgdf2","74a77077":"test_imgdf_to_see =  pd.merge(test_imgdf, test_imgdf1, on='filename', how='right')\ntest_imgdf_to_see","2d2c6f75":"import matplotlib.pyplot as plt\nf,a = plt.subplots(nrows=5, ncols=8,figsize=(13, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(a.flat):\n    ax.imshow(plt.imread(test_imgdf_to_see.FilePaths[i]))\n    ax.set_title(test_imgdf_to_see.label[i])\n    \nplt.tight_layout()\nplt.show()","a5fd758a":"test_imgdf2.to_csv('\/kaggle\/working\/test_submission.csv', index=False)","c6b5e2aa":"**Building a Model**","c4c3ba1d":"**Testing Model**","2a1dab33":"**Outputting the results as a Submission**","5950d91c":"**Train, Validation and Test**","a7176f20":"**Data Importing**","5feff507":"**Augmenting the Image Dataset**","74678ba6":"**Defining Labels (Classes)**","1669710d":"**Fruits Recognition**\n\n* Data Importing\n* Defining Labels (Classes)\n* Train, Validation and Test\n* Augmenting the Image Dataset\n* Building a Model\n* Testing Model","a4328826":"*Checking the images with labels*"}}