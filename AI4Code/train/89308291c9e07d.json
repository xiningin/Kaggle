{"cell_type":{"8a117515":"code","49a0fa9a":"code","6e205568":"code","4ba73b62":"code","84d90e05":"code","80d49452":"code","51799114":"code","7acf4bb2":"code","40773961":"code","1e44861e":"code","294e3c62":"code","60291d3f":"code","3802fb55":"code","b5cb8c04":"code","1fc43b69":"code","3bc6f3ea":"code","b15d34ee":"code","35448bb8":"code","c20554d1":"code","9ebc8096":"code","1bab4d11":"code","13b7aab4":"code","b2ab7112":"code","67eeda7a":"code","b7b50a1e":"markdown","3978b4bc":"markdown","fe86afce":"markdown","29b345a2":"markdown","8d6b8b60":"markdown","382aa5f7":"markdown","55fd2f3b":"markdown","a28f1d3f":"markdown","ae8c1291":"markdown","ca04c69b":"markdown","b0ae97a5":"markdown","cd6c7fc2":"markdown","ba87294b":"markdown","6c393b0c":"markdown","d7d5fb3f":"markdown","669ee6e5":"markdown","0e47fe84":"markdown","456c0517":"markdown"},"source":{"8a117515":"import os\nimport cv2\nimport ast\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt","49a0fa9a":"path = '\/kaggle\/input\/tensorflow-great-barrier-reef\/'\nos.listdir(path)","6e205568":"train_data = pd.read_csv(path+'train.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'example_sample_submission.csv')","4ba73b62":"print('Number train samples:', len(train_data))\nprint('Number test samples:', len(test_data))","84d90e05":"train_data.head()","80d49452":"train_data['video_id'].value_counts()","51799114":"train_data['sequence'].value_counts()","7acf4bb2":"video_frame = 7981\nfile_name = str(video_frame)+'.jpg'\ntrain_data[train_data['video_frame']==video_frame]","40773961":"print('file 7981.jpg in folder video_0:', file_name in os.listdir(path+'train_images\/video_0'))\nprint('file 7981.jpg in folder video_2:', file_name in os.listdir(path+'train_images\/video_2'))","1e44861e":"image_folder_0 = cv2.imread(path+'train_images\/video_0\/'+file_name)\nimage_folder_2 = cv2.imread(path+'train_images\/video_2\/'+file_name)","294e3c62":"print('shape of image in folder video_0:', image_folder_0.shape)\nprint('shape of image in folder video_2:', image_folder_2.shape)","60291d3f":"fig, ax = plt.subplots(1, 1, figsize=(20, 8))\nax.imshow(image_folder_0);\nax.set_xticklabels([])\nax.set_yticklabels([])\nplt.show()","3802fb55":"train_data[(train_data['video_frame']==video_frame)&(train_data['video_id']==2)]['annotations']","b5cb8c04":"row = 20722","1fc43b69":"boxes = ast.literal_eval(train_data.loc[row, 'annotations'])","3bc6f3ea":"fig, ax = plt.subplots(1, 1, figsize=(20, 8))\nax.imshow(image_folder_2)\nfor box in boxes:\n    p = matplotlib.patches.Rectangle((box['x'], box['y']), box['width'], box['height'],\n                                     ec='r', fc='none', lw=2.)\n    ax.add_patch(p)\nax.set_xticklabels([])\nax.set_yticklabels([])\nplt.show()","b15d34ee":"row = 5454\nfile_name = str(train_data.loc[row, 'video_frame'])+'.jpg'\nvideo_folder = 'video_'+str(train_data.loc[row, 'video_id'])\nboxes = ast.literal_eval(train_data.loc[row, 'annotations'])","35448bb8":"print('video folder:', video_folder)\nprint('file name:', file_name)","c20554d1":"image = cv2.imread(path+'train_images\/'+video_folder+'\/'+file_name)\nimage.shape","9ebc8096":"fig, ax = plt.subplots(1, 1, figsize=(20, 8))\nax.imshow(image)\nfor box in boxes:\n    p = matplotlib.patches.Rectangle((box['x'], box['y']), box['width'], box['height'],\n                                     ec='r', fc='none', lw=2.)\n    ax.add_patch(p)\nax.set_xticklabels([])\nax.set_yticklabels([])\nplt.show()","1bab4d11":"import PIL.Image\nimport greatbarrierreef\n\nenv = greatbarrierreef.make_env()\niter_test = env.iter_test()","13b7aab4":"pixel_array, sample_prediction_df = next(iter_test)\npixel_array","b2ab7112":"PIL.Image.fromarray(pixel_array)","67eeda7a":"samp_subm.to_csv('submission.csv', index=False)","b7b50a1e":"Plot image and annotations:","3978b4bc":"# Libraries","fe86afce":"# Load Data","29b345a2":"**Plot images**\n\nThe image in folder video_0 has no annotations.","8d6b8b60":"We load the images:","382aa5f7":"# Path","55fd2f3b":"# EDA\nThere are 3 values for the feature video_id which represent the number of the underlying folder.","a28f1d3f":"As we can see there are 2 images with this video_frame id. One in folder video_0 and another one in folder video_2:","ae8c1291":"# Intro\nWelcome to the [Tensorflow - Help Protect the Great Barrier Reef](https:\/\/www.kaggle.com\/c\/tensorflow-great-barrier-reef) compedition.\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/31703\/logos\/header.png)\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span>","ca04c69b":"# Example With Multi Boxes","b0ae97a5":"The image in the folder video_2 has one annotation:","cd6c7fc2":"# Load Image Files\n**train_images\/** - Folder containing training set photos of the form video_{video_id}\/{video_frame_number}.jpg.\n\nWe consider the image with the video_frame id 7981:","ba87294b":"We extract the boxes:","6c393b0c":"There are 20 different sequences:","d7d5fb3f":"# Export Data","669ee6e5":"# Overview","0e47fe84":"* video_id - ID number of the video the image was part of. The video ids are not meaningfully ordered.\n* video_frame - The frame number of the image within the video. Expect to see occasional gaps in the frame number from when the diver surfaced.\n* sequence - ID of a gap-free subset of a given video. The sequence ids are not meaningfully ordered.\n* sequence_frame - The frame number within a given sequence.\n* image_id - ID code for the image, in the format '{video_id}-{video_frame}'\n* annotations - The bounding boxes of any starfish detections in a string format that can be evaluated directly with Python. Does not use the same format as the predictions you will submit. Not available in test.csv. A bounding box is described by the pixel coordinate (x_min, y_min) of its lower left corner within the image together with its width and height in pixels.","456c0517":"# Use API\nTo use the api we follow the instructions of [this notebook](https:\/\/www.kaggle.com\/sohier\/great-barrier-reef-api-tutorial\/notebook). "}}