{"cell_type":{"1bcc8528":"code","3e7a00ff":"code","23be9feb":"code","35cc6890":"code","1ca690c1":"code","b697d102":"code","16696674":"code","8043dd4c":"code","45e7e586":"code","37250e3c":"code","ed96c5a5":"markdown","060faff2":"markdown","1b73ae82":"markdown","8384ce2a":"markdown","6cfac529":"markdown","1580c7d5":"markdown"},"source":{"1bcc8528":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3e7a00ff":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport csv\nfrom os import getcwd","23be9feb":"def get_data(filename):\n    with open(filename) as training_file:\n        labels = []\n        images = []\n        header = training_file.readline()\n        rows = training_file.readlines()\n        for row in rows:\n            row = row.strip().split(',')\n            labels.append(int(row[0]))\n            images.append(np.array(np.array_split(row[1:785], 28)))\n        labels = np.array(labels)\n        images = np.array(images)\n        images = images.astype(float)\n    return images, labels\n\npath_sign_mnist_train = f\"\/kaggle\/input\/sign_mnist_train.csv\"\npath_sign_mnist_test = f\"\/kaggle\/input\/sign_mnist_test.csv\"\ntrain_images, train_labels = get_data(path_sign_mnist_train)\ntest_images, test_labels = get_data(path_sign_mnist_test)\n\n\nprint(train_images.shape)\nprint(train_labels.shape)\nprint(test_images.shape)\nprint(test_labels.shape)\n","35cc6890":"\ntrain_images = train_images.reshape(-1,28,28,1)\ntest_images = test_images.reshape(-1,28,28,1)\n\n\ntraining_datagen = ImageDataGenerator(\n        rescale = 1.\/255, #scaling\n        rotation_range=12, #rotation within 12 degrees\n        width_shift_range=2, #horizontal shift\n        height_shift_range=2, #vertical shift\n        shear_range=0.2, #shearing \n        fill_mode='nearest',\n        zoom_range=0.2,\n)\n\n# Validation data we just scaling\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255,)","1ca690c1":"import random\nimport matplotlib.pyplot as plt\n\npick = random.choice(train_images)\nplt.imshow(np.array(pick).squeeze(), cmap=plt.cm.binary)\nplt.show()","b697d102":"class MyCallBack(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_accuracy') >= 0.997:\n            print('\\nAccuracy 99.6% archived:', logs.get('val_accuracy'))\n            self.model.stop_training = True\n            ","16696674":"keras.backend.set_floatx('float32')\n\nmodel = keras.models.Sequential([\n    keras.layers.Conv2D(32, (4,4), activation='relu', input_shape=(28, 28,1)),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(24, (3,3), activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    \n    keras.layers.Dropout(0.2),\n    keras.layers.Flatten(),\n\n    keras.layers.Dense(256, activation='swish'),\n    keras.layers.Dense(25, activation='softmax')\n])\n\nmodel.summary()","8043dd4c":"# Compile Model. \nmodel.compile(optimizer=keras.optimizers.Adam(lr=1e-3, decay=8e-6),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the Model\nhistory = model.fit(training_datagen.flow(train_images, train_labels, batch_size=50), \n                    epochs=100, \n                    steps_per_epoch=500, \n                    validation_data = validation_datagen.flow(test_images,  test_labels, batch_size=50), \n                    verbose = 1,\n                    shuffle=True,\n                    callbacks=[MyCallBack()],\n                    validation_steps=115\n                    )","45e7e586":"print('\\nValidation:')\nmodel.evaluate(test_images, test_labels, verbose=1)","37250e3c":"# Plot the chart for accuracy and loss on both training and validation\n%matplotlib inline\nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nfig = plt.figure(figsize=(14,6))\n\nax = fig.add_subplot(121)\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nax = fig.add_subplot(122)\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","ed96c5a5":"Thank you for attention","060faff2":"Lets have a look how our pictures look before we proceed with modeling","1b73ae82":"This was one of the tasks on Cursera cource - Tensorflow in Practice.\nThe challenge is to reach 99% accurace  by using no more than 2 Convolution Layrs.\n\nDataset is a SignMNIST (hand language for deaf) it has 26 lables what makes it even more challenging that  regular MNIST or Fashion MNIST.\n\nHere is my best try with reaching **99.6%** on evaluation.\n\nPlease share your comments.","8384ce2a":"Results mat vary withing 0.002","6cfac529":"Here we will use TensorFlow ImageGenerator for image augmentation on train data to have better generalization.","1580c7d5":"Creating callback for stoping training once we reach the goal accuracy"}}