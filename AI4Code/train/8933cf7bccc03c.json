{"cell_type":{"21a4e84c":"code","d682ac5e":"code","ae752e5c":"code","35789e64":"code","dfb68052":"code","bec4187b":"code","f5485a42":"code","2277b429":"code","9e62b27f":"code","8d477ef6":"code","4feebe37":"code","f5abf2d9":"code","331e1a63":"code","e65a2e53":"code","7e0351a7":"code","0d34281b":"code","aa19c2d3":"code","4c411733":"code","f2b9bff9":"code","2ceb3508":"code","f52cdab0":"code","8cb5e295":"code","aa78c9ac":"code","bacd38f2":"markdown","afe7cdfd":"markdown","4b3c5f2a":"markdown","7895f33b":"markdown","5322fd94":"markdown","c3007715":"markdown","8185a307":"markdown","8904c8c6":"markdown","a4a74b7e":"markdown","9785105a":"markdown","248e0f3a":"markdown","4a3a7846":"markdown","d3fff208":"markdown","128c4336":"markdown","0ef2d3fb":"markdown","84f28b9d":"markdown","0b0a4401":"markdown","f8e8736a":"markdown","8e7b3ee5":"markdown","a4119fec":"markdown","d8f4b2cf":"markdown","840dedf4":"markdown"},"source":{"21a4e84c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix","d682ac5e":"path = '..\/input'\nprint(os.listdir(path))","ae752e5c":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","35789e64":"print('train data shape:', train_data.shape)\nprint('test data shape:', test_data.shape)","dfb68052":"train_data_shuffle = train_data.copy()\ntest_data_shuffle = test_data.copy()","bec4187b":"new_order = np.random.permutation(train_data_shuffle.columns[1:])","f5485a42":"train_data_shuffle[train_data_shuffle.columns[1:]] = train_data_shuffle[new_order]\ntest_data_shuffle = test_data_shuffle[new_order]","2277b429":"X_train = train_data.copy()\ny_train = train_data['label']\ndel X_train['label']\nX_test = test_data.copy()\ny_train = to_categorical(y_train, num_classes = 10)\n\nX_train_shuffle = train_data_shuffle.copy()\ny_train_shuffle = train_data_shuffle['label']\ndel X_train_shuffle['label']\nX_test_shuffle = test_data_shuffle.copy()\ny_train_shuffle = to_categorical(y_train_shuffle, num_classes = 10)","9e62b27f":"X_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\n\nX_train_shuffle = X_train_shuffle.values.reshape(-1,28,28,1)\nX_test_shuffle = X_test_shuffle.values.reshape(-1,28,28,1)","8d477ef6":"X_train = X_train.astype('float32')\/255\nX_test = X_test.astype('float32')\/255\n\nX_train_shuffle = X_train_shuffle.astype('float32')\/255\nX_test_shuffle = X_test_shuffle.astype('float32')\/255","4feebe37":"fig, axs = plt.subplots(2, 5, figsize=(15, 6))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\nfor i in range(10):\n    idx = train_data[train_data['label']==i].index[0]\n    axs[i].imshow(X_train[idx][:,:,0], cmap='gray')\n    axs[i].set_title(y_train[idx].argmax())\n    axs[i].set_xticklabels([])\n    axs[i].set_yticklabels([])","f5abf2d9":"fig, axs = plt.subplots(2, 5, figsize=(15, 6))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\nfor i in range(10):\n    idx = train_data_shuffle[train_data_shuffle['label']==i].index[0]\n    axs[i].imshow(X_train_shuffle[idx][:,:,0], cmap='gray')\n    axs[i].set_title(y_train_shuffle[idx].argmax())\n    axs[i].set_xticklabels([])\n    axs[i].set_yticklabels([])","331e1a63":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2022)\nX_train_shuffle, X_val_shuffle, y_train_shuffle, y_val_shuffle = train_test_split(X_train_shuffle, y_train_shuffle, test_size = 0.1, random_state=2022)","e65a2e53":"def train_model(X_train, y_train, X_val, y_val, epochs, batch_size):\n    \n    datagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        zoom_range = 0.1,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=False,\n        vertical_flip=False)\n    datagen.fit(X_train)\n    \n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n\n    optimizer = RMSprop(lr=0.001,rho=0.9, epsilon=1e-08, decay=0.0)\n\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val, y_val),\n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size)\n    return model, history","7e0351a7":"epochs = 10\nbatch_size = 378","0d34281b":"model, history = train_model(X_train, y_train, X_val, y_val, epochs, batch_size)","aa19c2d3":"model_shuffle, history_shuffle = train_model(X_train_shuffle, y_train_shuffle, X_val_shuffle, y_val_shuffle, 10, batch_size)","4c411733":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\n\nacc = history.history['accuracy']\nacc_val = history.history['val_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","f2b9bff9":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history_shuffle.history['loss']\nloss_val = history_shuffle.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\n\nacc = history_shuffle.history['accuracy']\nacc_val = history_shuffle.history['val_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","2ceb3508":"y_val_pred = model.predict(X_val)","f52cdab0":"conf_mat = confusion_matrix(y_val.argmax(axis=1), y_val_pred.argmax(axis=1))\n\nfig, ax = plot_confusion_matrix(conf_mat=conf_mat,\n                                show_normed=True,\n                                show_absolute=False,\n                                figsize=(8, 8))\nfig.show()","8cb5e295":"y_val_pred_shuffle = model_shuffle.predict(X_val_shuffle)","aa78c9ac":"conf_mat = confusion_matrix(y_val.argmax(axis=1), y_val_pred_shuffle.argmax(axis=1))\n\nfig, ax = plot_confusion_matrix(conf_mat=conf_mat,\n                                show_normed=True,\n                                show_absolute=False,\n                                figsize=(8, 8))\nfig.show()","bacd38f2":"Original Data:","afe7cdfd":"# Analyse Wrong Predictions\nWe want to analyse the wrong predictions on the validation dataset.","4b3c5f2a":"Original Data:","7895f33b":"Shuffled Data:","5322fd94":"# Path","c3007715":"# Analyse Results","8185a307":"Original Data:","8904c8c6":"# Prepare Train And Test Data","a4a74b7e":"# Shuffle Data\nBased on the original data we shuffle the pixel randomly.","9785105a":"# Define Model\nWe use a simple CNN model:","248e0f3a":"Shuffled Data:","4a3a7846":"# Load Libraries","d3fff208":"Shuffled Data:","128c4336":"# Split train data to get val data","0ef2d3fb":"# Intro\nWelcome to the famous [MINST](https:\/\/www.kaggle.com\/c\/digit-recognizer) dataset\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3004\/logos\/header.png)\n\n\n<font size=\"4\">In this notebook we want to compare the prediction on the orginal data and the data with shuffled pixel. For the model we use a simple CNN.<\/font>\n\n<font size=\"4\"><span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span><\/font>","84f28b9d":"# Load Data","0b0a4401":"# Train Model\nWe use the same CNN to train the original and the shuffled data.","f8e8736a":"Original Data:","8e7b3ee5":"# Summary\nAs we can see the model will also produce good results on the shuffled data. But the convergence on the shuffled data is much slower than on the original data.","a4119fec":"# Scale data","d8f4b2cf":"# Some Examples\nFor each category we plot the original image and the image with shuffled pixels.","840dedf4":"Shuffled Data:"}}