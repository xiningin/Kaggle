{"cell_type":{"3d5e805d":"code","98fdc3cc":"code","cd908c6c":"code","a79cee78":"code","ee576104":"code","10dec75b":"code","4d952f20":"code","7af5e6ba":"code","063e6f31":"code","2207186c":"code","bdfcbd13":"code","4c434c96":"code","a63e400b":"code","b65dd386":"code","50343802":"code","448773be":"code","7d4f8a22":"code","d5e70d9d":"code","734403e5":"code","9c89e237":"code","b5b43f38":"code","1b582f04":"code","90a9f4ea":"code","97638a93":"code","b52384d7":"code","92931159":"code","3ea05acf":"code","58563c12":"code","1b80822c":"code","27b8b5b2":"code","0bd18791":"code","06606c84":"code","0833df05":"markdown","a206b1b1":"markdown","977df941":"markdown"},"source":{"3d5e805d":"import pandas as pd\nimport numpy as np\nimport nibabel as nib\nimport glob\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nfrom tifffile import imsave\nfrom zipfile import ZipFile\nimport nibabel as nib\nimport os\nimport random\n#import splitfolders  # or import split_folders\n\nfrom sklearn.preprocessing import MinMaxScaler\n#import segmentation_models_3D as sm\nimport keras\nimport tensorflow as tf\nimport datetime\nimport tarfile\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Model, load_model\nfrom keras.layers import Input ,BatchNormalization , Activation \nfrom keras.layers.convolutional import Conv2D, UpSampling2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import optimizers \nfrom sklearn.model_selection import train_test_split\nimport os\nimport nibabel as nib\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom keras import backend as K\nimport glob\nimport skimage.io as io\nimport skimage.color as color\nimport random as r\nimport math\n","98fdc3cc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cd908c6c":"!mkdir data","a79cee78":"zip_file = tarfile.open(\"\/kaggle\/input\/brats-2021-task1\/BraTS2021_Training_Data.tar\")\nzip_file.extractall(\".\/data\")\nzip_file.close()","ee576104":"Flair = nib.load('data\/BraTS2021_00003\/BraTS2021_00003_flair.nii.gz')\nSeg = nib.load('data\/BraTS2021_00003\/BraTS2021_00003_seg.nii.gz')\nT1 = nib.load('data\/BraTS2021_00003\/BraTS2021_00003_t1.nii.gz')\nT1ce = nib.load('data\/BraTS2021_00003\/BraTS2021_00003_t1ce.nii.gz')\nT2 = nib.load('data\/BraTS2021_00003\/BraTS2021_00003_t2.nii.gz')","10dec75b":"Path = '.\/data'\np = os.listdir(Path)","4d952f20":"Input_Data= []\n\ndef Data_Preprocessing(modalities_dir):\n    all_modalities = []    \n    for modality in modalities_dir:      \n        nifti_file   = nib.load(modality)\n        brain_numpy  = np.asarray(nifti_file.dataobj)    \n        all_modalities.append(brain_numpy)\n    brain_affine   = nifti_file.affine\n    all_modalities = np.array(all_modalities)\n    all_modalities = np.rint(all_modalities).astype(np.int16)\n    all_modalities = all_modalities[:, :, :, :]\n    all_modalities = np.transpose(all_modalities)\n    return all_modalities\n\nfor i in p[:10]:\n    brain_dir = os.path.normpath(Path+'\/'+ i+'\/' )\n    flair     = glob.glob(os.path.join(brain_dir, '*_flair*.nii.gz'))\n    t1        = glob.glob(os.path.join(brain_dir, '*_t1*.nii.gz'))\n    t1ce      = glob.glob(os.path.join(brain_dir, '*_t1ce*.nii.gz'))\n    t2        = glob.glob(os.path.join(brain_dir, '*_t2*.nii.gz'))\n    gt        = glob.glob( os.path.join(brain_dir, '*_seg*.nii.gz'))\n    modalities_dir = [flair[0], t1[0], t1ce[0], t2[0], gt[0]]\n    P_Data = Data_Preprocessing(modalities_dir)\n    Input_Data.append(P_Data)","7af5e6ba":"type(Input_Data),len(Input_Data)","063e6f31":"fig = plt.figure(figsize=(5,5))\nimmmg = Input_Data[3][100,:,:,3]\nimgplot = plt.imshow(immmg)\nplt.show()","2207186c":"def Data_Concatenate(Input_Data):\n    counter=0\n    Output= []\n    for i in range(5):\n        #print('$')\n        c=0\n        counter=0\n        for ii in range(len(Input_Data)):\n            if (counter != len(Input_Data)):\n                a= Input_Data[counter][:,:,:,i]\n                #print('a={}'.format(a.shape))\n                b= Input_Data[counter+1][:,:,:,i]\n                #print('b={}'.format(b.shape))\n                if(counter==0):\n                    c= np.concatenate((a, b), axis=0)\n                    #print('c1={}'.format(c.shape))\n                    counter= counter+2\n                else:\n                    c1= np.concatenate((a, b), axis=0)\n                    c= np.concatenate((c, c1), axis=0)\n                    #print('c2={}'.format(c.shape))\n                    counter= counter+2\n        c= c[:,:,:,np.newaxis]\n        Output.append(c)\n    return Output","bdfcbd13":"InData = Data_Concatenate(Input_Data)","4c434c96":"AIO= concatenate(InData, axis=3)\nAIO=np.array(AIO,dtype='float32')\nTR=np.array(AIO[:,:,:,1],dtype='float32')\nTRL=np.array(AIO[:,:,:,4],dtype='float32')","a63e400b":"X_train , X_test, Y_train, Y_test = train_test_split(TR, TRL, test_size=0.15, random_state=32)","b65dd386":"X_train.shape ,X_test.shape","50343802":"train_X = tf.data.Dataset.from_tensor_slices(X_train)\nval_X = tf.data.Dataset.from_tensor_slices(X_test)\ntrain_y = tf.data.Dataset.from_tensor_slices(Y_train)\nval_y = tf.data.Dataset.from_tensor_slices(Y_test)","448773be":"train_X.element_spec, train_y.element_spec, val_X.element_spec, val_y.element_spec ","7d4f8a22":"def brightness(img, mask):\n    img = tf.image.adjust_brightness(img, 0.1)\n    return img, mask\n \ndef gamma(img, mask):\n    img = tf.image.adjust_gamma(img, 0.1)\n    return img, mask\n\n\ndef crop(img, mask):\n    img = tf.image.central_crop(img, 0.7)\n    img = tf.image.resize(img, (240,240))\n    mask = tf.image.central_crop(mask, 0.7)\n    mask = tf.image.resize(mask, (240,240))\n    mask = tf.cast(mask, tf.uint8)\n    return img, mask\n\ndef flip_hori(img, mask):\n    img = tf.image.flip_left_right(img)\n    mask = tf.image.flip_left_right(mask)\n    return img, mask\n\ndef flip_vert(img, mask):\n    img = tf.image.flip_up_down(img)\n    mask = tf.image.flip_up_down(mask)\n    return img, mask\n\ndef rotate(img, mask):\n    img = tf.image.rot90(img)\n    mask = tf.image.rot90(mask)\n    return img, mask ","d5e70d9d":"train = tf.data.Dataset.zip((train_X, train_y))\nval = tf.data.Dataset.zip((val_X, val_y))","734403e5":"# perform augmentation on train data only\na = train.map(brightness)\nb = train.map(gamma)\n#c = train.map(hue)\n#d = train.map(crop)\n#e = train.map(flip_hori)\n#f = train.map(flip_vert)\n#g = train.map(rotate)\n\ntrain = train.concatenate(a)\ntrain = train.concatenate(b)\n#train = train.concatenate(c)\n#train = train.concatenate(d)\n#train = train.concatenate(e)\n#train = train.concatenate(f)\n#train = train.concatenate(g) ","9c89e237":"BATCH = 64\nAT = tf.data.AUTOTUNE\nBUFFER = 1000\nSTEPS_PER_EPOCH = 800\/\/BATCH\nVALIDATION_STEPS = 200\/\/BATCH\ntrain = train.cache().shuffle(BUFFER).batch(BATCH).repeat()\ntrain = train.prefetch(buffer_size=AT)\nval = val.batch(BATCH) ","b5b43f38":"fig = plt.figure(figsize=(5,5))\nimmmg = X_train[3]\nimgplot = plt.imshow(immmg)\nplt.show()","1b582f04":"fig = plt.figure(figsize=(5,5))\nimmmg = Y_train[3]\nimgplot = plt.imshow(immmg)\nplt.show()","90a9f4ea":"def Convolution(input_tensor,filters):\n    \n    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x) \n    return x\n\ndef model(input_shape):\n    \n    inputs = Input((input_shape))\n    \n    conv_1 = Convolution(inputs,32)\n    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n    \n    conv_2 = Convolution(maxp_1,64)\n    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n    \n    conv_3 = Convolution(maxp_2,128)\n    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n    \n    conv_4 = Convolution(maxp_3,256)\n    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n    \n    conv_5 = Convolution(maxp_4,512)\n    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n    \n    conv_6 = Convolution(upsample_6,256)\n    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n    \n    upsample_7 = concatenate([upsample_7, conv_3])\n    \n    conv_7 = Convolution(upsample_7,128)\n    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n    \n    conv_8 = Convolution(upsample_8,64)\n    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n    \n    upsample_9 = concatenate([upsample_9, conv_1])\n    \n    conv_9 = Convolution(upsample_9,32)\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n    \n    model = Model(inputs=[inputs], outputs=[outputs]) \n    \n    return model","97638a93":"model = model(input_shape = (240,240,1))\n#model.summary()","b52384d7":"def dice_coef(y_true, y_pred, smooth=1.0):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\n\nmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy',metrics=['accuracy',dice_coef])","92931159":"#history = model.fit(X_train,Y_train,batch_size=64,epochs=10,validation_split=0.20,verbose=1)\nhist = model.fit(train,validation_data=val,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=VALIDATION_STEPS,epochs=5) ","3ea05acf":"def Accuracy_Graph(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    #plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n                        wspace=0.35)\n    plt.show()\n    \n    \n# Dice Similarity Coefficient vs Epoch\ndef Dice_coefficient_Graph(history):\n\n    plt.plot(history.history['dice_coef'])\n    plt.plot(history.history['val_dice_coef'])\n    #plt.title('Dice_Coefficient')\n    plt.ylabel('Dice_Coefficient')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n                        wspace=0.35)\n    plt.show()","58563c12":"Accuracy_Graph(history)\nDice_coefficient_Graph(history)","1b80822c":"pref_Tumor = model.predict(TR)","27b8b5b2":"fig = plt.figure(figsize=(5,5))\nimmmg = TR[34,:,:]\nimgplot = plt.imshow(immmg)\nplt.show()","0bd18791":"fig = plt.figure(figsize=(5,5))\nimmmg = pref_Tumor[34,:,:,0]\nimgplot = plt.imshow(immmg)\nplt.show()","06606c84":"plt.figure(figsize=(15,10))\n\n\nplt.subplot(341)\nplt.title('Sample 1')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[100,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[100,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(342)\nplt.title('Sample 2')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[102,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[102,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(343)\nplt.title('Sample 3')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[32,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[32,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(344)\nplt.title('Sample 4')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[49,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[49,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(345)\nplt.title('Sample 5')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[51,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[51,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(346)\nplt.title('Sample 6')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[116,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[116,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(347)\nplt.title('Sample 7')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[217,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[217,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(348)\nplt.title('Sample 8')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[81,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_Tumor[81,:,:]),alpha=0.3,cmap='Reds')","0833df05":"# Original Data","a206b1b1":"# U Net Model","977df941":"# Predicted Data"}}