{"cell_type":{"3a9ac02f":"code","406ac896":"code","89502e72":"code","3f041933":"code","a8b07139":"code","5d7dfcb6":"code","ec8e3a77":"code","22c378ca":"code","6a645a1b":"code","201462db":"code","a9289fd0":"code","278ab8ca":"code","36ab9468":"code","f4adb584":"code","bbd85298":"code","a7145537":"code","745f081d":"code","008ef930":"code","bb29486b":"code","a2b56900":"code","209965fb":"code","bf16f95c":"code","b6fd78eb":"code","448b5920":"code","d3a35c5d":"code","0ad7b1e3":"code","b1d7dbe5":"code","b82f8b9e":"code","5e8b4040":"code","e9a667a9":"code","74b9d260":"code","092e24f3":"code","9350975c":"code","9da5b32e":"code","87dc1534":"code","ad56f0b9":"code","048c5936":"code","550d2bde":"code","5e32de42":"code","b4a68b7b":"code","9d475c1b":"code","7e1052ac":"code","7de529c6":"code","acb7defb":"code","85233e8d":"code","a161be4d":"code","6dcbc053":"code","2fa78604":"code","5042cf10":"code","d07cbe18":"code","3de356f5":"code","68e264fd":"code","67998d80":"markdown","b6d2490a":"markdown","1a39abc6":"markdown","2f79c292":"markdown","526b6378":"markdown","b0b74a89":"markdown","08457af1":"markdown"},"source":{"3a9ac02f":"#importing required libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report","406ac896":"#loading the train data\ntrain_df=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain_df.head()","89502e72":"train_df.shape","3f041933":"#loading the test data\ntest_df=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_df.head()","a8b07139":"test_df.shape","5d7dfcb6":"#concatinating train and test to get titanic dataset\ntitanic_df=pd.concat([train_df, test_df], sort = False)\ntitanic_df.shape","ec8e3a77":"#retrieving first five records of titanic dataset\ntitanic_df.head()","22c378ca":"#retrieving column names of the titanic dataset\ntitanic_df.columns","6a645a1b":"#information about the dataset\ntitanic_df.info()","201462db":"#distribution of Age column values\nsns.distplot(titanic_df['Age'])","a9289fd0":"#treating NULL values of Age column of the dataset\ntitanic_df['Age']=titanic_df['Age'].fillna(titanic_df['Age'].mean())","278ab8ca":"#treating NULL values of Embarked column of the dataset\ntitanic_df['Embarked']=titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])","36ab9468":"#dropping Cabin, PassengerId, Ticket and Fare columns\ntitanic_df=titanic_df.drop(columns=['Ticket', 'Fare', 'Cabin'])","f4adb584":"#checking for NULL values \ntitanic_df.isnull().sum()","bbd85298":"#distribution of Age column values after treating missing values\nsns.distplot(titanic_df['Age'])","a7145537":"#describing statistics of the numerical columns\ntitanic_df.describe()","745f081d":"#count of survivors\ntitanic_df['Survived'].value_counts()","008ef930":"#plotting count of survivors\nsurvived=titanic_df['Survived'].map({0:'Not Survived',1:'Survived'})\nsns.countplot(survived)","bb29486b":"#plotting categorical features related to Survived target\ncat_feats=['Pclass','Sex','Embarked']\nplt.figure(figsize=(20,5))\n\nfor i in range(len(cat_feats)):\n    plt.subplot(1,3,i+1)\n    sns.countplot(titanic_df[cat_feats[i]],hue=survived,data=titanic_df)","a2b56900":"#plotting survival probability as per Passenger class\nplt=titanic_df[['Pclass','Survived']].groupby('Pclass').mean().Survived.plot(kind='bar',color=['r','g','y'])\nplt.set_xlabel('Pclass')\nplt.set_ylabel('Survival Probability')","209965fb":"#plotting survival probability as per Sex\nplt=titanic_df[['Sex','Survived']].groupby('Sex').mean().Survived.plot(kind='bar',color=['r','g'])\nplt.set_xlabel('Sex')\nplt.set_ylabel('Survival Probability')","bf16f95c":"#plotting survival probability as per Embarked column\nplt=titanic_df[['Embarked','Survived']].groupby('Embarked').mean().Survived.plot(kind='bar',color=['r','g','y'])\nplt.set_xlabel('Embarked')\nplt.set_ylabel('Survival Probability')","b6fd78eb":"#plotting survival probability as per SibSp\nplt=titanic_df[['SibSp','Survived']].groupby('SibSp').mean().Survived.plot(kind='bar',color=['r','g','y','b','c','m'])\nplt.set_xlabel('Siblings_Spouse')\nplt.set_ylabel('Survival Probability')","448b5920":"#plotting survival probability as per Parch\nplt=titanic_df[['Parch','Survived']].groupby('Parch').mean().Survived.plot(kind='bar',color=['r','b','g','y','c'])\nplt.set_xlabel('Parent_Children')\nplt.set_ylabel('Survival Probability')","d3a35c5d":"#adding new column Familsize and IsAlone\ntitanic_df['FamilySize']=titanic_df['SibSp']+titanic_df['Parch']+1\ntitanic_df['IsAlone'] = 0\ntitanic_df.loc[titanic_df['FamilySize']==1, 'IsAlone'] = 1\ntitanic_df.columns","0ad7b1e3":"#adding new column Title\ntitanic_df['Title']=titanic_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitanic_df.columns","b1d7dbe5":"#distinct values in Title column\ntitanic_df['Title'].unique()","b82f8b9e":"#replacing some Title values with others\ntitanic_df['Title']=titanic_df['Title'].replace(['Don','Dr','Mme','Ms','Major','Lady','Sir','Mlle','Col','Capt',\n                                                 'Countess','Jonkheer','Dona'],'Others')","5e8b4040":"#plotting bar plot for Title column\ntitanic_df.Title.value_counts().plot(kind='bar')","e9a667a9":"#dropping Name, SibSp and Parch columns\ntitanic_df=titanic_df.drop(columns=['Name','SibSp','Parch'])\ntitanic_df.columns","74b9d260":"#categorical values into numerical ones\nle=LabelEncoder()\ncols=['Sex','Embarked','Title']\nfor i in cols:\n    titanic_df[i]=le.fit_transform(titanic_df[i])","092e24f3":"#correlation matrix for columns\nsns.heatmap(data=titanic_df.corr(),cmap='Blues',annot=True,linewidths=0.2)","9350975c":"#head values of the dataset reformed\ntitanic_df.head()","9da5b32e":"#transforming Age values in the range as other columns\ndata=[titanic_df]\nfor dataset in data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\ntitanic_df.head()","87dc1534":"#extracting training set from titanic dataset\ntrain=titanic_df[titanic_df['Survived'].notna()]\ntrain.info()","ad56f0b9":"#extracting testing set from titanic dataset\ntest=titanic_df[titanic_df['Survived'].isna()]\ntest.info()","048c5936":"#extracting features and target set from titanic_df\nfeature_df=train.drop(['PassengerId','Survived'],axis=1)\ntarget_df=train['Survived']","550d2bde":"#importing classification model creation packages\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier","5e32de42":"#classification model creation using different classifiers\nmodel_accuracy=[]\ntraining_accuracy=[]\ntesting_accuracy=[]\ncross_val_scores=[]\ndef classify(model,x,y):\n    x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.15)\n    model.fit(x_train,y_train)\n    y_pred=model.predict(x_test)\n    model_accuracy.append(round(accuracy_score(y_test,y_pred)*100,3))\n    training_accuracy.append(round(model.score(x_train, y_train)*100,3))\n    testing_accuracy.append(round(model.score(x_test, y_test)*100,3))\n    score=cross_val_score(model,x,y,cv=5)\n    cross_val_scores.append(np.mean(score)*100)","b4a68b7b":"#fitting different classifier models\nclassifiers=[\n    LogisticRegression(),\n    SGDClassifier(max_iter=5,tol=None),\n    KNeighborsClassifier(),\n    GaussianNB(),\n    SVC(kernel='linear'),\n    DecisionTreeClassifier(max_depth=4),\n    MLPClassifier(activation='logistic',max_iter=1500),\n    RandomForestClassifier(n_estimators=100,max_depth=4),\n    BaggingClassifier(n_estimators=50,base_estimator=KNeighborsClassifier()),\n    AdaBoostClassifier(n_estimators=50,base_estimator=LogisticRegression()),\n    GradientBoostingClassifier(learning_rate=0.01),\n    XGBClassifier(n_estimators=50)]\n\nfor classifier in classifiers:\n    classify(classifier,feature_df,target_df)","9d475c1b":"#results recorded in new dataframe\nmodel_results=pd.DataFrame({\n    'Model': ['Logistic Regression', 'SGD Classifier', 'KNN Classifier', 'Naive Bayes Classifier', \n              'Linear SVM Classifier', 'Decision Tree Classifier', 'MLP Classifier', 'Random Forest Classifier',\n              'Bagging Classifier', 'Adaboost Classifier', 'Gradientboost Classifier','XGBoost Classifier'],\n    'Accuracy': model_accuracy,\n    'Training_Accuracy':training_accuracy,\n    'Testing_Accuracy':testing_accuracy,\n    'Cross_Validation_Score':cross_val_scores\n})\nresult_df=model_results.sort_values(by='Accuracy', ascending=False)","7e1052ac":"#printing the accuracy result\nresult_df","7de529c6":"#splitting for training and testing\nx_train,x_test,y_train,y_test=train_test_split(feature_df, target_df, test_size=0.15)","acb7defb":"#implementing RandomForestClassifier model\nrfc_model=RandomForestClassifier(n_estimators=100,max_depth=4)\nrfc_model.fit(x_train,y_train)","85233e8d":"#predicting y for x_test part\npred=rfc_model.predict(x_test)","a161be4d":"#classification report for RandomForestClassifier model\nprint(classification_report(y_test,pred))","6dcbc053":"#Predicting survival for test data\nTestForPred=test.drop(['PassengerId', 'Survived'], axis = 1)","2fa78604":"#predicting y values\ny_pred=rfc_model.predict(TestForPred).astype(int)","5042cf10":"PassengerId=test['PassengerId']","d07cbe18":"rfc_pred=pd.DataFrame({'PassengerId': PassengerId, 'Survived':y_pred })\nrfc_pred.head()","3de356f5":"rfc_pred.shape","68e264fd":"#exporting results to csv file\nrfc_pred.to_csv(\"Titanic_Submission.csv\", index = False)","67998d80":"* We can add a new feature from existing columns SibSp and Parch to infer how many members per family aboard on Titanic.\n* We can infer Title column from Name feature to find more about the passenger aboarded. ","b6d2490a":"There are columns with NULL values. \nAge with 30 missing values and it can be treated using mean of other values in the Age column. As the values are normally distributed, it can be assumed that age values are symmetric about its mean.\n\nEmbarked is a categorical feature and has one missing value instead of dropping it, it can be replaced with most frequent value. This will not affect highly the survival rate.\n\nCabin column has a large range of missing values as compare to the size of the dataset. So to infer any knowledge from the data, we can drop this Cabin column as it will not affect the Survival rate that much. With Cabin we can drop other features like Ticket(column with mixed values), Fare(We have Pclass to get the 1st, 2nd and 3rd class passenger details). ","1a39abc6":"There are twelve columns in the titanic dataset.\n* PassengerId->Unique Identification of each passenger aboard in Titanic\n* Survived->Person Survived or not on the tragic Titanic crash\n* Pclass->Passenger Class as per Fare      \n* Sex->Sex    \n* Age->Age in years     \n* SibSp->siblings \/ spouses aboard the Titanic     \n* Parch->parent \/ children aboard the Titanic     \n* Ticket->Ticket Number     \n* Fare->Passenger fare for the ticket to aboard on Titanic     \n* Cabin->Cabin number     \n* Embarked->Port of Embarkation\n","2f79c292":"Survival rate is highly dependent on features like Sex, Pclass, IsAlone and Embarked","526b6378":"* For Pclass, First and Second class passengers survived more as compare to Third class passengers. \n* For Sex, survival rate for women are high compared to men as 'Women and Children were firsts while rescuing'.\n* For Embarked, survived or not are quite similar as per the strength of the ports, only for 'S':Southampton survival rate is low.","b0b74a89":"Titanic Dataset is the best dataset to practice all the primitive as well as important steps while building a machine learning model. These steps include:\n1. Loading the dataset\n2. Data preparation(data cleaning, handling NULL values, data analysis, visualization etc.)\n3. Choosing a model\n4. Training the model\n5. Evaluation of the model\n6. Hyperparamter Tuning\n7. Prediction","08457af1":"For final predictions we need to predict the available test data with us. We will implement the Random Forest Classifier model for predicting test set here."}}