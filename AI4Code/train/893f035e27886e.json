{"cell_type":{"4923c518":"code","820833c6":"code","f9f777b5":"code","20a7160e":"code","999e203e":"code","0bc1899c":"code","c69035b9":"code","8f7f371f":"code","a5a900a0":"code","09c0d64d":"code","7e2164d4":"code","9b82b93f":"code","8ada819b":"code","eccd97b9":"code","723c1bff":"code","b6e4f0a1":"code","4bd30b67":"code","08e02551":"code","79fef36d":"code","16bea6e4":"code","f84d6501":"code","55a7cb06":"code","7a155871":"code","a1d08385":"code","09f4f008":"code","2fe2ab0b":"code","1d948925":"code","aeb22b7a":"code","f135b04f":"code","7359aa86":"code","f46a2881":"code","6a73199b":"code","5683f5bf":"code","954cf3cd":"code","1bf9808c":"code","04107170":"code","da2a3fe5":"code","78232abf":"code","fe5950b3":"code","96bf4dda":"markdown","4f20f501":"markdown","965a897a":"markdown","fbf3b70f":"markdown","3381b5be":"markdown","acd52e04":"markdown","988be852":"markdown","c4eaaab9":"markdown","a9ca4d36":"markdown","2fa17fc7":"markdown","7e4b5c22":"markdown","c78e3418":"markdown","4e047af9":"markdown","de0c38ea":"markdown","69e4bd22":"markdown","689bf0f3":"markdown","18f73a81":"markdown","a79f5441":"markdown","78dda3cc":"markdown","c6033aea":"markdown","1821717e":"markdown","e63c678f":"markdown","8c439ff1":"markdown","e0e391ca":"markdown","252e58aa":"markdown","41929940":"markdown","799909eb":"markdown","a50d9644":"markdown","10877028":"markdown","66475c71":"markdown","8d7db3f8":"markdown","6676c50d":"markdown","692981e9":"markdown","e5353f14":"markdown","8ed23f98":"markdown","2cbbc1a8":"markdown","783dec49":"markdown","d4d99b13":"markdown","ed3c18b8":"markdown","d887b9b7":"markdown","e3d481d8":"markdown","f36de902":"markdown","35045caa":"markdown","26a1aaa8":"markdown","0424376c":"markdown","f75f68ea":"markdown"},"source":{"4923c518":"# Data Analysis\nimport numpy as np\nimport pandas as pd\nimport random\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# ML Models\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier","820833c6":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\ndatasets = [train_data, test_data]\ntrain_data.head()","f9f777b5":"train_data.info()","20a7160e":"test_data.info()","999e203e":"train_data.describe(exclude=['O'])","0bc1899c":"train_data.describe(include=['O'])","c69035b9":"plt.hist(train_data.loc[train_data['Embarked'].notnull(), 'Embarked'], bins=3)\nplt.xlabel('Embarked')\nplt.ylabel('Number of passengers')\nplt.title('The differences among all embarks')\nplt.show()","8f7f371f":"ax = sns.barplot(data=train_data, x='Sex', y='Survived')\nplt.title('Correlation between Sex and Survived')\nplt.show()\n\nMen = train_data[train_data['Sex'] == 'male']['Sex'].count()\nsurvived_men = train_data[(train_data['Sex'] == 'male') & (train_data['Survived'] == 1)]['Sex'].count()\nWomen = train_data[train_data['Sex'] == 'female']['Sex'].count()\nsurvived_women = train_data[(train_data['Sex'] == 'female') & (train_data['Survived'] == 1)]['Sex'].count()\n\nprint('The ratio of survived men : '+ '%' +str(round(100*survived_men \/ Men, 2)) )\nprint('The ratio of survived women : '+ '%' +str(round(100*survived_women \/ Women, 2)) )","a5a900a0":"ax = sns.barplot(data= train_data, x= 'Pclass', y='Survived')\nplt.title('Correlation between Pclass and Survived')\nplt.show()","09c0d64d":"ax = sns.barplot(data= train_data, x= 'Embarked', y='Survived')\nplt.title('Correlation between Embarked and Survived')\nplt.show()","7e2164d4":"train_data['bands'] = pd.qcut(train_data['Fare'], 3)\ntrain_data['bands'].unique()","9b82b93f":"for dataset in datasets:\n    \n    dataset.loc[(-0.001 < dataset['Fare']) & (dataset['Fare'] <= 8.662), 'Fare'] = 0\n    dataset.loc[(8.662 < dataset['Fare']) & (dataset['Fare'] <= 26.0), 'Fare'] = 1\n    dataset.loc[(26.0 < dataset['Fare']) & (dataset['Fare'] <= 513.329), 'Fare'] = 2\n    \n   \n    dataset['Fare'] = dataset.loc[dataset['Fare'].notnull(), 'Fare'].astype(int)\n","8ada819b":"print(train_data['Fare'].unique())\nprint(test_data['Fare'].unique())","eccd97b9":"ax = sns.pointplot(data=train_data, x='Fare', y='Survived')\nplt.title('Correlation between Fare and Survived')\nplt.show()","723c1bff":"train_data['AgeBands'] = pd.qcut(train_data['Age'], 5)\ntrain_data['AgeBands'].unique()","b6e4f0a1":"for dataset in datasets:\n    \n    dataset.loc[dataset['Age'] <= 19, 'Age'] = 10\n    dataset.loc[(19 < dataset['Age'] ) & (dataset['Age'] <= 25), 'Age' ] = 20\n    dataset.loc[(25.0 < dataset['Age'] ) & (dataset['Age'] <= 31.8), 'Age' ] = 30\n    dataset.loc[(31.8 < dataset['Age'] ) & (dataset['Age'] <= 41.0), 'Age' ] = 40\n    dataset.loc[(41.0 < dataset['Age'] ) & (dataset['Age'] <= 80.0), 'Age' ] = 50\n    \n    dataset['Age'] = dataset.loc[dataset['Age'].notnull(), 'Age'].astype(int)","4bd30b67":"print(train_data['Age'].unique())\nprint(test_data['Age'].unique())","08e02551":"sns.barplot(data= train_data, x='Age', y='Survived')\nplt.title('Correlation between Age and Survived')","79fef36d":"train_data.loc[(train_data['Age'] == 10), 'Age'] = 2\ntrain_data.loc[(train_data['Age'] == 20) | (train_data['Age'] == 50), 'Age'] = 0\ntrain_data.loc[(train_data['Age'] == 30) | (train_data['Age'] == 40), 'Age'] = 1\n\ntest_data.loc[(test_data['Age'] == 10), 'Age'] = 2\ntest_data.loc[(test_data['Age'] == 20) | (test_data['Age'] == 50), 'Age'] = 0\ntest_data.loc[(test_data['Age'] == 30) | (test_data['Age'] == 40), 'Age'] = 1\n\n\n# Let's give those null values the median of ages in their pclass\nfor pclass in range(1, 4):\n    \n    train_data.loc[ (train_data['Pclass'] == pclass) & (train_data['Age'].isnull()), 'Age'] = train_data.loc[ (train_data['Pclass'] == pclass) & (train_data['Age'].notnull()), 'Age' ].median()\n    test_data.loc[ (test_data['Pclass'] == pclass) & (test_data['Age'].isnull()), 'Age'] = test_data.loc[ (test_data['Pclass'] == pclass) & (test_data['Age'].notnull()), 'Age' ].median()","16bea6e4":"parchValues = train_data['Parch'].unique()\nSibSpValues = train_data['SibSp'].unique()","f84d6501":"train_data[ ['Parch', 'Survived'] ].groupby('Parch', as_index=False).mean().sort_values(by='Survived', ascending=False) ","55a7cb06":"train_data[ ['SibSp', 'Survived'] ].groupby('SibSp', as_index=False).mean().sort_values(by='Survived', ascending=False)","7a155871":"print('The shape before deletion for train data: ' + str(train_data.shape))\nprint('The shape before deletion for test data: ' + str(test_data.shape))\n\n\ntrain_data = train_data.drop(['Ticket', 'PassengerId', 'Cabin', 'AgeBands', 'bands'], axis=1)\ntest_data = test_data.drop(['Ticket', 'PassengerId', 'Cabin'], axis=1)\n    \nprint('\\nThe shape after deletion for train data: ' + str(train_data.shape))\nprint('The shape after deletion for test data: ' + str(test_data.shape))","a1d08385":"train_data.loc[train_data['Embarked'].isnull(), 'Embarked'] = 'S'\ntest_data.loc[test_data['Fare'].isnull(), 'Fare'] = test_data['Fare'].median()\n\ntest_data['Fare'] = test_data['Fare'].astype(int)","09f4f008":"# Their actual ratios\nsexMap = {'male':0.1889, 'female':0.742}\nembarkedMap = {'S':0.34, 'Q':0.38, 'C':0.55}\nPclassMap = {3:0.22, 2:0.46, 1:0.62}\n\n# Some feature engineering\ntrain_data['isAlone'] = 0\ntrain_data.loc[ (train_data['SibSp'] == 0) & (train_data['Parch'] == 0) , 'isAlone'] = 1\n\ntest_data['isAlone'] = 0\ntest_data.loc[ (test_data['SibSp'] == 0) & (test_data['Parch'] == 0) , 'isAlone'] = 1\n\n\n\n\n# For trainning data\ntrain_data['Embarked'] = train_data['Embarked'].map(embarkedMap)\ntrain_data['Sex'] = train_data['Sex'].map(sexMap)\ntrain_data['Pclass'] = train_data['Pclass'].map(PclassMap)\n    \ntrain_data.loc[train_data['SibSp'] >= 3, 'SibSp'] = 0\ntrain_data.loc[train_data['SibSp'] < 3, 'SibSp'] = 1\n    \n    \ntrain_data.loc[train_data['Parch'] >= 4, 'Parch'] = 0\ntrain_data.loc[(train_data['Parch'] > 0) & (train_data['Parch'] < 4), 'Parch'] = 1\n\n\n\n# For test data\ntest_data['Embarked'] = test_data['Embarked'].map(embarkedMap)\ntest_data['Sex'] = test_data['Sex'].map(sexMap) \ntest_data['Pclass'] = test_data['Pclass'].map(PclassMap)\n    \ntest_data.loc[test_data['SibSp'] >= 3, 'SibSp'] = 0\ntest_data.loc[test_data['SibSp'] < 3, 'SibSp'] = 1 \n    \ntest_data.loc[test_data['Parch'] >= 4, 'Parch'] = 0\ntest_data.loc[(test_data['Parch'] > 0) & (test_data['Parch'] < 4), 'Parch'] = 1\n","2fe2ab0b":"train_data['Title'] = train_data.Name.str.extract(r'(\\w+)\\.')\ntrain_data = train_data.drop('Name', axis=1)\n\ntest_data['Title'] = test_data.Name.str.extract(r'(\\w+)\\.')\ntest_data = test_data.drop('Name', axis= 1)\n\ntrain_data['Title'].unique()","1d948925":"titles = train_data['Title'].unique()\nnumDict = dict()\nfor title in titles:\n    numDict[title] = train_data.loc[ train_data['Title'] == title, 'Title' ].count()\n\ndf = train_data[ ['Title', 'Survived'] ].groupby('Title', as_index=False).mean().sort_values(by='Survived', ascending= False)\ndf['Repeated'] = [numDict[title] for title in df['Title']]\ndf","aeb22b7a":"# Positive correlation\ntrain_data = train_data.replace(['Countess', 'Ms', 'Mme', 'Lady', 'Dona', 'Mlle', 'Mrs', 'Miss', 'Master', 'Dr'], 2)\ntest_data = test_data.replace(['Countess', 'Ms', 'Mme', 'Lady', 'Dona', 'Mlle', 'Mrs', 'Miss', 'Master', 'Dr'], 2)\n\n# Nutral correlation\ntrain_data = train_data.replace(['Col', 'Major', 'Sir', 'Capt'], 1)\ntest_data = test_data.replace(['Col', 'Major', 'Sir', 'Capt'], 1)\n\n# Negative correlation\ntrain_data = train_data.replace(['Rev', 'Mr', 'Jonkheer', 'Don'], 0)\ntest_data = test_data.replace(['Rev', 'Mr', 'Jonkheer', 'Don'], 0)","f135b04f":"X = train_data.drop(['Survived'], axis=1)\ny = train_data['Survived']","7359aa86":"log_model = LogisticRegression()\nlog_model.fit(X, y)\nlog_model_score = round(log_model.score(X, y) * 100, 2)\nprint('%' + str(log_model_score))","f46a2881":"tree_model = DecisionTreeClassifier()\ntree_model.fit(X, y)\ntree_model_score = round(tree_model.score(X, y) * 100, 2)\nprint('%' + str(tree_model_score))","6a73199b":"forest_model = RandomForestClassifier()\nforest_model.fit(X, y)\nforest_model_score = round(forest_model.score(X, y) * 100, 2)\nprint('%' + str(forest_model_score))","5683f5bf":"SVC_model = SVC()\nSVC_model.fit(X, y)\nSVC_model_score = round(SVC_model.score(X, y) * 100, 2)\nprint('%' + str(SVC_model_score))","954cf3cd":"Linear_SVC_model = LinearSVC()\nLinear_SVC_model.fit(X, y)\nLinear_SVC_model_score = round(Linear_SVC_model.score(X, y) * 100, 2)\nprint('%' + str(Linear_SVC_model_score))","1bf9808c":"nb_model = GaussianNB()\nnb_model.fit(X, y)\nnb_model_score = round(nb_model.score(X, y) * 100, 2)\nprint('%' + str(nb_model_score))","04107170":"knn_model = KNeighborsClassifier()\nknn_model.fit(X, y)\nknn_model_score = round(knn_model.score(X, y) * 100, 2)\nprint('%' + str(knn_model_score))","da2a3fe5":"Perceptron_model = Perceptron()\nPerceptron_model.fit(X, y)\nPerceptron_model_score = round(Perceptron_model.score(X, y) * 100, 2)\nprint('%' + str(Perceptron_model_score))","78232abf":"SGD_model = SGDClassifier()\nSGD_model.fit(X, y)\nSGD_model_score = round(SGD_model.score(X, y) * 100, 2)\nprint('%' + str(SGD_model_score))","fe5950b3":"ourPred = forest_model.predict(test_data)\ntestReal = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmission = pd.DataFrame({\n        \"PassengerId\": testReal[\"PassengerId\"],\n        \"Survived\": ourPred\n    })\nsubmission.to_csv('submission.csv', index=False)\n","96bf4dda":"![pngtree-green-check-mark-icon-flat-style-png-image_1986021.jpg](attachment:38b0c260-5f3a-4812-b334-8eac968ad77b.jpg)","4f20f501":">  # ML Models","965a897a":"Same thing with Age","fbf3b70f":"**As we can see again 'Embarked' & 'Pclass' have their effect on 'Survived'**","3381b5be":"> **I think we can group them as two category:**\n\n**for Parch:**\n * *0 -> refers to 4 or more and zero and it's bad*\n * *1 -> refers to [1, 2, 3] and it's good*\n \n**for SibSp**\n * *0 -> refers to three or more values*\n * *1 -> refers to less than three*","acd52e04":"**Let's classify them into three categories:**\n   * child (2)\n   * Old & youth (0) \n   * else (1)","988be852":"**Categorize ( make numerical bands )**","c4eaaab9":"Now we will extract title from name and then remove name","a9ca4d36":"**KNeighborsClassifier**","2fa17fc7":"# Describe categorical data","7e4b5c22":"**Now we knew some important things:-**\n1. Most of Cabin Feature are missing data\n\n2. Our data has different types such that :\n    * {PassengerId, Age, SibSp, Parch, Fare} are numerical\n    * {survived, Name, Sex, Ticket, Cabin, Embarked, Pclass} are Categorical\n    \n3. Some Features might be unnecessary like :\n    * PassengerId -> Because it doesn't mean anything\n    * Name -> also it doesn't mean anything but we may extract some important information from it like titles\n    * Ticket -> it is also doesn't mean anything\n    * Cabin -> most of it are empty so we can't know is it efficient or not\n  ","c78e3418":"**DecisionTreeClassifier**","4e047af9":"*Actually, we don't have missing data instead of that in 'Embarked' so we can skip this step*\n* for this to missing values in 'Embarked' we will give it the mode in 'Embarked'\n* and one missing value in 'Fare' in test data","de0c38ea":"**Dropping**","69e4bd22":"![tumblr_ow192yPEzo1ti8ob9o1_250.gif](attachment:f400d1ca-3278-4b0a-a980-58b8f9823b03.gif)","689bf0f3":"# Describe numerical data","18f73a81":"Now we want to do the same thing with 'Fare' but first let's cut it into 3 bands","a79f5441":"**Since RandomForestClassifier is the best model we will use it.**","78dda3cc":"we will categorize Sex, SibSp, Parch and Embarked","c6033aea":"what about 'Pclass' & 'Embarked' features","1821717e":"> **Okay, now let's do some actions:**\n>  * Drop some features\n>  * make bands for the features which we said above\n>  * handle missing values","e63c678f":"![edit_find_T.png](attachment:23bbe90d-241e-4b64-9eed-e57a2efa2137.png)","8c439ff1":"**Perceptron**","e0e391ca":"**RandomForestClassifier**","252e58aa":"![Performance-management-to-fit-the-modern-workplace.jpg](attachment:04d9d37d-9a7c-4288-b73a-9184a55964b6.jpg)","41929940":"# Data Head","799909eb":"# Some Info","a50d9644":"**Handling missing values**","10877028":"*Let's start with sex feature*","66475c71":"**GaussianNB**","8d7db3f8":"\nAs we see here there is another reason here to drop ticket -> it has a lot of duplicates","6676c50d":"**As we can see here, there is a positive correlation between 'Fare' and 'Survived'**","692981e9":"**why don't we do that on 'Fare' feature and remove bands from our dataframe. \nin addition, we can make them categories.**","e5353f14":"\n> # EDA\n**Let us see the relation among our features and our target**","8ed23f98":"**Note:**\n * *SibSp = number of sisters + number of brothers + his\/her spouse*   (as it refers to sibling and spouse)\n * *Parch = number of parents travelled with him + number of chiledren*  (as it refers to parent and children)","2cbbc1a8":"**Linear_SVC**","783dec49":"> # For this simple solution we will try classify passengers in few steps:\n> \n>  * **Explore your Data**  \n>\n>  * **Exploratory Data Analysis (EDA)**\n> \n>  * **Making Decisions**\n>\n>  * **Cleaning & Missing Data Handling**\n> \n>  * **Prepare our data for ML**\n> \n>  * **Machine Learning (ML)** ","d4d99b13":"* ***Let's see the effect of each title***","ed3c18b8":"# Don't Forget to Upvote","d887b9b7":"**Logistic Regression**","e3d481d8":"**SGDClassifier**","f36de902":"***let's categorize them***\n* we gave the rarely-appear titles nutral values","35045caa":"**SVC**","26a1aaa8":"***As we can see women have a high ratio of survival, So 'Sex' feature is important***","0424376c":"> # Submission","f75f68ea":"Now we want to know the correlation between both 'Parch' and 'SibSp' with 'Survived'"}}