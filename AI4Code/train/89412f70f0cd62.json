{"cell_type":{"38e8386c":"code","161066a7":"code","73fa58a3":"code","b4d40866":"code","1d41306a":"code","0103af17":"code","85c05c91":"code","0396589b":"code","8ba72221":"code","e0f6dd23":"code","bc4bc098":"code","8740a0ba":"code","7f83bccc":"code","9a9b732f":"code","f51c9593":"code","e1f3fecb":"code","491bc4a7":"code","c119b669":"code","b1ff6dfb":"code","d4f86941":"markdown"},"source":{"38e8386c":"%matplotlib inline\nimport copy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport skimage\nfrom skimage import io, transform\nfrom sklearn.metrics import confusion_matrix\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms","161066a7":"print(os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/\"))","73fa58a3":"EPOCHS = 30\ndata_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\"\nTEST = 'test'\nTRAIN = 'train'\nVAL ='val'","b4d40866":"def data_transforms(phase):\n    if phase == TRAIN:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n        \n    if phase == VAL:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n    \n    if phase == TEST:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])        \n        \n    return transform\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","1d41306a":"image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms(x)) \n                  for x in [TRAIN, VAL, TEST]}\n\ndataloaders = {TRAIN: torch.utils.data.DataLoader(image_datasets[TRAIN], batch_size = 4, shuffle=True), \n               VAL: torch.utils.data.DataLoader(image_datasets[VAL], batch_size = 1, shuffle=True), \n               TEST: torch.utils.data.DataLoader(image_datasets[TEST], batch_size = 1, shuffle=True)}","0103af17":"len(dataloaders[TRAIN])","85c05c91":"dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL]}\nclasses = image_datasets[TRAIN].classes\nclass_names = image_datasets[TRAIN].classes","0396589b":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders[TRAIN]))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","8ba72221":"inputs, classes = next(iter(dataloaders[TRAIN]))","e0f6dd23":"def train_model(model, criterion, optimizer, scheduler, num_epochs):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch: {}\/{}\".format(epoch+1, num_epochs))\n        print(\"=\"*10)\n        \n        for phase in [TRAIN, VAL]:\n            if phase == TRAIN:\n                scheduler.step()\n                model.train()\n            else:\n                model.eval()\n            # initialize the parameters\n            # compute the loss\n            # compute the gradients\n            running_loss = 0.0\n            running_corrects = 0\n            for data in dataloaders[phase]:\n                inputs, labels = data\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                # forward\n                # track history when the phase is train\n                with torch.set_grad_enabled(phase==TRAIN):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","bc4bc098":"model_pre = models.vgg16()\nmodel_pre.load_state_dict(torch.load(\"..\/input\/vgg16\/vgg16-397923af.pth\"))","8740a0ba":"# donot calculate gradient since we will use the weights of pretrained model\nfor param in model_pre.features.parameters():\n    param.required_grad = False\n\nnum_features = model_pre.classifier[6].in_features\n# Remove last layer\nfeatures = list(model_pre.classifier.children())[:-1] \nfeatures.extend([nn.Linear(num_features, len(class_names))])\n# Replace the model classifier with new classifier\nmodel_pre.classifier = nn.Sequential(*features) \nprint(model_pre)","7f83bccc":"model_pre = model_pre.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_pre.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n# Decay LR by a factor of 0.1 every 10 epochs\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)","9a9b732f":"model_pre = train_model(model_pre, criterion, optimizer, exp_lr_scheduler, num_epochs=EPOCHS)","f51c9593":"def test_model():\n    running_correct = 0.0\n    running_total = 0.0\n    true_labels = []\n    pred_labels = []\n    with torch.no_grad():\n        for data in dataloaders[TEST]:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            true_labels.append(labels.item())\n            outputs = model_pre(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            pred_labels.append(preds.item())\n            running_total += labels.size(0)\n            running_correct += (preds == labels).sum().item()\n        acc = running_correct\/running_total\n    return (true_labels, pred_labels, running_correct, running_total, acc)","e1f3fecb":"true_labels, pred_labels, running_correct, running_total, acc = test_model()\nprint(\"Total Correct: {}, Total Test Images: {}\".format(running_correct, running_total))\nprint(\"Test Accuracy: \", acc)","491bc4a7":"cm = confusion_matrix(true_labels, pred_labels)\n# a nice hack for binary classification\ntn, fp, fn, tp = cm.ravel()\nax = sns.heatmap(cm, annot=True, fmt=\"d\")","c119b669":"recall = tp\/(tp + fn)\nprecision = tp\/((tp + fp))\nf1_score = 2 * (recall * precision)\/(precision + recall)","b1ff6dfb":"print(\"F1 Score:\", f1_score)","d4f86941":"**Confusion Matrix, Presision and Recall**"}}