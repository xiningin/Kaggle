{"cell_type":{"12385b87":"code","39cba31a":"code","91e1f08c":"code","57126ff1":"code","72056bbc":"code","02978b50":"code","29365a68":"code","10473bd4":"code","e92f681c":"code","f5bf33b9":"code","6335af75":"code","9aa32b63":"code","7577c9e3":"code","15025d3a":"code","c478cc86":"code","834b72be":"code","c83b0831":"code","111614a1":"code","77993fd0":"code","29f92715":"code","c0ba6830":"code","252865f2":"code","2f0f7953":"code","05a73504":"code","03e65799":"code","79f5eca0":"code","4cf712d4":"code","1b538a45":"code","3f35108e":"code","3c194672":"code","32d844ce":"code","4a3a81b2":"code","098d8778":"code","a1afb37a":"code","c6d8d96f":"code","d7fdf59b":"code","8d20a2d0":"code","5e36b27d":"code","313ee830":"code","2e232e06":"code","db706711":"code","4931a76b":"code","596b7aaa":"code","d5021556":"code","fa157c9d":"code","c60ff42a":"code","f9cab97e":"code","86d7d184":"code","e39083cb":"markdown","28107355":"markdown","0bd6c17f":"markdown","7ce1160d":"markdown","feaf05bb":"markdown","490de26b":"markdown","9558082e":"markdown","337ca67e":"markdown","dbbcf489":"markdown","0c49c272":"markdown","2c3ded17":"markdown","df720e15":"markdown","1ad44d9a":"markdown","84ced4ba":"markdown","60516925":"markdown","f5ae1777":"markdown","d9180e3f":"markdown","0714c314":"markdown","5f56b317":"markdown","5f0c6884":"markdown"},"source":{"12385b87":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n# general variables used\ninterval = 7\n\n# data are \u201eFallzahlen in Deutschland\u201c of the Robert Koch Institute (RKI), Germany:\n# https:\/\/www.rki.de\/DE\/Content\/InfAZ\/N\/Neuartiges_Coronavirus\/Fallzahlen.html\n# license-ID: \u201edl-de-by-2.0\"\n# license for 'Open Data Datenlizenz Deutschland \u2013 Namensnennung \u2013 Version 2.0':\n#             https:\/\/www.govdata.de\/dl-de\/by-2-0\n\n# location:\n# remote (newest data): https:\/\/opendata.arcgis.com\/datasets\/dd4580c810204019a7b8eb3e0b329dd6_0.csv\n# local: ..\/input\/\/dd4580c810204019a7b8eb3e0b329dd6_0.csv\ncorona = pd.read_csv('https:\/\/opendata.arcgis.com\/datasets\/dd4580c810204019a7b8eb3e0b329dd6_0.csv',\n                    index_col='ObjectId', parse_dates=['Meldedatum', 'Refdatum'],\n                    usecols=lambda column : column not in [\"IdBundesland\", \"Altersgruppe2\", \"Geschlecht\", \"NeuerFall\", \"NeuerTodesfall\", \"NeuGenesen\"])\n\ncorona.dropna(axis=1, inplace=True)\ncorona.head(20)","39cba31a":"# We don't need the column 'Datenstand'. It seems to have only informational value\ncorona.drop(['Datenstand'], axis=1, inplace=True)\ncorona.info()","91e1f08c":"corona","57126ff1":"# Define lists for all age classes (0-4, 5-14, 15-34, 35-59, 60-79, 80+)\nA00 = []\nA05 = []\nA15 = []\nA35 = []\nA60 = []\nA80 = []\n\ndef addWeightToAltersgruppe(weight, altersgruppe):\n    unknown = 0\n    \n    if weight < 0: print (\"negative weight found: \", weight)\n    \n    if altersgruppe == 'A00-A04':\n        A00.append(weight)\n    elif altersgruppe == 'A05-A14':\n        A05.append(weight)\n    elif altersgruppe == 'A15-A34':\n        A15.append(weight)\n    elif altersgruppe == 'A35-A59':\n        A35.append(weight)\n    elif altersgruppe == 'A60-A79':\n        A60.append(weight)\n    elif altersgruppe == 'A80+':\n        A80.append(weight)\n    else:\n        unknown += 1\n        \n# Mark entries where Meldedatum-Erkrankungsdatum > 30 as unknown\ndef correctErkrankungsDatum(IstErkr, MeldeDatum, Refdatum, Altersgruppe):\n    if (IstErkr == 0):\n        return 0\n    else:\n        timeDelta = MeldeDatum - Refdatum\n        if timeDelta.days > 30 or timeDelta.days < 0:\n            # Erkrangusdatum of this row is too far away from MeldeDatum or negative\n            return 0\n        else:\n            # collect delta of MeldeDatum and ReferenzDatum\n            addWeightToAltersgruppe(timeDelta.days, Altersgruppe)\n            return 1\n\ncoronaErkrBegin = corona[corona['IstErkrankungsbeginn'] == 1]\nprint(\"Amount of data with known beginning date of illness: \", (coronaErkrBegin.shape[0] * 100)\/corona.shape[0] ,\"%\")\n\ncorona['IstErkrankungsbeginn'] = corona.apply(lambda x: correctErkrankungsDatum(\n                x['IstErkrankungsbeginn'], x['Meldedatum'], x['Refdatum'], x['Altersgruppe']), axis=1)","72056bbc":"# calculate the Meanvalue for each of the collected Axx values\nM00 = round(pd.Series(A00).mean())\nM05 = round(pd.Series(A05).mean())\nM15 = round(pd.Series(A15).mean())\nM35 = round(pd.Series(A35).mean())\nM60 = round(pd.Series(A60).mean())\nM80 = round(pd.Series(A80).mean())\n\n# empty the long Axx lists because we don't need them any longer\nA00 = []\nA05 = []\nA15 = []\nA35 = []\nA60 = []\nA80 = []\n\nprint(\"Delta of all six age classes: \", M00, M05, M15, M35, M60, M80)","02978b50":"# Adjust entries with unknown sickness date with M00 .. M80\n# ==> imputedDate (imputiertes Datum)\n\ndef addMeanErkrankungsDatum(IstErkr, MeldeDatum, Refdatum, altersgruppe):\n    if (IstErkr == 1):\n        # these entries are already ok\n        return Refdatum\n    \n    else:\n        # Depending on Altersgruppe subtract Mean of ErkrankungsDatum of MeldeDatum\n        if altersgruppe == 'A00-A04':\n            delta = M00\n        elif altersgruppe == 'A05-A14':\n            delta = M05\n        elif altersgruppe == 'A15-A34':\n            delta = M15\n        elif altersgruppe == 'A35-A59':\n            delta = M35\n        elif altersgruppe == 'A60-A79':\n            delta = M60\n        elif altersgruppe == 'A80+':\n            delta = M80\n        else:\n            # comment next line if there are too much unknown Altersgrppen\n#            print(Refdatum, \" - unknown Altersgruppe found: \", altersgruppe)\n            return Refdatum\n        \n        imputedDate = MeldeDatum - np.timedelta64(delta, 'D')\n        return imputedDate\n\ncorona['Refdatum'] = corona.apply(lambda x: addMeanErkrankungsDatum(\n                    x['IstErkrankungsbeginn'], x['Meldedatum'], x['Refdatum'], x['Altersgruppe']), axis=1)","29365a68":"# Remove cols Altersgruppe, Meldedatum and IstErkrankungsbeginn (we don't need them anymore)\n# remaining columns can be seen in the listing of coronaDrop.info()\ncoronaDrop = corona.drop(['Altersgruppe', 'Meldedatum', 'IstErkrankungsbeginn'], axis=1)\ncoronaDrop.info()","10473bd4":"def sumKreisErkrankungsdatum(X):\n    n = X.shape[0]    \n    IdLandkreisCol = 4\n    RefDatumCol = 5\n\n    # define a list which will hold the new rows collected\n    erkrankte = []\n\n    row = X[0]\n    lastRefDatum = row[RefDatumCol] \n    lastId = row[IdLandkreisCol]\n    \n    for iter in range(1,n):\n        if (lastRefDatum == X[iter][RefDatumCol]) and (lastId == X[iter][IdLandkreisCol]):\n            # same RefDatum and IdLandkreis row read\n            # summarize cols AnzahlFall, AnzahlTodesfall, AnzahlGenesen\n            for r in [2, 3, 6]:\n                row[r] = row[r] + X[iter][r]\n\n        else:\n            # another RefDatum and\/or IdLandkreis row read\n            erkrankte.append(row)\n            \n            # use current row as the base row\n            row = X[iter]\n            lastRefDatum = X[iter][RefDatumCol] \n            lastId = X[iter][IdLandkreisCol]\n\n    # append the last row collected in the for-loop that is terminated\n    erkrankte.append(row)\n\n    # return a stack from the list erkrankte, a new nparray\n    return np.stack(erkrankte, axis=0)\n\n# Note: before performing the calculation sort the whole dataset according 'IdLandkreis' and 'Refdatum'\ncoronaDrop.sort_values(by=['IdLandkreis', 'Refdatum'], inplace=True)\n\n# IMPORTANT Note: if date-time\/timezone conversion errors happen then uncomment the last line of the following block\n#                 remove Timezone infos (once RKI's data contained UTC infos that Pandas could not handle directly)\ncoronaDrop['Refdatum'] = coronaDrop['Refdatum'].dt.tz_localize(None)\n\n# now call the defined function above returning a new nparray\nrkiSum = sumKreisErkrankungsdatum(coronaDrop.to_numpy())\nrkiSum.shape\n# rkiSum[0:9]","e92f681c":"# Swapping some columns in rkiSum\n# first swap IdKreis and new infections (AnzahlFall)\ncol1 = 2\ncol2 = 4\nrkiSum.T[[col1, col2]] = rkiSum.T[[col2, col1]]\n\n# second swap RefDatum and Tote\ncol1 = 3\ncol2 = 5\nrkiSum.T[[col1, col2]] = rkiSum.T[[col2, col1]]","f5bf33b9":"# definition of two helper functions used by \n# computeDoublingFactorAndRnumber and later by createBundeslandProgress\n\ndef getHighestMinimum(descList, factor):\n    \"\"\"\n    from a list containing descending items get that index which fulfills:\n    h = descList[0] (= biggest element of desclist)\n    find index i that descList[i] <= h\/factor and descList[i-1] > h\/factor\n    \"\"\"\n\n    if len(descList) == 0:\n        return 0\n    \n    i = 0\n    quot = int(descList[0] \/ factor)\n    for el in descList:\n        if el <= quot:\n            return i\n        else:\n            i += 1\n\n    return 1    # default\n\ndef calcSmoothedValue(descList, interval):\n    \"\"\"\n    get a smoothed (average) value of current NeuInfektionen from a dayrange (interval days)\n    This comes close to RKI's definition of Nowcasting with Generationenzeit = 4 (or 7) days\n    descList - list containing the total sum of new infections in descending order\n    \"\"\"\n    if len(descList) <= interval:\n        return descList[0] \/ len(descList)\n    else:\n        # descList is somewhat tricky because first element is also the sum of the rest of the list elements\n        # We only need to care about its first and its (interval+1)-th element (list starts with index 0)\n        return (descList[0] - descList[interval]) \/ interval\n    ","6335af75":"def computeDoublingFactorAndRnumber(X, interval):\n    \"\"\"\n    Every row in X contains exactly one combination of 'IdLandkreis' and 'RefDatum'\n    \"\"\"\n    n = X.shape[0]\n    \n    # we will add six new columns to X\n    X = np.append(X, np.zeros((n,6), dtype=int), axis=1)\n\n    IdLandkreisCol = 2\n    AnzahlFallCol = 4\n    AnzahlToteCol = 5\n    AnzahlGeneseneCol = 6\n    \n    # new columns to be used\n    SumNeuInfCol = 7\n    SumToteCol = 8\n    SumGenesenCol = 9    \n    VerdopplungsCol = 10\n    NowcastingCol = 11\n    ReprozahlCol = 12\n    \n    lastKreisId = -1\n    sumNeuInf = 0\n    sumTote   = 0\n    sumGenesene = 0\n    \n    # collect the cummulated infection numbers\n    seqNeuInf = []\n\n    print(\"computeDoublingFactorAndRnumber: day-interval for Nowcasting =\", interval)\n\n    for iter in range(n):\n        if lastKreisId == X[iter][IdLandkreisCol]:\n            # same Landkreis \/ Stadt - series\n            sumNeuInf += X[iter][AnzahlFallCol]\n            X[iter][SumNeuInfCol] = sumNeuInf\n            seqNeuInf.insert(0, sumNeuInf)\n            \n            sumTote += X[iter][AnzahlToteCol]\n            X[iter][SumToteCol] = sumTote\n\n            sumGenesene += X[iter][AnzahlGeneseneCol]\n            X[iter][SumGenesenCol] = sumGenesene\n            \n            # VerdopplungsZahl: search backwards in seqNeuInf until \n            #  finding an element e with: e <= sumNeuInf\/2.\n            #  Verd.zahl = number of indices you stepped back\n            X[iter][VerdopplungsCol] = getHighestMinimum(seqNeuInf, 2)\n            \n            X[iter][NowcastingCol] = calcSmoothedValue(seqNeuInf, interval)\n            if X[iter][NowcastingCol] == 0:\n                # Normally this case should not happen! When its the case then something is wrong with the RKI\n                # data i.e. some data is missing or many corrections (negative new infections) were delivered!\n                print (\"Warning: Nowcasting <= 0!\", X[iter])\n                # Choose a value near zero to avoid a Division by Zero Error later in else part\n                X[iter][NowcastingCol] = 0.1\n            if len(seqNeuInf) < (interval):\n                X[iter][ReprozahlCol] = 2.5 # = R_0, accord. RKI the initial value for R (2 - 3)\n            else:\n                # compute R as a quotient of two interval-day series (Nowcasting)\n                X[iter][ReprozahlCol] = X[iter][NowcastingCol] \/ X[iter-interval+1][NowcastingCol]\n\n        else:\n            # another IdLandkreis series will start\n            lastKreisId = X[iter][IdLandkreisCol]\n            sumNeuInf = X[iter][AnzahlFallCol]\n            sumTote   = X[iter][AnzahlToteCol]\n            sumGenesene = X[iter][AnzahlGeneseneCol]\n\n            # append new cols cummulated sum of F\u00e4lle, Tote, Genesene\n            X[iter][SumNeuInfCol] = sumNeuInf\n            X[iter][SumToteCol] = sumTote\n            X[iter][SumGenesenCol] = sumGenesene\n    \n            # and additional new cols for the factors and numbers\n            seqNeuInf = [sumNeuInf]\n            X[iter][VerdopplungsCol] = 1\n            X[iter][NowcastingCol] = float(sumNeuInf)\n            X[iter][ReprozahlCol]  = 2.5 # approx. the beginning of R for such kind of virus = R_0\n\n    return X\n\nrkiVRfactors = computeDoublingFactorAndRnumber(rkiSum, interval)","9aa32b63":"# To understand the computation of NewCasting (second last element) and ReprodZahl (last element)\n# see next print containing the first cases of SK Flensburg of the resulting npArray rkiVRfactors; \n# the number of new infections is the element after the Timestamp\nrkiVRfactors[0:14]","7577c9e3":"# Original taken from the german 'Statistisches Bundesamt':\n# https:\/\/www.destatis.de\/DE\/Themen\/Laender-Regionen\/Regionales\/Gemeindeverzeichnis\/Administrativ\/04-kreise.xlsx\n#\n# For several reasons some data had to be corrected i.e.:\n## - shrinking original header to only one header line\n## - removing blanks within bigger numbers and replacing ',' by '.' within numbers\n## - corrections in the columns 'Regionale Bezeichnung' and 'Kreisfreie Stadt - Landkreis'\n## - removing ',' within composed district or town names\n## - completing population numbers for the rows containing the name of a state (Bundesland)\n## - adding population numbers for 12 districts (IdKreis 11001-11012) of Berlin (numbers taken from RKI Dashboard:\n##     https:\/\/experience.arcgis.com\/experience\/478220a4c454480e823b17327b2bf1d4 )\n## - completing first row for whole Germany (key (Schl\u00fcsselnummer) = 0)\n#\n# Therefore use this modified file instead the original one, or you must perform all steps by your own ;-)\n\nfrom os import environ\nif environ.get('KAGGLE_URL_BASE') == 'https:\/\/www.kaggle.com':\n    # we are in Kaggle environment and expect the url above\n    filename = '..\/input\/districts-and-towns-in-germany2019\/Districts and Towns in Germany.2019.csv' \nelse:\n    # we are in another environment, maybe on a local machine\n    filename = '\/Users\/ralfschukey\/Documents\/Politik\/Statistisches_Bundesamt\/Districts and Towns in Germany.2019.csv'\n\nlandkreise = pd.read_csv(filename, index_col=0, dtype = {'Schl\u00fcsselnummer' : 'int64'},\n                        usecols=lambda column : column not in [\"NUTS3\"])\n# landkreise.info()\nlandkreise.head(30)","15025d3a":"# add two new columns NeuInfekt100000, Todesf\u00e4lle100000\n\ndef addPopulation100000(X):\n    n = X.shape[0]\n    X = np.append(X, np.zeros((n,2)), axis=1)\n\n    IdLandkreisCol = 2\n    SumInfCol = 7\n    SumToteCol = 8\n\n    Inf100000Col = 13\n    Tote100000Col = 14\n\n    for iter in range(n):\n        bev = landkreise.at[X[iter][IdLandkreisCol], 'Bev\u00f6lkerung']\n#           print(IdLandkreis, bev)\n        if (bev == 0):\n            X[iter][Inf100000Col] = 0\n            X[iter][Tote100000Col] = 0\n        else:\n            X[iter][Inf100000Col] = (X[iter][SumInfCol] * 100000)\/bev\n            X[iter][Tote100000Col] = (X[iter][SumToteCol] * 100000)\/bev\n\n    return X\n\nrki100000 = addPopulation100000(rkiVRfactors)\n\n# Swap two columns for better grouping\ncol1 = 10\ncol2 = 13\nrki100000.T[[col1, col2]] = rki100000.T[[col2, col1]]","c478cc86":"# add two new columns NeueF\u00e4lle7T and Inzidenz7T (new infected since the last 7 days \/ per 100000)\n\ndef addInzidenz7Days(X, interval):\n    n = X.shape[0]\n    X = np.append(X, np.zeros((n,2)), axis=1)\n\n    IdLandkreisCol = 2\n    ErkrDatumCol = 3\n    AnzahlFallCol = 4\n    NeueF\u00e4lle7TCol = 15\n    Inzidenz7TCol = 16\n    \n    lastKreisId = -1\n    indexList = []\n\n    for iter in range(n):\n        if lastKreisId == X[iter][IdLandkreisCol]:\n            # same Landkreis \/ Stadt - series\n            indexList.append(iter)\n            \n            # add current new case to sumNeuInf\n            sumNeuInf += X[iter][AnzahlFallCol]\n\n            currentErkrDatum = X[iter][ErkrDatumCol]\n            timeDelta = currentErkrDatum - firstErkrDatum\n            \n            # current row is more than 7 (interval+1) days away resp. FirstErkrDatum\n            while timeDelta.days >= interval:\n                # pop first element of list and read the new first element aka index\n                firstIndex = indexList.pop(0)\n                nextIndex = indexList[0]\n                \n                # subtract first remembered new case from sumNeuInf\n                sumNeuInf -= X[firstIndex][AnzahlFallCol]\n                \n                firstErkrDatum = X[nextIndex][ErkrDatumCol]\n                timeDelta = currentErkrDatum - firstErkrDatum\n        \n        else:\n            # another IdLandkreis row series will start: init some variables\n            lastKreisId = X[iter][IdLandkreisCol]\n            firstErkrDatum = X[iter][ErkrDatumCol]\n            indexList = [iter]\n            \n            sumNeuInf = X[iter][AnzahlFallCol]\n            bev = landkreise.at[lastKreisId, 'Bev\u00f6lkerung']\n\n        # for each row store NeueF\u00e4lle7T and Inzidenz7T\n        X[iter][NeueF\u00e4lle7TCol] = sumNeuInf\n        X[iter][Inzidenz7TCol ] = (sumNeuInf * 100000)\/bev\n\n    return X\n\nrkiInzidenz = addInzidenz7Days(rki100000, interval)","834b72be":"# Movinging last column rkiInzidenz two columns backwards\ncol1 = 15\ncol2 = 11\nrkiInzidenz.T[[col1, col2]] = rkiInzidenz.T[[col2, col1]]\ncol1 = 16\ncol2 = 12\nrkiInzidenz.T[[col1, col2]] = rkiInzidenz.T[[col2, col1]]\ncol1 = 13\ncol2 = 14\nrkiInzidenz.T[[col1, col2]] = rkiInzidenz.T[[col2, col1]]","c83b0831":"coronaAll = pd.DataFrame(data=rkiInzidenz, \n         columns=['Bundesland', 'Landkreis', 'IdKreis', 'ErkrDatum', 'Neuinf', 'Tote', 'Genesene', 'F\u00e4lleSum', 'ToteSum', 'GeneseneSum', 'F\u00e4lle100k', 'Neuinf7TSum', 'Inzidenz7T', 'Tote100k', 'VerdZahl', 'Nowcasting', 'ReprodZahl'])\ncoronaAll","111614a1":"def createBundeslandAndKreisSummary(border):\n    '''\n    return a new DataFrame containing the summary of all states\n    extracted from their Landkreise and Staedte\n    Also as a side-affect build a second DataFrame landkreiseLast consisting of the last entry per kreis\n    '''\n    \n    # Problem: the values for ReprodZahl and VerdZahl are calculated via mean() of all Landkreise!\n    # This might be incorrect because they tend to be too high!\n    # However later in createBundeslandProgress the values for R and V will be recalculated correctly.\n    \n    #  init all counter\n    FaelleSum = 0\n    GeneseneSum = 0\n    ToteSum = 0\n    Neuinf7TSum = 0\n    avgV = []\n    avgR = []\n    populationSum = 0\n    populationBuLand = 0\n    bundeslandId = 0\n    landkreiseLast = None\n    KeineNeuenF\u00e4lle = 0\n\n    # TODO: get rid of coronaAll['ErkrDatum'].describe()\n    lastErkrDatum = coronaAll['ErkrDatum'].sort_values(ascending=False).iloc[0] \n            # - np.timedelta64(0, 'D')\n    print(\"lastErkrDatum at all: \", lastErkrDatum, \", 7-daysBorder = \", border)\n\n    # iterate over the keys (Schl\u00fcsselnummern) of landkreise\n    for key in landkreise.index:\n        if key == 0:\n            # first row should contain: Staat, Deutschland \n            bundesland = landkreise.at[key, 'Kreisfreie Stadt \u2013 Landkreis']\n            summary = pd.DataFrame({'Bundesland': bundesland,\n                                    'F\u00e4lleSum'   :  0,\n                                    'GeneseneSum':  0,\n                                    'ToteSum'    :  0,\n                                    'Neuinf7TSum':  0,\n                                    'Inzidenz7T' :  0.,\n                                    'F\u00e4lle100k'  :  0.,\n                                    'Tote100k'   :  0.,\n                                    'VerdZahl'   :  0.,\n                                    'ReprodZahl' :  0.,\n                                    }, index=[0])\n            continue\n            \n        if key < 20:\n            # we read a row of a country (Bundesland)\n\n            # We know that with key == 1 the first Bundesland row will be read\n            # As until now nothing is collected skip next if-block\n\n            if key > 1:\n                if populationBuLand == 0:\n                    print('Error: Population in Bundesland ' + bundesland + ' is zero!')\n                    return None\n            \n                if populationBuLand != populationSum:\n                    print('Warning: Found different population numbers in Bundesland ' + bundesland + ':')\n                    print('         whole population read', populationBuLand, 'unequals sum of its districts', populationSum)\n                \n                if populationSum > 0:\n                    # post processing of the counters we have read so far\n                    land = pd.DataFrame({'Bundesland': bundesland,\n                                   'F\u00e4lleSum'    : FaelleSum,\n                                   'GeneseneSum' : GeneseneSum,\n                                   'ToteSum'     : ToteSum,\n                                   'Neuinf7TSum' : Neuinf7TSum,\n                                   'Inzidenz7T'  : Neuinf7TSum * 100000\/populationBuLand,\n                                   'F\u00e4lle100k'   : FaelleSum   * 100000\/populationBuLand,\n                                   'Tote100k'    : ToteSum     * 100000\/populationBuLand,\n                                   'VerdZahl'    : pd.Series(avgV, dtype='float16').mean(),\n                                   'ReprodZahl'  : pd.Series(avgR, dtype='float16').mean(),\n                                  }, index=[bundeslandId])\n                    summary = summary.append(land)\n                \n            # next Bundesland series is starting\n            bundeslandId = key\n            bundesland = landkreise.at[key, 'Kreisfreie Stadt \u2013 Landkreis']\n            populationBuLand = int(landkreise.at[key, 'Bev\u00f6lkerung'])\n            print('Processing districts and towns for', landkreise.at[key, 'Regionale Bezeichnung'], bundesland, '...')\n                \n            #  init all counter\n            populationSum = 0\n            FaelleSum = 0\n            GeneseneSum = 0\n            ToteSum = 0\n            Neuinf7TSum = 0\n            avgV = []\n            avgR = []\n\n        else:\n            if key < 1000:\n                # got row for a region of a Bundesland, ignore it\n                continue\n                \n            # we are within a series of one Bundesland\n            \n            # 1. interpolate the next last ErkrDatum of the actual landkreisID\n            coronaKreis = coronaAll[coronaAll['IdKreis'] == key]['ErkrDatum']\n            if (coronaKreis.size == 0):\n                # There is no data for this district available\n                print(\"Warning: No data found for IdKreis\", landkreise.at[key, 'Kreisfreie Stadt \u2013 Landkreis'])\n                continue\n                \n            foundIndex = coronaKreis.tail(1).index\n            ser = coronaAll.iloc[foundIndex]\n\n            # 2. sum \/ add all counters\n            populationSum = populationSum + int(landkreise.at[key, 'Bev\u00f6lkerung'])\n\n            FaelleSum = FaelleSum + int(ser['F\u00e4lleSum'])\n            GeneseneSum = GeneseneSum + int(ser['GeneseneSum'])\n            ToteSum = ToteSum + int(ser['ToteSum'])\n            avgV.append(float(ser['VerdZahl']))\n            avgR.append(float(ser['ReprodZahl']))\n            \n            # print(type(lastErkrDatum), 'vers.', type(ser['ErkrDatum'].values[0]))\n\n            timeDelta = lastErkrDatum - ser['ErkrDatum'].values[0]\n            if timeDelta.days < border:\n                Neuinf7TSum = Neuinf7TSum + int(ser['Neuinf7TSum'])\n                if landkreiseLast is None:\n                    landkreiseLast = ser\n                else:\n                    landkreiseLast = landkreiseLast.append(ser)\n\n            else:\n                KeineNeuenF\u00e4lle += 1\n                # print out the kreis\/town that had currently no new infections\n#                print(key, \": Last Erkr.Datum of \", landkreise.at[key, 'Kreisfreie Stadt \u2013 Landkreis'],\n#                      \"is too far:\", timeDelta.days, \"days\")\n\n    if populationBuLand == 0:\n        print('Error: Population in Bundesland ' + bundesland + ' is zero!')\n        return None\n            \n    if populationSum > 0:\n        # for the last Bundesland collected store its values\n        df = pd.DataFrame({'Bundesland'  : bundesland,\n                       'F\u00e4lleSum'    : FaelleSum,\n                       'GeneseneSum' : GeneseneSum,\n                       'ToteSum'     : ToteSum,\n                       'Neuinf7TSum' : Neuinf7TSum,\n                       'Inzidenz7T'  : Neuinf7TSum * 100000\/populationSum,\n                       'F\u00e4lle100k'   : FaelleSum   * 100000\/populationSum,\n                       'Tote100k'    : ToteSum     * 100000\/populationSum,\n                       'VerdZahl'    : pd.Series(avgV, dtype='float16').mean(),\n                       'ReprodZahl'  : pd.Series(avgR, dtype='float16').mean(),\n                       }, index=[bundeslandId])\n        summary = summary.append(df)\n    \n    print(\"Number of districts (total sum = 412) with no recent cases:\", KeineNeuenF\u00e4lle)\n    return summary, landkreiseLast\n\n# carefully adjust dateBorder!\ndaysBorder = 8 + round(max(M00, M05, M15, M35, M60, M80) \/ 2)  # \nbundeslaenderSum, landkreiseLast = createBundeslandAndKreisSummary(daysBorder)\n\n# in landkreiseLast use 'IdKreis' as index key because it is ambiguous now\nlandkreiseLast.set_index('IdKreis', inplace=True)","77993fd0":"landkreiseLast.describe()","29f92715":"def fillDeutschlandrow():\n\n    # summarize and average (mean) columnwise\n    srSum  = bundeslaenderSum.sum(axis=0)\n    srMean = bundeslaenderSum.mean(axis=0)\n\n    # first row 'Deutschland' Insgesamt\n    bevDeutschland = int(landkreise.at[0, 'Bev\u00f6lkerung'])\n    bundeslaenderSum.at[0, 'F\u00e4lleSum'   ] = srSum['F\u00e4lleSum']\n    bundeslaenderSum.at[0, 'ToteSum'    ] = srSum['ToteSum']\n    bundeslaenderSum.at[0, 'GeneseneSum'] = srSum['GeneseneSum']\n    bundeslaenderSum.at[0, 'Neuinf7TSum'] = srSum['Neuinf7TSum']\n    bundeslaenderSum.at[0, 'Inzidenz7T' ] = srMean['Inzidenz7T']\n    bundeslaenderSum.at[0, 'F\u00e4lle100k'  ] = (srSum['F\u00e4lleSum'] * 100000)\/bevDeutschland\n    bundeslaenderSum.at[0, 'Tote100k'   ] = (srSum['ToteSum'] * 100000)\/bevDeutschland\n    bundeslaenderSum.at[0, 'VerdZahl'   ] = srMean['VerdZahl']\n    bundeslaenderSum.at[0, 'ReprodZahl' ] = srMean['ReprodZahl']\n\nfillDeutschlandrow()\nbundeslaenderSum","c0ba6830":"# Calculate deathrate (Todesrate) per 100000 in bundeslaenderSum\ndef calculateDeathRate(F\u00e4lle, Tote):\n    return 100 * Tote \/ F\u00e4lle\n\ndef swapDFTwoColumns(df, col1, col2):\n    # swap new (last) column with VerdZahl\n    cols = list(df.columns)\n    cols[col1], cols[col2] = cols[col2], cols[col1]\n    return df[cols]\n\nbundeslaenderSum['Todesrate100k'] = bundeslaenderSum.apply(\n                lambda x: calculateDeathRate(x['F\u00e4lle100k'], x['Tote100k']), axis=1)\n\nbundeslaenderSum = swapDFTwoColumns(bundeslaenderSum, 8, 10)","252865f2":"#  sort bundeslaenderSum by Bundesland lexicographically, incl. the whole entry for Germany (Deutschland)\nbundeslaenderSum.sort_values(by=['Bundesland'], ascending=True)","2f0f7953":"bundeslaenderOnly = bundeslaenderSum.drop(index=0)\nbundeslaenderOnly.sort_values(by=['Bundesland'], ascending=True, inplace=True)\nbundeslaenderOnly","05a73504":"# Plot some Pie Charts concerning BundeslaenderOnly (sorted by Bundesland name)\ntotal = bundeslaenderOnly['F\u00e4lle100k'].sum()\n_ = bundeslaenderOnly.F\u00e4lle100k.plot.pie(labels=bundeslaenderOnly['Bundesland'].values, pctdistance=0.8,\n            fontsize=14, figsize=(12,12), startangle=90, autopct=lambda p: '{:.0f}'.format(p * total\/100))","03e65799":"# Plot some Pie Charts concerning BundeslaenderOnly (sorted by Bundesland name)\ntotal = bundeslaenderOnly['Inzidenz7T'].sum()\n_ = bundeslaenderOnly.Inzidenz7T.plot.pie(labels=bundeslaenderOnly['Bundesland'].values, pctdistance=0.8,\n            fontsize=14, figsize=(12,12), startangle=90, autopct=lambda p: '{:.2f}'.format(p * total\/100))","79f5eca0":"# 1. list of all districts\/towns that seem to be \/ contain a Corona hotspot (sort by F\u00e4lle100k, alt. Tote100k)\nhotspots1 = landkreiseLast.sort_values(by=['F\u00e4lle100k'], ascending=False).head(25)\n\n# print a list of districts (Landkreise) having the 'highest score' considering the selected code (here: F\u00e4lle100k)\nhotspots1","4cf712d4":"total1 = hotspots1['F\u00e4lle100k'].sum()\n_ = hotspots1.F\u00e4lle100k.plot.pie(labels=hotspots1['Landkreis'].values, pctdistance=0.85,\n            fontsize=14, figsize=(12,12), startangle=0, autopct=lambda p: '{:.2f}'.format(p * total1\/100))","1b538a45":"# 2. list of all districts\/towns that seem to be or contain a COVID-19 hotspot (sort by Inzidenz7T)\nhotspots2 = landkreiseLast.sort_values(by=['Inzidenz7T'], ascending=False).head(25)\n\n# print a list of districts (Landkreise) having the 'highest score' considering the selected code (here: Inzidenz7T)\nhotspots2","3f35108e":"total2 = hotspots2['Inzidenz7T'].sum()\n_ = hotspots2.Inzidenz7T.plot.pie(labels=hotspots2['Landkreis'].values, pctdistance=0.9,\n            fontsize=14, figsize=(12,12), startangle=0, autopct=lambda p: '{:.2f}'.format(p * total2\/100))","3c194672":"coronaDistrict = coronaAll[coronaAll['Landkreis'] == hotspots2.iat[0, 1]]     # hotspots2.iat[0, 1]\n\n# now we can change the index to 'Erkr.Datum' because it is unambiguously\ncoronaDistrict.set_index('ErkrDatum', inplace=True)\ncoronaDistrict.tail(25)","32d844ce":"# plot two parameters, both use a linear legend\n# Depending on the course of 'Neuinf' it makes sense to use a log scale (try it out)\nlandkreis = coronaDistrict.at[coronaDistrict.index[0], 'Landkreis']\ntitle = 'Course of COVID-19 in ' + landkreis\n\nfig1, ax1 = plt.subplots(figsize=(18,10))\nax1.set_title(title)\ncoronaDistrict.Neuinf.plot(legend=True, logy=True)\n_ = coronaDistrict.VerdZahl.plot(secondary_y=True, legend=True)","4a3a81b2":"# plot two other parameters, both use a log scale\nfig2, ax2 = plt.subplots(figsize=(18,10))\nax2.set_title(title)\ncoronaDistrict.Inzidenz7T.plot(legend=True, logy=True)\n_ = coronaDistrict.ReprodZahl.plot(secondary_y=True, logy=True, legend=True)","098d8778":"# look at the Hotspots (resp. F\u00e4lle100k or Tote100k) of a specific state (Bundesland)\nspecificBundesland = 'Nordrhein-Westfalen'    # Nordrhein-Westfalen\nBundesland = landkreiseLast[landkreiseLast['Bundesland'] == specificBundesland]\n\n# sort by the first code\nBundeslandHead1 = Bundesland.sort_values(by=['F\u00e4lle100k'], ascending=False).head(30)\nBundeslandHead1","a1afb37a":"total = BundeslandHead1['F\u00e4lle100k'].sum()\n_ = BundeslandHead1.F\u00e4lle100k.plot.pie(labels=BundeslandHead1['Landkreis'].values, pctdistance=0.9,\n            fontsize=12, figsize=(12,12), startangle=0, autopct=lambda p: '{:.2f}'.format(p * total\/100))","c6d8d96f":"# sort by the second code e.g. Inzidenz7T\nBundeslandHead2 = Bundesland.sort_values(by=['Inzidenz7T'], ascending=False).head(30)\nBundeslandHead2","d7fdf59b":"total = BundeslandHead2['Inzidenz7T'].sum()\n_ = BundeslandHead2.Inzidenz7T.plot.pie(labels=BundeslandHead2['Landkreis'].values, pctdistance=0.9,\n            fontsize=12, figsize=(12,12), startangle=0, autopct=lambda p: '{:.2f}'.format(p * total\/100))","8d20a2d0":"coronaErkrBegin = coronaAll.sort_values(by=['ErkrDatum', 'IdKreis'], ascending=True, inplace=False)\ncoronaErkrBegin.describe()","5e36b27d":"# (re-)calculate Neuinf7T and Inzidenz7T in DataFrame bLand\n# bLand's index consists of Erkr.Datum timestamps which is the basis for calculation\n# this function will be used within createBundeslandProgress (s. next)\n\ndef calcInzidenz7Days(bLand, population, interval):\n    # make a copy of the input DataFrame\n    bLandNew = bLand.copy(deep=True)\n    \n    sumNeuInf = 0\n    \n    # indexList holds the last dates\n    indexList = []\n\n    for currentErkrDatum in bLandNew.index:\n        if indexList == []:\n            # mark beginning of a list\n            firstErkrDatum = currentErkrDatum\n            sumNeuInf = bLandNew.at[currentErkrDatum, 'F\u00e4lleNeu']\n            indexList = [currentErkrDatum]\n        else:\n            sumNeuInf += bLandNew.at[currentErkrDatum, 'F\u00e4lleNeu']\n            indexList.append(currentErkrDatum)\n            timeDelta = currentErkrDatum - firstErkrDatum\n            \n            # current row is more than interval days away resp. FirstErkrDatum\n            while timeDelta.days >= interval:\n                # remove first element of list and read the new first element aka Erkr.Datum\n                removeErkrDatum = indexList.pop(0)\n                sumNeuInf -= bLandNew.at[removeErkrDatum, 'F\u00e4lleNeu']\n                firstErkrDatum = currentErkrDatum if indexList == [] else indexList[0]                    \n                timeDelta = currentErkrDatum - firstErkrDatum\n            \n        # for each row store NeueF\u00e4lle7T and Inzidenz7T\n        bLandNew.at[currentErkrDatum, 'Neuinf7TSum'] = sumNeuInf\n        bLandNew.at[currentErkrDatum, 'Inzidenz7T' ] = sumNeuInf * 100000\/population\n\n    return bLandNew","313ee830":"# Starting from first to last known Erkr.Datum in coronaErkrBegin for each timestamp collect\n# - for every bundesland the numbers from their landkreise ==> 16 DataFrames\n# - for whole Germany the numbers from their bundeslaender ==>  1 DataFrame\n\ndef createBundeslandProgress(IdBundesland, interval):\n    '''\n    return a new DataFrame containing the progress of all numbers of a certain Bundesland\n    as data use coronaErkrDatum, sorted by ErkrDatum und IdKreis and landkreise\n    TODO: Neuinf7TSum and Inzidenz7T have to be recalculated afterwards\n    '''\n    \n    #  init all counter\n    FaelleNeu = -1\n    ToteNeu = 0\n    GeneseneNeu = 0    \n    FaelleSum = 0\n    ToteSum = 0\n    GeneseneSum = 0\n    \n    # here we will store all collected entries\n    erkrDatumList = None\n    seqNowcasting = []\n\n    bundesland = landkreise.at[IdBundesland, 'Kreisfreie Stadt \u2013 Landkreis']\n\n    if IdBundesland == 0:\n        # iterate thru all states\n        coronaLand = coronaErkrBegin\n    else:\n        coronaLand = coronaErkrBegin[coronaErkrBegin['Bundesland'] == bundesland]\n\n    # test the Parameter\n    if len(coronaLand) == 0:\n        print(\"Could not find entries for the state\", bundesland)\n        return None\n    \n    populationBuLand = int(landkreise.at[IdBundesland, 'Bev\u00f6lkerung'])\n    lastErkrDatum = pd.to_datetime('2019-12-12')  # init with a dummy date\n\n    # for each ErkrDatum found summarize all items of coronaLand with this date in:\n    for iter in coronaLand.index:\n        currentErkrDatum = coronaLand.at[iter, 'ErkrDatum']\n        timeDelta = currentErkrDatum - lastErkrDatum\n        \n        if timeDelta.days > 0:\n            # read row with a newer ErkrDatum ==> save current erkrDay\n            if FaelleNeu == -1:\n                # first time when entering the loop, read value before loop begin\n                FaelleNeu   = coronaLand.at[iter, 'Neuinf']\n                ToteNeu     = coronaLand.at[iter, 'Tote']\n                GeneseneNeu = coronaLand.at[iter, 'Genesene']\n                seqNeuInf   = []\n                seqNowcasting = [float(FaelleNeu)]\n                lastErkrDatum = currentErkrDatum\n                continue\n                \n            else:\n                # we already read the next row but before save the collected so far\n                FaelleSum   += FaelleNeu\n                ToteSum     += ToteNeu\n                GeneseneSum += GeneseneNeu\n                seqNeuInf.insert(0, FaelleSum)\n\n            # Nowcasting, Reproduktionszahl: use a list for storing the last interval nowcasting entries\n            currentNow = calcSmoothedValue(seqNeuInf, interval)\n            seqNowcasting.append(currentNow)\n            \n            if len(seqNowcasting) <= interval:\n                reprozahl = 2.5 # = R_0\n            else:\n                # compute a smoothed R as a Quotient of two interval-day series (Nowcasting)\n                nowCastingFirst = seqNowcasting.pop(0)\n                reprozahl = currentNow \/ nowCastingFirst                \n\n            erkrDay = pd.DataFrame({'Bundesland' : bundesland,\n                            'F\u00e4lleNeu'   : FaelleNeu,\n                            'ToteNeu'    : ToteNeu,\n                            'GeneseneNeu': GeneseneNeu,\n                            'F\u00e4lleSum'   : FaelleSum,\n                            'ToteSum'    : ToteSum,\n                            'GeneseneSum': GeneseneSum,\n                            'F\u00e4lle100k'  : FaelleSum * 100000 \/ populationBuLand,\n                            'Neuinf7TSum': 0,\n                            'Inzidenz7T' : 0.,\n                            'Tote100k'   : ToteSum * 100000 \/ populationBuLand,\n                            'VerdZahl'   : getHighestMinimum(seqNeuInf, 2),\n                            'Nowcasting' : currentNow,\n                            'ReprodZahl' : reprozahl\n                           }, index=[lastErkrDatum])\n\n            lastErkrDatum = currentErkrDatum\n\n            # store the collected items so far\n            if erkrDatumList is None:\n                erkrDatumList = erkrDay\n            else:\n                erkrDatumList = erkrDatumList.append(erkrDay)\n                \n            #  init all counter\n            FaelleNeu   = coronaLand.at[iter, 'Neuinf']\n            ToteNeu     = coronaLand.at[iter, 'Tote']\n            GeneseneNeu = coronaLand.at[iter, 'Genesene']\n            \n        else:\n            # read another row with same ErkrDatum; sum \/ add all counters\n            FaelleNeu   += coronaLand.at[iter, 'Neuinf']\n            ToteNeu     += coronaLand.at[iter, 'Tote']\n            GeneseneNeu += coronaLand.at[iter, 'Genesene']\n            \n    # for the last entry collected store its values\n    FaelleSum   += FaelleNeu\n    ToteSum     += ToteNeu\n    GeneseneSum += GeneseneNeu\n\n    nowCastingFirst = seqNowcasting.pop(0)\n    reprozahl = currentNow \/ nowCastingFirst                \n\n    erkrDay = pd.DataFrame({'Bundesland' : bundesland,\n                            'F\u00e4lleNeu'   : FaelleNeu,\n                            'ToteNeu'    : ToteNeu,\n                            'GeneseneNeu': GeneseneNeu,\n                            'F\u00e4lleSum'   : FaelleSum,\n                            'ToteSum'    : ToteSum,\n                            'GeneseneSum': GeneseneSum,\n                            'F\u00e4lle100k'  : FaelleSum * 100000 \/ populationBuLand,\n                            'Neuinf7TSum': 0,\n                            'Inzidenz7T' : 0.,\n                            'Tote100k'   : ToteSum * 100000 \/ populationBuLand,\n                            'VerdZahl'   : getHighestMinimum(seqNeuInf, 2),\n                            'Nowcasting' : currentNow,\n                            'ReprodZahl' : reprozahl\n                           }, index=[currentErkrDatum])\n            \n    # store the collected items so far\n    erkrDatumList = erkrDatumList.append(erkrDay)\n    \n    erkrListInzidenz = calcInzidenz7Days(erkrDatumList, populationBuLand, interval)\n    return erkrListInzidenz\n\n# In a loop (range(1,16)) you could generate a DataFrame for every state (Bundesland)\n# Instead as an example we pick one or two of them","2e232e06":"# example1: Id = 5, North Rhine-Westphalia (Nordrhein Westfalen)\ncoronaBundesland1 = createBundeslandProgress(5, interval)\n\nif coronaBundesland1 is not None:\n    coronaBundesland1['Todesrate100k'] = coronaBundesland1.apply(\n                lambda x: calculateDeathRate(x['F\u00e4lle100k'], x['Tote100k']), axis=1)\n\n    # swap new column Todesrate100k with VerdZahl\n    coronaBundesland1 = swapDFTwoColumns(coronaBundesland1, 11, 14)\n\ncoronaBundesland1","db706711":"# example2: Id = 13, Mecklenburg-Western Pomerania (Mecklenburg-Vorpommern)\ncoronaBundesland2 = createBundeslandProgress(13, interval)\n\nif coronaBundesland2 is not None:\n    coronaBundesland2['Todesrate100k'] = coronaBundesland2.apply(\n                lambda x: calculateDeathRate(x['F\u00e4lle100k'], x['Tote100k']), axis=1)\n\n    # swap new column Todesrate100k with VerdZahl\n    coronaBundesland2 = swapDFTwoColumns(coronaBundesland2, 11, 14)\n    \ncoronaBundesland2","4931a76b":"# plot two parameters of coronaBundesland1, here both y-axes use a logarithmic scale\ndef plotCoronaState(coronaState):\n    name = coronaState.at[coronaState.index[0], 'Bundesland']\n\n    title = 'Course of COVID-19 data I in state ' + name\n    _, ax1 = plt.subplots(figsize=(18,10))\n    ax1.set_title(title)\n    coronaState.F\u00e4lleNeu.plot(legend=True)\n    coronaState.VerdZahl.plot(secondary_y=True, legend=True)\n    \n    title = 'Course of COVID-19 data II in state ' + name\n    _, ax2 = plt.subplots(figsize=(18,10))    \n    ax2.set_title(title)\n    coronaState.Inzidenz7T.plot(legend=True, logy=True)\n    coronaState.ReprodZahl.plot(secondary_y=True, legend=True, logy=True)\n\n# for both example states call the function\nif coronaBundesland1 is not None: plotCoronaState(coronaBundesland1)","596b7aaa":"if coronaBundesland2 is not None: plotCoronaState(coronaBundesland2)","d5021556":"# example1: Id = 5, North Rhine-Westphalia (Nordrhein Westfalen)\ncoronaGermany = createBundeslandProgress(0, interval)\n\ncoronaGermany['Todesrate100k'] = coronaGermany.apply(\n              lambda x: calculateDeathRate(x['F\u00e4lle100k'], x['Tote100k']), axis=1)\n\n# swap new column Todesrate100k with VerdZahl\ncoronaGermany = swapDFTwoColumns(coronaGermany, 11, 14)\n\ncoronaGermany.tail(30)","fa157c9d":"plotCoronaState(coronaGermany)","c60ff42a":"# Pick up a particular district with all its rows   LK G\u00fctersloh\ncoronaDistrict2 = coronaAll[coronaAll['Landkreis'] == 'SK Bonn']\n\n# now we can change the index to 'Erkr.Datum' because it is unambiguously\ncoronaDistrict2.set_index('ErkrDatum', inplace=True)\ncoronaDistrict2.tail(25)","f9cab97e":"# plot two parameters; Attention: in this example Neuinf uses a log scale\nlandkreis = coronaDistrict2.at[coronaDistrict2.index[0], 'Landkreis']\n\ntitle = 'Course of COVID-19 data I in ' + landkreis\nfig1, ax1 = plt.subplots(figsize=(18,10))\nax1.set_title(title)\ncoronaDistrict2.Neuinf.plot(legend=True, logy=False)\n_ = coronaDistrict2.VerdZahl.plot(secondary_y=True, legend=True)","86d7d184":"# plot two other parameters; Attention: in this example Inzidenz7T uses a log scale\ntitle = 'Course of COVID-19 data II in ' + landkreis\nfig2, ax2 = plt.subplots(figsize=(18,10))\nax2.set_title(title)\ncoronaDistrict2.Inzidenz7T.plot(legend=True)\n_ = coronaDistrict2.ReprodZahl.plot(secondary_y=True, legend=True)","e39083cb":"# Course of cases of a district with a peak\nHaving found those districts and towns with a peak for particular codes we can now look into more detail of this district\/town.\n\nFor example picking up the first district of the DataFrame hotspot2 (alternatively hotspot1) we computed before from coronaALL we can extract all data (= history) of that particular district.\nThis data will be stored in a new DataFrame `coronaDistrict` and with it for example we can print a table or plot a graph that will be done next.\n\nConcretely for the selected district or town I will plot two graphs each of them holding two codes made visible on a y-axis (one left, one right) and the x-axis showing a time series of the date of illness (ErkrDatum). The codes in the \n1. plot will be the number of new cases (Neuinf) and the doublingfactor (VerdZahl)\n2. plot will be the incidence per seven days (Inzidenz7T) and the reproduction number (ReprodZahl)\n\nIn the last section I also will explicitly pickup one *interesting* district to be discussed in more detail.","28107355":"## Process and analyse COVID-19 epidemiological data in Germany\n# Introduction and Motivation\nBeginning with the outbreak of the Corona pandemic since Mid of March Europe and therefore Germany, too, became one of the worldwide hotspots. This notebook tries to analyse the COVID-19 situation in Germany.\n\nTwo data sources will be used for the analysis:\n1. **COVID-19 cases in Germany** (COVID-19 Fallzahlen in Deutschland) of the Robert Koch Institute (RKI) since beginning of the year 2020. The RKI centrally collects all the cases that it gets electronically delivered by all local health authorities in Germany. These COVID-19 cases as raw data will be the basis for the subsequent steps to be performed in this notebook. The RKI updates its dataset every day at 00:00 MEZ therefore to be up to date it makes sense to directly read the data from that location.\n\n2. Some factors and relevant values \/ codes that will be computed in the following need for a better comparison with each other some demographic aspects concretely a relation to the population numbers of the areas that will be compared with. For this purpose later in section [Reading demographic data (2nd source)] a public dataset on Kaggle I published will be read to get the **population numbers for all districts, towns, states** and the whole country Germany. Because these numbers will change very very slowly in the time being this dataset needs no updates and therefore can be treated as constant.\n\n*Note:*\nAlthough the RKI publishes (or published(!) I don't find them anymore) some Feature Sets containing information about some factors they were described only little or not at all.\nAs a consequence I decided to do all the necessary steps and computations by my own that will occupy most parts in this notebook. Also it's a good exercise for handling with those numbers.\n\nHopefully and mostly I was guided by an epidemiological bulletin and some other resources from the RKI.\nUnfortunately I could not find an english version of this bulletin that is published only in German to share with you: \n[an der Heiden M, Hamouda O: Sch\u00e4tzung der aktuellen Entwicklung der SARS-CoV-2-Epidemie in Deutschland \u2013 Nowcasting](https:\/\/edoc.rki.de\/bitstream\/handle\/176904\/6650.4\/17_2020_2.Artikel.pdf).\nHowever on [Aktueller Lage-\/Situationsbericht des RKI zu COVID-19](https:\/\/www.rki.de\/DE\/Content\/InfAZ\/N\/Neuartiges_Coronavirus\/Situationsberichte\/Gesamt.html) \nyou can always find the current and all archived reports of the RKI published in German and English. Besides a very detailed summary about the current COVID-19 situation in Germany these reports also partly contain some explanations that relate to the bulletin referred above.\n\nOf course the RKI itself publishes on its [COVID-19 Dashboard](https:\/\/experience.arcgis.com\/experience\/478220a4c454480e823b17327b2bf1d4) the course of current infections and death cases and some other charts. But if you want to know more and that was my motivation getting more insight of the different numbers and codes on district, town and on state level I began creating this notebook.\n\nIn particular the codes I'm interested in are:\n1. the `Doubling factor` or `Doubling number` (german: `Verdopplungszahl`)\n2. the `Reproduction number` (german: `Reproduktionszahl`); in order to achieve this number first it involves computing another code the `Nowcasting`\n\nTaking into account the population numbers per town, district or region, further codes are interesting\n3. the number of `new infections` or the `death-rate` `per 100000` inhabitants\n4. the comulative `incidence` over the past seven days (german: `Inzidenz7T`) of new infections per 100000 inhabitants\n\nAll these codes will be computed on district and town, state and countrywide level.\n\nThese codes will be explained and\/or referenced in detail later.\n\n*Notes:*\n* Unfortunately the heading information used in the data are german words. I will try to translate them whenever it is necessary.\n* **Attention**: To be able to read the RKI raw dataset directly from the https address given below as in this notebook the next cell you must **toggle on your Kaggle Internet Settings**! I guess this Settings is only available when you have verified your Kaggle account. Otherwise you have to transfer the dataset manually to a local dataset in your environment (see example local location in the comments below).","0bd6c17f":"## Approximation of unknown beginning date of illness (Erkrankungsdatum)\nIf Erkrankungsdatum resp. Refdatum is unknown calculate an 'imported date' (ImputiertesDatum), see bulletin above for details. \n\nIn short: new Erkrankungsdatum = Meldedatum - Mxx corresponding to the age class of the current row.\n\nThe next function `addMeanErkrankungsDatum` performs this approximation using the constructed Mxx values from above. \nAfter using the function some columns can be dropped because we don't need them further on.\n\nLater column reference date (RefDatum) will be renamed to `beginning date of illness` (ErkrDatum).","7ce1160d":"# Visualise some codes of all german states\nFirst concerning the german states I tried some visualisation using Pandas pie charts. \n\nBefore doing this we have to get rid of the row holding the data for whole Germany. Otherwise the relation to the different states to the whole country would be unfair. Remember that the Germany row contains of the sum of its different states. Therefore we simply create a new DataFrame `bundeslaenderOnly` that has dropped the row holding the data for Germany (index = 0). Also we sort this new DataFrame by the state names (Bundesland).\n\nAs an example I will plot two Pie Charts, the first one showing the cases per 100000 (F\u00e4lle100k) for all states. The second one shows the incidence of the last seven days for all states.\n\n*Notes:* \n- The alphabetical ordering within both pie charts is counterclockwise.\n- The values within each of the pie charts are absolute values and not the percentage values Matplotlib uses. I think these are better to interpret because they just correspond to the table data. This is done with the defined lambda function and the format in the parameter autopct.","feaf05bb":"# Doubling factor and Reproduction number\nNext we will compute three sums and three important factors and codes that are useful for doing analysis resp. interpreting the COVID-19 data.\n\n* For all three different cases per row that is new cases, new recovered and new dead a corresponding total sum column will be created that contains the summation of the corresponding cases up to this day. Later when the npArray is converted back to a Pandas DataFrame `coronaAll` these columns will be named (in german) `F\u00e4lleSum` (all infections), `ToteSum` (all dead) and `GeneseneSum` (all recovered).\n\n* `Doublingfactor` (Verdopplungszahl) **VerdZahl** means: How many days are passing by before the number of total infections doubles. More formally: at any day d1 at that there were t total infections reported how many days will pass by until at day d2 (d2 = d1 + days) there are 2 * t infections in total. Obviously the less new infections occur the forthcoming days the doublingfactor will grow much faster. In contrast if this factor is small the infection rate has an exponential behaviour which is a bad sign.\n\n* `NewCasting` is used as a pre-calculation step before getting the `Reproduction number`. NewCasting means: Considering in sequence a certain number of new infections compute as NewCasting a 'smoothed' (= average) value of those numbers. This sequence can be seen like a sliding window of a fixed size (size = `interval`) over the last interval elements. The last value of this sequence is the number of new infections belonging to that day the NewCasting will be computed for. Whereby the first value of this sequence is interval-1 days ago. To be flexible the range of elements in this list to be considered will be defined by the global variable `interval` which currently is set to 7.\n\n* `Reproduction number` (Reproduktionszahl) **ReprodZahl**: Having computed the NewCasting for a certain day d the Reproduction number for d is simply the result of a quotient of the newcasting value of day d thru newcasting value of day d-interval.\n\n*Note:* According to the RKI the computation of the Reproduction number is much more complicated. If you want to know more details please look to the literature I mentioned right at the beginning of this notebook, section [Introduction and Motivation].\n\nInstead of using a 7-day R-number it is also possible to use a shorter i.e. 4-day R-number. However I use a 7-day R-number that is also recommended by the RKI. Moreover by using the variable interval I'm more flexible.\n\nThe following cell contains two helper functions:\n1. The first one  `getHighestMinimum` is used to compute the Doublingfactor. \n2. The second one `calcSmoothedValue` is used to compute the NowCasting.\n\nAfterwards in the next but one cell the main function `computeDoublingFactorAndRnumber` will be defined that results in a new npArray rkiVRfactors. These two function blocks are a big step in the calculation at all and well it took me quite a while to get it to work.\n\nRemember, as a result from the last steps made the input numpy.Ndarray rkiSum is already sorted by districts and RefDatum.","490de26b":"# Visualise the COVID-19 course of Germany\nUsing the function `createBundeslandProgress` defined some paragraphs above we can also compute the course of all states in Germany so that we get a COVID-19 course of the whole country. \n\nFor visualisation we also can use the plot function sequence `plotCoronaState` already defined above.\nAs before in Data Frame coronaBundesland the index of the new Data Frame `coronaGermany` is a timestamp series that fits best as a x-axis for plotting.\n\nAgain the first plot will show the **new cases** (left legend) and the **Doubling number** (right legend). \nThe second will hold the course of the **incidence** (left legend) and the course of the **reproduction number** (right legend).\n\nNote that in these examples both legends use a logarithmic scale so that either very small values and also bigger values are drawn in a reasonable shape. The whole plotting stuff will be handled by the function `plotCoronaState` (see next cell).","9558082e":"# Visualise the COVID-19 data course of a state\nUsing the last DataFrame `coronaBundesland` that holds all data of a certain state that was just calculated above I tried making some visualisation using Pandas\/Matplotlib plot functionality. As already said before the index of coronaBundesland is a timestamp series that fits best as a x-axis for plotting.\n\nAs mentioned before regarding the two illustrations (picking up two states) I will create two plots each containing two vertical axes, meaning the plot will contain two different curves that rely on the same x-axis (timestamp series).\nThe first plot will show the **new cases** and the **Doubling number** and the second will hold the course of the **incidence** (left legend) and the course of the **reproduction number** (right legend).\n\nNote that in these examples both legends use a logarithmic scale so that either very small values and also bigger values are drawn in a reasonable shape. The whole plotting stuff will be handled by the function `plotCoronaState` (see next cell).","337ca67e":"# COVID-19 data peaks within one state\nHaving computed the recent numbers of all districts and towns in whole Germany we can examine those numbers considering a certain state.\nFor example we want to know the 20 highest values of all districts in that state concerning a particular code in recent cases.\n\nAgain input source for achieving this is the DataFrame `landkreiseLast` that holds only those districts and towns that recently got new infections (remember daysborder used before in function createBundeslandAndKreisSummary. Again I tried some visualisation using Pandas pie charts.\n\nNext I will visualise again with the help of a Pie Chart some details of a certain state we will pick up.\nIn this case I choose the state (Bundesland) where I live that's North Rhine-Westphalia.\n\nFor the Pie Charts I choose in two examples as data to be plotted \n1. the number of dead per 100k (Tote100k) and\n2. the incidence per 7 days (Inzidenz7T. \n\n*Note:* After this again one could pick up a certain district of interest regarding the first or second case and plot its history by extracting its data from coronaAll. But this time I will leave this out because the method will be the same as I made before when picking up a particular district from Germany's peak districts (see above).","dbbcf489":"# Description of the RKI dataset\nFor all local districts (Landkreise) and towns (St\u00e4dte) in Germany this dataset contains an unsorted time series of COVID-19 cases, per day reporting new infections or cases (F\u00e4lle), recovered (Genesene) and died persons (Tote).\nEach row in the DataFrame corona above represents one or more cases. \n\nI will shortly describe the meaning of the different columns used in the DataFrame. Beware that during reading some fields of the original RKI dataset were skipped because I don't need them. \n\nIn the following enumeration I start with 0 corresponding to the column indices used in the DataFrame:\n0. Bundesland      - name of the state (Note that I skipped the BundeslandId)\n1. Landkreis       - district (beginning with the abbreviation LK) or town (beginning with the abbreviation SK)\n2. Altersgruppe    - age class (0-4, 5-14, 15-34, 35-59, 60-79, 80+ years)\n3. AnzahlFall      - number of new infection cases (this number can be negative, too e.g. a correction of cases before were delivered)\n4. AnzahlTodesfall - number of new death cases (this number can be negative, too e.g. a correction of cases before were delivered)\n5. Meldedatum      - notification date = date when a case was reported by a local authority to the RKI \n6. IdLandkreis     - unique Id of a Landkreis (1.)\n7. Refdatum        - reference date = beginning date of illness (see 9.) otherwise it is the same as Meldedatum (5.)\n8. AnzahlGenesen   - number of new recovered cases (this number can be negative, too e.g. a correction of cases before were delivered)\n9. IstErkrankungsbeginn - Boolean: if == 0 beginning date of illness is unknown, else it is known (s7.) \n\nA more detailed description of for the whole raw dataset can be found under [data description of the RKI Covid-19-Dashboard (in german)](https:\/\/www.arcgis.com\/home\/item.html?id=dd4580c810204019a7b8eb3e0b329dd6).\n\n*Notes:*\nThe date fields (5. and 7.) contain the time 00:00 (midnight) at MEZ timezone. The reason for this is because the datasets are always published daily at that time on the RKI website.\n\nSome columns I had skipped during reading of the csv file (or url):\n*IdBundesland, Altersgruppe2, Geschlecht, NeuerFall, NeuerTodesfall, NeuGenesen*; also the column *Datenstand* was dropped. They all have no important or no transparent meaning or are even not filled by the RKI.\n\n*Datenstand* (day of delivery): for  all columns it is always the same and therefore it can can be dropped.\n\n*Geschlecht* (sex): I skipped that column because of the fact that according the RKI the course of illness for male and female persons infected by the virus was very similar so that there is no need to differentiate between male and female cases.\n\nYou can see next the different fields I described e.g. by printing out with **corona.info()**.","0c49c272":"# Joining rows with same date of illness\nUntil now (in current DataFrame coronaDrop) for a particular district\/town (Landkreis\/Stadt) and reference date (RefDatum) very often there exist several rows but they differ in sex and age classes. Remember that RefDatum == (beginning) date of illness!\n\nNext these rows will be joined into one row whereas the different cases (new, recovered or died) will be summarised accordingly. \n\n*Note:* One drawback will be that no longer we can distinguish between sex and age classes. On the other hand also the RKI publishes most of its COVID-19 reports without differencing between sex and age classes. Of course it is known that older people belong to the COVID-19 risk category having a more violent course of disease (for more details see the paragraph `Demographic distribution of cases` in one of the RKI's COVID-19 status reports already mentioned in the introduction. On the other hand the *Mxx* values (see above) show that there are only small differences in the age classes.\n\nBefore joining the (beginning) date of illness (Erkrankungsdatum) the whole Pandas DataFrame coronaDrop will be sorted according the criteria:\n1. : 'IdLandkreis'\n2. : 'Refdatum'.\n\nNext the following defined function `sumKreisErkrankungsdatum` will be called with input *coronaDrop.to_numpy()* and as a result the dataset will be stored as a npArray. You also can see that the number of rows (before and after the function call) is now shrinked by a factor round about 5.5\n\nLastly some columns in rkiSum are swapped (see comments below)","2c3ded17":"# Reference date vs. notification date\nI begin with investigation on the columns `notification date` (Meldedatum), `reference date` (RefDatum) and `IstErkrankungsbeginn`.\nThe columns notification date (Meldedatum) and the flag `IstErkrankungsbeginn` will influence the column reference date (Refdatum) as follows: \n\nIf IstErkrankungsbeginn is\n\n* 1 ==> Refdatum refers to the beginning date of illness; nothing needs to be altered\n\n* 0 ==> the beginning date of illness is unknown; as an approximation use notification date (Meldedatum) subtracted by Mxx-Delta (a computed weight of the corresponding age class, see below)\n\nFirst let's look at all rows and see the coverage where corona['IstErkrankungsbeginn'] == 1\n\nThe next section and function definition `addWeightToAltersgruppe` build different lists of age classes: *Axx* containing time delta values.\n\nNext function `correctErkrankungsDatum` corrects those rows with *corona['IstErkrankungsbeginn'] == 1* when the date of illness is too far away (30 days) from the notification date. In this case *corona['IstErkrankungsbeginn']* will be set to zero.\n\nAfterwards from all Axx lists a Mean value Mxx is calculated. The Axx lists then will no longer be used and can be deleted.","df720e15":"## Observations\nIn the figures above you can see two plots of `coronaBundesland1` we defined before.\n\nThe first figure shows the course of new infections (abbr. Neuinf) and of the Doubling factor (abbr. VerdZahl). As you can see the new infections were climbing to its peak in the second half of March. This was the date when in whole Germany the COVID-19 pandemic was widely spread.\nIn the Beginning of April the curve was going down slowly until around mid of June it jumped to a second peak. The second peak happened because of the super-spreading event in the district LK G\u00fctersloh which belongs to North Rhine-Westphalia. In the next section I will show more about this super-spreader hotspot.\n\nThe curve for the doubling factor (abbr. VerdZahl) raises quite linear which for the whole state is hopefully a good sign because it means how bigger it is the more days are needed to double the total number of infections. Whereas the super-spreading event influence only slightly  the course of the curve in opposite to the number of new infections.\n\nThe second figure plots for the same state the factors incidence per 7 days (abbr. Inzidenz7T) and reproduction number (abbr. ReprodZahl) that both climbed slightly to a second peak mid of June.\n\nThe next two figures will show two plots of `coronaBundesland2` we defined before, too. As already said this second example is a state where relatively less infections were notified. But as in `coronaBundesland1` the curve of new infections also had some peaks around March but then are falling down until around 1.","1ad44d9a":"# Calculation of the 7 days incidence\nHaving available the district\/town population numbers in DataFrame landkreise in the first step (see addPopulation100000) we join them into the recent npArray.\nDoing so we add two columns that is the sum of all infections resp. deaths per 100k for every district or town. \n\nIn a second step in function addInzidenz7Days again we are adding two new columns:\n- newCases7Days (NeueF\u00e4lle7T): all new cases within the last 7 days (interval = 7)\n- incidence: newCases7Days per a population of 100000\n\nIn a third step again some rows are swapped.\nFor better visibility from the last npArray created `rkiInzidenz` I will convert it to a Pandas DataFrame `coronaAll`. The first rows will be printed out to give an overview what we have achieved so far.\n\n*Note:* **Seven days in sequence** for a district, town or a state does not always mean seven rows in sequence! Instead this means as many rows in sequence such that the difference from first row to the last one is not more than seven days! Take into account that not every day for a certain district, town or state a row with new infections will be delivered.","84ced4ba":"# Reading demographic data (2nd source)\nNext we want to bring the numbers we got so for in relation to the number of population (Bev\u00f6lkerung) in the different districts (Landkreise) and cities (St\u00e4dte). So we can calculate cases100k and factors100k according to cases or some of the factors. We need to do this because only this way it makes sense to compare different districts each other. In most cases we don't want to compare absolute values.\n\nFortunately the german national 'Statistisches Bundesamt' publishes a dataset which contains these values and what is also important the ids (IdKreis vs. Regionale Bezeichnung) for the different districts and towns correspond to each other. As described in the comments below I took several steps applied to the original dataset to get it to work. The dataset also contains data about the area and differentiation of sex of the population that we are not interested so far. I published this dataset in Kaggle with the name `Districts and Towns in Germany.2019`.\n\n*Notes:*\n- Depending on wether this notebook is running in Kaggle environment or not the pd.read_csv operation will read a different filename.\n- Again, as in the first RKI dataset read unfortunately the headings used in this data use german words, too. I will try to translate whenever it is necessary.","60516925":"# Pickup a certain district for data display\nAs a last example I will pick up a certain district's COVID-19 history that became a 'super-spreader' hotspot in Germany.\n\nAgain input data is the DataFrame coronaAll. The new DF coronaDistrict will get timestamps as its index what is useful for plotting a graph showing the time course of the selected corona codes.","f5ae1777":"# Getting COVID-19 data for a particular state\nBased on the COVID-19 data we calculated on district and town level we can now collect them in this way for e.g. get data for a whole particular state.\n\nThe function `createBundeslandAndKreisSummary` will return two Pandas DataFrames:\n- bundeslaenderSum: for each of the 16 states (country states and city states) within Germany this DataFrame will hold a row per state of all associated districts and towns from the particular state. Additionally the DataFrame will hold a row for whole Germany which results as a sum of its 16 states.  \n- landkreiseLast: some kind of report for all districts and towns containing their last row. The last row represents the last known delivery of data for that district and of course contains the cumulated sums of the interested numbers (infections, recovered and died persons).\n\nBefore calling this function a daysBorder will be defined: its purpose is to restrict the selection of districts and towns that will be reported in landkreiseLast to those where their last row lies within a certain timeframe (= daysborder). \nThis will ensure that only those districts and towns with new infections reported will be considered.\nYou can see this by a last print statement in the function saying how many districts were not considered.\n\n*Attention: The values for ReprodZahl and VerdZahl are calculated via mean() of all corresponding values of its districts and towns belonging to that state!\nThis might be incorrect because they tend to be too high compared with the numbers got from the RKI.\nHowever later when calculating the COVID-19 data for a particular state with function `createBundeslandProgress` the values for R and V are recalculates from scratch.*\n\nNext function `fillDeutschlandrow` completes bundeslaenderSum with a row for whole Germany (index = 0).\n\nAfterwards function `calculateDeathRate` adds a column death-rate per 100k to each row in bundeslaenderSum.\n\nTwo times the result of the functions can directly be seen by Pandas great visibility functionality. The second time the countries (including the row for whole Germany) are sorted lexicographically by their name.","d9180e3f":"## Observations\nIn the figure above you can see very clearly the dramatic explosion of new infections (Neuinf) in that district of North Rhine-Westphalia beginning mid of June! This peak is even much higher as in March where most districts or towns had the highest peak.\n\nThe reason for this was that after the lockdown and while the whole country tended to return to normal life one of Germany's biggest meat factories started its production again. The working and also the placement conditions for many foreign workers from East Europe were unsatisfactory and that is the reason the COVID-19 virus spread very much. In that sense LK G\u00fctersloh even became worldwide the hotspot of a super-spreader location concerning meat industries. As a result the whole district had to return to a lockdown. Fortunately meanwhile the lockdown terminated again and the meat factory is still closed.\n\nLooking to the curves therefore in mid June the new infections (abbr. Neuinf) were growing more and more and also got a very high peak. Whereas the Doubling factor (abbr. VerdZahl) rapidly went down and now from a very low point linearly starts growing again similar as at the beginning of the COVID-19 crisis mid of March.\n\nFor the same district the next plot shows the the factors incidence per 7 days (abbr. Inzidenz7T) and reproduction number (abbr. ReprodZahl) that both climbed to a much higher peak mid of June as in March. The peaks are a bit timely shifted. That's because how they are calculated.","0714c314":"# Germany's districts or towns with peaks \nHaving computed the recent numbers of all districts and towns in Germany we can examine those numbers.\nFor example we want to know the 20 highest values of all districts concerning a particular code in recent cases.\n\nInput source for achieving this is the DataFrame `landkreiseLast` that holds only those districts and towns that recently got new infections (remember daysborder used before in function createBundeslandAndKreisSummary. Again I tried some visualisation using Pandas pie charts.\n\nOf course depending on the day the RKI raw data was read we will find other recent numbers in the DataFrame `landkreiseLast` and therefore find other peaks as well. In other words we only take a snapshot of the raw data. Remember from the beginning we always read the newest RKI raw data.\n\nAs an example I will plot two Pie Charts. Before that for each dataset a table with its highest values will be printed out. The tables and Pie Charts are:\n1. The first one showing the cases per 100k population (F\u00e4lle100k) of 25 those districts\/towns with the highest value.\n2. The second one showing the 7 days incidence of 25 those districts\/towns with the highest value.\n\n*Notes:* \n- The ordering within both pie charts is counterclockwise. For better readability the ordering starts at 3'o clock.\n- Again the values within each of the pie charts are absolute values and not the percentage values Matplotlib uses.  This is done with the defined lambda function and the format in the parameter autopct.","5f56b317":"# Course of infections for a particular state\nTo recapitulate until now we have constructed several DataFrames. The most important ones are:\n- `coronaAll` holds all cases for every district and town in the whole country of Germany. Currently the DataFrame is sorted by 1:'IdKreis', 2:'ErkrDatum', which results from the iteration loop over landkreise within the last bigger function call of createBundeslandAndKreisSummary (see above). However we could change the sorting order if we would like and we will do as you will see in the next cell. \n\n- `coronaDistrict` a subset of coronaAll with the same ordering but with a new index (ErkrDatum) that is a timestamp. It holds the data of a specific district or town. This dataset is perfect to make further investigation according this particular district. We already made some example plots.\n\n- `bundeslaenderSum` and `bundeslaenderOnly` are DataFrames considering the COVID-19 data of all german states where each state is represented by one row. `bundeslaenderSum` occupies the same data as `bundeslaenderOnly` with an additional row considering whole Germany.\n\n- `landkreiseLast` a DataFrame that holds a report of the last rows of those districts and towns where new cases were reported recently.\n\nWhat is missing might be a DataFrame for a particular state (Bundesland) containing all the numbers of its associated districts and towns. In detail:\n- The index of the DataFrame will be a series of timestamps holding all points of date of illness (Erkr.Datum) that happened to that particular state. This index later can be used as the x-axis to perform some plots.\n- The columns of this DataFrame will hold all the collected numbers according to a certain Erkr.Datum.\n- However this DataFrame no longer holds separated data for a particular district or town!\n\nThis will be done next. As input data for this function there will be used a DataFrame `coronaErkrBegin` that will be derived by coronaAll but sorted by 1:'ErkrDatum', 2:'IdKreis' (we just swap both sort criteria).\n\nIn the following function `createBundeslandProgress` will perform all the necessary operations resulting a new DataFrame `coronaBundesland`. \nThe function requires two input parameters: 1:BundeslandId, 2:interval.\nWith the helper function `calcInzidenz7Days` in a last step the new DataFrame gets a column with the incidence numbers for the generated state.\n\nAfter this in a next cell the death rate per 100k population (Todesrate100k) is added as a next column to DataFrame `coronaBundesland`. Last but not least two columns will be swapped.\n\nFor illustration I will generate the numbers of two states, North Rhine-Westphalia (Nordrhein Westfalen) that has 17.932.651 inhabitants and Mecklenburg-Western Pomerania (Mecklenburg-Vorpommern) having 1.609.675 inhabitants. While the first state still suffers with a lot of COVID-19 cases the second state has the lowest COVID-19 cases.","5f0c6884":"# Conclusion\nAs you could see the RKI raw but base data delivered have much potential for the computation of different numbers, factors and codes at state or district level. Obviously still more things could be performed on this data. But for the first time I guess there is enough that was computed.\n\nIn my opinion another point to mention its quite difficult and when regarding ethical aspects, too, for trying to make some future predictions on this data. As all people know the COVID-19 infections can be very dangerous and unfortunately many many people died all over the world. Especially in the last weeks the numbers in the US show how dangerous this pandemic is. With respect to the people that already died and because currently we do not know when this pandemic disease will stop I think it is highly risky to make some predictions going into the future.\n\nOn the other hand what you could see so far and I hope in an impressive way all was done by *only* doing some statistical operations without A.I. or ML methods. Nevertheless there might be some fields where it makes sense to perform ML to get more insight in this dangerous pandemic.\n\nI'll look forward hearing from you via comments or upvoting.\n\nPlease all stay healthy!"}}