{"cell_type":{"085f4c99":"code","e0a9c0c5":"code","d977aa34":"code","71ca9384":"code","6b8a6dc0":"code","dcd0ebc1":"code","27c73bb4":"code","ddf97734":"code","fa4bae54":"code","3d71ab88":"code","49f5999d":"code","ee0ea9d9":"code","a9b5650b":"code","8d793ab0":"code","2a84ccef":"code","688f7027":"code","73314d91":"code","9757a0e8":"code","87a97e88":"code","48262ea2":"code","2b4b5f34":"code","5029afa5":"code","c77a1050":"code","ccc4b694":"code","556cafc1":"code","27de3422":"code","0066767e":"code","0a1e3ce5":"code","95a3130b":"code","5810b9f0":"code","7f62c69d":"code","b5b09e3b":"code","987f82da":"code","b52f4980":"code","c695fb6a":"code","0e32b59a":"markdown","ede378ee":"markdown","0199f0f5":"markdown","d5f24e06":"markdown","96547bf8":"markdown","968090d3":"markdown","a5601f52":"markdown","107f2f49":"markdown","76187496":"markdown","9f2cd319":"markdown","d91b881f":"markdown","f15fd28c":"markdown","ad127afa":"markdown","64e8ec2b":"markdown","ade868c9":"markdown","90f411b5":"markdown","fb317a30":"markdown","22c2262c":"markdown","d45324f0":"markdown","7251904a":"markdown","e319136b":"markdown","25d883be":"markdown","871c926a":"markdown","119f5b34":"markdown","20698dc5":"markdown","184dd17d":"markdown","f6ec61d5":"markdown","472176db":"markdown","d0a0c46c":"markdown","6576618d":"markdown","a9276ab1":"markdown"},"source":{"085f4c99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0a9c0c5":"#import libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sklearn\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#the dataset\ndata = pd.read_csv('\/kaggle\/input\/melbourne-housing-market\/Melbourne_housing_FULL.csv')\nprint(data.shape)\ndata.head()","d977aa34":"data.info()","71ca9384":"print('Categorical Features ')\nprint(data.select_dtypes(['object']).columns)\nprint('Numeric Features')\ndata.select_dtypes(['int64','float64']).columns","6b8a6dc0":"data.isnull().sum()","dcd0ebc1":"#drop columns\ndata.dropna(subset = ['Distance','Postcode','CouncilArea','Regionname','YearBuilt','Lattitude', 'Longtitude'], inplace = True)\ndata = data.drop(['Propertycount','SellerG','Address'], axis = 1)","27c73bb4":"#numerical variables\ndata['Price'].fillna((data['Price'].mean()), inplace = True)\ndata['Landsize'].fillna((data['Landsize'].mean()), inplace = True)\ndata['BuildingArea'].fillna((data['BuildingArea'].mean()), inplace = True)\n#Catigorical variables\ndata['Bedroom2'].fillna((data['Bedroom2'].value_counts().index[0]), inplace = True)\ndata['Bathroom'].fillna((data['Bedroom2'].value_counts().index[0]), inplace = True)\ndata['Car'].fillna((data['Car'].value_counts().index[0]), inplace = True)","ddf97734":"print(data.shape)\ndata.isnull().sum()","fa4bae54":"print('Categorical Features ')\nprint(data.select_dtypes(['object']).columns)\nprint('Numeric Features')\ndata.select_dtypes(['int64','float64']).columns","3d71ab88":"data.describe().T","49f5999d":"#t-test\nfrom scipy.stats import ttest_ind\nttest_ind(data['Rooms'], data['Bedroom2'])","ee0ea9d9":"data.drop(['Bedroom2'], axis = 1)","a9b5650b":"#t-test\nfrom scipy.stats import ttest_ind\nttest_ind(data['Rooms'], data['Bedroom2'])","8d793ab0":"data = data.drop(['Bedroom2'], axis=1)","2a84ccef":"plt.figure(figsize=(10,10))\nsns.heatmap(data.corr(), cmap = 'viridis', linewidth =1, annot=True, annot_kws = {'size':9})\nplt.title('Correlation of features')","688f7027":"plt.figure(figsize=(15,8))\nsns.distplot(data['Price'], kde = False,hist_kws=dict(edgecolor=\"b\"))","73314d91":"plt.figure(figsize =(15,8))\n\nax1 = plt.subplot(1,2,1)\nsns.boxplot(data=data, x='Type', y='Price')\nax1.set_xlabel('Type')\nax1.set_ylabel('Price')\nax1.set_title('Type vs Price')\n\nax2 = plt.subplot(1,2,2,sharey=ax1)\nsns.boxplot(data=data, x='Method', y='Price')\nax2.set_xlabel('Method')\nax2.set_ylabel('Price')\nax2.set_title('Method vs Price')\n\n\n","9757a0e8":"sns.set_style('darkgrid')\nsns.set(font_scale =1)\n\nplt.figure(figsize=(20,20))\n\nax1 =plt.subplot(3,2,1)\nsns.regplot(data=data, x='Rooms', y='Price',scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\nax1.set_xlabel('Rooms')\nax1.set_ylabel('Price')\nax1.set_title('Type vs Price')\n\nax2 = plt.subplot(3,2,2)\nsns.regplot(data=data, x='Bathroom', y='Price',scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\nax2.set_xlabel('Bath Room')\nax2.set_ylabel('Price')\nax2.set_title('Bath Room vs Price')\n\nax3 = plt.subplot(3,2,3)\nsns.regplot(data=data, x='Car', y='Price',scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\nax3.set_xlabel('Car')\nax3.set_ylabel('Price')\nax3.set_title('Car vs Price')\n\nax4 = plt.subplot(3,2,4)\nsns.regplot(data=data, x='BuildingArea', y='Price',scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\nax4.set_xlabel('BuildingArea')\nax4.set_ylabel('Price')\nax4.set_title('BuildingArea vs Price')\n\nax5 = plt.subplot(3,2,5)\nsns.regplot(data=data, x='Longtitude', y='Price',scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\nax5.set_xlabel('Longtitude')\nax5.set_ylabel('Price')\nax5.set_title('Longtitude vs Price')","87a97e88":"plt.figure(figsize=(8,10))\nsns.boxplot(data = data, y='Price')","48262ea2":"outliers = data[data['Price']>2500000]\noutliers.describe().T\n","2b4b5f34":"maxfence_price = data[data['Price']==2500000]\nmaxfence_price.describe().T","5029afa5":"#Remove item that has price that greater than 2.5M\ndata = data[data['Price']<=2500000]\nprint(data.shape)\ndata.describe().T","c77a1050":"data.info()","ccc4b694":"##create new dataset\n\nnew_data = data.copy()\nnew_data.drop(['Date','Suburb','Postcode','YearBuilt'],axis = 1, inplace = True)\nnew_data.info()","556cafc1":"one_hot_encode_cols = new_data.dtypes[new_data.dtypes ==np.object]\none_hot_encode_cols = one_hot_encode_cols.index.tolist()\n\nprint(new_data[one_hot_encode_cols].shape)\nnew_data[one_hot_encode_cols].head()","27de3422":"new_data = pd.get_dummies(new_data, columns = one_hot_encode_cols, drop_first = True)\nnew_data.describe().T","0066767e":"#import regression libraries\nfrom sklearn import preprocessing \n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.model_selection import KFold, cross_val_predict\n","0a1e3ce5":"X = new_data.drop('Price', axis=1)\ny = new_data.Price\nX.head()","95a3130b":"kf= KFold(shuffle=True, random_state=72018, n_splits=3)\n\nfor train_index, test_index in kf.split(X):\n    print('Train index', train_index[:10],len(train_index))\n    print('Test Index',test_index[:10], len(test_index))\n    print('')","5810b9f0":"scores=[]\n\nlr=LinearRegression()\ns= StandardScaler()\n\nfor train_index, test_index in kf.split(X):\n    X_train,X_test, y_train,y_test = (X.iloc[train_index,:],\n                                      X.iloc[test_index,:],\n                                      y.iloc[train_index],\n                                      y.iloc[test_index])\n    #print(X_train.shape)\n    #print(y_train.shape)\n    X_train_s=s.fit_transform(X_train)\n    \n    lr.fit(X_train,y_train)\n    \n    X_test_s=s.fit_transform(X_test)\n    \n    y_pred = lr.predict(X_test)\n    \n    score = r2_score(y_test.values,y_pred)\n    \n    scores.append(score)\n    \nscores\n    ","7f62c69d":"np.mean(scores)","b5b09e3b":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\nestimator = Pipeline([(\"scaler\", StandardScaler()),\n        (\"polynomial_features\", PolynomialFeatures()),\n        (\"ridge_regression\", Ridge())])\n\nhparams = {\n    'polynomial_features__degree': [1, 2],\n    'ridge_regression__alpha': np.geomspace(4, 20, 20)\n}\n\ngrid = GridSearchCV(estimator, hparams, cv=kf)","987f82da":"grid.fit(X,y)\nprint(grid.best_score_)\nprint(grid.best_params_)","b52f4980":"y_predict = grid.predict(X)\nr2_score(y, y_predict)","c695fb6a":"from sklearn.linear_model import ElasticNetCV\nalphas2 = np.array([0.005,0.05,0.1,1,5,20,50,80,100,120,140])\nl1_ratios = np.linspace(0.1,0.9,9)\nelasticNetCV = ElasticNetCV(alphas=alphas2, \n                            l1_ratio=l1_ratios,\n                            max_iter=1e4).fit(X_train, y_train)\nr2_score=r2_score(y_test, elasticNetCV.predict(X_test))\n\nprint(elasticNetCV.alpha_, elasticNetCV.l1_ratio_, r2_score)","0e32b59a":"**Categorical Feature** : Suburb. Address, Type, Method, SellerG, Date, CouncilArea, Region Name\n\n\n**Numeric Features** : Rooms, Price, Distance, Postcode, Bedroom2, Bathroom, Car, Land Size, Building Area, YearBuild, Lattitude, Longtitude, Property count","ede378ee":"**I convert the code below to markdown since Kaggle does not have enough space(20gb) to perform Gridsearch,r2_score is around 0.518**","0199f0f5":"## Step for cleaning data\n**+ Drop the Nan values of Distance, Postcode, Council Area, Region Name, Property Count because there are just a few missing value**\n**+ Drop the NaN value from year build because can not replace with any value**\n\n**+ Replace int64, and float64 variable with mean value**\n\n**+ Replace object variables with the values that has highest count values**\n\n**+ Drop the column Lattidu and Longtittude because if we replace with any values, it will conflict with Building Area or LandSize in my understanding**\n\n**+ Drop the column Seller G, Property Count and Address since theese variables has no  value for my further analyis**","d5f24e06":"**Price Distribution**","96547bf8":"grid.fit(X,y)\nprint(grid.best_score_)\nprint(grid.best_params_)","968090d3":"## Lasso Regression \n","a5601f52":"**Drop some variables that are considered to has no value to my further analysis**","107f2f49":"**Ploting categorical Features with Price**","76187496":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\nestimator = Pipeline([(\"scaler\", StandardScaler()),\n        (\"polynomial_features\", PolynomialFeatures()),\n        (\"lasso_regression\", Lasso())])\n\nhparams = {\n    'polynomial_features__degree': [1, 2, 3],\n    'lasso_regression__alpha': np.geomspace(0.6, 6, 30)\n}\n\ngrid = GridSearchCV(estimator, hparams, cv=kf)","9f2cd319":"**p-value** is 0.1526 which is much greater than 0.05, showing that the 2 dataset are the same since we can not reject the null hypotheis, lets drop 1 out of 2 columns\n\n**notice** The min value in the Bedroom2 columns is 0, so I decided to drop the Bedroom2 columns","d91b881f":"## Model Selection","f15fd28c":"## Cleaning Data","ad127afa":"**Notice** The Room column and Bedroom2 have nearly the same gerneral statistic, let's perform t-test to examinate whether they are carrying the same information or not","64e8ec2b":"**Notice** the outliers whose price are greater than 2.5M have no siginificant difference compare to value at max fence value\n\nAs can be seen, an averge house at 2.5M dollar has the mean rooms of 4, bathroom of 2.27, Building Area of 2.07\n\nMean while a higher price house, which is above 2.5M dollar has mean room of 4.2, bath rooms of 2.7, Building Area of 2.75\n\nWhich a range price from 2.5M dollar to 8M dollar but there are no significant different features, so mainly from my own experience, the price is evaluated base on the location, which i can not examicated in this project. Thus, these outliers should be removed since they has no relevant","ade868c9":"## Adjusting Features","90f411b5":"**Split data**","fb317a30":"## Linear Regression","22c2262c":"**p-value** is 0.1526 which is much greater than 0.05, showing that the 2 dataset are the same since we can not reject the null hypotheis, lets drop 1 out of 2 columns\n\n**notice** The min value in the Bedroom2 columns is 0,which is imposible, so I decided to drop the Bedroom2 columns","d45324f0":"**Correlation Heatmap**","7251904a":"## Features of the dataset","e319136b":"**Plotting numeric variables**\n\nBase on the Correlation Heatmap, the  mumeric variables that has significant correlation to Price is : Rooms, Bathroom, Cars, BuildingArea, Longittude","25d883be":"## One hot encoding dummies variables","871c926a":"## Outliers","119f5b34":"## Featuring data","20698dc5":"## Data Visualization","184dd17d":"**Notice: The Rooms column and Bedroom2 have nearly the same gerneral statistic, let's perform t-test to examinate whether they are carrying the same information or not**","f6ec61d5":"y_predict = grid.predict(X)\nr2_score(y, y_predict)","472176db":"As can be seen from the Price boxplot, the maximum value for the price is 2.5M dollar, and there are a lot of outliers","d0a0c46c":"## Ridge Regression with GridSearch","6576618d":"## ElasticNet Regression","a9276ab1":"**Fitting Linear Regression with K-fold Cross Validation**"}}