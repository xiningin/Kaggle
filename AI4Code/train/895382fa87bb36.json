{"cell_type":{"9d4cdc4e":"code","502a69f8":"code","3ca1eb3f":"code","fd0e5a49":"code","1f38414b":"code","509a0a06":"code","03419a71":"code","ef9b6b0a":"code","475c639d":"code","581f6ce2":"code","71fee088":"code","6d59eede":"code","9f529bdc":"code","4bccf00d":"code","e8812388":"code","51264409":"code","647568fe":"code","af192bf0":"code","011eb6ac":"code","96dfe5b3":"code","6f054180":"code","b5fabbfc":"code","933e2c0e":"code","d0f0fe1e":"code","a456c9f0":"code","0094e8c3":"code","be7c279f":"code","26a0b821":"code","00be052b":"code","99e6774d":"code","d0287a90":"code","a02539c9":"code","bff412ff":"code","4b340f4d":"code","f1c90630":"code","9f78f685":"code","e0deaa6d":"code","5b90ad7e":"code","f493df8a":"code","fc47b29e":"code","7bfd4f0a":"code","164f7503":"code","7f00add5":"code","1d07622f":"code","c7902a0c":"code","e29a81a5":"code","81347a6c":"code","6af55683":"markdown","3cea1221":"markdown","9f549db6":"markdown","fc34bfe6":"markdown","e6e5e8f8":"markdown","5b1d9dea":"markdown","333d7a77":"markdown","e7860143":"markdown","ebd3abb7":"markdown","997a7ac1":"markdown","7697c19c":"markdown","a68d7f58":"markdown","270a1735":"markdown","49d799f3":"markdown","7c36141d":"markdown","d055d369":"markdown","3890e52f":"markdown","9597dfb3":"markdown","a99630cf":"markdown","973e89a0":"markdown","4384fe7f":"markdown","6322d665":"markdown","a0a95f02":"markdown"},"source":{"9d4cdc4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","502a69f8":"# this code show more than one output in one cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","3ca1eb3f":"# import libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n%matplotlib inline","fd0e5a49":"# reading data in bbs_cust_base dataframe variable\nbbs_cust_base = pd.read_csv('\/kaggle\/input\/broadband-customers-base-churn-analysis\/bbs_cust_base_scfy_20200210.csv')\nbbs_cust_base.head(10)","1f38414b":"print('bbs_cust_base dataframe has {} rows and {} columns'.format(bbs_cust_base.shape[0],bbs_cust_base.shape[1]))","509a0a06":"# computer memory used by dataframe in bytes\nused_pc_memory = bbs_cust_base.memory_usage(deep=True).sum()\nused_pc_memory = used_pc_memory\/(1000*1000)\nprint('bbs_cust_base data frame is using {0:.2f} MB computer memory'.format(used_pc_memory))","03419a71":"# data set description\nbbs_cust_base.describe(include='all')","ef9b6b0a":"# removing Unnamed: 19 column\n\n# It shows the values of not null unnamed: 19 rows\nbbs_cust_base[bbs_cust_base['Unnamed: 19'].notnull()]\n\n# no use of Unnamed: 19 column so drop it\nbbs_cust_base.drop('Unnamed: 19',axis=1,inplace=True)","475c639d":"# removing duplicate rows\nbbs_cust_base.drop_duplicates(inplace=True)\nbbs_cust_base.shape","581f6ce2":"# creating column name's list\ncol = bbs_cust_base.columns.to_list()\n\n# printing number of unique values in each column.\nbbs_cust_base.nunique()","71fee088":"# creating catagorical columns name list\ncatcol = [_ for _ in col if bbs_cust_base[_].nunique() < 30]\n\n# printing all the unique values of categorical colum\nfor _ in catcol:\n    print('{} has {} unique value\/s - {}\\n'.format(_,bbs_cust_base[_].nunique(),bbs_cust_base[_].unique())) ","6d59eede":"# column name term_reas_code contains name of code that have the discription in column term_reas_desc\n# creating a list of unique values of both column\n\ntermination_reasion_code = bbs_cust_base.term_reas_code.unique()\ntermination_reasion_code_description = bbs_cust_base.term_reas_desc.unique()\n\n# creating a dictionary for termination reasion code and description\ntermination_reasion = dict(zip(termination_reasion_code,termination_reasion_code_description))\n\ntermination_reasion","9f529bdc":"# droping of no more usefule columns\n# every customer is billed monthly so bill_cycl column is not useful\n# serv_type for each customer is BBS only one type of service so it is also not usefull\n# both term_reas_desc column and term_reas_code have same meaning\n# service_code column is also not useful for us\nbbs_cust_base.drop(columns=['bill_cycl','serv_type','term_reas_desc','serv_code'],inplace=True)","4bccf00d":"# checking the null or missing values in dataframe\nplt.figure(figsize=(10,10))\nsns.heatmap(data=bbs_cust_base.isna(),yticklabels=False,cbar=False,cmap='Set3')\nplt.show()\n\n# columns information\nbbs_cust_base.info()","e8812388":"# rows of data frame have missng values in effc_strt_date column\nbbs_cust_base[bbs_cust_base['effc_strt_date'].isnull()].head()\n\n# shape of null value data frame\nprint('size of null data frame is ',bbs_cust_base[bbs_cust_base['effc_strt_date'].isnull()].shape)\n\n# total number of unique customers in null dataframe\nprint('total unique newacct_no is ',bbs_cust_base[bbs_cust_base['effc_strt_date'].isnull()].newacct_no.nunique())\n\n# churned customer in this null data set\nbbs_cust_base[bbs_cust_base['effc_strt_date'].isnull()].churn.value_counts()","51264409":"# drop null values of eff_strt_date column\nbbs_cust_base.dropna(subset=['effc_strt_date'],inplace=True)\n\n# let's see data after removing all null value other than column name term_reas_code\nplt.figure(figsize=(10,10))\nsns.heatmap(data=bbs_cust_base.isna(),yticklabels=False,cbar=False,cmap='Set3')\nplt.show()","647568fe":"# complaint_cnt column contains word ' customer\/ user pass away'. we replace this word by 0 complaint.\n# complaint_cnt has mixed dtype (integer and string)\n# first we change integer in string, than replace words we want and than again change dtype to integer\nbbs_cust_base['complaint_cnt'] = bbs_cust_base.complaint_cnt.astype('str')\nbbs_cust_base['complaint_cnt'] = bbs_cust_base.complaint_cnt.str.replace(' customer\/ user pass away','0')\nbbs_cust_base['complaint_cnt'] = bbs_cust_base.complaint_cnt.astype('int')","af192bf0":"# replace Y by 1 and N by 0 in columns - with_phone_service, churn and current_mth_churn\n# and converting their dtype to int32\nbbs_cust_base['with_phone_service'] = (bbs_cust_base.with_phone_service == 'Y').astype('int32')\nbbs_cust_base['churn'] = (bbs_cust_base.churn == 'Y').astype('int32')\nbbs_cust_base['current_mth_churn'] = (bbs_cust_base.current_mth_churn == 'Y').astype('int32')","011eb6ac":"# changing the data type from string\/int64 to int32\n\nbbs_cust_base[['contract_month','ce_expiry','secured_revenue']] = bbs_cust_base[['contract_month','ce_expiry','secured_revenue']].astype('int')\nbbs_cust_base[['image','tenure']] = bbs_cust_base[['image','tenure']].astype('int32')","96dfe5b3":"# changing effc_strt_date and effc_end_date column in datetime formate\n\nbbs_cust_base['effc_strt_date'] = pd.to_datetime(bbs_cust_base['effc_strt_date'],dayfirst=True)\nbbs_cust_base['effc_end_date'] = bbs_cust_base.effc_end_date.astype('datetime64[ns]')","6f054180":"# counting of service termination reason\nplt.figure(figsize=(15,10))\nsns.set_style('whitegrid')\nplt.title('service termination reasion counting')\nsns.countplot(x='term_reas_code',data=bbs_cust_base,hue='churn')\nplt.xticks(rotation=45)\nplt.show()","b5fabbfc":"# we devide term_reas in 4 category.\n# 1 for reason in not in control of service provider\n# 2 user issue of cost \n# 3 service problem\n# 0 for NaN\n\ndef term_reasencoder(a):\n    if a in ('REV','CLB','NU','OT','CUSN2','CUSB0','MGR'):\n        return 1\n    elif a in ('NET','UFSS','COVL3','COM15','COVL2','UCSH','LOSF','COVL1','COM10','UEMS','NWQU','NCAP'):\n        return 3\n    elif a in ('CUCO','OT','TRM','EXP','BILP','EXI','PLR'):\n        return 2\n    else:\n        return 0\n\nbbs_cust_base['term_reas_code'] = bbs_cust_base.term_reas_code.map(term_reasencoder)\nbbs_cust_base['term_reas_code'] = bbs_cust_base.term_reas_code.astype('int32')","933e2c0e":"def bandwidthencoder(a):\n    if a in ('30M', '10M','BELOW 10M', '50M'):\n        return 0\n    if a in ('100M','100M (FTTO)'):\n        return 1\n    if a in ('300M (FTTO)', '1000M (FTTO)', '500M (FTTO)'):\n        return 2\n\nbbs_cust_base['bandwidth'] = bbs_cust_base.bandwidth.map(bandwidthencoder)\nbbs_cust_base['bandwidth'] = bbs_cust_base.bandwidth.astype('int32')","d0f0fe1e":"# # creating new feature of month and year from effc_strt and effc_end\n# bbs_cust_base = bbs_cust_base.assign(start_month = bbs_cust_base.effc_strt_date.dt.month,\n#                                     start_year = bbs_cust_base.effc_strt_date.dt.year,\n#                                     end_month = bbs_cust_base.effc_end_date.dt.month,\n#                                     end_year = bbs_cust_base.effc_end_date.dt.year)","a456c9f0":"# newacct_no is unique id we set it to index of our dataset\nbbs_cust_base.set_index(keys='newacct_no',inplace = True)\nbbs_cust_base.head()","0094e8c3":"# kdeplot of tenure\nplt.figure(figsize=(8,8))\nsns.kdeplot(bbs_cust_base[bbs_cust_base.churn == 1].tenure,label='Churn')\nsns.kdeplot(bbs_cust_base[bbs_cust_base.churn == 0].tenure,label='Not Churn')","be7c279f":"# distribution of tenure column\nplt.figure(figsize=(8,8))\nsns.distplot(bbs_cust_base[bbs_cust_base.churn == 1].tenure,label='Churn',kde=False)\nsns.distplot(bbs_cust_base[bbs_cust_base.churn == 0].tenure,label='Not Churn',kde=False)\nplt.legend()","26a0b821":"# we creating new dataframe called broadband_ with some of useful features\nbroadband_ = bbs_cust_base[['contract_month','ce_expiry','secured_revenue','bandwidth','complaint_cnt','with_phone_service']]\n\n# creating new feature of month and year from effc_strt and effc_end\nbroadband_['start_month'] = bbs_cust_base.effc_strt_date.dt.month\nbroadband_['start_year'] = bbs_cust_base.effc_strt_date.dt.year\nbroadband_['end_month'] = bbs_cust_base.effc_end_date.dt.month\nbroadband_['end_year'] = bbs_cust_base.effc_end_date.dt.year","00be052b":"# As we know in this data set there are many rows for same unique customer id. \n# these rows have different tenure period depends on billing month\n# we replace this tenure period with the maximum tenure of the customer with company\n\nbroadband_['tenure'] = bbs_cust_base.groupby('newacct_no').tenure.max()","99e6774d":"# encoding for churn column - 0 if customer is not churn, 1 if customer is already churn but not in this month and 2 if customer churm in current mont\n# by adding churn and current_mth_churn columns values\nbroadband_['churn'] = bbs_cust_base.churn + bbs_cust_base.current_mth_churn","d0287a90":"# view top 5 rows of new dataframe less with feature called broadband_\nbroadband_.head()\n\n# shape of the broadband_\nbroadband_.shape","a02539c9":"# removing duplicate from the dataframe\nbroadband_ = broadband_.drop_duplicates()\n\n# size of dataframe after removing duplicates\nbroadband_.shape","bff412ff":"# pearsion vlaues of broadband_'s columns with one another\nplt.figure(figsize=(15,15))\nsns.heatmap(broadband_.corr(),annot=True,cbar=False)\nplt.show()","4b340f4d":"# selecting churn column as traget column and rest features as indepandet variable\ny = broadband_['churn']\nx = broadband_.drop(['churn'],axis=1)","f1c90630":"# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test =  train_test_split(x,y,test_size=0.25,random_state=42)","9f78f685":"# we define 2 list that one of them save results of models other list save name of model\nlabelList = []\nresultList = []","e0deaa6d":"# Logictic Regression with sklearn\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=1)\nlr.fit(x_train,y_train)\nlr_prediction = lr.predict(x_test)\nprint(\"test accuracy {}\".format(lr.score(x_test,y_test)))\n\n# adding result and label to lists\nlabelList.append(\"Log_Rec\")\nresultList.append(lr.score(x_test,y_test))","5b90ad7e":"# Decision Tree \nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(random_state=1)\ndt.fit(x_train,y_train)\ndt_prediction = dt.predict(x_test)\nprint(\"decison tree score : \",dt.score(x_test,y_test))\n\n# adding result and label to lists\nlabelList.append(\"Dec_Tree\")\nresultList.append(dt.score(x_test,y_test))","f493df8a":"# Random forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100,random_state = 1)\nrf.fit(x_train, y_train)\nrf_prediction = rf.predict(x_test)\nprint(\"Random forest algor. result: \",rf.score(x_test,y_test))\n\n# adding result and label to lists\nlabelList.append(\"Rand_For\")\nresultList.append(rf.score(x_test,y_test))","fc47b29e":"# Naive Byes \nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nnb_prediction = nb.predict(x_test)\nprint(\"print accuracy of naive bayes algo: \",nb.score(x_test,y_test))\n\n# adding result and label to lists\nlabelList.append(\"Naive_Byes\")\nresultList.append(nb.score(x_test,y_test))","7bfd4f0a":"# KNN model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3) #n_neighbors = k\nknn.fit(x_train,y_train)\nknn_prediction = knn.predict(x_test)\n\n# score\nprint(\" {} nn score: {} \".format(3,knn.score(x_test,y_test)))","164f7503":"# Finding optimum k value between 1 and 15\nscore_list = []\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors = each) # create a new knn model\n    knn2.fit(x_train,y_train)\n    knn2_prediction = knn2.predict(x_test)\n    score_list.append(knn2.score(x_test,y_test))\n\nplt.plot(range(1,15),score_list) # x axis is in interval of 1 and 15\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\n# finding max value in a list and it's index.\na = max(score_list) # finding max value in list\nb = score_list.index(a)+1 # index of max value.\n\nprint(\"k = \",b,\" and maximum value is \", a)\n\n# adding result and label to lists\nlabelList.append(\"KNN\")\nresultList.append(a)","7f00add5":"# First of all we combine 2 lists (labelList and resultList) by using zip method\nzipped = zip(labelList, resultList)\nzipped = list(zipped)\n\ndf = pd.DataFrame(zipped, columns=['label','result'])\ndf\n\n# Viewing this df table in form of graph\nnew_index = (df['result'].sort_values(ascending=False)).index.values \nsorted_data = df.reindex(new_index)\n\nplt.plot(sorted_data.loc[:,\"label\"],sorted_data.loc[:,\"result\"])\nplt.show()","1d07622f":"bbs_cust_base[(bbs_cust_base.ce_expiry >= -6) & (bbs_cust_base.ce_expiry <= 0)  & (bbs_cust_base.churn == 1)].index.nunique()","c7902a0c":"# confusion matrix of randomforest model\nfrom sklearn.metrics import confusion_matrix\nrf_cf_matrix = confusion_matrix(y_test,rf_prediction,labels=[0,1,2])\n\n# heatmap to see confusion metrix\nsns.heatmap(rf_cf_matrix,cbar=False,annot=True,cmap='coolwarm_r',fmt='')\nplt.xlabel('Original')\nplt.ylabel('Predict')","e29a81a5":"# actual vs predicted is the score of confusion matrix\ndf.loc[2,:]","81347a6c":"# dataframe creation\nbroadband_imp = bbs_cust_base[['contract_month','ce_expiry','secured_revenue','bandwidth','complaint_cnt','with_phone_service']]\n\n# creating new feature of month and year from effc_strt and effc_end\nbroadband_imp['start_month'] = bbs_cust_base.effc_strt_date.dt.month\nbroadband_imp['start_year'] = bbs_cust_base.effc_strt_date.dt.year\nbroadband_imp['end_month'] = bbs_cust_base.effc_end_date.dt.month\nbroadband_imp['end_year'] = bbs_cust_base.effc_end_date.dt.year\n\nbroadband_imp['tenure'] = bbs_cust_base.groupby('newacct_no').tenure.max()\nbroadband_imp['churn'] = bbs_cust_base.churn\n\n# dropping duplicate value\nbroadband_imp = broadband_imp.drop_duplicates()\nprint('After removing duplicate shape of broadband_imp is {}'.format(broadband_imp.shape))\n\n# selecting churn as traget column and rest features as indepandet variable\ny_imp = broadband_imp['churn']\nx_imp = broadband_imp.drop(['churn'],axis=1)\n\n# train test split\nx_train_imp, x_test_imp, y_train_imp, y_test_imp =  train_test_split(x_imp,y_imp,test_size=0.25,random_state=42)\n\n# Random forest\nrf_imp = RandomForestClassifier(n_estimators=100,random_state = 1)\nrf_imp.fit(x_train_imp, y_train_imp)\nrf_prediction_imp = rf.predict(x_test_imp)\nprint(\"Improved Random forest algor. result: \",rf_imp.score(x_test_imp,y_test_imp))\n\n# confusion matrix\nrf_cf_matrix_imp = confusion_matrix(y_test_imp,rf_prediction_imp,labels=[0,1])\n\n# heatmap to see confusion metrix\nsns.heatmap(rf_cf_matrix_imp,cbar=False,annot=True,cmap='coolwarm_r',fmt='')\nplt.xlabel('Original')\nplt.ylabel('Predict')","6af55683":"Our Random Forest model can be improved if we do not consider the current_mth_churn column by any type.","3cea1221":"# Question 1\n\n<h3\/> Total customers actually churned in last 6 months<h3\/>","9f549db6":"# handling missing values","fc34bfe6":"1. column name Unnamed: 19 has only 1 unique value in only 2 rows.\n2. if we consider column newacct_no as unique id than we can say that company has dealed 510125 times with his 27605 customers.","e6e5e8f8":"# Question 2\n\n<h3\/>Total customers predicted as churned by model<h3\/>","5b1d9dea":"# Question 3\n\n<h3\/>Total no. Of  matched customers from actual vs predicted<h3\/>","333d7a77":"# Assumption\nas per the value of ce_expiry column this data set is taking current month, Jan 2020. We also use Jan 2020 as current month","e7860143":"# conclusion\n\n<h1\/>Above Table and Graph shows that RandomForest is best suitable model for this dataset to find the churn customer.<h1\/>","ebd3abb7":"Anwer - After removing the duplicate rows from data set we can say that Total 971 customer actually churned in last 6 months (on the basis of newacct_no which is unique for each customer)","997a7ac1":"<h6\/>columns effc_strt_date, effc_end_date, contract_month and ce_expiry have less missing values. On other hand columns term_reas_code and term_reas_desc have too much missing values.<h6\/>","7697c19c":"# changing dtype of columns","a68d7f58":"# model building and testing","270a1735":"# Model Improvement","49d799f3":"# conclusion\n1. we have total 510125 rows in our original data set out of this only 1937 rows have missing values.\n2. these all missing values belong to only 200 unique id out of 27605 total unique id\n3. only 19 unique id have been churned at yet from this null data set\n<h4\/>On the basis of above three conclusion we can say that all these rows do not have any valuable counts So we can drope them from our data set<h4\/>","7c36141d":"This shows major improvement in the score of our RandomForest Model from 90.09% to 99.13%.","d055d369":"# Selecting features","3890e52f":"## Broadband Customers Churned Analysis\nThis NoteBook is created for the pridiction that custumer of broadband service provider is churned or not**","9597dfb3":"In this classification problem we create and test most of the models and than compare with their score to find best sutiable model. we use following models of sklearn\n1. Logictic Regression\n2. Decision Tree \n3. Random forest\n4. Naive Byes \n5. KNN model ","a99630cf":"This graph show that if customer has reason to churned than they do so. only some customers with reason cutting cost do not break service contract. ","973e89a0":"To find the answer we check two conditions\n1. is customer churned or not by churn > 0\n2. ce_expiry value is in range of -6 to 0\n3. NOTE - We count newacct_no which is unique, only one time even it is apper in data set more than one time","4384fe7f":"Answer - Total customer predicted churn with value 1 is 83 + 1390 + 827 = 2300 and with value 2 is 27 + 707 + 489 = 1223","6322d665":"Answer - Our best model Random Forest scored 90.0975 %","a0a95f02":"# finding the feature columns"}}