{"cell_type":{"a6666783":"code","7550390e":"code","d6fd0811":"code","443775d6":"code","35cfe6dd":"code","1762fdd6":"code","d4eaf59a":"code","5c379a30":"code","e1e9d19d":"code","198ee371":"code","e51e5fc4":"code","c35294ac":"code","0e482360":"code","2cfb0e2f":"code","899057a8":"code","e59d52d4":"markdown","c56c3a1a":"markdown","acfc865c":"markdown","82b1625a":"markdown","5b608c5e":"markdown"},"source":{"a6666783":"import numpy as np, pandas as pd, os\npd.options.display.max_rows = 999\n\nOOF_FILE = '..\/input\/nfl-oof-0513\/OOF_CV_513.csv'\ndf_pred = pd.read_csv(OOF_FILE)\ndf_pred.head()","7550390e":"import cv2\nfrom tqdm.notebook import tqdm\nimport subprocess\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom IPython.display import Video, display\n\nimport datetime as dt\nfrom pathlib import Path","d6fd0811":"BASE_DIR = '..\/input\/nfl-impact-detection\/'\n\n# LOAD TRAIN LABELS\ntrain = pd.read_csv(BASE_DIR+'train_labels.csv')\nprint('Train label shape is', train.shape )\ntrain.head()","443775d6":"# FIND TARGETS AND LABEL THEIR COMING AND GOING\ntrain['target'] = ((train.impact==1)&(train.confidence>1)&(train.visibility>0)).astype('int8')\ntrain['warning'] = 0\ntrain = train.sort_values(['video','label','frame']).reset_index(drop=True)\n\n# MARK PREVIOUS AND FOLLOWING IMPACT SO WE CAN WARN VIEWERS\nfor k in range(-10,1):\n    train.warning += train.target.shift(k).fillna(0)\nfor k in range(1,11):\n    train.warning -= train.target.shift(k).fillna(0)\n    \ntrain['hit'] = train.groupby(['video','frame']).target.transform('max')","35cfe6dd":"# LOAD TRACKING DATA\ntrack = pd.read_csv(BASE_DIR+'train_player_tracking.csv')\ntrack[\"time\"] = pd.to_datetime(track[\"time\"])\ntrack[\"color\"] = track[\"player\"].map(lambda x: \"black\" if \"H\" in x else \"white\")\nprint( track.shape )\ntrack.head()","1762fdd6":"# https:\/\/www.kaggle.com\/robikscube\/nfl-big-data-bowl-plotting-player-position\/notebook\ndef create_football_field(linenumbers=True,\n                          endzones=True,\n                          highlight_line=False,\n                          highlight_line_number=50,\n                          highlighted_name='Line of Scrimmage',\n                          fifty_is_los=False,\n                          figsize=(12, 6.33)):\n    \"\"\"\n    Function that plots the football field for viewing plays.\n    Allows for showing or hiding endzones.\n    \"\"\"\n    rect = patches.Rectangle((0, 0), 120, 53.3, linewidth=0.1,\n                             edgecolor='r', facecolor='forestgreen', zorder=0)  # changed the field color to forestgreen\n\n    fig, ax = plt.subplots(1, figsize=figsize)\n    ax.add_patch(rect)\n\n    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n             color='white')\n    if fifty_is_los:\n        plt.plot([60, 60], [0, 53.3], color='gold')\n        plt.text(62, 50, '<- Player Yardline at Snap', color='gold')\n    # Endzones\n    if endzones:\n        ez1 = patches.Rectangle((0, 0), 10, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ez2 = patches.Rectangle((110, 0), 120, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ax.add_patch(ez1)\n        ax.add_patch(ez2)\n    plt.xlim(0, 120)\n    plt.ylim(-5, 58.3)\n    plt.axis('off')\n    if linenumbers:\n        for x in range(20, 110, 10):\n            numb = x\n            if x > 50:\n                numb = 120 - x\n            plt.text(x, 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white')\n            plt.text(x - 0.95, 53.3 - 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white', rotation=180)\n    if endzones:\n        hash_range = range(11, 110)\n    else:\n        hash_range = range(1, 120)\n\n    for x in hash_range:\n        ax.plot([x, x], [0.4, 0.7], color='white')\n        ax.plot([x, x], [53.0, 52.5], color='white')\n        ax.plot([x, x], [22.91, 23.57], color='white')\n        ax.plot([x, x], [29.73, 30.39], color='white')\n\n    if highlight_line:\n        hl = highlight_line_number + 10\n        plt.plot([hl, hl], [0, 53.3], color='yellow')\n        plt.text(hl + 2, 50, '<- {}'.format(highlighted_name),\n                 color='yellow')\n    return fig, ax\n\n#create_football_field()\n#plt.show()","d4eaf59a":"def get_track_image(gameKey=58000, playID=1306, fps=60, frame=10, fmax=300, labels=False, \n                     warn1=[], warn2=[], hit=[]):\n\n    play_track = track.loc[(track.gameKey == gameKey) & (track.playID == playID)]\n    snap_time = play_track.loc[play_track.event == 'ball_snap','time'].iloc[0]\n\n    play_start = snap_time - dt.timedelta(seconds = 0.1) #10\/fps)\n    play_end = play_start + dt.timedelta(seconds = fmax\/fps)\n    play_track = play_track.loc[(play_track.time>=play_start)&(play_track.time<=play_end)]\n\n    current = play_start + dt.timedelta(seconds = frame\/fps)\n    abs_timedelta = abs(play_track['time'] - current).dt.total_seconds()\n    min_abs_timedelta = abs_timedelta.min()\n    play_current = play_track[abs_timedelta == min_abs_timedelta]\n\n    fig, ax = create_football_field(figsize=(20, 12))\n    play_current.plot(x=\"x\", y=\"y\",  kind='scatter', ax=ax, color = play_current['color'], s=100)\n    \n    draw = [warn1,warn2,hit]\n    colors = ['white','black','blue']\n    widths = [2,2,5]\n    \n    for i,j in enumerate(draw):\n        for k in j:\n            row = play_current.loc[(play_current.player==k)]\n            if len(row)==0: continue\n            row = row.iloc[0]\n            ax.plot([row.x-1,row.x-1],[row.y-1,row.y+1],color=colors[i],linewidth=widths[i])\n            ax.plot([row.x+1,row.x+1],[row.y-1,row.y+1],color=colors[i],linewidth=widths[i])\n            ax.plot([row.x-1,row.x+1],[row.y-1,row.y-1],color=colors[i],linewidth=widths[i])\n            ax.plot([row.x-1,row.x+1],[row.y+1,row.y+1],color=colors[i],linewidth=widths[i])\n\n    if labels:\n        play_home = play_current.loc[play_current['player'].str.contains('H')]\n        play_away = play_current.loc[play_current['player'].str.contains('V')]\n        for index, row in play_away.iterrows():\n            ax.annotate(row['player'], (row['x'], row['y']), verticalalignment='center', horizontalalignment='right', fontsize=12)\n        for index, row in play_home.iterrows():\n            ax.annotate(row['player'], (row['x'], row['y']), verticalalignment='center', horizontalalignment='left', \n                    color = 'white', fontsize=12)\n    \n    #Image from plot\n    ax.axis('off')\n    fig.tight_layout(pad=0)\n\n    # To remove the huge white borders\n    ax.margins(0)\n\n    fig.canvas.draw()\n    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n    image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n    plt.close()\n\n    return image_from_plot[72:-72,80:-80,:]","5c379a30":"# DISPLAY GAME, PLAY, FRAME, AND MARK HELMET LABELS\n# VARIABLE WARN1, WARN2, AND HIT ARE LISTS OF HELMET LABELS\nimg = get_track_image(57787,3413,frame=50,warn1=['H68'])\nplt.figure(figsize=(15,7))\nplt.imshow(img[::2,::2,::-1])\nplt.show()","e1e9d19d":"img.shape","198ee371":"valid_videos = df_pred.video.unique()\nprint('There are', len(valid_videos),'unique videos in OOF file.')\nprint('OOF file shape is', df_pred.shape )\ndf_pred.head()","e51e5fc4":"# https:\/\/www.kaggle.com\/nvnnghia\/evaluation-metrics\nfrom scipy.optimize import linear_sum_assignment\n\ndef iou_ltwh(bbox1, bbox2):\n    \n    \n    bbox1 = [float(x) for x in bbox1]\n    bbox2 = [float(x) for x in bbox2]\n    \n    bbox1[2] += bbox1[0] \n    bbox1[3] += bbox1[1] \n    \n    bbox2[2] += bbox2[0] \n    bbox2[3] += bbox2[1] \n\n    (x0_1, y0_1, x1_1, y1_1) = bbox1\n    (x0_2, y0_2, x1_2, y1_2) = bbox2\n\n    # get the overlap rectangle\n    overlap_x0 = max(x0_1, x0_2)\n    overlap_y0 = max(y0_1, y0_2)\n    overlap_x1 = min(x1_1, x1_2)\n    overlap_y1 = min(y1_1, y1_2)\n\n    # check if there is an overlap\n    if overlap_x1 - overlap_x0 <= 0 or overlap_y1 - overlap_y0 <= 0:\n            return 0\n\n    # if yes, calculate the ratio of the overlap to each ROI size and the unified size\n    size_1 = (x1_1 - x0_1) * (y1_1 - y0_1)\n    size_2 = (x1_2 - x0_2) * (y1_2 - y0_2)\n    size_intersection = (overlap_x1 - overlap_x0) * (overlap_y1 - overlap_y0)\n    size_union = size_1 + size_2 - size_intersection\n\n    return size_intersection \/ size_union\n\ndef precision_calc(gt_boxes, pred_boxes):\n    cost_matix = np.ones((len(gt_boxes), len(pred_boxes)))\n    for i, box1 in enumerate(gt_boxes):\n        for j, box2 in enumerate(pred_boxes):\n            dist = abs(box1[0]-box2[0])\n            if dist > 4:\n                continue\n            iou_score2 = iou_ltwh(box1[1:], box2[1:])\n\n            if iou_score2 < 0.35:\n                continue\n            else:\n                cost_matix[i,j]=0\n\n    row_ind, col_ind = linear_sum_assignment(cost_matix)\n    fn = len(gt_boxes) - row_ind.shape[0]\n    fp = len(pred_boxes) - col_ind.shape[0]\n    tp=0\n    for i, j in zip(row_ind, col_ind):\n        if cost_matix[i,j]==0:\n            tp+=1\n        else:\n            fp+=1\n            fn+=1\n    return tp, fp, fn\n\ndef competition_metric(valid_labels, pred_df, output=False):\n    ftp, ffp, ffn = [], [], []\n    cols = ['frame', 'left', 'top', 'width', 'height']\n    for video in valid_labels['video'].unique():\n        pred_boxes = pred_df[pred_df['video'] == video][cols].values\n        gt_boxes = valid_labels[valid_labels['video'] == video][cols].values\n       \n        tp, fp, fn = precision_calc(gt_boxes, pred_boxes)\n        ftp.append(tp)\n        ffp.append(fp)\n        ffn.append(fn)\n    \n    tp = np.sum(ftp)\n    fp = np.sum(ffp)\n    fn = np.sum(ffn)\n    precision = tp \/ (tp + fp + 1e-6)\n    recall =  tp \/ (tp + fn +1e-6)\n    f1_score = 2*(precision*recall)\/(precision+recall+1e-6)\n    if output:\n        return tp, fp, fn, precision, recall, f1_score\n    else:\n        print(f'TP: {tp}, FP: {fp}, FN: {fn}, PRECISION: {precision:.4f}, RECALL: {recall:.4f}, F1 SCORE: {f1_score}')\n\ntrue = train.loc[(train.video.isin(valid_videos))&(train.impact==1)&(train.confidence>1)&(train.visibility>0)]\nprint('There are %i ground truths for the videos in OOF file'%true.shape[0] )\nprint()\nprint('This OOF file has competition metric:')\ncompetition_metric(true, df_pred)","c35294ac":"# Modified function from to take single frame.\n# https:\/\/www.kaggle.com\/samhuddleston\/nfl-1st-and-future-getting-started\ndef annotate_frame(gameKey, playID, video_labels, slow=1, stop_frame=-1, start_frame=-1) -> str:\n    VIDEO_CODEC = \"MP4V\"\n    BLACK = (0, 0, 0)    # Black\n    WHITE = (255, 255, 255)    # White\n    IMPACT_COLOR = (0, 0, 255)  # Red\n    PRED_COLOR = (255, 0, 0) # Blue\n    PRED_COLOR_WARN1 = (0, 255, 255) # Yellow\n    PRED_COLOR_WARN2 = (0, 255, 0) # Green\n    \n    tp, fp, fn, pp, rr, ff = competition_metric(true.loc[(true.gameKey==gameKey)&(true.playID==playID)],\n                               df_pred.loc[(df_pred.gameKey==gameKey)&(df_pred.playID==playID)],True)\n    \n    video_path1 = BASE_DIR+'\/train\/%i_%.6i_Endzone.mp4'%(gameKey,playID)\n    video_path2 = BASE_DIR+'\/train\/%i_%.6i_Sideline.mp4'%(gameKey,playID)\n    \n    video_name1 = os.path.basename(video_path1)\n    video_name2 = os.path.basename(video_path2)\n    \n    hits1 = train.loc[train.video==video_name1].drop_duplicates('frame').sort_values('frame').hit.values\n    f_max1 = train.loc[train.video==video_name1,'frame'].max()\n    hits2 = train.loc[train.video==video_name2].drop_duplicates('frame').sort_values('frame').hit.values\n    f_max2 = train.loc[train.video==video_name2,'frame'].max()\n    \n    hits3 = df_pred.loc[df_pred.video==video_name1].frame.unique()\n    hits4 = df_pred.loc[df_pred.video==video_name2].frame.unique()\n    \n    if f_max1 != f_max2:\n        print('## WARNING: different length videos')\n    f_max = min(f_max1,f_max2)\n    print('Converting',f_max,'frames...',end='')\n    \n    vidcap1 = cv2.VideoCapture(video_path1)\n    vidcap2 = cv2.VideoCapture(video_path2)\n    \n    fps = vidcap1.get(cv2.CAP_PROP_FPS)\n    width1 = int(vidcap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height1 = int(vidcap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    \n    output_path = \"labeled_\" + video_name1.replace('_Endzone','')\n    tmp_output_path = \"tmp_\" + output_path\n    output_video = cv2.VideoWriter(tmp_output_path, cv2.VideoWriter_fourcc(*VIDEO_CODEC), fps\/slow, (width1, height1))\n    \n    frame = 0\n    while True:\n        \n        if frame%10==0: print(frame,', ',end='')\n        img = np.zeros((height1,width1,3),dtype='uint8')\n                \n        it_worked1, img1 = vidcap1.read()\n        if not it_worked1: break\n            \n        it_worked2, img2 = vidcap2.read()\n        if not it_worked2: break\n            \n        if frame<start_frame: \n            frame += 1\n            continue\n        if frame==stop_frame: break\n            \n        img[360:,:640,:] = img1[::2,::2,:]\n        img[360:,640:,:] = img2[::2,::2,:]\n        \n        # We need to add 1 to the frame count to match the label frame index that starts at 1\n        frame += 1\n        \n        # Let's add a frame index to the video so we can track where we are\n        img_name = f\"GamePlay_{video_name1.replace('_Endzone.mp4','')}_frame{frame}\"\n        cv2.putText(img, img_name, (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, WHITE, thickness=2)\n        \n        metric = f'TP: {tp}, FP: {fp}, FN: {fn}, PRECISION: {pp:.3f}, RECALL: {rr:.3f}, F1 SCORE: {ff:.4f}'\n        cv2.putText(img, metric, (10, 300), cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, thickness=1)\n            \n        # MAKE FOUR PROGRESS LINES\n        hh = 100\n        cv2.line(img, (20,hh),(600,hh),(0,0,255),4)\n        for k in np.where( hits1==1 )[0]:\n            x = int(k\/f_max * 580 + 20)\n            cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(0,0,255),cv2.FILLED) \n        x = int(frame\/f_max * 580 + 20)\n        cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(255,255,255),cv2.FILLED) \n        \n        hh = 150\n        cv2.line(img, (20,hh),(600,hh),(0,0,255),4)\n        for k in np.where( hits2==1 )[0]:\n            x = int(k\/f_max * 580 + 20)\n            cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(0,0,255),cv2.FILLED) \n        x = int(frame\/f_max * 580 + 20)\n        cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(255,255,255),cv2.FILLED) \n        \n        hh = 200\n        cv2.line(img, (20,hh),(600,hh),(255,0,0),4)\n        for k in hits3:\n            x = int(k\/f_max * 580 + 20)\n            cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(255,0,0),cv2.FILLED) \n        x = int(frame\/f_max * 580 + 20)\n        cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(255,255,255),cv2.FILLED) \n        \n        hh = 250\n        cv2.line(img, (20,hh),(600,hh),(255,0,0),4)\n        for k in hits4:\n            x = int(k\/f_max * 580 + 20)\n            cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(255,0,0),cv2.FILLED) \n        x = int(frame\/f_max * 580 + 20)\n        cv2.rectangle(img, (x-1,hh-10),(x+1,hh+10),(255,255,255),cv2.FILLED) \n        \n        w1, w2, h1 = [], [], []\n        \n        # DRAW 4 SETS OF BOXES\n        boxes = video_labels.query(\"video == @video_name1 and frame == @frame and warning != 0\")\n        for box in boxes.itertuples(index=False):\n            left = box.left\/\/2\n            top = box.top\/\/2 + 360\n            width = box.width\/\/2\n            height = box.height\/\/2\n            if box.impact == 1 and box.confidence > 1 and box.visibility > 0:   \n                color, thickness = IMPACT_COLOR, 2\n                #print('(Impact frame',frame,box.label,box.confidence,box.visibility,')',end='')  \n                h1.append(box.label)\n            elif box.warning == 1:    \n                color, thickness = WHITE, 1\n                w1.append(box.label)\n            else:\n                color, thickness = BLACK, 1\n                w2.append(box.label)\n            # Add a box around the helmet\n            cv2.rectangle(img, (left, top), (left + width, top + height), color, thickness=thickness)\n            #cv2.putText(img, box.label, (left, max(0, top - 5\/\/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, thickness=1)\n            \n        # Now, add the boxes\n        boxes = video_labels.query(\"video == @video_name2 and frame == @frame and warning != 0\")\n        for box in boxes.itertuples(index=False):\n            left = box.left\/\/2 + 640\n            top = box.top\/\/2 + 360\n            width = box.width\/\/2\n            height = box.height\/\/2\n            if box.impact == 1 and box.confidence > 1 and box.visibility > 0:   \n                color, thickness = IMPACT_COLOR, 2\n                #print('Impact frame',frame,box.label,box.confidence,box.visibility)            \n            elif box.warning == 1:    \n                color, thickness = WHITE, 1\n            else:\n                color, thickness = BLACK, 1\n            # Add a box around the helmet\n            cv2.rectangle(img, (left, top), (left + width, top + height), color, thickness=thickness)\n            #cv2.putText(img, box.label, (left, max(0, top - 5\/\/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, thickness=1)\n            \n            \n        #Now, add the boxes\n        boxes = df_pred.loc[(df_pred.video == video_name1) & (abs(df_pred.frame - frame)<=10)]\n        for box in boxes.itertuples(index=False):\n            left = box.left\/\/2\n            top = box.top\/\/2 + 360\n            width = box.width\/\/2\n            height = box.height\/\/2\n            if box.frame == frame:   \n                color, thickness = PRED_COLOR, 2\n                #print('(Pred frame',frame,')',end='')  \n            elif box.frame > frame:\n                color, thickness = PRED_COLOR_WARN1, 1\n            else:\n                color, thickness = PRED_COLOR_WARN2, 1\n                \n            # Add a box around the helmet\n            cv2.rectangle(img, (left, top), (left + width, top + height), color, thickness=thickness)\n            #cv2.putText(img, box.label, (left, max(0, top - 5\/\/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, thickness=1)\n                              \n        #Now, add the boxes\n        boxes = df_pred.loc[(df_pred.video == video_name2) & (abs(df_pred.frame - frame)<=10)]\n        for box in boxes.itertuples(index=False):\n            left = box.left\/\/2 + 640\n            top = box.top\/\/2 + 360\n            width = box.width\/\/2\n            height = box.height\/\/2\n            if box.frame == frame:   \n                color, thickness = PRED_COLOR, 2\n                #print('(Pred frame',frame,')',end='') \n            elif box.frame > frame:\n                color, thickness = PRED_COLOR_WARN1, 1\n            else:\n                color, thickness = PRED_COLOR_WARN2, 1\n\n            # Add a box around the helmet\n            cv2.rectangle(img, (left, top), (left + width, top + height), color, thickness=thickness)\n            #cv2.putText(img, box.label, (left, max(0, top - 5\/\/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, thickness=1)\n            \n        # DRAW ARIAL VIEW WITH TRACKING INFO\n        img3 = get_track_image(gameKey,playID,fps,frame+1,f_max, warn1=w1, warn2=w2, hit=h1)\n        img[:360,640:,:] = img3[::2,::2,:]    \n        \n        \n        output_video.write(img)\n    output_video.release()\n    \n    # Not all browsers support the codec, we will re-load the file at tmp_output_path and convert to a codec that is more broadly readable using ffmpeg\n    if os.path.exists(output_path):\n        os.remove(output_path)\n    subprocess.run([\"ffmpeg\", \"-i\", tmp_output_path, \"-crf\", \"18\", \"-preset\", \"veryfast\", \"-vcodec\", \"libx264\", output_path])\n    os.remove(tmp_output_path)\n    \n    return output_path","0e482360":"print('Here are some videos in OOF file')\nvalid_videos[:10]","2cfb0e2f":"# CHOOSE GAME, PLAY, AND CREATE VIDEO\ngame = '58102_002798' \ng = int( game.split('_')[0] )\np = int( game.split('_')[1] )\n\n# VARIABLE \"SLOW\" CONTROLS FRAME RATE\nannotate_frame(g, p, video_labels=train, slow=15, start_frame = -1, stop_frame = -1 )","899057a8":"display(Video(data='labeled_%i_%.6i.mp4'%(g,p), embed=True))","e59d52d4":"# Convert OOF and Submission Predictions into a Video!\nThis notebook converts your `submission.csv` or `oof.csv` file into a video that you can watch to analyze your model. The video displays ground truths and model predictions of all three video views simultaneously. After creating a video with this notebook, it is best to watch, by scrolling to this notebook's Output Section, and then watching the video in the Output Section. Then you will be able to click the full screen button. If you watch it embedded in the Jupyter Notebook, the full screen button doesn't work. The boxes in the video follow the following key:\n\n**Key:**  \nRed - ground truth impact  \nWhite - warns you that ground truth is coming within 10 frames  \nBlack - warns you that ground truth occurred within 10 frames in past  \n  \nBlue - model prediction   \nYellow - warns you that prediction is coming within 10 frames  \nGreen - warns you that prediction occurred within 10 frames in past  ","c56c3a1a":"# Load Train Labels","acfc865c":"# OOF Predictions","82b1625a":"# Load Tracking Data","5b608c5e":"# Make Videos\nThe code below can be cleaned up. The repeated code blocks can be put into a function"}}