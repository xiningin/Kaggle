{"cell_type":{"b55f2338":"code","19be0b77":"code","482f796e":"code","85d941d2":"code","3b5009cd":"code","d30bcd1a":"code","165e4d2c":"code","9af9ce7b":"code","52d49249":"code","40b9d54a":"code","53a21143":"code","571032a8":"code","61bf76ef":"code","2d55a49a":"code","a34c964e":"code","5fba7ee1":"code","37e9a793":"code","8b7e9f60":"code","a1dbfba8":"code","c4de41ba":"code","ca5291e1":"code","64a37ffc":"code","51958a9b":"code","48c90109":"code","11aa01a9":"code","267e3d8f":"code","8960f9a7":"code","a30b4302":"code","c4a12d48":"code","f835515c":"code","3aadcff4":"code","681dbf4d":"code","12bd9b77":"markdown","cffb72b0":"markdown","a68d90fd":"markdown","a5d094d8":"markdown","5a1508f3":"markdown","69a515d7":"markdown","cb179fe6":"markdown","fec1a4ad":"markdown","feed1c2c":"markdown","399a108a":"markdown","76fe3c5d":"markdown","0807e14b":"markdown"},"source":{"b55f2338":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","19be0b77":"# Reading the input data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nprint(train_data.info())","482f796e":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.info()","85d941d2":"# we will gather both data set to work directly with the entire data set\ntrain = train_data.set_index(\"PassengerId\")\ntest = test_data.set_index(\"PassengerId\")\ndata = pd.concat([train, test], axis=0, sort=False)\ndata.info()","3b5009cd":"data.head()","d30bcd1a":"sex = data.pop('Sex')\ndata['Female'] = (sex == \"female\")*1.0\ndata['Male'] = (sex == \"male\")*1.0\n\npclass = data.pop('Pclass')\ndata['Upclass'] = (pclass == 1)*1.0\ndata['Mpclass'] = (pclass == 2)*1.0\ndata[\"Lpclass\"] = (pclass == 3)*1.0\n\nembarked = data.pop('Embarked')\ndata['SEmbarked'] = (embarked == \"S\")*1.0\ndata['CEmbarked'] = (embarked == \"C\")*1.0\ndata[\"QEmbarked\"] = (embarked == \"Q\")*1.0\n\ndata.head()","165e4d2c":"# dropping Name and Cabin columns\ndata.drop([\"Name\", \"Cabin\"], axis = 1, inplace = True)","9af9ce7b":"data.Ticket","52d49249":"# Creating a list [code, number]\ndata.Ticket = data.Ticket.str.split() \n# Creating a new column that will save the ticket code if ther is no code we will put \"number\"\ndata[\"TicketCod\"] = data.Ticket.apply(lambda x: x[0][:] if len(x) == 2 else \"number\") \n# Uniforming the codes\ndata[\"TicketCod\"] = data.TicketCod.str.replace(\".\", \"\")  \ndata[\"TicketCod\"] = data.TicketCod.str.replace(\"\/\", \"\")\ndata[\"TicketCod\"] = data.TicketCod.apply(lambda x: x.upper())\n# log\ndata[\"TicketCod\"].value_counts()","40b9d54a":"# Relation between the TicketCod and Survived Columns\naux = pd.crosstab(data['TicketCod'], data['Survived'])\naux","53a21143":"# Calculating the percentage of survivance according to the ticket code\naux =np.round(aux[1]\/(aux[0]+aux[1])*100,0)\naux","571032a8":"# We have many kind of ticket codes, we will save the aux Serie information in a dictionary, \n# we will use it to tranform the ticket codes to a number\naux = aux.to_dict()\n\n# We need to add some codes that don't have the Survived information, and acording to some similar codes\n# we are determining its numerical values\naux[\"SCA3\"] = 0.0  #<-- similar to SCA4\n# These have no relation with other codes so we are going to treat them as they have no code (NUMBER group) \naux[\"LP\"] = 38.0\naux[\"AQ3\"] = 38.0\naux[\"AQ4\"] = 38.0\naux[\"STONOQ\"] = 13.0  #<-- similar to SOTONOQ","61bf76ef":"# Transforming the codes to their respective number\ndata['TicketCod'] = data['TicketCod'].apply(lambda x: aux[x])\n# Creating another column that will save the ticket number\ndata[\"TicketNum\"] = data.Ticket.apply(lambda x : 0 if x[-1][:] == 'LINE' else x[:][-1])\ndata[\"TicketNum\"] = data.TicketNum.values.astype('int64')\n# Deleting the old Ticket column\ndata.drop([\"Ticket\"], axis = 1, inplace = True)","2d55a49a":"# New data\ndata.head()","a34c964e":"data.isna().sum()","5fba7ee1":"data.corr()","37e9a793":"# The Age of the empty cells will be the mean of the ages inside the gruop of (Pclass, Upclass and Lpclass)\ndata.groupby([\"SibSp\",\"Upclass\", \"Lpclass\"])[\"Age\"].median()","8b7e9f60":"data[\"Age\"].fillna(data.groupby([\"SibSp\",\"Upclass\",\"Lpclass\"])[\"Age\"].transform(\"median\"), inplace=True)\n#data[\"Age\"].fillna(data[\"Age\"].median(), inplace = True)\ndata[\"Age\"] = data[\"Age\"].transform(lambda x: int(round(x,0)))","a1dbfba8":"# The Fare of the empty cells will be the mean of the ages inside the gruop of (Upclass, and TickedCod)\ndata.groupby([\"Upclass\", \"TicketCod\"])[\"Fare\"].median()","c4de41ba":"data[\"Fare\"].fillna(data.groupby([\"TicketCod\", \"TicketCod\"])[\"Fare\"].transform(\"median\"), inplace=True)\n#data[\"Fare\"].fillna(data[\"Fare\"].median(), inplace = True)\ndata[\"Fare\"] = data[\"Fare\"].transform(lambda x: round(x,4))","ca5291e1":"# Results:\ndata.isna().sum()","64a37ffc":"data.head(5)","51958a9b":"data.drop(\"Survived\", axis = 1, inplace = True)\ndata_stats = data.describe()\ndata_stats = data_stats.transpose()","48c90109":"def norm(x):\n  return (x - data_stats['mean']) \/ data_stats['std']\nnormed_data = norm(data)","11aa01a9":"normed_data.info()","267e3d8f":"# Final preprocessed data\nnormed_data.head()","8960f9a7":"ex_data = normed_data.loc[train.index]\nfeatures = list(ex_data.columns) \n\nprint(f'The inputs features are:\\n {features}')\n\"\"\"\nout_train: Outputs of the training data\nin_train: Inputs of the training data\n\"\"\"\nex_data_outputs = train[\"Survived\"].values   # We are using the train data because there the Survived column has int type\nex_data_inputs = ex_data[features].values \n\nprint(f'\\nData of the person with id = 1\\n{ex_data_inputs[0]}')\nprint(f'The have the person suvived?\\n {ex_data_outputs[0]}')\nprint(f'\\nInput shape: {ex_data_inputs.shape}')\nprint(f'Output shape: {ex_data_outputs.shape}')\n","a30b4302":"ex_train_inputs = ex_data_inputs[:710,:]\nex_train_outputs = ex_data_outputs[:710]\nex_test_inputs = ex_data_inputs[710:,:]\nex_test_outputs = ex_data_outputs[710:]\nprint(f'train input shape: {ex_train_inputs.shape}')\nprint(f'train output shape: {ex_train_outputs.shape}')\nprint(f'test input shape: {ex_test_inputs.shape}')\nprint(f'test output shape: {ex_test_outputs.shape}')","c4a12d48":"from tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense\n\ninputs = Input(shape = ex_train_inputs.shape[1])\nx = Dense(128, activation = \"relu\")(inputs)\nx = Dense(128, activation = \"relu\")(x)\noutputs = Dense(1, activation = \"sigmoid\")(x)\nexp_model = Model(inputs = inputs, outputs = outputs)\n\nexp_model.compile(optimizer = \"Adamax\",\n            loss = \"binary_crossentropy\",\n            metrics = [\"accuracy\"])\n\nexp_model.fit(ex_train_inputs, ex_train_outputs, epochs = 100)\nprint(\"Training Performance:\")\ntrain_loss, train_acc = exp_model.evaluate(ex_train_inputs, ex_train_outputs, verbose = 2)\nprint(\"Testing Performance:\")\ntest_loss, test_acc = exp_model.evaluate(ex_test_inputs, ex_test_outputs, verbose = 2)","f835515c":"train_set, test_set = normed_data.loc[train.index], normed_data.loc[test.index]\nfeatures = list(train_set.columns) \n\n\"\"\"\nout_train: Outputs of the training data\nin_train: Inputs of the training data\n\"\"\"\ntrain_outputs = train[\"Survived\"].values\ntrain_inputs = train_set[features].values\ntest_inputs = test_set[features].values\n\nprint(f'Input Training Shape: {train_inputs.shape}')\nprint(f'Output training Shape: {train_outputs.shape}')\nprint(f'Input Test Shape: {test_inputs.shape}')","3aadcff4":"from tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense\n\ninputs = Input(shape = train_inputs.shape[1])\nx = Dense(128, activation = \"relu\")(inputs)\nx = Dense(128, activation = \"relu\")(x)\noutputs = Dense(1, activation = \"sigmoid\")(x)\nmodel = Model(inputs = inputs, outputs = outputs)\n\nmodel.compile(optimizer = \"Adamax\",\n            loss = \"binary_crossentropy\",\n            metrics = [\"accuracy\"])\n\nmodel.fit(train_inputs, train_outputs, epochs = 100)\nprint(\"Training Performance:\")\ntrain_loss, train_acc = model.evaluate(train_inputs, train_outputs, verbose = 2)","681dbf4d":"# Making the predictions for the test data\npredictions = np.round(model.predict(test_inputs).reshape((418)),0)\npredictions = list(map(int, predictions))\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","12bd9b77":"## Filling the empty cells\nThe empty cells belongs to columns: Age, Fare. We wil use the correlation information to fill those cells.\n","cffb72b0":"## Normalizing the data","a68d90fd":"## Converting the categorical data to numerical: Pclass, Sex, Embarked, Ticket ","a5d094d8":"### Observations: Cabin, Age, Fare\n* The Cabin column has 327 empty values.\n* The Age column has 86 empty values.\n* The Fare column has 1 empty values.","5a1508f3":"# TITANIC PROBLEM","69a515d7":"# Training the model with the whole training data","cb179fe6":"### Processing Ticket Column","fec1a4ad":"### Observations: Cabin, Age, Embarked\n* The Cabin column has 687 empty values (We will delete it, because is to many lost information).\n* The Age column has 177 empty values (We will find some correlation wit other columns to fill those empty cells)\n* The Embarked column has 2 empty values (We will find some correlation wit other columns to fill those empty cells)","feed1c2c":"# Analyzing the raw imput data\n## Description:\n* PassengerId\n* Survival: 0 = No, 1 = Si\n* Pclass: (ticket class) 1 = Upper, 2 = Middle, 3 = lower\n* Name\n* Sex: female, male\n* Age\n* Sibsp: number of siblings \/ spouses aboard the Titanic\n* Parch: number of parent \/ childern aboard the Titanic\n* Ticket: ticket number\n* Fare: Passenger fare\n* Cabin: cabin number\n* Embarked: (port of embarkation) C = Cherbourg, Q = Queenstown, S = Southampton","399a108a":"Acording to the following table:\n* Age has a higher correlation with SibSp, Upclass and Lpclass\n* Fare has a higher correlation with Upclass and TickedCod","76fe3c5d":"### Observations:\nWe have thre columns (Name, Tieckt, Cabin) that are strings:\n* The Cabin column will be delate, because there are to many missing values.\n* The Name column will delate, because that information does not gives more details that we can get from the other columns.\n* The Ticket column gives us other kind of information that is important, so we will process it and convert it to a number type column.","0807e14b":"## Tunning The model (MLP)\nWe will make some experiments to set up the hyperparameters of the neural network, so we need to both a training set and a validatin data set,for that we will split the trainig data."}}