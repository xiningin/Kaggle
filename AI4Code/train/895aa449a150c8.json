{"cell_type":{"01e9debc":"code","9545007a":"code","dc8748e6":"code","fe77fd53":"code","e4e05d60":"code","00adf7af":"code","681e34c5":"code","6fce3bbb":"code","d3f9b2ac":"code","625efa45":"code","cf6f5266":"code","f20f3819":"code","4c90a7b5":"code","e2c3a72b":"code","3d379933":"code","af00ada2":"code","082acd3b":"code","a21c5549":"code","e962473a":"code","7fca2c28":"code","b6cd6304":"code","36ea8b53":"code","ba96419e":"code","54cca6fa":"code","3eb0f623":"markdown","e9ab4066":"markdown","80455f96":"markdown","0adf35e7":"markdown","9eedf423":"markdown","4aaf0f8d":"markdown","57cf85b0":"markdown","5cc5e414":"markdown","82769f0f":"markdown","65b9c1cc":"markdown","0e95c577":"markdown","6a398c39":"markdown","d8313722":"markdown"},"source":{"01e9debc":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport tensorflow as tf\nimport keras\nimport keras.layers as L\nimport math\nfrom keras.utils import Sequence\nfrom keras.preprocessing import image\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split","9545007a":"train_labels = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\nsample_submission = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')","dc8748e6":"train_labels.head()","fe77fd53":"sns.countplot(x='target',data=train_labels,palette='Set2')","e4e05d60":"path = list(train_labels['id'])\nfor i in range(len(path)):\n    path[i] = '..\/input\/g2net-gravitational-wave-detection\/train\/' +path[i][0]+'\/'+path[i][1]+'\/'+path[i][2]+'\/' + path[i] + '.npy'","00adf7af":"def id2path(idx,is_train=True):\n    path = '..\/input\/g2net-gravitational-wave-detection'\n    if is_train:\n        path += '\/train\/'+idx[0]+'\/'+idx[1]+'\/'+idx[2]+'\/'+idx+'.npy'\n    else:\n        path += '\/test\/'+idx[0]+'\/'+idx[1]+'\/'+idx[2]+'\/'+idx+'.npy'\n    return path","681e34c5":"!pip install -q nnAudio","6fce3bbb":"import torch\nfrom nnAudio.Spectrogram import CQT1992v2\ndef increase_dimension(idx,is_train,transform=CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=64)): # in order to use efficientnet we need 3 dimension images\n    waves = np.load(id2path(idx,is_train))\n    waves = np.hstack(waves)\n    waves = waves \/ np.max(waves)\n    waves = torch.from_numpy(waves).float()\n    image = transform(waves)\n    image = np.array(image)\n    image = np.transpose(image,(1,2,0))\n    return image","d3f9b2ac":"example = np.load(path[0])","625efa45":"fig,a =  plt.subplots(3,1)\na[0].plot(example[1],color='green')\na[1].plot(example[1],color='red')\na[2].plot(example[1],color='yellow')\nfig.suptitle('Target 1', fontsize=16)\nplt.show()\nplt.imshow(increase_dimension(train_labels['id'][0],is_train=True))\nplt.show()","cf6f5266":"example = np.load(path[1])\nfig,a =  plt.subplots(3,1)\na[0].plot(example[1],color='green')\na[1].plot(example[1],color='red')\na[2].plot(example[1],color='yellow')\nfig.suptitle('Target 0', fontsize=16)\nplt.show()\nplt.imshow(increase_dimension(train_labels['id'][1],is_train=True))\nplt.show()","f20f3819":"example = np.load(path[4])\nfig,a =  plt.subplots(3,1)\na[0].plot(example[1],color='green')\na[1].plot(example[1],color='red')\na[2].plot(example[1],color='yellow')\nfig.suptitle('Target 1', fontsize=16)\nplt.show()\nplt.imshow(increase_dimension(train_labels['id'][4],is_train=True))\nplt.show()","4c90a7b5":"example = np.load(path[2])\nfig,a =  plt.subplots(3,1)\na[0].plot(example[1],color='green')\na[1].plot(example[1],color='red')\na[2].plot(example[1],color='yellow')\nfig.suptitle('Target 0', fontsize=16)\nplt.show()\nplt.imshow(increase_dimension(train_labels['id'][2],is_train=True))\nplt.show()","e2c3a72b":"class Dataset(Sequence):\n    def __init__(self,idx,y=None,batch_size=256,shuffle=True):\n        self.idx = idx\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        if y is not None:\n            self.is_train=True\n        else:\n            self.is_train=False\n        self.y = y\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n    def __getitem__(self,ids):\n        batch_ids = self.idx[ids * self.batch_size:(ids + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x = np.array([increase_dimension(x,self.is_train) for x in batch_ids])\n        batch_X = np.stack(list_x)\n        if self.is_train:\n            return batch_X, batch_y\n        else:\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","3d379933":"train_idx =  train_labels['id'].values\ny = train_labels['target'].values\ntest_idx = sample_submission['id'].values","af00ada2":"x_train,x_valid,y_train,y_valid = train_test_split(train_idx,y,test_size=0.05,random_state=42,stratify=y)","082acd3b":"train_dataset = Dataset(x_train,y_train)\nvalid_dataset = Dataset(x_valid,y_valid)\ntest_dataset = Dataset(test_idx)","a21c5549":"!pip install -U efficientnet","e962473a":"import efficientnet.keras as efn","7fca2c28":"model = tf.keras.Sequential([L.InputLayer(input_shape=(69,193,1)),L.Conv2D(3,3,activation='relu',padding='same'),efn.EfficientNetB0(include_top=False,input_shape=(),weights='imagenet'),\n        L.GlobalAveragePooling2D(),\n        L.Dense(32,activation='relu'),\n        L.Dense(1, activation='sigmoid')])\n\nmodel.summary()\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n              loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n","b6cd6304":"model.fit(train_dataset,epochs=2,validation_data=valid_dataset)","36ea8b53":"preds = model.predict(test_dataset)\npreds = preds.reshape(-1)","ba96419e":"submission = pd.DataFrame({'id':sample_submission['id'],'target':preds})","54cca6fa":"submission.to_csv('submission.csv',index=False)","3eb0f623":"# Model","e9ab4066":"<img src=\"https:\/\/media.wired.com\/photos\/5c6c53bc0135c22d73b8ccd4\/master\/pass\/ligo.jpg\">","80455f96":"# Train Dataset","0adf35e7":"Since efficient net requires image shape to be at least 32X32 I am first using a Conv layer to increase channels to 6 then using reshape to increase image size if someone has a better way then please suggest","9eedf423":"I am using spectrogram images generated by @yasufuminakama which can be found here for <a href=\"https:\/\/www.kaggle.com\/yasufuminakama\/g2net-spectrogram-generation-train\">train<\/a> and here for <a href=\"https:\/\/www.kaggle.com\/yasufuminakama\/g2net-spectrogram-generation-test\">test<\/a>","4aaf0f8d":"<h2><center>If you found this notebook useful please upvote<\/center><\/h2>","57cf85b0":"# About the Competition\ud83d\udea9\n<p style=\"font-size:15px\">It's been said that teamwork makes the dream work. This couldn't be truer for the breakthrough discovery of gravitational waves (GW), signals from colliding binary black holes in 2015. It required the collaboration of experts in physics, mathematics, information science, and computing. GW signals have led researchers to observe a new population of massive, stellar-origin black holes, to unlock the mysteries of neutron star mergers, and to measure the expansion of the Universe. These signals are unimaginably tiny ripples in the fabric of space-time and even though the global network of GW detectors are some of the most sensitive instruments on the planet, the signals are buried in detector noise. Analysis of GW data and the detection of these signals is a crucial mission for the growing global network of increasingly sensitive GW detectors. These challenges in data analysis and noise characterization could be solved with the help of data science.\n<\/p><p>\nIn this competition, you\u2019ll aim to detect GW signals from the mergers of binary black holes. Specifically, you'll build a model to analyze simulated GW time-series data from a network of Earth-based detectors.\n<\/p><p>\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n<\/p>","5cc5e414":"# Data Description","82769f0f":"<h2><center>Work in Progress ... \u23f3<\/center><\/h2>","65b9c1cc":"Lets take a look at train_labels","0e95c577":"# EDA","6a398c39":"<div style=\"font-size:15px\">\n We are given 2 npy files and 2 csv files:-\n<ul>\n    <li><code>train:<\/code> the training set files, one npy file per observation; labels are provided in a files shown below\n<\/li>\n    <li><code>test:<\/code> the test set files; you must predict the probability that the observation contains a gravitational wave<\/li>\n    <li><code>training_labels.csv:<\/code> target values of whether the associated signal contains a gravitational wave<\/li>\n    <li><code>sample_submission.csv:<\/code> a sample submission file in the correct format\n<\/li>\n<\/ul>    \n<\/div>","d8313722":"lets take a look at example file"}}