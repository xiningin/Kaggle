{"cell_type":{"eb7dc374":"code","a666e521":"code","788214ee":"code","bdca910c":"code","b96a890f":"code","90bdbae3":"code","5f351790":"code","f02347dc":"code","83f176c8":"code","107243b8":"code","4a90c682":"code","979ace6d":"markdown","64cf4d6c":"markdown","6081d8eb":"markdown","c5f51b5f":"markdown","5ab6912f":"markdown","62e6f2f8":"markdown","4d43cace":"markdown","da385be6":"markdown","3f4378f9":"markdown","6ca7f74f":"markdown","42ce7781":"markdown"},"source":{"eb7dc374":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom glob import glob\nfrom PIL import Image\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport cv2\nimport fnmatch\nimport keras\nfrom time import sleep\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten,BatchNormalization,MaxPooling2D,Activation\nfrom keras.optimizers import RMSprop,Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras import backend as k","a666e521":"df = pd.read_csv('..\/input\/train.csv')\ny_train = np.array(df['label'])\nx_train = np.array(df.drop(['label'], axis=1))\nx_train = x_train.reshape(42000, 28, 28, 1)","788214ee":"df = pd.read_csv('..\/input\/test.csv')\nx_check = np.array(df)\nx_check = x_check.reshape(28000, 28, 28, 1)","bdca910c":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 101)\ny_train = to_categorical(y_train, num_classes = 10)\ny_test = to_categorical(y_test, num_classes = 10)","b96a890f":"import keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.applications.vgg16 import VGG16\ndef base_model(x):\n    BATCH_NORM = x\n    model = Sequential()\n\n    model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:], name='block1_conv1'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(64, (3, 3), padding='same', name='block1_conv2'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n\n    model.add(Conv2D(128, (3, 3), padding='same', name='block2_conv1'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(128, (3, 3), padding='same', name='block2_conv2'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n\n    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv1'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv2'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv3'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv4'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv1'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv2'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv3'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv4'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv1'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv2'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv3'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv4'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n\n    model.add(Flatten())\n\n    model.add(Dense(4096))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(4096, name='fc2'))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(10))\n    model.add(BatchNormalization()) if BATCH_NORM else None\n    model.add(Activation('softmax'))\n\n    model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n    return model\n#model.summary()\ncnn = base_model(1)","90bdbae3":"cnn.load_weights('model_check_path_2.hdf5')","5f351790":"from sklearn.metrics import classification_report\npred = cnn.predict(x_test)\nprint(classification_report(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1)))","f02347dc":"prediction = cnn.predict(x_check)","83f176c8":"pred_sub = []\nfor i in range(len(prediction)):\n    pred_sub.append(prediction[i].argmax())\npred_sub = np.array(pred_sub)\npred_sub.shape","107243b8":"submission = pd.DataFrame()\nsubmission['ImageId']=np.array([i+1 for i in range(len(pred_sub))])\nsubmission['Label']=pred_sub\nsubmission","4a90c682":"submission.to_csv('submission.csv')","979ace6d":"model.load_weights('model_check_path.hdf5')","64cf4d6c":"for i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.imshow(x_check[i].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"{}\".format(prediction[i].argmax()))","6081d8eb":"from keras.callbacks import ModelCheckpoint\nmcp = ModelCheckpoint(filepath='model_check_path.hdf5',monitor=\"val_acc\", save_best_only=True, save_weights_only=False)\nhist = model.fit(x_train,y_train,batch_size = 32, epochs = 100, verbose=1,  validation_split=0.2, callbacks=[mcp])","c5f51b5f":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.grid(b=False)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","5ab6912f":"\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1))\nplot_confusion_matrix(cm = cm,\n                      normalize    = False,\n                      cmap ='Reds',\n                      target_names = ['0','1', '2','3', '4', '5', '6', '7', '8', '9'],\n                      title        = \"Confusion Matrix\")","62e6f2f8":"from keras.callbacks import ModelCheckpoint\nmcp = ModelCheckpoint(filepath='model_check_path_2.hdf5',monitor=\"val_acc\", save_best_only=True, save_weights_only=False)\nhist = model.fit(x_train,y_train,batch_size = 32, epochs = 50, verbose=1,  validation_split=0.2, callbacks=[mcp])","4d43cace":"from keras.callbacks import ModelCheckpoint\nmcp = ModelCheckpoint(filepath='model_check_path_2.hdf5',monitor=\"val_acc\", save_best_only=True, save_weights_only=False)\nhist = cnn.fit(x_train,y_train,batch_size = 32, epochs = 60, verbose=1,  validation_split=0.2, callbacks=[mcp])","da385be6":"import keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU \nmodel = Sequential()\nmodel.add(Conv2D(32,(7,7),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(Conv2D(64,(5,5),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.15))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(1000, activation='relu'))\nmodel.add(Dense(10,activation='softmax'))\nmodel.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n#model.summary()","3f4378f9":"fig = plt.figure()\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=False)\nax.plot(hist.history['loss'], color='red')\nax.plot(hist.history['val_loss'], color ='green')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","6ca7f74f":"fig = plt.figure()\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=False)\nax.plot(hist.history['acc'], color='red')\nax.plot(hist.history['val_acc'], color ='green')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()","42ce7781":"import keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nmodel = Sequential()\nmodel.add(Conv2D(32,(7,7),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.15))\nmodel.add(Conv2D(64,(5,5),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.15))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.15))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.15))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(1000, activation='relu'))\nmodel.add(Dense(10,activation='softmax'))\nmodel.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n#model.summary()\n"}}