{"cell_type":{"7bc6292c":"code","21066cb8":"code","f54d03b5":"code","8df1c270":"code","1b2d4f75":"code","cd930cba":"code","568d33ba":"code","dceb082f":"code","e0479d2e":"code","eb92c59e":"code","9f94ef53":"code","7815e4a6":"code","d16976c1":"code","f4dc24ee":"code","dbc47593":"code","1f63855b":"code","7fb09edc":"code","6fa8d9b8":"code","d0ac9436":"code","5bba8cda":"code","601a462c":"code","2a6c3248":"code","c07e5acf":"code","ed2259f0":"code","1b8ddc58":"code","88035698":"code","0d4a1fae":"code","1ce2b77b":"code","7607e50c":"code","15a7e50c":"code","e74b4993":"code","237b1747":"code","2d375307":"code","16e26577":"code","8d184163":"code","f53ee8e8":"code","92d5f115":"code","0bf22c74":"code","25935303":"code","7c45f69d":"code","c44f5f77":"code","c25558fa":"code","854dbe57":"code","b8a57f35":"code","840f240a":"code","fb3f3c35":"code","9dd4fc60":"code","929f5007":"code","98ddbd8b":"code","fe42ba59":"code","c3f0558f":"code","37b40d8a":"code","4000b58d":"code","114472ae":"code","e2544fb4":"code","86e7c358":"code","29ac4361":"code","f6e5afc3":"code","a71bb5ee":"code","38ce6dc2":"code","5c83d2e1":"code","ba3ad767":"code","d36e67d5":"code","9986d5e0":"code","6004e45f":"markdown","255626dd":"markdown","aa5e3853":"markdown","7429351a":"markdown","f0e701c1":"markdown","4b0fc921":"markdown","a95ce7ff":"markdown","18d91a1d":"markdown","c69630a0":"markdown","8396285c":"markdown","702ba92c":"markdown","d73fa6ad":"markdown","e664947a":"markdown","9422a354":"markdown","7c05c345":"markdown","1ca1f6c0":"markdown","3250f3b6":"markdown","5bd70588":"markdown","35442e6a":"markdown","93c5b27a":"markdown","594142ad":"markdown","6fbd3932":"markdown","99863797":"markdown","44c37503":"markdown","86445e54":"markdown","d2749b70":"markdown","ae3f46ba":"markdown","e71e079d":"markdown","4c3f9739":"markdown","191adfa4":"markdown","914220e4":"markdown"},"source":{"7bc6292c":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","21066cb8":"%matplotlib inline\nimport os\nimport numpy as np\nfrom sklearn.tree import DecisionTreeRegressor\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn import preprocessing\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor, plot_importance\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom math import sqrt\nimport math as mh","f54d03b5":"df =pd.read_csv(\"\/kaggle\/input\/restaurant-revenue-prediction\/train.csv.zip\",sep=',')\ndf.shape","8df1c270":"df_test=pd.read_csv(\"\/kaggle\/input\/restaurant-revenue-prediction\/test.csv.zip\",sep=',')\ndf_test.shape","1b2d4f75":"numerical_features = df.select_dtypes([np.number]).columns.tolist()\ncategorical_features = df.select_dtypes(exclude = [np.number,np.datetime64]).columns.tolist()\nprint(categorical_features)\ncategorical_features=['City', 'City Group', 'Type']\nprint(categorical_features)\nprint(numerical_features)","cd930cba":"df.head()","568d33ba":"df.tail()","dceb082f":"df.columns","e0479d2e":"df.info()","eb92c59e":"df.describe","9f94ef53":"df_test.head()","7815e4a6":"df_test.info()","d16976c1":"df_test.columns","f4dc24ee":"df2=df.copy()","dbc47593":"# V\u00e9rifier les valeurs nulles.\ndf.isnull().sum().sum()","1f63855b":"df.isnull().sum().sort_index()\/len(df)","7fb09edc":"fig, ax = plt.subplots(1,2, figsize=(19, 5))\ng1 = sns.countplot(df['Type'],palette=\"Set2\", ax=ax[0]);\ng2 = sns.countplot(df_test['Type'],palette=\"Set2\", ax=ax[1]);\nfig.show()","6fa8d9b8":"(df['City'].nunique(), df_test['City'].nunique())","d0ac9436":"df_test.loc[df_test['Type']=='MB', 'Type'] = 'DT'","5bba8cda":"df[df['revenue'] > 10000000 ]","601a462c":"# Drop outliers\ndf = df[df['revenue'] < 10000000 ]\ndf.reset_index(drop=True).head()","2a6c3248":"df[\"City\"].value_counts()","c07e5acf":"plt.subplots(figsize=(30,10))\ncity_revenue_group = df[\"City\"].value_counts()\nx_axis = city_revenue_group.index\ny_axis = city_revenue_group\nplt.bar(x_axis,y_axis)\nplt.xlabel(\"Ville\")\nplt.ylabel(\"Nombre De restaurants\")\nplt.show()","ed2259f0":"# La cible\ny= df['revenue']","1b8ddc58":"y.describe()","88035698":"# les caracteristiques les plus correlees avec revenue\nplt.figure(figsize=(10, 8))\nsns.heatmap(df.drop(['revenue','City Group','Type'], axis=1).corr(), square=True)\nplt.suptitle('Pearson Correlation Heatmap')\nplt.show();","0d4a1fae":"corr_with_revenue = df.drop(['City Group','Type'],axis=1).corr()['revenue'].sort_values(ascending=False)\nplt.figure(figsize=(10,7))\ncorr_with_revenue.drop('revenue').plot.bar()\nplt.show();","1ce2b77b":"df[\"Type\"].value_counts()","7607e50c":"plt.subplots(figsize=(30,10))\nres_type = df[\"Type\"].value_counts()\nx_axis = res_type.index\ny_axis =res_type\nplt.bar(x_axis,y_axis)\nplt.xlabel(\"Type de Restaurant\")\nplt.ylabel(\"Nombre\")\nplt.show()","15a7e50c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn import cluster\nrelevant_pvars =  [\"P1\", \"P2\", \"P11\", \"P19\", \"P20\", \"P23\",\"P30\"]\ntrain = df.loc[:, relevant_pvars]\nkmeans = cluster.KMeans(n_clusters=5)\nkmeans.fit(train)  \n","e74b4993":"from sklearn.neighbors import NearestNeighbors\nnbrs = NearestNeighbors(n_neighbors=3).fit(train)\ndistances, indices = nbrs.kneighbors(train)\ndistanceDec = sorted(distances[:,3-1], reverse=False)\nplt.plot(indices[:,0], distanceDec)\nplt.xlabel('Points sorted according to distance of 3th nearest neighbor')\nplt.ylabel('3th Nearest Neighbor Distance')\nplt.show()","237b1747":"plt.axhline(3)\nplt.plot(indices[:,0], distanceDec)\nplt.xlabel('Points sorted according to distance of 3th nearest neighbor')\nplt.ylabel('3th Nearest Neighbor Distance')\nplt.show()","2d375307":"from sklearn.cluster import DBSCAN\ndbscan=DBSCAN(eps=3, min_samples=20)\ndbscan.fit(train)","16e26577":"labels=dbscan.labels_","8d184163":"#points extr\u00eames dont labels == -1\ndf[labels==-1]","f53ee8e8":"#Shape des donn\u00e9es repr\u00e9sentant des valeurs extremes\ndf[labels==-1].shape","92d5f115":"from sklearn.manifold import TSNE","0bf22c74":"model = TSNE(learning_rate=10)\ntsne_features = model.fit_transform(train)\nxs = tsne_features[:,0]\nys = tsne_features[:,1]\nplt.scatter(xs,ys, c=y)\nplt.show()\nplt.clf()","25935303":"df_train=df.copy()\ndf_train=df_train.drop('revenue', axis=1)\ndf_full = pd.concat([df_train,df_test])\ndf_full = df_full.drop('City', axis=1)\np_name = ['P'+str(i) for i in range(1,38)]","7c45f69d":"from sklearn.decomposition import PCA\npca = PCA().fit(df_full[p_name])\npca_list = ['pca'+str(i) for i in range(1,30,1)]\ndf_full[pca_list] = PCA(n_components=29).fit_transform(df_full[p_name])\ndf_full.drop(p_name,axis=1,inplace=True)","c44f5f77":"df3=pd.get_dummies(df_full, dtype=float)","c25558fa":"corr_with_target = df.corr()['revenue'].sort_values(ascending=False)\nplt.figure(figsize=(14,7))\ncorr_with_target.drop('revenue').plot.bar()\nplt.show()","854dbe57":"import seaborn as sns\nstr_list = [] # liste vide pour contenir les colonnes avec les mots \nfor colname, colvalue in df.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)\n            \nnum_list = df.columns.difference(str_list) \n\ndf_num = df[num_list]\nf, ax = plt.subplots(figsize=(30, 20))\nplt.title('Pearson Correlation of features')\n# dessiner heatmap en utilisant seaborn\nsns.heatmap(df_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)","b8a57f35":"coor_pos= corr_with_target[corr_with_target>0]\ncoor_neg= corr_with_target[corr_with_target<0]","840f240a":"coor_pos","fb3f3c35":"coor_neg","9dd4fc60":"# on va cr\u00e9er une nouvel attribut appel\u00e9 \"Age\" qui signifie depuis combien de temps le restaurant est-il ouvert.\nfrom datetime import date, datetime\n\ndef calculate_age(born):\n        born = datetime.strptime(born, \"%m\/%d\/%Y\").date()\n        today = date.today()\n        return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n\ndf['Age'] = df['Open Date'].apply(calculate_age)\ndf_test['Age'] = df_test['Open Date'].apply(calculate_age)\n\n\n# Drop 'Id' column from Dataframes\ndf = df.drop('Id', axis=1)\n\ndf.head()","929f5007":"fig, ax = plt.subplots(3, 1, figsize=(40, 30))\nfor variable, subplot in zip(categorical_features, ax.flatten()):\n    df_2 = df[[variable,'revenue']].groupby(variable).revenue.sum().reset_index()\n    df_2.columns = [variable,'total_revenue']\n    sns.barplot(x=variable, y='total_revenue', data=df_2 , ax=subplot)\n    subplot.set_xlabel(variable,fontsize=20)\n    subplot.set_ylabel('Total Revenue',fontsize=20)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(45)\n        label.set_size(20)\n    for label in subplot.get_yticklabels():\n        label.set_size(20)\nfig.tight_layout()","98ddbd8b":"#on va passer vers des valeurs discr\u00e8tes qui repr\u00e9sentent Open Date City, City Group, Type\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(df['Open Date'])\ndf['Open Date']=le.fit_transform(df['Open Date'])\nle.fit(df['City'])\ndf['City']=le.fit_transform(df['City'])\nle.fit(df['City Group'])\ndf['City Group']=le.fit_transform(df['City Group'])\nle.fit(df['Type'])\ndf['Type']=le.fit_transform(df['Type'])","fe42ba59":"#Divison des donn\u00e9es en train et test\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=324)\n#liste pour stocker les rmse\nrmsee=[]","c3f0558f":"from sklearn.linear_model import LogisticRegression\nregressor = LogisticRegression()\nregressor.fit(X_train, y_train)\ny_prediction = regressor.predict(X_test)\nRMSE_lr = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\nprint(RMSE_lr)\nrmsee.append(RMSE_lr)","37b40d8a":"from sklearn.ensemble import VotingRegressor","4000b58d":"randomforest = RandomForestRegressor()\nrandomforest.fit(X_train, y_train)\ny_prede = randomforest.predict(X_test)\nRMSE_RF = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prede))\nprint(RMSE_RF)\nrmsee.append(RMSE_RF)\n","114472ae":"from sklearn.ensemble import AdaBoostRegressor\nada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=30), learning_rate=0.5, random_state=42)\nada_reg.fit(X_train, y_train)\ny_pred = ada_reg.predict(X_test)\nRMSE_AD = sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred))\nprint(RMSE_AD)\nrmsee.append(RMSE_AD)","e2544fb4":"import xgboost\nxgb_reg = xgboost.XGBRegressor()\nxgb_reg.fit(X_train, y_train)\ny_pred = xgb_reg.predict(X_test)\n\nRMSE_XG=sqrt(mean_squared_error(y_test, y_pred))\n\nprint(RMSE_XG)\nrmsee.append(RMSE_XG)","86e7c358":"table1 = {'RMSE':rmsee,'Algorithmes':['Logistic regression','random forest','AdaBoost',\n                                               'XGBoost']}\ndf1 = pd.DataFrame.from_dict(table1, orient='index')\ndf1.transpose()","29ac4361":"best_estimators=[]","f6e5afc3":"from sklearn.model_selection import GridSearchCV","a71bb5ee":"## parameters\nparams = {\n    \"n_estimators\": [10, 30, 50, 100],\n    \"learning_rate\": [.01, 0.1, 0.5, 0.9, 0.95, 1],\n    \"random_state\" : [42]\n}\n\n## XGBoost Regressor\nAdaBoostR =   AdaBoostRegressor()\nAdaBoostR_grid = GridSearchCV(AdaBoostR, params, scoring='r2', cv=5, n_jobs=-1)\nAdaBoostR_grid.fit(X_train, y_train)\n\n## Output\nprint(\"Best parameters:  {}:\".format(AdaBoostR_grid.best_params_))\nprint(\"Best score: {}\".format(AdaBoostR_grid.best_score_))\n## Append to list\nbest_estimators.append([\"AdaBoostR\",AdaBoostR_grid.best_estimator_])","38ce6dc2":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n## pipeline\npipelines = []\n\nfor name,model in best_estimators:\n    pipeline = Pipeline([(\"Scaler\",StandardScaler()),\n                            (name,model)\n                        ])\n    pipelines.append([\"Scaled_\"+name,pipeline])","5c83d2e1":"numTrain=df.shape[0]\n\ntrain = df3[:numTrain]\ntest = df3[numTrain:]\n","ba3ad767":"best_model = Pipeline([(\"Scaler\",StandardScaler()),\n                                      (\"Votings\",VotingRegressor([\n                                                                  (\"AdaBoostR\", AdaBoostR_grid.best_estimator_)\n                                                                 ]))])\n## Fit the model \nbest_model = best_model.fit(train,y) # fit the model with all the train datase","d36e67d5":"d=best_model.predict(test)","9986d5e0":"my_submission = pd.DataFrame({'Id': df_test.index, 'Prediction': d})\nmy_submission.to_csv('submission.csv', index=False)","6004e45f":"<h3>2-<\/h3>","255626dd":"<h1>1.2 Features engineering<\/h1>","aa5e3853":"<h4>a. KNN<\/h4>","7429351a":"<h3>3- random foreset <\/h3>","f0e701c1":"<p>Le type MB sera remplac\u00e9 par le type DT dans l'ensemble de test car il n'est pas disponible dans notre ensemble d'entra\u00eenement. La fonctionnalit\u00e9 Ville est inutile car notre ensemble d'entra\u00eenement contient 34 villes uniques, mais l'ensemble de test contient 57 villes uniques.<\/p>","4b0fc921":"<h3>3 Utilisation des techniques indiquees<\/h3>","a95ce7ff":"<h3>5-XGBoost<\/h3>","18d91a1d":"<h4>a-la ville comportant le plus grand nombre de restuarants<\/h4>\n\n","c69630a0":"<p>Istanbul a Nombre maximum de restaurants = 50<\/p>","8396285c":"<p>Il existe principalement 2 caract\u00e9ristiques :\nCity Group\nType (Type de restaurant. FC\u00a0: Food Court, IL\u00a0: Inline, DT\u00a0: Drive Thru, MB\u00a0: Mobile)\nEt 37 Variables num\u00e9riques (discr\u00e8tes)\nP1 \u00e0 P37 <\/p>","702ba92c":"<h3>4. DBSCAN<\/h3>","d73fa6ad":"<h3>1-la r\u00e9gression logistique<\/h3>","e664947a":"<h3>2- la matrice de corr\u00e9lation<\/h3>","9422a354":"<h4>b- quelles sont les caracteristiques les plus correlees avec le cible<\/h4>","7c05c345":"<h1>1.3 Apprentissage du mod\u00e9le et r\u00e9gles des hyper-param\u00e8tres<\/h1>","1ca1f6c0":"<p>on a donc une ensemble de test de   100 000 resturants <\/p>","3250f3b6":"<p>Le type FC a tendance \u00e0 g\u00e9rer plus de revenue<\/p>","5bd70588":"<h3> 4-AdaBoost<\/h3>","35442e6a":"# 1-1 Analyse exploratoire et visualisation","93c5b27a":"<h3> 4-la date d'ouverture affecte la prediction finale<\/h3>","594142ad":"<h3>3- Kmeans<\/h3>","6fbd3932":"<h4>a. D\u00e9tection des valeurs manquantes<\/h4>","99863797":"<h4>c-Quelle type de restaurant est le plus pr\u00e9sent dans ce dataset ?<\/h4>","44c37503":"<p>p2 p28 p6 <\/p>","86445e54":"<h4>b- la transformation des donn\u00e9es<\/h4>","d2749b70":"<p>L'ensemble de donn\u00e9es est assez petit, il faut donc \u00e9viter les mod\u00e8les complexes avec de nombreux param\u00e8tres. L'utilisation d'un mod\u00e8le complexe pour cet ensemble de donn\u00e9es entra\u00eenera un surajustement du mod\u00e8le par rapport \u00e0 l'ensemble de donn\u00e9es. Des techniques de r\u00e9gularisation devront certainement \u00eatre utilis\u00e9es pour \u00e9viter la possibilit\u00e9 de surapprentissage.<\/p>","ae3f46ba":"<h3>5-le type de restaurant a tendance \u00e0 g\u00e9rer plus de revenue <\/h3>","e71e079d":"<h3> 1. Pretraitement des donnees<\/h3>","4c3f9739":"<h3>1-Visualisation de la correlation<\/h3>","191adfa4":"<h3>2-voting <\/h3>","914220e4":"<h3>5- t_SNE <\/h3>"}}