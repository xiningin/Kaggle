{"cell_type":{"426c9f1c":"code","dc30825b":"code","d2a1661f":"code","dcb8226d":"code","137c8c8d":"code","2f4be2fe":"code","1650ec38":"code","27d5fac5":"code","01b2e200":"code","5ac587d2":"code","47d8ca7b":"code","02af08a7":"code","5cf1e81f":"code","f9b6ee2e":"code","1cbae2f8":"markdown","58680906":"markdown"},"source":{"426c9f1c":"#Required Libraries\nimport numpy as np  \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics","dc30825b":"#Read dataset\ndata = pd.read_csv('\/kaggle\/input\/diabetes-dataset\/diabetes2.csv')\n","d2a1661f":"data.head()","dcb8226d":"data.Outcome.value_counts()","137c8c8d":"#Grab features and label from dataframe\nx = data[['Pregnancies','Glucose', 'BloodPressure', 'Age', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction']].values\ny = data['Outcome'].values\n\nprint(x.shape)\nprint(y.shape)","2f4be2fe":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)\nx_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size = 0.50, random_state = 42)\n\nprint(len(x_train))\nprint(len(x_test))\nprint(len(x_valid))","1650ec38":"class LogisticRegression:\n    \n    def __init__(self, l_rate=0.01, iterations=1000):  \n        self.l_rate = l_rate  \n        self.iterations = iterations \n        \n    def scale(self, x):  \n        x_scaled = x - np.mean(x, axis=0)\n        x_scaled = x_scaled \/ np.std(x_scaled, axis=0)\n        return x_scaled\n    \n    def fit(self, x, y):  \n        self.losses = []  \n        self.theta = np.zeros((1 + x.shape[1])) \n        n = x.shape[0]\n        \n        x = self.scale(x)  \n                \n        for i in range(self.iterations):\n            #Step1\n            y_pred = self.theta[0] + np.dot(x, self.theta[1:])\n            z = y_pred\n            #Step2\n            g_z =  1 \/ (1 + np.e**(-z))       \n            \n            #Step3\n            cost = (1\/n)*(-y * np.log(g_z) - (1 - y) * np.log(1 - g_z))\n            self.losses.append(cost) \n            \n            #Step4\n            d_theta1 = (1\/n) * np.dot(x.T, (g_z - y)) \n            d_theta0 = (1\/n) * np.sum(g_z - y)  \n            \n            #Step5\n            self.theta[1:] = self.theta[1:] - self.l_rate * d_theta1  \n            self.theta[0] = self.theta[0] - self.l_rate * d_theta0       \n        return self\n    \n    \n    def predict(self, x):  \n        x = self.scale(x)  \n       \n        y_pred = self.theta[0] + np.dot(x, self.theta[1:]) \n        z = y_pred\n        g_z = 1 \/ (1 + np.e**(-z))\n        return [1 if i > 0.4 else 0 for i in g_z] \n   ","27d5fac5":"model = LogisticRegression()\nmodel.fit(x_train, y_train)","01b2e200":"# print thetas\nprint(\"thetas= \", model.theta)","5ac587d2":"y_pred_train = model.predict(x_train)\ny_pred_valid = model.predict(x_valid)","47d8ca7b":"train_acc =  metrics.accuracy_score(y_train, y_pred_train)\nvalid_acc = metrics.accuracy_score(y_valid, y_pred_valid)  #Learning Algorithm hyper-parameters Tuning\n\nprint('Training Accuracy is : \\n', train_acc)\nprint('--------------------------------')\nprint('Validation Accuracy is : \\n', valid_acc)\nprint('--------------------------------')","02af08a7":"y_pred_test = model.predict(x_test)  \n\ntest_acc = metrics.accuracy_score(y_test, y_pred_test)  #Evaluate the learning algorithm performance\n\nprint('Testing Accuracy is : \\n', test_acc)\nprint('--------------------------------')","5cf1e81f":"#evaluation using cross validation\nnum_splits = 5\nkfold = StratifiedKFold(num_splits, shuffle= True, random_state = 1)\ntrain_accs, test_accs = [], []  #create empty lists to store accurcy values\nfor train_index, test_index in kfold.split(x, y):  #Generate indices to split data into training and test set.\n    x_train, x_test = x[train_index], x[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n  \n    model.fit(x_train, y_train)\n    y_pred_train = model.predict(x_train)\n    y_pred_test = model.predict(x_test)\n    \n    train_accs.append(metrics.accuracy_score(y_train, y_pred_train) * 100)\n    test_accs.append(metrics.accuracy_score(y_test, y_pred_test) * 100)\n","f9b6ee2e":"ave_train_acc = 0\nave_test_acc = 0\n\nprint(\"\\t\",\"Training_Acc\",\"\\t\",\"\\t\", \"Testing_Acc\")\n\nfor i in range(num_splits):\n    print(i,\"\\t\", train_accs[i],\"\\t\", test_accs[i])\n    \n    ave_train_acc+= train_accs[i]\/num_splits\n    ave_test_acc+= test_accs[i]\/num_splits\n    \nprint(\"Av\", \"\\t\", ave_train_acc,\"\\t\", ave_test_acc)","1cbae2f8":"![train%20valid%20test.png](attachment:train%20valid%20test.png)","58680906":"![crossvalid.png](attachment:crossvalid.png)\n\n\n![cv.png](attachment:cv.png)"}}