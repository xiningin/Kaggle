{"cell_type":{"02625f0c":"code","1a03c589":"code","1f2064df":"markdown","2b66c85e":"markdown"},"source":{"02625f0c":"\nimport pandas as pd \nimport numpy as np\n\ndef convert_to_bool(df, col_name):\n    df[col_name] = np.where(df[col_name] >= 0.5, True, False)       \n    \ndef convert_dataframe_to_bool(df, columns):        \n    bool_df = df.copy()\n    for col in columns:\n        convert_to_bool(bool_df, col)\n    return bool_df\n\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\naux_target_columns = ['sexual_explicit', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\nnum_identity = len(identity_columns)\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntrain.fillna(0, inplace = True)\ntrain = convert_dataframe_to_bool(train, ['target'] + identity_columns)\n\n\nweights = np.ones((len(train),))\n\n# Positive and negative examples get balanced weights in each part\n\n# These samples participate in the over all AUC term\nweights[train['target']]   =  1 \/ train['target'].sum()                \nweights[~train['target']]   =  1 \/ (~train['target']).sum()\nfor col in identity_columns:\n    hasIdentity = train[col]\n    # These samples participate in the subgroup AUC and BNSP terms    \n    weights[hasIdentity & train['target']]   +=  2 \/ (( hasIdentity &  train['target']).sum() * num_identity)\n    # These samples participate in the subgroup AUC and BPSN terms\n    weights[hasIdentity & ~train['target']]  +=  2 \/ (( hasIdentity & ~train['target']).sum() * num_identity)\n    # These samples participate in the BPSN term\n    weights[~hasIdentity & train['target']]  +=  1 \/ ((~hasIdentity &  train['target']).sum() * num_identity)\n    # These samples participate in the BNSP term\n    weights[~hasIdentity & ~train['target']] +=  1 \/ ((~hasIdentity & ~train['target']).sum() * num_identity)\n    \n    \n    \nweights = weights \/ weights.max()\n\n\ny_train = train['target'].values\ny_aux_train = train[aux_target_columns].values\ny_combined =  np.concatenate((y_train.reshape((-1, 1)), weights.reshape((-1, 1)), y_aux_train.reshape((-1, len(aux_target_columns)))), axis = 1)\n","1a03c589":"def custom_loss(data, targets):    \n    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:,1:2])(data[:,:1],targets[:,:1])\n    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:,1:],targets[:,2:])\n    return (bce_loss_1 * 1) + (bce_loss_2 * 1)","1f2064df":"### For loss weights, equal weights (both = 1) gave me the best results. ","2b66c85e":"# A loss function for the Jigsaw Unintended Bias in Toxicity Classification competition \n### (Public LB rank = 5)"}}