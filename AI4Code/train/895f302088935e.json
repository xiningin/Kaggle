{"cell_type":{"eda813ef":"code","b610457a":"code","5b6fcf15":"code","9210d58d":"code","1bc848c5":"code","c1f484f8":"code","ca150cdb":"code","1c79e14e":"code","8d2346a7":"code","ca5fd2b2":"code","4bc3a7ca":"code","062b6a32":"code","31cb6475":"code","e3657930":"code","3f5fc0b0":"code","538ea6ff":"code","4955a136":"code","29ff173d":"code","9f7dce15":"code","3ba67955":"code","65d5d2a0":"code","6813f499":"code","8354e55b":"code","cfe7f729":"code","65c39895":"code","06374f7f":"code","61eb1dda":"code","0698e344":"code","f18a16bf":"code","fd76232b":"code","a4fea68e":"code","0e8d0298":"code","e9a10db5":"code","c107bec4":"code","71d1e28e":"code","7978b897":"code","7febdb57":"code","26ce6efc":"code","558b4098":"code","424721ba":"markdown","2c147071":"markdown","90f6c32c":"markdown"},"source":{"eda813ef":"from __future__ import absolute_import, division, print_function, unicode_literals\n\n!pip install tensorflow==2.0.0-beta1\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","b610457a":"tf.executing_eagerly()","5b6fcf15":"import numpy as np\nimport pandas as pd\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image","9210d58d":"data_dir = '..\/input\/master\/P1_Facial_Keypoints-master\/data'\ntraining_dir = '..\/input\/master\/P1_Facial_Keypoints-master\/data\/training'\ntest_dir = '..\/input\/master\/P1_Facial_Keypoints-master\/data\/test'","1bc848c5":"label_frame = pd.read_csv(os.path.join(data_dir,'training_frames_keypoints.csv'), index_col='Unnamed: 0')\nlabel_frame.head()","c1f484f8":"test_label_frame = pd.read_csv(os.path.join(data_dir,'test_frames_keypoints.csv'), index_col='Unnamed: 0')\ntest_label_frame.head()","ca150cdb":"label_frame.shape","1c79e14e":"test_label_frame.shape","8d2346a7":"def get_img_paths(path):\n    file_path = os.listdir(path)\n    file_path_full = [os.path.join(training_dir, x) for x in file_path]\n    return file_path_full","ca5fd2b2":"training_img_paths = get_img_paths(training_dir)\nlen(training_img_paths)","4bc3a7ca":"test_img_paths = get_img_paths(test_dir)\nlen(test_img_paths)","062b6a32":"idx = list(test_label_frame.index)\nnew_paths = []\nfor x in test_img_paths:\n    y = os.path.basename(x)\n    if y in idx:\n        new_paths.append(x)\ntest_img_paths = np.array(new_paths)\ntest_img_paths.shape","31cb6475":"def get_labels(data_frame, img_paths=training_img_paths):\n    return np.array([data_frame.loc[os.path.basename(x)].values for x in img_paths])","e3657930":"training_labels = get_labels(label_frame, training_img_paths)\ntest_labels = get_labels(test_label_frame, test_img_paths)\nprint(training_labels.shape, test_labels.shape)\nprint(training_labels[0].shape)","3f5fc0b0":"input_size = 128","538ea6ff":"def _rotate_data(image, label):\n    angle = tf.random.uniform([1,1], minval=-45, maxval=45)\n    \n    image = Image.fromarray(np.array(tf.squeeze(image)))\n    image = Image.Image.rotate(image, angle)\n   \n    image = tf.convert_to_tensor(np.array(image))\n    image = tf.expand_dims(image, -1)\n    \n    rad = (22*angle)\/(7*180)\n    cos, sin = tf.math.cos(rad), tf.math.sin(rad)\n    rot_mat = np.array([[cos, -sin], [sin, cos]], dtype='float64')\n    rot_mat = tf.squeeze(rot_mat)\n    \n    label = tf.reshape(label, [-1,2])\n    \n    x0 = input_size\/2\n    label -= (x0, x0)\n    label = tf.matmul(label, rot_mat)\n    label += (x0, x0)\n    \n    label = tf.reshape(label, [-1])\n    \n    return image, label","4955a136":"def _preprocess_data(image, label):\n    \n    mfx = input_size \/ image.shape[0]\n    mfy = input_size \/ image.shape[1]\n\n    new_label = np.zeros(label.shape)\n    new_label[::2] = label[::2] * mfy\n    new_label[1::2] = label[1::2] * mfx\n    \n    image = tf.image.resize(image, [input_size, input_size])\n    image = tf.image.rgb_to_grayscale(image)\n#     return image, new_label\n    return _rotate_data(image, new_label)","29ff173d":"def _load_image(path):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    return image","9f7dce15":"def check_dataset(t=0, img_paths = training_img_paths,labels = training_labels):\n    img = _load_image(img_paths[t])\n    label = labels[t].copy()\n\n    img, label = _preprocess_data(img, label)\n    \n    img = tf.squeeze(img)\n    label = tf.reshape(label, [-1,2])\n    plt.figure()\n    plt.imshow(img, cmap='gray')\n    plt.scatter(label[:, 0], label[:, 1], s=20, marker='.', c='m')\n    plt.show()\n    \ncheck_dataset(100)","3ba67955":"check_dataset(0, test_img_paths, test_labels)","65d5d2a0":"from tensorflow import keras\nfrom tensorflow.keras import layers","6813f499":"!wget 'https:\/\/www.kaggleusercontent.com\/kf\/18233839\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..BfTDA0Blro9eIy1dl4UVpg.Mf_2a9Ij_7fgsZmhivYj44MDIngT7YaW9RLQT8HiFxnvJhX-YjJhhIWqH58godjcHtykW0G-lY81KLwHtVrDiAmqXjEdsnkmemwDPQz-ShMxCiDWR6mXBHOUGM-c1eFrmAQ1VYq0WHTWUNxGeeg0mEIuKCARsNRIQ6pcKxdLXgk.oSf8WyatV_djYgkKuSsyjw\/model8.h5'","8354e55b":"model1 = keras.models.load_model('model8.h5')","cfe7f729":"model1.summary()","65c39895":"keras.utils.plot_model(model1, 'model1.png')","06374f7f":"model1.compile(optimizer=tf.keras.optimizers.Adam() ,\n              loss='mae')","61eb1dda":"len(model1.trainable_variables)","0698e344":"BATCH_SIZE = 1024\nsteps_per_epoch=tf.math.ceil(BATCH_SIZE\/32).numpy()\nsteps_per_epoch","f18a16bf":"def train_step(images, labels):\n#     print('train step')\n    model1.fit(images, labels, epochs=5, verbose=1, batch_size=32)#, steps_per_epoch=steps_per_epoch)","fd76232b":"def train_model(epochs, image_paths = training_img_paths, train_labels = training_labels):\n    images = np.zeros((BATCH_SIZE,input_size, input_size,1))\n    labels = np.zeros((BATCH_SIZE,train_labels.shape[1]))\n    \n    for epoch in range(epochs):\n        print(epoch+1, end=' ')\n        x = tf.random.uniform([BATCH_SIZE], minval=0, maxval=len(image_paths), dtype=tf.dtypes.int32)\n        for i in range(BATCH_SIZE):\n            image = _load_image(image_paths[x[i]])\n            label = train_labels[x[i]].copy()\n            images[i], labels[i] = _preprocess_data(image, label)\n            \n#         print('here')\n#         print(images.shape)\n        train_step(images, labels)\n        ","a4fea68e":"train_model(5)","0e8d0298":"def check_model(t=0):\n\n    img = _load_image(training_img_paths[t])\n    label = training_labels[t].copy()\n\n    img, true_label = _preprocess_data(img, label)\n    img = tf.reshape(img, [1,input_size, input_size,1])\n    label = model1.predict(img).reshape((-1,2))\n    \n    img = tf.squeeze(img)\n    label = tf.reshape(label, [-1,2])\n    plt.figure()\n    plt.imshow(img, cmap='gray')\n    plt.scatter(label[:, 0], label[:, 1], s=20, marker='.', c='m')\n    plt.show()\n\n#     true_label = tf.reshape(true_label, [-1,2])\n#     plt.figure()\n#     plt.imshow(img, cmap='gray')\n#     plt.scatter(true_label[:, 0], true_label[:, 1], s=20, marker='.', c='m')\n#     plt.show()\n\n\nfor i in [0,10,110,1110,1,11,111,1111]:\n    check_model(i)\n","e9a10db5":"model1.save('model9.h5')\n\n# Recreate the exact same model purely from the file:\n# model = keras.models.load_model('path_to_my_model.h5')","c107bec4":"train_model(5)","71d1e28e":"def check_model(t=0):\n\n    img = _load_image(training_img_paths[t])\n    label = training_labels[t].copy()\n\n    img, true_label = _preprocess_data(img, label)\n    img = tf.reshape(img, [1,input_size, input_size,1])\n    label = model1.predict(img).reshape((-1,2))\n    \n    img = tf.squeeze(img)\n    label = tf.reshape(label, [-1,2])\n    plt.figure()\n    plt.imshow(img, cmap='gray')\n    plt.scatter(label[:, 0], label[:, 1], s=20, marker='.', c='m')\n    plt.show()\n\n#     true_label = tf.reshape(true_label, [-1,2])\n#     plt.figure()\n#     plt.imshow(img, cmap='gray')\n#     plt.scatter(true_label[:, 0], true_label[:, 1], s=20, marker='.', c='m')\n#     plt.show()\n\n\nfor i in [0,10,110,1110,1,11,111,1111]:\n    check_model(i)\n","7978b897":"model1.save('model10.h5')\n\n# Recreate the exact same model purely from the file:\n# model = keras.models.load_model('path_to_my_model.h5')","7febdb57":"train_model(5)","26ce6efc":"def check_model(t=0):\n\n    img = _load_image(training_img_paths[t])\n    label = training_labels[t].copy()\n\n    img, true_label = _preprocess_data(img, label)\n    img = tf.reshape(img, [1,input_size, input_size,1])\n    label = model1.predict(img).reshape((-1,2))\n    \n    img = tf.squeeze(img)\n    label = tf.reshape(label, [-1,2])\n    plt.figure()\n    plt.imshow(img, cmap='gray')\n    plt.scatter(label[:, 0], label[:, 1], s=20, marker='.', c='m')\n    plt.show()\n\n#     true_label = tf.reshape(true_label, [-1,2])\n#     plt.figure()\n#     plt.imshow(img, cmap='gray')\n#     plt.scatter(true_label[:, 0], true_label[:, 1], s=20, marker='.', c='m')\n#     plt.show()\n\n\nfor i in [0,10,110,1110,1,11,111,1111]:\n    check_model(i)\n","558b4098":"model1.save('model11.h5')\n\n# Recreate the exact same model purely from the file:\n# model = keras.models.load_model('path_to_my_model.h5')","424721ba":"# training\ndataset variables\n* training_labels\n* training_img_paths","2c147071":"# model","90f6c32c":"dataset variables\n* training_labels\n* training_img_paths"}}