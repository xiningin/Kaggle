{"cell_type":{"64ff1668":"code","d0bbb200":"code","72f7e0c7":"code","f80f8522":"code","76350501":"code","6ecda26d":"code","1d271dec":"code","277db1ca":"code","404100ef":"code","927c9293":"code","279f8016":"code","3084337c":"code","78aaf694":"code","f2866a3f":"code","8c2d0cda":"code","3b089c43":"code","ac6cabef":"markdown","9522c688":"markdown","d2bc6ec4":"markdown","3d73f7e2":"markdown","9309233c":"markdown","b0a7cb20":"markdown","8bf98f12":"markdown","5a7c1be4":"markdown","c788cb20":"markdown","9ed8f1af":"markdown","b0dc98c3":"markdown","fd426a23":"markdown","7f500654":"markdown","91d1f5aa":"markdown","2ece5bcb":"markdown","c5f7c47e":"markdown"},"source":{"64ff1668":"import numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor\nfrom pylab import mpl  \nmpl.rcParams['font.sans-serif'] = ['SimHei']  # Specify the font in the image","d0bbb200":"print('Reading Data...')\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\", dtype={\"Age\": np.float64}, )\ntest_data = pd.read_csv(\"..\/input\/titanic\/train.csv\", dtype={\"Age\": np.float64}, )","72f7e0c7":"train_data.head() #dataframe\u683c\u5f0f","f80f8522":"train_data.info()","76350501":"train_data.describe()","6ecda26d":"%matplotlib inline \nimport matplotlib.pyplot as plt\ndata_train = train_data\n\nfig = plt.figure()\nfig.set(alpha=0.2)  # Set chart color alpha parameter\n\nplt.subplot2grid((3,7),(0,0))             # Separate several small pictures in one big picture\ndata_train.Survived.value_counts().plot(kind='bar')# Histogram\nplt.title(\"Rescue situation \") # title\nplt.ylabel(\"people\")  \n\nplt.subplot2grid((3,7),(0,3))\ndata_train.Pclass.value_counts().plot(kind=\"bar\")\nplt.ylabel(\"people\")\nplt.title(\"class distribution\")\n\nplt.subplot2grid((3,7),(0,6))\nplt.scatter(data_train.Survived, data_train.Age)\nplt.ylabel(\"age\")                         # Set the ordinate name\nplt.grid(b=True, which='major', axis='y') \nplt.title(\"Rescue by age \")\n\n\nplt.subplot2grid((3,7),(2,0), colspan=2)\ndata_train.Age[data_train.Pclass == 1].plot(kind='kde')   \ndata_train.Age[data_train.Pclass == 2].plot(kind='kde')\ndata_train.Age[data_train.Pclass == 3].plot(kind='kde')\nplt.xlabel(\"age\")# plots an axis lable\nplt.ylabel(\"density\") \nplt.title(\"Passenger age distribution by class\")\n#plt.legend(('First Class', '2 First Class', '3 First Class'),loc='best') # sets our legend for our graph.\n\n\nplt.subplot2grid((3,7),(2,6))\ndata_train.Embarked.value_counts().plot(kind='bar')\nplt.title(\"Number of people on board at each boarding port\")\nplt.ylabel(\"people\")  \nplt.show()","1d271dec":"fig = plt.figure()\nfig.set(alpha=0.2)  # \u8bbe\u5b9a\u56fe\u8868\u989c\u8272alpha\u53c2\u6570\n\nSurvived_0 = data_train.Pclass[data_train.Survived == 0].value_counts()\nSurvived_1 = data_train.Pclass[data_train.Survived == 1].value_counts()\ndf=pd.DataFrame({'Not rescued':Survived_0,'Rescued':Survived_1})\ndf.plot(kind='bar', stacked=True)\nplt.title(\"Rescue status by passenger class\")\nplt.xlabel(\"Passenger class\") \nplt.ylabel(\"Number of people\") \nplt.show()","277db1ca":"fig = plt.figure()\nfig.set(alpha=0.2)  # \u8bbe\u5b9a\u56fe\u8868\u989c\u8272alpha\u53c2\u6570\n\nSurvived_m = data_train.Survived[data_train.Sex == 'male'].value_counts()\nSurvived_f = data_train.Survived[data_train.Sex == 'female'].value_counts()\ndf=pd.DataFrame({u'man':Survived_m, u'woman':Survived_f})\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"Rescue by gender\")\nplt.xlabel(u\"gender\") \nplt.ylabel(u\"people\")\nplt.show()","404100ef":"#\u7136\u540e\u6211\u4eec\u518d\u6765\u770b\u770b\u5404\u79cd\u8231\u7ea7\u522b\u60c5\u51b5\u4e0b\u5404\u6027\u522b\u7684\u83b7\u6551\u60c5\u51b5\nfig=plt.figure()\nfig.set(alpha=0.65) # \u8bbe\u7f6e\u56fe\u50cf\u900f\u660e\u5ea6\uff0c\u65e0\u6240\u8c13\nplt.title(u\"Rescue according to cabin class and gender\")\n\nax1=fig.add_subplot(141)\ndata_train.Survived[data_train.Sex == 'female'][data_train.Pclass != 3].value_counts().sort_index().plot(kind='bar', label=\"female highclass\", color='#FA2479')\nax1.set_xticks([0,1])\nax1.set_xticklabels([u\"0\", u\"1\"], rotation=0)\nax1.legend([u\"Female\/Premium\"], loc='best')\n\nax2=fig.add_subplot(142, sharey=ax1)\ndata_train.Survived[data_train.Sex == 'female'][data_train.Pclass == 3].value_counts().sort_index().plot(kind='bar', label='female, low class', color='pink')\nax2.set_xticklabels([u\"0\", u\"1\"], rotation=0)\nplt.legend([u\"Female\/Lower Class\"], loc='best')\n\nax3=fig.add_subplot(143, sharey=ax1)\ndata_train.Survived[data_train.Sex == 'male'][data_train.Pclass != 3].value_counts().sort_index().plot(kind='bar', label='male, high class',color='lightblue')\nax3.set_xticklabels([u\"0\", u\"1\"], rotation=0)\nplt.legend([u\"Male \/ Premium Class\"], loc='best')\n\nax4=fig.add_subplot(144, sharey=ax1)\ndata_train.Survived[data_train.Sex == 'male'][data_train.Pclass == 3].value_counts().sort_index().plot(kind='bar', label='male low class', color='steelblue')\nax4.set_xticklabels([u\"0\", u\"1\"], rotation=0)\nplt.legend([u\"Male \/ Lower Class\"], loc='best')\n\nplt.show()","927c9293":"# Functions\n\ndef get_title(name):\n    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"","279f8016":"print('Cleaning Data...')\n\n# When cleaning the data, the test set is also put into it, so that the format of the test set is the same as the training set when predicting the results later.\ncombined2 = pd.concat([train_data, test_data], axis=0)\ncombined2.Embarked.fillna('S', inplace=True)\ncombined2.Fare.fillna(np.median(combined2.Fare[combined2.Fare.notnull()]), inplace=True)\ncombined2['Title'] = combined2[\"Name\"].apply(get_title)\n\n# In order to facilitate the establishment of the model, we will map the str type data to the int type one by one.\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 7, \"Dona\":10, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 7, \"Capt\": 7, \"Ms\": 2}\ncombined2[\"TitleCat\"] = combined2.loc[:,'Title'].map(title_mapping)\ncombined2['CabinCat'] = pd.Categorical(combined2.Cabin.fillna('0').apply(lambda x: x[0])).codes\ncombined2.Cabin.fillna('0', inplace=True)\ncombined2['EmbarkedCat'] = pd.Categorical(combined2.Embarked).codes\ncombined2.drop(['Ticket'], axis=1, inplace=True)\n","3084337c":"print('Consolidating Data...')\n\nfull_data = pd.concat([combined2.drop(['Survived'],axis=1),\n                       pd.get_dummies(combined2.Sex, prefix='Sex'),\n                       combined2.Survived], axis=1)","78aaf694":"\nprint('Generating Features...')\n\nfull_data['FamilySize'] = full_data[\"SibSp\"] + full_data[\"Parch\"]\nfull_data['NameLength'] = full_data.Name.apply(lambda x: len(x))\n\nimport operator\nfamily_id_mapping = {}\ndef get_family_id(row):\n    last_name = row[\"Name\"].split(\",\")[0]\n    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n    \n    if family_id not in family_id_mapping:\n        if len(family_id_mapping) == 0:\n            current_id = 1\n        else:\n            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n        family_id_mapping[family_id] = current_id\n    return family_id_mapping[family_id]\nfamily_ids = full_data.apply(get_family_id, axis=1)\n# There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\nfamily_ids[full_data[\"FamilySize\"] < 3] = -1\nfull_data[\"FamilyId\"] = family_ids\n\n#### Person Label\nchild_age = 14\ndef get_person(passenger):\n    age, sex = passenger\n    if (age < child_age):\n        return 'child'\n    elif (sex == 'female'):\n        return 'female_adult'\n    else:\n        return 'male_adult'\nfull_data = pd.concat([full_data, pd.DataFrame(full_data[['Age', 'Sex']].apply(get_person, axis=1), columns=['person'])],axis=1)\ndummies = pd.get_dummies(full_data['person'])\nfull_data = pd.concat([full_data,dummies],axis=1)\n\ndef process_surname(nm):\n    return nm.split(',')[0].lower()\nfull_data['surname'] = full_data['Name'].apply(process_surname)\n\n#### Persihing Females\nperishing_female_surnames = list(set(full_data[(full_data.female_adult == 1.0) &\n                                     (full_data.Survived == 0.0) &\n                                     ((full_data.Parch > 0) | (full_data.SibSp > 0))]['surname'].values))\ndef perishing_mother_wife(passenger): \n    surname, Pclass, person = passenger\n    return 1.0 if (surname in perishing_female_surnames) else 0.0\nfull_data['perishing_mother_wife'] = full_data[['surname', 'Pclass', 'person']].apply(perishing_mother_wife, axis=1)\n\n#### Survivng Males\nsurviving_male_surnames = list(set(full_data[(full_data.male_adult == 1.0) &\n                                     (full_data.Survived == 1.0) &\n                                     ((full_data.Parch > 0) | (full_data.SibSp > 0))]['surname'].values))\ndef surviving_father_husband(passenger): \n    surname, Pclass, person = passenger\n    return 1.0 if (surname in surviving_male_surnames) else 0.0\nfull_data['surviving_father_husband'] = full_data[['surname', 'Pclass', 'person']].apply(surviving_father_husband, axis=1)\n\nclassers = ['Fare','Parch','Pclass','SibSp','TitleCat','CabinCat','Sex_female','Sex_male', 'EmbarkedCat', 'FamilySize', 'NameLength', 'FamilyId']\nage_et = ExtraTreesRegressor(n_estimators=200)\nX_train = full_data.loc[full_data.Age.notnull(),classers]\nY_train = full_data.loc[full_data.Age.notnull(),['Age']]\nX_test = full_data.loc[full_data.Age.isnull(),classers]\nage_et.fit(X_train,np.ravel(Y_train))\nage_preds = age_et.predict(X_test)\nfull_data.loc[full_data.Age.isnull(),['Age']] = age_preds","f2866a3f":"print('Building Model...')\n\n#### Model Build - Random Forest (Categorical Features)\nmodel_dummys = ['Age','male_adult', 'female_adult', 'child','perishing_mother_wife','surviving_father_husband','Fare','Parch','Pclass','SibSp','TitleCat','CabinCat','Sex_female','Sex_male', 'EmbarkedCat', 'FamilySize', 'NameLength', 'FamilyId']\nmodel_rf = RandomForestClassifier(n_estimators=300, min_samples_leaf=4, class_weight={0:0.745,1:0.255})\nX_data = full_data.iloc[:891,:]  # Remove the test set part from the data set\nX_train = X_data.loc[:,model_dummys]\nY_data = full_data.iloc[:891,:]\nY_train = Y_data.loc[:,['Survived']]\nX_t_data = full_data.iloc[891:,:]\nX_test = X_t_data.loc[:,model_dummys]\nmodel_rf.fit(X_train, np.ravel(Y_train))","8c2d0cda":"print('Generating Predictions...')\n\nmodel_results = model_rf.predict(X_test)\n","3b089c43":"print('Processing Submission File...')\n\n\nmodel_results = [str(int(x)) for x in model_results]\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = X_t_data.PassengerId\nsubmission['Survived'] = model_results\nsubmission.set_index(['PassengerId'],inplace=True, drop=True)\nsubmission.head(3)\nsubmission.to_csv('titanic_submission.csv')\n\nprint('Done.')\n","ac6cabef":"consolidate the cleaned data to  facilitate feature extraction later.","9522c688":"Feature extraction of data is originally a digital type of data that remains the same, and str type data with more information can extract multiple useful features.","d2bc6ec4":"## Then we clean the data and extract features","3d73f7e2":"Look at the distribution of data through icons","9309233c":"View the statistical description of the data","b0a7cb20":"Rescue according to cabin class and gender","8bf98f12":"Looking at the rescue situation by gender, it was found that a higher percentage of women were rescued.","5a7c1be4":"View general information about the data","c788cb20":"# First Notebook in Kaggle","9ed8f1af":"Read the first few lines of data to view the format of the data","b0dc98c3":"After we are familiar with the distribution of the data, we have mastered the characteristics that affect the results of the rescue. Next, we can process the data according to our understanding, get the characteristics of the data, and build our model according to the characteristics.","fd426a23":"Check whether the proportion of rescued is related to the rank of the ticket. It is found that the higher the rank, the higher the proportion of rescued.","7f500654":"When cleaning the data, we did not discard the name column, but used the last name in the name as a new feature. Although names are relatively independent, it is not feasible to use names to predict the model in most cases. However, in a very small space such as a ship, names are still closely related to survival results.","91d1f5aa":"Use sklearn's RandomForestClassifier algorithm interface to build a model.","2ece5bcb":"This is just a small modification and interpretation on Philip's code (https:\/\/www.kaggle.com\/philipkalinda\/titanic\/titanic-modelling\/run\/429408) that reduces the number of trees in the random forest by 99% (from 30.000 to 300) while retaining very similar accuracy. It helps making the model more manageable to further improvements and enabling more people to understand it.\n","c5f7c47e":"## First we read in the data and then check the distribution of the data"}}