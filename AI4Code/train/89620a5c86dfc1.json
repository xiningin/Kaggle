{"cell_type":{"58d98239":"code","a6618671":"code","02977c05":"code","4c9c1e5b":"code","06368773":"code","5a50376f":"code","0b42b600":"code","1a0cf1f0":"code","45b34ba4":"code","e5c74a60":"code","cc81bf65":"code","4e7af7a2":"code","83be0106":"code","ed11cbaa":"code","33c2bf66":"code","f3f7206a":"code","d22f63ce":"code","33dd2567":"code","5104ffec":"code","3be1e3ac":"code","e07359c8":"code","359749be":"code","279b408e":"code","c6408753":"code","ab746771":"code","a510b9a1":"code","9f89092a":"code","96539d69":"markdown","500f6e61":"markdown","e1fab7fd":"markdown","e3a9cd4a":"markdown","2cb9de2b":"markdown"},"source":{"58d98239":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom scipy.sparse import csr_matrix, hstack\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\nfrom tqdm import tqdm\n#tqdm.pandas()\n\n# Feature engineering\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Fitting\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport gc\nimport os\nDATA_PATH = \"..\/input\"\nprint(os.listdir(DATA_PATH))\n\n# Any results you write to the current directory are saved as output.","a6618671":"debug = False\ntrain = pd.read_json(os.path.join(DATA_PATH, 'train.json')).set_index('id')\ntest = pd.read_json(os.path.join(DATA_PATH, 'test.json')).set_index('id')\nif debug is True:\n    train = train.sample(100)\n    test = test.sample(100)\n\nprint(\"Training Data Shape: \", train.shape)\nprint(\"Testing Data Shape: \", test.shape)\n\nprint(\"Number of cuisines: \", train.cuisine.nunique())\n# Remove single-ingredient entries \ntrain = train[train['ingredients'].str.len()>1]","02977c05":"traindex = train.index\ntestdex = test.index\n\ntrain_size = train.shape[0]\n\ny_train = train.cuisine.copy()\n\ndf = pd.concat([train[['ingredients']], test], axis = 0)\nprint(\"All Data Shape: \", df.shape)\ndf_index = df.index\n\nfeatures_df = pd.DataFrame(index=df.index)","4c9c1e5b":"sns.countplot(y=train.cuisine, order=train.cuisine.value_counts().reset_index()[\"index\"])\nplt.title(\"Cuisine Distribution in training data\")\nplt.show()","06368773":"train['ings'] = train['ingredients'].apply(lambda x: \",\".join(x))","5a50376f":"withoz = train[train['ings'].str.contains(\"oz\\.\")]\nif len(withoz) > 0:\n    sns.countplot(y=withoz.cuisine, order=withoz.cuisine.value_counts().reset_index()[\"index\"])\n    plt.title(\"Cuisine Distribution for (oz) in ingredients\")\n    plt.show()","0b42b600":"fr_accents = ['\u00e9', '\u00e8', '\u00ea', '\u00eb', '\u00e0', '\u00e2', '\u00ee', '\u00f4', '\u00f9', '\u00fb', '\u00e7']\nwith_fr_accent = train[train['ings'].str.contains(\"|\".join(fr_accents))]\nif len(with_fr_accent) > 0:\n    sns.countplot(y=with_fr_accent.cuisine, order=with_fr_accent.cuisine.value_counts().reset_index()[\"index\"])\n    plt.title(\"Cuisine Distribution for French accents in ingredients\")\n    plt.show()","1a0cf1f0":"features_df['fr_accents'] = df.ingredients.apply(lambda x: \",\".join(x)).str.contains(\"|\".join(fr_accents)).astype(int)","45b34ba4":"es_accents = ['\u00e1', '\u00e9', '\u00ed', '\u00f3', '\u00fa', '\u00fc', '\u00f1']\nwith_es_accent = train[train['ings'].str.contains(\"|\".join(es_accents))]\nif len(with_es_accent) > 0:\n    sns.countplot(y=with_es_accent.cuisine, order=with_es_accent.cuisine.value_counts().reset_index()[\"index\"])\n    plt.title(\"Cuisine Distribution for Spanish accents in ingredients\")\n    plt.show()","e5c74a60":"features_df['es_accents'] = df.ingredients.apply(lambda x: \",\".join(x)).str.contains(\"|\".join(es_accents)).astype(int)","cc81bf65":"train.drop(['ings'], axis=1, inplace=True)","4e7af7a2":"ingredient_dict = {}\nfor _, row in train.iterrows():\n    for ing in row['ingredients']:\n        ingredient_dict.setdefault(ing, []).append(row['cuisine'])","83be0106":"endemic_ingredient_dict = {}\nfor ing, cui in ingredient_dict.items():\n    if len(cui) <= 1:\n        endemic_ingredient_dict[ing] = cui[0]\nlen(endemic_ingredient_dict)","ed11cbaa":"cuisines = train.cuisine.unique()\nprint(cuisines)","33c2bf66":"for cui in cuisines:\n    features_df[cui] = 0\nfor ing, cui in endemic_ingredient_dict.items():\n    features_df.loc[df.ingredients.apply(lambda x: \",\".join(x)).str.contains(ing),cui] = 1\n\nfeatures_df.head()","f3f7206a":"del test; del train; gc.collect();","d22f63ce":"vect = CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)\ndummies = vect.fit_transform(df['ingredients'].apply(','.join)) \n\nfull_matrix = csr_matrix(hstack([dummies, features_df]))","33dd2567":"X_train = full_matrix[:train_size,:]\nX_test = full_matrix[train_size:,:]","5104ffec":"print('All data matrix shape:', full_matrix.shape)\nprint('Train data matrix shape:', X_train.shape)\nprint('Test data matrix shape:', X_test.shape)","3be1e3ac":"%%time\nclassifier = LogisticRegression(multi_class='multinomial', \n                                solver='saga', \n                                verbose=1, \n                                n_jobs=-1)\n#score = cross_validate(classifier, X_train, y_train, cv=5)\n#print(score[\"test_score\"].mean())","e07359c8":"#cvscore = score[\"test_score\"].mean()","359749be":"%%time\nfrom sklearn.model_selection import GridSearchCV\ncv_params = {'C': np.logspace(-1, 2, 20), 'multi_class': ['ovr', 'multinomial']}\n#gridsearch = GridSearchCV(classifier, cv_params, cv=5, verbose=0, n_jobs=-1)\n#gridsearch.fit(X_train, y_train)","279b408e":"#cvscore = gridsearch.best_score_\nbestC = 1.8329807108324356\n#print(gridsearch.best_params_)\n#print(gridsearch.best_score_)","c6408753":"%%time\nclassifier = LogisticRegression(C=bestC,\n                                multi_class='ovr', \n                                solver='saga', \n                                verbose=1, \n                                n_jobs=-1)\n\nclassifier.fit(X_train, y_train)","ab746771":"y_pred = classifier.predict(X_train)\n#y_true = label_encoder.inverse_transform(y_train)\n\nprint(f'accuracy score on train data: {accuracy_score(y_train, y_pred)}')","a510b9a1":"def write_submission_file(prediction, index, filename,\n                          path_to_sample=os.path.join(DATA_PATH,'sample_submission.csv')):\n    #submission = pd.read_csv(path_to_sample, index_col='id')\n    submission = pd.Series(prediction, index=index).rename('cuisine')\n    #submission['cuisine'] = prediction\n    submission.to_csv(filename, header=True, index=True)","9f89092a":"# make submission\ny_pred = classifier.predict(X_test)\nwrite_submission_file(y_pred, testdex, \"logistic_cv_sub.csv\")","96539d69":"Apparently using \"oz.\" doesn't give any extra info as distribution of cuisines stays almost the same","500f6e61":"Now let's have a look at ingredients that are endemic to certain cuisine:","e1fab7fd":"Trying to use this info","e3a9cd4a":"Let's iterate over all ingredients and build a map from ingredient to cuisines","2cb9de2b":"Hmm, doesn't look like spanish or mexican. Still, let's try"}}