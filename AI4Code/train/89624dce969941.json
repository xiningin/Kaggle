{"cell_type":{"171cf798":"code","1225500b":"code","c5b6e690":"code","a7290328":"code","b77633f9":"code","ec6269d4":"code","1b7899cd":"code","9d2b2ebc":"code","5cb82f67":"code","5d962275":"code","976a0c1d":"code","145a0b4c":"code","5d8b0109":"code","08ee1000":"code","41c09c68":"code","9709c154":"code","4ef05b7e":"code","5b6f4efb":"code","5cbfd172":"code","2c171509":"code","3711aba5":"code","8d233f2c":"code","d6d762c0":"code","79e60fb0":"code","14d44542":"code","ca566c1c":"code","a0957f24":"code","f6723d17":"code","586df123":"code","4b04f004":"code","2b9fe93a":"code","d11fa918":"code","86317ecc":"code","6af6e1aa":"markdown","f83cb555":"markdown","5996c555":"markdown","70709906":"markdown","44ec1f9f":"markdown","0ee54e77":"markdown"},"source":{"171cf798":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1225500b":"import numpy as np\nimport pandas as pd\n\nimport os\n\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch.optim as optim\nimport torchvision.transforms as transforms","c5b6e690":"# class PawpularDataset(Dataset):\n#     def __init__(self, images_path, features_path, transform):\n#         self.images_path = images_path\n#         self.df = pd.read_csv(features_path, dtype={'Pawpularity': np.float32})\n        \n#         self.imgs = self.df['Id']\n#         self.targets = self.df['Pawpularity']\n#         self.transform = transform\n    \n#     def __len__(self):\n#         return len(self.df)\n    \n#     def __getitem__(self, index):\n#         img_id = self.imgs[index]\n#         img = Image.open(os.path.join(self.images_path, img_id+'.jpg')).convert('RGB')\n#         img = self.transform(img)\n        \n#         targets = self.targets[index]\n        \n#         return img, targets","a7290328":"# class PawpularDatasetTest(Dataset):\n#     def __init__(self, images_path, features_path, transform):\n#         self.images_path = images_path\n#         self.df = pd.read_csv(features_path)\n        \n#         self.imgs = self.df['Id']\n#         self.transform = transform\n    \n#     def __len__(self):\n#         return len(self.df)\n    \n#     def __getitem__(self, index):\n#         img_id = self.imgs[index]\n#         img = Image.open(os.path.join(self.images_path, img_id+'.jpg')).convert('RGB')\n#         img = self.transform(img)\n        \n#         return img","b77633f9":"# class PretrainedCNN(nn.Module):\n#     def __init__(self, hidden_size, num_classes, train=False):\n#         super(PretrainedCNN, self).__init__()\n#         self.train = train\n#         self.resnet = models.resnet18(pretrained=False) # TODO\n        \n#         self.resnet.fc = nn.Linear(self.resnet.fc.in_features, hidden_size) # TODO\n        \n#         self.fc = nn.Linear(hidden_size, num_classes)\n        \n#         self.relu = nn.ReLU()\n#         self.dropout = nn.Dropout(0.2)\n        \n#     def forward(self, images):\n#         for name, param in self.resnet.named_parameters():\n#             if 'fc.weight' in name or 'fc.bias' in name:\n#                 param.requires_grad = True\n#             else:\n#                 param.requires_grad = self.train\n                \n#         resnet_features = self.dropout(self.relu(self.resnet(images)))\n                \n#         return self.fc(resnet_features)","ec6269d4":"# transform = transforms.Compose(\n#   [\n#    transforms.Resize((256,256)),\n#    transforms.CenterCrop(224),\n#    transforms.ToTensor(),\n#    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n#                         std=[0.229, 0.224, 0.225])\n#   ]\n# )","1b7899cd":"# torch.manual_seed(1)\n\n# trainset = PawpularDataset(images_path='..\/input\/petfinder-pawpularity-score\/train', \n#                            features_path='..\/input\/petfinder-pawpularity-score\/train.csv', \n#                            transform=transform)\n\n\n# testloader = PawpularDatasetTest(images_path='..\/input\/petfinder-pawpularity-score\/test', \n#                            features_path='..\/input\/petfinder-pawpularity-score\/test.csv', \n#                            transform=transform)\n\n# train_loader = DataLoader(\n#     dataset=trainset,\n#     batch_size=64,\n#     shuffle=True\n# )\n\n# test_loader = DataLoader(\n#     dataset=testloader,\n#     batch_size=1,\n#     shuffle=False\n# )\n\n# num_examples = len(trainset)\n# val_len = round(0.33*num_examples)\n# train_len = num_examples - val_len\n\n# train, validation = torch.utils.data.random_split(trainset, [train_len, val_len])\n# train_loader = torch.utils.data.DataLoader(train, batch_size=100, \n#                                            shuffle=True, num_workers=2)\n# val_loader = torch.utils.data.DataLoader(validation, batch_size=100, \n#                                          shuffle=True, num_workers=2)","9d2b2ebc":"# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# hidden_size = 256\n# num_classes = 1\n# learning_rate = 3e-4\n# num_epochs = 5","5cb82f67":"# torch.manual_seed(1)\n\n# losses = list()\n# model = PretrainedCNN(hidden_size, num_classes).to(device)\n\n# criterion = nn.MSELoss()\n# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# for epoch in range(1, num_epochs+1):\n    \n#     for step, (img, target) in enumerate(train_loader):\n\n#         model.zero_grad()\n\n#         img = img.to(device)\n#         target = target.to(device)\n\n#         outputs = model(img)\n\n#         loss = criterion(outputs, target.unsqueeze(1))\n\n#         loss.backward()\n#         optimizer.step()\n\n#         losses.append(loss.item())\n#         stats = 'Epoch [%d\/%d], Step [%d], Loss: %.4f' % (epoch, num_epochs, step, loss.item())\n#         print('\\r' + stats, end='')\n        \n#     with torch.no_grad():\n#         val_losses = 0\n#         for img, target in val_loader:\n#             img = img.to(device)\n#             target = target.to(device)\n            \n#             outputs = model(img)\n#             val_loss = criterion(outputs, target.unsqueeze(1))\n#             val_losses += (1\/len(val_loader))*val_loss.item()\n            \n#         print('\\n Epoch [%d\/%d], Val Loss: %.4f' % (epoch, num_epochs, val_losses))","5d962275":"# res = []\n# with torch.no_grad():\n#     for images in test_loader:\n#         images = images.to(device)\n#         outputs = model(images)\n# #         res.append(float(outputs.squeeze(-1).cpu()))\n#         res.append(np.array(outputs.squeeze(1).cpu()))\n# print(res)","976a0c1d":"# data_test = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')","145a0b4c":"# sub = (pd.DataFrame({'Id': data_test['Id'].values, 'Pawpularity': res}))\n# sub","5d8b0109":"# sub.to_csv('submission.csv', index=False)","08ee1000":"class PawpularDataset(Dataset):\n    def __init__(self, images_path, features_path, transform, test=False):\n        self.images_path = images_path\n        self.df = pd.read_csv(features_path)\n        if test:\n            self.df['Pawpularity'] = np.nan # \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043d\u0430\u043f\u0438\u0441\u0430\u0442\u044c \u0443\u0434\u0430\u0447\u043d\u0435\u0435\n        \n        self.imgs = self.df['Id']\n        self.features = self.df.drop(['Id', 'Pawpularity'], axis=1)\n        self.targets = self.df['Pawpularity']\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_id = self.imgs[index]\n        img = Image.open(os.path.join(self.images_path, img_id+'.jpg')).convert('RGB')\n        img = self.transform(img)\n        \n        features = torch.FloatTensor(self.features.values[index])\n        targets = self.targets.values[index]\n        \n        return img, features, targets # \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0441\u0440\u0430\u0437\u0443 torch.tensor(targets, dtype=torch.float) \u0438 \u0442.\u0434.","41c09c68":"class PawpularCNN(nn.Module):\n    def __init__(self, input_size, dense_size, hidden_size, num_classes):\n        super(PawpularCNN, self).__init__()\n        self.resnet = models.resnet18(pretrained=False)\n        self.resnet.load_state_dict(\n            torch.load(\"..\/input\/resnet185c106cdepth\/resnet18-5c106cde.pth\")\n        )\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, hidden_size)\n        self.dense = nn.Linear(input_size, dense_size)\n        self.dense2 = nn.Linear(dense_size, dense_size)\n        \n        self.fc = nn.Linear(hidden_size+dense_size, dense_size)\n        self.out = nn.Linear(dense_size, num_classes)\n        \n        self.relu = nn.ReLU()\n        \n    def forward(self, images, features):\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n                \n        resnet_features = self.relu(self.resnet(images))\n        dense_features = self.relu(self.dense2(self.dense(features)))\n        \n        all_features = torch.cat((resnet_features, dense_features), dim=1)\n        all_features = torch.flatten(all_features, 1)\n        \n        return self.out(self.fc(all_features))","9709c154":"transform = transforms.Compose(\n  [\n   transforms.Resize((256,256)),\n   transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n  ]\n)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ninput_size = 12\nhidden_size = 100\ndense_size = 100\nnum_classes = 1\nlearning_rate = 3e-4\nnum_epochs = 10","4ef05b7e":"torch.manual_seed(42)\n\ntrainset = PawpularDataset(images_path='..\/input\/petfinder-pawpularity-score\/train', \n                           features_path='..\/input\/petfinder-pawpularity-score\/train.csv', \n                           transform=transform)\n\nnum_examples = len(trainset)\nval_len = round(0.33*num_examples)\ntrain_len = num_examples - val_len\n\n# train_loader = DataLoader(\n#     dataset=trainset,\n#     batch_size=64,\n#     shuffle=True\n# )\n\n# test_loader = DataLoader(\n#     dataset=testloader,\n#     batch_size=1,\n#     shuffle=False\n# )\n\ntrain, validation = torch.utils.data.random_split(trainset, [train_len, val_len])\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=100, \n                                           shuffle=True, num_workers=2)\nval_loader = torch.utils.data.DataLoader(validation, batch_size=100, \n                                         shuffle=True, num_workers=2)","5b6f4efb":"torch.manual_seed(101)\n\nlosses = list()\nmodel = PawpularCNN(input_size, dense_size, hidden_size, num_classes).to(device)\n\ncriterion = nn.MSELoss().to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\nfor epoch in range(1, num_epochs+1):\n    \n    for step, (img, features, target) in enumerate(train_loader):\n\n        model.zero_grad()\n\n        img = img.to(device)\n        features = features.to(device)\n        target = target.type(torch.FloatTensor) # \u043f\u043e\u0442\u043e\u043c \u0443\u0431\u0440\u0430\u0442\u044c \u044d\u0442\u0443 \u0441\u0442\u0440\u043e\u043a\u0443\n        target = target.to(device)\n\n        outputs = model(img, features)\n\n        loss = criterion(outputs, target.unsqueeze(1)).to(device)\n\n        loss.backward()\n        optimizer.step()\n\n        losses.append(loss.item())\n        stats = 'Epoch [%d\/%d], Step [%d], Loss: %.4f' % (epoch, num_epochs, step, loss.item())\n        print('\\r' + stats, end='')\n        \n    with torch.no_grad():\n        val_losses = 0\n        for img, features, target in val_loader:\n            img = img.to(device)\n            features = features.to(device)\n            target = target.to(device)\n            \n            outputs = model(img, features)\n            val_loss = criterion(outputs, target.unsqueeze(1)).to(device)\n            val_losses += (1\/len(val_loader))*val_loss.item()\n            \n        print('\\n Epoch [%d\/%d], Val Loss: %.4f' % (epoch, num_epochs, val_losses))","5cbfd172":"testset = PawpularDataset(images_path='..\/input\/petfinder-pawpularity-score\/test', \n                          features_path='..\/input\/petfinder-pawpularity-score\/test.csv', \n                          transform=transform, \n                          test=True)\n\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=1, \n                                          shuffle=False, num_workers=2)","2c171509":"res = []\nwith torch.no_grad():\n        for img, features, target in test_loader:\n            img = img.to(device)\n            features = features.to(device)\n            \n            outputs = model(img, features)\n            res.append(float(outputs.squeeze(-1).cpu()))","3711aba5":"res","8d233f2c":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error","d6d762c0":"data = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')","79e60fb0":"X_train, X_test, Y_train, Y_test = train_test_split(data.iloc[:, 1:-1], data.iloc[:, -1], test_size=0.1,\\\n                                                    shuffle=True, random_state=5)","14d44542":"rfr = RandomForestRegressor(n_estimators=500, max_depth=3, n_jobs=-1)\nrfr.fit(X_train, Y_train)","ca566c1c":"np.sqrt(mean_squared_error(rfr.predict(X_test), Y_test))","a0957f24":"X_val = data_test.iloc[:, 1:]","f6723d17":"prediction_rfr = rfr.predict(X_val)","586df123":"gbr = GradientBoostingRegressor(n_estimators=400, max_depth=1, learning_rate=0.01)\ngbr.fit(X_train, Y_train)\nprediction_gbr = gbr.predict(X_test)\nnp.sqrt(mean_squared_error(Y_test, prediction_gbr))","4b04f004":"prediction_gbr = gbr.predict(X_val)","2b9fe93a":"output = np.mean([res[0], prediction_rfr, prediction_gbr], axis=0)\noutput","d11fa918":"sub = (pd.DataFrame({'Id': data_test['Id'].values, 'Pawpularity': output}))\nsub","86317ecc":"sub.to_csv('submission.csv', index=False)","6af6e1aa":"### Submission","f83cb555":"### Random Forest Regressor","5996c555":"# Second Model","70709906":"# Combine Models","44ec1f9f":"### Combine","0ee54e77":"### Gradient Boosting Regressor"}}