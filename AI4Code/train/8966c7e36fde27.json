{"cell_type":{"79181359":"code","7a61b0f5":"code","68e7015a":"code","5c7c538e":"code","a542ff02":"code","1e14e46c":"code","91b45720":"code","4de2d734":"code","e7dba8ba":"code","c730d42a":"code","3e3b5601":"code","d6ec51d3":"code","96c702f1":"code","93813f43":"code","e81f5dde":"code","296b8047":"code","7572def1":"code","6d37a37a":"code","a0dcf90f":"code","b72636ca":"code","5a760869":"code","86b51db5":"code","6ecc76f5":"code","c601d433":"code","2526f527":"code","46403ef5":"code","f45e2cc3":"code","7dd6177c":"code","1b8d786b":"code","be4e55e1":"code","a024dbab":"code","b78a78ed":"code","b146a7f7":"code","8abf3965":"code","93890745":"code","fc47b614":"code","90858407":"code","3ae74109":"markdown","64eb3a58":"markdown","d281e26f":"markdown","50209e62":"markdown"},"source":{"79181359":"import pandas as pd","7a61b0f5":"df=pd.read_csv('train.csv')","68e7015a":"df.head()","5c7c538e":"###Drop Nan Values\ndf=df.dropna()\n","a542ff02":"import numpy as np","1e14e46c":"## Get the Independent Features\n\nX=df.drop('label',axis=1)","91b45720":"## Get the Dependent features\ny=df['label']","4de2d734":"X.shape","e7dba8ba":"y.shape","c730d42a":"import tensorflow as tf","3e3b5601":"tf.__version__","d6ec51d3":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","96c702f1":"### Vocabulary size\nvoc_size=5000","93813f43":"messages=X.copy()","e81f5dde":"messages.dropna(inplace=True)","296b8047":"messages.reset_index(inplace=True)","7572def1":"import nltk\nimport re\nfrom nltk.corpus import stopwords","6d37a37a":"nltk.download('stopwords')","a0dcf90f":"### Dataset Preprocessing\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]',' ', messages['title'][i]) #regex to select alphabetic character \n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')] #stemming to convert word into root form \n    review = ' '.join(review)\n    corpus.append(review)","b72636ca":"corpus","5a760869":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr","86b51db5":"sent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","6ecc76f5":"embedded_docs[0]","c601d433":"## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","2526f527":"len(embedded_docs),y.shape","46403ef5":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","f45e2cc3":"X_final.shape,y_final.shape","7dd6177c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","1b8d786b":"### Finally Training\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","be4e55e1":"y_pred=model.predict_classes(X_test)","a024dbab":"from sklearn.metrics import confusion_matrix","b78a78ed":"confusion_matrix(y_test,y_pred)","b146a7f7":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","8abf3965":"X_test","93890745":"from tensorflow.keras.models import load_model\n\n\nmodel.save('lstm.h5')","fc47b614":"l1=[]\ndef check_f_or_r(txt):\n    txt = re.sub('[^a-zA-Z]',' ',txt) #regex to select alphabetic character \n    txt = txt.lower()\n    txt = txt.split()\n    \n    txt = [ps.stem(word) for word in txt if not word in stopwords.words('english')] #stemming to convert word into its root form \n    txt = ' '.join(txt)\n    l1.append(txt)\n    onehot_repr1 = [one_hot(txt,voc_size)for words in l1] \n    embedded_docs_txt = pad_sequences(onehot_repr1,padding='pre',maxlen=20) \n    model = load_model('lstm.h5')\n    res = model.predict_classes(embedded_docs_txt) \n    return res","90858407":"print(check_f_or_r(\"Deamon spotted in road at night \"))","3ae74109":"### Embedding Representation","64eb3a58":"### Model Training","d281e26f":"### Performance Metrics And Accuracy","50209e62":"### Onehot Representation"}}