{"cell_type":{"275551c7":"code","a0f23f7e":"code","27f8704a":"code","777cbbd6":"code","c4300225":"code","3a19baec":"code","7891cc11":"code","b3730dd6":"code","8512277d":"code","d8873d74":"code","51c2ef8c":"code","ab6e992c":"code","7e1667a4":"code","b64b9e03":"code","1ab63b08":"code","5a608c44":"code","b5180e0e":"code","53c7f08e":"code","b5a4d3e6":"code","8815d91e":"code","0adbb9d1":"code","c345920f":"code","854ffa4c":"code","bf154900":"code","f92e2765":"code","f89f1e32":"code","d81ef4dc":"code","820b6c8c":"code","2eafc830":"code","991a4a83":"code","590670ab":"code","702de911":"code","c63213fc":"code","e9765371":"code","0d92f13c":"code","b3675d67":"code","9d3c458e":"code","31a290b3":"code","09bf7b87":"code","cd4f18f2":"code","f98ad188":"code","7959683f":"code","dade6100":"code","b9998942":"code","1f6cb67a":"code","0775314c":"code","c01b89ed":"code","2fbb1259":"code","7a281858":"code","19be07d0":"code","8ce9ee8e":"code","a7db9ded":"code","00b0c11d":"code","19442d13":"code","84e3e9c1":"code","932976cf":"code","e40ea31d":"code","8f242131":"code","8cfea757":"code","52801d2a":"code","21a2a2a9":"code","a46447d9":"code","5663ce9c":"code","e59373af":"code","e0cbbf27":"markdown","13318bf9":"markdown","02ddae36":"markdown"},"source":{"275551c7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","a0f23f7e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","27f8704a":"!apt-get install p7zip\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/train.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/test.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission.csv.7z","777cbbd6":"!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission_stg2.csv.zip\n!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/test_stg2.tsv.zip","c4300225":"train_data = pd.read_csv('train.tsv', sep='\\t')\ntrain_data.head(5)","3a19baec":"train_data.isnull().sum()","7891cc11":"print(train_data.shape)\nprint(train_data.columns)","b3730dd6":"train_data = train_data[train_data['price'] > 0].reset_index(drop=True)\ntrain_data,validation_data=train_test_split(train_data,test_size=0.2,random_state=42)\nprint(train_data.shape)\nprint(validation_data.shape)","8512277d":"train_data.isnull().sum()","d8873d74":"validation_data.isnull().sum()","51c2ef8c":"train = train_data.copy()\nvalid = validation_data.copy()","ab6e992c":"def split_categories(category):\n    try:\n      sub_category1,sub_category2,sub_category3 = category.split(\"\/\")\n      return sub_category1,sub_category2,sub_category3\n    except:\n      return (\"No label\",\"No label\",\"No label\")\n\ndef create_split_categories(data):\n    data['sub_category1'],data['sub_category2'],data['sub_category3']=zip(*data['category_name'].\\\n                                                                  apply(lambda x: split_categories(x)))","7e1667a4":"create_split_categories(train_data)\ncreate_split_categories(validation_data)","b64b9e03":"def fill_missing_values(data):\n    data['category_name'].fillna('unknown_cat', inplace=True)\n    data['brand_name'].fillna('unknown_brand', inplace=True)\n    data['item_description'].fillna('unknown_description', inplace=True)\n    return data","1ab63b08":"fill_missing_values(train_data)\nfill_missing_values(validation_data)","5a608c44":"test_data = pd.read_csv('test_stg2.tsv',sep='\\t')\ntest = test_data.copy()","b5180e0e":"test_data.head(5)","53c7f08e":"test_data.shape","b5a4d3e6":"test_data.isnull().sum()","8815d91e":"create_split_categories(test_data)\nfill_missing_values(test_data)","0adbb9d1":"from collections import Counter\n\ntrain_cond_id = Counter(list(train_data['item_condition_id']))\nval_cond_id = Counter(list(validation_data['item_condition_id']))\n\nfig, (ax1,ax3) = plt.subplots(1,2, figsize=(15,8))\n\nax1.bar(train_cond_id.keys(), train_cond_id.values(), width=0.2, align='edge', label='Train')\nax1.set_xticks([1,2,3,4,5])\nax1.set_xlabel('item_condition_id')\nax1.legend()\n\n\nax3.bar(val_cond_id.keys(), val_cond_id.values(), width=-0.2, align='edge', label='Val')\nax3.set_xticks([1,2,3,4,5])\nax3.set_xlabel('item_condition_id')\nax3.legend()\n\nfig.show()","c345920f":"train_data['log_prices']= np.log(train_data['price']+1)","854ffa4c":"validation_data['log_prices']= np.log(validation_data['price']+1)","bf154900":"sns.kdeplot(data=train_data['price'])\nplt.title('Distribution of price')\nplt.grid(True)","f92e2765":"sns.kdeplot(data=train_data['log_prices'])\nplt.title('Distribution of log_prices')\nplt.grid(True)","f89f1e32":"train_data.head(3)","d81ef4dc":"train_category_name = Counter(list(train_data['category_name']))\nval_category_name = Counter(list(validation_data['category_name']))\ntest_category_name = Counter(list(test_data['category_name']))","820b6c8c":"print(\"Top 10 categories in train data: \")\ntrain_category_name.most_common(10)","2eafc830":"print(\"Top 10 categories in validation data: \")\nval_category_name.most_common(10)","991a4a83":"print(\"Top 10 categories in test data: \")\ntest_category_name.most_common(10)","590670ab":"train_brand_name = Counter(list(train_data['brand_name']))\nval_brand_name = Counter(list(validation_data['brand_name']))\ntest_brand_name = Counter(list(test_data['brand_name']))","702de911":"print(\"Top 10 brands in train data: \")\ntrain_brand_name.most_common(15)","c63213fc":"print(\"Top 10 brands in validation data: \")\nval_brand_name.most_common(15)","e9765371":"print(\"Top 10 brands in test data: \")\ntest_brand_name.most_common(15)","0d92f13c":"import nltk\nnltk.download('stopwords')","b3675d67":"#remove stop words\nfrom nltk.corpus import stopwords\n\nstop = stopwords.words('english')\n\ndef remove_stop_words(x):\n    x = ' '.join([i for i in x.lower().split(' ') if i not in stop])\n    return x","9d3c458e":"train_data['item_description'] = train_data['item_description'].apply(remove_stop_words)\nvalidation_data['item_description'] = validation_data['item_description'].apply(remove_stop_words)\ntest_data['item_description'] = test_data['item_description'].apply(remove_stop_words)","31a290b3":"from tqdm import tqdm\nimport re\n\ndef decontracted(phrase):\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase\n\ndef text_preprocessing(text_col):\n  preprocessed_total = []\n  for sentence in tqdm(text_col.values):\n    sent = decontracted(sentence)\n    sent = sent.replace('\\\\r', ' ')\n    sent = sent.replace('\\\\\"', ' ')\n    sent = sent.replace('\\\\n', ' ')\n    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n    preprocessed_total.append(sent.lower().strip())\n  return preprocessed_total","09bf7b87":"train_data['item_description']=text_preprocessing(train_data['item_description'])\nvalidation_data['item_description']=text_preprocessing(validation_data['item_description'])\ntest_data['item_description']=text_preprocessing(test_data['item_description'])\n\ntrain_data['name']=text_preprocessing(train_data['name'])\nvalidation_data['name']=text_preprocessing(validation_data['name'])\ntest_data['name']=text_preprocessing(test_data['name'])","cd4f18f2":"print(train_data['item_description'].iloc[33],len(train_data['item_description'].iloc[33].split(' ')))\nprint(train['item_description'].iloc[33],len(train['item_description'].iloc[33].split(' ')))","f98ad188":"def clean_category(cate_col):\n    \n    \n\n    cate_list = []\n    for i in tqdm(cate_col.values):\n        i = re.sub('[^A-Za-z0-9]+', ' ', i)\n        i = i.replace(' ','')\n        i = i.replace('&','_')\n        cate_list.append(i.strip())\n    \n    return cate_list","7959683f":"train_data['sub_category1'] = clean_category(train_data['sub_category1'])\nvalidation_data['sub_category1'] = clean_category(validation_data['sub_category1'])\ntest_data['sub_category1'] = clean_category(test_data['sub_category1'])\n\ntrain_data['sub_category2'] = clean_category(train_data['sub_category2'])\nvalidation_data['sub_category2'] = clean_category(validation_data['sub_category2'])\ntest_data['sub_category2'] = clean_category(test_data['sub_category2'])\n\ntrain_data['sub_category3'] = clean_category(train_data['sub_category3'])\nvalidation_data['sub_category3'] = clean_category(validation_data['sub_category3'])\ntest_data['sub_category3'] = clean_category(test_data['sub_category3'])","dade6100":"#brand name processing\ntrain_data['brand_name'] = clean_category(train_data['brand_name'])\nvalidation_data['brand_name'] = clean_category(validation_data['brand_name'])\ntest_data['brand_name'] = clean_category(test_data['brand_name'])","b9998942":"from sklearn.feature_extraction.text import CountVectorizer\n\ncountvectorizer=CountVectorizer().fit(train_data['sub_category1'])                 \nbow_cat1_train=countvectorizer.transform(train_data['sub_category1'])\nbow_cat1_val=countvectorizer.transform(validation_data['sub_category1'])\nbow_cat1_test=countvectorizer.transform(test_data['sub_category1'])\n# print(\"After Vectorization of sub category1 feature: \")\n# print(bow_cat1_train.shape)\n# print(bow_cat1_val.shape)\n# print(bow_cat1_test.shape)\n# print(\"Some Features are: \")\n# print(countvectorizer.get_feature_names())\n\ncountvectorizer=CountVectorizer().fit(train_data['sub_category2'])   \nbow_cat2_train=countvectorizer.transform(train_data['sub_category2'])\nbow_cat2_val=countvectorizer.transform(validation_data['sub_category2'])\nbow_cat2_test=countvectorizer.transform(test_data['sub_category2'])\n# print(\"After Vectorization of sub category2 feature: \")\n# print(bow_cat2_train.shape)\n# print(bow_cat2_val.shape)\n# print(bow_cat2_test.shape)\n# print(\"Some Features are: \")\n# print(countvectorizer.get_feature_names()[50:60])\n\ncountvectorizer=CountVectorizer().fit(train_data['sub_category3'])   \nbow_cat3_train=countvectorizer.transform(train_data['sub_category3'])\nbow_cat3_val=countvectorizer.transform(validation_data['sub_category3'])\nbow_cat3_test=countvectorizer.transform(test_data['sub_category3'])\n# print(\"After Vectorization of sub category3 feature: \")\n# print(bow_cat3_train.shape)\n# print(bow_cat3_val.shape)\n# print(bow_cat3_test.shape)\n# print(\"Some Features are: \")\n# print(countvectorizer.get_feature_names()[200:210])","1f6cb67a":"print('cat1 train shape:',bow_cat1_train.shape)\nprint('cat1 validation shape:',bow_cat1_val.shape)\nprint('cat1 test shape:',bow_cat1_test.shape)\nprint('cat2 train shape:',bow_cat2_train.shape)\nprint('cat2 validation shape:',bow_cat2_val.shape)\nprint('cat2 test shape:',bow_cat2_test.shape)\nprint('cat3 train shape:',bow_cat3_train.shape)\nprint('cat3 validation shape:',bow_cat3_val.shape)\nprint('cat3 test shape:',bow_cat3_test.shape)","0775314c":"train_data.head(3)","c01b89ed":"countvectorizer=CountVectorizer().fit(train_data['brand_name'])  \nbow_brand_train=countvectorizer.transform(train_data['brand_name'])\nbow_brand_val=countvectorizer.transform(validation_data['brand_name'])\nbow_brand_test=countvectorizer.transform(test_data['brand_name'])\n# print(\"After Vectorization of brand_name feature: \")\n# print(bow_brand_train.shape)\n# print(bow_brand_val.shape)\n# print(bow_brand_test.shape)\n# print(\"Some Features are: \")\n# print(countvectorizer.get_feature_names()[35:45])","2fbb1259":"bow_brand_train.toarray()","7a281858":"countvectorizer=CountVectorizer(min_df=10).fit(train_data['name'])  \nbow_name_train=countvectorizer.transform(train_data['name'])\nbow_name_val=countvectorizer.transform(validation_data['name'])\nbow_name_test=countvectorizer.transform(test_data['name'])\n# print(\"After Vectorization of name feature: \")\n# print(bow_name_train.shape)\n# print(bow_name_val.shape)\n# print(bow_name_test.shape)\n# print(\"Some Features are: \")\n# print(countvectorizer.get_feature_names()[210:220])","19be07d0":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidfvectorizer=TfidfVectorizer(ngram_range=(1,2),min_df=10,max_features=5000).fit(train_data['item_description']) \ntfidf_description_train=tfidfvectorizer.transform(train_data['item_description'])\ntfidf_description_val=tfidfvectorizer.transform(validation_data['item_description'])\ntfidf_description_test=tfidfvectorizer.transform(test_data['item_description'])\n# print(\"After Vectorization of item description feature: \")\n# print(tfidf_description_train.shape)\n# print(tfidf_description_val.shape)\n# print(tfidf_description_test.shape)\n# print(\"Some Features are: \")\n# print(tfidfvectorizer.get_feature_names()[222:234])","8ce9ee8e":"from scipy.sparse import csr_matrix\n\nfeatures_train = csr_matrix(pd.get_dummies(train_data[['item_condition_id', 'shipping']],sparse=True).values)\nfeatures_val = csr_matrix(pd.get_dummies(validation_data[['item_condition_id', 'shipping']],sparse=True).values)\nfeatures_test = csr_matrix(pd.get_dummies(test_data[['item_condition_id', 'shipping']],sparse=True).values)\nprint(features_train.shape)\nprint(features_val.shape)\nprint(features_test.shape)","a7db9ded":"from scipy.sparse import hstack\nX_train=hstack((bow_cat1_train,bow_cat2_train,bow_cat3_train,bow_brand_train,bow_name_train,tfidf_description_train,features_train)).tocsr()\nX_val=hstack((bow_cat1_val,bow_cat2_val,bow_cat3_val,bow_brand_val,bow_name_val,tfidf_description_val,features_val)).tocsr()\nX_test=hstack((bow_cat1_test,bow_cat2_test,bow_cat3_test,bow_brand_test,bow_name_test,tfidf_description_test,features_test)).tocsr()\nprint(\"Shape of train data: \",X_train.shape) \nprint(\"Shape of cv data: \",X_val.shape)   \nprint(\"Shape of test data: \",X_test.shape)   ","00b0c11d":"# from sklearn.linear_model import LinearRegression\n# from sklearn.metrics import mean_squared_error\n# from sklearn.metrics import mean_squared_log_error\n\n# linearregression=LinearRegression(normalize=True)\n# linearregression.fit(X_train,train_data['log_prices'])  \n# ytrain_predict=linearregression.predict(X_train)\n# yval_predict=linearregression.predict(X_val)\n# train_error=np.sqrt(mean_squared_error(train_data['log_prices'],ytrain_predict))\n# val_error=np.sqrt(mean_squared_error(validation_data['log_prices'],yval_predict))\n# print(\"RMSLE on train is {} RMSLE on cv is {}\".format(train_error,val_error))\n\n","19442d13":"# yval_linear=linearregression.predict(X_val)\n# ytest_linear=linearregression.predict(X_test)","84e3e9c1":"# %matplotlib inline\n\n# fig, ax = plt.subplots(1, 2,figsize=(16, 8))\n\n\n\n# sns.regplot(ax=ax[0],x=train_data['log_prices'][40:80],y=ytrain_predict[40:80],marker=\"+\")\n# sns.regplot(ax=ax[1],x=validation_data['log_prices'][40:80],y=yval_predict[40:80],color=\"g\",marker=\"+\")\n\n","932976cf":"# from sklearn.linear_model import RidgeCV\n\n# ridge_cv = RidgeCV(alphas=(0.01, 0.1, 1.0, 10.0), cv=3)\n# ridge_cv.fit(X_train, train_data['log_prices'])\n# yval_predict = ridge_cv.predict(X_val)\n# print(\"Optimal alpha:\",ridge_cv.alpha_)\n# ridge_RMSLE = np.sqrt(mean_squared_error(validation_data['log_prices'],yval_predict))\n# print(\"RMSLE:\",ridge_RMSLE)","e40ea31d":"\n# ytrain_predict = ridge_cv.predict(X_train)\n# print(\"Optimal alpha:\",ridge_cv.alpha_)\n# ridge_RMSLE = np.sqrt(mean_squared_error(train_data['log_prices'],ytrain_predict))\n# print(\"RMSLE:\",ridge_RMSLE)","8f242131":"# yval_ridge=ridge_cv.predict(X_val)\n# ytest_ridge=ridge_cv.predict(X_test)","8cfea757":"# submission_data = pd.read_csv('sample_submission_stg2.csv')\n# submission_data.head(5)","52801d2a":"# submission_data.shape","21a2a2a9":"# submission_data.loc[:, 'price'] = np.expm1(ytest_ridge)","a46447d9":"# submission_data.head(5)","5663ce9c":"# submission_data.to_csv('submission.csv', index=False)","e59373af":"# train_data = train[['name', 'price', 'item_condition_id', 'brand_name', 'shipping', 'item_description', 'cat_1', 'cat_2', 'cat_3']]\n# test = test[['name', 'item_condition_id', 'brand_name', 'shipping', 'item_description', 'cat_1', 'cat_2', 'cat_3']]","e0cbbf27":"#**Model 1:Linear regression**","13318bf9":"#**Vectorization**","02ddae36":"#**Text processing**"}}