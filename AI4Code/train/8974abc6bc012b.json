{"cell_type":{"6de80714":"code","9a5e5cab":"code","9ed207cf":"code","37476fec":"code","9ed7fe6a":"code","2fc4f644":"code","7bef4906":"code","35a49737":"code","576fef54":"code","7d342942":"code","54e0f40b":"code","3b5fe7ca":"code","def1976b":"code","77db7c86":"code","e76b0ca3":"code","dec83f3c":"code","1b394770":"code","959519cc":"code","367c5a3c":"code","4260c887":"code","014c4a03":"code","31b05f71":"code","db1d2b73":"code","0c22e197":"code","cb417c37":"code","5f6b9450":"code","d6ffe400":"code","e50b4703":"markdown"},"source":{"6de80714":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a5e5cab":"df=pd.read_csv('\/kaggle\/input\/position-salaries\/Position_Salaries.csv')\n\n\nprint(df)","9ed207cf":"df.info()","37476fec":"df['Position'].value_counts()","9ed7fe6a":"plt.scatter(df['Level'],df['Salary'])","2fc4f644":"X=df.iloc[:,1].values.reshape(-1,1)\ny=df.iloc[:,-1].values\n\nX","7bef4906":"y","35a49737":"from sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=0)","576fef54":"X_train","7d342942":"print(X_train.shape)\nprint(X_test.shape)","54e0f40b":"from sklearn.linear_model import LinearRegression\n\nL=LinearRegression()","3b5fe7ca":"L.fit(X_train , y_train)","def1976b":"y_pred = L.predict(X_test)","77db7c86":"from sklearn.metrics import r2_score , mean_squared_error , mean_absolute_error\n\nprint('The r2 score',r2_score(y_test,y_pred))\nprint('The rmse',np.sqrt(mean_squared_error(y_test,y_pred)))\nprint('The mean absolute error',mean_absolute_error(y_test,y_pred))","e76b0ca3":"plt.plot(X_test,y_pred,color='red')\nplt.scatter(X,y)\nplt.legend()\nplt.show()","dec83f3c":"from sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree = 5)","1b394770":"X_train_poly=poly.fit_transform(X_train)\nX_test_poly=poly.fit_transform(X_test)","959519cc":"print(X_train_poly)\n\n\n\n\n","367c5a3c":"print(X_test_poly)","4260c887":"L.fit(X_train_poly,y_train)","014c4a03":"y_pred_2 = L.predict(X_test_poly)","31b05f71":"print('The r2 score',r2_score(y_test,y_pred_2))\nprint('The rmse',np.sqrt(mean_squared_error(y_test,y_pred_2)))\nprint('The mean absolute error',mean_absolute_error(y_test,y_pred_2))","db1d2b73":"poly_2 = PolynomialFeatures(degree = 10)\nX_train_poly_2=poly_2.fit_transform(X_train)\nX_test_poly_2=poly_2.fit_transform(X_test)\nL.fit(X_train_poly_2,y_train)\ny_pred_3 = L.predict(X_test_poly_2)\n\n\n\nprint('The r2 score',r2_score(y_test,y_pred_3))\nprint('The rmse',np.sqrt(mean_squared_error(y_test,y_pred_3)))\nprint('The mean absolute error',mean_absolute_error(y_test,y_pred_3))","0c22e197":"poly_3 = PolynomialFeatures(degree = 8)\nX_train_poly_3=poly_3.fit_transform(X_train)\nX_test_poly_3=poly_3.fit_transform(X_test)\nL.fit(X_train_poly_3,y_train)\ny_pred_4 = L.predict(X_test_poly_3)\n\n\n\nprint('The r2 score',r2_score(y_test,y_pred_4))\nprint('The rmse',np.sqrt(mean_squared_error(y_test,y_pred_4)))\nprint('The mean absolute error',mean_absolute_error(y_test,y_pred_4))","cb417c37":"poly_4 = PolynomialFeatures(degree = 7)\nX_train_poly_4=poly_4.fit_transform(X_train)\nX_test_poly_4=poly_4.fit_transform(X_test)\nL.fit(X_train_poly_4,y_train)\ny_pred_5 = L.predict(X_test_poly_4)\n\n\n\nprint('The r2 score',r2_score(y_test,y_pred_5))\nprint('The rmse',np.sqrt(mean_squared_error(y_test,y_pred_5)))\nprint('The mean absolute error',mean_absolute_error(y_test,y_pred_5))","5f6b9450":"poly_5 = PolynomialFeatures(degree = 6)\nX_train_poly_5=poly_5.fit_transform(X_train)\nX_test_poly_5=poly_5.fit_transform(X_test)\nL.fit(X_train_poly_5,y_train)\ny_pred_6 = L.predict(X_test_poly_5)\n\n\n\nprint('The r2 score',r2_score(y_test,y_pred_6))\nprint('The rmse',np.sqrt(mean_squared_error(y_test,y_pred_6)))\nprint('The mean absolute error',mean_absolute_error(y_test,y_pred_6))","d6ffe400":"\nplt.scatter(X_test,y_pred_6,color='red')\nplt.scatter(X,y,marker='+',color='green')\nplt.legend()\nplt.show()","e50b4703":"#   **Hence the polynomial degree should be 6 for the above dataset as it is giving the maximum r2score and minimum MAE and RMSE   **"}}