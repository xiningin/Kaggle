{"cell_type":{"e7c1ceb4":"code","fc9913e7":"code","936a5e12":"code","0f9cbe7b":"code","13c23f3a":"code","4c566c5b":"code","c30661f8":"code","fde20934":"code","df727529":"code","fe18b6ef":"code","c3428ba7":"code","64a682b6":"code","0e730e72":"code","68e6c619":"code","6221b495":"code","1ef7fd01":"code","bdf2cb19":"code","46eac406":"code","12892932":"code","5e1fb572":"code","c9cec885":"code","c851f334":"code","af2f3c58":"code","d356e895":"code","568dd777":"code","4466606e":"code","68193304":"code","6c0324c2":"code","79899193":"code","abcb024d":"code","01467ebd":"code","0a15e76a":"code","a6757937":"code","ca71d237":"code","3f7c3433":"code","cd60f094":"code","bc8febf3":"code","52b520bb":"code","4159a1b6":"code","59bf532c":"code","6d0fd962":"code","837cf0c1":"code","26d50846":"code","5600e35f":"code","f44e0738":"code","d553bb8f":"code","ecdf25c7":"code","337727ca":"code","94c2fd20":"code","f2af3767":"code","bf7a2b85":"code","6793ce6d":"code","0a50388b":"code","1b2e9168":"markdown","7da4199e":"markdown","db18aacd":"markdown","18014a6d":"markdown","144f6ffa":"markdown","561c4a32":"markdown","2abc98c1":"markdown","548f5685":"markdown","fa103754":"markdown","3bbd9f15":"markdown","7c8bc6ce":"markdown","afbc3847":"markdown","fadf0fc6":"markdown","58e373cf":"markdown","5b63b8a2":"markdown","4639ccef":"markdown","86f6955c":"markdown","a96f0f9b":"markdown","a20745d3":"markdown","7e0da5bc":"markdown","1a7f4cc2":"markdown","10c9abc3":"markdown","9152650c":"markdown","4ebaa4e4":"markdown"},"source":{"e7c1ceb4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        continue\n        #print(os.path.join(dirname, filename))\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc9913e7":"# !pip install jovian --upgrade --quiet","936a5e12":"import os\nimport torch\nimport tarfile\nimport torchvision\nimport torch.nn as nn\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nfrom torchvision.transforms import ToTensor\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.datasets.utils import download_url","0f9cbe7b":"transform_train = transforms.Compose([\n    \n    transforms.Resize((150,150)), #becasue vgg takes 150*150\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n    \n])\n\n#Augmentation is not done for test\/validation data.\ntransform_test = transforms.Compose([\n    \n    transforms.Resize((150,150)), #becasue vgg takes 150*150\n    transforms.ToTensor(),\n    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n    \n])","13c23f3a":"train_ds = ImageFolder('..\/input\/intel-image-classification\/seg_train\/seg_train', transform=transform_train)\ntest_ds = ImageFolder('..\/input\/intel-image-classification\/seg_test\/seg_test', transform=transform_test)\npred_ds = ImageFolder('\/kaggle\/input\/intel-image-classification\/seg_pred\/', transform=transform_test)","4c566c5b":"type(pred_ds)","c30661f8":"len(train_ds),len(test_ds),len(pred_ds)","fde20934":"image,label  = train_ds[0]\nprint(image.shape, label)","df727529":"image","fe18b6ef":"image.numpy()","c3428ba7":"# from matplotlib import pyplot as plt\n# plt.imshow(image.numpy())","64a682b6":"batch_size=128\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(test_ds, batch_size, num_workers=4, pin_memory=True)\npred_dl = DataLoader(pred_ds, batch_size, num_workers=4, pin_memory=True)","0e730e72":"batch_size=128\ntrain_dl2 = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)","68e6c619":"for images, _ in train_dl2:\n    print('images.shape:', images.shape)\n    plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n    break","6221b495":"import pathlib\nroot = pathlib.Path('..\/input\/intel-image-classification\/seg_train\/seg_train')\nclasses = sorted([j.name.split('\/')[-1] for j in root.iterdir()])\nclasses","1ef7fd01":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","bdf2cb19":"from torchvision import models \nmodelvgg = models.vgg19(pretrained = True)","46eac406":"modelresnet50 = models.resnet50(pretrained = True)","12892932":"for p in modelvgg.parameters() : \n    p.requires_grad = False","5e1fb572":"for q in modelresnet50.parameters() :\n    q.requires_grad = False","c9cec885":" modelvgg.classifier = nn.Sequential(\n  nn.Linear(in_features=25088, out_features=2048) ,\n  nn.ReLU(),\n  nn.Linear(in_features=2048, out_features=512) ,\n  nn.ReLU(),\n  nn.Dropout(p=0.6), \n    \n  nn.Linear(in_features=512 , out_features=6),\n  nn.LogSoftmax(dim=1)  \n)","c851f334":" modelresnet50.fc = nn.Sequential(\n  nn.Linear(in_features=2048, out_features=1024) ,\n  nn.ReLU(),\n  nn.Linear(in_features=1024, out_features=512) ,\n  nn.ReLU(),\n  nn.Dropout(p=0.6), \n  nn.Linear(in_features=512 , out_features=6),\n  nn.LogSoftmax(dim=1)  \n)","af2f3c58":"modelresnet50","d356e895":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","568dd777":"# class IntelCnnModel(ImageClassificationBase):\n#     def __init__(self):\n#         super().__init__()\n#         self.network = nn.Sequential(\n#             nn.Conv2d(3, 32, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n\n#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n\n#             nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n\n#             nn.Flatten(), \n#             nn.Linear(256*4*4, 1024),\n#             nn.ReLU(),\n#             nn.Linear(1024, 512),\n#             nn.ReLU(),\n#             nn.Linear(512, 6))\n        \n#     def forward(self, xb):\n#         return self.network(xb)","4466606e":"class IntelCnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = modelvgg\n        \n    def forward(self, xb):\n        return self.network(xb)","68193304":"class IntelCnnModelresnet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = modelresnet50\n        \n    def forward(self, xb):\n        return self.network(xb)","6c0324c2":"model = IntelCnnModel()\nmodel2 = IntelCnnModelresnet()","79899193":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')","abcb024d":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","01467ebd":"class DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","0a15e76a":"device = get_default_device()\ndevice","a6757937":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\npred_dl = DeviceDataLoader(pred_dl, device)\nto_device(model, device);","ca71d237":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()   #eval() is called to tell model that now it is validation mode and so don't perform stuff like dropout,backpropagation etc..\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train() #eval() is called to tell model that now it is training mode and so  perform stuff like dropout,backpropagation etc..\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","3f7c3433":"# model = to_device(IntelCnnModel(), device)\nmodel = to_device(model, device)\nevaluate(model, val_dl)","cd60f094":"# model = to_device(IntelCnnModel(), device)\nmodel2 = to_device(model2, device)\nevaluate(model2, val_dl)","bc8febf3":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 0.00001\nhistory = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","52b520bb":"num_epochs = 5\nopt_func = torch.optim.Adam\nlr = 0.000001\nhistory = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","4159a1b6":"val = evaluate(model, val_dl)","59bf532c":"val","6d0fd962":"val = {'val_loss': 0.25728750228881836, 'val_acc': 0.9077381491661072}","837cf0c1":"lrs = [.00001,.000001]\nepochs = [10,5]\njovian.log_hyperparameters(arch = arch,lrs = lrs,epochs = epochs)\njovian.log_metrics(test_loss=val['val_loss'], test_acc=val['val_acc'])","26d50846":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 0.00001\nhistory = fit(num_epochs, lr, model2, train_dl, val_dl, opt_func)","5600e35f":"num_epochs = 5\nopt_func = torch.optim.Adam\nlr = 0.0001\nhistory = fit(num_epochs, lr, model2, train_dl, val_dl, opt_func)","f44e0738":"val2 = evaluate(model2, val_dl)\nval2","d553bb8f":"# val2 = {'val_loss': 0.28198978304862976, 'val_acc': 0.8945777416229248}","ecdf25c7":"lrs2 = [.00001,.000001]\nepochs2 = [10,5]\njovian.log_hyperparameters(arch = arch,lrs = lrs2,epochs = epochs2)\njovian.log_metrics(test_loss=val2['val_loss'], test_acc=val2['val_acc'])","337727ca":"# def plot_accuracies(history):\n#     accuracies = [x['val_acc'] for x in history]\n    \n#     plt.plot(accuracies, '-x')\n#     plt.xlabel('epoch')\n#     plt.ylabel('accuracy')\n#     plt.title('Accuracy vs. No. of epochs');","94c2fd20":"# def plot_losses(history):\n#     train_losses = [x.get('train_loss') for x in history]\n#     val_losses = [x['val_loss'] for x in history]\n#     plt.plot(train_losses, '-bx')\n#     plt.plot(val_losses, '-rx')\n#     plt.xlabel('epoch')\n#     plt.ylabel('loss')\n#     plt.legend(['Training', 'Validation'])\n#     plt.title('Loss vs. No. of epochs');","f2af3767":"def predict_single(input,label, model):\n    input = to_device(input,device)\n    inputs = input.unsqueeze(0)   # unsqueeze the input i.e. add an additonal dimension\n    predictions = model(inputs)\n    prediction = predictions[0].detach().cpu()\n    print(f\"Prediction is {np.argmax(prediction)} of Model whereas given label is {label}\")","bf7a2b85":"models = [modelvgg, modelresnet50]","6793ce6d":"for i,img in enumerate(pred_ds):\n    for modell in models:\n        predict_single(img[0],img[1],modell)\n    break","0a50388b":"torch.save(model.state_dict(), 'modelvgg_intel.pth')\ntorch.save(model.state_dict(), 'modelresnet50_intel.pth')","1b2e9168":"add your own classifier according to need","7da4199e":"Can you plot some images?","db18aacd":"Create a base class for image classificaiton","18014a6d":"Get the default device and select GPU if available else select cpu","144f6ffa":"EDA","561c4a32":"# Transformation function that will transform images","2abc98c1":"Define a Function that can move tensors and model to specific device ","548f5685":"vgg","fa103754":"2. what is size of image?","3bbd9f15":"Function that will plot accuracy graph","7c8bc6ce":"1. How many images are present in train,test, pred folder","afbc3847":"Create classes with directory name","fadf0fc6":"Create a function that can calculate accuracy","58e373cf":"First let move model to gpu and then evaluate model once before training","5b63b8a2":"Create a dataloader that loads data in batches","4639ccef":"freeze all layers","86f6955c":"create an inherited class form above base class that will be our first model architecture","a96f0f9b":"Create dataset from Image Folder","a20745d3":"Now define some functions that will be used during training","7e0da5bc":"# Model2","1a7f4cc2":"Get currently using device name","10c9abc3":"Call data loader and move tensor and model to device","9152650c":"Function that will plot loss graph","4ebaa4e4":"3. print images of all categories"}}