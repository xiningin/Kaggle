{"cell_type":{"1e268850":"code","77efe9ae":"code","f38548d2":"code","1b4e4a79":"code","f10e95e5":"code","ed75414e":"code","2363e5a9":"code","bf12c7c8":"code","19c43ed5":"code","2203b408":"code","838d8368":"code","13819a41":"code","c188ea1d":"code","b264269f":"code","81b2d14f":"code","e5b01f00":"code","fbbea954":"code","c8ea452b":"code","263300e9":"code","6f08192c":"code","7f93dab2":"code","4d850107":"code","fd3ec8dd":"code","cf3ee484":"code","071af7ab":"code","226e9a50":"code","d21732aa":"code","d6e6a874":"code","68159494":"code","37c654de":"code","6dad2eb9":"code","e3463881":"code","b97cbb11":"code","a4332d7c":"code","86537c0d":"code","fb654ab8":"code","1bc25aaa":"code","4b6a2be0":"code","20320431":"code","06761d36":"code","02ca15da":"code","93520316":"code","478752ea":"code","a34b85a2":"code","a7809095":"code","3eea5100":"code","c99e9087":"code","cfe4e230":"markdown","faaefd64":"markdown","08cff6f7":"markdown","a3883e15":"markdown","2b9ef7ea":"markdown","4ab8d5ad":"markdown","43ee13e6":"markdown","da3ac950":"markdown","e715feef":"markdown","63d8cb93":"markdown","db55d0ec":"markdown","e769f3f2":"markdown","5dda1bcb":"markdown","787d73bc":"markdown","980f4cb6":"markdown","c60cfcf1":"markdown","b100d5dc":"markdown","48304e5a":"markdown","17626a3d":"markdown","bb038e16":"markdown","cbfa9ac8":"markdown","4c04a2f5":"markdown","3c195ad2":"markdown","e122038f":"markdown","eee5bdc4":"markdown","d598d1e4":"markdown","17a03a1f":"markdown","6c3791ae":"markdown","4bb63578":"markdown","4b547666":"markdown","668626e5":"markdown"},"source":{"1e268850":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import preprocessing \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","77efe9ae":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndata_dir = '\/kaggle\/input\/titanic'\nos.listdir(data_dir)","f38548d2":"train_dataset = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","1b4e4a79":"train_dataset.head()","f10e95e5":"temp = pd.DataFrame(index=train_dataset.columns)\ntemp['data_type'] = train_dataset.dtypes\ntemp['null_count'] = train_dataset.isnull().sum()\ntemp['unique_count'] = train_dataset.nunique()\ntemp","ed75414e":"categorical_dtypes = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\nfor i in categorical_dtypes:\n    print('************ Value Count in', i, '************')\n    print(train_dataset[i].value_counts())\n    print('')","2363e5a9":"embarked_mode = train_dataset['Embarked'].mode()\nembarked_mode[0]","bf12c7c8":"train_dataset['Embarked'].fillna(value=embarked_mode[0], inplace=True)","19c43ed5":"#Copied: https:\/\/www.codeastar.com\/data-wrangling\/\nindex_NaN_age = list(train_dataset[\"Age\"][train_dataset[\"Age\"].isnull()].index)\n \nfor i in index_NaN_age:\n  age_mean = train_dataset[\"Age\"].mean()\n  age_std = train_dataset[\"Age\"].std()\n  age_pred_w_spc = train_dataset[\"Age\"][((train_dataset['SibSp'] == train_dataset.iloc[i][\"SibSp\"]) & (train_dataset['Parch'] == train_dataset.iloc[i][\"Parch\"]) & (train_dataset['Pclass'] == train_dataset.iloc[i][\"Pclass\"]))].mean()\n  age_pred_wo_spc = np.random.randint(age_mean - age_std, age_mean + age_std)\n \n  if not np.isnan(age_pred_w_spc):\n        train_dataset['Age'].iloc[i] = age_pred_w_spc\n  else:\n    train_dataset['Age'].iloc[i] = age_pred_wo_spc","2203b408":"all_heat = sns.heatmap(train_dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\",\"Embarked\",\"Survived\"]].corr(), annot=True)\nplt.show()","838d8368":"train_dataset = train_dataset.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)","13819a41":"train_dataset.head()","c188ea1d":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder() \n\n\n#Sex Column  \ntrain_dataset['Sex']= label_encoder.fit_transform(train_dataset['Sex']) \n\n#Embarked Column\ntrain_dataset['Embarked']= label_encoder.fit_transform(train_dataset['Embarked'])\n\n# # Pclass Column\n# train_dataset = train_dataset.astype({'Pclass': 'object'})\n# train_dataset['Pclass']= label_encoder.fit_transform(train_dataset['Pclass'])","b264269f":"x_train_dataset = train_dataset.drop(['Survived'], axis = 1)\ny_train_dataset = train_dataset['Survived']","81b2d14f":"x_train_dataset.head()","e5b01f00":"y_train_dataset","fbbea954":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train_dataset = sc.fit_transform(x_train_dataset)","c8ea452b":"test_dataset = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","263300e9":"test_dataset.isnull().sum()\n\n# checktestDataset = test_dataset[test_dataset['Age'] >= 60]\n# checktestDataset.head(20)\n\n# checktestDataset = test_dataset[test_dataset['Fare'].isnull()==True]\n# checktestDataset","6f08192c":"mean_fare = test_dataset['Fare'].mean()\nmean_fare","7f93dab2":"test_dataset['Fare'].fillna(value=mean_fare, inplace=True)","4d850107":"embarked_mode = test_dataset['Embarked'].mode()\nembarked_mode[0]","fd3ec8dd":"test_dataset['Embarked'].fillna(value=embarked_mode[0], inplace=True)","cf3ee484":"#Copied: https:\/\/www.codeastar.com\/data-wrangling\/\nindex_NaN_age = list(test_dataset[\"Age\"][test_dataset[\"Age\"].isnull()].index)\n \nfor i in index_NaN_age:\n  age_mean = test_dataset[\"Age\"].mean()\n  age_std = test_dataset[\"Age\"].std()\n  age_pred_w_spc = test_dataset[\"Age\"][((test_dataset['SibSp'] == test_dataset.iloc[i][\"SibSp\"]) & (test_dataset['Parch'] == test_dataset.iloc[i][\"Parch\"]) & (test_dataset['Pclass'] == test_dataset.iloc[i][\"Pclass\"]))].mean()\n  age_pred_wo_spc = np.random.randint(age_mean - age_std, age_mean + age_std)\n \n  if not np.isnan(age_pred_w_spc):\n        test_dataset['Age'].iloc[i] = age_pred_w_spc\n  else:\n    test_dataset['Age'].iloc[i] = age_pred_wo_spc","071af7ab":"test_dataset.shape","226e9a50":"test_dataset.columns","d21732aa":"test_dataset = test_dataset.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)","d6e6a874":"test_dataset","68159494":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder() \n\n#Sex Column  \ntest_dataset['Sex']= label_encoder.fit_transform(test_dataset['Sex']) \n\n#Embarked Column\ntest_dataset['Embarked']= label_encoder.fit_transform(test_dataset['Embarked'])\n\n# # Pclass Column\n# train_dataset = train_dataset.astype({'Pclass': 'object'})\n# train_dataset['Pclass']= label_encoder.fit_transform(train_dataset['Pclass'])","37c654de":"test_dataset","6dad2eb9":"from sklearn.preprocessing import StandardScaler\nsc_test = StandardScaler()\ntest_dataset = sc_test.fit_transform(test_dataset)","e3463881":"Accuracy_Scores = []","b97cbb11":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(x_train_dataset, y_train_dataset)","a4332d7c":"y_pred_Logistic = classifier.predict(test_dataset)\nacc_Logistic = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_Logistic)\nacc_Logistic","86537c0d":"len(y_pred_Logistic), len(test_dataset)","fb654ab8":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=15)\nclassifier.fit(x_train_dataset, y_train_dataset)\ny_pred = classifier.predict(test_dataset)","1bc25aaa":"y_pred_KNN = classifier.predict(test_dataset)\nacc_KNN = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_KNN)\nacc_KNN","4b6a2be0":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train_dataset, y_train_dataset)","20320431":"y_pred_RF = classifier.predict(test_dataset)\nacc_RF = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_RF)\nacc_RF","06761d36":"from sklearn.svm import SVC\nclassifier = SVC()\nclassifier.fit(x_train_dataset, y_train_dataset)\ny_pred = classifier.predict(test_dataset)","02ca15da":"y_pred_SVC = classifier.predict(test_dataset)\nacc_SVC = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_SVC)\nacc_SVC","93520316":"len(y_pred_SVC), test_dataset.shape","478752ea":"print(\"Accuracy Scores:\")\nModel_Names = ['Logistic Regresion', 'KNN', 'Random Forest', 'SVC']\nfor i in range(len(Model_Names)):\n    print(Model_Names[i],'---->',Accuracy_Scores[i])","a34b85a2":"stop\nAccuracy Scores:\n\nLogistic Regresion ----> 0.7979900124843945\nKNN ----> 0.8036329588014981\nRandom Forest ----> 0.8058926342072409\nSVC ----> 0.823820224719101\n\nAccuracy Scores:\nLogistic Regresion ----> 0.7879026217228464\nKNN ----> 0.8238451935081148\nRandom Forest ----> 0.8160049937578027\nSVC ----> 0.8260299625468166\n\nAccuracy Scores:\nLogistic Regresion ----> 0.7879026217228464\nKNN ----> 0.8092134831460674\nRandom Forest ----> 0.8160049937578027\nSVC ----> 0.8260299625468166","a7809095":" test_df = pd.read_csv('..\/input\/titanic\/test.csv')\n submission = pd.DataFrame({\n                             'PassengerId': test_df['PassengerId'],\n                             'Survived': y_pred_SVC\n                           })\n\n submission.to_csv('prediction_without_Ensemble2.csv', index = False)\n print('Done Saving')","3eea5100":" from statistics import mode\n final_pred_Max_Voting = np.array([])\n for i in range(0, len(test_dataset)):\n     final_pred_Max_Voting = np.append(final_pred_Max_Voting, mode([y_pred_Logistic[i], y_pred_KNN[i], y_pred_RF[i], y_pred_SVC[i], y_pred_SVC[i]]))","c99e9087":" test_df = pd.read_csv('\/content\/test.csv')\n submission = pd.DataFrame({\n                              'PassengerId': test_df['PassengerId'],\n                             'Survived': final_pred_Max_Voting\n                           })\n\n submission.to_csv('prediction_with_Ensemble_Max_Voting3.csv', index = False)\n print('Done Saving')","cfe4e230":"## Imports","faaefd64":"#### For the `Fare` column","08cff6f7":"### Data Exploration","a3883e15":"## Different Models","2b9ef7ea":"#### For `Age` column","4ab8d5ad":"### Lets Impute the missing values","43ee13e6":"### Assigning `x_train_dataset` and `y_train_dataset`","da3ac950":"#### Before that let's have a lok at the heat Map and the correlation of varibaled on each other","e715feef":"### Encoding the categorical data","63d8cb93":"#### For the `Age` column","db55d0ec":"## train_dataset","e769f3f2":"### Feature Scaling on `test_dataset`","5dda1bcb":"### KNN","787d73bc":"### Random Forest","980f4cb6":"Creating the submission file","c60cfcf1":"### SVC","b100d5dc":"### Let's have a look at the categorical variable","48304e5a":"### Logistic Regression","17626a3d":"## test_dataset","bb038e16":"### Droping all the unwanted Columns","cbfa9ac8":"#### For the `Embarked` column","4c04a2f5":"## Lets Create the Submission File","3c195ad2":"### Max Voting","e122038f":"## Lets have a look at each of their Accuracies","eee5bdc4":"### Droping all the unwanted column","d598d1e4":"### Lets Impute the missing values","17a03a1f":"## Data dir's","6c3791ae":"### Encoding the categorical data","4bb63578":"## Applying Ensemble Techniques","4b547666":"#### For `Embarked` column","668626e5":"### Feature Scaling on `x_train_dataset`"}}