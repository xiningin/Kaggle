{"cell_type":{"fc1ca3c1":"code","4e18e8b4":"code","e63ee702":"code","a5203654":"code","1d5b6593":"code","29d7b886":"code","33b33dfb":"code","744d9b1c":"code","01dbaaaf":"code","ad2f4369":"code","467ebe61":"code","a7c3f527":"code","cad9d1a6":"code","93ae14cf":"code","de8ad6e8":"code","cfa8b250":"code","b43daca0":"code","b85090e9":"code","27c73566":"code","e250ba2d":"markdown","caa861cf":"markdown","18e10a84":"markdown","e6b56051":"markdown","0c26aadf":"markdown","6e5ccbe9":"markdown","f06418de":"markdown","73a61789":"markdown","db4abafe":"markdown","85d802f4":"markdown","2c3c734f":"markdown","4194a3d9":"markdown","fa642043":"markdown","f949c0aa":"markdown","d1cf1161":"markdown","c49a48cb":"markdown","c0bc84d1":"markdown","ef5d0948":"markdown","03519280":"markdown","bf84fc44":"markdown","8da6db61":"markdown","b207f828":"markdown","09db4bc1":"markdown"},"source":{"fc1ca3c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e18e8b4":"df_defects = pd.read_csv(\"..\/input\/monthly-defect-data-simulated\/software_defects_simulated.csv\")\ndf_defects['created_date'] = pd.to_datetime(df_defects['created_date'], format=\"%Y-%m-%d\")\ndf_defects.set_index('created_date', inplace=True)\ndf_defects = df_defects.groupby(pd.Grouper(freq='M')).sum()\n\n","e63ee702":"df_defects.head()","a5203654":"df_defects.index\n","1d5b6593":"df_defects.isnull().sum()","29d7b886":"df_defects.plot(figsize=(12, 6), title=\"Monthly Defect\", c=\"orange\")\n","33b33dfb":"from statsmodels.tsa.filters.hp_filter import hpfilter\nhp_cycle, hp_trend = hpfilter(df_defects['count'], lamb=14400)\ndf_defects['trend'] = hp_trend\ndf_defects[['count', 'trend']].plot(legend=True, figsize=(12, 5))\ndf_defects.drop('trend', inplace=True, axis=1)","744d9b1c":"from statsmodels.tsa.seasonal import seasonal_decompose\nresults = seasonal_decompose(df_defects['count'], model='additive', period=12)\nresults.plot();","01dbaaaf":"from statsmodels.tsa.stattools import adfuller\ndef ad_fuller_test(var):\n    results_stats = adfuller(var)\n    print('ADF Statistic: %f' % results_stats[0])\n    print('p-value: %f' % results_stats[1])\n    print('Critical Values:')\n    for key, value in results_stats[4].items():\n        print('\\t%s: %.3f' % (key, value))","ad2f4369":"ad_fuller_test(df_defects['count'])","467ebe61":"from statsmodels.tsa.stattools import acf\nacf(df_defects['count'])\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(df_defects, lags=12);","a7c3f527":"from pandas.plotting import lag_plot\nlag_plot(df_defects['count'])","cad9d1a6":"from statsmodels.graphics.tsaplots import month_plot\nmonth_plot(df_defects['count']);","93ae14cf":"df_defects.shape","de8ad6e8":"#split the dataset in train and test\ntrain = df_defects.iloc[:40]\ntest = df_defects.iloc[40:]\nstart = len(train)\nend = len(train) + len(test)-1","cfa8b250":"!pip install pmdarima","b43daca0":"from pmdarima import  auto_arima\nstepwise_fit = auto_arima(train['count'],start_p=0,start_q=0,max_p=6,max_q=6,seasonal=True,trace=True,m=15,\n                         start_P=0,start_Q=0,max_P=6,max_Q=6,D=1,stepwise=True)\nstepwise_fit.summary()","b85090e9":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tools.eval_measures import rmse\n\nmodel_sarimax = SARIMAX(train['count'],order=(0,1,0),seasonal_order=(0,1,0,15))\nmodel_sarimax_fit = model_sarimax.fit()\npred_sarimax = model_sarimax_fit.predict(start,end,typ='levels').rename('SARIMAX Predictions')\ntest.plot(figsize=(12,8),legend=True)\npred_sarimax.plot(legend=True)\nerror = rmse(test['count'],pred_sarimax)\nprint(\"Test Mean\",test.mean())\nprint(\"SARIMAX Predictions Mean\",pred_sarimax.mean())\nprint(\"SARIMAX Predictions Error\",error)","27c73566":"#Forecast into the future - Monthly forecast\nmodel_fr = SARIMAX(df_defects['count'],order=(0,1,0),seasonal_order=(0,1,0,15))\nresults = model_fr.fit()\nforecast = results.predict(len(df_defects),len(df_defects)+16,typ='levels').rename('SARIMAX Forecast')\ndf_defects['count'].plot(figsize=(12,8),legend=True)\nforecast.plot(legend=True)","e250ba2d":"Visualising Trend shows that a normal distribution","caa861cf":"Model Results\n Test Mean count    38.888889\n SARIMAX Predictions Mean 11.555555555553997\n SARIMAX Predictions Error 51.99572632010866\n\n So the model is not that great since predictions mean is far from test mean. That is ok since we have a very short dataset to train our model","18e10a84":" # Hodrecick - Prescott Filter for Trend analysis\n \n Visulaise the defect count trend","e6b56051":"# ACF Theory Implementation\n\nFrom above analysis and statistical test , it is clear that time series is not stationary . This can also be confirmed through ACF plots","0c26aadf":"As seen in the visualisation there seems to be 2 seassonal peaks one in Feb and June . This states that there is some event which\nis resposible for defect count increase in these 2 months .","6e5ccbe9":"# Predict Future Values- Defect Count","f06418de":"# ETS Models  - Error  - Trend - Seasonality ","73a61789":"# Test Train Data Split","db4abafe":"# SARIMA Time Series Model Implementation \n\nIdentify the recommended parameters for the SARIMA model","85d802f4":"# Seasonality Check\n\nIdentify the peak season ","2c3c734f":"Exploratary Data anlysis & Visualisation : This step is necessary beore modelling of any data.\n\nCheck for missing values","4194a3d9":"The dataset has a date time colum as created_date , check for index of the data frame","fa642043":"# Time Series - SARIMA Model Tutorial\n\n###  This tutorial notebook is present how SARIMA model can be used for pedicting or forecasting future based on historical records","f949c0aa":"Becuase of general increase there is some sort of auto-corelation as visual lag plot .For stationary data we should see sharp drop in the graph, which in our case is not\nhence our time series data is not stationary","d1cf1161":"Ignore the warning since the simulated dataset has very less values. ","c49a48cb":"The dataset has Index column as DatetimeIndex which is the pre-requiste for anytime series analysis\n","c0bc84d1":"# Augmented Dickey-Fuller test\n\nThe intuition behind a unit root test is that it determines how strongly a time series is defined by a trend.\n    \n    Null Hypothesis (H0): If failed to be rejected, it suggests the time series has a unit root, meaning it is non-stationary.\n    It has some time dependent structure.\n    \n    Alternate Hypothesis (H1): The null hypothesis is rejected; it suggests the time series does not have a unit root,\n    meaning it is stationary. It does not have time-dependent structure.\n    \n    We interpret this result using the p-value from the test. A p-value below a threshold (such as 5% or 1%) suggests we\n    reject the null hypothesis (stationary),\n    otherwise a p-value above the threshold suggests we fail to reject the null hypothesis (non-stationary).\n","ef5d0948":"So its good that our dataset does not have any missing values . Hence further we do not need to go to handle missing data.\nWe can go ahead and plot the data to visualise the defect cout over time","03519280":" ### Results . p-value 0.322179 > .05  - Failed to Reject Null hypothesis\n    # Time series has a unit root and is non-stationary.","bf84fc44":"ETS visualisation shows that there is trend and seasonality . Hence the time series is not stationary. Let us further check for stationaity\nusing statistical test.","8da6db61":"For any timeseries data should be presented in a time variable format. In pandas dataframe the data should be loaded with time colum as DateTimeIndex\n","b207f828":"Recommended Model for SARIMA \nSARIMAX(0, 1, 0)x(0, 1, 0, 15)\t","09db4bc1":"Data exploration "}}