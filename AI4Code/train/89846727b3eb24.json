{"cell_type":{"85bea3f8":"code","ebc4f1ce":"code","8d290693":"code","e26f2e31":"code","21e6ba1e":"code","fb498ee8":"code","17d811fe":"code","457c65a5":"code","b0ab329f":"code","62e0ee67":"code","0dfe7fcd":"code","84190d7e":"code","abf22037":"code","928ccdb5":"code","69eccdff":"code","078c0b36":"code","fbf5ed9d":"code","eb10c9dc":"code","9a891add":"code","52cf7751":"code","756029d8":"code","03215c9f":"code","00eada03":"code","87038d02":"code","7ad910f0":"code","ead5d7f3":"code","d94145be":"code","c7bb959e":"code","ec060754":"code","33e91cc6":"code","5170ca0a":"code","df552e11":"code","c6a0c2de":"code","d67b8ddf":"code","32538172":"code","93079ed1":"code","598af6b4":"code","fea4285d":"code","307556e9":"code","ac0cc696":"code","03db5e5d":"code","cf90f25c":"code","4d498947":"code","87650e66":"code","9d889c24":"code","fa4e8f81":"code","9c4cca77":"code","c9b44398":"code","088474ce":"code","51c225f6":"code","09355700":"code","4fcc26fa":"code","638e8655":"code","2be3d800":"code","3f18a3fd":"markdown","48d4e0fa":"markdown","2c4e780d":"markdown","e3240e34":"markdown","97247bf9":"markdown","17384d5b":"markdown","54b59e0c":"markdown","ff94e982":"markdown","f6bd7ca9":"markdown","644bcc0e":"markdown","230dc28c":"markdown","2c4ca8ea":"markdown","b3204e71":"markdown","12b41275":"markdown","8cbbdb08":"markdown","0ec1fde9":"markdown","c46150bf":"markdown","bd6fd2c5":"markdown","72485b6f":"markdown","a558c55b":"markdown","73130313":"markdown","7981ea33":"markdown","a445a9af":"markdown","2381d304":"markdown","484bc348":"markdown","b166491c":"markdown","f2e0e56f":"markdown","7ed62e06":"markdown","8a8f5e0b":"markdown","30b78f43":"markdown","76b5192c":"markdown"},"source":{"85bea3f8":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport math\nfrom tqdm import tqdm\nfrom PIL import Image\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import *\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model","ebc4f1ce":"candle_data = pd.read_csv('..\/input\/quickdraw-doodle-recognition\/train_simplified\/candle.csv')\ncandle_data.head()","8d290693":"strokes_str = candle_data.drawing[50]\nprint(type(strokes_str))\nprint(strokes_str)","e26f2e31":"strokes_list = eval(strokes_str)\nprint(type(strokes_list))\nprint(len(strokes_list))\n\nfor s in strokes_list:\n    print(s)","21e6ba1e":"path = os.listdir('..\/input\/quickdraw-doodle-recognition\/train_simplified')\nuniq_labels = np.array(sorted([x[:-4] for x in path]))","fb498ee8":"print(len(uniq_labels))\nprint(uniq_labels[:20])","17d811fe":"enc = LabelEncoder()\nenc.fit(uniq_labels)\n\ntemp = uniq_labels[[0, 37, 42]] \nprint(temp)\nprint(enc.transform(temp))","457c65a5":"label_lookup = pd.DataFrame({\n    'label' : list(map(lambda x : x.replace(' ', '_'), uniq_labels)),\n})\n\nlabel_lookup.head()","b0ab329f":"label_lookup.to_csv('path' + 'label_lookup.csv', header=True, index=False)","62e0ee67":"n_train = 24854214\nn_valid = 24854043\n\nprint(n_train)\nprint(n_valid)","0dfe7fcd":"bs = 64\n\ntrain_steps = 100\nvalid_steps = 100\n\nprint(train_steps)\nprint(valid_steps)","84190d7e":"train_temp = pd.read_csv('..\/input\/quickdrawcombined\/train.csv', chunksize=bs)\nnext(train_temp)","abf22037":"train = pd.read_csv('..\/input\/quickdrawcombined\/train.csv', chunksize=bs)\nvalid = pd.read_csv('..\/input\/quickdrawcombined\/valid.csv', chunksize=bs)","928ccdb5":"def img_to_np(img_str, ht, wt, lw, pad):\n    if img_str == 'drawing':\n        print(np.zeros((ht, wt), np.uint8))\n    \n    strokes = eval(img_str)\n    \n    ht_ = ht - 2*pad\n    wt_ = wt - 2*pad\n    \n    img = np.zeros((ht, wt), np.uint8)\n\n    for s in strokes:\n        sx = (np.array(s[0]) * wt_ \/ 256).round().astype('int') + pad\n        sy = (np.array(s[1]) * ht_ \/ 256).round().astype('int') + pad\n        for i in range(len(sx) - 1):\n            p1 = (sx[i],   sy[i])\n            p2 = (sx[i+1], sy[i+1])\n            img = cv2.line(img, p1, p2, (255, 0, 0), lw, lineType=cv2.LINE_AA)\n            \n    return img","69eccdff":"img_array = img_to_np(strokes_str, 64,64,1,5)\n\nplt.imshow(img_array, cmap='binary')\nplt.axis('off')\nplt.show()","078c0b36":"class DataGenerator(keras.utils.Sequence):\n    \n    #####################################################################\n    # Constructor\n    # - df is a TextFileReader for reading in DataFrame\n    #####################################################################\n    def __init__(self, df, n_classes, batch_size, n_steps, img_params):\n        #self.path = path\n        self.df = df\n        self.n_classes = n_classes\n        self.batch_size = batch_size\n        self.n_steps = n_steps\n        self.img_params = img_params\n        \n    #####################################################################\n    # __getitem__ \n    # This is directly called by Keras methods. It returns a single \n    # batch of data. \n    #####################################################################\n    def __getitem__(self, index):\n        \n        # Typically, this would determine the rows to select for the\n        # current batch. In our case, we will simply grab the next \n        # batch from the TextFileReader\n\n        X, y = self.__data_generation(index)\n\n        return X, y\n\n    #####################################################################\n    # __data_generation \n    # This is called by __getitem__ to generate the batch.\n    #####################################################################\n    def __data_generation(self, index):\n\n        # Get next batch\n        batch = next(self.df)\n\n        # Create blank canvas\n        ht, wt, lw, pad = self.img_params\n        X = np.zeros(shape=(len(batch), ht, wt, 1))\n        \n        ###########################################################\n        #print(index, len(batch), batch.columns)\n\n\n        # Process each image in the batch\n        for i, img_str in enumerate(batch.drawing.values):\n\n            if img_str == 'drawing':\n                img_str == batch.drawing.values[i+1]\n                batch.word.values[i] = batch.word.values[i+1]\n\n            X[i, :, :, 0] = img_to_np(img_str, ht, wt, lw, pad) \/ 255\n\n        # Get batch labels\n        labels = batch.word.values\n        y = enc.transform(labels)\n\n        return X, y\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return self.n_steps\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        return None","fbf5ed9d":"temp_dg = DataGenerator(train_temp, n_classes=20, batch_size=bs, n_steps=10,\n                        img_params=(64, 64, 1, 2))\n\nX, y = temp_dg.__getitem__(2)\n\nlabels = uniq_labels[y]\n\nplt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(X[i,:,:,0], cmap='binary')\n    plt.title(labels[i])\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","eb10c9dc":"train_dg = DataGenerator(train, batch_size=bs, n_classes=20, n_steps=train_steps,\n                         img_params=(64, 64, 1, 2))\n\nvalid_dg = DataGenerator(valid, batch_size=bs, n_classes=20, n_steps=valid_steps,\n                         img_params=(64, 64, 1, 2))","9a891add":"np.random.seed(1)\n\ncnn = Sequential()\n\ncnn.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same', input_shape=(64,64,1)))\ncnn.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\n\ncnn.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\n\ncnn.add(Conv2D(512, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(Conv2D(512, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\n\ncnn.add(Conv2D(1024, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(Conv2D(1024, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\ncnn.add(Flatten())\n\ncnn.add(Dense(2048, activation='relu'))\ncnn.add(BatchNormalization())\n\ncnn.add(Dense(1024, activation='relu'))\ncnn.add(BatchNormalization())\n\ncnn.add(Dense(512, activation='relu'))\ncnn.add(BatchNormalization())\n\ncnn.add(Dense(340, activation='softmax'))","52cf7751":"cnn.summary()","756029d8":"%%time \n\nopt = keras.optimizers.Adam(0.001)\ncnn.compile(loss='SparseCategoricalCrossentropy', optimizer=opt, metrics=['accuracy'])\n\nh1 = cnn.fit(train_dg, validation_data=valid_dg,\n             verbose=1, epochs=100, batch_size = 1000)","03215c9f":"def vis_training(hlist, start=1, size=[12,6], show_val=True):\n    tr_loss = []\n    va_loss = []\n    tr_acc = []\n    va_acc = []\n    for h in hlist:\n        tr_loss += h.history['loss'] \n        va_loss += h.history['val_loss']\n        tr_acc += h.history['accuracy'] \n        va_acc += h.history['val_accuracy']\n    \n    plt.figure(figsize = size)\n    a = start\n    b = len(tr_loss) + 1\n    plt.subplot(1,2,1)\n    plt.plot(range(a,b), tr_loss[a-1:], label='Training')\n    if(show_val): \n        plt.plot(range(a,b), va_loss[a-1:], label='Validation')\n    plt.title('Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.grid()\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(range(a,b), tr_acc[a-1:], label='Training')\n    if(show_val):  \n        plt.plot(range(a,b), va_acc[a-1:], label='Validation')\n    plt.title('Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.grid()\n    plt.legend()\n    plt.show()","00eada03":"vis_training([h1])","87038d02":"h2 = cnn.fit(train_dg, validation_data=valid_dg,\n             verbose=1, epochs=100,batch_size=100)","7ad910f0":"vis_training([h1,h2])","ead5d7f3":"keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)\nh3 = cnn.fit(train_dg, validation_data=valid_dg,\n             verbose=1, epochs=100,batch_size=100)","d94145be":"vis_training([h1, h2, h3])","c7bb959e":"def get_top_3(probs):\n    top_classes = np.argpartition(probs, -3)[-3:]                  # Gives top 3 classes in increasing order\n    top_classes = top_classes[np.argsort(probs[top_classes])]      # Sorts in increasing order\n    top_classes = np.flip(top_classes)                             # Flips the order.\n    top_probs = probs[top_classes]              \n\n    return top_probs, top_classes","ec060754":"NB = len(train_dg)\n#NB = 10\n\ntop_3_probs = np.zeros(shape=(64*NB, 3))\n\nfor i in range(NB):\n    batch_imgs, batch_labels = train_dg.__getitem__(i)\n    batch_pred = cnn.predict(batch_imgs)\n\n    ## Loop over each image in the batch\n    for j in range(64):\n        top_probs, top_classes = get_top_3(batch_pred[j, :])\n        top_3_probs[i,:] = top_probs\n\nprint(top_3_probs.shape)\n\nplt.figure(figsize=[10,6])\nfor i in range(3):\n    plt.subplot(3,1,i+1)\n    plt.hist(top_3_probs[:,i], color='orchid', edgecolor='k', bins = np.arange(0, 1.01, 0.025))\n    plt.yscale('log')\nplt.show()","33e91cc6":"def MAP3(t):\n    NB = len(valid_dg)\n    #NB = 20\n\n    sum_ap3 = 0\n    N_obs = 0\n\n    for i in range(NB):\n        batch_imgs, batch_labels = train_dg.__getitem__(i)\n        batch_pred = cnn.predict(batch_imgs)\n\n        ## Loop over each image in the batch\n        for j in range(64):\n            probs = batch_pred[j, :]\n            top_classes = np.argpartition(probs, -3)[-3:]                  # Gives top 3 classes in increasing order\n            top_classes = top_classes[np.argsort(probs[top_classes])]      # Sorts in increasing order\n            top_classes = np.flip(top_classes)                             # Flips the order.\n\n            top_probs = probs[top_classes]              # Don't need this when not using a threshold\n\n            # Keep Probs Over Threshold\n            sel = top_probs > t\n            sel[0] = True                               # Always keep first pred\n            top_classes = top_classes[sel]\n\n            K = len(top_classes)   # Number of classes to submit\n            if K == 3:\n                scores = np.array([11\/18, 5\/18, 2\/18])\n            elif K == 2:\n                scores = np.array([3\/4, 1\/4])\n            else:\n                scores = np.array([1])\n            \n            sel = (top_classes == batch_labels[j])\n            ap3 = np.sum(scores * sel)\n\n            sum_ap3 += ap3\n            N_obs += 1\n            \n            #print(ap3)\n\n    map3 = sum_ap3 \/ N_obs\n\n    return map3\n\nfor t in np.arange(0, 1.01, 0.05):\n    print(round(t, 2), '\\t', MAP3(t))","5170ca0a":"%%time\n\nMAP3_scores = []\nt_array = np.arange(0.05, 1.01, 0.05) \n\nfor t in t_array:\n    MAP3_scores.append(MAP3(t))\n\nplt.plot(t_array, MAP3_scores)\nplt.scatter(t_array, MAP3_scores)\nplt.show()","df552e11":"class GradCAM:\n    def __init__(self, model, classIdx, layerName=None):\n        self.model = model\n        self.classIdx = classIdx\n        self.layerName = layerName\n        if self.layerName is None:\n            self.layerName = self.find_target_layer()\n            \n    def find_target_layer(self):\n        for layer in reversed(self.model.layers):\n            if len(layer.output_shape) == 4:\n                return layer.name\n        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n        \n    def compute_heatmap(self, image, eps=1e-8):\n        gradModel = Model(\n            inputs=[self.model.inputs],\n            outputs=[self.model.get_layer(self.layerName).output,self.model.output]\n       )\n           \n        with tf.GradientTape() as tape:\n            inputs = tf.cast(image, tf.float32)\n            (convOutputs, predictions) = gradModel(inputs)\n            loss = predictions[:, self.classIdx]\n            grads = tape.gradient(loss, convOutputs)\n\n            castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n            castGrads = tf.cast(grads > 0, \"float32\")\n            guidedGrads = castConvOutputs * castGrads * grads\n            convOutputs = convOutputs[0]\n            guidedGrads = guidedGrads[0]\n\n            weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n            cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n\n            (w, h) = (image.shape[2], image.shape[1])\n            heatmap = cv2.resize(cam.numpy(), (w, h))\n            numer = heatmap - np.min(heatmap)\n            denom = (heatmap.max() - heatmap.min()) + eps\n            heatmap = numer \/ denom\n            heatmap = (heatmap * 255).astype(\"uint8\")\n        return heatmap\n\n    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n        colormap = cv2.COLORMAP_VIRIDIS):\n        heatmap = cv2.applyColorMap(heatmap, colormap)\n        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n        return (heatmap, output)","c6a0c2de":"train_new = pd.read_csv('..\/input\/quickdrawcombined\/train.csv', chunksize=bs)\n\ntrain_dg = DataGenerator(train_new, batch_size=bs, n_classes=20, n_steps=train_steps,\n                         img_params=(64, 64, 1, 2))\n\nX, y = train_dg.__getitem__(2)\n\nlabels = uniq_labels[y]\n\nplt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(X[i,:,:,0], cmap='binary')\n    plt.title(labels[i])\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","d67b8ddf":"batch_pred = cnn.predict(X)\nbatch_pred.shape","32538172":"plt.figure(figsize=[16,48])\nfor n in range(64):\n\n    top_probs, top_classes = get_top_3(batch_pred[n, :])\n    \n    cam = GradCAM(cnn, top_classes[0])             \n    heatmap = cam.compute_heatmap(X[[n], :, :, :]) \n\n    plt.subplot(16,4,n+1)\n    plt.imshow(X[n,:,:,0], cmap='binary')\n    plt.imshow(heatmap, alpha=0.6, cmap='coolwarm')\n    plt.title(f'{labels[n]} - {uniq_labels[top_classes]} \\n{top_classes} - {top_probs.round(2)}')\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","93079ed1":"cnn.save('demo_model.h5')","598af6b4":"test = pd.read_csv('..\/input\/quickdraw-doodle-recognition\/test_simplified.csv')\nprint(test.shape)\ntest.head()","fea4285d":"def img_to_np(img_str, ht, wt, lw, pad):\n\n    strokes = eval(img_str)\n\n    ht_ = ht - 2*pad\n    wt_ = wt - 2*pad\n\n    img = np.zeros((ht, wt), np.uint8)\n\n    for s in strokes:\n        sx = (np.array(s[0]) * wt_ \/ 256).round().astype('int') + pad\n        sy = (np.array(s[1]) * ht_ \/ 256).round().astype('int') + pad\n\n        for i in range(len(sx) - 1):\n            p1 = (sx[i],   sy[i])\n            p2 = (sx[i+1], sy[i+1])\n            img = cv2.line(img, p1, p2, (255, 0, 0), lw, lineType=cv2.LINE_AA)\n            #img = cv2.resize(img, (ht, wt))\n    return img","307556e9":"test_imgs = np.zeros(shape = (test.shape[0], 64, 64, 1))","ac0cc696":"%%time\n\nfor i, row in test.iterrows():\n    test_imgs[i,:,:,0] = img_to_np(row.drawing, 64, 64, 1, 2) \/ 255","03db5e5d":"plt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(test_imgs[i,:,:,0], cmap='binary')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","cf90f25c":"sample = test.sample(64)\nsample.shape\n\nplt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(img_to_np(sample.drawing.values[i], 64, 64, 1, 2), cmap='binary')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","4d498947":"cnn = keras.models.load_model('.\/demo_model.h5')\ncnn.summary()","87650e66":"test_imgs.shape","9d889c24":"%%time \n\nprobs = cnn.predict(test_imgs)\n\nprint(probs.shape)","fa4e8f81":"N_train = probs.shape[0]\ntop_3_probs = np.zeros(shape=(N_train, 3))\n\nfor i in range(N_train):\n    p = probs[i, :]\n    top_classes = np.argpartition(p, -3)[-3:]                      # Gives top 3 classes in increasing order\n    top_classes = top_classes[np.argsort(p[top_classes])]      # Sorts in increasing order\n    top_classes = np.flip(top_classes)                             # Flips the order.\n\n    top_probs = p[top_classes]              \n\n    top_3_probs[i,:] = top_probs\n    \nprint(top_3_probs[:10, :].round(2))\n\nprint(top_3_probs.shape)\n\nplt.figure(figsize=[10,6])\nfor i in range(3):\n    plt.subplot(3,1,i+1)\n    plt.hist(top_3_probs[:,i], color='orchid', edgecolor='k', bins = np.arange(0, 1.01, 0.025))\n    plt.yscale('log')\nplt.show()","9c4cca77":"N_train = probs.shape[0]\npredictions = []\n\nt = 0.35\n\nfor i in range(N_train):\n    p = probs[i, :]\n    top_classes = np.argpartition(p, -3)[-3:]                   # Gives top 3 classes in increasing order\n    top_classes = top_classes[np.argsort(p[top_classes])]       # Sorts in increasing order\n    top_classes = np.flip(top_classes)                          # Flips the order.\n\n    top_probs = p[top_classes]              \n\n    # Keep Probs Over Threshold\n    sel = top_probs > t\n    sel[0] = True                               # Always keep first pred\n    predictions.append(top_classes[sel])\n    \nprint(len(predictions))","c9b44398":"test.head()","088474ce":"submission = pd.read_csv('..\/input\/quickdraw-doodle-recognition\/sample_submission.csv')\nsubmission.head()","51c225f6":"len(submission)","09355700":"label_lookup_df = pd.read_csv('path' + 'label_lookup.csv')\nlabel_lookup = {k:v for k,v in zip(label_lookup_df.index.values, label_lookup_df.label.values)}\nlabel_lookup[0]","4fcc26fa":"%%time\n\nfor i in range(N_train):\n    classes = predictions[i]\n    words_list = [label_lookup[c] for c in classes]\n    words_string = ' '.join(words_list)\n    submission.loc[i, 'word'] = words_string\n    #print(words_string)\n    \nsubmission.head()","638e8655":"submission.to_csv('submission.csv', index=False)","2be3d800":"idx = np.random.choice(range(N_train), 64, replace=False)\ntest_sample = test.iloc[idx,:]\nsub_sample = submission.iloc[idx, :]\n\nplt.figure(figsize=[16,16])\n\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(img_to_np(test_sample.drawing.values[i], 64, 64, 1, 2), cmap='binary')\n    plt.title(sub_sample.word.values[i].replace(' ', '\\n'))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","3f18a3fd":"## Determine Predictions","48d4e0fa":"### Run 3","2c4e780d":"# Save the Model","e3240e34":"## Create Train and Valid Generators","97247bf9":"## Label Encoder","17384d5b":"## Create CAM Function","54b59e0c":"# Load and Prep Data","ff94e982":"## Distribution of Top 3 Probabilities","f6bd7ca9":"# CNN","644bcc0e":"### Run 2","230dc28c":"# MAP at 3","2c4ca8ea":"## Train Network","b3204e71":"# Training and Validation Sets","12b41275":"### Run 1","8cbbdb08":"# Evaluate the Model","0ec1fde9":"# Quick, Draw!\n\n#### Divya Sanathkumar\n\n\n\n\nThe Quick Draw dataset is a collection of images hand drawn by users which consists of about 340 classes. The goal is to build a Neural network that tries to classify these hand drawn images. In order to do that, a Convolutional Neural Networks, used to analyze visual imagery, is built. The data is split into training and validation sets and is fed to this CNN model to predict the accuracy of the image recognition.","c46150bf":"## Convert Test Strings to Arrays","bd6fd2c5":"# Create Submission","72485b6f":"# CAM","a558c55b":"# Load Test Data","73130313":"## Load Model","7981ea33":"# Images with Predictions","a445a9af":"## Create Function to display plot","2381d304":"## Generate Predictions","484bc348":"# Data Generators","b166491c":"## Distribution of Top 3 Probabilities","f2e0e56f":"## Batch Size and Steps Per Epoch","7ed62e06":"## Build Network","8a8f5e0b":"## img_to_np Function","30b78f43":"## Display Batch Images","76b5192c":"## Create Generator"}}