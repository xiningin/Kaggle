{"cell_type":{"8de1f8d7":"code","9ffe7bd7":"code","6849b7a7":"code","51665463":"code","e56cf9e0":"code","27ca663b":"code","16ac0a6e":"code","7e06bed9":"code","30571690":"code","cc395e2a":"code","61ff04bc":"code","2c116ef5":"code","519ee8fa":"code","a26f1adf":"code","c6a995eb":"code","e878e75f":"markdown"},"source":{"8de1f8d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","9ffe7bd7":"df = pd.read_csv('..\/input\/heart.csv')\ndf.head(5)","6849b7a7":"df.describe()","51665463":"df.info()","e56cf9e0":"sns.set_palette('Set2')\nsns.countplot(x='target',data=df)","27ca663b":"print('Male :',df.sex.value_counts().tolist()[0])\nprint('Female :',df.sex.value_counts().tolist()[1])\nsns.countplot(x='sex',data=df)","16ac0a6e":"df.shape","7e06bed9":"continuous = ['age','trestbps','chol','thalach','oldpeak']\ncolor = ['blue','green','red','yellow','orange']\nfor i,j in zip(continuous,color):\n    sns.distplot(df[i],color=j)\n    plt.show()","30571690":"categorical = [cat for cat in df.columns.tolist() if cat not in continuous]\ncategorical.remove('sex')\nfor i,j in zip(categorical,color):\n    sns.countplot(x=i,data=df,color=j,hue=df.sex)\n    plt.show()","cc395e2a":"corr = df.corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(corr,annot=True,linewidths=5)","61ff04bc":"categorical.remove('target')\nfor i in categorical:\n    df[i] = df[i].astype('object')\ndf.info()","2c116ef5":"y = df.iloc[:,13].values\ndf.drop(labels='target',axis=1,inplace=True)\ndf = pd.get_dummies(df,drop_first=True)\ndf.head()","519ee8fa":"from sklearn.model_selection import train_test_split\nnp.random.seed(42)\nx = df.iloc[:,:-1].values\nxtr, xtst, ytr, ytst = train_test_split(x,y,test_size=0.20,random_state=0)\nprint('X train : {}\\tY train :{}\\nX test : {}\\tY test : {}'.format(xtr.shape,ytr.shape,xtst.shape,ytst.shape))","a26f1adf":"from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB, GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nmodels = []\nmodels.append(('XGBoost',XGBClassifier()))\nmodels.append(('LightGBM',LGBMClassifier()))\nmodels.append(('AdaBoostClassifier',AdaBoostClassifier()))\nmodels.append(('Bagging',BaggingClassifier()))\nmodels.append(('Extra Trees Ensemble', ExtraTreesClassifier()))\nmodels.append(('Gradient Boosting',GradientBoostingClassifier()))\nmodels.append(('Random Forest', RandomForestClassifier()))\nmodels.append(('BNB',BernoulliNB()))\nmodels.append(('GNB',GaussianNB()))\nmodels.append(('KNN',KNeighborsClassifier()))\nmodels.append(('MLP',MLPClassifier()))\nmodels.append(('DTC',DecisionTreeClassifier()))\nmodels.append(('ETC',ExtraTreeClassifier()))","c6a995eb":"from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n%matplotlib inline\n\nbest_model = None\nbest_model_name = \"\"\nbest_valid = 0\n\nfor name, model in models:\n    model.fit(xtr,ytr)\n    proba = model.predict_proba(xtst)[:,1]\n    score = roc_auc_score(ytst, proba)\n    fpr, tpr, _  = roc_curve(ytst, proba)\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', label=f\"ROC curve (auc = {score})\")\n    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n    plt.title(f\"{name} Results\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    if score > best_valid:\n        best_valid = score\n        best_model = model\n        best_model_name = name\n\nprint(f\"Best model is {best_model_name}\")","e878e75f":"<h3>If you find it helpful, please upvote and encourage me. Stay tuned there is more to come.<\/h3>"}}