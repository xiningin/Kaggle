{"cell_type":{"f3f7bf86":"code","aca39737":"code","fa4967d0":"code","d71ea921":"code","7736122f":"code","6354f0b6":"code","cba265c1":"code","923647ac":"code","8cddd719":"code","a0ddd379":"code","22157163":"code","d8b42998":"code","abeb4ead":"code","4f307de9":"code","353f4277":"code","a4811738":"markdown","8609f50a":"markdown","0c081c8d":"markdown","453d9a93":"markdown","8f7fc032":"markdown","0f736ac7":"markdown","38bdcd82":"markdown"},"source":{"f3f7bf86":"import matplotlib.pyplot as plt\nfrom glob import glob\nfrom skimage.io import imread\nfrom skimage.color import rgb2gray\nfrom sklearn.model_selection import train_test_split\nimport keras\nimport numpy as np\n \nfrom keras.models import Sequential\nfrom keras.layers import (  Dense,\n                            Flatten,\n                            LeakyReLU\n                         )\nfrom keras.applications import  VGG19,ResNet50,ResNet152V2,InceptionV3,InceptionResNetV2,ResNet101,VGG16\nfrom keras.optimizers import Adam\nfrom keras.utils.np_utils import to_categorical\nfrom skimage.transform import resize\nfrom tqdm import tqdm\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import ResNet50,MobileNet, DenseNet201\nimport json\nimport math\nimport os\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy","aca39737":"def hist(History):\n    fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n \n    ax[0].plot(History.history['loss'])\n    ax[0].plot(History.history['val_loss'])\n    ax[0].legend(['Training loss', 'Validation Loss'],fontsize=18)\n    ax[0].set_xlabel('Epochs ',fontsize=16)\n    ax[0].set_ylabel('Loss',fontsize=16)\n    ax[0].set_title('Training loss x Validation Loss',fontsize=16)\n \n \n    ax[1].plot(History.history['accuracy'])\n    ax[1].plot(History.history['val_accuracy'])\n    ax[1].legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n    ax[1].set_xlabel('Epochs ',fontsize=16)\n    ax[1].set_ylabel('Accuracy',fontsize=16)\n    ax[1].set_title('Training Accuracy x Validation Accuracy',fontsize=16)\ndef plot_any(arr, title = ''):\n    plt.figure(figsize = (15, 25))\n    for i in range(len(arr)):\n        plt.subplot(1,len(arr),i + 1)\n        plt.title(title)\n        plt.imshow(arr[i], cmap = 'gray');\n\npath = '..\/input\/breast-cancer-data\/miasdata\/'\ntrain_path = glob(path + '\/train\/*')\ntest_path = glob(path + '\/test\/*')\ntrain_imgs = []\ntrain_labels = []\ntest_imgs  = []\ntest_labels = []\n \nx, y, z = 224, 224, 3\nimport re\nimport numpy as numpy\n \n#train\nfor klass, folder in enumerate(tqdm(train_path)):\n    for img in glob(folder + '\/*'):\n        a = cv2.imread(img)\n        print(img)\n \n \n        train_imgs.append(a)\n        train_labels.append(klass)\n \n#test\nfor klass, folder in enumerate(tqdm(test_path)):\n    for img in glob(folder + '\/*'):\n        \n        a = cv2.imread(img)\n   #     img_resize = resize(img_resize, (x, y, z))\n \n        test_imgs.append(a)\n        test_labels.append(klass)","fa4967d0":"import cv2\nsz=(224,224)\nx_train=[]\nx_test=[]\nfor i in range(0,len(train_imgs)):\n \n  a = cv2.resize(train_imgs[i],dsize=sz,interpolation=cv2.INTER_CUBIC)\n  x_train.append(a)\nfor i in range(0,len(test_imgs)):\n \n  b = cv2.resize(test_imgs[i],dsize=sz,interpolation=cv2.INTER_CUBIC)\n  x_test.append(b)\nplt.imshow(test_imgs[50])\n \n \ntest_images=np.array(x_test)\ntrain_images=np.array(x_train)\ntrain=[]\n \nprint(train_images.shape,test_images.shape)","d71ea921":"y_train = to_categorical(train_labels, 3)\ny_test = to_categorical(test_labels, 3)","7736122f":"train_datagen = ImageDataGenerator( rotation_range=90,\n                                    width_shift_range=0.15,\n                                    height_shift_range=0.15,\n                                    horizontal_flip = True,\n                                    vertical_flip = True,\n                                    zoom_range=(0.9,1),\n                                    fill_mode= 'nearest',\n                                    brightness_range=(0.8, 1.2),\n                                  )\n \ntrain_generator = train_datagen.flow(train_imgs, y_train, batch_size = 64)\nval_generator = train_datagen.flow(test_imgs, y_test, batch_size = 64, shuffle = True)","6354f0b6":"def build_model(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(3, activation='sigmoid'))\n    \n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    \n    return model","cba265c1":"\nresnet = ResNet50(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\n\nresnet.layers[49].trainable=True\nmodel = build_model(resnet ,lr = 1e-4)\n\n\nmodel.summary()\n\n \n\n\n","923647ac":"# Learning Rate Reducer\nlearn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,\n                                  verbose=1,factor=0.2, min_lr=1e-7)\n\n# Checkpoint\nfilepath=\"weights.best.hdf5\"\n","8cddd719":"\nvgg16 = VGG16(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\nfor layer in vgg16.layers[: -10]:\n    layer.trainable = False\nmodel = build_model(vgg16 ,lr = 1e-4)\n\n\nmodel.summary()\n\n \n# Learning Rate Reducer\nlearn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,\n                                  verbose=1,factor=0.2, min_lr=1e-7)\n\n# Checkpoint\nfilepath=\"weights.best.hdf5\"\n\n\n\n\n\nhistory = model.fit_generator(\n    train_generator,\n\n    epochs=29,\n    validation_data=val_generator,\n    callbacks=[learn_control]\n)\n","a0ddd379":"pred=model.predict(test_imgs)\n\nt_list=[]\nfor i in range(0,len(y_test)):\n  if (y_test[i][0]==1):\n    t_list.append(0)\n  elif (y_test[i][1]==1):\n    t_list.append(1)\n  elif (y_test[i][2]==1):\n    t_list.append(2)\na=0\n\np=[]\nfor i in range(0,len(pred)):\n  a=np.argmax(pred[i])\n\n  p.append(a)\n","22157163":"from keras.applications import ResNet50,MobileNet, DenseNet201\nimport json\nimport math\nimport os\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nresnet = VGG16(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\nfor layer in resnet.layers[: -10]:\n    layer.trainable = False\nmodel = build_model(resnet ,lr = 1e-4)\n\n\nmodel.summary()\n\n \n# Learning Rate Reducer\nlearn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,\n                                  verbose=1,factor=0.2, min_lr=1e-7)\n\n# Checkpoint\nfilepath=\"weights.best.hdf5\"\n\n\n\n\n\nhistory = model.fit_generator(\n    train_generator,\n\n    epochs=12,\n    validation_data=val_generator,\n    callbacks=[learn_control]\n)\n","d8b42998":"loss, accu = model.evaluate(test_imgs, y_test)\nprint(\"%s: %.2f%%\" % ('Accuracy...', accu))\nprint(\"%s: %.2f\" % ('loss.......', loss))","abeb4ead":"hist(history)","4f307de9":"pred=model.predict(test_imgs)\n\nt_list=[]\nfor i in range(0,len(y_test)):\n  if (y_test[i][0]==1):\n    t_list.append(0)\n  elif (y_test[i][1]==1):\n    t_list.append(1)\n  elif (y_test[i][2]==1):\n    t_list.append(2)\na=0\n\np=[]\nfor i in range(0,len(pred)):\n  a=np.argmax(pred[i])\n\n  p.append(a)\n","353f4277":"from sklearn.metrics import confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=55)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\ncm = confusion_matrix(t_list,p)\n\ncm_plot_label =['Dense', 'Fatty','Glanular']\nplot_confusion_matrix(cm, cm_plot_label, title ='Confusion Metrix for COVID19')","a4811738":"**Train and val generator**","8609f50a":"**Fine Tunning**","0c081c8d":"**History Funcation and load the manually preprocess dataset **","453d9a93":"**Label Encoding**","8f7fc032":"**Model Architecture**","0f736ac7":"**Resize Images**","38bdcd82":"**Import Libraries**"}}