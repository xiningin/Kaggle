{"cell_type":{"633d2d1f":"code","848d134c":"code","36aa7e9d":"code","233979f5":"code","bf63ab1e":"code","660a027e":"code","0a03cae4":"code","7a89e50b":"code","55aa56fb":"code","35e126c8":"code","6f0e0e9c":"code","e06bf4ae":"code","04c2a546":"code","eeaf3d7b":"code","b66c9a38":"code","9a9cafd3":"code","2fdaf83c":"code","ad01390e":"code","3e68a983":"code","4d905125":"code","0b1aeaeb":"code","10c7ba27":"code","47f09fcf":"code","ffab804a":"code","ce6f1b5f":"code","3d4e94fe":"code","6ff5bdf7":"code","8d3c9c92":"code","acb5c57f":"code","ca129e4c":"code","003d25ec":"code","ad9fa311":"code","33ea279b":"code","b338db0d":"code","249d4918":"code","26aba414":"code","2afcc279":"code","05397bb8":"code","3bd52223":"code","45f5611e":"code","0df08b53":"code","c8254a46":"code","0adbc977":"code","69712db2":"code","4d385321":"code","72b308d7":"code","b469eac5":"code","1d0d2ed4":"code","8c86ce6c":"code","ae3a56d5":"code","753c8563":"code","722c27f7":"code","023b8b69":"code","a98ecdb8":"markdown","54fc36a8":"markdown","5f7317e3":"markdown","6e386c64":"markdown","97040949":"markdown","910fc7af":"markdown","6ec51afe":"markdown","2659e321":"markdown","d2ac1de3":"markdown"},"source":{"633d2d1f":"# IMport Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv\n\nimport os,glob\n\n\nimport PIL\nimport tensorflow as tf\nimport matplotlib.image as image\nimport seaborn as sns\nfrom PIL import Image\n\nfrom matplotlib.pyplot import figure, imshow, axis\nfrom matplotlib.image import imread\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, Dense, BatchNormalization\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.models import Sequential\nimport random\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing import image\nfrom keras.utils.np_utils import to_categorical\n\nimport warnings\nwarnings.filterwarnings('ignore')","848d134c":"from numpy.random import seed\nseed(1)\n\nimport tensorflow\ntensorflow.random.set_seed(2)","36aa7e9d":"dir_path = '..\/input\/birds-vs-drone-dataset\/BirdVsDrone'\ndigits = sorted(os.listdir(dir_path))\nNUM_CLASSES = len(digits)\nprint(digits)\nprint('Number of classes : ', NUM_CLASSES)","233979f5":"bird_path='..\/input\/birds-vs-drone-dataset\/BirdVsDrone\/Birds'\ndrone_path='..\/input\/birds-vs-drone-dataset\/BirdVsDrone\/Drones'","bf63ab1e":"bird_path_grey='.\/BirdsGray'\ndrone_path_grey='.\/DronesGray'","660a027e":"#create an empty DataFrame for RGB images\ndf = pd.DataFrame(columns=['path','label'])\n\n#loop over bird images and label them 1\nfor dirname, _, filenames in os.walk(bird_path):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        df = df.append(pd.DataFrame([[os.path.join(dirname, filename),'bird']],columns=['path','label']))\n\n#loop over Drone images and label them 0\nfor dirname, _, filenames in os.walk(drone_path):\n    for filename in filenames:\n        df = df.append(pd.DataFrame([[os.path.join(dirname, filename),'drone']],columns=['path','label']))\n        #print(os.path.join(dirname, filename))\n\n#shuffle the dataset for redistribute the labels\ndf = df.sample(frac=1).reset_index(drop=True)\ndf.head(10)","0a03cae4":"df.shape","7a89e50b":"df['label'].value_counts().plot.barh()","55aa56fb":"from keras.preprocessing import image\n\nlabel = 'bird' #label for images with fire\ndata = df[df['label'] == label]\nsns.set_style('dark')\n\n\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics\/\/2),2,figsize=(15,15))\nplt.suptitle('bird')\nax = ax.ravel()\nfor i in range((pics\/\/2)*2):\n    path = data.sample(1).loc[:,'path'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)\/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","35e126c8":"label = 'drone' #label for images with fire\ndata = df[df['label'] == label]\nsns.set_style('dark')\n\n\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics\/\/2),2,figsize=(15,15))\nplt.suptitle('drone')\nax = ax.ravel()\nfor i in range((pics\/\/2)*2):\n    path = data.sample(1).loc[:,'path'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)\/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","6f0e0e9c":"generator = ImageDataGenerator(\n        rescale = 1\/255,\n        validation_split=0.2,\n        rotation_range=8, # rotation\n        width_shift_range=0.1, # horizontal shift\n        height_shift_range=0.1, # vertical shift\n        zoom_range=0.2, # zoom\n        horizontal_flip=True, # horizontal flip\n        brightness_range=[0.8,1.3] # brightness\n)","e06bf4ae":"train_gen = generator.flow_from_dataframe(df,x_col='path',y_col='label',target_size=(256,256),\n                                          batch_size=32,\n                                          class_mode='categorical',subset='training',seed=42)\nval_gen = generator.flow_from_dataframe(df,x_col='path',y_col='label',target_size=(256,256),\n                                        batch_size=32,\n                                        class_mode='categorical',subset='validation',seed=42)","04c2a546":"train_gen.image_shape","eeaf3d7b":"w = 10\nh = 10\n\nx= train_gen.next()\nimage = x[0]\nfig = plt.figure(figsize=(16, 16))\ncolumns = 4\nrows = 4\nfor i in range(1, columns*rows +1):\n    img = image[i]\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","b66c9a38":"def to_grayscale_then_rgb(image):\n    image = tf.image.rgb_to_grayscale(image)\n#     print(image.shape)\n    return image\n\n","9a9cafd3":"image = cv.imread(\"..\/input\/birds-vs-drone-dataset\/BirdVsDrone\/Birds\/singleBirdinsky0.jpeg\")\n\nimg=to_grayscale_then_rgb(image)\nprint(img.shape)","2fdaf83c":"generator_grey = ImageDataGenerator(\n        rescale = 1\/255,\n        validation_split=0.2,\n        rotation_range=8, # rotation\n        width_shift_range=0.1, # horizontal shift\n        height_shift_range=0.1, # vertical shift\n        zoom_range=0.2, # zoom\n        horizontal_flip=True, # horizontal flip\n        brightness_range=[0.8,1.3] # brightness\n    \n)","ad01390e":"train_gen_grey = generator_grey.flow_from_dataframe(df,x_col='path',y_col='label',target_size=(256,256),\n                                          batch_size=32,\n                                        color_mode='grayscale',\n                                          class_mode='categorical',subset='training',seed=42)\nval_gen_grey = generator_grey.flow_from_dataframe(df,x_col='path',y_col='label',target_size=(256,256),\n                                        batch_size=32,\n                                      color_mode='grayscale',\n                                        class_mode='categorical',subset='validation',seed=42)","3e68a983":"train_gen_grey.image_shape","4d905125":"val_gen_grey.image_shape","0b1aeaeb":"!pip install wandb","10c7ba27":"import wandb\nwandb.login()","47f09fcf":"from wandb.keras import WandbCallback\n\nwandb.init(project=\"Bird-Vs-Drone\", entity=\"harshwalia\")","ffab804a":"wandb.config = {\n  \"learning_rate\": 0.0001,\n  \"epochs\": 15,\n  \"batch_size\": 32,\n  \"loss\":'categorical_crossentropy',\n}\n\n# ... Define a model\n\nmodel = tf.keras.Sequential([\n    Flatten(input_shape=(256, 256, 1)),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dense(64, activation='relu'),\n    Dense(2,activation='softmax')\n])","ce6f1b5f":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","3d4e94fe":"history=model.fit(\n        train_gen_grey,\n        epochs=15,\n        validation_data=val_gen_grey,\n        callbacks=[WandbCallback()]\n        )","6ff5bdf7":"# plot_model_history(history)","8d3c9c92":"hist=history.history\nplt.plot(hist[\"accuracy\"],color=\"b\",label=\"train_accuracy\")\nplt.plot(hist[\"val_accuracy\"],color=\"g\",label=\"val_accuracy\")\nplt.legend(loc=\"lower right\")\nplt.show()","acb5c57f":"model.evaluate(train_gen_grey)","ca129e4c":"model.evaluate(val_gen_grey)","003d25ec":"input_layer=Input(shape=(256,256,3))\nlayer=Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_layer)\nlayer=MaxPool2D(pool_size=(2,2),strides=(1,1))(layer)\nlayer=BatchNormalization()(layer)\nlayer=Dropout(0.5)(layer)\n\nlayer=Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_layer)\nlayer=MaxPool2D(pool_size=(2,2),strides=(1,1))(layer)\nlayer=BatchNormalization()(layer)\nlayer=Dropout(0.5)(layer)\n\nlayer=Conv2D(filters=16,kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_layer)\nlayer=MaxPool2D(pool_size=(2,2),strides=(1,1))(layer)\nlayer=BatchNormalization()(layer)\nlayer=Dropout(0.5)(layer)\n\nlayer=Flatten()(layer)\n\nlayer=Dense(64,activation=\"relu\")(layer)\nlayer=BatchNormalization()(layer)\nlayer=Dropout(0.5)(layer)\n\nlayer=Dense(32,activation=\"relu\")(layer)\noutput_layer=Dense(2,activation=\"softmax\")(layer)\nmodel2=Model(inputs=input_layer,outputs=output_layer)\nmodel2.summary()","ad9fa311":"model2.compile(loss='categorical_crossentropy',\n       optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n       metrics=['accuracy'])","33ea279b":"history2 = model2.fit(\n    train_gen,\n    epochs=15,\n    validation_data=val_gen,\n    callbacks=[WandbCallback()]\n)","b338db0d":"hist=history2.history\nplt.plot(hist[\"accuracy\"],color=\"b\",label=\"train_accuracy\")\nplt.plot(hist[\"val_accuracy\"],color=\"g\",label=\"val_accuracy\")\nplt.legend(loc=\"lower right\")\nplt.show()","249d4918":"model2.evaluate(train_gen)","26aba414":"model2.evaluate(val_gen)","2afcc279":"resnet_model = Sequential()\n\npretrained_model= tf.keras.applications.ResNet50(include_top=False,\n                   input_shape=(256,256,3),\n                   pooling='avg',\n                   weights='imagenet')\nfor layer in pretrained_model.layers:\n        layer.trainable=False\n\nresnet_model.add(pretrained_model)","05397bb8":"resnet_model.add(Flatten())\nresnet_model.add(Dense(256, activation='relu'))\nresnet_model.add(Dense(128, activation='relu'))\nresnet_model.add(Dense(64, activation='relu'))\nresnet_model.add(Dense(2, activation='softmax'))","3bd52223":"resnet_model.summary()\n","45f5611e":"resnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                     loss='categorical_crossentropy',\n                     metrics=['accuracy'])\n\nhistory_resnet = resnet_model.fit(train_gen, validation_data=val_gen, epochs=15,callbacks=[WandbCallback()])","0df08b53":"# plot_model_history(history_resnet)","c8254a46":"hist=history_resnet.history\nplt.plot(hist[\"accuracy\"],color=\"b\",label=\"train_accuracy\")\nplt.plot(hist[\"val_accuracy\"],color=\"g\",label=\"val_accuracy\")\n# plt.axis(ymin=0.4,ymax=1)\nplt.legend(loc=\"lower right\")\nplt.show()","0adbc977":"resnet_model.evaluate(train_gen)","69712db2":"resnet_model.evaluate(val_gen)","4d385321":"files=val_gen.filenames\nclass_dict=val_gen.class_indices # a dictionary of the form class name: class index\nrev_dict={}\nfor key, value in class_dict.items():\n    rev_dict[value]=key   # dictionary of the form class index: class name","72b308d7":"predictions = resnet_model.predict(val_gen)","b469eac5":"from keras.preprocessing import image","1d0d2ed4":"fig = plt.figure(figsize=(16, 16))\ncolumns = 4\nrows = 4\nfor i in range(1, columns*rows +1):\n    index=np.argmax(predictions[i])\n    klass=rev_dict[index] \n    im = Image.open(files[i])\n    img=np.array(im)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.title(f'predicted class: { klass}')\nplt.show()","8c86ce6c":"dict_path=dict(zip(df.path, df.label))","ae3a56d5":"dict_path[files[i]]","753c8563":"len(predictions)","722c27f7":"cnt=0\ncolumns = 6\nrows = 6\nfor i in range(1, 165):\n    index=np.argmax(predictions[i])\n    pred_class=rev_dict[index] \n    actual_label=dict_path[files[i]]\n    if(actual_label!=pred_class):\n       cnt+=1\nprint(f'Number of misclassified example {cnt} out of {len(predictions)} examples')","023b8b69":"fig = plt.figure(figsize=(16, 16))\ncolumns = 6\nrows = 6\nfor i in range(1, columns*rows +1):\n    index=np.argmax(predictions[i])\n    pred_class=rev_dict[index] \n    im = Image.open(files[i])\n    actual_label=dict_path[files[i]]\n    if(actual_label!=pred_class):\n        img=np.array(im)\n        fig.add_subplot(rows, columns, i)\n        plt.imshow(img)\n        plt.title(f'predicted class: { pred_class}')\nplt.show()","a98ecdb8":"# Augmented Images","54fc36a8":"# Training Neural Network","5f7317e3":"# Convolution Neural Nets","6e386c64":"### RGB generator","97040949":"# Transfer learning","910fc7af":"# Training curve for CNN","6ec51afe":"### Grey scale images","2659e321":"# Training Curve for NN","d2ac1de3":"### grey scale image generator"}}