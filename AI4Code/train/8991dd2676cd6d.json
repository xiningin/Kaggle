{"cell_type":{"8dce62f6":"code","39cabe92":"code","8495e535":"code","de593ef8":"code","8e027be1":"code","9dde02e4":"code","1591a68b":"code","8f8b1b3d":"code","ce8fc17b":"code","b6a26e2e":"code","66dad1b5":"code","ddf9f5fc":"code","45846b9d":"code","54b97a02":"code","b0a441b5":"code","6cdc57b4":"code","fea3314a":"code","d7a9d197":"code","50196f34":"code","ecce6217":"code","f5e2efeb":"markdown","47de11c8":"markdown","7f20dedb":"markdown","150b6375":"markdown","477e4bc7":"markdown","5ee92f30":"markdown","d44f1f6e":"markdown","acf90bf8":"markdown","938514b7":"markdown","e9a5240e":"markdown","aa0f9bf6":"markdown","13de2cba":"markdown","e460bda9":"markdown","ecc28dcd":"markdown","e97e92c2":"markdown","19a68e56":"markdown","e253164d":"markdown","d4aae555":"markdown","9c762a3d":"markdown","6128c500":"markdown","42db3c05":"markdown","9efc3e56":"markdown","b2ecde98":"markdown","d78fa52e":"markdown","34f65dce":"markdown","1fde3466":"markdown","17cabe42":"markdown","85734215":"markdown"},"source":{"8dce62f6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport requests\nfrom bs4 import BeautifulSoup","39cabe92":"# create urls for all seasons of all leagues\nbase_url = 'https:\/\/understat.com\/league'\nleagues = ['La_liga', 'EPL', 'Bundesliga', 'Serie_A', 'Ligue_1', 'RFPL']\nseasons = ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']","8495e535":"# Starting with latest data for Spanish league, because I'm a Barcelona fan\nurl = base_url+'\/'+leagues[0]+'\/'+seasons[4]\nres = requests.get(url)\nsoup = BeautifulSoup(res.content, \"lxml\")\n\n# Based on the structure of the webpage, I found that data is in the JSON variable, under <script> tags\nscripts = soup.find_all('script')\n\n# Check our <script> tags\n# for el in scripts:\n#   print('*'*50)\n#   print(el.text)","de593ef8":"import json\n\nstring_with_json_obj = ''\n\n# Find data for teams\nfor el in scripts:\n    if 'teamsData' in str(el):\n        string_with_json_obj = str(el).strip()\n      \n# print(string_with_json_obj)\n\n# strip unnecessary symbols and get only JSON data\nind_start = string_with_json_obj.index(\"('\")+2\nind_end = string_with_json_obj.index(\"')\")\njson_data = string_with_json_obj[ind_start:ind_end]\n\njson_data = json_data.encode('utf8').decode('unicode_escape')","8e027be1":"# convert JSON data into Python dictionary\ndata = json.loads(json_data)\nprint(data.keys())\nprint('='*50)\nprint(data['138'].keys())\nprint('='*50)\nprint(data['138']['id'])\nprint('='*50)\nprint(data['138']['title'])\nprint('='*50)\nprint(data['138']['history'][0])\n\n# Print pretty JSON data to check out what we have there\n# s = json.dumps(data, indent=4, sort_keys=True)\n# print(s)","9dde02e4":"# Get teams and their relevant ids and put them into separate dictionary\nteams = {}\nfor id in data.keys():\n  teams[id] = data[id]['title']","1591a68b":"# EDA to get a feeling of how the JSON is structured\n# Column names are all the same, so we just use first element\ncolumns = []\n# Check the sample of values per each column\nvalues = []\nfor id in data.keys():\n  columns = list(data[id]['history'][0].keys())\n  values = list(data[id]['history'][0].values())\n  break\n\nprint(columns)\nprint(values)","8f8b1b3d":"sevilla_data = []\nfor row in data['138']['history']:\n  sevilla_data.append(list(row.values()))\n  \ndf = pd.DataFrame(sevilla_data, columns=columns)\ndf.head(2)","ce8fc17b":"# Getting data for all teams\ndataframes = {}\nfor id, team in teams.items():\n  teams_data = []\n  for row in data[id]['history']:\n    teams_data.append(list(row.values()))\n    \n  df = pd.DataFrame(teams_data, columns=columns)\n  dataframes[team] = df\n  print('Added data for {}.'.format(team))\n  ","b6a26e2e":"# Sample check of our newly created DataFrame\ndataframes['Barcelona'].head(2)","66dad1b5":"for team, df in dataframes.items():\n  dataframes[team]['ppda_coef'] = dataframes[team]['ppda'].apply(lambda x: x['att']\/x['def'] if x['def'] != 0 else 0)\n  dataframes[team]['oppda_coef'] = dataframes[team]['ppda_allowed'].apply(lambda x: x['att']\/x['def'] if x['def'] != 0 else 0)\n  \n# And check how our new dataframes look based on Sevilla dataframe\ndataframes['Sevilla'].head(2)","ddf9f5fc":"cols_to_sum = ['xG', 'xGA', 'npxG', 'npxGA', 'deep', 'deep_allowed', 'scored', 'missed', 'xpts', 'wins', 'draws', 'loses', 'pts', 'npxGD']\ncols_to_mean = ['ppda_coef', 'oppda_coef']","45846b9d":"frames = []\nfor team, df in dataframes.items():\n  sum_data = pd.DataFrame(df[cols_to_sum].sum()).transpose()\n  mean_data = pd.DataFrame(df[cols_to_mean].mean()).transpose()\n  final_df = sum_data.join(mean_data)\n  final_df['team'] = team\n  final_df['matches'] = len(df)\n  frames.append(final_df)\n  \nfull_stat = pd.concat(frames)","54b97a02":"full_stat = full_stat[['team', 'matches', 'wins', 'draws', 'loses', 'scored', 'missed', 'pts', 'xG', 'npxG', 'xGA', 'npxGA', 'npxGD', 'ppda_coef', 'oppda_coef', 'deep', 'deep_allowed', 'xpts']]\nfull_stat.sort_values('pts', ascending=False, inplace=True)\nfull_stat.reset_index(inplace=True, drop=True)\nfull_stat['position'] = range(1,len(full_stat)+1)","b0a441b5":"full_stat['xG_diff'] = full_stat['xG'] - full_stat['scored']\nfull_stat['xGA_diff'] = full_stat['xGA'] - full_stat['missed']\nfull_stat['xpts_diff'] = full_stat['xpts'] - full_stat['pts']","6cdc57b4":"cols_to_int = ['wins', 'draws', 'loses', 'scored', 'missed', 'pts', 'deep', 'deep_allowed']\nfull_stat[cols_to_int] = full_stat[cols_to_int].astype(int)","fea3314a":"col_order = ['position','team', 'matches', 'wins', 'draws', 'loses', 'scored', 'missed', 'pts', 'xG', 'xG_diff', 'npxG', 'xGA', 'xGA_diff', 'npxGA', 'npxGD', 'ppda_coef', 'oppda_coef', 'deep', 'deep_allowed', 'xpts', 'xpts_diff']\nfull_stat = full_stat[col_order]\npd.options.display.float_format = '{:,.2f}'.format\nfull_stat.head(10)","d7a9d197":"season_data = dict()\nseason_data[seasons[4]] = full_stat\nprint(season_data)\nfull_data = dict()\nfull_data[leagues[0]] = season_data\nprint(full_data)","50196f34":"full_data = dict()\nfor league in leagues:\n  \n  season_data = dict()\n  for season in seasons:    \n    url = base_url+'\/'+league+'\/'+season\n    res = requests.get(url)\n    soup = BeautifulSoup(res.content, \"lxml\")\n\n    # Based on the structure of the webpage, I found that data is in the JSON variable, under <script> tags\n    scripts = soup.find_all('script')\n    \n    string_with_json_obj = ''\n\n    # Find data for teams\n    for el in scripts:\n        if 'teamsData' in el.text:\n          string_with_json_obj = el.text.strip()\n\n    # print(string_with_json_obj)\n\n    # strip unnecessary symbols and get only JSON data\n    ind_start = string_with_json_obj.index(\"('\")+2\n    ind_end = string_with_json_obj.index(\"')\")\n    json_data = string_with_json_obj[ind_start:ind_end]\n    json_data = json_data.encode('utf8').decode('unicode_escape')\n    \n    \n    # convert JSON data into Python dictionary\n    data = json.loads(json_data)\n    \n    # Get teams and their relevant ids and put them into separate dictionary\n    teams = {}\n    for id in data.keys():\n      teams[id] = data[id]['title']\n      \n    # EDA to get a feeling of how the JSON is structured\n    # Column names are all the same, so we just use first element\n    columns = []\n    # Check the sample of values per each column\n    values = []\n    for id in data.keys():\n      columns = list(data[id]['history'][0].keys())\n      values = list(data[id]['history'][0].values())\n      break\n      \n    # Getting data for all teams\n    dataframes = {}\n    for id, team in teams.items():\n      teams_data = []\n      for row in data[id]['history']:\n        teams_data.append(list(row.values()))\n\n      df = pd.DataFrame(teams_data, columns=columns)\n      dataframes[team] = df\n      # print('Added data for {}.'.format(team))\n      \n    \n    for team, df in dataframes.items():\n      dataframes[team]['ppda_coef'] = dataframes[team]['ppda'].apply(lambda x: x['att']\/x['def'] if x['def'] != 0 else 0)\n      dataframes[team]['oppda_coef'] = dataframes[team]['ppda_allowed'].apply(lambda x: x['att']\/x['def'] if x['def'] != 0 else 0)\n      \n    cols_to_sum = ['xG', 'xGA', 'npxG', 'npxGA', 'deep', 'deep_allowed', 'scored', 'missed', 'xpts', 'wins', 'draws', 'loses', 'pts', 'npxGD']\n    cols_to_mean = ['ppda_coef', 'oppda_coef']\n    \n    frames = []\n    for team, df in dataframes.items():\n      sum_data = pd.DataFrame(df[cols_to_sum].sum()).transpose()\n      mean_data = pd.DataFrame(df[cols_to_mean].mean()).transpose()\n      final_df = sum_data.join(mean_data)\n      final_df['team'] = team\n      final_df['matches'] = len(df)\n      frames.append(final_df)\n\n    full_stat = pd.concat(frames)\n    \n    full_stat = full_stat[['team', 'matches', 'wins', 'draws', 'loses', 'scored', 'missed', 'pts', 'xG', 'npxG', 'xGA', 'npxGA', 'npxGD', 'ppda_coef', 'oppda_coef', 'deep', 'deep_allowed', 'xpts']]\n    full_stat.sort_values('pts', ascending=False, inplace=True)\n    full_stat.reset_index(inplace=True, drop=True)\n    full_stat['position'] = range(1,len(full_stat)+1)\n    \n    full_stat['xG_diff'] = full_stat['xG'] - full_stat['scored']\n    full_stat['xGA_diff'] = full_stat['xGA'] - full_stat['missed']\n    full_stat['xpts_diff'] = full_stat['xpts'] - full_stat['pts']\n    \n    cols_to_int = ['wins', 'draws', 'loses', 'scored', 'missed', 'pts', 'deep', 'deep_allowed']\n    full_stat[cols_to_int] = full_stat[cols_to_int].astype(int)\n    \n    col_order = ['position', 'team', 'matches', 'wins', 'draws', 'loses', 'scored', 'missed', 'pts', 'xG', 'xG_diff', 'npxG', 'xGA', 'xGA_diff', 'npxGA', 'npxGD', 'ppda_coef', 'oppda_coef', 'deep', 'deep_allowed', 'xpts', 'xpts_diff']\n    full_stat = full_stat[col_order]\n    full_stat = full_stat.set_index('position')\n    # print(full_stat.head(20))\n    \n    season_data[season] = full_stat\n  \n  df_season = pd.concat(season_data)\n  full_data[league] = df_season\n  \ndata = pd.concat(full_data)\ndata.head()\n  ","ecce6217":"data.to_csv('understat.com.csv')","f5e2efeb":"Wualya! We have the data for all matches of Sevilla in season 2018-2019 within La Liga!\n\nNow we want to do that for all Spanish teams. Let's loop through that bites baby!","47de11c8":"We are ready to calculate our totals and means. For this we loop through dictionary of dataframes and call .sum() and .mean() DataFrame methods that return Series, that's why we add .transpose() to those calls. We put these new DataFrames into a list and after that concat them into a new DataFrame `full_stat`","7f20dedb":"We found that the data interesting us is stored in teamsData variable, after creating a soup of html tags it becomes just a string, so we find that text and extract JSON from it.","150b6375":"Converting floats to integers where appropriate","477e4bc7":"Now we have a dictionary of DataFrames where key is the name of the team and value is the DataFrame with all games of that team.","5ee92f30":"Original table\n\n![full_table.JPG](http:\/\/sergilehkyi.com\/wp-content\/uploads\/2019\/06\/full_table.jpg)","d44f1f6e":"We can notice that here such metrics as PPDA and OPPDA (ppda and ppda_allowed) are represented as total amounts of attacking\/defensive actions, but in the original table it is shown as coefficient. Let's fix that!","acf90bf8":"### Understanding data with Python","938514b7":"Now we have all our numbers, but for every single game. What we need is the totals for the team. Let's find out the columns we have to sum up. For this we go back to original table at [understat.com](https:\/\/understat.com\/league\/La_liga\/2018) and we find that all metrics shoud be summed up and only PPDA and OPPDA are means in the end.","e9a5240e":"### Manipulations to make data as in the original source","aa0f9bf6":"## Exporting data to CSV file","13de2cba":"Next step is to understand where the data is located on the web-page. For this we open Developer Tools in Chrome, go to tab \"Network\", find file with data (in this case 2018) and check the \"Response\" tab. This is what we will get after running *requests.get(URL)*\n\n![requests_response_1.jpg](http:\/\/sergilehkyi.com\/wp-content\/uploads\/2019\/06\/requests_response_1.jpg)\n\nAfter going through content of the web-page we find that the data is stored under \"script\" tag and it is JSON encoded. So we will need to find this tag, get JSON from it and convert it into Python readable data structure.\n\n![requests_response_2.jpg](http:\/\/sergilehkyi.com\/wp-content\/uploads\/2019\/06\/requests_response_2.jpg)","e460bda9":"Testing the flow before going full into the process","ecc28dcd":"On the home page we can notice that the site has data for 6 European Leagues:\n\n![leagues.jpg](http:\/\/sergilehkyi.com\/wp-content\/uploads\/2019\/06\/leagues.jpg)\n\n*   La Liga\n*   EPL\n*   BundesLiga\n*   Serie A\n*   Ligue 1\n*   RFPL\n\nAnd we also see that the data collected is starting from season 2014\/2015. Another notion we make is the structure of URL. It is '`https:\/\/understat.com\/league'` + '`\/name_of_the_league`' + '`\/year_start_of_the_season`'\n\n![seasons.jpg](http:\/\/sergilehkyi.com\/wp-content\/uploads\/2019\/06\/seasons.jpg)\n\nSo we create global variables with this data to be able to select any of those.","e97e92c2":"We start by importing libraries that will be used in this project:\n* numpy - fundamental package for scientific computing with Python\n* pandas - library providing high-performance, easy-to-use data structures and data analysis tools\n* requests - is the only Non-GMO HTTP library for Python, safe for human consumption. (love this line from official docs :D)\n* BeautifulSoup - a Python library for pulling data out of HTML and XML files.","19a68e56":"## Intro","e253164d":"If you want to check how the entire <code>data<\/code> looks, just uncomment respective lines. (it is commented for the sake of saving screen space and do not oversaturate the view of notebook).\n\nWhen we start to research the <code>data<\/code> we understand that this is a dictionary of dictionaries of 3 keys: *`id`*, *`title`* and *`history`*. The first layer of dictionary uses ids as keys too.\n\nAlso from this we understand that *`history`* has data regarding every single match the team played in its own league (League Cup or Champions League games are not included).\n\nWe can gather teams names if go over the first layer dictionary.","d4aae555":"Prettifying output and final view of a DataFrame","9c762a3d":"## Scraping data for all teams of all leagues of all seasons","6128c500":"[](http:\/\/)![understat.JPG](http:\/\/sergilehkyi.com\/wp-content\/uploads\/2019\/06\/understat.jpg)\n\nIn this notebook I will describe the process of scraping data from web portal [understat.com](https:\/\/understat.com) that has a lot of statistical information about all games in top 5 European football leagues.\n\nFrom [understat.com](https:\/\/understat.com) home page:\n\n* Expected goals (xG) is the new revolutionary football metric, which allows you to evaluate team and player performance.\n\n* In a low-scoring game such as football, final match score does not provide a clear picture of performance.\n\n* This is why more and more sports analytics turn to the advanced models like xG, which is a statistical measure of the quality of chances created and conceded.\n\n* Our goal was to create the most precise method for shot quality evaluation.\n\n* For this case, we trained neural network prediction algorithms with the large dataset (>100,000 shots, over 10 parameters for each).\n\n* On this site, you will find our detailed xG statistics for the top European leagues.\n\nAt this moment they have not only xG metric, but much more, that makes this site perfect for scraping statistical data about football games.\n\n\n","42db3c05":"The *`history`* is the array of dictionaries where keys are names of metrics (read column names) and values are values, despite how tautological is that :D.\n\nWe understand that column names repeat over and over again so we add them to separate list. Also checking how the sample values look like.","9efc3e56":"### Working with JSON","b2ecde98":"Once we have gotten our JSON and cleaned it up we can convert it into Python dictionary and check how it looks (uncomment print statement to do that).","d78fa52e":"Also in the original table we have values of differences between expected metrics and real. Let's add those too.","34f65dce":"## Website research and structure of data","1fde3466":"Found that Sevilla has the id=138, so getting all the data for this team to be able to reproduce the same steps for all teams in the league.","17cabe42":"Next we reorder columns for better readability, sort rows based on points, reset index and add column 'position'.","85734215":"Putting all the previous code into loops to get all data."}}