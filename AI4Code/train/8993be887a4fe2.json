{"cell_type":{"47d71061":"code","c5624efb":"code","51a1135e":"code","b3d98385":"code","ddd8c2ff":"code","13ca1992":"code","bb4d87c5":"code","fc4b14eb":"code","12f5813a":"code","1337b23a":"code","f5c956ff":"code","50555d4e":"code","770fe9ba":"code","92f9ee36":"code","03519c28":"code","e3c63d54":"code","fffa79dd":"code","3d6a906b":"code","9f394ba3":"code","bc88f2ed":"code","f78735b0":"code","c266b3f1":"code","33b934c8":"code","d1d45814":"code","6f9b0a47":"code","9d8e0a60":"code","40d397eb":"code","8a435e2b":"code","4d367d26":"code","ebf5ca35":"code","a406b96b":"code","590084a1":"code","04f74579":"code","fc947d89":"markdown","96ebabc1":"markdown","4ab560d7":"markdown","64c2c9a9":"markdown","93228a8d":"markdown","21c85c9e":"markdown","d7a8fbaf":"markdown","8abcd396":"markdown","9ef034d6":"markdown","2340d876":"markdown","32b6f8c8":"markdown","298d5d4b":"markdown","63e23a89":"markdown","8fa4c2d4":"markdown","d8c969a0":"markdown","0767262f":"markdown"},"source":{"47d71061":"#importing necessary libraries\nimport tensorflow as tf\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom collections import defaultdict\nfrom tensorflow import keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Dropout, MaxPooling2D, Conv2D, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import DenseNet121, EfficientNetB5, Xception\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","c5624efb":"#loading training data\ntrain_df = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\ntrain_path = \"..\/input\/plant-pathology-2021-fgvc8\/train_images\"\ntrain_df.head()","51a1135e":"train_df.info()","b3d98385":"img = plt.imread(train_path+\"\/\"+train_df[\"image\"][0])\nimg.shape","ddd8c2ff":"plt.imshow(img)","13ca1992":"train_df.groupby('labels').count().plot(kind='bar', title='Target class distribution', figsize=(20,10), grid=1)","bb4d87c5":"train_df[\"labels\"].unique()","fc4b14eb":"fig, ax = plt.subplots(3, 4, figsize=(20, 10))\nfor i, img in enumerate(train_df.groupby('labels').first().reset_index().values):\n    ax[i\/\/4][i%4].imshow(plt.imread(f\"..\/input\/plant-pathology-2021-fgvc8\/train_images\/{img[1]}\"))\n    ax[i\/\/4][i%4].set_title(img[0])\n    ax[i\/\/4][i%4].axis('off')\nfig.suptitle('Image Samples', fontsize=18); ","12f5813a":"mlb = MultiLabelBinarizer().fit(train_df.labels.apply(lambda x : x.split()))\nlabels = pd.DataFrame(mlb.transform(train_df.labels.apply(lambda x : x.split())), columns = mlb.classes_)\n\nlabels = pd.concat([train_df['image'], labels], axis=1)\nlabels.head()","1337b23a":"image_datagen = ImageDataGenerator(\n    rescale=1\/255.0,\n    rotation_range=5,\n    zoom_range=0.1,\n    shear_range=0.05,\n    horizontal_flip=True,\n    validation_split=0.2\n    \n)\nIMAGE = (224, 224)\nBATCH_SIZE = 32","f5c956ff":"train_generator = image_datagen.flow_from_dataframe(\n    labels,\n    directory='..\/input\/resized-plant2021\/img_sz_256',\n    x_col=\"image\",\n    y_col=labels.columns.tolist()[1:],\n    target_size=IMAGE,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    subset=\"training\",\n    shuffle=True,\n    seed=42,\n    class_mode=\"raw\"\n)","50555d4e":"validation_generator = image_datagen.flow_from_dataframe(\n    labels,\n    directory='..\/input\/resized-plant2021\/img_sz_256',\n    x_col=\"image\",\n    y_col=labels.columns.tolist()[1:],\n    target_size=IMAGE,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    subset=\"validation\",\n    shuffle=True,\n    seed=42,\n    class_mode=\"raw\"\n)","770fe9ba":"example = next(train_generator)\nprint(example[0].shape)\nplt.imshow(example[0][0,:,:,:])\nplt.show()","92f9ee36":"WEIGHTS_PATH = '..\/input\/weights\/efficientnetb5_notop.h5'\nbase_model = EfficientNetB5(weights=WEIGHTS_PATH,include_top=False, input_shape=(224,224,3))\n\nx=base_model.output\n\nx=GlobalAveragePooling2D()(x)\n\nx=Dense(64,activation='relu')(x)\nx=Dropout(0.3)(x)\n\nx=Dense(32,activation='relu')(x)\nx=Dropout(0.3)(x)\n\npreds=Dense(6,activation='sigmoid')(x)\n\nmodel=Model(inputs=base_model.input, outputs=preds)","03519c28":"model.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=\"adam\",\n    metrics=[\"accuracy\"])","e3c63d54":"model_checkpoint = ModelCheckpoint(\n    filepath=\".\/appletree.h5\", \n    monitor='val_loss', \n    save_best_only=True, \n    verbose=1,\n    mode='min')\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss', \n    min_delta=0,\n    patience=10, \n    verbose=1, \n    restore_best_weights=True)","fffa79dd":"history = model.fit(train_generator,\n                validation_data=validation_generator,\n                steps_per_epoch = train_generator.n \/\/ BATCH_SIZE,\n                validation_steps = validation_generator.n \/\/ BATCH_SIZE,\n                epochs=10,\n                callbacks=[model_checkpoint, early_stopping])","3d6a906b":"model.save('apple')","9f394ba3":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","bc88f2ed":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f78735b0":"test_df = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')\ntest_path = \"..\/input\/plant-pathology-2021-fgvc8\/test_images\"","c266b3f1":"test_df.head()","33b934c8":"img = plt.imread(test_path+\"\/\"+test_df[\"image\"][0])\nplt.imshow(img)","d1d45814":"img = plt.imread(test_path+\"\/\"+test_df[\"image\"][1])\nplt.imshow(img)","6f9b0a47":"img = plt.imread(test_path+\"\/\"+test_df[\"image\"][2])\nplt.imshow(img)","9d8e0a60":"image_test_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n)","40d397eb":"test_generator = image_test_datagen.flow_from_dataframe(\n    test_df,\n    directory = test_path,\n    x_col = \"image\",\n    y_col = \"labels\",\n    target_size = IMAGE,\n    color_mode=\"rgb\",\n    batch_size=1,\n    shuffle=False,\n    seed=42,\n    subset=None\n)","8a435e2b":"loaded_model = keras.models.load_model(\"apple\")","4d367d26":"predicts = loaded_model.predict(test_generator)\npredicts","ebf5ca35":"verdict = (predicts>0.40)\nlabel = labels.columns.tolist()[1:]\nverdict","a406b96b":"answer = []\nfor i in range(verdict.shape[0]):\n    tmp = []\n    for j, c in enumerate(label):\n        if verdict[i, j]:\n            tmp.append(c)\n    answer.append(tmp)\n    \nanswer = [' '.join(t) for t in answer]\nanswer","590084a1":"test_df['labels'] = np.array(answer)\n\ntest_df","04f74579":"test_df.to_csv('submission.csv', index=False)","fc947d89":"## Visualization","96ebabc1":"# Model","4ab560d7":"# Training","64c2c9a9":"It can be seen that some pictures have several labels. I think this is a multi-label classification task","93228a8d":"# Image Generator","21c85c9e":"# Prediction","d7a8fbaf":"# Plant Pathology 2021 FGVC8\n## Description\n\nApples are one of the most important temperate fruit crops in the world. Foliar (leaf) diseases pose a major threat to the overall productivity and quality of apple orchards. The current process for disease diagnosis in apple orchards is based on manual scouting by humans, which is time-consuming and expensive.\n\nAlthough computer vision-based models have shown promise for plant disease identification, there are some limitations that need to be addressed. Large variations in visual symptoms of a single disease across different apple cultivars, or new varieties that originated under cultivation, are major challenges for computer vision-based disease identification. These variations arise from differences in natural and image capturing environments, for example, leaf color and leaf morphology, the age of infected tissues, non-uniform image background, and different light illumination during imaging etc.\n\nPlant Pathology 2021-FGVC8 challenge competition had a pilot dataset of 3,651 RGB images of foliar disease of apples. For Plant Pathology 2021-FGVC8, we have significantly increased the number of foliar disease images and added additional disease categories. This year\u2019s dataset contains approximately 23,000 high-quality RGB images of apple foliar diseases, including a large expert-annotated disease dataset. This dataset reflects real field scenarios by representing non-homogeneous backgrounds of leaf images taken at different maturity stages and at different times of day under different focal camera settings.\n\n## Specific Objectives\nThe main objective of the competition is to develop machine learning-based models to accurately classify a given leaf image from the test dataset to a particular disease category, and to identify an individual disease from multiple disease symptoms on a single leaf image.","8abcd396":"![image.png](attachment:8d039e7d-0380-4618-a593-359d17b30b0e.png)","9ef034d6":"No empty values.","2340d876":"Building a histogram of class labels","32b6f8c8":"Let's look at an example picture","298d5d4b":"## Image samples","63e23a89":"# Data Preprocessing","8fa4c2d4":"## Callbacks","d8c969a0":"Now let's highlight the most basic labels for future convenience","0767262f":"There are 12 classes in total. Many labels are complex. Let's look at an example of a picture from each label"}}