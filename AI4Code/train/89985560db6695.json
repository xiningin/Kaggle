{"cell_type":{"8df40eee":"code","6362efed":"code","00f5f9d0":"code","335eab82":"code","ec002c97":"code","5084f407":"code","f49deed7":"code","8a424f1e":"code","9a27cc02":"code","18d1bb74":"code","905d2575":"code","9562b3d7":"code","ff820f25":"code","069045f9":"code","eecf709e":"code","ad39b665":"code","af6afcf5":"code","a886822e":"code","88095512":"code","d3e9258c":"code","e07c6c95":"code","c276eb8a":"code","83b8d1eb":"code","2389a653":"code","009bc53c":"code","18a0b595":"code","70b755b3":"code","05b85f47":"code","a58205a8":"code","bdcc7f1e":"code","379ed15b":"code","d7019c07":"code","6a814ec3":"code","594f24bb":"code","e81bab0e":"code","09a24af9":"code","6c5b5ae9":"code","c94184ee":"code","7851a220":"code","21b1190d":"code","70f135a1":"code","b089589a":"code","cbae2c16":"code","a30a8fbe":"code","d95727f0":"code","804f9ca3":"code","6ee34245":"code","9265d2d5":"code","b296953b":"code","6cdfe9c8":"code","e1f472d8":"code","530f5e53":"code","6f0b00a5":"code","4953024c":"code","663260a7":"code","262bbc9e":"code","1db9dd29":"code","cc1170dd":"code","2563f399":"code","7bfeb7c6":"code","60c4ca9e":"code","906a6f37":"code","ab1885cd":"code","70c25eff":"code","a05f8ac3":"code","235f701c":"code","0b4f88e5":"code","4b698f86":"code","1cd9ae34":"code","b2e830d9":"code","e435d033":"code","ef64449b":"code","745e8929":"markdown","eb87268d":"markdown","1a0f2a18":"markdown","511353f3":"markdown","9d9c615f":"markdown","efb37949":"markdown","77a28722":"markdown","961d3402":"markdown","34912ee3":"markdown","1d407f33":"markdown","b3fb2204":"markdown","51207b5a":"markdown","444f5c4d":"markdown","9dfaa968":"markdown","b8171a87":"markdown","7fdccf34":"markdown","df027ee4":"markdown","a195757f":"markdown","68959ac5":"markdown","4b8d3611":"markdown","fc173efe":"markdown","caed5961":"markdown","0593aeac":"markdown","1d4971b0":"markdown","990f28fc":"markdown","980baaa1":"markdown","65b7b300":"markdown","3e21b873":"markdown","c05a6e35":"markdown","e90e179b":"markdown","a6e09d0e":"markdown","d426c51f":"markdown","70a8721e":"markdown","f0ddcc88":"markdown"},"source":{"8df40eee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6362efed":"!pip3 install pycaret[full]\n!pip3 install scikit-learn==0.23.2","00f5f9d0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom imblearn.over_sampling import SMOTE\nfrom pycaret.classification import * ","335eab82":"test_df = pd.read_csv(\"\/kaggle\/input\/telecom-churn-datasets\/churn-bigml-20.csv\")\ncustomer_df = pd.read_csv(\"\/kaggle\/input\/telecom-churn-datasets\/churn-bigml-80.csv\")","ec002c97":"customer_df.head()","5084f407":"customer_df.info()","f49deed7":"customer_df.describe()","8a424f1e":"customer_df.shape","9a27cc02":"customer_df.columns","18d1bb74":"customer_df.head()","905d2575":"numeric_columns = [\"Account length\", \"Number vmail messages\", \"Total day minutes\", \"Total day calls\", \"Total day charge\", \"Total eve minutes\", \"Total eve calls\", \"Total eve charge\", \"Total night minutes\", \"Total night calls\", \"Total night charge\", \"Total intl minutes\", \"Total intl calls\", \"Total intl charge\", \"Customer service calls\"]\ncategorical_columns = [\"State\", \"Area code\", \"International plan\", \"Voice mail plan\", \"Churn\"]\ntarget = [\"Churn\"]\n\nnumeric_df = customer_df[numeric_columns]\ntest_numeric_df = test_df[numeric_columns]\n\ncategorical_df = customer_df[categorical_columns]\ntest_categorical_df = test_df[categorical_columns]\n\ntarget_df = customer_df[target]\ntest_target_df = test_df[target]","9562b3d7":"customer_df[\"Churn\"].value_counts()","ff820f25":"# Just making sure we split the columns correctly\nlen(numeric_columns) + len(categorical_columns) + len(target)","069045f9":"plt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(numeric_df.corr(), vmin=-1, vmax=1, annot=True)\nheatmap.set_title('Correlation of numeric attributes', fontdict={'fontsize':12}, pad=12);","eecf709e":"print (\"Histogram for Numerical Variables\")\nplots = numeric_df.hist(figsize=(15,15))","ad39b665":"sns.pairplot(numeric_df)\nplt.show()","af6afcf5":"categorical_df.shape","a886822e":"categorical_df.head()","88095512":"len(categorical_df[\"State\"].value_counts())","d3e9258c":"temp_df = categorical_df[[\"Area code\", \"International plan\", \"Voice mail plan\"]]\ntemp_df.columns = temp_df.columns.str.replace(' ', '')\nsns.set(style=\"darkgrid\")\nfig, ax =plt.subplots(3,1)\nfig = plt.figure(figsize=(8, 6))\nmax_count = max([max(temp_df[i].value_counts()) for i in temp_df.columns])\nArea_code=sns.countplot(y=temp_df['Areacode'],ax=ax[0],order=temp_df.Areacode.value_counts().iloc[:2].index)\nInternational_plan=sns.countplot(y=temp_df['Internationalplan'],ax=ax[1],order=temp_df.Internationalplan.value_counts().iloc[:2].index)\nVoice_mail_plan=sns.countplot(y=temp_df['Voicemailplan'],ax=ax[2],order=temp_df.Voicemailplan.value_counts().iloc[:2].index)\nax[0].set_xlim(0,max_count)\nax[1].set_xlim(0,max_count)\nax[2].set_xlim(0,max_count)\nArea_code.set(xticklabels=[])\nInternational_plan.set(xticklabels=[])","e07c6c95":"numeric_df.drop(columns=[\"Total day minutes\", \"Total eve minutes\", \"Total night minutes\", \"Total intl minutes\"], axis=1, inplace=True)\ntest_numeric_df.drop(columns=[\"Total day minutes\", \"Total eve minutes\", \"Total night minutes\", \"Total intl minutes\"], axis=1, inplace=True)","c276eb8a":"plt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(numeric_df.corr(), vmin=-1, vmax=1, annot=True)\nheatmap.set_title('Correlation of numeric attributes', fontdict={'fontsize':12}, pad=12);","83b8d1eb":"numeric_df.head()\n# test_numeric_df.head()","2389a653":"scaler = StandardScaler()\nnumeric_df = pd.DataFrame(scaler.fit_transform(numeric_df) , columns = numeric_df.columns)\ntest_numeric_df = pd.DataFrame(scaler.transform(test_numeric_df) , columns = test_numeric_df.columns)","009bc53c":"numeric_df.head()","18a0b595":"categorical_df.head()","70b755b3":"list(categorical_df.columns)","05b85f47":"new_category_df = categorical_df.copy(deep=True)\nnew_category_df.head()\n\nnew_test_category_df = test_categorical_df.copy(deep=True)","a58205a8":"nominal_categories =  ['Area code', 'State']\nfor category in nominal_categories:\n    nominal_column = categorical_df[category]\n    nominal_column = nominal_column.reset_index(drop=True)\n    dummy_columns = pd.get_dummies(nominal_column.astype(str))\n    new_category_df.drop(columns=[category], axis=1, inplace=True)\n    new_category_df = new_category_df.reset_index(drop=True)\n    new_category_df = pd.concat([new_category_df, dummy_columns], axis=1)\n    \nfor category in nominal_categories:\n    nominal_column = test_categorical_df[category]\n    nominal_column = nominal_column.reset_index(drop=True)\n    dummy_columns = pd.get_dummies(nominal_column.astype(str))\n    new_test_category_df.drop(columns=[category], axis=1, inplace=True)\n    new_test_category_df = new_test_category_df.reset_index(drop=True)\n    new_test_category_df = pd.concat([new_test_category_df, dummy_columns], axis=1)","bdcc7f1e":"new_category_df.head()","379ed15b":"new_test_category_df.head()","d7019c07":"intl_plan = {\"International plan\":{\"No\": 0, \"Yes\": 1}}\nnew_category_df = new_category_df.replace(intl_plan)\nnew_test_category_df = new_test_category_df.replace(intl_plan)\n             \nvm_plan = {\"Voice mail plan\":{\"No\": 0, \"Yes\": 1}}\nnew_category_df = new_category_df.replace(vm_plan)\nnew_test_category_df = new_test_category_df.replace(vm_plan)\n\nchurn_cleanup = {\"Churn\":{False: 0, True: 1}}\nnew_category_df = new_category_df.replace(churn_cleanup)\nnew_test_category_df = new_test_category_df.replace(churn_cleanup)","6a814ec3":"new_category_df","594f24bb":"new_test_category_df","e81bab0e":"new_category_df = new_category_df.reset_index(drop=True)\nnew_test_category_df = new_test_category_df.reset_index(drop=True)","09a24af9":"combined_df = pd.concat([numeric_df, new_category_df], axis=1)\ncombined_test_df = pd.concat([test_numeric_df, new_test_category_df], axis=1)","6c5b5ae9":"combined_df.head()","c94184ee":"combined_test_df.head()","7851a220":"steps = [('pca', PCA()), ('m', LogisticRegression())]\nmodel = Pipeline(steps=steps)","21b1190d":"models = {}\nfor i in range(1,60):\n    steps = [('pca', PCA(n_components=i)), ('lr', LogisticRegression())]\n    models[str(i)] = Pipeline(steps=steps)","70f135a1":"x_columns = combined_df.columns.tolist()\nx_columns.remove('Churn')","b089589a":"results = []\nnames = []\nfor name, model in models.items():\n    model.fit(combined_df[x_columns],combined_df[\"Churn\"])\n    y_pred = model.predict(combined_test_df[x_columns])\n    f1 = f1_score(combined_test_df[\"Churn\"], y_pred)\n    accuracy = accuracy_score(combined_test_df[\"Churn\"], y_pred)\n    results.append(f1)\n    names.append(name)\n    print(f\"{name} components: F1 score ->{f1}, accuracy score ->{accuracy}\")","cbae2c16":"combined_df[\"Churn\"].value_counts()","a30a8fbe":"oversample = SMOTE()\nx, y = oversample.fit_resample(combined_df[x_columns], combined_df[\"Churn\"])","d95727f0":"x","804f9ca3":"y.value_counts()","6ee34245":"result_dict = {}\nfor name, model in models.items():\n    model.fit(x,y)\n    y_pred = model.predict(combined_test_df[x_columns])\n    f1 = f1_score(combined_test_df[\"Churn\"], y_pred)\n    accuracy = accuracy_score(combined_test_df[\"Churn\"], y_pred)\n    recall = recall_score(combined_test_df[\"Churn\"], y_pred)\n    result_dict[name] = f1\n    print(f\"{name} components: F1 score ->{f1}, accuracy score ->{accuracy}, recall score-> {recall}\")","9265d2d5":"results_ranking = {k: v for k, v in sorted(result_dict.items(), key=lambda item: item[1], reverse=True)}","b296953b":"results_ranking","6cdfe9c8":"pca = PCA(n_components=21)\nx_train_new = pca.fit_transform(x[x_columns])\nx_train_new","e1f472d8":"sum(pca.explained_variance_ratio_)","530f5e53":"len(x_train_new)","6f0b00a5":"X_test_new = pca.transform(combined_test_df[x_columns])","4953024c":"X_test_new","663260a7":"len(X_test_new)","262bbc9e":"caret_train_df = pd.DataFrame(x_train_new)\ncaret_test_df = pd.DataFrame(X_test_new)","1db9dd29":"caret_train_df[\"Churn\"] = y\ncaret_test_df[\"Churn\"] = combined_test_df[\"Churn\"]","cc1170dd":"caret_train_df","2563f399":"caret_x_columns = caret_train_df.columns.tolist()\ncaret_x_columns.remove(\"Churn\")","7bfeb7c6":"for i in caret_x_columns:\n#     caret_train_df[i] = caret_train_df[i].astype('string')\n    caret_train_df.rename(columns={i: f\"column{i}\"}, inplace=True)\n    caret_test_df.rename(columns={i: f\"column{i}\"}, inplace=True)","60c4ca9e":"new_caret_train_columns = caret_train_df.columns.tolist()\nnew_caret_train_columns.remove(\"Churn\")","906a6f37":"for numeric_column in new_caret_train_columns:\n    caret_train_df[numeric_column] = caret_train_df[numeric_column].astype(float)\n    caret_test_df[numeric_column] = caret_test_df[numeric_column].astype(float)\ncaret_train_df","ab1885cd":"caret_test_df","70c25eff":"classification_setup = setup(data= caret_train_df, target=\"Churn\", test_data=None, preprocess=False, silent = True)","a05f8ac3":"compare_models()","235f701c":"lgbm_model = create_model('lightgbm')","0b4f88e5":"tuned_lgbm_model = tune_model(lgbm_model)\nfinalize_model(tuned_lgbm_model)","4b698f86":"predictions = predict_model(tuned_lgbm_model, data = caret_test_df)\npredictions","1cd9ae34":"y_pred = predictions[\"Label\"]\ny_test = predictions[\"Churn\"]","b2e830d9":"f1 = f1_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)","e435d033":"print(f\"F1 score: {f1}\")","ef64449b":"print(f\"Accuracy score: {accuracy}\")","745e8929":"# 1. Importing relevant libraries","eb87268d":"## 3.3 One-hot encoding nominal attributes","1a0f2a18":"We see quite a large disparity between our target variable. This can be an issue later on. Common ways to mitigate this issue is to look at different evaluation metrics, or perform some form of oversamping\/undersamping of minority and majority class respectively","511353f3":"## 6.1 Benchmarking with Logsitic Regression","9d9c615f":"# 5. SMOTE for class balancing","efb37949":"## 3.1 Removing multicollinearlity","77a28722":"## 2.5 Distribution of categorical variables","961d3402":"## 3.5 Combining numeric and categorical columns","34912ee3":"# 9. Evaluating on unseen data","1d407f33":"We can see that there are certain attributes with correlation of 1. Total minutes and total charge is perfectly correlated, regardless whether it is day calls, evening calls, night calls. or international calls.<br> We can immediately drop these attributes.","b3fb2204":"## 9.3 Accuracy","51207b5a":"# 3. Preprocessing","444f5c4d":"## 6.2 Explained variance","9dfaa968":"We see F1 score perform really poorly due to the class imbalance in our dataset","b8171a87":"# 7. Comparing models with PyCaret","7fdccf34":"## 2.3 Correlation of numeric variables","df027ee4":"## 3.4 Label encoding ordinal values","a195757f":"## 2.4 Distribution of numeric variables","68959ac5":"## 9.1 Getting predictions","4b8d3611":"# 2. Exploratory Data Analysis","fc173efe":"## 8.1 Creating model","caed5961":"## 2.2 Distribution of target variable","0593aeac":"With 21 components, we have 95% of explained variance. Cool!","1d4971b0":"## 4.2 Benchmarking with Logistic Regression","990f28fc":"## 3.2 Scaling numeric attributes","980baaa1":"We see the optical number of components is 21 components","65b7b300":"Some bit of manual sorting has to be done here as certain categories are actually represented by numbers","3e21b873":"## 9.2 F1 score","c05a6e35":"# 6. Dimensionality reduction with PCA","e90e179b":"## 2.1 Seperating categorical and numerical variables","a6e09d0e":"## 8.2 Tuning model","d426c51f":"# 4. Dimensionality reduction using PCA","70a8721e":"## 4.1 Creating Pipeline","f0ddcc88":"# 8. LightGBM"}}