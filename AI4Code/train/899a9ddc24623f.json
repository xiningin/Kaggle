{"cell_type":{"1a0321da":"code","93bfb68d":"code","f07c7ae2":"code","2f430d50":"code","f780c1f2":"code","f2f8ef16":"code","667b27bf":"code","65e8159f":"code","2f53f928":"code","f25a4b35":"code","7f2cd6e1":"code","9ca19886":"code","8457f1b4":"code","2f85f7b6":"code","1b07892e":"code","96e240a9":"code","132f40fb":"code","f0b2829c":"code","0dd2c4ac":"code","2668d440":"code","6a6f4b1c":"code","ae39acb5":"code","f69257ae":"code","ea762f3a":"code","dfb32fb8":"code","018ee539":"code","815145f9":"code","e03733d4":"markdown"},"source":{"1a0321da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n!pip install dython\nfrom dython.nominal import compute_associations, associations\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93bfb68d":"train_path = '\/kaggle\/input\/dont-overfit-ii\/train.csv'\ntest_path = '\/kaggle\/input\/dont-overfit-ii\/test.csv'\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)","f07c7ae2":"df_train.head()","2f430d50":"df_train","f780c1f2":"df_train.var()","f2f8ef16":"df_train['0']","667b27bf":"df_train['target'].value_counts()","65e8159f":"for i in range(0, 291, 10):\n    ten = [str(x) for x in range(i, i+10)]\n    ten.append('target')\n    associations(df_train[ten], figsize=(10, 10))","2f53f928":"def draw_correlation_heat_map(data, col_list, label):\n    plt.subplots(figsize=(15,2))\n    corr_table = compute_associations(data[col_list])\n#     print(corr_table[[label]].sort_values(by=[label]))\n    sns.heatmap(corr_table[[label]].sort_values(by=[label]).T)\n    plt.title(f\"Fig. 3. Corelations between {label} and the rest of features.\")\n    return corr_table","f25a4b35":"for i in range(0, 291, 10):\n    ten = [str(x) for x in range(i, i+10)]\n    ten.append('target')\n    draw_correlation_heat_map(df_train, ten, 'target')","7f2cd6e1":"max_corr_list = []\nfor i in range(0, 291, 10):\n    ten = [str(x) for x in range(i, i+10)]\n    ten.append('target')\n    corr_table = compute_associations(df_train[ten])\n    corr = corr_table[['target']].sort_values(by=['target']).T\n    corr_index = corr[corr > 0.05].T.dropna().drop('target').index.tolist()\n    print(corr_index)\n    max_corr_list.extend(corr_index)\n\nprint(max_corr_list)","9ca19886":"df_train[max_corr_list].shape","8457f1b4":"from sklearn.decomposition import PCA\n\npca = PCA()\n# Apply PCA to the wine dataset\ntransformed_X = pca.fit_transform(df_train[max_corr_list])\n# Look at the percentage of variance explained by the different components\nprint(pca.explained_variance_ratio_.round(3))","2f85f7b6":"def create_pca(df, pca):\n    pca_names = ['pca_'+str(x) for x in range(10)]\n    print(pca_names)\n    pca_df = pd.DataFrame(pca.transform(df[max_corr_list])[:,0:10].reshape(-1,10), columns=pca_names)\n    pca_df.info()\n    return pca_df","1b07892e":"pca_df = create_pca(df_train, pca)","96e240a9":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(pca_df, df_train['target'], test_size=0.2, stratify=df_train['target'])","132f40fb":"x_train","f0b2829c":"x_test","0dd2c4ac":"y_train","2668d440":"from sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Lasso\nrfc = Lasso(alpha=0.031, tol=0.01)\nrfc.fit(x_train, y_train)","6a6f4b1c":"y_hat_train = rfc.predict(x_train)\ny_hat = rfc.predict(x_test)","ae39acb5":"from sklearn.metrics import roc_auc_score\nprint('auc_train:', roc_auc_score(y_train, y_hat_train))\nprint('auc_test:', roc_auc_score(y_test, y_hat))","f69257ae":"rfc = Lasso(alpha=0.031, tol=0.01)\nrfc.fit(pca_df, df_train['target'])","ea762f3a":"X_test = create_pca(df_test, pca)","dfb32fb8":"y_hat = rfc.predict(X_test)","018ee539":"df_test.head()","815145f9":"sample_submission= pd.DataFrame({'id':df_test['id'].to_numpy(), 'target':y_hat })\nsample_submission.to_csv(os.path.join('.\/',\"submission.csv\"), index=False)","e03733d4":"END"}}