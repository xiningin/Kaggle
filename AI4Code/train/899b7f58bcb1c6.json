{"cell_type":{"bab8ae50":"code","dd3c1649":"code","68265b70":"code","85df2b7d":"code","b444aaf9":"code","7bfca65b":"code","070eaa82":"code","1cb8baeb":"code","9eab67f8":"code","18bd0d60":"code","244c4014":"code","782fdf10":"code","29c7adff":"code","e07b0c7b":"code","3cc92d3f":"code","8124aac4":"code","7dfa809d":"code","e51d117d":"code","c92d26e8":"code","f82aa0f5":"code","ef745564":"code","0453b234":"code","d57f5815":"code","16583d5f":"code","edfcb274":"code","0fbe1312":"code","a9f4a180":"code","d7950198":"code","8de2603e":"code","2e2e8bc7":"code","6df3e36d":"code","e83ec34d":"code","d7cd8872":"code","f531cf1e":"code","b9dafaaa":"code","2b2eb16e":"code","c25bb51e":"code","a3456d50":"code","10a5ff97":"code","22792b81":"code","3158d8e6":"code","f2863b41":"code","6c76c36d":"code","f5c2653f":"code","2f2a7ee7":"code","0c69c7b1":"code","cc0de76f":"code","a6eab6f5":"code","cd71fdf0":"code","e7a3e76c":"code","c7e15ea1":"code","1989af3c":"code","42f134a8":"code","46845c27":"code","92b11ba1":"code","87509279":"code","35acd4df":"code","496aa112":"code","fe4cec0d":"code","a0a6c16e":"code","b7a33271":"code","04805e65":"code","335527d7":"code","8cb348d9":"code","60b681d6":"code","4fd3baf0":"code","430f9dbc":"code","308374f4":"code","174d3e9f":"code","58433c96":"code","a1d06f0c":"code","0db1e310":"code","efba8dfc":"code","0f96aa1d":"code","6946da73":"code","a1bd0505":"code","39ea46a1":"markdown","14bc15fa":"markdown","b4c850c1":"markdown","77cae279":"markdown","304b8fc5":"markdown","51aca32a":"markdown","3bd240da":"markdown","35d10620":"markdown","f982fecf":"markdown","53b8e968":"markdown","4f87072d":"markdown","6cefaa3c":"markdown","771cab3a":"markdown"},"source":{"bab8ae50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","dd3c1649":"from sklearn.decomposition import KernelPCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.calibration import CalibratedClassifierCV\nimport pickle\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization, Input\nfrom keras.models import Sequential, Model\nfrom keras import optimizers, regularizers, initializers\nfrom keras.callbacks import ModelCheckpoint, Callback\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nimport tensorflow as tf\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","68265b70":"NCA1 = 100\nNCA2 = 50\nDROPRATE = 0.2\nEP = 500\nBATCH_SIZE = 256\nVAL_RATIO = 0.1\nTEST_RATIO = 0.1","85df2b7d":"bbbp_df= pd.read_csv('..\/input\/bbbp_descriptors\/BBBP_df_revised.csv')\nprint(bbbp_df.shape)\nbbbp_df.head()","b444aaf9":"bbbp_df['p_np'].value_counts()","7bfca65b":"bbbp_descriptors_df= pd.read_csv('..\/input\/bbbp_descriptors\/BBBP_descriptors_df.csv',low_memory=False)\nprint(bbbp_descriptors_df.shape)\nbbbp_descriptors_df.head()","070eaa82":"# function to coerce all data types to numeric\n\ndef coerce_to_numeric(df, column_list):\n    df[column_list] = df[column_list].apply(pd.to_numeric, errors='coerce')","1cb8baeb":"coerce_to_numeric(bbbp_descriptors_df, bbbp_descriptors_df.columns)\nbbbp_descriptors_df.head()","9eab67f8":"bbbp_descriptors_df = bbbp_descriptors_df.fillna(0)\nbbbp_descriptors_df.head()","18bd0d60":"bbbp_scaler1 = StandardScaler()\nbbbp_scaler1.fit(bbbp_descriptors_df.values)\nbbbp_descriptors_df = pd.DataFrame(bbbp_scaler1.transform(bbbp_descriptors_df.values),\n                                   columns=bbbp_descriptors_df.columns)","244c4014":"nca = NCA1\ncn = ['col'+str(x) for x in range(nca)]","782fdf10":"bbbp_transformer1 = KernelPCA(n_components=nca, kernel='rbf', n_jobs=-1)\nbbbp_transformer1.fit(bbbp_descriptors_df.values)\nbbbp_descriptors_df = pd.DataFrame(bbbp_transformer1.transform(bbbp_descriptors_df.values),\n                                   columns=cn)\nprint(bbbp_descriptors_df.shape)\nbbbp_descriptors_df.head()","29c7adff":"X_train, X_test, y_train, y_test = train_test_split(bbbp_descriptors_df.values, bbbp_df['p_np'].values.flatten(), \n                                                    test_size=TEST_RATIO, \n                                                    random_state=42,stratify=bbbp_df['p_np'].values.flatten())","e07b0c7b":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n                                                      test_size=VAL_RATIO, \n                                                      random_state=42,stratify=y_train)","3cc92d3f":"def Find_Optimal_Cutoff(target, predicted):\n    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n    Parameters\n    ----------\n    target : Matrix with dependent or target data, where rows are observations\n\n    predicted : Matrix with predicted data, where rows are observations\n\n    Returns\n    -------     \n    list type, with optimal cutoff value\n\n    \"\"\"\n    fpr, tpr, threshold = roc_curve(target, predicted)\n    i = np.arange(len(tpr)) \n    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n\n    return list(roc_t['threshold']) ","8124aac4":"def Find_Optimal_threshold(target, predicted):\n    target = target.reshape(-1,1)\n    predicted = predicted.reshape(-1,1)\n    \n    rng = np.arange(0.0, 0.99, 0.001)\n    f1s = np.zeros((rng.shape[0],predicted.shape[1]))\n    for i in range(0,predicted.shape[1]):\n        for j,t in enumerate(rng):\n            p = np.array((predicted[:,i])>t, dtype=np.int8)\n            scoref1 = f1_score(target[:,i], p, average='binary')\n            f1s[j,i] = scoref1\n            \n    threshold = np.empty(predicted.shape[1])\n    for i in range(predicted.shape[1]):\n        threshold[i] = rng[int(np.where(f1s[:,i] == np.max(f1s[:,i]))[0][0])]\n        \n    return threshold","7dfa809d":"parameters = {'kernel':['sigmoid', 'rbf'], 'C':[1,0.5], 'gamma':[1\/nca,1\/np.sqrt(nca)],'probability':[True]}\nbbbp_svc = GridSearchCV(SVC(random_state=23,class_weight='balanced'), parameters, cv=5, scoring='roc_auc',n_jobs=-1)","e51d117d":"result = bbbp_svc.fit(X_train, y_train)","c92d26e8":"print(result.best_estimator_)","f82aa0f5":"print(result.best_score_)","ef745564":"pred = bbbp_svc.predict_proba(X_valid)","0453b234":"bbbp_svc_calib = CalibratedClassifierCV(bbbp_svc, cv='prefit')\nbbbp_svc_calib.fit(X_valid, y_valid)","d57f5815":"pred = bbbp_svc_calib.predict_proba(X_valid)\npred = pred[:,1]\npred_svc_t = np.copy(pred)","16583d5f":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","edfcb274":"pred = bbbp_svc_calib.predict(X_test)\nf1_score(y_test,pred)","0fbe1312":"pred = bbbp_svc_calib.predict_proba(X_test)\nroc_auc_score(y_test,pred[:,1])","a9f4a180":"pred = pred[:,1]\npred_svc = np.copy(pred)\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nsvc_score = f1_score(y_test,pred)\nprint(svc_score)","d7950198":"y = np.array(bbbp_descriptors_df.loc[23].values).reshape(1, -1)\nresult = bbbp_svc.predict(y)\nprob = bbbp_svc.predict_proba(y)\nprint(result)\nprint(prob)\nprint(int(prob[:,1]>threshold))","8de2603e":"bbbp_model = Sequential()\nbbbp_model.add(Dense(128, input_dim=bbbp_descriptors_df.shape[1], \n                     kernel_initializer='he_uniform'))\nbbbp_model.add(BatchNormalization())\nbbbp_model.add(Activation('tanh'))\nbbbp_model.add(Dropout(rate=DROPRATE))\nbbbp_model.add(Dense(64,kernel_initializer='he_uniform'))\nbbbp_model.add(BatchNormalization())\nbbbp_model.add(Activation('tanh'))\nbbbp_model.add(Dropout(rate=DROPRATE))\nbbbp_model.add(Dense(32,kernel_initializer='he_uniform'))\nbbbp_model.add(BatchNormalization())\nbbbp_model.add(Activation('tanh'))\nbbbp_model.add(Dropout(rate=DROPRATE))\nbbbp_model.add(Dense(1,kernel_initializer='he_uniform',activation='sigmoid'))","2e2e8bc7":"bbbp_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])","6df3e36d":"checkpoint = ModelCheckpoint('bbbp_model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')","e83ec34d":"unique_classes = np.unique(bbbp_df['p_np'].values.flatten())\nclass_weights = class_weight.compute_class_weight('balanced',unique_classes,\n                                                  bbbp_df['p_np'].values.flatten())\nclass_weights = {unique_classes[0]:class_weights[0],unique_classes[1]:class_weights[1]}","d7cd8872":"hist = bbbp_model.fit(X_train, y_train, \n                      validation_data=(X_valid,y_valid),epochs=EP, batch_size=BATCH_SIZE, \n                      class_weight=class_weights ,callbacks=[checkpoint])","f531cf1e":"plt.ylim(0., 1.0)\nplt.plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\nplt.plot(hist.epoch, hist.history[\"val_loss\"], label=\"Valid loss\")","b9dafaaa":"bbbp_model.load_weights('bbbp_model.h5')","2b2eb16e":"pred = bbbp_model.predict(X_valid)\npred_nn_t = np.copy(pred)","c25bb51e":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","a3456d50":"pred = bbbp_model.predict(X_test)\npred_nn = np.copy(pred)\nroc_auc_score(y_test,pred)","10a5ff97":"pred[pred<=threshold] = 0\npred[pred>threshold] = 1\nnn_score = f1_score(y_test,pred)\nprint(nn_score)","22792b81":"prob = bbbp_model.predict(y)\nprint(prob)\nprint(int(prob>=threshold))","3158d8e6":"inp = bbbp_model.input\nout = bbbp_model.layers[-2].output\nbbbp_model_gb = Model(inp, out)","f2863b41":"X_train = bbbp_model_gb.predict(X_train)\nX_valid = bbbp_model_gb.predict(X_valid)\nX_test = bbbp_model_gb.predict(X_test)","6c76c36d":"data = np.concatenate((X_train,X_test,X_valid),axis=0)","f5c2653f":"bbbp_scaler2 = StandardScaler()\nbbbp_scaler2.fit(data)\nX_train = bbbp_scaler2.transform(X_train)\nX_valid = bbbp_scaler2.transform(X_valid)\nX_test = bbbp_scaler2.transform(X_test)","2f2a7ee7":"data = np.concatenate((X_train,X_test,X_valid),axis=0)","0c69c7b1":"nca = NCA2","cc0de76f":"bbbp_transformer2 = KernelPCA(n_components=nca, kernel='rbf', n_jobs=-1)\nbbbp_transformer2.fit(data)\nX_train = bbbp_transformer2.transform(X_train)\nX_valid = bbbp_transformer2.transform(X_valid)\nX_test = bbbp_transformer2.transform(X_test)","a6eab6f5":"nca = X_train.shape[1]\nparameters = {'kernel':['sigmoid', 'rbf'], 'C':[1,0.5], 'gamma':[1\/nca,1\/np.sqrt(nca)],'probability':[True]}\nbbbp_svc_gb = GridSearchCV(SVC(random_state=23,class_weight='balanced'), parameters, cv=5, scoring='roc_auc',n_jobs=-1)","cd71fdf0":"result = bbbp_svc_gb.fit(X_train, y_train)","e7a3e76c":"print(result.best_estimator_)","c7e15ea1":"print(result.best_score_)","1989af3c":"pred = bbbp_svc_gb.predict_proba(X_valid)","42f134a8":"bbbp_svc_gb_calib = CalibratedClassifierCV(bbbp_svc_gb, cv='prefit')\nbbbp_svc_gb_calib.fit(X_valid, y_valid)","46845c27":"pred = bbbp_svc_gb_calib.predict_proba(X_valid)\npred = pred[:,1]\npred_svc_gb_t = np.copy(pred)","92b11ba1":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","87509279":"pred = bbbp_svc_gb_calib.predict(X_test)\nf1_score(y_test,pred)","35acd4df":"pred = bbbp_svc_gb_calib.predict_proba(X_test)\nroc_auc_score(y_test,pred[:,1])","496aa112":"pred = pred[:,1]\npred_svc_gb = np.copy(pred)\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nsvc_gb_score = f1_score(y_test,pred)\nprint(svc_gb_score)","fe4cec0d":"y = np.array(X_train[23,:])\ny = y.reshape(-1, nca)\nresult = bbbp_svc_gb_calib.predict(y)\nprob = bbbp_svc_gb_calib.predict_proba(y)\nprint(result)\nprint(prob)\nprint(int(prob[:,1]>=threshold))","a0a6c16e":"parameters = {'learning_rate':[0.05,0.1,0.15],'n_estimators':[75,100,125], 'max_depth':[3,4,5],\n               'booster':['gbtree','dart'],'reg_alpha':[0.,0.1,0.05],'reg_lambda':[0.,0.1,0.5,1.]}\n\nbbbp_xgb_gb = GridSearchCV(XGBClassifier(random_state=32), parameters, cv=5, scoring='roc_auc',n_jobs=-1)","b7a33271":"result = bbbp_xgb_gb.fit(X_train, y_train)","04805e65":"print(result.best_estimator_)","335527d7":"print(result.best_score_)","8cb348d9":"pred = bbbp_xgb_gb.predict_proba(X_valid)","60b681d6":"bbbp_xgb_gb_calib = CalibratedClassifierCV(bbbp_xgb_gb, cv='prefit')\nbbbp_xgb_gb_calib.fit(X_valid, y_valid)","4fd3baf0":"pred = bbbp_xgb_gb.predict_proba(X_valid)\npred = pred[:,1]\npred_xgb_gb_t= np.copy(pred)","430f9dbc":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","308374f4":"pred = bbbp_xgb_gb_calib.predict(X_test)\nf1_score(y_test,pred)","174d3e9f":"pred = bbbp_xgb_gb_calib.predict_proba(X_test)\nroc_auc_score(y_test,pred[:,1])","58433c96":"pred = pred[:,1]\npred_xgb_gb = np.copy(pred)\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nxgb_gb_score = f1_score(y_test,pred)\nprint(xgb_gb_score)","a1d06f0c":"result = bbbp_xgb_gb_calib.predict(y)\nprob = bbbp_xgb_gb_calib.predict_proba(y)\nprint(result)\nprint(prob)\nprint(int(prob[:,1]>=threshold))","0db1e310":"pred = (pred_svc_t+pred_nn_t.flatten()+pred_svc_gb_t+pred_xgb_gb_t)\/4.","efba8dfc":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","0f96aa1d":"pred = (pred_svc+pred_nn.flatten()+pred_svc_gb+pred_xgb_gb)\/4.\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nave_score = f1_score(y_test,pred)","6946da73":"with open('bbbp_transformer1.pkl', 'wb') as fid:\n    pickle.dump(bbbp_transformer1, fid)\nwith open('bbbp_transformer2.pkl', 'wb') as fid:\n    pickle.dump(bbbp_transformer2, fid)\nwith open('bbbp_scaler1.pkl', 'wb') as fid:\n    pickle.dump(bbbp_scaler1, fid)\nwith open('bbbp_scaler2.pkl', 'wb') as fid:\n    pickle.dump(bbbp_scaler2, fid)\nwith open('bbbp_svc_calib.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc_calib, fid)\nwith open('bbbp_svc.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc, fid)\nwith open('bbbp_svc_gb_calib.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc_gb_calib, fid)\nwith open('bbbp_svc_gb.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc_gb, fid)\nwith open('bbbp_xgb_gb_calib.pkl', 'wb') as fid:\n    pickle.dump(bbbp_xgb_gb_calib, fid)\nwith open('bbbp_xgb_gb.pkl', 'wb') as fid:\n    pickle.dump(bbbp_xgb_gb, fid)","a1bd0505":"sns.set(style=\"whitegrid\")\nax = sns.barplot(x=[svc_score,nn_score,svc_gb_score,xgb_gb_score,ave_score],\n                 y=['SVC','NN','SVC_GB','XGB_GB','ave'])\nax.set(xlim=(0.75, None))","39ea46a1":"# Comparision of Results with MoleculeNet results\n\nhttp:\/\/moleculenet.ai\/full-results\n\nThe best ROC AUC score on the test data for the MoleculeNet models is ~70, while the best score obtained in this kernel is ~90 on the test data. \n\n**Further Reading:**\n* https:\/\/arxiv.org\/pdf\/1703.00564.pdf","14bc15fa":"## Keras Neural Network Model","b4c850c1":"## F1 Score Result","77cae279":"The simplified molecular-input line-entry system (**SMILES**) is a specification in form of a line notation for describing the structure of chemical species using short ASCII strings. SMILES can be converted to molecular structure by using RDKIT module.\n\nExample: \n```python\nfrom rdkit import Chem\nm = Chem.MolFromSmiles('Cc1ccccc1')\n```\n\nFurther reading:\n* https:\/\/www.rdkit.org\/docs\/GettingStartedInPython.html","304b8fc5":"## Saving models, transformer and scaler","51aca32a":"## Loading molecular descriptors\n\nDescriptors dataframe contains 1625 molecular descriptors (including 3D descriptors) generated on the NCI database using Mordred python module.\n\nFurther Reading:\n* https:\/\/en.wikipedia.org\/wiki\/Molecular_descriptor\n* https:\/\/github.com\/mordred-descriptor\/mordred","3bd240da":"## Scaling and Principal component analysis (PCA) ","35d10620":"## For loading saved model\n\n```python\nwith open('bbbp_svc.pkl', 'rb') as fid:\n    bbbp_svc = pickle.load(fid)\n ```","f982fecf":"## Loading BBBP dataset\n\n**BBBP**: Binary labels of blood-brain barrier penetration(permeability).\n","53b8e968":"**Probability calibration:**\n\nSome models can give poor estimates of the class probabilities and some even do not support probability prediction. The *CalibratedClassifierCV*  calibrates the probabilities of a given model, or to add support for probability prediction.\n\n**Further Reading:**\n* https:\/\/scikit-learn.org\/stable\/modules\/calibration.html\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV","4f87072d":"## Gradient Boosting of Keras Model with SVC","6cefaa3c":"## Gradient Boosting of Keras Model with XGBoost","771cab3a":"## Sklearn SVC Model"}}