{"cell_type":{"f5fee2fe":"code","9f068eff":"code","6bf281f9":"code","356a5cd9":"code","87c201a5":"code","c528fa5f":"code","520cdccb":"code","23880601":"code","5083a3b7":"code","b4b75f1f":"code","e9ca3773":"code","2e2c779e":"code","30bc691b":"code","eabf6119":"code","c59c8cec":"code","88317658":"code","783eb4ab":"code","3f61868c":"code","d00c6bc0":"code","010d5b34":"code","25274545":"code","273f6ac3":"code","3f286799":"code","258aa816":"code","5179fb36":"code","23671ac6":"code","0d22dc4a":"code","98a8fa15":"code","5a9bff12":"markdown","42218764":"markdown","4b5637a5":"markdown","febd0f80":"markdown","52bfd7d4":"markdown","8d25a61f":"markdown"},"source":{"f5fee2fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9f068eff":"import pandas as pd\ntitanic_train_df = pd.read_csv('..\/input\/train.csv')\ntitanic_test_df = pd.read_csv('..\/input\/test.csv')\nprint(titanic_train_df.sample(2))\ntitanic_test_df.sample(2)","6bf281f9":"print(titanic_train_df.info())\ntitanic_test_df.info()","356a5cd9":"titanic_train_df['Family_Size']=titanic_train_df['SibSp']+titanic_train_df['Parch']\ntitanic_test_df['Family_Size']=titanic_test_df['SibSp']+titanic_test_df['Parch']\ntitanic_train_df.sample(5)","87c201a5":"# dropping Name, ticket, cabin from both data set as this column is not required for analysis and could see the null values in Age, Fare, Cabin and Embarked columns,\n# which will be replaced with mean or 3rd class info\n\ntitanic_train_df.drop(['Name','Ticket', 'Cabin'], axis=1, inplace=True)\ntitanic_test_df.drop(['Name','Ticket', 'Cabin'], axis=1, inplace=True)","c528fa5f":"# Filling NA value to Age with mean of the Age.\ntitanic_train_df.Age.fillna(titanic_train_df.Age.mean(), inplace=True)\ntitanic_test_df.Age.fillna(titanic_test_df.Age.mean(), inplace=True)","520cdccb":"titanic_test_df.Fare.fillna(titanic_test_df[titanic_test_df.Pclass==3].Fare.mean(), inplace=True)","23880601":"# Now the data set is ready by replacing the missing values. Now we need to replace Sex,Age,Embarked to categorical\ntitanic_train_df.info()","5083a3b7":"titanic_train_df['Sex'] = pd.Categorical(titanic_train_df['Sex']).codes\ntitanic_train_df['Embarked'] = pd.Categorical(titanic_train_df['Embarked']).codes\ntitanic_train_df.info()","b4b75f1f":"titanic_df = pd.concat([titanic_train_df, titanic_test_df])\n\nimport matplotlib.pyplot as plt\nnames = titanic_train_df['Survived'].unique()\nvalues = titanic_train_df['Survived'].value_counts().values\n\nfig, ax = plt.subplots()\nplt.xticks([0, 1])\nplt.title('Survived ratio in training set')\nplt.xlabel('0 - Dead, 1 - Survived')\nplt.ylabel('Count rate')\nfor i, v in enumerate(values):\n    ax.text(i, v+5, str(v), color='g', fontweight='bold')\nax.bar(names, values, color=(0.5,0.1,0.5,0.6),width=0.5)","e9ca3773":"titanic_train_df.info()","2e2c779e":"# The correlation shows that there is no relation between the independent and target variable ie. Survived column\n# class and fare is negative marginally related.\ntitanic_df.corr()","30bc691b":"plt.figure(figsize=(15,15))\nimport seaborn as sns\nsns.heatmap(titanic_df.corr(),annot=True, vmin=-1, vmax=1, cmap='RdBu')\n","eabf6119":"sns.pairplot(titanic_df)","c59c8cec":"titanic_test_df['Sex'] = pd.Categorical(titanic_test_df['Sex']).codes\ntitanic_test_df['Embarked'] = pd.Categorical(titanic_test_df['Embarked']).codes\ntitanic_test_df.info()","88317658":"#Getting ready the train data\nx_test_org = titanic_test_df\nX_train = titanic_train_df.drop('Survived', axis=1)\ny_train = titanic_train_df[['Survived']]\ny_train = np.ravel(y_train)\nprint(X.info(), y.shape)","783eb4ab":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb","3f61868c":"%%time\nparameters = {\n    \"criterion\": [\"gini\", \"entropy\"],\n    \"max_depth\": [1, 2, 3, 5, 10, None], \n    \"min_samples_split\": [2, 3, 5, 10],\n    \"min_samples_leaf\": [1, 5, 10, 20]\n}\n\ntree_model = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5).fit(X_train, y_train)\nprint(accuracy_score(y_train, tree_model.predict(X_train)))\nprint(tree_model.best_score_)\nprint(tree_model.best_params_)\nprint(tree_model.best_estimator_)","d00c6bc0":"%%time\nparameters = {\n    \"n_estimators\": [2, 4, 5, 8, 10, 15], \n    \"criterion\": [\"gini\", \"entropy\"],\n    \"max_features\": [\"auto\", \"log2\"], \n    \"max_depth\": [1, 2, 3, 5, 10], \n    \"min_samples_split\": [2, 3, 5, 10],\n    \"min_samples_leaf\": [1, 5, 10, 20]\n}\n\nforest_model = GridSearchCV(RandomForestClassifier(), parameters, cv=5).fit(X_train, y_train)\nprint(accuracy_score(y_train, forest_model.predict(X_train)))\nprint(forest_model.best_score_)\nprint(forest_model.best_params_)\nprint(forest_model.best_estimator_)","010d5b34":"%%time\nparameters = {\n    'max_depth': [3, 4, 5, 6, 7, 8], \n    'n_estimators': [5, 10, 20, 50, 100],\n    'learning_rate': np.linspace(0.02,0.16,8)\n}\n\nxgb_model = GridSearchCV(xgb.XGBClassifier(), parameters, cv=5).fit(X_train, y_train)\nprint(accuracy_score(y_train, xgb_model.predict(X_train)))\nprint(xgb_model.best_score_)\nprint(xgb_model.best_params_)\nprint(xgb_model.best_estimator_)","25274545":"%%time\nparameters = {'n_estimators': [5, 50, 100],\n              'learning_rate': np.linspace(0.02,0.16,4),\n              'num_leaves': [31, 61],\n              'min_data_in_leaf': [20, 30, 40],\n              'max_depth': range(3,8)\n}\n\nlgbm_model = GridSearchCV(lgbm.LGBMClassifier(), parameters, cv=5).fit(X_train, y_train)\nprint(accuracy_score(y_train, lgbm_model.predict(X_train)))\nprint(lgbm_model.best_score_)\nprint(lgbm_model.best_params_)\nprint(lgbm_model.best_estimator_)","273f6ac3":"%%time\nparameters = {'iterations': [10, 50, 100],\n              'learning_rate': np.linspace(0.02,0.12,2),\n              'depth': range(4,10)\n}\n\ncb_model = GridSearchCV(cb.CatBoostClassifier(verbose=False), parameters, cv=5).fit(X_train, y_train)\nprint(accuracy_score(y_train, cb_model.predict(X_train)))\nprint(cb_model.best_score_)\n# print(accuracy_score(y_val, cb_model.predict(X_val)))\nprint(cb_model.best_params_)\nprint(cb_model.best_estimator_)","3f286799":"tree_train_pred = tree_model.predict(X_train)\nforest_train_pred = forest_model.predict(X_train)\nxgb_train_pred = xgb_model.predict(X_train)\nlgbm_train_pred = lgbm_model.predict(X_train)\ncb_train_pred = cb_model.predict(X_train)","258aa816":"submission = pd.DataFrame(\n    {\n        'PassengerId': titanic_test_df['PassengerId'], \n        'Survived': tree_model.predict(x_test_org) \n    }\n)\nsubmission.to_csv(\"submission_tree.csv\", index=False)\n\nsubmission = pd.DataFrame(\n    {\n        'PassengerId': titanic_test_df['PassengerId'], \n        'Survived': forest_model.predict(x_test_org)\n    }\n)\nsubmission.to_csv(\"submission_forest.csv\", index=False)\n\nsubmission = pd.DataFrame(\n    {\n        'PassengerId': titanic_test_df['PassengerId'], \n        'Survived': xgb_model.predict(x_test_org) \n    }\n)\nsubmission.to_csv(\"submission_xgb.csv\", index=False)\n\nsubmission = pd.DataFrame(\n    { \n        'PassengerId': titanic_test_df['PassengerId'], \n        'Survived': lgbm_model.predict(x_test_org) \n    }\n)\nsubmission.to_csv(\"submission_lgbm.csv\", index=False)\n\nsubmission = pd.DataFrame(\n    { \n        'PassengerId': titanic_test_df['PassengerId'], \n        'Survived': cb_model.predict(x_test_org).astype(int)\n    }\n)\nsubmission.to_csv(\"submission_cb.csv\", index=False)","5179fb36":"tree_test_pred = tree_model.predict(x_test_org)\nforest_test_pred = forest_model.predict(x_test_org)\nxgb_test_pred = xgb_model.predict(x_test_org)\nlgbm_test_pred = lgbm_model.predict(x_test_org)\ncb_test_pred = cb_model.predict(x_test_org)\n\nmean_test_pred = np.round((tree_test_pred + forest_test_pred + xgb_test_pred + lgbm_test_pred + cb_test_pred) \/ 5)\n\nsubmission = pd.DataFrame(\n    { \n        'PassengerId': titanic_test_df['PassengerId'], \n        'Survived': mean_test_pred.astype(int)\n    }\n)\nsubmission.to_csv(\"submission_mean.csv\", index=False)","23671ac6":"base_pred = pd.DataFrame({\n    'tree':tree_train_pred.ravel(), \n    'forest':forest_train_pred.ravel(), \n    'xgb':xgb_train_pred.ravel(), \n    'lgbm':lgbm_train_pred.ravel(),\n    'cb': cb_train_pred.ravel()\n})\n\ntest_pred = pd.DataFrame({\n    'tree':tree_test_pred.ravel(), \n    'forest':forest_test_pred.ravel(), \n    'xgb':xgb_test_pred.ravel(), \n    'lgbm':lgbm_test_pred.ravel(),\n    'cb': cb_test_pred.ravel()\n})","0d22dc4a":"%%time\nfrom sklearn.svm import SVC\nparameters = {\n    'kernel': ['linear', 'poly', 'rbf'],\n    'C': [0.1, 0.5, 1,10,100,1000], \n    'gamma': [1, 0.1, 0.001, 0.0001, 'auto'],\n    'degree': [3, 4, 5]\n}\n\nfinal_model = GridSearchCV(SVC(), parameters, cv=5).fit(base_pred, y_train)\nprint(accuracy_score(y_train, final_model.predict(base_pred)))\nprint(final_model.best_score_)\nprint(final_model.best_params_)\nprint(final_model.best_estimator_)","98a8fa15":"final_pred = final_model.predict(test_pred)\n\nsubmission = pd.DataFrame(\n    { \n        'PassengerId': titanic_test_df['PassengerId'], \n        'Survived': final_pred\n    }\n)\nsubmission.to_csv(\"submission_final.csv\", index=False)","5a9bff12":"XGBoost","42218764":"CatBoost","4b5637a5":"Decision tree","febd0f80":"Stacking","52bfd7d4":"Random forest","8d25a61f":"LightGBM"}}