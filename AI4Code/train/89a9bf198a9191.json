{"cell_type":{"d9b26752":"code","69f4905b":"code","6b6c32fd":"code","cb75338b":"code","b3a92059":"code","47a0d1fa":"code","124837d9":"code","ff72aa92":"code","ee26c12e":"code","90a97c8a":"code","93c36610":"code","6611916d":"code","cd5a3a6a":"code","d74b10e9":"code","50b259e0":"markdown","b55e4612":"markdown","c971d779":"markdown","21f46755":"markdown","33eced29":"markdown","8ea85c4e":"markdown","0ca4c5b6":"markdown","33aea667":"markdown","a84a1f42":"markdown","7f46f9b4":"markdown"},"source":{"d9b26752":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","69f4905b":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom joblib import dump as save_model\nfrom joblib import load as load_weights\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","6b6c32fd":"dataset = pd.read_excel('..\/input\/concrete-compressive-strength\/Concrete_Data.xls')\nprint ('The Shape of Dataset: ',dataset.shape)\ndataset.head()","cb75338b":"dataset.describe().T","b3a92059":"print ('>>>>> Data Types        ')\nprint(dataset.dtypes)\nprint ('----------------------------------')\nprint ('>>>>> Counts of Missing values')\nprint (dataset.isna().sum())\nprint ('----------------------------------')\n# print ('         Numbers of unique values')\n# print ([[col,len (df[col].unique())] for col in df.columns])","47a0d1fa":"feature_name = [name.split('(')[0] for name in dataset.columns.values]\n\nplt.figure(figsize=(16,16))\nfor i,name in enumerate(dataset.columns.values[:-1]):\n    ax = plt.subplot((len (feature_name)-1)\/2, 2, i + 1)\n    sns.regplot(x=dataset[name], y=dataset[dataset.columns.values[-1]])\n    plt.xlabel(feature_name[i])\n    plt.ylabel(feature_name[-1])","124837d9":"# Select the target and features\nX = dataset.drop (columns=['Concrete compressive strength(MPa, megapascals) '])\ny = dataset['Concrete compressive strength(MPa, megapascals) ']\nprint ('X shape: ',X.shape)\nprint ('y shape: ',y.shape)","ff72aa92":"# split the data to train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n\nprint ('Shape of Train dataset (Features): ',X_train.shape)\nprint ('Shape of Train dataset (Target)  : ',y_train.shape)\nprint ('Shape of Test dataset (Features) : ',X_test.shape)\nprint ('Shape of Test dataset (Target)   : ',y_test.shape)\n","ee26c12e":"# take an object from the class\nModel = LinearRegression()\n\n# fit (train) the model\nModel.fit(X_train, y_train)\n\n# Showing Results\nprint('Train Score is :', Model.score(X_train, y_train))","90a97c8a":"from sklearn.preprocessing import PolynomialFeatures\nscores = []\n\nfor n in range (1,7):\n    # preprocessing\n    PolynomialFeaturesModel = PolynomialFeatures(degree=n)\n    X_train_new = PolynomialFeaturesModel.fit_transform(X_train)\n    X_test_new = PolynomialFeaturesModel.fit_transform(X_test)\n\n    # model\n    LR_Model = LinearRegression(normalize=True)\n    LR_Model.fit(X_train_new, y_train)\n    print ('Degree: ',n)\n    print('Train Score is :', LR_Model.score(X_train_new,y_train))\n    test_score = LR_Model.score(X_test_new,y_test)\n    print('Test Score is :', test_score)\n    scores.append((test_score,n))\n    print ('--------------------------------------')","93c36610":"# the best value of degree (n)\nscores.sort()\nn = scores[-1][1]\nn","6611916d":"PolynomialFeaturesModel = PolynomialFeatures(degree=n)\nX_train_new = PolynomialFeaturesModel.fit_transform(X_train)\nX_test_new = PolynomialFeaturesModel.fit_transform(X_test)\n\n# model\nLR_Model = LinearRegression(normalize=True)\nLR_Model.fit(X_train_new, y_train)\nprint ('Degree: ',n)\nprint('Train Score is :', LR_Model.score(X_train_new,y_train))\nprint('Test Score is :', LR_Model.score(X_test_new,y_test))\nprint ('--------------------------------------')","cd5a3a6a":"predictions = LR_Model.predict(X_test_new)","d74b10e9":"# mean absolute error and  mean squared error\nprint ('Mean Absolute Error (MAE): ',mean_absolute_error(y_test, predictions))\nprint ('--------------------------------------------')\nprint ('Mean Squared Error (MSE): ',mean_squared_error(y_test, predictions))\n","50b259e0":"The score is vary bad,\n\nwe will use *PolynomialFeatures* to increase the features and accuracy ","b55e4612":"# Data Visualization >> EDA","c971d779":"## Check to the missing value and data types","21f46755":"## Prepare and train the model\n\n* LinearRegression model will be selected.","33eced29":"# Separate the data\n\nTarget, Features, Train and Test","8ea85c4e":"## The best Model","0ca4c5b6":"## Read the dataset","33aea667":"# Import Libraries","a84a1f42":"Great!\n\nNo missing and categorical variables","7f46f9b4":"## Model Evaluation\n* mean absolute error\n* mean squared error"}}