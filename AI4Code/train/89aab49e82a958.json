{"cell_type":{"da458e5c":"code","ee41dcb5":"code","c318f96f":"code","7dd8e949":"code","edc2a9bb":"code","1ed61367":"code","ba900c84":"code","a849f0af":"code","7a329ba6":"code","e4e80683":"code","482e418f":"code","ba586652":"code","18457e0d":"code","9b6c9f89":"code","e391c0a5":"code","636e3e9c":"code","2035d893":"code","d7f63ddd":"markdown"},"source":{"da458e5c":"import os\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, MaxPool2D, concatenate, BatchNormalization, Dropout, AveragePooling2D\nfrom tensorflow.keras.activations import relu, sigmoid, softmax\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.utils import plot_model, save_img\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.metrics import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","ee41dcb5":"# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","c318f96f":"#make dirctories to copy files\nos.mkdir('train_class')\nos.mkdir('val_class')","7dd8e949":"emo_classes = {'class001':'neutral',\n              'class002':'happy',\n              'class003':'sad',\n              'class004':'surprise',\n              'class005':'fear',\n              'class006':'disgust',\n              'class007':'anger',\n              'class008':'contempt'}\n\n\n#source root directory and distination root directory\ntrain_src = \"..\/input\/affectnetsample\/train_class\/\"\ntrain_dst = \"..\/working\/train_class\/\"\n\nval_src = \"..\/input\/affectnetsample\/val_class\/\"\nval_dst = \"..\/working\/val_class\/\"","edc2a9bb":"# #copy images from source directory to destination directory\n# for class_no,emotion in emo_classes.items():\n#     new_train_src = os.path.join(train_src, class_no)\n#     new_train_dst = os.path.join(train_dst, emotion)\n#     os.mkdir(f'train_class\/{emotion}')\n    \n#     for img in os.listdir(new_train_src):\n#         shutil.copyfile(src = os.path.join(new_train_src, img),\n#                         dst = os.path.join(new_train_dst, img))\n    \n#     new_val_src = os.path.join(val_src, class_no)\n#     new_val_dst = os.path.join(val_dst, emotion)\n#     os.mkdir(f'val_class\/{emotion}')\n    \n#     for img in os.listdir(new_val_src):\n#         shutil.copyfile(src = os.path.join(new_val_src, img),\n#                         dst = os.path.join(new_val_dst, img))","1ed61367":"#copy images from source directory to destination directory\nfor class_no,emotion in emo_classes.items():\n    new_train_src = os.path.join(train_src, class_no)\n    new_train_dst = os.path.join(train_dst, emotion)\n    os.mkdir(f'train_class\/{emotion}')\n    \n    for img in os.listdir(new_train_src):\n        src = os.path.join(new_train_src, img)\n        dst = os.path.join(new_train_dst, img)\n        img_ = img_to_array(load_img(src, target_size=(224,224)))\n        save_img(dst, img_)\n        \n    \n    new_val_src = os.path.join(val_src, class_no)\n    new_val_dst = os.path.join(val_dst, emotion)\n    os.mkdir(f'val_class\/{emotion}')\n    \n    for img in os.listdir(new_val_src):\n        src = os.path.join(new_val_src, img)\n        dst = os.path.join(new_val_dst, img)\n        img_ = img_to_array(load_img(src, target_size=(224,224)))\n        save_img(dst, img_)","ba900c84":"#set new paths\ntrain_paths = {}\nval_paths ={}\n\nfor class_no,emotion in emo_classes.items():\n    new_train_dst = os.path.join(train_dst, emotion)\n    new_val_dst = os.path.join(val_dst, emotion)\n    \n    train_paths[emotion] = new_train_dst\n    val_paths[emotion] = new_val_dst\n    ","a849f0af":"for i in train_paths.keys():\n    #create figure layout\n    print(f'{i.upper()}')\n    figure_faces, axes = plt.subplots(nrows=1,ncols=3, figsize=[18,6], dpi=300)\n    axes = axes.ravel()\n    image_list = os.listdir(train_paths.get(i))[:5]\n\n    #intaract over image list to add them into figure\n    for j in range(len(axes)):\n        axes[j].imshow(load_img(os.path.join(train_paths.get(i), image_list[j])))\n\n    plt.show()","7a329ba6":"train_genarator = ImageDataGenerator(rescale=1. \/ 255,\n                               rotation_range=15,\n                               horizontal_flip=True,\n                               validation_split=0.2)\n\nval_genarator = ImageDataGenerator(rescale=1. \/ 255)\n\ntrain_data_genarator = train_genarator.flow_from_directory(\"..\/working\/train_class\/\",\n                                                     target_size=(224, 224),\n                                                     color_mode='grayscale',\n                                                     batch_size = 348)\n\nval_data_genarator = val_genarator.flow_from_directory(\"..\/working\/val_class\/\",\n                                                   target_size=(224, 224),\n                                                   color_mode='grayscale',\n                                                   batch_size = 348)\n                                                   ","e4e80683":"#callbacks\n\ncheck_pointer = ModelCheckpoint(filepath='exp_conv.hdf5',\n                                save_best_only=True)\n\nearly_stop = EarlyStopping(monitor='val_loss',\n                           patience=20,\n                           min_delta=0,\n                           restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1)","482e418f":"# def layer_set_concatenate(x,filter_1, filter_2, filter_3, kernel_1, kernel_2, kernel_3, activation_1, activation_2, activation_3):\n#     #branching 1.1\n#     con1 = Conv2D(filters=filter_1, kernel_size=kernel_1, padding='same', activation=activation_1)(x)\n#     bn1 = BatchNormalization()(con1)\n#     con2 = Conv2D(filters=filter_2, kernel_size=kernel_2, padding='same', activation=activation_2)(bn1)\n#     bn2 = BatchNormalization()(con2)\n\n#     #branching 1.2\n#     con3 = Conv2D(filters=filter_3, kernel_size=kernel_3, padding='same', activation=activation_3)(x)\n#     bn3 = BatchNormalization()(con3)\n\n#     #concatanate bn2 & x\n#     cc1 = concatenate([bn2, x], axis=3)\n\n#     bn4 = BatchNormalization()(cc1)\n\n#     #concatanate bn3 & bn4\n#     x = concatenate([bn3,bn4], axis=3)\n\n#     return x\n\n","ba586652":"# input_data = Input(shape=(56,56,1))\n\n# x = Conv2D(filters=64, kernel_size=(5,5), activation=relu, padding='same')(input_data)\n# x = BatchNormalization()(x)\n# x = MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n# x = Conv2D(filters=192, kernel_size=(3,3), activation=relu, padding='same')(x)\n# x = BatchNormalization()(x)\n\n\n# # concatenate layer block 1\n# x = layer_set_concatenate(x,\n#                           filter_1=16,\n#                           filter_2=32,\n#                           filter_3=128,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# # concatenate layer block 2\n# x = layer_set_concatenate(x,\n#                           filter_1=16,\n#                           filter_2=32,\n#                           filter_3=128,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# # concatenate layer block 3\n# x = layer_set_concatenate(x,\n#                           filter_1=16,\n#                           filter_2=32,\n#                           filter_3=128,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# x = MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n# x = BatchNormalization()(x)\n# x = Dropout(0.2)(x)\n\n# # concatenate layer block 4\n# x = layer_set_concatenate(x,\n#                           filter_1=32,\n#                           filter_2=64,\n#                           filter_3=256,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# # concatenate layer block 5\n# x = layer_set_concatenate(x,\n#                           filter_1=32,\n#                           filter_2=64,\n#                           filter_3=256,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# # concatenate layer block 6\n# x = layer_set_concatenate(x,\n#                           filter_1=32,\n#                           filter_2=64,\n#                           filter_3=256,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n\n# x = MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n# x = BatchNormalization()(x)\n# x = Dropout(0.3)(x)\n\n# # concatenate layer block 7\n# x = layer_set_concatenate(x,\n#                           filter_1=64,\n#                           filter_2=128,\n#                           filter_3=512,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# # concatenate layer block 8\n# x = layer_set_concatenate(x,\n#                           filter_1=64,\n#                           filter_2=128,\n#                           filter_3=512,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# # concatenate layer block 9\n# x = layer_set_concatenate(x,\n#                           filter_1=64,\n#                           filter_2=128,\n#                           filter_3=512,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# x = MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n# x = BatchNormalization()(x)\n# x = Dropout(0.4)(x)\n\n# # concatenate layer block 10\n# x = layer_set_concatenate(x,\n#                           filter_1=64,\n#                           filter_2=128,\n#                           filter_3=512,\n#                           kernel_1=(3,3),\n#                           kernel_2=(3,3),\n#                           kernel_3=(3,3),\n#                           activation_1=relu,\n#                           activation_2=relu,\n#                           activation_3=relu)\n\n# x = MaxPooling2D(pool_size=(2,2), strides=(1,1))(x)\n# x = BatchNormalization()(x)\n# x = Dropout(0.4)(x)\n\n# # flatten\n# x = Flatten()(x)\n\n# # output layer\n# x = Dense(units=512, activation=relu)(x)\n# x = Dropout(0.5)(x)\n# output_data = Dense(units=8, activation=softmax)(x)\n\n# model = Model(input_data, output_data)\n# model.summary()","18457e0d":"#inception module declaration\ndef inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj, name=None):\n    conv_1x1 = Conv2D(filters_1x1, kernel_size=(1, 1), padding='same', activation='relu')(x)\n\n    # 3 \u00d7 3 route = 1 \u00d7 1 CONV + 3 \u00d7 3 CONV\n    pre_conv_3x3 = Conv2D(filters_3x3_reduce, kernel_size=(1, 1), padding='same', activation='relu')(x)\n    conv_3x3 = Conv2D(filters_3x3, kernel_size=(3, 3), padding='same', activation='relu')(pre_conv_3x3)\n\n    # 5 \u00d7 5 route = 1 \u00d7 1 CONV + 5 \u00d7 5 CONV\n    pre_conv_5x5 = Conv2D(filters_5x5_reduce, kernel_size=(1, 1), padding='same', activation='relu')(x)\n    conv_5x5 = Conv2D(filters_5x5, kernel_size=(5, 5), padding='same', activation='relu')(pre_conv_5x5)\n\n    # pool route = POOL + 1 \u00d7 1 CONV\n    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n\n    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n\n    return output","9b6c9f89":"input_layer = Input(shape=(224, 224, 1))\n\nx = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7\/2')(input_layer)\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3\/2')(x)\nx = BatchNormalization()(x)\n\nx = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\nx = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2))(x)\n\n#inception block 1.1\nx = inception_module(x, filters_1x1=64,\n                     filters_3x3_reduce=96, filters_3x3=128,\n                     filters_5x5_reduce=16, filters_5x5=32,\n                     filters_pool_proj=32,\n                     name='inception_3a')\n\n#inception block 1.2\nx = inception_module(x, filters_1x1=128,\n                     filters_3x3_reduce=128, filters_3x3=192,\n                     filters_5x5_reduce=32, filters_5x5=96,\n                     filters_pool_proj=64,\n                     name='inception_3b')\n\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2))(x)\n\n#inception block 2.1\nx = inception_module(x, filters_1x1=192,\n                     filters_3x3_reduce=96, filters_3x3=208,\n                     filters_5x5_reduce=16, filters_5x5=48,\n                     filters_pool_proj=64,\n                     name='inception_4a')\n\n#inception block 2.2\nx = inception_module(x, filters_1x1=160,\n                     filters_3x3_reduce=112, filters_3x3=224,\n                     filters_5x5_reduce=24, filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4b')\n\n#inception block 2.3\nx = inception_module(x, filters_1x1=128,\n                     filters_3x3_reduce=128, filters_3x3=256,\n                     filters_5x5_reduce=24, filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4c')\n\n#inception block 2.4\nx = inception_module(x, filters_1x1=112,\n                     filters_3x3_reduce=144, filters_3x3=288,\n                     filters_5x5_reduce=32, filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4d')\n\n#inception block 2.5\nx = inception_module(x, filters_1x1=256,\n                     filters_3x3_reduce=160, filters_3x3=320,\n                     filters_5x5_reduce=32, filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_4e')\n\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3\/2')(x)\n\n#inception block 3.1\nx = inception_module(x, filters_1x1=256,\n                     filters_3x3_reduce=160, filters_3x3=320,\n                     filters_5x5_reduce=32, filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_5a')\n\n#inception block 3.2\nx = inception_module(x, filters_1x1=384,\n                     filters_3x3_reduce=192, filters_3x3=384,\n                     filters_5x5_reduce=48, filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_5b')\n\nx = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(x)\n\n# flatten\nx = Flatten()(x)\n\n# output layer\nx = Dense(units=512, activation=relu)(x)\nx = Dropout(0.5)(x)\noutput_layer = Dense(units=8, activation=softmax)(x)\n\nmodel = Model(input_layer, output_layer)\nmodel.summary()\n\n","e391c0a5":"plot_model(model,\n           to_file='baseline_conv.png',\n           show_shapes=True,\n           show_dtype=True,\n           show_layer_names=True)","636e3e9c":"model.compile(optimizer=Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","2035d893":"history = model.fit(train_data_genarator,\n                    validation_data = val_data_genarator,\n                    epochs = 200,\n                    callbacks=[early_stop, check_pointer, reduce_lr])","d7f63ddd":"# **GoogleNet Architecture**"}}