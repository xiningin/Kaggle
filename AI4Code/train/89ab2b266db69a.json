{"cell_type":{"43346b67":"code","b7420807":"code","900f01fe":"code","a66d31d3":"code","2a008b70":"code","f2432982":"code","95613f51":"code","4b928e18":"code","1746f768":"code","6306633f":"code","4903e97b":"code","96f71fc2":"code","a4f23554":"code","f92963f0":"code","b522298a":"code","b6fae75a":"code","260a13b3":"code","7b0af5da":"code","97452a01":"code","f6851759":"code","f769ee26":"code","7b8b3042":"code","01c8eb85":"code","bc1977b5":"code","d8ccc2be":"code","5b530113":"code","8da06873":"code","8419509d":"code","05c856c2":"code","ea24a14d":"code","7e34a555":"markdown","2a5a79f0":"markdown","54554695":"markdown","0faa9223":"markdown","b994c36a":"markdown","355eb6b1":"markdown","87d837f1":"markdown","e6741213":"markdown","5ee049c7":"markdown","208b3f68":"markdown","2c34e816":"markdown","f072fa12":"markdown"},"source":{"43346b67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential, load_model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import layers\nfrom keras.utils import np_utils\n\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7420807":"train_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntrain_df.head()","900f01fe":"train_df.shape","a66d31d3":"train_df.describe()","2a008b70":"X_train = train_df.iloc[:, 1:]\ny_train = train_df.iloc[:, 0]\n\nX_train.shape, y_train.shape","f2432982":"W = 28\nH = 28","95613f51":"sample = X_train.loc[42]\nplt.imshow(sample.values.reshape(W, H))","4b928e18":"plt.imshow(sample.values.reshape(W, H), cmap=plt.cm.gray)","1746f768":"X_train = X_train.astype('float32') \/ 255","6306633f":"X_train.describe()","4903e97b":"X_train = X_train.values.reshape(-1, W, H, 1)\nX_train.shape","96f71fc2":"number_of_classes = y_train.nunique()\n\ny_train = np_utils.to_categorical(y_train, number_of_classes)\n\ny_train.shape","a4f23554":"y_train","f92963f0":"input_shape = (W, H, 1)\n\nmodel = Sequential()\n\nmodel.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=input_shape))\nmodel.add(layers.MaxPool2D())\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(layers.MaxPool2D())\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Dense(number_of_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","b522298a":"early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='min')\nmcp_save = ModelCheckpoint('digit_recognizer.h5', save_best_only=True, monitor='val_loss', verbose=1, mode='auto')","b6fae75a":"history = model.fit(X_train,\n                    y_train, \n                    epochs=100, \n                    batch_size=32, \n                    verbose=1, \n                    validation_split=0.2,\n                    callbacks=[early_stopping, mcp_save])","260a13b3":"# function to plot accuracy \/ loss\ndef plotgraph(epochs, acc, val_acc):\n    # Plot training & validation accuracy values\n    plt.plot(epochs, acc, 'b')\n    plt.plot(epochs, val_acc, 'r')\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='upper left')\n    plt.show()","7b0af5da":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))","97452a01":"plotgraph(epochs, accuracy, val_accuracy)","f6851759":"plotgraph(epochs, loss, val_loss)","f769ee26":"test_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntest_df.head()","7b8b3042":"test_df.shape","01c8eb85":"X_test = test_df.values\nprint(X_test.shape)\n\n# Scale pixel values\nX_test = X_test.astype('float32') \/ 255\n\n# Reshape to (batch, W, H, channels)\nX_test = X_test.reshape(-1, W, H, 1)\nprint(X_test.shape)","bc1977b5":"# plot image entry #42, reshape image to size 28x28 pixel\nplt.imshow(X_test[42].reshape(28, 28), cmap=plt.cm.gray)","d8ccc2be":"model = load_model('\/kaggle\/working\/digit_recognizer.h5')","5b530113":"y_pred = model.predict(X_test)\ny_pred.shape","8da06873":"for i in range(10, 16):\n    plt.subplot(280 + (i%10+1))\n    plt.imshow(X_test[i].reshape(28, 28), cmap=plt.cm.gray)\n    plt.title(y_pred[i].argmax())\nplt.show()","8419509d":"plt.imshow(X_test[42].reshape(W, H), cmap=plt.cm.gray)\nprint(y_pred[42].argmax())","05c856c2":"output = []\nfor index, prediction in tqdm(enumerate(y_pred), total=y_pred.shape[0]):\n    image_id = index + 1\n    label = prediction.argmax()\n    output.append({\"ImageId\": image_id, \"Label\": label})\n\nsubmission_df = pd.DataFrame(output)\nsubmission_df.head()","ea24a14d":"submission_df.to_csv('submission.csv', index=False)","7e34a555":"## Scale pixel values\n\ndivide pixel value by 255","2a5a79f0":"## One hot encode label y\nusing keras.utils.np_utils.to_categorical()","54554695":"## Reshape train image for CNN input\nTensorflow (batch, width, height, channels)","0faa9223":"## Early stopping and Save best model\n\nEarlyStopping() will stop the training if there is no improvement on the monitored value (this example: val_loss)\n\nModelCheckpoint() will save the best val_loss model","b994c36a":"## Repeat the same preprocessing as train_df to test_df\n- Split labels & images\n- Scale image pixel values\n- Reshape flattened image pixel values to (bathc, width, height, channels)","355eb6b1":"## Split label & image\n- X_train is training images (pixel0 to pixel783, flattened image)\n- y_train is training labels (first column 'label')","87d837f1":"### Plot training graph\n`model.fit()` function will return a dictionary of training datas including loss, val_loss, accuracy, and val_accuracy\n\nthe dictionary will look something like this\n```js\n{\n    \"val_loss\": [ list of validation losses... ],\n    \"val_accuracy\": [ list of validation accuracies... ],\n    \"loss\": [ list of losses... ],\n    \"accuracy\": [ list of accuracies... ]\n}\n```","e6741213":"## Load test dataset","5ee049c7":"## Visualize prediction\n\nuse `.argmax()` to get highest accuracy in prediction list (predicted label)\n\nPlot image entry 10 to 16 and put the predicted label as title","208b3f68":"## Build submission format\n\nImageId,Label","2c34e816":"## Define model\n\nhttps:\/\/www.kaggle.com\/cdeotte\/how-to-choose-cnn-architecture-mnist\n\n- input shape (width, height, channels)\n- output layer's units (number_of_classes)","f072fa12":"## Predict test image\n\neach item of predictions `y_pred` is a list with length: 10 (output layer units\/number_of_classes), the accuracy of each label predicted. \n\n(value of index 1 is  0.93, means label `1` has accuracy 93% which also means this image 93% might be `1`)"}}