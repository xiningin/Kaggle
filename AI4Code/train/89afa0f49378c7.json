{"cell_type":{"10cded51":"code","dd907f81":"code","921444a0":"code","c8283ac3":"code","706ddca1":"code","f62950d2":"code","c16f231a":"code","c196ada6":"code","492c8c73":"code","1ffe50e4":"code","eb71600d":"code","acea5aaf":"code","db970dda":"code","14ac8525":"code","d3c44142":"code","305e261c":"code","874cea5a":"markdown","8369afc1":"markdown","1e7eb926":"markdown"},"source":{"10cded51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd907f81":"gujarat=pd.read_csv(\"\/kaggle\/input\/statewise-apple-datarik\/GApple.csv\")\nmaharashtra=pd.read_csv(\"\/kaggle\/input\/statewise-apple-datarik\/MApple.csv\")\nharayana=pd.read_csv(\"\/kaggle\/input\/statewise-apple-datarik\/HApple.csv\")\npunjab=pd.read_csv(\"\/kaggle\/input\/statewise-apple-datarik\/PApple.csv\")\nmp=pd.read_csv(\"\/kaggle\/input\/statewise-apple-datarik\/MPApple.csv\")\nrajasthan=pd.read_csv(\"\/kaggle\/input\/statewise-apple-datarik\/RApple.csv\")\ntomato=pd.read_csv(\"..\/input\/tomatopunjab\/Tomato (1).csv\")\nstate=[gujarat,maharashtra,harayana,punjab,mp,rajasthan,tomato]\nfor i in state:\n    i.drop([\"State\",\"Commodity\"],axis=1,inplace=True)\n    i['Price Date'] = pd.to_datetime(i['Price Date'])\n    i=i.set_index(\"Price Date\")","921444a0":"\"\"\"\nmodel=Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(50,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')\n\"\"\"","c8283ac3":"df1=tomato.reset_index()[\"Modal Price (Rs.\/Quintal)\"]\n\n\n\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler(feature_range=(0,1))\ndf1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n\ntrain_s=int(len(df1)*0.75)\ntest_s=len(df1)-train_s\ntrain_data,test_data=df1[0:train_s,:],df1[train_s:len(df1),:1]\n\n\nimport numpy\ndef create_dataset(dataset,time_step=1):\n    datax,datay=[],[]\n    for i in range(len(dataset)-time_step-1):\n        a = dataset[i:(i+time_step),0]\n        datax.append(a)\n        datay.append(dataset[i+time_step,0])\n    return numpy.array(datax),numpy.array(datay)\n\n\ntime_step=60\nx_train,y_train=create_dataset(train_data,time_step)\nx_test,y_test=create_dataset(test_data,time_step)\n\nx_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\nx_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\n\n\n\nmodel=Sequential()  \nmodel.add(LSTM(50,return_sequences=True,input_shape=(time_step,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam',metrics=[\"mae\",\"mape\",\"acc\"])","706ddca1":"model.summary()","f62950d2":"model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=2000,batch_size=64,verbose=1)","c16f231a":"train_predict=model.predict(x_train)\ntest_predict=model.predict(x_test)","c196ada6":"train_predict=scaler.inverse_transform(train_predict)\ntest_predict=scaler.inverse_transform(test_predict)\n","492c8c73":"import math\nfrom sklearn.metrics import mean_squared_error\nmath.sqrt(mean_squared_error(y_train,train_predict))","1ffe50e4":"math.sqrt(mean_squared_error(y_test,test_predict))","eb71600d":"plt.figure(figsize=(15,8))\nlook_back=time_step\ntrainPredictPlot=numpy.empty_like(df1)\ntrainPredictPlot[:,:] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back,:]=train_predict\n#shift test prediction for plotting\ntestPredictPlot=numpy.empty_like(df1)\ntestPredictPlot[:,:]=numpy.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1,:]=test_predict\n#plot baseline and prediction\nplt.plot(scaler.inverse_transform(df1))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.title(\"Blue=original,Yellow=how trains model,Green=Prediction  Punjab(epoch=2000 & time_step=60 & statcked lstm 4layer)\")\nplt.show()\n","acea5aaf":"predtomato=tomato[df1.shape[0]-test_predict.shape[0]:]\npredtomato[\"predicted values\"]=test_predict\npredtomato.tail(30)","db970dda":"import plotly.offline as pyo\nimport plotly.graph_objs as go\npt=pd.pivot_table(predtomato,values=[\"Modal Price (Rs.\/Quintal)\",\"predicted values\"],index=\"Price Date\")\ntrace0=go.Scatter(\n    x=pt.index,\n    y=pt[\"Modal Price (Rs.\/Quintal)\"],\n    mode=\"lines\",\n    name=\"TRUE VALUE\"\n)\ntrace1=go.Scatter(\n    x=pt.index,\n    y=pt[\"predicted values\"],\n    mode=\"lines\",\n    name=\"PREDICTED VALUE\"\n)\ndata=[trace0,trace1]\nlayout=go.Layout(title=\"TRUE VALUE\/PREDICTION\")\nfig=go.Figure(data=data,layout=layout)\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","14ac8525":"\"\"\"\nfrom pandas.tseries.offsets import DateOffset\nfuture_dates=[tomato.index[-1]+ DateOffset(months=x) for x in range(0,24)]\n\"\"\"","d3c44142":"len(test_data)\nx_input=test_data[len(test_data)-time_step:].reshape(1,-1)\ntemp_input=list(x_input)","305e261c":"from numpy import array\nlst_output=[]\nn_steps=60\ni=0\nfu=300\nwhile(i<fu):\n    if(len(temp_input)>n_steps):\n        x_input=np.array(temp_input[1:])\n        #print(\"{} day input {}\".format(i,x_input))\n        x_input=x_input.reshape(1,-1)\n        x_input=x_input.reshape(1,n_steps,1)\n        yhat=model.predict(x_input,verbose=0)\n        #print(\"{} day output {}\".format(i,yhat))\n        temp_input.extend(yhat[0].tolist())\n        temp_input=temp_input[1:]\n        lst_output.extend(yhat.tolist())\n        i+=1\n    else:\n        x_input=x_input.reshape((1,n_steps,1))\n        yhat=model.predict(x_input,verbose=0)\n        #print(yhat[0])\n        temp_input.extend(yhat[0].tolist())\n        #print(len(temp_input))\n        lst_output.extend(yhat.tolist())\n        i+=1\nday_new=np.arange(1,time_step+1)\nday_pred=np.arange(time_step+1,time_step+1+fu)\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(20,5))\ndf3=df1.tolist()\ndf3.extend(lst_output)\nplt.plot(df3[100:])","874cea5a":"FUTURE FORECASTING","8369afc1":"#### :)\n","1e7eb926":"# LSTM"}}