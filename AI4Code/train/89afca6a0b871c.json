{"cell_type":{"631db187":"code","08e53457":"code","335ba77d":"code","321f029a":"code","e5390a7f":"code","fbc6e5d0":"code","2c1d4190":"code","7c4f3504":"code","df0da3b4":"code","00808b01":"code","971f339d":"code","a22d0253":"code","34469bbf":"code","8a12d225":"code","6909f8f5":"code","b605a45b":"code","c1254d27":"code","c8118d0e":"code","be1bae9f":"code","7538762b":"markdown","384fd30d":"markdown","9592b684":"markdown","218619ec":"markdown"},"source":{"631db187":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08e53457":"df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","335ba77d":"df.describe()","321f029a":"df.isna().sum() #checking missing values","e5390a7f":"from sklearn.model_selection import train_test_split\n\nX = df.drop(\"Class\", axis = 1)\ny = df['Class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)","fbc6e5d0":"y_train.value_counts()","2c1d4190":"y_test.value_counts()","7c4f3504":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","df0da3b4":"from sklearn.tree import DecisionTreeClassifier","00808b01":"dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)","971f339d":"from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve\n\nconfusion_matrix(y_test, y_pred)","a22d0253":"print(classification_report(y_test, y_pred))","34469bbf":"# predict probabilities\nyhat = dt.predict_proba(X_test)\n# retrieve just the probabilities for the positive class\npos_probs = yhat[:, 1]","8a12d225":"fpr, tpr, thresholds = roc_curve(y_test, pos_probs)","6909f8f5":"from matplotlib import pyplot\n\n\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n# plot model roc curve\npyplot.plot(fpr, tpr, marker='.', label='Decision Tree Classifier')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","b605a45b":"# calculate the no skill line as the proportion of the positive class\nno_skill = len(y[y==1]) \/ len(y)\n# plot the no skill precision-recall curve\npyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# calculate model precision-recall curve\nprecision, recall, _ = precision_recall_curve(y_test, pos_probs)\n# plot the model precision-recall curve\npyplot.plot(recall, precision, marker='.', label='Decision Tree Classifier')\n# axis labels\npyplot.xlabel('Recall')\npyplot.ylabel('Precision')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","c1254d27":"from imblearn.over_sampling import SMOTE\nX1, y1 = SMOTE().fit_resample(X_train, y_train.ravel())","c8118d0e":"dt1 = DecisionTreeClassifier()\ndt1.fit(X1, y1)\ny_pred1 = dt1.predict(X_test)\nprint(classification_report(y_test, y_pred1))","be1bae9f":"from sklearn.linear_model import LogisticRegression\nlr1 = LogisticRegression() \nlr1.fit(X1, y1) \npredictions = lr1.predict(X_test) \n  \n# print classification report \nprint(classification_report(y_test, predictions))","7538762b":"![](http:\/\/miro.medium.com\/max\/1250\/1*6NkN_LINs2erxgVJ9rkpUA.png)","384fd30d":"![](http:\/\/miro.medium.com\/max\/3000\/1*CPnO_bcdbE8FXTejQiV2dg.png)","9592b684":"### Got 89% recall over scaling and oversampling data using SMOTE() !!!","218619ec":"**We need to improve recall ..**"}}