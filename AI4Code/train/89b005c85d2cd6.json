{"cell_type":{"3be26adc":"code","4067fd95":"code","dfcd09ea":"code","2e0d66d5":"code","d15607d6":"code","c627acb8":"code","f21eb368":"code","e9443f10":"code","65d88963":"code","08d97cc5":"code","478e24e0":"code","322eb511":"code","f8939416":"code","6cdcae77":"code","3b02b504":"code","35231825":"code","8fa82de6":"markdown","f895e081":"markdown","dfa0725b":"markdown","57a2e2b8":"markdown","19e79d3f":"markdown","2d53b162":"markdown","e495ea39":"markdown","776353bb":"markdown","0b731c38":"markdown","884e7fd5":"markdown","4b8509f1":"markdown","b9ac6424":"markdown","17e8482d":"markdown","4b0a6f35":"markdown","707d9153":"markdown"},"source":{"3be26adc":"import time\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import svm\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D, MaxPool2D\nfrom keras.layers import Activation, Dense, Flatten, Dropout\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\ndef plot_history(history):\n    \"\"\"\n    This function plot training history of a model \n    \"\"\"\n    plt.figure(1) \n    plt.subplot(211)  \n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])  \n    plt.title('model accuracy')  \n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')  \n    plt.legend(['train', 'test'], loc='upper left')  \n    plt.ylim(0.0, 1.1)\n     # summarize history for loss  \n\n    plt.subplot(212)  \n    plt.plot(history.history['loss'])  \n    plt.plot(history.history['val_loss'])  \n    plt.title('model loss')  \n    plt.ylabel('loss')  \n    plt.xlabel('epoch')  \n    plt.legend(['train', 'test'], loc='upper left')  \n    plt.ylim(0.0, 1.1)\n     \n    plt.show()\n\n\ndef find_outliers(data,outliers_fraction,n_neighbors):\n    \"\"\"\n    This function finds and plots outliers using the Local Outlier Factor method  \n    \"\"\"\n    # Example settings\n    n_samples = data.shape[0]\n    n_outliers = int(outliers_fraction * n_samples)\n    n_inliers = n_samples - n_outliers\n\n    # define outlier\/anomaly detection methods to be compared\n    anomaly_algorithms = [(\"Local Outlier Factor\", LocalOutlierFactor(\n            n_neighbors=n_neighbors, contamination=outliers_fraction))]\n\n    # Define datasets\n    blobs_params = dict(random_state=0, n_samples=n_inliers, n_features=2)\n    datasets = [data]\n\n    # # Compare given classifiers under given settings\n    xx, yy = np.meshgrid(np.linspace(-10000, 40000, 150),\n                         np.linspace(-10000, 40000, 150))\n\n#     plt.figure(figsize=(5,5))\n    plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n                        hspace=.01)\n\n    plot_num = 1\n    rng = np.random.RandomState(42)\n\n    for i_dataset, X_ in enumerate(datasets):\n        for name, algorithm in anomaly_algorithms:\n            t0 = time.time()\n            algorithm.fit(X_)\n            t1 = time.time()\n            plt.subplot(len(datasets), len(anomaly_algorithms), plot_num)\n            if i_dataset == 0:\n                plt.title(name)\n\n            # fit the data and tag outliers\n            if name == \"Local Outlier Factor\":\n                y_pred = algorithm.fit_predict(X_)\n            else:\n                y_pred = algorithm.fit(X).predict(X_)\n\n            # plot the levels lines and the points\n            if name != \"Local Outlier Factor\":  # LOF does not implement predict\n                Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])\n                Z = Z.reshape(xx.shape)\n                plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n#             print(y_pred)\n            colors = np.array(['b', 'y'])\n            plt.scatter(X_[:, 0], X_[:, 1],alpha=0.5, color=colors[(y_pred + 1) \/\/ 2])\n            plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n                     transform=plt.gca().transAxes, size=15,\n                     horizontalalignment='right')\n            plot_num += 1\n\n    plt.show()\n    return y_pred\n\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n#     print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\n\ndef get_model():\n    \"\"\"\n    This function creates and compile a Sequential model used as classifier\n    \"\"\"\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = 2,input_shape=(SIZE,SIZE,1),padding='same'))\n    model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n    model.add(Activation('relu'))\n    model.add(MaxPool2D(pool_size=2))\n\n    model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n    model.add(MaxPool2D(pool_size=2))\n\n    model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n    model.add(MaxPool2D(pool_size=2))\n\n    model.add(Dropout(0.3))\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(8,activation = 'softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    print('Compiled!')\n    return model\n\nnp.set_printoptions(precision=2)","4067fd95":"from sklearn.datasets import load_files\nimport numpy as np\n\ndata_dir = '..\/input\/xnaturev2\/XNature\/'\n\n# loading file names and their respective target labels into numpy array! \ndef load_dataset(path):\n    data = load_files(path)\n    files = np.array(data['filenames'])\n    targets = np.array(data['target'])\n    target_labels = np.array(data['target_names'])\n    return files,targets,target_labels\ndata, labels,target_labels = load_dataset(data_dir)\nprint('Loading complete!')\nprint('Data set size : ' , data.shape[0])","dfcd09ea":"#again prepare data load files and labels\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom skimage.color import rgb2gray\nSIZE=100\ndef convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        # Convert to Numpy Array\n        images_as_array.append(rgb2gray(img_to_array(load_img(file,target_size=(SIZE, SIZE)))))\n        \n    return images_as_array\n\nX = np.array(convert_image_to_array(data))\nX=X.reshape(X.shape[0],X.shape[1],X.shape[2],1) #\nprint('Original set shape : ',X.shape)\n\n\nprint('1st original image shape ',X[0].shape)\nno_of_classes = len(np.unique(labels))\ny = np_utils.to_categorical(labels,no_of_classes)\n\n","2e0d66d5":"import matplotlib.pyplot as plt \n%matplotlib inline\nfrom sklearn.decomposition import PCA\npca = PCA(2)  # 100*100*3 from 64 to 2 dimensions\nprojected = pca.fit_transform(X.reshape(X.shape[0],SIZE*SIZE*1))\nscatter=plt.scatter(projected[:, 0], projected[:, 1],\n            c=labels,cmap=plt.cm.get_cmap('Set1', 8), edgecolor='none', alpha=0.8)\nplt.title(\"PCA\")\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.colorbar()\n# plt.legend(handles=scatter.legend_elements()[0], labels=list(target_labels),loc='upper right', bbox_to_anchor=(1.5, 1))\n\nplt.show()\n","d15607d6":"#plot outliers and show corresponding iamges\ny_pred=find_outliers(projected,0.001,27)\noutliers=X[y_pred==-1]\nlbs=y[y_pred==-1]\nfor ol,lb in zip(outliers,lbs):    \n    print(target_labels[np.argmax([lb])])\n    plt.imshow(ol.reshape(SIZE,SIZE),cmap='gray')\n    plt.show()\n       ","c627acb8":"X=X[y_pred!=-1]\ny=y[y_pred!=-1]\nprint(X.shape)\nprint(y.shape)","f21eb368":"#split data into training and test sets\nfrom sklearn.model_selection import train_test_split\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33,shuffle=True)\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33,shuffle=True, random_state=42)\nx_train = x_train.astype('float32')\/255\nx_test = x_test.astype('float32')\/255\nprint('Training set shape : ',x_train.shape)\nprint('Testing set shape : ',x_test.shape)","e9443f10":"from matplotlib import pyplot as plt\n%matplotlib inline\nfrom collections import Counter\nimport pandas as pd\nD =Counter(np.argmax(y_train,axis=1))\nplt.title(\"number of ocurrences by class\")\nplt.bar(range(len(D)), D.values(), align='center')\nplt.xticks(range(len(D)), target_labels[list(D.keys())])\nplt.show()","65d88963":"from sklearn.utils import class_weight\n\ny_numbers=y_train.argmax(axis=1)\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_numbers),\n                                                 y_numbers)\nclass_weights = dict(enumerate(class_weights))\nclass_weights","08d97cc5":"#train the model\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras import backend as K\n\nmodel = get_model()\nmodel.summary()\n\nno_of_classes = len(np.unique(labels))\nbatch_size = 32\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\ncheckpointer = ModelCheckpoint(filepath = 'cnn_xnatureV2_balanced_weight.hdf5', verbose = 1, save_best_only = True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, verbose=1, min_lr=0.00005)\n\nhistory = model.fit(x_train,y_train,\n        batch_size = 32,\n        epochs=30,\n        validation_split=0.2,\n        class_weight=class_weights,\n        callbacks = [es,checkpointer,reduce_lr],\n        verbose=1, shuffle=True)","478e24e0":"plot_history(history)","322eb511":"# load the weights that yielded the best validation accuracy\n# model.load_weights('cnn_xnatureV2_balanced_weight.hdf5')\n# evaluate and print test accuracy\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])\n","f8939416":"# plotting some prefictions\ny_pred = model.predict(x_test)\nfig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]),cmap='gray')\n    pred_idx = np.argmax(y_pred[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","6cdcae77":"\nplot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), classes=target_labels,\n                      title='Confusion matrix, without normalization')\n\n# # Plot normalized confusion matrix\nplot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), classes=target_labels, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))","3b02b504":"#show classification errors\nei=y_test.argmax(axis=1)!=y_pred.argmax(axis=1)\nim_err=x_test[ei]\nact=y_test[ei]\npre=y_pred[ei]\nfor er,a,p in zip(im_err,act,pre):\n    plt.title(target_labels[np.argmax(p)]+\"\/\"+target_labels[np.argmax(a)])\n    plt.imshow(er.reshape(SIZE,SIZE),cmap='gray')\n    plt.show()","35231825":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom keras import backend as K\nfrom sklearn.utils import class_weight\n\n\n\nno_of_classes = len(np.unique(labels))\nbatch_size = 32\nkfold = KFold(n_splits=10, shuffle=True, random_state=7)\ncvscores=[]\n\nfor train_index, test_index in kfold.split(X,y):\n    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n    x_train, x_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    x_train = x_train.astype('float32')\/255\n    x_test = x_test.astype('float32')\/255\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, verbose=1, min_lr=0.0001)\n    y_numbers=y_train.argmax(axis=1)\n    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_numbers), y_numbers)\n    class_weights = dict(enumerate(class_weights))\n    print(class_weight)\n    model=get_model()\n    history = model.fit(x_train,y_train,\n        batch_size = 32,\n        epochs=10,\n        validation_split=0.2,\n        class_weight=class_weights,\n        callbacks = [reduce_lr],\n        verbose=1, shuffle=True)\n    # evaluate the model\n    y_pred = model.predict(x_test)\n    plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), classes=target_labels,\n                      title='Confusion matrix, without normalization')\n\n    # # Plot normalized confusion matrix\n    plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), classes=target_labels, normalize=True,\n                          title='Normalized confusion matrix')\n\n    plt.show()\n    scores = model.evaluate(x_test, y_test, verbose=0)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\nprint(np.mean(cvscores), np.std(cvscores))","8fa82de6":"some points look like outliers so I will use LocalOutlierFactor to remove some posible outliers","f895e081":"To help us with the imbalance task scikit-learn has a function that helps us calculate the weight of each class","dfa0725b":"# 4. Model Validation\nI used KFold with K= 10 and 10 epochs to validate the model, for each split I recompute the class weight. In order to evaluate the validation the confusion matrix classification is been presented. \n\nThe final result was ... \n\n<span style=\"color:blue\">Accuracy mean: *99.698%* std: 0.381<\/span>","57a2e2b8":"here I load the images and convert into gray images, then I performed a PCA in order to visualiza data to them find outliers, if exist.","19e79d3f":"Split data into training and testing datasets","2d53b162":"> ## Outliers remotion\n\nA simple visualization can help identify outliers, in this case I used PCA","e495ea39":"# 2. Train and package model","776353bb":"In this case the class Knife has much more data than the others and it could cause overfitting and misinterpretation of results.\n\n\nIn order to eliminate this bias of imbalance we need to balance the dataset. We can use different balancing methods both, using manual augmentation or using some functions like balanced_batch_generator.  Among them, the simplest that would be the undersampling of n-1 classes for the number of elements in the class with less elements or oversampling of the n-1 classes for the quantity of elements of the class with more elements. \n\nAnother known easy method to solve the imbalance problem is to adding weights to classes during the training as following:","0b731c38":"Therefore, we only need to adjust some parameters and pass the weights of the classes during the training of our model","884e7fd5":"## Imbalance analysis\nA simple bar chart show how the classes are imbalanced. Class knife has many more occurrences than the other classes","4b8509f1":"# 3. Testing model","b9ac6424":"# Some useful functions","17e8482d":"### Remove outliers","4b0a6f35":"# 1. Prepare data","707d9153":"# Loading original dataset\n I used load_files from sklearn.datasets package function to load the original dataset\n"}}