{"cell_type":{"4d0caedb":"code","32f73c79":"code","07a2bea7":"code","33b20295":"code","42a6cbd0":"code","7278700b":"code","c9a8ef82":"code","63fb3006":"code","abb76018":"code","14dd6714":"code","a76730b9":"code","fada61c9":"code","374419bb":"code","429a2331":"code","85956cf2":"code","d95f8590":"code","6740b3ee":"code","31d3e112":"code","d79a4a33":"code","4530152c":"code","66c56e18":"code","6a37c5d2":"code","98907f8d":"markdown","610dbd30":"markdown","ac79d919":"markdown","70b592cd":"markdown","516cd36f":"markdown","5e440cee":"markdown","48c1a124":"markdown","48028881":"markdown","074a4934":"markdown","6df753ae":"markdown","e65bb3eb":"markdown","5875e6ed":"markdown","9334d4de":"markdown","7e7ad04e":"markdown","0913581a":"markdown","1bf50299":"markdown","9856c290":"markdown","6369e4e0":"markdown","2fdc57da":"markdown","6ddf751c":"markdown","a212b9b9":"markdown"},"source":{"4d0caedb":"import os, sys, re\nfrom time import time, strftime, gmtime\nstart_notebook = time()\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\n!git clone -q https:\/\/github.com\/reyvaz\/tpu_segmentation.git\n!pip config set global.disable-pip-version-check true >\/dev\/null\n!pip install -qr tpu_segmentation\/requirements.txt >\/dev\/null\nfrom tpu_segmentation import *\n\nimport mask_functions as mf\n\nprint('Tensorflow version: ', tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE ","32f73c79":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n    print('TPU not found')\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu) \nelse:\n    strategy = tf.distribute.get_strategy()","07a2bea7":"IMAGE_SIZE = [1024, 1024] # Original size of the images\nN_CLASSES = 1\nN_CHANNELS = 1\nN_REPLICAS = strategy.num_replicas_in_sync\n\ngcs_path = KaggleDatasets().get_gcs_path('siimacr-pneumothorax-segmentation-tfrecs')\nTFRECS_TEST = tf.io.gfile.glob(gcs_path + '\/tfrecs\/*test*.tfrec')\nn_test_examples = count_data_items(TFRECS_TEST)\nprint('Number of TEST TFRecs: ', len(TFRECS_TEST))\nprint('Number of TEST examples: ', n_test_examples)","33b20295":"def read_test_tfrecord(example, str_feat):\n    features = {\n        str_feat: tf.io.FixedLenFeature([], tf.string)\n        }\n    example = tf.io.parse_single_example(example, features)\n    return example[str_feat]\n        \ndef load_test_dataset(filenames, str_feat = 'image'):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.map(lambda x: read_test_tfrecord(x, str_feat), \n                          num_parallel_calls=AUTO)\n    return dataset\n\ndef decode_resize_image(image_data, target_size, image_size = IMAGE_SIZE,\n                        make_rgb = True, n_channels = N_CHANNELS):\n\n    image = tf.image.decode_jpeg(image_data, channels=n_channels)\n    image = tf.cast(image, tf.float32) \/ 255.0  \n    if target_size != image_size: image = tf.image.resize(image, target_size)\n    if make_rgb:\n        image = tf.image.grayscale_to_rgb(image)\n        n_channels = 3\n    return tf.reshape(image, [*target_size, n_channels]) \n\ndescribe_ds = lambda x: print(re.sub('[<>]', '', str(x)))\n\ndef get_test_dataset(filenames, target_size, imgs_per_replica, make_rgb = True):\n    \n    batch_size = imgs_per_replica * N_REPLICAS\n    n_test = count_data_items(filenames)\n    min_steps = np.ceil(n_test\/batch_size).astype(int)\n\n    dataset = load_test_dataset(filenames)\n    dataset = dataset.map(lambda image: decode_resize_image(\n        image, target_size, make_rgb=make_rgb), AUTO)\n    \n    dataset = dataset.batch(batch_size).prefetch(AUTO) \n    describe_ds(dataset)\n    return dataset, n_test, min_steps","42a6cbd0":"n_rows, n_cols = 2, 5\n\ntemp_dataset = get_test_dataset(TFRECS_TEST[:1], (256, 256), 1, make_rgb = False)[0]\ntemp_dataset = temp_dataset.unbatch().take(n_rows*n_cols)\n\nfig, axs = plt.subplots(n_rows, n_cols, figsize=(25, 4*n_rows))\nfor c, item in enumerate(temp_dataset):\n    ax = fig.axes[c]\n    ax.imshow(item, cmap=plt.cm.bone)\n    ax.axis('off')","7278700b":"base_dir = '..\/input\/pneumothorax-segmentation-base\/'\nbin_meta = pd.read_csv(base_dir + 'bin_weights_meta.csv')\nseg_meta = pd.read_csv(base_dir + 'seg_weights_meta.csv')\nweigths_meta = bin_meta.append(seg_meta, ignore_index = True)\nweights_names = dict(zip(weigths_meta.key, weigths_meta.filename))","c9a8ef82":"weights_dir = base_dir + 'weights\/'\n\ndef load_pretrained_model(weights_id, compile_model = True, opt = [], loss = [], \n                          metrics = 'default', details = []):\n\n    prefix, size = weights_id.split('_')\n    size = eval(size.replace('x', ', '))\n    base, base_ver, model_type, _  = prefix.split('-')\n    wname = weights_names[weights_id]\n    weights_path = weights_dir + wname\n\n    base_name = base + base_ver\n\n    if 'bin' in model_type: \n        builder = build_classifier\n        if metrics == 'default': metrics = ['accuracy', 'AUC']\n            \n    elif 'unetpp' in model_type: builder = xnet\n    elif 'unet' in model_type and not 'unetpp' in model_type: builder = unet\n    \n    if 'unet' in model_type and metrics == 'default': \n        metrics = [dice_coef, dice_avg]\n    \n    with strategy.scope():\n        model = builder(base_name, 1, input_shape=(*size, 3), weights = None)\n        model.load_weights(weights_path)\n        if compile_model: model.compile(optimizer=opt, loss=loss, metrics=metrics)\n            \n    if len(details) > 0: \n        scope = locals()\n        return (model, *[eval(d, scope) for d in details])\n    else: return model\n\ndef assemble_ensemble(weights_ids, outter_size = (1024, 1024), \n                      ensemble_type = 'binary', metrics = 'default'):\n    \n    ensemble_outputs = []\n    resized_inputs = {}\n    with strategy.scope():\n        x = L.Input(shape=(*outter_size, 3))\n        for i, w in enumerate(weights_ids):\n            model, size = load_pretrained_model(w, compile_model = False, details = ['size'])\n            model._name = '{}-M{}'.format(model.name, i)\n            if size == outter_size:\n                model_output = model(x)\n            else:\n                if not str(size) in resized_inputs: \n                    resized_inputs[str(size)] = tf.image.resize(x, size)\n                model_output = model(resized_inputs[str(size)])\n                if ensemble_type == 'segmentation':\n                    model_output = tf.image.resize(model_output, outter_size)\n\n            ensemble_outputs.append(model_output)\n\n        y = L.Average(name = 'Simple_Average')(ensemble_outputs)\n\n        if metrics == 'default':\n            if ensemble_type == 'segmentation': metrics = [dice_coef, dice_avg] \n            else: metrics = ['accuracy', 'AUC']\n\n        name = '{}_Ensemble'.format(ensemble_type.title())\n        ensemble = tf.keras.Model(inputs=x, outputs=y, name=name)\n        ensemble.compile(optimizer=[], loss=[], metrics=metrics)\n    return ensemble","63fb3006":"ids_ds = load_test_dataset(TFRECS_TEST, str_feat = 'img_id').batch(512)\ntest_ids_bytes = []\nfor item in ids_ds:\n    test_ids_bytes += list(item.numpy())\nassert len(test_ids_bytes) == 3205\n\ntest_ids = [i.decode() for i in test_ids_bytes]\nprint('Num Test Examples: ', len(test_ids))","abb76018":"filenames = TFRECS_TEST\ntarget_size = (1024, 1024)\nimgs_per_replica = 8\n\ntest_ds, n_test, min_steps = get_test_dataset(filenames, target_size, imgs_per_replica)","14dd6714":"temp = bin_meta.groupby('fold')['metric'].nlargest(2)\nidxs = [i[1] for i in temp.index]\nbinary_members = bin_meta.loc[idxs].reset_index(drop=True)\n\nbinary_ensemble_members = binary_members.key.values\nprint('Number of Binary Ensemble Members: {}'.format(len(binary_ensemble_members)))\n\nbinary_ensemble = assemble_ensemble(binary_ensemble_members)\nbinary_ensemble.summary()","a76730b9":"start_binary_preds = time()\nbin_preds = binary_ensemble.predict(test_ds, verbose=1)\n\ntime_binary_preds = time() - start_binary_preds\nmin_secs = lambda secs: strftime(\"%M:%S\", gmtime(secs))\nprint('Time to make {} binary predictions: {} (MM:SS)'.format(n_test, min_secs(time_binary_preds)))","fada61c9":"bin_preds = bin_preds.squeeze()\nbinary_probs = dict(zip(test_ids, bin_preds))\nbinary_preds_df = pd.DataFrame(binary_probs.items(), columns = ['ImageId', 'pred_prob'])\n\ndisplay(binary_preds_df.head())","374419bb":"del binary_ensemble","429a2331":"size = (544, 544)\nsegmentation_ensemble_members = seg_meta.key.values\nprint('Number of Segmentation Ensemble Members: {}'.format(len(segmentation_ensemble_members)))\n\nsegmentation_ensemble = assemble_ensemble(segmentation_ensemble_members,\n                                          outter_size = size, ensemble_type = 'segmentation' )\nsegmentation_ensemble.summary()","85956cf2":"test_ds, n_test, total_steps = get_test_dataset(filenames, size, imgs_per_replica)\nprint('Total prediction steps: ', total_steps)\n\nn_parts = 3\nlen_part = np.ceil(min_steps\/n_parts).astype(int)\nprint('Max steps per part:', len_part)\n\nds_remain = test_ds\ntest_ds_parts = []\nfor d in range(n_parts):\n    dset = ds_remain.take(len_part)\n    test_ds_parts.append(dset)\n    ds_remain = ds_remain.skip(len_part)","d95f8590":"binary_treshhold = 0.60\nthresh_max = 0.75\nthresh_min = 0.40\nmin_area = 200\n\npred_rles = dict([[id, -1] for id in test_ids])\nprelim_masked = binary_preds_df.ImageId[binary_preds_df.pred_prob > binary_treshhold].values\nstart_mask_preds = time()\n\ni = 0\nmasked_ids = []\nfor p, test_ds_part in enumerate(test_ds_parts): \n    print('\\nPredicting and processing part {} of {}'.format(p+1, n_parts))\n    preds = segmentation_ensemble.predict(test_ds_part, verbose = 1)\n    preds = np.squeeze(preds)\n    print('Shape of predictions matrix {}: {}\\n'.format(p+1, preds.shape))\n\n    for pred in preds:\n        test_id = test_ids[i]\n        if binary_probs[test_id] > binary_treshhold:\n            pred_ = pred.copy()\n            pred  = (pred > thresh_max).astype(int)\n            if pred.sum() > min_area: \n                pred = (pred_ > thresh_min).astype(int)\n                pred = np.expand_dims(pred, axis = 2)\n                pred_mask = tf.image.resize(pred, IMAGE_SIZE)\n                pred_mask = np.squeeze(pred_mask)\n                pred_mask = (np.round(pred_mask)*255).astype(int)\n                mask_rle = mf.mask2rle(pred_mask.T, *IMAGE_SIZE)\n                pred_rles[test_id] = mask_rle\n                masked_ids.append(test_id)\n        i += 1\n    del preds, pred, pred_, pred_mask\n\ntime_mask_preds = time() - start_mask_preds\ndel segmentation_ensemble\nprint('Time to predict and post-process {} images: {} (MM:SS)'.format(n_test, min_secs(time_mask_preds)))","6740b3ee":"skip = 100\ndemo_ds = test_ds_parts[0].unbatch().skip(skip)\n\nn_rows = 2\nn_cols = 5\n\nmasked_examples = {}\nunmasked_examples = {}\nmax_examples = n_rows*n_cols\n\nfor i, image in enumerate(demo_ds):\n    test_id = test_ids[i+skip]\n    if test_id in masked_ids and len(masked_examples) < max_examples:\n        masked_examples[test_id] = image\n    elif not test_id in masked_ids and len(unmasked_examples) < max_examples: \n        unmasked_examples[test_id] = image\n    if len(masked_examples) == len(unmasked_examples) == max_examples: break\n","31d3e112":"fig, axs = plt.subplots(n_rows, n_cols, figsize=(25, 4*n_rows))\nfor c, (img_id, image) in enumerate(masked_examples.items()):\n    image = tf.image.resize(image, IMAGE_SIZE)\n    \n    mask = mf.rle2mask(pred_rles[img_id], *IMAGE_SIZE)\/255\n    mask = contoured_mask(mask.T, rgb_color = (200, 0, 150), alpha = 0.35)\n\n    ax = fig.axes[c]\n    ax.imshow(image, cmap=plt.cm.bone)\n    ax.imshow(mask)\n    ax.axis('off')\n    ax.set_title('Image ID: {}'.format(img_id), fontdict={'fontsize': 13})","d79a4a33":"fig, axs = plt.subplots(n_rows, n_cols, figsize=(25, 4*n_rows))\nfor c, (img_id, image) in enumerate(unmasked_examples.items()):\n    ax = fig.axes[c]\n    ax.imshow(image, cmap=plt.cm.bone)\n    ax.axis('off')\n    ax.set_title('Image ID: {}'.format(img_id), fontdict={'fontsize': 13})","4530152c":"sub_df = pd.DataFrame(pred_rles.items(), columns=['ImageId', 'EncodedPixels'])\nsub_df.to_csv('submission.csv', index=False)","66c56e18":"!rm -rf tpu_segmentation mask_functions.py __pycache__","6a37c5d2":"time_notebook = time() - start_notebook\nprint('Time to run notebook {} (MM:SS)'.format(min_secs(time_notebook)))","98907f8d":"# Binary Predictions","610dbd30":"## Retrieving Ordered Image IDs from TFRecs","ac79d919":"## Predict Mask, Post-Process, Encode and Record RLE","70b592cd":"#### Predictions with no Pneumothorax Disease","516cd36f":"### Perform Binary Predictions","5e440cee":"## Create Submission File","48c1a124":"### Visualize Predicted Examples","48028881":"## Mask Prediction Dataset(s)\n\nUnlike for the binary predictions, there's not sufficient memory to store the predicted masks for the entire test dataset. These mask predicitions are required for post-processing before encoding into RLE. \n\nAlthough mask predictions are not required for the entire test dataset (i.e. mask predictions for images predicited negative for pneumothorax are not needed), in order to take advantage of the TPU during inference, mask predictions will be done for all test images. \n\nFor this, the test dataset will be divided into several parts. Predictions will sequentially be made for each part, post-processed, and rle-encoded.","074a4934":"## Constants and TFRecs File Paths","6df753ae":"## Functions to Build Ensembles","e65bb3eb":"## Required Packages","5875e6ed":"## Distribution Strategy","9334d4de":"### Build Ensemble for Binary Predictions\n\nCNNs were trained across 5 cross-validation folds. The ensemble for binary predictions will include the top 2 best performing classifiers corresponding to each of the k-folds used during training. ","7e7ad04e":"## Pretrained Weights Metadata","0913581a":"# Mask Predictions","1bf50299":"## Visualize Test Examples","9856c290":"### Dataset for Binary Predictions","6369e4e0":"## Dataset Pipeline","2fdc57da":"### Build Segmentation Ensemble","6ddf751c":"#### Predictions with Pneumothorax Disease","a212b9b9":"# Identify Pneumothorax Disease in Chest X-Rays, Inference Notebook\n\nMore information about training the networks can be found [here]( https:\/\/github.com\/reyvaz\/pneumothorax_detection)\n\n#### Uses a 2-step approach for the identification of pneumothorax disease on the test dataset images. \n\nThe 1st step attempts to classify x-rays as presenting pneumothorax disease or not. To do so, it uses an ensemble of EfficientNet based image classifiers. The ensemble predictions are the simple average across all classifiers in the ensemble. \n\nIn the 2nd step, if the image was classified as likely having the disease in step 1, it tries to identify the location of the disease within the x-ray image. To do this, it uses an ensemble of Unet and Unet++ segmentation CNNs, all with EfficientNet encoders. The mask predictions are the simple average predictions across all CNNs in the the ensemble.\n\n**Credits**:\n\nThis notebook was inspired by Siddhartha\u2019s [Unet Plus Plus with EfficientNet Encoder](https:\/\/www.kaggle.com\/meaninglesslives\/nested-unet-with-efficientnet-encoder) notebook.\n\n**References**:\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, & Jian Sun. (2015). Deep Residual Learning for Image Recognition.\n\nMingxing Tan, & Quoc V. Le. (2020). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n\nOlaf Ronneberger, Philipp Fischer, & Thomas Brox. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation.\n\nZhou, Z., Siddiquee, M., Tajbakhsh, N., & Liang, J. (2019). UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation IEEE - Transactions on Medical Imaging."}}