{"cell_type":{"d6a2468f":"code","498d147b":"code","f9cfce40":"code","259a224f":"code","e920c200":"code","f9922bb0":"code","fab45bb3":"code","7ef3968b":"code","b9691f6b":"code","d33f8664":"code","2e85b0a3":"code","92a14538":"code","565f92e1":"code","e68c64c8":"code","87446784":"code","70f2e36b":"code","6ed3efc1":"code","889cd896":"code","47302ede":"code","3b5508c5":"code","6a46c509":"code","406fb791":"code","26fd568e":"code","b4cd473b":"code","2d87487a":"code","fb218cf8":"code","c6a1e9cf":"markdown","7d30b1b5":"markdown","f57be4b5":"markdown","c62b7739":"markdown","67ad4a7f":"markdown","3ce9a9a5":"markdown","e831f1e6":"markdown","0015f7b6":"markdown","e8a622f0":"markdown","8ef15efe":"markdown","e6a91b0a":"markdown","e47c12d3":"markdown","ee6b85a5":"markdown"},"source":{"d6a2468f":"import os\nprint((os.listdir('..\/input\/')))","498d147b":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import roc_auc_score, f1_score\nimport numpy as np","f9cfce40":"df_train = pd.read_csv('..\/input\/webclubrecruitment2019\/TRAIN_DATA.csv')\ndf_test = pd.read_csv('..\/input\/webclubrecruitment2019\/TEST_DATA.csv')\ntest_index=df_test['Unnamed: 0']","259a224f":"df_train.dtypes","e920c200":"df_train.V6.describe()","f9922bb0":"# Mean and standard deviation suggest outliers in the data which are not useful \ndf = df_train[df_train.V6 < 6000]\ndf = df[df.V6 > -3000]","fab45bb3":"(df_train.Class == 1).sum()","7ef3968b":"(df_train['Class'] == 0).sum()","b9691f6b":"from sklearn.model_selection import GridSearchCV\nparams = {\"max_depth\" : (3,4), \"n_estimators\" : (100, 150, 200, 250, 300, 350, 400, 450), 'loss' : ('exponential', 'deviance')}","d33f8664":"from sklearn.model_selection import train_test_split\ntrain_X = df.loc[:, 'V1':'V16']\n\ntrain_y = df.loc[:, 'Class']\n#train_X.drop('V2', axis = 'columns', inplace = True)\n\nx_train, x_test, y_train, y_test = train_test_split(train_X, train_y, test_size = 0.3)\n\n# V2 has many categories for binary classification. However dropping it doesnt help much","2e85b0a3":"train_X.columns","92a14538":"gb = GradientBoostingClassifier(n_estimators = 350,random_state = 123, max_depth = 3, loss = 'exponential')\n#gb= GradientBoostingClassifier()\n","565f92e1":"#clf  = GridSearchCV(gb, params, cv = 5, scoring = 'roc_auc')\n#clf.fit(train_X, train_y)","e68c64c8":"#(clf.best_params_)","87446784":"gb.fit(x_train, y_train)","70f2e36b":"\npred = gb.predict(x_test)","6ed3efc1":"print(f1_score(y_test, pred, average='macro')) \n","889cd896":"print(roc_auc_score(y_test, pred))","47302ede":"df_train = pd.read_csv('..\/input\/webclubrecruitment2019\/TRAIN_DATA.csv')\ndf_test = pd.read_csv('..\/input\/webclubrecruitment2019\/TEST_DATA.csv')\ntest_index=df_test['Unnamed: 0']","3b5508c5":"df_train = df_train[df_train.V6 < 6000]\ndf_train = df_train[df_train.V6 > -3000]","6a46c509":"gb = GradientBoostingClassifier(n_estimators=350, random_state=123, loss = 'exponential', max_depth = 3)\n#df_train.drop(\"V2\", axis = 'columns', inplace = True)\ntrain_X = df_train.loc[:, 'V1':'V16']\ntrain_y = df_train.loc[:, 'Class']\n\n\n\ngb.fit(train_X, train_y)\n","406fb791":"df_test.head()","26fd568e":"df_test.columns","b4cd473b":"df_test = df_test.loc[:, 'V1':'V16']\n#df_test.drop(\"V2\", axis = 'columns', inplace = True)\npred = gb.predict_proba(df_test)","2d87487a":"result=pd.DataFrame()\nresult['Id'] = test_index\nresult['PredictedValue'] = pd.DataFrame(pred[:,1])\nresult.head()","fb218cf8":"result.to_csv('output1.csv', index=False)","c6a1e9cf":"### Visualizing the Training Set","7d30b1b5":"### Reading the Train and Test Set","f57be4b5":"## My Kernel for WebClub Recruitment Test 2019","c62b7739":"### Now we use the entire dataset to train the Gradient Boosted Classifier","67ad4a7f":"### Initializing Classifier","3ce9a9a5":"### Importing required packages","e831f1e6":"### Training Classifier","0015f7b6":"Hence data is skewed","e8a622f0":"### Writing the results to a file","8ef15efe":"One Hot Encoding avoided since it doesn't affect Tree based models.","e6a91b0a":"GridSearchCV gives best parameters as n_estimators = 150, max_depth = 3, loss = 'exponential'","e47c12d3":"### Calculating predictions for the test set","ee6b85a5":"#### Though GridSearchCV gives n_estimators = 100 to be the best parameter, n_estimators = 350 is giving a higher score on submission"}}