{"cell_type":{"23ddd9fe":"code","b40b666c":"code","0e66b9fe":"code","8dc2e72e":"code","04a611e5":"code","21202e5e":"code","dd4b5c01":"code","7170599d":"code","ec26708d":"code","90cd2208":"code","a7464992":"code","cf219ba3":"code","c0a31427":"code","316873f2":"code","e8add9fd":"code","ac22da5e":"code","070167dd":"code","196e4f61":"code","542d3fc8":"code","01944da9":"code","e0585443":"code","2423db99":"code","183aad37":"code","6e1f8e3a":"code","a94adf0f":"code","fd33d3ab":"code","5c5e3554":"code","cb894555":"code","8bc40e61":"code","5e95b582":"code","a8cc5fde":"code","f669d3f3":"code","d97fe309":"code","8a61cd0b":"code","26594331":"code","c15da854":"code","a314aca7":"code","28be56d4":"code","756311c6":"code","4b0218e6":"code","485d1841":"markdown","b0d55061":"markdown","918bcf70":"markdown","686133c3":"markdown","231d9036":"markdown","b9ad0200":"markdown","01d1ecd4":"markdown","70933e40":"markdown","e9c80565":"markdown","8b42c395":"markdown","619a4feb":"markdown","5bc86ef3":"markdown","333c5c14":"markdown","9a275274":"markdown","e5ee4b0d":"markdown","c8575568":"markdown","ef582798":"markdown","edb7b8fd":"markdown"},"source":{"23ddd9fe":"from random import randint\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","b40b666c":"data_directory = os.path.join(os.getcwd(), '..\/input')\nprint(os.listdir(data_directory))","0e66b9fe":"!cat '..\/input\/readme.txt'","8dc2e72e":"data_dictionnary = {}\n\n# columns name from readme\n# define metadata and feature\noperational_settings = ['op_setting_{}'.format(i + 1) for i in range (3)]\nsensor_columns = ['sensor_{}'.format(i + 1) for i in range(27)]\nfeatures = operational_settings + sensor_columns\nmetadata = ['engine_no', 'time_in_cycles']\nlist_columns = metadata + features\n\n\nlist_file_train = [x for x in sorted(os.listdir(data_directory)) if 'train' in x]\n\n# names of the datasets\nfor file_train in list_file_train:\n    data_set_name = file_train.replace('train_', '').replace('.txt', '')\n    file_test = 'test_' + data_set_name + '.txt'\n    rul_test = 'RUL_' + data_set_name + '.txt'\n    \n    # dictionnaries with all datasets\n    data_dictionnary[data_set_name] = {\n        'df_train': pd.read_csv(os.path.join(data_directory, file_train), sep=' ', header=-1, names=list_columns),\n        'df_test': pd.read_csv(os.path.join(data_directory, file_test), sep=' ', header=-1, names=list_columns),\n        'RUL_test' :pd.read_csv(os.path.join(data_directory, rul_test), header=-1, names=['RUL']),\n    }","04a611e5":"data_dictionnary['FD001']['df_train'].head()","21202e5e":"# on regarde le max de time in cycle et on le cr\u00e9\u00e9 de la m\u00eame taille que le vecteur initial puis on fait la diff \ndef add_rul(g):\n    g['RUL'] = [max(g['time_in_cycles'])] * len(g)\n    g['RUL'] = g['RUL'] - g['time_in_cycles']\n    del g['engine_no']\n    return g.reset_index()\n\nfor data_set in data_dictionnary:\n    data_dictionnary[data_set]['df_train'] = data_dictionnary[data_set]['df_train']\\\n                        .groupby('engine_no').apply(add_rul).reset_index()\n    del data_dictionnary[data_set]['df_train']['level_1']","dd4b5c01":"data_dictionnary['FD001']['df_train'].head()","7170599d":"CHOSEN_DATASET = 'FD001'\n\ndf = data_dictionnary[CHOSEN_DATASET]['df_train'].copy()\n\ndf_eval = data_dictionnary[CHOSEN_DATASET]['df_test'].copy()","ec26708d":"dataset_description = df.describe()\ndataset_description","90cd2208":"axes = dataset_description.T.plot.bar(subplots=True, figsize=(15,10))","a7464992":"###############< ??? >###############\n# What can you conclude from the graph above?\n# Count = 0 --> There are null columns \n# Different scaling","cf219ba3":"df_plot = df.copy()[features]\ndf_corr = df_plot.corr(method='pearson')\nfig, ax = plt.subplots(figsize=(15,15))\naxes = sns.heatmap(df_corr, linewidths=.2, )","c0a31427":"###############< ??? >###############\n# Can you plot a correlation matrix with another correlation coeficient?\ndf_plot = df.copy()[features]\ndf_corr = df_plot.corr(method='kendall')\nfig, ax = plt.subplots(figsize=(15,15))\naxes = sns.heatmap(df_corr, linewidths=.2, )\n\n# correlation de rang, tau de kendall = (nbpaire concordante - nbpaires discordantes)\/(nbtotal de paires)\n# tau in [-1;1], if X,Y not correlated, tau ~0","316873f2":"###############< ??? >###############\n# What can append when you have correlated features?\n","e8add9fd":"nan_column = df.columns[df.isna().any()].tolist()\nconst_columns = [c for c in df.columns if len(df[c].drop_duplicates()) <= 2]\nprint('Columns with all nan: \\n' + str(nan_column) + '\\n')\nprint('Columns with all const values: \\n' + str(const_columns) + '\\n')","ac22da5e":"###############< ??? >###############\n# Can you find all the couples that are strongly correlated ?","070167dd":"df_plot = df.copy()\ndf_plot = df_plot.sort_values(metadata)\ngraph = sns.PairGrid(data=df_plot, x_vars=\"RUL\", y_vars=features, hue=\"engine_no\", height=4, aspect=6,)\ngraph = graph.map(plt.plot, alpha=0.5)\ngraph = graph.set(xlim=(df_plot['RUL'].max(),df_plot['RUL'].min()))\n# graph = graph.add_legend()","196e4f61":"###############< ??? >###############\n# What can you see from the graphs above?","542d3fc8":"###############< ??? >###############\n# Is is better to train on a smaller part?","01944da9":"number_of_engine_no = len(df['engine_no'].drop_duplicates())\n\nengine_no_val = range(50, 70)\nengine_no_train = [x for x in range(number_of_engine_no) if x not in engine_no_val]","e0585443":"selected_features = [x for x in features if x not in nan_column + const_columns]","2423db99":"data_train = df[df['engine_no'].isin(engine_no_train)]\ndata_val = df[df['engine_no'].isin(engine_no_val)]\n\nX_train, y_train = data_train[selected_features], data_train['RUL'] \nX_val, y_val = data_val[selected_features], data_val['RUL']\n\nX_eval = df_eval[selected_features]\n\n\nX_all, y_all = df[selected_features], df['RUL']","183aad37":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train, y_train)","6e1f8e3a":"print(\"Score on train data : \" + str(rf_reg.score(X_train, y_train)))\nprint(\"Score on test data : \" + str(rf_reg.score(X_val, y_val)))","a94adf0f":"###############< ??? >###############\n# Did you overfit?","fd33d3ab":"###############< ??? >###############\n# Can you have the RMSE?","5c5e3554":"from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\ncv_results = cross_validate(rf_reg, X_train, y_train, cv=10, return_estimator=True)","cb894555":"cv_results['test_score']","8bc40e61":"cv_results['estimator'][0].score(X_val, y_val)","5e95b582":"cv_results['estimator'][1].score(X_val, y_val)","a8cc5fde":"cv_results['estimator'][2].score(X_val, y_val)","f669d3f3":"cv_results['estimator'][3].score(X_val, y_val)","d97fe309":"cv_results['estimator'][4].score(X_val, y_val)","8a61cd0b":"###############< ??? >###############\n# Try to improve you model.\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\nrf_reg = RandomForestRegressor()\ncross_val_score(rf_reg, X_train, y_train, cv=10)","26594331":"y_pred = cross_val_predict(rf_reg, X_train, y_train, cv=10)","c15da854":"print(\"Score on test data : \" + str(rf_reg.score(X_val, y_val)))","a314aca7":"plot_regression_results(\n        ax, y, y_pred,\n        name,\n        (r'$R^2={:.2f} \\pm {:.2f}$' + '\\n' + r'$MAE={:.2f} \\pm {:.2f}$')\n        .format(np.mean(score['test_r2']),\n                np.std(score['test_r2']),\n                -np.mean(score['test_neg_mean_absolute_error']),\n                np.std(score['test_neg_mean_absolute_error'])),\n        elapsed_time)","28be56d4":"df_pred = data_train.copy()\ndf_pred['pred'] = rf_reg.predict(X_train)\ndf_pred['error'] = df_pred['pred'] - df_pred['RUL']","756311c6":"df_plot = df_pred.copy()\ndf_plot = df_plot.sort_values(['engine_no', 'time_in_cycles'])\ng = sns.PairGrid(data=df_plot, x_vars=\"RUL\", y_vars=['RUL', 'pred', 'error'], hue=\"engine_no\", height=6, aspect=6,)\ng = g.map(plt.plot, alpha=0.5)\ng = g.set(xlim=(df_plot['RUL'].max(),df_plot['RUL'].min()))","4b0218e6":"df_eval['pred'] = rf_reg.predict(X_eval)\n\ndf_eval['result'] = df_eval['pred']\ndf_eval['engine_id'] = list(range(len(df_eval)))\n\ndf_eval[['engine_id','result']].to_csv('submission.csv', index=False)","485d1841":"### Plot a temporal vizualisation of the features","b0d55061":"# Chosing a dataset ","918bcf70":"# Making a prediction","686133c3":"# Imports","231d9036":"# Prediction on test data and Output","b9ad0200":"### Score the model ","01d1ecd4":"### Selecting only relevant features","70933e40":"### Plotting some description of the dataset","e9c80565":"### Find columns that can be droped ","8b42c395":"# List data directory","619a4feb":"### Splitting test \/ train data","5bc86ef3":"# Load DATA","333c5c14":"### Actually making the split","9a275274":"### Correlation matrix","e5ee4b0d":"# Add RUL","c8575568":"### Training a random forest","ef582798":"### Plotting the result ","edb7b8fd":"# Data analysis"}}