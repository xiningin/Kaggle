{"cell_type":{"337eb086":"code","6b783e78":"code","f9c68365":"code","56919a01":"code","57667ba5":"code","7d83bac3":"code","4b94acdd":"code","eb79b50b":"code","7a739ffd":"code","cae81808":"code","be5b1f38":"code","d0ee369d":"code","4c61ad48":"code","52b4ab61":"code","137e0343":"code","3e5c9f34":"markdown","41715ff7":"markdown","90fd525a":"markdown","8d1640eb":"markdown","ac43748f":"markdown","342905f5":"markdown","18571e1b":"markdown","1feb879d":"markdown","453df4c6":"markdown","effdf55a":"markdown","b7e738e1":"markdown","5aea5f5b":"markdown","51572109":"markdown","0a796663":"markdown","d6943c01":"markdown","ba66284c":"markdown","aedfc6cc":"markdown","85f7f836":"markdown","0505f218":"markdown"},"source":{"337eb086":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\n\nimport seaborn as sns\nsns.set()\nimport torch.nn as nn\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim","6b783e78":"dataset = load_boston()","f9c68365":"df=pd.DataFrame(dataset.data)\ndf.columns=dataset.feature_names\ndf[\"Price\"]=dataset.target\ndf.head()","56919a01":"df.plot(x=\"RM\",y=\"Price\",style=\"o\")\n","57667ba5":"y=df[\"Price\"]\nx=df.drop(\"Price\",axis=1)","7d83bac3":"#from sklearn.preprocessing import StandardScaler\nsscaler = StandardScaler()\nsscaler.fit(x)\nX_std= sscaler.transform(x)","4b94acdd":"#from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_std,y,test_size=0.3,random_state=99)\nX_train.shape","eb79b50b":"class NN(nn.Module):\n  def __init__(self):\n    super(NN,self).__init__()\n    self.layer1=nn.Linear(X_train.shape[1],39)\n    self.layer2=nn.Linear(39,26)\n    self.layer3=nn.Linear(26,13)\n    self.layer4=nn.Linear(13,1)\n  def forward(self,x):\n    x=F.relu(self.layer1(x))\n    x=F.relu(self.layer2(x))\n    x=F.relu(self.layer3(x))\n    x=self.layer4(x)\n    return x\nmodel = NN()\nprint(model)","7a739ffd":"x=torch.tensor(np.array(X_train),dtype=torch.float32,requires_grad=True)\ny=torch.tensor(np.array(y_train).reshape(-1,1),dtype=torch.float32)\nx","cae81808":"#import torch.optim as optim\noptimizer= optim.SGD(model.parameters(),lr=0.003)","be5b1f38":"loss_fn=nn.MSELoss()","d0ee369d":"epochs=200\nfor i in range(epochs):\n  #initialize the model parameter\n  optimizer.zero_grad(set_to_none=True)\n  #calculate the loss\n  output=model(x)\n  loss=loss_fn(output,y)\n  #backpropagation\n  loss.backward()\n  #update the parameters\n  optimizer.step()\n  if(i%5==0):\n    print(f\"epochs: {i}......loss:{loss}\")","4c61ad48":"y_train_pred = model(torch.tensor(X_train,dtype=torch.float32,requires_grad=True))\ny_test_pred = model(torch.tensor(X_test,dtype=torch.float32))\n\n#convert to numpy array\ny_train_pred = y_train_pred.detach().numpy()\ny_test_pred = y_test_pred.detach().numpy()\n\n","52b4ab61":"test_accuracy=r2_score(y_test,y_test_pred)\ntrain_accuracy=r2_score(y_train,y_train_pred)\nprint(train_accuracy)\nprint(test_accuracy)","137e0343":"plt.xlabel(\"Price\")\nplt.ylabel(\"Predicted Price\")\nplt.scatter(y_train,y_train_pred,color='r',label=\"train_data\")\nplt.scatter(y_test,y_test_pred,color='b',label=\"test_data\")\nplt.legend()\nplt.show()","3e5c9f34":"### The score is good, can be improved using hyper-parameter tuning.","41715ff7":"\n\n> **Import the packages**\n\n","90fd525a":"**Read the dataset as pandas DataFrame**","8d1640eb":"## Summary\nwe have seen the Neural Network analysis constructed by PyTorch against the boston house prices dataset.Although we use a very simple network structure,the accuracy of the validation data is more than that of Linear Regression. <br>\n**I hopes this notebook helps the readers a little.** <br>\n\n\n\n","ac43748f":"**Accuracy: R^2**","342905f5":"#### Hello, EveryBody, this is part 1 of beginner series of Pytorch project, hopes it helps beginner to infer how pytorch works.","18571e1b":"## Train the model <br>\nFinally,we can train the model! <br>\nAt every epoch, we perform:<br>\n1. Initialize the gradient of the model parameter\n2. Calculate the loss\n3. calculate the gradient of the model parameter by backpropagation.\n4. Update the model parameter\n","1feb879d":"**The loss would be gradually decreasing.It indicates that the training model is being well done.**","453df4c6":"**Define an Optimizer**","effdf55a":"**Define Loss Function**","b7e738e1":"# **Visualize the results**\nFinally, let's visualize the result by matplotlib.<br>\nThe red and blue circles shows the results of training and validation data,respectively","5aea5f5b":"**Validation**","51572109":"**splitting the dataset**","0a796663":"split the target variable and test variable","d6943c01":"**Define A Neural Network Model by PyTorch**","ba66284c":"**Standardize the variable**\n","aedfc6cc":"**Convert Data into Tensor**","85f7f836":"let's try to check the correlation between \"Price\" and \"RM\"","0505f218":"**Load the Dataset**\n<br>\nwe use the boston boston house price dataset in the scikit-learn library"}}