{"cell_type":{"f442c21a":"code","deced8aa":"code","b6ea7bea":"code","dca60b1a":"code","25433b14":"code","7da90774":"code","b2d66d48":"code","acc7198b":"code","acb27955":"code","8ad5ea11":"code","d358a832":"code","5e466b21":"code","4802176c":"code","47b7f491":"code","83536206":"code","a2b9c23a":"code","0950359d":"code","f506ca28":"code","c500e8b5":"code","fd832fa8":"code","48325001":"code","71217efc":"code","ce0cd5a9":"code","675382dd":"code","d9434433":"code","9f85a269":"code","2c035e8c":"code","f917a096":"code","26f60ee8":"code","19c8e44c":"code","e8b2467e":"code","9db2fa5a":"code","db7153fa":"code","c536e474":"code","031ab859":"code","1a198ab5":"code","7c27c6a9":"code","1063e8da":"code","18d190e0":"code","ed3507b3":"code","71b1b2b7":"code","b42c3469":"code","788caa5e":"markdown","d1d03276":"markdown","4650ba0f":"markdown","8a079761":"markdown"},"source":{"f442c21a":"import numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\n\nfrom pandas_profiling import profile_report\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score,accuracy_score,f1_score,precision_score,recall_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import accuracy_score,log_loss,mean_absolute_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score,cross_validate\nfrom sklearn import tree\nimport graphviz \n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader,Dataset\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom imblearn.over_sampling import SMOTE\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","deced8aa":"train_df = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ntrain_df","b6ea7bea":"train_df.info()","dca60b1a":"train_df.describe()","25433b14":"fig, ax = plt.subplots()\nax.boxplot([train_df.platelets,train_df.creatinine_phosphokinase])\nplt.xticks([1,2],['platelets','creatinine_phosphokinase'])\nplt.legend()\nplt.show()","7da90774":"fix_features = pd.concat([train_df.platelets],axis=1)\nscaler = MinMaxScaler(feature_range=(0,1))\nfix_features = pd.DataFrame(scaler.fit_transform(fix_features))\ndf = pd.concat([train_df,fix_features],axis=1)\ndf.drop(['platelets'],axis=1,inplace=True)\ndf = df.rename(columns={0:'creatinine_phosphokinase',1:'platelets'})\ndf","b2d66d48":"df.keys()","acc7198b":"train_df.hist(figsize=(15,10))","acb27955":"f,ax = plt.subplots(1,1,figsize=(15,10))\nsns.countplot('age',hue='DEATH_EVENT',data=train_df,ax=ax)","8ad5ea11":"df.DEATH_EVENT.value_counts(normalize=True).plot(kind='bar')\nprint(df.DEATH_EVENT.value_counts(normalize=True)*100)","d358a832":"pd.crosstab(train_df.smoking,train_df.DEATH_EVENT).plot(kind='bar')\nplt.ylabel('Death num')\nplt.xlabel('Smoking')\nplt.title('Smoking and Death')\nplt.xticks(ticks=(0,1),labels=['None smoking','Smoking'])","5e466b21":"corr_data = df[df.keys()]\nk = len(train_df.keys())\ncols = corr_data.corr().nlargest(k,'DEATH_EVENT')['DEATH_EVENT'].index\ncolor_map = plt.cm.PuBu\ncm = np.corrcoef(df[cols].values.T)\nf,ax = plt.subplots(figsize=(14,12))\nplt.title('Correlation with Death event')\nheatmap = sns.heatmap(cm, vmax=1, linewidths=0.1,square=True,annot=True,cmap=color_map, linecolor=\"white\",xticklabels = cols.values ,yticklabels = cols.values)","4802176c":"f,ax = plt.subplots(figsize=(14,12))\nsns.histplot(x='age',data=train_df,hue='DEATH_EVENT',kde=True)","47b7f491":"f,ax = plt.subplots(figsize=(14,12))\nsns.histplot(x='time',data=train_df,hue='DEATH_EVENT',kde=True)\nplt.ylabel('Num people')","83536206":"df","a2b9c23a":"train, test = df[:-40], df[-40:]\nprint(train.shape,test.shape)","0950359d":"y_train = df.DEATH_EVENT\nx_train = df.drop('DEATH_EVENT',axis=1)\nprint(x_train.shape,y_train.shape)","f506ca28":"x_train, x_test, y_train, y_test = train_test_split(x_train,y_train,test_size=0.3,shuffle=True)","c500e8b5":"smote = SMOTE(random_state=0)\nx_train_oversample , y_train_oversample = smote.fit_resample(x_train.values,y_train.values) ","fd832fa8":"print(x_train_oversample.shape , y_train_oversample.shape)","48325001":"print(x_test.shape,y_test.shape)","71217efc":"from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\nfrom lightgbm import plot_importance,plot_metric\nfrom lightgbm import LGBMClassifier","ce0cd5a9":"skf = StratifiedKFold(n_splits=5,shuffle=True)","675382dd":"bagging_models = []\nfor train_idx,valid_idx in skf.split(x_train_oversample,y_train_oversample):\n    x_train, y_train = x_train_oversample[train_idx], y_train_oversample[train_idx]\n    x_valid , y_valid = x_train_oversample[valid_idx], y_train_oversample[valid_idx]\n    bagging = BaggingClassifier(base_estimator=RandomForestClassifier(),n_estimators=100,\n                                max_samples=50,oob_score=True,verbose=True)\n    bagging.fit(x_train,y_train)\n    pred = bagging.predict(x_valid)\n    print(f'Testset_Accuracy: {accuracy_score(y_valid,pred)}')\n    print(f'Testset_f1-score: {f1_score(y_valid,pred)}')\n    print(f'Testset_recall: {recall_score(y_valid,pred)}')\n    print(f'Testset_precision: {precision_score(y_valid,pred)}')\n    print('-------------------------------------------------')\n    bagging_models.append(bagging)\n    ","d9434433":"lgb_models = []\nfor train_idx,valid_idx in skf.split(x_train_oversample,y_train_oversample):\n    x_train, y_train = x_train_oversample[train_idx], y_train_oversample[train_idx]\n    x_valid , y_valid = x_train_oversample[valid_idx], y_train_oversample[valid_idx]\n    lgb = LGBMClassifier(n_estimators=500,learning_rate=3e-2,max_depth=100,\n                        verbose=100)\n    lgb.fit(x_train,y_train,eval_set=[(x_valid,y_valid)],early_stopping_rounds=100,eval_metric=['logloss'])\n    lgb_models.append(lgb)\n    ","9f85a269":"plot_metric(lgb)","2c035e8c":"plot_importance(lgb,figsize=(15,10))","f917a096":"for model in bagging_models:\n    pred = model.predict(x_test)\n    print(f'Testset_Accuracy: {accuracy_score(y_test,pred)}')\n    print(f'Testset_f1-score: {f1_score(y_test,pred)}')\n    print(f'Testset_recall: {recall_score(y_test,pred)}')\n    print(f'Testset_precision: {precision_score(y_test,pred)}')\n    print('-------------------------------------------------')\n# model_2 Best!","26f60ee8":"for model in lgb_models:\n    pred = model.predict(x_test)\n    print(f'Testset_Accuracy: {accuracy_score(y_test,pred)}')\n    print(f'Testset_f1-score: {f1_score(y_test,pred)}')\n    print(f'Testset_recall: {recall_score(y_test,pred)}')\n    print(f'Testset_precision: {precision_score(y_test,pred)}')\n    print('-------------------------------------------------')\n# model 4 Best!","19c8e44c":"bag_model = bagging_models[1]\npred = bag_model.predict(x_test)\nprint(f'Testset_Accuracy: {accuracy_score(y_test,pred)}')\nprint(f'Testset_f1: {f1_score(y_test,pred)}')\nprint(f'Testset_recall: {recall_score(y_test,pred)}')\nprint(f'Testset_precision: {precision_score(y_test,pred)}')","e8b2467e":"lgb_model = lgb_models[3]\npred = lgb_model.predict(x_test)\nprint(f'Testset_Accuracy: {accuracy_score(y_test,pred)}')\nprint(f'Testset_f1: {f1_score(y_test,pred)}')\nprint(f'Testset_recall: {recall_score(y_test,pred)}')\nprint(f'Testset_precision: {precision_score(y_test,pred)}')","9db2fa5a":"class CustomDataset(Dataset):\n    def __init__(self,data,label):\n        self.data = data\n        self.label = label\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        data = torch.tensor(self.data[idx],dtype=torch.float32)\n        label = torch.tensor(self.label[idx],dtype=torch.float32)\n        return data,label","db7153fa":"# GRU_train = np.array(x_train_oversample).reshape(x_train_oversample.shape[0],1,x_train_oversample.shape[1])\n# GRU_test = np.array(x_test).reshape(x_test.shape[0],1,x_test.shape[1])","c536e474":"# print(GRU_train.shape)","031ab859":"train_set = CustomDataset(x_train_oversample,y_train_oversample)\ntest_set = CustomDataset(x_test.values,y_test.values)","1a198ab5":"test_loader = DataLoader(test_set,batch_size=len(y_test),num_workers=0)","7c27c6a9":"y_test.value_counts()","1063e8da":"class GRU(nn.Module):\n    def __init__(self):\n        super(GRU,self).__init__()\n        self.gru1 = nn.Linear(12,100)\n        self.bn1 = nn.BatchNorm1d(100)\n        self.gru2 = nn.Linear(100,50)\n        self.bn2 = nn.BatchNorm1d(50)\n        self.fc1 = nn.Linear(50,10)\n        self.bn3 = nn.BatchNorm1d(10)\n        self.fc2 = nn.Linear(10,2)\n        self.relu = nn.ReLU()\n        self.swish = nn.Hardswish()\n        self.flatten = nn.Flatten()\n    def forward(self,x):\n        x = self.bn1(self.gru1(x))\n        x = self.swish(x)\n        x = self.bn2(self.gru2(x))\n        x = self.swish(x)\n        x = self.swish(self.bn3(self.fc1(x)))\n        x = self.fc2(x)\n        return x","18d190e0":"model = GRU()\nmodel","ed3507b3":"n_epochs = 100\ntrain_min_loss = 0\ntrain_acc = torch.zeros(n_epochs)\ntrain_loss = torch.zeros(n_epochs)\nvalid_acc = torch.zeros(n_epochs)\nvalid_loss = torch.zeros(n_epochs)\nkf = KFold(n_splits=7,shuffle=True)\nfor fold , (train_idx,valid_idx) in enumerate(kf.split(train_set)):\n    print(f'Fold:{fold+1}')\n    train_sampler_kfold = SubsetRandomSampler(train_idx)\n    valid_sampler_kfold = SubsetRandomSampler(valid_idx)\n    train_loader = torch.utils.data.DataLoader(train_set,batch_size=16,\n                                               num_workers=0,sampler=train_sampler_kfold,drop_last=True)\n    valid_loader = torch.utils.data.DataLoader(train_set,batch_size=16,\n                                num_workers=0,sampler=valid_sampler_kfold,drop_last=True)\n    valid_max_acc = 0\n    train_acc = torch.zeros(n_epochs)\n    train_loss = torch.zeros(n_epochs)\n    valid_acc = torch.zeros(n_epochs)\n    valid_loss = torch.zeros(n_epochs)\n    model = GRU()\n    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(),lr=0.0003)\n    criterion = torch.nn.CrossEntropyLoss()\n    for e in range(0, n_epochs):\n        model.train()\n        for data, labels in tqdm(train_loader):\n            data, labels = data.to(device).float(), labels.to(device).long()\n\n            optimizer.zero_grad()\n            logits = model(data)\n            logits = logits\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss[e] += loss.item()\n\n            softmax = logits.softmax(dim=1)\n            argmax = softmax.argmax(1)\n            equals = argmax == labels.reshape(argmax.shape)\n\n            train_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu()\n\n\n        train_loss[e] \/= len(train_loader)\n        train_acc[e] \/= len(train_loader)\n        model.eval()\n        with torch.no_grad():\n            for data , labels in tqdm(valid_loader):\n                data, labels = data.to(device).float(), labels.to(device).long()\n                \n                logits = model(data)\n                loss = criterion(logits,labels)\n                \n                valid_loss[e] += loss.item()\n                \n                softmax = logits.softmax(dim=1)\n                argmax = softmax.argmax(1)\n                equals = argmax == labels.reshape(argmax.shape)\n                \n                valid_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu()\n                \n            valid_loss[e] \/= len(valid_loader)\n            valid_acc[e] \/= len(valid_loader)\n        print('Epoch: {} \\tTraining acc: {:.6f} \\tTraining Loss: {:.6f}'.format(\n            e+1, train_acc[e], train_loss[e]))\n        \n        print('Epoch: {} \\tValidation acc: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            e+1, valid_acc[e], valid_loss[e]))\n        \n        if valid_max_acc <= valid_acc[e]:\n            torch.save(model,f'Linear_model_{fold}.pt')\n            print('model save complete...')\n            valid_max_acc = valid_acc[e]\n            patience = 0\n        else:\n            patience += 1\n            print(f'Patience :{patience}')\n            if patience > 15:\n                patience += 1\n                print('We meet early Stopping so End Training...')\n                print(f'Best Validation Accuracy : {valid_max_acc}')\n                break\n            ","71b1b2b7":"pred_0 = []\npred_1 = []\npred_2 = []\npred_3 = []\npred_4 = []\npred_5 = []\npred_6 = []\nfor i in range(7):\n    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n    model = GRU()\n    model = torch.load(f'.\/Linear_model_{fold}.pt')\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        prediction = []\n        for data,label in tqdm(test_loader):\n            data,label = data.to(device).float(),label.to(device) \n            logits = model(data)\n            softmax = logits.softmax(1)\n            prediction.append(softmax.detach().cpu())\n            prediction = torch.cat(prediction)\n            if i == 0:\n                pred_0 = prediction\n            if i == 1:\n                pred_1 = prediction\n            if i == 2:\n                pred_2 = prediction\n            if i == 3:\n                pred_3 = prediction\n            if i == 4:\n                pred_4 = prediction\n            if i == 5:\n                pred_5 = prediction\n            if i == 6:\n                pred_6 = prediction\npred = np.argmax((pred_0+pred_1+pred_2+pred_3+pred_4+pred_5+pred_6)\/7,axis=1)","b42c3469":"print(f'Testset_Accuracy: {accuracy_score(label.detach().cpu().numpy(),pred)}')\nprint(f'Testset_f1-score: {f1_score(label.detach().cpu().numpy(),pred)}')\nprint(f'Testset_recall: {recall_score(label.detach().cpu().numpy(),pred)}')\nprint(f'Testset_precision: {precision_score(label.detach().cpu().numpy(),pred)}')","788caa5e":"# EDA","d1d03276":"### describe\uc640 boxplot \uacb0\uacfc platelets\uac00 \ub2e4\ub978 feature\ub4e4 \ubcf4\ub2e4 max\uc5d0\uc11c \ub108\ubb34 \ub192\uc740 \uac12\uc744 \ubcf4\uc774\uace0 \uc788\uc5b4\uc11c Scaler\ub97c \ud1b5\ud574\uc11c scalering \uc9c4\ud589","4650ba0f":"## column \uc124\uba85\n* age: \ub098\uc774\n* anaemia : \ube48\ud608\uc99d(0:\uc815\uc0c1,1:\ube48\ud608)\n* creatinline_phosphokinase : \ud06c\ub808\uc544\ud2f4\ud0a4\ub098\uc81c \uac80\uc0ac \uacb0\uacfc\n* diabetes : \ub2f9\ub1e8\ubcd1 (0:\uc815\uc0c1,1:\ub2f9\ub1e8)\n* ejection fraaction : \ubc15\ucd9c \uacc4\uc218(%)\n* high blood pressure : \uace0\ud608\uc555(0:\uc815\uc0c1, 1:\uace0\ud608\uc555)\n* platelets : \ud608\uc911 \ud06c\ub808\uc544\ud2f4 \ub808\ubca8 (mg\/dL)\n* serum sodium : \ud608\uc911 \ub098\ud2b8\ub968 \ub808\ubca8 (mEq\/L)\n* sex : \uc131\ubcc4 (0:\uc5ec\uc131, 1:\ub0a8\uc131)\n* smoking : \ud761\uc5f0 (0:\ube44\ud761\uc5f0, 1:\ud761\uc5f0)\n* time : \uad00\ucc30 \uae30\uac04(\uc77c)\n* Death_Event : \uc0ac\ub9dd \uc5ec\ubd80 (0:\uc0dd\uc874,1:\uc0ac\ub9dd)","8a079761":"# Simple Model"}}