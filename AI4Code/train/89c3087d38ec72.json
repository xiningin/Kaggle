{"cell_type":{"fc3256c6":"code","b3c8c473":"code","15db7c6d":"code","867281cd":"code","af17a933":"code","a8379c41":"code","8fdbe888":"code","47b58a7e":"code","c09dae90":"code","a8124d3d":"markdown","698207fc":"markdown","37c42be3":"markdown","c2e6a619":"markdown","f7927e5c":"markdown","509fc264":"markdown","34c6d674":"markdown","39cb579d":"markdown"},"source":{"fc3256c6":"# Familiar imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.compose import ColumnTransformer\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom lightgbm import LGBMRegressor\nfrom sklearn.neural_network import MLPRegressor","b3c8c473":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()","15db7c6d":"# Separate target from features\ny = train['target']\nfeatures = train.drop(['target'], axis=1)","867281cd":"def submitprediction(prediction):\n    # Save the predictions to a CSV file\n    output = pd.DataFrame({'Id': OH_X_test.index,\n                       'target': prediction})\n    output.to_csv('submission.csv', index=False)","af17a933":"def preprocess_data(data, encoder=1, minmax=False):\n    # List of categorical columns\n    object_cols = [col for col in data.columns if 'cat' in col]\n\n    if encoder == 1:\n        the_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n    elif encoder == 2:\n        the_encoder = OrdinalEncoder()\n    \n    cat_cols_data = pd.DataFrame(the_encoder.fit_transform(data[object_cols]))\n    \n    # encoding removed index; put it back\n    cat_cols_data.index = data.index\n\n    #Remove categorical columns \n    num_cols_data = data.drop(object_cols, axis=1)\n\n    # Add new columns to numerical features\n    encoder_data = pd.concat([num_cols_data, cat_cols_data], axis=1)\n    \n    if encoder == 2:\n        encoder_data.columns = data.columns\n    \n    if minmax:       \n        # List of continuous columns\n        cont_cols = [col for col in features.columns if 'cont' in col]\n\n        scaler = MinMaxScaler()\n        scaler.fit(encoder_data[cont_cols])\n        encoder_data[cont_cols]= pd.DataFrame(scaler.transform(encoder_data[cont_cols]))\n        \n    return encoder_data","a8379c41":"OH_X_train = preprocess_data(features,1,False)\nOH_X_test = preprocess_data(test,1,False)","8fdbe888":"X_train, X_valid, y_train, y_valid = train_test_split(OH_X_train, y, random_state=0)","47b58a7e":"lgbm_parameters = {\n    'metric': 'rmse', \n    'n_jobs': -1,\n    'n_estimators': 50000,\n    'reg_alpha': 10.924491968127692,\n    'reg_lambda': 17.396730654687218,\n    'colsample_bytree': 0.21497646795452627,\n    'subsample': 0.7582562557431147,\n    'learning_rate': 0.009985133666265425,\n    'max_depth': 18,\n    'num_leaves': 63,\n    'min_child_samples': 27,\n    'max_bin': 523,\n    'cat_l2': 0.025083670064082797\n}\n\n\nlgbm_model = LGBMRegressor(**lgbm_parameters)\nlgbm_model.fit(X_train, y_train, eval_set = ((X_valid,y_valid)),verbose = -1, early_stopping_rounds = 400)  \nlgbm_test_pred = lgbm_model.predict(OH_X_test) \n","c09dae90":"submitprediction(lgbm_test_pred)","a8124d3d":"# Step 2: Load the data\n\nNext, we'll load the training and test data.  \n\nWe set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)","698207fc":"In the code cell above, we set `squared=False` to get the root mean squared error (RMSE) on the validation data.\n\n# Step 5: Submit to the competition\n\nWe'll begin by using the trained model to generate predictions, which we'll save to a CSV file.","37c42be3":"Welcome to the **[30 Days of ML competition](https:\/\/www.kaggle.com\/c\/30-days-of-ml\/overview)**!  In this notebook, you'll learn how to make your first submission.\n\nBefore getting started, make your own editable copy of this notebook by clicking on the **Copy and Edit** button.\n\n# Step 1: Import helpful libraries\n\nWe begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https:\/\/www.kaggle.com\/learn\/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning)** course.","c2e6a619":"Next, we break off a validation set from the training data.","f7927e5c":"# Step 3: Prepare the data\n\nNext, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  \n\nIn the **[Categorical Variables lesson](https:\/\/www.kaggle.com\/alexisbcook\/categorical-variables)** in the Intermediate Machine Learning course, you learned several different ways to encode categorical variables in a dataset.  In this notebook, we'll use ordinal encoding and save our encoded features as new variables `X` and `X_test`.","509fc264":"# Step 4: Train a model\n\nNow that the data is prepared, the next step is to train a model.  \n","34c6d674":"The next code cell separates the target (which we assign to `y`) from the training features (which we assign to `features`).","39cb579d":"Once you have run the code cell above, follow the instructions below to submit to the competition:\n1. Begin by clicking on the **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work."}}