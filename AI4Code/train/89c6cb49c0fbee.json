{"cell_type":{"00c62736":"code","b63c0a68":"code","f3a92d20":"code","9746592f":"code","e5200540":"code","675d9589":"code","a011d195":"code","c1943386":"code","d114c6a6":"code","a2f9af96":"code","7ebdea46":"code","d439fc29":"code","5d07877d":"code","216ef43d":"code","b5fc4ad5":"code","4816e05f":"code","9a71cd2b":"code","a28e32d1":"code","470046d2":"code","3e4f7b7b":"code","5e18ec1a":"code","ee3429f2":"code","5f06aa62":"code","8e8942e6":"code","20b907d1":"code","85c4065c":"code","2a73a2c5":"code","867216ed":"code","4f5b69b9":"code","56be9acb":"code","f7c06e91":"code","e9226873":"code","1a573ab5":"code","e3f97b93":"code","179f4f45":"code","093c1f76":"code","abedda97":"code","4c40382e":"code","92166444":"code","ba19ae47":"code","1f44ae40":"code","cc1cd841":"code","fc196971":"code","0d166e6b":"code","7e99f2c7":"code","b63b0698":"code","d17b3cee":"code","08e93319":"code","41c1c456":"code","a7e2585a":"code","63f2a5eb":"code","ded350b8":"code","9d782680":"code","ef011564":"code","d77127c7":"code","26f9da97":"code","64d885a6":"code","4a9d7922":"code","a6d2bf8f":"code","07a4a26f":"code","34c2251d":"code","63e2a713":"code","0064f197":"code","95e86b3b":"code","f81c9820":"code","02b591c1":"code","81953dc9":"code","a3f585c9":"code","d3d97e0b":"code","15c26a2f":"code","029cfde7":"code","14698efc":"code","bafd6e25":"code","3f71e8c2":"code","df25c125":"code","2398ca20":"code","5e400f79":"code","110d1a1c":"code","790ac907":"code","86bd138a":"code","6841aef5":"code","29b4eb16":"code","72e0af91":"code","ddcd24e8":"code","cabefe7a":"code","df8cc614":"code","2121fb8c":"code","6f312603":"code","679336d7":"code","9cf4ada4":"code","1c423f76":"code","633c88e6":"code","4589c03a":"code","f73351ab":"code","fa432841":"code","047a0e08":"code","5d589791":"code","c1e872d4":"code","4ddd5f57":"code","e518f0c8":"code","290b5258":"code","ab66b7bf":"code","a229d56c":"code","19509c96":"code","05f20408":"code","74e5e7f3":"code","04d5af6e":"code","f19ed44a":"code","e9c35fd4":"code","af4e962a":"code","30b6c0d0":"markdown","32177149":"markdown","45e65b18":"markdown","bd05bd53":"markdown","08c5bdad":"markdown","78d342f7":"markdown","772f6772":"markdown","aeed3499":"markdown","745ec02e":"markdown","bf834ad0":"markdown","5c41a293":"markdown","6368065f":"markdown","f2cd29ad":"markdown","5a83c9c8":"markdown","ab778b63":"markdown","bf7fee22":"markdown","26fafb98":"markdown","e3ee8ea1":"markdown","c3768f5a":"markdown","34561865":"markdown","8aaa601e":"markdown","bab9b168":"markdown","a6a2b660":"markdown","9c3b01c7":"markdown","7619a8ba":"markdown","275cdd35":"markdown","da98e6f9":"markdown","df75fa17":"markdown","309c2998":"markdown","800a334a":"markdown","6abc9507":"markdown","6ff8dc57":"markdown","be815a9c":"markdown","7ce01291":"markdown","1f05dc37":"markdown","455a54f3":"markdown","f686b38f":"markdown","4ee8ae98":"markdown","9d9936b8":"markdown","b37af5ab":"markdown","5105b67f":"markdown","c2342a65":"markdown","114b9b62":"markdown","158779d1":"markdown","f6e69564":"markdown","8c6d6b79":"markdown","7fa6f92a":"markdown","eb90d736":"markdown","79754f18":"markdown","beb03d8e":"markdown","e8d5593f":"markdown","f26383ce":"markdown","0ad4d5fd":"markdown","dd8f6a02":"markdown","3b84b817":"markdown","dde968a9":"markdown","3db21040":"markdown","38299cfd":"markdown","32cea808":"markdown","a69d16a1":"markdown","93081641":"markdown","d8ae47ad":"markdown","3804a51b":"markdown","a917abab":"markdown","3f3b8871":"markdown","eb432c81":"markdown","7d0e2f96":"markdown","b1716baa":"markdown","6e50249e":"markdown","66101e33":"markdown","15f13996":"markdown","d990a701":"markdown","99c1c2c0":"markdown","16776fd4":"markdown","a79960be":"markdown","a8dc26cc":"markdown","e8425959":"markdown","47784469":"markdown","0279b7da":"markdown","2eb8f98d":"markdown","6d756f67":"markdown","6ed402c1":"markdown","d36efb3c":"markdown","62d5d3ff":"markdown","632ea5e3":"markdown","83d0403c":"markdown","5b8f404a":"markdown","7ac44bec":"markdown","57eb1e67":"markdown","9530469a":"markdown","4a6e272d":"markdown","a38d1616":"markdown","d9f0466a":"markdown","fbbd003d":"markdown","4c0d70d8":"markdown","0af3466a":"markdown","a05e6c27":"markdown","5759581b":"markdown","f8dc29a9":"markdown","bee42acc":"markdown","6dcc8722":"markdown","afa3315f":"markdown","9e6b7542":"markdown","c8336ade":"markdown","25f18fbe":"markdown","0f3a4b25":"markdown","b6e11d54":"markdown","0d3f65e3":"markdown","c2e8dcca":"markdown","51ed6170":"markdown","8809cb7a":"markdown","3e5f02ed":"markdown","061fce0e":"markdown","a051dc1a":"markdown","02de61de":"markdown","35022304":"markdown","6d85347e":"markdown","8abd714f":"markdown","4eef9325":"markdown","134e7f59":"markdown","1ae7547c":"markdown","de7e722e":"markdown","322f7459":"markdown","9e22c414":"markdown","b7a283d6":"markdown","08f8c021":"markdown","ac3424e7":"markdown","997229f1":"markdown","ededcede":"markdown","ed0b0768":"markdown","2cc7031e":"markdown","fdd5d2e6":"markdown","7a48feb2":"markdown","33a05bab":"markdown","fc21e196":"markdown","b35ac24b":"markdown","2e2c4c7c":"markdown","651b207d":"markdown","35850174":"markdown","4163cdf6":"markdown","5c64912b":"markdown"},"source":{"00c62736":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import *\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.impute import *\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\nfrom scipy.stats import shapiro\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import *\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport ipywidgets as widgets\nfrom sklearn.compose import make_column_selector, make_column_transformer\n\n\n\n\n# Importamos nuestro propio fichero de utilidades\nimport md_grupoa_practica1extra_ficheroutilidad as utils\n\n","b63c0a68":"seed = 27912","f3a92d20":"train_size = 0.7","9746592f":"#Funcion para realizar gr\u00e1ficos de caja\ndef plot_boxplot(data):\n    \n    var = data.columns\n    data = widgets.fixed(data)\n\n    widgets.interact(_plot_boxplot, data=data, var=var)\n\n#Funci\u00f3n auxiliar para gr\u00e1ficos de caja    \ndef _plot_boxplot(data, var):\n    return data[var].iplot(kind=\"box\")\n\n#Funci\u00f3n para calcular el porcentaje de ceros en variables que no deber\u00edan de tener ceros\ndef ZeroCount(Data, param):\n    for s in param:\n        aux=Data[s]\n        zeros=aux.astype(bool).sum(axis=0)\n        totalval=np.product(aux.shape)\n        result= (1-(zeros\/totalval)) * 100    \n        #print(result)\n        print(f\"El porcentaje de ceros en la variable {s} es del {result:.2f}% \")\n        \n\n#Funci\u00f3n para calcular el porcentaje de valores nulos en variables\ndef MissingValuesCount(Data, param):\n    Nan= Data.isnull().sum()\n    for s in param:\n        Aux =Data[s]\n        TotalVal= np.product(Aux.shape)\n        NanSum = Aux.isnull().sum()\n        result= (NanSum\/TotalVal)*100  \n        print(f\"El porcentaje de valores nulos en la variable {s} es del {result:.2f}% \")\n\n\n#Funci\u00f3n para eliminar outliers\ndef outlier_rejection(X, y, seed):\n    model = IsolationForest(random_state=seed)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]\n\n\n#Funci\u00f3n para realizar la evaluacion de bases de datos medicas\ndef EvaluationWClassRepo(model,\n             X_train, X_test,\n             y_train, y_test):\n    \n    clf = model.fit(X_train, y_train)\n    \n    y_pred = clf.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    d = dict(enumerate(yTitanic.cat.categories))\n    a=\"% s\" % d.get(0)\n    b=\"% s\" % d.get(1)\n    labels=[a,b]\n    print(classification_report(y_test, y_pred, target_names=labels))\n    \n    disp = plot_confusion_matrix(clf, X_test, y_test)\n    \n    accuracy= accuracy*100\n\n    disp.ax_.set_title(f\" Tasa de precisi\u00f3n = {accuracy:.2f}\"+\"%\")\n    \n","e5200540":"filepathWisconsin = \"..\/input\/breast-cancer-wisconsin-data\/data.csv\"\nindexWisconsin = \"id\"\ntargetWisconsin = \"diagnosis\"\ndataWisconsin = utils.load_data(filepathWisconsin, indexWisconsin, targetWisconsin)\ndataWisconsin.sample(5, random_state=seed)","675d9589":"dataWisconsin = dataWisconsin.drop(dataWisconsin.columns[31], axis = 'columns')\ndataWisconsin.sample(5, random_state=seed)","a011d195":"(XWisconsin, yWisconsin) = utils.divide_dataset(dataWisconsin, target=\"diagnosis\")","c1943386":"XWisconsin.sample(5, random_state=seed)","d114c6a6":"yWisconsin.sample(5, random_state=seed)","a2f9af96":"(XWisconsin_train, XWisconsin_test, yWisconsin_train, yWisconsin_test) = train_test_split(XWisconsin, yWisconsin,\n                                                      stratify=yWisconsin,\n                                                      random_state=seed,\n                                                      train_size=train_size)","7ebdea46":"XWisconsin_train.sample(5, random_state=seed)","d439fc29":"XWisconsin_test.sample(5, random_state=seed)","5d07877d":"yWisconsin_train.sample(5, random_state=seed)","216ef43d":"yWisconsin_test.sample(5, random_state=seed)","b5fc4ad5":"filepath = \"..\/input\/pima-indians-diabetes-database\/diabetes.csv\"\nindexDiabetes = None\ntargetDiabetes = \"Outcome\"\ndataDiabetes = utils.load_data(filepath, indexDiabetes, targetDiabetes)\ndataDiabetes.sample(5, random_state=seed)","4816e05f":"(XDiabetes, yDiabetes) = utils.divide_dataset(dataDiabetes, target=\"Outcome\")","9a71cd2b":"XDiabetes.sample(5, random_state=seed)","a28e32d1":"yDiabetes.sample(5, random_state=seed)","470046d2":"(XDiabetes_train, XDiabetes_test, yDiabetes_train, yDiabetes_test) = train_test_split(XDiabetes, yDiabetes,\n                                                      stratify=yDiabetes,\n                                                      random_state=seed,\n                                                      train_size=train_size)","3e4f7b7b":"XDiabetes_train.sample(5, random_state=seed)","5e18ec1a":"XDiabetes_test.sample(5, random_state=seed)","ee3429f2":"yDiabetes_train.sample(5, random_state=seed)","5f06aa62":"yDiabetes_test.sample(5, random_state=seed)","8e8942e6":"indexTitanic=\"PassengerId\"\ntargetTitanic=\"Survived\" \nfilepathTitanic=\"..\/input\/titanic\/train.csv\"\ndataTitanic = utils.load_data(filepathTitanic, indexTitanic, targetTitanic)\ndataTitanic.sample(5, random_state=seed)\n","20b907d1":"(XTitanic, yTitanic) = utils.divide_dataset(dataTitanic, target=\"Survived\")","85c4065c":"XTitanic.sample(5, random_state=seed)","2a73a2c5":"yTitanic.sample(5, random_state=seed)","867216ed":"(XTitanic_train, XTitanic_test, yTitanic_train, yTitanic_test) = train_test_split(XTitanic, yTitanic,\n                                                      stratify=yTitanic,\n                                                      random_state=seed,\n                                                      train_size=train_size)","4f5b69b9":"XTitanic_train.sample(5, random_state=seed)","56be9acb":"XTitanic_test.sample(5, random_state=seed)","f7c06e91":"yTitanic_train.sample(5, random_state=seed)","e9226873":"yTitanic_test.sample(5, random_state=seed)","1a573ab5":"dataWisconsin_test= utils.join_dataset(XWisconsin_test,yWisconsin_test)\ndataWisconsin_train= utils.join_dataset(XWisconsin_train,yWisconsin_train)\n\ndataDiabetes_test= utils.join_dataset(XDiabetes_test,yDiabetes_test)\ndataDiabetes_train= utils.join_dataset(XDiabetes_train,yDiabetes_train)\n\ndataTitanic_test= utils.join_dataset(XTitanic_test,yTitanic_test)\ndataTitanic_train= utils.join_dataset(XTitanic_train,yTitanic_train)","e3f97b93":"dataWisconsin_train.shape","179f4f45":"dataWisconsin_train.info(memory_usage=False)","093c1f76":"yWisconsin_train.cat.categories","abedda97":"utils.plot_histogram(dataWisconsin_train)","4c40382e":"utils.plot_barplot(dataWisconsin_train)\nB,M= yWisconsin_train.value_counts()\nprint('Numero de masas benigneas: ',B)\nprint('Numero de masas malignas : ',M)","92166444":"utils.plot_pairplot(dataWisconsin_train, target=\"diagnosis\")","ba19ae47":"mean_train = dataWisconsin_train.iloc[:,[0,1,2,3,4,5,6,7,8,9,30]]\nse_train = dataWisconsin_train.iloc[:,[10,11,12,13,14,15,16,17,18,19,30]]\nworst_train = dataWisconsin_train.iloc[:,[20,21,22,23,24,25,26,27,28,29,30]]\nutils.plot_pairplot(mean_train, target=\"diagnosis\")","1f44ae40":"utils.plot_pairplot(se_train, target=\"diagnosis\")","cc1cd841":"utils.plot_pairplot(worst_train, target=\"diagnosis\")","fc196971":"fig, ax = plt.subplots()\nsns.heatmap(mean_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","0d166e6b":"fig, ax = plt.subplots()\nsns.heatmap(se_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","7e99f2c7":"fig, ax = plt.subplots()\nsns.heatmap(worst_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","b63b0698":"utils.plot_boxplot(dataWisconsin_train)","d17b3cee":"dataDiabetes_train.shape","08e93319":"dataDiabetes_train.info(memory_usage=False)","41c1c456":"yDiabetes.cat.categories","a7e2585a":"utils.plot_histogram(dataDiabetes_train)","63f2a5eb":"param=[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n\nutils.ZeroCount(dataDiabetes_train,param)","ded350b8":"utils.plot_barplot(dataDiabetes_train)\nS,N= yDiabetes_train.value_counts()\nprint('Numero de Diabetes: ',S)\nprint('Numero de no Diabbetes: ',N)","9d782680":"utils.plot_pairplot(dataDiabetes_train, target=\"Outcome\")","ef011564":"fig, ax = plt.subplots()\nsns.heatmap(dataDiabetes_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","d77127c7":"utils.plot_boxplot(dataDiabetes_train)","26f9da97":"dataTitanic_train.shape","64d885a6":"dataTitanic_train.info(memory_usage=False)","4a9d7922":"yTitanic.cat.categories","a6d2bf8f":"utils.plot_histogram(dataTitanic_train)","07a4a26f":"dataTitanic_train.isnull().sum()","34c2251d":"param=[\"Age\",\"Embarked\",\"Cabin\"]\nutils.MissingValuesCount(dataTitanic_train,param)\n","63e2a713":"utils.plot_barplot(dataTitanic_train)\nD,S= yTitanic_train.value_counts()\nprint('Numero de supervivientes: ',S)\nprint('Numero de muertos: ',D)","0064f197":"utils.plot_pairplot(dataTitanic_train, target=\"Survived\")","95e86b3b":"fig, ax = plt.subplots()\nsns.heatmap(dataTitanic_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","f81c9820":"utils.plot_boxplot(dataTitanic_train)","02b591c1":"def _filter_categorical_data(data):\n    \"\"\"Filter the categorical data.\"\"\"\n    return data.select_dtypes(include=\"category\")\n\ndef _plot_barplot(data, var):\n    \"\"\"Plot univariate distribution of the categorical variable.\"\"\"\n    # Count the relative frequency of unique values\n    count = data[var].value_counts(normalize=True)\n\n    return count.iplot(kind=\"bar\")\n\ndef Pruebaplot_barplot(data):\n    \"\"\"Plot univariate distribution of the categorical data.\"\"\"\n    #categorical_data = _filter_categorical_data(data)\n\n    # Add a dropdown widget to select\n    # the categorical feature to plot\n    var = data.columns\n    data = widgets.fixed(data)\n\n    widgets.interact(_plot_barplot, data=data, var=var)\n","81953dc9":"#Prueba\n#Sex Farea\nNotcat = dataTitanic_train.iloc[:,[3,7,10]]\n#Pclass Sex Sibsp Parch\nCat = dataTitanic_train.iloc[:,[0,2,4,5,7,10]]\nPruebaplot_barplot(Cat)","a3f585c9":"#Estimador para eliminar outliers\nOutlierRejection = FunctionSampler(func=utils.outlier_rejection, kw_args={\"seed\":seed})","d3d97e0b":"preproceserWinsconsin = make_column_transformer(('drop',['perimeter_mean','area_mean','perimeter_se','area_se','perimeter_worst','area_worst','concave points_mean','compactness_mean',\n          'concave points_se','compactness_se','concave points_worst','compactness_worst']),\n                                                remainder='passthrough')\n","15c26a2f":"#Variables para sustituir ceros\nfeatures1 = 'Glucose|BloodPressure'\nfeatures2 = 'BMI'\n#Variables que no hay que tocar\nfeatures3 = 'DiabetesPedigreeFunction|Age'\n\n#Estimador para integuers\nreplace0Integer_Estimator = make_pipeline(SimpleImputer(strategy=\"most_frequent\",missing_values=0 ))\n#Estimador para reales\nreplace0Float_Estimator = make_pipeline(SimpleImputer(strategy=\"mean\",missing_values=0 ))\n\npreproceserDiabetes = make_column_transformer(\n    (replace0Integer_Estimator, make_column_selector(pattern= features1)),\n    (replace0Float_Estimator, make_column_selector(pattern= features2)),\n     ('passthrough', make_column_selector(pattern= features3)))\n\n","029cfde7":"#Primer pipeline categoricos: Imputas y encoder\n#Segundo pipeline para numerico categoricos si hay valores perdidos media\n#Las variables que no aportan al modelo directamente no se meten\n\n#Variables categoricas y con valores perdidos\nfeaturesCat='Sex| Embarked'\n#Variables numerico categoricos y variables con valores peridos\nfeaturesR0 = 'Age|SibSp|Parch|Fare|Pclass'\n\n\n\n#Pipeline para las variables categ\u00f3ricas puras que se encargara de imputar los valores nulos y realizar un encoder\nCat_Estimator = make_pipeline(SimpleImputer(strategy='most_frequent'),\n                                    OneHotEncoder(handle_unknown='ignore'))\n\n#Pipeline para num\u00e9ricos y num\u00e9ricos categ\u00f3ricos que se encarga de eliminar los valores nulos\nNum_Estimator = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n\n\npreproceserTitanic = make_column_transformer(\n    (Cat_Estimator, make_column_selector(pattern=featuresCat)),\n    (Num_Estimator, make_column_selector(pattern=featuresR0))\n    \n)\n\n","14698efc":"#Generaci\u00f3n del modelo zero_r\nzero_r_model = DummyClassifier(strategy=\"most_frequent\")\n#Generaci\u00f3n del modelo de \u00e1rbol de decision\ntree_model = DecisionTreeClassifier(random_state=seed)","bafd6e25":"discretizerUWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizerQWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizerKWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")\n","3f71e8c2":"\n#Modelo de \u00e1rbol de decis\u00f3n con eliminaci\u00f3n de variables predictoras muy relacionadas\npreprocess_treemodel_Winsconsin=make_pipeline(preproceserWinsconsin, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones y con eliminaci\u00f3n\n# de variable predictoras muy relacionadas\npreprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerUWinsconsin,tree_model)\npreprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerQWinsconsin,tree_model)\npreprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerKWinsconsin,tree_model)","df25c125":"\n#Modelo de \u00e1rbol de decis\u00f3n con eliminaci\u00f3n de variables predictoras muy relacionadas \n#eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_Winsconsin=make_pipeline(OutlierRejection, preproceserWinsconsin, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones y con eliminaci\u00f3n\n# de variable predictoras muy relacionadas y eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerUWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerQWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerKWinsconsin,tree_model)\n\n","2398ca20":"discretizerUDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")\ndiscretizerQDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"quantile\")\ndiscretizerKDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"kmeans\")","5e400f79":"#Modelo de \u00e1rbol de decisi\u00f3n con sustituci\u00f3n de ceros\npreprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones y sustituci\u00f3n de ceros\npreprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,discretizerUDiabetes,tree_model)\npreprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,discretizerQDiabetes,tree_model)\npreprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,discretizerKDiabetes,tree_model)\n","110d1a1c":"\n#Modelo de \u00e1rbol de decisi\u00f3n con sustituci\u00f3n de ceros y eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones, sustituci\u00f3n de ceros y eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerUDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerQDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerKDiabetes,tree_model)","790ac907":"discretizerUTitanic = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizerQTitanic = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizerKTitanic = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","86bd138a":"#El preprocesamiento al que nos referiremos a continuaci\u00f3n consistar\u00e1 de dos partes, una en la eliminaci\u00f3n conversi\u00f3n de \n#categ\u00f3ricas y la sustituci\u00f3n de sus valores an\u00f3malos por un 0 y la otra en la sutituci\u00f3n de los valores an\u00f3malos del resto\n#de variables y la estandarizaci\u00f3n de estas variables\n\n#Modelo de \u00e1rbol de decisi\u00f3n con preprocesamiento\npreprocess_treemodel_Titanic = make_pipeline(preproceserTitanic, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con preprocesamiento y con tres tipos de discretizaciones\npreprocess_treemodel_discretizeU_Titanic=make_pipeline(preproceserTitanic,discretizerUTitanic,tree_model)\npreprocess_treemodel_discretizeQ_Titanic=make_pipeline(preproceserTitanic,discretizerQTitanic,tree_model)\npreprocess_treemodel_discretizeK_Titanic=make_pipeline(preproceserTitanic,discretizerKTitanic,tree_model)","6841aef5":"\n#Modelo de \u00e1rbol de decisi\u00f3n con preprocesamiento y eliminaci\u00f3nde outliers\nextra_preprocess_treemodel_Titanic=make_pipeline(preproceserTitanic,OutlierRejection, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con preprocesamiento, con tres tipos de discretizaciones \n#y eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_discretizeU_Titanic=make_pipeline(preproceserTitanic,OutlierRejection,discretizerUDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeQ_Titanic=make_pipeline(preproceserTitanic,OutlierRejection,discretizerQDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeK_Titanic=make_pipeline(preproceserTitanic,OutlierRejection,discretizerKDiabetes,tree_model)","29b4eb16":"utils.EvaluationWClassRepo(zero_r_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","72e0af91":"utils.EvaluationWClassRepo(tree_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","ddcd24e8":"utils.EvaluationWClassRepo(preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","cabefe7a":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","df8cc614":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","2121fb8c":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)\n","6f312603":"EvaluationWClassRepo(extra_preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","679336d7":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","9cf4ada4":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","1c423f76":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","633c88e6":"utils.EvaluationWClassRepo(zero_r_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","4589c03a":"utils.EvaluationWClassRepo(tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","f73351ab":"utils.EvaluationWClassRepo(preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","fa432841":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","047a0e08":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","5d589791":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","c1e872d4":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","4ddd5f57":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","e518f0c8":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","290b5258":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","ab66b7bf":"utils.EvaluationWClassRepo(zero_r_model,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","a229d56c":"utils.EvaluationWClassRepo(preprocess_treemodel_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","19509c96":"\nutils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","05f20408":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","74e5e7f3":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","04d5af6e":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","f19ed44a":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","e9c35fd4":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","af4e962a":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","30b6c0d0":"A continuaci\u00f3n vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XDiabetes_train y yDiabetes_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XDiabetes_test y yDiabetes_test) (30% del subconjunto incial)\n\nEsta divisi\u00f3n la realizaremos con el m\u00e9todo train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la pr\u00e1ctica).","32177149":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlaci\u00f3n:","45e65b18":"La base de datos Breast cancer Winscosin es el resultado del an\u00e1lisis de una imagen digitalizada de un aspirado con aguja fina (FNA) de una masa mamaria. El an\u00e1lisis se realiza teniendo en cuenta las distitnas variables que maneja la base de datos las cuales son:\n\n1. ID number: Es un n\u00famero creciente que servir\u00e1 de identificador para cada uno de los casos de la base de datos.\n2. Diagnosis: Variable que guardar\u00e1 el resultado del an\u00e1lisis de la masa mamaria. Si tiene el valor B en caso de que la masa sea benignea y M en caso de que la masa sea maligna. Esta variable ser\u00e1 la que tomemos como variable predictora.\n3. radius: Variable real que guardar\u00e1 la media de las distancias desde el centro hasta los puntos del per\u00edmetro de la masa.\n4. texture: Variable real que guardar\u00e1 la desviaci\u00f3n est\u00e1ndar de los valores de la escala de grises de la masa.\n5. perimeter: Variable real que guardar\u00e1 el per\u00edmetro de la masa.\n6. area: Variable real que guardar\u00e1 el per\u00edmetro de la masa.\n7. smoothness: Variable real que guardar\u00e1 la variaci\u00f3n local en longitudes de radio de la masa.\n8. compactness: Variable real resultante de la operaci\u00f3n perimeter^2 \/ area - 1.0 (los valores de la variables son los de la masa)\n9. concavity: Variable real que representa la severidad de las porciones c\u00f3ncavas del contorno de la masa.\n10. concave points: Variable real que represente el numero de porciones c\u00f3ncavas  del controno de la masa.\n11. symmetry: Variable real que representa la simetria de la masa.\n12. fractal dimension (\"coastline approximation\" - 1): Variable real que representa la aproximaci\u00f3n de la linea costera de la masa\n\nLas dos primeras variables son variables de informaci\u00f3n y el resto son variables que se computan para cada caso de masa mamaria analizada. Para estas \u00faltimas variables habr\u00e1 tres tipos para cada uno de los casos:\n\n    -Variable_mean: Guardar\u00e1 el valor medio de la variable.\n    -Variable_se: Guardar\u00e1 el error est\u00e1ndar de la variable.\n    -Variable_worst: Guardar\u00e1 el peor valor (media de los tres valores m\u00e1s grandes) de la variable.\n\nComo conclusion la base de datos se utilizar\u00e1 en nuestro estudio para generar un modelo que prediga seg\u00fan unos valores si la masa mamaria analiza es B (Benigna) o M (Maligna)\n","bd05bd53":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de \u00e1rbol de decisi\u00f3n. Como hemos mencionado en el an\u00e1lisis exploratorio utilizaremos 2 contenedores y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar.","08c5bdad":"#\u00a01. Preliminares","78d342f7":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluaci\u00f3n de modelos son las siguientes:\n* El mejor modelo que hemos obtenido ha sido el modelo del \u00e1rbol de decisi\u00f3n sin discretizaci\u00f3n y con el preprocesamiento b\u00e1sico con una tasa de verdaderos positivos de 0.60.\n* En general la tasa de veraderos positivos que hemos obtenidos de todos los modelos es bastante baja, siendo la m\u00e1s alta 0.6.\n* La eliminaci\u00f3n de outliers ha sobreajustado casi todos los modelos dando en la mayor\u00eda peores resultados para la tasa de verdaderos positivos, expecto para el modelo  de \u00e1rbol de decisi\u00f3n con discretizaci\u00f3n basado en K medians cuya tasas de verdaderos positivos es 0.52 cuando se eliminan outliers y 0.43 sin la eliminaci\u00f3n de outliers.\n* En el caso de la discretizaci\u00f3n, lo m\u00e1s recomendable es no realizar una discretizaci\u00f3n a este conjunto de datos si usamos como modelo un \u00e1rbol de decisi\u00f3n, sin embargo la discretizaci\u00f3n que mejores resultados ha dado sin eliminaci\u00f3n de outliers es la de igual frecuencia (con una tasa de verdaderos positivos de 0.58) y con eliminaci\u00f3n de outliers es la basada en K medians (con una tasa de verdaderos positivos de 0.52). No obstante; est\u00e1n ambas por debajo del modelo del \u00e1rbol de decisi\u00f3n sin discretizar con o sin eliminaci\u00f3n de outliers.\n","772f6772":"> ### *Conclusiones*","aeed3499":"Como hemos concluido en el an\u00e1lisis exploratorio, de los dos conjuntos de variables perimeter_mean-area_mean-radio mean y concavepoints_mean-compactness_mean-concavity_mean est\u00e1n muy relacionadas las variables dentro del conjunto y un conjunto de variables con el otro, por lo tanto para el preprocesamiento, vamos a generar un estimador que elimine todos los tipos (mean,se y worst) de dos variables de cada uno de los conjuntos de variables del conjunto de datos, para ello hemos elegido arbitrariamente que las variables que eliminaremos del primer conjunto de datos ser\u00e1n area y perimeter y del segundo ser\u00e1n concave y compactness.\nPara la generaci\u00f3n del estimador vamos a utilizar el m\u00e9todo make_column_transformer de la libreria sklearn.compose y vamos a indicar como par\u00e1metro tranformador 'drop' para que elimine la lista de variables de las que hemos hablado con anterior y hemos indicado que para el resto de variables simplemente no las toque igualando el par\u00e1metro remainder como 'passthrough'.","745ec02e":"Continuaremos con el an\u00e1lisis exploratorio realizando un diagrama de puntos:","bf834ad0":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","5c41a293":"## *3.3 Titanic*","6368065f":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Despu\u00e9s mostramos una muestra (sample) de los subconjuntos creados.","f2cd29ad":"## *4.1 Breast cancer Winsconsin*","5a83c9c8":"Lo primero que vamos a hacer es cargar la base de datos utilizando Outcome como variable objetivo y como la base de datos carece de una variable que se pueda utilizar como \u00edndice, no utilizaremos ninguna variable (None) como variable indice ya que en ese caso, el m\u00e9todo load_data gener\u00e1 un indice de forma autom\u00e1tica.","ab778b63":"> ### *Modelos sin preprocesamiento*","bf7fee22":"## *5.1 Breast cancer Winsconsin*","26fafb98":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Despu\u00e9s mostramos una muestra (sample) de los subconjuntos creados.","e3ee8ea1":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluaci\u00f3n de modelos son las siguientes:\n* El mejor modelo que hemos obtenido ha sido el modelo del \u00e1rbol de decisi\u00f3n con discretizaci\u00f3n con estrategia de igual anchura y con eliminaci\u00f3n de outliers con un valor de f1 de 0.71.\n* En general el valor f1 obtenido ha sido muy dispar, teniendo la mayoria de modelos resultados muy normales, pero estando presentes otros modelos con valores muy malos como el modelo de \u00e1rbol de decisi\u00f3n con discretizaci\u00f3n en igual frecuencia y eliminaci\u00f3n de outliers que ha tenido un valor de f1 de 0.38 mientras que el modelo con mejor valor ha sido el modelo del \u00e1rbol de decisi\u00f3n con discretizaci\u00f3n con estregia de igual anchura y con eliminaci\u00f3n de outliers con un valor muy bueno de f1 0.71.\n* La eliminaci\u00f3n de outliers ha sobreajustado casi todos los modelos dando en la mayor\u00eda peores resultados para el valor de f1, expecto para el modelo de \u00e1rbol de decisi\u00f3n con discretizaci\u00f3n con estregia de igual anchura y con eliminaci\u00f3n de outliers con un valor muy bueno de f1 0.71.\n* En el caso de la discretizaci\u00f3n, lo m\u00e1s recomendable es realizar una discretizaci\u00f3n con estrategia basada en k-means si no realizamos eliminaci\u00f3n de outliers pues hemos obtenido con ese modelo un f1 con valor 0.69, mientras que si realizamos outliers la mejor discretizaci\u00f3n es la de igual anchura pues ha obtenido un valor de f1 de 0.71.","c3768f5a":"Debido a que los datos originales que estamos manjeando poseen variables categ\u00f3ricas, no podemos evaluar el modelo \u00e1rbol de decisi\u00f3n para nuestros datos sin aplcarle anteriormente un preprocesamiento. Por eso pasamos directamente a evaluar los modelos de \u00e1rbol de decisi\u00f3n aplic\u00e1ndoles el preprocesamiento.","34561865":"A continuaci\u00f3n mostramos los distitnos valores que pueden tomar nuestras variables categ\u00f3ricas con el m\u00e9todo .categories:","8aaa601e":"A continuaci\u00f3n vamos a obtener el porcentaje de ceros que tienen estas variables con el m\u00e9todo del fichero de utilidad ZeroCount y as\u00ed comproboremos la cantida de ruido que tienen estas variables y si vale la pena tener estas variables en cuenta para el preprocesamiento:","bab9b168":"Teniendo en cuenta que la base de datos Titanic surge de un problema estad\u00edstico normal y corriente basado en el n\u00famero de supervivientes de una tragedia, en este caso la tragedia del hundimiento del titanic, la m\u00e9trica que utilizaremos para evaluar la calidad de los modelos generados podr\u00eda ser o recall o precission ya que accuracy funciona m\u00e1l con problemas desbalanceados y este lo est\u00e1. As\u00ed que si tenemos que elegir alguna de las dos m\u00e9tricas, podemos optar por utilizar como m\u00e9trica la puntuaci\u00f3n F1 que combina las m\u00e9tricas de recall y preccision.\n\nFinalmente, al utilizarse la base de datos para predecir si un viajero sobrevivi\u00f3 al Titanic dependiendo de ciertas caracter\u00edsitcas del viaje de este, consideraremos que dicha predicci\u00f3n es positiva si la variable objetivo Survived tiene el valor 1.","a6a2b660":"Teniendo en cuenta que la base de datos Breast cancer winsconsin surge de un problema m\u00e9dico y por ello, la m\u00e9trica normalmente utilizada para estos problemas y la que tenemos que emplear para la evaluaci\u00f3n es el recall o tasa de verdaderos positivos. Dicha tasa la podemos ver en la estructura classsification report que generar\u00e1 el m\u00e9todo EvalutationWClassRepo. \nFinalmente, al utilizarse la base de datos para predecir el resultado del an\u00e1lisis de una masa mamaria, consideraremos que dicho an\u00e1lisis da positivo si el diagn\u00f3stico es maligno,es decir; la tasa de veraderos positivos se observar\u00e1 teniendo en cuenta que un positivo quiere decir que la masa mamaria es maligna.","9c3b01c7":"> ### *Modelos con el preprocesamiento extra*","7619a8ba":"Las conclusiones que podemos sacar de estos gr\u00e1ficos esque ciertas variables tienen demasiados valores alejados de la mediana, estas variables son Sex, SibSp, Parch y Fare, siendo los diagramas de Fare y SibSp donde m\u00e1s se notas. Por ello consideramos que est\u00e1 justificado el uso de un estimador que elimine los valores outliers durante el modelado del problema.","275cdd35":"A continuaci\u00f3n le aplicaremos al modelo de \u00e1rbol de decisi\u00f3n el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al \u00e1rbol de decisi\u00f3n discretizado con 2 contenedores y todas las posibles estrategias de discretizaci\u00f3n.","da98e6f9":"#\u00a0Pr\u00e1ctica 1: An\u00e1lisis exploratorio de datos, preprocesamiento y validaci\u00f3n de modelos de clasificaci\u00f3n\n\n###\u00a0Miner\u00eda de Datos: Curso acad\u00e9mico 2020-2021\n\n### Integrantes:\n\n* Gonzalo Pinto Perez\n* Yeremi Martin Huaman Torres","df75fa17":"### **Visualizaci\u00f3n de las variables**","309c2998":"# 6. Evaluacion de modelos","800a334a":"### **Visualizaci\u00f3n de las variables**","6abc9507":"## *1.1 Variables globales*","6ff8dc57":"## *6.3 Titanic*","be815a9c":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","7ce01291":"La conclusi\u00f3n que podemos sacar esque el porcentaje de ruido que tienen variables como BloodPresure, Glucose o BMI es aceptable, mientras que el de las variables Insulin y SkinThickness (48.60% y 29.24% de ruido respectivamente) es tan alto que lo m\u00e1s recomendable esque no las tengamos en cuenta para generar nuestro modelos.","1f05dc37":"## *4.3 Titanic*","455a54f3":"### **Visualizaci\u00f3n de las variables**","f686b38f":"Podemos observar que el conjunto de datos tiene 398 casos y 31 variables,siendo estas quizas demasiadas para que se reprensenten con claridad en algunos de los gr\u00e1ficos que vamos a utilizar","4ee8ae98":"En esta parte aplicaremos el preprocesamiento en base a las modificaciones que hemos visto que necesita el conjunto de datos durante el an\u00e1lisis exploratorio.","9d9936b8":"A continuaci\u00f3n mostramos el tipo de cada una de las variables del conjunto de datos con el m\u00e9todo .info:","b37af5ab":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluaci\u00f3n de modelos son las siguientes:\n* Los dos mejores modelos son el modelo del \u00e1rbol de decisi\u00f3n con el preprocesamiento b\u00e1sico y sin discretizar y el modelo del \u00e1rbol de decisi\u00f3n con el preprocesamiento b\u00e1sico y con una discretizaci\u00f3n de igual frecuencia. Ambos tienen una tasa de verdaderos positivos del 0.94.\n* Si tenemos en cuenta la tasa de verdaderos positivos media (La media de la tasa de verdaderos positivos para positivo benigneo y positivo maligno) el mejor modelo ser\u00eda el \u00e1rbol de decisi\u00f3n con el preprocesamiento b\u00e1sico y sin discretizar con un tasa de verdaderos positivos media del 0.94.\n* En general hemos obtenido una tasa de verdaderos positivos alta para todos nuestros modelos (el m\u00e1s bajo sin contar el modelo ZeroR ha sido 0.64).\n* La eliminaci\u00f3n de outliers solo ha sobreajustado el modelo para este conjunto de datos ya que todos los modelos que han eliminado outliers han tenido peores resultados que su contraparte sin eliminaci\u00f3n de outliers.\n* La mejor discretizaci\u00f3n para el modelo de \u00e1rboles de decisi\u00f3n es la de igual frecuencia, eliminado o no outliers.","5105b67f":"### **Descripci\u00f3n del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables","c2342a65":"Primero mostramos el n\u00famero de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","114b9b62":"Seg\u00fan este diagrama podemos observar que en el conjunto de datos de entrenamiento hay m\u00e1s casos en los que el viajero no sobrevivi\u00f3 (el valor de la variable Survived ser\u00eda 0) que casos en los que el viajero sobrevivi\u00f3 (el valor de la variable Survived ser\u00eda 1) por lo que podemos indicar que el problema est\u00e1 desbalanceado.","158779d1":"## *1.2 Funciones auxiliares*","f6e69564":"> ### *Modelos sin preprocesamiento*","8c6d6b79":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","7fa6f92a":"Podemos observar que survived se trata de una variable num\u00e9rica categ\u00f3rica que podr\u00e1 tomar los valores 0 o 1 en caso negativo o afirmativo de que el pasajero sobreviviese al viaje respectivamente.","eb90d736":"# 4. Preprocesamiento de datos","79754f18":"Fijamos el tama\u00f1o del conjunto de entrenamiento:","beb03d8e":"Donde podemos observar que de las 9 variables, todas son de tipo entero excepto tres; BMI y DiabetesPedigreeFunction que son de tipo real (dato que tendremos que tener en cuenta si las modificamos en el preprocesamiento), y Outcome que es de tipo categ\u00f3rico y es la variable que tomaremos como variable objetivo.","e8d5593f":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero a\u00f1adi\u00e9ndoles un estimador que elimina outliers. Este estimador lo hemos a\u00f1adido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminaci\u00f3n de outliers puede generar sobreajuste y empeorar los resultados de la evaluaci\u00f3n; por lo tanto vamos a evaluar tanto las pipelines sin eliminaci\u00f3n de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","f26383ce":"## *3.2 Pima Indians diabetes*","0ad4d5fd":"> ### *Modelos sin preprocesamiento*","dd8f6a02":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlaci\u00f3n:","3b84b817":"Para acabar el an\u00e1lisis exploratorio vamos a realizar un diagrama de caja para comprobar si podr\u00edan haber outliers en las variables del conjunto de datos:","dde968a9":"A continuaci\u00f3n mostramos el tipo de cada una de las variables del conjunto de datos con el m\u00e9todo .info:","3db21040":"A continuacion vamos a realizar un diagrama de barras:","38299cfd":"Se nos muestra que las variables con valores nulos son Age, Embarked y Cabin. Los valores nulos de las variables Age y Embarked los arreglaremos durante el preprocesamiento ya que al ser variables categ\u00f3ricas no num\u00e9ricas las tendremos que convertir a variables categ\u00f3ricas num\u00e9ricas y los valores nulos asumiremos que es un error de quien haya redactado la base de datos y quer\u00eda poner el valor m\u00e1s frecuente. Los valores de la variable Cabin son distintos, ya que al tratarse de una variable de tipo string no la ibamos a tener en cuenta ya a la hora de generar los modelos. Sin embargo vamos a recurrir al m\u00e9todo MissignValuesCount para comprobar si el porcentaje de valores nulos (ruido) es tan grande que no deber\u00edamos de tener en cuenta estas variables durante el preprocesamiento.","32cea808":"Para acabar el an\u00e1lisis exploratorio vamos a realizar un diagrama de caja para comprobar si podr\u00edan haber outliers en las variables del conjunto de datos:","a69d16a1":"A continuaci\u00f3n vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XWisconsin_train y yWisconsin_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XWisconsin_test y yWisconsin_test) (30% del subconjunto incial)\n\nEsta divisi\u00f3n la realizaremos con el m\u00e9todo train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la pr\u00e1ctica).","93081641":"Podemos observar que el n\u00famero de casos es 623 y el n\u00famero de variables es 11.","d8ae47ad":"Podemos observar que en nuestro conjunto de datos hay m\u00e1s casos en los que la variable objetivo Outcome indicaba que el paciente tenia diabetes (350) que en los que la variable Outcome indicaba que el paciente no tenia diabaetes (187). Al haber tanta diferencia entre el n\u00famero de los casos en los que el paciente tiene o no diabetes podemos decir que el problema est\u00e1 desbalanceado.","3804a51b":"A continuaci\u00f3n le aplicaremos al modelo de \u00e1rbol de decisi\u00f3n el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al \u00e1rbol de decisi\u00f3n discretizado con 3 contenedores y todas las posibles estrategias de discretizaci\u00f3n.","a917abab":"## *5.2 Pima Indians diabetes*","3f3b8871":"### **Descripci\u00f3n del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables","eb432c81":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","7d0e2f96":"Teniendo en cuenta que la base de datos Pima Indians diabetes surge de un problema m\u00e9dico y por ello, la m\u00e9trica normalmente utilizada para estos problemas y la que tenemos que emplear para la evaluaci\u00f3n es el recall o tasa de verdaderos positivos. Dicha tasa la podemos ver en la estructura classsification report que generar\u00e1 el m\u00e9todo EvalutationWClassRepo. Finalmente, al utilizarse la base de datos para predecir de forma diagn\u00f3stica si un paciente tiene diabete o no, consideraremos que dicho an\u00e1lisis da positivo si la variable objetivo Outcome tiene el valor 1, es decir; la tasa de verdaderos positivos se observar\u00e1 teniendo en cuenta que un positivo quiere decir que el paciente tiene diabetes.","b1716baa":"> ### *Modelos con el preprocesamiento extra*","6e50249e":"A continuaci\u00f3n vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XTitanic_train y yTitanic_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XTitanic_test y yTitanic_test) (30% del subconjunto incial)\n\nEsta divisi\u00f3n la realizaremos con el m\u00e9todo train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la pr\u00e1ctica).","66101e33":"Las conclusiones que podemos obtener del siguiente histograma son las siguientes:\n* A pesar de tener 11 variables, solo 5 aparecen en nuestro histograma, por lo tanto debemos de analizar porque las otras 6 no aparecen. Name, ticket y Cabin no aparecen debido a que son variables de tipo string y sus valores no se pueden representar en este tipo de gr\u00e1ficos, adem\u00e1s de que consideramos que sus valores no aportan mucho a este tipo de problemas al ser variables de tipo string (y en el caso de Name y ticket tambi\u00e9n valores \u00fanicos) y por lo tanto no los tendremos en cuenta para desarrollar los estimadores para generar los modelos de esta base de datos. Sex y embarked no aparecen al ser variables categ\u00f3ricas no num\u00e9ricas, por lo tanto para poder ser tenidas en cuenta a la hora de generar nuestros modelos primero tenemos que modificarlas para convertirlas en variables categ\u00f3ricas num\u00e9ricas en el preprocesamiento.Finalmente Surivived no aparece al ser la variable objetivo.\n* De las variables que representadas solo Age posee un distribuci\u00f3n normal con tendecia central en forma de campana de gauss, mientras que Pclass posee una distribuci\u00f3n con tendencia exponencial creciente y el resto de variables (Sibsp, Parch y Fare) poseen una distribuci\u00f3n con tendencia exponencial decreciente.\n* Al ver simplemente el histograma podemos darnos cuenta de indicios de outliers en la variable Fare,sin embargo, habr\u00e1 que esperar a observar los diagramas de cajas para observar si el resto de variables poseen outliers.\n* No hemos observado que haya variables con valores no v\u00e1lidos durante la observaci\u00f3n del histograma.","15f13996":"## *3.1 Breast cancer Winsconsin*","d990a701":"Los modelos que evaluaremos ser\u00e1n el modelo zero_r y el modelo de arbol de decision que usar\u00e1 la semilla que estamos durante todo el problema.","99c1c2c0":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","16776fd4":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Despu\u00e9s mostramos una muestra (sample) de los subconjuntos creados.","a79960be":"Como hemos indicado en el preprocesamiento de esta base de datos lo que tendremos que hacer ser\u00e1 sustituir los valores cero de las variables Glucose, BloodPressure y BMI, eliminar una variable del par de variables Age y Pregnancies por su alto coeficiente de correlaci\u00f3n, eliminaci\u00f3n de las variables Insulin y SkinThickness por la cantidad de valores perdidos que tienen y dejar el resto de variables igual.\n\nPara la sustituci\u00f3n de valores cero de las variables Glucose, BloodPressure y BMI utilizaremos el estimador SimpleImputer pero teniendo en cuenta que BMI se trata de una variable real y que las otras dos se tratan de variables enteras, tendremos que generar un estimador para cada tipo de variable modificando la estrategia de b\u00fasqueda, pues aunque lo normal es utilizar la media para la sustituci\u00f3n de valores ruidosos, al ser Glucose y BloodPresure enteros, no se puede introducir de repente un valor con decimales (la media podr\u00eda tener o no decimales) por ello el simpleImputer que afectar\u00e1 a las variables enteras utilizar\u00e1 la estrategia \"most_frequent\" sustituyendo los ceros por el valor m\u00e1s frequente que claramente ser\u00e1 de tipo entero y sin decimales. Ambos SimpleImputer (de enteros y decimales) los \"combinaremos\" con un m\u00e9todo make_column_transformer donde le pasaremos a cada estimador las variables correspondientes asign\u00e1ndolas al par\u00e1metro pattern del make_column_selector. Para dejar al resto de variables igual simplemente declararemos las variables que no se deben de tocar en un par\u00e1metro aparte y se introducir\u00e1n en el make_column_transformer pero en vez de pasarle un estimador como par\u00e1metro introduciremos el valor 'passthrough' que simplemente dejar\u00e1 igual a las variables. Finalmente si queremos eliminar las variables que hemos acordado en el an\u00e1lisis exploratorio bastar\u00e1 con no incluirlas en el make_colum_transformer.","a8dc26cc":"## *2.3 Titanic*","e8425959":"#\u00a02. Acceso y almacenamiento de datos","47784469":"Al observar la matriz nos podemos dar cuenta de que el par de variables Glucose-Age y Glucose-Insulin est\u00e1n relacionados pero no lo suficiente para eliminar una de estas variables en el preproceasmiento; no obsatne, el par de variables Age-Pregnancies es el m\u00e1s relacionado del conjunto de datos y quizas deberiamos de eliminar una de estas variables durante el preprocesamiento.","0279b7da":"Las conclusiones que podemos sacar de esta matriz esque no s\u00f3lo no hay ning\u00fan par de variables muy relacionados entre s\u00ed, sino que aunque hay variables que est\u00e1n muy poco relacionadas entre si (con valores negativos en la matriz de correlaci\u00f3n) tampoco hay ning\u00fan par de variables que supere el -0.5 como coecifiente de correlaci\u00f3n. Por lo tanto podemos decir que ninguna de las variables del conjunto de datos es prescindible para realizar el posterior modelado del problema","2eb8f98d":"Podemos observar que diagnosis es una variable categ\u00f3rica que puede tomar el valor B en caso de que el resultado del diagnosis de la masa del paciente sea benigna y M en casao de que el resultado del diagnosis de la masa del paciente sea maligno.","6d756f67":"El proceso de evaluaci\u00f3n de modelos lo realizaremos siguiendo los siguientes paso para cada uno de los subapartados siguientes (uno para cada uno de las bases de datos que hemos tratado):\n1. Mencion de la m\u00e9trica que utilizaremos para elegir el mejor modelo de los evaluados en base a la base de datos que utilizaremos\n2. Mostrar el resultado de la evaluaci\u00f3n sobre el conjunto de datos corresponiente de los dos modelos sin inclusi\u00f3n de estimadores extra ,el resultado de la evaluaci\u00f3n sobre el conjunto de datos correspondiente de las 4 pipelines resultado de aplicarle al \u00e1rbol de decisi\u00f3n la discretizaci\u00f3n y el preprocesamiento y el resultado de la evaluaci\u00f3n sobre el conjunto de datos correspondiente de 4 pipelines resultado de a\u00f1adirle a las cuatro pipelines anteriores un estimador de eliminaci\u00f3n de outliers. La evaluci\u00f3n se realizar\u00e1 utilizando la funci\u00f3n del fichero de utilidad utils EvaluationWClassRepo\n3. Redacci\u00f3n de una peque\u00f1a conclusi\u00f3n que haga referencia al mejor resultado obtenido y las consecuencias supone dicho resultado.","6ed402c1":"> ### *Conclusiones*","d36efb3c":"## *5.3 Titanic*","62d5d3ff":"Podemos observar que este gr\u00e1fico representa las variables que antes no se nos han mostrado, y en principio no vemos ning\u00fan par de variables muy relacionados entre s\u00ed. Lo que si que vemos con m\u00e1s claridad esque si realizamos una discretizaci\u00f3n lo mejor ser\u00e1 utilizar una estrategia kmeans y con 2 contenedores ya que los casos con el mismo valor en la variable objetivo survived se encuentran m\u00e1s agrupados y m\u00e1s separados de los casos con distinto valor en la variable objetivo.","632ea5e3":"Las conclusiones que podemos sacar de estos diagramas de caja esque se indentifican la presencia de outliers en distintas variables (se puede ver claramente por ejemplo en los diagramas de caja de las variables radius_se y area_worst),por lo que se probar\u00e1 a utilizar un estimador que elimine los outliers para comprobar si mejora los resultados de los distintos modelos.","83d0403c":"Continuaremos con el an\u00e1lisis exploratorio realizando un diagrama de puntos:","5b8f404a":"Lo \u00fanico que podemos observar es lo que hemos mencionado al principio de este an\u00e1lisis, al ser 30 variables predictoras, algunas representaciones gr\u00e1ficas pueden no verse con claridad y este es un ejemplo. Por ello lo que vamos a hacer es dividir el diagrama de puntos entre tres, uno para cada uno de los tres tipos que pueden tener las variables predictoras: mean, se y worst.","7ac44bec":"> ### *Modelos con el preprocesamiento extra*","57eb1e67":"Cargamos la base de datos Breast cancer wisconsin  tratando la variable id como indice y la variable diagnosis como variable objetivo. Finalmente mostramos una muestra del conjunto de datos cargados","9530469a":"El porcentaje de valores nulos las dos variables que ya pensabamos arreglar durante el preprocesamiento (Age y Embarked) es tan inferior (menos del 20%) que las seguiremos teniendo en cuenta durante el preprocesamiento, mientras que el porcentaje de Cabin (que era una variable que no ibamos a tener en cuenta por el tipo de variable que era) es tan alto que la hubiesemos tenido que eliminar del proceso de generaci\u00f3n de modelos aunque el tipo de la variable no hubiese sido de tipo string.","4a6e272d":"Fijamos la semilla que utilizaremos:","a38d1616":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de \u00e1rbol de decisi\u00f3n. Como hemos mencionado en el an\u00e1lisis exploratorio utilizaremos 3 contenedores y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar","d9f0466a":"> ### *Conclusiones*","fbbd003d":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de \u00e1rbol de decisi\u00f3n. Como hemos mencionado en el an\u00e1lisis exploratorio utilizaremos 2 contenedores y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar","4c0d70d8":"## *2.1 Breast cancer Winsconsin*","0af3466a":"Si realizamos una observaci\u00f3n de este muestra podemos darnos cuenta de que destaca una variable llamada Unnamed 32 ya que en la muestra todos los sus valores son nulos (NaN). Si nos descargamos el fichero .csv de la base de datos Breast Cancer Wisconsin, podemos observar que esta variable es ruido ya que se ha introducido por error a la hora de cargar el conjunto de datos pues en el fichero se ha introducido una coma de m\u00e1s y al cargarlo esa coma la toma como otra variable, para ser exactos como la variable Unnamed32.\nPor ello lo que vamos a hacer a continuaci\u00f3n es eliminar dicha columna (mediante el m\u00e9todo de pandas drop) del conjunto de datos dataWisconsin y ense\u00f1aremos otra muestra de dicho conjunto de datos para confirmar si se han borrado correctamente.","a05e6c27":"### **Preeliminares del analisis exploratiro**\n\n","5759581b":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlaci\u00f3n:","f8dc29a9":"Observamos que en nuestro conjunto de datos entrenamientos hay m\u00e1s casos en el que el diagn\u00f3stico final fue benigneo(250)que en el que el diagn\u00f3stico final fue maligno (148), esto quiere decir que el problema est\u00e1 desbalanceado.","bee42acc":"Primero mostramos el n\u00famero de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","6dcc8722":"A continuacion vamos a realizar un diagrama de barras:","afa3315f":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero a\u00f1adi\u00e9ndoles un estimador que elimina outliers. Este estimador lo hemos a\u00f1adido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminaci\u00f3n de outliers puede generar sobreajuste y empeorar los resultados de la evaluaci\u00f3n; por lo tanto vamos a evaluar tanto las pipelines sin eliminaci\u00f3n de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","9e6b7542":"Cargamos la base de datos, pero al tener esta implicita tres archivos .csv utilizaremos \u00fanicamente el fichero train.csv pues es el \u00fanico que posee todas las variables predictoras que reccogen las caracter\u00edsticas de los pasajeros. Utilizaremos la variable PassenferId como \u00edndice y Survived como variable predictora y para cargar la base de datos utilizaremos el m\u00e9todo del utils load_data.","c8336ade":"Estas son las funciones axiliares que hemos creado para esta pr\u00e1ctica y que hemos a\u00f1adido a nuestro utils","25f18fbe":"Donde podemos observar que cada de las 31 variables que hay 30 son del tipo real y una que es del tipo categorico (Que es la variable que usaremos como variable objetivo, diagnosis)","0f3a4b25":"# 5. Algoritmos de clasificaci\u00f3n","b6e11d54":"La base de datos Titanic es una base de datos que recoge ciertas caracter\u00edsticas en sus variables sobre los distintos pasajeros del \u00fanico y famoso viaje del Titanic. Dichas variables son las siguientes:\n\n1. PassengerId: Variable num\u00e9rica entera creciente que actuar\u00e1 de indice de los distintos casos de la base de datos.\n2. Survived: Variable categ\u00f3rica num\u00e9rica que servir\u00e1 de variable objetico y que podr\u00e1 tener los valores 0 o 1, 0 en el caso de que el pasajero no sobrevivier\u00e1 en el viaje y 1 en el caso de que el pasajero sobreviviera. \n3. Pclass: Variable categ\u00f3rica num\u00e9rica que servir\u00e1 para indicar la clase del pasajero. La variable podr\u00e1 tener los valores 1,2 o 3; 1 en el caso de que el pasajero se alojase en primera clase, 2 en el caso de que el pasajero se alojase en segunda clase y 3 en el caso de que el pasajero se alojase en tercera clase.\n4. Name: Variable string de valores \u00fanicos que tendr\u00e1 el valor del nombre de los distintos pasajeros de los casos de la base de datos.\n5. Sex: Variable categ\u00f3rica que servir\u00e1 para indicar el g\u00e9nero del pasajero. La variable podr\u00f1a tener los valores male o female, male en el caso de que el g\u00e9nero del pasajero sea masculilno y female en el caso de que el g\u00e9nero del pasajero sea femenino.\n6. Age: Variale entera que servir\u00e1 para indicar la edad del pasajero.\n7. SibSp: Variable entera que servir\u00e1 para indicar el n\u00famero de hermanos (hermano, hermana, hermanastro o hermanastra) o de parejas (marido o mujer, las prometidas y amantes se ignoraron) que tiene el pasajero en el viaje.\n8. pArch: Variable entera que servir\u00e1 para indicar el n\u00famero de parientes que tiene el pasajero en el viaje (madre, padre, hija, hijo, hijastra, hijastro)\n9. Ticket: Variable string de valores \u00fanico que servir\u00e1 para indicar el n\u00famero de billete que tiene el pasajero. \n10. Fare: Variable real que servir\u00e1 para indicar la tarifa por la que ha pagado el pasajero por su billete.\n11. Cabin: Variable string que servir\u00e1 para indicar la cabina en la que viajaba el pasajero durante el viaje.\n12. Embarked: Variable categ\u00f3rica que podr\u00e1 tomar los valores C, Q o S en caso de que el pasajero embarcase en los puertos de Cherbourg, Queenstown o Southampton respectivamente.\n\n\nLa variable que usaremos como variable objetivo ser\u00e1 Survived, la variable que usaremos como indice ser\u00e1 PassengerId y el resto ser\u00e1n variables predictoras.\nComo conclusi\u00f3n, decir que esta base de datos se utilizar\u00e1 en nuestro estudio para generar modelos que prediga si un pasajero sobrevivir\u00e1 al viaje o no dependiendo de ciertas caracter\u00edsticas (que ser\u00e1n los valores de las variables predictoras).","0d3f65e3":"# 3. Analisis exploratorio","c2e8dcca":"A continuacion vamos a realizar un diagrama de barras:","51ed6170":"El n\u00famero de casos del conjunto de datos es 537 mientras que el n\u00famero de variables es 9","8809cb7a":"Las conclusiones que podemos sacar es que existe cierta relaci\u00f3n entre las variables del conjunto de variables radius_mean, perimeter_mean y area_mean y entre las variables del conjunto de variables concavity_mean, concave points_mean y concavity_mean. Adem\u00e1s de que existe cierta relaci\u00f3n entre estos dos conjuntos de variables, por lo tanto durante el preprocesamiento deberiamos de tener en cuenta estas conclusiones y decidir si tenemos en cuenta estas variables para modelar el problema.","3e5f02ed":"## *2.2 Pima Indians diabetes*","061fce0e":"## *6.1 Breast cancer Winsconsin*","a051dc1a":"## *6.2 Pima Indians diabetes*","02de61de":"Si observamos el tipo de cada una de las variables podemos darnos cuenta de que 3 son de tipo entero, que 2 son de tipo real (dato que quizas deberiamos de tener en cuenta m\u00e1s adelante en el preprocesamiento), 1 es de tipo categ\u00f3rico (que ser\u00e1 la variable que tomaremos como variable objetivo) y  5 son de tipo objeto, lo cual significar\u00e1 un inconveniente para la representaci\u00f3n de datos pues no aparecer\u00e1n en nuestras gr\u00e1ficas y tambi\u00e9n deberemos de replantearnos si estas variables objeto influir\u00e1n num\u00e9ricamente en la creaci\u00f3n de nuestros modelos finales.","35022304":"Tras observar el histograma que hemos obtenido sobre el conjunto de datos de entrenamiento, podemos sacar las siguientes conclusiones:\n* La primera conclusi\u00f3n que podemos sacar esque cada una de las variables perteneciente a un grupo (mean, se o worst) poseen una distribuci\u00f3n similar, con alguna excepci\u00f3n. Por ejemplo, las variables del grupo del valor medio (mean), tienen una distribuci\u00f3n normal con tendencia central en forma de campana de gauss, a excepci\u00f3n, de las variables area_mean, compactness_mean, concavity_mean y concave points_mean, que tienen una distribuci\u00f3n con tendencia exponencial decreciente. Por otra parte, las variables del grupo del error medio (se) poseen una distribuci\u00f3n exponencial decreciente apreciable en todas las variables del grupo. Finalmente, las variables del grupo del peor valor (worst) tienen una distribuci\u00f3n normal con tenencia central en forma de campana de gauss, a excepci\u00f3n, de las variables area_worstm compactness_worst, concavity_worts y fractal dimension_worst.\n* La segunda conclusi\u00f3n que podemos sacar esque entre las 31 variables, no hemos observado que haya presencia de datos no v\u00e1lidos ni indicios de outliers. No obstante; durante la realizaci\u00f3n de este an\u00e1lisis exploratorio realizaremos un diagrama de caja para cada una de las variables para analizar de forma m\u00e1s detallada la presencia de outliers.","6d85347e":"Para empezar vamos a cargar las librerias que utilizaremos durante el desarrollo de la pr\u00e1ctica","8abd714f":"Podemos observar que hay ciertas variables muy relacionadas entre si, como Age y Pregnancies, Glucose y Age o Glucose e Insulin; por lo que quizas en procesos posteriores deberiamos eliminar alguno de los miembros de estos pares de variables. Tamb\u00eden podemos darnos cuenta de que si realizamos una discretizaci\u00f3n quizas deber\u00edamos de realizarla con 3 contenedores, el problema, esque los datos est\u00e1n tan juntos que en principio no podemos definir ninguna estrategia de discretizaci\u00f3n correcta para este conjunto de datos.","4eef9325":"La base de datos Pima Indians diabetes tiene el objetivo de predecir de forma diagn\u00f3stica si un paciente tiene o no diabetes, bas\u00e1ndose en ciertas mediciones ya realizadas e incluidas en la base de datos. Algunas restricciones se han establecido en la seleccion de las instacias para la base de datos. En particular, todos los pacientes son mujeres con al menos 21 a\u00f1os con herencia del pueblo Pima (que \u00e9s un grupo de ind\u00edgenas de Estados Unidos que viven en Arizona). Las distitnas variables que maneja la base de datos son las siguientes:\n\n1. Pregnancies: N\u00famero entero que indica el n\u00famero de veces que ha estado embarazada la paciente.\n2. Glucose: N\u00famero entero que indica la concentraci\u00f3n de glucosa en plasma de la paciente tras 2 horas de que se la haya realizado una prueba oral de tolerancia a la glucosa.\n3. BloodPresure: N\u00famero entero que indica la presi\u00f3n arterial diast\u00f3lica de la paciente en mm\/hg.\n4. SkinThickness: N\u00famero entero que indica el espesor del pliegue cut\u00e1neo del triceps de la paciente en mm\n5. Insulin: N\u00famero real que indica el suelo insulino tras 2 horas de la paciente en mu U\/ml\n6. BMI: N\u00famero entero que indica el \u00edndice de masa corporal de la paciente dado por la divis\u00f3n del peso en kg entre la altura en metros al cuadrado\n7. DiabetesPedigreeFunction: N\u00famero real que indica el resultado de la funci\u00f3n de pedigree de la funci\u00f3n.\n8. Age: N\u00famero entero que indica la edad del paciente.\n9. Outcome: N\u00famero categ\u00f3rico num\u00e9rico que puede tener los valores 1 o 0. Esta variable tomar\u00e1 el valor 1 en el caso de que la paciente tenga diabetes y tomar\u00e1 el valor 0 en el caso de que la paciente no tenga diabetes.\n\nLa variable objetivo de este problema ser\u00eda outcome, mientras que el resto ser\u00e1n variables predictoras.\nComo conclusi\u00f3n, recordar que nuestra base de datos tendr\u00e1 la finalidad de que en base a los valores de las variables predictoras, intentar\u00e1 diagnosticar si un paciente tiene diabetes o no \"rellenando\" el valor de la variable objetivo Outcome.\n\n","134e7f59":"En esta parte generaremos los modelos que vamos a evaluar y las pipelines que saldr\u00e1n como resultado de aplicar a dichos modelos los estimadores que hemos creado en el apartado anterior (que tambi\u00e9n evaluaremos posteriormente).","1ae7547c":"Antes de empezar el analisis exploratorio obtendremos los conjuntos de entrenamiento y de test para todas las bases de datos sobre las que realizaremos el an\u00e1lisis exploratorio. Para ello volvemos a unir (usando el m\u00e9todo join_dataset del fichero utils) los conjuntos de variables predictoras con la variable clase de los subconjuntos de entrenamiento y de test de todas las bases de datos.","de7e722e":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","322f7459":"Primero mostramos el n\u00famero de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","9e22c414":"Al igual que para el gr\u00e1fico anterior vamos a realizar tres matrices distintas una para cada uno de los tipos que pueden tener las variables predictoras; mean,se y worst.","b7a283d6":"Como dato aclaratorio, tambi\u00e9n podriamos haber generado el estimador utilizando el transformador 'passthrough' y seleccionado todas las variables con las que nos queremos quedar sin igualar el par\u00e1metro remainder a passthrough, pues esto har\u00e1 que las variables que no le especifiquemos las borrar\u00e1 del conjunto de datos; b\u00e1sicamente es hacer el proceso que hemos hecho con el estimador al rev\u00e9s.","08f8c021":"Si observamos la gr\u00e1ficas podemos observar dos detalles importantes:\n* Lo primero es que no todas las variables tienen una distribuci\u00f3n normal con tendencia central en forma de campana de gauss, solamente las variables SkinThickness, BMI, BloodPresure y Glucose; mientras que el resto de variables( Age, Pregnancies, Insulin y DiabetesPedigreeFunction) poseen una distribuci\u00f3n con tendencia exponencial decreciente. De hecho en ciertas variables como DiabetesPedigreeFunction o Insulin, en sus gr\u00e1ficas podemos empezar a apreciar la aparici\u00f3n de outliers que comprobaremos m\u00e1s tarde con los gr\u00e1ficos de caja.\n* Lo segundo es que en las gr\u00e1ficas se puede observar como ciertas variables toman valores perdidos, es decir toman el valor 0 cuando seg\u00fan la l\u00f3gica de los valores que pueden tomar dichas variables ser\u00eda imposible que dichas variables tuvisen como valor un 0. Dichas variables son Glucose (un paciente no puede tener 0 de glucosa), BloodPresure (un paciente no puede tener 0 de presi\u00f3n sangu\u00ednea), SkinThickness (la piel de un paciente debe de tener grosor), Insulin (un paciente ha de tener insulina) y BMI (el \u00edndice de masa corporal de una persona no puede ser 0).","ac3424e7":"## *4.2 Pima Indians diabetes*","997229f1":"En estas dos muestra que hemos obtenido ya podemos observar valores nulos (NaN) en algunas variables que es un dato que vamos a tener que tener en cuenta a la hora de realizar el an\u00e1lisis exploratorio y el psoterior preprocesamiento de datos.","ededcede":"Diagrama de caja","ed0b0768":"Continuaremos con el an\u00e1lisis exploratorio realizando un diagrama de puntos:","2cc7031e":"A continuaci\u00f3n mostramos los distitnos valores que pueden tomar nuestras variables categ\u00f3ricas con el m\u00e9todo .categories:","fdd5d2e6":"Empezamos el preprocesamiento definiendo el estimador que hara uso de la funci\u00f3n outlier_rejection del fichero de utilidad utils para eliminar outliers. Este estimador se utilizar\u00e1 posteriormente en la generaci\u00f3n de modelos aplicandos\u00e9 al conjunto de datos.","7a48feb2":"Las conclusiones que podemos sacar de los distintos diagramas de cajas esque en las variables se aprecian cierta cantidad de valores que est\u00e1n demasiado distanciados de la mediana, not\u00e1ndose sobre todo en los diagramas de las variables Insulin y SkinThickness, por lo que se justifica el uso de un estimador para eliminar outliers para modelar este conjunto de datos.","33a05bab":"A continuaci\u00f3n mostramos los distitnos valores que pueden tomar nuestras variables categ\u00f3ricas con el m\u00e9todo .categories:","fc21e196":"### **Descripci\u00f3n del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables","b35ac24b":"Al realizar la carga de datos y ense\u00f1ar una muestra de los datos cargados, pudimos observar qeu habias ciertas variables con valores nulos (NaN) y como no hemos podido observar en el histograma que variables poseen dichos valores nulos, vamos a recurrir al m\u00e9todo isnull().sum para que se nos muestren todas las variables con valores nulos.","2e2c4c7c":"Podemos observar que la variable Outcome es una variable categ\u00f3rica num\u00e9rica que puede tomar los valores 0 o 1 en caso negativo o afirmativo de que el paciente tenga diabetes respectivamente.","651b207d":"Respecto a estas graficas podemas darnos cuenta que las variables radius_mean, perimeter_mean, area_mean estan muy relacionados, obviamente eso puede ser por que para obtener el perimetro y el area es necesario saber el radio. Puede que sea factible descartar estas variables y quedarnos con solo radio ya que al estar muy relacionados dicha eliminaci\u00f3n no afectar\u00eda negativamente a la generaci\u00f3n de modelos y consideramos que es mejor eliminar 3 variables que una para tener menos variables que gestionar durante el proceso de modelado.\nTambi\u00e9n podemos observar que la mejor forma de realizar una discretizaci\u00f3n \u00f3ptima ser\u00eda utilizando dos contenedores y quizas la mejor estrategia ser\u00eda utilizar KMeans, pero hay tantos casos que no se puede estar seguro a simple vista.","35850174":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero a\u00f1adi\u00e9ndoles un estimador que elimina outliers. Este estimador lo hemos a\u00f1adido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminaci\u00f3n de outliers puede generar sobreajuste y empeorar los resultados de la evaluaci\u00f3n; por lo tanto vamos a evaluar tanto las pipelines sin eliminaci\u00f3n de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","4163cdf6":"El preprocesamineto del conjunto de datos de la base de datos Titanic es algo complicado por ello vamos a dividir la explicaci\u00f3n en tres distintas partes:\n* Primero, tenemos que tratar las variables que hemos detectado que son categ\u00f3ricas puras y que tambi\u00e9n tienen valores nulos durante el an\u00e1lisis exploratorio, dichas variables son Sex y Embarked. Para ello crearemos un pipeline con dos estimadores, uno primero que ser\u00e1 SimpleImputer que sustituir\u00e1 los valores perdidos (NaN) usando la estrategia 'most_frequent' (que es la recomendable para variables categ\u00f3ricas puras) y otro OneHotEncoder que conviertir\u00e1 las variables categ\u00f3ricas puras en categ\u00f3ricas num\u00e9ricas.\n* Despu\u00e9s tenemos que tratar las variables categ\u00f3ricas num\u00e9ricas y las que contienen valores perdidos (NaN), que ser\u00e1n las variables Age, SibSp, Parch, Fare y Pclass. Para ello crearemos un pipeline con dos estimadores, uno primero que ser\u00e1 SimpleImputer que sustituir\u00e1 los valores perdidos (NaN) usando la estrategia 'median' que sustituir\u00e1 los valores perdidos por la mediana de los valores de la variable (esto es as\u00ed porque dentro de las variables tenemos una mezcla de variables enteras y reales y debido a esta mezcla no podemos recurrir ni a la media ni a la moda, 'most frequent', entonces recurriremos a la mediana) y el otro estimador ser\u00e1 un StandarScaler que intentar\u00e1 estandarizar las caracter\u00edsticas.\n* Finalmente estos dos estimadores los juntaremos en un m\u00e9todo_make_column_tranformer donde introduciremos las dos pipelines generadas con sus corresponientes conjuntos de variables, y para eliminar las variables que hemos acordado eliminar del conjunto de datos durante el an\u00e1lisis exploratorio (Name, Ticket y Cabin) simplemente no las introduciremos en ninguno de los dos conjuntos de variables.","5c64912b":"A continuaci\u00f3n le aplicaremos al modelo de \u00e1rbol de decisi\u00f3n el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al \u00e1rbol de decisi\u00f3n discretizado con 3 contenedores y todas las posibles estrategias de discretizaci\u00f3n."}}