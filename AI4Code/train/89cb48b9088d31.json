{"cell_type":{"629be1a3":"code","69dce689":"code","1924ecb4":"code","18ffdc17":"code","a2f080c2":"code","e6aa007b":"code","cc951fd9":"code","94cd6dd2":"code","3b882525":"code","d7ad9ea7":"code","d2d2a6e0":"code","0b32904c":"code","8d0d02b4":"code","c0eea1b5":"code","ff070f5e":"code","e2dfaca2":"code","5dcd727a":"code","070d5e8b":"code","aaa8e200":"code","aa850911":"code","63a0bf48":"code","a51d7251":"code","5fa18d4f":"code","ae341d62":"markdown"},"source":{"629be1a3":"import pandas as pd\n\ndata_frame = pd.read_csv(\"\/kaggle\/input\/gan-assignment2\/Geom(1).csv\")","69dce689":"opt = 'adam'\nloss = 'mse'","1924ecb4":"X = data_frame.values \nX.shape","18ffdc17":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test = train_test_split(X,test_size=0.2, random_state=11)\nx_train, x_validate = train_test_split(x_train,test_size=0.2, random_state=1)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(x_validate.shape)","a2f080c2":"import keras\nfrom keras import layers\n\nencoding_dim = 30\n\ninput_pts = keras.Input(shape=(122,))\na = layers.Dense(70,activation='linear')(input_pts)\n\nencoded = layers.Dense(encoding_dim, activation='linear')(a)\n\nb = layers.Dense(70,activation=\"linear\")(encoded)\ndecoded = layers.Dense(122, activation='linear')(b)\n\nautoencoder = keras.Model(input_pts, decoded)\n\nencoder = keras.Model(input_pts, encoded)\n\nencoded_input = keras.Input(shape=(encoding_dim,))\nb_layer = autoencoder.layers[-2]\ndecoder_layer = autoencoder.layers[-1]\n\ndecoder = keras.Model(encoded_input, decoder_layer(b_layer(encoded_input)))\n\nautoencoder.compile(optimizer=opt, loss=loss)","e6aa007b":"autoencoder.fit(x_train, x_train,\n                epochs=150,\n                batch_size=13,\n                shuffle=True,\n                validation_data=(x_validate, x_validate))","cc951fd9":"encoded_pts = encoder.predict(x_test)\ndecoded_pts = decoder.predict(encoded_pts)","94cd6dd2":"encoded_pts.shape","3b882525":"decoded_pts.shape","d7ad9ea7":"x_test[0,0::2].shape # X coordinates","d2d2a6e0":"x_test[0,1::2].shape # Y coordinates","0b32904c":"np.amax(X)","8d0d02b4":"from sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=3,ncols=5,figsize=(50,30))\n\nfor i in range(len(x_test)):\n    ax[0,i].set_xlim(xmin=-150,xmax=150)\n    ax[0,i].set_ylim(ymin=-150,ymax=150)\n    ax[0,i].plot(x_test[i,0::2], x_test[i,1::2],'bo')\n    ax[0,i].grid(linestyle = '--', linewidth = 0.5)\n    \n    ax[1,i].set_xlim(xmin=-150,xmax=150)\n    ax[1,i].set_ylim(ymin=-150,ymax=150)\n    ax[1,i].plot(decoded_pts[i,0::2], decoded_pts[i,1::2],'ro')\n    ax[1,i].grid(linestyle = '--', linewidth = 0.5)\n    \n    ax[2,i].set_xlim(xmin=-150,xmax=150)\n    ax[2,i].set_ylim(ymin=-150,ymax=150)\n    ax[2,i].plot(x_test[i,0::2], x_test[i,1::2],'bo')\n    ax[2,i].set_xlim(xmin=-150,xmax=150)\n    ax[2,i].set_ylim(ymin=-150,ymax=150)\n    ax[2,i].plot(decoded_pts[i,0::2], decoded_pts[i,1::2],'ro')\n    ax[2,i].grid(linestyle = '--', linewidth = 0.5)\n    ax[2,i].set_title(\"MSE = \"+str(round(mean_squared_error(x_test[i],decoded_pts[i]),5)),fontsize=30)","c0eea1b5":"mean_squared_error(x_test,decoded_pts)","ff070f5e":"# This is the size of our encoded_2 representations\nencoding_dim = 60  \n\n# This is our input image\ninput_pts = keras.Input(shape=(122,))\n# \"encoded_2\" is the encoded_2 representation of the input\na_2 = layers.Dense(70,activation='linear')(input_pts)\nencoded_2 = layers.Dense(encoding_dim, activation='linear')(a_2)\n# \"decoded_2\" is the lossy reconstruction of the input\n\nb_2 = layers.Dense(70,activation='linear')(encoded_2)\ndecoded_2 = layers.Dense(122, activation='linear')(b_2)\n\n# This model maps an input to its reconstruction\nautoencoder = keras.Model(input_pts, decoded_2)\n\n# This model maps an input to its encoded_2 representation\nencoder = keras.Model(input_pts, encoded_2)\n\n# This is our encoded_2 (32-dimensional) input\n\nencoded_2_input = keras.Input(shape=(encoding_dim,))\n\n# Retrieve the last layer of the autoencoder model\n\nb_layer_2 = autoencoder.layers[-2]\n\ndecoder_layer = autoencoder.layers[-1]\n\n# Create the decoder model\ndecoder = keras.Model(encoded_2_input, decoder_layer(b_layer_2(encoded_2_input)))\n\nautoencoder.compile(optimizer=opt, loss=loss)\n# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n\nprint(\" \")","e2dfaca2":"autoencoder.fit(x_train, x_train,\n                epochs=150,\n                batch_size=13,\n                shuffle=True,\n                validation_data=(x_validate, x_validate))","5dcd727a":"encoded_2_pts = encoder.predict(x_test)\ndecoded_2_pts = decoder.predict(encoded_2_pts)","070d5e8b":"encoded_2_pts.shape","aaa8e200":"decoded_pts.shape","aa850911":"x_test[0,0::2].shape","63a0bf48":"x_test[0,1::2].shape","a51d7251":"fig, ax = plt.subplots(nrows=3,ncols=5,figsize=(50,30))\n\nfor i in range(len(x_test)):\n    ax[0,i].set_xlim(xmin=-150,xmax=150)\n    ax[0,i].set_ylim(ymin=-150,ymax=150)\n    ax[0,i].plot(x_test[i,0::2], x_test[i,1::2],'bo')\n    ax[0,i].grid(linestyle = '--', linewidth = 0.5)\n    \n    ax[1,i].set_xlim(xmin=-150,xmax=150)\n    ax[1,i].set_ylim(ymin=-150,ymax=150)\n    ax[1,i].plot(decoded_2_pts[i,0::2], decoded_2_pts[i,1::2],'ro')\n    ax[1,i].grid(linestyle = '--', linewidth = 0.5)\n    \n    ax[2,i].set_xlim(xmin=-150,xmax=150)\n    ax[2,i].set_ylim(ymin=-150,ymax=150)\n    ax[2,i].plot(x_test[i,0::2], x_test[i,1::2],'bo')\n    ax[2,i].grid(linestyle = '--', linewidth = 0.5)\n    ax[2,i].set_xlim(xmin=-150,xmax=150)\n    ax[2,i].set_ylim(ymin=-150,ymax=150)\n    ax[2,i].plot(decoded_2_pts[i,0::2], decoded_2_pts[i,1::2],'ro')\n    ax[2,i].grid(linestyle = '--', linewidth = 0.5)\n    ax[2,i].set_title(\"MSE = \"+str(round(mean_squared_error(x_test[i],decoded_2_pts[i]),5)),fontsize=30)","5fa18d4f":"mean_squared_error(x_test,decoded_2_pts)","ae341d62":"# 60"}}