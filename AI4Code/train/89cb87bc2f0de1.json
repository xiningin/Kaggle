{"cell_type":{"271c809a":"code","ab20b342":"code","82e61cd0":"code","c5019ebb":"code","31261830":"code","dc655753":"code","14f161fd":"code","7f6b68dd":"code","7cf4559f":"markdown","7a90fb67":"markdown","923a7d0b":"markdown","92f70373":"markdown"},"source":{"271c809a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab20b342":"!pip uninstall -y kaggle\n!pip install --upgrade pip\n!pip install kaggle==1.5.6\n!mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\n!ls -lha kaggle.json\n!chmod 600 ~\/.kaggle\/kaggle.json\n!kaggle competitions download -c ai-tomato\n!unzip ai-tomato.zip","82e61cd0":"import torch\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nif device == 'cuda':\n  torch.cuda.manual_seed_all(111)\n\ntrain = pd.read_csv('training_set.csv', header=None, skiprows=1)\n\ntrain","c5019ebb":"train[0] = train[0] % 10000 \/100\ntrain.drop(4, axis=1,inplace=True) #rainfall \uc0ad\uc81c\n\nxtrain = train.loc[:,[i for i in train.keys()[:-1]]]\nytrain = train[train.keys()[-1]]\n\nxtrain = np.array(xtrain)\nxtrain = torch.FloatTensor(xtrain).to(device)\n\nytrain = np.array(ytrain)\nytrain = torch.FloatTensor(ytrain).view(-1,1).to(device)\n\ntrain","31261830":"dataset = TensorDataset(xtrain, ytrain)\ndataloader = DataLoader(dataset, batch_size=5, shuffle=True, drop_last=True) # \ubc30\uce58\uc0ac\uc774\uc988 5\ub85c \ubc14\uafd4\uc90c\n\ntorch.manual_seed(111)\n\nlin1 = nn.Linear(6,32)\nlin2 = nn.Linear(32,1)\n\nnn.init.kaiming_uniform_(lin1.weight)\nnn.init.kaiming_uniform_(lin2.weight)\n\nrelu = nn.ReLU()\n\nmodel = nn.Sequential(lin1,relu,\n                      lin2).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\nloss = nn.MSELoss().to(device)\n\nnb_epochs = 500\nfor epoch in range(nb_epochs + 1):\n  for x,y in dataloader:\n    x = x.to(device)\n    y=y.to(device)\n\n    H = model(x)\n    cost = loss(H, y)\n\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n\n  if epoch%50 == 0:\n      print('Epoch {}  Cost {}'.format(epoch, cost.item()))\n\nprint('Learning Finished')","dc655753":"test = pd.read_csv('test_set.csv')\ntest=test.dropna(axis=1)","14f161fd":"test['date'] = test['date'] % 10000 \/100\ntest.drop('rain fall', axis=1,inplace=True) #rainfall \uc0ad\uc81c\n\nxtest = test.loc[:,[i for i in test.keys()[:]]]\nxtest = np.array(xtest)\nxtest = torch.from_numpy(xtest).float().to(device)\n\nH = model(xtest)\n\nH = H.cpu().detach().numpy().reshape(-1,1)\n\nsubmit = pd.read_csv('submit_sample.csv')\n\nfor i in range(len(submit)):\n  submit['expected'][i] = H[i]\n\nsubmit.to_csv('sub.csv', index = None, header=True)\n\nsubmit","7f6b68dd":"!kaggle competitions submit -c ai-tomato -f sub.csv -m \"Message\"","7cf4559f":"# \uc5d0\uce21\uac12 \uad6c\ud558\uae30","7a90fb67":"# \uac00\uc911\uce58 \ucd08\uae30\ud654 \ubc0f \ub370\uc774\ud130 \ud559\uc2b5","923a7d0b":"# import","92f70373":"# \ub370\uc774\ud130 \ub85c\ub4dc\ubc0f \ud544\uc694\uc5c6\ub294\ubd80\ubd84 \ubc84\ub9bc"}}