{"cell_type":{"0b29d167":"code","6b3582e2":"code","7cddf0bb":"code","9f153067":"code","8c280ece":"code","7c5c42b7":"code","73cd727d":"code","f3e6998f":"code","7836aa26":"code","55962bbe":"code","985fd9c1":"code","effc5f02":"code","7abd5a6b":"code","408a81e0":"code","3bf4991e":"code","84d2a217":"code","ac4375f6":"code","8c3b4d29":"code","b92ae5b1":"code","637e9a7c":"markdown"},"source":{"0b29d167":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import scale\nfrom tensorflow.keras import backend as K, callbacks\nfrom sklearn.metrics import accuracy_score as accuracy, f1_score, mean_absolute_error as mae\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom keras.utils.vis_utils import plot_model\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b3582e2":"dataset_NASDAQ = pd.read_csv(\"\/kaggle\/input\/cnnpred-stock-market-prediction\/Processed_NASDAQ.csv\", parse_dates=['Date'])\ndataset_NYSE = pd.read_csv(\"\/kaggle\/input\/cnnpred-stock-market-prediction\/Processed_NYSE.csv\", parse_dates=['Date'])\ndataset_SP = pd.read_csv(\"\/kaggle\/input\/cnnpred-stock-market-prediction\/Processed_SP.csv\", parse_dates=['Date'])\ndataset_DJI = pd.read_csv(\"\/kaggle\/input\/cnnpred-stock-market-prediction\/Processed_DJI.csv\", parse_dates=['Date'])\ndataset_RUSSELL = pd.read_csv(\"\/kaggle\/input\/cnnpred-stock-market-prediction\/Processed_RUSSELL.csv\", parse_dates=['Date'])","7cddf0bb":"dataset_NASDAQ.index = dataset_NASDAQ['Date']\ndataset_NYSE.index = dataset_NYSE['Date']\ndataset_SP.index = dataset_SP['Date']\ndataset_DJI.index = dataset_DJI['Date']\ndataset_RUSSELL.index = dataset_RUSSELL['Date']","9f153067":"dataset_NASDAQ.columns","8c280ece":"dataset_NASDAQ","7c5c42b7":"whole_data = dataset_NASDAQ.append(dataset_NYSE, ignore_index=True)","73cd727d":"whole_data","f3e6998f":"whole_data = whole_data.append(dataset_SP, ignore_index=True)\nwhole_data = whole_data.append(dataset_DJI, ignore_index=True)\nwhole_data = whole_data.append(dataset_RUSSELL, ignore_index=True)\nwhole_data","7836aa26":"whole_data[\"Close\"]","55962bbe":"print(len(dataset_NASDAQ ))\nprint(len(dataset_NYSE))\nprint(len(dataset_SP))\nprint(len(dataset_DJI ))\nprint(len(dataset_RUSSELL))","985fd9c1":"whole_data.isnull().sum()","effc5f02":"whole_data.info()","7abd5a6b":"import matplotlib.pyplot as plt\nwhole_data.hist(figsize=(30,30))\nplt.show()","408a81e0":"# Kalan k\u0131sma sonra bak:\n# Neyi predict edece\u011fiz ??","3bf4991e":"predict_index = 'DJI'\nnumber_of_stocks = 0\norder_stocks = []\npredict_day = 1\n\n\ndef prepare_for_CNN():\n    global number_of_stocks\n    global samples_in_each_stock\n    global number_feature\n    #global predict_index\n    global order_stocks\n    tottal_train_data = np.empty((0,82))\n    tottal_train_target = np.empty((0))\n    tottal_test_data = np.empty((0,82))\n    tottal_test_target = np.empty((0))\n    \n    for data in [dataset_DJI, dataset_NASDAQ, dataset_NYSE, dataset_RUSSELL, dataset_SP]:\n        \n        number_of_stocks += 1\n        \n        df_name = data['Name'][0]\n        order_stocks.append(df_name)\n        del data['Name']\n\n        target = (data['Close'][predict_day:] \/ data['Close'][:-predict_day].values).astype(int)\n        print(target)\n        print(\"*****\")\n        data = data[:-predict_day]\n        target.index = data.index\n        # Becasue of using 200 days Moving Average as one of the features\n        data = data[200:]\n        data = data.fillna(0)\n        data['target'] = target\n        target = data['target']\n        del data['target']\n        del data['Date']\n        # data['Date'] = data['Date'].apply(lambda x: x.weekday())\n\n        number_feature = data.shape[1]\n        samples_in_each_stock = data.shape[0]\n\n        train_data = data[data.index < '2016-04-21']\n        train_data = scale(train_data)\n\n        if df_name == predict_index:\n            tottal_train_target = target[target.index < '2016-04-21']\n            tottal_test_target = target[target.index >= '2016-04-21']\n\n        data = pd.DataFrame(scale(data.values), columns=data.columns)\n        data.index = target.index\n        test_data = data[data.index >= '2016-04-21']\n\n        tottal_train_data = np.concatenate((tottal_train_data, train_data))\n        print(tottal_train_data.shape)\n        tottal_test_data = np.concatenate((tottal_test_data, test_data))\n        print(tottal_test_data.shape)\n        \n    train_size = int(tottal_train_data.shape[0]\/number_of_stocks)\n    print(\"Train size:\", train_size)\n    test_size = int(tottal_test_data.shape[0] \/ number_of_stocks)\n    print(\"Test size:\", test_size)\n    \n    tottal_train_data = tottal_train_data.reshape(number_of_stocks, train_size, number_feature)\n    print(\"Total train data shape:\", tottal_train_data.shape)\n    tottal_test_data = tottal_test_data.reshape(number_of_stocks, test_size, number_feature) \n    print(\"Total test data shape:\", tottal_test_data.shape)\n\n    return tottal_train_data, tottal_test_data, tottal_train_target, tottal_test_target","84d2a217":"def cnn_data_sequence(data, target, seque_len):\n    print ('sequencing data ...')\n    new_train = []\n    new_target = []\n\n    for index in range(data.shape[1] - seque_len + 1):\n        new_train.append(data[:, index: index + seque_len])\n        new_target.append(target[index + seque_len - 1])\n\n    new_train = np.array(new_train)\n    new_target = np.array(new_target)\n\n    return new_train, new_target","ac4375f6":"def f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n    precision_pos = precision(y_true, y_pred)\n    recall_pos = recall(y_true, y_pred)\n    precision_neg = precision((K.ones_like(y_true)-y_true), (K.ones_like(y_pred)-K.clip(y_pred, 0, 1)))\n    recall_neg = recall((K.ones_like(y_true)-y_true), (K.ones_like(y_pred)-K.clip(y_pred, 0, 1)))\n    f_posit = 2*((precision_pos*recall_pos)\/(precision_pos+recall_pos+K.epsilon()))\n    f_neg = 2 * ((precision_neg * recall_neg) \/ (precision_neg + recall_neg + K.epsilon()))\n\n    return (f_posit + f_neg) \/ 2\n\ndef sklearn_acc(model, test_data, test_target):\n    overall_results = model.predict(test_data)\n    test_pred = (overall_results > 0.5).astype(int)\n    acc_results = [mae(overall_results, test_target), accuracy(test_pred, test_target),\n                   f1_score(test_pred, test_target, average='macro')]\n\n    return acc_results","8c3b4d29":"number_filter = [8,8,8]\n\ndef CNN(train_data, test_data, train_target, test_target):\n    # hisory of data in each sample\n    seq_len = 60\n    epoc = 100\n    drop = 0.1\n    \n    cnn_train_data, cnn_train_target = cnn_data_sequence(train_data, train_target, seq_len)\n    cnn_test_data, cnn_test_target = cnn_data_sequence(test_data, test_target, seq_len)\n    result = []\n    \n    for i in range(1,5):\n        K.clear_session()\n        print ('i: ', i)\n        \n        print('fitting model')\n        \n        model = Sequential()\n\n        #layer 1\n        model.add(Conv2D(number_filter[0], (1, 1), activation='relu', input_shape=(number_of_stocks,seq_len, number_feature), data_format='channels_last'))\n        model.add(Dropout(0.1)) # added\n        \n        #layer 2\n        model.add(BatchNormalization())   # added\n        model.add(Conv2D(number_filter[1], (number_of_stocks, 3), activation='relu'))\n        model.add(MaxPool2D(pool_size=(1, 2)))\n        model.add(Dropout(0.2))   # added\n\n        \n        #layer 3\n        model.add(Conv2D(number_filter[2], (1, 3), activation='relu'))\n        model.add(MaxPool2D(pool_size=(1, 2)))\n        \n        # Flattening Layer:\n        model.add(Flatten())\n        model.add(Dropout(0.4))  # added\n        \n        # Last Layer:\n        model.add(Dense(1, activation='sigmoid'))\n\n        model.compile(optimizer='Adam', loss='mae', metrics=['acc',f1])\n\n        #best_model = callbacks.ModelCheckpoint(filepath, monitor='val_f1', verbose=0, save_best_only=True,\n                                               #save_weights_only=False, mode='max', period=1)\n\n        model.fit(cnn_train_data, cnn_train_target, epochs=epoc, batch_size=128, verbose=0, validation_split=0.25) #callbacks=[best_model],\n\n    #   model = load_model(filepath, custom_objects={'f1': f1})\n        test_pred = sklearn_acc(model,cnn_test_data, cnn_test_target)\n        print (test_pred)\n        result.append(test_pred)\n        \n        model.summary() # added \n        \n        # plot_model(model)    \n    \n    print('saving results')\n    results = pd.DataFrame(result , columns=['MAE', 'Accuracy', 'F-score'])\n    results = results.append([results.mean(), results.max(), results.std()], ignore_index=True)\n    #results.to_csv(join(Base_dir, '3D-models\/{}\/new results.csv'.format(predict_index)), index=False)\n    return results\n    ","b92ae5b1":"train_data, test_data, train_target, test_target = prepare_for_CNN()\n\nCNN(train_data, test_data, train_target, test_target)","637e9a7c":"## Data Preparation"}}