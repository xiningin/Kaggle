{"cell_type":{"e64de4c3":"code","56fd8f84":"code","2fc21e25":"code","0af24e05":"code","fb3cddd6":"code","dbd0b1bc":"code","deaa0ebb":"code","7854311c":"code","2940e0bd":"code","4180612a":"code","4dce48b8":"code","328858ae":"markdown","d32c45bf":"markdown","857101cd":"markdown","5b717d54":"markdown","b6688ff3":"markdown","2590617a":"markdown","fc471a1d":"markdown","60c44b77":"markdown","c6004313":"markdown","624a212c":"markdown","6fb0c795":"markdown","5747313e":"markdown","c51bf265":"markdown"},"source":{"e64de4c3":"import os\nimport json\nimport pandas as pd\nimport re\nfrom nltk import sent_tokenize\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use(\"bmh\")","56fd8f84":"# Read meta information\ndf_meta = pd.read_csv(\"\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv\", index_col=\"sha\")    \n\n# Read and format articles from each folder\ndirs = [\"biorxiv_medrxiv\", \"comm_use_subset\", \"custom_license\", \"noncomm_use_subset\"]\n\n# Initialize an empty list\ndocs = []\n\n# Loop over json-files and extract information to docs\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if dirname[-4:] == \"json\":\n            # Load file\n            j = json.load(open((os.path.join(dirname, filename)), \"rb\"))\n\n            # Extract the information    \n            paper_id = j[\"paper_id\"]\n\n            title = j[\"metadata\"][\"title\"]\n\n            authors = j[\"metadata\"][\"authors\"]\n\n            try:\n                abstract = j[\"abstract\"][0]\n            except:\n                abstract = \"\"\n\n            full_text = \"\"    \n            for text in j[\"body_text\"]:\n                full_text += text[\"text\"] + \" \"\n\n            # Get meta data information for the file\n            file_code = filename.split(\".\")[0]\n\n            try:\n                publish_time = df_meta.loc[file_code, \"publish_time\"]\n            except KeyError:\n                publish_time = \"\"\n\n            try:\n                journal = df_meta.loc[file_code, \"journal\"]\n            except KeyError:\n                journal= \"\"    \n\n            try:\n                source_folder = df_meta.loc[file_code, \"full_text_file\"]\n            except KeyError:\n                source_folder = \"\"\n\n            # Append all information to docs\n            docs.append([paper_id, title, abstract, full_text, \n                         publish_time, journal, authors, source_folder])","2fc21e25":"# Build up DataFrame\ndf = pd.DataFrame(docs, columns=[\"paper_id\", \"title\", \"abstract\", \"full_text\",\n                                 \"publish_time\", \"journal\", \"authors\", \"source_folder\"])\nprint(df.head())\nprint(\"\\n# of rows and columns:\", df.shape)\n","0af24e05":"# Generate filters\ncovid19_synonyms = ['covid',\n                    'coronavirus disease 19',\n                    'sars cov 2', \n                    '2019 ncov',\n                    '2019ncov',\n                    '2019 n cov',\n                    '2019n cov',\n                    'ncov 2019',\n                    'n cov 2019',\n                    'coronavirus 2019',\n                    'wuhan pneumonia',\n                    'wuhan virus',\n                    'wuhan coronavirus',\n                    'coronavirus',\n                    'coronavirus-disease',\n                    'coronavirus disease',\n                    'coronavirus-disease 19',\n                    'sars-cov-2', \n                    '2019-ncov',\n                    '2019 n-cov',\n                    '2019-n-cov',\n                    '2019n-cov',\n                    'ncov-2019',\n                    'n-cov 2019',\n                    'n-cov-2019',\n                    'coronavirus-2019',\n                    'wuhan-pneumonia',\n                    'wuhan-virus',\n                    'wuhan-coronavirus',\n                    'corona-virus']\n\n\nincubation_synonyms = ['incubation period',\n                       'period of incubation',\n                       'latent period',\n                       'latency period',\n                       'period of latency',\n                       'window period',\n                       'incubation',\n                       'incubate']\n\nduration_expression = ['\\sday|', '\\sd|' '\\shour|', '\\shr']\nnumber_expression = r\"(\\d+(?:\\.\\d+)?(?:\\-\\d+(?:\\.\\d+)?)?(?:\\\u2212\\d+(?:\\.\\d+)?)?(?:\\s\\-\\s\\d+(?:\\.\\d+)?)?(?:\\s\\\u2212\\s\\d+(?:\\.\\d+)?)?(?:\\sto\\s\\d+(?:\\.\\d+)?)?(?:\\sand\\s\\d+(?:\\.\\d+)?)?)\"\n\nnumber_date_expression = number_expression + number_expression.join([d for d in duration_expression])\nprint(\"Regex Number-Date-Expressions:\\n\", number_date_expression)\n","fb3cddd6":"# Extract incubation information\nfor id, text in enumerate(df[\"full_text\"]):\n    article_incubation_sentences = str()\n    article_incubation_means = str()\n    article_incubation_medians = str()\n    article_incubation_max = str()\n    article_incubation_min = str()\n    article_incubation_iqr = str()\n    #for sentence in text.split(\". \"):\n    for sentence in sent_tokenize(text, language=\"english\"):\n        # Replace false float representations (e.g. \"4\u00b75\" instead of 4.5)\n        sentence = sentence.replace(\"\u00b7\", \".\")\n        # For each sentence, look for covid19 synonym ...\n        if len(re.findall(\"|\".join(covid19_synonyms), sentence.lower())) > 0:\n            # ... as well as an incubation synonym ...\n            if len(re.findall(\"|\".join(incubation_synonyms), sentence.lower())) > 0:\n                # ... as well as a duration expression.\n                if len(re.findall(\"|\".join(duration_expression), sentence.lower())) > 0:\n                    # We append these sentences for each article ...\n                    article_incubation_sentences += sentence + \"\\n\\n\"\n                    # ... and store the incubation sentences to our dataframe df\n                    df.loc[id, \"incubation_sentences\"] = article_incubation_sentences\n                    # Extract mean information\n                    # See whether mean is present in sentence\n                    if len(re.findall(\"\\smean\\s|average\", sentence.lower())) > 0:\n                        if re.findall(\"\\smean\\s|average\", sentence.lower())[0] == \" mean \":\n                            mean_syn = \"mean\"\n                        elif re.findall(\"\\smean\\s|average\", sentence.lower())[0] == \"average\":\n                            mean_syn = \"average\"\n                        # Reduce sentence to part after \"mean\" is mentioned\n                        sentence_reduced = sentence.lower().split(mean_syn, maxsplit=1)[1]\n                        # Now extract the first (!) number-duration expression, which likely refers to the mean\n                        try: \n                            mean_expression = re.search(number_date_expression, sentence_reduced)[0]\n                            # For each article store the expressions from each sentence\n                            article_incubation_means += mean_expression + \"; \"\n                        except TypeError:\n                            pass\n                        # Store the measures in our dataframe df, reject empty strings\n                        if len(article_incubation_means) > 0:\n                            df.loc[id, \"incubation_mean\"] = article_incubation_means\n                    # See whether median is present in sentence\n                    if len(re.findall(\"median\", sentence.lower())) > 0:\n                        # Reduce sentence to part after \"median\" is mentioned\n                        sentence_reduced = sentence.lower().split(\"median\", maxsplit=1)[1]\n                        # Now extract the first (!) number-duration expression, which likely refers to the median\n                        try:\n                            median_expression = re.search(number_date_expression, sentence_reduced)[0]\n                            # For each article store the expressions from each sentence\n                            article_incubation_medians += median_expression + \"; \"\n                        except TypeError:\n                            pass\n                        # Store the measures in our dataframe df, reject empty strings\n                        if len(article_incubation_medians) > 0:\n                            df.loc[id, \"incubation_median\"] = article_incubation_medians\n                    # See whether Inter-quartile range is present in sentence\n                    if len(re.findall(\"iqr|interquartile range|inter-quartile-range|inter-quartile range|iq-range\", sentence.lower())) > 0:\n                        iqr_syn = re.findall(\"iqr|interquartile range|inter-quartile-range|inter-quartile range|iq-range\", sentence.lower())[0]\n                        # Reduce sentence to part after \"iqr\" is mentioned\n                        sentence_reduced = sentence.lower().split(iqr_syn, maxsplit=1)[1]\n                        # Now extract the first (!) number-duration expression, which likely refers to the iqr\n                        try:\n                            iqr_expression = re.search(number_expression, sentence_reduced)[0]\n                            # For each article store the expressions from each sentence\n                            article_incubation_iqr += iqr_expression + \"; \"\n                        except TypeError:\n                            pass\n                        # Store the measures in our dataframe df, reject empty strings\n                        if len(article_incubation_iqr) > 0:\n                            df.loc[id, \"incubation_iqr\"] = article_incubation_iqr","dbd0b1bc":"# Investigate the extracted values                \nprint(\"Share of articles with incubation out of total articles:\", (df[\"incubation_sentences\"].count() \/ (len(df[\"incubation_sentences\"])))*100, \"%\") # Percentage of articles that contain incubation information\nprint(\"# of articles with mean incubation statement:\", df[df[\"incubation_mean\"].notnull()][\"incubation_mean\"].count())\nprint(\"# of articles with median incubation statement:\", df[df[\"incubation_median\"].notnull()][\"incubation_median\"].count())\nprint(\"# of articles with inter-quartile-range incubation statement:\", df[df[\"incubation_iqr\"].notnull()][\"incubation_iqr\"].count())","deaa0ebb":"# Define function normalizer \ndef normalizer(dataframe, column = str, normalized_columnname = str):\n    print(\"Normalizing column {} in dataframe:\".format(column))\n    for id, entry in enumerate(dataframe[column]):\n        if (type(entry) == str) and (len(entry)>0):\n            print(\"Initial entry: {}\".format(entry))\n            entry_split = entry[:-1].split(\"; \")\n            entries = []\n            for i in range(0, len(entry_split)):\n                # Check if it is a range statement containing two numbers\n                if len(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])) == 1:\n                    number = float(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])[0])\n                elif len(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])) == 2:\n                    # If it is, then we take the average of the range numbers\n                    first_number = float(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])[0])\n                    second_number = float(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])[1])\n                    number = (first_number+second_number)\/2\n                # Next, we investigate the duration expression and convert everything to days\n                duration = re.search(r\"day|d|hour|hr\", entry_split[i])[0]\n                if (duration == \"hour\") or (duration == \"hr\"):\n                    number = number \/ 24\n                # And add the standardized entry to a list\n                entries.append(number)\n            # In case one article mentiones several measures, we average over those\n            entries_avg = np.mean(entries)\n            print(\"Normalized entries: {}\".format(entries_avg))\n            # Put entry into df\n            dataframe.loc[id, normalized_columnname] = entries_avg\n \n# Define funtion normalizer_iqr to transform the inter-quartile-range column\ndef normalizer_iqr(dataframe, column = str, q1_columnname = str, q3_columnname = str):\n    print(\"Normalizing column {} in dataframe:\".format(column))\n    for id, entry in enumerate(dataframe[column]):\n        if (type(entry) == str) and (len(entry)>0):\n            print(\"Initial entry: {}\".format(entry))\n            entry_split = entry[:-1].split(\"; \")\n            q1 = []\n            q3 = []\n            for i in range(0, len(entry_split)):\n                # Make sure that it is a range statement containing two numbers\n                if len(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])) == 1:\n                    print(\"Not a range statement for entry\", entry, \" in \", id)\n                elif len(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])) == 2:\n                    # If it is a range, then we split up the numbers\n                    q1_number = float(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])[0])\n                    q3_number = float(re.findall(r\"(\\d+(?:\\.\\d+)?)\", entry_split[i])[1])\n                 # And add the standardized entries to the lists\n                q1.append(q1_number)\n                q3.append(q3_number)\n            # In case one article mentiones several measures, we average over those\n            q1_avg = np.mean(q1)\n            q3_avg = np.mean(q3)\n            print(\"Normalized entries: q1={}; q3={}\".format(q1_avg, q3_avg))\n            # Put entries into df\n            dataframe.loc[id, q1_columnname] = q1_avg            \n            dataframe.loc[id, q3_columnname] = q3_avg","7854311c":"# Apply the normalizer function to the incubation columns in df \nprint(\"Mean column transformation:\\n\")\nnormalizer(df, column=\"incubation_mean\", \n           normalized_columnname=\"incubation_mean_new\")\nprint(\"\\n\\n\")\nprint(\"Median column transformtion:\\n\")\nnormalizer(df, column=\"incubation_median\", \n           normalized_columnname=\"incubation_median_new\")\nprint(\"\\n\\n\")\nprint(\"Inter-quartile range column transformtion:\\n\")\nnormalizer_iqr(df, \"incubation_iqr\", \n               q1_columnname=\"incubation_q1_new\", \n               q3_columnname=\"incubation_q3_new\")","2940e0bd":"## Slice dataframe for plotting only where we have extracted values and easier reference\ndf_mean = df[df[\"incubation_mean_new\"].notnull()]\ndf_median = df[df[\"incubation_median_new\"].notnull()]\ndf_q1 = df[df[\"incubation_q1_new\"].notnull()]\ndf_q3 = df[df[\"incubation_q3_new\"].notnull()]","4180612a":"### Histograms for each measure\nfig, axs = plt.subplots(nrows=4, ncols=1, figsize=(15, 10), sharex=True)\nfig.suptitle(\"Incubation times of COVID-19 stated for different measures\", fontsize=14)\n\n# Quartile 1 plot\naxs[0].hist(df_q1[\"incubation_q1_new\"], \n   color=\"olivedrab\", \n   alpha=0.4, \n   bins=len(df_q1),\n   label=\"\\\"1st Quartile\\\" statements\")\naxs[0].set_ylabel(\"# of statements\")\naxs[0].axvline(np.mean(df_q1[\"incubation_q1_new\"]), \n            label = \"distribution mean: \" + str(round(np.mean(df_q1[\"incubation_q1_new\"]),1)), \n            color=\"olivedrab\")\naxs[0].axvline(np.median(df_q1[\"incubation_q1_new\"]), \n            label = \"distribution median:\" + str(round(np.median(df_q1[\"incubation_q1_new\"]),1)), \n            color=\"olivedrab\",\n            linestyle=\"dashed\")\naxs[0].set_title(\"\\\"1st Quartile\\\"\")\naxs[0].legend(loc='upper right')\n\n# Median plot\naxs[2].hist(df_median[\"incubation_median_new\"], \n   color=\"peru\", \n   alpha=0.4,\n   bins=len(df_median),\n   label=\"\\\"Median\\\" statements\")\naxs[2].set_ylabel(\"# of statements\")\naxs[2].axvline(np.mean(df_median[\"incubation_median_new\"]), \n            label = \"distribution mean: \" + str(round(np.mean(df_median[\"incubation_median_new\"]),1)), \n            color=\"peru\")\naxs[2].axvline(np.median(df_median[\"incubation_median_new\"]),\n            label = \"distribution median:\" + str(round(np.median(df_median[\"incubation_median_new\"]),1)), \n            color=\"peru\",\n            linestyle=\"dashed\")\naxs[1].set_title(\"\\\"Median\\\"\")\naxs[2].legend(loc='upper right')\n\n# Mean plot\naxs[1].hist(df_mean[\"incubation_mean_new\"], \n   color=\"royalblue\", \n   alpha=0.4,\n   bins=len(df_mean),\n   label=\"\\\"Mean\\\" statements\")\naxs[1].set_ylabel(\"# of statements\")\naxs[1].axvline(np.mean(df_mean[\"incubation_mean_new\"]), \n            label = \"distribution mean: \" + str(round(np.mean(df_mean[\"incubation_mean_new\"]),1)), \n            color=\"royalblue\")\naxs[1].axvline(np.median(df_mean[\"incubation_mean_new\"]), \n            label = \"distribution median: \" + str(round(np.median(df_mean[\"incubation_mean_new\"]),1)), \n            color=\"royalblue\",\n            linestyle=\"dashed\")\naxs[2].set_title(\"\\\"Mean\\\"\")\naxs[1].legend(loc='upper right')\n\n# Quartile 3 plot\naxs[3].hist(df_q3[\"incubation_q3_new\"], \n   color=\"tomato\",\n   alpha=0.4, \n   bins=len(df_q3),\n   label=\"\\\"3rd Quartile\\\" statements\")\naxs[3].set_ylabel(\"# of statements\")\naxs[3].set_xlabel(\"Incubation Time (Days)\")\naxs[3].axvline(np.mean(df_q3[\"incubation_q3_new\"]), \n            label = \"distribution mean: \" + str(round(np.mean(df_q3[\"incubation_q3_new\"]),1)), \n            color=\"tomato\")\naxs[3].axvline(np.median(df_q3[\"incubation_q3_new\"]),\n            label = \"distribution median:\" + str(round(np.median(df_q3[\"incubation_q3_new\"]),1)), \n            color=\"tomato\",\n            linestyle=\"dashed\")\naxs[3].set_title(\"\\\"3rd Quartile\\\"\")\naxs[3].legend(loc='upper right')\n\n#fig.tight_layout()  \nfig.subplots_adjust(hspace=0.4)\nplt.show()","4dce48b8":"# Reduced Boxplot based on median values of extracted information measure-wise\nfig, ax = plt.subplots(figsize=(10, 5))\nboxes = [\n    {\n        \"label\" : \"\",\n        # Whiskers are set equal to 1st and 3rd quartiles in order to hide them\n        \"whislo\": np.median(df_q1[\"incubation_q1_new\"]),   \n        \"q1\"    : np.median(df_q1[\"incubation_q1_new\"]),   \n        \"med\"   : np.median(df_median[\"incubation_median_new\"]),  \n        \"mean\"  : np.median(df_mean[\"incubation_mean_new\"]),\n        \"q3\"    : np.median(df_q3[\"incubation_q3_new\"]),  \n        \"whishi\": np.median(df_q3[\"incubation_q3_new\"]),    \n        \"fliers\": []    \n    }\n]\nax.bxp(boxes, \n       showfliers=False, \n       showmeans=True, \n       vert=False, \n       meanline=True,\n       boxprops=dict(linewidth=3),\n       medianprops=dict(linewidth=3, color=\"royalblue\", linestyle=\"-\"),\n       meanprops=dict(linewidth=3, color=\"darkred\", linestyle=\"--\"))\nplt.xlabel(\"Incubation Time (Days)\")\nplt.title(\"Distribution of Incubation Time Estimates of COVID-19\")\nplt.show()","328858ae":"As the number of articles on COVID-19 is already huge, this notebook applies an automatized information extraction based on regular expressions. Since this is my first kaggle participation, any feedback is very welcomed. Thank you!","d32c45bf":"I import the metadata-file and also go though each json-file in each folder and extract all relevant information for our analysis. In specific, following variables for each article are stored:\n* paper_id: Identification code\n* title: Title\n* authors: Authors\n* abstract: article abstract\n* body_text: Full article text\n* publish_time: Date of publication\n* journal: Journal of publication\n* source_folder: the name of the folder, where the article is stored in\n","857101cd":"# 3. Now we extract the information on incubation of COVID-19\nThe following code will go over each sentence in all articles and check for numbers on the duration of COVID-19 incubation period. The information is extracted using regular expressions and is stored in new columns of the main datafaIn order to extract the right information, the following steps are applied in order:\n\n**Tokenization and Lowercasing:**\nThe nltk sentence tokenization is exploited to split the article bodies into sentences. Also all steps are applied on the lower-cased sentences.\n\n**Filtering:**\nClearly, there are many synonyms used for incubation and COVID-19 - hence they will be checked for, too. Also, I want to make sure to only extract COVID-19-related incubation references and miss incubation references relating to other illnesses. Hence, a sentence of interest contains a COVID-19 reference as well as a incubation reference as well as a duration expression (e.g. day, d or hour).\n\n**Measures:**\nStatements on incubation can refer to different measures like the mean, median, 1st quartile or 3rd quartile. The filtered sentence is scanned for each of these measures (includes synonyms like mean(s) and average(s)). \n\n**Number Extraction:**\nI extract the number from a number-date-expression (e.g. \"4.0 days\" or \"72 to 88 hours\") that follows (!) the measure. Notably, the regular espression used captures\n* floats, e.g. \"4.2\" \n* integers, e.g. \"5\"\n* ranges, e.g. \"3-4\" or \"3 - 4\" or \"3 to 4\" or (between) \"3 and for\" (Notably, \"-\" unicode characters 8722 and 45 are both included)\n* combinations of these, e.g. \"3 to 3.8\"\n","5b717d54":"# 6. Results and Discussion\n*Results for data status of 16th April 2020*\n* We saw that mean and median incubation times are the measures that are stated most often in the analyzed articles. This makes sense, as these \"global\" measures represent the distribution best.\n* For some measures that were investigated, we face outliers in our extracted information. Thus, aggregating the distributions of stated measures by the median, which is less outlier-sensitive than the mean, seems to be preferable.\n* Using the medians of each disctibution of stated measures, we can state that COVID-19 incubation time seems to be estimated to be estimated by\n    \n    1. 1st Quartile = 3.0 days\n    2. Mean = 4.7 days\n    3. 2nd Quartile i.e. Median = 5.2 days\n    4. 3rd Quartile = 7 days\n\nThe following graph presents a reduced boxplot based on these median values and thus represents a distribution representation of the incubation time estimates in analyzed articles. In this reduced boxplot, the red dashed line represents the mean and the dashed blue solid line represents the median. Furthermore, the box ends at the 1st and 3rd Quartile.\n","b6688ff3":"**To sum up**, the presented approach employs regular expression to extract information on incubation time from scientific articles. Thereby, information on measures like mean, median and inter-quartile range have been successfully extracted. Visualization helped to get an impression on the distribtion of scientific estimations on incubation time. As mentioned in the discussion section, there is clearly space for improvement of the approach and I aim to do so soon.\n\nIn that sense, I am looking forward to your opinion and feedback.","2590617a":"# 4. Investigate the extracted information\nLet us see how much information we were able to extract:","fc471a1d":"# 2. Read-in the meta-information and all articles","60c44b77":"# 5. Plot extracted incubation information\nFor getting a clearer picture on incubation time of COVID-19, the results are visualized. For that, the following code generates a joint histogram plot showing the number of times each measure is estimate estimated in an article. Furthermore, the mean and median over all estimates is calculated and displayed.\n\nEach histogram shows the number of statements for each measure in the analysed articles. Additionally, the mean and median are added for each estimated distribution to show the middle values of estimations. Note that the median is more robust on outliers, which makes this measure preferable in our context.","c6004313":"The dataframe *df* contains the extracted information. However, there is still need to process these columns in order to\n1. convert it from string to float\n2. take the average for range statements (e.g. \"3-5 days\" becomes \"4 days\")\n3. convert hours to days\n\nFor these purposes, two normalizing functions (*normalizer* and *normalizer_iqr*) are defined in the following and then applied on each generated column in our dataframe *df*. When applying the functions, each transformation is printed out for error checking.","624a212c":"![Title_v2.jpg](attachment:Title_v2.jpg)","6fb0c795":"# 1. Import packages","5747313e":"# 7. Discussion: \nThe outlined process of information extraction has been defined in close response to the articles. As has been shown, the approach is able to extract a lot of incubation information correctly. However, some shortcomings shall be adressed for further improvement:\n\n* **Inability of extraction of correct information:** \nThough the regex is able to extract much of different number-date statements, it is reasonable that quite some information could not be extracted. In future, I aim to use these possibilities to improve the algorithm in order to capture more relevant information.\n    1. If the number-date statement is preceeding the measure in a sentence, this information is not extracted. This has been reasoned as a number-date statement preceeding a measure has been found to typically not be related to this measure. However, a statement like \"with 5.5 days, COVID-19 has a relatively small mean incubation latent period\" is falsely neglected, too. \n    2. The current algorithm only extracts integers and floats. This means that incubation periods in written-out form, e.g. \"mean incubation period of ten days\" are neglected.\n    3. Sometimes an incubation number may not be directly followed by a duration statement, e.g. \"median incubation period measured in days is about 6\". Such numbers will not be extracted, since we cannot be sure about to which temporal period they refer to.****\n\n* **Extraction of false information:** \nComputers will hardly understand grammar perfectly. Depending on the structure of sentence, the extracted numbers may be related to something else. An example may be the statement \"2019-ncov showed to have a mean incubation time that is less than sars incubation time of 10 days\", where the extracted information of \"10 days\" is not referring to COVID-19.\n\n* **Outlier treatment:** \nAs can be seen especially in the barcharts for measures mean and median, we can see that there are some outliers. While the presented approach was designed in close coordination with which numbers it is able to extract and which numbers is (and should) not, it would be a good idea to do some automatized outlier treatment.\n\n* **Measures:**\nThis approach extracted the following measures from the articles: mean, median, 1st and 3rd quartile. Clearly, the approach could be easily used to extract information on other measures like minimum and maximum. Notably, this has been implemented, was however rejected as no sensible information could be extracted for these measures. Nevertheless, a further refinement of the extraction process could also be more successful in this sense.","c51bf265":"Having retrieved all this information, our main DataFrame for analysis, called *df*, is generated. Shape and head of *df* look like like that:"}}