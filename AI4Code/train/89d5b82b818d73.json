{"cell_type":{"cb5fa54f":"code","04655687":"code","a5ec8da2":"code","9302819f":"code","c1c6ebfe":"code","6660a7a1":"code","ee83be2b":"code","e861775e":"code","d7325f38":"code","ee064f89":"code","304081c6":"code","4f21d942":"code","b321a061":"code","cb415b9e":"code","f31bb5b1":"code","1f7e82e4":"code","112f5205":"code","e3993f5b":"code","a74bb3ca":"code","e7c3e63a":"code","c7868ed1":"code","6481c00d":"code","ec184183":"code","e58ef782":"code","24a59efc":"code","42aff63f":"code","1424576d":"code","f78f1f77":"code","6e73a136":"code","40c90139":"code","f5f4a746":"code","29450099":"code","cac1e6d1":"code","343dffae":"markdown","5429fb9c":"markdown","1facc5e6":"markdown","0b68deff":"markdown","63c4bade":"markdown","d21e642f":"markdown","265e9657":"markdown","721efcb1":"markdown","481181e7":"markdown","d2d90cb0":"markdown","2fed0425":"markdown","8fd6e5b0":"markdown","bdc87b53":"markdown","29311290":"markdown","a327c535":"markdown","f6319a6e":"markdown"},"source":{"cb5fa54f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","04655687":"# Import useful libraries\n\nimport time\nimport re\nimport string\nfrom numpy import mean\nfrom numpy import set_printoptions\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-darkgrid')\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, KFold, GridSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.utils.multiclass import type_of_target\n\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom collections import Counter\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nimport warnings\nwarnings.filterwarnings('ignore')","a5ec8da2":"# Read dataset\n\ntrain_data = pd.read_csv('..\/input\/av-janatahack-crosssell-prediction\/train.csv')\ntest_data = pd.read_csv('..\/input\/av-janatahack-crosssell-prediction\/test.csv')\ntrain_data.columns = train_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\ntest_data.columns = test_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')","9302819f":"print('Train Data Shape: ', train_data.shape)\nprint('Test Data Shape: ', test_data.shape)\ntrain_data.head()","c1c6ebfe":"train_data.isnull().sum()","6660a7a1":"train_data['response'].value_counts()","ee83be2b":"train_data.nunique()","e861775e":"fig, axes = plt.subplots(ncols = 2, figsize = (13, 3), dpi = 100)\nplt.tight_layout()\n\ntrain_data.groupby('response').count()['id'].plot(kind = 'pie', ax = axes[0], labels = ['Interested (87.7%)', 'Not Interested (12.1%)'])\nsns.countplot(x = train_data['response'], hue = train_data['response'], ax = axes[1])\n\naxes[0].set_ylabel('')\naxes[1].set_ylabel('')\naxes[1].set_xticklabels(['Interested (87.7%)', 'Not Interested (12.1%)'])\naxes[0].tick_params(axis = 'x', labelsize = 8)\naxes[0].tick_params(axis = 'y', labelsize = 8)\naxes[1].tick_params(axis = 'x', labelsize = 8)\naxes[1].tick_params(axis = 'y', labelsize = 8)\n\naxes[0].set_title('Label Distribution in Training Set', fontsize = 8)\naxes[1].set_title('Label Count in Training Set', fontsize =8)\n\nplt.show()","d7325f38":"# looking at the frequency of records by age\n\nplt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.copper(np.linspace(0, 1, 66))\ntrain_data['age'].value_counts().head(66).plot.bar(color = color)\nplt.title('Age distribution (Most policy holders are young. Age is highly skewed)', fontsize = 15)\nplt.xticks(rotation = 90)\nplt.show()","ee064f89":"train_data['type'] = 'train'\ntest_data['type'] = 'test'\n\nmaster_data = pd.concat([train_data, test_data])","304081c6":"plt.figure(figsize = (8, 5))\nsns.distplot(master_data['annual_premium'])\nplt.title('Annual Premium distribution (Highly skewed to the right)', fontsize = 15)\nplt.show()","4f21d942":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['gender'] == 'Male'), 'age'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Male\"})\nsns.distplot(master_data.loc[(master_data['gender'] == 'Female'), 'age'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Female\"})\nplt.title('Age distribution by Gender', fontsize = 15)\nplt.show()","b321a061":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['gender'] == 'Male'), 'annual_premium'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Male\"})\nsns.distplot(master_data.loc[(master_data['gender'] == 'Female'), 'annual_premium'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Female\"})\nplt.title('Annual Premium distribution by Gender', fontsize = 15)\nplt.show()","cb415b9e":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['driving_license'] == 0), 'age'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Not Licensed for driving\"})\nsns.distplot(master_data.loc[(master_data['driving_license'] == 1), 'age'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Licensed for Driving\"})\nplt.title('Age distribution by Driving License', fontsize = 15)\nplt.show()","f31bb5b1":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['driving_license'] == 0), 'annual_premium'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Not Licensed for driving\"})\nsns.distplot(master_data.loc[(master_data['driving_license'] == 1), 'annual_premium'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Licensed for Driving\"})\nplt.title('Annual Premium distribution by Driving License', fontsize = 15)\nplt.show()","1f7e82e4":"plt.figure(figsize = (18, 5))\nsns.boxplot(master_data['annual_premium'])\nplt.title('Annual Premium distribution (Highly skewed to the right)', fontsize = 15)\nplt.show()","112f5205":"plt.figure(figsize = (8, 5))\nsns.distplot(master_data['vintage'])\nplt.title('No. of days customer was associated with the company', fontsize = 15)\nplt.show()","e3993f5b":"# looking at the frequency of records by age\n\nplt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.copper(np.linspace(0, 1, 50))\ntrain_data['policy_sales_channel'].value_counts().head(50).plot.bar(color = color)\nplt.title('Top Policy Sales Channels', fontsize = 15)\nplt.xticks(rotation = 90)\nplt.show()","a74bb3ca":"# looking at the frequency of records by sales channel\n\nplt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.copper(np.linspace(0, 1, 53))\ntrain_data['region_code'].value_counts().head(53).plot.bar(color = color)\nplt.title('Customers count by top regions', fontsize = 15)\nplt.xticks(rotation = 90)\nplt.show()","e7c3e63a":"fig, axes = plt.subplots(ncols = 2, figsize = (13, 3), dpi = 100)\nplt.tight_layout()\n\ntrain_data.groupby('previously_insured').count()['id'].plot(kind = 'pie', ax = axes[0], labels = ['Insured Customers (54.1%)', 'Not Insured Customers (45.9%)'])\nsns.countplot(x = train_data['previously_insured'], hue = train_data['previously_insured'], ax = axes[1])\n\naxes[0].set_ylabel('')\naxes[1].set_ylabel('')\naxes[1].set_xticklabels(['Insured Customers (54.1%)', 'Not Insured Customers (45.9%)'])\naxes[0].tick_params(axis = 'x', labelsize = 8)\naxes[0].tick_params(axis = 'y', labelsize = 8)\naxes[1].tick_params(axis = 'x', labelsize = 8)\naxes[1].tick_params(axis = 'y', labelsize = 8)\n\naxes[0].set_title('Label Distribution in Training Set', fontsize = 8)\naxes[1].set_title('Label Count in Training Set', fontsize =8)\n\nplt.show()","c7868ed1":"sns.countplot(data = master_data, x = 'driving_license', hue = 'gender')\nplt.ylabel('Count')\nplt.show()","6481c00d":"# Unique values for all the columns\nfor col in train_data.columns[~(train_data.columns.isin(['age', 'id', 'region_code', 'annual_premium', 'policy_sales_channel', 'vintage']))].tolist():\n    print(\" Unique Values --> \" + col, ':', len(train_data[col].unique()), ': ', train_data[col].unique())","ec184183":"gender = {'Male': 0, 'Female': 1}\ndriving_license = {0: 0, 1: 1}\npreviously_insured = {0: 1, 1: 0}\nvehicle_age = {'> 2 Years': 2, '1-2 Year': 1, '< 1 Year': 0}\nvehicle_damage = {'Yes': 1, 'No': 0}\n\nmaster_data['gender'] = master_data['gender'].map(gender)\nmaster_data['driving_license'] = master_data['driving_license'].map(driving_license)\nmaster_data['previously_insured'] = master_data['previously_insured'].map(previously_insured)\nmaster_data['vehicle_age'] = master_data['vehicle_age'].map(vehicle_age)\nmaster_data['vehicle_damage'] = master_data['vehicle_damage'].map(vehicle_damage)\n\nmaster_data['policy_sales_channel'] = master_data['policy_sales_channel'].apply(lambda x: np.int(x))\nmaster_data['region_code'] = master_data['region_code'].apply(lambda x: np.int(x))\n\nmaster_data.head()","e58ef782":"# Numerical columns\nnumerical_cols = ['age', 'vintage']\n\n# categorical column \ncat_col = ['gender', 'driving_license', 'region_code', 'previously_insured', 'vehicle_age', 'vehicle_damage', 'policy_sales_channel']\n\n#master_data['policy_sales_channel'] = master_data['policy_sales_channel'].map(master_data['policy_sales_channel'].value_counts())\n#master_data['region_code'] = master_data['region_code'].map(master_data['region_code'].value_counts())\n\nss = StandardScaler()\nmaster_data[numerical_cols] = ss.fit_transform(master_data[numerical_cols])\n\nmm = MinMaxScaler()\nmaster_data[['annual_premium']] = mm.fit_transform(master_data[['annual_premium']])\n\nmaster_data.head()","24a59efc":"train_data = master_data.loc[(master_data['type'] == 'train')]\ntest_data = master_data.loc[(master_data['type'] == 'test')]\n\ntrain_data = train_data.drop(['id', 'type'], axis = 1)\ntrain_data['response'] = train_data['response'].apply(lambda x: np.int(x))\n\ntestIDs = test_data['id']\ntest_data = test_data.drop(['id', 'type', 'response'], axis = 1)\ntrain_data.head()","42aff63f":"for column in cat_col:\n    train_data[column] = train_data[column].astype('str')\n\nX = train_data.drop(['response'], axis = 1).values\ny = train_data['response'].values\n\n#cat_cols = [0, 2, 3, 4, 5, 6, 8]","1424576d":"kfold, scores = KFold(n_splits = 5, shuffle = True, random_state = 22), list()\nfor train, test in kfold.split(X):\n    X_train, X_test = X[train], X[test]\n    y_train, y_test = y[train], y[test]\n\n    model = LGBMClassifier(random_state = 22, max_depth = 7, n_estimators = 230, reg_lambda = 1.2, reg_alpha = 1.2, min_child_weight = 1, \n                           learning_rate = 0.15, gamma = 0.3, colsample_bytree = 0.5, eval_metric = 'auc', is_higher_better = 1, plot = True)\n    model.fit(X_train, y_train)\n    preds = [pred[1] for pred in model.predict_proba(X_test)]\n    score = roc_auc_score(y_test, preds, average = 'weighted')\n    scores.append(score)\n    print('Validation ROC AUC:', score)\nprint(\"Average Validation ROC AUC: \", sum(scores)\/len(scores))","f78f1f77":"yTest = model.predict(X_test)\n\nfpr, tpr, thresholds = roc_curve(yTest.ravel(), y_test)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label = 'AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.0])\nplt.ylim([-0.1,1.01])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","6e73a136":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)","40c90139":"bestLGB = LGBMClassifier(random_state = 22, max_depth = 7, n_estimators = 110, reg_lambda = 1.2, reg_alpha = 1.2, min_child_weight = 1,\n                         learning_rate = 0.15, gamma = 0.3, colsample_bytree = 0.5)\nbestLGB.fit(X_train, y_train)\ny_pred = bestLGB.predict_proba(X_test)","f5f4a746":"for column in cat_col:\n    test_data[column] = test_data[column].astype('str')","29450099":"Preds = [predClass[1] for predClass in model.predict_proba(test_data.values)]","cac1e6d1":"submission = pd.DataFrame(data = {'id': testIDs, 'Response': Preds})\nsubmission.to_csv('cross_sell.csv', index = False)\nsubmission.head()","343dffae":"<img src='https:\/\/datahack-prod.s3.ap-south-1.amazonaws.com\/__sized__\/contest_cover\/cover_5-thumbnail-1200x1200.png'>","5429fb9c":"### Splitting the dataset","1facc5e6":"model = LGBMClassifier(random_state = 22)\n\nparam_grid = {\"learning_rate\"    : [0.01, 0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40],\n              \"max_depth\"        : [4, 5, 6, 7, 8, 9, 10],\n              \"min_child_weight\" : [1, 3, 5, 7],\n              \"gamma\"            : [0.0, 0.1, 0.2 , 0.3, 0.4],\n              \"colsample_bytree\" : [0.3, 0.4, 0.5 , 0.7],\n              \"n_estimators\"     : [50, 70, 90, 100, 120, 150, 200, 250, 300, 350, 400, 450],\n              'reg_alpha'        : [1,1.2],\n              'reg_lambda'       : [1,1.2,1.4]\n              }\n\nkfold = KFold(n_splits = 6, shuffle = True, random_state = 22)\n\ngrid_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = \"accuracy\", n_jobs  = -1, cv = kfold, verbose = 1)\ngrid_result = grid_search.fit(X_train, y_train)\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","0b68deff":"## LGBM Classifier with kFold","63c4bade":"# Exploratory Data Analysis","d21e642f":"# Problem Statement","265e9657":"# Feature Engineering","721efcb1":"# References:\n1. K-Fold - https:\/\/machinelearningmastery.com\/k-fold-cross-validation\/\n2. LightGBM - https:\/\/towardsdatascience.com\/understanding-lightgbm-parameters-and-how-to-tune-them-6764e20c6e5b","481181e7":"##### We should oversample the minority class to account for customers without a driving license","d2d90cb0":"## ROC AUC Curve","2fed0425":"# Submission","8fd6e5b0":"# Predictions","bdc87b53":"# Model Building","29311290":"## Combine Training and Test Data for additional visualizations","a327c535":"# Loading Dataset","f6319a6e":"<b>Cross-selling<\/b> identifies products or services that satisfy additional, complementary needs that are unfulfilled by the original product that a customer possesses. As an example, a mouse could be cross-sold to a customer purchasing a keyboard. Oftentimes, cross-selling points users to products they would have purchased anyways; by showing them at the right time, a store ensures they make the sale.\n\nCross-selling is prevalent in various domains and industries including banks. For example, credit cards are cross-sold to people registering a savings account. In ecommerce, cross-selling is often utilized on product pages, during the checkout process, and in lifecycle campaigns. It is a highly-effective tactic for generating repeat purchases, demonstrating the breadth of a catalog to customers. Cross-selling can alert users to products they didn't previously know you offered, further earning their confidence as the best retailer to satisfy a particular need."}}