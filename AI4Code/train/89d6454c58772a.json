{"cell_type":{"7149623d":"code","43ac848a":"code","1ba946e4":"code","11e84252":"code","6f8c749c":"code","6da5a613":"code","7dcabf8a":"code","dd5765e3":"code","73fb22bd":"code","32bb05a1":"code","0aac3a0f":"code","81c60f8e":"code","88ee6d09":"code","fee378d6":"code","dfa46544":"code","a64a8724":"code","a909368a":"code","9000830f":"code","12aac4b5":"code","e5cb77be":"code","f86ad00d":"code","6acfbe8f":"code","40feef7f":"code","fad0e4fd":"code","4a91623c":"code","ff0573ae":"code","274bfccc":"code","8a0cbf11":"code","46fbf4b2":"code","45510ac0":"code","9e24759c":"code","6398b6ad":"code","d3d7f992":"code","8809afa2":"code","ff3e44b6":"code","66cd88ac":"code","a07f231b":"code","d20e066b":"code","748285a6":"code","5ccaccc9":"code","445a1173":"code","e390ff49":"code","9278f16b":"code","9b5f6328":"code","7c458b41":"code","f9e55b0f":"markdown","2e59970e":"markdown","74b6ff99":"markdown","75430690":"markdown","cea64fae":"markdown","ba769dbc":"markdown","230e5ecd":"markdown","e746b71e":"markdown","677ecf78":"markdown","926ab21f":"markdown","7ab958fa":"markdown","7f8f5c7c":"markdown","e06885ff":"markdown","060f9370":"markdown","ce3e952f":"markdown","d0fbae6e":"markdown","7c565382":"markdown","6b685763":"markdown","1ad4fe68":"markdown","0c40c2a0":"markdown"},"source":{"7149623d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport re\nprint(os.listdir(\"..\/input\"))","43ac848a":"df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/test.csv\")\nfeature_list = []\ndf.head()","1ba946e4":"df.drop(\"PassengerId\", 1, inplace=True)\ndf.head()","11e84252":"df.info()","6f8c749c":"plt.figure(figsize=(6, 6))\nplt.pie(df[\"Pclass\"].value_counts(), labels=df[\"Pclass\"].value_counts().index, autopct='%1.1f%%')\nplt.title(\"Pclass Percentages\")\nplt.show()","6da5a613":"print(df.groupby(by='Pclass').mean()[\"Survived\"])","7dcabf8a":"df[\"Pclass\"].corr(df[\"Survived\"])","dd5765e3":"feature_list.append('Pclass')","73fb22bd":"df[\"Age\"].isna().sum()","32bb05a1":"print(\"{:.2f}%\".format((df[\"Age\"].isna().sum() \/ len(df.index)) * 100))","0aac3a0f":"age_description = df[\"Age\"].describe()\nage_description","81c60f8e":"plt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\nplt.hist(x=df[\"Age\"].dropna())\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.title(\"Age Histogram\")\n\nplt.subplot(1, 2, 2)\nsns.boxplot(x=df[\"Age\"])\nplt.title(\"Age Boxplot\")\nplt.show()","88ee6d09":"df[\"Age\"].corr(df[\"Survived\"])","fee378d6":"temp_age = df[\"Age\"].fillna(value=df[\"Age\"].mean())","dfa46544":"print(\"NaN count:\", temp_age.isna().sum())\n\nplt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\nplt.hist(x=temp_age.dropna())\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.title(\"Age Histogram\")\n\nplt.subplot(1, 2, 2)\nsns.boxplot(x=temp_age)\nplt.title(\"Age Boxplot\")\nplt.show()","a64a8724":"temp_age.corr(df[\"Survived\"])","a909368a":"df[\"Cat_Age\"] = pd.cut(temp_age, bins=[0, 18, 60, 100], labels=[0, 1, 2]) # 0:child, 1:adult, 2:old\ndf.drop(\"Age\", axis=1, inplace=True)","9000830f":"sns.barplot(x=df[\"Cat_Age\"], y=df[\"Survived\"])\nplt.xticks(np.arange(3), (\"Child\", \"Adult\", \"Old\"))\nplt.show()","12aac4b5":"df[\"Cat_Age\"].corr(df[\"Survived\"])","e5cb77be":"feature_list.append('Cat_Age')\nfeature_list","f86ad00d":"plt.figure(figsize=(6, 6))\nplt.pie(df[\"Sex\"].value_counts(), labels=df[\"Sex\"].value_counts().index, autopct='%1.1f%%')\nplt.title(\"Sex Percentages\")\nplt.show()","6acfbe8f":"df[\"Sex\"] = df[\"Sex\"].apply(lambda x: 0 if x == \"male\" else 1) # 0: male, 1: female","40feef7f":"df[\"Sex\"].corr(df[\"Survived\"])","fad0e4fd":"feature_list.append('Sex')\nfeature_list","4a91623c":"df[\"Alone\"] = df.apply(lambda row: 1 if row[\"SibSp\"] + row[\"Parch\"] == 0 else 0, axis=1) # 1: Alone, 0: Not alone","ff0573ae":"df[\"Alone\"].corr(df[\"Survived\"])","274bfccc":"feature_list.append('Alone')\nfeature_list","8a0cbf11":"df[\"Ticket\"].isna().sum()","46fbf4b2":"df[\"Ticket\"].nunique()","45510ac0":"df.drop(\"Cabin\", 1, inplace=True)\ntest_df.drop(\"Cabin\", 1, inplace=True)\ndf.head()","9e24759c":"df[\"Fare\"] = pd.cut(df[\"Fare\"], 3, labels=[0, 1, 2]) # 0: Low, 1: Medium, 2: High\n\ntest_df[\"Fare\"].fillna(test_df[\"Fare\"].mean(), inplace=True)\ntest_df[\"Fare\"] = pd.cut(test_df[\"Fare\"], 3, labels=[\"Low\", \"Medium\", \"High\"])\ndf.head()","6398b6ad":"df[\"Fare\"].corr(df[\"Survived\"])","d3d7f992":"feature_list.append(\"Fare\")\nfeature_list","8809afa2":"df.head()","ff3e44b6":"import sklearn.preprocessing","66cd88ac":"embarked_encoder = sklearn.preprocessing.LabelEncoder()\n\ndf[\"Embarked\"].fillna(\"S\", inplace=True)\ndf[\"Embarked\"] = embarked_encoder.fit_transform(df[\"Embarked\"])\ndf.head()","a07f231b":"df[\"Embarked\"].corr(df[\"Survived\"])","d20e066b":"feature_list.append(\"Embarked\")\nfeature_list","748285a6":"import sklearn.model_selection\nimport sklearn.ensemble\nimport sklearn.metrics","5ccaccc9":"X, y = df[feature_list], df[\"Survived\"]","445a1173":"X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)","e390ff49":"model_rf = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\nmodel_gb = sklearn.ensemble.GradientBoostingClassifier()","9278f16b":"model_rf.fit(X_train, y_train)\nmodel_gb.fit(X_train, y_train)","9b5f6328":"yhat_rf = model_rf.predict(X_test)\nyhat_gb = model_gb.predict(X_test)","7c458b41":"accuracy_rf = sklearn.metrics.accuracy_score(y_test, yhat_rf)\nrecall_rf = sklearn.metrics.recall_score(y_test, yhat_rf)\nprecision_rf = sklearn.metrics.precision_score(y_test, yhat_rf)\n\nprint(\"Random Forest Accuracy:\", accuracy_rf)\nprint(\"Random Forest Recall:\", recall_rf)\nprint(\"Random Forest Precision:\", precision_rf)\nprint()\n\naccuracy_gb = sklearn.metrics.accuracy_score(y_test, yhat_gb)\nrecall_gb = sklearn.metrics.recall_score(y_test, yhat_gb)\nprecision_gb = sklearn.metrics.precision_score(y_test, yhat_gb)\n\nprint(\"Gradient Boosting Accuracy:\", accuracy_gb)\nprint(\"Gradient Boosting Recall:\", recall_gb)\nprint(\"Gradient Boosting Precision:\", precision_gb)\nprint()","f9e55b0f":"Let's check the survival rates of passenger classes.","2e59970e":"Now, we will check the NaN count again and plot the previous graphs once more to check the changes are negligible.","74b6ff99":"We know that if you are a child you have a higher chance to survive. We can validate this deduction by splitting the data into 3 groups: child, adult, and old. These groups are put into a column named *Cat_Age* after categorical age.","75430690":"Now, we can check the correlation between *Alone* and *Survived*.","cea64fae":"## Age\nLet's check how age affects the survival rate. The steps are similar to the *Pclass*. But, first we need to validate our data.\n\n* Are there any NaN values?\n* Are there any non-logical values (such as input errors, etc.)?\n* How is age distributed along victims?","ba769dbc":"## Pclass\nThe objectives of this section includes:\n\n1. To check the relationship between *Survived* and *Pclass*.\n2. To decide whether or not to put the *Pclass* to final features list.","230e5ecd":"You can see that the plot is right skewed and there is no abnormal value in the histogram. The mean of age is 29.7 and the median is 28. You can see there are some outliers in the data but we know that this is normal since people can live 100 years or more in some rare cases. You can also see that there is negative correlation between age and survival rate.\n\nLet's fill the data with the mean and see how correlation changes.","e746b71e":"## Ticket\nI think that *Ticket* is a rough one. Because it is not standard through passangers. So, I will write all of my trials and not delete any of them. **Be ready for lots of crappy things in this section. So, DON'T JUDGE ME!**\n\nLet's start with how many NaNs and unique tickets are there.","677ecf78":"There is quite a bit of difference. This is because we fill NaN values with the mean. Let's look at to the correlation.","926ab21f":"## Sex\nThe same questions as before apply for sex as well. Let's look our population in terms of *Sex*.","7ab958fa":"## Siblings \/ Spouses & Parents \/ Children\nThese two features can be considered as a single one. Because they both refer to family relationships. We can extract a new feature that states if the passanger travels alone or not according to family member counts.","7f8f5c7c":"Now, check for the correlation between *Cat_Age* and *Survived*.","e06885ff":"Ok. Now, check for correlation. But, we need to encode it to numerical values since they are nominal strings.","060f9370":"A very high positive correlation. This means that as the gender changes from male to female to survivability increases. This is a very good feature and will be definitely added to our feature list. Now the feature list updated as `['Pclass', 'Cat_Age', 'Sex']`.","ce3e952f":"This is much better, right? We definitely add *Cat_Age* into our feature list. Our feature list now includes `[Pclass, Cat_Age]`. The latest snapshot of our dataset is like that:","d0fbae6e":"That's a sweet negative correlation. This means that if you are alone it is likely that you cannot survive. This is an important feature for us. Thus, we will add it to our feature list. The list is now `['Pclass', 'Cat_Age', 'Sex', 'Alone']`.","7c565382":"There is a negative correlation between *Pclass* and *Survived* and it is significant. As the *Pclass* increases *Survival* is decreases. This statement supports the previous ratios. So, we definitely put *Pclass* into our final feature list.\n\nThus, our final feature list now includes: `['Pclass']`","6b685763":"The results say that majority of people who did survive belongs to the 1st class and 2nd class. We will calculate the correlation between them to see how stronger is this relation.","1ad4fe68":"This number tells us there are 681 unique ticket numbers. What about the remaining 210? They may be the ones that traveled together. So, this can support the *Alone* feature! Also, some ticket numbers alphabetic prefixes. We should also consider extracting them from the number.","0c40c2a0":"There are 177 missing values. That is 19.87% of the whole data. This may be an important issue. But, let's continue with the data at hand."}}