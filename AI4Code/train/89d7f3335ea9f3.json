{"cell_type":{"ac80beca":"code","1bed9b3a":"code","188a4ec2":"code","c74af44d":"code","390dd40d":"code","577aec59":"code","913a1967":"code","1bec12d8":"code","4cb73fca":"code","b8131952":"code","6f374eba":"markdown","91a07df7":"markdown","70106167":"markdown","5942505e":"markdown","5f0b05a5":"markdown"},"source":{"ac80beca":"import warnings\nwarnings.filterwarnings(\"ignore\")","1bed9b3a":"import pandas as pd\nimport os\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler","188a4ec2":"train = pd.read_csv(\"..\/input\/tabular-playground-series-mar-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-mar-2021\/test.csv\")\n\n#Features\nX = train.drop([\"id\", \"target\"], axis=1)\nX_test = test.drop([\"id\"], axis=1)\nX_all = pd.concat([X, X_test], axis=0)\n\n#Label\ny = train.target","c74af44d":"#Data overview\nfrom pandas_profiling.profile_report import ProfileReport\nProfileReport(X_all)","390dd40d":"#Encoding categorical data\n\n#List of categorical col\nlist_cat = [col for col in X.columns if col.startswith(\"cat\")]\n\n\nle = LabelEncoder()\n\nfor col in list_cat:\n    X_all[col] = le.fit_transform(X_all[col])\n   ","577aec59":"#Feature scaling\n\nscaler = StandardScaler().fit(X_all)\nX_all = pd.DataFrame(columns = X_all.columns,\n                            data = scaler.transform(X_all))\n\nX_all.head()","913a1967":"#Train, val, test split\n\nX = X_all.iloc[:len(train), :]\nX_test = X_all.iloc[len(train):, :]\n\n#To save time we keep only a random subset of the training set\nsample_size = 0.1\ntrain_sample = pd.concat([X, y], axis = 1)\ntrain_sample = train_sample.sample(frac = sample_size, random_state = 0)\n\n# Train\/val split\ntrain_size = 0.8\ntrain_set = train_sample.iloc[:int(len(train_sample) * train_size), :]\nval_set = train_sample.iloc[int(len(train_sample) * train_size):, :]\n\n\nXtrain = train_set.drop(labels = ['target'], axis = 1)\nytrain = train_set.target\n\nXval = val_set.drop(labels = ['target'], axis = 1)\nyval = val_set.target","1bec12d8":"from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n\nfrom sklearn.metrics import roc_auc_score","4cb73fca":"classifiers = [\n    SVC(kernel=\"linear\", C=0.025),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1, max_iter=1000),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    HistGradientBoostingClassifier(max_leaf_nodes=100, validation_fraction=None)]\n\nfor model in classifiers:\n    clf = model\n    clf.fit(Xtrain, ytrain)\n    \n    #Print model name, train set performance and val set performance\n    print(\"Model :\", str(model).split('(')[0])\n    train_score = roc_auc_score(ytrain, clf.predict(Xtrain))\n    print('Training set evaluation :', train_score)\n    val_score = roc_auc_score(yval, clf.predict(Xval))\n    print('Validation set evaluation :', val_score)\n\n    print('')","b8131952":"# Training on the whole data\nclf = AdaBoostClassifier()\nclf.fit(X, y)\n\nytest = clf.predict(X_test)\n\n#Save\nresult = pd.DataFrame()\n\nresult[\"id\"] = test.id\nresult[\"target\"] = ytest.flatten()\n\nresult.to_csv(os.path.join(\"submission.csv\"), index=False)","6f374eba":"# About this notebook\n\nAs the data for this challenge are provided without context, I find it difficult to guess which models may be suited to the problem at hand and which one will certainly not work well.\n\nThe goal here is to try a \"brute force\" approach of this question by systematicly testing 8 classification models with minimal hyperparameters optimization.\n\nIn this notebook, we will:\n1. Preprocess data: encoding, scaling, train\/val split\n2. Train and test 8 models\n3. Choose the most promising one and sumit the result","91a07df7":"# Model testing\n\nWe test a selection of classification models from sklearn without any hyperparameter optimization.","70106167":"# Submission","5942505e":"## Quick interpretation :\n\nThe area under the ROC curve is comprised between 0 and 1, 1 being the best possible performance.\n\nThe performance of most classifiers are pretty close around 0.75 except for HistGradientBoostingClassifier which is obviously overfitting. However the AdaBoostClassifier each a slightly better result.\n\nLet's choose this model for our first submission and see how we perform...\n","5f0b05a5":"# Preprocessing data\n\n1. Data loading and overview\n2. Categorical values encoding\n3. Feature scaling\n4. Train\/test split"}}