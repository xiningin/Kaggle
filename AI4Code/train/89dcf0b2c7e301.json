{"cell_type":{"3468929c":"code","f9d1a2af":"code","34f51fab":"code","cf294ad0":"code","729465a7":"code","584f50f2":"code","a8d5863c":"code","683925f4":"code","903de5e7":"code","1990c442":"code","78155262":"code","2325903f":"code","b35e1eb6":"code","165b12a0":"code","7a77ed4e":"code","07df2f5e":"code","fb551f85":"code","10a6d3c0":"code","fc424a4d":"code","6eb8c5f0":"code","6d32ad11":"code","53f11992":"code","472c3cc4":"code","370dcece":"code","59007aad":"code","4c8f4ea9":"code","516d8534":"code","3acb1f6c":"code","86f422f4":"code","629e2177":"code","0e288bce":"markdown","6cc19efe":"markdown","213eef4e":"markdown","61389809":"markdown","7a861938":"markdown","eaaf0565":"markdown","5ebcbbfe":"markdown","f89a197c":"markdown","f1e55d1b":"markdown","862e48de":"markdown","57179db3":"markdown","c081aafd":"markdown","eeb241a9":"markdown","ac19b6a4":"markdown","84ca940d":"markdown","86872e67":"markdown","bfd15d0d":"markdown","7ad096d7":"markdown"},"source":{"3468929c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nfrom tqdm.notebook import tqdm\n!conda install gdcm -c conda-forge -y\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nfrom skimage import exposure\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')","f9d1a2af":"dataset_dir = '..\/input\/siim-covid19-detection'","34f51fab":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)\/\/cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n","cf294ad0":"dicom_paths = glob(f'{dataset_dir}\/train\/*\/*\/*.dcm')\nimgs = [dicom2array(path) for path in dicom_paths[:4]]\nplot_imgs(imgs)","729465a7":"imgs = [exposure.equalize_hist(img) for img in imgs]\nplot_imgs(imgs)","584f50f2":"from bokeh.plotting import figure as bokeh_figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn import preprocessing\nimport random\nfrom random import randint","a8d5863c":"train = pd.read_csv(f'{dataset_dir}\/train_image_level.csv')\ntrain_study = pd.read_csv(f'{dataset_dir}\/train_study_level.csv')\ntrain.head()","683925f4":"train_study.head()","903de5e7":"# merge study csv\ntrain_study['StudyInstanceUID'] = train_study['id'].apply(lambda x: x.replace('_study', ''))\ndel train_study['id']\ntrain = train.merge(train_study, on='StudyInstanceUID')\ntrain.head()","1990c442":"# add StudyInstanceUID_count column\ngroup_col = 'StudyInstanceUID'\ndf=pd.DataFrame(train.groupby(group_col)['id'].count())\ndf.columns = [f'{group_col}_count']\ntrain=train.merge(df.reset_index(), on=group_col)\none_study_multi_image_df = train[train[f'{group_col}_count'] > 1]\nprint(len(one_study_multi_image_df))\ntrain = train[train[f'{group_col}_count'] == 1] # delete 'StudyInstanceUID_count > 1' data\none_study_multi_image_df.head()","78155262":"def pie_plot(train_df, variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: bar plot & value count\n    \"\"\"\n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (20,10))\n    plt.pie(varValue, labels=varValue.index, autopct=\"%1.1f%%\")\n#     plt.xticks(varValue.index, varValue.index.values)\n#     plt.ylabel(\"Frequency\")\n    plt.title('target')\n    plt.show()\n    \ntrain['target'] = 'Negative for Pneumonia'\ntrain.loc[train['Typical Appearance']==1, 'target'] = 'Typical Appearance'\ntrain.loc[train['Indeterminate Appearance']==1, 'target'] = 'Indeterminate Appearance'\ntrain.loc[train['Atypical Appearance']==1, 'target'] = 'Atypical Appearance'\nprint(train.target.value_counts())\npie_plot(train, 'target')    ","2325903f":"train.boxes.values[0] # x_min, y_min, width, height","b35e1eb6":"train.label.values[0] # x_min, y_min, x_max, y_max","165b12a0":"class_names = ['Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance'] # we have 3 positive classes\nunique_classes = np.unique(train[class_names].values, axis=0)\nunique_classes # no multi label ","7a77ed4e":"imgs = []\nlabel2color = {\n    '[1, 0, 0]': [255,0,0], # Typical Appearance\n    '[0, 1, 0]': [0,255,0], # Indeterminate Appearance\n    '[0, 0, 1]': [0,0,255], # Atypical Appearance\n    '[0, 0, 0]': None, # negative\n}\nlabel2target = {\n    '[1, 0, 0]': 'typical',\n    '[0, 1, 0]': 'indeterminate',\n    '[0, 0, 1]': 'atypical'\n}\nthickness = 3\nscale = 5\nFONT = cv2.FONT_HERSHEY_SIMPLEX; FONT_SCALE = 1; FONT_THICKNESS = 2; FONT_LINE_TYPE = cv2.LINE_AA;\n\nfor _, row in train[train['Negative for Pneumonia']==0].iloc[:8].iterrows():\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{dataset_dir}\/train\/{study_id}\/*\/*')[0]\n    img = dicom2array(path=img_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    claz = row[class_names].values\n    color = label2color[str(claz.tolist())]\n    target = label2target[str(claz.tolist())]\n\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row['label'].split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l)\/scale)\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []    \n\n    text_width, text_height = cv2.getTextSize(target, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n    for box in bboxes:\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n        )\n        box_width = int(box[2]) - int(box[0])\n        img = cv2.putText(img, target, (int(box[0])-(text_width-box_width)\/\/2, int(box[1])-10),\n                        FONT, FONT_SCALE, color, FONT_THICKNESS, FONT_LINE_TYPE)          \n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)\n","07df2f5e":"imgs = []\nthickness = 3\nscale = 5\n\nfor _, row in train[train['Typical Appearance'] == 1].iloc[:16].iterrows():\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{dataset_dir}\/train\/{study_id}\/*\/*')[0]\n    img = dicom2array(path=img_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    claz = row[class_names].values\n    color = label2color[str(claz.tolist())]\n\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row['label'].split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l)\/scale)\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []    \n    \n    for box in bboxes:\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n    )\n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","fb551f85":"imgs = []\nthickness = 3\nscale = 5\n\nfor _, row in train[train['Indeterminate Appearance'] == 1].iloc[:16].iterrows():\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{dataset_dir}\/train\/{study_id}\/*\/*')[0]\n    img = dicom2array(path=img_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    claz = row[class_names].values\n    color = label2color[str(claz.tolist())]\n\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row['label'].split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l)\/scale)\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []    \n    \n    for box in bboxes:\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n    )\n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","10a6d3c0":"imgs = []\nthickness = 3\nscale = 5\n\nfor _, row in train[train['Atypical Appearance'] == 1].iloc[:16].iterrows():\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{dataset_dir}\/train\/{study_id}\/*\/*')[0]\n    img = dicom2array(path=img_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    claz = row[class_names].values\n    color = label2color[str(claz.tolist())]\n\n    bboxes = []\n    bbox = []\n    \n    for i, l in enumerate(row['label'].split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l)\/scale)\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []    \n    \n    for box in bboxes:\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n    )\n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","fc424a4d":"train_with_size = pd.read_csv('..\/input\/siim-external\/train.csv') # present for you\ntrain_with_size = train_with_size[train_with_size['Negative for Pneumonia'] == 0]\ntrain_with_size['class_id'] = 0\ntrain_with_size.loc[train_with_size['Indeterminate Appearance'] == 1, 'class_id'] = 1\ntrain_with_size.loc[train_with_size['Atypical Appearance'] == 1, 'class_id'] = 2\ntrain_with_size.head()","6eb8c5f0":"num_2_label = {0: 'Typical Appearance', 1: 'Indeterminate Appearance', 2: 'Atypical Appearance'}\nHEATMAP_SIZE = (int(train_with_size.height.mean()), int(train_with_size.width.mean()), 3)\n\n# Initialize\nheatmap = np.zeros((HEATMAP_SIZE), dtype=np.int16)\nbbox_np = train_with_size[[\"class_id\", \"scaled_x_min\", \"scaled_x_max\", \"scaled_y_min\", \"scaled_y_max\"]].to_numpy()\nbbox_np[:, 1:3] *= int(train_with_size.width.mean())\nbbox_np[:, 3:5] *= int(train_with_size.height.mean())\nbbox_np = np.floor(bbox_np).astype(np.int16)\n\n# Color map stuff\ncustom_cmaps = [\n    matplotlib.colors.LinearSegmentedColormap.from_list(\n        colors=[(0.,0.,0.), c, (0.95,0.95,0.95)], \n        name=f\"custom_{i}\") for i,c in enumerate(sns.color_palette(\"Spectral\", 4))\n]\n\nfor row in tqdm(bbox_np, total=bbox_np.shape[0]):\n    heatmap[row[3]:row[4]+1, row[1]:row[2]+1, row[0]] += 1\n    \nfig = plt.figure(figsize=(20,25))\nplt.suptitle(\"Heatmaps Showing Bounding Box Placement\\n \", fontweight=\"bold\", fontsize=16)\nfor i in range(4):\n    plt.subplot(4, 4, i+1)\n    if i==0:\n        plt.imshow(heatmap.mean(axis=-1), cmap=\"bone\")\n        plt.title(f\"Average of All Classes\", fontweight=\"bold\")\n    else:\n        plt.imshow(heatmap[:, :, i-1], cmap=custom_cmaps[i-1])\n        plt.title(num_2_label[i-1], fontweight=\"bold\")\n        \n    plt.axis(False)\nfig.tight_layout(rect=[0, 0.03, 1, 0.97])\nplt.show()","6d32ad11":"# We need to compare on the same scale.\ntrain_with_size['area'] = (train_with_size['scaled_x_max'] - train_with_size['scaled_x_min']) * (train_with_size['scaled_y_max'] - train_with_size['scaled_y_min'])","53f11992":"plt.figure(figsize=(12,5))\nplt.title('typical only: distribution of box area (max 1)')\nax = sns.distplot(train_with_size[train_with_size['Typical Appearance']==1]['area'])\nplt.show()","472c3cc4":"plt.figure(figsize=(12,5))\nplt.title('indeterminate only: distribution of box area (max 1)')\nax = sns.distplot(train_with_size[train_with_size['Indeterminate Appearance']==1]['area'])\nplt.show()","370dcece":"plt.figure(figsize=(12,5))\nplt.title('atypical only: distribution of box area (max 1)')\nax = sns.distplot(train_with_size[train_with_size['Atypical Appearance']==1]['area'])\nplt.show()","59007aad":"small_images = train_with_size.query('x_min != 0').sort_values('area').image_id.values[:16]\ntrain['image_id'] = train['id'].apply(lambda x: x.replace('_image', ''))","4c8f4ea9":"imgs = []\n\nfor _, row in train[train.image_id.isin(small_images)].iterrows():\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{dataset_dir}\/train\/{study_id}\/*\/*')[0]\n    img = dicom2array(path=img_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    claz = row[class_names].values\n    color = label2color[str(claz.tolist())]\n    target = label2target[str(claz.tolist())]\n\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row['label'].split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l)\/scale)\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []    \n\n    text_width, text_height = cv2.getTextSize(target, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n    for box in bboxes:\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n        )\n        box_width = int(box[2]) - int(box[0])\n        img = cv2.putText(img, target, (int(box[0])-(text_width-box_width)\/\/2, int(box[1])-10),\n                        FONT, FONT_SCALE, color, FONT_THICKNESS, FONT_LINE_TYPE)          \n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","516d8534":"imgs = []\nfor i in range(32):\n    if i % 2 == 0:\n        row = train[train['Negative for Pneumonia']==1].iloc[i]\n    else:\n        row = train[train['Typical Appearance']==1].iloc[i]\n        \n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{dataset_dir}\/train\/{study_id}\/*\/*')[0]\n    img = dicom2array(path=img_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    claz = row[class_names].values\n    color = label2color[str(claz.tolist())]\n\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row['label'].split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l)\/scale)\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []    \n    \n    for box in bboxes:\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n    )\n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","3acb1f6c":"CONF_THRESHOLD = 0.3\n\ndef pred_str_to_confidence_box_maps(pred_str):\n    confidence_box_maps = []\n\n    for i, pred in enumerate(pred_str.split(' ')):\n        if i % 6 == 0:\n            confidence_box_map = {}\n            box = []\n        elif i % 6 == 1:\n            conf = float(pred)\n            confidence_box_map['conf'] = conf\n    #         print(confidence_box_map)\n        else:\n            box.append(int(float(pred)))\n        if i % 6 == 5:\n            confidence_box_map['box'] = box\n            if conf > CONF_THRESHOLD:\n                confidence_box_maps.append(confidence_box_map)\n    return confidence_box_maps\n\ndef add_bbox(img, confidence_box_maps):\n    for confidence_box_map in confidence_box_maps:\n        conf = confidence_box_map['conf']\n        box = confidence_box_map['box']\n        text = f'{round(conf, 4)}'\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            [255,0,0], thickness\n        )    \n        box_width = int(box[2]) - int(box[0])\n        if img.shape[0] > 2000:\n#         if True:\n            font_scale = int(7 * img.shape[0] \/ 4000)\n            font_tickness = int(20 * img.shape[0] \/ 4000)\n        else:\n            font_scale = int(7 * img.shape[0] \/ 2000)\n            font_tickness = int(20 * img.shape[0] \/ 2000)            \n        text_width, text_height = cv2.getTextSize(text, FONT, font_scale, font_tickness)[0]\n#         text_width, text_height, font_scale, font_tickness = 677, 135, 6, 17,\n        img = cv2.putText(img, text, (int(box[0])-(text_width-box_width)\/\/2, int(box[1])-40),\n                        FONT, font_scale, [255,0,0], font_tickness, FONT_LINE_TYPE)              \n    return img\n\ndef print_study_conf(sub, image_id):\n    study_id = glob(f'..\/input\/siim-covid19-detection\/test\/*\/*\/{image_id}.dcm')[0].split('\/')[-3]\n    study_pred_str = sub[sub['id'].str.startswith(study_id)].PredictionString.values[0]\n    names, confs = [], []\n    for i, pred in enumerate(study_pred_str.split(' ')):\n        if i % 6 == 0:\n            names.append(pred)\n        if i % 6 == 1:\n            confs.append(pred)\n    print('<\u2193study conficence\u2193>')\n    for name, conf in zip(names, confs):\n        print(f'{name} confidence: {conf}')\n\n\ndef plot_with_pred(sub, image_id):\n    print_study_conf(sub, image_id)\n    path = glob(f'..\/input\/siim-covid19-detection\/test\/*\/*\/{image_id}.dcm')[0]\n    img = dicom2array(path)\n    pred_str = sub[sub['id'].str.startswith(image_id)].PredictionString.values[0]\n    confidence_box_maps = pred_str_to_confidence_box_maps(pred_str)\n    if len(confidence_box_maps) == 0:\n        print(f'{image_id}: There are no boxes with confidence greater than {CONF_THRESHOLD}.')\n    img = add_bbox(img, confidence_box_maps)\n    plot_img(img)\n","86f422f4":"part_of_my_sub = pd.read_csv('..\/input\/test-subs\/part_of_submission.csv')  # use your submission.csv\npart_of_my_sub","629e2177":"image_ids = ['d5911a060ee4', '25b281d5a9f3', '03a778f5a68b', '2aaab6a41f1a', '4f7f40e478b1', '88782677cbec']\nfor image_id in image_ids:\n    plot_with_pred(part_of_my_sub, image_id) # input: submission.csv, image_id","0e288bce":"Let's learn to recognize the positive samples \ud83d\udcaa","6cc19efe":"we have 512images with 'StudyInstanceUID_count > 1'.  \nSince the problem has not been solved, I deleted this data.  \nhttps:\/\/www.kaggle.com\/c\/siim-covid19-detection\/discussion\/239980","213eef4e":"\u30fbAs we can see in the heat map, the 'typical' seems to have the largest area.  \n\u30fbIn atypical, small boxes are in the majority.  \nDoes the box get bigger as the annotator confidently labels typical examples?  \nOr does the range get larger because the typical example has a more advanced disease state?  \nI don't know the truth, but it's fun to imagine the annotation process \ud83d\ude0c  \n\nUpdated:\nThe following url describes annotations.  \nhttps:\/\/www.kaggle.com\/c\/siim-covid19-detection\/discussion\/240250","61389809":"# Plot img with bounding box","7a861938":"difficult... give me the doctor's eyes \ud83d\ude21","eaaf0565":"Maybe, you can try some preprocess like equalize histogram. You can see the difference between before and after","5ebcbbfe":"# Atypical Appearance only","f89a197c":"# Typical Appearance only","f1e55d1b":"left-right difference in indeterminate & atypical?","862e48de":"# plot small boxes only","57179db3":"# plot from submission.csv","c081aafd":"# box area distribution","eeb241a9":"# simple plot","ac19b6a4":"# compare negative \/ typical","84ca940d":"# Indeterminate Appearance only","86872e67":"# load & preprocess","bfd15d0d":"# heatmap","7ad096d7":"## \ud83d\ude0a Please upvote if you found this helpful \ud83d\ude0a"}}