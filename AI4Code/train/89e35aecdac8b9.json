{"cell_type":{"18cc6b83":"code","df1d1f8d":"code","3d03cff3":"code","b57bee21":"code","733971e0":"code","2087957a":"code","cfd4e390":"code","bdb0acf0":"code","7fca8a28":"code","5880033b":"code","43a662e2":"code","34778679":"code","65b200c2":"code","3f870b44":"code","bf239123":"code","ca6b2284":"code","e17d497e":"code","7f14efa0":"code","ef2aafbf":"code","555d03e4":"code","a7d0ed4b":"code","6d1d4e67":"code","053944e9":"code","6eb63879":"code","87581715":"code","9b30d07a":"code","a076ce68":"code","0c7333f1":"code","494bc799":"code","6f39d3af":"code","074b82ed":"code","16a3ec06":"code","e0d29e57":"code","1f46c3a8":"code","2ed1caed":"code","23f23bff":"code","e2111f5a":"code","79d69530":"code","60cd2a73":"code","6bd0dbaf":"code","3ef4f229":"code","b1444eba":"code","a8e74ba9":"code","dec2142d":"code","f0e760fe":"code","d3057aed":"code","17d2d243":"code","009826ce":"code","cec1254e":"code","ff165d6e":"code","d449c426":"code","1dad07a9":"code","fe32b08a":"code","1a16ad22":"code","d4f88f38":"code","9629f851":"code","64f801aa":"code","f30c6b8d":"code","bcf12f85":"code","29da62da":"code","7ffad1f3":"code","4af00395":"code","66ef90a8":"code","4b072b19":"code","af0da787":"code","75c04274":"code","28fb9d7f":"code","697b29ad":"code","f6e89ef6":"code","34e7163d":"code","fcf6cfd3":"markdown","97652213":"markdown","7c05fa3d":"markdown","940ac152":"markdown","5da515b2":"markdown","9817962b":"markdown","4e78a2cb":"markdown","a2231a14":"markdown","15c034b1":"markdown","598aada6":"markdown","fdcc03e9":"markdown","82b0ac00":"markdown","190fc801":"markdown","0e092d4f":"markdown","348a3ca0":"markdown","3d8e3f18":"markdown","7aa3c60e":"markdown","664270bf":"markdown","0dc3d851":"markdown","a3ae8f6f":"markdown","4b03db69":"markdown","fc9e31de":"markdown","041de160":"markdown"},"source":{"18cc6b83":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.datasets import load_wine\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, SCORERS\n\nimport xgboost","df1d1f8d":"pd.options.display.max_columns = None","3d03cff3":"sns.set(font_scale=1.4)\nsns.set_style({'font.family': 'serif',\n               'fontname': 'Times New Roman'})","b57bee21":"mpl.rcParams['figure.dpi'] = 100","733971e0":"titanic_df = sns.load_dataset('titanic')\ntitanic_df.head()","2087957a":"titanic_df.dropna(subset=['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare'], inplace=True)\ntitanic_df.shape","cfd4e390":"titanic_df.drop(columns=['who', 'deck', 'embark_town', \n                         'alive', 'embarked', 'class', \n                         'alone', 'adult_male'], inplace=True)\ntitanic_df.head()","bdb0acf0":"label_encoder = LabelEncoder()\ntitanic_df['sex'] = label_encoder.fit_transform(list(titanic_df['sex'].values))\n\ntitanic_df['age'] = titanic_df['age'] \/ np.max(titanic_df['age'])\ntitanic_df['fare'] = titanic_df['fare'] \/ np.max(titanic_df['fare'])\n\ntitanic_df.head()","7fca8a28":"ax = sns.pairplot(titanic_df, hue='survived', height=2)\nplt.show()","5880033b":"X = titanic_df.loc[:,'pclass':'fare'].to_numpy()\ny = titanic_df['survived'].to_numpy()","43a662e2":"X_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y,\n                                                    stratify = y,\n                                                    test_size=0.25, \n                                                    random_state=0)","34778679":"print('Amostras de treino:')\nprint(f' * X_train: {X_train.shape}')\nprint(f' * y_train: {y_train.shape}')\n\nprint('Amostras de teste:')\nprint(f' * X_test: {X_test.shape}')\nprint(f' * y_test: {y_test.shape}')","65b200c2":"logistic_model = LogisticRegression()","3f870b44":"SCORERS.keys()","bf239123":"cv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(logistic_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","ca6b2284":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","e17d497e":"knn_model = KNeighborsClassifier(n_neighbors=3)","7f14efa0":"cv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(knn_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","ef2aafbf":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","555d03e4":"tree_model = DecisionTreeClassifier(criterion='entropy',\n                                    max_depth=3,\n                                    min_samples_split=2,\n                                    random_state=0)","a7d0ed4b":"cv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(tree_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","6d1d4e67":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","053944e9":"logistic_model.fit(X_train, y_train)\nknn_model.fit(X_train, y_train)\ntree_model.fit(X_train, y_train)","6eb63879":"print('Regress\u00e3o Log\u00edstica')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, logistic_model.predict(X_test)), 4)}')\nprint('--------')\n\nprint('KNN')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, knn_model.predict(X_test)), 4)}')\nprint('--------')\n\nprint('\u00c1rvore de decis\u00e3o')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, tree_model.predict(X_test)), 4)}')","87581715":"print(classification_report(y_test, logistic_model.predict(X_test), target_names=['No', 'Yes']))","9b30d07a":"fig, ax = plt.subplots(figsize=(5,5))\n\ncm = confusion_matrix(y_test, logistic_model.predict(X_test), labels=logistic_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=pd.Series(logistic_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\n\nplt.show()","a076ce68":"print(classification_report(y_test, knn_model.predict(X_test), target_names=['No', 'Yes']))","0c7333f1":"fig, ax = plt.subplots(figsize=(5,5))\n\ncm = confusion_matrix(y_test, knn_model.predict(X_test), labels=knn_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=pd.Series(knn_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\n\nplt.show()","494bc799":"print(classification_report(y_test, tree_model.predict(X_test), target_names=['No', 'Yes']))","6f39d3af":"fig, ax = plt.subplots(figsize=(5,5))\n\ncm = confusion_matrix(y_test, tree_model.predict(X_test), labels=tree_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=pd.Series(tree_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\n\nplt.show()","074b82ed":"hard_voting_model = VotingClassifier(estimators=[('logistic_model', logistic_model),\n                                                 ('knn_model', knn_model),\n                                                 ('tree_model', tree_model)], \n                                     voting='hard')","16a3ec06":"cv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(hard_voting_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","e0d29e57":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","1f46c3a8":"hard_voting_model.fit(X_train, y_train)","2ed1caed":"print('Hard Voting')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, hard_voting_model.predict(X_test)), 4)}')","23f23bff":"print(classification_report(y_test, hard_voting_model.predict(X_test), target_names=['No', 'Yes']))","e2111f5a":"fig, ax = plt.subplots(figsize=(5,5))\n\ncm = confusion_matrix(y_test, hard_voting_model.predict(X_test), labels=hard_voting_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=pd.Series(hard_voting_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\n\nplt.show()","79d69530":"soft_voting_model = VotingClassifier(estimators=[('logistic_model', logistic_model),\n                                                 ('knn_model', knn_model),\n                                                 ('tree_model', tree_model)],\n                                     voting='soft')","60cd2a73":"cv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(soft_voting_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","6bd0dbaf":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","3ef4f229":"soft_voting_model.fit(X_train, y_train)","b1444eba":"print('Soft Voting')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, soft_voting_model.predict(X_test)), 4)}')","a8e74ba9":"print(classification_report(y_test, soft_voting_model.predict(X_test), target_names=['No', 'Yes']))","dec2142d":"fig, ax = plt.subplots(figsize=(5,5))\n\ncm = confusion_matrix(y_test, soft_voting_model.predict(X_test), labels=soft_voting_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=pd.Series(soft_voting_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\n\nplt.show()","f0e760fe":"random_forest_model = RandomForestClassifier(n_estimators=30, \n                                             criterion='entropy',\n                                             max_depth=10,\n                                             min_samples_split=2,\n                                             random_state=0)","d3057aed":"cv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(random_forest_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","17d2d243":"print('Valida\u00e7\u00e3o Cruzada - Random Forest:\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","009826ce":"random_forest_model.fit(X_train, y_train)","cec1254e":"print('Random Forest')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, random_forest_model.predict(X_test)), 4)}')","ff165d6e":"print(classification_report(y_test, random_forest_model.predict(X_test), target_names=['No', 'Yes']))","d449c426":"fig, ax = plt.subplots(figsize=(5,5))\n\ncm = confusion_matrix(y_test, random_forest_model.predict(X_test), labels=random_forest_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=pd.Series(random_forest_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\n\nplt.show()","1dad07a9":"bagging_model = BaggingClassifier(KNeighborsClassifier(n_neighbors=3),\n                                  n_estimators=800,\n                                  max_samples=100)\n\ncv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(bagging_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)\n\nprint('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","fe32b08a":"bagging_model.fit(X_train, y_train)\n\nprint('Bagging')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, bagging_model.predict(X_test)), 4)}')","1a16ad22":"ada_model = AdaBoostClassifier(LogisticRegression(),\n                               n_estimators=300, \n                               learning_rate=0.5)\n\ncv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(ada_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)\n\nprint('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","d4f88f38":"ada_model.fit(X_train, y_train)\n\nprint('Ada Boost')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, ada_model.predict(X_test)), 4)}')","9629f851":"%%capture\n\nxgb_model = xgboost.XGBClassifier(booster = 'gbtree', \n                                  learning_rate = 0.005,\n                                  n_estimators = 50,\n                                  max_depth = 4,\n                                  random_state = 0)\n\ncv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(xgb_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","64f801aa":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","f30c6b8d":"%%capture\n\nxgb_model.fit(X_train, y_train)","bcf12f85":"print('XGBoost')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, xgb_model.predict(X_test)), 4)}')","29da62da":"%%time\n%%capture\n\nhard_voting_model = VotingClassifier(estimators=[('logistic_model', logistic_model),\n                                                 ('knn_model', knn_model),\n                                                 ('tree_model', tree_model),\n                                                 ('random_forest_model', random_forest_model),\n                                                 ('bagging_model', bagging_model),\n                                                 ('ada_model', ada_model),\n                                                 ('xgb_model', xgb_model)], \n                                     voting='hard')\n\ncv = KFold(n_splits = 5, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(hard_voting_model, \n                           X_train, y_train, \n                           scoring = 'accuracy', \n                           cv = cv)","7ffad1f3":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","4af00395":"%%capture\n\nhard_voting_model.fit(X_train, y_train)","66ef90a8":"print('Hard Voting')\nprint(f'Acur\u00e1cia: {round(accuracy_score(y_test, hard_voting_model.predict(X_test)), 4)}')","4b072b19":"wine_data = load_wine()","af0da787":"print(wine_data.DESCR)","75c04274":"wine_df = pd.DataFrame(wine_data['data'], \n                       columns=wine_data['feature_names'])\nwine_df['TYPE'] =  wine_data['target']\nwine_df.head()","28fb9d7f":"X = wine_df.loc[:,'alcohol':'proline'].to_numpy()\ny = wine_df['TYPE'].to_numpy()","697b29ad":"X_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size=0.25, \n                                                    random_state=0)","f6e89ef6":"print('Amostras de treino:')\nprint(f' * X_train: {X_train.shape}')\nprint(f' * y_train: {y_train.shape}')\n\nprint('Amostras de teste:')\nprint(f' * X_test: {X_test.shape}')\nprint(f' * y_test: {y_test.shape}')","34e7163d":"### Continua\u00e7\u00e3o ###","fcf6cfd3":"#### Regress\u00e3o Log\u00edstica","97652213":"### 1.5) Soft Voting","7c05fa3d":"### 1.2) Treinamento dos modelos\n* Regress\u00e3o Log\u00edstica;\n* k-vizinhos mais pr\u00f3ximos (KNN);\n* \u00c1rvore de decis\u00e3o.","940ac152":"#### \u00c1rvore de decis\u00e3o","5da515b2":"* Outros algoritmos:\n    * [LightGBM](https:\/\/lightgbm.readthedocs.io\/en\/latest\/)\n    * [CatBoost](https:\/\/catboost.ai\/)","9817962b":"### 1.9) Ensembles de ensembles?","4e78a2cb":"#### Pr\u00e9-processamento dos dados","a2231a14":"### 1.4) Hard Voting\n* [VotingClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier)","15c034b1":"## 1. Classifica\u00e7\u00e3o bin\u00e1ria","598aada6":"#### XGBoost\n* [XGBoost](https:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html)","fdcc03e9":"#### k-vizinhos mais pr\u00f3ximos (KNN)","82b0ac00":"* [KFold](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n* [cross_val_score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_val_score.html)","190fc801":"# Ensemble Learning: Hard\/Soft Voting, Random Forest, Bagging e Boosting\n\n* T\u00f3picos abordados:\n    * Problemas de classifica\u00e7\u00e3o em aprendizagem de m\u00e1quina;\n    * Pr\u00e9-processamento de dados;\n    * Hard Voting e Soft Voting;\n    * Random Forest;\n    * Bagging;\n    * Boosting:\n        * Ada Boost;\n        * XGBoost;\n    * M\u00e9tricas para avalia\u00e7\u00e3o de modelos:\n        * Acur\u00e1cia;\n        * F1;\n        * Precis\u00e3o;\n        * Revoca\u00e7\u00e3o;\n    * Valida\u00e7\u00e3o cruzada.","0e092d4f":"### 1.1) Base de dados: Titanic","348a3ca0":"#### Ada Boosting\n* [AdaBoostClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)","3d8e3f18":"### 1.7) Bagging\n* [BaggingClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.BaggingClassifier.html)","7aa3c60e":"### 1.8) Boosting","664270bf":"---","0dc3d851":"### 2.1) Base de dados: Wine","a3ae8f6f":"### 1.6) Random Forest\n* [RandomForestClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)","4b03db69":"## 2. Desafio: classifica\u00e7\u00e3o multiclasse","fc9e31de":"### 1.3) Avalia\u00e7\u00e3o dos modelos","041de160":"#### Divis\u00e3o em treino e teste"}}