{"cell_type":{"21ec7612":"code","3b5bcbf4":"code","49e7621a":"code","71af728b":"code","b5903f22":"code","83ed5616":"code","b29104d8":"code","4e673288":"code","b4d7f8ec":"code","568ce4a6":"code","385d5c58":"code","7a0c68cc":"code","0cb09110":"code","fbec3833":"code","5dfb456f":"code","7dea0095":"code","1ffa0aa1":"code","687a9b1c":"code","17989d1e":"code","98926ad9":"code","d4b9c722":"code","1c0c8e8e":"code","db086904":"code","8e05fa86":"code","8871d2c2":"code","b953d4bb":"code","fc4177c7":"code","0e9591ee":"code","d2071528":"code","70302593":"markdown","28aeee5d":"markdown","80d4323b":"markdown","8641d3f4":"markdown","b974f07e":"markdown","ea2aae3b":"markdown","c0240830":"markdown","c9becd33":"markdown","036f81fa":"markdown","1c0759b6":"markdown","25f2f2c4":"markdown","c4b75e57":"markdown","55b0a4e4":"markdown","95b8b16d":"markdown","200b43f7":"markdown","557e9c90":"markdown"},"source":{"21ec7612":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3b5bcbf4":"! nvidia-smi","49e7621a":"import os\nimport platform\nimport numpy as np\nimport pandas as pd\nimport random as python_random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom skimage import io, transform\n\nimport copy\nimport time","71af728b":"# ! pip install --upgrade --force-reinstall SimpleITK==2.0.2","b5903f22":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Setting seed\ntorch.manual_seed(2021)","83ed5616":"DataDir = '\/kaggle\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset'\nos.listdir(DataDir)","b29104d8":"data = {\"location\": [],\n        \"label\": []\n        }\n\nfor i in os.listdir(DataDir):\n  path = os.path.join(DataDir, i)\n  for j in os.listdir(path):\n    data['location'].append(os.path.join(path, j))\n    data['label'].append(i)","4e673288":"data = pd.DataFrame(data)\ndata.head()","b4d7f8ec":"le = LabelEncoder()\ndata['label'] = le.fit_transform(data['label'])","568ce4a6":"le.classes_","385d5c58":"data.head()","7a0c68cc":"class FishData(Dataset):\n  def __init__(self, data, root_dir='', transform=None, preprocess=False, train=True):\n    self.landmarks_frame = data\n    if (not train) or preprocess:\n# This is our basic transformation according to the paper\n# Which is to resize the image to 590x445\n      transform = transforms.Compose([\n                  transforms.ToPILImage(),\n                  transforms.Resize((590, 445)),\n                  transforms.ToTensor()])\n    self.transform = transform\n    self.root_dir = root_dir\n    self.preprocess = preprocess\n\n  def __len__(self):\n    return len(self.landmarks_frame)\n\n  def __getitem__(self, idx):\n    if torch.is_tensor(idx):\n      idx = idx.tolist()\n\n    img_name = os.path.join(self.root_dir,\n      self.landmarks_frame.iloc[idx, 0])\n    \n    # I would use\n    # image = io.imread(img_name) instead of the next 2 lines\n    # But this throws an error. I am not sure why.(Works in colab just fine)\n    # Any help would be appreciated!\n    image = Image.open(img_name)\n    image = np.array(image)\n    label = self.landmarks_frame.iloc[idx, 1]\n\n    if self.transform:\n      image = self.transform(image)\n\n    if self.preprocess:\n      sample = image\n    else:\n      sample = (image, label)\n\n    return sample","0cb09110":"# Shuffling the data\ndata = data.sample(frac=1)\n\n# Defining my test size\nTEST_FRAC = 0.25\nTEST_SIZE = int(np.floor(len(data) * TEST_FRAC))\n\ntrain_data = data.iloc[TEST_SIZE:]\ntest_data = data.iloc[:TEST_SIZE]\n\nprint(f\"test size is {TEST_SIZE}\")\n\nVAL_FRAC = 0.2\nVAL_SIZE = int(np.floor(len(train_data) * VAL_FRAC))\n\ntrain_data = train_data.iloc[VAL_SIZE:]\nval_data = train_data.iloc[:VAL_SIZE]\n\nprint(f\"test size is {VAL_SIZE}\")\nprint(f\"test size is {len(train_data)}\")","fbec3833":"# Calculating mean and std of each channel\ndata_preprocess = FishData(train_data, preprocess=True)\n# Define a loader to load the data\nloader = DataLoader(\n      data_preprocess\n    , batch_size=len(data)\n    , num_workers=0\n)\n# Get the data\ndata_preprocess = next(iter(loader))\n# Add each channel for each image\n# i.e. Sum all the Red channels, Blue channels and Green channels\ntemp = torch.zeros(list(data_preprocess.shape)[1:])\nfor i in data_preprocess:\n  temp += i\n\ntemp \/= data_preprocess.shape[0]","5dfb456f":"channel_0_mean = temp[0].mean()\nchannel_1_mean = temp[1].mean()\nchannel_2_mean = temp[2].mean()\n\nchannel_0_std = temp[0].std()\nchannel_1_std = temp[1].std()\nchannel_2_std = temp[2].std()","7dea0095":"# A good habit to save RAM :)\ndel temp\ndel data_preprocess\nimport gc\ngc.collect()","1ffa0aa1":"# define pytorch transforms\n# Uncomment transforms.Normalize to normalize each image\nTRANSFORM = transforms.Compose([\n     transforms.ToPILImage(),\n     transforms.Resize((590, 445)),\n     transforms.RandomHorizontalFlip(p=0.5),\n     transforms.RandomRotation(degrees=(-20, 20)),\n     transforms.RandomVerticalFlip(p=0.5),\n     transforms.ToTensor()\n    #  transforms.Normalize((channel_0_mean, channel_1_mean, channel_2_mean),\n    #                       (channel_0_std, channel_1_std, channel_2_std))\n     ])","687a9b1c":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nLEARNING_RATE = 1e-3\nBATCH_SIZE = 8\nNUM_EPOCHS = 10","17989d1e":"train_dataset = FishData(train_data, transform=TRANSFORM)\ntest_dataset = FishData(test_data, train=False)\nval_dataset = FishData(val_data, train=False)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\ndataloaders_dict = {\"train\": train_loader,\n                    \"val\": val_loader}","98926ad9":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=NUM_EPOCHS, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n    train_acc_history = []\n\n    val_loss_history = []\n    train_loss_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    best_loss = np.inf\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(DEVICE)\n                labels = labels.to(DEVICE)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https:\/\/discuss.pytorch.org\/t\/how-to-optimize-inception-model-with-auxiliary-classifiers\/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() \/ len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_loss < best_loss:\n                best_acc = epoch_acc\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n                val_loss_history.append(epoch_loss)\n            else:\n                train_acc_history.append(epoch_acc)\n                train_loss_history.append(epoch_loss)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    print('Best val Loss: {:4f}'.format(best_loss))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n\n    result_dict = {\n        \"train_acc\": train_acc_history,\n        \"train_loss\": train_loss_history,\n        \"val_acc\": val_acc_history,\n        \"val_loss\": val_loss_history\n    }\n\n    return model, result_dict","d4b9c722":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","1c0c8e8e":"def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # Initialize these variables which will be set in this if statement. Each of these\n    #   variables is model specific.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.wide_resnet101_2(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\n\nfeature_extract = False\n# Initialize the model for this run\nmodel_ft, input_size = initialize_model(\"resnet\", 9, feature_extract, use_pretrained=True)\n\n# Print the model we just instantiated\nprint(model_ft)","db086904":"model_ft = model_ft.to(DEVICE)\n\n# Gather the parameters to be optimized\/updated in this run. If we are\n#  finetuning we will be updating all parameters(In this case as mentioned\n# above, we will be updating the weights of layer 4 only. However, if we are\n#  doing feature extract method, we will only update the parameters\n#  that we have just initialized, i.e. the parameters with requires_grad\n#  is True.\nparams_to_update = model_ft.parameters()\nprint(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True and 'layer4' in name:\n            params_to_update.append(param)\n            print(\"\\t\",name)\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.Adamax(params_to_update)","8e05fa86":"criterion = nn.CrossEntropyLoss()\n\n# Train and evaluate\nmodel_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=NUM_EPOCHS, is_inception=False)","8871d2c2":"def check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n    \n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=DEVICE)\n            y = y.to(device=DEVICE)\n            \n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n        \n        print(f'Got {num_correct} \/ {num_samples} with accuracy {float(num_correct)\/float(num_samples)*100:.2f}') \n    \n    model.train()","b953d4bb":"hist['train_acc'] = [i.cpu().numpy().tolist() for i in hist['train_acc']]\nhist['val_acc'] = [i.cpu().numpy().tolist() for i in hist['val_acc']]","fc4177c7":"check_accuracy(test_loader, model_ft)","0e9591ee":"plt.plot(hist['train_acc'], label='train_acc')\nplt.plot(hist['val_acc'], label='val_acc')\nplt.legend()\nplt.show()","d2071528":"plt.plot(hist['train_loss'], label=\"train_loss\")\nplt.plot(hist['val_loss'], label='val_loss')\nplt.legend()\nplt.show()","70302593":"General Imports","28aeee5d":"Now to the most interesting part. Here is where we handle the reshaping of each network. Note, this is not an automatic procedure and is unique to each model. Recall, the final layer of a CNN model, which is often times an FC layer, has the same number of nodes as the number of output classes in the dataset. Since all of the models have been pretrained on Imagenet, they all have output layers of size 1000, one node for each class. The goal here is to reshape the last layer to have the same number of inputs as before, AND to have the same number of outputs as the number of classes in the dataset. In the following sections we will discuss how to alter the architecture of each model individually.","80d4323b":"One trick to fine-tune a pre-trained model is that you update the weights of the last layer and freeze the remaining.\n\nThis works because the first couple of layers learn basic edge detection and the later layers are responsible to learn more complex features.\n\nAs a pre-trained network is trained on a huge dataset, it is already an expert in detecting basic features like edge detection. Now we only need to lean the more complex features of our dataset.\n\n\nQuestion: Can you update the weights of all the layers of a pre-trained model?\n\nAns: YES! you can! But in this case, as the size of the dataset is too small, it is best that we update the parameters of the last layer only. Updating all the parameters will make the model a little less stable and you might see varying accuracies.\n\nYou should try playing with freezing and unfreezing layers and check it out by yourself!","8641d3f4":"YES! I will be working on the NA dataset as it is the original opne without any augmentation.\n\nI will be doing my own image augmentation later in the code\n\nThe reason for this is that in real life, the images that we will be testing our code on will not be augmented.","b974f07e":"We need to define Train, Test and Val sets\n\nPS: It is important that Test and Val sets have the same distribution, so for these two sets, I will perform only the basic transformations.\n\nWhereas on the Train set, I will be performing data augmentation.\n\nThere are 2 reasons why we do data augmentation:\n1. To prevent overfitting\n2. To increase the size of the dataset ","ea2aae3b":"The train_model function handles the training and validation of a given model. As input, it takes a PyTorch model, a dictionary of dataloaders, a loss function, an optimizer, a specified number of epochs to train and validate for, and a boolean flag for when the model is an Inception model. The is_inception flag is used to accomodate the Inception v3 model, as that architecture uses an auxiliary output and the overall model loss respects both the auxiliary output and the final output, as described here. The function trains for the specified number of epochs and after each epoch runs a full validation step. It also keeps track of the best performing model (in terms of validation accuracy), and at the end of training returns the best performing model. After each epoch, the training and validation accuracies are printed.","c0240830":"PyTorch imports and Label Encoder","c9becd33":"This helper function sets the .requires_grad attribute of the parameters in the model to False when we are feature extracting. By default, when we load a pretrained model all of the parameters have .requires_grad=True, which is fine if we are training from scratch or finetuning. However, if we are feature extracting and only want to compute gradients for the newly initialized layer then we want all of the other parameters to not require gradients. This will make more sense later.","036f81fa":"Next step is optional and generally increases the performance of the model.\nBut, in this case, I omitted it as I already got 100% accuracy","1c0759b6":"Next Step is to create a Data Loader which loads all the data from the files to the model\n\nTo create our Data Loader, we need a DataFrame which contains the path of each image corresponding to the label","25f2f2c4":"In this step, I will be calculating the means and the std of each channel to normalize them","c4b75e57":"Why did i choose a test fraction of 0.25?\n\nThat is because the size of the dataset is relatively small and in order to have high confidence on the test set, we need a larger test set\n\nPS: Validation set is always derived from the train set.","55b0a4e4":"As you can see that each location corresponds to the label\n\nNext, we need to encode the labels into a numeric form","95b8b16d":"As you can see that the loss was still decreasing, we could use a couple of more epochs.\n\nSomething you shoult try! And comment the results!","200b43f7":"The labels are now encoded as integers","557e9c90":"Creating our Data Loader Class\n* This class needs to have 3 different methods:\n    1. __init__\n        * To initialize the class objects\n    2. __len__\n        * This will return the total size of our data     \n    3. __getitem__\n        * This returns a tuple consisting of the image and corresponding label\n        \nMore about this Class can be found here: https:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html"}}