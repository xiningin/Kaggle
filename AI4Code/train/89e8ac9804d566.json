{"cell_type":{"97094431":"code","e0bc95fc":"code","976ea5da":"code","4dca5c18":"code","5c85cbee":"code","bffc2c98":"code","047b71ef":"code","9d61b2d0":"code","52d9853a":"code","3d5d92bb":"code","ca303a20":"code","33d0c738":"code","8d357974":"code","0e2e771a":"code","61a263c0":"code","41fc8e50":"code","8a5d9512":"code","c53c316c":"code","aa7ba089":"code","676be913":"code","ab313d33":"code","f1ab39bf":"code","2a930e1e":"code","f284db3c":"code","17c04d7b":"code","6f4f1c49":"code","8e998886":"code","79b0812f":"code","8d1b75a8":"code","8786e908":"code","78606b01":"code","de049df5":"code","db61983b":"code","6d2371ad":"code","9920a7f8":"code","7e321e96":"code","32490b76":"code","0ad39b57":"code","8ddce147":"code","5dfa62ef":"code","d96a03a7":"code","5a5a6150":"code","3c72e918":"code","6d874264":"code","7bc31b6a":"code","6f5d8582":"code","276c126b":"code","9e77551c":"code","c289ae33":"code","c9cd0649":"code","54bf2bea":"code","b43bc1d3":"code","9b231af3":"code","3135695a":"code","dd54940b":"code","57554837":"code","9b29e3cb":"code","65a6b4cf":"code","df3b0825":"code","71e221b0":"code","eca5b1d2":"code","48e7a5f7":"code","92d6e659":"code","6b2e419d":"code","ca38b6e4":"code","9369f7d2":"code","4175d4ac":"code","4b11cb41":"code","72156878":"code","bd61b2d2":"code","51dee8cc":"code","47d1d238":"code","9f86650f":"code","ca284318":"code","91721ac8":"code","05abc4d3":"code","ce2a5276":"markdown","881759ff":"markdown","290fc576":"markdown","034c72d4":"markdown","0f73e194":"markdown","e24a7310":"markdown","ce7cef04":"markdown","26b3f8cd":"markdown","52a810f1":"markdown"},"source":{"97094431":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\npd.set_option('display.max_columns',None)","e0bc95fc":"%%time\n# d=pd.read_csv('\/kaggle\/input\/lending-club\/rejected_2007_to_2018q4.csv\/rejected_2007_to_2018Q4.csv')\ndf= pd.read_csv('\/kaggle\/input\/lending-club\/accepted_2007_to_2018q4.csv\/accepted_2007_to_2018Q4.csv')","976ea5da":"df","4dca5c18":"df.info()","5c85cbee":"# d.info()","bffc2c98":"j= df.isnull().mean()*100","047b71ef":"type(j)","9d61b2d0":"j.sort_values(ascending=False).head(50)","52d9853a":"j.sort_values(ascending=False)[50:90]","3d5d92bb":"k= j.sort_values(ascending=False).head(90)\nl= k.index\ntype(l)  ## pandas.core.indexes.base.Index\n## convert pandas.core.indexes.base.index to list\ntype(l.tolist())\nm=l.tolist()","ca303a20":"%%time\n# But 1st lets drop columns with high nan values manually\nfor i in m:\n    df.drop(columns = [i],axis=1, inplace=True)","33d0c738":"int_shape= df.shape\nprint(int_shape)","8d357974":"%%time\n## Remove the missing values from the rows having greater than 50 missing values \nd = np.where(df.isnull().sum(axis=1)>50)\ndf= df.drop(df.index[d])\nprint(round(100*(1-df.count()\/len(df)),2))  ## print the percentage of missing values in each column","0e2e771a":"shape2= df.shape\n #print(\"loss of data : \",(int_shape-shape2))","61a263c0":"print(type(round(100*(1-df.count()\/len(df)),2)),'\\n')\n\nprint(round(100*(1-df.count()\/len(df)),2).sort_values(ascending=False).head(10))","41fc8e50":"display(df)\ncolumns_to_drop= ['url','id','zip_code']\ncheck_these_columns=['total_rec_late_fee','recoveries','collection_recovery_fee','collections_12_mths_ex_med',\n                     'policy_code','chargeoff_within_12_mths','delinq_amnt']\n\n## I think these catergorical values have same value through out \ncat_same= ['hardship_flag','disbursement_method','debt_settlement_flag','application_type','pymnt_plan','loan_status'] ## Added loan_status to check relationship","8a5d9512":"def without_hue(plot, feature):\n    total = len(feature)\n    for p in plot.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width() \/ 2 - 0.05\n        y = p.get_y() + p.get_height()\n        ax.annotate(percentage, (x, y), size = 12)\n    #plt.show()\n    \nplt.figure(figsize=(15,10))\nj=1\nfor i in cat_same:\n    plt.subplot(2,3,j)\n    ax= sns.countplot(x=df[i])\n    plt.xticks(rotation=90)\n    without_hue(ax,df[i])\n    j=j+1\nplt.tight_layout()\nplt.show()\n","c53c316c":"# columns to dropn\n","aa7ba089":"df[df['loan_status']=='Does not meet the credit policy. Status:Fully Paid']","676be913":"df.hist(figsize=(20,20));","ab313d33":"# Fico Score: \nsns.regplot(x='fico_range_low', y='int_rate', data=df[:100])","f1ab39bf":"sns.regplot(x='fico_range_low', y='int_rate', data=df[:1000])","2a930e1e":"sns.regplot(x='fico_range_low', y='int_rate', data=df[:10000])","f284db3c":"%%time\n### Counting the unique values in categorical dataset\ncat_feat= df.select_dtypes(include='object')\nfor i in cat_feat:\n    print('Feature name {} have : '.format(i), df[i].nunique(), ' Values', '\\n')\n    ","17c04d7b":"for i in cat_feat:\n    n=df[i].nunique()\n    if n<=5:\n        print('Feature name \"{}\" have : '.format(i), n, ' Values')\n    ","6f4f1c49":"df['loan_status'].value_counts()","8e998886":"# Filter out \nloan_status_df= df[df['loan_status']!='Current']\nloan_status_df= loan_status_df[df['loan_status']!='Late (31-120 days)']\nloan_status_df= loan_status_df[df['loan_status']!='In Grace Period ']\nloan_status_df= loan_status_df[df['loan_status']!='Late (16-30 days)']","79b0812f":"# df.replace({'a':{1:11, 2:22}})  ## a : is columns name\nloan_status_df['loan_status'] =loan_status_df['loan_status'].replace({'Charged Off':'Default', 'Fully Paid':'Good','Does not meet the credit policy. Status:Fully Paid': 'Good','Does not meet the credit policy. Status:Charged Off':'Default'})","8d1b75a8":"'''loan_status_df['loan_status'] =df['loan_status'].replace('Charged Off','Default')\nloan_status_df['loan_status'] =df['loan_status'].replace('Fully Paid','Good')''';","8786e908":"loan_status_df['loan_status'].value_counts()","78606b01":"loan_status_df['last_fico_range_low'].min()","de049df5":"loan_status_df['last_fico_range_low']=loan_status_df.apply(lambda x: x['fico_range_low'] if x['last_fico_range_low']==0 else x['last_fico_range_low'],axis=1)","db61983b":"loan_status_df['last_fico_range_low'].value_counts().sort_index()","6d2371ad":"pd.cut(loan_status_df['last_fico_range_low'],5)","9920a7f8":"loan_status_df['fico_buckets']=pd.cut(loan_status_df['last_fico_range_low'],5,labels=['High Risky','Risky','Low Risk','Good','Excellent'])","7e321e96":"loan_status_df['fico_buckets'].value_counts()","32490b76":"loan_status_df_fin =loan_status_df[['loan_status','fico_buckets']].groupby(['loan_status','fico_buckets']).agg({'fico_buckets':'count'})","0ad39b57":"loan_status_df_fin.rename({'fico_buckets':'count'},axis='columns').reset_index()","8ddce147":"sns.barplot(x=\"fico_buckets\", y=\"count\", hue=\"loan_status\", \n            data=loan_status_df_fin.rename({'fico_buckets':'count'},axis='columns').reset_index())","5dfa62ef":"pd.qcut(loan_status_df['int_rate'],5)","d96a03a7":"loan_status_df['rate_buckets']=pd.qcut(loan_status_df['int_rate'],5,labels=['Low','Medium','High','Very High','ForgetIt'])","5a5a6150":"loan_status_df['rate_buckets'].value_counts()","3c72e918":"loan_rate_df = loan_status_df[['loan_status','rate_buckets']].groupby(['loan_status','rate_buckets']).agg({'rate_buckets':'count'})","6d874264":"loan_rate_df.rename({'rate_buckets':'count'},axis='columns').reset_index()","7bc31b6a":"sns.barplot(x=\"rate_buckets\", y=\"count\", hue=\"loan_status\", \n            data=loan_rate_df.rename({'rate_buckets':'count'},axis='columns').reset_index())","6f5d8582":"loan_status_df[['loan_status','rate_buckets','fico_buckets']].groupby(['fico_buckets','rate_buckets']).agg({'loan_status':'count'})","276c126b":"pd.crosstab(index=loan_status_df['fico_buckets'],columns=loan_status_df['rate_buckets'], margins=True)","9e77551c":"pd.crosstab(index=loan_status_df['fico_buckets'],columns=loan_status_df['rate_buckets']).apply(lambda x: x\/x.sum(), axis=1)","c289ae33":"fico_rate_ct=pd.crosstab(index=loan_status_df['fico_buckets'],columns=loan_status_df['rate_buckets'])","c9cd0649":"fico_rate_ct.plot.bar();","54bf2bea":"\nfrom scipy import stats\n(chi2, p, dof,_) = stats.chi2_contingency([fico_rate_ct.iloc[0].values,fico_rate_ct.iloc[1].values, \n                                           fico_rate_ct.iloc[2].values, fico_rate_ct.iloc[3].values, fico_rate_ct.iloc[4].values])","b43bc1d3":"print (\"chi2     : \" ,chi2)\nprint (\"p-value  : \" ,p)\nprint (\"Degree for Freedom : \" ,dof)","9b231af3":"import math\nloan_status_df['fico_score']=loan_status_df['last_fico_range_low'].apply(lambda x: int(math.ceil(x\/10))*10)","3135695a":"loan_status_df.head()","dd54940b":"loan_status_df[loan_status_df['loan_status']=='Default']['fico_score'].value_counts().sort_index()","57554837":"default_df=pd.DataFrame(loan_status_df[loan_status_df['loan_status']=='Default']['fico_score'].value_counts())","9b29e3cb":"default_df=default_df.reset_index()","65a6b4cf":"default_df.columns = ['fico_score','default_total']","df3b0825":"default_df","71e221b0":"default_df[['fico_score','default_total']].corr()","eca5b1d2":"sns.regplot(x='fico_score',y='default_total',data=default_df)","48e7a5f7":"default_df[['fico_score','default_total']].corr('spearman')","92d6e659":"!pip install pwlf\nimport pwlf","6b2e419d":"pwlf = pwlf.PiecewiseLinFit(default_df['fico_score'], default_df['default_total'])","ca38b6e4":"pwise_model = pwlf.fit(4)","9369f7d2":"pwlf.fit_breaks","4175d4ac":"pwlf.slopes","4b11cb41":"pwlf.intercepts","72156878":"yHat_piecewise = pwlf.predict(default_df['fico_score'])","bd61b2d2":"loan_sample=loan_status_df.sample(10000)","51dee8cc":"loan_sample.shape","47d1d238":"loan_sample['loan_status'].value_counts()","9f86650f":"loan_sample.head()","ca284318":"loan_status_df_fin = loan_status_df[['loan_status','fico_buckets']].groupby(['loan_status','fico_buckets']).agg({'fico_buckets':'count'})","91721ac8":"sns.barplot(x=\"fico_buckets\", y=\"count\", hue=\"loan_status\", data=loan_status_df_fin.rename({'fico_buckets':'count'},axis='columns').reset_index())","05abc4d3":"sns.regplot(x='fico_score',y='default_total',data=loan_df)","ce2a5276":"# Ok","881759ff":"Dataset contains the full LendingClub data available from their site. There are separate files for accepted and rejected loans. The accepted loans also include the FICO scores, which can only be downloaded when you are signed in to LendingClub and download the data.","290fc576":"# \ud83d\udcddProblem Statement\nYou work for the LendingClub company which specialises in lending various types of loans to urban customers. When the company receives a loan application, the company has to make a decision for loan approval based on the applicant\u2019s profile. Two types of risks are associated with the bank\u2019s decision:\n\nIf the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\nIf the applicant is not likely to repay the loan, i.e. he\/she is likely to default, then approving the loan may lead to a financial loss for the company\nThe data given contains the information about past loan applicants and whether they \u2018defaulted\u2019 or not. The aim is to identify patterns which indicate if a person is likely to default, which may be used for takin actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.\n\nWhen a person applies for a loan, there are two types of decisions that could be taken by the company:\n\nLoan accepted: If the company approves the loan, there are 3 possible scenarios described below:\n\nFully paid: Applicant has fully paid the loan (the principal and the interest rate)\nCurrent: Applicant is in the process of paying the instalments, i.e. the tenure of the loan is not yet completed. These candidates are not labelled as 'defaulted'.\nCharged-off: Applicant has not paid the instalments in due time for a long period of time, i.e. he\/she has defaulted on the loan\nLoan rejected: The company had rejected the loan (because the candidate does not meet their requirements etc.). Since the loan was rejected, there is no transactional history of those applicants with the company and so this data is not available with the company (and thus in this dataset)\n\nBusiness Objectives\nLendingClub is the largest online loan marketplace, facilitating personal loans, business loans, and financing of medical procedures. Borrowers can easily access lower interest rate loans through a fast online interface.\nLike most other lending companies, lending loans to \u2018risky\u2019 applicants is the largest source of financial loss (called credit loss). The credit loss is the amount of money lost by the lender when the borrower refuses to pay or runs away with the money owed. In other words, borrowers who defaultcause the largest amount of loss to the lenders. In this case, the customers labelled as 'charged-off' are the 'defaulters'.\nIf one is able to identify these risky loan applicants, then such loans can be reduced thereby cutting down the amount of credit loss. Identification of such applicants using EDA and machine learning is the aim of this case study.\nIn other words, the company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default. The company can utilise this knowledge for its portfolio and risk assessment.\nTo develop your understanding of the domain, you are advised to independently research a little about risk analytics (understanding the types of variables and their significance should be enough).","034c72d4":"# table \n\n## # LoanStatNew Description\n0. **loan_amnt :**\tThe listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n1. **term :**\tThe number of payments on the loan. Values are in months and can be either 36 or 60.\n2. **int_rate :**\tInterest Rate on the loan\n3. **installment :**\tThe monthly payment owed by the borrower if the loan originates.\n4. **grade :**\tLC assigned loan grade\n5. **sub_grade :**\tLC assigned loan subgrade\n6. **emp_title :**\tThe job title supplied by the Borrower when applying for the loan.*\n7. **emp_length :**\tEmployment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n8. **home_ownership :**\tThe home ownership status provided by the borrower during registration or obtained from the credit report. Our values are: RENT, OWN, MORTGAGE, OTHER\n9. **annual_inc :**\tThe self-reported annual income provided by the borrower during registration.\n10. **verification_status :**\tIndicates if income was verified by LC, not verified, or if the income source was verified\n11. **issue_d :**\tThe month which the loan was funded\n12. **loan_status :**\tCurrent status of the loan\n13. **purpose :**\tA category provided by the borrower for the loan request.\n14. **title :**\tThe loan title provided by the borrower\n15. **zip_code :**\tThe first 3 numbers of the zip code provided by the borrower in the loan application.\n16. **addr_stat :**e\tThe state provided by the borrower in the loan application\n17. **dti :**\tA ratio calculated using the borrower\u2019s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower\u2019s self-reported monthly income.\n18. **earliest_cr_line :**\tThe month the borrower's earliest reported credit line was opened\n19. **open_acc :**\tThe number of open credit lines in the borrower's credit file.\n20. **pub_rec :**\tNumber of derogatory public records\n21. **revol_bal :**\t Total credit revolving balance\n22. **revol_util :**\tRevolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n23. **total_acc :**\tThe total number of credit lines currently in the borrower's credit file\n24. **initial_list_status :**\tThe initial listing status of the loan. Possible values are \u2013 W, F\n25. **application_type :**\tIndicates whether the loan is an individual application or a joint application with two co-borrowers\n26. **mort_acc :**\tNumber of mortgage accounts.\n27. **pub_rec_bankruptcies :**\tNumber of public record bankruptcies","0f73e194":"# Data Cleaning\n* drop columns with more than 80 nan value df = df.loc[:, df.isin([' ','NULL',0]).mean() < .8]\n> didn't ran this because ram was completely exhausted without task completion \n","e24a7310":"After Remove the missing values from the rows having greater than 5 missing values ::  \nwe went from (2,260,701, 113) to (976,746 rows \u00d7 113 columns)\n#### thus will remove only rows with more than 50 missing nan in row which is closs to 50%","ce7cef04":"# Lending Club data preparation ( Statistical Approach) \n### Statistical Thinking - Data Understanding and Preparation\n* Step 1 understand the data and business around it\n* Step 2 Try to understand how the data is collected and what are error it might have faced ( eg survey, scraping or generated by business)\n* Step 3 : Need to understand weather the data is `Raw` or some1 have summarized the data. generally when we get data from ware houses we end up getting summarized data\n* Step 4 : If data is summarized we need to understand lineage of data and the process through which it has gonne through. Basically understand how the data is summarized\n* Step 5 : understand the distribution and Nature of ur data. (here **Descriptive statistics** comes into play)\n* Step 6 : Analyze the data, draw and assess conclusion from it","26b3f8cd":"**Interpretation :**\nAs data sample increases noise also increase in data.","52a810f1":"### d=pd.read_csv('\/kaggle\/input\/lending-club\/rejected_2007_to_2018q4.csv\/rejected_2007_to_2018Q4.csv')\n\n![lending club.PNG](attachment:d0e573d6-c332-43ac-a9b2-832416b7902e.PNG)\n\n![lending club info.PNG](attachment:04c6f55e-0411-450f-b99e-f5a5abe93703.PNG)"}}