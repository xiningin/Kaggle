{"cell_type":{"0cd594a6":"code","26c94852":"code","feb3b403":"code","bd75d666":"code","fed30d76":"code","c5cdc9b3":"code","0ce5c767":"code","f6fc991c":"code","aa61ea37":"code","21cff8b8":"code","6d2b9067":"code","95ed9ef4":"code","671205f3":"code","dee0713b":"code","d13a0ba9":"code","0ffc8832":"code","9e33ff09":"code","76648005":"code","a8002bbc":"code","6a9e0df5":"code","6583e382":"code","4408080f":"markdown","f0f88930":"markdown","065ef580":"markdown","1b920f16":"markdown","3a9040c3":"markdown","1e62904d":"markdown","44d762f2":"markdown","0ff6e323":"markdown","e3ef003d":"markdown","7cdc9417":"markdown","4dcef8b6":"markdown","30f82694":"markdown","88a2737d":"markdown","bb8944ef":"markdown","e056e601":"markdown","4c2ba1c4":"markdown","add46466":"markdown"},"source":{"0cd594a6":"import time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\n\npd.options.display.max_columns = 99\nplt.rcParams['figure.figsize'] = (12, 8)","26c94852":"df_train = pd.read_csv('..\/input\/train.csv', parse_dates=['date'], index_col=['date'])\ndf_test = pd.read_csv('..\/input\/test.csv', parse_dates=['date'], index_col=['date'])\ndf_train.shape, df_test.shape","feb3b403":"df_train.head()","bd75d666":"num_stores = len(df_train['store'].unique())\nfig, axes = plt.subplots(num_stores, figsize=(8, 16))\n\nfor s in df_train['store'].unique():\n    t = df_train.loc[df_train['store'] == s, 'sales'].resample('W').sum()\n    ax = t.plot(ax=axes[s-1])\n    ax.grid()\n    ax.set_xlabel('')\n    ax.set_ylabel('sales')\nfig.tight_layout();","fed30d76":"s1i1 = df_train.loc[(df_train['store'] == 1) & (df_train['item'] == 1)]\ns1i1.head()","c5cdc9b3":"s1i1['sales'].plot();","0ce5c767":"fig = seasonal_decompose(s1i1['sales'], model='additive', freq=365).plot()","f6fc991c":"dftest = adfuller(s1i1['sales'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\ndfoutput","aa61ea37":"diff_1 = s1i1['sales'].diff(1)\ndiff_1.dropna(inplace=True)\nfig = seasonal_decompose(diff_1, model='additive', freq=365).plot()","21cff8b8":"dftest = adfuller(diff_1, autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\ndfoutput","6d2b9067":"fig, ax = plt.subplots(2)\nax[0] = sm.graphics.tsa.plot_acf(diff_1, lags=50, ax=ax[0])\nax[1] = sm.graphics.tsa.plot_pacf(diff_1, lags=50, ax=ax[1])","95ed9ef4":"from itertools import product\n\nps = range(0, 7) # Up to 6 AR terms\nd = 1            # Differencing is 1\nqs = range(0, 7) # Up to 6 MA terms\n\nparams = product(ps, qs)\nparams_list = list(params)\nprint(\"Number of parameter combinations for grid search: {}\".format(len(params_list)))","671205f3":"def optimiseARIMA(ts, params_list, d):\n    results = []\n    best_aic = np.inf\n    \n    for param in params_list:\n        try:\n            arima = sm.tsa.ARIMA(ts.astype(float), freq='D',\n                                 order=(param[0], d, param[1])).fit()\n        except:\n            continue\n        \n        aic = arima.aic\n        if aic < best_aic:\n            best_model = arima\n            best_aic = aic\n            best_param = param\n            \n        results.append([param, arima.aic])\n        \n    df_results = pd.DataFrame(results)\n    print(results)\n    df_results.columns = ['parameters', 'aic']\n    df_results = df_results.sort_values(by='aic', ascending=True).reset_index(drop=True)\n    \n    return df_results","dee0713b":"%%time\nresults = optimiseARIMA(s1i1['sales'], params_list, d)","d13a0ba9":"results.head(10)","0ffc8832":"%%time\narima = sm.tsa.ARIMA(s1i1['sales'].astype(float), freq='D', order=(6, 1, 6)).fit()\nprint(arima.summary())","9e33ff09":"arima_results = df_test.reset_index()\narima_results['sales'] = 0","76648005":"tic = time.time()\n\nfor s in arima_results['store'].unique():\n    for i in arima_results['item'].unique():\n        si = df_train.loc[(df_train['store'] == s) & (df_train['item'] == i), 'sales']\n        try:\n            arima = sm.tsa.ARIMA(si.astype(float), freq='D', order=(6, 1, 6)).fit()\n        except:\n            arima = sm.tsa.ARIMA(si.astype(float), freq='D', order=(2, 1, 2)).fit()\n            print(\"ARIMA(6,1,6) failed to converge for store {} item {}. ARIMA(2,1,2) used instead.\".format(s, i))\n        fcst = arima.predict(start='2018-01-01', end='2018-03-31', dynamic=True)\n        arima_results.loc[(arima_results['store'] == s) & (arima_results['item'] == i), 'sales'] = fcst.values\n        \n        toc = time.time()\n        if i % 10 == 0:\n            print(\"Completed store {} item {}. Cumulative time: {:.1f}m\".format(s, i, (toc-tic)\/60))","a8002bbc":"arima_results.drop(['date', 'store', 'item'], axis=1, inplace=True)\narima_results.head()","6a9e0df5":"arima_results.to_csv('arima_results.csv', index=False)","6583e382":"forecast = arima.predict(start='2017-10-01', end='2017-12-31', dynamic=True)\nactual = df_train.loc[(df_train['store'] == 10) & (df_train['item'] == 50), 'sales']\n\nforecast.plot()\nactual.loc['2017-10-01':].plot()\nplt.legend(['ARIMA', 'Actual'])\nplt.ylabel('Sales');","4408080f":"### Example forecast","f0f88930":"# Store Item Demand Forecasting Challenge","065ef580":"### Example store and item","1b920f16":"## Autoregressive Integrated Moving Average (ARIMA)\n\n<a href=\"https:\/\/www.kaggle.com\/c\/demand-forecasting-kernels-only\">Link to competition on Kaggle.<\/a>\n\nThe <a href=\"https:\/\/en.wikipedia.org\/wiki\/Autoregressive_integrated_moving_average\">ARIMA<\/a> model is a generalisation of an ARMA model that can be applied to non-stationary time series.","3a9040c3":"### Plot ACF and PACF\n\nThe <a href=\"https:\/\/en.wikipedia.org\/wiki\/Autocorrelation\">Autocorrelation Function<\/a> (ACF) is the correlation of a signal with a delayed copy of itself as a function of delay.\n\nThe <a href=\"https:\/\/en.wikipedia.org\/wiki\/Partial_autocorrelation_function\">Partial Autocorrelation Function<\/a> (PACF) is the partial correlation of a signal with a delayed copy of itself, controlling for the values of the time series at all shorter delays, as a function of delay.","1e62904d":"The Dickey-Fuller test p-value is lower than I would have expected, but the time series is not considered stationary using a 1% Critical Value and we can see visually that there is an upwards trend.","44d762f2":"### Time Series Decomposition\n\nDecompose the example time series into trend, seasonal, and residual components.\n","0ff6e323":"Unsurprisingly, the more complex models have the lowest AIC values. We proceed with the ARIMA(6,1,6) model..","e3ef003d":"### Take first differences\n\nWe can try to remove the trend by applying a first difference to the time series.","7cdc9417":"There is clearly yearly seasonality and a non-stationary, upward trend. We can run a Dickey-Fuller test to examine the stationarity.","4dcef8b6":"### Build Model\n\nWe will implement grid search to identify the optimal parameters for our ARIMA(p,d,q) model, using the following possible values:","30f82694":"## Make Predictions","88a2737d":"## ARIMA\n\nWe will build a SARIMA model for a single store and item, and then retrain it and generate predictions for all time series in the dataset.","bb8944ef":"Clearly there are seasonal patterns in the data. In this case, the ACF and PACF are too complex to infer the appropriate parameters for the ARIMA model.","e056e601":"The trend has been eliminated and the Dickey-Fuller test implies that the data is now stationary. Note that there is still some evidence of seasonality, however.","4c2ba1c4":"## Load Data","add46466":"All stores appear to show identical trends and seasonality; they just differ in scale."}}