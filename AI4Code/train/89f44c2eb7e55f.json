{"cell_type":{"9e4f40da":"code","45e5d697":"code","3c5d518d":"code","6882fee1":"code","c25a6bca":"code","bf4e2bae":"code","faffa01a":"code","801b8a79":"code","a5b62c66":"code","06b915d9":"code","f73caef7":"code","c766c388":"code","5d9e55fa":"code","6eb22ec4":"code","44285451":"code","5c15d899":"code","035c4a48":"code","b5cb4042":"code","cd7d6669":"code","eaad520a":"code","8595de36":"code","b6d435ff":"code","b8f57a32":"code","53c040fd":"code","1a3f6a75":"code","2548e605":"code","8bff250d":"code","16c13e08":"code","57405659":"code","db326790":"code","95ceaf16":"code","9758a691":"code","d6a1468f":"code","d95d278d":"code","ad2d8610":"code","56f50b24":"code","fa46aebf":"code","02355e54":"code","5115175b":"code","cdead69c":"code","d12ad364":"markdown","8d3b10a1":"markdown","8eeee068":"markdown","0aeb0a2b":"markdown","ff391220":"markdown","1d654087":"markdown","39512338":"markdown","413b2c9b":"markdown","9f276f34":"markdown","e607aec1":"markdown","024e4260":"markdown","62fa0104":"markdown","df4e252f":"markdown","0cdf36aa":"markdown","58c6a2bc":"markdown","ccb8ab4c":"markdown","35042acd":"markdown","1218e727":"markdown","b382ee1d":"markdown","75af14d3":"markdown","3f00eef9":"markdown","518d5c7a":"markdown","da869bf3":"markdown","dd0dc9e1":"markdown","3aa0eb7d":"markdown","5424d6a6":"markdown","6f54c7f2":"markdown","d2b08e1e":"markdown","d3c802f8":"markdown","b5e1cedc":"markdown","4c2747bf":"markdown","2a97a9b8":"markdown","e96e5ea0":"markdown","df6168d1":"markdown","f18bebda":"markdown","9b74dea4":"markdown","c1a55eca":"markdown"},"source":{"9e4f40da":"# For data cleaning\/wrangling\nimport numpy as np      # vectors and matrices || Linear Algebra\nimport pandas as pd     # tables and data manipulations \n\n# Visualization Libraries\nimport matplotlib.pyplot as plt # plots\nimport seaborn as sns           # attractive plots","45e5d697":"df = pd.read_csv(\"..\/input\/superstoredata\/Sample - Superstore.csv\")","3c5d518d":"df.head(2)","6882fee1":"# Call columns\ndf.columns","c25a6bca":"# Drop Some Columns\ndf = df.drop([\"Row ID\", \"Order ID\", \"Customer ID\", \"Customer Name\", \"Postal Code\", \"Product ID\", \"Product Name\", \"City\"], axis=1)","bf4e2bae":"# Check the first few entries again\ndf.head(2)","faffa01a":"# Number of samples and features\nprint(\"The Dataset has:\")\nrows, col = df.shape\nprint(\"Rows : %s, features : %s\" % (rows, col))","801b8a79":"# Check if there's missing data\n# Turn it into a dataframe\npd.DataFrame(df.isnull().sum(), columns=[\"Number of Missing Values\"]).T","a5b62c66":"# Describe df\ndf.describe().T","06b915d9":"df.info()","f73caef7":"df.head(1)","c766c388":"df['Order Date'] = pd.to_datetime(df['Order Date'])\ndf['Ship Date']  = pd.to_datetime(df['Ship Date'])","5d9e55fa":"df.info()","6eb22ec4":"# Get Unique values under Country column\npd.DataFrame(df.Country.unique(), columns=[\"Countries\"])","44285451":"# Get Unique values under State column\npd.DataFrame(df.State.unique(), columns=[\"States\"]).count()","5c15d899":"%%HTML\n<div class='tableauPlaceholder' id='viz1621996077222' style='position: relative'><noscript><a href='#'><img alt='Sales Per State ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;sales_per_state&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='Sales_Analysis_16218381582000&#47;sales_per_state' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;sales_per_state&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en-US' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1621996077222');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","035c4a48":"%%HTML\n<div class='tableauPlaceholder' id='viz1621928625977' style='position: relative'><noscript><a href='#'><img alt='Profitability Per State ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;profitability_per_state&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='Sales_Analysis_16218381582000&#47;profitability_per_state' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;profitability_per_state&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1621928625977');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","b5cb4042":"region_sales = df.groupby(\"Region\").sum()[[\"Sales\"]]\nregion_sales","cd7d6669":"region_profits = df.groupby(\"Region\").sum()[[\"Profit\"]]\nregion_profits","eaad520a":"plt.style.use('seaborn')\nplt.figure(figsize=(15,10))\n\nplt.suptitle(\"Regions Count & Pie Plots\", fontname = \"Times New Roman\", size = 35, color=\"m\")\n\n# Count Plot\nplt.subplot(2,2,1)\nsns.countplot(x=\"Region\", data = df, palette = \"Set1\")\nplt.xlabel(\"Regions\")\n\n# Pie Plot\nplt.subplot(2,2,2)\ncolors = [\"blue\", \"purple\", \"green\", \"red\"]\nexplode = (0.02, 0.1, 0.1, 0.2)\nlabels = 'West', 'East', 'Central', 'South'\ndf[\"Region\"].value_counts().plot.pie(y=\"Region\", labels=labels, explode = explode, figsize=(25,15), autopct='%1.1f%%',\n                                    startangle = 90, shadow=True, wedgeprops={'edgecolor': 'red'}, colors=colors)\n#plt.tight_layout()","8595de36":"region_sales_and_profit = df.groupby(\"Region\").sum()[[\"Sales\", \"Profit\"]] \n# Turn into a Dataframe\nregion_sales_and_profit_df = pd.DataFrame(region_sales_and_profit)\nregion_sales_and_profit_df","b6d435ff":"plt.subplot(2, 2, 1)\nplt.suptitle(\"Regional Sales vs. Profits Pie Plots\", size=60, fontname = \"Impact\", color = \"red\")\n# Regional Sales Pie Plot\ncolors = [\"blue\", \"purple\", \"green\", \"red\"]\nexplode = (0.02, 0.1, 0.1, 0.2)\nregion_sales_and_profit_df[\"Sales\"].plot.pie(explode = explode, figsize=(20,7), autopct='%1.1f%%',\n                                    startangle = 90, shadow=True, wedgeprops={'edgecolor': 'red'}, colors=colors)\nplt.title(\"Regional Sales Pie Chart\", size = 25, fontname = \"Helvetica\")\n\n\nplt.subplot(2, 2, 2)\n# Regional Profits Pie Plot\ncolors = [\"blue\", \"purple\", \"green\", \"red\"]\nexplode = (0.02, 0.1, 0.1, 0.2)\nregion_sales_and_profit_df[\"Profit\"].plot.pie(explode = explode, figsize=(25,30), autopct='%1.1f%%',\n                                    startangle = 90, shadow=True, wedgeprops={'edgecolor': 'r'}, colors=colors)\nplt.title(\"Regional Profit Pie Chart\", size = 25, fontname = \"Helvetica\")\n\nplt.tight_layout()","b8f57a32":"# Calculate shipment days and turn it into a dataframe\nship_df = pd.DataFrame((df[\"Ship Date\"] - df[\"Order Date\"]), columns = [\"Shipped After\"])\nship_df.head()","53c040fd":"ship_df.max()","1a3f6a75":"ship_df.min()","2548e605":"ship_df.mean()","8bff250d":"pd.DataFrame(df[\"Ship Mode\"].unique(), columns = [\"Shipping Methods\"])","16c13e08":"ship_sales_and_profit = df.groupby(\"Ship Mode\").sum()[[\"Sales\", \"Profit\"]] \n# Turn into a Dataframe\nship_sales_and_profit_df = pd.DataFrame(ship_sales_and_profit)\nship_sales_and_profit_df","57405659":"plt.subplot(2, 2, 1)\nplt.suptitle(\"Shipment Modes Sales vs. Profits Charts\", size=40, fontname = \"Impact\", color = \"red\")\n\n# Ship Mode Sales Pie Plot\ncolors = [\"blue\", \"purple\", \"green\", \"red\"]\nexplode = (0.02, 0.1, 0.1, 0.2)\nship_sales_and_profit_df[\"Sales\"].plot.pie(explode = explode, figsize=(20,7), autopct='%1.1f%%',\n                                    startangle = 90, shadow=True, wedgeprops={'edgecolor': 'red'}, colors=colors)\nplt.title(\"Shipment Sales Chart\", size = 25, fontname = \"Helvetica\")\n\n\nplt.subplot(2, 2, 2)\n# Ship Mode Profits Pie Plot\ncolors = [\"blue\", \"purple\", \"green\", \"red\"]\nexplode = (0.02, 0.1, 0.1, 0.2)\nship_sales_and_profit_df[\"Profit\"].plot.pie(explode = explode, figsize=(20,9), autopct='%1.1f%%',\n                                    startangle = 90, shadow=True, wedgeprops={'edgecolor': 'r'}, colors=colors)\nplt.title(\"Shipment Mode Profit Chart\", size = 25, fontname = \"Helvetica\")\n\n#plt.tight_layout()","db326790":"# Get unique segments in the dataset\npd.DataFrame(df.Segment.unique(), columns=[\"Segmentations\"])","95ceaf16":"seg = df.groupby(\"Segment\").sum()[[\"Quantity\", \"Sales\"]] ","9758a691":"plt.figure(figsize=(25, 15))\nplt.suptitle(\"Segment Quantity vs. Sales Charts\", size=40, fontname = \"Impact\", color = \"red\")\n\n\n# Quantity Segmentation Pie Plot\nplt.subplot(3, 3, 1)\n#colors = [\"magenta\", \"yellow\", \"cyan\"]\nexplode = (0.02, 0.1, 0.2)\nseg[\"Quantity\"].plot.pie(explode = explode, autopct='%1.1f%%', startangle = 90, shadow=True,\n                         wedgeprops={'edgecolor': 'red'})\nplt.title(\"Quantity Segmentation Chart\", size = 15, fontname = \"Helvetica\")\n\nplt.subplot(3, 3, 2)\n# Barplot\nsns.barplot(x = 'Segment', y = 'Quantity', data = df, estimator = sum, ci=None)\n# Add titles (main and on axis)\nplt.title(\"Segmentation & Quantity\", size = 15, fontname = \"Helvetica\")\nplt.xlabel(\"Consumer Segments\")\n\n\n# Quantity Segmentation Pie Plot\nplt.subplot(3, 3, 3)\n#colors = [\"magenta\", \"yellow\", \"cyan\"]\nexplode = (0.02, 0.1, 0.2)\nseg[\"Sales\"].plot.pie(explode = explode, autopct='%1.1f%%', startangle = 90, shadow=True, \n                      wedgeprops={'edgecolor': 'red'})\nplt.title(\"Segment Sales Chart\", size = 15, fontname = \"Helvetica\")\nplt.figure(figsize=(25, 10))\n\n# Call Seg\nseg","d6a1468f":"pd.DataFrame(df.Category.unique(), columns = [\"Category\"])","d95d278d":"cat = df.groupby(\"Category\").sum()[[\"Sales\", \"Profit\", \"Quantity\"]] \ncat","ad2d8610":"plt.figure(figsize=(25, 15))\nplt.suptitle(\"Category vs. Sales Charts\", size=40, fontname = \"Impact\", color = \"red\")\n\n\n# Quantity Segmentation Pie Plot\nplt.subplot(3, 3, 1)\n#colors = [\"magenta\", \"yellow\", \"cyan\"]\nexplode = (0.02, 0.1, 0.2)\ncat[\"Quantity\"].plot.pie(explode = explode, autopct='%1.1f%%', startangle = 90, shadow=True,\n                         wedgeprops={'edgecolor': 'red'})\nplt.title(\"Category Segmentation Chart\", size = 15, fontname = \"Helvetica\")\n\nplt.subplot(3, 3, 2)\n# Barplot\nsns.barplot(x = 'Category', y = 'Quantity', data = df, estimator = sum, ci=None)\n# Add titles (main and on axis)\nplt.title(\"Category & Quantity\", size = 15, fontname = \"Helvetica\")\nplt.xlabel(\"Categories\")\n\n\n# Quantity Segmentation Pie Plot\nplt.subplot(3, 3, 3)\n#colors = [\"magenta\", \"yellow\", \"cyan\"]\nexplode = (0.02, 0.1, 0.2)\ncat[\"Sales\"].plot.pie(explode = explode, autopct='%1.1f%%', startangle = 90, shadow=True, \n                      wedgeprops={'edgecolor': 'red'})\nplt.title(\"Category Sales Chart\", size = 15, fontname = \"Helvetica\")\nplt.figure(figsize=(25, 10))\n","56f50b24":"%%HTML\n<div class='tableauPlaceholder' id='viz1622092849889' style='position: relative'><noscript><a href='#'><img alt='Quarterly Sales &amp; Profit Trend  ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;quarterly_sales_trends&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='Sales_Analysis_16218381582000&#47;quarterly_sales_trends' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;quarterly_sales_trends&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en-US' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1622092849889');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","fa46aebf":"# Create a Quarter Column\ndf['Quarter'] = pd.PeriodIndex(df['Order Date'], freq = 'Q')\ndf.head(1)","02355e54":"fig, ax = plt.subplots(figsize=(25,5))\n# Plot Quaterly Sales for Stock Segmentation\ndf.groupby([\"Quarter\", \"Category\"]).count()[['Sales']].unstack().plot(ax=ax)\nplt.title(\"Quarterly Sales Trends for Stock Segments\", size = 35, fontname = \"Impact\", color='r')\nplt.xlabel(\"Quarters\")","5115175b":"fig, ax = plt.subplots(figsize=(25,7))\n# Plot Quaterly Sales for Stock Segmentation\ndf.groupby([\"Quarter\", \"Segment\"]).count()['Sales'].unstack().plot(ax=ax)\nplt.title(\"Quarterly Segment Sales Trends\", size = 35, fontname = \"Impact\", color='r')\nplt.xlabel(\"Quarters\")\n","cdead69c":"%%HTML\n<div class='tableauPlaceholder' id='viz1622098441377' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;Dashboard1&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='Sales_Analysis_16218381582000&#47;Dashboard1' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sa&#47;Sales_Analysis_16218381582000&#47;Dashboard1&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en-US' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1622098441377');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.minWidth='420px';vizElement.style.maxWidth='650px';vizElement.style.width='100%';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.minWidth='420px';vizElement.style.maxWidth='650px';vizElement.style.width='100%';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='1027px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","d12ad364":"> ### $Analysis$\n>- We have 3 different segments of buyers:\n    1. General Consumers\n    2. Corporate buyers\n    3. Home Office buyers\n\n> ### Quantity Analsysis in each Segment","8d3b10a1":"# <font color=blue>1. Retail Data Analysis\n    \n> ## 1.1 What Is Retail Data Analysis?\nRetail data analysis is an analysis of everything in your business, from sales and inventory to customer data. It enables businesses to effectively track customer actions, like their purchases and foot traffic in the store- whether done in person or online. Since the advent of e-commerce, retail business has changed a whole lot more, as are other types of businesses. Use of data to increase profits has been in high demands than ever before; retail stores, small and big, now keep every bit of data available to make their online presence even more valuable and to score new buyers, and retain their regulars. \n\n>Data is accessible at nearly every touchpoint that consumers and retailers interact nowadays\u2014including both online and offline. As a result, Smal and Medium Business (SMB) retailers can use insight collected from data to prepare for future store planning needs, including marketing, employee management, inventory control and more. In fact, SMBs can be even more agile and nimble in rolling out their analytics efforts and react more quickly to leverage data into a competitive edge.\n>## 1.2 Problem Statement\n>Just like any other retail business fratenity, this superstore has tasked us with performing extensive data analysis to deliver or uncover hidden insights on how the company can increase its profits while minimizing the losses.\n>## 1.3 About The Dataset\n>The dataset we will use in this project can be found [here](https:\/\/data.world\/stanke\/sample-superstore-2018). We will dive deeper into the features involved in our data.\n>## 1.4 Experimental Design\n>We will use static data- dataset already available rather than real-time data from an IoT system.\n>## 1.5 Software tools & Hardware Requirements: \n>- Jupyter Notebook, \n>- Python3 Liraries such as [NumPy](https:\/\/numpy.org\/doc\/stable\/user\/quickstart.html), [Pandas](https:\/\/pandas.pydata.org\/docs\/), [Matplotlib](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/visualization.html) and [Seaborn](https:\/\/seaborn.pydata.org\/) \n>- Supervised Learning libraries such [Scikit-Learn](https:\/\/scikit-learn.org\/stable\/)\n  ... will be exploited for the development and experimentation of the project.\n\n","8eeee068":"> ## 4.3 Customer Segmentation Analysis\n>- Customer segmentation is the process of separating customers into groups on the basis of their shared behavior or other attributes. The groups should be homogeneous within themselves and should also be heterogeneous to each other.\n>- Customer segmentation is useful in understanding what demographic and psychographic sub-populations there are within our customers in a business case.\n>- The overall aim of this process is to identify high-value customer base i.e. customers that have the highest growth potential or are the most profitable.\n    - We will try understand the classes of our customers\n    - We will also try understand loyal customer class base- to see who we sell most to\n    - We want to undertand the sales batch and profitability of each group\n\n> #### What are the avaialble categories of buyers in our superstore?","0aeb0a2b":"> ### $Analysis$\n>- About 32% of our customers are in the Western Region\n>- The second largest percentage of our customers are based in the central region\n>- We have the lowest number of buyers from the South\n>- We also have 28.5% of our customers in the Eastern region. ","ff391220":"> ### Quarterly Sales Trends for Stock Segments\n>- Sales Trends for:-\n    1. Consumer\n    2. Corporate\n    3. Home Office","1d654087":"> ### $Observation$\n>- We do see that we successfully managed to convert the date columns into datetime datatype, as they were originally supposed to be. \n\n> Now that we have a general knowledge of our dataset, let's go ahead and uncover some hidden insights","39512338":"> ## 2.2 Data Ingestion","413b2c9b":"> ### $Analysis$\n>- 50% of the customers were general Consumers\n>- The superstore also served Corporate market as the second largest group\n>- Most orders came from general Consumers\n\n> ## 4.4 Stock Category Analysis\n>- Here we go ahead to dig deeper into classifications of stock sold by the store\n>- #### What are the available classes of goods in this store?","9f276f34":"> ### $Observation$\n>- We do notice different data types under each column\n>- We also notice that the two columns that are supposed to be of date format are classified as `object` data type; we have to correct that as we want to analyse the dates too at the later stage.\n\n> ### Convert non-date columns to datetime stamp","e607aec1":"> ## 4.2 Shipping Analysis\n>- Let us try analyse the efficiency or responsiveness of our business in attending to customers orders\n>- We also will look at the shipment modes that the business utilizes \n    - We know that the more responsive the business is in fulfilling the orders, the more customers it will retain and attract. ","024e4260":"> ## Regional Sales and Profit Analysis \n>- Let as take a look at the sales and profitability of each region.","62fa0104":"> ### The longest it took to ship an order","df4e252f":"> ### $Analysis$\n>- Our customers come from almost all states.\n\n> #### Which states saw the most sales?\n>- We will make use of Maps and spread out data based on sales per state, i.e. states from which buyers were based and had their products shipped to them. ","0cdf36aa":"# <font color=blue>3. Data Preprocessing<\/font>\n> - Before moving on to analysing our data, let's first weed out some anomalies or anything that could hurt our data analysis and, possibly predictions. \n> - We also want to have only the necessary features to work with at a later stage, so that would mean dropping those we wil deem unnecessary to our cause.\n\n> ### Why preprocessing?\n>>1. Real world data are generally\n    - __Incomplete__: lacking attribute values, lacking certain attributes of interest, or containing only aggregate data\n    - __Noisy__: containing errors or outliers\n    - __Inconsistent__: containing discrepancies in codes or names\n>>2. Tasks in data preprocessing\n    - __Data cleaning__: fill in missing values, smooth noisy data, identify or remove outliers, and resolve inconsistencies.\n    - __Data integration__: using multiple databases, data cubes, or files.\n    - __Data transformation__: normalization and aggregation.\n    - __Data reduction__: reducing the volume but producing the same or similar analytical results.\n    - __Data discretization__: part of data reduction, replacing numerical attributes with nominal ones.\n\n> - We will perform the above preprocessing tasks without explicitely stating so.\n> - We already saw some entries in the dataset, let's go ahead and see what the columns mean and which ones can be dropped.\n\n> ### Features\/Columns","58c6a2bc":"> ### $Observation$\n>- We originally had 21 columns, and now we only have 13 left after dropping those we deem unnecesary.\n>- We can drop more depending on what we want to analyse moving forward but for now let's go ahead aand work with the ones we decided to keep.\n\n> #### <CENTER>Column Descriptions<\/CENTER>\n>|$Order Date$ | corresponds to the date on which a customer placed an order with the store. |\n| :-| :-|\n| $Ship Date$ | corresponds to the date on which an order was sent out to the customer who placed an order with the store.\n|$Ship Mode$| The class of the shipment mode: first class or second class, each of which has different shipping speeds.\n|$Segment$| Category of the consumer who placed an order- a regular consumer or another company(corporate purchase)?.\n|$Country$| Country in which the consumer resides.\n|$State$| State of customer's residency.\n|$Region$| Region from which the cumstomer placed an order from.\n|$Category$|Order category.\n|$Sub-Category$|Order sub-category.\n|$Sales\t$|Total revenue from sales of that order.\n|$Quantity$| Number of ordered items.\n|$Discount$|Whether or not the customer got a discount with the items bought.\n|$Profit$| Profit made from the purchased items\n\n> ### Size of the dataset: How many entries are in our dataset?","ccb8ab4c":"> ### $Analysis$\n>-  The longest it ever took to ship the order to the customer was 7 days (1 week).\n\n> ### The shortest it took to ship an order","35042acd":"# 5. Dashboard","1218e727":"> - The above dataframe shows grouped regional sales and profits.","b382ee1d":"> ### $Analysis$ $and$ $keys$\n>- The bluer and bigger the dot in each state, the more the profits, \n>- The more bigger and red the do the less the profits or an indication of a loss, \n>- California had the highest profit (76,381), followed by New York with 74,039.\n>- One interesting insight:\n    - Texas had the third highest sales, but made a loss. We will try investigate why. \n","75af14d3":">### $Observation$\n>- We see that there are no missing entries in this dataset.\n\n> ### Statistical Description of Numerical Entries in this Dataset","3f00eef9":"> - We see that we have 4 different shipping modes:\n    1. First Class\n    2. Second Class\n    3. Standard Class\n    4. Same Day\n\n> ### Shipping Modes Profitability\n>- Which shipping method was more profitable? Let's find out:","518d5c7a":"> ### Is there missing data?","da869bf3":"> ### Hypothesis:\n> - __The more sales for each shipping mode, the more the profits__.\n\n> ### $Analysis$\n>- Most shoppers prefer Standard Class Shipping, followed by Second class.\n>- So most shoppers were not in a rush to get their orders delivered same day, hence only 5.6% sales of Same Day Delivery mode. \n    - We do observe that the more the sales, the more profit the business made, conforming to our original hypothesis\n    - This makes sense, we expect to make more profit where we sell more","dd0dc9e1":"> ### Check Dataframe Info Again","3aa0eb7d":"> ## 4.5 Sales and Profit Trends\n> #### Now to the big question: Is this business growing in terms of sales and profits?\n> ### Quarterly Sales Trends","5424d6a6":"> ### $Analysis$\n>- Some orders were shipped within same day of ordering\n\n> ### The Average Shipping Time After Placing An Order","6f54c7f2":"> ### Get Info About Features of the Dataset\n>- We want to observe different datatypes under each column so we have an idea what we are working with. ","d2b08e1e":"> ### $Analysis$ $and$ $keys$\n>- The bluer the state, the more the sales, and the more red the state, the less the sales\n>- California had the highest sales (457,688), followed by New York with 310,876\n\n> #### Which States were most profitable?\n>- #### Let's vizualize profitability with each state","d3c802f8":"> ### $Analysis$\n>- On average, the business ships to customers within 3 days after order placement.\n> #### Recommendation: - <font color=red>Reduce shipment days after customers have placed an order<\/font>.\n    \n> ### Available Shipping Modes\n>- Let's take a look at the available shipping methods for this business","b5e1cedc":"> ### $Analysis$\n>- Central Region had 21.8% of sales, but 13.9% of profits\n>- Eastern Region had 29.5% of sales, and 32.0% of profits\n>- Southern Region had 17.1% of sales, and 16.3% of profits\n>- Western Region had 31.6% of sales and 37.9% of profits\n    - We do observe that the more the sales, the more profit the business made\n    - This makes sense, we expect to make more profit where we sell more\n    - Southern Region saw the least sales; hence the least profit- this is the region that the business should improve in: do more marketing perharps. ","4c2747bf":"# <font color=blue>4. Exploratory Data Analysis<\/font>\n> - We will formulate random questions and try to answer them with data visualilization and analysis as we go along.\n\n>## 4.1 Geographical Segmentation Analysis\n>- #### From which countries do our buyers come from?","2a97a9b8":"> ### $Observation$\n> - Some biggest takeaways from the above:\n    1. Minimum profit of -6599.978 was the biggest loss\n    - Highest amount of profit ever made by the store was 8399.976\n    - At one point sales hit the highest of 22638.48\n    - Average profit is 234.26 while that of sales is 623.25\n    - On average, customers order about 4 items\n    - The highest number of items ordered was 14\n","e96e5ea0":"> ### $Analysis$\n>- All the buyers are based in the United States\n\n> - #### How many states are our customers from?","df6168d1":"> - These are the columns we have in the dataframe and we can see right away which ones we can get rid of as they are not so important for our data analysis.\n  >>- They are: \n      - `Row ID`\n      - `Order ID`\n      - `Customer ID`\n      - `Customer Name`\n      - `Postal Code`\n      - `Region`\n      - `Product ID`\n      - `Product Name`\n\n> ### Dropping Unnecessary Columns","f18bebda":"# <font color=blue>2. Loading Necessary Libraries & Data Ingestion<\/font>\n> ## 2.1 Importing Neccessary Libraries","9b74dea4":"> ### $Observation$\n>- With the above snipped, we see that data ingestion was successful- we have checked the first 2 entries in the dataset just to get a feel of what we will be working with. \n>- The columns are our tell-all, and some of them are straightforward while others are not so easy to decipher (understandably so).","c1a55eca":"> ### $Ananlysis$\n>- The famous category was Office Supplies, but it looks like Technology sold more- this could be for furious reasons: \n    - Office supplies may not be as expensive compared to technology goods. \n    - Office supplies get ordered in large quantities hence their count will be higher than any category"}}