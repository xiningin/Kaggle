{"cell_type":{"c2454488":"code","737f61ba":"code","10ec9cbb":"code","61272f36":"code","09a15d3d":"code","6d4224e0":"code","e676ef0a":"code","164aacf8":"code","06cdbbd2":"code","5a5b28d7":"code","12b7868b":"code","4ebb4a30":"code","974bf215":"code","65cfb832":"code","e4b174cb":"code","75c4609b":"code","32b94b6e":"code","3858bccd":"code","5e3b664f":"code","1bd132b6":"code","3f0f901b":"code","754db13a":"code","86c4d3a8":"code","b7c0bba7":"code","97df1c78":"code","738e5c68":"code","ebdecef3":"code","111f4be6":"code","bc332615":"code","7258a3af":"code","250bb1ba":"code","f03616d6":"code","fb28cc9e":"code","8fc3b0d5":"code","46df94df":"code","5bff373f":"code","4a43bf3b":"code","19fe1a98":"code","a4db7609":"code","53dbde00":"code","fcbaf549":"code","acad38ae":"code","259ec5ef":"code","b11e4418":"code","ccde5bb7":"code","32c9e254":"code","c33730dd":"code","24e28703":"code","56e146fb":"markdown","6a277bcd":"markdown","37023c5c":"markdown","1c0617d4":"markdown","daac42b2":"markdown","39930698":"markdown","21511d9a":"markdown","ea191d87":"markdown","396230ce":"markdown","d314e623":"markdown","f3f34ab8":"markdown","09d2b5e2":"markdown","5f98d5b3":"markdown","513a4c45":"markdown","1e894d2c":"markdown","a5819b97":"markdown","7409ef7b":"markdown","16bcbc4a":"markdown","e91dd9e2":"markdown","92ba3c89":"markdown","4181b151":"markdown","897f3ae9":"markdown","c7629e69":"markdown","9b49df6c":"markdown","2cafdbc4":"markdown","b1e9f248":"markdown","bb214f64":"markdown","72eb7b52":"markdown","603d8a3a":"markdown"},"source":{"c2454488":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","737f61ba":"#Let's start with importing the libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","10ec9cbb":"import sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","61272f36":"#Let's read the csv file to a dataframe 'df'\n\ndf = pd.read_csv(\"\/kaggle\/input\/country-dataset\/Country-data.csv\")\ndf.head()","09a15d3d":"#Checking for the data types. As we see country is a stringID column hence it is object type\ndf.info()","6d4224e0":"#Checking various statistics of columns like mean, median , presence of outliers\ndf.describe(percentiles=[0.25,0.5,0.75,0.95,0.99])","e676ef0a":"#Converting the columns 'exports','health','imports' to absolute value as they are a percentage of Gdp\n\ndf['exports'] = df['exports']*df['gdpp']\/100\ndf['health'] = df['health']*df['gdpp']\/100\ndf['imports'] = df['imports']*df['gdpp']\/100\ndf.head()","164aacf8":"#Checking for the inter-relationships of the attributes\nsns.pairplot(df)","06cdbbd2":"sns.heatmap(df.corr())","5a5b28d7":"#Since our problem is focussed on countries who need help, we need to restrict outliers that lie in a developed nation's range. We do not cap outliers for under developed nations as we may miss out some countries that actually might require help\n\n#low child mortality can be capped\nq = df['child_mort'].quantile(0.01)\ndf['child_mort'][df['child_mort'] < q] = q\nsns.boxplot(df['child_mort'])\nplt.show()","12b7868b":"#Capping low inflation outliers\n\nq = df['inflation'].quantile(0.01)\ndf['inflation'][df['inflation'] < q] = q\nsns.boxplot(df['inflation'])\nplt.show()","4ebb4a30":"#Capping low total_fer outliers\n\nq = df['total_fer'].quantile(0.01)\ndf['total_fer'][df['total_fer'] < q] = q\nsns.boxplot(df['total_fer'])\nplt.show()","974bf215":"#Capping high income outliers to 90 percentile range. We take a little higher range because countries such income levels are self sufficient\n\nq = df['income'].quantile(0.9)\ndf['income'][df['income'] > q] = q\nsns.boxplot(df['income'])\nplt.show()","65cfb832":"# Similarly Capping countries of high health with 90percentile\n\nq = df['health'].quantile(0.9)\ndf['health'][df['health'] > q] = q\nsns.boxplot(df['health'])\nplt.show()","e4b174cb":"#Same capping applies to both export and import\n\nq = df['exports'].quantile(0.9)\ndf['exports'][df['exports'] > q] = q\nsns.boxplot(df['exports'])\nplt.show()","75c4609b":"q = df['imports'].quantile(0.9)\ndf['imports'][df['imports'] > q] = q\nsns.boxplot(df['imports'])\nplt.show()","32b94b6e":"#Capping higher life expectancy to 90percentile range\nq = df['life_expec'].quantile(0.9)\ndf['life_expec'][df['life_expec'] > q] = q\nsns.boxplot(df['life_expec'])\nplt.show()","3858bccd":"#Overall GDP outliers capped at 90percentile range\nq = df['gdpp'].quantile(0.9)\ndf['gdpp'][df['gdpp'] > q] = q\nsns.boxplot(df['gdpp'])\nplt.show()","5e3b664f":"from sklearn.preprocessing import StandardScaler\nsk = StandardScaler()\nscaled_df = sk.fit_transform(df.iloc[:,1:])\nscaled_df","1bd132b6":"df_scaled = pd.DataFrame(scaled_df)\ndf_scaled.head()","3f0f901b":"# Checking for optimal number of clusters using the Elbow approach\nssd = []\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\nfor num_clusters in range_n_clusters:\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(df_scaled)\n    \n    ssd.append(kmeans.inertia_)\n    \nplt.plot(ssd)","754db13a":"#Let's check the Hopkin's score\n\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nimport numpy as np\nfrom math import isnan\n \ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n)\n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","86c4d3a8":"#Let's take the average of 10 iteration of Hopkin's score\na=[]\nfor i in range(10):\n    a.append(hopkins(df_scaled))\n\nprint(sum(a)\/len(a))","b7c0bba7":"#Let's check the Silhoutte score\n\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\nfor num_clusters in range_n_clusters:\n    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(df_scaled)\n    \n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(df_scaled, kmeans.labels_)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))\n    ","97df1c78":"#Applying the Kmeans package\n\nkmeans = KMeans(n_clusters=3, max_iter=50,random_state=100)\nkmeans.fit(df_scaled)","738e5c68":"#Merging the clustered labels into the dataframe df\n\ndf['labels'] = kmeans.labels_\ndf.head()","ebdecef3":"sns.boxplot(x='labels', y='child_mort', data=df)","111f4be6":"sns.boxplot(x='labels', y='gdpp', data=df)","bc332615":"sns.boxplot(x='labels', y='income', data=df)","7258a3af":"df['labels'].value_counts()","250bb1ba":"target = df[df['labels']==0]\ntarget.sort_values(by=['child_mort','gdpp','income'],ascending=[False,True,True]).head()","f03616d6":"import numpy as np\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca.fit(df_scaled)\n\ndf_array = pca.transform(df_scaled)\n\nfig, (ax1) = plt.subplots(1, 1)\nsns.scatterplot(x= df_array[:, 0], y=df_array[:,1], ax=ax1)","fb28cc9e":"fig, (ax2) = plt.subplots(1, 1)\n\ncmap  = sns.color_palette(\"Set1\", n_colors=3)\nsns.scatterplot(x= df_array[:, 0], y=df_array[:,1], hue=kmeans.labels_,  palette = cmap, ax=ax2)","8fc3b0d5":"#Lets fit the single linkage with the scaled data\n\nmergings = linkage(df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","46df94df":"#Cutting the tree with 3 clusters\n\nh_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\nh_labels","5bff373f":"#Adding the label column to the dataset\n\ndf['labels'] = h_labels","4a43bf3b":"sns.boxplot(x='labels', y='gdpp', data=df)","19fe1a98":"df[(df['labels']==1) | (df['labels']==2)]","a4db7609":"sns.boxplot(x='labels', y='child_mort', data=df)","53dbde00":"sns.boxplot(x='labels', y='income', data=df)","fcbaf549":"df['labels'].value_counts()","acad38ae":"df[df['labels']==0].sort_values(by=['child_mort','gdpp','income'],ascending=[False,True,True]).head()","259ec5ef":"mergings = linkage(df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","b11e4418":"h_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )  \nh_labels","ccde5bb7":"df['labels'] = h_labels\ndf","32c9e254":"df['labels'].value_counts()","c33730dd":"sns.boxplot(x='labels', y='gdpp', data=df)","24e28703":"df[df['labels']==0].sort_values(by=['child_mort','gdpp','income'],ascending=[False,True,True]).head()","56e146fb":"Interpreting the clusters from various attributes","6a277bcd":"We can see Cluster 0 seems to have very high child mortality which is a matter of concern. The median is way higher than UN's mentioned limit of 50.","37023c5c":"We can see 3 and 4 seems to provide high silhoutte scores.","1c0617d4":"So we obtain 3 clusters\n\nCluster 1 being the group of High income,gdp and low child mortality\nCluster 0 being the group of low income,gdp and high child mortality\nCluster 2 being the group of average income,gdp and high child mortality\n\nHence Cluster 0 is the primary target","daac42b2":"# Optional - Visualizing using PCA","39930698":"# Problem Statement\n\nHELP International is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. It runs a lot of operational projects from time to time along with advocacy drives to raise awareness as well as for funding purposes.\n\n \n\nAfter the recent funding programmes, they have been able to raise around $ 10 million. Now the CEO of the NGO needs to decide how to use this money strategically and effectively. The significant issues that come while making this decision are mostly related to choosing the countries that are in the direst need of aid. \n\n \n\nAnd this is where you come in as a data analyst. Your job is to categorise the countries using some socio-economic and health factors that determine the overall development of the country. Then you need to suggest the countries which the CEO needs to focus on the most.  The datasets containing those socio-economic factors and the corresponding data dictionary are provided below.","21511d9a":"<b>Complete Linkage!<\/b>","ea191d87":"# Hierarchical Clustering","396230ce":"# K-Means Clustering","d314e623":"So we have out scaled data stored as 'df_scaled'.Lets perform the clustering on the data set","f3f34ab8":"We fundamentally have idea about 3 major types of countries- under-developed\/ developing and developed nations. So from the curve we have the ideal option of 3 or 4 clusters","09d2b5e2":"So the Top 5 countries to focus:-","5f98d5b3":"We obtain the same countries as Kmeans","513a4c45":"We see single linkage to be inefficient with 3 clusters. Cluster 1 represents a country with high income and GDP as well as high mortality while Nigeria shows high mortality with sustainable economy. ","1e894d2c":"Capping the outliers","a5819b97":"Lets ","7409ef7b":"We have the major 45 countries that are of prime concern. Lets find the top 5 countries to target","16bcbc4a":"Let's proceed with 3 clusters","e91dd9e2":"We can confirm from the correlation heatmap that high income,export\/import,health,life expectancy are signs of a developed nation while higher inflation,child mort,total_fer are signs of under-developed nations and those are the countries we need to address.","92ba3c89":"# Scaling","4181b151":"We can get some basic insights about the factors that add to a developing\/developed nation from their inter-relationships\n\nWe can see \n-income,health,export\/import have strong linear relationship for a higher GDP\n-Child mort,total fer seems to be higher for countries with low GDP\n-Inflation seems to be slightly higher for countries with lower income\/GDP\n","897f3ae9":"Similarly cluster 0 shows low level of income as a sign of under developed nation","c7629e69":"And the results are same!","9b49df6c":"<b>Cluster inferences<\/b>\n\n-Cluster 0 is under-developed nation\n\n-Cluster 1 is developed nation\n\n-Cluster 2 is developing nation\n\nOur main focus is on cluster 0","2cafdbc4":"<b>Single Linkage!<\/b>\n","b1e9f248":"So we can see the 3 clusters formed here","bb214f64":"Hopkin's value lies between 85-90% which is good value.This shows the data has a good tendency of getting associated into clusters\n","72eb7b52":"Cluster 0 seems to have lower GDP while cluster 2 seems to show signs of a developing nation","603d8a3a":"We see complete linkage to perform better than single linkage "}}