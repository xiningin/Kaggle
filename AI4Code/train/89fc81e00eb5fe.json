{"cell_type":{"3889f59d":"code","139e9a89":"code","0a0c202d":"code","7e065878":"code","26e6211d":"code","86ae7157":"code","692b9b46":"code","9754c62f":"code","0f0fb9ec":"code","ff03e21f":"code","89f39433":"code","1fe2c91d":"code","f6de3a50":"code","6b846b00":"code","6b53eea1":"code","94147bc6":"code","63d9cbbc":"code","96eb29f7":"code","e26ab034":"code","a50a1313":"code","5749432f":"code","25d6cfa4":"code","96cec5b3":"code","857bab7d":"code","d96bc248":"code","df9cdca4":"code","89757254":"code","a05a5cfa":"code","42458798":"code","ee1e68a6":"code","38c439d0":"code","155456c4":"code","95f055ff":"code","bf7753fc":"code","cf2beea7":"code","b4b00157":"code","e7356573":"code","c036d7f8":"code","1771f478":"code","8cb87cd3":"code","02b7d380":"code","73cd3deb":"code","898a974a":"code","7f60cb2e":"code","331b032f":"code","65efb08f":"code","e7037844":"code","1c91b55d":"code","8a47dcbe":"code","8810fac6":"code","c5c69550":"code","1a94c847":"code","2057f1cc":"code","f2fcfda4":"code","cf864f6a":"code","a048cf93":"code","a9145207":"code","a4e96ba2":"markdown","e1a5fc44":"markdown","8cac46a3":"markdown","2497417b":"markdown","2a28c16b":"markdown","f9e40cde":"markdown","0e0d305b":"markdown","87a11d9d":"markdown","3ddcba84":"markdown","2c045cac":"markdown","2562b702":"markdown","9f56aabc":"markdown","a1f2f096":"markdown","7161bc50":"markdown","17a4e30d":"markdown","4cc15fa1":"markdown","40e11132":"markdown","ba573c94":"markdown","816fc866":"markdown","709f02a3":"markdown","7706187f":"markdown","7df00231":"markdown","bbbc597b":"markdown"},"source":{"3889f59d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","139e9a89":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0a0c202d":"pd.pandas.set_option('display.max_columns', None)\ndataset = pd.read_csv('..\/input\/a-fine-windy-day-hackerearth-ml-challenge\/train_data.csv')\ndataset.head()","7e065878":"dataset.columns","26e6211d":"dataset.isnull().sum()","86ae7157":"null_col = [i for i in dataset.columns if dataset[i].isnull().sum()>0 and dataset[i].dtypes != 'O']\nnull_col","692b9b46":"for i in null_col:\n    dataset[i].fillna(dataset[i].mean(), inplace=True)\ndataset.isnull().sum()","9754c62f":"dataset.cloud_level.value_counts()","0f0fb9ec":"dataset['cloud_level'].fillna('Low', inplace=True)\ndataset.isnull().sum()","ff03e21f":"dataset['turbine_status'].unique()","89f39433":"# dum = ['turbine_status']\n# df_dum = pd.get_dummies(dataset[dum])\n# dataset = pd.concat([dataset,df_dum],axis=1)\n# dataset.drop('turbine_status', axis=1, inplace=True)","1fe2c91d":"dataset['turbine_status'].fillna('Missing', inplace=True)\nl = ['BA', 'A2', 'ABC', 'AAA', 'BD', 'AC', 'BB', 'BCB', 'B', 'AB', 'Missing', 'B2', 'BBB', 'A', 'D']\nfeat_tur = dict()\nfor i in range(len(l)):\n    feat_tur[l[i]] = i\nfeat_tur\ndataset['turbine_status']=dataset['turbine_status'].map(feat_tur)\n\ndataset.isnull().sum()","f6de3a50":"dataset['datetime'] = pd.to_datetime(dataset['datetime'])\ndataset['day'] = dataset['datetime'].dt.date\ndataset['time'] = dataset['datetime'].dt.time\n# dataset.drop('datetime', axis=1, inplace=True)\ndataset['day'] = pd.to_datetime(dataset['day'])\ndataset['time']= pd.to_datetime(dataset['time'].astype(str))\ndataset.dtypes","6b846b00":"dataset['date']=dataset['day'].dt.day\ndataset['month']=dataset['day'].dt.month\ndataset['year']=dataset['day'].dt.year\ndataset.drop('day', axis=1, inplace=True)\ndataset.head(2)","6b53eea1":"dataset['time_hour'] = dataset['time'].dt.hour\ndataset['time_minute'] = dataset['time'].dt.minute\ndataset.drop('time', axis=1, inplace=True)\ndataset.head(2)","94147bc6":"dataset.dtypes","63d9cbbc":"plt_feat = ['datetime', 'wind_speed(m\/s)',\n       'atmospheric_temperature(\u00b0C)', 'shaft_temperature(\u00b0C)',\n       'blades_angle(\u00b0)', 'gearbox_temperature(\u00b0C)', 'engine_temperature(\u00b0C)',\n       'motor_torque(N-m)', 'generator_temperature(\u00b0C)',\n       'atmospheric_pressure(Pascal)', 'area_temperature(\u00b0C)',\n       'windmill_body_temperature(\u00b0C)', 'wind_direction(\u00b0)', 'resistance(ohm)',\n       'rotor_torque(N-m)', 'cloud_level', 'blade_length(m)',\n       'blade_breadth(m)', 'windmill_height(m)']","96eb29f7":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfor i in plt_feat:\n    plt.figure(figsize=(8,4))\n    sns.scatterplot(data=dataset, x=i, y='windmill_generated_power(kW\/h)')","e26ab034":"def change(s):\n    if s<-200 or s>300:\n        return dataset[\"gearbox_temperature(\u00b0C)\"].mean()\n    else:\n        return s\ndataset[\"gearbox_temperature(\u00b0C)\"] = dataset[\"gearbox_temperature(\u00b0C)\"].apply(change)","a50a1313":"def remove_99_atmospheric_temperature(s):\n    if s == -99.000000:\n        return dataset['atmospheric_temperature(\u00b0C)'].mean()\n    else:\n        return s\n    \n\ndataset[ 'atmospheric_temperature(\u00b0C)'] = dataset[ 'atmospheric_temperature(\u00b0C)'].apply(remove_99_atmospheric_temperature)\nsns.scatterplot(data=dataset, x= 'atmospheric_temperature(\u00b0C)', y='windmill_generated_power(kW\/h)')","5749432f":"def remove_99_shaft_temperature(s):\n    if s == -99.000000:\n        return dataset['shaft_temperature(\u00b0C)'].mean()\n    else:\n        return s\n    \ndataset[ 'shaft_temperature(\u00b0C)'] = dataset[ 'shaft_temperature(\u00b0C)'].apply(remove_99_shaft_temperature)\nsns.scatterplot(data=dataset, x= 'shaft_temperature(\u00b0C)', y='windmill_generated_power(kW\/h)')","25d6cfa4":"def remove_99_blade_length(s):\n    if s == -99.000000:\n        return dataset['blade_length(m)'].mean()\n    else:\n        return s\n    \ndataset[ 'blade_length(m)'] = dataset[ 'blade_length(m)'].apply(remove_99_blade_length)\nsns.scatterplot(data=dataset, x= 'blade_length(m)', y='windmill_generated_power(kW\/h)')","96cec5b3":"def remove_99_area_temperature(s):\n    if s < -10:\n        return dataset['area_temperature(\u00b0C)'].mean()\n    else:\n        return s\n    \ndataset[ 'area_temperature(\u00b0C)'] = dataset[ 'area_temperature(\u00b0C)'].apply(remove_99_area_temperature)\nsns.scatterplot(data=dataset, x= 'area_temperature(\u00b0C)', y='windmill_generated_power(kW\/h)')","857bab7d":"def remove_99_engine_temperature(s):\n    if s < 38:\n        return dataset['engine_temperature(\u00b0C)'].mean()\n    else:\n        return s\n    \ndataset[ 'engine_temperature(\u00b0C)'] = dataset[ 'engine_temperature(\u00b0C)'].apply(remove_99_engine_temperature)\nsns.scatterplot(data=dataset, x= 'engine_temperature(\u00b0C)', y='windmill_generated_power(kW\/h)')","d96bc248":"dataset.drop('windmill_body_temperature(\u00b0C)', axis=1, inplace=True)","df9cdca4":"dataset['radius'] = dataset['blade_length(m)'] * dataset['blade_length(m)'] * 3.14","89757254":"sns.scatterplot(data=dataset, x= 'radius', y='windmill_generated_power(kW\/h)')","a05a5cfa":"dataset['air_density'] = dataset['atmospheric_pressure(Pascal)'] \/ (dataset['atmospheric_temperature(\u00b0C)'] * 287.058)\nsns.scatterplot(data=dataset, x= 'air_density', y='windmill_generated_power(kW\/h)')","42458798":"def air_density_remover(s):\n    if s < -38000:\n        return dataset['air_density'].mean()\n    else:\n        return s\n    \ndataset[ 'air_density'] = dataset[ 'air_density'].apply(air_density_remover)\nsns.scatterplot(data=dataset, x= 'air_density', y='windmill_generated_power(kW\/h)')","ee1e68a6":"# list_99 = [ 'atmospheric_temperature(\u00b0C)', 'shaft_temperature(\u00b0C)', 'blade_length(m)']\n## area_temperature less than -10\n## engine_temp less than 38 engine_temperature\n## drop 'windmill_body_temperature(\u00b0C)'","38c439d0":"dataset['cloud_level'].value_counts()","155456c4":"# cloud_level = {'Low':'Low', 'Medium':'Medium', 'Extremely Low':'Low'}\n# dataset['cloud_level']=dataset['cloud_level'].map(cloud_level)\n# dataset['cloud_level'].value_counts()","95f055ff":"cloud = pd.get_dummies(dataset['cloud_level'])\ncloud.head(2)","bf7753fc":"train_data = pd.concat([dataset, cloud], axis=1)\ntrain_data.drop('cloud_level', axis=1, inplace=True)\ntrain_data.head(2)","cf2beea7":"train_data.info()","b4b00157":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nfeature_scale = [i for i in train_data.columns if i not in ['tracking_id','datetime', 'windmill_generated_power(kW\/h)']]\nscale.fit(train_data[feature_scale])","e7356573":"scaled = pd.DataFrame(scale.transform(train_data[feature_scale]), columns=feature_scale)\nscaled.head()","c036d7f8":"data = pd.concat([train_data[['tracking_id','datetime', 'windmill_generated_power(kW\/h)']], scaled], axis=1)\ndata.head()","1771f478":"X_train = data.drop(['windmill_generated_power(kW\/h)','datetime', 'tracking_id'], axis=1)\ny_train = data['windmill_generated_power(kW\/h)']\nX_train.shape, y_train.shape","8cb87cd3":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\ndef baseline_model():\n    model = Sequential([\n        Dense(27, input_dim=27, kernel_initializer='normal', activation='relu'),\n        Dense(15,  kernel_initializer='normal', activation='relu'),\n        Dense(5,  kernel_initializer='normal', activation='relu'),\n        Dense(1, kernel_initializer='normal')\n    ])\n\n    model.compile(optimizer='adam', \n                 loss='mean_squared_error',\n    )\n    return model\n\nestimator = KerasRegressor(build_fn=baseline_model, epochs=30, batch_size=5, verbose=1)\nkfold = KFold(n_splits=2)\nresults = cross_val_score(estimator, X_train, y_train, cv=kfold)\n# results = cross_val_score(estimator, X_train, y_train)\nprint(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n\nestimator.fit(X_train, y_train)\n\n# model.fit(X_train, y_train, epochs=3)","02b7d380":"# from sklearn.ensemble import RandomForestRegressor\n\n# model = RandomForestRegressor(n_estimators=1000).fit(X_train, y_train)\n# print(f'Training Accuracy: {model.score(X_train, y_train)}')","73cd3deb":"# from xgboost import XGBRegressor\n# xgb = XGBRegressor(n_estimators=500,max_depth=5,booster='gbtree',n_jobs=-1,learning_rate=0.1,reg_lambda=0.01,reg_alpha=0.3)\n# xgb.fit(X_train, y_train)\n# print(f'Training Accuracy: {xgb.score(X_train, y_train)}')","898a974a":"# from sklearn.ensemble import GradientBoostingRegressor\n# gboost = GradientBoostingRegressor(criterion='mse',random_state=0,max_depth=5,n_estimators=500,min_samples_split=2,min_samples_leaf=2)\n# gboost.fit(X_train,y_train)\n# print(f'Training Accuracy: {gboost.score(X_train, y_train)}')","7f60cb2e":"# from sklearn.tree import DecisionTreeRegressor\n# tree = DecisionTreeRegressor(min_samples_leaf=2)\n# tree.fit(X_train, y_train)\n# print(f'Training Accuracy: {tree.score(X_train, y_train)}')","331b032f":"# scene","65efb08f":"test_data = pd.read_csv('..\/input\/a-fine-windy-day-hackerearth-ml-challenge\/test_data.csv')\ntest_data.head(2)","e7037844":"test_data.columns","1c91b55d":"test_data.isnull().sum()","8a47dcbe":"test_null_col = [i for i in test_data.columns if test_data[i].isnull().sum()>0 and test_data[i].dtypes != 'O']\n\nfor i in test_null_col:\n    test_data[i].fillna(test_data[i].mean(), inplace=True)\n\ntest_data['cloud_level'].fillna(dataset['cloud_level'].mode(), inplace=True)\n# test_data.dropna(how='any',axis=0,inplace=True)\n# test_data['datetime'] = encode.fit_transform(test_data['datetime'])\n# test_data['tracking_id'] = encode.fit_transform(test_data['tracking_id'])\n\ntest_data['turbine_status'].fillna('Missing', inplace=True)\nl = ['BA', 'A2', 'ABC', 'AAA', 'BD', 'AC', 'BB', 'BCB', 'B', 'AB', 'Missing', 'B2', 'BBB', 'A', 'D']\ntest_feat_tur = dict()\nfor i in range(len(l)):\n    test_feat_tur[l[i]] = i\ntest_feat_tur\ntest_data['turbine_status']=test_data['turbine_status'].map(test_feat_tur)\n\ntest_data['datetime'] = pd.to_datetime(test_data['datetime'])\ntest_data['day'] = test_data['datetime'].dt.date\ntest_data['time'] = test_data['datetime'].dt.time\n# test_data.drop('datetime', axis=1, inplace=True)\ntest_data['day'] = pd.to_datetime(test_data['day'])\ntest_data['time']= pd.to_datetime(test_data['time'].astype(str))\ntest_data['date']=test_data['day'].dt.day\ntest_data['month']=test_data['day'].dt.month\ntest_data['year']=test_data['day'].dt.year\ntest_data.drop('day', axis=1, inplace=True)\ntest_data['time_hour'] = test_data['time'].dt.hour\ntest_data['time_minute'] = test_data['time'].dt.minute\ntest_data.drop('time', axis=1, inplace=True)\n\n# dum = ['turbine_status']\n# df_dum = pd.get_dummies(test_data[dum])\n# test_data = pd.concat([test_data,df_dum],axis=1)\n# test_data.drop('turbine_status', axis=1, inplace=True)\n\n# test_data['cloud_level']=test_data['cloud_level'].map(cloud_level)\n# test_data['cloud_level'].value_counts()\n\n##feature changing start\n\n# low = test_data['gearbox_temperature(\u00b0C)'] < -200\n# high = test_data['gearbox_temperature(\u00b0C)'] > 300\n# low = np.where(low)\n# high = np.where(high)\n# test_data.drop(low[0],inplace=True)\n# test_data.drop(high[0],inplace=True)\n# test_data.index = range(test_data.shape[0])\n\n# low = test_data['engine_temperature(\u00b0C)'] < 38\n# low = np.where(low)\n# test_data.drop(low[0],inplace=True)\n# test_data.index = range(test_data.shape[0])\n\n# low = test_data['area_temperature(\u00b0C)'] < 10\n# low = np.where(low)\n# test_data.drop(low[0],inplace=True)\n# test_data.index = range(test_data.shape[0])\n\n# low = test_data['blade_length(m)'] < -20\n# low = np.where(low)\n# test_data.drop(low[0],inplace=True)\n# test_data.index = range(test_data.shape[0])\n\n## feature changing ends\n\n### replacing outliers with mean\n#----------------------------START\n\ntest_data[\"gearbox_temperature(\u00b0C)\"] =      test_data[\"gearbox_temperature(\u00b0C)\"].apply(change)\ntest_data[ 'atmospheric_temperature(\u00b0C)'] = test_data[ 'atmospheric_temperature(\u00b0C)'].apply(remove_99_atmospheric_temperature)    \ntest_data[ 'shaft_temperature(\u00b0C)'] =       test_data[ 'shaft_temperature(\u00b0C)'].apply(remove_99_shaft_temperature)    \ntest_data[ 'blade_length(m)'] =             test_data[ 'blade_length(m)'].apply(remove_99_blade_length)    \ntest_data[ 'area_temperature(\u00b0C)'] =        test_data[ 'area_temperature(\u00b0C)'].apply(remove_99_area_temperature)    \ntest_data[ 'engine_temperature(\u00b0C)'] =      test_data[ 'engine_temperature(\u00b0C)'].apply(remove_99_engine_temperature)\ntest_data.drop('windmill_body_temperature(\u00b0C)', axis=1, inplace=True)\n\n#----------------------------END\n\ntest_data['radius'] = test_data['blade_length(m)'] * test_data['blade_length(m)'] * 3.14\ntest_data['air_density'] = test_data['atmospheric_pressure(Pascal)'] \/ (test_data['atmospheric_temperature(\u00b0C)'] * 287.058)\ntest_data[ 'air_density'] = test_data[ 'air_density'].apply(air_density_remover)\n\ncloud = pd.get_dummies(test_data['cloud_level'])\n\ntest_data = pd.concat([test_data, cloud], axis=1)\ntest_data.drop('cloud_level', axis=1, inplace=True)\n\ntest_feature_scale = [i for i in test_data.columns if i not in ['tracking_id','datetime']]\nscale.fit(test_data[test_feature_scale])\n\ntest_scaled = pd.DataFrame(scale.transform(test_data[test_feature_scale]), columns=test_feature_scale)\nfinal_testdata = pd.concat([test_data[['tracking_id', 'datetime']], test_scaled], axis=1)\nfinal_testdata.head()","8810fac6":"final_testdata.isnull().sum()","c5c69550":"X_test = final_testdata.drop(['tracking_id','datetime'], axis=1)","1a94c847":"X_test.shape, X_train.shape","2057f1cc":"X_test.columns, X_train.columns","f2fcfda4":"test = final_testdata.copy()","cf864f6a":"test.head()","a048cf93":"# test.fillna(test.mean())","a9145207":"test['preds']=estimator.predict(X_test)\nprediction=test[['tracking_id','datetime','preds']]\nprediction.columns=['tracking_id','datetime','windmill_generated_power(kW\/h)']\n# preds['tracking_id']=encode.inverse_transform(preds['tracking_id'])\n# preds['datetime']=encode.inverse_transform(preds['datetime'])\n# preds.drop('Unnamed: 0', inplace=True)\nprediction.to_csv('my_submission.csv',index=False, header=True)","a4e96ba2":"#### Decision Tree --> 99.2893%\n#### Training Accuracy --> 94.1229%","e1a5fc44":"## Feature Scaling","8cac46a3":"#### XGBoost --> 98.6206%\n#### Testing Accuracy --> 95.65499%","2497417b":"## Working with test data","2a28c16b":"### Removing null values from numerical dataset","f9e40cde":"### Seperating Dependent and Independent Variable","0e0d305b":"### Creating new feature","87a11d9d":"### Removing null values from categorical dataset","3ddcba84":"#### Random Forest --> 99.3998%\n#### Testing Accuracy --> 95.835418%","2c045cac":"## Data Exploration","2562b702":"## Importing Libraries","9f56aabc":"## Null Values","a1f2f096":"#### Gradient Boosting --> 98.5157%\n#### Testing Accuracy --> 94.1229%","7161bc50":"#### Further seperating date into date, month, year","17a4e30d":"## Model Training","4cc15fa1":"### Neural Network","40e11132":"## Removing Outliers","ba573c94":"### Seperating data and time from 'datetime' feature","816fc866":"### Model Fitting","709f02a3":"#### Similarly seperating hour and minute from time","7706187f":"## Data Visualization","7df00231":"## Feature Engineering","bbbc597b":"## Submission"}}