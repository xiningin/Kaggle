{"cell_type":{"2966b8c1":"code","a72106f0":"code","a048298d":"code","62769bb5":"code","37f615f9":"code","1f2ca654":"code","4a9594fd":"code","15230c5e":"code","3110158e":"code","95a35604":"code","76f029d7":"code","b8c16454":"code","57be711b":"code","a30f2ed7":"code","28e76ca6":"code","e7265452":"code","e9a7e53f":"code","c3c6f55e":"code","20bdebed":"code","a8c84fdc":"code","56ce826d":"code","cb973051":"code","a2c9bf5f":"code","19745c89":"code","9090f903":"markdown","34117cf5":"markdown","ff2edd64":"markdown","5a5b2988":"markdown","18d8f357":"markdown","6f223588":"markdown","664c1fb2":"markdown"},"source":{"2966b8c1":"import shutil\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)","a72106f0":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a048298d":"CONTENT_DIR = '\/kaggle\/content'\n\nTRAIN_DIR = CONTENT_DIR + '\/train'\nTRAIN_DIR_DOG = TRAIN_DIR + '\/dog'\nTRAIN_DIR_CAT = TRAIN_DIR + '\/cat'\n\nVALID_DIR = CONTENT_DIR + '\/valid'\nVALID_DIR_DOG = VALID_DIR + '\/dog'\nVALID_DIR_CAT = VALID_DIR + '\/cat'","62769bb5":"# Extract files\nimport zipfile\nwith zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/train.zip', 'r') as zipf:\n    zipf.extractall(CONTENT_DIR)\n    \n# !ls -la ..\/content\/train\/\n# -rw-r--r-- 1 root root  12414 Nov  2 03:15 cat.0.jpg\n# ...\n# -rw-r--r-- 1 root root   3339 Nov  2 03:46 dog.9999.jpg","37f615f9":"# Split cats and dogs images to train and valid datasets\nimg_filenames = os.listdir(TRAIN_DIR)\nprint('Num of images:', len(img_filenames))\n\ndog_filenames = [fn for fn in img_filenames if fn.startswith('dog')]\ncat_filenames = [fn for fn in img_filenames if fn.startswith('cat')]\n\ndataset_filenames = train_test_split(\n    dog_filenames, cat_filenames, test_size=0.1, shuffle=True, random_state=42\n)\n\ntrain_dog_total, valid_dog_total, train_cat_total, valid_cat_total = [len(fns) for fns in dataset_filenames]\ntrain_total = train_dog_total + train_cat_total\nvalid_total = valid_dog_total + valid_cat_total\nprint('Train: {}, test: {}'.format(train_total, valid_total))","1f2ca654":"# Move images\nmake_dirs = [TRAIN_DIR_DOG, VALID_DIR_DOG, TRAIN_DIR_CAT, VALID_DIR_CAT]\nfor dir, fns in zip(make_dirs, dataset_filenames):\n    os.makedirs(dir, exist_ok=True)\n    for fn in tqdm.tqdm(fns):\n        shutil.move(os.path.join(TRAIN_DIR, fn), dir)\n    print('elements in {}: {}'.format(dir, len(os.listdir(dir))))","4a9594fd":"# Uncomment and run to clear content dir\n# !rm -rf ..\/content\/*","15230c5e":"BATCH_SIZE = 128\nIMAGE_SHAPE = 128","3110158e":"train_generator = ImageDataGenerator(rescale=1.\/255)\nvalid_generator = ImageDataGenerator(rescale=1.\/255)","95a35604":"train_data = train_generator.flow_from_directory(\n    directory=TRAIN_DIR,\n    target_size=(IMAGE_SHAPE, IMAGE_SHAPE),\n    batch_size=BATCH_SIZE,\n    class_mode='binary'\n)\nvalid_data = valid_generator.flow_from_directory(\n    directory=VALID_DIR,\n    target_size=(IMAGE_SHAPE, IMAGE_SHAPE),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)","76f029d7":"# show 25 images\nsome_pets = next(train_data)[0][:25]\nfig, axes = plt.subplots(5, 5, figsize=(20, 20))\nfor img, ax in zip(some_pets, axes.flatten()):\n    ax.imshow(img)\nplt.tight_layout()\nplt.show()","b8c16454":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(\n        filters=32,\n        kernel_size=(3, 3),\n        activation='relu',\n        input_shape=(IMAGE_SHAPE, IMAGE_SHAPE, 3)\n    ),\n    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=512, activation='relu'),\n    tf.keras.layers.Dense(units=2, activation='softmax')\n])","57be711b":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","a30f2ed7":"model.summary()","28e76ca6":"EPOCHS = 60","e7265452":"history = model.fit_generator(\n    generator=train_data,\n    steps_per_epoch=(train_total + BATCH_SIZE - 1) \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=valid_data,\n    validation_steps=(valid_total + BATCH_SIZE - 1) \/\/ BATCH_SIZE,\n)","e9a7e53f":"# save model - optional\nmodel.save('.\/checkpoints\/model4_60epoch.h5')","c3c6f55e":"# download model - optional\n# import os\n# os.chdir(r'\/kaggle\/working')\n# from IPython.display import FileLink\n# FileLink(r'.\/checkpoints\/model4_60epoch.h5')","20bdebed":"# set finish path\n# os.chdir(r'..')","a8c84fdc":"plt.figure(figsize=(12, 8))\n\nplt.subplot(1, 2, 1)\nplt.plot(range(EPOCHS), history.history['accuracy'], label='train')\nplt.plot(range(EPOCHS), history.history['val_accuracy'], label='valid')\nplt.legend(loc='lower right')\nplt.title('Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(EPOCHS), history.history['loss'], label='train')\nplt.plot(range(EPOCHS), history.history['val_loss'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Loss (sparse_categorical_crossentropy)')\n\nplt.show()","56ce826d":"TEST_DIR = CONTENT_DIR + '\/test'\n\n# Extract files\nimport zipfile\nwith zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/test1.zip', 'r') as zipf:\n    zipf.extractall(TEST_DIR)","cb973051":"test_generator = ImageDataGenerator(rescale=1.\/255)\n\ntest_data = test_generator.flow_from_directory(\n    directory=TEST_DIR,\n    target_size=(IMAGE_SHAPE, IMAGE_SHAPE),\n    batch_size=1,\n    class_mode='binary',\n    shuffle=False\n)\ntest_data.reset()\n\ntest_total = len(test_data.filenames)\npredict = model.predict_generator(test_data, steps=test_total, verbose=1)","a2c9bf5f":"# labels = dict((v,k) for k,v in train_data.class_indices.items())\n# predictions = [labels[k] for k in np.argmax(predict,axis=1)]\n# predictions","19745c89":"submission = pd.read_csv('\/kaggle\/input\/dogs-vs-cats\/sampleSubmission.csv', index_col='id')\nsubmission['label'] = np.argmax(predict,axis=1)\nsubmission.to_csv('.\/my_submission.csv')","9090f903":"# Image visualization","34117cf5":"# Preprocessing\n1. decode images\n1. rescale image layers from [0..255] to [0,1]","ff2edd64":"**Baseline to Image Classification Using CNN (Dogs vs. Cats) with Tensorflow & Keras**\n\n* Intro part.\n* 2nd part: [Intro to CNN: Augmentation & Dropout](https:\/\/www.kaggle.com\/imcr00z\/intro-to-cnn-augmentation-dropout)\n* 3rd part: [Transfer Learning (Dogs vs. Cats) 98% acc.](https:\/\/www.kaggle.com\/imcr00z\/transfer-learning-dogs-vs-cats-98-acc)","5a5b2988":"# Predictions\n1. unzip test data\n1. scale and predict\n1. save results","18d8f357":"# Unpack & load data\n1. unpack data\n1. split dogs and cats to train and valid datasets\n1. put dogs and cats files according to their catalogs (need for ImageDataGenerator)","6f223588":"# Train visualization\nLook to validation loss. You see overfitting after ? epoch. Maybe better stay there","664c1fb2":"# Model\n1. create model\n1. compile\n1. summary\n1. training"}}