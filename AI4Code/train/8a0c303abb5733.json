{"cell_type":{"cbf91eac":"code","b97e8dc2":"code","d956d000":"code","67d9c30f":"code","635a0987":"code","7ff83da2":"code","b87474ae":"code","ad3372af":"code","2013cbde":"code","841c200d":"code","6e096c89":"code","191425e5":"code","a62fb8e3":"code","723be109":"code","4e1743a2":"code","3c422a83":"code","2fbb5031":"code","e169e587":"code","6e78df4c":"code","3a138be5":"code","b6a2bfcd":"code","3df88f4f":"code","76b52144":"code","2d84c41a":"code","31cb2001":"code","261e0e45":"code","e76ffdb6":"code","97a296cb":"code","91b7a4de":"code","b6b905d3":"code","0b5afb0d":"code","f53acbe4":"code","50d228c7":"code","2d258d0f":"code","e9c1445c":"code","9cd5f1aa":"code","d417a10c":"code","7e555bfb":"markdown","e7773075":"markdown","9f9ecaa7":"markdown","94ae6d20":"markdown","39cca4a5":"markdown","11815e58":"markdown","32ce6c09":"markdown","13530041":"markdown","97191066":"markdown","ef3e2836":"markdown","38a1c943":"markdown","aa7f34fa":"markdown","b2d21e28":"markdown","3b17f2c0":"markdown","a797f6db":"markdown","1f1ac99e":"markdown","3dc2b77e":"markdown","62412dc4":"markdown","bf2cdc33":"markdown","f43e31ea":"markdown","a3d9f630":"markdown","f88d143e":"markdown","8ec51307":"markdown","3909aa52":"markdown","305a3c30":"markdown","fefe0f99":"markdown","5ea9ff2c":"markdown","8cd44bee":"markdown","546913bc":"markdown","8bcdbdb7":"markdown","1454883b":"markdown","898d29b8":"markdown","8345dfbf":"markdown","48426200":"markdown","47e96db8":"markdown","e9b341c3":"markdown","99439ea5":"markdown","b48e5ff5":"markdown","da7be327":"markdown","e7b8f201":"markdown"},"source":{"cbf91eac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b97e8dc2":"advertising_dataset = pd.read_csv('..\/input\/advertising\/advertising.csv')","d956d000":"advertising_dataset.shape","67d9c30f":"advertising_dataset.head()","635a0987":"advertising_dataset.info()","7ff83da2":"sns.countplot(advertising_dataset['Clicked on Ad'], data=advertising_dataset)","b87474ae":"sns.distplot(advertising_dataset['Age'][advertising_dataset['Clicked on Ad']==1], color='green')\nsns.distplot(advertising_dataset['Age'][advertising_dataset['Clicked on Ad']==0], color='red')\nplt.legend(\"0\", \"1\")\nplt.show()","ad3372af":"sns.distplot(advertising_dataset['Daily Time Spent on Site'][advertising_dataset['Clicked on Ad']==1], color='green')\nsns.distplot(advertising_dataset['Daily Time Spent on Site'][advertising_dataset['Clicked on Ad']==0], color='red')\nplt.show()","2013cbde":"sns.countplot(advertising_dataset['Male'][advertising_dataset['Clicked on Ad']==1])","841c200d":"sns.countplot(advertising_dataset['Male'][advertising_dataset['Clicked on Ad']==0])","6e096c89":"x = advertising_dataset['Area Income']\ny = advertising_dataset['Clicked on Ad']\nplt.scatter(x, y)","191425e5":"sns.distplot(advertising_dataset['Daily Internet Usage'][advertising_dataset['Clicked on Ad']==1], color='green')\nsns.distplot(advertising_dataset['Daily Internet Usage'][advertising_dataset['Clicked on Ad']==0], color='red')","a62fb8e3":"sns.pairplot(advertising_dataset, hue = 'Clicked on Ad', vars = ['Daily Time Spent on Site', 'Age' ,'Area Income', 'Daily Internet Usage'],\n             palette = 'husl')","723be109":"advertising_dataset.duplicated().sum()","4e1743a2":"advertising_dataset.describe()","3c422a83":"advertising_dataset['Timestamp'] = pd.to_datetime(advertising_dataset['Timestamp']) \nadvertising_dataset['Month'] = advertising_dataset['Timestamp'].dt.month \nadvertising_dataset['Day'] = advertising_dataset['Timestamp'].dt.day     \nadvertising_dataset['Hour'] = advertising_dataset['Timestamp'].dt.hour   \nadvertising_dataset[\"Weekday\"] = advertising_dataset['Timestamp'].dt.dayofweek ","2fbb5031":"advertising_dataset = advertising_dataset.drop(['Timestamp'], axis=1)\nadvertising_dataset.head()","e169e587":"plt.figure(figsize=(12,5))\nsns.heatmap(advertising_dataset.corr(), cmap='RdYlGn', annot=True)\nplt.show()","6e78df4c":"advertising_dataset.drop(['Male', 'Month', 'Day', 'Hour', 'Weekday'], axis=1)","3a138be5":"cat_features = advertising_dataset.select_dtypes(include=['object']).columns\ncat_features","b6a2bfcd":"advertising_dataset = pd.get_dummies(advertising_dataset)\nadvertising_dataset.shape","3df88f4f":"features = advertising_dataset.drop(['Clicked on Ad'], axis=1)\nlabel = advertising_dataset['Clicked on Ad']\nfeatures.shape, label.shape","76b52144":"from sklearn.model_selection import train_test_split\nfeature_train, feature_test, label_train, label_test = train_test_split(features, label, random_state = 7, test_size=0.3)\nfeature_train.shape, feature_test.shape, label_train.shape, label_test.shape","2d84c41a":"#Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]\n\n#Number of features to consider in every split\nmax_features = ['auto', 'sqrt']\n\n#Maximum number of levels in a tree\nmax_depth = [int(x) for x in np.linspace(start=5, stop=30, num=6)]\n\n#Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n\n#Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]\n\n#Random Grid\nrandom_grid = {'n_estimators' : n_estimators,\n              'max_features' : max_features,\n              'max_depth' : max_depth,\n              'min_samples_split' : min_samples_split,\n              'min_samples_leaf' : min_samples_leaf}","31cb2001":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_forest = RandomForestClassifier()\nrandom_forest_model = RandomizedSearchCV(estimator=random_forest, param_distributions=random_grid, scoring='accuracy',\n                                        cv=5, n_jobs=1, n_iter=10, verbose=2)\nrandom_forest_model.fit(feature_train, label_train)","261e0e45":"random_forest_model.best_params_","e76ffdb6":"label_pred = random_forest_model.predict(feature_test)\nlabel_pred","97a296cb":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve","91b7a4de":"confusion_matrix(label_test, label_pred)","b6b905d3":"plot_confusion_matrix(random_forest_model, feature_test, label_test)","0b5afb0d":"accuracy_score(label_train, random_forest_model.predict(feature_train))","f53acbe4":"accuracy_score(label_test, label_pred)","50d228c7":"recall_score(label_test, label_pred)","2d258d0f":"precision_score(label_test, label_pred)","e9c1445c":"f1_score(label_test, label_pred)","9cd5f1aa":"plt.style.use('seaborn')\n\nfpr, tpr, thresholds = roc_curve(label_test, random_forest_model.predict_proba(feature_test)[:,1], pos_label=1)\n\nrandom_probs = [0 for i in range(len(label_test))]\np_fpr, p_tpr, _ = roc_curve(label_test, random_probs, pos_label=1)\n\nplt.plot(fpr, tpr, linestyle='--',color='orange', label='Random Forest')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n\nplt.title('Random Forest ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC',dpi=300)\n\nplt.show()","d417a10c":"auc = roc_auc_score(label_test, random_forest_model.predict_proba(feature_test)[:,1])\nauc","7e555bfb":"* Dropping columns which do not have good correlation with the label and other features","e7773075":"# Displaying top rows of the dataset","9f9ecaa7":"# Importing the dataset","94ae6d20":"# Exploratory Data Analysis","39cca4a5":"# Precision Score","11815e58":"# Visualizing target variable","32ce6c09":"* Performing one hot encoding to convert categorical values into numeric","13530041":"* It is observed that:\n* Age < 35, majority of people have not clicked on the advertisement.\n* Age > 35, majority of people have clicked on the advertisement.","97191066":"* It is observed that more females than males have clicked on the advertisement.","ef3e2836":"* It is observed that people who have spent more than 60 hours on Site have not clicked on the advertisement.","38a1c943":"* The dataset is balanced.","aa7f34fa":"* It is observed that equal number of males and females have not clicked on the advertisement.","b2d21e28":"* Area Income more than 35000 has got more cliekced.","3b17f2c0":"# Confusion Matrix","a797f6db":"* There is no duplicate row in the dataset.","1f1ac99e":"# Preparing parameters for hyperparameter tuning","3dc2b77e":"# Accuracy","62412dc4":"# Model building using ensemble technique and randomizedsearchcv","bf2cdc33":"# Metrices for evaluating model performance","f43e31ea":"# Separating dataset into features and label","a3d9f630":"# Displaying number of rows and columns in the dataset","f88d143e":"# Splitting the data into train and test","8ec51307":"# ROC AUC CURVE","3909aa52":"# Feature Engineering","305a3c30":"# Visualizing outliers in the dataset","fefe0f99":"# Recall Score","5ea9ff2c":"# Displaying the best parameters","8cd44bee":"# Checking duplicate in the dataset","546913bc":"# ROC Curve","8bcdbdb7":"* There is no missing value in the dataset","1454883b":"* Observation\n* People using internet<175 per day clicks on the adverstisement.\n* People using internet>175 per day do not click on the adverstisement.","898d29b8":"* There is no outliers in the dataset.","8345dfbf":"# Viewing dataset information","48426200":"* Extracting Timestamp to generate new columns as Month, Day, Hour and Weekday","47e96db8":"# Predicting the label for the test features","e9b341c3":"### Correlation Matrix","99439ea5":"### Feature Extraction","b48e5ff5":"# Visualizing relation between features and label","da7be327":"# F1 Score","e7b8f201":"* Categorical Features"}}