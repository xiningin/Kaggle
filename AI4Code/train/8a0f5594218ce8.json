{"cell_type":{"ebc132e0":"code","c15940c4":"code","dc2ee604":"code","f156a71c":"code","2d239a40":"code","82cb1db7":"code","459e7400":"code","6aae05a0":"code","f0f9c310":"code","6c360b85":"code","7c000032":"code","bdb4b78a":"code","c78e010e":"code","9992477f":"code","c250a4a2":"code","925508b3":"code","1540c20e":"code","af8cf91f":"code","b481ba9a":"code","281acdf7":"code","07be4b33":"code","c9994abd":"code","74c5ceee":"markdown","c3b43ad5":"markdown","063bf7ee":"markdown","02e0d498":"markdown","99e600fe":"markdown","aff81c57":"markdown","02ad1352":"markdown","a575bf07":"markdown","94b54611":"markdown"},"source":{"ebc132e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c15940c4":"from PIL import Image","dc2ee604":"import keras\nfrom keras.layers import Conv2D,Flatten,Dense,MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator","f156a71c":"#Code by Gajulamandyam Deva Kumar https:\/\/www.kaggle.com\/devaloo\/kerneledb31c4357\n\ntrain_datagen = ImageDataGenerator(rescale = 1\/255)\ntest_datagen = ImageDataGenerator(rescale = 1\/255)","2d239a40":"trainset = train_datagen.flow_from_directory(r\"..\/input\/is-that-santa-image-classification\/is that santa\/train\",target_size = (150,150),class_mode='binary',batch_size=80)\ntestset = test_datagen.flow_from_directory(r\"..\/input\/is-that-santa-image-classification\/is that santa\/test\",target_size = (150,150),class_mode = 'binary',batch_size= 20)","82cb1db7":"#Code by Gajulamandyam Deva Kumar https:\/\/www.kaggle.com\/devaloo\/kerneledb31c4357\n\nmodel = keras.models.Sequential([Conv2D(16,(3,3),input_shape = (150,150,3),activation = 'relu'),\n                                 MaxPooling2D(2,2),\n                                 Conv2D(32,(3,3),activation = 'relu'),\n                                 MaxPooling2D(2,2),\n                                 Conv2D(64,(3,3),activation = 'relu'),\n                                 MaxPooling2D(2,2),\n                                 Flatten(),\n                                 Dense(512,activation = 'relu'),\n                                 Dense(1,activation = 'sigmoid')\n    \n])","459e7400":"model.summary()","6aae05a0":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer = RMSprop(learning_rate = 0.001),loss = 'binary_crossentropy',metrics = ['accuracy'])","f0f9c310":"model.fit(trainset,steps_per_epoch=50,epochs = 10,validation_data=testset,validation_steps=20)","6c360b85":"trainset.class_indices","7c000032":"#Code by Gajulamandyam Deva Kumar https:\/\/www.kaggle.com\/devaloo\/kerneledb31c4357\n\nfrom keras.preprocessing import image\ntestdata1 = image.load_img(\"..\/input\/is-that-santa-image-classification\/is that santa\/train\/santa\/151.Santa.jpg\",target_size = (150,150))\nimport numpy as np\nx1=image.img_to_array(testdata1)\nx1=np.expand_dims(x1, axis=0)\nimages = np.vstack([x1])\nans = model.predict(images)\nif ans[0][0] == 0:\n    print(\"it is not a Santa\")\nelse:\n    print(\"it is a Santa\")","bdb4b78a":"!pip install kornia","c78e010e":"import torch\nimport torchvision\nimport kornia as K","9992477f":"img_bgr: np.array = cv2.imread('..\/input\/is-that-santa-image-classification\/is that santa\/train\/santa\/10.Santa.jpg')  # HxWxC \/ np.uint8\nimg_rgb: np.array = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb); plt.axis('off');","c250a4a2":"x_rgb: torch.tensor = torchvision.io.read_image('..\/input\/is-that-santa-image-classification\/is that santa\/train\/santa\/10.Santa.jpg')  # CxHxW \/ torch.uint8\nx_rgb = x_rgb.unsqueeze(0)  # BxCxHxW\nprint(x_rgb.shape);","925508b3":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/hello_world_tutorial.html\n\nx_bgr: torch.tensor = K.image_to_tensor(img_bgr)  # CxHxW \/ torch.uint8\nx_bgr = x_bgr.unsqueeze(0)  # 1xCxHxW\nprint(f\"convert from '{img_bgr.shape}' to '{x_bgr.shape}'\")","1540c20e":"x_rgb: torch.tensor = K.color.bgr_to_rgb(x_bgr)  # 1xCxHxW \/ torch.uint8","af8cf91f":"img_bgr: np.array = K.tensor_to_image(x_bgr)\nimg_rgb: np.array = K.tensor_to_image(x_rgb)","b481ba9a":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/hello_world_tutorial.html\n\nfig, axs = plt.subplots(1, 2, figsize=(32, 16))\naxs = axs.ravel()\n\naxs[0].axis('off')\naxs[0].imshow(img_rgb)\n\naxs[1].axis('off')\naxs[1].imshow(img_bgr)\n\nplt.show()","281acdf7":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_augmentation_sequential.html?highlight=bbox\n\nfrom kornia import augmentation as K\nfrom kornia.augmentation import AugmentationSequential\n#from kornia.geometry import bbox_to_mask   #Deprecated??\nfrom kornia.utils import image_to_tensor, tensor_to_image\nfrom torchvision.transforms import transforms\nfrom kornia.geometry.bbox import bbox_to_mask as _bbox_to_mask\n\nto_tensor = transforms.ToTensor()\nto_pil = transforms.ToPILImage()\n\ndef plot_resulting_image(img, bbox, keypoints, mask):\n    img = img * mask\n    img_draw = cv2.polylines(np.array(to_pil(img)), bbox.numpy(), isClosed=True, color=(255, 0, 0))\n    for k in keypoints[0]:\n        img_draw = cv2.circle(img_draw, tuple(k.numpy()[:2]), radius=6, color=(255, 0, 0), thickness=-1)\n    return img_draw\n\nimg = cv2.imread(\"..\/input\/is-that-santa-image-classification\/is that santa\/train\/santa\/208.Santa.jpg\", cv2.IMREAD_COLOR)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nh, w = img.shape[:2]\n\nimg_tensor = image_to_tensor(img).float() \/ 255.\nplt.imshow(img); plt.axis('off');","07be4b33":"from kornia.geometry.bbox import bbox_to_mask as _bbox_to_mask\nfrom  kornia.geometry.bbox import bbox_to_mask\n\n#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_augmentation_sequential.html?highlight=bbox\n\naug_list = AugmentationSequential(\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=1.0),\n    K.RandomAffine(360, [0.1, 0.1], [0.7, 1.2], [30., 50.], p=1.0),\n    K.RandomPerspective(0.5, p=1.0),\n    data_keys=[\"input\", \"bbox\", \"keypoints\", \"mask\"],\n    return_transform=False,\n    same_on_batch=False,\n)\n\nbbox = torch.tensor([[[355,10],[660,10],[660,250],[355,250]]])\nkeypoints = torch.tensor([[[465, 115], [545, 116]]])\nmask = bbox_to_mask(torch.tensor([[[155,0],[600,0],[600,400],[155,400]]]), w, h).float()#changed to 600 since we got 615 images. Original code was 900\n\nimg_out = plot_resulting_image(img_tensor, bbox, keypoints, mask)\nplt.imshow(img_out); plt.axis('off');","c9994abd":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_augmentation_sequential.html?highlight=bbox\n\n#import torch.linalg_solve as linalg_solve #Clicked twice the snippet the warning disappeared\n\nout_tensor = aug_list(img_tensor, bbox.float(), keypoints.float(), mask)\nimg_out = plot_resulting_image(\n    out_tensor[0][0],\n    out_tensor[1].int(),\n    out_tensor[2].int(),\n    out_tensor[3][0],\n)\nplt.imshow(img_out); plt.axis('off');","74c5ceee":"#Very economic epochs.","c3b43ad5":"#Define Augmentation Sequential and Different Labels","063bf7ee":"#Acknowledgment:\n\nGajulamandyam Deva Kumar https:\/\/www.kaggle.com\/devaloo\/kerneledb31c4357","02e0d498":"#Convert from BGR to RGB with a kornia.color component.","99e600fe":"#Visualize an image with Matplotib","aff81c57":"#Working with Kornia","02ad1352":"#Load an image with Torchvision\n\nIt returns the images in a torch.Tensor in the shape (C,H,W)","a575bf07":"#Load an image with Kornia\n\n\"The utility is kornia.image_to_tensor which casts a numpy.ndarray to a torch.Tensor and permutes the channels to leave the image ready for being used with any other PyTorch or Kornia component. The image is casted into a 4D torch.Tensor with zero-copy.\"","94b54611":"#On the previous Notebook it was (before fixed) \n\nFound 615 images belonging to 2 classes.\n\nFound 617 images belonging to 2 classes."}}