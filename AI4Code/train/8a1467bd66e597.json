{"cell_type":{"b6b4a51f":"code","ed46b89d":"code","07847248":"code","bcf65298":"code","06da6974":"code","7aab94c1":"code","d19e79b0":"code","26a44b87":"code","b3146f77":"code","53c8f2c0":"code","3d4f6fdc":"code","92822209":"code","3e685632":"code","7a8b1ac6":"code","dd53779d":"code","d330d7f9":"code","55cb5fab":"code","50ae6f85":"code","6acfa8d6":"code","86fa11da":"code","1ed827a3":"code","51f3377e":"code","ac598b11":"code","7f1ecd6b":"code","c76f314c":"code","d6d328c1":"code","9f47b98d":"code","11cd9d4c":"code","d743fdbe":"code","736fe54a":"code","c78722ad":"code","a5a24bb1":"code","9f6e4ac4":"code","12dcf11e":"code","13e6ebd8":"code","ce9d3c47":"code","b4298c11":"code","26ab3a55":"code","b52e84fc":"code","e52fca02":"code","3e2caf06":"code","a9a43c67":"code","65877de2":"code","41899f1b":"code","e53f52a5":"code","057ffa32":"code","e2e2a9a5":"code","ce3fc85e":"code","21288f49":"code","f644f2e8":"code","0c91b256":"code","2d041b10":"code","a9e2ad05":"code","e17e11db":"code","cc76c981":"code","19c48362":"code","7572ec3e":"code","4a99ba00":"code","9a29f8ca":"code","6d1a618f":"code","216672e8":"code","d03482e3":"code","9bc94f0d":"code","8cbd9547":"code","459e3c9c":"code","7153ecf1":"markdown","c3154716":"markdown","1c111b11":"markdown","10a83952":"markdown","af421f3f":"markdown","4b4c8589":"markdown","e2e1ab4e":"markdown","7d636b47":"markdown","e03cac42":"markdown","ddd8f068":"markdown","7c722531":"markdown","7c0aa3f1":"markdown","6458ae3f":"markdown","3f8a03e3":"markdown","6485d93d":"markdown","62e1925c":"markdown","587bd474":"markdown","47b14be1":"markdown","e890fd59":"markdown","cfcbe915":"markdown","26f29876":"markdown","611dce99":"markdown","181451e7":"markdown","edf1215c":"markdown","755a398b":"markdown","efcd3c32":"markdown","420b0b91":"markdown","7b9dabd8":"markdown","5607be40":"markdown","f5d6e755":"markdown","22f068c3":"markdown","580e5e56":"markdown","56c08c1e":"markdown","4a064751":"markdown","70cadc20":"markdown","26cdacf3":"markdown","234a0748":"markdown","6d358307":"markdown"},"source":{"b6b4a51f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes=True)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom glob import glob\nimport re\nimport gc\nfrom scipy.stats import zscore\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","ed46b89d":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV,cross_validate","07847248":"!wget \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00287\/Activity%20Recognition%20from%20Single%20Chest-Mounted%20Accelerometer.zip\"","bcf65298":"!unzip \"\/kaggle\/working\/Activity Recognition from Single Chest-Mounted Accelerometer.zip\"","06da6974":"files_path=glob(r\"\/kaggle\/working\/Activity Recognition from Single Chest-Mounted Accelerometer\/*.csv\")","7aab94c1":"def Dataframe(files_path):\n    df_participants=pd.DataFrame()\n    for index,file_path in enumerate(files_path):\n        df=pd.read_csv(file_path,header=None)\n        df[\"User_id\"]=int(re.sub(r'[^0-9]',\"\",file_path))\n        df_participants=df_participants.append(df.iloc[:,1:])\n    return df_participants","d19e79b0":"data=Dataframe(files_path)\ndata.columns=['x_acceleration','y_acceleration','z_acceleration','Label','User_id']\ndata.index=range(len(data))","26a44b87":"data=data.reindex(columns=[\"User_id\",\"x_acceleration\",\"y_acceleration\",\"z_acceleration\",\"Label\"])","b3146f77":"data","53c8f2c0":"data.shape","3d4f6fdc":"# Counts of each participants\ndata.User_id.value_counts().sort_index()","92822209":"# Checking Null values \ndata.isnull().sum()\n## There are no Null values","3e685632":"# Checking some statistical values\ndata.describe()","7a8b1ac6":"# Target incidence\ndata.Label.value_counts().sort_index()","dd53779d":"# Here rows having '0' as Label will be dropped\ndata.drop(list(data[data.Label==0].index),axis=0,inplace=True)","d330d7f9":"data.set_axis(range(len(data)),axis=0,inplace=True)","55cb5fab":"# adding more features to the data\nA_x=np.square(data['x_acceleration'])\nA_y=np.square(data['y_acceleration'])\nA_z=np.square(data['z_acceleration'])\nA_m=np.sqrt(A_x + A_y + A_z)\ndata[\"mag_acceleration\"]=A_m\ndata=data.reindex([\"User_id\",\"x_acceleration\",\"y_acceleration\",\"z_acceleration\",\"mag_acceleration\",\"Label\"],axis=1)","50ae6f85":"data.head()","6acfa8d6":"# Corelation of features with the target variable\ndata.corr().Label.sort_values()","86fa11da":"# checking the corelation between the features\nfig=plt.gcf()\nfig.set_size_inches((10,6))\nsns.heatmap(data.corr(),annot=True,linewidths=1);","1ed827a3":"# checking the co-relation between different features\nsns.pairplot(data[[\"x_acceleration\",\"y_acceleration\",\"z_acceleration\",\"mag_acceleration\",\"Label\"]],corner=True)\nplt.show()","51f3377e":"ev=EllipticEnvelope(contamination=0.1,random_state=42)","ac598b11":"predict_outliers=ev.fit_predict(data[[\"x_acceleration\",\"y_acceleration\",\"z_acceleration\"]])","7f1ecd6b":"print(\"Number of Outliers=\",np.sum(predict_outliers==-1))\nprint(\"Percentage of Outliers=\",str(round((np.sum(predict_outliers==-1)\/len(data))*100,2))+\"%\")","c76f314c":"predict_outliers","d6d328c1":"fig=plt.gcf()\nfig.set_size_inches((15,5))\nsns.kdeplot(predict_outliers,shade=True,color=\"magenta\",bw=0.1)\nplt.show()","9f47b98d":"fig=plt.gcf()\nfig.set_size_inches((12,4))\nsns.distplot(data.x_acceleration,color=\"red\")\nplt.title('Acceleration in the x-axis',fontsize=20);","11cd9d4c":"# Number of outliers in x_acceleration\nprint(\"Number of outliers=\",len(data[(zscore(data.x_acceleration)<-3) | (zscore(data.x_acceleration)>3)]))\nprint(\"Percentage of Outliers=\", str(round((len(data[(zscore(data.x_acceleration)<-3) | (zscore(data.x_acceleration)>3)])\/len(data))*100,2))+\"%\")","d743fdbe":"# here the dots are showing the outliers location\nfig=plt.gcf()\nfig.set_size_inches((12,4))\nsns.boxplot(data.x_acceleration,color=\"green\",fliersize=5);","736fe54a":"fig=plt.gcf()\nfig.set_size_inches((12,4))\nsns.distplot(data.y_acceleration,color=\"red\")\nplt.title('Acceleration in the y-axis',fontsize=20);","c78722ad":"# Number of outliers in y_acceleration\nprint(\"Number of outliers=\",len(data[(zscore(data.y_acceleration)<-3) | (zscore(data.y_acceleration)>3)]))\nprint(\"Percentage of Outliers=\", str(round((len(data[(zscore(data.y_acceleration)<-3) | (zscore(data.y_acceleration)>3)])\/len(data))*100,2))+\"%\")","a5a24bb1":"# here the dots are showing the outliers location\nfig=plt.gcf()\nfig.set_size_inches((12,4))\nsns.boxplot(data.y_acceleration,color=\"green\",fliersize=5);","9f6e4ac4":"fig=plt.gcf()\nfig.set_size_inches((12,4))\nsns.distplot(data.z_acceleration,color=\"red\")\nplt.title('Acceleration in the z-axis',fontsize=20);","12dcf11e":"# Number of outliers in z_acceleration\nprint(\"Number of outliers=\",len(data[(zscore(data.z_acceleration)<-3) | (zscore(data.z_acceleration)>3)]))\nprint(\"Percentage of Outliers=\", str(round((len(data[(zscore(data.z_acceleration)<-3) | (zscore(data.z_acceleration)>3)])\/len(data))*100,2))+\"%\")","13e6ebd8":"# here the dots are showing the outliers location\nfig=plt.gcf()\nfig.set_size_inches((12,4))\nsns.boxplot(data.z_acceleration,color=\"green\",fliersize=5);","ce9d3c47":"fig=plt.gcf()\nfig.set_size_inches((12,4))\nsns.countplot(\"User_id\",data=data)\nplt.xlabel(\"User_id\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.show()","b4298c11":"data.User_id.value_counts()","26ab3a55":"label_counts=data.Label.value_counts(normalize=True)\nlabel_counts","b52e84fc":"fig=plt.gcf()\nfig.set_size_inches((10,6))\ncmap=plt.get_cmap(\"Set1\")\ncolor=cmap(np.arange(len(label_counts)))\nplt.pie(label_counts,labels=label_counts.index,wedgeprops=dict(width=0.6),autopct=\"%.2f%%\",colors=color,shadow=True,labeldistance=1.1);\nplt.title('Label for each of the tasks',fontsize=20)\nplt.show()","e52fca02":"user_task_df=pd.crosstab(data.User_id,data.Label)\nuser_task_df","3e2caf06":"# Here \n## Blue Color ----> Maximum\n## Red Color  ----> Minimum\nuser_task_df.style.highlight_max(axis=1,color=\"blue\").highlight_min(axis=1,color=\"red\")","a9a43c67":"user_task_df.plot(kind=\"bar\",stacked=True,figsize=(15,6))\nplt.legend(bbox_to_anchor=(1.02,1))\nplt.title('Time spent on individual Tasks',fontsize=18)\nplt.xlabel('User id',fontsize=15)\nplt.ylabel('Count of the Labels',fontsize=15)\nplt.show()","65877de2":"max_dict,min_dict={},{}\nfor i,value in enumerate(data.Label.unique()):\n    max_dict[i]=data.x_acceleration[data.Label==value].max()\n    min_dict[i]=data.x_acceleration[data.Label==value].min()","41899f1b":"fig=plt.gcf()\nfig.set_size_inches((12,4))\nplt.bar(np.arange(len(max_dict))-0.4,max_dict.values(),width=0.4,color=\"cyan\",label=\"Max\")\nplt.bar(np.arange(len(min_dict)),min_dict.values(),width=0.4,color=\"magenta\",label=\"Min\")\nplt.legend()\nplt.title(\"Minimum and Maximum values of x_acceleration in each task\",fontsize=20)\nplt.xlabel(\"Labels\",fontsize=15)\nplt.ylabel(\"Value of acceleration\",fontsize=15)\nplt.xticks(np.arange(len(max_dict)),[str(i) for i in range(1,8)])\nplt.show()","e53f52a5":"max_dict,min_dict={},{}\nfor i,value in enumerate(data.Label.unique()):\n    max_dict[i]=data.y_acceleration[data.Label==value].max()\n    min_dict[i]=data.y_acceleration[data.Label==value].min()","057ffa32":"fig=plt.gcf()\nfig.set_size_inches((12,4))\nplt.bar(np.arange(len(max_dict))-0.4,max_dict.values(),width=0.4,color=\"cyan\",label=\"Max\")\nplt.bar(np.arange(len(min_dict)),min_dict.values(),width=0.4,color=\"magenta\",label=\"Min\")\nplt.legend()\nplt.title(\"Minimum and Maximum values of y_acceleration in each task\",fontsize=20)\nplt.xlabel(\"Labels\",fontsize=15)\nplt.ylabel(\"Value of acceleration\",fontsize=15)\nplt.xticks(np.arange(len(max_dict)),[str(i) for i in range(1,8)])\nplt.show()","e2e2a9a5":"max_dict,min_dict={},{}\nfor i,value in enumerate(data.Label.unique()):\n    max_dict[i]=data.z_acceleration[data.Label==value].max()\n    min_dict[i]=data.z_acceleration[data.Label==value].min()","ce3fc85e":"fig=plt.gcf()\nfig.set_size_inches((12,4))\nplt.bar(np.arange(len(max_dict))-0.4,max_dict.values(),width=0.4,color=\"cyan\",label=\"Max\")\nplt.bar(np.arange(len(min_dict)),min_dict.values(),width=0.4,color=\"magenta\",label=\"Min\")\nplt.legend()\nplt.title(\"Minimum and Maximum values of z_acceleration in each task\",fontsize=20)\nplt.xlabel(\"Labels\",fontsize=15)\nplt.ylabel(\"Value of acceleration\",fontsize=15)\nplt.xticks(np.arange(len(max_dict)),[str(i) for i in range(1,8)])\nplt.show()","21288f49":"def user_axis_acceleration_plot(user):\n    for i in range(user.shape[1]):\n        plt.figure(figsize=(14,5))\n        plt.subplot(user.shape[1],1,i+1)\n        plt.plot(user[:,i],color='blue')\n        plt.show()\nfor i in sorted(list(data.User_id.unique())):\n    print('User_id',i)\n    print('The acceleration in x,y,z axis and the Labels')\n    user_axis_acceleration_plot(data[data.User_id==i].iloc[:,1:].values)\n    print('End of',i,'plot\\n')","f644f2e8":"x=data.iloc[:,:-1]\ny=data.iloc[:,-1:]","0c91b256":"train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.2,random_state=42)","2d041b10":"len(train_x)","a9e2ad05":"len(test_x)","e17e11db":"sc=StandardScaler()\ntrain_x=sc.fit_transform(train_x)\ntest_x=sc.transform(test_x)","cc76c981":"# finding the optimal value of k\nnon_optimal_y=[]\nfor i in range(1,15):\n    knn=KNeighborsClassifier(n_neighbors=i,p=2)\n    knn.fit(train_x,train_y)\n    optimal_y=knn.predict(test_x)\n    optimal_y=optimal_y.reshape(len(optimal_y),1)\n    non_optimal_y.append(np.mean(optimal_y!=test_y))","19c48362":"# using Elbow Method in order to find the optimal value of k\nfig=plt.gcf()\nfig.set_size_inches((10,5))\nsns.set(style=\"darkgrid\")\nplt.plot(range(1,len(non_optimal_y)+1),non_optimal_y,\"-ok\")\nplt.title(\"To find Optimal value of K\",fontsize=15)\nplt.xlabel(\"K\",fontsize=14)\nplt.ylabel(\"Error\",fontsize=14)\nplt.show()","7572ec3e":"# pipeline having various models in it\nmodel_pipeline=[\n    (\"knn\",KNeighborsClassifier(n_neighbors=8,p=2,n_jobs=-1)),\n    (\"decision_tree\",DecisionTreeClassifier(criterion=\"entropy\",random_state=42)),\n    (\"random_forest\",RandomForestClassifier(n_estimators=70,random_state=42,n_jobs=-1))\n]","4a99ba00":"estimators={}\nfor model_name , model in model_pipeline:\n    estimator_metrics,d=[],{}\n    print(f\"Showing results for {model_name} classifier :- \")\n    model.fit(train_x,train_y)\n    estimator_metrics.append(model)\n\n    pred_train_y=model.predict(train_x)\n    d[\"pred_train_y\"]=pred_train_y\n    \n    pred_test_y=model.predict(test_x)\n    d[\"pred_test_y\"]=pred_test_y\n    \n    print(\"For Training Set :-\")\n    print(f\"Accuracy_Score = {metrics.accuracy_score(train_y,pred_train_y)}\")\n    d[\"Accuracy_Score_train\"]=metrics.accuracy_score(train_y,pred_train_y)\n    \n    print(\"For Testing Set :-\")\n    print(f\"Accuracy_Score = {metrics.accuracy_score(test_y,pred_test_y)}\\n\")\n    d[\"Accuracy_Score_test\"]=metrics.accuracy_score(test_y,pred_test_y)\n    \n    estimator_metrics.append(d)\n    estimators[model_name]=estimator_metrics","9a29f8ca":"# Confusion matrix for all models\nmodels_confusion_matrix=[]\nfor model_name , model in estimators.items():\n    models_confusion_matrix.append(metrics.confusion_matrix(test_y,model[1][\"pred_test_y\"]))\n    \n#The values are normalised in order to plot the confusion matrix\nknn_confusion_matrix=np.round((models_confusion_matrix[0]\/models_confusion_matrix[0].sum(axis=1)),4)\ndecision_tree_confusion_matrix=np.round((models_confusion_matrix[1]\/models_confusion_matrix[1].sum(axis=1)),4)\nrandom_forest_confusion_matrix=np.round((models_confusion_matrix[2]\/models_confusion_matrix[2].sum(axis=1)),4)","6d1a618f":"fig=plt.gcf()\nfig.set_size_inches((10,5))\nsns.set(font_scale=1.4)\nplots=sns.heatmap(knn_confusion_matrix,annot=True,linewidths=1,annot_kws={\"size\": 15})\nplots.set(xticklabels=[1,2,3,4,5,6,7])\nplots.set(yticklabels=[1,2,3,4,5,6,7])\nplt.show()","216672e8":"fig=plt.gcf()\nfig.set_size_inches((10,5))\nsns.set(font_scale=1.4)\nplots=sns.heatmap(decision_tree_confusion_matrix,annot=True,linewidths=1,annot_kws={\"size\": 15})\nplots.set(xticklabels=[1,2,3,4,5,6,7])\nplots.set(yticklabels=[1,2,3,4,5,6,7])\nplt.show()","d03482e3":"fig=plt.gcf()\nfig.set_size_inches((10,5))\nsns.set(font_scale=1.4)\nplots=sns.heatmap(random_forest_confusion_matrix,annot=True,linewidths=1,annot_kws={\"size\": 15})\nplots.set(xticklabels=[1,2,3,4,5,6,7])\nplots.set(yticklabels=[1,2,3,4,5,6,7])\nplt.show()","9bc94f0d":"for model_name , model in estimators.items():\n    print(f\"Cross Validation Score of {model_name} :-\")\n    scores=cross_validate(model[0],train_x,train_y,scoring=\"accuracy\",cv=5)\n    print(\"Score=\",scores[\"test_score\"].mean())\n    print(\"\\n\")","8cbd9547":"KNN_score=[estimators[\"knn\"][1][\"Accuracy_Score_train\"],estimators[\"knn\"][1][\"Accuracy_Score_test\"]]\ndecision_score=[estimators[\"decision_tree\"][1][\"Accuracy_Score_train\"],estimators[\"decision_tree\"][1][\"Accuracy_Score_test\"]]\nrandom_score=[estimators[\"random_forest\"][1][\"Accuracy_Score_train\"],estimators[\"random_forest\"][1][\"Accuracy_Score_test\"]]","459e3c9c":"ind = np.arange(2) \nwidth = 0.1\nplt.figure(figsize=(10,6))\nplt.bar(ind, KNN_score, width, label='KNN_score')\nplt.bar(ind + width, decision_score, width, label='Decision_tree_score')\nplt.bar(ind + width + width, random_score, width, label='Random_forest_score')\n\nplt.ylabel('Accuracy',fontsize=15)\nplt.title('Comparison of Accuracy ',fontsize=20)\n\nplt.xticks(ind + width \/ 3, ('Train_data','Test_data'),fontsize=15)\nplt.legend(fontsize=15)\nplt.show()","7153ecf1":"Conclusion:\n\nMost(~50%) of the z_acceleration lies in between 1800 and 2200","c3154716":"Conlusion:-\n\nHere we can see that y_acceleration is more co-related with the magnitude of acceleration.","1c111b11":"### 3.2.1- x_acceleration","10a83952":"Insight- 2:\n\nBoth Minimum & Maximum values of acceleration in X-axis is in task-1","af421f3f":"### 3.2.3- z_acceleration","4b4c8589":"From the elbow method the value of K is choosen, The accuracy remains the same(approximately) for the value of K from range (8 to 15), hence 8 is choosen as the optimal value.","e2e1ab4e":"## 3.3- Exploring the relationship between participants and their activities\n\n","7d636b47":"# 2- Data Preperation","e03cac42":"## 4.1 - Data Spliting","ddd8f068":"Insight- 5:\n\nThe labels are dependent on all x,y,z axis acceleration.","7c722531":"## 4.2 - Feature Scaling","7c0aa3f1":"#### 3.2.2.1- Anomaly Detection","6458ae3f":"# 5- Final Model Selection\n\n## Recommendation: K-Nearest Neighbours is a better classifier on the Accelerometer dataset\n\n1- Accuracy of KNN Classifier is 79.63%, Decision tree Classifier is 73.62% and Random Forest Classifier is 78.84% on the Test data.\n\n2- Accuracy from the KNN Classifier is slightly higher than that of Random Forest but much higher than the Decision tree.\n\n3- The computational complexity for KNN is comparatively more as it doesn't built a generalised model during the training phase hence it requires more time in testing phase, also we can say that it computes distances of each query instance to all training samples but as KNN performs instance-based learning, a well-tuned K can model complex decision spaces having arbitrarily complicated decision boundarie which are not modeled by other 'eager' Classifiers like Decision tree.\n\n4- KNN naturally supports incremental learning.\n\n5- Random Forest overfitts the model as it is showing less bias and high variance, thus making it less compatible for this data.\nBut KNN is showing less bias and less variance as compared to other Classifiers.\n\n6- KNN classifier gives test error rates closer to that of Bayesian classier (the gold standard)\n\n7- KNN classifier works better in large number of samples like this data.","3f8a03e3":"#### 3.2.3.1- Anomaly Detection","6485d93d":"# 3- EDA","62e1925c":"Conclusion:\n\n Most(~50%) of the x_acceleration lies in between 1750 and 2250","587bd474":"Decision-Tree confusion matrix","47b14be1":"Goal: The activities are predicted based the movements traced by the accelerometer for 15 users. Every participant wore a custom-developed chest mounted uncaliberated acceleraometer and the data was collected at 52 observations per second. The 7 activities in the Label column of the data is explored against the acceleration in x,y and z-axis.","e890fd59":"### 3.2.4- User_id","cfcbe915":"Random-Forest confusion matrix","26f29876":"Conclusion:\n\nMost(~50%) of the y_acceleration lies in between 2250 and 2600","611dce99":"## 4.3 - Building Pipeline","181451e7":"Insight - 1 :\n\nTime spent by each individual on task 1 (Working at Computer) is the maximum.","edf1215c":"### 3.2.2- y_acceleration","755a398b":"## 4.5 - Comparison between KNN , Decision tree and Random Forest Classifier","efcd3c32":"Conclusion:\n\nMaximum amount of data is available from the Users 1,5,7,9 which is around 160000 data entries.\nMinimum amount of data is available from the User 13.","420b0b91":"Insight- 3:\n\nBoth Minimum & Maximum values of acceleration in Y-axis is in task-1","7b9dabd8":"KNN confusion matrix","5607be40":"Conclusion:\n\nPeople have spent most of the time on task 1 i.e. Working at Computer and the least time on task 6 i.e. Walking and Talking with Someone.\nTask 2,6,5 are the least performed actions, which is around 2.5%\nTask 1,7 are the most performed actions, which is around 30%.","f5d6e755":"From K-Fold Cross validation, KNN is performing better in the training set as it is showing less variance in the accuracy score.","22f068c3":"#### 3.2.1.1- Anomaly Detection","580e5e56":"# 1- Data Collection","56c08c1e":"# 4- Data Modelling","4a064751":"Insight- 4:\n\nBoth Minimum & Maximum values of acceleration in Z-axis is in task-1","70cadc20":"## 3.2- Exploring each feature\n\n","26cdacf3":"## 4.4 - Cross- Validation","234a0748":"### 3.2.5- Label","6d358307":"## 3.1- Anomaly Detection\n\nOn whole Data Set"}}