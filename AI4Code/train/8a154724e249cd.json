{"cell_type":{"4c6ed352":"code","7f153a17":"code","415948e0":"code","488f85ad":"code","e78ebc90":"code","51bb1a0e":"code","2dbb9794":"code","7ddb244c":"code","d5cda182":"code","f8069914":"code","9a6b0c55":"code","4536a019":"code","b971a409":"code","f24112c6":"code","e6236658":"code","5aa1a4c1":"code","46b3002f":"code","97268ae2":"code","091ff928":"code","50f15049":"code","bae7fa78":"code","7d182e6d":"code","9e4e52e1":"code","b0e6b2b2":"code","94dca3c3":"code","90f7edad":"code","76ddabdb":"code","6db4fd5d":"code","49bf14fc":"code","93867b7d":"code","d3f3b0dc":"code","30c0161d":"code","585c3cfc":"code","93a607c1":"code","72d831ea":"code","7a650461":"markdown","cb05f576":"markdown","c780186a":"markdown","8df819fc":"markdown","1b41f506":"markdown","337a688c":"markdown","77d1123b":"markdown","2e2d1303":"markdown","1d596990":"markdown","eff74625":"markdown","7a673a60":"markdown","0790adf6":"markdown","294b6b80":"markdown"},"source":{"4c6ed352":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7f153a17":"#Gerekli K\u00fct\u00fcphaneler\n!pip install pyspark\n!pip install findspark\n!pip install PyArrow","415948e0":"import warnings\nimport findspark\nimport pandas as pd\nimport seaborn as sns\nfrom pyspark.ml.classification import GBTClassifier, LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, StandardScaler\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import Bucketizer","488f85ad":"warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.2f' % x)","e78ebc90":"#SparkSession ile spark\u0131 aya\u011fa kald\u0131r\u0131yoruz\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"pyspark_giris_2\") \\\n    .getOrCreate()","51bb1a0e":"#Veri Okuma ve Anlama\nspark_df = spark.read.csv(\"..\/input\/churn-modellingcsv\/Churn_Modelling.csv\", header=True, inferSchema=True)\ntype(spark_df)","2dbb9794":"spark_df.head()","7ddb244c":"# G\u00f6zlem ve de\u011fi\u015fken say\u0131s\u0131\nprint(\"Shape: \", (spark_df.count(), len(spark_df.columns)))","d5cda182":"# De\u011fi\u015fken tipleri\nspark_df.printSchema()\nspark_df.dtypes","f8069914":"# De\u011fi\u015fken isimlerinin k\u00fc\u00e7\u00fclt\u00fclmesi\nspark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])\nspark_df.show(5)","9a6b0c55":"# \u00f6zet istatistikler\nspark_df.describe().show()","4536a019":"# Kategorik de\u011fi\u015fken s\u0131n\u0131f istatistikleri\nspark_df.groupby(\"exited\").count().show()","b971a409":"# E\u015fsiz s\u0131n\u0131flar\nspark_df.select(\"exited\").distinct().show()\nspark_df.select(\"tenure\").distinct().show()\nspark_df.select(\"geography\").distinct().show()","f24112c6":"# select(): De\u011fi\u015fken se\u00e7imi\nspark_df.select(\"creditscore\", \"tenure\").show(5)\n# Groupby \nspark_df.groupby(\"exited\").agg({\"tenure\": \"mean\"}).show()\nspark_df.groupby(\"exited\").agg({\"balance\": \"mean\"}).show()\nspark_df.groupby(\"exited\").agg({\"estimatedsalary\": \"mean\"}).show()","e6236658":"spark_df.dtypes","5aa1a4c1":"# T\u00fcm numerik de\u011fi\u015fkenlerin se\u00e7imi ve \u00f6zet istatistikleri\nnum_cols = [col[0] for col in spark_df.dtypes if col[1] != 'string']\n\nspark_df.select(num_cols).describe().toPandas().transpose()","46b3002f":"# T\u00fcm kategorik de\u011fi\u015fkenlerin se\u00e7imi ve \u00f6zeti\ncat_cols = [col[0] for col in spark_df.dtypes if col[1] == 'string']\n\nfor col in cat_cols:\n    spark_df.select(col).distinct().show()","97268ae2":"#target a g\u00f6re\nfor col in num_cols:\n    spark_df.groupby(\"exited\").agg({col: \"mean\"}).show()","091ff928":"# Missing Values\n\nfrom pyspark.sql.functions import when, count, col\n\nspark_df.select([count(when(col(c).isNull(), c)).alias(c) for c in spark_df.columns]).toPandas().T","50f15049":"##De\u011fi\u015fken silme\nspark_df=spark_df.drop(\"customerid\")\nspark_df=spark_df.drop(\"rownumber\")\nspark_df=spark_df.drop(\"surname\")\nspark_df=spark_df.drop(\"geography\")\nspark_df.show(5)","bae7fa78":"spark_df.select('age').describe().toPandas().transpose()\n\nbucketizer = Bucketizer(splits=[0, 18, 34, 54, 65, 92], inputCol=\"age\", outputCol=\"age_cat\")\n\nspark_df = bucketizer.setHandleInvalid(\"keep\").transform(spark_df) #D\u00f6n\u00fc\u015f\u00fcm i\u015flemi\n\nspark_df.show(50)\nspark_df.groupby(\"age_cat\").count().show()\nspark_df.groupby(\"age_cat\").agg({'exited': \"mean\"}).show()\n\n\nspark_df = spark_df.withColumn(\"age_cat\", spark_df[\"age_cat\"].cast(\"integer\")) #ondal\u0131klardan kurtulma\nspark_df.groupby(\"age_cat\").agg({'exited': \"mean\"}).show()","7d182e6d":"#when ile de\u011fi\u015fken olu\u015fturma\nspark_df = spark_df.withColumn('tenure_segment', when(spark_df['tenure'] < 5, \"tenure_segment_b\").otherwise(\"tenure_segment_a\"))\n#withcloumn ile de\u011fi\u015fken olu\u015fturma\nspark_df = spark_df.withColumn('new_creditscore\/estimatedsalary', spark_df.creditscore \/ spark_df.estimatedsalary)\nspark_df = spark_df.withColumn('new_numofproducts\/tenure', spark_df.numofproducts \/ spark_df.tenure)\nspark_df = spark_df.withColumn('new_numofproducts\/estimatedsalary', spark_df.numofproducts \/ spark_df.estimatedsalary)\nspark_df.show(5)\n","9e4e52e1":"indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_label\")\nindexer.fit(spark_df).transform(spark_df)\ntemp_sdf = indexer.fit(spark_df).transform(spark_df)\nspark_df = temp_sdf.withColumn(\"gender_label\", temp_sdf[\"gender_label\"].cast(\"integer\"))\n\n\nindexer = StringIndexer(inputCol=\"tenure_segment\", outputCol=\"tenure_segment_label\")\nindexer.fit(spark_df).transform(spark_df)\ntemp_sdf = indexer.fit(spark_df).transform(spark_df)\nspark_df = temp_sdf.withColumn(\"tenure_segment_label\", temp_sdf[\"tenure_segment_label\"].cast(\"integer\"))\n\n\nspark_df = spark_df.drop('gender')\nspark_df = spark_df.drop('tenure_segment')\nspark_df.show(5)","b0e6b2b2":"spark_df.select([count(when(col(c).isNull(), c)).alias(c) for c in spark_df.columns]).toPandas().T\n","94dca3c3":"spark_df=spark_df.dropna()","90f7edad":"spark_df.select([count(when(col(c).isNull(), c)).alias(c) for c in spark_df.columns]).toPandas().T","76ddabdb":"encoder = OneHotEncoder(inputCols=[\"age_cat\"], outputCols=[\"age_cat_ohe\"])\n\nspark_df = encoder.fit(spark_df).transform(spark_df)\nspark_df.show(5)","6db4fd5d":"stringIndexer = StringIndexer(inputCol='exited', outputCol='label')\ntemp_sdf = stringIndexer.fit(spark_df).transform(spark_df)\n\nspark_df = temp_sdf.withColumn(\"label\", temp_sdf[\"label\"].cast(\"integer\"))\nspark_df.show(5)","49bf14fc":"cols = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', \n        'hascrcard', 'isactivemember', 'estimatedsalary', 'age_cat', 'new_creditscore\/estimatedsalary',\n        'new_numofproducts\/tenure', 'new_numofproducts\/estimatedsalary', 'gender_label', \n        'tenure_segment_label', 'age_cat_ohe']\n\n\n# Vectorize independent variables.\nva = VectorAssembler(inputCols=cols, outputCol=\"features\")\nva_df = va.transform(spark_df)\nva_df.show()\n\n# Final df\nfinal_df = va_df.select(\"features\", \"label\")\nfinal_df.show(5)","93867b7d":"train_df, test_df = final_df.randomSplit([0.7, 0.3], seed=13)\n","d3f3b0dc":"train_df.show(10)\n","30c0161d":"test_df.show(10)","585c3cfc":"print(\"Training Dataset Count: \" + str(train_df.count()))\nprint(\"Test Dataset Count: \" + str(test_df.count()))","93a607c1":"gbm = GBTClassifier(maxIter=100, featuresCol=\"features\", labelCol=\"label\")\ngbm_model = gbm.fit(train_df)\ny_pred = gbm_model.transform(test_df)\ny_pred.show()\n\ny_pred.filter(y_pred.label == y_pred.prediction).count() \/ y_pred.count() #accuracy","72d831ea":"from pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nevaluator = BinaryClassificationEvaluator()\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(gbm.maxDepth, [2, 4, 6])\n             .addGrid(gbm.maxBins, [20, 30])\n             .addGrid(gbm.maxIter, [10, 20])\n             .build())\n\ncv = CrossValidator(estimator = gbm, estimatorParamMaps = paramGrid, evaluator = evaluator, numFolds = 10)\n\ncv_model = cv.fit(train_df)\ny_pred = cv_model.transform(test_df)\n\nac = y_pred.select(\"label\",\"prediction\")\n\nac.filter(ac.label == ac.prediction).count() \/ ac.count()","7a650461":"## Features","cb05f576":"# Data Preprocessing & Feature Engineering","c780186a":"## Bucketization \/ Bining \/ Num to Cat","8df819fc":"# Gradient Boosted Tree Classifier","1b41f506":"# One Hot Encoding","337a688c":"# Label Encoding","77d1123b":"# Model Tuning","2e2d1303":"## Target","1d596990":"# Defining Target & Features","eff74625":"# Feature Interaction","7a673a60":"# Spark installation","0790adf6":"## Split the dataset into test & train sets","294b6b80":"\n# Exploratory Data Analysis\n\n\nDe\u011fi\u015fkenler\n\nSURNAME: Soy isim\n\nCREDITSCORE: Kredi Skoru\n\nGEOGRAPHY: \u00dclke\n\nGENDER: Cinsiyet\n\nAGE: Ya\u015f\n\nTENURE: Ka\u00e7 y\u0131ll\u0131k m\u00fc\u015fteri oldu\u011fu bilgisi\n\nNUMOFPRODUCTS: Kullan\u0131lan banka \u00fcr\u00fcn\u00fc\n\nHASCRCARD: Kredi kart\u0131 durumu (0=No, 1=Yes)\n\nISACTIVEMEMBER: Aktif \u00fcyelik durumu (0=No, 1=Yes)\n\nESTIMATEDSALARY: Tahmini maa\u015f\n\nEXITED: Terk mi de\u011fil mi? (0=No, 1=Yes)\n\n"}}