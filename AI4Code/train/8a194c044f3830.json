{"cell_type":{"6bb7dfce":"code","f8d96d7c":"code","143bfe7f":"code","82705700":"code","4b2a81a7":"code","0ee00ad3":"code","3e8015a1":"code","e45f5f80":"code","cf9fe82a":"code","df35932a":"code","c5b38dd9":"code","9829ecc6":"code","ab3450b4":"code","7b7c73ba":"code","ba3cd7a9":"code","62eeb158":"code","7db66710":"code","ab9b2494":"markdown","ea813956":"markdown","549cef98":"markdown","00fda956":"markdown","7c75727f":"markdown"},"source":{"6bb7dfce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport cv2\nimport glob\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread, imshow, imsave\nfrom keras.preprocessing.image import load_img, array_to_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Input, Dropout\nfrom keras.optimizers import SGD, Adam, Adadelta, Adagrad\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_v3 import InceptionV3\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread\nnp.random.seed(111)\n\nimport keras\nprint(\"keras version=\", keras.__version__)\nimport tensorflow as tf\nprint(\"tf. version = \", tf.__version__)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nf = open(\"output.csv\", \"a\")\nf.write(\"Now the file has more content!\")\nimport keras\nimport tensorflow as tf\nf.write(keras.__version__)\nf.write(tf.__version__)\nf.close()","f8d96d7c":"from IPython.display import FileLink\nimport os\nos.chdir(r'\/kaggle\/working')\nFileLink(r'save_weights.h5')\nprint(\"show link???\")","143bfe7f":"# Define some Paths\ninput_path = Path('..\/input\/cat-dataset\/cats')\ncats = os.listdir(input_path)\nprint(\"Total number of sub-directories found: \", len(cats))\n\n# Store the meta-data in a dataframe for convinience \ndata = []\nfor folder in cats:\n    new_dir = input_path \/ folder\n    images = sorted(new_dir.glob('*.jpg'))\n    annotations = sorted(new_dir.glob('*.cat'))\n    n = len(images)\n    for i in range(n):\n        img = str(images[i])\n        annotation = str(annotations[i])\n        data.append((img, annotation))\n    print(\"Processed: \", folder)\nprint(\" \")\nprint(\"AAAA\")","82705700":"print(\"VISUAL AAA\")\ndf = pd.DataFrame(data=data, columns=['img_path', 'annotation_path'], index=None)\nprint(\"Total number of samples in the dataset: \", len(df))\nprint(\" \")\ndf.head(10)\n\nprint(\"end of visual path here\")","4b2a81a7":"# Plot some cats and respective annotations\nprint('start show image')\nf, ax = plt.subplots(3,2, figsize=(20,15))\n\n# Get six random samples\nsamples = df.sample(6).reset_index(drop=True)\n\nfor i, sample in enumerate(samples.values):\n    # Get the image path\n    sample_img = df['img_path'][i]\n    # Get the annotation path\n    sample_annot = df['annotation_path'][i]\n    # Read the annotation file\n    f = open(sample_annot)\n    points = f.read().split(' ')\n    points = [int(x) for x in points if x!='']\n    # Get the list of x and y coordinates\n    xpoints = points[1:19:2]\n    ypoints = points[2:19:2]\n    # close the file\n    f.close()\n    \n    ax[i\/\/2, i%2].imshow(imread(sample_img))\n    ax[i\/\/2, i%2].axis('off')\n    ax[i\/\/2, i%2].scatter(xpoints, ypoints, c='g')\n    \nplt.show()    \nprint('end of show image')","0ee00ad3":"# Check for the directory and if it doesn't exist, make one.\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\n    \n# make the models sub-directory\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","3e8015a1":"print(\"copy weight fail!?!?\")\n# Copy the weights from your input files to the cache directory\n!cp ..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 ~\/.keras\/models\/\nprint(\"copy the weight ?!?!\")","e45f5f80":"# A simple data generator\ndef data_gen(data, batch_size=32):\n    # Get total number of samples in the data\n    n = len(data)\n    \n    # Define two numpy arrays for containing batch data and labels\n    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n    batch_labels = np.zeros((batch_size,18), dtype=np.float32)\n    \n    # Get a numpy array of all the indices of the input data\n    indices = np.arange(n)\n    \n    # Initialize a counter\n    i =0\n    while True:\n        np.random.shuffle(indices)\n        # Get the next batch \n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n        for j, idx in enumerate(next_batch):\n            img_name = data['img_path'][idx]\n            #print(img_name)\n            img = imread(img_name)\n            h,w,_ = img.shape\n            sample_img = cv2.resize(img, (224,224))\n            \n            # Get the annotation path\n            annot = data['annotation_path'][idx]\n            # Read the annotation file\n            f = open(annot)\n            points = f.read().strip().split(' ')[1:]\n            points = [float(x) for x in points]\n            \n            xcoords = points[0:18:2]\n            ycoords = points[1:18:2]\n            \n            xpoints = np.array(xcoords, dtype=np.float32) \/ w\n            ypoints = np.array(ycoords, dtype=np.float32) \/ h\n            \n            #xpoints *=224\n            #ypoints *=224\n            \n            \n            final_points = []\n            for k in range(len(xpoints)):\n                final_points.append(xpoints[k])\n                final_points.append(ypoints[k])\n            \n            f.close()\n            \n            final_points = np.array(final_points)\n            batch_data[j] = sample_img\n            batch_labels[j] = final_points\n        batch_data = preprocess_input(batch_data)\n        yield batch_data, batch_labels\n        i +=1  ","cf9fe82a":"def build_model():\n    base_model = ResNet50(input_shape=(224,224,3), include_top=False, weights='imagenet')\n    base_model_output = base_model.output\n    x = Flatten(name='flatten')(base_model_output)\n    x = Dense(512, activation='relu', name='fc1')(x)\n    x = Dropout(0.5, name='dropout2')(x)\n    x = Dense(128, activation='relu', name='fc2')(x)\n    x = Dropout(0.5, name='dropout1')(x)\n    x = Dense(18, name='fc3')(x)\n    \n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model = Model(inputs=base_model.input, outputs=x)\n    #model = Model(inputs=input_img, outputs=x)\n    return model","df35932a":"model = build_model()\nmodel.summary()\n# model.save(\"model_save_1.h5\")\n\nprint(\"looks like can build\")","c5b38dd9":"print(\"train test split start123\")\ntrain_df, valid_df = train_test_split(df, test_size=0.1, random_state=111)\nprint(\"Number of training samples: \", len(train_df))\nprint(\"Number of validation samples: \", len(valid_df))\n\n\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = train_df.reset_index(drop=True)","9829ecc6":"nb_epochs = 30\nbatch_size = 32\nnb_tr_batches = len(train_df) \/\/ batch_size\nnb_val_batches = len(valid_df) \/\/ batch_size\ntrain_data_gen = data_gen(train_df, batch_size)\nvalid_data_gen = data_gen(valid_df, batch_size)","ab3450b4":"print(\"start train\")\n#opt = SGD(lr=0.001, momentum=0.9, nesterov=True)\nestop = EarlyStopping(monitor='val_loss', mode='min', patience=10)\nopt = Adam(lr=0.001)\nmodel.compile(loss='mean_squared_error', optimizer=opt)","7b7c73ba":"print(\"run fit generator\")\nmodel.fit_generator(train_data_gen,epochs=nb_epochs, steps_per_epoch=nb_tr_batches,\n                    validation_data=valid_data_gen, validation_steps=nb_val_batches, \n                    callbacks=[estop])\n\n","ba3cd7a9":"print(\"start save weight\")\nmodel.save('saved_model.h5')\nprint(\"save weight!!\")","62eeb158":"from IPython.display import FileLink\nimport os\nos.chdir(r'\/kaggle\/working')\nFileLink(r'output.csv')\nFileLink(r'saved_model_2.h5')\n","7db66710":"import IPython\nimport PIL\n\n\ndef run_cat(catname):\n    img = imread(catname)\n    h, w, _ = img.shape\n    print(h,w)\n    img224 = cv2.resize(img, (224,224))\n    img = cv2.resize(img, (224,224))\n    IPython.display.display(PIL.Image.fromarray(img))\n\n    f = open(catname + \".cat\")\n    points = f.read().split(' ')\n    print(\"cat1 raw:\", points)\n    points = [int(x) for x in points if x!='']\n    # Get the list of x and y coordinates\n    xpoints = points[1:19:2]\n    ypoints = points[2:19:2]\n    f.close()\n    print(\"cat1 xy=\", xpoints, ypoints)\n    from tensorflow.keras.preprocessing import image\n\n\n    print(\"before\", img.shape, type(img))\n    batch_data = np.zeros((1, 224, 224, 3), dtype=np.float32)\n    batch_data[0] = img\n    batch_data = preprocess_input(batch_data)\n    print(\"after\", img.shape, type(img))\n    ret = model.predict(batch_data)\n    print(ret)\n\n    print(\"h\", (ret*h).astype(np.int))\n    print(\"w\", (ret*w).astype(np.int))\n    print(\"224\", (ret*224).astype(np.int))\n\n    rr = ret[0]\n    for i in range(0,18,2):\n        #img224[] = (255,0,0)\n        ima224 = cv2.circle(img224, (int(rr[i+1]*224), int(rr[i]*224)), 2, (255,0,0), 2)\n    IPython.display.display(PIL.Image.fromarray(img224))\n\n\n    #img = imread(catname)\n    #for i in range(0,18,2):\n    #    img[int(rr[i+1]*h)%h][int(rr[i]*w)%w] = (255,0,0)\n    #IPython.display.display(PIL.Image.fromarray(img))\n\n\n    #[[ 0.13151725  0.1333843   0.22975737  0.12062433  0.16293192  0.1613504\n    #   0.16739428  0.02244981 -0.0051895  -0.0412662  -0.00523635  0.03137928\n    #   0.0759026   0.1189046   0.16216643  0.14579456  0.09665697  0.16210774]]\n\nrun_cat(\"..\/input\/cat-dataset\/CAT_00\/00000001_020.jpg\");\nrun_cat(\"..\/input\/cat-dataset\/CAT_00\/00000001_024.jpg\");\nrun_cat(\"..\/input\/cat-dataset\/CAT_00\/00000001_027.jpg\");","ab9b2494":"Next, we will try to build a Deep CNN that can learn the facial embeddings for a cat","ea813956":"Hello, fellow Kagglers. We are going to look a very interesting problem today. This dataset consists of images of cats along with their facial landmarks. So, in short, this problem is to develop facial embeddings for cats. LOL!! Let's dive in\n![](https:\/\/media.giphy.com\/media\/3o752eDHQgwl8zS3Oo\/giphy.gif)","549cef98":"## Visualization\nLet's take some random samples from the dataset and plot some cats along with the facial keypoints ","00fda956":"The dataset is arranged in the following structure:\n```\n--cats\n       --CAT_00\n                 - -.jpg\n                - -.jpg.cat\n       --CAT_01\n                 - -*.jpg\n                 -- *.jpg.cat         \n        .............................\n        ..............................\n  ```      \nThere are 7 subdirectories in total. Each of the subdirectory contains cat images and their corresponding facial key points annotations. The annotation file contains `.cat` extension in the end and contains landmarks in the following format:\n `[num_keypoints x1 y1 x2 y2 x3 y3 ..........................x18 y18 '']`","7c75727f":"model.summary()\n\nsamples = df.sample(1).reset_index(drop=True)\nsample = samples[0]\nprint(sample)\nmodel.predit(sample)"}}