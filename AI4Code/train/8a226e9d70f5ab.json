{"cell_type":{"597df48c":"code","ae1dc724":"code","ae923f06":"code","1167a20c":"code","8e0a35e1":"code","db0272ef":"code","a87ba787":"code","a60b7bb3":"code","a9af0851":"code","c1a324b4":"code","391cf1f4":"code","9ce1589e":"code","f146e4a9":"code","c67ebb47":"code","0234127c":"code","121dd308":"code","b533a65a":"code","03cde31e":"code","f3fb4c2a":"markdown","b5b3fcbf":"markdown","a0b4cfc1":"markdown","30244fea":"markdown","af9b7e14":"markdown","fadbf718":"markdown","e39d4e07":"markdown","97c083dd":"markdown"},"source":{"597df48c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nfrom pathlib import Path\nimport base64\nimport cv2\nimport matplotlib.pyplot as plt\nimport json \nfrom tqdm.notebook import tqdm \nimport scipy \nfrom joblib import Parallel , delayed","ae1dc724":"IMG_SIZE = 128\nbase_path = Path('..\/input\/endoscopy-dataset\/')\ntrain_path = list((base_path \/'train').glob('train*'))\ntest_path = list((base_path \/ 'test').glob('test*'))","ae923f06":"label_info = pd.read_csv((base_path \/'class_id_info.csv'))\ncategories = {i[0]:i[1]-1 for i in label_info.to_numpy()}\nlabel_info","1167a20c":"\ndef xyxy2coco(xyxy):\n    x1,y1,x2,y2 =xyxy\n    w,h =  x2-x1, y2-y1\n    return [x1,y1,w,h] \n\ndef xyxy2yolo(xyxy):\n    \n    x1,y1,x2,y2 =xyxy\n    w,h =  x2-x1, y2-y1\n    xc = x1 + int(np.round(w\/2)) # xmin + width\/2\n    yc = y1 + int(np.round(h\/2)) # ymin + height\/2\n    return [xc\/IMG_SIZE,yc\/IMG_SIZE,w\/IMG_SIZE,h\/IMG_SIZE] \n\ndef scale_bbox(img, xyxy):\n    # Get scaling factor\n    scale_x = IMG_SIZE\/img.shape[1]\n    scale_y = IMG_SIZE\/img.shape[0]\n    \n    x1,y1,x2,y2 =xyxy\n    x1 = int(np.round(x1*scale_x, 4))\n    y1 = int(np.round(y1*scale_y, 4))\n    x2 = int(np.round(x2*scale_x, 4))\n    y2= int(np.round(y2*scale_y, 4))\n\n    return [x1, y1, x2, y2] # xmin, ymin, xmax, ymax\n\ndef save_image_label(json_file,mode): \n    with open(json_file,'r') as f: \n        json_file =json.load(f)\n\n    image_id = json_file['file_name'].replace('.json','')\n    \n    # decode image data\n    image = np.frombuffer(base64.b64decode(json_file['imageData']), np.uint8)\n    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n    cv2.imwrite(str(new_image_path \/ (image_id + '.png')) ,image)\n    \n    # extract bbox\n    origin_bbox = []\n    if mode == 'train':\n        with open(new_label_path \/ (image_id + '.txt'), 'w') as f:\n            for i in json_file['shapes']: \n                bbox = i['points'][0] + i['points'][2]\n                origin_bbox.append(bbox)\n                bbox = scale_bbox(image,bbox)\n                bbox = xyxy2yolo(bbox)\n                \n                labels = [categories[i['label']]]+bbox\n                f.writelines([f'{i} ' for i in labels] + ['\\n']) \n    return origin_bbox\n\n","8e0a35e1":"import multiprocessing as mp \n\n# \uc800\uc7a5\ud560 \ud30c\uc77c \uacbd\ub85c\nsave_path = Path('.\/train_data')\nnew_image_path = save_path \/ 'images' # image\ud3f4\ub354 \nnew_label_path = save_path \/ 'labels' # label\ud3f4\ub354\n\nnew_image_path.mkdir(parents=True,exist_ok=True)\nnew_label_path.mkdir(parents=True,exist_ok=True)\n\n# data\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud574 mlutiprocessing \uc801\uc6a9\ntmp = Parallel(n_jobs=mp.cpu_count(),prefer=\"threads\")(delayed(save_image_label)(str(train_json),'train') for train_json in tqdm(train_path[:1000]))","db0272ef":"n = 96\nfilename = train_path[n].name.replace('.json','.png')\nsample = cv2.imread(f'.\/train_data\/images\/{filename}')[:,:,::-1].astype(np.uint8)\nfor i in tmp[n]: \n    i = list(map(int,i))\n    sample = cv2.rectangle(sample,(i[0],i[1]),(i[2],i[3]),(0,0,255),1)\nplt.imshow(sample)","a87ba787":"from sklearn.model_selection import train_test_split\n# \ud559\uc2b5 \uc774\ubbf8\uc9c0\uac00 \ub9ce\uc740 \uad00\uacc4\ub85c 10000\uac1c\ub9cc \uc0ac\uc6a9\nimages_path = list(new_image_path.glob('*'))[:10000]\n\ntrain_path_list,valid_path_list = train_test_split(images_path,test_size=0.1,random_state=42)","a60b7bb3":"with open('train_dataset.txt', 'w') as f:\n    f.writelines([f'{i}\\n' for i in train_path_list])\nwith open('valid_dataset.txt', 'w') as f:\n    f.writelines([f'{i}\\n ' for i in valid_path_list]) \n    ","a9af0851":"! pip install -r yolov5\/requirements.txt\n! pip install scipy --upgrade","c1a324b4":"!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n!pip .\/yolov5\/install requirements.txt  # install dependencies\n","391cf1f4":"!pip install -q --upgrade wandb\n# Login \nimport wandb\nwandb.login()","9ce1589e":"# Create .yaml file \nimport yaml\n\ndata_yaml = dict(\n    train = '.\/train_dataset.txt',\n    val = '.\/valid_dataset.txt',\n    nc = 4,\n    names = ['01_ulcer','02_mass','04_lymph','05_bleeding']\n)\n\n# Note that I am creating the file in the yolov5\/data\/ directory.\nwith open('endoscopy.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=True)\n","f146e4a9":"!python .\/yolov5\/train.py --img 128 \\\n                          --batch 100\\\n                          --epochs 30\\\n                          --data .\/endoscopy.yaml\\\n                          --weights ..\/input\/ultralyticsyolov5aweights\/yolov5s.pt\\\n                          --project yolov5-endoscopy\\\n                          --save-period 1\\\n                          --name endoscopy","c67ebb47":"import multiprocessing as mp \n\nsave_path = Path('.\/test_data').resolve()\nnew_image_path = save_path \/ 'images'\n\nnew_image_path.mkdir(parents=True,exist_ok=True)\n\ntest_path_list = list(new_image_path.glob('*'))\n\n## test\ub97c \uc704\ud574\uc11c 100\uc7a5\ub9cc Inference\ntmp = Parallel(n_jobs=16,prefer=\"threads\")(delayed(save_image_label)(str(train_json),'test') for train_json in tqdm(test_path[:100]))","0234127c":"!python .\/yolov5\/detect.py --weights .\/yolov5-endoscopy\/endoscopy4\/weights\/best.pt \\\n                           --source .\/test_data\/images \\\n                           --save-txt \\\n                           --save-conf\n                           ","121dd308":"def xywh2xyxy(x):\n    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    y = x.copy()\n    y[0] = x[0] - x[2] \/ 2  # top left x\n    y[1] = x[1] - x[3] \/ 2  # top left y\n    y[2] = x[0] + x[2] \/ 2  # bottom right x\n    y[3] = x[1] + x[3] \/ 2  # bottom right y\n    return y\n\ntotal_list = []\nresults = {\n    'file_name':[], 'class_id':[], 'confidence':[], 'point1_x':[], 'point1_y':[],\n    'point2_x':[], 'point2_y':[], 'point3_x':[], 'point3_y':[], 'point4_x':[], 'point4_y':[]\n}\n\nresult_path = Path('.\/yolov5\/runs\/detect\/exp5')\nresult_img = list(result_path.glob('*.png'))\nresult_label = list(result_path.glob('labels\/*.txt'))\n\nfor i in result_label:\n\n    with open(str(i),'r') as f:\n\n        file_name = i.name.replace('.txt','.json')\n        img_name = file_name.replace('.json','.png')\n        ow,oh,_ = cv2.imread(str(result_path \/ img_name))[:,:,::-1].shape\n        for line in f.readlines():\n            corrdi = line[:-1].split(' ')\n            label,xc,yc,w,h,score = corrdi\n            xc,yc,w,h,score = list(map(float,[xc,yc,w,h,score]))\n            xc,w = np.array([xc,w]) * ow\n            yc,h = np.array([yc,h]) * oh\n\n            refine_cordi = xywh2xyxy([xc,yc,w,h])\n            refine_cordi = np.array(refine_cordi).astype(int)\n            x_min,y_min,x_max,y_max = refine_cordi\n\n            results['file_name'].append(file_name)\n            results['class_id'].append(label)\n            results['confidence'].append(score)\n            results['point1_x'].append(x_min)\n            results['point1_y'].append(y_min)\n            results['point2_x'].append(x_max)\n            results['point2_y'].append(y_min)\n            results['point3_x'].append(x_max)\n            results['point3_y'].append(y_max)\n            results['point4_x'].append(x_min)\n            results['point4_y'].append(y_max)","b533a65a":"df = pd.DataFrame(results)\ndf['class_id'] = df['class_id'].apply(lambda x:int(x)+1)\ndf","03cde31e":"pd.DataFrame(df).to_csv('.\/final_submission.csv', index = False)","f3fb4c2a":"install yolov5 ","b5b3fcbf":"* \uc81c\ucd9c\ud558\uae30 \uc704\ud574\uc11c label\uc744 \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc5d0 \ub9de\ub3c4\ub85d denormalize\ud6c4 xyxy\ud615\ud0dc\ub85c \ubcc0\uacbd\ud569\ub2c8\ub2e4. ","a0b4cfc1":"## Load json file\njson file \uc744 \uc77d\uc740\ud6c4 yolo format\uc73c\ub85c bbox\ub97c \ub9cc\ub4e4\uace0 image\ub97c decoding\ud558\uc5ec image\ub97c \ud574\ub2f9\ud3f4\ub354\uc5d0 \uc0dd\uc131\ud569\ub2c8\ub2e4. ","30244fea":"## test code\n","af9b7e14":"* \ud574\ub2f9 yolov5 code\uc5d0\uc11c detect.py\ub97c \uc2e4\ud589\uc2dc\ud0b5\ub2c8\ub2e4. \n* \uc800\uc7a5\ub418\uc5b4\uc788\ub294 weigth\ub97c \ubd88\ub7ec\uc624\uace0 test\ub97c \ud558\uace0\uc790\ud55c \uc774\ubbf8\uc9c0\uc758 \uacbd\ub85c\ub97c source\uc5d0 \ucd94\uac00\ud569\ub2c8\ub2e4. \n* save-txt : txt\ud30c\uc77c\ub85c \uc800\uc7a5 save-conf : txt\ud30c\uc77c\uc5d0 confidence score\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4. (confidence score\uc740 txt\uc5d0 \ub9c8\uc9c0\ub9c9 \uc5f4\uc5d0 \uc788\uc74c)","fadbf718":"* detect\uc758 \uacb0\uacfc\ub97c \ubcf4\uae30 \uc704\ud574\uc11c json\ud30c\uc77c\uc744 image\ub97c \ucd94\ucd9c\ud569\ub2c8\ub2e4.","e39d4e07":"##  Load library  ","97c083dd":"# [wandb \ud559\uc2b5 \ub9c1\ud06c](https:\/\/wandb.ai\/stickypanda03\/yolov5-endoscopy\/runs\/mu38zhis?workspace=user-stickypanda03)"}}