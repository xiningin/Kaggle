{"cell_type":{"da31b191":"code","4e92c9c3":"code","5fe44435":"code","c3ab81b2":"code","b21b4c71":"code","115b6108":"code","a8ed50da":"code","12cfffd9":"code","01d0e637":"code","9ffe13b1":"code","3a221ff5":"code","56d1e8af":"code","76442521":"code","dd41913e":"code","0042432a":"code","272c06a8":"code","df48833f":"code","f6374faf":"code","a36a03b3":"code","4b8c507f":"code","54b0b7bb":"code","7c4d8c7d":"code","f7d6f0ca":"code","186ed1bc":"code","d2b137ff":"code","8dc968d3":"code","c1644f9b":"code","2f0ff5c8":"code","a970f1dd":"code","119aacf3":"code","1895ea5c":"code","dd09efbe":"code","d09bad29":"code","7dd0e21d":"code","9b3d78bc":"code","3346057b":"code","4e9c8db7":"markdown","282e721e":"markdown","ac646558":"markdown","3eb5947c":"markdown","64fed9c8":"markdown","1756f259":"markdown","7c18bb82":"markdown","ccb9488b":"markdown","8cf40763":"markdown","f9fe7367":"markdown","d0837fcc":"markdown","2cc15e2b":"markdown","87b7e9a0":"markdown","64a24a43":"markdown","5019686f":"markdown","4b26111e":"markdown","20733a58":"markdown"},"source":{"da31b191":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.spatial import distance_matrix\n\nfrom sklearn import preprocessing\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\ndatadir = \"..\/input\/\"","4e92c9c3":"train = pd.read_csv(datadir + 'champs-scalar-coupling\/train.csv')\ntest = pd.read_csv(datadir + 'champs-scalar-coupling\/test.csv')\nstructures = pd.read_csv(datadir + 'champs-scalar-coupling\/structures.csv')","5fe44435":"train.head()","c3ab81b2":"pseudolabels = pd.read_csv(datadir + \"pseudolabels\/simple_blend_nn_lgb_hill.csv\")\ntest['scalar_coupling_constant'] = pseudolabels['scalar_coupling_constant']","b21b4c71":"train_bonds = pd.read_csv(datadir + 'predicting-molecular-properties-bonds\/train_bonds.csv')\ntest_bonds = pd.read_csv(datadir + 'predicting-molecular-properties-bonds\/test_bonds.csv')","115b6108":"angs = pd.read_csv(datadir + \"angle-and-dihedral-for-the-champs-structures\/angles.csv\")","a8ed50da":"ang_tor_test = pd.read_hdf(datadir + \"ang-tor\/test_ang_tor.h5\")\nang_tor_train = pd.read_hdf(datadir + \"ang-tor\/train_ang_tor.h5\")","12cfffd9":"neig_struct = pd.read_hdf(datadir + \"ang-tor\/struct_neighbours.h5\")\n","01d0e637":"mulliken = pd.read_csv(datadir + 'qm9-mulliken\/mulliken_charges_fom_qm9.csv')","9ffe13b1":"coups_to_isolate = ['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']\nfor coup in coups_to_isolate:\n    scale_min = train['scalar_coupling_constant'].loc[train.type == coup].min()\n    scale_max = train['scalar_coupling_constant'].loc[train.type == coup].max()\n    scale_mid = (scale_max + scale_min)\/2\n    scale_norm = scale_max - scale_mid\n    #print(train['scalar_coupling_constant'].loc[train.type == coup].max())\n\n    print(scale_norm, scale_mid)\n    \n    train['scalar_coupling_constant'].loc[train.type == coup] = (train['scalar_coupling_constant'].loc[train.type == coup] - scale_mid)\/scale_norm\n    test['scalar_coupling_constant'].loc[test.type == coup] = (test['scalar_coupling_constant'].loc[test.type == coup] - scale_mid)\/scale_norm","3a221ff5":"#scale_min  = train['scalar_coupling_constant'].min()\n#scale_max  = train['scalar_coupling_constant'].max()\n#scale_mid = (scale_max + scale_min)\/2\n#scale_norm = scale_max - scale_mid\n\n#train['scalar_coupling_constant'] = (train['scalar_coupling_constant'] - scale_mid)\/scale_norm\n\n# One hot encoding gets  too big for Kaggle, let's try label\n# use npz now, back to OH\ntrain[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']] =  pd.get_dummies(train['type'])\ntest[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']]  =  pd.get_dummies(test['type'])\n\n#le = preprocessing.LabelEncoder()\n#le.fit(['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN'])\n#train['l_type'] = (le.transform(train['type']) + 1)\/8.\n#test['l_type'] = (le.transform(test['type']) + 1)\/8.","56d1e8af":"structures[['C', 'F' ,'H', 'N', 'O']] = pd.get_dummies(structures['atom'])\nstructures[['x', 'y', 'z']] = structures[['x', 'y', 'z']]\/10.","76442521":"structures = pd.merge(structures, mulliken[['molecule_name', 'atom_index', 'mulliken_charge']], how = 'left',\n                  left_on  = ['molecule_name', 'atom_index'],\n                  right_on = ['molecule_name', 'atom_index'])","dd41913e":"test_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(test_bonds['nbond'])#test_bonds['nbond']\/3\ntrain_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(train_bonds['nbond'])#train_bonds['nbond']\/3\n","0042432a":"angs['dihedral'] = angs['dihedral']\/np.pi\n# Should I rather one-hot this?\nangs['shortest_path_n_bonds'] = angs['shortest_path_n_bonds']\/6.0\nangs = angs.fillna(0)","272c06a8":"MapAtoms = {6.0 : 'C', 7.0 : 'N', 8.0 : 'O'}\nang_tor_test['ThirdAtom']  = ang_tor_test['ThirdAtom'].replace(MapAtoms)\nang_tor_train['ThirdAtom'] = ang_tor_train['ThirdAtom'].replace(MapAtoms)\n\nang_tor_test['SecondAtom']  = ang_tor_test['SecondAtom'].replace(MapAtoms)\nang_tor_train['SecondAtom'] = ang_tor_train['SecondAtom'].replace(MapAtoms)","df48833f":"#ThirdAtomNames = ['No', 'C1', 'C2', 'C3', 'C+', 'Car', 'O2', 'O3', 'Nam', 'Nar', 'N2', 'N3', 'N3+', 'Npl',  \n#        'Ng+', 'Nox']\n\nThirdAtomNames = ['C','N','O']\n\nT = [_ + \"T\" for _ in ThirdAtomNames]\n\n#SecondAtomNames = ['No', 'C3', 'N3', 'O3', 'C1', 'C2', 'Nam', 'O2', 'Nar', 'Car',\n#       'N2', 'Npl', 'N3+', 'Ng+']\nSecondAtomNames = ['C','N','O']\n\nS = [_ + \"S\" for _ in SecondAtomNames]\n\n\nang_tor_test[T] =  pd.get_dummies( ang_tor_test['ThirdAtom'])[ThirdAtomNames]\nang_tor_train[T] =  pd.get_dummies( ang_tor_train['ThirdAtom'])[ThirdAtomNames]\n\nang_tor_test[S] =  pd.get_dummies( ang_tor_test['SecondAtom'])[SecondAtomNames]\nang_tor_train[S] =  pd.get_dummies( ang_tor_train['SecondAtom'])[SecondAtomNames]","f6374faf":"#MapAtoms = dict(enumerate(ThirdAtomNames))\n#MapAtoms = {val:key for (key, val) in MapAtoms.items()}","a36a03b3":"#ang_tor_train['ThirdAtom_l'] = ang_tor_train['ThirdAtom'].replace(MapAtoms)\n#ang_tor_test['ThirdAtom_l'] =  ang_tor_test['ThirdAtom'].replace(MapAtoms)\n\n#ang_tor_train['SecondAtom_l'] = ang_tor_train['SecondAtom'].replace(MapAtoms)\n#ang_tor_test['SecondAtom_l'] =  ang_tor_test['SecondAtom'].replace(MapAtoms)\n\n#ang_tor_test['ThirdAtom_l'] = ang_tor_test['ThirdAtom_l']\/15.\n#ang_tor_train['ThirdAtom_l'] = ang_tor_train['ThirdAtom_l']\/15.\n\n#ang_tor_test['SecondAtom_l'] = ang_tor_test['SecondAtom_l']\/15.\n#ang_tor_train['SecondAtom_l'] = ang_tor_train['SecondAtom_l']\/15.\n","4b8c507f":"ang_tor_test[\"Angle\"] = ang_tor_test[\"Angle\"]\/180\nang_tor_train[\"Angle\"] = ang_tor_train[\"Angle\"]\/180","54b0b7bb":"ang_tor_test['Torsion'] = ang_tor_test['Torsion']\/180\nang_tor_train['Torsion'] = ang_tor_train['Torsion']\/180","7c4d8c7d":"ang_tor_vals = ['Angle', 'Torsion', 'cosT', 'cos2T'] + S + T#, 'SecondAtom', 'ThirdAtom']","f7d6f0ca":"test = pd.merge(test, ang_tor_test[[ 'id'] + ang_tor_vals], how = 'left',\n                  left_on  = [ 'id'],\n                  right_on = ['id'])","186ed1bc":"train = pd.merge(train, ang_tor_train[[ 'id'] + ang_tor_vals], how = 'left',\n                  left_on  = [ 'id'],\n                  right_on = ['id'])","d2b137ff":"neig_struct[[1,6,7,8,9]] = neig_struct[[1,6,7,8,9]]\/4.0","8dc968d3":"structures[['n_H', 'n_C', 'n_N', 'n_O', 'n_F']] = neig_struct[[1,6,7,8,9]]","c1644f9b":"train_mol_names = train['molecule_name'].unique()\ntest_mol_names  = test['molecule_name'].unique()\n\ntrain_structures = structures.loc[structures['molecule_name'].isin(train_mol_names)]\ntest_structures = structures.loc[structures['molecule_name'].isin(test_mol_names)]\n\ntrain_struct_group = train_structures.groupby('molecule_name')\ntest_struct_group  = test_structures.groupby('molecule_name')\n\ntrain_group = train.groupby('molecule_name')\ntest_group  = test.groupby('molecule_name')\n\ntrain_bond_group = train_bonds.groupby('molecule_name')\ntest_bond_group  = test_bonds.groupby('molecule_name')\n\ntrain_angs = angs.loc[angs['molecule_name'].isin(train_mol_names)]\ntest_angs = angs.loc[angs['molecule_name'].isin(test_mol_names)]\n\ntrain_angs_group = train_angs.groupby('molecule_name')\ntest_angs_group  = test_angs.groupby('molecule_name')\n\n#train_angs_group = ang_tor_train.groupby('molecule_name')\n#test_angs_group = ang_tor_test.groupby('molecule_name')\n\n\n# Find max nodes in graph:\nmax_size = train_struct_group.size().max()","2f0ff5c8":"# Values our nodes will have\nnode_vals = ['C', 'F' ,'H', 'N', 'O', 'mulliken_charge', 'n_H', 'n_C', 'n_N', 'n_O', 'n_F']\n#Values our edges will have (minus distance, for now)\nbond_vals = ['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']#['nbond']\nj_coup_vals = ['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']#'l_type']\nang_vals = ['shortest_path_n_bonds','cosinus','dihedral']\n#ang_vals = ['sp',  'Angle', 'Torsion', 'cosT', 'cos2T'] + ['ThirdAtom_l', 'SecondAtom_l']#+ T + S\nedge_vals = j_coup_vals + bond_vals + ang_vals + ang_tor_vals\n\n# Find amount of training molecules\nn_train_mols = len(train_mol_names)\nn_test_mols = len(test_mol_names)\n\n# Find dim of edges and nodes\nbond_dim  = len(bond_vals)\nj_coup_dim= len(j_coup_vals)\nang_tor_dim = len(ang_tor_vals)\nang_dim   = len(ang_vals)\nnode_dim  = len(node_vals)\nedge_dim  = len(edge_vals) \n\n# Additional edge dims for distances\nadd_edge_dim = 1","a970f1dd":"def make_arrs(val_group, struct_group, bond_group, ang_group, test):\n    i = 0\n    for values, structs, bonds, angles in zip(val_group, struct_group, bond_group, ang_group):\n        if (not i%1000):\n            print(i)\n\n        # Calculate distances\n        distances = np.zeros((max_size, max_size, 1))\n        coords = structs[1][['x','y','z']].values\n        dists  = distance_matrix(coords, coords)\n        distances[:dists.shape[0],:dists.shape[1], 0] = dists \n        \n        # Create nodes\n        mol_info = structs[1][node_vals].values\n        nodes = np.zeros((max_size, node_dim))\n        nodes[:mol_info.shape[0], :mol_info.shape[1]] = mol_info\n\n        # Create edges\n        in_feats = np.zeros((max_size, max_size, j_coup_dim + ang_tor_dim))\n        ind = values[1][['atom_index_0', 'atom_index_1' ]].values\n        in_feats[ind[:,0], ind[:,1], 0:j_coup_dim + ang_tor_dim] = values[1][j_coup_vals + ang_tor_vals].values\n        in_feats[ind[:,1], ind[:,0], 0:j_coup_dim + ang_tor_dim] = in_feats[ind[:,0], ind[:,1], 0:j_coup_dim + ang_tor_dim]\n\n        # Create bonds\n        in_bonds = np.zeros((max_size, max_size, bond_dim))\n        ind_bonds = bonds[1][['atom_index_0', 'atom_index_1' ]].values\n        in_bonds[ind_bonds[:,0], ind_bonds[:,1]] = bonds[1][bond_vals].values\n        in_bonds[ind_bonds[:,1], ind_bonds[:,0]] = in_bonds[ind_bonds[:,0], ind_bonds[:,1]]\n        \n        \n        \n        # Create angles\n        ind_angs = angles[1][['atom_index_0', 'atom_index_1' ]].values\n        ang_mat  = np.zeros((max_size, max_size, ang_dim))\n        ang_mat[ind_angs[:,0], ind_angs[:,1]]  = angles[1][ang_vals]\n        ang_mat[ind_angs[:,1], ind_angs[:,0]]  = ang_mat[ind_angs[:,0], ind_angs[:,1]]\n        \n        # concat all edge values \n        in_edges = np.concatenate((in_feats, in_bonds, ang_mat, distances),axis=2)\n\n\n\n        \n        if not test:           \n            out_edges = np.zeros((max_size, max_size, 1))\n            out_edges[ind[:,0], ind[:,1], 0] = values[1]['scalar_coupling_constant' ].values\n            out_edges[ind[:,1], ind[:,0], 0] = out_edges[ind[:,0], ind[:,1], 0]\n        \n\n            train_nodes_array[i]      = nodes\n            train_in_edges_array[i]   = in_edges\n            train_out_edges_array[i]  = out_edges\n        else:\n            out_edges = np.zeros((max_size, max_size, 1))\n            out_edges[ind[:,0], ind[:,1], 0] = values[1]['scalar_coupling_constant' ].values\n            out_edges[ind[:,1], ind[:,0], 0] = out_edges[ind[:,0], ind[:,1], 0]\n            \n            test_nodes_array[i]      = nodes\n            test_in_edges_array[i]   = in_edges\n            test_out_edges_array[i]  = out_edges\n        i = i + 1\n","119aacf3":"train_nodes_array     = np.zeros((n_train_mols, max_size, node_dim), dtype=np.float32) \ntrain_in_edges_array  = np.zeros((n_train_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) \ntrain_out_edges_array = np.zeros((n_train_mols, max_size, max_size, 1),dtype=np.float32) \n\n","1895ea5c":"make_arrs(train_group, train_struct_group, train_bond_group, train_angs_group, test = False)","dd09efbe":"np.savez_compressed(\"nodes_train.npz\" , train_nodes_array)\nnp.savez_compressed(\"in_edges_train.npz\" , train_in_edges_array)\nnp.savez_compressed(\"out_edges_train.npz\" , train_out_edges_array)","d09bad29":"del train_nodes_array\ndel train_in_edges_array\ndel train_out_edges_array","7dd0e21d":"test_nodes_array     = np.zeros((n_test_mols, max_size, node_dim), dtype=np.float32) \ntest_in_edges_array  = np.zeros((n_test_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) \ntest_out_edges_array = np.zeros((n_test_mols, max_size, max_size, 1),dtype=np.float32) \n","9b3d78bc":"make_arrs(test_group, test_struct_group, test_bond_group, test_angs_group, test = True)","3346057b":"np.savez_compressed(\"nodes_test.npz\" , test_nodes_array)\nnp.savez_compressed(\"in_edges_test.npz\" , test_in_edges_array)\nnp.savez_compressed(\"out_edges_test.npz\" , test_out_edges_array)","4e9c8db7":"## Reads from angles file\nTaken from: https:\/\/www.kaggle.com\/soerendip\/calculate-angles-and-dihedrals-with-networkx\n(thanks Rakete!)","282e721e":"## Process neighbour struct values","ac646558":"## Read in bonds files\nTaken from:   https:\/\/www.kaggle.com\/asauve\/dataset-with-number-of-bonds-between-atoms  \n(thanks Alexandre Sauv\u00e9!)","3eb5947c":"## Define node and edge values","64fed9c8":"## Read in the mulliken charges from qm9","1756f259":"# Process angles","7c18bb82":"## Read angles and torsions","ccb9488b":"## Normalize targets so they have are centered around 0 and have max of 1, and one-hot encode coupling types","8cf40763":"## Pre-process the structures by one-hot encoding the atom types, and normalize distances to have around max of 1","f9fe7367":"## Save as numpy arrays","d0837fcc":"## Read in train, test and structures files","2cc15e2b":"# **Graph creator**\n\nA graph is a relativly natural way of representing molecules, and many method make use of structuring the data in this way.\n\nThis kernel shows a basic example of one can structure our data as a graph.   \n\nHere we will create an array for our node values, and an adjacency matrix for our edge values. \n\n\n(**Note**: One can argue whether an adjacency matrix is really the best way to go here as we have an undirected graph, and it is therefore a bit innefficienct ( n^2 as opposed to n(n-1)\/2 ), but it is easy to work with)\n\nThis is by no means the fastest way of doing this, but it is straightforward and only has to be run once, and the output can then be used. ","87b7e9a0":"## Process bonds","64a24a43":"## Process angles and torsions","5019686f":"## Read neighbours struct file","4b26111e":"## Find training and testing molecules, and split structrues into test and train. Then group by molecule\n","20733a58":"## Pre-allocate arrays that we will fill later\n"}}