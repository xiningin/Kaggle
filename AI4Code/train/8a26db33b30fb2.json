{"cell_type":{"2aa2b7ce":"code","0927a561":"code","a226b4a3":"code","624b9e3d":"code","ee52b7b7":"code","8144dcb2":"code","f75260fc":"code","7cf2d6ab":"code","684e14c3":"code","c31c465f":"code","0a5ddc96":"code","3296f428":"code","c5d018d9":"code","a02300a5":"code","d46092b1":"code","8e003fe8":"code","bf2c389a":"code","50e7173f":"code","3db9531e":"code","5ac13164":"code","7e9a5d9d":"code","8b0fa02e":"code","fb49c942":"code","4604b0c7":"code","45608b7e":"code","7c81145e":"code","57c48c9e":"code","94d23f16":"code","2fc9d76b":"code","1efc69b2":"code","7471bc77":"code","80db43ca":"code","f736640f":"code","b27ff43f":"code","8d7dd0e4":"code","145fbdc7":"code","9106ba4a":"code","a72793fb":"code","77c7588b":"markdown","3ee6ebeb":"markdown","5da2da88":"markdown","2ec9c9fe":"markdown","7b29d124":"markdown","7239a1de":"markdown","da317edd":"markdown","f358beaf":"markdown","46b95785":"markdown","865d757a":"markdown","89e01369":"markdown","8295d66e":"markdown","5026bcab":"markdown","f57f1ccd":"markdown","cfa7f1b4":"markdown","9969fc00":"markdown","82e7939e":"markdown","2242cb0c":"markdown","e056bf19":"markdown","fa3a6be7":"markdown","ebf4a13a":"markdown","7dfe2326":"markdown","41b959da":"markdown","fc7e8bba":"markdown","a4f070a5":"markdown","5b637535":"markdown","6d38f569":"markdown","345020f3":"markdown","dd12b255":"markdown","622e9dda":"markdown","5c93bae6":"markdown","1e96feaf":"markdown","2fcdc347":"markdown"},"source":{"2aa2b7ce":"import collections\nimport json\nimport os\nimport uuid\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageDraw, ImageFilter\nimport tifffile as tiff \nimport seaborn as sns","0927a561":"!ls ..\/input\/hubmap-kidney-segmentation\/","a226b4a3":"train = pd.read_csv(\"..\/input\/hubmap-kidney-segmentation\/train.csv\")\ntrain.info()","624b9e3d":"train.head()","ee52b7b7":"ds_info = pd.read_csv(\"..\/input\/hubmap-kidney-segmentation\/HuBMAP-20-dataset_information.csv\")\nds_info.info()","8144dcb2":"ds_info.head()","f75260fc":"!ls ..\/input\/hubmap-kidney-segmentation\/train","7cf2d6ab":"!ls ..\/input\/hubmap-kidney-segmentation\/test","684e14c3":"img_id_1 = \"aaa6a05cc\"\nimage_1 = tiff.imread('..\/input\/hubmap-kidney-segmentation\/train\/' + img_id_1 + \".tiff\")\nprint(\"This image's id:\", img_id_1)\nimage_1.shape","c31c465f":"plt.figure(figsize=(15, 15))\nplt.imshow(image_1)","0a5ddc96":"plt.figure(figsize=(8,8))\nplt.imshow(image_1[5200:5600, 5600:6000, :])","3296f428":"img_id_4 = \"e79de561c\"\nimage_4 = tiff.imread('..\/input\/hubmap-kidney-segmentation\/train\/' + img_id_4 + \".tiff\")\nprint(\"This image's id:\", img_id_4)\nimage_4.shape\nimage_4 = image_4[0][0].transpose(1, 2, 0)\nplt.figure(figsize=(10, 10))\nplt.imshow(image_4)","c5d018d9":"# https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n \ndef rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","a02300a5":"mask_1 = rle2mask(train[train[\"id\"]==img_id_1][\"encoding\"].iloc[-1], (image_1.shape[1], image_1.shape[0]))\nmask_1.shape","d46092b1":"plt.figure(figsize=(10,10))\nplt.imshow(mask_1, cmap='coolwarm', alpha=0.5)","8e003fe8":"plt.figure(figsize=(10,10))\nplt.imshow(image_1)\nplt.imshow(mask_1, cmap='coolwarm', alpha=0.5)","bf2c389a":"mask_4 = rle2mask(train[train[\"id\"]==img_id_4][\"encoding\"].iloc[-1], (image_4.shape[1], image_4.shape[0]))\nmask_4.shape\nplt.figure(figsize=(10,10))\nplt.imshow(image_4)\nplt.imshow(mask_4, cmap='coolwarm', alpha=0.5)","50e7173f":"plt.figure(figsize=(8,8))\nplt.imshow(image_1[5200:6200, 5000:6000, :])\nplt.imshow(mask_1[5200:6200, 5000:6000], cmap='coolwarm', alpha=0.5)","3db9531e":"plt.figure(figsize=(8,8))\nplt.imshow(np.rot90(image_1[5200:6200, 5000:6000, :]))\nplt.imshow(np.rot90(mask_1[5200:6200, 5000:6000]), cmap='coolwarm', alpha=0.5)","5ac13164":"plt.figure(figsize=(8,8))\nplt.imshow(np.fliplr(image_1[5200:6200, 5000:6000, :]))\nplt.imshow(np.fliplr(mask_1[5200:6200, 5000:6000]), cmap='coolwarm', alpha=0.5)","7e9a5d9d":"im_filterd = Image.fromarray(image_1)\nim_filterd = np.array(im_filterd.filter(ImageFilter.EDGE_ENHANCE_MORE))\nimage_1 = np.array(im_filterd)\n\nplt.figure(figsize=(8,8))\nplt.imshow(image_1[5200:6200, 5000:6000, :])\nplt.imshow(mask_1[5200:6200, 5000:6000], cmap='coolwarm', alpha=0.5)","8b0fa02e":"os.makedirs(f\".\/image\/{img_id_1}\/\")\nos.makedirs(f\".\/mask\/{img_id_1}\/\")","fb49c942":"pil_img = Image.fromarray(image_1[5200:6200, 5000:6000, :])\nprint(pil_img.mode)\n\nimg_uuid = str(uuid.uuid4())\n\npil_img.save(f'.\/image\/{img_id_1}\/{img_id_1}_{img_uuid}.jpg')\nnp.save(f'.\/mask\/{img_id_1}\/{img_id_1}_{img_uuid}', mask_1[5200:6200, 5000:6000])","4604b0c7":"with open(\"..\/input\/hubmap-kidney-segmentation\/train\/e79de561c.json\") as f:\n    e79de561c_json = json.load(f)\n    \nprint(\"lenght of json:\", len(e79de561c_json))\nprint(e79de561c_json[0])","45608b7e":"def flatten(l):\n    for el in l:\n        if isinstance(el, collections.abc.Iterable) and not isinstance(el, (str, bytes)):\n            yield from flatten(el)\n        else:\n            yield el\n\ndef draw_structure(structures, im):\n    \"\"\"\n    anatomical_structure: list of points of anatomical_structure poligon.\n    im: numpy array of image read from tiff file.\n    \"\"\"\n    \n    im = Image.fromarray(im)\n    draw = ImageDraw.Draw(im)\n    for structure in structures:\n        structure_flatten = list(flatten(structure[\"geometry\"][\"coordinates\"][0]))\n        structure = []\n        for i in range(0, len(structure_flatten), 2):\n            structure.append(tuple(structure_flatten[i:i+2]))\n        \n        draw.line(structure, width=100, fill='Red')\n    return im","7c81145e":"plt.figure(figsize=(8,8))\nimage_4_with_line = draw_structure(e79de561c_json, image_4)\nplt.imshow(image_4_with_line)","57c48c9e":"with open(f\"..\/input\/hubmap-kidney-segmentation\/train\/{img_id_1}-anatomical-structure.json\") as f:\n    anatomical_structure_json = json.load(f)\n    \nanatomical_structure_json","94d23f16":"plt.figure(figsize=(8,8))\nimage_1_with_line = draw_structure(anatomical_structure_json, image_1)\nplt.imshow(image_1_with_line)","2fc9d76b":"ds_info.head()","1efc69b2":"ds_info.shape","7471bc77":"def train_or_test(image_file):\n    id, _ = image_file.split(\".\")\n    if id in list(train[\"id\"]):\n        return \"train\"\n    else:\n        return \"test\"\n    \nds_info[\"category\"] = ds_info[\"image_file\"].map(train_or_test)","80db43ca":"plt.style.use(\"Solarize_Light2\")","f736640f":"plt.figure(figsize=(15, 5))\ng = sns.countplot(data=ds_info, x=\"patient_number\", hue=\"category\", palette=sns.color_palette(\"Set2\", 8))\ng.set_title(\"Number of images per patient\")","b27ff43f":"fig, axes = plt.subplots(1, 2, figsize=(10,5), gridspec_kw=dict(wspace=0.1, hspace=0.6))\nfig.suptitle(\"race and ethnicity\", fontsize=15)\ng = sns.countplot(data=ds_info, x=\"race\", hue=\"category\", palette=sns.color_palette(\"Set2\", 8),ax=axes[0])\ng.set_title(\"distribution of race\", fontsize=12)\ng = sns.countplot(data=ds_info, x=\"ethnicity\", palette=sns.color_palette(\"Set2\", 8), hue=\"category\",ax=axes[1])\ng.set_title(\"distribution of ethnicity\", fontsize=12)","8d7dd0e4":"#Create figure and Axes. And set title.\nfig, axes = plt.subplots(2, 2, figsize=(10,6), gridspec_kw=dict(wspace=0.1, hspace=0.6))\nfig.suptitle(\"Sex and age\", fontsize=15)\n\n#Too check layout, I'll show text on each Axes.\ngs = axes[0, 1].get_gridspec()\naxes[0, 0].remove()\naxes[1, 0].remove()\n#Add gridspec we got\naxbig = fig.add_subplot(gs[:, 0])\n\ng = sns.countplot(data=ds_info, x=\"sex\", hue=\"category\", palette=sns.color_palette(\"Set2\", 8),ax=axbig)\ng.set_title(\"distribution of sex\", fontsize=12)\n\n#Add three plots.\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"train\"][\"age\"], color=\"tomato\", kde=False, rug=False,ax=axes[0,1])\ng.set(xlim=(30,80))\ng.set(ylim=(0,3))\ng.set_title(\"distribution of age for train\", fontsize=12)\n\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"test\"][\"age\"], color=\"teal\", kde=False, rug=False, ax=axes[1,1])\ng.set(xlim=(30,80))\ng.set(ylim=(0,3))\ng.set_title(\"distribution of age for test\", fontsize=12)","145fbdc7":"fig, axes = plt.subplots(2, 2, figsize=(10,10), gridspec_kw=dict(wspace=0.1, hspace=0.4))\nfig.suptitle(\"Physical information for train\", fontsize=15)\n\n\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"train\"][\"weight_kilograms\"], color=\"tomato\", kde=False, rug=False, ax=axes[0,0])\ng.set(xlim=(55,135))\ng.set(ylim=(0,5))\ng.set_title(\"weight_kilograms\", fontsize=12)\n\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"train\"][\"height_centimeters\"], color=\"tomato\", kde=False, rug=False, ax=axes[0,1])\ng.set(xlim=(155,195))\ng.set(ylim=(0,5))\ng.set_title(\"height_centimeters\", fontsize=12)\n\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"train\"][\"bmi_kg\/m^2\"], color=\"tomato\", kde=False, rug=False, ax=axes[1,0])\ng.set(xlim=(22,37.5))\ng.set(ylim=(0,5))\ng.set_title(\"bmi_kg\/m^2\", fontsize=12)\n\ng = sns.countplot(ds_info[ds_info[\"category\"]==\"train\"][\"laterality\"], ax=axes[1,1])\ng.set_title(\"laterality\", fontsize=12)\n\n\nfig, axes = plt.subplots(2, 2, figsize=(10,10), gridspec_kw=dict(wspace=0.1, hspace=0.4))\nfig.suptitle(\"Physical information for test\", fontsize=15)\n\n\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"test\"][\"weight_kilograms\"], color=\"teal\", kde=False, rug=False, ax=axes[0,0])\ng.set(xlim=(55,135))\ng.set(ylim=(0,5))\ng.set_title(\"weight_kilograms\", fontsize=12)\n\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"test\"][\"height_centimeters\"], color=\"teal\", kde=False, rug=False, ax=axes[0,1])\ng.set(xlim=(155,195))\ng.set(ylim=(0,5))\ng.set_title(\"height_centimeters\", fontsize=12)\n\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"test\"][\"bmi_kg\/m^2\"], color=\"teal\", kde=False, rug=False, ax=axes[1,0])\ng.set(xlim=(22,37.5))\ng.set(ylim=(0,5))\ng.set_title(\"bmi_kg\/m^2\", fontsize=12)\n\ng = sns.countplot(ds_info[ds_info[\"category\"]==\"test\"][\"laterality\"], ax=axes[1,1])\ng.set_title(\"laterality\", fontsize=12)","9106ba4a":"ds_info[\"Ratio_of_medulla_to_cortex\"] = ds_info[\"percent_medulla\"] \/ ds_info[\"percent_cortex\"] ","a72793fb":"fig, axes = plt.subplots(1, 2, figsize=(10,5), gridspec_kw=dict(wspace=0.1, hspace=0.6))\nfig.suptitle(\"distribution of ratio of medulla to cortex\", fontsize=15)\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"train\"][\"Ratio_of_medulla_to_cortex\"], color=\"tomato\",kde=False, rug=False, ax=axes[0])\ng.set(ylim=(0,5))\ng.set_title(\"train\", fontsize=12)\ng = sns.distplot(ds_info[ds_info[\"category\"]==\"test\"][\"Ratio_of_medulla_to_cortex\"], color=\"teal\", kde=False, rug=False, ax=axes[1])\ng.set(ylim=(0,5))\ng.set_title(\"test\", fontsize=12)","77c7588b":"Show the mask of the kidney image.","3ee6ebeb":"### train directory\n\ntiff files are kidney image data. json files include unencoded annotations. ","5da2da88":"There are two kinds of json files. About glomerulus segmentation file files, I'll explain it in [here](#99), and about anatomical structure file in [here](#100).","2ec9c9fe":"### Save as image\n\nWith pillow, we can save our processed kideny images and masks as image file. For create dataset, I'll try.","7b29d124":"<a id=\"100\"><\/a>\n### Anatomical structure file\n\nIn the same way with glomerulus segmentation file, we can show anatomical structure segmentations. This file contains anatomical structure segmentations. They are intended to help us identify the various parts of the tissue.","7239a1de":"## Load data\n\nThere are three csv data and two directories.","da317edd":"I'll define utility function. By this function, we can get PIL.Image.Image instance with line.","f358beaf":"## With Annotation json file\n\nWe have also two kinds of annotation files. I'll explain what information they have and how to visualize them.","46b95785":"If we want to see with the image, ","865d757a":"<a id=\"1\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Introduction<\/div>","89e01369":"## mask\n\nWe can decode mask from encoding column of train.csv.","8295d66e":"<a id=\"99\"><\/a>\n### Glomerulus segmentation file\n\nAccording to the description of dataset, the same information as the rle-encoded mask is stored.","5026bcab":"## Processing\n\nTo create dataset for model training, we have to generate dataset from these pictures. I'll explain how to process and save image.","f57f1ccd":"### Rotate","cfa7f1b4":"### Crop","9969fc00":"## Notes for new participants\n\nWe should be aware that notebooks that have been around for some time may not be in line with the current situation. We may want to pay attention to when the notebook was last run and the data used. \n\nThis competition [updated dataset](https:\/\/www.kaggle.com\/c\/hubmap-kidney-segmentation\/discussion\/224826), and [this discussion](https:\/\/www.kaggle.com\/c\/hubmap-kidney-segmentation\/discussion\/207884) will help us understand how it happened and the precautions we need to take with updating. ","82e7939e":"### HuBMAP-20-dataset_information.csv\n\nThis file includes additional information (including anonymized patient data) about each image. I'll visualize this information in following part.","2242cb0c":"There are 20 data. Each data has 16 colmuns.\n\n15 data are for training, and rest are test. It includes anonymized patient data.","e056bf19":"### flip","fa3a6be7":"Glomerulus is...","ebf4a13a":"### with filters\n\nWe can use filters with [ImageFilter Module](https:\/\/pillow.readthedocs.io\/en\/stable\/reference\/ImageFilter.html). The current version of Pillow provides the following set of predefined image enhancement filters:\n\n- BLUR\n- CONTOUR\n- DETAIL\n- EDGE_ENHANCE\n- EDGE_ENHANCE_MORE\n- EMBOSS\n- FIND_EDGES\n- SHARPEN\n- SMOOTH\n- SMOOTH_MORE\n\nAfter converting image to PIL image with Image.fromarray function, we can use image filter. And we can return it to np.array.","7dfe2326":"### train.csv\n\nThere are 8 training set. This csv includes ids corresponding to data in train directory. Also it has mask data in \"encoding\" column. This data is encoded with RLE encoding. ","41b959da":"<a id=\"4\"><\/a> <br>\n# <div class=\"alert alert-block alert-success\">Visualization of HuBMAP-20-dataset_information<\/div>\n\nI'll try to visualize HuBMAP-20-dataset_information to easy understand.","fc7e8bba":"### test directory","a4f070a5":"According to the [report](https:\/\/www.kaggle.com\/c\/hubmap-kidney-segmentation\/discussion\/198116) in the discussion, some annotations still be missing. For more information on the impact of this missing annotation data on prediction performance and data handling, [this discussion](https:\/\/www.kaggle.com\/c\/hubmap-kidney-segmentation\/discussion\/227616#1250442) is helpful.","5b637535":"## Goal\n\nGoal of this competition is development of a segmentation algorithm to identify the \"Glomerulus\" in the kidney.\n\nWe are given histological images of the kidney and annotation information representing the glomerular segmentation. Also we can use anatomical structure segmentation information and additional information (including anonymized patient data) about each image. ","6d38f569":"------------\n<a id=\"101\"><\/a> <br>\n## Reference\n\n[1] https:\/\/en.wikipedia.org\/wiki\/Glomerulus_(kidney) \n\n[2] https:\/\/www.kaggle.com\/c\/hubmap-kidney-segmentation\/discussion\/197552","345020f3":"## About Glomerulus\n\nThe glomerulus is one of the components of the \"nephron\". Nephron is said to be one million in one kidney. How many nephrons there are can be seen [later](#3) when you visualize the dataset. I'll put image of nephron from [reference[1]](#101). Nephron has roughly three components, glomerulus, bowman's capsule and tubule. \n\nGlomerulus is a mass of capillaries surrounded by a Bowman's capsule. The name comes from the fact that they look just like a hairball when viewed under a microscope. They act like filter paper.\nPlasma (the non-cellular components of blood) sent to the kidney is filtered out during its passage through the capillaries of the glomerulus. Some of it comes out of the Bowman's capsule as the original urine. \n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/1\/18\/Bowman%27s_capsule_and_glomerulus.svg\/1280px-Bowman%27s_capsule_and_glomerulus.svg.png\" width=\"250\">","dd12b255":"<a id=\"2\"><\/a> <br>\n# <div class=\"alert alert-block alert-success\">Loading and overviewing dataset<\/div>\n\n## Load Library","622e9dda":"## HuBMAP Let's Visualize and Understand Dataset\n\n### Release note\n\n- Version1: First release\n\n- Version2: Reorganized and added information to easier understand.\n\n- Version3: Add how to visualize anatomical-structure.json.\n\n- Version4: Add how to visualize glomerulus_segmentation_file.\n\n- Version5: Add explanation for background.\n\n- Version6: Maintained with additional data.\n\n## Contents\n\n1. [Introduction](#1)\n1. [Loading and overviewing dataset](#2)\n1. [Read and show Kidney image data](#3)\n1. [Visualization of HuBMAP-20-dataset_information](#4)","5c93bae6":"Let's see one more example.","1e96feaf":"<a id=\"3\"><\/a> <br>\n# <div class=\"alert alert-block alert-warning\">Read and show Kidney image data<\/div>\n\nWe are given histological images of the kidney. These images are tiff format. We can load this data with tifffile module. Let's load and show them.","2fcdc347":"Some tiff files are saved by different shape. We can view them in the same way by reading and then taking the transposition."}}