{"cell_type":{"2284df51":"code","b2a2b8e2":"code","850f8996":"code","cb78029f":"code","07464804":"code","98942b6f":"code","14d7363e":"code","b12b751d":"code","ed588fe9":"code","b38e4014":"code","ddba30bf":"code","ab666816":"code","4b20456d":"code","21be08f3":"code","05b16787":"code","4c841e31":"code","992624d7":"code","22556e42":"code","cfc4fbaf":"code","45dda97a":"code","f780bd2f":"code","5b9fdf57":"code","621129c5":"code","d0150df8":"code","4dbf8417":"code","a9019fa2":"code","796d7676":"code","90b2b541":"code","9b755c13":"code","e51b44ff":"code","a1f1f42e":"code","55881e1b":"code","3c3aecbe":"code","e01ca8e1":"code","76f03046":"code","f54d141d":"code","9a3dc491":"code","10833401":"code","eae4b12a":"code","c099765f":"code","ff08daad":"code","1029ab84":"code","619b4c12":"code","8339e847":"code","985a628c":"code","8fc40e37":"code","59bb46fb":"code","d46357ff":"code","b98c2851":"code","3105a940":"code","f64fdb2a":"code","bd053ae9":"code","ec8e543f":"code","fde89207":"code","d1b7942e":"code","4932bd2c":"code","ebc8de12":"code","5212d4b3":"code","b93a56d9":"code","f648f6df":"code","151c04bb":"code","aa30305a":"code","df72b319":"code","05572ff4":"code","1f21d741":"code","211822a7":"code","21374645":"code","ce3b4550":"code","444552e7":"code","062c0729":"code","67b95caf":"code","9ddab87b":"code","c0d78b4a":"code","15160f98":"code","9a896bf6":"code","1db65adc":"code","27216b1b":"code","ad42ea4a":"code","34a62b10":"code","54f957d5":"code","4a80107c":"code","8bd55c55":"code","2d6236fa":"code","09f68847":"code","8f60c947":"code","de70e50f":"code","02f83d41":"code","c61772b5":"code","45e1c29f":"code","7e03252b":"code","6b1ffd63":"code","0fe75984":"code","94dfd66d":"code","cb7714c8":"code","4f935e55":"code","da0ee79a":"code","90a97fc7":"code","cf6fc78e":"code","07830cd5":"code","514518bb":"code","90672855":"code","7cb4c5ca":"code","ac471869":"code","ea541bdd":"code","ee29294a":"code","8ee474eb":"code","851f3ac5":"code","a4518803":"code","ea6e0d93":"code","62da4ac4":"code","7481a82c":"code","d0634062":"code","88447d20":"code","a0e6c1ab":"code","5bf43853":"code","f6585906":"code","d0033f8f":"code","e7ea8c6f":"code","cd33e425":"code","c526bdbe":"code","50c932e5":"code","cdd809c4":"code","346fba38":"code","fce51a21":"code","aa6137e6":"code","b47b3946":"code","9f1c801c":"code","1618bd08":"code","901353ff":"code","99d86ca1":"code","e99ce747":"code","e36bf551":"code","b20865e1":"code","1f7ae591":"code","7c155a5e":"code","7971b3c0":"code","54ca4ae2":"code","f23ec9ff":"code","75d1d80b":"code","4b80a5da":"code","7d06110f":"code","eeb46bcc":"code","a2e80eef":"code","45c02406":"code","8ba0b888":"code","79e6fe34":"code","da63277f":"code","245431e0":"markdown","0f680829":"markdown","e6d56423":"markdown","81dddbed":"markdown","f38e4d66":"markdown","2b187078":"markdown","cb21fd56":"markdown","8faa6984":"markdown","4fba8306":"markdown","aef05dfb":"markdown","aee6e54b":"markdown","afb2fe79":"markdown","cb600bc5":"markdown","4bf17f6b":"markdown","0fdaf845":"markdown","bdfd635c":"markdown","9373db91":"markdown","3a88bfd5":"markdown","6bf94062":"markdown","a2b6d998":"markdown","437db935":"markdown","cce5c5e0":"markdown","d51f7a57":"markdown","abb3cb05":"markdown","6814ce79":"markdown","470b4f41":"markdown","adf95bc6":"markdown","acc81561":"markdown","1f32e3dc":"markdown","4dc601b9":"markdown","f54e74eb":"markdown","21f983dc":"markdown","6c9a2545":"markdown"},"source":{"2284df51":"import numpy as np \nimport pandas as pd\n\nimport glob\nimport json","b2a2b8e2":"root_path = '\/kaggle\/input\/CORD-19-research-challenge\/'\nmetadata_path = f'{root_path}\/metadata.csv'\nmeta_df = pd.read_csv(metadata_path, dtype={\n    'pubmed_id': str,\n    'Microsoft Academic Paper ID': str, \n    'doi': str\n})\nmeta_df.head(2)","850f8996":"meta_df.shape","cb78029f":"meta_df.cord_uid.nunique()","07464804":"meta_df.isnull().sum()","98942b6f":"meta_df[meta_df.sha.notnull()][meta_df.sha.dropna().str.contains(';')].sha.iloc[0]","14d7363e":"meta_df.sha.dropna().str.contains(';').sum()","b12b751d":"meta_df.sha = meta_df.sha.apply(lambda x: x.split(';')[0] if pd.notnull(x) else x)","ed588fe9":"meta_df.sha.dropna().str.contains(';').sum()","b38e4014":"meta_df.sha.nunique()","ddba30bf":"all_json = glob.glob(f'{root_path}\/**\/pdf_json\/*.json', recursive=True)\nlen(all_json)","ab666816":"all_json_pmc = glob.glob(f'{root_path}\/**\/pmc_json\/*.json', recursive=True)\nlen(all_json_pmc)","4b20456d":"methods = ['methods','method','statistical methods','materials','materials and methods',\n                'data collection','the study','study design','experimental design','objective',\n                'objectives','procedures','data collection and analysis', 'methodology',\n                'material and methods','the model','experimental procedures','main text']","21be08f3":"# [''.join(x.lower() for x in m if x.isalpha()) for m in methods]\n\n# for m in methods:\n#     print(''.join(x.lower() for x in m if x.isalpha()))","05b16787":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.abstract = []\n            self.body_text = []\n            self.methods = []\n            self.results = []\n\n            # Abstract\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            # Methods\n            for entry in content['body_text']:\n                section_title = ''.join(x.lower() for x in entry['section'] if x.isalpha()) #remove numbers and spaces\n                if any(m in section_title for m in [''.join(x.lower() for x in m if x.isalpha()) for m in methods]) : \n                    self.methods.append(entry['text'])\n            # Results\n            results_synonyms = ['result']\n            for entry in content['body_text']:\n                section_title = ''.join(x.lower() for x in entry['section'] if x.isalpha())\n                if any(r in section_title for r in results_synonyms) :\n                    self.results.append(entry['text'])\n                    \n            self.abstract = '\\n'.join(self.abstract)\n            self.body_text = '\\n'.join(self.body_text)\n            self.methods = '\\n'.join(self.methods)\n            self.results = '\\n'.join(self.results)\n\n    def __repr__(self):\n        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\nfirst_row = FileReader(all_json[0])\nprint(first_row)","4c841e31":"dict_ = {'paper_id': [], 'abstract': [], 'body_text': [], 'methods': [], 'results': []}\nfor idx, entry in enumerate(all_json):\n    if idx % (len(all_json) \/\/ 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json)}')\n    content = FileReader(entry)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['abstract'].append(content.abstract)\n    dict_['body_text'].append(content.body_text)\n    dict_['methods'].append(content.methods)\n    dict_['results'].append(content.results)","992624d7":"papers = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text', 'methods', 'results'])\npapers.head()","22556e42":"papers.isnull().sum()","cfc4fbaf":"papers[(papers.results.str.len() != 0) | (papers.methods.str.len() != 0)].shape","45dda97a":"df = pd.merge(meta_df, papers, left_on='sha', right_on='paper_id', how='left').drop('sha', axis=1)","f780bd2f":"df.shape","5b9fdf57":"df.body_text.notnull().sum()","621129c5":"papers.paper_id.nunique()","d0150df8":"# set(papers.paper_id.values).difference(set(meta_df.sha.values))\n\n# len(set(papers.paper_id.values).difference(set(meta_df.sha.values)))\n\n# len(set(papers.paper_id.values).intersection(set(meta_df.sha.values)))","4dbf8417":"df.head()","a9019fa2":"df.shape","796d7676":"df.columns","90b2b541":"# Methods\nmethods = ['methods','method','statistical methods','materials','materials and methods',\n    'data collection','the study','study design','experimental design','objective',\n    'objectives','procedures','data collection and analysis', 'methodology',\n    'material and methods','the model','experimental procedures','main text']","9b755c13":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.body_text = []\n            self.methods = []\n            self.results = []\n\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            \n            # Methods\n            for entry in content['body_text']:\n                section_title = ''.join(x.lower() for x in entry['section'] if x.isalpha()) #remove numbers and spaces\n                if any(m in section_title for m in [''.join(x.lower() for x in m if x.isalpha()) for m in methods]) : \n                    self.methods.append(entry['text'])\n            # Results\n            results_synonyms = ['result']\n            for entry in content['body_text']:\n                section_title = ''.join(x.lower() for x in entry['section'] if x.isalpha())\n                if any(r in section_title for r in results_synonyms) :\n                    self.results.append(entry['text'])\n                    \n            self.body_text = '\\n'.join(self.body_text)\n            self.methods = '\\n'.join(self.methods)\n            self.results = '\\n'.join(self.results)\n\n    def __repr__(self):\n        return f'{self.paper_id}: {self.body_text[:200]}...'\nfirst_row = FileReader(all_json_pmc[0])\nprint(first_row)","e51b44ff":"dict_ = {'paper_id': [], 'body_text': [], 'methods': [], 'results': []}\nfor idx, entry in enumerate(all_json_pmc):\n    if idx % (len(all_json_pmc) \/\/ 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json_pmc)}')\n    content = FileReader(entry)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['body_text'].append(content.body_text)\n    dict_['methods'].append(content.methods)\n    dict_['results'].append(content.results)","a1f1f42e":"pmc_text = pd.DataFrame(dict_, columns=['paper_id', 'body_text', 'methods', 'results'])\npmc_text.head()","55881e1b":"pmc_text.shape","3c3aecbe":"pmc_text[pmc_text.body_text == '']","e01ca8e1":"pmc_text = pmc_text[pmc_text.body_text != '']","76f03046":"pmc_text.shape","f54d141d":"df = pd.merge(df, pmc_text, left_on='pmcid', right_on='paper_id', how='left').drop('paper_id_y', axis=1)","9a3dc491":"df.head(3)","10833401":"df.columns","eae4b12a":"df.drop(columns=['pmcid', 'pubmed_id', 'license', 'arxiv_id', 'mag_id', 'who_covidence_id',\n                'pdf_json_files', 'pmc_json_files', 's2_id'], inplace=True)","c099765f":"df.head(2)","ff08daad":"df[df.abstract_x != df.abstract_y].dropna().shape","1029ab84":"df[df.abstract_x != df.abstract_y][['abstract_x', 'abstract_y', 'url']].head(10)","619b4c12":"df[df.abstract_x != df.abstract_y][['abstract_x', 'abstract_y', 'url']].url.iloc[4]","8339e847":"df[(df.abstract_x != df.abstract_y) & (df.abstract_x.isnull()) & ((df.abstract_y != '') & (df.abstract_y.notnull())) & (~df.url.isnull())][\n    ['abstract_x', 'abstract_y', 'url', 'body_text_x', 'body_text_y']].head(5)","985a628c":"df[(df.abstract_x != df.abstract_y) & (df.abstract_x.isnull()) & ((df.abstract_y != '') & (df.abstract_y.notnull())) & (~df.url.isnull())][\n    ['abstract_x', 'abstract_y', 'url', 'body_text_x', 'body_text_y']].iloc[2].url","8fc40e37":"df.shape","59bb46fb":"df.abstract_x.isnull().sum(), (df.abstract_x =='').sum() # missing abstracts in json files","d46357ff":"df.abstract_y.isnull().sum(), (df.abstract_y=='').sum() # missing abstracts in metadata","b98c2851":"df.loc[df.abstract_x.isnull() & (df.abstract_y != '') & (df.abstract_y.notnull()), 'abstract_x'].shape","3105a940":"df.loc[df.abstract_x.isnull() & (df.abstract_y != '') & (df.abstract_y.notnull()), 'abstract_x'] = df[df.abstract_x.isnull() & (df.abstract_y != '') & (df.abstract_y.notnull())].abstract_y","f64fdb2a":"df.abstract_x.isnull().sum()","bd053ae9":"(df.abstract_x.isnull() & ((df.abstract_y != '') | (df.abstract_y.notnull()))).sum()","ec8e543f":"df.rename(columns = {'abstract_x': 'abstract', 'paper_id_x': 'paper_id'}, inplace=True)\ndf.drop('abstract_y', axis=1, inplace=True)","fde89207":"df.columns","d1b7942e":"df.shape","4932bd2c":"df.shape","ebc8de12":"(df.body_text_x != df.body_text_y).sum()","5212d4b3":"df[(df.body_text_x != df.body_text_y) & df.body_text_y.notnull()][['body_text_x', 'body_text_y']].head(10).iloc[2].values[0][:500]","b93a56d9":"df[(df.body_text_x != df.body_text_y) & df.body_text_y.notnull()][['body_text_x', 'body_text_y']].head(10).iloc[2].values[1][:500]","f648f6df":"df[df.body_text_x != df.body_text_y].head()","151c04bb":"df.iloc[3485].body_text_x[:250]","aa30305a":"df.iloc[3485].body_text_y[:250]","df72b319":"df.iloc[3485].url","05572ff4":"df.iloc[3488].body_text_x[:500]","1f21d741":"df.iloc[3488].body_text_y[:500]","211822a7":"df.iloc[3488].url","21374645":"df.body_text_x.isnull().sum(), df.body_text_y.isnull().sum()","ce3b4550":"df.body_text_x.notnull().sum(), df.body_text_y.notnull().sum()","444552e7":"(df.body_text_x == '').sum(), (df.body_text_y == '').sum()","062c0729":"df.loc[df.body_text_y.notnull(), 'body_text_x'] = df.loc[df.body_text_y.notnull(), 'body_text_y']","67b95caf":"df.body_text_x.notnull().sum()","9ddab87b":"df.rename(columns = {'body_text_x': 'body_text'}, inplace=True)\ndf.drop('body_text_y', axis=1, inplace=True)","c0d78b4a":"df.columns","15160f98":"df[['methods_x', 'methods_y', 'url']][df.methods_y.notnull()].methods_y.iloc[0]","9a896bf6":"df[['methods_x', 'methods_y', 'url']][df.methods_y.notnull()].url.iloc[0]","1db65adc":"(df.methods_x == '').sum(), df.methods_x.isnull().sum()","27216b1b":"(df.methods_y == '').sum(), df.methods_y.isnull().sum()","ad42ea4a":"# use methods_y (from pmc) when it's available\nmask = (df.methods_y.notnull()) & (df.methods_y != '')\ndf.loc[mask, 'methods_x'] = df.loc[mask, 'methods_y']\n\n# same for results\nmask = (df.results_y.notnull()) & (df.results_y != '')\ndf.loc[mask, 'results_x'] = df.loc[mask, 'results_y']","34a62b10":"((df.methods_x != '') & (df.methods_x.notnull())).sum()","54f957d5":"df.rename(columns = {'methods_x': 'methods', 'results_x': 'results'}, inplace=True)\ndf.drop(columns=['methods_y', 'results_y'], inplace=True)","4a80107c":"df.rename(columns = {'source_x': 'source'}, inplace=True)","8bd55c55":"df.columns","2d6236fa":"df.head(3)","09f68847":"len(df.cord_uid), df.cord_uid.nunique()","8f60c947":"df.duplicated('cord_uid').sum()","de70e50f":"df = df.loc[df[['title', 'abstract','body_text', 'url']].notnull().sum(axis=1).groupby(df.cord_uid).idxmax()]","02f83d41":"df.head()","c61772b5":"df.duplicated('cord_uid').sum()","45e1c29f":"len(df.paper_id.dropna())","7e03252b":"df.paper_id.nunique()","6b1ffd63":"df.dropna(subset=['paper_id'])[df.dropna(subset=['paper_id']).duplicated('paper_id', keep=False)][['cord_uid', 'paper_id', 'body_text']].sort_values('paper_id')","0fe75984":"df.dropna(subset=['paper_id'])[df.dropna(subset=['paper_id']).duplicated('paper_id', keep=False)].shape","94dfd66d":"df[(~df.duplicated(subset=['paper_id'])) | (df['paper_id'].isnull())].shape","cb7714c8":"df = df[(~df.duplicated(subset=['paper_id'])) | (df['paper_id'].isnull())]","4f935e55":"df.paper_id.value_counts().max()","da0ee79a":"df.paper_id.nunique()","90a97fc7":"df.isnull().sum()","cf6fc78e":"df.reset_index(drop=True, inplace=True)","07830cd5":"# some new columns for convenience\ndf['publish_year'] = df.publish_time.str[:4].fillna(-1).astype(int) # 360 times None\ndf['doi_url'] = 'http:\/\/dx.doi.org\/' + df.doi ","514518bb":"df.url.isnull().sum()","90672855":"df.loc[df.url.isnull(), 'url'] = df.loc[df.url.isnull(), 'doi_url']","7cb4c5ca":"df.url[df.url.str.contains(';')==True].iloc[4500]","ac471869":"df.url = df.url.apply(lambda x: x.split(';') if pd.notnull(x) else x)","ea541bdd":"df.url.iloc[78]","ee29294a":"def filter_urls(url_list):\n    '''Returns the first url that does not contain 'api' '''\n    if np.array(pd.notnull(url_list)).any():\n        temp = [a for a in url_list if 'api' not in a] # only keep urls without 'api'\n        if len(temp)>0:\n            return temp[0].strip() # pick the first one and strip whitespace\n        else:\n            return url_list[0].strip() # if there are no urls without 'api'\n    else:\n        return url_list # if nan","8ee474eb":"filter_urls(df.url.iloc[78])","851f3ac5":"#df.url = df.url.apply(lambda x: [a for a in x if 'api' not in a][0].strip() if np.array(pd.notnull(x)).any() else x)","a4518803":"df.url = df.url.apply(filter_urls)","ea6e0d93":"all_texts = df.title.fillna('') + ' ' + df.abstract.fillna('') + ' ' + df.body_text.fillna('').str[:20000]","62da4ac4":"df['is_covid19'] = all_texts.str.contains('COVID-19|covid|sar cov 2|SARS-CoV-2|2019-nCov|2019 ncov|SARS Coronavirus 2|2019 Novel Coronavirus|coronavirus 2019| Wuhan coronavirus|wuhan pneumonia|wuhan virus', case=False)","7481a82c":"df.is_covid19.sum()","d0634062":"df.head()","88447d20":"from IPython.utils import io\n\nwith io.capture_output() as captured:\n    !pip install scispacy\n    !pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_lg-0.2.4.tar.gz\n    !pip install spacy-langdetect\n    !pip install spac scispacy spacy_langdetect https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.3\/en_core_sci_lg-0.2.3.tar.gz","a0e6c1ab":"import scispacy\nimport spacy\nimport en_core_sci_lg\nfrom spacy_langdetect import LanguageDetector","5bf43853":"# medium model\nnlp = en_core_sci_lg.load(disable=[\"tagger\", \"ner\"])\nnlp.max_length = 6000000\nnlp.add_pipe(LanguageDetector(), name='language_detector', last=True)","f6585906":"doc = nlp('This is some English text. Das ist ein Haus. This is a house.')\ndoc._.language","d0033f8f":"for s in doc.sents:\n    print(s._.language)","e7ea8c6f":"doc = nlp(df[df.paper_id == '1a8a4dbbaa94ced4ef6af69ec7a09d3fa4c0eece'].body_text.iloc[0])","cd33e425":"doc[:500]","c526bdbe":"doc_engl = ''\nfor s in doc.sents:\n    if (s._.language['language'] == 'en'):\n        doc_engl += s.text ","50c932e5":"doc_engl[:2000]","cdd809c4":"all_texts = df.title.fillna('') + ' ' + df.abstract.fillna('') + ' ' + df.body_text.fillna('').str[:4000]","346fba38":"df['text_language'] = all_texts.apply(lambda x: nlp(str(x[:4000]))._.language['language'])\n\ndf.text_language.value_counts()","fce51a21":"df.loc[df[df.text_language != 'en'].index].shape","aa6137e6":"df = df.drop(df[df.text_language != 'en'].index)","b47b3946":"# Check language of all abstracts\n\n# df['abstract_lang'] = df.abstract.apply(lambda x: nlp(str(x))._.language['language'])\n\n#  df[df.abstract.isnull()]","9f1c801c":"# Number of non-english abstracts\n\n# df[(df.abstract_lang != 'en') & (df.abstract.notnull())].abstract_lang.value_counts()\n\n# Keep all english abstracts and those without abstract\n\n# df = df[(df.abstract_lang == 'en') | (df.abstract.isnull())]\n\n# df.shape\n\n# df.paper_id.nunique()\n\n# Analyze title\/text body of the papers without abstract\n\n# temp = df[df.abstract.isnull()].copy()\n\n# def remove_non_english_sentences(doc):\n#     doc = nlp(doc)\n#     doc_engl = ''\n#     for s in doc.sents:\n#         if (s._.language['language'] == 'en'):\n#             doc_engl += s.text \n#     return doc_engl\n\n# remove_non_english_sentences(df[df.paper_id == '1a8a4dbbaa94ced4ef6af69ec7a09d3fa4c0eece'].body_text.iloc[0])\n\n# temp['text_length'] = temp.body_text.apply(lambda x: len(x))\n\n# temp['english_text'] = temp.body_text.apply(remove_non_english_sentences)\n\n# temp['english_length'] = temp.english_text.apply(lambda x: len(x))\n\n# temp.to_csv('df_english.csv', index=False)\n\n# (temp.english_length\/temp.text_length).hist()\n\n# ((temp.english_length\/temp.text_length)<0.8).sum()\n\n# temp[((temp.english_length\/temp.text_length)<0.8)].head()\n\n# temp[temp.paper_id == '7925057cfe0cb75ae6079879cb2d22d23e42dfa5'].body_text.values[0][:500]\n\n# temp[temp.paper_id == '617197cc751a9208cb0af1b4e31baeddc8d2e985'].body_text.values[0]\n\n# temp[temp.paper_id == 'ca51b53fa512085e1aa166d5308602ff1666a90c'].body_text.values[0][:500]\n\n# df = df.drop(temp[((temp.english_length\/temp.text_length)<0.8)].index)","1618bd08":"# temp['title_lang'] = df.title.apply(lambda x: nlp(str(x))._.language['language'])\n\n# temp.title_lang.value_counts()\n\n# Too many false-positves. \n\n# temp[temp.paper_id == '6f6b7b1efffae7f3765f29fe801ab63dd35110bb'].body_text.values[0]\n\n# temp[temp.title_lang == 'de']\n\n# We check the beginning of each text body instead.\n\n# temp['text_lang'] = df.body_text.apply(lambda x: nlp(str(x[:2000]))._.language['language'])\n\n# temp.text_lang.value_counts()\n\n# Number of non-english texts to drop.\n\n# df.loc[temp[temp.text_lang != 'en'].index].shape\n\n# df = df.drop(temp[temp.text_lang != 'en'].index)","901353ff":"# filter_dict = {\n#     \"discussion\": [\"conclusions\",\"conclusion\",'| discussion', \"discussion\",  'concluding remarks',\n#                    'discussion and conclusions','conclusion:', 'discussion and conclusion',\n#                    'conclusions:', 'outcomes', 'conclusions and perspectives', \n#                    'conclusions and future perspectives', 'conclusions and future directions'],\n#     \"results\": ['executive summary', 'result', 'summary','results','results and discussion','results:',\n#                 'comment',\"findings\"],\n#     \"introduction\": ['introduction', 'background', 'i. introduction','supporting information','| introduction'],\n#     \"methods\": ['methods','method','statistical methods','materials','materials and methods',\n#                 'data collection','the study','study design','experimental design','objective',\n#                 'objectives','procedures','data collection and analysis', 'methodology',\n#                 'material and methods','the model','experimental procedures','main text',],\n#     \"statistics\": ['data analysis','statistical analysis', 'analysis','statistical analyses', \n#                    'statistics','data','measures'],\n#     \"clinical\": ['diagnosis', 'diagnostic features', \"differential diagnoses\", 'classical signs','prognosis', 'clinical signs', 'pathogenesis',\n#                  'etiology','differential diagnosis','clinical features', 'case report', 'clinical findings',\n#                  'clinical presentation'],\n#     'treatment': ['treatment', 'interventions'],\n#     \"prevention\": ['epidemiology','risk factors'],\n#     \"subjects\": ['demographics','samples','subjects', 'study population','control','patients', \n#                'participants','patient characteristics'],\n#     \"animals\": ['animals','animal models'],\n#     \"abstract\": [\"abstract\", 'a b s t r a c t','author summary'], \n#     \"review\": ['review','literature review','keywords']}","99d86ca1":"study_designs = {'RCT': ['RCT', 'randomized controlled trial', 'randomised controlled trial', 'randomized control trial', 'randomised control trial',\n                         'randomized clinical trial','randomised clinical trial'], \n                'time series analysis': ['time series analysis', 'time series', 'survival analysis'],\n                'retrospective cohort': ['retrospective cohort'],\n                'cross-sectional case-control': ['cross-sectional case-control', 'cross sectional case control', 'cross-sectional case control'],\n                'prospective case-control': ['prospective case-control', 'prospective case control'],\n                'matched case-control': ['matched case-control', 'matched case control'],\n                'medical records review': ['medical records review'],\n                'prevalence survey': ['prevalence survey'],\n                'syndromic surveillance': ['syndromic surveillance'],\n                'systematic review': ['systematic review'],\n                'meta-analysis': ['meta-analysis', 'meta analysis', 'meta-syntheses'],\n                'interventional study': ['interventional study'],\n                'association': ['association', 'associated with'],\n                 'p-value': ['p-value', 'p value'],\n                 'pseudo-randomized controlled trial': ['pseudo-randomized controlled trial', 'pseudo-randomised controlled trial']\n                }","e99ce747":"generic_keywords = ['estimation',\n 'prevalence survey',\n 'response rate',\n 'incidence',\n 'psychometric evaluation of instrument',\n 'median time to event',\n 'pooled OR',\n 'd-pooled',\n 'randomized controlled trial',\n 'non-randomized',\n 'allocation method',\n 'Cochrane review',\n 'Cox proportional hazards',\n 'gamma',\n 'Weibull',\n 'pseudo-randomised',\n 'chart review',\n 'log odds',\n 'surveillance',\n 'time-to-event analysis',\n 'pooled adjusted odds ratio',\n 'pooled relative risk',\n 'data abstraction forms',\n 'frequency',\n 'etiology logistic regression',\n 'exclusion criteria',\n 'eligibility criteria',\n 'right-censored',\n 'pooled odds ratio',\n 'non-comparative study',\n 'medical records review',\n 'CONSORT',\n 'number of controls per case',\n 'quasi-randomised',\n 'risk of bias',\n 'publication bias',\n 'syndromic surveillance',\n 'truncated',\n 'longitudinal',\n 'matching criteria',\n 'double-blind',\n \"Cohen's d\",\n 'registry data',\n 'Adjusted Odds Ratio',\n 'questionnaire development',\n 'Kaplan-Meier',\n 'heterogeneity',\n 'recruitment',\n 'randomization method',\n 'censoring',\n 'meta-analysis',\n 'non-randomised',\n '\u03b2',\n 'electronic medical records',\n 'eligibility',\n 'cross-sectional survey',\n 'PRISMA',\n 'prevalence',\n 'inclusion criteria',\n 'control arm',\n 'protocol',\n 'pooled risk ratio',\n 'non-response bias',\n 'baseline',\n 'retrospective chart review',\n 'survival analysis',\n 'logistic regression',\n 'blind',\n 'exposure status',\n 'randomized',\n 'associated with',\n 'lognormal',\n 'systematic review',\n 'RCT',\n 'randomised',\n 'survey instrument',\n 'interrater reliability',\n 'randomisation',\n 'pooled RR',\n 'hazard ratio',\n 'AOR',\n 'potential confounders',\n 'treatment effect',\n 'randomized clinical trial',\n 'data collection instrument',\n 'pooled AOR',\n 'association',\n 'power',\n \"cohen's kappa\",\n 'pseudo-randomized',\n 'treatment arm',\n 'search string',\n 'quasi-randomized',\n 'cohort',\n 'risk factors',\n 'difference between means',\n 'registry',\n 'inter-rater reliability',\n 'Odds Ratio',\n 'placebo',\n 'databases searched',\n 'risk factor analysis',\n 'difference in means',\n 'random sample',\n 'etiology',\n 'i2']","e36bf551":"for a in generic_keywords:\n    if a not in [x for v in study_designs.values() for x in v]:\n        study_designs[a] = [a]","b20865e1":"len([x for v in study_designs.values() for x in v])","1f7ae591":"# def tag_study_design(study_designs):\n#     df['study_design'] = [set() for _ in range(len(df))]\n#     for tag in study_designs.keys():\n#         for synonym in study_designs[tag]:\n#             df[df.abstract.str.contains(synonym, case=False, na=False)].study_design.apply(lambda x: x.add(tag))","7c155a5e":"def tag_study_design(study_designs):\n    df['study_abstract'] = [set() for _ in range(len(df))]\n    df['study_methods'] = [set() for _ in range(len(df))]\n    df['study_results'] = [set() for _ in range(len(df))]\n\n    for tag in study_designs.keys():\n        for synonym in study_designs[tag]:\n            df[df.abstract.str.contains(synonym, case=False, na=False) | df.title.str.contains(synonym, case=False, na=False)].study_abstract.apply(lambda x: x.add(tag))\n            df[df.methods.str.contains(synonym, case=False, na=False)].study_methods.apply(lambda x: x.add(tag))\n            df[df.results.str.contains(synonym, case=False, na=False)].study_results.apply(lambda x: x.add(tag))\n    \n    df['study_design'] = df.apply(lambda x: list(x.study_abstract.union(x.study_methods).union(x.study_results)), axis=1)\n    df.study_abstract = df.study_abstract.apply(lambda x: list(x))\n    df.study_methods = df.study_abstract.apply(lambda x: list(x))\n    df.study_results = df.study_results.apply(lambda x: list(x))","7971b3c0":"tag_study_design(study_designs)","54ca4ae2":"df[df.study_design.str.len() != 0].tail(20).study_design","f23ec9ff":"len(df.study_abstract[df.study_abstract.str.len() != 0])","75d1d80b":"len(df.study_methods[df.study_methods.str.len() != 0])","4b80a5da":"len(df.study_results[df.study_results.str.len() != 0])","7d06110f":"len(df.study_design[df.study_design.str.len() != 0])","eeb46bcc":"len(df.study_design[(df.study_design.str.len() != 0) & df.is_covid19])","a2e80eef":"df.drop(columns=['text_language', 'study_abstract', 'study_methods', 'study_results'], inplace=True)","45c02406":"df.head()","8ba0b888":"df.shape","79e6fe34":"df.columns","da63277f":"df.to_csv('cord19_df.csv', index=False)","245431e0":"We fill some missing values in 'url' using the doi field.","0f680829":"Check language of each text (only use the first 4000 characters).","e6d56423":"## Number of non-english texts to drop.","81dddbed":"## pmc_json","f38e4d66":"Where available we use the text from the pmc file (body_text_y), trusting the statement that it is of higher quality.","2b187078":"This only contains the full text - no abstracts!","cb21fd56":"We keep those with the least nans (in the columns 'title', 'abstract','body_text' and 'url'):","8faa6984":"## pdf_json","4fba8306":"# Load Packages","aef05dfb":"# Quick comparison of both texts","aee6e54b":"### Different Abstract in Metadata and JSON files","afb2fe79":"Checking some of the files online, it seems that where the abstract is missing in the metadata, the abstract in the JSON file is simply the beginning of the text.","cb600bc5":"Keywords from  [https:\/\/docs.google.com\/spreadsheets\/d\/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E\/edit#gid=1217643351](https:\/\/docs.google.com\/spreadsheets\/d\/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E\/edit#gid=1217643351)","4bf17f6b":"# Export as .csv","0fdaf845":"Some exploration and preprocessing to create one dataframe and export it as .csv.","bdfd635c":"the remaining missing values are also empty in the json files","9373db91":"# Extract Study Design\/ Methodological Keywords","3a88bfd5":"Some rows contain multiple sha, we only keep the first one.","6bf94062":"Since the abstracts from the metadata seem more reliable we generally use these, but fill the missing values with the abstract from the extracted values from the JSON file.","a2b6d998":"To read the JSON files we follow [COVID EDA: Initial Exploration Tool](https:\/\/www.kaggle.com\/ivanegapratama\/covid-eda-initial-exploration-tool).","437db935":"Some 'url' fields contain more than one url, we pick the first non-API link. ","cce5c5e0":"We still have to compare the text body from pdf and pmc files.","d51f7a57":"body_text_x is from pdf, body_text_y from pmc","abb3cb05":"# Duplicates","6814ce79":"Now the paper_id is unique.","470b4f41":"# Language Detection to remove non-english articles and abstracts","adf95bc6":"# Load all json files","acc81561":"# Some new columns for convenience","1f32e3dc":"# Load and Prepare Data","4dc601b9":"# Exploration\/Cleaning","f54e74eb":"Some paper ids are duplicated","21f983dc":"Check if body_text contains empty strings","6c9a2545":"abstract_x from metadata, abstract_y from json"}}