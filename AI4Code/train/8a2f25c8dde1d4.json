{"cell_type":{"f178da77":"code","3efbc66d":"code","c2c22aea":"code","5bf75d99":"code","09854e0e":"code","fd31ee0b":"code","1c1f49f8":"code","b4f5d974":"code","83dc6e88":"code","43baec9d":"code","081798b9":"markdown","19d58464":"markdown","1cd3087d":"markdown","3eedfeb4":"markdown","f274d025":"markdown","07bd6ff5":"markdown","1da3bb8c":"markdown","bd60bbc3":"markdown","c9f6ea60":"markdown"},"source":{"f178da77":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn import gaussian_process\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nfrom sklearn.feature_selection import RFECV\n\n","3efbc66d":"df = pd.read_csv('..\/input\/trip-advisor.csv')\ndata1=df.copy(deep=True)\nX = df.drop(['Score'],axis=1)\ny = df['Score'].values\n\n# check the sum of num values (if any)\ndf.isnull().sum()\n","c2c22aea":"# Features need to be encoded\nencode_list=['User country code','Period of stay code','Traveler type code','Swimming Pool code','Exercise Room code','Basketball Court code',\n             'Yoga Classes code','Club code','Free Wifi code','Hotel name code','Hotel stars code','Nr. rooms code',\n             'User continent code','Review month code','Review weekday code']\n\n#Features not need to be encoded\nnot_encode_list=['Nr. reviews','Nr. hotel reviews','Helpful votes','Member years']","5bf75d99":"# Label Encoding of the Categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\ndata1['User country code'] = label.fit_transform(data1['User country'])\ndata1['Period of stay code'] = label.fit_transform(data1['Period of stay'])\ndata1['Traveler type code'] = label.fit_transform(data1['Traveler type'])\ndata1['Swimming Pool code'] = label.fit_transform(data1['Swimming Pool'])\ndata1['Exercise Room code'] = label.fit_transform(data1['Exercise Room'])\ndata1['Basketball Court code'] = label.fit_transform(data1['Basketball Court'])\ndata1['Yoga Classes code'] = label.fit_transform(data1['Yoga Classes'])\ndata1['Club code'] = label.fit_transform(data1['Club'])\ndata1['Free Wifi code'] = label.fit_transform(data1['Free Wifi'])\ndata1['Hotel name code'] = label.fit_transform(data1['Hotel name'])\ndata1['Hotel stars code'] = label.fit_transform(data1['Hotel stars'])\ndata1['Nr. rooms code'] = label.fit_transform(data1['Nr. rooms'])\ndata1['User continent code'] = label.fit_transform(data1['User continent'])\ndata1['Review month code'] = label.fit_transform(data1['Review month'])\ndata1['Review weekday code'] = label.fit_transform(data1['Review weekday'])\n\n","09854e0e":"X=pd.concat([data1[not_encode_list],data1[encode_list]],axis=1)\n\n#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nnames=X.columns\nsc_X = StandardScaler()\nX = sc_X.fit_transform(X)\nscaled_X = pd.DataFrame(X, columns=names)\nscaled_X.head()","fd31ee0b":"# Correlation Heatmap\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(scaled_X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","1c1f49f8":"#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA=[\n    GradientBoostingClassifier(),\n    RandomForestClassifier(),\n    \n    LogisticRegressionCV(),\n    KNeighborsClassifier(),\n        \n    DecisionTreeClassifier(),    \n    XGBClassifier()\n    \n]\n\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(scaled_X.iloc[:,0:20], y, test_size = 0.2, random_state = 0)\n\nMLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Test Accuracy']\nMLA_compare1=pd.DataFrame(columns=MLA_columns)\n\nMLA_predict=y\n\n\nfor count,alg in enumerate(MLA):\n    classifier = alg\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test) \n    MLA_name=alg.__class__.__name__\n    MLA_compare1.loc[count, 'MLA Name']=MLA_name\n    MLA_compare1.loc[count, 'MLA Parameters']=str(alg.get_params())\n    MLA_compare1.loc[count, 'MLA Test Accuracy']= accuracy_score(y_test, y_pred)\n    \nMLA_compare1.sort_values(by=['MLA Test Accuracy'], ascending=False, inplace=True)\n\nMLA_compare1","b4f5d974":"from sklearn.feature_selection import RFECV\nfrom sklearn.linear_model import LogisticRegressionCV\n\nMLA_columns = ['MLA Name','MLA Features', 'Number of MLA Features']\nMLA_compare2=pd.DataFrame(columns=MLA_columns)\n\nMLA=[\n    GradientBoostingClassifier(),\n    RandomForestClassifier(),\n    LogisticRegressionCV(),   \n    XGBClassifier()\n]\n\nfig = plt.figure(figsize=(12,7))\nplt.xticks([])\nplt.ylabel(\"Cross validation score of number of selected features\")\n    \nfor count, alg in enumerate(MLA):\n    MLA_name = alg.__class__.__name__\n    MLA_compare2.loc[count, 'MLA Name'] = MLA_name\n    clf_rf_4 =  alg\n    rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n    rfecv = rfecv.fit(X_train, y_train)\n    x=pd.DataFrame(X_train.columns[rfecv.support_],columns=['Models'])\n    MLA_compare2.loc[count,'MLA Features'] = list(x['Models'])\n    MLA_compare2.loc[count,'Number of MLA Features'] = rfecv.n_features_\n    \n    \n    ax = fig.add_subplot(2, 2, count+1)\n    plt.xlabel(MLA_name)\n\n    major_ticks = np.arange(1, 20, 1)\n    minor_ticks = np.arange(0, 20, 1)\n\n    ax.set_xticks(major_ticks)\n    ax.set_xticks(minor_ticks, minor=True)\n    ax.set_yticks(major_ticks)\n    ax.set_yticks(minor_ticks, minor=True)\n    \n    ax.grid(which='both')\n    ax.grid(which='minor', alpha=0.2)\n    ax.grid(which='major', alpha=0.5)\n    #ax.set_axisbelow(True)\n\n    ax.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.tight_layout()\nplt.show()\n    \n\nMLA_compare2.sort_values(by=['Number of MLA Features'],inplace=True)\nMLA_compare2","83dc6e88":"from sklearn.cross_validation import train_test_split\n\nMLA=[\n    GradientBoostingClassifier(),\n    RandomForestClassifier(),\n    LogisticRegressionCV(),   \n    XGBClassifier()\n]\nMLA_compare3 = pd.DataFrame(columns=['MLA Name','Accuracy'])\nfor count,alg in enumerate(MLA):\n    features = MLA_compare2.loc[count, 'MLA Features']\n    \n    X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(scaled_X.loc[:,features], y, test_size = 0.2, random_state = 0)\n    \n    MLA_name = alg.__class__.__name__\n    MLA_compare3.loc[count, 'MLA Name'] = MLA_name \n    classifier = alg\n    classifier = classifier.fit(X_train_final,y_train_final)\n    ac = accuracy_score(y_test_final,classifier.predict(X_test_final))\n    MLA_compare3.loc[count, 'Accuracy'] = ac\n    \nMLA_compare3.sort_values(by=['Accuracy'],inplace=True, ascending=False)\nMLA_compare3.index = MLA_compare3.index.sort_values()\n\nMLA_compare3\n","43baec9d":"from sklearn import linear_model\nclf_rf = LogisticRegressionCV()\n\nfor c in range(MLA_compare2.shape[0]):\n    if MLA_compare3.loc[0, 'MLA Name'] == MLA_compare2.loc[c,'MLA Name']:\n        feat = MLA_compare2.loc[c, 'MLA Features']\n        print(len(feat))\nX_train_best, X_test_best, y_train_best, y_test_best = train_test_split(scaled_X.loc[:,feat], y, test_size = 0.2, random_state = 0)\nclr_rf = clf_rf.fit(X_train_best,y_train_best)\n\nac = accuracy_score(y_test_best,clf_rf.predict(X_test_best))\nprint('Accuracy is: ',ac)\ncm = confusion_matrix(y_test,clf_rf.predict(X_test_best))\nsns.heatmap(cm,annot=True,fmt=\"d\")","081798b9":"## Model Data","19d58464":"## Conclusion\nFrom the above step we came to a conclusion that **LogisticRegressionCV** is the model with the **Accuracy** of **47.52%**.\nThis model has the following 6 features which are most valuable :                                                                           \n**['Swimming Pool code', 'Exercise Room code', 'Yoga Classes code', 'Free Wifi code', 'Hotel stars code', 'Nr. rooms code']**","1cd3087d":"## Feature Selection\nWe have selection the best 4 models from the above \"Model Selection\". Below we have to select the best features of those selected models.","3eedfeb4":"## Import Libraries\n","f274d025":"## Visualization\n","07bd6ff5":"In the above step we see that **Logistic RegressionCV** is the best model because it has highest **accuarcy**. Below we find the **confusion matrix** of it.","1da3bb8c":"Below we are going to find the **accuracy** of each selected model with their respective features which are selected in above step.","bd60bbc3":"## Feature Scaling\n","c9f6ea60":"## Meet and Greet Data\n"}}