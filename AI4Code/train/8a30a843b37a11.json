{"cell_type":{"60958f93":"code","462f74da":"code","e16162b1":"code","21859953":"code","e2728990":"code","35e806a0":"code","04d00f36":"code","ae796a18":"markdown","4b3873af":"markdown","de02ef48":"markdown","0abce472":"markdown","cc04701a":"markdown","50e25a71":"markdown"},"source":{"60958f93":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tensorflow as tf\nfrom tensorflow import keras\nimport string\n\n","462f74da":"#Only Selecting the Images and excluding the directories in the folder\n# images_names=fnmatch.filter(os.listdir('\/kaggle\/input\/captcha-version-2-images\/samples\/'),'*.*')\nfrom PIL import Image\n\ntext_file=open(r\"..\/input\/UsedSentences.txt\",\"r\")\n\ndetails=[]\noutputs=[]\nnames=[]\nfor line in text_file:\n    a=line.split('#')\n    outputs.append(a[1].strip('\\n'))\n    details.append(a[0])\n\nfor detail in details:\n    a=detail.split(' ')\n    names.append(a[0])\nX=[]\n\nfor name in names:\n    img=Image.open('..\/input\/CleanedImages\/Encoder_Clean_Renamed\/'+name+'.png','r')\n    img = img.resize((784,32), Image.ANTIALIAS)\n    img=np.asarray(img)\n    img=img[:,:,0]\n    X.append(img)\n\nX=np.asarray(X)\nplt.imshow(X[42])\nplt.title(outputs[42])\nprint(\"No of Images :\",X.shape[0])\n\nsymbols = \" \"+string.ascii_lowercase + string.ascii_uppercase+\"0123456789.,*&!@~():`^]\u00a2\u2018;|-\u00ab\"\nprint(\"Characters :\",symbols)\nprint(\"No of chars :\",len(symbols))\n\n# print(os.listdir('..\/input\/linesdata\/data\/sentences\/s01\/'))\n","e16162b1":"Y=np.zeros(shape=(len(outputs),98,len(symbols)))\nfor example_no,name in enumerate(outputs):\n    for letter_no,letter in enumerate(name):\n        try:\n            Y[example_no][letter_no][symbols.index(letter)]=1\n        except:\n            print(letter,end=\" \")\n\n\n","21859953":"X=np.reshape(X,(X.shape[0],X.shape[1],X.shape[2],1))\nprint(\"Shape of X is :\",X.shape)","e2728990":"# Neural Network Model \n# Try Removing Batch Normalisation and see how the performance decreases.\ndef OCRModel():\n    image=keras.layers.Input((32,784,1))\n    conv1=keras.layers.Conv2D(16,(3,3),activation='relu',padding='same')(image)\n    mp1=keras.layers.MaxPooling2D((2,2),padding='same')(conv1)\n    conv2=keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(mp1)\n    mp2=keras.layers.MaxPooling2D((2,2),padding='same')(conv2)\n    conv3=keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')(mp2)\n    mp3=keras.layers.MaxPooling2D((2,2),padding='same')(conv3)\n    conv4=keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(mp3)\n    mp4=keras.layers.MaxPooling2D((2,1),padding='same')(conv4)\n    conv5=keras.layers.Conv2D(256,(3,3),activation='relu',padding='same')(mp4)\n    mp5=keras.layers.MaxPooling2D((2,1),padding='same')(conv5)\n    conv6=keras.layers.Conv2D(256,(3,3),activation='relu',padding='same')(mp5)\n    # mp6=keras.layers.MaxPooling2D((1,3),padding='same')(conv6)\n    bn=keras.layers.BatchNormalization()(conv6)\n    sq=keras.backend.squeeze(bn,axis=1)\n\n    rn1=keras.layers.Bidirectional(keras.layers.LSTM(256,return_sequences=True))(sq)\n    rn2=keras.layers.Bidirectional(keras.layers.LSTM(256,return_sequences=True))(rn1)\n\n    exd=keras.backend.expand_dims(rn2,axis=2)\n    maping=keras.layers.Conv2D(len(symbols),(2,2),activation='relu',padding='same')(exd)\n    maping=keras.backend.squeeze(maping,axis=2)\n    maping = tf.keras.layers.Softmax()(maping)\n\n    # bn = keras.layers.BatchNormalization()(conv3)\n    model=keras.Model(image,maping)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    \n    return model\n","35e806a0":"from keras.utils.vis_utils import plot_model\nOCR=OCRModel()\nOCR.fit(X,Y,epochs=50)\n# plot_model(OCR, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)","04d00f36":"xx=OCR.predict(X)\nindex=466\nc=\"\"\nprint(len(xx[0]))\nfor i in range(len(xx[0])):\n    c=c+(symbols[np.argmax(xx[index][i])])\nprint(\"predicted:\",c.strip())\nprint(\"\\nOrignal:\",outputs[index])\nplt.imshow(X[index][:,:,0])","ae796a18":"Hello Guys My Name is Dhruv Aditya Mittal and I am a researcher in Data Analytics. In this notebook I will be developing a very simple Optical Character Reconition System using Deep Learning. The model provides descent accuracy on testing dataset. ","4b3873af":"Here UsedSentences.txt Contains the output of the text in the Image and the name of the Image. The name of the image is used to extract the image from the directory and add it to our dataset. Feel free to play with this piece of code and get more clearity of the dataset.","de02ef48":"Decoding the Output of the Model and Comparing it.....","0abce472":"Here I have created a One Hot Encoded Array. 98 is taken as the maximum number of Character in the Sentences. If the letter is present in the output then it is encoded to 1.","cc04701a":"If you like the Code feel free to fork the Notebook and don't forget to Upvote it. Cheers....","50e25a71":"Just Reshaping the Shape of X in order to pass it to the convolution."}}