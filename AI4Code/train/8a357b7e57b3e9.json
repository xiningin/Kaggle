{"cell_type":{"54c1e95c":"code","228daf28":"code","a9ca4d6c":"code","323b2400":"code","9f832452":"code","2e1637d2":"code","0b02c755":"code","aa9134e4":"code","5bd3e0a4":"code","69b44a88":"code","b9e1475f":"code","3de1e448":"code","c3a48607":"code","3f39b50e":"code","12752ce3":"code","f898bab0":"code","e0861080":"code","a95d92e9":"code","aa17ce41":"code","9047307f":"code","47b6644f":"code","fae2fa50":"code","30067600":"code","2f72bff9":"code","779a2dbe":"code","079ba0d1":"code","279d35aa":"code","832977ff":"code","186540c2":"code","1cbbf1a0":"code","570b93ba":"code","c6597978":"code","8a1814f2":"code","ae14e7ed":"code","7f1a08c7":"code","548e1cea":"code","84edb434":"code","32938eee":"code","1270ddd1":"code","74574708":"code","aefb2a96":"code","53539a14":"code","45554dab":"code","a0d4f663":"code","5e34e454":"code","fa4dbede":"code","f91117fd":"code","9a996e16":"markdown","63da971b":"markdown","fcbaa495":"markdown","151ab025":"markdown"},"source":{"54c1e95c":"# GPU\n!nvidia-smi","228daf28":"import os\nimport pandas as pd\n\nsample = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n\nif len(sample) == 2477:\n    sample.to_csv('submission.csv', index=False)\n    os._exit(00)","a9ca4d6c":"import sys\nsys.path.append('..\/input\/timm126')\nsys.path.append('..\/input\/timm126\/timm126')\nsys.path.append('..\/input\/timm413')\nsys.path.append('..\/input\/timm413\/timm413')\nfrom timm126 import timm as timm_126\nfrom timm413 import timm_new as timm_413\nprint(timm_126.__version__)\nprint(timm_413.__version__)","323b2400":"# offline gdcm\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","9f832452":"import os\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\n\ndef read_xray(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    im = Image.fromarray(array)\n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    return im","2e1637d2":"#public image_ids\npublic = pd.read_csv('..\/input\/covid-public-test\/sample_submission.csv')\npublic['type'] = public['id'].apply(lambda x: x[-5:])\npublic_image = public[public['type'] == 'image'].reset_index(drop=True)\npublic_image['image_id'] = public_image['id'].apply(lambda x: x[:-6])\npublic_image_ids = public_image['image_id'].to_list()","0b02c755":"image_id = []\ndim0 = []\ndim1 = []\nsz = 512\nsave_dir = f'\/kaggle\/tmp\/test\/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/test')):\n    for file in filenames:\n        if file[:-4] in public_image_ids:\n            continue\n        xray = read_xray(os.path.join(dirname, file))\n        im = resize(xray, size=sz)  \n        im.save(os.path.join(save_dir, file.replace('dcm', 'png')))\n        image_id.append(file.replace('.dcm', ''))\n        dim0.append(xray.shape[0])\n        dim1.append(xray.shape[1])","aa9134e4":"meta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1})\nmeta.head()","5bd3e0a4":"# test image root path\n# all images: root + image_id +.png\nroot = '\/kaggle\/tmp\/test'","69b44a88":"!pip install '\/kaggle\/input\/pycocotools\/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' --no-deps > \/dev\/null\n\nsys.path.append(\"\/kaggle\/input\/timm-efficientdet-pytorch-fixdiv\")\nsys.path.append(\"\/kaggle\/input\/omegaconf\")\nsys.path.append(\"\/kaggle\/input\/weightedboxesfusion\")\n\nfrom ensemble_boxes import *\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold\n\nimport math\nimport gc, os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nfrom glob import glob\nimport pydicom\nfrom tqdm import tqdm\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom skimage import exposure\nfrom bokeh.plotting import figure as bokeh_figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs\nfrom PIL import Image\nfrom sklearn import preprocessing\nfrom random import randint\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nimport torch.optim as optim\n\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchEval\nfrom effdet.efficientdet import HeadNet\n\nimport torchvision\nfrom torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(device)","b9e1475f":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed = 2020\nseed_everything(seed)\nNFOLDS = 5\n\n#ImageNet\nmean = np.array([[[0.485, 0.456, 0.406]]])\nstd = np.array([[[0.229, 0.224, 0.225]]])","3de1e448":"public = pd.read_csv('..\/input\/covid-public-test\/sample_submission.csv')\ntest = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n\n#submit\nif len(test) != 2477:\n    test = pd.concat([test, public]).reset_index(drop=True).drop_duplicates(keep=False).reset_index(drop=True)\n    \ntest['type'] = test['id'].apply(lambda x: x[-5:])\ntest_study = test[test['type'] == 'study'].reset_index(drop=True)\ntest_image = test[test['type'] == 'image'].reset_index(drop=True)\ntest_study['study_id'] = test_study['id'].apply(lambda x: x[:-6])\ntest_image['image_id'] = test_image['id'].apply(lambda x: x[:-6])\ntest_study = test_study.rename(columns={'PredictionString': 'PredictionString1'})\ntest_image = test_image.rename(columns={'PredictionString': 'PredictionString2'})\ntest_study_ = test_study.drop(['type', 'study_id'], axis=1)\ntmp = pd.DataFrame(columns=test_study.columns)\n\nfor i in tqdm(range(len(test_study))):\n    study_id = test_study.iloc[i, 3]\n    img_paths = glob(f'..\/input\/siim-covid19-detection\/test\/{study_id}\/*\/*')\n    if len(img_paths) == 1:\n        img_path = img_paths[0]\n        image_id = img_path.split('\/')[-1][:-4]\n        test_study.loc[i, 'image_id'] = image_id\n    else:\n        add_df = pd.concat([test_study.iloc[i:i+1]]*(len(img_paths)-1)).reset_index(drop=True)\n        for j in range(len(img_paths)):\n            if j == 0:\n                img_path = img_paths[j]\n                image_id = img_path.split('\/')[-1][:-4]\n                test_study.loc[i, 'image_id'] = image_id\n            else:\n                img_path = img_paths[j]\n                image_id = img_path.split('\/')[-1][:-4]\n                add_df.loc[j-1, 'image_id'] = image_id\n        tmp = tmp.append(add_df).reset_index(drop=True)","c3a48607":"test = pd.concat([test_study, tmp]).sort_values('id').reset_index(drop=True)\ntest = test.merge(meta, on='image_id').merge(test_image[['PredictionString2', 'image_id']], on='image_id')\ntest.head()","3f39b50e":"def get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=sz, width=sz, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)\n\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n\nclass COVIDDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        super().__init__()\n        self.df = df\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        image_id = self.df.iloc[index, 4]\n        image = cv2.imread(f'{root}\/{image_id}.png').astype(np.float32)\n        width = self.df.iloc[index, 6]\n        height = self.df.iloc[index, 5]\n        image \/= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        return image, image_id, width, height\n\n    def __len__(self):\n        return self.df.shape[0]","12752ce3":"def load_net(checkpoint_path, model_name):\n    config = get_efficientdet_config(model_name)\n    net = EfficientDet(config, pretrained_backbone=False)\n    config.num_classes = 1\n    config.image_size = 512\n    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n    checkpoint = torch.load(checkpoint_path)\n    net.load_state_dict(checkpoint['model_state_dict'])\n    del checkpoint\n    gc.collect()\n    net = DetBenchEval(net, config)\n    net.eval()\n    return net.cuda()\n\n\ndef make_predictions(images, score_threshold=0.001):\n    images = torch.stack(images).cuda().float()\n    predictions = []\n    with torch.no_grad():\n        det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n        for i in range(images.shape[0]):\n            boxes = det[i].detach().cpu().numpy()[:,:4]    \n            scores = det[i].detach().cpu().numpy()[:,4]\n            indexes = np.where(scores > score_threshold)[0]\n            boxes = boxes[indexes]\n            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n            predictions.append({\n                'boxes': boxes[indexes],\n                'scores': scores[indexes],\n            })\n    return [predictions]\n\n\ndef run_wbf(predictions, image_index, image_size=512, iou_thr=0.5, skip_box_thr=0.001, weights=None):\n    boxes = [(prediction[image_index]['boxes']\/(image_size-1)).tolist()  for prediction in predictions]\n    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n    boxes, scores, labels = non_maximum_weighted(boxes, scores, labels, iou_thr=iou_thr, skip_box_thr=skip_box_thr, weights=weights)\n    boxes = boxes*(image_size-1)\n    return boxes, scores, labels\n\n\ndef format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(f\"opacity {j[0]} {j[1][0]} {j[1][1]} {j[1][2]} {j[1][3]}\")\n    return \" \".join(pred_strings)","f898bab0":"dataset = COVIDDataset(\n    df=test,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)","e0861080":"# EFD3 inference\nefd3 = test.copy()\nprint('<<<<<<<<<<EFD3>>>>>>>>>>')\nfor i in range(NFOLDS):\n    print(f'=====FOLD {i}=====')\n    net = load_net(checkpoint_path=f'..\/input\/efd3ver001-weight\/fold{i}-best.bin', model_name='tf_efficientdet_d3')\n    results = []\n    for images, image_ids, widths, heights in tqdm(data_loader):\n        predictions = make_predictions(images)\n        for j, image in enumerate(images):\n            boxes, scores, labels = run_wbf(predictions, image_index=j)\n            boxes = boxes.astype(np.float32).clip(min=0, max=sz)\n            boxes[:, 0] = boxes[:, 0] \/ sz \n            boxes[:, 1] = boxes[:, 1] \/ sz\n            boxes[:, 2] = boxes[:, 2] \/ sz\n            boxes[:, 3] = boxes[:, 3] \/ sz\n            result = {'PredictionString': format_prediction_string(boxes, scores)}\n            results.append(result)\n    efd3[f'PredictionString_{i}'] = np.nan\n    for k in tqdm(range(len(efd3))):\n        efd3.loc[k, f'PredictionString_{i}'] = f\" {results[k]['PredictionString']}\"  \n    del net, results\n    gc.collect()\n    \nefd3['id'] = efd3['image_id'].apply(lambda x: x + '_image')\nefd3.head()","a95d92e9":"# EFD4 inference\nefd4 = test.copy()\nprint('<<<<<<<<<<EFD4>>>>>>>>>>')\nfor i in range(NFOLDS):\n    print(f'=====FOLD {i}=====')\n    net = load_net(checkpoint_path=f'..\/input\/efd4ver002-weight\/fold{i}-best.bin', model_name='tf_efficientdet_d4')\n    results = []\n    for images, image_ids, widths, heights in tqdm(data_loader):\n        predictions = make_predictions(images)\n        for j, image in enumerate(images):\n            boxes, scores, labels = run_wbf(predictions, image_index=j)\n            boxes = boxes.astype(np.float32).clip(min=0, max=sz)\n            boxes[:, 0] = boxes[:, 0] \/ sz \n            boxes[:, 1] = boxes[:, 1] \/ sz\n            boxes[:, 2] = boxes[:, 2] \/ sz\n            boxes[:, 3] = boxes[:, 3] \/ sz\n            result = {'PredictionString': format_prediction_string(boxes, scores)}\n            results.append(result)\n    efd4[f'PredictionString_{i}'] = np.nan\n    for k in tqdm(range(len(efd4))):\n        efd4.loc[k, f'PredictionString_{i}'] = f\" {results[k]['PredictionString']}\"  \n    del net, results\n    gc.collect()\n    \nefd4['id'] = efd4['image_id'].apply(lambda x: x + '_image')\nefd4.head()","aa17ce41":"# EFD5 inference\nefd5 = test.copy()\nprint('<<<<<<<<<<EFD5>>>>>>>>>>')\nfor i in range(NFOLDS):\n    print(f'=====FOLD {i}=====')\n    net = load_net(checkpoint_path=f'..\/input\/efd5ver005-weight\/fold{i}-best.bin', model_name='tf_efficientdet_d5')\n    results = []\n    for images, image_ids, widths, heights in tqdm(data_loader):\n        predictions = make_predictions(images)\n        for j, image in enumerate(images):\n            boxes, scores, labels = run_wbf(predictions, image_index=j)\n            boxes = boxes.astype(np.float32).clip(min=0, max=sz)\n            boxes[:, 0] = boxes[:, 0] \/ sz \n            boxes[:, 1] = boxes[:, 1] \/ sz\n            boxes[:, 2] = boxes[:, 2] \/ sz\n            boxes[:, 3] = boxes[:, 3] \/ sz\n            result = {'PredictionString': format_prediction_string(boxes, scores)}\n            results.append(result)\n    efd5[f'PredictionString_{i}'] = np.nan\n    for k in tqdm(range(len(efd5))):\n        efd5.loc[k, f'PredictionString_{i}'] = f\" {results[k]['PredictionString']}\"  \n    del net, results\n    gc.collect()\n    \nefd5['id'] = efd5['image_id'].apply(lambda x: x + '_image')\nefd5.head()","9047307f":"!pip install ..\/input\/pytorch-160-with-torchvision-070\/torch-1.6.0cu101-cp37-cp37m-linux_x86_64.whl\n!pip install ..\/input\/pytorch-160-with-torchvision-070\/torchvision-0.7.0cu101-cp37-cp37m-linux_x86_64.whl","47b6644f":"public = pd.read_csv('..\/input\/covid-public-test\/sample_submission.csv')\ntest_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n\n#submit\nif len(test_df) != 2477:\n    test_df = pd.concat([test_df, public]).reset_index(drop=True).drop_duplicates(keep=False).reset_index(drop=True)\n    \ntest_df['type'] = test_df['id'].apply(lambda x: x[-5:])\ntest_df = test_df[test_df['type'] == 'image'].reset_index(drop=True)\nmeta['id'] = meta['image_id'] + '_image'\ntest_df = test_df.merge(meta, on='id', how='left')\ntest_df = test_df.drop(['type', 'image_id'], axis=1)\ntest_df['split'] = 'test'\ntest_df['fold'] = -1\nefd3 = test_df[['id']].merge(efd3, on='id')\nefd4 = test_df[['id']].merge(efd4, on='id')\nefd5 = test_df[['id']].merge(efd5, on='id')","fae2fa50":"test_df","30067600":"import shutil\ndim = 512\nNFOLDS = 5\ntest_dir = root\ntmp = pd.DataFrame(columns=test_df.columns)\niou_th = [0.60, 0.61, 0.61, 0.60, 0.60]\nconf_th = 0.001\nsTH = 0.001\nlTH = 0.362\nweights1 = [[1.2, 1.2, 1, 0.7], [1, 4, 2, 0], [1.1, 1.1, 1, 0.5], [1.5, 1.5, 1, 0.7], [1.5, 1.5, 1, 0.9]]\n\nfor i in range(NFOLDS):\n    print(f'==========FOLD{i}==========')\n    labels_dict = {}\n    scores_dict = {}\n    boxes_dict = {}\n    test_df_ = test_df.copy()\n    test_df_['PredictionString'] = ''\n    test_df_['fold'] = i\n    \n    #yolo inference\n    weights_dir = f'\/kaggle\/input\/yolov5ver005-weight\/fold{i}_best.pt'\n    shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5\/', f'\/kaggle\/working\/yolov5\/fold{i}')\n    os.chdir(f'\/kaggle\/working\/yolov5\/fold{i}')\n    !python detect.py --weights $weights_dir --img 512 --conf 0.001 --iou 0.5 --source $test_dir --save-txt --save-conf --exist-ok\n    \n    for j in tqdm(range(len(test_df_))):\n        image_id = test_df_.iloc[j, 0][:-6]\n        labels_dict[j] = []\n        scores_dict[j] = []\n        boxes_dict[j] = []\n        \n        #yolo\n        labels_list = []\n        scores_list = []\n        boxes_list = []\n        try:\n            f = open(f'\/kaggle\/working\/yolov5\/fold{i}\/runs\/detect\/exp\/labels\/{image_id}.txt', 'r')\n            string = f.read().split(' ')\n            string.pop(0)\n            bbox_num = len(string) \/\/ 5\n\n            for k in range(bbox_num):\n                label = 0\n                xmid = float(string[0+5*k])\n                ymid = float(string[1+5*k])\n                w = float(string[2+5*k])\n                h = float(string[3+5*k])\n                xmin = xmid - w\/2\n                xmax = xmid + w\/2\n                ymin = ymid - h\/2\n                ymax = ymid + h\/2\n                score = float(string[4+5*k][:-3])\n                labels_list.append(label)\n                scores_list.append(score)\n                boxes_list.append([xmin, ymin, xmax, ymax])\n            labels_dict[j].append(labels_list)\n            scores_dict[j].append(scores_list)\n            boxes_dict[j].append(boxes_list)\n        except:\n            labels_dict[j].append([])\n            scores_dict[j].append([])\n            boxes_dict[j].append([])\n            \n        #EFD3\n        labels_list = []\n        scores_list = []\n        boxes_list = []\n        try:\n            string = efd3.loc[j, f'PredictionString_{i}'].split(' ')\n            string.pop(0)\n            bbox_num = len(string) \/\/ 6\n            for k in range(bbox_num):\n                label = 0\n                score = float(string[1+6*k])\n                xmin = float(string[2+6*k])\n                ymin = float(string[3+6*k])\n                xmax = float(string[4+6*k])\n                ymax = float(string[5+6*k])\n                labels_list.append(label)\n                scores_list.append(score)\n                boxes_list.append([xmin, ymin, xmax, ymax])\n            labels_dict[j].append(labels_list)\n            scores_dict[j].append(scores_list)\n            boxes_dict[j].append(boxes_list)\n        except:\n            labels_dict[j].append([])\n            scores_dict[j].append([])\n            boxes_dict[j].append([])\n            \n        #EFD4\n        labels_list = []\n        scores_list = []\n        boxes_list = []\n        try:\n            string = efd4.loc[j, f'PredictionString_{i}'].split(' ')\n            string.pop(0)\n            bbox_num = len(string) \/\/ 6\n            for k in range(bbox_num):\n                label = 0\n                score = float(string[1+6*k])\n                xmin = float(string[2+6*k])\n                ymin = float(string[3+6*k])\n                xmax = float(string[4+6*k])\n                ymax = float(string[5+6*k])\n                labels_list.append(label)\n                scores_list.append(score)\n                boxes_list.append([xmin, ymin, xmax, ymax])\n            labels_dict[j].append(labels_list)\n            scores_dict[j].append(scores_list)\n            boxes_dict[j].append(boxes_list)\n        except:\n            labels_dict[j].append([])\n            scores_dict[j].append([])\n            boxes_dict[j].append([])\n            \n        #EFD5\n        labels_list = []\n        scores_list = []\n        boxes_list = []\n        try:\n            string = efd5.loc[j, f'PredictionString_{i}'].split(' ')\n            string.pop(0)\n            bbox_num = len(string) \/\/ 6\n            for k in range(bbox_num):\n                label = 0\n                score = float(string[1+6*k])\n                xmin = float(string[2+6*k])\n                ymin = float(string[3+6*k])\n                xmax = float(string[4+6*k])\n                ymax = float(string[5+6*k])\n                labels_list.append(label)\n                scores_list.append(score)\n                boxes_list.append([xmin, ymin, xmax, ymax])\n            labels_dict[j].append(labels_list)\n            scores_dict[j].append(scores_list)\n            boxes_dict[j].append(boxes_list)\n        except:\n            labels_dict[j].append([])\n            scores_dict[j].append([])\n            boxes_dict[j].append([])\n    \n        #WBF per fold\n        print('=== WBF per fold ===')\n        width = test_df_.loc[j, 'dim1']\n        height = test_df_.loc[j, 'dim0']\n        boxes, scores, labels = weighted_boxes_fusion(\n            boxes_dict[j], \n            scores_dict[j], \n            labels_dict[j],\n            iou_thr=iou_th[i], \n            skip_box_thr=conf_th, \n            weights=weights1[i]\n        )\n        boxes[:, 0] = boxes[:, 0] * width\n        boxes[:, 1] = boxes[:, 1] * height\n        boxes[:, 2] = boxes[:, 2] * width\n        boxes[:, 3] = boxes[:, 3] * height\n    \n        if len(boxes) == 0:  #BBox_num == 0\n            continue\n        else:\n            box_num = len(boxes)\n            for b in range(box_num):\n                #small box removed\n                if ((boxes[b][2] - boxes[b][0]) * (boxes[b][3] - boxes[b][1])) \/ (width * height) < sTH:\n                    continue\n                \n                #large box removed\n                if ((boxes[b][2] - boxes[b][0]) * (boxes[b][3] - boxes[b][1])) \/ (width * height) > lTH:\n                    continue\n                \n                #edge box removed\n                if ((boxes[b][2] + boxes[b][0])\/2 < width*0.05) | ((boxes[b][2] + boxes[b][0])\/2 > width*0.95) | ((boxes[b][3] + boxes[b][1])\/2 < height*0.05) | ((boxes[b][3] + boxes[b][1])\/2 > height*0.95):\n                    continue\n                \n                #horizontal box removed\n                if (boxes[b][2] - boxes[b][0]) > width*0.6:\n                    continue\n                    \n                try:\n                    test_df_.loc[j, 'PredictionString'] += f'opacity {scores[b]} {int(boxes[b][0])} {int(boxes[b][1])} {int(boxes[b][2])} {int(boxes[b][3])} '\n                except:\n                    continue\n                    \n    tmp = tmp.append(test_df_, ignore_index=True)\n    del labels_dict, scores_dict, boxes_dict\n    gc.collect()","2f72bff9":"shutil.rmtree('\/kaggle\/working\/yolov5\/fold0')\nshutil.rmtree('\/kaggle\/working\/yolov5\/fold1')\nshutil.rmtree('\/kaggle\/working\/yolov5\/fold2')\nshutil.rmtree('\/kaggle\/working\/yolov5\/fold3')\nshutil.rmtree('\/kaggle\/working\/yolov5\/fold4')\nos.chdir(f'\/kaggle\/working')","779a2dbe":"tmp","079ba0d1":"#tmp = pd.read_csv('..\/input\/detection-final-sub-df\/det_inf_per_fold.csv')\ntmp.to_csv('\/kaggle\/working\/det_inf_per_fold.csv', index=False)\ndet_inf_per_fold = tmp","279d35aa":"# WBF across folds\nweights2 = [1.5, 1, 1, 1.5, 2]  # 0.5982 \/ 0.5684 \/ 0.5637 \/ 0.5835 \/ 0.6316\nens_th = 0.65\nid_list = tmp.id.unique()\nlabels_dict = {}\nscores_dict = {}\nboxes_dict = {}\ntest_df['PredictionString'] = ''\n\nprint('=== WBF across folds ===')\nfor i in tqdm(range(len(id_list))):\n    image_id = id_list[i]\n    dfs = tmp[tmp['id'] == image_id].sort_values('fold').reset_index(drop=True)\n    width = dfs['dim1'].mean()\n    height = dfs['dim0'].mean()\n    labels_dict[i] = []\n    scores_dict[i] = []\n    boxes_dict[i] = []\n    \n    for j in range(NFOLDS):\n        labels_list = []\n        scores_list = []\n        boxes_list = []\n        try:\n            string = dfs[dfs['fold'] == j].iloc[0, 1].split(' ')\n            bbox_num = len(string) \/\/ 6\n            for k in range(bbox_num):\n                label = 0\n                score = float(string[1+6*k])\n                xmin = float(string[2+6*k]) \/ width\n                ymin = float(string[3+6*k]) \/ height\n                xmax = float(string[4+6*k]) \/ width\n                ymax = float(string[5+6*k]) \/ height\n                labels_list.append(label)\n                scores_list.append(score)\n                boxes_list.append([xmin, ymin, xmax, ymax])\n            labels_dict[i].append(labels_list)\n            scores_dict[i].append(scores_list)\n            boxes_dict[i].append(boxes_list)\n        except:\n            labels_dict[i].append([])\n            scores_dict[i].append([])\n            boxes_dict[i].append([])\n            \n    boxes, scores, labels = weighted_boxes_fusion(\n        boxes_dict[i], \n        scores_dict[i], \n        labels_dict[i],\n        iou_thr=ens_th, \n        skip_box_thr=conf_th, \n        weights=weights2\n    )\n  \n    boxes[:, 0] = boxes[:, 0] * width\n    boxes[:, 1] = boxes[:, 1] * height\n    boxes[:, 2] = boxes[:, 2] * width\n    boxes[:, 3] = boxes[:, 3] * height\n    \n    if len(boxes) == 0:  #BBox_num == 0\n        continue\n    else:\n        box_num = len(boxes)\n        for b in range(box_num):\n            #small box removed\n            if ((boxes[b][2] - boxes[b][0]) * (boxes[b][3] - boxes[b][1])) \/ (width * height) < sTH:\n                continue\n                \n            #large box removed\n            if ((boxes[b][2] - boxes[b][0]) * (boxes[b][3] - boxes[b][1])) \/ (width * height) > lTH:\n                continue\n                \n            #edge box removed\n            if ((boxes[b][2] + boxes[b][0])\/2 < width*0.05) | ((boxes[b][2] + boxes[b][0])\/2 > width*0.95) | ((boxes[b][3] + boxes[b][1])\/2 < height*0.05) | ((boxes[b][3] + boxes[b][1])\/2 > height*0.95):\n                continue\n                \n            #horizontal box removed\n            if (boxes[b][2] - boxes[b][0]) > width*0.6:\n                continue\n              \n            try:\n                index = test_df[test_df['id'] == image_id].index\n                test_df.loc[index, 'PredictionString'] += f'opacity {scores[b]} {int(boxes[b][0])} {int(boxes[b][1])} {int(boxes[b][2])} {int(boxes[b][3])} '\n            except:\n                continue\n                \ndel labels_dict, scores_dict, boxes_dict\ngc.collect()","832977ff":"test_df","186540c2":"test_image = test_df.drop('fold', axis=1)\ntest_image.head()","1cbbf1a0":"test_image.to_csv('public_image.csv', index=False)","570b93ba":"public = pd.read_csv('..\/input\/covid-public-test\/sample_submission.csv')\ntest = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n\n#submit\nif len(test) != 2477:\n    test = pd.concat([test, public]).reset_index(drop=True).drop_duplicates(keep=False).reset_index(drop=True)\n\ntest['type'] = test['id'].apply(lambda x: x[-5:])\ntest_study = test[test['type'] == 'study'].reset_index(drop=True)\ntest_study['study_id'] = test_study['id'].apply(lambda x: x[:-6])\ntest_image = test_image[['id', 'PredictionString']]\ntest_image['image_id'] = test_image['id'].apply(lambda x: x[:-6])\n\ntmp = pd.DataFrame(columns=test_study.columns)\nfor i in tqdm(range(len(test_study))):\n    study_id = test_study.iloc[i, 3]\n    img_paths = glob(f'..\/input\/siim-covid19-detection\/test\/{study_id}\/*\/*')\n    if len(img_paths) == 1:\n        img_path = img_paths[0]\n        image_id = img_path.split('\/')[-1][:-4]\n        test_study.loc[i, 'image_id'] = image_id\n    else:\n        add_df = pd.concat([test_study.iloc[i:i+1]]*(len(img_paths)-1)).reset_index(drop=True)\n        for j in range(len(img_paths)):\n            if j == 0:\n                img_path = img_paths[j]\n                image_id = img_path.split('\/')[-1][:-4]\n                test_study.loc[i, 'image_id'] = image_id\n            else:\n                img_path = img_paths[j]\n                image_id = img_path.split('\/')[-1][:-4]\n                add_df.loc[j-1, 'image_id'] = image_id\n        tmp = tmp.append(add_df).reset_index(drop=True)\n        \ntest_study = pd.concat([test_study, tmp]).sort_values('id').reset_index(drop=True)\ntest = test_study.merge(test_image[['PredictionString', 'image_id']], on='image_id')","c6597978":"test","8a1814f2":"class COVIDDataset(Dataset):\n    def __init__(self, root, df, transform=None):\n        self.root = root\n        self.df = df\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image_id = self.df.iloc[idx, 4]\n        img = cv2.imread(f'{root}\/{image_id}.png')\n        \n        if self.transform:  #input shape should be: (sz, sz, 3)\n            img = self.transform(image=img)['image']\n        \n        img = (img\/255.0 - mean) \/ std  #Normalization\n        img = np.transpose(img, (2, 0, 1))  #shape(3, sz, sz)\n        img = torch.from_numpy(img)\n\n        return img","ae14e7ed":"def inference_fn1(data_loader, model, device):\n    model.eval()    \n    preds1 = []\n    preds2 = []\n    \n    for i, x in tqdm(enumerate(data_loader)):\n        img = x\n        img = img.to(device, dtype=torch.float)\n        \n        with torch.no_grad():\n            pred1, pred2, pred3 = model(img)\n            preds1.append(nn.Softmax()(pred1).detach().cpu().numpy())\n            preds2.append(nn.Sigmoid()(pred2).detach().cpu().numpy())\n            \n        del img, pred1, pred2, pred3\n        gc.collect()\n        \n    predictions1 = np.concatenate(preds1)\n    predictions2 = np.concatenate(preds2).reshape(-1, 1)\n    predictions = np.hstack([predictions1, predictions2])\n    \n    del preds1, preds2, predictions1, predictions2\n    gc.collect()\n    \n    return predictions\n\n\ndef inference_fn2(data_loader, model, device):\n    model.eval()    \n    preds1 = []\n    preds2 = []\n    \n    for i, x in tqdm(enumerate(data_loader)):\n        img = x\n        img = img.to(device, dtype=torch.float)\n        \n        with torch.no_grad():\n            pred1, pred2 = model(img)\n            preds1.append(nn.Softmax()(pred1[:, :4]).detach().cpu().numpy())\n            preds2.append(nn.Sigmoid()(pred1[:, 4]).detach().cpu().numpy())\n            \n        del img, pred1, pred2\n        gc.collect()\n        \n    predictions1 = np.concatenate(preds1)\n    predictions2 = np.concatenate(preds2).reshape(-1, 1)\n    predictions = np.hstack([predictions1, predictions2])\n    \n    del preds1, preds2, predictions1, predictions2\n    gc.collect()\n    \n    return predictions","7f1a08c7":"num_class1 = 4\nnum_class2 = 1\n\nclass Model0(nn.Module):\n    def __init__(self):\n        super(Model0, self).__init__()\n        e = timm_413.create_model(\n            'efficientnet_b3',\n            pretrained=False, \n            drop_rate=0.3, \n            drop_path_rate=0.2\n            )\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head,\n            e.bn2,\n            e.act2\n        )\n        self.logit1 = nn.Linear(1536, 4)\n        self.logit2 = nn.Sequential(\n            nn.Softmax(),\n            nn.Linear(4, 4),\n            nn.ReLU(),\n            nn.Linear(4, 1)\n        )\n\n        self.mask = nn.Sequential(\n            nn.Conv2d(136, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0)\n        )\n        \n    def forward(self, image):\n        batch_size = len(image)\n        x = 2 * image - 1\n        x = self.b0(x)\n        x = self.b1(x)\n        x = self.b2(x)\n        x = self.b3(x)\n        x = self.b4(x)\n        x = self.b5(x)\n        mask = self.mask(x)\n        x = self.b6(x)\n        x = self.b7(x)\n        x = self.b8(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        logit1 = self.logit1(x)\n        logit2 = self.logit2(logit1)\n        return logit1, logit2, mask\n\nclass Model1(nn.Module):\n    def __init__(self):\n        super(Model1, self).__init__()\n        #e = timm.create_model('tf_efficientnetv2_l', pretrained=True, in_chans=3)\n        e = Model_Y()\n        #e.load_state_dict(fix_key(torch.load(\"..\/data\/efb3_chex_02_epoch{}_step{}.pth\".format(6,18685))))\n        e = e.model\n\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head,\n            e.bn2,\n            e.act2\n        )\n        self.logit1 = nn.Linear(1536, num_class1)\n        self.logit2 = nn.Sequential(\n            nn.Softmax(),\n            nn.Linear(num_class1, num_class1),\n            nn.ReLU(),\n            nn.Linear(num_class1, num_class2))\n        self.mask = nn.Sequential(\n            nn.Conv2d(136, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n\n    def forward(self, image):\n        batch_size = len(image)\n        x = 2 * image - 1\n        x = self.b0(x)\n        x = self.b1(x)\n        x = self.b2(x)\n        x = self.b3(x)\n        x = self.b4(x)\n        x = self.b5(x)\n        mask = self.mask(x)\n        x = self.b6(x)\n        x = self.b7(x)\n        x = self.b8(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        logit1 = self.logit1(x)\n        logit2 = self.logit2(logit1)\n        return logit1, logit2, mask\n\nclass Model_Y(nn.Module):\n    def __init__(self, out_size=14, pretrained=True):\n        super().__init__()\n        self.model = timm_413.create_model(\n            'efficientnet_b3',\n            pretrained=False, \n            drop_rate=0.3, \n            drop_path_rate=0.2\n            )\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(1536, out_size)\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nclass Model2(nn.Module):\n    def __init__(self):\n        super(Model2, self).__init__()\n        e = timm_413.create_model(\n            'tf_efficientnetv2_l', \n            pretrained=False, \n            in_chans=3\n        )\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head,\n            e.bn2,\n            e.act2\n        )\n        self.logit = nn.Linear(1280, 5)\n        self.mask = nn.Sequential(\n            nn.Conv2d(224, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n        \n    def forward(self, image):\n        batch_size = len(image)\n        x = 2 * image - 1\n        x = self.b0(x)\n        x = self.b1(x)\n        x = self.b2(x)\n        x = self.b3(x)\n        x = self.b4(x)\n        x = self.b5(x)\n        mask = self.mask(x)\n        x = self.b6(x)\n        x = self.b7(x)\n        x = self.b8(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        logit = self.logit(x)\n        \n        return logit, mask\n    \nclass Model_3(nn.Module):\n    def __init__(self):\n        super(Model_3, self).__init__()\n        e = Model_X()\n        e = e.model\n\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head,\n            e.bn2,\n            e.act2\n        )\n        self.logit1 = nn.Linear(1280, 4)\n        self.logit2 = nn.Sequential(\n            nn.Softmax(),\n            nn.Linear(4, 4),\n            nn.ReLU(),\n            nn.Linear(4, 1))\n        self.mask = nn.Sequential(\n            nn.Conv2d(224, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n\n    def forward(self, image):\n        batch_size = len(image)\n        x = 2 * image - 1\n        x = self.b0(x)\n        x = self.b1(x)\n        x = self.b2(x)\n        x = self.b3(x)\n        x = self.b4(x)\n        x = self.b5(x)\n        mask = self.mask(x)\n        x = self.b6(x)\n        x = self.b7(x)\n        x = self.b8(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        logit1 = self.logit1(x)\n        logit2 = self.logit2(logit1)\n        return logit1, logit2, mask\n\nclass Model_X(nn.Module):\n    def __init__(self, out_size=14, model_name=\"tf_efficientnetv2_l\", pretrained=False):\n        super().__init__()\n        self.model = timm_413.create_model(model_name, pretrained=pretrained, in_chans=3)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Sequential(\n            nn.Linear(n_features, out_size),\n        )\n    def forward(self, x):\n        x = self.model(x)\n        return x","548e1cea":"test['Negative'] = 0\ntest['Typical'] = 0\ntest['Indeterminate'] = 0\ntest['Atypical'] = 0\ntest['None'] = 0\ntarget_cols = test.columns[6:].to_list()","84edb434":"det_inf_per_fold = det_inf_per_fold.rename(columns={'id': 'image_id'})\ndet_inf_per_fold['image_id'] = det_inf_per_fold['image_id'].apply(lambda x: x[:-6])\ndet_inf_per_fold.head()","32938eee":"test_ds = COVIDDataset(root=root, df=test, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=0)\nNFOLDS = 5\nall_predictions = 0\nnum_models = 7\n\nfor i in range(NFOLDS):\n    print(f'==========FOLD{i}==========')\n    predictions = 0\n    \n    model0 = Model0()\n    model0.load_state_dict(torch.load(f'..\/input\/covid-5class-efb3-seg-512-weight-0703-5\/0703_5_fold_{i}.pth'))\n    model0.to(device)\n    predictions += inference_fn1(test_dl, model0, device) \/ (NFOLDS * num_models)\n    del model0\n    gc.collect()\n    \n    model1 = Model1()\n    model1.load_state_dict(torch.load(f'..\/input\/5cls-efb3-seg-512-chex-ep6-18685\/model_1_fold_{i}.pth'))\n    model1.to(device)\n    predictions += inference_fn1(test_dl, model1, device) \/ (NFOLDS * num_models)\n    del model1\n    gc.collect()\n    \n    model2 = Model2()\n    model2.load_state_dict(torch.load(f'..\/input\/covid-5class-efv2l-seg-512-weight-0630-1\/0630_1_fold_{i}.pth'))\n    model2.to(device)\n    predictions += inference_fn2(test_dl, model2, device) \/ (NFOLDS * num_models)\n    del model2\n    gc.collect()\n    \n    model3 = Model_3()\n    model3.load_state_dict(torch.load(f'..\/input\/5cls-efv2l-seg-512-chex-1ep\/0630_1_fold_{i}.pth'))\n    model3.to(device)\n    predictions += inference_fn1(test_dl, model3, device) \/ (NFOLDS * num_models)\n    del model3\n    gc.collect()\n    \n    model4 = Model_3()\n    model4.load_state_dict(torch.load(f'..\/input\/5cls-efv2l-in21k-seg-512-chex-ep6-18685\/model_1_fold_{i}.pth'))\n    model4.to(device)\n    predictions += inference_fn1(test_dl, model4, device) \/ (NFOLDS * num_models)\n    del model4\n    gc.collect()\n    \n    model5 = Model1()\n    model5.load_state_dict(torch.load(f'..\/input\/5cls-efb3-seg-focal-512-chex-ep6-18685\/model_1_fold_{i}.pth'))\n    model5.to(device)\n    predictions += inference_fn1(test_dl, model5, device) \/ (NFOLDS * num_models)\n    del model5\n    gc.collect()\n    \n    from collections import OrderedDict\n    def fix_key(state_dict):\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            if k.startswith('module.'):\n                k = k[7:]\n            new_state_dict[k] = v\n        return new_state_dict\n    \n    model6 = Model1()\n    state_dict = torch.load(f'..\/input\/5cls-efb3-seg-512-chex-ep6-18685-bs16\/model_1_fold_{i}.pth')\n    state_dict =  fix_key(state_dict)\n    model6.load_state_dict(state_dict)\n    model6.to(device)\n    predictions += inference_fn1(test_dl, model6, device) \/ (NFOLDS * num_models)\n    del model6\n    gc.collect()\n    \n    #####################################################################\n    #Post-Processing\n    fold = det_inf_per_fold[det_inf_per_fold['fold'] == i].reset_index(drop=True)\n    fold = test.iloc[:, 4:5].merge(fold, on='image_id')\n    for j in tqdm(range(len(fold))):\n        confs = []\n        try:\n            string = fold.loc[j, 'PredictionString'].split(' ')\n            bbox_num = len(string) \/\/ 6\n            for b in range(bbox_num):\n                confs.append(float(string[6*b+1]))\n            max_conf = max(confs)\n            predictions[j, 0] *= (1 - max_conf)  #Negative\n            predictions[j, 4] *= (1 - max_conf)  #None\n        except:\n            continue     \n            \n    all_predictions += predictions\n    \ntest[target_cols] = all_predictions","1270ddd1":"nn_mean = test['Negative'] * 0.55 + test['None'] * 0.45\ntest['Negative'] = nn_mean\ntest['None'] = nn_mean\n\nw = 0.025\nfor i in tqdm(range(len(test))):\n    opacity = 1 - test.loc[i, 'None']\n    test.loc[i, 'Typical'] += opacity * w\n    test.loc[i, 'Indeterminate'] += opacity * w\n    test.loc[i, 'Atypical'] += opacity * w","74574708":"test.head(10)","aefb2a96":"test_image = test[['image_id', 'None', 'PredictionString_y']]\ntest_image = test_image.rename(columns={'image_id': 'id', 'PredictionString_y': 'PredictionString'})\ntest_image['id'] = test_image['id'].apply(lambda x: x + '_image')\n\nfor i in tqdm(range(len(test_image))):\n    none_conf = test_image.iloc[i, 1]\n    test_image.iloc[i, 2] += f' none {none_conf} 0 0 1 1'\n    \ntest_image = test_image.drop('None', axis=1)\ntest_image.head(10)","53539a14":"test_study = test.drop(['type', 'study_id', 'image_id', 'PredictionString_x', 'PredictionString_y', 'None'], axis=1)\ntest_study = test_study.groupby('id').mean()\ntest_study['id'] = test_study.index\ntest_study = test_study.reset_index(drop=True).iloc[:, [4, 0, 1, 2, 3]]\ntest_study.head(10)","45554dab":"labels = [\"negative\", \"typical\", \"indeterminate\", \"atypical\"]\ndictionary = {\"negative\": 'Negative', \"typical\": 'Typical', \"indeterminate\": 'Indeterminate', \"atypical\": 'Atypical'}\ntest_study['PredictionString'] = np.nan\n\nfor i in tqdm(range(len(test_study))):\n    s = ''\n    for label in labels:\n        s += f\"{label} {test_study.loc[i, f'{dictionary[label]}']} 0 0 1 1\" + ' '\n    test_study.loc[i, 'PredictionString'] = s","a0d4f663":"test_study = test_study[['id', 'PredictionString']]","5e34e454":"test = pd.concat([test_study, test_image]).reset_index(drop=True)","fa4dbede":"test.head(20)","f91117fd":"sample = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\ntest_dict = dict(zip(test['id'], test['PredictionString']))\nsample['PredictionString'] = sample['id'].map(test_dict)\nsample.to_csv('submission.csv', index=False)","9a996e16":"# Detection","63da971b":"# Classification","fcbaa495":"# DICOM to PNG","151ab025":"# Submission"}}