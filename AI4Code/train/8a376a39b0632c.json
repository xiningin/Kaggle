{"cell_type":{"ca71aa42":"code","cb282a46":"code","7aa4977a":"code","d84956fa":"code","c683083e":"code","ba81893e":"code","952b2163":"code","23a7e72c":"code","4e133d02":"code","9fe278eb":"code","d7acbc0b":"code","202b6aec":"code","152a4d88":"markdown","833a71c2":"markdown","8d7c4e0f":"markdown","198c7da4":"markdown","22e63df9":"markdown","965cb9a5":"markdown","48c2197c":"markdown","150b8cb8":"markdown","eec34230":"markdown","8118a8a4":"markdown","0ce131c5":"markdown"},"source":{"ca71aa42":"!pip install noisereduce","cb282a46":"import librosa\nimport random\nimport IPython\n\nimport numpy as np\nimport pandas as pd\nimport noisereduce as nr\n\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt\nfrom scipy.ndimage import maximum_filter1d","7aa4977a":"INPUT = \"..\/input\/birdsong-recognition\/\"\nSEED = 20200807","d84956fa":"def audio_to_spec(audio, sr):\n    spec = librosa.power_to_db(\n        librosa.feature.melspectrogram(audio, sr=sr, fmin=20, fmax=16000, n_mels=128)\n    )\n    return spec.astype(np.float32)\n\ndef envelope(y, rate, threshold):\n    mask = []\n    y_mean = maximum_filter1d(np.abs(y), mode=\"constant\", size=rate\/\/20)\n    for mean in y_mean:\n        if mean > threshold:\n            mask.append(True)\n        else:\n            mask.append(False)\n    return mask, y_mean","c683083e":"path_lst = []\nfor directory in Path(f\"{INPUT}\/train_audio\").iterdir():\n    path_lst += [path for path in Path(directory).iterdir()]\n    \n\ntrain_df = pd.read_csv(f\"{INPUT}\/train.csv\")\ntrain_df.head(1)","ba81893e":"random.seed(SEED)\npath = random.sample(path_lst, 1)[0]\ndisplay(train_df.query(f\"filename=='{path.name}'\")[[\"rating\", \"ebird_code\"]])\n\nx, sr = librosa.load(path=path, mono=True)\nprint(\"sampling rate:\", sr)\nplt.plot(x)\nplt.show()\n\nIPython.display.Audio(data=x, rate=sr)","952b2163":"thr = 0.25\nmask, env = envelope(x, sr, thr)\n\nplt.plot(x[mask], label=\"birdcall\")\nplt.plot(x[np.logical_not(mask)], label=\"noise\")\nplt.legend(bbox_to_anchor=(1, 1), loc='upper right')","23a7e72c":"x_denoise = nr.reduce_noise(audio_clip=x, noise_clip=x[np.logical_not(mask)], verbose=True)","4e133d02":"plt.plot(x_denoise)","9fe278eb":"plt.figure(figsize=(16, 8))\nplt.imshow(audio_to_spec(x, sr))\nplt.show()\n\nplt.figure(figsize=(16, 8))\nplt.imshow(audio_to_spec(x_denoise, sr))\nplt.show()","d7acbc0b":"IPython.display.Audio(data=x, rate=sr)","202b6aec":"IPython.display.Audio(data=x_denoise, rate=sr)","152a4d88":"I detect point no birdcall by using *Sound Envelope*.\n\n\nI reffered [this notebook](https:\/\/www.kaggle.com\/jainarindam\/imp-remove-background-dead-noise) and [this discussion](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/discussion\/169582). (Thank you [Arindam](https:\/\/www.kaggle.com\/jainarindam)!)","833a71c2":"### Utils","8d7c4e0f":"### import libraly","198c7da4":"compare spectrogram","22e63df9":"noise reduction using spectral gating in python\n\nI show [this discussion](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/discussion\/169582#946072), and I use [this library](https:\/\/pypi.org\/project\/noisereduce\/).  \n*audio_clip* is pure audio data and *noise_clip* is low level of sound from Sound Envelope.\n\n","965cb9a5":"sompare audio","48c2197c":"### Denoise\n\nload path","150b8cb8":"### Constants","eec34230":"sampling and load audio data","8118a8a4":"It seems that noise has been removed.\n\nI have made dataset of deonise audio spectrogram image. ([here](https:\/\/www.kaggle.com\/takamichitoda\/birdcall-spectrogram-images\/activity))\n\nI train model by use this dataset, I got local fold-0 0.6319398546 and LB 0.543.","0ce131c5":"# Birdcall noise reduction\n\n\nI show [this discussion](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/discussion\/169582#946072).  \nI try to remove noise by using Sound Envelope.\n\nversion 3:\n- I use scipy.ndimage.maximum_filter1d instead of pandas.rolling (ref. [this discussion](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/discussion\/172921#962037))"}}