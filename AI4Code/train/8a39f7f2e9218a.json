{"cell_type":{"b01fe390":"code","b163c1e5":"code","18377d7c":"code","66a6c3d2":"code","a058a5c2":"code","1fd2173f":"code","35ff36a8":"code","fc564f82":"code","d937606b":"code","8bfd035f":"code","b0acc1dd":"code","5db2ff12":"code","cb263502":"markdown","0440d7d1":"markdown","b0739af0":"markdown","b478d9cc":"markdown","70056f5f":"markdown","4789eece":"markdown","f3247837":"markdown"},"source":{"b01fe390":"!pip install ..\/input\/pytorchtabnet\/pytorch_tabnet-3.1.1-py3-none-any.whl","b163c1e5":"import os, sys, shutil, glob\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm","18377d7c":"def make_directory(folder):\n    if os.path.isdir(folder):\n        shutil.rmtree(folder)\n    os.makedirs(folder)\n    print(f\"build directory : < {folder} >\")","66a6c3d2":"# tmp path\nsubmission_dir = '\/kaggle\/working'\nworking_dir = '\/kaggle\/working_space'\ntmp_output_dir = '\/kaggle\/tmp_output'\ntmp_data_dir = '\/kaggle\/tmp'\noriginal_data_dir = '\/kaggle\/input\/optiver-realized-volatility-prediction'\n\n# source and working_space path\nsource_path = '\/kaggle\/input\/volatility\/src'\nprepare_path = os.path.join(working_dir, 'prepare')\nlgbm_path = os.path.join(working_dir, 'light_gbm')\ntabnet_path = os.path.join(working_dir, 'tabnet')\n\n# make directory\nmake_directory(tmp_output_dir)\nmake_directory(tmp_data_dir)\n\n# copy code to working_space\n\nshutil.copytree(src = '\/kaggle\/input\/volatility\/src',\n                dst = working_dir)","a058a5c2":"%cd $prepare_path\n\n# preprocessing test data\n\n!python preprocessing.py --data_dir=$original_data_dir\\\n                         --tmp_data_dir=$tmp_data_dir\\\n                         --test_data\n\n# only preprocessing test_data\n# use preprocessed_train_data in volatility_data for train set","1fd2173f":"%cd $lgbm_path\n\n# lightgbm prediction\n\nlgb_model_dir = 'models'\n\n!python predict_test.py --data=$tmp_data_dir\\\n                        --save_dir=$tmp_output_dir\\\n                        --save_sub\\\n                        --model_dir=$lgb_model_dir\nprint('predict by lightgbm')","35ff36a8":"model_dir = '0825_1015'\n\nmodel_folder = os.path.join(tabnet_path, 'models\/')\nmodel_folder += model_dir + '\/tabnet_' + model_dir\nmodel_folder","fc564f82":"%cd $model_folder\n\nfor i, model in enumerate(sorted(glob.glob('.\/*'))):\n    print(f\"zip model fold {i} again\")\n    shutil.make_archive(model, \"zip\", model)","d937606b":"%cd $tabnet_path\n\n# tabnet prediction\n\npreprocessed_train_data_path = '\/kaggle\/input\/volatility-data\/preprocessed_data'\n\n!python predict_test.py --train_data=$preprocessed_train_data_path\\\n                        --test_data=$tmp_data_dir\\\n                        --save_dir=$tmp_output_dir\\\n                        --save_sub\\\n                        --model_dir=$model_dir\n\nprint('predict by tabnet')","8bfd035f":"%cd \/kaggle\/working\n\nresults = glob.glob(tmp_output_dir + '\/*')\nsubmission = pd.read_csv(results[0])\ntargets = 0\nfor result in results:\n    target = pd.read_csv(result)['target']\n    targets += target\ntargets = targets\/len(results)\nsubmission['target'] = targets\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","b0acc1dd":"# delete tmp directory\n\nif os.path.isdir(working_dir):\n    shutil.rmtree(working_dir)\nif os.path.isdir(tmp_output_dir):\n    shutil.rmtree(tmp_output_dir)\nif os.path.isdir(tmp_data_dir):\n    shutil.rmtree(tmp_data_dir)","5db2ff12":"# complete","cb263502":"# \ud83d\ude80 python package style code\n### with package code on datasets - LightGBM and TabNet\n\nThis is the code of training model and inference.   \nNormally we use **ipynb** style code in kaggle.    \nI just change the code style to **py package** and it's better for training with shell command.\n\nI refer the original code below and thanks to @chumajin\n\n[[Notebook] Reference Notebook by chumajin](https:\/\/www.kaggle.com\/chumajin\/optiver-realized-ensemble-tabnet-and-lgbm)\n\n------\n\n### This Notebook is the code for last prediction. \n#### Anyone can download my public code dataset of 'volatility' \n#### and it include \n* **preprocessing and feature engineering**\n* **lgbm train and predict**\n* **tabnet train and predict**\n\nThe code of 'volatility_2021.ipynb' in volatility code dataset is the local version of this notebook.  \nJust enjoy it!","0440d7d1":"----\n### My Public datasets\n`1. Volatility` : source code of py files\n* prepare : preprocessing and feature engineering\n* light_gbm : train and predict\n* tabnet : train and predict\n\n\n`2.volatility-data` : feature engineered data\n* preprocessed_test.csv\n* preprocessed_train.csv","b0739af0":"## 1. Model Inference\n\n### 1-1. light gbm\n\n","b478d9cc":"### 1-2. tabnet\n\nThe format of tabnet trained model is **zip**.  \nBut, zip file is auto unpacked during dataset mounting.  \nSo, it need to be zipped again.\n\nWe need to use **shutil.make_archive** not **!zip** command.  \nI refered the function of `'save_model and load_model'` in original tabnet code.  \n\nhttps:\/\/github.com\/dreamquark-ai\/tabnet\/blob\/develop\/pytorch_tabnet\/abstract_model.py","70056f5f":"## 0-3. Preprocessing and Feature Engineering\n\n```py\n!python preprocessing.py --data_dir=='location for raw data'\\\n                         --temp_data_dir=='location for feature engineered data'\\\n                         --train_data=='either use train data or not(store_true)'\\\n                         --test_data=='either use test data or not(store_true)'\n\n```","4789eece":"----\n\n## 0. Prepare\n### 0-1. Install and Import","f3247837":"### 0-2. Make directory for working"}}