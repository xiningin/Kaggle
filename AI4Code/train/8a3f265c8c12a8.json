{"cell_type":{"3381bc56":"code","7fd186cf":"code","c338aa95":"code","d6e3ac62":"code","758fb3dd":"code","5855922e":"code","0336b086":"code","0993b8de":"code","85254115":"code","688a134a":"code","7beb269f":"code","96f33f60":"code","970296dc":"code","f6f84da9":"code","762edbeb":"code","c3826158":"code","eddda64f":"code","f5bab439":"code","4ab306d0":"code","0173d2c3":"code","a6f3cd11":"code","9d4bbd03":"code","dd05ac91":"code","b547e33e":"code","841ecc5b":"code","39306633":"code","89e8d209":"code","cb6d6f07":"code","1e24cd4e":"code","b70bc160":"code","15fdd8b8":"code","42b4ae18":"code","30e77d35":"code","1f598c31":"code","99a77db3":"code","e0bcb8b3":"code","22000ab5":"code","43f677e4":"code","19484c59":"code","be09d023":"code","397540c5":"code","f0532525":"code","49cb73ff":"code","0fb2212c":"code","3e93a859":"code","8f58b33c":"code","ba9ab4cf":"code","2bfae0c9":"code","0214cca2":"code","c599a69a":"code","c2527df5":"code","4b0eb6ca":"code","c1f49c66":"code","0e9ba31c":"code","0dc6e407":"code","34ff0943":"code","c023a9bb":"code","22fd8195":"code","74f65387":"markdown","964e819c":"markdown","ba766954":"markdown","655b8244":"markdown","c653a3a8":"markdown","081e0f3c":"markdown"},"source":{"3381bc56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data visualization\nimport seaborn as sns # EDA\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n#import plotly.graph_objs as go\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7fd186cf":"data = pd.read_csv(\"..\/input\/heart.csv\")","c338aa95":"data.info #We learn what data has","d6e3ac62":"data.columns #we learn data's features","758fb3dd":"data.head(8)","5855922e":"#We will practise how can we use 'lineplot'\ndata.chol.plot(kind=\"line\",color=\"green\",label=\"chol\",grid=True,linestyle=\":\")\ndata.thalach.plot(kind=\"line\",color=\"purple\",label=\"thalach\",grid=True)\ndata.age.plot(kind=\"line\",color=\"pink\",label=\"age\",grid=True)\ndata.trestbps.plot(kind=\"line\",color=\"orange\",label=\"trestbps\",grid=True)\nplt.legend(loc=\"upper right\") #legend: puts feature label into plot\nplt.xlabel(\"indexes\")\nplt.ylabel(\"Features\")\nplt.title(\"Heart Diseases\")\nplt.show()","0336b086":"#We will practise how can we use Scatter Plot\n#I want to compare 'age' and 'chol'. Is there any connection with these features?\ndata.plot(kind=\"scatter\", x=\"age\", y=\"chol\", alpha= 0.5, color=\"brown\")\nplt.xlabel(\"age\")\nplt.ylabel(\"chol\")\nplt.title(\"age and chol with Scatter Plot\")\nplt.show()","0993b8de":"#Histogram shows frequency of feature to us.\ndata.cp.plot(kind=\"hist\",bins=50,figsize=(5,5))\nplt.show()","85254115":"# My first filter -> logical and\ndata[(data['cp']>2) & (data['sex']<1)]","688a134a":"# My second filter -> logical or\ndata[(data['age']>70) | (data['ca']>2)]","7beb269f":"# Lets think of every feature as a list. \nprint(data.age[0])\nprint('')\n# we can see all ages with enumerate\nfor index, value in enumerate(data.age[0:5]): \n   print(index,\" : \",value)\nprint('')\n# other option is iterrows(). We can see 5 sexes with details.    \nfor index, value in data[['sex']][0:5].iterrows(): \n     print(index,\" : \",value)","96f33f60":"#usage of tuble func.\ni=3; #global  variable(scope)\ndef tuble_ex():\n  # there is no local scope however 't' has 3 variables. Because we have global scope.\n    t=(data.age[i],data.age[i+1],data.age[i+2])\n    return t\na,b,c = tuble_ex() # 3 variables returned.\nprint(a,b,c)\nprint(tuble_ex())","970296dc":"#Nested func. practise with oldpeak and cp values. \nfor i in range(6): \n    def square():\n        def add(): \n            x= data.oldpeak[i]\n            y= data.cp[i]\n            z= x+y\n            return z\n        return add()**2\n    if square() > 5 and square() < 10:\n        print(square(),\"Normal\")\n    else:\n        print(square(),\"Critical\")","f6f84da9":"#Map,Lambda,zip() practise\nx= map(lambda k:k**2,data.sex[0:5])\ny= map(lambda k:k,data.age[0:5])\n#print(x,y)\nlist1= list(x)\nlist2= list(y)\nz= zip(list1,list2)\nz_list=list(z)\nprint(z_list)","762edbeb":"# I can find the average age of patients\n# I want to create new section about probabilities according to ages.\nthreshold = sum(data.age)\/len(data.age)\nprint(\"Threshold:\",threshold)\n#list comprehension\ndata[\"probability\"]= [\"high\" if i>threshold else \"low\" for i in data.age]\ndata.loc[:10,[\"probability\",\"age\"]]","c3826158":"data.info()","eddda64f":"# I want to learn frequency of ages\nprint(\"age\",\"frequency\")\nprint(data.age.value_counts(dropna=False))","f5bab439":"#If we want to find outlier datas, we should use describe() method.\n#Its easier to see statistical calculations.\n#Also its ignore null entries.\ndata.describe()\n#We can see visualization of statistical calculations.\ndata.boxplot(column=\"age\", by=\"sex\")\n# ages value by sex\nplt.show()","4ab306d0":"#Lets practise how can we melt of data_new.\ndata_new = data.head()\ndata_new","0173d2c3":"melted = pd.melt(frame=data_new,id_vars='age',value_vars=['restecg','exang'])\nmelted","a6f3cd11":"# rivot: reverse of melting\nmelted.pivot(index='age',columns='variable',values='value')","9d4bbd03":"#How can we concatenate to dataframes?\ndata1= data.head()\ndata2= data.tail()\nconc_data_row= pd.concat([data1,data2],axis=0,ignore_index=True) \nconc_data_row","dd05ac91":"data1= data.sex.head()\ndata2= data.chol.head()\nconc_data_col= pd.concat([data1,data2],axis=1) #axis=1: adds df in column\nconc_data_col","b547e33e":"data.dtypes","841ecc5b":"#I want to convert object to categorical and float to int.\ndata.probability= data.probability.astype('category')\ndata.oldpeak=data.oldpeak.astype('int')\ndata.dtypes","39306633":"#Lets find missing values. \ndata.info()\n#As we can see this dataframe hasn't got any null entry or missing value. What am I lucky!!!\u2714\n#I think,this dataset has already been cleared but anyway..","89e8d209":"# We can check lots of things with 'assert'\nassert data.target.notnull().all()\n#returns nothing it means we don't have any nan values.","cb6d6f07":"assert data.slope.dtypes == np.int","1e24cd4e":"# high level filter :d\nfilter1=data.thal>2\nfilter2= data.slope<1\ndata.age[filter1 & filter2]","b70bc160":"#I just want to practise usage of plain python func.\ndef cross(n):\n    return n*2\ndata[\"new\"]= data.age.apply(cross)+data.cp\n#data.new\ndata.loc[:5,\"slope\":]","15fdd8b8":"# Setting index: type1 is outer, type 2 is inner index\ndata1=data.set_index([\"age\",\"chol\"])\ndata1.head(10)","42b4ae18":"# Lets group all features according to cp\ndata.groupby(\"cp\").mean()\n#data.groupby(\"cp\").age.max()","30e77d35":"# How many patients fasting blood sugar is > 120 mg\/dl? (true=1, false=0)\ndata.fbs.value_counts(dropna=False)","1f598c31":"# Which age range is more likely to be a heart patient?\nage_list= list(data.age)\n# I am gonna use 'Counter' method. We should import it at the beginning.\nage_count= Counter(age_list)\nmost_common_age= age_count.most_common(15)\nx,y = zip(*most_common_age)\nx,y = list(x), list(y)\n\n#Visualization\nplt.figure(figsize=(15,5))\nsns.barplot(x=x, y=y, palette= sns.cubehelix_palette(len(x)))\nplt.ylabel('Frequency')\nplt.xlabel('Ages')\nplt.title('Most common ages of heart patients')","99a77db3":"# As we can see;\ndata.age.value_counts()","e0bcb8b3":"#Lets find type of heart attack by all ages. (cp values)\nage_list=list(data.age.unique())\n#cp_list= list(data.cp.unique())\ncp_zero=[]\ncp_one=[]\ncp_two=[]\ncp_three=[]\nfor i in age_list:\n    x= data[data['age']==i]\n    cp_zero.append(sum(x.cp==0)\/len(x))\n    cp_one.append(sum(x.cp==1)\/len(x))\n    cp_two.append(sum(x.cp==2)\/len(x))\n    cp_three.append(sum(x.cp==3)\/len(x))\n#Visualization\nf,ax= plt.subplots(figsize=(15,9))\nsns.barplot(y=cp_zero,x=age_list,color='purple',alpha=0.5,label='Type 0')\nsns.barplot(y=cp_one,x=age_list,color='green',alpha=0.7,label='Type 1')\nsns.barplot(y=cp_two,x=age_list,color='yellow',alpha=0.6,label='Type 2')\nsns.barplot(y=cp_three,x=age_list,color='blue',alpha=0.6,label='Type 3')\n\nax.legend(loc='lower right',frameon=True)\nax.set(xlabel='Ages', ylabel='Cp values', title='Type of heart attack by age')","22000ab5":"#As we can see;\ndata.loc[:20,[\"age\",\"cp\"]]","43f677e4":"#Sorted Chol values by age\nage_list= list(data.age.unique())\nchol_ratio=[]\nfor i in age_list:\n    x=data[data['age']==i]\n    chol_rate=sum(x.chol)\/len(x)\n    chol_ratio.append(chol_rate)\ndatac= pd.DataFrame({'age_list': age_list,'chol_ratio': chol_ratio})\nnew_index=(datac['chol_ratio'].sort_values(ascending=False)).index.values\nsorted_data=datac.reindex(new_index)\nsorted_data.head()","19484c59":"#Sorted trestbps values by age\nage_list= list(data.age.unique())\ntbps_ratio=[]\nfor i in age_list:\n    x=data[data['age']==i]\n    tbps_rate=sum(x.trestbps)\/len(x)\n    tbps_ratio.append(tbps_rate)\ndatat= pd.DataFrame({'age_list': age_list,'tbps_ratio': tbps_ratio})\nnew_index=(datat['tbps_ratio'].sort_values(ascending=False)).index.values\nsorted_data2=datat.reindex(new_index)\nsorted_data2.head()","be09d023":"#We have values in two different ranges so I normalized them.\nsorted_data['chol_ratio']=sorted_data['chol_ratio']\/max(sorted_data['chol_ratio'])\nsorted_data2['tbps_ratio']=sorted_data2['tbps_ratio']\/max(sorted_data2['tbps_ratio'])\ndata_all=pd.concat([sorted_data,sorted_data2['tbps_ratio']],axis=1)\ndata_all.sort_values('chol_ratio',inplace=True)\ndata_all.head()","397540c5":"#Visualization with point plot\nf,ax1 = plt.subplots(figsize=(20,10))\nsns.pointplot(x=data_all['age_list'],y=data_all['chol_ratio'],data_all=data_all,color='lime',alpha=0.8)\nsns.pointplot(x=data_all['age_list'],y=data_all['tbps_ratio'],data_all=data_all,color='purple',alpha=0.8)\nplt.text(40,0.58,'chol ratio',color='lime',fontsize=18,style='normal')\nplt.text(40,0.55,'trestbps ratio',color='purple',fontsize=18,style='normal')\nplt.xlabel('Ages',fontsize=15,color='orange')\nplt.ylabel('Values',fontsize=15,color='orange')\nplt.title('Chol vs Trestbps Values',fontsize=20,color='orange')\nplt.grid()","f0532525":"# Visualization with joint plot\nfrom scipy import stats \n#I include it for see pearsonr value.\ng= sns.jointplot(data_all['age_list'],data_all['tbps_ratio'],kind=\"kde\",height=5)\ng = g.annotate(stats.pearsonr)\nplt.savefig('graph.png')\nplt.show()","49cb73ff":"g= sns.jointplot(data_all.chol_ratio,data_all.tbps_ratio,height=5,ratio=3,color=\"purple\")\ng = g.annotate(stats.pearsonr)","0fb2212c":"data_all.head()","3e93a859":"#Linear model\nsns.lmplot(x=\"chol_ratio\",y=\"age_list\",data=data_all)\nplt.show()","8f58b33c":"sns.kdeplot(data_all.age_list,data_all.chol_ratio,shade=True,cut=5,color=\"brown\")\nplt.show()","ba9ab4cf":"pal= sns.cubehelix_palette(2,rot=-.5,dark=.3)\nsns.violinplot(data=data_all.loc[:,[\"chol_ratio\",\"tbps_ratio\"]],palette=pal,inner=\"points\")\nplt.show()\n#It means the most value we have is about 0.8 for chol_ratio and the most value we have is between 0.8 and 0.9 for tbps_ratio. ","2bfae0c9":"data_all.corr()\n#As we can see; values of data_all are positive correlation so values are directly proportional.\n#The similarity between chol and tbps value are very low.","0214cca2":"#Correlation map\nf,ax= plt.subplots(figsize=(5,5))\nsns.heatmap(data_all.corr(), annot=True, linewidths=.5, fmt='.1f', ax=ax)\nplt.show()","c599a69a":"#I want to learn chest pain type (cp) according in heart data.\nlabels= data.cp.value_counts().index\ncolors=[\"orange\",\"pink\",\"brown\",\"gray\"]\nexplode= [0,0,0,0]\nsizes=data.cp.value_counts().values\n#Visualization with pie plot\nplt.figure(figsize=(7,7))\nplt.pie(sizes,explode=explode,labels=labels,colors=colors,autopct='%1.1f%%')\nplt.title('Chest pain type(cp) according in heart.csv',color=\"blue\",fontsize=15)","c2527df5":"data.head(10)","4b0eb6ca":"#I want to learn age, gender and chest pain type correlations.\nsns.boxplot(x=\"sex\", y=\"age\", hue=\"cp\", data=data, palette=\"PRGn\")\nplt.title(\"0: female, 1:male\",color=\"gray\")\nplt.show()","c1f49c66":"#Other option is;\nsns.swarmplot(x=\"sex\", y=\"age\", hue=\"cp\", data=data)\nplt.title(\"0: female, 1:male\",color=\"gray\")\nplt.show()","0e9ba31c":"#I used swarmplot to learn about age,gender and the possibility of having heart disease.\nsns.swarmplot(x=\"sex\", y=\"age\", hue=\"probability\", data=data)\nplt.title(\"0: female, 1:male\",color=\"gray\")\nplt.show()","0dc6e407":"data.ca.value_counts()","34ff0943":"#Lets see \"ca\" value(number of major vessels (0-3) colored by flourosopy).\nplt.figure(figsize=(10,6))\ncount= data.ca.value_counts()\nsns.barplot(x=count.index, y=count.values)\nplt.ylabel(\"Number of ca\")\nplt.xlabel(\"Ca values\")\nplt.title(\"Ca values in data\", color=\"black\", fontsize=\"12\")","c023a9bb":"sns.pairplot(data_all.loc[:,[\"chol_ratio\",\"age_list\"]])\nplt.show()","22fd8195":"sns.pairplot(data.loc[:,[\"chol\",\"age\",\"ca\",\"oldpeak\"]])\nplt.show()","74f65387":"We can understand so many info with these plots. According to heart.csv;\n* The most patients who are heart disease man.\n* Heart patients are mostly in age from 50 to 60.\n* chest pain type is mostly 2 in women whereas it is 0 in men and type 3 is common in men.\n\nWhen we change features in func. we can find so many different info. about heart disease. \ud83c\udf88","964e819c":".\ud83c\udfae\ud83c\udfae\ud83c\udfae","ba766954":"Cleaning Data \u2728\n","655b8244":"As we can see on boxplot, we haven't got any outlier value. \ud83d\udcaf","c653a3a8":"Lets compare\n* age,\n* chol (serum cholestoral in mg\/dl),\n* trestbps values (resting blood pressure)\nand find the** correlation!**","081e0f3c":"**Lets start to EDA! \ud83c\udf8a**"}}