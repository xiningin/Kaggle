{"cell_type":{"c14b7ca1":"code","ea956507":"code","800dc048":"code","551bb432":"code","ba378f22":"code","711cdc28":"code","3a82b49c":"code","d842e0b6":"code","a1178a0d":"code","04c0b9ff":"code","fb3cfb73":"code","cdbe3abb":"code","3e28dd88":"code","204a3538":"code","70720b8d":"code","96ec2f40":"code","760e5ab0":"code","eb737526":"markdown","3db7355d":"markdown","1420b59a":"markdown","bffc2bb6":"markdown","f3c8821d":"markdown","08f45ed0":"markdown","b0426c88":"markdown","748947da":"markdown"},"source":{"c14b7ca1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ea956507":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","800dc048":"!pip install pandas_flavor","551bb432":"from pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef missing(df):\n        return sorted(\n                    [(col,str(df[col].dtypes),np.round(df[col].isna().sum()\/len(df) * 100,2)) for col in df.columns if df[col].isna().sum() !=0 ],\n                    key = lambda x: x[2], reverse=True)\n    \n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_col(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef discrete_features(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef continious_features(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n@register_dataframe_method\ndef unique_value_column(df):\n#     returns unique value if object, else describe \n\n    if df.dtype == 'object':\n    \n        return list(df.unique())\n    else:\n        return df.describe().to_dict()\n    \n    \n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_col()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n        \n    \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_col()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n\n            length = len(df[i])\n            tmp = np.round((length - df[i].between(lower_range,upper_range).sum())\/length * 100, 2)\n            if tmp != 0:\n                features[i] = tmp\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Percent Missing'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    print(df.dtypes.value_counts(ascending=False))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = missing(df)\n    print(*tmp,sep=\"\\n\") if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())\n","ba378f22":"df = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndf.drop(\"Id\", axis=1, inplace=True)\ndf.about()","711cdc28":"# Plotting numerical features with polynomial order to detect outliers.\n\n# https:\/\/www.kaggle.com\/datafan07\/beginner-eda-with-feature-eng-and-blending-models\/notebook\n\nfrom matplotlib.ticker import MaxNLocator\n\ndef srt_reg(y, df,x_size=30,y_size=30,*args,**kwargs):\n    \n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, figsize=(x_size,y_size))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sns.regplot(x=i,\n                    y=y,\n                    data=df,\n                    ax=j,\n                    order=3,\n                    ci=None,\n                    color='#e74c3c',\n                    line_kws={'color': 'black'},\n                    scatter_kws={'alpha':0.4},\n                   *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n        plt.tight_layout()\n\ndef srt_box(y, df,*args,**kwargs):\n    fig, axes = plt.subplots(19, 3, figsize=(30,30))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sortd = df.groupby([i])[y].median().sort_values(ascending=False)\n        sns.boxplot(x=i,\n                    y=y,\n                    data=df,\n                    palette='plasma',\n                    order=sortd.index,\n                    ax=j,\n                    *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n\ndef histplt(df,x_size=30,y_size=60,*args,**kwargs):\n    \n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sns.histplot(df[i],ax=j,*args,**kwargs)\n        j.tick_params(labelrotation=45)\n#         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n\ndef countplt(df,x_size=10,y_size=10,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(\n                             figsize=(x_size,y_size)\n                            )\n        \n        sns.countplot( x=df,ax=ax,*args,**kwargs)\n        ax.tick_params(labelrotation=45)\n#         ax.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n#         plt.tight_layout()\n        \n    else:\n        ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, \n                                 figsize=(x_size,y_size)\n                                )\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            sns.countplot(data=df, x=i,ax=j,*args,**kwargs)\n            j.tick_params(labelrotation=45)\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n\n    \ndef bar_with_variable(df,y,x_size=30,y_size=30):\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n        \n        if i == y:\n            continue\n#         tmp = pd.DataFrame(df.groupby(i)[y].median()).reset_index(inplace=True)\n        sns.barplot(data=pd.DataFrame(df.groupby(i)[y].median()).reset_index(),\n                    x=i,\n                    y=y,\n                    ax=j,*args,**kwargs)\n        j.tick_params(labelrotation=45)\n#         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n    \ndef violinplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n    \n    \n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.violinplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n            \n            lower_range, upper_range = df[i].IQR_range()\n            outliers = df[(df[i] > upper_range) | (df[i] < lower_range)][i]\n            sns.scatterplot(y=outliers, x=0, marker='D', color='crimson', ax=j)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.violinplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \ndef boxplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()","3a82b49c":"sns.set(style=\"darkgrid\",font_scale=1.1)\nplt.rcParams['figure.dpi']=200","d842e0b6":"countplt(df[\"Species\"],x_size=5,y_size=5)","a1178a0d":"histplt(df.get_numeric_df(),x_size=20,y_size=10,kde=True,bins=20,alpha =0.5)","04c0b9ff":"violinplt(df=df,y=\"Species\",x_size=20,y_size =10,alpha =0.5)","fb3cfb73":"x = df.columns.to_list()\nx.remove(\"Species\")\nx = df[x]\nx.head()","cdbe3abb":"y = \"Species\"\ny = df[y]\ny.head()","3e28dd88":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import cross_val_score\n\n\nfrom sklearn.preprocessing import LabelEncoder","204a3538":"encoder = LabelEncoder()\ny = encoder.fit_transform(y)\ny","70720b8d":"lgr = LogisticRegression(max_iter=1000)\nrf = RandomForestClassifier()\nknn = KNeighborsClassifier()\nsvc = SVC()\n\nmodels = {\"LogisticRegression\":lgr,\n          \"RandomForestClassifier\":rf,\n          \"KNeighborsClassifier\":knn,\n          \"SVC\":svc,\n         }\n\nimport warnings\nwarnings.filterwarnings('ignore')","96ec2f40":"accuraces = {}\nfor name, model in models.items():\n    acc = cross_val_score(model, x, y, scoring='accuracy',n_jobs=-1,cv=10, verbose=1)\n#     print(acc)\n    accuraces[name] = acc\n\naccuraces\n\nfor key in accuraces.keys():\n    print(f'{key : <25} {np.round(sum(accuraces[key])\/len(accuraces[key]) * 100, 2)} %')","760e5ab0":"tmp = np.round(cross_val_score(SVC(C=10, gamma=0.0222, kernel='rbf', tol=0.0334),X=x,y=y, scoring=\"accuracy\", cv = 10), 3)\nprint(tmp, np.mean(tmp))","eb737526":"```\nfrom tune_sklearn import TuneGridSearchCV\n\n# trying wider combinations first\n# tuned_parameters = [{'kernel': ['rbf'], 'gamma': np.linspace(1e-5,1e-1,10),\n#                      'C': np.linspace(1,2000,10),\n#                     'tol':np.linspace(1e-4,1e-1,10)},\n# #                     {'kernel': ['sigmoid'], 'gamma': np.linspace(1e-5,1e-1,10),\n# #                      'C': np.linspace(1,2000,10),\n# #                     'tol':np.linspace(1e-4,1e-1,10)},\n# #                     {'kernel': ['linear'], 'gamma': np.linspace(1e-5,1e-1,10),\n# #                      'C': np.linspace(1,2000,10),\n# #                     'tol':np.linspace(1e-4,1e-1,10)},\n                    \n# #                     {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n# #                      'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000,1500],\n# #                     'tol':np.linspace(1e-4,1e-1,10)},\n# #                     {'kernel': ['linear'], 'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000, 1500], 'tol':np.linspace(1e-4,1e-1,10)}\n#                    ]\n\n# then narrow down and tune further\n\ntuned_parameters = [{'kernel': ['rbf'],\n                     'gamma': np.linspace(1e-4,1e-1,20),\n                     'C': np.linspace(1,500,20),\n                    'tol':np.linspace(1e-4,1e-1,20)},]\n\nscores = [ 'accuracy']\n\nfor score in scores:\n    print(f\"# Tuning hyper-parameters for {score}\")\n    print()\n\n    clf = TuneGridSearchCV(SVC(C=1), tuned_parameters,early_stopping=False, cv=10,\n                       scoring=score, n_jobs=-1)\n    clf.fit(x,y)\n\n    print(\"Best parameters set found on development set:\")\n    print()\n    print(clf.best_params_)\n    print()\n    print(\"Grid scores on development set:\")\n    print()\n    means = clf.cv_results_['mean_test_score']\n    stds = clf.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n        print(\"%0.3f (+\/-%0.03f) for %r\"\n              % (mean, std * 2, params))\n    print()\n    \n```","3db7355d":"# HyperParameter tuning","1420b59a":"# Imports","bffc2bb6":"# EDA","f3c8821d":"# Define custom methods\n## For data description","08f45ed0":"# Feature Engg","b0426c88":"# ML model train and test","748947da":"## for plots"}}