{"cell_type":{"4ce48dee":"code","91bc93ab":"code","bb718d37":"code","7270c065":"code","f36c41cb":"code","48cab8a5":"code","2e29864c":"code","b6533b24":"code","958ec78d":"code","1c2838d1":"code","c135388e":"code","67c524bd":"code","630fb553":"code","8dbc27ac":"code","d1c5f622":"code","674e25e0":"code","a8c50cd8":"code","9ba8b4f9":"code","4012d34d":"code","aa8910ee":"code","19b7867a":"code","5b73c892":"code","07808dc8":"code","71c9e7bb":"code","7e425462":"code","7481f1d5":"code","16094c68":"code","f5d2190f":"code","91d6cecd":"code","60c944e2":"code","af7c03fd":"code","a023aac9":"markdown","0b26b8a3":"markdown","4cc55c67":"markdown","ebc91938":"markdown","409a2fb3":"markdown","8ef8c935":"markdown","0129cc48":"markdown","ae13a15c":"markdown","f37d567e":"markdown","88bc1553":"markdown","5e44fbcf":"markdown","019c5ded":"markdown","ecfa4af9":"markdown"},"source":{"4ce48dee":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# load data\ntrain = pd.read_csv('..\/input\/train.csv')\nprint('Shape of train set {}'.format(train.shape))\ntest = pd.read_csv('..\/input\/test.csv')\nprint('Shape of test set {}'.format(test.shape))","91bc93ab":"# for param tuning\nfrom sklearn.model_selection import  GridSearchCV\nfrom sklearn.metrics import get_scorer","bb718d37":"def onehot_encode(cat_feat, data):\n    '''\n    Encode given categorical feature and add names of new binary columns into the set of features\n    :param cat_feat:\n    :param data:\n    :return:\n    '''\n    encoded = pd.get_dummies(data[cat_feat], prefix=cat_feat, dummy_na=True)\n    res = pd.concat([data.drop(columns=[cat_feat]), encoded], axis='columns')\n    return res\n\ndef cal_dependency_rate(df):\n    df['n_dependency'] = df['hogar_total'] - df['hogar_adul']\n    non_zero = (df.hogar_adul != 0)\n    df.loc[non_zero, 'num_dep_rate'] = df.loc[non_zero, 'n_dependency']\/df.loc[non_zero, 'hogar_adul']\n    df.loc[-non_zero, 'num_dep_rate'] = np.nan\n    return df\n\ndef add_quality(df, componente='pared', component='wall'):\n    for i in [1,2,3]:\n        i_quality = (df['e{}{}'.format(componente, i)] == 1)\n        df.loc[i_quality, '{}_quality'.format(component)] = i\n    return df\n\ndef to_english(df, sp_pre='pared', eng_pre='wall_', translate=None):\n    '''\n    rename certain columns in specified dataframe from Spanish \n    to English, given the translation\n    '''\n    for sp in translate.keys():\n        spanish_name = sp_pre + '{}'.format(sp)\n        english_name = eng_pre + '{}'.format(translate[sp])\n        df.rename(columns={spanish_name: english_name}, inplace=True)\n    \n    return df","7270c065":"# join train and test\ntest['Target'] = np.nan\ndata_all = pd.concat([train, test])\n\nprint('Shape of all data: {}'.format(data_all.shape))\nn_house = data_all['idhogar'].nunique()\nprint('# unique households in data: {}'.format(n_house))","f36c41cb":"n_row = data_all.shape[0]\nn_null = data_all.drop('Target', axis='columns').isnull().values.sum(axis=0)\ncolumns = list(data_all.columns)\ncolumns.remove('Target')\npd.DataFrame({'column': columns, \n              'n_null': n_null}).sort_values('n_null', ascending=False).head(10)","48cab8a5":"def mk_derived_feats(df):\n    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n                 ('working_man_fraction', 'r4h2', 'r4t3'),\n                 ('all_man_fraction', 'r4h3', 'r4t3'),\n                 ('human_density', 'tamviv', 'rooms'),\n                 ('human_bed_density', 'tamviv', 'bedrooms'),\n#                  ('rent_per_person', 'v2a1', 'r4t3'),\n#                  ('rent_per_room', 'v2a1', 'rooms'),\n                 ('mobile_density', 'qmobilephone', 'r4t3'),\n#                  ('tablet_density', 'v18q1', 'r4t3'),\n                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n#                  ('tablet_adult_density', 'v18q1', 'r4t2'),\n                 #('', '', ''),\n                ]\n    \n    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n                 ('people_weird_stat', 'tamhog', 'r4t3')]\n\n    for f_new, f1, f2 in feats_div:\n        df['fe_' + f_new] = (df[f1] \/ df[f2]).astype(np.float32)       \n    for f_new, f1, f2 in feats_sub:\n        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n    return df\n\ndef mk_agg_feats(df):\n    # aggregation rules over household\n    aggs_num = {'age': ['min', 'max', 'mean'],\n                'escolari': ['min', 'max', 'mean']\n               }\n    aggs_cat = {'dis': ['sum', 'mean']} # mean will give us percentage of disable members\n    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n            aggs_cat[f_] = ['mean', 'count'] # mean will give us percentage of the type\n    \n    # aggregate over household\n    for name_, df_ in [('18', df.query('age >= 18'))]:\n        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n        df = df.join(df_agg, how='left', on='idhogar')\n        del df_agg\n    \n    return df\n\ndef drop_redundant(df):\n    # Drop SQB variables, as they are just squres of other vars \n    df.drop([f_ for f_ in df.columns if f_.startswith('SQB') or f_ == 'agesq'], axis=1, inplace=True)\n    # Drop id's\n#     df.drop(['Id', 'idhogar'], axis=1, inplace=True)\n    # Drop repeated columns\n    df.drop(['hhsize', 'area2'], axis=1, inplace=True)\n    return df","2e29864c":"from sklearn.preprocessing import LabelEncoder\n\nyes_no_map = {'no': 0, 'yes': 1}\ndata_all['dependency'] = data_all['dependency'].replace(yes_no_map).astype(np.float32)\ndata_all['edjefe'] = data_all['edjefe'].replace(yes_no_map).astype(np.float32)\ndata_all['edjefa'] = data_all['edjefa'].replace(yes_no_map).astype(np.float32)\n\ndata_all['idhogar'] = LabelEncoder().fit_transform(data_all['idhogar'])\n\ndata_all = mk_derived_feats(data_all)\ndata_all = mk_agg_feats(data_all)\ndata_all = drop_redundant(data_all)","b6533b24":"fe_feats = [ff for ff in data_all.columns if ff.startswith('fe_')]\nfe_feats","958ec78d":"agg_feats = [ff for ff in data_all.columns if ff.startswith('agg')]\nagg_feats","1c2838d1":"basic_feats = ['dependency']\n# basic_feats = ['hogar_nin', 'hogar_adul', 'hogar_mayor', 'dependency', \n#                 'overcrowding', 'rooms', 'bedrooms']","c135388e":"is_head = (data_all.parentesco1 == 1)\nhead_df = data_all.loc[is_head, :]\n# print('Shape of head_df: {}'.format(head_df.shape))\n\nn_head = head_df.shape[0]\nprint('# unique household heads: {}'.format(n_head))","67c524bd":"head_df.loc[head_df['male'] == 1, 'head_gender'] = 'male'\nhead_df.loc[head_df['female'] == 1, 'head_gender'] = 'female'\nprint('Shape of head_df: {}'.format(head_df.shape))\n\n# one-hot encode head gender\nhead_df = onehot_encode('head_gender', head_df)\n\nhead_gender_feats = [cc for cc in head_df.columns if 'head_gender' in cc]\nhead_gender_feats","630fb553":"# convert binary edu levels to numeric values\nfor i in range(1, 10):\n    head_df.loc[head_df['instlevel{}'.format(i)] == 1, 'head_edu_level'] = i\n    \nhead_df = head_df.rename(columns={'escolari': 'head_school_years'})","8dbc27ac":"# as there are a few households with no head, we need an left outer join \n# to avoid missing those houses\ncols = ['idhogar', 'head_school_years', 'head_edu_level'] + head_gender_feats\ndata_all = pd.merge(data_all, head_df[cols], how='left', on='idhogar')\nprint(data_all.shape)","d1c5f622":"house_head_feats = ['head_school_years', 'head_edu_level'] + head_gender_feats","674e25e0":"data_all = add_quality(data_all, componente='pared', component='wall')\ndata_all = add_quality(data_all, componente='techo', component='roof')\ndata_all = add_quality(data_all, componente='viv', component='floor')\nprint(data_all.shape)","a8c50cd8":"# rename material columns\n# wall\ntranslate = {'blolad': 'block',\n             'zocalo': 'socket',\n             'preb': 'cement',\n             'des': 'waste',\n             'mad': 'wood',\n             'zinc': 'zink',\n             'fibras': 'natural_fibers',\n             'other': 'other'}\ndata_all = to_english(data_all, sp_pre='pared', eng_pre='wall_', \n                   translate=translate)\nwall_feats = [cc for cc in data_all.columns if 'wall_' in cc]\n\n# floor\ntranslate = { \n    'moscer': 'mosaic',\n    'cemento': 'cement',\n    'other': 'other',\n    'natur': 'natural',\n    'notiene': 'no_floor',\n    'madera': 'wood'\n}\ndata_all = to_english(data_all, sp_pre='piso', eng_pre='floor_', translate=translate)\nfloor_feats = [cc for cc in data_all.columns if 'floor_' in cc]\n\n# roof\ntranslate = {\n     'zinc': 'zinc',\n     'entrepiso': 'fiber cement',\n     'cane': 'natural fibers',\n     'otro': 'other'\n}\ndata_all = to_english(data_all, sp_pre='techo', eng_pre='roof_', translate=translate)\nroof_feats = [cc for cc in data_all.columns if 'roof_' in cc]\n","9ba8b4f9":"material_feats = roof_feats + wall_feats + floor_feats","4012d34d":"# water\ntranslate = {\n    'guadentro': 'inside_house',\n    'guafuera': 'outside_house',\n    'guano': 'no'\n}\ndata_all = to_english(data_all, sp_pre='abasta', eng_pre='water_provision_', \n                   translate=translate)\nwater_feats = [cc for cc in data_all.columns if 'water_provision_' in cc]\n\n# electricity\ntranslate = {\n    'public': 'public',\n    'planpri': 'private_plan',\n    'noelec': 'no',\n    'coopele': 'cooperate'\n}\ndata_all = to_english(data_all, sp_pre='', eng_pre='electric_', translate=translate)\nelec_feats = [cc for cc in data_all.columns if 'electric_' in cc]\n\n# energy\ntranslate = {\n    'cinar1': 'no',\n    'cinar2': 'electricity',\n    'cinar3': 'gas',\n    'cinar4': 'charcoal'\n}\ndata_all = to_english(data_all, sp_pre='energco', eng_pre='energy_', translate=translate)\nenergy_feats = [cc for cc in data_all.columns if 'energy_' in cc]\n\n# toilet\ntranslate = {\n    '1': 'no',\n    '2': 'sewer',\n    '3': 'septic_tank',\n    '5': 'black hole',\n    '6': 'other'\n}\ndata_all = to_english(data_all, sp_pre='sanitario', eng_pre='toilet_', translate=translate)\ntoilet_feats = [cc for cc in data_all.columns if 'toilet_' in cc]\n\n# rubbish\ntranslate = {\n    '1': 'tanker truck',\n    '2': 'buried',\n    '3': 'burning',\n    '4': 'throw empty place',\n    '5': 'throw to river',\n    '6': 'other'\n}\ndata_all = to_english(data_all, sp_pre='elimbasu', eng_pre='rubbish_', translate=translate)\nrubbish_feats = [cc for cc in data_all.columns if 'rubbish_' in cc]","aa8910ee":"facility_feats = water_feats + elec_feats + energy_feats + toilet_feats + rubbish_feats","19b7867a":"translate = {\n    '1': 'own_fully_paid',\n    '2': 'own_pay_installment',\n    '3': 'rented',\n    '4': 'precarious',\n    '5': 'other'\n}\ndata_all = to_english(data_all, sp_pre='tipovivi', eng_pre='living_type_', \n                      translate=translate)","5b73c892":"live_feats = [cc for cc in data_all.columns if 'living_type_' in cc]","07808dc8":"features = basic_feats + house_head_feats + material_feats + facility_feats + live_feats + fe_feats + agg_feats\nprint('# features: {}'.format(len(features)))\n\ncols = ['Id'] + features + ['Target']\ntrain = data_all.loc[data_all['Target'].notnull(), cols]\n# train on all members, not just househeads\nX_train, y_train = train[features], train['Target']\ntest = data_all.loc[data_all['Target'].isnull(), cols]\nX_test = test[X_train.columns]","71c9e7bb":"X_train.shape, y_train.shape, X_test.shape","7e425462":"X_train.dtypes.value_counts()","7481f1d5":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import f1_score","16094c68":"# from sklearn.model_selection import train_test_split\n# xtrain,xtest,ytrain,ytest = train_test_split(X_train,y_train,train_size=.85,random_state=1234)","f5d2190f":"%%time\nestimator = CatBoostClassifier(verbose=False, loss_function='MultiClass')\nestimator.fit(X_train,y_train)","91d6cecd":"# y_pred = estimator.predict(xtest)\n# f1_score(ytest, y_pred, average='macro')","60c944e2":"%%time\npred = estimator.predict(X_test)\nsub =  pd.read_csv(\"..\/input\/sample_submission.csv\")\nsub[\"Target\"] = pred.astype(\"int64\")\nsub.to_csv(\"catboost_sub.csv\", index=False)","af7c03fd":"sub.head()","a023aac9":"Three columns `rez_esc`, `v18q1` and `v2a1` are dominated by NAs. Care should be taken if we want to use them later.","0b26b8a3":"### merge gender and edu data","4cc55c67":"## Renting or owning a house","ebc91938":"## Feature engineering\nThis part is based on https:\/\/www.kaggle.com\/mlisovyi\/feature-engineering-lighgbm-with-f1-macro, with additional  comments to clarify things.","409a2fb3":"## House material","8ef8c935":"## Facility","0129cc48":"## Add data of household head","ae13a15c":"### edu level","f37d567e":"## Helpers","88bc1553":"# Transforming and merging data","5e44fbcf":"## Check NAs","019c5ded":"# Light gbm","ecfa4af9":"### gender"}}