{"cell_type":{"961b59c8":"code","be7569f6":"code","92971fd9":"code","11dbfad9":"code","d3354d47":"code","a16e14d0":"code","5310b828":"code","c2e6fc1f":"code","e5af6bf5":"code","19c4fb48":"code","b61d85a2":"code","3a5996cc":"code","4b24a854":"code","7402a5c0":"code","6f5cd91c":"code","724270be":"code","6e739416":"code","8f40c891":"code","7b8cccdc":"code","64ae0ab6":"code","cd0f6a40":"code","5537ff02":"code","5f80e6bd":"code","8e867fab":"code","a3dd8fe1":"code","9f99c066":"code","5b17ba9c":"code","1abf8a9c":"code","2f43b37b":"code","54af2fce":"code","6e82c502":"code","b23f197f":"code","27167032":"code","c5b57b60":"code","31d5d8f6":"code","91f8bde7":"code","58ea2c9c":"code","5a06b97b":"code","26ad620d":"code","ab48775e":"code","1b0ace89":"code","544a62d1":"code","92b836d6":"code","d0fe35cb":"code","cfe99cd7":"code","326f62eb":"code","171f2d54":"code","cec5cf64":"code","b1de3a35":"code","a2a118ef":"code","fc9b8d7c":"code","fcd46958":"code","817ed7be":"code","a72ce291":"code","5bc2324c":"code","9a7849cc":"code","8c196134":"code","ec6e91f7":"code","343fdcd7":"code","012fe735":"code","be2a47b3":"code","a680a451":"code","40fb04a9":"code","6a7eaa18":"code","5b2a153c":"code","2be8aa9b":"code","503a409f":"code","4cc81e12":"code","612d09ae":"code","61c22c8a":"code","df2e2f0d":"code","c2ef5ef1":"code","cbafa6f9":"code","0ce5f3a2":"code","7803769b":"code","865b424b":"code","4ac405e4":"code","54eb64b9":"code","30ffc78b":"code","5a08c8a0":"code","379c31fa":"code","4148db68":"code","08729d8c":"code","e11d5bdd":"code","e4aae930":"code","b87ebd8d":"code","8a030e0f":"code","c3308a64":"code","ab169988":"code","786af217":"code","b7ba9ded":"code","7b54ce5a":"code","a83837ab":"code","293a859b":"code","9135a152":"code","59e37ab2":"markdown","74dddbd4":"markdown","65c9a1d9":"markdown","b4b5632c":"markdown","817189fd":"markdown","5e8ec598":"markdown","8512bbd9":"markdown","fd909baf":"markdown","90c4884a":"markdown","6de6dcaa":"markdown","e1c117ce":"markdown","f76085b4":"markdown","bb01ea97":"markdown","47b3b8e7":"markdown","86e6c530":"markdown","96a983c5":"markdown","42b59178":"markdown","45d5ee57":"markdown","ca1dc37e":"markdown","c0580d65":"markdown","037050bc":"markdown","1ca6224e":"markdown","7111ccd8":"markdown","7f1534a0":"markdown","b977c43e":"markdown","48ccaee2":"markdown","e9d9b1bc":"markdown"},"source":{"961b59c8":"!pip install livelossplot","be7569f6":"import numpy as np\nimport pandas as pd\n\nimport os\n\nimport seaborn as sns\nsns.set()\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import models, optimizers\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom livelossplot import PlotLossesKeras\n\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom catboost import CatBoostClassifier\n\nfrom scipy.stats import mode\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","92971fd9":"df_train = pd.read_csv('..\/input\/titanic\/train.csv', index_col=0)\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv', index_col=0)\ndf_train","11dbfad9":"df_test.head()","d3354d47":"fig, axes = plt.subplots(ncols=2, figsize=(12, 4))\n\nnans = df_train.isnull().sum() \/ df_train.shape[0]\nnans.plot(kind='bar', grid=True, color='darkgreen', rot=30, title='Missing values (train), %', ax=axes[0])\nprint('Train\\n', nans[nans != 0])\n\nnans = df_test.isnull().sum() \/ df_test.shape[0]\nnans.plot(kind='bar', grid=True, color='darkgreen', rot=30, title='Missing values (test), %', ax=axes[1])\nprint('Test\\n', nans[nans != 0])","a16e14d0":"df_train['Embarked'].value_counts(dropna=False).to_frame().T","5310b828":"categorical_features = ['Embarked']","c2e6fc1f":"df_train['Cabin'].str.replace(r'[0-9.]+','').value_counts(dropna=False).to_frame().T","e5af6bf5":"def preprocessing_cabin(string):\n    if isinstance(string, float):\n        return 'NaN'\n    else:\n        string2 = ''.join(filter(lambda x: x.isalpha(), string))\n        return string2","19c4fb48":"df_train['Cabin'].apply(lambda x: preprocessing_cabin(x)).value_counts().to_frame().T","b61d85a2":"categorical_features2 = ['Cabin']","3a5996cc":"df_train['Ticket'].value_counts().to_frame().T","4b24a854":"delete_columns = ['Ticket']","7402a5c0":"df_train['Fare'].value_counts().to_frame().T","6f5cd91c":"numeric_features = ['Fare']","724270be":"df_train['Parch'].value_counts().to_frame().T","6e739416":"categorical_features2.append('Parch')","8f40c891":"df_train['SibSp'].value_counts()","7b8cccdc":"pd.cut(df_train['SibSp'], bins=[0, 1, 2, 8], right=False, retbins=True, labels=['few', 'a few', 'many'])","64ae0ab6":"df_train['SibSp']","cd0f6a40":"categorical_features2.append('SibSp')","5537ff02":"df_train['Age'].value_counts(dropna=False).to_frame().T","5f80e6bd":"list_handling = df_train['Name'].apply(lambda x: x.split(',')[1].split('.')[0]).value_counts()\nlist_handling","8e867fab":"df_train2 = df_train.copy()\n\nfor elem in list_handling.index:\n    cond1 = df_train2['Name'].str.contains(elem + '.', regex=False)\n    cond2 = df_train2['Age'].isnull()\n    df_train2.loc[cond1 & cond2, 'Age'] = df_train2.loc[cond1, 'Age'].mean()","a3dd8fe1":"fig, axes = plt.subplots(sharey=True, ncols=2, figsize=(14, 5))\ndf_train['Age'].plot(kind='kde', ax=axes[0])\ndf_train2['Age'].plot(kind='kde', ax=axes[1])\nfig.suptitle('Age: Train with Nans -> Train without Nans', y=0.98, fontsize=14)\nplt.show()","9f99c066":"numeric_features.append('Age')","5b17ba9c":"df_train['Sex'].value_counts(dropna=False).to_frame().T","1abf8a9c":"categorical_features.append('Sex')","2f43b37b":"df_train['Name'].value_counts(dropna=False)","54af2fce":"delete_columns.append('Name')","6e82c502":"df_train['Pclass'].value_counts(dropna=False).to_frame().T","b23f197f":"categorical_features.append('Pclass')","27167032":"set(df_train.columns) - set(delete_columns) - set(numeric_features) - set(categorical_features)","c5b57b60":"categorical_features2","31d5d8f6":"Y_train = df_train['Survived']\ndf_train.drop('Survived', axis=1, inplace=True)","91f8bde7":"df_train.head()","58ea2c9c":"numeric_features","5a06b97b":"class DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, columns, return_frame=None):\n        self.columns = columns\n        self.return_frame = return_frame\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.columns] if self.return_frame else X[self.columns].values","26ad620d":"class AddFeatureSibSp(BaseEstimator, TransformerMixin):\n    def __init__(self, columns, bins, labels):\n        self.columns = columns\n        self.bins = bins\n        self.labels = labels\n        \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        list_result = np.empty(shape=(X.shape[0], len(self.columns)), dtype=object)\n        \n        for i, column in enumerate(self.columns):\n\n            dataframe = pd.DataFrame(X[:, i], columns=[column])\n            labels_frame = pd.cut(dataframe[column], bins=self.bins, right=False, retbins=True, labels=self.labels)[0].to_frame()\n            list_result[:, i] = labels_frame.values[:, 0]\n        \n        return list_result","ab48775e":"AddFeatureSibSp(columns=['SibSp', 'Parch'], bins=[0, 1, 2, 8], labels=['few', 'a few', 'many']).fit_transform(X=df_train[['SibSp', 'Parch']].values)","1b0ace89":"imputer1 = SimpleImputer(strategy='most_frequent')\nonehot1 = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\npipe1 = Pipeline([\n    ('selector', DataFrameSelector(columns=['SibSp', 'Parch'])),\n    ('new_feature', AddFeatureSibSp(columns=['SibSp', 'Parch'], bins=[0, 1, 2, 8], labels=['few', 'a few', 'many'])),\n    ('imputer', imputer1),\n    ('onehot', onehot1)\n])","544a62d1":"pipe1.fit_transform(df_train).shape","92b836d6":"pipe1.fit_transform(df_train)[:12]","d0fe35cb":"np.vstack([df_train['SibSp'].loc[:12], df_train['Parch'].loc[:12]]).T","cfe99cd7":"def preprocessing_cabin2(obj):\n    list_return = []\n    for string in obj:\n        string = string[0]\n        if isinstance(string, float):\n            list_return.append('NaN')\n        else:\n            string2 = ''.join(filter(lambda x: x.isalpha(), string))\n            list_return.append(string2)\n\n    return np.array(list_return, dtype=object)","326f62eb":"pipe2 = Pipeline([\n    ('selector', DataFrameSelector(columns=['Cabin'])),\n    ('transform', FunctionTransformer(lambda x: preprocessing_cabin2(x)))\n])","171f2d54":"pipe2.fit_transform(df_train)[:5]","cec5cf64":"imputer2 = SimpleImputer(strategy='constant', fill_value='NaN')\nonehot2 = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\npipe2 = Pipeline([\n    ('selector', DataFrameSelector(columns=['Cabin'])),\n    ('transform', FunctionTransformer(lambda x: preprocessing_cabin2(x))),\n    ('reshape', FunctionTransformer(np.reshape, kw_args={'newshape': (-1, 1)})),\n    ('imputer', imputer2),\n    ('onehot', onehot2)\n])","b1de3a35":"pipe2.fit_transform(df_train)[:]","a2a118ef":"pipe2.fit_transform(df_train).shape","fc9b8d7c":"categorical_features","fcd46958":"imputer3 = SimpleImputer(strategy='most_frequent')\nonehot3 = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\npipe3 = Pipeline([\n    ('selector', DataFrameSelector(columns=categorical_features)),\n    ('imputer', imputer3),\n    ('onehot', onehot3)\n])","817ed7be":"pipe3.fit_transform(df_train)[:]","a72ce291":"pipe3.fit_transform(df_train).shape","5bc2324c":"numeric_features","9a7849cc":"imputer4 = KNNImputer(n_neighbors=10, weights='distance')\nscaler = MinMaxScaler()\n\npipe4 = Pipeline([\n    ('selector', DataFrameSelector(columns=['Fare'])),\n    ('imputer', imputer4),\n    ('scaler', scaler)\n])","8c196134":"pipe4.fit_transform(df_train)[:5]","ec6e91f7":"class ChangeAge(BaseEstimator, TransformerMixin):\n    def __init__(self, df, column2='Name', column1='Age'):\n        self.column1 = column1\n        self.column2 = column2\n        self.df = df\n        self.list_names = df[self.column2].apply(lambda x: x.split(',')[1].split('.')[0]).value_counts()\n        self.median = df[self.column1].median()\n        \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        dataframe = X.copy()\n        \n        for elem in self.list_names.index:\n            cond1 = dataframe[self.column2].str.contains(elem + '.', regex=False)\n            cond2 = dataframe[self.column1].isnull()\n            \n            cond3 = self.df[self.column2].str.contains(elem + '.', regex=False)\n            dataframe.loc[cond1 & cond2, self.column1] = self.df.loc[cond3, self.column1].mean()\n\n        return dataframe[self.column1].values","343fdcd7":"df_train['Age'].values[:20]","012fe735":"model = ChangeAge(df=df_train, column1='Age', column2='Name')\nmodel.fit_transform(X=df_train[['Age', 'Name']])[:20]","be2a47b3":"df_test['Age'].values[:30]","a680a451":"model.transform(X=df_test[['Age', 'Name']])[:30]","40fb04a9":"np.isnan(model.transform(X=df_test[['Age', 'Name']])).any()","6a7eaa18":"scaler2 = MinMaxScaler()\n\npipe5 = Pipeline([\n    ('selector', DataFrameSelector(columns=['Age', 'Name'], return_frame=True)),\n    ('imputer', ChangeAge(df=df_train, column1='Age', column2='Name')),\n    ('reshape', FunctionTransformer(np.reshape, kw_args={'newshape': (-1, 1)})),\n    ('scaler', scaler2)\n])","5b2a153c":"pipe_all = FeatureUnion(transformer_list=[\n    ('SibSp_Parch', pipe1),\n    ('Cabin', pipe2),\n    ('Categorical', pipe3),\n    ('Fare', pipe4),\n    ('Age', pipe5)\n])","2be8aa9b":"# parameters = {\n#     'model__penalty' : ['l1', 'l2'],\n#     'model__C' : np.logspace(-1, 0, 3000),\n#     'model__multi_class': ['auto', 'ovr', 'multinomial']\n# }\n\nmodel = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n\nlr_pipe = Pipeline([\n    ('features', pipe_all),\n    ('model', model)\n])\n\n# scoring = {\n#     'acc': 'accuracy'\n# }\n\n# gs = GridSearchCV(estimator=lr_pipe, param_grid=parameters, scoring=scoring, \n#                   cv=10, refit='acc', n_jobs=-1, verbose=1)\n\n# gs.fit(df_train, Y_train)","503a409f":"gs_best_params = {\n    'model__C': 0.49609538663257724,\n    'model__multi_class': 'multinomial',\n    'model__penalty': 'l2'\n}","4cc81e12":"lr_pipe.set_params(**gs_best_params)\nlr_pipe.fit(df_train, Y_train)\n\npred = lr_pipe.predict(df_test)","612d09ae":"submission = pd.DataFrame({\"Survived\": pred}, index=df_test.index)\nsubmission.to_csv(\"submission_lr.csv\")","61c22c8a":"# X1, X2, Y1, Y2 = train_test_split(df_train, Y_train, test_size=0.2, random_state=42, stratify=Y_train)","df2e2f0d":"# X1 = pipe_all.fit_transform(X1)\n# X2 = pipe_all.transform(X2)\n\n# X1.shape, X2.shape","c2ef5ef1":"# Y1 = tf.keras.utils.to_categorical(Y1, num_classes=2)\n# Y2 = tf.keras.utils.to_categorical(Y2, num_classes=2)","cbafa6f9":"# Y1.shape, Y2.shape","0ce5f3a2":"# model = Sequential()\n\n# model.add(Dense(X1.shape[1], kernel_initializer='glorot_normal', activation='relu', input_shape=(X1.shape[1],) ))\n# # model.add(Dropout(0.3))\n# model.add(Dense(30, kernel_initializer='glorot_normal', activation='relu'))\n\n# model.add(Dense(15, kernel_initializer='glorot_normal', activation='relu'))\n\n# # model.add(Dropout(0.3))\n# model.add(Dense(10, kernel_initializer='glorot_normal', activation='relu'))\n# # model.add(Dropout(0.3))\n# model.add(Dense(5, kernel_initializer='glorot_normal', activation='relu'))\n\n\n# model.add(Dense(2, kernel_initializer='glorot_normal', activation='softmax'))\n# model.compile(optimizer=optimizers.Adam(lr=1 * 1e-4), loss='categorical_crossentropy', metrics=['acc'])\n\n# model.summary()","7803769b":"# checkpoint_path = 'bestmodel2{epoch:02d}.hdf5'\n\n# checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n# # checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\n# scheduler = LearningRateScheduler(lambda epoch, lr: lr * 0.99, verbose=1)\n\n# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, mode='min', verbose=1)\n\n# tqdm_callback = tfa.callbacks.TQDMProgressBar(\n#     leave_epoch_progress=False, \n#     leave_overall_progress=True, \n#     show_epoch_progress=False,\n#     show_overall_progress=True\n# )\n\n# callbacks_list = [\n#     checkpoint,\n#     PlotLossesKeras(),\n#     scheduler, \n#     tqdm_callback, \n#     early_stop,\n# ]\n\n\n# history = model.fit(X1, Y1, batch_size=32, epochs=100, \n#                     callbacks=callbacks_list, verbose=0, validation_data=(X2, Y2))","865b424b":"# np.where(np.array(history.history['val_acc']) == max(history.history['val_acc']))[0]","4ac405e4":"# for ind in sorted(1 + np.where(np.array(history.history['val_acc']) == max(history.history['val_acc']))[0], reverse=True):\n#     if ind < 10:\n#         ind2 = f'0{ind}'\n#     else:\n#         ind2 = str(ind)\n        \n#     name_file = f'bestmodel2{ind2}.hdf5'\n#     if name_file in os.listdir():\n#         break","54eb64b9":"# name_file","30ffc78b":"name_file = '..\/input\/keras-model-for-titanic\/bestmodel224.hdf5'","5a08c8a0":"model = models.load_model(name_file)","379c31fa":"# np.array(history.history['val_acc'])[int(ind2) - 1]","4148db68":"train = pipe_all.fit_transform(df_train)\ntest = pipe_all.transform(df_test)\n\npred = model.predict(test).argmax(axis=1)","08729d8c":"submission = pd.DataFrame({\"Survived\": pred}, index=df_test.index)\nsubmission.to_csv(\"submission_nn.csv\")","e11d5bdd":"# parameters = {\n#     'model__iterations': range(500, 1100 + 25, 50),\n#     'model__max_depth': range(4, 7),\n#     'model__learning_rate': np.logspace(-3, -1, 7),\n#     'model__l2_leaf_reg': [2, 3, 4, 5],\n#     'model__loss_function': ['Logloss', 'CrossEntropy'],\n# #     'model__random_seed': [42],\n# #     'model__task_type': ['GPU']\n# }\n\ncatboost_model = CatBoostClassifier(verbose=False, random_state=42)\n\ncatboost_pipe = Pipeline([\n    ('features', pipe_all),\n    ('model',catboost_model)\n])\n\n# scoring = {\n#     'acc': 'accuracy'\n# }\n\n# gs = GridSearchCV(estimator=catboost_pipe, param_grid=parameters, scoring=scoring, \n#                   cv=10, refit='acc', \n#                   n_jobs=-1, \n#                   verbose=1)\n\n# gs.fit(df_train, Y_train, model__verbose=False, model__plot=False)","e4aae930":"gs_best_params = {\n    'model__iterations': 850,\n    'model__l2_leaf_reg': 3,\n    'model__learning_rate': 0.01,\n    'model__loss_function': 'Logloss',\n    'model__max_depth': 4,\n#     'model__verbose': [False]\n}","b87ebd8d":"catboost_pipe.set_params(**gs_best_params)\n\ncatboost_pipe.fit(df_train, Y_train)\n\npred = catboost_pipe.predict(df_test)","8a030e0f":"submission = pd.DataFrame({\"Survived\": pred}, index=df_test.index)\nsubmission.to_csv(\"submission_catboost.csv\")","c3308a64":"# parameters = {\n#     'model__n_estimators': range(600, 1000 + 50, 50),\n#     'model__max_features': np.arange(0.2, 0.9 + 0.1, 0.1),\n#     'model__max_depth': range(3, 8 + 1, 1),\n#     'model__min_samples_split': range(4, 5 + 1, 1)\n# }\n\nrandomforest_model = RandomForestClassifier(random_state=42)\n\nrandomforest_pipe = Pipeline([\n    ('features', pipe_all),\n    ('model',randomforest_model)\n])\n\n# scoring = {\n#     'acc': 'accuracy'\n# }\n\n# gs = GridSearchCV(estimator=randomforest_pipe, param_grid=parameters, scoring=scoring, \n#                   cv=10, refit='acc', \n#                   n_jobs=-1, \n#                   verbose=1)\n\n# gs.fit(df_train, Y_train)","ab169988":"gs_best_params = {\n    'model__max_depth': 7, \n    'model__max_features': 0.7000000000000002, \n    'model__min_samples_split': 4, \n    'model__n_estimators': 800\n}","786af217":"randomforest_pipe.set_params(**gs_best_params)\n\nrandomforest_pipe.fit(df_train, Y_train)\n\npred = randomforest_pipe.predict(df_test)","b7ba9ded":"submission = pd.DataFrame({\"Survived\": pred}, index=df_test.index)\nsubmission.to_csv(\"submission_forest.csv\")","7b54ce5a":"class CustomVoting(BaseEstimator, TransformerMixin):\n    def __init__(self, models, voting='soft', count_classes=2):\n        self.models = models\n        self.voting = voting\n        self.count = count_classes\n        \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        if self.voting == 'soft':\n            for_test = np.zeros((X.shape[0], self.count))\n            for i in range(len(self.models)):\n                for_test += self.models[i].predict_proba(X)\n\n            return np.argmax(for_test, axis=1)\n        \n        elif self.voting == 'hard':\n            for_test = np.zeros((X.shape[0], len(self.models)))\n            for i in range(len(self.models)):\n                for_test[:, i] += np.argmax(self.models[i].predict_proba(X), axis=1)\n\n            return np.int32(mode(for_test, axis=1)[0].T.flatten())","a83837ab":"lr_pipe['model'].fit(train, Y_train)\ncatboost_pipe['model'].fit(train, Y_train)\nrandomforest_pipe['model'].fit(train, Y_train)\n\nvoting = CustomVoting(models=[\n    lr_pipe['model'], \n    model, \n    catboost_pipe['model'], \n#     randomforest_pipe['model']\n], )\n\npred_voting = voting.fit_transform(test)","293a859b":"submission = pd.DataFrame({\"Survived\": pred_voting}, index=df_test.index)\nsubmission.to_csv(\"submission_voting.csv\")","9135a152":"voting = CustomVoting(models=[\n    lr_pipe['model'], \n    model, \n    catboost_pipe['model'], \n#     randomforest_pipe['model']\n], voting='hard')\n\npred_voting = voting.fit_transform(test)\n\nsubmission = pd.DataFrame({\"Survived\": pred_voting}, index=df_test.index)\nsubmission.to_csv(\"submission_voting_hard.csv\")","59e37ab2":"# Data","74dddbd4":"# Ensemble","65c9a1d9":"Fare is number feature","b4b5632c":"## Logistic Regression","817189fd":"## RandomForest","5e8ec598":"Pclass is categorical feature","8512bbd9":"Since an already trained Keras model cannot be turned into sklearn, I will write a custom voting:","fd909baf":"For keras online train","90c4884a":"Parch is categorical feature. After transfrom","6de6dcaa":"## Features","e1c117ce":"Ticket, I think, not important feature","f76085b4":"Since the training of the neural network is not reproducible, I will load the best model","bb01ea97":"## Nans","47b3b8e7":"Sibsp, Cabin, Parch - after transformations will become categorical\n\nSurvived - target","86e6c530":"## Keras Neural Network","96a983c5":"SibSp - categorical feature, that which you need to make a discrete categorical","42b59178":"I can try word embedding later. I'll delete it for now","45d5ee57":"2 values inside Sex, 3 values inside Pclass and Embarked","ca1dc37e":"# Models","c0580d65":"## Catboost","037050bc":"# Pipelines","1ca6224e":"Cabin is categorical feature. But first, it needs to be processed.","7111ccd8":"With RandomForest, the forecast is worse than without it:","7f1534a0":"Feature contains many NaN values => imputation","b977c43e":"Score = 0.78947","48ccaee2":"# Packages","e9d9b1bc":"Embarked is categorical feature"}}