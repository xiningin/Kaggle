{"cell_type":{"64e2cc22":"code","c621701b":"code","5c7967e7":"code","256a76c1":"code","8e405772":"code","b8eddb38":"code","815f4e71":"code","3ddd9d97":"code","a338554f":"code","b4aeb86a":"code","d2138de5":"code","df534a02":"code","f7cf8590":"code","f9f58baf":"code","2521d129":"code","0a5cda76":"code","9931373f":"code","cb247b83":"code","1f80847e":"code","e09af6e9":"code","33878f9f":"code","8f6e27d0":"code","2e041947":"code","3d36f308":"code","1b3251e9":"code","61c95b90":"code","0477af84":"code","1d6b66f1":"code","b1c385e5":"code","be9a56bf":"code","ad1ef9fa":"code","ac3a7587":"code","3f7745b2":"code","e1adc8d3":"code","9813e105":"code","aad22a06":"code","f3509f1a":"code","4f5f4252":"code","6b956799":"code","7a58a70b":"markdown","79bb1e0f":"markdown","739e245f":"markdown","cf28f6bb":"markdown","54001b5c":"markdown","fc22183e":"markdown","7e78e908":"markdown","fcfe6d2c":"markdown","d2758477":"markdown","76540cc7":"markdown","41796349":"markdown","8fb38abb":"markdown","7f043450":"markdown","27036d53":"markdown","e2f174a6":"markdown","7b5c3a6d":"markdown","a21d7215":"markdown"},"source":{"64e2cc22":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom sklearn.preprocessing import LabelEncoder\nlabenc = LabelEncoder()\nfrom sklearn.preprocessing import StandardScaler\nstdscal = StandardScaler()\nfrom sklearn.model_selection import train_test_split as tts\nfrom keras.models import Sequential\nseq = Sequential()\nfrom keras.layers import Dense,Activation,Dropout\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c621701b":"train_data = pd.read_csv('..\/input\/san-francisco-crime-classification\/train.csv')\ntrain_data.head()","5c7967e7":"test_data = pd.read_csv('..\/input\/san-francisco-crime-classification\/test.csv')\ntest_data.head()","256a76c1":"samp_sub = pd.read_csv('..\/input\/sample-submission\/sampleSubmission.csv')\nsamp_sub.head()","8e405772":"samp_sub.columns.value_counts().sum()","b8eddb38":"train_data['year'] = train_data['Dates'].apply(lambda x : x.split()[0].split('-')[0])\ntrain_data.head()","815f4e71":"train_data['Month'] = train_data['Dates'].apply(lambda x : x.split()[0].split('-')[1])\ntrain_data.head()","3ddd9d97":"train_data['Day'] = train_data['Dates'].apply(lambda x : x.split()[0].split('-')[2])\ntiming_train = train_data['Dates'].apply(lambda x : x.split()[1].split(':')[:2])\ntiming_train.head()","a338554f":"train_data['Timing'] = [int(x[0])*60 + int(x[1]) for x in timing_train]\ntrain_data.head()","b4aeb86a":"train_data.drop('Dates',axis = 1, inplace = True)","d2138de5":"test_data['Years'] = test_data['Dates'].apply(lambda x : x.split()[0].split('-')[0])\ntest_data['Months'] = test_data['Dates'].apply(lambda x : x.split()[0].split('-')[1])\ntest_data['Days'] = test_data['Dates'].apply(lambda x : x.split()[0].split('-')[2])\ntiming_test = test_data['Dates'].apply(lambda x : x.split()[1].split(':')[:2])\ntest_data['Timing'] = [int(x[0])*60 + int(x[1]) for x in timing_test]\ntest_data.head()","df534a02":"test_data.drop('Dates',axis = 1, inplace = True)","f7cf8590":"train_data.PdDistrict.value_counts().plot(kind = 'bar',figsize = (12,12))\nplt.show()","f9f58baf":"train_data.DayOfWeek.value_counts().plot(kind = 'bar',figsize = (12,12))\nplt.show()","2521d129":"train_data['Category'].value_counts().plot(kind = 'bar',figsize = (12,12))\nplt.ylabel('Numbers')\nplt.xlabel('Category of Crime')\nplt.show()","0a5cda76":"train_data['DayOfWeek'].replace(to_replace=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],value=[i for i in range(0,7)],inplace=True)\ntest_data['DayOfWeek'].replace(to_replace=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],value=[i for i in range(0,7)],inplace=True)\ntrain_data.head()","9931373f":"train_data['DayOfWeek'] = labenc.fit_transform(train_data['DayOfWeek'])\ntrain_data.head()","cb247b83":"test_data['DayOfWeek'] = labenc.fit_transform(test_data['DayOfWeek'])\ntest_data.head()","1f80847e":"train_data = pd.concat([train_data,pd.get_dummies(train_data['PdDistrict'])],axis = 1)\ntrain_data.drop('PdDistrict',axis = 1, inplace = True)\ntrain_data.head()","e09af6e9":"test_data = pd.concat([test_data,pd.get_dummies(test_data['PdDistrict'])],axis = 1)\ntest_data.drop('PdDistrict',axis = 1, inplace = True)\ntest_data.head()","33878f9f":"train_data.drop(['Descript','Resolution','Address'],axis = 1, inplace = True)\ntest_data.drop('Address',axis = 1, inplace = True)","8f6e27d0":"train_data[train_data[\"Y\"] == max(train_data[\"Y\"])]","2e041947":"stdscal.fit(train_data[[\"X\",\"Y\",\"Timing\"]]) \ntrain_data[[\"X\",\"Y\",\"Timing\"]]  = stdscal.transform(train_data[[\"X\",\"Y\",\"Timing\"]])\ntrain_data.head()","3d36f308":"stdscal.fit(test_data[[\"X\",\"Y\",\"Timing\"]]) \ntest_data[[\"X\",\"Y\",\"Timing\"]]  = stdscal.transform(test_data[[\"X\",\"Y\",\"Timing\"]])\ntest_data.head()","1b3251e9":"train_data[\"rot45_X\"] = .707* train_data[\"Y\"] + .707* train_data[\"X\"]\ntrain_data[\"rot45_Y\"] = .707* train_data[\"Y\"] - .707* train_data[\"X\"]\n\ntrain_data[\"rot30_X\"] = (1.732\/2)* train_data[\"X\"] + (1.\/2)* train_data[\"Y\"]\ntrain_data[\"rot30_Y\"] = (1.732\/2)* train_data[\"Y\"] - (1.\/2)* train_data[\"X\"]\n\ntrain_data[\"rot60_X\"] = (1.\/2)* train_data[\"X\"] + (1.732\/2)* train_data[\"Y\"]\ntrain_data[\"rot60_Y\"] = (1.\/2)* train_data[\"Y\"] - (1.732\/2)* train_data[\"X\"]\n\ntrain_data[\"radial_r\"] = np.sqrt( np.power(train_data[\"Y\"],2) + np.power(train_data[\"X\"],2) )\ntrain_data.head()","61c95b90":"test_data[\"rot45_X\"] = .707* test_data[\"Y\"] + .707* test_data[\"X\"]\ntest_data[\"rot45_Y\"] = .707* test_data[\"Y\"] - .707* test_data[\"X\"]\n\ntest_data[\"rot30_X\"] = (1.732\/2)* test_data[\"X\"] + (1.\/2)* test_data[\"Y\"]\ntest_data[\"rot30_Y\"] = (1.732\/2)* test_data[\"Y\"] - (1.\/2)* test_data[\"X\"]\n\ntest_data[\"rot60_X\"] = (1.\/2)* test_data[\"X\"] + (1.732\/2)* test_data[\"Y\"]\ntest_data[\"rot60_Y\"] = (1.\/2)* test_data[\"Y\"] - (1.732\/2)* test_data[\"X\"]\n\ntest_data[\"radial_r\"] = np.sqrt( np.power(test_data[\"Y\"],2) + np.power(test_data[\"X\"],2) )\ntest_data.head()","0477af84":"X = train_data.drop('Category',axis = 1)\ny = pd.get_dummies(train_data['Category'])\ny.head()","1d6b66f1":"X = X.astype(float)\nX.head()","b1c385e5":"X_train,X_test,y_train,y_test = tts(X,y,test_size=0.15,random_state=42)","be9a56bf":"seq.add(Dense(256, input_shape = (X.shape[1],)))\nseq.add(Dense(128))\nseq.add(Activation('selu'))\nseq.add(Dense(128))\nseq.add(Activation('selu'))\nseq.add(Dropout(0.5))\nseq.add(Dense(64))\nseq.add(Activation('selu'))\nseq.add(Dropout(0.5))\nseq.add(Dense(64))\nseq.add(Activation('selu'))\nseq.add(Dropout(0.5))\nseq.add(Dense(64))\nseq.add(Activation('selu'))\nseq.add(Dense(64))\nseq.add(Dropout(0.5))\nseq.add(Activation('selu'))\nseq.add(Dense(39))\nseq.add(Activation('softmax'))\nseq.summary()","ad1ef9fa":"seq.compile(optimizer='adam',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","ac3a7587":"train = seq.fit(X_train,y_train, \n         batch_size=32,\n         epochs=16,\n         verbose=2,\n         validation_data=(X_test,y_test))","3f7745b2":"test=test_data.drop(['Id'],axis=1)\ntest=test.astype(float)\ntest.dtypes","e1adc8d3":"pred=seq.predict(test)","9813e105":"m = np.max(pred, axis=1).reshape(-1, 1)\npredicted = np.array((pred == m), dtype='int32')\npredicted","aad22a06":"col_names=list(samp_sub.columns)\ncol_names.remove('Id')\nprint(col_names)","f3509f1a":"submission = pd.DataFrame()\nsubmission['Id'] = test_data['Id']\nfor i , entry in enumerate(col_names):\n    submission[entry] = predicted[:,i]","4f5f4252":"submission.head()","6b956799":"submission.to_csv('..\/working\/submission.csv', index=False)","7a58a70b":"Creating a new data column with the title \"dar\" in the train_data dataframe and creating a new dataframe timing_train to extract time from \"Dates\" column","79bb1e0f":"Replacing the days of week with numbers for the days Monday to Sunday with the range of numbers from 0 to 7","739e245f":"Adding all the colummns which were added into train_data into test_data as well","cf28f6bb":"Implementing Principal Component Analysis (PCA) method of unsupervised learning with the help of train_data dataframe to train our model","54001b5c":"Plotting bar graphs to represent the data of district wise crime counts from train_data dataframe","fc22183e":"Creating a new data column with the title \"month\" in the train_data dataframe","7e78e908":"Collecting the datasets and assigning them variable names","fcfe6d2c":"Creating a new data column with the title \"year\" in the train_data dataframe","d2758477":"Compiling our model in order to fit in the training data","76540cc7":"Plotting bar graph of category of crime and numbers for each of them using train_data","41796349":"Creating a new data column with the title \"Timing\" in the train_data dataframe with the help of timing_train dataframe","8fb38abb":"Entering our predictions dataset into a new submission dataframe for the final output csv file generation ","7f043450":"Plotting bar graphs to represent the data of day wise crime counts in a week from train_data dataframe","27036d53":"Using the test_data dataframe to get the prediction outputs from our trained model","e2f174a6":"Exporting our final submission.csv file as output into the kaggle working directory","7b5c3a6d":"Training our model using train_data dataframe","a21d7215":"Importing all the necessary packages"}}