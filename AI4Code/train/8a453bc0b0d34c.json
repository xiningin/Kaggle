{"cell_type":{"8da15d36":"code","f5b3db0c":"code","30cbed70":"code","91d68d23":"code","8a6d6e3e":"code","1aee74ff":"code","98f045a0":"code","f5b6b223":"markdown","2bf928f5":"markdown","ca5d9eb1":"markdown","93d341d8":"markdown"},"source":{"8da15d36":"import numpy as np\nimport nltk\nnltk.download('punkt')\n\n\nfrom nltk.stem.porter import PorterStemmer\nstemmer=PorterStemmer()\n\ndef token_ize(sentence):\n    # tokenize each sentence by splitting from \" \" \n    return nltk.word_tokenize(sentence)\n\n\ndef stemming(word):\n    return stemmer.stem(word.lower())\n\ndef b_o_w(tokenize_sentence,list_of_words):\n    \"\"\"\n    Parameters\n    ----------\n    tokenize_sentence : [\"hi\",\"how\",\"are\",\"you\"]\n        result of tokenizer \n    list_of_words : [\"hi\",\"bye\",\"how\",\"are\",\"you\"]\n        bag of all words\n    Returns\n    -------\n    list with [1,0,1,1,1]\n    \"\"\"\n    stemmed=[stemming(w) for w in tokenize_sentence]\n    bag=np.zeros(len(list_of_words),dtype=np.float32)\n    for idx,word in enumerate(list_of_words):\n        if word in stemmed:\n            bag[idx]=1.0\n    return bag\n","f5b3db0c":"import torch\nimport torch.nn as nn\n\nclass ChatNet(nn.Module):\n  def __init__(self,input_size,classes):\n    super().__init__()\n    self.l1=nn.Linear(input_size,128)\n    self.l2=nn.Linear(128,64)\n    self.l3=nn.Linear(64,32)\n    self.l4=nn.Linear(32,classes)\n    self.d0=nn.Dropout(p=0.1)\n    self.relu=nn.ReLU()\n\n\n  def forward(self,x):\n    out=self.l1(x)\n    out=self.relu(out)\n    out=self.l2(out)\n    out=self.relu(out)\n    out=self.l3(out)\n    out=self.relu(out)\n    out=self.d0(out)\n    out=self.l4(out)\n\n    return out\n","30cbed70":"import json\nwith open(\"..\/input\/chatbot-dataset-for-transport-rental-agency\/intents.json\",\"r\") as f:\n  intents = json.load(f)","91d68d23":"import numpy as np\nimport random\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# Separating required field from dictionary\nall_words=[]\ntags=[]\nx_y=[]\n\nfor intent in intents[\"intents\"]:\n  t=intent[\"tag\"]\n  tags.append(t)\n  for i in intent[\"patterns\"]:\n    each_word=token_ize(i)\n    all_words.extend(each_word)\n    x_y.append((each_word,t))\n\n# stem and lower each word\nignore_words = ['?', '.', '!']\nall_words = [stemming(w) for w in all_words if w not in ignore_words]\n# remove duplicates and sort\nall_words = sorted(set(all_words))\ntags = sorted(set(tags))\n\n\n# create training data\nX_train = []\ny_train = []\nfor (pattern_sentence, tag) in x_y:\n    # X: bag of words for each pattern_sentence\n    bag = b_o_w(pattern_sentence, all_words)\n    X_train.append(bag)\n    # y: Label index\n    label = tags.index(tag)\n    y_train.append(label)\n\nX_train = np.array(X_train)\ny_train = np.array(y_train)\n\n\n\n# Hyper-parameters \nnum_epochs = 1000\nbatch_size = 8\nlearning_rate = 0.0001\ninput_size = len(X_train[0])\noutput_size = len(tags)\nprint(input_size, output_size)\n\n\n\nclass Chat_Dataset(Dataset):\n\n    def __init__(self):\n        self.n_samples = len(X_train)\n        self.x_data = X_train\n        self.y_data = y_train\n\n    # support indexing such that dataset[i] can be used to get i-th sample\n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n\n    # we can call len(dataset) to return the size\n    def __len__(self):\n        return self.n_samples\n\n\n\ndataset = Chat_Dataset()\ntrain_loader = DataLoader(dataset=dataset,\n                          batch_size=batch_size,\n                          shuffle=True,\n                          num_workers=0)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = ChatNet(input_size, output_size).to(device)\n\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\nfor epoch in range(num_epochs):\n  for words,labels in train_loader:\n\n    words=words.to(device)\n    labels = labels.to(dtype=torch.long).to(device)\n\n    outputs = model(words)\n\n    loss = criterion(outputs, labels)\n\n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if (epoch+1) % 100 == 0:\n        print (f'Epoch [{epoch+1}\/{num_epochs}], Loss: {loss.item():.4f}')\n\n\nprint(f'final loss: {loss.item():.4f}')\n","8a6d6e3e":"!mkdir \/tmp\/Chatbot_Transport_Rental","1aee74ff":"data = {\n\"model_state\": model.state_dict(),\n\"input_size\": input_size,\n\"output_size\": output_size,\n\"all_words\": all_words,\n\"tags\": tags\n}\n\nFILE = \"\/tmp\/Chatbot_Transport_Rental\/data.pth\"\ntorch.save(data, FILE)\n\nprint(f'training complete. file saved to {FILE}')","98f045a0":"import random\nimport json\n\nimport torch\n\n#from model import NeuralNet\n#from nltk_utils import bag_of_words, tokenize\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nwith open('..\/input\/chatbot-dataset-for-transport-rental-agency\/intents.json', 'r') as json_data:\n    intents = json.load(json_data)\n\nFILE = \"\/tmp\/Chatbot_Transport_Rental\/data.pth\"\ndata = torch.load(FILE)\n\ninput_size = data[\"input_size\"]\noutput_size = data[\"output_size\"]\nall_words = data['all_words']\ntags = data['tags']\nmodel_state = data[\"model_state\"]\n\nmodel = ChatNet(input_size,output_size).to(device)\nmodel.load_state_dict(model_state)\nmodel.eval()\n\nbot_name = \"Sammy\"\nprint(\"Let's chat! (type 'quit' to exit)\")\nwhile True:\n    # sentence = \"do you use credit cards?\"\n    sentence = input(\"You: \")\n    if sentence == \"quit\":\n        break\n\n    sentence = token_ize(sentence)\n    X = b_o_w(sentence, all_words)\n    X = X.reshape(1, X.shape[0])\n    X = torch.from_numpy(X).to(device)\n\n    output = model(X)\n    _, predicted = torch.max(output, dim=1)\n\n    tag = tags[predicted.item()]\n\n    probs = torch.softmax(output, dim=1)\n    prob = probs[0][predicted.item()]\n    if prob.item() > 0.6:\n        for intent in intents['intents']:\n            if tag == intent[\"tag\"]:\n                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n    else:\n        print(f\"{bot_name}: I do not understand...\")","f5b6b223":"### **nltk_utils.py**\n#### This includes nltk package","2bf928f5":"### **Chat.py**","ca5d9eb1":"### **train.py**\n#### These include dataset, dataloader and neural trainer, model saver","93d341d8":"### **model.py**"}}