{"cell_type":{"66555f3b":"code","24482b43":"code","c69b6299":"code","a773e4ad":"code","4dea5bcb":"code","1395dd3d":"code","5416e681":"code","78be8bc3":"code","816bb762":"code","6ec01229":"code","e837493d":"markdown","ff5c63e0":"markdown","7c5bc9d7":"markdown","ea419ce1":"markdown"},"source":{"66555f3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24482b43":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [20,8]\nimport seaborn as sns","c69b6299":"df=pd.read_csv('..\/input\/weatherww2\/Summary of Weather.csv',nrows=4908)\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='Dark2')#yellowgreenblue","a773e4ad":"df = df.replace([0,' ','NULL'],np.nan)\ndf.dropna(thresh=df.shape[0]*0.6,how='all',axis=1,inplace=True)\ndf.dropna(inplace=True)\ndf.drop(['Date'],axis=1,inplace=True)\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='Dark2')#yellowgreenblue\ndisplay(df.sample(2))","4dea5bcb":"dfCorr = df.corr()\nfilteredDf = dfCorr[((dfCorr >= 0.5) | (dfCorr <= -1)) & (dfCorr !=1.000)]\nplt.figure(figsize=(15,8))\nsns.heatmap(filteredDf, annot=True, cmap=\"Reds\")\nplt.show()","1395dd3d":"from sklearn.model_selection import train_test_split\n# Split data as %20 is test and %80 is train set\n\nX=df[['MaxTemp']]\ny=df[['MAX']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\nfrom sklearn.linear_model import LinearRegression\n\nlin_df = LinearRegression()  \nlin_df.fit(X_train, y_train)\ny_pred = lin_df.predict(X_test)                                     # Predict Linear Model\naccuracy_score = lin_df.score(X_test, y_test)                       # Accuracy score\nprint(\"Linear Regression Model Accuracy Score: \" + \"{:.1%}\".format(accuracy_score))\n\nfrom sklearn.metrics import mean_squared_error,r2_score\n\nprint(\"\\nR2 Score: \" +\"{:.3}\\n\".format(r2_score(y_test, y_pred)));\n\n# Finally draw figure of Linear Regression Model\n\nplt.scatter(X_test, y_test, color='r')\nplt.plot(X_test, y_pred, color='g')\nplt.show()\n\n# plt.scatter(y_test,y_pred, color='r')\n# plt.plot(y_test,y_pred, color='g')\n# plt.show()","5416e681":"df.cov()","78be8bc3":"df1=df.sample(df.shape[1])\nnp.linalg.eigvals(df1.apply(pd.to_numeric, errors='coerce').fillna(0))","816bb762":"from numpy import linalg as LA\ndef eigen(X):\n    weight1, value1 = LA.eig(X)\n    print(weight1,'\\n\\n',value1)\neigen(df1.apply(pd.to_numeric, errors='coerce').fillna(0))","6ec01229":"# Eigen vector in decreasing order of magnitude of Eigen values.\nfrom numpy import linalg as LA\ndef eigen(X):\n    weight1, value1 = LA.eig(X)\n    index=weight1.argsort()[::-1]\n    print([{weight1[i]:value1[i]} for i in index])\neigen(df1.apply(pd.to_numeric, errors='coerce').fillna(0))","e837493d":"# Linear Regression","ff5c63e0":"# Reference \n\nhttps:\/\/www.kaggle.com\/mathchi\/1-lr-mlr-pr-dt-rf-predict-data-calcofi#2.Multiple-Linear-Regression","7c5bc9d7":"#  Eigen value and Eigen vector ","ea419ce1":"# covariance matrix"}}