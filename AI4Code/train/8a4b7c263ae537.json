{"cell_type":{"278edbe9":"code","2c7b4cdd":"code","0e2935a7":"code","2549ce3a":"code","a25ecc9f":"code","f29dbbcf":"code","38de4da8":"code","2073476a":"code","a1599389":"code","a8b37c62":"code","bd4eb0be":"code","c8653fba":"code","a7a9562e":"code","0bf6c51b":"markdown","d3fa09f0":"markdown","c76e2b35":"markdown","7cb425be":"markdown","145911ba":"markdown","6f29cbc5":"markdown","e343c9e4":"markdown"},"source":{"278edbe9":"import torch\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm\n\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\nimport glob\nimport os\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset","2c7b4cdd":"df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\n# val = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ndf['Pawpularity'] = df['Pawpularity']\/100","0e2935a7":"df.groupby('Pawpularity').count().plot.bar(y='Id', figsize=(15,10), xticks=np.linspace(0,100,51), rot=0, xlabel='Pawpularity score', ylabel='Counts', \\\n                                           title='Distribution of scores by sample counts');","2549ce3a":"paths100 = []\nfor _id in df[df['Pawpularity'] == 1]['Id']:\n    paths100.append(os.path.join('..\/input\/petfinder-pawpularity-score\/train', _id + '.jpg'))\n\nfig, axes = plt.subplots(5,5,figsize=(10,10))\nfig.tight_layout()\nfor p, ax in zip(np.random.choice(paths100, size=5*5), axes.ravel()):\n    image = cv2.imread(p, cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n    image \/= 255.0\n    ax.imshow(image)\n    ax.axis('off')\naxes.ravel()[2].set_title('Score 100');","a25ecc9f":"pathsnot100 = []\nfor _id in df[df['Pawpularity'] != 1]['Id']:\n    pathsnot100.append(os.path.join('..\/input\/petfinder-pawpularity-score\/train', _id + '.jpg'))\n\nfig, axes = plt.subplots(5,5,figsize=(10,10))\nfig.tight_layout()\nfor p, ax in zip(np.random.choice(pathsnot100, size=5*5), axes.ravel()):\n    image = cv2.imread(p, cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n    image \/= 255.0\n    ax.imshow(image)\n    ax.axis('off')\naxes.ravel()[2].set_title('Score not 100');","f29dbbcf":"train, val = train_test_split(df, test_size=0.2, stratify=df['Pawpularity']==1.0)","38de4da8":"train.head()","2073476a":"class PetDataset(Dataset):\n    def __init__(self, dataframe, transforms=None):\n        self.dataframe = dataframe\n        self.transforms = transforms\n        self.path = '..\/input\/petfinder-pawpularity-score\/train'\n\n    def __getitem__(self, index):\n        \n        image_path = os.path.join(self.path, self.dataframe.iloc[index].Id + '.jpg')\n        target = self.dataframe.iloc[index].Pawpularity\n        \n        # meta = np.array(self.dataframe.iloc[index,1:-1], dtype=np.int8)\n        \n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n        else:\n            image = torch.tensor(image, dtype=torch.float32)\n        targt = torch.as_tensor(target, dtype=torch.float32)\n        # meta = torch.as_tensor(meta, dtype=torch.float32)\n        # targt = torch.as_tensor(np.hstack((meta,target)), dtype=torch.float32)\n        return image, targt\n        \n    def __len__(self):\n        return len(self.dataframe)","a1599389":"train_transform = A.Compose(\n    [\n        A.Resize(224, 224),# 224\n        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20, p=0.5),\n        A.RGBShift(r_shift_limit=0.05, g_shift_limit=0.05, b_shift_limit=0.05, p=0.5),\n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)\n\nval_transform = A.Compose(\n    [\n        A.Resize(224, 224),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)\n\ntrain_dataset = PetDataset(train, train_transform)\nval_dataset = PetDataset(val, val_transform)","a8b37c62":"train_loader = DataLoader(\n    train_dataset,\n    batch_size=16,\n    shuffle=True,\n    pin_memory=True,\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=8,\n    shuffle=False,\n    pin_memory=True,\n)","bd4eb0be":"dataset = PetDataset(train)\ndef visualize(dataset):\n    fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(10,10))\n    axes = ax.ravel()\n    for i, (X, y) in enumerate(dataset):\n        if i < len(axes):\n            axes[i].imshow(X)\n            axes[i].set_title(y)\n            axes[i].axis('off')\n        else:\n            break\n\nvisualize(dataset)","c8653fba":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = timm.create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=1).to(device)\n\n# pretrain head first for faster convergence\nfor p in model.parameters():\n    p.requires_grad_(False)\n\nfor p in model.head.parameters():\n    p.requires_grad_(True)\n\ncriterion = torch.nn.BCEWithLogitsLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\nmilestones = [1,2,3]\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1, verbose=True)\nscheduler_reduce = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)\nnum_epochs = 20","a7a9562e":"train_loader_len = len(train_loader)\nval_loader_len = len(val_loader)\nbest_rmse = 1000\nPAT = 5\n\nfor epoch in range(1, num_epochs + 1):\n    \n    model.train()\n    closs = 0\n    \n    for X, y in train_loader:\n        X, y = X.to(device), y.to(device).view(-1,1)\n        model_output = model(X)\n        loss = criterion(model_output, y)\n        closs += loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    print(f\"Epoch {epoch}\\nLoss {closs\/train_loader_len:0.5f}\")\n    \n    model.eval()\n    crmse = 0\n    with torch.no_grad():\n        for X, y in val_loader:\n            X, y = X.to(device), y.to(device).view(-1,1)\n            model_output = model(X)\n            rmse = 100*torch.sqrt(F.mse_loss(torch.sigmoid(model_output), y))\n            crmse += rmse.item()\n            \n    mean_rmse = crmse\/val_loader_len\n    print(f\"Mean rmse {mean_rmse:0.5f}\\n\")\n    \n    scheduler.step()\n    scheduler_reduce.step(mean_rmse)\n    \n    if epoch == milestones[-1]:\n        print('Unfreeze all')\n        for p in model.parameters():\n            p.requires_grad_(True)\n    if mean_rmse <= best_rmse:\n        patience = 0\n        best_rmse = mean_rmse       \n        print(f\"Save with best_rmse {best_rmse}\")\n        torch.save(model.state_dict(), 'my_model.pth')\n    else:\n        if patience >= PAT:\n            break\n        else:\n            patience += 1","0bf6c51b":"# What's happening here?\nIn this nootebook I will show you simple basic idea so far that gives rmse 18.6  \nWhat I've done before and it didn't work out:  \n- Use metadata and score data in two heads of NN (the idea is to help backbone coefficients change to right way to predict score)\n    - Use MSE for score and BCE for meta\n- Tried to create NN for dividing score to 3 parts (0-33, 34-66, 67-100) and then learn 3 different NN for predicting score in this intervals.\n    - The problem was that it's not much difference between the pictures, so it can't be divided into score groups in efficient way.  \n\nSearching public notebooks we can see this way of solving the problem:\n- Normalize score from 0 to 1\n- Dont use metadata\n- Use vision transformer as base NN\n- Use BCE as loss function","d3fa09f0":"### But I wanted to do some simple EDA and what I've find out","c76e2b35":"### After many tries I found out good LR ","7cb425be":"#### What to do next?  \n#### I think that key for better score is ensembling methods of this idea","145911ba":"### As I expected I can't see particular difference between them. But when we will do train\/test split we will use this information","6f29cbc5":"### Here above we can see a big bias in score of 100. Let's see if it's images are different form other scores","e343c9e4":"# PLEASE UPVOTE THIS NOTEBOOK IF IT WAS USEFUL FOR YOU :)"}}