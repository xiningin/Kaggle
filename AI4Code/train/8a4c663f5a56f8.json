{"cell_type":{"1461dfa5":"code","f4eb0fe6":"code","b90004f7":"code","4d13a0de":"code","46292619":"code","c8084967":"code","aec9be0c":"code","35c862b5":"code","caef4766":"code","1aca167f":"code","918e2f5f":"code","d8eb0dc3":"code","d6b1e243":"code","dc7bd87d":"code","94669c09":"code","6cfe3580":"code","3a234ecd":"code","7f60f20e":"code","9079730a":"code","ce18b8de":"code","c4ab1555":"code","5960002f":"code","eda8c1d7":"code","bb5b7e97":"code","f6696792":"code","94a7dafd":"code","eff2a75a":"code","8e885d5e":"code","cb333d2d":"code","9f7a42cd":"code","c9403e72":"code","aeb76ba1":"code","8382774d":"code","63881f93":"code","60c91e58":"code","36878d7a":"code","ccec7a02":"code","a776006f":"code","314f40ed":"code","b4fa714c":"code","6853eb09":"code","f60c8cba":"code","24fdaa46":"code","660f6ae9":"code","8140a37e":"code","5c4b7c5d":"code","0588d588":"code","0ed019c7":"markdown","8a666107":"markdown","aef267e7":"markdown","f3927a3d":"markdown","2ba0b353":"markdown","f3f3b837":"markdown","d7395e88":"markdown","531130f1":"markdown","657cf467":"markdown","2785260c":"markdown","7072b31e":"markdown","5923130e":"markdown","ad567a76":"markdown","ed5edddf":"markdown","ef9af936":"markdown"},"source":{"1461dfa5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4eb0fe6":"data = pd.read_csv(r'\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv(r'\/kaggle\/input\/titanic\/test.csv')","b90004f7":"data.head(2)","4d13a0de":"test.head(2)","46292619":"data.describe()","c8084967":"data.isnull().sum()","aec9be0c":"sns.heatmap( data.isnull() , yticklabels = False , cbar = False , cmap = 'Blues')\n\n#20% of age is missing , small % so we can replace it ","35c862b5":"import matplotlib.pyplot as plt\nimport seaborn as sns","caef4766":"sns.set_style('white')\n#You this function to remove grid from background of your graphs \n# I dont like grid in my bg  so i have removed them ","1aca167f":"sns.countplot( x= 'Survived' , data = data)\n\n# Around 62% passengers travelling in titanic died ","918e2f5f":"sns.countplot( x= 'Survived' ,hue= 'Sex',  data = data)\n\n# Maximum passenger who died were Male and maximum who survived were female ","d8eb0dc3":"sns.countplot( x= 'Survived' , hue= 'Pclass', data = data)\n\n# maximum passenger travelling from 3rd class died while max passenger from first class survived ","d6b1e243":"#lets see the age range for these passengers\n\nsns.displot(data['Age'] , kde= False)\n# Graph is skewed towards younger people , and a goon peak for small children from ae 0-10 and 20-35","dc7bd87d":"sns.countplot(x='SibSp' , data = data)\n\n#maximum passenger travelling were single without family and second most highest has 1 , that could be a spouse\/partner  \n## majority doesnt have children or spouse on board","94669c09":"sns.displot( data['Fare'] , kde = False, bins = 10)\n#Since majority travelled in 3rd class , so majority fare is between 0-150$\n#Considering these fare data was from titanic time , price seems okay for second and third class ","6cfe3580":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Pclass' , y= 'Age' , data = data )","3a234ecd":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 3:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24 \n        \n    else: \n      return Age","7f60f20e":"data['Age'] = data[['Age' , 'Pclass']].apply(impute_age , axis= 1)","9079730a":"data.isnull().sum()","ce18b8de":"data = data.drop('Cabin' , axis =1 )\n#As 80% cabin data is missing , we will drop the column ","c4ab1555":"data.isnull().sum()","5960002f":"data.dropna(inplace = True)\ndata.isnull().sum()","eda8c1d7":"test.isnull().sum()","bb5b7e97":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Pclass' , y= 'Age' , data = test )","f6696792":"def impute_test_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 3:\n            return 42\n        elif Pclass == 2:\n            return 26\n        else:\n            return 24 \n        \n    else: \n      return Age","94a7dafd":"test['Age'] = test[['Age' , 'Pclass']].apply(impute_test_age , axis= 1)","eff2a75a":"test.isnull().sum()","8e885d5e":"test['Fare'].fillna(test['Fare'].mean(), inplace=True)","cb333d2d":"test.isnull().sum()","9f7a42cd":"sex_train = pd.get_dummies( data['Sex'] , drop_first = True)\nsex_test = pd.get_dummies( test['Sex'] , drop_first = True)","c9403e72":"sex_train","aeb76ba1":"sex_test","8382774d":"embarked_train = pd.get_dummies(data['Embarked'] , drop_first = True)\nembarked_test = pd.get_dummies(test['Embarked'] , drop_first = True)\n","63881f93":"pclass_train = pd.get_dummies(data['Pclass'] , drop_first = True)\npclass_test = pd.get_dummies(test['Pclass'] , drop_first = True)","60c91e58":"data = pd.concat([data,sex_train , embarked_train , pclass_train ] , axis= 1)\ntest = pd.concat([test,sex_test , embarked_test , pclass_test] , axis= 1)","36878d7a":"data.head(2)","ccec7a02":"data= data.drop(['PassengerId' , 'Name' , 'Ticket' , 'Sex' , 'Embarked'], axis = 1 )","a776006f":"test = test.drop([ 'Name' , 'Ticket' , 'Sex' , 'Embarked'], axis = 1 )","314f40ed":"data","b4fa714c":"test = test.drop('Cabin' , axis = 1)\n","6853eb09":"from sklearn.model_selection import train_test_split\n\nx = data.drop(['Survived'], axis=1)\ny = data[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3 , random_state = 0)","f60c8cba":"from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression(solver='lbfgs', max_iter=500 )\nlog_reg.fit(x_train, y_train )\n","24fdaa46":"y_pred = log_reg.predict(x_test)","660f6ae9":"from sklearn.metrics import accuracy_score , confusion_matrix\n\naccuracy_score(y_pred, y_test)","8140a37e":"confusion_matrix(y_pred, y_test)","5c4b7c5d":"predictions = log_reg.predict(test.drop('PassengerId', axis=1))","0588d588":"\n#set ids as PassengerId and predict survival \ncust_id = test['PassengerId']\noutput = pd.DataFrame({ 'PassengerId' : cust_id ,  'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","0ed019c7":"1. passengers travelling in First class were older and have average age around 37\n2. passengers travelling in second class has average about 29 \n3. passengers travelling in third class are young crowd , average age about 24","8a666107":"# Prepare Submission File\nWe make submissions in CSV files. Submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the housing data is the string 'Id'). The prediction column will use the name of the target field.\n\nWe will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file.","aef267e7":"**We will solve this problem in 5 simple steps : **\n* 1. Gather and load the data (using kaggle input command)\n* 2. Visualize and gain better insights from the data \n* 3. Perform some data cleaning - fix null and missing values using imputation and treat categorical variables \n* 4. Build the LR model \n* 5. Evaluate the performance of model created","f3927a3d":"# Turn Categorical columns into Numerical encoding \n\nOne Hot Encoding, one of the most useful techniques that a data scientist can know. This techniques label encodes categorical columns resulting in a 1 if the value is true, with all associated values in that row taking value 0. ","2ba0b353":"# Step 5: We will evaluate the performance of model built ","f3f3b837":"***Train data is cleaned now*****","d7395e88":"# **Step 1 : Gather and load the data into our notebook **","531130f1":"**We can see we have around 20% amount of missing data for AGE and around 80% data is missing for Cabin **","657cf467":"# **Step 3: Data Cleaning **","2785260c":"# **Step 2: Visualize the data **","7072b31e":"#  Step 4: Build the model ","5923130e":"* We have already checked that 20% of age is missing from our data \n* Age could be a important factor in determining Survival , so we can't drop the column \n* Instead we will create a imputation function ","ad567a76":"# Imputing Test data Age","ed5edddf":"**If this notebook helped you to publish or solve the problem:**\n* **Do UPVOTE **\n* *Share the link of this document in your notebook for reference :D*","ef9af936":"**Age missing null values are imputed now **"}}