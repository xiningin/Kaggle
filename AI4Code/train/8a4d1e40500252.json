{"cell_type":{"09c8cb45":"code","4d00a4b0":"code","b82dcfd6":"code","46bb7cf0":"code","f8c8c8dd":"code","44f523c4":"code","0552b02f":"code","5befe94f":"code","39ef1881":"code","dc028a35":"code","bb51322a":"code","97bc0878":"code","6653d35b":"code","3e6c3b54":"code","e60762a7":"code","046a325f":"code","81c0d638":"code","0f9ff61c":"code","4151d0cf":"code","0a05e997":"code","4717831d":"code","f9e6147b":"code","a908b7dc":"code","09d54893":"code","6b5392fa":"code","3ad94773":"code","cf25bc33":"code","cc82352e":"code","c1ab25e0":"code","1e413b79":"code","a9aecd94":"code","c1e13ff3":"code","55abe69f":"code","77091eca":"code","a13c719c":"code","3bc1f33f":"code","e97ea475":"code","860d8d8a":"code","159e5ceb":"code","7c6b28c6":"code","a24d9939":"code","1e3fa425":"code","7a6f23d0":"code","8cd590c3":"code","b7732e1e":"code","a97d6c57":"code","fd464e5c":"code","d3690cb8":"code","7ab1a875":"code","8bd47411":"code","d7ff94e4":"code","c8e2dbe0":"code","3d57871e":"code","8975d832":"code","48619c8d":"code","0085faeb":"code","44363d3e":"code","86b90bda":"code","cf25cacb":"code","753d5759":"code","2452a673":"code","92e3fcf5":"code","b4acde79":"code","f98d73de":"code","fbcd7a01":"code","9729d177":"code","132f2b3e":"code","a8cb690c":"code","fd550283":"code","22a9febd":"code","196fcdbf":"code","a5154bee":"code","6e51b464":"code","2198d288":"code","fdc51493":"code","4a774c35":"code","3f35b85e":"code","414d23b8":"code","b83eac9d":"code","bbf8ed28":"code","186fc110":"code","b4e12820":"code","960f4178":"code","af91aa16":"code","0cc6e0f1":"code","59f439d5":"code","e2af4d29":"code","e305fc94":"code","94131f4c":"code","2ffa769d":"markdown","b281a751":"markdown","fe963ef8":"markdown","3de285d8":"markdown","ed664e96":"markdown","4bda22d4":"markdown","706bc744":"markdown","7a831f49":"markdown","899f755d":"markdown","f80a2e54":"markdown","149a821e":"markdown","9a9a0ed1":"markdown","27c14ed7":"markdown","b8a77a3a":"markdown","d77d6321":"markdown","e894d409":"markdown","2d2b0eff":"markdown","1408df62":"markdown","3d2eb23a":"markdown","dc7784ce":"markdown","de6e95a1":"markdown","59458cd2":"markdown","20ab04f9":"markdown","16e95fa3":"markdown","40ed0f85":"markdown","02b0c0b5":"markdown","44db8f8b":"markdown","72865d1e":"markdown","1d1adaa2":"markdown","2c2daca1":"markdown","c7615077":"markdown","c48a88f4":"markdown","3bc246a4":"markdown","cac61098":"markdown","461df9a6":"markdown","3fc25d2d":"markdown","d4aa36b1":"markdown","cc0cda82":"markdown","bfa5c019":"markdown","1b6fd5c7":"markdown","0e1bd94f":"markdown","08527ade":"markdown","5dc0cb58":"markdown","fae6732f":"markdown","225f6910":"markdown","2ca9e9ad":"markdown","27d0ea86":"markdown","6c444866":"markdown","4fa383ce":"markdown","eceac866":"markdown","af7197ae":"markdown","6c7fa961":"markdown","1172b108":"markdown","3fb48d61":"markdown","f65b7ead":"markdown","99588c36":"markdown","cfc24e6e":"markdown","63903b58":"markdown","e16199ae":"markdown","c454a352":"markdown","7653d662":"markdown","e76afb0d":"markdown","1b397795":"markdown","63c4642f":"markdown","3073b15c":"markdown","5c7920c0":"markdown","ab5fee6d":"markdown","b5f7ab7b":"markdown","cda7bcb1":"markdown"},"source":{"09c8cb45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d00a4b0":"import datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as ply\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport tensorflow as tf\nimport shap","b82dcfd6":"dataset= pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')\ndataset.head()","46bb7cf0":"# Checking Missing values\ndataset.isna().sum()","f8c8c8dd":"# Identifying datatypes and shape of training dataset\nprint(dataset.shape)\ndataset.dtypes","44f523c4":"# Drop ID\ndataset.drop(labels='id',axis=1,inplace=True)\ndataset.head()","0552b02f":"# numeric features in dataset\ndataset_num_features = ['Age', 'Region_Code','Annual_Premium','Policy_Sales_Channel','Vintage']\n\n#Catagorical features dataset\ndataset_cat_features = ['Gender','Driving_License','Previously_Insured','Vehicle_Age','Vehicle_Damage']","5befe94f":"print(dataset_num_features)","39ef1881":"dataset[dataset_num_features].describe()","dc028a35":"for i in dataset_num_features:   \n    plt.figure(figsize=(10,8),dpi=100)\n    sns.violinplot(x=\"Response\",y=i, data=dataset)\n    plt.title(f\"Response by {i}\")\n    plt.show()","bb51322a":" \n\n# Age\nAge_range = pd.Series(pd.cut(dataset.Age, bins = 6, precision = 0),name='Age_range')\n\n# Region_Code\nRegion_Code_range = pd.Series(pd.cut(dataset.Region_Code, bins = 10, precision = 0),name='Region_Code_range')\n\n#Annual_Primium\nAnnual_Primium_range = pd.Series(pd.cut(dataset.Annual_Premium, bins = 5, precision = 0),name='Annual_Primium_range')\n\n#Policy_Sales_Channel\nPolicy_Sales_Channel_range = pd.Series(pd.cut(dataset.Policy_Sales_Channel,bins = 10, precision = 0),name='Policy_Sales_Channel_range')\n\n#Vintage\nVintage_range =pd.Series(pd.cut(dataset.Vintage,bins = 5, precision = 0),name='Vintage_range')","97bc0878":"# Modified Categorical Dataset:\n\nmod_dataset = pd.concat([Age_range,\n                Region_Code_range,\n                Annual_Primium_range,\n                Policy_Sales_Channel_range,\n                Vintage_range], \n               axis=1)\n\nprint('Modified Dataset Shape :', mod_dataset.shape,'\\n______________________________________\\n')\nprint('New Columns:',mod_dataset.columns,'\\n______________________________________\\n' )\nprint(mod_dataset.dtypes,'\\n______________________________________\\n')\n\nmod_dataset.head()","6653d35b":"#Age_range\nplt.figure(figsize=(10,7),dpi=300)\nsns.countplot(x=Age_range, hue=dataset.Response)\nplt.xticks()\nplt.xlabel('Age_range',fontsize=14)\nplt.ylabel('Count',fontsize=14)\nplt.show()\n\n#Region_Code_range\nplt.figure(figsize=(10,7),dpi=300)\nsns.countplot(x=Region_Code_range, hue=dataset.Response)\nplt.xticks(fontsize=8)\nplt.xlabel('Region_Code_range',fontsize=14)\nplt.ylabel('Count',fontsize=14)\nplt.show()\n\n#Annual_Primium_range\nplt.figure(figsize=(10,7),dpi=300)\nsns.countplot(x=Annual_Primium_range, hue=dataset.Response)\nplt.xticks(fontsize=8)\nplt.xlabel('Annual_Primium_range',fontsize=14)\nplt.ylabel('Count',fontsize=14)\nplt.show()\n\n#Policy_Sales_Channel_range\nplt.figure(figsize=(10,7),dpi=300)\nsns.countplot(x=Policy_Sales_Channel_range, hue=dataset.Response)\nplt.xticks(fontsize=8)\nplt.xlabel('Policy_Sales_Channel_range',fontsize=14)\nplt.ylabel('Count',fontsize=14)\nplt.show()\n\n#Vintage_range\nplt.figure(figsize=(10,7),dpi=300)\nsns.countplot(x=Vintage_range, hue=dataset.Response)\nplt.xticks(fontsize=8)\nplt.xlabel('Vintage_range',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\nplt.show()\n\n# plt.subplot(2,3,6)\n# sns.countplot(x=Age_range)\n# plt.xticks(fontsize=8)\n# plt.xlabel('Age_range',fontsize=14)\n# plt.ylabel('Count',fontsize=14)\n","3e6c3b54":"dataset_cat_features","e60762a7":"# getting Dummies for Binary Catagorical features in dataset_mod1:\ndataset_mod1=pd.get_dummies(dataset, columns=['Gender','Driving_License','Previously_Insured','Vehicle_Damage'],\n                            drop_first=True)","046a325f":"# getting Dummies for non-binary Catagorical features ataset_mod1:\ndataset_mod1=pd.get_dummies(dataset_mod1, columns=['Vehicle_Age'])","81c0d638":"print('\\n columns :',dataset_mod1.columns)\n\nprint('\\n________________________\\n Shape:',dataset_mod1.shape)\n\ndataset_mod1.head()","0f9ff61c":"dataset_mod1_cat_features = ['Gender_Male',\n                             'Driving_License_1',\n                             'Previously_Insured_1',\n                             'Vehicle_Age_1-2 Year',\n                             'Vehicle_Age_< 1 Year',\n                             'Vehicle_Age_> 2 Years',\n                             'Vehicle_Damage_Yes']","4151d0cf":"# Data Counts and basic information in Catagorical features\nfor category in dataset_mod1_cat_features:\n    print(dataset_mod1[category].value_counts(), '\\n____________________________________\\n')\n","0a05e997":"# ploting counts \n\nplt.figure(figsize=(30,20),dpi=300)\n#Gender\nplt.subplot(2,3,1)\nsns.countplot(x=dataset_mod1.Gender_Male)\nplt.xlabel('Gender_Male',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\n\n# Driving_License\nplt.subplot(2,3,2)\nsns.countplot(x=dataset_mod1.Driving_License_1)\nplt.xlabel('Driving_License_1',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\n# Previously_Insured\nplt.subplot(2,3,3)\nsns.countplot(x=dataset_mod1.Previously_Insured_1)\nplt.xlabel('Previously_Insured_1',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\n# Vehicle_Age\nplt.subplot(2,3,4)\nsns.countplot(x=dataset_mod1['Vehicle_Age_> 2 Years'])\nplt.xlabel('Vehicle_Age_> 2 Years',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\n# Vehicle_Damage\nplt.subplot(2,3,5)\nsns.countplot(x=dataset_mod1.Vehicle_Damage_Yes)\nplt.xlabel('Vehicle_Damage_Yes',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\n#Response\nplt.subplot(2,3,6)\nsns.countplot(x=dataset.Response)\nplt.xlabel('Response',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\nplt.show()\n\nprint(f\"\"\"Positive Response - {dataset.Response.value_counts()[1]\/\n(dataset.Response.value_counts()[1] + dataset.Response.value_counts()[0])*100}%\"\"\")\n\n","4717831d":"#data distribution of categorical features in both response group\nfor i in dataset_mod1_cat_features:   \n    plt.figure(figsize=(10,8),dpi=100)\n    sns.violinplot(x=\"Response\",y=i, data=dataset_mod1)\n    plt.title(f\"Response by {i}\")\n    plt.show()","f9e6147b":"plt.figure(figsize=(10,7),dpi=100)\nplt.title(\"Correlation plot\")\nsns.heatmap(dataset_mod1.corr(),linewidths=5, annot=True,annot_kws={'size': 8},cmap='coolwarm')","a908b7dc":"plt.figure(figsize=(10,7),dpi=100)\nsns.scatterplot(x=dataset_mod1.Annual_Premium,y=dataset.Age, hue=dataset.Response)\nplt.show()","09d54893":"plt.figure(figsize=(10,7),dpi=100)\nsns.scatterplot(x=dataset_mod1.Annual_Premium,y=dataset.Vintage, hue=dataset.Response)\nplt.show()","6b5392fa":"plt.figure(figsize=(10,7),dpi=100)\nsns.scatterplot(x=dataset_mod1.Age,y=dataset.Annual_Premium, hue=dataset.Response)\nplt.show()","3ad94773":"# Colums in dataset_mod1\nprint(dataset_mod1.columns)","cf25bc33":"# Arranging columns in dataset_mod1:\ndataset_mod1= dataset_mod1[['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel',\n       'Vintage', 'Gender_Male', 'Driving_License_1',\n       'Previously_Insured_1', 'Vehicle_Damage_Yes', 'Vehicle_Age_1-2 Year',\n       'Vehicle_Age_< 1 Year', 'Vehicle_Age_> 2 Years','Response']]","cc82352e":"# Renaming columns in dataset_mod1 to prevent future problems with XGBClassifier\ndataset_mod1=dataset_mod1.rename(columns={'Vehicle_Age_1-2 Year':'Vehicle_Age_1_to_2 Year','Vehicle_Age_< 1 Year':'Vehicle_Age_lessthan_1_Year',\n                             'Vehicle_Age_> 2 Years':'Vehicle_Age_morethan_2 Years'})\ndataset_mod1","c1ab25e0":"print('\\n Shape:', dataset_mod1.shape,'\\n__________________________\\n')\nprint('Column:',dataset_mod1.columns)","1e413b79":"# Previous Colum names:\nprint(dataset_mod1_cat_features)","a9aecd94":"# modified column names: \ndataset_mod1_cat_features = ['Gender_Male', 'Driving_License_1', 'Previously_Insured_1',\n'Vehicle_Damage_Yes', 'Vehicle_Age_1_to_2 Year',\n       'Vehicle_Age_lessthan_1_Year', 'Vehicle_Age_morethan_2 Years']\nprint(dataset_mod1_cat_features)","c1e13ff3":"# Assigned independent and the target features.\n\nX = dataset_mod1.iloc[:, 0:-1]\nY = dataset_mod1.iloc[:, -1]\n\nprint(X.shape)\nprint(Y.shape)","55abe69f":"print(X)","77091eca":"print(Y)","a13c719c":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nY= le.fit_transform(Y)\nprint(Y)","3bc1f33f":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.01, random_state = 0)","e97ea475":"print(X_train.shape)\nprint(X_train)","860d8d8a":"print(X_test.shape)\nprint(X_test)","159e5ceb":"print(Y_train.shape)\nprint(Y_train)","7c6b28c6":"print(Y_test.shape)\nprint(Y_test)","a24d9939":"# from sklearn.preprocessing import StandardScaler\n# sc = StandardScaler()\n# X_train = sc.fit_transform(X_train)\n# X_test = sc.transform(X_test)","1e3fa425":"# print(X_train.shape)\n# print(X_train)","7a6f23d0":"# print(X_test.shape)\n# print(X_test)","8cd590c3":"from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc, roc_curve, recall_score, classification_report ","b7732e1e":"from sklearn.ensemble import RandomForestClassifier","a97d6c57":"RF_classifier = RandomForestClassifier()","fd464e5c":"RF_classifier.fit(X_train, Y_train)","d3690cb8":"Y_pred = RF_classifier.predict(X_test)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)),1))","7ab1a875":"print (classification_report(Y_test, Y_pred))","8bd47411":"cm = confusion_matrix(Y_test, Y_pred)\n\nprint(cm)\nprint(f\"Accuracy Score :{accuracy_score(Y_test, Y_pred)}\")\n\nplt.figure(figsize=(10,5),dpi=80)\nsns.heatmap(cm\/np.sum(cm), annot=True, fmt='.2', cmap='Blues')\nplt.xlabel('Predicted label',fontsize=14)\nplt.ylabel('True label',fontsize=14)\nplt.show()","d7ff94e4":"from sklearn.model_selection import cross_val_score\n\nCV_accuracies = cross_val_score(estimator = RF_classifier, X = X_train, y = Y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(CV_accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(CV_accuracies.std()*100))","c8e2dbe0":"feat_importances = pd.Series(RF_classifier.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')","3d57871e":"Y_pred_proba = RF_classifier.predict_proba(X_test)\n(fpr, tpr,_) = roc_curve(Y_test, Y_pred_proba[:,1])\n\nplt.figure(figsize=(10,7),dpi=100)\nplt.plot(fpr,tpr)\nplt.title('Receiver operating characteristic Curve: HICSP')\nplt.xlabel('False Positive Rate(FPR):Precision')\nplt.ylabel('True Positive Rate (TPR): Recall')\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","8975d832":"from sklearn.model_selection import RandomizedSearchCV","48619c8d":"# RF Params:\nRF_parameters = {'n_estimators': [100],\n                 'criterion': ['entropy', 'gini'],\n                 'min_samples_split': [5, 7,10],\n                 'min_samples_leaf': [4, 6, 8],\n                 'max_depth': [2,3,4,5,6,7,10]\n                }","0085faeb":"RF_classifier_random = RandomizedSearchCV(estimator = RF_classifier, param_distributions = RF_parameters, n_iter = 10, \n                               cv = 10, verbose= 1, random_state= 404, n_jobs = -1)","44363d3e":"RF_classifier_random.fit(X_train, Y_train)","86b90bda":"Y_pred = RF_classifier_random.predict(X_test)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)),1))","cf25cacb":"print (classification_report(Y_test, Y_pred))","753d5759":"cm = confusion_matrix(Y_test, Y_pred)\n\nprint(cm)\nprint(f\"Accuracy Score :{accuracy_score(Y_test, Y_pred)}\")\n\nplt.figure(figsize=(10,5),dpi=80)\nsns.heatmap(cm\/np.sum(cm), annot=True, fmt='.2', cmap='Blues')\nplt.xlabel('Predicted label',fontsize=14)\nplt.ylabel('True label',fontsize=14)\nplt.show()","2452a673":"Y_pred_proba = RF_classifier_random.predict_proba(X_test)\n(fpr, tpr,_) = roc_curve(Y_test, Y_pred_proba[:,1])\n\nplt.figure(figsize=(10,7),dpi=100)\nplt.plot(fpr,tpr)\nplt.title('Receiver operating characteristic Curve: HICSP')\nplt.xlabel('False Positive Rate(FPR):Precision')\nplt.ylabel('True Positive Rate (TPR): Recall')\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","92e3fcf5":"from xgboost import XGBClassifier","b4acde79":"XGB_classifier = XGBClassifier()","f98d73de":"XGB_classifier.fit(X_train, Y_train)","fbcd7a01":"Y_pred = XGB_classifier.predict(X_test)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)),1))","9729d177":"print (classification_report(Y_test, Y_pred))","132f2b3e":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(Y_test, Y_pred)\n\nprint(cm)\nprint(f\"Accuracy Score :{accuracy_score(Y_test, Y_pred)}\")\n\nplt.figure(figsize=(10,5),dpi=80)\nsns.heatmap(cm\/np.sum(cm), annot=True, fmt='.2', cmap='Blues')\nplt.xlabel('Predicted label',fontsize=14)\nplt.ylabel('True label',fontsize=14)\nplt.show()","a8cb690c":"from sklearn.model_selection import cross_val_score\n\nCVS_accuracies = cross_val_score(estimator = XGB_classifier, X = X_train, y = Y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(CVS_accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(CVS_accuracies.std()*100))","fd550283":"Y_pred_proba = XGB_classifier.predict_proba(X_test)\n#Classifier_scores = classifier.predict_proba(X_test)[:,1]\n(fpr, tpr,_) = roc_curve(Y_test, Y_pred_proba[:,1])\n\nplt.figure(figsize=(10,7),dpi=100)\nplt.plot(fpr,tpr)\nplt.title('Receiver operating characteristic Curve: HICSP')\nplt.xlabel('False Positive Rate(FPR):Precision')\nplt.ylabel('True Positive Rate (TPR): Recall')\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","22a9febd":"# explainer = shap.TreeExplainer(XGB_classifier)\n# shap_values = explainer.shap_values(X_test)\n# shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n# shap.summary_plot(shap_values, X_test, plot_size=(10,8))","196fcdbf":"feature_importance = XGB_classifier.get_booster().get_score(importance_type='total_gain')\nkeys = list(feature_importance.keys())\nvalues = list(feature_importance.values())\n\nfeature_importance_data = pd.DataFrame(data=values, index=keys, \n                                       columns=[\"score\"]).sort_values(by = \"score\", ascending=True)\n\nfeature_importance_data.plot(kind='barh',figsize=(10,7))","a5154bee":"from sklearn.model_selection import RandomizedSearchCV","6e51b464":"# A parameter grid for XGBClassifier\nXGB_parameters = {'eta':[0.01,0.02,0.03,0.04,0.05],\n          'gamma': [0.5, 1, 1.5, 2, 5],\n          'max_depth': [3, 5, 7, 9],\n          'min_child_weight': [1, 5, 10],\n          'subsample': [0.6, 0.8, 1.0],\n          'colsample_bytree': [0.6, 0.8, 1.0]\n         }","2198d288":"XGB_classifier_random = RandomizedSearchCV(estimator = XGB_classifier, param_distributions = XGB_parameters, n_iter = 10, \n                               cv = 10, verbose= 1, random_state= 42, n_jobs = -1)","fdc51493":"XGB_classifier_random.fit(X_train, Y_train)","4a774c35":"Y_pred = XGB_classifier_random.predict(X_test)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)),1))","3f35b85e":"print (classification_report(Y_test, Y_pred))","414d23b8":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(Y_test, Y_pred)\n\nprint(cm)\nprint(f\"Accuracy Score :{accuracy_score(Y_test, Y_pred)}\")\n\nplt.figure(figsize=(10,5),dpi=80)\nsns.heatmap(cm\/np.sum(cm), annot=True, fmt='.2', cmap='Blues')\nplt.xlabel('Predicted label',fontsize=14)\nplt.ylabel('True label',fontsize=14)\nplt.show()","b83eac9d":"Y_pred_proba = XGB_classifier_random.predict_proba(X_test)\n(fpr, tpr,_) = roc_curve(Y_test, Y_pred_proba[:,1])\n\nplt.figure(figsize=(10,7),dpi=100)\nplt.plot(fpr,tpr)\nplt.title('Receiver operating characteristic Curve: HICSP')\nplt.xlabel('False Positive Rate(FPR):Precision')\nplt.ylabel('True Positive Rate (TPR): Recall')\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","bbf8ed28":"from catboost import CatBoostClassifier, Pool","186fc110":"Cat_classifier = CatBoostClassifier()","b4e12820":"Cat_classifier = Cat_classifier.fit(X_train,Y_train,\n                                    eval_set = (X_test, Y_test), \n                                    cat_features = dataset_mod1_cat_features,\n                                    use_best_model = True,\n                                    plot = True,\n                                    early_stopping_rounds = 10,\n                                    )","960f4178":"Y_pred = Cat_classifier.predict(X_test)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)),1))","af91aa16":"print (classification_report(Y_test, Y_pred))","0cc6e0f1":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(Y_test, Y_pred)\n\nprint(cm)\nprint(f\"Accuracy Score :{accuracy_score(Y_test, Y_pred)}\")\n\nplt.figure(figsize=(10,5),dpi=80)\nsns.heatmap(cm\/np.sum(cm), annot=True, fmt='.2', cmap='Blues')\nplt.xlabel('Predicted label',fontsize=14)\nplt.ylabel('True label',fontsize=14)\nplt.show()","59f439d5":"Y_pred_proba = Cat_classifier.predict_proba(X_test)\n(fpr, tpr,_) = roc_curve(Y_test, Y_pred_proba[:,1])\n\nplt.figure(figsize=(10,7),dpi=100)\nplt.plot(fpr,tpr)\nplt.title('Receiver operating characteristic Curve: HICSP')\nplt.xlabel('False Positive Rate(FPR):Precision')\nplt.ylabel('True Positive Rate (TPR): Recall')\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","e2af4d29":"explainer = shap.TreeExplainer(Cat_classifier)\nshap_values = explainer.shap_values(X_test)","e305fc94":"shap.summary_plot(shap_values, X_test, plot_type=\"bar\")","94131f4c":"shap.summary_plot(shap_values, X_test, plot_size=(10,8))","2ffa769d":"### Classification Report","b281a751":"# 4.3 - CatBoost","fe963ef8":"Build a model to predict whether a policyholder would be interested in Vehicle Insurance. ","3de285d8":"### Ploting AUC\/ROC  ","ed664e96":"### Classification Report","4bda22d4":"### Predicting the Test\/Validation set results","706bc744":"## 4.1.a - RF (Default)","7a831f49":"**Out of all the tested models here i.e. RF(default), RF_random(RandomizedSearch), XGB(Default), XGB_random(RandomisedSearch) and CatBoost, we were able to get an accuracy score of 87.93% with XGB_random. The score was closely followed by XGB(Default)and CatBoost, both yielding the accuracy score of 87.9%.** \n\n**As we found the highest AUC score of 84.93% with XGB(Default), Compared to 84.7% with XGB_random and 84.58% with CatBoost, We will proceed to apply XGB(Default) model on provided test dataset**","899f755d":"### Confusion Matrix","f80a2e54":"### Classification Report\n","149a821e":"#### - Premium vs Vintage ","9a9a0ed1":"**Inference:**","27c14ed7":"### Data Distribution\n   - **numeric features**","b8a77a3a":"# Notebook \n   - Step-1: **Libraries and dataset**\n   - Step-2: **Exploratory Data Analysis**\n   - Step-3: **Data Cleaning and Preprocessing**\n   - Step-4: **Data-Modelling-and-Evaluation**\n   - Step-5: **Concluding Remarks**","d77d6321":"#### - Age Vs Vintage ","e894d409":"### Ploting AUC\/ROC  ","2d2b0eff":"### 2.a - Numeric features","1408df62":"### Ploting AUC\/ROC  ","3d2eb23a":"### Feature Importances","dc7784ce":"\n**Inference**:\n- Based on the dataset $Gender$, $DrivingLicense$, $RegionCode$ doesn't influence the Response to the vehicle insurence purchasing option.\n\n- A majority of the customer who gave positive response are not $PreviouslyInsured$.\n\n- Customers with newer cars are less willing to buy vehicle insurance\n\n- Customers with no previous experience in Vehicle damage is more reluctent for vehicle insurance.\n\n- Customers from Policy_Sales_Channel arround 25 and 125 showed more positive response. \n","de6e95a1":"### Encoding the dependent\/target\/response Variable","59458cd2":"**Age**\n   - Majority of the customers are between the age group of 20-30 years.\n   - Most of the negative response came from these age group. \n   - In contrast, age groups between 30 - 60 years were more positive towards buying Car Insurance.\n   \n**Region Code**\n  - The region code doesn't seems to influence the response. Larger customer base is observed in the region code between 26 to 31, the majority of the customers are from these regions in both positive and negative response groups.\n   \n**Annual Premium**\n   - The Annual Premium also doesn't seems to influence the response.\n   \n**Policy Sales Channel**\n   - The Policy Sales Channel between 147-163 showed a significant spike in negative response, but overal Policy Sales Channe doesn't influence the response.\n\n**Response by Vintage**\n   - The data distribution appeared to be simmilar in both positive and negative response group.","20ab04f9":"### Predicting the Test\/Validation set results\u00b6\u00b6","16e95fa3":"### Cross validation","40ed0f85":"## 4.2.a - XGBClassifier (Default)","02b0c0b5":"## Dataset\n   - 1.a. Training Dataset","44db8f8b":"## 4.1 - Random Forrest","72865d1e":"### Predicting the Test\/Validation set response","1d1adaa2":"# Conclusion and Results:","2c2daca1":"### Confusion Matrix","c7615077":"## 4.2.b - XGBClassifier (RandomizedSearch)","c48a88f4":"Our client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nAn insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000\/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000\/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called \u2018sum assured\u2019) to the customer.","3bc246a4":"### 2.b - Categorical features","cac61098":"# Step-2 $$Exploratory-Data-Analysis$$","461df9a6":"### Confusion Matrix","3fc25d2d":"### Classification Report","d4aa36b1":"### Feature Importances","cc0cda82":"# $$Health-Insurance-Cross-Sell-Prediction$$\n","bfa5c019":"#### Shap based importance:","1b6fd5c7":"**Inference** :\n   - Age: \n       - Between 20 to 85 years old.\n       - 3\/4 of the customer are below 50 years of age\n\n   - Annual_premium:\n       - Average annual premium ~ 30.5k. \n       \n   - Vintage: \n       - Average customer association rate with company is approx 5 months.\n       - Half of the customers are associated with the company between ~3 to ~7 months.\n","0e1bd94f":"- Majority of the customers who responded yes are with company for more than 3 months.","08527ade":"# **Step-1: $$Importing-Libraries-and-Dataset$$**","5dc0cb58":"### Classification Report\u00b6\n","fae6732f":"# Step-3 $$Data-Cleaning-and-Preprocessing$$","225f6910":"### Predicting the Test\/Validation set results","2ca9e9ad":"### Converting num_features to Cat_features","27d0ea86":"- Most of the customers who responded yes are paying less than 10K as Annual Primium.","6c444866":"**Inference** :\n   - The Number of male is slightly higher than the female customer.\n   - Majority of them have driving license\n   - The Number of previously insured is slightly less compared to number of previously uninsured customers.\n   - Majority of the customers have vehicle age less than 2 years.\n   - the dataset has slightly more customers with previous vehicle damage experience compared to the customers with no previous experince with vehicle damage.\n   - Only 12% out of 381109 customers responded positive to the purchase the additional vehicle insurance offer. this results in a sample size of 46710 positive responses. ","4fa383ce":"### Predicting the Test\/Validation set results\u00b6\u00b6","eceac866":"#### Data Counts in Categorical features:","af7197ae":"# Step-4 $$Data-Modelling-and-Evaluation$$","6c7fa961":"### Feature Importances","1172b108":"## Libraries","3fb48d61":"#### - Premium Vs Age :","f65b7ead":"### Ploting AUC\/ROC  ","99588c36":"### Confusion Matrix","cfc24e6e":"## $$Work in Progress:$$\n\n###   1. Tuning XGB and CatBoost for better performance\n","63903b58":"#### Correlation between feature","e16199ae":"# Objective","c454a352":"# Prelude","7653d662":"### Ploting AUC\/ROC  ","e76afb0d":"## Feature Scaling","1b397795":"## 4.1.b - RF (Random Search)","63c4642f":"- Most of the customers who responded yes are between 30 to 60 years of age and paying less than 10K as Annual Primium","3073b15c":"### Confusion Matrix","5c7920c0":"## Splitting the dataset into the Training set and Test\/validation set","ab5fee6d":"#### Data Distribution in Categirical features ","b5f7ab7b":"![how-to-get-a-low-car-insurance-quote-1.jpg](attachment:how-to-get-a-low-car-insurance-quote-1.jpg)","cda7bcb1":"### Cross validation"}}