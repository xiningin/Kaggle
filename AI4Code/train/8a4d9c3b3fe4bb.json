{"cell_type":{"81010865":"code","6adad3ec":"code","75d32b9b":"code","8574b4a8":"code","345118bd":"code","d92ce8f4":"code","c9400336":"code","d07631ba":"code","49bd0017":"code","a6a01376":"code","4e216aa5":"code","c45c0692":"code","50c26141":"code","e587e701":"code","d7d8f323":"code","25af03aa":"markdown","24d939e7":"markdown","ce5d191e":"markdown","d54fd3d4":"markdown","f3511cb6":"markdown","c359959b":"markdown","a0f786d3":"markdown","fb77fc21":"markdown","7d875294":"markdown","4993fc7f":"markdown","351af23a":"markdown"},"source":{"81010865":"import pandas as pd\nimport altair as alt\nalt.data_transformers.disable_max_rows()\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBClassifier","6adad3ec":"df = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")","75d32b9b":"df","8574b4a8":"df.describe()","345118bd":"df[\"f1\"].isnull().sum()\n5* 957919 \/ 100","d92ce8f4":"column_names = []\nnumber_of_Nan_values = []\nfor x in df.columns:\n    column_names.append(x)\n    number_of_Nan_values.append(df[x].isnull().sum())\n\nnull_info = pd.DataFrame({\n    \"column_names\" : column_names,\n    \"number_of_NAN_values\" : number_of_Nan_values\n})\ndisplay(null_info)\ndisplay(null_info[null_info[\"number_of_NAN_values\"] < 47895.95])","c9400336":"for x in df.columns:\n    df[x].fillna(df[x].mean() , inplace = True)\n\n\ncolumn_names = []\nnumber_of_Nan_values = []\nfor x in df.columns:\n    column_names.append(x)\n    number_of_Nan_values.append(df[x].isnull().sum())\n\nnull_info = pd.DataFrame({\n    \"column_names\" : column_names,\n    \"number_of_NAN_values\" : number_of_Nan_values\n})\ndisplay(null_info)\ndisplay(null_info[null_info[\"number_of_NAN_values\"] < 47895.95])","d07631ba":"data = {\n    \"claimed\" : len(df[df[\"claim\"] == 1]),\n    \"unclaimed\" : len(df[df[\"claim\"] == 0])\n}\nstatus = list(data.keys())\ncount = list(data.values())\nfig = plt.figure(figsize = (10, 5))\nplt.bar(status, count, color ='maroon',\n        width = 0.1)\n \nplt.xlabel(\"status\")\nplt.ylabel(\"No.\")\nplt.title(\"Class diffference\")\nplt.show()","49bd0017":"from sklearn.metrics import accuracy_score , roc_auc_score\nfrom sklearn.model_selection import train_test_split\ncols = list(df.columns)\ncols.pop(-1)\ncols.pop(0)\nX = df[cols]\ny = df[\"claim\"]\n\ntrain_x , test_x , train_y , test_y = train_test_split(X,y,test_size = 0.33 , stratify = df[\"claim\"] , random_state = 42)","a6a01376":"def score(prediction , probability , true_value):\n    roc_score = roc_auc_score(true_value , probability)\n    accuracy = accuracy_score(true_value , prediction)\n    print(\"roc_auc_score :\" , roc_score)\n    print(\"accuracy :\", accuracy)","4e216aa5":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()\nLR.fit(train_x,train_y)\nprediction = LR.predict(test_x)\nprobability = LR.predict_proba(test_x)\nscore(prediction , probability[: , -1] , test_y)","c45c0692":"from sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(max_depth= 10)\nRF.fit(train_x,train_y)\nprediction = RF.predict(test_x)\nprobability = RF.predict_proba(test_x)\nscore(prediction , probability[: , 0] , test_y)","50c26141":"model = XGBClassifier(label_encoder = False ,  eval_metric = roc_auc_score , learning_rate = 0.1)\nmodel.fit(train_x,train_y)\nprediction = model.predict(test_x)\nprobability = model.predict_proba(test_x)\nscore(prediction , probability[: , 0] , test_y)","e587e701":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\nfor x in test_df.columns:\n    test_df[x].fillna(test_df[x].mean() , inplace = True)","d7d8f323":"best = XGBClassifier(label_encoder = False ,  eval_metric = roc_auc_score , learning_rate = 0.1)\nbest.fit(X,y)\npredictions = best.predict_proba(test_df[cols])[:,0]\ndata = {\n    \"id\" : list(test_df[\"id\"]),\n    \"claim\" : list(predictions)\n}\nsubmission = pd.DataFrame(data)\n\nsubmission.to_csv(\"submission.csv\", index = False)","25af03aa":"Now that we've removed ","24d939e7":"Since the two classes are the more or less the same we won't have to worry about class Imbalance","ce5d191e":"# Dependencies","d54fd3d4":"### Random Forests","f3511cb6":"columns f1 to f118 are features that affect the the probability that a person will claim the insurance policy our task is to find out the relation between the features and the claim column","c359959b":"Since all the collumns have less than 47895.95 null values we will not need to drop any of them.","a0f786d3":"Next we'll attempt to train a model on the dataset the models we'll be using will be Logistic Regression , Random Forests and XGBoost we'll measure the models accuracy and auc score","fb77fc21":"First thing we'll do is remove the NAN values. Since all the features are numerical I will fill the Nan rows with the mean of the specific column. If a column contains more NaN values than 50% of the number of rows it will be removed. ( 5% of 957919 = 47895.95)","7d875294":"### XGBoost Classifier","4993fc7f":"Since xgboost has the best score we'll train it on the entire train dataset and predict the test dataset","351af23a":"### Logistic Regression Model"}}