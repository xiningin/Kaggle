{"cell_type":{"0caf109a":"code","aadaaa5f":"code","b0b6bbe7":"code","ba45df34":"code","5dead290":"code","6d0f68d2":"code","dc09c9e5":"code","9c0ae923":"code","9bc8ea3d":"code","9f2949a3":"code","6bf61654":"code","ec55d409":"code","2076eac1":"code","9f2746d0":"code","d26f1f29":"markdown","44823830":"markdown","6294b589":"markdown","09e900ec":"markdown","88ade57a":"markdown","657eb03a":"markdown"},"source":{"0caf109a":"import keras\nfrom keras import regularizers, optimizers\nfrom keras import losses\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Input, Dropout, Embedding, LSTM\nfrom keras.optimizers import RMSprop, Adam, Nadam\nfrom keras.preprocessing import sequence\n\nimport torch\nfrom torch import nn\nfrom functools import reduce\n\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\n\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\n\nimport tensorflow\nimport sys","aadaaa5f":"path = '..\/input\/creditcardfraud\/creditcard.csv'\ndf = pd.read_csv(path, sep=\",\", index_col=None)\ndf.head()","b0b6bbe7":"# Standardize\ndf['Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\ndf['Time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))","ba45df34":"anomalies = df[df[\"Class\"] == 1]\nnormal = df[df[\"Class\"] == 0]\n\nanomalies.shape, normal.shape","5dead290":"for f in range(0, 20):\n    normal = normal.iloc[np.random.permutation(len(normal))]\n    \n\ndata_set = pd.concat([normal[:2000], anomalies])\n\nx_train, x_test = train_test_split(data_set, test_size = 0.4, random_state = 42)\n\nx_train = x_train.sort_values(by=['Time'])\nx_test = x_test.sort_values(by=['Time'])\n\ny_train = x_train[\"Class\"]\ny_test = x_test[\"Class\"]\n\nx_train.head(10)","6d0f68d2":"x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1])\nx_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1])\ninput_shape = (x_train.shape[1], 1)\n\ny_train = keras.utils.to_categorical(y_train, 2)\ny_test = keras.utils.to_categorical(y_test, 2)\n\nprint(\"Shapes:\\nx_train:%s\\ny_train:%s\\n\" % (x_train.shape, y_train.shape))\nprint(\"x_test:%s\\ny_test:%s\\n\" % (x_test.shape, y_test.shape))\nprint(\"input_shape:{}\\n\".format(input_shape))","dc09c9e5":"class Tree():\n    def __init__(self):\n        self.num_cut = [1, 1]\n        self.num_leaf = np.prod(np.array(self.num_cut) + 1)\n        self.num_class = 2\n        \n    def torch_kron_prod(self, a, b):\n        res = torch.einsum('ij,ik->ijk', [a, b])\n        res = torch.reshape(res, [-1, np.prod(res.shape[1:])])\n        return res\n    \n    def torch_bin(self, x, cut_points, temperature=0.1):\n        D = cut_points.shape[0]\n        W = torch.reshape(torch.linspace(1.0, D + 1.0, D + 1), [1, -1])\n        cut_points, _ = torch.sort(cut_points)\n        b = torch.cumsum(torch.cat([torch.zeros([1]), -cut_points], 0),0)\n        h = torch.matmul(x, W) + b\n        res = torch.exp(h-torch.max(h))\n        res = res\/torch.sum(res, dim=-1, keepdim=True)\n        return h\n    \n    def nn_decision_tree(self, x, cut_points_list, leaf_score, temperature=0.1):\n        leaf = reduce(self.torch_kron_prod,\n                      map(lambda z: self.torch_bin(x[:, z[0]:z[0] + 1], z[1], temperature), enumerate(cut_points_list)))\n        return torch.matmul(leaf, leaf_score)","9c0ae923":"tree = Tree()\n\ncut_points_list = [torch.rand([i], requires_grad=True) for i in tree.num_cut]\nleaf_score = torch.rand([tree.num_leaf, tree.num_class], requires_grad=True)\n\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(cut_points_list + [leaf_score], lr=0.001, weight_decay=0.001)","9bc8ea3d":"model = nn.Sequential(\n          nn.Linear(31,16),\n          nn.ReLU(),\n          nn.Linear(16,8),\n          nn.ReLU(),\n          nn.Linear(8,2),\n          nn.Sigmoid()\n        )","9f2949a3":"for i in range(300):\n    optimizer.zero_grad()\n    x_batches = torch.split(torch.tensor(x_train).type(torch.float32), 32)\n    y_batches = torch.split(torch.tensor(y_train).type(torch.long), 32)\n    \n    losses = torch.zeros(len(x_batches))\n    accs = torch.zeros(len(x_batches))\n    for j,x in enumerate(x_batches):\n        out = model(x)\n        y_pred = tree.nn_decision_tree(out, cut_points_list, \n                                       leaf_score, temperature=0.1)\n        y_max = torch.max(y_batches[j], axis=1)[1]\n        y_pred_max = torch.max(y_pred, axis=1)[1]\n        \n        acc = len(torch.where(y_max == y_pred_max)[0]) \/ len(y_max)\n        accs[j] = acc\n        \n        loss = loss_function(y_pred, y_max)\n        losses[j] = loss\n        \n        loss.backward()\n        optimizer.step()\n    if((i+1) % 20 == 0):\n        print(\"i:{:4d}, loss:{:1.3f}, acc:{:1.3f}\".format(i+1, losses.mean(), accs.mean()))","6bf61654":"def predict(tree, X, y):\n    X = torch.tensor(X).type(torch.float32)\n    y = torch.tensor(y).type(torch.long)\n\n    out = model(X)\n    y_pred = tree.nn_decision_tree(out, cut_points_list, leaf_score, temperature=0.1)\n    y_max = torch.max(y, axis=1)[1]\n    y_pred_max = torch.max(y_pred, axis=1)[1]\n\n    acc = len(torch.where(y_max == y_pred_max)[0]) \/ len(y_max)\n    loss = loss_function(y_pred, y_max)\n    return y_pred, acc, loss","ec55d409":"y_pred, acc, loss = predict(tree, x_test, y_test)\nprint(\"Accuracy:{:1.3f}, Loss:{:1.3f}\"\n         .format(acc, loss))","2076eac1":"class Visualization:\n    labels = [\"Normal\", \"Anomaly\"]\n\n    def draw_confusion_matrix(self, y, ypred):\n        matrix = confusion_matrix(y, ypred)\n\n        plt.figure(figsize=(10, 8))\n        colors=[ \"orange\",\"green\"]\n        sns.heatmap(matrix, xticklabels=self.labels, yticklabels=self.labels, cmap=colors, annot=True, fmt=\"d\")\n        plt.title(\"Confusion Matrix\")\n        plt.ylabel('Actual')\n        plt.xlabel('Predicted')\n        plt.show()\n\n\n    def draw_anomaly(self, y, error, threshold):\n        groupsDF = pd.DataFrame({'error': error,\n                                 'true': y}).groupby('true')\n\n        figure, axes = plt.subplots(figsize=(12, 8))\n\n        for name, group in groupsDF:\n            axes.plot(group.index, group.error, marker='x' if name == 1 else 'o', linestyle='',\n                    color='r' if name == 1 else 'g', label=\"Anomaly\" if name == 1 else \"Normal\")\n\n        axes.hlines(threshold, axes.get_xlim()[0], axes.get_xlim()[1], colors=\"b\", zorder=100, label='Threshold')\n        axes.legend()\n        \n        plt.title(\"Anomalies\")\n        plt.ylabel(\"Error\")\n        plt.xlabel(\"Data\")\n        plt.show()\n\n    def draw_error(self, error, threshold):\n            plt.plot(error, marker='o', ms=3.5, linestyle='',\n                     label='Point')\n\n            plt.hlines(threshold, xmin=0, xmax=len(error)-1, colors=\"b\", zorder=100, label='Threshold')\n            plt.legend()\n            plt.title(\"Reconstruction error\")\n            plt.ylabel(\"Error\")\n            plt.xlabel(\"Data\")\n            plt.show()","9f2746d0":"visualize = Visualization()\ny_pred2 = torch.max(y_pred, axis=1)[1].detach().numpy()\ny_test2 = np.argmax(y_test, axis=1)\nvisualize.draw_confusion_matrix(y_test2, y_pred2)","d26f1f29":"<h1 id=\"dataset\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","44823830":"<h1 id=\"training\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","6294b589":"<h1 id=\"visualization\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Visaulization\n        <a class=\"anchor-link\" href=\"#visualization\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","09e900ec":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/312305\/633246\/752964d08f6001573444649668b0b011\/dataset-cover.jpg?t=2019-08-22-03-58-44\" class=\"Header_CoverImg-sc-1431b7d ibFJYv\">\n<\/div>","88ade57a":"<h1 id=\"prediction\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Prediction\n        <a class=\"anchor-link\" href=\"#prediction\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","657eb03a":"<h1 id=\"tree\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Decision Tree\n        <a class=\"anchor-link\" href=\"#tree\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}