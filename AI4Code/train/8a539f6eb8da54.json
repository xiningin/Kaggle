{"cell_type":{"f8ee46b9":"code","3d8cdb15":"code","72589fb0":"code","0ea53680":"code","51435e58":"code","c8fbf22c":"code","4cc9d405":"code","5580d058":"code","694eb22e":"code","7c23c973":"code","2bec29b7":"code","a9344080":"code","b0695304":"code","9ef1f027":"code","b30da53b":"code","ab1da43c":"code","336db17d":"code","e8abe488":"code","c44791ce":"code","afda1881":"code","bdecc38b":"code","3a873adb":"code","4d4845db":"code","82b61702":"code","061f4d03":"code","79a24ec3":"code","846cee86":"code","cd815268":"markdown","9f9bd245":"markdown","023d9bdb":"markdown","02677625":"markdown","0d24a531":"markdown","e9ccf0df":"markdown","646ab3c8":"markdown","1db9c0fc":"markdown","e3a1faa0":"markdown","7587be20":"markdown","63899f58":"markdown","2f6e57b9":"markdown","966f7642":"markdown","1ba0e45a":"markdown","1ad25689":"markdown","40ac922a":"markdown"},"source":{"f8ee46b9":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/appliances-energy-prediction\/KAG_energydata_complete.csv')\ndf.describe()","3d8cdb15":"X = df.drop(['Appliances','date'],axis=1)\ny = df.Appliances","72589fb0":"print(X.shape)\nprint(y.shape)","0ea53680":"from sklearn import model_selection\nfrom sklearn import linear_model\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X[:20], y[:20], test_size=0.5, random_state=42)\nmodel = linear_model.LinearRegression()\n\nmodel.fit(X_train, y_train)","51435e58":"from sklearn import metrics\nimport numpy as np","c8fbf22c":"erro_treino = metrics.mean_squared_error(y_train,model.predict(X_train))\nprint('RMSE no treino:', np.sqrt(erro_treino))\n\nerro_teste = metrics.mean_squared_error(y_test,model.predict(X_test))\nprint('RMSE no teste:', np.sqrt(erro_teste))","4cc9d405":"r2 = model.score(X_train, y_train)\nprint('r\u00b2 no treino:', r2)\n\nr2 = model.score(X_test, y_test)\nprint('r\u00b2 no teste:', r2)","5580d058":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport seaborn as sns","694eb22e":"def plot_residuals_and_coeff(resid_train, resid_test, coeff):\n    fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n    axes[0].bar(np.arange(len(resid_train)), resid_train)\n    axes[0].set_xlabel(\"n\u00fam. amostras\")\n    axes[0].set_ylabel(\"res\u00edduo\")\n    axes[0].set_title(\"treino\")\n    axes[1].bar(np.arange(len(resid_test)), resid_test)\n    axes[1].set_xlabel(\"n\u00fam. amostras\")\n    axes[1].set_ylabel(\"res\u00edduo\")\n    axes[1].set_title(\"teste\")\n    axes[2].bar(np.arange(len(coeff)), coeff)\n    axes[2].set_xlabel(\"n\u00fam. coeficientes\")\n    axes[2].set_ylabel(\"coeficiente\")\n    fig.tight_layout()\n    return fig, axes\n\nresiduo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","7c23c973":"model = linear_model.Ridge()\nmodel.fit(X_train, y_train)\n\nerro_treino = metrics.mean_squared_error(y_train,model.predict(X_train))\nprint('RMSE no treino:', np.sqrt(erro_treino))\n\nerro_teste = metrics.mean_squared_error(y_test,model.predict(X_test))\nprint('RMSE no teste:', np.sqrt(erro_teste))","2bec29b7":"residuo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","a9344080":"model = linear_model.Lasso(alpha=2.5)\nmodel.fit(X_train, y_train)\n\nerro_treino = metrics.mean_squared_error(y_train,model.predict(X_train))\nprint('RMSE no treino:', np.sqrt(erro_treino))\n\nerro_teste = metrics.mean_squared_error(y_test,model.predict(X_test))\nprint('RMSE no teste:', np.sqrt(erro_teste))","b0695304":"residuo_treino = y_train - model.predict(X_train)\nresiduo_teste = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","9ef1f027":"df = pd.read_csv('..\/input\/appliances-energy-prediction\/KAG_energydata_complete.csv')\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X[:20], y[:20], test_size=0.5, random_state=42)\n\nrmse_treino = []\nrmse_teste  = []\nalpha = []\n\nfor a in range(-4,8):\n    model = linear_model.Lasso(alpha=10**a)\n    model.fit(X_train, y_train)\n    \n    print(\"################################################\")\n    print('Alpha:', 10**a)\n    \n    rmse_treino.append(np.sqrt(metrics.mean_squared_error(y_train, model.predict(X_train))))\n    rmse_teste.append(np.sqrt(metrics.mean_squared_error(y_test, model.predict(X_test))))\n    alpha.append(a)\n    \n    print('MSE no treino:', rmse_treino[-1])\n    print('MSE no teste:', rmse_teste[-1])\n    \n    print(\"################################################\")\n\nplt.plot(alpha, rmse_treino, alpha, rmse_teste)","b30da53b":"rmse_treino = []\nrmse_teste  = []\nalpha = []\n\nfor a in range(-4,8):\n    model = linear_model.Ridge(alpha=10**a)\n    model.fit(X_train, y_train)\n    \n    print(\"################################################\")\n    print('Alpha:', 10**a)\n    \n    rmse_treino.append(np.sqrt(metrics.mean_squared_error(y_train, model.predict(X_train))))\n    rmse_teste.append(np.sqrt(metrics.mean_squared_error(y_test, model.predict(X_test))))\n    alpha.append(a)\n    \n    print('MSE no treino:', rmse_treino[-1])\n    print('MSE no teste:', rmse_teste[-1])\n    \n    print(\"################################################\")\n\nplt.plot(alpha, rmse_treino, alpha, rmse_teste)","ab1da43c":"from sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV","336db17d":"# Utilizando o Lasso CV\nlasso_reg = LassoCV(cv=5, random_state=0)\nlasso_reg.fit(X_train, y_train)\nbest_alpha_lasso = lasso_reg.alpha_\nprint(\"Best alpha => \", best_alpha_lasso)\n# Com este valor fazemos o cross validation para outros par\u00e2metros","e8abe488":"# Utilizando o Ridge CV\nridge_reg = RidgeCV(cv=5)\nridge_reg.fit(X_train, y_train)\nbest_alpha_ridge = ridge_reg.alpha_\nprint(\"Best alpha => \", best_alpha_ridge)\n# Com este valor fazemos o cross validation para outros par\u00e2metros","c44791ce":"X = df.drop(['Appliances','date'],axis=1)\ny = df.Appliances\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=42)\n\nmodel = linear_model.Ridge(alpha = best_alpha_ridge)\nmodel.fit(X_train, y_train)\n\nerro_treino = np.sqrt(metrics.mean_squared_error(y_train,model.predict(X_train)))\nprint('RMSE no treino:', erro_treino)\n\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test,model.predict(X_test)))\nprint('RMSE no teste:', erro_teste)\n\nresiduo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","afda1881":"X = df.drop(['Appliances','date'],axis=1)\ny = df.Appliances\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=42)\n\nmodel = linear_model.Lasso(alpha = best_alpha_lasso)\nmodel.fit(X_train, y_train)\n\nerro_treino = np.sqrt(metrics.mean_squared_error(y_train,model.predict(X_train)))\nprint('RMSE no treino:', erro_treino)\n\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test,model.predict(X_test)))\nprint('RMSE no teste:', erro_teste)\n\nresiduo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","bdecc38b":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\n\ndata_gs, data_cv, target_gs, target_cv = train_test_split(X, y, test_size=0.95, random_state=42)\n\npipeline = Pipeline([('scaler', StandardScaler()), ('clf', linear_model.Ridge())])\n\n# utiliza-se GridSearchCV para achar os melhores par\u00e2metros\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'clf__alpha': [0.1,1, 1.5, 3, 5, 7,10,100,1000]} # quais par\u00e2metros e quais valores ser\u00e3o testados\nclf = GridSearchCV(pipeline, parameters, cv=3, iid=False) # clf vai armazenar qual foi a melhor configura\u00e7\u00e3o\nclf.fit(data_gs, target_gs)\n\nprint(clf.best_params_ )\n\n# utilizando valida\u00e7\u00e3o cruzada para avaliar o modelo\nscores = cross_val_score(clf, data_cv, target_cv, cv=5, scoring='neg_mean_squared_error')\n\nscores = -scores\nscores = np.sqrt(scores)\n\nprint('RMSE - %.2f +- %.2f' % (scores.mean(), scores.std()))","3a873adb":"print('R\u00b2:', clf.score(X_test, y_test) )\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test, clf.predict(X_test)))\nprint('RMSE no treino:', erro_teste)","4d4845db":"data_gs, data_cv, target_gs, target_cv = train_test_split(X, y, test_size=0.95, random_state=42)\n\npipeline = Pipeline([('scaler', StandardScaler()), ('clf', linear_model.Lasso())])\n\n# utiliza-se GridSearchCV para achar os melhores par\u00e2metros\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'clf__alpha': [0.1,1, 1.5, 3, 5, 7,10,100,1000]} # quais par\u00e2metros e quais valores ser\u00e3o testados\nclf = GridSearchCV(pipeline, parameters, cv=3, iid=False) # clf vai armazenar qual foi a melhor configura\u00e7\u00e3o\nclf.fit(data_gs, target_gs)\n\nprint(clf.best_params_ )\n\n# utilizando valida\u00e7\u00e3o cruzada para avaliar o modelo\nscores = cross_val_score(clf, data_cv, target_cv, cv=5, scoring='neg_root_mean_squared_error')\n\nscores = -scores\n# scores = np.sqrt(scores)\n\nprint('RMSE - %.2f +- %.2f' % (scores.mean(), scores.std()))","82b61702":"print('R\u00b2:', clf.score(X_test, y_test) )\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test, clf.predict(X_test)))\nprint('RMSE no treino:', erro_teste)","061f4d03":"data_gs, data_cv, target_gs, target_cv = train_test_split(X, y, test_size=0.95, random_state=42)\n\npipeline = Pipeline([('scaler', StandardScaler()), ('clf', linear_model.ElasticNet())])\n\n# utiliza-se GridSearchCV para achar os melhores par\u00e2metros\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'clf__alpha': [0.1,1, 1.5, 3, 5, 7,10,100,1000]} # quais par\u00e2metros e quais valores ser\u00e3o testados\nclf = GridSearchCV(pipeline, parameters, cv=3, iid=False) # clf vai armazenar qual foi a melhor configura\u00e7\u00e3o\nclf.fit(data_gs, target_gs)\n\nprint(clf.best_params_ )\n\n# utilizando valida\u00e7\u00e3o cruzada para avaliar o modelo\nscores = cross_val_score(clf, data_cv, target_cv, cv=5, scoring='neg_mean_squared_error')\n\nscores = -scores\nscores = np.sqrt(scores)\n\nprint('RMSE - %.2f +- %.2f' % (scores.mean(), scores.std()))","79a24ec3":"print('R\u00b2:', clf.score(X_test, y_test) )\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test, clf.predict(X_test)))\nprint('RMSE no treino:', erro_teste)","846cee86":"residuo_treino = y_train - clf.predict(X_train)\nresiduo_teste  = y_test - clf.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, clf.best_estimator_['clf'].coef_)","cd815268":"Esse conjunto de dados est\u00e1 dispon\u00edvel em https:\/\/archive.ics.uci.edu\/ml\/datasets\/Appliances+energy+prediction# e um Github do artigo que originou essa contribui\u00e7\u00e3o est\u00e1 dispon\u00edvel em https:\/\/github.com\/LuisM78\/Appliances-energy-prediction-data.\n\nO objetivo \u00e9 utilizar as informa\u00e7\u00f5es de clima fora e dentro de uma casa para estimar o consumo de energia el\u00e9trico que aquela casa, naquelas condi\u00e7\u00f5es meteorol\u00f3gicas, demandaria. Portanto, ser\u00e3o considerados atributos todas as colunas exceto appliances e a data, e essa coluna ser\u00e1 utilizada como *target*.","9f9bd245":"Testando agora o Lasso","023d9bdb":"Elasticnet combina L1 e L2","02677625":"Os resultados de erro no treino s\u00e3o mais baixos que do Ridge, por\u00e9m mais altos que a regress\u00e3o linear sem regulariza\u00e7\u00e3o, por\u00e9m o erro no teste caiu aproximadamente para a metade. Tamb\u00e9m \u00e9 poss\u00edvel perceber que L1 reduziu significativamente o n\u00famero de atributos que, de fato, contribuem para a solu\u00e7\u00e3o do problema.\n\nTamb\u00e9m \u00e9 poss\u00edvel perceber que o **par\u00e2metro alpha \u00e9 configur\u00e1vel**, portanto \u00e9 importante fazer uma varredura para identificar qual seria o melhor valor.","0d24a531":"Por \u00faltimo, tamb\u00e9m \u00e9 poss\u00edvel visualizar essa diferen\u00e7a de forma gr\u00e1fica. Compara-se o res\u00edduo por amostra tanto no treino quanto no teste, e observa-se os coeficientes encontrados:","e9ccf0df":"O erro no treino n\u00e3o \u00e9 mais pr\u00f3ximo a zero, mas \u00e9 poss\u00edvel perceber que *o erro no teste diminuiu*. Vale lembrar que os dados do teste s\u00e3o mais parecidos com os dados do mundo real, ou seja, s\u00e3o informa\u00e7\u00f5es que o modelo n\u00e3o teve acesso, portanto mais dif\u00edceis de serem previstas corretamente.\n\nGraficamente, \u00e9 poss\u00edvel perceber uma mudan\u00e7a nos pesos tamb\u00e9m:","646ab3c8":"**Utilizando Ridge \u2014 L2**","1db9c0fc":"**Utilizando LASSO \u2014 L1**","e3a1faa0":"## A combina\u00e7\u00e3o NumPy, Pandas e Scikit-Learn \u00e9 muito poderosa\n\nEmbora O Scikit-Learn seja respons\u00e1vel por facilitar grande parte do pipeline de Machine Learning, dois componentes s\u00e3o essenciais para ler arquivos e manipular as informa\u00e7\u00f5es: NumPy e Pandas. O NumPy auxilia a manipula\u00e7\u00e3o matricial dos dados, que \u00e9 fundamental para aprendizado de m\u00e1quina; enquanto o Pandas atua como um facilitador para a manipula\u00e7\u00e3o de dados de forma menos estruturada.\n\n*Esse conte\u00fado \u00e9 baseado no cap\u00edtulo 'Machine Learning' de Numerical Python, segunda edi\u00e7\u00e3o, de Robert Johannson.*\n\nA seguir \u00e9 utilizado o comando read_csv do Pandas para ter acesso aos dados do arquivo 'energy_data.csv', e o comando *describe* gera um sum\u00e1rio dos dados quando poss\u00edvel. A nomenclatura df para a vari\u00e1vel vem de DataFrame do Pandas, mas poderia ser o nome que o programador quisesse dar.","7587be20":"Em seguida, \u00e9 importante calcular o res\u00edduo entre o que o modelo diz e o que de fato \u00e9. Esse res\u00edduo tamb\u00e9m pode ser acumulado como erro utilizando alguma fun\u00e7\u00e3o. Vamos verificar ent\u00e3o qual \u00e9 o erro para o pr\u00f3prio conjunto de treino utilizando o erro quadr\u00e1tico m\u00e9dio, e depois o erro no teste.","63899f58":"\u00c9 poss\u00edvel perceber que o erro no treino \u00e9 muito baixo, praticamente zero, enquanto que o erro no teste \u00e9 bastante alto (> 104). Isso se deve a um fen\u00f4meno chamado **overfitting**. \u00c9 muito comum que, quando o n\u00famero de atributos seja maior que o n\u00famero de amostras, a regress\u00e3o fique sobreajustada (overfit) para os dados de treino, e n\u00e3o generaliza suficiente para o conjunto de teste.","2f6e57b9":"## Exerc\u00edcios\n\n1. **Fa\u00e7a a busca de melhor par\u00e2metro de alpha para reduzir o erro quadr\u00e1tico m\u00e9dio nessa base de apenas 20 amostras, considerando L1 e L2. Considere utilizar as fun\u00e7\u00f5es LassoCV e RidgeCV, e busque informa\u00e7\u00f5es sobre elas na documenta\u00e7\u00e3o do Scikit-Learn.**\n\n\n2. **Recarregue a base e n\u00e3o filtre apenas 20 amostras e aplique os modelos de regress\u00e3o vistos. Tenha um olhar cr\u00edtico para os seguintes questionamentos ap\u00f3s codificar e ver os resultados:**\n    * Qual regress\u00e3o teve o melhor resultado?\n    * H\u00e1 algum sinal de overfitting?\n    * Todos atributos s\u00e3o relevantes para o problema?\n    * Todos coeficientes est\u00e3o em uma mesma magnitude?","966f7642":"S\u00e3o 27 atributos que far\u00e3o a composi\u00e7\u00e3o de X, e o total de amostras s\u00e3o 19735. Por se tratar de um problema de regress\u00e3o, ser\u00e3o importados os m\u00f3dulos do Scikit-Learn para a separa\u00e7\u00e3o dos dados e a gera\u00e7\u00e3o dos regressores (modelos de regress\u00e3o). Em seguida, os dados s\u00e3o separados com o comando *train_test_split* e um modelo de Regress\u00e3o Linear \u00e9 treinado com a fun\u00e7\u00e3o *fit*.\n\n**Vamos supor um cen\u00e1rio com 20 amostras do conjunto inicial para prop\u00f3sitos did\u00e1ticos:**","1ba0e45a":"Podemos agora carregar todos os dados e comparar o desempenho utilizando L1 e L2","1ad25689":"\u00c9 poss\u00edvel perceber nas escalas dos res\u00edduos que os erros s\u00e3o muito maiores no conjunto de teste do que no conjunto de treino. *Uma das formas de corrigir esse problema \u00e9 aplicando regulariza\u00e7\u00e3o*, for\u00e7ando os coeficientes a residirem num espa\u00e7o pr\u00f3ximo. As duas normais mais comuns de regulariza\u00e7\u00e3o s\u00e3o L1 e L2, respectivamente LASSO e Ridge. Enquanto que L2 favorece com coeficientes menores, L1 favorece modelos que t\u00eam poucos coeficientes pr\u00f3ximos de zero.\n\n\n**Quando usar L1 ou L2?**\n\n* L1: Deseja-se eliminar o maior n\u00famero de atributos que n\u00e3o contribuem com o problema;\n* L2: Limitar a magnitude dos coeficientes do modelo.","40ac922a":"Em vez de utilizarmos o LassoCV ou RidgeCV, poder\u00edamos tamb\u00e9m buscar por eles atrav\u00e9s do grid search"}}