{"cell_type":{"5481656f":"code","0dfc48ff":"code","83008e36":"code","c5ab1ba1":"code","7f8b6d7d":"code","90671487":"code","009b6777":"code","375d25fd":"code","7a41e785":"code","79e3ba2e":"code","78bcd710":"code","6a4c45be":"code","dc994f0b":"code","72ab7730":"code","c6038279":"markdown","c27a5c6a":"markdown","aa66b382":"markdown","093af5f7":"markdown"},"source":{"5481656f":"import os\nimport sys\nsys.path = ['..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master',] + sys.path\nimport pandas as pd\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torchvision.models as models\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom sklearn.model_selection import KFold, StratifiedKFold","0dfc48ff":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nseed = 42\nrandom_state = set_seed(seed)","83008e36":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","c5ab1ba1":"class ClassificationDataset:\n    \n    def __init__(self, image_paths, targets, isTrain=True): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.isTrain = isTrain\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item])\n        image1 = np.vstack(image).transpose((1, 0)).astype(np.float32)[np.newaxis, ]\n        targets = self.targets[item]\n                \n        return {\n            \"image1\": torch.tensor(image1, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }        ","7f8b6d7d":"df = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\nprint (df.shape)\ndf['img_path'] = df['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')","90671487":"df.head()","009b6777":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        \n        \n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        \n        return x","375d25fd":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","7a41e785":"def train(data_loader, model, optimizer, device):\n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs1 = data[\"image1\"]\n        targets = data['targets']\n        \n        inputs1, targets_a, targets_b, lam = mixup_data(inputs1, targets.view(-1, 1), use_cuda=True)\n\n        inputs1 = inputs1.to(device, dtype=torch.float)\n        targets_a = targets_a.to(device, dtype=torch.float)\n        targets_b = targets_b.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs1)\n        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs1 = data[\"image1\"]\n            targets = data[\"targets\"]\n            \n            inputs1 = inputs1.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs1)\n            output = torch.sigmoid(output)\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","79e3ba2e":"paths = [\n 'efficientnet-b0-08094119.pth',\n 'efficientnet-b1-dbc7070a.pth',\n 'efficientnet-b2-27687264.pth',\n 'efficientnet-b3-c8376fa2.pth',\n 'efficientnet-b4-e116e8b3.pth',\n 'efficientnet-b5-586e6cc6.pth',\n 'efficientnet-b6-c76e70fd.pth',\n 'efficientnet-b7-dcc49843.pth',\n]\npretrained_model = {\n    'efficientnet-b0': '..\/input\/efficientnet-pytorch\/' + paths[0],\n    'efficientnet-b1': '..\/input\/efficientnet-pytorch\/' + paths[1],\n    'efficientnet-b2': '..\/input\/efficientnet-pytorch\/' + paths[2],\n    'efficientnet-b3': '..\/input\/efficientnet-pytorch\/' + paths[3],\n    'efficientnet-b4': '..\/input\/efficientnet-pytorch\/' + paths[4],\n    'efficientnet-b5': '..\/input\/efficientnet-pytorch\/' + paths[5],\n    'efficientnet-b6': '..\/input\/efficientnet-pytorch\/' + paths[6],\n    'efficientnet-b7': '..\/input\/efficientnet-pytorch\/' + paths[7],\n}\n","78bcd710":"device = \"cuda\"\nbaseline_name = 'efficientnet-b4'\nmodel = enetv2(baseline_name, out_dim=1)\nmodel.to(device)\nmodel.load_state_dict(torch.load('..\/input\/eff-mixup-v98\/aug_training_0_10.pt'))","6a4c45be":"submission = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy')","dc994f0b":"test_dataset = ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\ntest_predictions, test_targets = evaluate(test_loader, model, device=device)","72ab7730":"test_predictions = np.array(test_predictions)\nsubmission.target = test_predictions[:, 0]\nsubmission.drop(['img_path'], axis=1, inplace=True)\nsubmission.to_csv('submission.csv', index=False)","c6038279":"\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:48<00:00,  1.79it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.20it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=0, Valid ROC AUC=0.9569773452692557\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:48<00:00,  1.79it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.20it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=1, Valid ROC AUC=0.9742243389195545\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:48<00:00,  1.79it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.20it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=2, Valid ROC AUC=0.9731241303886597\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:47<00:00,  1.79it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.18it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=3, Valid ROC AUC=0.9790477440801959\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:48<00:00,  1.79it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.20it\/s]\n\n\nEpoch=4, Valid ROC AUC=0.978897236115816\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:47<00:00,  1.79it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.20it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=5, Valid ROC AUC=0.9835655618084868\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:47<00:00,  1.79it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:02<00:00, 10.20it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=6, Valid ROC AUC=0.9811368040032304\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:51<00:00,  1.78it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.19it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=7, Valid ROC AUC=0.9855572135396216\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:58<00:00,  1.78it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.18it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=8, Valid ROC AUC=0.9860122539739846\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:59<00:00,  1.78it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.18it\/s]\n\n\nEpoch=9, Valid ROC AUC=0.9836957324427887\n\n\nTraining: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5017\/5017 [46:58<00:00,  1.78it\/s]\n\n\nEvaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1255\/1255 [02:03<00:00, 10.19it\/s]\n\n\nTraining:   0%|          | 0\/5017 [00:00<?, ?it\/s]\n\n\nEpoch=10, Valid ROC AUC=0.9832956086605378","c27a5c6a":"# Imports","aa66b382":"# Some Assumptions\n\n**I guess 5-Fold will result in 0.98**\n\nAs we can see in discussion section many kagglers reported similar results.\n\nI am not planning to do the same but trying something else to have a generalized model with features of signal processing and images both.","093af5f7":"# Training Logs"}}