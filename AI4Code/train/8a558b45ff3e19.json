{"cell_type":{"e83c96a3":"code","2bbe3ce0":"code","8d10f682":"code","f27327e8":"code","05144c4f":"code","4c8c3637":"code","38247db8":"code","b132cc54":"code","765996e6":"code","c7dfa50b":"code","abb388a1":"code","eb955a72":"code","c4299adb":"code","3ee3ac8f":"code","4b19e7b2":"code","8454b1b0":"code","cee0643a":"code","b4e0f55e":"code","441d140a":"markdown","3750d9c1":"markdown","a0d438e5":"markdown","d73f77a0":"markdown","d4b670c6":"markdown","51d35673":"markdown","27b1ec0b":"markdown","a9d5ce4c":"markdown","bf432b4c":"markdown","c49cf22b":"markdown","4d94a552":"markdown"},"source":{"e83c96a3":"class config():    \n    INPUT_DIR=\"\/kaggle\/input\/CORD-19-research-challenge\/\"\n    OUTPUT_DIR=\"\/kaggle\/working\/\"","2bbe3ce0":"import pandas as pd\nimport re","8d10f682":"meta_df = pd.read_csv(f'{config.INPUT_DIR}\/metadata.csv',\n                      usecols=['publish_time', 'title', 'abstract',\n                               'pmc_json_files',\n                               'doi'\n                              ])\nmeta_df['publish_time'] = pd.to_datetime(meta_df['publish_time'])\nmeta_df.info()","f27327e8":"meta_df.dropna(inplace=True)\nmeta_df.info()","05144c4f":"meta_df['abstract_nw'] = meta_df.abstract.str.split().apply(len)","4c8c3637":"print(meta_df.query('abstract_nw<=3').abstract.values)","38247db8":"meta_df = meta_df.query('abstract_nw>3')","b132cc54":"meta_df['title_lower'] = meta_df['title'].str.lower()","765996e6":"idx = meta_df.groupby(['title_lower'])['publish_time'].transform(max) == meta_df['publish_time']\nmeta_df = meta_df[idx]\nmeta_df.info()","c7dfa50b":"meta_df.drop_duplicates(subset =\"title_lower\", keep='last', inplace=True)\nmeta_df.info()","abb388a1":"meta_df.abstract.str.lower().str.extract(r'^(\\w+)').iloc[:,0].value_counts().head(15)","eb955a72":"max_loops = 5\nabstract_first_words = ['abstract', 'background', 'objective', 'publisher', 'introduction', 'summary']\nwhile max_loops:\n    changed = 0\n    for w in abstract_first_words:\n        regex_pat = re.compile(f'^{w}s?'+ r'\\s*', flags=re.IGNORECASE)\n        idx = meta_df.abstract.str.contains(regex_pat, na=False)\n        changed += sum(idx)\n        meta_df.loc[idx, 'abstract'] = meta_df[idx].abstract.replace(regex_pat, '')\n        \n    regex_pat = re.compile(r'^[.:\/\\-&]+\\s*')\n    idx = meta_df.abstract.str.contains(regex_pat, na=False)\n    changed += sum(idx)\n    meta_df.loc[idx, 'abstract'] = meta_df[idx].abstract.replace(regex_pat, '')\n        \n    print(changed)\n    if changed == 0:\n        break\n    max_loops -= 1\n","c4299adb":"meta_df.abstract.str.lower().str.extract(r'^(\\w+)').iloc[:,0].value_counts().head(15)","3ee3ac8f":"meta_df['abstract_lower'] = meta_df.abstract.str.lower()\nidx = meta_df.groupby(['abstract_lower'])['publish_time'].transform(max) == meta_df['publish_time']\nmeta_df = meta_df[idx]\nmeta_df.info()","4b19e7b2":"meta_df.drop(['abstract_nw', 'title_lower', 'abstract_lower', 'langid'], axis=1, inplace=True)","8454b1b0":"len(meta_df)","cee0643a":"meta_df.reset_index(drop=True, inplace=True)","b4e0f55e":"meta_df.to_pickle(config.OUTPUT_DIR+'meta_df.pkl')","441d140a":"**<center style=\"color:#FBB03B; font-size: 24pt;\">Work in progress...<\/center>**","3750d9c1":"## Remove commun words at the begining of abstracts","a0d438e5":"## Drop duplicates papers (by title)","d73f77a0":"## Drop rows with any NA fields","d4b670c6":"## Drop small abstracts","51d35673":"### Keep one of them","27b1ec0b":"# Clean","a9d5ce4c":"# Load and clean meta data","bf432b4c":"## Drop duplicates papers having same abstract","c49cf22b":"# Save","4d94a552":"### Keep recent publications"}}