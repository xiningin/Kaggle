{"cell_type":{"1c892575":"code","34aca395":"code","ddc6f465":"code","bee9918f":"code","3d9b2493":"code","06d7ecb3":"code","450a5d38":"code","9a7e62d2":"code","cfd27f72":"code","d68ba180":"code","2d060183":"code","7eb58227":"code","bcdecc64":"code","ac8d8e5c":"code","b3f6bd77":"code","90c0424a":"code","e64c93fb":"code","069ff1bf":"code","c5d209d5":"code","e310c92e":"code","0e9548d6":"markdown","83235c1f":"markdown","f28d8b96":"markdown","cecf6458":"markdown","f76d6dd8":"markdown","6e1e888d":"markdown","95d54076":"markdown","3313697c":"markdown"},"source":{"1c892575":"import pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\ndef make_report(y_pred , y_true, fig_size = (20,20)):\n    print (\"\")\n    print (\"Classification Report: \")\n    print (classification_report(y_true, y_pred))\n    cm = confusion_matrix(y_true, y_pred)\n    fig, ax = plot_confusion_matrix(figsize=fig_size, conf_mat=cm)\n    plt.show()","34aca395":"data = pd.read_pickle('\/kaggle\/input\/traffic-signs-preprocessed\/data0.pickle')\nprint('keys:', data.keys())\nprint('train shape:', data['x_train'].shape)\nprint('test shape:', data['x_test'].shape)\nprint('validation shape:', data['x_validation'].shape)","ddc6f465":"for i in range(2):\n    img = data['x_train'][i].T\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()","bee9918f":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y, num_classes):\n        self.x = x\n        self.y = y\n        self.n_class = num_classes\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        x=torchvision.transforms.functional.to_tensor(self.x[idx].astype(np.uint8).reshape((32, 32, 3)))\n        \n        label_idx = self.y[idx]\n        label = np.zeros(self.n_class)\n        label[label_idx] = 1\n        label = torch.tensor(label)\n#         return {'x': self.x[idx], 'y': label}\n        return {'x': x, 'y': label}\n    \nBATCH_SIZE = 256    \ntrain_dataset = MyDataset(data['x_train'], data['y_train'], 43)\ndataLoader_train = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True)\n\ntest_dataset = MyDataset(data['x_test'], data['y_test'], 43)\ndataLoader_test = torch.utils.data.DataLoader(test_dataset,\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True)\n\nvalidation_dataset = MyDataset(data['x_validation'], data['y_validation'], 43)\ndataLoader_validation = torch.utils.data.DataLoader(validation_dataset,\n                                                    batch_size=BATCH_SIZE,\n                                                    shuffle=True)","3d9b2493":"plt.hist(data['y_train'], bins = 43)","06d7ecb3":"class Model(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(64, 512),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.flatten(x) \n        x = self.fc(x)\n        return x\n    \nmodel = Model(43)\nprint(model)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","450a5d38":"%%time\n\nn_epochs = 3\nprint('started!')\nfor epoch in range(n_epochs):\n    train_batch_loss = 0\n    model.train()\n    for step, batch in enumerate(dataLoader_train):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n        train_batch_loss += loss.item()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    test_batch_loss = 0\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader_test):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n            outputs = model(x)\n            loss = criterion(outputs, torch.max(y, 1)[1])\n            test_batch_loss += loss.item()\n\n    print('epoch {}\/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs,\n                                                                              train_batch_loss \/ len(dataLoader_train),\n                                                                              test_batch_loss \/ len(dataLoader_test)))\n    \ntorch.save(model.state_dict(), '.\/model_RGB')","9a7e62d2":"def res(dataLoader):  \n    trues = []\n    preds = []\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n\n            outputs = model(x)\n\n            true_labels = torch.max(y, 1)[1]\n            trues = trues + true_labels.tolist()\n            pred_labels = torch.max(outputs, 1)[1]\n            preds = preds + pred_labels.tolist()\n\n\n    make_report(y_pred = preds, y_true = trues)\n\nprint('Test')\nres(dataLoader_test)\nprint('validation')\nres(dataLoader_validation)","cfd27f72":"data = pd.read_pickle('\/kaggle\/input\/traffic-signs-preprocessed\/data4.pickle')\nprint('keys:', data.keys())\nprint('train shape:', data['x_train'].shape)\nprint('test shape:', data['x_test'].shape)\nprint('validation shape:', data['x_validation'].shape)","d68ba180":"for i in range(2):\n    img = data['x_train'][i].T\n    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n    plt.axis('off')\n    plt.show()","2d060183":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y, num_classes):\n        self.x = x\n        self.y = y\n        self.n_class = num_classes\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        x=torchvision.transforms.functional.to_tensor(self.x[idx].astype(np.uint8).reshape((32, 32, 1)))\n        \n        label_idx = self.y[idx]\n        label = np.zeros(self.n_class)\n        label[label_idx] = 1\n        label = torch.tensor(label)\n#         return {'x': self.x[idx], 'y': label}\n        return {'x': x, 'y': label}\n    \nBATCH_SIZE = 256    \ntrain_dataset = MyDataset(data['x_train'], data['y_train'], 43)\ndataLoader_train = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True)\n\ntest_dataset = MyDataset(data['x_test'], data['y_test'], 43)\ndataLoader_test = torch.utils.data.DataLoader(test_dataset,\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True)\n\nvalidation_dataset = MyDataset(data['x_validation'], data['y_validation'], 43)\ndataLoader_validation = torch.utils.data.DataLoader(validation_dataset,\n                                                    batch_size=BATCH_SIZE,\n                                                    shuffle=True)","7eb58227":"# #68 percent\n# class Model(torch.nn.Module):\n    \n#     def __init__(self, num_classes):\n#         super().__init__()\n        \n#         self.conv = torch.nn.Sequential(\n#             torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(32),\n#             torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(32),\n#         )\n        \n#         self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n#         self.fc = torch.nn.Sequential(\n#             torch.nn.Linear(32, 256),\n#             torch.nn.ReLU(),\n#             torch.nn.Dropout(0.3),\n#             torch.nn.Linear(256, num_classes)\n#         )\n        \n#     def forward(self, x):\n#         x = self.conv(x)\n#         x = self.flatten(x) \n#         x = self.fc(x)\n#         return x\n    \n# model = Model(43)\n# print(model)\n# criterion = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","bcdecc64":"# #81\n# class Model(torch.nn.Module):\n    \n#     def __init__(self, num_classes):\n#         super().__init__()\n        \n#         self.conv = torch.nn.Sequential(\n#             torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(32),\n#             torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(64),\n#         )\n        \n#         self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n#         self.fc = torch.nn.Sequential(\n#             torch.nn.Linear(64, 512),\n#             torch.nn.ReLU(),\n#             torch.nn.Linear(512, num_classes)\n#         )\n        \n#     def forward(self, x):\n#         x = self.conv(x)\n#         x = self.flatten(x) \n#         x = self.fc(x)\n#         return x\n    \n# model = Model(43)\n# print(model)\n# criterion = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","ac8d8e5c":"#90\nclass Model(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(64, 512),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.flatten(x) \n        x = self.fc(x)\n        return x\n    \nmodel = Model(43)\nprint(model)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","b3f6bd77":"%%time\n\nn_epochs = 3\nprint('started!')\nfor epoch in range(n_epochs):\n    train_batch_loss = 0\n    model.train()\n    for step, batch in enumerate(dataLoader_train):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n        train_batch_loss += loss.item()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    test_batch_loss = 0\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader_test):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n            outputs = model(x)\n            loss = criterion(outputs, torch.max(y, 1)[1])\n            test_batch_loss += loss.item()\n\n    print('epoch {}\/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs,\n                                                                              train_batch_loss \/ len(dataLoader_train),\n                                                                              test_batch_loss \/ len(dataLoader_test)))\n    \ntorch.save(model.state_dict(), '.\/model_gray')","90c0424a":"def res(dataLoader):  \n    trues = []\n    preds = []\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n\n            outputs = model(x)\n\n            true_labels = torch.max(y, 1)[1]\n            trues = trues + true_labels.tolist()\n            pred_labels = torch.max(outputs, 1)[1]\n            preds = preds + pred_labels.tolist()\n\n\n    make_report(y_pred = preds, y_true = trues)\n\nprint('Test')\nres(dataLoader_test)\nprint('validation')\nres(dataLoader_validation)","e64c93fb":"model = Model(43)\nmodel.load_state_dict(torch.load('.\/model_gray'))","069ff1bf":"model.conv[0]\ndef imshow_filter(img,row,col):\n    print('-------------------------------------------------------------')\n    plt.figure()\n    for i in range(len(filters)):\n        img = filters[i]\n        img = np.transpose(img, (1, 2, 0))\n        img = img\/(img.max()-img.min())\n        plt.subplot(row,col,i+1)\n        plt.imshow(img,cmap= 'gray')\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()\n\nprint('layer1')\nfilters = model.conv[0].weight.data.cpu().numpy()\nimshow_filter(filters,8, 4)\n\nprint('layer2')\nfilters = model.conv[3].weight.data.cpu().numpy()[:,0:1,:,:]\nimshow_filter(filters,8, 4)\n\nprint('layer3')\nfilters = model.conv[6].weight.data.cpu().numpy()[:,0:1,:,:]\nimshow_filter(filters,8, 8)","c5d209d5":"#90\nclass VizModel(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(64, 512),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        for layer in self.conv:\n            x = layer(x)\n            for i in range(16):\n                img = x.detach().numpy()[0,i:i+1,:,:]\n                img = np.transpose(img, (1, 2, 0))\n                img = img\/(img.max()-img.min())+0.001\n                plt.subplot(8,4,i+1)\n                plt.imshow(img,cmap= 'gray')\n                plt.xticks([])\n                plt.yticks([])\n            plt.savefig('.\/{}.jpg'.format(layer))\n            plt.show()\n\n        x = self.flatten(x) \n        x = self.fc(x)\n        return x\n\nmodel = VizModel(43)\nmodel.load_state_dict(torch.load('.\/model_gray'))","e310c92e":"a = next(iter(dataLoader_train))\nx = a['x'][4:5,:,:,:]\nmodel(x)\n\nimg = x[0,:,:,:].T\nplt.imshow(img, cmap='gray', vmin=0, vmax=1)\nplt.axis('off')\nplt.savefig('.\/sign.jpg')\nplt.show()","0e9548d6":"# EDA","83235c1f":"# Gray scale ","f28d8b96":"so the classes are balanced","cecf6458":"# Imports","f76d6dd8":"# Modeling","6e1e888d":"# Loading data","95d54076":"# Visualization of filters and outputs","3313697c":"## outputs "}}