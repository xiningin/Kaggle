{"cell_type":{"6b554824":"code","1f288f5d":"code","c50ec292":"code","064df60b":"code","dc13e28f":"code","d4032786":"code","a6c6f50a":"code","256b4ba8":"code","48c50eeb":"code","bf417b61":"code","354bc7db":"code","e67c5ac3":"code","b18ecb79":"code","396ad05f":"code","f91ba5e3":"code","73183a6b":"code","625d1d1f":"code","2ae61499":"code","9e9a392f":"code","8ed8b773":"code","5e1a60d3":"code","67aef657":"code","69bfc6ac":"code","b4007708":"code","b5439f62":"code","d3a3137f":"code","72a27a5d":"markdown","74519c83":"markdown","d41b613a":"markdown","648b582f":"markdown","c62b5331":"markdown","f193deb6":"markdown","6bd56782":"markdown","9a18fe38":"markdown","70ab4dec":"markdown","1133d7fe":"markdown","5170d108":"markdown","c6510eef":"markdown","53458189":"markdown","c86ad3dc":"markdown","321c0759":"markdown","7c53dd26":"markdown","14945762":"markdown","2737893e":"markdown","c7b1c204":"markdown","033e86e2":"markdown"},"source":{"6b554824":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f288f5d":"import matplotlib.pyplot as plt\nimport matplotlib.image as mtimg\nimport sklearn\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.layers import Conv2D, Dropout, Flatten, Dense, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport itertools","c50ec292":"train_df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntrain_df.head()","064df60b":"test_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","dc13e28f":"X_train = train_df.drop(columns=['label'], axis = 1)\ny_train = train_df['label']\n\ncountplot = sns.countplot(y_train)\ny_train.value_counts()","d4032786":"X_train.isnull().sum()","a6c6f50a":"# Rescaling the train and test dataframes so that the gradient converges quicker!\n\nX_train\/=255.0\ntest_df\/=255.0","256b4ba8":"X_train = X_train.values.reshape(-1, 28,28,1)\ntest_df = test_df.values.reshape(-1, 28,28,1)","48c50eeb":"y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)","bf417b61":"randomseed = 19\nX_train, X_val,y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = randomseed)","354bc7db":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=5,input_shape=(28, 28, 1), activation = 'relu'))\nmodel.add(Conv2D(32, kernel_size=5, activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size=3,activation = 'relu'))\nmodel.add(Conv2D(64, kernel_size=3,activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size=3, activation = 'relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128, activation = \"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation = \"softmax\"))","e67c5ac3":"model.summary()","b18ecb79":"optimizer = Adam(lr = 0.001)","396ad05f":"train_datagen = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    \n)\n\ntrain_datagen.fit(X_train)","f91ba5e3":"model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])","73183a6b":"EPOCHS = 30\nBATCH_SIZE = 32","625d1d1f":"checkpoint = ModelCheckpoint(\n    '.\/', \n    monitor='val_accuracy',\n    verbose = 1,\n    save_best_only=True,\n    mode='max',\n    save_weights_only = False\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0,\n    patience=5,\n    verbose=1,\n    restore_best_weights=True\n)\n\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    patience=3,\n    verbose=1,\n    factor=0.2,\n    min_lr=0.0001\n)\n\ncallbacks_list = [\n    checkpoint,\n    early_stopping,\n    learning_rate_reduction\n]","2ae61499":"history = model.fit(train_datagen.flow(X_train,y_train),callbacks=callbacks_list, verbose = 1,  validation_data=(X_val, y_val), epochs = EPOCHS)","9e9a392f":"\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","8ed8b773":"#Plotting the history of the model training\nEPOCHS = early_stopping.stopped_epoch#Due to early stopping\nif EPOCHS < 30: \n    EPOCHS +=1 \n\nplt.figure(figsize=(8,8))\nplt.subplot(1,2,1)\nplt.plot(range(EPOCHS), acc, label='Training Accuracy')\nplt.plot(range(EPOCHS), val_acc, label=\"Validation Accuracy\")\nplt.legend(loc=\"lower right\")\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(EPOCHS), loss, label='Training Loss')\nplt.plot(range(EPOCHS), val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","5e1a60d3":"def plot_confusion_matrix(cm , classes, normalize=False, cmap=plt.cm.Blues, title='Confusion Matrix'):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    ticks = np.arange(len(classes))\n    plt.xticks(ticks, classes, rotation = 45)\n    plt.yticks(ticks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","67aef657":"y_pred = model.predict(X_val)\ny_pred_classes = np.argmax(y_pred, axis = 1)\n\ny_true = np.argmax(y_val, axis = 1)\n\ncm = sklearn.metrics.confusion_matrix(y_true, y_pred_classes)\nplot_confusion_matrix(cm, classes=range(10))","69bfc6ac":"errors = (y_pred_classes - y_true != 0)\nY_pred_classes_errors = y_pred_classes[errors]\nY_pred_errors = y_pred[errors]\nY_true_errors = y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    plt.figure(figsize=(100,100))\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","b4007708":"results = model.predict(test_df, verbose = 1)","b5439f62":"results_ndx = np.argmax(results, axis = 1)\nresults_series = pd.Series(results_ndx,name=\"Label\")","d3a3137f":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results_series],axis = 1)\n\nsubmission.to_csv(\".\/cnn_mnist2.csv\",index=False)","72a27a5d":"## Early Stopping Conditions and Modifying the Learning Rate when the Model shows little to no improvement\n\nThis allows our model to escape the LR Plateau and changing the LR enables our model to get more and more accurate.","74519c83":"## Plotting the change in losses and accuracy over the epochs","d41b613a":"We use the Categorical CrossEntropy loss as our predictions are categorical in nature (i.e. 0 to 9)","648b582f":"Thus there are no null values, and we can proceed with our data preprocessing!","c62b5331":"## Visualizing the Errors","f193deb6":"## CNN Model using Tensorflow Sequential API","6bd56782":"## 1. Importing the necessary libraries and doing data preparation","9a18fe38":"> References:\n> 1. [Building a 5 Layer Deep CNN for MNIST](https:\/\/medium.com\/@yugkhanna1\/building-a-5-layer-cnn-model-with-keras-to-identify-handwritten-digits-complex-yet-simple-f06b8b375346)\n> 2. [This awesome notebook!](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6)","70ab4dec":"### Importing dataset","1133d7fe":"Split the train dataframe into train and validation sets to ensure no overfitting occurs!","5170d108":"Thus our data is uniformally distributed and we can directly split it without worries.","c6510eef":"> We observe that our model has done very good at classifying almost all of the validation data. A few mistakes have arisen in 5\/6 discrimation and a few in 4\/9 discrimation (which is likely to be made by a human as well).","53458189":"***Now we reshape the image data into 28 x 28 sized images with one Grayscale channel. If the image was coloured, we would have used (28,28,3) for the RGB channels.***","c86ad3dc":"## We received a whopping 99.33% Validation Accuracy!","321c0759":"[Visit this link to know more about the Model Architecture!](https:\/\/medium.com\/@yugkhanna1\/building-a-5-layer-cnn-model-with-keras-to-identify-handwritten-digits-complex-yet-simple-f06b8b375346)","7c53dd26":"The errors are not stupid in any way and even a human would have reasonable difficulty in correctly classifying the above images. We can be satisfied with the performance of our model!","14945762":"## Confusion Matrix\n\nA confusion matrix helps us to better judge the performance of our model by showing tabular representation of which class got missclassifed as another, allowing us to draw inferences!","2737893e":"Convert the train dataframe to categorical form for easy learning by the CNN. \nNow a label 4 is represented by [0,0,0,1,0,0,0,0,0,0].","c7b1c204":"**We use the Adam Optimizer.**\n\nAdam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n\nWhen introducing the algorithm, the authors list the attractive benefits of using Adam on non-convex optimization problems, as follows:\n\n- Straightforward to implement.\n- Computationally efficient.\n- Little memory requirements.\n- Invariant to diagonal rescale of the gradients.\n- Well suited for problems that are large in terms of data and\/or parameters.\n- Appropriate for non-stationary objectives.\n- Appropriate for problems with very noisy\/or sparse gradients.\n- Hyper-parameters have intuitive interpretation and typically require little tuning.\n","033e86e2":"## Performing Data Augmentation\n\nThe ImageDataGenerator function allows us to create more training examples from already existing examples, by doing small transformations like rotation, zooming, shifting the height and width and so on, which results in believable images. This ensures that the model has enough training data to not overfit and also increases the robustness of the model as it can better respond to variations in the images."}}