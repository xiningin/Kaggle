{"cell_type":{"cca65895":"code","5cce2764":"code","e87f3f44":"code","f1acdd6c":"code","d925604f":"code","f7544be4":"code","dbca6052":"code","d69b3811":"code","e9625916":"code","acd1bb80":"code","836bc64e":"markdown","6145d9a5":"markdown","33b59297":"markdown","74e628e7":"markdown","ef56e17b":"markdown","97d24906":"markdown","7c0b4619":"markdown","4e6bd3ff":"markdown"},"source":{"cca65895":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cce2764":"import keras\nfrom keras.utils import np_utils\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nimport matplotlib.pyplot as plt\n\n\n\n# the data, split between train and test sets\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nprint(x_train.shape, y_train.shape)","e87f3f44":"image_index = 7777 # You may select anything up to 60,000\nprint(y_train[image_index]) # The label is 8\nplt.imshow(x_train[image_index], cmap='Greys')","f1acdd6c":"# x_train.shape[0] = 60000 and x_test.shape[0] = 10000\n\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","d925604f":"y_train = np_utils.to_categorical(y_train, num_classes=None)\n\ny_test = np_utils.to_categorical(y_test, num_classes=None)","f7544be4":"# Modifying the value of each pixel in range of 0 to 1 - improves the learning rate of model\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n# Grey scale values and pixel value ranges from 0 - 255\nx_train \/= 255\nx_test \/= 255\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","dbca6052":"batch_size = 128\nnum_classes = 10\nepochs = 10\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])","d69b3811":"# Trains the model for fixed number of epochs (iterations on the dataset)\nmy_model = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\nprint(\"The model has successfully trained\")\n\n# .h5 is Hierarchical Data Format (HDF). Contains multidimensional arrays of data\nmodel.save('mnist.h5')\nprint(\"Model saved as mnist.h5\")","e9625916":"score = model.evaluate(x_test, y_test, verbose = 1)\n\n# To reduce the loss we have used Adadelta Optimizer in training our model\nprint(\"Test Loss\" , score[0])\nprint(\"Test Accuracy\" , score[1])","acd1bb80":"image_index = 3333 #Data at index 3333 is 7\nplt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\npred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\nprint(pred.argmax())","836bc64e":"**Processing the data**\n\n*   The MNIST dataset of digits are with structure (nb_samples, 28, 28) with 2D per image of 28x28 pixel greyscale.\n\n*   But the *Convolution2D* layers in Keras are designed to work on 3D per example.\n\n*   There are 4D (nb_samples, nb_channels, width, height) with deep layers and each example should become set of feature maps.\n\n*   Thus the examples of MNIST requires different CNN layer design or a parameter , constructor layer to accept this shape.\n\n*   *Thus matrix reshape is done to accept this change (60000, 28, 28, 1) - Padding*\n","6145d9a5":"**Create the model**\n\nCNN model with convolutional and pooling layers. Works better for images with grid structures, CNN works well for image classification problems.\n\nOur convolutional layers will have `64 neurons`(feature maps) and `3x3 feature detector`\n\nIn `max pooling 2x2` matrix. In Keras, a Dense layer implements the operation `output = activation(dot(input, weights) + bias)`\n\n**Convolutional Layers**\n\n![alt text](https:\/\/miro.medium.com\/max\/1332\/1*V7YGj0ZWil9V-i0k74QVSQ.png)\n\n**Pooling Layer**\n\n![alt text](https:\/\/miro.medium.com\/max\/608\/1*oVOUhBIi59Gb5w7eBzqYuA.png)","33b59297":"**Parameters**\n\n`num_classes` - Number of classifier outputs\n\n`batch_size` - Number of samples propagated through network, from total trainig samples the algorithm takes first 128 training dataset from (1 to 128) and trains the network. And subsequently trains with set of 128 till end.\n\n`epochs` - Number of times the training vectors are used to update weights\n\n`Dropout` - Deactivate some neurons while training, to reduce over fitting of model\n\n**Activation function**\n\n`relu` - Commonly used for hidden layers. `max(y,0)` where y is the summation of (Weights and Inputs) + Bias","74e628e7":"## **MNIST Dataset**\n\nModified National Institute of Standards and Technology database\n\nIt is a large dataset of handwritten digits used for training image processing systems\n\nTraining data was taken from American Census Bureau employees \nTesting data was taken from American high school students\n\n**Features**\n1. 60,000 training images , 10,000 testing images\n2. Extended version of MNIST is called EMNIST published in 2017\n3. Each image is 28x28 and linearized vector of 1x784\n\n![mnist dataset](https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/02\/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png)","ef56e17b":"**Evaluating Our Model**\n\nIn test data set we have around 10,000 images. The testing data was not involved in training data.","97d24906":"Digit Recognition using CNN in MNIST dataset. Basic intro towards Keras, CNN, optimizers with detailed explanation.\n\n## *If you like it, Please upvote!*","7c0b4619":"**Converting class vectors to Binary class matrices - One hot encoding**\n\nOur model cannot work on categorical data directly thus **one hot encoding** is performed.\n\nThe digits from 0 - 9 are represented as set of 9 - 0's and 1 - 1's. Where based on the position of 1 the digit is identified.\n\neg) 3 as [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","4e6bd3ff":"**Training the Model**\n\n`model.fit()` - Start the training of the model, takes training data, validation data , epochs and batch size\n\nAfter the training of the model, saving the model and definition in 'mnist.h5' file"}}