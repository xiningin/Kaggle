{"cell_type":{"b921deaa":"code","e5381b86":"code","2e8e5b37":"code","188cea71":"code","5da600e0":"code","1a76af15":"code","2591549f":"code","6f6e1a6a":"code","16885700":"code","644f35e7":"code","0921b036":"code","10a3f6aa":"code","7d64e2ef":"code","601c5bba":"markdown","02ecc81c":"markdown","047a91a3":"markdown","2b5cc77f":"markdown","bad7adc5":"markdown","a69a77f2":"markdown","3e2dfdea":"markdown"},"source":{"b921deaa":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","e5381b86":"data = pd.read_csv('..\/input\/german-credit-data-with-risk\/german_credit_data.csv')","2e8e5b37":"data","188cea71":"data.info()","5da600e0":"def binary_encode(df, columns_with_positive_values):\n    df = df.copy()\n    for column, positive_value in columns_with_positive_values:\n        df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n    return df\n\ndef ordinal_encode(df, columns_with_orderings):\n    df = df.copy()\n    for column, ordering in columns_with_orderings:\n        df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df\n\ndef onehot_encode(df, columns_with_prefixes):\n    df = df.copy()\n    for column, prefix in columns_with_prefixes:\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","1a76af15":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop duplicate id column\n    df = df.drop('Unnamed: 0', axis=1)\n    \n    # Encode missing values as 'none'\n    for column in ['Saving accounts', 'Checking account']:\n        df[column] = df[column].fillna('none')\n    \n    # Binary encode the Sex and Risk columns\n    df = binary_encode(\n        df,\n        columns_with_positive_values=[\n            ('Sex', 'male'),\n            ('Risk', 'bad')\n        ]\n    )\n    \n    # Ordinal encode the Saving accounts and Checking account columns\n    df = ordinal_encode(\n        df,\n        columns_with_orderings=[\n            ('Saving accounts', ['none', 'little', 'moderate', 'rich', 'quite rich']),\n            ('Checking account', ['none', 'little', 'moderate', 'rich'])\n        ]\n    )\n    \n    # One-hot encode the Housing and Purpose columns\n    df = onehot_encode(\n        df,\n        columns_with_prefixes=[\n            ('Housing', 'H'),\n            ('Purpose', 'P')\n        ]\n    )\n    \n    # Split df into X and y\n    y = df['Risk'].copy()\n    X = df.drop('Risk', axis=1).copy()\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","2591549f":"def evaluate_model(model, X_test, y_test, classification_threshold=0.5):\n    \n    y_true = np.array(y_test)\n    \n    y_pred = (model.predict_proba(X_test) >= classification_threshold).astype(np.int)\n    y_pred = list(map(\n        lambda x: x[1],\n        y_pred\n    ))\n    \n    print(\"Test Accuracy: {:.2f}%\".format(accuracy_score(y_true, y_pred) * 100))\n    \n    cm = confusion_matrix(y_true, y_pred)\n    clr = classification_report(y_true, y_pred, target_names=[\"Not Risky\", \"Risky\"])\n    \n    plt.figure(figsize=(8, 8))\n    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.xticks(np.arange(2) + 0.5, [\"Not Risky\", \"Risky\"])\n    plt.yticks(np.arange(2) + 0.5, [\"Not Risky\", \"Risky\"])\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","6f6e1a6a":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","16885700":"X_train","644f35e7":"y_train","0921b036":"y_train.value_counts()","10a3f6aa":"model = LogisticRegression(\n    class_weight={\n        0: 1,\n        1: 1.5\n    }\n)\n\nmodel.fit(X_train, y_train)","7d64e2ef":"evaluate_model(model, X_test, y_test, classification_threshold=0.4)","601c5bba":"# Helper Functions","02ecc81c":"# Results","047a91a3":"# Getting Started","2b5cc77f":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/AWmsXeIcI_E","bad7adc5":"# Preprocessing","a69a77f2":"# Training","3e2dfdea":"# Task for Today  \n\n***\n\n## Loan Risk Prediction  \n  \nGiven *data about German loans*, let's try to detect **high-risk loans** in the data.  \n  \nWe will use a logistic regression model to make our predictions."}}