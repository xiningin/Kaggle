{"cell_type":{"2a467ea9":"code","3448cef7":"code","fe138118":"code","57ce5585":"code","2aa2a521":"code","8c5e998f":"code","49c1fac3":"code","34e9dbae":"code","94214bfe":"code","6a5e673a":"code","06edeebc":"code","35a72563":"code","84fd2cd8":"code","530bebaf":"code","80e94b9c":"code","68c0446d":"code","723431e0":"code","a2376566":"code","de1cdabd":"code","227b5004":"code","09c23ef9":"code","c33c04fa":"code","a5925b43":"code","a2c749a9":"code","344ada7e":"code","654285b0":"code","0d1e7676":"markdown","021136e2":"markdown","7bb4d904":"markdown","dfd840f3":"markdown","db8f0c62":"markdown","813c5479":"markdown","e70acd59":"markdown","04805b04":"markdown","97a817f5":"markdown","6a63fed6":"markdown","edb1c507":"markdown","2b2fb14e":"markdown","1e7272be":"markdown"},"source":{"2a467ea9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3448cef7":"df = pd.read_csv('\/kaggle\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\ndf.head()","fe138118":"df.describe()","57ce5585":"df.describe(include=['object'])","2aa2a521":"df['neighbourhood_group'].value_counts().to_frame()","8c5e998f":"df['room_type'].value_counts().to_frame()","49c1fac3":"df_grp1 = df[['neighbourhood_group','price']].groupby(['neighbourhood_group'],as_index=False).mean()\ndf_grp1=df_grp1.rename(columns={'price':'average_price'})\ndf_grp1","34e9dbae":"df_grp2 = df[['room_type','price']].groupby(['room_type'],as_index=False).mean()\ndf_grp2=df_grp2.rename(columns={'price':'average_price'})\ndf_grp2","94214bfe":"df_grp3 = df[['neighbourhood_group','room_type','price']].groupby(['neighbourhood_group','room_type'],as_index=False).mean()\ndf_grp3 = df_grp3.rename(columns={'price':'average_price'})\ndf_pivot = df_grp3.pivot(index='room_type',columns='neighbourhood_group')\ndf_pivot","6a5e673a":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15, 6))\nsns.scatterplot(x=df.longitude,y=df.latitude,hue=df.neighbourhood_group)\nplt.title('Airbnb distribtion across the 5 boroughs of NY')","06edeebc":"import folium\nfrom folium import plugins\n# New York coordinates\nlat = 40.7128\nlon = -74.0060\nny_map = folium.Map(location=[lat,lon], zoom_start=12)   # create new york map\n# instantiate a marker cluster for the airbnb locations in the dataframe\nairbnb =  plugins.MarkerCluster().add_to(ny_map)\n\n# randomly select a portion of the data for plotting on the map\ndf_smp = df.sample(frac=0.1, replace=False, random_state=1)\nlatitudes = list(df_smp.latitude)\nlongitudes = list(df_smp.longitude)\nprice = list(df_smp.price)\nlabels = ['$'+str(x)+' per night' for x in price]  # add pop-up price to each marker on the map\n# loop through the data and add markers to feature group\ni = 0\nfor lat, lng, label in zip(latitudes, longitudes, labels):\n    folium.Marker(\n        location=[lat, lng],\n        icon=None,\n        popup=label,\n    ).add_to(airbnb)\n\nny_map\n","35a72563":"colors_list = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'lightgreen']\nexplode_list = [0.05, 0.05, 0, 0.05, 0.05] # ratio for each feature with which to offset each wedge.\n\ndf_grp1['average_price'].plot(kind='pie',\n                            figsize=(15, 6),\n                            autopct='%1.1f%%', \n                            startangle=45,    \n                            shadow=True,       \n                            labels=None,         # turn off labels on pie chart\n                            pctdistance=1.12,    # the ratio between the center of each pie slice and the start of the text generated by autopct \n                            colors=colors_list,  # add custom colors\n                            explode=explode_list # 'explode' lowest 3 continents\n                            )\n\n# scale the title up by 12% to match pctdistance\nplt.title('Average Airbnb Price in New York 5 Boroughs', y=1.12) \nplt.axis('equal') \n# add legend\nplt.legend(labels=df_grp1['neighbourhood_group'], loc='upper left') \n\nplt.show()","84fd2cd8":"ax = df_pivot.T.plot.bar(figsize=(12, 6))\nplt.ylabel('Average price ($)')\nplt.xlabel('Boroughs')\nax.set_xticklabels(df_grp1['neighbourhood_group'])","530bebaf":"fig,ax = plt.subplots()\nim = ax.pcolor(df_pivot, cmap='hot_r')\n\nylabels = df_pivot.columns.levels[1]\nxlabels = df_pivot.index\n\nax.set_xticks(np.arange(df_pivot.shape[1]) + 0.5, minor=False)\nax.set_yticks(np.arange(df_pivot.shape[0]) + 0.5, minor=False)\n\nax.set_xticklabels(ylabels, minor=False)\nax.set_yticklabels(xlabels, minor=False)\n\n#rotate label if too long\nplt.xticks(rotation=45)\n\ncbar = fig.colorbar(im)\ncbar.ax.set_ylabel('average price')\nplt.show()","80e94b9c":"df_num = df.select_dtypes(exclude=['object'])\ndf_num.head()","68c0446d":"nan = df_num.isnull()\nfor column in nan.columns.values.tolist():\n    print(nan[column].value_counts())\n    print('')","723431e0":"df_num.fillna(0, inplace=True)","a2376566":"# remove features that don't contribute to price prediction\nX = df_num.drop(['id','host_id','latitude','longitude','price'],axis=1)\ny = df_num['price']","de1cdabd":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nlr = LinearRegression()\nsgdr = SGDRegressor()\nmlpreg = MLPRegressor(random_state=0, max_iter=100)\nsvrl = SVR(kernel='linear',C=0.01)\nrfreg = RandomForestRegressor()\nxgr = XGBRegressor()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nscaler = StandardScaler() \n\npipeline = Pipeline(steps=[('scaler',scaler),('name',xgr)])\nmodel = pipeline.fit(X_train,y_train)\nscore = model.score(X_test,y_test)\npredict = model.predict(X_test)\nmae = mean_absolute_error(y_test,predict)#, squared=False)\n    \nprint('score: %1.3f, mae: %1.4f'%(score,mae))","227b5004":"# room_type and neigbourhood_group\nrmtyp = pd.get_dummies(df['room_type'])\nneigh_grp = pd.get_dummies(df['neighbourhood_group'])\nneigh = pd.get_dummies(df['neighbourhood'])\ndf_new = pd.concat([df_num,rmtyp,neigh_grp,neigh], axis=1)\ndf_new.head()","09c23ef9":"X = df_new.drop(['id','host_id','price','latitude','longitude'],axis=1)\ny = df_new['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9)\n\npipeline = Pipeline(steps=[('scaler',scaler),('name',xgr)])\nmodel = rfreg.fit(X_train,y_train)\nscore = model.score(X_test,y_test)\npredict = model.predict(X_test)\nmae = mean_absolute_error(y_test,predict)\n    \nprint('score: %1.3f, mae: %1.4f'%(score,mae))","c33c04fa":"plt.figure(figsize=(10,6), dpi=80)\nsns.boxplot(df_new['price'])","a5925b43":"# price outliers removal\nq3 = df_new['price'].quantile(0.75)\nq1 = df_new['price'].quantile(0.25)\nprice_ub = q3 + 1.5*(q3-q1)      # upper bound\nprice_lb = q1 - 1.5*(q3-q1)     # lower bound\ndf_new2 = df_new[df_new.price < price_ub]\nprint('removed outliers: ',df_new.shape[0]-df_new2.shape[0])","a2c749a9":"X = df_new2.drop(['id','host_id','price','latitude','longitude'],axis=1) \ny = df_new2['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=30)\n\npipeline = Pipeline(steps=[('scaler',scaler),('name',xgr)])\nmodel = pipeline.fit(X_train,y_train)\nscore = model.score(X_test,y_test)\npredict = model.predict(X_test)\nmae = mean_absolute_error(y_test,predict)\n    \nprint('score: %1.3f, mae: %1.4f'%(score,mae))","344ada7e":"from sklearn.model_selection import cross_val_score\n\ncv_score = cross_val_score(xgr, X, y, cv=4, scoring='neg_mean_absolute_error')\nprint('cross validation mae: ', -1*cv_score)","654285b0":"#predict = model.predict(X)\nprdct = pd.DataFrame(predict, columns=['predicted_price'])\ndf_submit = pd.concat([df_new2['id'],prdct], axis=1)\ndf_submit.to_csv('NY_airbnb_predicted_price.csv')","0d1e7676":"Not much improvement. Lets check for outliers in the price labels..\n","021136e2":"# Task Details\nAs of August 2019, this data set contains almost 50 thousand airbnb listings in NYC. The purpose of this task is to predict the price of NYC Airbnb rentals based on the data provided and any external dataset(s) with relevant information.\n\n# Evaluation\nA solution with low root-mean-squared error (RMSE) based on cross-validation that can be reproduced and interpreted is ideal. Given the limited number of variables in this dataset, accurate predictions will be difficult.","7bb4d904":"# Lets throw in some visuals","dfd840f3":"All the tested models performed poorly. Let's add some non-numeric features. ","db8f0c62":"Now we re-train..","813c5479":"Removal of outliers helped!","e70acd59":"Now we train a model...","04805b04":"Lets check cross validation scores","97a817f5":"only the column 'reviews_per_month' has NaNs. We deal it...","6a63fed6":"# Some quick stats...","edb1c507":"**Not bad!**","2b2fb14e":"I have a habit of testing multiple models...","1e7272be":"# Lets develop a model based on numeric features only"}}