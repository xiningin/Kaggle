{"cell_type":{"6b98f28b":"code","556b294c":"code","1d4b8680":"code","a001206a":"code","d1835d0c":"code","9eb0d571":"code","227d5eee":"code","b41d44d7":"code","1e080ee5":"code","fd446046":"code","9849d9ee":"code","3d92d5f1":"code","b468fa36":"code","5da7062d":"code","69499e4e":"markdown","8e990b06":"markdown","16bfe00b":"markdown","a96838ed":"markdown","46f278b1":"markdown","6fec22e8":"markdown","724e88d4":"markdown","26af1270":"markdown","8830aba6":"markdown"},"source":{"6b98f28b":"from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\nfrom keras.preprocessing.image import load_img, img_to_array\n\nimport numpy as np \nimport sklearn.cluster","556b294c":"model = InceptionV3()","1d4b8680":"from PIL import Image\nimport requests\nurl = 'https:\/\/i.guim.co.uk\/img\/media\/c9b0aad22638133aa06cd68347bed2390b555e63\/0_477_2945_1767\/master\/2945.jpg?width=1200&height=1200&quality=85&auto=format&fit=crop&s=97bf92d90f51da7067d00f8156512925'\nimage_cat = Image.open(requests.get(url, stream=True).raw)\nimage_cat = image_cat.resize((299,299))","a001206a":"image_cat","d1835d0c":"# Convert to numpy array, reshape and preprocess\nimage = img_to_array(image_cat)\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\nimage = preprocess_input(image)\nimage[0].shape","9eb0d571":"predictions = model.predict(image)","227d5eee":"#function of keras, allows to see the prob of each prediction\ndecode_predictions(predictions)","b41d44d7":"# extract the index of the top 5 classes predicted by the model for the image selected \nmodel.predict(image).argsort()[0, -5:][::-1]\n\n#keep the index of the first and the second class \nfirst_class = model.predict(image).argsort()[0, -5:][-1]\nsecond_class = model.predict(image).argsort()[0, -5:][-2]","1e080ee5":"!pip install lime\nfrom lime.lime_image import LimeImageExplainer","fd446046":"explainer = LimeImageExplainer()","9849d9ee":"explanation = explainer.explain_instance(image[0], #the image\n                                         model.predict, \n                                         top_labels=2, #want just to see the 2 main classes predicted\n                                         num_samples=500, # number of observation sampled from the original distribution in order to computer the linear regression\n                                         random_seed=42)","3d92d5f1":"from skimage.segmentation import mark_boundaries\nfrom matplotlib import pyplot as plt","b468fa36":"# maps for the first class predicted\ntemp, mask = explanation.get_image_and_mask(first_class, positive_only=True, num_features=5, hide_rest=True)\n# plot image and mask together\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nprint('mask for prediction of class: ',decode_predictions(predictions)[0][0][1])","5da7062d":"# maps for the second class predicted \ntemp, mask = explanation.get_image_and_mask(second_class, positive_only=True, num_features=5, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nprint('mask for prediction of class: ', decode_predictions(predictions)[0][1][1])","69499e4e":"In this notebook I will use Lime method (In this notebook I will use Lime method ([LIme information](https:\/\/steadforce.com\/en\/explainable-ai-with-lime\/)) to observe what are the information that the model used \n to observe what are the information that the model used \nfor classification of the image.","8e990b06":"That's it . The mask presented in the 2 picture represent the picture that the model used for the classification task of the image. This is a very powerful for the interpretation of the ML model, since they are considered as 'black boxes'.","16bfe00b":"# EXPLENABILITY USING LIME ","a96838ed":"\nwe call explain_instance to generate a new explanation. We need to provide:\n\nour observation: here the first row of our numpy matrix (that has only one row since we only have one image)\n\nour predict function, we can simply use the one from our model here top_labels the number of classes to explain. Here our model generate probabilities for more than a 1000 classes (and we looked at the five first).\n\nWe do not want LIME to generate local models to explain each of those classes. As lime is pretty slow with images, let's only ask for the explanation to our two main classes,\n\nnum_samples: the number of new datapoints to create to fit a linear model, let's set it to 500","46f278b1":"We will use a random picture for applying the lime mode, be free to choose whatever picture you like.","6fec22e8":"In this model, I will use a pretrained CNN, specifically InceptionV3 ([here more information](https:\/\/en.wikipedia.org\/wiki\/Inceptionv3)), since the aim of this notebook is not built a model, but evaluated it. ","724e88d4":"\nexplanation.get_image_and_mask() allows to take and plot the maps.\n\nindex of the class to explain (that we discovered before)\n\npositive_only: In order to show the part of the image that contribute positively to this class being selected\n\nnum_features: number of superpixels to use. LIME breaks down our image into a set of superpixels, each containing several pixels. Those superpixels are equivalent to features in tabular data.\n\nhide_rest: to hide the rest of the image\n\nThat returns a new image and a mask as numpy arrays. You can then use mark_boundaries to show the image together with the mask.","26af1270":"Please use GPU for running this notebook, and upvote it if you like it :)","8830aba6":"# LIME"}}