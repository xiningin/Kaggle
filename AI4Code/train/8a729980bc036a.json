{"cell_type":{"dcb43708":"code","d95645dc":"code","3469a416":"code","d3e09d07":"code","0b75e21e":"code","3b655d9a":"code","bb5e7567":"code","0ddd0a8b":"code","046d6f46":"code","8d8a24c2":"code","e377b5c9":"code","b27dfbd0":"code","62e851c3":"code","f6c66027":"code","4ba88adb":"code","b16a5cf8":"code","56a16494":"code","0839489c":"code","f9977d2d":"code","1d0ffef9":"code","f14c7a5e":"code","fadd7c81":"code","7dfdea67":"code","7c7c162d":"code","dd748c1e":"code","53fe89fe":"code","e020e933":"code","8fd582b5":"code","b2d9a223":"code","9a10aa64":"code","7738f55f":"code","09c605ab":"code","7f28e07a":"code","2e863966":"code","6aaedd86":"code","ec088c60":"code","2335b54a":"code","f05dbae5":"code","d0cfe011":"code","91243425":"code","237d6894":"code","5dd79257":"markdown","4875140f":"markdown","89bd27db":"markdown","0ef40323":"markdown","d945d913":"markdown","a83c2d8f":"markdown","3121e634":"markdown","63213c9d":"markdown","e4143877":"markdown","fb82f71b":"markdown","648d6a31":"markdown","5f2679c5":"markdown","790dc845":"markdown","d075e24b":"markdown","3fc202ca":"markdown","1ac4cc97":"markdown","d9fea909":"markdown","726b7266":"markdown","137ad28d":"markdown","08338cd2":"markdown","9e6183e7":"markdown"},"source":{"dcb43708":"import numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as Data","d95645dc":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nPassengerId = test['PassengerId']\nall_data = pd.concat([train,test], ignore_index = True)","3469a416":"train.info()","d3e09d07":"sns.catplot(x='Sex', y='Survived', hue='Pclass', kind=\"bar\", data=train)","0b75e21e":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=2)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=[0, train['Age'].max()])\nfacet.add_legend()\nplt.xlabel('Age')\nplt.ylabel('Survival density')","3b655d9a":"sns.catplot(x='Embarked',hue='Survived', kind='count', data=train)","bb5e7567":"all_data['Title'] = all_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\nprint(set(dict(all_data['Title']).values()))\nall_data.info()\nTitle_Dict = {}\nTitle_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))\nTitle_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))\nTitle_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))\nTitle_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))\nTitle_Dict.update(dict.fromkeys(['Mr'], 'Mr'))\nTitle_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))\n\nall_data['Title'] = all_data['Title'].map(Title_Dict)\nsns.barplot(x=\"Title\", y=\"Survived\", data=all_data)","0ddd0a8b":"all_data['FamilySize'] = all_data['SibSp'] + all_data['Parch'] + 1\nsns.catplot(x='FamilySize', y='Survived', kind='bar', data=all_data)","046d6f46":"def famLabel(s):\n    if s>=2 and s<=4:\n        return 2\n    elif ((s>4) and (s<=7)) or (s==1):\n        return 1\n    elif (s>7):\n        return 0\n    \nall_data['FamilyLabel'] = all_data['FamilySize'].apply(famLabel)\nsns.catplot(x='FamilyLabel', y='Survived', kind='bar', data=all_data)","8d8a24c2":"all_data['Cabin'] = all_data['Cabin'].fillna('Unknown')\nall_data['Deck'] = all_data['Cabin'].str.get(0)\nsns.catplot(x='Deck', y='Survived', kind='bar', data=all_data)","e377b5c9":"def deckLabel(s):\n    if s=='E' or s=='D' or s=='B':\n        return 2\n    elif s=='U' or s=='C' or s=='G' or s=='A' or s=='F':\n        return 1\n    else:\n        return 0\n\nall_data['DeckLabel'] = all_data['Deck'].apply(deckLabel)\nsns.barplot(x='DeckLabel', y='Survived', data=all_data)","b27dfbd0":"ticketCount = dict(all_data['Ticket'].value_counts())\nall_data['TicketGroup'] = all_data['Ticket'].apply(lambda x: ticketCount[x])\nsns.catplot(x='TicketGroup', y='Survived', kind='bar', data=all_data)","62e851c3":"def ticLabel(s):\n    if s>=2 and s<=4:\n        return 2\n    elif (s>4 and s<=8) or (s==1):\n        return 1\n    elif s>11:\n        return 0\n    \nall_data['TicketLabel'] = all_data['TicketGroup'].apply(ticLabel)\nsns.barplot(x='TicketLabel', y='Survived', data=all_data)","f6c66027":"age_df = all_data[['Age', 'Pclass', 'Sex', 'Title']]\nage_df=pd.get_dummies(age_df)\nknown_age = age_df[age_df.Age.notnull()].values\nunknown_age = age_df[age_df.Age.isnull()].values\ny = known_age[:, 0]\nX = known_age[:, 1:]\nrfr = RandomForestRegressor(random_state=0, n_estimators=100, n_jobs=-1)\nrfr.fit(X, y)\npredictedAges = rfr.predict(unknown_age[:, 1::])\nall_data.loc[ (all_data.Age.isnull()), 'Age' ] = predictedAges","4ba88adb":"all_data[all_data['Embarked'].isnull()]","b16a5cf8":"all_data.groupby(by=[\"Pclass\",\"Embarked\",\"TicketLabel\",\"DeckLabel\"]).Fare.median()","56a16494":"all_data['Embarked'] = all_data['Embarked'].fillna('C')","0839489c":"all_data[all_data['Fare'].isnull()]","f9977d2d":"fare=all_data[(all_data['Embarked'] == \"S\") & (all_data['Pclass'] == 3) & (all_data['TicketLabel'] == 1.0)].Fare.median()\nall_data['Fare']=all_data['Fare'].fillna(fare)","1d0ffef9":"all_data['Surname'] = all_data['Name'].apply(lambda x: x.split(',')[0].strip())\nsurname_Count = dict(all_data['Surname'].value_counts())\nall_data['FamilyGroup'] = all_data['Surname'].apply(lambda x:surname_Count[x])\nFemale_Child_Group = all_data.loc[(all_data['FamilyGroup'] >= 2 ) & ((all_data['Age'] <= 12) | (all_data['Sex'] == 'female'))]\nMale_Adult_Group = all_data.loc[(all_data['FamilyGroup'] >= 2) & (all_data['Age'] > 12 ) & (all_data['Sex'] == 'male')]","f14c7a5e":"Female_Child=pd.DataFrame(Female_Child_Group.groupby('Surname')['Survived'].mean().value_counts())\nFemale_Child.columns=['GroupCount']\nFemale_Child","fadd7c81":"sns.barplot(x=Female_Child.index, y=Female_Child[\"GroupCount\"])\nplt.xlabel('Average Survived')","7dfdea67":"MaleAdult = pd.DataFrame(Male_Adult_Group.groupby('Surname')['Survived'].mean().value_counts())\nMaleAdult.columns=['GroupCount']\nMaleAdult","7c7c162d":"sns.barplot(x=MaleAdult.index, y=MaleAdult['GroupCount'])","dd748c1e":"Female_Child_Group=Female_Child_Group.groupby('Surname')['Survived'].mean()\nDead_List=set(Female_Child_Group[Female_Child_Group.apply(lambda x:x==0)].index)\nprint(Dead_List)\nMale_Adult_List=Male_Adult_Group.groupby('Surname')['Survived'].mean()\nSurvived_List=set(Male_Adult_List[Male_Adult_List.apply(lambda x:x==1)].index)\nprint(Survived_List)","53fe89fe":"train=all_data.loc[all_data['Survived'].notnull()]\ntest=all_data.loc[all_data['Survived'].isnull()]\ntest.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Sex'] = 'male'\ntest.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Age'] = 60\ntest.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Title'] = 'Mr'\ntest.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Sex'] = 'female'\ntest.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Age'] = 5\ntest.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Title'] = 'Miss'\nall_data.info()","e020e933":"all_data=pd.concat([train, test])\nall_data=all_data[['Survived','Pclass','Sex','Age','Fare','Embarked','Title','FamilyLabel','DeckLabel','TicketGroup']]\nall_data=pd.get_dummies(all_data)\ntrain=all_data[all_data['Survived'].notnull()]\ntest=all_data[all_data['Survived'].isnull()].drop('Survived',axis=1)\nX = train.values[:,1:]\ny = train.values[:,0]","8fd582b5":"scaler=StandardScaler()\nX_scaled=scaler.fit(X).transform(X)","b2d9a223":"model = LogisticRegression()\nmodel.fit(X_scaled,y)\nscore = cross_val_score(model, X_scaled, y, cv= 10)\nprint(\"{}:{},{}\".format('LR',score.mean(),score.std()))","9a10aa64":"model = SVC()\nmodel.fit(X_scaled,y)\nscore = cross_val_score(model, X_scaled, y, cv= 10)\nprint(\"{}:{},{}\".format('SVM',score.mean(),score.std()))","7738f55f":"model = GradientBoostingClassifier()\nmodel.fit(X_scaled,y)\nscore = cross_val_score(model, X_scaled, y, cv= 10)\nprint(\"{}:{},{}\".format('GDBT',score.mean(),score.std()))","09c605ab":"myNet = nn.Sequential(\n    nn.Linear(17, 8),\n    nn.ReLU(),\n    nn.Linear(8, 4),\n    nn.ReLU(),\n    nn.Linear(4, 1),\n    nn.Sigmoid()\n)","7f28e07a":"optimzer = torch.optim.SGD(myNet.parameters(), lr=0.05)\nloss_func = nn.MSELoss()","2e863966":"def train(model, train_x, train_y, epoch_num, criterion, optimizer):\n    accuracy = 0\n    for epoch in range(epoch_num):\n        out = model(train_x)\n        loss = criterion(out, train_y)\n        \n        preds = (out > torch.Tensor([0.5])).squeeze()\n        true_preds = (preds==train_y.squeeze()).sum().item()\n        accuracy = true_preds\/preds.shape[0]\n        \n        if epoch % 1000 == 0:\n            print('Epoch: {:2d} | Loss: {:.4f} | Accurancy: {:.4f}'.format(epoch, loss, accuracy))\n        optimzer.zero_grad()\n        loss.backward()\n        optimzer.step()\n        \ntrain_X=torch.Tensor(X_scaled)\nexp_y = np.expand_dims(y, axis=1)\ntrain_Y=torch.Tensor(exp_y)\ntrain(myNet, train_X, train_Y, 10000, loss_func, optimzer)","6aaedd86":"test_scaled_X=scaler.fit(test).transform(test)\ntest_X=torch.Tensor(test_scaled_X)\npred_y = myNet(test_X)\npredictions = []\nfor i in pred_y:\n    if i > torch.Tensor([0.5]):\n        predictions.append(1)\n    else:\n        predictions.append(0)\n        \nsubmission = pd.DataFrame({\"PassengerId\": PassengerId, \"Survived\": predictions})\nsubmission.to_csv(\".\/titanic.csv\", index=False)","ec088c60":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()  \n        self.fc = nn.Sequential(\n            nn.Linear(17, 8),\n            nn.ReLU(),\n            nn.Linear(8, 4),\n            nn.ReLU(),\n            nn.Linear(4, 1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, inputs):\n        return self.fc(inputs)","2335b54a":"myNet = Net()\nprint(myNet)","f05dbae5":"# Train\noptimzer = torch.optim.SGD(myNet.parameters(), lr=0.005, momentum=0.9)\nloss_func = nn.BCELoss()","d0cfe011":"def train(model, loader, epoch_num, criterion, optimizer):\n    losses = []\n    accuracy_reocrd = []\n    for epoch in range(epoch_num):\n        running_loss = 0.0\n        batches = 0\n        accuracy = []\n        for step, (batch_x, batch_y) in enumerate(loader):\n            \n            optimzer.zero_grad()\n            out = model(batch_x)\n\n            preds = (out > torch.Tensor([0.5])).squeeze()\n            true_preds = (preds==batch_y.squeeze()).sum().item()\n            accuracy.append(true_preds\/preds.shape[0])\n            \n            loss = criterion(out, batch_y)\n            loss.backward()\n\n            optimizer.step()\n            running_loss += loss.item()\n            batches += 1\n            \n        losses.append(running_loss\/batches) \n        aver_accuracy = np.mean(accuracy)\n        accuracy_reocrd.append(aver_accuracy)\n        if epoch % 1000 == 0:\n            print('Epoch: {:2d} | Loss: {:.4f} | Accurancy: {:.4f}'.format(epoch, losses[-1], aver_accuracy))\n    return losses, accuracy_reocrd\n        \ntrain_X=torch.Tensor(X_scaled)\nexp_y = np.expand_dims(y, axis=1)\ntrain_Y=torch.Tensor(exp_y)\n\ntorch_dataset = Data.TensorDataset(train_X, train_Y)\nloader = Data.DataLoader(\n    dataset=torch_dataset,\n    batch_size=100,\n    shuffle=True,\n)\n\nloss, accuracy = train(myNet, loader, 10000, loss_func, optimzer)","91243425":"def plot_loss_accuracy(loss, accuracy):\n    fid = plt.figure(figsize=(20,5))\n\n    Axes = plt.subplot(121, title=\"loss\")\n    Axes.axes.tick_params(which='both',direction='in',top=True, right=True)\n    plt.minorticks_on()\n    Axes.set_facecolor((0,0,0,0.02))\n    # draw the line\n    loss_X = np.arange(0,len(loss))\n    plt.plot(loss_X, loss, 'k-', linewidth=3, color = 'r', label='loss')\n    plt.grid(True,which='major',linewidth=0.5)\n    plt.grid(True,which='minor',linewidth=0.1)\n    plt.xlabel(\"epoch number\")\n    plt.ylabel(\"loss\")\n    plt.legend(loc='best',fontsize='x-small')\n\n    Axes = plt.subplot(122, title=\"accuracy\")\n    Axes.axes.tick_params(which='both',direction='in',top=True, right=True)\n    plt.minorticks_on()\n    Axes.set_facecolor((0,0,0,0.02))\n    # draw the line\n    accuracy_X = np.arange(0,len(accuracy))\n    plt.plot(accuracy_X, accuracy, 'k-', linewidth=3, color = 'b', label='accuracy')\n    plt.grid(True,which='major',linewidth=0.5)\n    plt.grid(True,which='minor',linewidth=0.1)\n    plt.xlabel(\"epoch number\")\n    plt.ylabel(\"accuracy\")\n    plt.legend(loc='best',fontsize='x-small')","237d6894":"plot_loss_accuracy(loss, accuracy)","5dd79257":"# Survival rate of women is higher than men","4875140f":"# Train with GDBT","89bd27db":"# Age<12 child survival rate is higher","0ef40323":"# Prepare for the training data","d945d913":"# Try NN networks","a83c2d8f":"# Fill missing Embarked Data","3121e634":"# Train with LR","63213c9d":"# Fill missing Fare data","e4143877":"# Different Cabin level has different survival rate","fb82f71b":"# Deal with some abnormal training data (women\/child dead or men,adult live)","648d6a31":"# Train","5f2679c5":"**Author: Xueren Ge**    \n**Time: Dec,8,2020**","790dc845":"# Normalization","d075e24b":"# different Ticket has different survival rate","3fc202ca":"# Output with NN networks","1ac4cc97":"# Train with SVM","d9fea909":"# More trial\n\nuse **batches** to train, and adjust some parameters, but it seems doesn't work better :(","726b7266":"# Name indicate the occupation, different career has different survival rates","137ad28d":"# Fill missing Age data","08338cd2":"# Embarked site C has more survival rate","9e6183e7":"# Family size has an impact on survival rate"}}