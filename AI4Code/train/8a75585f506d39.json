{"cell_type":{"8ebc1ffd":"code","47f19033":"code","62cb08e1":"code","2d2bcc67":"code","7be09a02":"code","fbdf32de":"code","09b5e53a":"code","1ab496ab":"code","1476ffa9":"code","7a10c710":"code","a27b342d":"code","99421349":"code","609c44e9":"code","fbde590d":"code","d5c5d934":"code","ff32d980":"code","94eaaa4c":"code","fb26b5ff":"code","c8933ff4":"code","aa956a07":"code","233d878e":"code","9dc19fe9":"code","dfb2a4df":"code","56ecb024":"code","24d3117c":"code","8e8d3378":"code","5bccd753":"code","f9b1343c":"code","1bc78147":"code","8f30e7e5":"code","d6bf280e":"code","bf29cff3":"code","db046c0a":"code","e1927902":"code","4e851934":"markdown","f8f4d017":"markdown","dc46745a":"markdown"},"source":{"8ebc1ffd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47f19033":"# Importing libraries\nimport pandas as pd\nimport numpy as np","62cb08e1":"# Reading the input data file\nimport csv\ndf_camp = pd.read_csv('..\/input\/customer-personality-analysis\/marketing_campaign.csv', sep='\\t')\ndf_camp.head()","2d2bcc67":"# Describing the input dataframe\ndf_camp.describe()","7be09a02":"# Null check in dataframe\ndf_camp.isna().sum()","fbdf32de":"# Remove the columns where Income is null\ndf_camp = df_camp[~df_camp['Income'].isna()]\ndf_camp.isna().sum()","09b5e53a":"# Dropping Z variable because it is already considered\ndf_camp.drop(['Z_CostContact','Z_Revenue'],axis=1 ,inplace=True)\ndf_camp.columns","1ab496ab":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.displot(df_camp['Year_Birth'])","1476ffa9":"# Handling education column\ndf_camp['Education'] = df_camp['Education'].replace(['PhD','Master','2n Cycle'],'Post Graduate')\ndf_camp['Education'] = df_camp['Education'].replace(['Graduation','Basic'],'Under Graduate')\ndf_camp['Education'].unique()","7a10c710":"# Vizualizing distribution of education column\nsns.displot(df_camp['Education'])","a27b342d":"## Vizualizing distribution of marital status column\nsns.displot(df_camp['Marital_Status'])\nplt.xticks(rotation=45)\nplt.show()","99421349":"df_camp['Marital_Status'] = df_camp['Marital_Status'].replace(['Together','Married'],'Relationship')\ndf_camp['Marital_Status'] = df_camp['Marital_Status'].replace(['Single','Divorced','Widow','Alone','Absurd','YOLO'],'Single')\ndf_camp['Marital_Status'].unique()","609c44e9":"# Vizualizing distribution of updated marital status column\nsns.displot(df_camp['Marital_Status'])","fbde590d":"# Combining features\nprint(df_camp['Kidhome'].unique())\nprint(df_camp['Teenhome'].unique())\n\ndf_camp['Total_kids'] = df_camp['Kidhome'] + df_camp['Teenhome']\ndf_camp['Total_kids'].unique()","d5c5d934":"# Vizualizing distribution of total kids column\nsns.displot(df_camp['Total_kids'].sort_values().astype(str))","ff32d980":"# Viewing all the columns in the new dataframe\ndf_camp.columns","94eaaa4c":"# Creating new features using expense\ndf_camp['Total_expense'] = df_camp['MntWines'] + df_camp['MntFruits'] + df_camp['MntMeatProducts'] + df_camp['MntFishProducts'] + df_camp['MntSweetProducts'] + df_camp['MntGoldProds']\nsns.displot(df_camp['Total_expense'])","fb26b5ff":"# Creating new features using campaign acceptance features\ndf_camp['Total_accepted'] = df_camp['AcceptedCmp1'] + df_camp['AcceptedCmp2'] + df_camp['AcceptedCmp3'] + df_camp['AcceptedCmp4'] + df_camp['AcceptedCmp5']\ndf_camp['Total_accepted'].unique()","c8933ff4":"# Vizualizing the distribution plot for total accepted feature\nsns.displot(df_camp['Total_accepted'].astype(str))","aa956a07":"# Creating new feature - Total purchase\ndf_camp['Total_purchase'] = df_camp['NumDealsPurchases'] + df_camp['NumWebPurchases'] + df_camp['NumCatalogPurchases'] + df_camp['NumStorePurchases'] \nsns.displot(df_camp['Total_purchase'])","233d878e":"df_camp['Dt_Customer'] = pd.to_datetime(df_camp['Dt_Customer'])","9dc19fe9":"df_camp['first_date'] = pd.to_datetime('01-01-2015')\ndf_camp['days_engaged'] = (df_camp['first_date'] - df_camp['Dt_Customer']).dt.days","dfb2a4df":"# importing date class from datetime module\nfrom datetime import date\n\n# creating the date object of today's date\ntodays_date = date.today()\n\n# fetching the current year, month and day of today\ndf_camp['current_year'] = todays_date.year\n\ndf_camp['total_year_enrol'] = df_camp['current_year'] - pd.DatetimeIndex(df_camp['Dt_Customer']).year","56ecb024":"df_camp.columns","24d3117c":"# Dropping unnecessary columns\ndf_camp.drop(['Kidhome','Teenhome', 'Dt_Customer', 'MntWines', 'MntFruits',\n       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n       'AcceptedCmp2', 'first_date','ID'],axis=1,inplace=True)\ndf_camp.columns","8e8d3378":"# Getting all the categorical variable\ncatg_col=[]\nfor i in df_camp.columns:\n    if(df_camp[i].dtype =='object'):\n        catg_col.append(i)\n        \nprint(catg_col)","5bccd753":"# Label encoding for all categorical nominal variable\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\nfor i in catg_col:\n    df_camp[i]= encoder.fit_transform(df_camp[i])\n    \nprint(df_camp)","f9b1343c":"# Implement standardization of features\nfrom sklearn.preprocessing import StandardScaler\nscale_data = StandardScaler()\ndf_val = scale_data.fit_transform(df_camp.values)\ndf_model = pd.DataFrame(df_val, columns=df_camp.columns)\ndf_model","1bc78147":"# Determining correlation between all correlation\nplt.figure(figsize=(15,15))\nsns.heatmap(df_camp.corr(),annot=True,cmap = 'YlGnBu',linewidths=1)","8f30e7e5":"# Creating new dataframe for clustering\ndf_model.columns\nX = df_model.iloc[:,[3,10]]","d6bf280e":"# Elbow method to calculate N\nfrom sklearn.cluster import KMeans\nwcss = [] \nfor i in range(1, 11): \n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X) \n    wcss.append(kmeans.inertia_)\n\nplt.plot(range(1, 11), wcss)\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS') \nplt.show()","bf29cff3":"# Validating all the columns which will be used for clustering\nX.columns","db046c0a":"# K means Clustering\nkmeans = KMeans(n_clusters=2, init=\"k-means++\",random_state=50)\nlabel = kmeans.fit_predict(X[['Income', 'Total_purchase']])","e1927902":"#Getting the Centroids\ncentroids = kmeans.cluster_centers_\nu_labels = np.unique(label)\n \n#plotting the results:\nfor i in u_labels:\n    plt.scatter(X[label == i].iloc[:,0] , X[label == i].iloc[:,1] , label = i)\nplt.scatter(centroids[:,0] , centroids[:,1] , s = 60, color = \"black\")\nplt.xlabel('Income')\nplt.ylabel('Total Purchase')\nplt.legend()\nplt.show()","4e851934":"The most important insight is that customer who have low income has less purchases are much wiser than customers who have low income and high purchase","f8f4d017":"## Insights","dc46745a":"## <center>Customer Personality Analysis<\/center>"}}