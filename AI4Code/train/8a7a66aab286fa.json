{"cell_type":{"68fb40cd":"code","1171d307":"code","bc5e3844":"code","4293b524":"code","386d9287":"code","8f836542":"code","4ff18950":"code","01f78114":"code","e761e610":"code","d08fef82":"code","bd39e86e":"code","27d6250b":"code","9fe679e9":"code","a6d31dbc":"code","98e2b91a":"code","5cd1e3f5":"code","1a9f3eba":"code","86381dd2":"code","c57075d0":"code","73c60459":"code","0257bed7":"code","ab561f21":"code","6e70093d":"code","e41043fe":"code","47aa1387":"code","16ef9b4f":"code","29ece6a9":"code","5d33ecf5":"code","f9cb8682":"code","18ecc669":"code","c57b287f":"code","0fdf6b52":"code","f3cffd1c":"code","e6f9f18b":"code","97a58449":"code","b86fe5d3":"code","e9ef9067":"code","23e8fce5":"code","d606c8cb":"code","e7e7c2f3":"code","2e0376f9":"code","f54c508e":"code","cea18220":"code","e6e98fcd":"code","ce4c7446":"code","7a36f298":"code","91092d6e":"code","e72cf206":"code","c5fd1211":"code","3fe391c7":"code","4f0d6891":"code","c33826b8":"code","ddc3ce10":"code","bb659154":"code","99d50270":"code","1a9ad8ea":"code","e47b5883":"markdown","d0e6ae60":"markdown","f49c0cba":"markdown","b4095bcf":"markdown","cc2b27c1":"markdown","e656fddd":"markdown","7c942ef9":"markdown","5a7c4f50":"markdown","5a4c8623":"markdown","af591114":"markdown","32f0c0ac":"markdown","149ebf71":"markdown","01aa16f0":"markdown","f7765149":"markdown","a75584f2":"markdown","dde4042a":"markdown","e02fda4a":"markdown","9fee7d2a":"markdown","30a189b9":"markdown","c6f07d79":"markdown","99033b1a":"markdown","8da733cd":"markdown","123d876d":"markdown","4ab6a4f7":"markdown","afa11404":"markdown","8ec52e79":"markdown","bf39b41f":"markdown","6ea53b1b":"markdown","cea26b89":"markdown","06137c6e":"markdown","cde45037":"markdown","b9849b77":"markdown","e709af63":"markdown","0257b74e":"markdown","a0a43248":"markdown","f89a21bc":"markdown","2376e56b":"markdown","932dbf1a":"markdown","bb78eb0f":"markdown","ceefe7d9":"markdown","9da05630":"markdown","52fb0a3e":"markdown","924ca89f":"markdown","b4d2423f":"markdown","81639129":"markdown","f99f1f23":"markdown","e86d0a8f":"markdown","c9933628":"markdown","0c1175ef":"markdown","1a062197":"markdown","fb5dc0c3":"markdown","976522da":"markdown","e55cd937":"markdown"},"source":{"68fb40cd":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport lightgbm as lgb \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom itertools import product\nfrom sklearn.cluster import KMeans\nimport os","1171d307":"!pwd","bc5e3844":"!ls -l \/kaggle\/input\/hcg-test-data-services-dept","4293b524":"read_dir = \"\/kaggle\/input\/hcg-test-data-services-dept\"","386d9287":"booking = pd.read_csv(f\"{read_dir}\/bookings.csv\")\nLTV = pd.read_csv(f\"{read_dir}\/LTV_class.csv\")","8f836542":"booking","4ff18950":"LTV","01f78114":"booking.info()","e761e610":"booking.describe(include=\"all\")","d08fef82":"def correct_type_booking(booking,LTV):\n    booking[\"GuestID\"] = booking['GuestID'].apply(lambda x:str(x))\n    LTV[\"GuestID\"] = LTV['GuestID'].apply(lambda x:str(x))\n    booking[\"RoomGroupID\"] = booking['RoomGroupID'].apply(lambda x:str(x))\n    booking.loc[booking[\"RoomNo\"].notna(),\"RoomNo\"] = booking.loc[booking[\"RoomNo\"].notna(),\"RoomNo\"].apply(lambda x:str(x))\n    return booking,LTV\nbooking,LTV = correct_type_booking(booking,LTV)","bd39e86e":"booking.describe(include=\"object\")","27d6250b":"booking.describe()","9fe679e9":"LTV.describe()","a6d31dbc":"labeled_booking = pd.merge(booking, LTV, on='GuestID',how=\"outer\")\nlabeled_booking","98e2b91a":"labeled_booking[labeled_booking.LTV_Cluster.notna()].describe()","5cd1e3f5":"labeled_booking[labeled_booking.LTV_Cluster.notna()].describe(include=\"object\")","1a9f3eba":"ltv_id = LTV.GuestID\nbooking_id = labeled_booking.GuestID\nprint(\"number of custommers have labels is\",len(ltv_id))\nprint(\"number of custommers in database is\",len(booking_id.unique()))","86381dd2":"sub_df = labeled_booking[[\"GuestID\",\"CreatedDate\"]] # ID of guest and the booking date\nnum_booking = sub_df.groupby(\"GuestID\").count().sort_values(by=\"CreatedDate\",ascending=False)\nnum_booking","c57075d0":"ax = sns.countplot(x=\"CreatedDate\", data=num_booking)\nfor container in ax.containers:\n    ax.bar_label(container)\nax.set_xlabel(\"num booking of a guest\")\nplt.show()","73c60459":"vis_data = pd.merge(num_booking,LTV,how=\"outer\",on=\"GuestID\")\nvis_data[\"LTV_Cluster\"] = vis_data[\"LTV_Cluster\"].fillna(value=\"Unidentify\")\nax = sns.countplot(x=\"LTV_Cluster\", data=vis_data,order=[\"Unidentify\",1,2,3])\nfor container in ax.containers:\n    ax.bar_label(container)\nax.set_xlabel(\"life-time value\")\nax.set_ylabel(\"count customers\")\nplt.show()","0257bed7":"vis_data = labeled_booking.copy()\nvis_data[\"LTV_Cluster\"] = vis_data[\"LTV_Cluster\"].fillna(value=\"Unidentify\")\nax = sns.countplot(x=\"LTV_Cluster\", data=vis_data)\nfor container in ax.containers:\n    ax.bar_label(container)\nax.set_xlabel(\"life-time value\")\nax.set_ylabel(\"count bookings\")\nplt.show()","ab561f21":"num_booking[\"returning\"] = num_booking[\"CreatedDate\"]>1","6e70093d":"vis_data = pd.merge(num_booking,LTV,how=\"outer\",on=\"GuestID\")\nvis_data[\"LTV_Cluster\"] = vis_data[\"LTV_Cluster\"].fillna(value=\"Unidentify\")\nax = sns.countplot(\n    x=\"LTV_Cluster\", hue=\"returning\", \n    data=vis_data,order=[\"Unidentify\",1,2,3])\n\n# add annotations\nfor c in ax.containers:\n    \n    # custom label calculates percent and add an empty string so 0 value bars don't have a number\n    labels = [f'{v.get_height():.0f}' if v.get_height() > 0 else '0' for v in c]\n    \n    ax.bar_label(c, labels=labels, label_type='edge')\n\nplt.show()","e41043fe":"vis_data = labeled_booking.copy()\nvis_data[\"Channel\"] = vis_data[\"Channel\"].fillna(\"Missing\")\nax = sns.countplot(\n    x=\"LTV_Cluster\", hue=\"Channel\", \n    data=vis_data)\n\n# add annotations\nfor c in ax.containers:\n\n    labels = [f'{v.get_height():.0f}' if v.get_height() > 0 else '' for v in c]\n    \n    ax.bar_label(c, labels=labels, label_type='edge')\n\nplt.show()","47aa1387":"a = labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"RoomGroupID\"]].copy()\na[\"RoomGroupID\"] = a[\"RoomGroupID\"].str.upper().apply(lambda x:[x])\nb = a.groupby(\"GuestID\").sum()\nb = b.reset_index()\n#apply set to filter out the similar values, then get length to know how many country appear in each guest row\nb[\"LenRoomGroupID\"] = b[\"RoomGroupID\"].apply(lambda x:len(set(x)))\nb[\"RoomGroupID\"] = b[\"RoomGroupID\"].apply(lambda x:str(set(x)))\nax = sns.countplot(data = b,x=\"RoomGroupID\")\nfor container in ax.containers:\n    ax.bar_label(container)\n\nax.set_xlabel(\"RoomGroupID per guest\")\nplt.show()","16ef9b4f":"vis_data = labeled_booking.copy()\nax = sns.countplot(\n    x=\"LTV_Cluster\", hue=\"RoomGroupID\", \n    data=vis_data)\n\n# add annotations\nfor c in ax.containers:\n\n    labels = [f'{v.get_height():.0f}' if v.get_height() > 0 else '' for v in c]\n    \n    ax.bar_label(c, labels=labels, label_type='edge')\n\nplt.show()","29ece6a9":"sns.heatmap(\n    labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"RoomPrice\",\"TotalPayment\",\"Adults\",\"Children\"]]\n    .corr(),\n    annot = True\n    )","5d33ecf5":"sns.pairplot(labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"RoomPrice\",\"TotalPayment\",\"Adults\",\"Children\"]])","f9cb8682":"sns.heatmap(labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"RoomPrice\",\"TotalPayment\",\"Adults\",\"Children\"]]\n            .groupby(\"GuestID\")\n            .sum()\n            .corr()\n            ,annot = True)","18ecc669":"a = labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"Country\"]].copy()\na[\"Country\"] = a[\"Country\"].apply(lambda x:[x])\nb = a.groupby(\"GuestID\").sum()\nb = b.reset_index()\n\n#apply set to filter out the similar values, then get length to know how many country appear in each guest row\nb[\"Country\"] = b[\"Country\"].apply(lambda x:len(set(x)))\n\nax = sns.countplot(data = b[b.Country>1],x=\"Country\")\nfor container in ax.containers:\n    ax.bar_label(container)\n\nax.set_xlabel(\"Country per guest\")\nplt.show()","c57b287f":"vis_data = labeled_booking[labeled_booking.LTV_Cluster.notna()]\nvis_data = vis_data[[\"Country\",\"CreatedDate\"]].groupby(\"Country\").count().sort_values(by=\"CreatedDate\",ascending=False).reset_index().head(20)\nax = sns.barplot(x=\"Country\",y=\"CreatedDate\",data=vis_data)\n\n# add annotations\nfor c in ax.containers:\n\n    labels = [f'{v.get_height():.0f}' if v.get_height() > 0 else '' for v in c]\n    \n    ax.bar_label(c, labels=labels, label_type='edge')\n\nplt.show()","0fdf6b52":"vis_data = labeled_booking[labeled_booking.LTV_Cluster.notna()]\nvis_data = vis_data[[\"Country\",\"CreatedDate\"]].groupby(\"Country\").count().sort_values(by=\"CreatedDate\",ascending=True).reset_index().head(20)\nax = sns.barplot(x=\"Country\",y=\"CreatedDate\",data=vis_data)\n\n# add annotations\nfor c in ax.containers:\n\n    labels = [f'{v.get_height():.0f}' if v.get_height() > 0 else '' for v in c]\n    \n    ax.bar_label(c, labels=labels, label_type='edge')\n\nplt.show()","f3cffd1c":"a = labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"Status\"]].copy()\na[\"Status\"] = a[\"Status\"].str.upper().apply(lambda x:[x])\nb = a.groupby(\"GuestID\").sum()\nb = b.reset_index()\n#apply set to filter out the similar values, then get length to know how many country appear in each guest row\nb[\"LenStatus\"] = b[\"Status\"].apply(lambda x:len(set(x)))\nb[\"Status\"] = b[\"Status\"].apply(lambda x:str(set(x)))","e6f9f18b":"ax = sns.countplot(data = b,x=\"Status\")\nfor container in ax.containers:\n    ax.bar_label(container)\n\nax.set_xlabel(\"Status per guest\")\nplt.show()","97a58449":"labeled_booking[\"ArrivalDate\"] = pd.to_datetime(labeled_booking[\"ArrivalDate\"],format=\"%Y-%m-%d\")\nlabeled_booking[\"CreatedDate\"] = pd.to_datetime(labeled_booking[\"CreatedDate\"],format=\"%Y-%m-%d\")\nlabeled_booking[\"DepartureDate\"] = pd.to_datetime(labeled_booking[\"DepartureDate\"],format=\"%Y-%m-%d\")","b86fe5d3":"vis_data = labeled_booking[labeled_booking.LTV_Cluster.notna()].copy()\nvis_data[\"arrival_quarter\"] = vis_data[\"ArrivalDate\"].dt.quarter\nax = sns.countplot(data = vis_data,x=\"arrival_quarter\")\nfor c in ax.containers:\n\n    labels = [f'{v.get_height():.0f}' if v.get_height() > 0 else '' for v in c]\n    \n    ax.bar_label(c, labels=labels, label_type='edge')\nplt.show()\nax = sns.countplot(data = vis_data,x=\"arrival_quarter\",hue=\"LTV_Cluster\")\nfor c in ax.containers:\n\n    labels = [f'{v.get_height():.0f}' if v.get_height() > 0 else '' for v in c]\n    \n    ax.bar_label(c, labels=labels, label_type='edge')\nplt.show()","e9ef9067":"def create_planning_staying_days(df):\n    df = df.copy()\n    df[\"PlanningTime\"] = (df[\"ArrivalDate\"]-df[\"CreatedDate\"]).apply(lambda x:x.days)\n    df[\"StayingTime\"] = (df[\"DepartureDate\"]-df[\"ArrivalDate\"]).apply(lambda x:x.days)\n    return df","23e8fce5":"vis_data = labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"ArrivalDate\",\"CreatedDate\",\"DepartureDate\",\"LTV_Cluster\"]].copy()\nvis_data = create_planning_staying_days(vis_data)\nvis_data = vis_data.groupby(\"GuestID\").mean()\nsns.displot(vis_data, x=\"PlanningTime\", col=\"LTV_Cluster\", bins=100)\nplt.show()\nsns.displot(vis_data, x=\"StayingTime\", col=\"LTV_Cluster\", bins=50)\nplt.show()","d606c8cb":"def create_cost_feature(df):\n    df = df.copy()\n    df1 = df.copy().groupby(\"GuestID\").mean()\n    df2 = df[[\"GuestID\",\"TotalPayment\"]].copy().groupby(\"GuestID\").sum()\n\n    df1 = df1.rename(\n    {\n        \"TotalPayment\":\"AvgPaymentPerBooking\",\n        \"RoomPrice\":\"AvgRoomPricePerBooking\",\n    },\n    axis =1)\n\n    df = pd.merge(df1,df2,on=\"GuestID\")\n    return df","e7e7c2f3":"vis_data = labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"TotalPayment\",\"RoomPrice\",\"LTV_Cluster\"]].copy()\nvis_data = create_cost_feature(vis_data)","2e0376f9":"sns.displot(vis_data, x=\"TotalPayment\", col=\"LTV_Cluster\", bins=20)\nplt.show()\nsns.displot(vis_data, x=\"AvgPaymentPerBooking\", col=\"LTV_Cluster\", bins=20)\nplt.show()\nsns.displot(vis_data, x=\"AvgRoomPricePerBooking\", col=\"LTV_Cluster\", bins=20)\nplt.show()","f54c508e":"def create_person_feat(df):\n    df = df.copy().groupby(\"GuestID\").mean()\n    return df","cea18220":"vis_data = labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"Adults\",\"Children\",\"LTV_Cluster\"]].copy()\nvis_data = create_person_feat(vis_data)","e6e98fcd":"sns.displot(vis_data, x=\"Adults\", col=\"LTV_Cluster\", bins=50)\nplt.show()\nsns.displot(vis_data, x=\"Children\", col=\"LTV_Cluster\", bins=50)\nplt.show()","ce4c7446":"def avg_days_between_booking(df):\n    df_group = df.groupby(\"GuestID\")\n    AVG_DAYs = {}\n    for group in df_group.groups.keys():\n        total_booking = df.loc[df_group.groups[group],:].sort_values(by=\"CreatedDate\",ascending=False)\n        avg_date = (total_booking[\"CreatedDate\"].iloc[0]-total_booking[\"CreatedDate\"].iloc[-1])\/(len(total_booking)-1)\n        AVG_DAYs[group] = avg_date.days\n    df = df_group.mean().reset_index()\n    df = pd.merge(\n        df,\n        pd.DataFrame({\"GuestID\":AVG_DAYs.keys(),\"AvgDateBetweenBookings\":AVG_DAYs.values()}),\n        on=\"GuestID\",\n        how=\"outer\"\n    )\n    return df","7a36f298":"vis_data = labeled_booking[labeled_booking.LTV_Cluster.notna()][[\"GuestID\",\"CreatedDate\",\"LTV_Cluster\"]].copy()\nvis_data = avg_days_between_booking(vis_data)\nsns.displot(vis_data, x=\"AvgDateBetweenBookings\", col=\"LTV_Cluster\", bins=50)\nplt.show()","91092d6e":"def turn_to_datetime(df,cols):\n    df = df.copy()\n    for col in cols:\n        df[col] = pd.to_datetime(df[col],format=\"%Y-%m-%d\")\n    return df\n\ndef turn_to_0_1(df,cols):\n    df = df.copy()\n    for col in cols:\n        df[col] = df[col]\/df[col].max()\n    return df\n\ndef min_max_scaling(df,cols):\n    df = df.copy()\n    for col in cols:\n        df[col] = (df[col]-df[col].min())\/(df[col].max()-df[col].min())\n    return df\n\ndef standardizing(df,cols):\n    df = df.copy()\n    for col in cols:\n        df[col] = (df[col]-df[col].mean())\/df[col].std()\n    return df\n\ndef get_categorical_feat(df,cols):\n    df = df.copy()\n    list_new_df = []\n    for col in cols:\n        df[col] = df[col].str.upper().apply(lambda x:[x])\n        df_group = df.groupby(\"GuestID\").sum().reset_index()\n        df_group[col] = df_group[col].apply(lambda x:set(x))\n        dummies_df = df_group[col].str.join(sep='*').str.get_dummies(sep='*')\n        list_new_df.append(dummies_df)\n    df_group.drop(columns=cols,inplace=True)\n    df = pd.concat([df_group,*list_new_df],axis=1)\n    return df    ","e72cf206":"def create_RFM_feature(directory):\n    booking = pd.read_csv(f\"{directory}\/bookings.csv\")\n    LTV = pd.read_csv(f\"{directory}\/LTV_class.csv\")\n    booking,LTV = correct_type_booking(booking,LTV)\n    num_booking = booking[[\"GuestID\",\"CreatedDate\"]].groupby(\"GuestID\").count().sort_values(by=\"CreatedDate\",ascending=False)\n    num_booking[\"returning\"] = num_booking[\"CreatedDate\"]>1\n    returning_guest = num_booking[num_booking[\"returning\"]]\n    guest_id = returning_guest.index\n    RFM_feat = {\"R_value\":[],\"F_value\":[],\"M_value\":[]}\n    for id in guest_id:\n        guest_df = booking[booking.GuestID==id]\n        R_value = pd.Timestamp('1\/1\/2021') - pd.to_datetime(guest_df.DepartureDate).max()\n        F_value = len(guest_df.groupby(by=['ArrivalDate']))\n        M_value = guest_df.TotalPayment.sum()\n        RFM_feat[\"R_value\"].append(R_value.days)\n        RFM_feat[\"F_value\"].append(F_value)\n        RFM_feat[\"M_value\"].append(M_value)\n    RFM_feat[\"GuestID\"] = guest_id\n    RFM_feat = pd.DataFrame(RFM_feat)\n    return RFM_feat","c5fd1211":"RFM_feat = create_RFM_feature(f'{read_dir}')\nRFM_feat","3fe391c7":"def load_data_and_feature_engineering(directory):\n    booking = pd.read_csv(f\"{directory}\/bookings.csv\")\n    LTV = pd.read_csv(f\"{directory}\/LTV_class.csv\")\n    booking,LTV = correct_type_booking(booking,LTV)\n    labeled_booking = pd.merge(booking, LTV, on='GuestID',how=\"outer\")\n    num_booking = labeled_booking[[\"GuestID\",\"CreatedDate\"]].groupby(\"GuestID\").count().sort_values(by=\"CreatedDate\",ascending=False)\n    num_booking[\"returning\"] = num_booking[\"CreatedDate\"]>1\n    df = pd.merge(labeled_booking,num_booking.drop(columns=[\"CreatedDate\"]),how='outer',on='GuestID')\n    df = df[df.returning==True]\n    df_labeled_ungroup = df[df.LTV_Cluster.notna()]\n    df_unlabeled_ungroup = df[df.LTV_Cluster.isna()]\n\n    #Correct datetime type\n    datetime_feat = turn_to_datetime(df_labeled_ungroup[[\"GuestID\",\"CreatedDate\",\"ArrivalDate\",\"DepartureDate\"]],[\"CreatedDate\",\"ArrivalDate\",\"DepartureDate\"])\n    datetime_feat_unlab = turn_to_datetime(df_unlabeled_ungroup[[\"GuestID\",\"CreatedDate\",\"ArrivalDate\",\"DepartureDate\"]],[\"CreatedDate\",\"ArrivalDate\",\"DepartureDate\"])\n    # Create planning and staying time\n    datetime_feat = create_planning_staying_days(datetime_feat)\n    datetime_feat = avg_days_between_booking(datetime_feat)\n    datetime_feat_unlab = create_planning_staying_days(datetime_feat_unlab)\n    datetime_feat_unlab = avg_days_between_booking(datetime_feat_unlab)\n\n    # Cost feature\n    cost_feature = df_labeled_ungroup[[\"GuestID\",\"TotalPayment\",\"RoomPrice\"]].copy()\n    cost_feature = create_cost_feature(cost_feature)\n    cost_feature_unlab = df_unlabeled_ungroup[[\"GuestID\",\"TotalPayment\",\"RoomPrice\"]].copy()\n    cost_feature_unlab = create_cost_feature(cost_feature_unlab)\n\n    # People feature\n    people_feature = df_labeled_ungroup[[\"GuestID\",\"Adults\",\"Children\"]].copy()\n    people_feature = create_person_feat(people_feature)\n    people_feature_unlab = df_unlabeled_ungroup[[\"GuestID\",\"Adults\",\"Children\"]].copy()\n    people_feature_unlab = create_person_feat(people_feature_unlab)\n\n    #Merge all numeric feature\n    numeric_feat = pd.merge(cost_feature,datetime_feat,on=\"GuestID\")\n    numeric_feat = pd.merge(numeric_feat,people_feature,on=\"GuestID\")\n    numeric_feat_unlab = pd.merge(cost_feature_unlab,datetime_feat_unlab,on=\"GuestID\")\n    numeric_feat_unlab = pd.merge(numeric_feat_unlab,people_feature_unlab,on=\"GuestID\")\n\n    #Normalize\n    numeric_feat = turn_to_0_1(numeric_feat,[\"AvgPaymentPerBooking\",\"AvgRoomPricePerBooking\",\"TotalPayment\",\"PlanningTime\",\"StayingTime\",\"AvgDateBetweenBookings\"])\n    numeric_feat_unlab = turn_to_0_1(numeric_feat_unlab,[\"AvgPaymentPerBooking\",\"AvgRoomPricePerBooking\",\"TotalPayment\",\"PlanningTime\",\"StayingTime\",\"AvgDateBetweenBookings\"])\n    \n    # sign to know unlabel\n    numeric_feat_unlab[\"LTV_Cluster\"] = -1\n\n    # Categorical feature: RoomGroupId, Status\n    categorical_feat = get_categorical_feat(df_labeled_ungroup[[\"GuestID\",\"RoomGroupID\",\"Status\"]],[\"RoomGroupID\",\"Status\"])\n    categorical_feat_unlab = get_categorical_feat(df_unlabeled_ungroup[[\"GuestID\",\"RoomGroupID\",\"Status\"]],[\"RoomGroupID\",\"Status\"])\n    categorical_feat_unlab.drop(columns=[\"I\"],inplace=True)\n\n    #feat\n    feat = pd.merge(numeric_feat,categorical_feat,on=\"GuestID\")\n    feat = pd.merge(feat,LTV,on=\"GuestID\")\n    feat_unlab = pd.merge(numeric_feat_unlab,categorical_feat_unlab,on=\"GuestID\")\n\n    # Drop correlate features and RFM feature\n    feat = feat.drop(columns=[\"StayingTime\",\"TotalPayment\"])\n    feat_unlab = feat_unlab.drop(columns=[\"StayingTime\",\"TotalPayment\"])\n\n    return feat,feat_unlab","4f0d6891":"feat,feat_unlab = load_data_and_feature_engineering(f\"{read_dir}\")","c33826b8":"print(\"Given LTV cluster\")\nsns.heatmap(feat.corr())\nplt.show()\nprint(\"Not Given LTV cluster\")\nsns.heatmap(feat_unlab.corr())\nplt.show()","ddc3ce10":"def train_lightgbm_without_add_more_data(feat):\n    #Using given LTV cluster\n    l = sklearn.preprocessing.LabelEncoder()\n    l.fit(feat.LTV_Cluster) \n    feat.LTV_Cluster=pd.Series(l.transform(feat.LTV_Cluster))\n    x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(\n        feat.drop(columns=[\"LTV_Cluster\",\"GuestID\"]),\n        feat[\"LTV_Cluster\"],\n        test_size=.2,\n        random_state=47)\n    train_data=lgb.Dataset(x_train,label=y_train)\n    #setting parameters for lightgbm\n    param = {'num_leaves':50, 'objective':'multiclass','num_class':3,'max_depth':7,'learning_rate':.05,'max_bin':200}\n    param['metric'] = ['multiclass']\n    num_round=100\n    lgbm=lgb.train(param,train_data,num_round)\n    train_pred=lgbm.predict(x_train)\n    train_pred = np.argmax(train_pred,axis=1)\n    print(\"Training Result\\n\",sklearn.metrics.classification_report(y_train, train_pred))\n    test_pred=lgbm.predict(x_test)\n    test_pred = np.argmax(test_pred,axis=1)\n    print(\"Testing Result\\n\",sklearn.metrics.classification_report(y_test, test_pred))\n","bb659154":"train_lightgbm_without_add_more_data(feat)","99d50270":"def train_lightgbm_with_data_from_rfm(feat,feat_unlab,RFM_feat):\n    # Create new cluster and train lightgbm without rfm features\n    KM = KMeans(n_clusters=3,max_iter=1000,random_state=47)\n    RFM_feat[\"LTV_Cluster\"] = KM.fit_predict(RFM_feat[['R_value','M_value','F_value']])\n    mixed_feat = pd.concat([feat.drop(columns=[\"LTV_Cluster\"]),feat_unlab.drop(columns=[\"LTV_Cluster\"])],axis=0).reset_index(drop=True)\n    mixed_feat = pd.merge(mixed_feat,RFM_feat[[\"GuestID\",\"LTV_Cluster\"]],on=\"GuestID\").drop(columns=[\"GuestID\"])\n    \n    x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(\n        mixed_feat.drop(columns=[\"LTV_Cluster\"]),\n        mixed_feat[\"LTV_Cluster\"],\n        test_size=.2,\n        random_state=47)\n    train_data=lgb.Dataset(x_train,label=y_train)\n    #setting parameters for lightgbm\n    param = {'num_leaves':10, 'objective':'multiclass','num_class':3,'max_depth':5,'learning_rate':.05,'max_bin':100}\n    param['metric'] = ['multiclass']\n    num_round=50\n    \n    lgbm=lgb.train(param,train_data,num_round)\n    \n    train_pred=lgbm.predict(x_train)\n    train_pred = np.argmax(train_pred,axis=1)\n    print(\"Training Result\\n\",sklearn.metrics.classification_report(y_train, train_pred))\n    \n    test_pred=lgbm.predict(x_test)\n    test_pred = np.argmax(test_pred,axis=1)\n    print(\"Testing Result\\n\",sklearn.metrics.classification_report(y_test, test_pred))","1a9ad8ea":"train_lightgbm_with_data_from_rfm(feat,feat_unlab,RFM_feat)","e47b5883":"* Average days between bookings of guests in `cluster1` are often shorter than `cluster2` and `cluster3` with focusing on range 0-300 while this number is 0-600 on the others.","d0e6ae60":"correct data type\n\n* `GuestID` is currently `int` but it should be converted to string to represent the categorical meaning and can be visualized with `tensorflow_data_validation`\n* `RoomGroupID`, `RoomNo` are categorical too, do the same\n* `RoomNo` has missing values, so do a bit trick to avoid transform `null` value into string \"nan\"","f49c0cba":"## Average planning time (time between the booking date and arrival date) and staying time (between arrival and departure time) per booking","b4095bcf":"\ud83e\udc32 6914 customers do not have labels","cc2b27c1":"* Create RFM value based on basic formular in description to create labels.","e656fddd":"## What is status","7c942ef9":"summary statistics of all variables","5a7c4f50":"Conclude:\n* Guests often arrive hotel at the beginning of a year, and gradually decrease quarterly\n* Guests coming in Q1 and Q2 distribute quite similarly, where mostly have LTV Cluster 1 value \n* Guests coming hotels in Q4 is likely belong to LTV_Cluster 2(**Medium**) while the cluster 1 and 3 share the same value. ","5a4c8623":"The country value of each guest in different booking is not the same, so this value is not the country where they come from or their nationality, it can be the location when they booking.\n\n* Let see top 20 country they book from","af591114":"There are 5401 customers just booking once in this database (first-time customer). \n\n1642 guests booked twice, 253 guest booked 3 times, etc. All of them are called returning customers.\n\nThe number of returning customers is over 1642 ,but there are just 496 guests mentioned in label file","32f0c0ac":"* Almost guests in **cluster3** and **cluster2** don't bring children when booking hotel while **cluster1** bring them more frequently.\n* guest in **cluster3** come to hotel with amount of adults between 0-2.5, this number of **cluster2** and **cluster1** is much more with upto 3-3.5 person.","149ebf71":"## Which channels each LTV-value-customers often use to book hotel","01aa16f0":"## How Room group affect LTV cluster ","f7765149":"No idea about this one, but it's can be encode by one-hot","a75584f2":"## Average days between bookings of each guest","dde4042a":"## Average Adults and Children per booking of guest","e02fda4a":"## With each customer, does the total of RoomPrice and TotalPayment correlate to each other, also check against total amount of adults and children","9fee7d2a":"\ud83e\udc32 Just 1210 row have labels, 8790 others do not have","30a189b9":"* Reproduce the features transform in above steps to get the new dataset, remove the first-time customers","c6f07d79":"* Check whether each guest has unique country value or not","99033b1a":"There are some points: \n\n* missing values in 3 column `Channel` **(37.19%)**, `RoomNo` **(2.1%)**, `Country` **(4.82%)** in `Booking` file.\n* column `CreatedDate` and `ArrivalDate` in `Booking` doesn't have missing value so it means that in this database, there is no custommer cancel the booking or the cancel bookings are not recorded\n* Take into account the 2 visualizations ,`GuestID` in `Booking` has `10000` rows but unique column is `7410`, `GuestID` in `LTV` has `496` row and unique value is `496`. ID in LTV is unique but ID in Booking is not\n","8da733cd":"These features in each booking is not too correlated to each other","123d876d":"* Transform date columns to datetime format","4ab6a4f7":"# Explore given labels and feature","afa11404":"* Train LightGBM from new cluster created from RFM features","8ec52e79":"Count customers of each `num_booking`","bf39b41f":"* Quite good with 0.99% acc on train set and 0.90% acc on test set. F1 is acceptable on cluster 0,1 but not on cluster 2. It because there're too little data. Try to create new data based on RFM feature","6ea53b1b":"there are a slight correlation between the total amount of customers in `RoomPrice` against `TotalPayment` and `Adults`","cea26b89":"* Train LightGBM with given LTV cluster","06137c6e":"* **cluster1** pay below 3000 averagely, focus on range from 0-2000\n* **cluster2** pay the same with **cluster1**, focus on range from 0-2000, but sometime also have payment upto over 5000\n* **cluster3** number focus on range from 400-3000, payment from 5000-6000 occur more frequently than **cluster2**\n* Average price of room in 3 cluster distribute similarly with each other.","cde45037":"## Which quarter users often arrive hotel, and how it distribute to LTV_cluster","b9849b77":"## Top country user booking from","e709af63":"## Visualize total payment, average payment and average room price per booking of each customers","0257b74e":"# Load Data","a0a43248":"* Count bookings in each life-time value type","f89a21bc":"# First insights","2376e56b":"Check unique of `RoomGroupID` on each customers","932dbf1a":"Thank you for reading!\n","bb78eb0f":"# Modeling","ceefe7d9":"* Count customers in each life-time value","9da05630":"* Check correlation after cleansing","52fb0a3e":"China is the place where the most user book hotel from. \n\nLT (not sure which nation is LT, it can be Lithunia) is the place where the least user book hotel from.","924ca89f":"## Check the quantity of labels","b4d2423f":"\ud83e\udc32 Not comprehense what is `other` because of missing information in data description. But the chart indicate that users often use `online` booking rather than `offline` in all 3 types of customers. Also, there're a lot of missing value in this feature.","81639129":"Now let see all returning customers have labels or just a subset.","f99f1f23":"\ud83e\udc32 Not all the returning customers have labels","e86d0a8f":"Conclude:\n* The planning time of **LTV-cluster-1 guests** and **LTV-cluster-2 guests** distribute averagely in range from 1-100 days while **LTV-cluster-3 guests** stay below 70 days. In particular, **cluster1** and **cluster2** also have very high numbers like 250-300 days.\n* On the other hand, The staying time of **cluster1** is much lower than **cluster2** and **cluster3** where guest can stay upto over 25 days.\n* The distribution of **cluster3** guests's planning time is much more balance from 1-25 days.\n* Nevertheless, the distribution of **cluster1** and **cluster2** guests's planning time is focus on range from 1-10 days.\n* I guess using these features can help model more easily distinguish guests from different LTV values","c9933628":"Statistics of subset that have labels","0c1175ef":"* Result quite good with 0.95% accuracy on train set and 93% acc on test set, not too much overfiting. \n\nI think it because I didn't explore sufficient features of RFM score to produce effective clusters, next time will be better","1a062197":"* Bottom 20 country ","fb5dc0c3":"## In each booking, does RoomPrice and TotalPayment correlate to each other, also check against amount of adults and children","976522da":"# Create dataset, Cleansing, Feature Engineering","e55cd937":"\ud83e\udc32 Again, we dont have information about what are these group numbers meaning, but from the chart, the distribution of 3 Groups of room is quite similar on 3 LTV cluster, so can not conclude anything in this chart and `RoomGroupID`, maybe this ID just is a identification number to ease manage by hotel owner. And I will use one-hot encoding for this column."}}