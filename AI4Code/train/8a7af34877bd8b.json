{"cell_type":{"7b4d737e":"code","b84e1d4f":"code","b80bb9ff":"code","888140f0":"code","9f14ec19":"code","b26a96b3":"code","35e933aa":"code","48e30b67":"code","27e2e098":"code","e5db7b7c":"code","69b199ed":"code","35f2f995":"code","5f17617e":"code","b6d5af93":"code","21f20250":"code","e8e8cbad":"code","e1d091b9":"code","3c37311c":"code","33fef2a7":"code","a908ec3e":"code","aedbb5f5":"code","c3ba7433":"code","deda3859":"code","e6e4fa39":"code","881974aa":"code","f8e76412":"code","9cb1b529":"code","335b5ce4":"code","901277fd":"code","ff0cf3a3":"code","4295fdcd":"code","bded2f42":"code","b067420a":"code","39235b32":"code","73ffbe0c":"code","78e0bcf5":"code","31c92e04":"code","92dda2fe":"code","67a08b2a":"code","f16a4b0c":"code","aa8f61a6":"code","f39f0932":"code","504f0de4":"code","52e7e3f1":"code","e5e4be7b":"code","b3ebd8e7":"code","ef4d6572":"code","ef3d18ab":"markdown","cab02125":"markdown","a8a008d9":"markdown","45c56635":"markdown","7a5411b5":"markdown","5a7adab1":"markdown","b6e63445":"markdown","61ce985d":"markdown","60aa3a58":"markdown","78f712a6":"markdown","32266e7d":"markdown","fd982c98":"markdown","fbda55f8":"markdown","2952d445":"markdown","12ff763b":"markdown","bee78eed":"markdown","d2d35ca8":"markdown","0bcf19a6":"markdown","0a5038cb":"markdown","9cbdc0ec":"markdown","2bc2b6bf":"markdown","5b98015f":"markdown","16add1a5":"markdown"},"source":{"7b4d737e":"#!pip install spacy","b84e1d4f":"#!python -m spacy download pt_core_news_sm","b80bb9ff":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, ImageColorGenerator\nimport seaborn as sns\nimport spacy\nfrom spacy.lang.pt import Portuguese\nimport nltk\nfrom nltk import tokenize\nimport re\nfrom string import punctuation\nfrom PIL import Image\n%matplotlib inline\n\nComentarios = pd.read_csv('..\/input\/BurguesaComments.csv')\n\nstop_words = pd.read_csv('..\/input\/Stop_Words_Personalizadas.csv')\nstop_words = list(stop_words.Stops)","888140f0":"Comentarios.head()","9f14ec19":"Comentarios.rename(columns={'Post comment text': 'comentarios', 'Post comment author': 'Nome'}, inplace=True)\nComentarios.head()","b26a96b3":"Comentarios.info()","35e933aa":"Comentarios.dropna(inplace=True)\nComentarios.isna().sum()","48e30b67":"nlp = Portuguese()","27e2e098":"cerveja_mask = np.array(Image.open(\"..\/input\/latinha_cerveja.png\")) # Mask para formato da nuvem de palavras\ncerveja_color = np.array(Image.open(\"..\/input\/cerveja_burguesa.png\"))# Imagem para gerar as cores das palavras\nimage_colors = ImageColorGenerator(cerveja_color) # Fun\u00e7\u00e3o da biblioteca WordCloud para gerar as cores","e5db7b7c":"def nuvem_de_palavras(texto, coluna_texto): # Fun\u00e7\u00e3o para gerar a nuvem de palavras e salvar a imagem gerada\n    todas_palvaras = ' '.join([texto for texto in texto[coluna_texto]])\n\n    nuvem_palavras = WordCloud(font_path='..\/input\/Montserrat-ExtraBold.ttf', width=1280, height=720, color_func=image_colors, mask=cerveja_mask, background_color='white', max_font_size = 250, max_words=200, collocations = True, contour_width=10, contour_color='black',random_state=4).generate(todas_palvaras)\n    nuvem_palavras.to_file(\"Nuvem_de_Palavras.png\")\n    plt.figure(figsize = (10, 7))\n    plt.imshow(nuvem_palavras, interpolation ='bilinear')\n    plt.axis('off')\n    plt.show()","69b199ed":"nuvem_de_palavras(Comentarios, 'comentarios')","35f2f995":"Comentarios.comentarios.count()","5f17617e":"Comentarios.drop_duplicates(['comentarios'], inplace=True)","b6d5af93":"Comentarios.comentarios.count()","21f20250":"def Limpeza_dados(comentarios):\n    comentarios = re.sub(r\"http\\S+\", \"\", comentarios).lower()\n    comentarios = re.sub(r\"[-|0-9]\", \"\", comentarios).lower()\n    comentarios = re.sub(r'[-.\/?!,\":;()\\']', ' ', comentarios).lower()\n    return (comentarios)\n\nComentarios['comentarios_1'] = [Limpeza_dados(i) for i in Comentarios.comentarios]","e8e8cbad":"Comentarios.head()","e1d091b9":"# Importando l\u00e9xico de palavras\nop_lexico =  pd.read_csv('..\/input\/opLexico_Facebook_Burguesa.txt', header=None,\n                         names=('Lexico', 'Emoji', 'Polaridade', 'Metodo'), index_col=False)\nop_lexico.head()","3c37311c":"def RemoveLetrasRepetidas(comentario): # Fun\u00e7\u00e3o para remover letras repetidas\n    comentario = nlp(comentario)\n    palavras = list()\n    for palavra in comentario:\n        if palavra.text not in list(op_lexico.Lexico):\n            palavras.append(re.compile(r'(.)\\1{1,}', re.IGNORECASE).sub(r'\\1', palavra.text))\n        else:\n            palavras.append(palavra.text)\n    return (\" \".join(palavras))\n\nComentarios['comentarios_2'] = [RemoveLetrasRepetidas(i) for i in Comentarios.comentarios_1]","33fef2a7":"Comentarios[10:15]","a908ec3e":"# Importando pontua\u00e7\u00f5es da biblioteca NLTK\npontuacao = list()\nfor ponto in punctuation:\n    pontuacao.append(ponto)","aedbb5f5":"def RemoveStopWords(comentario): # Fun\u00e7\u00e3o para remover stopwords e pontua\u00e7\u00f5es\n    comentario = nlp(comentario)\n    palavras = [palavra.text for palavra in comentario if palavra.text not in stop_words and palavra.text\n                not in pontuacao]\n    return (\" \".join(palavras))\n\nComentarios['comentarios_3'] = [RemoveStopWords(i) for i in Comentarios.comentarios_2]","c3ba7433":"Comentarios.head()","deda3859":"nuvem_de_palavras(Comentarios, 'comentarios_3')","e6e4fa39":"op_lexico.head()","881974aa":"pontos = []\ndef Score_sentimento(comentario):\n    comentario = nlp(comentario)\n    sentimento = []\n    for palavra in comentario:\n        if palavra.text not in list(op_lexico.Lexico):\n            sentimento.append(0)\n        else:\n            polaridade = op_lexico.loc[op_lexico['Lexico'] == palavra.text, ['Polaridade']]\n            polaridade = list(polaridade['Polaridade'])\n            polaridade = polaridade[0]\n            sentimento.append(polaridade)\n    score = sum(sentimento)\n    pontos.append(score)\n    if score > 0:\n        return 'Positivo'\n    elif score == 0:\n        return 'Neutro'\n    else:\n        return 'Negativo'\n    \nComentarios['classificacao'] = [Score_sentimento(i) for i in Comentarios.comentarios_3]","f8e76412":"Comentarios['pontuacao'] = pontos","9cb1b529":"Comentarios.comentarios_3.count()","335b5ce4":"Comentarios.drop_duplicates(['comentarios_3'], inplace=True)\nComentarios.comentarios_3.dropna(inplace=True)","901277fd":"Comentarios.comentarios_3.count()","ff0cf3a3":"Comentarios[Comentarios['classificacao']=='Positivo']","4295fdcd":"Comentarios[Comentarios['classificacao']=='Neutro']","bded2f42":"Comentarios[Comentarios['classificacao']=='Negativo']","b067420a":"token_nltk = tokenize.WhitespaceTokenizer()\npalavras = ' '.join([texto for texto in Comentarios['comentarios_3']])\npalavras = token_nltk.tokenize(palavras)\npalavras_freq = nltk.FreqDist(palavras)\nComentarios_frequencia = pd.DataFrame({\"Palavras\": list(palavras_freq.keys()), \"Frequencia\": list(palavras_freq.values())})\nComentarios_frequencia.sort_values(by='Frequencia', ascending=False).head(20)","39235b32":"def pareto(coluna_texto, quantidade):\n    palavras = ' '.join([texto for texto in coluna_texto])\n    palavras = token_nltk.tokenize(palavras)\n    frequencia = nltk.FreqDist(palavras)\n    Comentarios_frequencia = pd.DataFrame({\"Palavras\": list(frequencia.keys()), \"Frequencia\": list(frequencia.values())})\n    Comentarios_frequencia = Comentarios_frequencia.nlargest(columns=\"Frequencia\", n=quantidade)\n    plt.figure(figsize=(20, 10))\n    ax = sns.barplot(data=Comentarios_frequencia, x=\"Palavras\", y=\"Frequencia\", color='red')\n    ax.set(ylabel=\"Contagem\")\n    ax\n    \npareto(Comentarios.comentarios_3, 10)","73ffbe0c":"Comentarios.drop('comentarios_1', axis=1, inplace=True)\nComentarios.drop('comentarios_2', axis=1, inplace=True)\nComentarios.drop('comentarios_3', axis=1, inplace=True)","78e0bcf5":"Comentarios.sort_values(by='pontuacao', ascending=False).head()","31c92e04":"Comentarios.sort_values(by='pontuacao', ascending=True).head(15)","92dda2fe":"positivos = Comentarios[Comentarios['classificacao']=='Positivo'].shape\nneutros = Comentarios[Comentarios['classificacao']=='Neutro'].shape\nnegativos = Comentarios[Comentarios['classificacao']=='Negativo'].shape\nprint('Total de coment\u00e1rios Positivos: {}, Neutros: {}, Negativos: {}'.format(positivos[0], neutros[0], negativos[0]))","67a08b2a":"Comentarios.Nome.value_counts().head(10)","f16a4b0c":"#Coment\u00e1rios sobre vers\u00e3o puro malte\npuromalte = list()\nfor comentario in Comentarios.comentarios:\n    comentario = comentario.lower()\n    i = nlp(comentario)\n    for palavra in i:\n        if palavra.text == \"malte\" or palavra.text == \"puro\":\n            puromalte.append(comentario)","aa8f61a6":"#Coment\u00e1rios sobre a ta\u00e7a burguesa\ntaca = list()\nfor comentario in Comentarios.comentarios:\n    comentario = comentario.lower()\n    i = nlp(comentario)\n    for palavra in i:\n        if palavra.text == \"ta\u00e7a\":\n            taca.append(comentario)","f39f0932":"#Coment\u00e1rios sobre o atendimento\natendimento = list()\nfor comentario in Comentarios.comentarios:\n    comentario = comentario.lower()\n    i = nlp(comentario)\n    for palavra in i:\n        if palavra.text == \"atendimento\" or palavra.text == \"contato\" or palavra.text == \"atende\" or palavra.text == \"atender\" or palavra.text == \"responder\" or palavra.text == \"responde\" or palavra.text == \"vendedores\" or palavra.text == \"vender\":\n            atendimento.append(comentario)","504f0de4":"#Coment\u00e1rios sobre onde comprar\ncomprar = list()\nfor comentario in Comentarios.comentarios:\n    comentario = comentario.lower()\n    i = nlp(comentario)\n    for palavra in i:\n        if palavra.text == \"encontro\" or palavra.text == \"encontrar\" or palavra.text == \"achar\" or palavra.text == \"cidade\" or palavra.text == \"comprar\" or palavra.text == \"compra\":\n            comprar.append(comentario)","52e7e3f1":"len(taca)","e5e4be7b":"len(puromalte)","b3ebd8e7":"len(atendimento)","ef4d6572":"len(comprar)","ef3d18ab":"**Coment\u00e1rios com mais elementos negativos**","cab02125":"**Alguns tipos de coment\u00e1rios frequentes e interessantes**","a8a008d9":"**Removendo letras repetidas**","45c56635":"**Palavras\/Emojis com maior frequ\u00eancia**","7a5411b5":"**Removendo Stop Words e Pontua\u00e7\u00f5es**","5a7adab1":"**Fun\u00e7\u00e3o para criar gr\u00e1fico de palavras\/emojis com maior frequ\u00eancia**","b6e63445":"**Fun\u00e7\u00e3o para classificar os coment\u00e1rios como Positivo, Neutro ou Negativo e atribuir pontua\u00e7\u00e3o**","61ce985d":"**Atribuindo classifica\u00e7\u00f5es para os coment\u00e1rios**","60aa3a58":"**Algumas observa\u00e7\u00f5es**\n\n1. Esses coment\u00e1rios foram extra\u00eddos de uma p\u00e1gina de cerveja (Cerveja Burguesa);\n2. O m\u00e9todo escolhido foi o de L\u00e9xicos de palavras com sentimentos por falta de dados rotulados;\n3. Foram utilizados outras t\u00e9cnicas para tentar melhorar o modelo, como stemming, lemmatization e retirar acentos,\nmas como foi utilizado um l\u00e9xico o resultado ficou melhor apenas com as limpezas presentes no modelo;\n4. O l\u00e9xico que foi utilizado como base foi o opLexicon, mas modifiquei o arquivo com base nos coment\u00e1rios dessa\np\u00e1gina, o processamento de linguagem natural \u00e9 uma tarefa dif\u00edcil e exige adapta\u00e7\u00e3o para cada situa\u00e7\u00e3o espec\u00edfica;\n5. A forma de avalia\u00e7\u00e3o foi an\u00e1lise emp\u00edrica baseado na leitura dos comet\u00e1rios Head(60) e Tail(60) de cada\nclassifica\u00e7\u00e3o (Positivo, Neutro, Negativo) e corringindo onde o modelo estava errando;\n6. As stopwords utlizadas foram totalmente personalizadas, peguei como base algumas stopwords na internet, mas\nadicionei muitas conforme fui melhorando o modelo;\n7. Coment\u00e1rios negativos n\u00e3o significam que s\u00e3o cr\u00edticas ou algo falando mal, significa que tem v\u00e1rios elementos\nconsiderados negativos no coment\u00e1rio;\n8. Os dados foram extra\u00eddos com a ferramente Google Data Studio vinculada com o Supermetrics;\n9. N\u00e3o \u00e9 um modelo perfeito, mas com base nos coment\u00e1rios lidos e apenas na minha vis\u00e3o subjetiva, posso dizer\nque tem uma acur\u00e1cia de 75%, como sou novato n\u00e3o consegui uma forma melhor de avalia\u00e7\u00e3o at\u00e9 o momento.\n\n**Sinta-se a vontade para dar sugest\u00f5es ou cr\u00edticas**","78f712a6":"**Criando vari\u00e1vel de tokeniza\u00e7\u00e3o da biblioteca Spacy**","32266e7d":"### **An\u00e1lise dos Dados e Resultados**","fd982c98":"**Total de coment\u00e1rios Positivos, Neutros e Negativos**","fbda55f8":"# **Importando bibliotecas e base de dados**","2952d445":"# **Modelo para classifica\u00e7\u00e3o de coment\u00e1rios dos Facebook**","12ff763b":"**Criando fun\u00e7\u00e3o para Nuvem de Palavras**","bee78eed":"**Coment\u00e1rios com mais elementos positivos**","d2d35ca8":"**Renomeando colunas coment\u00e1rios e nomes**","0bcf19a6":"# **Criando modelo de classifica\u00e7\u00e3o de coment\u00e1rios**","0a5038cb":"**Pessoas que mais comentaram**","9cbdc0ec":"**Retirando linhas sem coment\u00e1rios do DataFrame**","2bc2b6bf":"# **Pre-Processamento dos Dados e Criando WordCloud**","5b98015f":"**Removendo links, virgulas, ponto e virgulas, n\u00fameros e deixando em caixa baixa.**","16add1a5":"**Removendo coment\u00e1rios duplicados**"}}