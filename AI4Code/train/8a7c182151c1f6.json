{"cell_type":{"bd319946":"code","c35f52a6":"code","8bf6b2f2":"code","131e655e":"code","ec67a815":"code","7d5b30d6":"code","2edd5a21":"code","fbe4a5f5":"code","1665ab60":"code","c782a8cc":"code","69dcd555":"code","b699f901":"code","0721fd1c":"code","d43e51d6":"code","db70440c":"code","0095d015":"code","303b3ba6":"code","49082f18":"code","dfb83cf5":"code","f10341e4":"code","7d176c15":"code","7c6f48b8":"code","08a7e917":"code","0dca7ea1":"code","de33b2ac":"code","8c6d3233":"code","12d3d3dd":"code","83141918":"code","c5dd7be2":"code","c5ced9d5":"code","4bb57c50":"code","cb65d924":"code","b646011e":"code","6944c5f5":"code","f2aba2a2":"code","f51bc060":"code","7e869ac7":"code","ea028488":"code","8fb53c41":"code","baf3f688":"markdown","dde34220":"markdown","f1f1fc0c":"markdown"},"source":{"bd319946":"# IMPORT MODULES\n# TURN ON the GPU !\n\nimport os\nfrom operator import itemgetter    \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nget_ipython().magic(u'matplotlib inline')\nplt.style.use('ggplot')\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Imputer\nfrom pandas.tools.plotting import scatter_matrix\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\nfrom sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n#from sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, ShuffleSplit\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc\nfrom sklearn.utils.fixes import signature\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nfrom mlxtend.plotting import plot_learning_curves\nfrom mlxtend.preprocessing import shuffle_arrays_unison\n\nimport tensorflow as tf\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\nfrom keras.utils import to_categorical\n\nprint(os.getcwd())\nprint(\"Modules imported \\n\")\nimport os\nprint(os.listdir(\"..\/input\/\"))","c35f52a6":"print(os.listdir(\"..\/input\/\"))","8bf6b2f2":"# Load MIMIC2 data \n\ndata = pd.read_csv('..\/input\/mimic3d\/mimic3d.csv')\nprint(\"With id\", data.shape)\ndata_full = data.drop('hadm_id', 1)\nprint(\"No id\",data_full.shape)","131e655e":"print(data_full.shape)\ndata_full.info()\ndata_full.describe()","ec67a815":"data_full.head(10)","7d5b30d6":"# Label = LOS\n\ny = data_full['LOSgroupNum']\nX = data_full.drop('LOSgroupNum', 1)\nX = X.drop('LOSdays', 1)\nX = X.drop('ExpiredHospital', 1)\nX = X.drop('AdmitDiagnosis', 1)\nX = X.drop('AdmitProcedure', 1)\nX = X.drop('marital_status', 1)\nX = X.drop('ethnicity', 1)\nX = X.drop('religion', 1)\nX = X.drop('insurance', 1)\n\nprint(\"y - Labels\", y.shape)\nprint(\"X - No Label No id \", X.shape)\nprint(X.columns)","2edd5a21":"data_full.groupby('LOSgroupNum').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_type').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_location').size().plot.bar()\nplt.show()","fbe4a5f5":"# Check that all X columns have no missing values\nX.info()\nX.describe()","1665ab60":"# MAP Text to Numerical Data\n# Use one-hot-encoding to convert categorical features to numerical\n\nprint(X.shape)\ncategorical_columns = [\n                    'gender',                     \n                    'admit_type',\n                    'admit_location'\n                      ]\n\nfor col in categorical_columns:\n    #if the original column is present replace it with a one-hot\n    if col in X.columns:\n        one_hot_encoded = pd.get_dummies(X[col])\n        X = X.drop(col, axis=1)\n        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n        \nprint(X.shape)","c782a8cc":"\nprint(data_full.shape)\nprint(X.shape)\n#XnotNorm = np.array(X.copy())\nXnotNorm = X.copy()\nprint('XnotNorm ', XnotNorm.shape)\n\nynotNorm = y.copy()\nprint('ynotNorm ', ynotNorm.shape)","69dcd555":"# Normalize X\n\nx = XnotNorm.values #returns a numpy array\nscaler = preprocessing.StandardScaler()\nx_scaled = scaler.fit_transform(x)\nXNorm = pd.DataFrame(x_scaled, columns=XnotNorm.columns)\n#print(XNorm)\n#print(y)\nprint('X normalized')","b699f901":"# SPLIT into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=7)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","0721fd1c":"# Test Models and evaluation metric\nseed = 42\nscoring = 'accuracy' \n\n# Spot Check Algorithms\nMymodels = []\n#Mymodels.append(('LogReg', LogisticRegression()))\nMymodels.append(('RandomForestClassifier', RandomForestClassifier()))\nMymodels.append(('SGDclassifier', SGDClassifier()))\n#Mymodels.append(('KNearestNeighbors', KNeighborsClassifier()))\nMymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n#Mymodels.append(('GaussianNB', GaussianNB()))\n#Mymodels.append(('SVM', SVC()))\n\n# Evaluate each model in turn\nresults = []\nnames = []\nfor name, model in Mymodels:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg) ","d43e51d6":"# Optimize hyper params for one model\n\nmodel = RandomForestClassifier()\n\nparam_grid = [{},]\n\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring=scoring)\ngrid_search.fit(XNorm, y)\n\nprint(grid_search.best_estimator_)","db70440c":"model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","0095d015":"# FEATURE IMPORTANCE - NORMALIZED - last model\n\ntrainFinalFI = XNorm\nyFinalFI = y\n\nmodel.fit(trainFinalFI,yFinalFI)\n\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model[FI_model[\"Feature Importance\"] > 0.005].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\nplt.xticks(rotation=90)\nplt.xticks(rotation=90)\nplt.show()","303b3ba6":"# List of important features for model\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model=FI_model.sort_values('Feature Importance', ascending = False)\nprint(FI_model[FI_model[\"Feature Importance\"] > 0.001])","49082f18":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Error\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = 1-np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = 1-np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","dfb83cf5":"# LEARNING CURVES Train \/ Validation\n\ntitle = \"Learning Curves \"\ncv = ShuffleSplit(n_splits=7, test_size=0.2)\nplot_learning_curve(model, title, X_train, y_train, cv=cv, n_jobs=4)\n#plot_learning_curve(model, title, XNorm, y, ylim=(0.01, 0.99), cv=cv, n_jobs=4)","f10341e4":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","7d176c15":"# Model FINAL fit and evaluation on test\n\nmodel.fit(X_train, y_train)\nfinal_predictions = model.predict(X_test)\n\n#final_acc = accuracy(y_test, final_predictions)\n# Confusion matrix\n\nconf_mx = confusion_matrix(y_test, final_predictions)\nprint('conf_mx ready')","7c6f48b8":"def plot_confusion_matrix(cm,target_names,title='Confusion Matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n","08a7e917":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = [0,1,2,3],\n                      title        = \"Confusion Matrix\")","0dca7ea1":"# Confusion matrix and all metrics - for EACH class separately\n\nNumClasses = 4\n\nTP = 0\nTN = 0\nFP = 0\nFN = 0\n\nfor z in range(NumClasses):\n# One class at a time - calculate confusion matrix\n    SumCM = np.sum(conf_mx)\n    TPz = conf_mx[z,z]\n    FNz = np.sum(conf_mx[z,:], axis=0) -TPz\n    FPz = np.sum(conf_mx[:,z], axis=0) -TPz\n    TNz = SumCM - (TPz+FNz+FPz)\n    #FPz = np.sum(conf_mx[z], axis=-1) \n    #FPz = sum(conf_mx(:, z))-conf_mx(z, z)\n    #FNz = sum(conf_mx(x, :), 2)-conf_mx(x, x)\n    print('Class ',z)\n  \n\n    # Create conf matrix for class z\n    cmZ = np.zeros([2, 2], dtype=np.int32)\n    cmZ[0,0] = TNz\n    cmZ[0,1] = FPz\n    cmZ[1,0] = FNz\n    cmZ[1,1] = TPz\n\n    plot_confusion_matrix(cmZ, \n                          normalize    = False,\n                          target_names = [0,1],\n                          title        = \"Confusion matrix for one class \")\n\n    accuracy = (TPz+TNz)\/(TPz+TNz+FPz+FNz)\n    recall = TPz\/(TPz+FNz)\n    precision = TPz\/(TPz+FPz)\n    f1score = 2*recall*precision\/(recall+precision)\n    #roc_auc = auc(FPz, TPz)\n    \n    print('TPz ',TPz)\n    print('FNz ',FNz)\n    print('FPz ',FPz)\n    print('TNz ',TNz)\n    print('sum ', TPz+TNz+FPz+FNz)\n    print(cmZ)\n    print('Sum of CM ', np.sum(cmZ))\n    print ('accuracy ',round(accuracy,4))\n    print('recall ', round(recall,4))\n    print('precision ', round(precision,4))\n    print('F1Score ', round(f1score,4))\n    print('-'*40)\n    \n    TP = TP + TPz\n    TN = TN + TNz\n    FP = FP + FPz\n    FN = FN + FNz\nprint ('TN: ', TN)\nprint ('FP: ', FP)\nprint ('FN: ', FN)\nprint ('TP: ', TP)\nprint('_'*40)    ","de33b2ac":"# Confusion Matrix for the WHOLE MODEL - ALL Classes\n\nprint('Confusion Matix for ALL Classes')\n\nTP = TP \/ NumClasses\nTN = TN \/ NumClasses\nFP = FP \/ NumClasses\nFN = FN \/ NumClasses\n\n\ncm = np.zeros([2, 2], dtype=np.int32)\ncm[0,0] = TN\ncm[0,1] = FP\ncm[1,0] = FN\ncm[1,1] = TP\n\nplot_confusion_matrix(cm, \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Confusion Matrix\")\n","8c6d3233":"def multiclass_roc_auc_score(y_test, final_predictions, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(final_predictions)\n\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('AUC ROC ',multiclass_roc_auc_score(y_test, final_predictions))","12d3d3dd":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)\n\nprint(y_train)\nprint(y_test)\n","83141918":"# Transfer data to NN format\n\nx_val = X_test\npartial_x_train = X_train\ny_val = y_test\npartial_y_train = y_train\n\nprint(\"partial_x_train \", partial_x_train.shape)\nprint(\"partial_y_train \", partial_y_train.shape)\n\nprint(\"x_val \", x_val.shape)\nprint(\"y_val \", y_val.shape)","c5dd7be2":"yTrain = to_categorical(partial_y_train)\nyVal = to_categorical(y_val)\nprint(yTrain.shape)\nprint(yVal.shape)","c5ced9d5":"# NN MODEL\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(30,)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(4, activation='softmax'))\nprint(model.summary())\n\n# FIT \/ TRAIN model\n\nNumEpochs = 100\nBatchSize = 16\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\nhistory = model.fit(partial_x_train, yTrain, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, yVal))\n\nresults = model.evaluate(x_val, yVal)\nprint(\"_\"*100)\nprint(\"Test Loss and Accuracy\")\nprint(\"results \", results)\nhistory_dict = history.history\nhistory_dict.keys()","4bb57c50":"# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['categorical_accuracy']\nval_acc_values = history_dict['val_categorical_accuracy']\nepochs = range(1, (len(history_dict['categorical_accuracy']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n","cb65d924":"# Final Fit \/ Predict\n\nfinal_predictions = model.predict(x_val)\nprint(final_predictions)","b646011e":"# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n\nprint(final_predictions)\npred = []\nnumTest = final_predictions.shape[0]\nfor i in range(numTest):\n    pred.append(np.argmax(final_predictions[i])) \npredictions = np.array(pred)  \nprint(predictions)","6944c5f5":"# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n\nprint(yVal)\npred = []\nnumTest = yVal.shape[0]\nfor i in range(numTest):\n    pred.append(np.argmax(yVal[i])) \nyValNum = np.array(pred)  \nprint(yValNum)","f2aba2a2":"conf_mx = confusion_matrix(yValNum, predictions)\nprint('conf_mx ready')","f51bc060":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = [0,1,2,3],\n                      title        = \"Confusion Matrix\")","7e869ac7":"# Confusion matrix and all metrics - for EACH class separately\n\nNumClasses = 4\n\nTP = 0\nTN = 0\nFP = 0\nFN = 0\n\nfor z in range(NumClasses):\n# One class at a time - calculate confusion matrix\n    SumCM = np.sum(conf_mx)\n    TPz = conf_mx[z,z]\n    FNz = np.sum(conf_mx[z,:], axis=0) -TPz\n    FPz = np.sum(conf_mx[:,z], axis=0) -TPz\n    TNz = SumCM - (TPz+FNz+FPz)\n    #FPz = np.sum(conf_mx[z], axis=-1) \n    #FPz = sum(conf_mx(:, z))-conf_mx(z, z)\n    #FNz = sum(conf_mx(x, :), 2)-conf_mx(x, x)\n    print('Class ',z)\n  \n\n    # Create conf matrix for class z\n    cmZ = np.zeros([2, 2], dtype=np.int32)\n    cmZ[0,0] = TNz\n    cmZ[0,1] = FPz\n    cmZ[1,0] = FNz\n    cmZ[1,1] = TPz\n\n    plot_confusion_matrix(cmZ, \n                          normalize    = False,\n                          target_names = [0,1],\n                          title        = \"Confusion matrix for one class \")\n\n    accuracy = (TPz+TNz)\/(TPz+TNz+FPz+FNz)\n    recall = TPz\/(TPz+FNz)\n    precision = TPz\/(TPz+FPz)\n    f1score = 2*recall*precision\/(recall+precision)\n    #roc_auc = auc(FPz, TPz)\n    \n    print('TPz ',TPz)\n    print('FNz ',FNz)\n    print('FPz ',FPz)\n    print('TNz ',TNz)\n    print('sum ', TPz+TNz+FPz+FNz)\n    print(cmZ)\n    print('Sum of CM ', np.sum(cmZ))\n    print ('accuracy ',round(accuracy,4))\n    print('recall ', round(recall,4))\n    print('precision ', round(precision,4))\n    print('F1Score ', round(f1score,4))\n    print('-'*40)\n    \n    TP = TP + TPz\n    TN = TN + TNz\n    FP = FP + FPz\n    FN = FN + FNz\n    ","ea028488":"# Confusion Matrix for the WHOLE MODEL - ALL Classes\n\nprint('Confusion Matix for ALL Classes')\n\nTP = TP \/ NumClasses\nTN = TN \/ NumClasses\nFP = FP \/ NumClasses\nFN = FN \/ NumClasses\n\n\ncm = np.zeros([2, 2], dtype=np.int32)\ncm[0,0] = TN\ncm[0,1] = FP\ncm[1,0] = FN\ncm[1,1] = TP\n\nplot_confusion_matrix(cm, \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Confusion Matrix\")\n","8fb53c41":"print('AUC ROC ',multiclass_roc_auc_score(yValNum, predictions))","baf3f688":"**NN model**  ","dde34220":"# IMPUTE missing values\n\nX.fillna(value='unknown', axis=1, inplace=True)","f1f1fc0c":"* The original data is from MIMIC2 - Multiparameter Intelligent Monitoring in Intensive Care (deidentified DB) available freely from \nhttps:\/\/mimic.physionet.org\/\n* Each instance in the mldata.csv attached is one admission\n* Testing a theory I have, that one can predict LOS just by the number of interactions betweeen patient and hospital per day, \nLOS days was grouped 0-4, 4-8, etc.\n\nLet me know *your* results on this  dataset"}}