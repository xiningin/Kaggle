{"cell_type":{"ced5dd6e":"code","725cc94c":"code","4f3ae0ec":"code","ddbce7e2":"code","daebf9e0":"code","3eba7104":"code","71bd4ea5":"code","d91c5435":"code","8b793e07":"code","7c3d27a9":"code","53730f5d":"code","c48baae6":"code","c58b36e7":"code","860f2483":"code","234f7f71":"code","8c2ecc61":"code","0792c6a5":"code","545a8319":"code","61470639":"code","d6f5c4ab":"code","8ae771a7":"code","45d80575":"code","8bdb35f1":"code","52ffabcf":"code","7175ad0e":"code","d8fe5b26":"code","a3abd9c8":"code","cc28a243":"code","62327c2e":"code","cdb32732":"code","1640f522":"code","7e8ac91f":"code","930b181d":"code","f4f96c1d":"code","044da11a":"code","54e790da":"code","8318eddd":"code","42ef27c3":"code","3b98bfac":"code","8d630171":"code","3f0c5d7a":"code","ddad585d":"markdown","e2b54181":"markdown","377a5e88":"markdown","b8cc6ea5":"markdown","3f0dcd8d":"markdown","ae019641":"markdown","90f367cc":"markdown","daadd1fb":"markdown","4839a384":"markdown","dd2120c9":"markdown","d7e1eb60":"markdown","f5eaeba8":"markdown","87ec6e71":"markdown","e7f73265":"markdown","6d1a5e70":"markdown","8dafc271":"markdown","cc525115":"markdown","208c876a":"markdown","2d063cae":"markdown","1db653d0":"markdown","22d21008":"markdown","9b77eabb":"markdown","b659bc60":"markdown","bffa812a":"markdown","793b60ae":"markdown","4b68b6fc":"markdown","f539e407":"markdown","02913884":"markdown"},"source":{"ced5dd6e":"!pip install fastai2 --quiet","725cc94c":"from fastai2.text.all import *","4f3ae0ec":"path = Path('..\/input\/jigsaw-toxic-comment-classification-challenge')","ddbce7e2":"from zipfile import ZipFile\n\nwith ZipFile(path\/'train.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall('..\/output\/kaggle\/working')\n    \nwith ZipFile(path\/'test.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall('..\/output\/kaggle\/working')\n    \nwith ZipFile(path\/'test_labels.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall('..\/output\/kaggle\/working')\n    \nwith ZipFile(path\/'sample_submission.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall('..\/output\/kaggle\/working')","daebf9e0":"path_w = Path('..\/output\/kaggle\/working')","3eba7104":"path_w.ls()","71bd4ea5":"df = pd.read_csv(path_w\/'train.csv')","d91c5435":"df.head()","8b793e07":"blocks = (TextBlock.from_df(text_cols='comment_text', is_lm=True, res_col_name='text'))","7c3d27a9":"test_df = pd.read_csv(path_w\/'test.csv')","53730f5d":"test_df.head()","c48baae6":"text_df = pd.Series.append(df['comment_text'], test_df['comment_text'])","c58b36e7":"text_df = pd.DataFrame(text_df)","860f2483":"text_df.head()","234f7f71":"get_x = ColReader('text')\nsplitter = RandomSplitter(0.1, seed=42)","8c2ecc61":"lm_dblock = DataBlock(blocks=blocks,\n                     get_x=get_x,\n                     splitter=splitter)","0792c6a5":"lm_dls = lm_dblock.dataloaders(text_df, bs=64)","545a8319":"lm_learn = language_model_learner(lm_dls, AWD_LSTM, pretrained=True, metrics=[accuracy, Perplexity()])","61470639":"lm_learn.to_fp16()\nlm_learn.fine_tune(10, 4e-3)","d6f5c4ab":"lm_learn.save_encoder('fine_tuned')","8ae771a7":"ys = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n       'identity_hate']","45d80575":"blocks = (TextBlock.from_df('comment_text', seq_len=lm_dls.seq_len, vocab=lm_dls.vocab), \n          MultiCategoryBlock(encoded=True, vocab=ys))","8bdb35f1":"toxic_clas = DataBlock(blocks=blocks,\n                      get_x=ColReader('text'),\n                      get_y=ColReader(ys),\n                      splitter=RandomSplitter())","52ffabcf":"toxic_clas.summary(df.iloc[:100])","7175ad0e":"dls = toxic_clas.dataloaders(df)","d8fe5b26":"loss_func = BCEWithLogitsLossFlat(thresh=0.8)\nmetrics = [partial(accuracy_multi, thresh=0.8)]","a3abd9c8":"learn = text_classifier_learner(dls, AWD_LSTM, metrics=metrics, loss_func=loss_func)","cc28a243":"learn.lr_find()","62327c2e":"learn.load_encoder('fine_tuned');","cdb32732":"learn.to_fp16()\n\nlr = 1e-2\nmoms = (0.8,0.7, 0.8)\nlr *= learn.dls.bs\/128\nlearn.fit_one_cycle(1, lr, moms=moms, wd=0.1)","1640f522":"learn.freeze_to(-2)\nlr\/=2\nlearn.fit_one_cycle(1, slice(lr\/(2.6**4), lr), moms=moms, wd=0.1)","7e8ac91f":"learn.freeze_to(-3)\nlr \/=2\nlearn.fit_one_cycle(1, slice(lr\/(2.6**4), lr), moms=moms, wd=0.1)","930b181d":"learn.unfreeze()\nlr \/= 5\nlearn.fit_one_cycle(2, slice(lr\/(2.6**4),lr), moms=(0.8,0.7,0.8), wd=0.1)","f4f96c1d":"dl = learn.dls.test_dl(test_df['comment_text'])","044da11a":"preds = learn.get_preds(dl=dl)","54e790da":"sub = pd.read_csv(path_w\/'sample_submission.csv')","8318eddd":"sub.head()","42ef27c3":"preds[0][0].cpu().numpy()","3b98bfac":"sub[ys] = preds[0]","8d630171":"sub.head()","3f0c5d7a":"sub.to_csv('submission.csv', index=False)","ddad585d":"Note that this `get_x` should be the same as our output column","e2b54181":"## Toxic Comment Classification","377a5e88":"Now let's build the `DataBlock` Pipeline:","b8cc6ea5":"Which it works just fine! So let's build our `DataLoaders`:","3f0dcd8d":"Now this is where things get a bit tricky, as we want to know how to build our thresholds for `BCELossLogits` and `accuracy_multi` (as ideally we'd want them both to be the same). To make sure my model is very strong, I'll set their thresholds to activations > 0.8:","ae019641":"And now the `DataLoaders`:","90f367cc":"It will take abit to pre-process everything, `fastai` will tokenize for us beforehand (should take about 14 minutes). \n\nNext, as per the ULM-FiT technique, we'll want to train our langauge model. First let's build our `Learner`:","daadd1fb":"Now you may notice there was a `res_col_name` parameter. This is where our *tokenized* text will be output to. Next we need to tell how to grab our `x` and how we want to split our data. We'll split by 10% randomly:","4839a384":"In this notebook we're going to explore end-to-end training of the Toxic Comments multi-label dataset using fastai2 and the high-level DataBlock API. First let's install `fastai2`:","dd2120c9":"To work with the data we need to unzip everything:","d7e1eb60":"Next we'll make our `text_classification_learner`:","f5eaeba8":"# End to End Toxic Comments in fastai2","87ec6e71":"So we have our `comment_text` and a one-hot-encoded `y-label` for multi-class classification. Let's look at how to build a `DataBlock` for this to use in the `fastai2` framework. First let's look at the `TextBlock`. This will be where we dictate what kind of tokenizer we use, if it's a language model, and so forth:","e7f73265":"## Submitting the Predictions:","6d1a5e70":"Now before we actually do this, one trick is to train the langauge model on as much data as we possibly can, as it's unlabelled. We'll make another `DataFrame` for this specifically:","8dafc271":"For getting the predictions, we call `learn.get_preds` and pass in this `DataLoader`:","cc525115":"Now that we have our pre-trained model, let's build our down-stream multi-label classification task:","208c876a":"And then we just find the learning rate and fit!","2d063cae":"For our next part we'll want to make a `DataBlock` that uses the original vocab and sets us up for a multi-label classification problem:","1db653d0":"Since our task is a text problem, let's grab the `fastai2` text sub-library:","22d21008":"`fastai` has a nice in-house `fit` called `fine_tune`, which follows the freezing\/unfreezing transfer-learning protocol. We can pass in the number of frozen epochs and unfrozen, however Jeremy and Sylvain found that one was enough, so we'll pass in the number of *unfrozen* epochs as well as a learning rate:","9b77eabb":"Now let's see our training data:","b659bc60":"We'll use the unfreezing methodology for the ULM-FiT model to train and for its learning rate:","bffa812a":"And now we can submit it!","793b60ae":"We can test if it works by calling `toxic_clas.summary()`:","4b68b6fc":"Easy enough, let's push those predictions to it. They come in the same order we passed them in as:","f539e407":"Now let's try to submit some predictions. To make a test set we should call `learn.dls.test_dl` and pass in our `DataFrame` with the text to use:","02913884":"Now let's see how our sample submission wants it?"}}