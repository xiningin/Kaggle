{"cell_type":{"9d922535":"code","391bb88d":"code","c99d9e81":"code","02764a75":"code","158a75a4":"code","6d9d3bc6":"code","7c52984b":"code","4696e35b":"code","52668e03":"code","0b049a90":"code","07c6170f":"markdown","f2084587":"markdown","decffba0":"markdown","3135b14e":"markdown","a3c34c0e":"markdown","e5868dff":"markdown","636f0503":"markdown"},"source":{"9d922535":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","391bb88d":"training_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntesting_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntraining_data.describe()","c99d9e81":"training_data.head(25)","02764a75":"training_data.isna().any()","158a75a4":"passenger_id = testing_data[\"PassengerId\"]\n\ndef fix_csv(csv):\n    csv = csv.drop([\"PassengerId\", \"Cabin\", \"Ticket\", \"Name\"], axis=1)\n    \n    csv[\"Age\"].fillna(csv[\"Age\"].mean(), inplace=True)\n    csv[\"Embarked\"].fillna(\"N\", inplace=True)\n    csv[\"Fare\"].fillna(csv[\"Fare\"].mean(), inplace=True)\n    \n    return csv\n\ntraining_data = fix_csv(training_data)\ntesting_data = fix_csv(testing_data)\n\ntraining_data.head(25)","6d9d3bc6":"training_data.isna().any()","7c52984b":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\n\ntraining_data[\"Sex\"] = encoder.fit_transform(training_data[\"Sex\"])\ntesting_data[\"Sex\"] = encoder.transform(testing_data[\"Sex\"])\nprint(encoder.classes_)\n\ntraining_data[\"Embarked\"] = encoder.fit_transform(training_data[\"Embarked\"])\ntesting_data[\"Embarked\"] = encoder.transform(testing_data[\"Embarked\"])\nprint(encoder.classes_)\n\ntraining_data.head(25)","4696e35b":"from sklearn.model_selection import train_test_split\n\nX = training_data.drop(\"Survived\", axis=1)\ny = training_data[\"Survived\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)","52668e03":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import tree\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score\n\nknn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\nlin_reg = LinearRegression().fit(X_train, y_train)\ndec_tree = tree.DecisionTreeClassifier().fit(X_train, y_train)\nsgd = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3)).fit(X_train, y_train)\n\nknn_predictions = knn.predict(X_test)\nlin_reg_predictions = lin_reg.predict(X_test)\ndec_tree_predictions = dec_tree.predict(X_test)\nsgd_predictions = sgd.predict(X_test)\n \nprint(\"Nearest Neighbor: \" + str(accuracy_score(y_test, knn_predictions)))\nprint(\"Linear Regression: \" + str(r2_score(y_test, lin_reg_predictions)))\nprint(\"Decision Tree: \" + str(accuracy_score(y_test, dec_tree_predictions)))\nprint(\"SGD Classifier: \" + str(accuracy_score(y_test, sgd_predictions)))\n\nsubmission = knn.predict(testing_data)","0b049a90":"submission = pd.DataFrame({\"PassengerId\": passenger_id.values, \"Survived\": submission})\n\nsubmission.to_csv(\"submission.csv\", index=False)","07c6170f":"Finding that the decision tree returns the best score, we can begin to build the CSV we will be turning in. We need the passenger ID column from the test data and our predictions to build the CSV.","f2084587":"Female = 0, Male = 1. \n\nC = 0, N = 1, Q = 2, S = 3.\n\nNow that our data is transformed and ready, *hopefully*, we can start splitting our data and fitting it to our models. Let y be our target and X be our input.","decffba0":"We can see that our age column isn't the only column that has missing values, our emabarked column also contains missing categorical values. The cabin value won't matter since it will be dropped.","3135b14e":"Once our data is split into training and testing, we can begin to import our various models, fit them, and test them to see the accuracy. Based on our results, we will choose the most effective model.","a3c34c0e":"Lets also take a quick look at the data. Seems like the name, ticket, and POSSIBLY cabin could be dropped (Cabin could be impactful since the position of a cabin might be closer to a life-raft). We also know we have to turn the Sex and Embarked columns into numerical data since they cannot stay categorical. \n\nFor the missing age values, we can just get the mean or median of the entire age column and replace it. The results will not be 100% but it will be a lot closer than simply discarding them. With some more thorough data analysis, we can begin to predict the missing age values and then use that to build a even better model. \n\nAfter further review too, we can probably drop the PassengerID too.","e5868dff":"By doing \"training_data.isna().any()\", we can see that we do not have any more NaN values. We can start transforming our categorical data of 'Sex' and 'Embarked' into numerical data.","636f0503":"We can start by reading in our training and testing data with pandas and getting a general feel for the training data. We can see immediately that some passengers ages are missing from the data set. "}}