{"cell_type":{"d760c668":"code","9c32c2a8":"code","e7cdea7a":"code","c291bd53":"code","5b0e5ca0":"code","050ef2e1":"code","c4d540f9":"code","6fe92fa4":"code","31bcb295":"code","275504b2":"code","9db4c52d":"code","10f06fcf":"code","d5d0b3e8":"code","42e8d935":"code","9214c2c3":"code","54f53794":"code","51bdb67e":"code","26146c36":"code","dec9f9a9":"code","cd028409":"code","e14b8d75":"code","2efa5cd8":"code","93bf846a":"code","de244889":"code","28523185":"code","f721f2fb":"code","35c032e0":"code","ef99adc6":"code","5a289551":"code","d789ad5a":"code","3c70bb23":"code","8510b886":"code","1c52eef6":"code","29b9d50c":"code","c6d94424":"code","52357b57":"code","a0d680e6":"code","49d261c4":"code","7de4ba4e":"code","2a12f8bb":"code","3787b6a2":"code","8bb94e93":"markdown","41d3b059":"markdown","da3903fd":"markdown","ea1d49ee":"markdown","cf9f98f6":"markdown","b38e2bb4":"markdown","2e4eff8a":"markdown","3c84d403":"markdown","c381b817":"markdown","b0d08c9c":"markdown","5274ec67":"markdown","cef81011":"markdown","7ae59659":"markdown","93c10a19":"markdown","48299d2b":"markdown","980840c7":"markdown","1f5225f2":"markdown","f25a7542":"markdown","69548d0f":"markdown","db6d4c42":"markdown","510a2863":"markdown"},"source":{"d760c668":"!pip install -q mtcnn","9c32c2a8":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport os\n\nfrom tqdm import tqdm_notebook as tqdm\ntqdm().pandas()\n\nimport matplotlib.pyplot as plt\n\n\nfrom mtcnn.mtcnn import MTCNN\n\nfrom PIL import Image\n\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D, Conv2DTranspose\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Reshape\nfrom keras.utils.vis_utils import plot_model","e7cdea7a":"PATH = '..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/'\n\ndef load_image(filename):\n    image = Image.open(filename)\n    image = image.convert('RGB')\n    image = np.asarray(image)\n    \n    return image\n\ndef load_faces(path, n_faces):\n    faces = list()\n    for filename in tqdm(os.listdir(path)):\n        face = load_image(path+filename)\n        faces.append(face)\n        if len(faces) >= n_faces:\n            break\n    \n    return np.asarray(faces)\n\ndef plot_faces(faces, n):\n    plt.figure(figsize=(13,8))\n    for i in range(n * n):\n        plt.subplot(n, n, i+1)\n        plt.axis('off')\n        plt.imshow(faces[i])\n    plt.show()","c291bd53":"faces = load_faces(PATH, 25)\nplot_faces(faces, 5)","5b0e5ca0":"faces[0].shape","050ef2e1":"'''\nBelow functions take a lot of time to extract faces from 50k images, \nThey were ran once and the output of the function was store in file img_align_celeba.npz\nThe intention behind doing this is to save time running the below functions again in future\n\n\n\n\ndef extract_face(model, pixels, required_size=(80, 80)):\n    faces = model.detect_faces(pixels)\n    \n    # skip cases where we could not detect a face\n    if len(faces) == 0:\n        return None\n    x1, y1, width, height = faces[0]['box']\n    \n    # force detected pixel values to be positive (bug fix) \n    x1, y1 = abs(x1), abs(y1)    \n    \n    x2, y2 = x1 + width, y1 + height\n    \n    face_pixels = pixels[y1:y2, x1:x2]\n    \n    image = Image.fromarray(face_pixels)\n    image = image.resize(required_size)\n    \n    face_array = np.asarray(image)\n    \n    return face_array\n    \n    \ndef load_faces(path, n_faces):\n    model = MTCNN()\n    faces = list()\n    \n    for filename in tqdm(os.listdir(path)):\n        pixels = load_image(path+filename)\n        \n        face = extract_face(model, pixels)\n        \n        if face is None:\n            continue\n            \n        faces.append(face)\n        if len(faces) >= n_faces:\n            break\n    \n    return np.asarray(faces)\n\n\nall_faces = load_faces(PATH, 50000)\n\n'''","c4d540f9":"'''\nnp.savez_compressed('img_align_celeba.npz', all_faces)\n'''","6fe92fa4":"data = np.load('..\/input\/detected-faces-mtcnn\/img_align_celeba.npz')\n\nfaces = data['arr_0']\n\nprint('Loaded: ', faces.shape)","31bcb295":"plot_faces(faces, 5)","275504b2":"def define_discriminator(in_shape=(80,80,3)):\n    model = Sequential()\n    \n    #Normal\n    model.add(Conv2D(128, (5,5), padding='same', input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #Downsample to 40x40\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n\n    #Downsample to 20x20\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #Downsample to 10x10\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #Downsample to 5x5\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    \n    model.add(Dense(1, activation='sigmoid'))\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \n    return model\n\nmodel = define_discriminator()\n\nplot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)","9db4c52d":"def define_generator(latent_dim):\n    model = Sequential()\n    n_nodes = 128 * 5 * 5 \n    \n    model.add(Dense(n_nodes, input_dim=latent_dim))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((5, 5, 128)))\n    \n    #upsample to 10x10\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #upsample to 20x20\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))  \n    \n    #upsample to 40x40\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #upsample to 80x80\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Conv2D(3, (5,5), activation='tanh', padding='same'))\n    \n    return model\n\n\n\nlatent_dim = 100\n\nmodel = define_generator(latent_dim)\n\nplot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)","10f06fcf":"# define the combined generator and discriminator model, for updating the generator\n\ndef define_gan(generator, discriminator):\n    discriminator.trainable = False\n    model = Sequential()\n    \n    model.add(generator)\n    model.add(discriminator)\n    \n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    \n    return model","d5d0b3e8":"latent_dim = 100\n\ndiscriminator = define_discriminator()\n\ngenerator = define_generator(latent_dim)\n\ngan_model = define_gan(generator, discriminator)\n\n# plot gan model\nplot_model(gan_model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)","42e8d935":"def load_real_samples():\n    trainX = np.load('..\/input\/detected-faces-mtcnn\/img_align_celeba.npz')\n\n    X = trainX['arr_0']\n    \n    X = X.astype('float32')\n    \n    # scale from [0,255] to [-1,1]\n    X = (X - 127.5) \/ 127.5\n    \n    return X\n\n\ndef generate_real_samples(dataset, n_samples):\n    ix = np.random.randint(0, dataset.shape[0], n_samples)\n    X = dataset[ix]\n    y = np.ones((n_samples, 1))\n    \n    return X, y","9214c2c3":"def generate_latent_points(latent_dim, n_samples):\n    x_input = np.random.randn(latent_dim * n_samples)\n    # reshape into a batch of inputs for the network\n    x_input = x_input.reshape(n_samples, latent_dim)\n    \n    return x_input\n\n\ndef generate_fake_samples(generator, latent_dim, n_samples):\n    x_input = generate_latent_points(latent_dim, n_samples)\n    X = generator.predict(x_input)\n    \n    y = np.zeros((n_samples, 1))\n    \n    return X, y","54f53794":"n_samples = 25\nX, _ = generate_fake_samples(model, latent_dim, n_samples)\n\nX = (X + 1) \/ 2.0\nplt.figure(figsize=(10, 5))\nfor i in range(n_samples):\n    plt.subplot(5, 5, i+1)\n    plt.axis('off')\n    plt.imshow(X[i])\n\nplt.show()","51bdb67e":"def save_plot(examples, epoch, n=10):\n  # plot images\n    plt.figure(figsize=(10,5))\n    for i in range(n * n):\n        # define subplot\n        plt.subplot(n, n, 1 + i)\n        # turn off axis\n        plt.axis('off')\n        # plot raw pixel data\n        plt.imshow(examples[i])\n        # save plot to file\n    filename = 'generated_plot_e%03d.png' % (epoch+1) \n    plt.savefig(filename)\n    plt.close()\n\ndef summarize_performance(epoch, generator, discriminator, dataset, latent_dim, n_samples=100):\n    x_real, y_real = generate_real_samples(dataset, n_samples)\n    _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n    \n    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)\n    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n\n    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n    \n    save_plot(x_fake, epoch)\n    \n    # save model to file\n    filename = 'generator_model_%03d.h5' % (epoch + 1)\n    generator.save(filename)","26146c36":"def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n    bat_per_epo = int(dataset.shape[0] \/ n_batch)\n    half_batch = int(n_batch \/ 2)\n    \n    for i in range(n_epochs):\n        g_losses, d_losses = list(), list()\n        for j in range(bat_per_epo):\n            X_real, y_real = generate_real_samples(dataset, half_batch)\n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n\n            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n\n            #Train & Update Discriminator weights\n            d_loss, _ = d_model.train_on_batch(X, y)\n\n            # prepare points in latent space as input for the generator\n            X_gan = generate_latent_points(latent_dim, n_batch)\n\n            # create inverted labels for the fake samples\n            y_gan = np.ones((n_batch, 1))\n\n            # update the generator via the discriminator's error\n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            \n            g_losses.append(g_loss)\n            d_losses.append(d_loss)\n\n        print('>%d, d=%.3f, g=%.3f' % (i+1, np.mean(d_losses), np.mean(g_losses)))\n        \n        # evaluate the model every n_eval epochs\n        if (i+1) % 10 == 0:\n            summarize_performance(i, g_model, d_model, dataset, latent_dim)","dec9f9a9":"latent_dim = 100\n\ndiscriminator = define_discriminator()\n\ngenerator = define_generator(latent_dim)\n\ngan_model = define_gan(generator, discriminator)\n\ndataset = load_real_samples()\n\ntrain(generator, discriminator, gan_model, dataset, latent_dim)","cd028409":"OUTPUT_PATH = '\/kaggle\/input\/output-gan-model\/'\n\nplt.figure(figsize=(30,20))\nimg = plt.imread(OUTPUT_PATH+'generated_plot_e010.png')\n_ = plt.axis('off')\n_ = plt.imshow(img)","e14b8d75":"OUTPUT_PATH = '\/kaggle\/input\/output-gan-model\/'\n\nplt.figure(figsize=(30,20))\nimg = plt.imread(OUTPUT_PATH+'generated_plot_e050.png')\n_ = plt.axis('off')\n_ = plt.imshow(img)","2efa5cd8":"OUTPUT_PATH = '\/kaggle\/input\/output-gan-model\/'\n\nplt.figure(figsize=(30,20))\nimg = plt.imread(OUTPUT_PATH+'generated_plot_e100.png')\n_ = plt.axis('off')\n_ = plt.imshow(img)","93bf846a":"from keras.models import load_model\n\ndef generate_latent_points(latent_dim, n_samples):\n    \n    x_input = np.random.randn(latent_dim * n_samples)\n    \n    x_input = x_input.reshape(n_samples, latent_dim)\n    \n    return x_input\n                           \ndef show_plot(examples, n):\n  # plot images\n    plt.figure(figsize=(20,10))\n    for i in range(n * n):\n        # define subplot\n        plt.subplot(n, n, 1 + i)\n        # turn off axis\n        plt.axis('off')\n        # plot raw pixel data\n        plt.imshow(examples[i])\n    plt.show()","de244889":"model = load_model(OUTPUT_PATH+'generator_model_100.h5')\n\nlatent_points = generate_latent_points(100, 16) \n\nX = model.predict(latent_points)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nshow_plot(X, 4)","28523185":"np.linspace(0, 1, num=5)","f721f2fb":"def interpolate_points(p1, p2, n_steps=10):\n    ratios = np.linspace(0, 1, num=n_steps)\n    vectors = list()\n    for ratio in ratios:\n        v = (1.0 - ratio) * p1 + ratio * p2\n        vectors.append(v)\n    return np.asarray(vectors)\n\n\ndef plot_generated(examples, n):\n    plt.figure(figsize=(20,5))\n    for i in range(n):\n    \n        plt.subplot(1, n, 1 + i)\n    \n        plt.axis('off')\n\n        plt.imshow(examples[i])\n    plt.show()","35c032e0":"model = load_model(OUTPUT_PATH+'generator_model_100.h5')\n\nlatent_points = generate_latent_points(100, 2) \n\ninterpolated = interpolate_points(latent_points[0], latent_points[1])\nX = model.predict(interpolated)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nplot_generated(X, len(interpolated))","ef99adc6":"latent_points = generate_latent_points(100, 2) \n\ninterpolated = interpolate_points(latent_points[0], latent_points[1])\nX = model.predict(interpolated)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nplot_generated(X, len(interpolated))","5a289551":"latent_points = generate_latent_points(100, 2) \n\ninterpolated = interpolate_points(latent_points[0], latent_points[1])\nX = model.predict(interpolated)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nplot_generated(X, len(interpolated))","d789ad5a":"latent_points = generate_latent_points(100, 2) \n\ninterpolated = interpolate_points(latent_points[0], latent_points[1])\nX = model.predict(interpolated)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nplot_generated(X, len(interpolated))","3c70bb23":"from numpy import vstack\nfrom numpy.random import randn\nfrom numpy import arccos\nfrom numpy import clip\nfrom numpy import dot\nfrom numpy import sin\nfrom numpy import linspace\nfrom numpy.linalg import norm\n\n\n\n# spherical linear interpolation (slerp)\ndef slerp(val, low, high):\n    omega = arccos(clip(dot(low\/norm(low), high\/norm(high)), -1, 1))\n    so = sin(omega)\n    if so == 0:\n        # L'Hopital's rule\/LERP\n        return (1.0-val) * low + val * high\n    return sin((1.0-val)*omega) \/ so * low + sin(val*omega) \/ so * high\n\ndef interpolate_points(p1, p2, n_steps=10):\n    ratios = np.linspace(0, 1, num=n_steps)\n    vectors = list()\n    for ratio in ratios:\n        v = slerp(ratio, p1, p2)\n        vectors.append(v)\n    return np.asarray(vectors)","8510b886":"latent_points = generate_latent_points(100, 2) \n\ninterpolated = interpolate_points(latent_points[0], latent_points[1])\nX = model.predict(interpolated)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nplot_generated(X, len(interpolated))","1c52eef6":"latent_points = generate_latent_points(100, 2) \n\ninterpolated = interpolate_points(latent_points[0], latent_points[1])\nX = model.predict(interpolated)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nplot_generated(X, len(interpolated))","29b9d50c":"POINTS_PATH = '\/kaggle\/working\/'\nx = np.load(POINTS_PATH+'latent_points.npz')","c6d94424":"'''\n\n## Below points were generated once and saved, since the points generated are random.\n\nlatent_points = generate_latent_points(100, 36) \n\n\nX = model.predict(latent_points)\n\nnp.savez_compressed('latent_points.npz', latent_points)\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nshow_plot(X, 6)\n'''","52357b57":"type(data['arr_0'])","a0d680e6":"\ndata = np.load(POINTS_PATH+'latent_points.npz') \n\nlatent_points = np.asarray(data['arr_0'])\n\nX = model.predict(latent_points)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nshow_plot(X, 6)","49d261c4":"# retrieve specific points\nsmiling_woman_ix = [6, 9, 35] \nneutral_woman_ix = [10, 24, 27] \nneutral_man_ix = [4, 7, 8]","7de4ba4e":"def average_points(points, ix):\n    # convert to zero offset points\n    zero_ix = [i-1 for i in ix]\n    \n    vectors = points[zero_ix]\n    avg_vector = np.mean(vectors, axis=0)\n    all_vectors = np.vstack((vectors, avg_vector))\n    \n    return all_vectors\n\n# average vectors\nsmiling_woman = average_points(latent_points, smiling_woman_ix)\nneutral_woman = average_points(latent_points, neutral_woman_ix)\nneutral_man = average_points(latent_points, neutral_man_ix)\n\n\nall_vectors = np.vstack((smiling_woman, neutral_woman, neutral_man))\n\nimages = model.predict(all_vectors)\n\nimages = (images + 1) \/ 2.0\n","2a12f8bb":"plt.figure(figsize=(20,5))\nr=3\nc=4\n\nx=0\nfor i in range(r):\n    for j in range(c):\n        x += 1\n    \n        plt.subplot(r, c, x)\n    \n        plt.axis('off')\n\n        plt.imshow(images[x-1])\nplt.show()","3787b6a2":"result_vector = smiling_woman[-1] - neutral_woman[-1] + neutral_man[-1]\n\nresult_vector = np.expand_dims(result_vector, 0)\nresult_image = model.predict(result_vector)\n\n# scale pixel values\nresult_image = (result_image + 1) \/ 2.0\nplt.imshow(result_image[0])\nplt.show()","8bb94e93":"<h3><center>6. Define GAN (Generator + Discriminator)<\/center><\/h3>\n\n![image.png](attachment:image.png)","41d3b059":"<h3>3. After 100 EPOCHS<\/h3>","da3903fd":"<h3><center>1. Importing Libraries<\/center><\/h3>\n\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">","ea1d49ee":"<h2><center>Developing GAN for CelebA Data<\/center><\/h2>","cf9f98f6":"<h3><center>2. Exploring the dataset<\/center><\/h3>","b38e2bb4":"<h3>2. After 50 EPOCHS<\/h3>","2e4eff8a":"<div style=\"font-family:verdana; word-spacing:1.7px;\">\nRunning the example generates 25 examples of fake  images and visualizes them on a single plot of 5 by 5 images. As the model is not trained, the generated images are completely random pixel values in [-1, 1], rescaled to [0, 1]. As we might expect, the images look like a mess of gray.\n    <\/div>","3c84d403":"<h3><center>7. Generating Real Samples<\/center><\/h3>","c381b817":"<h3><center>11. Interpolate Between Generated Faces<\/center><\/h3>","b0d08c9c":"<h3><center>9. Train GAN Network<\/center><\/h3>\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nFirst, the discriminator model is updated for a half batch of real samples, then a half batch of fake samples, together forming one batch of weight updates. <br><br>The generator is then updated via the combined GAN model. <br><br>Importantly, the class label is set to 1 or real for the fake samples. This has the effect of updating the generator toward getting better at generating real samples on the next batch.<\/div>","5274ec67":"<h3><center>12. Vector Arithmetic in Latent Space<\/center><\/h3>\n\n        smiling woman \u2212 neutral woman + neutral man = smiling man","cef81011":"We need three faces for each of smiling woman, neutral woman, and neutral man.\n\n(Positions\/index)<br>\nSmiling Women - 6, 9, 35<br>\nNeutral Women - 10, 24, 27<br>\nNeutral Man - 4, 7, 8\n","7ae59659":"<h3><center>8. Create Latent space & Generate Fake Samples from it<\/center><\/h3>\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nWe have to generate new random points in the latent space. We can achieve this by calling the randn() NumPy function for generating arrays of random numbers drawn from a standard Gaussian.\n    <\/div>","93c10a19":"<h3><center>5. Define Generator<\/center><\/h3>\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nIt is recommended to use the hyperbolic tangent activation function as the output from the generator model. As such, it is also recommended that real images used to train the discriminator are scaled so that their pixel values are in the range [-1,1]. This is so that the discriminator will always receive images as input, real and fake, that have pixel values in the same range.\n    <\/div>","48299d2b":"Next, we can retrieve each vector and calculate the average for each vector type (e.g. smiling woman). We could perform vector arithmetic with single images directly, but we will get a more robust result if we work with an average of a few faces with the desired property.","980840c7":"<h3>1. After 10 EPOCHS<\/h3>","1f5225f2":"<h3><center>10. Explore the Latent Space for Generated Faces<\/center><\/h3>","f25a7542":"<h3><center>3. Extract Faces using MTCNN<\/center><\/h3>","69548d0f":"First 3 are examples from the latent space and the last one in a row is the average value","db6d4c42":"<div style=\"font-family:verdana; word-spacing:1.7px;\">\nWe have performed a linear interpolation which assumes that the latent space is a uniformly distributed hypercube. Technically, our chosen latent space is a 100-dimension hypersphere or multimodal Gaussian distribution. There is a mathematical function called the spherical linear interpolation function, or Slerp, that should be used when interpolating this space to ensure the curvature of the space is taken into account.\n    <\/div>","510a2863":"<h3><center>4. Define Discriminiator<\/center><\/h3>"}}