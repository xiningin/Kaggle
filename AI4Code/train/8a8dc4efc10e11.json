{"cell_type":{"6ec2e9d6":"code","3c5b1bdf":"code","1407343e":"code","e6845150":"code","b71e4878":"code","f3843bd7":"code","76f1ddd0":"code","5e627629":"code","08b96f6d":"code","38c126fc":"code","fef3587e":"code","c2b20982":"code","de744098":"code","c205cf86":"code","626b242a":"code","ae2f0f72":"markdown","038673b1":"markdown","e73be496":"markdown","fc4d2975":"markdown","2237d330":"markdown","2994d9f1":"markdown","4824e751":"markdown","87e1ce23":"markdown"},"source":{"6ec2e9d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3c5b1bdf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.layers import *\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.models import Model, load_model, save_model, Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv2DTranspose\nfrom keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\nfrom keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.backend.tensorflow_backend import set_session\n\nsns.set(style='white', context='notebook', palette='deep')","1407343e":"import os\nimport numpy as np       # linear algebra\nimport pandas as pd      # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom glob import glob    # finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\nfrom skimage.util import montage \nfrom skimage.io   import imread\n%matplotlib inline","e6845150":"BASE_IMG_PATH = os.path.join('..','input\/finding-lungs-in-ct-data\/')\nDS_FACT = 2\nSEED=42\n\nall_image_files = glob(os.path.join(BASE_IMG_PATH,'2d_images','*.tif'))\nall_mask_files  = glob(os.path.join(BASE_IMG_PATH,'2d_masks','*.tif'))\n\nprint('No. of images:', len(all_image_files))\nprint(all_image_files[0])\nprint(all_mask_files[0])","b71e4878":"test_image = np.expand_dims(imread(all_image_files[0])[::2, ::2],0)\ntest_mask  = np.expand_dims(imread(all_mask_files[0])[::2, ::2],0)\/255.0\nfig, (ax1 ,ax2) = plt.subplots(1, 2)\nax1.imshow(test_image[0])\nax2.imshow(test_mask[0])\nprint(test_image.shape)","f3843bd7":"images  = np.stack((np.expand_dims(imread(i)[::DS_FACT, ::DS_FACT], -1) for i in all_image_files),0)\nmasks   = np.stack((np.expand_dims(imread(i)[::DS_FACT, ::DS_FACT]\/255., -1) for i in all_mask_files),0)\n                  \nX_train, X_test, y_train,  y_test = train_test_split(images, masks, test_size=0.1)\n\nprint('X_train - len\/shape:', len(X_train), X_train.shape)\nprint('Y_train is {}, min is {}, max is {}, mean is {}'.format(y_train.shape, y_train.min(), y_train.max(), y_train.mean()))\nprint('X_test  - len\/shape:', len(X_test), y_test.shape)\nprint(images.shape[:])","76f1ddd0":"def unet(inputs, n=32):\n    bn    = BatchNormalization()(inputs)  \n    conv1 = Conv2D(n, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(bn)\n    conv1 = Conv2D(n, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    pool1 = Dropout(0.1)(pool1)\n\n    conv2 = Conv2D(n*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n    conv2 = Conv2D(n*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    pool2 = Dropout(0.1)(pool2)\n\n    conv3 = Conv2D(n*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n    conv3 = Conv2D(n*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    pool3 = Dropout(0.1)(pool3)\n\n    conv4 = Conv2D(n*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n    conv4 = Conv2D(n*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)    \n    pool4 = Dropout(0.1)(pool4)\n\n    convm = Conv2D(n*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool4)\n    convm = Conv2D(n*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(convm)\n\n    up6   = Conv2DTranspose(n*8, (2, 2), strides=(2, 2), padding='same')(convm)\n    conv6 = concatenate([up6, conv4])\n    conv6 = Dropout(0.1)(conv6)                   \n    conv6 = Conv2D(n*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n    conv6 = Conv2D(n*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n\n    up7   = Conv2DTranspose(n*4, (2, 2), strides=(2, 2), padding='same')(conv6)\n    conv7 = concatenate([up7, conv3])\n    conv7 = Dropout(0.1)(conv7)\n    conv7 = Conv2D(n*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n    conv7 = Conv2D(n*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n\n    up8   = Conv2DTranspose(n*2, (2, 2), strides=(2, 2), padding='same')(conv7)\n    conv8 = concatenate([up8, conv2])\n    conv8 = Dropout(0.1)(conv8)  \n    conv8 = Conv2D(n*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n    conv8 = Conv2D(n*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n\n    up9   = Conv2DTranspose(n, (2, 2), strides=(2, 2), padding='same')(conv8)\n    conv9 = concatenate([up9, conv1])\n    conv9 = Dropout(0.1)(conv9) \n    conv9 = Conv2D(n, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n    conv9 = Conv2D(n, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n\n    output = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[output])","5e627629":"\ninput_img = Input(X_train.shape[1:], name='img')\nn_filters   = 32\n\nmodel = unet(input_img, n_filters)\n\nmodel.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nprint(model.summary())","08b96f6d":"from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\ncallbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n    ModelCheckpoint('model-lung.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]\n","38c126fc":"history = model.fit(X_train, y_train, batch_size=10, epochs=24, callbacks=callbacks, \\\n                    validation_data=(X_test, y_test))","fef3587e":"def plot_history(history, title):\n    plt.figure(figsize=(10,3))\n    # Plot training & validation accuracy values\n    plt.subplot(121)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n\n    # Plot training & validation loss values\n    plt.subplot(122)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()","c2b20982":"plot_history(history, 'UNet Loss\/Accuracy')","de744098":"model.load_weights('model-lung.h5')","c205cf86":"plt.imshow(\n    model.predict(X_train[0].reshape(1,256, 256, 1))[0,:,:,0], \n    cmap='gray')","626b242a":"y_predict = model.predict(X_test)\n\nfor i in range(X_test.shape[0]): \n    fig, ax = plt.subplots(1,3,figsize=(12,6))\n    ax[0].set_title('Original')\n    ax[1].set_title('Result')\n    ax[2].set_title('Predicted Result')\n    ax[0].imshow(X_test[i,:,:,0], cmap='gray')\n    ax[1].imshow(y_test[i,:,:,0])\n    ax[2].imshow(y_predict[i,:,:,0])","ae2f0f72":"# Load an image and check it out ... ","038673b1":"# Locate all the image and mask files ","e73be496":"# Define the model","fc4d2975":"# Define the UNET ","2237d330":"# Evaluation","2994d9f1":"Load all the images and masks","4824e751":"# Show the predictions of all 27 validation cases","87e1ce23":"The validation loss is 0.0267"}}