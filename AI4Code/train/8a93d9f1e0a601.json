{"cell_type":{"eb664358":"code","8e26e59a":"code","db3ac45b":"code","f95ea5c6":"code","4bcc5eb8":"code","8f8fb7e4":"code","43b186bc":"code","c4ed4b71":"code","2dc396b6":"code","af3557ac":"code","98d46277":"code","38851ba1":"code","0f2d0407":"code","eff6c37b":"code","93a0d141":"code","b493505a":"code","ee7f766f":"code","7581197b":"code","7db23400":"code","2e34d18c":"code","8a4ff058":"code","984c19ec":"code","fb738f46":"code","e14aead2":"code","db3bb41a":"code","976b944c":"code","4d7fe36e":"code","77624d80":"code","356b5dd9":"code","c6bed677":"markdown"},"source":{"eb664358":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf","8e26e59a":"data=pd.read_csv(\"..\/input\/plant-pathology-2021-fgvc8\/train.csv\")","db3ac45b":"data.shape","f95ea5c6":"data.head()","4bcc5eb8":"data[\"image\"].head()","8f8fb7e4":"import matplotlib.pyplot as plt","43b186bc":"train_paths=\"..\/input\/plant-pathology-2021-fgvc8\/train_images\/\"","c4ed4b71":"img=plt.imread(train_paths+data[\"image\"][4])","2dc396b6":"img.shape","af3557ac":"plt.imshow(img)","98d46277":"data[\"labels\"].unique()","38851ba1":"zerofilling=np.zeros((18632,6))","0f2d0407":"labels=pd.DataFrame(columns=[\"healthy\",\"scab\",\"frog_eye_leaf_spot\",\"complex\",\"rust\",\"powdery_mildew\"],data=zerofilling)","eff6c37b":"labels.head()","93a0d141":"for i in range(data.shape[0]):\n    full_lab=data.loc[i,\"labels\"]\n    for j in range(6):\n        lab=labels.columns[j]\n        if lab in full_lab:\n            labels.loc[i,lab]=1","b493505a":"labels.head()","ee7f766f":"labels.index=data.index","7581197b":"labels.head()","7db23400":"data.drop(\"labels\",axis=1,inplace=True)","2e34d18c":"data=pd.concat([data,labels],axis=1)","8a4ff058":"print(\"Label Counts:\\n\")\nprint(labels.sum())\nprint(\"\\n\\nLabel Percentages:\\n\")\nprint(100*labels.sum()\/data.shape[0])","984c19ec":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","fb738f46":"train_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   samplewise_center=True, \n                                   samplewise_std_normalization=True,\n                                   validation_split = 0.2)","e14aead2":"train_generator = train_datagen.flow_from_dataframe(dataframe = data,\n                                                   directory = train_paths,\n                                                   target_size = (128,128),\n                                                   x_col = 'image',\n                                                   y_col = list(labels.columns),\n                                                   batch_size = 32,\n                                                   color_mode = 'rgb',\n                                                   class_mode = 'raw',\n                                                   subset = 'training')\n\ntest_generator = train_datagen.flow_from_dataframe(dataframe = data,\n                                                 directory = train_paths,\n                                                 target_size = (128,128),\n                                                 x_col = 'image',\n                                                 y_col = list(labels.columns),\n                                                 batch_size = 32,\n                                                 color_mode = 'rgb',\n                                                 class_mode = 'raw',\n                                                 subset = 'validation')","db3bb41a":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization","976b944c":"convnet=Sequential([\n\n    Conv2D(filters=16,kernel_size=5,strides=3,padding=\"same\",activation=\"relu\",name=\"conv1\",input_shape=(128,128,3)),\n    BatchNormalization(name=\"BN1\"),\n    MaxPool2D(pool_size=(2,2),name=\"Pool1\"),\n\n    Conv2D(filters=32,kernel_size=4,strides=2,padding=\"same\",name=\"conv2\",activation=\"relu\"),\n    BatchNormalization(name=\"BN2\"),\n    MaxPool2D(pool_size=(2,2),name=\"Pool2\"),\n\n    Conv2D(filters=64,kernel_size=3,strides=1,padding=\"same\",name=\"conv3\",activation=\"relu\"),\n    BatchNormalization(name=\"BN3\"),\n    MaxPool2D(pool_size=(2,2),name=\"Pool3\"),\n    \n    Conv2D(filters=32,kernel_size=1,strides=1,padding=\"valid\",name=\"conv4\",activation=\"relu\"),\n    BatchNormalization(name=\"BN4\"),\n\n    Flatten(name=\"Flatten\"),\n    \n    Dense(64,activation=\"relu\",name=\"FullyConnected1\"),\n    Dropout(0.3,name=\"DropOut1\"),\n    BatchNormalization(name=\"BN5\"),\n    \n    Dense(32,activation=\"relu\",name=\"FullyConnected2\"),\n    Dropout(0.3,name=\"DropOut2\"),\n    BatchNormalization(name=\"BN6\"),\n    \n    Dense(6,activation=\"sigmoid\",name=\"OutputDense\")\n])\n\nconvnet.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])","4d7fe36e":"convnet.summary()","77624d80":"history = convnet.fit(train_generator, validation_data=test_generator, epochs=5)","356b5dd9":"history2 = convnet.fit(train_generator, validation_data=test_generator, epochs=2)","c6bed677":"The data is quite imbalanced.\nI'll try a baseline model first, then we'll see."}}