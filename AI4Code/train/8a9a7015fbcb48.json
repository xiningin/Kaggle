{"cell_type":{"ea9319c8":"code","7a90a771":"code","9125d224":"code","b6397792":"code","b6d18174":"code","f4b75b6b":"code","0b72c5fc":"code","992ed630":"code","f929a704":"code","d7ed1075":"code","2c51a3d4":"code","99b83557":"code","902cb087":"code","d2ae0ad2":"code","682c01cd":"code","1d6cdb81":"code","6944323b":"code","b501891c":"code","0db12434":"code","8afa1689":"code","b6fce055":"code","5f4ff5fe":"code","d51ccbab":"code","c44ab0f8":"code","3d43355c":"code","685e8ec6":"code","be4e359d":"code","558482ca":"code","dc6bc0cc":"code","226e8e67":"code","d14d0d66":"code","dc8cd4cf":"code","56d021d8":"code","be1feecd":"code","9359b338":"code","1ea8d914":"code","adcc2e50":"code","19af3388":"code","daa68fc2":"code","cd1a3e7a":"code","6ed5b24d":"code","7f4d8785":"code","0d7b6204":"code","d38a5c49":"code","edde4bd9":"code","0c67f749":"code","660ce468":"code","b873c58d":"code","1c3bbdaa":"code","7de3333c":"code","66b9be7d":"code","86c8d550":"markdown","17094830":"markdown","80c50e7e":"markdown","d50a1c83":"markdown","dae66c7d":"markdown","95015443":"markdown","e485d008":"markdown","3f266353":"markdown","db6f7fe6":"markdown","68dc023f":"markdown","706fdd0d":"markdown","0dab5ca3":"markdown","b149a2e4":"markdown","c819cc84":"markdown","9c1f5af4":"markdown","23b1dd1d":"markdown","51d33c87":"markdown","a3fa9356":"markdown","7336fe9a":"markdown","44ebf7b7":"markdown","a9f6414d":"markdown","e77b47f3":"markdown","3d3fe6b8":"markdown","3e98fa52":"markdown","29ff11a6":"markdown","19224fc1":"markdown","bf9b358f":"markdown","7e672ade":"markdown"},"source":{"ea9319c8":"# https:\/\/github.com\/abdul-haseeb123\/projects\/tree\/master\/KHP","7a90a771":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9125d224":"# LOADING OUR DATA\nproperties_fe = pd.read_csv(\"..\/input\/zameencom-property-data-pakistan\/Property_with_Feature_Engineering.csv\")\nproperties_fe.head()","b6397792":"# Checking cities for subsetting later\nprint(properties_fe[\"city\"].unique())\nproperties_fe.shape","b6d18174":"df = properties_fe[properties_fe[\"city\"] == \"Karachi\"] # Subsetting the data with respect to Karachi\ndf.head()\ndf.shape","f4b75b6b":"# dropping unnecessary columns\ncol_names = [\"location_id\",\"page_url\",\"province_name\",\"locality\",\"area_marla\",\"year\",\"month\",\"day\",\"agency\",\"agent\",\"latitude\",\"longitude\",\"property_id\",\"property_type\",\"price_bin\",\"purpose\",\"date_added\",\"city\",\"area\"]\ndf = df.drop(col_names, axis=1)","0b72c5fc":"df = df.reset_index()\ndf = df.drop(\"index\",axis=1)\ndf.head()","992ed630":"# Checking if any null values in the df\ndf.isna().sum()","f929a704":"# importing matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\n\ndf.shape","d7ed1075":"df['bedrooms'].unique()","2c51a3d4":"df[df['bedrooms']>13]","99b83557":"df['baths'].unique()","902cb087":"df = df.drop(df[(df['baths']==0) & (df['bedrooms'] > 3)].index)\ndf","d2ae0ad2":"df.drop(df[(df['bedrooms']==0) | (df['baths']==0)].index, inplace=True)","682c01cd":"df[df[\"baths\"] > df[\"bedrooms\"]].head(25)","1d6cdb81":"df['price_per_sqft'] = df['price'] \/ df['area_sqft']\ndf.head()","6944323b":"len(df['location'].unique())","b501891c":"df['location'] = df['location'].apply(lambda x: x.strip())\nlocation_stats = df.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_stats.head(40)","0db12434":"len(location_stats[location_stats <= 10])","8afa1689":"locations_less_than_10 = location_stats[location_stats <= 10]\ndf['location'] = df['location'].apply(lambda x:'others' if x in locations_less_than_10 else x)","b6fce055":"df['location'].nunique()","5f4ff5fe":"df[df['area_sqft'] \/ df['bedrooms'] < 300]","d51ccbab":"df.drop(df[df['area_sqft'] \/ df['bedrooms'] < 300].index, inplace = True)","c44ab0f8":"df['price_per_sqft'].describe()","3d43355c":"# removing price_per_sqft outliers \ndef remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key,subdf in df.groupby('location'):\n        m = np.mean(subdf['price_per_sqft'])\n        std = np.std(subdf['price_per_sqft'])\n        reduced_df = subdf[(subdf['price_per_sqft'] > (m-std)) & (subdf['price_per_sqft'] <= (m+std))]\n        df_out = pd.concat([df_out,reduced_df], ignore_index=True)\n    return df_out","685e8ec6":"df = remove_pps_outliers(df)\ndf.shape","be4e359d":"def plot_scatter_chart(df, location):\n    bedroom_2 = df[(df['location'] == location) & (df['bedrooms'] == 2)]\n    bedroom_3 = df[(df['location'] == location) & (df['bedrooms'] == 3)]\n    matplotlib.rcParams[\"figure.figsize\"] = (15,10)\n    plt.scatter(bedroom_2['area_sqft'], bedroom_2['price']\/100000, color='blue', label=\"2 Bedroom\", s=50)\n    plt.scatter(bedroom_3['area_sqft'], bedroom_3['price']\/100000, marker='+', color=\"green\", label=\"3 Bedroom\", s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price\")\n    plt.title(location)\n    plt.legend()","558482ca":"plot_scatter_chart(df, \"M. A. Jinnah Road\")","dc6bc0cc":"def remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby(\"location\"):\n        bhk_stats = {}\n        for bedroom, bedroom_df in location_df.groupby(\"bedrooms\"):\n            bhk_stats[bedroom] = {\n                'mean' : np.mean(bedroom_df[\"price_per_sqft\"]),\n                'std' : np.std(bedroom_df[\"price_per_sqft\"]),\n                'count': bedroom_df.shape[0]\n            }\n        for bedroom, bedroom_df in location_df.groupby(\"bedrooms\"):\n            stats = bhk_stats.get(bedroom - 1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bedroom_df[bedroom_df['price_per_sqft'] < (stats['mean'])].index.values)\n    return df.drop(exclude_indices, axis=\"index\") ","226e8e67":"df = remove_bhk_outliers(df)\ndf.shape","d14d0d66":"df.groupby('location')['location'].agg('count').sort_values(ascending=False).head(40)","dc8cd4cf":"plot_scatter_chart(df,\"Shahra-e-Faisal\")","56d021d8":"fig, ax = plt.subplots(figsize=(15,10))\nplt.hist(df['price_per_sqft'], rwidth=0.8)\nplt.xlabel(\"Price Per Square Ft\")\nplt.ylabel(\"Count\")\nplt.show()","be1feecd":"df[df['baths'] > df['bedrooms']]","9359b338":"df[df['baths'] > (df['bedrooms'] + 2)]","1ea8d914":"df = df.drop(df[df['baths'] > (df['bedrooms'] + 2)].index)\ndf.shape","adcc2e50":"df1 = df.drop(\"price_per_sqft\", axis=1)","19af3388":"dummies = pd.get_dummies(df1['location'])\ndummies.head(3)","daa68fc2":"df1 = pd.concat([df1, dummies.drop('others', axis=1)], axis=\"columns\")\ndf1 = df1.drop(\"location\", axis=1)\ndf1.head()\ndf1.shape","cd1a3e7a":"X = df1.drop('price', axis=1) # Features\nX.head()","6ed5b24d":"y = df1['price'] # Predictor or predicted_variable\ny.head()","7f4d8785":"from sklearn.model_selection import train_test_split # for dividing data into training and test sets\nfrom sklearn.linear_model import LinearRegression # for predicting price\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nlr.score(X_test, y_test)","0d7b6204":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\ncross_val_score(LinearRegression(), X, y, cv=cv)","d38a5c49":"# importing other regression models to find the best performing model using GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV","edde4bd9":"def find_best_model_using_gridsearchcv(X, y):\n    algos = {\n        'linear_regression': {\n            'model':LinearRegression(),\n            'params': {'normalize':[True,False]}\n    \n        },'decision_tree_regressor':{\n            'model': DecisionTreeRegressor(),\n            'params': {'criterion': ['mse','friedman_mse'], 'splitter':['best','random']}\n        },'lasso': {\n            'model':Lasso(),\n            'params': {'alpha':[1,2], 'selection':['random','cyclic']}\n        }\n    }\n    \n    \n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    scores = []\n    for algo_name, config in algos.items():\n        gs = GridSearchCV(config['model'], config['params'], return_train_score=False, n_jobs=-1, cv=cv)\n        gs.fit(X, y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_ ,\n            'best_params': gs.best_params_\n        })\n        \n    return pd.DataFrame(scores, columns=['model','best_score','best_params'])","0c67f749":"find_best_model_using_gridsearchcv(X, y)","660ce468":"dtr = DecisionTreeRegressor(criterion='friedman_mse', splitter='random', random_state=0)\ndtr.fit(X, y)","b873c58d":"X.columns","1c3bbdaa":"def predict_price(location, sqft, bedrooms, baths):\n    loc_index = np.where(X.columns==location)[0][0]\n    \n    x = np.zeros(len(X.columns))\n    x[0] = baths\n    x[1] = sqft\n    x[2] = bedrooms\n    if loc_index >= 0:\n        x[loc_index] = 1\n    return dtr.predict([x])[0] \/ 100000","7de3333c":"print(str(int(predict_price('Nazimabad', 1800, 4, 3))) + \" Lakhs\")","66b9be7d":"print(str(int(predict_price('Scheme 33', 1080, 3, 2))) + \" Lakhs\")","86c8d550":"As we add the column price_per_sqft for our dimensionality reduction we will now remove this column as this is not a feature for predicting property pricing...","17094830":"**Our Problem Statement is to analyze the dataset of properties in Karachi and then building a model to predict its price using location, Area(Sq.ft), bedrooms, baths...**","80c50e7e":"In the above cell we are dropping those indexes that are having no baths and having bedrooms greater than 3 cause they can probably be a typo error.","d50a1c83":"As the price of property is continuous so we will be using regression models ","dae66c7d":"Note that our linear regression model performs with 83% accuracy which is quite good...","95015443":"First we make dummies of our locations","e485d008":"Notice how much it is having standard deviation we will reduce it...","3f266353":"# MODEL BUILDING AND EVALUATION","db6f7fe6":"We are also dropping those properties that are either having no bedrooms or no baths in the above cell...","68dc023f":"As You can see in the above cell that there are some properties which have bedrooms even greater than 10...This could be possible that some of them could be typo error while others can be having other errors in them as well like very less baths or no baths...Lets inspect the properties that are having bedrooms more than 13","706fdd0d":"We have add a column of price_per_sqft for our feature engineering so that we can remove the outliers from our data....","0dab5ca3":"# PROBLEM STATEMENT","b149a2e4":"Then we plot the graph and 5000 price per square ft is the most common price ","c819cc84":"As decision_tree_regressor performs the best with 93% accuracy we will be using its best params and bulding our model...","9c1f5af4":"Firstly there were 199 unique locations and now we are having only 102 unique locations after dimensionality reduction","23b1dd1d":"# KARACHI PROPERTY PRICE PREDICTION","51d33c87":"# DATA CLEANING","a3fa9356":"# OUTLIERS DETECTION AND REMOVALS:","7336fe9a":"There are some homes that are having more number of baths as compared to its bedrooms which is quite uncommon...","44ebf7b7":"Notice in the above graph that there are some properties having 3 bedrooms still in less price than 2 bedrooms properties in a specfied location. Now they can also be considered as outliers and we should also remove them so that they cannot affect our model performance","a9f6414d":"Notice that there are 98 locations that are having properties less than 10 so we can categorize them as others which will help us in dimensionality reduction in our machine learning model.","e77b47f3":"Notice how some of them are having no baths and some are having very less number of baths as compared to their bedrooms...","3d3fe6b8":"# EDA (EXPLORATORY DATA ANALYSIS):\nAs there are so much columns so we will be dropping the columns that have either very little importance or can be considered as extras..","3e98fa52":"Then use shuffle split for our cross validation and it gives the maximum accuracy of 86%...","29ff11a6":"In the above cell we assume that on  minimum a bedroom must be more than 300 sq.ft so those that were not following that rule in our data we will be removing them as they will be considered as outliers...","19224fc1":"**HERE IS MY GITHUB REPOSITORY LINK FOR THIS PROJECT IN WHICH I HAD MAKE BACK END AND FRONT END FOR THIS MODEL AND DEPLOYED IT USING EC2 INSTANCE OF AMAZON AWS\nPLEASE STAR IT AS WELL**","bf9b358f":"Then we concat them with our data...","7e672ade":"Also notice in the above cell that some properties are having upto 12 baths as well, this could be a typo error as well"}}