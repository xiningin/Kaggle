{"cell_type":{"a36d3bea":"code","8f1ada81":"code","cbeb02cc":"code","8fdc71bf":"code","f1757840":"code","a94da554":"code","b01681b1":"code","c178258f":"code","298818b2":"code","c4639bef":"code","1ca6542c":"code","460d87b1":"code","8fa1ab41":"code","2daaa9c1":"code","04909ca5":"code","5862bf3e":"code","c865c9d0":"code","7c96b0e1":"code","debddff6":"code","e9ca0d5f":"code","3f5c6c7c":"code","5706ddfb":"code","14560fde":"code","3f3fa994":"code","b846f7d6":"code","45502594":"code","c2cf1ad5":"code","302a690c":"code","c01050c9":"code","2b285ae2":"code","12963cb9":"code","7909be35":"code","d5ba48b3":"code","c152d780":"markdown","5e0b0523":"markdown","42f5aa09":"markdown","ebff5882":"markdown","f0c8cee7":"markdown","ee01f750":"markdown","41fcc5ce":"markdown","ff281ad1":"markdown","b55f2d02":"markdown","74943e36":"markdown","80daf974":"markdown","05643bef":"markdown","a0a3e1b5":"markdown","f8c62dbc":"markdown","4d8ead51":"markdown","e502ac82":"markdown","1e1c9410":"markdown","d061bf59":"markdown"},"source":{"a36d3bea":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom plotly.subplots import make_subplots\nimport tensorflow.keras.layers as L\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport os\n\ndata_dir = '..\/input\/vehicle-data\/'","8f1ada81":"# reading all data\nvehicle = pd.read_csv(os.path.join(data_dir, 'Train_Vehicletravellingdata.csv'))\nweather = pd.read_csv(os.path.join(data_dir, 'Train_WeatherData.csv'))\ntrain = pd.read_csv(os.path.join(data_dir, 'Train.csv'))","cbeb02cc":"vehicle.head()","8fdc71bf":"weather.head()","f1757840":"train.head()","a94da554":"cons_df = pd.concat([vehicle, weather.drop(columns=['ID', 'Date time'])], axis=1)\ncons_df = cons_df.merge(train, on=['ID'])","b01681b1":"# Let's see the count of target variable\ndriving_style_df = cons_df['DrivingStyle'].value_counts().to_frame()\ndriving_style_df.columns = ['count']\ndriving_style_df['Labels'] = driving_style_df.index\n\nfig = px.bar(driving_style_df, x='Labels', y='count')\nfig.show()","c178258f":"# Count of missing values in columns\nmissing_values = cons_df.isnull().sum()\nmissing_values = missing_values[missing_values > 0].sort_values()\n\nmissing_values = missing_values.to_frame()\nmissing_values.columns = ['count']\nmissing_values.index.names = ['Name']\nmissing_values['Name'] = missing_values.index\n\nfig = px.bar(missing_values, x='Name', y='count')\nfig.show()","298818b2":"# Checking distribution of Speed\ndf = px.data.tips()\nfig = px.box(cons_df, y=\"Speed of the vehicle (kph)\", points=\"all\")\nfig.show()","c4639bef":"# Histogram\ndf = px.data.tips()\nfig = px.histogram(cons_df, x=\"Speed of the vehicle (kph)\", color=\"Lane of the road\", marginal=\"violin\")\nfig.show()","1ca6542c":"# Aggregating on vehicle ID\nagg_df = cons_df.groupby(['ID']).agg({'Speed of the vehicle (kph)': 'mean', 'DrivingStyle': 'first'})","460d87b1":"# Histogram\ndf = px.data.tips()\nfig = px.histogram(agg_df, x=\"Speed of the vehicle (kph)\", color=\"DrivingStyle\", marginal=\"violin\")\nfig.show()","8fa1ab41":"transform_df = cons_df.copy()\ntransform_df['count'] = cons_df.groupby(['ID'])['DrivingStyle'].transform('count')","2daaa9c1":"# Taking the vehicle of each class with maximum number of observations\nds1 = transform_df.loc[transform_df['DrivingStyle'] == 1]\nds1 = ds1.loc[ds1['count'] == ds1['count'].max()]\nprint(ds1['ID'].nunique())\n\nds2 = transform_df.loc[transform_df['DrivingStyle'] == 2]\nds2 = ds2.loc[ds2['count'] == ds2['count'].max()]\nprint(ds2['ID'].nunique())\n\nds3 = transform_df.loc[transform_df['DrivingStyle'] == 3]\nds3 = ds3.loc[ds3['count'] == ds3['count'].max()]\nprint(ds3['ID'].nunique())","04909ca5":"ds1x = np.linspace(0, 1, len(ds1))\nds2x = np.linspace(0, 1, len(ds2))\nds3x = np.linspace(0, 1, len(ds3))\n\nds1y = ds1['Speed of the vehicle (kph)'].values\nds2y = ds2['Speed of the vehicle (kph)'].values\nds3y = ds3['Speed of the vehicle (kph)'].values\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=ds1x, y=ds1y,\n                    mode='lines',\n                    name='aggressive'))\nfig.add_trace(go.Scatter(x=ds2x, y=ds2y,\n                    mode='lines',\n                    name='normal'))\nfig.add_trace(go.Scatter(x=ds3x, y=ds3y,\n                    mode='lines', name='vague'))\n\nfig.show()","5862bf3e":"label_encoding_columns = ['Road Condition', 'Precipitation', 'Precipitation intensity', 'Day time']\ncons_df[label_encoding_columns] = cons_df[label_encoding_columns].apply(LabelEncoder().fit_transform)","c865c9d0":"train_df = cons_df.drop(columns=['ID of the preceding vehicle', 'Date time', 'DrivingStyle'])","7c96b0e1":"missing_values_columns = list(missing_values['Name'])\n\nfor col in missing_values_columns:\n    train_df[col] = train_df[col].fillna(train_df[col].mean())","debddff6":"train_df = train_df.drop(train_df[(train_df['Speed of the vehicle (kph)'] >140) | (train_df['Speed of the vehicle (kph)']< 20)].index).reset_index(drop=True)","e9ca0d5f":"# Speed Ratio\ntrain_df['speed_ratio'] = (train_df['Speed of the vehicle (kph)']\/train_df['Speed of the preceding vehicle']).clip(0, 2)\n\n# Time ratio\ntrain_df['time_ratio1'] = (train_df['Time gap with the preceeding vehicle in seconds']\/train_df['Speed of the vehicle (kph)']).clip(0, 2)\ntrain_df['time_ratio2'] = (train_df['Time gap with the preceeding vehicle in seconds']\/train_df['Speed of the preceding vehicle']).clip(0, 2)\n\n# Weight Ratio\ntrain_df['weight_ratio'] = (train_df['Weight of the preceding vehicle']\/train_df['weight of vehicle in kg']).clip(0, 100)\n","3f5c6c7c":"train_df.filter(regex=r'_ratio').describe()","5706ddfb":"scaling_columns = [\n    'Speed of the vehicle (kph)', 'Speed of the preceding vehicle', 'Length of preceding vehicle',\n    'Time gap with the preceeding vehicle in seconds', 'Weather details-Air temperature', 'Weight of the preceding vehicle',\n    'Relative humidity', 'Wind direction', 'Wind speed in m\/s', 'Length of vehicle in cm', 'weight of vehicle in kg',\n    'Number of axles', 'Number of axles'\n]\nscaler = StandardScaler()\ntrain_df[scaling_columns] = scaler.fit_transform(train_df[scaling_columns])","14560fde":"train_df.head()","3f3fa994":"train_df.columns","b846f7d6":"sequences = list()\n\nfor name, group in tqdm(train_df.groupby(['ID'])):\n    sequences.append(group.drop(columns=['ID']).values)","45502594":"len_sequences = []\nfor one_seq in sequences:\n    len_sequences.append(len(one_seq))\npd.Series(len_sequences).describe()","c2cf1ad5":"#Padding the sequence with the values in last row to max length\nto_pad = 112\nnew_seq = []\nfor one_seq in sequences:\n    len_one_seq = len(one_seq)\n    last_val = one_seq[-1]\n    n = to_pad - len_one_seq\n   \n    to_concat = np.repeat(one_seq[-1], n).reshape(21, n).transpose()\n    new_one_seq = np.concatenate([one_seq, to_concat])\n    new_seq.append(new_one_seq)\nfinal_seq = np.stack(new_seq)\n\nseq_len = 80\nfinal_seq=tf.keras.preprocessing.sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')","302a690c":"target = pd.get_dummies(train['DrivingStyle'])\ntarget = np.asarray(target)","c01050c9":"X_train,X_test,y_train,y_test = train_test_split(final_seq,target,test_size=0.20,random_state=34)","2b285ae2":"model = tf.keras.models.Sequential()\nmodel.add(L.LSTM(128, dropout=0.2, input_shape=(seq_len, 21), return_sequences=True))\nmodel.add(L.LSTM(64, dropout=0.2, input_shape=(seq_len, 21), return_sequences=True))\nmodel.add(L.LSTM(64, dropout=0.2))\nmodel.add(L.Dense(3, activation='softmax'))","12963cb9":"adam = tf.keras.optimizers.Adam(lr=0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n\nmodel.summary()","7909be35":"history = model.fit(\n    final_seq,\n    target,\n    epochs=150,\n    batch_size=84,\n    validation_data=(X_test,y_test),\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n    ]\n)","d5ba48b3":"fig = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=(\"Loss\", \"Accuracy\"),\n    shared_yaxes=True,\n    shared_xaxes=True,\n    vertical_spacing=0.1,\n    horizontal_spacing=0.03)\n\nepochs = list(range(1, len(history.history['loss'])+1))\n\nfig.add_trace(\n    go.Scatter(x=epochs, y=history.history['loss'], name='loss'),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Scatter(x=epochs, y=history.history['val_loss'], name='val_loss'),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=epochs, y=history.history['accuracy'], name='acc'),\n    row=1, col=2\n)\nfig.add_trace(\n    go.Scatter(x=epochs, y=history.history['val_accuracy'], name='val_acc'),\n    row=1, col=2\n)","c152d780":"### Imputing missing values with mean","5e0b0523":"Here\n> \u201c1\u201d indicates: \u201cAggressive\u201d\n> \u201c2\u201d indicates: \u201cNormal\u201d\n> \u201c3\u201d indicates: \u201cVague\u201d\n\nThe speed distriubtion of Aggressive driver is more spread than Normal. The vague drivers have most of the data points concentrated near the mean.","42f5aa09":"We can observe that At most of the time normal driving has slower speed than other two, whereas aggressive driving has too much fluctuation than other two.","ebff5882":"## Merge data\nSince vehicle and weather have same number of rows with same sequence of vehicle Id and time we directly concat the dataframes and then merge train data on ID column.","f0c8cee7":"## Imports and read","ee01f750":"### Remove outliers","41fcc5ce":"### Analysing speed","ff281ad1":"### Scaling\nLet's use standard scaler for scaling the columns with large range values","b55f2d02":"## EDA\n\nCount of target values","74943e36":"### Understanding speed of one vehicle from each class","80daf974":"### Missing values graph","05643bef":"### Let's make some features","a0a3e1b5":"### Comparing mean speed throughout journey","f8c62dbc":"## Preprocessing\n\n### Label encoding","4d8ead51":"## Data Transformations","e502ac82":"### Drop redundant columns","1e1c9410":"## LSTM with ADAM\n### Modelling","d061bf59":"We can see that the average speed on Lane 2 is greater than Lane 1 and the Lane 2 speed distribution is slightly skewed towards right with respect to Lane 1"}}