{"cell_type":{"c59d048b":"code","d5b265e4":"code","6377b2ef":"code","f7ef9ef8":"code","75ae15d2":"code","35958778":"code","9937b102":"code","35dc4944":"code","ff203c41":"code","9e73edfb":"code","88b3b3f2":"code","d7d2c63d":"code","40b847a4":"code","9d39856c":"code","fee754a7":"code","03fc8b0c":"code","f670f9d9":"code","2b84c79a":"code","2243b477":"code","eac100d6":"code","7d601852":"code","881dc0a3":"code","3a80c8e1":"code","259b0fc0":"code","cf4c3341":"code","cf52e82f":"code","3185853e":"code","f7fb8f89":"code","115e5346":"code","8aa1d33f":"code","a26a1c3a":"code","4a18226b":"code","e7f3361a":"code","2dc3fafe":"code","58120ac2":"code","3dcd88ad":"code","88761890":"code","3297cca7":"code","656e6de1":"code","4e25260d":"code","a7456e8c":"code","4a64e9eb":"code","6a7a1be2":"code","08937d98":"code","7801e0dd":"code","17b8a255":"code","de61c296":"code","e5b73599":"code","5d5b9bde":"code","f52a0b01":"code","95a6e3c4":"code","e42f083a":"code","7913eb60":"code","82f70f17":"code","029cf5b0":"code","99c93b32":"code","5e604ba0":"code","80f0c251":"code","5fbb5fe5":"code","7750c9bf":"code","283ecfea":"code","97ef71bf":"code","eedcb1ce":"code","13b2a87a":"code","58ca404b":"code","8b604361":"code","9751a9f6":"code","b823887c":"markdown","532b565b":"markdown","ebba2e6a":"markdown","dd503e5f":"markdown","a4a1cf39":"markdown","35cd1cda":"markdown","c38b2448":"markdown","f47d6a06":"markdown","7e8ecae4":"markdown","b9af213f":"markdown","fffc511d":"markdown"},"source":{"c59d048b":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import models, transforms, datasets\nimport time\n%matplotlib inline","d5b265e4":"torch.__version__","6377b2ef":"import sys\nsys.version","f7ef9ef8":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint('Using gpu : %s ' % torch.cuda.is_available())","75ae15d2":"data_dir = '..\/input\/dogscats\/dogscats\/dogscats\/'\nprint(os.listdir('..\/input\/dogscats\/dogscats\/dogscats\/'))","35958778":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                std = [0.229, 0.224, 0.225])\nvgg_format = transforms.Compose([\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize,\n])","9937b102":"dsets = {x:datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)\n        for x in ['train', 'valid']}","35dc4944":"dsets['train'].class_to_idx","ff203c41":"dset_sizes = {x : len(dsets[x]) for x in ['train', 'valid']}\ndset_sizes","9e73edfb":"dset_classes = dsets['valid'].classes\ndset_classes","88b3b3f2":"load_train = torch.utils.data.DataLoader(dsets['train'], batch_size=64, \n                                        shuffle=True, num_workers=6)","d7d2c63d":"load_test = torch.utils.data.DataLoader(dsets['valid'], batch_size=5, \n                                        shuffle=True, num_workers=6)","40b847a4":"count = 1\nfor data in load_test:\n    print(count , end=',')\n    if count == 1:\n        inputs_try, labels_try = data\n    count += 1","9d39856c":"labels_try","fee754a7":"inputs_try.shape","03fc8b0c":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = np.clip(std * inp + mean, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)","f670f9d9":"out = torchvision.utils.make_grid(inputs_try)\nimshow(out, title=[dset_classes[x] for x in labels_try])","2b84c79a":"inputs, classes = next(iter(load_train))\n\nn_images =  8\n\nout = torchvision.utils.make_grid(inputs[0:n_images])\n\nimshow(out, title=[dset_classes[x] for x in classes[0:n_images]])","2243b477":"inputs, classes = next(iter(load_test))\n\nn_images =  8\n\nout = torchvision.utils.make_grid(inputs[0:n_images])\n\nimshow(out, title=[dset_classes[x] for x in classes[0:n_images]])","eac100d6":"model_vgg = models.vgg16(pretrained=True)","7d601852":"import json\nfpath = '..\/input\/imagenet-class-index\/imagenet_class_index.json'\nwith open(fpath) as f:\n    class_dict = json.load(f)","881dc0a3":"dic_imagenet = [class_dict[str(i)][1] for i in range(len(class_dict))]","3a80c8e1":"inputs_try, lables_try = inputs_try.to(device), labels_try.to(device)\n\nmodel_vgg = model_vgg.to(device)","259b0fc0":"outputs_try = model_vgg(inputs_try)","cf4c3341":"outputs_try","cf52e82f":"outputs_try.shape","3185853e":"m_softm = nn.Softmax(dim=1)\nprobs = m_softm(outputs_try)\nvals_try, preds_try = torch.max(probs, dim=1)","f7fb8f89":"torch.sum(probs, 1)","115e5346":"vals_try","8aa1d33f":"print([dic_imagenet[i] for i in preds_try.data])","a26a1c3a":"out = torchvision.utils.make_grid(inputs_try.data.cpu())\nimshow(out, title=[dset_classes[x] for x in labels_try.data.cpu()])","4a18226b":"print(model_vgg)","e7f3361a":"for param in model_vgg.parameters():\n    param.requires_grad = False\nmodel_vgg.classifier._modules['6'] = nn.Linear(4096, 2)\nmodel_vgg.classifier._modules['7'] =  torch.nn.LogSoftmax(dim=1)","2dc3fafe":"print(model_vgg.classifier)","58120ac2":"model_vgg = model_vgg.to(device)","3dcd88ad":"criterion = nn.NLLLoss()\nlr = 0.001\noptimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(), lr = lr)","88761890":"def train_model(model, dataloader, size, epochs=1, optimizer=None):\n    model.train()\n    \n    for epoch in range(epochs):\n        running_loss = 0.0\n        running_corrects = 0\n        for inputs, classes in dataloader:\n            inputs = inputs.to(device)\n            classes = classes.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, classes)\n            optimizer = optimizer\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            _, preds = torch.max(outputs.data, 1)\n            #statistics\n            running_loss += loss.data.item()\n            running_corrects += torch.sum(preds == classes.data)\n        epoch_loss = running_loss \/ size\n        epoch_acc = running_corrects.data.item() \/ size\n        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))","3297cca7":"%time\ntrain_model(model_vgg, load_train,\n            size=dset_sizes['train'], epochs=2, optimizer=optimizer_vgg)\n","656e6de1":"def test_model(model, dataloader, size):\n    model.eval()\n    predictions = np.zeros(size)\n    all_classes = np.zeros(size)\n    all_proba = np.zeros((size, 2))\n    i = 0\n    running_loss = 0.0\n    running_corrects = 0\n    for inputs, classes in dataloader:\n        inputs = inputs.to(device)\n        classes = classes.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, classes)\n        _, preds = torch.max(outputs.data, 1)\n        # statistics\n        running_loss += loss.data.item()\n        running_corrects += torch.sum(preds == classes.data)\n        predictions[i : i + len(classes)] = preds.to('cpu').numpy()\n        all_classes[i : i + len(classes)] = classes.to('cpu').numpy()\n        all_proba[i : i + len(classes)] = outputs.data.to('cpu').numpy()\n        \n        i += len(classes)\n    epoch_loss = running_loss \/ size\n    epoch_acc = running_corrects.data.item() \/ size\n    print('Loss : {:.4f} Acc : {:.4f}'.format(epoch_loss, epoch_acc))\n    return predictions, all_proba, all_classes","4e25260d":"%time\npredictions, all_proba, all_classes = test_model(model_vgg, load_test, size=\n                                                dset_sizes['valid'])","a7456e8c":"# Get a batch of training data\ninputs, classes = next(iter(load_test))\n\nout = torchvision.utils.make_grid(inputs[0: n_images])\n\nimshow(out, title=[dset_classes[x] for x in classes[0:n_images]])","4a64e9eb":"outputs = model_vgg(inputs[:n_images].to(device))\nprint(torch.exp(outputs))","6a7a1be2":"classes[:n_images]","08937d98":"x_try = model_vgg.features(inputs_try)\nx_try.shape","7801e0dd":"def preconvfeat(dataloader):\n    conv_features = []\n    labels_list = []\n    for data in dataloader:\n        inputs, labels = data\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        x = model_vgg.features(inputs)\n        conv_features.extend(x.data.cpu().numpy())\n        labels_list.extend(labels.data.cpu().numpy())\n        conv_features = np.concatenate([[feat] for feat in conv_features])\n        \n        return (conv_features, labels_list)","17b8a255":"%%time\nconv_feat_train, labels_train = preconvfeat(load_train)","de61c296":"conv_feat_train.shape","e5b73599":"%%time\nconv_feat_valid, labels_valid = preconvfeat(load_test)","5d5b9bde":"def data_gen(conv_feat, labels, batch_size=64, shuffle=True):\n    labels = np.array(labels)\n    if shuffle:\n        index = np.random.permutation(len(conv_feat))\n        conv_feat = conv_feat[index]\n        labels = labels[index]\n    for idx in range(0, len(conv_feat), batch_size):\n        yield(conv_feat[idx:idx + batch_size], labels[idx : idx + batch_size])","f52a0b01":"def train_model(model, size, epochs=1, optimizer=None):\n    model.train()\n    \n    for epoch in range(epochs):\n        dataloader = data_gen(conv_feat_train, labels_train)\n        running_loss = 0.0\n        running_corrects = int(0)\n        for inputs, classes in dataloader:\n            \n            inputs, classes = torch.from_numpy(inputs).to(device), torch.from_numpy(classes).to(device)\n            inputs = inputs.to(device)\n            classes = classes.to(device)\n            inputs = inputs.view(inputs.size(0), -1)\n            outputs = model(inputs)\n            loss = criterion(outputs, classes)\n            optimizer = optimizer\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            _, preds = torch.max(outputs.data, 1)\n            # statistics\n            running_loss += loss.data.item()\n            running_corrects += torch.sum(preds == classes.data)\n        epoch_loss = running_loss \/ size\n        epoch_acc = running_corrects.item() \/ size\n        print('Loss : {:.4f} Acc : {:.4f}'.format(epoch_loss, epoch_acc))","95a6e3c4":"%%time\ntrain_model(model_vgg.classifier, size=dset_sizes['train'], epochs=50,\n           optimizer=optimizer_vgg)","e42f083a":"def test_model(model, size):\n    model.eval()\n    predictions = np.zeros(size)\n    all_classes = np.zeros(size)\n    all_proba = np.zeros((size, 2))\n    i = 0\n    running_loss = 0.0\n    running_corrects = 0\n    for inputs, classes in data_gen(conv_feat_valid, labels_valid, shuffle=False):\n        inputs, classes = torch.from_numpy(inputs).to(device),torch.from_numpy(classes).to(device)\n        inputs = inputs.to(device)\n        classes = classes.to(device)\n        inputs = inputs.view(inputs.size(0), -1) \n        outputs = model(inputs)\n        loss = criterion(outputs, classes)\n        _, preds = torch.max(outputs.data, 1)\n        # statistics\n        running_loss += loss.data.item()\n        running_corrects += torch.sum(preds == classes.data)\n        #print(i)\n        predictions[i:i+len(classes)] = preds.to('cpu').numpy()\n        all_classes[i : i + len(classes)] = classes.to('cpu').numpy()\n        all_proba[i : i + len(classes),:] = outputs.data.to('cpu').numpy()\n        #print(preds.cpu())\n        i += len(classes)\n    epoch_loss = running_loss \/ size\n    epoch_acc = running_corrects.data.item() \/ size\n    print('Loss {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n    return predictions , all_proba, all_classes\n        ","7913eb60":"predictions, all_proba, all_classes = test_model(model_vgg.classifier,size=dset_sizes['valid'])","82f70f17":"n_view = 8","029cf5b0":"correct = np.where(predictions == all_classes)[0]\ncorrect","99c93b32":"len(correct) \/ dset_sizes['valid']","5e604ba0":"from numpy.random import random, permutation\nidx = permutation(correct)[:n_view]","80f0c251":"idx","5fbb5fe5":"loader_correct = torch.utils.data.DataLoader([dsets['valid'][x] for x\n                                             in idx], batch_size = n_view, shuffle=True)","7750c9bf":"for data in loader_correct:\n    inputs_cor, labels_cor = data","283ecfea":"out = torchvision.utils.make_grid(inputs_cor)\nimshow(out, title=[l.item() for l in labels_cor])","97ef71bf":"from IPython.display import Image, display\nfor x in idx:\n    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))","eedcb1ce":"incorrect = np.where(predictions!=all_classes)[0]\nfor x in permutation(incorrect)[:n_view]:\n    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))","13b2a87a":"correct_cats = np.where((predictions == 0) & (predictions == all_classes))[0]\nmost_correct_cats = np.argsort(all_proba[correct_cats, 0])[:n_view]","58ca404b":"for x in most_correct_cats:\n    display(Image(filename=dsets['valid'].imgs[correct_cats[x]][0], retina=True))","8b604361":"#3. The images we most confident were dogs, and are actually dogs\ncorrect_dogs = np.where((predictions==1) & (predictions==all_classes))[0]\nmost_correct_dogs = np.argsort(all_proba[correct_dogs,0])[:n_view]","9751a9f6":"for x in most_correct_dogs:\n    display(Image(filename=dsets['valid'].imgs[correct_dogs[x]][0], retina=True))","b823887c":"### Viewing model prediction","532b565b":"### Training fully connected module","ebba2e6a":"## Imports","dd503e5f":"### Speeding up the learning by precomputing features","a4a1cf39":"#### training the model","35cd1cda":"`LogSoftmax`:\n        $$LogSoftmax(x_i) = log(\\frac{exp(x_i)}{\\sum_jexp(x_j)})$$","c38b2448":"### Modifying the last layer and setting the gradient false to all layers","f47d6a06":"#### Creating loss function and optimizer","7e8ecae4":"### Creating a new data generator","b9af213f":"### Creating VGG Model","fffc511d":"## data processing"}}