{"cell_type":{"cadf5924":"code","798a46a1":"code","9bad6b39":"code","a4a87f7b":"code","7a9ac158":"code","886f14ff":"code","af6c4d45":"code","c3fbe5fc":"code","4f702cd8":"code","f22a94c5":"code","19526953":"code","dc2dbd6a":"code","de309390":"code","5319e4b7":"code","be9d0f32":"code","7effeb33":"code","d0abb97f":"code","e108e0b6":"code","d22d4632":"code","8a6324bd":"code","938cdbd6":"code","4a898061":"code","7ed50163":"code","e9ef8de9":"markdown","e9365196":"markdown","c9f9bbf7":"markdown","df550bf8":"markdown","53d5b429":"markdown","389eed22":"markdown","f4095ae3":"markdown","57705f71":"markdown","f9ffd826":"markdown","76b88eee":"markdown","f1899c4b":"markdown","638e47f5":"markdown","6a0424b2":"markdown","d56edca7":"markdown","5c346c7e":"markdown","633c5f28":"markdown","381bc8b3":"markdown","4cac0fe6":"markdown","c545fb0b":"markdown","65cd8b79":"markdown","d7cd351d":"markdown","b045f47b":"markdown","2bcb21af":"markdown"},"source":{"cadf5924":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport re\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly\nplotly.offline.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\n\nimport plotly.figure_factory as ff\nimport cufflinks as cf\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")\nplt.style.use('seaborn')","798a46a1":"dataset = pd.read_csv('..\/input\/google-play-store-apps\/googleplaystore.csv')\nreview = pd.read_csv('..\/input\/google-play-store-apps\/googleplaystore_user_reviews.csv')\n\ndisplay(dataset.sample(5))","9bad6b39":"# Removing duplicates\ndataset.drop_duplicates(subset='App', inplace=True)\n\n# Converting size in KB into MB\ndef convert_mb(x):\n    if 'k' in x:\n        x = x.replace('k','')\n        return float(x)\/1028\n    elif 'M' in x:\n        return x.replace('M','')\n    else:\n        return np.NAN\n        \ndataset['Size'] = dataset['Size'].apply(convert_mb)\n\n\n# Removing chars from Installs\ndataset['Installs'] = dataset['Installs'].apply(lambda x: x.replace('+',''))\ndataset['Installs'] = dataset['Installs'].apply(lambda x: x.replace(',',''))\n\n# Replcaing data containing non-numeric values with null\ndataset['Installs'] = dataset['Installs'].apply(lambda x: np.NaN if re.search('[^0-9]+', x) else x)\n\n# Removing dollar from Price\ndataset['Price'] = dataset['Price'].apply(lambda x: x.replace('$',''))\n\n\n# Removing all the null values\ndataset.dropna(inplace=True)\n\n# Converting above processed column to numeric\ndataset['Rating'] = dataset['Rating'].astype('float64')\ndataset['Size'] = dataset['Size'].astype('float64')\ndataset['Price'] = dataset['Price'].astype('float64')\ndataset['Reviews'] = dataset['Reviews'].astype('int64')\ndataset['Installs'] = dataset['Installs'].astype('int64')","a4a87f7b":"review.sample(5)","7a9ac158":"# Merging the two datasets\n\nmerged_df = pd.merge(review,dataset, on='App',how='inner')\nmerged_df.dropna(subset=['Sentiment', 'Translated_Review'], inplace=True)\n\n\n\n# Creating a dataframe based on count of postivie,negative,neutral sentiments\n\ngroups = merged_df.groupby(['Category','Sentiment']).agg({'App':'count'}).reset_index()\npx.bar(data_frame=groups.sort_values(by='App', ascending=False),x='Category',y='App', color='Sentiment')","886f14ff":"positive_df = groups.query('Sentiment == \"Positive\"')\nnegative_df = groups.query('Sentiment == \"Negative\"')\n\nmerged_pos_neg = pd.merge(positive_df, negative_df, on='Category',how='left')\n\nmerged_pos_neg.fillna(1, inplace=True)\np = merged_pos_neg['App_x']\nn = merged_pos_neg['App_y']\nmerged_pos_neg['Ratio'] = p\/n\n\npx.bar(data_frame=merged_pos_neg.sort_values(by='Ratio'), x='Category', y='Ratio')","af6c4d45":"# Let's analyze the no.of installs and ratio of reviews per install\n\ngroups = merged_df.groupby(['Category']).agg({'Installs':'sum','Translated_Review':'count'}).reset_index().sort_values(by='Installs', ascending=False)\n\n# Calculate the ratio\ninstall_data = groups['Installs']\nreview_data = groups['Translated_Review']\n\ngroups['Ratio'] = review_data\/install_data\n\n# plot no.of installs\npx.bar(data_frame=groups,x='Category',y='Installs')","c3fbe5fc":"# plot ratio of review per install\npx.bar(data_frame=groups,x='Category',y='Ratio')","4f702cd8":"#Segregate +ve and -ve Reviews\ntrans_pos_review = merged_df.query('Sentiment == \"Positive\"')['Translated_Review']\ntrans_neg_review = merged_df.query('Sentiment == \"Negative\"')['Translated_Review']","f22a94c5":"import spacy\nnlp = spacy.load('en_core_web_sm')\n\n#Lemmatization of the words which are Adjective\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\ndef preprocess_text(text):\n    doc = nlp(text, disable=['ner','parser'])\n    lemmas = [token.lemma_ for token in doc if token.pos_ == 'ADJ']\n    a_lemmas = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stop_words]\n    return ' '.join(a_lemmas)\n\ntrans_neg_review = trans_neg_review.apply(preprocess_text)\ntrans_pos_review = trans_pos_review.apply(preprocess_text)","19526953":"# Negative\nneg_list = []\nfor i in trans_neg_review:\n    neg_list.append(i.split(' '))\n\nneg_list = sum(neg_list, [])\n\nwhile '' in neg_list:\n    neg_list.remove('')\n    \n\n# Positive    \npos_list = []\nfor i in trans_pos_review:\n    pos_list.append(i.split(' '))\n\npos_list = sum(pos_list, [])\n\nwhile '' in pos_list:\n    pos_list.remove('')\n    \n\ndisplay(neg_list[:7])\ndisplay(pos_list[:7])","dc2dbd6a":"from wordcloud import WordCloud\nwc = WordCloud(background_color=\"white\", max_words=200, colormap=\"Set2\")\n\nwc.generate(' '.join(neg_list))\nplt.figure(figsize=(10, 10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","de309390":"wc.generate(' '.join(pos_list))\nplt.figure(figsize=(10, 10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","5319e4b7":"categories = dataset['Category'].value_counts().sort_values(ascending=True)\n\ndata = [go.Pie(\n        labels = categories.index,\n        values = categories.values,\n        hoverinfo = 'label+value'\n    \n)]\n\nplotly.offline.iplot(data, filename='category')","be9d0f32":"data = [go.Histogram(\n        x = dataset['Rating'],\n        xbins = {'start': 1, 'size': 0.1, 'end' :5}\n)]\n\nprint('Average app rating = ', np.mean(dataset['Rating']))\nplotly.offline.iplot(data, filename='overall_rating_distribution')","7effeb33":"import scipy.stats as stats\nf = stats.f_oneway(dataset.loc[dataset.Category == 'BUSINESS']['Rating'], \n               dataset[dataset.Category == 'FAMILY']['Rating'],\n               dataset[dataset.Category == 'GAME']['Rating'],\n               dataset[dataset.Category == 'PERSONALIZATION']['Rating'],\n               dataset[dataset.Category == 'LIFESTYLE']['Rating'],\n               dataset[dataset.Category == 'FINANCE']['Rating'],\n               dataset[dataset.Category == 'EDUCATION']['Rating'],\n               dataset[dataset.Category == 'MEDICAL']['Rating'],\n               dataset[dataset.Category == 'TOOLS']['Rating'],\n               dataset[dataset.Category == 'PRODUCTIVITY']['Rating'],\n               dataset[dataset.Category == 'PHOTOGRAPHY']['Rating']\n              )\n\nprint(f)\nprint('\\nThe p-value is extremely small, hence we reject the null hypothesis in favor of the alternate hypothesis.\\n')\n\n\n\ngroups = dataset.groupby('Category').filter(lambda x: len(x) > 200).reset_index()\narray = groups['Rating'].hist(by=groups['Category'], sharex=True, figsize=(20,20))","d0abb97f":"groups = dataset.groupby('Category').filter(lambda x: len(x) >= 120).reset_index()\n\nprint('Average rating = ', np.nanmean(list(groups.Rating)))\n\nlayout = {'title' : 'App ratings across major categories',\n        'xaxis': {'tickangle':-40},\n        'yaxis': {'title': 'Rating'},\n          'plot_bgcolor': 'rgb(250,250,250)',\n          'shapes': [{\n              'type' :'line',\n              'x0': -.5,\n              'y0': np.nanmean(list(groups.Rating)),\n              'x1': 19,\n              'y1': np.nanmean(list(groups.Rating)),\n              'line': { 'dash': 'dashdot'}\n          }]\n          }\n\ndata = [{\n    'y': dataset[dataset.Category==category]['Rating'], \n    'type':'violin',\n    'name' : category,\n    'showlegend':False,\n    #'marker': {'color': 'Set2'},\n    } for i,category in enumerate(list(set(groups.Category)))]\n\n\n\nplotly.offline.iplot({'data': data, 'layout': layout})","e108e0b6":"groups = dataset.groupby('Category').filter(lambda x: len(x) >= 20).reset_index()\n\nsns.set_style(\"darkgrid\")\nax = sns.jointplot(groups['Size'], groups['Rating'])","d22d4632":"groups = dataset.groupby(['Category']).filter(lambda x: len(x) > 250).reset_index()\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15, 8)\np = sns.stripplot(data=groups, x='Price', y='Category')\ntitle = ax.set_title('Price based on Category')","8a6324bd":"groups = dataset.groupby(['Category']).filter(lambda x: len(x) > 250).reset_index().query('Price > 300').sort_values(by='Installs', ascending=False)\n\ngroups[['App','Category','Price','Installs']]","938cdbd6":"data = dataset.groupby(['Type'])['Installs'].agg(sum).reset_index()\ndisplay(data)\nplt.bar(data=data, x='Type', height='Installs')\n","4a898061":"#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(10, 15))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':0.5 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':15 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=30)\n\ncorrelation_heatmap(dataset[['Installs','Rating','Price','Size','Reviews']])","7ed50163":"sns.lmplot(data=dataset,x='Reviews',y='Installs')","e9ef8de9":"Correlation between features","e9365196":"Apps per Category","c9f9bbf7":"#### Impact of size on Rating - Small vs Large apps","df550bf8":"# One-way Anova Test - App ratings accross categories\n\n    f = (between group variation) \/ (Within group variation)\nNull hypothesis = Mean of ratings for categories is same","53d5b429":"                                                Creating Wordcloud of Negative reviews","389eed22":"The average app ratings across categories is significantly different.","f4095ae3":"Creating list of negative and positive adjectives","57705f71":"App Reviews","f9ffd826":"                                                Creating Wordcloud of Positive reviews","76b88eee":"#### Trend of app prices for famous categories","f1899c4b":"It seems the apps belonging to gaming,family,news,sports have received a lot of written negative reviews","638e47f5":"Paid vs Free apps installation","6a0424b2":"Apps belonging to categories Health & fitness, Personalization, Books & Reference have better ratings\n\nDating apps don't seem to perform that good as compared to others\n\nMore than 50% of apps in Health & Fitness having rating more than 4.5","d56edca7":"#### Ration of Positive to negative reviews","5c346c7e":"#### Cleaning and Feature engineering","633c5f28":"Gaming apps have received a lot of written reviews and also the ratio of positive to negative reviews is also less as compared to other apps","381bc8b3":"Play store Apps","4cac0fe6":"Pick out those adjectives","c545fb0b":"Let's check the apps which are charging more than 300 dollars","65cd8b79":"A positive correaltion 0.6 exists between number of installs and reviews","d7cd351d":"#### Reading file and Data info","b045f47b":"App ratings","2bcb21af":"Let's have a look at those good and bad reviews"}}