{"cell_type":{"5e37f189":"code","a416b417":"code","af3ab42b":"code","3ce74455":"code","603a2b82":"code","d11d71c3":"code","3eae55ea":"code","82d99b1e":"code","b6e6f042":"code","bc2ab2b6":"code","586cd7fb":"code","559c5fab":"code","41e66b58":"code","254ffb4c":"code","a5947859":"code","9753077d":"code","f1aabfe0":"code","668fa226":"code","3e172217":"code","588bdba5":"code","f8ea739d":"code","9cb34ff1":"code","e0b3ccf8":"code","6df53997":"code","f6643605":"code","3b744c1f":"code","f651353f":"code","de7885c1":"code","d3620487":"code","8b23f32f":"code","47e792e4":"code","21f6978e":"code","c5c248b6":"code","837cb873":"code","8a61cd21":"markdown","191ac3e8":"markdown","5c2f599b":"markdown"},"source":{"5e37f189":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a416b417":"import requests\nfrom bs4 import BeautifulSoup# Buat request ke website\nr = requests.get('https:\/\/www.kompas.com\/')\nsoup = BeautifulSoup(r.content, 'html.parser')# Buat object untuk parse((mengurai) format HTML \nlink = []\n# Ambil semua tautan berita yang menarik\nfor i in soup.find('div', {'class':'most__wrap'}).find_all('a'): \n    \n    i['href'] = i['href'] + '?page=all'\n    link.append(i['href'])\n    #dari tiap tautan ambil paragraph, kombinasikan tiap paragraph\n    #simpan ke dalam larik documents\n    \ndocuments = []\nfor i in link:\n    # Buat request ke tautan\n    r = requests.get(i)\n    # Initialize BeautifulSoup object untuk parse\/mengurai isi \n    soup = BeautifulSoup(r.content, 'html.parser')\n    # ambil semua paragraph dan masukkan ke dalam larik sen\n    sen = []\n    for i in soup.find('div', {'class':'read__content'}).find_all('p'):\n        sen.append(i.text)\n    # tabahkan semua paragraph yang sudah digabungkan ke dalam larik documents\n    documents.append(' '.join(sen))","af3ab42b":"for d in documents:\n    print(d)","3ce74455":"import re\nimport string\ndocuments_clean = []\nfor d in documents:\n    # Remove Unicode\n    document_test = re.sub(r'[^\\x00-\\x7F]+', ' ', d)\n    # Remove Mentions\n    document_test = re.sub(r'@\\w+', '', document_test)\n    # Lowercase the document\n    document_test = document_test.lower()\n    # Remove punctuations\n    document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)\n    # Lowercase the numbers\n    document_test = re.sub(r'[0-9]', '', document_test)\n    # Remove the doubled space\n    document_test = re.sub(r'\\s{2,}', ' ', document_test)\n    documents_clean.append(document_test)","603a2b82":"documents_clean[0:5]","d11d71c3":"!pip install Sastrawi","3eae55ea":"# import StemmerFactory class\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory# create stemmer\nfactory = StemmerFactory()\nstemmer = factory.create_stemmer()# stemming process\nsentence = 'Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan'\noutput   = stemmer.stem(sentence)\nprint(output)","82d99b1e":"from Sastrawi.Stemmer.StemmerFactory import StemmerFactory# create stemmer\nfactory = StemmerFactory()\nstemmer = factory.create_stemmer()# stemming process\n# import StopWordRemoverFactory class\nfrom Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\nfactory = StopWordRemoverFactory()\nstopword = factory.create_stop_word_remover()\ndocuments_clean=[]\n\nfor d in documents:\n    outputstem= stemmer.stem(d)\n    d= stopword.remove(outputstem)\n    # Remove Unicode\n    document_test = re.sub(r'[^\\x00-\\x7F]+', ' ', d)\n    # Remove Mentions\n    document_test = re.sub(r'@\\w+', '', document_test)\n    # Lowercase the document\n    document_test = document_test.lower()\n    # Remove punctuations\n    document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)\n    # Lowercase the numbers\n    document_test = re.sub(r'[0-9]', '', document_test)\n    # Remove the doubled space\n    outputstop = re.sub(r'\\s{2,}', ' ', document_test)\n    documents_clean.append(outputstop)","b6e6f042":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\ntfidfvectorizer = TfidfVectorizer(analyzer='word')\ntfidf_wm = tfidfvectorizer.fit_transform(documents_clean)\ntfidf_tokens = tfidfvectorizer.get_feature_names()","bc2ab2b6":"print(tfidf_wm[0])","586cd7fb":"print(tfidf_tokens[0])","559c5fab":"print(documents_clean[0])","41e66b58":"documents_clean","254ffb4c":"# wordcloud\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = 'lightcyan',\n                      width = 1200,\n                      height = 700).generate(str(documents_clean))\n\nplt.figure(figsize = (15, 10))\nplt.imshow(wordcloud)\nplt.title(\"WordCloud \", fontsize = 20)","a5947859":"from sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np # linear algebra\ncv = CountVectorizer()\nwords = cv.fit_transform(documents_clean)\nsum_words = words.sum(axis=0)\n\n\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\nfrequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n\ncolor = plt.cm.twilight(np.linspace(0, 1, 20))\nfrequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 7), color = color)\nplt.title(\"Most Frequently Occuring Words - Top 20\")","9753077d":"print(\"Shape of X :\", words.shape)","f1aabfe0":"import matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Instantiate a TfidfVectorizer object\nvectorizer = TfidfVectorizer()# It fits the data and transform it as a vector\nX = vectorizer.fit_transform(documents_clean)# Convert the X as transposed matrix\nX = X.T.toarray()# Create a DataFrame and set the vocabulary as the index\ndf = pd.DataFrame(X, index=vectorizer.get_feature_names())\nfrom sklearn.cluster import KMeans\nSum_of_squared_distances = []\nK = range(2,10)\nfor k in K:\n   km = KMeans(n_clusters=k, max_iter=200, n_init=10)\n   km = km.fit(X)\n   Sum_of_squared_distances.append(km.inertia_)\nplt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","668fa226":"true_k = 3\nmodel = KMeans(n_clusters=true_k, init='k-means++', max_iter=200, n_init=10)\nmodel.fit(X)\nlabels=model.labels_","3e172217":"print(labels)","588bdba5":"number=[0,1,2,3,4,5,6,7,8,9]","f8ea739d":"wiki_cl=pd.DataFrame(list(zip(number,labels)),columns=['title','cluster'])\nprint(wiki_cl.sort_values(by=['cluster']))","9cb34ff1":"from sklearn.cluster import KMeans\ntrue_k = 6\nmodel = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\nmodel.fit(words)","e0b3ccf8":"order_centroids = model.cluster_centers_.argsort()[:, ::-1]\nterms = cv.get_feature_names()\n\nfor i in range(true_k):\n    print(\"Cluster %d:\" % i),\n    for ind in order_centroids[i, :10]:\n        print(' %s' % terms[ind]),\n    print\n\nprint(\"\\n\")\nprint(\"Prediction\")\nY = cv.transform([\"piala dunia\"])\nprediction = model.predict(Y)\nprint(\"Cluster number :\", prediction)\nY = cv.transform([\"ronaldo\"])\nprediction = model.predict(Y)\nprint(\"Cluster number :\", prediction)","6df53997":"X = vectorizer.fit_transform(documents_clean)","f6643605":"X = vectorizer.fit_transform(documents_clean).todense()","3b744c1f":"import scipy.cluster.hierarchy as sch\nX = vectorizer.fit_transform(documents_clean).todense()\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward',metric='euclidean'),orientation=\"top\")\nplt.title('Dendrogram')\nplt.xlabel('Jarak Ward')\nplt.ylabel('Nomor Dokumen')\nplt.show()","f651353f":"from sklearn.cluster import AgglomerativeClustering\n\ncluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')  \ncluster.fit_predict(X) \nprint(cluster.labels_)","de7885c1":"# Menjalankan Hierarchical Clustering ke dataset\nfrom sklearn.cluster import AgglomerativeClustering\nimport matplotlib.pyplot as plt\nhc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n\ny_hc = hc.fit_predict(X)\n# hc.fit_predict(X)\n# plt.scatter([X[:,0]],[X[:,1]], c=hc.labels_, cmap='rainbow')\n \n# Visualisasi hasil clusters\nplt.scatter([X[:,0]],[X[:,0]], s = 100, c = 'red', label = 'Cluster 1')\n\nplt.scatter([X[:,1]],[X[:,1]], s = 100, c = 'blue', label = 'Cluster 2')\n\nplt.title('Clusters pelanggan')\nplt.xlabel('Pendapatan tahunan (juta Rupiah)')\nplt.ylabel('Rating pengeluaran (1-100)')\nplt.legend()\nplt.show()","d3620487":"import scipy.cluster.hierarchy as sch\nX = vectorizer.fit_transform(documents_clean).todense()\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'single',metric='euclidean'),orientation=\"right\")\nplt.title('Dendrogram')\nplt.xlabel('Jarak Single')\nplt.ylabel('Nomor Dokumen')\nplt.show()","8b23f32f":"import scipy.cluster.hierarchy as sch\nX = vectorizer.fit_transform(documents_clean).todense()\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'complete',metric='euclidean'),orientation=\"right\")\nplt.title('Dendrogram')\nplt.xlabel('Jarak Complete')\nplt.ylabel('Nomor Dokumen')\nplt.show()","47e792e4":"import scipy.cluster.hierarchy as sch\nX = vectorizer.fit_transform(documents_clean).todense()\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'average',metric='euclidean'),orientation=\"right\")\nplt.title('Dendrogram')\nplt.xlabel('Jarak Rerata')\nplt.ylabel('Nomor Dokumen')\nplt.show()","21f6978e":"from sklearn.cluster import AgglomerativeClustering\n\ncluster = AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward')  \ncluster.fit_predict(X) \nprint(cluster.labels_)","c5c248b6":"from scipy.cluster.hierarchy import dendrogram, linkage\nfrom matplotlib import pyplot as plt\n\nlinked = linkage(X, 'single')\n\nlabelList = range(0, 10)\n\nplt.figure(figsize=(10, 7))\ndendrogram(linked,\n            orientation='top',\n            labels=labelList,\n            distance_sort='descending',\n            show_leaf_counts=True)\nplt.show()","837cb873":"from scipy.cluster.hierarchy import dendrogram, linkage\nfrom matplotlib import pyplot as plt\n\nlinked = linkage(X, 'average')\n\nlabelList = range(0, 10)\n\nplt.figure(figsize=(10, 7))\ndendrogram(linked,\n            orientation='top',\n            labels=labelList,\n            distance_sort='descending',\n            show_leaf_counts=True)\nplt.show()","8a61cd21":"3. PERINTAH CLUSTERING ALGORITMA HIRARKI","191ac3e8":"2. PERINTAH CLUSTERING ALGORITMA K-MEANS","5c2f599b":"1. PERINTAH UNTUK SCRAPPING HALAMAN KOMPAS.COM"}}