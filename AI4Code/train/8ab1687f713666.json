{"cell_type":{"a2d42e96":"code","8383eb33":"code","fb57c1d6":"code","cb655174":"code","527c4d9b":"code","8502d39b":"code","8c0b5052":"code","36a61aea":"code","426b9d24":"code","683f3ca5":"code","d6fd4207":"code","55f45eff":"code","d8662ff4":"code","8dbe9a4b":"code","3962396e":"code","decef6d9":"code","7fec8cf3":"code","6832a1b4":"code","48e3fdbd":"code","6ffb831a":"code","5c29573a":"code","8e89ada1":"code","5ca69386":"code","6c89f03e":"code","5f1558da":"code","587da1aa":"code","e4a4ff41":"code","f60c9a76":"code","6b5c04ab":"code","5ccbf7e7":"code","b92ee3a2":"code","2d42cb55":"code","98888b4d":"code","ab09f323":"code","a9faa9a6":"code","1addb682":"code","86aa1d52":"code","a28b167e":"code","83a0cc63":"code","0ca112fa":"code","63a6eb9c":"markdown","10b9d223":"markdown","e1dbc103":"markdown","ee73e135":"markdown","7d6aed58":"markdown","c0722e8d":"markdown","a94ec13e":"markdown","d417d255":"markdown","f5e53fd9":"markdown","f3a166a8":"markdown","636a3e08":"markdown","b485e861":"markdown","cd1e76bc":"markdown","c31404bf":"markdown","80284c44":"markdown","26418f8e":"markdown","d831c549":"markdown","ae3f4235":"markdown"},"source":{"a2d42e96":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","8383eb33":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith(\".csv\"):\n            print(os.path.join(dirname, filename))","fb57c1d6":"base_path=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\"\nsubmission_file=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\/submit.csv\"\ntest_path=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\/test.csv\"\ntrain_path=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\/train.csv\"","cb655174":"train_data=pd.read_csv(train_path)\ntest_data=pd.read_csv(test_path)","527c4d9b":"train_data.head()","8502d39b":"test_data.head()","8c0b5052":"submission=pd.read_csv(submission_file)","36a61aea":"submission.head()","426b9d24":"trainX,evalX,trainY,evalY = train_test_split(train_data.iloc[:,0].values,\n                                             train_data.iloc[:,1].values,\n                                             random_state=11,\n                                             test_size=0.2\n                                            )","683f3ca5":"testX = test_data.iloc[:,0].values","d6fd4207":"num_train_images = len(trainX)\nnum_eval_images=len(evalX)","55f45eff":"print(\"Number of train images: \",num_train_images)\nprint(\"Number of eval images: \",num_eval_images)\nprint(\"Number of test images: \",len(testX))","d8662ff4":"EPOCHS=5\nBATCH_SIZE=32\nIMAGE_DIM=(256,256)","8dbe9a4b":"def get_path_of_image(image_id):\n    return os.path.join(base_path,f\"{image_id}.png\")","3962396e":"def check_and_remove_defected_images(ids,labels):\n    defected = []\n    for i,img_id in enumerate(ids):\n        try:\n            image = tf.io.read_file(get_path_of_image(img_id))\n            image = tf.image.decode_png(image,channels=3)\n        except:\n            defected.append(img_id)\n            ids = np.delete(ids,i)\n            labels = np.delete(labels,i)\n    return defected,ids,labels","decef6d9":"def load_tf_image(image_path,dim):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image,channels=3)\n    image = tf.image.resize(image,dim)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = image\/255.0\n    return image","7fec8cf3":"def generate_tf_dataset(X,Y,image_size):\n    X = [get_path_of_image(str(x)) for x in X]\n    datasetX = tf.data.Dataset.from_tensor_slices(X).map(\n            lambda path: load_tf_image(path,image_size),\n            num_parallel_calls=tf.data.experimental.AUTOTUNE\n    )\n    datasetY = tf.data.Dataset.from_tensor_slices(Y)\n    dataset = tf.data.Dataset.zip((datasetX,datasetY))\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    return dataset","6832a1b4":"def plot_images_grid(data,num_rows=1,labels=None,class_names=None):\n    images, labels = data\n    n=len(images)\n    if n > 1:\n        num_cols=np.ceil(n\/num_rows)\n        fig,axes=plt.subplots(ncols=int(num_cols),nrows=int(num_rows))\n        axes=axes.flatten()\n        fig.set_size_inches((15,15))\n        for i,image in enumerate(images):\n            axes[i].imshow(image.numpy())\n            label = labels[i].numpy()\n            axes[i].set_title(class_names[label])","48e3fdbd":"defected,trainX,trainY = check_and_remove_defected_images(trainX,trainY)\nprint(\"Train Elements Defected: \",defected)","6ffb831a":"defected,trainX,trainY = check_and_remove_defected_images(evalX,evalY)\nprint(\"Eval Elements Defected: \",defected)","5c29573a":"train_dataset=generate_tf_dataset(trainX,trainY,IMAGE_DIM)\nprint(train_dataset.element_spec)","8e89ada1":"eval_dataset=generate_tf_dataset(evalX,evalY,IMAGE_DIM)\nprint(eval_dataset.element_spec)","5ca69386":"class_names=[\"not stable\",\"stable\"]","6c89f03e":"plot_images_grid(next(iter(train_dataset.take(1))),class_names=class_names,num_rows=4)","5f1558da":"plot_images_grid(next(iter(eval_dataset.take(1))),class_names=class_names,num_rows=4)","587da1aa":"densenet= tf.keras.applications.DenseNet121(\n                include_top=False, weights='imagenet',input_shape=(*IMAGE_DIM,3)\n            )\ndensenet.summary()","e4a4ff41":"densenet.trainable = False","f60c9a76":"model = tf.keras.Sequential([\n    densenet,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(256,activation=\"relu\"),\n    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n])","6b5c04ab":"model.summary()","5ccbf7e7":"model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])","b92ee3a2":"checkpoint_path=\"best_checkpoint\"","2d42cb55":"model_checkpoint=tf.keras.callbacks.ModelCheckpoint(checkpoint_path,monitor=\"val_accuracy\",\n                                                    save_best_only=True,mode=\"max\",\n                                                    save_weights_only=True,\n                                                    verbose=1)\nearly_stop=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=10,\n                                            mode=\"max\")\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',mode=\"max\",\n                                                 factor=0.2,patience=5, \n                                                 min_lr=0.001)","98888b4d":"callbacks=[model_checkpoint,early_stop,reduce_lr]","ab09f323":"history=model.fit(train_dataset,\n                  epochs=EPOCHS,\n                  steps_per_epoch=num_train_images\/\/BATCH_SIZE,\n                  validation_data=eval_dataset,\n                  validation_steps=num_eval_images\/\/BATCH_SIZE,\n                  callbacks=callbacks)","a9faa9a6":"if os.path.isfile(checkpoint_path):\n    model.load_weights(checkpoint_path)","1addb682":"test_images_path = [get_path_of_image(str(x)) for x in testX]\ntest_dataset = tf.data.Dataset.from_tensor_slices(test_images_path).map(\n        lambda path: load_tf_image(path,IMAGE_DIM),\n        num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\ntest_dataset=test_dataset.batch(BATCH_SIZE)\ntest_dataset=test_dataset.prefetch(tf.data.experimental.AUTOTUNE)","86aa1d52":"predictions = model.predict(test_dataset,verbose=1)","a28b167e":"predictions= np.squeeze(predictions,axis=1)","83a0cc63":"predictions.shape","0ca112fa":"submission.stable = predictions\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","63a6eb9c":"## Predicting Stable Structures\n\nThis is starter notebook for tensorflow users for this competition. It uses tf.data for loading data for training and model is trained using transfer learning.","10b9d223":"## Training Model\n\nIt uses densenet121 pretrained model on imagenet, chop off its last classification layers (Dense Layers) and finetune it.","e1dbc103":"## Setting up train and eval tf dataset\n\nCreate tf datasets using tf.data for training and validation. A single element of these datasets return *(Image,Label)* where Image = *(batch_size,image_width,image_height,channels)* and Label = *(batch_size,)*. ","ee73e135":"Reading CSV files and viewing their heads","7d6aed58":"model training happens here with fit method. It takes tf datasets and steps.","c0722e8d":"predicting test data using test dataset and saving results in`predictions`","a94ec13e":"Loading best model checkpoint","d417d255":"## Helper Functions\n\n- get_path_of_image : for getting path to image from its id\n- check_and_remove_defected_images : check and remove any corrupted image\n- load_tf_image : loading and normalizing image and converting to tensor\n- generate_tf_dataset : generate tf dataset","f5e53fd9":"Getting Path to csv files:\n\n- train.csv\n- test.csv \n- submission.csv","f3a166a8":"Setting Parameters here","636a3e08":"Making densenet model to not train","b485e861":"Saving predictions is submission.csv file.","cd1e76bc":"check and remove any corrupted png files from dataset","c31404bf":"## Predicting test data\n\nTest dataset is created which return *(batch_size,Image Tensor)* as single element.","80284c44":"Callbacks for:\n- model_checkpointing- For checpointing model with best validation accuracy.\n- early_stop- Stop training of model if model's validation accuracy did not improved in last 10 steps\n- reduce_lr- reduce learning rate if validation accuracy did not improved in last 5 steps.","26418f8e":"## Plotting and Visualizing images","d831c549":"Importing required dependencies","ae3f4235":"Splitting data into training and evaluation"}}