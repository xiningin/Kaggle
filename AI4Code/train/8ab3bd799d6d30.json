{"cell_type":{"d20feb30":"code","06d30fb0":"code","e3f95521":"code","20b0b1c2":"code","66a4d1a9":"code","7cc041e2":"code","0a8a006f":"code","89bb0516":"code","eee7f78d":"code","18b6798e":"code","5a3ff11a":"code","e0ad4a77":"code","7b93da4e":"code","a3c3145c":"code","eb8e9dbc":"code","c2a7e74b":"code","667170db":"code","14edc535":"markdown","47e1588a":"markdown","35a01f0a":"markdown","64927574":"markdown","fed64d73":"markdown","2dd9148b":"markdown","3157c35c":"markdown","ae2f44c7":"markdown","2615f163":"markdown"},"source":{"d20feb30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06d30fb0":"df=pd.read_csv(\"\/kaggle\/input\/spam-text-message-classification\/SPAM text message 20170820 - Data.csv\")\ndf.head()","e3f95521":"df.shape","20b0b1c2":"import nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer","66a4d1a9":"stemmer=PorterStemmer()\nlemmatizer=WordNetLemmatizer()","7cc041e2":"corpus=[]\nfor i in range(len(df)): \n    #Replacing all values other than alphabets in the df with a space\n    review=re.sub(\"[^a-zA-Z]\",\" \",df[\"Message\"][i])\n    #Converting the text into lowercase \n    review=review.lower()\n    #Converting review into a list \n    review=review.split()\n    #Lemmatizing the word in the review other than stopwords\n    review=[lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words(\"english\"))]\n    #Joining the list values to get review back\n    review=\" \".join(review)\n    #Appending in corpus list\n    corpus.append(review)","0a8a006f":"corpus","89bb0516":"from sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer()\nX=cv.fit_transform(corpus).toarray()","eee7f78d":"X","18b6798e":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf[\"Category\"]=le.fit_transform(df[\"Category\"])","5a3ff11a":"df.head()","e0ad4a77":"y=df[\"Category\"]","7b93da4e":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","a3c3145c":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(X_train, y_train)","eb8e9dbc":"#Predicting the values\ny_pred=spam_detect_model.predict(X_test)","c2a7e74b":"from sklearn.metrics import confusion_matrix,accuracy_score\ncm=confusion_matrix(y_test,y_pred)\ncm","667170db":"accuracy_score(y_test,y_pred)","14edc535":"# Training the Model using Naive Bayes Classifier","47e1588a":"# Import Libraries","35a01f0a":"# Import Dataset","64927574":"# Creating the Bag of Words Model","fed64d73":"# Encoding the Dependent Variable","2dd9148b":"# Checking Confusion Marix and Accuracy score","3157c35c":"# Splitting the Dataset into Train and Test set","ae2f44c7":"We got an accuracy of 97%, which is pretty impressive","2615f163":"# Cleaning the Text"}}