{"cell_type":{"660b2efe":"code","a03755cd":"code","31cea193":"code","257b98f4":"code","57f8beac":"code","3ee8c12d":"code","84f914ca":"code","d9968c4e":"code","8bb65d85":"code","476bcb98":"code","f0ff2432":"code","8a449e56":"code","8f266816":"code","2d401d0b":"code","90226ec2":"code","e0459e90":"code","f91f2099":"code","1bd4be09":"code","aa505ded":"code","13d98ddd":"code","ac6e3095":"code","3f3bac77":"code","2cce1b77":"code","c24d5bf4":"code","4f352732":"code","392131ef":"code","76173450":"code","23447aed":"code","5c27ba4b":"code","24517529":"code","2b4d3d8d":"markdown","31e6462a":"markdown","58dce1a6":"markdown","c7bf2a80":"markdown","d58f948e":"markdown","92814c1a":"markdown","9f6d94d5":"markdown","049cf2a6":"markdown","c29bf38b":"markdown","4a3228b2":"markdown","89b7b5bd":"markdown"},"source":{"660b2efe":"! pip install -q \/kaggle\/input\/readability\/readability-0.3.1-py3-none-any.whl\n! pip install -q \/kaggle\/input\/syntok\/syntok-1.3.1-py3-none-any.whl\nimport readability\nimport syntok.segmenter as segmenter\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a03755cd":"train_data = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/test.csv')","31cea193":"train_data.info()\ntrain_data.head()","257b98f4":"test_data.info()\ntest_data.head()","57f8beac":"pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/sample_submission.csv')","3ee8c12d":"def tokenize(text):\n    \"\"\"Tokenizing and creating excerpts in the format suggested in the README of readability project.\"\"\"\n    return '\\n\\n'.join(\n        '\\n'.join(\n            ' '.join(token.value for token in sentence)\n            for sentence in paragraph)\n        for paragraph in segmenter.analyze(text))","84f914ca":"train_data.loc[:,'readability_object'] = train_data.apply(lambda row: readability.getmeasures(tokenize(row.excerpt), lang='en'), axis=1)","d9968c4e":"train_data.info()\ntrain_data.head()","8bb65d85":"X = pd.DataFrame(train_data['id'])\nX.loc[:,'readability'] = train_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nX.loc[:,'syll_per_word'] = train_data.apply(lambda row: row.readability_object['sentence info']['syll_per_word'], axis=1)\nX.loc[:,'words_per_sentence'] = train_data.apply(lambda row: row.readability_object['sentence info']['words_per_sentence'], axis=1)\nX.loc[:,'type_token_ratio'] = train_data.apply(lambda row: row.readability_object['sentence info']['type_token_ratio'], axis=1)\nX.loc[:,'syllables'] = train_data.apply(lambda row: row.readability_object['sentence info']['syllables'], axis=1)\nX.loc[:,'words'] = train_data.apply(lambda row: row.readability_object['sentence info']['words'], axis=1)\nX.loc[:,'wordtypes'] = train_data.apply(lambda row: row.readability_object['sentence info']['wordtypes'], axis=1)\nX.loc[:,'sentences'] = train_data.apply(lambda row: row.readability_object['sentence info']['sentences'], axis=1)\nX.loc[:,'complex_words_dc'] = train_data.apply(lambda row: row.readability_object['sentence info']['complex_words_dc'], axis=1)\nX.loc[:,'tobeverb'] = train_data.apply(lambda row: row.readability_object['word usage']['tobeverb'], axis=1)\nX.loc[:,'auxverb'] = train_data.apply(lambda row: row.readability_object['word usage']['auxverb'], axis=1)\nX.loc[:,'conjunction'] = train_data.apply(lambda row: row.readability_object['word usage']['conjunction'], axis=1)\nX.loc[:,'pronoun'] = train_data.apply(lambda row: row.readability_object['word usage']['pronoun'], axis=1)\nX.loc[:,'preposition'] = train_data.apply(lambda row: row.readability_object['word usage']['preposition'], axis=1)\nX.loc[:,'nominalization'] = train_data.apply(lambda row: row.readability_object['word usage']['nominalization'], axis=1)","476bcb98":"X.info()\nX.head()","f0ff2432":"tar_corr = pd.merge(X, train_data['target'], left_index=True, right_index=True).corr().loc['target']\ntar_corr","8a449e56":"to_remove = ['id']\nfor val in tar_corr.index:\n    if tar_corr[val] > -0.1 and tar_corr[val] < 0.1:\n        to_remove.append(val)\n\nto_remove","8f266816":"X = X.drop(to_remove, axis=1)","2d401d0b":"X.info()\nX.head()","90226ec2":"y = train_data['target']","e0459e90":"y.describe()","f91f2099":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)","1bd4be09":"model = SVR()\ncv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=0)\nspace = {'kernel': ['poly', 'rbf', 'sigmoid'],\n         'degree': [1, 2, 3, 4, 5],\n         'C': [1e-2, 0.1, 1]}\nsearch = GridSearchCV(model, space, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\nresult = search.fit(train_X, train_y)","aa505ded":"print(result.best_score_)\nprint(result.best_params_)","13d98ddd":"model = SVR(kernel=result.best_params_['kernel'], degree=result.best_params_['degree'], C=result.best_params_['C'])\n\nmodel.fit(train_X, train_y)","ac6e3095":"train_preds = model.predict(train_X)\nmean_squared_error(train_y, train_preds)","3f3bac77":"val_preds = model.predict(val_X)\nmean_squared_error(val_y, val_preds)","2cce1b77":"test_data.loc[:,'readability_object'] = test_data.apply(lambda row: readability.getmeasures(tokenize(row.excerpt), lang='en'), axis=1)","c24d5bf4":"test_data.info()\ntest_data.head()","4f352732":"X_test = pd.DataFrame(test_data['id'])\nX_test.loc[:,'readability'] = test_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nX_test.loc[:,'syll_per_word'] = test_data.apply(lambda row: row.readability_object['sentence info']['syll_per_word'], axis=1)\nX_test.loc[:,'words_per_sentence'] = test_data.apply(lambda row: row.readability_object['sentence info']['words_per_sentence'], axis=1)\nX_test.loc[:,'type_token_ratio'] = test_data.apply(lambda row: row.readability_object['sentence info']['type_token_ratio'], axis=1)\nX_test.loc[:,'syllables'] = test_data.apply(lambda row: row.readability_object['sentence info']['syllables'], axis=1)\nX_test.loc[:,'words'] = test_data.apply(lambda row: row.readability_object['sentence info']['words'], axis=1)\nX_test.loc[:,'wordtypes'] = test_data.apply(lambda row: row.readability_object['sentence info']['wordtypes'], axis=1)\nX_test.loc[:,'sentences'] = test_data.apply(lambda row: row.readability_object['sentence info']['sentences'], axis=1)\nX_test.loc[:,'complex_words_dc'] = test_data.apply(lambda row: row.readability_object['sentence info']['complex_words_dc'], axis=1)\nX_test.loc[:,'tobeverb'] = test_data.apply(lambda row: row.readability_object['word usage']['tobeverb'], axis=1)\nX_test.loc[:,'auxverb'] = test_data.apply(lambda row: row.readability_object['word usage']['auxverb'], axis=1)\nX_test.loc[:,'conjunction'] = test_data.apply(lambda row: row.readability_object['word usage']['conjunction'], axis=1)\nX_test.loc[:,'pronoun'] = test_data.apply(lambda row: row.readability_object['word usage']['pronoun'], axis=1)\nX_test.loc[:,'preposition'] = test_data.apply(lambda row: row.readability_object['word usage']['preposition'], axis=1)\nX_test.loc[:,'nominalization'] = test_data.apply(lambda row: row.readability_object['word usage']['nominalization'], axis=1)","392131ef":"X_test = X_test.drop(to_remove, axis=1)","76173450":"test_preds = model.predict(X_test)","23447aed":"solution = pd.DataFrame(test_data['id'])\nsolution.loc[:, 'target'] = test_preds","5c27ba4b":"solution.info()","24517529":"solution.to_csv('submission.csv', index=False)","2b4d3d8d":"# Creating Features","31e6462a":"# Functions","58dce1a6":"# Initialization","c7bf2a80":"# Evaluating the result","d58f948e":"I am using the [readability](https:\/\/pypi.org\/project\/readability\/) and [syntok](https:\/\/pypi.org\/project\/syntok\/) to gather features from excerpts.","92814c1a":"In this notebook, I try to solve the [CommonLit Readability Prize](https:\/\/www.kaggle.com\/c\/commonlitreadabilityprize\/overview) competition using [Support Vector Machine](https:\/\/en.wikipedia.org\/wiki\/Support-vector_machine).\n\nI have created a similar model using [Decision Tree](https:\/\/en.wikipedia.org\/wiki\/Decision_tree) and [Random Forest](https:\/\/en.wikipedia.org\/wiki\/Random_forest) which got a score of 0.941 and 0.780 respectively.\n\nThe notebook for the models are:\n - [Decision Tree with score 0.941](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-decision-tree)\n - [Random Forest with score 0.780](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-random-forest)\n\nThis notebook will be similar to the [Random Forest](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-random-forest) one. And will use insights gained from [this notebook](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-data-observations).","9f6d94d5":"I will be using the **SMOGIndex** readability grade as it was found to be best in [this notebook](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-data-observations). Also, I am removing (not creating) some features based on insights gained from the same notebook.","049cf2a6":"Using Grid Search to find the optimal values of hyperparameters.","c29bf38b":"# Training","4a3228b2":"We will remove every feature with correlation value between -0.1 and 0.1.","89b7b5bd":"# Creating features for test set and predicting results"}}