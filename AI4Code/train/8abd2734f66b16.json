{"cell_type":{"964bbe1d":"code","48ec2acb":"code","e1e4708f":"code","ff81fa29":"code","07b8a0dc":"code","739e2ef0":"code","552000ea":"code","84ce2d53":"code","e4ccd645":"code","7d4a8694":"code","94bb95c6":"code","b2d1e768":"code","3e569ca5":"code","5fdbdc92":"code","94e79ba4":"code","f639c302":"code","3f9c78b9":"code","63780b0a":"code","dd7200f7":"code","7e31a02a":"code","3ccb298f":"code","edc76547":"code","b73c02c4":"code","a3b663b6":"code","c5fe2963":"code","dceae787":"code","87300ffb":"code","7c49ef22":"code","784d63b0":"code","e65f45e5":"code","99a2c30f":"code","ed5406d2":"code","8979bc26":"code","80c4a3f7":"code","4609a9d7":"code","f5d65c0d":"code","e408fece":"code","f1197e55":"code","aabf63a1":"code","03b61db8":"code","78907653":"code","bd8b6985":"code","f670c2f4":"code","653b2484":"code","d2b7ea9a":"code","8fe885b4":"code","e284623d":"code","738fdc30":"code","d633d26c":"code","ad86bd48":"code","bd9cb422":"code","b6fc1ea6":"code","833535ed":"code","cb7f1fc1":"code","4f9012b8":"code","90690c6b":"code","47ff414d":"code","74f6fa0c":"code","2c8eaa4f":"code","e401548b":"code","1e9fecac":"code","023bd5cd":"code","ec87a121":"code","3b90750d":"code","8fb5248d":"code","f1c90baf":"code","4c90ff10":"code","c52158a2":"code","a8340044":"code","344a3a09":"code","6d2b6fce":"code","311cadaa":"code","c908e731":"code","0f7c9c07":"code","982db39d":"code","db972ee9":"code","7c89a9ae":"code","6f58a5e5":"code","332bcfb7":"code","b2c4ca2a":"code","55e74644":"code","fb106846":"code","032335e2":"code","2a17fa4d":"code","33dfaee5":"code","06036005":"code","cd81362d":"code","1a9a4f19":"code","e3246c38":"code","879c3888":"code","7e257504":"code","f0aa8f2e":"code","baee1a9a":"code","f60f59e9":"code","2d4fe441":"code","19135e4d":"code","37c0c48a":"code","40b4da64":"code","8e0f08cc":"code","ad314975":"code","83f071a6":"code","acb21746":"code","61a17112":"code","f843a0d1":"markdown","6817ec91":"markdown","f5c908dc":"markdown","8dbb3de1":"markdown","83dfa276":"markdown","9dd1717e":"markdown","d038ed31":"markdown","391dd6c1":"markdown","a6fb03db":"markdown","1edc1b6f":"markdown","f6b71495":"markdown","59bdf6ec":"markdown","4b796bf8":"markdown","2d905262":"markdown","526b2b33":"markdown","dfd2492f":"markdown","91812e1b":"markdown","75f4a038":"markdown","ac3ee799":"markdown","3e4763b9":"markdown","04425638":"markdown","22f7deac":"markdown"},"source":{"964bbe1d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","48ec2acb":"#from pandas_profiling import ProfileReport\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nimport pickle\nimport warnings\nwarnings.simplefilter(\"ignore\")","e1e4708f":"train_data=pd.read_csv('\/kaggle\/input\/math-hackathon-2021\/train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/math-hackathon-2021\/test.csv')\ntrain_c=train_data.copy(deep=True)\ntest_c=test_data.copy(deep=True)","ff81fa29":"# profile = ProfileReport(train_data, title=\"Car Price Prediction EDA\", explorative=True)\n# profile","07b8a0dc":"print(\"shape of train data before dropping duplicates\",train_c.shape)\nprint(\"number of duplicate values in train set is ---->\",len(train_c)-len(train_c.drop_duplicates()))\ntrain_c.drop_duplicates(inplace=True)\ntrain_c.reset_index(inplace=True)\nprint(\"shape of train data after dropping duplicates\",train_c.shape)\ntrain_c.drop('index',axis=1,inplace=True)","739e2ef0":"#train_c.dtypes","552000ea":"#train_c.describe()","84ce2d53":"# fig, ax = plt.subplots(figsize =(10, 7))\n# ax.hist(train_c['Price'])","e4ccd645":"#plt.boxplot(train_c['Price'])","7d4a8694":"print(\"number of categories in manufacturer is\",train_c.Manufacturer.nunique())\nprint(\"number of missing values in manufacturer is\",train_c.Manufacturer.isna().sum())","94bb95c6":"#train_c.Manufacturer.value_counts()[:20].plot(kind='bar')","b2d1e768":"train_c['Manufacturer_processed']=train_c['Manufacturer']\nman_cat={'HYUNDAI':1,'TOYOTA':2,'MERCEDES-BENZ':3,'FORD':4,'CHEVROLET':5,'BMW':6,'HONDA':7,'LEXUS':8,'NISSAN':9,'VOLKSWAGEN':10,'SSANGYONG':11,'KIA':12,'OPEL':13,'MITSUBISHI':14,'SUBARU':15,'AUDI':16,'MAZDA':17,'JEEP':18}\ntrain_c['Manufacturer_processed'].replace(man_cat,inplace=True)\ntrain_c.Manufacturer_processed[~train_c['Manufacturer_processed'].isin(man_cat.values())]=19\ntrain_c['Manufacturer_processed']=pd.to_numeric(train_c['Manufacturer_processed'])","3e569ca5":"#train_c.Manufacturer_processed.value_counts()[:20].plot(kind='bar')","5fdbdc92":"print(\"number of categories in Models is\",train_c.Model.nunique())\nprint(\"number of missing values in Models is\",train_c.Model.isna().sum())","94e79ba4":"#train_c.Model.value_counts()[:30].plot(kind='bar')","f639c302":"cat=train_c.Model.value_counts()>=100\ncat=cat[cat].index\nmodel_cat={}\nfor i in range(len(cat)):\n    model_cat[cat[i]]=i\ntrain_c['Model_processed']=train_c.Model\ntrain_c['Model_processed'].replace(model_cat,inplace=True)\ntrain_c.Model_processed[~train_c['Model_processed'].isin(model_cat.values())]=39\ntrain_c['Model_processed']=pd.to_numeric(train_c['Model_processed'])","3f9c78b9":"#train_c.Model_processed.value_counts().plot(kind='bar',figsize=(20,10))","63780b0a":"print(\"number of categories in Production years is\",train_c['Prod. year'].nunique())\nprint(\"number of missing values in Production years is\",train_c['Prod. year'].isna().sum())","dd7200f7":"#since price is skewed i'm taking median here.\n#train_c.groupby('Prod. year')['Price'].agg('median').plot(kind='bar',figsize=(20,15))","7e31a02a":"#train_c.groupby('Prod. year')['Price'].agg('count').plot(kind='bar',figsize=(20,10))","3ccb298f":"train_c['Car_age'] = 2021 - train_c['Prod. year']","edc76547":"print(\"number of categories in category\",train_c['Category'].nunique())\nprint(\"number of missing values in categories is\",train_c['Category'].isna().sum())","b73c02c4":"#train_c['Category'].value_counts().plot(kind='bar')","a3b663b6":"train_c['category_processed'] = train_c['Category'].apply(lambda x: 'rare' if x == 'Goods wagon' or x == 'Pickup'\n                                              or x == 'Cabriolet' or x == 'Limousine' else x)","c5fe2963":"print(\"number of categories in Leather interior is\",train_c['Leather interior'].nunique())\nprint(\"number of missing values in Leather interior is\",train_c['Leather interior'].isna().sum())","dceae787":"#train_c['Leather interior'].value_counts().plot(kind='bar')","87300ffb":"print(\"number of categories in Fuel type is\",train_c['Fuel type'].nunique())\nprint(\"number of missing values in Fuel type is\",train_c['Fuel type'].isna().sum())","7c49ef22":"#train_c['Fuel type'].value_counts().plot(kind='bar')","784d63b0":"train_c['fuel_type_processed'] = train_c['Fuel type'].apply(lambda x: 'Hybrid-hydrogen' if x == 'Plug-in Hybrid' or x == 'Hydrogen' else x)","e65f45e5":"print(\"number of categories in Engine volume is\",train_c['Engine volume'].nunique())\nprint(\"number of missing values in Engine volume is\",train_c['Engine volume'].isna().sum())","99a2c30f":"#train_c['Engine volume'].value_counts()[:25].plot(kind='bar')","ed5406d2":"train_c['Turbo_engine'] = train_c['Engine volume'].apply(lambda x: 'Yes' if x.split(\" \")[-1] == 'Turbo' else 'No')\ntrain_c['Engine volume'] = train_c['Engine volume'].apply(lambda x: x.split(\" \")[0]).astype(float)","8979bc26":"print(\"number of categories in Cylinders is\",train_c['Cylinders'].nunique())\nprint(\"number of missing values in Cylinders is\",train_c['Cylinders'].isna().sum())","80c4a3f7":"#train_c['Cylinders'].value_counts().plot(kind='bar')","4609a9d7":"print(\"number of categories in Gear box type is\",train_c['Gear box type'].nunique())\nprint(\"number of missing values in Gear box type is\",train_c['Gear box type'].isna().sum())","f5d65c0d":"#train_c['Gear box type'].value_counts().plot(kind='bar')","e408fece":"print(\"number of categories in Drive wheels is\",train_c['Drive wheels'].nunique())\nprint(\"number of missing values in Drive wheels is\",train_c['Drive wheels'].isna().sum())","f1197e55":"#train_c['Drive wheels'].value_counts().plot(kind='bar')","aabf63a1":"print(\"number of categories in Doors is\",train_c['Doors'].nunique())\nprint(\"number of missing values in Doors is\",train_c['Doors'].isna().sum())","03b61db8":"#train_c['Doors'].value_counts().plot(kind='bar')","78907653":"train_c['doors_processed']=train_c.Doors.replace(to_replace={'04-May':4,'02-Mar':2,'>5':6})\ntrain_c['doors_processed']=train_c['doors_processed'].astype('int')","bd8b6985":"train_c['Wheel'].value_counts().plot(kind='bar')","f670c2f4":"print(\"number of categories in Wheel is\",train_c['Wheel'].nunique())\nprint(\"number of missing values in Wheel is\",train_c['Wheel'].isna().sum())","653b2484":"print(\"number of categories in Color is\",train_c['Color'].nunique())\nprint(\"number of missing values in Color is\",train_c['Color'].isna().sum())","d2b7ea9a":"#train_c['Color'].value_counts().plot(kind='bar')","8fe885b4":"train_c['Airbags'].value_counts().plot(kind='bar')","e284623d":"print(\"number of categories in Airbags is\",train_c['Airbags'].nunique())\nprint(\"number of missing values in Airbags is\",train_c['Airbags'].isna().sum())","738fdc30":"#train_c.groupby('Airbags')['Price'].agg('sum').plot(kind='bar')","d633d26c":"#train_c['Levy'].value_counts()[:10].plot(kind='bar')","ad86bd48":"train_c['is_levy_missing']=False\ntrain_c.is_levy_missing[train_c['Levy']=='-']=True\ntrain_c['levy_processed']=train_c['Levy'].replace(\"-\",np.nan)\nprint(\"number of missing values in levy is\",train_c.levy_processed.isna().sum())\n#train_c['levy_processed'].replace(np.nan,0,inplace=True)\n#train_c.levy_processed=train_c.levy_processed.astype(int)","bd9cb422":"import seaborn as sns","b6fc1ea6":"def check_correlation(df):\n    new_df=df[~df['levy_processed'].isna()]\n    new_df['levy_processed']= new_df['levy_processed'].astype('int')\n    sns.heatmap( new_df.corr() , linewidth = 0.5 , cmap = 'coolwarm' )\n    return new_df.corr()","833535ed":"train_c['Levy_cor']=train_c['levy_processed']\ntrain_c['Levy_cor']= train_c.groupby(['Engine volume', 'Cylinders'])['Levy_cor'].transform(\n    lambda grp: grp.fillna(grp.median())\n)\n\ntrain_c['Levy_cor']= train_c.groupby(['Engine volume'])['Levy_cor'].transform(\n    lambda grp: grp.fillna(grp.median())\n)\n\n\ntrain_c['Levy_cor']= train_c.groupby(['Cylinders'])['Levy_cor'].transform(\n    lambda grp: grp.fillna(grp.median())\n)\n\ntrain_c['Levy_cor']=train_c['Levy_cor'].astype('int')","cb7f1fc1":"train_c['mileage_processed']=train_c['Mileage'].str.split(n=1,expand=True)[0:][0]\ntrain_c['mileage_processed']=train_c['mileage_processed'].astype('int')","4f9012b8":"train_c['mileage_processed']=train_c['mileage_processed'].replace(0,np.nan)\ntrain_c['mileage_processed']= train_c.groupby('Prod. year')['mileage_processed'].transform(\n    lambda grp: grp.fillna(grp.median())\n)\n# Fill remaining na's(if any) with median of entire data\ntrain_c['mileage_processed']= train_c['mileage_processed'].fillna(train_c['mileage_processed'].median())\ntrain_c['mileage_processed']= train_c['mileage_processed'].astype('int')","90690c6b":"print(\"number of missing values in ID is\",train_c['ID'].isna().sum())","47ff414d":"\ndef loss(actual,predicted):\n    '''\n    actual: actual value\n    predicted: predicted value\n    \n    '''\n    #return np.sqrt(mean_squared_error(actual, predicted))\n    return np.sqrt(mean_squared_log_error(actual, predicted))","74f6fa0c":"def preprocess(train,mode=None):\n    train_c=train.copy(deep=True)\n    if mode=='train':\n        train_c.drop_duplicates(inplace=True)\n        train_c.reset_index(inplace=True)\n        train_c.drop('index',axis=1,inplace=True)\n    train_c['Car_age'] = 2021 - train_c['Prod. year']\n    train_c['category_processed'] = train_c['Category'].apply(lambda x: 'rare' if x == 'Goods wagon' or x == 'Pickup'\n                                              or x == 'Cabriolet' or x == 'Limousine' else x)\n    train_c['fuel_type_processed'] = train_c['Fuel type'].apply(lambda x: 'Hybrid-hydrogen' if x == 'Plug-in Hybrid' or x == 'Hydrogen' else x)\n    train_c['Turbo_engine'] = train_c['Engine volume'].apply(lambda x: 'Yes' if x.split(\" \")[-1] == 'Turbo' else 'No')\n    train_c['Engine volume'] = train_c['Engine volume'].apply(lambda x: x.split(\" \")[0]).astype(float)\n\n    train_c['doors_processed']=train_c.Doors.replace(to_replace={'04-May':4,'02-Mar':2,'>5':6})\n    train_c['doors_processed']=train_c['doors_processed'].astype('int')\n    train_c['is_levy_missing']=False\n    train_c.is_levy_missing[(train_c['Levy']=='-' )]=True\n    train_c['levy_processed']=train_c['Levy'].replace(\"-\",np.nan)\n    train_c['levy_processed']=train_c['levy_processed'].fillna(0)\n    train_c['levy_processed']=train_c['levy_processed'].astype('float')\n    train_c['mileage_processed']=train_c['Mileage'].str.split(n=1,expand=True)[0:][0]\n    train_c['mileage_processed']=train_c['mileage_processed'].astype('float')\n    \n    return train_c","2c8eaa4f":"#colu=[,,,,,,,,,,,,,'Car_age','Turbo_engine','levy']\nall_features=pd.DataFrame()\n#manufacturer_all={'HYUNDAI':1,'TOYOTA':2,'MERCEDES-BENZ':3,'FORD':4,'CHEVROLET':5,'BMW':6,'HONDA':7,'LEXUS':8,'NISSAN':9,'VOLKSWAGEN':10,'SSANGYONG':11,'KIA':12,'OPEL':13,'MITSUBISHI':14,'SUBARU':15,'AUDI':16,'MAZDA':17,'JEEP':18}\nlevy_selected='No'\nif levy_selected=='No':\n    all_features['Levy']=['-']\nelse:\n    all_features['Levy']=['100']\nall_features['Manufacturer']=['HONDA']\nall_features['Model']=['FIT']\nall_features['Prod. year']=[2010]\nall_features['Category']=['Jeep']\nall_features['Leather interior']=['Yes']\nall_features['Fuel type']=['Hybrid']\nall_features['Engine volume']=['3.0 Turbo']\nall_features['Cylinders']=[6.0]\nall_features['Gear box type']=['Automatic']\nall_features['Drive wheels']=['4x4']\n\nall_features['Doors']=[6]\nall_features['Wheel']=['Left wheel']\nall_features['Color']='Silver'\nall_features['Airbags']=[12]\n#all_features['is_levy_missing']=['No']\n#all_features['Levy']=\"-\"\n\nall_features['Mileage']=['1000']","e401548b":"def pipeline(train_data,test_data):\n    train_data=preprocess(train_data,'train')\n    test_data=preprocess(test_data)\n    continuous=['levy_processed','mileage_processed','Car_age']\n    categories=['Model','Prod. year','Leather interior','Engine volume','Cylinders','Gear box type','Drive wheels','Wheel','Color','Airbags','is_levy_missing',\n           'Manufacturer','category_processed','fuel_type_processed','Turbo_engine','doors_processed']\n    column_trans = make_column_transformer((preprocessing.MinMaxScaler(), continuous),(preprocessing.OrdinalEncoder(),categories),remainder='passthrough')\n    X_train=train_data[continuous+categories]\n    X_test=test_data[continuous+categories]\n    combined_df=pd.concat([X_train,X_test])\n    transf=column_trans.fit(combined_df)\n    X_train_transformed=transf.transform(X_train)\n    X_test_transformed=transf.transform(X_test)\n    y_train=train_data['Price']\n    #y_test=test_data['Price']\n    return X_train_transformed,X_test_transformed,y_train\n    ","1e9fecac":"X_train,X_test,y_train=pipeline(train_data,all_features)","023bd5cd":"continuous=['levy_processed','mileage_processed','Car_age']\ncategories=['Model','Prod. year','Leather interior','Engine volume','Cylinders','Gear box type','Drive wheels','Wheel','Color','Airbags','is_levy_missing','Manufacturer','category_processed','fuel_type_processed','Turbo_engine','doors_processed']","ec87a121":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","3b90750d":"kfold = KFold(5,shuffle=True, random_state=3)","8fb5248d":"# from sklearn.model_selection import GridSearchCV\n# kfold = KFold(5,shuffle=True, random_state=3)\n# gsc = GridSearchCV(\n#     estimator=model,\n#     param_grid={\n#         'n_estimators': range(90,120,1),\n#         #'max_features': range(50,401,50),\n#         'min_samples_leaf': range(0,20,1),\n#         'min_samples_split': range(0,20,1),\n#     },\n#     scoring=custom_scorer,\n#     cv=kfold\n# )\n\n# grid_result = gsc.fit(X_train, y_train)\n\n# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","f1c90baf":"Best: 1.220228 using {'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 90}\nBest: 1.218737 using {'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 110}-->shuffle=false\nBest: -1.310629 using {'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 50}-->neg mean","4c90ff10":"X_train.shape","c52158a2":"param_grid={\n        'n_estimators': range(0,200,1),\n        'max_features': range(0,19,1),\n        'min_samples_leaf': range(0,200,1),\n        'min_samples_split': range(0,200,1),\n    }","a8340044":"# from sklearn.model_selection import RandomizedSearchCV\n# clf = RandomizedSearchCV(model,param_grid,random_state=0,cv=kfold,scoring=custom_scorer)\n# search = clf.fit(X_train, y_train)\n# search.best_params_","344a3a09":"from sklearn.metrics.scorer import make_scorer\ncustom_scorer = make_scorer(loss, greater_is_better=True)","6d2b6fce":"model.get_params()","311cadaa":"from sklearn.metrics import mean_squared_log_error\nmean_squared_log_error","c908e731":"# from sklearn.model_selection import RandomizedSearchCV\n# distributions = dict(C=uniform(loc=0, scale=4),penalty=['l2', 'l1'])\n# clf = RandomizedSearchCV(model,distributions,random_state=0,cv=kfold,scoring=loss)\n# search = clf.fit(X_train, y_train)\n# search.best_params_","0f7c9c07":"# model2 = ExtraTreesRegressor(random_state = 42,n_jobs=-1,min_samples_leaf=10,min_samples_split=2,n_estimators=90)\n# model2.fit(X_train,y_train)\n# pred=model2.predict(X_train)\n# print(loss(y_train,pred))\n# print(mean_squared_log_error(y_train,pred))","982db39d":"model = ExtraTreesRegressor(random_state = 42,n_jobs=-1)\nmodel.fit(X_train,y_train)\npred=model.predict(X_train)\nprint(loss(y_train,pred))","db972ee9":"model.predict(X_test)","7c89a9ae":"t=pd.DataFrame(X_test,columns=continuous+categories)\nt","6f58a5e5":"tr=pd.DataFrame(X_train,columns=continuous+categories)\n","332bcfb7":"shap_values","b2c4ca2a":"import shap\nshap_values = shap.TreeExplainer(model).shap_values(tr)\nshap.summary_plot(shap_values, tr, plot_type=\"bar\")","55e74644":"import shap\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(t)\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0], t)","fb106846":"model.predict(X_test)","032335e2":"train_data.loc[(train_data['Manufacturer']=='HONDA') & (train_data['Model']=='FIT')&(train_data['Price']==60502)]","2a17fa4d":"pip install joblib","33dfaee5":"# import joblib\n# joblib.dump(model, \"test.pkl\", 9)\n","06036005":"mod=joblib.load(\"test.pkl\", mmap_mode=None)\nmod.predict(X_test)","cd81362d":"# filename = 'finalized_rfmodel_reduced_size.pkl'\n# pickle.dump(model, open(filename, 'wb'),protocol=pickle.HIGHEST_PROTOCOL)","1a9a4f19":"Best: 1.220228 using {'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 90}\nBest: 1.218737 using {'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 110}-->shuffle=false\nBest: -1.310629 using {'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 50}-->neg mean","e3246c38":"# train_los=0\n# test_los=0\n# kfold = KFold(5,shuffle=True, random_state=3)\n# for fold,(train_idx, val_idx) in enumerate(kfold.split(X_train)):\n#     train_x=X_train[train_idx]\n#     train_y=y_train[train_idx]\n#     test_x=X_train[val_idx]\n#     test_y=y_train[val_idx]\n#     #print(train_x.columns)\n# #     print(\"t\",train_y.columns)\n#     #etr = ExtraTreesRegressor(random_state = 42)\n#     etr = ExtraTreesRegressor(random_state = 42,n_jobs=-1,min_samples_leaf=5,min_samples_split=5,n_estimators=90)\n#     #etr=LGBMRegressor()\n#     etr.fit(train_x,train_y)\n#     pred_test=etr.predict(test_x)\n#     pred_train=etr.predict(train_x)\n#     #print(pred_train)\n# #     pred_test = np.where(pred_test < 0, 0, pred_test)\n# #     pred_train = np.where(pred_train < 0, 0, pred_train)\n#     train_los+=loss(train_y,pred_train)\n#     test_los+=loss(test_y,pred_test)\n#     print(fold,\"--->train loss\",loss(train_y,pred_train))\n#     print(fold,\"--->test loss\",loss(test_y,pred_test))\n#     #print('MSLE:', (mean_squared_log_error(train_y,pred_train)))\n# #     print('MSLE:', (mean_squared_log_error(np.expm1(np.log1p(test_y)), np.expm1(pred_test))))\n# print('train',train_los\/5)\n# print(\"test\",test_los\/5)","879c3888":"{'n_estimators': 117,\n 'min_samples_split': 24,\n 'min_samples_leaf': 173,\n 'max_features': 14}","7e257504":"'n_estimators': 30,\n 'min_samples_split': 20,\n 'min_samples_leaf': 130,\n 'max_features': 4}train 1.6066865291306267\ntest 1.6096675049270928","f0aa8f2e":"{'n_estimators': 119, 'min_samples_split': 19, 'min_samples_leaf': 17} train 1.2420386855851893\ntest 1.2789529708201557","baee1a9a":"train 1.0341349089148444\ntest 1.14405685620292\nBest: -1.310629 using {'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 50}-->neg mean\n","f60f59e9":"train 1.1601067344428182\ntest 1.2202279450649385\n90","2d4fe441":"0 --->train loss 0.208406655046884\n0 --->test loss 1.0077802337403365\n1 --->train loss 0.20136042821633984\n1 --->test loss 1.0671952632966928\n2 --->train loss 0.21841283846640225\n2 --->test loss 0.9550240091270588\n3 --->train loss 0.21167675292449983\n3 --->test loss 1.042051994650577\n4 --->train loss 0.22213158348953427\n4 --->test loss 0.986565156191457\ntrain 0.21239765162873203\ntest 1.0117233314012244","19135e4d":"train 0.21236829723338527\ntest 1.0203812439403657","37c0c48a":"1.0203812439403657-0.9876407739155336","40b4da64":"train 0.029163936496856613\ntest 0.9876407739155336","8e0f08cc":"0 --->train loss 0.02873577587863731\n0 --->test loss 0.8594117392222028\n1 --->train loss 0.02932350575009186\n1 --->test loss 0.9265065107629952\n2 --->train loss 0.02388891237034141\n2 --->test loss 0.8816895936484594\n3 --->train loss 0.012756141672408971\n3 --->test loss 0.9027523402510272\n4 --->train loss 0.03067280100314065\n4 --->test loss 0.8876000133633137\ntrain 0.025075427334924037\ntest 0.8915920394495996","ad314975":"0 --->train loss 0.03489586342564365\n0 --->test loss 0.9822132326407299\n1 --->train loss 0.034870391295271676\n1 --->test loss 1.05188182018834\n2 --->train loss 0.027475785655244514\n2 --->test loss 0.9111995937141081\n3 --->train loss 0.012955473253012734\n3 --->test loss 1.0126641272407275\n4 --->train loss 0.035941676183478655\n4 --->test loss 0.9491906682372114\ntrain 0.029227837962530246\ntest 0.9814298884042232","83f071a6":"plt.figure(figsize=(15, 10))\nplt.barh(continuous+categories,etr.feature_importances_)","acb21746":"plt.figure(figsize=(15, 10))\nplt.barh(continuous+categories,etr.feature_importances_)","61a17112":"import matplotlib.pyplot as plt","f843a0d1":"Lets explore the data and see anything interesting we can get out of it. i'll make a copy of my train and test data you know just to be on safer side. i won't be doing all the EDA myself, i'm gonna use ProfileReport from pandas profiling.\n[you can check out more here](https:\/\/pandas-profiling.github.io\/pandas-profiling\/docs\/master\/index.html). it's a really good library to quickly get a visual report with some statistics. \n\n*note:* click on toggle details to get more information.","6817ec91":"**13.Color**\n* There are 16 categories in colors and 0 missing values.","f5c908dc":"# Target variable: \n**Price**\n\n* target variable price is skewed.\n* box plot is squished and hard to interprete.","8dbb3de1":"# Categorical variable\n**1. Manufacturer**\n* lets put the maufacturer who produced less than 100 cars to rare category.\n* you can see some of the important things about manufacturer below.\n* there are 65 distinct categories in Manufacturer and 0 missing values.","83dfa276":"**6.Fuel type**\n* there are 2 distinct categories in Fuel type and 0 missing values.\n* lets club in hybrid hydrogen and hydrogen as their rare categories","9dd1717e":"**3. Prod. year**\n* there are 54 distinct categories in Production year and 0 missing values.\n* by using production year we can get the age of a car, that might help in predicting the car price right? and we can also get one more feature.","d038ed31":"**Math Hackathon** \n\n**what is this hackathons problem statement?**\n\nWith the rise in the variety of cars with differentiated capabilities and features such as model, production year, category, brand, fuel type, engine volume, mileage, cylinders, colour, airbags and many more, Math company is bringing a car price prediction challenge for all. We all aspire to own a car within budget with the best features available. To solve the price problem they have created a dataset of 19237 for the training dataset and 8245 for the test dataset.\n\n[read more here](https:\/\/machinehack.com\/hackathons\/data_hack_mathcothon_car_price_prediction_challenge\/overview)","391dd6c1":"**11. Doors**\n* Doors have 3 distinct categories and 0 missing values.\n\n* Doors need some cleaning up, 04-may is probably the 4 doors and 02-mar is the 2 doors. lets replace them respectively.","a6fb03db":"**4.Category**\n\n* there are 11 distinct categories in Categories and 0 missing values.\n* lets put Pickup,cabriolet,limousine to rare category since they are less in number","1edc1b6f":"# 3.ID\n* during the experimentation on feature selection it turned out that ID is also one of the usefull feature. \n* there aren't any missing values in IDs and since we have already dropped the duplicate values from the dataframe, hence that's also not a problem now.","f6b71495":"# Continuous variables:\n\n**1.Levy**\n* Levy is supposed to be int\/float but unfortunately it's in object form let's convert, oh! before converting it if you have observed properly Levy has '-' which will through an error if you try to convert it to float\/int. we have to take care of that as well.\n* let's create another column on if levy is missing\/not, this will come in handy in future. for every '_' i'm considering as levy is missing.\n* and we have got 5709 '-' which needs to be taken care of.\n* let's fill '_'  in levy with nan and it will be easier to replace later.\n* since levy is highly correlated with engine volume and cylinders i'm gonna take their help to fill the missing values.","59bdf6ec":"let's see how many duplicate values we have and drop them, it helps for the better generalization of our model.","4b796bf8":"**2.Mileage**\n* for our luck Mileage is also in object format and which has a km which is not really neseccary for us. let's handle them.\n* in this case mileage can be inferred as odometer and there are lot of vehicles with 0 mileage and these are also not from the recent years. so odometer reading might be incorrect.\n* i'm taking the help of production year to impute the incorrect(0) odometer values for mileage ","2d905262":"**10. Drive wheels**\n* There are 3 categories in Drive wheels and 0 missing values.","526b2b33":"**12. Wheel**\n* There are 2 different categories in wheel and 0 missing values.\n","dfd2492f":"**8. Cylinders**\n* There are 13 categories in cylinders and 0 missing values.","91812e1b":"**Target variable:**\n* Price\n\n**Categorical variables:**\n* Manufacturer\n* Model\n* Prod.year\n* Category\n* Leather interior\n* Fuel type\n* Engine volume\n* cylinders\n* Gear box type\n* Drive wheels\n* Doors\n* Wheel\n* color\n* Air bags\n\n**Continuous variables:**\n* Levy\n* Mileage\n\n\n*let's explore the independent variables one by one and also do the feature engineering along the way.*\n\n*let's start by checking the datatypes of the variable and summary statistics*\n\nnote: as i said eariler i'm not gonna do an exhaustive EDA here you can get most of them using the pandas profile report.","75f4a038":"**2.Model**\n* there are 1590 distinct categories in Models and 0 missing values.\n* lets put models with less than 100 count to rare category","ac3ee799":"**9. Gear box type**\n* Gear box type has 2 distinct categories and 0 missing values\n\n","3e4763b9":"**14.Airbags**\n* There are 17 categories in Airbags and 0 missing values.","04425638":"**7.Engine volume**\n* There are 107 different categories in engine volume and 0 missing values.\n* we can create turbo engine feature from using engine volume.","22f7deac":"**5. Leather interior**\n* there are 2 distinct categories in Leather interior and 0 missing values.\n"}}