{"cell_type":{"fc8eea7d":"code","e86b6c92":"code","c6294a8a":"code","d256682c":"code","b5b70ab7":"code","ff9ef6ce":"code","6ceefe8e":"code","5a05be80":"code","6b69702c":"code","d213199a":"code","d8fe6dc8":"code","302cafc9":"code","6cf8f5af":"code","2e9a20b1":"code","e16d62c2":"code","60c82e93":"code","27b18c70":"code","a4db6a68":"code","fe738bc4":"code","b7b0b29c":"code","4439887a":"code","cf9cbb60":"code","4a30a81f":"code","a40eecef":"code","d08ea45d":"code","26e5005f":"code","117ce4c1":"code","cb00ba1c":"code","c85550a3":"code","8259278b":"code","f3ca2d83":"code","1a877737":"code","14f3bb81":"code","32c5c008":"code","4beda9a9":"code","d798e4c5":"code","147b8470":"code","c4417f07":"code","5b080f3b":"code","768fa200":"code","fc864a63":"code","cb05761b":"code","139272e0":"code","8e85d3ab":"code","cec57216":"code","03e3e41c":"code","2c724206":"code","6a76775e":"code","2c162b7b":"code","477350ce":"code","0becc66c":"code","6694ffa0":"code","21f6dcf6":"code","47489de8":"code","87c83319":"code","a6fc0f17":"code","e6f2a7a8":"code","97f0b2a6":"code","d6f4137c":"code","b171c1d9":"code","5c359deb":"code","ae00e005":"code","4e6e67c2":"code","f954b16d":"code","fa8b6a4e":"code","a11f173d":"code","0f7976c9":"code","d0f1cf8a":"code","c77acca7":"code","a2d73fc0":"code","23973053":"code","4dc1f982":"code","81ce9926":"code","aacd3b87":"code","60166f68":"code","39c3cd12":"code","2834696f":"code","4033becf":"code","e7344eed":"code","c7ea1a36":"code","8161e559":"code","e3595639":"code","bc9daebb":"code","c879c966":"code","42ded2f2":"code","5055d8d0":"code","a197d03e":"code","4d4b4655":"code","a7307d97":"code","4f47aa34":"code","a0cd3a0e":"code","0608c32d":"code","15358694":"code","f304c8a4":"code","9dc13298":"code","8229f767":"code","0da7d31b":"code","0edb91f4":"code","ed191386":"code","1279338b":"code","b4b7026a":"code","381f0fc5":"code","ba3e83fe":"code","72d1702b":"code","ff203379":"code","0589166c":"code","0bcc5244":"markdown","258ee9eb":"markdown","23a579af":"markdown","e10b7559":"markdown","876b9751":"markdown","8488b2cf":"markdown","93ab687a":"markdown","a1b13661":"markdown","72305a13":"markdown","a01f2831":"markdown","b2918c46":"markdown","face7387":"markdown","3166d4f7":"markdown","7d4577fc":"markdown","ce05bee2":"markdown","9167aa12":"markdown","e3e6f39e":"markdown","df50ba45":"markdown","300403fa":"markdown","f96e5d3d":"markdown","b4349853":"markdown","841a021f":"markdown","602d39a9":"markdown","1f722b60":"markdown","15505649":"markdown","949c2b44":"markdown","8b47a9e4":"markdown","fd30527f":"markdown","80aefd03":"markdown","602ac486":"markdown","2c03e900":"markdown","e08ba495":"markdown","5a5a0dca":"markdown","377bbae2":"markdown","23cdb025":"markdown","ec625ac6":"markdown","583e3642":"markdown","c1f0c3cd":"markdown","578354b7":"markdown","bfcf4349":"markdown","53e831ca":"markdown"},"source":{"fc8eea7d":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","e86b6c92":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","c6294a8a":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","d256682c":"train.head()","b5b70ab7":"test.head()","ff9ef6ce":"train.info()","6ceefe8e":"train.describe().T","5a05be80":"train['Pclass'].value_counts()","6b69702c":"train['Sex'].value_counts()","d213199a":"train['SibSp'].value_counts()","d8fe6dc8":"train['Parch'].value_counts()","302cafc9":"train['Ticket'].value_counts()","6cf8f5af":"train['Cabin'].value_counts()","2e9a20b1":"train['Embarked'].value_counts()","e16d62c2":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","60c82e93":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","27b18c70":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","a4db6a68":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","fe738bc4":"train.head()","b7b0b29c":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","4439887a":"train.describe().T","cf9cbb60":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","4a30a81f":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","a40eecef":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","d08ea45d":"train.sort_values(\"Fare\", ascending=False).head()","26e5005f":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","117ce4c1":"train.sort_values(\"Fare\", ascending=False).head()","cb00ba1c":"test.sort_values(\"Fare\", ascending=False)","c85550a3":"test['Fare'] = test['Fare'].replace(512.3292, 300)","8259278b":"test.sort_values(\"Fare\", ascending=False)","f3ca2d83":"train.isnull().sum()","1a877737":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","14f3bb81":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","32c5c008":"train.isnull().sum()","4beda9a9":"test.isnull().sum()","d798e4c5":"train.isnull().sum()","147b8470":"test.isnull().sum()","c4417f07":"train[\"Embarked\"].value_counts()","5b080f3b":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","768fa200":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","fc864a63":"train.isnull().sum()","cb05761b":"test.isnull().sum()","139272e0":"test[test[\"Fare\"].isnull()]","8e85d3ab":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","cec57216":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","03e3e41c":"test[\"Fare\"].isnull().sum()","2c724206":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","6a76775e":"train.isnull().sum()","2c162b7b":"test.isnull().sum()","477350ce":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","0becc66c":"train.head()","6694ffa0":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","21f6dcf6":"train.head()","47489de8":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","87c83319":"train.head()","a6fc0f17":"train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","e6f2a7a8":"test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","97f0b2a6":"train.head()","d6f4137c":"test.head()","b171c1d9":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","5c359deb":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","ae00e005":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","4e6e67c2":"train.isnull().sum()","f954b16d":"test['Title'] = test['Title'].map(title_mapping)","fa8b6a4e":"test.head()","a11f173d":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","0f7976c9":"train.head()","d0f1cf8a":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","c77acca7":"# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)","a2d73fc0":"train.head()","23973053":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","4dc1f982":"train.head()","81ce9926":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])","aacd3b87":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","60166f68":"train.head()","39c3cd12":"train.head()","2834696f":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","4033becf":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","e7344eed":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","c7ea1a36":"train.head()","8161e559":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","e3595639":"test.head()","bc9daebb":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","c879c966":"train.head()","42ded2f2":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","5055d8d0":"test.head()","a197d03e":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","4d4b4655":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","a7307d97":"train.head()","4f47aa34":"test.head()","a0cd3a0e":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","0608c32d":"x_train.shape","15358694":"x_test.shape","f304c8a4":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","9dc13298":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","8229f767":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","0da7d31b":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","0edb91f4":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","ed191386":"xgb_cv_model.fit(x_train, y_train)","1279338b":"xgb_cv_model.best_params_","b4b7026a":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","381f0fc5":"xgb_tuned =  xgb.fit(x_train,y_train)","ba3e83fe":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","72d1702b":"test","ff203379":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","0589166c":"output.head()","0bcc5244":"## Logistic Regression","258ee9eb":"### Age","23a579af":"## Analysis and Visualization of Numeric and Categorical Variables","e10b7559":"### Embarked","876b9751":"### Embarked","8488b2cf":"#### SibSp vs survived:","93ab687a":"**Variables and Their Types:**\n\nSurvival: Survival -> 0 = No, 1 = Yes\n\nPclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton","a1b13661":"## Gradient Boosting Classifier","72305a13":"### Sex","a01f2831":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","b2918c46":"### Fare","face7387":"# Data Preparation","3166d4f7":"## Missing Value Treatment","7d4577fc":"## Outlier Treatment","ce05bee2":"# Data Understanding (Exploratory Data Analysis)","9167aa12":"## Importing Librarires","e3e6f39e":"### Basic summary statistics about the numerical data","df50ba45":"### Fare","300403fa":"# Business Understanding \/ Problem Definition","f96e5d3d":"**Variable Notes:**\n\nPclass: A proxy for socio-economic status (SES)\n- 1st = Upper\n- 2nd = Middle\n- 3rd = Lower\n\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n- Sibling = brother, sister, stepbrother, stepsister\n- Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch: The dataset defines family relations in this way...\n- Parent = mother, father\n- Child = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","b4349853":"### Name - Title","841a021f":"### Ticket","602d39a9":"**Titanic Survival Prediction:**\n\nUse machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","1f722b60":"## Deleting Unnecessary Variables","15505649":"### Embarked & Title","949c2b44":"### Cabin","8b47a9e4":"#### Pclass vs survived:","fd30527f":"## Loading Data","80aefd03":"### Family Size","602ac486":"# Modeling, Evaluation and Model Tuning","2c03e900":"## Random Forest","e08ba495":"#### Parch vs survived:","5a5a0dca":"#### Sex vs survived:","377bbae2":"## Spliting the train data","23cdb025":"### AgeGroup","ec625ac6":"### Classes of some categorical variables","583e3642":"### Pclass","c1f0c3cd":"# Deployment","578354b7":"### Visualization","bfcf4349":"## Variable Transformation","53e831ca":"## Feature Engineering"}}