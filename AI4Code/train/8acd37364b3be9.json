{"cell_type":{"985311ac":"code","240e17df":"code","04c37285":"code","dabfdc38":"code","0e06cad4":"code","cc7101b5":"code","b3e149d6":"code","aee14bdd":"code","9407bd5f":"code","9a02d0e5":"code","2a7d0654":"code","29d59bdf":"code","d13b598a":"code","c39a4539":"code","c7e89bbc":"code","6415b4ac":"code","363bd27c":"code","18ab6e46":"code","3781f25f":"code","aa179257":"code","d85e8361":"code","5545081f":"code","f92b3cfc":"code","7b758be3":"code","49f53895":"code","49c1fd28":"code","fbe7b90d":"code","b3737d59":"code","119d925a":"code","59768fe3":"code","de7fc870":"code","d6004cf0":"code","0debeb5d":"code","330f4b07":"code","9d3716b3":"code","cd409c60":"code","02c24499":"code","e96719d1":"code","747ded9b":"code","81a927fd":"code","1b458f05":"code","fe301943":"code","4b790b06":"code","25e836b8":"code","6b9a73e0":"code","5a1b2486":"code","8fa062e9":"code","2f519d7b":"code","32ccb816":"code","dccbc1cc":"code","d95b6e63":"code","bc1cb5a1":"code","c1e5c2b6":"code","b3bde184":"code","16f4342a":"code","d1d6a96c":"code","114a1f8b":"code","d0659432":"code","c18f1bd1":"code","4f268f71":"code","6f34e339":"markdown","fea55e74":"markdown","b01dfff3":"markdown","7875063a":"markdown","ccbc64e7":"markdown","37bff338":"markdown","49da9d1b":"markdown","f40b472e":"markdown","3e9435f2":"markdown","49779a03":"markdown","39fa7102":"markdown","a9e511be":"markdown","73b712d2":"markdown","6e8aef9f":"markdown","c728916a":"markdown","3a00490c":"markdown","018e6772":"markdown","36c022bc":"markdown","1b2dd2ba":"markdown","74c10e29":"markdown","fc766eb4":"markdown","93a2267b":"markdown","46e1511a":"markdown","9793fa19":"markdown","6f212438":"markdown","3a4ae449":"markdown","5e66a0e5":"markdown","0ac795d5":"markdown","3cfa45e0":"markdown","45be195f":"markdown","19ec2a35":"markdown","2bba6d89":"markdown","620e2de4":"markdown","7a727804":"markdown","5ac3fb28":"markdown","faf061a6":"markdown","d2d0691f":"markdown","a91e42b4":"markdown","37ba2c34":"markdown","1e0652ef":"markdown","45e60a6b":"markdown","07db2c6c":"markdown","eb9083b6":"markdown","57bac2ca":"markdown","a15c9384":"markdown","4f301a04":"markdown","0ea6d4f0":"markdown"},"source":{"985311ac":"# basic libraries to work on the dataframe\nimport pandas as pd\nimport numpy as np\n# data Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# libraries\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Increasing the columns views limit\npd.options.display.max_columns = None\npd.options.display.max_rows = 150\npd.options.display.float_format = '{:.2f}'.format","240e17df":"#Reading the data file using pandas\nlead=pd.read_csv('..\/input\/lead-scoring-dataset\/Lead Scoring.csv')\nlead.head()","04c37285":"# check the shape of the dataset\nlead.shape","dabfdc38":"# check statistics for numerical columns\nlead.describe().transpose()","0e06cad4":"# check whether there are any duplicates\nlead.duplicated().sum()","cc7101b5":"#Lets have a look at all the columns, their datatypes and also get an idea of null values present\nlead.info()\n","b3e149d6":"# change nomenclature to snakecase\nlead.columns = lead.columns.str.replace(' ', '_').str.lower()\n\n# test\nlead.columns","aee14bdd":"# shorten column names\nlead.rename(columns = {'totalvisits': 'total_visits', 'total_time_spent_on_website': 'time_on_website', \n                    'how_did_you_hear_about_x_education': 'source', 'what_is_your_current_occupation': 'occupation',\n                    'what_matters_most_to_you_in_choosing_a_course' : 'course_selection_reason', \n                    'receive_more_updates_about_our_courses': 'courses_updates', \n                     'update_me_on_supply_chain_content': 'supply_chain_content_updates',\n                    'get_updates_on_dm_content': 'dm_content_updates',\n                    'i_agree_to_pay_the_amount_through_cheque': 'cheque_payment',\n                    'a_free_copy_of_mastering_the_interview': 'mastering_interview'}, inplace = True)\n\nlead.head(1)","9407bd5f":"lead.drop('prospect_id', axis = 1, inplace = True)\n","9a02d0e5":"# Select all non-numeric columns\nlead_obj = lead.select_dtypes(include='object')\n\n# Find out columns that have \"Select\"\ns = lambda x: x.str.contains('Select', na=False)\nl = lead_obj.columns[lead_obj.apply(s).any()].tolist()\nprint (l)","2a7d0654":"# select all the columns that have a \"Select\" entry\nsel_cols = ['specialization', 'source', 'lead_profile', 'city']\n\n# replace values\nlead[sel_cols] = lead[sel_cols].replace('Select', np.NaN)","29d59bdf":"# Calculate percentage of null values for each column\n(lead.isnull().sum() \/ lead.shape[0]) * 100","d13b598a":"lead.drop(['source', 'lead_quality', 'lead_profile', 'asymmetrique_activity_index', \n                      'asymmetrique_profile_index', 'asymmetrique_activity_score', 'asymmetrique_profile_score',\n        'tags', 'last_activity', 'last_notable_activity'], \n        axis = 1, inplace = True)\n\nlead.head(1)\n","c39a4539":"# Lets look at what are we left with\n# Calculate percentage of null values for each column\n(lead.isnull().sum() \/ lead.shape[0]) * 100","c7e89bbc":"lead.country.value_counts(normalize = True, dropna = False) * 100","6415b4ac":"lead.drop('country', axis = 1, inplace = True)","363bd27c":"lead.course_selection_reason.value_counts(normalize = True, dropna = False) * 100","18ab6e46":"lead.drop('course_selection_reason', axis = 1, inplace = True)","3781f25f":"lead.occupation.value_counts(normalize = True, dropna = False) * 100","aa179257":"# combine low representing categories\nlead.loc[(lead.occupation == 'Student') | (lead.occupation == 'Other') | (lead.occupation == 'Housewife') | \n       (lead.occupation == 'Businessman') , 'occupation'] = 'Student and Others'","d85e8361":"lead.occupation.value_counts(normalize = True) * 100","5545081f":"# impute proportionately\nlead['occupation'] = lead.occupation.fillna(pd.Series(np.random.choice(['Unemployed', 'Working Professional', \n                                                                    'Student and Others'], \n                                                                   p = [0.8550, 0.1078, 0.0372], size = len(lead))))","f92b3cfc":"lead.specialization.value_counts(normalize = True, dropna = False) * 100","7b758be3":"# categorize all management courses\nlead.loc[(lead.specialization == 'Finance Management') | (lead.specialization == 'Human Resource Management') | \n       (lead.specialization == 'Marketing Management') |  (lead.specialization == 'Operations Management') |\n       (lead.specialization == 'IT Projects Management') | (lead.specialization == 'Supply Chain Management') |\n       (lead.specialization == 'Healthcare Management') | (lead.specialization == 'Hospitality Management') |\n       (lead.specialization == 'Retail Management') , 'specialization'] = 'Management Specializations'\n\n# categorize all busines courses\nlead.loc[(lead.specialization == 'Business Administration') | (lead.specialization == 'International Business') | \n       (lead.specialization == 'Rural and Agribusiness') | (lead.specialization == 'E-Business') \n        , 'specialization'] = 'Business Specializations'\n\n# categorize all industry courses\nlead.loc[(lead.specialization == 'Banking, Investment And Insurance') | (lead.specialization == 'Media and Advertising') |\n       (lead.specialization == 'Travel and Tourism') | (lead.specialization == 'Services Excellence') |\n       (lead.specialization == 'E-COMMERCE'), 'specialization'] = 'Industry Specializations'","49f53895":"lead.specialization.value_counts(normalize = True) * 100","49c1fd28":"# impute proportionately\nlead['specialization'] = lead.specialization.fillna(pd.Series(np.random.choice(['Management Specializations',  \n                                                    'Business Specializations', 'Industry Specializations'], \n                                                                   p = [0.7258, 0.1213, 0.1529 ], size = len(lead))))","fbe7b90d":"lead.city.value_counts(normalize = True, dropna = False) * 100","b3737d59":"# categorize all non-mumbai, but Maharashtra cities\nlead.loc[(lead.city == 'Thane & Outskirts') | (lead.city == 'Other Cities of Maharashtra'), \n       'city'] = 'Non-Mumbai Maharashtra Cities'\n\n# categorize all other cities\nlead.loc[(lead.city == 'Other Cities') | (lead.city == 'Other Metro Cities') | (lead.city == 'Tier II Cities') , \n       'city'] = 'Non-Maharashtra Cities'","119d925a":"lead.city.value_counts(normalize = True) * 100","59768fe3":"# impute proportionately\nlead['city'] = lead.city.fillna(pd.Series(np.random.choice(['Mumbai', 'Non-Mumbai Maharashtra Cities', \n                                                                    'Non-Maharashtra Cities'], \n                                                                   p = [0.5784, 0.2170, 0.2046 ], size = len(lead))))","de7fc870":"(lead.isnull().sum() \/ lead.shape[0]) * 100","d6004cf0":"# determine unique values for all object datatype columns\nfor k, v in lead.select_dtypes(include='object').nunique().to_dict().items():\n    print('{} = {}'.format(k,v))","0debeb5d":"lead.lead_origin.value_counts(normalize = True, dropna = False) * 100","330f4b07":"#There are a lot of smaller values which will not be used as definitive factors, lets group them together\nlead.loc[(lead.lead_origin == 'Lead Import') | (lead.lead_origin == 'Quick Add Form') | (lead.lead_origin == 'Lead Add Form')\n       , 'lead_origin'] = 'Lead Add Form and Others'","9d3716b3":"lead.lead_source.value_counts(normalize = True, dropna = False) * 100","cd409c60":"# Lets impute the missing values with the mode of data i.e. clearly 'Google'\nlead.lead_source.fillna(lead.lead_source.mode()[0], inplace=True)","02c24499":"#There are a lot of smaller values which will not be used as definitive factors, lets group them together\nlead['lead_source'] = lead['lead_source'].apply(lambda x: x if \n                                            ((x== 'Google') | (x=='Direct Traffic') | (x=='Olark Chat') | \n                                             (x=='Organic Search') | (x=='Reference')) \n                                            else 'Other Social Sites')","e96719d1":"# determine unique values\nfor k, v in lead.select_dtypes(include='object').nunique().to_dict().items():\n    print('{} = {}'.format(k,v))","747ded9b":"# select rest of the binary columns in a new dataframe\nlead_bin = lead[['do_not_email', 'do_not_call', 'search', 'newspaper_article', 'x_education_forums', \n           'newspaper', 'digital_advertisement', 'through_recommendations', 'mastering_interview']]\n\n# see value counts for each of the columns\nfor i in lead_bin.columns:\n    x = (lead_bin[i].value_counts(normalize = True)) * 100\n    print(x)\n    print()","81a927fd":"drop_bin = ['do_not_call', 'search', 'newspaper_article', 'x_education_forums', \n           'newspaper', 'digital_advertisement', 'through_recommendations', 'magazine', 'courses_updates', \n           'supply_chain_content_updates', 'dm_content_updates', 'cheque_payment']\n\nlead.drop(drop_bin, axis = 1, inplace = True)","1b458f05":"lead.lead_number = lead.lead_number.astype('object')","fe301943":"lead.total_visits.fillna(lead.total_visits.median(), inplace=True)\nlead.total_visits = lead.total_visits.astype('int')","4b790b06":"lead.page_views_per_visit.fillna(lead.page_views_per_visit.median(), inplace=True)","25e836b8":"lead.info()","6b9a73e0":"# Set style\nplt.style.use('ggplot')\n\n# See distribution of each of these columns\nfig = plt.figure(figsize = (14, 10))\nplt.subplot(2, 2, 1)\nplt.hist(lead.total_visits, bins = 20)\nplt.title('Total website visits')\n\nplt.subplot(2, 2, 2)\nplt.hist(lead.time_on_website, bins = 20)\nplt.title('Time spent on website')\n\nplt.subplot(2, 2, 3)\nplt.hist(lead.page_views_per_visit, bins = 20)\nplt.title('Average number of page views per visit')\n\nplt.show()","5a1b2486":"plt.figure(figsize = (14,12))\nsns.heatmap(lead[['total_visits', 'time_on_website', 'page_views_per_visit']].corr(), cmap=\"YlGnBu\", annot = True)\nplt.show()","8fa062e9":"plt.figure(figsize = (10, 14))\n\nplt.subplot(3,1,1)\nsns.boxplot(lead.total_visits)\n\nplt.subplot(3,1,2)\nsns.boxplot(lead.time_on_website)\n\nplt.subplot(3,1,3)\nsns.boxplot(lead.page_views_per_visit)\nplt.show()","2f519d7b":"plt.figure(figsize = (14, 8))\n\nlead.groupby('lead_origin')['lead_number'].count().sort_values(ascending = False).plot(kind= 'barh', width = 0.8, \n                                                            edgecolor = 'black', \n                                                            color = plt.cm.Paired(np.arange(len(lead))))\nplt.show()\n","32ccb816":"plt.figure(figsize = (14, 8))\n\nlead.groupby('lead_source')['lead_number'].count().sort_values(ascending = False).plot(kind= 'barh', width = 0.8, \n                                                            edgecolor = 'black', \n                                                            color = plt.cm.Paired(np.arange(len(lead))))\nplt.show()","dccbc1cc":"plt.figure(figsize = (10, 8))\n\nlead.groupby('specialization')['lead_number'].count().sort_values(ascending = False).plot(kind= 'barh', width = 0.8, \n                                                            edgecolor = 'black', \n                                                            color = plt.cm.Paired(np.arange(len(lead))))\nplt.show()","d95b6e63":"plt.figure(figsize = (14, 8))\n\nlead.groupby('occupation')['lead_number'].count().sort_values(ascending = False).plot(kind= 'barh', width = 0.8, \n                                                            edgecolor = 'black', \n                                                            color = plt.cm.Paired(np.arange(len(lead))))\nplt.show()","bc1cb5a1":"plt.figure(figsize = (14, 8))\n\nlead.groupby('city')['lead_number'].count().sort_values(ascending = False).plot(kind= 'barh', width = 0.8, \n                                                            edgecolor = 'black', \n                                                            color = plt.cm.Paired(np.arange(len(lead))))\nplt.show()","c1e5c2b6":"plt.figure(figsize = (14, 8))\n\nlead.groupby('do_not_email')['lead_number'].count().sort_values(ascending = False).plot(kind= 'barh', width = 0.8, \n                                                            edgecolor = 'black', \n                                                            color = plt.cm.Paired(np.arange(len(lead))))\nplt.show()","b3bde184":"# determine unique values\nfor k, v in lead.select_dtypes(include='object').nunique().to_dict().items():\n    print('{} = {}'.format(k,v))","16f4342a":"binlist = ['do_not_email', 'mastering_interview']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the housing list\nlead[binlist] = lead[binlist].apply(binary_map)\n\n# check the operation was success\nlead.head()","d1d6a96c":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(lead[['lead_origin', 'lead_source', 'specialization', 'occupation', 'city']], drop_first = True)\n\n# Adding the results to the master dataframe\nlead = pd.concat([lead, dummy1], axis=1)","114a1f8b":"# Dropping the columns for which dummies have been created\nlead.drop(['lead_origin', 'lead_source', 'specialization', 'occupation', 'city'], axis = 1, inplace = True)\n\nlead.head()","d0659432":"num_cols = lead[['total_visits', 'time_on_website', 'page_views_per_visit']]\n\n# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\nnum_cols.describe(percentiles=[.25, .5, .75, .90, .95, .99])","c18f1bd1":"# capping at 99 percentile\nlead.total_visits.loc[lead.total_visits >= lead.total_visits.quantile(0.99)] = lead.total_visits.quantile(0.99)\nlead.page_views_per_visit.loc[lead.page_views_per_visit >= \n                            lead.page_views_per_visit.quantile(0.99)] = lead.page_views_per_visit.quantile(0.99)","4f268f71":"plt.figure(figsize = (10, 14))\n\nplt.subplot(2,1,1)\nsns.boxplot(lead.total_visits)\n\nplt.subplot(2,1,2)\nsns.boxplot(lead.page_views_per_visit)\nplt.show()","6f34e339":"## Lead Source","fea55e74":"## Converting Binary (Yes\/No) to 0\/1","b01dfff3":"## Observations\n\nLooking at both the box plots and the statistics, there are upper bound outliers in both total_visits and page_views_per_visit columns. We can also see that the data can be capped at 99 percentile.","7875063a":"As we can see, we were able to significantly reduce the number of outliers by capping","ccbc64e7":"## Observations\nThere are five columns that still have high null values: country, specialization, occupation, course_selection_reason, and city. We will look at them individually to see what can be done","37bff338":"Most of the speciliazation taken are management","49da9d1b":"## Handle Binary columns\n* Drop those columns that have significant data imbalance\n* Drop all those columns that have only 1 unique entry","f40b472e":"Unempployed users are the most significant leads","3e9435f2":"# Handle Numerical columns\n## lead_number column: change datatype\nlead_number column is a unique identifier for each leads. Therefore, aggregations won't be of any relevance. We should change it to object","49779a03":"## Observations: \nNo significaqnt correlation such that columns can be dropped","39fa7102":"## Observation\nAs can be seen from the above output, the categorical columns (i.e. number of unique values > 2) are:\n\n* lead_origin\n* lead_source","a9e511be":"We have two binary columns: do_not_email, mastering_interview","73b712d2":"## Observation\nThe distribution of the data is very heavily skewed, with Better career prospects + null values = approx 100% of the total. It is safe to drop this column.","6e8aef9f":"## Specialization","c728916a":"# DATA Preparation","3a00490c":"## city column","018e6772":"# Outliers Treatment","36c022bc":"## Observation\n\nThe following columns can be dropped as they have just 1 unique values\n* magazine\n* course_updates\n* supply_chain_content_updates\n* dm_content_updates\n* cheque_payment\n\nLet's now check the data imbalance for the rest of the columns","1b2dd2ba":"## Observation\nThe distribution of the data is very heavily skewed, with India + null values = 97% of the total. It is safe to drop this column.","74c10e29":"## country column","fc766eb4":"# Drop columns that have null values > 40% or Sales generated columns","93a2267b":"## lead_source column","46e1511a":"## Observation\nFor occupation, we can first combine categories, and then impute proportionally to maintain the distribution and not introduce bias","9793fa19":"## Observations\n\nHigh peaks and skewed data. There might be a possibility of outliers. We will check them next","6f212438":"## total_visits column\nFor this column, we need to handle the missing values, and can convert the datatype to integer since visits can't be decimal","3a4ae449":"## Creating dummy variable for categorical columns\n### Categorical columns are: lead_origin, lead_source, specialization, occupation, city","5e66a0e5":"## Observation\nFor specialization, we can first combine categories based on the course type, and then impute proportionally to maintain the distribution and not introduce bias","0ac795d5":"## Handle null values and sales generated columns\n* Given there are a number of columns with very high number of null entries, let's calculate the percentage of null values in each column, and take a decision from there.\n* Furthermore, we can also drop Sales generated columns because those are the data entries that are made after the sales team has connected with the student. Those data have no bearing to the purpose of our model ie. providing lead score. The columns are\n    * tags\n    * lead_quality\n    * all asymmetrique columns\n    * last_activity\n    * last_notable_activity","3cfa45e0":"## page_views_per_visit column\n### Handle missing values","45be195f":"## Observations\n\nA large number of columns have null values. Those columns should ideally be dropped\nProspect ID and Lead Number both serve the same purpose. They are both unique identifiers. We will drop Prospect ID\nColumn names are just too long. We will modify the column names\nFew categorical columns have \"Select\" in their entries. Those select are essentially null values because Select appears when someone does not select anything from the dropdown","19ec2a35":"## course_selection_reason column","2bba6d89":"## Observations\nWe will categorize cities based on logical decisions and impute proportionately","620e2de4":"# Data Cleaning\nRename column names\nLong column names make analysis tiring as one has to always refer to column names. Also has impact on charts created later on\nIdeally, we should follow python's preferred Snakecase nomenclature","7a727804":"Mumbai in particular and Maharashtra in general dominates the lead. This is likely due to the fact that the courses are based in Mumbai","5ac3fb28":"## City","faf061a6":"## Observations\nBecause of heavy data imbalance, we can drop the following columns as well\n\n* do_not_call\n* search\n* newspaper_article\n* x_education_forums\n* newspaper\n* digital_advertisement\n* through_recommendations","d2d0691f":"## specialization column","a91e42b4":"## Handle categorical columns with low number of missing values and low representation of categories\nIn this step, we will go through the rest of the categorical columns one by one and\n\n    Merge categories that have low representation\n    Impute the missing values","37ba2c34":"## Categorical columns\n\n\n### Lead Origin","1e0652ef":"## Drop prospect_id column","45e60a6b":"## occupation column","07db2c6c":"# Exploratory Data Analysis\n## Numerical columns","eb9083b6":"## Observation: \nAs can be seen, there are quite a few columns with high number of missing data. Since there are no ways to get data back from reliable sources, we can drop all those columns that have missing values > 40%","57bac2ca":"## lead_origin column","a15c9384":"There are 4 columns that contains Select, which are effectively null values. We are going to make that change","4f301a04":"## Replace \"Select\" category with null values","0ea6d4f0":"## Occupation"}}