{"cell_type":{"126eeb00":"code","4be21f71":"code","8d8f8c77":"code","79b3aa35":"code","2676d23d":"code","e0d4db96":"code","01c5a0f0":"code","62882ee2":"code","fc2aab84":"code","8b66de39":"code","d627d031":"code","efff9aed":"code","3b0b0bd0":"code","c9a1eb0b":"code","06f8b09d":"code","e06f2d88":"code","9f78f399":"code","bc228cb3":"code","788a5fdc":"code","1f6c0890":"code","25ce53ce":"code","93f731dc":"code","e06c07c4":"code","12264d26":"code","226ccfbb":"code","9348ef67":"code","467ef80f":"code","0d66c837":"code","34865324":"code","e3efbf09":"code","047010a5":"code","200a9fb6":"code","de7ef89e":"markdown"},"source":{"126eeb00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/digit-recognizer\/train.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4be21f71":"digits = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')","8d8f8c77":"digits.head(25)","79b3aa35":"X = digits.drop('label',axis=1)\ny= digits['label']","2676d23d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y, test_size =0.2,random_state=1) ","e0d4db96":"import matplotlib.pyplot as plt\npd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 50)\nplt.rcParams['font.size']=14","01c5a0f0":"x_train, x_test = X_train\/255.0,  X_test\/255.0","62882ee2":"from tensorflow.keras.utils import to_categorical\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","fc2aab84":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","8b66de39":"model = Sequential()\n#Defining layers of the model\nmodel.add(Dense(128, activation= 'sigmoid', input_shape = (784,)))\nmodel.add(Dense(64, activation= 'sigmoid'))\nmodel.add(Dense(10, activation= 'softmax'))","d627d031":"model.summary()","efff9aed":"#Compiling the Model\nmodel.compile(optimizer='sgd', loss= 'categorical_crossentropy', metrics=['accuracy'])","3b0b0bd0":"%%time\n#Training the Model\nhistory = model.fit(x_train, y_train, batch_size= 32, epochs=20, validation_split=0.2)","c9a1eb0b":"pd.DataFrame(history.history).plot(figsize=(10,7))\nplt.grid(True)\nplt.show()","06f8b09d":"from tensorflow.keras.layers import BatchNormalization, Activation\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.layers import BatchNormalization, Activation\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.regularizers import  l1, l2\nfrom tensorflow.keras.layers import Dropout","e06f2d88":"model12 = Sequential()\nmodel12.add(Dense(256, activation= 'elu', input_shape = (784,)))\n# model12.add(BatchNormalization())\nmodel12.add(Dropout(0.25))\nmodel12.add(Dense(128, activation= 'elu'))\n# model12.add(BatchNormalization())\nmodel12.add(Dropout(0.25))\nmodel12.add(Dense(64, activation= 'elu'))\n# model12.add(BatchNormalization())\nmodel12.add(Dense(32, activation= 'elu'))\n# model12.add(BatchNormalization())\nmodel12.add(Dense(10, activation= 'softmax'))\nmodel12.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])\nhistory12 = model12.fit(x_train, y_train, batch_size= 64, epochs= 20, validation_split=0.2)","9f78f399":"pd.DataFrame(history12.history).plot(figsize=(10,7))\nplt.grid(True)\nplt.show()","bc228cb3":"model11 = Sequential()\n#Defining layers of the model\nmodel11.add(Flatten(input_shape  = (784,)))\nmodel11.add(Dense(256))\nmodel11.add(BatchNormalization())\n# model11.add(Dropout(0.25))\nmodel11.add(Activation('elu'))\nmodel11.add(Dense(128))\n# model11.add(BatchNormalization())\n# model11.add(Dropout(0.25))\nmodel11.add(Activation('elu')) \nmodel11.add(Dense(64))\nmodel11.add(BatchNormalization())\nmodel11.add(Activation('elu'))\nmodel11.add(Dense(32))\nmodel11.add(BatchNormalization())\nmodel11.add(Activation('elu'))\nmodel11.add(Dense(10, activation= 'softmax'))\nmodel11.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy']) \nhistory11 = model11.fit(x_train, y_train ,batch_size= 64, epochs=32, validation_split=0.3)","788a5fdc":"pd.DataFrame(history11.history).plot(figsize=(10,7))\nplt.grid(True)\nplt.show()","1f6c0890":"model11.evaluate(x_test, y_test, verbose=0)","25ce53ce":"model1 = Sequential()\n#Defining layers of the model\nmodel1.add(Flatten(input_shape  = (784,)))\nmodel1.add(Dense(256))\n# model1.add(BatchNormalization())\n# model11.add(Dropout(0.25))\nmodel1.add(Activation('elu'))\nmodel1.add(Dense(128))\n# model11.add(BatchNormalization())\n# model11.add(Dropout(0.25))\nmodel1.add(Activation('elu')) \nmodel1.add(Dense(64))\nmodel1.add(BatchNormalization())\nmodel1.add(Activation('elu'))\nmodel1.add(Dense(32))\n# model1.add(BatchNormalization())\nmodel1.add(Activation('elu'))\nmodel1.add(Dense(10, activation= 'softmax'))\nmodel1.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy']) \nhistory1 = model1.fit(x_train, y_train ,batch_size= 64, epochs=32, validation_split=0.3)","93f731dc":"model1.evaluate(x_test, y_test, verbose=0)","e06c07c4":"model2 = Sequential()\n#Defining layers of the model\nmodel2.add(Flatten(input_shape  = (784,)))\nmodel2.add(Dense(512))\nmodel2.add(Activation('relu'))\nmodel2.add(Dense(256))\nmodel2.add(Activation('relu'))\nmodel2.add(Dense(128))\nmodel2.add(Activation('relu')) \nmodel2.add(Dense(128))\nmodel2.add(Activation('relu')) \nmodel2.add(Dense(64))\nmodel2.add(Activation('relu'))\nmodel2.add(Dense(32))\nmodel2.add(Activation('relu'))\nmodel2.add(Dense(10, activation= 'softmax'))\nmodel2.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy']) \nhistory2 = model2.fit(x_train, y_train ,batch_size= 64, epochs=50, validation_split=0.2)","12264d26":"model2.evaluate(x_test, y_test, verbose=0)","226ccfbb":"test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","9348ef67":"test.head()","467ef80f":"test = test\/255.0","0d66c837":"pred=model2.predict(test)","34865324":"pred_classes = np.argmax(pred,axis = 1) ","e3efbf09":"results = pd.Series(pred_classes,name=\"Label\")","047010a5":"results","200a9fb6":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submission_digit_divya.csv\",index=False)","de7ef89e":"Normalizing the dataset"}}