{"cell_type":{"9ab24941":"code","79c84da2":"code","3918e9f5":"code","3917f8ac":"code","5704ad65":"code","de829e15":"code","9fea83ce":"code","b81c47eb":"code","87440dd2":"code","3f9b2460":"code","d74bb252":"code","2aee0831":"code","3f7431e2":"code","ea8d193d":"code","b847118e":"code","3ce83b45":"code","2e27f9ad":"code","5e1fb57e":"code","a56e76cd":"code","29f8a0a9":"code","88fe854c":"code","5f14587d":"code","e9fd6d5f":"code","6d31bbe6":"code","4c5f7494":"code","05237d96":"code","ce63bfb4":"code","806a3573":"code","158aa5f2":"code","60dc6a11":"code","2a83d78a":"code","b8bfdab5":"code","b6b327ee":"code","9a307729":"code","89a7858f":"code","7de010a2":"code","0109e79d":"code","b8c1624f":"code","43f46fee":"code","4d40758f":"code","cfe5c19e":"code","19bef487":"code","48afacb1":"code","b37a9213":"code","c89e36e7":"code","b62b6631":"code","d7269d73":"code","1892fad4":"code","5481e59b":"code","47d44603":"code","25ee77fd":"code","6cccaa73":"code","c73beaea":"code","659e9079":"code","a9fe8461":"code","3f2cc886":"code","b326317d":"code","45a8a464":"code","9b754368":"code","a94c6d74":"code","96e4c81f":"code","ed85cff5":"code","e10a1654":"code","7d1adf74":"code","7d76c6e2":"code","74aeda5e":"code","334b9644":"code","49540254":"code","7529fd58":"code","04e993a4":"code","686392f8":"code","77e9af2b":"code","64f1fe91":"code","609e2d53":"code","48dece90":"code","16961f9b":"code","5d5321d0":"code","0f27413d":"code","daa9250d":"code","bd11927d":"code","ff8439f0":"code","4249af4a":"code","f9ebddeb":"code","9d4dba8a":"code","512cbbe2":"code","562cbe71":"code","acb5a402":"code","b11a05de":"code","35d717d5":"code","5c372af3":"code","3f9dd90d":"code","34acb777":"code","de5e9c2f":"code","f7736184":"code","92d0f74d":"code","d4aae03d":"code","1586d32a":"code","6a1f7966":"code","7d3cc3eb":"code","bbddcbc1":"code","07031ab1":"code","68b52abe":"code","603759e5":"code","51fe777b":"code","b8aa3fc3":"code","87fec855":"code","c24888c5":"code","164c6cf3":"code","657fce03":"code","d087fafb":"code","9c5d6536":"code","14ce883c":"code","6284b6b4":"code","420dbfc8":"code","cc107cca":"code","9d7eaab0":"code","db90e32d":"code","73d10393":"code","b507044a":"code","513db1d8":"code","5b1e2dae":"code","2660c113":"code","b296dbb1":"markdown","3d6203e0":"markdown","3e64a487":"markdown","34a40de9":"markdown","d0be8e5f":"markdown","00d3d93c":"markdown","7e8a7bcd":"markdown","431d49eb":"markdown","6c72642e":"markdown","b707b43b":"markdown","87d4cc9d":"markdown","d5df484a":"markdown","9b610e33":"markdown","9ae1ab5e":"markdown","b99de8d3":"markdown","0977fdf9":"markdown","d018470d":"markdown","5581459f":"markdown","4007c0d6":"markdown","be991f6b":"markdown","4b3cfb59":"markdown","f944b331":"markdown","40a33985":"markdown","92d7a23c":"markdown","c5e2cff7":"markdown","8ba1fcc8":"markdown","2cae0a93":"markdown","6bcd429a":"markdown","bd66ddcb":"markdown","4689b16b":"markdown","a64f10a0":"markdown","c27e1e18":"markdown","3842126e":"markdown","1ff9e27b":"markdown","aa9a4101":"markdown","41b83378":"markdown","47ac05db":"markdown"},"source":{"9ab24941":"import numpy as np\nimport pandas as pd \nimport scipy.stats as sci\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nimport re","79c84da2":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')","3918e9f5":"def examine(data):\n    print(\"Data Info \\n\")\n    data.info()\n    print(data.describe())\n    print(\"\\nNumber Of duplicate Values \\n\")\n    temp = data.isnull().sum()\n    print(data.duplicated().value_counts(),\"\\n\")\n    per = (temp \/data.shape[0])*100\n    print(\"Print Null Value Count\\n\")\n    print(\"Number(0) and percentage(1) of null values\\n\")\n    print(pd.concat([temp,per],axis = 1))","3917f8ac":"examine(df_train)","5704ad65":"examine(df_test)","de829e15":"df_train.Cabin.unique(),df_test.Cabin.unique()","9fea83ce":"df_train.Age.hist(bins = 20)","b81c47eb":"df_train.Embarked.fillna(sci.mode(df_train.Embarked)[0][0],inplace = True) ","87440dd2":"df_test.Age.hist(bins = 20)","3f9b2460":"df_test.Fare.fillna(sci.mode(df_train.Fare.dropna())[0][0],inplace = True) ","d74bb252":"df_test.head()","2aee0831":"sns.countplot(x = 'Survived' , data = df_train)","3f7431e2":"x = df_train.groupby(['Sex','Survived'])['Survived'].count()\nsns.countplot(x = 'Sex', hue = 'Survived',data = df_train)\nprint(x)","ea8d193d":"print('Percentage of Females Survived of Pclass = 1 is',df_train[(df_train.Pclass == 1)&(df_train.Sex == 'female')]['Survived'].mean()*100)\nprint('Percentage of Females Survived of Pclass = 2 is',df_train[(df_train.Pclass == 2)&(df_train.Sex == 'female')]['Survived'].mean()*100)\nprint('Percentage of Females Survived of Pclass = 3 is',df_train[(df_train.Pclass == 3)&(df_train.Sex == 'female')]['Survived'].mean()*100)","b847118e":"print('Percentage of Males Survived of Pclass = 1 is',df_train[(df_train.Pclass == 1)&(df_train.Sex == 'male')]['Survived'].mean()*100)\nprint('Percentage of Males Survived of Pclass = 2 is',df_train[(df_train.Pclass == 2)&(df_train.Sex == 'male')]['Survived'].mean()*100)\nprint('Percentage of Males Survived of Pclass = 3 is',df_train[(df_train.Pclass == 3)&(df_train.Sex == 'male')]['Survived'].mean()*100)","3ce83b45":"plt.figure(figsize = [7,8])\nsns.violinplot(x = 'Sex', y = 'Age',hue = 'Survived',data = df_train)","2e27f9ad":"print('Percentage of Males survived age less than 15 are :',df_train[(df_train.Age <= 15) & (df_train.Sex == 'male')]['Survived'].mean()*100)","5e1fb57e":"print(df_train[(df_train.Age < 15)&(df_train.Sex == 'male')].groupby(['Pclass'])['Survived'].mean())\ndf_train[(df_train.Age <= 15) & (df_train.Sex == 'male')].groupby(['Pclass','Survived'])['Survived'].mean()","a56e76cd":"print('Percentage of females survived age less than 15 are :',df_train[(df_train.Age <= 15) & (df_train.Sex == 'female')]['Survived'].mean()*100)","29f8a0a9":"for dataset in [df_train,df_test]:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1","88fe854c":"df_train[['FamilySize', 'Survived']].groupby('FamilySize')['Survived'].mean()","5f14587d":"plt.figure(figsize = [10,8])\nsns.countplot(x = 'FamilySize', hue = 'Survived',data = df_train)","e9fd6d5f":"for dataset in [df_train, df_test]:\n    dataset['IsAlone'] = 1\n    dataset.loc[(dataset.FamilySize > 1), 'IsAlone'] = 0\n\ndf_train.groupby('IsAlone')['Survived'].mean()","6d31bbe6":"df_train[(df_train.FamilySize == 1) & (df_train.Age < 16)].groupby(['Pclass','Sex'])['Survived'].mean()","4c5f7494":"df_train[(df_train.FamilySize == 1) & (df_train.Age.isnull())].groupby(['Pclass','Sex'])['Survived'].mean()","05237d96":"for dataset in [df_train, df_test]:\n    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(df_train['Title'], df_train['Sex'])\n#used code from the discussion section of this competiton","ce63bfb4":"for dataset in [df_train, df_test]:\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Countess', 'Dr', 'Jonkheer', 'Lady', 'Major', 'Rev', 'Sir', 'Don', 'Rev'], 'High' )\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')","806a3573":"print(pd.crosstab(df_train['Title'], df_train['Sex']))\nprint(\"*******************************************************\")\nprint(pd.crosstab(df_test['Title'], df_test['Sex']))","158aa5f2":"df_test['Title'] = df_test['Title'].replace('Dona', 'High')","60dc6a11":"df_train[(df_train.Title == 'Master') | (df_train.Title == 'Miss')].groupby(['Title'])['Age'].mean()","2a83d78a":"df_train[df_train['Title'] == 'Miss'].describe()","b8bfdab5":"df_train[(df_train['Title'] == 'Miss')&(df_train['FamilySize'] != 1)&(df_train['Parch'] != 0)]['Age'].mean()","b6b327ee":"#we have to create a new Title for Female Child which will be a subset of Title Miss\ndf_train.loc[(df_train.Title == 'Miss') & (df_train.Parch != 0) & (df_train.FamilySize > 1), 'Title'] = 'FemaleChild'\ndf_train[(df_train.Title == 'FemaleChild') & (df_train.Age.isnull())]","9a307729":"df_train.groupby(['Title'])['Survived'].mean()","89a7858f":"df_test.loc[(df_test.Title == 'Miss') & (df_test.Parch != 0) & (df_test.FamilySize > 1), 'Title'] = 'FemaleChild'","7de010a2":"df_train['Ticket'].describe()","0109e79d":"df_train[(df_train.Title == 'FemaleChild') & (df_train.Age.isnull())]","b8c1624f":"combined = df_train.append(df_test,sort = False)\ncombined.shape","43f46fee":"combined.groupby(['Pclass', 'Sex', 'Title'])['Age'].mean()","4d40758f":"x = combined.groupby(['Pclass', 'Sex', 'Title'])['Age'].mean().reset_index()","cfe5c19e":"x","19bef487":"def imputeage(row):\n    return x[(x.Pclass == row.Pclass) & (x.Sex == row.Sex) & (x.Title == row.Title)]['Age'].values[0]","48afacb1":"df_train['Age'], df_test['Age'] = [dataset.apply(lambda x: imputeage(x) if np.isnan(x['Age']) else x['Age'], axis = 1)for dataset in [df_train,df_test]]","b37a9213":"df_train.head()","c89e36e7":"df_train.Cabin = df_train.Cabin.astype('str').apply(lambda x : re.findall(\"[a-zA-Z]\",x)[0] if x !='nan' else 'T')","b62b6631":"df_test.Cabin = df_test.Cabin.astype('str').apply(lambda x : re.findall(\"[a-zA-Z]\",x)[0] if x !='nan' else 'T')","d7269d73":"combined.Cabin = combined.Cabin.astype('str').apply(lambda x : re.findall(\"[a-zA-Z]\",x)[0] if x !='nan' else 'T')","1892fad4":"y = combined.groupby(['Pclass','Embarked']).apply(lambda x: x.Cabin.value_counts()).reset_index()","5481e59b":"y.drop(['Cabin'],axis = 1,inplace = True)","47d44603":"y = y[~y.level_2.str.contains(\"T\")]","25ee77fd":"y","6cccaa73":"def imputecabin(row):\n    return y[(y.Pclass == row.Pclass) & (y.Embarked == row.Embarked)]['level_2'].values[0] ","c73beaea":"df_train['Cabin'], df_test['Cabin'] = [dataset.apply(lambda x: imputecabin(x) if x['Cabin'] == 'T' else x['Cabin'], axis = 1)for dataset in [df_train,df_test]]","659e9079":"df_train.head()","a9fe8461":"df_train.Age.plot(kind = 'hist',bins = 50 )","3f2cc886":"df_train.Fare.plot(kind = 'hist')","b326317d":"df_train.FamilySize.plot(kind = 'hist')","45a8a464":"df_train.Title.value_counts()","9b754368":"df_train.Cabin.value_counts()","a94c6d74":"df_train.Embarked.value_counts()","96e4c81f":"df_train.IsAlone.value_counts()","ed85cff5":"df_train.SibSp.value_counts()","e10a1654":"df_train.Parch.value_counts()","7d1adf74":"df_train.Pclass.value_counts()","7d76c6e2":"df_train.Pclass.unique()","74aeda5e":"df_train.SibSp.unique()","334b9644":"df_train.Parch.unique()","49540254":"df_train.Title.unique()","7529fd58":"df_train.head()","04e993a4":"for dataset in [df_train,df_test]: \n    dataset['Age_bin'] = pd.cut(dataset['Age'], bins=[0,12,20,40,120], labels=['Children','Teenage','Adult','Elder'])","686392f8":"for dataset in [df_train,df_test]:    \n    dataset['Fare_bin'] = pd.cut(dataset['Fare'], bins=[0,7.91,14.45,31,120], labels=['Low_fare','median_fare',\n                                                                                      'Average_fare','high_fare'])","77e9af2b":"df_train.head()","64f1fe91":"df_train.Pclass.value_counts()","609e2d53":"df_train['Age'] = df_train['Age'].astype('int')\ndf_train['Fare'] = df_train['Fare'].astype('int')\ndf_test['Age'] = df_test['Age'].astype('int')\ndf_test['Fare'] = df_test['Fare'].astype('int')\ndf_train['Age*Class'] = df_train['Age'] * df_train['Pclass']\ndf_test['Age*Class'] = df_test['Age'] * df_test['Pclass']","48dece90":"df_train.info()","16961f9b":"def checkcomb(data,data2):\n    print(df_train.groupby(data)['Survived'].mean())\n    print(df_train.groupby([data,data2])['Survived'].mean())\n    print(df_train.groupby([data,data2])['Survived'].count())","5d5321d0":"checkcomb('FamilySize','Sex')\ncheckcomb('Cabin','Sex')\ncheckcomb('Title','Sex')\ncheckcomb('Embarked','Sex')\ncheckcomb('Fare_bin','Sex')","0f27413d":"df_train['ClassGen'] = df_train['Pclass'].astype('str') + df_train['Sex']\ndf_test['ClassGen'] = df_test['Pclass'].astype('str') + df_test['Sex']","daa9250d":"df_train['FamGen'] = df_train['FamilySize'].astype('str') + df_train['Sex']\ndf_test['FamGen'] = df_test['FamilySize'].astype('str') + df_test['Sex']","bd11927d":"df_train['AgeSex'] = df_train['Age_bin'].astype('str') + df_train['Sex']\ndf_test['AgeSex'] = df_test['Age_bin'].astype('str') + df_test['Sex']","ff8439f0":"df_train['EmbarkedSex'] = df_train['Embarked'].astype('str') + df_train['Sex']\ndf_test['EmbarkedSex'] = df_test['Embarked'].astype('str') + df_test['Sex']","4249af4a":"df_train['Fare_binSex'] = df_train['Fare_bin'].astype('str') + df_train['Sex']\ndf_test['Fare_binSex'] = df_test['Fare_bin'].astype('str') + df_test['Sex']","f9ebddeb":"df_train['TitleSex'] = df_train['Title'].astype('str') + df_train['Sex']\ndf_test['TitleSex'] = df_test['Title'].astype('str') + df_test['Sex']","9d4dba8a":"df_train['CabinSex'] = df_train['Cabin'].astype('str') + df_train['Sex']\ndf_test['CabinSex'] = df_test['Cabin'].astype('str') + df_test['Sex']","512cbbe2":"df_train.head()","562cbe71":"for dataset in [df_train,df_test]:\n    drop_column = ['Age','Fare','Name','Ticket','Age*Class','Pclass','Age_bin','Embarked','Fare_bin','Title','Cabin','Sex','FamilySize']\n    dataset.drop(drop_column, axis=1, inplace = True)","acb5a402":"sns.heatmap(df_train.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\nfig=plt.gcf()\nfig.set_size_inches(20,12)\nplt.show()","b11a05de":"df_train = pd.get_dummies(data = df_train,columns = [\"TitleSex\",\"AgeSex\",\"EmbarkedSex\",\"Fare_binSex\",'ClassGen','CabinSex','FamGen','IsAlone'])\ndf_test = pd.get_dummies(data =  df_test,columns = [\"TitleSex\",\"AgeSex\",\"EmbarkedSex\",\"Fare_binSex\",'ClassGen','CabinSex','FamGen','IsAlone'])","35d717d5":"from sklearn.model_selection import train_test_split #for split the data\nfrom sklearn.metrics import accuracy_score  #for accuracy_score\nfrom sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nfrom sklearn.metrics import confusion_matrix #for confusion matrix","5c372af3":"df_test.info()","3f9dd90d":"Y = df_train.Survived\ndf_train.drop(['Survived','PassengerId'],axis = 1,inplace = True)","34acb777":"from sklearn.model_selection import train_test_split\nx_train,y_train = np.array(df_train),np.array(Y)\nx_val,y_val = np.array(df_train),np.array(Y)\n#x_train,x_val,y_train,y_val = train_test_split(np.array(df_train),np.array(Y),test_size = 0.3,random_state = 0,shuffle = False)","de5e9c2f":"from sklearn.preprocessing import StandardScaler \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nsc=StandardScaler()","f7736184":"x_train=sc.fit_transform(x_train)\nx_val = sc.fit_transform(x_val)","92d0f74d":"reg = LogisticRegression().fit(x_train, y_train)\nprint(reg.score(x_train, y_train)) #0.14\nprint(reg.score(x_val, y_val))","d4aae03d":"from sklearn.feature_selection import SelectFromModel,RFE\nsmf = SelectFromModel(reg,threshold = -np.inf,max_features = 5)\nsmf.fit(x_train,y_train)\nfeature_idx = smf.get_support()\nfeature_name = df_train.columns[feature_idx]\nfeature_name","1586d32a":"coeff_df = pd.DataFrame(df_train.columns)\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(reg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","6a1f7966":"coeff_df[abs(coeff_df['Correlation']) > 0.2]['Feature']","7d3cc3eb":"print(np.round(abs(reg.coef_),decimals = 2) > 0.2)","bbddcbc1":"predictors = x_train\nselector = RFE(reg,n_features_to_select = 1)\nselector = selector.fit(predictors,y_train)","07031ab1":"order = selector.ranking_\norder","68b52abe":"feature_ranks = []\nfor i in order:\n    feature_ranks.append(f\"{i}. {df_train.columns[i-1]}\")\nfeature_ranks","603759e5":"from sklearn.model_selection import train_test_split\n#x_train,y_train = np.array(df_train),np.array(Y)\n#x_val,y_val = np.array(df_train),np.array(Y)\nx_train,x_val,y_train,y_val = train_test_split(np.array(df_train),np.array(Y),test_size = 0.3,random_state = 0,shuffle = False)","51fe777b":"x_train=sc.fit_transform(x_train)\nx_val = sc.fit_transform(x_val)","b8aa3fc3":"reg = LogisticRegression(dual = False,random_state = 5,C= 0.14).fit(x_train, y_train)\nprint(reg.score(x_train, y_train)) #0.14\nprint(reg.score(x_val, y_val))","87fec855":"from sklearn.svm import LinearSVC\nregr = LinearSVC(penalty = 'l1',dual = False,loss = 'squared_hinge')\nregr.fit(x_train, y_train)\nprint(regr.score(x_train, y_train))\nprint(regr.score(x_val, y_val))","c24888c5":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf","164c6cf3":"model = Sequential()\n\nmodel.add(Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n\n# The Output Layer :\nmodel.add(Dense(1,activation='sigmoid',kernel_regularizer='l1'))\n\nmodel.compile(optimizer=Adam(learning_rate=0.1, epsilon=1e-07, decay=0.01),loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel.fit(x_train,y_train,batch_size = 64,validation_data=(x_val,y_val),epochs=500,use_multiprocessing=True)","657fce03":"df_train.shape","d087fafb":"x_test = df_test","9c5d6536":"x_test = sc.transform(x_test.drop(['PassengerId'],axis = 1))","14ce883c":"svm_out = regr.predict(x_test)\nprint(svm_out)","6284b6b4":"nn_out = model.predict(x_test)","420dbfc8":"for i,j in enumerate(nn_out):\n    if j < 0.5 :\n        nn_out[i] = 0\n    else :\n        nn_out[i] = 1 ","cc107cca":"print(nn_out.flatten().astype('int'))","9d7eaab0":"log_out = reg.predict(x_test)\nprint(log_out)","db90e32d":"x_PassengerId = np.array(df_test['PassengerId'])","73d10393":"dict = {'PassengerId': x_PassengerId, 'Survived': nn_out.flatten().astype('int') }  \n     \ndf = pd.DataFrame(dict) \n  \n# saving the dataframe \ndf.to_csv('21thsub.csv',index=False)","b507044a":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(x_train, y_train)\nY_pred = random_forest.predict(x_test)\nrandom_forest.score(x_train, y_train)\nacc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)\nacc_random_forest","513db1d8":"Y_pred","5b1e2dae":"x_PassengerId = np.array(df_test['PassengerId'])","2660c113":"dict = {'PassengerId': x_PassengerId, 'Survived': Y_pred_rf}  \n     \ndf = pd.DataFrame(dict) \n  \n# saving the dataframe \ndf.to_csv('21thsub_rand.csv',index=False)","b296dbb1":"### Train Data Over View","3d6203e0":"Converted the age into 4 bins  Children, Teenage, Adult, Elder","3e64a487":"Above output gives us some insights that if you are a child then you've really had better chances of survival than aged people so now while impute Age we have to care somewhat about Age as well other than Pclass and sex. \nNow the points comes how to can we get to know whether the person is child or not if Age is NULL. we've seen that in name column we've Titles like Master, Miss and etc... so we will take that title and make a column to know whether a person is child or not ","34a40de9":"# Cabin Imputaion","d0be8e5f":"As we've seen above Percentage of male surviving is less than 20% but for children age less than 15 percentage of surviving goes up to 52% and will go further up after we'll imputer NaN value of Age of Males.","00d3d93c":"#### Since Cabin has more than 76% of null values we remove the column","7e8a7bcd":"as we can notice we have so many titles for the name doing Simple Hot Encoding will is somewhat increaing and creating sparse features. so what we can do now is simply group them and reduce the Title.","431d49eb":"so as we can clearly see no. families having family size more than 4 are so few. So it doesn't mean much to for survial category so we can now make a new featrure using this observation 'IsAlone' which have value 0 if family size > 1, and have value 1 if family size = 1.","6c72642e":"From Obove outputs we can easily conclude that while rescuing Pclass = 1 people were given preference both male and female.\nWe can further dive Age wise surivived percentage of People.","b707b43b":"# Data Modeling","87d4cc9d":"Majority people aborad couldn't survived.","d5df484a":"so now we have an interesting observation that if one was travelling in a family than it has higher chances to survive than for solo traveller.\nfor family size 2-3-4 chances of survival increases but after that it decreases to a great extent so we need to analysis this more that why is that hapening","9b610e33":"this shows that title has some sort of help while rescuing ","9ae1ab5e":"# EDA (Exploratory Data Analysis)","b99de8d3":"# Data Cleaning","0977fdf9":"Function for checking relation of column with sex","d018470d":"This feature will help in improving the accuracy score.","5581459f":"# Age Imputation using the titles ","4007c0d6":"White Dot in the middle in the graph shows the median.\nFrom the above plot we can conclude many things:-\n    1. As we can see Survived plot of Male is much much wider from age 0 to 15 or so. From this we can conclude childrens were given preferences.\n    2. Survived = 0 plot for Males is much wider than Survived = 1 from age 60-80 or so.","be991f6b":"#### Now we look at Embarked","4b3cfb59":"# Overview\nPassengerId is the unique id of the row and it doesn't have any effect on target\n\nSurvived is the target variable we are trying to predict (0 or 1):\n1 = Survived\n0 = Not Survived\n\nPclass (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has 3 unique values (1, 2 or 3):\n1 = Upper Class\n2 = Middle Class\n3 = Lower Class\n\nName, Sex and Age are self-explanatory\n\nSibSp is the total number of the passengers' siblings and spouse\n\nParch is the total number of the passengers' parents and children\n\nTicket is the ticket number of the passenger\n\nFare is the passenger fare\n\nCabin is the cabin number of the passenger\n\nEmbarked is port of embarkation and it is a categorical feature which has 3 unique values (C, Q or S):\nC = Cherbourg\nQ = Queenstown\nS = Southampton","f944b331":"#### Now we look at Fare","40a33985":"We can clearly observe from graph that females are given priority while rescuing as majority of the females survived.\nwhereas majority of Males died.\nStill we are not clear about the people who Survived as of what age group people survived or what Class of People Survived","92d7a23c":"so what happened in above is that we are returning a value from x dataframe according to Pclass, Sex, Title values of row..\nYou must be wondereing why is values[0] doing, Actually x[(x.Pclass == row.Pclass) & (x.Sex == row.Sex) & (x.Title == row.Title)]['Age'] will return a row from x so \".values\" will convert into a an array.","c5e2cff7":"## Test Data","8ba1fcc8":"This output clears more about the data of male aged less than 16. As we can see all chilren of Pclass 1 and Pclass 2 survived but not the same for children of Pclass 3.","2cae0a93":"#### Since Cabin has more than 76% of null values we remove the column","6bcd429a":"## Same On Test Data","bd66ddcb":"## Train Data","4689b16b":"## Columns to Drop","a64f10a0":"### Test Data OverView","c27e1e18":"#### Now we look at age","3842126e":"## Combining columns that have relation with Sex","1ff9e27b":"Converted the Fare into 4 bins  Low_fare, median_fare, Average_fare, high_fare ","aa9a4101":"#### Now we look at age","41b83378":"so from above output it is further clear than min age for a female having Title 'Miss' can be 0.75 and max age can be 63.","47ac05db":"we are left with Dona in Test dataset we'll replace that also with High"}}