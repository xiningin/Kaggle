{"cell_type":{"4fd63a8e":"code","636d1884":"code","78d27366":"code","804dc240":"code","7ac31eef":"code","82c8b631":"code","c5cfb971":"code","39340280":"code","28bfec97":"code","c3aed564":"code","ff37e141":"code","e9606c91":"code","e53227fa":"code","30880374":"code","6b1da072":"code","8f932d1f":"code","3ef52f91":"code","8640f84c":"code","1a450de8":"code","79732d0d":"code","18d2e762":"code","250b2aae":"code","473f7266":"code","3dc1dfb6":"code","62c845d6":"code","6dcfcfc3":"code","9352ae66":"code","817b61f7":"code","e82cbf11":"code","01cad647":"code","92486ec5":"code","200f8be0":"markdown","fbd21a11":"markdown","5e51185a":"markdown","aaa5e1aa":"markdown","66ad9c42":"markdown","c994efd4":"markdown","a11ba15e":"markdown","25b62272":"markdown"},"source":{"4fd63a8e":"# Import the libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport pathlib\nimport matplotlib.pyplot as plt","636d1884":"# Visualize Dataset\nurl = \"..\/input\/chessman-image-dataset\/chessman-image-dataset\/Chessman-image-dataset\/Chess\"\ndir_chess = pathlib.Path(url)\nlength = len(list(dir_chess.glob('*\/*.*')))\nprint(f\"The length of Dataset is: {length}\")","78d27366":"# Verificando os Tipos de Arquivos\ndef tipo_arquivo(diretorio):\n    tipo = []\n    for _, _, arquivos in tf.io.gfile.walk(diretorio):\n        for arquivo in arquivos:\n            tipo.append(arquivo.upper().split('.')[-1])\n    return tipo\n\ndef extract_class(diretorio):\n    classes = []\n    for diretorio, _, arquivos in tf.io.gfile.walk(diretorio):\n            for arquivo in arquivos:\n                classes.append(diretorio.split('\/')[-1])\n    return classes\n\n# Plotando os Tipos de arquivos:\ntp = pd.Series(tipo_arquivo(dir_chess))\nlabels = tp.unique()\ny = tp.value_counts()\n\n\nwidth = 0.9  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(15,8))\nbar = ax.bar(labels, y, width, label='Tipos')\n\n# Formating Barchart\nax.legend(fontsize=16)\nax.bar_label(bar, padding=3, fontsize=15, color='r', fontweight='bold')\nax.set_title('TIPOS DE ARQUIVOS', fontweight= 'bold', fontsize=24)\nax.tick_params(axis='both', labelsize=14)\nax.set_xticks(labels)\n\n# Retirando excessos no Gr\u00e1fico\nax.axes.yaxis.set_visible(False) # Retirando os valores de Y\n\nax.spines['top'].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"left\"].set_visible(False)\nax.spines[\"bottom\"].set_visible(False)\nax.set_xticklabels(labels, fontweight= 'bold')\nplt.show()","804dc240":"class_pieces = pd.Series(extract_class(dir_chess))\nlabels = np.unique(class_pieces.values)\nexplode = (np.arange(0,len(labels)) * 0) + 0.01\nplt.figure(figsize=(10,8))\nplt.pie(class_pieces.value_counts(), labels = labels,autopct='%1.1f%%', shadow=True,\n        startangle=90,\n        textprops={\"fontsize\":12, 'fontweight':'bold'},\n       explode = explode)  # Pie chart\nplt.axis('equal')\nplt.title('Proportion of each observed category', fontsize=24, fontweight='bold')  # Proportion per category\nplt.show()","7ac31eef":"def display_examples(class_names, images, labels, title='Some examples of images of the dataset'):\n    \"\"\"Display 25 images\"\"\"\n    fig = plt.figure(figsize=(20, 10))\n    fig.suptitle(title, fontsize=26, fontweight='bold')\n    for i in range(25):\n        plt.subplot(5, 5, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        images = np.squeeze(images)\n        plt.imshow(images[i])\n        plt.xlabel(class_names[labels[0][i]], fontweight='bold', fontsize=14)\n    plt.show()","82c8b631":"train_ds = tf.keras.utils.image_dataset_from_directory(directory=dir_chess)\nclass_names = train_ds.class_names\nimage, label = [], []\nfor images, labels in train_ds.take(1):\n    image.append(images\/255.)\n    label.append(labels.numpy().astype(int))\n\ndisplay_examples(class_names=class_names, images=image, labels=label)","c5cfb971":"# Inspecionando as Imagens para verificar os tamanhos\n\nfor i, example in enumerate(train_ds.take(5)):\n    print('Batch {} shape: {} label: {}'.format(i+1, example[0].shape,example[1]))","39340280":"IMAGE_RES = 256\ndef scale(image, label):\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image, label","28bfec97":"train_ds = tf.keras.utils.image_dataset_from_directory(directory=dir_chess,\n                                                       subset='training',\n                                                       validation_split=0.2,\n                                                       seed= 0)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(directory=dir_chess,\n                                                        subset='validation',\n                                                        validation_split=0.2,\n                                                        seed=0,)","c3aed564":"for img, lbl in train_ds.take(1):\n    img.shape, lbl.shape\npiece_shape, just_img = img.shape[1:], img.shape[1:3]\n\nprint (f\"Piece of Shape: {piece_shape} - Just Image: {just_img}\")","ff37e141":"SHUFFLE_SIZE = 100\ntrain_fds = train_ds.map(scale).shuffle(SHUFFLE_SIZE).cache().prefetch(1)\ntest_fds = test_ds.map(scale).cache().prefetch(1)\n\n# Build the Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\nnum_classes = len(class_names) # Get the number classes\n\n# Clear and set random seed\ntf.keras.backend.clear_session()\nnp.random.seed(0)\ntf.random.set_seed(0)\n\n# Create a Multilayer CNN\nchess_model = tf.keras.Sequential([\n    Conv2D(32, 3, activation='relu', input_shape=piece_shape),\n    MaxPooling2D(),\n    Conv2D(32, 3, activation='relu'),\n    MaxPooling2D(),\n    Conv2D(32, 3, activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(num_classes, activation='softmax')\n    ])\n\n# Compile and Train Model\nEPOCH = 20\n\nchess_model.compile(\n    optimizer = 'adam',\n    loss = tf.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy']\n)\n\nhistory = chess_model.fit(\n    train_fds,\n    validation_data=test_fds,\n    epochs=EPOCH)","e9606c91":"def plot_accuracy_loss(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(EPOCH)\n    plt.figure(figsize=(24, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.legend(loc='best')\n    plt.title('Training and Validation Accuracy', fontsize=20, fontweight='bold')\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='best')\n    plt.title('Training and Validation Loss', fontsize=20, fontweight='bold')\n    plt.show()\n\nplot_accuracy_loss(history)","e53227fa":"idx = 0\nfor batch_images, _ in train_fds.take(1):\n    print(f\"Image shape: {batch_images.shape}\")\n    \nour_image = batch_images[idx]\nplt.imshow(our_image)\nplt.axis('off')\nplt.grid(visible=None)\nplt.show()","30880374":"# Create a Functions to Show Images\ndef show(original_img, trans_img):\n    f = plt.figure(figsize=(6, 6))\n    f.add_subplot(1,2,1)\n    plt.imshow(original_img)\n    plt.axis('off')\n    f.add_subplot(1,2,2)\n    plt.imshow(trans_img)\n    plt.axis('off')\n    plt.show(block=True)\n\ndef show_images(img, indx, trans, p1=None, p2=None, b=False):\n    plt.figure(figsize=(10, 10))\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        if not b:\n            new_img = trans(img[indx])\n        elif p2==None:\n            new_img = trans(img[indx], p1)\n            new_img = np.clip(new_img, 0, 1)\n        else:\n            new_img = trans(img[indx], p1, p2)\n            new_img = np.clip(new_img, 0, 1)\n        plt.imshow(new_img)\n        plt.axis('off')\n\n# Crop an Image\nnew_image = tf.image.random_crop(our_image, [120, 120, 3])\nshow_images(batch_images, idx, tf.image.random_crop,[120, 120, 3], b=True)","6b1da072":"from tensorflow.keras.layers import RandomFlip\nfrom tensorflow.keras.layers import RandomRotation\nfrom tensorflow.keras.layers import RandomZoom\nfrom tensorflow.keras.layers import RandomTranslation\nfrom tensorflow.keras.layers import RandomContrast\n\ndata_augmentation = tf.keras.Sequential([\n    RandomFlip('horizontal'),\n    RandomRotation(0.1),\n    RandomZoom(0.2),\n    RandomContrast(0.1),\n    RandomTranslation(height_factor=0.2, width_factor=0.2)\n    ])\nplt.figure(figsize=(10, 10))\nfor images, _ in train_fds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0])\n        plt.axis('off')","8f932d1f":"# Import Model\ntf.keras.backend.clear_session()\nnp.random.seed(0)\ntf.random.set_seed(0)\n\n# Create a Multilayer CNN\nchess_model = tf.keras.Sequential([\n    data_augmentation, # Include New Layer\n    Conv2D(32, 3, activation='relu',\n    input_shape=piece_shape),\n    MaxPooling2D(),\n    Conv2D(32, 3, activation='relu'),\n    MaxPooling2D(),\n    Conv2D(32, 3, activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(num_classes, activation='softmax')\n    ])\n\n# Compile and Train Model\nEPOCH = 20\noptimizer = tf.keras.optimizers.SGD()\n\nchess_model.compile(\n    optimizer = optimizer,\n    loss = tf.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy']\n)\n\nhistory = chess_model.fit(\n    train_fds,\n    validation_data=test_fds,\n    epochs=EPOCH)","3ef52f91":"# Plotting Accuracy\nplot_accuracy_loss(history)","8640f84c":"## Vamos mexer na Learning Rate e verificar se temos par\u00e2metros melhores.\ninitial_history = chess_model.fit(\n    train_fds,\n    validation_data=test_fds,\n    epochs=EPOCH,\n    callbacks=[\n        tf.keras.callbacks.LearningRateScheduler(\n            lambda epoch: 1e-3 * 10 ** (epoch \/ 30)\n    )\n    ]\n)","1a450de8":"learning_rates = 1e-3 * (10 ** (np.arange(EPOCH) \/ 30))\nplt.figure(figsize=(15,7))\nplt.semilogx(\n    learning_rates, \n    initial_history.history['loss'], \n    lw=3, color='#000'\n)\n\nplt.title('Learning rate vs. loss', size=25, fontweight='bold')\nplt.xlabel('Learning rate', size=14, fontweight='bold')\nplt.ylabel('Loss', size=14, fontweight='bold')\nplt.show()","79732d0d":"inital_ds = pd.DataFrame(initial_history.history)\nindex_min_loss = inital_ds['loss'].idxmin() \nbest_lr_loss = inital_ds['lr'][index_min_loss]\nprint(f\"The best learning rate (Loss): {best_lr_loss:.2}\")","18d2e762":"plot_accuracy_loss(history)","250b2aae":"import tensorflow_hub as hub\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\ndef format_image(image, label):\n    image = tf.image.resize(image, (224, 224)) \/255.0\n    return image, label\n\ntrain_batches = train_ds.shuffle(100).map(format_image).prefetch(1)\ntest_batches = test_ds.map(format_image).prefetch(1)\n\n# Extract Pre-trained Model (imagenet21k_b0)\nurl = \"https:\/\/tfhub.dev\/google\/imagenet\/efficientnet_v2_imagenet1k_b1\/classification\/2\"\n\nfeature_extration_nm = hub.KerasLayer( url, input_shape=(224, 224, 3))","473f7266":"# Freeze Pre-Trained Model\nfeature_extration_nm.trainable = False\n\n# Clear and seed\ntf.keras.backend.clear_session()\nnp.random.seed(0)\ntf.random.set_seed(0)\n\nchess_model_pt = tf.keras.Sequential([\n    feature_extration_nm,\n    Dropout(0.5),\n    Dense(num_classes)\n    \n])\n\n# Compile and Train Model\noptimizer = tf.keras.optimizers.Adam()\nchess_model_pt.compile(\n    optimizer=optimizer,\n    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'])\n\nEPOCH = 20\nhistory = chess_model_pt.fit(\n    train_batches,\n    validation_data=test_batches,\n    epochs=EPOCH)","3dc1dfb6":"# Plot Visualization\nplot_accuracy_loss(history)","62c845d6":"test_loss, test_accuracy = chess_model_pt.evaluate(test_batches)  # Evaluate on Test Set\nprint('Test accuracy: {:.2f}% loss: {:.2f}'.format(test_accuracy * 100, test_loss))","6dcfcfc3":"## Vamos mexer na Learning Rate e verificar se temos par\u00e2metros melhores.\ninitial_history = chess_model_pt.fit(\n    train_batches,\n    validation_data=test_batches,\n    epochs=EPOCH,\n    callbacks=[\n        tf.keras.callbacks.LearningRateScheduler(\n            lambda epoch: 1e-3 * 10 ** (epoch \/ 30)\n    )\n    ]\n)","9352ae66":"learning_rates = 1e-3 * (10 ** (np.arange(EPOCH) \/ 30))\n\nplt.semilogx(\n    learning_rates, \n    initial_history.history['loss'], \n    lw=3, color='#000'\n)\nplt.title('Learning rate vs. loss', size=20)\nplt.xlabel('Learning rate', size=14)\nplt.ylabel('Loss', size=14)\nplt.show()","817b61f7":"inital_ds = pd.DataFrame(initial_history.history)\nindex_min_loss = inital_ds['loss'].idxmin() \nbest_lr_loss = inital_ds['lr'][index_min_loss]\nprint(f\"The best learning rate (Loss): {best_lr_loss:.2}\")","e82cbf11":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\noptimizer = tf.keras.optimizers.Adam(learning_rate=best_lr_loss)\nchess_model_pt.compile(\n    optimizer=optimizer,\n    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'])\n\nEPOCH = 100\nhistory = chess_model_pt.fit(\n    train_batches,\n    validation_data=test_batches,\n    epochs=EPOCH,\n    callbacks=callback)","01cad647":"EPOCH = len(history.history['loss'])\nplot_accuracy_loss(history)","92486ec5":"im_image_batch, im_label_batch = next(iter(test_batches))\nim_images = im_image_batch.numpy()\nim_labels = im_label_batch.numpy()\n\nim_named_labels = [class_names[im_labels[i]] for i, lbl in enumerate(range(32))]\n\nim_named_pred = pred_ks = np.argmax(chess_model_pt.predict(test_batches), axis=-1)\n\n# Plotting Predictions\n# Plot the first X (num_rows * num_cols) test images\n# (true and predicted labels)\n\nnum_rows = 5\nnum_cols = 4\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nplt.suptitle(\"'Model predictions (Black: correct, Red: incorrect)\", fontsize=20)\nfor i in range(num_images):\n  ax = plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plt.imshow(im_images[i])\n  title = class_names[im_labels[i]] + ' (' + class_names[im_named_pred[i]] + ') '\n  plt.title(title)\n  if class_names[int(im_labels[i])] != class_names[im_named_pred[i]]:\n    ax.set_title(title, style='italic', color='red')\n  plt.axis('off')\nplt.tight_layout()","200f8be0":"# **Chess Model**","fbd21a11":"## Predicitions ","5e51185a":"## Transfer Learning","aaa5e1aa":"## Applying Augmentation","66ad9c42":"## Visualize Performance","c994efd4":"## Building Pipeline","a11ba15e":"## **Exploring data**","25b62272":"## Reformating Images"}}