{"cell_type":{"328db5ed":"code","c9ca3c7e":"code","b3d9b47a":"code","0ddd33cd":"code","a636ca3b":"code","e2898982":"code","9c21e73d":"code","fd875af1":"code","f428cf51":"code","32e9a999":"code","900cee08":"code","40c4d40e":"code","5dd87924":"code","573e8971":"code","09f6130c":"code","10ddb523":"code","b2d1fb52":"code","1a0d5b9a":"code","1665c0bf":"code","36015cef":"code","5717f829":"code","2aac6e56":"markdown","a3433377":"markdown"},"source":{"328db5ed":"import os\nfor filenames in os.listdir('\/kaggle\/input\/'):\n        print(os.path.join(\"\/kaggle\/input\", filenames))","c9ca3c7e":"import numpy as np \nimport pandas as pd\n\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\nimport matplotlib.pyplot as plt","b3d9b47a":"base_dir = os.path.join(\"\/kaggle\/input\/terrain-images\/Images\/\")\nprint(\"Base directory --> \", os.listdir(base_dir))","0ddd33cd":"# Train set\ntrain_dir = os.path.join(base_dir + \"Train\/\")\nprint(\"Train --> \", os.listdir(train_dir),end = \"\\n\\n\")\n\n# Test set\ntest_dir = os.path.join(base_dir +\"Test\/\")\nprint(\"Test --> \", os.listdir(test_dir))","a636ca3b":"# Displaying random image from the dataset\n\nfig, ax = plt.subplots(1, 7, figsize=(15, 10))\n\nsample_highway = random.choice(os.listdir(train_dir + \"Highway\"))\nimage = load_img(train_dir + \"Highway\/\" + sample_highway)\nax[0].imshow(image)\nax[0].set_title(\"Highway\")\nax[0].axis(\"Off\")\n\nsample_cropland = random.choice(os.listdir(train_dir + \"Crop Land\"))\nimage = load_img(train_dir + \"Crop Land\/\" + sample_cropland)\nax[1].imshow(image)\nax[1].set_title(\"Crop Land\")\nax[1].axis(\"Off\")\n\nsample_forest = random.choice(os.listdir(train_dir + \"Forest\"))\nimage = load_img(train_dir + \"Forest\/\" + sample_forest)\nax[2].imshow(image)\nax[2].set_title(\"Forest\")\nax[2].axis(\"Off\")\n\nsample_residential = random.choice(os.listdir(train_dir + \"Residential\"))\nimage = load_img(train_dir + \"Residential\/\" + sample_residential)\nax[3].imshow(image)\nax[3].set_title(\"Residential\")\nax[3].axis(\"Off\")\n\nsample_industrial = random.choice(os.listdir(train_dir + \"Industrial\"))\nimage = load_img(train_dir + \"Industrial\/\" + sample_industrial)\nax[4].imshow(image)\nax[4].set_title(\"Industrial\")\nax[4].axis(\"Off\")\n\nsample_river = random.choice(os.listdir(train_dir + \"River\"))\nimage = load_img(train_dir + \"River\/\" + sample_river)\nax[5].imshow(image)\nax[5].set_title(\"River\")\nax[5].axis(\"Off\")\n\nsample_pasture = random.choice(os.listdir(train_dir + \"Pasture\"))\nimage = load_img(train_dir + \"Pasture\/\" + sample_pasture)\nax[6].imshow(image)\nax[6].set_title(\"Pasture\")\nax[6].axis(\"Off\")\n\nplt.show()","e2898982":"model = tf.keras.models.Sequential([\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    \n    tf.keras.layers.Dense(7, activation='softmax')\n])","9c21e73d":"model.summary()","fd875af1":"model.compile(loss = 'categorical_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","f428cf51":"train_datagen = ImageDataGenerator(\n      rescale = 1.\/255,\n      rotation_range = 40,\n      width_shift_range = 0.2, # Shifting image width by 20%\n      height_shift_range = 0.2,# Shifting image height by 20%\n      shear_range = 0.2,       # Rotation across X-axis by 20%\n      zoom_range = 0.2,        # Image zooming by 20%\n      horizontal_flip = True,\n      fill_mode = 'nearest',\n      validation_split = 0.1)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = (64,64),\n    class_mode = 'categorical',\n    batch_size = 100\n)","32e9a999":"history = model.fit_generator(\n      train_generator,\n      steps_per_epoch = np.ceil(20986\/100),  # 20986 images = batch_size * steps\n      epochs = 50,\n      verbose = 1)","900cee08":"acc = history.history['accuracy']\nloss = history.history['loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(7,7))\n\nplt.plot(epochs, acc, 'g', label='Training accuracy')\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure(figsize=(7,7))\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","40c4d40e":"model.save('\/kaggle\/working\/model.h5')\nmodel.save_weights('\/kaggle\/working\/model_weights.h5')","5dd87924":"len(os.listdir(test_dir))","573e8971":"test_img = os.listdir(test_dir)\n\ntest_df = pd.DataFrame({'Image': test_img})\ntest_df.head()","09f6130c":"test_gen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    test_dir, \n    x_col = 'Image',\n    y_col = None,\n    class_mode = None,\n    target_size = (64, 64),\n    batch_size = 7,\n    shuffle = False\n)","10ddb523":"predict = model.predict_generator(test_generator, steps = int(np.ceil(14\/7)))","b2d1fb52":"# Identifying the classes\n\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\nlabel_map","1a0d5b9a":"test_df['Label'] = np.argmax(predict, axis = -1)\n\ntest_df['Label'] = test_df['Label'].replace(label_map)","1665c0bf":"test_df","36015cef":"v = random.randint(0, 24)\n\nplt.figure(figsize=(12, 24))\nfor index, row in test_df.iterrows():\n    filename = row['Image']\n    category = row['Label']\n    img = load_img(test_dir +\"\/\" + filename, target_size = (150, 150))\n    plt.subplot(7, 2, index + 1)\n    plt.imshow(img)\n    plt.xlabel(filename + ' ( ' + \"{}\".format(category) + ' )' )\nplt.tight_layout()\nplt.show()","5717f829":"lis = []\nfor ind in test_df.index: \n    if(test_df['Label'][ind] in test_df['Image'][ind]):\n        lis.append(1)\n    else:\n        lis.append(0)\nprint(\"Accuracy of the model on test data is {:.2f}%\".format((sum(lis)\/len(lis))*100))","2aac6e56":"![ezgif.com-gif-maker.gif](attachment:ezgif.com-gif-maker.gif)","a3433377":"## Image Augmentation"}}