{"cell_type":{"763fe1b6":"code","6a23b54a":"code","93d48afa":"code","2425c917":"code","3954bdbd":"code","30c5bf74":"code","d470f1bf":"code","ed18a88c":"code","2f5fcbcf":"code","f845d466":"code","1a75ac63":"code","eb3d9e43":"code","d1672955":"markdown","f4667a48":"markdown","097c7d5e":"markdown","e2e1fe5b":"markdown","117d74fd":"markdown","1460ff51":"markdown","d2836777":"markdown","352b1307":"markdown","aa73ea2c":"markdown","cd40bb84":"markdown","3a710e38":"markdown","65c059fa":"markdown"},"source":{"763fe1b6":"import pandas as pd\nimport seaborn as sns\nimport dateutil.parser\nimport plotly.graph_objects as go","6a23b54a":"df = pd.read_csv(\"..\/input\/internet-articles-data-with-users-engagement\/articles_data.csv\", index_col=0)\ndf.head()","93d48afa":"df.info()","2425c917":"df.describe()","3954bdbd":"top_publishers = df[\"source_name\"].value_counts().head(5)\ntop_publishers","30c5bf74":"top_publishers_list = top_publishers.index.tolist()\n\ndf_sample = df[df[\"source_name\"].isin(top_publishers_list)]","d470f1bf":"def top_n(df, n, main_field, grouping_fields, sumi=False):        \n    all_cols = grouping_fields+[main_field]\n    titles_df = df.dropna(subset=all_cols)\n    titles_df = titles_df[all_cols]\n    if sumi:\n        titles_df = titles_df.groupby(grouping_fields).sum()\n    titles_df = titles_df.sort_values([main_field], ascending=False)\n    titles_df.rename(columns={main_field: main_field+'_sum'}, inplace=True)\n    return titles_df.head(n)\n\ntop_n(df_sample, 10, main_field='engagement_reaction_count', grouping_fields=['title', 'source_name'])","ed18a88c":"top_n(df_sample, 10, main_field='engagement_share_count', grouping_fields=['title', 'source_name'])","2f5fcbcf":"top_n(df_sample, 10, sumi=True, main_field='top_article', grouping_fields=['author'])","f845d466":"def engagement_per_publisher(df):\n    epp = []\n    publishers = list(df['source_name'].unique())\n    engagement_columns = ['engagement_reaction_count', 'engagement_comment_count', 'engagement_share_count']\n    for ec in engagement_columns:\n        df_eng = df.groupby(['source_name'])[ec].agg('sum')\n        epp.append((ec, df_eng.tolist()))\n    return publishers, epp\n\n\npublishers, engagements_per_publisher = engagement_per_publisher(df_sample)\n\nfig = go.Figure(go.Bar(x = publishers, y=engagements_per_publisher[0][1], name=engagements_per_publisher[0][0]))\n\nfor eng_name, eng_results in engagements_per_publisher[1:]: \n    fig.add_trace(go.Bar(x = publishers, y=eng_results , name=eng_name))\n\nfig.update_layout(barmode='stack', xaxis={'categoryorder':'array'})\nfig.show()","1a75ac63":"def articles_per_publisher(df):\n    df = df.dropna(subset=['source_name', 'published_at'])\n    def parse_date(date_string):\n        do = dateutil.parser.parse(date_string)\n        return do.date().isoformat()\n    df[\"published_at_day\"] = df['published_at'].apply(lambda x : parse_date(x))\n    df_date_pub = df.sort_values(['source_name', 'published_at_day'])\n    dates_list = df_date_pub['published_at_day'].unique().tolist()\n    \n    df_date_pub = df.groupby(['source_name', 'published_at_day'])['published_at_day'].agg('count')\n    list_date_pub = df_date_pub.tolist()\n    p_len = len(dates_list)\n    ldp_chunks = [list_date_pub[x:x+p_len] for x in range(0, len(list_date_pub), p_len)]\n    return ldp_chunks, dates_list\n\nldp_chunks, dates_list = articles_per_publisher(df_sample)\n\nfig = go.Figure(go.Bar(x = dates_list, y=ldp_chunks[0], name=top_publishers_list[0]))\n\nfor publisher, count in zip(top_publishers_list[1:], ldp_chunks[1:]): \n    fig.add_trace(go.Bar(x = dates_list, y=count , name=publisher))\n\nfig.update_layout(barmode='stack', xaxis={'categoryorder':'array', 'categoryarray':dates_list})\nfig.show()","eb3d9e43":"df_temp = df_sample \\\n    .groupby(['source_id'])['source_name','top_article', 'engagement_reaction_count', 'engagement_comment_count','engagement_share_count', 'engagement_comment_plugin_count']\\\n    .agg('sum')\n    \n# min-max normilization\ndf_temp = (df_temp-df_temp.min())\/(df_temp.max()-df_temp.min())\n\nax = sns.heatmap(df_temp, cmap='RdYlGn_r', robust=True, annot_kws = {'size':14})\nax.tick_params(labelsize=14)\nax.figure.set_size_inches((5, 5))","d1672955":"### Top articles based on shares","f4667a48":"# Importing libraries","097c7d5e":"# Visualizing data\n\nFor a subset of publishers","e2e1fe5b":"### Top articles based on reactions","117d74fd":"### Engagement per publisher","1460ff51":"### Top authors based on `top_article` attribute","d2836777":"### Heatmap","352b1307":" Selecting only top publishers for further anlysis","aa73ea2c":"### Top publishers","cd40bb84":"# Dataset info","3a710e38":"### Articles collected every day","65c059fa":"# Loading dataset"}}