{"cell_type":{"057637c8":"code","f43a3998":"code","e40e7b40":"code","ae67c185":"code","69347711":"code","ef94d5d7":"code","ae86bb68":"code","f97bde79":"code","2fe9b06b":"code","952207d2":"code","021040bc":"code","d403e5e2":"code","76370c71":"code","64d1f0dd":"code","12891710":"markdown","875a0218":"markdown","be2e5052":"markdown","7c873a48":"markdown","e0fedeef":"markdown","8b11ee34":"markdown"},"source":{"057637c8":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom scipy.stats import skew","f43a3998":"N_SAMPLES = 10000\nN_TEST = 1000\nMAX_TIMESTEPS = 6\nMASK_VALUE = -1\n\ntrain_X = np.random.uniform(size=(N_SAMPLES, MAX_TIMESTEPS, 1))\ntrain_L = np.random.randint(2, MAX_TIMESTEPS, N_SAMPLES)\n\ntest_X = np.random.uniform(size=(N_TEST, MAX_TIMESTEPS, 1))\ntest_L = np.random.randint(2, MAX_TIMESTEPS, N_TEST)","e40e7b40":"for i in range(N_SAMPLES):\n    train_X[i, train_L[i]:] = MASK_VALUE","ae67c185":"for i in range(N_TEST):\n    test_X[i, test_L[i]:] = MASK_VALUE","69347711":"train_y = skew(train_X, axis=1)\ntest_y = skew(test_X, axis=1)","ef94d5d7":"input_ = tf.keras.Input(shape=(None, 1))\nmasked = tf.keras.layers.Masking(MASK_VALUE)(input_)\nlstm1 = tf.keras.layers.LSTM(32, return_sequences=True)(masked)\nlstm2 = tf.keras.layers.LSTM(32)(lstm1)\noutput = tf.keras.layers.Dense(1)(lstm2)\n\nmodel = tf.keras.Model(inputs=input_, outputs=output)\nmodel.summary()","ae86bb68":"model.compile('adam', 'mse')","f97bde79":"hist = model.fit(train_X, train_y, epochs=3)","2fe9b06b":"prediction = model.predict(test_X)","952207d2":"prediction[:5]","021040bc":"test_y[:5]","d403e5e2":"mean_absolute_error(test_y, prediction)","76370c71":"mean_squared_error(test_y, prediction)","64d1f0dd":"np.percentile(prediction, np.arange(0, 100, 10))","12891710":"Generate random values and calculate the label using the problem. The model should be able to learn how to calculate the skewness of a sequence. To define data with different lengths, we set the unused parts of the data as -1.","875a0218":"Define the connections of the nodes in the network and verify the model. The Masking layer removes the numbers whose values are equal to -1. This allows us to tell the network that the data lengths are different. The return_sequence flag defines if the LSTM should return only the last or the full sequence","be2e5052":"View the predictions on the test set","7c873a48":"Compile the model by providing the optimization algorithm and the loss function","e0fedeef":"Import all the needed modules","8b11ee34":"Train the model for 3 epochs"}}