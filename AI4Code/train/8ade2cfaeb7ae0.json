{"cell_type":{"b0b751ed":"code","dc1e534e":"code","56b1b921":"code","67099322":"code","7ee2259f":"code","aadffc17":"code","c0b48a43":"code","26cef2e1":"code","c34e879d":"code","5b9e9b86":"code","6b9db0ec":"code","8e38d422":"code","5def0e04":"code","8ead34bf":"code","5f041555":"code","f3b15abd":"code","bbc05a83":"code","5fff3229":"code","1b690cd4":"code","618fbf02":"code","3dcbd90c":"code","47c169d2":"code","ccaa9085":"code","a03f90d0":"code","d4e150ba":"code","715f615e":"code","e0ecb98b":"code","a727075c":"code","e701caa3":"code","9540d9a0":"code","95dd6447":"code","ac0b4133":"code","eb2ff2c3":"code","332474ba":"code","fc3cd1fe":"markdown","8517f583":"markdown","4077d078":"markdown","80111a99":"markdown","1c054912":"markdown","b0d52c55":"markdown","0fff86d6":"markdown","4990dce6":"markdown","aafc6a6e":"markdown","1e1f1c58":"markdown","39cb9bd3":"markdown","a9c6b56c":"markdown","0f3fe4bc":"markdown","33bf86ce":"markdown","2df48a7d":"markdown","5f2a6f84":"markdown","bf1ed449":"markdown","7942ac84":"markdown","24232a88":"markdown","96a8c778":"markdown"},"source":{"b0b751ed":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score","dc1e534e":"df = pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")\ndf.head()","56b1b921":"df.shape","67099322":"df.info()","7ee2259f":"df.describe().T","aadffc17":"df.isnull().sum()","c0b48a43":"df.duplicated()","26cef2e1":"sns.heatmap(df.corr())","c34e879d":"sns.histplot(df, x=\"Sex\", hue=\"HeartDisease\", multiple=\"dodge\")","5b9e9b86":"sns.histplot(df, x=\"ChestPainType\", hue=\"HeartDisease\", multiple=\"dodge\")","6b9db0ec":"sns.histplot(df, x=\"RestingECG\", hue=\"HeartDisease\", multiple=\"dodge\")","8e38d422":"sns.histplot(df, x=\"ExerciseAngina\", hue=\"HeartDisease\", multiple=\"dodge\")","5def0e04":"sns.histplot(df, x=\"ST_Slope\", hue=\"HeartDisease\", multiple=\"dodge\")","8ead34bf":"sns.histplot(df, x=\"Age\", kde=True)","5f041555":"sns.histplot(df, x=\"RestingBP\", kde=True)","f3b15abd":"sns.histplot(df, x=\"Cholesterol\", kde=True)","bbc05a83":"sns.histplot(df, x=\"MaxHR\", kde=True)","5fff3229":"sns.histplot(df, x=\"Oldpeak\", kde=True)","1b690cd4":"sns.pairplot(df, hue=\"HeartDisease\")","618fbf02":"sns.boxplot(x=df[\"HeartDisease\"], y=df[\"Age\"])","3dcbd90c":"sns.boxplot(x=df[\"HeartDisease\"], y=df[\"RestingBP\"])","47c169d2":"sns.boxplot(x=df[\"HeartDisease\"], y=df[\"Cholesterol\"])","ccaa9085":"sns.boxplot(x=df[\"HeartDisease\"], y=df[\"MaxHR\"])","a03f90d0":"string_col = df.select_dtypes(include=\"object\").columns\nstring_col","d4e150ba":"df[string_col].head()","715f615e":"#label encoding\nlabel_encoder = LabelEncoder()\nfor i in string_col:\n    df[i] = label_encoder.fit_transform(df[i])","e0ecb98b":"df.head()","a727075c":"X = df.iloc[:,:-1].values\ny = df.iloc[:,-1].values","e701caa3":"dummy_encoder = OneHotEncoder()\nX = dummy_encoder.fit_transform(X).toarray()","9540d9a0":"#Logistic regression\nacc = []\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\nmodel_LR = LogisticRegression()\nfor train_index, test_index in skf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model_LR.fit(X_train, y_train)\n    y_predict = model_LR.predict(X_test)\n    acc.append(roc_auc_score(y_test, y_predict))\nprint(\"Accuracy: \", np.mean(acc))","95dd6447":"#SVM\nacc = []\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\nmodel_svm = SVC(kernel=\"rbf\", C=1)\nfor train_index, test_index in skf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model_svm.fit(X_train, y_train)\n    y_predict = model_svm.predict(X_test)\n    acc.append(roc_auc_score(y_test, y_predict))\nprint(\"Accuracy: \", np.mean(acc))","ac0b4133":"#Random forest\nacc = []\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\nmodel_RF = RandomForestClassifier(criterion=\"entropy\", n_estimators=200)\nfor train_index, test_index in skf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model_RF.fit(X_train, y_train)\n    y_predict = model_RF.predict(X_test)\n    acc.append(roc_auc_score(y_test, y_predict))\nprint(\"Accuracy: \", np.mean(acc))","eb2ff2c3":"#KNN\nacc = []\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\nmodel_KNN = KNeighborsClassifier(n_neighbors=10)\nfor train_index, test_index in skf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model_KNN.fit(X_train, y_train)\n    y_predict = model_KNN.predict(X_test)\n    acc.append(roc_auc_score(y_test, y_predict))\nprint(\"Accuracy: \", np.mean(acc))","332474ba":"#gradient boosting\nacc = []\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\nmodel_GB = GradientBoostingClassifier(n_estimators=10, max_depth=1)\nfor train_index, test_index in skf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model_GB.fit(X_train, y_train)\n    y_predict = model_GB.predict(X_test)\n    acc.append(roc_auc_score(y_test, y_predict))\nprint(\"Accuracy: \", np.mean(acc))","fc3cd1fe":"**Here we can see that, there are 6 int types data and 1 float data type, 5 object data types**","8517f583":"**We have successfully seperated the object data types from our dataframe, now its time to lable encode them**","4077d078":"### Exploratory Data Analysis","80111a99":"**Now we are all set for training and testing our machine learining models. I have choose five machine learining algorithms, they are Logistic Regression, SVM, KNN, Random Forest, Gradient Boosting.**","1c054912":"### Data Preprocessing","b0d52c55":"**Here before splitting the dataframe as traing and testing data, I have used Stratified KFold cross validation method for better results.**","0fff86d6":"**As we can see there are no null values.\nNow we check for duplicte values**","4990dce6":"#### Final Accuracy","aafc6a6e":"### Loading the dataset","1e1f1c58":"**It is clear that our data has 918 rows and 12 columns**","39cb9bd3":"### Checking the correlation between the int type attributes","a9c6b56c":"### Applying machine learining models","0f3fe4bc":"**As we can see here, all the categorical data has been labled as numbers. But our machine learning model may think that these numbers are correlated, so avoid this problem we need to do the dummy encoding for our data. Before that we need to sepeate the dependent variable which is \"HeartDisease\" from our data frame**","33bf86ce":"**Here we can see that MaxHR has high negative correlation with HeartDisease and Oldpeak has positive correlation with HeartDisease.**","2df48a7d":"**Machine learining model only deals with numbers and mathematics. Since we have some categorical data in our data frame, we are going to leble encode all the columns which are object data types.**","5f2a6f84":"**Here we can see that there are few outliers in our data. And we also have seen the pairplot and kde plots of our data.**","bf1ed449":"**As we can see there are no duplicates as well.**","7942ac84":"**Checking for null values**","24232a88":"**All the  five algorithms have performed well for this dataset and have given good accuracies.**","96a8c778":"### Importing all the required libraries"}}