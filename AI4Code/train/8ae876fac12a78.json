{"cell_type":{"c614d700":"code","ae0ca71f":"code","f67c6acc":"code","16f9ef2d":"code","3ed2f742":"code","3ca2c882":"code","28efb1f4":"code","d5cc8795":"code","25258dc4":"code","5fa95d90":"code","11c0be54":"code","df18ab44":"code","704d618b":"code","44c8ef35":"code","8b42c180":"code","b827629e":"code","a5e55ce8":"code","c3dd8b98":"code","b08bbd15":"code","f19328bf":"code","1d9295d2":"code","2f531c47":"code","f707828f":"code","38e67c92":"code","419de286":"code","30609cc0":"code","5f6cc56c":"markdown"},"source":{"c614d700":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae0ca71f":"# Importing the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f67c6acc":"# Importing the dataset\ndataset = pd.read_csv('\/kaggle\/input\/hotel-booking-demand\/hotel_bookings.csv')\ndataset","16f9ef2d":"# Exploring the dataset\nprint(dataset.info(), '\\n\\n')\nprint('Information about null values in dataset\\n')\nprint(dataset.isnull().sum())","3ed2f742":"# Cleaning the dataset\nreplacements = {'children': 0.0, 'country': 'Unknown', 'agent': 0.0,\n                'company': 0.0}\ndataset.fillna(replacements, inplace = True)","3ca2c882":"dataset['meal'].value_counts()","28efb1f4":"# Since meal has Undefined values, it was changed to SC\ndataset['meal'].replace(to_replace = 'Undefined', value = 'SC', inplace = True)","d5cc8795":"# Checking if there are rows with 0 guests\nno_guests = list(dataset.loc[dataset['adults']\n                   + dataset['children']\n                   + dataset['babies'] == 0].index)\nno_guests","25258dc4":"# Since rows with 0 guests make no sense, those rows were dropped\ndataset.drop(dataset.index[no_guests], inplace = True)","5fa95d90":"# Separating the resort and city hotel information\nresort = dataset.loc[(dataset['hotel'] == 'Resort Hotel')]\ncity = dataset.loc[(dataset['hotel'] == 'City Hotel')]","11c0be54":"# Finding the cancellation for each hotel per month\nresort_per_month = resort.groupby('arrival_date_month')['hotel'].count()\nresort_cancel_per_month = resort.groupby('arrival_date_month')['is_canceled'].sum()\n\ncity_per_month = city.groupby('arrival_date_month')['hotel'].count()\ncity_cancel_per_month = city.groupby('arrival_date_month')['is_canceled'].sum()\n\nresort_cancel_data = pd.DataFrame({'Hotel': 'Resort Hotel',\n                                'Month': list(resort_per_month.index),\n                                'Bookings': list(resort_per_month.values),\n                                'Cancelations': list(resort_cancel_per_month.values)})\n\ncity_cancel_data = pd.DataFrame({'Hotel': 'City Hotel',\n                                'Month': list(city_per_month.index),\n                                'Bookings': list(city_per_month.values),\n                                'Cancelations': list(city_cancel_per_month.values)})\n\nfull_cancel_data = pd.concat([resort_cancel_data, city_cancel_data], ignore_index = True)\nfull_cancel_data['cancel_percent'] = full_cancel_data['Cancelations'] \/ full_cancel_data['Bookings'] * 100\n\nordered_months = ['January', 'February', 'March', 'April', 'May', 'June', \n          'July', 'August', 'September', 'October', 'November', 'December']\nfull_cancel_data['Month'] = pd.Categorical(full_cancel_data['Month'], categories = ordered_months, ordered = True)","df18ab44":"# Plot figure\nplt.figure(figsize = (12, 8))\nsns.barplot(x = 'Month', y = 'cancel_percent' , hue = 'Hotel',\n            hue_order = ['City Hotel', 'Resort Hotel'], data = full_cancel_data)\nplt.title('Cancelations per month', fontsize = 16)\nplt.xlabel('Month', fontsize = 16)\nplt.xticks(rotation = 45)\nplt.ylabel('Cancelations [%]', fontsize = 16)\nplt.legend(loc = 'upper right')\nplt.show()","704d618b":"# Finding the percentage of cancellations for each hotel\nresort_cancellations = resort['is_canceled'].sum()\nresort_percentage_cancel = round(resort_cancellations \/ resort.shape[0] * 100, 2)\ncity_cancellations = city['is_canceled'].sum()\ncity_percentage_cancel = round(city_cancellations \/ city.shape[0] * 100, 2)\n\nprint('% of cancellations for Resort Hotel is {0}%'.format(resort_percentage_cancel))\nprint('% of cancellations for City Hotel is {0}%'.format(city_percentage_cancel))","44c8ef35":"# The above data begs the question whether the pricing of each hotel plays a part in cancellation or not\n# Checking to see if each room has adults or not since it is plausible that adults would pay most of the room fare\n\n# Checking to see if each room has adults\nindex_city = list(city.loc[city['adults'] == 0].index)\nindex_resort = list(resort.loc[resort['adults'] == 0].index)\n\nprint(index_city)\nprint('\\n')\nprint(index_resort)","8b42c180":"# Since there are quite a few rows with no adults, it is safe to assume that adults and children pay the room fare\n\n# Finding the average price per person in each hotel\nresort_avg_price = round((resort['adr'] \/ (resort['adults'] + resort['children'])).mean(), 2)\ncity_avg_price = round((city['adr'] \/ (city['adults'] + city['children'])).mean(), 2)\n\nprint('The average price per person at Resort Hotel is \u20ac {0}'.format(resort_avg_price))\nprint('The average price per person at City Hotel is \u20ac {0}'.format(city_avg_price))","b827629e":"# Finding the correlation\ncorrelation = dataset.corr()['is_canceled']\nprint(correlation)","a5e55ce8":"# Dropping irrelevant columns\ndataset.drop(['arrival_date_year', 'assigned_room_type', 'booking_changes', 'reservation_status', \n              'country', 'reservation_status_date', 'days_in_waiting_list'], axis = 1, inplace = True)","c3dd8b98":"dataset.info()","b08bbd15":"# Making the numerical features and categorical features for one-hot encoding and simple imputing\nnumerical_features = list(dataset.select_dtypes(exclude = [object]))\ncategorical_features = list(dataset.select_dtypes(include = [object]))\nnumerical_features.remove('is_canceled')","f19328bf":"# Changing the dataset into dependent and independent variables\nX = dataset.drop(['is_canceled'], axis = 1)[numerical_features + categorical_features]\ny = dataset['is_canceled']","1d9295d2":"# Pre-processing features\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nnumeric_transformer = SimpleImputer(strategy = 'constant')\ncategoric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy = 'constant', fill_value = 'Unknown')),\n    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))])\npreprocessor = ColumnTransformer(transformers = [('numeric', numeric_transformer, numerical_features),\n                                               ('categorical', categoric_transformer, categorical_features)])\n\nX = preprocessor.fit_transform(X)","2f531c47":"# Splitting the dataset into training and testing\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","f707828f":"# Create and fit the classifier on the training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 300, n_jobs = -1, random_state = 0)\nclassifier.fit(X_train, y_train)","38e67c92":"# Make predictions using the classifier\ny_pred = classifier.predict(X_test)","419de286":"# Evaluate the performance of the classifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error, classification_report\naccuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nreport = classification_report(y_test, y_pred)\n\nprint('The accuracy of the classifier is {0}%'.format(accuracy))\nprint('\\nThe calculated RMSE is {0}'.format(rmse))\nprint('\\nThe classification report is as follows:\\n')\nprint(report)","30609cc0":"# Plotting the confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (10, 8))\nsns.heatmap(cm, annot = True, fmt = '.0f', linewidths = .5, square = True)\nplt.xlabel('Predicted labels')\nplt.ylabel('Actual labels')\nplt.title('Accuracy: {0}'.format(round(accuracy, 2)))\nplt.show()","5f6cc56c":"As you can see, we got an accuracy of 86.71% which isn't the greatest but is quite decent.\n\nOne of the ways the accuracy can be improved is to try Hyperparameter Tuning using GridSearchCV, or even trying to build an ANN. Other ensemble methods might work too.\n\nFeel free to copy and edit the kernel to try your own methods."}}