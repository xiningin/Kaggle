{"cell_type":{"4716abcb":"code","52bb391c":"code","347b860a":"code","e02f2d85":"code","03d9b11e":"code","167f3a53":"code","7dadcaee":"code","dcf538fa":"code","5de1a53e":"code","6e5d84f0":"code","6c97b657":"code","5b13847c":"code","572a73e8":"code","3c4c21c6":"code","9ffb7648":"code","08dad471":"code","eb5684d3":"code","5a12957b":"code","bcc6b0fe":"code","af5f4fcb":"code","e49b515e":"markdown"},"source":{"4716abcb":"#model selction tools\nfrom sklearn.model_selection import train_test_split , GridSearchCV\\\n        , StratifiedKFold , TimeSeriesSplit,KFold,cross_val_score\n#metrics \nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n#models \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor,BaggingRegressor,GradientBoostingRegressor\nimport xgboost as xgb\nimport catboost as cb\n#tools\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.utils import shuffle\nfrom sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,GradientBoostingRegressor\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.utils import shuffle\nimport xgboost as xgb\nimport catboost as cb\n\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import cross_val_score\n\n\n","52bb391c":"import os\nos.listdir(\"..\/input\/bike-sharing-demand\")","347b860a":"import pandas as pd\nimport numpy as np\n\n# train_path = r\"train.csv\"\n# test_path = r\"test.csv\"\ntrain_path = r\"..\/input\/bike-sharing-demand\/train.csv\"\ntest_path = r\"..\/input\/bike-sharing-demand\/test.csv\"\ndf_train = pd.read_csv(train_path,parse_dates=['datetime'],dayfirst=True)\ndf_test = pd.read_csv(test_path,parse_dates=['datetime'],dayfirst=True)","e02f2d85":"df_train.shape","03d9b11e":"df_test.shape","167f3a53":"def get_date_attributes(DF,Date_Col_name):\n    \n    DF['Year'] = DF[Date_Col_name].dt.year.astype('int')\n    DF['Week'] = DF[Date_Col_name].dt.isocalendar().week.astype('int')\n    DF['Month'] = DF[Date_Col_name].dt.month.astype('int')\n    DF['WeekDay'] = DF[Date_Col_name].dt.weekday.astype('int')\n    DF['Hour'] = DF['datetime'].dt.hour\n    return DF\n\ndef new_feature(DF,function,new_col_name):\n    DF[new_col_name]  = DF.apply(function,axis=1)\n    return DF\n\ndef map_colmun_to_Categorical(DF,new_col_name,from_vals,to_vals):\n    DF[new_col_name].replace(from_vals,to_vals,inplace=True)\n    return DF\ndef CreateLag(DF,used_col,shift = -1):\n    col_name = f'{used_col}_shift({shift})'\n    DF[col_name] = DF[used_col].shift(shift)\n    DF[col_name].fillna(0, inplace=True)\n    return DF\ndef CreateRoll(DF,used_col,roll = 4):\n    col_name = f'{used_col}_rolling({roll}With_Mean)'\n    DF[col_name] = DF[used_col].rolling(roll).mean()\n    DF[col_name].fillna(0, inplace=True)\n    return DF\ndef CreateEWM(DF,used_col,com = 0.9):\n    col_name = f'{used_col}_EWM_Com({com}With_Mean)'\n    DF[col_name] = DF[used_col].ewm(com=com).mean()\n    DF[col_name].fillna(0, inplace=True)\n    return DF","7dadcaee":"df_train = get_date_attributes(df_train,'datetime')\ndf_test = get_date_attributes(df_test,'datetime')","dcf538fa":"def rush_hour(df):\n    #from 8 am , 6 pm\n    rush_range_1 = 2 # around the rush hour by +- 2 hrs\n    rush_range_2 = 5 # around the rush hour by +- 4 hrs\n    is_functional = df['workingday'] \n    \n    if (abs(df['Hour'] - 8) <= rush_range_1): \n        return np.exp(-abs(df['Hour'] - 8)) * is_functional\n    \n    elif (abs(df['Hour'] - 18) <= rush_range_2):\n        return np.exp(-abs(df['Hour'] - 18)) * is_functional\n    else:\n        return 0\n        \ndef dead_hour(df):\n    #dead_range_1 = 5 # around the dead hour by +- 3 hrs from 4 am\n    is_functional = df['workingday'] \n    \n    if(df['Hour'] in [22,23,0,1,2,3,4,5]):\n        return np.exp(-abs(df['Hour'] - 4)) * is_functional\n    else:\n        return 0 ","5de1a53e":"day_state = lambda df : 1  if (df['Hour'] >=6 and df['Hour'] <=18) else 0","6e5d84f0":"Ideal = lambda df: 1 if (df['temp'] < 30 and df['windspeed'] > 30) else 0","6c97b657":"df_train = new_feature(df_train,rush_hour,'rush_hour')\ndf_train = new_feature(df_train,dead_hour,'dead_hour')\ndf_train = new_feature(df_train,day_state,'day_state')\ndf_train = new_feature(df_train,Ideal,'Ideal')\n\ndf_test = new_feature(df_test,rush_hour,'rush_hour')\ndf_test = new_feature(df_test,dead_hour,'dead_hour')\ndf_test = new_feature(df_test,day_state,'day_state')\ndf_test = new_feature(df_test,Ideal,'Ideal')","5b13847c":"ColsForLag =  [\"temp\" ,\"weather\" ,\"rush_hour\",\"dead_hour\",\"humidity\",\"windspeed\",\"Ideal\"]\n\nt  = -1\nfor col in ColsForLag:\n    df_train = CreateLag(df_train,col,(+t))\nfor col in ColsForLag:\n    df_train = CreateLag(df_train,col,(+t-1))\nfor col in ColsForLag:\n    df_train = CreateLag(df_train,col,(+t-2))\nfor col in  ColsForLag:\n    df_train = CreateRoll(df_train,col,4)\nfor col in  ColsForLag:\n    df_train = CreateEWM(df_train,col,0.9)\n    \nfor col in ColsForLag:\n    df_test = CreateLag(df_test,col,(+t))\nfor col in ColsForLag:\n    df_test = CreateLag(df_test,col,(+t-1))\nfor col in ColsForLag:\n    df_test = CreateLag(df_test,col,(+t-2))\nfor col in  ColsForLag:\n    df_test = CreateRoll(df_test,col,4)\nfor col in  ColsForLag:\n    df_test = CreateEWM(df_test,col,0.9)","572a73e8":"lag1_features , lag2_features , lag3_features , rolling_features,ewn_features = [],[],[],[],[]\nt = -1\n\nfor used_col in ColsForLag:\n    col_name = f'{used_col}_shift({+t})'\n    lag1_features.append(col_name)\n    \nfor used_col in ColsForLag:\n    col_name = f'{used_col}_shift({+t-1})'\n    lag2_features.append(col_name)\n    \nfor used_col in ColsForLag:\n    col_name = f'{used_col}_shift({+t-2})'\n    lag3_features.append(col_name)\n\nfor used_col in ColsForLag:\n    col_name = f'{used_col}_rolling({4}With_Mean)'\n    rolling_features.append(col_name)\n\nfor used_col in ColsForLag:\n    col_name = f'{used_col}_EWM_Com({0.9}With_Mean)'\n    ewn_features.append(col_name)","3c4c21c6":"original_features = ['Hour','Week', 'Month','Year','windspeed'\n                     ,'WeekDay','humidity','workingday','season','weather','Ideal']\n\nweather_features=['rush_hour','dead_hour','day_state']\n\nselected_features = original_features + weather_features + lag1_features + lag2_features + lag3_features + rolling_features + ewn_features\n","9ffb7648":"df_train[\"count\"] = np.log(df_train[\"count\"]+0.00001)","08dad471":"X1 = df_train[selected_features]\ny1 = df_train[\"count\"]\n\n# tss = TimeSeriesSplit(n_splits=2)\n# train_ind,test_ind  = tss.split(X1,groups=[20,1])\n\nX_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.2, random_state=42,shuffle=True,)","eb5684d3":"def rmsle(y_true, y_pred, convertExp=True):\n    if convertExp:\n        y_true = 10**(y_true)\n        y_pred = 10**(y_pred)\n        \n    log_true = np.nan_to_num(np.array([np.log(y+1.0) for y in y_true]))\n    log_pred = np.nan_to_num(np.array([np.log(y+1.0) for y in y_pred]))\n    \n    output = np.sqrt(np.mean((log_true - log_pred)**2))\n    return output\n\nrmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False) \nScoring = rmsle_scorer","5a12957b":"params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\ngbm_model = GradientBoostingRegressor(**params)\ngbm_model.fit(X_train,y_train)\n\npred_test = gbm_model.predict(X_test)\npred_train= gbm_model.predict(X_train)\n\nprint('(Test) CatBoost Regression RMSLE:', rmsle(y_test, pred_test, True))\nprint('(Train) CatBoost Regression RMSLE:', rmsle(y_train, pred_train, True))","bcc6b0fe":"train_dataset = cb.Pool(X_train, y_train) \ntest_dataset = cb.Pool(X_test, y_test)\n\n# model = cb.CatBoostRegressor(loss_function='RMSE',random_state=0,max_depth=4,iterations=3200,\n#                                            l2_leaf_reg=1,learning_rate=0.038,subsample=0.85)\n\nmodel = cb.CatBoostRegressor(silent=True,loss_function='RMSE')\nmodel.fit(X_train,y_train)\npred_test = model.predict(X_test)\npred_train= model.predict(X_train)\n\nprint('(Test) CatBoost Regression RMSLE:', rmsle(y_test, pred_test, True))\nprint('(Train) CatBoost Regression RMSLE:', rmsle(y_train, pred_train, True))\n","af5f4fcb":"df_test['y'] =  np.exp(model.predict(df_test[selected_features]))\nfinal_df = df_test[['datetime', 'y']].copy()\nsave_to_path = r'submission.csv'\nfinal_df.to_csv(save_to_path, index=False)","e49b515e":"df_test.set_index('datetime',inplace=True)"}}