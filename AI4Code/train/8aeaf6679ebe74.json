{"cell_type":{"37e7c085":"code","425e7bc7":"code","60cd2998":"code","3bcd04fc":"code","9fdf5cda":"code","3e9e8b2c":"code","03fbbdd6":"code","3264a7d7":"code","2998d746":"code","a2b9b1bf":"code","2975770f":"code","6a77b1f6":"code","1ce83504":"code","d6ee54d2":"code","662ac76b":"code","a17adba8":"code","c41b26a7":"code","799264d3":"code","a497d565":"code","94496b11":"code","78c7c846":"code","aec2568d":"code","67017554":"code","0398058a":"code","0fb137b1":"code","afb61dd1":"code","24739d72":"code","47fc79a0":"code","42d5a841":"code","94cee3cd":"code","a1a17f92":"code","4660990f":"code","755c520c":"code","2a6f9279":"markdown","6fecd730":"markdown","19614e02":"markdown","6cf7610c":"markdown","a30f7942":"markdown","b5b82fd8":"markdown","844a5a14":"markdown","b5d1cfcb":"markdown","ad6ba457":"markdown","87fb7dc8":"markdown","4c98efc0":"markdown","8679a263":"markdown","314ae425":"markdown","85ac11f6":"markdown","7e8f14c7":"markdown","a0960637":"markdown","765eb694":"markdown","342f9d05":"markdown","348718da":"markdown","20193318":"markdown","bf25910a":"markdown","1583ec86":"markdown","8bb523d2":"markdown","bdde70a0":"markdown","f2f3f23b":"markdown","eca5ff57":"markdown","fbcec5b8":"markdown","cccd08b2":"markdown","e2c04154":"markdown","b77af290":"markdown","d4621ee7":"markdown","e9e84f9f":"markdown","332b1762":"markdown","f03f2559":"markdown","831898d0":"markdown"},"source":{"37e7c085":"!pip install pycaret==2.0","425e7bc7":"# Demonstration of how to use pycaret for classification\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom pycaret.utils import version\nversion()","60cd2998":"from pycaret.datasets import get_data\ndataset = get_data('iris')","3bcd04fc":"#check the shape of data\ndataset.shape","9fdf5cda":"data = dataset.sample(frac=0.9, random_state=786).reset_index(drop=True)\ndata_unseen = dataset.drop(data.index).reset_index(drop=True)\n\nprint('Data for Modeling: ' + str(data.shape))\nprint('Unseen Data For Predictions: ' + str(data_unseen.shape))","3e9e8b2c":"from pycaret.classification import *\niris = setup(data = data, target = 'species', session_id=1)","03fbbdd6":"compare_models()","3264a7d7":"nbmodel = create_model('nb')","2998d746":"print(nbmodel)","a2b9b1bf":"qdamodel=create_model('qda')","2975770f":"print(qdamodel)","6a77b1f6":"xgbmodel=create_model('xgboost')","1ce83504":"print(xgbmodel)","d6ee54d2":"tuned_nb=tune_model(nbmodel)","662ac76b":"print(tuned_nb)","a17adba8":"tuned_qda=tune_model(qdamodel)","c41b26a7":"print(tuned_qda)","799264d3":"tuned_xgb=tune_model(xgbmodel)","a497d565":"print(tuned_xgb)","94496b11":"plot_model(tuned_nb, plot = 'confusion_matrix')","78c7c846":"plot_model(tuned_qda, plot = 'confusion_matrix')","aec2568d":"plot_model(tuned_xgb, plot = 'confusion_matrix')","67017554":"plot_model(tuned_nb, plot = 'class_report')","0398058a":"plot_model(tuned_qda, plot = 'class_report')","0fb137b1":"plot_model(tuned_xgb, plot = 'class_report')","afb61dd1":"plot_model(tuned_nb, plot='boundary')","24739d72":"plot_model(tuned_qda, plot='boundary')","47fc79a0":"plot_model(tuned_xgb, plot='boundary')","42d5a841":"predict_model(tuned_qda)","94cee3cd":"save_model(tuned_qda,'Final QDA Model')","a1a17f92":"saved_final_qda = load_model('Final QDA Model')","4660990f":"new_prediction = predict_model(saved_final_qda, data=data_unseen)","755c520c":"new_prediction.head()","2a6f9279":"## Confusion Matrix","6fecd730":"Once the model is loaded in the environment, you can simply use it to predict on any new data using the same predict_model() function.","19614e02":"## Dataset for the Tutorial\n\n__Iris Dataset from UCI__. This is perhaps the best known database to be found in the pattern recognition literature. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. Short descriptions of each column are as follows:\n<br>\n- __sepal_length__: Length of Sepal\n- __sepal_width__: Width of Sepal\n- __petal_length__: Length of Petal\n- __petal_width__: Width of Petal\n- __species__: One of three class (Setosa, Versicolour, Virginica) Target Column","6cf7610c":"# Save\/load Model.","a30f7942":"# Tuning a Model.","b5b82fd8":"# Comparing All Models-Favourite Part","844a5a14":"![image.png](attachment:image.png)","b5d1cfcb":"# Create a Model","ad6ba457":"## 2.Tuned Quadratic Discriminant Analysis","87fb7dc8":"In order to demonstrate the predict_model() function on unseen data, a sample of 15 records has been withheld from the original dataset to be used for predictions. This should not be confused with a train\/test split as this particular split is performed to simulate a real life scenario. Another way to think about this is that these 15 records were not available at the time when the machine learning experiment was performed.","4c98efc0":"To load a saved model at a future date in the same or an alternative environment, we would use PyCaret's load_model() function and then easily apply the saved model on new unseen data for prediction.","8679a263":"![image.png](attachment:image.png)\n","314ae425":"__Notice__ how a few tasks that are imperative to perform modeling are automatically handled such as missing value imputation, categorical encoding etc. Most of the parameters in setup() are optional and used for customizing the pre-processing pipeline. These parameters are out of scope for this tutorial but as you progress to the intermediate and expert levels, we will cover them in much greater detail.","85ac11f6":"## 1.Tuned Naive Bayes","7e8f14c7":"## Fallback of compare models.\ncompare_models() is a powerful function and often a starting point in any experiment, it does not return any trained models.It is for evaluating top performing models and finalize a few candidates for continued experimentation.","a0960637":"create_model() function  uses the default hyperparameters. In order to tune hyperparameters, the tune_model() function should be used. This function automatically tunes the hyperparameters of a model on a pre-defined search space and scores it using stratified cross validation.","765eb694":"## 3.Tuned Extreme Gradient Boosting(XGboost).","342f9d05":"# Plot a Model","348718da":"## 2.Quadratic Discriminant Analysis","20193318":"## Notice how the results after tuning have been improved:\n\n- __Naive Bayes Classifier__ (Before: 0.9589 , After: 0.9689)\n- __Quadratic Discriminant Analysis__ (Before: 0.9689 , After: 0.9689)\n- __XGBoost__ (Before: 0.9689 , After: 0.9689)","bf25910a":"# Predict on test \/ hold-out Sample","1583ec86":"## Decision Boundary Plot","8bb523d2":"## 1. Naive Bayes","bdde70a0":"In this notebook I will demonstrate how to use PyCaret library,which is a really fast way to get base estimations of all ml models.\n<br>\nPycaret can be implemented for the following fields:<br>\n- Regression (all models implemented)\n- Classification(all models implemented)\n- NLP(basic methods,pre trained not included)\n- Time Series Analysis\n\nreference for notebook : Pycaret documentation tutorials hosted on github.","f2f3f23b":"The accuracy on the test\/hold-out set is 0.9512 compared to 0.9689 achieved on the tuned_qda CV results. This is not a significant difference. If there is a large variation between the test\/hold-out and CV results, then this would normally indicate over-fitting but could also be due to several other factors and would require further investigation. In this case, we will move forward with finalizing the model and predicting on unseen data (the 10% that we had separated in the beginning and never exposed to PyCaret).","eca5ff57":"## 3. Extreme Gradient Boosting.(XGBoost)","fbcec5b8":"The setup() function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment. setup() must be called before executing any other function in pycaret. It takes two mandatory parameters: a pandas dataframe and the name of the target column. \n\nWhen setup() is executed, PyCaret's inference algorithm will automatically infer the data types for all features based on certain properties. The data type should be inferred correctly but this is not always the case. To account for this, PyCaret displays a table containing the features and their inferred data types after setup() is executed. If all of the data types are correctly identified enter can be pressed to continue or quit can be typed to end the expriment. Ensuring that the data types are correct is of fundamental importance in PyCaret as it automatically performs a few pre-processing tasks which are imperative to any machine learning experiment. These tasks are performed differently for each data type which means it is very important for them to be correctly configured.","cccd08b2":"## Index\n- __Getting Data__: How to import data from PyCaret repository\n- __Setting up Environment__: How to setup an experiment in PyCaret and get started with building multiclass models\n- __Create Model__: How to create a model, perform stratified cross validation and evaluate classification metrics\n- __Tune Model__: How to automatically tune the hyper-parameters of a multiclass model\n- __Plot Model__: How to analyze model performance using various plots\n- __Predict Model__: How to make predictions on new \/ unseen data\n- __Save \/ Load Model__: How to save \/ load a model for future use","e2c04154":"# Setting up the Environment in PyCaret","b77af290":"## Classification Report","d4621ee7":"Not even a line have created over 15 models using 10 fold stratified cross validation and evaluated the 5 most commonly used classification metrics (Accuracy, Recall, Precision, F1, Kappa). The score grid printed above highlights the highest performing metric for comparison purposes only.If you want the models to be compared for recall then you can do compare_models(sort = 'Recall'),which  will sort the grid by Recall instead of Accuracy.","e9e84f9f":"# Getting Data.","332b1762":"We have now finished the experiment by finalizing the tuned_qda model which is now stored in the tuned_qda variable. We have also used the model stored in tuned_qda to predict data_unseen. This brings us to the end of our experiment, but one question is still to be asked: What happens when you have more new data to predict? Do you have to go through the entire experiment again? The answer is no, PyCaret's inbuilt function save_model() allows you to save the model along with entire transformation pipeline for later use.","f03f2559":"## The following things can be efficiently and pretty fastly done by Pycaret:<br>\n![image.png](attachment:image.png)\n\n","831898d0":"### Loading the saved model"}}