{"cell_type":{"a8146ef1":"code","01a5f17b":"code","f8649bdc":"code","0b182e87":"code","fab2fcbb":"code","98d9f7e8":"code","89709963":"code","9168f2d0":"code","fcef883e":"code","10efbb3d":"code","ed47a866":"code","eaa79597":"code","a734bffe":"code","e2a8bebf":"code","6545bfe5":"code","b1685c65":"code","2fd084ed":"markdown","276dd430":"markdown","0c0f2efd":"markdown","7b0554b0":"markdown","36c4eb18":"markdown","3d7076e4":"markdown","662de546":"markdown","5bc69143":"markdown","1b6abcbd":"markdown","349b8419":"markdown","9f91a4ed":"markdown"},"source":{"a8146ef1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","01a5f17b":"data = pd.read_csv(r\"\/kaggle\/input\/twitter-user-gender-classification\/gender-classifier-DFE-791531.csv\",encoding = \"latin1\")\ndata.head()","f8649bdc":"data.columns","0b182e87":"data.info()","fab2fcbb":"data = pd.concat([data.gender,data.description],axis=1) # New data contains just two columns\ndata.dropna(axis = 0,inplace = True) # Drop NaN values\ndata.gender = [1 if each == \"female\" else 0 for each in data.gender] # 1 for female, 0 for male\ndata.gender.value_counts()","98d9f7e8":"data.head()","89709963":"first_description = data.description[4] \nfirst_description","9168f2d0":"import re\ndescription = re.sub(\"[^a-zA-Z]\",\" \",first_description)  # Except from a to z, and from A to Z will be transform to space\ndescription = description.lower()   # Make whole words lowercase\ndescription","fcef883e":"import nltk # natural language tool kit\nnltk.download(\"stopwords\")      \nfrom nltk.corpus import stopwords  \ndescription = nltk.word_tokenize(description) # To split words\ndescription = [ word for word in description if not word in set(stopwords.words(\"english\"))]","10efbb3d":"description","ed47a866":"import nltk as nlp\n\nlemma = nlp.WordNetLemmatizer()\ndescription = [ lemma.lemmatize(word) for word in description] \n\ndescription = \" \".join(description)","eaa79597":"description","a734bffe":"description_list = []\nfor description in data.description:\n    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n    description = description.lower()   \n    description = nltk.word_tokenize(description)\n    description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n    lemma = nlp.WordNetLemmatizer()\n    description = [ lemma.lemmatize(word) for word in description]\n    description = \" \".join(description)\n    description_list.append(description)","e2a8bebf":"from sklearn.feature_extraction.text import CountVectorizer # for bag of words\nmax_features = 5000\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\nsparce_matrix = count_vectorizer.fit_transform(description_list).toarray()  # x\nprint(\"Most Common {} word is {}\".format(max_features,count_vectorizer.get_feature_names()))","6545bfe5":"y = data.iloc[:,0].values   # male or female classes (output)\nx = sparce_matrix # our input\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# visualize number of digits classes\nplt.figure(figsize=(15,7))\nsns.countplot(y)\nplt.title(\"Number of Gender\")","b1685c65":"# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)\n\n\n# naive bayes\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n# prediction\ny_pred = nb.predict(x_test)\n\nprint(\"Accuracy: \",nb.score(y_pred.reshape(-1,1),y_test))","2fd084ed":"Let's apply these to all tweets with for loop","276dd430":"### Lemmatazation\n* For grammatical reasons, documents are going to use different forms of a word, such as organize, organizes, and organizing. Additionally, there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set.\n\n* The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n\n* *  am, are, is $\\Rightarrow$ be\n* * car, cars, car's, cars' $\\Rightarrow$ car\n* * The result of this mapping of text will be something like:\n* * the boy's cars are different colors $\\Rightarrow$ the boy car be differ color","0c0f2efd":"Our aim is to classify the gender from tweets so, we just need gender and description columns.","7b0554b0":"### Bag of Words\n* A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, such as with machine learning algorithms.\n* The approach is very simple and flexible, and can be used in a myriad of ways for extracting features from documents.\n* A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n\n    1. A vocabulary of known words.\n    1. A measure of the presence of known words.\n    \n\n* It is called a \u201cbag\u201d of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.\n* A very common feature extraction procedures for sentences and documents is the bag-of-words approach (BOW). In this approach, we look at the histogram of the words within the text, i.e. considering each word count as a feature.","36c4eb18":"## Cleaning Data ","3d7076e4":"Natural language processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.\n* In this notebook, we will learn the basics of the NLP by using Twitter User Gender Classification dataset.\n* We will classify the dataset by using Naive Bayes Algorithm","662de546":"### Regular Expression:\n* Regular Expression, is a sequence of characters that forms a search pattern.\n* RegEx can be used to check if a string contains the specified search pattern.","5bc69143":"## Import Twitter Data","1b6abcbd":"### Applying Our Machine Learning Model","349b8419":"### Stopwords (Irrelavent Words)\n* In computing, stop words are words that are filtered out before or after the natural language data (text) are processed. While \u201cstop words\u201d typically refers to the most common words in a language, all-natural language processing tools don\u2019t use a single universal list of stop words.","9f91a4ed":"Firstly, I will show you whole process from one tweet. Then, it will be applied for whole tweets in the dataset"}}