{"cell_type":{"c0f41508":"code","fdad1d0a":"code","0e75cfad":"code","8c360111":"code","206b7aee":"code","484e4cd0":"code","3b6403c1":"code","1818cdf9":"code","5b49cf86":"code","b71c5081":"code","a425d27f":"code","2b36fa15":"code","4b138947":"code","240be47f":"code","80661692":"code","76a998d6":"code","e0f9768a":"code","775fab39":"code","6c1e9d4b":"code","70bb3e8b":"code","cd71a040":"code","e484539a":"code","a0a340ea":"code","8a842f21":"code","d21d0df2":"code","eb9ede1f":"code","29535ae2":"code","802eeb5d":"code","413fd7b7":"code","5a8099f6":"code","71aa5028":"code","489b925a":"code","693c5a0e":"code","9e4f7ca9":"code","00e9e036":"code","f399abfc":"code","69542eea":"code","dac051eb":"code","2a802636":"code","ed3d3b6d":"code","49063c52":"code","407fb3d2":"code","7f1c1529":"code","d7510394":"code","bbf3c5f8":"code","683b4935":"code","a448f230":"code","412f16fd":"code","be484bf3":"code","3305504a":"code","19c27265":"code","8648452b":"code","02511cb1":"code","2df8f341":"code","a8b46d69":"code","1e7091f6":"code","17f77afd":"code","be92e25a":"code","5dc096c1":"code","b2666a7a":"code","f3ee03d1":"code","fb73c198":"code","d9a3b41b":"code","3b9afb7c":"code","c973d09d":"code","f14b60e0":"code","4e58507a":"code","474af2c6":"code","9115e6eb":"code","166b57c9":"code","cda9c5ab":"code","bd07f447":"code","ede27ebc":"code","eee2bab2":"code","426975ce":"code","fd6c8134":"code","a20e5a08":"code","b54c7568":"code","f23b5e88":"code","3a1f2440":"code","f7e9d351":"code","71f5def5":"code","e796bcd7":"code","163146d7":"code","f9abe73c":"code","1c406f07":"markdown","40bd2d59":"markdown","2835003a":"markdown","d511cb1d":"markdown","f74872b4":"markdown","5fcfae23":"markdown","9b96bbf3":"markdown","dc737a57":"markdown","4cc5bd0d":"markdown","f21c74f2":"markdown","44cf6ff4":"markdown","60a06fa1":"markdown","df5708c7":"markdown","2a9972fa":"markdown","2f89c911":"markdown","f2c5a38b":"markdown","b63708d6":"markdown","c533e8ee":"markdown","281c2bf7":"markdown","ef7594c3":"markdown","71dda975":"markdown","304257e8":"markdown","d4feebf5":"markdown","7c80aa37":"markdown","05669b24":"markdown","e7cfb9ed":"markdown","4fa5e345":"markdown","4c5c9ea1":"markdown","830a64cf":"markdown","f89c11c4":"markdown","197f2602":"markdown","a94fbb3b":"markdown","0b96a61e":"markdown","53524d54":"markdown","62be8fd5":"markdown","404efccf":"markdown","2df24ed0":"markdown","fb0101ff":"markdown","78be475d":"markdown","cb6c7570":"markdown","eb934ddd":"markdown","ca1f1c10":"markdown","cb0545a7":"markdown","0ca1fb72":"markdown","9e44d061":"markdown","1e8e659e":"markdown","031af0f1":"markdown","98d496da":"markdown","e07e7f18":"markdown","1416029f":"markdown","3db452db":"markdown","53b73a26":"markdown","2e3be98e":"markdown","f01538e5":"markdown","4b6aca44":"markdown","20a9e3c7":"markdown","ff957518":"markdown","6a15358d":"markdown","d25b4990":"markdown","12f29bba":"markdown","008b5888":"markdown","1131f3a9":"markdown","2cad270e":"markdown","b7dc0381":"markdown","5ecd9b63":"markdown","9abee073":"markdown","ba44d384":"markdown","ce67d18d":"markdown","1b2d05a4":"markdown","c6c9557b":"markdown","42ba0400":"markdown","7e5e0a30":"markdown","3ec067ac":"markdown","47845b90":"markdown","ba90115b":"markdown","ce63bb54":"markdown","02bb5c1b":"markdown","613247cd":"markdown","13e0a7c3":"markdown","9563fb16":"markdown","7f46c54d":"markdown","8f13d9d4":"markdown","93b8cf9a":"markdown","9eb628eb":"markdown","5638fb9b":"markdown","33edff83":"markdown","ddb94da4":"markdown","e02f9f63":"markdown"},"source":{"c0f41508":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","fdad1d0a":"mult_choice = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\")","0e75cfad":"# Check if there are missing values in the column 'Q1'\nmult_choice['Q1'].isnull().any()\n# Group the data based on the responses for 'Q1' and count the responses in each group\nage_group = mult_choice.groupby('Q1')['Q1'].count() #There are no missing values\n# Remove the group 'What is your age (# years)?' after grouping\nage_group.drop(index='What is your age (# years)?',inplace=True)","8c360111":"# Plot a bar graph\nax = age_group.plot(kind=\"bar\", figsize=(10,8), color=\"green\", fontsize=12);\nax.set_xlabel('Age group', fontsize=14)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_height())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    # get_x pulls left or right; get_height pushes up or down\n    ax.text(i.get_x() - .05, i.get_height()+.5, str(round((i.get_height()\/total)*100, 2))+'%')","206b7aee":"mult_choice['Q2'].isnull().any()\ngender = mult_choice.groupby('Q2')['Q2'].count().sort_values(ascending=False)\ngender.drop(index='What is your gender? - Selected Choice',inplace=True)","484e4cd0":"def my_autopct(pct):\n    return ('%1.1f%%' % pct) if pct > 1 else ''\n\ndf = pd.DataFrame(gender, index=['Male', 'Female', 'Prefer not to say', 'Prefer to self-describe'])\ndf.plot.pie(subplots=True, colors=['c', 'y', 'b', 'g'], autopct = my_autopct, fontsize=14, figsize=(6, 6))","3b6403c1":"# Let's count the rows in 'Q2' whose value is 'Male' and set normalize=True to get the proportion\nincome_of_males = mult_choice['Q10'][mult_choice['Q2'] == 'Male'].value_counts(normalize=True)\n# Let's reset the index to put the salary range in its proper order\nincome_of_males = income_of_males.reindex(index = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n                                                           \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n                                                           \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n                                                           \"300,000-500,000\", \"> $500,000\"])\n# We repeat for the females\nincome_of_females = mult_choice['Q10'][mult_choice['Q2'] == 'Female'].value_counts(normalize=True)\nincome_of_females = income_of_females.reindex(index = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n                                                           \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n                                                           \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n                                                           \"300,000-500,000\", \"> $500,000\"])","1818cdf9":"# We plot double horizontal bar graph to ease the comparison\nax = plt.subplots(figsize=(10,8)) \nwidth = .4 \nind = np.arange(24)\nplt.style.use('ggplot')\nplt.barh(ind, income_of_males, width, color='blue', label='Male')\nplt.barh(ind + width, income_of_females, width, color='red', label='Female')\n\nplt.xlabel('Proportion')\nplt.ylabel('Current Yearly Compensation')\nplt.title('Income distribution by gender')\n\nplt.yticks(ind + width, (\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n            \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n            \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n            \"300,000-500,000\", \"> $500,000\"))\nplt.legend()\nplt.show()\n","5b49cf86":"mult_choice['Q3'].isnull().any()\nresidence_country = mult_choice.groupby('Q3')['Q3'].count().sort_values(ascending=True)\nresidence_country.drop(index=['In which country do you currently reside?'],inplace=True)","b71c5081":"ax = residence_country.plot(kind=\"barh\", figsize=(24,20), color=\"green\", fontsize=16);\nax.set_ylabel(\"Residence country\", fontsize=18)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y(), str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","a425d27f":"income_in_US = mult_choice['Q10'][mult_choice['Q3'] == 'United States of America'].value_counts(normalize=True)\nincome_in_US = income_in_US.reindex(index = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n                                                           \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n                                                           \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n                                                           \"300,000-500,000\", \"> $500,000\"])\nincome_in_India = mult_choice['Q10'][mult_choice['Q3'] == 'India'].value_counts(normalize=True)\nincome_in_India = income_in_India.reindex(index = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n                                                           \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n                                                           \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n                                                           \"300,000-500,000\", \"> $500,000\"])","2b36fa15":"ax = plt.subplots(figsize=(10,8)) \nwidth = .4 \nind = np.arange(24)\nplt.style.use('ggplot')\nplt.barh(ind, income_in_US, width, color='blue', label='US')\nplt.barh(ind + width, income_in_India, width, color='red', label='India')\n\nplt.xlabel('Proportion')\nplt.ylabel('Current Yearly Compensation')\nplt.title('Income distribution by country')\n\nplt.yticks(ind + width, (\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n            \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n            \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n            \"300,000-500,000\", \"> $500,000\"))\nplt.legend()\nplt.show()","4b138947":"mult_choice['Q4'].isnull().any()\nedu_level = mult_choice.groupby('Q4')['Q4'].count().sort_values(ascending=True)\nedu_level.drop(index=['What is the highest level of formal education that you have attained or plan to attain within the next 2 years?'],inplace=True)","240be47f":"ax = edu_level.plot(kind=\"barh\", figsize=(20,10), color=\"green\", fontsize=16);\nax.set_ylabel(\"Educational Level\", fontsize=20)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","80661692":"income_of_doctors = mult_choice['Q10'][mult_choice['Q4'] == \"Doctoral degree\"].value_counts(normalize=True)\nincome_of_masters = mult_choice['Q10'][mult_choice['Q4'] == \"Master\u2019s degree\"].value_counts(normalize=True)\nincome_of_no_edu = mult_choice['Q10'][mult_choice['Q4'] == \"No formal education past high school\"].value_counts(normalize=True)","76a998d6":"idx = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n        \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n        \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n        \"300,000-500,000\", \"> $500,000\"]\nincome_of_doctors = income_of_doctors.reindex(index = idx)\nincome_of_masters = income_of_masters.reindex(index = idx)\nincome_of_no_edu = income_of_no_edu.reindex(index = idx)","e0f9768a":"ax = plt.subplots(figsize=(10,8)) \nwidth = .4 \nind = np.arange(24)\nplt.style.use('ggplot')\nplt.barh(ind, income_of_no_edu, width, color='blue', label='No education past high school')\nplt.barh(ind + width, income_of_masters, width, color='red', label='Master\\'s degree')\nplt.barh(ind + 2*width, income_of_doctors, width, color='green', label='Doctoral degree')\n\nplt.xlabel('Proportion')\nplt.ylabel('Current Yearly Compensation')\nplt.title('Income distribution by educational level')\n\nplt.yticks(ind + width, (\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n            \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n            \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n            \"300,000-500,000\", \"> $500,000\"))\nplt.legend()\nplt.show()","775fab39":"# Check if there are missing values\nmult_choice['Q5'].isnull().any()\n# Drop missing rows with missing values\njob_filtered = mult_choice['Q5'].dropna()\n# Check the size of the cleaned data\njob_filtered.shape\njob_title = mult_choice.groupby('Q5')['Q5'].count().sort_values(ascending=True)\njob_title.drop(index=['Select the title most similar to your current role (or most recent title if retired): - Selected Choice'],inplace=True)","6c1e9d4b":"ax = job_title.plot(kind=\"barh\", figsize=(16,6), color=\"green\", fontsize=14);\nax.set_ylabel(\"Job title\", fontsize=16)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .1, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=14)","70bb3e8b":"income_DataScientist = mult_choice['Q10'][mult_choice['Q5'] == 'Data Scientist'].value_counts(normalize=True)\nincome_SoftwareEngineer = mult_choice['Q10'][mult_choice['Q5'] == 'Software Engineer'].value_counts(normalize=True)\nincome_DataAnalyst = mult_choice['Q10'][mult_choice['Q5'] == 'Data Analyst'].value_counts(normalize=True)","cd71a040":"idx = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n        \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n        \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n        \"300,000-500,000\", \"> $500,000\"]\nincome_DataScientist = income_DataScientist.reindex(index = idx)\nincome_SoftwareEngineer = income_SoftwareEngineer.reindex(index = idx)\nincome_DataAnalyst = income_DataAnalyst.reindex(index = idx)","e484539a":"ax = plt.subplots(figsize=(10,8)) \nwidth = .4 \nind = np.arange(24)\nplt.style.use('ggplot')\nplt.barh(ind, income_DataScientist, width, color='red', label='Data Scientist')\nplt.barh(ind + width, income_SoftwareEngineer, width, color='blue', label='Software Engineer')\nplt.barh(ind + 2*width, income_DataAnalyst, width, color='green', label='Data Analyst')\n\nplt.xlabel('Proportion')\nplt.ylabel('Current Yearly Compensation')\nplt.title('Income distribution by job title')\n\nplt.yticks(ind + width, (\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n            \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n            \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n            \"300,000-500,000\", \"> $500,000\"))\nplt.legend()\nplt.show()","a0a340ea":"mult_choice['Q6'].isnull().any()\ncompany_filtered = mult_choice['Q6'].dropna()\ncompany_size = mult_choice.groupby('Q6')['Q6'].count()\ncompany_size.drop(index=['What is the size of the company where you are employed?'],inplace=True)\ncompany_size = company_size.reindex(index = [\"0-49 employees\", \"50-249 employees\", \"250-999 employees\", \"1000-9,999 employees\", \"> 10,000 employees\"])","8a842f21":"ax = company_size.plot(kind=\"barh\", figsize=(14,4), color=\"green\", fontsize=12);\nax.set_ylabel(\"Employees Number\", fontsize=12)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","d21d0df2":"mult_choice['Q7'].isnull().any()\nno_of_employees_filtered = mult_choice['Q7'].dropna()\nno_of_employees = mult_choice.groupby('Q7')['Q7'].count()\nno_of_employees.drop(index=['Approximately how many individuals are responsible for data science workloads at your place of business?'],inplace=True)\nno_of_employees = no_of_employees.reindex(index = [\"0\", \"1-2\",\"3-4\",\"5-9\",\"10-14\", \"15-19\", \"20+\"])","eb9ede1f":"ax = no_of_employees.plot(kind=\"barh\", figsize=(20,4), color=\"green\", fontsize=14);\nax.set_ylabel(\"No of employees with Data Science roles\", fontsize=14)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=14)","29535ae2":"mult_choice['Q8'].isnull().any()\nML_incorporated = mult_choice['Q8'].dropna()\nML_incorporated = mult_choice.groupby('Q8')['Q8'].count()\nML_incorporated.drop(index=['Does your current employer incorporate machine learning methods into their business?'],inplace=True)","802eeb5d":"ax = ML_incorporated.plot(kind=\"barh\", figsize=(20,8), color=\"green\", fontsize=18);\nax.set_ylabel(\"Is ML incorporated?\", fontsize=20)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","413fd7b7":"# Merge the columns for the different categories of 'Q9' separating the responces by a semicolon delimiter\nmult_choice['Q9'] = mult_choice[mult_choice.columns[11:20]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\n# Split back the column into different columns using the delimiter  \njob_roles = mult_choice['Q9'].str.split(';', expand = True)\n# Remove the rows with value -1\njob_roles = job_roles[job_roles != '-1']\n# Use .stack() to slice the dataframe apart and stack the columns on top of one another\njob_roles = job_roles.stack().value_counts().nlargest(8).sort_values(ascending=True)","5a8099f6":"ax = job_roles.plot(kind=\"barh\", figsize=(24,14), color=\"green\", fontsize=20);\nax.set_ylabel(\"Job roles\", fontsize=24)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","71aa5028":"mult_choice['Q10'].isnull().any()\nyearly_compensation = mult_choice['Q10'].dropna()\nyearly_compensation.shape\nyearly_compensation = mult_choice.groupby('Q10')['Q10'].count()\nyearly_compensation.drop(index=['What is your current yearly compensation (approximate $USD)?'],inplace=True)\nyearly_compensation = yearly_compensation.reindex(index = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n                                                           \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n                                                           \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n                                                           \"300,000-500,000\", \"> $500,000\"])","489b925a":"ax = yearly_compensation.plot(kind=\"barh\", figsize=(24,14), color=\"green\", fontsize=20);\nax.set_ylabel(\"Current yearly compensation\", fontsize=20)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","693c5a0e":"mult_choice['Q11'].isnull().any()\nmoney_spent = mult_choice['Q11'].dropna()\nmoney_spent = mult_choice.groupby('Q11')['Q11'].count()\nmoney_spent.drop(index=['Approximately how much money have you spent on machine learning and\/or cloud computing products at your work in the past 5 years?'],inplace=True)\nmoney_spent = money_spent.reindex(index = [\"$0 (USD)\", \"$1-$99\", \"$100-$999\", \"$1000-$9,999\", \"$10,000-$99,999\", \"> $100,000 ($USD)\"])","9e4f7ca9":"ax = money_spent.plot(kind=\"barh\", figsize=(16,3), color=\"green\", fontsize=12);\nax.set_ylabel(\"Money spent on ML and cloud computing\", fontsize=10)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","00e9e036":"mult_choice['Q12'] = mult_choice[mult_choice.columns[22:35]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nfavorite_media = mult_choice['Q12'].str.split(';', expand = True)\nfavorite_media = favorite_media[favorite_media != '-1']\nfavorite_media = favorite_media.stack().value_counts().nlargest(11).sort_values(ascending=True)","f399abfc":"ax = favorite_media.plot(kind=\"barh\", figsize=(24,12), color=\"green\", fontsize=20);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","69542eea":"mult_choice['Q13'] = mult_choice[mult_choice.columns[35:48]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\ncourse_platform = mult_choice['Q13'].str.split(';', expand = True)\ncourse_platform = course_platform[course_platform != '-1']\ncourse_platform = course_platform.stack().value_counts().nlargest(12).sort_values(ascending=True)","dac051eb":"ax = course_platform.plot(kind=\"barh\", figsize=(24,14), color=\"green\", fontsize=20);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","2a802636":"income_coursera = mult_choice['Q10'][mult_choice['Q13_Part_2'] == 'Coursera'].value_counts(normalize=True)\nincome_Kaggle = mult_choice['Q10'][mult_choice['Q13_Part_6'] == 'Kaggle Courses (i.e. Kaggle Learn)'].value_counts(normalize=True)\nincome_Udemy = mult_choice['Q10'][mult_choice['Q13_Part_8'] == 'Udemy'].value_counts(normalize=True)\nidx = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n        \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n        \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n        \"300,000-500,000\", \"> $500,000\"]\nincome_coursera = income_coursera.reindex(index = idx)\nincome_Kaggle = income_Kaggle.reindex(index = idx)\nincome_Udemy = income_Udemy.reindex(index = idx)","ed3d3b6d":"ax = plt.subplots(figsize=(10,8)) \nwidth = .4 \nind = np.arange(24)\nplt.style.use('ggplot')\nplt.barh(ind, income_coursera, width, color='red', label='Coursera')\nplt.barh(ind + width, income_Kaggle, width, color='blue', label='Kaggle')\nplt.barh(ind + 2*width, income_Udemy, width, color='green', label='Udemy')\n\nplt.xlabel('Proportion')\nplt.ylabel('Current Yearly Compensation')\nplt.title('Income distribution by platform on which course began or completed')\n\nplt.yticks(ind + width, (\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n            \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n            \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n            \"300,000-500,000\", \"> $500,000\"))\nplt.legend()\nplt.show()","49063c52":"mult_choice['Primary tool'] = mult_choice[mult_choice.columns[48:55]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nprimary_tool = mult_choice['Primary tool'].str.split(';', expand = True)\n# Remove rows that contain values -1, 1, 0 and 14\nprimary_tool = primary_tool[~((primary_tool != '-1') ^ (primary_tool != '1') ^ (primary_tool != '0') ^ (primary_tool != '14'))]\nprimary_tool = primary_tool.stack().value_counts().nlargest(6).sort_values(ascending=True)","407fb3d2":"ax = primary_tool.plot(kind=\"barh\", figsize=(24,7), color=\"green\", fontsize=20);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","7f1c1529":"mult_choice['Q15'].isnull().any()\nexprience_length = mult_choice['Q15'].dropna()\nexprience_length.shape\nexprience_length = mult_choice.groupby('Q15')['Q15'].count()\nexprience_length.drop(index=['How long have you been writing code to analyze data (at work or at school)?'],inplace=True)\nexprience_length = exprience_length.reindex(index = [\"I have never written code\", \"< 1 years\", \"1-2 years\", \"3-5 years\", \"5-10 years\", \"10-20 years\", \"20+ years\"])","d7510394":"ax = exprience_length.plot(kind=\"barh\", figsize=(16,4), color=\"green\", fontsize=12);\nax.set_ylabel(\"Length of code writing experience\", fontsize=12)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","bbf3c5f8":"mult_choice['Q16'] = mult_choice[mult_choice.columns[56:69]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nide_used = mult_choice['Q16'].str.split(';', expand = True)\nide_used = ide_used[ide_used != '-1']\nide_used = ide_used.stack().value_counts().nlargest(11).sort_values(ascending=True)","683b4935":"ax = ide_used.plot(kind=\"barh\", figsize=(24,10), color=\"green\", fontsize=20);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","a448f230":"mult_choice['Q17'] = mult_choice[mult_choice.columns[69:82]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nnotebook_used = mult_choice['Q17'].str.split(';', expand = True)\nnotebook_used = notebook_used[notebook_used != '-1']\nnotebook_used = notebook_used.stack().value_counts().nlargest(12).sort_values(ascending=True)","412f16fd":"ax = notebook_used.plot(kind=\"barh\", figsize=(24,12), color=\"green\", fontsize=20);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","be484bf3":"mult_choice['Q18'] = mult_choice[mult_choice.columns[82:95]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nlanguage_used = mult_choice['Q18'].str.split(';', expand = True)\nlanguage_used = language_used[language_used != '-1']\nlanguage_used = language_used.stack().value_counts().nlargest(11).sort_values(ascending=True)","3305504a":"ax = language_used.plot(kind=\"barh\", figsize=(24,8), color=\"green\", fontsize=16);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","19c27265":"income_Python = mult_choice['Q10'][mult_choice['Q18_Part_1'] == 'Python'].value_counts(normalize=True)\nincome_SQL = mult_choice['Q10'][mult_choice['Q18_Part_3'] == 'SQL'].value_counts(normalize=True)\nincome_R = mult_choice['Q10'][mult_choice['Q18_Part_2'] == 'R'].value_counts(normalize=True)","8648452b":"idx = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n        \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n        \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n        \"300,000-500,000\", \"> $500,000\"]\nincome_Python = income_Python.reindex(index = idx)\nincome_SQL = income_SQL.reindex(index = idx)\nincome_R = income_R.reindex(index = idx)","02511cb1":"ax = plt.subplots(figsize=(10,8)) \nwidth = .4 \nind = np.arange(24)\nplt.style.use('ggplot')\nplt.barh(ind, income_Python, width, color='red', label='Python')\nplt.barh(ind + width, income_SQL, width, color='blue', label='SQL')\nplt.barh(ind + 2*width, income_R, width, color='green', label='R')\n\nplt.xlabel('Proportion')\nplt.ylabel('Current Yearly Compensation')\nplt.title('Income distribution by programming language')\n\nplt.yticks(ind + width, (\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\", \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \n            \"15,000-19,999\", \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \"60,000-69,999\", \n            \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"250,000-299,999\", \n            \"300,000-500,000\", \"> $500,000\"))\nplt.legend()\nplt.show()","2df8f341":"mult_choice['Q19'].isnull().any()\nlang_recommended = mult_choice['Q19'].dropna()\nlang_recommended = mult_choice.groupby('Q19')['Q19'].count().sort_values(ascending=True)\nlang_recommended.drop(index=['What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice'],inplace=True)","a8b46d69":"ax = lang_recommended.plot(kind=\"barh\", figsize=(16,6), color=\"green\", fontsize=12);\nax.set_ylabel(\"Language recommended to learn first\", fontsize=14)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","1e7091f6":"mult_choice['Q20'] = mult_choice[mult_choice.columns[97:110]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nvisualization_library = mult_choice['Q20'].str.split(';', expand = True)\nvisualization_library = visualization_library[visualization_library != '-1']\nvisualization_library = visualization_library.stack().value_counts().nlargest(12).sort_values(ascending=True)","17f77afd":"ax = visualization_library.plot(kind=\"barh\", figsize=(24,10), color=\"green\", fontsize=20);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","be92e25a":"mult_choice['Q21'] = mult_choice[mult_choice.columns[110:116]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nhardware_used = mult_choice['Q21'].str.split(';', expand = True)\nhardware_used = hardware_used[hardware_used != '-1']\nhardware_used = hardware_used.stack().value_counts().nlargest(5).sort_values(ascending=True)","5dc096c1":"ax = hardware_used.plot(kind=\"barh\", figsize=(12,4), color=\"green\", fontsize=14);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=14)","b2666a7a":"mult_choice['Q22'].isnull().any()\ntpu_usage = mult_choice['Q22'].dropna()\ntpu_usage.shape\ntpu_usage = mult_choice.groupby('Q22')['Q22'].count()\ntpu_usage.drop(index=['Have you ever used a TPU (tensor processing unit)?'],inplace=True)\ntpu_usage = tpu_usage.reindex(index = [\"Never\", \"Once\", \"2-5 times\", \"6-24 times\", \"> 25 times\"])","f3ee03d1":"ax = tpu_usage.plot(kind=\"barh\", figsize=(14,3), color=\"green\", fontsize=12);\nax.set_ylabel(\"Frequency of TPU usage\")\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","fb73c198":"mult_choice['Q23'].isnull().any()\nML_usage = mult_choice['Q23'].dropna()\nML_usage = mult_choice.groupby('Q23')['Q23'].count()\nML_usage.drop(index=['For how many years have you used machine learning methods?'],inplace=True)\nML_usage = ML_usage.reindex(index = [\"< 1 years\", \"1-2 years\", \"2-3 years\", \"3-4 years\", \"4-5 years\", \"5-10 years\", \"10-15 years\", \"20+ years\"])","d9a3b41b":"ax = ML_usage.plot(kind=\"barh\", figsize=(12,5), color=\"green\", fontsize=12);\nax.set_ylabel(\"Length of ML methods usage\", fontsize=12)\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","3b9afb7c":"mult_choice['Q24'] = mult_choice[mult_choice.columns[118:131]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nML_algorithm = mult_choice['Q24'].str.split(';', expand = True)\nML_algorithm = ML_algorithm[ML_algorithm != '-1']\nML_algorithm = ML_algorithm.stack().value_counts().nlargest(12).sort_values(ascending=True)","c973d09d":"ax = ML_algorithm.plot(kind=\"barh\", figsize=(16,8), color=\"green\", fontsize=14);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","f14b60e0":"mult_choice['Q25'] = mult_choice[mult_choice.columns[131:140]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nML_tools = mult_choice['Q25'].str.split(';', expand = True)\nML_tools = ML_tools[ML_tools != '-1']\nML_tools = ML_tools.stack().value_counts().nlargest(8).sort_values(ascending=True)","4e58507a":"ax = ML_tools.plot(kind=\"barh\", figsize=(16,8), color=\"green\", fontsize=14);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","474af2c6":"mult_choice['Q26'] = mult_choice[mult_choice.columns[140:148]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nvision_methods = mult_choice['Q26'].str.split(';', expand = True)\nvision_methods = vision_methods[vision_methods != '-1']\nvision_methods = vision_methods.stack().value_counts().nlargest(7).sort_values(ascending=True)","9115e6eb":"ax = vision_methods.plot(kind=\"barh\", figsize=(20,12), color=\"green\", fontsize=24);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=20)","166b57c9":"mult_choice['Q27'] = mult_choice[mult_choice.columns[148:155]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nNLP_method = mult_choice['Q27'].str.split(';', expand = True)\nNLP_method = NLP_method[NLP_method != '-1']\nNLP_method = NLP_method.stack().value_counts().nlargest(6).sort_values(ascending=True)","cda9c5ab":"ax = NLP_method.plot(kind=\"barh\", figsize=(16,6), color=\"green\", fontsize=20);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=18)","bd07f447":"mult_choice['Q28'] = mult_choice[mult_choice.columns[155:168]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nML_frameworks = mult_choice['Q28'].str.split(';', expand = True)\nML_frameworks = ML_frameworks[ML_frameworks != '-1']\nML_frameworks = ML_frameworks.stack().value_counts().nlargest(12).sort_values(ascending=True)","ede27ebc":"ax = ML_frameworks.plot(kind=\"barh\", figsize=(20,10), color=\"green\", fontsize=16);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","eee2bab2":"mult_choice['Q29'] = mult_choice[mult_choice.columns[168:181]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\ncloud_computing = mult_choice['Q29'].str.split(';', expand = True)\ncloud_computing = cloud_computing[cloud_computing != '-1']\ncloud_computing = cloud_computing.stack().value_counts().nlargest(12).sort_values(ascending=True)","426975ce":"ax = cloud_computing.plot(kind=\"barh\", figsize=(20,10), color=\"green\", fontsize=16);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","fd6c8134":"mult_choice['Q30'] = mult_choice[mult_choice.columns[181:194]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\ncloud_product = mult_choice['Q30'].str.split(';', expand = True)\ncloud_product = cloud_product[cloud_product != '-1']\ncloud_product = cloud_product.stack().value_counts().nlargest(12).sort_values(ascending=True)","a20e5a08":"ax = cloud_product.plot(kind=\"barh\", figsize=(20,10), color=\"green\", fontsize=16);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","b54c7568":"mult_choice['Q31'] = mult_choice[mult_choice.columns[194:207]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nbigData_product = mult_choice['Q31'].str.split(';', expand = True)\nbigData_product = bigData_product[bigData_product != '-1']\nbigData_product = bigData_product.stack().value_counts().nlargest(12).sort_values(ascending=True)","f23b5e88":"ax = bigData_product.plot(kind=\"barh\", figsize=(20,10), color=\"green\", fontsize=16);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","3a1f2440":"mult_choice['Q32'] = mult_choice[mult_choice.columns[207:220]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nML_product = mult_choice['Q32'].str.split(';', expand = True)\nML_product = ML_product[ML_product != '-1']\nML_product = ML_product.stack().value_counts().nlargest(12).sort_values(ascending=True)","f7e9d351":"ax = ML_product.plot(kind=\"barh\", figsize=(20,10), color=\"green\", fontsize=16);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","71f5def5":"mult_choice['Q33'] = mult_choice[mult_choice.columns[220:233]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nautoML_tools = mult_choice['Q33'].str.split(';', expand = True)\nautoML_tools = autoML_tools[autoML_tools != '-1']\nautoML_tools = autoML_tools.stack().value_counts().nlargest(12).sort_values(ascending=True)","e796bcd7":"ax = autoML_tools.plot(kind=\"barh\", figsize=(14,6), color=\"green\", fontsize=12);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=12)","163146d7":"mult_choice['Q34'] = mult_choice[mult_choice.columns[233:246]].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\nRelational_DB = mult_choice['Q34'].str.split(';', expand = True)\nRelational_DB = Relational_DB[Relational_DB != '-1']\nRelational_DB = Relational_DB.stack().value_counts().nlargest(12).sort_values(ascending=True)","f9abe73c":"ax = Relational_DB.plot(kind=\"barh\", figsize=(20,10), color=\"green\", fontsize=16);\ntotals = []\n\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\nfor i in ax.patches:\n    ax.text(i.get_width() + 1, i.get_y() + .2, str(round((i.get_width()\/total)*100, 2))+'%', fontsize=16)","1c406f07":"## Income distribution by residence country","40bd2d59":"63% of the respondents never used automated ML tools. Auto-Sklearn is used by 9% of the respondents followed by Google AutoML (6%).","2835003a":"## Respondents by length of code writing exprience","d511cb1d":"Around 78% of the respondents have code writing experience not exceeding 5 years. The modal code writing experience is 1-2 years, which covers 26% of the respondents.","f74872b4":"Only 19% of the respondents work in companies which established ML methods for more than 2 years, 72% of the respondents work in companies companies which never used ML methods or used ML methods for less than 2 years.","5fcfae23":"Image classification, general purpose image\/video tools and image segmentation methods are most commonly used computer vision methods.","9b96bbf3":"## Income by job title","dc737a57":"MySQL is the most used relational database, followed by PostgresSQL and Microsoft SQL Server.","4cc5bd0d":"Let's compare the compensation of graduate degree holders (Master's and Doctoral degree holders) to those who have no formal education past high school.","f21c74f2":"Kaggle Notebooks(Kernels) are the leading hosted notebooks used by 23.7% of the respondents, followed by Google Colab (22.3%). 25% of the respondents do not use any hosted notebook products.","44cf6ff4":"Though Python is the most used programming languages, the proportion of R and SQL programmers earning higher compensations is \nslightly higher than that of Python.","60a06fa1":"82% of the repondents are male while around 16% of them are females.","df5708c7":"CPUs and GPUs are most widely used specialized hardwares by the respondents.","2a9972fa":"## Respondents by cloud computing platforms used on a regular basis","2f89c911":"Only 23% of the respondents work in companies where more than 20 people are assigned in Data Science roles, and around 53% of the respondents are from companies which assign less than 5 people for Data Science roles.","f2c5a38b":"## Respondents by cloud computing products used on a regular basis","b63708d6":"Scikit-learn, TensorFlow and Keras are the most commonly used ML frameworks.","c533e8ee":"The age group 25-29 is the modal group (the group with the highest frequency). 80% of the respondents lie in the age group 18-39.","281c2bf7":"## Respondents by NLP method used regularly","ef7594c3":"In the income range 0 - 49,999 the proportion of Indian residents is higher than that of US residents. For the compensation range beyond 50,000 the percentage of US residents is higher than that of Indians. Hence, we can conclude that respondents from USA earn higher than those from India.","71dda975":"The proportion of Data Scientists who earn more than USD 80,000 is higher than that of Software Engineers and Data Analysts. ","304257e8":"## Respondents by recommendation on programming language to learn first","d4feebf5":"## Respondents by job title","7c80aa37":"## Respondents by length of machine learning methods usage","05669b24":"## Respondents by hosted notebook products used on regular basis","e7cfb9ed":"## Respondents' current yearly compensation","4fa5e345":"Matplotlib, Seaborn and Ggplot are most chosen data visualization libraries by 33.7%, 22.1% and 13.4% of the respondents respectively.","4c5c9ea1":"**Importing libraries**","830a64cf":"## Respondents by specialized hardware used on regular basis","f89c11c4":"Coursera is the leading among platforms on which Data Science course began or completed. Kaggle and Udemy follow in second and third place respectively.","197f2602":"India (24.3%), USA (15.7%) and Brazil (3.7%) are the top three contries interms of number of respondents.","a94fbb3b":"29% of the respondents work in companies with 0-49 employees, where as 23% of the respondents are from companies with higher than 10,000 employees.","0b96a61e":"Let's compare the income of Indian residents and USA residents, countries where large number of respondents are from.","53524d54":"43.5% of the respondents use no ML tools. Automated model selection is used by 17.8% of the respondents. Automated data augmentation and Automated hyperparameter tuning have nearly equal users (around 10% of the respondents).","62be8fd5":"Python is the most widely used programming language (by 34.3% of respondents) followed by SQL (17.5%) and R (12.3%).","404efccf":"## Respondents by big data \/ analytics products used on a regular basis","2df24ed0":"54% of the respondents use lacal development environments, followed by basic statistical software (19.5%).","fb0101ff":"## Respondents by TPU usage","78be475d":"## Income distribution by gender","cb6c7570":"Data Scientists, students, software engineers and Data Analysts are the job titles with highest number of respondents in their respective order. They comprise around 60% of the respondents.","eb934ddd":"The proportion of respondents with no formal education past high school earning more than USD 500,000 exceeds those of Master's and Doctoral degree holders.","ca1f1c10":"81% of the respondents have never used TPUs before. Only 1% of the respondents used TPUs more than 25 times.","cb0545a7":"## Respondents by company size","0ca1fb72":"Let's compare the income of the three most frequent paid job titles, Data Scientists,Software Engineers and Data Analysts.","9e44d061":"29% of the respondents don't use any cloud computing product. But AWS Elastic Compute Cloud (EC2), Google Compute Engine (GCE) and AWS Lambda are among the most used cloud computing products by users.","1e8e659e":"Though 48.3% of the respondents never use ML products, Google Cloud ML Engine and Azure ML Studio are used by nearly equal percentage of the respondents.","031af0f1":"Linear or logistic regression is ML algorithm used by 23% of the respondents where as Decision Trees or Random forests are used by 19% of the respondents.","98d496da":"Kaggle is the most favorite media source that report on Data Science topics followed by blogs and Youtube.","e07e7f18":"The most frequent job roles are analyzing and understanding data to influence product or business decisions (24.5% of the cases) and building prototypes to apply ML to new areas (20% of the cases).","1416029f":"44% of the respondents have Master's degree holders, followed by Bachelor's (31%) and Doctoral degree (14.3%).","3db452db":"### Respondents by favorite media sources that report on data science topics","53b73a26":"## Respondents by primary data analysis tool used at work or school","2e3be98e":"## Respondents by educational level","f01538e5":"## Income by programming language","4b6aca44":"USD 0-999 is the modal salary range followed by USD 10,000-14,999 and USD 100,000-124,999 consecutively.","20a9e3c7":"The proportion of respondents who completed or began Data Science course on Coursera is higher than that of Kaggle and Udemy in the compensation range greater than USD 25,000.","ff957518":"For the income rage 0 - 7,499, the proportion of females exceeds that of males where as for income ranges beyond 7500 the proportion of males exceeds females. This leads to the conclusion that females earn a lower compensation as compared to males. We have to make further analysis to judge whether this pay difference to attributes to gender difference or to difference in educational level and experience.","6a15358d":"## Respondents by Relational Data Base product used on regular basis","d25b4990":"## Respondents by number of employees responsible for data science roles","12f29bba":"## Respondents by residence country","008b5888":"## Respondents by programming language used on regular basis","1131f3a9":"**Kaggle ML & DS Survey Analysis**","2cad270e":"Let's compare the income generated by the three most common programming languages, Python","b7dc0381":"## Respondents by IDEs used on regular basis","5ecd9b63":"64% of the respondents spent less than 1000 USD on ML and cloud computing products in the past five years. 18.5% of the repondents spent more than USD 10,000.","9abee073":"Python is the most recommended language to learn first.","ba44d384":"## Respondents by gender","ce67d18d":"## Respondents by data visualization libraries or tools used on regular basis","1b2d05a4":"## Respondents by ML products used regularly","c6c9557b":"## Income by educational level","42ba0400":"## Respondents by machine learning frameworks used on a regular basis","7e5e0a30":"44.6% of the respondents don't use any big data analytics products. Google BigQuery, Databricks and AWS Redshift are among the most used big data analytics products by users.","3ec067ac":"## Respondents by job roles","47845b90":"## Respondents by ML tools used on regular basis?","ba90115b":"## Respondents by automated ML tools used regularly","ce63bb54":"## Respondents by age group","02bb5c1b":"## Income by platform on which data science course began or competed","613247cd":"## Respondents by ML algorithms used on regular basis?","13e0a7c3":"## Respondents by Machine Learning implementing employers","9563fb16":"Word embedding\/vectors, encoder-decoder models and transformer language models are most frequently used NLP methods by the respondents.","7f46c54d":"Jupyter is the IDE used by 28% of the respondents followed by Visual Studio (11.7%) and RStudio (11.5%).","8f13d9d4":"## Respondents by platform on which data science course began or completed ","93b8cf9a":"76% of the respondents have used ML methods for not more than 3 years. Only 1.3% of the respondents have used ML methods for more than 20 years.","9eb628eb":"Amazon Web Services is the most widely used cloud computing platform (28.3% respondents use it). Google Cloud Platform (21.9%) and Microsoft Azure (13.9%) follow in the rank.","5638fb9b":"## Conclusion\n- Kaggle is the most favorite media source that report on Data Science topics followed by blogs and Youtube.\n- Coursera is the leading platforms on which respondents began or completed Data Science course followed by Kaggle and Udemy.\n- Respondents who completed or began Data Science course on Coursera earn higher than those who completed or began their courses on Kaggle and Udemy.\n- Python is the most widely used programming language followed by SQL and R.\n- The most recommended programming language to learn first is Python.\n- Matplotlib is the most used data visualization library followed by Seaborn.\n- The most frequently used ML algorithm is Linear or logistic regression.\n- MySQL is the most used relational database, followed by PostgresSQL and Microsoft SQL Server.","33edff83":"## Money spent on machine learning or cloud computing products","ddb94da4":"## Respondents by computer vision methods used on a regular basis","e02f9f63":"This survey includes the responses of 19,717 respondents. We will analyze the responses for different groups of the respondents."}}