{"cell_type":{"a280191c":"code","43f13a9a":"code","9c0b8670":"code","2fb06a30":"code","18bb4002":"code","c5b75332":"code","b1d14432":"code","243e0a7f":"code","ecfbaa8e":"code","10ffc9af":"code","7500ebb4":"code","07c942be":"code","b4cff00c":"code","945d0d15":"code","c5642581":"code","d9d741a4":"code","9002d923":"code","90836575":"code","4f359603":"code","5c23b802":"code","68e909c1":"code","043068f0":"code","8756c756":"code","089f2ef3":"code","a51da45f":"code","a3b0dca7":"code","1ce0d757":"code","1b332798":"code","3e13ee2c":"code","a89f7f64":"code","2590956c":"code","96953a10":"code","a33b05e7":"code","1a058a9b":"code","db873273":"code","32c6ad6c":"code","6eed1f54":"code","4532d972":"code","a3c7b784":"code","087b7f22":"code","6251b8a4":"code","39e688d7":"code","620be6cc":"code","a92d4f2d":"code","b792776a":"code","b68da77c":"code","53d711f6":"markdown","0f56bf52":"markdown","ca42780c":"markdown","a71c6d6b":"markdown","7e95f4b3":"markdown","baca1339":"markdown","0335770e":"markdown","3467ed0f":"markdown","179548e2":"markdown","d906225a":"markdown","a76c2acb":"markdown","bd19e01a":"markdown"},"source":{"a280191c":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier,LGBMRegressor\n\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import mean_squared_log_error,make_scorer,r2_score  \nfrom sklearn import preprocessing\npd.set_option('display.max_rows',500)\npd.set_option('display.max_columns',900)\n# from pandas_profiling import ProfileReport\nimport plotly\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","43f13a9a":"\n\ntrain = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/submission.csv')","9c0b8670":"df= pd.concat([train, test])\n\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Create date columns\nle = preprocessing.LabelEncoder()\ndf['Day_num'] = le.fit_transform(df.Date)\ndf['Day'] = df['Date'].dt.day\ndf['Month'] = df['Date'].dt.month\ndf['Year'] = df['Date'].dt.year\n\ndf.head(5)","2fb06a30":"df[(df['Province_State']=='Florida') & (df['Id']>0)].tail()","18bb4002":"########Fl\u00f3rida casos corre\u00e7\u00e3o########\n#df['ConfirmedCases']=np.where(((df['Province_State']=='Florida')&(df['Day_num']==82)),21019,df['ConfirmedCases'])\ndf['Mortalidade']=np.where(df['ConfirmedCases']==0,0,df['Fatalities']\/df['ConfirmedCases'])\n\n\n\n\ndf[(df['Country_Region']=='Brazil') & (df['Id']>0)].tail()","c5b75332":"df['Province_State'].fillna('Vazio',inplace=True)\ndf['Local']=np.where(df['Province_State']== 'Vazio',df['Country_Region'],df['Country_Region']+'\/'+df['Province_State'])","b1d14432":"df_test=df[df['ForecastId']>0]\ndf['Date']=df['Date'].astype('str')\ndf=df[df['Id']>0]\ndf['ConfirmedCases'].fillna(0,inplace=True)\n\nprint(df.dtypes)\ndf[(df['Local']=='Brazil')].tail()","243e0a7f":"df_f=df[df['Month']>2]\n\ndf0=df[(df['Day_num'].between(0,14))]\ndf1=df[(df['Day_num'].between(1,15))]\ndf2=df[(df['Day_num'].between(2,16))]\ndf3=df[(df['Day_num'].between(3,17))]\ndf4=df[(df['Day_num'].between(4,18))]\n\ndf5=df[(df['Day_num'].between(5,19))]\ndf6=df[(df['Day_num'].between(6,20))]\ndf7=df[(df['Day_num'].between(7,21))]\ndf8=df[(df['Day_num'].between(8,22))]\ndf9=df[(df['Day_num'].between(9,23))]\ndf10=df[(df['Day_num'].between(10,24))]\ndf11=df[(df['Day_num'].between(11,25))]\ndf12=df[(df['Day_num'].between(12,26))]\ndf13=df[(df['Day_num'].between(13,27))]\ndf14=df[(df['Day_num'].between(14,28))]\ndf15=df[(df['Day_num'].between(15,29))]\ndf16=df[(df['Day_num'].between(16,30))]\ndf17=df[(df['Day_num'].between(17,31))]\ndf18=df[(df['Day_num'].between(18,32))]\ndf19=df[(df['Day_num'].between(19,33))]\ndf20=df[(df['Day_num'].between(20,34))]\ndf21=df[(df['Day_num'].between(21,35))]\ndf22=df[(df['Day_num'].between(22,36))]\ndf23=df[(df['Day_num'].between(23,37))]\ndf24=df[(df['Day_num'].between(24,38))]\ndf25=df[(df['Day_num'].between(25,39))]\ndf26=df[(df['Day_num'].between(26,40))]\ndf27=df[(df['Day_num'].between(27,41))]\ndf28=df[(df['Day_num'].between(28,42))]\ndf29=df[(df['Day_num'].between(29,43))]\ndf30=df[(df['Day_num'].between(30,44))]\ndf31=df[(df['Day_num'].between(31,45))]\ndf32=df[(df['Day_num'].between(32,46))]\ndf33=df[(df['Day_num'].between(33,47))]\ndf34=df[(df['Day_num'].between(34,48))]\ndf35=df[(df['Day_num'].between(35,49))]\ndf36=df[(df['Day_num'].between(36,50))]\ndf37=df[(df['Day_num'].between(37,51))]\ndf38=df[(df['Day_num'].between(38,52))]\ndf39=df[(df['Day_num'].between(39,53))]\ndf40=df[(df['Day_num'].between(40,54))]\ndf41=df[(df['Day_num'].between(41,55))]\ndf42=df[(df['Day_num'].between(42,56))]\ndf43=df[(df['Day_num'].between(43,57))]\ndf44=df[(df['Day_num'].between(44,58))]\ndf45=df[(df['Day_num'].between(45,59))]\ndf46=df[(df['Day_num'].between(46,60))]\ndf47=df[(df['Day_num'].between(47,61))]\ndf48=df[(df['Day_num'].between(48,62))]\ndf49=df[(df['Day_num'].between(49,63))]\ndf50=df[(df['Day_num'].between(50,64))]\ndf51=df[(df['Day_num'].between(51,65))]\ndf52=df[(df['Day_num'].between(52,66))]\ndf53=df[(df['Day_num'].between(53,67))]\ndf54=df[(df['Day_num'].between(54,68))]\ndf55=df[(df['Day_num'].between(55,69))]\ndf56=df[(df['Day_num'].between(56,70))]\ndf57=df[(df['Day_num'].between(57,71))]\ndf58=df[(df['Day_num'].between(58,72))]\ndf59=df[(df['Day_num'].between(59,73))]\ndf60=df[(df['Day_num'].between(60,74))]\ndf61=df[(df['Day_num'].between(61,75))]\ndf62=df[(df['Day_num'].between(62,76))]\ndf63=df[(df['Day_num'].between(63,77))]\ndf64=df[(df['Day_num'].between(64,78))]\ndf65=df[(df['Day_num'].between(65,79))]\ndf66=df[(df['Day_num'].between(66,80))]\ndf67=df[(df['Day_num'].between(67,81))]\ndf68=df[(df['Day_num'].between(68,82))]\n#df69=df[(df['Day_num'].between(69,83))]\n\n\n\n\n\n\n\ndfr=df[(df['Day_num'].between(69,83))]\n\n\n#df6=df[((df['Month']==3)&(df['Day'].between(23,31)))|((df['Month']==4)&(df['Day'].between(1,6)))]\n","ecfbaa8e":"dfr.tail()","10ffc9af":"def make_decay(df):\n    \n\n    dft=df.pivot_table(index='Local',columns='Date',values='ConfirmedCases').reset_index()\n    Lista_colunas=['Local','dia_01','dia_02','dia_03','dia_04','dia_05','dia_06','dia_07',\n               'dia_08','dia_09','dia_10','dia_11','dia_12','dia_13','dia_14','dia_15']\n    dft_copy=dft.copy()\n    dft.columns=Lista_colunas\n    C1=np.where(\n        (dft.iloc[: , -15].values)==0,\n    (np.power(dft.iloc[: , -8].values\/((dft.iloc[: , -15].values)+1),1\/7)) -(1)\n    ,(np.power(dft.iloc[: , -8].values\/((dft.iloc[: , -15].values)),1\/7)) -(1)\n    )\n\n    C1=np.where(C1<0,0,C1)\n\n    C2=np.where(\n        (dft.iloc[: , -8].values)==0,\n    (np.power(dft.iloc[: , -1].values\/((dft.iloc[: , -8].values)+1),1\/7)) -(1)\n    ,(np.power(dft.iloc[: , -1].values\/((dft.iloc[: , -8].values)),1\/7)) -(1)\n    )\n\n    C2=np.where(C2<0,0,C2)\n\n    dft['Crescimento_1']=C1\n    dft['Crescimento_2']=C2\n    \n    #dataset adicionais\n    #gdp2020 = pd.read_csv('\/kaggle\/input\/covidinformacoes\/gdp.csv')\n#population2020 = pd.read_csv('\/kaggle\/input\/population2020\/population2020.csv')\n    \n\n    emprego_vul= pd.read_csv('\/kaggle\/input\/covidinformacoes\/Vulnerable employment ( of total employment).csv',skiprows=1)\n    diox_carb=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Carbon dioxide emissions per capita (tonnes).csv',skiprows=1)\n    expec_vida=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Life expectancy at birth.csv',skiprows=1)\n    gastos_saude=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Current health expenditure ( of GDP).csv',skiprows=1)\n    idh=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Human Development Index (HDI).csv',skiprows=1)\n    idade_mediana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Median age (years).csv',skiprows=1)\n    tuberculose=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Tuberculosis incidence (per 100000 people).csv',skiprows=1)\n    desigualdade_exp_vida=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Inequality in life expectancy ().csv',skiprows=1)\n    desigualdade_idh_ajustado=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Inequality-adjusted HDI (IHDI).csv',skiprows=1)\n    desigualdade_ganhos=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Inequality in income ().csv',skiprows=1)\n    desemprego=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Unemployment total ( of labour force).csv',skiprows=1)\n    #idade_mediana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Median age (years).csv',skiprows=1)\n    #idade_mediana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Median age (years).csv',skiprows=1)\n    populacao=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Population total (millions).csv',skiprows=1)\n    populacao_65=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Population ages 65 and older (millions).csv',skiprows=1)\n    pop_urbana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Population urban ().csv',skiprows=1)\n    energia_nr=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Fossil fuel energy consumption ( of total energy consumption).csv',skiprows=1)\n    pop_prisao=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Prison population (per 100000 people).csv',skiprows=1)\n    usu_internet=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Internet users total ( of population).csv',skiprows=1)\n    jovens_sem_oc=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Youth not in school or employment ( ages 15-24).csv',skiprows=1)\n    escola_anos=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Mean years of schooling (years).csv',skiprows=1)\n    \n    #df_life=emprego_vul.copy()\n    \n    def func(x):\n        x_new = 0\n        try:\n            x_new = float(x.replace(\",\", \"\"))\n        except:\n    #         print(x)\n            x_new = np.nan\n        return x_new\n    \n    tmp = populacao.iloc[:,1].values.tolist()\n    populacao= populacao[['Country', '2018']]\n    populacao['Country']=np.where(populacao['Country']=='United States','US',populacao['Country'])\n    populacao['2018'] = populacao['2018'].apply(lambda x: func(x))\n    populacao.columns = ['Country', 'populacao']\n    \n    tmp = populacao_65.iloc[:,1].values.tolist()\n    populacao_65= populacao_65[['Country', '2018']]\n    populacao_65['Country']=np.where(populacao_65['Country']=='United States','US',populacao_65['Country'])\n    populacao_65['2018'] = populacao_65['2018'].apply(lambda x: func(x))\n    populacao_65.columns = ['Country', 'populacao_65']    \n\n    tmp = pop_urbana.iloc[:,1].values.tolist()\n    pop_urbana= pop_urbana[['Country', '2018']]\n    pop_urbana['Country']=np.where(pop_urbana['Country']=='United States','US',pop_urbana['Country'])\n    pop_urbana['2018'] = pop_urbana['2018'].apply(lambda x: func(x))\n    pop_urbana.columns = ['Country', 'pop_urbana']    \n\n    tmp = energia_nr.iloc[:,1].values.tolist()\n    energia_nr= energia_nr[['Country', '2014']]\n    energia_nr['Country']=np.where(energia_nr['Country']=='United States','US',energia_nr['Country'])\n    energia_nr['2014'] = energia_nr['2014'].apply(lambda x: func(x))\n    energia_nr.columns = ['Country', 'energia_nr']    \n\n    tmp = usu_internet.iloc[:,1].values.tolist()\n    usu_internet= usu_internet[['Country', '2017']]\n    usu_internet['Country']=np.where(usu_internet['Country']=='United States','US',usu_internet['Country'])\n    usu_internet['2017'] = usu_internet['2017'].apply(lambda x: func(x))\n    usu_internet.columns = ['Country', 'usu_internet']\n    \n    tmp = jovens_sem_oc.iloc[:,1].values.tolist()\n    jovens_sem_oc= jovens_sem_oc[['Country', '2017']]\n    jovens_sem_oc['Country']=np.where(jovens_sem_oc['Country']=='United States','US',jovens_sem_oc['Country'])\n    jovens_sem_oc['2017'] = jovens_sem_oc['2017'].apply(lambda x: func(x))\n    jovens_sem_oc.columns = ['Country', 'jovens_sem_oc']\n    \n    tmp = escola_anos.iloc[:,1].values.tolist()\n    escola_anos= escola_anos[['Country', '2018']]\n    escola_anos['Country']=np.where(escola_anos['Country']=='United States','US',escola_anos['Country'])\n    escola_anos['2018'] = escola_anos['2018'].apply(lambda x: func(x))\n    escola_anos.columns = ['Country', 'escola_anos']\n    \n    tmp = emprego_vul.iloc[:,1].values.tolist()\n    emprego_vul = emprego_vul[['Country', '2018']]\n    emprego_vul['Country']=np.where(emprego_vul['Country']=='United States','US',emprego_vul['Country'])\n    emprego_vul['2018'] = emprego_vul['2018'].apply(lambda x: func(x))\n    emprego_vul.columns = ['Country', 'Emprego_vulneravel']\n\n    tmp = diox_carb.iloc[:,1].values.tolist()\n    diox_carb = diox_carb[['Country', '2016']]\n    diox_carb['Country']=np.where(diox_carb['Country']=='United States','US',diox_carb['Country'])\n    diox_carb['2016'] = diox_carb['2016'].apply(lambda x: func(x))\n    diox_carb.columns = ['Country', 'Dioxido_carbono']\n\n    tmp = expec_vida.iloc[:,1].values.tolist()\n    expec_vida = expec_vida[['Country', '2018']]\n    expec_vida['Country']=np.where(expec_vida['Country']=='United States','US',expec_vida['Country'])\n    expec_vida['2018'] = expec_vida['2018'].apply(lambda x: func(x))\n    expec_vida.columns = ['Country', 'Expec_vida']\n    \n    tmp = gastos_saude.iloc[:,1].values.tolist()\n    gastos_saude = gastos_saude[['Country', '2016']]\n    gastos_saude['Country']=np.where(gastos_saude['Country']=='United States','US',gastos_saude['Country'])\n    gastos_saude['2016'] = gastos_saude['2016'].apply(lambda x: func(x))\n    gastos_saude.columns = ['Country', 'Gastos_saude']\n    \n    tmp = idh.iloc[:,1].values.tolist()\n    idh = idh[['Country', '2018']]\n    idh['Country']=np.where(idh['Country']=='United States','US',idh['Country'])\n    idh['2018'] = idh['2018'].apply(lambda x: func(x))\n    idh.columns = ['Country', 'IDH'] \n    \n    tmp= idade_mediana.iloc[:,1].values.tolist()\n    idade_mediana = idade_mediana[['Country', '2020']]\n    idade_mediana['Country']=np.where(idade_mediana['Country']=='United States','US',idade_mediana['Country'])\n    idade_mediana['2020'] = idade_mediana['2020'].apply(lambda x: func(x))\n    idade_mediana.columns = ['Country', 'Idade']\n    \n    tmp= tuberculose.iloc[:,1].values.tolist()\n    tuberculose = tuberculose[['Country', '2017']]\n    tuberculose['Country']=np.where(tuberculose['Country']=='United States','US',tuberculose['Country'])\n    tuberculose['2017'] = tuberculose['2017'].apply(lambda x: func(x))\n    tuberculose.columns = ['Country', 'Tuberculose']\n    \n    tmp= desigualdade_exp_vida.iloc[:,1].values.tolist()\n    desigualdade_exp_vida = desigualdade_exp_vida[['Country', '2018']]\n    desigualdade_exp_vida['Country']=np.where(desigualdade_exp_vida['Country']=='United States','US',desigualdade_exp_vida['Country'])\n    desigualdade_exp_vida['2018'] = desigualdade_exp_vida['2018'].apply(lambda x: func(x))\n    desigualdade_exp_vida.columns = ['Country', 'desigualdade_exp_vida']\n    \n    tmp= desigualdade_ganhos.iloc[:,1].values.tolist()\n    desigualdade_ganhos = desigualdade_ganhos[['Country', '2018']]\n    desigualdade_ganhos['Country']=np.where(desigualdade_ganhos['Country']=='United States','US',desigualdade_ganhos['Country'])\n    desigualdade_ganhos['2018'] = desigualdade_ganhos['2018'].apply(lambda x: func(x))\n    desigualdade_ganhos.columns = ['Country', 'desigualdade_ganhos']\n    \n    tmp= desigualdade_idh_ajustado.iloc[:,1].values.tolist()\n    desigualdade_idh_ajustado = desigualdade_idh_ajustado[['Country', '2018']]\n    desigualdade_idh_ajustado['Country']=np.where(desigualdade_idh_ajustado['Country']=='United States','US',desigualdade_idh_ajustado['Country'])\n    desigualdade_idh_ajustado['2018'] = desigualdade_idh_ajustado['2018'].apply(lambda x: func(x))\n    desigualdade_idh_ajustado.columns = ['Country', 'desigualdade_idh_ajustado']\n    \n    tmp= desemprego.iloc[:,1].values.tolist()\n    desemprego = desemprego[['Country', '2018']]\n    desemprego['Country']=np.where(desemprego['Country']=='United States','US',desemprego['Country'])\n    desemprego['2018'] = desemprego['2018'].apply(lambda x: func(x))\n    desemprego.columns = ['Country', 'desemprego']\n    \n    # Merge\n    \n    dft['Country']=dft['Local'].str.split('\/',expand=True)[0]\n    \n    #train = pd.merge(train, population2020, how='left', left_on = 'Country_Region', right_on = 'name')\n    train=dft.copy()\n    train = pd.merge(train, desemprego, how='left',on='Country')\n    train = pd.merge(train, idade_mediana, how='left', on='Country')\n    train = pd.merge(train, idh, how='left', on='Country')\n    train = pd.merge(train, emprego_vul, how='left', on='Country')\n    train = pd.merge(train, gastos_saude, how='left', on='Country')\n    train = pd.merge(train, expec_vida, how='left', on='Country')\n    train = pd.merge(train, diox_carb, how='left', on='Country')\n    train = pd.merge(train, tuberculose, how='left',on='Country')\n    train = pd.merge(train, desigualdade_exp_vida, how='left', on='Country')\n    train = pd.merge(train, desigualdade_ganhos, how='left',on='Country')\n    train = pd.merge(train, desigualdade_idh_ajustado, how='left', on='Country')\n    train = pd.merge(train, populacao, how='left', on='Country')\n    train = pd.merge(train, populacao_65, how='left', on='Country')\n    train = pd.merge(train, pop_urbana, how='left', on='Country')\n    #train = pd.merge(train, pop_prisao, how='left', on='Country')\n    train = pd.merge(train, energia_nr, how='left', on='Country')\n    train = pd.merge(train, usu_internet, how='left', on='Country')\n    train = pd.merge(train, jovens_sem_oc, how='left', on='Country')\n    train = pd.merge(train, escola_anos, how='left', on='Country')\n    \n    dft=train.copy()\n    dft['Pop_maior65']=np.where(((dft['populacao_65']==-99) | (dft['populacao']==-99)),0,dft['populacao_65'] \/ dft['populacao'])\n    dft.rename({'Taiwan*':'Taiwan'}, axis=1)\n    Beta1_RM=-0.1692\n    dft['Decay']=np.where(((dft['Crescimento_1']==0)|(dft['Crescimento_2']==0)),\n                          Beta1_RM,np.power(dft['Crescimento_2']\/(dft['Crescimento_1']),1\/7) - 1)\n    dft['Decay']=np.where(((dft['Crescimento_1']==0) & (dft['Crescimento_2']==0)),\n                    0,dft['Decay'])\n    dft['Decay']=np.where(dft['Decay'].fillna('Vazio')=='Vazio',0,dft['Decay'])\n    dft['Decay']=np.where(((dft['Decay']>0.02)&(dft['Crescimento_2']>0.20)),(1.5*Beta1_RM),dft['Decay'])\n    dft['Decay']=np.where(((dft_copy.iloc[: ,1].values>100) & (dft['Crescimento_2']>0.1)),(Beta1_RM),dft['Decay'])\n    \n    dft.fillna(-99,inplace=True)\n    \n    \n    return (dft)\n\n\n\n\n# Aplicar fun\u00e7\u00f5es nas diferentes janelas temporais\n\ndft0=make_decay(df0)\ndft1=make_decay(df1)\ndft2=make_decay(df2)\ndft3=make_decay(df3)\ndft4=make_decay(df4)\ndft5=make_decay(df5)\ndft6=make_decay(df6)\ndft7=make_decay(df7)\ndft8=make_decay(df8)\ndft9=make_decay(df9)\ndft10=make_decay(df10)\ndft11=make_decay(df11)\ndft12=make_decay(df12)\ndft13=make_decay(df13)\ndft14=make_decay(df14)\ndft15=make_decay(df15)\ndft16=make_decay(df16)\ndft17=make_decay(df17)\ndft18=make_decay(df18)\ndft19=make_decay(df19)\ndft20=make_decay(df20)\ndft21=make_decay(df21)\ndft22=make_decay(df22)\ndft23=make_decay(df23)\ndft24=make_decay(df24)\ndft25=make_decay(df25)\ndft26=make_decay(df26)\ndft27=make_decay(df27)\ndft28=make_decay(df28)\ndft29=make_decay(df29)\ndft30=make_decay(df30)\ndft31=make_decay(df31)\ndft32=make_decay(df32)\ndft33=make_decay(df33)\ndft34=make_decay(df34)\ndft35=make_decay(df35)\ndft36=make_decay(df36)\ndft37=make_decay(df37)\ndft38=make_decay(df38)\ndft39=make_decay(df39)\ndft40=make_decay(df40)\ndft41=make_decay(df41)\ndft42=make_decay(df42)\ndft43=make_decay(df43)\ndft44=make_decay(df44)\ndft45=make_decay(df45)\ndft46=make_decay(df46)\ndft47=make_decay(df47)\ndft48=make_decay(df48)\ndft49=make_decay(df49)\ndft50=make_decay(df50)\ndft51=make_decay(df51)\ndft52=make_decay(df52)\ndft53=make_decay(df53)\ndft54=make_decay(df54)\ndft55=make_decay(df55)\ndft56=make_decay(df56)\ndft57=make_decay(df57)\ndft58=make_decay(df58)\ndft59=make_decay(df59)\ndft60=make_decay(df60)\ndft61=make_decay(df61)\ndft62=make_decay(df62)\ndft63=make_decay(df63)\ndft64=make_decay(df64)\ndft65=make_decay(df65)\ndft66=make_decay(df66)\ndft67=make_decay(df67)\ndft68=make_decay(df68)\n#dft69=make_decay(df19)\n\n\n\ndftr=make_decay(dfr)\n\n\ndfmodel=pd.concat([dft0,dft1,dft2,dft3,dft4,dft5,dft6\n                  ,dft7,dft8,dft9,dft10,dft11,dft12\n                  ,dft13,dft14,dft15,dft16,dft17\n                  ,dft18,dft19,dft20,dft21,dft22,dft23\n                  ,dft24,dft25,dft26,dft26,dft27,dft28\n                  ,dft29,dft30,dft31,dft32,dft33,dft34\n                  ,dft35,dft36,dft37,dft38,dft39,dft40\n                  ,dft41,dft42,dft43,dft44,dft45,dft46\n                  ,dft47,dft48,dft49,dft50,dft51,dft52\n                  ,dft53,dft54,dft55,dft56,dft57,dft58\n                  ,dft59,dft60,dft61,dft62\n                   ,dft63,dft64\n                   ,dft65,dft66,dft67,dft68\n                   \n                  \n                  \n                  ],ignore_index=True)\ndfmodel.head()","7500ebb4":"dfmodel.describe()","07c942be":"dfmodel.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in dfmodel.columns]\ndftr.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in dftr.columns]\n\n\ndfmodel.fillna(-99,inplace=True)\ndftr.fillna(-99,inplace=True)\n\nresposta=dftr['Decay']\ndfteste_cat= dftr.drop(columns=['Crescimento_1','Crescimento_2','Decay'])\ndfteste= dftr.drop(columns=['Local','Crescimento_1','Crescimento_2','Country','Decay'])\n\ny=dfmodel['Decay']\nvariaveis_cat=dfmodel.drop(columns=['Crescimento_1','Crescimento_2','Decay'])\nvariaveis=dfmodel.drop(columns=['Local','Crescimento_1','Crescimento_2','Country','Decay'])\n\n\nX_train, X_test,y_train,y_test = train_test_split(variaveis, y,test_size=0.1)\ncX_train, cX_test,cy_train,cy_test = train_test_split(variaveis_cat, y,test_size=0.1)\n\n","b4cff00c":"import catboost\nfrom catboost import CatBoostRegressor, Pool","945d0d15":"train_pool = Pool(X_train,\n                  label=y_train\n                  #cat_features=['Local','Country'])\n                 )\nval_pool = Pool(X_test,\n                  label=y_test\n                  #cat_features=['Local','Country'])\n               )\ntest_pool = Pool(dfteste,\n                  label=resposta\n                  #cat_features=['Local','Country'])\n                )","c5642581":"model = CatBoostRegressor(objective='RMSE')\n\nmodel.fit(train_pool, plot=True, eval_set=val_pool, verbose=500)","d9d741a4":"from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n\nparams = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n          'learning_rate': 0.01, 'loss': 'ls'}\nclfGB = GradientBoostingRegressor(**params)\n\nclfGB.fit(X_train, y_train)\nrGB=clfGB.predict(dfteste)\n\nclfRF = RandomForestRegressor()\n\nclfRF.fit(X_train, y_train)\nrRF=clfRF.predict(dfteste)\n","9002d923":"#Hyper Parameters\nparams= {'boosting_type' : 'dart',\n         'max_depth':-1,\n         'objective':'regression',\n         'nthread': 5,\n         'num_leaves':64,\n         'learning_rate':0.01,\n         'max_bin':256,\n         'subsample_for_bin':200,\n         'subsample':1,\n         'subsample_freq':1,\n         'colsample_bytree':0.8,\n         'reg_alpha':1.2,\n         'reg_lambda':1.2,\n         'min_split_gain':0.5,\n         'min_child_weight':1,\n         'min_child_samples':5,\n         'metric':'l2'    \n}\n\ngridParams = {'learning_rate': [0.001,0.01,0.03,0.05,0.07,0.09]\n              ,'num_leaves':[10,20,30,50,70]\n              ,'boosting_type': ['dart']\n              ,'objective': ['regression']\n              ,'random_state' : [13]\n              ,'min_split_gain': [0.01,0.03,0.05]\n              ,'drop_rate' : [0.015,0.02,0.04,0.05,0.07]\n              ,'max_bin': [64,128,256]\n              ,'reg_alpha':[0,1,2,3,5,7]\n              ,'reg_lambda':[0,1,2,3,5,7]\n              ,'colsample_bytree':[0.03,0.05,0.6,0.7,0.8,0.9]\n              ,'min_child_weight':[0.1,0.25,0.5,0.8,1,1.5,2,3]\n}\n\nmdl = lgb.LGBMRegressor(boosting_type='dart',\n                       objective='regression',\n                       n_jobs=-1,\n                       silent=True,\n                       max_depth=params['max_depth'],\n                       max_bin=params['max_bin'],\n                       subsample_for_bin= params['subsample_for_bin'],\n                       subsample=params['subsample'],\n                        subsample_freq=params['subsample_freq'],\n                        min_split_gain=params['min_split_gain'],\n                        min_child_weight=params['min_child_weight'],\n                        min_child_samples=params['min_child_samples'],\n                       )\n\nmdl.get_params().keys()\n\ngrid=RandomizedSearchCV(mdl, gridParams, scoring=make_scorer(score_func=r2_score, greater_is_better=True)\n                        ,n_iter=25,n_jobs=-1)\n\ngrid.fit(X_train,y_train)\n\nprint(grid.best_params_)\nprint(grid.best_score_)\n\n#Get from Grid\/RandomizedSearch\n\nparams['min_split_gain']= grid.best_params_['min_split_gain']\nparams['learning_rate']= grid.best_params_['learning_rate']\nparams['max_bin']= grid.best_params_['max_bin']\nparams['num_leaves']= grid.best_params_['num_leaves']\nparams['drop_rate']= grid.best_params_['drop_rate']\nparams['reg_alpha']= grid.best_params_['reg_alpha']\nparams['reg_lambda']= grid.best_params_['reg_lambda']\nparams['colsample_bytree']= grid.best_params_['colsample_bytree']\nparams['min_child_weight']= grid.best_params_['min_child_weight']\n\n\ntrain_data=lgb.Dataset(X_train,label=y_train)\nlgbm_cases= lgb.train(params,\n               train_data,\n               600,\n               verbose_eval=4)","90836575":"resp=model.predict(test_pool)\nrespLGB=lgbm_cases.predict(dfteste)\nprint(\"MSE CatBoost: %.4f\"  %mean_squared_error(resp,resposta))\nprint(\"MSE GradientBoosting: %.4f\" %mean_squared_error(rGB,resposta))\nprint(\"MSE RandomForest: %.4f\" %mean_squared_error(rRF,resposta))\nprint(\"MSE LightGBM: %.4f\" %mean_squared_error(respLGB,resposta))\n\n\n","4f359603":"dftr['Previsto']=resp\ndftr['Resposta']=resposta\ndftr['Erro']=np.where((((dftr['Previsto'])==0)|(dftr['Resposta'])==0),0,np.abs((dftr['Previsto'] \/ dftr['Resposta']) -1))\ndftr.describe()","5c23b802":"dftr['Modelado']=np.where(dftr['Erro']>0.33,dftr['Decay'],dftr['Previsto'])\ndftr[dftr['Local'].isin(['Brazil','US\/New York','US\/New Jersey','US\/Florida','Italy','Spain','France','Germany'])]","68e909c1":"dft=df_f.pivot_table(index='Local',columns='Date',values='ConfirmedCases').reset_index()\n\ndft_copy=dft.copy()\n#dft.columns=Lista_colunas\nC1=np.where(\n        (dft.iloc[: , -15].values)==0,\n    (np.power(dft.iloc[: , -8].values\/((dft.iloc[: , -15].values)+1),1\/7)) -(1)\n    ,(np.power(dft.iloc[: , -8].values\/((dft.iloc[: , -15].values)),1\/7)) -(1)\n    )\n\nC1=np.where(C1<0,0,C1)\n\nC2=np.where(\n        (dft.iloc[: , -8].values)==0,\n    (np.power(dft.iloc[: , -1].values\/((dft.iloc[: , -8].values)+1),1\/7)) -(1)\n    ,(np.power(dft.iloc[: , -1].values\/((dft.iloc[: , -8].values)),1\/7)) -(1)\n    )\n\nC2=np.where(C2<0,0,C2)\n\ndft['Crescimento_1']=C1\ndft['Crescimento_2']=C2\n\nBeta1_RM=-0.1692\ndft['Decay']=np.where(((dft['Crescimento_1']==0)|(dft['Crescimento_2']==0)),\n                          Beta1_RM,np.power(dft['Crescimento_2']\/(dft['Crescimento_1']),1\/7) - 1)\ndft['Decay']=np.where(((dft['Crescimento_1']==0) & (dft['Crescimento_2']==0)),\n                    0,dft['Decay'])\ndft['Decay']=np.where(dft['Decay'].fillna('Vazio')=='Vazio',0,dft['Decay'])\ndft['Decay']=np.where(((dft['Decay']>0.02)&(dft['Crescimento_2']>0.20)),(1.5*Beta1_RM),dft['Decay'])\ndft['Decay']=np.where(((dft_copy.iloc[: ,1].values>100) & (dft['Crescimento_2']>0.1)),(Beta1_RM),dft['Decay'])\n\ndft.head()\n\ndt=pd.merge(dft,dftr[['Local','Modelado']],on='Local',how='left')\ndt.head()","043068f0":"dt[dt['Local'].isin(['Brazil','US\/New York','US\/New Jersey','US\/Illinois','US\/California','Italy','Spain','France','Germany'])]","8756c756":"Beta0=0.9414\n#Beta1=-0.1692\ndft=dt.copy()\ndft['Decay_Calculado']=dft['Decay']\ndft['Decay']=dft['Modelado']\nBeta1=dft['Decay']\n\n\n\n#dft['Cres_2020-04-01']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-02']=dft['Cres_2020-04-01']*((dft['Cres_2020-04-01']*(Beta1)+Beta0))\n#dft['Cres_2020-04-03']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-04']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-05']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-06']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-07']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-08']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-09']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-10']=dft['Cres_2020-04-09']*((dft['Cres_2020-04-09']*(Beta1)+Beta0))\n#dft['Cres_2020-04-11']=dft['Cres_2020-04-10']*((dft['Cres_2020-04-10']*(Beta1)+Beta0))\n#dft['Cres_2020-04-12']=dft['Cres_2020-04-11']*((dft['Cres_2020-04-11']*(Beta1)+Beta0))\n#dft['Cres_2020-04-13']=dft['Cres_2020-04-12']*((dft['Cres_2020-04-12']*(Beta1)+Beta0))\n#dft['Cres_2020-04-14']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\ndft['Cres_2020-04-15']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\ndft['Cres_2020-04-16']=dft['Cres_2020-04-15']*((dft['Cres_2020-04-15']*(Beta1)+Beta0))\ndft['Cres_2020-04-17']=dft['Cres_2020-04-16']*((dft['Cres_2020-04-16']*(Beta1)+Beta0))\ndft['Cres_2020-04-18']=dft['Cres_2020-04-17']*((dft['Cres_2020-04-17']*(Beta1)+Beta0))\ndft['Cres_2020-04-19']=dft['Cres_2020-04-18']*((dft['Cres_2020-04-18']*(Beta1)+Beta0))\ndft['Cres_2020-04-20']=dft['Cres_2020-04-19']*((dft['Cres_2020-04-19']*(Beta1)+Beta0))\ndft['Cres_2020-04-21']=dft['Cres_2020-04-20']*((dft['Cres_2020-04-20']*(Beta1)+Beta0))\ndft['Cres_2020-04-22']=dft['Cres_2020-04-21']*((dft['Cres_2020-04-21']*(Beta1)+Beta0))\ndft['Cres_2020-04-23']=dft['Cres_2020-04-22']*((dft['Cres_2020-04-22']*(Beta1)+Beta0))\ndft['Cres_2020-04-24']=dft['Cres_2020-04-23']*((dft['Cres_2020-04-23']*(Beta1)+Beta0))\ndft['Cres_2020-04-25']=dft['Cres_2020-04-24']*((dft['Cres_2020-04-24']*(Beta1)+Beta0))\ndft['Cres_2020-04-26']=dft['Cres_2020-04-25']*((dft['Cres_2020-04-25']*(Beta1)+Beta0))\ndft['Cres_2020-04-27']=dft['Cres_2020-04-26']*((dft['Cres_2020-04-26']*(Beta1)+Beta0))\ndft['Cres_2020-04-28']=dft['Cres_2020-04-27']*((dft['Cres_2020-04-27']*(Beta1)+Beta0))\ndft['Cres_2020-04-29']=dft['Cres_2020-04-28']*((dft['Cres_2020-04-28']*(Beta1)+Beta0))\ndft['Cres_2020-04-30']=dft['Cres_2020-04-29']*((dft['Cres_2020-04-29']*(Beta1)+Beta0))\n\ndft['Cres_2020-05-01']=dft['Cres_2020-04-30']*((dft['Cres_2020-04-30']*(Beta1)+Beta0))\ndft['Cres_2020-05-02']=dft['Cres_2020-05-01']*((dft['Cres_2020-05-01']*(Beta1)+Beta0))\ndft['Cres_2020-05-03']=dft['Cres_2020-05-02']*((dft['Cres_2020-05-02']*(Beta1)+Beta0))\ndft['Cres_2020-05-04']=dft['Cres_2020-05-03']*((dft['Cres_2020-05-03']*(Beta1)+Beta0))\ndft['Cres_2020-05-05']=dft['Cres_2020-05-04']*((dft['Cres_2020-05-04']*(Beta1)+Beta0))\ndft['Cres_2020-05-06']=dft['Cres_2020-05-05']*((dft['Cres_2020-05-05']*(Beta1)+Beta0))\ndft['Cres_2020-05-07']=dft['Cres_2020-05-06']*((dft['Cres_2020-05-06']*(Beta1)+Beta0))\ndft['Cres_2020-05-08']=dft['Cres_2020-05-07']*((dft['Cres_2020-05-07']*(Beta1)+Beta0))\ndft['Cres_2020-05-09']=dft['Cres_2020-05-08']*((dft['Cres_2020-05-08']*(Beta1)+Beta0))\ndft['Cres_2020-05-10']=dft['Cres_2020-05-09']*((dft['Cres_2020-05-09']*(Beta1)+Beta0))\ndft['Cres_2020-05-11']=dft['Cres_2020-05-10']*((dft['Cres_2020-05-10']*(Beta1)+Beta0))\ndft['Cres_2020-05-12']=dft['Cres_2020-05-11']*((dft['Cres_2020-05-11']*(Beta1)+Beta0))\ndft['Cres_2020-05-13']=dft['Cres_2020-05-12']*((dft['Cres_2020-05-12']*(Beta1)+Beta0))\ndft['Cres_2020-05-14']=dft['Cres_2020-05-13']*((dft['Cres_2020-05-13']*(Beta1)+Beta0))\n\n\n","089f2ef3":"#dft['2020-04-01']=(1+dft['Cres_2020-04-01'])*dft['2020-03-31']\n#dft['2020-04-02']=(1+dft['Cres_2020-04-02'])*dft['2020-04-01']\n#dft['2020-04-03']=(1+dft['Cres_2020-04-03'])*dft['2020-04-02']\n#dft['2020-04-04']=(1+dft['Cres_2020-04-04'])*dft['2020-04-03']\n#dft['2020-04-05']=(1+dft['Cres_2020-04-05'])*dft['2020-04-04']\n#dft['2020-04-06']=(1+dft['Cres_2020-04-06'])*dft['2020-04-05']\n#dft['2020-04-07']=(1+dft['Cres_2020-04-07'])*dft['2020-04-06']\n#dft['2020-04-08']=(1+dft['Cres_2020-04-08'])*dft['2020-04-07']\n#dft['2020-04-09']=(1+dft['Cres_2020-04-09'])*dft['2020-04-08']\n#dft['2020-04-10']=(1+dft['Cres_2020-04-10'])*dft['2020-04-09']\n#dft['2020-04-11']=(1+dft['Cres_2020-04-11'])*dft['2020-04-10']\n#dft['2020-04-12']=(1+dft['Cres_2020-04-12'])*dft['2020-04-11']\n#dft['2020-04-13']=(1+dft['Cres_2020-04-13'])*dft['2020-04-12']\n#dft['2020-04-14']=(1+dft['Cres_2020-04-14'])*dft['2020-04-13']\ndft['2020-04-15']=(1+dft['Cres_2020-04-15'])*dft['2020-04-14']\ndft['2020-04-16']=(1+dft['Cres_2020-04-16'])*dft['2020-04-15']\ndft['2020-04-17']=(1+dft['Cres_2020-04-17'])*dft['2020-04-16']\ndft['2020-04-18']=(1+dft['Cres_2020-04-18'])*dft['2020-04-17']\ndft['2020-04-19']=(1+dft['Cres_2020-04-19'])*dft['2020-04-18']\ndft['2020-04-20']=(1+dft['Cres_2020-04-20'])*dft['2020-04-19']\ndft['2020-04-21']=(1+dft['Cres_2020-04-21'])*dft['2020-04-20']\ndft['2020-04-22']=(1+dft['Cres_2020-04-22'])*dft['2020-04-21']\ndft['2020-04-23']=(1+dft['Cres_2020-04-23'])*dft['2020-04-22']\ndft['2020-04-24']=(1+dft['Cres_2020-04-24'])*dft['2020-04-23']\ndft['2020-04-25']=(1+dft['Cres_2020-04-25'])*dft['2020-04-24']\ndft['2020-04-26']=(1+dft['Cres_2020-04-26'])*dft['2020-04-25']\ndft['2020-04-27']=(1+dft['Cres_2020-04-27'])*dft['2020-04-26']\ndft['2020-04-28']=(1+dft['Cres_2020-04-28'])*dft['2020-04-27']\ndft['2020-04-29']=(1+dft['Cres_2020-04-29'])*dft['2020-04-28']\ndft['2020-04-30']=(1+dft['Cres_2020-04-30'])*dft['2020-04-29']\n\ndft['2020-05-01']=(1+dft['Cres_2020-05-01'])*dft['2020-04-30']\ndft['2020-05-02']=(1+dft['Cres_2020-05-02'])*dft['2020-05-01']\ndft['2020-05-03']=(1+dft['Cres_2020-05-03'])*dft['2020-05-02']\ndft['2020-05-04']=(1+dft['Cres_2020-05-04'])*dft['2020-05-03']\ndft['2020-05-05']=(1+dft['Cres_2020-05-05'])*dft['2020-05-04']\ndft['2020-05-06']=(1+dft['Cres_2020-05-06'])*dft['2020-05-05']\ndft['2020-05-07']=(1+dft['Cres_2020-05-07'])*dft['2020-05-06']\ndft['2020-05-08']=(1+dft['Cres_2020-05-08'])*dft['2020-05-07']\ndft['2020-05-09']=(1+dft['Cres_2020-05-09'])*dft['2020-05-08']\ndft['2020-05-10']=(1+dft['Cres_2020-05-10'])*dft['2020-05-09']\ndft['2020-05-11']=(1+dft['Cres_2020-05-11'])*dft['2020-05-10']\ndft['2020-05-12']=(1+dft['Cres_2020-05-12'])*dft['2020-05-11']\ndft['2020-05-13']=(1+dft['Cres_2020-05-13'])*dft['2020-05-12']\ndft['2020-05-14']=(1+dft['Cres_2020-05-14'])*dft['2020-05-13']","a51da45f":"def make_decay_d(df):\n    \n\n    dft=df.pivot_table(index='Local',columns='Date',values='Mortalidade').reset_index()\n    Lista_colunas=['Local','dia_01','dia_02','dia_03','dia_04','dia_05','dia_06','dia_07',\n               'dia_08','dia_09','dia_10','dia_11','dia_12','dia_13','dia_14','dia_15']\n    dft_copy=dft.copy()\n    dft.columns=Lista_colunas\n    C1=np.where(\n        (dft.iloc[: , -15].values)==0,\n    (np.power(dft.iloc[: , -8].values\/((dft.iloc[: , -15].values)+1),1\/7)) -(1)\n    ,(np.power(dft.iloc[: , -8].values\/((dft.iloc[: , -15].values)),1\/7)) -(1)\n    )\n\n    C1=np.where(C1<0,0,C1)\n\n    C2=np.where(\n        (dft.iloc[: , -8].values)==0,\n    (np.power(dft.iloc[: , -1].values\/((dft.iloc[: , -8].values)+1),1\/7)) -(1)\n    ,(np.power(dft.iloc[: , -1].values\/((dft.iloc[: , -8].values)),1\/7)) -(1)\n    )\n\n    C2=np.where(C2<0,0,C2)\n\n    dft['Crescimento_1']=C1\n    dft['Crescimento_2']=C2\n    \n    #dataset adicionais\n    #gdp2020 = pd.read_csv('\/kaggle\/input\/covidinformacoes\/gdp.csv')\n#population2020 = pd.read_csv('\/kaggle\/input\/population2020\/population2020.csv')\n    \n\n    emprego_vul= pd.read_csv('\/kaggle\/input\/covidinformacoes\/Vulnerable employment ( of total employment).csv',skiprows=1)\n    diox_carb=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Carbon dioxide emissions per capita (tonnes).csv',skiprows=1)\n    expec_vida=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Life expectancy at birth.csv',skiprows=1)\n    gastos_saude=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Current health expenditure ( of GDP).csv',skiprows=1)\n    idh=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Human Development Index (HDI).csv',skiprows=1)\n    idade_mediana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Median age (years).csv',skiprows=1)\n    tuberculose=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Tuberculosis incidence (per 100000 people).csv',skiprows=1)\n    desigualdade_exp_vida=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Inequality in life expectancy ().csv',skiprows=1)\n    desigualdade_idh_ajustado=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Inequality-adjusted HDI (IHDI).csv',skiprows=1)\n    desigualdade_ganhos=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Inequality in income ().csv',skiprows=1)\n    desemprego=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Unemployment total ( of labour force).csv',skiprows=1)\n    #idade_mediana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Median age (years).csv',skiprows=1)\n    #idade_mediana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Median age (years).csv',skiprows=1)\n    populacao=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Population total (millions).csv',skiprows=1)\n    populacao_65=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Population ages 65 and older (millions).csv',skiprows=1)\n    pop_urbana=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Population urban ().csv',skiprows=1)\n    energia_nr=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Fossil fuel energy consumption ( of total energy consumption).csv',skiprows=1)\n    pop_prisao=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Prison population (per 100000 people).csv',skiprows=1)\n    usu_internet=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Internet users total ( of population).csv',skiprows=1)\n    jovens_sem_oc=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Youth not in school or employment ( ages 15-24).csv',skiprows=1)\n    escola_anos=pd.read_csv('\/kaggle\/input\/covidinformacoes\/Mean years of schooling (years).csv',skiprows=1)\n    \n    #df_life=emprego_vul.copy()\n    \n    def func(x):\n        x_new = 0\n        try:\n            x_new = float(x.replace(\",\", \"\"))\n        except:\n    #         print(x)\n            x_new = np.nan\n        return x_new\n    \n    tmp = populacao.iloc[:,1].values.tolist()\n    populacao= populacao[['Country', '2018']]\n    populacao['Country']=np.where(populacao['Country']=='United States','US',populacao['Country'])\n    populacao['2018'] = populacao['2018'].apply(lambda x: func(x))\n    populacao.columns = ['Country', 'populacao']\n    \n    tmp = populacao_65.iloc[:,1].values.tolist()\n    populacao_65= populacao_65[['Country', '2018']]\n    populacao_65['Country']=np.where(populacao_65['Country']=='United States','US',populacao_65['Country'])\n    populacao_65['2018'] = populacao_65['2018'].apply(lambda x: func(x))\n    populacao_65.columns = ['Country', 'populacao_65']    \n\n    tmp = pop_urbana.iloc[:,1].values.tolist()\n    pop_urbana= pop_urbana[['Country', '2018']]\n    pop_urbana['Country']=np.where(pop_urbana['Country']=='United States','US',pop_urbana['Country'])\n    pop_urbana['2018'] = pop_urbana['2018'].apply(lambda x: func(x))\n    pop_urbana.columns = ['Country', 'pop_urbana']    \n\n    tmp = energia_nr.iloc[:,1].values.tolist()\n    energia_nr= energia_nr[['Country', '2014']]\n    energia_nr['Country']=np.where(energia_nr['Country']=='United States','US',energia_nr['Country'])\n    energia_nr['2014'] = energia_nr['2014'].apply(lambda x: func(x))\n    energia_nr.columns = ['Country', 'energia_nr']    \n\n    tmp = usu_internet.iloc[:,1].values.tolist()\n    usu_internet= usu_internet[['Country', '2017']]\n    usu_internet['Country']=np.where(usu_internet['Country']=='United States','US',usu_internet['Country'])\n    usu_internet['2017'] = usu_internet['2017'].apply(lambda x: func(x))\n    usu_internet.columns = ['Country', 'usu_internet']\n    \n    tmp = jovens_sem_oc.iloc[:,1].values.tolist()\n    jovens_sem_oc= jovens_sem_oc[['Country', '2017']]\n    jovens_sem_oc['Country']=np.where(jovens_sem_oc['Country']=='United States','US',jovens_sem_oc['Country'])\n    jovens_sem_oc['2017'] = jovens_sem_oc['2017'].apply(lambda x: func(x))\n    jovens_sem_oc.columns = ['Country', 'jovens_sem_oc']\n    \n    tmp = escola_anos.iloc[:,1].values.tolist()\n    escola_anos= escola_anos[['Country', '2018']]\n    escola_anos['Country']=np.where(escola_anos['Country']=='United States','US',escola_anos['Country'])\n    escola_anos['2018'] = escola_anos['2018'].apply(lambda x: func(x))\n    escola_anos.columns = ['Country', 'escola_anos']\n    \n    tmp = emprego_vul.iloc[:,1].values.tolist()\n    emprego_vul = emprego_vul[['Country', '2018']]\n    emprego_vul['Country']=np.where(emprego_vul['Country']=='United States','US',emprego_vul['Country'])\n    emprego_vul['2018'] = emprego_vul['2018'].apply(lambda x: func(x))\n    emprego_vul.columns = ['Country', 'Emprego_vulneravel']\n\n    tmp = diox_carb.iloc[:,1].values.tolist()\n    diox_carb = diox_carb[['Country', '2016']]\n    diox_carb['Country']=np.where(diox_carb['Country']=='United States','US',diox_carb['Country'])\n    diox_carb['2016'] = diox_carb['2016'].apply(lambda x: func(x))\n    diox_carb.columns = ['Country', 'Dioxido_carbono']\n\n    tmp = expec_vida.iloc[:,1].values.tolist()\n    expec_vida = expec_vida[['Country', '2018']]\n    expec_vida['Country']=np.where(expec_vida['Country']=='United States','US',expec_vida['Country'])\n    expec_vida['2018'] = expec_vida['2018'].apply(lambda x: func(x))\n    expec_vida.columns = ['Country', 'Expec_vida']\n    \n    tmp = gastos_saude.iloc[:,1].values.tolist()\n    gastos_saude = gastos_saude[['Country', '2016']]\n    gastos_saude['Country']=np.where(gastos_saude['Country']=='United States','US',gastos_saude['Country'])\n    gastos_saude['2016'] = gastos_saude['2016'].apply(lambda x: func(x))\n    gastos_saude.columns = ['Country', 'Gastos_saude']\n    \n    tmp = idh.iloc[:,1].values.tolist()\n    idh = idh[['Country', '2018']]\n    idh['Country']=np.where(idh['Country']=='United States','US',idh['Country'])\n    idh['2018'] = idh['2018'].apply(lambda x: func(x))\n    idh.columns = ['Country', 'IDH'] \n    \n    tmp= idade_mediana.iloc[:,1].values.tolist()\n    idade_mediana = idade_mediana[['Country', '2020']]\n    idade_mediana['Country']=np.where(idade_mediana['Country']=='United States','US',idade_mediana['Country'])\n    idade_mediana['2020'] = idade_mediana['2020'].apply(lambda x: func(x))\n    idade_mediana.columns = ['Country', 'Idade']\n    \n    tmp= tuberculose.iloc[:,1].values.tolist()\n    tuberculose = tuberculose[['Country', '2017']]\n    tuberculose['Country']=np.where(tuberculose['Country']=='United States','US',tuberculose['Country'])\n    tuberculose['2017'] = tuberculose['2017'].apply(lambda x: func(x))\n    tuberculose.columns = ['Country', 'Tuberculose']\n    \n    tmp= desigualdade_exp_vida.iloc[:,1].values.tolist()\n    desigualdade_exp_vida = desigualdade_exp_vida[['Country', '2018']]\n    desigualdade_exp_vida['Country']=np.where(desigualdade_exp_vida['Country']=='United States','US',desigualdade_exp_vida['Country'])\n    desigualdade_exp_vida['2018'] = desigualdade_exp_vida['2018'].apply(lambda x: func(x))\n    desigualdade_exp_vida.columns = ['Country', 'desigualdade_exp_vida']\n    \n    tmp= desigualdade_ganhos.iloc[:,1].values.tolist()\n    desigualdade_ganhos = desigualdade_ganhos[['Country', '2018']]\n    desigualdade_ganhos['Country']=np.where(desigualdade_ganhos['Country']=='United States','US',desigualdade_ganhos['Country'])\n    desigualdade_ganhos['2018'] = desigualdade_ganhos['2018'].apply(lambda x: func(x))\n    desigualdade_ganhos.columns = ['Country', 'desigualdade_ganhos']\n    \n    tmp= desigualdade_idh_ajustado.iloc[:,1].values.tolist()\n    desigualdade_idh_ajustado = desigualdade_idh_ajustado[['Country', '2018']]\n    desigualdade_idh_ajustado['Country']=np.where(desigualdade_idh_ajustado['Country']=='United States','US',desigualdade_idh_ajustado['Country'])\n    desigualdade_idh_ajustado['2018'] = desigualdade_idh_ajustado['2018'].apply(lambda x: func(x))\n    desigualdade_idh_ajustado.columns = ['Country', 'desigualdade_idh_ajustado']\n    \n    tmp= desemprego.iloc[:,1].values.tolist()\n    desemprego = desemprego[['Country', '2018']]\n    desemprego['Country']=np.where(desemprego['Country']=='United States','US',desemprego['Country'])\n    desemprego['2018'] = desemprego['2018'].apply(lambda x: func(x))\n    desemprego.columns = ['Country', 'desemprego']\n    \n    # Merge\n    \n    dft['Country']=dft['Local'].str.split('\/',expand=True)[0]\n    \n    #train = pd.merge(train, population2020, how='left', left_on = 'Country_Region', right_on = 'name')\n    train=dft.copy()\n    train = pd.merge(train, desemprego, how='left',on='Country')\n    train = pd.merge(train, idade_mediana, how='left', on='Country')\n    train = pd.merge(train, idh, how='left', on='Country')\n    train = pd.merge(train, emprego_vul, how='left', on='Country')\n    train = pd.merge(train, gastos_saude, how='left', on='Country')\n    train = pd.merge(train, expec_vida, how='left', on='Country')\n    train = pd.merge(train, diox_carb, how='left', on='Country')\n    train = pd.merge(train, tuberculose, how='left',on='Country')\n    train = pd.merge(train, desigualdade_exp_vida, how='left', on='Country')\n    train = pd.merge(train, desigualdade_ganhos, how='left',on='Country')\n    train = pd.merge(train, desigualdade_idh_ajustado, how='left', on='Country')\n    train = pd.merge(train, populacao, how='left', on='Country')\n    train = pd.merge(train, populacao_65, how='left', on='Country')\n    train = pd.merge(train, pop_urbana, how='left', on='Country')\n    #train = pd.merge(train, pop_prisao, how='left', on='Country')\n    train = pd.merge(train, energia_nr, how='left', on='Country')\n    train = pd.merge(train, usu_internet, how='left', on='Country')\n    train = pd.merge(train, jovens_sem_oc, how='left', on='Country')\n    train = pd.merge(train, escola_anos, how='left', on='Country')\n    \n    dft=train.copy()\n    dft['Pop_maior65']=np.where(((dft['populacao_65']==-99) | (dft['populacao']==-99)),0,dft['populacao_65'] \/ dft['populacao'])\n    dft.rename({'Taiwan*':'Taiwan'}, axis=1)\n\n    \n    dft.fillna(-99,inplace=True)\n    \n    \n    return (dft)\n\n\n\n\n# Aplicar fun\u00e7\u00f5es nas diferentes janelas temporais\n\ndft0=make_decay_d(df0)\ndft1=make_decay_d(df1)\ndft2=make_decay_d(df2)\ndft3=make_decay_d(df3)\ndft4=make_decay_d(df4)\ndft5=make_decay_d(df5)\ndft6=make_decay_d(df6)\ndft7=make_decay_d(df7)\ndft8=make_decay_d(df8)\ndft9=make_decay_d(df9)\ndft10=make_decay_d(df10)\ndft11=make_decay_d(df11)\ndft12=make_decay_d(df12)\ndft13=make_decay_d(df13)\ndft14=make_decay_d(df14)\ndft15=make_decay_d(df15)\ndft16=make_decay_d(df16)\ndft17=make_decay_d(df17)\ndft18=make_decay_d(df18)\ndft19=make_decay_d(df19)\ndft20=make_decay_d(df20)\ndft21=make_decay_d(df21)\ndft22=make_decay_d(df22)\ndft23=make_decay_d(df23)\ndft24=make_decay_d(df24)\ndft25=make_decay_d(df25)\ndft26=make_decay_d(df26)\ndft27=make_decay_d(df27)\ndft28=make_decay_d(df28)\ndft29=make_decay_d(df29)\ndft30=make_decay_d(df30)\ndft31=make_decay_d(df31)\ndft32=make_decay_d(df32)\ndft33=make_decay_d(df33)\ndft34=make_decay_d(df34)\ndft35=make_decay_d(df35)\ndft36=make_decay_d(df36)\ndft37=make_decay_d(df37)\ndft38=make_decay_d(df38)\ndft39=make_decay_d(df39)\ndft40=make_decay_d(df40)\ndft41=make_decay_d(df41)\ndft42=make_decay_d(df42)\ndft43=make_decay_d(df43)\ndft44=make_decay_d(df44)\ndft45=make_decay_d(df45)\ndft46=make_decay_d(df46)\ndft47=make_decay_d(df47)\ndft48=make_decay_d(df48)\ndft49=make_decay_d(df49)\ndft50=make_decay_d(df50)\ndft51=make_decay_d(df51)\ndft52=make_decay_d(df52)\ndft53=make_decay_d(df53)\ndft54=make_decay_d(df54)\ndft55=make_decay_d(df55)\ndft56=make_decay_d(df56)\ndft57=make_decay_d(df57)\ndft58=make_decay_d(df58)\ndft59=make_decay_d(df59)\ndft60=make_decay_d(df60)\ndft61=make_decay_d(df61)\ndft62=make_decay_d(df62)\ndft63=make_decay_d(df63)\ndft64=make_decay_d(df64)\ndft65=make_decay_d(df65)\ndft66=make_decay_d(df66)\ndft67=make_decay_d(df67)\ndft68=make_decay_d(df68)\n#dft69=make_decay(df19)\n\n\n\ndftr_d=make_decay_d(dfr)\n\n\ndfmodel_d=pd.concat([dft0,dft1,dft2,dft3,dft4,dft5,dft6\n                  ,dft7,dft8,dft9,dft10,dft11,dft12\n                  ,dft13,dft14,dft15,dft16,dft17\n                  ,dft18,dft19,dft20,dft21,dft22,dft23\n                  ,dft24,dft25,dft26,dft26,dft27,dft28\n                  ,dft29,dft30,dft31,dft32,dft33,dft34\n                  ,dft35,dft36,dft37,dft38,dft39,dft40\n                  ,dft41,dft42,dft43,dft44,dft45,dft46\n                  ,dft47,dft48,dft49,dft50,dft51,dft52\n                  ,dft53,dft54,dft55,dft56,dft57,dft58\n                  ,dft59,dft60,dft61,dft62\n                   ,dft63,dft64\n                   ,dft65,dft66,dft67,dft68\n                   \n                  \n                  \n                  ],ignore_index=True)\n\ndfmodel_d.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in dfmodel_d.columns]\ndftr_d.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in dftr_d.columns]\n\n\ndfmodel_d.fillna(-99,inplace=True)\ndftr_d.fillna(-99,inplace=True)\n\nresposta_d=dftr_d['Crescimento_2']\n#dfteste_cat= dftr.drop(columns=['Crescimento_1','Crescimento_2','Decay'])\ndfteste_d= dftr_d.drop(columns=['Local','Crescimento_1','Crescimento_2','Country','dia_15'])\n\ny_d=dfmodel_d['Crescimento_2']\n#variaveis_cat=dfmodel.drop(columns=['Crescimento_1','Crescimento_2','Decay'])\nvariaveis_d=dfmodel_d.drop(columns=['Local','Crescimento_1','Crescimento_2','Country','dia_15'])\n\n\nX_trainD, X_testD,y_trainD,y_testD = train_test_split(variaveis_d, y_d,test_size=0.1)\n#cX_train, cX_test,cy_train,cy_test = train_test_split(variaveis_cat, y,test_size=0.1)","a3b0dca7":"\n\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n\nparams = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n          'learning_rate': 0.01, 'loss': 'ls'}\nclfGB = GradientBoostingRegressor(**params)\n\nclfGB.fit(X_trainD, y_trainD)\nrGB=clfGB.predict(dfteste_d)\n\nclfRF = RandomForestRegressor()\n\nclfRF.fit(X_trainD, y_trainD)\nrRF=clfRF.predict(dfteste_d)\n\n####LightGBM#######\n#Hyper Parameters\nparams= {'boosting_type' : 'dart',\n         'max_depth':-1,\n         'objective':'regression',\n         'nthread': 5,\n         'num_leaves':64,\n         'learning_rate':0.01,\n         'max_bin':256,\n         'subsample_for_bin':200,\n         'subsample':1,\n         'subsample_freq':1,\n         'colsample_bytree':0.8,\n         'reg_alpha':1.2,\n         'reg_lambda':1.2,\n         'min_split_gain':0.5,\n         'min_child_weight':1,\n         'min_child_samples':5,\n         'metric':'l2'    \n}\n\ngridParams = {'learning_rate': [0.001,0.01,0.03,0.05,0.07,0.09]\n              ,'num_leaves':[10,20,30,50,70]\n              ,'boosting_type': ['dart']\n              ,'objective': ['regression']\n              ,'random_state' : [13]\n              ,'min_split_gain': [0.01,0.03,0.05]\n              ,'drop_rate' : [0.015,0.02,0.04,0.05,0.07]\n              ,'max_bin': [64,128,256]\n              ,'reg_alpha':[0,1,2,3,5,7]\n              ,'reg_lambda':[0,1,2,3,5,7]\n              ,'colsample_bytree':[0.03,0.05,0.6,0.7,0.8,0.9]\n              ,'min_child_weight':[0.1,0.25,0.5,0.8,1,1.5,2,3]\n}\n\nmdl = lgb.LGBMRegressor(boosting_type='dart',\n                       objective='regression',\n                       n_jobs=-1,\n                       silent=True,\n                       max_depth=params['max_depth'],\n                       max_bin=params['max_bin'],\n                       subsample_for_bin= params['subsample_for_bin'],\n                       subsample=params['subsample'],\n                        subsample_freq=params['subsample_freq'],\n                        min_split_gain=params['min_split_gain'],\n                        min_child_weight=params['min_child_weight'],\n                        min_child_samples=params['min_child_samples'],\n                       )\n\nmdl.get_params().keys()\n\ngrid=RandomizedSearchCV(mdl, gridParams, scoring=make_scorer(score_func=r2_score, greater_is_better=True)\n                        ,n_iter=25,n_jobs=-1)\n\ngrid.fit(X_trainD,y_trainD)\n\nprint(grid.best_params_)\nprint(grid.best_score_)\n\n#Get from Grid\/RandomizedSearch\n\nparams['min_split_gain']= grid.best_params_['min_split_gain']\nparams['learning_rate']= grid.best_params_['learning_rate']\nparams['max_bin']= grid.best_params_['max_bin']\nparams['num_leaves']= grid.best_params_['num_leaves']\nparams['drop_rate']= grid.best_params_['drop_rate']\nparams['reg_alpha']= grid.best_params_['reg_alpha']\nparams['reg_lambda']= grid.best_params_['reg_lambda']\nparams['colsample_bytree']= grid.best_params_['colsample_bytree']\nparams['min_child_weight']= grid.best_params_['min_child_weight']\n\n\ntrain_data=lgb.Dataset(X_trainD,label=y_trainD)\nlgbm_cases= lgb.train(params,\n               train_data,\n               600,\n               verbose_eval=4)\n\n\n#####CatBoost######\ntrain_pool_d = Pool(X_trainD,\n                  label=y_trainD\n                  #cat_features=['Local','Country'])\n                 )\nval_pool_d = Pool(X_testD,\n                  label=y_testD\n                  #cat_features=['Local','Country'])\n               )\ntest_pool_d = Pool(dfteste_d,\n                  label=resposta_d\n                  #cat_features=['Local','Country'])\n                )\nmodel = CatBoostRegressor(objective='RMSE')\n\nmodel.fit(train_pool_d, plot=True, eval_set=val_pool_d, verbose=500)","1ce0d757":"resp=model.predict(test_pool_d)\nrespLGB=lgbm_cases.predict(dfteste_d)\nprint(\"MSE CatBoost: %.4f\"  %mean_squared_error(resp,resposta))\nprint(\"MSE GradientBoosting: %.4f\" %mean_squared_error(rGB,resposta))\nprint(\"MSE RandomForest: %.4f\" %mean_squared_error(rRF,resposta))\nprint(\"MSE LightGBM: %.4f\" %mean_squared_error(respLGB,resposta))\n\ndftr_d['Previsto']=resp\ndftr_d['Resposta']=resposta_d\n\ndftr_d[dftr_d['Local'].isin(['Brazil','US\/New York','US\/New Jersey','US\/Florida','Italy','Spain','France','Germany'])]","1b332798":"dftr_d['Previsto']=np.where((dftr_d['Crescimento_2'])>(dftr_d['Crescimento_1']),dftr_d['Previsto'],dftr_d['Previsto']\/7)\ncopy_dftr=dftr_d.copy()\ndftr_d=df_f.pivot_table(index='Local',columns='Date',values='Mortalidade').reset_index()\n\ndftr_copy=dftr_d.copy()\n#dft.columns=Lista_colunas\nC1=np.where(\n        (dftr_d.iloc[: , -15].values)==0,\n    (np.power(dftr_d.iloc[: , -8].values\/((dftr_d.iloc[: , -15].values)+1),1\/7)) -(1)\n    ,(np.power(dftr_d.iloc[: , -8].values\/((dftr_d.iloc[: , -15].values)),1\/7)) -(1)\n    )\n\nC1=np.where(C1<0,0,C1)\n\nC2=np.where(\n        (dftr_d.iloc[: , -8].values)==0,\n    (np.power(dftr_d.iloc[: , -1].values\/((dftr_d.iloc[: , -8].values)+1),1\/7)) -(1)\n    ,(np.power(dftr_d.iloc[: , -1].values\/((dftr_d.iloc[: , -8].values)),1\/7)) -(1)\n    )\n\nC2=np.where(C2<0,0,C2)\n\ndftr_d['Crescimento_1']=C1\ndftr_d['Crescimento_2']=C2\n\n\n\n\nBeta0=0.25\n#Beta1=-0.1692\n\nBeta1=copy_dftr['Previsto']\n\n\n\n#dft['Cres_2020-04-01']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-02']=dft['Cres_2020-04-01']*((dft['Cres_2020-04-01']*(Beta1)+Beta0))\n#dft['Cres_2020-04-03']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-04']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-05']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-06']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-07']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-08']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-09']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-10']=dft['Cres_2020-04-09']*((dft['Cres_2020-04-09']*(Beta1)+Beta0))\n#dft['Cres_2020-04-11']=dft['Cres_2020-04-10']*((dft['Cres_2020-04-10']*(Beta1)+Beta0))\n#dft['Cres_2020-04-12']=dft['Cres_2020-04-11']*((dft['Cres_2020-04-11']*(Beta1)+Beta0))\n#dft['Cres_2020-04-13']=dft['Cres_2020-04-12']*((dft['Cres_2020-04-12']*(Beta1)+Beta0))\n#dft['Cres_2020-04-14']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-15']=dftr_d['Crescimento_2']*((dftr_d['Crescimento_2']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-16']=dftr_d['Cres_2020-04-15']*((dftr_d['Cres_2020-04-15']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-17']=dftr_d['Cres_2020-04-16']*((dftr_d['Cres_2020-04-16']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-18']=dftr_d['Cres_2020-04-17']*((dftr_d['Cres_2020-04-17']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-19']=dftr_d['Cres_2020-04-18']*((dftr_d['Cres_2020-04-18']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-20']=dftr_d['Cres_2020-04-19']*((dftr_d['Cres_2020-04-19']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-21']=dftr_d['Cres_2020-04-20']*((dftr_d['Cres_2020-04-20']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-22']=dftr_d['Cres_2020-04-21']*((dftr_d['Cres_2020-04-21']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-23']=dftr_d['Cres_2020-04-22']*((dftr_d['Cres_2020-04-22']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-24']=dftr_d['Cres_2020-04-23']*((dftr_d['Cres_2020-04-23']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-25']=dftr_d['Cres_2020-04-24']*((dftr_d['Cres_2020-04-24']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-26']=dftr_d['Cres_2020-04-25']*((dftr_d['Cres_2020-04-25']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-27']=dftr_d['Cres_2020-04-26']*((dftr_d['Cres_2020-04-26']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-28']=dftr_d['Cres_2020-04-27']*((dftr_d['Cres_2020-04-27']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-29']=dftr_d['Cres_2020-04-28']*((dftr_d['Cres_2020-04-28']*(Beta1)+Beta0))\ndftr_d['Cres_2020-04-30']=dftr_d['Cres_2020-04-29']*((dftr_d['Cres_2020-04-29']*(Beta1)+Beta0))\n\ndftr_d['Cres_2020-05-01']=dftr_d['Cres_2020-04-30']*((dftr_d['Cres_2020-04-30']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-02']=dftr_d['Cres_2020-05-01']*((dftr_d['Cres_2020-05-01']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-03']=dftr_d['Cres_2020-05-02']*((dftr_d['Cres_2020-05-02']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-04']=dftr_d['Cres_2020-05-03']*((dftr_d['Cres_2020-05-03']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-05']=dftr_d['Cres_2020-05-04']*((dftr_d['Cres_2020-05-04']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-06']=dftr_d['Cres_2020-05-05']*((dftr_d['Cres_2020-05-05']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-07']=dftr_d['Cres_2020-05-06']*((dftr_d['Cres_2020-05-06']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-08']=dftr_d['Cres_2020-05-07']*((dftr_d['Cres_2020-05-07']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-09']=dftr_d['Cres_2020-05-08']*((dftr_d['Cres_2020-05-08']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-10']=dftr_d['Cres_2020-05-09']*((dftr_d['Cres_2020-05-09']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-11']=dftr_d['Cres_2020-05-10']*((dftr_d['Cres_2020-05-10']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-12']=dftr_d['Cres_2020-05-11']*((dftr_d['Cres_2020-05-11']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-13']=dftr_d['Cres_2020-05-12']*((dftr_d['Cres_2020-05-12']*(Beta1)+Beta0))\ndftr_d['Cres_2020-05-14']=dftr_d['Cres_2020-05-13']*((dftr_d['Cres_2020-05-13']*(Beta1)+Beta0))","3e13ee2c":"dftr_d['2020-04-15']=(1+dftr_d['Cres_2020-04-15'])*dftr_d['2020-04-14']\ndftr_d['2020-04-16']=(1+dftr_d['Cres_2020-04-16'])*dftr_d['2020-04-15']\ndftr_d['2020-04-17']=(1+dftr_d['Cres_2020-04-17'])*dftr_d['2020-04-16']\ndftr_d['2020-04-18']=(1+dftr_d['Cres_2020-04-18'])*dftr_d['2020-04-17']\ndftr_d['2020-04-19']=(1+dftr_d['Cres_2020-04-19'])*dftr_d['2020-04-18']\ndftr_d['2020-04-20']=(1+dftr_d['Cres_2020-04-20'])*dftr_d['2020-04-19']\ndftr_d['2020-04-21']=(1+dftr_d['Cres_2020-04-21'])*dftr_d['2020-04-20']\ndftr_d['2020-04-22']=(1+dftr_d['Cres_2020-04-22'])*dftr_d['2020-04-21']\ndftr_d['2020-04-23']=(1+dftr_d['Cres_2020-04-23'])*dftr_d['2020-04-22']\ndftr_d['2020-04-24']=(1+dftr_d['Cres_2020-04-24'])*dftr_d['2020-04-23']\ndftr_d['2020-04-25']=(1+dftr_d['Cres_2020-04-25'])*dftr_d['2020-04-24']\ndftr_d['2020-04-26']=(1+dftr_d['Cres_2020-04-26'])*dftr_d['2020-04-25']\ndftr_d['2020-04-27']=(1+dftr_d['Cres_2020-04-27'])*dftr_d['2020-04-26']\ndftr_d['2020-04-28']=(1+dftr_d['Cres_2020-04-28'])*dftr_d['2020-04-27']\ndftr_d['2020-04-29']=(1+dftr_d['Cres_2020-04-29'])*dftr_d['2020-04-28']\ndftr_d['2020-04-30']=(1+dftr_d['Cres_2020-04-30'])*dftr_d['2020-04-29']\n\ndftr_d['2020-05-01']=(1+dftr_d['Cres_2020-05-01'])*dftr_d['2020-04-30']\ndftr_d['2020-05-02']=(1+dftr_d['Cres_2020-05-02'])*dftr_d['2020-05-01']\ndftr_d['2020-05-03']=(1+dftr_d['Cres_2020-05-03'])*dftr_d['2020-05-02']\ndftr_d['2020-05-04']=(1+dftr_d['Cres_2020-05-04'])*dftr_d['2020-05-03']\ndftr_d['2020-05-05']=(1+dftr_d['Cres_2020-05-05'])*dftr_d['2020-05-04']\ndftr_d['2020-05-06']=(1+dftr_d['Cres_2020-05-06'])*dftr_d['2020-05-05']\ndftr_d['2020-05-07']=(1+dftr_d['Cres_2020-05-07'])*dftr_d['2020-05-06']\ndftr_d['2020-05-08']=(1+dftr_d['Cres_2020-05-08'])*dftr_d['2020-05-07']\ndftr_d['2020-05-09']=(1+dftr_d['Cres_2020-05-09'])*dftr_d['2020-05-08']\ndftr_d['2020-05-10']=(1+dftr_d['Cres_2020-05-10'])*dftr_d['2020-05-09']\ndftr_d['2020-05-11']=(1+dftr_d['Cres_2020-05-11'])*dftr_d['2020-05-10']\ndftr_d['2020-05-12']=(1+dftr_d['Cres_2020-05-12'])*dftr_d['2020-05-11']\ndftr_d['2020-05-13']=(1+dftr_d['Cres_2020-05-13'])*dftr_d['2020-05-12']\ndftr_d['2020-05-14']=(1+dftr_d['Cres_2020-05-14'])*dftr_d['2020-05-13']","a89f7f64":"dftr_d[dftr_d['Local'].isin(['Brazil','US\/New York','US\/New Jersey','US\/Florida','Italy','Spain','France','Germany'])]","2590956c":"dfm=df_f.pivot_table(index='Local',columns='Date',values='Fatalities').reset_index()\n#dft.iloc[: , -8].values\/((dft.iloc[: , -15].values)\nmortes_adj=dfm.iloc[: , -1].values.sum() \/ dft_copy.iloc[: , -1].values.sum()\ndft['mortes']=dfm.iloc[: , -1].values \/ dft_copy.iloc[: , -1].values\n \nprint(mortes_adj)\ndft.head()","96953a10":"dft[dft['Local'].isin(['Brazil','US\/New York','US\/New Jersey','US\/Florida','Italy','Spain','France','Germany'])]","a33b05e7":"#dft.loc(dft['mortes']>(2*mortes_adj),'mortes')=(2*mortes_adj)\n#dft.loc(dft['mortes']<(mortes_adj\/2),'mortes')=(mortes_adj\/2)\ndft['mortes']=np.where(dft['mortes']>(2*mortes_adj),(2*mortes_adj),np.where(dft['mortes']<(mortes_adj\/2),(mortes_adj\/2),dft['mortes']))","1a058a9b":"dfi=dft[['Local', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04',\n       '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09',\n       '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14',\n       '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19',\n       '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24',\n       '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29',\n       '2020-03-30', '2020-03-31',  '2020-04-01', '2020-04-02', '2020-04-03',\n       '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08',\n       '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13',\n       '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18',\n       '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23',\n       '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28',\n       '2020-04-29', '2020-04-30','2020-05-01','2020-05-02','2020-05-03','2020-05-04','2020-05-05','2020-05-06','2020-05-07'\n      ,'2020-05-08','2020-05-09','2020-05-10','2020-05-11','2020-05-12','2020-05-13','2020-05-14']]\ndfi.head()","db873273":"dfi['2020-05-07'].sum()","32c6ad6c":"df = dfi.melt('Local', var_name='Date', value_name='ConfirmedCases')\n\n\ndf=pd.merge(df,dft[['Local','mortes']],on='Local',how='left')\ndf['Fatalities']=df['ConfirmedCases']*df['mortes']\ndf[df['Local']=='Brazil']","6eed1f54":"dfif=dftr_d[['Local', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04',\n       '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09',\n       '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14',\n       '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19',\n       '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24',\n       '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29',\n       '2020-03-30', '2020-03-31',  '2020-04-01', '2020-04-02', '2020-04-03',\n       '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08',\n       '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13',\n       '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18',\n       '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23',\n       '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28',\n       '2020-04-29', '2020-04-30','2020-05-01','2020-05-02','2020-05-03','2020-05-04','2020-05-05','2020-05-06','2020-05-07'\n      ,'2020-05-08','2020-05-09','2020-05-10','2020-05-11','2020-05-12','2020-05-13','2020-05-14']]\ndffat = dfif.melt('Local', var_name='Date', value_name='Mortalidade')\n\ndffat.tail()","4532d972":"\ndf_test.head()\ndf_test=df_test.drop(columns=['ConfirmedCases','Fatalities'])\ndf_test['Date']=df_test['Date'].astype('str')\ndf_test=pd.merge(df_test,df[['Local','Date','ConfirmedCases','Fatalities']],on=['Local','Date'],how='left')\ndf_test.drop(columns='Mortalidade',inplace=True)\ndf_test.tail()","a3c7b784":"dftestefinal=pd.merge(df_test,dffat,on=['Local','Date'],how='left')\ndftestefinal['Fatalities']=dftestefinal['ConfirmedCases']*dftestefinal['Mortalidade']\ndftestefinal.tail()","087b7f22":"dff=dftestefinal.sort_values(by='ConfirmedCases',ascending=False)\ndff.head(20)","6251b8a4":"\ndfm = dfm.melt('Local', var_name='Date', value_name='Fatalities')\n\ndfat=pd.merge(dftestefinal,dfm[['Local','Fatalities','Date']],on=['Local','Date'],how='left',suffixes=('_predicted','_real'))\ndfat['Fatalities_real'].fillna('Vazio',inplace=True)\ndfat['Fatalities']=np.where(dfat['Fatalities_real']=='Vazio',dfat['Fatalities_predicted'],dfat['Fatalities_real'])\ndfat[dfat['Local']=='Brazil']","39e688d7":"submission=dfat[['ForecastId','ConfirmedCases','Fatalities']]\nsubmission['ForecastId']=submission['ForecastId'].astype('int32')\nsubmission['Fatalities']=submission['Fatalities'].astype('float')\nprint(submission.dtypes)\nsubmission.sample(10)\n\n\n","620be6cc":"submission.describe()","a92d4f2d":"df_test[df_test['ConfirmedCases'].isna()]","b792776a":"dftpronto=dfat.copy()","b68da77c":"submission.to_csv('submission.csv',index=None)\nsubmission.sample(10)","53d711f6":"# Make predictions","0f56bf52":"# Use datetime functions","ca42780c":"# Take a look at Brazil, New York and more","a71c6d6b":"# Adjust fatalities","7e95f4b3":"# Creation of dataframes with different time windows","baca1339":"# Country and Province State names treatment","0335770e":"# Model to get fatalitites rate","3467ed0f":"# Make submission","179548e2":"# Regression with CatBoost","d906225a":"# Load the data","a76c2acb":"# Function to aggregate datasets into the model to calculate Cases decay","bd19e01a":"# Regression with SkLearn RandomForest,GradientBoosting and LightGBM DART"}}