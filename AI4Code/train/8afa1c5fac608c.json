{"cell_type":{"2a6a3a68":"code","dd98ed54":"code","d15531af":"code","00d7d9a7":"code","17afdfdb":"code","ccb4f02f":"code","0bbdf00e":"code","b7abd8eb":"code","a690444a":"code","67477da3":"code","c7a0742a":"code","9a9c70bd":"code","65d81907":"code","6bc87608":"code","865584dd":"code","1d7c3879":"code","a9cdcd79":"code","ce904228":"code","b223542c":"code","c3b1d910":"code","d8d5e026":"code","6f8c4031":"code","af6d725a":"code","9b3e6be2":"code","c289c923":"code","13797af9":"code","0406337c":"code","38aad98b":"code","96bf6cc7":"code","e7421396":"code","b251e072":"code","489cd2fe":"code","8e5ec12d":"code","81c424a2":"code","f1c2a27e":"code","e3291601":"code","8ea1eddf":"code","1efb140b":"code","5839a26f":"code","aae78fae":"code","872f1e30":"code","f41f7103":"code","f06c1d94":"code","246299b5":"code","114d5913":"code","f6054288":"code","10077e42":"code","52a286c1":"code","b2034123":"code","18646837":"code","50aa783d":"code","5b41c88e":"code","e18de618":"code","bbdb6f37":"code","dde63f66":"code","96ce5a62":"code","8663b50c":"code","8fecb342":"code","e0179f86":"code","3ff2d586":"code","36899247":"code","d087ce70":"code","938caff5":"code","6637f485":"code","a387f201":"code","2f5d782a":"markdown","3537ff47":"markdown","f67609f2":"markdown","31fb010a":"markdown","412033e0":"markdown","cdcca012":"markdown","8699c82a":"markdown","96698cb0":"markdown","342e2991":"markdown","dffe015a":"markdown","efc51b58":"markdown","c3a23d64":"markdown","c67d5f59":"markdown","9f65cdf4":"markdown","890558e8":"markdown","6de9a227":"markdown","1514c34c":"markdown","13cec3ac":"markdown","4dc53288":"markdown","610cb343":"markdown","38f18c51":"markdown","321da076":"markdown","a0b3a869":"markdown","063b2391":"markdown","364f39a9":"markdown","8758a7d9":"markdown","dd87c5c8":"markdown","b8844310":"markdown","44342339":"markdown","81248399":"markdown","01da2eaf":"markdown","00b9fbce":"markdown","b21d3765":"markdown","b8a56c32":"markdown"},"source":{"2a6a3a68":"#\u0130mport Library","dd98ed54":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","d15531af":"import pandas as pd\nimport numpy as np\nimport pandas_profiling\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport warnings\nwarnings.filterwarnings('ignore')","00d7d9a7":"#Dataset\n\ntrain=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')  # Loading the train dataset\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')    # Loading the test dataset\n\ntarget=train['Survived']\n\n\n#Basic info about the dataset\n\nprint('Shape of train dataset:-',train.shape)\nprint('Shape of test dataset:-' ,test.shape)\n\n#Info about datatype and statistical model\n\nprint('\\n')\nprint(train.info())\ntrain.describe()","17afdfdb":"train.head(10)","ccb4f02f":"test.shape","0bbdf00e":"train.shape","b7abd8eb":"train.info()","a690444a":"print(test.info()),print(train.info())","67477da3":"#How many null values are in which column in train\n\ntrain.isnull().sum() ","c7a0742a":"#How many null values are in which column in test\n\ntest.isnull().sum()","9a9c70bd":"#import library\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","65d81907":"#we visualize all categorical data on dead and survivors\n\ndef bar_chart(feature):\n    survived = train[train[\"Survived\"]==1][feature].value_counts()\n    dead = train[train[\"Survived\"]==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = [\"Survived\",\"Dead\"]\n    df.plot(kind=\"bar\", stacked = True,figsize=(10,5))","6bc87608":"bar_chart(\"Sex\")","865584dd":"bar_chart(\"Pclass\")","1d7c3879":"bar_chart('SibSp')","a9cdcd79":"bar_chart('Parch')","ce904228":"bar_chart('Embarked')","b223542c":"# combining train and test dataset\n# and adding a new column from their nicknames\n\ntrain_test_data = [train, test] \n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","c3b1d910":"train[\"Title\"].value_counts()","d8d5e026":"test['Title'].value_counts()","6f8c4031":"#Collection for name\n\ntitle_mapping = {\"Mr\":0,\"Miss\":1,\"Mrs\":2,\n                \"Master\":3,\"Rev\":3,\"Ms\":3,\"Col\":3,\"Mlle\":3,\"Major\":3,\"Jonkheer\":3,\"Lady\":3,\"Capt\":3,\n                \"Countess\":3,\"Sir\":3,\"Don\":3,\"Mme\":3,\"Dr\":3,\"Dona\":3}\n\nfor dataset in train_test_data:\n    dataset[\"Title\"] = dataset[\"Title\"].map(title_mapping)","af6d725a":"train.head()","9b3e6be2":"bar_chart(\"Title\")","c289c923":"#Delete unnecessary featurefrom dataset\ntrain.drop(\"Name\",axis =1, inplace = True)\ntest.drop(\"Name\", axis = 1, inplace = True)","13797af9":"sex_mapping = {\"male\":0,\"female\":1}\n\nfor dataset in train_test_data:\n    dataset[\"Sex\"] = dataset[\"Sex\"].map(sex_mapping)","0406337c":"bar_chart(\"Sex\")","38aad98b":"#Fill missing age with median age for each Title(Mr,Mrs,Miss, Others)\n\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"),inplace = True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"),inplace = True)","96bf6cc7":"train.head()\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","e7421396":"#distribution of dead and survivors by age \n\nfacet = sns.FacetGrid(train, hue=\"Survived\", aspect = 4)\nfacet.map(sns.kdeplot,\"Age\", shade = True)\nfacet.set(xlim=(0,train[\"Age\"].max()))\nfacet.add_legend()\nplt.show()","b251e072":"for dataset in train_test_data:\n    dataset.loc[ (dataset['Age'] <= 16), 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","489cd2fe":"bar_chart(\"Age\")","8e5ec12d":"for dataset in train_test_data:\n    Pclass1 = dataset[dataset[\"Pclass\"]==1][\"Embarked\"].value_counts()\n    Pclass2 = dataset[dataset[\"Pclass\"]==2][\"Embarked\"].value_counts()\n    Pclass3 = dataset[dataset[\"Pclass\"]==3][\"Embarked\"].value_counts()\n\ndf = pd.DataFrame([Pclass1, Pclass2,Pclass3])\ndf.index = [\"1st class\",\"2nd class\",\"3rd class\"]\ndf.plot(kind = \"bar\",stacked = True, figsize=(10,5))","81c424a2":" for dataset in train_test_data:\n        dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")\n     ","f1c2a27e":"embarked_mapping = {\"S\":0,\"C\":1,\"Q\":2}\nfor dataset in train_test_data:\n    dataset[\"Embarked\"]= dataset[\"Embarked\"].map(embarked_mapping)","e3291601":"# Fiil missing Fare with median fare for each Pclass\n\nfor dataset in train_test_data:\n    dataset[\"Fare\"].fillna(dataset.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace = True)\ntrain.head(100)","8ea1eddf":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","1efb140b":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","5839a26f":"train.head()","aae78fae":"#we only get the 1st letter of the cabin number\n\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","872f1e30":"\nPclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","f41f7103":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","f06c1d94":"# fill missing Fare with median fare for each Pclass\n\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","246299b5":"#By adding 2 columns, we get a new feature.\n\nfor dataset in train_test_data:\n    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1","114d5913":"\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","f6054288":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","10077e42":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","52a286c1":"\ntrain_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","b2034123":"train_data.head(10)\n","18646837":" #Importing Classifier Modules\n    \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","50aa783d":"train.info()\n","5b41c88e":"\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","e18de618":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","bbdb6f37":"round(np.mean(score)*100, 2)\n","dde63f66":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","96ce5a62":"round(np.mean(score)*100, 2)","8663b50c":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","8fecb342":"# Random Forest Score\n\nround(np.mean(score)*100, 2)","e0179f86":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","3ff2d586":"# Naive Bayes Score\n\nround(np.mean(score)*100, 2)","36899247":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\n","d087ce70":"round(np.mean(score)*100,2)","938caff5":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","6637f485":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","a387f201":"submission = pd.read_csv('submission.csv')\nsubmission.head()","2f5d782a":"# Age\nWe fillna Title's median age for missing age","3537ff47":"# !!! Age value is missing for many rows.\n# !!! Cabin values are also missing in many rows","f67609f2":"# fill out missing embark with S embark\n\n","31fb010a":"* more than 50% of 1 st class are from S embark\n* more than 50% of 2 nd class are from S embark\n* more than 50% of 3 rd class are from S embark","412033e0":"> The Chart above confirms Women more likely survivied than Men ","cdcca012":"# 2-Decision Tree","8699c82a":"**Title map**\n\n* Mr : 0\n* Miss : 1\n* Mrs: 2\n* Others: 3","96698cb0":"# Cabin Column","342e2991":"\n* The Chart above show a person aboarded with more than 2 siblings or spouse more likely survived\n* The Chart above show a person aboarded without siblings or spouse more likely dead","dffe015a":"# References\n\nThis notebook is created by learning from the following notebooks:\n\n* Mukesh ChapagainTitanic Solution: A Beginner's Guide\n* How to score 0.8134 in Titanic Kaggle Challenge\n* Titanic: factors to survive\n* Titanic Survivors Dataset and Data Wrangling","efc51b58":"We use bar chart for Categorical Features\n\n* Pclass\n* Sex\n* SibSp ( # of siblings and spouse)\n* Parch ( # of parents and children)\n* Embarked\n* Cabin","c3a23d64":"\n* The Chart above show a person aboarded from C slightly more likely survived\n* The Chart above show a person aboarded from Q more likely dead\n* The Chart above show a person aboarded from S more likely dead","c67d5f59":"# FamilySize Column\n\n* sibsp: # of siblings \/ spouses aboard the Titanic\n* parch: # of parents \/ children aboard the Titanic","9f65cdf4":"# Data Dictionary\n* Survived: 0 = No, 1 = Yes\n* pclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n* sibsp: # of siblings \/ spouses aboard the Titanic\n* parch: # of parents \/ children aboard the Titanic\n* ticket: Ticket number\n* cabin: Cabin number\n* embarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton","890558e8":"# Cross Validation (K-fold)","6de9a227":"# 1-KNN","1514c34c":"# 4-Naive Bayes","13cec3ac":"# Titanic Dataset Analyze\n\n**We will do this in a few steps**\n* EDA (Exploratory Data Analysis)\n* Data Visualization\n* Data Dictionary\n* Feature Enginnering  \n* Modeling","4dc53288":"* The Chart above show 1st class more likely survivied than other classes\n* The Chart above show 3rd class more likely dead than other classes","610cb343":"# Binning\nBinning\/Converting Numerical Age to Categorical Variable\n\n* child:0\n* young:1\n* adult:2\n* mid-age :3\n* senior:4","38f18c51":"# 3. Data Visualization","321da076":"# 5-SVM","a0b3a869":"# Fare Column","063b2391":"* **Data, we see that it does the same action in certain parts of the age**. \n* Just like Seasonality.\n* **We divide it into 5 different groups.**","364f39a9":"# Testing","8758a7d9":"# 4. Feature Enginnering","dd87c5c8":"* The Chart above show a person aboarded with **more than 2 parents or children** more likely survived\n* The Chart above show a person aboarded ****alone**** more likely dead","b8844310":"# Sex \nmale : 0 Female : 1","44342339":"As can be seen from the quantities, we can collect the lesser ones in a single group.","81248399":"# Exploratory Data Analysis (EDA)\n","01da2eaf":"Feature engineering is the process of using domain knowledge of the data\nto create features (feature vectors) that make machine learning algorithms work.\n\nfeature vector is an n-dimensional vector of numerical features that represent some object.\nMany algorithms in machine learning require a numerical representation of objects,\nsince such representations facilitate processing and statistical analysis.\n![https:\/\/miro.medium.com\/max\/638\/1*8nMiAqNbGlTgevVaWbF60g.png](https:\/\/miro.medium.com\/max\/638\/1*8nMiAqNbGlTgevVaWbF60g.png)","00b9fbce":"# 5-Modelling","b21d3765":"# 3-Ramdom Forest","b8a56c32":"# Embarked\n**Filling Missing Values**"}}