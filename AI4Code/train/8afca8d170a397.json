{"cell_type":{"32d967fc":"code","a94fbefd":"code","cf8a402a":"code","1e384df3":"code","ab61a983":"code","ac6cac6c":"code","c2725189":"code","5a8c8037":"code","42741053":"code","767b696f":"code","4f6e97df":"code","0783bdce":"code","8a8ebb78":"code","4f0a2278":"code","90808ec9":"code","79d4da0a":"code","a0071d13":"code","37c7808c":"code","ce22035b":"code","e482492f":"code","595f0e2d":"code","f8eafa89":"code","356f32ab":"code","177c902c":"code","75f1f43a":"code","d25b5be4":"code","13b7ea60":"code","9aca48ce":"code","73d99bf8":"code","85d5d422":"code","b6eefbde":"code","06f2f881":"code","83b3aa62":"code","4dd4c6be":"code","7f6afbb4":"code","58751919":"code","9bf2f3c9":"code","53ee71f3":"code","4aecb0da":"code","c00926a5":"code","da1f536e":"code","1ed1993a":"code","2d0976a2":"code","130ea9c2":"code","a55b5a2e":"code","90ed2929":"code","dd17866c":"code","331533fd":"code","aa8bf3bb":"code","b8695a67":"code","4225d977":"code","de61cef2":"code","d06e80d2":"code","10cc34b0":"code","e22d3b04":"code","a9207f38":"code","2109b99b":"code","6f98aa1f":"code","58323c68":"code","e17f80c2":"code","0826763e":"code","829dd42b":"code","eec0da8f":"code","4e7149c7":"code","2d09aea8":"code","8f9e9662":"code","0a2c32ce":"code","5e5ac321":"code","5bbc74c4":"code","f659a391":"code","ad5fa4e2":"code","5421345c":"code","2b2df195":"code","f551635e":"markdown","3c944a5f":"markdown","8a2508ec":"markdown","9d353335":"markdown","5c85e5c6":"markdown","8938b77a":"markdown","1da41216":"markdown","f5a72d94":"markdown","5040ef22":"markdown","ec164c6d":"markdown","335a552e":"markdown","db299822":"markdown","19fdad89":"markdown","088374a9":"markdown","73e7cb11":"markdown","8819b21e":"markdown","091a6ea6":"markdown","912c9caa":"markdown","1302b75a":"markdown","ac76c59f":"markdown","17e38189":"markdown","266b5950":"markdown","a27e9be7":"markdown","b621d155":"markdown","a2ec5453":"markdown","e9c7ca0d":"markdown","1ca09d85":"markdown","ccc0c8c2":"markdown","b94737f4":"markdown","4a394782":"markdown","40883908":"markdown","2ba4cee2":"markdown","7e806ae5":"markdown","9d937468":"markdown","3b01cf1d":"markdown","810882e5":"markdown","68960c24":"markdown","5d16f372":"markdown","c3d23031":"markdown","794911fc":"markdown","2bd28ccd":"markdown","d530289b":"markdown","62aad763":"markdown","943f061d":"markdown","b999bb38":"markdown"},"source":{"32d967fc":"import numpy as np\nimport pandas as pd\nimport scipy.special\nimport matplotlib.pyplot as plt\nimport os\nimport random","a94fbefd":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","cf8a402a":"import warnings\nwarnings.filterwarnings(\"ignore\")","1e384df3":"path_in = '..\/input\/titanic\/'\nos.listdir(path_in)","ab61a983":"train_data = pd.read_csv(path_in+'train.csv', index_col=0)\ntest_data = pd.read_csv(path_in+'test.csv', index_col=0)\nsamp_subm = pd.read_csv(path_in+'gender_submission.csv', index_col=0)","ac6cac6c":"def plot_bar_survivor(data, feature, rot=False):\n    \"\"\" Compare the distribution between survived and nor survived \"\"\"\n    \n    df_not_survived = data[data['Survived']==0]\n    df_survived = data[data['Survived']==1]\n    \n    survived_label = df_survived[feature].value_counts().sort_index()\n    dict_survived = dict(zip(survived_label.keys(), ((100*(survived_label)\/len(df_survived.index)).tolist())))\n    survived_names = list(dict_survived.keys())\n    survived_values = list(dict_survived.values())\n    \n    not_survived_label = df_not_survived[feature].value_counts().sort_index()\n    dict_not_survived = dict(zip(not_survived_label.keys(), ((100*(not_survived_label)\/len(df_not_survived.index)).tolist())))\n    not_survived_names = list(dict_not_survived.keys())\n    not_survived_values = list(dict_not_survived.values())\n    \n    fig, axs = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n    \n    axs[0].bar(survived_names, survived_values, color='yellowgreen')\n    axs[1].bar(not_survived_names, not_survived_values, color='sandybrown')\n    axs[0].grid()\n    axs[1].grid()\n    axs[0].set_title('Survived')\n    axs[1].set_title('Not Survived')\n    axs[0].set_ylabel('%')\n    if(rot==True):\n        axs[0].set_xticklabels(survived_names, rotation=45)\n        axs[1].set_xticklabels(not_survived_names, rotation=45)\n    plt.show()","c2725189":"def plot_bar_compare(train, test, name, rot=False):\n    \"\"\" Compare the distribution between train and test data \"\"\"\n    \n    fig, axs = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n    \n    train_label = train[name].value_counts().sort_index()\n    dict_train = dict(zip(train_label.keys(), ((100*(train_label)\/len(train.index)).tolist())))\n    train_names = list(dict_train.keys())\n    train_values = list(dict_train.values())\n    \n    test_label = test[name].value_counts().sort_index()\n    dict_test = dict(zip(test_label.keys(), ((100*(test_label)\/len(test.index)).tolist())))\n    test_names = list(dict_test.keys())\n    test_values = list(dict_test.values())\n    \n    axs[0].bar(train_names, train_values, color='yellowgreen')\n    axs[1].bar(test_names, test_values, color='sandybrown')\n    axs[0].grid()\n    axs[1].grid()\n    axs[0].set_title('Train data')\n    axs[1].set_title('Test data')\n    axs[0].set_ylabel('%')\n    if(rot==True):\n        axs[0].set_xticklabels(train_names, rotation=45)\n        axs[1].set_xticklabels(test_names, rotation=45)\n    plt.show()","5a8c8037":"print('number train samples: ', len(train_data.index))\nprint('number test samples: ', len(test_data.index))\nprint('number features: ', len(train_data.columns)-1)","42741053":"train_data.isnull().sum()","767b696f":"cols_with_missing_train = [col for col in train_data.columns if train_data[col].isnull().any()]\ncols_with_missing_test = [col for col in test_data.columns if test_data[col].isnull().any()]","4f6e97df":"print('train columns with missing data:', cols_with_missing_train)\nprint('test columns with missing data:', cols_with_missing_test)","0783bdce":"print('train missing values: {:0.2f}%'.format(100*train_data['Age'].isna().sum()\/len(train_data)))\nprint('test missing values: {:0.2f}%'.format(100*test_data['Age'].isna().sum()\/len(test_data)))","8a8ebb78":"age_mean = int(train_data[train_data['Age'].notnull()]['Age'].mean())\nage_std = int(train_data[train_data['Age'].notnull()]['Age'].std())\nage_mean, age_std","4f0a2278":"def fill_age(s):\n    if np.isnan(s) == False:\n        return s\n    else:\n        return random.randrange(age_mean-age_std, age_mean+age_std)","90808ec9":"train_data['Age'] = train_data['Age'].apply(fill_age)\ntest_data['Age'] = test_data['Age'].apply(fill_age)","79d4da0a":"print('train missing values: {:0.2f}%'.format(100*train_data['Cabin'].isna().sum()\/len(train_data)))\nprint('test missing values: {:0.2f}%'.format(100*test_data['Cabin'].isna().sum()\/len(test_data)))","a0071d13":"train_data['Cabin'] = train_data['Cabin'].fillna('Unknown', inplace=False)\ntest_data['Cabin'] = test_data['Cabin'].fillna('Unknown', inplace=False)","37c7808c":"print('train missing values:', train_data['Embarked'].isna().sum())","ce22035b":"train_data['Embarked'] = train_data['Embarked'].fillna('Unknown', inplace=False)","e482492f":"print('test missing values:', test_data['Fare'].isna().sum())","595f0e2d":"mean = test_data['Fare'].mean()\ntest_data['Fare'] = test_data['Fare'].fillna(mean, inplace=False)","f8eafa89":"plot_bar_survivor(train_data, 'Age')","356f32ab":"plot_bar_survivor(train_data, 'Sex')","177c902c":"plot_bar_survivor(train_data, 'Fare')","75f1f43a":"plot_bar_survivor(train_data, 'SibSp')","d25b5be4":"train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1","13b7ea60":"plot_bar_survivor(train_data, 'FamilySize')","9aca48ce":"def family_group(s):\n    if (s >= 2) & (s <= 4):\n        return 2\n    elif ((s > 4) & (s <= 7)) | (s == 1):\n        return 1\n    elif (s > 7):\n        return 0","73d99bf8":"train_data['FamilyGroup'] = train_data['FamilySize'].apply(family_group)\ntest_data['FamilyGroup'] = test_data['FamilySize'].apply(family_group)","85d5d422":"plot_bar_survivor(train_data, 'FamilyGroup')","b6eefbde":"def IsAlone(s):\n    if s==1:\n        return 1\n    else:\n        return 0","06f2f881":"train_data['IsAlone'] = train_data['FamilySize'].apply(IsAlone)\ntest_data['IsAlone'] = test_data['FamilySize'].apply(IsAlone)","83b3aa62":"plot_bar_survivor(train_data, 'IsAlone')","4dd4c6be":"ticket_group = dict((train_data['Ticket'].append(test_data['Ticket'])).value_counts())\ntrain_data['TicketGroup'] = train_data['Ticket'].apply(lambda x: ticket_group[x])\ntest_data['TicketGroup'] = test_data['Ticket'].apply(lambda x: ticket_group[x])","7f6afbb4":"plot_bar_survivor(train_data, 'TicketGroup')","58751919":"train_data['Title'] = train_data['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip())\ntest_data['Title'] = test_data['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip())\ntitle_dict = {}\ntitle_dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))\ntitle_dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))\ntitle_dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))\ntitle_dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))\ntitle_dict.update(dict.fromkeys(['Mr'], 'Mr'))\ntitle_dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))\ntrain_data['Title'] = train_data['Title'].map(title_dict)\ntest_data['Title'] = test_data['Title'].map(title_dict)","9bf2f3c9":"plot_bar_compare(train_data, test_data, 'Title', rot=True)","53ee71f3":"plot_bar_survivor(train_data, 'Title')","4aecb0da":"def age_group(s):\n    if s == 0:\n        return -1\n    elif (s > 0) & (s <= 13):\n        return 1\n    elif (s > 13) & (s <= 20):\n        return 2\n    elif (s > 20) & (s <= 30):\n        return 3\n    elif (s > 30) & (s <= 40):\n        return 4\n    elif (s > 40) & (s <= 50):\n        return 5\n    elif (s > 50) & (s <= 60):\n        return 6\n    elif (s > 60) & (s <= 70):\n        return 7\n    elif (s > 70) & (s <= 80):\n        return 8","c00926a5":"train_data['AgeGroup'] = train_data['Age'].apply(age_group)\ntest_data['AgeGroup'] = test_data['Age'].apply(age_group)","da1f536e":"plot_bar_compare(train_data, test_data, 'AgeGroup', rot=False)","1ed1993a":"plot_bar_survivor(train_data, 'AgeGroup')","2d0976a2":"def fare_group(s):\n    if (s <= 8):\n        return 1\n    elif (s > 8) & (s <= 15):\n        return 2\n    elif (s > 15) & (s <= 31):\n        return 3\n    elif s > 31:\n        return 4","130ea9c2":"train_data['FareGroup'] = train_data['Fare'].apply(fare_group)\ntest_data['FareGroup'] = test_data['Fare'].apply(fare_group)","a55b5a2e":"plot_bar_survivor(train_data, 'FareGroup')","90ed2929":"def last_name(s):\n    lastname = s.split(',')[0]\n    return lastname","dd17866c":"train_data['LastName'] = train_data['Name'].apply(last_name)\ntest_data['LastName'] = test_data['Name'].apply(last_name)","331533fd":"for row in train_data.index:\n    if train_data.loc[row, 'Sex']=='female' or train_data.loc[row, 'Age']<14:\n        train_data.loc[row, 'WomenOrChild'] = 1\n    else:\n        train_data.loc[row, 'WomenOrChild'] = 0\n\nfor row in test_data.index:\n    if test_data.loc[row, 'Sex']=='female' or test_data.loc[row, 'Age']<14:\n        test_data.loc[row, 'WomenOrChild'] = 1\n    else:\n        test_data.loc[row, 'WomenOrChild'] = 0","aa8bf3bb":"plot_bar_survivor(train_data, 'WomenOrChild')","b8695a67":"train_data['FarePerPerson']=train_data['Fare']\/(train_data['FamilySize']+1)\ntest_data['FarePerPerson']=test_data['Fare']\/(test_data['FamilySize']+1)","4225d977":"train_data['AgePclass'] = train_data['Age']*train_data['Pclass']\ntest_data['AgePclass'] = test_data['Age']*test_data['Pclass']","de61cef2":"plot_bar_compare(train_data, test_data, 'Sex', rot=False)","d06e80d2":"plot_bar_compare(train_data, test_data, 'Embarked', rot=False)","10cc34b0":"plot_bar_compare(train_data, test_data, 'FamilySize', rot=False)","e22d3b04":"plot_bar_compare(train_data, test_data, 'TicketGroup', rot=False)","a9207f38":"plot_bar_compare(train_data, test_data, 'FareGroup', rot=False)","2109b99b":"train_data['Cabin'] = train_data['Cabin'].str[0]\ntest_data['Cabin'] = test_data['Cabin'].str[0]","6f98aa1f":"plot_bar_compare(train_data, test_data, 'Cabin', rot=False)","58323c68":"features_cat = ['Sex', 'Cabin', 'Embarked', 'Title']\nle = LabelEncoder()\nfor col in features_cat:\n    le.fit(train_data[col])\n    train_data[col] = le.transform(train_data[col])\n    test_data[col] = le.transform(test_data[col])","e17f80c2":"plot_bar_compare(train_data, test_data, 'Pclass', rot=False)","0826763e":"train_data_dummy = pd.get_dummies(train_data['Pclass'], prefix = 'Pclass')\ntrain_data = pd.concat([train_data, train_data_dummy], axis=1)\ndel train_data['Pclass']\ntest_data_dummy = pd.get_dummies(test_data['Pclass'], prefix = 'Pclass')\ntest_data = pd.concat([test_data, test_data_dummy], axis=1)\ndel test_data['Pclass']","829dd42b":"corr = train_data.corr()\ncorr.style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)","eec0da8f":"no_features = ['Survived', 'Name', 'Ticket', 'LastName']","4e7149c7":"X_train = train_data[train_data.columns.difference(no_features)].copy(deep=False)\ny_train = train_data['Survived']\nX_test = test_data[test_data.columns.difference(no_features)].copy(deep=False)","2d09aea8":"min_max = MinMaxScaler()\nX_train_scaled = min_max.fit_transform(X_train)\nX_test_scaled = min_max.transform(X_test)","8f9e9662":"param_grid = {'criterion': ['gini'],\n              'max_features': [None, 'auto', 'sqrt', 'log2'],\n              'max_depth': [i for i in range(1, 6)],\n              'class_weight': [None, 'balanced'],\n              'min_samples_split': [2, 4, 6, 8, 10 ,12],\n              'min_samples_leaf': [1, 2, 3, 4],\n              'random_state': [2020]}\ngrid = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid, cv=5, scoring='accuracy')\ngrid.fit(X_train_scaled, y_train)\nbest_params = grid.best_params_\nprint('Best score of cross validation: {:.2f}'.format(grid.best_score_))\nprint('Best parameters:', best_params)","0a2c32ce":"model = DecisionTreeClassifier()\nmodel.set_params(**best_params)","5e5ac321":"model.fit(X_train_scaled, y_train)","5bbc74c4":"importance = model.feature_importances_","f659a391":"fig = plt.figure(figsize=(10, 6))\nx = X_train.columns.values\nplt.barh(x, 100*importance)\nplt.title('Feature Importance', loc='left')\nplt.xlabel('Percentage')\nplt.grid()\nplt.show()","ad5fa4e2":"y_test = model.predict(X_test_scaled)","5421345c":"output = pd.DataFrame({'PassengerId': samp_subm.index,\n                       'Survived': y_test})\noutput.to_csv('submission.csv', index=False)","2b2df195":"output['Survived'].value_counts()","f551635e":"## FareGroup\nThe distributions are similar.","3c944a5f":"## Feature Cabin\nThis is a categorical feature. \nThere are 77% missing values in the train and 78% missing values in the testd data. We fill the missing values with the new category *Unkown*.","8a2508ec":"# Input path","9d353335":"# Encoding data (necessary)\nIn this section we show how to deal with encoding techniques. For this we recommend another competition:\nhttps:\/\/www.kaggle.com\/drcapa\/categorical-feature-encoding-challenge-xgb <br>\nThere are some classes of features we have to encode with different techniques: <br>\n1) categorical features: Sex, Cabin, Embarked and Title. <br>\n2) binary features: Age_was_missing, Cabin_was_missing,\tEmbarked_was_missing <br>\n3) ordinal features: Pclass <br>\nWe leave out the features Name and Ticket because we don't want to use for prediction.","5c85e5c6":"# Write Output For Submission","8938b77a":"# Analyse Of Survivors\nWe focus on the survivors of the train data. Are there any patterns?","1da41216":"# Select features\nWe don't want to use all features, i.e. *Name*. And the column *Survived* is the target we have to predict.","f5a72d94":"# Define Model\nWe use the Decision Tree Classifier. First we use simple GridSearchCV to get a suitable set of hyperparameters","5040ef22":"## Ticket group\nWe see there are multiple ticket labels. So we can define groups of them. For this we have to sum up the train and test data.","ec164c6d":"## SibSp","335a552e":"## Familiy Group\nWith the new label *FamilySize* we can create the family group based on the number of members.","db299822":"## Age*Pclass","19fdad89":"\n## Fare","088374a9":"Columns with number of missing values of the train data:","73e7cb11":"# Correlation Matrix","8819b21e":"## Feature Age\nThis is a numerical feature. There are 19% missing values in the train and 20% missing values in the testd data. There are several techniques to fill the missing data, i.e. set them to zero oder the mean value. We want to fill the missing values with random numbers based on the mean and std of the given ages.","091a6ea6":"## Age\nWe can group the age for simplification. For this we use 9 groups (class 0 is for the missing values). We can see there are significant \ndifferent distributions for class 3 and 4.","912c9caa":"## Sex","1302b75a":"# Define X_train, y_train and X_test","ac76c59f":"# Load data","17e38189":"# Intro\nWelcome to the legendary [Titanic ML](https:\/\/www.kaggle.com\/c\/titanic\/data) competition.\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3136\/logos\/header.png)\nThis notebook is a starter code for all beginners and easy to understand. We will give an introduction to analysis and feature engineering.<br> \nTherefore we focus on\n* a simple analysis of the data,\n* create new features,\n* encoding and\n* scale data.\n\nWe use categorical feature encoding techniques, compare <br>\nhttps:\/\/www.kaggle.com\/drcapa\/categorical-feature-encoding-challenge-xgb <br>\nWe label the **necessary** operations and the operations for **advanced** feature engeneering. So for the first run you can skip the advanced feature engeneering.\n\nWe also want to focus on the rule \"women and children first\".\n\nFinally we define a simple classification model with cross validation to find suitable model parameters.\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. <\/span>","266b5950":"## Categorical features\nWe use the simple LabelEncoder. ","a27e9be7":"# Create new features (advanced)\nBased on the given features we are able to create new features.\n## Family Size\nWe combine both features *SibSp* (number of  of siblings \/ spouses aboard the Titanic) and *Parch* (number of parents \/ children aboard the Titanic) to the *FamilySize*.","b621d155":"# Handle missing values (necessary)","a2ec5453":"## Ordinal features\nFor the feature *Pclass* we use the one-hot-encoding.","e9c7ca0d":"# Feature Importance\nWe want to know useful are the features for predicting a target variable.","1ca09d85":"# Compare train and test data (advanced)\nIn the previous picture we can see that there significant differences for the *Age*. What is with other features?\n## Sex\nThe distributions are similar.","ccc0c8c2":"## Embarked\nThere are differences between train and test.","b94737f4":"## Feature Embarked\nThe Port of Embarkation is a categorical feature. There are 2 missing values in the train data set. We fill the missing values with the new category *Unkown*.","4a394782":"## Age","40883908":"## FamilySize\nThe distributions are similar.","2ba4cee2":"## Last Name","7e806ae5":"# Predict test data","9d937468":"## Fare group","3b01cf1d":"## Feature Fare\nThe passenger fare is a numerical feature. There is one missing value in the test data. We fill this with the mean value.","810882e5":"# Load Libraries","68960c24":"## Title of a passenger\nFrom the feature *Name* we can extract the title of the passengers. Further we want to sum up some title to one title, i.e. instead of *Mme*, *Ms* and *Mrs* we only use *Mrs*. We will see that the distribution is similar between train and test.","5d16f372":"## IsAlone\nBased on the feature FamilySize we can define the feature IsAlone as follows:","c3d23031":"# Scale date\nTo avoid numercial effects between small and large numbers we scale the data.","794911fc":"## Women And Childreen First\nWe define childreen as passangers with age < 14.","2bd28ccd":"## TicketGroup\nThe distributions are similar.","d530289b":"# Overview\nThe titanic data set is small. In total we have only 1309 samples.","62aad763":"## Fare Per Passanger","943f061d":"# Plot function","b999bb38":"## Feature Cabin\nBevor starting with encoding we want so simplify the values of the feature *Cabin*. We only want to use the first character. The cabine group *T* is only included in the train data."}}