{"cell_type":{"556bd65b":"code","cf19785f":"code","978a1136":"code","2d244306":"code","6effb3c2":"code","13eec56c":"code","3336a928":"code","2ca0d832":"code","8cdae871":"code","e9d8a7d0":"code","97d7c1d5":"code","eedc8459":"code","494e7545":"code","68262ce8":"code","ed47c54b":"code","08ee1b7d":"code","8c76cd1c":"code","ae7f2a79":"code","4f39a918":"code","39b9dd25":"code","cdbebd51":"code","00b9eed5":"code","d8a2cfc6":"code","38134047":"code","91112c22":"code","1f1819a8":"code","042216ce":"code","826e2b09":"code","d6df615f":"code","13a9e40f":"markdown","e0b0ef31":"markdown","26fd1c4a":"markdown","9546e7a9":"markdown","afb5ef8e":"markdown","fcce1051":"markdown","ee034937":"markdown","43ae787d":"markdown","9c496b1f":"markdown","62ad719a":"markdown","56b4ab6e":"markdown","cec8a9db":"markdown"},"source":{"556bd65b":"\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport os\nimport cv2\nimport glob\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","cf19785f":"plt.rcParams['figure.dpi']=80\nplt.rcParams['font.size']=11\nplt.rcParams['font.family']='sans-serif'\nplt.rcParams[\"figure.figsize\"]=(10,10)\nplt.rcParams[\"figure.facecolor\"]=\"white\"","978a1136":"ima_path=r\"\/kaggle\/input\/petfinder-pawpularity-score\/train\"\ndata_copy=pd.read_csv(r\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\")\ndata=pd.read_csv(r\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\")\ndata.head()","2d244306":"def read_ima(path,labels,buff=10):\n    images=np.zeros(shape=(buff,320,320,3),dtype=\"int\")\n    pawpularities=[]\n    ima_path=os.path.normpath(path+\"\/*.jpg\")\n    for j,image in enumerate(glob.glob(ima_path)[:buff]):\n        im=cv2.imread(image)\n        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        im=cv2.resize(im,dsize=(320,320))         \n        id=image.split(\"\/\")[-1].split(\".\")[0]\n        pawpopularity=(labels[labels[\"Id\"]==id].Pawpularity.to_numpy())\n        images[j-1]=im\n        pawpularities.append(pawpopularity)\n\n        \n    return images,np.array(pawpularities)\nima,pawpol=read_ima(ima_path,data[[\"Id\",\"Pawpularity\"]],buff=16)","6effb3c2":"fig=plt.figure(figsize=(15,15))\nax=fig.subplots(4,4)\nax=ax.ravel()\nfor j,axis in enumerate(ax):\n    axis.imshow(ima[j])\n    axis.set_title(\"Pawpularity:\" +str(pawpol[j][0]))\n    axis.set_xticks([])\n    axis.set_yticks([])","13eec56c":"Id=data[[\"Id\",\"Pawpularity\"]]\ndata.drop(\"Id\",axis=1,inplace=True)\n","3336a928":"sns.distplot(data.Pawpularity,color=\"green\")","2ca0d832":"features=np.array(data.columns[:-1])\nfig,axes=plt.subplots(2,len(features)\/\/2,figsize=(20,20),sharex=True,sharey=True)\naxes=axes.ravel()\nfor j,i in enumerate(data.columns[:-1]):\n    sns.histplot(data=data,x=\"Pawpularity\",hue=i,ax=axes[j],palette=[\"#7bba84\",\"#eb0505\"],legend=False)\n    axes[j].spines['right'].set_visible(False)\n    axes[j].spines['top'].set_visible(False)\n    axes[j].spines['left'].set_visible(False)\n    axes[j].tick_params(axis=u'both', which=u'both',length=0)\n    axes[j].legend([\"0\",\"1\"], title=i,edgecolor=\"white\")\n","8cdae871":"corr=data.corr()\nup_triang = np.triu(np.ones_like(corr)).astype(bool)\nsns.heatmap(corr,annot=True,fmt=\".2f\",mask=up_triang)\n","e9d8a7d0":"fig,axes=plt.subplots(2,len(features)\/\/2,figsize=(20,20),sharey=True)\naxes=axes.ravel()\nfor j,i in enumerate(data.columns[:-1]):\n    sns.boxplot(data=data,y=\"Pawpularity\",x=i,ax=axes[j],palette=[\"#7bba84\",\"#eb0505\"])\n    axes[j].spines['right'].set_visible(False)\n    axes[j].spines['top'].set_visible(False)\n    if (j!=0 and j!=6):\n        axes[j].spines['left'].set_visible(False)\n        axes[j].set_ylabel(\"\")\n        axes[j].tick_params(axis=u'y', which=u'both',length=0)","97d7c1d5":"fig,axes=plt.subplots(nrows=2,ncols=len(features)\/\/2,figsize=(29,20))\n\nfig.subplots_adjust(hspace=0.15,wspace=0.3)\nfig.set_facecolor(\"#151716\")\naxes=axes.ravel()\nfor i,feature in enumerate(features):\n    t=data[feature].value_counts().reset_index()\n    sns.barplot(data=t,x=\"index\",y=feature,ax=axes[i],palette=[\"#7bba84\",\"#eb0505\"])\n    for bar in axes[i].patches:\n        axes[i].annotate(format(bar.get_height()\/len(data), '.2f')+ \"%\",\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()+0.01), ha='center', va='center',\n                   size=13, xytext=(0, 8),\n                   textcoords='offset points',color=\"white\")\n    axes[i].set_ylabel(\"\")\n    lim=np.array(axes[i].get_ylim())\n    axes[i].set_xlabel(\"\")\n    axes[i].tick_params(axis='both', colors='white',size=10)\n    axes[i].set_ylim(lim+[-0.2,1000])\n    axes[i].text(x=-.2,y=lim[1]+500,s=feature,fontsize=13,fontfamily=\"serif\",fontweight=\"heavy\",color=\"white\")\n    axes[i].set_facecolor(\"#202925\")","eedc8459":"#it can be achieved with pandas.DataFrame.value_counts method in one line(data.iloc[:,:-1].value_counts()[:10].reset_index())\n#Just for flex purpose the below code\nvectors=[]\nfor i in range(len(data)):\n    values=data.iloc[i].values[:-1]\n    value=\"\".join([str(num) for num in values])\n    vectors.append(value)\nvectors=np.array(vectors)\nunique,counts=np.unique(vectors,return_counts=True)\nprint(\"There is\",len(unique),\" unique One-Hot encoded values of features\",\"\\n\"*3)\nind=np.argsort(counts)[::-1]\nind=ind[:10]\nunique,counts=unique[ind],counts[ind]\narr=np.array([[int(i) for i in value] for value in unique])\narr=np.hstack([arr,counts[:,np.newaxis]])\nunique_vec=pd.DataFrame(arr,columns=np.hstack([features,\"Counts\"]))\ninfo_feature=data.merge(unique_vec,how=\"left\",right_on=list(features),left_on=list(features),indicator=True)\ninfo_feature=info_feature[info_feature._merge==\"both\"].drop(\"_merge\",axis=1)\nmean_pawpularity=info_feature.groupby(by=list(features)).Pawpularity.mean().reset_index()\nunique_vec=unique_vec.merge(mean_pawpularity,how=\"left\",right_on=list(features),left_on=list(features))\nunique_vec.Pawpularity=(unique_vec.Pawpularity.round(1))\nunique_vec.rename({\"Pawpularity\":\"Mean_pawpularity\"},axis=\"columns\",inplace=True)\nunique_vec","494e7545":"data_encoded=pd.concat([data,pd.DataFrame(vectors,columns=[\"encode\"])],axis=1)","68262ce8":"fig=plt.figure(figsize=(20,20))\nfig.subplots_adjust(hspace=0.10,wspace=0.1)\nfig.set_facecolor(\"#151716\")\nax=fig.subplots(2,5,sharey=True)\naxes=ax.ravel()\nfor i in range(0,len(unique)):\n    temp=data[data_encoded.encode==unique[i]]\n    sns.distplot(temp.Pawpularity,ax=axes[i],color=\"#28808a\")\n    for j,feature in enumerate(features):\n        axes[i].text(x=57,y=(0.036-j*0.0018),s=f\"{feature}:{unique[i][j]}\",color=\"#d2d8d9\",fontweight=\"roman\",bbox=dict(facecolor=\"red\",alpha=0.5))\n      \n    axes[i].set_facecolor(\"#151716\")\n    axes[i].spines['right'].set_visible(False)\n    axes[i].spines['top'].set_visible(False)\n    axes[i].spines['left'].set_visible(False)\n    axes[i].tick_params(axis='both', colors='white',size=5)\n    axes[i].tick_params(axis=u'both', which=u'both',length=0)\n    axes[i].set_ylabel(\"\")\n    axes[i].set_xlabel(\"Pawpularity\",color=\"white\")\n    ","ed47c54b":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression,mutual_info_regression\nx=data.iloc[:,:-1]\ny=data.iloc[:,-1]\nmodel_F=SelectKBest(f_regression,k=5)\nmodel_F.fit(x,y)\nprint(f\"Selected features with F-values : {features[model_F.get_support()]}\")\nmodel_Mut=SelectKBest(mutual_info_regression,k=5)\nmodel_Mut.fit(x,y)\nprint(\"Selected features with mutual inform. :\",features[model_Mut.get_support()])","08ee1b7d":"from sklearn.feature_selection import SelectFromModel,RFE\nfrom sklearn.linear_model import LinearRegression,SGDRegressor\nfrom sklearn.metrics import mean_squared_error\nmodel_Ln=LinearRegression()\nmodel_SGD=SGDRegressor()\n\nprint(\"-\"*30,\"\\nBest features with Linear Regre.\\n\",\"-\"*30,sep=\"\")\nfrom_Ln=SelectFromModel(model_Ln,threshold=\"0.90*mean\")\nfrom_Ln.fit(x,y)\nind=from_Ln.get_support()\nfor i,j in enumerate(features[ind]):\n    print(f\"{j} \\n Coefficient:{abs(from_Ln.estimator_.coef_[ind][i])}\")\n\nprint(\"\\n \"*2)\nprint(\"-\"*30,\"\\nBest features with SGDregressor\",\"\\n\",\"-\"*30,sep=\"\")\nfrom_SGD=SelectFromModel(model_SGD,threshold=\"0.90*mean\")\nfrom_SGD.fit(x,y)\nind=from_SGD.get_support()\nfor i,j in enumerate(features[ind]):\n    print(f\"{j} \\n Coefficient:{abs(from_SGD.estimator_.coef_[ind][i])}\")","8c76cd1c":"from sklearn.ensemble import ExtraTreesRegressor\nfig=plt.figure(figsize=(15,10))\nax=fig.subplots()\nextre=ExtraTreesRegressor()\nextre.fit(x,y)\nstd = np.std([\n    tree.feature_importances_ for tree in extre.estimators_], axis=0)\nind=np.argsort(extre.feature_importances_)[::-1]\nsns.barplot(x=features,y=extre.feature_importances_,order=features[ind],ax=ax,yerr=std,palette=sns.color_palette(\"flare\"))\nax.set_title(\"Extra Trees\",fontweight=\"bold\",fontsize=15,fontstyle=\"italic\",fontfamily=\"cursive\")\nax.set_facecolor(\"#edede1\")","ae7f2a79":"from sklearn.ensemble import RandomForestRegressor\n#from sklearn.model_selection import GridSearchCV\nfig=plt.figure(figsize=(15,10))\nax=fig.subplots()\nrand=RandomForestRegressor()\nrand.fit(x,y)\nstd = np.std([\n    tree.feature_importances_ for tree in rand.estimators_], axis=0)\nind=np.argsort(rand.feature_importances_)[::-1]\nsns.barplot(x=features,y=rand.feature_importances_,order=features[ind],ax=ax,yerr=std,palette=sns.color_palette(\"flare\"))\nax.set_title(\"Random Forest\",fontweight=\"bold\",fontsize=15,fontstyle=\"italic\",fontfamily=\"cursive\")\nax.set_facecolor(\"#edede1\")\n","4f39a918":"ids=[file.split(\"\\\\\")[-1].split(\".\")[0] for file in glob.glob(ima_path+\"\/\/*.jpg\")]\nimport cv2\nimage_size=(456,456)#image's size tha EfficientB5 expects\nimages=[]\nfor file in ids:\n    image=cv2.imread(os.path.join(ima_path,file)+\".jpg\")\n    image=cv2.resize(image,dsize=image_size)\n    images.append(image)\n    \nimages=np.array(images)","39b9dd25":"import tensorflow as tf\nEfficient_model=tf.keras.applications.EfficientNetB5()\nModel=tf.keras.models.Model(Efficient_model.input,\n        Efficient_model.layers[-3].output)#model.layer[-3] is a global pooling layer and returns 2042 features per sample","cdbebd51":"#preprocessing images for efficient model\npre_images=tf.keras.applications.efficientnet.preprocess_input(images)\n#creating embedding on batches because they dont fit in memory at once\nbatch_size=8\nembeddings=np.zeros(shape=(len(pre_images),2048))\nfor i in range(len(pre_images)\/\/batch_size):\n    embedding=Model(pre_images[i*batch_size:(i+1)*batch_size])\n    embeddings[i*batch_size:(i+1)*batch_size]=embedding","00b9eed5":"from sklearn import cluster\nfrom sklearn.metrics import silhouette_score\n\n\ninertials=[]\n#silhouettes=[]\nbatch_size=4*826\nfor clusters in range(1,11):\n    mini_Kmeans=cluster.MiniBatchKMeans(n_clusters=clusters,batch_size=batch_size)\n    for i in range(len(pre_images)\/\/batch_size):\n            mini_Kmeans.partial_fit(embeddings[i*batch_size:(i+1)*batch_size])\n    #score=silhouette_score(embeddings,mini_Kmeans.predict(embeddings))\n    #silhouettes.append(score)\n    inertials.append(mini_Kmeans.inertia_)\nplt.plot(list(range(1,11)),inertials)\n\n#label_kmneans=mini_Kmeans.predict(embeddings)\n#extended_data=pandas.concat([data,pd.DataFrame(label_kmneans,columns=[\"Labels_kmeans\"])],axis=1)","d8a2cfc6":"from sklearn import cluster\nclusters=2\nbatch_size=4*826\nmini_Kmeans=cluster.MiniBatchKMeans(n_clusters=clusters,batch_size=batch_size)\nfor i in range(len(pre_images)\/\/batch_size):\n        mini_Kmeans.partial_fit(embeddings[i*batch_size:(i+1)*batch_size])\n            \nlabel_kmeans=mini_Kmeans.predict(embeddings)\nextended_data=pd.concat([data_copy,pd.DataFrame(label_kmeans,columns=[\"Labels_kmeans\"])],axis=1)\nextended_data[\"file\"]=extended_data.Id.apply(lambda x:os.path.join(ima_path,x+\".jpg\"))\n","38134047":"fig=plt.figure(figsize=(25,20))\nfig.subplots_adjust(wspace=0.2,hspace=0.1)\nax=fig.subplots(clusters,4)\nfor clust in range(0,clusters):#i chose clust so there is no confliction with sklearn.cluster module \n    files=extended_data[extended_data.Labels_kmeans==clust].sample(4).file.values\n    for i in range(0,4):\n        ima=cv2.imread(files[i],)\n        ima=cv2.cvtColor(ima,cv2.COLOR_BGR2RGB)\n        ima=cv2.resize(ima,dsize=(220,220))\n        ax[clust,i].imshow(ima)\n        ax[clust,i].set_xticks([])\n        ax[clust,i].set_yticks([])\n\n       ","91112c22":"#cluster=5\nclusters=5\nbatch_size=4*826\nmini_Kmeans=cluster.MiniBatchKMeans(n_clusters=clusters,batch_size=batch_size)\nfor i in range(len(pre_images)\/\/batch_size):\n        mini_Kmeans.partial_fit(embeddings[i*batch_size:(i+1)*batch_size])\n            \nlabel_kmeans=mini_Kmeans.predict(embeddings)\nextended_data=pd.concat([data_copy,pd.DataFrame(label_kmeans,columns=[\"Labels_kmeans\"])],axis=1)\nextended_data[\"file\"]=extended_data.Id.apply(lambda x:os.path.join(ima_path,x+\".jpg\"))\nfig=plt.figure(figsize=(25,20))\nfig.subplots_adjust(wspace=0.2,hspace=0.1)\nax=fig.subplots(clusters,4)\nfor clust in range(0,clusters):#i chose clust so there is no confliction with sklearn.cluster module \n    files=extended_data[extended_data.Labels_kmeans==clust].sample(4).file.values\n    for i in range(0,4):\n        ima=cv2.imread(files[i],)\n        ima=cv2.cvtColor(ima,cv2.COLOR_BGR2RGB)\n        ima=cv2.resize(ima,dsize=(220,220))\n        ax[clust,i].imshow(ima)\n        ax[clust,i].set_xticks([])\n        ax[clust,i].set_yticks([])\n","1f1819a8":"from sklearn.decomposition import TruncatedSVD,PCA\n\nSvd=TruncatedSVD(n_components=800)\nSvd.fit(embeddings)\nprint(\"SVD explained variance:\",Svd.explained_variance_ratio_.sum())\npca=PCA(n_components=800)\npca.fit(embeddings)\nprint(\"PCA explained variance:\",pca.explained_variance_ratio_.sum())","042216ce":"from sklearn.cluster import KMeans\nsvd_embde=Svd.transform(embeddings)\ninertias=[]\nfor clusters in range(1,11):\n    kmeans=KMeans(n_clusters=clusters)\n    kmeans.fit(svd_embde)\n    inertias.append(kmeans.inertia_)\nplt.plot(list(range(1,11)),inertias)","826e2b09":"clusters=2\nkmeans=KMeans(n_clusters=clusters)\nkmeans.fit(svd_embde)\nsvd_labels=kmeans.predict(svd_embde)\nextended_data=pd.concat([data_copy,pd.DataFrame(svd_labels,columns=[\"SVD_Labels_kmeans\"])],axis=1)\nextended_data[\"file\"]=extended_data.Id.apply(lambda x:os.path.join(ima_path,x+\".jpg\"))\n","d6df615f":"fig=plt.figure(figsize=(20,15))\nfig.subplots_adjust(wspace=0.2,hspace=0.1)\nax=fig.subplots(clusters,4)\nfor clust in range(0,clusters):\n    files=extended_data[extended_data.SVD_Labels_kmeans==clust].sample(4).file.values\n    for i in range(0,4):\n        ima=cv2.imread(files[i],)\n        ima=cv2.cvtColor(ima,cv2.COLOR_BGR2RGB)\n        ima=cv2.resize(ima,dsize=(220,220))\n        ax[clust,i].imshow(ima)\n        ax[clust,i].set_xticks([])\n        ax[clust,i].set_yticks([])\n","13a9e40f":"Because features are all of them binary, we can not create new informations from them but we can try to assign each image to a cluster. In clustering we will use the extracted features from a pretrained *EfficientB5* model. ","e0b0ef31":"Now we will reduce the features maps(extracted from Efficient model) to 600 and we are going to fit Kmeans again(now there is no need for online learning because they fit in memory).PCA and TruncatedSVD are similar methods so on they will give similar \"results\"","26fd1c4a":"<p>As you can see there are some features that are not &quot;balanced&quot;. They contain almost one of the two values they can take(1&quot;True&quot; or 0&quot;False&quot;). Also there is not significant difference between conditional distributions <strong>P(Pawpularity|feature)<\/strong>,so there is no a particular feature that has big impact on the Pawpularity<\/p>","9546e7a9":"<p>Lets count the <strong>unique one-hot values<\/strong> of features(e.x 10101100) and&nbsp; calculate the <strong>mean Pawpularity<\/strong><\/p>\n","afb5ef8e":"I will select clusters=2 and visualize the clustered images(I will visualize for 5 clusters)","fcce1051":"<p>You can notice below that Trees gives the opposite results from the linear models. They give low importance on the high-coeff features of Linear Regression,indicating that there is possibly no&nbsp; linear relation between features and target.<\/p>","ee034937":"<p>The distribution of Pawpopularity is a little bit skewed at the left and have a high value at 100..<\/p>","43ae787d":"It is clear that Kmeans try to distinguish cats from dogs but does not achieve it very well. Probably a Vggnet that uses Dense layers instead of Global pooling for his latest layers would give us better results. Also experiments with clustering methods could give better results","9c496b1f":"It is clear that we should select cluster=2","62ad719a":"First,we will fit a MiniBatchKmeans algorithm without dimensionality reduction","56b4ab6e":"Maybe the distribution of popularity depends to specific combinations of features(ex. 1010101011).A distribution plot for combinations with the most occurrences will help us...","cec8a9db":"<!-- #######  YAY, I AM THE SOURCE EDITOR! #########-->\n<p>&nbsp;<\/p>\n<p>&nbsp;In the current notebook we will see some basic <strong>EDA<\/strong> for the features and will try to find the feature with the most <strong>influence<\/strong> on the Pawpularity of a pet. The Dasatet consists only of binary features(1 and 0)that indicates what \"characteristics\" appears in the image,e.x. if there is a humam or the image is blurred. Of course they are not enought for the prediction of popularity but we can discover some intresting information about the \"aesthetics\" that judge the beauty of a pet<img src=\"https:\/\/html-online.com\/editor\/tiny4_9_11\/plugins\/emoticons\/img\/smiley-tongue-out.gif\" alt=\"tongue-out\" \/><strong><br \/><\/strong><\/p>"}}