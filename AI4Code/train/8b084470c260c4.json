{"cell_type":{"6876b0b5":"code","102074aa":"code","5721ee2c":"code","55dbbdc4":"code","06b2a580":"code","077708f8":"code","26c5cd25":"code","961e2e25":"code","e6d41157":"code","cbb8f66d":"code","b60a37fa":"code","fcd41511":"code","4bef85e5":"code","76c0a077":"code","f44656f2":"code","58b9f655":"code","d5b5265c":"code","110decb6":"code","79a6b888":"code","877688bb":"code","be7e5bc3":"code","673b2526":"code","63271eeb":"code","7c86c534":"code","15ec20c9":"code","61b1ec10":"code","243f8d01":"code","d6b5beb2":"code","7c56557e":"code","6f2668aa":"code","56b6de22":"code","f00e9d69":"code","20c8d67a":"markdown","2860ecb6":"markdown","7efef7d1":"markdown"},"source":{"6876b0b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","102074aa":"# Important libraries for working out with images preprocessing and training\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport keras\nfrom keras.layers import Dense,Convolution2D,Dropout,MaxPooling2D,BatchNormalization,Flatten\nfrom keras.models import Sequential,Model\nfrom keras.preprocessing.image import ImageDataGenerator\n","5721ee2c":"# Looking for the image directories\nos.listdir(\"..\/input\/repository\/shobhitsrivastava-ds-Violence-a245c62\/Images\/\")","55dbbdc4":"# Setting the image path\npath = \"..\/input\/repository\/shobhitsrivastava-ds-Violence-a245c62\/Images\/\"","06b2a580":"#Getting data generated from the directories through image data generator\ndata = ImageDataGenerator(rescale = 1.\/255, zoom_range = 0.3,horizontal_flip=True,rotation_range= 15).flow_from_directory(path,target_size= (224,224),color_mode= \"rgb\",classes= [\"Rifle\",\"tank\",\"guns\",\"knife images\"],batch_size=90)","077708f8":"x,y = data.next()\nplt.subplot(4,3,2)\nfor i in range(0,12):\n    image = x[i]\n    label = y[i]\n    print (label)\n    plt.imshow(image)\n    plt.show()","26c5cd25":"len(data)","961e2e25":"# Defining the Sequential model\nmodel= Sequential()","e6d41157":"#Adding up the layers of the network\nmodel.add(Convolution2D(32,(3,3),input_shape=(224,224,3),padding = \"Same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n#model.add(Dropout(0.2))\nmodel.add(Convolution2D(32,(3,3),padding = \"Same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n#model.add(Dropout(0.2))\nmodel.add(Convolution2D(64,(3,3),padding = \"Same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n#model.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = \"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(4,activation=\"softmax\"))","cbb8f66d":"# Implementing the callback function so as to stop the algorithm from the furthur traning in case the accuracy dips down\nclbk= keras.callbacks.EarlyStopping(monitor='accuracy',mode='min')","b60a37fa":"#Cmpiling the model\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","fcd41511":"# Printing out the model summary\nmodel.summary()","4bef85e5":"# Training the model  \nhistory_1 = model.fit_generator(data,steps_per_epoch=int(1273\/20),epochs=10,shuffle=False,callbacks=[clbk])","76c0a077":"data","f44656f2":"history_1.history","58b9f655":"model.save(\"Mymodel_2.h5\")","d5b5265c":"loss= history_1.history[\"loss\"]\nacc= history_1.history[\"acc\"]","110decb6":"# Plotting the model loss\nplt.plot(loss,color=\"r\")\nplt.title(\"Loss progression curve\")","79a6b888":"# Plotting the model accuracy\nplt.plot(acc,color=\"b\")\nplt.title(\" Accuracy progression curve\")","877688bb":"#Importig the transfer learning model VGG19\nfrom keras.applications import VGG19","be7e5bc3":"# Assigning weight and input shape\nmodel_sec=VGG19(weights=\"imagenet\",include_top=False,input_shape=(224,224,3))\nmodel_sec.summary()","673b2526":"# Generating the data\ndata_final = ImageDataGenerator(rescale = 1\/255, zoom_range = 0.2,horizontal_flip=True,vertical_flip=True).flow_from_directory(path,target_size=(224,224),color_mode=\"rgb\",classes=[\"Rifle\",\"tank\",\"guns\",\"knife images\"],batch_size=90)","63271eeb":"# Making the strting top layers of the model as non-trainable\nfor layer in model_sec.layers:\n    layer.trainable=False","7c86c534":"model_2=model_sec.output","15ec20c9":"# Adding the last trainable layers to the model\nmodel_2= Flatten()(model_2)\nmodel_2= Dense(512,activation=\"relu\")(model_2)\nmodel_2= Dropout(0.3)(model_2)\nmodel_2= Dense(256,activation=\"relu\")(model_2)\nmodel_2= Dropout(0.3)(model_2)\npred= Dense(4,activation=\"softmax\")(model_2)\nmodel_final =Model(input=model_sec.input,output=pred)","61b1ec10":"# Compiling the model\nmodel_final.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])","243f8d01":"# Training\nhistory = model_final.fit_generator(data_final,steps_per_epoch=int(1273\/80),epochs=8,shuffle=False,callbacks=[clbk])","d6b5beb2":"history.history","7c56557e":"model_final.save(\"Myfinal_model_2.h5\")","6f2668aa":"loss_final= history.history[\"loss\"]\nacc_final = history.history[\"acc\"]","56b6de22":"plt.plot(loss_final,color=\"r\")\nplt.title(\"Loss Progression Curve\")","f00e9d69":"plt.plot(acc_final,color=\"b\")\nplt.title(\"Accuracy Progression Curve\")","20c8d67a":"**Transfer Learning**","2860ecb6":"* > > The main reason behind using the transfer learning model is the availability of the small dataset","7efef7d1":" **About the Dataset**<br>\n*  The image dataset is divided into 4 categories of Knives, Rifel, Pistol Gun, and Tanks.<br>\n*  All the four categories of the dataset contains nearly 300 images each.<br>\n*  The labelling of each data that we will be getting is as follows:<br>\n <br>\n*         Knives: [0,0,0,1]; Source of Dataset : [Knives Google Images](https:\/\/www.google.com\/search?client=ubuntu&hs=wzV&channel=fs&tbm=isch&sa=1&ei=bAnpXPn9EMyAvgT9yKq4BA&q=knives&oq=knives&gs_l=img.3..35i39l2j0l8.196908.198173..198392...0.0..0.469.1060.1j0j1j1j1......0....1..gws-wiz-img.....0.JcGsBEjb3GE)<br>\n*         Pistol: [1,0,0,0]; Source of Dataset : [Pistol Google Images](https:\/\/www.google.com\/search?q=gun&client=ubuntu&hs=gtV&channel=fs&source=lnms&tbm=isch&sa=X&ved=0ahUKEwjd88SnrLbiAhVB_XMBHU6ADbMQ_AUIDigB&biw=1546&bih=818)<br>\n*         Rifel:  [0,0,1,0]; Source of Dataset : [Rifel Google Images](https:\/\/www.google.com\/search?q=rifel&client=ubuntu&hs=RJB&channel=fs&source=lnms&tbm=isch&sa=X&ved=0ahUKEwi7wo69rbbiAhVVg-YKHRvJAd4Q_AUIDigB)<br>\n*         Tanks:  [0,1,0,0]; Source of Dataset : [Tanks Google Images](https:\/\/www.google.com\/search?client=ubuntu&hs=nyV&channel=fs&tbm=isch&sa=1&ei=JQnpXKaaKpaRwgOrxqP4DQ&q=tanks&oq=tanks&gs_l=img.3..35i39l2j0l8.64613.67160..67306...1.0..0.1000.3454.1j1j5-1j2j1......0....1..gws-wiz-img.....0..0i67j0i10.GDshavd9sMQ)<br>\n* **In the following lines I will be training two neural network algorithms,the **first** one will be the traditional designed and the **second** one will be the transfer learning one in which I will be using **VGG19** neural network algorithm**"}}