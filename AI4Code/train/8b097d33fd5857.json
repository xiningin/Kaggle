{"cell_type":{"e5752e16":"code","eac1c9bf":"code","965529aa":"code","5faf59c0":"code","a2a25bc2":"code","abb4a048":"code","8580bc6d":"code","4fe442ae":"code","7c30d04f":"code","dc27c7c2":"code","b66ba414":"code","db4f62dd":"code","573d860c":"code","df93be47":"code","ecd22bf5":"code","2071bf73":"code","a170606b":"code","6b7160f2":"code","4012cd53":"code","2a712329":"code","b074e53c":"code","8c3f2661":"code","a66d0eea":"code","4d8c9b2c":"code","92b5772d":"code","6c5d57cb":"code","0bc58db0":"code","511d0680":"code","41266676":"code","ec04bc26":"code","f8b66c17":"markdown","8b79c91a":"markdown","739435b1":"markdown","19c17213":"markdown","098d91e9":"markdown","8e463ccb":"markdown","35834bf5":"markdown","255ba89c":"markdown","bb8ad5ad":"markdown","e7604dac":"markdown"},"source":{"e5752e16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eac1c9bf":"# import moduals\nimport csv, json, datetime as dt, statistics\nimport numpy as np #use numpy to deal with matrices\nimport pandas as pd #use pandas for data manipulation and analysis\nimport requests #use requests to handle interacting with the APIs\nimport time\n\n# ensure tables show all columns\/rows\npd.set_option('display.max_columns', None)\npd.set_option(\"max_rows\", None)","965529aa":"# Define a function to return data from the API\ndef get_request(url, parameters=None): \n    response = requests.get(url=url, params=parameters)\n    return response.json()","5faf59c0":"# Steamspy API\nurl = \"https:\/\/steamspy.com\/api.php\"\nparameters = {\"request\": \"all\"}","a2a25bc2":"# request 'all' from Steamspy and parse into dataframe\njson_data = get_request(url, parameters=parameters)  # get all app data from steamspy API\nsteam_spy_all = pd.DataFrame.from_dict(json_data, orient='index')   # give every game a row in a dataframe\n\n# generate sorted(by average playtime in the last two weeks. In minutes.) app_list from Steamspy data\napp_list = steam_spy_all[['average_2weeks', 'appid', 'name', 'owners', 'positive', 'negative']].sort_values('average_2weeks', ascending=False).reset_index(drop=True)","abb4a048":"# export csv \napp_list.to_csv('steam_app_list.csv', index=False)","8580bc6d":"# read from stored csv to speed up\napp_list = pd.read_csv('..\/input\/steam-app-list-newcsv\/steam_app_list_new.csv')\n\n# display first few rows\napp_list.head(20)","4fe442ae":"# Only show games whose owners are \"500,000 .. 1,000,000\"\nmost_owned_1 = app_list[app_list['owners'] == \"100,000,000 .. 200,000,000\"]\nmost_owned_1.head()","7c30d04f":"# create a new dataframe to store \nm_owned = pd.DataFrame()\nm_owned = m_owned.append(most_owned_1)\nm_owned.head()","dc27c7c2":"# Append other games with most owner ranges to the dataframe\nmost_owned_2 = app_list[app_list['owners'] == \"50,000,000 .. 100,000,000\"]\nmost_owned_3 = app_list[app_list['owners'] == \"20,000,000 .. 50,000,000\"]\nmost_owned_4 = app_list[app_list['owners'] == \"10,000,000 .. 20,000,000\"]\nm_owned = m_owned.append([most_owned_2, most_owned_3, most_owned_4])\nm_owned.head(50)","b66ba414":"# There is a problem here, some games, such as Half-Life 2, are owned by enormous amount of people. However, they are very old game so people barely play them now.\n# I think instead of using owners, I'd rather use the other parameter of Steamspy: top100in2weeks \u2014 Returns Top 100 games by players in the last two weeks.","db4f62dd":"url = \"https:\/\/steamspy.com\/api.php\"\nparameters = {\"request\": \"top100in2weeks\"}\n\n# request 'top100in2weeks' from Steamspy and parse into dataframe\njson_data = get_request(url, parameters=parameters)  # get all app data from steamspy API\nsteam_spy_top100in2weeks = pd.DataFrame.from_dict(json_data, orient='index')   # give every game a row in a dataframe\n\n# generate sorted(by average playtime in the last two weeks. In minutes.) app_list from Steamspy data\napp_list_v2 = steam_spy_top100in2weeks[['average_2weeks', 'appid', 'name', 'owners', 'positive', 'negative']].sort_values('average_2weeks', ascending=False).reset_index(drop=True)\n\n# export csv \napp_list_v2.to_csv('steam_app_list_v2.csv', index=False)","573d860c":"# read from stored csv to speed up\napp_list_v2 = pd.read_csv('..\/input\/steam-app-list-v2top100in2weeks\/app_list_v2.csv')","df93be47":"# display first few rows\napp_list_v2.head(100)","ecd22bf5":"# read from stored csv to speed up\napp_list = pd.read_csv('..\/input\/steam-app-list-newcsv\/steam_app_list_new.csv')\n\n# display first few rows\napp_list.head(100)","2071bf73":"# Now it looks good, let's first culculate positive rating rate","a170606b":"* Before moving on, I think there are 2 problems to solve.\n* 1st problem is, apps such as the EVGA Precision X1 are tools instead of games.\n* What we want are games, so we need to somehow tell them apart and only show apps that are games.\n* Fourtunately, utility apps are marked with 'utilites' in parameters, 'genre'and 'tags'.\n* Unfortunately, there isn't an easy way to obtain all 'tags or 'genre' data associated with a certain game.\n* So intead scrape those data, I want to use a workaround to get a dictionary containing all apps fall within the genre 'Utilities.'\n* Then I'll get rid of those apps...","6b7160f2":"# Steamspy API\uff0c again\nurl = \"https:\/\/steamspy.com\/api.php\"\nparameters = {'request': 'genre', 'genre': 'Utilities'} # later we will make request with these two parameters\n\n# send request to Steamspy\njson_data_g = get_request(url, parameters=parameters)  # get utility apps and put in a dictionary\nsteam_spy_g = pd.DataFrame.from_dict(json_data_g, orient='index')   # give every app in the dictionary a row in a dataframe\n\n# only keep what's necessary for filtering and sort app_list_v3 by 'appid'\napp_list_v3 = steam_spy_g[['appid', 'name']].sort_values('appid').reset_index(drop=True)\n\napp_list_v3.head(10) # read it\n\n# Now, we have a list of all utility apps and their IDs","4012cd53":"# Save the dataframe as csv file\napp_list_v3.to_csv('app_list_v3.csv', index=False)","2a712329":"# read the csv\napp_list_v3 = pd.read_csv('..\/input\/app-list-v3\/app_list_v3.csv')\napp_list_v3.head(10)","b074e53c":"# Put all utility apps' appids into a list\nut_list = app_list_v3['appid'].tolist()\n\n# Now it's time to remove all apps in app_list_v3(utility apps) from app_list\n# first, we create a new column to record whether or not an app belongs to 'Utilities' \n\n#app_list['utilities?'] = 'unknown'\nut_list\n\n# Please ignore code below in this code block\n\n#def ut_check(row):\n#    if row['appid'] in ut_list:    \n#        app_list_v2.drop('appid', axis= 0)\n\n#def weightedScore(row):\n#    score = 0.4*row['A']+0.4*row['B']+0.2*row['C']\n#    return score\n\n#df['D'] = df.apply(weightedScore, axis=1)\n#display(df)","8c3f2661":"# Now we can start to mark them out utilizing the utility app list, ut_list\n# create a function to check if an app is a utility app\ndef ut_check(row):\n    if row['appid'] in ut_list:  \n        return 'yes' # if it is, write 'yes'\n    else:\n        return 'no' # otherwise, write 'no'\n\n# apply the function to the dataframe and put the result in a new column called 'utilities'\napp_list['utilities'] = app_list.apply(ut_check, axis=1) \napp_list.head(20)\n\n# another way to do the same thing, print out the results then write into a new column\n# def ut_check(row):\n#    if row['appid'] in ut_list:  \n#        print ('yes')\n#    else:\n#        return ('no')","a66d0eea":"# we can now drop all non-game apps according to 'utilities?'\n# instead using drop function, I'll use query funtion to select and muster non-utility apps\nnon_ut = app_list.query('utilities == \"no\"')\n\n# drop 'utilities' column as we no longer need it\nnon_ut = non_ut.drop(['utilities'], axis=1)\n\nnon_ut.head(20)","4d8c9b2c":"# I'll just do this just as how I got non-utility apps\n# Steamspy API\uff0c again, query 'tag' this time\nurl = \"https:\/\/steamspy.com\/api.php\"\nparameters = {'request': 'tag', 'tag': 'Co-op'} # later we will make request with these two parameters\n\n# send request to Steamspy\njson_data_t = get_request(url, parameters=parameters)  # get co-op games and put in a dictionary\napp_list_v4 = pd.DataFrame.from_dict(json_data_t, orient='index')   # give every game in the dictionary a row in a dataframe\n\n# only keep what's necessary for filtering and sort app_list_v4 by 'appid'\n#app_list_v4 = steam_spy_g[['appid', 'name']].sort_values('appid').reset_index(drop=True)\n\n# Put all co-op games' appids into a list\ncoop_list = app_list_v4['appid'].tolist()\n\n# Now we can start to mark them out utilizing the co-op list\n# create a function to check if a game is co-op\ndef coop_check(row):\n    if row['appid'] in coop_list:  \n        return 'yes' # if it is, write 'yes'\n    else:\n        return 'no' # otherwise, write 'no'\n\n# apply the function to the dataframe and put the result in a new column called 'coop'\nnon_ut['co_op'] = non_ut.apply(coop_check, axis=1) \n#non_ut.head(20)\n\n# use query funtion to select and garner co-op games\ncoop_games = non_ut.query('co_op == \"yes\"')\n\n# drop 'coop' column as we no longer need it\ncoop_games = coop_games.drop(['co_op'], axis=1)\n\ncoop_games.head(20)","92b5772d":"# Save as csv\ncoop_games.to_csv('coop_games.csv', index=False)","6c5d57cb":"# read the csv to speed up and to be save\ncoop_g = pd.read_csv('..\/input\/coop-games\/coop_games.csv')\ncoop_g.head(20)","0bc58db0":"# We first create a new function for the calculation\ndef pos_rate(row):\n    all_r = row['positive'] + row['negative']\n    p_ratio = row['positive']\/all_r\n    p_ratio_2d = round(p_ratio, 2)  # round to 2 digits after decimal\n    p_ratio_2d = str(round(p_ratio_2d * 100))\n    return p_ratio_2d\n\n# apply the function to the file to get positive ratio\ncoop_g['positive ratio(%)'] = coop_g.apply(pos_rate, axis=1)\n\ncoop_g.drop([('positive'),('negative')], axis=1, inplace=True)  # delete positive & negative column for all we need is the ratio\ncoop_g.rename(columns = {'owners':'number of owners\u2014range', 'average_2weeks':'average playtime in the last two weeks(minute)'}, inplace = True) # change some columns' names\n\ncoop_g.head(20)","511d0680":"# save to csv\ncoop_g.to_csv('coop_g.csv', index=False)","41266676":"# read csv\nfinal_list = pd.read_csv('..\/input\/final-list\/coop_g.csv')\nfinal_list.head()","ec04bc26":"# import modules needed\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\n# Map the values into a linear regression model\nX = final_list['average playtime in the last two weeks(minute)'].values.reshape(-1,1)\nY = final_list['positive ratio(%)'].values.reshape(-1,1)\nLr = LinearRegression()\nLr.fit(X,Y)\nY_predict = Lr.predict(X)\n\n# Style and give labels to the visual\nplt.style.use('fivethirtyeight')\nplt.style.use('seaborn-poster')\nplt.title('Play Longer Together = Higher Game Rating?')\nplt.xlabel('Average Playtime in the Last Two Weeks (Minute)')\nplt.ylabel('Positive Rating Ratio (%)')\n\n# Plot the visual\nplt.scatter(X,Y)\nplt.plot(X,Y_predict, color = 'gold')\nplt.show()","f8b66c17":"* Now we have all the data we need in a preffered order\n* There is one last step before going into machine learning, that is, calculate positive rating rate","8b79c91a":"* As we can see, there are only two games that has that volume of owners, we want to see more games","739435b1":"I need a matrx of games so I can start to filter games","19c17213":"* Now we've got the well-organized dataset ready.\n* It's time for machine learning.\n* I will use linear regression to find out, for co-op games, if there is a correlation between average playtime and rating positive ratio. ","098d91e9":"* Sadly enough, if we read the file, we know the data in it is not accurate\n* how come many Top 100 games by players in the last two weeks have 0 min play time?\n* due to my experience, many games in this list are either super old, or definitely not boring\/short enough for people to finish playing within 1 minute...\n* we have to give this up and go back and use app_list, jeez","8e463ccb":"* An interesting finding already! The game that has the most average playtime in the last two weeks is \u61d2\u4eba\u4fee\u4ed9\u4f20(the Legend of a lazy guy striving to become a god), an indie word simulation game. Players of this game spent an average 11157mins(7.75days) in this game last two weeks. All you need to do for the gameplay are some clicks, and the game will basically run and play itself for as long as you want. It was released in 2018; however, it seems the UI is very basic, and the resolution is not really up to date. What's more interesting is that though the game is a word game that runs 100% in simplified Chinese, there seem to be a lot of non-Chinese speaking players out there in love with this game. Here is one of their reviews on Steam: \n\n* \"Is it fun: Yes. Do I understand a word it says: No. Does it matter: Yes. Do I really care: No\"\n\n* OK I guess that makes sense?","35834bf5":"* Now we get games with the longest average playtime in the last two weeks.\n* We need to filter out games that are not owned by large enough amount of people\n* Due to Steam's privacy policy, the Steamspy can only get a range of estimated amount of owners for each game.\n* Looking at the data, we learn that the largest owners range is \"\"100,000,000 .. 200,000,000\"\"","255ba89c":"* As shown, there is a slight positive correlation between the two factors.\n* We just don't know if it is because the game is great, so people would love to play logner together; or because people are able to play the game with each other for an extended period of time, they enjoy the game more.","bb8ad5ad":"* Initially I wanted to learn some insight about gamers, my questions are like: What is the relationship between the number of games owned and time spent in game playing? What is the most loved game in specific genre? But then my goal changed.\n* The goal of the project now is to advise users the best games for time-killing and communicating during COVID pandemic.\n* The main data source here is SteamSpy, a platform uses API to the Steam software distribution service that is owned by Valve to estimate the number of sales of software titles offered on the service. It also provides many more other data such as game id and average playtime.\n* Steam Spy API: https:\/\/steamspy.com\/api.php\n* There are two steps: 1. find the best game for time-killing and communicating during COVID pandemic 2. introduce them to users\n* There is an impiortant reference: Gathering Data from the Steam Store API using Python: https:\/\/nik-davis.github.io\/posts\/2019\/steam-data-collection\/ This project tried to gain insights into what makes a game more successful in Steam in terms of sales, play-time and ratings.\n* There is another work I can reference: https:\/\/data2win.me\/2017\/09\/18\/2017-09-18-looking-for-good-and-populated-co-op-games-to-play-with-you-friends-this-plot-will-help\/ It uses R to identify good and populated co-op games and visualizes them. The visualization is good.","e7604dac":"* After solving the first problem, we can go ahead and solve the 2nd one\n* There are a lot of single player game\n* We need to filter them out and keep only co-op games"}}