{"cell_type":{"3c55df8e":"code","c4b9cc7e":"code","3ca711ab":"code","80d6e997":"code","44e8fcf6":"code","c9a4f366":"code","ce5800a6":"code","e125deaf":"code","c667f42e":"code","76f3ae62":"code","90f9ee59":"code","98d33d6e":"code","d4009407":"code","6d5a5b5d":"code","544f8d23":"code","5eb9d426":"code","a16f8174":"code","2eaa3e33":"code","e0322132":"code","88de50a3":"code","638e3644":"code","7d99d2ac":"code","1e15bc70":"code","48e6a57f":"code","22abf716":"code","5999b577":"code","894acaed":"code","3c7be591":"code","173d3ccd":"code","48ecd16c":"code","ee948207":"markdown","effdc26d":"markdown","18232546":"markdown","b7b2b8fd":"markdown","1e50adb1":"markdown","ea60f523":"markdown","6534ccd3":"markdown","19e277c5":"markdown","3ca252a4":"markdown","d687c62f":"markdown","47a49151":"markdown","bf188af3":"markdown","df84e79f":"markdown","04377781":"markdown","3141ad86":"markdown","d9dc90d6":"markdown","4301e178":"markdown","3c915c3b":"markdown","ecab74e3":"markdown","6abd3218":"markdown","c11c71fa":"markdown","ab9086fd":"markdown","661ab366":"markdown","8696edf4":"markdown","0580a202":"markdown","8fd65b34":"markdown","bde41e41":"markdown","237bdddb":"markdown","697f76cc":"markdown","be3a957c":"markdown","43bbf9b2":"markdown","e1d6490a":"markdown","0071e2fc":"markdown","5c81fcd4":"markdown","3924e188":"markdown"},"source":{"3c55df8e":"\nfrom IPython.display import IFrame, YouTubeVideo\nYouTubeVideo('N2apCx1rlIQ',width=600, height=400)","c4b9cc7e":"YouTubeVideo('3fNf8KX1AlQ',width=600, height=400)","3ca711ab":"!pip install joypy --progress-bar off","80d6e997":"import os\n\n\nimport random\nimport seaborn as sns\nimport cv2\n# General packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\n\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nimport nibabel as nib\nimport h5py\nimport plotly.graph_objs as go\nfrom IPython.display import Image, display\nimport joypy\nimport warnings\nwarnings.filterwarnings(\"ignore\")","44e8fcf6":"os.listdir('\/kaggle\/input\/trends-assessment-prediction\/')","c9a4f366":"BASE_PATH = '..\/input\/trends-assessment-prediction'\n\n# image and mask directories\ntrain_data_dir = f'{BASE_PATH}\/fMRI_train'\ntest_data_dir = f'{BASE_PATH}\/fMRI_test'\n\n\nprint('Reading data...')\nloading_data = pd.read_csv(f'{BASE_PATH}\/loading.csv')\ntrain_data = pd.read_csv(f'{BASE_PATH}\/train_scores.csv')\nsample_submission = pd.read_csv(f'{BASE_PATH}\/sample_submission.csv')\nprint('Reading data completed')","ce5800a6":"display(train_data.head())\nprint(\"Shape of train_data :\", train_data.shape)","e125deaf":"display(loading_data.head())\nprint(\"Shape of loading_data :\", loading_data.shape)","c667f42e":"# checking missing data\ntotal = train_data.isnull().sum().sort_values(ascending = False)\npercent = (train_data.isnull().sum()\/train_data.isnull().count()*100).sort_values(ascending = False)\nmissing_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","76f3ae62":"total = loading_data.isnull().sum().sort_values(ascending = False)\npercent = (loading_data.isnull().sum()\/loading_data.isnull().count()*100).sort_values(ascending = False)\nmissing_loading_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_loading_data.head()","90f9ee59":"def plot_bar(df, feature, title='', show_percent = False, size=2):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    total = float(len(df))\n    sns.barplot(np.round(df[feature].value_counts().index).astype(int), df[feature].value_counts().values, alpha=0.8, palette='Set2')\n\n    plt.title(title)\n    if show_percent:\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x()+p.get_width()\/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(100*height\/total),\n                    ha=\"center\", rotation=45) \n    plt.xlabel(feature, fontsize=12, )\n    plt.ylabel('Number of Occurrences', fontsize=12)\n    plt.xticks(rotation=90)\n    plt.show()","98d33d6e":"plot_bar(train_data, 'age', 'age count and %age plot', show_percent=True, size=4)","d4009407":"def plot_bar(df, feature, title='', show_percent = False, size=2):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    total = float(len(df))\n    sns.barplot(np.round(df[feature].value_counts().index).astype(int), df[feature].value_counts().values, alpha=0.8, palette='Set2')\n\n    plt.title(title)\n    if show_percent:\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x()+p.get_width()\/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(100*height\/total),\n                    ha=\"center\", rotation=45) \n    plt.xlabel(feature, fontsize=12, )\n    plt.ylabel('Number of Occurrences', fontsize=12)\n    plt.xticks(rotation=90)\n    plt.show()","6d5a5b5d":"### Age count Distribution\nfor col in train_data.columns[2:]:\n    plot_bar(train_data, col, f'{col} count plot', size=4)","544f8d23":"temp_data =  train_data.drop(['Id'], axis=1)\n\nplt.figure(figsize = (12, 8))\nsns.heatmap(temp_data.corr(), annot = True, cmap=\"RdYlGn\")\nplt.yticks(rotation=0) \n\nplt.show()","5eb9d426":"temp_data =  loading_data.drop(['Id'], axis=1)\n\nplt.figure(figsize = (20, 20))\nsns.heatmap(temp_data.corr(), annot = True, cmap=\"RdYlGn\")\nplt.yticks(rotation=0) \n\nplt.show()","a16f8174":"temp_data =  loading_data.drop(['Id'], axis=1)\n# Create correlation matrix\ncorrel = temp_data.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = correl.where(np.triu(np.ones(correl.shape), k=1).astype(np.bool))\n# Find index of feature columns with correlation greater than 0.5\nto_drop = [column for column in upper.columns if any(upper[column] > 0.5)]\n\nprint('Very high correlated features: ', to_drop)","2eaa3e33":"# Draw Plot\nimport joypy\n\ntargets= loading_data.columns[1:]\n\n\nplt.figure(figsize=(16,10), dpi= 80)\nfig, axes = joypy.joyplot(loading_data, column=list(targets), ylim='own', figsize=(14,10))\n\n# Decoration\nplt.title('Distribution of features IC_01 to IC_29', fontsize=22)\nplt.show()","e0322132":"# Download the ch2better template image for display\n!wget https:\/\/github.com\/Chaogan-Yan\/DPABI\/raw\/master\/Templates\/ch2better.nii","88de50a3":"\"\"\"\n    Load and display a subject's spatial map\n\"\"\"\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nmask_filename = f'{BASE_PATH}\/fMRI_mask.nii'\nsubject_filename = '..\/input\/trends-assessment-prediction\/fMRI_train\/10004.mat'\nsmri_filename = 'ch2better.nii'\nmask_niimg = nl.image.load_img(mask_filename)\n\n\ndef load_subject(filename, mask_niimg):\n    \"\"\"\n    Load a subject saved in .mat format with\n        the version 7.3 flag. Return the subject\n        niimg, using a mask niimg as a template\n        for nifti headers.\n        \n    Args:\n        filename    <str>            the .mat filename for the subject data\n        mask_niimg  niimg object     the mask niimg object used for nifti headers\n    \"\"\"\n    subject_data = None\n    with h5py.File(subject_filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_niimg = nl.image.new_img_like(mask_niimg, subject_data, affine=mask_niimg.affine, copy_header=True)\n    return subject_niimg\nsubject_niimg = load_subject(subject_filename, mask_niimg)\nprint(\"Image shape is %s\" % (str(subject_niimg.shape)))\nnum_components = subject_niimg.shape[-1]\nprint(\"Detected {num_components} spatial maps\".format(num_components=num_components))","638e3644":"nlplt.plot_prob_atlas(subject_niimg, bg_img=smri_filename, view_type='filled_contours', draw_cross=False,title='All %d spatial maps' % num_components, threshold='auto')","7d99d2ac":"grid_size = int(np.ceil(np.sqrt(num_components)))\nfig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*10, grid_size*10))\n[axi.set_axis_off() for axi in axes.ravel()]\nrow = -1\nfor i, cur_img in enumerate(nl.image.iter_img(subject_niimg)):\n    col = i % grid_size\n    if col == 0:\n        row += 1\n    nlplt.plot_stat_map(cur_img, bg_img=smri_filename, title=\"IC %d\" % i, axes=axes[row, col], threshold=3, colorbar=False)","1e15bc70":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n!pip install pycaret --quiet","48e6a57f":"from pycaret.regression import *\n","22abf716":"BASE_PATH = '..\/input\/trends-assessment-prediction'\n\nfnc_df = pd.read_csv(f\"{BASE_PATH}\/fnc.csv\")\nloading_df = pd.read_csv(f\"{BASE_PATH}\/loading.csv\")\nlabels_df = pd.read_csv(f\"{BASE_PATH}\/train_scores.csv\")","5999b577":"fnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\nlabels_df[\"is_train\"] = True\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntest_df = df[df[\"is_train\"] != True].copy()\n","894acaed":"target_cols = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\ntest_df = test_df.drop(target_cols + ['is_train'], axis=1)\n\n# Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\nFNC_SCALE = 1\/500\ntest_df[fnc_features] *= FNC_SCALE","3c7be591":"target_models_dict = {\n    'age': 'age_br',\n    'domain1_var1':'domain1_var1_ridge',\n    'domain1_var2':'domain1_var2_svm',\n    'domain2_var1':'domain2_var1_ridge',\n    'domain2_var2':'domain2_var2_svm',\n}","173d3ccd":"## load PyCaret models\n\nfor index, target in enumerate(target_cols):\n    model_name = target_models_dict[target]\n    model = load_model(f'..\/input\/pycaret-trends-models\/{model_name}', platform = None, authentication = None, verbose=True)\n\n    predictions = predict_model(model, data=test_df)\n    test_df[target] = predictions['Label'].values","48ecd16c":"sub_df = pd.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\n\nsub_df.to_csv(\"submission1.csv\", index=False)\nsub_df.head()","ee948207":"**inference**\n\n* `domain1_var2` and `domain1_var1` has 438 missing values each.\n* `domain2_var2` and `domain2_var1` has 39 missing values each\n","effdc26d":"# About this Notebook\n\nIn this notebook, i will try to cover following topics in as much detail as possible:\n* `Domain Knowledge`: In general, domain knowledge is important when posing the question you want answered from data, as well as understanding the limitations of the data. If you don't understand these things (e.g., if you're working with a client on a new problem), then an essential skill is being able to ask the right questions to tease these things out.\n* `Basic statistics on the dataset`\n* `Extensive EDA`\n* `Visualization of spatial maps`\n* `Sample Submission`\n\n\n**This kernel will be a work in Progress,and I will keep on updating it as the competition progresses**\n    \n**<span style=\"color:Red\">Please upvote this kernel if you like it . It motivates me to produce more quality content :)**","18232546":"**File Format**\n\nThe subject spatial maps have been saved in .mat files using the v7.3 flag, so they must be loaded as h5py datasets, and a nifti file must be used to set the headers for display purposes. We have included the load_subject function, which takes a subject .mat filename, and the loaded nilearn image to use for setting the headers.\n\n","b7b2b8fd":"## Checking for Null values \n\n#### train_data","1e50adb1":"## What's Next\n* Better Visualization ","ea60f523":"### Q7) What do we need to predict?\n\nWe need to predict values for following output variables:\n\n* `age`\n* `domain1_var1`\n* `domain1_var2`\n* `domain2_var1`\n* `domain2_var2`","6534ccd3":"### Displaying all Components in a Probability Atlas\nFirst, we will display the 53 spatial maps in one complete atlas using the `nilearn` `plot_prob_atlas` function. These maps will be overlaid on a structural MRI template.","19e277c5":"### plot showing distribution of loading_data features ","3ca252a4":"The dataset comprises of following important files:\n* `train_scores.csv`: This file has `age`, `domain1_var1`, `domain1_var2`, `domain2_var1`, `domain2_var2` as important feature variables.\n* `loading.csv`: This file has `IC_01` to `IC_29` as important feature variables.","d687c62f":"## Sample Submission","47a49151":"### Heatmap showing correlation between train_data features","bf188af3":"# Preliminaries\nNow Let's Begin by Importing the data","df84e79f":"## My other works for this competition\n\nIf you like my work, please take a look at my other works which i have done in this competition so far\n* https:\/\/www.kaggle.com\/rohitsingh9990\/trends-pycaret-training-inference","04377781":"#### loading_data","3141ad86":"# Domain Knowledge\n\nSo lets start with the domain knowledge and Address the few important questions\n\n\n### Q1) What is the motivation behind this competition?\n\nHuman brain research is among the most complex areas of study for scientists. We know that age and other factors can affect its function and structure, but more research is needed into what specifically occurs within the brain. With much of the research using MRI scans, data scientists are well positioned to support future insights. In particular, neuroimaging specialists look for measurable markers of behavior, health, or disorder to help identify relevant brain regions and their contribution to typical or symptomatic effects.\n\nThe competition(TReNDS) is meant to encourage approaches able to predict age plus additional continuous individual-level assessment values, given multimodal brain features such as 3D functional spatial maps from resting-state functional MRI, static functional network connectivity (FNC) matrices, and source-based morphometry (SBM) loading values from structural MRI. For this task, one of the largest datasets of unbiased multimodal brain imaging features is made available. Given a set of multimodal imaging features, the developed predictors should output age and assessment predictions.\n\n\n\n\n\n### Q2) What is Neuroimaging?\n","d9dc90d6":"**inference**\n\nThe above heatmap shows very high correlation between some features. For example\n* `IC_13` and `IC_14` has a correlation value as high as 0.55\n* `IC_10` and `IC_22` are also very highly negative correlated with correlation value -0.54","4301e178":"**inference**\n* `domain1_var1` has 64 unique values when rounded to nearest integers, 23 is the most frequent.\n* `domain1_var2` has 81 unique values when rounded to nearest integers, 28 is the most frequent.\n* `domain2_var1` has 76 unique values when rounded to nearest integers, 16 is the most frequent.\n* `domain2_var2` has 83 unique values when rounded to nearest integers, 22 is the most frequent.","3c915c3b":"# END NOTES\nThis notebook is work in progress. \nI will keep on updating this kernel with my new findings and learning in order to help everyone who has just started in this competition.\n\n**<span style=\"color:Red\">Please upvote this kernel if you like it . It motivates me to produce more quality content :)**  ","ecab74e3":"#### Create Submission\n","6abd3218":"## EDA","c11c71fa":"### Q3) What is an fMRI scan and how does it work??\n\nAn fMRI scan is a functional magnetic resonance imaging scan that measures and maps the brain\u2019s activity. An fMRI scan uses the same technology as an MRI scan. An MRI is a noninvasive test that uses a strong magnetic field and radio waves to create an image of the brain. The image an MRI scan produces is just of organs\/tissue, but an fMRI will produce an image showing the blood flow in the brain. By showing the blood flow it will display which parts of the brain are being stimulated.\n\n![](https:\/\/www.sciencealert.com\/images\/articles\/processed\/fmri-scanss_1024.jpg)\n\n\n* [Important Read](https:\/\/www.jameco.com\/Jameco\/workshop\/HowItWorks\/what-is-an-fmri-scan-and-how-does-it-work.html)\n\n\n","ab9086fd":"# References\n\n* https:\/\/pycaret.org\/regression\/\n* https:\/\/www.kaggle.com\/bbradt\/loading-and-exploring-spatial-maps\n* Few ideas taken from https:\/\/www.kaggle.com\/tanulsingh077\/prostate-cancer-in-depth-understanding-eda-model\n","661ab366":"## Loading Dataset\n","8696edf4":"\n## 4. Loading and Exploring Spatial Maps\nHere we will see, how to load and display subject spatial map information for fMRI spatial maps. In general the spatial maps are saved as 4-D tensors\n\n\ue244\ud835\udc56\u2208\u211d\ud835\udc4b\u00d7\ud835\udc4c\u00d7\ud835\udc4d\u00d7\ud835\udc3e\n \nwhere  \ud835\udc4b ,  \ud835\udc4c , and  \ud835\udc4d  are the three spatial dimensions of the volume, and  \ud835\udc3e  is the number of independent components.","0580a202":"### Q8) What are expectations of the competition Host?\n\nHosts are expecting models which generalize well on data from a different scanner\/site (site 2). All subjects from site 2 were assigned to the test set, so their scores are not available. While there are fewer site 2 subjects than site 1 subjects in the test set, the total number of subjects from site 2 will not be revealed until after the end of the competition. To make it more interesting, the IDs of some site 2 subjects have been revealed below. Use this to inform your models about site effects. Site effects are a form of bias. To generalize well, models should learn features that are not related to or driven by site effects.\n\n\n\n","8fd65b34":"**inference**\n* Top 5 most frequent ages are 57, 60, 54, 55, 50\n* Most of the patients lie between the age group 22 to 77.","bde41e41":"## Important blogs, research papers and kaggle discussions\n\n* https:\/\/www.kaggle.com\/c\/trends-assessment-prediction\/discussion\/145818\n* https:\/\/www.kaggle.com\/c\/trends-assessment-prediction\/discussion\/145791\n* https:\/\/www.kaggle.com\/c\/trends-assessment-prediction\/discussion\/145597\n* https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3181933\/\n* https:\/\/journals.plos.org\/plosone\/article?id=10.1371\/journal.pone.0066572\n* https:\/\/www.kaggle.com\/c\/trends-assessment-prediction\/discussion\/146205","237bdddb":"### Let's Start with distribution of variables in train_data\n\nFor Visualization purpose i have rounded the values to their nearest integer","697f76cc":"### Q4) How Features Were Obtained (FMRI image Data Collection)?\n\nAn unbiased strategy was utilized to obtain the provided features. This means that a separate, unrelated large imaging dataset was utilized to learn feature templates. Then, these templates were \"projected\" onto the original imaging data of each subject used for this competition using spatially constrained independent component analysis (scICA) via group information guided ICA (GIG-ICA).\n\nThe first set of features are source-based morphometry (SBM) loadings. These are subject-level weights from a group-level ICA decomposition of gray matter concentration maps from structural MRI (sMRI) scans.\n\nThe second set are static functional network connectivity (FNC) matrices. These are the subject-level cross-correlation values among 53 component timecourses estimated from GIG-ICA of resting state functional MRI (fMRI).\n\nThe third set of features are the component spatial maps (SM). These are the subject-level 3D images of 53 spatial networks estimated from GIG-ICA of resting state functional MRI (fMRI).","be3a957c":"### Heatmap showing correlation between loading_data features","43bbf9b2":"### Q6) How the dataset look likes?\n\n**Files**\n* `fMRI_train` - a folder containing 53 3D spatial maps for train samples in .mat format\n* `fMRI_test` - a folder containing 53 3D spatial maps for test samples in .mat format\n* `fnc.csv` - static FNC correlation features for both train and test samples\n* `loading.csv` - sMRI SBM loadings for both train and test samples\n* `train_scores.csv` - age and assessment values for train samples\n* `sample_submission.csv` - a sample submission file in the correct format\n\n* `reveal_ID_site2.csv` - a list of subject IDs whose data was collected with a different scanner than the train samples\n* `fMRI_mask.nii` - a 3D binary spatial map\n* `ICN_numbers.txt` - intrinsic connectivity network numbers for each fMRI spatial map; matches FNC names\n\nThe .mat files for this competition can be read in python using `h5py`, and the `.nii` file can be read in python using nilearn.\n****","e1d6490a":"![](https:\/\/images.squarespace-cdn.com\/content\/5a0b0eb1ace864b50eccea63\/1564620684180-ECGGLZMYN4W05AICZ07K\/brainscansscience.jpg?content-type=image%2Fjpeg)","0071e2fc":"### Q5) What are we doing in this competition?\n\nIn this challenge, kagglers will predict `age` and `assessment values` from two domains using features derived from brain MRI images as inputs.\n\n\n\n","5c81fcd4":"**inference**\n* `age` and `domain1_var1` has a correlation value of 0.34, which is quite significant and shows a positive correlation between thease two variables.","3924e188":"### Displaying Individual Component Maps\n\nAdditionally, we can separately display each of the 53 maps to get a more complete view\nof individual component structure."}}