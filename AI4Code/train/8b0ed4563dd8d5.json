{"cell_type":{"325838cc":"code","24b1365e":"code","778820df":"code","fa3bb114":"code","35e0f1d0":"code","d69db0f5":"code","4257efce":"code","0428e078":"code","67eb8a7f":"code","02b01c86":"code","01153139":"code","878e06dc":"code","391432eb":"code","90139952":"code","33b520cf":"code","5896a0d3":"code","5e1f8a9f":"code","992fcd8f":"code","75c2b2e7":"code","b95706ec":"code","cf8c3db6":"code","6cd87c13":"code","a7d7d697":"code","8e445ebf":"code","dff0aed6":"code","93080a3c":"code","534c783c":"code","49ab3e98":"code","b2f3bb25":"code","7522b6b1":"code","1af66e51":"code","7ff62854":"code","13b1ed38":"code","9369f4e6":"code","1dbca1cb":"code","41551e8a":"code","5a6ceb68":"code","7bc114c5":"code","88126894":"code","30e50c6f":"code","c0d8278c":"code","5ce1eb69":"code","132a153a":"code","c2e3067c":"code","3836a024":"code","68690740":"code","5972c898":"code","53a3355b":"code","c2849284":"code","3a19327f":"code","706f31b6":"code","b125e11a":"code","95c11e45":"code","f269b39f":"code","fbaba8de":"code","5c8e261e":"code","0eb65267":"code","5e7f115e":"code","d81746cc":"code","9505d58c":"code","ba2b7e7d":"code","fbcb5279":"code","de7a2a1d":"code","1dcffcc5":"code","29ff3a37":"code","25969137":"code","2bcf40ad":"code","8ae483fe":"code","be01cb50":"code","04e3c3bf":"code","fff17576":"code","6228529d":"code","d78f4547":"code","ba594e91":"code","46053f5b":"code","d158cdb3":"code","8ffa500a":"code","2c4aeda1":"code","ed47a358":"code","8568f0c8":"code","caf0a58d":"code","0a9aecdc":"markdown","25bad2fc":"markdown","320f726f":"markdown","de7dfe96":"markdown","b6d5c4ce":"markdown","35dda3b1":"markdown","7699233a":"markdown","c5533dca":"markdown","d2b08765":"markdown"},"source":{"325838cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","24b1365e":"train = pd.read_csv(\"..\/input\/train.csv\", nrows = 1000000)\ntest = pd.read_csv(\"..\/input\/test.csv\")","778820df":"train.shape\n","fa3bb114":"test.shape","35e0f1d0":"train.head(10)","d69db0f5":"train.describe()","4257efce":"#check for missing values in train data\ntrain.isnull().sum().sort_values(ascending=False)","0428e078":"#drop the missing values\ntrain = train.drop(train[train.isnull().any(1)].index, axis = 0)","67eb8a7f":"train.shape","02b01c86":"#check the target column\ntrain['fare_amount'].describe()","01153139":"#38 fields have negative fare_amount values.\nfrom collections import Counter\nCounter(train['fare_amount']<0)","878e06dc":"train = train.drop(train[train['fare_amount']<0].index, axis=0)\ntrain.shape","391432eb":"#no more negative values in the fare field\ntrain['fare_amount'].describe()","90139952":"#highest fare is $500\ntrain['fare_amount'].sort_values(ascending=False)","33b520cf":"train['passenger_count'].describe()","5896a0d3":"#max is 208 passengers. Assuming that a bus is a 'taxi' in NYC, I don't think a bus can carry 208 this is DEFINITELY an outlier. \n#Lets drop it \ntrain[train['passenger_count']>8]","5e1f8a9f":"train = train.drop(train[train['passenger_count']==208].index, axis = 0)","992fcd8f":"#much neater now! Max number of passengers are 6. Which makes sense is the cab is an SUV :)\ntrain['passenger_count'].describe()","75c2b2e7":"#Next, let us explore the pickup latitude and longitudes\ntrain['pickup_latitude'].describe()","b95706ec":"train[train['pickup_latitude']<-90]","cf8c3db6":"train[train['pickup_latitude']>90]","6cd87c13":"#We need to drop these outliers\ntrain = train.drop(((train[train['pickup_latitude']<-90])|(train[train['pickup_latitude']>90])).index, axis=0)","a7d7d697":"train.shape","8e445ebf":"#similar operation for pickup longitude\ntrain['pickup_longitude'].describe()","dff0aed6":"train[train['pickup_longitude']<-180]","93080a3c":"train[train['pickup_longitude']>180]","534c783c":"train = train.drop(((train[train['pickup_longitude']<-180])|(train[train['pickup_longitude']>180])).index, axis=0)","49ab3e98":"#similar operation for dropoff latitude and longitude\ntrain[train['dropoff_latitude']<-90]","b2f3bb25":"train[train['dropoff_latitude']>90]","7522b6b1":"train = train.drop(((train[train['dropoff_latitude']<-90])|(train[train['dropoff_latitude']>90])).index, axis=0)","1af66e51":"train[train['dropoff_latitude']<-180]|train[train['dropoff_latitude']>180]","7ff62854":"train.dtypes","13b1ed38":"train['key'] = pd.to_datetime(train['key'],infer_datetime_format = True)\ntrain['pickup_datetime']  =  pd.to_datetime(train['pickup_datetime'],infer_datetime_format=True)","9369f4e6":"#Convert for test data\ntest['key'] = pd.to_datetime(test['key'],infer_datetime_format = True)\ntest['pickup_datetime']  = pd.to_datetime(test['pickup_datetime'],infer_datetime_format = True)","1dbca1cb":"#check the dtypes after conversion\ntrain.dtypes","41551e8a":"def haversine_distance(lat1,long1, lat2,long2):\n    data = [train,test]\n    for i in data:\n        r = 6371\n        phi1 = np.radians(i[lat1])\n        phi2 = np.radians(i[lat2])\n        \n        delta_phi = np.radians(i[lat2]-i[lat1])\n        delta_lambda = np.radians(i[long2]-i[long1])\n        \n        a = np.sin(delta_phi \/2.0)**2 + np.cos(phi1)* np.cos(phi2) * np.sin(delta_lambda \/ 2.0) ** 2\n        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    \n        \n        d = (r * c) #in kilometers\n        i['H_Distance'] = d\n    return d","5a6ceb68":"haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')","7bc114c5":"train['H_Distance'].head(10)","88126894":"data = [train,test]\nfor i in data:\n    i['Year'] = i['pickup_datetime'].dt.year\n    i['Month'] = i['pickup_datetime'].dt.month\n    i['Date'] = i['pickup_datetime'].dt.day\n    i['Day of Week'] = i['pickup_datetime'].dt.dayofweek\n    i['Hour'] = i['pickup_datetime'].dt.hour","30e50c6f":"#pickup latitude and longitude = 0\ntrain.loc[((train['pickup_latitude']==0) & (train['pickup_longitude']==0))&((train['dropoff_latitude']!=0) & (train['dropoff_longitude']!=0)) & (train['fare_amount']==0)]","c0d8278c":"train = train.drop(train.loc[((train['pickup_latitude']==0) & (train['pickup_longitude']==0))&((train['dropoff_latitude']!=0) & (train['dropoff_longitude']!=0)) & (train['fare_amount']==0)].index, axis=0)","5ce1eb69":"#1 row dropped\ntrain.shape","132a153a":"#dropoff latitude and longitude = 0\ntrain.loc[((train['pickup_latitude']!=0) & (train['pickup_longitude']!=0))&((train['dropoff_latitude']==0) & (train['dropoff_longitude']==0)) & (train['fare_amount']==0)]","c2e3067c":"train = train.drop(train.loc[((train['pickup_latitude']!=0) & (train['pickup_longitude']!=0))&((train['dropoff_latitude']==0) & (train['dropoff_longitude']==0)) & (train['fare_amount']==0)].index, axis=0)","3836a024":"high_distance = train.loc[(train['H_Distance']>200)&(train['fare_amount']!=0)]","68690740":"high_distance","5972c898":"high_distance['H_Distance'] = high_distance.apply(\n    lambda row: (row['fare_amount'] - 2.50)\/1.56,\n    axis=1\n)","53a3355b":"#sync the train data with the newly computed distance values from high_distance dataframe\ntrain.update(high_distance)","c2849284":"train[train['H_Distance']==0]","3a19327f":"train[(train['H_Distance']==0)&(train['fare_amount']==0)]","706f31b6":"train = train.drop(train[(train['H_Distance']==0)&(train['fare_amount']==0)].index, axis = 0)","b125e11a":"#4 rows dropped\ntrain[(train['H_Distance']==0)].shape","95c11e45":"#Between 6AM and 8PM on Mon-Fri\nrush_hour = train.loc[(((train['Hour']>=6)&(train['Hour']<=20)) & ((train['Day of Week']>=1) & (train['Day of Week']<=5)) & (train['H_Distance']==0) & (train['fare_amount'] < 2.5))]\nrush_hour","f269b39f":"train=train.drop(rush_hour.index, axis=0)","fbaba8de":"#Between 8PM and 6AM on Mon-Fri\nnon_rush_hour = train.loc[(((train['Hour']<6)|(train['Hour']>20)) & ((train['Day of Week']>=1)&(train['Day of Week']<=5)) & (train['H_Distance']==0) & (train['fare_amount'] < 3.0))]\n#print(Counter(non_work_hours['Hour']))\n#print(Counter(non_work_hours['Day of Week']))\nnon_rush_hour\n#keep these. Since the fare_amount is not <2.5 (which is the base fare), these values seem legit to me.","5c8e261e":"#Saturday and Sunday all hours\nweekends = train.loc[((train['Day of Week']==0) | (train['Day of Week']==6)) & (train['H_Distance']==0) & (train['fare_amount'] < 3.0)]\nweekends\n#Counter(weekends['Day of Week'])\n#keep these too. Since the fare_amount is not <2.5, these values seem legit to me.","0eb65267":"train.loc[(train['H_Distance']!=0) & (train['fare_amount']==0)]","5e7f115e":"scenario_3 = train.loc[(train['H_Distance']!=0) & (train['fare_amount']==0)]","d81746cc":"len(scenario_3)","9505d58c":"#We do not have any distance values that are outliers.\nscenario_3.sort_values('H_Distance', ascending=False)","ba2b7e7d":"scenario_3['fare_amount'] = scenario_3.apply(\n    lambda row: ((row['H_Distance'] * 1.56) + 2.50), axis=1\n)","fbcb5279":"scenario_3['fare_amount']","de7a2a1d":"train.update(scenario_3)","1dcffcc5":"train.loc[(train['H_Distance']==0) & (train['fare_amount']!=0)]","29ff3a37":"scenario_4 = train.loc[(train['H_Distance']==0) & (train['fare_amount']!=0)]","25969137":"len(scenario_4)","2bcf40ad":"#Using our prior knowledge about the base price during weekdays and weekends for the cabs.\n#I do not want to impute these 1502 values as they are legible ones.\nscenario_4.loc[(scenario_4['fare_amount']<=3.0)&(scenario_4['H_Distance']==0)]","8ae483fe":"scenario_4.loc[(scenario_4['fare_amount']>3.0)&(scenario_4['H_Distance']==0)]","be01cb50":"scenario_4_sub = scenario_4.loc[(scenario_4['fare_amount']>3.0)&(scenario_4['H_Distance']==0)]","04e3c3bf":"scenario_4_sub = scenario_4.loc[(scenario_4['fare_amount']>3.0)&(scenario_4['H_Distance']==0)]","fff17576":"len(scenario_4_sub)","6228529d":"scenario_4_sub['H_Distance'] = scenario_4_sub.apply(\nlambda row: ((row['fare_amount']-2.50)\/1.56), axis=1\n)","d78f4547":"train.update(scenario_4_sub)","ba594e91":"train.columns","46053f5b":"test.columns","d158cdb3":"#not including the pickup_datetime columns as datetime columns cannot be directly used while modelling. Features need to extracted from the \n#timestamp fields which will later be used as features for modelling.\ntrain = train.drop(['key','pickup_datetime'], axis = 1)\ntest = test.drop(['key','pickup_datetime'], axis = 1)","8ffa500a":"x_train = train.iloc[:,train.columns!='fare_amount']\ny_train = train['fare_amount'].values\nx_test = test","2c4aeda1":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor()\nrf.fit(x_train, y_train)\nrf_predict = rf.predict(x_test)\n#print(rf_predict)","ed47a358":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['fare_amount'] = rf_predict\nsubmission.to_csv('submission_1.csv', index=False)\nsubmission.head(20)","8568f0c8":"from sklearn import linear_model\nlr = linear_model.LinearRegression()\nlr.fit(x_train, y_train)\nlr_predict = lr.predict(x_test)","caf0a58d":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['fare_amount'] = lr_predict\nsubmission.to_csv('submission_2.csv', index=False)\nsubmission.head(20)","0a9aecdc":"\nFirst, let's split the datetime field 'pickup_datetime' to the following - \n* year\n* month\n* date\n* hour\n* day of week\n\nUsing these we shall calculate the day of the week and come to our conclusions about how pickup_location affects the fare.\nAlso, create a new field 'distance' to fetch the distance between the pickup and the drop.","25bad2fc":"We can calulate the distance in a sphere when latitudes and longitudes are given by [Haversine formula](https:\/\/en.wikipedia.org\/wiki\/Haversine_formula)\n\n**haversine(\u03b8) = sin\u00b2(\u03b8\/2)**\n\nEventually, the formual boils down to the following where \u03c6 is latitude, \u03bb is longitude, R is earth\u2019s radius (mean radius = 6,371km) to include latitude and longitude coordinates (A and B in this case).\n\n**a = sin\u00b2((\u03c6B - \u03c6A)\/2) + cos \u03c6A . cos \u03c6B . sin\u00b2((\u03bbB - \u03bbA)\/2)**\n\n**c = 2 * atan2( \u221aa, \u221a(1\u2212a) )**\n\n**d = R \u22c5 c**\n\n**d = Haversine distance**\n\n*Refer [this](https:\/\/community.esri.com\/groups\/coordinate-reference-systems\/blog\/2017\/10\/05\/haversine-formula) page for more info and examples on Haversine formula*","320f726f":"We can see a few rows with distance =0. This could be due to 2 reasons \n1. The cab waited the whole time and the passenger eventually cancelled. *That's why the pickup and drop co-ordinates are the same and maybe, the passenger was charged for the waiting time.*\n2. The pickup and drop co-ordinates were not entered. In other words, these are **missing values**!\n\n28667 rows are too many rows to be deleted. We need to impute these missing values. I have a plan. I intend to impute the missing distance values with the fare and average price per kilometer of NYC cabs.\n\nA quick Google search gave me the following prices  - \n\n* $$2.5 base-price  +  $1.56\/km --> 6AM to 8PM Mon-Fri\n\n* $$3.0 base-price  +  $1.56\/km --> 8PM to 6AM Mon-Fri and Sat&Sun\n\nHowever, before we proceed with the above steps, lets check for the following scenarios to impute the missing fare amount and the H_Distance in train data.\n\n","de7dfe96":"Check the H_Distance fields which are greater than 200 kms cause there is no way that people would travel more than 200 kms at the most in NYC in a CAB!","b6d5c4ce":"Quick Googling gave me this info\n* Latitudes range from -90 to 90.\n* Longitudes range from -180 to 180.\n\nThe above describe clearly shows some outliers. Let's filter them","35dda3b1":"**PART 1 --> DATA CLEANSING & EXPLORATORY DATA ANALYSIS (EDA)**\n\nWill perform the following activities\n* Shape of train and test sets\n* Check for NaNs and drop them (if any)\n* Check for outliers and drop them (if any)\n* Type conversion of relevant fields\n* We Can do it easily with the help of pandas profiling.","7699233a":"There are values which are greater than 100 kms! In NYC I am not sure why people would take cabs to travel more than a 100 kms. Since the number of bins for 100-200 kms is quite high, I will keep these. These outliers could be because of typos or missing values in the latitude or longitude. Remove fields of the following - \n1.  Pickup latitude and pickup longitude are 0 but dropoff latitude and longitude are not 0, but the fare is 0\n2. vice versa of point 1.\n3. Pickup latitude and pickup longitude are 0 but dropoff latitude and longitude are not 0, but the fare is NOT 0. Here I will have to impute the distance values in both the train and test data.","c5533dca":"Fare amount has a negative value, which doesn't make sense. Remove these fields","d2b08765":"**Univariate Analysis**\n* Now We Perform Univariate Analysis,i.e. Analysing Each variable one by one. To get best insights from it."}}