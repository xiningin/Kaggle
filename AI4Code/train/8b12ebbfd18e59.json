{"cell_type":{"91781bd8":"code","f21d388a":"code","893ad072":"code","3c4e6e71":"code","026b8b71":"code","c0392c0b":"code","3539ae09":"code","ccf0be41":"code","993f3913":"code","774b2376":"code","daefd335":"code","9fbbbb5d":"code","795715ce":"code","58aa1c46":"code","1cc6fb44":"code","53e8a544":"code","446e7242":"code","133e758e":"code","c8c523b2":"code","52b3ee92":"code","ab0e28e1":"code","88a4c9cc":"code","bc59a4f6":"code","ea584eaa":"code","fb0d05ce":"code","651bc8c3":"markdown","45dda600":"markdown","49834905":"markdown","30082161":"markdown","c4c668d0":"markdown","11ad06aa":"markdown","704a2429":"markdown","023aa1a1":"markdown"},"source":{"91781bd8":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport sklearn\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import IsolationForest\n%matplotlib inline\n\nfrom sklearn.preprocessing import StandardScaler \n","f21d388a":"DATA_PATH = '..\/input\/israeli-polling-anomaly\/'\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))        ","893ad072":"# \u05de-1951 \u05d5\u05e2\u05d3 1992 \u05e2\u05de\u05d3 \u05d0\u05d7\u05d5\u05d6 \u05d4\u05d7\u05e1\u05d9\u05de\u05d4 \u05d1\u05d9\u05e9\u05e8\u05d0\u05dc \u05e2\u05dc 1%, \u05d5\u05d1\u05d9\u05df 1992 \u05dc-2003 \u05e2\u05dc 1.5%. \u05d1\u05de\u05d0\u05d9 2004 \u05d4\u05d5\u05e2\u05dc\u05d4  \u05d0\u05d7\u05d5\u05d6 \u05d4\u05d7\u05e1\u05d9\u05de\u05d4 \u05dc-2%. \u05d5\u05d1\u05de\u05e8\u05e5 2014 \u05d4\u05ea\u05e7\u05d1\u05dc \u05ea\u05d9\u05e7\u05d5\u05df \u05e0\u05d5\u05e1\u05e3 \u05dc\u05d7\u05d5\u05e7 \u05d4\u05de\u05e2\u05dc\u05d4 \u05d0\u05ea \u05d0\u05d7\u05d5\u05d6 \u05d4\u05d7\u05e1\u05d9\u05de\u05d4 \u05dc-3.25%.\n# \u05d0\u05d7\u05d5\u05d6 \u05d4\u05d7\u05e1\u05d9\u05de\u05d4\n# block_percent = 0.0325 # \u05e6\u05dd\u05d2\u05e7\u05e8\u05de \nblock_percent = 0.015","3c4e6e71":"df = pd.read_csv(DATA_PATH + 'votes_2019.csv', encoding='iso_8859_8')\nprint(df.shape)\n\ndf.head()","026b8b71":" df.iloc[:,7:51].head()","c0392c0b":"df = df.dropna(axis=0, how='any')\nprint(\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd:\", df['\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd'].sum())\nprint(\"\u05e4\u05e1\u05d5\u05dc\u05d9\u05dd:\", df['\u05e4\u05e1\u05d5\u05dc\u05d9\u05dd'].sum())\noverall_votes_per_party = df.iloc[:,7:50].sum() # corrected from orig kernel, \n","3539ae09":"# count votes cast and compare to \"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd\" - should be same number\ndf[\"manual_sum_totalVotes\"] = df.iloc[:,7:].sum(axis=1)\nprint(df[\"manual_sum_totalVotes\"].head())\n\nprint(df[[\"manual_sum_totalVotes\",\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd\",\"\u05db\u05e9\u05e8\u05d9\u05dd\"]].head())\nprint((df[\"manual_sum_totalVotes\"]!=df[\"\u05db\u05e9\u05e8\u05d9\u05dd\"]).sum(axis=0)) # 0  : vote count is OK!\n\ndf.drop(\"manual_sum_totalVotes\",axis=1,inplace=True)","ccf0be41":"overall_votes_per_party","993f3913":"print(list(df.columns))","774b2376":"percantage_vote_per_pary = overall_votes_per_party\/df['\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd'].sum()\npercantage_vote_per_pary.sort_values(ascending=False).plot.bar(alpha=0.7,figsize=(16,6))","daefd335":"percantage_vote_per_pary = overall_votes_per_party\/df['\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd'].sum()\npercantage_vote_per_pary = percantage_vote_per_pary[percantage_vote_per_pary.values>block_percent]\npercantage_vote_per_pary.sort_values(ascending=False).plot.bar(alpha=0.7,figsize=(16,6))","9fbbbb5d":"df.head()","795715ce":"### total voting booths per district + normalize by population. \n### ideally, group also by voting year when including more years\ndf[\"total_voting_booths\"] = df.groupby([\"\u05e1\u05de\u05dc \u05d9\u05e9\u05d5\u05d1\"])[\"\u05de\u05e1\u05e4\u05e8 \u05e7\u05dc\u05e4\u05d9\"].transform(\"size\")\n\ndf[\"max_voting_booths\"] = df.groupby([\"\u05e1\u05de\u05dc \u05d9\u05e9\u05d5\u05d1\"])[\"\u05de\u05e1\u05e4\u05e8 \u05e7\u05dc\u05e4\u05d9\"].transform(\"max\")\n\ndf[\"booth_per_pop\"] = df[\"total_voting_booths\"].div(df[\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd\"])\n\ndf[\"booth_per_pop\"].describe()","58aa1c46":"## another feature: ratio between party with most votes cast and rest. could do as logsumexp  . Capture \"1 party town\" outliers. Subtract self? \ndf[\"max_party_vote\"] = df.iloc[0,7:50].max(axis=0)\ndf[\"max_party_ratio\"] = df[\"max_party_vote\"]\/df[\"\u05db\u05e9\u05e8\u05d9\u05dd\"]  # df.iloc[0,7:50].sum()\n\ndf.head()","1cc6fb44":"df.columns","53e8a544":"df.columns[3:50].drop(\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd\")","446e7242":"# percentage_cols = df[df.columns[3:50].drop(\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd\")]\n# for c in percentage_cols:\n#     df[c] = 100*df[c].div(df[\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd\"])","133e758e":"df[\"percent_invalid\"] = (df[\"\u05e4\u05e1\u05d5\u05dc\u05d9\u05dd\"]+5).div(df[\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd\"]+5)\ndf[\"max_party_as_percent_of_votes\"] = (df[\"max_party_vote\"]+5).div(df[\"\u05db\u05e9\u05e8\u05d9\u05dd\"]+5)","c8c523b2":"df.tail()","52b3ee92":"df_feat = pd.get_dummies(df.drop(['\u05e9\u05dd \u05d9\u05e9\u05d5\u05d1', '\u05e1\u05de\u05dc \u05d9\u05e9\u05d5\u05d1', '\u05de\u05e1\u05e4\u05e8 \u05e7\u05dc\u05e4\u05d9'],axis=1))  # drop the settlement from data for now - meaningless without additional demographic data\n# df_feat = pd.get_dummies(df.drop(['\u05e1\u05de\u05dc \u05d9\u05e9\u05d5\u05d1', '\u05de\u05e1\u05e4\u05e8 \u05e7\u05dc\u05e4\u05d9'],axis=1))  # keep the settlement from data for now - meaningless without additional demographic data\n\n\ndf_feat.tail(3)","ab0e28e1":"# ## try standard scaler\n# scl = StandardScaler()\n\n# df_feat = scl.fit_transform(df_feat)","88a4c9cc":"# model = IsolationForest().fit(df_feat.values)\nmodel = IsolationForest(n_estimators=140,max_samples=600,behaviour=\"new\").fit(df_feat)","bc59a4f6":"# preds = model.predict(df_feat)\npreds = model.decision_function(df_feat)","ea584eaa":"print(\"total predicted anomalies:\",preds.sum())","fb0d05ce":"sub = pd.read_csv(DATA_PATH + 'sample_sub.csv')\n# sub['poll'] = (preds == -1).astype(int) # ORIG\nsub['poll'] = preds # Probabilistic predictions for AUC\nsub.to_csv('submission.csv', index=False)","651bc8c3":"### Anomaly Detection\n\n* Quick 101 on isolation forests for anomaly\/fraud detection: https:\/\/www.kaggle.com\/danofer\/anomaly-detection-for-feature-engineering-v2\n","45dda600":"## some features","49834905":"* 50% of the votes going to a single party? Sounds about right for that instance.\n","30082161":"### Preprocessing","c4c668d0":"### Votes Distribution","11ad06aa":"## Starter kernel\n\n\n* V2 : removed normalization of variables by population\/voters. Either a bug or I don't know what - but it gave much much worse results, than keeping the raw count variables (Suspicious)\n\n* V5: Try with standard scaler \/ z-score normalization \\[NO Effect\\]\n* V6\/V7 : change isolation forest model settings + get probabilistic output (new skl behavior) : big boost\n* V8: As V7 , + restore standard sclaer + use more samples, trees for model , + 2 percentage features (`percent_invalid, max_party_as_percent_of_votes`) + correct types pointed out by [Itamar Mushkin](https:\/\/www.kaggle.com\/danofer\/israel-election-anomalies-starter\/output?scriptVersionId=20661991#627305)  LB : 0.79483\n\n* V9 : restore model settings to V7's . Keep other changes\n\n* V10: disable one of the new percentage features. Go back to V8 model settings\n\n* V11: Try smoothing the 2 percentage features (+3) [LB: 0.79247]\n* V12: disable the percentage features again (for now)\n\n* V13 - readded percentage features (@) with smoothing. Set isolation forest model settings to lower\n\n* V14 : get count of booths instead of max number (and also get max number) , modify count of max voted party's ratio. \n","704a2429":"#### normalize to percentages \n* Divide by total voters\n* WARNING! This (and prior) code is sensitive to the column indices - if you want to add more years, you will need to fix the code. (The columns\/party names change over years as do the # of parties)\n\n* Try for only some columns + with smoothing","023aa1a1":"### Votes Distribution above block percent"}}