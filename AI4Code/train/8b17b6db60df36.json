{"cell_type":{"cbf5cf51":"code","fa2a2d08":"code","f1497758":"code","4b10d54f":"code","a0661b96":"code","279fea5f":"code","0de8fa2c":"code","5d4757b8":"code","a418b8f2":"code","cf319ee0":"code","2180d287":"code","76b7ca81":"code","aa404238":"code","264700b1":"code","730e53d7":"code","8dbc03e7":"code","fbe2b067":"code","81083871":"code","6715f277":"code","70c3a68e":"code","5b179c79":"code","d1385e85":"code","5f6cec5a":"code","a86746bd":"code","a07c09ef":"code","7d846a03":"markdown","a631df9c":"markdown","9c38acc3":"markdown","ec6e84aa":"markdown","1b72d98b":"markdown","6073cb81":"markdown","e0249bbe":"markdown","fc6b9fd3":"markdown","864dc98e":"markdown","5b067fa7":"markdown","17c85b5f":"markdown","26d52c15":"markdown","c4de1fb8":"markdown","84424423":"markdown","94eca9f4":"markdown","261b9e77":"markdown","785c0ec7":"markdown"},"source":{"cbf5cf51":"import datetime as dt\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\n\nimport os\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport cv2\nfrom scipy.stats import uniform\n\nfrom tqdm import tqdm\nfrom glob import glob\n\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Masking\nfrom keras.utils import np_utils, to_categorical\n\n\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","fa2a2d08":"## import Keras and its module for image processing and model building\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization","f1497758":"#copying the pretrained models to the cache directory\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n\n#copy the Xception models\n!cp ..\/input\/keras-pretrained-models\/xception* ~\/.keras\/models\/\n#show\n!ls ~\/.keras\/models","4b10d54f":"img = load_img('..\/input\/sheep-goat\/sheep_goat\/goat\/goat28.jpg')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array \nprint('image shape: ', x.shape)\n\nprint('Goat Image')\nplt.imshow(img)\nplt.show()\n\n\nimg = load_img('..\/input\/sheep-goat\/sheep_goat\/sheep\/sheep3.jpg')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array \nprint('Sheep Image')\nplt.imshow(img)\nplt.show()\n\n","a0661b96":"\ndir_kaggle ='..\/input\/sheep-goat\/'\ndata_kaggle ='..\/input\/sheep-goat\/sheep_goat\/'\ngoat  ='..\/input\/sheep-goat\/sheep_goat\/goat\/'\nsheep ='..\/input\/sheep-goat\/sheep_goat\/sheep\/'\n\n\nclass_data= ['goat','sheep']\nlen_class_data = len(class_data)","279fea5f":"image_count = {}\ntrain_data = []\n\nfor i , class_data in tqdm(enumerate(class_data)):\n    class_folder = os.path.join(data_kaggle,class_data)\n    label = class_data\n    image_count[class_data] = []\n    \n    for path in os.listdir(os.path.join(class_folder)):\n        image_count[class_data].append(class_data)\n        train_data.append(['{}\/{}'.format(class_data, path), i, class_data])","0de8fa2c":"#show image count\nfor key, value in image_count.items():\n    print('{0} -> {1}'.format(key, len(value)))","5d4757b8":"#create a dataframe\ndf = pd.DataFrame(train_data, columns=['file', 'id', 'label'])\ndf.shape\ndf.head()","a418b8f2":"cnt_pro = df['label'].value_counts()\nplt.figure(figsize=(6,4))\nsns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('label', fontsize=12)\nplt.xticks(rotation=80)\nplt.show();","cf319ee0":"#masking function\ndef create_mask_for_plant(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    lower_hsv = np.array([0,0,250])\n    upper_hsv = np.array([250,255,255])\n    \n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\n#image segmentation function\ndef segment_image(image):\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output\/255\n\n#sharpen the image\ndef sharpen_image(image):\n    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n    return image_sharp\n\n# function to get an image\ndef read_img(filepath, size):\n    img = image.load_img(os.path.join(data_kaggle, filepath), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img)\n    return img","2180d287":"nb_rows = 3\nnb_cols = 5\nfig, axs = plt.subplots(nb_rows, nb_cols, figsize=(10, 5));\nplt.suptitle('SAMPLE IMAGES');\nfor i in range(0, nb_rows):\n    for j in range(0, nb_cols):\n        axs[i, j].xaxis.set_ticklabels([]);\n        axs[i, j].yaxis.set_ticklabels([]);\n        axs[i, j].imshow((read_img(df['file'][np.random.randint(100)], (255,255)))\/255.);\nplt.show();","76b7ca81":"#get an image\nimg = read_img(df['file'][12],(255,255))\n#mask\nimage_mask = create_mask_for_plant(img)\n#segmentation\nimage_segmented = segment_image(img)\n#sharpen the image\nimage_sharpen = sharpen_image(image_segmented)\n\nfig, ax = plt.subplots(1, 4, figsize=(10, 5));\nplt.suptitle('SAMPLE PROCESSED IMAGE', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIGINAL', fontsize=12)\nax[1].set_title('MASK', fontsize=12)\nax[2].set_title('SEGMENTED', fontsize=12)\nax[3].set_title('SHARPEN', fontsize=12)\n\n\nax[0].imshow(img\/255);\nax[1].imshow(image_mask);\nax[2].imshow(image_segmented);\nax[3].imshow(image_sharpen);\n\n","aa404238":"INPUT_SIZE=255\n\n##preprocess the input\nX_train = np.zeros((len(df), INPUT_SIZE, INPUT_SIZE, df.shape[1]), dtype='float')\nfor i, file in tqdm(enumerate(df['file'])):\n    #read image\n    img = read_img(file,(INPUT_SIZE,INPUT_SIZE))\n    #masking and segmentation\n    image_segmented = segment_image(img)\n    #sharpen\n    image_sharpen = sharpen_image(image_segmented)\n    x = xception.preprocess_input(np.expand_dims(image_sharpen.copy(), axis=0))\n    X_train[i] = x","264700b1":"print('Train Image Shape: ', X_train.shape)\nprint('Train Image Size: ', X_train.size)","730e53d7":"y = df['id']\ntrain_x, train_val, y_train, y_val = train_test_split(X_train, y, test_size=0.1, random_state=101)","8dbc03e7":"print('GOAT IMAGES ON TRAINING DATA: ',y_train[y_train==0].shape[0])\nprint('SHEEP IMAGES ON TRAINING DATA: ',y_train[y_train==1].shape[0])","fbe2b067":"##get the features\nxception_bf = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\nbf_train_x = xception_bf.predict(train_x, batch_size=32, verbose=1)\nbf_train_val = xception_bf.predict(train_val, batch_size=32, verbose=1)","81083871":"#print shape of feature and size\nprint('Train Shape: ', bf_train_x.shape)\nprint('Train Size: ', bf_train_x.size)\n\nprint('Validation Shape: ', bf_train_val.shape)\nprint('Validation Size: ', bf_train_val.size)","6715f277":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Input\nfrom keras.optimizers import SGD, Adam\nfrom keras.utils import np_utils\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n#keras Sequential model\nmodel = Sequential()\nmodel.add(Dense(units = 75 , activation = 'relu', input_dim=bf_train_x.shape[1]))\nmodel.add(Dense(units = 2, activation = 'softmax'))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.15))\nmodel.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","70c3a68e":"#train the model \nhistory = model.fit(bf_train_x, y_train, epochs=1000, batch_size=32);","5b179c79":"from keras.utils import plot_model\nplot_model(model, to_file='model.png')","d1385e85":"plt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nplt.savefig('model_accuracy.png')\n# summarize history for loss\nplt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nplt.savefig('model_loss.png')","5f6cec5a":"#predict the validation data\npredictions = model.predict_classes(bf_train_val)","a86746bd":"confusion_mat = confusion_matrix(y_val, predictions)\n\nplt.figure(figsize=(4,4))\nsns.heatmap(confusion_mat, square=True, annot=True,\n            yticklabels=['Goat', 'Sheep'],\n            xticklabels=['Goat', 'Sheep']);\nplt.title('CONFUSION MATRIX');\nplt.xlabel('Y_TRUE');\nplt.ylabel(\"PREDICTIONS\");","a07c09ef":"print(classification_report(y_val, predictions))","7d846a03":"# Visualize Model\n","a631df9c":"# Goat and Sheep","9c38acc3":"#### CONFUSION MATRIX","ec6e84aa":"Separating the sheep from the goats\n\nTaxonomy\nWhile sheep and goats have many similarities, their taxonomy (scientific clasification) eventually diverges. Each is a distinct species and genus. Sheep (Ovis aries) have 54 chromosomes, while goats (Capra aegagrus hircus) have 60. While sheep and goats will occasionally mate, fertile sheep-goat hybrids are rare. Hybrids made in the laboratory are called chimeras.\n\n\nLook at their tails\nThe easist way to tell the difference between a sheep and goat is to look at their tails. A goat's tail goes up (unless it is sick, frightened, or in distress). Sheep tails hang down and are often docked (shortened) for health and sanitary reasons.\n\n\nForaging behavior\nA big difference between sheep and goats is their foraging behavior and diet selection. Goats are natural browsers, preferring to eat leaves, twigs, vines, and shrubs. They are very agile and will stand on their hind legs to reach vegetation. Goats like to eat the tops of plants. Sheep are grazers, preferring to eat short, tender grasses and clover. Their dietary preference is forbs (broadleaf weeds) and they like to graze close to the soil surface. Goats require and select a more nutritious diet.\n\n\nBehavior\nSheep and goats usually exhibit different behavior. Goats are naturally curious and independent, while sheep tend to be more distant and aloof. Sheep have a stronger flocking instinct and become very agitated if they are separated from the rest of the flock. It is easier to keep sheep inside a fence than goats. Sheep are easier to handle than goats.\n\nGoats will seek shelter more readily than sheep. Neither species likes to get its feet wet and both prefer upland grazing to lowland. In a fight, a ram will back up and charge to butt heads. A goat will rear up on his hind legs and come down forceably to butt heads. During controntation, such fighting behavior favors the ram.\n\n\nPhysical differences\nSheep and goats have numerous physical differences. Most goats have hair coats that do not require shearing or combing. Most sheep grow woolly coats that need to be sheared at least annually. Lamb tails are usually docked (shortened) whereas goat tails are not.\n\nSheep have an upper lip that is divided by a distinct philtrum (groove). The goat does not.\nMale goats have glands beneath their tail. Sheep have face or tear glands beneath their eyes and foot or scent glands between the toes. Male goats develop a distinct odor as they grow in sexual maturity. The odor is very strong during the rut (mating season). Sexually mature rams have much less of an odor.\n\n\nHorns\nMost goats are naturally horned. Some goats have beards. Many breeds of sheep are naturally hornless (polled). Some sheep have manes. Goat horns are more narrow, upright, and less curved than sheep horns. Sheep tend to curl their horns in loops on the sides of their heads.\n\nSource information :http:\/\/www.sheep101.info\/sheepandgoats.html","1b72d98b":"### SHOW SAMPLE PROCESSED IMAGE\n","6073cb81":"The plot_model() function in Keras will create a plot of your network[[2](https:\/\/machinelearningmastery.com\/visualize-deep-learning-neural-network-model-keras\/)] . \nThis function takes a few useful arguments:\n\n* model: (required) The model that you wish to plot.\n* to_file: (required) The name of the file to which to save the plot.\n* show_shapes: (optional, defaults to False) Whether or not to show the output shapes of each layer.\n* show_layer_names: (optional, defaults to True) Whether or not to show the name for each layer.","e0249bbe":"#### LOSS AND ACCURACY","fc6b9fd3":"This notebook, tried to predict the goat\/sheep based on image","864dc98e":"### SHOW SAMPLE IMAGES","5b067fa7":"Data for training and testing\nTo select a set of training data that will be input in the Machine Learning algorithm, to ensure that the classification algorithm training can be generalized well to new data. For this study using a sample size of 10%, assumed it ideal ratio between training and testing","17c85b5f":"#### CLASSIFICATION REPORT","26d52c15":"LOSS is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater. The goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples. While Accuracy refers to how close a measurement is to the true value of what is being measured.","c4de1fb8":"###  FEATURES EXTRACTION","84424423":"### IMAGE PREPROCESSING","94eca9f4":"![https:\/\/globalanimalpartnership.org\/wp-content\/uploads\/2017\/06\/dr9vw2yzvfugmblrb48g.jpg](https:\/\/globalanimalpartnership.org\/wp-content\/uploads\/2017\/06\/dr9vw2yzvfugmblrb48g.jpg)","261b9e77":"### DEEP LEARNING MODEL","785c0ec7":"#### SPLIT THE DATA"}}