{"cell_type":{"1baf9c68":"code","f1c92967":"code","695f46ce":"code","e4849c64":"code","43f574a5":"code","eeab0326":"code","21cbe237":"code","fbb11c58":"code","c19c1cd3":"code","7bd2e60d":"code","86b83a1b":"code","838c3f0c":"code","e7948b10":"code","040d0ab0":"code","caae767b":"code","a8cd41d9":"code","b274a7c9":"code","42f81702":"code","9fe325f4":"code","595ed9ed":"code","e9bc4064":"code","8ba62190":"code","52ca1acf":"code","6e3c8f81":"code","f3ea2016":"code","fa6e7087":"code","4cd831fc":"code","b4d41686":"code","290c76c4":"code","44f1c4c5":"code","e592ba6a":"code","e5203857":"code","d3b1141e":"code","f763c8c6":"code","a51ed2f2":"code","d11e40c7":"code","2661975b":"code","32f8ae9d":"code","f815fbcc":"code","7cceceeb":"code","725260b3":"code","7e9274fd":"code","121ee5d8":"code","ad47f2cd":"code","3682df98":"code","372d3d11":"code","b25e8221":"code","12ca57c3":"code","61fcf7fd":"code","093466cb":"code","8e700130":"code","64edbba4":"code","af8470c6":"code","86c9aab9":"code","a6b4c5a6":"code","a45439e5":"markdown","1e1bdf4c":"markdown","419cb11f":"markdown","8e60ffff":"markdown","2e2f8b11":"markdown","cca97f44":"markdown","5896b2f3":"markdown","a5f0afea":"markdown","ecda4c09":"markdown","6011783f":"markdown","de212f1b":"markdown","506b9f9d":"markdown","608be2cc":"markdown","7e0e7b0d":"markdown","8acb193c":"markdown","2b806144":"markdown","42efb06a":"markdown","407901d3":"markdown","6eb9acf2":"markdown","33d7a57e":"markdown","968d8cea":"markdown","ab75cc48":"markdown","5176839c":"markdown","d4f35a54":"markdown","f6c6d32b":"markdown","91e829e5":"markdown","a08a3b51":"markdown","8807b140":"markdown","4bd14f8e":"markdown","3ee2a916":"markdown","f01e5571":"markdown","48bfe2c7":"markdown","08b2a68e":"markdown","8cf93f1f":"markdown"},"source":{"1baf9c68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1c92967":"# Importing Libraries\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nsns.set_style('darkgrid')\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (9, 5)\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'","695f46ce":"df = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","e4849c64":"df.columns","43f574a5":"df.age.value_counts().shape\n# there are total of 41 different\/unique ages","eeab0326":"# unique values per column\nunique_value_dict = {}\n\nfor col_name in list(df.columns):\n    unique_value_dict[col_name] = df[col_name].value_counts().shape[0]\n\nunique_value_df = pd.DataFrame(unique_value_dict, index = [\"Unique Counts\"]).transpose()\nunique_value_df","21cbe237":"# Checking how data values are\ndf.head(10)","fbb11c58":"print('Shape of the dataframe is: ' ,df.shape)","c19c1cd3":"# info about all the columns\ndf.info()","7bd2e60d":"#checking summary of dataset\ndf.describe(include='all')","86b83a1b":"df.isnull().sum()\n# we can clearly see there are no missing values","838c3f0c":"# visually checking for the presence of missing values\nimport missingno as msno\nmsno.bar(df)\n\n# each bar is full, so that implies no missing values","e7948b10":"# Since all the columns are of numeric type, we have to manually segregate the ones which are categorical\ncat_cols = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']\nunique_value_df.loc[cat_cols]","040d0ab0":"# visualizing the univariate analysis of categorical columns\n\nfig, axes = plt.subplots(4,2, figsize=(18,18))\n\ncat_cols = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']\ncat_names = ['SEX', 'CP', 'FBS', 'REST-ECG', 'EXNG', 'SLOPE', 'CAA', 'THALL']\ncat_colors = ['Set3', 'Set1', 'Set2', 'Blues_r', 'Oranges_r', 'autumn_r', 'icefire_r', 'summer']\nidx = 0\n\nfor row in range(4):\n    for col in range(2):\n        \n        axes[row, col].set_title(cat_names[idx])\n        \n        sns.countplot(df[f'{cat_cols[idx]}'],\n                     palette = cat_colors[idx],\n                     edgecolor = sns.color_palette(cat_colors[idx], 4),\n                     linewidth = 1, \n                     ax = axes[row,col])\n        \n        idx += 1\n        \n\nplt.tight_layout(pad=3);","caae767b":"continuous_cols = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nunique_value_df.loc[continuous_cols]","a8cd41d9":"fig, axes = plt.subplots(2,3, figsize=(15,12))\n\n#use the axis for plotting\ncontinuous_cols = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\ncontinuous_names = ['AGE', 'TRTBPS', 'CHOL', 'THALACHH', 'OLDPEAK']\ncontinuous_colors = ['Greens', 'Blues_r', 'viridis', 'Blues_r', 'RdPu']\n\nidx = 0\nfor row in range(2):\n    for col in range(3):\n        axes[row, col].set_title(continuous_names[idx])\n        sns.boxenplot(y = df[continuous_cols[idx]],\n                        palette = continuous_colors[idx], \n                        color = continuous_colors[idx],\n                       linewidth=3,\n                       ax=axes[row,col]);\n        idx += 1\n        if idx == 5: # cause output is outside loop\n            break;\n\n        \n#use the axis for plotting\naxes[1, 2].set_title('(Plot.2.6)OUTPUT')\nsns.countplot(df.output,\n             palette = 'vlag_r',\n             saturation=0.50,\n             ax=axes[1,2]);\n\nplt.tight_layout(pad=3);","b274a7c9":"fig, axes = plt.subplots(2,2, figsize=(10,8))\n\n\ncols = ['age', 'trtbps', 'chol', 'thalachh']\nnames = ['(Plot.3.1)AGE and OUTPUT', '(Plot.3.2) BLOOD PRESSURE and OUTPUT', '(Plot.3.3) CHOLESTROL and OUTPUT', \n             '(Plot.3.4) HEART RATE and OUTPUT']\ncolors = ['Set1', 'Set1', 'Set2', 'Blues_r']\nidx = 0\n\nfor row in range(2):\n    for col in range(2):\n        \n        axes[row, col].set_title(names[idx])\n        \n        \n        sns.kdeplot(data = df,\n                    x = cols[idx],\n                    hue = 'output',\n                    palette = colors[idx],\n                    fill = True,\n                    ax = axes[row,col])\n        \n        idx += 1\n\nplt.tight_layout(pad=3);","42f81702":"fig, axes = plt.subplots(2,2, figsize=(10,8))\n\n\ncols = ['cp', 'thall', 'restecg', 'exng']\nnames = [ '(Plot.3.5) CHEST PAIN and OUTPUT', '(Plot.3.6) THALL and OUTPUT',\n             '(Plot.3.7) RESTECG and OUTPUT', '(Plot.3.6) EXNG and OUTPUT']\ncolors = ['Oranges_r', 'autumn_r', 'icefire_r', 'summer']\nidx = 0\n\nfor row in range(2):\n    for col in range(2):\n        \n        axes[row, col].set_title(names[idx])\n        \n        sns.countplot(data = df,\n                      x = cols[idx],\n                      hue = 'output',\n                      palette = colors[idx],\n                      edgecolor = sns.color_palette(colors[idx], 4),\n                      linewidth = 1, \n                      ax = axes[row,col])\n        \n        idx += 1\n        \nplt.tight_layout(pad=3);","9fe325f4":"plt.figure(figsize = (12,10))\nplt.title('(Plot.4.1) Correlation between variables')\nsns.heatmap(df.corr(), fmt='.1f', annot=True, cmap= \"bone_r\");","595ed9ed":"print('(Plot.5.1)')\nsns.pairplot(df, hue='output', diag_kind = \"kde\", kind = \"scatter\", palette = \"husl\")","e9bc4064":"# checking on columns\ndisplay(df.columns)\nprint()\ndisplay(f'total number of columns present: {len(df.columns)}')","8ba62190":"# splitting columns into dependent and independent \nX = df.iloc[:, :-1] # all columns except last\ny = df.iloc[:, -1]","52ca1acf":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\n# using SelectKBest to select top best featues\nselect_k_best = SelectKBest(score_func = chi2, k=9)\ntop_9_features = select_k_best.fit(X,y)\n\n# top 9 featuers\nbest_feature_score = pd.DataFrame({'Scores':top_9_features.scores_}, index = X.columns)\nbest_feature_score.sort_values(by=['Scores'], ascending=False)","6e3c8f81":"# plotting 9 best features based on SelectKBest using chi2\nbest_feature_score.nlargest(9, 'Scores').plot(kind='barh')","f3ea2016":"from sklearn.ensemble import ExtraTreesClassifier\n\nET_model = ExtraTreesClassifier()\nET_model.fit(X,y)\n\n# converting feature importance scores to dataframe\nET_feature_importance = pd.DataFrame({'Feature_Importance': ET_model.feature_importances_}, index = X.columns)\nET_feature_importance.sort_values(by=['Feature_Importance'], ascending=False)","fa6e7087":"ET_feature_importance.nlargest(9, 'Feature_Importance').plot(kind='barh')","4cd831fc":"df_feature_selected = df.copy()\ndf_feature_selected.drop(['sex', 'chol', 'restecg', 'fbs'], axis=1, inplace=True)\ndf_feature_selected.head()","b4d41686":"df.columns","290c76c4":"df_feature_selected.columns","44f1c4c5":"df_feature_selected.columns = ['age', 'chest_pain_type', 'resting_blood_pressure', 'max_heart_rate_achieved', 'exercise_induced_angina',\n                              'st_depression', 'st_slope_type', 'no_of_major_vessels', 'thallasemia_type', 'output']","e592ba6a":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\n\n# feature and train-test split\nX = df_feature_selected.iloc[:,:-1]\ny = df_feature_selected.iloc[:,-1]\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\n# classification\nclassifier_gini = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n                             min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, \n                             random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, \n                             ccp_alpha=0.0)\nclassifier_gini = classifier_gini.fit(x_train, y_train)\n\ny_pred = classifier_gini.predict(x_test)\nprint(metrics.classification_report(y_test, y_pred))","e5203857":"!pip install pydotplus","d3b1141e":"# visualizing tree classification using \"gini\"\n\nfrom sklearn.tree import export_graphviz\n# from sklearn.externals.six import StringIO\nfrom six import StringIO\nfrom IPython.display import Image\nimport pydotplus\n\n## About the above libraries\n# export_graphviz: export a decision tree in DOT (DOT is a graph description language. DOT graphs are typically files with the filename extension gv or dot; [https:\/\/graphviz.org\/doc\/info\/lang.html]) format, which is a GraphViz (open source graph visualization software) representation of decision tree.\n# pydotplus: provides a Python Interface to Graphviz's Dot language.","f763c8c6":"string_io = StringIO()\n\nexport_graphviz(classifier_gini, out_file = string_io,\n               filled = True, rounded = True,\n               special_characters = True, feature_names = X.columns,\n               class_names = ['0', '1'])\n\ngraph = pydotplus.graph_from_dot_data(string_io.getvalue())\n\n# graph.write_png('name_.png')\nImage(graph.create_png())","a51ed2f2":"# classification using Entropy\nclassifier_entropy = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=4, min_samples_split=2, \n                             min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, \n                             random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, \n                             ccp_alpha=0.0)\nclassifier_entropy = classifier_entropy.fit(x_train, y_train)\n\ny_pred = classifier_entropy.predict(x_test)\nprint(metrics.classification_report(y_test, y_pred))","d11e40c7":"string_io = StringIO()\n\nexport_graphviz(classifier_entropy, out_file = string_io,\n               filled = True, rounded = True,\n               special_characters = True, feature_names = X.columns,\n               class_names = ['0', '1'])\n\ngraph = pydotplus.graph_from_dot_data(string_io.getvalue())\n\n# graph.write_png('name_.png')\nImage(graph.create_png())","2661975b":"one_hot_data = df_feature_selected.copy()\none_hot_data.head()","32f8ae9d":"# 1. CP: type of chest pain \none_hot_data.loc[one_hot_data['chest_pain_type'] == 0, 'chest_pain_type'] = 'typical angina'\none_hot_data.loc[one_hot_data['chest_pain_type'] == 1, 'chest_pain_type'] = 'atypical angina'\none_hot_data.loc[one_hot_data['chest_pain_type'] == 2, 'chest_pain_type'] = 'non-anginal pain'\none_hot_data.loc[one_hot_data['chest_pain_type'] == 3, 'chest_pain_type'] = 'asymptomatic'","f815fbcc":"# 2. exng: enxercise induced angina\none_hot_data.loc[one_hot_data['exercise_induced_angina'] == 1, 'exercise_induced_angina'] = 'yes'\none_hot_data.loc[one_hot_data['exercise_induced_angina'] == 0, 'exercise_induced_angina'] = 'no'","7cceceeb":"# 3. slp: slope of peak exercise ST segment\none_hot_data.loc[one_hot_data['st_slope_type'] == 0, 'st_slope_type'] = 'upsloping'\none_hot_data.loc[one_hot_data['st_slope_type'] == 1, 'st_slope_type'] = 'flat'\none_hot_data.loc[one_hot_data['st_slope_type'] == 2, 'st_slope_type'] = 'downsloping'","725260b3":"one_hot_data['thallasemia_type'].value_counts()","7e9274fd":"# 4.  thall: thalassemia blood disorder\n#thal - thalassemia_type\none_hot_data.loc[one_hot_data['thallasemia_type'] == 0, 'thallasemia_type'] = 'None'\none_hot_data.loc[one_hot_data['thallasemia_type'] == 1, 'thallasemia_type'] = 'fixed defect'\none_hot_data.loc[one_hot_data['thallasemia_type'] == 2, 'thallasemia_type'] = 'normal blood flow'\none_hot_data.loc[one_hot_data['thallasemia_type'] == 3, 'thallasemia_type'] = 'reversible defect'","121ee5d8":"one_hot_data.head()","ad47f2cd":"X = one_hot_data.iloc[:, :-1]\ny = one_hot_data.iloc[:, -1]\n\n# splitting into train test split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=1, stratify=y)","3682df98":"x_test.columns","372d3d11":"# for col in encoding_cols:\n#     print(X[col].value_counts())","b25e8221":"encoding_cols = ['chest_pain_type', 'exercise_induced_angina', 'st_slope_type', 'thallasemia_type']\n\nfrom sklearn.preprocessing import OneHotEncoder\n\noh_encode = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n\nx_train_encoded = pd.DataFrame(oh_encode.fit_transform(x_train[encoding_cols]), index = x_train.index)\nx_test_encoded = pd.DataFrame(oh_encode.transform(x_test[encoding_cols]), index = x_test.index)\n\nx_train_num = x_train.drop(['chest_pain_type', 'exercise_induced_angina', 'st_slope_type', 'thallasemia_type'], axis=1)\nx_test_num = x_test.drop(['chest_pain_type', 'exercise_induced_angina', 'st_slope_type', 'thallasemia_type'], axis=1)\n\nx_train_en = pd.concat([x_train_num, x_train_encoded], axis=1)\nx_test_en = pd.concat([x_test_num, x_test_encoded], axis=1)","12ca57c3":"# for col in encoding_cols:\n#     print(X[col].value_counts())","61fcf7fd":"x_train_en.head()","093466cb":"from sklearn import preprocessing\n\ncols = x_train_en.columns\nidx_train = x_train_en.index\nidx_test = x_test_en.index\n\nscaler = preprocessing.MinMaxScaler()\nx_scaled = scaler.fit_transform(x_train_en)\nx_train = pd.DataFrame(x_scaled, columns = cols, index = idx_train)\n\nx_scaled = scaler.transform(x_test_en)\nx_test = pd.DataFrame(x_scaled, columns = cols, index = idx_test)\n","8e700130":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV \n\nmodel = LogisticRegression(penalty = 'l2')\nparam = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\nclassifier = GridSearchCV(estimator = model, param_grid = param, n_jobs=-1)\n\nclassifier.fit(x_train, y_train)\n\n# printing result\nprint(classifier.best_estimator_)\nprint(\"***********************************************************************************************\")\nprint(classifier.best_score_)\nprint(\"***********************************************************************************************\")\nprint(classifier.best_params_)\nprint(\"***********************************************************************************************\")\n","64edbba4":"from sklearn.metrics import classification_report\n\nfinal_model = LogisticRegression(solver='liblinear')\nfinal_model.fit(x_train, y_train)\n\ny_pred = final_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","af8470c6":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_test,y_pred))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot=True)","86c9aab9":"import sklearn\nsklearn.metrics.roc_auc_score(y_test,y_pred)","a6b4c5a6":"from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr)\nplt.title('ROC curve for Heart disease Logistic R classifier')\nplt.xlabel('False positive Rate')\nplt.ylabel('True positive Rate')\nplt.grid(True)","a45439e5":"### EDA - Exploratory Analysis and Visualization","1e1bdf4c":"#### Observations:-\n        - SEX: The data has more Males compared to female.\n        - CP: Most of the patients are suffering with typical anginal chest pain (cp=0) i.e., one or more of the heart's arteries is narrowed or blocked.\n        - FBS: Most people have their fasting blood sugar lesser than 120mg\/dl.\n        - REST-ECG: Most people have either normal or showing probable or definite left ventricular hypertrophy by Estes\u2019 criteria.\n        - EXNG: Less people are suffering with exercise induced angina.\n        - CAA: Most people have some issue with 0th major vessel. \n        - THALL: blood disorder caused by 'normal blood flow' is highest, followed by 'reversible defect (a blood flow is observed but it is not normal)","419cb11f":"#### Model Evaluation","8e60ffff":"#### Conclusions:\n    There isn't any strong correlation between any variables, but few variable is showing upto 0.6 correlation as positive and negative association. So, they can be considered as affecting the target variable than any other variables.\n    * output with [caa, oldpeak, exng, thalachh, cp]: [+\/-] 0.4\n    * age with max heart rate (thalachh) : -0.4\n    * cp with exng: -0.4 \n    * thalachh with exng: -0.4 && with slp: 0.4 \n    * oldpeak with slp: -0.6","2e2f8b11":"### Model Building : Decision Tree Classifier\n* Using DecisionTreeClassifier\n    * criterion='gini'\n    * criterion='entropy'","cca97f44":"##### Observation: Decision Tree with criterion='gini' performed better with Label encoding","5896b2f3":"#### 3. Bivariate Analysis\n\nIn this block, we will be analyzing variables to `output variable`\n * age and output\n * bloop pressure and output\n * cholestrol and output\n * heart rate and output\n * chest pain and output\n * thall and output\n * electrocardiograph and output\n * angina and output","a5f0afea":"* The dataset contain a total of 14 columns, with abbreviations in their column names.","ecda4c09":"### Data and DataFrame","6011783f":"#### Observations:\n        - Althought most of the patients are above 20, but there is no significant relationship between age and heart attack. **So, the intuition of older age to heart attack is rejected**\n        - Blood pressure and cholestrol doesn't contribute much info for deciding whether there is some heart disease or not.\n        - thalachh: Patients with higher heart rate are more prone to heart diseases\n        - cp: Patients with non-anginal chest pain are more prone to heart diseases\n        - thall: It seems 'normal blood flow' patients are more prone to heart diseases\n        - Patients with abnormal ST-T electrocardiographic wave are more prone.\n        - exng: Patients who does not have exercise induced angina are more prone to heart diseases.","de212f1b":"#### Feature Scaling\n* using min-max scaler","506b9f9d":"### Missing Values","608be2cc":"#### 2. Univariate Analysis of Continuous and Target Variables","7e0e7b0d":"Observations: Four least important features as per ExtraTreesClassifier are:\n* chol - Cholestrol of a patient\n* sex - male\/female\n* restecg - esting electrocardiographic results\n* fbs - person\u2019s fasting blood sugar","8acb193c":"### Heart Attack Analysis using Python- A Case Study\n\nWhen a heart attack occurs, the heart muscle that has lost blood supply begins to suffer injury. The amount of damage to the heart muscle depends on the size of the area supplied by the blocked artery and the time between injury and treatment. Heart muscle damaged by a heart attack heals by forming scar tissue.","2b806144":"### Data Pre-processing\n* changing abbreviated column names to descriptive column names","42efb06a":"#### Model Building","407901d3":"2. #### Use of ExtraTreesClassifier to score fearures","6eb9acf2":"Observations: Four least important features as per chi2 test are:\n* sex - male\/female\n* thall - a blood disorder\n* restecg - esting electrocardiographic results\n* fbs - person\u2019s fasting blood sugar","33d7a57e":"#### 5. Multivariate Analysis","968d8cea":"### Column Details","ab75cc48":"### Model Building using Hyper parameter tuning and model evaluation","5176839c":"### Feature Selection & Feature Importance","d4f35a54":"#### [Columns Description](https:\/\/towardsdatascience.com\/heart-disease-uci-diagnosis-prediction-b1943ee835a7):\n\n1. `'age'`= Age of the person (in years)\n2. `'sex'` =  Gender of the person (1=Male ; 0=Female)\n3. `'cp'` = Chest Pain type\n      * Value 0: typical angina\n      * Value 1: atypical angina\n      * Value 2: non-anginal pain\n      * Value 3: asymptomatic\n4. `'trtbps'` = The person\u2019s resting blood pressure (mm Hg on admission to the hospital)\n5. `'chol'` = The person\u2019s cholesterol measurement in mg\/dl\n6. `'fbs'` = The person\u2019s fasting blood sugar (> 120 mg\/dl, 1 = true; 0 = false)\n7. `'restecg'` = resting electrocardiographic results\n      * Value 0: showing probable or definite left ventricular hypertrophy by Estes\u2019 criteria\n      * Value 1: normal\n      * Value 2: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n8. `'thalachh'` = The person\u2019s maximum heart rate achieved\n9. `'exng'` = exercise induced angina (1 = yes; 0 = no)\n10. `'oldpeak'` = ST depression induced by exercise relative to rest (\u2018ST\u2019 relates to positions on the ECG plot. See more here)\n11. `'slp'` = The slope of the peak exercise ST segment\n     * Value 0: upsloping\n     * Value 1: flat\n     * Value 2: downsloping\n12. `'caa'` = number of major vessels (there are total of 5: the superior and inferior vena cava, the pulmonary artery, the pulmonary vein, and the aorta.)\n13. `'thall'` = A blood disorder called thalassemia \n    * Value 0: NULL (dropped from the dataset previously\n    * Value 1: fixed defect (no blood flow in some part of the heart)\n    * Value 2: normal blood flow\n    * Value 3: reversible defect (a blood flow is observed but it is not normal)\n    \n14. `'output'` = Target variable OR diagnosis of heart disease (angiographic disease status)\n     * Value 0: < 50% diameter narrowing\n     * Value 1: > 50% diameter narrowing","f6c6d32b":"#### Observations:\n        - AGE: Most patient are between the age (48-61)\n        - TRTBPS: Most patient have their blood pressure between (120-140)\n        - CHOL: Most patient have their cholestrol level between (220-260)\n        - THALACHH: Most patient have their heart rate between (135-165)","91e829e5":"### EDA - Inferences:\n\nSo, after concluding we may say that factors that don't affect Heart attack much are:\n * age\n * sex\n * blood pressure\n * cholestrol\n \nAnd factors that do affect to Heart Attack are:\n * chest pain(non-anginal)\n * fasting blood sugar(when more than 120 mg\/dl)\n * electrocardiograph (with abnormal ST-T wave)\n * high heart rate\n * angina induced by exercise (not)\n * old peak\n * downsloping peak exercise ST segement\n * number of major vessels \n * thall rate","a08a3b51":"1. #### Use of chi-squared (chi2) stats test for scoring k-best fearures","8807b140":"#### 1. Univariate Analysis of Categorical Variables","4bd14f8e":"#### Final Feature Selection Inference:\nAs per the observations from our EDA, chi2 test and ExtraTreesClassifier, features like \n* sex, \n* chol, \n* restecg (esting electrocardiographic results)\n* fbs (person\u2019s fasting blood sugar)\n\nare found to be least important atleast in 2 out of 3 observations.\n**Thus dropping this 4 columns**","3ee2a916":"### Data Preprocessing (part-2) \n* One-hot encoding of categorical variables\n* Min-Max Scaler","f01e5571":"#### assigning categorical values to categorical columns","48bfe2c7":"\n####  Final Observations:\n\n**Univariate Analysis**\n1. The dataset consists of more the number of **male** than **female**.\n2. There are outliers in almost every continous variables. \n\n**Bivariate Analysis**\n\n3. There is no strong relationship between **age** and Heart Disease.\n4. *Blood pressure* and *cholestrol* doesn't have much to contribute in Heart Disease. \n5. People with *higher heart rate* is more prone to Heart Disease. \n6. People with *non-anginal chest pain* i.e. cp=2 are more prone to Heart Disease\n7. People with *thall blood disorder of type = 2* are more prone to Heart Disease\n8. People with *restecg = 1* i.e. having normal wave are more prone to Heart Disease{*a bit confusing though*}\n9. People with *exng = 0* i.e. no exercise induced angina are more prone to Heart Disease\n\n**Correlation**\n\n10. oldpeak with slp seems a bit correlated. Other than this, there is no apparent linear correlation between continuous variables as  most of the correlation values are below {+\/-}0.5.\n\n**Multivariate Analysis**\n\n11. We observed:\n       * Heart Attack is less prone when *fasting blood sugar* is less than 120 mg\/dl\n       * *Oldpeak* at 0 is more prone\n       * *Slope* at 2 i.e. at downsloping is more prone\n       * *Caa* or number of major vessels at 1 is more prone","08b2a68e":"#### 4. Correlation Between Variables","8cf93f1f":"#### One Hot Encoding"}}