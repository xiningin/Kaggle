{"cell_type":{"01336ca8":"code","4f458518":"code","7a6f165a":"code","95781c81":"code","4c53654e":"code","74f9fed9":"code","e5a4fd7f":"code","849cf729":"code","e5347610":"code","817e4ced":"code","e3556649":"code","9a4c5f00":"code","1f0b99aa":"code","54b911f8":"code","5e409846":"code","71df7d00":"code","cf271d9a":"code","d2d4584e":"code","3ed7e1ef":"code","4d811164":"code","c07f6840":"code","bfdb36b3":"code","a42e9ade":"code","f471665d":"code","dddde913":"code","a7f2744d":"code","e9d4f6b3":"code","8b360f61":"code","390c7629":"code","e0c691d0":"code","a6839750":"code","360ef671":"code","7dfe8eb0":"code","e86d8ab9":"code","fe84322a":"code","b3cba5f5":"code","d4785c94":"code","be493efe":"code","89a18ca4":"code","353a0841":"code","74594f93":"code","e3531f18":"markdown","19068fa0":"markdown","df34b8ca":"markdown","9de8da95":"markdown"},"source":{"01336ca8":"import gc\nimport os\nfrom pathlib import Path\nimport sys\nimport collections\n\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm_notebook as tqdm\n\nimport joblib\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nfrom sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n# from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, QuantileTransformer #, MinMaxScaler\n# from sklearn.experimental import enable_iterative_imputer\n# from sklearn.impute import SimpleImputer #, IterativeImputer, MissingIndicator\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import mean_squared_error\n\nimport category_encoders as ce\nimport lightgbm as lgbm\n","4f458518":"%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15, 5)\npd.options.display.max_columns = 50","7a6f165a":"VERSION = \"1.6.6\"","95781c81":"# Is this environment Kaggle kernel?\nIS_KAGGLE = \"KAGGLE_URL_BASE\" in os.environ\nprint(f\"IS_KAGGLE: {IS_KAGGLE}\")\n\n# GPU enviroment?\nUSE_GPU = \"NVIDIA_VISIBLE_DEVICES\" in os.environ\nprint(f\"USE_GPU: {USE_GPU}\")\n\n# Save and load interim data?\nUSE_CACHE = False","4c53654e":"model_dir = Path(\".\" if IS_KAGGLE else \"..\/output\/models\")\nmodel_dir.mkdir(parents=True, exist_ok=True)","74f9fed9":"def reduce_mem_usage(df: pd.DataFrame, verbose: bool = True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ (1024 ** 2)    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n#                     df[col] = df[col].astype(np.float16)\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n            end_mem, 100 * (start_mem - end_mem) \/ start_mem)\n        )\n        \n    return df","e5a4fd7f":"train = pd.read_csv(\"..\/input\/exam-for-students20200129\/train.csv\", index_col=0, na_values=\"\").pipe(reduce_mem_usage)\nX_test = pd.read_csv(\"..\/input\/exam-for-students20200129\/test.csv\", index_col=0, na_values=\"\").pipe(reduce_mem_usage)","849cf729":"# \u5c0f\u6570\u70b9\u304c\u307b\u3068\u3093\u3069\u30b3\u30f3\u30de\u306a\u306e\u3067\u3001decimal\u3092\u30b3\u30f3\u30de\u6307\u5b9a\u3057\u3066\u8aad\u307f\u8fbc\u307f\ndf_country = pd.read_csv(\"..\/input\/exam-for-students20200129\/country_info.csv\", decimal=\",\").pipe(reduce_mem_usage)","e5347610":"# GDP\u3060\u3051\u5c0f\u6570\u70b9\u304cdot\u3067\u6570\u5024\u3068\u3057\u3066\u8aad\u3081\u3066\u3044\u306a\u3044\u306e\u3067\u3001\u6570\u5024\u306b\u5909\u63db\ndf_country[\"GDP ($ per capita)\"] = df_country[\"GDP ($ per capita)\"].astype(np.float32)","817e4ced":"df_country","e3556649":"df_country.info()","9a4c5f00":"train","1f0b99aa":"train = train.reset_index().merge(df_country, how=\"left\", on=\"Country\").set_index(\"Respondent\")\nX_test = X_test.reset_index().merge(df_country, how=\"left\", on=\"Country\").set_index(\"Respondent\")","54b911f8":"train.info()","5e409846":"X_train = train.drop(columns=\"ConvertedSalary\")\n# log\u5909\u63db\u3057\u3066RMSLE\u3067\u8a55\u4fa1\u3057\u3084\u3059\u304f\u3059\u308b\ny_train = np.log1p(train.ConvertedSalary)","71df7d00":"split_cols = [\n  \"DevType\",\n  \"CommunicationTools\",\n  \"FrameworkWorkedWith\",\n  \"AdsActions\",\n  \"ErgonomicDevices\",\n  \"Gender\",\n  \"SexualOrientation\",\n  \"RaceEthnicity\"\n]","cf271d9a":"def flatten(l):\n    for el in l:\n        if isinstance(el, collections.abc.Iterable) and not isinstance(el, (str, bytes)):\n            yield from flatten(el)\n        else:\n            yield el","d2d4584e":"def split_text(df):\n    for col in split_cols:\n        categories = list(set(flatten(X_train[col].str.split(\";\").tolist())))\n        categories = [i for i in categories if str(i) != 'nan']\n        for category in categories:\n            df[f\"{col}_{category}\"] = df[col].str.contains(category).astype(np.float32)\n        # count ;\n        df[f\"count_{col}\"] = df[col].str.count(\";\")\n    return df","3ed7e1ef":"X_train = split_text(X_train)\nX_test = split_text(X_test)","4d811164":"X_train.info()","c07f6840":"# LGBM\u3067\u30a8\u30e9\u30fc\u306b\u306a\u308b\u306e\u3067\u30ea\u30cd\u30fc\u30e0\u3057\u3066\u304a\u304f\nX_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train.columns]\nX_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_test.columns]","bfdb36b3":"object_cols = X_train.select_dtypes(include=\"object\").columns.tolist()","a42e9ade":"class BaseTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return self\n\n    def get_feature_names(self):\n        pass\n\nclass KFoldTargetEncoder(BaseTransformer):\n    \"\"\"K-Fold target encoder\"\"\"\n\n    def __init__(self, cols=None,\n                 n_splits=5, random_state=24, shuffle=True, **kwargs):\n        super().__init__()\n        if cols is None:\n            cols = []\n        self.cols = cols\n        self.enc = ce.TargetEncoder(cols=cols, return_df=False, **kwargs)\n        self.n_splits = n_splits\n        self.random_state = random_state\n        self.shuffle = shuffle\n        self.kwargs = kwargs\n        self.train_idx = None\n        self.y = None\n\n    def fit(self, X, y=None):\n        self.enc.fit(X[self.cols], y)\n        self.train_idx = X.index\n        self.y = y\n        return self\n\n    def transform(self, X):\n        if self.train_idx is X.index:\n            # training data \u306e\u5909\u63db\n            df = pd.DataFrame(index=X.index, columns=self.cols, dtype=float)\n            skf = KFold(n_splits=self.n_splits, random_state=self.random_state, shuffle=self.shuffle)\n            for train_idx, val_idx in skf.split(X, self.y):\n                enc = ce.TargetEncoder(cols=self.cols, return_df=False, **self.kwargs)\n                X_train, y_train = X.loc[X.index[train_idx], self.cols], self.y.iloc[train_idx]\n                X_val = X.loc[X.index[val_idx], self.cols]\n                enc.fit(X_train, y_train)\n                df.loc[df.index[val_idx], self.cols] = enc.transform(X_val)\n            return df\n        # test data \u306e\u5909\u63db\n        return self.enc.transform(X[self.cols])\n\n    def get_feature_names(self):\n        return self.cols\n","f471665d":"feature_union1 = FeatureUnion([\n    (\"te\", KFoldTargetEncoder(\n        cols=object_cols,\n        smoothing=.8\n    )),\n], n_jobs=None, verbose=True)","dddde913":"X_train1 = feature_union1.fit_transform(X_train, y_train)\nX_test1 = feature_union1.transform(X_test)","a7f2744d":"oe = ce.OrdinalEncoder(cols=object_cols)","e9d4f6b3":"X_train = oe.fit_transform(X_train, y_train)\nX_test = oe.transform(X_test)","8b360f61":"feature_names = X_train.columns.tolist()","390c7629":"X_train = np.hstack([X_train, X_train1])\nX_test = np.hstack([X_test, X_test1])","e0c691d0":"feature_names += feature_union1.get_feature_names()","a6839750":"X_train.shape","360ef671":"# Kfold lgbm\n\nmodels = []\n\nseeds = [114]\n\nfor seed in seeds:\n    params = {\n        \"objective\": \"regression\",\n        \"learning_rate\": .02,\n        \"tree_learner\": \"data\",\n        \"device_type\": \"cpu\",\n        \"num_leaves\": 128,\n        \"seed\": seed,\n        \"colsample_bytree\": .8,\n        \"max_depth\": 7,\n        \"subsample\": .9,\n    #     \"min_data_in_leaf\": 128,\n        \"metric\": [\"rmse\"]\n    }\n\n    skf = KFold(n_splits=5, random_state=seed, shuffle=True)\n\n    for i, (train_ix, test_ix) in enumerate(skf.split(X_train, y_train)):\n        X_train_, y_train_ = X_train[train_ix,], y_train.values[train_ix]\n        X_val_, y_val_ = X_train[test_ix,], y_train.values[test_ix]\n\n        train_data = lgbm.Dataset(\n            data=X_train_,\n            label=y_train_,\n            feature_name=feature_names\n        )\n\n        val_data = lgbm.Dataset(\n            data=X_val_,\n            label=y_val_,\n            reference=train_data,\n            feature_name=feature_names\n        )\n\n        model = lgbm.train(params=params, train_set=train_data, num_boost_round=9999, valid_sets=[val_data],\n                           early_stopping_rounds=200, verbose_eval=100)\n        models.append(model)\n        y_pred_ = model.predict(X_val_)\n        score = mean_squared_error(y_val_, y_pred_)\n\n        print('CV Score of Fold_%d is %f' % (i, score))","7dfe8eb0":"joblib.dump(models, model_dir \/ f\"models-lgbm-{VERSION}.joblib\")","e86d8ab9":"for i, model in enumerate(models):\n    if i == 0:\n        y_preds = model.predict(X_test)\n    else:\n        y_preds = np.vstack((y_preds, model.predict(X_test)))","fe84322a":"# target\u306flog\u5909\u63db\u3055\u308c\u3066\u3044\u308b\u306e\u3067, exp\u3067\u5143\u306b\u623b\u3059\ny_preds = np.expm1(y_preds)","b3cba5f5":"y_pred = y_preds.mean(axis=0)","d4785c94":"submission = pd.read_csv('..\/input\/exam-for-students20200129\/sample_submission.csv', index_col=0)\nsubmission.ConvertedSalary = y_pred\nsubmission.to_csv(model_dir \/ f'submission-{VERSION}.csv')","be493efe":"submission","89a18ca4":"for i, model in enumerate(models):\n    if i == 0:\n        feature_importances = pd.DataFrame({f\"m{i}\": pd.Series(model.feature_importance(importance_type=\"gain\"),\n                                                               index=model.feature_name())},\n                                          index=model.feature_name())\n    else:\n        feature_importances[f\"m{i}\"] = pd.Series(model.feature_importance(importance_type=\"gain\"),\n                                                 index=model.feature_name())","353a0841":"feature_importances[\"mean\"] = feature_importances.mean(axis=1)","74594f93":"with pd.option_context(\"display.max_rows\", 1000):\n    print(feature_importances[\"mean\"].sort_values(ascending=False))","e3531f18":"# \u30c6\u30ad\u30b9\u30c8\u51e6\u7406\n\u8907\u6570\u30ab\u30c6\u30b4\u30ea\u9805\u76ee\u304c\u542b\u307e\u308c\u308b\u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u91cf\u3092\u5206\u5272\u3059\u308b","19068fa0":"## Prediction","df34b8ca":"# Encoding","9de8da95":"# Modeling"}}