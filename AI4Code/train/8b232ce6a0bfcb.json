{"cell_type":{"e7f70c1a":"code","f65fea62":"code","458ea63a":"code","038d3e91":"code","3fc89f68":"code","45132de7":"code","b9239f1c":"code","6e2cd8cb":"code","fdcd2f92":"code","f8080d33":"code","379cf869":"code","53dfbe87":"code","6169951e":"code","df5c3d73":"code","7a3b6924":"code","90c5431a":"code","0f0d580f":"code","dcd305fd":"code","76d7d588":"code","7b8bc1e4":"code","74b4abfe":"markdown","88f16328":"markdown","bfa9e1a4":"markdown","34c7e974":"markdown","2d40fcaa":"markdown","897136e7":"markdown","01c395a7":"markdown","b1b20201":"markdown","ae261c14":"markdown","fe06e60b":"markdown","f1b501b1":"markdown","6e10225c":"markdown","bb2e6307":"markdown","b343991d":"markdown","9cb75b69":"markdown","9bd165c9":"markdown","bbace978":"markdown"},"source":{"e7f70c1a":"!pip install -q --upgrade seaborn","f65fea62":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","458ea63a":"dim = 512 #512, 256, 'original'\nepochs = 25\nbatch_size = 16\nfold = 0","038d3e91":"train_df = pd.read_csv(f'..\/input\/siim-covid19-yolov5-2class-labels\/meta.csv')\ntrain_df['image_path'] = '..\/input\/siimcovid19-512-jpg-image-dataset\/train\/'+train_df.image_id+'.jpg'\ntrain_df.head()","3fc89f68":"gkf  = GroupKFold(n_splits = 5)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):\n    train_df.loc[val_idx, 'fold'] = fold\ntrain_df.head()","45132de7":"train_files = []\nval_files   = []\nval_files += list(train_df[train_df.fold==fold].image_path.unique())\ntrain_files += list(train_df[train_df.fold!=fold].image_path.unique())\nlen(train_files), len(val_files)","b9239f1c":"os.makedirs('\/kaggle\/working\/siim-covid-19\/labels\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/siim-covid-19\/labels\/val', exist_ok = True)\nos.makedirs('\/kaggle\/working\/siim-covid-19\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/siim-covid-19\/images\/val', exist_ok = True)\nlabel_dir = '\/kaggle\/\/input\/siim-covid19-yolov5-2class-labels\/labels\/'\nfor file in tqdm(train_files):\n    shutil.copy(file, '\/kaggle\/working\/siim-covid-19\/images\/train')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/siim-covid-19\/labels\/train')\n    \nfor file in tqdm(val_files):\n    shutil.copy(file, '\/kaggle\/working\/siim-covid-19\/images\/val')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/siim-covid-19\/labels\/val')","6e2cd8cb":"class_ids  = {0:'opacity'}\nclass_names = ['opacity']","fdcd2f92":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/siim-covid-19\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/siim-covid-19\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train.txt') ,\n    val   =  join( cwd , 'val.txt' ),\n    nc    = 1,\n    names = class_names\n    )\n\nwith open(join( cwd , 'siim-covid-19.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'siim-covid-19.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","f8080d33":"# https:\/\/www.kaggle.com\/ultralytics\/yolov5\n# !git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n# %cd yolov5\nshutil.copytree('\/kaggle\/input\/yolov5-official-v50-dataset\/', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5')\n%pip install -qr requirements.txt # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","379cf869":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data\/images\/\nImage(filename='runs\/detect\/exp\/zidane.jpg', width=600)","53dfbe87":"# !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache \n!WANDB_MODE=\"dryrun\" python train.py --img $dim --batch $batch_size\\\n--epochs $epochs --data \/kaggle\/working\/siim-covid-19.yaml\\\n--weights yolov5x.pt --cache","6169951e":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels_correlogram.jpg'));","df5c3d73":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels.jpg'));","7a3b6924":"import matplotlib.pyplot as plt\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch0.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch1.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch2.jpg'))","90c5431a":"fig, ax = plt.subplots(3, 2, figsize = (3*5,4*5), constrained_layout = True)\nfor row in range(3):\n    ax[row][0].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'test_batch{row}.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'test_batch{row}.jpg', fontsize = 12)","0f0d580f":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/results.png'));","dcd305fd":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/confusion_matrix.png'));","76d7d588":"plt.figure(figsize=(2*10, 2*8))\nfor idx, tag in enumerate(['P', 'R', 'PR', 'F1']):\n    plt.subplot(2, 2, idx+1)\n    plt.imshow(plt.imread(f'runs\/train\/exp\/{tag}_curve.png'));\n    plt.axis('OFF')\n    plt.title(tag, fontsize=15)\nplt.tight_layout()\nplt.show()","7b8bc1e4":"shutil.rmtree('\/kaggle\/working\/siim-covid-19')\nshutil.rmtree('runs\/detect')\nfor file in (glob('**\/*.png', recursive = True)+glob('**\/*.jpg', recursive = True)):\n    os.remove(file)","74b4abfe":"# YOLOv5 Stuff","88f16328":"# Removing Files","bfa9e1a4":"# (Loss, Map) Vs Epoch","34c7e974":"# [YOLOv5](https:\/\/github.com\/ultralytics\/yolov5)\n![](https:\/\/user-images.githubusercontent.com\/26833433\/98699617-a1595a00-2377-11eb-8145-fc674eb9b1a7.jpg)\n![](https:\/\/user-images.githubusercontent.com\/26833433\/90187293-6773ba00-dd6e-11ea-8f90-cd94afc0427f.png)","2d40fcaa":"# Precision, Recall, Precision-Recall, F1 Curve","897136e7":"# Overview:\n* Basic idea was to use **classification** model for **Study-Level** & **detection** model for **Image-Level**,\n\n# Notebooks:\n\n#### Study-Level:\n* **train**: [SIIM-COVID-19: EffNetB6 Study-Level [train] TPU\ud83e\ude7a](https:\/\/www.kaggle.com\/awsaf49\/siim-covid-19-effnetb6-study-level-train-tpu\/)\n* **infer**: [SIIM-COVID-19: EffNetB6 Study-Level [infer]\ud83e\ude7a](https:\/\/www.kaggle.com\/awsaf49\/siim-covid-19-effnetb6-study-level-infer) [LB: **0.338**]\n* **data**: [SIIM-COVID-19: 512x512 tfrec Data](https:\/\/www.kaggle.com\/awsaf49\/siim-covid-19-512x512-tfrec-data)\n\n#### Image-Level:\n* **train**: [SIIM-COVID-19: YOLOv5 Image-Level [train]](https:\/\/www.kaggle.com\/awsaf49\/siim-covid-19-yolov5-image-level-train)\n* **infer**: [SIIM-COVID-19: YOLOv5 Image-Level [infer]](https:\/\/www.kaggle.com\/awsaf49\/siim-covid-19-yolov5-image-level-infer) **placeholder**, seems someting is wrong with `image-level` data, gives very small score `0.051`.\n\n# Dataset:\n\n#### JPEG\n* [1024x1024](https:\/\/www.kaggle.com\/awsaf49\/siimcovid19-1024-jpg-image-dataset)\n* [512x512](https:\/\/www.kaggle.com\/awsaf49\/siimcovid19-512-jpg-image-dataset)\n* [256x256](https:\/\/www.kaggle.com\/awsaf49\/siimcovid19-256-jpg-image-dataset)\n\n#### TFRECORD\n* [1024x1024](https:\/\/www.kaggle.com\/awsaf49\/siimcovid19-1024x1024-tfrec-dataset)\n* [512x512](https:\/\/www.kaggle.com\/awsaf49\/siimcovid19-512x512-tfrec-dataset)\n* [256x256](https:\/\/www.kaggle.com\/awsaf49\/siimcovid19-256x256-tfrec-dataset)","01c395a7":"# Train","b1b20201":"## Pretrained Checkpoints:\n\n| Model | AP<sup>val<\/sup> | AP<sup>test<\/sup> | AP<sub>50<\/sub> | Speed<sub>GPU<\/sub> | FPS<sub>GPU<\/sub> || params | FLOPS |\n|---------- |------ |------ |------ | -------- | ------| ------ |------  |  :------: |\n| [YOLOv5s](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | 37.0     | 37.0     | 56.2     | **2.4ms** | **416** || 7.5M   | 13.2B\n| [YOLOv5m](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | 44.3     | 44.3     | 63.2     | 3.4ms     | 294     || 21.8M  | 39.4B\n| [YOLOv5l](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | 47.7     | 47.7     | 66.5     | 4.4ms     | 227     || 47.8M  | 88.1B\n| [YOLOv5x](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | **49.2** | **49.2** | **67.7** | 6.9ms     | 145     || 89.0M  | 166.4B\n| | | | | | || |\n| [YOLOv5x](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0) + TTA|**50.8**| **50.8** | **68.9** | 25.5ms    | 39      || 89.0M  | 354.3B\n| | | | | | || |\n| [YOLOv3-SPP](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0) | 45.6     | 45.5     | 65.2     | 4.5ms     | 222     || 63.0M  | 118.0B","ae261c14":"# GT Vs Pred","fe06e60b":"# Copying Files","f1b501b1":"# Split","6e10225c":"# Confusion Matrix","bb2e6307":"# Selecting Models\nIn this notebok I'm using `v5x`. To select your prefered model just replace `--cfg models\/yolov5s.yaml --weights yolov5s.pt` with the following command:\n* `v5s` : `--cfg models\/yolov5s.yaml --weights yolov5s.pt`\n* `v5m` : `--cfg models\/yolov5m.yaml --weights yolov5m.pt`\n* `v5l` : `--cfg models\/yolov5l.yaml --weights yolov5l.pt`\n* `v5x` : `--cfg models\/yolov5x.yaml --weights yolov5x.pt`","b343991d":"# Batch Image","9cb75b69":"# Get Class Name","9bd165c9":"# Class Distribution","bbace978":"# [SIIM-FISABIO-RSNA COVID-19 Detection](https:\/\/www.kaggle.com\/c\/siim-covid19-detection)\n> Identify and localize COVID-19 abnormalities on chest radiographs\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/26680\/logos\/header.png)"}}