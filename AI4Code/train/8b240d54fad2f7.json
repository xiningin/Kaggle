{"cell_type":{"e3eecb3e":"code","eec99ded":"code","d090058c":"code","12778b63":"code","69eed1bc":"code","63836d8d":"code","65bd0281":"code","4975012c":"code","e7e641f7":"code","05d55831":"code","7ebd5017":"code","e46156e2":"code","e714fb52":"code","1b41c592":"code","1b494c63":"code","e8664813":"code","8f879efd":"code","38bb33b9":"code","de91922b":"code","5305ec98":"code","e0290b98":"code","f79e7cb4":"code","23919ff1":"code","4018923b":"code","b529aeb4":"code","ce23fe2d":"code","22cc4b3b":"code","f82559a7":"code","ed2f7cef":"code","e835a3ca":"code","365d9521":"code","b45cdc9b":"code","d0b2cb11":"code","20905804":"code","dc0aa063":"code","f61da054":"code","4e5be7ff":"code","97066e0e":"code","1f72ce54":"code","bc37c56f":"code","2ad45d64":"code","2d48f080":"code","b8793b64":"code","23f18e24":"code","4991f620":"code","64d74e9a":"code","7335b4bb":"code","797025c6":"code","597f9760":"code","0a7e5b44":"code","97bd5e19":"code","8336fb25":"code","6dcd781a":"code","cea4b839":"code","f8829dc6":"code","812594f4":"code","c554a747":"code","78d28a6d":"code","f95b10cc":"code","597a4404":"code","b915f1d1":"code","2d748b4d":"code","7345ceac":"code","dcbdb2ca":"code","1000b875":"code","80189a76":"code","e2d60dfd":"code","cd4c972e":"code","4038940a":"code","765105ed":"code","1966a3b0":"code","1b5f4644":"code","c9a1f877":"code","a893f344":"code","e3439fde":"code","8fb397e7":"code","dd2a97f3":"code","a7d045a6":"code","21e31844":"code","8e04de5b":"code","8d2d7931":"code","3d05b183":"code","e58890c9":"markdown","210d6a2b":"markdown","ab366002":"markdown","d8f7265d":"markdown","60503184":"markdown","67f37475":"markdown","68356060":"markdown","67c953d7":"markdown","d9451565":"markdown","026e1d88":"markdown","82a0d78f":"markdown","31df5d99":"markdown","294d8635":"markdown","e4e6812b":"markdown","8919d449":"markdown","518fa013":"markdown","b8d3e22a":"markdown","d8b9e781":"markdown","48e54d19":"markdown","b68816fc":"markdown","09147df2":"markdown","0f0ed24f":"markdown","07108f55":"markdown","bb5f6a11":"markdown","4e912a1d":"markdown","868fddda":"markdown","ded5fedc":"markdown","2346e9a0":"markdown","4a7a3e95":"markdown","3bfcf1c5":"markdown","133e1996":"markdown","0b275e4d":"markdown","6ab6a16b":"markdown","b48b6bc7":"markdown","b0ef98f6":"markdown","6f20ac76":"markdown","8176c53d":"markdown"},"source":{"e3eecb3e":"import numpy as np \nimport pandas as pd \n\n#EDA \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n#Imputation \nfrom sklearn.impute import SimpleImputer\n\n#split\n\nfrom sklearn.model_selection import train_test_split\n\n# Deep Learning \nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Evaluation\nfrom sklearn.metrics import accuracy_score, classification_report","eec99ded":"#Define theme for matplotlib and seaborn to ensure consistency\nsns.set_theme()","d090058c":"df = pd.read_csv('..\/input\/lending-club\/accepted_2007_to_2018q4.csv\/accepted_2007_to_2018Q4.csv',\n                 usecols=['loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n                          'emp_title', 'emp_length', 'home_ownership', 'annual_inc',\n                          'verification_status', 'issue_d', 'loan_status', 'purpose', 'title',\"addr_state\",\n                          'dti', 'earliest_cr_line', 'open_acc', 'pub_rec', 'revol_bal',\n                          'revol_util', 'total_acc', 'initial_list_status', 'application_type',\n                          'mort_acc', 'pub_rec_bankruptcies'])","12778b63":"df.head()","69eed1bc":"df.shape","63836d8d":"df.info()","65bd0281":"#target analysis\ndf[\"loan_status\"].value_counts(dropna = False)","4975012c":"replace_status = {\"Fully Paid\":\"Paid\",\n             \"Current\": \"Paid\",\n             \"Charged Off\": \"Default\",\n              \"Does not meet the credit policy. Status:Charged Off\":\"Default\",\n              \"Does not meet the credit policy. Status:Charged Off\":\"Default\",\n              \"Does not meet the credit policy. Status:Fully Paid\":\"Paid\",\n              \"Late (31-120 days)\":\"Late\",\n              \"Late (16-30 days)\":\"Late\",\n              \"In Grace Period\":\"Late\",\n              \"Default\":\"Default\"\n             }","e7e641f7":"df[\"loan_status\"] = df[\"loan_status\"].replace(replace_status)","05d55831":"# Keep Default or Paid loans only\ndf = df[ (df[\"loan_status\"]== \"Paid\") | (df[\"loan_status\"]== \"Default\")]","7ebd5017":"df[\"loan_status\"].value_counts(dropna= False)","e46156e2":"df.describe().transpose()","e714fb52":"df.shape","1b41c592":"#Target analysis\ndf[\"loan_status\"].value_counts(dropna = False).plot(kind = \"bar\",figsize = (10,5))","1b494c63":"# all object type features\ndf.describe( include= [\"object\"]).transpose()","e8664813":"def create_countplot(axes, x_val,order_val, title, rotation=\"n\"):\n    sns.countplot(ax= axes, data=df, x=x_val, order = order_val.value_counts(dropna= False).index,hue = \"loan_status\")\n    axes.set_title(title)\n    if rotation ==\"y\":\n        axes.set_xticklabels(list(order_val.unique()), rotation=90)","8f879efd":"fig, ax = plt.subplots(2,3, figsize= (20,10))\n\ncreate_countplot(ax[0,0],'term', df[\"term\"],\"The number of payments on the loan (months)\" )\n\ncreate_countplot(ax[0,1],'grade', df[\"grade\"],\"Loan grade\")\n\ncreate_countplot(ax[0,2],'sub_grade', df[\"sub_grade\"],\"Loan sub_grade\",\"y\")\n\ncreate_countplot(ax[1,0],'emp_length', df[\"emp_length\"],\"Borrower length of employment (years)\", \"y\" )\n\ncreate_countplot(ax[1,1],'home_ownership', df[\"home_ownership\"],\"Borrower home ownership status\" )\n\ncreate_countplot(ax[1,2],'verification_status', df[\"verification_status\"],\"verification_status\" )\n\n\nplt.tight_layout()\nplt.show()","38bb33b9":"fig, ax = plt.subplots(1,3, figsize= (20,6))\n\ncreate_countplot(ax[0],'purpose', df[\"purpose\"],\"Purpose of loan\" ,\"y\")\ncreate_countplot(ax[1],'initial_list_status', df[\"initial_list_status\"],\"Initial listing status of the loan\" )\ncreate_countplot(ax[2],'application_type', df[\"application_type\"],\"Application type\" )\n\n\n\nplt.tight_layout()\nplt.show()","de91922b":"## too many unique titles to plot \ndf[\"emp_title\"].value_counts(dropna= False)","5305ec98":"df[[\"title\",\"purpose\"]]","e0290b98":"#convert to date \ndf[\"issue_d\"] = pd.to_datetime(df[\"issue_d\"])\ndf[\"earliest_cr_line\"] = pd.to_datetime(df[\"earliest_cr_line\"])","f79e7cb4":"fig, ax = plt.subplots(1,2, figsize= (20,6))\n\nax[0].plot(df['issue_d'].value_counts().sort_index())\nax[1].plot(df['earliest_cr_line'].value_counts().sort_index())\nax[0].set_title(\"Issue date\")\nax[1].set_title(\"Earliest credit line\")\n\nplt.tight_layout()\nplt.show()","23919ff1":"plt.figure(figsize= (15,7))\nsns.heatmap(df.corr(), vmin=1, vmax=-1, annot=True, cmap=\"Spectral\")","4018923b":"df.isnull().sum()[df.isnull().sum()>0]","b529aeb4":"plt.figure(figsize = (10,7))\nsns.heatmap(df.isnull(), cmap = \"viridis\",  cbar=False, yticklabels=False)\nplt.title(\"Heatmap of blank values\",fontsize =15)","ce23fe2d":"((df.isnull().sum()\/len(df))*100).plot(kind = \"bar\", figsize = (10,7))\nplt.title(\"Percent of null values\",fontsize= 15)\nplt.show()","22cc4b3b":"imputer_mean = SimpleImputer() #mean imputation\nimputer_mode = SimpleImputer(strategy=\"most_frequent\")","f82559a7":"## Reset index for concat \ndf = df.reset_index(drop = True)","ed2f7cef":"mode_impute = [\"emp_title\",\"earliest_cr_line\"]\nmean_impute = [\"annual_inc\",\"dti\",\"open_acc\",\"pub_rec\",\"revol_util\",\"total_acc\",\"mort_acc\",\"pub_rec_bankruptcies\"]","e835a3ca":"mean_df = pd.DataFrame(data = imputer_mean.fit_transform(df[mean_impute]), columns = mean_impute)","365d9521":"df.drop(mean_impute,axis = 1,inplace =True)","b45cdc9b":"df = pd.concat([df,mean_df],axis =1)","d0b2cb11":"df.head()","20905804":"df[\"emp_length\"].fillna(df[\"emp_length\"].mode()[0], inplace = True)\ndf[\"earliest_cr_line\"].fillna(df[\"earliest_cr_line\"].mode()[0],inplace = True)","dc0aa063":"df.isnull().sum()","f61da054":"# too many unique values \ndf.drop(\"emp_title\",axis =1, inplace = True)\n\n# title is the same as \"purpose\" we can therefore drop this column\ndf.drop(\"title\",axis =1, inplace = True)\n\n## grade holds the same information as subgrade\ndf.drop(\"grade\",axis =1, inplace = True)","4e5be7ff":"df[\"term\"] = df[\"term\"].apply(lambda x : x[:3]).astype(int)\nprint(df[\"term\"].value_counts())","97066e0e":"df[\"emp_length\"].value_counts()","1f72ce54":"replace_dictionary = {\"< 1 year\":\"1 years\" }\ndf[\"emp_length\"].replace(replace_dictionary,inplace=True)","bc37c56f":"df[\"emp_length\"] =df[\"emp_length\"].apply(lambda x: x[:2]).astype(int)","2ad45d64":"## Target to dummies \ndf[\"loan_status\"] = df[\"loan_status\"].map({\"Paid\":0,\"Default\":1})","2d48f080":"df[\"home_ownership\"].value_counts()","b8793b64":"# lets group None and Any --> Other\ndf[\"home_ownership\"]= df[\"home_ownership\"].replace([\"ANY\",\"NONE\"], \"OTHER\")","23f18e24":"dummy_cols = [ \"home_ownership\", \"verification_status\", \"purpose\",\"initial_list_status\", \"application_type\",\"sub_grade\", \"addr_state\"]\n","4991f620":"#get dummy columns\ndf_dummies = pd.get_dummies(df[dummy_cols], drop_first=True)\n\n#drop from original dataframe\ndf.drop(dummy_cols,axis =1, inplace=True)","64d74e9a":"df= pd.concat([df,df_dummies],axis =1)","7335b4bb":"df.drop(\"issue_d\",axis =1, inplace=True)","797025c6":"print(df[\"earliest_cr_line\"].value_counts())","597f9760":"# extract year column \ndf[\"year_earliest\"] = pd.to_datetime(df[\"earliest_cr_line\"]).dt.year\n\n#extract month column \ndf[\"month_earliest\"] = pd.to_datetime(df[\"earliest_cr_line\"]).dt.month\n\n#drop old column as we dont it now\ndf.drop([\"earliest_cr_line\"],axis=1, inplace=True)","0a7e5b44":"df.iloc[:,:20].info()","97bd5e19":"####################### ------- DELETE ------FOR Testing only ##########3\n#df = df.sample(n= 100000, random_state = 42)\n\n\n##################################### DELETE #################3\n\ndf[\"loan_status\"].value_counts()","8336fb25":"X = df.drop(\"loan_status\",axis =1 )\ny= df[\"loan_status\"]","6dcd781a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","cea4b839":"from sklearn.preprocessing import MinMaxScaler","f8829dc6":"scaler = MinMaxScaler()","812594f4":"# we only transform X_test to stop any leakage \nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","c554a747":"X_train","78d28a6d":"print(\"Tensorflow version \" + tf.__version__)\n\ntry:\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n  raise BaseException('ERROR: Not connected to a TPU runtime')\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","f95b10cc":"EPOCHS = 100\nBATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', \n    verbose=1,\n    patience=10,\n    mode='min')\n\nstep_epoch = len(df)\/BATCH_SIZE","597a4404":"METRICS = [\n     # tf.keras.metrics.TruePositives(name='tp'),\n      #tf.keras.metrics.FalsePositives(name='fp'),\n      #tf.keras.metrics.TrueNegatives(name='tn'),\n      #tf.keras.metrics.FalseNegatives(name='fn'), \n      #tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      #tf.keras.metrics.Precision(name='precision'),\n      #tf.keras.metrics.Recall(name='recall'),\n      #tf.keras.metrics.AUC(name='auc'),\n      #tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]","b915f1d1":"df.shape","2d748b4d":"def make_model(metrics=METRICS, output_bias=None):\n  if output_bias is not None:\n    output_bias = tf.keras.initializers.Constant(output_bias)\n  model = tf.keras.Sequential([\n      tf.keras.layers.Dense(120, activation='relu'),\n      tf.keras.layers.Dropout(0.5),\n      \n      tf.keras.layers.Dense(60, activation='relu'),\n      tf.keras.layers.Dropout(0.5),\n      \n      tf.keras.layers.Dense(1, activation='sigmoid',\n                         bias_initializer=output_bias),\n  ])\n\n  model.compile(\n      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n      loss=tf.keras.losses.BinaryCrossentropy(),\n      metrics=metrics)\n\n  return model","7345ceac":"with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n  model = make_model()\n\n# train model normally\nmodel.fit(X_train,y_train, epochs=EPOCHS, batch_size = BATCH_SIZE, validation_data=(X_test,y_test), callbacks = early_stopping)","dcbdb2ca":"model.summary()","1000b875":"neg  = df[\"loan_status\"].value_counts()[0]\npos = df[\"loan_status\"].value_counts()[1]\n\nprint(\"% of False:\",neg\/ len(df))\nprint(\"% of True:\",pos \/ len(df))","80189a76":"history = pd.DataFrame(data = model.history.history)\n\n## Plot the loss of the traing and test set \nhistory.plot()","e2d60dfd":"print( \"best epoch: \", history[\"val_loss\"].argmin() )","cd4c972e":"model.evaluate(X_test,y_test)","4038940a":"# Note - predict_classes was deprecated as of tensorflow 2.6 \ny_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5).astype(\"int32\")","765105ed":"print( accuracy_score(y_test,y_pred) )\n\nprint( classification_report(y_test,y_pred) )","1966a3b0":"initial_bias = np.log([pos\/neg])\ninitial_bias","1b5f4644":"with tpu_strategy.scope(): \n  model_bias = make_model(output_bias=initial_bias)\n\n# train model normally\nmodel_bias.fit(X_train,y_train, epochs=EPOCHS, batch_size = BATCH_SIZE, validation_data=(X_test,y_test), callbacks = early_stopping)","c9a1f877":"history_bias = pd.DataFrame(data = model_bias.history.history)\n\nhistory_bias[[\"loss\",\"val_loss\"]].plot()","a893f344":"model_bias.evaluate(X_test,y_test)","e3439fde":"# Note - predict_classes was deprecated as of tensorflow 2.6 \ny_pred = model_bias.predict(X_test)\ny_pred = (y_pred > 0.5).astype(\"int32\")","8fb397e7":"# Note - predict_classes was deprecated as of tensorflow 2.6 \ny_pred = model_bias.predict(X_test)\ny_pred = (y_pred > 0.5).astype(\"int32\")\n\nprint( accuracy_score(y_test,y_pred) )\n\nprint( classification_report(y_test,y_pred) )","dd2a97f3":"weight_for_0 = (1 \/ neg) * (len(df) \/ 2.0)\nweight_for_1 = (1 \/ pos) * (len(df) \/ 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","a7d045a6":"with tpu_strategy.scope(): \n  model_weighted = make_model(output_bias=initial_bias)\n\n## note the class weight \nmodel_weighted.fit(X_train,y_train, epochs=EPOCHS, batch_size = BATCH_SIZE, validation_data=(X_test,y_test), callbacks = early_stopping\n                  ,class_weight=class_weight)","21e31844":"history_weighted = pd.DataFrame(data = model_weighted.history.history)\n\n## Plot the loss of the traing and test set \nhistory_weighted.plot()","8e04de5b":"model_weighted.evaluate(X_test,y_test)","8d2d7931":"history_weighted[\"val_loss\"].argmin()","3d05b183":"# Note - predict_classes was deprecated as of tensorflow 2.6 \ny_pred = model_weighted.predict(X_test)\ny_pred = (y_pred > 0.5).astype(\"int32\")\n\nprint( accuracy_score(y_test,y_pred) )\n\nprint( classification_report(y_test,y_pred) )","e58890c9":"### Non-numeric analysis","210d6a2b":"***Note*** Very imbalanced data set \\\n***NB*** for determining the type of metric used in prediction i.e. accuracy will not work ","ab366002":"Puropose and Title are essentially duplicates with Purpose being more descriptive \\\nAs such we can drop Title ","d8f7265d":"# Feature Engineering \nas per above ","60503184":"# Scaling ","67f37475":"We will drop everything NOT ***Default or Paid*** i.e. null and Late \\\nIn another notebook we can investigate how ***Late*** payments affect ***Default*** and look at imputing the null values","68356060":"<style type=\"text\/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-0lax{text-align:left;vertical-align:top}\n<\/style>\n<table class=\"tg\">\n<thead>\n  <tr>\n    <th class=\"tg-fymr\">Change<\/th>\n    <th class=\"tg-fymr\">Column<\/th>\n    <th class=\"tg-fymr\">Comment<\/th>\n  <\/tr>\n<\/thead>\n<tbody>\n  <tr>\n    <td class=\"tg-0pky\" rowspan=\"7\">Dummies<br><br><\/td>\n    <td class=\"tg-0pky\">home_ownership<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">verification_status<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">purpose<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">initial_list_status<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">application_type<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">sub grade<\/td>\n    <td class=\"tg-0pky\">Potentially ordinal but too many values<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0lax\">addr_state<\/td>\n    <td class=\"tg-0lax\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">Numerical conversion <\/td>\n    <td class=\"tg-0pky\">emp_length<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">term<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">Drop<\/td>\n    <td class=\"tg-0pky\">emp title<\/td>\n    <td class=\"tg-0pky\">Due to the number of unique values<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">title<\/td>\n    <td class=\"tg-0pky\">Duplicate of Purpose<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">grade<\/td>\n    <td class=\"tg-0pky\">Duplicate information as in subgrade<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">Date<\/td>\n    <td class=\"tg-0pky\">issue_d<\/td>\n    <td class=\"tg-0pky\">get month and year<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">earliest_cr_line<\/td>\n    <td class=\"tg-0pky\">get month and year<\/td>\n  <\/tr>\n<\/tbody>\n<\/table>","67c953d7":"# Deep learning  - Multilayer Perceptons\n\n## Base model\nWe will use a basic model with dropout layers (to reduce overfitting). We can then look changing the bias\/ threshold due to the imbalanced dataset","d9451565":"<div style=\"text-align: center; color: #345; padding-top: 10px;\">\n<h1 style=\"background-color: skyblue; font-family: newtimeroman; font-size: 220%; text-align: center;\"><span style=\"color: #000000;\">Deep Learning - Predicting loan defaults <\/span><span style=\"color: #000000;\"><br><\/br>\n    <img src=\"https:\/\/mma.prnewswire.com\/media\/76307\/lending_club_logo.jpg?w=200\"\/><span style=\"color: #0000ff;\"><\/h1>\n<\/div>","026e1d88":"### 2. Correlation Analysis","82a0d78f":"We need to beat an accuracy of 87% \\\ni.e. a model that only notes False (not Paid) ","31df5d99":"# Exploratory Data Analysis\n1. individual column and data type investigation \n1. correlation analysis","294d8635":"# Split ","e4e6812b":"We can ignore the day value as this is only the first","8919d449":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>LoanStatNew<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>loan_amnt<\/td>\n      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>term<\/td>\n      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>int_rate<\/td>\n      <td>Interest Rate on the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>installment<\/td>\n      <td>The monthly payment owed by the borrower if the loan originates.<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>grade<\/td>\n      <td>LC assigned loan grade<\/td>\n    <\/tr>\n    <tr>\n      <th>5<\/th>\n      <td>sub_grade<\/td>\n      <td>LC assigned loan subgrade<\/td>\n    <\/tr>\n    <tr>\n      <th>6<\/th>\n      <td>emp_title<\/td>\n      <td>The job title supplied by the Borrower when applying for the loan.*<\/td>\n    <\/tr>\n    <tr>\n      <th>7<\/th>\n      <td>emp_length<\/td>\n      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.<\/td>\n    <\/tr>\n    <tr>\n      <th>8<\/th>\n      <td>home_ownership<\/td>\n      <td>The home ownership status provided by the borrower during registration\u00a0or obtained from the credit report.\u00a0Our values are: RENT, OWN, MORTGAGE, OTHER<\/td>\n    <\/tr>\n    <tr>\n      <th>9<\/th>\n      <td>annual_inc<\/td>\n      <td>The self-reported annual income provided by the borrower during registration.<\/td>\n    <\/tr>\n    <tr>\n      <th>10<\/th>\n      <td>verification_status<\/td>\n      <td>Indicates if income was verified by LC, not verified, or if the income source was verified<\/td>\n    <\/tr>\n    <tr>\n      <th>11<\/th>\n      <td>issue_d<\/td>\n      <td>The month which the loan was funded<\/td>\n    <\/tr>\n    <tr>\n      <th>12<\/th>\n      <td>loan_status<\/td>\n      <td>Current status of the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>13<\/th>\n      <td>purpose<\/td>\n      <td>A category provided by the borrower for the loan request.<\/td>\n    <\/tr>\n    <tr>\n      <th>14<\/th>\n      <td>title<\/td>\n      <td>The loan title provided by the borrower<\/td>\n    <\/tr>\n    <tr>\n      <th>15<\/th>\n      <td>addr_state<\/td>\n      <td>The state provided by the borrower in the loan application<\/td>\n    <\/tr>\n    <tr>\n      <th>16<\/th>\n      <td>dti<\/td>\n      <td>A ratio calculated using the borrower\u2019s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower\u2019s self-reported monthly income.<\/td>\n    <\/tr>\n    <tr>\n      <th>17<\/th>\n      <td>earliest_cr_line<\/td>\n      <td>The month the borrower's earliest reported credit line was opened<\/td>\n    <\/tr>\n    <tr>\n      <th>18<\/th>\n      <td>open_acc<\/td>\n      <td>The number of open credit lines in the borrower's credit file.<\/td>\n    <\/tr>\n    <tr>\n      <th>19<\/th>\n      <td>pub_rec<\/td>\n      <td>Number of derogatory public records<\/td>\n    <\/tr>\n    <tr>\n      <th>20<\/th>\n      <td>revol_bal<\/td>\n      <td>Total credit revolving balance<\/td>\n    <\/tr>\n    <tr>\n      <th>21<\/th>\n      <td>revol_util<\/td>\n      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.<\/td>\n    <\/tr>\n    <tr>\n      <th>22<\/th>\n      <td>total_acc<\/td>\n      <td>The total number of credit lines currently in the borrower's credit file<\/td>\n    <\/tr>\n    <tr>\n      <th>23<\/th>\n      <td>initial_list_status<\/td>\n      <td>The initial listing status of the loan. Possible values are \u2013 W, F<\/td>\n    <\/tr>\n    <tr>\n      <th>24<\/th>\n      <td>application_type<\/td>\n      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers<\/td>\n    <\/tr>\n    <tr>\n      <th>25<\/th>\n      <td>mort_acc<\/td>\n      <td>Number of mortgage accounts.<\/td>\n    <\/tr>\n    <tr>\n      <th>26<\/th>\n      <td>pub_rec_bankruptcies<\/td>\n      <td>Number of public record bankruptcies<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>","518fa013":"##### Feature Engineering notes\nFrom the above the categorical values need to be processed","b8d3e22a":"# New bias model ","d8b9e781":"# Target Preprocessing\nLooking at the target there are multiple categories. \\\nFor our analysis we want to define a Binary classification of ***Default vs Paid***","48e54d19":"### Poor performance \n87% accuracy as seen above is not ideal, as this is showing that the model may only be labelling most things FALSE\nWe can also see this via the F1 score for 1 (positive) of 0.0, which is very poor ","b68816fc":"# New Weighted model \n*The goal is to identify fraudulent transactions, but you don't have very many of those positive samples to work with, so you would want to have the classifier heavily weight the few examples that are available. You can do this by passing Keras weights for each class through a parameter. These will cause the model to \"pay more attention\" to examples from an under-represented class.*\n\n\n***Note***: Scaling by len(df)\/2 helps keep the loss to a similar magnitude.\\\n***Note***: The sum of the weights of all examples stays the same.","09147df2":"## Data\nData contains 2 sets for data for rejected and accepted loans, from the Lending club, between 2007 to 2018 Quarter 4. \\\nWe will look at the accepted loans and only a subset of the columns (see list below)\n\n\n## Business summary\nCan we predict if a given borrower will default on their loan payments using the historical data provided. i.e. will the loan be ***Charged-off*** or set to ***Default*** status\n\n## Goal\nTo develop a classification model that predicts the **\"loan status\"** of a loan \n\nDescription of the columns used in prediction: \\\n**Note** with over 150 columns in this dataset, only the below will be used","0f0ed24f":"# Null Analysis & Processing\nThis step can be very time intensive depending on the approach \n\nOptions are:\n1. Use regression \/ classification techniques to find the missing values - ***very time intensive***\n1. Imputation of null values with mean, median or mode\n    * Use other features to group, then use impute mean,median, mode by grouping   - ***somewhat time intensive***\n    \n            i.e. to impute \"revol_util\", find the mean of \"revol_util\" groupby \"purpose\", then impute values based on grouping\n            df.groupby(\"purpose\")[\"revol_util\"].mean()             \n\n    * apply mean, median, mode across the whole column for imputation - ***least time intensive***\n    ","07108f55":"### Date Analysis","bb5f6a11":"## Dummies\nConvert all categorical (non-ordinal) features into dummy columns including the target column ","4e912a1d":"## Drop \n* emp_title\n* title\n* grade","868fddda":"note the null values in target ","ded5fedc":"# Read Data and review","2346e9a0":"# Libraries","4a7a3e95":"# Imputation\n#### Notes: \n\n* Numerical vals  impute with mean \n* categorical vals imputewith model \n\n*** We can ignore title & emp_length as we will drop these features ***","3bfcf1c5":"# Model Evaluation \n\nWe note that the classes are imbalanced, there are very few Default loans. ","133e1996":"### Number of Layers and neurons \nAs a general rule of thumb\n* The number of inital neurons in the ***first layer***= total number of features or less \n* The number of inital neurons in the ***second layer***= approx. half of the number of features\n* The number of hiden layers is 2 \nThis is what we will start with but can be changed in future runs ","0b275e4d":"## mean \n* annual_inc\n* dti\n* open_acc\n* pub_rec\n* revol_util\n* total_acc\n* mort_acc\n* pub_rec_bankruptcies\n## mode\n* emp_title\n* \"earliest_cr_line\"    ---Date","6ab6a16b":"## Convert to numerical\n","b48b6bc7":"<style type=\"text\/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-0lax{text-align:left;vertical-align:top}\n<\/style>\n<table class=\"tg\">\n<thead>\n  <tr>\n    <th class=\"tg-fymr\">Change<\/th>\n    <th class=\"tg-fymr\">Column<\/th>\n    <th class=\"tg-fymr\">Comment<\/th>\n  <\/tr>\n<\/thead>\n<tbody>\n  <tr>\n    <td class=\"tg-0pky\" rowspan=\"7\">Dummies<br><br><\/td>\n    <td class=\"tg-0pky\">home_ownership<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">verification_status<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">purpose<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">initial_list_status<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">application_type<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">sub grade<\/td>\n    <td class=\"tg-0pky\">Potentially ordinal but too many values<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0lax\">addr_state<\/td>\n    <td class=\"tg-0lax\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">Numerical conversion <\/td>\n    <td class=\"tg-0pky\">emp_length<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">term<\/td>\n    <td class=\"tg-0pky\"><\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">Drop<\/td>\n    <td class=\"tg-0pky\">emp title<\/td>\n    <td class=\"tg-0pky\">Due to the number of unique values<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">title<\/td>\n    <td class=\"tg-0pky\">Duplicate of Purpose<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">grade<\/td>\n    <td class=\"tg-0pky\">Duplicate information as in subgrade<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\">Date<\/td>\n    <td class=\"tg-0pky\">issue_d<\/td>\n    <td class=\"tg-0pky\">get month and year<\/td>\n  <\/tr>\n  <tr>\n    <td class=\"tg-0pky\"><\/td>\n    <td class=\"tg-0pky\">earliest_cr_line<\/td>\n    <td class=\"tg-0pky\">get month and year<\/td>\n  <\/tr>\n<\/tbody>\n<\/table>","b0ef98f6":"#### To save time we will go with the easiest method, but first lets some quick analysis","6f20ac76":"# TPU Setup \nhttps:\/\/www.kaggle.com\/docs\/tpu","8176c53d":"## Date Processing \nWe can extract the year, month and day values from the two columns \n* issue_d  ---- date loan was issued \n* earliest_cr_line --- earliest credit line month\n\n### Note:\n**issue_d** should be dropped as this tells us that the loan was already issued, we want to understand if a loan has defaulted **before** a loan is issued\nThis is therefore data leakage and issue_d should be dropped "}}