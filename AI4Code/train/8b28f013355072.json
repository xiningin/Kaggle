{"cell_type":{"01f46324":"code","2792a682":"code","a7c9ba52":"code","e342af2e":"code","7f5726ea":"code","c55e9e2a":"code","96d7e0ca":"code","47e2c17f":"code","d85f4656":"code","f1b3522f":"code","b94aa03f":"code","573630e8":"code","f3040709":"code","0acefd22":"markdown"},"source":{"01f46324":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n#Importing the Dataset\ndf =pd.read_csv(\"..\/input\/googleplaystore_user_reviews.csv\",encoding=\"latin1\")","2792a682":"#Now Lets set dataset which collumns we are interested\ndf = pd.concat([df.Translated_Review, df.Sentiment], axis = 1)","a7c9ba52":"#Now eleminate the nan value becasue they can affect our model\ndf.dropna(axis = 0, inplace = True)","e342af2e":"#Replace the Sentiment by Encoding, Positive=0, Negative = 1, Netural= 2\ndf.Sentiment = [0 if i==\"Positive\" else 1 if i== \"Negative\" else 2 for i in df.Sentiment]","7f5726ea":"#Now lets Cleaning the Text\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ntext_list = []\nfor i in df.Translated_Review :\n    review = re.sub('[^a-zA-Z]', ' ', i)\n    review = review.lower() \n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review) \n    text_list.append(review)  ","c55e9e2a":"# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1000)\nx = cv.fit_transform(text_list).toarray()\ny = df.iloc[:, 1].values","96d7e0ca":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)","47e2c17f":"# Now Fitting Naive Bayes classifier to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)","d85f4656":"# Predicting the Test set results\ny_pred = classifier.predict(x_test)\n","f1b3522f":"# Making the Confusion Matrix and find Accuracy\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)    \naccuracy = accuracy_score(y_test, y_pred)\nprint(cm)\nprint(accuracy)","b94aa03f":"#Now Fitting Random Forest Classifier to the Traning set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, random_state = 0)\nclassifier.fit(x_train, y_train)","573630e8":"# Predicting the Test set results\ny_pred = classifier.predict(x_test)","f3040709":"# Making the Confusion Matrix and find Accuracy\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)    \naccuracy = accuracy_score(y_test, y_pred)\nprint(cm)\nprint(accuracy)","0acefd22":"#**Conculation**\n#For NLP Naive Bayes classifier and Random Forest Classifier both are used. In this particular case Random Forest gives us better  result\n"}}