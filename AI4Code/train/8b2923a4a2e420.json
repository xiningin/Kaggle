{"cell_type":{"6e35ed82":"code","d72a215f":"code","8351e6cf":"code","3244172e":"code","b252c266":"code","49597140":"code","830285e9":"code","65eeb200":"code","44b66437":"code","03f358f0":"code","ae9a05c4":"code","54c2d567":"code","c53e135e":"code","8a110414":"code","094ca666":"code","10dad580":"code","cf73a42c":"code","f373f688":"markdown"},"source":{"6e35ed82":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.preprocessing import StandardScaler    \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","d72a215f":"train = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv',nrows=50000)\ntest = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')","8351e6cf":"X = train.drop(columns=['id','target'])\ny = train['target']\ntest = test.drop(columns=['id'])","3244172e":"X = X.fillna(X.mean())\ntest = test.fillna(test.mean())","b252c266":"sc = StandardScaler()\nX = sc.fit_transform(X)\ntest = sc.transform(test)","49597140":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)","830285e9":"EPOCHS = 15\nBATCH_SIZE = 64\nLEARNING_RATE = 0.001","65eeb200":"class TabularTrain(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n\n## test data    \nclass TabularTest(Dataset):\n    \n    def __init__(self, X_data):\n        self.X_data = X_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n    \n\n","44b66437":"train_data = TabularTrain(torch.FloatTensor(X_train), \n                       torch.FloatTensor(y_train))\n\ntest_data = TabularTest(torch.FloatTensor(X_test))","03f358f0":"train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(dataset=test_data, batch_size=1)","ae9a05c4":"X_train.shape","54c2d567":"class TabularSept(nn.Module):\n    def __init__(self):\n        super(TabularSept, self).__init__()\n        # Number of input features is 285.\n        self.layer_1 = nn.Linear(285, 64) \n        self.layer_2 = nn.Linear(64, 64)\n        self.layer_out = nn.Linear(64, 1) \n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.1)\n        self.batchnorm1 = nn.BatchNorm1d(64)\n        self.batchnorm2 = nn.BatchNorm1d(64)\n        \n    def forward(self, inputs):\n        x = self.relu(self.layer_1(inputs))\n        x = self.batchnorm1(x)\n        x = self.relu(self.layer_2(x))\n        x = self.batchnorm2(x)\n        x = self.dropout(x)\n        x = self.layer_out(x)\n        \n        return x","c53e135e":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n##############","8a110414":"model = TabularSept()\nmodel.to(device)\nprint(model)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","094ca666":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum\/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","10dad580":"losss = []\naccs = []\nmodel.train()\nfor e in range(1, EPOCHS+1):\n    epoch_loss = 0\n    epoch_acc = 0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_pred = model(X_batch)\n        \n        loss = criterion(y_pred, y_batch.unsqueeze(1))\n        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n        \n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        losss.append(epoch_loss)\n        accs.append(epoch_acc)\n\n    print(f'Epoch {e+0:03}: | Loss: {epoch_loss\/len(train_loader):.5f} | Acc: {epoch_acc\/len(train_loader):.3f}')","cf73a42c":"y_pred_list = []\nmodel.eval()\nwith torch.no_grad():\n    for X_batch in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_list.append(y_test_pred.cpu().numpy())\n\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]","f373f688":"# Simplest NN Baseline with Pytorch (for Beginners)"}}