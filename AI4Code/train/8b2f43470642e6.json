{"cell_type":{"a49d168d":"code","7667f86a":"code","8ade0563":"code","cd9c34f6":"code","12504a28":"code","3d6789b0":"code","38afd21c":"code","709a4385":"code","861933f6":"code","65c7b786":"code","c82c6cc2":"code","f6dcb158":"code","8fd8fd14":"code","c8df1b44":"code","959d3e8a":"code","4035d314":"code","d25ab388":"code","bc5de7c7":"code","d897137a":"code","4e00183c":"code","ed3c6441":"code","1dfd2de9":"code","6742f5fb":"code","3a0103e5":"code","1f0bae04":"code","c4b4a546":"code","6ae7b7e8":"code","79399d98":"code","d27d9c41":"code","654f12b1":"code","e1d6ca56":"code","3abe4e09":"code","b6e44431":"code","49b1d668":"code","0b0439ab":"code","8089028b":"markdown","6842bf64":"markdown","6887d4f5":"markdown","69ba2060":"markdown","a277af8d":"markdown","42bee502":"markdown","2237723e":"markdown","05b782ea":"markdown","f933bb4c":"markdown","eb10f900":"markdown","4a741cd0":"markdown","318f3511":"markdown","1e2d48a4":"markdown","25caf067":"markdown","e0997ac1":"markdown"},"source":{"a49d168d":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7667f86a":"# \uc704\uc758 \uac01 \ub370\uc774\ud130 \uacbd\ub85c\ub97c \ud1b5\ud574 csv \ud30c\uc77c 3\uac1c\ub97c \ubd88\ub7ec\uc634(\uc77d\uc74c)\ntrain = pd.read_csv('\/kaggle\/input\/dlp-private-competition-dataset-modificated\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/dlp-private-competition-dataset-modificated\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/dlp-private-competition-dataset-modificated\/submission.csv')\n# tarin, test, submission\uc758 \ud589,\uc5f4\uc218 \uc870\ud68c\nprint(train.shape, test.shape, submission.shape)\n# tarin, test, submission \uc758 data type, \ubc30\uc5f4, \ud2b9\uc9d5 \ub4f1\uc744 \ud655\uc778\ndisplay(train.head(3), test.head(3), submission.head(3))","8ade0563":"# modeling \uc804 \uc0c1\uad00\ub3c4 \ubd84\uc11d (target\uac12\uacfc \uac01 column\uc758 \uc0c1\uad00\uad00\uacc4 \uc2dc\uac01\ud654)\nimport matplotlib.pyplot as plt\nprint(train.corr()['Y'].sort_values(ascending=False)[:10])\nprint(train.corr()['Y'].sort_values(ascending=True)[:10])\n\ncorr_with_Y = train.corr()[\"Y\"].sort_values(ascending=False)[:10]\nplt.figure(figsize=(20,6))\ncorr_with_Y.drop(\"Y\").plot.bar()\nplt.show();","cd9c34f6":"import seaborn as sns\n# saleprice correlation matrix\ncorrmat = train.corr()\n# corr_num = 15 #number of variables for heatmap\ncorr_num = 10\ncols_corr = corrmat.nlargest(corr_num, 'Y')['Y'].index\ncorr_mat_sales = np.corrcoef(train[cols_corr].values.T)\nsns.set(font_scale=1.25)\nf, ax = plt.subplots(figsize=(12, 9))\nhm = sns.heatmap(corr_mat_sales, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 7}, yticklabels=cols_corr.values, xticklabels=cols_corr.values)\nplt.show()","12504a28":"import missingno as msno\nmsno.matrix(df=train, figsize=(8, 8), color=(0.8, 0.5, 0.2))","3d6789b0":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.scatter(x = train['C109'], y = train['Y'])\nplt.ylabel('Y', fontsize=13)\nplt.xlabel('C109', fontsize=13)\nplt.show()","38afd21c":"#  Joint plot \uadf8\ub9ac\uae30\nsns.jointplot(x=train['C109'], y=train['Y'], kind='reg')","709a4385":"# outlier: \ud3c9\uade0\uce58\uc5d0\uc11c \ud06c\uac8c \ubc97\uc5b4\ub098\uc11c \ub2e4\ub978 \ub300\uc0c1\ub4e4\uacfc \ud655\uc5f0\ud788 \uad6c\ubd84\ub418\ub294 \ud45c\ubcf8\ntrain[train['Y'] > 80].index","861933f6":"train = train.drop([4476],0)\nfig, ax = plt.subplots()\nax.scatter(x = train['C109'], y = train['Y'])\nplt.ylabel('Y', fontsize=13)\nplt.xlabel('C109', fontsize=13)\nplt.show()","65c7b786":"fig = plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.distplot(train['Y'])\nplt.title('Y distribution')\nplt.subplot(1,2,2)\nsns.distplot(np.log1p(train['Y']))\nplt.title('Y distribution after normalization')\n# skewness (\uc65c\ub3c4, \uce58\uc6b0\uc9c4 \uc815\ub3c4) : 3(mean-median) \/ standard deviation)\n# skewness = 0 : normally distributed.\n# skewness > 0 : more weight in the left tail of the distribution.\n# skewness < 0 : more weight in the right tail of the distribution. \n# kurtosis (\ucca8\ub3c4, \ubfb0\uc871\ud55c \uc815\ub3c4) : E ((X-mean)\/ standard deviation)^4\nprint('skewness: %f' % train['Y'].skew())\nprint('kurtosis: %f' % train['Y'].kurt())\nprint('skewness after normalization: %f' % np.log1p(train['Y']).skew())\nprint('kurtosis after normalization: %f' % np.log1p(train['Y']).kurt())","c82c6cc2":"test['Y'] = 9999\ntest.head()\n# test\uc14b\uc5d0 Y\uac12\uc5d0 9999\ub97c insert (\ub098\uc911\uc5d0 \ubd84\ud560\ub54c Y\uac12\uc774 9999\uc778 \uac83\ub4e4\ub9cc test\ub85c \ube7c\uc8fc\uba74 \ub428)","f6dcb158":"total = pd.concat([train,test],0, sort = True)     # train\uacfc test\ub97c \ud569\uccd0\uc90c \nprint(train.shape, test.shape, \"--> \",total.shape)     # train\uacfc test\uac00 \ud569\uccd0\uc838\uc11c total\uc774 \ub418\ub294\ub370 shape\ub97c \ud655\uc778\ntotal.head()     # total\uc758 \uc55e\uc5d0 5\uac1c \ud589 \ud655\uc778(\uc798 \ud569\uccd0\uc84c\ub098..)","8fd8fd14":"total.tail()     # total\uc758 \ub9c8\uc9c0\ub9c9 5\uac1c \ud589 \ud655\uc778(\uc798 \ud569\uccd0\uc84c\ub098..)","c8df1b44":"total = total.drop(['ID'], 1)\ntotal.head(3)","959d3e8a":"# \ubb38\uc790\ud615 \ubcc0\uc218\uac00 \uc18d\ud574\uc788\ub294 Column indexing\ncate_col = list(total.dtypes[total.dtypes == 'object'].index)  ","4035d314":"from sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder()\n\nlbl.fit(list(total['A'].values))\ntotal['A'] = lbl.transform(list(total['A'].values))\ntotal.head(3)","d25ab388":"for c in cate_col:\n    lbl.fit(list(total[c].values))\n    total[c] = lbl.transform(list(total[c].values))  # unique_column\uc744 \uc804\ubd80 label_encoding\ud568\ntotal.head(3)","bc5de7c7":"cate_col = ['END_TM', 'A', 'B']\n\nfor col in cate_col:\n    total[col] = total[col].astype('category')\n    \n# END_TM, A, B\ub294 Label Encoding\uc73c\ub85c \uc22b\uc790\ub85c \ubc14\uafb8\uc5c8\uc9c0\ub9cc \uc6d0\ub798\ub294 category \uac12\uc784,\n# Label Encoding\uc73c\ub85c 1,2,3,4,5,... \uc73c\ub85c \ubc14\ub00c\uc5c8\uae30 \ub54c\ubb38\uc5d0 LightGBM \ubaa8\ub378\uc740 \uadf8\ub0e5 \uc5f0\uc18d\uc801\uc778 \uac12\uc73c\ub85c \uc774\ud574\ud568\n# \uadf8\ub807\uae30 \ub54c\ubb38\uc5d0 \ud574\ub2f9 column\uc744 \uc22b\uc790\uc774\uc9c0\ub9cc Category\ub85c \ubcc0\ud658\uc2dc\ucf1c\uc918\uc57c \ud568","d897137a":"pd.set_option('display.max_columns', 10000)\n# head() \ucd9c\ub825\uc2dc\uc5d0 \uc804\uccb4\ub85c \ubcf4\uc774\uac8c \ub9cc\ub4e4\uc5b4 \uc90c, \ub113\uc774\ub97c \ub298\ub824\uc90c, \ud654\uba74\n\ntotal.head()     # \ub0a0\uc9dc\uae4c\uc9c0 \uc804\ubd80 Label Encoding \ub418\uc5c8\uc74c..(\ud544\uc694\ud558\ub2e4\uba74 Label Encoding \uc804\uc5d0 \ub530\ub85c Feature Engineering \uc9c4\ud589)","4e00183c":"round(total.isnull().sum() \/ len(total) * 100, 2).sort_values(ascending=False)[0:25]","ed3c6441":"missing = list(round(total.isnull().sum() \/ len(total) * 100, 2).sort_values(ascending=False)[:25].index)\nmissing","1dfd2de9":"#\ube48 \uac12\uc744 \ubaa8\ub450 \uc911\uc559\uac12\uc73c\ub85c \ucc44\uc6b0\uae30\nfor col in missing:\n    total[col] = total[col].fillna(total[col].median())","6742f5fb":"# \ube48 \uce78\uc774 \ubaa8\ub450 \ucc44\uc6cc\uc84c\ub294\uc9c0 \ud655\uc778\nround(total.isnull().sum() \/ len(total) * 100, 2).sort_values(ascending=False)[:5]","3a0103e5":"test = total[total['Y'] == 9999]     # total['Y']\uac00 9999\uc778 \uac12\ub9cc test\ub85c \ubf51\uc544\uc90c\nprint(total.shape,test.shape)\ntest.head()     # test\uc5d0\uc11c\ub294 Y\uac12\uc740 \ud544\uc694 \uc5c6\uae30 \ub54c\ubb38\uc5d0 \uc0ad\uc81c\ud574\uc918\uc57c\ud568","1f0bae04":"test = test.drop(['Y'],1)\nprint(test.shape)\ntest.head() ","c4b4a546":"train = total[total['Y'] != 9999]     # total['Y']\uac00 9999\uc774 \uc544\ub2cc \uac12\ub9cc train\uc73c\ub85c \ubf51\uc544\uc90c\nprint(train.shape)\ntrain.head()     # \uc798 \ubd84\ub9ac\ub418\uc5c8\uad70..","6ae7b7e8":"y = pd.DataFrame(train['Y'])\ny.head()","79399d98":"X = train.drop(['Y'],1)\nX.head()","d27d9c41":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split (X,y, random_state=0)","654f12b1":"import lightgbm as lgb\nmodel = lgb.LGBMRegressor (objective = 'regression', num_leaves=144,\n                         learning_rate=0.005,n_estimators=720, max_depth=13,\n                         metric='rmse', is_training_metric=True, max_bin=55,\n                         bagging_fraction=0.8, verbose=-1, bagging_freq=5, feature_fraction=0.9)\n\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\n# model = Ridge(random_state=0)\n# model = Lasso(random_state=0)\n# model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n\nfrom catboost import CatBoostRegressor\n# model = CatBoostRegressor(verbose=0, n_estimators=100)\nfrom sklearn.ensemble import RandomForestRegressor # regressor (\uc5f0\uc18d\ud615 \uc790\ub8cc)\n# model = RandomForestRegressor(random_state=0)","e1d6ca56":"model.fit(X_train, y_train)\n#=== MSE\ub85c \ud3c9\uac00\ud560 \uacbd\uc6b0 \uc544\ub798\uc640 \uac19\uc774 \uc9c4\ud589===#\nfrom sklearn.metrics import mean_squared_error\n\npred_train = model.predict(X_train)\npred_valid = model.predict(X_valid)\nprint(mean_squared_error(pred_train, y_train))\nprint(mean_squared_error(pred_valid, y_valid))\n\n# Lgbm: 8.76, 18.64\n# Lidge: 24.57, 3198.74\n# Rasso: 44.37, 48.40\n# Elasticnet: 41.259, 51.518\n# catboost regressor: 19.22, 23.76\n# Randomforest regressor: 3.528, 19.787\n\n# #=== House Price\uc5d0\uc11c RMSE \uac12\uc744 \uad6c\ud558\ub294 \uacbd\uc6b0 \uc544\ub798\uc640 \uac19\uc774 \uc9c4\ud589===#\n# from sklearn.metrics import mean_squared_error\n\n# pred_train = lgbm.predict(X_train)\n# pred_valid = lgbm.predict(X_valid)\n\n# print(np.sqrt(mean_squared_error(np.log1p(y_train), np.log1p(pred_train))))\n# print(np.sqrt(mean_squared_error(np.log1p(y_valid), np.log1p(pred_valid))))\n\n# # \uc704\uc5d0\ub294 MSE\uc774\uba70, RMSE\ub97c \uad6c\ud560\ub54c\ub294 \ud574\ub2f9\uc73c\ub85c \uc9c4\ud589","3abe4e09":"import matplotlib.pyplot as plt\nplot1 = pd.DataFrame(y_valid).reset_index(drop=True)\nplot2 = pd.DataFrame(pred_valid)\n\nfig, axes = plt.subplots(1,1,figsize=(14, 6))\nplot1.sort_index().plot(ax=axes).set_xlabel('index');\nplot2.sort_index().plot(ax=axes).set_ylabel('value');\naxes.legend(['y_valid', 'pred_valid']);\naxes.set_title('y_value vs Predicted_value', fontsize=16);","b6e44431":"# feature importance \uc870\ud68c\nlgb.plot_importance(model)\nplt.rcParams['figure.figsize'] = [5,25]\nplt.show()","49b1d668":"pred_test = model.predict(test)\npred_test","0b0439ab":"submission['Y'] = pred_test\nsubmission.to_csv(\"submission_fianl.csv\", index=False)\nsubmission.tail()","8089028b":"# Import Library\n- \ubd84\uc11d\uc5d0 \ud544\uc694\ud55c Library\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4","6842bf64":"# (\u2605\uc704\uc5d0 RMSE \ubcf4\ucda9\uc124\uba85) House Price \ub300\ud68c Scoring \ubc29\uc2dd\n\n- House Price\uc5d0\uc11c\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc2e4\uc81c\uac12\uacfc \uc608\uce21\uac12\uc758 Log\ub97c \uc50c\uc5b4\uc11c RMSE\ub97c \uad6c\ud558\ub77c\uace0 \ud558\uc600\uc74c\n  > Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n- RMSE\ub294 MSE\uc758 root\ub97c \ucde8\ud574\uc900 \uac12\uc784, \uae30\uc874\uc5d0 MSE\ub97c \uad6c\ud588\ub358 \uc2dd\uc5d0 np.sqrt(Numpy\uc758 square root)\ub97c \uc50c\uc5b4\uc90c\uc73c\ub85c\uc368 \uac12\uc744 \uad6c\ud574\uc8fc\uc5b4\uc57c \ud568\n\n\n\n![](http:\/\/)","6887d4f5":"# Merge train & test dataset (for Feature Engineering)\n- Feature Engineering\uc744 \ud560\ub54c Train\uacfc Test dataset\uc744 \ub3d9\uc2dc\uc5d0 \uc9c4\ud589\ud574\uc57c \ud568\n- \ud560\ub54c\ub9c8\ub2e4 \ub530\ub85c \uc9c4\ud589\ud558\uba74 \ubd88\ud3b8\ud558\uae30 \ub54c\ubb38\uc5d0 \ud569\uccd0\ub193\uace0 \uc9c4\ud589\ud568(\ucd94\ud6c4 \ub2e4\uc2dc Train\uacfc Test\ub85c \ubd84\ub9ac\ud568)","69ba2060":"# Split the dataset(3) (X, y -> X_train, y_train, X_valid, y_valid)\n- \uc55e\uc5d0\uc11c \ubd84\ub9ac\ud55c X\uc640 y\ub97c train\uacfc valid\ub85c \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \ub370\uc774\ud130 \uc138\ud2b8\ub97c \ubd84\ub9ac\ud558\ub294 \uc774\uc720\ub294 \ubaa8\ub378\uc774 overfitting\uc774 \ub418\uc5c8\ub294\uc9c0 \uac80\uc99d\ud558\uae30 \uc704\ud568\uc785\ub2c8\ub2e4.\n- \uc774\ud574\uac00 \uc5b4\ub824\uc6b8 \uc2dc \uae30\uc874\uc5d0 \ubc30\ud3ec\ud55c Machine Learning Pipeline\uc744 \ucc38\uace0\ud574\uc8fc\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.","a277af8d":"# Split the dataset (total -> train \/ test)\n- \ubaa8\ub4e0 Feature Engineering\uc744 \uc9c4\ud589\ud588\uae30 \ub54c\ubb38\uc5d0 \ub2e4\uc2dc \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \uae30\uc874\uc5d0 total\ub85c \ud569\uccd0\uc9c4\uac83\uc744 \ub2e4\uc2dc train\uacfc test\ub85c \ubd84\ub9ac\ud569\ub2c8\ub2e4.","42bee502":"# Predict wafer thick (with test dataset)\n- \uc55e\uc5d0 \uac80\uc99d\uc744 \ud1b5\ud574 \ubaa8\ub378\uc774 \ud559\uc2b5\uc774 \uc798 \ub418\uc5c8\ub294\uc9c0 \ud655\uc778\uc774 \ub418\uc5c8\ub2e4\uba74 Test dataset\uc744 \uac00\uc9c0\uace0 \uc608\uce21\ud574\ubd04","2237723e":"# Split the dataset(2) (train -> X \/ y)\n- train \ub370\uc774\ud130\ub97c X\ubcc0\uc218\uc640 y\ubcc0\uc218\ub85c \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \ud574\ub2f9\uc740 \ubaa8\ub378\uc744 \ub3cc\ub9ac\uae30\uc804\uc5d0 \uc0ac\uc804 \uacfc\uc815\uc774\ubbc0\ub85c \ud2b9\ubcc4\ud55c \uc774\uc720\uc5c6\uc774 \uc9c4\ud589\ub429\ub2c8\ub2e4.","05b782ea":"### \ube48 \uac12 \ucc44\uc6b0\uae30","f933bb4c":"# Find column having a string data\n- Model\uc740 string(\ubb38\uc790) data\ub294 \ubd84\uc11d\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\n- dataset\uc5d0\uc11c string\uc744 \uac00\uc9c0\uace0 \uc788\ub294 column\uc744 \ucc3e\uc544\uc11c \uc22b\uc790\ub85c \ubc14\uafd4\uc8fc\uac70\ub098 \uc9c0\uc6cc\uc57c Model\uc774 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","eb10f900":"# Train and Calculate MSE (Loss function)\n- X_train \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uc608\uce21\uac12 Pred_train\uacfc y_train\uac04\uc758 \ucc28\uc774 --- (1)\n- X_valid \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uc608\uce21\uac12 Pred_valid\uc640 y_valid\uac04\uc758 \ucc28\uc774 --- (2)\n- (1)\uacfc (2)\uac00 \ucc28\uc774\uac00 \ud06c\ub2e4\uba74 Overfitting\uc774\ubbc0\ub85c \ud5a5\ud6c4 \uc608\uce21\uc5d0 \uc5b4\ub824\uc6b8 \uc218 \uc788\uc74c","4a741cd0":"### EDA (exploratory data analysis)","318f3511":"# Import Model (LightGBM)","1e2d48a4":"# Import Dataset\n- \ubd84\uc11d\uc5d0 \ud544\uc694\ud55c Dataset\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4","25caf067":"# Change data from string to numeric(using Label Encoding)\n- \uc55e\uc5d0\uc11c \ucc3e\uc544\uc900 string data\ub97c numerical data(\uc22b\uc790\ud615)\uc73c\ub85c \ubc14\uafd4\uc90d\ub2c8\ub2e4.\n- \uc5ec\uae30\uc11c\ub294 Label Encoding\uc774\ub77c\ub294 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. (Label Encoding\uc740 \uc784\uc758\ub85c \uc21c\uc11c\ub300\ub85c 1\ubd80\ud130 \uc9c0\uc815\ud574\uc11c \ubc14\uafd4\uc90d\ub2c8\ub2e4.)","e0997ac1":"# Submit the result\n- test dataset\uc744 \uac00\uc9c0\uace0 \uc608\uce21\ud55c \uacb0\uacfc\ub97c submission dataset\uc5d0 import\ud558\uc5ec kaggle\uc5d0 \uc81c\ucd9c!"}}