{"cell_type":{"6a98d249":"code","370c4d9c":"code","bfc9833e":"code","c67605bb":"code","49a15491":"code","a5e02f4e":"code","e07c05a8":"code","a985824d":"code","3416e9a9":"code","bf34e485":"code","305a75a7":"code","3dffd4ed":"code","aa28754a":"code","df1234a0":"code","cc5f7c48":"code","6c429c21":"code","5e6023ca":"code","398e03fd":"code","18dc0aeb":"code","95dacd2b":"code","f408cae1":"code","6fce07a8":"code","61c50d8e":"code","d649a6a6":"code","227fad1a":"code","4b7f90a7":"code","f7422e8f":"code","fe9b5dba":"code","af7a9b1f":"code","13289dba":"code","fe22d65c":"code","8ebd0012":"code","a75ecad8":"markdown","37e1f78e":"markdown","3e6560ce":"markdown","d1495bc2":"markdown","1eba0ebe":"markdown","08b17e4a":"markdown","2c3c50aa":"markdown","3b3b6aea":"markdown","aa53225a":"markdown","a7177265":"markdown","4e0debac":"markdown","ba1f7c2e":"markdown","96c94381":"markdown","a5d3060a":"markdown","b8877745":"markdown","941231f6":"markdown","093f7883":"markdown"},"source":{"6a98d249":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # plotting\n%matplotlib inline\n\nfrom sklearn.preprocessing import OrdinalEncoder\n\nimport missingno as msno\n\nimport warnings\nwarnings.filterwarnings('ignore')","370c4d9c":"train_df = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nsample_df = pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")\n\ntrain_df[\"isTrain\"] = True\ntest_df[\"isTrain\"] = False\n\ntt = pd.concat([train_df, test_df]).reset_index(drop=True).copy()","bfc9833e":"train_df.head(4)","c67605bb":"categorical_features = ['key', 'audio_mode', 'time_signature']\n\nnumerical_features = ['song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'audio_valence']\n\n# All 13 features\nfeatures = categorical_features + numerical_features\n\ntarget = 'song_popularity'\n\nmsno.matrix(train_df[features+[target]], figsize=(10, 6), fontsize=10)","49a15491":"features_with_null = [feature for feature in features if train_df[feature].isnull().values.any()]\nfeatures_with_null","a5e02f4e":"train_df[\"key\"].fillna(0)","e07c05a8":"song_duration_mean = train_df[\"song_duration_ms\"].mean() # Could be median\n\ntrain_df[\"song_duration_ms_imputed\"] = train_df[\"song_duration_ms\"].fillna(song_duration_mean)\n\ntrain_df.loc[train_df[\"song_duration_ms\"].isna()][[\"song_duration_ms\", \"song_duration_ms_imputed\"]].head(3)\n","a985824d":"# As an example, by audio_mode\n\nsd_mean_map = train_df.groupby(\"audio_mode\")[\"song_duration_ms\"].mean().to_dict()\nsd_mean_map","3416e9a9":"sd_mean_series = train_df[\"audio_mode\"].map(sd_mean_map)\nsd_mean_series","bf34e485":"train_df[\"song_duration_ms_imputed\"] = train_df[\"song_duration_ms\"].fillna(sd_mean_series)","305a75a7":"train_df.loc[train_df[\"song_duration_ms\"].isna()][[\"song_duration_ms\", \"song_duration_ms_imputed\"]].head(5)","3dffd4ed":"key_target_map = train_df.groupby(\"key\")[target].mean().to_dict()\ntrain_df[target].map(key_target_map)","aa28754a":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\", add_indicator=False)","df1234a0":"ax = train_df['danceability'].plot(\n    kind='hist', bins=50, \n    title='distribution of song_duration'\n)\nax.axvline(train_df['danceability'].mean(), color='black')\nax.axvline(train_df['danceability'].median(), color='orange')","cc5f7c48":"# Fit \/ Transform on train, transform only on val\/test\n\ntr_imp = imputer.fit_transform(train_df[features])\ntest_imp = imputer.transform(test_df[features])","6c429c21":"# For kaggle competition you can kind of cheat by fitting on all data\n\ntt_impute = imputer.fit_transform(tt[features])\ntt_simple_impute = pd.DataFrame(tt_impute, columns=features)\ntt_simple_impute[\"isTrain\"] = tt.isTrain\ntt_simple_impute.head()","5e6023ca":"tt_simple_impute.key.unique()","398e03fd":"from sklearn.experimental import enable_iterative_imputer # noqa\nfrom sklearn.impute import IterativeImputer","18dc0aeb":"%%time\nit_imputer = IterativeImputer(max_iter=10)\ntrain_iterimp = it_imputer.fit_transform(train_df[features])\ntest_iterimp = it_imputer.transform(test_df[features])\n\n# Fit and transform on train + test\ntt_iterimp = it_imputer.fit_transform(tt[features])\n\n# Create train test imputed dataframe\ntt_iter_imp_df = pd.DataFrame(tt_iterimp, columns=features)\ntt_iter_imp_df[\"isTrain\"] = tt.isTrain\ntt_iter_imp_df.head()","95dacd2b":"tt_iter_imp_df.key.unique()","f408cae1":"%%time\nfrom sklearn.impute import KNNImputer\n\nknn_imptr = KNNImputer(n_neighbors=1)\ntrain_knnimp = knn_imptr.fit_transform(train_df[features])\ntest_knnimp = knn_imptr.transform(test_df[features])\ntt_knnimp = knn_imptr.fit_transform(tt[features])\ntt_imp = pd.DataFrame(tt_knnimp, columns=features)\n\n# Create KNN Train\/Test imputed dataframe\ntt_knn_imp_df = pd.DataFrame(tt_imp, columns=features)\ntt_knn_imp_df[\"isTrain\"] = tt.isTrain\ntt_knn_imp_df[target] = tt[target]\ntt_knn_imp_df.head()","6fce07a8":"tt_knn_imp_df.key.unique()","61c50d8e":"# !rm -r kuma_utils\n!git clone https:\/\/github.com\/analokmaus\/kuma_utils.git","d649a6a6":"import sys\nsys.path.append(\"kuma_utils\/\")\nfrom kuma_utils.preprocessing.imputer import LGBMImputer","227fad1a":"%%time\nlgbm_imtr = LGBMImputer(n_iter=100, verbose=True)\n\ntrain_lgbmimp = lgbm_imtr.fit_transform(train_df[features])\ntest_lgbmimp = lgbm_imtr.transform(test_df[features])\n\ntt_lgbmimp = lgbm_imtr.fit_transform(tt[features])\ntt_imp = pd.DataFrame(tt_lgbmimp, columns=features)\n\n# Create LGBM Train\/Test imputed dataframe\ntt_lgbm_imp_df = pd.DataFrame(tt_imp, columns=features)\ntt_lgbm_imp_df[\"isTrain\"] = tt.isTrain\ntt_lgbm_imp_df.head()","4b7f90a7":"tt_lgbm_imp_df.key.unique()","f7422e8f":"lgbm_plot = tt_lgbm_imp_df[tt_lgbm_imp_df.isTrain][features_with_null]\nlgbm_plot['Imputer'] = 'LGMB imp'\n\nknn_plot = tt_knn_imp_df[tt_knn_imp_df.isTrain][features_with_null]\nknn_plot['Imputer'] = 'KNN imp'\n\niterative_plot = tt_iter_imp_df[tt_iter_imp_df.isTrain][features_with_null]\niterative_plot['Imputer'] = 'Iterative imp'\n\nsimple_plot = tt_simple_impute[tt_simple_impute.isTrain][features_with_null]\nsimple_plot['Imputer'] = 'Simple imp'\n\noriginal_plot = train_df[features_with_null]\noriginal_plot['Imputer'] = 'None'\n\ncompare_imputed = pd.concat([original_plot, simple_plot, iterative_plot, knn_plot, lgbm_plot]).reset_index(drop=True).copy()\n\ni = 0\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(4, 2, figsize=(24,16))\n\nfor feature in features_with_null:\n    i += 1\n    plt.subplot(4, 2, i)\n    sns.distplot(lgbm_plot[feature], hist=False, label='lgbm', color='silver', kde_kws={'linewidth':3})\n    sns.distplot(knn_plot[feature], hist=False, label='KNN', color='lime', kde_kws={'linewidth':3})\n    sns.distplot(iterative_plot[feature], hist=False, label='Iterative', color='r')\n    sns.distplot(simple_plot[feature], hist=False, label='Simple', color='orange')\n    sns.distplot(original_plot[feature], hist=False, label='Original', color='b', kde_kws={'linestyle':'--','linewidth':1})\n    \n    # Didn't managed this to work:\n    #sns.displot(data=compare_imputed, x=feature, hue='Imputer', kind=\"kde\")\n    \n    plt.xlabel(feature, fontsize=12)\n    locs, labels = plt.xticks()\n    plt.tick_params(axis='x', which='major', labelsize=10, pad=-2)\n    plt.tick_params(axis='y', which='major', labelsize=10)\n    \nplt.show();","fe9b5dba":"modal_map = {0: 'minor', 1: 'Major'}\ntrain_df[\"tonal_mode\"] = train_df.audio_mode.map(modal_map)\ntt_knn_imp_df[\"tonal_mode\"] = tt_knn_imp_df.audio_mode.map(modal_map)\n\nkey_map = {0: 'C', 1: 'C#\/Db', 2: 'D', 3: 'D#\/Eb', 4: 'E', 5: 'F', 6: 'F#\/Gb', 7: 'G', 8: 'G#\/Ab', 9: 'A', 10: 'A#\/Bb', 11: 'B'}\ntrain_df[\"key_name\"] = train_df.key.map(key_map).fillna('Unknown')\ntt_knn_imp_df[\"key_name\"] = tt_knn_imp_df.key.map(key_map).fillna('Unknown')\n\ntrain_df[\"tonality\"] = train_df[\"key_name\"] + \" \" + train_df[\"tonal_mode\"]\ntt_knn_imp_df[\"tonality\"] = tt_knn_imp_df[\"key_name\"] + \" \" + tt_knn_imp_df[\"tonal_mode\"]","af7a9b1f":"feature = \"tonality\"\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nax1 = sns.countplot(\n    x=feature, hue=target, data=train_df, palette=\"Set2\", \n    order = train_df.groupby(feature)['id'].count().sort_values(ascending = False).index,\n)\n\nnew_labels = ['Not Popular', 'Popular']\n\nax1.legend(bbox_to_anchor=(1.00, 0.45), title='Popularity', labels = new_labels)\nax1.set_title(f\"Target distribution by {feature}, sort by song count\")\n\nax2 = ax1.twinx()\nax2.grid(None)\n\n# We need to set the dataframe with same order as arder set in ax1\nlineplot_df = train_df.groupby(feature).agg(popularity_percent=(target, np.mean), total_song_count=(\"id\", \"count\"),).reset_index().sort_values(by=['total_song_count'], ascending=False)\n\nax2 = sns.lineplot(\n        x=feature, y='popularity_percent', data=lineplot_df, color='royalblue', ax=ax2, \n        marker='s', linestyle='-', linewidth=.0\n)\n\nax1.set_ylim(0, 3000)\nax1.tick_params(axis='x', rotation=90)\nax2.set_ylim(0, 0.5)\nax2.set_ylabel('% Popular Songs', color='royalblue')","13289dba":"feature = \"tonality\"\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nax1 = sns.countplot(\n    x=feature, hue=target, data=tt_knn_imp_df, palette=\"Set2\", \n    order = tt_knn_imp_df.groupby(feature)[target].count().sort_values(ascending = False).index,\n)\n\nnew_labels = ['Not Popular', 'Popular']\n\nax1.legend(bbox_to_anchor=(1.00, 0.45), title='Popularity', labels = new_labels)\nax1.set_title(f\"Target distribution by {feature}, sort by song count\")\n\nax2 = ax1.twinx()\nax2.grid(None)\n\n# We need to set the dataframe with same order as arder set in ax1\nlineplot_df = tt_knn_imp_df.groupby(feature).agg(popularity_percent=(target, np.mean), total_song_count=(target, \"count\"),).reset_index().sort_values(by=['total_song_count'], ascending=False)\n\nax2 = sns.lineplot(\n        x=feature, y='popularity_percent', data=lineplot_df, color='royalblue', ax=ax2, \n        marker='s', linestyle='-', linewidth=.0\n)\n\nax1.set_ylim(0, 3000)\nax1.tick_params(axis='x', rotation=90)\nax2.set_ylim(0, 0.5)\nax2.set_ylabel('% Popular Songs', color='royalblue')","fe22d65c":"num_songs_by_tonality = []\nfor tone in lineplot_df.tonality:\n    num_songs = len(train_df[train_df.tonality == tone])\n    # print(\"\ud83c\udfb9\" + tone + \" \" + str(num_songs))\n    num_songs_by_tonality.append(num_songs)\n\nlineplot_df[\"original_song_count\"] = num_songs_by_tonality\nlineplot_df[\"imputed\"] = lineplot_df[\"total_song_count\"] - lineplot_df[\"original_song_count\"]\nlineplot_df[\"%imputed\"] = lineplot_df[\"imputed\"] \/ lineplot_df[\"original_song_count\"]\nlineplot_df.style.background_gradient(axis=0, cmap='YlOrRd')","8ebd0012":"lineplot_df[\"key\"] = lineplot_df[\"tonality\"].map(lambda x: str(x)[:-6])\ngrouped = lineplot_df.groupby(\"key\")[\"total_song_count\", \"original_song_count\", \"imputed\"].sum().sort_values('total_song_count', ascending=False).reset_index()\ngrouped[\"%imputed\"] = grouped[\"imputed\"] \/ grouped[\"original_song_count\"]\ngrouped.style.background_gradient(axis=0, cmap='YlOrRd')","a75ecad8":"### Iterative Imputer","37e1f78e":"## Sklearn Imputation\n- `SimpleImputer` similar to pandas `fillna`\n- `IterativeImputer`\n- `KNNImputer`","3e6560ce":"## Key anlysis","d1495bc2":"## Load competition data","1eba0ebe":"## LightGBM Imputer!!","08b17e4a":"### GroupBy fills\nSame technique as target encoding","2c3c50aa":"## Compare Imputation Distribution","3b3b6aea":"## Imputations","aa53225a":"## Import Libraries","a7177265":"#### Note: example of a created target encoded feature","4e0debac":"# Handling Missing Values\n  \n## Based on:\n- **Kaggle:** [Handling With Missing Data [Youtube Stream]](https:\/\/www.kaggle.com\/robikscube\/handling-with-missing-data-youtube-stream)\n- **Youtube:** [Handling Missing Values (with Rob Mulla)](https:\/\/youtu.be\/EYySNJU8qR0)","ba1f7c2e":"### Features and missind data","96c94381":"**To notice**: the imputer assigns decimals, but `key` is categorical!","a5d3060a":"**To notice**: the imputer assigns integers to categorical feature `key`!","b8877745":"### Pandas imputation","941231f6":"### KNN Imputer","093f7883":"### Simple Imputer"}}