{"cell_type":{"dff9ddca":"code","c4ad599c":"code","68a776fc":"code","49bafb10":"code","4d6646f8":"code","a8a50592":"code","f9c103f7":"markdown","a3817683":"markdown","ab113326":"markdown","7adee920":"markdown","6c55a5a0":"markdown"},"source":{"dff9ddca":"import gc\nimport glob\nfrom multiprocessing import cpu_count\nimport subprocess\nimport time\nimport warnings\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom albumentations import (Compose, HorizontalFlip, HueSaturationValue,\n                            Normalize, RandomBrightnessContrast, Resize,\n                            ShiftScaleRotate)\nfrom torch.utils.data import DataLoader, Dataset\n\nwarnings.filterwarnings('ignore')","c4ad599c":"LEARNING_RATE = 0.1\nBATCH_SIZE = 1024\nEPOCH = 20\nIMAGE_SIZE = 32\n\nCLASS_WEIGHT = [1.0, 1.0, 1.0, 1.25, 1.25, 2.5, 2.5, 10.0, 10.0, 10.0]\nN_CLASSES = 10\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif torch.cuda.is_available():\n    cudnn.benchmark = True","68a776fc":"class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        # if you are interested in resnet archtecture, check below link.\n        # [https:\/\/github.com\/pytorch\/vision\/blob\/master\/torchvision\/models\/resnet.py]\n        model = torchvision.models.resnet18(pretrained=False)\n\n        self.conv1 = model.conv1\n        self.bn1 = model.bn1\n        self.relu = model.relu\n        self.maxpool = model.maxpool\n        self.layer1 = model.layer1\n        self.layer2 = model.layer2\n        self.layer3 = model.layer3\n        self.layer4 = model.layer4\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # for arbital image size\n        self.fc = nn.Linear(model.fc.in_features, N_CLASSES)\n\n        for m in self.modules(): # weight initialization\n            if isinstance(m, nn.Conv2d): # remove when you use pretrained weight\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, nn.BatchNorm2d): # remove when you use pretrained weight\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        out = self.fc(x.squeeze())\n\n        return out","49bafb10":"class Imbalanced_CIFAR10_Dataset(Dataset):\n    def __init__(self, mode, visualize=False):\n        self.mode = mode\n        self.labels = pd.read_csv(\"..\/input\/train.csv\")[\"label\"].values\n        self.visualize = visualize\n\n        if mode == \"test\":\n            self.image_files = sorted(glob.glob(\"..\/input\/images\/test\/*.png\"))\n            self.labels = [0] * len(self.image_files)\n        else:  # train or valid\n            self.image_files = sorted(glob.glob(\"..\/input\/images\/train\/*.png\"))\n\n            if mode == \"train\":  # 80% training\n                self.image_files = self.image_files[\n                    0 : int(len(self.image_files) * 0.8)\n                ]\n                \n                self.labels = self.labels[0 : int(len(self.labels) * 0.8)]\n\n            else:  # 20% validation\n                self.image_files = self.image_files[int(len(self.image_files) * 0.8) :]\n                self.labels = self.labels[int(len(self.labels) * 0.8) :]\n\n        assert len(self.image_files) == len(self.labels)\n\n        self.class_weight = [(CLASS_WEIGHT[x]) for x in self.labels]\n\n        print(\"Loading {} images on memory...\".format(mode))\n        self.images = np.zeros((len(self.image_files), 32, 32, 3)).astype(\"uint8\")\n\n        for i in range(len(self.image_files)):\n            self.images[i] = cv2.imread(self.image_files[i])\n            if self.visualize and i>10:\n                break\n\n    def _augmentation(self, img):\n        #-------\n        def _albumentations(mode, visualize):\n            aug_list = []\n\n            aug_list.append(\n                Resize(IMAGE_SIZE, IMAGE_SIZE, interpolation=cv2.INTER_CUBIC, p=1.0)\n            )\n\n            if mode == \"train\": # use data augmentation only with train mode\n                aug_list.append(HorizontalFlip(p=0.5))\n\n                # if you want to use additional augmentation, add operations like below.\n                # albumentations: [https:\/\/github.com\/albu\/albumentations]\n                \"\"\"\n                aug_list.append(\n                    ShiftScaleRotate(\n                        p=1.0, shift_limit=0.0625, scale_limit=0.2, rotate_limit=15\n                    )\n                )\n                aug_list.append(RandomBrightnessContrast(p=0.5))\n                aug_list.append(\n                    HueSaturationValue(\n                        p=0.5, hue_shift_limit=5, sat_shift_limit=30, val_shift_limit=20\n                    )\n                )\n                \"\"\"\n                \n            if not visualize:\n                aug_list.append(\n                    Normalize(\n                        p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n                    )  # rgb\n                )  # based on imagenet\n\n            return Compose(aug_list, p=1.0)\n\n        def _cutout(img):\n            # [https:\/\/arxiv.org\/pdf\/1708.04552.pdf]\n            mask_value = [\n                int(np.mean(img[:, :, 0])),\n                int(np.mean(img[:, :, 1])),\n                int(np.mean(img[:, :, 2])),\n            ]\n\n            mask_size_v = int(IMAGE_SIZE * np.random.randint(10, 60) * 0.01)\n            mask_size_h = int(IMAGE_SIZE * np.random.randint(10, 60) * 0.01)\n\n            cutout_top = np.random.randint(\n                0 - mask_size_v \/\/ 2, IMAGE_SIZE - mask_size_v\n            )\n            cutout_left = np.random.randint(\n                0 - mask_size_h \/\/ 2, IMAGE_SIZE - mask_size_h\n            )\n            cutout_bottom = cutout_top + mask_size_v\n            cutout_right = cutout_left + mask_size_h\n\n            if cutout_top < 0:\n                cutout_top = 0\n\n            if cutout_left < 0:\n                cutout_left = 0\n\n            img[cutout_top:cutout_bottom, cutout_left:cutout_right, :] = mask_value\n\n            return img\n        #-------\n        \n        img = _albumentations(self.mode, self.visualize)(image=img)[\"image\"]\n        if (\n            self.mode == \"train\"\n            and np.random.uniform() >= 0.5  # 50%\n        ):\n            img = _cutout(img)\n        \n        return img\n    \n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # RGB\n\n        img = self._augmentation(img)\n        img = img.transpose(2, 0, 1)  # (h, w, c) -> (c, h, w)\n\n        assert img.shape == (3, IMAGE_SIZE, IMAGE_SIZE)\n\n        return (torch.tensor(img), torch.tensor(self.labels[idx]))","4d6646f8":"class Runner(object):\n    def __init__(self):\n        self.model, self.criterion, self.optimizer = self._build_model()\n        self.train_loss_history = []\n        self.valid_loss_history = []\n        self.valid_weighted_accuracy_history = []\n\n    def _build_model(self):\n        model = Network()\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.SGD(\n            model.parameters(),\n            lr=LEARNING_RATE,\n            momentum=0.9,\n            weight_decay=1e-4,\n            nesterov=True,\n        )\n        \n        # if you want to adam optimizer, use below optimizer.\n        \"\"\"\n        optimizer = optim.Adam(\n            model.parameters(),\n            lr=LEARNING_RATE,\n        )\n        \"\"\"\n\n        return model.to(DEVICE), criterion, optimizer\n\n    def _build_loader(self, mode):\n        dataset = Imbalanced_CIFAR10_Dataset(mode=mode)\n\n        if mode == \"train\":\n            drop_last_flag = True\n            sampler = torch.utils.data.sampler.RandomSampler(data_source=dataset.image_files)\n            \n            # if you want to sample data based on metric weight, use below sampler.\n            \"\"\"\n            sampler = torch.utils.data.sampler.WeightedRandomSampler(\n                dataset.class_weight, dataset.__len__()\n            )\n            \"\"\"\n            \n        else:  # valid, test\n            drop_last_flag = False\n            sampler = torch.utils.data.sampler.SequentialSampler(data_source=dataset.image_files)\n\n        loader = DataLoader(\n            dataset,\n            batch_size=BATCH_SIZE,\n            sampler=sampler,\n            num_workers=cpu_count(),\n            worker_init_fn=lambda x: np.random.seed(),\n            drop_last=drop_last_flag,\n            pin_memory=True,\n        )\n\n        return loader\n\n    def _calc_weighted_accuracy(self, preds, labels):\n        score = 0\n        total = 0\n\n        for (pred, label) in zip(preds, labels):\n            if pred == label:\n                score += CLASS_WEIGHT[label]\n            total += CLASS_WEIGHT[label]\n\n        return score \/ total\n\n    def _train_loop(self, loader):\n        self.model.train()\n        running_loss = 0\n\n        for (images, labels) in loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n            outputs = self.model.forward(images)\n\n            train_loss = self.criterion(outputs, labels)\n\n            self.optimizer.zero_grad()\n            train_loss.backward()\n\n            self.optimizer.step()\n\n            running_loss += train_loss.item()\n\n        train_loss = running_loss \/ len(loader)\n        \n        return train_loss\n\n    def _valid_loop(self, loader):\n        self.model.eval()\n        running_loss = 0\n\n        valid_preds, valid_labels = [], []\n\n        for (images, labels) in loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = self.model.forward(images)\n            valid_loss = self.criterion(outputs, labels)\n            running_loss += valid_loss.item()\n\n            _, predicted = torch.max(outputs.data, 1)\n\n            valid_preds.append(predicted.cpu())\n            valid_labels.append(labels.cpu())\n\n        valid_loss = running_loss \/ len(loader)\n\n        valid_preds = torch.cat(valid_preds)\n        valid_labels = torch.cat(valid_labels)\n        valid_weighted_accuracy = self._calc_weighted_accuracy(\n            valid_preds, valid_labels\n        )\n\n        return valid_loss, valid_weighted_accuracy\n\n    def _test_loop(self, loader):\n        self.model.eval()\n\n        test_preds = []\n\n        for (images, labels) in loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = self.model.forward(images)\n            _, predicted = torch.max(outputs.data, 1)\n\n            test_preds.append(predicted.cpu())\n\n        test_preds = torch.cat(test_preds)\n\n        return test_preds\n\n    #-------\n\n    def train_model(self):\n        train_loader = self._build_loader(mode=\"train\")\n        valid_loader = self._build_loader(mode=\"valid\")\n\n        scheduler = optim.lr_scheduler.MultiStepLR(\n            self.optimizer, milestones=[int(EPOCH * 0.8), int(EPOCH * 0.9)], gamma=0.1\n        )\n        \n        # scheduler examples: [http:\/\/katsura-jp.hatenablog.com\/entry\/2019\/01\/30\/183501]\n        # if you want to use cosine annealing, use below scheduler.\n        \"\"\"\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n            self.optimizer, T_max=EPOCH, eta_min=0.0001\n        )\n        \"\"\"\n        \n        for current_epoch in range(1, EPOCH + 1, 1):\n            start_time = time.time()\n            train_loss = self._train_loop(train_loader)\n            valid_loss, valid_weighted_accuracy = self._valid_loop(valid_loader)\n\n            print(\n                \"epoch: {} \/ \".format(current_epoch)\n                + \"train loss: {:.5f} \/ \".format(train_loss)\n                + \"valid loss: {:.5f} \/ \".format(valid_loss)\n                + \"valid w-acc: {:.5f} \/ \".format(valid_weighted_accuracy)\n                + \"lr: {:.5f} \/ \".format(self.optimizer.param_groups[0][\"lr\"])\n                + \"time: {}sec\".format(int(time.time()-start_time))\n            )\n\n            self.train_loss_history.append(train_loss)\n            self.valid_loss_history.append(valid_loss)\n            self.valid_weighted_accuracy_history.append(valid_weighted_accuracy)\n\n            scheduler.step()\n            \n    def make_submission_file(self):\n        test_loader = self._build_loader(mode=\"test\")\n        test_preds = self._test_loop(test_loader)\n\n        submission_df = pd.read_csv(\"..\/input\/sample_submission.csv\")\n        submission_df[\"label\"] = test_preds\n        submission_df.to_csv(\".\/submission.csv\", index=False)\n\n        print(\"---submission.csv---\")\n        print(submission_df.head())\n\n    def plot_history(self):\n        plt.figure(figsize=(20, 5))\n        plt.subplot(1, 2, 1)\n        plt.plot(\n            np.arange(EPOCH) + 1,\n            self.train_loss_history,\n            label=\"train loss\",\n            color=\"red\",\n            linestyle=\"dashed\",\n            linewidth=3.0,\n        )\n        plt.plot(\n            np.arange(EPOCH) + 1,\n            self.valid_loss_history,\n            label=\"valid loss\",\n            color=\"red\",\n            linestyle=\"solid\",\n            linewidth=3.0,\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.ylim(0, 2)\n        plt.legend()\n        plt.grid()\n\n        plt.subplot(1, 2, 2)\n        plt.plot(\n            np.arange(EPOCH) + 1,\n            self.valid_weighted_accuracy_history,\n            label=\"valid w-acc\",\n            color=\"red\",\n            linestyle=\"solid\",\n            linewidth=3.0,\n            marker=\"o\",\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.ylim(0, 1)\n        plt.legend()\n        plt.grid()\n\n        plt.show()\n        plt.savefig(\".\/loss.png\", dpi=100)","a8a50592":"def check_augmentation():\n    dataset = Imbalanced_CIFAR10_Dataset(mode=\"train\", visualize=True)\n    for i in range(10):\n        plt.figure(figsize=(15,5))\n        for j in range(8):\n            plt.subplot(1,8,j+1)\n            plt.imshow(dataset.__getitem__(i)[0].cpu().numpy().transpose(1,2,0))\n        plt.tight_layout()\n        plt.show()\n    del dataset\n    gc.collect()\n\ndef main():\n    print(\"visualizing dataset...\")\n    check_augmentation()\n    \n    print(\"Initializing...\")\n    runner = Runner()\n    \n    print(\"Start training...\")\n    runner.train_model()\n    runner.plot_history()\n    \n    print(\"Making submission file...\")    \n    runner.make_submission_file()\n\n    \nif __name__ == \"__main__\":\n    main()","f9c103f7":"----\n## \u30e2\u30c7\u30eb\u5b9a\u7fa9\u90e8 (Network\u30af\u30e9\u30b9)\n- `__init__` : \u5404\u7a2e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u521d\u671f\u5316\u3002\n- `forward` : \u9806\u4f1d\u64ad\u30b0\u30e9\u30d5\u3092\u5b9a\u7fa9\u3002\u9006\u4f1d\u64ad\u306e\u30d1\u30b9\u306f\u3053\u308c\u3092\u53c2\u7167\u3057\u3066\u81ea\u52d5\u7684\u306b\u6c7a\u307e\u308b\u3002","a3817683":"----","ab113326":"----\n## \u5404\u7a2e\u30d1\u30e9\u30e1\u30fc\u30bf\u5b9a\u7fa9\u90e8","7adee920":"----\n## \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u5b9a\u7fa9\u90e8 (Imbalanced_CIFAR10_Dataset\u30af\u30e9\u30b9)\n- `__init__` : \u5404\u7a2e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u521d\u671f\u5316\u3002\n- `_augmentation` : \u30c7\u30fc\u30bf\u6c34\u5897\u3057\u6a5f\u80fd\u3092\u8a2d\u5b9a\u3002albumentations\u304b\u3089\u5e7e\u3064\u304b\u3068\u3001\u81ea\u524d\u306ecutout\u3092\u4f8b\u3068\u3057\u3066\u5b9f\u88c5\u3057\u3066\u3044\u308b\u3002 \n- `__len__` : 1epoch\u3076\u3093\u306e\u30c7\u30fc\u30bf\u6570\u3092\u5b9a\u7fa9\u3002\n- `__getitem__` : \u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\u3092\u5b9f\u884c\u3002\u3053\u306e\u95a2\u6570\u306e\u8fd4\u308a\u5024\u306e\u96c6\u5408\u304c\u30df\u30cb\u30d0\u30c3\u30c1\u3068\u306a\u308b\u3002","6c55a5a0":"----\n## \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u5b9f\u884c\u90e8 (Runner\u30af\u30e9\u30b9)\n- `__init__` : \u5404\u7a2e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u521d\u671f\u5316\u3002\n- `_build_model` : \u30e2\u30c7\u30eb\u3001\u640d\u5931\u95a2\u6570\u3001\u6700\u9069\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u5b9a\u7fa9\u3057\u4f5c\u6210\u3002\n- `_build_loader` : \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u3092\u5b9a\u7fa9\u3057\u4f5c\u6210\u3002\n- `_calc_weighted_accuracy` : Weighted Accuracy\u8a08\u7b97\u7528\u95a2\u6570\n- `_train_loop` : Train\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5b66\u7fd2\u51e6\u7406\u3002\n- `_valid_loop` : Validation\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u63a8\u8ad6\u51e6\u7406\u3002\n- `_test_loop` : Test\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u63a8\u8ad6\u51e6\u7406\u3002\n- `train_model` : \u30e2\u30c7\u30eb\u4f5c\u6210\u3002\n- `make_submission_file` : \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3066\u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3002\n- `plot_history` : \u640d\u5931\u95a2\u6570\u3084\u8a55\u4fa1\u6307\u6a19\u306e\u56f3\u793a\u3002"}}