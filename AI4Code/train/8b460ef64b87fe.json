{"cell_type":{"9439a1ad":"code","66626641":"code","ead1fa50":"code","3296ec56":"code","529fd004":"code","ab781527":"code","ac39e95c":"code","16149dbc":"code","43fda307":"code","734d2a23":"code","1f1cb856":"code","c4022448":"code","e14fbac2":"code","337fedb1":"code","c655ee00":"code","b90c6f11":"code","668d03c5":"code","c9e601b6":"code","0a877a43":"code","349b580e":"markdown","8137ecff":"markdown","e033e678":"markdown","8765838c":"markdown","769e365b":"markdown"},"source":{"9439a1ad":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport seaborn as sns\nimport sys\nimport itertools\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\n\nimport csv\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nimport datetime","66626641":"items = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nshops = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\ncats = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ntrain = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\ntest = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/test.csv\")","ead1fa50":"# Change data type for date calculation\ntrain[\"date\"] = pd.to_datetime(train[\"date\"], format=\"%d.%m.%Y\")\n# Merge some duplicate shops\ntrain[\"shop_id\"] = train[\"shop_id\"].replace({0: 57, 1: 58, 11: 10, 40: 39})\n# Keep only shops that are in the test set\ntrain = train.loc[train.shop_id.isin(test[\"shop_id\"].unique()), :]\n# Drop training items with extreme or negative prices or sales counts\ntrain = train[(train[\"item_price\"] > 0) & (train[\"item_price\"] < 50000)]\ntrain = train[(train[\"item_cnt_day\"] > 0) & (train[\"item_cnt_day\"] < 1000)]","3296ec56":"shops['city'] = shops['shop_name'].apply(lambda x: x.split()[0])\nshops.loc[shops['city'] =='!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'\n\n# Create Label Encoder\nlabel_encoder = LabelEncoder()\n# City Feature Label Encoding \nshops['city'] = label_encoder.fit_transform(shops['city'])","529fd004":"# Create the date the product was first sold as a feature\nitems['first_sale_date'] = train.groupby('item_id').agg({'date_block_num': 'min'})['date_block_num']\n# Refine null values in items table\nitems = items.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)","ab781527":"cats['split'] = cats['item_category_name'].str.split('-')\ncats['type'] = cats['split'].map(lambda x: x[0].strip())\ncats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n# if subtype is nan then type\ncats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\ncats = cats[['item_category_id','type_code', 'subtype_code']]","ac39e95c":"# Merge data\ntrain = train.merge(shops, on='shop_id', how='left')\ntrain = train.merge(items, on='item_id', how='left')\ntrain = train.merge(cats, on='item_category_id', how='left')\ntest = test.merge(shops, on='shop_id', how='left')\ntest = test.merge(items, on='item_id', how='left')\ntest = test.merge(cats, on='item_category_id', how='left')","16149dbc":"test[\"date_block_num\"] = 34\ntest[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\ntest[\"shop_id\"] = test.shop_id.astype(np.int8)\ntest[\"item_id\"] = test.item_id.astype(np.int16)\ntest = test.drop(columns=\"ID\")","43fda307":"df = pd.concat([train, test])","734d2a23":"group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\ndf = df.merge(group, on=['date_block_num','shop_id','item_id'], how='left')\ndf['item_cnt_month'] = (df['item_cnt_month']\n                                .fillna(0)\n                                .clip(0,20) # NB clip target here\n                                .astype(np.float16))","1f1cb856":"df = df.drop(['date','shop_name','item_name','item_cnt_day'], axis=1)","c4022448":"def add_mean(df, idx_features):\n    # Check base features\n    assert (idx_features[0] == 'date_block_num') and \\\n           len(idx_features) in [2, 3]\n    \n    # Set derived feature name \n    if len(idx_features) == 2:\n        feature_name = idx_features[1] + '_mean_sales'\n    else:\n        feature_name = idx_features[1] + '_' + idx_features[2] + '_mean_sales'\n    \n    # Get average monthly sales by grouping based on base features\n    group = df.groupby(idx_features).agg({'item_cnt_month': 'mean'})\n    group = group.reset_index()\n    group = group.rename(columns={'item_cnt_month': feature_name})\n    \n    # Merge df with group based on idx_features\n    df = df.merge(group, on=idx_features, how='left')\n    \n    return df","e14fbac2":"# Create monthly average sales derived features grouped by ['date_block_num', 'item_id']\ndf = add_mean(df=df, idx_features=['date_block_num', 'item_id'])\n\n# Create monthly average sales derived features grouped by ['date_block_num', 'shop_id']\ndf = add_mean(df=df, idx_features=['date_block_num', 'shop_id'])\n\n# Create monthly average sales derived features grouped by ['date_block_num', 'item_category_id']\ndf = add_mean(df=df, idx_features=['date_block_num', 'item_category_id'])\n\n# Create monthly average sales derived features grouped by ['date_block_num', 'item_id', 'city']\ndf = add_mean(df=df, idx_features=['date_block_num', 'item_id', 'city'])\n\n# Create monthly average sales derived features grouped by ['date_block_num', 'shop_id', 'item_category_id']\ndf = add_mean(df=df, idx_features=['date_block_num', 'shop_id', 'item_category_id'])\n\n# Create monthly average sales derived features grouped by ['date_block_num', 'shop_id', 'subtype_code']\ndf = add_mean(df=df, idx_features=['date_block_num', 'shop_id', 'subtype_code'])","337fedb1":"df['duration_after_first_sale'] = df['date_block_num'] - df['first_sale_date']\ndf['month'] = df['date_block_num']%12","c655ee00":"keep_from_month = 2  # The first couple of months are dropped because of distortions to their features (e.g. wrong item age)\nvalid_month = 33\n\nvalid = df.loc[df.date_block_num == valid_month, :]\ntrain = df.loc[df.date_block_num < valid_month, :]\ntrain = train[train.date_block_num >= keep_from_month]\nX_train = train.drop(columns=\"item_cnt_month\")\ny_train = train.item_cnt_month\nX_valid = valid.drop(columns=\"item_cnt_month\")\ny_valid = valid.item_cnt_month\ntest = df.drop(columns=\"item_cnt_month\").loc[df.date_block_num == 34, :]","b90c6f11":"model_lgb = LGBMRegressor(colsample_bytree=0.8,learning_rate=0.01, max_depth=8,\n              min_child_weight=1, min_split_gain=0.0222415, n_estimators=35000,\n              num_leaves=966, reg_alpha=0.04, reg_lambda=0.073,\n              subsample=0.6)","668d03c5":"start = datetime.datetime.now()\nlgbm = model_lgb.fit(X_train, \n                     y_train,\n                     eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                     eval_metric ='rmse',\n                     early_stopping_rounds = 400,\n                     verbose =True)\nend = datetime.datetime.now()\nend-start","c9e601b6":"feature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, X_train.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp[:10].sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png')","0a877a43":"sales_prediction = model_lgb.predict(test)\ntest = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/test.csv\")\ntest_result= pd.DataFrame(sales_prediction)\ntest_result.columns = ['item_cnt_month']\npredict = test_result['item_cnt_month']\nsales_predict_submission = pd.DataFrame({'ID':test['ID'],'item_cnt_month':predict})\nsales_predict_submission.to_csv('submission.csv', index=False)","349b580e":"# 3. Modeling","8137ecff":"# 1: Importing Necessary Libraries and datasets","e033e678":"# 2. Data Preprocessing","8765838c":"This kernel is going to solve <font color=\"red\"><b> Predict Future Sales with Advanced Regression Analysis<\/b><\/font>, a popular machine learning dataset for <b>Kaggler<\/b>.<br> \nI am going to share how I work with a dataset step by step  <b>from data preparation and data analysis to statistical tests and implementing machine learning models.<\/b> <br>\nI will also describe the model results along with other tips.<br>\nLet's get started.<\/div>\n<br>\nIf you like this notebook or find this notebook helpful, Please feel free to <font color=\"red\"><b>UPVOTE<\/b><\/font> and\/or leave a comment.\n \n<div> <b>This notebook is always a work in progress. So, please stay tuned for more to come.<\/b><\/div>\n\n\nThis notebook referenced the following.<br>\nhttps:\/\/www.kaggle.com\/deinforcement\/top-1-predict-future-sales-features-lightgbm<br>\nhttps:\/\/www.kaggle.com\/werooring\/top-3-5-lightgbm-with-feature-engineering<br>\nhttps:\/\/www.kaggle.com\/dlarionov\/feature-engineering-xgboost","769e365b":"![image.png](attachment:82c8de5d-31c0-499e-b872-5ca3d3487500.png)"}}