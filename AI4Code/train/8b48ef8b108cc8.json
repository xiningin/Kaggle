{"cell_type":{"5b8fd629":"code","b912a563":"code","dfcec7ef":"code","0c71e814":"code","199bf1b2":"code","908d7d67":"code","a23a59da":"code","4369ccc7":"code","a9b664fa":"code","9465ddec":"code","332688df":"code","97e0a238":"code","210831c6":"code","94b8f072":"code","782e8160":"code","5cee52db":"code","a0c3a940":"code","27b03ba1":"code","2f03931b":"code","a2c16297":"code","9be07340":"code","e889991d":"code","ba715746":"code","5501cf62":"code","be338572":"markdown","5a9334df":"markdown","f1cd7d99":"markdown","176066f6":"markdown","06bf7d10":"markdown","f03fc0b6":"markdown","c25fcf44":"markdown","de94bb77":"markdown","970bac7b":"markdown","e7a58b80":"markdown","e40a93a4":"markdown","033f1735":"markdown","d756044d":"markdown","3ec5a95f":"markdown","27d8bb02":"markdown","9f4804a4":"markdown","9c642e9f":"markdown","160d8431":"markdown","417abec1":"markdown","f294520f":"markdown","bccf963f":"markdown","7fdf8c52":"markdown","a414d21e":"markdown","24f2d4e6":"markdown","4d2f2e3b":"markdown","ba6d4374":"markdown","34e0463f":"markdown","a91a89e7":"markdown"},"source":{"5b8fd629":"!pip install tensorflow==2.2","b912a563":"import tensorflow as tf\nfrom tensorflow import keras\n\nprint(\"TensorFlow Version :\", tf.__version__)\nprint(\"Keras Version      :\", keras.__version__)","dfcec7ef":"!pip list --version","0c71e814":"import os\nimport cv2\nimport random\nimport numpy as np\n\nimg_size_224p = 128 # \u26a0\ufe0fCan be Customized\u26a0\ufe0f If use 224 pixels, it will be Out of Memory (OOM)\n\npath_train  = '..\/input\/orchid-genus\/orchid-genus\/train'\npath_test   = '..\/input\/orchid-genus\/orchid-genus\/test'\ncategories  = ['cattleya', 'dendrobium', 'oncidium', 'phalaenopsis', 'vanda']\n\ndef create_data_img(folder_path):\n    imageData = []\n    for category in categories:\n        path = os.path.join(folder_path, category)\n        class_num = categories.index(category) # Take the Label as the Index\n        for img in os.listdir(path):\n            img_array   = cv2.imread(os.path.join(path, img)) \n            img_convert = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n            img_resize  = cv2.resize(img_convert, (img_size_224p, img_size_224p))\n            imageData.append([img_resize, class_num])\n    \n    return imageData\n\ndataTrain   = create_data_img(path_train)\ndataTest    = create_data_img(path_test)\n\n# Shuffle the Train Data (if don't shuffle, the Train Data will be sorted by Labels)\nrandom.seed(10) # 10 as the Shuffle Index, so that when re-running the program, the results of the shuffle are the same\nrandom.shuffle(dataTrain)","199bf1b2":"# X for Features & y for Labels\nX_train, y_train, X_test, y_test = [], [], [], []\n\nfor features, label in dataTrain:\n    X_train.append(features)\n    y_train.append(label)\n\nfor features, label in dataTest:\n    X_test.append(features)\n    y_test.append(label)\n\n# -1 in reshape, means to let Numpy define the appropriate data dimensions\nX_train = np.array(X_train).reshape(-1, img_size_224p, img_size_224p, 3)\ny_train = np.asarray(y_train)\nX_test  = np.array(X_test).reshape(-1, img_size_224p, img_size_224p, 3)\ny_test  = np.asarray(y_test)\n\nprint(\"X_train :\", X_train.shape)\nprint(\"y_train :\", y_train.shape)\nprint(\"X_test  :\", X_test.shape)\nprint(\"y_test  :\", y_test.shape)","908d7d67":"print(\"Array of X_train :\\n\\n\", X_train[0]) # Take the first data for example\nprint(\"\\nArray of X_test  :\\n\\n\", X_test[0])\n\ndef prep_pixels(train, test):\n    # Convert from integers to floats\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    # Normalize (feature scaling) to range 0-1\n    train_norm = train_norm \/ 255.0\n    test_norm = test_norm \/ 255.0\n    # Return normalized images\n    return train_norm, test_norm\n\nX_train_norm, X_test_norm = prep_pixels(X_train, X_test)\n\nprint(\"\\nArray of X_train_norm :\\n\\n\", X_train_norm[0])\nprint(\"\\nArray of X_test_norm  :\\n\\n\", X_test_norm[0])","a23a59da":"from keras.utils import to_categorical\n\nprint(\"Array of y_train :\", y_train)\nprint(\"Array of y_test  :\", y_test)\n\n# One Hot Encode target values\ny_train_encode = to_categorical(y_train)\ny_test_encode  = to_categorical(y_test)\n\nprint(\"\\nArray of y_train_encode :\\n\\n\", y_train_encode)\nprint(\"\\nArray of y_test_encode :\\n\\n\", y_test_encode)","4369ccc7":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nnrows = 5 # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\nncols = 5 # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\nhspace = 0\nwspace = 0\nfig, ax = plt.subplots(nrows, ncols, figsize=(10, 10))    \nfig.subplots_adjust(hspace, wspace)\n\nfor i in range(nrows):\n    for j in range(ncols):\n        temp = i*ncols+j                # Index looping\n        ax[i,j].imshow(X_train[temp])   # Show Features\/images\n        if y_train[temp] == 0:\n            judul = \"cattleya\"\n        elif y_train[temp] == 1:\n            judul = \"dendrobium\"\n        elif y_train[temp] == 2:\n            judul = \"oncidium\"\n        elif y_train[temp] == 3:\n            judul = \"phalaenopsis\"\n        elif y_train[temp] == 4:\n            judul = \"vanda\"\n        ax[i,j].set_title(judul)        # Show Labels\n        ax[i,j].axis('off')             # Hide axis\nplt.show()","a9b664fa":"import gc     # Gabage Collector for cleaning deleted data from memory\n\ndel dataTrain\ndel dataTest\ndel X_train\ndel X_test\n#del y_train  # Used later for Confusion Matrix\n#del y_test   # Used later for Confusion Matrix\n\ngc.collect()","9465ddec":"print(\"X_train_norm     :\", X_train_norm.shape)\nprint(\"y_train_encode   :\", y_train_encode.shape)\nprint(\"X_test_norm      :\", X_test_norm.shape)\nprint(\"y_test_encode    :\", y_test_encode.shape)","332688df":"from keras.applications import MobileNetV2\nfrom keras.utils import plot_model\n\n'''\nImportant Notes:\n\nweights='imagenet'            The initial weights are filled directly with the \"optimal\" weight of the imagenet (pre-trained).\nweights=None                  The initial weight are filled with a random value (in case: training from scratch).\ninclude_top=False             Cut the head (top) of mobilenetv2 architecture, so that it can be modified according to the label used (in case: orchid).\nconv_base.trainable=False     Can only be used if weights=\"imagenet\", this means the weight in the feature extractor will be frozen,\n                              it will not be updated during training, in other words, the extractor feature is only used.\n'''\n\nconv_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size_224p, img_size_224p, 3))\nconv_base.trainable = False\nconv_base.summary()\nplot_model(conv_base, to_file='model.png', show_shapes=True, show_layer_names=False, rankdir='TB', expand_nested=False, dpi=80)","97e0a238":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom keras.optimizers import Adam\n\ndef define_model_mobilenetv2():\n    model = Sequential()\n    model.add(conv_base)                        # The Feature Extractor uses a Pre-trained Model\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(5, activation='softmax'))   # This means that in the Hidden Layer there are 5 Neurons (5 Orchid Labels)\n                                                # activation='softmax'is used because of the Multi-Class Classification problem\n    \n    # Compile Model\n    opt = Adam(lr=0.0001)                       # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy is used because\n    return model                                                                        # of the Multi-Class Classification problem\n\n# Clean the Previous Model (retraining needs)\nif \"model\" in globals(): # Check if the Model Variables exist\n  del model\n  gc.collect()\n\nmodel = define_model_mobilenetv2()\nmodel.summary()\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, rankdir='TB', expand_nested=False, dpi=80)","210831c6":"%%time\n\nimport pandas as pd\nfrom sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n\ndef evaluate_model(dataX, dataY, n_folds=5):  # \u26a0\ufe0fCan be Customized\u26a0\ufe0f At this step, the Train Data will be split into Train and Validation Data\n    epochs = 10                               # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\n    batch_size = 64                           # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\n\n    scores, histories = list(), list()\n    kfold = KFold(n_folds, shuffle=True, random_state=1) # 1 as the Shuffle Index, so that when re-running the program, the results of the shuffle are the same\n\n    i = 0\n    # Enumerate splits\n    for train_ix, val_ix in kfold.split(dataX):\n        i = i+1\n        model = define_model_mobilenetv2() # Define Model: Using MobileNetV2 which has been modified before\n        trainX, trainY, valX, valY = dataX[train_ix], dataY[train_ix], dataX[val_ix], dataY[val_ix]  # Select rows for Train and Validation\n        history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, validation_data=(valX, valY), verbose=1) # Fit Model\n        loss, acc = model.evaluate(valX, valY, verbose=0) # Evaluate Model\n        print('\\nFold ' + str(i) + ' Accuracy = %.3f' % (acc * 100.0))\n        print('Fold ' + str(i) + ' Loss = %.3f' % (loss) + '\\n')\n        scores.append(acc) # Append Scores\n        histories.append(history) # Append Histories\n\n        #----------------------------- Additional -----------------------------#\n\n        model.save(\"model_fold_\" + str(i) + \".h5\")  # Save Model as h5\n        model_csv = pd.DataFrame(history.history)   # Save Model Report to csv\n        csv_file = \"model_fold_\" + str(i) + \".csv\"\n        with open(csv_file, mode=\"w\") as f:\n          model_csv.to_csv(f)\n        \n        # Clean the RAM for every Fold\n        del trainX\n        del trainY\n        del valX\n        del valY\n        del model\n        gc.collect()\n\n    return scores, histories\n    \nscores, histories = evaluate_model(X_train_norm, y_train_encode)","94b8f072":"import warnings\nwarnings.filterwarnings('ignore')\n\ndef summarize_diagnostics_combine(histories):\n    plt.figure(figsize=(10,10))\n    \n    for i in range(len(histories)):\n        # Loss Plot\n        plt.subplot(211) # 2 rows, 1 column, 1st index\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.plot(histories[i].history['loss'], color='blue', marker='.', label='train')\n        plt.plot(histories[i].history['val_loss'], color='orange', marker='.', label='test')\n        plt.legend(['train', 'validation'], loc='upper right')\n        \n        # Accuracy Plot\n        plt.subplot(212) # 2 rows, 1 column, 2nd index\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy')\n        plt.plot(histories[i].history['accuracy'], color='blue', marker='.', label='train')\n        plt.plot(histories[i].history['val_accuracy'], color='orange', marker='.', label='test')\n        plt.legend(['train', 'validation'], loc='lower right')\n    plt.show()\n\nsummarize_diagnostics_combine(histories)","782e8160":"import warnings\nwarnings.filterwarnings('ignore')\n\ndef summarize_diagnostics_single(histories):\n    for i in range(len(histories)):\n        plt.figure(figsize=(16,6))\n\n        # Loss Plot\n        plt.subplot(221) # 2 rows, 2 column, 1st index\n        plt.title('Fold ' + str(i+1))\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.plot(histories[i].history['loss'], color='blue', marker='.', label='train')\n        plt.plot(histories[i].history['val_loss'], color='orange', marker='.', label='test')\n        plt.legend(['train', 'validation'], loc='upper right')\n\n        # Accuracy Plot\n        plt.subplot(222) # 2 rows, 2 column, 2nd index\n        plt.title('Fold ' + str(i+1))\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy')\n        plt.plot(histories[i].history['accuracy'], color='blue', marker='.', label='train')\n        plt.plot(histories[i].history['val_accuracy'], color='orange', marker='.', label='test')\n        plt.legend(['train', 'validation'], loc='lower right')\n        plt.show()\n\nsummarize_diagnostics_single(histories)","5cee52db":"from numpy import mean\nfrom numpy import std\n\ndef summarize_performance(scores):\n    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n    plt.boxplot(scores)\n    plt.show()\n\n# Summarize estimated performance\nsummarize_performance(scores)","a0c3a940":"%%time\n\nimport pandas as pd\n\nepochs = 10       # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\nbatch_size = 64   # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\n\nmodel = define_model_mobilenetv2() # Define Model: Using MobileNetV2 which has been modified before\nhistory = model.fit(X_train_norm, y_train_encode, epochs=epochs, batch_size=batch_size, verbose=1) # Fit model","27b03ba1":"fig, ax = plt.subplots(1, 1, figsize=(8, 3))\nax.plot(history.history['accuracy'], 'og', linestyle='dashed')\n#ax.plot(history.history['val_accuracy'])\nax.set_ylabel('Accuracy')\nax.set_xlabel('Epoch')\n#ax.legend(['train', 'val'], loc='lower right')\nplt.show()\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 3))\nax.plot(history.history['loss'], 'ob', linestyle='dashed')\n#ax.plot(history.history['val_loss'])\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\n#ax.legend(['train', 'val'], loc='upper right')\nplt.show()","2f03931b":"model.save(\"model_without_kfold.h5\")       # Save Model as h5\nmodel_csv = pd.DataFrame(history.history)  # Save Model Report to csv\ncsv_file = \"model_without_kfold.csv\"\nwith open(csv_file, mode=\"w\") as f:\n  model_csv.to_csv(f)","a2c16297":"# Clean the Previous Model (RAM Cleaner)\nif \"model\" in globals():\n  del model\n  gc.collect()\n\n# Load Model (Enter Path of Selected Model)\nfrom keras.models import load_model\nmodel = load_model('.\/model_fold_5.h5') # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\n#model.summary()","9be07340":"from sklearn.preprocessing import LabelBinarizer\n\nif \"encoder\" in globals(): # RAM Cleaner\n  del encoder\n  del y_train_encode_new\n  del y_test_encode_new\n  del pred\n  del prediksi\n  del pred_label\n  del true_label\n  gc.collect()\n\nencoder             = LabelBinarizer() # Encoding Labels (y) in different ways, for Confusion Matrix purposes\ny_train_encode_new  = encoder.fit_transform(y_train)\ny_test_encode_new   = encoder.fit_transform(y_test)\n\npred        = model.predict(X_test_norm.astype('float32'), verbose=0)\nprediksi    = np.argmax(pred, axis=-1) # Try -> predict.shape -> (800, 5) -> axis = -1 it will get that value 5 (number of Orchid Labels)\n\npred_label  = model.predict_classes(X_test_norm, batch_size=64, verbose=0)  # Prediction Result Label\ntrue_label  = np.argmax(y_test_encode_new, axis=-1)                         # Actual Label (in Dataset)\n\nprint(\"Predict Label :\", pred_label)\nprint(\"Actual Label  :\", true_label, \"\\n\")\n\nloss, acc = model.evaluate(X_test_norm, y_test_encode_new, verbose=1)","e889991d":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\ntarget_names = ['cattleya', 'dendrobium', 'oncidium', 'phalaenopsis', 'vanda']\ncmatrix = confusion_matrix(true_label, pred_label)\ncreport = classification_report(true_label, prediksi, target_names=target_names)\n\nprint(\"Accuracy : {:.3f}%\".format(acc*100))\nprint(\"Loss     : {:.3f}\".format(loss))\n\nprint(\"\\nClassification Report :\\n\")\nprint(creport)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(cmatrix, cmap=\"crest_r\", annot=True, fmt='.4g', linewidths=2, linecolor='white', cbar=False, ax=ax)\n# cmap options: rocket, mako, flare, crest, magma, viridis, rocket_r, cubehelix, seagreen, Blues, ...\n\nax.set_title('Confusion Matrix', fontsize=18, pad=24)\nax.set_xticklabels(labels=target_names, fontsize=12)\nax.set_yticklabels(labels=target_names, fontsize=12)\n\nplt.xlabel(\"(y) Predict Label\", fontsize=16, color=\"darkgreen\", labelpad=24)\nplt.ylabel(\"(y) Actual Label\", fontsize=16, color=\"darkgreen\", labelpad=24)\nplt.show()","ba715746":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import load_model\n\n# Load and Prepare the Image\ndef load_image(filename):\n    img = load_img(filename, target_size=(img_size_224p, img_size_224p))\n    plt.imshow(img)\n    plt.axis(\"off\");\n    img = img_to_array(img)\n    img = img.reshape(-1, img_size_224p, img_size_224p, 3)\n    img = img.astype('float32')\n    img = img \/ 255.0\n    return img\n\n# Load an Image and Predict the Class\/Label\ndef run_example(new_data_path):\n    # Load the Image\n    img = load_image(new_data_path)\n    # Load Model\n    model = load_model('.\/model_fold_5.h5') # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\n    # Predict the Class\/Label\n    result = model.predict_classes(img) # OPTION 1\n    #result = model.predict(img)        # OPTION 2\n    if result[0] == 0:\n        print(\"\\nPredict Label: Cattleya\")\n    elif result[0] == 1:\n        print(\"\\nPredict Label: Dendrobium\")\n    elif result[0] == 2:\n        print(\"\\nPredict Label: Oncidium\")\n    elif result[0] == 3:\n        print(\"\\nPredict Label: Phalaenopsis\")\n    elif result[0] == 4:\n        print(\"\\nPredict Label: Vanda\")","5501cf62":"# Get image data directly from the internet\n#!wget -O 'new_test_data.jpg' 'https:\/\/lumencms.blob.core.windows.net\/media-generated\/538\/_L2A0849-ANSU-VANDA-Vanda-Terra-2-600-600.jpg'\n\n# Get image data from the dataset\nnew_data_path = '..\/input\/orchid-genus\/orchid-genus\/inet\/dendrobium\/D1.jpg' # \u26a0\ufe0fCan be Customized\u26a0\ufe0f\nrun_example(new_data_path)","be338572":"## 3-2. Modified a MobileNetV2 Architecture","5a9334df":"## 5-4. Testing Model with Test Data from Internet","f1cd7d99":"## 2-6. Clean up Useless Data (RAM Cleaner)","176066f6":"## 4-2. Plot the Graphs of Training & Validation Results (Combine)","06bf7d10":"---\n# 3. Build CNN Architecture: MobileNetV2\n---","f03fc0b6":"---\n# 4. OPTION 1: Training with K-Fold Cross Validation\n---","c25fcf44":"## 4-2. Plot the Graphs of Training & Validation Results (Single)","de94bb77":"---\n# 4. OPTION 2: Training without K-Fold Cross Validation\n---","970bac7b":"---\n# 6. Conclusion\n---\n\nThe resulting CNN model is overfitting, this means that training accuracy and testing accuracy have a high difference. Some solutions that can be used to reduce overfitting are as follows:<br>\n1. Add More Dataset\n2. Use Data Augmentation Technique\n3. Adjust CNN Architecture\n4. Adjust Hyperparameters\n5. Use Dropout Regularization Technique\n\nUPDATE: It has been tested with an input shape image of 224x224x3 on the Google Colaboratory platform, resulting in a test accuracy score of 80-90%. The link can be accessed at: https:\/\/github.com\/alamehan\/skripsi-cnn-anggrek","e7a58b80":"## 5-2. Testing Model with Test Data","e40a93a4":"## 2-2. Get Features (X) & Labels (y)","033f1735":"---\n# 2. Data Preprocessing\n---","d756044d":"## 5-3. Evaluate Model with Confusion Matrix","3ec5a95f":"## 2-4. Labels (y) : One Hot Encoding","27d8bb02":"# Orchid Classification using CNN (MobileNetV2) + K-Fold + Confusion Matrix\n\n**AUTHOR** : Raihan Allaam - https:\/\/alamehan.github.io\/links\/\n\n---\n\n<img src=\"https:\/\/raw.githubusercontent.com\/alamehan\/skripsi-cnn-anggrek\/master\/assets\/genus.jpg\" width=500><br>\n\n**DESCRIPTION** : \n\nOrchid is one of the ornamental plants that is widely cultivated. Each genus of orchids has different cultivation methods, so orchid cultivators who are just starting out need to know the genus of orchids they will cultivate first. However, not a few beginners trying to cultivate orchids without sufficient knowledge and experience, so the cultivated orchids do not grow and flower optimally. In this study, a system was built that could classify the image of orchid genera, namely the genus Cattleya, Dendrobium, Oncidium, Phalaenopsis, and Vanda. Image classification is carried out using the Convolutional Neural Network (CNN) method. Where the image of the orchid as input data will be carried out according to the genus classification process. All of these classification processes are carried out through a training and testing scheme, where the training stage produces a CNN model and updated weights, then the testing stage uses the model to be tested against new image data. K-Fold Cross Validation is used at the training stage, then to evaluate the CNN model after testing, the Confusion Matrix is used.\n\n---\n\n**DATASET USED** :\n\n- 4000 train data without background + augmentation (800 image\/genus)\n- 2500 test data (500 image\/genus)\n- 185 test data from internet (25 cattleya and 40 other genus)\n\n---\n\n**SETUP & HYPERPARAMETER** :\n\n- Image Input Shape: 128x128x3 (RGB)\n- CNN Architecture: MobileNetV2\n- K in K-Fold Cross Validation: 5\n- Epoch: 10 & Batch Size: 64\n- Optimizer: Adam\n- Learning Rate: 0.0001","9f4804a4":"## 2-5. Plot the Dataset","9c642e9f":"## 4-1. Training without K-Fold","160d8431":"## 5-1. Load Selected CNN Model","417abec1":"## 2-1. Load Image Data as Array","f294520f":"## 4-1. Training with 5-Fold","bccf963f":"## 4-2. Plot the Graphs of Training Results","7fdf8c52":"---\n# 5. Testing Our CNN Model\n---","a414d21e":"## 4-3. Save Model as H5 & CSV","24f2d4e6":"## 2-7. The Final Data to be used on CNN","4d2f2e3b":"## 3-1. Load a Pretrained MobileNetV2 Model","ba6d4374":"## 4-3. Mean & Standard Deviation Scores","34e0463f":"---\n# 1. Install TensorFlow 2.2\n---","a91a89e7":"## 2-3. Features (X) : Feature Scaling"}}