{"cell_type":{"64d7c838":"code","71a9cd48":"code","682a75c7":"code","7f6b1171":"code","259e6609":"code","1297fba7":"code","34b5422e":"code","382bb252":"code","8271788a":"code","fe7ec4a1":"code","bee9e65f":"code","bb9d15aa":"code","7dfa0369":"code","790627fb":"code","d8de41c9":"code","532e707f":"code","de926942":"code","3fdda0cc":"code","1ddaf59b":"code","938c8076":"code","744d6694":"code","0a72861d":"code","a1d4d931":"markdown","3e7985fe":"markdown","0f70dfa4":"markdown","eba3ded0":"markdown","df3f6860":"markdown","eeeb81d1":"markdown","57ff91d9":"markdown","fcb6b71c":"markdown","48cc8134":"markdown","4b906963":"markdown","2234dace":"markdown","439ff452":"markdown","b470843f":"markdown","e2abaacd":"markdown"},"source":{"64d7c838":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lifetimes\n\n#Let's make this notebook reproducible \nnp.random.seed(42)\n\nimport random\nrandom.seed(42)\n\nimport warnings\nwarnings.filterwarnings('ignore')","71a9cd48":"# Make the default figures a bit bigger\nplt.rcParams['figure.figsize'] = (7,4.5) \nplt.rcParams[\"figure.dpi\"] = 140 \n\nsns.set(style=\"ticks\")\nsns.set_context(\"poster\", font_scale = .5, rc={\"grid.linewidth\": 5})","682a75c7":"df1 = pd.read_csv('..\/input\/olist_orders_dataset.csv')\ndf2 = pd.read_csv('..\/input\/olist_customers_dataset.csv')\ndf3 = pd.read_csv('..\/input\/olist_order_payments_dataset.csv')\n\ncols = ['customer_id', 'order_id', 'order_purchase_timestamp']\norders = df1[cols]\norders = orders.set_index('customer_id')\norders.drop_duplicates(inplace=True)\n\n# too few \ncols = ['order_id', 'payment_value']\npayment = df3[cols]\npayment = payment.set_index('order_id')\npayment.drop_duplicates(inplace=True)\n\ncols = ['customer_id', 'customer_unique_id']\ncustomers = df2[cols]\ncustomers = customers.set_index('customer_id')\n\nelog = pd.concat([orders,customers], axis=1, join='inner')\nelog.reset_index(inplace=True)\n\ncols = ['customer_unique_id', 'order_purchase_timestamp']\nelog = elog[cols]\n\nelog['order_purchase_timestamp'] = pd.to_datetime(elog['order_purchase_timestamp'])\nelog['order_date'] = elog.order_purchase_timestamp.dt.date\nelog['order_date'] = pd.to_datetime(elog['order_date'])\n\ncols = ['customer_unique_id', 'order_date']\nelog = elog[cols]\n\nelog.columns = ['CUSTOMER_ID', 'ORDER_DATE']\n\n\nelog.info()\ndisplay(elog.sample(5))","7f6b1171":"elog.ORDER_DATE.describe()","259e6609":"%%time\ncalibration_period_ends = '2018-06-30'\n\nfrom lifetimes.utils import calibration_and_holdout_data\n\nsummary_cal_holdout = calibration_and_holdout_data(elog, \n                                                   customer_id_col = 'CUSTOMER_ID', \n                                                   datetime_col = 'ORDER_DATE', \n                                                   freq = 'D', #days\n                                        calibration_period_end=calibration_period_ends,\n                                        observation_period_end='2018-09-28' )\n","1297fba7":"summary_cal_holdout.head()","34b5422e":"%%time \n\nfrom lifetimes import ModifiedBetaGeoFitter\n\nmbgnbd = ModifiedBetaGeoFitter(penalizer_coef=0.01)\nmbgnbd.fit(summary_cal_holdout['frequency_cal'], \n        summary_cal_holdout['recency_cal'], \n        summary_cal_holdout['T_cal'],\n       verbose=True)","382bb252":"print(mbgnbd)","8271788a":"#returning_customers_summary = summary_cal_holdout[summary_cal_holdout['frequency_cal'] > 0]\n#returning_customers_summary[['monetary_value_cal', 'frequency_cal']].corr()","fe7ec4a1":"#%%time \n\n#from lifetimes import GammaGammaFitter\n\n#gg = GammaGammaFitter(penalizer_coef = 0.01)\n#gg.fit(returning_customers_summary['frequency_cal'],\n#        returning_customers_summary['monetary_value_cal'],\n#       verbose=True)","bee9e65f":"#print(gg)","bb9d15aa":"t = 90 # days to predict in the future \nsummary_cal_holdout['predicted_purchases'] = mbgnbd.conditional_expected_number_of_purchases_up_to_time(t, \n                                                                                      summary_cal_holdout['frequency_cal'], \n                                                                                      summary_cal_holdout['recency_cal'], \n                                                                                      summary_cal_holdout['T_cal'])\n\nsummary_cal_holdout['p_alive'] = mbgnbd.conditional_probability_alive(summary_cal_holdout['frequency_cal'], \n                                                                         summary_cal_holdout['recency_cal'], \n                                                                         summary_cal_holdout['T_cal'])\nsummary_cal_holdout['p_alive'] = np.round(summary_cal_holdout['p_alive'] \/ summary_cal_holdout['p_alive'].max(), 2)\n\n#summary_cal_holdout['clv'] = gg.customer_lifetime_value(\n#    mbgnbd, #the model to use to predict the number of future transactions\n#    summary_cal_holdout['frequency_cal'],\n#    summary_cal_holdout['recency_cal'],\n#    summary_cal_holdout['T_cal'],\n#    summary_cal_holdout['monetary_value_cal'],\n#    time=3, # months\n#    discount_rate=0 #0.0025 # = 0.03\/12 monthly discount rate ~ 3% annually\n#)\n#summary_cal_holdout['clv'] += (-1*summary_cal_holdout['clv'].min())","7dfa0369":"display(summary_cal_holdout.sample(2).T)","790627fb":"%%time \n\nfrom lifetimes.plotting import plot_period_transactions\nax = plot_period_transactions(mbgnbd, max_frequency=7)\nax.set_yscale('log')\nsns.despine();","d8de41c9":"%%time \n\nfrom lifetimes.plotting import plot_calibration_purchases_vs_holdout_purchases\n\nplot_calibration_purchases_vs_holdout_purchases(mbgnbd, summary_cal_holdout)\nsns.despine();","532e707f":"from lifetimes.plotting import plot_history_alive\nfrom datetime import date\nfrom pylab import figure, text, scatter, show\n\nindividual = summary_cal_holdout.iloc[4942]\n\nid = individual.name\nt = 365*50\n\ntoday = date.today()\ntwo_year_ago = today.replace(year=today.year - 2)\none_year_from_now = today.replace(year=today.year + 1)\n\nsp_trans = elog.loc[elog['CUSTOMER_ID'] == id]\n\nfrom lifetimes.utils import calculate_alive_path\n\nt = (today - sp_trans.ORDER_DATE.min().date()).days\np_alive_today = pd.DataFrame(calculate_alive_path(mbgnbd, sp_trans, 'ORDER_DATE', t, freq='D'))[0].tail(1).values\np_alive_today = np.round(p_alive_today[0], 2)\nprint('Probability that customer is alive today is', p_alive_today)\n\nt = (one_year_from_now - sp_trans.ORDER_DATE.min().date()).days\nax = plot_history_alive(mbgnbd, t, sp_trans, 'ORDER_DATE', start_date=two_year_ago) #, start_date='2016-01-01'\nax.vlines(x=today, ymin=0, ymax=1.05, colors='#4C4C4C')\nax.hlines(y=0.8, xmin=two_year_ago, xmax=one_year_from_now, colors='#4C4C4C')\n\nax.set_xlim(two_year_ago, one_year_from_now) # sp_trans.ORDER_DATE.min()\nax.set_ylim(0, 1.05)\n\nplt.xticks(rotation=-90)\ntext(0.75, 0.1, p_alive_today, ha='center', va='center', transform=ax.transAxes)\n\nsns.despine()","de926942":"elog.columns = ['CUSTOMER_ID', 'date']","3fdda0cc":"%%time\n# Get expected and actual repeated cumulative transactions.\n\nfrom lifetimes.utils import expected_cumulative_transactions\n\nt = (elog.date.max() - elog.date.min()).days\ndf = expected_cumulative_transactions(mbgnbd, elog, 'date', 'CUSTOMER_ID', t)","1ddaf59b":"df.tail()","938c8076":"%%time\n# Calibration period = 2016-09-04 to 2017-09-30\nfrom datetime import datetime\n\ncal = datetime.strptime('2018-06-30', '%Y-%m-%d')\n\nfrom lifetimes.plotting import plot_cumulative_transactions\nt = (elog.date.max() - elog.date.min()).days\nt_cal = (cal - elog.date.min()).days\nplot_cumulative_transactions(mbgnbd, elog, 'date', 'CUSTOMER_ID', t, t_cal, freq='D')\nsns.despine()","744d6694":"%%time \n\nfrom lifetimes.plotting import plot_incremental_transactions\nplot_incremental_transactions(mbgnbd, elog, 'date', 'CUSTOMER_ID', t, t_cal, freq='D')\nsns.despine()","0a72861d":"#print(\"Expected conditional average revenue: \u20ac%s, Average revenue: \u20ac%s\" % (\n#    np.round(gg.conditional_expected_average_profit(\n#        returning_customers_summary['frequency_cal'],\n#        returning_customers_summary['monetary_value_cal']\n#    ).mean(), 2),\n#    np.round(returning_customers_summary[returning_customers_summary['frequency_cal']>0]['monetary_value_cal'].mean(), 2)\n#))","a1d4d931":"### Predictions for each customer","3e7985fe":"### Predicted Transactions with Time","0f70dfa4":"# Predicting customer lifetime value and future purchases \n\nIn most cases value of a firm is profits from existing and future customers (a.k.a. Customer Equity). Research done by Frederick Reichheld of Bain & Company (the inventor of the net promoter score) shows increasing customer retention rates by 5% increases profits by 25% to 95% (Reichheld 2001). \n\nIt is possible to calculate Customer Equity (CE) because Customer Lifetime Value (CLV) can be measured with a reasonable degree of precision.\n\n*CLV is the present value of the future (net) cash flows associated with the customer (Gupta and Lehmann 2003). It is a forward-looking concept, not to be confused with historic customer profitability.*\n\nNot all customers are equally important to a firm. Maintaining long-term relation with all of them (especially the loss makers) is not optimal because eventually marketing is all about attracting and retaining profitable customers (Kotler and Armstrong 1996). Hence the objective of CLV is firstly on general topics of firm\u2019s profitability and secondly as an input in customer acquisition decision and customer acquisition\/retention trade-offs (Berger and Nasr 1998).\n\n\n## Objectives\n\nThe primary goal of this work is to build a probabilistic model for forecasting customer lifetime value in non-contractual setting on an individual level. \n\nUsing the results of this exercise, managers should be able to: \n1. Distinguish active customers from inactive customers. \n2. Generate transaction forecasts for individual customers.\n3. Predict the purchase volume of the entire customer base.\n\n## Import packages","eba3ded0":"## Creating RFM Matrix based on transaction log\n\n#### Spliting calibration and holdout period","df3f6860":"## Read data\n\nReading in transaction log. i.e. Amount spent per customer each day","eeeb81d1":"## Training model - MBG\/NBD \n\nModel assumptions:\n\n* While active, the number of transactions made by a customer follows a Poisson process\nwith transaction rate $\\lambda$.\n* Heterogeneity in $\\lambda$ across customers follows a Gamma distribution with shape parameter $r$ and scale parameter $\\alpha$.\n* At time zero and right after each purchase the customer becomes inactive with a constant probability $p$.\n* Heterogeneity in $p$ across customers follows a Gamma distribution with parameter $a$ and $b$.\n* The transaction rate $\\lambda$ and the dropout probability $p$ vary independently across customers.\n\n","57ff91d9":"### Estimating customer lifetime value using the Gamma-Gamma model\n\nThe Gamma-Gamma model and the independence assumption:\n\nModel assumes that there is no relationship between the monetary value and the purchase frequency. In practice we need to check whether the Pearson correlation between the two vectors is close to 0 in order to use this model.","fcb6b71c":"#### Plotting parameters","48cc8134":"### Predict the conditional, expected average lifetime value of our customers.\n","4b906963":"#### Date range of orders","2234dace":"### Model performance will increase if it is trained on all the data and not a sample as is the case here\n\nCheers..\n\nhttps:\/\/github.com\/1dhiman \n\nhttp:\/\/linkedin.com\/in\/dhimananubhav","439ff452":"### Feature set","b470843f":"### Customer Probability History","e2abaacd":"## Model evaluation\n\n### Accessing model fit"}}