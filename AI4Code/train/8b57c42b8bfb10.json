{"cell_type":{"34b6883d":"code","05599aef":"code","7cfb89ec":"code","5e9fd576":"code","857e4a27":"code","1e895a25":"code","55e3e286":"code","8ea59784":"code","93743b17":"markdown","f498c8df":"markdown","1760566a":"markdown","79043730":"markdown","df6663f5":"markdown","2b307f77":"markdown","c891c936":"markdown","1bcb76be":"markdown"},"source":{"34b6883d":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn import ensemble","05599aef":"# \n#############################################################################\n# Load data\nboston = datasets.load_boston()\n#print(boston.data.shape, boston.target.shape)\n#print(boston.feature_names)","7cfb89ec":"# Creamos DataFrame \ndata = pd.DataFrame(boston.data,columns=boston.feature_names)\ndata = pd.concat([data,pd.Series(boston.target,name='MEDV')],axis=1)\ndata.head()","5e9fd576":"\nX=....'completar codigo'....\ny=....'completar codigo'....\n","857e4a27":"x_training_set, x_test_set, y_training_set, y_test_set = train_test_split(....'completar codigo'....)","1e895a25":"# parametros https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingRegressor.html\nparams = {'n_estimators': ....,'learning_rate': ....., 'loss': .....}\n'''loss: se refiere a la funci\u00f3n de perdida: \n        \"ls\" se refiere a la regresi\u00f3n de m\u00ednimos cuadrados. \n        \"lad\" (least absolute deviation) es una funci\u00f3n de p\u00e9rdida altamente robusta basada \u00fanicamente en la informaci\u00f3n de las variables de entrada. \n        \"huber\" es una combinaci\u00f3n de los dos.'''\n'''n_estimators: El n\u00famero de etapas de bossting para realizar. \n        Gradient Boosting es bastante robusto para un ajuste excesivo, \n        por lo que un gran n\u00famero generalmente resulta en un mejor rendimiento.'''\n\n# usamos Gradient Boosting regressor https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingRegressor.html\nmodel = ensemble.GradientBoostingRegressor(**params)\n\n# ajustamos el modelo con el dataset de entrenamiento \nmodel.fit(....'completar codigo'....)","55e3e286":"from sklearn.metrics import mean_squared_error\n\n\"validar el modelo usando alguna metrica de regresion como MSE\"\ny_predicted = model.predict(....'completar codigo'....)\n\n#  mean squared error\nprint(\"Mean squared error: %.2f\"% mean_squared_error(....'completar codigo'....))\n","8ea59784":"\nfrom sklearn.model_selection import cross_val_predict\n\nfig, ax = plt.subplots()\nax.scatter(....'completar codigo'...., ....'completar codigo'...., edgecolors=(0, 0, 0))\nax.set_xlabel('Real')\nax.set_ylabel('Predecida')\nax.set_title(\"Ground Truth vs Predecido\")\nplt.show()","93743b17":"**Responda las siguientes preguntas:**\n------------------------------------\n* ***EXISTEN COLUMNAS CON DATOS FALTANTES ???? (NaN)***\n* ***NECESITA REALIZAR ALG\u00faN PRE-PROCESAMIENTO ????***","f498c8df":"**Dividir dataset en TRAIN\/TEST**\n---------------------------------\n\n> puede usar la funcion \"train_test_split()\" [link](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html)","1760566a":"**Entrenamiento\/ajuste del modelo: ** \n------------------------------------\n\nAjustar el modelo a los datos supervisados ","79043730":"**Estudio de par\u00e1metros del modelo**\n------------------------------------\nUse la m\u00e9trica MSE para validar su modelo ","df6663f5":"** PROBLEMA : **\n================\n\nPredecir los precios medios de las viviendas ubicadas en el \u00e1rea de Boston dados otros atributos de la casa. \n\n***Detalles de datos***:\n\nBoston House Prices dataset\n===========================\n\nNotas:\n------\nCaracter\u00edsticas del Data Set:  \n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric\/categorical predictive\n    \n    :Median Value (attribute 14) is usually the target\n\n    :Attribute Information (in order):\n        - CRIM   per capita crime rate by town\n        - ZN   proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS   proportion of non-retail business acres per town\n        - CHAS   Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX   nitric oxides concentration (parts per 10 million)\n        - RM   average number of rooms per dwelling\n        - AGE   proportion of owner-occupied units built prior to 1940\n        - DIS   weighted distances to five Boston employment centres\n        - RAD   index of accessibility to radial highways\n        - TAX   full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B   1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT   % lower status of the population\n        - MEDV   Median value of owner-occupied homes in $1000's\n\n    :\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nesta es una copia de UCI ML housing dataset.\nhttp:\/\/archive.ics.uci.edu\/ml\/datasets\/Housing\n\nla data fue tomada de StatLib library que es elaborado por Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.","2b307f77":"**Seleccione el Target y las Variables predictoras **\n-----------------------------------------\n","c891c936":"****Cargue el conjunto de datos.****\n===========================\n\nUse el m\u00f3dulo de pandas para leer los datos. Verifique algunos registros del conjunto de datos.","1bcb76be":"**Reporte de Acurracy**\n-------------------------\n\n\ngraficar los valores predecidos vs los datos reales "}}