{"cell_type":{"645a4af0":"code","83dd8b15":"code","b96a7a21":"code","6ecb253e":"code","c3d14f99":"code","f3085b76":"code","1909a41e":"code","399e2374":"code","30ac44e2":"code","828bf6b7":"code","7ada6e8b":"code","e4961f5f":"code","66339310":"code","6cb08ecb":"code","c6af2833":"code","9a941803":"code","39be4e0b":"code","aab9b343":"code","484b0371":"code","48d13e0f":"code","b533ca32":"code","52adcc25":"code","31532f60":"code","fa85ebe3":"code","38b04f33":"code","fdb28d53":"markdown","f494150e":"markdown","7b8f1932":"markdown","b51fac70":"markdown","1be2aa8b":"markdown","e46f53ae":"markdown","b59547ed":"markdown","7c418c7a":"markdown","940c5bb2":"markdown","8935dc39":"markdown","cff4b4a2":"markdown","cad63e8c":"markdown","6cdd6ee6":"markdown","897b114c":"markdown","e9f2b062":"markdown","e86b5a86":"markdown","5549a7f8":"markdown","ab75aea8":"markdown","5caf03ad":"markdown","bb18926a":"markdown","7792bfa0":"markdown","f3a1fb68":"markdown","ecf96410":"markdown","c0abf3b8":"markdown"},"source":{"645a4af0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport os\nimport warnings","83dd8b15":"warnings.filterwarnings(\"ignore\")\nprint(\"Uyar\u0131lar kapat\u0131ld\u0131...\")\nprint(os.listdir(\"..\/input\"))","b96a7a21":"from keras.optimizers import SGD\nfrom keras.datasets import cifar10\n\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nprint(\"Gerekli Keras k\u00fct\u00fcphaneleri y\u00fcklendi...\")","6ecb253e":"from os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\ndatasets_dir = join(cache_dir, 'datasets') # \/cifar-10-batches-py\nif not exists(datasets_dir):\n    makedirs(datasets_dir)\n\n\n!cp ..\/input\/cifar-10-python.tar.gz ~\/.keras\/datasets\/\n!ln -s  ~\/.keras\/datasets\/cifar-10-python.tar.gz ~\/.keras\/datasets\/cifar-10-batches-py.tar.gz\n!tar xzvf ~\/.keras\/datasets\/cifar-10-python.tar.gz -C ~\/.keras\/datasets\/","c3d14f99":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()\nprint(\"CIFAR-10 dataset loaded...\")","f3085b76":"def add_side(images, side_type, side_size=1):\n        #Kenar eklenen g\u00f6r\u00fcnt\u00fcleri tutacak liste\n        new_images=list()\n        #G\u00f6r\u00fcnt\u00fc listesindeki g\u00f6r\u00fcnt\u00fcler al\u0131n\u0131yor\n        for image in images:\n        \n            if side_type==\"horizantal\":\n                #G\u00f6r\u00fcnt\u00fcn\u00fcn y\u00fcksekli\u011finde ve istenen \u00f6l\u00e7\u00fcde kenar olu\u015fturuluyor\n                side=np.ones((image.shape[0],side_size,image.ndim), dtype=image.dtype)*255\n                #Kenar g\u00f6r\u00fcnt\u00fcye yatay olarak ekleniyor\n                image=np.hstack((image,side))\n            elif side_type==\"vertical\":#vertical\n                #G\u00f6r\u00fcnt\u00fcn\u00fcn geni\u015fli\u011finde ve istenen \u00f6l\u00e7\u00fcde kenar olu\u015fturuluyor\n                side=np.ones((side_size,image.shape[1],image.ndim), dtype=image.dtype)*255\n                #Kenar g\u00f6r\u00fcnt\u00fcye dikey olarak ekleniyor\n                image=np.vstack((image,side))\n            \n            new_images.append(image)\n        return new_images","1909a41e":"rows=list()\nstep=12\nfor i in range(0, 130, step):\n    horizantal_sided_images=add_side(X_train[i:i+step], side_type=\"horizantal\", side_size=3)\n    row=np.hstack((horizantal_sided_images))\n    \n    rows.append(row)\n\nvertical_sided_images=add_side(rows, side_type=\"vertical\",side_size=3)\ngallery=np.vstack((vertical_sided_images))\nplt.figure(figsize=(12,12))\nplt.imshow(gallery)\nplt.xticks([])\nplt.yticks([])\nplt.show()","399e2374":"class VGGNet():\n    @staticmethod\n    def build(width, height, depth, classes):\n        model = Sequential([\n        Conv2D(64, (3, 3), input_shape=(width,height,depth), padding='same',\n               activation='relu'),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        BatchNormalization(axis=-1),\n        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        Conv2D(128, (3, 3), activation='relu', padding='same',),\n        BatchNormalization(axis=-1),\n        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n        Conv2D(256, (3, 3), activation='relu', padding='same',),\n        Conv2D(256, (3, 3), activation='relu', padding='same',),\n        Conv2D(256, (3, 3), activation='relu', padding='same',),\n        BatchNormalization(axis=-1),\n        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n        Conv2D(512, (3, 3), activation='relu', padding='same',),\n        Conv2D(512, (3, 3), activation='relu', padding='same',),\n        Conv2D(512, (3, 3), activation='relu', padding='same',),\n        BatchNormalization(axis=-1),\n        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n        Conv2D(512, (3, 3), activation='relu', padding='same',),\n        Conv2D(512, (3, 3), activation='relu', padding='same',),\n        Conv2D(512, (3, 3), activation='relu', padding='same',),\n        BatchNormalization(axis=-1),\n        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n        Flatten(),\n        Dense(4096, activation='relu'),\n        Dense(4096, activation='relu'),\n        Dense(classes, activation='softmax')\n        ])\n        return model","30ac44e2":"class MiniVGGNet():\n    @staticmethod\n    def build(width, height, depth, classes):\n        model=Sequential()\n        #=============== First Convolutional Layer ========================\n        model.add(Conv2D(32, (3,3), padding=\"same\",input_shape=(width,height,depth)))\n        model.add(Activation(\"relu\"))\n        #G\u00f6r\u00fcnt\u00fc \u015fekli channels_last oldu\u011fu i\u00e7in axis=-1 oluyor.\n        model.add(BatchNormalization(axis=-1))\n        \n        model.add(Conv2D(32, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        #G\u00f6r\u00fcnt\u00fc \u015fekli channels_last oldu\u011fu i\u00e7in axis=-1 oluyor.\n        model.add(BatchNormalization(axis=-1))\n                  \n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        #=============== Second Convolutional Layer ========================        \n        model.add(Conv2D(64, (3,3), padding=\"same\"))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=-1))\n        \n        model.add(Conv2D(64, (3,3), padding=\"same\"))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=-1))\n        \n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        #================ First Fully Connected Layer =====================\n        model.add(Flatten())\n        model.add(Dense(512))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n                  \n        #================ Soft Classifier ================================\n        model.add(Dense(classes))\n        model.add(Activation('softmax'))\n        \n    \n        return model     \n     \n        ","828bf6b7":"def show_model_history(modelHistory, model_name):\n    history=pd.DataFrame()\n    history[\"Train Loss\"]=modelHistory.history['loss']\n    history[\"Validation Loss\"]=modelHistory.history['val_loss']\n    history[\"Train Accuracy\"]=modelHistory.history['acc']\n    history[\"Validation Accuracy\"]=modelHistory.history['val_acc']\n    \n    fig, axarr=plt.subplots(nrows=2, ncols=1 ,figsize=(12,8))\n    axarr[0].set_title(\"History of Loss in Train and Validation Datasets\")\n    history[[\"Train Loss\", \"Validation Loss\"]].plot(ax=axarr[0])\n    axarr[1].set_title(\"History of Accuracy in Train and Validation Datasets\")\n    history[[\"Train Accuracy\", \"Validation Accuracy\"]].plot(ax=axarr[1]) \n    plt.suptitle(\" Convulutional Model {} Loss and Accuracy in Train and Validation Datasets\".format(model_name))\n    plt.show()","7ada6e8b":"X_train =X_train.astype(np.float32)\/255.0\nX_test= X_test.astype(np.float32)\/255.0\nprint(\"Normalizasyon ger\u00e7ekle\u015ftirildi...\")","e4961f5f":"print(\"y_train.shape:\",y_train.shape)\nprint(\"y_train[0]:\",y_train[0])","66339310":"labelBinarizer=LabelBinarizer()\ny_train=labelBinarizer.fit_transform(y_train)\ny_test=labelBinarizer.transform(y_test)\nprint(\"A\u011f i\u00e7in OneHot kodlama ger\u00e7ekle\u015ftirildi...\")","6cb08ecb":"print(\"y_train.shape:\",y_train.shape)\nprint(\"y_train[0]:\",y_train[0])","c6af2833":"print(K.image_data_format())","9a941803":"VGGNet_type=\"normal\"\nif VGGNet_type==\"normal\":\n    print(\"Normal VGGNet modeli se\u00e7ildi...\")\n    model=VGGNet.build(width=32, height=32, depth=3, classes=10)\nelse:\n    print(\"Mini VGGNet modeli se\u00e7ildi...\")\n    model = MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n","39be4e0b":"opt = SGD(lr=0.01, decay=0.01 \/ 40, momentum=0.9, nesterov=True)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\nprint(\"Model derlendi...\")","aab9b343":"modelHistory = model.fit(X_train, y_train, \n                         validation_data=(X_test, y_test),\n                         batch_size=64, \n                         epochs=40, \n                         verbose=0)\nprint(\"Model e\u011fitildi...\")","484b0371":" show_model_history(modelHistory=modelHistory, model_name=VGGNet_type)","48d13e0f":"predictions = model.predict(X_test, batch_size=256)\nprint(\"Test veri seti \u00fczerinde tahmin yap\u0131ld\u0131...\")","b533ca32":"acc_score=accuracy_score(y_test.argmax(axis=1),predictions.argmax(axis=1))\nprint(\"Accuracy score:\",acc_score)\n\nclass_names=[\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\nprint(\"Confusion Matrix:\\n\")\ncm=confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\nprint(cm)\nprint(\"Classification Report:\\n\")\ncr=classification_report(y_test.argmax(axis=1),\n                            predictions.argmax(axis=1), \n                            target_names=class_names)\nprint(cr)","52adcc25":"plt.figure(figsize=(12,12))\nsns.heatmap(cm, annot=True,\n           xticklabels=[\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n                        \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"],\n            yticklabels=[\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n                         \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"],\n            fmt=\"d\"\n           )","31532f60":"history=pd.DataFrame()","fa85ebe3":"history[\"Train Loss\"]=modelHistory.history['loss']\nhistory[\"Validatin Loss\"]=modelHistory.history['val_loss']\nhistory[\"Train Accuracy\"]=modelHistory.history['acc']\nhistory[\"Validation Accuracy\"]=modelHistory.history['val_acc']","38b04f33":"history.plot(figsize=(12,8))\nplt.title(\"E\u011fitim A\u015famas\u0131ndaki Kay\u0131p ve Ba\u015far\u0131 Grafi\u011fi\")\nplt.show()","fdb28d53":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"4.2.\"><\/a>4.2. VGGNet Modelinin Derlenmesi\n\nSGD(Stochastic Gradient Desent) optimizasyon algoritmas\u0131 \u00f6\u011frenme oran\u0131 olarak 0.01, \u00f6\u011frenme oran\u0131n\u0131 zamanla azaltan zay\u0131flatma(decay) de\u011fi\u015fkenin de\u011feri 0.01\/40, momentum terim de\u011feri 0.9 ve SGD e\u011fimini h\u0131zland\u0131ran nestrov y\u00f6ntemi True yap\u0131l\u0131m\u0131\u015ft\u0131r.  ","f494150e":"**\u00c7al\u0131\u015fmay\u0131 be\u011fenirseniz l\u00fctfen oy vermeyi unutmay\u0131n ^____^. **","7b8f1932":"Keras modelleri g\u00f6r\u00fcnt\u00fcleri iki farkl\u0131 g\u00f6r\u00fcnt\u00fc formuna g\u00f6re e\u011fitilir;channels last(kanal en sonda), channels first(kanal en ba\u015fta). Model e\u011fitilmeden \u00f6nce hangi g\u00f6r\u00fcnt\u00fc formunun kullan\u0131ld\u0131\u011f\u0131n\u0131n bilinmesi gerekir. Keras'\u0131n kulland\u0131\u011f\u0131 varsay\u0131lan g\u00f6r\u00fcnt\u00fc formu channel last't\u0131r. \n\nKanal en sonda formunda boyutlar geni\u015flik, y\u00fckseklik ve kanal olara s\u0131ralan\u0131r. Kanal en ba\u015fta g\u00f6r\u00fcnt\u00fc formunda boyutlar kanal, geni\u015flik ve y\u00fckseklik olarak s\u0131ralan\u0131r.\n\nKullan\u0131lan g\u00f6r\u00fcnt\u00fc formunu a\u015fa\u011f\u0131daki gibi kolayca \u00f6\u011frenilebilir. ","b51fac70":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=\"4.\"><\/a>4. VGGNet Modellerinin CIFAR-10 \u00dczerinde Kullan\u0131lmas\u0131\n\nMakine \u00f6\u011frenmesi uygulamalar\u0131nda en \u00f6nemli ad\u0131mlar\u0131ndan biri veri setinin modele uygun bi\u00e7ime getirilmesidir. Cifar10 veri seti profesyonelce olu\u015fturulmu\u015f bir veri seti oldu\u011fu \u00e7ok fazla \u00f6n i\u015flemeye gerek ihtiya\u00e7 yoktur. Ancak yinede yap\u0131lmas\u0131 gereken bir ka\u00e7 \u00f6n i\u015flem vard\u0131r. ","1be2aa8b":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"3.1.\"><\/a>3.1. MiniVGGNet\n\nMiniVGGNet tamamen ki\u015fisel bir tercih olarak Andrew Rosebrock taraf\u0131nda adland\u0131r\u0131lm\u0131\u015ft\u0131r. Katman say\u0131s\u0131 6 olmas\u0131na ra\u011fmen BatchNormalization etkisiyle olduk\u00e7a iyi sonu\u00e7 vermektedir. ","e46f53ae":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=\"1.\"><\/a>\u00c7al\u0131\u015fman\u0131n \u00d6zeti\n    \nBu \u00e7al\u0131\u015fmada derin a\u011f mimarisi olan VGGNet modelleri CIFAR-10 veri seti \u00fczerinde kullan\u0131lacakt\u0131r. Ilk \u00f6nce CIFAR-10  veri seti Kaggle \u00e7al\u0131\u015fma ortam\u0131na dahil edilecektir ve veri setinin g\u00f6rselle\u015ftirilmesi yap\u0131lacakt\u0131r. Daha sonra VGGNet hakk\u0131nda bilgiler verilecektir. VGGNet modellerinin kodlanmas\u0131 s\u0131n\u0131f kullan\u0131larak yap\u0131lacakt\u0131r. Olu\u015fturulan VGGNet modelleri CIFAR-10 e\u011fitim veri seti \u00fczerinde e\u011fiticilecek  ve daha sonra test verilerinin tahmininde kullan\u0131lacakt\u0131r.","b59547ed":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"4.1.\"><\/a>4.1. CIFAR-10 Veri Setinin Haz\u0131rlanmas\u0131\n\nBir \u00e7ok makine \u00f6\u011frenmesi y\u00f6nteminde oldu\u011fu gibi derin a\u011f modelleri de \u00f6l\u00e7eklendirilmi\u015f verilerde daha iyi sonu\u00e7 verirler. G\u00f6r\u00fcnt\u00fcler i\u00e7in yap\u0131lan \u00f6l\u00e7eklendirme i\u015flemi normalle\u015ftirme olarak adland\u0131r\u0131l\u0131r. Cifar10 g\u00f6r\u00fcnt\u00fcleri i\u00e7in normalle\u015ftirme i\u015flemi her bir pikselin 255'e b\u00f6l\u00fcnmesiyle ger\u00e7ekle\u015ftirilebilir. A\u015fa\u011f\u0131da e\u011fitim ve test g\u00f6r\u00fcnt\u00fclerinin normalle\u015ftirmesi yap\u0131lm\u0131\u015ft\u0131r.","7c418c7a":"Kullan\u0131lacak VGG mimarisini a\u015fa\u011f\u0131daki gibi se\u00e7ilebilir. VGG16 mimarisi i\u00e7in VGGNet_type de\u011fi\u015fkenini \"normal\" yapmak yeterli olacakt\u0131r.","940c5bb2":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"3.2.\"><\/a>3.2. VGGNet Modellerinin Kodlanmas\u0131\n\nBu \u00e7al\u0131\u015fmada VGG16 mimarisi kullan\u0131lm\u0131\u015ft\u0131r. Keras ile derin a\u011f mimarilerinin olu\u015fturulmas\u0131 olduk\u00e7a kolayd\u0131r. Katmanlar s\u0131rayla modele eklenerek derin a\u011f mimarisi olu\u015fturulur. A\u015fa\u011f\u0131da VGG16 ve MiniVGG mimarisine ait derin a\u011f mimarileri yer almaktad\u0131r. ","8935dc39":"# <a class=\"anchor\" id=\"0.\"><\/a>\u0130\u00e7indekiler\n\n* [1. \u00c7al\u0131\u015fman\u0131n \u00d6zeti](#1.)\n* * [1.1. Gerekli K\u00fct\u00fcphanelerin Dahil Edilmesi](#1.1.) \n* [2. CIFAR-10](#2.)\n* * [2.1. CIFAR-10 Veri Setinin Kaggle Ortam\u0131na Aktar\u0131lmas\u0131](#2.1.)\n* * [2.2. CIFAR-10 Veri Setinin G\u00f6rselle\u015ftirilmesi](#2.2.)\n* [3. VGGNet](#3.)\n* * [3.1. MiniVGGNet](#3.1.)\n* * [3.2. VGGNet Modellerinin Kodlanmas\u0131](#3.2.)\n* [4. VGGNet Modellerinin CIFAR-10 \u00dczerinde Kullan\u0131lmas\u0131](#4.)\n* * [4.1. CIFAR-10 Veri Setinin Haz\u0131rlanmas\u0131](#4.1.)\n* * [4.2. VGGNet Modelinin Derlenmesi](#4.2.)\n* * [4.3. VGGNet Modelinin E\u011fitilmesi](#4.3.)\n* * [4.4. CIFAR-10 Test Verileri \u00dczerinde Tahmin](#4.4.)","cff4b4a2":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"2.1.\"><\/a>2.1. CIFAR-10 Veri Setinin Kaggle Ortam\u0131na Aktar\u0131lmas\u0131\n\nVeri setinin \u00e7al\u0131\u015fma ortam\u0131na dahil edilmesi, veri setini oldu\u011fu sayfada a\u015fa\u011f\u0131daki gibi verilmi\u015ftir. ","cad63e8c":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"4.3.\"><\/a>4.3. VGGNet Modelinin E\u011fitilmesi\nModelin e\u011fitimi test veri setiyle beraber veriliyor. Bu \u015fekilde modelnin e\u011fitim ve test veri setleri i\u00e7in ba\u015far\u0131 ve kay\u0131p oranlar\u0131 g\u00f6zlemlenebilecektir. SGD optimizasyon y\u00f6nteminin kullanaca\u011fi \u00f6rnek miktar\u0131 64 olarak batch_size parametresiyle belirleniyor. Optimizasyon algoritmas\u0131 veri seti \u00fczerinde 40 kez \u00e7al\u0131\u015ft\u0131r\u0131lmas\u0131 epochs parametresiyle belirleniyor. verbose de\u011ferinin 0 olarak atanmas\u0131 model e\u011fitilirken \u00e7\u0131kt\u0131 yaz\u0131lmas\u0131n\u0131 engelliyor.  ","6cdd6ee6":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"1.1.\"><\/a>1.1. Gerekli K\u00fct\u00fcphanelerin Dahil Edilmesi\n\n\u00c7al\u0131\u015fmada kullan\u0131lacak k\u00fct\u00fcphaneler; numpy, pandas, sklearn, matplotlib ve keras","897b114c":"**5. Derin \u00d6\u011frenme Modelinin Serile\u015ftirmeyle Kaydedilmesi ve Y\u00fcklenmesi**\n\nDerin \u00f6\u011frenme modellerinin e\u011fitilmesi saatlerce, hatta haftlarca s\u00fcrebildi\u011fi i\u00e7in e\u011fitilen modellerin kaydedilmesini ve tekra y\u00fcklenmesini bilmek \u00f6nemlidir.\n\n","e9f2b062":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"4.4.\"><\/a>4.4. CIFAR-10 Test Verileri \u00dczerinde Tahmin\n\nE\u011fitilen model ile test veri seti \u00fczerinde tahmin yap\u0131l\u0131yor","e86b5a86":"Veri setinde ne t\u00fcr g\u00f6r\u00fcnt\u00fcler oldu\u011funu g\u00f6rmek faydal\u0131 olacakt\u0131r. Veri setini olu\u015fturan ki\u015filer g\u00f6r\u00fcnt\u00fcde sadece ilgili nesnenin olmas\u0131n\u0131 sa\u011flam\u0131\u015flard\u0131r. Arka planlar farkl\u0131 ve karma\u015f\u0131k olsada g\u00f6r\u00fcnt\u00fclerde sadece ilgili nesne olacak \u015fekilde olu\u015fturulmu\u015ftur.  \n\nA\u015fa\u011f\u0131daki add_side fonksiyonu \u00fc\u00e7 parametre almaktad\u0131r; images, side_type, side_size.\n* **images**: G\u00f6r\u00fcnt\u00fcleri tutan listedir\n* **side_type**: G\u00f6r\u00fcnt\u00fclere eklenecek kenar tipini tutar. Yatay kenar i\u00e7in \"horizantal\", dikey kenar i\u00e7in \"vertical\" de\u011ferini tutmas\u0131 gerekir\n* **side_size**: Eklenecek kenar\u0131n \u00f6l\u00e7\u00fcs\u00fcn\u00fc belirler\n\nFonksiyon side_type parametre de\u011ferine g\u00f6re, g\u00f6r\u00fcnt\u00fc listesine dikey veya yatay kenarlar ekler.","5549a7f8":"cifar10.load_data() fonksiyonu herbiri iki de\u011fi\u015fken tutan iki demet(tuple) veri tipini d\u00f6ner. Birinci demette e\u011fitim i\u00e7in ayr\u0131lan veri ve hedef listesi, ikinci demette test i\u00e7in ayr\u0131lan veri ve hedef listesi yer almaktad\u0131r. ","ab75aea8":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=\"2.2.\"><\/a>2.2. CIFAR-10 Veri Setinin G\u00f6rselle\u015ftirilmesi","5caf03ad":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=\"2.\"><\/a>2. CIFAR-10\n\nCIFAR-10, nesne tan\u0131ma i\u00e7in kullan\u0131lan yerle\u015fik bir bilgisayar-g\u00f6r\u00fc veri setidir. 80 milyon minik g\u00f6r\u00fcnt\u00fc veri setinin bir alt k\u00fcmesidir.  Alex Krizhevsky, Vinod Nair ve Geoffrey Hinton taraf\u0131ndan toplanm\u0131\u015ft\u0131r.\n\nT\u0131pk\u0131 MNIST gibi, CIFAR-10 da bilgisayarl\u0131 g\u00f6r\u00fc ve makine \u00f6\u011frenmesi literat\u00fcr\u00fcnde g\u00f6r\u00fcnt\u00fc s\u0131n\u0131fland\u0131rma i\u00e7in bir ba\u015fka standart k\u0131yaslama veri seti olarak kabul edilir.\n\n\nMNIST'te y\u00fczde 97 s\u0131n\u0131fland\u0131rma do\u011frulu\u011fu elde eden bir modeli e\u011fitmek olduk\u00e7a kolay olmakla birlikte, CIFAR-10 i\u00e7in b\u00f6yle bir model elde etmek olduk\u00e7a zordur.\n\nBuradaki zorluk, nesnelerin ortaya \u00e7\u0131kma \u015feklindeki dramatik de\u011fi\u015fkenlikten kaynaklan\u0131yor. \u00d6rne\u011fin, belirli bir koordinat aral\u0131\u011f\u0131nda k\u0131rm\u0131z\u0131 bir piksel i\u00e7eren b\u00f6lgeyi kamyon, araba, geyik veya gemi olarak kabul edemeyiz. Bu piksel, bahsi ge\u00e7en nesnelerin hepsinde olabilir. \n\nCIFAR-10 verileri, s\u0131n\u0131f ba\u015f\u0131na 6000 g\u00f6r\u00fcnt\u00fc i\u00e7eren, 10 s\u0131n\u0131f i\u00e7in toplamda 60.000 32x32 renkli g\u00f6r\u00fcnt\u00fcden olu\u015fur. Veri setini olu\u015fturan ki\u015filer, verileri 50.000 e\u011fitim g\u00f6r\u00fcnt\u00fcs\u00fc ve 10.000 test g\u00f6r\u00fcnt\u00fcs\u00fcne ay\u0131rm\u0131\u015ft\u0131r.\n\nVeri k\u00fcmesindeki etiket s\u0131n\u0131flar\u0131:\n\n* airplane: u\u00e7ak\n* car: otomobil\n* bird: ku\u015f\n* cat: kedi\n* deer: geyik\n* dog: k\u00f6pek\n* kurba\u011fa: frog\n* horse: at\n* ship: gemi\n* truck: kamyon\n\nS\u0131n\u0131flar tamamen birbirini d\u0131\u015flayacak \u00f6rneklerden olu\u015fturulmu\u015ftur. Yani, otomobiller ve kamyonlar aras\u0131nda \u00f6rt\u00fc\u015fme yoktur. \u201cOtomobil\u201d sedanlar, SUV'ler vb. modelleri i\u00e7erir. \"Kamyon\" sadece b\u00fcy\u00fck kamyonlar\u0131 i\u00e7erir. \u00d6rne\u011fin; kamyonet  i\u00e7ermez.\n","bb18926a":"S\u0131n\u0131fland\u0131rma sonu\u00e7lar\u0131n\u0131 ","7792bfa0":"Model davran\u0131\u015f\u0131n\u0131 e\u011fitim ve test veri setlerinin ba\u015far\u0131 ve kay\u0131p oranlar\u0131n\u0131 g\u00f6zlemleyerek incelenebilir. ","f3a1fb68":"Keras k\u00fct\u00fcphanesinden kullan\u0131lacak modell\u00fcr geli\u015ftirime ortam\u0131na dahil ediliyor.","ecf96410":"Keras derin a\u011f modellerine hedef de\u011fi\u015fken listesini verilmesi sklearn modellerine hedef de\u011fi\u015fken listesi verilmesinden biraz farkld\u0131r. sklearn modellerine hedef de\u011fi\u015fken listesini bir boyutlu verebilirken, keras modelleri i\u00e7in OneHot kodla i\u015fleminin yap\u0131lmas\u0131 gerekir. OneHot kodlama i\u015fleminde her bir hedef de\u011fi\u015fen s\u0131n\u0131f say\u0131s\u0131 uzunlu\u011funda bir listede tutulur. \u00d6rne\u011fin 6 de\u011ferine sahip bir hedef de\u011fi\u015fkenin OneHot kodlama g\u00f6sterimi a\u015fa\u011f\u0131daki gibi olacakt\u0131r:\n* [6]==>[0 0 0 0 0 0 1 0 0 0]","c0abf3b8":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=\"3.\"><\/a>3. VGGNet\n\nVGGNet Oxford \u00dcniversitesi Visual Geometry Group taraf\u0131nda \u00f6nerilmi\u015ftir. VGGNet'in iki temel karakteristi\u011fi vard\u0131r: 1) T\u00fcm CONV katmanlar\u0131ndan 3x3 filtre kullanmas\u0131 2) Bir\u00e7ok CONV=>RELU katman\u0131n\u0131 POOL katman\u0131ndan \u00f6nce \u00fcst \u00fcste kullanmas\u0131d\u0131r. \n\nVGG mimarisi 16 ve 19 katmanl\u0131 olmak \u00fczere iki farkl\u0131 t\u00fcr\u00fc vard\u0131r; VGG16, VGG19. Katman say\u0131s\u0131 a\u011f\u0131rl\u0131k katmanlar\u0131n\u0131n say\u0131s\u0131na g\u00f6re belirlenmi\u015ftir. "}}