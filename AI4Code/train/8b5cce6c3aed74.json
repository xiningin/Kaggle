{"cell_type":{"8e61ef84":"code","d3facc0f":"code","4a647a3b":"code","1e05fe2e":"code","9bf3b595":"code","8d80c593":"code","7df44f1c":"code","30391ce8":"code","e02ce1ae":"code","29e52239":"code","d874df65":"code","27f998f5":"code","ff68a192":"code","af9610c7":"code","37339289":"code","bde3d932":"code","d1ad4410":"code","47ea0101":"code","486e1ea2":"markdown","8f527165":"markdown","a584c4ad":"markdown","d80b2624":"markdown","78a63856":"markdown","4d8e7ddc":"markdown","cbb6af53":"markdown","168bb050":"markdown","f167d63b":"markdown","ad64519d":"markdown"},"source":{"8e61ef84":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport re\nimport cv2\nimport keras\nimport random\nfrom keras.layers import MaxPool2D,Conv2D,UpSampling2D,Input,Dropout,Dense,Convolution2D,MaxPooling2D,Reshape,Flatten,Conv2DTranspose\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.image import img_to_array\nfrom tqdm import tqdm\nfrom PIL import Image \nfrom IPython.display import SVG\nfrom keras.callbacks import ModelCheckpoint\n\nprint('start')","d3facc0f":"# to get the files in proper order\ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n\n# defining the size of the image\nSIZE = 160\n\n#\u5f97\u5230\u5f69\u8272\u56fe\u50cf\ncolor_img = []\npath = '..\/input\/landscape-image-colorization\/landscape Images\/color'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):    \n    if i == '6000.jpg':\n        break\n    else:    \n        img = cv2.imread(path + '\/'+i,1)\n        # BGR\u8f6cRGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        #\u5f52\u4e00\u5316\n        img = img.astype('float32') \/ 255.0\n        color_img.append(img_to_array(img))\n\n#\u5f97\u5230\u7070\u8272\u56fe\u50cf\ngray_img = []\npath = '..\/input\/landscape-image-colorization\/landscape Images\/gray'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):\n     if i == '6000.jpg':\n        break\n     else: \n        img = cv2.imread(path + '\/'+i,1)\n\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        #\u5f52\u4e00\u5316\n        img = img.astype('float32') \/ 255.0\n        gray_img.append(img_to_array(img))\n         \n   ","4a647a3b":"# defining function to plot images pair\ndef plot_images(color,grayscale):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('Color Image', color = 'blue', fontsize = 20)\n    plt.imshow(color)\n    plt.subplot(1,3,2)\n    plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n    plt.imshow(grayscale)\n   \n    plt.show()","1e05fe2e":"for i in range(42,45):\n     plot_images(color_img[i],gray_img[i])","9bf3b595":"#\u8bad\u7ec3\u96c6\ntrain_gray_image = gray_img[:4500]\ntrain_color_image = color_img[:4500]\n\n#\u9a8c\u8bc1\u96c6\nval_gray_image = gray_img[4500:5500]\nval_color_image = color_img[4500:5500]\n\n#\u6d4b\u8bd5\u96c6\ntest_gray_image = gray_img[5500:]\ntest_color_image = color_img[5500:]\n\n# reshape\ntrain_g = np.reshape(train_gray_image,(len(train_gray_image),SIZE,SIZE,3))\ntrain_c = np.reshape(train_color_image, (len(train_color_image),SIZE,SIZE,3))\nprint('Train color image shape:',train_c.shape)\n\nval_g = np.reshape(val_gray_image,(len(val_gray_image),SIZE,SIZE,3))\nval_c = np.reshape(val_color_image, (len(val_color_image),SIZE,SIZE,3))\nprint('Validation color image shape:',train_c.shape)\n\ntest_gray_image = np.reshape(test_gray_image,(len(test_gray_image),SIZE,SIZE,3))\ntest_color_image = np.reshape(test_color_image, (len(test_color_image),SIZE,SIZE,3))\nprint('Test color image shape',test_color_image.shape)","8d80c593":"#\u901a\u8fc7CNN\u4e2d\u7684kernal\u6570\u548ckernel size\u8fdb\u884c\u4e0b\u91c7\u6837\u548c\u4e0a\u91c7\u6837\n#down\u4e3a\u4e0b\u91c7\u6837\uff0cup\u4e3a\u4e0a\u91c7\u6837\nfrom keras import layers\ndef down(filters , kernel_size, apply_batch_normalization = True):\n    downsample = tf.keras.models.Sequential()\n    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n    if apply_batch_normalization:\n        downsample.add(layers.BatchNormalization())\n    downsample.add(keras.layers.LeakyReLU())\n    return downsample\n\n\ndef up(filters, kernel_size, dropout = False):\n    upsample = tf.keras.models.Sequential()\n    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n    if dropout:\n        upsample.dropout(0.2)\n    upsample.add(keras.layers.LeakyReLU())\n    return upsample\n","7df44f1c":"def model():\n    inputs = layers.Input(shape= [160,160,3])\n    d1 = down(128,(3,3),False)(inputs)\n    d2 = down(128,(3,3),False)(d1)\n    d3 = down(256,(3,3),True)(d2)\n    d4 = down(512,(3,3),True)(d3)\n    \n    d5 = down(512,(3,3),True)(d4)\n    #upsampling\n    u1 = up(512,(3,3),False)(d5)\n    u1 = layers.concatenate([u1,d4])\n    u2 = up(256,(3,3),False)(u1)\n    u2 = layers.concatenate([u2,d3])\n    u3 = up(128,(3,3),False)(u2)\n    u3 = layers.concatenate([u3,d2])\n    u4 = up(128,(3,3),False)(u3)\n    u4 = layers.concatenate([u4,d1])\n    u5 = up(3,(3,3),False)(u4)\n    u5 = layers.concatenate([u5,inputs])\n    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n    return tf.keras.Model(inputs=inputs, outputs=output)","30391ce8":"model = model()\nmodel.summary()","e02ce1ae":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])\nepochs = 50\nbatch_size = 50\nhistory = model.fit(train_g, train_c, epochs = epochs,batch_size = batch_size,verbose = 0,validation_data=(val_g,val_c))","29e52239":"model.evaluate(test_gray_image,test_color_image)","d874df65":"from tensorflow.keras import backend as Keras\nKeras.clear_session()\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs2 = range(1,epochs+1)\nfig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(121)\nax.plot(epochs2,loss,'bo',label = 'Training Loss')\nax.plot(epochs2,val_loss,'b',label='Validation Loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nax2 = fig.add_subplot(122)\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nax2.plot(epochs2,acc,'bo',label = 'Training Acc')\nax2.plot(epochs2,val_acc,'b',label='Validation Acc')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","27f998f5":"# defining function to plot images pair\ndef plot_images(color,grayscale,predicted):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('Color Image', color = 'blue', fontsize = 20)\n    plt.imshow(color)\n    plt.subplot(1,3,2)\n    plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n    plt.imshow(grayscale)\n    plt.subplot(1,3,3)\n    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n    plt.imshow(predicted)\n   \n    plt.show()\n\nfor i in range(79,82):\n    predicted = np.clip(model.predict(test_gray_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n    plot_images(test_color_image[i],test_gray_image[i],predicted)\n\n ","ff68a192":"def model_1():\n    inputs = layers.Input(shape= [160,160,3])\n    d1 = down(128,(5,5),False)(inputs)\n    d2 = down(128,(5,5),False)(d1)\n    d3 = down(256,(5,5),True)(d2)\n    d4 = down(256,(3,3),True)(d3)\n    d5 = down(512,(3,3),True)(d4)\n    \n     #upsampling\n    u1 = up(256,(3,3),False)(d5)\n    u1 = layers.concatenate([u1,d4])\n    u2 = up(256,(5,5),False)(u1)\n    u2 = layers.concatenate([u2,d3])\n    u3 = up(128,(5,5),False)(u2)\n    u3 = layers.concatenate([u3,d2])\n    u4 = up(128,(5,5),False)(u3)\n    u4 = layers.concatenate([u4,d1])\n    u5 = up(3,(3,3),False)(u4)\n    u5 = layers.concatenate([u5,inputs])\n    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n\n    return tf.keras.Model(inputs=inputs, outputs=output)","af9610c7":"model_1 = model_1()\nmodel_1.summary()","37339289":"model_1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])\nepochs = 100\nbatch_size = 20\nhistory_1 = model_1.fit(train_g, train_c, epochs = epochs,batch_size = batch_size,verbose = 0,validation_data=(val_g,val_c))","bde3d932":"from tensorflow.keras import backend as Keras\nKeras.clear_session()\nloss = history_1.history['loss']\nval_loss = history_1.history['val_loss']\nepochs2 = range(1,epochs+1)\nfig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(121)\nax.plot(epochs2,loss,'bo',label = 'Training Loss')\nax.plot(epochs2,val_loss,'b',label='Validation Loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nax2 = fig.add_subplot(122)\nacc = history_1.history['acc']\nval_acc = history_1.history['val_acc']\nax2.plot(epochs2,acc,'bo',label = 'Training Acc')\nax2.plot(epochs2,val_acc,'b',label='Validation Acc')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","d1ad4410":"model_1.evaluate(test_gray_image,test_color_image)","47ea0101":"# defining function to plot images pair\ndef plot_images(color,grayscale,predicted):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('Color Image', color = 'blue', fontsize = 20)\n    plt.imshow(color)\n    plt.subplot(1,3,2)\n    plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n    plt.imshow(grayscale)\n    plt.subplot(1,3,3)\n    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n    plt.imshow(predicted)\n   \n    plt.show()\n\nfor i in range(79,82):\n    predicted = np.clip(model_1.predict(test_gray_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n    plot_images(test_color_image[i],test_gray_image[i],predicted)\n","486e1ea2":"- \u6a21\u578b\u7ed3\u679c","8f527165":"- \u67e5\u770b\u56fe\u7247\uff08\u5f69\u8272\u4e0e\u7070\u8272\u5bf9\u6bd4\uff09","a584c4ad":"## 03 \u6a21\u578b","d80b2624":"- \u67e5\u770b\u6d4b\u8bd5\u96c6\u8bad\u7ec3\u7ed3\u679c","78a63856":"- \u8bad\u7ec3\u96c6\u4e0e\u6d4b\u8bd5\u96c6\u7684\u5212\u5206\u4e0ereshape","4d8e7ddc":"### Fitting model","cbb6af53":"## 02 \u6570\u636e","168bb050":"### Baseline Model","f167d63b":"# Autoencoder - Dogs and Cats\n#### \u6768\u8273\u8273 21210690119\n\n- Autoencoder\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u7ecf\u8fc7\u8bad\u7ec3\u53ef\u4ee5\u5c06\u8f93\u5165\u590d\u5236\u5230\u8f93\u51fa\u4e2d\u3002\n- Autoencoder\u662f\u901a\u8fc7\u5c06\u6570\u636e\u7f16\u7801\u4e3a\u4f4e\u7ef4\u6f5c\u5728\u6a21\u5f0f\uff0c\u518d\u5c06\u6f5c\u5728\u6a21\u5f0f\u89e3\u7801\u4e3a\u56fe\u50cf\uff0c\u56e0\u800c\u53ef\u4ee5\u5728\u7ef4\u6570\u707e\u96be\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6570\u636e\u964d\u7ef4\uff0c\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684autoencoder\u6a21\u578b\u5e94\u5f53\u80fd\u591f\u538b\u7f29\u6570\u636e\u5e76\u6700\u5c0f\u5316\u91cd\u5efa\u8bef\u5dee\u3002\n\n\u4ee5\u4e0b\u4e3a\u7528CNN\u7684\u65b9\u6cd5\u5bf9\u56fe\u7247\u505aautoencoding\u7684\u6982\u5ff5\u56fe\uff1a\n\n![image.png](attachment:af93d6da-4be5-486d-8543-940002abe215.png)\n\n- \u901a\u8fc7CNN\u4e2d\u7684convolution+pooling\uff0c\u5bf9\u56fe\u7247\u4e2d\u7684\u50cf\u7d20\u4fe1\u606f\u964d\u7ef4\u3001\u6d53\u7f29\n- \u518d\u5c55\u5f00\uff0c\u8fdb\u884cencode\u64cd\u4f5c\uff0c\u5373\u5c55\u5f00\u4e3a\u4e00\u7ef4\u6570\u636e\u3002\u6b64\u4e00\u7ef4\u6570\u636e\u4e0d\u4ec5\u80fd\u591f\u5c06\u539f\u56fe\u7247\u6570\u636e\u7684\u4fe1\u606f\u4fdd\u7559\uff0c\u8fd8\u80fd\u591f\u8bb0\u5f55\u5c11\u91cf\u5dee\u5f02\u3002\u5373\u8f93\u5165\u56fe\u50cf\u6709\u566a\u70b9\uff0c\u5bf9\u6bd4\u56fe\u50cf\u4e3a\u9ad8\u6e05\u7684\u60c5\u51b5\u4e0b\uff0c\u4e00\u7ef4\u6570\u636e\u53ef\u8bb0\u5f55\u4ece\u566a\u70b9\u5230\u9ad8\u6e05\u7684\u903b\u8f91\u5173\u7cfb\uff0c\u7406\u8bba\u4e0a\u5c31\u53ef\u4ee5\u6d88\u9664\u9a6c\u8d5b\u514b\uff1b\u540c\u7406\uff0c\u8f93\u5165\u4e3a\u9ed1\u767d\u7167\u7247\uff0c\u5bf9\u6bd4\u56fe\u50cf\u4e3a\u5f69\u8272\u7167\u7247\uff0c\u4e00\u7ef4\u6570\u636e\u53ef\u4f9d\u8bb0\u5f55\u9ed1\u767d\u5230\u5f69\u8272\u7684\u5173\u7cfb\uff0c\u80fd\u591f\u4e3a\u9ed1\u767d\u7167\u7247\u8fdb\u884c\u4e0a\u8272\u64cd\u4f5c\u3002\n","ad64519d":"## 01 Import"}}