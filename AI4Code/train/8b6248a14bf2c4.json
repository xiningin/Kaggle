{"cell_type":{"da3c2e5c":"code","b3dc551b":"code","78dc1988":"code","a0564b93":"code","c5337c23":"code","d8c5eaab":"code","c617cdb1":"code","d35d518b":"code","69570360":"code","f6d5839b":"code","5fa603d4":"code","013d1928":"code","b80055cb":"code","8bbc8f7f":"code","df99ad59":"code","0aa1844c":"code","5a371c84":"code","54f95e99":"code","e2220010":"code","7f9619b4":"code","625d3d12":"code","779b98c7":"code","57ecf0d6":"code","704388ed":"code","6bbb46e8":"code","7b468a37":"code","c024742d":"code","d17f9139":"code","f718be71":"code","25497acd":"code","411441df":"code","d3714982":"code","aa8fbf3c":"code","98c30508":"code","2f719974":"code","8654c830":"code","75f005fe":"code","aac0f2d1":"code","36867b0d":"code","3a508f1a":"code","45052b13":"markdown","955b45a5":"markdown","ef4bbc6a":"markdown","a8c9fe5c":"markdown","88792a57":"markdown","c8162ead":"markdown","b5a89782":"markdown","cc48a05f":"markdown","39e613e8":"markdown","03243a1e":"markdown","a29c81b3":"markdown","4fe7b912":"markdown","a91c7b2b":"markdown","c0701345":"markdown","9ca9a2e6":"markdown","03b0e55b":"markdown","947d0007":"markdown","e94bbd99":"markdown","5591fd49":"markdown","8c93946f":"markdown","f826bce0":"markdown","01ff37af":"markdown","3d45a341":"markdown","bb1ce096":"markdown","f8fa9499":"markdown","82a4c324":"markdown","113647eb":"markdown","75483ded":"markdown"},"source":{"da3c2e5c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","b3dc551b":"data=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndata.head()","78dc1988":"data.info()","a0564b93":"data.describe()","c5337c23":"sns.heatmap(data.isnull(),yticklabels=False,cmap='viridis',cbar=False)\n#age and cabin has most null values","d8c5eaab":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=data)","c617cdb1":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass',data=data)","d35d518b":"sns.set_style('whitegrid')\nsns.countplot(x='Pclass',hue='Sex',data=data)","69570360":"plt.figure(figsize=(19, 8))\nsns.boxplot(x='Pclass',y='Age',data=data,hue='Sex',color=\"cyan\")","f6d5839b":"data.groupby(['Pclass','Sex'])['Age'].mean()","5fa603d4":"sns.distplot(data['Age'],kde=False)","013d1928":"data['Age']=data['Age'].fillna(0)\ntest['Age']=test['Age'].fillna(0)","b80055cb":"def fill_AgeD(row):\n    if(row['Sex']=='male' and row['Pclass']==1 and row['Age']==0):\n        row['Age']=41\n    elif(row['Sex']=='female' and row['Pclass']==1 and row['Age']==0):\n        row['Age']=35\n    elif(row['Sex']=='male' and row['Pclass']==2 and row['Age']==0):\n        row['Age']=31\n    elif(row['Sex']=='female' and row['Pclass']==2 and row['Age']==0):\n        row['Age']=29\n    elif(row['Sex']=='male' and row['Pclass']==3 and row['Age']==0):\n        row['Age']=26\n    elif(row['Sex']=='female' and row['Pclass']==3 and row['Age']==0):\n        row['Age']=22\n    return row\n    \ndata=data.apply(fill_AgeD,axis=1)\n","8bbc8f7f":"test.groupby(['Pclass','Sex'])['Age'].mean()","df99ad59":"def fill_AgeT(row):\n    if(row['Sex']=='male' and row['Pclass']==1 and row['Age']==0):\n        row['Age']=40\n    elif(row['Sex']=='female' and row['Pclass']==1 and row['Age']==0):\n        row['Age']=41\n    elif(row['Sex']=='male' and row['Pclass']==2 and row['Age']==0):\n        row['Age']=31\n    elif(row['Sex']=='female' and row['Pclass']==2 and row['Age']==0):\n        row['Age']=24\n    elif(row['Sex']=='male' and row['Pclass']==3 and row['Age']==0):\n        row['Age']=24\n    elif(row['Sex']=='female' and row['Pclass']==3 and row['Age']==0):\n        row['Age']=23\n    return row\n    \ntest=test.apply(fill_AgeT,axis=1)\ntest.head()","0aa1844c":"data.groupby(['Pclass','Sex'])['Age'].mean()","5a371c84":"sns.distplot(data['Age'],kde=False)","54f95e99":"sns.heatmap(data.isnull(),yticklabels=False,cmap='viridis',cbar=False)","e2220010":"data.drop('Cabin',axis=1,inplace=True)\ntest.drop('Cabin',axis=1,inplace=True)","7f9619b4":"def age_cat(val):\n    if val<1:\n        return 'Infant'\n    elif val>1 and val < 13:\n        return 'Child'\n    elif val>13 and val < 18:\n        return 'Teen'\n    elif val>18 and val < 65:\n        return 'Adult'\n    else:\n        return 'Elderly'\ndata['Age_category']=data['Age'].apply(age_cat)","625d3d12":"plt.figure(figsize=(15, 8))\nsns.set_style('whitegrid')\nsns.countplot(x='Age_category',hue='Survived',data=data)","779b98c7":"res=data[data['Survived']==1].groupby('Sex')['Survived'].count()\nres\nres=np.array(res)\nlabels=['Female','Male']\nplt.pie(res,autopct='%1.1f%%', shadow=True, startangle=140,labels=labels,explode = (0.1,0))\n#most people survived from Embarked Region=Southampton\n","57ecf0d6":"res=data[data['Survived']==1].groupby('Embarked')['Survived'].count()\nres=np.array(res)\nlabels=['Cherbourg','Queenstown','Southampton']\nplt.pie(res,autopct='%1.1f%%', shadow=True, startangle=140,labels=labels,explode = (0.1, 0, 0))\n#most people survived from Embarked Region=Southampton\n","704388ed":"res=pd.get_dummies(data['Embarked'])\ndata=pd.concat([data,res],axis=1)\ndata.drop('Embarked',axis=1,inplace=True)\nres=pd.get_dummies(test['Embarked'])\ntest=pd.concat([test,res],axis=1)\ntest.drop('Embarked',axis=1,inplace=True)\ndata.head()\n","6bbb46e8":"data['Family_Size']=data['SibSp']+data['Parch']+1\ndata.drop(['SibSp','Parch'],axis=1,inplace=True)\ntest['Family_Size']=test['SibSp']+test['Parch']+1\ntest.drop(['SibSp','Parch'],axis=1,inplace=True)\ndata.head()","7b468a37":"data['Sex']=data['Sex'].map({ 'male': 1, 'female': 0})\ntest['Sex']=test['Sex'].map({ 'male': 1, 'female': 0})\n","c024742d":"test.loc[test['Fare'].isna(),['Fare']]=13.67","d17f9139":"X=data.iloc[:,[2,4,5,7,9,10,11,12]].values\ny=data.iloc[:,1].values\ntest_X=test.iloc[:,[1,3,4,6,7,8,9,10]].values","f718be71":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)","25497acd":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\ntest_X =sc.transform(test_X)","411441df":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n# Creating odd list K for KNN\nneighbors = list(range(1,30))\n# empty list that will hold cv scores\ncv_scores = [ ]\n#perform 10-fold cross-validation\nfor K in neighbors:\n    knn = KNeighborsClassifier(n_neighbors = K)\n    scores = cross_val_score(knn,X_train,y_train,cv = 10,scoring =\n    \"accuracy\")\n    cv_scores.append(scores.mean())\n# Changing to mis classification error\nmse = [1-x for x in cv_scores]\n# determing best k\noptimal_k = neighbors[mse.index(min(mse))]\n\nprint(\"The optimal no. of neighbors is {}\".format(optimal_k))","d3714982":"from sklearn.neighbors import KNeighborsClassifier\nKNNclassifier=KNeighborsClassifier(n_neighbors=12)\nKNNclassifier.fit(X_train,y_train)\ny_pred = KNNclassifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy :\",accuracy_score(y_test,y_pred)*100)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)","aa8fbf3c":"from sklearn.svm import SVC\nSVMlinear=SVC(kernel='linear')\nSVMlinear.fit(X_train,y_train)\nSVMlinear_predict=SVMlinear.predict(X_test)\ny_pred = SVMlinear.predict(X_test)\nprint(\"Accuracy :\",accuracy_score(y_test,y_pred)*100)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)","98c30508":"from sklearn.svm import SVC\nSVMrbf=SVC(kernel='rbf')\nSVMrbf.fit(X_train,y_train)\nSVMrbf_predict=SVMrbf.predict(X_test)\ny_pred = SVMrbf.predict(X_test)\nprint(\"Accuracy :\",accuracy_score(y_test,y_pred)*100)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)","2f719974":"from sklearn.naive_bayes import GaussianNB\nNB=GaussianNB()\nNB.fit(X_train,y_train)\nNB_predict=NB.predict(X_test)\ny_pred = NB.predict(X_test)\nprint(\"Accuracy :\",accuracy_score(y_test,y_pred)*100)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)","8654c830":"from sklearn.tree import DecisionTreeClassifier\nDecisionTree=DecisionTreeClassifier(criterion='entropy',random_state=0)\nDecisionTree.fit(X_train,y_train)\nDecisionTree_predict=DecisionTree.predict(X_test)\ny_pred = DecisionTree.predict(X_test)\nprint(\"Accuracy :\",accuracy_score(y_test,y_pred)*100)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)","75f005fe":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\ntrees = list(range(1,20))\n# empty list that will hold cv scores\ncv_scores = [ ]\n#perform 10-fold cross-validation\nfor n in trees:\n    RFC = RandomForestClassifier(n_estimators = n,criterion='entropy',random_state=0)\n    scores = cross_val_score(RFC,X_train,y_train,cv = 10,scoring =\n    \"accuracy\")\n    cv_scores.append(scores.mean())","aac0f2d1":"# Changing to mis classification error\nmse = [1-x for x in cv_scores]\n# determing best n\noptimal_n = trees[mse.index(min(mse))]\nprint(\"The optimal no. of trees is {}\".format(optimal_n))","36867b0d":"from sklearn.ensemble import RandomForestClassifier\nRFC=RandomForestClassifier(n_estimators=17,criterion='entropy',random_state=0)\nRFC.fit(X_train,y_train)\nRFC_predict=RFC.predict(X_test)\ny_pred = RFC.predict(X_test)\nprint(\"Accuracy :\",accuracy_score(y_test,y_pred)*100)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)","3a508f1a":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = RFC.predict(test_X)\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput['PassengerId']=output['PassengerId'].astype(int)\n\noutput.to_csv('submission1.csv', index=False)","45052b13":"**<font size=\"4\">Distribution of Age after filling null's<\/font>**","955b45a5":"<font size=\"4\">SVM Model(kernel=linear)<\/font>","ef4bbc6a":"<font size=\"4\">Most Models like KNN work on Euclidean Distance, larger values will impact the result,hence scaling is required.<\/font>","a8c9fe5c":"**<font size=\"3\">getting Age distribution before filling<\/font>**","88792a57":"<font size=\"4\">Generating Output File<\/font>","c8162ead":"**<font size=\"4\">Data Pre-Processing<\/font>**","b5a89782":"**<font size=\"4\">Same for test data<\/font>**","cc48a05f":"<font size=\"4\">Naive Bayes Model<\/font>","39e613e8":"<font size=\"4\">SVM Model(kernel=rbf)<\/font>","03243a1e":"<font size=\"3\">X & Y matrix<\/font>","a29c81b3":"<font size=\"4\">Decision tree classifier<\/font>","4fe7b912":"<font size=\"4\">Finding Optimum no. of trees, using K-fold cross Validation<\/font>","a91c7b2b":"**<font size=\"4\">After filling the overall mean from each class is almost same<\/font>**","c0701345":"**<font size=\"3\">Conclusion from EDA : We can take mean of age along each Pclass to fill the null values<\/font>**","9ca9a2e6":"**<font size=\"4\">Cabin has 90 % + null values,dropping it<\/font>**","03b0e55b":"**<font size=\"4\">Age distribution based on category<\/font>**","947d0007":"**<font size=\"4\">Filling null values in age by mean from each class ,based on gender<\/font>**","e94bbd99":"<font size=\"4\">Conclusion: Random Forest Classifier has highest accuracy with 82%<\/font>","5591fd49":"**<font size=\"4\">EDA for filling missing values<\/font>**","8c93946f":"**<font size=\"4\">Load Data<\/font>**","f826bce0":"**<font size=\"4\">Male vs Female surviving %<\/font>**","01ff37af":"<font size=\"4\">Finding Optimum value of K, using K-fold cross Validation<\/font>","3d45a341":"<font size=\"5\">Please do Vote up if you like my work,any help to upgrade this is appreciated.<\/font>\n* Linkedin : https:\/\/www.linkedin.com\/in\/pratikrandad\/**","bb1ce096":"**<font size=\"4\">People surviving from each embarked places they boarded <\/font>**","f8fa9499":"**<font size=\"4\">Basic Data Analysis<\/font>**","82a4c324":"**<font size=\"4\">Filling Null values in Age by 0 for easier calculation<\/font>**","113647eb":"**<font size=\"4\">Finding missing values<\/font>**","75483ded":"**<font size=\"4\">Test has 1 null value in fare column<\/font>**"}}