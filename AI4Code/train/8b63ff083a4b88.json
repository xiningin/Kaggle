{"cell_type":{"1521887c":"code","63942294":"code","0fe6c8b2":"code","6691047c":"code","e12e6887":"code","f487e4e8":"code","3ff191f6":"markdown","206042e9":"markdown","1ff0d8c2":"markdown","14fa6d3e":"markdown","f46aeda0":"markdown"},"source":{"1521887c":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","63942294":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob","0fe6c8b2":"train_path = \"..\/input\/fruits\/fruits-360\/Training\/\"\ntest_path =  \"..\/input\/fruits\/fruits-360\/Test\/\"\n\nimg = load_img(train_path + \"Apple Braeburn\/0_100.jpg\")\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\n\nx = img_to_array(img)\nprint(x.shape)\n\nclassName = glob(train_path + \"\/*\" )\nnumberOfClass = len(className)\nprint(\"Number Of Class\",numberOfClass)","6691047c":"model = Sequential()\nmodel.add(Conv2D(32,(3,3),input_shape = x.shape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(numberOfClass)) # output\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer = \"rmsprop\",\n              metrics = [\"accuracy\"])\n\nbatch_size=32\n\n","e12e6887":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.3,\n                                   horizontal_flip = True,\n                                   zoom_range = 0.3)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                train_path,\n                                target_size = x.shape[:2],\n                                batch_size = batch_size,\n                                color_mode = \"rgb\",\n                                class_mode = \"categorical\")\n\ntest_generator = test_datagen.flow_from_directory(\n                                test_path,\n                                target_size = x.shape[:2],\n                                batch_size = batch_size,\n                                color_mode = \"rgb\",\n                                class_mode = \"categorical\")\n\nhist = model.fit_generator(\n        generator = train_generator,\n        steps_per_epoch = 1600 \/\/ batch_size,\n        epochs = 100,\n        validation_data = test_generator,\n        validation_steps = 800 \/\/ batch_size)\n","f487e4e8":"print(hist.history.keys())\nplt.plot(hist.history[\"loss\"], label = \"Train Loss\")\nplt.plot(hist.history[\"val_loss\"], label = \"Validation Loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(hist.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(hist.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()\nplt.show()","3ff191f6":"## Data Generation","206042e9":"#  Fruits CNN Modelling\n\nContent\n* [Implementing Libraries](#1)","1ff0d8c2":"## Implementing Libraries ","14fa6d3e":"## Model Evaluation","f46aeda0":"## Modelling"}}