{"cell_type":{"d1b68bd9":"code","35a4c92d":"code","e1e6b739":"code","f2689534":"code","374ec446":"code","3d9e61cb":"code","b9a76cc4":"code","7f7f4ebf":"code","2394142b":"code","bf3112d9":"code","3ccbb136":"code","9672d4cf":"code","ce11ad06":"code","254385b9":"code","a03e158e":"code","9caf3bf1":"code","868bde68":"code","51e7dc76":"code","4b0b1bed":"code","4d8541ec":"code","b9123518":"code","8240ecb1":"code","1379c976":"code","07b4ae6f":"code","8be8b085":"code","213e37c2":"code","c408e4f4":"code","5c5c00cb":"code","c80bd3c4":"markdown","ffa5fcb5":"markdown","1a72740c":"markdown","5094f755":"markdown","f1590487":"markdown","fb264ae1":"markdown","5b76da48":"markdown","2bfb5481":"markdown","0c8f6236":"markdown","695e1917":"markdown","dc30023b":"markdown"},"source":{"d1b68bd9":"import torch\nimport torchvision\nprint(torch.__version__)\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport os\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\n%matplotlib inline","35a4c92d":"#hyper parameters:\nRANDOM_SEED = 123\nBATCH_SIZE = 32\nNUM_EPOCHS = 256\nnum_epochs = 256\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","e1e6b739":"df= pd.read_csv(os.path.join(path,'train_labels.csv'))","f2689534":"#conversion to int dict:\n\nfull_dict={'ace of spades': 0, 'two of spades':1, 'three of spades':2, 'four of spades':3, 'five of spades':4, 'six of spades':5, 'seven of spades':6,\n      'eight of spades':7, 'nine of spades':8, 'ten of spades':9, 'jack of spades':10, 'queen of spades':11, 'king of spades':12,\n      'ace of hearts': 13, 'two of hearts': 14, 'three of hearts': 15, 'four of hearts': 16, 'five of hearts': 17, 'six of hearts': 18,\n      'seven of hearts':19, 'eight of hearts':20, 'nine of hearts':21, 'ten of hearts':22, 'jack of hearts': 23, 'queen of hearts': 24,\n      'king of hearts':25,\n      'ace of clubs': 26, 'two of clubs': 27, 'three of clubs': 28, 'four of clubs': 29, 'five of clubs': 30, 'six of clubs': 31,\n      'seven of clubs':32, 'eight of clubs':33, 'nine of clubs':34, 'ten of clubs':35, 'jack of clubs': 36, 'queen of clubs': 37,\n      'king of clubs':38,\n      'ace of diamonds': 39, 'two of diamonds': 40, 'three of diamonds': 41, 'four of diamonds': 42, 'five of diamonds': 43, 'six of diamonds': 44,\n      'seven of diamonds':45, 'eight of diamonds':46, 'nine of diamonds':47, 'ten of diamonds':48, 'jack of diamonds': 49, 'queen of diamonds': 50,\n      'king of diamonds':51\n           \n}","374ec446":"df['class_number'] = df['class'].map(full_dict)\ndf.loc[df['class_number'].isnull()]","3d9e61cb":"#conversion to int dict:\n\nfull_dict={'ace of spades': 0, 'two of spades':1, 'three of spades':2, 'four of spades':3, 'five of spades':4, 'six of spades':5, 'seven of spades':6,\n      'eight of spades':7, 'nine of spades':8, 'ten of spades':9, 'jack of spades':10, 'queen of spades':11, 'king of spades':12,\n      'ace of hearts': 13, 'two of hearts': 14, 'three of hearts': 15, 'four of hearts': 16, 'five of hearts': 17, 'six of hearts': 18,\n      'seven of hearts':19, 'eight of hearts':20, 'nine of hearts':21, 'ten of hearts':22, 'jack of hearts': 23, 'queen of hearts': 24,\n      'king of hearts':25,\n      'ace of clubs': 26, 'two of clubs': 27, 'three of clubs': 28, 'four of clubs': 29, 'five of clubs': 30, 'six of clubs': 31,\n      'seven of clubs':32, 'seven of seven':32, 'eight of clubs':33, 'eigth of clubs':33, 'nine of clubs':34, 'ten of clubs':35, 'jack of clubs': 36, 'queen of clubs': 37,\n      'king of clubs':38,\n      'ace of diamonds': 39, 'two of diamonds': 40, 'three of diamonds': 41, 'four of diamonds': 42, 'five of diamonds': 43, 'six of diamonds': 44,\n      'seven of diamonds':45, 'eight of diamonds':46, 'nine of diamonds':47, 'ten of diamonds':48, 'jack of diamonds': 49, 'queen of diamonds': 50,\n      'king of diamonds':51\n           \n}","b9a76cc4":"class MyDataset(Dataset):\n\n    def __init__(self, csv_path, img_dir, transform=None):\n    \n        df = pd.read_csv(csv_path)\n        self.img_dir = img_dir\n        self.img_names = df['filename']\n        self.y = df['class'].map(full_dict)\n        self.transform = transform\n\n    def __getitem__(self, index):\n        img = Image.open(os.path.join(self.img_dir,\n                                      self.img_names[index])).convert('RGB')#to convert grayscale images to RGB.\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        \n        label = self.y[index]\n        return img, label\n\n    def __len__(self):\n        return self.y.shape[0]","7f7f4ebf":"#Loading the pictures data\npath = '..\/input\/object-detection-dataset-standard-52card-deck'\n\n\nPATH_OF_DATA = os.path.join(path,'train\/train')\nTEST_PATH_OF_DATA = os.path.join(path,'test\/test')\nprint(PATH_OF_DATA)","2394142b":"#Transformers\ncustom_transform = transforms.Compose([#transforms.Lambda(lambda x: x\/255.),# not necessary\n                                       transforms.Resize((256, 256)),\n                                       transforms.RandomCrop((224, 224)),\n                                       #transforms.ColorJitter(brightness=0.5),\n                                       transforms.RandomRotation(degrees=45),\n                                       transforms.RandomHorizontalFlip(p=0.1),\n                                       #transforms.RandomVerticalFlip(p=0.5),\n                                       #transforms.RandomGrayscale(p=0.05),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.0, 0.0, 0.0), (1.0, 1.0, 1.0))\n                                      ])\n\ntest_transforms = transforms.Compose([#transforms.Lambda(lambda x: x\/255.),# not necessary\n                                       transforms.Resize((256, 256)),\n                                       transforms.RandomCrop((224, 224)),\n                                       #transforms.ColorJitter(brightness=0.5),\n                                       #transforms.RandomRotation(degrees=45),\n                                       #transforms.RandomHorizontalFlip(p=0.1),\n                                       #transforms.RandomVerticalFlip(p=0.5),\n                                       #transforms.RandomGrayscale(p=0.05),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.0, 0.0, 0.0), (1.0, 1.0, 1.0))\n                                      ])","bf3112d9":"df.nunique()","3ccbb136":"train_dataset = MyDataset(csv_path=os.path.join(path,'train_labels.csv'),\n                          img_dir=PATH_OF_DATA,\n                          transform=custom_transform)","9672d4cf":"train_loader = DataLoader(dataset=train_dataset,\n                          batch_size=BATCH_SIZE,\n                          drop_last=True,\n                          shuffle=True, # want to shuffle the dataset\n                          num_workers=2) # number processes\/CPUs to use","ce11ad06":"    valid_dataset = MyDataset(\n        csv_path=os.path.join(path,'train_labels.csv'),\n        img_dir=PATH_OF_DATA,\n        transform=test_transforms)\n\n    valid_loader = DataLoader(\n        dataset=valid_dataset,\n        batch_size=12,\n        shuffle=False,\n        num_workers=2)","254385b9":"    test_dataset = MyDataset(\n        csv_path=os.path.join(path,'test_labels.csv'),\n        img_dir=TEST_PATH_OF_DATA,\n        transform=test_transforms)\n\n    test_loader = DataLoader(\n        dataset=test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=2)","a03e158e":"for images, labels in train_loader:  \n    print('Image batch dimensions:', images.shape)\n    print('Image label dimensions:', labels.shape)\n    print('Class labels of 10 examples:', labels[:10])\n    break","9caf3bf1":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(0)\n\nnum_epochs = 2\nfor epoch in range(num_epochs):\n\n    for batch_idx, (x, y) in enumerate(train_loader):\n        \n        print('Epoch:', epoch+1, end='')\n        print(' | Batch index:', batch_idx, end='')\n        print(' | Batch size:', y.size()[0])\n        \n        x = x.to(device)\n        y = y.to(device)","868bde68":"example_rows = 2\nexample_cols = 5\n\n#sampler = torch.utils.data.RandomSampler(train_dataset)\n\n# Get a batch of images and labels  \n#images, indices = next(iter(sampler)) \n\nplt.rcParams['figure.dpi'] = 120  # Increase size of pyplot plots\n\n# Show a grid of example images    \nfig, axes = plt.subplots(example_rows, example_cols, figsize=(9, 5)) #  sharex=True, sharey=True)\naxes = axes.flatten()\n\n\nfor ax, image in zip(axes, images):\n    #ii=0\n    #ax.imshow(np.uint8((image.cpu().numpy().transpose((1, 2, 0)))))\n    ax.imshow(image.cpu().numpy().transpose((1, 2, 0)))\n    ax.set_axis_off()\n    #ax.set_title(f'T: {images(targets[1])}')\n    #ax.set_title(train_dataset.y[ii], fontsize=7)\n    #ii+=1\n\n\nfig.subplots_adjust(wspace=0.02, hspace=0)\nfig.suptitle('Augmented training set images', fontsize=20)\n#plt.show()","51e7dc76":"def compute_accuracy(model, data_loader):\n    correct_pred, num_examples = 0, 0\n    for i, (features, targets) in enumerate(data_loader):            \n        features = features.to(device)\n        targets = targets.to(device)\n        logits = model(features)\n        _, predicted_labels = torch.max(logits, 1)\n        num_examples += targets.size(0)\n        correct_pred += (predicted_labels == targets).sum()\n    return correct_pred.float()\/num_examples * 100","4b0b1bed":"import time\nimport torch\n\n\n\ndef train_model(model, num_epochs, train_loader,\n                valid_loader, test_loader, optimizer, device):\n\n    start_time = time.time()\n    minibatch_loss_list, train_acc_list, valid_acc_list = [], [], []\n    for epoch in range(num_epochs):\n\n        model.train()\n        for batch_idx, (features, targets) in enumerate(train_loader):\n\n            features = features.to(device)\n            targets = targets.to(device, dtype=torch.int64)\n\n            # ## FORWARD AND BACK PROP\n            logits = model(features)\n            loss = torch.nn.functional.cross_entropy(logits, targets)\n            optimizer.zero_grad()\n\n            loss.backward()\n\n            # ## UPDATE MODEL PARAMETERS\n            optimizer.step()\n\n            # ## LOGGING\n            minibatch_loss_list.append(loss.item())\n            if batch_idx % 50:\n                print(f'Epoch: {epoch+1:03d}\/{num_epochs:03d} '\n                      f'| Batch {batch_idx+1:04d}\/{len(train_loader):04d} '\n                      f'| Loss: {loss:.4f}')\n#################################################################################################################################\n        model.eval()\n        with torch.no_grad():  # save memory during inference\n            train_acc = compute_accuracy(model, train_loader#, device=device\n                                         )\n            valid_acc = compute_accuracy(model, valid_loader#, device=device\n                                         )\n            print(f'Epoch: {epoch+1:03d}\/{num_epochs:03d} '\n                  f'| Train: {train_acc :.2f}% '\n                  f'| Validation: {valid_acc :.2f}%')\n            train_acc_list.append(train_acc.item())\n            valid_acc_list.append(valid_acc.item())\n\n        elapsed = (time.time() - start_time)\/60\n        print(f'Time elapsed: {elapsed:.2f} min')\n\n    elapsed = (time.time() - start_time)\/60\n    print(f'Total Training Time: {elapsed:.2f} min')\n\n    #test_acc = compute_accuracy(model, test_loader#, device=device)\n    #print(f'Test accuracy {test_acc :.2f}%')\n\n    return minibatch_loss_list, train_acc_list, valid_acc_list","4d8541ec":"# imports from installed libraries\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n\ndef plot_training_loss(minibatch_loss_list, num_epochs, iter_per_epoch,\n                       results_dir=None, averaging_iterations=100):\n\n    plt.figure()\n    ax1 = plt.subplot(1, 1, 1)\n    ax1.plot(range(len(minibatch_loss_list)),\n             (minibatch_loss_list), label='Minibatch Loss')\n\n    if len(minibatch_loss_list) > 1000:\n        ax1.set_ylim([\n            0, np.max(minibatch_loss_list[1000:])*1.5\n            ])\n    ax1.set_xlabel('Iterations')\n    ax1.set_ylabel('Loss')\n\n    ax1.plot(np.convolve(minibatch_loss_list,\n                         np.ones(averaging_iterations,)\/averaging_iterations,\n                         mode='valid'),\n             label='Running Average')\n    ax1.legend()\n\n    ###################\n    # Set scond x-axis\n    ax2 = ax1.twiny()\n    newlabel = list(range(num_epochs+1))\n\n    newpos = [e*iter_per_epoch for e in newlabel]\n\n    ax2.set_xticks(newpos[::10])\n    ax2.set_xticklabels(newlabel[::10])\n\n    ax2.xaxis.set_ticks_position('bottom')\n    ax2.xaxis.set_label_position('bottom')\n    ax2.spines['bottom'].set_position(('outward', 45))\n    ax2.set_xlabel('Epochs')\n    ax2.set_xlim(ax1.get_xlim())\n    ###################\n\n    plt.tight_layout()\n\n    if results_dir is not None:\n        image_path = os.path.join(results_dir, 'plot_training_loss.pdf')\n        plt.savefig(image_path)\n\n\ndef plot_accuracy(train_acc_list, valid_acc_list, results_dir):\n\n    num_epochs = len(train_acc_list)\n\n    plt.plot(np.arange(1, num_epochs+1),\n             train_acc_list, label='Training')\n    plt.plot(np.arange(1, num_epochs+1),\n             valid_acc_list, label='Validation')\n\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout()\n\n    if results_dir is not None:\n        image_path = os.path.join(\n            results_dir, 'plot_acc_training_validation.pdf')\n        plt.savefig(image_path)\n\n\ndef show_examples(model, data_loader):\n\n    for batch_idx, (features, targets) in enumerate(data_loader):\n\n        with torch.no_grad():\n            features = features\n            targets = targets\n            logits = model(features)\n            predictions = torch.argmax(logits, dim=1)\n        break\n\n    fig, axes = plt.subplots(nrows=3, ncols=5,\n                             sharex=True, sharey=True)\n\n    nhwc_img = np.transpose(features, axes=(0, 2, 3, 1))\n    nhw_img = np.squeeze(nhwc_img.numpy(), axis=3)\n\n    for idx, ax in enumerate(axes.ravel()):\n        ax.imshow(nhw_img[idx], cmap='binary')\n        ax.title.set_text(f'P: {predictions[idx]} | T: {targets[idx]}')\n        ax.axison = False\n\n    plt.tight_layout()\n    plt.show()","b9123518":"class AlexNet(torch.nn.Module):\n\n    def __init__(self, num_classes):\n        super().__init__()\n        self.features = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 256, kernel_size=11, stride=4, padding=2),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n            #\n            torch.nn.Conv2d(256, 192, kernel_size=5, padding=2),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n            #\n            torch.nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            torch.nn.ReLU(inplace=True),\n            #\n            torch.nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            torch.nn.ReLU(inplace=True),\n            #\n            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = torch.nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = torch.nn.Sequential(\n            torch.nn.Dropout(0.5),\n            torch.nn.Linear(256 * 6 * 6, 4096),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Dropout(0.5),\n            torch.nn.Linear(4096, 4096),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), 256 * 6 * 6)\n        logits = self.classifier(x)\n        return logits","8240ecb1":"model = AlexNet(num_classes=52)\n\nmodel = model.to(DEVICE)\n\noptimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.01)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                       factor=0.1,\n                                                       mode='max',\n                                                       verbose=True)","1379c976":"#Training the Model\nminibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n    model=model,\n    num_epochs=NUM_EPOCHS,\n    train_loader=train_loader,\n    valid_loader=valid_loader,\n    test_loader=test_loader,\n    optimizer=optimizer,\n    device=DEVICE, \n    )","07b4ae6f":"plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n                   num_epochs=NUM_EPOCHS,\n                   iter_per_epoch=len(train_loader),\n                   results_dir=None,\n                   averaging_iterations=20)\nplt.show()\n\nplot_accuracy(train_acc_list=train_acc_list,\n              valid_acc_list=valid_acc_list,\n              results_dir=None)\nplt.ylim([80, 100])\nplt.show()","8be8b085":"plot_accuracy(train_acc_list=train_acc_list,\n              valid_acc_list=valid_acc_list,\n              results_dir=None)","213e37c2":"#reverse dict:\n\nrev_dict={0: 'ace of spades', 1: 'two of spades', 2: 'three of spades', 3: 'four of spades', 4: 'five of spades', 5: 'six of spades', 6: 'seven of spades',\n      7: 'eight of spades', 8: 'nine of spades', 9: 'ten of spades', 10: 'jack of spades', 11: 'queen of spades', 12: 'king of spades',\n      13: 'ace of hearts', 14: 'two of hearts', 15: 'three of hearts', 16: 'four of hearts', 17: 'five of hearts', 18: 'six of hearts',\n      19: 'seven of hearts', 20: 'eight of hearts', 21: 'nine of hearts', 22: 'ten of hearts', 23: 'jack of hearts', 24: 'queen of hearts',\n      25: 'king of hearts',\n      26: 'ace of clubs', 27: 'two of clubs', 28: 'three of clubs', 29: 'four of clubs', 30: 'five of clubs', 31: 'six of clubs',\n      32: 'seven of clubs', 33: 'eight of clubs', 34: 'nine of clubs', 35: 'ten of clubs', 36: 'jack of clubs', 37: 'queen of clubs',\n      38: 'king of clubs',\n      39: 'ace of diamonds', 40: 'two of diamonds', 41: 'three of diamonds', 42: 'four of diamonds', 43: 'five of diamonds', 44: 'six of diamonds',\n      45: 'seven of diamonds', 46: 'eight of diamonds', 47: 'nine of diamonds', 48: 'ten of diamonds', 49: 'jack of diamonds', 50: 'queen of diamonds',\n      51: 'king of diamonds'\n           \n}","c408e4f4":"for batch_idx, (features, targets) in enumerate(train_loader):\n\n    with torch.no_grad():\n        features = features\n        targets = targets\n        logits = model(features.cuda())\n        predictions = torch.argmax(logits, dim=1)\n    break\n\nfig, axes = plt.subplots(nrows=3, ncols=5,\n                          sharex=True, sharey=True, figsize=(15,12\n                                                             ))\n\nnhwc_img = np.transpose(features, axes=(0, 2, 3, 1))\n#nhwc_img = np.transpose(features, axes=(0, 2, 1))\n#nhw_img = np.squeeze(nhwc_img.numpy(), axis=1)\n\nfor idx, ax in enumerate(axes.ravel()):\n    ax.imshow(nhwc_img[idx], cmap='binary', aspect='auto')\n    ax.title.set_text(f'P: {rev_dict[predictions[idx].item()]} | T: {rev_dict[predictions[idx].item()]}')\n    ax.axison = False\n\nplt.tight_layout()\nplt.show()","5c5c00cb":"for batch_idx, (features, targets) in enumerate(valid_loader):\n\n    with torch.no_grad():\n        features = features\n        targets = targets\n        logits = model(features.cuda())\n        predictions = torch.argmax(logits, dim=1)\n    break\n\nfig, axes = plt.subplots(nrows=3, ncols=4,\n                          sharex=True, sharey=True, figsize=(15,12\n                                                             ))\n\nnhwc_img = np.transpose(features, axes=(0, 2, 3, 1))\n#nhwc_img = np.transpose(features, axes=(0, 2, 1))\n#nhw_img = np.squeeze(nhwc_img.numpy(), axis=1)\n\nfor idx, ax in enumerate(axes.ravel()):\n    ax.imshow(nhwc_img[idx], cmap='binary', aspect='auto')\n    ax.title.set_text(f'P: {rev_dict[predictions[idx].item()]} | T: {rev_dict[predictions[idx].item()]}')\n    ax.axison = False\n\nplt.tight_layout()\nplt.show()","c80bd3c4":"> **Functions**","ffa5fcb5":"> **Data Loader and Dataset**","1a72740c":"We can see that there are to kinds of nulls:\n1. eigth of clubs\n2. seven of seven\n\nThe former is clearly eight of clubs, and after checking, the latter is seven of clubs, so I just added them to the class dictionrary, and we are good to go.","5094f755":"> **setting the architeture**","f1590487":"# **EDA**","fb264ae1":"# **SAETUP**","5b76da48":"> **AlexNet**","2bfb5481":"> **Training the model and results**","0c8f6236":"> **Checking the Data**","695e1917":"In this project I'll use Alexnet in order to identify playing cards in a complete identification (ace of clubs. 52 categories)","dc30023b":"# **Complete Identification**"}}