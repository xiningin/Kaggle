{"cell_type":{"a242b878":"code","ce12a9ef":"code","4736389e":"code","56d9233b":"code","c5e78440":"code","aaa8c38d":"code","7d0fac2e":"code","bfd6f00a":"code","e31cffb0":"code","03fe7c93":"code","663f1de7":"code","76c265b0":"code","f1446f94":"code","ab4d9e7a":"markdown","3d64a43e":"markdown","36824e78":"markdown","73a10bfb":"markdown","476a43fb":"markdown","174c27ea":"markdown","3af64d4f":"markdown","308964ee":"markdown"},"source":{"a242b878":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nfrom random import sample\nimport time\n\nimport os\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom textblob import TextBlob","ce12a9ef":"PATH = '\/kaggle\/input\/jigsaw-toxic-severity-rating\/'\nvalid_data = pd.read_csv(PATH + 'validation_data.csv')\ncomment_data = pd.read_csv(PATH + 'comments_to_score.csv')\nsub = pd.read_csv(PATH + 'sample_submission.csv')","4736389e":"valid_data.sort_values('worker', inplace=True)\nvalid_data.head()","56d9233b":"valid_data.values.shape","c5e78440":"txteg = valid_data.values[0,2] # get text example from more_toxic\nvalid_data[valid_data['less_toxic']==txteg].head() # look for example in less_toxic","aaa8c38d":"#################################\n# get all unique texts\n#################################\nuts = list(set(valid_data['more_toxic'].values.tolist() + valid_data['less_toxic'].values.tolist()))\n# store texts in a dictionary with default value -1\nut_dict = {}\nfor ut in uts:\n    ut_dict[ut] = -1\n\n#################################\n# set values for unique texts given information from valid_data (relatively more or less)\n#################################\nepochs = 60 # number of times to loop over the dataset and make revisions to dictionary\nlrevisions = []\nlreversals = []\nfor i in range(epochs+1):\n    revisions = 0\n    reversals = 0\n    for index, row in valid_data.iterrows():\n        if (ut_dict[row['less_toxic']]==-1) and (ut_dict[row['more_toxic']]==-1): # both undefined\n            ut_dict[row['less_toxic']]=random.uniform(0, 100)\n            ut_dict[row['more_toxic']]=random.uniform(0, 100)\n            revisions += 2\n        elif (ut_dict[row['less_toxic']]!=-1) and (ut_dict[row['more_toxic']]==-1): # less defined, more not\n            cap = ut_dict[row['less_toxic']]\n            val = random.uniform(cap, 100)\n            ut_dict[row['more_toxic']] = val\n            revisions += 1\n        elif (ut_dict[row['less_toxic']]==-1) and (ut_dict[row['more_toxic']]!=-1): # less not defined, more defined\n            cap = ut_dict[row['more_toxic']]\n            val = random.uniform(0, cap)\n            ut_dict[row['less_toxic']] = val\n            revisions += 1\n        else: # both defined\n            if ut_dict[row['less_toxic']]<ut_dict[row['more_toxic']]:\n                pass # this is good to go\n            else: # more < less, which is wrong\n                changeType = random.choice([1,2,3]) # select 1 of 3 different types of revisions\n                if changeType==1: # reverse values\n                    more = ut_dict[row['more_toxic']]\n                    less = ut_dict[row['less_toxic']]\n                    ut_dict[row['more_toxic']] = less + random.uniform(-1, 1) # more = less + jitter\n                    ut_dict[row['less_toxic']] = more + random.uniform(-1, 1) # less = more + jitter\n                elif changeType==2: # set more to less + 1-ish\n                    ut_dict[row['more_toxic']] = ut_dict[row['less_toxic']] + random.uniform(0, 1)\n                elif changeType==3: # set less to more - 1-ish\n                    ut_dict[row['less_toxic']] = ut_dict[row['more_toxic']] - random.uniform(0, 1)\n                revisions += 1\n                reversals += 1\n    lrevisions.append(revisions)\n    lreversals.append(reversals)\n    if i % 5 == 0:\n        print(\"Round {} completed with {} total revisions and {} reversals.\".format(i,revisions,reversals))\nprint(\"All rounds completed.\")","7d0fac2e":"print(\"Algorithm Performance - all runs\")\npd.DataFrame({'Revisions':lrevisions,'Reversals':lreversals}).plot(figsize=(12, 6));","bfd6f00a":"print(\"Algorithm Performance - excluding the 1st run\")\npd.DataFrame({'Revisions':lrevisions[1:],'Reversals':lreversals[1:]}).plot(figsize=(12, 6));","e31cffb0":"# initialize lists\ntoxic_text = []\ntarget = []\naugmentation_percent = 0.90\n\n#################################\n# loop through valid_data and add text & target to training data lists\n# - also add a small jitter since we have duplicate text examples, for some regularization\n#################################\nfor index, row in tqdm(valid_data.iterrows()):\n    if random.uniform(0, 1)<augmentation_percent: # only augment x% of the time\n        try: # augmentations\n            augshuf = random.uniform(0, 1)\n            if augshuf<0.35:\n                french_translation = str(TextBlob(row['more_toxic']).translate(to='fr'))\n                more_toxic = str(TextBlob(french_translation).translate(to='en')) # back to Eng\n                french_translation = str(TextBlob(row['less_toxic']).translate(to='fr'))\n                less_toxic = str(TextBlob(french_translation).translate(to='en')) # back to Eng\n            else: # remove a random word\n                rand_word = sample(list(set(row['more_toxic'].split(\" \"))))[0]\n                more_toxic = row['more_toxic'].replace(rand_word, '')\n                rand_word = sample(list(set(row['less_toxic'].split(\" \"))))[0]\n                more_toxic = row['less_toxic'].replace(rand_word, '')\n            toxic_text.append(more_toxic)\n            target.append(ut_dict[row['more_toxic']] + random.uniform(-1, 1)) # value plus small jitter\n            toxic_text.append(less_toxic)\n            target.append(ut_dict[row['less_toxic']] + random.uniform(-1, 1)) # value plus small jitter\n        except:\n            toxic_text.append(row['more_toxic'])\n            target.append(ut_dict[row['more_toxic']] + random.uniform(-1, 1)) # value plus small jitter\n            toxic_text.append(row['less_toxic'])\n            target.append(ut_dict[row['less_toxic']] + random.uniform(-1, 1)) # value plus small jitter\n    else:\n        toxic_text.append(row['more_toxic'])\n        target.append(ut_dict[row['more_toxic']] + random.uniform(-1, 1)) # value plus small jitter\n        toxic_text.append(row['less_toxic'])\n        target.append(ut_dict[row['less_toxic']] + random.uniform(-1, 1)) # value plus small jitter","03fe7c93":"print(\"Text list length: \", len(toxic_text))\nprint(\"Target list length: \", len(target))","663f1de7":"training_data = pd.DataFrame()\ntraining_data['text'] = toxic_text\ntraining_data['target'] = target\ntraining_data.head()","76c265b0":"plt.hist(target, label='training target distribution');\nplt.legend();","f1446f94":"training_data.to_csv('jigsaw_rate_severity_training_data.csv', index=False)","ab4d9e7a":"## Quick EDA\n\nCan text be found more than once in either column?  - Answer: Yes","3d64a43e":"#### Compile Training Data & Target\n\n- Add all text in valid_data to a training dataset\/list with a corresponding target\n- Apply some augmentation to each text since we have duplicate texts\n- Apply some jitter to the target value since we have duplicate texts and augmentations, and just for some regularization","36824e78":"# Jigsaw Rate Severity - Simple LSTM\n\n**Work:**\n - Forked https:\/\/www.kaggle.com\/elcaiseri\/jigsaw-keras-embedding-lstm\n - Revised data prep and model architecture to run with single input (text) and get single score (relative severity of toxicity)\n     - Target is created by using the (less) and (more) information to assign a value that adheres to all (less) and (more) information\n - Revised optimizer and manually tuned learning rate for better performance\n - Added text augmentation\n\n**References and Acknowledgements:**\n - https:\/\/www.kaggle.com\/elcaiseri\/jigsaw-keras-embedding-lstm\n - https:\/\/www.kaggle.com\/elcaiseri\n - https:\/\/www.kaggle.com\/c\/jigsaw-toxic-severity-rating\/overview\n - https:\/\/github.com\/tensorflow\/tensorflow\/issues\/38613\n - https:\/\/www.kaggle.com\/yeayates21\/commonlit-text-augmentation-eng-to-fre-to-eng\/notebook","73a10bfb":"## Data Wrangling","476a43fb":"#### Final Training Data","174c27ea":"#### Create Target\n\n- We use the (less) and (more) information to assign values that adhere to all (less) and (more) information\n- We assign values to each text, then we loop through the data repeatedly, revising the values each time if there are cases where the value does not adhere\n- If all values adhere to the (less) and (more) information, then we should see fewer revisision with each round","3af64d4f":"## Imports","308964ee":"## Data Preprocessing"}}