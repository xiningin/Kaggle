{"cell_type":{"0ca2f79c":"code","c5f5587b":"code","f809eab0":"code","eaa08181":"code","8f815bc8":"code","e184050f":"code","5fbc866e":"code","8fe4e4f5":"code","8a5946da":"code","a21932ab":"code","c18b031e":"code","254fce21":"code","82c54da1":"code","ea965e21":"markdown","4eea0413":"markdown","19df8bca":"markdown","133329e5":"markdown","0c13bb0b":"markdown","b1a12fd3":"markdown","c6e3b8d0":"markdown","ce9060fd":"markdown","f5afa640":"markdown","37f02777":"markdown","a4c18d6b":"markdown","0dac986d":"markdown","e2f88567":"markdown"},"source":{"0ca2f79c":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import layers\nfrom collections import defaultdict\nfrom PIL import Image\nfrom six.moves import range\n\nprint(\"Tensorflow version \" + tf.__version__)","c5f5587b":"np.random.seed(1337)\nnum_classes = 10\n\nepochs = 30\nlatent_dim = 128\n\nadam_lr = 0.0002\nadam_beta_1 = 0.5","f809eab0":"def build_generator(latent_size):\n    cnn = tf.keras.Sequential()\n\n    cnn.add(layers.Dense(7 * 7 * 128, input_dim=latent_size))\n    cnn.add(layers.LeakyReLU(alpha=0.2))\n    cnn.add(layers.Reshape((7, 7, 128)))\n\n    cnn.add(layers.Conv2DTranspose(128, 4, strides=2, padding='same',\n                          kernel_initializer='glorot_normal'))\n    cnn.add(layers.LeakyReLU(alpha=0.2))\n    cnn.add(layers.BatchNormalization())\n\n    cnn.add(layers.Conv2DTranspose(128, 4, strides=2, padding='same',\n                          kernel_initializer='glorot_normal'))\n    cnn.add(layers.LeakyReLU(alpha=0.2))\n    cnn.add(layers.BatchNormalization())\n\n    cnn.add(layers.Conv2D(1, 7, padding='same',\n                          activation='tanh',\n                          kernel_initializer='glorot_normal'))\n    \n    return cnn","eaa08181":"def build_discriminator():\n\n    cnn = tf.keras.Sequential()\n\n    cnn.add(layers.Conv2D(32, 3, padding='same', strides=2,\n                          input_shape=(28, 28, 1)))\n    cnn.add(layers.LeakyReLU(0.2))\n    cnn.add(layers.Dropout(0.3))\n\n    cnn.add(layers.Conv2D(64, 3, padding='same', strides=1))\n    cnn.add(layers.LeakyReLU(0.2))\n    cnn.add(layers.Dropout(0.3))\n\n    cnn.add(layers.Conv2D(128, 3, padding='same', strides=2))\n    cnn.add(layers.LeakyReLU(0.2))\n    cnn.add(layers.Dropout(0.3))\n\n    cnn.add(layers.Conv2D(256, 3, padding='same', strides=1))\n    cnn.add(layers.LeakyReLU(0.2))\n    cnn.add(layers.Dropout(0.3))\n    \n    cnn.add(layers.GlobalMaxPooling2D()),\n    cnn.add(layers.Dense(1))\n    \n    return cnn","8f815bc8":"print('Discriminator model:')\ndiscriminator = build_discriminator()\ndiscriminator.summary()","e184050f":"print('Generator model:')\ngenerator = build_generator(latent_dim)\ngenerator.summary()","5fbc866e":"class GAN(tf.keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n\n    def train_step(self, real_images):\n        if isinstance(real_images, tuple):\n            real_images = real_images[0]\n        # Sample random points in the latent space\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Decode them to fake images\n        generated_images = self.generator(random_latent_vectors)\n\n        # Combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n\n        # Assemble labels discriminating real from fake images\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n        # Add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n","8fe4e4f5":"class GANMonitor(tf.keras.callbacks.Callback):\n    def __init__(self, num_img=3, latent_dim=128):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))","8a5946da":"gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\ngan.compile(\n    d_optimizer=tf.keras.optimizers.Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n    g_optimizer=tf.keras.optimizers.Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n)","a21932ab":"batch_size = 64\n(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\nall_digits = np.concatenate([x_train, x_test])\nall_digits = all_digits.astype(\"float32\") \/ 255\nall_digits = np.reshape(all_digits, (-1, 28, 28, 1))\ndataset = tf.data.Dataset.from_tensor_slices(all_digits)\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)","c18b031e":"gan.fit(\n    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n)","254fce21":"!ls","82c54da1":"Image.open(\"generated_img_2_20.png\")","ea965e21":"For this tutorial, we will be focusing on the MNIST dataset. The MNIST dataset is a dataset of images of handwritten digits from 0 to 9. Since there are 10 digits, there are also 10 classes. The random seed is used so that the results are reproducible. We will load in our data after we define our methods below.","4eea0413":"## 4. Load the data\n\nNow that the models have been defined and built, we have to load the data to train the model on. This tutorial will focus on the MNIST dataset. Luckily for us, the MNIST dataset can be easily accessed from the TensorFlow API.\n\nWe want our data to be normalized to [0, 1]. As the data initially is between [0, 255], we will have to do some basic preprocessing and reshaping. Additionally, don't need a training and testing dataset because the images in both the the training and testing dataset are real images. Therefore, we can combine the two into a singular dataset to be used in our training.\n\nRun the next cell to load and normalize the data.","19df8bca":"## 3. Build the discriminator\n\nThe second part of our generative model is our discriminator. The discriminator will be trained separately. It determines if the inputted image is a real or a fake image. The discriminator is used to train the generator.","133329e5":"We will also create a subclass of the TensorFlow Keras Callback class called GANMonitor. Calling an instance of this subclass allos us to save a generated image at the end of each epoch to see how the model is improving.","0c13bb0b":"Adapted from [GitHub ACGAN Keras Example](https:\/\/github.com\/keras-team\/keras\/blob\/master\/examples\/mnist_acgan.py) and [GitHub Training Override Example](https:\/\/github.com\/keras-team\/keras-io\/blob\/master\/examples\/generative\/dcgan_overriding_train_step.py)\n\nTensorFlow 1.x --> Tensorflow 2.x\n\nUses GPU Accelerator","b1a12fd3":"Run the following cells to train the discriminator.","c6e3b8d0":"## 6. Visualize the generated images\n\nRun the following cell to visualize some of the saved generated images.","ce9060fd":"## 2. Building the generator\n\nThe first step of building the GAN is to build the generator model. As the name implies, the generator model will be the part of our model that generates the images. The function that builds our generator is defined in the following cell using the TensorFlow Keras API.","f5afa640":"Let's now build our combined model. The generator is the model will be trained with the output of the discriminator. Additionally, since we have two ouputs, we want to measure both the binary crosentropy and the sparse cateogircal crossentropy as our losses.","37f02777":"We are going to create a new class called GAN and it will be a subclass of the TensorFlow Keras Model class. By creating a new subclass, we can rewrite the ```train_step``` function, which will allow us to call ```model.fit()```. This reduces the code that we have to write to train this generative model and it allows for ease of readability.","a4c18d6b":"## 5. Train the model\n\nWe previously specified the model to train for 30 epochs. Try training the model on more or less epochs to see the differences in loss and accuracy. The loss for our generative model and for our discriminator can be seen at the end of each epoch.","0dac986d":"## 3. Build the combined model\n\nAlthough the discriminator was trained separately, it's necessary to train the generator by using the discriminator. The generator will output an image and the discriminator will determine if the generated fake image is real or fake. The output of the discriminator will help train the generator.","e2f88567":"## 1. Introduction\n\nThis tutorial will go over the steps to build an ACGAN model on the MNIST dataset. The MNIST dataset is a dataset of images of handwritten digits 0 through 9. The ACGAN model, once trained, will generate fake images that resemble the real images of each class.\n\nRun the following cells to import the necessary packages for this tutorial."}}