{"cell_type":{"7f0a839d":"code","715fb18e":"code","e5436438":"code","21222ace":"code","fc4eb8c4":"code","827de832":"code","4b2d3093":"code","ff7cf044":"code","7eb073c2":"code","38c6b885":"markdown","3581914f":"markdown","a1b8c911":"markdown","def57b79":"markdown","ae708b09":"markdown","3442a265":"markdown","cbf82590":"markdown","36e4b47d":"markdown","73f3a0a9":"markdown","5fc2eca4":"markdown","8b923591":"markdown","8f636085":"markdown","bef9c2d2":"markdown","acbd88a9":"markdown","ffdde2ca":"markdown","45e0a6c5":"markdown"},"source":{"7f0a839d":"import streamlit as st\nfrom spacy import displacy","715fb18e":"from gensim.summarization import summarize","e5436438":"from sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer\nfrom sumy.summarizers.lex_rank import LexRankSummarizer","21222ace":"import nltk \nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize, sent_tokenize","fc4eb8c4":"from bs4 import BeautifulSoup\nfrom urllib.request import urlopen","827de832":"@st.cache\ndef get_text(raw_url):\n    page = urlopen(raw_url)\n    soup = BeautifulSoup(page)\n    fetched_text = ' '.join(map(lambda p:p.text,soup.find_all('p')))\n    return fetched_text","4b2d3093":"def sumy_summarizer(docx):\n    parser = PlaintextParser.from_string(docx, Tokenizer(\"english\"))\n    lex_summarizer = LexRankSummarizer()\n    summary = lex_summarizer(parser.document, 3)\n    summary_list = [str(sentence) for sentence in summary]\n    result = ' '.join(summary_list)\n    return result","ff7cf044":"def nltk_summarizer(docx):\n    stopWords = set(stopwords.words(\"english\")) \n    words = word_tokenize(docx) \n    freqTable = dict() \n    for word in words: \n        word = word.lower() \n        if word in stopWords: \n            continue\n        if word in freqTable: \n            freqTable[word] += 1\n        else: \n            freqTable[word] = 1\n       \n    sentences = sent_tokenize(docx) \n    sentenceValue = dict() \n   \n    for sentence in sentences: \n        for word, freq in freqTable.items(): \n            if word in sentence.lower(): \n                if sentence in sentenceValue: \n                    sentenceValue[sentence] += freq \n                else: \n                    sentenceValue[sentence] = freq \n                    \n    sumValues = 0\n    for sentence in sentenceValue: \n        sumValues += sentenceValue[sentence] \n        \n    average = int(sumValues \/ len(sentenceValue)) \n    \n    summary = '' \n    for sentence in sentences: \n        if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.5 * average)): \n            summary += \" \" + sentence \n    return summary ","7eb073c2":"def main():\n    \n    st.title(\"Text Summarizer App\")\n    \n    activities = [\"Summarize Via Text\", \"Summazrize via URL\"]\n    choice = st.sidebar.selectbox(\"Select Activity\", activities)\n    \n    if choice == 'Summarize Via Text':\n        st.subheader(\"Summary using NLP\")\n        raw_text = st.text_area(\"Enter Text Here\",\"Type here\")\n        summary_choice = st.selectbox(\"Summary Choice\" , [\"Gensim\",\"Sumy Lex rank\",\"NLTK\"])\n        if st.button(\"Summarize Via Text\"):\n            if summary_choice == 'Gensim':\n                summary_result = summarize(raw_text)\n                \n            elif summary_choice == 'Sumy Lex rank':\n                summary_result = sumy_summarizer(raw_text)\n                \n            elif summary_choice == 'NLTK':\n                summary_result = nltk_summarizer(raw_text)\n                \n            \n            st.write(summary_result)\n            \n            \n    if choice == 'Summazrize via URL':\n        st.subheader(\"Summarize Your URL\")\n        raw_url = st.text_input(\"Enter URL\",\"Type Here\")\n        if st.button(\"Summarize\"):\n            result = get_text(raw_url)\n            #st.write(result)\n            st.subheader(\"Summarized Text\")\n            docx = sumy_summarizer(result)\n            \n            \n            \n            html = docx.replace(\"\\n\\n\" , \"\\n\")\n            st.markdown(html,unsafe_allow_html=True)\n            \nif __name__ == '__main__':\n    main()","38c6b885":"Let's import Streamlit and Spacy first. ","3581914f":"Function for Sumy ","a1b8c911":"Function for NLTK","def57b79":"# Let's Get Started !!!","ae708b09":"# Creating a Text Summarization App ","3442a265":"If you really enjoyed this Notebook and it helped you, Please upvote. Your upvotes keeps me motivated and helps me grow \ud83d\ude0a\nThank you for reading my Notebook. Have a Great Day !!","cbf82590":"Let's now import **web scrapping** packages ","36e4b47d":"Function for Web Scraping","73f3a0a9":"Main Function","5fc2eca4":"GitHub : https:\/\/github.com\/SidSharma97\/Text-Summariztion","8b923591":"The main Version will Look like : https:\/\/www.youtube.com\/watch?v=YWp2QtuoIYo \nThis is my Youtube Channel ","8f636085":"Hey Fellow Enthusiasts !\nThe idea behind creating this app was to explore various features of **Streamlit** library using NLP Packages !","bef9c2d2":"The third package that we will import will be **NLTK**","acbd88a9":"Now we will import second package. The package we will use is **Sumy**","ffdde2ca":"U can put in text or you can just put in a URL. It will work in both ways !","45e0a6c5":"Now, the idea is to have three different packages and check which will be suitable for us(giving best results). \nThe first package will be **Gensim**"}}