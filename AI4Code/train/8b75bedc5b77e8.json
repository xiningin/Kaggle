{"cell_type":{"83a18d89":"code","84a3dc72":"code","2e334880":"code","bb9b6a0d":"code","acd87a2b":"code","e057019f":"code","5efc5904":"code","e40e5aa2":"code","3c739bde":"code","b3d30d2d":"code","9ea33ef4":"code","b8473057":"code","19221452":"code","46c6a8ad":"code","5489aa57":"code","cbd6c15f":"code","38289a5f":"code","f80b2a0b":"code","d3c62f5c":"code","20dda6a1":"code","23fe0259":"code","959df105":"code","b4a6e7ec":"markdown","050cb605":"markdown","22da3c0c":"markdown","eec6ab57":"markdown","0c202a9e":"markdown","f021814c":"markdown","065b95dc":"markdown","f87fa78f":"markdown","b65410a6":"markdown","2cb5ffc8":"markdown","08fe7001":"markdown","039404bb":"markdown","37f0726c":"markdown","7a739920":"markdown","cbf59050":"markdown"},"source":{"83a18d89":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","84a3dc72":"# Computational libraries\nimport numpy as np\nimport pandas as pd\n\n# Imporitng Data Visualization Libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = [10, 5]\n\n#import miscellaneous libraries\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\npd.set_option('display.width', None)\n\n#Importing Warning Libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Importing Data Preparation and Modeling Libraries\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import *\n\n# Convolutional Neural Network\n\n# Importing the tensorflow  libraries\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import *\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    Dense,\n    Dropout,\n    Flatten,\n    MaxPool2D\n)\nfrom tensorflow.keras.preprocessing import image","2e334880":"# Part 1 - Data Preprocessing\n\n# Preprocessing the Training set\n\ntrain_datagen = ImageDataGenerator(rescale = 1.0\/255, shear_range = 0.2, zoom_range = 0.2,\n                                  horizontal_flip = True,vertical_flip = True,\n                                  rotation_range=20,width_shift_range=0.2,\n                                height_shift_range=0.2)\n\ntrain_df = train_datagen.flow_from_directory('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/train',\n                                            target_size = (128,128), batch_size = 32, class_mode= 'categorical',\n                                            seed=42,shuffle=True)\n","bb9b6a0d":"# Preprocessing the validation set\nvalid_datagen = ImageDataGenerator(rescale = 1.0\/255)\n\nvalid_df = valid_datagen.flow_from_directory('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/val',\n                                            target_size = (128, 128), batch_size = 32,\n                                            class_mode = 'categorical',seed=42,shuffle=True)","acd87a2b":"# Preprocessing the Test set\ntest_datagen = ImageDataGenerator(rescale = 1.0\/255)\n\ntest_df = test_datagen.flow_from_directory('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test',\n                                            target_size = (128,128), batch_size = 32,\n                                            class_mode = 'categorical',seed=42,shuffle=False)","e057019f":"# Part 2 -  Building the CNN\n\n# Initialising the CNN\ncnn = Sequential()\n\n# Step 1 - Convolution\ncnn.add(Conv2D(filters = 32, padding = 'same', kernel_size=3, activation='relu',\n                              input_shape=[128, 128, 3]))\n\n# Step 2 - Pooling\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(Dropout(rate=0.25))\n\n# Adding a second convolutional layer\ncnn.add(Conv2D(filters = 32, padding='same', kernel_size=3, activation='relu'))\ncnn.add(Conv2D(filters = 64, padding='same', kernel_size=3, activation='relu'))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(Dropout(rate=0.25))\n\n# Step 3 - Flattening\ncnn.add(Flatten())\n\n# Step 4 - Full Connection\ncnn.add(Dense(units=128, activation='relu'))\ncnn.add(Dense(units=128, activation='relu'))\n\ncnn.add(Dropout(rate=0.25))\n\n# Step 5 - Output layer\ncnn.add(Dense(units=4, activation='softmax'))","5efc5904":"cnn.summary()","e40e5aa2":"# Part 3 - Training the CNN\n\n# Compiling the CNN\ncnn.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n","3c739bde":"# Training the CNN on the Training set & evaluating it on the validation set\n# cnn.fit(x = train_df, validation_data = valid_df, epochs = 10)\nhistory = cnn.fit(train_df, validation_data = valid_df, epochs = 20)","b3d30d2d":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","9ea33ef4":"cnn.evaluate(valid_df)","b8473057":"# test_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/fresh cotton plant\/dsd (223).jpg', target_size = (128, 128))\n# test_image\n\n\npred = [\"diseased cotton leaf\",\"diseased cotton plant\",\"fresh cotton leaf\",\"fresh cotton plant\"]\ntest_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/fresh cotton plant\/dsd (223).jpg', target_size = (128, 128))\ntest_image = image.img_to_array(test_image)\ntest_image=test_image\/255\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\npred[result.argmax()]","19221452":"# test_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/fresh cotton leaf\/d (133)_iaip.jpg', target_size = (128, 128))\n# test_image\n\npred = [\"diseased cotton leaf\",\"diseased cotton plant\",\"fresh cotton leaf\",\"fresh cotton plant\"]\ntest_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/fresh cotton leaf\/d (133)_iaip.jpg', target_size = (128, 128))\ntest_image = image.img_to_array(test_image)\ntest_image=test_image\/255\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\npred[result.argmax()]","46c6a8ad":"# test_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/diseased cotton plant\/dd (885)_iaip.jpg', target_size = (128,128))\n# test_image\n\npred = [\"diseased cotton leaf\",\"diseased cotton plant\",\"fresh cotton leaf\",\"fresh cotton plant\"]\ntest_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/diseased cotton plant\/dd (885)_iaip.jpg', target_size = (128,128))\ntest_image = image.img_to_array(test_image)\ntest_image=test_image\/255\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\npred[result.argmax()]","5489aa57":"# test_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/diseased cotton leaf\/dis_leaf (153)_iaip.jpg', target_size = (128, 128))\n# test_image\n\npred = [\"diseased cotton leaf\",\"diseased cotton plant\",\"fresh cotton leaf\",\"fresh cotton plant\"]\ntest_image = image.load_img('\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/test\/diseased cotton leaf\/dis_leaf (153)_iaip.jpg', target_size = (128, 128))\ntest_image = image.img_to_array(test_image)\ntest_image=test_image\/255\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\npred[result.argmax()]","cbd6c15f":"test_df.reset()\npred=cnn.predict(test_df,verbose=1)","38289a5f":"predicted_class_indices=np.argmax(pred,axis=1)","f80b2a0b":"labels = (train_df.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","d3c62f5c":"filenames=test_df.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults.to_csv(\"results.csv\",index=False)","20dda6a1":"\n# Change your kernel's working directory(it's very important to change the working directory as you will not have write access to other directories) \n# Change it to 'kaggle\/working' using the below command\nimport os\nos.chdir(r'\/kaggle\/working')","23fe0259":"results.to_csv(r'results.csv',index=False)","959df105":"from IPython.display import FileLink\nFileLink(r'results.csv')","b4a6e7ec":"_________________________________","050cb605":"In this dataset we are provided with images that belong to 4 classes : diseased leaf , diseased plant , fresh leaf and fresh plant. The objective of this study is to create a CNN model to help us predict whether these image of the leaf\/plant belong to the diseased category or the healthy category. Working with images is pretty memory consuming, especially if you read and preprocess all of them at the same time. The following approach avoids this problem in Keras, leaving more space in memory to use augmentation and\/or loading pre-trained models. I have tried my best to comment all the important steps but if any step is not well explained, I request the kagglers to ask the doubts or make suggestions on the comments. Happy learning :-)","22da3c0c":"### Let us make predictions on some random images","eec6ab57":"## 1. Importing libraries & preprocessing","0c202a9e":"# COTTON DISEASE PREDICTION ","f021814c":"3.1 Importing new images using load_img object for classification, Importing image of fresh cotton plant","065b95dc":"### Let us save predictions to a new file","f87fa78f":"#### If you are unable to download the output file using above method, then follow the below method","b65410a6":"3.3 Importing new images using load_img object for classification, Importing image of diseased cotton plant\n","2cb5ffc8":"## 3. Making predictions","08fe7001":"![crop_prot_crop_insectpest%20_cotton_clip_image002_0009.jpg](attachment:crop_prot_crop_insectpest%20_cotton_clip_image002_0009.jpg)","039404bb":"3.2 Importing new images using load_img object for classification, Importing image of fresh cotton leaf\n","37f0726c":"### <a> Happy Learning :-) ","7a739920":"## 2. Building CNN","cbf59050":"3.4 Importing new images using load_img object for classification, Importing image of diseased cotton leaf\n"}}