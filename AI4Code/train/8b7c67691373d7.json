{"cell_type":{"15ae47c2":"code","2ca886a9":"code","39f2ac47":"code","a1ba7ff4":"code","17dd381d":"code","a41668a9":"code","0ce184f2":"code","5d377bde":"code","4fa91f0d":"code","a1d04390":"code","5ac4d6cf":"code","0836ea21":"code","2060fdec":"code","bc721644":"code","de716252":"code","08b435e8":"code","dcfea931":"code","28d232f6":"code","d5b10ae0":"code","e6d8167e":"code","a25fb808":"code","3bc84c98":"code","d5d84c29":"code","266a9362":"code","eeb9663f":"code","d6db4f8d":"markdown"},"source":{"15ae47c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2ca886a9":"import os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","39f2ac47":"TRAINING_DIR = \"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/train\"\ntraining_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                      rotation_range=40,\n                                      width_shift_range=0.2,\n                                      height_shift_range=0.2,\n                                      shear_range=0.2,\n                                      zoom_range=0.2,\n                                      horizontal_flip=True,\n                                      fill_mode='nearest')\ntrain_generator = training_datagen.flow_from_directory(TRAINING_DIR,\n                                                        target_size=(150,150),\n                                                        class_mode='categorical',\n                                                        batch_size=126)\n\nVALIDATION_DIR = \"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\"\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                              target_size=(150,150),\n                                                              class_mode='categorical',\n                                                              batch_size=126)\nTEST_DIR = \"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/test\"\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(TEST_DIR,\n                                                 target_size=(150,150),\n                                                 class_mode=\"categorical\",\n                                                 batch_size=126)\n","a1ba7ff4":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten,Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\ncnn= Sequential()\ncnn.add(Conv2D(filters=64,activation=\"relu\",kernel_size=3,input_shape=(150,150,3)))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\ncnn.add(Conv2D(filters=64, activation=\"relu\",kernel_size=3))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\ncnn.add(Conv2D(filters=128, activation=\"relu\",kernel_size=3))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\ncnn.add(Conv2D(filters=128, activation=\"relu\",kernel_size=3))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\ncnn.add(Flatten())\ncnn.add(Dropout(0.2))\ncnn.add(Dense(units=512, activation=\"relu\"))\ncnn.add(Dense(units=3,activation=\"softmax\"))\ncnn.summary()","17dd381d":"cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\ncallback=EarlyStopping(monitor=\"val_loss\", patience=2)\nhistory=cnn.fit(train_generator,validation_data= test_generator,epochs=10,\n        steps_per_epoch=20,validation_steps=3,callbacks=[callback])","a41668a9":"pd.DataFrame(cnn.history.history)","0ce184f2":"sns.set_style(\"darkgrid\")\npd.DataFrame(cnn.history.history).plot(figsize=(15,10))","5d377bde":"from tensorflow.keras.preprocessing import image\ndef predictor(location):\n    test_image=image.load_img(location,target_size=(150,150))\n    test_image=image.img_to_array(test_image)\n    test_image=np.expand_dims(test_image, axis=0)\n    result=cnn.predict(test_image)\n    training_set.class_indices\n    \n    print(result[0][0])\n    return prediction","4fa91f0d":"from PIL import Image\npic= Image.open(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/paper-hires1.png\")\npic","a1d04390":"test_image =image.load_img(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/paper-hires1.png\",target_size=(150,150))\ntest_image","5ac4d6cf":"test_image= image.img_to_array(test_image)\ntest_image.shape #now image is in the form that we want","0836ea21":"#lets expand the dimensions\ntest_image = np.expand_dims(test_image,axis=0)\ntest_image.shape","2060fdec":"result = cnn.predict(test_image)\nresult # CNN predicts the image as papir with %100 certainity","bc721644":"result[0]","de716252":"result[0][0]","08b435e8":"def predictor(location):\n    test_image=image.load_img(location,target_size=(150,150))\n    test_image=image.img_to_array(test_image)\n    test_image=np.expand_dims(test_image, axis=0)\n    result=cnn.predict(test_image)\n    if result[0][0] == 1:\n        prediction = \"It is a papir\"\n    elif result[0][1] == 1:\n        prediction = \"It is a rock\"\n    else:\n        prediction =\"It is a scissors\"\n    return prediction","dcfea931":"#Lets get another picture and test our model:\nImage.open(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/rock-hires1.png\")\n","28d232f6":"predictor(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/rock-hires1.png\")\n#Our model predicts correctly","d5b10ae0":"#Lets make another test:\nImage.open(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/scissors-hires1.png\")","e6d8167e":"predictor(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/scissors-hires1.png\")","a25fb808":"import os\nimages = os.listdir(VALIDATION_DIR) # Here we create a list named images from the validation directory\nimages","3bc84c98":"predictions= list()\nfor i in images:\n    \n    location = \"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/\"+i\n    prediction=predictor(location)\n    predictions.append(prediction)\n    \n        ","d5d84c29":"predictions_df= pd.DataFrame(predictions)\nimages_df =pd.DataFrame(images)","266a9362":"new_df= pd.concat([predictions_df,images_df],axis=1)\nnew_df.columns=[\"Predictions of CNN\",\"Real Values\"]\nnew_df #This comparison of prediction with the actual values\n#There is %100 accuracy  in the predictions of the CNN","eeb9663f":"\nfig, axs = plt.subplots(5, 5, figsize=(20, 10))\ncount = 0\nfor i in images[:5]:\n  # get the list of images in the particular class\n    location = \"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/\"+i\n  # plot 5 images per class\n    img = Image.open(location)\n    for j in range(5):\n        axs[count][j].title.set_text(predictor(location))\n        axs[count][j].imshow(img)  \n        j+=1\n\n    count += 1\nfig.tight_layout()\n","d6db4f8d":"#Now lets create a function that goes through all of these steps and returns the predictioons of the model"}}