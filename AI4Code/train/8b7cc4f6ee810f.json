{"cell_type":{"5c14b566":"code","974bc2b8":"code","953a3b8e":"code","8b0e9f51":"code","cb43f870":"code","e489844f":"code","fe296254":"code","fb638702":"code","f994c2cc":"code","691b93c7":"code","ecebb1fc":"code","a998bf78":"code","aec1d36b":"code","1d86d07f":"code","a3d96077":"code","fab3e8c7":"code","1a691cd1":"code","24f4bc29":"code","3e418793":"code","eb7adc16":"code","52ed0ee8":"code","ac5c8ac2":"code","f12b7bcb":"code","4bef36fa":"code","5edadab6":"code","a889c0eb":"code","0dec2b41":"code","8c419976":"code","3c1715f4":"code","7e04e067":"code","cc5947fb":"code","9e4fe731":"code","682eba73":"code","614ca8cd":"code","9f71e21e":"code","d6b2c928":"code","3081a194":"code","35bcd876":"code","7d8a2f23":"code","8403f2af":"code","555e2846":"code","216301fe":"code","8235bf4a":"code","168ea9d6":"code","ba5c253b":"code","2dc2c2bd":"code","37d2cd9f":"code","47869a6d":"code","bd168150":"code","4e7e7149":"code","54bedf98":"code","f22775b0":"code","927357fa":"code","f572f87e":"code","57e473c1":"code","f33187d6":"code","e678404e":"code","3bba778b":"code","83bcd827":"code","b52a3422":"code","7539ef01":"code","4ee8a2e5":"code","dd5cc195":"code","0953ebc6":"code","45dc1764":"code","38edab85":"code","2ca42b6c":"code","7a2c96f6":"code","98f92dc7":"code","13d74d00":"code","fcf8cdc1":"code","5e117ca1":"code","9c6187f2":"code","de8fb756":"code","e3f46c03":"code","7bb7bdeb":"code","639a67dc":"code","48518a9c":"code","b61ccbf6":"code","41f59492":"code","bea17b49":"code","58abbaf0":"code","77823a77":"code","cb1a2507":"code","60e029b9":"code","f52e18ed":"code","8db3f82b":"code","76bced60":"code","5ccca967":"code","1b966e02":"code","de564a19":"code","87ceaf6e":"code","cc25e112":"code","03f1410d":"code","45d67e7a":"code","fa9a3cdc":"code","2f61099f":"code","11d6f308":"code","e799175b":"code","49b43190":"code","d82c62bb":"code","30761cd5":"code","1d987973":"code","032c0b04":"code","b44e1aa6":"code","37a8bce7":"code","9f6f1162":"code","90de9790":"code","81c2169d":"code","51634789":"code","39f6ed27":"code","87c19f1f":"code","88606801":"code","8950bc4b":"code","ac5e8549":"code","cf7099f2":"code","8f3c735a":"code","1c26e4eb":"code","42a7689f":"code","e65a14ca":"code","5a5fc0c4":"code","04de29f1":"code","33d09f80":"code","1d588617":"code","56b140c7":"code","c2235ecc":"code","dfe149d1":"code","ece1575d":"code","2bff9274":"code","888d900d":"code","e6d99154":"code","7e36db61":"code","4baa3b64":"code","eef501fe":"code","31fa3306":"code","968b1212":"code","ac301a76":"code","cc88c1d1":"code","74228d82":"code","93d1ed01":"code","c47ac81e":"code","ba5d8456":"code","562117a3":"code","eb07c411":"code","4e8ace15":"code","c737cc32":"code","0bff03e5":"code","307ad0ac":"code","ddcb346b":"markdown","2d04b13f":"markdown","03d824d5":"markdown","70afb2c6":"markdown","52fa0067":"markdown","5cb252da":"markdown","b9345422":"markdown","0f7d0ad7":"markdown","20c89043":"markdown","75625d55":"markdown","1ee3d49a":"markdown","99e1ff1d":"markdown","e933472a":"markdown","854e50d7":"markdown","a4a7b4ed":"markdown","d5d31820":"markdown","a42bb711":"markdown","aa521324":"markdown","9d7c3a53":"markdown","9b9c8b41":"markdown","597f692b":"markdown","2698f239":"markdown","dd905eab":"markdown","46998c6f":"markdown","f260430f":"markdown","8f2bdf74":"markdown","31fda287":"markdown","c556f22b":"markdown","d45e09aa":"markdown","477d1912":"markdown","d369f24d":"markdown","594a6581":"markdown","bc29eb6e":"markdown","78137319":"markdown","36c644e0":"markdown","57425792":"markdown","2457c43d":"markdown","0315a5de":"markdown","40b50434":"markdown","41aa909a":"markdown","ced3a54c":"markdown","734bf760":"markdown","af68c658":"markdown","4d4090d2":"markdown","9d3cd083":"markdown","34c5e85d":"markdown","c66abde7":"markdown","faca2cb7":"markdown","13937c9a":"markdown","ebda2a0c":"markdown","3ddd4745":"markdown","25768ad8":"markdown","d654d316":"markdown","f1995ab4":"markdown","82afe60c":"markdown","e6ad3350":"markdown","d7d5bcf6":"markdown","0f4bf7b7":"markdown","3aad13ca":"markdown","8b884295":"markdown","a160c5ad":"markdown","e0855eb0":"markdown","d9748739":"markdown","81ba3b2e":"markdown","7a0581c6":"markdown","a3c9fd41":"markdown","c52e7d84":"markdown","cac16316":"markdown","e5f85d35":"markdown","783757af":"markdown","afcbac60":"markdown","d4eeb98d":"markdown","7784fc5f":"markdown","0be37888":"markdown","f59dc259":"markdown","243b2f79":"markdown","ad026e7d":"markdown","3360e408":"markdown","41e1e580":"markdown","7f41fa62":"markdown","dbcf8781":"markdown","e29d7505":"markdown","26668a14":"markdown","794e5a8e":"markdown","d8901f49":"markdown","4ffb7c7f":"markdown","8d3c746f":"markdown","f22674ea":"markdown","510d59cb":"markdown","d3f4cec1":"markdown","5df72438":"markdown","b3c9b4e3":"markdown"},"source":{"5c14b566":"# pip install colorama","974bc2b8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats.mstats import winsorize\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import KFold, TimeSeriesSplit\nfrom sklearn.feature_selection import RFECV\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nimport multiprocessing\n\n\nimport re\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.warn(\"this will not show\")\n\n%matplotlib inline\n\npd.options.display.max_rows = 1000\npd.options.display.max_columns = 1000\npd.options.display.max_colwidth = 1000","953a3b8e":"# from google.colab import drive\n# drive.mount('\/content\/drive')","8b0e9f51":"%%time\n\nfiles = ['..\/input\/ieee-fraud-detection\/test_identity.csv', \n         '..\/input\/ieee-fraud-detection\/test_transaction.csv',\n         '..\/input\/ieee-fraud-detection\/train_identity.csv',\n         '..\/input\/ieee-fraud-detection\/train_transaction.csv']\n\ndef load_data(file):\n    return pd.read_csv(file)\n\nwith multiprocessing.Pool() as pool:\n    test_id, test_tr, train_id, train_tr = pool.map(load_data, files)","cb43f870":"train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\ntest = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n\ndel test_id, test_tr, train_id, train_tr\ngc.collect()","e489844f":"print(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\nprint(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')","fe296254":"# Check for column mismatches\ndef diff(li1, li2):\n    li1_dif = [i for i in li1 + li2 if i not in li1]\n    li2_dif = [i for i in li1 + li2 if i not in li2]\n\n    print(f\"\"\"not in list1:\n{li1_dif}\\n   \nnot in list2:\n{li2_dif}\"\"\")\n\ndiff(sorted(train.columns), sorted(test.columns))","fb638702":"test.rename(columns=lambda x: x.replace(\"id-\",\"id_\") if \"id-\" in x else x, inplace=True)","f994c2cc":"# pip install colorama\ndef column_details(regex, df):\n  # We will focus on each column in detail\n  # Uniqe Values, DTYPE, NUNIQUE, NULL_RATE\n    global columns\n    columns=[col for col in df.columns if re.search(regex, col)]\n\n    from colorama import Fore, Back, Style\n\n    print('Unique Values of the Features:\\nfeature: DTYPE, NUNIQUE, NULL_RATE\\n')\n    for i in df[columns]:\n        color = Fore.RED if df[i].dtype =='float64' else Fore.BLUE if df[i].dtype =='int64' else Fore.GREEN\n        print(f'{i}: {color} {df[i].dtype}, {df[i].nunique()}, %{round(df[i].isna().sum()\/len(df[i])*100,2)}\\n{Style.RESET_ALL}{pd.Series(df[i].unique()).sort_values().values}\\n')\n      ","691b93c7":"def null_values(df, rate=0):\n    \"\"\"a function to show null values with percentage\"\"\"\n    nv=pd.concat([df.isnull().sum(), 100 * df.isnull().sum()\/df.shape[0]],axis=1).rename(columns={0:'Missing_Records', 1:'Percentage (%)'})\n    return nv[nv['Percentage (%)']>rate].sort_values('Percentage (%)', ascending=False)","ecebb1fc":"def labels(ax, df, xytext=(0, 0)):\n    for bar in ax.patches: \n        ax.annotate('%{:.2f}\\n{:.0f}'.format(100*bar.get_height()\/len(df),bar.get_height()), (bar.get_x() + bar.get_width() \/ 2,  \n                    bar.get_height()), ha='center', va='center', \n                    size=11, xytext=xytext, \n                    textcoords='offset points')\n\ndef plot_col(col, df, figsize=(20,6)):\n\n    fig, ax = plt.subplots(1,2,figsize=figsize, sharey=True)\n\n    plt.subplot(121)\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    ax[0] = sns.countplot(x=col, data=df, hue='isFraud', \n                  order=np.sort(df[col].dropna().unique()),\n                  )\n    ax[0].tick_params(axis='x', rotation=90)\n    labels(ax[0],df[col].dropna(),(0, 0))\n    \n    ax_twin = ax[0].twinx()\n    # sns.set(rc={\"lines.linewidth\": 0.7})\n    ax_twin = sns.pointplot(x=col, y='Fraud', data=tmp, color='black', legend=False, \n                  order = np.sort(df[col].dropna().unique()), \n                  linewidth=0.1)\n    \n\n    ax[0].grid()\n\n    plt.subplot(122)\n    ax[1] = sns.countplot(x=df[col].dropna(),\n                  order= np.sort(df[col].dropna().unique()),\n                  )\n    ax[1].tick_params(axis='x', rotation=90)\n    labels(ax[1],df[col].dropna())\n    plt.show()\n","a998bf78":"# Remove the highly collinear features from data\ndef remove_collinear_features(x, threshold):\n    '''\n    Objective:\n        Remove collinear features in a dataframe with a correlation coefficient\n        greater than the threshold. Removing collinear features can help a model \n        to generalize and improves the interpretability of the model.\n\n    Inputs: \n        x: features dataframe\n        threshold: features with correlations greater than this value are removed\n\n    Output: \n        dataframe that contains only the non-highly-collinear features\n    '''\n\n    # Calculate the correlation matrix\n    corr_matrix = x.corr()\n    iters = range(len(corr_matrix.columns) - 1)\n    drop_cols = []\n\n    # Iterate through the correlation matrix and compare correlations\n    for i in iters:\n        for j in range(i+1):\n            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n            col = item.columns\n            row = item.index\n            val = abs(item.values)\n\n            # If correlation exceeds the threshold\n            if val >= threshold:\n                # Print the correlated features and the correlation value\n#                 print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n                drop_cols.append(col.values[0])\n\n    # Drop one of each pair of correlated columns\n    drops = set(drop_cols)\n    x = x.drop(columns=drops)\n\n    return drops","aec1d36b":"import scipy.stats as sts\n\n# References:\n# https:\/\/towardsdatascience.com\/the-search-for-categorical-correlation-a1cf7f1888c9\n# https:\/\/en.wikipedia.org\/wiki\/Cram%C3%A9r%27s_V\n\ndef cramers_v(x, y):\n    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n        uses correction from Bergsma and Wicher, \n        Journal of the Korean Statistical Society 42 (2013): 323-328\n    \"\"\"\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = sts.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))","1d86d07f":"def simplify_column(col, df, threshold=0.005, value='mode'):\n  df[col] = df[col].replace(df[col].value_counts(dropna=True)[df[col].value_counts(dropna=True, normalize=True)<threshold].index,df[col].mode()[0] if value=='mode' else 'other')\n  return df[col]","a3d96077":"# Memory Reduction\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: \n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","fab3e8c7":"# Frequency Encoding\n\ndef frequency_encoding(train, test, columns, self_encoding=False):\n    for col in columns:\n        df = pd.concat([train[[col]], test[[col]]])\n        fq_encode = df[col].value_counts(dropna=False, normalize=True).to_dict()\n        if self_encoding:\n            train[col] = train[col].map(fq_encode)\n            test[col]  = test[col].map(fq_encode)            \n        else:\n            train[col+'_freq'] = train[col].map(fq_encode)\n            test[col+'_freq']  = test[col].map(fq_encode)\n    return train, test","1a691cd1":"def plot_feature_importances(model, num=10, figsize=(20,10)):\n    feature_imp = pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)[:num]\n    plt.figure(figsize=figsize)\n    sns.barplot(x=feature_imp, y=feature_imp.index)\n    plt.title(\"Feature Importance\")\n    plt.show()","24f4bc29":"train = train.drop('TransactionID', axis=1)\ntest = test.drop('TransactionID', axis=1)","3e418793":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\ngc.collect()","eb7adc16":"train.to_pickle('.\/train_1.pkl') \ntest.to_pickle('.\/test_1.pkl')","52ed0ee8":"# train = pd.read_pickle('.\/train_1.pkl')\n# test= pd.read_pickle('.\/test_1.pkl')","ac5c8ac2":"ax = sns.countplot(x='isFraud', data= train)\nlabels(ax, train)","f12b7bcb":"missig_rate = np.product(train.isnull().sum().sum())\/ np.product(train.shape)*100\nprint(f'missing value in train data: {missig_rate:.2f}%')\n\nmissig_rate = np.product(test.isnull().sum().sum())\/ np.product(test.shape)*100\nprint(f'missing value in test data: {missig_rate:.2f}%')","4bef36fa":"import missingno as msno\nmsno.matrix(train.sample(100));","5edadab6":"null_values(train, 90)","a889c0eb":"null_values(test, 90)","0dec2b41":"one_value_cols, many_null_cols, big_top_value_cols =[],[],[] \n\nfor df in [train, test]:\n  one_value_cols += [col for col in df.columns if df[col].nunique() == 1]\n  many_null_cols += [col for col in df.columns if df[col].isnull().sum() \/ df.shape[0] > 0.9]\n  big_top_value_cols += [col for col in df.columns if df[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n\ncols_to_drop = list(set(one_value_cols + many_null_cols + big_top_value_cols))\n\nif 'isFraud' in cols_to_drop: \n  cols_to_drop.remove('isFraud')\n\ntrain = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)\n\nprint(f'{len(cols_to_drop)} features are going to be dropped for being useless')","8c419976":"(train['TransactionDT']\/\/(3600*24)).describe()","3c1715f4":"(test['TransactionDT']\/\/(3600*24)).describe()","7e04e067":"import datetime\nSTART_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')","cc5947fb":"from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\ndates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\nus_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())","9e4fe731":"for k, df in enumerate([train, test]):\n  df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n  df['DT_M'] = ((df['DT'].dt.year-2017-k)*12 + df['DT'].dt.month).astype(np.int8).apply(lambda x: x%12 if x>12 else x)\n  df['DT_W'] = ((df['DT'].dt.year-2017-k)*52 + df['DT'].dt.weekofyear).astype(np.int8).apply(lambda x: x%52 if x>52 else x)\n  df['DT_D'] = ((df['DT'].dt.year-2017-k)*365 + df['DT'].dt.dayofyear).astype(np.int16).apply(lambda x: x%365 if x>365 else x)\n  \n  df['DT_hour'] = (df['DT'].dt.hour).astype(np.int8)\n  df['DT_day_week'] = (df['DT'].dt.dayofweek).astype(np.int8)\n  df['DT_day_month'] = (df['DT'].dt.day).astype(np.int8)\n\n  # Holidays\n  df['DT_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)","682eba73":"train = train.drop('DT',axis=1)\ntest = test.drop('DT',axis=1)","614ca8cd":"for df in [train, test]:\n  column_details(regex='^DT_.*', df=df)","9f71e21e":"columns=[col for col in train.columns if re.search('^DT_.*', col)]\ncolumns.remove('DT_D')\n\nfor col in columns:\n  plot_col(col, df=train)","d6b2c928":"plt.figure(figsize=(12,8))\nplt.subplot(121)\nsns.stripplot(y='TransactionAmt', x='isFraud', data=train)\nplt.axhline(5000, color='red')\nplt.title('Train')\n\nplt.subplot(122)\nsns.stripplot(y='TransactionAmt', data=test)\nplt.axhline(5000, color='red')\nplt.title('Test');","3081a194":"for df in [train, test]:\n  df['TransactionAmt'] = df['TransactionAmt'].clip(0,5000)","35bcd876":"train[train.isFraud==1]['TransactionAmt'].mean(), \\\ntrain[train.isFraud==0]['TransactionAmt'].mean(), \\\ntrain['TransactionAmt'].mean(), \\\ntest['TransactionAmt'].mean()","7d8a2f23":"plt.figure(figsize=(15,8))\nplt.suptitle('Time of transaction vs Amount by isFraud')\nfraud_mean, nonfraud_mean = train[train.isFraud==1]['TransactionAmt'].mean(), train[train.isFraud==0]['TransactionAmt'].mean()\nsns.scatterplot(x=train['TransactionDT']\/\/(3600*24), y=train['TransactionAmt'], data=train, hue='isFraud', size=\"isFraud\", sizes=(200, 20))\nplt.axhline(y=fraud_mean ,color='red',label=f'fraud mean:{round(fraud_mean,2)}')\nplt.axhline(y=nonfraud_mean, color='green',label=f'non-froud mean:{round(nonfraud_mean,2)}')\nplt.legend()\n\nplt.yscale('log')\nplt.show()","8403f2af":"for df in [train, test]:\n  column_details(regex='id_30', df=df)","555e2846":"old_versions_id_30 = set(train['id_30'].unique()) - set(test['id_30'].unique())\nnew_versions_id_30 = set(test['id_30'].unique()) - set(train['id_30'].unique())","216301fe":"test['id_30'] =test['id_30'].apply(lambda x: np.nan if x in new_versions_id_30 else x)\ntrain['id_30'] =train['id_30'].apply(lambda x: np.nan if x in old_versions_id_30 else x)","8235bf4a":"for df in [train, test]:\n  column_details(regex='id_31', df=df)","168ea9d6":"old_versions_id_31 = set(train['id_31'].unique()) - set(test['id_31'].unique())\nnew_versions_id_31 = set(test['id_31'].unique()) - set(train['id_31'].unique())","ba5c253b":"test['id_31'] =test['id_31'].apply(lambda x: np.nan if x in new_versions_id_31 else x)\ntrain['id_31'] =train['id_31'].apply(lambda x: np.nan if x in old_versions_id_31 else x)","2dc2c2bd":"old_versions_id_33 = set(train['id_33'].unique()) - set(test['id_33'].unique())\nnew_versions_id_33 = set(test['id_33'].unique()) - set(train['id_33'].unique())","37d2cd9f":"test['id_33'] =test['id_33'].apply(lambda x: np.nan if x in new_versions_id_33 else x)\ntrain['id_33'] =train['id_33'].apply(lambda x: np.nan if x in old_versions_id_33 else x)","47869a6d":"cramers_v(train.id_28,train.id_29), cramers_v(test.id_28,test.id_29)","bd168150":"train = train.drop('id_29', axis=1)\ntest = test.drop('id_29', axis=1)","4e7e7149":"column_details(regex='V\\d*', df=df)","54bedf98":"columns=[col for col in train.columns if re.search('^V\\d*', col)]\nlen(columns)","f22775b0":"plt.figure(figsize=(15,15))\nsns.heatmap(train[columns+['isFraud']].sample(frac=0.2).corr(),annot=False, cmap=\"coolwarm\");","927357fa":"corr_treshold = 0.75\ndrop_col = remove_collinear_features(train[columns],corr_treshold)\nlen(drop_col)","f572f87e":"train = train.drop(drop_col, axis=1)\ntest = test.drop(drop_col, axis=1)","57e473c1":"columns=[col for col in train.columns if re.search('^V\\d*', col)]\nlen(columns)","f33187d6":"plt.figure(figsize=(10,10))\nsns.heatmap(train[columns+['isFraud']].sample(frac=0.2).corr(),annot=False, cmap=\"coolwarm\");","e678404e":"old_versions_DeviceInfo = set(train['DeviceInfo'].unique()) - set(test['DeviceInfo'].unique())\nnew_versions_DeviceInfo= set(test['DeviceInfo'].unique()) - set(train['DeviceInfo'].unique())","3bba778b":"test['DeviceInfo'] =test['DeviceInfo'].apply(lambda x: np.nan if x in new_versions_DeviceInfo else x)\ntrain['DeviceInfo'] =train['DeviceInfo'].apply(lambda x: np.nan if x in old_versions_DeviceInfo else x)","83bcd827":"for df in [train, test]:\n  column_details(regex='DeviceType', df=df)","b52a3422":"plot_col('DeviceType', df=train)","7539ef01":"column_details(regex='R_emaildomain', df=train)","4ee8a2e5":"for df in [train, test]:\n  df['R_emaildomain_1'] = df['R_emaildomain'].fillna('').apply(lambda x: x.split(\".\")[0]).replace({'':np.nan})\n  df['R_emaildomain_2'] = df['R_emaildomain'].str.split('.', expand=True).iloc[:,1:].fillna('').apply(lambda x:('.'.join(x)).strip('.'), axis=1).replace({'':np.nan})","dd5cc195":"column_details(regex='P_emaildomain', df=train)","0953ebc6":"for df in [train, test]:\n  df['P_emaildomain_1'] = df['P_emaildomain'].fillna('').apply(lambda x: x.split(\".\")[0]).replace({'':np.nan})\n  df['P_emaildomain_2'] = df['P_emaildomain'].str.split('.', expand=True).iloc[:,1:].fillna('').apply(lambda x:('.'.join(x)).strip('.'), axis=1).replace({'':np.nan})","45dc1764":"for col in ['R_emaildomain_2', 'P_emaildomain_2']:\n  plot_col(col, df=train)","38edab85":"cramers_v(train.R_emaildomain_2,train.P_emaildomain_2)","2ca42b6c":"cramers_v(test.R_emaildomain_2,test.P_emaildomain_2)","7a2c96f6":"train = train.drop(['R_emaildomain','P_emaildomain','P_emaildomain_2'], axis=1)\ntest = test.drop(['R_emaildomain','P_emaildomain','P_emaildomain_2'], axis=1)","98f92dc7":"for df in [train, test]:\n  column_details(regex='addr', df=df)","13d74d00":"for df in [train, test]:\n  df['addr'] = (df['addr2'].astype(str)+'_'+df['addr1'].astype(str)).replace({'nan_nan':np.nan})","fcf8cdc1":"train['addr1'].nunique(), train['addr2'].nunique(), train['addr'].nunique()","5e117ca1":"test['addr1'].nunique(), test['addr2'].nunique(), test['addr'].nunique()","9c6187f2":"gc.collect()","de8fb756":"old_versions_card1 = set(train['card1'].unique()) - set(test['card1'].unique())\nnew_versions_card1 = set(test['card1'].unique()) - set(train['card1'].unique())","e3f46c03":"len(old_versions_card1), len(new_versions_card1)","7bb7bdeb":"test['card1'] =test['card1'].apply(lambda x: np.nan if x in new_versions_card1 else x)\ntrain['card1'] =train['card1'].apply(lambda x: np.nan if x in old_versions_card1 else x)","639a67dc":"rareCards=[]\nfor k, df in enumerate([train, test]):\n  rare_cards = df.card1.value_counts()\n  rare_cards = rare_cards.where(rare_cards<3).dropna().sort_index().index\n  rareCards += list(rare_cards)\n\n  print(f\"{('TEST' if k else 'TRAIN')}\")\n  print(f\"Number of unique in card1: {df.card1.nunique()}\")\n  print(f\"Number of unique values with frequency less than 3 in card1: {len(rare_cards)}\\n\")\nrareCards = set(rareCards)","48518a9c":"# Countplot of the frequency of the unique value frequencies in card1\nplt.figure(figsize=(30,6))\ntrain.card1.value_counts().to_frame().value_counts().head(100).plot.bar();","b61ccbf6":"for df in [train, test]:\n  df['card1'] = df['card1'].apply(lambda x: np.nan if x in rareCards else x)","41f59492":"column_details(regex='^card', df=train)","bea17b49":"for col in ['card2','card3','card4','card5','card6']: \n  old_versions_col= set(train[col].unique()) - set(test[col].unique())\n  new_versions_col = set(test[col].unique()) - set(train[col].unique()) \n  test[col] =test[col].apply(lambda x: np.nan if x in new_versions_col else x)\n  train[col] =train[col].apply(lambda x: np.nan if x in old_versions_col else x)","58abbaf0":"null_values(train[['D8','D9']])","77823a77":"for col in ['D9','DT_hour']:\n  plot_col(col, df=train)","cb1a2507":"train[['D9', 'DT_hour']].corr()","60e029b9":"train.D8.describe()","f52e18ed":"for df in [train, test]:\n  df['D8_digitalized'] = pd.Series(np.digitize(df['D8'].fillna(-1), bins=[-1,0,1,75,150,1710]))\n  df['D8'] = df['D8'].fillna(-1).astype(int)\n\nplot_col('D8_digitalized', df=train)","8db3f82b":"for df in [train, test]:\n  column_details(regex='^D\\d.*', df=df)","76bced60":"columns=[col for col in train.columns if re.search('^D\\d.*', col)]+['DT_hour']\n\ncorr_treshold = 0.75\ndrop_col = remove_collinear_features(train[columns],corr_treshold)\ndrop_col","5ccca967":"plt.figure(figsize=(15,10))\nsns.heatmap(train[columns].corr(),annot=True, cmap=\"coolwarm\");","1b966e02":"drop_col={'D12', \"D11\", 'D2', 'D6', 'D9'}","de564a19":"for df in [train, test]:\n  df = df.drop(drop_col, axis=1)","87ceaf6e":"column_details(regex='^C\\d', df=train)","cc25e112":"columns=[col for col in train.columns if re.search('^C\\d.*', col)]\ncorr_treshold = 0.9\ndrop_col = remove_collinear_features(train[columns],corr_treshold)\ndrop_col","03f1410d":"train = train.drop(drop_col, axis=1)\ntest = test.drop(drop_col, axis=1)","45d67e7a":"column_details(regex='^dist', df=df)","fa9a3cdc":"for df in [train, test]:  \n  df['dist1_digitalized'] = pd.Series(np.digitize(df['dist1'].fillna(-1), bins=[-1,0,1,2,4,50,75,100,10300]))\n\nplot_col('dist1_digitalized', df=train)","2f61099f":"  train = train.drop('dist1', axis=1)\n  test = test.drop('dist1', axis=1)","11d6f308":"column_details(regex='^M\\d*', df=train)","e799175b":"plot_col('M4', df=train)","49b43190":"temp_dict = train.groupby(['M4'])['isFraud'].agg(['mean']).to_dict()['mean']\ntrain['M4_target_mean'] = train['M4'].replace(temp_dict)\ntest['M4_target_mean']  = test['M4'].replace(temp_dict)","d82c62bb":"for df in [train, test]:\n  column_details(regex='ProductCD', df=df)","30761cd5":"plot_col('ProductCD', df=train)","1d987973":"temp_dict = train.groupby(['ProductCD'])['isFraud'].agg(['mean']).to_dict()['mean']\ntrain['ProductCD_target_mean'] = train['ProductCD'].replace(temp_dict)\ntest['ProductCD_target_mean']  = test['ProductCD'].replace(temp_dict)","032c0b04":"self_encode_True= ['ProductCD', 'DeviceInfo', 'DeviceType', 'addr'] + \\\n                  ['R_emaildomain_1', 'R_emaildomain_2','P_emaildomain_1'] + \\\n                  ['id_12','id_15','id_16','id_28','id_30','id_31','id_33',\"id_34\",'id_35', 'id_36', 'id_37', 'id_38'] + \\\n                  ['M1','M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']+ \\\n                  ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'] + \\\n                  [ 'card4', 'card6']\n\nself_encode_False=['card1', 'card2', 'card3', 'card5']+ \\\n                  ['C1', 'C5', 'C13']","b44e1aa6":"train, test = frequency_encoding(train, test, self_encode_True, self_encoding=True)\ntrain, test = frequency_encoding(train, test, self_encode_False, self_encoding=False)","37a8bce7":"train.to_pickle('.\/train_2.pkl') \ntest.to_pickle('.\/test_2.pkl')\n\n# train= pd.read_pickle('.\/train_2.pkl') \n# test= pd.read_pickle('.\/test_2.pkl')\n\ngc.collect()","9f6f1162":"V_columns = [col for col in train.columns if re.search('^V\\d*', col)]\ntrain[V_columns] = train[V_columns].fillna(-1)\ntest[V_columns] = test[V_columns].fillna(-1)\n\nsc_V = MinMaxScaler()\nsc_V.fit(train[V_columns])\ntrain[V_columns] = sc_V.transform(train[V_columns])\ntest[V_columns] = sc_V.transform(test[V_columns])","90de9790":"# df = pd.concat([train, test], ignore_index=True, sort=False)\n\n# plt.figure(figsize=(25,6))\n# pca = PCA().fit(df[columns])\n# plt.plot(range(1,64),np.cumsum(pca.explained_variance_ratio_), \"bo-\")\n# plt.xlabel(\"Component Count\")\n# plt.ylabel(\"Variance Ratio\")\n# plt.xticks(range(1,df[columns].shape[1]+1))\n# plt.grid()\n# plt.show()","81c2169d":"del df","51634789":"pca = PCA(n_components = 3)\npca.fit(train[V_columns])\npca_V_train = pca.transform(train[V_columns])\npca_V_test = pca.transform(test[V_columns])\n\nnp.cumsum(pca.explained_variance_ratio_)","39f6ed27":"gc.collect()","87c19f1f":"pca_V_train = pd.DataFrame(data = pca_V_train).add_prefix('pca_V')\ntrain = pd.concat([train, pca_V_train], ignore_index=False, sort=False, axis=1)\ntrain.drop(V_columns, axis=1, inplace=True)\n\npca_V_test = pd.DataFrame(data = pca_V_test).add_prefix('pca_V')\ntest = pd.concat([test, pca_V_test], ignore_index=False, sort=False, axis=1)\ntest.drop(V_columns, axis=1, inplace=True)\n","88606801":"del pca_V_train, pca_V_test","8950bc4b":"train = train.drop('TransactionDT',axis=1)\ntest = test.drop('TransactionDT',axis=1)","ac5e8549":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\n\ntrain.to_pickle('.\/train_3.pkl') \ntest.to_pickle('.\/test_3.pkl')\n\ngc.collect()","cf7099f2":"# train= pd.read_pickle('.\/train_3.pkl') \n# test= pd.read_pickle('.\/test_3.pkl')","8f3c735a":"import pandas as pd\nimport numpy as np\nimport multiprocessing\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom time import time\nimport datetime\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, TimeSeriesSplit\nfrom sklearn.metrics import roc_auc_score\n\n# for modeling \nimport sklearn\nfrom lightgbm import LGBMClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split, KFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report, recall_score, f1_score\nfrom sklearn.metrics import plot_precision_recall_curve, precision_recall_curve, plot_roc_curve, roc_curve, plot_confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn import datasets, metrics\nfrom sklearn.decomposition import PCA\n\n# to avoid warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.warn(\"this will not show\")\n\n\n\nwarnings.simplefilter('ignore')\nsns.set()\n%matplotlib inline","1c26e4eb":"X = train.drop(['isFraud'], axis=1)\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state =42)","42a7689f":"lgb = LGBMClassifier(\n          max_bin = 63,\n          num_leaves = 255,\n          num_iterations = 500,\n          learning_rate = 0.01,\n          tree_learner = 'serial',\n          is_dfing_metric = False,\n          min_data_in_leaf = 1,\n          min_sum_hessian_in_leaf = 100,\n          sparse_threshold=1.0,\n          # device = 'gpu',\n          num_thread = -1,\n          save_binary= True,\n          seed= 42,\n          feature_fraction_seed = 42,\n          bagging_seed = 42,\n          drop_seed = 42,\n          data_random_seed = 42,\n          objective = 'binary',\n          boosting_type = 'gbdt',\n          verbose = 1,\n          metric = 'auc',\n          is_unbalance = True,\n          boost_from_average = False,\n)","e65a14ca":"%time \nlgb.fit(X_train, y_train)\n# %time prints CPU Times and Wall Time","5a5fc0c4":"gc.collect()","04de29f1":"plot_feature_importances(lgb, 30)","33d09f80":"y_pred = lgb.predict(X_test)","1d588617":"plot_confusion_matrix(lgb, X_test, y_test, values_format = '', \n                      display_labels=['Not Fraud', 'Fraud'])\nplt.grid(None)\nprint(classification_report(y_test, y_pred, zero_division=0))","56b140c7":"y_train_pred = lgb.predict(X_train)\nplot_confusion_matrix(lgb, X_train, y_train, values_format = '', \n                      display_labels=['Not Fraud', 'Fraud'])\nplt.grid(None)\nprint(classification_report(y_train, y_train_pred, zero_division=0))","c2235ecc":"print('Test ROC AUC score:', roc_auc_score(y_test, lgb.predict_proba(X_test)[:, 1]))\nprint('Train ROC AUC score:', roc_auc_score(y_train, lgb.predict_proba(X_train)[:, 1]))","dfe149d1":"from sklearn import metrics\n\nlgb.fit(X_train, y_train)\ny_pred = lgb.predict_proba(X_test)[:, 1]\n\nauc = metrics.roc_auc_score(y_test, y_pred)\n\nfalse_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n\nplt.figure(figsize=(8, 8), dpi=100)\nplt.axis('scaled')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.title(\"AUC & ROC Curve\")\nplt.plot(false_positive_rate, true_positive_rate, 'g')\nplt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgreen', alpha=0.7)\nplt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=12, weight='bold', color='blue')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.show()","ece1575d":"import pickle\npickle.dump(lgb,open(\".\/LightGBM.pkl\",\"wb\"), protocol=4)","2bff9274":"X = train.drop(['isFraud'], axis=1)\ny = train['isFraud']","888d900d":"# LGBMClassifier with GPU\n\nclf = LGBMClassifier(\n          max_bin = 63,\n          num_leaves = 255,\n          num_iterations = 500,\n          learning_rate = 0.01,\n          tree_learner = 'serial',\n          is_dfing_metric = False,\n          min_data_in_leaf = 1,\n          min_sum_hessian_in_leaf = 100,\n          sparse_threshold=1.0,\n          # device = 'gpu',\n          num_thread = -1,\n          save_binary= True,\n          seed= 42,\n          feature_fraction_seed = 42,\n          bagging_seed = 42,\n          drop_seed = 42,\n          data_random_seed = 42,\n          objective = 'binary',\n          boosting_type = 'gbdt',\n          verbose = 1,\n          metric = 'auc',\n          is_unbalance = True,\n          boost_from_average = False,\n)","e6d99154":"%time \nclf.fit(X, y)\n# %time prints CPU Times and Wall Time","7e36db61":"gc.collect()","4baa3b64":"sub= pd.read_csv('..\/input\/ieee-fraud-detection\/sample_submission.csv')","eef501fe":"sub['isFraud']=pd.DataFrame(clf.predict_proba(test))[[1]]","31fa3306":"sub.to_csv('.\/submission.csv',index=False)","968b1212":"sub","ac301a76":"X = train.drop(['isFraud'], axis=1)\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state =42)","cc88c1d1":"xgb = XGBClassifier()","74228d82":"%time xgb.fit(X_train, y_train)","93d1ed01":"gc.collect()","c47ac81e":"y_pred = xgb.predict(X_test)","ba5d8456":"def plot_feature_importances(model, num=10, figsize=(20,10)):\n    feature_imp = pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)[:num]\n    plt.figure(figsize=figsize)\n    sns.barplot(x=feature_imp, y=feature_imp.index)\n    plt.title(\"Feature Importance\")\n    plt.show()\n    \nplot_feature_importances(xgb, 30)","562117a3":"plot_confusion_matrix(xgb, X_test, y_test, values_format = '', \n                      display_labels=['Not Fraud', 'Fraud'])\nplt.grid(None)\nprint(classification_report(y_test, y_pred, zero_division=0))","eb07c411":"y_train_pred = xgb.predict(X_train)\nplot_confusion_matrix(xgb, X_train, y_train, values_format = '', \n                      display_labels=['Not Fraud', 'Fraud'])\nplt.grid(None)\nprint(classification_report(y_train, y_train_pred, zero_division=0))","4e8ace15":"from sklearn import metrics\n\n# xgb.fit(X_train, y_train)\ny_pred = xgb.predict_proba(X_test)[:, 1]\n\nauc = metrics.roc_auc_score(y_test, y_pred)\n\nfalse_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n\nplt.figure(figsize=(8, 8), dpi=100)\nplt.axis('scaled')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.title(\"AUC & ROC Curve\")\nplt.plot(false_positive_rate, true_positive_rate, 'g')\nplt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgreen', alpha=0.7)\nplt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=12, weight='bold', color='blue')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.show()","c737cc32":"y_pred = lgb.predict(X_test)\nlgb_recall = recall_score(y_test, y_pred)\nlgb_f1_score = f1_score(y_test, y_pred)\nlgb_AUC = roc_auc_score(y_test, lgb.predict_proba(X_test)[:, 1])\n\n\ny_pred = xgb.predict(X_test)\nxgb_recall = recall_score(y_test, y_pred)\nxgb_f1_score = f1_score(y_test, y_pred)\nxgb_AUC = roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1],average='micro')","0bff03e5":"df_eval=pd.DataFrame({ 'Model':[\"LightGBM\",'XGBOOST'],\n                        'Recall':[lgb_recall,xgb_recall],\n                        'F1':[lgb_f1_score,xgb_f1_score],\n                        'AUC':[lgb_AUC,xgb_AUC]})\ndf_eval","307ad0ac":"sns.relplot(x=\"Recall\", y=\"AUC\", hue=\"Model\", size=\"F1\", sizes=(100, 400), \n            alpha=1, palette=\"bright\", height=4, legend='full', data=df_eval);","ddcb346b":"We generated a new feature from 'ProductCD' according to the mean of the target feature.","2d04b13f":"We replaced \"rare card1 values\" with Nan.","03d824d5":"### id_31","70afb2c6":"## Exploratory Data Analysis (EDA)","52fa0067":"We generated a new feature from 'M4' according to the mean of the target feature.","5cb252da":"### DeviceType","b9345422":"### Saving Model","0f7d0ad7":"Working with large data while training ML Models requires large RAM memory. To overcome this limitation, we used a function to reduce the memory footprint of the data. The general approach is to convert dtype of each feature ('int16', 'int32', 'int64', 'float16', 'float32', 'float64') to the lowest possible dtype.\n\n","20c89043":"According to Wikipedia, feature engineering refers to the process of using domain knowledge to extract features from raw data via data mining techniques. These features can then be used to improve the performance of machine learning algorithms.\nFeature engineering does not necessarily have to be fancy though. One simple, yet prevalent, use case of feature engineering is in time-series data. The importance of feature engineering in this realm is due to the fact that (raw) time-series data usually only contains one single column to represent the time attribute, namely date-time (or timestamp).\nRegarding this date-time data, feature engineering can be seen as extracting useful information from such data as standalone (distinct) features. For example, from a date-time data of \u201c2020\u201307\u201301 10:21:05\u201d, we might want to extract the following features from it:\n\nMonth: 7\n\nDay of month: 1\n\nDay name: Wednesday (2020\u201307\u201301 was Wednesday)\n\nHour: 10","75625d55":"### Frequency Encoders","1ee3d49a":"With so many features, the performance of your algorithm will drastically degrade. PCA is a very common way to speed up your Machine Learning algorithm by getting rid of correlated variables which don\u2019t contribute in any decision making. The training time of the algorithms reduces significantly with less number of features. \nIn addition, Overfitting mainly occurs when there are too many variables in the dataset. So, PCA helps in overcoming the overfitting issue by reducing the number of features.\n\nSo, if the input dimensions are too high, then using PCA to speed up the algorithm is a reasonable choice. Now we will apply PCA to the V columns of 62 features. We are looking for a requirement that it represents more than 90% of the data.","99e1ff1d":"### PCA for V Columns","e933472a":"### card1","854e50d7":"### Encoders","a4a7b4ed":"The distribution of D8 is intense between 0 and 1. So we digitized D8 columns in order to find out a meaningful pattern.","d5d31820":"### Evaluation of XgGBoost","a42bb711":"3.5% of transacations are fraud. Notice how imbalanced is our original dataset! Most of the transactions are non-fraud. If we use this dataframe as the base for our predictive models and analysis we might get a lot of errors and our algorithms will probably overfit since it will \"assume\" that most transactions are not fraud. But we don't want our model to assume, we want our model to detect patterns that give signs of fraud!\n\nImbalance means that the number of data points available for different the classes is different","aa521324":"While train datasets are having observations for 182 days, test datasets are having observations for 183 days. There is a gap of 30 days between two datasets. We can generate some useful time-features from TransactionDT.","9d7c3a53":"From the competition overview:\n\nIn this competition, you\u2019ll benchmark machine learning models on a challenging large-scale dataset. The data comes from Vesta's real-world e-commerce transactions and contains a wide range of features from device type to product features. You also have the opportunity to create new features to improve your results.\n\nIf successful, you\u2019ll improve the efficacy of fraudulent transaction alerts for millions of people around the world, helping hundreds of thousands of businesses reduce their fraud loss and increase their revenue. And of course, you will save party people just like you the hassle of false positives.\n\nYou are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n\nThe data is broken into two files identity and transaction, which are joined by TransactionID. Not all transactions have corresponding identity information.\n\n`Categorical Features - Transaction`\n- ProductCD\n- card1 - card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9\n\n`Categorical Features - Identity`\n- DeviceType\n- DeviceInfo\n- id_12 - id_38\n\nThe TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp).\n\n`Files`\n\n- train_{transaction, identity}.csv - the training set\n- test_{transaction, identity}.csv - the test set (you must predict the isFraud value for these observations)\n- sample_submission.csv - a sample submission file in the correct format\n\n\nVesta Corporation provided the dataset for this competition. Vesta Corporation is the forerunner in guaranteed e-commerce payment solutions. Founded in 1995, Vesta pioneered the process of fully guaranteed card-not-present (CNP) payment transactions for the telecommunications industry. Since then, Vesta has firmly expanded data science and machine learning capabilities across the globe and solidified its position as the leader in guaranteed ecommerce payments. Today, Vesta guarantees more than $18B in transactions annually.","9b9c8b41":"### ProductCD","597f692b":"**V Columns subsets having similar NAN structures**\n\n* V2-11\n* V12-34\n* V35-52\n* V53-74\n* V75-94\n* V95-131\n* V139-166\n* V167-216\n* V217-278\n* V279-317\n* V322-339","2698f239":"### id_12-38","dd905eab":"D8 and D9 have the same missing value rate in train and test dataset. They have to be related with each other.","46998c6f":"Columns having more than %90 missing values are listed above. There are some diffirences between test and train in terms of the missing values.\n","f260430f":"### id_30","8f2bdf74":"We synchronized test['card1] and train[card1]","31fda287":"### V1-339","c556f22b":"The correlated columns having the most missing values are dropped. So, we replaced some columns in the dropping column list below.","d45e09aa":"### Predict test data","477d1912":"### M1-9","d369f24d":"We made the column names of the independent features the same.","594a6581":"### addr1-2","bc29eb6e":"#### Outlier Functions","78137319":"### Handling missing values","36c644e0":"![float.png](data:image\/png;base64,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)","57425792":"![domain.jpg](data:image\/jpeg;base64,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)","2457c43d":"### Read dataset","0315a5de":"Gradient Boosting Decision Trees (GBDT) algorithms have been proven to be among the best algorithms in machine learning. XGBoost, the most popular GBDT algorithm, has won many competitions on websites like Kaggle. However, XGBoost is not the only GBDT algorithm with state-of-the-art performance. There are other GBDT algorithms that have more advantages than XGBoost and even more potent like LightGBM and CatBoost.\n\nFirst, let's train the model with LightGBM.","40b50434":"#### Correlation Functions","41aa909a":"According to Python Official Documentation, you can explicitly invoke the Garbage Collector to release unreferenced memory with `gc.collect()`","ced3a54c":"In the competition the probability that an online transaction is fraudulent will be predicted, as denoted by the binary target isFraud.\n\nData is separated into two datasets: information about the identity of the customer and transaction information. Not all transactions belong to identities, which are available. Maybe it would be possible to use additional transactions to generate new features.","734bf760":"#### Description Functions","af68c658":"Columns containing only 1 unique value and containing more than 90 percent missing values and when missing values are dropped, columns with more than 90 percent of the remaining data are dropped from the dataset.","4d4090d2":"Since almost all values of 'TransactionID' are unique, it is dropped.","9d3cd083":"The averages of TransactionAmt of train and test datasets are nearly same. The average of the fraud transactions(149.24) is bigger than the average of the non-fraud transactions(134.26).","34c5e85d":"### R_emaildomain","c66abde7":"We produced 2 new columns with mail server and domain.","faca2cb7":"The minimum value in D columns has to equal the minimum value for each month and day. In order to meet this condition, the START_DATE has been determined as '2017-11-30'. Ref: https:\/\/www.kaggle.com\/kyakovlev\/ieee-fe-with-some-eda","13937c9a":"Test dataset has some new software vesion that train dataset doesn't have. And also train dataset has a software vesion that test dataset doesn't have. We replace them with Nan value.","ebda2a0c":"- In December, the Fraud rate decreased. December is the common month for both train and test datasets.\n- In the morning hours, the fraud rate was high. Afternoon, It decreased.\n- Fraud rate decreases towards the last days of the month, while decreasing during the holidays.\n- Fraud rate tends to increase from the beginning of the week, tends to decrease on Friday and Sunday.","3ddd4745":"Test dataset has some new device that train dataset doesn't have. And also train dataset has a device that test dataset doesn't have. We replace them with Nan value.","25768ad8":"#### Memory Reduction","d654d316":"So we have two medium-sized datasets with a lot of columns. Train and test data have similar number of rows","f1995ab4":"One of the columns having more than %90 correlation are dropped.","82afe60c":"id_28 and id_29 are having high correlation. (Treshold= 0.9). So we dropped 'id_29'","e6ad3350":"### TransactionAmt","d7d5bcf6":"<a href=\"https:\/\/colab.research.google.com\/github\/fidanfatih\/Fraud_Detection\/blob\/main\/fraud_detection.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","0f4bf7b7":"## FUNCTIONS","3aad13ca":"There is no transaction having a transaction amount of more than 5000. So we clipped them from 5000.","8b884295":"We produced 2 new columns with mail server and domain.","a160c5ad":"### DeviceInfo","e0855eb0":"addr1 and addr2 are realted with adress. add2 - Country \/ addr1 - subzone. By combining them, we create a new column","d9748739":"### Model Evaluation","81ba3b2e":"When a sample took randomly, It is shown that many observations have \"correlated missing values\".","7a0581c6":"D9 and DT_hour are having similar distribution. D9 must be related with hour.","a3c9fd41":"Datasets have too much missing values.","c52e7d84":"### D1-15","cac16316":"## IEEE-CIS Fraud Detection \n[Kaggle Link](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/overview)","e5f85d35":"**1- Data Preprosessing**\n\n- Import Modules\n- Data Load and Integration\n- Data Review and Understanding\n- Memory reduction\n\n**2- Exploratory Data Analysis (EDA)**\n- summarize data\n- drop redundant columns\n- converting data to the same standard\n- dtype transformation\n- Data Visualization\n- Insights & visual graphs\n- Feature engineering\n- Detect outliers  \n- Handling missing values\n- Frequency Encoding\n\n**3- Model Building**\n- Dimensionally reduction (PCA)\n- Model Training (XGBoost, LightGBM)\n- Model Evaluation\n\n**4- Model Deployment**\n- Save and Export the Model as .pkl\n- Build a web interface with streamlit\n- Model deployment on cloud","783757af":"One hot encoding was not used to get rid of the curse of multidimensionality. Although label encoding is a good solution for ordinal categorical data, it is not a suitable solution for nominal categorical data. It can be said that frequency encoding is the best solution for this data.","afcbac60":"### P_emaildomain","d4eeb98d":"## Modeling with LightGBM","7784fc5f":"#### Plot Functions","0be37888":"### id_33","f59dc259":"### D8-9","243b2f79":"  **FEATURES**\n- **`isFraud` : binary, Target** \n\n- **`TransactionID`** : all unique \n<br># It is pure noise right now\n\n- **`TransactionDT`** : time series\n<br>Time from reference time point. VERY valuable column\n\n- **`TransactionAmt`** : continous\n<br>It has many unique values and has to be combined with other columns. The best score boost should come from TransactionDT->TransactionAmt combination\n\n- **`P_emaildomain`** : categoric, 56 uniques\n<br>It's possible to make subgroup feature from it or general group\n\n- **`R_emaildomain`** : categoric, 59 uniques\n<br>It's possible to make subgroup feature from it or general group\n\n- **`DeviceType`** : categoric, 2 uniques\n<br>\n\n- **`DeviceInfo`** : categoric, 700 uniques\n<br>\n\n- **`ProductCD`** : categoric, 5 uniques\n<br>100% categorical feature options to use: Frequency encoding\/Target encoding\/Combinations with other columns\/Model categorical feature\n\n- **`card1-6`** : categoric, numeric\n<br>Categorical features with information about Client\n\n- **`addr1-2`** : \n<br>addr1 - subzone \/ add2 - Country \n\n- **`dist1-2`** : numeric\n<br>dist1 - local distance from merchant \/ dist2 - Country distance\n\n- **`C1-14`** : numeric\n<br>\n\n- **`D1-15`** : numeric\n<br>timedelta, such as days between previous transaction, etc. Minimal value will be same for each month and day but maximum and mean values will grow over time.\n\n- **`M1-9`** : categoric\n<br>\n\n- **`V1-339`** : numeric, categoric\n<br>\n\n- **`id_01_38`** : numeric, categoric\n<br>","ad026e7d":"R_emaildomain_2 and P_emaildomain_2 are categorically 90% correlated. So we dropped P_emaildomain_2.","3360e408":"### Memory Reduction Functions","41e1e580":"### Export Data","7f41fa62":"### TransactionDT","dbcf8781":"## Modeling with XGBoost","e29d7505":"### Training with all train data","26668a14":"### Modeling","794e5a8e":"## Compare Models","d8901f49":"### card2-6","4ffb7c7f":"Colaboratory, or Colab for short, is a Google Research product, which allows developers to write and execute Python code through their browser. Google Colab is an excellent tool for deep learning tasks. It is a hosted Jupyter notebook that requires no setup and has an excellent free version, which gives free access to Google computing resources such as GPUs and TPUs. So, We use Colab for the project.","8d3c746f":"- For now we don't know exactly what these values represent.\n- W has the most number of observations, C the least.\n- ProductCD C has the most fraud with >11%\n- ProductCD W has the least with ~2%","f22674ea":"V columns seem redundant and related. Also, many subsets have similar NAN structures. We determined the columns with correlation (r > 0.75) in the V columns and dropped one of them, leaving only the independent columns. After dropping the correlated V columns, we have only 62 V columns.","510d59cb":"### dist1-2","d3f4cec1":"### C1-14","5df72438":"%%time is a magic command. It's a part of IPython. It prints the wall time for the entire cell whereas %time gives you the time for first line only. Using %%time prints 2 values:\n- CPU Times\n- Wall Time","b3c9b4e3":"In this project, most important evaluation metrics are AUC, Recall and F1 score orderly. LightGBM has the best AUC and Recall score when XGBoost has the best F1 score.\n\nAs seen above, LightGBM has done much better than XGBoost. It is also more successful than XGBoost in terms of training time and lower memory usage.\n\n**Important Parameters of light GBM:**\n\n`num_leaves`: the number of leaf nodes to use. Having a large number of leaves will improve accuracy, but will also lead to overfitting.\n\n`min_child_samples`: the minimum number of samples (data) to group into a leaf. The parameter can greatly assist with overfitting: larger sample sizes per leaf will reduce overfitting (but may lead to under-fitting).\n\n`max_depth`: controls the depth of the tree explicitly. Shallower trees reduce overfitting.\n\n**Tuning for imbalanced data**\n\nThe simplest way to account for imbalanced or skewed data is to add weight to the positive class examples:\n\n`scale_pos_weight`: the weight can be calculated based on the number of negative and positive examples: sample_pos_weight = number of negative samples \/ number of positive samples.\n\n**Tuning for overfitting**\n\nIn addition to the parameters mentioned above the following parameters can be used to control overfitting:\n\n`max_bin`: the maximum numbers of bins that feature values are bucketed in. A smaller max_binreduces overfitting.\n\n`min_child_weight`: the minimum sum hessian for a leaf. In conjuction with min_child_samples, larger values reduce overfitting.\nbagging_fraction and bagging_freq: enables bagging (subsampling) of the training data. Both values need to be set for bagging to be used. The frequency controls how often (iteration) bagging is used. Smaller fractions and frequencies reduce overfitting.\n\n`feature_fraction`: controls the subsampling of features used for training (as opposed to subsampling the actual training data in the case of bagging). Smaller fractions reduce overfitting.\nlambda_l1 and lambda_l2: controls L1 and L2 regularization.\n\n**Tuning for accuracy**\n\nAccuracy may be improved by tuning the following parameters:\n\n`max_bin`: a larger max_bin increases accuracy.\n\n`learning_rate`: using a smaller learning rate and increasing the number of iterations may improve accuracy.\n\n`num_leaves`: increasing the number of leaves increases accuracy with a high risk of overfitting."}}