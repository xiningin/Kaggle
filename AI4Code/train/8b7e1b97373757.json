{"cell_type":{"204c48d8":"code","48265e0f":"code","ef84928f":"code","05497c49":"code","0b08281e":"code","71a821b2":"code","8d2a9ee0":"code","3c67ad30":"code","062d3a4e":"code","847af100":"code","7d1ea1da":"code","7fecd146":"code","9ac5d22a":"code","6c2e4504":"code","26425309":"code","0d166cfb":"code","a145226c":"code","afc70290":"code","bb815017":"code","92d5193a":"code","20f30aa9":"code","67727c8a":"code","0ecb61a7":"code","7412b01b":"code","d0370f3d":"code","04c1512f":"code","9583555d":"code","499f975f":"code","0c8e1223":"code","efeeb834":"code","0a02f7b8":"code","c48a658a":"code","fa8bb89d":"code","6881f300":"code","9b2b2c8f":"code","317f6115":"code","95fae26d":"code","afb262a4":"code","6356ce6b":"code","9fc16def":"code","1e1ed796":"code","b9a5a486":"code","6138e245":"markdown"},"source":{"204c48d8":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","48265e0f":"# import both train and test data...\ntrain=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","ef84928f":"train.head()","05497c49":"train.info()\ntest.info()","0b08281e":"# check missing values\nprint(train.isnull().sum().sort_values(ascending=False))\nprint(20*'_')\ntest.isnull().sum().sort_values(ascending=False)","71a821b2":"train.columns","8d2a9ee0":"# drop Cabin field from both train and test dataset as there are lots of missing value \n#drop_Columns=['Cabin','PassengerId','Ticket']\ndrop_Columns=['Cabin','PassengerId','Ticket']\ntrain.drop(drop_Columns,axis=1, inplace=True)\ntest_passengerid=test['PassengerId']\ntest.drop(drop_Columns,axis=1,inplace=True)","3c67ad30":"train.head()","062d3a4e":"# Impute Age value with mean value\ntrain['Age'].fillna(train['Age'].median(),inplace=True)\ntest['Age'].fillna(test['Age'].median(),inplace=True)\n","847af100":"train.isnull().sum().sort_values(ascending=False)","7d1ea1da":"# impute missing value of fare column with mean value \ntrain['Fare'].fillna(train['Fare'].median(),inplace=True)\ntest['Fare'].fillna(test['Fare'].median(),inplace=True)","7fecd146":"# Impute missing values from the Embarked column from both train and test dataset.\ntrain['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)\n","9ac5d22a":"test['Embarked'].fillna(test['Embarked'].mode()[0],inplace=True)","6c2e4504":"test.isnull().sum().sort_values(ascending=False)","26425309":"train.groupby('Survived').count()","0d166cfb":"# Exploratory Data Analysis.\nsns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","a145226c":"sns.set_style('whitegrid')","afc70290":"# Countplot of Survived column.\nsns.countplot(x='Survived', data=train)","bb815017":"train.columns\n","92d5193a":"# Survived against Sex ratio.\nsns.countplot(x='Survived',hue='Sex', data=train)\n# By looking at plot, it clearly says that more women survived that men.","20f30aa9":"# Check survived rate against PClass\nsns.countplot(x='Survived', hue='Pclass', data=train)","67727c8a":"# Check distribution ratio of Age.\nsns.distplot(train['Age'].dropna(),kde=False,bins=30)","0ecb61a7":"train['Embarked'].value_counts()","7412b01b":"train['Embarked'].value_counts()","d0370f3d":"# Feature Encoding:\ntrain['Sex']=train['Sex'].map({'male':1,'female':0}).astype(int)\n  ","04c1512f":"train['Embarked']=train['Embarked'].map({'S':0,'C':1,'Q':2}).astype(int)","9583555d":"test['Sex']=test['Sex'].map({'male':1,'female':0}).astype(int)\ntest['Embarked']=test['Embarked'].map({'S':0,'C':1,'Q':2}).astype(int)","499f975f":"# for first submission drop 'Name'\ntrain.drop('Name',axis=1,inplace=True)\ntest.drop('Name',axis=1,inplace=True)","0c8e1223":"train.head()","efeeb834":"# Chec correlation with Target variable\ncorr=train.corr()\nplt.figure(figsize=(10,10))   \nsns.heatmap(corr,annot=True,fmt=\".0%\")\nplt.show()","0a02f7b8":"train.columns","c48a658a":"# \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nX=train.drop('Survived',axis=1)\ny=train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20,random_state=101)\n\nlogr=LogisticRegression()\n","fa8bb89d":"def models(X_train,y_train):\n    ## Logistic Regression Model\n        from sklearn.linear_model import LogisticRegression\n        logis= LogisticRegression(C=50)\n        logis.fit(X_train, y_train)\n        train_score1 =logis.score(X_train,y_train)\n        test_score1 =logis.score(X_test,y_test)\n\n        ## Random Forest Model\n        from sklearn.ensemble import RandomForestClassifier\n        rf = RandomForestClassifier(n_estimators=10,criterion=\"entropy\",random_state=5)\n        rf.fit(X_train,y_train)\n        train_score2 =rf.score(X_train,y_train)\n        test_score2 =rf.score(X_test,y_test)\n\n        ## KNN\n        from sklearn.neighbors import KNeighborsClassifier\n        knc = KNeighborsClassifier(n_neighbors=11)\n        knc.fit(X_train,y_train)\n        train_score3 =knc.score(X_train,y_train)\n        test_score3 =knc.score(X_test,y_test)\n\n        ## SVC\n        from sklearn.svm import SVC\n        sv = SVC()\n        sv.fit(X_train, y_train)\n        train_score4 =sv.score(X_train,y_train)\n        test_score4 =sv.score(X_test,y_test)\n\n        ## XgBoost\n        from xgboost import XGBClassifier\n        boost= XGBClassifier(learning_rate=0.01)\n        boost.fit(X_train,y_train)\n        train_score5 =boost.score(X_train,y_train)\n        test_score5 =boost.score(X_test,y_test)\n\n        ## Print Accuracy\n        print(\"Logistic train score: \", train_score1, \"Test score : \",test_score1)\n        print(\"Random Forest train score: \", train_score2, \"Test score : \",test_score2)\n        print(\"KNN train score: \", train_score3, \"Test score : \",test_score3)\n        print(\"SVC train score: \", train_score4, \"Test score : \",test_score4)\n        print(\"Xgboost train score: \", train_score5, \"Test score : \",test_score5)\n        \n        return logis,rf,knc,sv,boost","6881f300":"model=models(X_train,y_train)","9b2b2c8f":"model\n","317f6115":"from sklearn.metrics import classification_report","95fae26d":"from sklearn.metrics import classification_report","afb262a4":"for i in range(len(model)):\n    print(\"Model \", i)\n    Report = classification_report(y_test,model[i].predict(X_test))\n    print(Report)","6356ce6b":"# Evaluate model\n#from sklearn.metrics import accuracy_score\n\n#print (accuracy_score(y_test,pred))\n","9fc16def":"pred_test=model[4].predict(test)  \n","1e1ed796":"final_predFile=pd.DataFrame({ 'PassengerId': test_passengerid,\n                               'Survived': pred_test})","b9a5a486":"# create final CSV file.\nfinal_predFile.to_csv(r'ResultSubmission.csv',index=False)","6138e245":"**#Feature Engineering**"}}