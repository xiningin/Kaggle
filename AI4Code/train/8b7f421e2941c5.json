{"cell_type":{"198d9d88":"code","8d960ae5":"code","578aff48":"code","e8b6866e":"code","72323414":"code","d25e64a1":"code","f4c65962":"code","a0a5fa23":"code","4d6d3ede":"code","d05e2405":"code","51b90234":"code","daf92e66":"code","93822fd8":"code","431b42f9":"code","8eb0d14d":"code","ba0c61c8":"code","64098be3":"code","e49f6677":"code","9dae0f32":"code","097b7318":"code","bd987872":"code","c829232c":"code","8b5471e0":"markdown","99b488fc":"markdown","d14c61c9":"markdown","4a969c87":"markdown","d466767a":"markdown","b84f7fb4":"markdown","5d0f143f":"markdown","d7dba1ce":"markdown","6da18911":"markdown","a6af8368":"markdown","1c9dd0a6":"markdown","cf35f2f6":"markdown","daf4de4f":"markdown","30447b9f":"markdown","0c906362":"markdown","c5006969":"markdown","13eda90b":"markdown","a82102a3":"markdown","fc4e6102":"markdown","a7cc00ed":"markdown"},"source":{"198d9d88":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","8d960ae5":"#read Train and test data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\n\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\n#concat train and Test data\nall_Data = pd.concat([train.drop('Survived', axis=1), test], axis=0, sort=True)\ngroup_all_data = all_Data.groupby(['Sex'])['PassengerId'].count()\n\nprint('how many people have by sex in all dataset', group_all_data )\nprint()\nprint('Total of: \\n',all_Data.isnull().sum())\n\nprint('Sample of Data \\n')\nprint(all_Data.head(5))\nprint()\n#visualize the null in all dataset \nall_Data_total = all_Data.isnull().sum().sum()\nprint('Quantity persons on Training and Test Data:', all_Data_total)\n\nprint('% People by Sex: \\n', group_all_data*100\/all_Data_total)\n\n","578aff48":"#show all the columns\npd.options.display.max_columns = None\n\n#print Train Dataset \nprint(train.info())\nprint(train.describe())\nprint(train.head(5))","e8b6866e":"#from pandas.plotting import scatter_matrix\ncol_obj = ['Survived', 'Pclass', 'Age', 'SibSp','Parch', 'Fare']\n#scatter_matrix(train[col_obj], figsize=(12,8))\nsns.pairplot(train.drop('PassengerId', axis=1).dropna(), hue='Survived')\n","72323414":"group_s = train.groupby(['Sex'])['PassengerId'].count()\nprint('train data has:', group_s.sum() , ' rows \\n' )\nprint(\"Q by sex (train)\\n \" , group_s)\nprint(\"\\n % train data (train)  \\n\",group_s*100\/group_s.sum())","d25e64a1":"group_svs = train.groupby(['Survived'])['PassengerId'].count()*100\/train.groupby(['Survived'])['PassengerId'].count().sum()\nprint('% people Die\/survived \\n', group_svs.round(2))\nprint()\ngroup_svs.plot(kind='bar', title='% of survived')\nplt.xticks([0,1], ['Die','Survived'])\nplt.ylabel('percentage')\nplt.show()\n","f4c65962":"#group_sur_sex = train.groupby(['Survived','Sex'])['PassengerId'].count()*100\/train.groupby(['Survived','Sex'])['PassengerId'].count().sum().sum()\n#print(group_sur_sex.round(2))\n#group_sur_sex.plot(kind='bar',hue=['Survived'])\n#p=group_sur_sex.unstack().plot(kind='bar')\n#plt.title('% survived based on sex')\n#plt.xticks([0,1],['Die','Survived'])\n#plt.show()\n\n(pd.crosstab(train.Survived, train.Sex, margins=True, normalize='all').round(4)*100).style.background_gradient(cmap='summer_r')","a0a5fa23":"group_sbc= train.groupby(['Pclass'])['PassengerId'].count()*100\/train.groupby(['Pclass'])['PassengerId'].count().sum()\nprint('% people on each Class \\n', group_sbc.round(2))\np = group_sbc.plot(kind='bar')\nplt.title('% survived by Class')\nplt.show()\nctb = pd.crosstab(train.Pclass, train.Survived,  margins=True , normalize='all').round(4)*100\n#ctb.plot(kind='bar')\nctb.style.background_gradient(cmap='summer_r')","4d6d3ede":"group_sur_class = train.groupby(['Survived','Pclass','Sex'])['Survived'].count()\n#print(group_sur_class)\n#group_sur_class.unstack().plot(kind='bar')\n\n# % survived by Row'\nctb = pd.crosstab(index = [train.Pclass, train.Sex], columns=train.Survived, normalize='index').round(4)*100\nctb.style.background_gradient(cmap='summer_r')\nctb\n\n# % survived by Class & Sex'\nctb_ = pd.crosstab(index = [train.Pclass, train.Sex], columns=train.Survived, normalize='all').round(4)*100\nctb_.style.background_gradient(cmap='summer_r')#ctb.plot(kind='bar')","d05e2405":"group_sur_class = train.groupby(['Sex','Survived','Pclass'])['Pclass'].count()\n#print(group_sur_class)\np = group_sur_class.unstack().plot(kind='bar')\nplt.title('Q survived & sex for each Class ')\nplt.show()\n\np = pd.crosstab([train.Sex, train.Survived], train.Pclass, normalize='columns').plot(kind='bar')\nplt.title('% survived & sex in base of the Class ')\nplt.show()\n\n\npd.crosstab([train.Sex, train.Survived], train.Pclass, normalize='columns').style.background_gradient('summer_r')\n","51b90234":"#sns.distplot(train.Age.dropna())\n#train['Age'].fillna(train['Age'].mean(), inplace=True)\n#f, axes = plt.subplots(1,3, figsize=(18,8))\nsns.distplot(train.Age.dropna(),label='Age')\n\nplt.legend()\nplt.show()","daf92e66":"sns.distplot(train.Age.dropna()[train.Survived==True],label='survived', color='green',hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[train.Survived==False], label='Die', color='red',hist_kws=dict(alpha=0.1))\n\nplt.legend()\nplt.show()","93822fd8":"grid = sns.FacetGrid(train.dropna(), col='Pclass', margin_titles=True)\nbins = np.linspace(0, 70, 10)\ngrid.map(sns.distplot, 'Age', bins=bins)","431b42f9":"f, axes = plt.subplots(2,3, figsize=(18,8))\nplt.subplot(231)\nplt.hist(x=train.Age[train.Pclass==1].dropna())\nplt.title('distribution of Age on Class I')\n\nplt.subplot(232)\nplt.hist(x=train.Age[train.Pclass==2].dropna())\nplt.title('Distribution of Age on Class II')\n\nplt.subplot(233)\nplt.hist(x=train.Age[train.Pclass==3].dropna())\nplt.title('Distribution of Age on Class III')\n\nsns.distplot(train.Age.dropna()[(train.Survived==True) & (train.Pclass==1)],label='surv_class_I', hist=True, color='green', ax=axes[1][0], hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[(train.Survived==False) & (train.Pclass==1)],label='Die_class_I',  hist=True, color='Red', ax=axes[1][0], hist_kws=dict(alpha=0.1))\n\n\nsns.distplot(train.Age.dropna()[(train.Survived==True) & (train.Pclass==2)],label='surv_class_II',  hist=True, color='green', ax=axes[1][1], hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[(train.Survived==False) & (train.Pclass==2)],label='Die_class_II',  hist=True, color='Red', ax=axes[1][1], hist_kws=dict(alpha=0.1))\n\nsns.distplot(train.Age.dropna()[(train.Survived==True) & (train.Pclass==3)],label='surv_class_II',  hist=True, color='green', ax=axes[1][2], hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[(train.Survived==False) & (train.Pclass==3)],label='Die_class_III',  hist=True, color='red', ax=axes[1][2], hist_kws=dict(alpha=0.1))\n\nplt.legend()\nplt.show()","8eb0d14d":"plt.figure(figsize=(15,8))\nsns.distplot(train.Fare.dropna(), hist=False, label='All' )\nsns.distplot(train.Fare.dropna()[train.Survived==1], color='green', label='survived', hist=False)\nsns.distplot(train.Fare.dropna()[train.Survived==0], color='red', label='Die', hist=False)\nplt.legend()\n","ba0c61c8":"train['cFare']= train.Fare.apply(lambda r: 'Low' if r <100 else ('Medium' if (r>=100 and r<200) else ('High' if (r>=200 and r<=300) else 'Ultra')  )).astype('category')\n#train.groupby([train.Farex,train.Survived])['PassengerId'].count()\ntrain.cFare.cat.reorder_categories(['Low','Medium','High','Ultra'], inplace=True)\n\n#we create table to CFare cross Survived\nctb = pd.crosstab(train.cFare, train.Survived)\n\n#Normalize data by row, to obtein ratio of survived\/die by category of Fare\nctb_Nr = pd.crosstab(train.cFare, train.Survived, normalize='index')\nctb.style.background_gradient('summer_r')\nctb_Nr.plot(kind='bar')\nplt.legend(labels=['D', 'S'])\nplt.title('% Die\/Survive base on Category Fare')\n\nprint('table Q values on \\n \\n', ctb)\nprint('\\n')\n# Present the data on %\nprint('table %  row margin values on \\n', ctb_Nr.round(4)*100)\n","64098be3":"from sklearn.impute import SimpleImputer\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import  Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nimport numpy as np\n#separar los datos\nfrom sklearn.model_selection import train_test_split\n# modelo Lineales\nfrom sklearn import linear_model\n# Funcion para procesar data\nfrom sklearn.preprocessing import FunctionTransformer","e49f6677":"# create a target array\ntarget = train.Survived\n#creta a function to get only the numerical data\nget_numeric_data = FunctionTransformer(lambda x: x[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], validate=False)\n#divide the train.csv on Train an Test Data to test models\nX_train, X_test,y_train, y_test = train_test_split(train, target, test_size=0.3, random_state=42)","9dae0f32":"#select the imputer and the Strategy\nimp = SimpleImputer(strategy='mean')\n# Scale the Data\nscl = preprocessing.StandardScaler()\n\n# declare\nlg = linear_model.LogisticRegression()\nlsgd = linear_model.SGDClassifier()\nlper = linear_model.Perceptron()\nrclas = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)","097b7318":"pipeline_lg = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('lg', lg)])\npipeline_rc = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('lsgd', lsgd)])\npipeline_pc = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('per',lper )])\npipeline_rclass = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('rdc',rclas )])\n\npipeline_lg.fit(X_train, y_train)\npipeline_rc.fit(X_train, y_train)\npipeline_pc.fit(X_train, y_train)\npipeline_rclass.fit(X_train, y_train)\n\nprint(pipeline_lg.score(X_test, y_test))\nprint(pipeline_rc.score(X_test, y_test))\nprint(pipeline_pc.score(X_test, y_test))\nprint(pipeline_rclass.score(X_test, y_test))","bd987872":"test.head()","c829232c":"predictions = pipeline_rclass.predict(test)\n\n\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","8b5471e0":"### 2.3 How many people **survive** if we consider  **Sex**?\n<a id=\"stp2.3\"><\/a>","99b488fc":"### 2. Select the numeric atributes\n* Create the Target array \n* Create a function transform to select the numerical variables. The idea is to include this selection on a pipeline process\n* Divide the object en Train and Test ","d14c61c9":"### How many people in each **class ** in %?\n### How many people Die\/survived in each **class** in %?","4a969c87":"## General view of Train DataSet","d466767a":"## How is survive distriburion depend it on Fare","b84f7fb4":"**Die\/survive on each class by sex**","5d0f143f":"# Step 1: Read all Data\n<a id=\"stp1\"><\/a>\n\nMerge the train and test data, the idea is to understand what are the quantity of data (all the universe), and how it was the proportion by Sex","d7dba1ce":"### How many people die and survive in base of each **class & Sex**?","6da18911":"###  2.1 How many people was on Titanic (train Dataset)** ?\n<a id=\"stp2.1\"><\/a>","a6af8368":"###  1. Import libraries to train models ","1c9dd0a6":"## How is Age distribution on Titanic\n\n**The Age Can be  ~ a normal distribution**","cf35f2f6":"### note:\nWe need to take care when construct our model about :\n* Age\n* Cabin\n*  Embarked\n*  Fare\nBecause the are features with Nulls values\n\n# Step 2: Begin to work with the Train Data Analysis\n<a id=\"stp2\"><\/a>\n\n**We work with Train Data and we launch 3 Action  on the train Dataset **\n1. Info\n2. Describe\n3. show 5 lines","daf4de4f":"The amount of people  on % by sex is similar on all_data\n\n### 2.2  How many people **Die\/Survive**?\n<a id=\"stp2.2\"><\/a>","30447b9f":"# We are goint to create four categories on Fare\nWe will create 4 class of Fare\n\n1. The low price will be less [0, 100[\n2. Medium [100 to 200[\n3. High [200 to 300[\n4. Ultra [300 , [\n\nThe table will be normalize base on Fare categorie and cross by survived\n\n## HIP: if you are Ultra, Do you have a high chance to survived?","0c906362":"![](http:\/\/)# Step 0:  Load libraries\n<a id=\"stp0\"><\/a>","c5006969":"## How is Age distribution by Class","13eda90b":"## How is Age distribution if we consider the Survived & Die ","a82102a3":"###  Create Pipeline for each model\nOn each pipeline we:\n1. get same attribute on dataframe using function get_numeric_data\n2. Impute on mean values with SimpleImputer\n3. Scale the variable on StandarScaler\n4.  Add a Method \n5. Create the each pipeline\n6. Print the Score","fc4e6102":"## How is age distribution on each Class & Die\/Survive","a7cc00ed":"# Machine learning \n\n## Testing only the numerical values\n0. Import libraries to train models\n1. Divide object & numeric atributes \n2.  Create Pipeline for each model\n3. Test different models one by one.\n4. Automate model in array and Test\n"}}