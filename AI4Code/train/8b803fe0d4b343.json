{"cell_type":{"ff1c1636":"code","efa26ba7":"code","985bbd0c":"code","068a7bc5":"code","295e579d":"code","4507d2f4":"code","9d9e376c":"code","6e845763":"code","8c8527a6":"code","41f3a637":"code","a1f6a5d4":"code","a4928261":"code","b392cf37":"code","a5124bf9":"code","fbff01fe":"code","ddc85c1a":"code","7a35f910":"code","747b643c":"code","a3cfc682":"code","f2ba5f0f":"code","0146bf1f":"code","677a68cb":"code","78345666":"code","0929320e":"code","2478bff6":"code","bb584b9f":"code","e42355f7":"code","2c0084d8":"code","cb45f01e":"code","89e0d02f":"code","9fa755b5":"code","cbd65a4c":"code","b69f7e26":"code","29ab7fae":"code","f4c1e22b":"code","754628cf":"code","1cce6b9d":"code","7c985d61":"code","e615f38a":"code","873e9e5f":"code","7893ab2c":"code","36608325":"code","00c4c147":"code","7e7e4b42":"markdown","9a9bd083":"markdown","4d8212fd":"markdown","91ebfd44":"markdown","d3be6639":"markdown","b66587d4":"markdown","62f86777":"markdown","07cb1263":"markdown","ea797bf4":"markdown","6c907034":"markdown","5945549a":"markdown","5a64e402":"markdown"},"source":{"ff1c1636":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","efa26ba7":"# Import \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","985bbd0c":"# Readiin in data in dataframe\nwm = pd.read_csv('\/kaggle\/input\/retail-analysis-with-walmart-sales-data\/WALMART_SALES_DATA.csv')\nwm.head()","068a7bc5":"# Basic check up for missing value\nwm.isna().sum()","295e579d":"wm.groupby('Store').sum()['Weekly_Sales'].sort_values(ascending = False).head()","4507d2f4":"wm.groupby('Store').std()['Weekly_Sales'].sort_values(ascending = False).head()","9d9e376c":"# Calculating Coefficient of Variation (CV)\n\n# Equation is CV = The Standard Deviation of dataset \/ The mean of dataset\n\ncv = wm.groupby('Store').std()['Weekly_Sales'] \/ wm.groupby('Store').mean()['Weekly_Sales']\ncv = cv.reset_index().rename(columns = {'Weekly_Sales': 'Coefficient of Variation'})\n\ncv.head()","6e845763":"# Maximum CV\ncv.sort_values(by='Coefficient of Variation', ascending = False).head()","8c8527a6":"# Convert Date column to datetime object\nwm['Date'] = pd.to_datetime(wm['Date'], format=\"%d-%m-%Y\")\nwm.info()","41f3a637":"# Extract the year and month\nwm['Year'] = pd.DatetimeIndex(wm['Date']).year\nwm['Month'] = pd.DatetimeIndex(wm['Date']).month\nwm.head()","a1f6a5d4":"# Quarter Three is from month July (6) to September (9) and Year 2012\n\nwm_q3_2012 = wm[(wm['Month'].isin([6,7,8,9])) & (wm['Year'] == 2012)] \nwm_q3_2012.head()","a4928261":"fig = px.bar(data_frame = wm_q3_2012.groupby('Store').sum().reset_index(),\n             x = 'Store', y = 'Weekly_Sales', text = 'Weekly_Sales')\n\n\nfig.update_layout(title = 'Total Weekly Sales of 45 Walmart stores during Q3 of 2012',\n                  yaxis_title = 'Total Weekly Sales',\n                  font = dict(family = \"Courier New, monospace\",\n                              size = 14, color = 'black')\n                  )\n\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n\nfig.update_layout(\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = [n for n in range(1,46)],\n    )\n)\n\n\n\nfig.show()","b392cf37":"# Growth Rate by Store so first recorded date of quarter 3 to last date\nwm_q3_2012['Date'].iloc[0] , wm_q3_2012['Date'].iloc[-1]","a5124bf9":"gr_wm = wm_q3_2012[(wm_q3_2012['Date'] == '2012-06-01') | (wm_q3_2012['Date'] == '2012-09-28')]\npct_wm = gr_wm.groupby('Store')['Weekly_Sales'].pct_change().dropna().reset_index().rename(columns={'index':'Store','Weekly_Sales':'%Change'})\npct_wm['Store'] = gr_wm['Store'].unique()\npct_wm.head()","fbff01fe":"# Top Performing WM Stores during Q3 2012\npct_wm.sort_values(by='%Change',ascending=False).head()","ddc85c1a":"# Decrease in weekly sales a lot during Q3 2012\npct_wm.sort_values(by='%Change',ascending=False).tail()","7a35f910":"# Creating Holiday DataFrame\nholiday = wm[wm['Holiday_Flag'] == 1]\nholiday.tail()","747b643c":"# What are holiday dates present here?\nholiday['Date'].value_counts()","a3cfc682":"# Assigning Holiday Name to Each presented date to make it easier for the comparison \n\n# Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n# Labour Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\n# Thanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n# Christmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13\n\nfrom datetime import datetime\n\nsuper_bowl = [datetime.strptime(date,\"%d-%b-%y\").date() for date in '12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13'.split(\", \")]\nlabour_day = [datetime.strptime(date,\"%d-%b-%y\").date() for date in '10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13'.split(\", \")]\nthanksgiving = [datetime.strptime(date,\"%d-%b-%y\").date() for date in '26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13'.split(\", \")]\nchristmas = [datetime.strptime(date,\"%d-%b-%y\").date() for date in '31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13'.split(\", \")]\n\ndef assign_holiday(date):\n    if date in super_bowl:\n        return 'Super Bowl'\n    elif date in labour_day:\n        return 'Labor Day'\n    elif date in thanksgiving:\n        return 'Thanksgiving'\n    elif date in christmas:\n        return 'Christmas'\n    else:\n        return 'Not Holiday'\n    \nholiday['Occasion'] = holiday['Date'].apply(lambda date: assign_holiday(date))\nholiday.head()","f2ba5f0f":"holiday_year = holiday.groupby(['Year','Occasion']).sum().reset_index()\n\nfig = px.bar(data_frame = holiday_year, \n             x = 'Year', y = 'Weekly_Sales',\n             color = 'Occasion', barmode = 'group',\n             text = 'Weekly_Sales', height = 550,\n             color_discrete_sequence = px.colors.qualitative.Safe)\n\nfig.update_layout(title = 'Walmart Total Sales from 2010 to 2012 by Public Holiday',\n                  yaxis_title = 'Total Sales',\n                  legend_title = 'Holiday',\n                  font = dict(family = \"Courier New, monospace\",\n                              size = 14, color = 'black')\n                  )\n\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n\nfig.update_layout(\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = [n for n in range(2010,2013)],\n    )\n)\n\nfig.show()","0146bf1f":"# Mean sales in non-holiday season for all stores together\nnon_holi_mean_sales = wm[wm['Holiday_Flag'] == 0]['Weekly_Sales'].mean()\nnon_holi_mean_sales \/ 10**6","677a68cb":"# Holiday Sales that is greater than mean \nholiday.groupby('Occasion')['Weekly_Sales'].mean() \/ 10**6 # Unit in Million (easier for comparison)","78345666":"# Top 3 Total Sales Walmart across 2 year\nfig = px.line(data_frame = wm[wm['Store'].isin(wm.groupby('Store').sum().sort_values(by='Weekly_Sales',ascending = False).iloc[:3].index.to_list())],\n              x = 'Date', y = 'Weekly_Sales',\n              color = 'Store', color_discrete_sequence = px.colors.qualitative.Safe)\n\nfig.update_layout(title = 'Top 3 Walmart Stores (by Total Sales) Weekly Sales',\n                  yaxis_title = 'Weekly Sales',\n                  font = dict(family = \"Courier New, monospace\",\n                              size = 14, color = 'black')\n                  )\n\nfig.show()","0929320e":"# Monthly Sales\nimport calendar\n\nfig = px.bar(data_frame = wm.groupby('Month').sum().reset_index(),\n             x = 'Month', y = 'Weekly_Sales',\n             text = 'Weekly_Sales', height = 550)\n\nfig.update_layout(title = 'Walmart Overall Monthly Sales from 2011 to 2013',\n                  yaxis_title = 'Total Sales',\n                  font = dict(family = \"Courier New, monospace\",\n                              size = 14, color = 'black')\n                  )\n\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n\nfig.update_yaxes(tickprefix=\"$\")\n\nfig.update_layout(\n    xaxis = dict(\n        ticktext = [calendar.month_name[n] for n in range(1,13)],\n        tickvals = [n for n in range(1,13)]\n    )\n)\n\nfig.show()","2478bff6":"fig = px.bar(data_frame = wm.groupby(['Month','Year']).sum().reset_index(),\n             x = 'Month', y = 'Weekly_Sales', color = 'Year',\n             text = 'Weekly_Sales', height = 550)\n\nfig.update_layout(title = 'Walmart Monthly Sales by Year',\n                  yaxis_title = 'Total Sales',\n                  font = dict(family = \"Courier New, monospace\",\n                              size = 14, color = 'black')\n                  )\n\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n\nfig.update(layout_coloraxis_showscale=False)\n\nfig.update_yaxes(tickprefix=\"$\")\n\nfig.update_layout(\n    xaxis = dict(\n        ticktext = [calendar.month_name[n] for n in range(1,13)],\n        tickvals = [n for n in range(1,13)]\n    )\n)\n\nfig.show()","bb584b9f":"# By Year Sales\nplt.figure(dpi=120)\nsns.barplot(data = wm.groupby('Year').sum().reset_index(),\n            x = 'Year', y = 'Weekly_Sales', palette = 'Set2')\nplt.title(\"Yearly Sales\")\nplt.ylabel(\"Sales (dollar)\")\nplt.show()","e42355f7":"# Recap of how does the Data Look like\nwm.head()","2c0084d8":"# Adding More columns\nwm['Day'] = pd.DatetimeIndex(wm['Date']).day\nwm['Holiday'] = wm['Date'].apply(lambda date: assign_holiday(date))\n\n\nwm.head()","cb45f01e":"# Checking for outlier and NaN value\n\nfeatures_list = 'Temperature, Fuel_Price, CPI, Unemployment, Year, Month, Day'.split(\", \")\n\nplt.figure(dpi=150)\ncount = 1\nfor feature in features_list:\n    plt.subplot(4,2,count)\n    sns.boxplot(wm[feature])\n    count += 1\nplt.tight_layout()\nplt.show()","89e0d02f":"# Removing Outlier\n\ndef remove_out(feature):\n\n    p25 = wm[feature].quantile(0.25)\n    p75 = wm[feature].quantile(0.75)\n    iqr = p75 - p25\n    \n    upper_limit = p75 + 1.5 * iqr \n    lower_limit = p25 - 1.5 * iqr\n    \n    new_df = wm[(wm[feature] > lower_limit) & (wm[feature] < upper_limit)]\n    \n    return new_df\n\nfor feature in features_list:\n    wm = remove_out(feature)\nwm.shape","9fa755b5":"from sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoder = OrdinalEncoder()\nwm['Holiday'] = ordinal_encoder.fit_transform(wm[['Holiday']])\n\nprint(ordinal_encoder.categories_)","cbd65a4c":"wm.head()","b69f7e26":"corr_matrix = wm.corr()\ncorr_matrix['Weekly_Sales'].sort_values(ascending = False)","29ab7fae":"from sklearn.model_selection import train_test_split\n\nfeatures = 'Temperature, Fuel_Price, CPI, Unemployment, Year, Month, Day, Holiday'.split(\", \")\ntarget = 'Weekly_Sales'\n\nX = wm[features]\ny = wm[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)","f4c1e22b":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\n\nprediction = lin_reg.predict(X_test)","754628cf":"from sklearn.metrics import mean_squared_error\n\nlin_rmse = np.sqrt(mean_squared_error(y_test, prediction))\nprint(\"RSME:\", lin_rmse)\nprint(\"Score:\", lin_reg.score(X_train, y_train) * 100,\"%\")","1cce6b9d":"sns.scatterplot(prediction, y_test)","7c985d61":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(X_train, y_train)\n\ntree_prediction = tree_reg.predict(X_test)\ntree_rmse = np.sqrt(mean_squared_error(y_test, tree_prediction))\nprint(\"RMSE:\",tree_rmse)\nprint(\"Score:\", tree_reg.score(X_train, y_train) * 100, \"%\")","e615f38a":"sns.scatterplot(tree_prediction, y_test)","873e9e5f":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor()\nforest_reg.fit(X_train, y_train)\n\nforest_prediction = forest_reg.predict(X_test)\nforest_rmse = np.sqrt(mean_squared_error(y_test, forest_prediction))\nprint(\"RMSE:\",forest_rmse)\nprint(\"Score:\", forest_reg.score(X_train, y_train) * 100, \"%\")","7893ab2c":"sns.scatterplot(forest_prediction, y_test)","36608325":"# Fine-Tune model using GridSearch\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators': [3, 10, 30, 45, 60], 'max_features': [2,4,6,8]},\n]\n\nforest_reg = RandomForestRegressor()\ngrid_search = GridSearchCV(forest_reg, param_grid, cv = 5,\n                           scoring = 'neg_mean_squared_error',\n                           return_train_score = True)\n\ngrid_search.fit(X_train, y_train)","00c4c147":"grid_search.best_params_","7e7e4b42":"# Statistical Model\n**Task -** For Store 1 \u2013 Build prediction models to forecast demand (Linear Regression \u2013 Utilize variables like date and restructure dates as 1 for 5 Feb 2010 (starting from the earliest date in order). Hypothesize if CPI, unemployment, and fuel price have any impact on sales.) Change dates into days by creating new variable.\nSelect the model which gives best accuracy.","9a9bd083":"# Task 5 - Provide a monthly and semester view of sales in units and give insights","4d8212fd":"# Task 3 - Which store\/s has good quarterly growth rate in Q3\u20192012","91ebfd44":"# Thank you for checking out my work!","d3be6639":"**Task 1 Answer** - Store 20 had the highest sales with 3.013978e+08 dollar","b66587d4":"**Task 3 Answer** - Store 17 and 44 were the only two Wm Stores that have increased their weekly sales during Quarter 3 of year 2012. Other than those two, other stores had decreased their weekly sales. Although Store 4 had the highest weekly sales during this time period, their sales actually went down.","62f86777":"**Task 2 Anwer** - Store 14 had the maximum standard deviation in Weekly Sales. Additionally, Store 35 has the maximum coefficient of variation at approximately 0.299","07cb1263":"## Tasks:\n1) Which store has maximum sales\n\n2) Which store has maximum standard deviation i.e., the sales vary a lot. Also, find out the coefficient of mean to standard deviation\n\n3) Which store\/s has good quarterly growth rate in Q3\u20192012\n\n4) Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together\n\n5) Provide a monthly and semester view of sales in units and give insights","ea797bf4":"# Task 2 - Which store has maximum standard deviation i.e., the sales vary a lot. Also, find out the coefficient of mean to standard deviation","6c907034":"### Percentage Change","5945549a":"# Task 4 - Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together\n\nNote on Holiday Events -->\n* Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n* Labour Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\n* Thanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n* Christmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13","5a64e402":"# Task 1 - Which store has maximum sales"}}