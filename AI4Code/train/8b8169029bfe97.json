{"cell_type":{"dee723d6":"code","1798ceca":"code","179e44fb":"code","a180060f":"code","fad61776":"code","6aca3e7b":"code","9ef6ff97":"code","da74c7ec":"code","8844a20e":"code","41399896":"code","78ca01bd":"code","bb0cdfda":"code","286304e1":"code","720f526e":"code","ae6346a2":"code","49362e54":"code","b86df158":"code","9467096c":"code","386f89cf":"code","af79164b":"code","f1a97ede":"code","792120f7":"code","8cc848ef":"code","1c578cfa":"code","88617ca0":"code","420b222b":"code","67b27b2d":"code","c2760ece":"code","699587b0":"code","f8ff23aa":"code","150f0237":"code","b303f1f9":"code","06cd881d":"markdown","5ccdf3f5":"markdown","1fa41c0f":"markdown","5dd098b3":"markdown","c3fb2d26":"markdown","8957c15c":"markdown","7973a010":"markdown","fcba9c90":"markdown","24eb46e1":"markdown"},"source":{"dee723d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom collections import Counter\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1798ceca":"df = pd.read_csv(\"\/kaggle\/input\/real-or-fake-fake-jobposting-prediction\/fake_job_postings.csv\")","179e44fb":"df.head()","a180060f":"df.info()","fad61776":"df.isnull().sum()","6aca3e7b":"text_df = df[[\"title\", \"company_profile\", \"description\", \"requirements\", \"benefits\"]]\ntext_df = text_df.fillna(' ')\n\ntext_df.head()","9ef6ff97":"cat_df = df[[\"telecommuting\", \"has_company_logo\", \"has_questions\", \"employment_type\", \"required_experience\", \"required_education\", \"industry\", \"function\",\"fraudulent\"]]\ncat_df = cat_df.fillna(\"None\")\ncat_df[\"telecommuting\"] = [0 if i==\"None\" else i for i in cat_df[\"telecommuting\"]]\ncat_df[\"has_questions\"] = [0 if i==\"None\" else i for i in cat_df[\"has_questions\"]]\ncat_df[\"has_company_logo\"] = [0 if i==\"None\" else i for i in cat_df[\"has_company_logo\"]]\n\ncat_df.head(10)","da74c7ec":"Counter(cat_df[\"employment_type\"])\n","8844a20e":"cat_df = pd.get_dummies(cat_df, columns=[\"employment_type\"])","41399896":"Counter(cat_df[\"required_experience\"])","78ca01bd":"cat_df = pd.get_dummies(cat_df, columns=[\"required_experience\"])","bb0cdfda":"Counter(cat_df[\"industry\"])","286304e1":"cat_df.drop(labels=[\"industry\"],axis=1,inplace=True)","720f526e":"Counter(cat_df[\"function\"])","ae6346a2":"cat_df.drop(labels=[\"function\"],axis=1,inplace=True)","49362e54":"cat_df = pd.get_dummies(cat_df, columns=[\"required_education\"])","b86df158":"cat_df.head()","9467096c":"import re\nimport nltk as nlp\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef clean_tex(data,max_features):\n    description_list = []\n    for description in data:\n        description = re.sub(\"[^a-zA-Z]\",\" \",description)\n        description = description.lower()\n        description = nlp.word_tokenize(description)\n        description = [word for word in description if not word in set(stopwords.words(\"english\"))]\n        lemma = nlp.WordNetLemmatizer()\n        description = [lemma.lemmatize(word) for word in description ]\n        description =\" \".join(description)\n        description_list.append(description)\n    count_vectorizer = CountVectorizer(max_features=max_features)\n    sparce_matrix=count_vectorizer.fit_transform(description_list).toarray()\n    return sparce_matrix","386f89cf":"text_df.head()","af79164b":"text_matrix = clean_tex(text_df.title,50)\ntext_matrix.shape","f1a97ede":"company_matrix = clean_tex(text_df.company_profile,50)\nprint(company_matrix.shape)\n","792120f7":"description_matrix = clean_tex(text_df.description,200)\nprint(description_matrix.shape)\n","8cc848ef":"requirements_matrix = clean_tex(text_df.requirements,100)\nprint(requirements_matrix.shape)","1c578cfa":"benefits_matrix = clean_tex(text_df.benefits,20)\nprint(benefits_matrix.shape)","88617ca0":"cat_x = cat_df.iloc[:,:-1].values\nprint(cat_x.shape)","420b222b":"x = np.concatenate((cat_x,text_matrix,company_matrix,description_matrix,requirements_matrix,benefits_matrix),axis=1)\nprint(x.shape)","67b27b2d":"Counter(cat_df[\"fraudulent\"])","c2760ece":"y = cat_df.iloc[:,4].values\ny.shape","699587b0":"Counter(y)","f8ff23aa":"from sklearn.model_selection import train_test_split\nx_train, x_test , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=42)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","150f0237":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(x_train,y_train)\n\n#%%\ny_pred = nb.predict(x_test)\nprint(\"score\",nb.score(x_test,y_test))\n","b303f1f9":"from sklearn.neighbors import KNeighborsClassifier\n\nnb = KNeighborsClassifier(n_neighbors=4)\n\nnb.fit(x_train,y_train)\n\nprint(\"score\",nb.score(x_test,y_test))","06cd881d":"* Categorical Data","5ccdf3f5":"<a id=\"2\" >\n    \n# Preprocessing","1fa41c0f":"1. [Load and Check Data](#1)\n2. [Preprocessing](#2)\n3. [Create Model](#3)","5dd098b3":"* With KNN","c3fb2d26":"<a id=\"3\">\n    \n# Create a Model","8957c15c":"<a id =\"1\" >\n    \n# Load and Check Data","7973a010":"* With Gaussian","fcba9c90":"* Text Datas","24eb46e1":"* Make text data suitable for our model"}}