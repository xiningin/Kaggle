{"cell_type":{"84327d24":"code","50999cbd":"code","09a171c9":"code","57ee0aa9":"code","1f0599a8":"code","aab86b86":"code","2d3f7c52":"code","2c36782c":"code","ffd59fd0":"code","5a20e77d":"code","e88d2c6b":"code","18448525":"markdown"},"source":{"84327d24":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')","50999cbd":"data=pd.read_csv(\"..\/input\/heart.csv\")","09a171c9":"data.head()","57ee0aa9":"data.info()","1f0599a8":"data.describe()","aab86b86":"plt.figure(figsize=(15,8))\nsns.heatmap(data.corr() , annot = True , cmap=\"inferno\")\nplt.show()","2d3f7c52":"sns.countplot(x = \"target\" , hue=\"sex\" ,  data=data , palette=\"dark\")\nplt.legend([\"Female\", \"Male\"])\nplt.xlabel(\" Disease                             Not Disease\")\nplt.show()","2c36782c":"y = data[\"target\"].values\nx = data.drop([\"target\"] , axis=1)","ffd59fd0":"#Normalization\nfrom sklearn.preprocessing import StandardScaler\nx = StandardScaler().fit_transform(x)","5a20e77d":"#train test split\nfrom sklearn.model_selection import train_test_split\nx_train , x_test , y_train , y_test = train_test_split(x , y , test_size=0.25 , random_state=0)","e88d2c6b":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\n\n#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=27,random_state=42) #n_estimators : Olu\u015facak Subsample Tree lerin say\u0131s\u0131\nrf.fit(x_train,y_train)\n\n#Knn\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=4)\nknn.fit(x_train,y_train)\n\n#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\n\n#Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n#SVM\nfrom sklearn.svm import SVC\nsvm = SVC(random_state=1)\nsvm.fit(x_train,y_train)\n\n\nprint(\"Decision Tree Score ...: {}\".format(dt.score(x_test,y_test)))\nprint(\"Random Forest Score ...: {}\".format(rf.score(x_test,y_test)))\nprint(\"Knn Score : {}\".format(knn.score(x_test,y_test)))\nprint(\"Logistic Regression Score {}\".format(lr.score(x_test,y_test)))\nprint(\"Naive Bayes Score ...: {}\".format(nb.score(x_test,y_test)))\nprint(\"SVM Score ...: {}\".format(svm.score(x_test,y_test)))","18448525":"**Random Forest has the best score (0.881578947368421)**"}}