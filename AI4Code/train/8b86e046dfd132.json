{"cell_type":{"cf6d528f":"code","3747d9ae":"code","0fa61721":"code","893667be":"code","2425ffb5":"code","6d14f9c4":"code","45048d5a":"code","93180067":"code","473b5e2c":"code","fa31c942":"code","21ab0e78":"code","9e1239a2":"code","370a623a":"code","4d17771a":"code","34c45503":"code","508b62e2":"code","01736fe9":"code","10d74a52":"code","49ad3d49":"code","137a33ca":"code","b9577413":"code","f3c1443d":"code","3939e8c2":"code","b7c7cfeb":"code","1993eb47":"code","a93ac82b":"code","b8450e94":"code","4908b5e5":"code","67ea7549":"code","4d7d04ac":"code","067a914f":"code","d4e7db9e":"code","31eb9ea1":"code","1da51398":"code","486e7fbe":"code","d715959e":"code","157ac284":"code","1a4a6e19":"code","431eced2":"code","80815d39":"code","b603d966":"code","a7599874":"code","2eb9af81":"code","49a824cb":"code","b567d022":"code","b6be0435":"code","de75270f":"code","68a9db25":"code","0620cd80":"code","c409b7bc":"code","1c1f88bc":"code","d035ad7f":"code","11d4c777":"code","4f4f42c8":"code","0e9755c3":"code","c2643cc6":"code","7fe42c20":"code","f7f24133":"code","2d3dc7c5":"code","daf429ab":"code","a11b850d":"code","6f9cff58":"code","1d66bea0":"code","525610e1":"markdown","3d0c7fe0":"markdown","3f420259":"markdown","23e48c0d":"markdown","921144fc":"markdown","02877fee":"markdown","2311d777":"markdown","65e93ed1":"markdown","28a160f8":"markdown","4aaeecec":"markdown","fa5a3eac":"markdown","9f89b2e7":"markdown","45a4ced9":"markdown","03b9498e":"markdown"},"source":{"cf6d528f":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3747d9ae":"#import data\ntrain = pd.read_csv('..\/input\/train.csv',index_col=0)","0fa61721":"#view data\ntrain.head(5)","893667be":"#Number and types of columns\ntrain.info()","2425ffb5":"#Look at statistics\ntrain.describe()","6d14f9c4":"#Look for missing data\nsns.heatmap(train.isnull(),yticklabels=False,cbar=False)","45048d5a":"#Comparing survival by features\nplt.figure(figsize=[15,5])\nplt.subplot(1,3,1)\nsns.countplot(x=\"Sex\",data=train, hue=\"Survived\")\nplt.title('Gender comparison')\n\nplt.subplot(1,3,2)\nsns.countplot(x='Pclass',data=train, hue=\"Survived\")\nplt.title('Class comparison')\n\nplt.subplot(1,3,3)\nsns.countplot(x='Embarked',data=train, hue=\"Survived\")\nplt.title('Class comparison')","93180067":"#Looking at spreads in data\nplt.figure(figsize=[15,10])\nplt.subplot(2,2,1)\nsns.distplot(train['Age'].dropna(),kde=True,bins=10)\nplt.xlim(0)\nplt.title('Age spread')\n\nplt.subplot(2,2,2)\nsns.distplot(train['Fare'],kde=True,bins=50)\nplt.xlim(0)\nplt.title('Fare spread')\n\nplt.subplot(2,2,3)\nsns.countplot(x='SibSp',data=train)\nplt.title('Sibling spread')\n\nplt.subplot(2,2,4)\nsns.countplot(x='Parch',data=train)\nplt.title('Parent spread')","473b5e2c":"#Comparing age by features\nplt.figure(figsize=[15,5])\nplt.subplot(1,4,1)\nsns.boxplot(x='Pclass',y='Age',data=train)\nplt.title('Class comparison')\n\nplt.subplot(1,4,2)\nsns.boxplot(x='Sex',y='Age',data=train)\nplt.title('Sex comparison')\n\nplt.subplot(1,4,3)\nsns.boxplot(x='SibSp',y='Age',data=train)\nplt.title('Sibling comparison')\n\n#Parents not used\nplt.subplot(1,4,4)\nsns.boxplot(x='Parch',y='Age',data=train)\nplt.title('Parent comparison')","fa31c942":"#Considered fare but not progressed with this as no clear correlation\nsns.lmplot(x='Age',y='Fare',data=train)","21ab0e78":"#Creating a feature and observation set\ntrain_age = train.drop(['Survived','Name','Parch','Ticket','Fare','Cabin','Embarked'],axis=1).dropna()\ntrain_age_features = train_age.drop('Age',axis=1)\ntrain_age_observations=train_age['Age']\nprint(train_age_features.shape)\nprint(train_age_observations.shape)","9e1239a2":"train_age_features.head(5)","370a623a":"#Split passenger classes\npclasses = pd.get_dummies(train_age_features['Pclass'],drop_first=True)\n#Split sex\ngenders = pd.get_dummies(train_age_features['Sex'],drop_first=True)\n\ngenders.head(5)         ","4d17771a":"train_age_features.drop(['Pclass','Sex'],axis=1,inplace=True)","34c45503":"train_age_features_2 = pd.concat([train_age_features,pclasses,genders],axis=1)\ntrain_age_features_2.head(5)","508b62e2":"train_age_observations.head(5)","01736fe9":"from sklearn.linear_model import LinearRegression\npredict_age = LinearRegression()\npredict_age.fit(train_age_features_2,train_age_observations)\nprint(train_age_features_2.columns.values)\nprint(predict_age.coef_)\nprint(predict_age.intercept_)","10d74a52":"#define predictive function\n\ndef add_age(mylist):\n    Age = mylist['Age']\n    Pclass = mylist['Pclass']\n    SibSp = mylist['SibSp']\n    if mylist['Sex'] == 'Male':\n        SibSp = 1\n    else:\n        Sex = 0\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            predicted_age = predict_age.predict([[SibSp,0,0,Sex]]).round()[0]\n\n        elif Pclass == 2:\n            predicted_age = predict_age.predict([[SibSp,1,0,Sex]]).round()[0]\n\n        else:\n            predicted_age = predict_age.predict([[SibSp,0,1,Sex]]).round()[0]\n\n    else:\n        predicted_age = Age\n    \n    if predicted_age < 0:\n        return 1\n    else: \n        return predicted_age","49ad3d49":"train['Age_predict'] = train[['Age','Pclass','SibSp','Sex']].apply(add_age, axis =1)","137a33ca":"#Age distibution of passengers\nsns.distplot(train['Age_predict'],kde=True,bins=20,color='Red',label=\"Predicted ages\")\nsns.distplot(train['Age'].dropna(),kde=True,bins=20,color='Blue',label=\"Known ages\")\nplt.xlim(-5)\nplt.legend()","b9577413":"#Showing predicted ages has no nulls now\nsns.heatmap(train.isnull(),yticklabels=False,cbar=False)","f3c1443d":"train.head(5)","3939e8c2":"print(train['Age'].min())\nprint(train['Age'].max())\nprint(train['Age_predict'].min())\nprint(train['Age_predict'].max())","b7c7cfeb":"train['Cabin'].describe()","1993eb47":"train['Cabin'].head(5)","a93ac82b":"#Extract cabin numbers and letters from Cabin field\ntrain['Cabin_number'] = train.Cabin.str.extract('(\\d+)')\ntrain['Cabin_deck_letter'] =train.Cabin.str.extract('(\\D+)')","b8450e94":"train['Cabin_deck_letter'].unique()","4908b5e5":"sns.countplot(x='Cabin_deck_letter',data=train, hue='Survived')","67ea7549":"train['Name'].describe()","4d7d04ac":"train['Name'].head()","067a914f":"train['Title'] = train.Name.str.split(',').apply(lambda x: x[1]).str.split('.').apply(lambda x: x[0])\ntrain['First_names'] = train.Name.str.split(',').apply(lambda x: x[1]).str.split('.').apply(lambda x: x[1])\ntrain['Surname'] = train.Name.str.split(',').apply(lambda x: x[0])\ntrain['First_name_length']=train.First_names.apply(len)\ntrain['Surname_length']=train.Surname.apply(len)","d4e7db9e":"train['First_names'].head()","31eb9ea1":"train[['Title','First_names','Surname','First_name_length']].head(5)","1da51398":"#Exploring name lengths\nplt.figure(figsize=[15,10])\nplt.subplot(2,2,1)\nsns.distplot(train['First_name_length'],kde=True,bins=10,color='Blue')\nplt.title('First name')\n\nplt.subplot(2,2,2)\nsns.distplot(train['Surname_length'],kde=True,bins=10,color='Red')\nplt.title('Surname')","486e7fbe":"#Exploring name lengths\nplt.figure(figsize=[15,10])\nplt.subplot(2,2,1)\nsns.boxplot(x='Survived',y='First_name_length',data=train)\nplt.title('First name')\n\nplt.subplot(2,2,2)\nsns.boxplot(x='Survived',y='Surname_length',data=train)\nplt.title('Surname')","d715959e":"#Exploring titles\ntrain.Title.unique()","157ac284":"# Survival chances vs title\nplt.figure(figsize=[15,10])\nplt.subplot(2,2,1)\nsns.countplot(x='Title',hue='Survived',data=train)\nplt.ylim(0)\n\nplt.subplot(2,2,2)\nsns.countplot(x='Title',hue='Survived',data=train)\nplt.ylim(0,10)\nplt.title('Zoomed')","1a4a6e19":"train.head(5)","431eced2":"#Replace empty cabin letters with 'Unknown'\ntrain.Cabin_deck_letter = train.Cabin_deck_letter.fillna(value=\"Unknown\")","80815d39":"#Add dummies for categoric variables\nPclass_dummy = pd.get_dummies(train['Pclass'],drop_first = True)\nSex_dummy = pd.get_dummies(train['Sex'],drop_first = True)\nEmbarked_dummy = pd.get_dummies(train['Embarked'],drop_first = True)\nCabin_deck_letter_dummy = pd.get_dummies(train['Cabin_deck_letter'],drop_first = True)","b603d966":"#Drop categoric columns\ntrain_features = train.drop(['Title','Survived','Name','Age','Ticket','Cabin','Cabin_number','Surname','First_names','Surname_length','Pclass','Sex','Embarked','Cabin_deck_letter'],axis=1)","a7599874":"#Add dummy columns. This is the feature dataframe.\nX = pd.concat([train_features,Pclass_dummy,Sex_dummy,Embarked_dummy,Cabin_deck_letter_dummy],axis=1)\nX.head(10)","2eb9af81":"#The observation series\ny = train.Survived\ny.head(5)","49a824cb":"#Check they are the same shape\nprint(X.shape)\nprint(y.shape)","b567d022":"#Check the correlation between variables\nplt.figure(figsize=[15,10])\nZ=pd.concat([X,y],axis=1)\nsns.heatmap(Z.corr(), vmin = -1, vmax=1, annot=True, cmap=\"coolwarm\")","b6be0435":"# import the class\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score","de75270f":"# instantiate the model \nlogreg_1 = LogisticRegression(solver='lbfgs',max_iter=1000,C=1,penalty='l2')","68a9db25":"#1st score\nscores_logreg_1 = cross_val_score(logreg_1, X, y, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.3f (+\/- %0.3f)\" % (scores_logreg_1.mean(), scores_logreg_1.std() * 2))","0620cd80":"#Dropping individual features\ntesting_list = ['SibSp','Parch','Fare','Age_predict','First_name_length',[2,3],'male',['Q','S'],['B','C','D','E','F','F E','F G','G','T','Unknown']]\n\nX_temp = X\nfor col in testing_list:\n    X_temp= X.drop(col,axis=1)\n    if len(X_temp.columns)>0:\n        scores_logreg_temp = cross_val_score(logreg_1, X_temp, y, cv=10, scoring='accuracy')\n        print(\"Dropping %s - Accuracy: %0.3f (+\/- %0.3f)\" % (col, scores_logreg_temp.mean(), scores_logreg_temp.std() * 2))","c409b7bc":"#Exhausting combinations of dropping features to check nothing is missed\ntesting_list = ['SibSp','Parch','Fare','Age_predict','First_name_length',[2,3],'male',['Q','S'],['B','C','D','E','F','F E','F G','G','T','Unknown']]\nscores_list = []\nsd_list =[]\naccomp_features_list = []\n\nX_temp = X\nfor col in testing_list:\n    X_temp= X.drop(col,axis=1)\n    scores_logreg_temp = cross_val_score(logreg_1, X_temp, y, cv=10, scoring='accuracy')\n    scores_list.append(scores_logreg_temp.mean())\n    sd_list.append(scores_logreg_temp.std())\n    accomp_features_list.append(col)\n    for col_2 in testing_list:\n        X_temp_2 = X_temp\n        if col != col_2:\n            X_temp_2 = X_temp.drop(col_2,axis=1)    \n        scores_logreg_temp = cross_val_score(logreg_1, X_temp_2, y, cv=10, scoring='accuracy')\n        scores_list.append(scores_logreg_temp.mean())\n        sd_list.append(scores_logreg_temp.std())\n        accomp_features_list.append([col,col_2])\n            \nprint(\"Complete\")","1c1f88bc":"#Show feature results in table\nfeature_testing = pd.concat([pd.Series(accomp_features_list),pd.Series(scores_list),pd.Series(sd_list)],axis=1)\nfeature_testing.columns = (['FeaturesDropped','PredictionAccuracy','StandardDeviation'])\nfeature_testing.head(5)","d035ad7f":"print(feature_testing.iloc[feature_testing['PredictionAccuracy'].idxmax()])\nfig, ax1 = plt.subplots()\n\ncolor = 'tab:red'\nax1.set_xlabel('Index')\nax1.set_ylabel('Accuracy', color=color)\nax1.plot(feature_testing.index, feature_testing.PredictionAccuracy, color=color, alpha=0.5)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_ylim([0.5,0.9])\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ncolor = 'tab:blue'\nax2.set_ylabel('Standard Deviation', color=color)  # we already handled the x-label with ax1\nax2.plot(feature_testing.index, feature_testing.StandardDeviation, color=color, ls='--', alpha = 0.5)\nax2.tick_params(axis='y', labelcolor=color)\nax2.set_ylim([0,0.1])\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped","11d4c777":"X_final_log_reg = X.drop(['Parch','First_name_length','T'],axis=1)\nprint(X_final_log_reg.shape)\nX_final_log_reg.head(5)","4f4f42c8":"#Model to be used for final run\nlogreg_final = LogisticRegression(solver='lbfgs',max_iter=1000,C=1,penalty='l2')\nlogreg_final.fit(X_final_log_reg,y)\n\npredictions = logreg_final.predict(X_final_log_reg)","0e9755c3":"from sklearn.metrics import classification_report\nprint(classification_report(y,predictions))","c2643cc6":"#import data\ntest = pd.read_csv('..\/input\/test.csv',index_col=0)","7fe42c20":"#view data\ntest.head(5)","f7f24133":"#Checking for any missing data\nsns.heatmap(test.isnull(),yticklabels=False,cbar=False)","2d3dc7c5":"#Replace missing fare with mean\ntest.Fare = test.Fare.fillna(value = test.Fare.mean())\nsns.heatmap(test.isnull(),yticklabels=False,cbar=False)","daf429ab":"#Checking data is similar to above\n#Train\nplt.figure(figsize=[15,20])\nplt.subplot(4,2,1)\nsns.distplot(train['Age'].dropna(),kde=True,bins=10)\nplt.xlim(0)\nplt.title('Train - Age spread')\n\nplt.subplot(4,2,2)\nsns.distplot(test['Age'].dropna(),kde=True,bins=10)\nplt.xlim(0)\nplt.title('Test - Age spread')\n\nplt.subplot(4,2,3)\nsns.distplot(train['Fare'],kde=True,bins=50)\nplt.xlim(0)\nplt.title('Train - Fare spread')\n\nplt.subplot(4,2,4)\nsns.distplot(test['Fare'],kde=True,bins=50)\nplt.xlim(0)\nplt.title('Test - Fare spread')\n\nplt.subplot(4,2,5)\nsns.countplot(x='SibSp',data=train)\nplt.title('Train - Sibling spread')\n\nplt.subplot(4,2,6)\nsns.countplot(x='SibSp',data=test)\nplt.title('Test - Sibling spread')\n\nplt.subplot(4,2,7)\nsns.countplot(x='Parch',data=train)\nplt.title('Train - Parent spread')\n\nplt.subplot(4,2,8)\nsns.countplot(x='Parch',data=test)\nplt.title('Test - Parent spread')","a11b850d":"#Cleaning process as above\ntest['Cabin_number'] = test.Cabin.str.extract('(\\d+)')\ntest['Cabin_deck_letter'] =test.Cabin.str.extract('(\\D+)')\ntest['Age_predict'] = test[['Age','Pclass','SibSp','Sex']].apply(add_age, axis =1)\ntest['Title'] = test.Name.str.split(',').apply(lambda x: x[1]).str.split('.').apply(lambda x: x[0])\ntest['First_names'] = test.Name.str.split(',').apply(lambda x: x[1]).str.split('.').apply(lambda x: x[1])\ntest['Surname'] = test.Name.str.split(',').apply(lambda x: x[0])\ntest['First_name_length']=test.First_names.apply(len)\ntest['Surname_length']=test.Surname.apply(len)\ntest.Cabin_deck_letter = test.Cabin_deck_letter.fillna(value=\"Unknown\")\nPclass_dummy = pd.get_dummies(test['Pclass'],drop_first = True)\nSex_dummy = pd.get_dummies(test['Sex'],drop_first = True)\nEmbarked_dummy = pd.get_dummies(test['Embarked'],drop_first = True)\nCabin_deck_letter_dummy = pd.get_dummies(test['Cabin_deck_letter'],drop_first = True)\ntest_features = test.drop(['Title','Name','Age','Ticket','Cabin','Cabin_number','Surname','First_names','Surname_length','Pclass','Sex','Embarked','Cabin_deck_letter'],axis=1)\nX_test = pd.concat([test_features,Pclass_dummy,Sex_dummy,Embarked_dummy,Cabin_deck_letter_dummy],axis=1)\nX_test.drop(['Parch','First_name_length'],axis=1,inplace=True)\nprint(X_test.shape)\nX_test.head(10)","6f9cff58":"#Making predictions\npredictions = logreg_final.predict(X_test)","1d66bea0":"#Output for submission\noutput = pd.concat([pd.Series(X_test.index),pd.Series(predictions)],axis=1)\noutput.columns = ['PassengerId','Survived']\noutput.to_csv('output.csv', index=False)","525610e1":"### 5.1.4 Final logistic model","3d0c7fe0":"### 5.1.1 Simple base model","3f420259":"# 1. Importing libraries and data","23e48c0d":"### 5.1.2 Feature optimisation","921144fc":"# 3. Data cleaning\/ feature creation","02877fee":"# 4. Preparing data for predictions","2311d777":"## 5.1 Logistic regression","65e93ed1":"## 3.1 Predicting age for missing values","28a160f8":"## 3.2 Creating features from Cabin field","4aaeecec":"## 6.1 Logistic regression","fa5a3eac":"# 6. Predicting unseen data","9f89b2e7":"# 2. Data exploratory","45a4ced9":"## 3.3 Creating features from name column****","03b9498e":"# 5. Predictions"}}