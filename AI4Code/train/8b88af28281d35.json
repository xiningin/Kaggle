{"cell_type":{"840badf3":"code","8e2678a8":"code","e42a9898":"code","5f82b5bc":"code","3d91b0f9":"code","e3a02fcd":"code","dc4e63b6":"code","1336f30b":"code","d1be72ac":"code","3ded5f59":"code","67ea5bff":"code","cc959028":"code","5619fb27":"code","10b6ce60":"code","eb5ed131":"code","0bb108e0":"code","9dc13d9d":"code","22501ec3":"code","cf2e937a":"code","7585f18c":"code","02a06eb7":"code","02406fdd":"code","cdd5c16b":"markdown","66604e02":"markdown","b8742030":"markdown","a8f2a60e":"markdown","aa99eaaf":"markdown","73cb249c":"markdown","9cd77501":"markdown","79da182d":"markdown","16378f85":"markdown","33e23182":"markdown","dbfd92c5":"markdown","e28ab93c":"markdown","f6c8eac2":"markdown","123ebcd0":"markdown","27981b91":"markdown","c0af79df":"markdown","e055efa9":"markdown","5722accc":"markdown","711292ad":"markdown"},"source":{"840badf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e2678a8":"from fastai.vision.all import *\nfrom fastai.imports import *\nfrom fastai.vision.data import *\nfrom fastai import *\nimport numpy as np\nimport fastai\nimport matplotlib.pyplot as plt","e42a9898":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","5f82b5bc":"path = Path(\"\/kaggle\/input\/ai4all-project\/figures\/classifier\")\npath.ls()","3d91b0f9":"def _add1(x): return x+1\ndumb_tfm = RandTransform(enc=_add1, p=0.5)\nstart,d1,d2 = 2,False,False\nfor _ in range(40):\n    t = dumb_tfm(start, split_idx=0)\n    if dumb_tfm.do: test_eq(t, start+1); d1=True\n    else:           test_eq(t, start)  ; d2=True\nassert d1 and d2\ndumb_tfm","e3a02fcd":"from PIL import Image\n\nimg = Image.open(\"..\/input\/ai4all-project\/figures\/classifier\/lassoRandomForest_5gene_roc.png\")\nimg","dc4e63b6":"TensorTypes = (TensorImage,TensorMask,TensorPoint,TensorBBox)","1336f30b":"_,axs = subplots(1,2)\nshow_image(img, ctx=axs[0], title='original')\nshow_image(img.flip_lr(), ctx=axs[1], title='flipped');","d1be72ac":"img.resize((64,64))","3ded5f59":"timg = TensorImage(image2tensor(img))\ntpil = PILImage.create(timg)","67ea5bff":"tpil.resize((64,64))","cc959028":"TensorTypes = (TensorImage,TensorMask,TensorPoint,TensorBBox)\n\ndef flip_lr(x:Image.Image): return x.transpose(Image.FLIP_LEFT_RIGHT)\ndef flip_lr(x:TensorImageBase): return x.flip(-1)\ndef flip_lr(x:TensorPoint): return TensorPoint(_neg_axis(x.clone(), 0))\ndef flip_lr(x:TensorBBox):  return TensorBBox(TensorPoint(x.view(-1,2)).flip_lr().view(-1,4))","5619fb27":"img = PILImage(PILImage.create(timg).resize((600,400)))\nimg","10b6ce60":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,sz in zip(axs.flatten(), [300, 500, 700]):\n    show_image(img.crop_pad(sz), ctx=ax, title=f'Size {sz}');","eb5ed131":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,mode in zip(axs.flatten(), [PadMode.Zeros, PadMode.Border, PadMode.Reflection]):\n    show_image(img.crop_pad((600,700), pad_mode=mode), ctx=ax, title=mode);","0bb108e0":"#Randomly crop an image to size\n\n_,axs = plt.subplots(1,3,figsize=(12,4))\nf = RandomCrop(200)\nfor ax in axs: show_image(f(img), ctx=ax);","9dc13d9d":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax in axs: show_image(f(img, split_idx=1), ctx=ax);","22501ec3":"test_eq(ResizeMethod.Squish, 'squish')","cf2e937a":"Resize(224)","7585f18c":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,method in zip(axs.flatten(), [ResizeMethod.Squish, ResizeMethod.Pad, ResizeMethod.Crop]):\n    rsz = Resize(256, method=method)\n    show_image(rsz(img, split_idx=0), ctx=ax, title=method);","02a06eb7":"crop = RandomResizedCrop(256)\n_,axs = plt.subplots(3,3,figsize=(9,9))\nfor ax in axs.flatten():\n    cropped = crop(img)\n    show_image(cropped, ctx=ax);","02406fdd":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Mar\u00edlia Prata, @mpwolke Was here' )","cdd5c16b":"#Sensitivity and specificity plotted for each assay (Results: Primary analysis)\n\nSensitivity and specificity (95% confidence intervals) plotted for each assay using the current MHRA TPP criteria: \u226520 days post-symptom onset in confirmed laboratory cases of SARS-CoV-2 for positive cases, and >6 months prior to the first known COVID-19 cases for negatives.\n\nThe MHRA TPP target performance is shown (dashed line) including the required lower bound of the 95% confidence interval (dotted line) for both sensitivity and specificity. Data are presented for 994 known negative samples and 536 known positive samples run on each assay; equivocal results were excluded from the calculation of sensitivity and specificity for the DiaSorin assay (n=9).\n\n![](https:\/\/els-jbs-prod-cdn.jbs.elsevierhealth.com\/cms\/attachment\/b133bd71-362b-48ab-bbc5-5ddf9ecd437d\/gr1_lrg.jpg)\nhttps:\/\/assets.publishing.service.gov.uk\/government\/uploads\/system\/uploads\/attachment_data\/file\/898437\/Evaluation__of_sensitivity_and_specificity_of_4_commercially_available_SARS-CoV-2_antibody_immunoassays.pdf","66604e02":"#Results: Secondary analysis\n\nThey used ROC curves to investigate the performance of each assay. ROC curves evaluate the trade-off between true positive \nrates (ie assay sensitivity) versus false positive rates (ie 1-specificity) at a given assay threshold.\n \nDistribution of numerical results obtained for each assay, using samples defined according to the current MHRA TPP criteria. Assay thresholds (set by the manufacturers) are shown as dashed lines. For the purposes of plotting values on a log scale, values of zero were set to the lowest non-zero value and results of greater or less than the largest or smallest values were truncated to the largest and smallest values. Data are presented for 994 known negative samples and 536 known positive samples run on each assay.\n \n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTnJoJj-mDvtFtHQ1Tg1gow-93rMzOBb5MPog&usqp=CAU) \nhttps:\/\/assets.publishing.service.gov.uk\/government\/uploads\/system\/uploads\/attachment_data\/file\/898437\/Evaluation__of_sensitivity_and_specificity_of_4_commercially_available_SARS-CoV-2_antibody_immunoassays.pdf","b8742030":"#Center crop","a8f2a60e":"#Sensitivity and specificity\n\nSensitivity and specificity are statistical measures of the performance of a binary classification test that are widely used in medicine:\n\nSensitivity measures the proportion of positives that are correctly identified (e.g., the percentage of sick people who are correctly identified as having some illness).\n\nSpecificity measures the proportion of negatives that are correctly identified (e.g., the percentage of healthy people who are correctly identified as not having some illness).\n\nThe terms \"positive\" and \"negative\" do not refer to benefit, but to the presence or absence of a condition; for example if the condition is a disease, \"positive\" means \"diseased\" and \"negative\" means \"healthy\".\nhttps:\/\/en.wikipedia.org\/wiki\/Sensitivity_and_specificity","aa99eaaf":"##Potential consequences of false-positive COVID-19 swab test results\n\nGLOBAL PERSPECTIVE\n\nFinancial\n\nMisspent funding (often originating from taxpayers) and human resources for test and trace.\/Unnecessary testing\/\nFunding replacements in the workplace\/Various business losses.\n\nEpidemiological and diagnostic performance\n\nOverestimating COVID-19 incidence and the extent of asymptomatic infection\/ \nMisleading diagnostic performance, potentially leading to mistaken purchasing or investment decisions if a new test shows high performance by identification of negative reference samples as positive (ie, is it a false positive or does the test show higher sensitivity than the other comparator tests used to establish the negativity of the test sample?)\n\nSocietal\n\nMisdirection of policies regarding lockdowns and school closures\/Increased depression and domestic violence (eg, due to lockdown, isolation, and loss of earnings after a positive test).\n\nhttps:\/\/www.thelancet.com\/journals\/lanres\/article\/PIIS2213-2600(20)30453-7\/fulltext","73cb249c":"Summarising, false-positive COVID-19 swab test results might be increasingly likely in the current epidemiological climate in the UK, with substantial consequences at the personal, health system, and societal levels.\n\nSeveral measures might help to minimise false-positive results and mitigate possible consequences. Firstly, stricter standards should be imposed in laboratory testing. This includes the development and implementation of external quality assessment schemes and internal quality systems, such as automatic blinded replication of a small number of tests for performance monitoring to ensure false-positive and false-negative rates remain low, and to permit withdrawal of a malfunctioning test at the earliest possibility.\n\nSecondly, pretest probability assessments should be considered, and clear evidence-based guidelines on interpretation of test results developed. \n\nThirdly, policies regarding the testing and prevention of virus transmission in health-care workers might need adjustments, with an immediate second test implemented for any health-care worker testing positive. Finally, research is urgently required into the clinical and epidemiological significance of prolonged virus shedding and the role of people recovering from COVID-19 in disease transmission.\nhttps:\/\/www.thelancet.com\/journals\/lanres\/article\/PIIS2213-2600(20)30453-7\/fulltext","9cd77501":"#Asymptomatic people affects the other key parameter of testing\n\nAlthough testing capacity and therefore the rate of testing in the UK and worldwide has continued to increase, more and more asymptomatic individuals have undergone testing.\n\nThis growing inclusion of asymptomatic people affects the other key parameter of testing, the pretest probability, which underpins the veracity of the testing strategy. In March and early April, 2020, most people tested in the UK were severely ill patients admitted to hospitals with a high probability of infection.\n\nSince then, the number of COVID-19-related hospital admissions has decreased markedly from more than 3000 per day at the peak of the first wave, to just more than 100 in August, while the number of daily tests jumped from 11\u2008896 on April 1, 2020, to 190\u2008220 on Aug 1, 2020. \n\nIn other words, the pretest probability will have steadily decreased as the proportion of asymptomatic cases screened increased against a background of physical distancing, lockdown, cleaning, and masks, which have reduced viral transmission to the general population. \n\nAt present, only about a third of swab tests are done in those with clinical needs or in health-care workers (defined as the pillar 1 community in the UK), while the majority are done in wider community settings (pillar 2). At the end of July, 2020, the positivity rate of swab tests within both pillar 1 (1\u00b77%) and pillar 2 (0\u00b75%) remained significantly lower than those in early April, when positivity rates reached 50%.https:\/\/www.thelancet.com\/journals\/lanres\/article\/PIIS2213-2600(20)30453-7\/fulltext","79da182d":"![](https:\/\/static.healthcare.siemens.com\/siemens_hwem-hwem_ssxa_websites-context-root\/wcm\/idc\/groups\/public\/@global\/@lab\/documents\/image\/mda5\/odky\/~edisp\/5_vs_10_percent_prevalence-07401380\/~renditions\/5_vs_10_percent_prevalence-07401380~8.jpg)\n\nWhat happens when the specificity is reduced to 96%?\n\nA 96% specificity may seem high, but a difference of as small as 3 to 4 percent can create dramatic changes in test results.\n\nhttps:\/\/www.siemens-healthineers.com\/br\/laboratory-diagnostics\/assays-by-diseases-conditions\/infectious-disease-assays\/specificity-matters","16378f85":"#Why Specificity Matters in COVID-19 antibody testing\n\nTest quality and accuracy are paramount to minimize risks of inaccurate results.\n\nSensitivity vs Specificity\n\nTest sensitivity indicates the ability of the test to correctly identify patients that have the disease. A test\u2019s sensitivity is also known as the true positive rate. If a diagnostic test correctly identified 100% of all positive results, it would be as sensitive as possible.\nTest specificity indicates the ability of the test to correctly identify patients that do not have the disease. If a test correctly identifies all people without the disease as negative, it would be as specific as possible.\n\nSpecificity in COVID-19 testing\nFor SARS-CoV-2 antibody testing, the CDC suggests use of tests with a specificity \u226599.5% to minimize the potential for false-positive results.1\n\nThere are numerous tests that claim to detect antibodies to the SARS-CoV-2 virus; only a few are highly accurate.\nhttps:\/\/www.siemens-healthineers.com\/br\/laboratory-diagnostics\/assays-by-diseases-conditions\/infectious-disease-assays\/specificity-matters","33e23182":"#False-negative tests - Asymptomatic or mildly symptomatic patients\n\nGlobally, most effort so far has been invested in turnaround times and low test sensitivity (ie, false negatives); one systematic review reported false-negative rates of between 2% and 33% in repeat sample testing.\n\nAlthough false-negative tests have until now had priority due to the devastating consequences of undetected cases in health-care and social care settings, and the propagation of the epidemic especially by asymptomatic or mildly symptomatic patients, the consequences of a false-positive result are not benign from various perspectives, in particular among health-care workers.\nhttps:\/\/www.thelancet.com\/journals\/lanres\/article\/PIIS2213-2600(20)30453-7\/fulltext","dbfd92c5":"#Evaluation of sensitivity and specificity of four commercially available SARS-CoV-2 antibody immunoassays\n\nPublic Health England, Porton Down - Nuffield Department of Medicine, University of Oxford - Oxford University Hospitals NHS Foundation Trust \n\nTo cope with the demand for serological diagnosis, several manufacturers have developed immunoassays that are compatible with current global laboratory infrastructures, including high-throughput analyzers. However, assembling appropriate and large sets of samples to thoroughly test the performance of these assays has been difficult within the very short time frames of assay development and release, and direct comparisons of platforms have been limited.\n\nTo directly evaluate and compare the sensitivity and specificity of four commercial immunoassays for SARS-CoV-2 antibody \n, the authors formed a collaboration between Public Health England -Porton Down, Oxford University Hospitals NHS Foundation Trust, and the University of Oxford. Using a large collection of serum\/plasma samples from individuals with SARS-CoV-2 infection confirmed by RT-PCR, and a bank of known negative samples collected pre-pandemic, they ran the same samples across all four platforms in a \u2018head-to-head\u2019 evaluation.\nhttps:\/\/assets.publishing.service.gov.uk\/government\/uploads\/system\/uploads\/attachment_data\/file\/898437\/Evaluation__of_sensitivity_and_specificity_of_4_commercially_available_SARS-CoV-2_antibody_immunoassays.pdf ","e28ab93c":"![](https:\/\/static.healthcare.siemens.com\/siemens_hwem-hwem_ssxa_websites-context-root\/wcm\/idc\/groups\/public\/@global\/@lab\/documents\/image\/mda5\/ody3\/~edisp\/highly_accurate_tests_covid-19_siemens_healthineers_16x9-07370965\/~renditions\/highly_accurate_tests_covid-19_siemens_healthineers_16x9-07370965~8.jpg)Siemens Healthineers","f6c8eac2":"#Image resize with tpil","123ebcd0":"#Potential consequences of false-positive COVID-19 swab test results\n\nINDIVIDUAL PERSPECTIVE\n\nHealth-related\n\nFor swab tests taken for screening purposes before elective procedures or surgeries: unnecessary treatment cancellation or postponement\n\nFor swab tests taken for screening purposes during urgent hospital admissions: potential exposure to infection following a wrong pathway in hospital settings as an in-patient.\n\n\n\nFinancial\n\nFinancial losses related to self-isolation, income losses, and cancelled travel, among other factors\n\n\nPsychological\n\nPsychological damage due to misdiagnosis or fear of infecting others, isolation, or stigmatisation.\nhttps:\/\/www.thelancet.com\/journals\/lanres\/article\/PIIS2213-2600(20)30453-7\/fulltext","27981b91":"#Dataloader has no Batches, therefore I couldn't run some cells. Go to Plan B.","c0af79df":"#Randomly flip with probability p","e055efa9":"#Sensitivity, specificity and predictive values of molecular and serological tests for COVID-19. A longitudinal study in #emergency room.\n\nAuthors: Zeno Bisoffi, ELENA POMARI, Michela Deiana, Chiara Piubelli, Niccolo Ronzoni, Anna Beltrame, Giulia Bertoli, Niccolo Riccardi, Francesca Perandin, Fabio Formenti, Federico Gobbi, Dora Buonfrate, Ronaldo Silva\ndoi: https:\/\/doi.org\/10.1101\/2020.08.09.20171355\nNow published in Diagnostics doi: 10.3390\/diagnostics10090669\n\nAccuracy of diagnostic tests is essential for suspected cases of Coronavirus Disease 2019 (COVID-19). This study aimed to assess the sensitivity, specificity and positive and negative predictive value (PPV and NPV) of molecular and serological tests for the diagnosis of SARS-CoV-2 infection.\n\nThe authors evaluated three RT-PCR methods including six different gene targets; five serologic rapid diagnostic tests (RDT); one ELISA test. The final classification of infected\/not infected patients was performed using Latent Class Analysis in combination with clinical re-assessment of incongruous cases and was the basis for the main analysis of accuracy. Of 346 patients consecutively enrolled, 85 (24.6%) were classified as infected.\n\nThe molecular test with the highest sensitivity, specificity, PPV and NPV was RQ-SARS-nCoV-2 with 91.8% (C.I. 83.8-96.6), 100% (C.I. 98.6-100.0), 100.0% (C.I. 95.4-100.0) and 97.4% (C.I. 94.7-98.9) respectively, followed by CDC 2019-nCoV with 76.2% (C.I. 65.7-84.8), 99.6% (C.I. 97.9-100.0), 98.5% (C.I. 91.7-100.0) and 92.9% (C.I. 89.2-95.6) and by in-house test targeting E-RdRp with 61.2% (C.I. 50.0-71.6), 99.6% (C.I. 97.9-100.0), 98.1% (C.I. 89.9-100.0) and 88.7% (C.I. 84.6-92.1).\n \nThe analyses on single gene targets found the highest sensitivity for S and RdRp of the RQ-SARS-nCoV-2 (both with sensitivity 94.1%, C.I. 86.8-98.1). The in-house RdRp had the lowest sensitivity (62.4%, C.I. 51.2-72.6). The specificity ranged from 99.2% (C.I. 97.3-99.9) for in-house RdRp and N2 to 95.0% (C.I. 91.6-97.3) for E. The PPV ranged from 97.1% (C.I. 89.8-99.6) of N2 to 85.4% (C.I. 76.3-92.00) of E, and the NPV from 98.1% (C.I. 95.5-99.4) of gene S to 89.0% (C.I. 84.8-92.4) of in-house RdRp. \n\nAll serological tests had <50% sensitivity and low PPV and NPV. One RDT (VivaDiag IgM) had high specificity (98.5%, with PPV 84.0%), but poor sensitivity (24.7%). Molecular tests for SARS-CoV-2 infection showed excellent specificity, but significant differences in sensitivity. As expected, serological tests have limited utility in a clinical context.\nhttps:\/\/www.medrxiv.org\/content\/10.1101\/2020.08.09.20171355v1","5722accc":"#False-positive COVID-19 results: hidden problems and costs\n\nAuthors: Elena Surkova; Vladyslav Nikolayevskyy; Francis Drobniewski\nPublished:September 29, 2020DOI:https:\/\/doi.org\/10.1016\/S2213-2600(20)30453-7\n\nRT-PCR tests to detect severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) RNA are the operational gold standard for detecting COVID-19 disease in clinical practice. RT-PCR assays in the UK have analytical sensitivity and specificity of greater than 95%, but no single gold standard assay exists.\n\nNew assays are verified across panels of material, confirmed as COVID-19 by multiple testing with other assays, together with a consistent clinical and radiological picture. These new assays are often tested under idealised conditions with hospital samples containing higher viral loads than those from asymptomatic individuals living in the community. As such, diagnostic or operational performance of swab tests in the real world might differ substantially from the analytical sensitivity and specificity.https:\/\/www.thelancet.com\/journals\/lanres\/article\/PIIS2213-2600(20)30453-7\/fulltext","711292ad":"#How do highly specific antibody tests support good performance, even with low disease prevalence?\n\nLet\u2019s look at what happens in two cities, one with a 5% disease prevalence, another with 10% prevalence.\n\nWhat happens when the population is tested with an assay that has higher specificity of 99.8%?\n\nA highly specific test minimizes inaccurate results. With a higher disease prevalence, fewer people will experience incorrect results.\n\n![](https:\/\/static.healthcare.siemens.com\/siemens_hwem-hwem_ssxa_websites-context-root\/wcm\/idc\/groups\/public\/@global\/@lab\/documents\/image\/mda5\/odky\/~edisp\/citya_cityb-07401378\/~renditions\/citya_cityb-07401378~8.jpg)https:\/\/www.siemens-healthineers.com\/br\/laboratory-diagnostics\/assays-by-diseases-conditions\/infectious-disease-assays\/specificity-matters"}}