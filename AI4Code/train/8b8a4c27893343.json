{"cell_type":{"2ecf003b":"code","93ba835f":"code","a46a2987":"code","0a4dff14":"code","d864fb79":"code","c6f376b3":"code","5d63587f":"code","b8fccfb6":"code","665bb396":"code","e5701ff9":"code","955bab04":"code","2d4942ca":"code","3d764d67":"code","96952ee5":"code","8a9c85f9":"code","344d1c04":"markdown","6e063936":"markdown","0cf80552":"markdown","dc523779":"markdown","9534adbb":"markdown","c24f0ddb":"markdown"},"source":{"2ecf003b":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nimport time\nfrom torch.autograd import Variable\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Resize, Normalize, Compose)\nfrom albumentations.pytorch import ToTensor\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torch.nn.modules.loss import NLLLoss\nimport torch.utils.data as data\nimport torchvision.models as models\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.nn import functional as F\n\ntorch.backends.cudnn.enabled = False","93ba835f":"df = pd.read_csv(\"\/kaggle\/input\/severstal-steel-defect-detection\/train.csv\")\ndf.head()","a46a2987":"train_defect = df[df[\"EncodedPixels\"].notnull()]\n\nmaster_df = pd.DataFrame()\nmaster_df[\"Image_Class\"]=train_defect[\"ImageId_ClassId\"]\n\ndef image_id(row):\n    return row['Image_Class'].strip().split(\"_\")[0]\n\ndef class_id(row):\n    return row[\"Image_Class\"].strip().split(\"_\")[1]\n\nmaster_df[\"ImageId\"] = master_df.apply(image_id,axis=1)\nmaster_df[\"ClassId\"] = master_df.apply(class_id,axis=1)\nmaster_df = master_df.drop([\"Image_Class\"],axis=1)\nmaster_df = master_df.reset_index()\nmaster_df = master_df.drop([\"index\"] , axis=1)\nmaster_df.head()","0a4dff14":"# Split into train and test\nmsk = np.random.rand(len(master_df)) < 0.8\ntrain_df = master_df[msk]\ntrain_df = train_df.reset_index(drop=True)\nval_df = master_df[~msk]\nval_df = val_df.reset_index(drop=True)\nval_df.head()","d864fb79":"class Dataset_Classifier(Dataset):\n    def __init__(self, root, df):\n        mean = (0.485, 0.456, 0.406)\n        std = (0.229, 0.224, 0.225)\n        self.root = root\n        self.df = df\n        self.num_samples = len(self.df)\n        self.transform = Compose(\n            [\n            #Resize(224,224),\n             Normalize(mean = mean , std = std, p=1),\n            ToTensor(),\n            ])\n        \n    def __getitem__(self,idx):\n        fname = self.df[\"ImageId\"][idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        label = self.df[\"ClassId\"][idx]\n        return images, torch.from_numpy(np.array([int(label)-1],dtype=np.float32))\n    \n    def __len__(self):\n        return self.num_samples","c6f376b3":"# Creating Traindataset\ntrain_data_folder = \"\/kaggle\/input\/severstal-steel-defect-detection\/train_images\/\"\ntrain_dataset = Dataset_Classifier(train_data_folder,train_df)\n\n# Creating Validation Dataset\nval_dataset = Dataset_Classifier(train_data_folder,val_df)","5d63587f":"# Creating Train DataLoader\ntrain_dataloader = DataLoader(train_dataset,shuffle = False,batch_size = 128)\n\n# Creating Test DataLoader\nval_dataloader = DataLoader(val_dataset,shuffle = False,batch_size = 32)","b8fccfb6":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n    \n\n# Visualize our dataloader works fine\nexample = next(iter(train_dataloader))\n\nout = torchvision.utils.make_grid(example[0])\nprint(example[1])\nimshow(out)","665bb396":"BatchNorm2d = nn.BatchNorm2d\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channel, channel, out_channel, stride=1, is_shortcut=False):\n        super(BasicBlock, self).__init__()\n        self.is_shortcut = is_shortcut\n\n        self.conv_bn1 = ConvBn2d(in_channel,    channel, kernel_size=3, padding=1, stride=stride)\n        self.conv_bn2 = ConvBn2d(   channel,out_channel, kernel_size=3, padding=1, stride=1)\n\n        if is_shortcut:\n            self.shortcut = ConvBn2d(in_channel, out_channel, kernel_size=1, padding=0, stride=stride)\n\n\n    def forward(self, x):\n        z = F.relu(self.conv_bn1(x),inplace=True)\n        z = self.conv_bn2(z)\n\n        if self.is_shortcut:\n            x = self.shortcut(x)\n\n        z += x\n        z = F.relu(z,inplace=True)\n        return z\n\n\nclass ConvBn2d(nn.Module):\n\n    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1, stride=1):\n        super(ConvBn2d, self).__init__()\n        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, padding=padding, stride=stride, bias=False)\n        self.bn   = nn.BatchNorm2d(out_channel, eps=1e-5)\n\n    def forward(self,x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return x\n\n\nclass ResNet34(nn.Module):\n\n    def __init__(self, num_class=1000 ):\n        super(ResNet34, self).__init__()\n\n\n        self.block0  = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, padding=3, stride=2, bias=False),\n            BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n        self.block1  = nn.Sequential(\n             nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n             BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,),\n          * [BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,) for i in range(1,3)],\n        )\n        self.block2  = nn.Sequential(\n             BasicBlock( 64,128,128, stride=2, is_shortcut=True, ),\n          * [BasicBlock(128,128,128, stride=1, is_shortcut=False,) for i in range(1,4)],\n        )\n        self.block3  = nn.Sequential(\n             BasicBlock(128,256,256, stride=2, is_shortcut=True, ),\n          * [BasicBlock(256,256,256, stride=1, is_shortcut=False,) for i in range(1,6)],\n        )\n        self.block4 = nn.Sequential(\n             BasicBlock(256,512,512, stride=2, is_shortcut=True, ),\n          * [BasicBlock(512,512,512, stride=1, is_shortcut=False,) for i in range(1,3)],\n        )\n        self.logit = nn.Linear(512,num_class)\n\n\n\n    def forward(self, x):\n        batch_size = len(x)\n\n        x = self.block0(x)\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        logit = self.logit(x)\n        return logit","e5701ff9":"class Resnet34_classification(nn.Module):\n    def __init__(self,num_class=4):\n        # Abstracting the Resnet 34 Class \n        super(Resnet34_classification, self).__init__()\n        e = ResNet34()\n        # Defining the blocks we want from Resnet\n        self.block = nn.ModuleList([\n            e.block0,\n            e.block1,\n            e.block2,\n            e.block3,\n            e.block4,\n        ])\n        # After defining the blocks we are dropping the parent Resnet\n        e = None  #dropped\n        \n        # Extracting the features\n        self.feature_1 = nn.Conv2d(512,32, kernel_size=1) #dummy conv for dim reduction\n        # Getting the logits\n        self.feature_2 = nn.Linear(32,num_class)\n        self.logit = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        batch_size,C,H,W = x.shape\n\n        for i in range( len(self.block)):\n            x = self.block[i](x)\n            #print(i, x.shape)\n\n        x = F.dropout(x,0.5,training=self.training)\n        x = F.adaptive_avg_pool2d(x, 1)\n        x = self.feature_1(x)\n        x = x.view(-1,32)\n        x = self.feature_2(x)\n        logit = self.logit(x)\n        return logit","955bab04":"# Use GPU\nuse_gpu = torch.cuda.is_available()\n\n# Declare the Network\nmodel = Resnet34_classification()\n\n# model = models.resnet18(pretrained=True)\n# num_ftrs = model.fc.in_features\n# model.fc = nn.Linear(num_ftrs, 4)\n\nif use_gpu:\n    model = model.cuda()\n\n# Declare Loss Function\ncriterion = nn.CrossEntropyLoss()\n\n# Declare Optimizer \noptimizer = optim.Adam(model.parameters(),  lr=0.0001)\n\n# Scheduler \nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","2d4942ca":"# Training Function \ndef train(model,criterion, optimizer, scheduler, dataloader, use_gpu, num_epochs=20):\n    print(\"Training Initiated\")\n    since = time.time()\n    steps = 0\n    model.train(True)\n    #scheduler.step()\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        \n        running_loss = 0.0\n        \n        for data in dataloader:\n            \n            steps += 1\n            inputs, labels = data\n            if use_gpu:\n                \n                inputs = inputs.cuda()\n                labels = labels.cuda()\n                \n            optimizer.zero_grad()\n            #m = nn.LogSoftmax(dim=1)\n            outputs = model.forward(inputs)\n#             outputs = m(outputs)\n#             outputs = outputs.squeeze()\n            labels = labels.squeeze()\n#             print(m(outputs).type())\n            labels = labels.long()\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            if steps % 10 == 0:\n                model.eval()\n                validation_loss = 0\n                accuracy = 0\n                for i,(inputs,labels) in enumerate(val_dataloader):\n                    optimizer.zero_grad()\n                    inputs, labels = inputs.to('cuda') , labels.to('cuda')\n                    with torch.no_grad():\n                        outputs = model.forward(inputs)\n                        labels = labels.squeeze()\n                        labels = labels.long()\n                        validation_loss = criterion(outputs,labels)\n                        ps = torch.exp(outputs).data\n                        equality = (labels.data == ps.max(1)[1])\n                        accuracy += equality.type_as(torch.FloatTensor()).mean()\n                val_loss = validation_loss \/ len(val_dataloader)\n                train_ac = accuracy \/len(val_dataloader)\n                \n                print(\"Epoch: {}\/{}... | \".format(epoch+1, num_epochs),\n                      \"Loss: {:.4f} | \".format(running_loss\/10),\n                      \"Validation Loss {:.4f} | \".format(val_loss),\n                      \"Accuracy {:.4f}\".format(train_ac))\n                \n                if train_ac > best_acc :\n                    best_acc = train_ac\n                    print(\"------------Saving Best Model-----------\")\n                    torch.save(model.state_dict(),\"models_best.pth\")\n\n                running_loss = 0\n\n","3d764d67":"try:\n    train(model, criterion, optimizer, exp_lr_scheduler, train_dataloader, use_gpu,\n                       num_epochs=50)\nexcept:\n    torch.save(model.state_dict(),\"model_error.pth\")","96952ee5":"# saving the model\ntorch.save(model.state_dict(),\"model_last.pth\")","8a9c85f9":"# Loading and check the model\nmodel = Resnet34_classification()\nmodel.load_state_dict(torch.load(\"model_last.pth\"))\nmodel.eval()","344d1c04":"After training your classifier , we have to train the segmenatation module . You can find the notebook https:\/\/www.kaggle.com\/robinreni\/pytorch-segnet-deeplabv3-training","6e063936":"This kernel helps you to train restnet34 model for steel dataset . Its giving 82% accuracy on validatation set . If you need to improve accuracy try your tweaks in the code . After training for inference you can refer this notebook : https:\/\/www.kaggle.com\/bibek777\/heng-s-model-inference-kernel. Happy Coding ! **Please UPVOTE if you find this kernel useful .**","0cf80552":"### Building the datapipeline","dc523779":"After trainin your classifier , we have to train the segmenatation module . You can find the notebook https:\/\/www.kaggle.com\/robinreni\/heng-s-pytorch-resnet34-classifier-training","9534adbb":"As Heng mentioned here, his latest experiments uses Classification + Segmentation pipeline, shown in the figure below:\n![image.png](attachment:image.png)","c24f0ddb":"Now we created the Resnet34 Block , now we define the blocks according to the way we want "}}