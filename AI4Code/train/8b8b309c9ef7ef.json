{"cell_type":{"92210c10":"code","ba6775c8":"code","ae21efd0":"code","9ed44ae5":"code","40d355f4":"code","cb8203a8":"code","59a12b75":"code","9e2988bd":"code","c374d34d":"code","12ade8a3":"code","3afaac08":"code","e41f2ad3":"code","ac2be055":"code","fbb85de4":"code","b8e08da7":"code","a0beb051":"code","26996a26":"code","b57e1721":"code","36403f90":"code","9fc7bfa1":"markdown","bce8d3e3":"markdown","d883d977":"markdown","f902f9ce":"markdown","0b154077":"markdown","57b0ed26":"markdown","475aee27":"markdown","ae325c5b":"markdown"},"source":{"92210c10":"#import all the packages...\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport tensorflow_probability as tfp\nimport tensorflow as tf\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom dateutil import relativedelta\nimport datetime","ba6775c8":"df = pd.read_excel('..\/input\/timeseries-data\/Data.xlsx')","ae21efd0":"df=df[['Date','Key','Volume','avg_T','precipitation']]","9ed44ae5":"df.columns","40d355f4":"df.Date = pd.to_datetime(df.Date,format='%d-%m-%Y')\n#Brand_list = df.Key.unique()\nBrand_list = ['B']","cb8203a8":"final = pd.DataFrame(columns=[\"Brand\",\"Forecast_values\",\"Actual_values\"])\n#iterate for all the brands...\nseed_value = 123\nfor brand_name in Brand_list:\n    print(brand_name)\n    \n    brand_df = df.loc[df.Key == brand_name]\n    brand_df.set_index('Date',inplace=True)\n    tmp = []\n\n    forecast = pd.DataFrame()\n    Actuals = pd.DataFrame()\n    p = pd.DataFrame()\n    k = pd.DataFrame()\n    #run for le cycle 3+9,4+8 etc....  \n    tf.random.set_seed(seed_value)\n    flag_option = True\n    flag_month_feb = 3\n    flag_month_july = 8\n    if len(brand_df)>12:\n        train_start = datetime.date(2019, 3, 1)\n        train_till = datetime.date(2019, 12, 1)\n        Actuals_end = datetime.date(2020, 2, 1)\n        train_date = train_start\n        while train_date < train_till:\n            model = None\n            test_date = train_date + relativedelta.relativedelta(months=1)\n            dependent_colume = 'Volume'\n            x = brand_df.drop(columns=[dependent_colume,'Key'])\n            y = brand_df[[dependent_colume]]\n            train_x = x[:train_date]\n            train_y = y[:train_date][[dependent_colume]]\n            test_x = x[test_date:]\n            test_y = y[test_date:][[dependent_colume]]\n            train_date = train_date + relativedelta.relativedelta(months=1)\n            try:\n                my_list = []\n                t = dict()\n                \n                                    \n                if ((flag_option == True) and (flag_month_july == test_date.month)) :\n                    print(\"july imputation\")\n                    train_y['2019-07-01':'2019-07-01'] = np.average(train_y.loc[((train_y.index.month == 7) & \n                                                                                 ((train_y.index.year>=2016) & (train_y.index.year<=2018)))])\n                    \n                if ((flag_option == True) and (flag_month_feb == test_date.month)) :\n                    print(\"feb imputation\")\n                    train_y['2020-02-01':'2020-02-01'] = np.average(train_y.loc[((train_y.index.month == 2) & \n                                                                                 ((train_y.index.year>=2017) & (train_y.index.year<=2019)))])  \n                \n                # extrating linear trend parameter from series \n                trend = tfp.sts.LocalLinearTrend(observed_time_series=np.array(train_y))\n                \n                # extrating seasonal parameter from series \n                seasonal = tfp.sts.Seasonal(num_seasons=12, observed_time_series=np.array(train_y))\n\n                my_list.append(trend)\n                my_list.append(seasonal)\n\n                    \n                \n                if test_date < Actuals_end:\n                    test_x = test_x[test_date:test_date]\n                for i in train_x.columns:\n                    t[str(i)] = tfp.sts.LinearRegression(design_matrix=tf.concat([tf.reshape(np.array(train_x[i].astype(float)),(-1,1)),\n                                                                        tf.reshape(np.array(test_x[i].astype(float)),(-1,1))],axis=-2),name=i)\n                    my_list.append(t[str(i)])\n                #creating strcutural model = ts + trend + seasonal\n                model = tfp.sts.Sum(my_list, observed_time_series=np.array(train_y))\n        #         #build surrogate model for getting optimal prior value...\n                variational_posteriors = tfp.sts.build_factored_surrogate_posterior(model=model,seed=seed_value)\n                num_variational_steps = 200\n                num_variational_steps = int(num_variational_steps)\n                optimizer = tf.optimizers.Adam(learning_rate=.1)\n\n\n        #         #generating different posterior samples...\n                q_samples_co2_ = variational_posteriors.sample(50,seed=seed_value)\n            \n                seed_value = seed_value + 1\n                print(\"Seed_value-----\",seed_value)\n                \n                if test_date > Actuals_end:\n                    print(test_date)\n                    p = pd.DataFrame()\n                    model_forecast_dist = tfp.sts.forecast(model,observed_time_series=np.array(train_y),parameter_samples=q_samples_co2_,num_steps_forecast=len(test_x))\n                    p[\"Forecast_values\"] =np.array(tfp.sts.forecast(model,observed_time_series=np.array(train_y),parameter_samples=q_samples_co2_,num_steps_forecast=len(test_x)).mean()).ravel()\n                    p.index = test_y[test_date:].index\n                    p[\"Brand\"] = str(brand_name) +str(\"_\")+ p.index.month.astype(str) +str(\"_\")+p.index.year.astype(str)\n            \n                    \n                    k = pd.DataFrame()\n                    k = test_y[test_date:]\n                    k.columns = ['Actual_values']\n                    k.index = test_y[test_date:].index\n                    k[\"Brand\"] = str(brand_name) +str(\"_\")+ k.index.month.astype(str) +str(\"_\")+k.index.year.astype(str)\n\n                    break\n                 \n                \n                co2_forecast_dist = tfp.sts.forecast(model,observed_time_series=np.array(train_y),parameter_samples=q_samples_co2_,num_steps_forecast=1)\n\n                forecast[str(brand_name)+str('_')+str(test_date.month)+str(\"_\")+str(test_date.year)] = np.array(co2_forecast_dist.mean())[0]\n                Actuals[str(brand_name)+str('_')+str(test_date.month)+str(\"_\")+str(test_date.year)] = test_y[:test_date].values[0]\n            except Exception as e:\n                print(e)\n                print(\"exception\")\n                continue\n\n        if ((len(forecast)>0) & (len(Actuals)>0)):\n            forecast=forecast.T.reset_index()\n            forecast.columns=[\"Brand\",\"Forecast_values\"]\n            if len(p)>0:\n                forecast= pd.concat([forecast,p],axis=0)\n            Actuals=Actuals.T.reset_index()\n            Actuals.columns=[\"Brand\",\"Actual_values\"]\n            if len(k)>0:\n                Actuals= pd.concat([Actuals,k],axis=0)\n            brand_wise_merge = forecast.merge(Actuals,on=\"Brand\",how=\"left\")\n            final = final.append(brand_wise_merge,ignore_index=True)\n        else:\n            print(\"doesn't match with TFP\")\n    else:\n        print(\"length mismatch\")","59a12b75":"final.head(30)","9e2988bd":"plt.figure(figsize=(15,8))\nplt.plot(['Apr','May','June','July','Aug','Sep','Oct','Nov','Dec'],\n         final.Actual_values,label='Actual value')\nplt.plot(['Apr','May','June','July','Aug','Sep','Oct','Nov','Dec'],\n         final.Forecast_values,label='Forecast Value')\nplt.legend()\nplt.show()","c374d34d":"final['Error']=np.abs(final['Actual_values']-final['Forecast_values'])\nfinal[['Brandname','leMonth','leYear']] = final.Brand.str.split(\"_\",expand=True)","12ade8a3":"Agg_accuracy = final.groupby(by=['leMonth','leYear']).sum()[['Error','Actual_values']]\nAgg_accuracy['Accuracy'] = np.round((1-(Agg_accuracy['Error']\/Agg_accuracy['Actual_values']))*100,2)","3afaac08":"Agg_accuracy_brand = final.groupby(by=['Brandname']).sum()[['Error','Actual_values']]\nAgg_accuracy_brand['Accuracy'] = np.round((1-(Agg_accuracy_brand['Error']\/Agg_accuracy_brand['Actual_values']))*100,2)","e41f2ad3":"Agg_accuracy_brand","ac2be055":"Agg_accuracy","fbb85de4":"def plot_components(dates,component_means_dict,component_stddevs_dict,x_locator=None,x_formatter=None):\n    \n    \"\"\"Plot the contributions of posterior components in a single figure.\"\"\"\n    colors = sns.color_palette()\n    c1, c2 = colors[0], colors[1]\n    axes_dict = collections.OrderedDict()\n    num_components = len(component_means_dict)\n    fig = plt.figure(figsize=(12, 2.5 * num_components))\n    for i, component_name in enumerate(component_means_dict.keys()):\n        \n        component_mean = component_means_dict[component_name]\n        component_stddev = component_stddevs_dict[component_name]\n\n        ax = fig.add_subplot(num_components,1,1+i)\n        ax.plot(dates, component_mean, lw=2)\n        ax.fill_between(dates,\n                         component_mean-2*component_stddev,\n                         component_mean+2*component_stddev,\n                         color=c2, alpha=0.5)\n        ax.set_title(component_name)\n        if x_locator is not None:\n            ax.xaxis.set_major_locator(x_locator)\n            ax.xaxis.set_major_formatter(x_formatter)\n        axes_dict[component_name] = ax\n    fig.autofmt_xdate()\n    fig.tight_layout()\n    return fig, axes_dict","b8e08da7":"# Get the distributions over component outputs from the posterior marginals on\n# training data, and from the forecast model.\ncomponent_dists = tfp.sts.decompose_by_component(\n    model,\n    observed_time_series=np.array(train_y),\n    parameter_samples=q_samples_co2_)\n\nforecast_component_dists = tfp.sts.decompose_forecast_by_component(\n    model,\n    forecast_dist=co2_forecast_dist,\n    parameter_samples=q_samples_co2_)","a0beb051":"demand_component_means_, demand_component_stddevs_ = (\n    {k.name: c.mean() for k, c in component_dists.items()},\n    {k.name: c.stddev() for k, c in component_dists.items()})\n\n(\n    demand_forecast_component_means_,\n    demand_forecast_component_stddevs_\n) = (\n    {k.name: c.mean() for k, c in forecast_component_dists.items()},\n    {k.name: c.stddev() for k, c in forecast_component_dists.items()}\n    )","26996a26":"demand_dates = pd.date_range('2014-01-01','2019-12-01', freq='MS')","b57e1721":"import collections\n# Concatenate the training data with forecasts for plotting.\ncomponent_with_forecast_means_ = collections.OrderedDict()\ncomponent_with_forecast_stddevs_ = collections.OrderedDict()\nfor k in demand_component_means_.keys():\n    component_with_forecast_means_[k] = np.concatenate([\n      demand_component_means_[k],\n      demand_forecast_component_means_[k]], axis=-1)\n    component_with_forecast_stddevs_[k] = np.concatenate([\n      demand_component_stddevs_[k],\n      demand_forecast_component_stddevs_[k]], axis=-1)\n\n#print(len(component_with_forecast_means_['LocalLinearTrend\/']))\n    \nfig, axes = plot_components(\n  demand_dates,\n  component_with_forecast_means_,\n  component_with_forecast_stddevs_,\n  x_locator=None, x_formatter=None)\nfor ax in axes.values():\n    ax.axvline(demand_dates[-10], linestyle=\"--\", color='red')","36403f90":"final.to_excel('TFP_Sts_ouput.xlsx')","9fc7bfa1":"Import all the requires packages. we are using statsmodel 0.10.0 latest stable version.need to be cautious while using date time.","bce8d3e3":"# TFP","d883d977":"For modelling we follow differnt steps:\n1. iterate over all brands and take out single brand each time.\n2. provide train and test date based on requirement.\n3. divide train and test data as le cycle works for whole year. ex apr is start so (3+9,4+8 etc..) each time upto december we have to complete, start date could be any.\n4. extract the linear trends from the timeseries.\n5. extract seasonal pattern from timeseries.\n6. if any external drivers then add up using linear regression method in design metric.\n7. append up in the list and use sum function of sts.\n8. Build surrogate posterior model for the given model to get the optimum value. optimum values it selects from the given samples relatively. ex. if user has provided 50 samples then model will iterate 50 times in surrogate model where it will compare optimal value and at end whichever is more correct it will use it.\n9. try optimizing using adam optimizer. we can have differnt optimizer as well like rmsprop etc.\n10. forecast for required no of steps ( basically ahead month or year based on freuqency).\n11. save the result and iterate till end.\n","f902f9ce":"Calculate the accuracy which is mape (1- ABS(actual-forcast)\/actual). we use mape as it is unit less and later can multiply with 100 so we can get results in percentage.","0b154077":"Above graphs shows the strcutural component of Timeseries and how each contributed to the forecast","57b0ed26":"load data from excel file. we can add up workbook sheet as well in which we can import multiple sheets but here as single sheet is required hence directly read_excel works fine.","475aee27":"Tensorflow probability model is a structural timeseries model. In this model it basically decomposes time series in various structural component. it try to learn seasonality, trends and past lags estimate. we can add additional external driver as well through design metrics.","ae325c5b":"Convert date column in datetime format as we have to create index as datetime format only. be careful while giving format of date as it might change later operations.\nget the unique brand list as we have to iterate over all the brands separately."}}