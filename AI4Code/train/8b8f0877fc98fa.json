{"cell_type":{"043b42d0":"code","223f614f":"code","678d8a52":"code","acb8a1b5":"code","36be74bd":"code","6d301022":"code","9d7fb50f":"code","dad43c91":"code","1d047c3b":"markdown","c85e39c5":"markdown","dae311de":"markdown","caf1fe13":"markdown","f7decf86":"markdown","ee97ab32":"markdown","1fb14998":"markdown"},"source":{"043b42d0":"import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nfrom pathlib import Path\nimport glob\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\n\nimport psutil\nimport random\nimport os\nimport time\nimport sys\nimport math\nfrom contextlib import contextmanager","223f614f":"N_SPLITS = 20\nSEED = 1234","678d8a52":"LOG_PATH = Path(\".\/log\/\")\nLOG_PATH.mkdir(parents=True, exist_ok=True)","acb8a1b5":"@contextmanager\ndef timer(name: str):\n    t0 = time.time()\n    p = psutil.Process(os.getpid())\n    m0 = p.memory_info()[0] \/ 2. ** 30\n    try:\n        yield\n    finally:\n        m1 = p.memory_info()[0] \/ 2. ** 30\n        delta = m1 - m0\n        sign = '+' if delta >= 0 else '-'\n        delta = math.fabs(delta)\n        print(f\"[{m1:.1f}GB({sign}{delta:.1f}GB): {time.time() - t0:.3f}sec] {name}\", file=sys.stderr)\n\n\ndef set_seed(seed=1234):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n\n    \ndef comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()\/xhat.shape[0]\n\n\ndef score_log(df: pd.DataFrame, num_files: int, nam_file: str, data_shape: tuple, n_fold: int, seed: int, mpe: float):\n    score_dict = {'n_files': num_files, 'file_name': nam_file, 'shape': data_shape, 'fold': n_fold, 'seed': seed, 'score': mpe}\n    # noinspection PyTypeChecker\n    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n    df.to_csv(LOG_PATH \/ f\"log_score.csv\", index=False)\n    return df\n","36be74bd":"set_seed(SEED)\nfeature_dir = \"..\/input\/indoor-navigation-and-location-wifi-features\"\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nsubm = pd.read_csv('..\/input\/indoor-location-navigation\/sample_submission.csv', index_col=0)","6d301022":"lgb_params = {'objective': 'root_mean_squared_error',\n              'boosting_type': 'gbdt',\n              'n_estimators': 50000,\n              'learning_rate': 0.1,\n              'num_leaves': 90,\n              'colsample_bytree': 0.4,\n              'subsample': 0.6,\n              'subsample_freq': 2,\n              'bagging_seed': SEED,\n              'reg_alpha': 8,\n              'reg_lambda': 2,\n              'random_state': SEED,\n              'n_jobs': -1\n              }\n\nlgb_f_params = {'objective': 'multiclass',\n                'boosting_type': 'gbdt',\n                'n_estimators': 50000,\n                'learning_rate': 0.1,\n                'num_leaves': 90,\n                'colsample_bytree': 0.4,\n                'subsample': 0.6,\n                'subsample_freq': 2,\n                'bagging_seed': SEED,\n                'reg_alpha': 10,\n                'reg_lambda': 2,\n                'random_state': SEED,\n                'n_jobs': -1\n                }","9d7fb50f":"score_df = pd.DataFrame()\noof = list()\npredictions = list()\nfor n_files, file in enumerate(train_files):\n    data = pd.read_csv(file, index_col=0)\n    test_data = pd.read_csv(test_files[n_files], index_col=0)\n\n    oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n    preds_x, preds_y = 0, 0\n    preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n\n    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n    for fold, (trn_idx, val_idx) in enumerate(kf.split(data.iloc[:, :-4])):\n        X_train = data.iloc[trn_idx, :-4]\n        y_trainx = data.iloc[trn_idx, -4]\n        y_trainy = data.iloc[trn_idx, -3]\n        y_trainf = data.iloc[trn_idx, -2]\n\n        X_valid = data.iloc[val_idx, :-4]\n        y_validx = data.iloc[val_idx, -4]\n        y_validy = data.iloc[val_idx, -3]\n        y_validf = data.iloc[val_idx, -2]\n\n        modelx = lgb.LGBMRegressor(**lgb_params)\n        with timer(\"fit X\"):\n            modelx.fit(X_train, y_trainx,\n                       eval_set=[(X_valid, y_validx)],\n                       eval_metric='rmse',\n                       verbose=True,\n                       early_stopping_rounds=5\n                       )\n\n        modely = lgb.LGBMRegressor(**lgb_params)\n        with timer(\"fit Y\"):\n            modely.fit(X_train, y_trainy,\n                       eval_set=[(X_valid, y_validy)],\n                       eval_metric='rmse',\n                       verbose=True,\n                       early_stopping_rounds=5\n                       )\n        modelf = lgb.LGBMClassifier(**lgb_f_params)\n        with timer(\"fit F\"):\n            modelf.fit(X_train, y_trainf,\n                       eval_set=[(X_valid, y_validf)],\n                       eval_metric='multi_logloss',\n                       verbose=True,\n                       early_stopping_rounds=5\n                       )\n\n        oof_x[val_idx] = modelx.predict(X_valid)\n        oof_y[val_idx] = modely.predict(X_valid)\n        oof_f[val_idx] = modelf.predict(X_valid).astype(int)\n\n        preds_x += modelx.predict(test_data.iloc[:, :-1]) \/ N_SPLITS\n        preds_y += modely.predict(test_data.iloc[:, :-1]) \/ N_SPLITS\n        preds_f_arr[:, fold] = modelf.predict(test_data.iloc[:, :-1]).astype(int)\n\n        score = comp_metric(oof_x[val_idx], oof_y[val_idx], oof_f[val_idx],\n                            y_validx.to_numpy(), y_validy.to_numpy(), y_validf.to_numpy())\n        print(f\"fold {fold}: mean position error {score}\")\n        score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, fold, SEED, score)\n\n    print(\"*+\"*40)\n    print(f\"file #{n_files}, shape={data.shape}, name={os.path.basename(file)}\")\n    score = comp_metric(oof_x, oof_y, oof_f,\n                        data.iloc[:, -4].to_numpy(), data.iloc[:, -3].to_numpy(), data.iloc[:, -2].to_numpy())\n    oof.append(score)\n    print(f\"mean position error {score}\")\n    print(\"*+\"*40)\n    score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, 999, SEED, score)\n\n    preds_f_mode = stats.mode(preds_f_arr, axis=1)\n    preds_f = preds_f_mode[0].astype(int).reshape(-1)\n    test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n    test_preds.columns = subm.columns\n    test_preds.index = test_data[\"site_path_timestamp\"]\n    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n    predictions.append(test_preds)","dad43c91":"all_preds = pd.concat(predictions)\nall_preds = all_preds.reindex(subm.index)\nall_preds.to_csv('submission.csv')\nall_preds.head(20)","1d047c3b":"## Using LightGBM regressor ","c85e39c5":"Splitting the data into train and validation and passed them through LGBm and then ssaving the predicitions into pred","dae311de":"Create some tuned paratmeters for the LGB ( These will be tweaked to get the best performance)","caf1fe13":"Get all the data in our nb env","f7decf86":"Save the predictions into the same format as required ","ee97ab32":"Get file path from kaggle ","1fb14998":"Some utility code\n\n1. A timer\n2. A seed setter\n3. A intermediate metric finder\n4. A score logger"}}