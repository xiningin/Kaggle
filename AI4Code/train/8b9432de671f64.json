{"cell_type":{"c279c4fe":"code","4e476a3c":"code","167eef81":"code","e9cb1faa":"code","9cac9d33":"code","67df6815":"markdown","4a7407b9":"markdown","002380f7":"markdown","568ce494":"markdown"},"source":{"c279c4fe":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score, confusion_matrix, classification_report\n\n\ndf = pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndf.head()","4e476a3c":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeRegressor\n\nDT_bmi_pipe = Pipeline( steps=[ \n                               ('scale',StandardScaler()),\n                               ('lr',DecisionTreeRegressor(random_state=42))\n                              ])\nX = df[['age','gender','bmi']].copy()\nX.gender = X.gender.replace({'Male':0,'Female':1,'Other':-1}).astype(np.uint8)\n\nMissing = X[X.bmi.isna()]\nX = X[~X.bmi.isna()]\nY = X.pop('bmi')\nDT_bmi_pipe.fit(X,Y)\npredicted_bmi = pd.Series(DT_bmi_pipe.predict(Missing[['age','gender']]),index=Missing.index)\ndf.loc[Missing.index,'bmi'] = predicted_bmi","167eef81":"df['gender'] = df['gender'].replace({'Male':0,'Female':1,'Other':-1}).astype(np.uint8)\ndf['Residence_type'] = df['Residence_type'].replace({'Rural':0,'Urban':1}).astype(np.uint8)\ndf['work_type'] = df['work_type'].replace({'Private':0,'Self-employed':1,'Govt_job':2,'children':-1,'Never_worked':-2}).astype(np.uint8)\ndf['ever_married'] = df['ever_married'].replace({'No':0,'Yes':1}).astype(np.uint8)\ndf['smoking_status'] = df['smoking_status'].replace({'never smoked':0,'formerly smoked':1, 'smokes':2, 'Unknown':99}).astype(np.uint8)\ndf.head()","e9cb1faa":"from sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE, BorderlineSMOTE\n\nhighly_corr_features =  ['gender','age','hypertension','heart_disease','ever_married', 'work_type','avg_glucose_level','bmi']\nX = df[highly_corr_features]\ny = df['stroke']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n\n#SMOTE\nX_train_resh, y_train_resh = SMOTE(random_state=42).fit_resample(X_train, y_train.ravel())\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_resh==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_resh==0)))","9cac9d33":"from xgboost.sklearn import XGBClassifier \n\n#XGBoot\nclf = XGBClassifier(n_estimators=800, \n                    learning_rate= 0.3, \n                    max_depth=3, \n                    min_child_weight=3, \n                    gamma=0.4, \n                    subsample=0.7, \n                    colsample_bytree=0.8,\n                    scale_pos_weight=1, \n                    seed=65,\n                    use_label_encoder=False)\nclf.fit(X_train_resh,y_train_resh,eval_metric='auc') \ny_pred = clf.predict(X_test)\n\nprint(\"Accuracy: %.4g\" % accuracy_score(y_test, y_pred))\nprint(\"F1-Score: %.4g \\n\" % f1_score(y_test, y_pred))\nprint(\"Confusion matrix: \\n {}\".format(confusion_matrix(y_test, y_pred)))\nprint(\"\\n {}\".format(classification_report(y_test, y_pred)))","67df6815":"# Missing data","4a7407b9":"# Encoding categorical values","002380f7":"# Sampling","568ce494":"# XGBoost"}}