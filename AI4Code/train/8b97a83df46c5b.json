{"cell_type":{"1ae5aa1b":"code","c87ef452":"code","e6d200e9":"code","99be44b3":"code","460c7596":"code","230c68f5":"code","15bc3d6a":"code","2f90781a":"code","e5e82ad1":"code","c9451601":"code","b6db43b0":"code","553c5aa8":"code","039039ff":"markdown","3cbcd8a8":"markdown","ecb52602":"markdown","a19a9afd":"markdown","02cb2676":"markdown","d2638454":"markdown","6144e450":"markdown","1809056e":"markdown","32c87e69":"markdown","caaec44d":"markdown"},"source":{"1ae5aa1b":"from sklearn.preprocessing import LabelEncoder\nfrom functools import partial\nfrom sklearn import ensemble\nfrom sklearn import model_selection\nfrom hyperopt import hp, fmin, atpe, Trials\nfrom hyperopt.pyll.base import scope\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as ptl\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","c87ef452":"train= pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest=pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\ntrain.head()","e6d200e9":"train.shape","99be44b3":"train['kfold']= -1\ntrain = train.sample(frac=1).reset_index(drop=True)\ntrain.loc[:, \"bins\"] = pd.cut(\n train[\"loss\"], bins=19, labels=False\n )\nkf = model_selection.StratifiedKFold(n_splits=15)\nfor f, (t_, v_) in enumerate(kf.split(X=train, y=train.bins.values)):\n    train.loc[v_, 'kfold'] = f\ntrain = train.drop(\"bins\", axis=1)","460c7596":"X=train.iloc[:,1:].copy()\nX.drop('loss',axis=1,inplace=True)","230c68f5":"target =['loss', 'kfold']\nX=X\ny=train[target]","15bc3d6a":"def optimize(params,x,y):\n    model= XGBRegressor(n_jobs=2,nthread=2,random_state=0,**params)\n    RMSE = []\n    for i in range(1,3):\n        X_t=x[x.kfold != i]\n        X_train=X_t.iloc[:,:-1]\n        y_t=y[y.kfold !=i]\n        y_train=y_t.iloc[:,0].values\n        X_te=x[x.kfold == i]\n        X_test=X_te.iloc[:,:-1]\n        y_te=y[y.kfold==i]\n        y_test=y_te.iloc[:,0].values\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n        fold_ras = mean_squared_error(y_test, preds, squared=False)\n        RMSE.append(fold_ras)\n    print(RMSE)\n    return (np.mean(RMSE))","2f90781a":"param_space = {\n \"learning_rate\": hp.uniform(\"learning_rate\", 0.008, 0.06),\n \"max_depth\": scope.int(hp.quniform(\"max_depth\",10 , 15, 1)),\n \"n_estimators\": scope.int(hp.quniform(\"n_estimators\", 1350, 1750, 1)),\n    \n \"tree_method\": hp.choice(\"tree_method\", [\"gpu_hist\"]),\n \"booster\": hp.choice(\"booster\", [\"gbtree\"]),\n \"objective\": hp.choice(\"objective\", [\"reg:squarederror\"]),\n \"eval_metric\": hp.choice(\"eval_metric\", [\"rmse\"]),\n \"predictor\": hp.choice(\"predictor\", [\"gpu_predictor\"]),\n \"gpu_id\": hp.choice(\"gpu_id\", [0]),\n \n # uniform chooses a value between two values \n \"subsample\": hp.uniform(\"subsample\", 0.7, 0.98),\n    \"min_child_weight\": hp.uniform(\"min_child_weight\",15, 70),\n    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.75, 0.96),\n    \"reg_alpha\": hp.uniform(\"reg_alpha\", 140, 200),\n    \"reg_lambda\": hp.uniform(\"reg_lambda\", 150, 200),\n    \"gamma\": hp.uniform(\"gamma\", 60, 90),\n    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0.01, 3),\n    \"colsample_bylevel\": hp.uniform(\"colsample_bylevel\", 0.7, 0.96),\n    \"colsample_bynode\": hp.uniform(\"colsample_bynode\", 0.6, 0.96)\n }\noptimization_function = partial(\n optimize,\n #param_names=param_names, \nx=X, y=y\n )   \ntrials = Trials() \nhopt = fmin( \n fn=optimization_function,\n space=param_space,\n algo=atpe.suggest, \n max_evals=15,\n trials=trials\n )\nprint(hopt)","e5e82ad1":"para1={'booster': 0, 'colsample_bylevel': 0.9377629603546923, 'colsample_bynode': 0.6203129196844466, 'colsample_bytree': 0.8662523590957234, 'eval_metric': 0, 'gamma': 2.56784868937463, 'gpu_id': 0, 'learning_rate': 0.020372546225192883, 'max_delta_step': 8.174023744945664, 'max_depth': 10.0, 'min_child_weight': 342.4606309007503, 'n_estimators': 909.0, 'predictor': 0, 'reg_alpha': 4.337902688500327, 'reg_lambda': 6.925018305951919, 'subsample': 0.855931381854741, 'tree_method': 0}\npara2={'booster': 0, 'colsample_bylevel': 0.7055480507601603, 'colsample_bynode': 0.7861994124766559, 'colsample_bytree': 0.8711839613327488, 'eval_metric': 0, 'gamma': 3.4191878868002514, 'gpu_id': 0, 'learning_rate': 0.011352981411403947, 'max_delta_step': 9.419376785482035, 'max_depth': 12.0, 'min_child_weight': 339.00894929804645, 'n_estimators': 1773.0, 'predictor': 0, 'reg_alpha': 4.788928093561186, 'reg_lambda': 2.811859534488748, 'subsample': 0.8972123878494193, 'tree_method': 0}\npara={'booster': 0, 'colsample_bylevel': 0.7329518979370699, 'colsample_bynode': 0.8508650522327323, 'colsample_bytree': 0.7598384658099369, 'eval_metric': 0, 'gamma': 73.24552392852276, 'gpu_id': 0, 'learning_rate': 0.020917931572846417, 'max_delta_step': 2.6071993050270432, 'max_depth': 10.0, 'min_child_weight': 52.37481170728059, 'n_estimators': 1718.0, 'objective': 0, 'predictor': 0, 'reg_alpha': 166.15539016968125, 'reg_lambda': 181.6854279589871, 'subsample': 0.869912010017318, 'tree_method': 0}\npara_base={'booster': 0, 'colsample_bylevel': 0.8085333759685713, 'colsample_bynode': 0.8758340404751047, 'colsample_bytree': 0.7996066384650472, 'eval_metric': 0, 'gamma': 2.756119257892028, 'gpu_id': 0, 'learning_rate': 0.01338781357269889, 'max_delta_step': 6.099261739333243, 'max_depth': 9.0, 'min_child_weight': 358.6918370093609, 'n_estimators': 1130.0, 'objective': 0, 'predictor': 0, 'reg_alpha': 2.7998966086509953, 'reg_lambda': 3.598574311888844, 'subsample': 0.968651042334799, 'tree_method': 0}","c9451601":"model=XGBRegressor(n_jobs=4,nthread=4,random_state=0,booster='gbtree', colsample_bylevel= para['colsample_bylevel'], colsample_bynode= para['colsample_bynode'], colsample_bytree= para['colsample_bytree'], gamma= para['gamma'],eval_metric= \"rmse\",gpu_id=0, learning_rate=para['learning_rate'],max_delta_step=para['max_delta_step'], max_depth=10, min_child_weight=para['min_child_weight'], n_estimators=1718,predictor='gpu_predictor', reg_alpha=para['reg_alpha'],reg_lambda=para['reg_lambda'], subsample=para['subsample'], tree_method='gpu_hist')","b6db43b0":"X_t=X\nX_train=X_t.iloc[:,:-1]\ny_t=y\ny_train=y_t.iloc[:,0].values\nmodel.fit(X_train, y_train)","553c5aa8":"test1=test.iloc[:,1:]\npreds= model.predict(test1)\nsubmi= pd.DataFrame({'id':test['id'],'loss':preds})\nsubmi.to_csv('submission1.csv',index=False)","039039ff":"<a id=\"1\"><\/a>\n<h2 style='background:skyblue; border:0; color:white'><center>Training and submission<center><h2>","3cbcd8a8":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/25225\/logos\/header.png)","ecb52602":"<a id=\"1\"><\/a>\n<h2 style='background:skyblue; border:0; color:white'><center>Files and cross validation setup<center><h2>","a19a9afd":"**In versions less than 4 I have used TPE (Tree of Parzen Estimator) algorithm which is designed to optimize quantization hyperparameters to find quantization configuration that achieve an expected accuracy target and provide best possible latency improvement.**\n**Adaptive TPE is recently added, adaptive TPE was invented at ElectricBrain and it is actually a series of (not so) little improvements that they experimented with on top of TPE.**\n","02cb2676":"# Tabular Playground AUG 2021 with GPU","d2638454":"<a id=\"1\"><\/a>\n<h2 style='background:skyblue; border:0; color:white'><center>HyperParameter Optimization<center><h2>","6144e450":"<a id=\"1\"><\/a>\n<h2 style='background:skyblue; border:0; color:white'><center>Imports<center><h2>","1809056e":"### Now create a dictionary named as para and manually put max_depth and n_estimator parameter and you are good to go.","32c87e69":"### Please upvote if you like my notebook. Do comment If you have any queries.","caaec44d":"**Ideally Its a Classificaion problem but as the metrics that is being used is RMSE so I used Regression model.**"}}