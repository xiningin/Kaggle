{"cell_type":{"acd217bb":"code","199e997e":"code","4b8da1f6":"code","49e8ef5d":"code","cf7ed587":"code","46488077":"code","2124074b":"code","18b3add6":"code","8958c460":"code","006adf31":"code","a8a37b08":"code","6bd122c6":"code","fa4b0def":"code","dfeedf89":"code","746d3d31":"code","c1774b73":"code","249d29ad":"code","73687d70":"code","90f5153f":"code","97028812":"code","0c2f7e2a":"code","c31a4cd9":"code","3adb78e0":"code","1c6c9ca0":"code","0a9c0276":"code","aefd3a34":"code","14d24142":"code","7f51ed0e":"code","d8a2cbc6":"code","54451fc2":"code","c3d08f98":"code","b13f3540":"code","91d57770":"code","c6f5a97e":"code","7604396e":"code","ab2fbbd6":"code","07c81b51":"code","5b4ec086":"code","902b55e3":"code","240a2a66":"code","27f9bda6":"markdown","819b8ff3":"markdown","f3830a67":"markdown","68eb1204":"markdown","1fa2dd49":"markdown","4a7b06b0":"markdown","8321b67a":"markdown","a800d47f":"markdown","ff0c5b24":"markdown","cc8ad1d5":"markdown","56cde0ff":"markdown","ea5e2f70":"markdown","79bbf44f":"markdown","c364dee4":"markdown","a33e90af":"markdown","cc893155":"markdown","fd68802d":"markdown","1beb0627":"markdown"},"source":{"acd217bb":"import warnings\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","199e997e":"# Files\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4b8da1f6":"training_set = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_set = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","49e8ef5d":"sns.set(style=\"whitegrid\")\npd.options.display.max_rows = 100\npd.options.display.max_columns = 100\nwarnings.filterwarnings('ignore')","cf7ed587":"print(training_set.shape)\ndisplay(training_set.head())","46488077":"print(test_set.shape)\ndisplay(test_set.head())","2124074b":"def cat_analysis(df, feature, x, y, figsize=(8,5), rotation=\"45\", palette=None, order=None):\n    \n    data = (pd.DataFrame(df[feature].value_counts())\n                .reset_index()\n                .rename(columns={'index': x, feature: y}))\n    \n    fig, ax = plt.subplots(figsize=figsize)\n    ax = sns.barplot(x=x, y=y, data=data, palette=palette, order=order);\n    plt.xticks(rotation=rotation)\n    plt.title(f\"Distribution of {feature}\")\n    plt.show()\n    \ndef dummify(data, feature):\n    \n    # Get dummy variables\n    temp_df = pd.get_dummies(data[feature])\n    \n    # Add prefix to prevent duplicated feature names\n    temp_df = temp_df.add_prefix(feature + \"_\")\n    \n    # Concatenante the new features with the main dataframe\n    data = pd.concat([data, temp_df], axis=1)\n    \n    # Drop the original feature\n    data.drop(feature, axis=1, inplace=True)\n    \n    # Return the new dataframe\n    return data\n\ndef prepare_data(data_original):\n    \n    data = data_original.copy()\n    \n    ################ Name => Boy \/ surname ######################\n    # From the name, extract \"is a boy?\" and \"surname\"\n    data[\"boy\"] = data[\"Name\"].apply(lambda x: 1 if (\"Master.\" in x.split(\" \")[1:-1]) else 0)\n    data[\"surname\"] = data[\"Name\"].apply(lambda x: x.split(\",\")[0])\n    data.drop(\"Name\", axis=1, inplace=True)\n    \n    # Sex\n    data = dummify(data, \"Sex\")\n    # Since \"Sex\" it's a binary variable, we don't need to keep a feature for male AND for female\n    data.drop(\"Sex_male\", axis=1, inplace=True) # Just one is enough\n \n    ############### Family Size ################\n    data[\"family_size\"] = 1 + data[\"SibSp\"] + data[\"Parch\"]\n    data.drop([\"SibSp\", \"Parch\"], axis=1, inplace=True)\n    \n    ################## Dropping other features ##########################\n    data.drop(\"Ticket\", axis=1, inplace=True)\n    data.drop(\"Cabin\", axis=1, inplace=True)\n    data.drop(\"Embarked\", axis=1, inplace=True)\n    data.drop(\"PassengerId\", axis=1, inplace=True)\n    data.drop(\"Fare\", axis=1, inplace=True)\n    data.drop(\"Age\", axis=1, inplace=True)\n    data.drop(\"Pclass\", axis=1, inplace=True)\n    \n    ############# Woman Child Group ############\n    \n    # Copy family name to create a \"woman child group\" based on the surname\n    data[\"wcg_surname\"] = data[\"surname\"].copy()\n\n    # Remove men from groups\n    mask = (data[\"Sex_female\"] == 0) & (data[\"boy\"] == 0)\n    data.loc[mask, \"wcg_surname\"] = \"no_group\"\n    \n    data.drop(\"surname\", axis=1, inplace=True)\n    \n    return data","18b3add6":"fig, ax = plt.subplots(figsize=(15,5))\nax = sns.barplot(x=\"Sex\", y=\"Survived\", data=training_set);\nplt.xticks(rotation=0)\nplt.title(\"Percentage of survived by gender\")\nplt.show()","8958c460":"def name_title(title):\n    \"\"\" For each passenger, the function parses the name, from the second word to the second-last one.\n    The title is still among those positions.\n    According to the value, the function assigns a group.\n    \n    \"\"\"\n    \n    for word in title.split(\" \")[1:-1]:\n        if (word in [\"Mme.\", \"Ms.\", \"Mrs.\"]):\n            return \"woman\"\n\n        elif (word in [\"Mr.\"]):\n            return \"man\"\n\n        elif (word in [\"Master.\"]):\n            return \"boy\"\n\n        elif (word in [\"Miss.\", \"Mlle.\"]):\n            return \"miss\"\n\n        elif (word in [\"Capt.\", \"Col.\", \"Major.\", \"Rev.\", \"Dr.\"]):\n            return \"army\"\n\n        elif (word in [\"Jonkheer.\", \"Don.\", \"Sir.\", \"Countess.\", \"Dona.\", \"Lady.\"]):\n            return \"gentry\"\n    \n    else:\n        return \"other\"\n\ntraining_set[\"title\"] = training_set[\"Name\"].apply(name_title)\n\n# Distribution\ncat_analysis(training_set, \"title\", \"title\", \"total_people\", rotation=90, figsize=(16,5))\n\n# Survived by family_size\nfig, ax = plt.subplots(figsize=(15,5))\nax = sns.barplot(x=\"title\", y=\"Survived\", data=training_set);\nplt.xticks(rotation=0)\nplt.title(\"Percentage of survived by title\")\nplt.show()\n\n# Remove temporary feature\ntraining_set.drop(\"title\", axis=1, inplace=True)","006adf31":"train_prep = prepare_data(training_set)\ntest_prep = prepare_data(test_set)","a8a37b08":"# Create a new dataframe\ndata_wcg_name = train_prep.copy()[[\"Sex_female\", \"boy\", \"wcg_surname\", \"Survived\"]]\ndata_wcg_name[\"wcg_surname_size\"] = 1\n\ndata_wcg_name.head()","6bd122c6":"len(data_wcg_name)","fa4b0def":"# Remove passengers labelled by \"no group\"\nmask = data_wcg_name[\"wcg_surname\"] != \"no_group\"\ndata_wcg_name = data_wcg_name[mask]","dfeedf89":"len(data_wcg_name)","746d3d31":"# Group by \"woman child group\" and count the number of members and the number of survivers for each group\ncolumns = {'Survived': 'survived_number'}\ndata_wcg_name = data_wcg_name.groupby(\"wcg_surname\").agg({'Survived':'sum', 'wcg_surname_size':'count'}).reset_index().rename(columns=columns)\n\ndata_wcg_name.head(15)\n","c1774b73":"# Create new feature <All died>\ndata_wcg_name[\"wcg_name_all_died\"] = data_wcg_name[\"survived_number\"].apply(lambda x: 1 if x == 0 else 0)\ndata_wcg_name.head(15)","249d29ad":"# Create feature <All survived>\ndata_wcg_name[\"wcg_name_all_survived\"] = data_wcg_name[\"survived_number\"] == data_wcg_name[\"wcg_surname_size\"]\ndata_wcg_name[\"wcg_name_all_survived\"] = data_wcg_name[\"wcg_name_all_survived\"] * 1\n\ndata_wcg_name.head()","73687d70":"# Import Test dataset\nwcg_name_test = test_prep.copy()[[\"wcg_surname\"]]\nwcg_name_test.head()","90f5153f":"\nwcg_name_test[\"wcg_surname_size\"] = 1\nwcg_name_test[\"survived_number\"] = 0\nwcg_name_test[\"wcg_name_all_died\"] = 0\nwcg_name_test[\"wcg_name_all_survived\"] = 0\nmask = wcg_name_test[\"wcg_surname\"] != \"no_group\"\nwcg_name_test = wcg_name_test[mask]\n\n# Merge train and test\ndata_wcg_name = pd.concat([data_wcg_name, wcg_name_test])\n\ndata_wcg_name.head()","97028812":"data_wcg_name.tail()","0c2f7e2a":"\ndata_wcg_name = data_wcg_name.groupby(\"wcg_surname\").sum().reset_index()\ndata_wcg_name.head()","c31a4cd9":"data_wcg_name.tail()","3adb78e0":"# Keep \"woman child groups\" composed by more than one people\nmask = data_wcg_name[\"wcg_surname_size\"] > 1\ndata_wcg_name = data_wcg_name[mask]\n\n# Remove unneeded columns\ndata_wcg_name.drop([\"survived_number\", \"wcg_surname_size\"], axis=1, inplace=True)\n\ndata_wcg_name.head()","1c6c9ca0":"print(len(train_prep))\nprint(len(data_wcg_name))","0a9c0276":"# Merge with the training dataset\ntrain_prep = train_prep.merge(data_wcg_name, how=\"left\", on=\"wcg_surname\")\ntrain_prep.head(15)","aefd3a34":"display(data_wcg_name.head())\nprint(f\"Total groups: {data_wcg_name.shape[0]}\")\nprint(f\"All died: {data_wcg_name['wcg_name_all_died'].sum()}\")\nprint(f\"All survived: {data_wcg_name['wcg_name_all_survived'].sum()}\")\nprint(f\"Either all died or all survived: {data_wcg_name['wcg_name_all_died'].sum() + data_wcg_name['wcg_name_all_survived'].sum()}\")\n","14d24142":"for i, row in train_prep.iterrows():\n    \n    # All died processing\n    if ((train_prep.loc[i, \"wcg_name_all_died\"] == 1)):\n        train_prep.loc[i, \"all_died\"] = 1\n    elif ((train_prep.loc[i, \"wcg_name_all_died\"] == 0)):\n        train_prep.loc[i, \"all_died\"] = 0\n    else:\n        train_prep.loc[i, \"all_died\"] = np.nan\n          \n    # All survived processing\n    if ((train_prep.loc[i, \"wcg_name_all_survived\"] == 1)):\n        train_prep.loc[i, \"all_survived\"] = 1\n    elif ((train_prep.loc[i, \"wcg_name_all_survived\"] == 0)):\n        train_prep.loc[i, \"all_survived\"] = 0\n    else:\n        train_prep.loc[i, \"all_survived\"] = np.nan","7f51ed0e":"train_prep.drop([\"wcg_surname\", \"wcg_name_all_died\", \"wcg_name_all_survived\"], axis=1, inplace=True)","d8a2cbc6":"print(train_prep.shape)\ndisplay(train_prep.head())","54451fc2":"nanbyfeature2 = pd.DataFrame(train_prep.isna().sum()).sort_values(by=0, ascending=False)\nnanbyfeature2[\"percent\"] = np.round(nanbyfeature2[0] \/ len(train_prep) * 100,2)\nnanbyfeature2","c3d08f98":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntest_data_prepared = prepare_data(test_data)\n\n# Merge \"name wcg\"\ntest_data_prepared = test_data_prepared.merge(data_wcg_name, how=\"left\", on=\"wcg_surname\")\ntest_data_prepared[\"wcg_name_all_died\"]\ntest_data_prepared[\"wcg_name_all_survived\"]\n\nfor i, row in test_data_prepared.iterrows():\n    \n    # All died processing\n    if ((test_data_prepared.loc[i, \"wcg_name_all_died\"] == 1)):\n        test_data_prepared.loc[i, \"all_died\"] = 1\n    elif ((test_data_prepared.loc[i, \"wcg_name_all_died\"] == 0)):\n        test_data_prepared.loc[i, \"all_died\"] = 0\n    else:\n        test_data_prepared.loc[i, \"all_died\"] = np.nan\n          \n    # All survived processing\n    if ((test_data_prepared.loc[i, \"wcg_name_all_survived\"] == 1)):\n        test_data_prepared.loc[i, \"all_survived\"] = 1\n    elif ((test_data_prepared.loc[i, \"wcg_name_all_survived\"] == 0)):\n        test_data_prepared.loc[i, \"all_survived\"] = 0\n    else:\n        test_data_prepared.loc[i, \"all_survived\"] = np.nan\n\ntest_data_prepared.drop([\"wcg_surname\", \"wcg_name_all_died\", \"wcg_name_all_survived\"], axis=1, inplace=True)","b13f3540":"print(len(test_data_prepared))","91d57770":"test_data_prepared.head()","c6f5a97e":"test_data_prepared.tail()","7604396e":"test_data_prepared['Predict'] = 0\n\nfor i, row in test_data_prepared.iterrows():\n    \n    if ((test_data_prepared.loc[i, \"Sex_female\"] == 1)):\n        test_data_prepared.loc[i, \"Predict\"] = 1\n       \n    # All died processing\n    if ((test_data_prepared.loc[i, \"all_died\"] == 1)):\n        test_data_prepared.loc[i, \"Predict\"] = 0\n    elif ((test_data_prepared.loc[i, \"all_died\"] == 0)):\n        test_data_prepared.loc[i, \"Predict\"] = 1\n        \n    # All survived processing\n    if ((test_data_prepared.loc[i, \"all_survived\"] == 1)):\n        test_data_prepared.loc[i, \"Predict\"] = 1\n    elif ((test_data_prepared.loc[i, \"all_survived\"] == 0)):\n        test_data_prepared.loc[i, \"Predict\"] = 0","ab2fbbd6":"test_data_prepared.head()","07c81b51":"test_data_prepared.tail()","5b4ec086":"submission = test_data_prepared\nsubmission['PassengerId'] = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")['PassengerId'].copy()\nsubmission.head()","902b55e3":"submission = pd.DataFrame({\n        \"PassengerId\": submission[\"PassengerId\"], \n        \"Survived\": submission[\"Predict\"]\n    })","240a2a66":"submission.to_csv(\"submission.csv\", index=False)\nprint('Submission successfully saved')","27f9bda6":"The gender model predicts all females survive and all males perish. The plot below shows why this model scores well.","819b8ff3":"## Introduction\n\nThe aim of the titanic challenge is to predict which passengers within the test dataset survived based on passenger information contained in the training dataset. As a baseline model, Kaggle present a 'gender model' (GM) which assumes all females survive and all males perish which scores highly (~76%) because the majority of females survived (74%) and the vast majority of males perished (81%).\n\nThis notebook retraces the steps of other Kagglers listed below, and improves upon the GM with a women-children-groups-model (WCGM) that assumes women and children within family group shared a common fate; They either all died together, or they all survived together. This model improves on the GM by identifing the minority of women that died and the rare males (boys) that lived. The WCGM model acheives a public score of 80% - 4% higher than the GM, and places it in the top 4% of predictions.\n\nhttps:\/\/www.kaggle.com\/cdeotte\/titanic-using-name-only-0-81818\nhttps:\/\/www.kaggle.com\/nicodesh\/xgboost-with-5-features-0-82296-step-by-step\nhttps:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\nhttps:\/\/www.kaggle.com\/masumrumi\/a-statistical-analysis-ml-workflow-of-titanic\n","f3830a67":"We've got a group information for about 25% of passengers.","68eb1204":"### \"Boy\" feature\n\nBoys can be identified from the title (Master) that is included within the Name string.","1fa2dd49":"## Now include test..","4a7b06b0":"Once boys are seperated from men, we can see that \"man\" passengers fared badly. In contrast, the boys fared better with a survvial rate of almost 0.60%.\n\n1. The feature \"boy\" will help to find \"men\" who are not actually men but children. So it will help predicting \"male\" passengers that survived.\n\n2. The WCG features will help to find boys who were in a family where everybody died, so we will not predict all boys survived and be more accurate.","8321b67a":"Steps:\n\n1. I create a new dataset from the training set where I group by \"woman child group\" which is the surname of all passengers, except for men where the value is \"no_group\"\n2. I create new features: \"all died\" means everybody died in this group. \"all survived\" means everybody survived in this group.\n3. I import the test set.\n4. I group again, to be able to count how many people there are in each group.\n5. I remove groups with only 1 people across all data","a800d47f":"#### NaN by feature","ff0c5b24":"## Data overview\n","cc8ad1d5":"## The gender model","56cde0ff":"### Prepare the data sets","ea5e2f70":"### Submission","79bbf44f":"## Import libraries & data\n","c364dee4":"## Woman Child Group Engineering","a33e90af":"## Functions","cc893155":"### Applying all-died and all-survived to the training dataset\n\nThe main dataset has now 2 new features :\n\n1. All survived by group\n2. All died by group\n\nThese are now used to complete an 'all_survived' feature for the women-children groups.","fd68802d":"# Make predictions\n\n### Get and prepare the test data","1beb0627":"As we can see, a majority died together or survived together."}}