{"cell_type":{"a685c43c":"code","72bd7118":"code","e8725089":"code","aeb9a5ec":"code","a0041766":"code","b6a1d4f0":"code","66303435":"code","b1b45cb7":"code","d0c04ee4":"code","d167cceb":"code","33473039":"code","98a38d5b":"code","9714808e":"code","5b016b56":"code","be82bc64":"code","7889b631":"code","a6f44bea":"code","02b0a45e":"code","aaff8f8a":"code","1ec3934e":"code","e7df222f":"code","88349ace":"code","d2f499bf":"code","409ac268":"code","2e6252ce":"code","6b81008d":"code","88e18a6d":"code","ba17cad4":"code","c0d9d8cb":"code","551e8aac":"code","dbaa244f":"code","0e542b48":"markdown"},"source":{"a685c43c":"import pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","72bd7118":"PATHS = [\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Monday-WorkingHours.pcap_ISCX.csv',\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Tuesday-WorkingHours.pcap_ISCX.csv',\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Wednesday-workingHours.pcap_ISCX.csv',\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Friday-WorkingHours-Morning.pcap_ISCX.csv',\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n    '..\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv'\n    \n]\ndf = pd.read_csv(PATHS[len(PATHS)-1])\n","e8725089":"df[' Label'].value_counts()","aeb9a5ec":"# for i in range(0,len(PATHS)):\n#     temp = pd.read_csv(PATHS[i])\n#     print(PATHS[i])\n#     print(temp[' Label'].value_counts())\n#     print('\\n')\n    ","a0041766":"m = df.loc[df[' Flow Packets\/s'] != np.inf,' Flow Packets\/s'].max()\ndf[' Flow Packets\/s'].replace(np.inf,m,inplace=True)\nm = df.loc[df['Flow Bytes\/s'] != np.inf,'Flow Bytes\/s'].max()\ndf['Flow Bytes\/s'].replace(np.inf,m,inplace=True)","b6a1d4f0":"dtypes = df.dtypes\nprint(f\"Number of columns with Int {len(dtypes[dtypes == int])}\")\nprint(f\"Number of columns with float {len(dtypes[dtypes == float])}\")\nprint(f\"Number of columns with object {len(dtypes[dtypes == object])}\")","66303435":"null_index = df[df['Flow Bytes\/s'].isnull()].index.tolist()\ntargets = df.loc[null_index,' Label']","b1b45cb7":"null_values = df.isna().sum()\nnull_values[null_values >0]","d0c04ee4":"null_index = np.where(df['Flow Bytes\/s'].isnull())[0]\ndf.dropna(inplace = True)","d167cceb":"# labels = df[' Label'].unique()\n# label_enc  = dict()\n# for i in range(len(labels)):\n#     label_enc[labels[i]] = i\n# df[' Label'] = df[' Label'].map(label_enc)\n# import plotly.express as px\n# fig = px.imshow(df.corr())\n# fig.show()\n","33473039":"# import plotly.express as px\n# fig = px.imshow(df.corr())\n# fig.show()","98a38d5b":"# temp = df[df[' Label'] == 'BENIGN']\n# temp[' Destination Port'].describe()\n# temp = temp.sample(frac = 0.1)","9714808e":"# df = df[df[' Label'] != 'BENIGN']\n# df = pd.concat([df,temp])","5b016b56":"from sklearn.model_selection import StratifiedKFold\ndf['folds'] = 0\nskf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\nfor i, (_, test_index) in enumerate(skf.split(df[[' Destination Port']], df[' Label'])):\n    df.iloc[test_index, -1] = i","be82bc64":"df = pd.get_dummies(df)","7889b631":"col = [' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n       ' Total Backward Packets', 'Total Length of Fwd Packets',\n       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n       ' Bwd Packet Length Std', 'Flow Bytes\/s', ' Flow Packets\/s',\n       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n       ' Bwd Header Length', 'Fwd Packets\/s', ' Bwd Packets\/s',\n       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n       ' ECE Flag Count', ' Down\/Up Ratio', ' Average Packet Size',\n       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n       ' Fwd Header Length.1', 'Fwd Avg Bytes\/Bulk', ' Fwd Avg Packets\/Bulk',\n       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes\/Bulk', ' Bwd Avg Packets\/Bulk',\n       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min']","a6f44bea":"train_df= df[df['folds'] != 5]\nvalid_df = df[df['folds'] == 5]","02b0a45e":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ntrain_df[col] = scaler.fit_transform(train_df[col])\nvalid_df[col] = scaler.transform(valid_df[col])","aaff8f8a":"# train_df[' Label'].value_counts()","1ec3934e":"# train_df[' Label'] = train_df[' Label'].map({'DDoS':0, 'BENIGN':1})\n# valid_df[' Label'] = valid_df[' Label'].map({'DDoS':0, 'BENIGN':1})","e7df222f":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls = 1e-2, lr = 1e-3):\n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    #Multi Layer perceptron\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(dropout_rates[3])(x)\n    \n    for i in range(2, len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation('swish')(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 2])(x)\n    \n    out = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name = 'action')(x)\n#     else:    \n#         out = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name = 'action')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = [out])\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n                  loss = {\n                          'action': tf.keras.losses.BinaryCrossentropy(label_smoothing = ls), \n                         },\n                  metrics = { \n                             'action': tf.keras.metrics.Accuracy(name = 'accuracy'), \n                            }, \n                 )\n    \n    return model","88349ace":"params = {'num_columns': len(col), \n          'num_labels': 2, \n          'hidden_units': [96, 96, 896, 448, 448, 256], \n          'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882, 0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448], \n          'ls': 0, \n          'lr':1e-3, \n         }","d2f499bf":"batch_size = 64","409ac268":"train_df.iloc[:,-2:]","2e6252ce":"fold = 5\nckp_path = f'JSModel_{fold}.hdf5'\nmodel = create_mlp(**params)\nckp = ModelCheckpoint(ckp_path, monitor = 'val_accuracy', verbose = 0, \n                      save_best_only = True, save_weights_only = True, mode = 'max')\nes = EarlyStopping(monitor = 'val_accuracy', min_delta = 1e-4, patience = 20, mode = 'max', \n                   baseline = None, restore_best_weights = True, verbose = 0)\nhistory = model.fit(train_df[col], [train_df.iloc[:,-2:],train_df.iloc[:,-2:]], \n                    validation_data = (valid_df[col], [ valid_df.iloc[:,-2:],valid_df.iloc[:,-2:]]), \n                    epochs = 10, batch_size = batch_size, callbacks = [ckp, es], verbose = True)\nhist = pd.DataFrame(history.history)","6b81008d":"model.load_weights('..\/input\/ann-cicids\/JSModel_5.hdf5')","88e18a6d":"res = model.predict(valid_df[col])\nres = np.argmax(res,axis =1)\n\ntruth = np.argmax(valid_df.iloc[:,-2:].values,axis = 1)\n\ntruth = np.argmax(valid_df.iloc[:,-2:].values,axis = 1)\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(truth, res)\nprecision,recall,_,_ = precision_recall_fscore_support(truth,res)\n","ba17cad4":"epochs = [ i for i in range(1,11)]\nhist['epochs'] = epochs","c0d9d8cb":"import plotly.graph_objects as go\nimport json\n!pip install -U kaleido\nimport kaleido","551e8aac":"fig = go.Figure()\nfig.add_trace(go.Scatter(\n                            x=hist['epochs'], y=hist['val_loss'],\n                            mode='lines+markers',\n                            name = \"Validation Loss\"\n                        )\n            )\n\nfig.add_trace(go.Scatter(\n                            x=hist['epochs'], y=hist['loss'],\n                            mode='lines+markers',\n                            name = \"Train Loss\"\n                        )\n            )\n\nfig.update_layout(title=\"Loss Versus Epochs for MLP\",\n                   xaxis_title='Epoch',\n                   yaxis_title='Loss')\nfig.write_image(\"mlp_loss.jpeg\")\nfig.show()","dbaa244f":"fig = go.Figure()\nfig.add_trace(go.Scatter(\n                            x=hist['epochs'], y=hist['val_AUC'],\n                            mode='lines+markers',\n                            name = \"Validation AUC\"\n                        )\n            )\n\nfig.add_trace(go.Scatter(\n                            x=hist['epochs'], y=hist['AUC'],\n                            mode='lines+markers',\n                            name = \"Train AUC\"\n                        )\n            )\nfig.update_layout(title=\"AUC Versus Epochs for MLP\",\n                   xaxis_title='Epoch',\n                   yaxis_title='AUC')\nfig.write_image(\"mlp_auc.jpeg\")\nfig.show()","0e542b48":"# Model "}}