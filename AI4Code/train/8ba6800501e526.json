{"cell_type":{"faed985f":"code","36e4fef6":"code","1bb877c3":"code","05406910":"code","5ccabe2f":"code","3d4f2040":"code","dc8d8aad":"code","81aaf9c8":"code","048a13e2":"code","555f1e15":"code","0b881a27":"code","0713720e":"code","5d6980f3":"code","cac61ec1":"code","52228bea":"code","9ddc2ee2":"code","69566c9c":"code","597822e7":"code","c9da10d7":"code","779ea287":"code","d5ef1c97":"code","9025831f":"code","2fc242f8":"code","ce4e76b4":"code","4ba424fa":"code","ffc6471d":"markdown","aa643863":"markdown","10d4d354":"markdown","3fce88b4":"markdown","bce61c35":"markdown","592f00be":"markdown","fe91a22e":"markdown","87638edc":"markdown","93bdc187":"markdown","f49597c1":"markdown","db9f1fd7":"markdown","ad9921c8":"markdown"},"source":{"faed985f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36e4fef6":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter","1bb877c3":"data = pd.read_csv(\"..\/input\/drug-classification\/drug200.csv\")","05406910":"data.head()","5ccabe2f":"data.info()","3d4f2040":"data.describe()","dc8d8aad":"sns.countplot(data[\"Drug\"])\nprint(data.Drug.value_counts())","81aaf9c8":"plt.plot(data.Na_to_K[data.Drug == \"DrugY\"]) # Di\u011ferlerinden kolayca ayr\u0131l\u0131yor.\nplt.plot(data.Na_to_K[data.Drug == \"drugx\"])\nplt.plot(data.Na_to_K[data.Drug == \"drugA\"])\nplt.plot(data.Na_to_K[data.Drug == \"drugB\"])\nplt.plot(data.Na_to_K[data.Drug == \"drugC\"])\n\nplt.show()","048a13e2":"sns.countplot(data[\"Cholesterol\"])\nprint(data.Cholesterol.value_counts())","555f1e15":"sns.countplot(data[\"Age\"])\nplt.show()","0b881a27":"sns.countplot(data[\"BP\"])\nprint(data.BP.value_counts())","0713720e":"data.isnull().sum()","5d6980f3":"data['Sex'].replace({'M', 'F'},{1, 0}, inplace=True)\ndata['BP'].replace({'HIGH', 'LOW', 'NORMAL'},{1, 2, 3}, inplace=True)\ndata['Cholesterol'].replace({'HIGH', 'NORMAL'},{1, 0}, inplace=True)","cac61ec1":"data.boxplot(column=\"Na_to_K\")\nplt.show()","52228bea":"describe = data.describe()\nNa_to_K_desc = describe[\"Na_to_K\"]\nNa_to_K_desc","9ddc2ee2":"data.drop(data[data[\"Na_to_K\"] > 31].index, inplace=True)","69566c9c":"data.boxplot(column=\"Na_to_K\")\nplt.show()","597822e7":"x = data.drop(['Drug'], axis=1)\ny = data['Drug']\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix","c9da10d7":"print(\"X_train shape:\",x_train.shape)\nprint(\"X_test shape:\",x_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\",y_test.shape)","779ea287":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\ndata_stan = scaler.fit_transform(x)\n\ndata_stan = pd.DataFrame(data_stan, columns=x.columns)\ndata_stan.head()","d5ef1c97":"# knn model -> k = 3\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3) # n_neighbors = k\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\nprint(\" {} nn score: {} \".format(3,knn.score(x_test,y_test)))\n\n# find k value\nscore_list = []\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\n# knn model -> k = 1\nknn = KNeighborsClassifier(n_neighbors = 1) # n_neighbors = k\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\nprint(\" {} nn score: {} \".format(1,knn.score(x_test,y_test)))","9025831f":"from sklearn.naive_bayes import GaussianNB \ngnb = GaussianNB() \ngnb.fit(x_train, y_train) \n\nprint(\"score: \", gnb.score(x_test,y_test))","2fc242f8":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\n\nprint(\"score: \", dt.score(x_test,y_test))","ce4e76b4":"from sklearn.svm import SVC\n \nsvm = SVC(random_state = 1)\nsvm.fit(x_train,y_train)\n\nprint(\"score: \", svm.score(x_test,y_test))","4ba424fa":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\n\nvoting = VotingClassifier(estimators=[(\"dt\",dt),(\"knn\",knn),(\"svm\",svm),(\"gnb\",gnb)])\n\nfor i in (dt, knn, svm, voting):\n    i.fit(x_train, y_train)\n    y_pred = i.predict(x_test)\n    print(i, \"= \",accuracy_score(y_test, y_pred))","ffc6471d":"<a id=\"6\"><\/a><br>\n# Classification ","aa643863":"<a id=\"3\"><\/a><br>\n# Missing Value and Outlier","10d4d354":"<a id=\"11\"><\/a><br>\n## Voting Classifier","3fce88b4":"<a id=\"9\"><\/a><br>\n## Decison Tree","bce61c35":"<a id=\"10\"><\/a><br>\n## Support Vector Machine","592f00be":"<a id=\"8\"><\/a><br>\n## Naive Bayes ","fe91a22e":"<a id=\"7\"><\/a><br>\n## KNN","87638edc":"# Drug Classification\n\n<font color = \"blue\">\nContent:  \n\n1. [Dataset](#1)\n2. [Visualization (G\u00f6rselle\u015ftirme)](#2)\n3. [Missing Value and Outlier](#3)\n4. [Train\/Test Split](#4)\n5. [Standardize](#5)\n6. [Classification](#6)\n    * [KNN](#7)\n    * [Naive Bayes](#8)\n    * [Decision Tree](#9)\n    * [Support Vector Machine](#10)\n    * [Voting Classifier](#11)","93bdc187":"<a id=\"1\"><\/a><br>\n# Dataset\n\n* Age -> min=15, max=74\n* Sex -> F, M\n* BP -> HIGH, NORMAL, LOW\n* Cholesterol -> HIGH, NORMAL\n* Na_to_K (Na to Potassium Ration)\n* Drug -> DrugY, drugX, drugA, drugB, drugC","f49597c1":"<a id=\"2\"><\/a><br>\n# Visualization","db9f1fd7":"<a id=\"5\"><\/a><br>\n# Standardize","ad9921c8":"<a id=\"4\"><\/a><br>\n# Train\/Test Split"}}