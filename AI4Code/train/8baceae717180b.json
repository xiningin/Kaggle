{"cell_type":{"7ccd3704":"code","de211031":"code","ad815452":"code","a9d325a0":"code","71fd04cb":"code","d776668d":"code","2c6e0849":"code","6c988fcc":"code","346e1b3a":"code","f55297f3":"code","474ecf0f":"code","b67ecd93":"code","8d92b066":"code","193229c7":"code","23aa6ccf":"code","db7bb558":"code","fd64d3bb":"code","9400f1f9":"code","73e77252":"code","db95e9e2":"code","a8458e3a":"code","7dde1b10":"code","1f2123f2":"code","ef9d04b6":"code","cc3ad22c":"code","bb831270":"code","aa640ceb":"code","4dd258e5":"code","c7d90bf5":"code","82fb6d32":"code","84370307":"markdown","72baa71a":"markdown","dd754a5d":"markdown","1591c6d7":"markdown","fc96c3b3":"markdown","b3482985":"markdown","86412445":"markdown","5b6a9bdd":"markdown","ebdc60fd":"markdown","8b3709a7":"markdown"},"source":{"7ccd3704":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","de211031":"## using BERT as an embedding layer : We will not train the variables of BIRT,\n## we will use it as how it comes.\nimport pandas as pd\nimport numpy as np\nimport re\nimport math\nfrom bs4 import BeautifulSoup\nimport random","ad815452":"pip install bert-for-tf2","a9d325a0":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nimport bert","71fd04cb":"cols=[\"sentiment\",\"id\",\"date\",\"query\",'user',\"text\"]\ndata=pd.read_csv(\"\/kaggle\/input\/stanford-140-for-nlp\/training.1600000.processed.noemoticon.csv\",\n                header=None,\n                names=cols,\n                engine=\"python\",\n                encoding=\"latin1\")","d776668d":"# Dropping some use less columns\ndata.drop([\"id\",\"date\",'query',\"user\"],axis=1,inplace=True)","2c6e0849":"data.head()","6c988fcc":"def clean_tweet(tweet):\n    tweet = BeautifulSoup(tweet,\"lxml\").get_text()\n    tweet = re.sub(r\"@[A-Za-z0-9]+\",\" \",tweet) # like replace for string\n    tweet = re.sub(r\"https?:\/\/[A-Za-z0-9.\/]+\",' ',tweet) # replacing https and ? as s is not conformed\n    tweet = re.sub(r\"[^a-zA-Z.!?']\",\" \",tweet) # removing everything other than these\n    tweet = re.sub(r\" +\",\" \",tweet)\n    return tweet","346e1b3a":"%%time\ndata_clean = [clean_tweet(tweet) for tweet in data.text]","f55297f3":"data_clean[0]","474ecf0f":"# Changing the value of labels\ndata_labels=data.sentiment.values\ndata_labels[data_labels==4] = 1","b67ecd93":"FullTokenizer=bert.bert_tokenization.FullTokenizer\n# at hub all the pre-trained models are present\nbert_layer=hub.KerasLayer(\"https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-12_H-768_A-12\/1\", \n                          trainable=False)\nvocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case=bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer=FullTokenizer(vocab_file,do_lower_case)","8d92b066":"## CLS token at the very beginning.\ndef encode_sent(sent):\n    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]\n","193229c7":"data_inputs = [encode_sent(sent) for sent in data_clean]","23aa6ccf":"data_inputs[0]","db7bb558":"# need a list of mask: where padding values in out sentences\n# data_inputs, list of masks , segments input(1-second sentence  and 0-first sentence)\ndef get_ids(tokens):\n    return tokenizer.convert_tokens_to_ids(tokens)\n\ndef get_mask(tokens):\n    return np.char.not_equal(tokens,\"[PAD]\").astype(int)# tells when we will be facing a padding token\n\n# when we get first SEP token we get the second sentence\ndef get_segments(tokens):\n    seg_ids=[]\n    current_seg_id=0\n    for tok in tokens:\n        seg_ids.append(current_seg_id)\n        if tok == \"[SEP]\":\n            current_seg_id=1-current_seg_id #Covert 1 to 0 and 0 to 1\n    return seg_ids\n","fd64d3bb":"data_with_len=[[sent,data_labels[i],len(sent)] for i, sent in enumerate(data_inputs)]\n\nrandom.shuffle(data_with_len)\ndata_with_len.sort(key=lambda x: x[2])\nsorted_all= [([get_ids(sent_lab[0]),\n               get_mask(sent_lab[0]),\n               get_segments(sent_lab[0])],\n              sent_lab[1])\n            for sent_lab in data_with_len if sent_lab[2]>7]\n## getting only data whose length is more than 7","9400f1f9":"sorted_all","73e77252":"my_sent = [\"[CLS]\"] + tokenizer.tokenize(\"Roses are red.\") + [\"[SEP]\"]\n\nbert_layer([tf.expand_dims(tf.constant(get_ids(my_sent),tf.int32),0),\n             tf.expand_dims(tf.constant(get_mask(my_sent),tf.int32),0),\n             tf.expand_dims(tf.constant(get_segments(my_sent),tf.int32),0)])","db95e9e2":"## The first part is for classification and the second gives the tokens for the embeded layer\n## Second one is for token level of spcification\n## We need ot get a vertor for each of out words.\n\n# import time \n# while True:\n#     print(\"5\")\n#     time.sleep(80)\n\n## The numbers of input we have\/batch size = no of batches \nNB_BATCHES = math.ceil(len(sorted_all)\/BATCH_SIZE)\n## get 1\/10 of it to create testing set\nNB_BATCHES_TEST = NB_BATCHES\/\/10\n## Need to shuffle the data set as shaorter are in the start and longer at the end\nall_batched.shuffle(NB_BATCHES)\n## If size is large use less than No of batches in buffer\n\n## Creating testing and training dataset\n\ntest_dataset=all_batched.take(NB_BATCHES_TEST)\ntrain_dataset=all_batched.skip(NB_BATCHES_TEST)","a8458e3a":"class DCNNBERTEmbedding(tf.keras.Model):\n    def __init__(self,\n                nb_filters=50,\n                FFN_units=512,\n                nb_classes=2,\n                dropout_rate=0.1,\n                name=\"dcnn\"):\n        super(DCNNBERTEmbedding,self).__init__(name=name)\n        \n        self.bert_layer=hub.KerasLayer(\n                    \"https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-12_H-768_A-12\/1\",\n                    trainable=False)\n        # creating the CNN layer\n        ## using padding valid : stride out feature detecture by 1\n        self.bigram = layers.Conv1D(filters=nb_filters,\n                                    kernel_size=2,\n                                    padding=\"valid\",\n                                    activation=\"relu\")\n        \n        self.trigram = layers.Conv1D(filters=nb_filters,\n                                     kernel_size=3,\n                                     padding=\"valid\",\n                                     activation=\"relu\")\n        \n        self.fourgram = layers.Conv1D(filters=nb_filters,\n                                      kernel_size=4,\n                                      padding=\"valid\",\n                                      activation=\"relu\")\n        \n        ## Creating a layer which takes the max of all the outputs\n        \n        self.pool=layers.GlobalAveragePooling1D()\n        \n        ## Creatign two dense layers with hidden number of units between the two dense layers\n        \n        self.dense1=layers.Dense(units=FFN_units,\n                                 activation=\"relu\")\n        ## Create a sense of gerenalarity using Dropout\n        \n        self.dropout=layers.Dropout(dropout_rate)\n        \n        if nb_classes==2:\n            \n            self.dense2=layers.Dense(units=1,\n                                     activation=\"sigmoid\")\n        else :\n            self.dense2=layers.Dense(units=nb_classes,\n                                     activation=\"softmax\")\n    def emb_with_bert(self,all_tokens):\n        _,embs=self.bert_layer([all_tokens[:,0,:],\n                                all_tokens[:,1,:],\n                                all_tokens[:,2,:]])\n        return embs\n    ## as we only need second part of the output\n        \n    \n    def call(self,inputs,training):\n        ## training Bool:if trainign false not use of fropout\n        x=self.embedding(inputs)\n        x_1=self.bigram(x)\n        x_1=self.pool(x_1)\n        ## each of 50 feature detector of size 2 we get 1 number which has max values\n        \n        x_2=self.trigram(x)\n        x_2=self.pool(x_2)\n        \n        x_3=self.fourgram(x)\n        x_3=self.pool(x_3)   ## (batch_szie, nb_filters)\n        \n        ## now concat all the results and apply dense layers\n        \n        merged=tf.concat([x_1,x_2,x_3],axis=1) ## (batch_size,3*nb_flters)\n        merged=self.dense1(merged)\n        \n        merged=self.dropout(merged,training)\n        output=self.dense2(merged)\n        \n        return output","7dde1b10":"\nNB_FILTERS=100\nFFN_UNITS=256\nNB_CLASSES=2\n\nDROPOUT_RATE=0.2\n\nBATCH_SIZE=32\nNB_EPOCHS=5","1f2123f2":"Dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\n                         FFN_units=FFN_UNITS,\n                         nb_classes=NB_CLASSES,\n                         dropout_rate=DROPOUT_RATE)","ef9d04b6":"if NB_CLASSES==2:\n    Dcnn.compile(loss=\"binary_crossentropy\",\n                optimizer=\"adam\",\n                metrics=[\"accuracy\"])\nelse:\n    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n                optimizer=\"adam\",\n                metrics=[\"sparse_categorcal_accuracy\"])","cc3ad22c":"## Creating Checkpoint in order to save the model weights of model\ncheckpoint_path=\".\/ckpt_bert_tok\"\n\nckpt=tf.train.Checkpoint(Dcnn=Dcnn)\nckpt_manager=tf.train.CheckpointManager(ckpt,checkpoint_path,max_to_keep=1)\n\nif ckpt_manager.latest_checkpoint:\n        ckpt.restore(ckpt_manager.latest_checkpoint)\n        print(\"Latest chekcpoint restored\")","bb831270":"class MyCustomCallback(tf.keras.callbacks.Callback):\n    \n    def on_epoch_ends(self,epoch,logs=\"None\"):\n        ckpt_manager.save()\n        print(f\"Checkpoint is saved at {checkpoint_path}\")","aa640ceb":"Dcnn.fit(train_dataset,\n        epochs=NB_EPOCHS,\n        callbacks=[MyCustomCallback()])","4dd258e5":"results=Dcnn.evaluate(test_dataset)\nprint(results)","c7d90bf5":"def get_prediction(sent):\n    tokens = encode_sent(sent)\n    ## As tensorflow works with batches need to send batches even if we have only 1 senteance\n    inputs = tf.expand_dims(tokens,0)\n    output = Dcnn(inputs,training=False)\n    ## *2 as we have two classes \n    sentiment = math.floor(output*2)\n    \n    if sentiment ==0:\n        print(f\"Output of the model : {sentiment}\\npredicted sentiment : negative\")\n    elif sentiment ==1:\n        print(f\"Output of the model : {sentiment}\\npredicted sentiment : positive\")","82fb6d32":"get_prediction(\"Pls help me, i am stuck\")","84370307":"# Tokenization\n## we need to create a BERT layer to have access to meta data for tokenizer(like vocab size)","72baa71a":"### We will create a padded batch(so we pad sentences for every batch independently), this way we add the minimum of padding tokens possible. For that, we sort the sentences by length, apply padded_batches and then shuffle\n\n","dd754a5d":"## Evaluating the model","1591c6d7":"# Cleaning Data","fc96c3b3":"# Model Building","b3482985":"<img src=\"data:image\/jpeg;base64,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\" width=75% height=36%>\n\n# Importing libraries","86412445":"#### We use the first sentence for BERT inputs so we add the CLS token at the beginning and the SEP token at  the end of end sentence.","5b6a9bdd":"### using Small BERT","ebdc60fd":"## As the data is in XML","8b3709a7":"# Dataset Creation:\n### We need to create the 3 different inputs for each sentence"}}