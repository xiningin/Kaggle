{"cell_type":{"43dad75a":"code","cfd77bc9":"code","a9dc1d4b":"code","761804da":"code","969f2f47":"markdown","a237d017":"markdown","448444fe":"markdown","bfbd56e9":"markdown","218fa44a":"markdown","2afea7b6":"markdown"},"source":{"43dad75a":"from IPython.display import YouTubeVideo\nYouTubeVideo('mPFq5KMxKVw', width=800, height=450)","cfd77bc9":"from tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nnum_classes = 2\nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmy_new_model = Sequential()\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = False","a9dc1d4b":"my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])","761804da":"from tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 224\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n\ntrain_generator = data_generator.flow_from_directory(\n        '..\/input\/urban-and-rural-photos\/rural_and_urban_photos\/train',\n        target_size=(image_size, image_size),\n        batch_size=24,\n        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(\n        '..\/input\/urban-and-rural-photos\/rural_and_urban_photos\/val',\n        target_size=(image_size, image_size),\n        class_mode='categorical')\n\nmy_new_model.fit_generator(\n        train_generator,\n        steps_per_epoch=3,\n        validation_data=validation_generator,\n        validation_steps=1)","969f2f47":"### Note on Results:\nThe printed validation accuracy can be meaningfully better than the training accuracy at this stage. This can be puzzling at first.\n\nIt occurs because the training accuracy was calculated at multiple points as the network was improving (the numbers in the convolutions were being updated to make the model more accurate).  The network was inaccurate when the model saw the first training images, since the weights hadn't been trained\/improved much yet.  Those first training results were averaged into the measure above.\n\nThe validation loss and accuracy measures were calculated **after** the model had gone through all the data.  So the network had been fully trained when these scores were calculated.\n\nThis isn't a serious issue in practice, and we tend not to worry about it.","a237d017":"### Fit Model","448444fe":"# Intro\n\n**This is Lesson 4 in the [Deep Learning](https:\/\/www.kaggle.com\/learn\/deep-learning) track**  \n\nAt the end of this lesson, you will be able to use transfer learning to build highly accurate computer vision models for your custom purposes, even when you have relatively little data.\n\n# Lesson\n","bfbd56e9":"# Your Turn\n[Write your own kernel to do transfer learning](https:\/\/www.kaggle.com\/dansbecker\/exercise-using-transfer-learning\/).\n\n# Keep Going\nAfter the exercise, you move on to [data augmentation](https:\/\/www.kaggle.com\/dansbecker\/data-augmentation\/).  It's a clever (and easy) trick to improve your models.\n\n\n---\nHave questions, comments or feedback?  Bring them to [the Learn forum](https:\/\/www.kaggle.com\/learn-forum)\n\n**[Deep Learning Track Home](https:\/\/www.kaggle.com\/learn\/deep-learning)**","218fa44a":"### Compile Model","2afea7b6":"# Sample Code\n\n### Specify Model"}}