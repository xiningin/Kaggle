{"cell_type":{"5d84f4c5":"code","3dd2578a":"code","ecba0080":"code","aaa3a0cd":"code","51221cd2":"code","3b4841d7":"code","d963ec38":"code","ddf4aae3":"code","e2d64c62":"code","9c37faac":"code","572d1775":"code","d81c4786":"code","3213cf94":"code","1e06e07a":"code","63fc6561":"code","ce1f709e":"code","8c644717":"code","8977d623":"code","6de1e009":"code","7c188529":"code","361bce3b":"code","b39a5fae":"code","80c4661c":"code","920f8759":"code","b24150b7":"code","0106a869":"code","ad3845db":"code","29036c79":"code","b78235a7":"code","4e9aade2":"code","6212e831":"code","8c8a965d":"code","d3146190":"code","25630542":"code","0625d3ac":"code","258430ad":"code","a1ed9fa7":"code","1dff5ae2":"code","6b6a8cd0":"code","82ee1908":"code","9fdf70ec":"code","baa773d7":"code","76e72735":"code","99948825":"code","1238a689":"markdown","cda78dfb":"markdown"},"source":{"5d84f4c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3dd2578a":"# Load datasets\ntrain = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","ecba0080":"# Import libraries\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import mnist","aaa3a0cd":"train.shape","51221cd2":"test.shape","3b4841d7":"train.head()","d963ec38":"test.head(2)","ddf4aae3":"X_train = train.drop('label', axis=1)\ny_train = train['label']","e2d64c62":"X_train.shape","9c37faac":"# Now, reshape our data to image dimension\nX_train = X_train.values.reshape(42000,28,28,1)","572d1775":"X_train.shape","d81c4786":"# test to see a single image\nsingle_img = X_train[0]","3213cf94":"#single_img","1e06e07a":"single_img.shape","63fc6561":"# lets see how the image looks like\nplt.imshow(single_img)","ce1f709e":"y_train","8c644717":"y_train.shape","8977d623":"# Convert y_train to categorical values\nexample = to_categorical(y_train)","6de1e009":"example","7c188529":"example.shape","361bce3b":"example[0]","b39a5fae":"y_cat_train = to_categorical(y_train,10)","80c4661c":"single_img.max()","920f8759":"single_img.min()","b24150b7":"# We should normalize our training data\nX_train = X_train\/255","0106a869":"# Lets see example when it scaled\nscaled_one = X_train[3]","ad3845db":"scaled_one.max()","29036c79":"# Make sure it's still the image\nplt.imshow(scaled_one)","b78235a7":"# Check again the shape of training data\nX_train.shape","4e9aade2":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam","6212e831":"model = Sequential()\n\n# First add Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=(28,28,1),\n                activation='relu'))\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2,2)))\n# Flatten layer is to flatten the images from 28 by 28 to 764 before final layer\nmodel.add(Flatten())\n# Add Dense layer\nmodel.add(Dense(128, activation='relu'))\n#model.add(Dense(64, activation='relu'))\n# Last layer is classifier\nmodel.add(Dense(10, activation='softmax'))\n\n# Compile our model\nopt = Adam(learning_rate=0.005)\nmodel.compile(loss='categorical_crossentropy',\n             optimizer=opt,\n              metrics=['accuracy'])","8c8a965d":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='accuracy',patience=3, verbose=1)","d3146190":"model.fit(X_train, y_cat_train,epochs=100,callbacks=[early_stop],batch_size=16)","25630542":"model.metrics_names","0625d3ac":"losses = pd.DataFrame(model.history.history)","258430ad":"losses.head()","a1ed9fa7":"\ntest.shape\n","1dff5ae2":"test = test.values.reshape(28000,28,28,1)","6b6a8cd0":"test.shape","82ee1908":"predictions = model.predict_classes(test)","9fdf70ec":"len(predictions)","baa773d7":"#test\nimgId = list(range(1,28001))\nimgId = pd.Series(imgId)","76e72735":"imgId","99948825":"sub = pd.DataFrame({'ImageID':imgId , 'Label': predictions})\nsub.to_csv(\"test_submission.csv\", index=False)","1238a689":"## Preprocessing Data","cda78dfb":"# Training our model\n"}}