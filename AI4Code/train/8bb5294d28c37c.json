{"cell_type":{"708d533d":"code","a2b8543f":"code","da41f883":"code","a9c0dec6":"code","a1ff8f9e":"code","6869095c":"code","42a32513":"code","47418e07":"code","70f02ac8":"code","32975d56":"code","e5bf55c0":"markdown","ec539c0d":"markdown","e71cdd4f":"markdown","c252428a":"markdown","ada13f00":"markdown","41f3b613":"markdown","134f8472":"markdown","e8c7f350":"markdown","38415251":"markdown","e62b1c06":"markdown"},"source":{"708d533d":"import torchvision\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport time\nimport pandas as pd","a2b8543f":"train_path = \"\/kaggle\/input\/100-bird-species\/train\"\nval_path = \"\/kaggle\/input\/100-bird-species\/valid\"\ntest_path = \"\/kaggle\/input\/100-bird-species\/test\" \nbatch_size = 64\ntransform = transforms.Compose([\n    transforms.Resize(64),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntrain_folder = torchvision.datasets.ImageFolder(root=train_path, transform=transform)\nvalid_folder = torchvision.datasets.ImageFolder(root=val_path, transform=transform)\ntest_folder = torchvision.datasets.ImageFolder(root=test_path, transform=transform)\ntrain_ds = DataLoader(train_folder, batch_size=batch_size)\nvalid_ds = DataLoader(valid_folder, batch_size=batch_size)\ntest_ds = DataLoader(test_folder, batch_size=batch_size)","da41f883":"class CNNModel(nn.Module):\n    \n    def __init__(self, num_classes):\n        super(CNNModel, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, 11, stride=1, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","a9c0dec6":"n_classes = len(train_folder.classes)\nmodel = CNNModel(n_classes)\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\nmodel.to(device)","a1ff8f9e":"epochs = 10\ntrain_steps = len(train_ds)\nvalid_steps = len(valid_ds)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = torch.nn.CrossEntropyLoss()\nmetrics = {\"loss\": [], \"val_loss\": [], \"val_accuracy\": []}\nfor epoch in range(epochs):\n    train_losses = []\n    valid_losses = []\n    model.train()\n    begin = time.time()\n    for batch in train_ds:\n        optimizer.zero_grad()\n        inputs, targets = batch\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        output = model(inputs)\n        loss = loss_fn(output, targets)\n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.data.item())\n        if len(train_losses) > 0 and len(train_losses) % 20 == 0:\n            current = time.time()\n            elapsed = current - begin\n            print(\"Epoch %d: [Training] %.2fs\/%.2fs\"%(epoch + 1, elapsed, elapsed \/ float(len(train_losses)) * train_steps))\n    model.eval()\n    num_correct = 0\n    num_samples = 0\n    begin = time.time()\n    for batch in valid_ds:\n        optimizer.zero_grad()\n        inputs, targets = batch\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        output = model(inputs)\n        loss = loss_fn(output, targets)\n        valid_losses.append(loss.data.item())\n        correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n        num_correct += torch.sum(correct).item()\n        num_samples += correct.shape[0]\n        if len(valid_losses) > 0 and len(valid_losses) % 10 == 0:\n            current = time.time()\n            elapsed = current - begin\n            print(\"Epoch %d: [Validation] %.2fs\/%.2fs\"%(epoch + 1, elapsed, elapsed \/ float(len(valid_losses)) * valid_steps))\n    train_loss = torch.mean(torch.Tensor(train_losses)).item()\n    valid_loss = torch.mean(torch.Tensor(valid_losses)).item()\n    accuracy = num_correct \/ num_samples if num_samples > 0 else 0\n    metrics[\"loss\"].append(train_loss)\n    metrics[\"val_loss\"].append(valid_loss)\n    metrics[\"val_accuracy\"].append(accuracy)\n    print(\"Training Loss: %.2f Validation Loss: %.2f accuracy: %.2f\" %(train_loss, valid_loss, accuracy))","6869095c":"pd.DataFrame(metrics).plot()","42a32513":"np.random.choice(len(test_folder), 1)","47418e07":"labels = train_folder.classes\nfor i in np.random.choice(len(test_folder), 30):\n    item, actual = test_folder[i]\n    prediction = model(item.view(-1, 3, 64, 64).to(device)).argmax()\n    print(\"Prediction: %s Actual result: %s\"%(labels[prediction], labels[actual]))","70f02ac8":"path = \"bird_classfier\"\ntorch.save(model, path)","32975d56":"model = torch.load(path)","e5bf55c0":"## 4. Model Evaluation","ec539c0d":"# Bird Classification with PyTorch\n## Table of Contents\n* 1. Set up\n* 2. Import datasets\n* 3. Model Development\n* 4. Model Evaluation\n* 5. Make Predictions\n* 6. Save the Model\n\n## 1. Set up","e71cdd4f":"## 6. Save the Model","c252428a":"## 5. Make Predictions","ada13f00":"## 7. Load the Model","41f3b613":"### 3.2 Training","134f8472":"### Loss & Accuracy over time","e8c7f350":"### 3.1 The CNN Model","38415251":"## 2. Import datasets","e62b1c06":"## 3. Model Development"}}