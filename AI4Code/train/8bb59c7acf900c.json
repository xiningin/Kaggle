{"cell_type":{"52a15fb8":"code","a49cc5b0":"code","ca12ade1":"code","595eab33":"code","8fa96275":"code","18610b0d":"code","97de5a2d":"code","6e148406":"code","403fedd3":"code","2d029108":"code","cdb465d0":"code","8ba940d4":"code","a25b613a":"code","7fdfa3c3":"code","2ab141b4":"code","8492a751":"code","e92cc4cf":"code","5f695aa1":"code","cbb2472d":"code","e1d1260c":"code","7428edaa":"code","b578ec89":"code","aae4180b":"code","be7ae7f1":"code","2ad7e293":"code","99421d87":"code","fbb9e979":"code","a50190e6":"markdown","7f96175d":"markdown","7b611c88":"markdown","affdb778":"markdown","edd7ee12":"markdown","063813fc":"markdown","cd89533d":"markdown","eeec822b":"markdown","ab6bebe9":"markdown","867250ba":"markdown","06747049":"markdown","d2deba9a":"markdown","f9ec3811":"markdown","51d13c2e":"markdown","dd38293f":"markdown","62a6c865":"markdown","e679e06d":"markdown","5d21c90e":"markdown","1c8965da":"markdown","b3b749fc":"markdown","f253f5fc":"markdown"},"source":{"52a15fb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a49cc5b0":"import sklearn\nimport matplotlib.pyplot as plt\nimport math","ca12ade1":"D = pd.read_csv(\"..\/input\/flight-take-off-data-jfk-airport\/M1_final.csv\")\nD","595eab33":"D.info()","8fa96275":"from sklearn.preprocessing import LabelEncoder \nlabel = LabelEncoder()\n","18610b0d":"D['OP_UNIQUE_CARRIER'] = label.fit_transform(D['OP_UNIQUE_CARRIER'])\nD['TAIL_NUM'] = label.fit_transform(D['TAIL_NUM'])\nD['DEST'] = label.fit_transform(D['DEST'])\nD['Dew Point'] = label.fit_transform(D['Dew Point'])\nD['Condition']= label.fit_transform(D['Condition'])\nD['Wind'] = label.fit_transform(D['Wind'].astype(str))\nD.head()","97de5a2d":"X = D.drop(\"TAXI_OUT\",axis=1).values\nY = D[\"TAXI_OUT\"].values\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.10,shuffle= True)\nprint(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)","6e148406":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nl_linear = LinearRegression()\nl_linear = l_linear.fit(X_train,Y_train)\nl_linear_rms = (mean_squared_error(Y_test,l_linear.predict(X_test))**0.5)\nprint(l_linear_rms)","403fedd3":"from sklearn.linear_model import Ridge\n\nl_ridge = Ridge(alpha=0.05, normalize=True)\nl_ridge.fit(X_train,Y_train)\nl_ridge_rms = mean_squared_error(Y_test,l_ridge.predict(X_test))**0.5\nprint(l_ridge_rms)","2d029108":"from sklearn.linear_model import Lasso\n\nl_lasso = Lasso(alpha=0.05, normalize=True)\nl_lasso.fit(X_train,Y_train)\nl_lasso_rms = mean_squared_error(Y_test,l_lasso.predict(X_test))**0.5\nprint(l_lasso_rms)","cdb465d0":"from sklearn.neighbors import KNeighborsRegressor\n\nl_knn = KNeighborsRegressor(n_neighbors = 200)\nl_knn.fit(X_train, Y_train)\n\nl_knn_rms = mean_squared_error(Y_test,l_knn.predict(X_test))**0.5\nprint(l_knn_rms)","8ba940d4":"from sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\n\nSC1 = StandardScaler()\nSC2 = StandardScaler()\n\nX1 = X_train.copy()\nX2 = X_test.copy()\n\nX1 = SC1.fit_transform(X1)\nX2 = SC2.fit_transform(X2)\n\nsvr = SVR()\nsvr.fit(X1,Y_train)\n\nl_svr_rms = mean_squared_error(Y_test,svr.predict(X2),squared = False)\nprint(l_svr_rms)","a25b613a":"from sklearn.linear_model import BayesianRidge\n\nl_bayes = BayesianRidge()\nl_bayes.fit(X_train, Y_train)\n\nl_bayes_rms = mean_squared_error(Y_test,l_bayes.predict(X_test))**0.5\nprint(l_bayes_rms)","7fdfa3c3":"from sklearn.ensemble import RandomForestRegressor\n\nl_random = RandomForestRegressor()\nl_random.fit(X_train,Y_train)\n\nl_random_rms = mean_squared_error(Y_test,l_random.predict(X_test))**0.5\nprint(l_random_rms)","2ab141b4":"from lightgbm import LGBMRegressor\n\nl_lightgbm = LGBMRegressor()\nl_lightgbm.fit(X_train,Y_train)\n\nl_lightgbm_rms = mean_squared_error(Y_test,l_lightgbm.predict(X_test))**0.5\nprint(l_lightgbm_rms)","8492a751":"print(D['OP_UNIQUE_CARRIER'].unique())\nprint(D['TAIL_NUM'].unique()) \nprint(D['DEST'].unique())\nprint(D['Dew Point'].unique())\nprint(D['Wind'].unique())\nprint(D['Condition'].unique())\nD['DEST'].value_counts()","e92cc4cf":"Y = D[\"TAXI_OUT\"].values\nX = D.drop(\"TAXI_OUT\",axis=1)\nX = pd.get_dummies(X, columns=[\"MONTH\",\"DAY_OF_MONTH\",\"DAY_OF_WEEK\",\"OP_UNIQUE_CARRIER\",\"DEST\",\"Wind\",\"Condition\"])\n\nX.tail()","5f695aa1":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.10,shuffle= True)\nprint(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)","cbb2472d":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\no_linear = LinearRegression()\no_linear = o_linear.fit(X_train,Y_train)\n\no_linear_rms = (mean_squared_error(Y_test,o_linear.predict(X_test))**0.5)\nprint(o_linear_rms)","e1d1260c":"from sklearn.linear_model import Ridge\n\no_ridge = Ridge(alpha=0.05, normalize=True)\no_ridge.fit(X_train,Y_train)\n\no_ridge_rms = mean_squared_error(Y_test,o_ridge.predict(X_test))**0.5\nprint(o_ridge_rms)","7428edaa":"from sklearn.linear_model import Lasso\n\no_lasso = Lasso(alpha=0.05, normalize=True)\no_lasso.fit(X_train,Y_train)\n\no_lasso_rms = mean_squared_error(Y_test,o_lasso.predict(X_test))**0.5\nprint(o_lasso_rms)","b578ec89":"from sklearn.neighbors import KNeighborsRegressor\n\no_knn = KNeighborsRegressor(n_neighbors = 200)\no_knn.fit(X_train, Y_train)\n\no_knn_rms = mean_squared_error(Y_test,o_knn.predict(X_test))**0.5\nprint(o_knn_rms)","aae4180b":"from sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\n\nSC1 = StandardScaler()\nSC2 = StandardScaler()\n\nX1 = X_train.copy()\nX2 = X_test.copy()\n\nX1 = SC1.fit_transform(X1)\nX2 = SC2.fit_transform(X2)\n\nsvr = SVR()\nsvr.fit(X1,Y_train)\n\no_svr_rms = mean_squared_error(Y_test,svr.predict(X2),squared = False)\nprint(o_svr_rms)","be7ae7f1":"from sklearn.linear_model import BayesianRidge\n\no_bayes = BayesianRidge()\no_bayes.fit(X_train, Y_train)\n\no_bayes_rms = mean_squared_error(Y_test,o_bayes.predict(X_test))**0.5\nprint(o_bayes_rms)","2ad7e293":"from sklearn.ensemble import RandomForestRegressor\n\no_random = RandomForestRegressor()\no_random.fit(X_train,Y_train)\n\no_random_rms = mean_squared_error(Y_test,o_random.predict(X_test))**0.5\nprint(o_random_rms)","99421d87":"from lightgbm import LGBMRegressor\n\no_lightgbm = LGBMRegressor()\no_lightgbm.fit(X_train,Y_train)\n\no_lightgbm_rms = mean_squared_error(Y_test,o_lightgbm.predict(X_test))**0.5\nprint(o_lightgbm_rms)","fbb9e979":"l_array = np.array([l_linear_rms,l_ridge_rms,l_lasso_rms,l_knn_rms,l_svr_rms,l_bayes_rms,l_random_rms,l_lightgbm_rms])\no_array = np.array([o_linear_rms,o_ridge_rms,o_lasso_rms,o_knn_rms,o_svr_rms,o_bayes_rms,o_random_rms,o_lightgbm_rms])\nmodels = [\"LNR\",\"RR\",\"LSR\",\"KNNR\",\"SVR\",\"BR\",\"RFR\",\"LGBM\"]\nplt.plot(models,l_array)\nplt.plot(models,o_array)\nplt.legend([\"Label Encoding\",\"One Hot Encoding\"])\nplt.xlabel(\"ML Models\")\nplt.ylabel(\"RMSE\")\nplt.show()","a50190e6":"**lightgbm**","7f96175d":"**random forest**","7b611c88":"**svr**","affdb778":"**lable encoding**","edd7ee12":"**splitting features and outcome**","063813fc":"**one hot encoding**","cd89533d":"**naive bayes**","eeec822b":"**splitting features and outcome**","ab6bebe9":"**ridge regression**","867250ba":"**comparision**","06747049":"**naive bayes**","d2deba9a":"**svr**","f9ec3811":"**lasso regression**","51d13c2e":"**linear regression**","dd38293f":"**linear regression**","62a6c865":"**random forest**","e679e06d":"**lightgbm******","5d21c90e":"**lasso regression**","1c8965da":"**ridge regression**","b3b749fc":"**knn**","f253f5fc":"**knn**"}}