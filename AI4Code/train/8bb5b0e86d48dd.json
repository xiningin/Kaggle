{"cell_type":{"a4b7fa11":"code","71a74639":"code","2ff14429":"code","4a0e5c94":"code","8af4f340":"code","96ad3c46":"code","9ee7e8a8":"code","8c7f6e4c":"code","60037349":"code","cce4173b":"code","33ea3d49":"code","c5fc30f0":"code","b357bc14":"code","44d5f4ec":"code","713e6f2e":"code","1740410f":"code","f488569c":"code","cc63f446":"code","768bb16f":"code","b572109b":"code","dfa517de":"code","14aace7a":"code","9a12cdd6":"code","c4207602":"markdown","e4d4f793":"markdown","151db22d":"markdown","6bd389ce":"markdown","243dca9d":"markdown","4a6343d5":"markdown","618f450a":"markdown","e7c002df":"markdown","4b164898":"markdown","1594c8e0":"markdown","21d4adb5":"markdown","ebf53209":"markdown","9cf282ec":"markdown","4317c4b1":"markdown","84308912":"markdown","fc3b71a4":"markdown"},"source":{"a4b7fa11":"import numpy as np\nimport pandas as pd","71a74639":"train = pd.read_csv('UCI_HAR_dataset\/csv_files\/train.csv')\ntest = pd.read_csv('UCI_HAR_dataset\/csv_files\/test.csv')\nprint(train.shape, test.shape)\n\n","2ff14429":"train.head(3)","4a0e5c94":"# get X_train and y_train from csv files\nX_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\ny_train = train.ActivityName","8af4f340":"# get X_test and y_test from test csv file\nX_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\ny_test = test.ActivityName","96ad3c46":"print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\nprint('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))","9ee7e8a8":"labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']","8c7f6e4c":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","60037349":"from datetime import datetime\ndef perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True, cm_cmap=plt.cm.Greens):\n    \n    \n    # to store results at various phases\n    results = dict()\n    \n    # time at which model starts training \n    train_start_time = datetime.now()\n    print('training the model..')\n    model.fit(X_train, y_train)\n    print('Done \\n \\n')\n    train_end_time = datetime.now()\n    results['training_time'] =  train_end_time - train_start_time\n    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n    \n    \n    # predict test data\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred = model.predict(X_test)\n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n   \n\n    # calculate overall accuracty of the model\n    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n    \n    # confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(8,8))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n    plt.show()\n    \n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_report = metrics.classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_report'] = classification_report\n    print(classification_report)\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return results\n    \n    ","cce4173b":"def print_grid_search_attributes(model):\n    # Estimator that gave highest score among all the estimators formed in GridSearch\n    print('--------------------------')\n    print('|      Best Estimator     |')\n    print('--------------------------')\n    print('\\n\\t{}\\n'.format(model.best_estimator_))\n\n\n    # parameters that gave best results while performing grid search\n    print('--------------------------')\n    print('|     Best parameters     |')\n    print('--------------------------')\n    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n\n\n    #  number of cross validation splits\n    print('---------------------------------')\n    print('|   No of CrossValidation sets   |')\n    print('--------------------------------')\n    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n\n\n    # Average cross validated score of the best estimator, from the Grid Search \n    print('--------------------------')\n    print('|        Best Score       |')\n    print('--------------------------')\n    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n\n    \n    ","33ea3d49":"from sklearn import linear_model\nfrom sklearn import metrics\n\nfrom sklearn.model_selection import GridSearchCV","c5fc30f0":"\n# start Grid search\nparameters = {'C':[0.01, 0.1, 1, 10, 20, 30], 'penalty':['l2','l1']}\nlog_reg = linear_model.LogisticRegression()\nlog_reg_grid = GridSearchCV(log_reg, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)\nlog_reg_grid_results =  perform_model(log_reg_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n","b357bc14":"plt.figure(figsize=(8,8))\nplt.grid(b=False)\nplot_confusion_matrix(log_reg_grid_results['confusion_matrix'], classes=labels, cmap=plt.cm.Greens, )\nplt.show()","44d5f4ec":"# observe the attributes of the model \nprint_grid_search_attributes(log_reg_grid_results['model'])","713e6f2e":"from sklearn.svm import LinearSVC","1740410f":"parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}\nlr_svc = LinearSVC(tol=0.00005)\nlr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, n_jobs=-1, verbose=1)\nlr_svc_grid_results = perform_model(lr_svc_grid, X_train, y_train, X_test, y_test, class_labels=labels)","f488569c":"print_grid_search_attributes(lr_svc_grid_results['model'])","cc63f446":"from sklearn.svm import SVC\nparameters = {'C':[2,8,16],\\\n              'gamma': [ 0.0078125, 0.125, 2]}\nrbf_svm = SVC(kernel='rbf')\nrbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters, n_jobs=-1)\nrbf_svm_grid_results = perform_model(rbf_svm_grid, X_train, y_train, X_test, y_test, class_labels=labels)","768bb16f":"print_grid_search_attributes(rbf_svm_grid_results['model'])","b572109b":"from sklearn.tree import DecisionTreeClassifier\nparameters = {'max_depth':np.arange(3,10,2)}\ndt = DecisionTreeClassifier()\ndt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=-1)\ndt_grid_results = perform_model(dt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(dt_grid_results['model'])","dfa517de":"from sklearn.ensemble import RandomForestClassifier\nparams = {'n_estimators': np.arange(10,201,20), 'max_depth':np.arange(3,15,2)}\nrfc = RandomForestClassifier()\nrfc_grid = GridSearchCV(rfc, param_grid=params, n_jobs=-1)\nrfc_grid_results = perform_model(rfc_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(rfc_grid_results['model'])","14aace7a":"from sklearn.ensemble import GradientBoostingClassifier\nparam_grid = {'max_depth': np.arange(5,8,1), \\\n             'n_estimators':np.arange(130,170,10)}\ngbdt = GradientBoostingClassifier()\ngbdt_grid = GridSearchCV(gbdt, param_grid=param_grid, n_jobs=-1)\ngbdt_grid_results = perform_model(gbdt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(gbdt_grid_results['model'])","9a12cdd6":"print('\\n                     Accuracy     Error')\nprint('                     ----------   --------')\nprint('Logistic Regression : {:.04}%       {:.04}%'.format(log_reg_grid_results['accuracy'] * 100,\\\n                                                  100-(log_reg_grid_results['accuracy'] * 100)))\n\nprint('Linear SVC          : {:.04}%       {:.04}% '.format(lr_svc_grid_results['accuracy'] * 100,\\\n                                                        100-(lr_svc_grid_results['accuracy'] * 100)))\n\nprint('rbf SVM classifier  : {:.04}%      {:.04}% '.format(rbf_svm_grid_results['accuracy'] * 100,\\\n                                                          100-(rbf_svm_grid_results['accuracy'] * 100)))\n\nprint('DecisionTree        : {:.04}%      {:.04}% '.format(dt_grid_results['accuracy'] * 100,\\\n                                                        100-(dt_grid_results['accuracy'] * 100)))\n\nprint('Random Forest       : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n                                                           100-(rfc_grid_results['accuracy'] * 100)))\nprint('GradientBoosting DT : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n                                                        100-(rfc_grid_results['accuracy'] * 100)))","c4207602":"# 1. Logistic Regression with Grid Search","e4d4f793":"# 6.  Gradient Boosted Decision Trees With GridSearch","151db22d":"#  2. Linear SVC with GridSearch","6bd389ce":"# 5. Random Forest Classifier with GridSearch","243dca9d":"\n# 7. Comparing all models","4a6343d5":"### Generic function to run any model specified","618f450a":"### Function to plot the confusion matrix","e7c002df":"### Labels that are useful in plotting confusion matrix","4b164898":"### Method to print the gridsearch Attributes","1594c8e0":"# Conclusion :","21d4adb5":"# 3.  Kernel SVM with GridSearch","ebf53209":"# Let's model with our data","9cf282ec":"> We can choose ___Logistic regression___ or ___Linear SVC___ or ___rbf SVM___.","4317c4b1":"# 4. Decision Trees with GridSearchCV","84308912":"In the real world, domain-knowledge, EDA and feature-engineering matter most.","fc3b71a4":"## Obtain the train and test data"}}