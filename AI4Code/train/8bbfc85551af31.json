{"cell_type":{"82e93c7a":"code","ea24ed45":"code","8ec4cbdb":"code","88a8e574":"code","cd3182bf":"code","93916f5a":"code","3f1a3e81":"code","a315c24c":"code","c4ad15a9":"code","a80b3813":"code","fefbd994":"code","80f51cf8":"code","e1f7dac5":"code","daac22f4":"code","0ec1aad8":"code","ab741899":"code","554689e8":"code","b04221ad":"code","7c66240f":"code","90f47972":"code","2f963c4e":"code","311b054c":"code","c0a8a0e8":"code","e9e98665":"code","6b7b8282":"markdown","055cf966":"markdown","cb83f8fc":"markdown","79a8f5bc":"markdown","7890928f":"markdown","4cf1ef34":"markdown","4aa166e5":"markdown","efd1aee7":"markdown","e2d6bff2":"markdown","c170ef2f":"markdown","d6fafb03":"markdown","44320776":"markdown","7ee633b6":"markdown","81c740db":"markdown","fe811d59":"markdown","8e528619":"markdown","1cd6bf8e":"markdown","a3be457a":"markdown","e6994c94":"markdown","99d9505a":"markdown","0b747d8d":"markdown","8c496568":"markdown","f3ed1312":"markdown","88eb199d":"markdown","1f1f98bd":"markdown","97af1790":"markdown","2816a6c1":"markdown","c52b0af7":"markdown","5823821f":"markdown","71ef7092":"markdown","388c48b6":"markdown","cafec9e4":"markdown","24007674":"markdown","6608a5a9":"markdown","0eba3a38":"markdown","331a106a":"markdown","4dcb2c6e":"markdown","98e9b90d":"markdown"},"source":{"82e93c7a":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style = \"darkgrid\")\nimport pydicom as dcm\nimport matplotlib.cm as cm\nimport gc","ea24ed45":"df_train = pd.read_csv(\"..\/input\/rsna-str-pulmonary-embolism-detection\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/rsna-str-pulmonary-embolism-detection\/test.csv\")\ndf_sub = pd.read_csv(\"..\/input\/rsna-str-pulmonary-embolism-detection\/sample_submission.csv\")","8ec4cbdb":"df_train.head().T","88a8e574":"df_train.shape","cd3182bf":"train_cols = ['pe_present_on_image', 'negative_exam_for_pe', 'qa_motion',\n       'qa_contrast', 'flow_artifact', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1',\n       'leftsided_pe', 'chronic_pe', 'true_filling_defect_not_pe',\n       'rightsided_pe', 'acute_and_chronic_pe', 'central_pe', 'indeterminate']","93916f5a":"count = 0\nfor col in train_cols:\n    if len(df_train[col].value_counts())==2:\n        count += 1\nif count==len(train_cols):\n    print(\"All the features other than UID's are Binary features.\")","3f1a3e81":"def plot_grid(cols = train_cols):\n    fig=plt.figure(figsize=(8, 22))\n    columns = 2\n    rows = 7\n    for i in range(1, columns*rows + 1):\n        col = cols[i-1]\n        fig.add_subplot(rows, columns, i)\n        df_train[col].value_counts().plot(kind = \"bar\", color = \"Purple\", alpha = 0.4)\n        count_0 = df_train[col].value_counts()[0]\n        count_1 = df_train[col].value_counts()[1]\n        ratio = count_0\/count_1\n        plt.xlabel(f\"Feature name: {col}\\n Count 0: {count_0}\\n Count 1: {count_1}\\n Ratio(0:1): {ratio:.1f}:1\")\n    plt.tight_layout()\n    plt.show()\n\nplot_grid()","a315c24c":"corr_mat = df_train[train_cols].corr()\nmask = np.triu(np.ones_like(corr_mat, dtype=bool))\nf, ax = plt.subplots(figsize=(14, 12))\nsns.heatmap(corr_mat, mask = mask, cmap = \"summer\", annot = True, vmax = 0.3, square = False, linewidths = 0.5, center = 0)","c4ad15a9":"def details_first_three(df = df_train):\n    print(f\"Number of unique entries in StudyInstanceUID: {len(df.StudyInstanceUID.value_counts())}\")\n    print(f\"Number of unique entries in SeriesInstanceUID: {len(df.SeriesInstanceUID.value_counts())}\")\n    print(f\"Number of unique entries in SOPInstanceUID: {len(df.SOPInstanceUID.value_counts())}\")\ndetails_first_three()","a80b3813":"df_test.head(3)","fefbd994":"df_test.shape","80f51cf8":"details_first_three(df_test)","e1f7dac5":"df_sub.head(3)","daac22f4":"df_sub.shape","0ec1aad8":"df_sub[\"label_features\"] = df_sub.id.apply(lambda x: \"_\".join(x.split(\"_\")[1:]))","ab741899":"df_sub.label_features[df_sub.label_features == \"\"] = \"UID\"","554689e8":"df_sub.label_features.value_counts()","b04221ad":"img_addr = [\"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/0003b3d648eb\/d2b2960c2bbf\/00ac73cfc372.dcm\", \n           \"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/005df0f53614\/5e0e0d0b7a65\/081c2fa491a1.dcm\",\n           \"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/0072baad76be\/d555455a1dc2\/096497b1da4e.dcm\", \n           \"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/00d4f4409f0c\/38a51605b9ab\/079e029c0d1a.dcm\", \n           \"..\/input\/rsna-str-pulmonary-embolism-detection\/test\/00e7015490cb\/291c07d4a7c0\/09c25538116c.dcm\", \n            \"..\/input\/rsna-str-pulmonary-embolism-detection\/test\/0227030d6278\/599fccda6e2b\/0c247bfd9c27.dcm\", \n           \"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/00102474a2db\/c1a6d49ce580\/06ce8f7a39ae.dcm\", \n           \"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/00102474a2db\/c1a6d49ce580\/0fd29873e8e4.dcm\",\n           \"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/00617c9fe236\/16ed05bf3395\/01d00e27c5ac.dcm\", \n            \"..\/input\/rsna-str-pulmonary-embolism-detection\/test\/08115e1b649d\/f69e3f9c7067\/10ba32beefb2.dcm\"]","7c66240f":"def plot_image_grid(addresses = img_addr):\n    fig=plt.figure(figsize=(12, 12))\n    columns = 5\n    rows = 2\n    for i in range(1, columns*rows + 1):\n        addr = addresses[i-1]\n        fig.add_subplot(rows, columns, i)\n        plt.imshow(dcm.dcmread(addr).pixel_array)\n        plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\nplot_image_grid()","90f47972":"dicom_atts = [\"SpecificCharacterSet\",\"ImageType\",\"SOPInstanceUID\",\"Modality\",\"Manufacturer\", \"ManufacturerModelName\",\"PatientName\",\"PatientID\",\n             \"PatientSex\",\"DeidentificationMethod\",\"BodyPartExamined\",\"SliceThickness\", \"KVP\",\"SpacingBetweenSlices\",\"DistanceSourceToDetector\",\n              \"DistanceSourceToPatient\",\"GantryDetectorTilt\", \"TableHeight\",\"RotationDirection\",\"XRayTubeCurrent\",\"GeneratorPower\",\n              \"FocalSpots\",\"ConvolutionKernel\",\"PatientPosition\",\"RevolutionTime\", \"SingleCollimationWidth\",\"TotalCollimationWidth\",\"TableSpeed\",\"TableFeedPerRotation\",\n              \"SpiralPitchFactor\", \"StudyInstanceUID\",\"SeriesInstanceUID\",\"StudyID\",\"InstanceNumber\",\"PatientOrientation\",\n              \"ImagePositionPatient\",\"ImageOrientationPatient\",\"FrameOfReferenceUID\",\"PositionReferenceIndicator\",\n              \"SliceLocation\",\"SamplesPerPixel\",\"PhotometricInterpretation\", \"Rows\",\"Columns\",\"PixelSpacing\",\"BitsAllocated\",\"BitsStored\",\"HighBit\",\n              \"PixelRepresentation\",\"PixelPaddingValue\",\"WindowCenter\",\"WindowWidth\",\"RescaleIntercept\", \"RescaleSlope\",\"RescaleType\"]\n\nlist_attributes = [\"ImageType\",\"ImagePositionPatient\",\"ImageOrientationPatient\",\"PixelSpacing\"]\n\ndef dicom_metadata(folder_path):\n    files = os.listdir(folder_path)\n    patient_id = folder_path.split('\/')[-1]\n    \n    ## Each row is an image file:\n    base_data = {'Patient': [patient_id]*len(files), 'File': files}\n    patient_df = pd.DataFrame(data=base_data)\n    \n    ## Add Columns by looping through DICOM attributes for each image file:\n    slices = [dcm.dcmread(folder_path + '\/' + s) for s in files] \n    for d in dicom_atts:\n        attribute_i = []\n        for s in slices:\n            try:\n                attribute_i.append(s[d].value)\n            except:\n                attribute_i.append(np.nan)\n        patient_df[d] = attribute_i\n        \n    ## Store min pixel value for each image file \n    attribute_min_pixel = []\n    for s in slices:\n        try:\n            mp = np.min(s.pixel_array.astype(np.int16).flatten())\n        except:\n            mp = np.nan\n        attribute_min_pixel.append(mp)\n    patient_df[\"MinPixelValue\"] = attribute_min_pixel\n  \n    return patient_df","2f963c4e":"df = dicom_metadata(\"..\/input\/rsna-str-pulmonary-embolism-detection\/test\/00268ff88746\/75d23269adbd\")","311b054c":"df.head(3)","c0a8a0e8":"print(f\"CT Scan resolution is: {df.Rows.value_counts().index[0]}x{df.Columns.value_counts().index[0]}\")","e9e98665":"del df_train, df_test, df_sub, df, count, dicom_atts, list_attributes, img_addr, corr_mat, mask, train_cols\ngc.collect()","6b7b8282":"> Seems like we need to predict some \"label\" for the entries from test file.","055cf966":"> Let's now see what Submission files looks like and what do we need to predict?","cb83f8fc":"> Also, we know from the competition's data overview that SOPInstanceUID is a Unique Identifier for a image and to verify it, we can see that the number of unique SOP values is same as length of train data.","79a8f5bc":"> Now, Let's talk a little about test data.","7890928f":"I hope you like the work, I will make sure to update this over time. Please leave your comments down below in case of any suggestions.\n\nThanks for reading and Good Luck with the competition! :)","4cf1ef34":"> Unique values for first three features.","4aa166e5":"> Let's now talk a little bit about train.csv file.","efd1aee7":"> Now, we can see that we need to predict values for the above mentioned labels other than the UID itself.\n\nActually, this verifies the information provided by Jebastin Nadar in a discussion that:\n\n> *Each study has multiple images. We have to predict labels for images as well as studies.*\n    \n> *Image level - predict for each image i.e SOPInstanceUID*\n  \n> *Labels to predict : pe_present_on_image*\n    \n> *Study level - predict for each study i.e StudyInstanceUID*\n    \n> *Labels to predict : negative_exam_for_pe , indeterminate, rv_lv_ratio_gte_1, rv_lv_ratio_lt_1, leftsided_pe, rightsided_pe, central_pe, chronic_pe, acute_and_chronic_pe*\n","e2d6bff2":"> Now, we can see that the number of uniques entries for both Study and Series Instance UID is same.","c170ef2f":"> Let's now see some of the values from this data too!","d6fafb03":"> Let's see the total number of unique values in \"StudyInstanceUID\", \"SeriesInstanceUID\" and \"SOPInstanceUID\".","44320776":"* Bonus for reaching this far!\n\nNote: We can fetch the metadata details from the dcm image by using the following function (dicom_metadata).","7ee633b6":"> Let's now plot the two categories of all features side by side and see the count of values.","81c740db":"> Let's now see the data!","fe811d59":"> Now, there are a total of 58 columns in the metadata, many features being not of any use, some are helpful too.\n> Let's see the resolution of most of the scans available.","8e528619":"## Reading and Understanding the files","1cd6bf8e":"> Shape of train data","a3be457a":"> Okay, so now, We know that All of the remaining features from training file are binary features.","e6994c94":"> Now, we know by the Overview page of this competition that : \n\n> *In this competition we are predicting a number of labels, at both the image and study level. Note that some labels are logically mutually exclusive.*","99d9505a":"> Let's now see the correlation between all the binary features available in the data.","0b747d8d":"> Let's pick some random image addresses.","8c496568":"## Bonus: DICOM Metadata!","f3ed1312":"> So with this plot, we can now see that the classes are not that balanced in between all those features.\n> Many of them have count of \"0\" to be very high in comparision to \"1\" and vice versa. ","88eb199d":"## Importing essential Libraries","1f1f98bd":"* We can see that SOPInstanceUID is available here in the metadata. So, now, it'll be very easy for us to join the dataframes if we want to do so.\n* Also, \"Patient\" is nothing but the SeriesInstanceUID.\n* We conclude that StudyInstanceUID is also in the metadata.","97af1790":"> It seems 3 features are object and all other are int. Let's see the cardinality of remaining features.","2816a6c1":"> Shape of test data","c52b0af7":"> Seems like the case for Study and Series Instance UID is same here as train.","5823821f":"### What do we predict?","71ef7092":"> Shape of Submission file","388c48b6":"> Now, finally, let's see some of the images provided to us in train and test folders.","cafec9e4":"Competition Overview:\n\n> If every breath is strained and painful, it could be a serious and potentially life-threatening condition. A pulmonary embolism (PE) is caused by an artery blockage in the lung. It is time consuming to confirm a PE and prone to overdiagnosis. Machine learning could help to more accurately identify PE cases, which would make management and treatment more effective for patients.\nCurrently, CT pulmonary angiography (CTPA), is the most common type of medical imaging to evaluate patients with suspected PE. These CT scans consist of hundreds of images that require detailed review to identify clots within the pulmonary arteries. As the use of imaging continues to grow, constraints of radiologists\u2019 time may contribute to delayed diagnosis.\nThe Radiological Society of North America (RSNA\u00ae) has teamed up with the Society of Thoracic Radiology (STR) to help improve the use of machine learning in the diagnosis of PE.\nIn this competition, you\u2019ll detect and classify PE cases. In particular, you'll use chest CTPA images (grouped together as studies) and your data science skills to enable more accurate identification of PE. If successful, you'll help reduce human delays and errors in detection and treatment.\nWith 60,000-100,000 PE deaths annually in the United States, it is among the most fatal cardiovascular diseases. Timely and accurate diagnosis will help these patients receive better care and may also improve outcomes.\n\n\n![Image](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F603584%2F9a3aac7e7ac865f134201cc2a5cd52f3%2Fkaggle_header3.png?generation=1599585319459400&alt=media)","24007674":"> Almost all of the features seems to be containing unique information which is good for us!","6608a5a9":"> Amazing, Isn't it? :)","0eba3a38":"> Let's now explore the data! :)","331a106a":"## Visualizing some of the Scans","4dcb2c6e":"> Let's now check what these labels really are.","98e9b90d":"> For example: let's fetch the metadata for images from \"test\/00268ff88746\/75d23269adbd\" directory."}}