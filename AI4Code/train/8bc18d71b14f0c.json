{"cell_type":{"fa88d97c":"code","a44c3120":"code","f5c18936":"code","2edb9374":"code","7c7197e3":"code","8da718ed":"code","15f6167c":"code","dcb4869f":"code","e256d606":"code","721952d8":"code","a80c91b8":"code","62d72c42":"code","13479a1d":"code","a7f2a9a7":"code","a9454df3":"code","06e203f9":"code","3ea37321":"code","0507687c":"code","b05ff46a":"code","f585fd2c":"code","c675b313":"code","f60801a4":"code","c834d977":"code","9888c3c3":"code","6b08ee87":"markdown","4a5aa550":"markdown","97bbcec0":"markdown","17721534":"markdown","b2572308":"markdown","894575c2":"markdown","db101e4c":"markdown","f616445e":"markdown"},"source":{"fa88d97c":"import os\nos.listdir(\"..\/input\/plant-diseases-classification-using-alexnet\")","a44c3120":"\n#Import tensorflow and keras library\nimport tensorflow as tf\nimport keras_preprocessing\nfrom tensorflow.keras.preprocessing import image\nimport pickle\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import TensorBoard\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nimport keras\n\nprint(\"[INFO]: Tensorflow version{}\".format(tf.__version__))\nstate_gpu = tf.test.gpu_device_name()\nprint(\"[INFO]: GPU usage{0}\".format(state_gpu))","f5c18936":"# Initializing the CNN\nclassifier = Sequential()\n\n# Convolution Step 1\nclassifier.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\n\n# Max Pooling Step 1\nclassifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 2\nclassifier.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n\n# Max Pooling Step 2\nclassifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 3\nclassifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 4\nclassifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 5\nclassifier.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n\n# Max Pooling Step 3\nclassifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nclassifier.add(BatchNormalization())\n\n# Flattening Step\nclassifier.add(Flatten())\n\n# Full Connection Step\nclassifier.add(Dense(units = 4096, activation = 'relu'))\nclassifier.add(Dropout(0.4))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(units = 4096, activation = 'relu'))\nclassifier.add(Dropout(0.4))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(units = 1000, activation = 'relu'))\nclassifier.add(Dropout(0.2))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(units = 38, activation = 'softmax'))\nclassifier.summary()","2edb9374":"classifier.load_weights('..\/input\/plant-diseases-classification-using-alexnet\/best_weights_9.hdf5')","7c7197e3":"# Truncate and replace softmax layer for transfer learning\nnum_classes = 10   \nclassifier2 = Sequential()\nfor layer in classifier.layers[:-2]: # go through until last layer\n    classifier2.add(layer)\n\nclassifier2.summary()\nclassifier2.add(Dense(num_classes, activation='softmax'))\nclassifier2.summary()\n\n","8da718ed":"# Compiling the Model\nfrom keras import optimizers\n\"\"\"\nclassifier.compile(optimizer=optimizers.SGD(lr=0.001, momentum=0.9, decay=0.005),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\"\"\"\nLEARNING_RATE = 0.0001\n#LEARNING_RATE = 0.001\n\n#Optimizer\nopt = Adam(lr = LEARNING_RATE)\nclassifier2.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","15f6167c":"\n# this is the augmentation configuration we will use for training\ntrain_gen = ImageDataGenerator(\nrescale = 1.\/255,\nwidth_shift_range=0.2,\nheight_shift_range=0.2,\nshear_range=0.2,\nzoom_range=0.2,\nhorizontal_flip=True,\nfill_mode='nearest')\n\nvalid_gen = ImageDataGenerator(rescale = 1.\/255)","dcb4869f":"# ImageDataGenerator and get train data and validation data\nTRAINING_DIR = '..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/' \nVALIDATION_DIR = '..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/'\n","e256d606":"TARGET_SIZE = (224,224)\nTRAIN_BATCH_SIZE = 128\nVALID_BATCH_SIZE = 128\nSEED = 42\n\n#Data Iterator\ntrain_data = train_gen.flow_from_directory(\nTRAINING_DIR,\ntarget_size = TARGET_SIZE,\nclass_mode = 'categorical',\ncolor_mode = \"rgb\",\nbatch_size = TRAIN_BATCH_SIZE,\nshuffle = True,\nseed = SEED\n)\n\nvalid_data = valid_gen.flow_from_directory(\nVALIDATION_DIR,\ntarget_size = TARGET_SIZE,\nclass_mode = 'categorical',\ncolor_mode = \"rgb\",\nbatch_size = VALID_BATCH_SIZE\n)","721952d8":"TRAINING_NUM = train_data.n #or train_data.samples\nVALID_NUM = valid_data.n\nEPOCHS = 25\n\nSTEP_SIZE_TRAIN = TRAINING_NUM \/\/ TRAIN_BATCH_SIZE \nSTEP_SIZE_VALID = VALID_NUM \/\/ VALID_BATCH_SIZE\n\n#Train Model\nhistory = classifier2.fit_generator(generator = train_data,\n                    steps_per_epoch = STEP_SIZE_TRAIN,\n                    validation_data = valid_data,\n                    validation_steps = STEP_SIZE_VALID,\n                    epochs = EPOCHS,\n                    verbose=1\n)\n","a80c91b8":"#Save Model\nfilepath=\"Model_stage2_conf1.hdf5\"\nclassifier2.save(filepath)\n\nfilepath2=\"Model_wieghts_stage2_conf1.h5\"\nclassifier2.save_weights(filepath2)","62d72c42":"best_val_acc = max(history.history['val_acc'])\nprint(best_val_acc)","13479a1d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n#Plot Accuracy and Loss\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","a7f2a9a7":"# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfrom keras import layers\nfor i, layer in enumerate(classifier.layers):\n   print(i, layer.name)","a9454df3":"# we chose to train the top 2 conv blocks, i.e. we will freeze\n# the first 8 layers and unfreeze the rest:\nprint(\"Freezed layers:\")\nfor i, layer in enumerate(classifier.layers[:20]):\n    print(i, layer.name)\n    layer.trainable = False\n","06e203f9":"#trainable parameters decrease after freezing some bottom layers   \nclassifier.summary()","3ea37321":"# Compiling the Model\nfrom keras import optimizers\nclassifier.compile(optimizer=optimizers.SGD(lr=0.001, momentum=0.9, decay=0.005),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","0507687c":"# image preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\n\nbatch_size = 128\nbase_dir = \"..\/input\/new-plant-diseases-dataset\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\"\n\ntraining_set = train_datagen.flow_from_directory(base_dir+'\/train',\n                                                 target_size=(224, 224),\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagen.flow_from_directory(base_dir+'\/valid',\n                                            target_size=(224, 224),\n                                            batch_size=batch_size,\n                                            class_mode='categorical')","b05ff46a":"class_dict = training_set.class_indices\nprint(class_dict)","f585fd2c":"li = list(class_dict.keys())\nprint(li)","c675b313":"train_num = training_set.samples\nvalid_num = valid_set.samples","f60801a4":"# checkpoint\nfrom keras.callbacks import ModelCheckpoint\nweightpath = \"best_weights_9.hdf5\"\ncheckpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\n#fitting images to CNN\nhistory = classifier.fit_generator(training_set,\n                         steps_per_epoch=train_num\/\/batch_size,\n                         validation_data=valid_set,\n                         epochs=25,\n                         validation_steps=valid_num\/\/batch_size,\n                         callbacks=callbacks_list)\n#saving model\nfilepath=\"AlexNetModel.hdf5\"\nclassifier.save(filepath)","c834d977":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","9888c3c3":"# predicting an image\nfrom keras.preprocessing import image\nimport numpy as np\nimage_path = \"..\/input\/new-plant-diseases-dataset\/test\/test\/TomatoEarlyBlight1.JPG\"\nnew_img = image.load_img(image_path, target_size=(224, 224))\nimg = image.img_to_array(new_img)\nimg = np.expand_dims(img, axis=0)\nimg = img\/255\n\nprint(\"Following is our prediction:\")\nprediction = classifier.predict(img)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nd = prediction.flatten()\nj = d.max()\nfor index,item in enumerate(d):\n    if item == j:\n        class_name = li[index]\n\n##Another way\n# img_class = classifier.predict_classes(img)\n# img_prob = classifier.predict_proba(img)\n# print(img_class ,img_prob )\n\n\n#ploting image with predicted class name        \nplt.figure(figsize = (4,4))\nplt.imshow(new_img)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","6b08ee87":"**Compiling the Model**","4a5aa550":"**Loading Weights To The Model**","97bbcec0":"**Visualising Training Progress**","17721534":"**Model Summary After Freezing**","b2572308":"**Image Preprocessing**","894575c2":"**Predicting New Test Image(s)**","db101e4c":"**Fine Tuning By Freezing Some Layers Of Our Model**","f616445e":"**Building CNN Based On AlexNet Architecture**"}}