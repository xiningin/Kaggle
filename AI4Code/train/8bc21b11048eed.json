{"cell_type":{"f41f86f9":"code","672660ec":"code","c33a09f6":"code","ac3a526d":"code","6994654e":"code","17eb2af1":"code","de4ed41d":"code","97e4bdc1":"code","8532513f":"code","c737cadf":"markdown","ce815b6f":"markdown","3b6fa120":"markdown","5bdc44ef":"markdown"},"source":{"f41f86f9":"! conda install -c conda-forge gdcm -y","672660ec":"import numpy as np\nimport pandas as pd \nimport os\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nimport cv2\nimport warnings\nimport albumentations as A","c33a09f6":"# config params\nclass CFG:\n    data_path = '..\/input\/siim-covid19-detection\/'\n    size = 512\n    seed = 2021\n    working_dir = '\/kaggle\/working\/'","ac3a526d":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n","6994654e":"# storage file for the transformed images\n!mkdir train","17eb2af1":"# prepare a dataframe for producing resized images with bboxes\nxtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')\n\n\npath_list = []\nimage_list = []\nsplits = []\n\nfor split in ['train']:\n    \n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            fullpath = dirname + '\/' + file\n            path_list.append(fullpath)\n            image_list.append(file)\n\ndf = pd.DataFrame(image_list, columns =['image_id'])\ndf['image_path'] = path_list\n\nxtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')\nxtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')\n","de4ed41d":"# common transformation we shall use\ntransform = A.Compose(\n    [\n        A.Resize(height = CFG.size , width = CFG.size, p=1),\n    ], \n    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        \n\nimg_list = []\nlabel_list = []\n\n# loop over files\nfor ii in range(len(xtrain_img)):\n    # get the image\n    row = xtrain_img.loc[ii]\n    img_path = row['image_path']\n    img = dicom2array(path=img_path)\n    newname = img_path.split('\/')[-1].replace('dcm', 'jpg')\n    img_list.append(newname)\n    \n    # get the bounding boxes\n    bboxes = []\n    bbox = []\n    labels = []\n    confidences = []\n\n    for i, l in enumerate(row['label'].split(' ')):\n        if (i % 6 == 0) :\n            labels.append(l)\n        if (i % 6 == 1):\n            confidences.append(l)\n        if (i % 6 > 1):\n            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []    \n\n    # transform both\n    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))\n    new_image = result['image']\n    new_bboxes = np.array(result['bboxes']).tolist()\n\n    # format the output\n#    print('orig label: ' + row['label'])\n    newlabel = ''\n    if labels[0] == 'none':\n        newlabel = 'none 1 0 0 1 1'\n    else:\n        for j in range(len(labels)):\n            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '\n#    print('new label:' + newlabel)\n    label_list.append(newlabel)\n    \n    # store the new image\n    cv2.imwrite(CFG.working_dir + 'train\/' + newname , new_image)","97e4bdc1":"# store the new boxes with image_ids\nxmeta = pd.DataFrame(img_list, columns =['image_id'])\nxmeta['label'] = label_list\nxmeta.to_csv('bounding_boxes.csv', index = False)","8532513f":"# wrap it up\n!zip -rm -qq rescaled_with_bb.zip train bounding_boxes.csv","c737cadf":"# Functions","ce815b6f":"# Data","3b6fa120":"# Generation","5bdc44ef":"Adapted from: \n* https:\/\/www.kaggle.com\/phunghieu\/gwd-resize-images-bboxes\n* https:\/\/www.kaggle.com\/muhammadimran112233\/siim-a-data-science-approach-starter"}}