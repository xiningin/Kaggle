{"cell_type":{"4952edff":"code","8c35ef0e":"code","4aff83ac":"code","aa082a9b":"code","5c7388d3":"code","04834654":"code","6d37409f":"code","c318e86b":"code","d3b6da2d":"code","150ba9d7":"code","734ec544":"code","d332b95d":"code","3c378e67":"code","d42cd5a4":"code","4fdaa501":"code","8c53d1d3":"code","ace07802":"code","f6dc5fc5":"code","5e0ce334":"code","fae7e23e":"code","7800b787":"code","c536ecc3":"code","44ebdaac":"code","dd404d1c":"code","ef49a3a0":"code","d151f419":"code","3ce32be2":"markdown","c0732cae":"markdown","db91cdc9":"markdown","f4015b50":"markdown","a111d8c6":"markdown","ddefdbdb":"markdown","f00fefb1":"markdown","46a3190f":"markdown","e75b0cd8":"markdown","2c594db1":"markdown","8756dd14":"markdown"},"source":{"4952edff":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing \n\nimport math\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout","8c35ef0e":"train = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/train.csv\")\n\ntrain.head(10)","4aff83ac":"# Name of the features\nprint(train.columns)","aa082a9b":"# Data types of features\nprint(train.dtypes)","5c7388d3":"print(train.describe())","04834654":"# Presence of null values\nprint(train.isna().sum())","6d37409f":"# Get bar plots for the categorical features\ncolumns_str = [\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Embarked\",\"Survived\"]\n\nfig, axs = plt.subplots(3, 2, sharex=False, sharey=True, figsize=(30,30))\n\ncount_row = 0\ncount_columns = 0\nfor column in columns_str:    \n    \n    #print(c)\n    Bar_Plot = sns.countplot(x=column,hue='Survived',data=train,ax = axs[count_row][count_columns]).set_title(\"Frequeny distribution for: \" + str(column))\n        \n   \n    count_columns +=1\n    \n    if count_columns == 2:\n        count_row+=1\n        count_columns=0","c318e86b":"# Substitute cabin with deck \ntrain[\"Cabin\"] = train[\"Cabin\"].str[0]\ntrain[\"Cabin\"] = train[\"Cabin\"].fillna(\"N\")\nprint(train.groupby([\"Cabin\"]).agg({\"Cabin\":\"count\",'Survived': 'mean'}))\n\n# Extract initial alphabhet of the ticket. For completely numbered tickets substitute with X\ntrain['Ticket'] = train['Ticket'].map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')","d3b6da2d":"train[\"Embarked\"] = train[\"Embarked\"].fillna(\"N\")\ncolumns_str = [\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Embarked\",\"Cabin\"]\n\n\nfor column in columns_str:    \n    \n    \n    fact_plot = sns.factorplot(x=column,y='Survived',data=train)\n\n# Factor plot not recognising axes","150ba9d7":"f, ax = plt.subplots(1, 1,figsize=(15,15))\n\nsns.distplot(ax= ax,a = train[train['Survived']==1]['Age'], color=\"blue\", label=\"Survived\")\nsns.distplot(ax=ax,a = train[train['Survived']==0]['Age'], color=\"red\", label=\"Expired\")\n\nplt.legend(labels=['Survived', 'Expired'])\nax.set_xlabel(\"Age\")\nplt.show()","734ec544":"f, ax = plt.subplots(1, 1,figsize=(15,15))\n\nsns.distplot(ax= ax,a = train[train['Survived']==1]['Fare'], color=\"blue\", label=\"Survived\")\nsns.distplot(ax=ax,a = train[train['Survived']==0]['Fare'], color=\"red\", label=\"Expired\")\n\nplt.legend(labels=['Survived', 'Expired'])\nax.set_xlabel(\"Fare\")\nplt.show()","d332b95d":"# See if any features are related to fare and age for imputaton\n\nfig, axes = plt.subplots(1, 2, sharex=False, sharey=True, figsize=(20,5))\nsns.boxplot(x=\"Pclass\", y=\"Age\", data=train, ax=axes[0]).set_title(\"Boxplot of Age with Pclass\")\nsns.boxplot(x=\"Pclass\", y=\"Fare\", data=train, ax=axes[1]).set_title(\"Boxplot of Fare with Pclass\")\nplt.show()\n\nfig, axes = plt.subplots(1, 2, sharex=False, sharey=True, figsize=(20,5))\nsns.boxplot(x=\"SibSp\", y=\"Age\", data=train,ax=axes[0]).set_title(\"Boxplot of Age with number of siblings\")\nsns.boxplot(x=\"SibSp\", y=\"Fare\", data=train,ax=axes[1]).set_title(\"Boxplot of Fare with number of siblings\")\nplt.show()\n\nfig, axes = plt.subplots(1, 2, sharex=False, sharey=True, figsize=(20,5))\nsns.boxplot(x=\"Embarked\", y=\"Age\", data=train,ax=axes[0]).set_title(\"Boxplot of Age with port of destination\")\nsns.boxplot(x=\"Embarked\", y=\"Fare\", data=train,ax=axes[1]).set_title(\"Boxplot of Fare with port of destination\")\nplt.show()\n\nfig, axes = plt.subplots(1, 2, sharex=False, sharey=True, figsize=(20,5))\nsns.boxplot(x=\"Sex\", y=\"Age\", data=train,ax=axes[0]).set_title(\"Boxplot of Age with Sex\")\nsns.boxplot(x=\"Sex\", y=\"Fare\", data=train,ax=axes[1]).set_title(\"Boxplot of Fare with Sex\")\nplt.show()\n\nfig, axes = plt.subplots(1, 2, sharex=False, sharey=True, figsize=(20,5))\nsns.boxplot(x=\"Parch\", y=\"Age\", data=train,ax=axes[0]).set_title(\"Boxplot of Age with number of Parents\/Children\")\nsns.boxplot(x=\"Parch\", y=\"Fare\", data=train,ax=axes[1]).set_title(\"Boxplot of Fare with number of Parents\/Children\")\nplt.show()\n\nfig, axes = plt.subplots(1, 2, sharex=False, sharey=True, figsize=(20,5))\nsns.boxplot(x=\"Cabin\", y=\"Age\", data=train,ax=axes[0]).set_title(\"Boxplot of Age with Cabin no.\")\nsns.boxplot(x=\"Cabin\", y=\"Fare\", data=train,ax=axes[1]).set_title(\"Boxplot of Fare with Cabin no.\")\nplt.show()\n","3c378e67":"train.Fare = train.groupby('Pclass')['Fare'].apply(lambda x: x.fillna(x.mean()))\ntrain.Age = train.groupby('Pclass')['Age'].apply(lambda x: x.fillna(x.mean()))\ntrain[\"Pclass\"] = train[\"Pclass\"].apply(str)\n\ntrain['Family_Size'] = train['SibSp'] + train['Parch']+1\n\ntrain.loc[train.Cabin==\"N\",\"Cabin\"] = \"A\"\ntrain.loc[train.Cabin==\"D\",\"Cabin\"] = \"C\"\ntrain.loc[train.Cabin=='G','Cabin']  = \"F\"\ntrain.loc[train.Cabin=='B','Cabin']  = \"E\"\ntrain.loc[train.Embarked==\"N\",\"Embarked\"] = \"Q\"\n\ntrain[\"Not Alone\"] = 0\ntrain.loc[train.Family_Size>1,\"Not Alone\"]=1\n\ntrain.drop(columns=[\"PassengerId\",\"Name\"],inplace=True)","d42cd5a4":"print(train.isna().sum())","4fdaa501":"y_train = train[\"Survived\"]\ntrain.drop(columns=[\"Survived\"],inplace=True)\n\nX_train = train\ny_train = y_train.values\ny_train = y_train.reshape((len(y_train), 1))","8c53d1d3":"test = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/test.csv\")\n\ntest[\"Cabin\"] = test[\"Cabin\"].str[0]\ntest[\"Cabin\"] = test[\"Cabin\"].fillna(\"A\")\ntest[\"Pclass\"] = test[\"Pclass\"].apply(str)\n\ntest.loc[test.Cabin=='G','Cabin']  = \"F\"\ntest.loc[test.Cabin=='B','Cabin']  = \"E\"\ntest.loc[test.Cabin==\"D\",\"Cabin\"] = \"C\"\n\ntest[\"Embarked\"] = test[\"Embarked\"].fillna(\"Q\")\n\ntest['Ticket'] = test['Ticket'].map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\ntest.Fare = test.groupby('Pclass')['Fare'].apply(lambda x: x.fillna(x.mean()))\ntest.Age = test.groupby('Pclass')['Age'].apply(lambda x: x.fillna(x.mean()))\n\ntest_without_ID = test.drop(columns=[\"PassengerId\",\"Name\"])\n\ntest_without_ID['Family_Size'] = test_without_ID['SibSp'] + test_without_ID['Parch']+1\ntest_without_ID[\"Not Alone\"] = 0\ntest_without_ID.loc[test_without_ID.Family_Size>1,\"Not Alone\"]=1\n\nX_test= test_without_ID\n","ace07802":"encode_df = pd.concat([X_train,X_test], join=\"inner\")","f6dc5fc5":"encode_df = pd.get_dummies(encode_df)","5e0ce334":"X_train = encode_df.iloc[0: len(X_train),:]\nX_test = encode_df.iloc[len(X_train):,:]","fae7e23e":"LR = LogisticRegression()\n","7800b787":"LG = LGBMClassifier(boosting_type = 'dart',num_leaves = 32,max_depth = 10,colsample_bytree = 0.8,extra_trees = True,n_jobs = -1,random_state = 42)\n","c536ecc3":"ext = ExtraTreesClassifier(n_estimators = 1000,max_depth = 17,min_samples_split = 25,min_samples_leaf = 18,n_jobs = -1,random_state = 42)\n","44ebdaac":"gb=GradientBoostingClassifier(max_depth= 2, n_estimators = 400)","dd404d1c":"def build_model():\n    \n    model = Sequential()\n    model.add(Dense(units=30,kernel_initializer='normal',activation='elu',input_dim=len(X_train.columns)))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=30,kernel_initializer='normal',activation='elu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=1,kernel_initializer='normal',activation='sigmoid'))    \n    model.compile(optimizer=\"Adam\",loss='binary_crossentropy',metrics=['accuracy'])\n    \n    return model\n\nkeras_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(\n                            build_model,\n                            epochs=200,batch_size=16,\n                        verbose = 0)\n\nkeras_clf._estimator_type = \"classifier\"","ef49a3a0":"clf = VotingClassifier(estimators=[('LR',LR),('LGBM' , LG),(\"EXT\",ext),(\"GB\",gb),(\"NN\",keras_clf)], voting='soft')\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)","d151f419":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = pred\nprint(submission.head(5))\n\nsubmission.to_csv(\"Submission.csv\", index=False)","3ce32be2":"## Exploratory Data Analysis","c0732cae":"Some attributes of the data\n\n```\nsurvival: Survival 0 = No, 1 = Yes\npclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\nsex: Sex\nAge: Age in years\nsibsp: # of siblings \/ spouses aboard the Titanic\nparch: # of parents \/ children aboard the Titanic\nticket:Ticket number\nfare: Passenger fare\ncabin: Cabin number\nembarked: C = Cherbourg, Q = Queenstown, S = Southampton\n```","db91cdc9":"- Age and Fare has good correlation with Pclass. Hence imputation can be done with that","f4015b50":"- Unknown cabins have a lower survivability (Lower mean)\n- Cabin A has a similar survivability to the missing decks. \n- Let's analyse further with factor plots","a111d8c6":"- Cabin B and E and Cabin F and G and D and C have similar survivability\n- Cabin N (missing) has close survivability with A\n- Hence features B,E,F,G,D,C and null values can be clubbed together\n- Null values in Embarked can be substituted with Q","ddefdbdb":"## References\n\n- https:\/\/www.kaggle.com\/erikgarcia\/apr-21-logistic-regression\n- https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n- https:\/\/www.kaggle.com\/bhavikjain\/tabular-playground-series-april-ensemble\n- https:\/\/www.kaggle.com\/pranjalverma08\/tps-april-21-ann-pseudo-label-score-81-101\/#data\n\n","f00fefb1":"## Feature engineering\n","46a3190f":"## For submission","e75b0cd8":"## Implementation with voting classifier\n\n- Logistic regression\n- LightGBM\n- ExtraTreesClassifier\n- GradientBoostingClassifier\n- Neural network\n\n### References for models -:\n- https:\/\/www.kaggle.com\/bhavikjain\/tabular-playground-series-april-ensemble\n- https:\/\/www.kaggle.com\/pranjalverma08\/tps-april-21-ann-pseudo-label-score-81-101\/#data","2c594db1":"## Loading test set and performing feature engineering","8756dd14":"- A higher proportion of people above the age of 40 have survived than between 0 and 10"}}