{"cell_type":{"08600a85":"code","5f7c198f":"code","e0ec3e6d":"code","2bdb89fc":"code","8c57864f":"code","f05e61f0":"code","3762f2bb":"code","8aa620c3":"code","528481ab":"code","240ca741":"code","2ad339f6":"code","a48f03b2":"code","4bda818e":"code","ef917865":"code","a67191d2":"markdown","17a8a798":"markdown","d40721ff":"markdown","123bca06":"markdown","37ed08c1":"markdown","f12da498":"markdown"},"source":{"08600a85":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv('..\/input\/pima-diabetes\/pimaindians-diabetes.data.csv', header = None)","5f7c198f":"df.describe()","e0ec3e6d":"df.head(3)","2bdb89fc":"print((df[[1,2, 3,4,5,6,7,8]] ==0).sum())","8c57864f":"#marking 0 as NAN","f05e61f0":"df[[1,2,3,4,5]] = df[[1,2,3,4,5]].replace(0, np.NaN)\nprint(df.isnull().sum())","3762f2bb":"df.dropna(inplace=True)\nprint(df.shape)","8aa620c3":"# split dataset into inputs and outputs\nvalues = df.values\nX = values[:,0:8]\ny = values[:,8]\n# evaluate an LDA model on the dataset using k-fold cross validation\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import KFold,cross_val_score\nmodel = LinearDiscriminantAnalysis()\nkfold = KFold(n_splits=3, random_state=7)\nresult = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\nprint(result.mean())","528481ab":"type(values)","240ca741":"df.fillna(df.mean(), inplace=True)\n\n# count the number of NaN values in each column\n\nprint(df.isnull().sum())","2ad339f6":"values = df.values","a48f03b2":"X = values[:,0:8]\nmodel = LinearDiscriminantAnalysis()\n\nkfold = KFold(n_splits=3, random_state=7)\n\nresult = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n\nprint(result.mean())","4bda818e":"from sklearn.preprocessing import Imputer\n\n# fill missing values with mean column values\n\nvalues = df.values\n\nimputer = Imputer()\n\ntransformed_values = imputer.fit_transform(values)\n\n# count the number of NaN values in each column\n\nprint(np.isnan(transformed_values).sum())","ef917865":"# evaluate an LDA model on the dataset using k-fold cross validation\n\nmodel = LinearDiscriminantAnalysis()\n\nkfold = KFold(n_splits=3, random_state=7)\n\nresult = cross_val_score(model, transformed_values, y, cv=kfold, scoring='accuracy')\n\nprint(result.mean())","a67191d2":"## Remove Rows With Missing Values","17a8a798":"## Algo's that Support Missing Values","d40721ff":"1: Plasma glucose concentration\n\n2: Diastolic blood pressure\n\n3: Triceps skinfold thickness\n\n4: 2-Hour serum insulin\n\n5: Body mass index","123bca06":"## Imputing Missing Values","37ed08c1":"The scikit-learn library provides the Imputer() pre-processing class that can be used to replace missing values.\n\nIt is a flexible class that allows you to specify the value to replace (it can be something other than NaN) and the technique used to replace it (such as mean, median, or mode). The Imputer class operates directly on the NumPy array instead of the DataFrame.\n\nThe example below uses the Imputer class to replace missing values with the mean of each column then prints the number of NaN values in the transformed matrix.","f12da498":"There are algorithms that can be made robust to missing data, such as k-Nearest Neighbors that can ignore a column from a distance measure when a value is missing.\n\nThere are also algorithms that can use the missing value as a unique and different value when building the predictive model, such as classification and regression trees."}}