{"cell_type":{"eeea2964":"code","66f17940":"code","7e7ecaef":"code","2dcb8643":"code","75b08d0c":"markdown","abb3c66e":"markdown","bdc2f2a9":"markdown","3eb661d6":"markdown","4cfbeaa7":"markdown","015435a9":"markdown","0b6ee8d5":"markdown","eb0ec257":"markdown","f7f4d984":"markdown"},"source":{"eeea2964":"# Installs\n!cp \/kaggle\/input\/gdcm-conda-install\/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline .\/gdcm\/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\n!rm -rf .\/gdcm.tar\n\nprint(\"\\n... IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t\u2013 TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t\u2013 TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t\u2013 NUMPY VERSION: {np.__version__}\");\n\nimport pydicom\nfrom pydicom import dcmread\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t\u2013 MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n\n# To give access to automl files\nsys.path.append(\"\/kaggle\/input\/automl-efficientdet-efficientnetv2\/automl\")\nsys.path.append(\"\/kaggle\/input\/automl-efficientdet-efficientnetv2\/automl\/brain_automl\")\nsys.path.append(\"\/kaggle\/input\/automl-efficientdet-efficientnetv2\/automl\/brain_automl\/efficientdet\")\nsys.path.append(\"\/kaggle\/input\/automl-efficientdet-efficientnetv2\/automl\/brain_automl\/efficientnetv2\")","66f17940":"TRAIN_CSV_PATH = \"\/kaggle\/input\/siim-covid19-updated-train-labels\/updated_train_labels.csv\"\nSS_CSV_PATH = \"\/kaggle\/input\/siim-covid19-updated-train-labels\/updated_sample_submission.csv\"\n\nprint(\"\\n\\nCOMBINED AND EXPLODED TRAIN DATAFRAME\\n\\n\")\ntrain_df = pd.read_csv(TRAIN_CSV_PATH)\ndisplay(train_df)\n\nprint(\"\\n\\nSAMPLE SUBMISSION DATAFRAME\\n\\n\")\nss_df = pd.read_csv(SS_CSV_PATH)\ndisplay(ss_df)\n\nimage_df = pd.read_csv(\"\/kaggle\/input\/siim-covid19-detection\/train_image_level.csv\")\nall_image_ids = image_df.id.str.replace(\"_image\", \"\")\nbbox_image_ids = image_df.dropna().id.str.replace(\"_image\", \"\")","7e7ecaef":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    \"\"\" Convert dicom file to numpy array \n    \n    Args:\n        path (str): Path to the dicom file to be converted\n        voi_lut (bool): Whether or not VOI LUT is available\n        fix_monochrome (bool): Whether or not to apply monochrome fix\n        \n    Returns:\n        Numpy array of the respective dicom file \n        \n    \"\"\"\n    # Use the pydicom library to read the dicom file\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to \n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    # The XRAY may look inverted\n    #   - If we want to fix this we can\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    # Normalize the image array and return\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\n\ndef dicom2array_2(fname, target_size=512, use_clahe=True, clip_limit=2., grid_size=(8,8)):\n    dicom = pydicom.dcmread(fname)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    im = data - np.min(data)\n    im = 255. * im \/ np.max(im)\n    \n    if dicom.PhotometricInterpretation == \"MONOCHROME1\": # check for inverted image\n        im = 255. - im\n    \n    if use_clahe:\n        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)\n        climg = clahe.apply(im.astype('uint8'))\n        img = Image.fromarray(climg.astype('uint8'), 'L')\n    else:\n        img = Image.fromarray(im.astype('uint8'), 'L')\n    org_size = img.size\n    \n    if max(img.size) > target_size:\n        img.thumbnail((target_size, target_size), Image.ANTIALIAS)\n    \n    return np.asarray(img)\n\ndef get_absolute_file_paths(directory):\n    all_abs_file_paths = []\n    for dirpath,_,filenames in os.walk(directory):\n        for f in filenames:\n            all_abs_file_paths.append(os.path.abspath(os.path.join(dirpath, f)))\n    return all_abs_file_paths","2dcb8643":"try:\n    display(study_df)\nexcept:\n    study_df = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_study_level.csv\")\n    study_df = study_df[study_df.id.str.contains(\"study\")]\n    study_df[\"id\"] = study_df[\"id\"].str.replace(\"_study\", \"\")\n    study_df[\"study_dir\"] = \"\/kaggle\/input\/siim-covid19-detection\/train\/\"+study_df[\"id\"]\n    study_df[\"images_per_study\"] = study_df.study_dir.progress_apply(lambda x: len(get_absolute_file_paths(x)))\nmultiple_images_per_study_df = study_df[study_df.images_per_study>1].reset_index(drop=True)\n\nfor dir_path in multiple_images_per_study_df.study_dir.values:\n    image_paths = get_absolute_file_paths(dir_path)\n    if len(image_paths)<=4:\n        plt.figure(figsize=(18,4))\n        plt.suptitle(f\"\\n\\nSTUDY: {dir_path.rsplit('\/', 1)[1]}\", fontsize=16, fontweight=\"bold\")\n        for j, x in enumerate(image_paths):\n            if any(True for xx in all_image_ids if xx in x):\n                title = \"\\nINCLUDED IN IMAGE LEVEL\"\n                if any(True for xx in bbox_image_ids if xx in x):\n                    title += \" - W\/ BBOX!!!\"\n            else:\n                title = \"xxxxxxxxxxxxxxxxxxxxxxx\"\n            plt.subplot(1,4,j+1)\n            plt.imshow(dicom2array_2(x))\n            plt.axis(False)\n            plt.title(title, fontweight=\"bold\")\n    elif len(image_paths)<=8:\n        plt.figure(figsize=(18,8))\n        plt.suptitle(f\"\\n\\nSTUDY: {dir_path.rsplit('\/', 1)[1]}\", fontsize=16, fontweight=\"bold\")\n        for j, x in enumerate(image_paths):\n            if any(True for xx in all_image_ids if xx in x):\n                title = \"\\nINCLUDED IN IMAGE LEVEL\"\n                if any(True for xx in bbox_image_ids if xx in x):\n                    title += \" - W\/ BBOX!!!\"\n            else:\n                title = \"xxxxxxxxxxxxxxxxxxxxxxx\"\n            plt.subplot(2,4,j+1)\n            plt.imshow(dicom2array_2(x))\n            plt.axis(False)\n            plt.title(title, fontweight=\"bold\")\n    else:\n        plt.figure(figsize=(18,12))\n        plt.suptitle(f\"\\n\\nSTUDY: {dir_path.rsplit('\/', 1)[1]}\", fontsize=16, fontweight=\"bold\")\n        for j, x in enumerate(image_paths):\n            if any(True for xx in all_image_ids if xx in x):\n                title = \"\\nINCLUDED IN IMAGE LEVEL\"\n                if any(True for xx in bbox_image_ids if xx in x):\n                    title += \" - W\/ BBOX!!!\"\n            else:\n                title = \"xxxxxxxxxxxxxxxxxxxxxxx\"\n            plt.subplot(3,4,j+1)\n            plt.imshow(dicom2array_2(x))\n            plt.title(title, fontweight=\"bold\")\n            plt.axis(False)\n    \n    plt.tight_layout()\n    plt.show()\n","75b08d0c":"**<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\">1.1  THE DATA<\/h2>\n\n---\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">BACKGROUND INFORMATION<\/b>\n\nIn this competition, we are identifying and localizing COVID-19 abnormalities on chest radiographs. <br>**This is an object detection and classification problem.**\n\nFor each test image, you will be predicting a bounding box and class for all findings. \n* If you predict that there are no findings, you should create a prediction of **`\"none 1 0 0 1 1\"`** \n    * \"none\" is the class ID for no finding, and this provides a one-pixel bounding box with a confidence of 1.0\n\nFurther, for each test study, you should make a determination within the following labels:\n\n> **`'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance'`**\n\nTo make a prediction of one of the above labels, create a prediction string similar to the \"none\" class above: \n* i.e. **`atypical 1 0 0 1 1`**\n\n---\n\n**MESSAGE FROM THE COMPETITION HOST ON LABEL AND BBOX DETAILS:**\n\nIn this challenge, the chest radiographs (CXRs) were categorized using a specific grading schema, based on a published paper:\n\n[**Litmanovich DE, Chung M, Kirkbride RR, Kicska G, Kanne JP. Review of chest radiograph findings of COVID-19 pneumonia and suggested reporting language. Journal of thoracic imaging. 2020 Nov 14;35(6):354-60.**](https:\/\/journals.lww.com\/thoracicimaging\/Fulltext\/2020\/11000\/Review_of_Chest_Radiograph_Findings_of_COVID_19.4.aspx)\n\nPer the grading schema, chest radiographs are classified into one of four categories, which are mutually exclusive:\n\n1. **Typical Appearance**: Multifocal bilateral, peripheral opacities with rounded morphology, lower lung\u2013predominant distribution\n2. **Indeterminate Appearance**: Absence of typical findings AND unilateral, central or upper lung predominant distribution\n3. **Atypical Appearance**: Pneumothorax, pleural effusion, pulmonary edema, lobar consolidation, solitary lung nodule or mass, diffuse tiny nodules, cavity\n4. **Negative for Pneumonia**: No lung opacities\n\nBounding boxes were placed on lung opacities, whether typical or indeterminate. Bounding boxes were also placed on some atypical findings including solitary lobar consolidation, nodules\/masses, and cavities. Bounding boxes were not placed on pleural effusions, or pneumothoraces. No bounding boxes were placed for the negative for pneumonia category.\n\nIn cases of multiple adjacent opacities, we opted for one large bounding box, rather than multiple adjacent smaller boxes, to improve consistency in the labeling.\n\nAnnotators did have access to the COVID status for each patient, but were asked to adhere to the grading system above irrespective of the status. As such, some patients who were COVID negative still had chest radiographs with typical appearances. Similarly, some patients who were COVID positive had atypical appearances, or were negative for pneumonia (no lung opacities), because the grading system is based off the chest radiographic findings alone.\n\nThe goal in this challenge is to determine the appropriate category for each radiograph, as well as localize the lung opacities with a bounding box prediction.\n\n---\n\nThe images are in DICOM format, which means they contain additional data that might be useful for visualizing and classifying.\nNote that the images are in **DICOM** format, which means they contain additional data that might be useful for visualizing and classifying.\n\n![Example Radiographs](https:\/\/i.imgur.com\/QWmbhXx.png)\n\n<br>\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">DATASET INFORMATION<\/b>\n\nThe **train dataset** comprises **`6,334`** chest scans in **DICOM** format, which were de-identified to protect patient privacy. \n\nNote that all images are stored in paths with the form **`study\/series\/image`**. \n* The **`study`** ID here relates directly to the study-level predictions\n* the **`image`** ID is the ID used for image-level predictions\n\nThe **test dataset** is of roughly the same scale as the training dataset. \n* As this is a kernels only competition we shsould plan accordingly\n* i.e. we should be able to infer on the entirety of the training dataset within the submission kernel\n\n<br>\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">DATA FILES<\/b>\n> **`train_study_level.csv`**\n> * **`id`** - unique study identifier\n> * **Negative for Pneumonia** - **`1`** if the study is negative for pneumonia, **`0`** otherwise\n> * **Typical Appearance** - **`1`** if the study has this appearance, **`0`** otherwise\n> * **Indeterminate Appearance**  - **`1`** if the study has this appearance, **`0`** otherwise\n> * **Atypical Appearance**  - **`1`** if the study has this appearance, **`0`** otherwise\n\n> **`train_image_level.csv`**\n> * **`id`** - unique image identifier\n> * **`boxes`** - bounding boxes in easily-readable dictionary format\n> * **`label`** - the correct prediction label for the provided bounding boxes","abb3c66e":"<br>\n\n<a id=\"helper_functions\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkred; background-color: #ffffff;\" id=\"helper_functions\">3&nbsp;&nbsp;HELPER FUNCTIONS<\/h1>","bdc2f2a9":"<br>\n\n<a id=\"setup\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkred; background-color: #ffffff;\" id=\"setup\">2&nbsp;&nbsp;NOTEBOOK SETUP<\/h1>","3eb661d6":"<h1 style=\"text-align: center; font-family: Verdana; font-size: 32px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; font-variant: small-caps; letter-spacing: 3px; color: #186b75; background-color: #ffffff;\">SIIM \u2013 COVID19 Detection<br><br><font color=\"red\">EfficientNetV2-B3<\/font><\/h1>\n\n<h2 style=\"text-align: center; font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: underline; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\">Study Level Image Exploration<\/h2>\n<h5 style=\"text-align: center; font-family: Verdana; font-size: 12px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">CREATED BY: DARIEN SCHETTLER<\/h5><br>\n\n<br>\n\n<center>\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0<\/center>\n<center>\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb<\/center>\n<center>\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0<\/center>\n<center>\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea\ud83d\udd2c\ud83e\ude7a\ud83d\udc8a\ud83e\uddec\ud83e\udda0\ud83e\uddeb\ud83e\uddea<\/center>\n<center>\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\udda0\ud83e\udda0\ud83e\udda0\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a<\/center>\n<center>\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a<\/center>\n\n<br>\n","4cfbeaa7":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\">1.2  THE GOAL<\/h2>\n\n---\n\nIn this competition, you\u2019ll identify and localize COVID-19 abnormalities on chest radiographs. In particular, you'll categorize the radiographs as one of a possible **`4`** categories. \n\nIn this competition, we are making predictions at both a study (multi-image) and image level.\n* **`negative for pneumonia`** or **`typical`**, **`indeterminate`**, or **`atypical`** \n     \nYou'll work with a dataset consisting of **`8,781`** scans that have been annotated by experienced radiologists. You can train your model with **`6,334`** independently-labeled images and you will be evaluated on a test set of **`2,447`** images. \n\nThe challenge uses the standard PASCAL VOC 2010 mean Average Precision (mAP) at IoU > 0.5.\n* Note that the linked document describes VOC 2012, which differs in some minor ways (e.g. there is no concept of \"difficult\" classes in VOC 2010). The P\/R curve and AP calculations remain the same.\n\n<br>\n\n<center>\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a<\/center>\n\n<center><font color=\"red\"><b>If successful, you'll help radiologists diagnose the millions of COVID-19 patients more confidently and quickly.<\/b><\/font><\/center>\n\n<center>\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a\ud83e\ude7a<\/center>","015435a9":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\">1.3  ADDITIONAL INFORMATION ON ABNORMALITIES<\/h2>\n\n---\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">Negative for Pneumonia<\/b>\n* No lung opacities\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">Typical Appearance<\/b>\n* Multifocal bilateral, peripheral opacities with rounded morphology, lower lung\u2013predominant distribution\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">Indeterminate Appearance<\/b>\n* Absence of typical findings AND unilateral, central or upper lung predominant distribution\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">Atypical Appearance<\/b>\n* Pneumothorax, pleural effusion, pulmonary edema, lobar consolidation, solitary lung nodule or mass, diffuse tiny nodules, cavity","0b6ee8d5":"<br>\n\n<a id=\"background_information\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkred; background-color: #ffffff;\" id=\"background_information\">1&nbsp;&nbsp;BACKGROUND INFORMATION<\/h1>","eb0ec257":"<br>\n\n<a id=\"imports\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: darkred;\" id=\"imports\">0&nbsp;&nbsp;IMPORTS<\/h1>","f7f4d984":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkred; background-color: #ffffff;\">TABLE OF CONTENTS<\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#imports\">0&nbsp;&nbsp;&nbsp;&nbsp;IMPORTS<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#background_information\">1&nbsp;&nbsp;&nbsp;&nbsp;BACKGROUND INFORMATION<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#setup\">2&nbsp;&nbsp;&nbsp;&nbsp;SETUP<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#helper_functions\">3&nbsp;&nbsp;&nbsp;&nbsp;HELPER FUNCTIONS<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#tabular_data\">4&nbsp;&nbsp;&nbsp;&nbsp;TABULAR DATA<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#image_data\">5&nbsp;&nbsp;&nbsp;&nbsp;IMAGE DATA<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#find_duplicates\">6&nbsp;&nbsp;&nbsp;&nbsp;IDENTIFY DUPLICATES<\/a><\/h2>\n\n---\n\n<br>"}}