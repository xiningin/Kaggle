{"cell_type":{"0c814c39":"code","238549bb":"code","8f4ac145":"code","02c6cf30":"code","40f45521":"code","73fd595e":"code","b6247663":"code","a46b26a1":"code","d43751a2":"code","7dce9777":"code","50321963":"code","b84fad88":"code","2679e510":"code","f4f32a1d":"code","c68d61d0":"code","4e268ce4":"code","f533035e":"code","62c517c7":"code","ffe524ab":"code","36f74258":"code","88f59417":"code","10db2f3a":"code","152d7f94":"code","200cac54":"code","4f5b7f34":"code","3615412d":"code","d45644a9":"code","a49b2c97":"code","5e7b71b2":"code","12581004":"code","6da4d698":"code","4e11209c":"code","0e5998da":"code","f9fa359d":"code","efdc93d8":"code","cf719ede":"code","da5764a1":"code","bda44f25":"code","d5361363":"code","85513427":"code","5c51d4da":"code","19437150":"code","70871cee":"code","74b831a6":"code","dad1cb5b":"code","d8c5003d":"code","b2e08f52":"code","96a313e3":"code","eae71153":"code","0e941e4f":"code","00c5a11f":"code","8c3bef87":"code","b653a971":"code","54f8efc1":"code","7a499722":"code","a2e6e021":"code","1bad38a3":"code","8a23a44e":"code","52285346":"code","14846a68":"code","786c0a83":"code","15f58890":"code","0adfc020":"code","66b7c5cf":"code","1b30ee45":"code","d2222c5b":"code","bb969e9c":"code","f2cb9314":"code","ab3b8e2c":"code","6e4dc2d7":"code","e768d8b1":"code","c2f990e4":"code","99d8eb0a":"code","33afa5ff":"code","3576e223":"code","e3c283c3":"code","3a8ba7c3":"code","d8082193":"code","cbe29b8b":"code","9e611fdc":"code","a9a101db":"code","43d9227a":"code","f0c1c8d7":"code","42fdc75d":"code","0b05d08c":"markdown","91ae531a":"markdown","bd6277fa":"markdown","ab825d79":"markdown","83b7bddd":"markdown","d8cafe34":"markdown","c3c47662":"markdown","855c7ea3":"markdown","0697efb9":"markdown","7d1977dd":"markdown","5bbb20ea":"markdown","0fac1ec1":"markdown","a1134159":"markdown","3029cfb1":"markdown","b0efe49a":"markdown","e2b08b70":"markdown","0015a9b6":"markdown","b9e56ab9":"markdown","7e9573be":"markdown","cf662ef0":"markdown","d174abad":"markdown","a0099304":"markdown","91b5b1bc":"markdown","f1c7f610":"markdown","11b625a9":"markdown","15f2c130":"markdown","1d69fddc":"markdown","b4a35b5e":"markdown","e6a4d7b7":"markdown","5167e573":"markdown","6dcb0a81":"markdown","585c74fe":"markdown","8b72c309":"markdown","716e6807":"markdown","8b3848b7":"markdown","112fcbb2":"markdown","6d17b7fb":"markdown","652063a3":"markdown","36253478":"markdown","18f8ab4c":"markdown","39190519":"markdown","1cad1bb2":"markdown","4d7010f1":"markdown","318ee2b9":"markdown","93116f46":"markdown","3dc01095":"markdown"},"source":{"0c814c39":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import subprocess as sub","238549bb":"missing_values={\"N\/A\",\"?\",\"-\"} # In Data description file  it has been said that Missing Values will be ? N\/A. Hence I am\n#using this paramenter to check them.\nDF=pd.read_csv('..\/input\/parkinsons-data-set\/parkinsons.data',sep=',',encoding='UTF-8',na_values=missing_values)","8f4ac145":"DF.columns=DF.columns.str.replace(':','')","02c6cf30":"DF.head()","40f45521":"print(\"The Total Number of rows : {} & Columns : {}.\".format(DF.shape[0],DF.shape[1]))","73fd595e":"DF.info()","b6247663":"print(DF.isna().apply(pd.value_counts))","a46b26a1":"print(DF.isnull().apply(pd.value_counts))","d43751a2":"DF.isnull().sum().value_counts()","7dce9777":"DF.isna().sum().value_counts()","50321963":"Class_Balance=DF['status'].value_counts()\nClass_Balance\nHealthy=DF[DF['status']==0]\nPDS=DF[DF['status']==1]\nHealthy=Healthy.shape[0]\nPDS=PDS.shape[0]\nPD_PERCENT=(PDS\/(PDS + Healthy)) * 100\nNon_PD=100 - PD_PERCENT\nprint(Class_Balance)\nprint(\"Total Number of patients in our data , who have Parkinson's Disease:{}\".format(PD_PERCENT))\nprint(\"Total Number of patients in our data , who are healthy:{}\".format(Non_PD))\nsns.countplot(DF['status'],orient=\"h\",saturation=1,palette='copper');\n\nif PD_PERCENT > Non_PD:\n    print(\"There is some class Imbalance in our data , we may have to take measures while building our model to accomodate this\")","b84fad88":"DF.describe().T","2679e510":"DF.skew(axis=0)","f4f32a1d":"df_healthy=DF.loc[DF['status']==0]\ndf_PD=DF.loc[DF['status']==1]","c68d61d0":"print(\"##############################vocal fundamental frequency##############################\")\n\nplt.scatter(df_healthy['MDVPFo(Hz)'],np.zeros_like(df_healthy['MDVPFo(Hz)']),marker='s',color='Red',)\nplt.scatter(df_PD['MDVPFo(Hz)'],np.zeros_like(df_PD['MDVPFo(Hz)']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('Average vocal fundamental frequency')\nplt.show()\n\nplt.scatter(df_healthy['MDVPFhi(Hz)'],np.zeros_like(df_healthy['MDVPFhi(Hz)']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPFhi(Hz)'],np.zeros_like(df_PD['MDVPFhi(Hz)']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('Maximum vocal fundamental frequency')\nplt.show()\n\nplt.scatter(df_healthy['MDVPFlo(Hz)'],np.zeros_like(df_healthy['MDVPFlo(Hz)']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPFlo(Hz)'],np.zeros_like(df_PD['MDVPFlo(Hz)']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('Minimum vocal fundamental frequency')\nplt.show()\n\n","4e268ce4":"print(\"##############################Several measures of variation in fundamental frequency##############################\")\n\nplt.scatter(df_healthy['MDVPJitter(%)'],np.zeros_like(df_healthy['MDVPJitter(%)']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPJitter(%)'],np.zeros_like(df_PD['MDVPJitter(%)']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('MDVPJitter(%)')\nplt.grid(True)\nplt.show()\nplt.scatter(df_healthy['MDVPJitter(Abs)'],np.zeros_like(df_healthy['MDVPJitter(Abs)']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPJitter(Abs)'],np.zeros_like(df_PD['MDVPJitter(Abs)']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('MDVPJitter(Abs)')\nplt.grid(True)\nplt.show()\nplt.scatter(df_healthy['MDVPRAP'],np.zeros_like(df_healthy['MDVPRAP']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPRAP'],np.zeros_like(df_PD['MDVPRAP']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('MDVPRAP')\nplt.grid(True)\nplt.show()\nplt.scatter(df_healthy['MDVPPPQ'],np.zeros_like(df_healthy['MDVPPPQ']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPPPQ'],np.zeros_like(df_PD['MDVPPPQ']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('MDVPPPQ')\nplt.grid(True)\nplt.show()\nplt.scatter(df_healthy['JitterDDP'],np.zeros_like(df_healthy['JitterDDP']),marker='s',color='Red')\nplt.scatter(df_PD['JitterDDP'],np.zeros_like(df_PD['JitterDDP']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('JitterDDP ')\nplt.grid(True)\nplt.show()","f533035e":"print(\"##############################Several measures of variation in amplitude##############################\")\n\nplt.scatter(df_healthy['MDVPShimmer'],np.zeros_like(df_healthy['MDVPShimmer']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPShimmer'],np.zeros_like(df_PD['MDVPShimmer']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('MDVPShimmer')\nplt.show()\nplt.scatter(df_healthy['MDVPShimmer(dB)'],np.zeros_like(df_healthy['MDVPShimmer(dB)']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPShimmer(dB)'],np.zeros_like(df_PD['MDVPShimmer(dB)']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('MDVPShimmer(dB)')\nplt.show()\nplt.scatter(df_healthy['ShimmerAPQ3'],np.zeros_like(df_healthy['ShimmerAPQ3']),marker='s',color='Red')\nplt.scatter(df_PD['ShimmerAPQ3'],np.zeros_like(df_PD['ShimmerAPQ3']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('ShimmerAPQ3')\nplt.show()\nplt.scatter(df_healthy['ShimmerAPQ5'],np.zeros_like(df_healthy['ShimmerAPQ5']),marker='s',color='Red')\nplt.scatter(df_PD['ShimmerAPQ5'],np.zeros_like(df_PD['ShimmerAPQ5']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('ShimmerAPQ5')\nplt.show()\nplt.scatter(df_healthy['MDVPAPQ'],np.zeros_like(df_healthy['MDVPAPQ']),marker='s',color='Red')\nplt.scatter(df_PD['MDVPAPQ'],np.zeros_like(df_PD['MDVPAPQ']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('MDVPAPQ')\nplt.show()\n\nplt.scatter(df_healthy['ShimmerDDA'],np.zeros_like(df_healthy['ShimmerDDA']),marker='s',color='Red')\nplt.scatter(df_PD['ShimmerDDA'],np.zeros_like(df_PD['ShimmerDDA']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('ShimmerDDA')\nplt.show()\n","62c517c7":"plt.figure(figsize=(12,8))\nsns.distplot(df_healthy['NHR'],kde=True,color='r',hist=False,label=\"NHR_Healthy\")\nsns.distplot(df_PD['NHR'],kde=True,color='G',hist=False,label=\"NHR_Positive\")\nplt.legend()\nplt.title(\"NHR Distribution\")","ffe524ab":"plt.figure(figsize=(12,8))\nsns.distplot(df_healthy['HNR'],kde=True,color='r',hist=False,label=\"HNR_Healthy\")\nsns.distplot(df_PD['HNR'],kde=True,color='G',hist=False,label=\"HNR_Positive\")\nplt.legend()\nplt.title(\"HNR Distribution\")","36f74258":"print(\"##############################Nonlinear dynamical complexity measures##############################\")\n\nplt.scatter(df_healthy['RPDE'],np.zeros_like(df_healthy['RPDE']),marker='s',color='Red')\nplt.scatter(df_PD['RPDE'],np.zeros_like(df_PD['RPDE']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('RPDE')\nplt.show()\nplt.scatter(df_healthy['D2'],np.zeros_like(df_healthy['D2']),marker='s',color='Red')\nplt.scatter(df_PD['D2'],np.zeros_like(df_PD['D2']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('D2')\nplt.show()\n\nplt.scatter(df_healthy['DFA'],np.zeros_like(df_healthy['DFA']),marker='s',color='Red')\nplt.scatter(df_PD['DFA'],np.zeros_like(df_PD['DFA']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('DFA')\nplt.show()","88f59417":"plt.figure(figsize=(12,8))\nsns.distplot(df_healthy['spread1'],kde=True,color='r',hist=False,label=\"spread1 Normal\")\nsns.distplot(df_PD['spread1'],kde=True,color='G',hist=False,label=\"spread1 PD\")\nsns.distplot(df_healthy['spread2'],kde=True,color='yellow',hist=False,label=\"spread2 Normal\")\nsns.distplot(df_PD['spread2'],kde=True,color='black',hist=False,label=\"spread2 PD\")\nsns.distplot(df_healthy['PPE'],kde=True,color='purple',hist=False,label=\"PPE Normal\")\nsns.distplot(df_PD['PPE'],kde=True,color='orange',hist=False,label=\"PPE PD\")\nplt.legend()\nplt.title(\"Spread\")","10db2f3a":"sns.violinplot(df_healthy['MDVPFhi(Hz)'])\nplt.show()\nsns.violinplot(df_PD['RPDE'])\nplt.show()","152d7f94":"sns.FacetGrid(DF,hue='status',height=5).map(plt.scatter,\"MDVPFhi(Hz)\",\"MDVPRAP\").add_legend();\nsns.FacetGrid(DF,hue='status',height=5).map(plt.scatter,\"MDVPPPQ\",\"MDVPShimmer\").add_legend();\nsns.FacetGrid(DF,hue='status',height=5).map(plt.scatter,\"MDVPPPQ\",\"MDVPShimmer\").add_legend();\nplt.show()","200cac54":"A=DF[DF.columns[4:9]].apply(lambda x: x.corr(DF['MDVPFo(Hz)']))\nprint(A)\nsns.distplot(A,hist=True)","4f5b7f34":"B=DF[DF.columns[9:15]].apply(lambda x: x.corr(DF['MDVPFo(Hz)']))\nsns.distplot(B)","3615412d":"C=DF[DF.columns[9:15]].apply(lambda x: x.corr(DF['MDVPJitter(%)']))\nprint(C)\nsns.distplot(C)","d45644a9":"DF.corr()","a49b2c97":"def plot_corr(df, size=25):\n    corr = df.corr()\n    fig, ax = plt.subplots(figsize=(size, 45))\n    ax.matshow(corr)\n    plt.xticks(range(len(corr.columns)), corr.columns)\n    plt.yticks(range(len(corr.columns)), corr.columns)","5e7b71b2":"plot_corr(DF)","12581004":"import scipy.stats as stats\nsns.scatterplot(DF['MDVPShimmer'],DF['status'],hue=DF['MDVPShimmer'],alpha=0.8);\n\n\nH0=\"variation in amplitude does not have an impact on Parkinson's disease diagnosis\"\nHa=\"variation in amplitude does have significant impact on diagnosis\"\n\nAVG_FREQ_Healthy=np.array(DF[DF['status']==1].MDVPShimmer)\nAVG_FREQ_PD=np.array(DF[DF['status']==0].MDVPShimmer)\n\nt,p_value=stats.ttest_ind(AVG_FREQ_Healthy,AVG_FREQ_PD,axis=0)\n\nif p_value < 0.05:\n    print(Ha)\nelse:\n    print(H0)\n\n","6da4d698":"plt.scatter(df_healthy['NHR'],np.zeros_like(df_healthy['NHR']),marker='s',color='Red')\nplt.scatter(df_PD['NHR'],np.zeros_like(df_PD['NHR']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('NHR')\nplt.show()\n\nplt.scatter(df_healthy['HNR'],np.zeros_like(df_healthy['HNR']),marker='s',color='Red')\nplt.scatter(df_PD['HNR'],np.zeros_like(df_PD['HNR']),marker='|',color='blue',alpha=0.4)\nplt.xlabel('HNR')\nplt.show()\n\nH0=\"NHR does not have an impact on Parkinson's disease diagnosis\"\nHa=\"NHR does have significant impact on diagnosis\"\n\nAVG_FREQ_Healthy=np.array(DF[DF['status']==1].NHR)\nAVG_FREQ_PD=np.array(DF[DF['status']==0].NHR)\n\nt,p_value=stats.ttest_ind(AVG_FREQ_Healthy,AVG_FREQ_PD,axis=0)\n\nif p_value < 0.05:\n    print(Ha)\nelse:\n    print(H0)\n\n\nH0=\"HNR does not have an impact on Parkinson's disease diagnosis\"\nHa=\"HNR does have significant impact on diagnosis\"\n\nAVG_FREQ_Healthy=np.array(DF[DF['status']==1].HNR)\nAVG_FREQ_PD=np.array(DF[DF['status']==0].HNR)\n\nt,p_value=stats.ttest_ind(AVG_FREQ_Healthy,AVG_FREQ_PD,axis=0)\n\nif p_value < 0.01:\n    print(Ha)\nelse:\n    print(H0)\n    \n\n\nH0=\"spread2 does not have an impact on Parkinson's disease diagnosis\"\nHa=\"spread2 does have significant impact on diagnosis\"\n\nAVG_FREQ_Healthy=np.array(DF[DF['status']==1].spread2)\nAVG_FREQ_PD=np.array(DF[DF['status']==0].spread2)\n\nt,p_value=stats.ttest_ind(AVG_FREQ_Healthy,AVG_FREQ_PD,axis=0)\n\nif p_value < 0.01:\n    print(Ha)\nelse:\n    print(H0)\n    \n\n\n","4e11209c":"from sklearn.model_selection import train_test_split","0e5998da":"X=DF.drop(['name','status'],axis=1)\nY=DF['status']","f9fa359d":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=22)","efdc93d8":"from sklearn.linear_model import LogisticRegression","cf719ede":"M1_Log_Raw=LogisticRegression(solver='liblinear')\nM1_Log_scaled=LogisticRegression(solver='liblinear')","da5764a1":"M1_Log_Raw.fit(X_train,Y_train)","bda44f25":" M1_Log_Raw.score(X_train,Y_train) * 100","d5361363":"M1_PRED=M1_Log_Raw.predict(X_test)","85513427":"M1_Log_Raw.score(X_test,Y_test) * 100","5c51d4da":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report","19437150":"from  sklearn.utils import resample\ndf_majority=DF[DF['status']==1]\ndf_minority=DF[DF['status']==0]\ndf_upsample_minority=resample(df_minority,replace=True,random_state=12,n_samples=147)\nDF1=pd.concat([df_majority,df_upsample_minority])","70871cee":"DF1.drop(['name'],axis=1,inplace=True)","74b831a6":"count=DF1['status'].value_counts()\ncount.plot(kind='bar',figsize=(5,5));","dad1cb5b":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","d8c5003d":"scaler.fit(DF1)","b2e08f52":"XS=DF1.drop(['status'],axis=1)\nYS=DF1['status']","96a313e3":"Xs_Train,Xs_Test,Ys_train,Ys_Test=train_test_split(XS,YS,test_size=0.3,random_state=23)","eae71153":"M1_Log_scaled.fit(Xs_Train,Ys_train)","0e941e4f":"Pred2_S=M1_Log_scaled.predict(Xs_Test)","00c5a11f":"print(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----Logistic Model with Raw Data----\")\nprint(\"Model Score on Raw Training data :{}\".format( M1_Log_Raw.score(X_train,Y_train) * 100))\nprint(\"Model Score on Raw Test Data : {}\".format(M1_Log_Raw.score(X_test,Y_test) * 100))\nprint(classification_report(Y_test,M1_PRED))\nCM_M1_Log=confusion_matrix(Y_test,M1_PRED,labels=[0,1])\nsns.heatmap(CM_M1_Log,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Logistic Model with Raw Data:{}\".format(accuracy_score(Y_test,M1_PRED)*100))\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----Logistic Model with Scaled Data----\")\nprint(\"Model Score on scaled Training data :{}\".format(M1_Log_scaled.score(Xs_Train,Ys_train) * 100))\nprint(\"Model Score on scaled Test data :{}\".format(M1_Log_scaled.score(Xs_Test,Ys_Test) * 100))\nprint(classification_report(Ys_Test,Pred2_S))\ncm1_s=confusion_matrix(Ys_Test,Pred2_S,labels=[0,1])\nsns.heatmap(cm1_s,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Logistic Model with Scaled  Data:{}\".format(accuracy_score(Ys_Test,Pred2_S)*100))\nif (M1_Log_Raw.score(X_train,Y_train) > M1_Log_scaled.score(Xs_Train,Ys_train)):\n    print(\"Model Score on Raw Training Data is higher than Scaled Training Data\")\nelse : \n    print(\"Model Score on Scaled Training Data is higher than Raw Training Data\")\nif (M1_Log_scaled.score(X_test,Y_test) > M1_Log_Raw.score(Xs_Test,Ys_Test)):\n    print(\"Model Score on Raw Testing Data is higher than Scaled Testing Data\")\nelse : \n    print(\"Model Score on Scaled Testing Data is higher than Raw Testing Data\")","8c3bef87":"from sklearn.naive_bayes import GaussianNB\nModel2_NB=GaussianNB()","b653a971":"Model2_NB.fit(X_train,Y_train)\nModel2_NB.fit(Xs_Train,Ys_train)","54f8efc1":"Model2_NB_Pred_on_Raw=Model2_NB.predict(X_test)\nModel2_NB_pred_on_scaled=Model2_NB.predict(Xs_Test)","7a499722":"print(Model2_NB.score(X_test,Y_test))\nprint(Model2_NB.score(Xs_Test,Ys_Test))","a2e6e021":"print(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----Naive Bayes Model with Raw Data----\")\nprint(\"Model Score on Raw Training data :{}\".format(Model2_NB.score(X_train,Y_train) * 100))\nprint(\"Model Score on Raw Test Data : {}\".format(Model2_NB.score(X_test,Y_test) * 100))\nprint(classification_report(Y_test,Model2_NB_Pred_on_Raw))\nCM_M2_NB=confusion_matrix(Y_test,Model2_NB_Pred_on_Raw,labels=[0,1])\nsns.heatmap(CM_M2_NB,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Naive Bayes Model with Raw Data:{}\".format(accuracy_score(Y_test,Model2_NB_Pred_on_Raw)*100))\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----Naive Bayes Model with Scaled Data----\")\nprint(\"Model Score on scaled Training data :{}\".format(Model2_NB.score(Xs_Train,Ys_train) * 100))\nprint(\"Model Score on scaled Test data :{}\".format(Model2_NB.score(Xs_Test,Ys_Test) * 100))\nprint(classification_report(Ys_Test,Model2_NB_pred_on_scaled))\nCM_M2_NB1=confusion_matrix(Ys_Test,Model2_NB_pred_on_scaled,labels=[0,1])\nsns.heatmap(CM_M2_NB1,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Logistic Model with Scaled  Data:{}\".format(accuracy_score(Ys_Test,Model2_NB_pred_on_scaled)*100))\nif (Model2_NB.score(X_train,Y_train) > Model2_NB.score(Xs_Train,Ys_train)):\n    print(\"Model Score on Raw Training Data is higher than Scaled Training Data\")\nelse : \n    print(\"Model Score on Scaled Training Data is higher than Raw Training Data\")\nif (Model2_NB.score(X_test,Y_test) > Model2_NB.score(Xs_Test,Ys_Test)):\n    print(\"Model Score on Raw Testing Data is higher than Scaled Testing Data\")\nelse : \n    print(\"Model Score on Scaled Testing Data is higher than Raw Testing Data\")","1bad38a3":"from sklearn.svm import SVC","8a23a44e":"M3_SVM_Raw=SVC(C=1,gamma='scale',kernel='rbf',probability=True)\nM3_SVM_scaled=SVC(C=1,gamma='scale',kernel='rbf',probability=True)","52285346":"M3_SVM_Raw.fit(X_train,Y_train)","14846a68":"M3_SVM_scaled.fit(Xs_Train,Ys_train)","786c0a83":"print(M3_SVM_Raw.score(X_train,Y_train))\nprint(M3_SVM_scaled.score(Xs_Train,Ys_train))","15f58890":"print(M3_SVM_Raw.score(X_test,Y_test))\nprint(M3_SVM_scaled.score(Xs_Test,Ys_Test))","0adfc020":"PRED_3_SVM_Raw=M3_SVM_Raw.predict(X_test)\nPRED_3_SVM_Sample=M3_SVM_scaled.predict(Xs_Test)","66b7c5cf":"print(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----SVM  Model with Raw Data----\")\nprint(\"Model Score on Raw Training data :{}\".format(M3_SVM_Raw.score(X_train,Y_train) * 100))\nprint(\"Model Score on Raw Test Data : {}\".format(M3_SVM_Raw.score(X_test,Y_test) * 100))\nprint(classification_report(Y_test,PRED_3_SVM_Raw))\nCM_M3_SVM=confusion_matrix(Y_test,PRED_3_SVM_Raw,labels=[0,1])\nsns.heatmap(CM_M3_SVM,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Support Vector Machine with Raw Data:{}\".format(accuracy_score(Y_test,PRED_3_SVM_Raw)*100))\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----SVM  Model with Scaled Data----\")\nprint(\"Model Score on scaled Training data :{}\".format(M3_SVM_scaled.score(Xs_Train,Ys_train) * 100))\nprint(\"Model Score on scaled Test data :{}\".format(M3_SVM_scaled.score(Xs_Test,Ys_Test) * 100))\nprint(classification_report(Ys_Test,PRED_3_SVM_Sample))\nCM_M3_SVM=confusion_matrix(Ys_Test,PRED_3_SVM_Sample,labels=[0,1])\nsns.heatmap(CM_M3_SVM,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Support Vector Machine with Scaled  Data:{}\".format(accuracy_score(Ys_Test,PRED_3_SVM_Sample)*100))\nif (M3_SVM_Raw.score(X_train,Y_train) > M3_SVM_scaled.score(Xs_Train,Ys_train)):\n    print(\"Model Score on Raw Training Data is higher than Scaled Training Data\")\nelse : \n    print(\"Model Score on Scaled Training Data is higher than Raw Training Data\")\nif (M3_SVM_Raw.score(X_test,Y_test) > M3_SVM_scaled.score(Xs_Test,Ys_Test)):\n    print(\"Model Score on Raw Testing Data is higher than Scaled Testing Data\")\nelse : \n    print(\"Model Score on Scaled Testing Data is higher than Raw Testing Data\")","1b30ee45":"from sklearn.neighbors import KNeighborsClassifier\nM4_KNN_Raw=KNeighborsClassifier()","d2222c5b":"M4_KNN_sample=KNeighborsClassifier()","bb969e9c":"M4_KNN_Raw.fit(X_train,Y_train)\nM4_KNN_sample.fit(Xs_Train,Ys_train)","f2cb9314":"print(M4_KNN_Raw.score(X_train,Y_train))\nprint(M4_KNN_sample.score(Xs_Train,Ys_train))","ab3b8e2c":"print(M4_KNN_Raw.score(X_test,Y_test))\nprint(M4_KNN_sample.score(Xs_Test,Ys_Test))","6e4dc2d7":"PRED_4_KNN_Raw=M4_KNN_Raw.predict(X_test)\nPRED_4_KNN_Sample=M4_KNN_sample.predict(Xs_Test)","e768d8b1":"print(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----KNN  Model with Raw Data----\")\nprint(\"Model Score on Raw Training data :{}\".format(M4_KNN_Raw.score(X_train,Y_train) * 100))\nprint(\"Model Score on Raw Test Data : {}\".format(M4_KNN_Raw.score(X_test,Y_test) * 100))\nprint(classification_report(Y_test,PRED_4_KNN_Raw))\nCM4_KNN_Raw=confusion_matrix(Y_test,PRED_4_KNN_Raw,labels=[0,1])\nsns.heatmap(CM4_KNN_Raw,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of KNN with Raw Data:{}\".format(accuracy_score(Y_test,PRED_4_KNN_Raw)*100))\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----KNN  Model with Scaled Data----\")\nprint(\"Model Score on scaled Training data :{}\".format(M4_KNN_sample.score(Xs_Train,Ys_train) * 100))\nprint(\"Model Score on scaled Test data :{}\".format(M4_KNN_sample.score(Xs_Test,Ys_Test) * 100))\nprint(classification_report(Ys_Test,PRED_4_KNN_Sample))\nCM4_KNN_SCALED=confusion_matrix(Ys_Test,PRED_4_KNN_Sample,labels=[0,1])\nsns.heatmap(CM4_KNN_SCALED,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of KNN with Scaled  Data:{}\".format(accuracy_score(Ys_Test,PRED_4_KNN_Sample)*100))\nif (M4_KNN_Raw.score(X_train,Y_train) > M4_KNN_sample.score(Xs_Train,Ys_train)):\n    print(\"Model Score on Raw Training Data is higher than Scaled Training Data\")\nelse : \n    print(\"Model Score on Scaled Training Data is higher than Raw Training Data\")\nif (M4_KNN_sample.score(X_test,Y_test) > M4_KNN_sample.score(Xs_Test,Ys_Test)):\n    print(\"Model Score on Raw Testing Data is higher than Scaled Testing Data\")\nelse : \n    print(\"Model Score on Scaled Testing Data is higher than Raw Testing Data\")","c2f990e4":"from sklearn.metrics import roc_curve,auc,roc_auc_score\nPRED_PROB_LOG_A=M1_Log_Raw.predict_proba(X_test)\nPRED_PROB_LOG_B=M1_Log_scaled.predict_proba(Xs_Test)\nPRED_PROB_NB_A=Model2_NB.predict_proba(X_test)\nPRED_PROB_NB_B=Model2_NB.predict_proba(Xs_Test)\nPRED_PROB_SVM_A=M3_SVM_Raw.predict_proba(X_test)\nPRED_PROB_SVM_B=M3_SVM_scaled.predict_proba(Xs_Test)\nPRED_PROB_KNN_A=M4_KNN_Raw.predict_proba(X_test)\nPRED_PROB_KNN_B=M4_KNN_sample.predict_proba(Xs_Test)\n\n\nfpr1, tpr1, thresh1 = roc_curve(Y_test, PRED_PROB_LOG_A[:,1], pos_label=1)\nfpr2,tpr2,thresh2= roc_curve(Ys_Test,PRED_PROB_LOG_B[:,1],pos_label=1)\nfpr3,tpr3,thresh3=roc_curve(Y_test,PRED_PROB_NB_A[:,1],pos_label=1)\nfpr4,tpr4,thresh4=roc_curve(Ys_Test,PRED_PROB_NB_B[:,1],pos_label=1)\nfpr5,tpr5,thresh5=roc_curve(Y_test,PRED_PROB_SVM_A[:,1],pos_label=1)\nfpr6,tpr6,thresh6=roc_curve(Ys_Test,PRED_PROB_SVM_B[:,1],pos_label=1)\nfpr7,tpr7,thresh7=roc_curve(Y_test,PRED_PROB_KNN_A[:,1],pos_label=1)\nfpr8,tpr8,thresh8=roc_curve(Ys_Test,PRED_PROB_KNN_B[:,1],pos_label=1)\n\n\nrandom_probs = [0 for i in range(len(Y_test))]\np_fpr, p_tpr, _ = roc_curve(Y_test, random_probs, pos_label=1)\n\n\nAUC_LOG_RAW=roc_auc_score(Y_test,PRED_PROB_LOG_A[:,1])\nAUC_LOG_SAMPLED=roc_auc_score(Ys_Test,PRED_PROB_LOG_B[:,1])\nAUC_NB_RAW=roc_auc_score(Y_test,PRED_PROB_NB_A[:,1])\nAUC_NB_UPSAMPLED=roc_auc_score(Ys_Test,PRED_PROB_NB_B[:,1])\nAUC_SVM_RAW=roc_auc_score(Y_test,PRED_PROB_SVM_A[:,1])\nAUC_SVM_SCALED=roc_auc_score(Ys_Test,PRED_PROB_SVM_B[:,1])\nAUC_KNN_RAW=roc_auc_score(Y_test,PRED_PROB_KNN_A[:,1])\nAUC_KNN_UPSAMPLED=roc_auc_score(Ys_Test,PRED_PROB_KNN_B[:,1])\nAUC_SCORES=pd.array([AUC_LOG_RAW,AUC_LOG_SAMPLED,AUC_NB_RAW,AUC_NB_UPSAMPLED,AUC_SVM_RAW,AUC_SVM_SCALED,AUC_KNN_RAW,AUC_KNN_UPSAMPLED])\n#Plot Area Under Curve\n\n#plt.plot(fpr1,tpr1,linestyle='--',color='orange', label='Logistic Regression RAW')\nplt.plot(fpr2,tpr2,linestyle='solid',color='blue', label='Logistic Regression Scaled')\n#plt.plot(fpr3,tpr3,linestyle='--',color='Green', label='Naive Bayes RAW')\nplt.plot(fpr4,tpr4,linestyle='solid',color='Red', label='Naive Bayes Scaled')\n#plt.plot(fpr5,tpr5,linestyle='--',color='violet',label='SVM RAW')\nplt.plot(fpr6,tpr6,linestyle='--',color='black',label='SVM Scaled')\n#plt.plot(fpr7,tpr7,linestyle='--',color='violet',label='KNN RAW')\nplt.plot(fpr8,tpr8,linestyle='solid',color='orange',label='KNN Scaled')\n\nplt.plot(p_fpr, p_tpr, linestyle=':', color='red')\n# title\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC',dpi=300)\nplt.show();\n\nprint(\"ROC_AUC_Score for Logistic Regression with Raw Data:{}\".format(AUC_LOG_RAW  * 100))\nprint(\"ROC_AUC_Score for Logistic Regression with scaled  Data:{}\".format(AUC_LOG_SAMPLED  * 100))\nprint(\"ROC_AUC_Score for Naive Bayes with Raw Data:{}\".format(AUC_NB_RAW * 100))\nprint(\"ROC_AUC_Score for Naive Bayes with scaled  Data:{}\".format(AUC_NB_UPSAMPLED * 100))\nprint(\"ROC_AUC_Score for SVM with Raw Data:{}\".format(AUC_SVM_RAW * 100))\nprint(\"ROC_AUC_Score for SVM with Scaled  Data:{}\".format(AUC_SVM_SCALED * 100))  \nprint(\"ROC_AUC_Score for KNN with Raw Data:{}\".format(AUC_KNN_RAW * 100))\nprint(\"ROC_AUC_Score for KNN with Scaled  Data:{}\".format(AUC_KNN_UPSAMPLED * 100))  \nprint(\"=======================================================================\")\nprint(\"The Best AUC_SCORE that we have got is :{}\".format(AUC_SCORES.max()  * 100))","99d8eb0a":"from mlxtend.classifier import StackingCVClassifier # I am using mlxtend libraray for the this purpose of stacking\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier","33afa5ff":"clf1 = GaussianNB()\nclf2 = RandomForestClassifier(criterion='gini',random_state=1, n_estimators=300)\nclf3 = KNeighborsClassifier(n_neighbors=5,weights='distance',algorithm='ball_tree')\n\nMeta_CLF = LogisticRegression(solver='liblinear',max_iter=100,C=1.0)\nsclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=Meta_CLF, use_probas=True, cv=3,random_state=32)\n\nfor clf, label in zip([clf1, clf2, clf3, sclf], \n                      ['Gaussian Naive', \n                       'Random Forest', \n                       'KNN',\n                       'StackingClassifier']):\n\n    scores = model_selection.cross_val_score(clf, Xs_Train, Ys_train, cv=3, scoring='roc_auc')\n    print(\"Accuracy: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean() * 100, scores.std(), label))\n\n    # Fit on train data \/ predict on test data\nsclf_fit = sclf.fit(Xs_Train, Ys_train)\nmypreds = sclf_fit.predict_proba(Xs_Test)\n# \"predict\" delivers classes, \"predict_proba\" delivers probabilities\n# Probabilities for classes (1,0)\nzeros = [i[0] for i in mypreds]\nones  = [i[1] for i in mypreds]\n\n# Get IDs and predictions\ny_id = Ys_Test.values.tolist()\npreddf = pd.DataFrame({'ID_code': y_id,'target': ones})\npreddf['ID_code'] = preddf['ID_code'].map(lambda x: str(x)[:-2])\npreddf['ID_code'] = preddf['ID_code'].map(lambda x: str(x)[2:])\n\n\n\n\n# Look at predictions\n#print(preddf.head())\n\n# Save DF\npreddf.to_csv('submission.csv', index=False)","3576e223":"from sklearn.ensemble import RandomForestClassifier\nM5_RF_RAW=RandomForestClassifier()\nM5_RF_Scaled=RandomForestClassifier()\nM5_RF_RAW.fit(X_train,Y_train)\nM5_RF_Scaled.fit(Xs_Train,Ys_train)","e3c283c3":"PRED5_RF_RAW=M5_RF_RAW.predict(X_test)\nPRED5_RF_Scaled=M5_RF_Scaled.predict(Xs_Test)","3a8ba7c3":"print(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----Random Forest  Model with Raw Data----\")\nprint(\"Model Score on Raw Training data :{}\".format(M5_RF_RAW.score(X_train,Y_train) * 100))\nprint(\"Model Score on Raw Test Data : {}\".format(M5_RF_RAW.score(X_test,Y_test) * 100))\nprint(classification_report(Y_test,PRED5_RF_RAW))\nCM4_RF_RAW=confusion_matrix(Y_test,PRED5_RF_RAW)\nsns.heatmap(CM4_RF_RAW,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Random Forest with Raw Data:{}\".format(accuracy_score(Y_test,PRED5_RF_RAW)*100))\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----Random Forest  Model with Scaled Data----\")\nprint(\"Model Score on scaled Training data :{}\".format(M5_RF_Scaled.score(Xs_Train,Ys_train) * 100))\nprint(\"Model Score on scaled Test data :{}\".format(M5_RF_Scaled.score(Xs_Test,Ys_Test) * 100))\nprint(classification_report(Ys_Test,PRED5_RF_Scaled))\nCM5_RF_SCALED=confusion_matrix(Ys_Test,PRED5_RF_Scaled)\nsns.heatmap(CM5_RF_SCALED,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Random Forest with Scaled  Data:{}\".format(accuracy_score(Ys_Test,PRED5_RF_Scaled)*100))\nif (M5_RF_RAW.score(X_train,Y_train) > M5_RF_Scaled.score(Xs_Train,Ys_train)):\n    print(\"Model Score on Raw Training Data is higher than Scaled Training Data\")\nelse : \n    print(\"Model Score on Scaled Training Data is higher than Raw Training Data\")\nif (M5_RF_RAW.score(X_test,Y_test) > M5_RF_Scaled.score(Xs_Test,Ys_Test)):\n    print(\"Model Score on Raw Testing Data is higher than Scaled Testing Data\")\nelse : \n    print(\"Model Score on Scaled Testing Data is higher than Raw Testing Data\")","d8082193":"from sklearn.ensemble import BaggingClassifier\nBGS=BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear'),random_state=13)","cbe29b8b":"BGS.fit(Xs_Train,Ys_train)\nPRED_Bagging=BGS.predict(Xs_Test)\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----BAGGING with Scaled Data----\")\nprint(\"Model Score on scaled Training data :{}\".format(BGS.score(Xs_Train,Ys_train) * 100))\nprint(\"Model Score on scaled Test data :{}\".format(BGS.score(Xs_Test,Ys_Test) * 100))\nprint(classification_report(Ys_Test,PRED_Bagging))\nCM6_Bagging_Scaled=confusion_matrix(Ys_Test,PRED_Bagging)\nsns.heatmap(CM6_Bagging_Scaled,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Bagging with Scaled  Data:{}\".format(accuracy_score(Ys_Test,PRED_Bagging)*100))\n","9e611fdc":"from sklearn.ensemble import AdaBoostClassifier\nADA=AdaBoostClassifier()","a9a101db":"ADA.fit(Xs_Train,Ys_train)","43d9227a":"ADA.fit(Xs_Train,Ys_train)\nPRED_ADA=ADA.predict(Xs_Test)\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----Boosting with Scaled Data----\")\nprint(\"Model Score on scaled Training data :{}\".format(ADA.score(Xs_Train,Ys_train) * 100))\nprint(\"Model Score on scaled Test data :{}\".format(ADA.score(Xs_Test,Ys_Test) * 100))\nprint(classification_report(Ys_Test,PRED_ADA))\nCM7_Boosting_Scaled=confusion_matrix(Ys_Test,PRED_ADA)\nsns.heatmap(CM7_Boosting_Scaled,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint(\"The Accuracy Score of Boosiing with Scaled  Data:{}\".format(accuracy_score(Ys_Test,PRED_ADA)*100))\n","f0c1c8d7":"from sklearn.metrics import precision_score, recall_score\n","42fdc75d":"print(\"The Precision score:{} & Recall Score:{} of Logistic model on scaled data.\".format(precision_score(Ys_Test,Pred2_S,average='weighted')*100,recall_score(Ys_Test,Pred2_S,average='weighted')*100))\nprint(\"The Precision score:{} & Recall Score:{} of Gaussian Naive on scaled data.\".format(precision_score(Ys_Test,Model2_NB_pred_on_scaled,average='weighted')*100,recall_score(Ys_Test,Model2_NB_pred_on_scaled,average='weighted')*100))\nprint(\"The Precision score:{} & Recall Score:{} of SVM model on scaled data.\".format(precision_score(Ys_Test,PRED_3_SVM_Sample,average='weighted')*100,recall_score(Ys_Test,PRED_3_SVM_Sample,average='weighted')*100))\nprint(\"The Precision score:{} & Recall Score:{} of KNN model on scaled data.\".format(precision_score(Ys_Test,PRED_4_KNN_Sample,average='weighted')*100,recall_score(Ys_Test,PRED_4_KNN_Sample,average='weighted')*100))\nprint(\"The Precision score:{} & Recall Score:{} of Random Forest on scaled data.\".format(precision_score(Ys_Test,PRED5_RF_Scaled,average='weighted')*100,recall_score(Ys_Test,PRED5_RF_Scaled,average='weighted')*100))\nprint(\"The Precision score:{} & Recall Score:{} of Bagging on scaled data.\".format(precision_score(Ys_Test,PRED_Bagging,average='weighted')*100,recall_score(Ys_Test,PRED_Bagging,average='weighted')*100))\nprint(\"The Precision score:{} & Recall Score:{} of ADA Boosting on scaled data.\".format(precision_score(Ys_Test,PRED_ADA,average='weighted')*100,recall_score(Ys_Test,PRED_ADA,average='weighted')*100))","0b05d08c":"# Split Data using train test split","91ae531a":"## Handling Class Imbalance \n\n1. 75% of our data were positive for parkinson's disease, In order to solve the class imbalance I am using upsampling method using resample.\n2. Through this method we will generate random samples of minority data (Status=0) and add them to the dataset, This method will allow our models to make decisions without bias towards the majority class.\n3. Now all our models will be compared for metrics on two datasets.\n\n### Raw, Unscaled, Imbalanced Dataset VS Scaled, Balanced Dataset ","bd6277fa":"# Final Comparison \n\nWhen we compare all our Supervised learning Models(Logistic,KNN, SVM, Gaussian Naive) & Ensemble models (Random Forest,Bagging and Boosting ). \n\n### We observe that:\n\n1. All models have performed better on scaled data , and definitely scaling\/Normalization should be considered before proceeidng with analysis as this has a great impact on our results.\n2. Though Some models have very good accuracy score, their precision and recall are not that great.\n3. Considering the accuracy score alone in this problem statement is not advisable, we should consider Precision , Recall & Type 2 error.\n4. Type 1 error or False positive for this statement can be neglected to an extent as misclassifications here may further be diagnoised, In other words we are not going to miss much by saying a healthy person to be positive of PD as further diagnosis is going to clarify the symptoms.\n5. To the flip side Type 2 error or False Negavtives should be highly condsidered, If we classify a PD positive as healthy then the person may be not treated and this could further worsen their well being. \n\n### What is  Precision??\n\n##### Precision is nothing but, what propation of our positive prediction were actually positive.\n\n### What is Recall??\n\n#### Recall is propotion of our predicted positives vs Total number of positives.\n\n##### For our Problem Statement.\n\nPositive means Person is healthy\nNegative means Person is Positive for Parkinson's disease.","ab825d79":"Our Dataset that is going to be scaled has equal values for both classes without Bias","83b7bddd":"MDVP density is high at 250 which substantiates the mean value of 195\nRPDE density is high between 0.4 & 0.6","d8cafe34":"# BAGGING","c3c47662":"#### Ada Boostin has done great too in this dataset. \n\nWith upsampled and Scaled data our Type 1 error is zero, and Type 2 error is just 2.\nThe model has produced an accuracy score of whooping 98% with precision & recall 1.00 & 0.95\n\n##### Take Away :\n\n1. When our model says a person is positive(Healthy) they are 100% positive.\n2. Propotion of our predicted positives vs Total number of positives is 95%.\n3. There is no False positive prediction made(Type 1 Error), Our model has not done a misclassification on saying a Healthy person to be Positive of Parkinson's disease.\n4. Though there are type 2 errprs , where our model says a PD positive person as healthy, the error rate is less. \n5. Considering all the advantages of this model, Type 2 error is minimal.\n","855c7ea3":"Our KNN Model with scaled data has better precison , Recall and less type 2 error, when this model says 43 people are halthy 92% they are helathy.","0697efb9":"1. Maximum vocal fundamemtal frequency of both healthy and PD positive patients has a strong overlap with each other. With Max vocal freq alone it is hard to say if a person is Positive or not.\n\n#### Though there is someoverlap \n2.  Average vocal fundamental freq & Minimum fundamental frq has some clear distribution at some intravels.","7d1977dd":"## Five Point Summary","5bbb20ea":"Measures of variation in amplitude also has overlapping, but PD positive individuals have high value for all parametes which denotes variation in amplitude","0fac1ec1":"#### Though Model score is 74% our recall score for SVM is high with 0.93 which means , Out of total positives how much positives we predicted right.\n\nPrecison is low, Among the positives we predicted how much were actually positive(","a1134159":"# Data Observations:\n\n1. Our Dataset  has 24 attributes\/columns.\n2. We deal with Object, Int and Float datatype\n3. Status Column is a categorical variable with dtype int.\n4. Missing Values - Though in the description file it has been mentioned missing values are denoted by N\/A, We do not see any   N\/A value in the dataset.\n5. Our independent variables are measured in different scales Hz, DB, %, Absolute value(MDVP:Jitter(Abs)), Hence we have may have to use a scaling techinque to scale different quantities of measurement.","3029cfb1":"#### Our Meta Classifier has produced a accuracy score of 99.17 % which is great. This is the significance of stacking.\n\nStacking is an ensemble machine learning algorithm that learns how to best combine the predictions from multiple well-performing machine learning models.\n\nThe meta-model is trained on the predictions made by base models on out-of-sample data. That is, data not used to train the base models is fed to the base models, predictions are made, and these predictions, along with the expected outputs, provide the input and output pairs of the training dataset used to fit the meta-model.\n\n##### We use three models to three models Gaussian Naive,KNN & Random forest to train our data, These individual predictions are later used and fed to our Meta Classifier which is LogisticRegression.\n\n#### Advantages & how it is different from Bagging and Boositing.\n\n### Advantages : \n\n1. Same dataset can be exposed and analyzed by different ML models that are good in different ways\n2. Unlike Bagging , Stacking is not limited to just decision tress and are VERSATILE\/ Flexible to other models.\n3. Unlike Boosting , the model is not seqentially improved based on predictions, A single model is used to do the best         prediction among the other models.","b0efe49a":"#### See the distribution of MDVP:Fo(Hz) - Average vocal fundamental frequency,MDVP:Fhi(Hz) - Maximum vocal fundamental frequency and MDVP:Flo(Hz) - Minimum vocal fundamental frequency for both healthy and PD positive patients.\n\n1. I am using scatter plot for this univariate analysis.\n2. Using np.zeros_like to have y axis without any value \n3. Using alpha to ensure we are clearly able to see the overlap,The alpha blending value, between 0 (transparent) and 1 (opaque).","e2b08b70":"### Inference: \n\n#### As you can see, Our Logistic model has 88% on training and 85% on test dataset, There may be a chance of slight overfit and different scales of measurement may have had some degree of influence in our analysis..\n\n## Let's Fix that","0015a9b6":"Naive Bayes doesn't seem to be a good model for this problem statement.\n\nThe model performance in terms of Accuracy, Type 1 & Tyoe 2 errors suggest Naive bayes should not be considered for prediction in this case.\n\nThe type 1 error false Negative numbers alone can be considered to reject this model. \n\nBoth raw & scaled data produce type 2 error of 14 & 15, which means it wrongly classifies PD positive person as healthy person which has a lot of risks.\n\nNaive Bayes is not Recommended for this dataset.","b9e56ab9":"# K Nearest Neighbour ","7e9573be":"#### Does variation in amplitude has any impact on Parkinsons Disease Diagnosis???","cf662ef0":"# Boosting ","d174abad":"## Result :\n\n1. From All our models we can say that our Ensemble model with Logistic Regression as meta classifier was good with 99.17% accuracy on test data.\n2. Our Random Forest & Boosting model is  having 1.00 precision and 0.95  recall.\n3. This means when our model says a person is positive for Parkinsons we are 100% confident that the person is poitive for PD.\n\n#### Considering all these accuracy\/Precision\/ Recall our Stacking Model,Random Forest and Boosting model is the best models to classify the patients into the respective labels using the attributes from their voice recordings.","a0099304":"#### Does ratio of noise to tonal components(HNR,NHR) & measures of fundamental frequency variation(spread 2) have any impact on Diagnosis ??","91b5b1bc":"Scaling the Data since we have multiple magnitude and Units of independent variable.\n\n1. Some have Hertz \n2. Some have Decibel\n3. Some have percentage\n\nVariables in hertz tend to have higher magnitude and hence it is good to scale our data , If not scaled these variables may tend to outweigh the analysis and it is a good preactise to scale the dataset.\n\nI am using Standard scaler for this activity from skilearn, Since our dataset is small I am scaling the entire dataset and then spliting them into training and testing data.","f1c7f610":"HNR  for PD positive is distributed between 3 to 32\nHNR  for Healthy person is distributed between 13 to 37","11b625a9":"Several measures of variation in amplitude","15f2c130":"# Meta-classifier","1d69fddc":"## Time to Check some Hypothesis","b4a35b5e":"### Univariate Analysis","e6a4d7b7":"### Evaluating Supervised Learning Models through ROC AUC scores","5167e573":"#### Inference :\n1. Our Central Tendancies of attributies tend have a relation with their unit of measurement. \n2. Attributes measured in Hertz have high magnitude. Whereas ,Central tendancies\/Min max features of other units like Decibel.","6dcb0a81":"# Logistic Regression ","585c74fe":"Now that we have trained our models, Let's see the concept of Stacking \n\nStacking is the process of using multiple models to predict the target and use them finally on a Meta Classifier","8b72c309":"Though , Naive bayes has a goood AUC_ROC score of 91.25, That is not our best model. As I have said right after applying Gaussian Naive the type 1 and type 2 (False Positive & False Negative) errors are high for this model.\n\nRecall is low just 0.67, which means it is just above 0.5. We have much better models that could do the job right than the Naive Bayes.\n\nOur KNN model has produced AUC_SCORE of 95% which is phenomenoal and Area Under Curve is more.As you can see the Orange line it is smooth and covers a wider area for FPR VS TPR.\n\n","716e6807":"# Random Forest ","8b3848b7":"We could see that the Our Logistic Model on scaled, balanced data has a good score on Testing data than Training.","112fcbb2":"# Naive Bayes ","6d17b7fb":"### The Model we were looking for :\n\n#### Random Forest has done great for us in this dataset. \n\nWith upsampled and Scaled data our Type 1 error is zero, and Type 2 error is just 2.\nThe model has produced an accuracy score of whooping 98% with precision & recall 1.00 & 0.95\n\n##### Take Away :\n\n1. When our model says a person is positive(Healthy) they are 100% positive.\n2. Propotion of our predicted positives vs Total number of positives is 95%.\n3. There is no False positive prediction made(Type 1 Error), Our model has not done a misclassification on saying a Healthy person to be Positive of Parkinson's disease.\n4. Though there are type 2 errprs , where our model says a PD positive person as healthy, the error rate is less. \n5. Considering all the advantages of this model, Type 2 error is minimal.\n","652063a3":"NHR for PD positive is higher than that of the healthy person ","36253478":"# Ensemble Technique Project","18f8ab4c":"Correlation between :\n1. Average vocal fundamental frequency vs Measures of variation in fundamental frequency - They are negatively corelated\n2. Average vocal fundamental frequency vs Measures of variation in amplitude - They are negatively corelated too \n3. Measures of variation in fundamental frequency VS Measures of variation in amplitude - They are positivley corelated\n","39190519":"TIP : Using liblinear solver here as that is best for small datasets, 'liblinear' is a good choice, whereas 'sag' and\n      'saga' are faster for large ones.\n     For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n     handle multinomial loss; 'liblinear' is limited to one-versus-rest\n     schemes.","1cad1bb2":"## Target Class Distribution - Status column\n\n1.  Our Variable of interest in this dataset is Status column, with all other parameters of voice given for a patient , Our model will predict if the person is healthy or he\/she symptotic towards parkinson's \n\n### TIP : Pandas by default has the capability to check  missing value and \u201cNA\u201d through isnull() method, However we have been said that missing values are marked N\/A in this dataset. To customize the other values like __,N\/A,? we can create a list and use the \"missing_values\" parameter while reading the dataset.\n\nThis option allows us to handle missing values which are not handled by pandas by default.","4d7010f1":"# Inference Confusion Matrix Logistic Regression\n\n1. Our Model predicted that 35 were positive for Parkinson's disease and they were actually positive.\n2. Our scaled data says 7 were predicted to be having Parkinson's and they were actually healthy compared to True Negative values of Raw data\n3. Type 1 & Type 2 errors (False Positive, False Negative)\n\nIn  this problem statement , False negative means our model is saying a positive person symptotic of Parkinson's disease as a healthy person.\n\n# TRADE OFF ERRORS(TYPE1 & TYPE2)\n\nFalse Positive in this scenario can be somewhat accepted, as the person may further be tested for the PD condition and this error does not going to cause larger issue. \n\nHowever, False Negatives Should be precise and minimun, as we cannot allow our model to predict a PD positive person to be healthy as this may cause greater implications in terms of further diagnosis and treatment.\n\nWhen we compare both our logistic model on Raw and scaled data , Both  model on scaled & raw data does produce  False Negatives.\n\nConsidering, Accuracy, F1 score  & errors(Our Logistic model on scaled data is better and scores on testing data is better and improving from training data)","318ee2b9":"Symmetrical distribution : Values close to 0\n1. MDVP:Fo(Hz)\n2. spread1\n3. spread2\n4. PPE\n\nNegative skewness and Tail is larger towards the left hand side of the distribution\n1. HNR\n2. status\n3. RPDE\n4. DFA\n\nPositive skewness and Tail is larger towards the Right hand side of the distribution\nAll other attributes have a very high distribution towards right of the median","93116f46":"# Support Vector Machine","3dc01095":"Though there is overlap in factors of amplitude we could see that the PD positive patients tend to have high rate of factors for amplitude compared to that of healthy individuals.\n\nJitter Abs value is almost same for for healthy and Positive patients and it has a avg value of 0.000044"}}