{"cell_type":{"7acd1947":"code","64d6354f":"code","ac879df4":"code","5f361028":"code","723a03bf":"code","3be93722":"code","1fd84fbd":"code","067ccf3b":"code","f6a15284":"code","9551aba2":"code","ad91812e":"code","d40cd816":"code","b8430163":"code","037b032d":"code","b2636817":"code","7e43f834":"code","08846111":"code","310940c7":"code","f0205fc1":"code","9d117465":"code","00eccaf3":"code","dc1473bd":"code","9afbff97":"code","571dce53":"code","3fa17278":"code","589ec489":"code","4d0e0dd1":"code","a8034d33":"code","aafa2673":"code","75044355":"code","44157d4f":"code","bcb46b8a":"code","b7718ead":"code","271b7ef6":"code","6f4d2210":"code","c4682622":"code","074e195a":"code","2eada6e4":"code","879e6f55":"code","5bfd4dd2":"code","503fd4a7":"code","b33a22f5":"code","30911eb7":"code","b501bb04":"code","409aec28":"code","bd73ecc9":"code","6e5fdde8":"code","59fdf115":"code","944e76a4":"code","4cfb9da6":"code","53163a53":"code","42427270":"code","c491e7a4":"code","e4b1089c":"code","dff9c1ee":"code","57607aca":"code","2b605328":"code","078078d5":"code","c1e1e876":"code","387dc649":"code","091a4e41":"code","9fc71622":"code","20cd3c6a":"code","4a90cedc":"code","8435a7b7":"code","e50e4cad":"code","a9676bbc":"code","1e6aa20e":"code","4abdd3f9":"code","6d3c2b54":"code","8d8d652a":"code","30405602":"code","316a2eb2":"code","9386424e":"code","7dfbda73":"code","539f0e68":"code","b248b810":"code","80ff3417":"code","d7818750":"code","15a43b5d":"code","0852ed93":"markdown","71ac5d27":"markdown","bc38c09c":"markdown","944fb646":"markdown","30865979":"markdown","6ff8d674":"markdown","d1939ffb":"markdown","6585217e":"markdown","3ba7805f":"markdown","c7eab819":"markdown","7aa486d3":"markdown","9f77cad8":"markdown","eba6fd97":"markdown","3529fabb":"markdown","3777ce28":"markdown","e484c2dd":"markdown","a90be0f6":"markdown","a2ce57c6":"markdown","c624b040":"markdown","ffceb130":"markdown","20c8371c":"markdown","6e962c37":"markdown","e5f7047c":"markdown","cb042c8f":"markdown","8f55fd1f":"markdown","76ed8288":"markdown","f8763fe7":"markdown","696f2b13":"markdown","9a87b173":"markdown","c49081bd":"markdown","0f0b58dd":"markdown","4696f9cc":"markdown","642de1dc":"markdown"},"source":{"7acd1947":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","64d6354f":"heart_data_df = pd.read_csv('..\/input\/heart.csv')\nheart_data_df.head()","ac879df4":"heart_data_df.rename(columns={'sex':'sex(numeric)',\n                              'cp':'chest_pain_type(numeric)', \n                              'trestbps':'resting_blood_pressure', \n                              'chol':'serum_cholestrol', \n                              'fbs':'fasting_blood_sugar(numeric)',\n                              'restecg':'resting_ecg_results(numeric)',\n                              'thalach':'max_heart_rate', \n                              'exang':'exercise_angina(numeric)',\n                              'ca':'n_major_colored_vessels(numeric)',\n                              'slope':'slope(numeric)',\n                              'thal':'thal(numeric)',\n                              'target':'condition(numeric)'}, inplace=True)\nheart_data_df.head()","5f361028":"heart_data_df['sex(categorical)'] = heart_data_df['sex(numeric)'].astype('category')\nheart_data_df['sex(categorical)'].cat.categories = ['female', 'male']\n\nheart_data_df['fasting_blood_sugar(categorical)'] = heart_data_df['fasting_blood_sugar(numeric)'].astype('category')\nheart_data_df['fasting_blood_sugar(categorical)'].cat.categories = ['normal', 'high']\n\nheart_data_df['exercise_angina(categorical)'] = heart_data_df['exercise_angina(numeric)'].astype('category')\nheart_data_df['exercise_angina(categorical)'].cat.categories = ['no', 'yes']\n\nheart_data_df['condition(categorical)'] = heart_data_df['condition(numeric)'].astype('category')\nheart_data_df['condition(categorical)'].cat.categories = ['healthy', 'diseased']\n\nheart_data_df.dtypes","723a03bf":"sns.set(palette='tab10')","3be93722":"plot = sns.countplot(data=heart_data_df, x='condition(categorical)')\nplot.set_ylim((0, 225))\n\ncounts = heart_data_df[['age', 'condition(categorical)']].groupby(['condition(categorical)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\n\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex,\n              counts.loc[counts_iter, 'count'] + 8,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","1fd84fbd":"plt.figure(figsize=(7,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='sex(categorical)')\nplot.set_ylim((0, 160))\n\ncounts = heart_data_df[['age', 'sex(categorical)', 'condition(categorical)']].groupby(['condition(categorical)', 'sex(categorical)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - plot.patches[0].get_width() \/ 2,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + plot.patches[0].get_width() \/ 2,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","067ccf3b":"plt.figure(figsize=(7,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='fasting_blood_sugar(categorical)')\nplot.set_ylim((0, 225))\n\ncounts = heart_data_df[['age', 'fasting_blood_sugar(categorical)', 'condition(categorical)']].groupby(['condition(categorical)', 'fasting_blood_sugar(categorical)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - plot.patches[0].get_width() \/ 2,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + plot.patches[0].get_width() \/ 2,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","f6a15284":"plt.figure(figsize=(7,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='exercise_angina(categorical)')\nplot.set_ylim((0,200))\n\ncounts = heart_data_df[['age', 'exercise_angina(categorical)', 'condition(categorical)']].groupby(['condition(categorical)', 'exercise_angina(categorical)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - plot.patches[0].get_width() \/ 2,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + plot.patches[0].get_width() \/ 2,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","9551aba2":"plt.figure(figsize=(13,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='chest_pain_type(numeric)')\nplot.set_ylim((0,140))\n\ncounts = heart_data_df[['age', 'chest_pain_type(numeric)', 'condition(categorical)']].groupby(['condition(categorical)', 'chest_pain_type(numeric)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - 1.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex - 0.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + 0.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + 1.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","ad91812e":"plt.figure(figsize=(10,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='resting_ecg_results(numeric)')\nplot.set_ylim((0, 160))\n\ncounts = heart_data_df[['age', 'resting_ecg_results(numeric)', 'condition(categorical)']].groupby(['condition(categorical)', 'resting_ecg_results(numeric)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","d40cd816":"plt.figure(figsize=(13,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='thal(numeric)')\nplot.set_ylim((0,180))\n\ncounts = heart_data_df[['age', 'thal(numeric)', 'condition(categorical)']].groupby(['condition(categorical)', 'thal(numeric)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - 1.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex - 0.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + 0.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + 1.5 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","b8430163":"plt.figure(figsize=(13,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='slope(numeric)')\nplot.set_ylim((0,180))\n\ncounts = heart_data_df[['age', 'slope(numeric)', 'condition(categorical)']].groupby(['condition(categorical)', 'slope(numeric)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","037b032d":"plt.figure(figsize=(16,5))\nplot = sns.countplot(data=heart_data_df, x='condition(categorical)', hue='n_major_colored_vessels(numeric)')\nplot.set_ylim((0,180))\n\ncounts = heart_data_df[['age', 'n_major_colored_vessels(numeric)', 'condition(categorical)']].groupby(['condition(categorical)', 'n_major_colored_vessels(numeric)']).count().rename(columns={'age':'count'}).reset_index()\ntotal = counts['count'].sum()\ncounts_iter = 0\nfor barIndex in range(len(counts['condition(categorical)'].unique())):\n    plot.text(barIndex - 2 * plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex - plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex,\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + plot.patches[0].get_width(),\n              counts.loc[counts_iter, 'count'] + 2.5,\n              str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n              color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1\n    \n    plot.text(barIndex + 2 * plot.patches[0].get_width(),\n          counts.loc[counts_iter, 'count'] + 2.5,\n          str(counts.loc[counts_iter, 'count']) + '\\n(' + str(round((counts.loc[counts_iter, 'count'] \/ total)*100, 2)) + '%)',\n          color='black', horizontalAlignment='center', fontsize=15)\n    counts_iter += 1","b2636817":"scatter_mat = sns.pairplot(data=heart_data_df[['condition(categorical)', 'age', 'resting_blood_pressure', 'serum_cholestrol', 'max_heart_rate', 'oldpeak']],\n             diag_kind='kde',\n             hue='condition(categorical)',\n             markers='o')\nupper_triangle_indices = np.triu_indices_from(scatter_mat.axes, 1)\nrow_indices, column_indices = upper_triangle_indices[0], upper_triangle_indices[1]\nfor i,j in zip(row_indices, column_indices):\n    scatter_mat.axes[i, j].set_visible(False)","7e43f834":"experiments_df = pd.DataFrame(columns=['classifier', 'best_acc_params', 'best_prec_params', 'best_recall_params', 'best_f1_params', 'Scaled', 'n_PCA_comps', 'n_MDS_comps'])\nfeature_cols = ['age', 'sex(numeric)', 'fasting_blood_sugar(numeric)', 'chest_pain_type(numeric)', 'resting_blood_pressure', 'serum_cholestrol', 'resting_ecg_results(numeric)', 'max_heart_rate', 'exercise_angina(numeric)', 'oldpeak', 'slope(numeric)', 'n_major_colored_vessels(numeric)', 'thal(numeric)']\nX = heart_data_df[feature_cols]\ny = heart_data_df['condition(numeric)']","08846111":"C_values = [round(n, 2) for n in list(np.arange(0.010, 1.1, 0.010))] + [round(n, 2) for n in list(np.arange(1.1, 2.1, 0.10)) + [*range(3, 31)]]\nkernels = ['linear', 'rbf', 'sigmoid']\nn_cores = -1","310940c7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=DeprecationWarning)","f0205fc1":"def get_best_hyper_params(classifier_type, input_features, labels, kernel, cv, n_jobs, param_grid):\n    if(classifier_type == 'LogisticReg'):\n        classifier = LogisticRegression(random_state=0)\n    elif (classifier_type == 'SVM'):\n        if(kernel not in kernels):\n            return\n        classifier = SVC(kernel=kernel, random_state=0)\n    elif (classifier_type == 'kNN'):\n        classifier = KNeighborsClassifier()\n    elif (classifier_type == 'RandomForest'):\n        classifier = RandomForestClassifier(random_state=0)\n    else:\n        return\n        \n    acc_grid = GridSearchCV(classifier, cv=cv, n_jobs=n_jobs, param_grid=param_grid)\n    _ = acc_grid.fit(input_features, labels)\n    best_acc_params = acc_grid.best_params_.copy()\n    best_acc_params['score'] = acc_grid.best_score_\n    \n    prec_grid = GridSearchCV(classifier, cv=cv, n_jobs=n_jobs, param_grid=param_grid, scoring='precision')\n    _ = prec_grid.fit(input_features, labels)\n    best_prec_params = prec_grid.best_params_.copy()\n    best_prec_params['score'] = prec_grid.best_score_\n    \n    recall_grid = GridSearchCV(classifier, cv=cv, n_jobs=n_jobs, param_grid=param_grid, scoring='recall')\n    _ = recall_grid.fit(input_features, labels)\n    best_recall_params = recall_grid.best_params_.copy()\n    best_recall_params['score'] = recall_grid.best_score_\n    \n    f1_grid = GridSearchCV(classifier, cv=cv, n_jobs=n_jobs, param_grid=param_grid, scoring='f1')\n    _ = f1_grid.fit(input_features, labels)\n    best_f1_params = f1_grid.best_params_.copy()\n    best_f1_params['score'] = f1_grid.best_score_\n    \n    return best_acc_params, best_prec_params, best_recall_params, best_f1_params","9d117465":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='LogisticReg',\n#                                              input_features=X,\n#                                              labels=y, \n#                                              kernel=None,\n#                                              cv=4,\n#                                              n_jobs=n_cores, \n#                                              param_grid={'C':C_values})\n\n# experiments_df = experiments_df.append({'classifier':'LogisticReg',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':False,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","00eccaf3":"gammas = C_values","dc1473bd":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='SVM', \n#                                              input_features=X,\n#                                              labels=y, \n#                                              kernel='linear',\n#                                              cv=4,\n#                                              n_jobs=n_cores, \n#                                              param_grid={'C':C_values})\n\n# experiments_df = experiments_df.append({'classifier':'SVM_linear',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':False,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","9afbff97":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                              input_features=X,\n#                                              labels=y, \n#                                              kernel='rbf',\n#                                              cv=4,\n#                                              n_jobs=n_cores, \n#                                              param_grid={'C':C_values, 'gamma':gammas})\n\n# experiments_df = experiments_df.append({'classifier':'SVM_rbf',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':False,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","571dce53":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                              input_features=X,\n#                                              labels=y, \n#                                              kernel='sigmoid',\n#                                              cv=4,\n#                                              n_jobs=n_cores, \n#                                              param_grid={'C':C_values, 'gamma':gammas})\n\n# experiments_df = experiments_df.append({'classifier':'SVM_sigmoid',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':False,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","3fa17278":"n_neighbors = [*range(1, 21)]","589ec489":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='kNN',\n#                                              input_features=X,\n#                                              labels=y,\n#                                              kernel=None,\n#                                              cv=4,\n#                                              n_jobs=n_cores, \n#                                              param_grid={'n_neighbors':n_neighbors})\n\n# experiments_df = experiments_df.append({'classifier':'kNN',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':False,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","4d0e0dd1":"n_estimators = [*range(4, 51)]\nmax_features = [*range(1, 14)]\nmax_leaf_nodes = [*range(2, 101)]","a8034d33":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='RandomForest',\n#                                           input_features=X,\n#                                           labels=y,\n#                                           kernel=None,\n#                                           cv=4,\n#                                           n_jobs=n_cores, \n#                                           param_grid={'n_estimators':n_estimators, 'max_features':max_features, \n#                                                       'max_leaf_nodes':max_leaf_nodes})\n\n# experiments_df = experiments_df.append({'classifier':'RandomForest',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':False,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","aafa2673":"from sklearn.preprocessing import StandardScaler\nscaled_X = pd.DataFrame(StandardScaler().fit_transform(X))","75044355":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='LogisticReg',\n#                                              input_features=scaled_X,\n#                                              labels=y, \n#                                              kernel=None,\n#                                              cv=4,\n#                                              n_jobs=n_cores, \n#                                              param_grid={'C':C_values})\n\n# experiments_df = experiments_df.append({'classifier':'LogisticReg',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':True,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","44157d4f":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                              input_features=scaled_X,\n#                                              labels=y,\n#                                              kernel='linear',\n#                                              cv=4,\n#                                              n_jobs=n_cores,\n#                                              param_grid={'C':C_values})\n\n# experiments_df = experiments_df.append({'classifier':'SVM_linear',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':True,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","bcb46b8a":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                              input_features=scaled_X,\n#                                              labels=y,\n#                                              kernel='rbf',\n#                                              cv=4,\n#                                              n_jobs=n_cores,\n#                                              param_grid={'C':C_values, 'gamma':gammas})\n\n# experiments_df = experiments_df.append({'classifier':'SVM_rbf',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':True,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","b7718ead":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                              input_features=scaled_X,\n#                                              labels=y,\n#                                              kernel='sigmoid',\n#                                              cv=4,\n#                                              n_jobs=n_cores,\n#                                              param_grid={'C':C_values, 'gamma':gammas})\n\n# experiments_df = experiments_df.append({'classifier':'SVM_sigmoid',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':True,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","271b7ef6":"n_neighbors = [*range(1, 21)]","6f4d2210":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='kNN',\n#                                              input_features=scaled_X,\n#                                              labels=y,\n#                                              kernel=None,\n#                                              cv=4,\n#                                              n_jobs=n_cores,\n#                                              param_grid={'n_neighbors':n_neighbors})\n\n# experiments_df = experiments_df.append({'classifier':'kNN',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':True,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","c4682622":"n_estimators = [*range(4, 51)]\nmax_features = [*range(1, 14)]\nmax_leaf_nodes = [*range(2, 101)]","074e195a":"# (best_acc_params,\n#  best_prec_params,\n#  best_recall_params,\n#  best_f1_params) = get_best_hyper_params(classifier_type='RandomForest',\n#                                              input_features=scaled_X,\n#                                              labels=y,\n#                                              kernel=None,\n#                                              cv=4,\n#                                              n_jobs=n_cores,\n#                                              param_grid={'n_estimators':n_estimators, 'max_features':max_features,\n#                                                       'max_leaf_nodes':max_leaf_nodes})\n\n# experiments_df = experiments_df.append({'classifier':'RandomForest',\n#                                         'best_prec_params':best_prec_params,\n#                                         'best_recall_params':best_recall_params,\n#                                         'best_acc_params':best_acc_params,\n#                                         'best_f1_params':best_f1_params,\n#                                         'Scaled':True,\n#                                         'n_PCA_comps':0, 'n_MDS_comps':0}, ignore_index=True)\n# experiments_df","2eada6e4":"# experiments_df.to_msgpack('experiments.msgpack')","879e6f55":"from sklearn.decomposition import PCA","5bfd4dd2":"# for n_comps in range(1, 13):\n    \n#     pca = PCA(n_components=n_comps, random_state=0)\n#     pca_X = pd.DataFrame(pca.fit_transform(scaled_X))\n\n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='LogisticReg',\n#                                                  input_features=pca_X,\n#                                                  labels=y, \n#                                                  kernel=None,\n#                                                  cv=4,\n#                                                  n_jobs=n_cores, \n#                                                  param_grid={'C':C_values})\n\n#     experiments_df = experiments_df.append({'classifier':'LogisticReg',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':n_comps, 'n_MDS_comps':0}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                                  input_features=pca_X,\n#                                                  labels=y,\n#                                                  kernel='linear',\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'C':C_values})\n\n#     experiments_df = experiments_df.append({'classifier':'SVM_linear',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':n_comps, 'n_MDS_comps':0}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                                  input_features=pca_X,\n#                                                  labels=y,\n#                                                  kernel='rbf',\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'C':C_values, 'gamma':gammas})\n\n#     experiments_df = experiments_df.append({'classifier':'SVM_rbf',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':n_comps, 'n_MDS_comps':0}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                                  input_features=pca_X,\n#                                                  labels=y,\n#                                                  kernel='sigmoid',\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'C':C_values, 'gamma':gammas})\n\n#     experiments_df = experiments_df.append({'classifier':'SVM_sigmoid',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':n_comps, 'n_MDS_comps':0}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='kNN',\n#                                                  input_features=pca_X,\n#                                                  labels=y,\n#                                                  kernel=None,\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'n_neighbors':n_neighbors})\n\n#     experiments_df = experiments_df.append({'classifier':'kNN',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':n_comps, 'n_MDS_comps':0}, ignore_index=True)\n\n    \n#     max_features = list(set([1] + [*range(1, n_comps)]))\n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='RandomForest',\n#                                                  input_features=pca_X,\n#                                                  labels=y,\n#                                                  kernel=None,\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'n_estimators':n_estimators, 'max_features':max_features,\n#                                                           'max_leaf_nodes':max_leaf_nodes})\n\n#     experiments_df = experiments_df.append({'classifier':'RandomForest',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':n_comps, 'n_MDS_comps':0}, ignore_index=True)\n\n#     experiments_df.to_msgpack('experiments.msgpack')","503fd4a7":"from sklearn.manifold import MDS","b33a22f5":"# for n_comps in range(1, 13):\n#     mds = MDS(n_components=n_comps, random_state=0)\n#     mds_X = pd.DataFrame(mds.fit_transform(scaled_X))\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='LogisticReg',\n#                                                  input_features=mds_X,\n#                                                  labels=y, \n#                                                  kernel=None,\n#                                                  cv=4,\n#                                                  n_jobs=n_cores, \n#                                                  param_grid={'C':C_values})\n\n#     experiments_df = experiments_df.append({'classifier':'LogisticReg',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':0, 'n_MDS_comps':n_comps}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                                  input_features=mds_X,\n#                                                  labels=y,\n#                                                  kernel='linear',\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'C':C_values})\n\n#     experiments_df = experiments_df.append({'classifier':'SVM_linear',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':0, 'n_MDS_comps':n_comps}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_params) = get_best_hyper_params(classifier_type='SVM',\n#                                                  input_features=mds_X,\n#                                                  labels=y,\n#                                                  kernel='rbf',\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'C':C_values, 'gamma':gammas})\n\n#     experiments_df = experiments_df.append({'classifier':'SVM_rbf',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':0, 'n_MDS_comps':n_comps}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_score) = get_best_hyper_params(classifier_type='SVM',\n#                                                  input_features=mds_X,\n#                                                  labels=y,\n#                                                  kernel='sigmoid',\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'C':C_values, 'gamma':gammas})\n\n#     experiments_df = experiments_df.append({'classifier':'SVM_sigmoid',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':0, 'n_MDS_comps':n_comps}, ignore_index=True)\n\n    \n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_score) = get_best_hyper_params(classifier_type='kNN',\n#                                                  input_features=mds_X,\n#                                                  labels=y,\n#                                                  kernel=None,\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'n_neighbors':n_neighbors})\n\n#     experiments_df = experiments_df.append({'classifier':'kNN',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':0, 'n_MDS_comps':n_comps}, ignore_index=True)\n\n    \n#     max_features = list(set([1] + [*range(1, n_comps)]))\n#     (best_acc_params,\n#      best_prec_params,\n#      best_recall_params,\n#      best_f1_score) = get_best_hyper_params(classifier_type='RandomForest',\n#                                                  input_features=mds_X,\n#                                                  labels=y,\n#                                                  kernel=None,\n#                                                  cv=4,\n#                                                  n_jobs=n_cores,\n#                                                  param_grid={'n_estimators':n_estimators, 'max_features':max_features,\n#                                                           'max_leaf_nodes':max_leaf_nodes})\n\n#     experiments_df = experiments_df.append({'classifier':'RandomForest',\n#                                             'best_prec_params':best_prec_params,\n#                                             'best_recall_params':best_recall_params,\n#                                             'best_acc_params':best_acc_params,\n#                                             'best_f1_params':best_f1_params,\n#                                             'Scaled':True,\n#                                             'n_PCA_comps':0, 'n_MDS_comps':n_comps}, ignore_index=True)\n\n#     experiments_df.to_msgpack('experiments.msgpack')","30911eb7":"!pip install wget","b501bb04":"# #  this cell downloads the experiments.pkl pickle to the current directory on Kaggle cloud.\nimport wget\nurl = 'https:\/\/res.cloudinary.com\/code-sage-cloud\/raw\/upload\/v1553486810\/experiments.msgpack'\nmsgpack_filename = wget.download(url, '')\nmsgpack_filename","409aec28":"experiments_df = pd.read_msgpack(msgpack_filename)","bd73ecc9":"def get_acc_score(x):\n    return dict(x['best_acc_params'])['score']\ndef get_prec_score(x):\n    return dict(x['best_prec_params'])['score']\ndef get_recall_score(x):\n    return dict(x['best_recall_params'])['score']\ndef get_f1_score(x):\n    return dict(x['best_f1_params'])['score']","6e5fdde8":"rows_without_dimen_reduction = experiments_df[(experiments_df['n_PCA_comps'] == 0) & (experiments_df['n_MDS_comps'] == 0)]","59fdf115":"acc_without_dimen_reduction = rows_without_dimen_reduction[['classifier', 'best_acc_params']]\nplt.figure(figsize=(16,6))\nx = acc_without_dimen_reduction['classifier']\ny = acc_without_dimen_reduction.apply(get_acc_score, axis=1)\nbarPlot = sns.barplot(x=x,y=y, hue=experiments_df['Scaled'])\n_ = plt.ylim((0.5, 1))\n_ = plt.title(\"Classifiers' Accuracy Scores Comparison (no-scaling vs. scaled)\")\n_ = plt.legend(title='Scaling', loc='lower right')\nnum_classifier_types = len(x.unique())\nfor barIndex in range(num_classifier_types):\n    barPlot.text(barIndex - barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex] - 0.023,\n                 str(round(y[barIndex], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)\n    \n    barPlot.text(barIndex + barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex + num_classifier_types] - 0.023,\n                 str(round(y[barIndex + num_classifier_types], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)","944e76a4":"prec_without_dimen_reduction = rows_without_dimen_reduction[['classifier', 'best_prec_params']]\nplt.figure(figsize=(16,6))\nx = prec_without_dimen_reduction['classifier']\ny = prec_without_dimen_reduction.apply(get_prec_score, axis=1)\nbarPlot = sns.barplot(x=x,y=y, hue=experiments_df['Scaled'])\n_ = plt.ylim((0.5, 1))\n_ = plt.title(\"Classifiers' Precision Scores Comparison (no-scaling vs. scaled)\")\n_ = plt.legend(title='Scaling', loc='lower right')\nnum_classifier_types = len(x.unique())\nfor barIndex in range(num_classifier_types):\n    barPlot.text(barIndex - barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex] - 0.023,\n                 str(round(y[barIndex], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)\n    \n    barPlot.text(barIndex + barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex + 6] - 0.023,\n                 str(round(y[barIndex + 6], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)","4cfb9da6":"recall_without_dimen_reduction = rows_without_dimen_reduction[['classifier', 'best_recall_params']]\nplt.figure(figsize=(16,6))\nx = recall_without_dimen_reduction['classifier']\ny = recall_without_dimen_reduction.apply(get_recall_score, axis=1)\nbarPlot = sns.barplot(x=x,y=y, hue=experiments_df['Scaled'])\n_ = plt.ylim((0.5, 1.0))\n_ = plt.title(\"Classifiers' Recall Scores Comparison (no-scaling vs. scaled)\")\n_ = plt.legend(title='Scaling', loc='lower right')\nnum_classifier_types = len(x.unique())\nfor barIndex in range(num_classifier_types):\n    barPlot.text(barIndex - barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex] - 0.023,\n                 str(round(y[barIndex], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)\n    \n    barPlot.text(barIndex + barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex + 6] - 0.023,\n                 str(round(y[barIndex + 6], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)","53163a53":"f1_without_dimen_reduction = rows_without_dimen_reduction[['classifier', 'best_f1_params']]\nplt.figure(figsize=(16,6))\nx = f1_without_dimen_reduction['classifier']\ny = f1_without_dimen_reduction.apply(get_f1_score, axis=1)\nbarPlot = sns.barplot(x=x,y=y, hue=experiments_df['Scaled'])\n_ = plt.ylim((0.5, 1))\n_ = plt.title(\"Classifiers' F1-Scores Comparison (no-scaling vs. scaled)\")\n_ = plt.legend(title='Scaling', loc='lower right')\nnum_classifier_types = len(x.unique())\nfor barIndex in range(num_classifier_types):\n    barPlot.text(barIndex - barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex] - 0.023,\n                 str(round(y[barIndex], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)\n    \n    barPlot.text(barIndex + barPlot.patches[0].get_width() \/ 2,\n                 y[barIndex + 6] - 0.023,\n                 str(round(y[barIndex + 6], 5)),\n                 color='w', horizontalalignment='center', fontsize=12)","42427270":"scaled_rows_without_reduc = rows_without_dimen_reduction[rows_without_dimen_reduction['Scaled'] == True]\npca_rows = scaled_rows_without_reduc.append(experiments_df[(experiments_df['n_PCA_comps'] > 0)])\nmds_rows = scaled_rows_without_reduc.append(experiments_df[(experiments_df['n_MDS_comps'] > 0)])","c491e7a4":"plt.figure(figsize=(26,9))\nplt.subplot(1,2,1)\nx = pca_rows['n_PCA_comps']\ny = pca_rows.apply(get_acc_score, axis=1)\ny.index = pca_rows.index.copy()\nhue = pca_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.legend(loc='lower right')\n_ = plt.title(\"Classifiers' Accuracy Scores across 0 to 12 PCA components\")\nmaxIndices = list(y.nlargest(3).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_pca_rows = pca_rows.loc[maxIndices, ['classifier', 'n_PCA_comps']].copy()\nmax_pca_rows['score'] =  pca_rows.loc[maxIndices].apply(get_acc_score, axis=1)\nprint('top 3 in PCA accuracy:\\n', max_pca_rows, '\\n\\n')\n    \nplt.subplot(1,2,2)\nx = mds_rows['n_MDS_comps']\ny = mds_rows.apply(get_acc_score, axis=1)\ny.index = mds_rows.index.copy()\nhue = mds_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.title(\"Classifiers' Accuracy Scores across 0 to 12 MDS components\")\nmaxIndices = list(y.nlargest(3).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_mds_rows = mds_rows.loc[maxIndices, ['classifier', 'n_MDS_comps']].copy()\nmax_mds_rows['score'] =  mds_rows.loc[maxIndices].apply(get_acc_score, axis=1)\nprint('top 3 in MDS accuracy:\\n', max_mds_rows)","e4b1089c":"plt.figure(figsize=(26,9))\nplt.subplot(1,2,1)\nx = pca_rows['n_PCA_comps']\ny = pca_rows.apply(get_prec_score, axis=1)\ny.index = pca_rows.index.copy()\nhue = pca_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.title(\"Classifiers' Precision Scores across 0 to 12 PCA components\")\nmaxIndices = list(y.nlargest(5).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_pca_rows = pca_rows.loc[maxIndices, ['classifier', 'n_PCA_comps']].copy()\nmax_pca_rows['score'] =  pca_rows.loc[maxIndices].apply(get_prec_score, axis=1)\n    \nplt.subplot(1,2,2)\nx = mds_rows['n_MDS_comps']\ny = mds_rows.apply(get_prec_score, axis=1)\ny.index = mds_rows.index.copy()\nhue = mds_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.title(\"Classifiers' Precision Scores across 0 to 12 MDS components\")\nmaxIndices = list(y.nlargest(5).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_mds_rows = mds_rows.loc[maxIndices, ['classifier', 'n_MDS_comps']].copy()\nmax_mds_rows['score'] =  mds_rows.loc[maxIndices].apply(get_prec_score, axis=1)\nplt.show()\n\nprint('top 5 in PCA precision:\\n\\n', max_pca_rows, '\\n\\n')\nprint('top 5 in MDS precision:\\n', max_mds_rows)","dff9c1ee":"plt.figure(figsize=(26,9))\nplt.subplot(1,2,1)\nx = pca_rows['n_PCA_comps']\ny = pca_rows.apply(get_recall_score, axis=1)\ny.index = pca_rows.index.copy()\nhue = pca_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.title(\"Classifiers' Recall Scores across 0 to 12 PCA components\")\nmaxIndices = list(y.nlargest(5).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_pca_rows = pca_rows.loc[maxIndices, ['classifier', 'n_PCA_comps']].copy()\nmax_pca_rows['score'] =  pca_rows.loc[maxIndices].apply(get_recall_score, axis=1)\n    \nplt.subplot(1,2,2)\nx = mds_rows['n_MDS_comps']\ny = mds_rows.apply(get_recall_score, axis=1)\ny.index = mds_rows.index.copy()\nhue = mds_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.title(\"Classifiers' Recall Scores across 0 to 12 MDS components\")\nmaxIndices = list(y.nlargest(5).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_mds_rows = mds_rows.loc[maxIndices, ['classifier', 'n_MDS_comps']].copy()\nmax_mds_rows['score'] =  mds_rows.loc[maxIndices].apply(get_recall_score, axis=1)\nplt.show()\n\nprint('top 5 in PCA recall:\\n\\n', max_pca_rows, '\\n\\n')\nprint('top 5 in MDS recall:\\n\\n', max_mds_rows)","57607aca":"recall_of_SVM_sigmoid_pca = pca_rows[pca_rows['classifier'] == 'SVM_sigmoid'].apply(get_recall_score, axis=1).reset_index(drop=True)\nrecall_of_SVM_rbf_pca = pca_rows[pca_rows['classifier'] == 'SVM_rbf'].apply(get_recall_score, axis=1).reset_index(drop=True)\nprint('recall_of_SVM_rbf_pca == recall_of_SVM_sigmoid_pca:\\n', recall_of_SVM_rbf_pca == recall_of_SVM_sigmoid_pca, '\\n')\n\nrecall_of_SVM_sigmoid_mds = mds_rows[mds_rows['classifier'] == 'SVM_sigmoid'].apply(get_recall_score, axis=1).reset_index(drop=True)\nrecall_of_SVM_rbf_mds = mds_rows[mds_rows['classifier'] == 'SVM_rbf'].apply(get_recall_score, axis=1).reset_index(drop=True)\nprint('recall_of_SVM_rbf_mds == recall_of_SVM_sigmoid_mds:\\n', recall_of_SVM_rbf_mds == recall_of_SVM_sigmoid_mds)","2b605328":"plt.figure(figsize=(28,9))\nplt.subplot(1,2,1)\nx = pca_rows['n_PCA_comps']\ny = pca_rows.apply(get_f1_score, axis=1)\ny.index = pca_rows.index.copy()\nhue = pca_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.title(\"Classifiers' F1-Scores across 0 to 12 PCA components\")\nmaxIndices = list(y.nlargest(5).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_pca_rows = pca_rows.loc[maxIndices, ['classifier', 'n_PCA_comps']].copy()\nmax_pca_rows['score'] =  pca_rows.loc[maxIndices].apply(get_f1_score, axis=1)\n    \nplt.subplot(1,2,2)\nx = mds_rows['n_MDS_comps']\ny = mds_rows.apply(get_f1_score, axis=1)\ny.index = mds_rows.index.copy()\nhue = mds_rows['classifier']\n_ = sns.lineplot(x=x, y=y, hue=hue)\n_ = plt.title(\"Classifiers' F1-Scores across 0 to 12 MDS components\")\nmaxIndices = list(y.nlargest(5).index)\nscatterXs = x[maxIndices]\nscatterYs = y[maxIndices]\nplt.scatter(x=scatterXs, y=scatterYs, s=120, facecolors='none', edgecolors='r')\nfor i in maxIndices:\n    plt.text(scatterXs.loc[i] - 0.2,\n             scatterYs.loc[i]+0.0022,\n             str(round(scatterYs.loc[i], 5)), horizontalalignment='center')\nmax_mds_rows = mds_rows.loc[maxIndices, ['classifier', 'n_MDS_comps']].copy()\nmax_mds_rows['score'] =  mds_rows.loc[maxIndices].apply(get_f1_score, axis=1)\nplt.show()\n\nprint('top 5 in PCA F1-score:\\n\\n', max_pca_rows, '\\n\\n')\nprint('top 5 in MDS F1-score:\\n\\n', max_mds_rows)","078078d5":"f1_of_SVM_rbf_mds = mds_rows[mds_rows['classifier'] == 'SVM_rbf'].apply(get_f1_score, axis=1).reset_index(drop=True)\n\nf1_of_SVM_sigmoid_mds = mds_rows[mds_rows['classifier'] == 'SVM_sigmoid'].apply(get_f1_score, axis=1).reset_index(drop=True)\n\nf1_of_kNN_mds = mds_rows[mds_rows['classifier'] == 'kNN'].apply(get_f1_score, axis=1).reset_index(drop=True)\n\nf1_of_RandomForest_mds = mds_rows[mds_rows['classifier'] == 'RandomForest'].apply(get_f1_score, axis=1).reset_index(drop=True)\n\n(f1_of_SVM_rbf_mds == f1_of_SVM_sigmoid_mds) & (f1_of_SVM_sigmoid_mds == f1_of_kNN_mds) &(f1_of_SVM_sigmoid_mds == f1_of_RandomForest_mds)","c1e1e876":"y = heart_data_df['condition(numeric)']","387dc649":"best_prec_experiment = dict(*experiments_df[(experiments_df['classifier'] == 'RandomForest') & (experiments_df['n_MDS_comps'] == 4)]['best_prec_params'])\nprec_oriented_classifier = RandomForestClassifier(n_estimators=best_prec_experiment['n_estimators'],\n                                                  max_features=best_prec_experiment['max_features'],\n                                                  max_leaf_nodes=best_prec_experiment['max_leaf_nodes'],\n                                                  random_state=0)","091a4e41":"best_recall_experiment = dict(*experiments_df[(experiments_df['classifier'] == 'SVM_rbf') & (experiments_df['n_MDS_comps'] == 4)]['best_recall_params'])\nrecall_oriented_classifier = SVC(kernel='rbf',\n                                 C=best_recall_experiment['C'],\n                                 gamma=best_recall_experiment['gamma'],\n                                 probability=True,\n                                 random_state=0)","9fc71622":"best_f1_experiment = dict(experiments_df[(experiments_df['classifier'] == 'RandomForest') & (experiments_df['n_PCA_comps'] == 0) & (experiments_df['n_MDS_comps'] == 0)]['best_f1_params'][5])\nf1_oriented_classifier = RandomForestClassifier(n_estimators=best_f1_experiment['n_estimators'],\n                                                  max_features=best_f1_experiment['max_features'],\n                                                  max_leaf_nodes=best_f1_experiment['max_leaf_nodes'],\n                                                  random_state=0)","20cd3c6a":"from sklearn.base import BaseEstimator, ClassifierMixin\nglobal Y\nY = y.copy()","4a90cedc":"class MyClassifier(BaseEstimator, ClassifierMixin):\n    \n    def __init__(self, prec=None, f1=None, recall=None, l=0, m=0, n=0):\n#         self.threshold = threshold\n        self.l, self.m, self.n = l,m,n\n        self.prec = prec\n        self.f1 = f1\n        self.recall = recall\n    \n    def fit(self, X, y):\n        mds_X = MDS(n_components=4, random_state=0).fit_transform(X)\n        \n        self.prec.fit(mds_X, y)\n        self.f1.fit(X, y)\n        self.recall.fit(mds_X,y)\n        \n        return self\n    \n    def predict(self, X):\n        index = X.index.copy()\n        mds_X = pd.DataFrame(MDS(n_components=4, random_state=0).fit_transform(X), index=index.copy())\n        \n        prec_results = self.prec.predict(mds_X)\n        f1_results = self.f1.predict(X)\n        recall_results = self.recall.predict(mds_X)\n        \n        prec_proba = self.prec.predict_proba(mds_X)\n        f1_proba = self.f1.predict_proba(X)\n        recall_proba = self.recall.predict_proba(mds_X)\n        \n        heuristic = self.l * prec_proba[:,1] * prec_results + self.m * f1_proba[:,1] * f1_results + self.n * recall_proba[:,1] * recall_results\n        heuristic_df = pd.DataFrame(heuristic, columns=['heuristic'])\n        \n        heuristic_df['labels'] = 0\n        heuristic_df['label_str'] = 'low'\n        heuristic_df.loc[:,'labels'][heuristic_df['heuristic'] > 0.5] = 1\n        heuristic_df.loc[:,'label_str'][heuristic_df['heuristic'] > 0] = 'medium'\n        heuristic_df.loc[:,'label_str'][heuristic_df['heuristic'] > 0.5] = 'high'\n        global Y\n        heuristic_df['actual_label'] = [*Y.loc[index]]\n    \n        return heuristic_df[['labels', 'label_str', 'actual_label', 'heuristic']]\n#         return heuristic_df['labels']\n    \n    def get_params(self, deep=True):\n        return {\"prec\":self.prec, 'l':self.l, 'm':self.m, 'n':self.n,\n                \"f1\":self.f1, \"recall\":self.recall}\n\n    def set_params(self, **parameters):\n        for parameter, value in parameters.items():\n            setattr(self, parameter, value)\n        return self","8435a7b7":"weights = [{'l':[l], 'm':[m] , 'n':[n]} for l in np.arange(0,1,0.01) for m in np.arange(0,1,0.01) for n in np.arange(0,1,0.01) if (l + m + n == 1.0) and (l != 0) and (m != 0) and (l >= m) and (m >= n)]","e50e4cad":"from sklearn.model_selection import cross_val_score, cross_val_predict","a9676bbc":"# classifier = MyClassifier(prec_oriented_classifier, f1_oriented_classifier, recall_oriented_classifier)\n# # thresholds = [*np.arange(0, 1, 0.001)]\n# heuristic_grid = GridSearchCV(classifier, cv=4, n_jobs=n_cores, param_grid=weights)","1e6aa20e":"# heuristic_grid.fit(scaled_X, y)","4abdd3f9":"# heuristic_grid.best_params_","6d3c2b54":"# heuristic_grid.best_score_","8d8d652a":"# import pickle\n# with open('with_0_recall_and_highest_score.pkl', \"wb\") as pkl_file:\n#     pickle.dump(heuristic_grid, pkl_file)","30405602":"# cross_val_score(classifier, scaled_X, y, cv=4, n_jobs=n_cores)","316a2eb2":"classifier = MyClassifier(prec_oriented_classifier, f1_oriented_classifier, recall_oriented_classifier, 0.5, 0.5)\ncvp_result = cross_val_predict(classifier, scaled_X, y, cv=4, n_jobs=n_cores)","9386424e":"cvp = pd.DataFrame(cvp_result, columns=['label', 'label_str', 'actual_label', 'heuristic'])","7dfbda73":"cvp.groupby(['label_str', 'actual_label']).count()","539f0e68":"count = cvp.groupby(['label_str', 'actual_label', 'label']).count()\n# count['label'] = (count['label'] \/ count['label'].sum()) * 100\ncount","b248b810":"len(cvp['heuristic'].unique())","80ff3417":"cvp.groupby(['label_str']).count()","d7818750":"# sns.distplot([*cvp['heuristic'][cvp.actual_label == 0]], bins=20)\n# # sns.distplot?\n# sns.distplot([*cvp['heuristic'][cvp.actual_label == 1]], bins=20)\nplt.hist([*cvp['heuristic'][cvp.actual_label == 0]], bins=20, fc=(0,1,0,0.5))\nplt.hist([*cvp['heuristic'][cvp.actual_label == 1]], bins=20, fc=(1,0,0,0.5))\n\nplt.legend(['healthy', 'diseased'])\nplt.xlabel('heuristic')\nplt.ylabel('count')","15a43b5d":"cvp.dtypes","0852ed93":"## Performance without Dimensionality Reduction","71ac5d27":"### with RBF kernel","bc38c09c":"## kNN","944fb646":"### with linear kernel","30865979":"## Multi-Dimensional Scaling (MDS)","6ff8d674":"## Logistic Regression","d1939ffb":"## Performance with Dimensionality Reduction","6585217e":"<span style=\"color:blue\"><b>Lets choose <span style=\"color:green\">SVM_rbf with 4 MDS components<\/span>, for later use, in our heuristic. I know SVM_rbf gave 1.0 score on any number of PCA\/MDS components, I'm going with 4 since having less components may lead to under-fitting on unseen data(this is just my hunch, you're welcome to give your opinion\/feedback if there are other possibilities or if the hunch is a hoax; or anything else I missed).<\/b><\/span>","3ba7805f":"### with Sigmoid kernel","c7eab819":"## Logistic Regression","7aa486d3":"### with sigmoid kernel","9f77cad8":"## SVM","eba6fd97":"## Principal Component Transform (PCT via PCA objects)","3529fabb":"<span style=\"color:red\">WARNING! Below, wherever there are 0 PCA\/MDS components, all 13 of the original columns are used there instead. Keep it in mind while looking at the outputs\/plots.<\/span>","3777ce28":"#### Note that in the above plot on the right, lines of all classifiers (except for LogisticReg and SVM_linear) are in perfect overlap which is why there is only one line there instead of 4. Here's the boolean equality check for all of their F1-scores across different number of MDS components:","e484c2dd":"# Heart Disease Diagnosis Heuristics","a90be0f6":"### with linera kernel","a2ce57c6":"### No-Scaling vs. Scaled","c624b040":"### with RBF kernel","ffceb130":"## SVM","20c8371c":"## Random Forests","6e962c37":"<span style=\"color:blue\"><b>Lets choose <span style=\"color:green\">SVM_rbf with 9 PCA components<\/span>, for later use, in our heuristic. Since it gives the best balance between number of components and score. Though I'm not sure if its alright to use PCA components of this, and MDS components in case of precision and recall metrics; open for suggestions\/feedback.<\/b><\/span>","e5f7047c":"# with Standard Scaling","cb042c8f":"Having those assumptions, I've come up with this formula:\n\n<b>chances of heart disease = (0.5 * precision) + (0.5 * f1)<\/b>","8f55fd1f":"## Random Forests","76ed8288":"# Without scaling","f8763fe7":"## kNN","696f2b13":"A core assumption in the heuristic is that the likelihood of a classifier trained for a particular metric (precision, recall, or F1) to output a 'yes' or 1 for heart disease is as follows:\n\n<b>recall > F1 > precision<\/b>\n\ni.e. recall will say 'yes' even if there are slightest chances of presence of diseases. F1 will take a balanced approach towards the decision. precision would be the most meticulous about saying 'yes' about presence of heart disease. ","9a87b173":"#### Note that in the above plots, lines of both SVM_rbf and SVM_sigmoid are in perfect overlap which is why SVM_rbf is totally hidden. Here's the boolean equality check for both of their recall scores across different number of PCA & MDS components:","c49081bd":"<span style=\"color:blue\"><b>Lets choose <span style=\"color:green\">RandomForest with 4 MDS components<\/span>, for later use, in our heuristic, as it gives a neat balance of number of components and, in this case, precision score attained.<\/b><\/span>","0f0b58dd":"# Now, let's visualize the performance of models","4696f9cc":"I used the following code to generate the plots and the diagnosing-heuristic. It takes a lot of time, more than Kaggle allows, so, I ran it on my machine and pickled the resulting dataframe, which is <a href=\"https:\/\/res.cloudinary.com\/code-sage-cloud\/raw\/upload\/v1553486810\/experiments.msgpack\">downloadable here<\/a>.\nYou can uncomment the cells below to run the hyper-parameter tuning code, or you can <a href=\"#Now,-let's-visualize-the-performance-of-models\">go directly to the plots and diagnosing part<\/a>","642de1dc":"# Dimensionality Reduction"}}