{"cell_type":{"01142a82":"code","1f5c558a":"code","0d218125":"code","2fbbbabe":"code","df812803":"code","6d7f0d08":"code","2a684201":"code","49761f5f":"code","08e1ab41":"code","3ebc5e3c":"code","97c3242b":"code","32302f6b":"code","4df88323":"code","85a20475":"code","1000c01b":"code","d5dabcde":"code","d7fe3991":"code","0185b3c7":"code","800f4a54":"code","16162789":"code","8c338ab5":"code","b12d32a7":"code","e793e055":"code","b21fc0d6":"code","b530b073":"code","e724f3a8":"code","dd5a78f9":"code","c63eb387":"code","79ee0b83":"code","93fd5b35":"code","92b2dd0c":"code","7c36785f":"code","df80f25e":"code","6c15d13c":"code","73dd838d":"code","c6b23db8":"code","7928653c":"markdown","ff0582d4":"markdown","e654d792":"markdown","03b87ed7":"markdown","f227d6bd":"markdown","b9b07e2c":"markdown","f0a17df2":"markdown","12d685da":"markdown","7857d170":"markdown","949ac277":"markdown","db8235d2":"markdown","7fd507b6":"markdown","76457609":"markdown","b228ee3f":"markdown"},"source":{"01142a82":"import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn.datasets import load_digits\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1f5c558a":"mnist = load_digits()","0d218125":"type(mnist)","2fbbbabe":"mnist.keys()","df812803":"mnist.data.shape","6d7f0d08":"mnist.images","2a684201":"X=mnist.data\ny=mnist.target","49761f5f":"X.shape","08e1ab41":"y.shape","3ebc5e3c":"df=pd.DataFrame(X,columns=mnist.feature_names)\nprint(df.head())","97c3242b":"X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.14,random_state=21,stratify=y)\nknn=KNeighborsClassifier(n_neighbors=9)\nknn.fit(X_train,y_train)\nprediction = knn.predict(X_val)\n\nprint(prediction)\nprint(knn.score(X_val,y_val))","32302f6b":"print(\"training data points: {}\".format(len(y_train)))\nprint(\"validation data points: {}\".format(len(y_val)))","4df88323":"kvalues = range(1, 30, 2)\naccuracies = []\n\nfor k in range(1, 30,2):\n          model = KNeighborsClassifier(n_neighbors=k)\n          model.fit(X_train,y_train)\n          # evaluate the model and update the accuracies list\n          score = model.score(X_val,y_val)\n          print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n          accuracies.append(score*100)\n","85a20475":"plt.plot(kvalues,accuracies,markersize=6,marker='o')\nplt.xlabel('K-value')\nplt.ylabel('Accuracy(%)')","1000c01b":"i = np.argmax(accuracies)\n#print(i)\nprint(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kvalues[i],accuracies[i]))","d5dabcde":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.13,random_state=30,stratify=y)\nmodel = KNeighborsClassifier(n_neighbors=kvalues[i])\nmodel.fit(X_train,y_train)\npredictions = model.predict(X_test)\n\naccuracy=accuracy_score(y_test, predictions)\nprint(\"k=%d achieved highest accuracy of %.3f%% on test data\" % (kvalues[i],accuracy*100))","d7fe3991":"print(\"EVALUATION ON TESTING DATA\")\nprint(classification_report(y_test, predictions))\n\nprint (\"Confusion matrix\")\nprint(confusion_matrix(y_test,predictions))","0185b3c7":"print(\"training data points: {}\".format(len(y_train)))\nprint(\"testing data points: {}\".format(len(y_test)))","800f4a54":"X_val","16162789":"X_test","8c338ab5":"plt.matshow(X_test[9].reshape(8,8))","b12d32a7":"X_test[9].reshape(8,8)","e793e055":"y_test[9]#verified with the target data. Its correct","b21fc0d6":"X=mnist.data\ny=mnist.target","b530b073":"X.shape","e724f3a8":"X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.14,random_state=21,stratify=y)\ndt=DecisionTreeClassifier()\ndt.fit(X_train,y_train)\nprediction = dt.predict(X_val)\n\nprint(prediction)\nprint(dt.score(X_val,y_val))\n","dd5a78f9":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.13,random_state=30,stratify=y)\ndt_model = DecisionTreeClassifier()\ndt_model.fit(X_train,y_train)\npredictions = dt_model.predict(X_test)\n\naccuracy_dt=accuracy_score(y_test, predictions)\n","c63eb387":"print(\"EVALUATION ON TESTING DATA\")\nprint(classification_report(y_test, predictions))\n\nprint (\"Confusion matrix\")\nprint(confusion_matrix(y_test,predictions))","79ee0b83":"print(\"Decision tree achieved highest accuracy of %.3f%% on test data\" % (accuracy_dt*100))","93fd5b35":"print(predictions)\nprint(dt_model.score(X_test,y_test))","92b2dd0c":"X=mnist.data\ny=mnist.target","7c36785f":"X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.14,random_state=21,stratify=y)\nrf=RandomForestClassifier(n_estimators=400)\nrf.fit(X_train,y_train)\nprediction = rf.predict(X_val)\n\nprint(prediction)\nprint(rf.score(X_val,y_val))\n","df80f25e":"\naccuracies = []\n\nfor k in [1,100,200,300,400,500,600,700]:\n          model = RandomForestClassifier(n_estimators=k)\n          model.fit(X_train,y_train)\n          # evaluate the model and update the accuracies list\n          score = model.score(X_val,y_val)\n          print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n          accuracies.append(score*100)","6c15d13c":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.13,random_state=30,stratify=y)\nrf_model = RandomForestClassifier(n_estimators=300)\nrf_model.fit(X_train,y_train)\npredictions = rf_model.predict(X_test)\n\naccuracy_rf=accuracy_score(y_test, predictions)","73dd838d":"print(\"EVALUATION ON TESTING DATA\")\nprint(classification_report(y_test, predictions))\n\nprint (\"Confusion matrix\")\nprint(confusion_matrix(y_test,predictions))","c6b23db8":"print(\"KNN achieved highest accuracy of %.3f%% on test data\" %  (accuracy*100) + \"\\n\" +\n      \"Random Forest achieved highest accuracy of %.3f%% on test data\" % (accuracy_rf*100)+ \"\\n\" +\n      \"Decision tree achieved highest accuracy of %.3f%% on test data\" % (accuracy_dt*100))","7928653c":"# VISUALIZING ACCURACIES AGAINST DIFFERENT K-VALUES","ff0582d4":"## SPLITING THE DATA INTO TRAIN & VAL SETS","e654d792":"## CHECKING THE LENGTH OF THE TRAIN AND TEST DATA","03b87ed7":"## LIBRARIES TO IMPORT","f227d6bd":"# CREATING A DATAFRAME TO SEE THE DATA VALUES","b9b07e2c":"## RECHECKING WITH THE IMAGES AND TARGET","f0a17df2":"## FINDING THE BEST K-VALUE BASED ON THE ACCURACY","12d685da":"## ASSIGNING THE DATA AND TARGET VARIABLES TO X & y respectively","7857d170":"## LOADING MNIST DATASET AND CHECKING THE KEY VALUES","949ac277":"### Random Forest Algorithm","db8235d2":"## SPLITING THE DATA INTO TRAIN & TEST SETS","7fd507b6":"## CHECKING THE LENGTH OF THE TRAIN AND VAL DATA","76457609":"### Decision Tree Algorithm","b228ee3f":"# ACHIEVED F-SCORE OF 100% WITH K=9"}}