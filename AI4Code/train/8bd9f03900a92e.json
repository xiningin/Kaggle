{"cell_type":{"16db31a0":"code","5aa3c729":"code","6dd2050e":"code","af7b7884":"code","14810424":"code","47f5d4e8":"code","54bc98e3":"code","a3e815b9":"code","8b78b4f8":"code","a45a094e":"code","611a3603":"code","56597c50":"code","cfa99011":"code","110ec547":"code","00a8a8d9":"code","1da0d368":"code","52f774b7":"markdown","70f9727d":"markdown","9d87e3cb":"markdown"},"source":{"16db31a0":"!pip install ..\/input\/python-datatable\/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > \/dev\/null 2>&1","5aa3c729":"import numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nimport datatable as dt\nimport lightgbm as lgb\nfrom matplotlib import pyplot as plt\nimport riiideducation\n\n_ = np.seterr(divide='ignore', invalid='ignore')","6dd2050e":"data_types_dict = {\n    'user_id': 'int32', \n    'content_id': 'int16', \n    'answered_correctly': 'int8', \n    'prior_question_elapsed_time': 'float32', \n    'prior_question_had_explanation': 'bool'\n}\ntarget = 'answered_correctly'","af7b7884":"train_df = dt.fread('..\/input\/riiid-test-answer-prediction\/train.csv', columns=set(data_types_dict.keys())).to_pandas()\ntrain_df = train_df[train_df[target] != -1].reset_index(drop=True)\ntrain_df['prior_question_had_explanation'].fillna(False, inplace=True)\ntrain_df = train_df.astype(data_types_dict)","14810424":"train_df['lag'] = train_df.groupby('user_id')[target].shift()\ncum = train_df.groupby('user_id')['lag'].agg(['cumsum', 'cumcount'])\ntrain_df['user_correctness'] = cum['cumsum'] \/ cum['cumcount']\ntrain_df.drop(columns=['lag'], inplace=True)","47f5d4e8":"user_agg = train_df.groupby('user_id')[target].agg(['sum', 'count'])\ncontent_agg = train_df.groupby('content_id')[target].agg(['sum', 'count'])","54bc98e3":"train_df = train_df.groupby('user_id').tail(24).reset_index(drop=True)","a3e815b9":"questions_df = pd.read_csv(\n    '..\/input\/riiid-test-answer-prediction\/questions.csv', \n    usecols=[0, 3],\n    dtype={'question_id': 'int16', 'part': 'int8'}\n)\ntrain_df = pd.merge(train_df, questions_df, left_on='content_id', right_on='question_id', how='left')\ntrain_df.drop(columns=['question_id'], inplace=True)","8b78b4f8":"train_df['content_count'] = train_df['content_id'].map(content_agg['count']).astype('int32')\ntrain_df['content_id'] = train_df['content_id'].map(content_agg['sum'] \/ content_agg['count'])","a45a094e":"valid_df = train_df.groupby('user_id').tail(6)\ntrain_df.drop(valid_df.index, inplace=True)","611a3603":"train_df.head()","56597c50":"features = [\n    'content_id',\n    'prior_question_elapsed_time',\n    'prior_question_had_explanation',\n    'user_correctness',\n    'part',\n    'content_count'\n]\n\nparams = {\n    'objective': 'binary',\n    'seed': 42,\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'max_bin': 800,\n    'num_leaves': 80\n}","cfa99011":"tr_data = lgb.Dataset(train_df[features], label=train_df[target])\nva_data = lgb.Dataset(valid_df[features], label=valid_df[target])\n\nmodel = lgb.train(\n    params, \n    tr_data, \n    num_boost_round=10000,\n    valid_sets=[tr_data, va_data], \n    early_stopping_rounds=50,\n    verbose_eval=50\n)\n\n# model.save_model(f'model.txt')\nlgb.plot_importance(model, importance_type='gain')\nplt.show()","110ec547":"user_sum_dict = user_agg['sum'].astype('int16').to_dict(defaultdict(int))\nuser_count_dict = user_agg['count'].astype('int16').to_dict(defaultdict(int))\ncontent_sum_dict = content_agg['sum'].astype('int32').to_dict(defaultdict(int))\ncontent_count_dict = content_agg['count'].astype('int32').to_dict(defaultdict(int))","00a8a8d9":"# model = lgb.Booster(model_file='..\/input\/riiid-lgbm-starter\/model.txt')\nenv = riiideducation.make_env()\niter_test = env.iter_test()\nprior_test_df = None","1da0d368":"%%time\n\nfor (test_df, sample_prediction_df) in iter_test:\n    if prior_test_df is not None:\n        prior_test_df[target] = eval(test_df['prior_group_answers_correct'].iloc[0])\n        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(drop=True)\n        \n        user_ids = prior_test_df['user_id'].values\n        content_ids = prior_test_df['content_id'].values\n        targets = prior_test_df[target].values\n        \n        for user_id, content_id, answered_correctly in zip(user_ids, content_ids, targets):\n            user_sum_dict[user_id] += answered_correctly\n            user_count_dict[user_id] += 1\n            content_sum_dict[content_id] += answered_correctly\n            content_count_dict[content_id] += 1\n\n    prior_test_df = test_df.copy()\n    \n    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n    test_df = pd.merge(test_df, questions_df, left_on='content_id', right_on='question_id', how='left')\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('bool')    \n    \n    user_sum = np.zeros(len(test_df), dtype=np.int16)\n    user_count = np.zeros(len(test_df), dtype=np.int16)\n    content_sum = np.zeros(len(test_df), dtype=np.int32)\n    content_count = np.zeros(len(test_df), dtype=np.int32)\n    \n    for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n        user_sum[i] = user_sum_dict[user_id]\n        user_count[i] = user_count_dict[user_id]\n        content_sum[i] = content_sum_dict[content_id]\n        content_count[i] = content_count_dict[content_id]\n\n    test_df['user_correctness'] = user_sum \/ user_count\n    test_df['content_count'] = content_count\n    test_df['content_id'] = content_sum \/ content_count\n       \n    test_df[target] = model.predict(test_df[features])\n    env.predict(test_df[['row_id', target]])","52f774b7":"# Inference","70f9727d":"# Preprocess","9d87e3cb":"# Train"}}