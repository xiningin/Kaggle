{"cell_type":{"e5fa994d":"code","6035d34d":"code","795aefad":"code","ddd54f89":"code","e6e9e76b":"code","ea22c2d4":"code","92c3f199":"code","f3852b72":"code","7cb456f8":"code","d93e829c":"code","f1cf9132":"code","c2511811":"code","6d2c1038":"code","f20ba33e":"code","749fc30f":"code","bf09b45d":"code","db51a870":"code","870ec87d":"code","ab64adb2":"code","f19cbf9d":"code","1c6e0178":"code","6b1d3d1a":"code","168cd270":"code","402c4864":"code","7ab7ba35":"code","42f51491":"code","c14e238e":"markdown","17001e86":"markdown","e9ee1f4b":"markdown"},"source":{"e5fa994d":"import torch\nimport torchvision\nfrom torchvision import transforms\nimport torch.nn as nn\nimport time\nimport os\nimport copy\nfrom torchvision import datasets, models, transforms\nimport glob\nimport matplotlib.pyplot as plt\n# from __future__ import print_function\n# !pip intsall torchsummary\n\n# import torchsummary\nimport torchvision.models as models","6035d34d":"print(torch.__version__)\nprint(torch.cuda.get_device_name())\nprint(torch.cuda.get_device_properties('cuda'))\n","795aefad":"DATA_DIR = '..\/input\/cat-and-dog'\nsz = 32\nbatch_size = 16\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","ddd54f89":"os.listdir(DATA_DIR)","e6e9e76b":"trn_dir = f'{DATA_DIR}\/training_set\/training_set'\nval_dir = f'{DATA_DIR}\/test_set\/test_set'","ea22c2d4":"os.listdir(val_dir)","92c3f199":"os.listdir(trn_dir)","f3852b72":"trn_fnames = glob.glob(f'{trn_dir}\/*\/*.jpg')\ntrn_fnames[:5]","7cb456f8":"img = plt.imread(trn_fnames[1])\nplt.imshow(img);","d93e829c":"img.shape","f1cf9132":"train_ds = datasets.ImageFolder(trn_dir)","c2511811":"train_ds.class_to_idx","6d2c1038":"train_ds.root","f20ba33e":"train_ds.imgs","749fc30f":"type(train_ds.transform)","bf09b45d":"tfms = transforms.Compose([\n    transforms.Resize((sz, sz)),  # PIL Image\n    transforms.ToTensor(),        # Tensor\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_ds = datasets.ImageFolder(trn_dir, transform=tfms)\nvalid_ds = datasets.ImageFolder(val_dir, transform=tfms)","db51a870":"len(train_ds), len(valid_ds)","870ec87d":"train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, \n                                       shuffle=True, num_workers=8)\nvalid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, \n                                       shuffle=True, num_workers=8)","ab64adb2":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\n    \"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std  = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    plt.axis('off')\n    if title is not None:\n        plt.title(title)\n","f19cbf9d":"inputs, targets = next(iter(train_dl))\nout = torchvision.utils.make_grid(inputs, padding=3)\nplt.figure(figsize=(16, 12))\nimshow(out, title='Random images from training data')","1c6e0178":"print(f'The shape of one Image is: {inputs[0].shape}')\nprint(f'The label of This Image is: {targets[0]}')","6b1d3d1a":"imshow(inputs[0])","168cd270":"dataloaders ={'train':train_dl,'test':valid_dl}","402c4864":"class net(nn.Module):\n    def __init__(self, num_class):\n        super(net, self).__init__()\n        \n        self.base = models.resnet18(pretrained = True)\n        self.base.fc = nn.Linear(in_features = 512, out_features = 2, bias = False)\n    \n    def forward(self, x):\n        \n        y = self.base(x)\n        return y","7ab7ba35":"model = net(2).to(device)\nprint(model)","42f51491":"model.base.fc","c14e238e":"# data loader\n","17001e86":"# Build Model ","e9ee1f4b":"# Read Image "}}