{"cell_type":{"8492a17e":"code","d318a4c9":"code","6396e6c9":"code","65073035":"code","04b7b537":"code","488db200":"code","6ed6e004":"code","074d01b2":"code","5b8e0879":"markdown","a9907614":"markdown","990d5c33":"markdown","da4dce9a":"markdown","bb847edd":"markdown","6a5ae2cc":"markdown"},"source":{"8492a17e":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","d318a4c9":"def get_bird_data(augmentation=0):\n    transform_train = transforms.Compose([\n        transforms.Resize(128),\n        transforms.RandomCrop(128, padding=8, padding_mode='edge'), # Take 128x128 crops from padded images\n        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n        transforms.ToTensor(),\n    ])\n    \n    transform_test = transforms.Compose([\n        transforms.Resize(128),\n        transforms.CenterCrop(128),\n        transforms.ToTensor(),\n    ])\n    trainset = torchvision.datasets.ImageFolder(root='\/kaggle\/input\/birds21wi\/birds\/train', transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n\n    testset = torchvision.datasets.ImageFolder(root='\/kaggle\/input\/birds21wi\/birds\/test', transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n    \n    classes = open(\"\/kaggle\/input\/birds21wi\/birds\/names.txt\").read().strip().split(\"\\n\")\n    \n    # Backward mapping to original class ids (from folder names) and species name (from names.txt)\n    class_to_idx = trainset.class_to_idx\n    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n    return {'train': trainloader, 'test': testloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n\ndata = get_bird_data()","6396e6c9":"dataiter = iter(data['train'])\nimages, labels = dataiter.next()\nimages = images[:8]\nprint(images.size())\n\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(\"Labels:\" + ', '.join('%9s' % data['to_name'][labels[j].item()] for j in range(8)))","65073035":"def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n    net.to(device)\n    net.train()\n    losses = []\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n\n    # Load previous training state\n    if state:\n        net.load_state_dict(state['net'])\n        optimizer.load_state_dict(state['optimizer'])\n        start_epoch = state['epoch']\n        losses = state['losses']\n\n    # Fast forward lr schedule through already trained epochs\n    for epoch in range(start_epoch):\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n    for epoch in range(start_epoch, epochs):\n        sum_loss = 0.0\n\n        # Update learning rate when scheduled\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n        for i, batch in enumerate(dataloader, 0):\n            inputs, labels = batch[0].to(device), batch[1].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()  # autograd magic, computes all the partial derivatives\n            optimizer.step() # takes a step in gradient direction\n\n            losses.append(loss.item())\n            sum_loss += loss.item()\n\n            if i % print_every == print_every-1:    # print every 10 mini-batches\n                if verbose:\n                  print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss \/ print_every))\n                sum_loss = 0.0\n        if checkpoint_path:\n            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n    return losses","04b7b537":"resnet = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet18', pretrained=True)\nresnet.fc = nn.Linear(512, 555)\n\nlosses = train(resnet, data['train'], epochs=5, lr=.01, print_every=10, checkpoint_path='.\/')","488db200":"def smooth(x, size):\n  return np.convolve(x, np.ones(size)\/size, mode='valid')\n\nplt.plot(smooth(losses,50))","6ed6e004":"def predict(net, dataloader, ofname):\n    out = open(ofname, 'w')\n    out.write(\"path,class\\n\")\n    net.to(device)\n    net.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(dataloader, 0):\n            if i%100 == 0:\n                print(i)\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            fname, _ = dataloader.dataset.samples[i]\n            out.write(\"test\/{},{}\\n\".format(fname.split('\/')[-1], data['to_class'][predicted.item()]))\n    out.close()","074d01b2":"predict(resnet, data['test'], \"preds.csv\")","5b8e0879":"# Transfer Learning!\n\nImport all the things!","a9907614":"## Bird Dataset\n\nOur dataset is already stored in the folder `\/kaggle\/input\/birds21wi`. We can set it up with torch as follows.\n\nOne thing to note, PyTorch will create internal class ids based on the ordering of classes in the folder (in alphabetical, not numerical order unfortunately). This means we have to create a backward mapping both to the original class ids and the class names.","990d5c33":"## Make Our Predictions!\n\nWe'll predict for all 10,000 images in the test set. Remember we need to use our inverse mapping from to get back to the original class ids.","da4dce9a":"## Training Code\n\nSame as previous transfer learning notebook...","bb847edd":"### Visualizing Bird Data\n\nJust to make sure things make sense","6a5ae2cc":"### Training ResNet\n\nUse PyTorch's pretrained ResNet model. We change the last layer to fit our output size (555 classes) and train for 5 epochs at learning rate of 0.01."}}