{"cell_type":{"b78374a2":"code","b510aaf2":"code","6bbab20e":"code","b89e8136":"code","a5abcd52":"code","d76cbfce":"code","2b19e8b6":"code","7b72b35f":"code","29bd194b":"code","e9d19bce":"code","2637a8bc":"code","6f4a0be8":"code","0b01a6dd":"code","0747ed37":"code","27923b36":"code","bc8f8071":"code","d726e5c5":"code","4937e93e":"code","7c5a1ab4":"code","6ef7bb93":"code","bcf16ea7":"code","d763eb13":"code","77bfdf84":"code","78269059":"code","451f00c1":"code","eaf038c1":"code","fede9d6c":"code","fffe4996":"code","2a3ccf0e":"code","f3e5ecd8":"code","c59ffe03":"code","66192b31":"code","3ad205a6":"code","c8eb9a2b":"code","460ccd37":"code","833e1d0b":"code","bc209979":"code","a672f6d3":"code","2ca6b5fb":"code","de9e3747":"code","f44770d6":"code","7f408e17":"code","a94a715a":"code","93cc6f70":"code","8a2ea41c":"code","f5d5f610":"code","6eab74fe":"code","5a56e7c3":"code","b1d25c59":"code","4b9d622b":"code","7f9441f1":"code","f612c7c8":"code","a3d410fb":"code","c6217504":"code","baa957da":"code","5519c27d":"code","08805b1f":"code","c04e79c0":"code","a4ed5a93":"code","3a31b45f":"code","abfedd67":"code","f53e133a":"code","13a74afc":"code","8b92341d":"code","44e2cb4a":"code","2c4b17ac":"code","41ee6bd8":"code","daa93c46":"code","cc6dfc24":"code","48c0973a":"code","1dcaea73":"code","61cbc633":"code","29073015":"code","cd77d84e":"code","5f8a335b":"code","372dbc46":"code","16c031f4":"code","35a08dac":"code","2f6b95c5":"code","bae48aa9":"code","6a1fa44a":"code","06c34952":"code","94eb575b":"code","aa96bb66":"code","e8cd3429":"code","33003661":"code","d9b90223":"code","5550d70f":"code","49b137af":"code","9c29b60b":"code","20f5963f":"code","ff25b278":"code","853d0d12":"code","11ef75c4":"code","7a83d430":"code","1f59993f":"code","61c4622b":"code","aa3a2724":"code","dafbba93":"code","2163c6e2":"code","371d4eb9":"code","1733d65d":"code","fffe5b29":"code","9aba4d89":"code","553b4bbc":"code","95e49f4e":"code","d86b9aed":"code","999918dd":"code","5de379cb":"markdown","75d5e6ec":"markdown","390ab428":"markdown","0a9580e0":"markdown","ac001a94":"markdown","1828667b":"markdown","2f3c98ab":"markdown","7553afd5":"markdown","0b60e8ab":"markdown","3a7f83cf":"markdown","71a1c954":"markdown","fd0d13a3":"markdown","cda02817":"markdown","6b49efce":"markdown","dacb3be7":"markdown","a334f113":"markdown","52f39380":"markdown","f48eee0b":"markdown","d8e51b18":"markdown","ffcd233d":"markdown","1c78ddcb":"markdown","5d14624d":"markdown","3cd00500":"markdown","bce3de7a":"markdown","e3eb1a6b":"markdown","57f0dd97":"markdown","3be8f8a3":"markdown","409b0f89":"markdown","3da82638":"markdown","dd274f43":"markdown","4ba780cc":"markdown","1c95df60":"markdown","cbfcd97c":"markdown","f75818c2":"markdown","7109b3dd":"markdown","dd2d7040":"markdown","611bd4c1":"markdown","30b3195e":"markdown"},"source":{"b78374a2":"# Visualisations\nimport matplotlib.pyplot as plt \nimport matplotlib\n%matplotlib inline\nimport plotly\nimport plotly.offline as py\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\nfrom plotly.tools import make_subplots\ninit_notebook_mode()\n\n# Warnings\nimport warnings\nwarnings.filterwarnings(action = 'ignore')\n\n# Data exploration\nimport pandas as pd\n\n# Numerical\nimport numpy as np\n\n# Random\nnp.random.seed(11)\n\n# Splitt and encode\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Make pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import FeatureUnion\n\n# Regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Grid Search\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\n# Files in dataset\nimport os\nprint(os.listdir(\"..\/input\"))","b510aaf2":"# Load and inspect data\ncrimes_df = pd.read_csv(\"..\/input\/crimes_NYC.csv\")\ncrimes_df.info()","6bbab20e":"# Make df with NaNs in target column (SUSP_RACE here) and return df without that column\ndef susp_n(column_name, condition):\n    print(\"Values in {}: \\n\".format(column_name), crimes_df[column_name].value_counts(dropna = False), sep = '')   # check if there any NaNs\n    crimes_df.loc[(condition), column_name] = np.nan # change 'WRONG' values to NaNs\n    susp_nan = crimes_df[crimes_df[column_name].isnull()] # df with NaNs only\n    susp_nan.drop(column_name, axis = 1)   # delete SUSP_RACE column\n    print(\"\\nValues in {} after changing: \\n\".format(column_name), susp_nan[column_name].value_counts(dropna = False), sep = '')   # check if there any NaNs\n    return susp_nan","b89e8136":"# Select column and condition to change values\ncolumn_name = 'SUSP_RACE'\ncondition = crimes_df[column_name] == 'UNKNOWN'\nsn = susp_n(column_name, condition)","a5abcd52":"# Split data into train and test sets using StratifiedShuffleSplit\ndef for_split(column_name):\n    df_non_nan = crimes_df.dropna(subset = [column_name], axis = 0).reset_index() #reset_index() is crucial here\n    split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 11)\n    for train_index, test_index in split.split(df_non_nan, df_non_nan[column_name]):\n        strat_train_set = df_non_nan.loc[train_index]\n        strat_test_set = df_non_nan.loc[test_index]\n    return strat_train_set, strat_test_set","d76cbfce":"# Execute for_split()\nstrat_train_set, strat_test_set = for_split(column_name)","2b19e8b6":"# Make train df and extract target labels\ndef train_and_drop(column_name, strat_train_set):\n    susp_labels = strat_train_set[column_name].copy().to_frame()\n    crimes_df = strat_train_set.drop(column_name, axis = 1)\n    return susp_labels, crimes_df","7b72b35f":"# Execute train_and_drop\nsusp_labels, crimes_df = train_and_drop(column_name, strat_train_set)","29bd194b":"# Select categorical and numerical values to feed pipeline\ndef select(selected_list):\n    crimes_df_num = crimes_df.select_dtypes(include = [np.number]).drop('index', axis = 1)\n    crimes_df_cat = crimes_df[selected_list]\n    return crimes_df_num, crimes_df_cat","e9d19bce":"selected_list = ['BORO_NM'] # list of categorical values\ncrimes_df_num, crimes_df_cat = select(selected_list)","2637a8bc":"# Encode categorical labels\ndef one_hot_encoder(labels):\n    one_hot_encoder = OneHotEncoder(sparse = False)\n    crimes_labels_1hot = one_hot_encoder.fit_transform(labels) # for scikit-learn versions 19.x this line won`t work, because susp_race_labels are not int type\n    return crimes_labels_1hot","6f4a0be8":"# Execute encoding\ncrimes_labels_1hot = one_hot_encoder(susp_labels)\nprint(crimes_labels_1hot)","0b01a6dd":"# Write a selector\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y = None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values","0747ed37":"# One pipeline for cat and num values\ndef pipeline(df):\n    num_attribs = list(crimes_df_num)\n    cat_attribs = list(crimes_df_cat)\n    \n    num_pipeline = Pipeline([\n        ('selector', DataFrameSelector(num_attribs)),\n        #('imputer', SimpleImputer(strategy=\"median\")), SimpleImputer won't work here, all num_attribs are already completed and don't have any NaN\n        ('std_scaler', StandardScaler()),\n    ])\n    cat_pipeline = Pipeline([\n        ('selector', DataFrameSelector(cat_attribs)),\n        ('cat_encoder', OneHotEncoder(sparse = False)), \n    ])\n    \n    # Create one pipeline for the whole process\n    full_pipeline = FeatureUnion(transformer_list = [\n        ('num_pipeline', num_pipeline),\n        ('cat_pipeline', cat_pipeline),\n    ])\n    \n    # Encode values using full_pipeline\n    crimes_prepared = full_pipeline.fit_transform(crimes_df)\n    \n    return crimes_prepared, num_pipeline, cat_pipeline, num_attribs, full_pipeline","27923b36":"# Execute pipeline()\ncrimes_prepared, num_pipeline, cat_pipeline, num_attribs, full_pipeline = pipeline(crimes_df) # Is it ok, to load all these values from function?","bc8f8071":"# Compute linear regression\ndef linear_reg(crimes_prepared, crimes_labels_1hot):\n    lin_reg = LinearRegression()\n    lin_reg.fit(crimes_prepared, crimes_labels_1hot)\n    \n    #compute with cross_cal_score\n    lin_scores = cross_val_score(lin_reg, crimes_prepared, crimes_labels_1hot, scoring = 'neg_mean_squared_error', cv = 10)\n    lin_rmse_scores = np.sqrt(-lin_scores)\n    return lin_rmse_scores","d726e5c5":"# Execute lin_reg()\nlin_rmse_scores = linear_reg(crimes_prepared, crimes_labels_1hot)","4937e93e":"# Decission tree regression\ndef decision_t(crimes_prepared, crimes_labels_1hot):\n    tree_reg = DecisionTreeRegressor(random_state=11)\n    tree_reg.fit(crimes_prepared, crimes_labels_1hot)\n    \n    # compute with cross_val_score\n    scores = cross_val_score(tree_reg, crimes_prepared, crimes_labels_1hot, scoring = 'neg_mean_squared_error', cv = 10)\n    tree_rmse_scores = np.sqrt(-scores)\n    \n    return tree_rmse_scores","7c5a1ab4":"tree_rmse_scores = decision_t(crimes_prepared, crimes_labels_1hot)","6ef7bb93":"# Display all scores\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","bcf16ea7":"# Execute display_scores(scores) function\nprint(\"Linear Regression\")\ndisplay_scores(lin_rmse_scores)\nprint(\"\\nDecision Tree\")\ndisplay_scores(tree_rmse_scores)","d763eb13":"# Calculate rf score\ndef random_f(crimes_prepared, crimes_labels_1hot):\n    forest_reg = RandomForestRegressor(random_state=11)\n    forest_reg.fit(crimes_prepared, crimes_labels_1hot)\n    \n    # compute with cross_val_score\n    scores = cross_val_score(forest_reg, crimes_prepared, crimes_labels_1hot, scoring = 'neg_mean_squared_error', cv = 10)\n    forest_rmse_scores = np.sqrt(-scores)\n    return forest_rmse_scores","77bfdf84":"forest_rmse_scores = random_f(crimes_prepared, crimes_labels_1hot)","78269059":"# Execute display_scores(scores) function\nprint(\"Random forest\")\ndisplay_scores(forest_rmse_scores)","451f00c1":"# Find best params using Grid Search\ndef grid():\n    param_grid = [\n        {'n_estimators': [3, 10, 30], 'max_features': [3, 5, 7, 9]},\n        {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n    ]\n    forest_reg = RandomForestRegressor(random_state = 11)\n    grid_search = GridSearchCV(forest_reg, param_grid, cv = 5, scoring = 'neg_mean_squared_error', \n                          return_train_score = True)\n    grid_search.fit(crimes_prepared, crimes_labels_1hot)\n    return grid_search","eaf038c1":"# Execute grid() function\ngrid_search = grid()","fede9d6c":"print(\"Grid search best parameters: \", grid_search.best_params_)\nprint(\"Grid search best estimator: \", grid_search.best_estimator_)","fffe4996":"# Evaluation scores\nprint(\"Evaluation scores\")\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n    print(np.sqrt(-mean_score), params)","2a3ccf0e":"# Find best params using Randomized Search\ndef random_search():\n    param_distribs = {\n        'n_estimators': randint(low = 1, high = 200),\n        'max_features': randint(low = 3, high = 9),\n    }\n    forest_reg = RandomForestRegressor(random_state = 11)\n    rnd_search = RandomizedSearchCV(forest_reg, param_distributions = param_distribs,\n                                    n_iter = 10, cv = 5, scoring = 'neg_mean_squared_error', random_state = 11)\n    rnd_search.fit(crimes_prepared, crimes_labels_1hot)\n\n    return rnd_search","f3e5ecd8":"# Execute random_search()\nrnd_search = random_search()","c59ffe03":"print(\"Best parameters: {}\".format(rnd_search.best_params_))\nprint(\"Best random search score: {}\".format(np.sqrt(-rnd_search.best_score_)))","66192b31":"# find feature importance\ndef important_feat():\n    feature_importances = grid_search.best_estimator_.feature_importances_\n    # Chcek most importanct attributes\n    cat_encoder = cat_pipeline.named_steps['cat_encoder']\n    cat_one_hot_attribs = list(cat_encoder.categories_[0])\n    attributes = num_attribs + cat_one_hot_attribs\n    return sorted(zip(feature_importances, attributes), reverse = True)","3ad205a6":"# Execute important_feat()\nfeature_importances = important_feat()\nprint(feature_importances)","c8eb9a2b":"# Evaluate final score on test set\ndef final_score_eval(column_name):\n    final_model = grid_search.best_estimator_\n    \n    X_test = strat_test_set.drop(column_name, axis = 1)\n    y_test = strat_test_set[column_name].copy().to_frame()\n    \n    # Second step - OneHotEncoder, encoding integers to sparse matrix as an output, if (sparse = False) array as an output\n    cat_encoder = OneHotEncoder(sparse = False)\n    y_test_encoded_ohe = cat_encoder.fit_transform(y_test)\n    \n    X_test_prepared = full_pipeline.transform(X_test)\n    final_predictions = final_model.predict(X_test_prepared)\n    \n    final_mse = mean_squared_error(y_test_encoded_ohe, final_predictions)\n    final_rmse = np.sqrt(final_mse) \n    print(\"Final score: \", final_rmse)\n    return final_rmse, final_model, cat_encoder","460ccd37":"# Execute\nfinal_rmse, final_model, cat_encoder= final_score_eval(column_name)","833e1d0b":" def find_nans(sn):\n    X_to_find = full_pipeline.transform(sn)\n    NaNs_found = final_model.predict(X_to_find)\n    return NaNs_found","bc209979":"# Execute find_nans()\nNaNs_found = find_nans(sn)\nNaNs_found[:5]","a672f6d3":"# Decode values, encoded with OneHotEncoder\none_hot_decode = cat_encoder.inverse_transform(NaNs_found)\none_hot_decode[:5]","2ca6b5fb":"# Make a df with decoded values\ndef nans_df(column_name):\n    found = pd.DataFrame(one_hot_decode, columns = [column_name], index = sn.index)\n    return found","de9e3747":"# Execute nans_df \nfound_race = nans_df(column_name)\nfound_race[:5]","f44770d6":"# Fill NaNs in raw data frame\ndef fill_nans(col_df, data_frame):\n    for index in col_df[column_name].index, data_frame[column_name].index:\n        data_frame[column_name].loc[data_frame[column_name].isnull()] = col_df[column_name]\n    return data_frame","7f408e17":"# Make a room for new values in raw dataframe\ndef make_room(df, raw_condition):\n    df.loc[raw_condition, column_name] = np.nan\n    return df","a94a715a":"# Read original data frame\ncrimes_NYC_raw = pd.read_csv(\"..\/input\/crimes_NYC.csv\")\ncrimes_NYC_raw[column_name].value_counts(dropna = False)\nraw_condition = crimes_NYC_raw[column_name] == 'UNKNOWN'\ncrimes_NYC = make_room(crimes_NYC_raw, raw_condition)\n","93cc6f70":"fill_nans(found_race, crimes_NYC)","8a2ea41c":"# Uncomment for sanity check\ncrimes_NYC.info()\ncrimes_NYC['SUSP_RACE'].value_counts(dropna = False)","f5d5f610":"# Copy crimes_NYC df\ncrimes_df = crimes_NYC.copy()","6eab74fe":"# Start values for 'SUSP_AGE_GROUP' column\ncolumn_name = 'SUSP_AGE_GROUP'\ncondition = ((crimes_df[column_name] != '25-44') & \n               (crimes_df[column_name] != '18-24') &\n               (crimes_df[column_name] != '45-64') &\n               (crimes_df[column_name] != '65+') &\n               (crimes_df[column_name] != '<18'))","5a56e7c3":"sn = susp_n(column_name, condition)","b1d25c59":"sn['SUSP_AGE_GROUP'].value_counts(dropna = False)","4b9d622b":"strat_train_set, strat_test_set = for_split(column_name)","7f9441f1":"susp_labels, crimes_df = train_and_drop(column_name, strat_train_set)","f612c7c8":"selected_list = ['BORO_NM', 'SUSP_RACE']\ncrimes_df_num, crimes_df_cat = select(selected_list)","a3d410fb":"crimes_labels_1hot = one_hot_encoder(susp_labels)\nprint(crimes_labels_1hot)","c6217504":"crimes_prepared, num_pipeline, cat_pipeline, num_attribs, full_pipeline = pipeline(crimes_df)","baa957da":"lin_rmse_scores = linear_reg(crimes_prepared, crimes_labels_1hot)","5519c27d":"tree_rmse_scores = decision_t(crimes_prepared, crimes_labels_1hot)","08805b1f":"# Execute display_scores(scores) function\nprint(\"Linear Regression\")\ndisplay_scores(lin_rmse_scores)\nprint(\"\\nDecision Tree\")\ndisplay_scores(tree_rmse_scores)","c04e79c0":"forest_rmse_scores = random_f(crimes_prepared, crimes_labels_1hot)","a4ed5a93":"# Execute display_scores(scores) function\nprint(\"Random forest\")\ndisplay_scores(forest_rmse_scores)","3a31b45f":"grid_search = grid()","abfedd67":"print(\"Grid search best parameters: \", grid_search.best_params_)\nprint(\"Grid search best estimator: \", grid_search.best_estimator_)","f53e133a":"# Evaluation scores\nprint(\"Evaluation scores\")\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n    print(np.sqrt(-mean_score), params)","13a74afc":"rnd_search = random_search()","8b92341d":"print(\"Best parameters: {}\".format(rnd_search.best_params_))\nprint(\"Best random search score: {}\".format(np.sqrt(-rnd_search.best_score_)))","44e2cb4a":"feature_importances = important_feat()\nprint(feature_importances)","2c4b17ac":"final_rmse, final_model, cat_encoder= final_score_eval(column_name)","41ee6bd8":"NaNs_found = find_nans(sn)\nNaNs_found[:5]","daa93c46":"# Decode values, encoded with OneHoTEncoder\none_hot_decode = cat_encoder.inverse_transform(NaNs_found)\none_hot_decode[:5]","cc6dfc24":"found_age = nans_df(column_name)\nfound_age[:5]","48c0973a":"# Read original data frame\n#crimes_NYC = pd.read_csv(\"..\/input\/nyc-crimes-2018-random-forest-regressor-nans\/crimes_NYC.csv\")\ncrimes_NYC[column_name].value_counts(dropna = False)\n\nraw_condition = ((crimes_NYC[column_name] != '25-44') & \n               (crimes_NYC[column_name] != '18-24') &\n               (crimes_NYC[column_name] != '45-64') &\n               (crimes_NYC[column_name] != '65+') &\n               (crimes_NYC[column_name] != '<18'))\n\ncrimes_NYC = make_room(crimes_NYC, raw_condition)\n\nfill_nans(found_age, crimes_NYC)","1dcaea73":"crimes_NYC.info()","61cbc633":"# copy crimes_NYC df\ncrimes_df = crimes_NYC.copy()","29073015":"# Start values for 'SUSP_SEX'\ncolumn_name = 'SUSP_SEX'\ncondition = ((crimes_df[column_name] != 'F') & \n              (crimes_df[column_name] != 'M'))","cd77d84e":"sn = susp_n(column_name, condition)","5f8a335b":"sn['SUSP_SEX'].value_counts(dropna=False)","372dbc46":"strat_train_set, strat_test_set = for_split(column_name)","16c031f4":"susp_labels, crimes_df = train_and_drop(column_name, strat_train_set)","35a08dac":"selected_list = ['BORO_NM', 'SUSP_RACE', 'SUSP_AGE_GROUP']\ncrimes_df_num, crimes_df_cat = select(selected_list)","2f6b95c5":"crimes_labels_1hot = one_hot_encoder(susp_labels)\nprint(crimes_labels_1hot)","bae48aa9":"crimes_prepared, num_pipeline, cat_pipeline, num_attribs, full_pipeline = pipeline(crimes_df)","6a1fa44a":"lin_rmse_scores = linear_reg(crimes_prepared, crimes_labels_1hot)","06c34952":"tree_rmse_scores = decision_t(crimes_prepared, crimes_labels_1hot)","94eb575b":"# Execute display_scores(scores) function\nprint(\"Linear Regression\")\ndisplay_scores(lin_rmse_scores)\nprint(\"\\nDecision Tree\")\ndisplay_scores(tree_rmse_scores)","aa96bb66":"forest_rmse_scores = random_f(crimes_prepared, crimes_labels_1hot)","e8cd3429":"# Execute display_scores(scores) function\nprint(\"Random forest\")\ndisplay_scores(forest_rmse_scores)","33003661":"grid_search = grid()","d9b90223":"print(\"Grid search best parameters: \", grid_search.best_params_)\nprint(\"Grid search best estimator: \", grid_search.best_estimator_)","5550d70f":"# Evaluation scores\nprint(\"Evaluation scores\")\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n    print(np.sqrt(-mean_score), params)","49b137af":"rnd_search = random_search()","9c29b60b":"print(\"Best parameters: {}\".format(rnd_search.best_params_))\nprint(\"Best random search score: {}\".format(np.sqrt(-rnd_search.best_score_)))","20f5963f":"feature_importances = important_feat()\nprint(feature_importances)","ff25b278":"final_rmse, final_model, cat_encoder= final_score_eval(column_name)","853d0d12":"NaNs_found = find_nans(sn)\nNaNs_found[:5]","11ef75c4":"# Decode values, encoded with OneHoTEncoder\none_hot_decode = cat_encoder.inverse_transform(NaNs_found)\none_hot_decode[:5]","7a83d430":"found_sex = nans_df(column_name)\nfound_sex[:6]","1f59993f":"crimes_NYC[column_name].value_counts(dropna = False)\n\nraw_condition = ((crimes_NYC[column_name] != 'F') & \n              (crimes_NYC[column_name] != 'M'))\ncrimes_NYC = make_room(crimes_NYC, raw_condition)\nfill_nans(found_sex, crimes_NYC)","61c4622b":"crimes_NYC.info()","aa3a2724":"# Write df to csv\ncrimes_NYC.to_csv('crimes_complete.csv', index = False)","dafbba93":"# Find rows in main data frame with values filled in selected column\ndef find_rows(df_with_index, selected_df):\n    crimes_filtered = crimes_NYC.iloc[crimes_NYC.index.isin(selected_df.index)]\n    return crimes_filtered","2163c6e2":"# Execute\n# find race\ndf_filled_race = find_rows(crimes_NYC, found_race)\n# find age\ndf_filled_age = find_rows(crimes_NYC, found_age)\n# find sex\ndf_filled_sex = find_rows(crimes_NYC, found_sex)","371d4eb9":"# Make comparison of values in random values columns and regression based values\ndf_filled_race = df_filled_race[['SUSP_RACE', 'suspector_race_rand']]\ndf_filled_race.reset_index()\ndf_filled_age = df_filled_age[['SUSP_AGE_GROUP', 'suspector_age_rand']]\ndf_filled_age.reset_index()\ndf_filled_sex = df_filled_sex[['SUSP_SEX', 'suspector_sex_rand']]\ndf_filled_sex.reset_index()","1733d65d":"race_reg = df_filled_race['SUSP_RACE'].value_counts(normalize = True) * 100\nrace_rnd = df_filled_race['suspector_race_rand'].value_counts(normalize = True) * 100\nprint(race_reg.index)\nage_reg = df_filled_age['SUSP_AGE_GROUP'].value_counts(normalize = True) * 100\nage_rnd = df_filled_age['suspector_age_rand'].value_counts(normalize = True) * 100\nprint(age_reg.index)\nsex_reg = df_filled_sex['SUSP_SEX'].value_counts(normalize = True) * 100\nsex_rnd = df_filled_sex['suspector_sex_rand'].value_counts(normalize = True) * 100\nprint(sex_reg.index)","fffe5b29":"# Make list from all series to obtain x values in right format (list of lists)\nlista = [race_reg, race_rnd, age_reg, age_rnd, sex_reg, sex_rnd]\n\n# Function takes list of series and returns proper x values for chart\ndef make_list(lista):\n    lista2 = []\n    for item in lista:\n        item = list(item)\n        lista2.append(item)\n    return lista2","9aba4d89":"# Execute function make_lists\nx = make_list(lista)\nx_race = x[0:2]\nx_sex = x[4:6]\nx_age = x[2:4]\nall_x = [x_race, x_age, x_sex] # just to make easier looping through \nindexes = [race_reg.index, age_reg.index, sex_reg.index]\n#print(x_race)\n#print(x_data[0])\nprint(all_x[0])\nprint(all_x)\nprint(x[0])","553b4bbc":"# Function to select visible traces at start\ndef vis(value):\n    if value == 0:\n        visible = True\n    else:\n        visible = False\n    return visible","95e49f4e":"# Function to group legends - kind of hardcoding \ndef legend_gr(count):\n    # find group\n    if float(count * 0.5).is_integer():\n        legend_group = 'group' + str((int(count * 0.5) + 1))\n    else:\n        legend_group = 'group' + str(int((count + 1) * 0.5))\n    return legend_group","d86b9aed":"# Function to hide duplicated legends\ndef hide(count):\n    if count % 2 == 0:\n        showlegend = True\n    else:\n        showlegend = False\n    return showlegend","999918dd":"# Find percent of found values\n\ncolors = ['#154B68', '#166D88',\n          '#38686A', '#869485',\n          '#BBB49F',  '#B1B6B9']\n\n\nx_data = x\ny_data = ['Values from<br>regression', 'Random values']\n\n\n# traces_race\ntraces = []\ncount = 0\nfor j in range(0, len(all_x)):\n    for i in range(0, len(all_x[j][0])):\n        for xd, yd in zip(all_x[j], y_data):\n            traces.append(go.Bar(\n                x = [xd[i]],\n                y = [yd],\n                text = [\"{0:.2f}\".format(xd[i]) + '%'],\n                hoverinfo = 'text',\n                orientation = 'h',\n                showlegend = hide(count),\n                name = indexes[j][i],\n                visible = vis(j),\n                legendgroup = str(legend_gr(count)),\n                marker = dict(\n                    color = colors[i],\n                    line = dict(\n                        color = '#f8f8f8',\n                        width = 1\n                    )\n                )\n            ))\n            count += 1\n\n\nupdatemenus = list([\n    dict(active=-1,\n         buttons=list([   \n            dict(label = 'race',\n                method = 'update',\n                args = [{'visible': [True, True, True, True, True, True, True, True, True, True, True, True, \n                                     False, False, False, False, False, False, False, False, False, False,\n                                     False, False, False, False]},\n                        {'title': 'Percentage differences between ways of filling in NaN values<br>in suspector race column.'}]),\n            dict(label = 'age',\n                method = 'update',\n                args = [{'visible': [False, False, False, False, False, False, False, False, False, False, False, False,\n                                     True, True, True, True, True, True, True, True, True, True,\n                                     False, False, False, False]},\n                        {'title': 'Percentage differences between ways of filling in NaN values<br>in suspector age group column.'}]),\n            dict(label = 'sex',\n                method = 'update',\n                args = [{'visible': [False, False, False, False, False, False, False, False, False, False, False, False,\n                                     False, False, False, False, False, False, False, False, False, False,\n                                     True, True, True, True]},\n                        {'title': 'Percentage differences between ways of filling in NaN values<br>in suspector sex column.'}]),\n        ]),\n        pad = {'r': 0, 't': 2},\n        x = -0.01,\n        y = 1.17,\n        yanchor = 'top',\n        direction = 'right',\n        bgcolor = '#daecf8',\n        bordercolor = '#daecf8',\n        font = dict(size=11, color='#2f2f30')\n    )\n])\n\nlayout = go.Layout(\n    title = 'Percentage differences between ways of filling in NaN values',\n    xaxis=dict(\n        showgrid = True,\n        showline = True,\n        autorange = True,\n        #rangemode = 'normal',\n        #fixedrange = True,\n        linecolor = '#D7DEE2',\n        showticklabels = True,\n        ticklen = 8,\n        tickwidth = 1,\n        tickcolor='#D7DEE2',\n        ticks='outside',\n        zeroline = False, \n        domain = [0.15, 1],\n        titlefont = dict(\n            family = 'Arial, sans-serif',\n            size = 18,\n            color = '#2f2f30'\n        ),\n    ),\n    yaxis = dict(\n        showgrid = False,\n        showline = False,\n        showticklabels = False,\n        zeroline = False,\n    ),\n    barmode = 'stack',\n    bargap = 0.3,\n    paper_bgcolor = '#EFF7FC',\n    plot_bgcolor = '#EFF7FC',\n    margin = dict(\n        l = 150,\n        r = 185,\n        t = 140,\n        b = 100\n    ),\n    height = 500,\n    width = 1000,\n    updatemenus=updatemenus,\n    legend = dict(\n        font=dict(\n            family = 'Arial, sans-serif',\n            size = 12,\n            color = '#2f2f30'\n        )\n    )\n)\n\nannotations = list([\n    dict(text = 'Select<br>feature', \n         x = -0.2,\n         y = 1.17,\n         yref = 'paper',\n         xref = 'paper',\n         align = 'left',\n         showarrow = False,\n         font = dict(\n             size = 14,\n             color = '#2f2f30'))\n])\n\nfor yd, xd in zip(y_data, x_data):\n    # labeling the y-axis\n    annotations.append(dict(xref = 'paper', yref = 'y',\n                            x = 0.11, y = yd,\n                            xanchor = 'right',\n                            text = str(yd),\n                            font = dict(family = 'Arial, sans-serif', size = 16,\n                                      color = '#2f2f30'),\n                            showarrow = False, align = 'right'))\n\nlayout['annotations'] = annotations\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig)","5de379cb":"### Prepare data","75d5e6ec":"### Randomized search","390ab428":"1. Rising rmse in filled columns, could be caused by many factors like decreasing amount of training data or caused by basing on filled columns, not on raw data.\n2. There are visible differences between columns using random values and regression values. Training sets equal to 50% of all data are too small of course.\n\nThank you for your time.\nIf you know better solutions for this kind of problem don't hesitate to post it. Any comments and are welcome.","0a9580e0":"### Liear Regression","ac001a94":"### Random Forest","1828667b":"### Grid Search","2f3c98ab":"Short table of contents:\n1. [Imports](#1)\n2. ['SUSP_RACE':](#2)\n    * [Train models](#3)\n    * [Fine-tune](#4)\n    * [Evaluation](#5)\n3. ['SUSP_AGE_GROUP'](#6)\n    * [Train models](#7)\n    * [Fine-tune](#8)\n    * [Evaluation](#9)\n4. ['SUSP_SEX'](#10)\n    * [Train models](#11)\n    * [Fine-tune](#12)\n    * [Evaluation](#13)\n5. [Visual comparisons](#14)\n6. [Final toughts](#15)","7553afd5":"### Decision Tree\n","0b60e8ab":"Frankly, it isn't the best performance I've ever seen, and it's slightly lower than best training score. Is it kind of underfitting?","3a7f83cf":"<a id=\"5\"><\/a> <br>\n## Evaluation","71a1c954":"<a id=\"11\"><\/a> <br>\n## Train Models","fd0d13a3":"### Grid search","cda02817":"<a id=\"1\"><\/a> <br>\n# Imports","6b49efce":"<a id=\"12\"><\/a> <br>\n## Fine-tune model","dacb3be7":"### Linear Regression","a334f113":"### Random Forest","52f39380":"<a id=\"8\"><\/a> <br>\n## Fine-tune model","f48eee0b":"<a id=\"4\"><\/a> <br>\n## Fine-tune model","d8e51b18":"<a id=\"14\"><\/a> <br>\n# Visual comparisons","ffcd233d":"This notebook is continuation of previous two. To understand the context I invite to read first and second relative to the same data set. In this kernel I try to improve method of filling NaN values which I have applied in [NYC Crimes 2018 - Random Forest Regressor & NaNs](https:\/\/www.kaggle.com\/mihalw28\/nyc-crimes-2018-random-forest-regressor-nans) notebook through apply functions to reduce wasting time. What is more, at the end of this notebook I present some comparisons between filling NaNs using random values and regression. ","1c78ddcb":"<a id=\"9\"><\/a> <br>\n## Evaluation","5d14624d":"<a id=\"10\"><\/a> <br>\n# SUSP_SEX","3cd00500":"### Randomized search","bce3de7a":"<a id=\"2\"><\/a> <br>\n# SUSP_RACE","e3eb1a6b":"### Random Forest","57f0dd97":"<a id=\"7\"><\/a> <br>\n## Train models","3be8f8a3":"As you can see all columns in data frame have 109543 non-null values except 3. *SUSP_AGE_GROUP*, *SUSP_RACE*, *SUSP_SEX* with filled NaNs respectively *suspector_age_rand*, *suspector_race_rand* and *suspector_sex_rand* are placed at the end of the df. It is important to mention that already filled suspector columns are filled with random values. More info in previous [kernel](https:\/\/www.kaggle.com\/mihalw28\/nyc-crimes-2018-random-forest-regressor-nans).\n\nTo be precise, not all columns in data frame have appropriate values. If you want verificate it yourself, chek values in victim columns. However I didn't have reason to change those values yet. (There is a possibility I'll take care of it later.)","409b0f89":"Notebook created: 2018-01-10\nLast update: 2018-01-10\nVersion 1\n\nList of previous kernels relative to data set used in this kernel:\n1. First, introductory kernel - [NYC Crimes 2018 - data cleaning, part I](https:\/\/www.kaggle.com\/mihalw28\/nyc-crimes-2018-data-cleaning-part-i)\n2. Second - [NYC Crimes 2018 - Random Forest Regressor & NaNs](https:\/\/www.kaggle.com\/mihalw28\/nyc-crimes-2018-random-forest-regressor-nans)\n3. This one - [Fill NaNs using regression, part II](https:\/\/www.kaggle.com\/mihalw28\/fill-nans-with-ml)\n4. Last, mostly visualisations - [NYC crimes 2018 - visualistions](https:\/\/www.kaggle.com\/mihalw28\/nyc-crimes-2018-visualistions)","3da82638":"### Linear Regression","dd274f43":"### Decision Tree","4ba780cc":"<a id=\"6\"><\/a> <br>\n# SUSP_AGE_GROUP","1c95df60":"### Decission Tree","cbfcd97c":"<a id=\"15\"><\/a> <br>\n# Summary and final toughts","f75818c2":"### Grid Search","7109b3dd":"<a id=\"3\"><\/a> <br>\n## Train models","dd2d7040":"### Randomized Search\n","611bd4c1":"<a id=\"13\"><\/a> <br>\n## Evaluation","30b3195e":"As you could see my models are pretty simple. I selected basic regression models and followed them to get scores. I  won't intend find new models' parameters and try to obtain better results in this project. Or maybe if I'll find while. :)"}}