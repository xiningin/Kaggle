{"cell_type":{"a595b9ad":"code","482e583e":"code","9388cac4":"code","7cbfb3f6":"code","4dab0c71":"code","dedd0650":"code","d0de6537":"code","b74d69e3":"code","a77fea4e":"code","909758e1":"code","b059e45d":"code","9a8785f1":"code","6afc1297":"code","4c205419":"code","d41e9696":"code","a70a3b1d":"code","64c0a15d":"code","cd3ec1e9":"code","50b8c20e":"code","dd9b1f68":"code","2966c8c1":"code","49f37cb9":"code","95e0063b":"code","6a537ef7":"code","836982d3":"code","ea7f8822":"code","7d24a0ec":"code","1b626bd2":"code","a2f5268b":"code","1e2aac20":"code","b5a82144":"code","2f94cff3":"code","ab1172fc":"markdown","84f8700c":"markdown","773812df":"markdown","5d214d42":"markdown","b320d939":"markdown","5fd72fb1":"markdown","ad96326e":"markdown","b2607050":"markdown","78bd68b6":"markdown","9318bcd2":"markdown","174f3b4f":"markdown","015ab6c5":"markdown","62c98c27":"markdown","9b5f601d":"markdown","903ebd6e":"markdown","e4718fd6":"markdown","4a6ae64b":"markdown"},"source":{"a595b9ad":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\ndf=pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')\ndf.head()","482e583e":"df.shape","9388cac4":"\npx.histogram(df,x='discourse_type')","7cbfb3f6":"df['length_of_text_char']=list(map(len,df['discourse_text']))\ndf['length_of_text_word']=list(map(lambda x:len(x.split(' ')),df['predictionstring']))\n","4dab0c71":"px.histogram(df,x='length_of_text_char',marginal='box')","dedd0650":"px.histogram(df,x='length_of_text_word',marginal='box')","d0de6537":"df['char\/word']=df['length_of_text_char']\/df['length_of_text_word']\npx.histogram(df,x='char\/word',marginal='box')","b74d69e3":"crop=df[df['discourse_type']=='Lead']\ncrop2=df[df['discourse_type']!='Lead']\naverage=np.mean(crop2['length_of_text_word'])-np.mean(crop['length_of_text_word'])\nif average<0:new='increased'\nelse:new='decreased'\nprint('Shift of length of text',np.abs(average),'words',new)\npx.histogram(crop,x='length_of_text_word',marginal='box')","a77fea4e":"crop=df[df['discourse_type']=='Position']\naverage=np.mean(crop2['length_of_text_word'])-np.mean(crop['length_of_text_word'])\nif average<0:new='increased'\nelse:new='decreased'\nprint('Shift of length of text',np.abs(average),'words',new)\npx.histogram(crop,x='length_of_text_word',marginal='box')","909758e1":"crop=df[df['discourse_type']=='Evidence']\ncrop2=df[df['discourse_type']!='Evidence']\naverage=np.mean(crop2['length_of_text_word'])-np.mean(crop['length_of_text_word'])\nif average<0:new='increased'\nelse:new='decreased'\nprint('Shift of length of text',np.abs(average),'words',new)\npx.histogram(crop,x='length_of_text_word',marginal='box')\n","b059e45d":"crop=df[df['discourse_type']=='Claim']\ncrop2=df[df['discourse_type']!='Claim']\naverage=np.mean(crop2['length_of_text_word'])-np.mean(crop['length_of_text_word'])\nif average<0:new='increased'\nelse:new='decreased'\nprint('Shift of length of text',np.abs(average),'words',new)\npx.histogram(crop,x='length_of_text_word',marginal='box')","9a8785f1":"crop=df[df['discourse_type']=='Concluding Statement']\ncrop2=df[df['discourse_type']!='Concluding Statement']\naverage=np.mean(crop2['length_of_text_word'])-np.mean(crop['length_of_text_word'])\nif average<0:new='increased'\nelse:new='decreased'\nprint('Shift of length of text',np.abs(average),'words',new)\npx.histogram(crop,x='length_of_text_word',marginal='box')","6afc1297":"crop=df[df['discourse_type']=='Counterclaim']\ncrop2=df[df['discourse_type']!='Counterclaim']\naverage=np.mean(crop2['length_of_text_word'])-np.mean(crop['length_of_text_word'])\nif average<0:new='increased'\nelse:new='decreased'\nprint('Shift of length of text',np.abs(average),'words',new)\npx.histogram(crop,x='length_of_text_word',marginal='box')","4c205419":"crop=df[df['discourse_type']=='Rebuttal']\ncrop2=df[df['discourse_type']!='Rebuttal']\naverage=np.mean(crop2['length_of_text_word'])-np.mean(crop['length_of_text_word'])\nif average<0:new='increased'\nelse:new='decreased'\nprint('Shift of length of text',np.abs(average),'words',new)\npx.histogram(crop,x='length_of_text_word',marginal='box')","d41e9696":"classes=set(list(df['discourse_type']))\nhist=dict()\nfor c in classes:\n    crop=df[df['discourse_type']==c]\n    ma=np.max(crop['length_of_text_word'])\n    hist[c]=ma\nhist","a70a3b1d":"T={'Class':list(hist.keys()),'Count':list(hist.values())}\npx.bar(T, x='Class', y='Count')","64c0a15d":"sentences=list(df['discourse_text'])\nfrom tqdm import tqdm\nfrom nltk.tokenize import word_tokenize\nprint('Tokenizing')\ntokenized=list(map(word_tokenize,tqdm(sentences)))\n","cd3ec1e9":"histogram=dict()\nprint('Taking out the freuqency of each word')\nfor k in tqdm(tokenized):\n    for word in k:\n        try:\n            histogram[word]+=1\n        except:\n            histogram[word]=1\n        ","50b8c20e":"print('We have',len(histogram.keys()),'unique words and symbols in our dataset')","dd9b1f68":"print('Percentage of imbalance in the data',np.var(list(histogram.values()))\/(np.max(list(histogram.values())-np.min(list(histogram.values()))))**2*100,'Percentage')","2966c8c1":"from spacy.lang.en.stop_words import STOP_WORDS as stop_words\nprint('We have ,',len(stop_words),'stopwords')","49f37cb9":"#calculates percentage of stopwords in each essay\ndef calculate(words):\n    n=0\n    for word in words:\n        if word in stop_words:\n            n+=1\n    return n\/len(words)*100\ndf['stopwords']=list(map(calculate,tokenized))\n","95e0063b":"h=df.groupby('discourse_type').mean()","6a537ef7":"h","836982d3":"print('Average percentage of stopwords,',np.mean(h['stopwords']))\npx.bar(h,x='stopwords')","ea7f8822":"px.histogram(df,x='stopwords',marginal='box')","7d24a0ec":"percentile25 = df['stopwords'].quantile(0.25)\npercentile75 = df['stopwords'].quantile(0.75)","1b626bd2":"iqr=(percentile75-percentile25)","a2f5268b":"upper_limit = percentile75 + 1.5 * iqr\nlower_limit = percentile25 - 1.5 * iqr\nprint(upper_limit,lower_limit)","1e2aac20":"df['outlier1']=(df['stopwords']>upper_limit).astype(int)\ndf['outlier2']=(df['stopwords']<lower_limit).astype(int)\ndf['outlier']=np.minimum(df['outlier1']+df['outlier2'],1)\ndf['outlier']=np.where(df['outlier']==1,True,False)\npx.histogram(df,x='outlier')","b5a82144":"percentile25 = df['length_of_text_word'].quantile(0.25)\npercentile75 = df['length_of_text_word'].quantile(0.75)\niqr=(percentile75-percentile25)\nupper_limit = percentile75 + 1.5 * iqr\nlower_limit = percentile25 - 1.5 * iqr\nprint(upper_limit,lower_limit)\n\ndf['outlier1']=(df['length_of_text_word']>upper_limit).astype(int)\ndf['outlier2']=(df['length_of_text_word']<lower_limit).astype(int)\ndf['outlier3']=np.minimum(df['outlier1']+df['outlier2'],1)\ndf['outlier3']=np.where(df['outlier']==1,True,False)\npx.histogram(df,x='outlier3')","2f94cff3":"df['outliers']=np.minimum(df['outlier'].astype(int)+df['outlier3'].astype(int),1).astype(bool)\npx.histogram(df,x='outliers')","ab1172fc":"# Rebuttal","84f8700c":"# Position","773812df":"# See any  imbalance in the frequency of the words","5d214d42":"# Merge Everything","b320d939":"# Conclusions from this part\nDiffernet classes show great swingsin  max number of words , the shifts were average words\n\nquick plot over this by observing a bar plot of the number of words on each class","5fd72fb1":"# Counterclaim","ad96326e":"# Conclusions from this part\nWe might consider taking samples with too many stopwords as outliers","b2607050":"# Removing Outlier","78bd68b6":"# Evidence","9318bcd2":"# Tokenize the words","174f3b4f":"# Claim","015ab6c5":"# Observe any changes in statistics on each target , length of the word and sentence can \"have\" a influence on the rating\n\n# Lead","62c98c27":"# Thank YOU\n\nWork is still in progress and i will be updating this kernel , please give me feedbacks and improvements you want ,so that i can make this kernel better","9b5f601d":"# Plot the percentage of stopwords\n\n50 percent of the essays are filled with just stopwords , they dont seem to change much with the class though","903ebd6e":"# Outlier removal based on sentence length","e4718fd6":"# Concluding Statement","4a6ae64b":"# StopWords\nCertain classes may have a high stop word count, \n\nwhat are stopwords ?\n\nThey are words like 'a','an','the',etc and have no meaning in themselves a high stopword count may have a infleuence on the class\n\nspacy library already has many stopwords installed "}}