{"cell_type":{"3edbfd96":"code","a0ea906c":"code","c9b9417c":"code","3af45399":"code","b77566e0":"code","29ea2748":"code","c47ec54c":"code","20a0a119":"code","d899107b":"code","ac47b3fb":"code","f2e76723":"code","4a8fcfdd":"code","49d370c0":"code","7e5d17b1":"code","c1fd5ede":"code","80d232eb":"markdown","cf8802df":"markdown","117049a2":"markdown"},"source":{"3edbfd96":"import os\nimport random\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nimport optuna\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Tabular data file paths\nTRAIN_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/train.csv'\nTEST_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/test.csv'\n\n\nTARGET_NAME = 'Pawpularity'\nVAL_SIZE = 0.15\nSEED = 2021\nEARLY_ROUNDS = 50","a0ea906c":"def set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n    \n    \ndef get_features(df: pd.DataFrame) -> list:\n    \"\"\"Function selects input features from a DataFrame.\n    :param df: DataFrame containing features, Ids and possibly target values\n    :return: List of input features\n    \"\"\"\n    return [column for column in df.columns\n            if column != 'Id' and column != TARGET_NAME]\n\n\ndef add_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Function adds new features to the DataFrame\n    by summing up existing features. Uses variable \"features\"\n    defined outside the scope of this function.\n    :param df: Original DataFrame\n    :return: Updated DataFrame\n    \"\"\"\n    # Normalized sum of all original features\n    df['features_sum'] = df[features].sum(axis=1) \/ len(features)\n\n    # Feature pairs (normalized)\n    for i in range(len(features) - 1):\n        for j in range(i + 1, len(features)):\n            feature_1 = features[i]\n            feature_2 = features[j]\n            df[f'{feature_1}_{feature_2}'] = (df[feature_1] + df[feature_2]) \/ 2\n\n    # Feature triplets (normalized)\n    for i in range(len(features) - 2):\n        for j in range(i + 1, len(features) - 1):\n            for z in range(j + 1, len(features)):\n                feature_1 = features[i]\n                feature_2 = features[j]\n                feature_3 = features[z]\n                df[f'{feature_1}_{feature_2}_{feature_3}'] = (\n                    df[feature_1] + df[feature_2] + df[feature_3]) \/ 3\n\n    return df\n    \n    \n    \nset_seed(SEED)\nset_display()\n\n# Train data set\ndata_train = pd.read_csv(TRAIN_DATA_PATH)\nprint(f'Train data shape: {data_train.shape}')\ndata_train.head()","c9b9417c":"# Test data set\ndata_test = pd.read_csv(TEST_DATA_PATH)\nprint(f'Test data shape: {data_test.shape}')\ndata_test.head()","3af45399":"# Distribution of the target values\nprint(f'Target values: {data_train[TARGET_NAME].min()} - {data_train[TARGET_NAME].max()}\\n'\n      f'Mean value: {data_train[TARGET_NAME].mean()}\\n'\n      f'Median value: {data_train[TARGET_NAME].median()}\\n'\n      f'Standard deviation: {data_train[TARGET_NAME].std()}')\n\nsns.histplot(data=data_train, x=TARGET_NAME, kde=True)\nplt.axvline(data_train[TARGET_NAME].mean(), c='orange', ls='-', lw=3, label='Mean')\nplt.axvline(data_train[TARGET_NAME].median(), c='green', ls='-', lw=3, label='Median')\nplt.legend()\nplt.title('Pawpularity Score')\nplt.tight_layout()\nplt.show()","b77566e0":"data_train.head()","29ea2748":"# List of original input features\n# features = get_features(data_train)\n\n# # Add new features\n# data_train = add_features(data_train)\n# data_test = add_features(data_test)\n# data_train.head()","c47ec54c":"!pip -qq install pycaret\n\nfrom pycaret.regression import *","20a0a119":"ignore_feature = ['Id']\nreg = setup(data = data_train, \n             target = 'Pawpularity',\n             numeric_imputation = 'mean',\n             categorical_features = []  , \n             ignore_features = ignore_feature,\n             normalize = True,\n             silent = True,\n           create_clusters=True)","d899107b":"compare_models()","ac47b3fb":"cb = create_model('lightgbm')","f2e76723":"interpret_model(cb)","4a8fcfdd":"cb = create_model('huber')","49d370c0":"predictions = predict_model(cb, data = data_test)\n\ndata_test['Pawpularity'] = predictions['Label']\ndata_test[['Id','Pawpularity']].to_csv('submission.csv',index=False)\ndata_test[['Id','Pawpularity']]","7e5d17b1":"cb = create_model('lar')","c1fd5ede":"predictions2 = predict_model(cb, data = data_test)\n\ndata_test['Pawpularity'] = predictions['Label']*0.5+predictions2['Label']*0.5\ndata_test[['Id','Pawpularity']].to_csv('submission.csv',index=False)\ndata_test[['Id','Pawpularity']]","80d232eb":"### SHAP values for LGBM","cf8802df":"# Understanding different regression models with Pycaret!!\n\n![Pycaret](https:\/\/miro.medium.com\/max\/1400\/1*Cku5-rqmqSIuhUyFkIAdIA.png)","117049a2":"### Kindly upvote if it seems relevant!"}}