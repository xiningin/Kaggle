{"cell_type":{"f3f33a16":"code","ba7ab5ab":"code","e4b0bc6c":"code","72c2ef9a":"code","6f11b9e6":"code","3db5e376":"code","7651a7e9":"code","c702becf":"code","cdbf80ea":"code","84e4ce5c":"code","44ab0432":"code","30fcfdbf":"code","3b692e27":"code","bc53c3c4":"code","d4fa0bcb":"code","3370b682":"code","c413c565":"code","b1cfa14e":"code","8a241d22":"code","26f8b702":"code","6e847e44":"code","b073caa7":"code","b96e4f3f":"code","1852b9e9":"code","309abf67":"code","c24254c4":"code","1f7c3a6c":"code","b4a25fea":"markdown"},"source":{"f3f33a16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nPATH=\"..\/input\/\"\nprint(os.listdir(PATH))\n\n# Any results you write to the current directory are saved as output.","ba7ab5ab":"app_train = pd.read_csv(PATH + 'application_train.csv',)\napp_test = pd.read_csv(PATH + 'application_test.csv',)\nprint (\"\u0444\u043e\u0440\u043c\u0430\u0442 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438:\", app_train.shape)\nprint (\"\u0444\u043e\u0440\u043c\u0430\u0442 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438:\", app_test.shape)","e4b0bc6c":"app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = 0)","72c2ef9a":"app_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)","6f11b9e6":"#\u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043b\u0435\u0439\u0431\u043b\u044b, \u0438\u0445 \u0436\u0435 \u043d\u0435\u0442 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0438 \u043f\u0440\u0438 \u0432\u044b\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u043d\u0438\u0438 \u043e\u043d\u0438 \u043f\u043e\u0442\u0435\u0440\u044f\u044e\u0442\u0441\u044f. \ntrain_labels = app_train['TARGET']\n\n# \u0412\u044b\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u043d\u0438\u0435 - \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u044b. \u0438\u043c\u0435\u044e\u0449\u0438\u0435\u0441\u044f \u0432 \u043e\u0431\u043e\u0438\u0445 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430\u0445\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n\nprint('\u0424\u043e\u0440\u043c\u0430\u0442 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438: ', app_train.shape)\nprint('\u0424\u043e\u0440\u043c\u0430\u0442 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438: ', app_test.shape)\n\n# Add target back in to the data\napp_train['TARGET'] = train_labels","3db5e376":"# \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u043d\u043e\u0432\u044b\u0439 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u0434\u043b\u044f \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\npoly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\npoly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n\n# \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u043e\u0442\u0443\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'median')\n\npoly_target = poly_features['TARGET']\n\npoly_features = poly_features.drop('TARGET', axis=1)\n\npoly_features = imputer.fit_transform(poly_features)\npoly_features_test = imputer.transform(poly_features_test)\n\nfrom sklearn.preprocessing import PolynomialFeatures\n                                  \n# \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u043e\u0431\u044a\u0435\u043a\u0442 \u0441\u0442\u0435\u043f\u0435\u043d\u0438 3\npoly_transformer = PolynomialFeatures(degree = 3)\n\n# \u0422\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0430 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\npoly_transformer.fit(poly_features)\n\n# \u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\npoly_features = poly_transformer.transform(poly_features)\npoly_features_test = poly_transformer.transform(poly_features_test)\nprint('\u0424\u043e\u0440\u043c\u0430\u0442 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432: ', poly_features.shape)","7651a7e9":"poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])[:15]","c702becf":"# \u0414\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u0434\u043b\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447 \npoly_features = pd.DataFrame(poly_features, \n                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                           'EXT_SOURCE_3', 'DAYS_BIRTH']))\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0442\u0430\u0440\u0433\u0435\u0442\npoly_features['TARGET'] = poly_target\n\n# \u0440\u0430\u0441\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044e\npoly_corrs = poly_features.corr()['TARGET'].sort_values()\n\n# \u041e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0441 \u043d\u0430\u0438\u0432\u044b\u0441\u0448\u0435\u0439 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0435\u0439\nprint(poly_corrs.head(10))\nprint(poly_corrs.tail(5))","cdbf80ea":"# \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\npoly_features_test = pd.DataFrame(poly_features_test, \n                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n\n# \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u043c \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u044b\npoly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\napp_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n\n# \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u044b\npoly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\napp_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n\n# \u0412\u044b\u0440\u043e\u0432\u043d\u044f\u0435\u043c \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u044b\napp_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)\n\n# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0444\u043e\u0440\u043c\u0430\u0442\nprint('\u0422\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0441 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0438\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438: ', app_train_poly.shape)\nprint('\u0422\u0435\u0441\u0442\u043e\u0432\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0441 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0438\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438: ', app_test_poly.shape)","84e4ce5c":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\n\n# \u0423\u0431\u0435\u0440\u0435\u043c \u0442\u0430\u0440\u0433\u0435\u0442 \u0438\u0437 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nif 'TARGET' in app_train:\n    train = app_train.drop(labels = ['TARGET'], axis=1)\nelse:\n    train = app_train.copy()\nfeatures = list(train.columns)\n\n# \u043a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\ntest = app_test.copy()\n\n# \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u044e\u0449\u0435\u0435 \u043f\u043e \u043c\u0435\u0434\u0438\u0430\u043d\u0435\nimputer = SimpleImputer(strategy = 'median')\n\n# \u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f\nscaler = MinMaxScaler(feature_range = (0, 1))\n\n# \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\nimputer.fit(train)\n\n# \u0422\u0440\u0430\u043d\u0441\u043e\u0444\u0440\u043c\u0430\u0446\u0438\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043e\u043a\ntrain = imputer.transform(train)\ntest = imputer.transform(app_test)\n\n# \u0442\u043e \u0436\u0435 \u0441\u0430\u043c\u043e\u0435 \u0441 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0435\u0439\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('\u0424\u043e\u0440\u043c\u0430\u0442 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438: ', train.shape)\nprint('\u0424\u043e\u0440\u043c\u0430\u0442 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438: ', test.shape)","44ab0432":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(train,train_labels,test_size=0.3,random_state=17)","30fcfdbf":"X_train.shape, y_train.shape","3b692e27":"from sklearn.metrics import accuracy_score, roc_auc_score","bc53c3c4":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV","d4fa0bcb":"c_values = np.logspace(-2, 3, 20)","3370b682":"grid1.best_score_","c413c565":"%%time\nlog_reg1 = LogisticRegression(C = 0.0001,solver=\"lbfgs\",max_iter=2500)\n\nc_values1 = np.logspace(-2, 3, 30)\nparameters={'C':c_values1}\ngrid1 = GridSearchCV(log_reg1, parameters, scoring='roc_auc', cv=3)\ngrid1.fit(X_train, y_train)\nprint(grid1)\n# summarize the results of the grid search\nprint(grid1.best_score_)\nprint (grid1.best_params_)","b1cfa14e":"from datetime import datetime\n\nnow = datetime.now()","8a241d22":"now #\u0432\u0440\u0435\u043c\u044f \u0431\u044b\u043b\u043e 4.16","26f8b702":"%%time\n\n\n# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nlog_reg = LogisticRegression(C = 0.99,solver=\"lbfgs\",max_iter=2500)\n\nparameters={'C':c_values}\ngrid = GridSearchCV(log_reg, parameters, cv=5)\ngrid.fit(X_train, y_train)\nprint(grid)\n# summarize the results of the grid search\nprint(grid.best_score_)\nprint (grid.best_params_)\n# \u0422\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\n#log_reg.fit(X_train, y_train)\n\n\n#log_reg_pred_acc = log_reg.predict(X_test)\n#log_reg_pred = log_reg.predict_proba(X_test)[:, 1]\n#print (\"\u0414\u043e\u043b\u044f \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432: \",accuracy_score(y_test,log_reg_pred_acc))\n#print (\"ROC-AUC: \",roc_auc_score(y_test,log_reg_pred))","6e847e44":"from sklearn.linear_model import LogisticRegression\n\n# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nlog_reg = LogisticRegression(C = 28.072,solver=\"lbfgs\", max_iter=2500)\n\n# \u0422\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nlog_reg.fit(train, train_labels)\n\n\nlog_reg_pred = log_reg.predict_proba(test)[:, 1]\n# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n#predictions = random_forest.predict_proba(test)[:, 1]\n\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430 \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\nsubmit.to_csv('up_linear_model.csv', index = False)","b073caa7":"from sklearn.linear_model import LogisticRegressionCV \nfrom sklearn.model_selection import cross_val_score, StratifiedKFold","b96e4f3f":"from sklearn.ensemble import RandomForestClassifier\n\n# \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\nrandom_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)\n\n# \u0422\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0430 \u043d\u0430 \u0442\u0435\u0440\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nrandom_forest.fit(train, train_labels)\n\n# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\npredictions = random_forest.predict_proba(test)[:, 1]\n\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430 \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\nsubmit.to_csv('random_forest_baseline.csv', index = False)","1852b9e9":"poly_features_names = list(app_train_poly.columns)\n\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0430 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u0434\u043b\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nimputer = SimpleImputer(strategy = 'median')\n\npoly_features = imputer.fit_transform(app_train_poly)\npoly_features_test = imputer.transform(app_test_poly)\n\n# \u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f\nscaler = MinMaxScaler(feature_range = (0, 1))\n\npoly_features = scaler.fit_transform(poly_features)\npoly_features_test = scaler.transform(poly_features_test)\n\nrandom_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50)\n\n# \u0422\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0430 \u043d\u0430 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nrandom_forest_poly.fit(poly_features, train_labels)\n\n# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\npredictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]\n\n# \u0414\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430\nsubmit.to_csv('random_forest_baseline_engineered.csv', index = False)","309abf67":"from lightgbm import LGBMClassifier\n\nclf = LGBMClassifier()\nclf.fit(train, train_labels)\n\npredictions = clf.predict_proba(test)[:, 1]\n\n# \u0414\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430\nsubmit.to_csv('lightgbm_baseline.csv', index = False)","c24254c4":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.head()","1f7c3a6c":"submit.to_csv('log_reg_baseline.csv', index = False)","b4a25fea":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.head()"}}