{"cell_type":{"91d96d75":"code","ceb8afa8":"code","de5fa519":"code","93839f6b":"code","cdc1ac0f":"code","6452b224":"code","756101a2":"code","b2c10c32":"code","a12858a9":"code","53d582a2":"code","983d3dfd":"code","b8e44f37":"code","a0f458a5":"code","d7575e69":"code","2e1df3de":"code","845f2b92":"code","55f3741e":"code","1655c4ef":"code","b6c7294a":"code","3813f8cc":"code","e8670359":"code","796818d8":"code","e0c701fa":"code","845a648c":"code","bfa6a50f":"code","33b200d6":"code","6c630466":"code","c2df4350":"code","afc92733":"code","cfe9698f":"code","d394e005":"markdown","1f356a3a":"markdown","fa2c82a2":"markdown"},"source":{"91d96d75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nfrom sklearn.impute import SimpleImputer\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ceb8afa8":"PATH = \"\/kaggle\/input\/titanic\/\"","de5fa519":"train = pd.read_csv(f'{PATH}train.csv')","93839f6b":"print(train.shape)\ntrain.describe()","cdc1ac0f":"train.columns","6452b224":"train.dtypes","756101a2":"train.isna().sum()","b2c10c32":"train.head()","a12858a9":"test = pd.read_csv(f'{PATH}test.csv')","53d582a2":"drop_col = [\"PassengerId\",\"Ticket\",\"Name\"]\nX = train.drop(drop_col + [\"Survived\"],axis = 1)\ny = train[\"Survived\"]\nX_test = test.drop(drop_col,axis = 1)\nprint(f\"X {X.shape}\")\nprint(f\"y {y.shape}\")\nprint(f\"X_test {X_test.shape}\")","983d3dfd":"ohe_X = pd.get_dummies(X)\nohe_X_test = pd.get_dummies(X_test)\n","b8e44f37":"ohe_X.head().T","a0f458a5":"ohe_X_test.head().T","d7575e69":"final_ohe_X, final_ohe_X_test = ohe_X.align(ohe_X_test,join=\"left\",axis =1 )\n                                                                  ","2e1df3de":"final_ohe_X_test.head()","845f2b92":"from sklearn.model_selection import train_test_split\nX_train,X_val,y_train,y_val =  train_test_split(final_ohe_X,y,test_size=0.3, random_state=123)\nprint(f\"X_train {X_train.shape}\")\nprint(f\"y_train {y_train.shape}\")\nprint(f\"X_val {X_val.shape}\")\nprint(f\"y_val {y_val.shape}\")","55f3741e":"def impute_data(X_train,X_valid,X_test):\n    cols_with_missing = [col for col in X_train.columns\n                     if X_train[col].isnull().any()]\n    print(f\"cols_with_missing {cols_with_missing}\")\n    X_train_plus = X_train.copy()\n    X_valid_plus = X_valid.copy()\n    X_test_plus = X_test.copy()\n\n    # Make new columns indicating what will be imputed\n    for col in cols_with_missing:\n        X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n        X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n        X_test_plus[col + '_was_missing'] = X_test_plus[col].isnull()\n\n    # Imputation\n    my_imputer = SimpleImputer()\n    imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n    imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n    imputed_X_test_plus = pd.DataFrame(my_imputer.transform(X_test_plus))\n    \n\n    # Imputation removed column names; put them back\n    imputed_X_train_plus.columns = X_train_plus.columns\n    imputed_X_valid_plus.columns = X_valid_plus.columns\n    imputed_X_test_plus.columns = X_test_plus.columns\n    \n    \n    return imputed_X_train_plus,imputed_X_valid_plus,imputed_X_test_plus\n","1655c4ef":"imputed_X_train,imputed_X_val,imputed_X_test = impute_data(X_train,X_val,final_ohe_X_test)","b6c7294a":"imputed_X_train.T","3813f8cc":"imputed_X_test.isna().sum()","e8670359":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, \n                               bootstrap = True,\n                               max_features = 'sqrt')\n# Fit on training data\nmodel.fit(imputed_X_train, y_train)","796818d8":"from sklearn.metrics import accuracy_score\nval_predict = model.predict(imputed_X_val)\nprint(f\"accuracy {accuracy_score(y_val, val_predict)}\")","e0c701fa":"from sklearn import metrics\nimport matplotlib.pyplot as plt\ny_pred_proba = model.predict_proba(imputed_X_val)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\nauc = metrics.roc_auc_score(y_val, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","845a648c":"from sklearn.model_selection import train_test_split\nX_train,X_val,y_train,y_val =  train_test_split(final_ohe_X,y,test_size=0.3, random_state=123)\nprint(f\"X_train {X_train.shape}\")\nprint(f\"y_train {y_train.shape}\")\nprint(f\"X_val {X_val.shape}\")\nprint(f\"y_val {y_val.shape}\")","bfa6a50f":"type(imputed_X_test)","33b200d6":"from sklearn.model_selection import cross_val_score\ntrain_X = pd.concat([imputed_X_train,imputed_X_val])\ntrain_y = pd.concat([y_train,y_val])\nmodel = RandomForestClassifier(n_estimators=100, \n                               bootstrap = True,\n                               max_features = 'sqrt')\n# Fit on training data\nmodel.fit(train_X, train_y)\nscores = cross_val_score(model, train_X, train_y, cv=5, scoring = \"accuracy\")\nprint(scores)\nprint(scores.mean())","6c630466":"submit_file =  pd.DataFrame()\nsubmit_file['PassengerId'] = test.PassengerId\nsubmit_file['Survived'] = model.predict(imputed_X_test)","c2df4350":"submit_file","afc92733":"submit_file.to_csv(\"submit.csv\",index=False)","cfe9698f":"feat_importances = pd.Series(model.feature_importances_, index=imputed_X_train.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","d394e005":"# Train Test Split","1f356a3a":"# One hot encoding","fa2c82a2":"# KFOLD"}}