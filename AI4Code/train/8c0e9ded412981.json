{"cell_type":{"2698d452":"code","fc69bfcf":"code","ebaf1938":"code","d2d80b18":"code","c99cdc64":"code","9c46f9de":"code","157d626f":"code","1cec88ac":"code","7f53f432":"code","d2e0058c":"code","446eb01b":"code","37821ae9":"code","07d916e0":"code","34efe431":"code","63801aea":"code","50749dc8":"code","cd009008":"code","174b1689":"code","b62dbf38":"code","f8f2afd9":"code","3b9b0ef8":"markdown","83865fe0":"markdown","91662851":"markdown","6ceefba1":"markdown","640d0da4":"markdown"},"source":{"2698d452":"# !pip install optuna","fc69bfcf":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport optuna\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.base import TransformerMixin\n\nimport xgboost as xgb\nimport lightgbm as lgb","ebaf1938":"df = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/train.csv')\ndf.head()","d2d80b18":"figure, ax = plt.subplots(figsize=(16, 16))\nsns.heatmap(df.sample(n=1_000).corr(), annot=True, linewidths=.5, ax=ax)","c99cdc64":"def objective_xgb(trial, data, target):\n    parameters = {\n        'tree_method': 'gpu_hist',\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008, 0.009, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]),\n        'n_estimators': 1000,\n        'max_depth': trial.suggest_categorical('max_depth', [5, 7, 9, 11, 13, 15, 17, 20]),\n        'random_state': trial.suggest_categorical('random_state', [24, 48, 2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }\n    \n    # \u041f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0447\u0435\u0440\u0435\u0437 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e, \u0443\u0441\u0440\u0435\u0434\u043d\u044f\u0435\u043c \u043e\u0448\u0438\u0431\u043a\u0443 \n    folds = KFold(n_splits=5, random_state=1337, shuffle=True)\n    rmse = []\n    \n    for train_idx, test_idx in folds.split(data, target):\n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n    \n        model = xgb.XGBRegressor(**parameters)\n        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)\n    \n        rmse.append(mean_squared_error(y_test, model.predict(X_test), squared=False))\n    \n    print(f'Mean RMSE for all the folds: {np.mean(rmse)}')\n    \n    return np.mean(rmse)","9c46f9de":"\"\"\"\nstudy_xgb = optuna.create_study(direction='minimize')\nstudy_xgb.optimize(objective_xgb, n_trials=50)\n\nprint(f'Number of finished trials: {len(study_xgb.trials)}')\nprint(f'Best trial: {study_xgb.best_trial.params}')\n\"\"\"","157d626f":"xgb_parameters = {\n    'objective': 'reg:squarederror',\n    'tree_method': 'gpu_hist',\n    'n_estimators': 1000,\n    'lambda': 7.610705234008646, \n    'alpha': 0.0019377246932580476, \n    'colsample_bytree': 0.5, \n    'subsample': 0.7, \n    'learning_rate': 0.012, \n    'max_depth': 20, \n    'random_state': 24, \n    'min_child_weight': 229\n}","1cec88ac":"def objective_lgb(trial):\n    X, y = df.drop(columns=['target', 'id']).values, df['target'].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)\n    \n    ds_train = lgb.Dataset(X_train, label=y_train)\n    ds_test = lgb.Dataset(X_test, label=y_test)\n   \n    parameters = {\n        'device_type': 'gpu',\n        'objective': 'regression',\n        'metric': 'rmse',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n    }\n\n    gbm = lgb.train(parameters, ds_train)\n    prediction = gbm.predict(X_test)\n    accuracy = mean_squared_error(y_test, prediction, squared=False)\n    \n    return accuracy","7f53f432":"\"\"\"\nstudy_lgb = optuna.create_study(direction='minimize')\nstudy_lgb.optimize(objective_lgb, n_trials=100)\n\nprint(f'Number of finished trials: {len(study_lgb.trials)}')\nprint(f'Best trial: {study_lgb.best_trial.params}')\n\"\"\"","d2e0058c":"lgb_parameters = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting': 'gbdt',\n    'lambda_l1': 3.2737454713243543e-07,\n    'lambda_l2': 3.685676983230042e-06,\n    'num_leaves': 190,\n    'feature_fraction': 0.47291296723211934,\n    'bagging_fraction': 0.8846579981793894,\n    'bagging_freq': 3,\n    'min_child_samples': 58,\n    'verbose': 0,\n    'device_type': 'gpu'\n}","446eb01b":"class NonLinearTransformer(TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X = X.drop(columns=['id'])\n    \n        for c in X.columns:\n            if c == 'target':\n                continue\n            X[f'{c}^2'] = X[c] ** 2\n            \n        return X","37821ae9":"pipe_xgb = Pipeline([\n    ('custom', NonLinearTransformer()),\n    ('scaling', StandardScaler()),\n    ('regression', xgb.XGBRegressor(**xgb_parameters))\n])\n\npipe_lgb = Pipeline([\n    ('custom', NonLinearTransformer()),\n    ('scaling', StandardScaler()),\n    ('regression', lgb.LGBMRegressor(**lgb_parameters))\n])","07d916e0":"df_train = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/train.csv')\ndf_predict = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/test.csv')","34efe431":"X, y = df_train.drop(columns=['target']), df_train['target']","63801aea":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)","50749dc8":"pipe_xgb.fit(X_train, y_train)\npipe_lgb.fit(X_train, y_train)\n\nprint(f'XGB Score: {pipe_xgb.score(X_test, y_test)}, LGB Score: {pipe_lgb.score(X_test, y_test)}')\nprint(f'XGB RMSE: {mean_squared_error(y_test, pipe_xgb.predict(X_test), squared=False)}, LGB RMSE: {mean_squared_error(y_test, pipe_lgb.predict(X_test), squared=False)}')","cd009008":"def ensemble_predict(X):\n    target_xgb = pipe_xgb.predict(X)\n    target_lgb = pipe_lgb.predict(X)\n\n    return [0.85 * x + 0.15 * l for (x, l) in zip(target_xgb, target_lgb)]","174b1689":"print(f'Ensemble RMSE: {mean_squared_error(y_test, ensemble_predict(X_test), squared=False)}')","b62dbf38":"pipe_xgb.fit(X, y)\npipe_lgb.fit(X, y)","f8f2afd9":"target = pd.DataFrame({\n    'id': df_predict['id'], 'target': ensemble_predict(df_predict)\n})\ntarget.to_csv('submission.csv', index=False)","3b9b0ef8":"\u0421\u0447\u0438\u0442\u0430\u0435\u0442\u0441\u044f \u0434\u043e\u043b\u0433\u043e \u0438 \u043d\u0430 GPU, \u0442\u0430\u043a \u0447\u0442\u043e \u0432\u044b\u043f\u0438\u0448\u0435\u043c \u043d\u0438\u0436\u0435 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b.","83865fe0":"\u041f\u0440\u043e\u0434\u0435\u043b\u044b\u0432\u0430\u0435\u043c \u043f\u043e\u0445\u043e\u0436\u0443\u044e \u043f\u0440\u043e\u0446\u0435\u0434\u0443\u0440\u0443 \u0441 `LightGBM`.","91662851":"\u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u043c\u0430\u0442\u0440\u0438\u0446\u0443, \u0447\u0442\u043e\u0431\u044b \u0432\u044b\u043a\u0438\u043d\u0443\u0442\u044c \u0441\u0438\u043b\u044c\u043d\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u043b\u0438\u0440\u0443\u044e\u0449\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438.","6ceefba1":"\u041c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0431\u044b \u0432\u044b\u043a\u0438\u043d\u0443\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a `cont6`, \u043d\u043e \u0442\u0430\u043a \u043a\u0430\u043a \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043c\u0430\u043b\u043e, \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0435\u0433\u043e.\n\n\u0411\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u044c \u0438\u0437 \u0434\u0432\u0443\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430, `XGBoost` \u0438 `LightGBM`.\n\u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0443 `optuna`.","640d0da4":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442."}}