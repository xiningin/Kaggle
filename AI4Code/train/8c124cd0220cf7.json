{"cell_type":{"862d823a":"code","09b7b88f":"code","7f3ac080":"code","5db05380":"code","8ebcd73a":"code","bcbd90ec":"code","154cb3bf":"code","db0a5eee":"code","96a50773":"code","40150618":"code","4cce96ee":"code","537e2fcb":"code","53c7e599":"code","989e480d":"code","c457ba2f":"code","c5200ffa":"code","ed2da1ba":"code","08adf1c8":"code","36d95a8b":"code","249b9229":"markdown","79f0bbcb":"markdown","38f09890":"markdown","a3bfc3e8":"markdown","c213d5d4":"markdown","a552d06a":"markdown","40df1a58":"markdown","6af4652e":"markdown"},"source":{"862d823a":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","09b7b88f":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","7f3ac080":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","5db05380":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()","8ebcd73a":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","bcbd90ec":"for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","154cb3bf":"PATH = '.\/cifar_net.pth'\ntorch.save(net.state_dict(), PATH)","db0a5eee":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","96a50773":"net = Net()\nnet.load_state_dict(torch.load(PATH))","40150618":"outputs = net(images)","4cce96ee":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))","537e2fcb":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct \/ total))","53c7e599":"class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))","989e480d":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","c457ba2f":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module): \n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3)\n        self.conv2 = nn.Conv2d(32, 64, 3)\n        self.conv3 = nn.Conv2d(64, 128, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(128 * 2 * 2, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 32)\n        self.fc4 = nn.Linear(32, 10)\n        self.dropout1 = nn.Dropout(p=0.2, inplace=False)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.dropout1(x)\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.dropout1(x)\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.dropout1(x)\n        x = x.view(-1, 128 * 2 * 2)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\n\nnet = Net()\nnet.to(device)","c5200ffa":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","ed2da1ba":"for epoch in range(10):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 6000 == 5999:    # print every 6000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 6000))\n            running_loss = 0.0\n\nprint('Finished Training')","08adf1c8":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct \/ total))","36d95a8b":"PATH = '.\/seventy-percent-net.pth'\ntorch.save(net.state_dict(), PATH)","249b9229":"\n\nI completed the tutorial \"Deep Learning with PyTorch: A 60 Minute Blitz\". @ https:\/\/pytorch.org\/tutorials\/beginner\/deep_learning_60min_blitz.html <br\/>\n\nThe tutorial walks you through pytorch and tensors then provides example code to a CNN. I tweaked the sample code at the end and improved the test accuracy of the net.\n\nAuthor: Caleb Woy","79f0bbcb":"# Tutorial Code\n\n1.Loading and normalizing CIFAR10","38f09890":"# My Improvements\n\nNow I'll recreate the CNN. But with a few changes.","a3bfc3e8":"3. Define a Loss function and optimizer","c213d5d4":"2. Define a CNN","a552d06a":"4. Train the network","40df1a58":"Changes made:\n\n1. Utilized Cuda tensors to speed up training.\n51 to 55% accuracy\n\n2. Added a third convolutional layer and increased number of output channels for each convolutional layer.<br\/>\n55% to 63% accuracy\n\n3. Added a fourth fully connected hidden layer. I did this to increase the number of parameters in our Net a little further to get us closer to the point of interpolation.<br\/> \n63% to 68% accuracy\n\n4. Added 20% Dropout between each max pool and convolutional layer, increased epochs to 10. Dropout helps to make our Neural Net more robust by randomly reducing the spread of error for each backpropagation. This combats the vanishing gradient problem.<br\/> \n68% to 70% accuracy","6af4652e":"5. Test the network on the test data"}}