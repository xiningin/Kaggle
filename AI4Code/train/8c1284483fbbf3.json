{"cell_type":{"17e7f0dc":"code","f7397f6c":"code","335eebf1":"code","59f84600":"code","7ee33c4a":"code","de6a2ff8":"code","f03013f2":"code","161912dd":"code","706f7dc7":"code","7ea8cfcc":"code","16773cca":"code","2b7453f5":"code","d77ef636":"code","540b6343":"code","b96043ed":"code","b1ca3cd4":"code","4b48b306":"code","12cd9e45":"code","478150f8":"code","89691698":"code","38d3231f":"code","3622e796":"code","2c3a0911":"code","e9210643":"code","55d7278e":"code","682a0ab0":"code","e7762c42":"code","f2073152":"code","021043c0":"code","7deb85ab":"code","608d9b7c":"code","79bbf687":"code","2e1061be":"code","4471eec7":"code","f6c00b6e":"code","e8687d62":"code","32487dd0":"code","4c520c0c":"code","08007440":"code","59d6972f":"code","cc564a91":"code","3ba8a2b6":"code","4a0c918b":"code","943c3afd":"code","897cc936":"code","c6a4210a":"code","e71d8ac9":"code","915d1c79":"code","5afb15be":"markdown","f9bc16cd":"markdown","278d2b35":"markdown","53a9ba14":"markdown","592b5b8c":"markdown"},"source":{"17e7f0dc":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC  \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport missingno\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","f7397f6c":"traindata = pd.read_csv(\"..\/input\/musicalprefrences\/train.csv\")\ntestdata = pd.read_csv(\"..\/input\/musicalprefrences\/test.csv\")\n\nmusic_dataset = pd.concat([traindata, testdata]).reset_index(drop=True)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\npalette = ['#2596be',\"#e28743\",\"#80391e\"]\nsns.palplot(palette)","335eebf1":"music_dataset.head()","59f84600":"music_dataset.size","7ee33c4a":"missingno.bar(music_dataset, color=palette, figsize=(30,6))","de6a2ff8":"testdata.columns = [i.strip() for i in testdata.columns]\ntraindata.columns = [i.strip() for i in traindata.columns]","f03013f2":"print(testdata.columns)","161912dd":"print(traindata.columns)","706f7dc7":"raw1 = traindata.drop(['Id'],axis=1)","7ea8cfcc":"raw1.info()","16773cca":"testdata.info()","2b7453f5":"raw1.describe()","d77ef636":"raw2 = raw1.drop(['Album_type','Version'],axis=1)\ntestdata=testdata.drop(['Album_type','Version'],axis=1)\ntestdata['Vocal'].fillna('N',inplace=True)\nraw2 = raw2.reset_index(drop=True)","540b6343":"raw3 = raw2.dropna()\nraw3","b96043ed":"print(raw3.columns.values)","b1ca3cd4":"resort_columns=['Category','Duration','Release_year', 'BPM','Energy','Dancebility', 'Happiness','Artists', 'Track',  'Artists_Genres', 'Album',\n       'Labels', 'Key', 'Vocal', 'Country']\nresort_columns_t=['Duration','Release_year', 'BPM','Energy','Dancebility', 'Happiness','Artists', 'Track',  'Artists_Genres', 'Album',\n       'Labels', 'Key', 'Vocal', 'Country']\nraw4=raw3[resort_columns]\ntestdata=testdata[resort_columns_t]","4b48b306":"y_train=raw4['Category']\nraw4=pd.concat([raw4.drop(['Category'],axis=1),testdata],axis=0)","12cd9e45":"print('Artists:',len(raw4['Artists'].unique()))\nprint('Track:',len(raw4['Track'].unique()))\nprint('Key:',len(raw4['Key'].unique()))\nprint('Artists_Genres:',len(raw4['Artists_Genres'].unique()))\nprint('Vocal:',raw4['Vocal'].unique())\nprint('Country:',len(raw4['Country'].unique()))","478150f8":"print(raw4['Track'].value_counts())\nprint(raw4['Artists'].value_counts())\nprint(raw4['Vocal'].value_counts())","89691698":"raw4 = raw4.drop(['Track'],axis=1)","38d3231f":"raw4[\"isMajor\"], raw4[\"Key\"] = raw4[\"Key\"].apply(lambda x: x.split(\" \")[1]), raw4[\"Key\"].apply(lambda x: x.split(\" \")[0])\nraw4.loc[:,\"Key\"] = raw4[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\n\nraw4.loc[:,\"isMajor\"] = (raw4[\"isMajor\"]==\"Major\").astype(int)","3622e796":"keydum = pd.get_dummies(raw4[\"Key\"])\nkeydum = keydum.reset_index(drop=True)","2c3a0911":"def key2dum(key):\n    list_h=[]\n    list_l=[]\n    list_M=[]\n    for i in range(len(key)):\n        if '#' in key[i]:\n            list_h.extend([1])\n        else:\n            list_h.extend([0])\n        if '\u266d' in key[i]:\n            list_l.extend([1])\n        else:\n            list_l.extend([0])\n        # see major or not\n        if 'Major' in key[i]:\n            list_M.extend([1])\n        else:\n            list_M.extend([0])\n    dummydummy=pd.DataFrame({'#':list_h,'b':list_l,'Major or not':list_M})   \n    return dummydummy","e9210643":"raw4 = raw4.reset_index(drop=True)\nkeydum = key2dum(raw4['Key'])\nkeydum","55d7278e":"raw4 = raw4.reset_index(drop=True)\ndef voc2dum(key):\n    list_F=[]\n    list_M=[]\n    list_N=[]\n    for i in range(len(key)):\n        if 'F' in key[i]:\n            list_F.extend([1])\n        else:\n            list_F.extend([0])\n        # see major or not\n        if 'M' in key[i]:\n            list_M.extend([1])\n        else:\n            list_M.extend([0])\n        if 'N' in key[i]:\n            list_N.extend([1])\n        else:\n            list_N.extend([0])\n    dummydummy=pd.DataFrame({'VF':list_F,'VM':list_M,'VM':list_N})   \n    return dummydummy","682a0ab0":"vocdum=voc2dum(raw4['Vocal'])\nvocdum","e7762c42":"unique = []\nfor i in raw4.index:\n    unique.extend(raw4.loc[i,'Artists_Genres'].split(\"|\"))\n\nSuni = pd.Series(unique)\nprint(len(Suni.unique()))\nSuni = Suni.unique()","f2073152":"def style2dum(form,col):\n    data=np.zeros((len(col),len(form)))\n    for i in range(len(form)):\n        for j in range(len(col)):\n            if form[i] in col[j]:\n                data[j][i]=1\n    quasidum = pd.DataFrame(data )\n    return quasidum","021043c0":"stydum = style2dum(Suni,raw4['Artists_Genres'])\nstydum.columns = Suni\nstydum.columns","7deb85ab":"stydum","608d9b7c":"den = stydum.sum(axis=1)\nimport math\n\nfor i in range(946):\n    for j in Suni:\n        stydum.loc[i,j]\/=math.sqrt(den[i])","79bbf687":"embedding = TSNE(n_components = 2, init = \"pca\")\nesd = embedding.fit_transform(stydum)\nesd = pd.DataFrame(esd, columns = [\"sty_tsne1\",\"sty_tsne2\"])","2e1061be":"extdum = pd.get_dummies(raw4['Country'])\nembedding1 = TSNE(n_components=2, init=\"pca\")\nesd1 = embedding1.fit_transform(extdum)\nesd1 = pd.DataFrame(esd1,columns=[\"con_tsne1\",\"con_tsne2\"])\n","4471eec7":"namedum = pd.get_dummies(raw4['Artists'])\nembedding2 = TSNE(n_components=3, init=\"pca\")\nesd2 = embedding1.fit_transform(namedum)\nesd2 = pd.DataFrame(esd1,columns=[\"name_tsne1\",\"name_tsne2\"])","f6c00b6e":"raw5 = pd.concat([raw4,esd,esd1,vocdum,keydum],axis=1)\nraw5 = raw5.drop(['Artists_Genres','Key','Vocal','Country','Artists','Album','Labels'],axis = 1)\nraw5","e8687d62":"scaler = MinMaxScaler()\nscaler.fit(raw5)\n\nraw5 = pd.DataFrame(data=scaler.transform(raw5),columns = raw5.columns,index=raw5.index)\n\nraw5.to_csv('clean_data.csv',index=0)\n\nX_train=raw5[raw5.index<len(y_train)]\nX_test =raw5[raw5.index>=len(y_train)]\n\nXt_train, Xt_test, yt_train, yt_test = train_test_split(X_train, y_train, test_size = 0.20,random_state=5467)","32487dd0":"svclassifier = SVC(kernel='poly')\nfitted = svclassifier.fit(Xt_train, yt_train)\ny_pred = svclassifier.predict(Xt_test)\n\nsvclassifierl = SVC(kernel='linear')\nfittedl = svclassifierl.fit(Xt_train, yt_train)\ny_predl = svclassifierl.predict(Xt_test)","4c520c0c":"KN = KNeighborsClassifier()\nKN.fit(Xt_train,yt_train)\nKN_pred = KN.predict(Xt_test)","08007440":"rf = RandomForestClassifier()\nrf.fit(Xt_train,yt_train)\nrf_pred = rf.predict(Xt_test)","59d6972f":"gd = GradientBoostingClassifier()\ngd.fit(Xt_train,yt_train)\ngd_pred = gd.predict(Xt_test)","cc564a91":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(Xt_train,yt_train)\ntree_pred = decision_tree.predict(Xt_test)","3ba8a2b6":"regr = LogisticRegression() \nregr.fit(Xt_train, yt_train)\nLog_pred = regr.predict(Xt_test)","4a0c918b":"print('Logistic_Regression:',accuracy_score(yt_test, Log_pred)*100,'%')\nprint('Decision Tree:', accuracy_score(yt_test, tree_pred)*100,'%') # to summarize all\nprint('Random Forest:', accuracy_score(yt_test, rf_pred)*100,'%')\nprint('Gradient Boost:', accuracy_score(yt_test, gd_pred)*100,'%')\nprint('KNeighbors:',accuracy_score(yt_test, KN_pred)*100,'%')\nprint('SVM_p:',accuracy_score(yt_test, y_pred)*100,'%')\nprint('SVM_l:',accuracy_score(yt_test, y_predl)*100,'%')","943c3afd":"gd_scored = cross_val_score(gd,X_train,y_train,cv=5)\nprint(gd_scored)\nprint(confusion_matrix(yt_test,gd_pred))\nprint(classification_report(yt_test,gd_pred))","897cc936":"rf_scored=cross_val_score(rf,X_train,y_train,cv=5)\nprint(rf_scored)\nprint(confusion_matrix(yt_test,rf_pred))\nprint(classification_report(yt_test,rf_pred))","c6a4210a":"final_pred = gd.predict(X_test)\nfinal_pred","e71d8ac9":"final_pred=pd.DataFrame({'Id':np.linspace(665,964,300,dtype=np.int16),'Category':final_pred})\nfinal_pred.to_csv('submission.csv',index=0)","915d1c79":"final_pred.head()","5afb15be":"The same song with different key or other things is a problem \\\nWe assume that the name is less important than the other features, so we'll just drop it.","f9bc16cd":"We can see that Random Forest and Gradient Boost. Let's go to see how good they are more precisely.\n","278d2b35":"Then first I will make a linear model for testing, that is, assume that the effects are linearly added.","53a9ba14":"We decide to drop irrelated columns, after that we will delete all line with null-value ","592b5b8c":"Listing all unique Artists_Genres"}}