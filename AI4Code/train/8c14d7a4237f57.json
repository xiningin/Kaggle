{"cell_type":{"e131691f":"code","ab110ad6":"code","9906970e":"code","53f27100":"code","103c18d2":"code","ad2c8975":"code","107390c3":"code","734b884f":"code","040ab9f1":"code","e4ebaacf":"code","5e8fb358":"code","f48d8551":"code","02718dc8":"code","622fe800":"code","13f9c067":"code","c83e38b9":"code","b2278a64":"code","85b94d43":"code","eb9d2ae8":"code","6aad0e57":"code","d3c081c7":"code","38ed13d2":"code","64ecc2e6":"code","7e351e3e":"code","c596f9f8":"code","d68d3a03":"code","767c3082":"code","05bf6d64":"code","cfec4699":"code","76cb9e10":"code","d7d5cf76":"code","12cba861":"code","606fa7a7":"code","3a3d5731":"code","c16e3b4d":"code","eb7800c7":"code","2902df98":"code","fe97bb19":"code","ae48ceda":"code","ba860207":"code","c24afa40":"code","48b7d40a":"code","8777425b":"code","aeaa3a4f":"markdown","53b7763e":"markdown","40b89e2d":"markdown","2fd09164":"markdown","4c6b52a7":"markdown","7357ac78":"markdown","a7cc1511":"markdown","3c972cc9":"markdown","2f118bca":"markdown"},"source":{"e131691f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab110ad6":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","9906970e":"heart = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","53f27100":"heart.head()","103c18d2":"heart.shape","ad2c8975":"heart.info()","107390c3":"heart.isnull().sum()","734b884f":"sns.countplot(heart['sex'])","040ab9f1":"sns.countplot(heart['cp'])","e4ebaacf":"sns.countplot(heart['fbs'])","5e8fb358":"sns.countplot(heart['restecg'])","f48d8551":"sns.countplot(heart['exang'])","02718dc8":"sns.countplot(heart['slope'])","622fe800":"sns.countplot(heart['ca'])","13f9c067":"sns.countplot(heart['thal'])","c83e38b9":"sns.countplot(heart['target'])","b2278a64":"plt.scatter(heart['trestbps'], heart['age'])\nplt.xlabel('resting blood pressure (trestbps)')\nplt.ylabel('age')","85b94d43":"plt.scatter(heart['chol'], heart['age'])\nplt.xlabel('serum cholestoral (chol)')\nplt.ylabel('age')","eb9d2ae8":"plt.scatter(heart['thalach'], heart['age'])\nplt.xlabel('maximum heart rate achieved (thalach)')\nplt.ylabel('age')","6aad0e57":"plt.scatter(heart['oldpeak'], heart['age'])\nplt.xlabel('oldpeak')\nplt.ylabel('age')","d3c081c7":"sns.pairplot(data=heart)","38ed13d2":"sns.heatmap(data=heart)","64ecc2e6":"heart.corr()","7e351e3e":"sns.heatmap(heart.corr())","c596f9f8":"x = heart.drop(['target'], axis = 1)\ny = heart['target']","d68d3a03":"from sklearn.model_selection import train_test_split\n","767c3082":"x_train, x_test, y_train, y_test = train_test_split(x,y, train_size = 0.6, random_state = 2)","05bf6d64":"from sklearn.preprocessing import StandardScaler","cfec4699":"sc = StandardScaler()","76cb9e10":"x_train_1 = sc.fit_transform(x_train);x_train_1.shape","d7d5cf76":"x_test_1 = sc.fit_transform(x_test);x_test_1.shape","12cba861":"from sklearn.linear_model import LogisticRegression","606fa7a7":"log = LogisticRegression(random_state = 3)","3a3d5731":"log.fit(x_train_1,y_train)","c16e3b4d":"y_pred = log.predict(x_test_1)\ny_pred","eb7800c7":"from sklearn.metrics import confusion_matrix","2902df98":"cm = confusion_matrix(y_test, y_pred)\ncm","fe97bb19":"from sklearn.metrics import accuracy_score","ae48ceda":"acc = accuracy_score(y_test, y_pred)\nacc","ba860207":"#Training score\nTrain_score = log.score(x_train_1,y_train)\n#Testing score\nTest_score = log.score(x_test_1,y_test)\n","c24afa40":"Train_score","48b7d40a":"Test_score","8777425b":"index = [0.001 , 0.1 ,0.01 , 1 , 10 , 100 ,1000]\ntrain = pd.Series()\ntest = pd.Series()\nfor i in index:\n    clf = LogisticRegression(C=i)\n    clf.fit(x_train_1,y_train)\n    y_pred_LR = classifier.predict(x_test_1)\n    train = train.append(pd.Series(clf.score(x_train_1,y_train)))\n    test = test.append(pd.Series(clf.score(x_test_1,y_test)))\n    \nplt.plot(index, train)\nplt.plot(index, test)\nplt.xticks(index)    \n","aeaa3a4f":"# Implementing Logistic Regression","53b7763e":"# Scaling our x_train and x_test ","40b89e2d":"# Correlation","2fd09164":"# Importing Dataset","4c6b52a7":"# Importing Libraries","7357ac78":"# Testing and Training Data","a7cc1511":"# Splitting Data into X and Y","3c972cc9":"# Visualization","2f118bca":"# Understanding Dataset"}}