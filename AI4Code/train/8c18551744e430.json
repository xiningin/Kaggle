{"cell_type":{"12f78b07":"code","a54322db":"code","6d31aced":"code","cd7e402c":"code","a2036ea2":"code","cc33a43f":"code","09c311c3":"code","586e8146":"code","986e61f9":"code","59f091b7":"code","3d8397d0":"code","510128e9":"code","2b560da7":"code","d603bd6d":"code","d81da6f8":"markdown","26d7f483":"markdown","f4a2efec":"markdown","14c9bd3c":"markdown","bc591252":"markdown","84eb2e3f":"markdown","397ab3d7":"markdown","3e3261c5":"markdown"},"source":{"12f78b07":"import numpy as np\nimport pandas as pd\nimport keras \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D,AveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils.vis_utils import plot_model\nfrom keras.layers import Input, GlobalAveragePooling2D\nfrom keras import models\nfrom keras.models import Model","a54322db":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")","6d31aced":"train.head()","cd7e402c":"Y = train[\"label\"]\nX = train.drop([\"label\"], axis=1)","a2036ea2":"X = X.values.reshape(-1,28,28,1)\nX = X\/255.0\nX.shape","cc33a43f":"train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.2, random_state=42)","09c311c3":"nRows,nCols,nDims = train_X.shape[1:]\ninput_shape = (nRows, nCols, nDims)\ninput_img = Input(shape=(28, 28, 1))","586e8146":"l1 = Conv2D(64, (3,3), activation='relu', padding = 'valid')(input_img)\nl2 = Conv2D(32, (1,1), padding='valid', activation='relu')(l1)\nl3 = MaxPooling2D((2,2),strides=(2,2))(l2)\nmid = Conv2D(8, (3,3), padding='valid', activation='relu')(l3)\nl4 = Conv2D(8, (1,1), padding='valid', activation='relu')(mid)\nl5 = MaxPooling2D((2,2),strides=(1,1))(l4)\nl6 = Conv2D(8, (3,3), padding='valid', activation='relu')(l5)\nl7 = Conv2D(6, (1,1), padding='valid', activation='relu')(l6)\noutput = Flatten()(l7)\nout    = Dense(10, activation='softmax')(output)","986e61f9":"model = Model(inputs = input_img, outputs = out)\nmodel.summary()","59f091b7":"plot_model(model, to_file='model_plot_MNIST_9.5K.png', show_shapes=True, show_layer_names=True)","3d8397d0":"model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])","510128e9":"history = model.fit(train_X, train_Y, validation_data=(val_X, val_Y), epochs=20, batch_size=32)","2b560da7":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","d603bd6d":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Training Loss vs Validation Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","d81da6f8":"### **Training the Model** ","26d7f483":"### **Model Architecture**","f4a2efec":"### **Loading the dataset** ","14c9bd3c":"![](https:\/\/media1.tenor.com\/images\/268bede39f4a5110e9cc1bd560db5474\/tenor.gif?itemid=3565457)","bc591252":"### **Importing the Libraries**","84eb2e3f":"### **Preprocessing Steps**","397ab3d7":"If you liked this notebook, then do **Upvote** as it will keep me motivated in creating such kernels ahead. **Thanks!!**\n","3e3261c5":"### **Output Visualizations** "}}